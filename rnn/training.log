vocab.t7 or data.t7 detected as stale. Re-running preprocessing...	
one-time setup: preprocessing input text file /home/ubuntu/scimirrorbot/dat/training/input.txt...	
loading text file...	
creating vocabulary mapping...	
putting data into tensor...	
saving /home/ubuntu/scimirrorbot/dat/training/vocab.t7	
saving /home/ubuntu/scimirrorbot/dat/training/data.t7	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 471, val: 25, test: 0	
vocab size: 120	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 275576	
cloning rnn	
cloning criterion	
1/23550 (epoch 0.002), train_loss = 4.79176111, grad/param norm = 6.1325e-01, time/batch = 0.6945s	
2/23550 (epoch 0.004), train_loss = 4.29296728, grad/param norm = 1.7338e+00, time/batch = 0.6549s	
3/23550 (epoch 0.006), train_loss = 3.60653511, grad/param norm = 1.0337e+00, time/batch = 0.6545s	
4/23550 (epoch 0.008), train_loss = 3.56212004, grad/param norm = 1.0872e+00, time/batch = 0.6531s	
5/23550 (epoch 0.011), train_loss = 3.51078897, grad/param norm = 9.2583e-01, time/batch = 0.6512s	
6/23550 (epoch 0.013), train_loss = 3.40065499, grad/param norm = 6.6667e-01, time/batch = 0.6527s	
7/23550 (epoch 0.015), train_loss = 3.36569302, grad/param norm = 7.7007e-01, time/batch = 0.6527s	
8/23550 (epoch 0.017), train_loss = 3.42386916, grad/param norm = 7.4965e-01, time/batch = 0.6548s	
9/23550 (epoch 0.019), train_loss = 3.46371933, grad/param norm = 7.3143e-01, time/batch = 0.6527s	
10/23550 (epoch 0.021), train_loss = 3.31483083, grad/param norm = 6.7675e-01, time/batch = 0.6502s	
11/23550 (epoch 0.023), train_loss = 3.33069913, grad/param norm = 5.6701e-01, time/batch = 0.6502s	
12/23550 (epoch 0.025), train_loss = 3.51358881, grad/param norm = 6.2219e-01, time/batch = 0.6500s	
13/23550 (epoch 0.028), train_loss = 3.50400775, grad/param norm = 4.9673e-01, time/batch = 0.6497s	
14/23550 (epoch 0.030), train_loss = 3.52927452, grad/param norm = 6.3974e-01, time/batch = 0.6501s	
15/23550 (epoch 0.032), train_loss = 3.44186326, grad/param norm = 6.4561e-01, time/batch = 0.6500s	
16/23550 (epoch 0.034), train_loss = 3.50982599, grad/param norm = 6.3111e-01, time/batch = 0.6504s	
17/23550 (epoch 0.036), train_loss = 3.33848809, grad/param norm = 7.0074e-01, time/batch = 0.6513s	
18/23550 (epoch 0.038), train_loss = 3.54744392, grad/param norm = 6.9349e-01, time/batch = 0.6611s	
19/23550 (epoch 0.040), train_loss = 3.45590369, grad/param norm = 6.8722e-01, time/batch = 0.6501s	
20/23550 (epoch 0.042), train_loss = 3.33290948, grad/param norm = 6.7523e-01, time/batch = 0.6539s	
21/23550 (epoch 0.045), train_loss = 3.51375173, grad/param norm = 6.4219e-01, time/batch = 0.6525s	
22/23550 (epoch 0.047), train_loss = 3.43594797, grad/param norm = 6.2150e-01, time/batch = 0.6503s	
23/23550 (epoch 0.049), train_loss = 3.53378152, grad/param norm = 6.1429e-01, time/batch = 0.6536s	
24/23550 (epoch 0.051), train_loss = 3.33520067, grad/param norm = 5.7537e-01, time/batch = 0.6495s	
25/23550 (epoch 0.053), train_loss = 3.31830315, grad/param norm = 7.3996e-01, time/batch = 0.6534s	
26/23550 (epoch 0.055), train_loss = 3.43561604, grad/param norm = 5.7690e-01, time/batch = 0.6552s	
27/23550 (epoch 0.057), train_loss = 3.47692481, grad/param norm = 7.1005e-01, time/batch = 0.6577s	
28/23550 (epoch 0.059), train_loss = 3.35971695, grad/param norm = 6.0947e-01, time/batch = 0.6508s	
29/23550 (epoch 0.062), train_loss = 3.41626557, grad/param norm = 7.8842e-01, time/batch = 0.6538s	
30/23550 (epoch 0.064), train_loss = 3.33760220, grad/param norm = 5.6769e-01, time/batch = 0.6509s	
31/23550 (epoch 0.066), train_loss = 3.35989943, grad/param norm = 5.6796e-01, time/batch = 0.6532s	
32/23550 (epoch 0.068), train_loss = 3.44265924, grad/param norm = 5.7598e-01, time/batch = 0.6515s	
33/23550 (epoch 0.070), train_loss = 3.31210285, grad/param norm = 7.5591e-01, time/batch = 0.6500s	
34/23550 (epoch 0.072), train_loss = 3.27426862, grad/param norm = 6.7069e-01, time/batch = 0.6509s	
35/23550 (epoch 0.074), train_loss = 3.27456789, grad/param norm = 7.3000e-01, time/batch = 0.6531s	
36/23550 (epoch 0.076), train_loss = 3.41678110, grad/param norm = 5.6981e-01, time/batch = 0.6526s	
37/23550 (epoch 0.079), train_loss = 3.27430895, grad/param norm = 8.1795e-01, time/batch = 0.6512s	
38/23550 (epoch 0.081), train_loss = 3.36939052, grad/param norm = 7.9380e-01, time/batch = 0.6496s	
39/23550 (epoch 0.083), train_loss = 3.43417009, grad/param norm = 6.4789e-01, time/batch = 0.6500s	
40/23550 (epoch 0.085), train_loss = 3.37530482, grad/param norm = 6.6797e-01, time/batch = 0.6496s	
41/23550 (epoch 0.087), train_loss = 3.31889329, grad/param norm = 6.4657e-01, time/batch = 0.6504s	
42/23550 (epoch 0.089), train_loss = 3.54269777, grad/param norm = 9.8093e-01, time/batch = 0.6502s	
43/23550 (epoch 0.091), train_loss = 3.47795753, grad/param norm = 5.5836e-01, time/batch = 0.6546s	
44/23550 (epoch 0.093), train_loss = 3.37310781, grad/param norm = 6.4340e-01, time/batch = 0.6503s	
45/23550 (epoch 0.096), train_loss = 3.30960835, grad/param norm = 6.6597e-01, time/batch = 0.6497s	
46/23550 (epoch 0.098), train_loss = 3.39356809, grad/param norm = 5.9705e-01, time/batch = 0.6499s	
47/23550 (epoch 0.100), train_loss = 3.41124277, grad/param norm = 5.7653e-01, time/batch = 0.6527s	
48/23550 (epoch 0.102), train_loss = 3.36231551, grad/param norm = 4.7257e-01, time/batch = 0.6494s	
49/23550 (epoch 0.104), train_loss = 3.44112484, grad/param norm = 5.3006e-01, time/batch = 0.6548s	
50/23550 (epoch 0.106), train_loss = 3.49892851, grad/param norm = 6.8740e-01, time/batch = 0.6500s	
51/23550 (epoch 0.108), train_loss = 3.45194863, grad/param norm = 5.4796e-01, time/batch = 0.6516s	
52/23550 (epoch 0.110), train_loss = 3.32518225, grad/param norm = 5.1813e-01, time/batch = 0.6512s	
53/23550 (epoch 0.113), train_loss = 3.39945451, grad/param norm = 5.0821e-01, time/batch = 0.6537s	
54/23550 (epoch 0.115), train_loss = 3.26194280, grad/param norm = 7.1975e-01, time/batch = 0.6534s	
55/23550 (epoch 0.117), train_loss = 3.55900321, grad/param norm = 8.2819e-01, time/batch = 0.6495s	
56/23550 (epoch 0.119), train_loss = 3.36073972, grad/param norm = 6.6093e-01, time/batch = 0.6572s	
57/23550 (epoch 0.121), train_loss = 3.51212983, grad/param norm = 6.0643e-01, time/batch = 0.6521s	
58/23550 (epoch 0.123), train_loss = 3.35349912, grad/param norm = 6.6024e-01, time/batch = 0.6498s	
59/23550 (epoch 0.125), train_loss = 3.34851919, grad/param norm = 7.2441e-01, time/batch = 0.6499s	
60/23550 (epoch 0.127), train_loss = 3.35269471, grad/param norm = 6.8778e-01, time/batch = 0.6498s	
61/23550 (epoch 0.130), train_loss = 3.40013549, grad/param norm = 7.0854e-01, time/batch = 0.6567s	
62/23550 (epoch 0.132), train_loss = 3.39604133, grad/param norm = 5.8790e-01, time/batch = 0.6516s	
63/23550 (epoch 0.134), train_loss = 3.37078631, grad/param norm = 5.8127e-01, time/batch = 0.6512s	
64/23550 (epoch 0.136), train_loss = 3.39801583, grad/param norm = 5.8512e-01, time/batch = 0.6515s	
65/23550 (epoch 0.138), train_loss = 3.48007306, grad/param norm = 7.8051e-01, time/batch = 0.6521s	
66/23550 (epoch 0.140), train_loss = 3.31125953, grad/param norm = 5.8096e-01, time/batch = 0.6510s	
67/23550 (epoch 0.142), train_loss = 3.49973251, grad/param norm = 4.8565e-01, time/batch = 0.6499s	
68/23550 (epoch 0.144), train_loss = 3.35503845, grad/param norm = 8.1273e-01, time/batch = 0.6505s	
69/23550 (epoch 0.146), train_loss = 3.36446477, grad/param norm = 5.5807e-01, time/batch = 0.6506s	
70/23550 (epoch 0.149), train_loss = 3.32510690, grad/param norm = 6.3392e-01, time/batch = 0.6516s	
71/23550 (epoch 0.151), train_loss = 3.26861294, grad/param norm = 5.0558e-01, time/batch = 0.6550s	
72/23550 (epoch 0.153), train_loss = 3.44602390, grad/param norm = 7.0812e-01, time/batch = 0.6531s	
73/23550 (epoch 0.155), train_loss = 3.30639178, grad/param norm = 4.8014e-01, time/batch = 0.6538s	
74/23550 (epoch 0.157), train_loss = 3.37806682, grad/param norm = 5.7422e-01, time/batch = 0.6562s	
75/23550 (epoch 0.159), train_loss = 3.35289767, grad/param norm = 5.3108e-01, time/batch = 0.6640s	
76/23550 (epoch 0.161), train_loss = 3.39242251, grad/param norm = 5.7020e-01, time/batch = 0.6594s	
77/23550 (epoch 0.163), train_loss = 3.34619855, grad/param norm = 5.2859e-01, time/batch = 0.6548s	
78/23550 (epoch 0.166), train_loss = 3.37537378, grad/param norm = 4.4104e-01, time/batch = 0.6553s	
79/23550 (epoch 0.168), train_loss = 3.35334474, grad/param norm = 6.4614e-01, time/batch = 0.6526s	
80/23550 (epoch 0.170), train_loss = 3.33862074, grad/param norm = 4.8981e-01, time/batch = 0.6537s	
81/23550 (epoch 0.172), train_loss = 3.43869874, grad/param norm = 6.2260e-01, time/batch = 0.6519s	
82/23550 (epoch 0.174), train_loss = 3.36678135, grad/param norm = 5.6124e-01, time/batch = 0.6499s	
83/23550 (epoch 0.176), train_loss = 3.27118947, grad/param norm = 6.1632e-01, time/batch = 0.6492s	
84/23550 (epoch 0.178), train_loss = 3.39095175, grad/param norm = 6.8105e-01, time/batch = 0.6503s	
85/23550 (epoch 0.180), train_loss = 3.37269511, grad/param norm = 7.9166e-01, time/batch = 0.6526s	
86/23550 (epoch 0.183), train_loss = 3.44216760, grad/param norm = 1.0328e+00, time/batch = 0.6500s	
87/23550 (epoch 0.185), train_loss = 3.35068883, grad/param norm = 6.9126e-01, time/batch = 0.6504s	
88/23550 (epoch 0.187), train_loss = 3.30080717, grad/param norm = 4.2169e-01, time/batch = 0.6493s	
89/23550 (epoch 0.189), train_loss = 3.46576523, grad/param norm = 5.4897e-01, time/batch = 0.6503s	
90/23550 (epoch 0.191), train_loss = 3.24763527, grad/param norm = 7.3538e-01, time/batch = 0.6530s	
91/23550 (epoch 0.193), train_loss = 3.22175775, grad/param norm = 7.0284e-01, time/batch = 0.6528s	
92/23550 (epoch 0.195), train_loss = 3.43380353, grad/param norm = 7.1790e-01, time/batch = 0.6537s	
93/23550 (epoch 0.197), train_loss = 3.45870637, grad/param norm = 6.1016e-01, time/batch = 0.6527s	
94/23550 (epoch 0.200), train_loss = 3.37910151, grad/param norm = 6.6175e-01, time/batch = 0.6522s	
95/23550 (epoch 0.202), train_loss = 3.21852573, grad/param norm = 5.6220e-01, time/batch = 0.6524s	
96/23550 (epoch 0.204), train_loss = 3.40348457, grad/param norm = 5.5993e-01, time/batch = 0.6525s	
97/23550 (epoch 0.206), train_loss = 3.46873235, grad/param norm = 6.3836e-01, time/batch = 0.6524s	
98/23550 (epoch 0.208), train_loss = 3.33088763, grad/param norm = 4.7145e-01, time/batch = 0.6531s	
99/23550 (epoch 0.210), train_loss = 3.25016662, grad/param norm = 4.0474e-01, time/batch = 0.6619s	
100/23550 (epoch 0.212), train_loss = 3.25323454, grad/param norm = 6.4027e-01, time/batch = 0.6831s	
101/23550 (epoch 0.214), train_loss = 3.29856649, grad/param norm = 1.0792e+00, time/batch = 0.6544s	
102/23550 (epoch 0.217), train_loss = 3.32942236, grad/param norm = 6.6332e-01, time/batch = 0.6519s	
103/23550 (epoch 0.219), train_loss = 3.38562486, grad/param norm = 5.9490e-01, time/batch = 0.6521s	
104/23550 (epoch 0.221), train_loss = 3.41808993, grad/param norm = 6.7665e-01, time/batch = 0.6525s	
105/23550 (epoch 0.223), train_loss = 3.29922340, grad/param norm = 5.0873e-01, time/batch = 0.6529s	
106/23550 (epoch 0.225), train_loss = 3.36208509, grad/param norm = 4.9100e-01, time/batch = 0.6499s	
107/23550 (epoch 0.227), train_loss = 3.38363646, grad/param norm = 6.7562e-01, time/batch = 0.6499s	
108/23550 (epoch 0.229), train_loss = 3.25059253, grad/param norm = 5.5716e-01, time/batch = 0.6496s	
109/23550 (epoch 0.231), train_loss = 3.37614898, grad/param norm = 4.9455e-01, time/batch = 0.6508s	
110/23550 (epoch 0.234), train_loss = 3.33167857, grad/param norm = 4.9995e-01, time/batch = 0.6504s	
111/23550 (epoch 0.236), train_loss = 3.34770974, grad/param norm = 5.2924e-01, time/batch = 0.6516s	
112/23550 (epoch 0.238), train_loss = 3.38862336, grad/param norm = 8.1771e-01, time/batch = 0.6524s	
113/23550 (epoch 0.240), train_loss = 3.56346669, grad/param norm = 1.5825e+00, time/batch = 0.6500s	
114/23550 (epoch 0.242), train_loss = 3.46680022, grad/param norm = 9.7599e-01, time/batch = 0.6504s	
115/23550 (epoch 0.244), train_loss = 3.20973679, grad/param norm = 6.5598e-01, time/batch = 0.6510s	
116/23550 (epoch 0.246), train_loss = 3.36860587, grad/param norm = 5.1582e-01, time/batch = 0.6509s	
117/23550 (epoch 0.248), train_loss = 3.28367598, grad/param norm = 4.4227e-01, time/batch = 0.6527s	
118/23550 (epoch 0.251), train_loss = 3.25553317, grad/param norm = 4.7576e-01, time/batch = 0.6523s	
119/23550 (epoch 0.253), train_loss = 3.23997993, grad/param norm = 5.7870e-01, time/batch = 0.6554s	
120/23550 (epoch 0.255), train_loss = 3.34072945, grad/param norm = 4.7802e-01, time/batch = 0.6531s	
121/23550 (epoch 0.257), train_loss = 3.49670571, grad/param norm = 5.0225e-01, time/batch = 0.6537s	
122/23550 (epoch 0.259), train_loss = 3.38935150, grad/param norm = 3.9886e-01, time/batch = 0.6521s	
123/23550 (epoch 0.261), train_loss = 3.20119927, grad/param norm = 3.9807e-01, time/batch = 0.6515s	
124/23550 (epoch 0.263), train_loss = 3.23424599, grad/param norm = 4.8532e-01, time/batch = 0.6517s	
125/23550 (epoch 0.265), train_loss = 3.29445871, grad/param norm = 7.1640e-01, time/batch = 0.6545s	
126/23550 (epoch 0.268), train_loss = 3.12514943, grad/param norm = 9.0826e-01, time/batch = 0.6582s	
127/23550 (epoch 0.270), train_loss = 3.12455748, grad/param norm = 7.7897e-01, time/batch = 0.6525s	
128/23550 (epoch 0.272), train_loss = 3.32247352, grad/param norm = 8.2168e-01, time/batch = 0.6527s	
129/23550 (epoch 0.274), train_loss = 3.20996559, grad/param norm = 8.3583e-01, time/batch = 0.6517s	
130/23550 (epoch 0.276), train_loss = 3.29610532, grad/param norm = 6.6582e-01, time/batch = 0.6532s	
131/23550 (epoch 0.278), train_loss = 3.12139212, grad/param norm = 5.7438e-01, time/batch = 0.6569s	
132/23550 (epoch 0.280), train_loss = 3.29903126, grad/param norm = 7.6611e-01, time/batch = 0.6638s	
133/23550 (epoch 0.282), train_loss = 3.22252360, grad/param norm = 1.0903e+00, time/batch = 0.6601s	
134/23550 (epoch 0.285), train_loss = 3.17522747, grad/param norm = 8.7383e-01, time/batch = 0.6578s	
135/23550 (epoch 0.287), train_loss = 3.32595468, grad/param norm = 3.8548e-01, time/batch = 0.6581s	
136/23550 (epoch 0.289), train_loss = 3.14311504, grad/param norm = 4.5089e-01, time/batch = 0.6568s	
137/23550 (epoch 0.291), train_loss = 3.09938312, grad/param norm = 5.6955e-01, time/batch = 0.6535s	
138/23550 (epoch 0.293), train_loss = 3.21567170, grad/param norm = 6.0777e-01, time/batch = 0.6520s	
139/23550 (epoch 0.295), train_loss = 3.08359203, grad/param norm = 5.6354e-01, time/batch = 0.6521s	
140/23550 (epoch 0.297), train_loss = 3.34226968, grad/param norm = 5.0076e-01, time/batch = 0.6531s	
141/23550 (epoch 0.299), train_loss = 3.04282051, grad/param norm = 5.7652e-01, time/batch = 0.6645s	
142/23550 (epoch 0.301), train_loss = 3.16872485, grad/param norm = 8.4601e-01, time/batch = 0.6558s	
143/23550 (epoch 0.304), train_loss = 3.29918368, grad/param norm = 9.8132e-01, time/batch = 0.6513s	
144/23550 (epoch 0.306), train_loss = 3.12801454, grad/param norm = 7.9880e-01, time/batch = 0.6515s	
145/23550 (epoch 0.308), train_loss = 3.13622587, grad/param norm = 6.6469e-01, time/batch = 0.6568s	
146/23550 (epoch 0.310), train_loss = 3.23704747, grad/param norm = 1.1897e+00, time/batch = 0.6572s	
147/23550 (epoch 0.312), train_loss = 3.16065272, grad/param norm = 1.1835e+00, time/batch = 0.6547s	
148/23550 (epoch 0.314), train_loss = 3.30460110, grad/param norm = 8.2487e-01, time/batch = 0.6548s	
149/23550 (epoch 0.316), train_loss = 3.13599065, grad/param norm = 5.8763e-01, time/batch = 0.6531s	
150/23550 (epoch 0.318), train_loss = 3.23434108, grad/param norm = 5.3517e-01, time/batch = 0.6515s	
151/23550 (epoch 0.321), train_loss = 3.19856310, grad/param norm = 4.1727e-01, time/batch = 0.6550s	
152/23550 (epoch 0.323), train_loss = 3.21927179, grad/param norm = 4.3043e-01, time/batch = 0.6521s	
153/23550 (epoch 0.325), train_loss = 3.10263034, grad/param norm = 4.4560e-01, time/batch = 0.6576s	
154/23550 (epoch 0.327), train_loss = 3.12129987, grad/param norm = 5.6216e-01, time/batch = 0.6516s	
155/23550 (epoch 0.329), train_loss = 3.18058419, grad/param norm = 7.4206e-01, time/batch = 0.6520s	
156/23550 (epoch 0.331), train_loss = 3.13270069, grad/param norm = 6.5770e-01, time/batch = 0.6895s	
157/23550 (epoch 0.333), train_loss = 3.26501141, grad/param norm = 3.7870e-01, time/batch = 0.6589s	
158/23550 (epoch 0.335), train_loss = 3.01639884, grad/param norm = 5.0733e-01, time/batch = 0.6546s	
159/23550 (epoch 0.338), train_loss = 3.14359629, grad/param norm = 9.6520e-01, time/batch = 0.6537s	
160/23550 (epoch 0.340), train_loss = 3.14418506, grad/param norm = 1.1020e+00, time/batch = 0.6544s	
161/23550 (epoch 0.342), train_loss = 3.19479817, grad/param norm = 7.8505e-01, time/batch = 0.6541s	
162/23550 (epoch 0.344), train_loss = 3.24202064, grad/param norm = 4.3545e-01, time/batch = 0.6523s	
163/23550 (epoch 0.346), train_loss = 3.16781693, grad/param norm = 4.5923e-01, time/batch = 0.6519s	
164/23550 (epoch 0.348), train_loss = 3.11426127, grad/param norm = 5.5979e-01, time/batch = 0.6536s	
165/23550 (epoch 0.350), train_loss = 2.95226830, grad/param norm = 1.1080e+00, time/batch = 0.6517s	
166/23550 (epoch 0.352), train_loss = 3.03183153, grad/param norm = 1.2055e+00, time/batch = 0.6515s	
167/23550 (epoch 0.355), train_loss = 3.17185192, grad/param norm = 7.2514e-01, time/batch = 0.6514s	
168/23550 (epoch 0.357), train_loss = 3.00998658, grad/param norm = 3.1129e-01, time/batch = 0.6511s	
169/23550 (epoch 0.359), train_loss = 3.17267856, grad/param norm = 4.3427e-01, time/batch = 0.6505s	
170/23550 (epoch 0.361), train_loss = 3.06450670, grad/param norm = 4.4842e-01, time/batch = 0.6531s	
171/23550 (epoch 0.363), train_loss = 2.96922077, grad/param norm = 4.2590e-01, time/batch = 0.6552s	
172/23550 (epoch 0.365), train_loss = 3.10220741, grad/param norm = 5.7256e-01, time/batch = 0.6540s	
173/23550 (epoch 0.367), train_loss = 3.00820691, grad/param norm = 5.1306e-01, time/batch = 0.6520s	
174/23550 (epoch 0.369), train_loss = 3.03811676, grad/param norm = 4.4828e-01, time/batch = 0.6514s	
175/23550 (epoch 0.372), train_loss = 3.01771353, grad/param norm = 5.3146e-01, time/batch = 0.6515s	
176/23550 (epoch 0.374), train_loss = 3.05521781, grad/param norm = 8.3233e-01, time/batch = 0.6514s	
177/23550 (epoch 0.376), train_loss = 3.19030821, grad/param norm = 7.7650e-01, time/batch = 0.6550s	
178/23550 (epoch 0.378), train_loss = 3.00362761, grad/param norm = 5.4584e-01, time/batch = 0.6545s	
179/23550 (epoch 0.380), train_loss = 2.98934841, grad/param norm = 6.5278e-01, time/batch = 0.6521s	
180/23550 (epoch 0.382), train_loss = 3.04323306, grad/param norm = 1.0447e+00, time/batch = 0.6514s	
181/23550 (epoch 0.384), train_loss = 3.01769856, grad/param norm = 1.3436e+00, time/batch = 0.6536s	
182/23550 (epoch 0.386), train_loss = 3.03258908, grad/param norm = 9.4832e-01, time/batch = 0.6525s	
183/23550 (epoch 0.389), train_loss = 2.96480300, grad/param norm = 4.8732e-01, time/batch = 0.6519s	
184/23550 (epoch 0.391), train_loss = 3.08542749, grad/param norm = 5.0301e-01, time/batch = 0.6534s	
185/23550 (epoch 0.393), train_loss = 2.98079296, grad/param norm = 5.0143e-01, time/batch = 0.6521s	
186/23550 (epoch 0.395), train_loss = 3.08063552, grad/param norm = 5.5053e-01, time/batch = 0.6519s	
187/23550 (epoch 0.397), train_loss = 2.95126585, grad/param norm = 5.0642e-01, time/batch = 0.6514s	
188/23550 (epoch 0.399), train_loss = 2.99694686, grad/param norm = 4.1765e-01, time/batch = 0.6553s	
189/23550 (epoch 0.401), train_loss = 3.09186455, grad/param norm = 3.9870e-01, time/batch = 0.6585s	
190/23550 (epoch 0.403), train_loss = 3.10088335, grad/param norm = 6.6620e-01, time/batch = 0.6523s	
191/23550 (epoch 0.406), train_loss = 2.92119672, grad/param norm = 8.3112e-01, time/batch = 0.6597s	
192/23550 (epoch 0.408), train_loss = 2.99099070, grad/param norm = 5.5127e-01, time/batch = 0.6521s	
193/23550 (epoch 0.410), train_loss = 2.97943734, grad/param norm = 4.1715e-01, time/batch = 0.6526s	
194/23550 (epoch 0.412), train_loss = 3.05625054, grad/param norm = 6.2627e-01, time/batch = 0.6528s	
195/23550 (epoch 0.414), train_loss = 2.88621298, grad/param norm = 5.4942e-01, time/batch = 0.6549s	
196/23550 (epoch 0.416), train_loss = 3.03570604, grad/param norm = 3.7572e-01, time/batch = 0.6558s	
197/23550 (epoch 0.418), train_loss = 2.94029661, grad/param norm = 3.2679e-01, time/batch = 0.6527s	
198/23550 (epoch 0.420), train_loss = 2.97750561, grad/param norm = 3.5022e-01, time/batch = 0.6540s	
199/23550 (epoch 0.423), train_loss = 2.97146714, grad/param norm = 4.5457e-01, time/batch = 0.6536s	
200/23550 (epoch 0.425), train_loss = 3.05236781, grad/param norm = 7.8503e-01, time/batch = 0.6571s	
201/23550 (epoch 0.427), train_loss = 3.06830275, grad/param norm = 1.0543e+00, time/batch = 0.6612s	
202/23550 (epoch 0.429), train_loss = 3.09029211, grad/param norm = 8.8633e-01, time/batch = 0.6623s	
203/23550 (epoch 0.431), train_loss = 2.94789470, grad/param norm = 8.6434e-01, time/batch = 0.6544s	
204/23550 (epoch 0.433), train_loss = 3.06821276, grad/param norm = 8.5143e-01, time/batch = 0.6529s	
205/23550 (epoch 0.435), train_loss = 2.92482471, grad/param norm = 9.4074e-01, time/batch = 0.6510s	
206/23550 (epoch 0.437), train_loss = 3.04030315, grad/param norm = 8.9235e-01, time/batch = 0.6519s	
207/23550 (epoch 0.439), train_loss = 3.08409899, grad/param norm = 7.6432e-01, time/batch = 0.6522s	
208/23550 (epoch 0.442), train_loss = 2.85258064, grad/param norm = 7.1373e-01, time/batch = 0.6575s	
209/23550 (epoch 0.444), train_loss = 2.76805396, grad/param norm = 8.8750e-01, time/batch = 0.6582s	
210/23550 (epoch 0.446), train_loss = 2.79508210, grad/param norm = 1.0858e+00, time/batch = 0.6602s	
211/23550 (epoch 0.448), train_loss = 2.96677141, grad/param norm = 8.7411e-01, time/batch = 0.6555s	
212/23550 (epoch 0.450), train_loss = 3.01711074, grad/param norm = 5.5527e-01, time/batch = 0.6629s	
213/23550 (epoch 0.452), train_loss = 2.94972648, grad/param norm = 5.1409e-01, time/batch = 0.6606s	
214/23550 (epoch 0.454), train_loss = 2.87410105, grad/param norm = 7.2248e-01, time/batch = 0.6539s	
215/23550 (epoch 0.456), train_loss = 3.05622954, grad/param norm = 8.2375e-01, time/batch = 0.6569s	
216/23550 (epoch 0.459), train_loss = 2.98586823, grad/param norm = 6.4358e-01, time/batch = 0.6538s	
217/23550 (epoch 0.461), train_loss = 2.93881143, grad/param norm = 5.9216e-01, time/batch = 0.6513s	
218/23550 (epoch 0.463), train_loss = 2.98970335, grad/param norm = 5.0168e-01, time/batch = 0.6516s	
219/23550 (epoch 0.465), train_loss = 2.97197499, grad/param norm = 7.7137e-01, time/batch = 0.6513s	
220/23550 (epoch 0.467), train_loss = 2.90239369, grad/param norm = 8.4782e-01, time/batch = 0.6514s	
221/23550 (epoch 0.469), train_loss = 2.99158532, grad/param norm = 6.2252e-01, time/batch = 0.6532s	
222/23550 (epoch 0.471), train_loss = 2.74302735, grad/param norm = 3.5212e-01, time/batch = 0.6531s	
223/23550 (epoch 0.473), train_loss = 2.86872316, grad/param norm = 6.3031e-01, time/batch = 0.6518s	
224/23550 (epoch 0.476), train_loss = 2.85518993, grad/param norm = 5.9422e-01, time/batch = 0.6513s	
225/23550 (epoch 0.478), train_loss = 2.92005062, grad/param norm = 5.8526e-01, time/batch = 0.6532s	
226/23550 (epoch 0.480), train_loss = 2.87085990, grad/param norm = 5.7075e-01, time/batch = 0.6535s	
227/23550 (epoch 0.482), train_loss = 2.83224475, grad/param norm = 7.0107e-01, time/batch = 0.6502s	
228/23550 (epoch 0.484), train_loss = 2.92004843, grad/param norm = 9.1667e-01, time/batch = 0.6505s	
229/23550 (epoch 0.486), train_loss = 3.00138057, grad/param norm = 7.9186e-01, time/batch = 0.6512s	
230/23550 (epoch 0.488), train_loss = 3.05322550, grad/param norm = 6.9039e-01, time/batch = 0.6507s	
231/23550 (epoch 0.490), train_loss = 2.92126981, grad/param norm = 9.6445e-01, time/batch = 0.6523s	
232/23550 (epoch 0.493), train_loss = 3.07554659, grad/param norm = 1.0976e+00, time/batch = 0.6570s	
233/23550 (epoch 0.495), train_loss = 2.98353082, grad/param norm = 7.8585e-01, time/batch = 0.6568s	
234/23550 (epoch 0.497), train_loss = 2.91159252, grad/param norm = 7.2272e-01, time/batch = 0.6814s	
235/23550 (epoch 0.499), train_loss = 2.89670079, grad/param norm = 6.1413e-01, time/batch = 0.6505s	
236/23550 (epoch 0.501), train_loss = 2.93662936, grad/param norm = 7.7183e-01, time/batch = 0.6503s	
237/23550 (epoch 0.503), train_loss = 2.78444598, grad/param norm = 1.1412e+00, time/batch = 0.6505s	
238/23550 (epoch 0.505), train_loss = 2.85365105, grad/param norm = 9.5955e-01, time/batch = 0.6506s	
239/23550 (epoch 0.507), train_loss = 2.83728437, grad/param norm = 6.4017e-01, time/batch = 0.6514s	
240/23550 (epoch 0.510), train_loss = 3.07582390, grad/param norm = 6.2665e-01, time/batch = 0.6514s	
241/23550 (epoch 0.512), train_loss = 2.99517661, grad/param norm = 4.2476e-01, time/batch = 0.6532s	
242/23550 (epoch 0.514), train_loss = 2.76183102, grad/param norm = 3.7309e-01, time/batch = 0.6521s	
243/23550 (epoch 0.516), train_loss = 2.84751156, grad/param norm = 3.9206e-01, time/batch = 0.6513s	
244/23550 (epoch 0.518), train_loss = 2.85509832, grad/param norm = 4.2966e-01, time/batch = 0.6515s	
245/23550 (epoch 0.520), train_loss = 2.86415226, grad/param norm = 4.7950e-01, time/batch = 0.6575s	
246/23550 (epoch 0.522), train_loss = 2.87547205, grad/param norm = 6.5255e-01, time/batch = 0.6573s	
247/23550 (epoch 0.524), train_loss = 2.88825595, grad/param norm = 6.7113e-01, time/batch = 0.6658s	
248/23550 (epoch 0.527), train_loss = 2.88521006, grad/param norm = 4.9462e-01, time/batch = 0.6524s	
249/23550 (epoch 0.529), train_loss = 2.83643053, grad/param norm = 4.2570e-01, time/batch = 0.6718s	
250/23550 (epoch 0.531), train_loss = 2.73589316, grad/param norm = 5.7461e-01, time/batch = 0.6544s	
251/23550 (epoch 0.533), train_loss = 2.92661869, grad/param norm = 7.6817e-01, time/batch = 0.6570s	
252/23550 (epoch 0.535), train_loss = 2.78949280, grad/param norm = 5.2996e-01, time/batch = 0.6512s	
253/23550 (epoch 0.537), train_loss = 2.75239198, grad/param norm = 4.2324e-01, time/batch = 0.6510s	
254/23550 (epoch 0.539), train_loss = 2.85228825, grad/param norm = 8.1910e-01, time/batch = 0.6505s	
255/23550 (epoch 0.541), train_loss = 2.84674368, grad/param norm = 7.4620e-01, time/batch = 0.6504s	
256/23550 (epoch 0.544), train_loss = 2.99557812, grad/param norm = 5.8802e-01, time/batch = 0.6507s	
257/23550 (epoch 0.546), train_loss = 2.86155958, grad/param norm = 6.1360e-01, time/batch = 0.6504s	
258/23550 (epoch 0.548), train_loss = 2.85368305, grad/param norm = 4.7825e-01, time/batch = 0.6508s	
259/23550 (epoch 0.550), train_loss = 2.74491773, grad/param norm = 4.7480e-01, time/batch = 0.6507s	
260/23550 (epoch 0.552), train_loss = 2.90558945, grad/param norm = 7.8030e-01, time/batch = 0.6526s	
261/23550 (epoch 0.554), train_loss = 2.88562648, grad/param norm = 8.5581e-01, time/batch = 0.6524s	
262/23550 (epoch 0.556), train_loss = 2.66282517, grad/param norm = 4.2692e-01, time/batch = 0.6509s	
263/23550 (epoch 0.558), train_loss = 2.74313559, grad/param norm = 3.3787e-01, time/batch = 0.6506s	
264/23550 (epoch 0.561), train_loss = 2.85735748, grad/param norm = 5.3421e-01, time/batch = 0.6509s	
265/23550 (epoch 0.563), train_loss = 2.78888523, grad/param norm = 7.2776e-01, time/batch = 0.6526s	
266/23550 (epoch 0.565), train_loss = 2.79636242, grad/param norm = 7.5736e-01, time/batch = 0.6504s	
267/23550 (epoch 0.567), train_loss = 2.86829473, grad/param norm = 7.4356e-01, time/batch = 0.6507s	
268/23550 (epoch 0.569), train_loss = 2.99052288, grad/param norm = 9.7271e-01, time/batch = 0.6515s	
269/23550 (epoch 0.571), train_loss = 3.13677598, grad/param norm = 1.9577e+00, time/batch = 0.6511s	
270/23550 (epoch 0.573), train_loss = 2.94839354, grad/param norm = 7.3358e-01, time/batch = 0.6624s	
271/23550 (epoch 0.575), train_loss = 2.85579645, grad/param norm = 3.7363e-01, time/batch = 0.6521s	
272/23550 (epoch 0.577), train_loss = 2.83481521, grad/param norm = 4.6686e-01, time/batch = 0.6516s	
273/23550 (epoch 0.580), train_loss = 2.94386445, grad/param norm = 5.4199e-01, time/batch = 0.6509s	
274/23550 (epoch 0.582), train_loss = 2.85229117, grad/param norm = 4.9486e-01, time/batch = 0.6516s	
275/23550 (epoch 0.584), train_loss = 2.80312215, grad/param norm = 5.9563e-01, time/batch = 0.6530s	
276/23550 (epoch 0.586), train_loss = 2.77110018, grad/param norm = 7.4959e-01, time/batch = 0.6523s	
277/23550 (epoch 0.588), train_loss = 2.80785925, grad/param norm = 8.5538e-01, time/batch = 0.6517s	
278/23550 (epoch 0.590), train_loss = 2.81155629, grad/param norm = 6.9932e-01, time/batch = 0.6512s	
279/23550 (epoch 0.592), train_loss = 2.80564610, grad/param norm = 4.8393e-01, time/batch = 0.6513s	
280/23550 (epoch 0.594), train_loss = 2.85920582, grad/param norm = 5.0691e-01, time/batch = 0.6508s	
281/23550 (epoch 0.597), train_loss = 2.73233309, grad/param norm = 4.4446e-01, time/batch = 0.6518s	
282/23550 (epoch 0.599), train_loss = 2.82099444, grad/param norm = 4.5096e-01, time/batch = 0.6510s	
283/23550 (epoch 0.601), train_loss = 2.86223084, grad/param norm = 5.2938e-01, time/batch = 0.6506s	
284/23550 (epoch 0.603), train_loss = 2.74422545, grad/param norm = 8.3065e-01, time/batch = 0.6504s	
285/23550 (epoch 0.605), train_loss = 2.92252818, grad/param norm = 9.7533e-01, time/batch = 0.6515s	
286/23550 (epoch 0.607), train_loss = 2.84455644, grad/param norm = 7.8999e-01, time/batch = 0.6532s	
287/23550 (epoch 0.609), train_loss = 2.74531399, grad/param norm = 5.3316e-01, time/batch = 0.6505s	
288/23550 (epoch 0.611), train_loss = 2.79524746, grad/param norm = 5.4404e-01, time/batch = 0.6508s	
289/23550 (epoch 0.614), train_loss = 2.75293703, grad/param norm = 6.0649e-01, time/batch = 0.6503s	
290/23550 (epoch 0.616), train_loss = 2.77879820, grad/param norm = 4.3905e-01, time/batch = 0.6503s	
291/23550 (epoch 0.618), train_loss = 2.79225639, grad/param norm = 4.3587e-01, time/batch = 0.6517s	
292/23550 (epoch 0.620), train_loss = 2.83759613, grad/param norm = 5.6827e-01, time/batch = 0.6508s	
293/23550 (epoch 0.622), train_loss = 2.79409317, grad/param norm = 5.5002e-01, time/batch = 0.6507s	
294/23550 (epoch 0.624), train_loss = 2.68424943, grad/param norm = 4.7533e-01, time/batch = 0.6512s	
295/23550 (epoch 0.626), train_loss = 2.72407289, grad/param norm = 5.4915e-01, time/batch = 0.6504s	
296/23550 (epoch 0.628), train_loss = 2.76997468, grad/param norm = 5.6278e-01, time/batch = 0.6508s	
297/23550 (epoch 0.631), train_loss = 2.65421633, grad/param norm = 3.7835e-01, time/batch = 0.6503s	
298/23550 (epoch 0.633), train_loss = 2.82976426, grad/param norm = 4.2877e-01, time/batch = 0.6506s	
299/23550 (epoch 0.635), train_loss = 2.73772558, grad/param norm = 7.1005e-01, time/batch = 0.6512s	
300/23550 (epoch 0.637), train_loss = 2.87233172, grad/param norm = 9.6396e-01, time/batch = 0.6521s	
301/23550 (epoch 0.639), train_loss = 2.85342635, grad/param norm = 6.7469e-01, time/batch = 0.6519s	
302/23550 (epoch 0.641), train_loss = 2.83293926, grad/param norm = 5.2774e-01, time/batch = 0.6515s	
303/23550 (epoch 0.643), train_loss = 2.82799038, grad/param norm = 5.0462e-01, time/batch = 0.6516s	
304/23550 (epoch 0.645), train_loss = 2.77968874, grad/param norm = 5.7110e-01, time/batch = 0.6510s	
305/23550 (epoch 0.648), train_loss = 2.78473654, grad/param norm = 6.0647e-01, time/batch = 0.6509s	
306/23550 (epoch 0.650), train_loss = 2.72909897, grad/param norm = 5.9601e-01, time/batch = 0.6505s	
307/23550 (epoch 0.652), train_loss = 2.83883641, grad/param norm = 5.3367e-01, time/batch = 0.6517s	
308/23550 (epoch 0.654), train_loss = 2.75911288, grad/param norm = 4.2532e-01, time/batch = 0.6524s	
309/23550 (epoch 0.656), train_loss = 2.59666632, grad/param norm = 4.5904e-01, time/batch = 0.6501s	
310/23550 (epoch 0.658), train_loss = 2.95900120, grad/param norm = 9.9059e-01, time/batch = 0.6503s	
311/23550 (epoch 0.660), train_loss = 2.79121058, grad/param norm = 1.2167e+00, time/batch = 0.6519s	
312/23550 (epoch 0.662), train_loss = 2.83840594, grad/param norm = 5.4264e-01, time/batch = 0.6509s	
313/23550 (epoch 0.665), train_loss = 2.90068442, grad/param norm = 6.7107e-01, time/batch = 0.6510s	
314/23550 (epoch 0.667), train_loss = 2.81372685, grad/param norm = 6.6409e-01, time/batch = 0.6507s	
315/23550 (epoch 0.669), train_loss = 2.84398771, grad/param norm = 5.7511e-01, time/batch = 0.6518s	
316/23550 (epoch 0.671), train_loss = 2.68294305, grad/param norm = 5.6892e-01, time/batch = 0.6527s	
317/23550 (epoch 0.673), train_loss = 2.74063901, grad/param norm = 5.2986e-01, time/batch = 0.6584s	
318/23550 (epoch 0.675), train_loss = 2.76429628, grad/param norm = 4.8602e-01, time/batch = 0.6527s	
319/23550 (epoch 0.677), train_loss = 2.71514521, grad/param norm = 4.8283e-01, time/batch = 0.6501s	
320/23550 (epoch 0.679), train_loss = 2.70177055, grad/param norm = 6.5247e-01, time/batch = 0.6509s	
321/23550 (epoch 0.682), train_loss = 2.74279375, grad/param norm = 7.6801e-01, time/batch = 0.6521s	
322/23550 (epoch 0.684), train_loss = 2.72451618, grad/param norm = 5.6476e-01, time/batch = 0.6510s	
323/23550 (epoch 0.686), train_loss = 2.79027563, grad/param norm = 6.8952e-01, time/batch = 0.6511s	
324/23550 (epoch 0.688), train_loss = 2.89909180, grad/param norm = 8.0729e-01, time/batch = 0.6507s	
325/23550 (epoch 0.690), train_loss = 2.59589012, grad/param norm = 5.3887e-01, time/batch = 0.6502s	
326/23550 (epoch 0.692), train_loss = 2.67640691, grad/param norm = 4.4547e-01, time/batch = 0.6506s	
327/23550 (epoch 0.694), train_loss = 2.76989925, grad/param norm = 3.1560e-01, time/batch = 0.6504s	
328/23550 (epoch 0.696), train_loss = 2.69839422, grad/param norm = 3.5218e-01, time/batch = 0.6502s	
329/23550 (epoch 0.699), train_loss = 2.66502489, grad/param norm = 5.1271e-01, time/batch = 0.6502s	
330/23550 (epoch 0.701), train_loss = 2.70626771, grad/param norm = 5.0716e-01, time/batch = 0.6502s	
331/23550 (epoch 0.703), train_loss = 2.74705532, grad/param norm = 3.1948e-01, time/batch = 0.6520s	
332/23550 (epoch 0.705), train_loss = 2.78545429, grad/param norm = 2.9185e-01, time/batch = 0.6508s	
333/23550 (epoch 0.707), train_loss = 2.80702510, grad/param norm = 5.2513e-01, time/batch = 0.6506s	
334/23550 (epoch 0.709), train_loss = 2.66320131, grad/param norm = 5.9811e-01, time/batch = 0.6529s	
335/23550 (epoch 0.711), train_loss = 2.74732778, grad/param norm = 5.7316e-01, time/batch = 0.6502s	
336/23550 (epoch 0.713), train_loss = 2.61147482, grad/param norm = 5.2969e-01, time/batch = 0.6504s	
337/23550 (epoch 0.715), train_loss = 2.65695290, grad/param norm = 4.2775e-01, time/batch = 0.6503s	
338/23550 (epoch 0.718), train_loss = 2.71011580, grad/param norm = 5.3782e-01, time/batch = 0.6502s	
339/23550 (epoch 0.720), train_loss = 2.73341292, grad/param norm = 7.9419e-01, time/batch = 0.6503s	
340/23550 (epoch 0.722), train_loss = 2.75953326, grad/param norm = 7.5180e-01, time/batch = 0.6504s	
341/23550 (epoch 0.724), train_loss = 2.72089037, grad/param norm = 5.9587e-01, time/batch = 0.6515s	
342/23550 (epoch 0.726), train_loss = 2.61909518, grad/param norm = 3.2512e-01, time/batch = 0.6511s	
343/23550 (epoch 0.728), train_loss = 2.72430201, grad/param norm = 5.3653e-01, time/batch = 0.6504s	
344/23550 (epoch 0.730), train_loss = 2.74714252, grad/param norm = 7.6243e-01, time/batch = 0.6503s	
345/23550 (epoch 0.732), train_loss = 2.68145144, grad/param norm = 7.0915e-01, time/batch = 0.6505s	
346/23550 (epoch 0.735), train_loss = 2.63438607, grad/param norm = 5.3704e-01, time/batch = 0.6513s	
347/23550 (epoch 0.737), train_loss = 2.51526470, grad/param norm = 4.0962e-01, time/batch = 0.6503s	
348/23550 (epoch 0.739), train_loss = 2.79143108, grad/param norm = 5.7675e-01, time/batch = 0.6530s	
349/23550 (epoch 0.741), train_loss = 2.66960825, grad/param norm = 8.2933e-01, time/batch = 0.6522s	
350/23550 (epoch 0.743), train_loss = 2.85681882, grad/param norm = 6.8908e-01, time/batch = 0.6511s	
351/23550 (epoch 0.745), train_loss = 2.82283564, grad/param norm = 4.3236e-01, time/batch = 0.6528s	
352/23550 (epoch 0.747), train_loss = 2.80682857, grad/param norm = 4.6390e-01, time/batch = 0.6512s	
353/23550 (epoch 0.749), train_loss = 2.66919687, grad/param norm = 5.6240e-01, time/batch = 0.6596s	
354/23550 (epoch 0.752), train_loss = 2.88959322, grad/param norm = 6.3534e-01, time/batch = 0.6506s	
355/23550 (epoch 0.754), train_loss = 2.60918967, grad/param norm = 6.4011e-01, time/batch = 0.6504s	
356/23550 (epoch 0.756), train_loss = 2.82118218, grad/param norm = 4.6668e-01, time/batch = 0.6505s	
357/23550 (epoch 0.758), train_loss = 2.67682107, grad/param norm = 3.3166e-01, time/batch = 0.6509s	
358/23550 (epoch 0.760), train_loss = 2.49626819, grad/param norm = 3.1099e-01, time/batch = 0.6503s	
359/23550 (epoch 0.762), train_loss = 2.55100697, grad/param norm = 4.3137e-01, time/batch = 0.6502s	
360/23550 (epoch 0.764), train_loss = 2.59587665, grad/param norm = 4.7562e-01, time/batch = 0.6505s	
361/23550 (epoch 0.766), train_loss = 2.62317124, grad/param norm = 4.8488e-01, time/batch = 0.6515s	
362/23550 (epoch 0.769), train_loss = 2.74857321, grad/param norm = 4.3770e-01, time/batch = 0.6510s	
363/23550 (epoch 0.771), train_loss = 2.67866994, grad/param norm = 3.9588e-01, time/batch = 0.6527s	
364/23550 (epoch 0.773), train_loss = 2.53092463, grad/param norm = 5.1184e-01, time/batch = 0.6505s	
365/23550 (epoch 0.775), train_loss = 2.62143070, grad/param norm = 6.6475e-01, time/batch = 0.6504s	
366/23550 (epoch 0.777), train_loss = 2.72606644, grad/param norm = 6.2761e-01, time/batch = 0.6500s	
367/23550 (epoch 0.779), train_loss = 2.70013496, grad/param norm = 5.5456e-01, time/batch = 0.6501s	
368/23550 (epoch 0.781), train_loss = 2.83197704, grad/param norm = 5.4058e-01, time/batch = 0.6509s	
369/23550 (epoch 0.783), train_loss = 2.57325783, grad/param norm = 5.9824e-01, time/batch = 0.6503s	
370/23550 (epoch 0.786), train_loss = 2.62900874, grad/param norm = 7.5565e-01, time/batch = 0.6503s	
371/23550 (epoch 0.788), train_loss = 2.65627202, grad/param norm = 5.9447e-01, time/batch = 0.6521s	
372/23550 (epoch 0.790), train_loss = 2.67642396, grad/param norm = 4.6692e-01, time/batch = 0.6510s	
373/23550 (epoch 0.792), train_loss = 2.66758022, grad/param norm = 3.2241e-01, time/batch = 0.6506s	
374/23550 (epoch 0.794), train_loss = 2.72877542, grad/param norm = 3.4079e-01, time/batch = 0.6509s	
375/23550 (epoch 0.796), train_loss = 2.57325693, grad/param norm = 3.1336e-01, time/batch = 0.6503s	
376/23550 (epoch 0.798), train_loss = 2.59339404, grad/param norm = 4.0601e-01, time/batch = 0.6505s	
377/23550 (epoch 0.800), train_loss = 2.69896912, grad/param norm = 3.8761e-01, time/batch = 0.6504s	
378/23550 (epoch 0.803), train_loss = 2.60405840, grad/param norm = 4.1006e-01, time/batch = 0.6549s	
379/23550 (epoch 0.805), train_loss = 2.71096204, grad/param norm = 3.5760e-01, time/batch = 0.6518s	
380/23550 (epoch 0.807), train_loss = 2.76976186, grad/param norm = 5.1290e-01, time/batch = 0.6580s	
381/23550 (epoch 0.809), train_loss = 2.69982755, grad/param norm = 6.4503e-01, time/batch = 0.6662s	
382/23550 (epoch 0.811), train_loss = 2.69719547, grad/param norm = 7.0193e-01, time/batch = 0.6613s	
383/23550 (epoch 0.813), train_loss = 2.64039302, grad/param norm = 5.9781e-01, time/batch = 0.6539s	
384/23550 (epoch 0.815), train_loss = 2.65929182, grad/param norm = 5.7810e-01, time/batch = 0.6553s	
385/23550 (epoch 0.817), train_loss = 2.60203405, grad/param norm = 6.5382e-01, time/batch = 0.6516s	
386/23550 (epoch 0.820), train_loss = 2.67745851, grad/param norm = 6.2896e-01, time/batch = 0.6527s	
387/23550 (epoch 0.822), train_loss = 2.60482202, grad/param norm = 5.5272e-01, time/batch = 0.6512s	
388/23550 (epoch 0.824), train_loss = 2.60898203, grad/param norm = 5.3607e-01, time/batch = 0.6520s	
389/23550 (epoch 0.826), train_loss = 2.57657284, grad/param norm = 4.4158e-01, time/batch = 0.6517s	
390/23550 (epoch 0.828), train_loss = 2.62045966, grad/param norm = 5.3990e-01, time/batch = 0.6518s	
391/23550 (epoch 0.830), train_loss = 2.65715982, grad/param norm = 5.2892e-01, time/batch = 0.6579s	
392/23550 (epoch 0.832), train_loss = 2.49515189, grad/param norm = 2.9044e-01, time/batch = 0.6555s	
393/23550 (epoch 0.834), train_loss = 2.54742577, grad/param norm = 3.1380e-01, time/batch = 0.6516s	
394/23550 (epoch 0.837), train_loss = 2.71582965, grad/param norm = 3.5554e-01, time/batch = 0.6544s	
395/23550 (epoch 0.839), train_loss = 2.68407479, grad/param norm = 3.9422e-01, time/batch = 0.6553s	
396/23550 (epoch 0.841), train_loss = 2.50864496, grad/param norm = 4.8381e-01, time/batch = 0.6571s	
397/23550 (epoch 0.843), train_loss = 2.49677885, grad/param norm = 5.4237e-01, time/batch = 0.6531s	
398/23550 (epoch 0.845), train_loss = 2.68630257, grad/param norm = 4.8620e-01, time/batch = 0.6525s	
399/23550 (epoch 0.847), train_loss = 2.66754230, grad/param norm = 4.3953e-01, time/batch = 0.6504s	
400/23550 (epoch 0.849), train_loss = 2.64404989, grad/param norm = 4.2046e-01, time/batch = 0.6520s	
401/23550 (epoch 0.851), train_loss = 2.63279432, grad/param norm = 4.0085e-01, time/batch = 0.6586s	
402/23550 (epoch 0.854), train_loss = 2.61575613, grad/param norm = 6.5621e-01, time/batch = 0.6848s	
403/23550 (epoch 0.856), train_loss = 2.55751334, grad/param norm = 6.6655e-01, time/batch = 0.6522s	
404/23550 (epoch 0.858), train_loss = 2.50709768, grad/param norm = 5.5028e-01, time/batch = 0.6650s	
405/23550 (epoch 0.860), train_loss = 2.56610658, grad/param norm = 4.7561e-01, time/batch = 0.6566s	
406/23550 (epoch 0.862), train_loss = 2.45353818, grad/param norm = 3.2680e-01, time/batch = 0.6528s	
407/23550 (epoch 0.864), train_loss = 2.63281582, grad/param norm = 3.7525e-01, time/batch = 0.6516s	
408/23550 (epoch 0.866), train_loss = 2.66121637, grad/param norm = 4.4049e-01, time/batch = 0.6566s	
409/23550 (epoch 0.868), train_loss = 2.55555847, grad/param norm = 5.1031e-01, time/batch = 0.6570s	
410/23550 (epoch 0.870), train_loss = 2.54127960, grad/param norm = 3.7829e-01, time/batch = 0.6571s	
411/23550 (epoch 0.873), train_loss = 2.59795583, grad/param norm = 3.4943e-01, time/batch = 0.6566s	
412/23550 (epoch 0.875), train_loss = 2.61273722, grad/param norm = 3.0883e-01, time/batch = 0.6518s	
413/23550 (epoch 0.877), train_loss = 2.50636168, grad/param norm = 4.0200e-01, time/batch = 0.6532s	
414/23550 (epoch 0.879), train_loss = 2.55277291, grad/param norm = 4.7966e-01, time/batch = 0.6510s	
415/23550 (epoch 0.881), train_loss = 2.60777132, grad/param norm = 5.6114e-01, time/batch = 0.6509s	
416/23550 (epoch 0.883), train_loss = 2.48716344, grad/param norm = 5.9885e-01, time/batch = 0.6504s	
417/23550 (epoch 0.885), train_loss = 2.52596944, grad/param norm = 5.6184e-01, time/batch = 0.6504s	
418/23550 (epoch 0.887), train_loss = 2.46509652, grad/param norm = 5.9888e-01, time/batch = 0.6542s	
419/23550 (epoch 0.890), train_loss = 2.54561291, grad/param norm = 5.0222e-01, time/batch = 0.6507s	
420/23550 (epoch 0.892), train_loss = 2.67375103, grad/param norm = 4.8947e-01, time/batch = 0.6509s	
421/23550 (epoch 0.894), train_loss = 2.57552775, grad/param norm = 6.0846e-01, time/batch = 0.6521s	
422/23550 (epoch 0.896), train_loss = 2.64243664, grad/param norm = 4.7573e-01, time/batch = 0.6509s	
423/23550 (epoch 0.898), train_loss = 2.61162659, grad/param norm = 4.0085e-01, time/batch = 0.6525s	
424/23550 (epoch 0.900), train_loss = 2.51567814, grad/param norm = 3.8960e-01, time/batch = 0.6506s	
425/23550 (epoch 0.902), train_loss = 2.72121179, grad/param norm = 3.9066e-01, time/batch = 0.6504s	
426/23550 (epoch 0.904), train_loss = 2.55688195, grad/param norm = 4.3916e-01, time/batch = 0.6503s	
427/23550 (epoch 0.907), train_loss = 2.44073659, grad/param norm = 4.9222e-01, time/batch = 0.6506s	
428/23550 (epoch 0.909), train_loss = 2.52241552, grad/param norm = 6.1521e-01, time/batch = 0.6504s	
429/23550 (epoch 0.911), train_loss = 2.32561136, grad/param norm = 4.4299e-01, time/batch = 0.6525s	
430/23550 (epoch 0.913), train_loss = 2.56907414, grad/param norm = 4.2574e-01, time/batch = 0.6516s	
431/23550 (epoch 0.915), train_loss = 2.44872896, grad/param norm = 3.6885e-01, time/batch = 0.6540s	
432/23550 (epoch 0.917), train_loss = 2.45325558, grad/param norm = 4.0985e-01, time/batch = 0.6572s	
433/23550 (epoch 0.919), train_loss = 2.46307119, grad/param norm = 5.0037e-01, time/batch = 0.6893s	
434/23550 (epoch 0.921), train_loss = 2.62945436, grad/param norm = 6.5251e-01, time/batch = 0.6508s	
435/23550 (epoch 0.924), train_loss = 2.67105937, grad/param norm = 6.9033e-01, time/batch = 0.6516s	
436/23550 (epoch 0.926), train_loss = 2.54588999, grad/param norm = 4.4289e-01, time/batch = 0.6506s	
437/23550 (epoch 0.928), train_loss = 2.48233699, grad/param norm = 2.8421e-01, time/batch = 0.6514s	
438/23550 (epoch 0.930), train_loss = 2.57014740, grad/param norm = 3.2331e-01, time/batch = 0.6532s	
439/23550 (epoch 0.932), train_loss = 2.65223009, grad/param norm = 4.5229e-01, time/batch = 0.6506s	
440/23550 (epoch 0.934), train_loss = 2.45603933, grad/param norm = 4.9154e-01, time/batch = 0.6512s	
441/23550 (epoch 0.936), train_loss = 2.71503081, grad/param norm = 3.5392e-01, time/batch = 0.6533s	
442/23550 (epoch 0.938), train_loss = 2.46990453, grad/param norm = 4.7767e-01, time/batch = 0.6526s	
443/23550 (epoch 0.941), train_loss = 2.67647793, grad/param norm = 6.4998e-01, time/batch = 0.6516s	
444/23550 (epoch 0.943), train_loss = 2.62744809, grad/param norm = 5.4481e-01, time/batch = 0.6502s	
445/23550 (epoch 0.945), train_loss = 2.53441108, grad/param norm = 3.8425e-01, time/batch = 0.6504s	
446/23550 (epoch 0.947), train_loss = 2.50622433, grad/param norm = 3.9690e-01, time/batch = 0.6513s	
447/23550 (epoch 0.949), train_loss = 2.48871951, grad/param norm = 3.7196e-01, time/batch = 0.6553s	
448/23550 (epoch 0.951), train_loss = 2.57713326, grad/param norm = 4.8694e-01, time/batch = 0.6588s	
449/23550 (epoch 0.953), train_loss = 2.52839630, grad/param norm = 5.6675e-01, time/batch = 0.6648s	
450/23550 (epoch 0.955), train_loss = 2.62902486, grad/param norm = 4.4295e-01, time/batch = 0.6580s	
451/23550 (epoch 0.958), train_loss = 2.51561820, grad/param norm = 3.5278e-01, time/batch = 0.6557s	
452/23550 (epoch 0.960), train_loss = 2.49579126, grad/param norm = 4.0702e-01, time/batch = 0.6523s	
453/23550 (epoch 0.962), train_loss = 2.66905625, grad/param norm = 5.0609e-01, time/batch = 0.6558s	
454/23550 (epoch 0.964), train_loss = 2.48957948, grad/param norm = 5.2510e-01, time/batch = 0.6555s	
455/23550 (epoch 0.966), train_loss = 2.63600138, grad/param norm = 4.3617e-01, time/batch = 0.6536s	
456/23550 (epoch 0.968), train_loss = 2.50606086, grad/param norm = 3.5012e-01, time/batch = 0.6522s	
457/23550 (epoch 0.970), train_loss = 2.31012622, grad/param norm = 3.5820e-01, time/batch = 0.6555s	
458/23550 (epoch 0.972), train_loss = 2.39908988, grad/param norm = 4.6528e-01, time/batch = 0.6558s	
459/23550 (epoch 0.975), train_loss = 2.76079640, grad/param norm = 4.0926e-01, time/batch = 0.6534s	
460/23550 (epoch 0.977), train_loss = 2.39554432, grad/param norm = 4.0350e-01, time/batch = 0.6509s	
461/23550 (epoch 0.979), train_loss = 2.37410129, grad/param norm = 3.7427e-01, time/batch = 0.6544s	
462/23550 (epoch 0.981), train_loss = 2.57522950, grad/param norm = 4.0608e-01, time/batch = 0.6565s	
463/23550 (epoch 0.983), train_loss = 2.72366875, grad/param norm = 5.2734e-01, time/batch = 0.6518s	
464/23550 (epoch 0.985), train_loss = 2.64953334, grad/param norm = 5.1126e-01, time/batch = 0.6506s	
465/23550 (epoch 0.987), train_loss = 2.64706305, grad/param norm = 4.3699e-01, time/batch = 0.6508s	
466/23550 (epoch 0.989), train_loss = 2.52714100, grad/param norm = 4.1728e-01, time/batch = 0.6504s	
467/23550 (epoch 0.992), train_loss = 2.52126160, grad/param norm = 4.1834e-01, time/batch = 0.6502s	
468/23550 (epoch 0.994), train_loss = 2.72279788, grad/param norm = 4.9332e-01, time/batch = 0.6503s	
469/23550 (epoch 0.996), train_loss = 2.63951200, grad/param norm = 6.4706e-01, time/batch = 0.6505s	
470/23550 (epoch 0.998), train_loss = 2.60865286, grad/param norm = 4.9159e-01, time/batch = 0.6501s	
471/23550 (epoch 1.000), train_loss = 2.51584234, grad/param norm = 5.5105e-01, time/batch = 0.6524s	
472/23550 (epoch 1.002), train_loss = 2.50222220, grad/param norm = 6.0816e-01, time/batch = 0.6509s	
473/23550 (epoch 1.004), train_loss = 2.63244848, grad/param norm = 6.0976e-01, time/batch = 0.6520s	
474/23550 (epoch 1.006), train_loss = 2.58427688, grad/param norm = 4.2262e-01, time/batch = 0.6512s	
475/23550 (epoch 1.008), train_loss = 2.56434541, grad/param norm = 4.1779e-01, time/batch = 0.6520s	
476/23550 (epoch 1.011), train_loss = 2.41996677, grad/param norm = 4.1299e-01, time/batch = 0.6504s	
477/23550 (epoch 1.013), train_loss = 2.43001172, grad/param norm = 3.7195e-01, time/batch = 0.6510s	
478/23550 (epoch 1.015), train_loss = 2.43648690, grad/param norm = 2.8759e-01, time/batch = 0.6506s	
479/23550 (epoch 1.017), train_loss = 2.41413930, grad/param norm = 4.1171e-01, time/batch = 0.6513s	
480/23550 (epoch 1.019), train_loss = 2.58058289, grad/param norm = 5.1315e-01, time/batch = 0.6576s	
481/23550 (epoch 1.021), train_loss = 2.38479181, grad/param norm = 4.5690e-01, time/batch = 0.6527s	
482/23550 (epoch 1.023), train_loss = 2.53082632, grad/param norm = 3.9627e-01, time/batch = 0.6570s	
483/23550 (epoch 1.025), train_loss = 2.47634465, grad/param norm = 2.9363e-01, time/batch = 0.6696s	
484/23550 (epoch 1.028), train_loss = 2.54419234, grad/param norm = 3.5894e-01, time/batch = 0.6557s	
485/23550 (epoch 1.030), train_loss = 2.66238028, grad/param norm = 3.9310e-01, time/batch = 0.6522s	
486/23550 (epoch 1.032), train_loss = 2.55529524, grad/param norm = 3.9113e-01, time/batch = 0.6534s	
487/23550 (epoch 1.034), train_loss = 2.68377140, grad/param norm = 3.7920e-01, time/batch = 0.6508s	
488/23550 (epoch 1.036), train_loss = 2.34644463, grad/param norm = 3.5131e-01, time/batch = 0.6592s	
489/23550 (epoch 1.038), train_loss = 2.64810815, grad/param norm = 3.9706e-01, time/batch = 0.6690s	
490/23550 (epoch 1.040), train_loss = 2.58694445, grad/param norm = 7.1489e-01, time/batch = 0.6586s	
