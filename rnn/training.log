tput: No value for $TERM and no -T specified
vocab.t7 or data.t7 detected as stale. Re-running preprocessing...	
one-time setup: preprocessing input text file /home/ubuntu/scimirrorbot/dat/training/input.txt...	
loading text file...	
creating vocabulary mapping...	
putting data into tensor...	
saving /home/ubuntu/scimirrorbot/dat/training/vocab.t7	
saving /home/ubuntu/scimirrorbot/dat/training/data.t7	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 665, val: 36, test: 0	
vocab size: 132	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 283268	
cloning rnn	
cloning criterion	
1/33250 (epoch 0.002), train_loss = 4.89483620, grad/param norm = 5.3641e-01, time/batch = 0.6962s	
2/33250 (epoch 0.003), train_loss = 4.59052017, grad/param norm = 1.5968e+00, time/batch = 0.6719s	
3/33250 (epoch 0.005), train_loss = 3.84499791, grad/param norm = 1.1701e+00, time/batch = 0.6736s	
4/33250 (epoch 0.006), train_loss = 3.51077292, grad/param norm = 1.2496e+00, time/batch = 0.6671s	
5/33250 (epoch 0.008), train_loss = 3.54854064, grad/param norm = 1.0692e+00, time/batch = 0.6493s	
6/33250 (epoch 0.009), train_loss = 3.38876855, grad/param norm = 8.8482e-01, time/batch = 0.6550s	
7/33250 (epoch 0.011), train_loss = 3.65641815, grad/param norm = 9.2266e-01, time/batch = 0.6696s	
8/33250 (epoch 0.012), train_loss = 3.58782502, grad/param norm = 6.7413e-01, time/batch = 0.6652s	
9/33250 (epoch 0.014), train_loss = 3.36745592, grad/param norm = 7.4184e-01, time/batch = 0.6498s	
10/33250 (epoch 0.015), train_loss = 3.66540183, grad/param norm = 1.0810e+00, time/batch = 0.6600s	
11/33250 (epoch 0.017), train_loss = 3.49511685, grad/param norm = 6.5139e-01, time/batch = 0.6903s	
12/33250 (epoch 0.018), train_loss = 3.50909854, grad/param norm = 5.6695e-01, time/batch = 0.6823s	
13/33250 (epoch 0.020), train_loss = 3.51800528, grad/param norm = 6.0117e-01, time/batch = 0.6768s	
14/33250 (epoch 0.021), train_loss = 3.46203333, grad/param norm = 6.3743e-01, time/batch = 0.6719s	
15/33250 (epoch 0.023), train_loss = 3.60807065, grad/param norm = 7.6253e-01, time/batch = 0.6737s	
16/33250 (epoch 0.024), train_loss = 3.52925159, grad/param norm = 8.0601e-01, time/batch = 0.6738s	
17/33250 (epoch 0.026), train_loss = 3.48590202, grad/param norm = 5.8272e-01, time/batch = 0.6725s	
18/33250 (epoch 0.027), train_loss = 3.54098210, grad/param norm = 5.9725e-01, time/batch = 0.6740s	
19/33250 (epoch 0.029), train_loss = 3.63104496, grad/param norm = 7.3299e-01, time/batch = 0.6744s	
20/33250 (epoch 0.030), train_loss = 3.51094195, grad/param norm = 5.9537e-01, time/batch = 0.6584s	
21/33250 (epoch 0.032), train_loss = 3.46335553, grad/param norm = 6.9499e-01, time/batch = 0.6628s	
22/33250 (epoch 0.033), train_loss = 3.49928387, grad/param norm = 6.5306e-01, time/batch = 0.6635s	
23/33250 (epoch 0.035), train_loss = 3.42214606, grad/param norm = 5.7728e-01, time/batch = 0.6555s	
24/33250 (epoch 0.036), train_loss = 3.38331694, grad/param norm = 5.9687e-01, time/batch = 0.6703s	
25/33250 (epoch 0.038), train_loss = 3.69276490, grad/param norm = 8.3199e-01, time/batch = 0.6727s	
26/33250 (epoch 0.039), train_loss = 3.44162855, grad/param norm = 7.1863e-01, time/batch = 0.6717s	
27/33250 (epoch 0.041), train_loss = 3.42561396, grad/param norm = 5.4169e-01, time/batch = 0.6720s	
28/33250 (epoch 0.042), train_loss = 3.43896833, grad/param norm = 7.1366e-01, time/batch = 0.6651s	
29/33250 (epoch 0.044), train_loss = 3.40277511, grad/param norm = 5.6600e-01, time/batch = 0.6585s	
30/33250 (epoch 0.045), train_loss = 3.38081501, grad/param norm = 5.9652e-01, time/batch = 0.6474s	
31/33250 (epoch 0.047), train_loss = 3.51986590, grad/param norm = 6.0388e-01, time/batch = 0.6522s	
32/33250 (epoch 0.048), train_loss = 3.38812310, grad/param norm = 7.9551e-01, time/batch = 0.6489s	
33/33250 (epoch 0.050), train_loss = 3.46625681, grad/param norm = 7.3466e-01, time/batch = 0.6478s	
34/33250 (epoch 0.051), train_loss = 3.44293137, grad/param norm = 4.8771e-01, time/batch = 0.6649s	
35/33250 (epoch 0.053), train_loss = 3.40086120, grad/param norm = 7.0653e-01, time/batch = 0.6717s	
36/33250 (epoch 0.054), train_loss = 3.50390797, grad/param norm = 7.6337e-01, time/batch = 0.6846s	
37/33250 (epoch 0.056), train_loss = 3.42007930, grad/param norm = 5.8398e-01, time/batch = 0.6842s	
38/33250 (epoch 0.057), train_loss = 3.51216716, grad/param norm = 4.9947e-01, time/batch = 0.6722s	
39/33250 (epoch 0.059), train_loss = 3.48861119, grad/param norm = 6.7581e-01, time/batch = 0.6731s	
40/33250 (epoch 0.060), train_loss = 3.51795348, grad/param norm = 5.5499e-01, time/batch = 0.6726s	
41/33250 (epoch 0.062), train_loss = 3.57139494, grad/param norm = 7.8641e-01, time/batch = 0.6746s	
42/33250 (epoch 0.063), train_loss = 3.51980289, grad/param norm = 5.4408e-01, time/batch = 0.6719s	
43/33250 (epoch 0.065), train_loss = 3.53849769, grad/param norm = 5.2409e-01, time/batch = 0.6694s	
44/33250 (epoch 0.066), train_loss = 3.38889170, grad/param norm = 5.2513e-01, time/batch = 0.6624s	
45/33250 (epoch 0.068), train_loss = 3.45014933, grad/param norm = 5.6349e-01, time/batch = 0.6510s	
46/33250 (epoch 0.069), train_loss = 3.49095304, grad/param norm = 5.7622e-01, time/batch = 0.6484s	
47/33250 (epoch 0.071), train_loss = 3.45424149, grad/param norm = 5.3546e-01, time/batch = 0.6435s	
48/33250 (epoch 0.072), train_loss = 3.48853701, grad/param norm = 4.7486e-01, time/batch = 0.6515s	
49/33250 (epoch 0.074), train_loss = 3.36942438, grad/param norm = 5.4374e-01, time/batch = 0.6497s	
50/33250 (epoch 0.075), train_loss = 3.39871560, grad/param norm = 6.0043e-01, time/batch = 0.6499s	
51/33250 (epoch 0.077), train_loss = 3.60697552, grad/param norm = 6.7261e-01, time/batch = 0.6517s	
52/33250 (epoch 0.078), train_loss = 3.41951876, grad/param norm = 4.8508e-01, time/batch = 0.6468s	
53/33250 (epoch 0.080), train_loss = 3.51569824, grad/param norm = 7.1628e-01, time/batch = 0.6452s	
54/33250 (epoch 0.081), train_loss = 3.50717402, grad/param norm = 7.1110e-01, time/batch = 0.6604s	
55/33250 (epoch 0.083), train_loss = 3.58353188, grad/param norm = 6.1291e-01, time/batch = 0.6487s	
56/33250 (epoch 0.084), train_loss = 3.49633839, grad/param norm = 5.2958e-01, time/batch = 0.6493s	
57/33250 (epoch 0.086), train_loss = 3.35640609, grad/param norm = 5.8736e-01, time/batch = 0.6468s	
58/33250 (epoch 0.087), train_loss = 3.53226242, grad/param norm = 6.8852e-01, time/batch = 0.6443s	
59/33250 (epoch 0.089), train_loss = 3.49938062, grad/param norm = 7.4887e-01, time/batch = 0.6614s	
60/33250 (epoch 0.090), train_loss = 3.36384849, grad/param norm = 6.6867e-01, time/batch = 0.6590s	
61/33250 (epoch 0.092), train_loss = 3.53237900, grad/param norm = 6.0554e-01, time/batch = 0.6720s	
62/33250 (epoch 0.093), train_loss = 3.29968674, grad/param norm = 6.9551e-01, time/batch = 0.6750s	
63/33250 (epoch 0.095), train_loss = 3.43421009, grad/param norm = 6.4718e-01, time/batch = 0.6700s	
64/33250 (epoch 0.096), train_loss = 3.44586274, grad/param norm = 4.7835e-01, time/batch = 0.6600s	
65/33250 (epoch 0.098), train_loss = 3.29673836, grad/param norm = 6.4121e-01, time/batch = 0.6696s	
66/33250 (epoch 0.099), train_loss = 3.54057226, grad/param norm = 5.9234e-01, time/batch = 0.6645s	
67/33250 (epoch 0.101), train_loss = 3.39162193, grad/param norm = 7.1230e-01, time/batch = 0.6561s	
68/33250 (epoch 0.102), train_loss = 3.45279974, grad/param norm = 6.1258e-01, time/batch = 0.6627s	
69/33250 (epoch 0.104), train_loss = 3.50884990, grad/param norm = 5.4889e-01, time/batch = 0.6627s	
70/33250 (epoch 0.105), train_loss = 3.44330440, grad/param norm = 7.3902e-01, time/batch = 0.6680s	
71/33250 (epoch 0.107), train_loss = 3.47202357, grad/param norm = 6.8455e-01, time/batch = 0.6668s	
72/33250 (epoch 0.108), train_loss = 3.46362764, grad/param norm = 5.4856e-01, time/batch = 0.6669s	
73/33250 (epoch 0.110), train_loss = 3.49369310, grad/param norm = 4.7196e-01, time/batch = 0.6678s	
74/33250 (epoch 0.111), train_loss = 3.36719508, grad/param norm = 6.8612e-01, time/batch = 0.6819s	
75/33250 (epoch 0.113), train_loss = 3.55633170, grad/param norm = 6.7866e-01, time/batch = 0.6866s	
76/33250 (epoch 0.114), train_loss = 3.49501943, grad/param norm = 4.7837e-01, time/batch = 0.6850s	
77/33250 (epoch 0.116), train_loss = 3.51884124, grad/param norm = 5.1754e-01, time/batch = 0.6743s	
78/33250 (epoch 0.117), train_loss = 3.46888717, grad/param norm = 6.7488e-01, time/batch = 0.6744s	
79/33250 (epoch 0.119), train_loss = 3.56045758, grad/param norm = 5.9006e-01, time/batch = 0.6686s	
80/33250 (epoch 0.120), train_loss = 3.52092883, grad/param norm = 5.6324e-01, time/batch = 0.6716s	
81/33250 (epoch 0.122), train_loss = 3.43612042, grad/param norm = 4.8039e-01, time/batch = 0.6899s	
82/33250 (epoch 0.123), train_loss = 3.41300212, grad/param norm = 4.2295e-01, time/batch = 0.6786s	
83/33250 (epoch 0.125), train_loss = 3.40054905, grad/param norm = 5.0188e-01, time/batch = 0.6654s	
84/33250 (epoch 0.126), train_loss = 3.55505023, grad/param norm = 6.1791e-01, time/batch = 0.6743s	
85/33250 (epoch 0.128), train_loss = 3.44687513, grad/param norm = 5.8790e-01, time/batch = 0.6679s	
86/33250 (epoch 0.129), train_loss = 3.53497531, grad/param norm = 9.2328e-01, time/batch = 0.6705s	
87/33250 (epoch 0.131), train_loss = 3.40798964, grad/param norm = 6.7966e-01, time/batch = 0.6715s	
88/33250 (epoch 0.132), train_loss = 3.44423629, grad/param norm = 6.5872e-01, time/batch = 0.6720s	
89/33250 (epoch 0.134), train_loss = 3.47131464, grad/param norm = 5.7744e-01, time/batch = 0.6665s	
90/33250 (epoch 0.135), train_loss = 3.49250076, grad/param norm = 4.9365e-01, time/batch = 0.6601s	
91/33250 (epoch 0.137), train_loss = 3.55572168, grad/param norm = 5.6893e-01, time/batch = 0.6545s	
92/33250 (epoch 0.138), train_loss = 3.53358680, grad/param norm = 4.6737e-01, time/batch = 0.6548s	
93/33250 (epoch 0.140), train_loss = 3.54180627, grad/param norm = 4.7303e-01, time/batch = 0.6482s	
94/33250 (epoch 0.141), train_loss = 3.58529708, grad/param norm = 5.3839e-01, time/batch = 0.6729s	
95/33250 (epoch 0.143), train_loss = 3.48488434, grad/param norm = 4.8216e-01, time/batch = 0.6638s	
96/33250 (epoch 0.144), train_loss = 3.36281648, grad/param norm = 6.4489e-01, time/batch = 0.6467s	
97/33250 (epoch 0.146), train_loss = 3.24912377, grad/param norm = 6.5810e-01, time/batch = 0.6508s	
98/33250 (epoch 0.147), train_loss = 3.38431532, grad/param norm = 4.1256e-01, time/batch = 0.6527s	
99/33250 (epoch 0.149), train_loss = 3.49429223, grad/param norm = 4.6239e-01, time/batch = 0.6511s	
100/33250 (epoch 0.150), train_loss = 3.37923867, grad/param norm = 4.0912e-01, time/batch = 0.6551s	
101/33250 (epoch 0.152), train_loss = 3.36874451, grad/param norm = 6.2886e-01, time/batch = 0.6588s	
102/33250 (epoch 0.153), train_loss = 3.48534759, grad/param norm = 9.8386e-01, time/batch = 0.6614s	
103/33250 (epoch 0.155), train_loss = 3.41212234, grad/param norm = 8.4755e-01, time/batch = 0.6590s	
104/33250 (epoch 0.156), train_loss = 3.43355296, grad/param norm = 6.5450e-01, time/batch = 0.6585s	
105/33250 (epoch 0.158), train_loss = 3.36917252, grad/param norm = 5.7385e-01, time/batch = 0.6635s	
106/33250 (epoch 0.159), train_loss = 3.51575332, grad/param norm = 6.6609e-01, time/batch = 0.6564s	
107/33250 (epoch 0.161), train_loss = 3.43056564, grad/param norm = 1.0656e+00, time/batch = 0.6547s	
108/33250 (epoch 0.162), train_loss = 3.55486044, grad/param norm = 9.1232e-01, time/batch = 0.6539s	
109/33250 (epoch 0.164), train_loss = 3.40834265, grad/param norm = 4.3719e-01, time/batch = 0.6573s	
110/33250 (epoch 0.165), train_loss = 3.47482671, grad/param norm = 4.5258e-01, time/batch = 0.6539s	
111/33250 (epoch 0.167), train_loss = 3.23877458, grad/param norm = 5.5631e-01, time/batch = 0.6573s	
112/33250 (epoch 0.168), train_loss = 3.33073549, grad/param norm = 4.8237e-01, time/batch = 0.6484s	
113/33250 (epoch 0.170), train_loss = 3.26232487, grad/param norm = 6.9277e-01, time/batch = 0.6529s	
114/33250 (epoch 0.171), train_loss = 3.35498967, grad/param norm = 7.5798e-01, time/batch = 0.6527s	
115/33250 (epoch 0.173), train_loss = 3.28594403, grad/param norm = 6.4191e-01, time/batch = 0.6641s	
116/33250 (epoch 0.174), train_loss = 3.21636107, grad/param norm = 5.1576e-01, time/batch = 0.6668s	
117/33250 (epoch 0.176), train_loss = 3.31705920, grad/param norm = 4.8542e-01, time/batch = 0.6789s	
118/33250 (epoch 0.177), train_loss = 3.28990700, grad/param norm = 4.7884e-01, time/batch = 0.6756s	
119/33250 (epoch 0.179), train_loss = 3.39107271, grad/param norm = 6.7929e-01, time/batch = 0.6680s	
120/33250 (epoch 0.180), train_loss = 3.21514330, grad/param norm = 6.1694e-01, time/batch = 0.6891s	
121/33250 (epoch 0.182), train_loss = 3.27877825, grad/param norm = 7.9015e-01, time/batch = 0.6885s	
122/33250 (epoch 0.183), train_loss = 3.66783484, grad/param norm = 2.9130e+00, time/batch = 0.6826s	
123/33250 (epoch 0.185), train_loss = 3.43585109, grad/param norm = 1.4472e+00, time/batch = 0.6815s	
124/33250 (epoch 0.186), train_loss = 3.34764014, grad/param norm = 4.2719e-01, time/batch = 0.6842s	
125/33250 (epoch 0.188), train_loss = 3.32327640, grad/param norm = 3.2710e-01, time/batch = 0.6774s	
126/33250 (epoch 0.189), train_loss = 3.32286962, grad/param norm = 3.6937e-01, time/batch = 0.6848s	
127/33250 (epoch 0.191), train_loss = 3.15701756, grad/param norm = 4.4558e-01, time/batch = 0.6773s	
128/33250 (epoch 0.192), train_loss = 3.34116200, grad/param norm = 5.4863e-01, time/batch = 0.6655s	
129/33250 (epoch 0.194), train_loss = 3.14652614, grad/param norm = 8.0424e-01, time/batch = 0.6697s	
130/33250 (epoch 0.195), train_loss = 3.26651829, grad/param norm = 6.0774e-01, time/batch = 0.6634s	
131/33250 (epoch 0.197), train_loss = 3.17582547, grad/param norm = 3.8575e-01, time/batch = 0.6671s	
132/33250 (epoch 0.198), train_loss = 3.19947453, grad/param norm = 4.8086e-01, time/batch = 0.6711s	
133/33250 (epoch 0.200), train_loss = 3.15071672, grad/param norm = 5.8825e-01, time/batch = 0.6776s	
134/33250 (epoch 0.202), train_loss = 3.27029503, grad/param norm = 9.2603e-01, time/batch = 0.6691s	
135/33250 (epoch 0.203), train_loss = 3.26009910, grad/param norm = 1.0257e+00, time/batch = 0.6680s	
136/33250 (epoch 0.205), train_loss = 3.31879469, grad/param norm = 9.1005e-01, time/batch = 0.6861s	
137/33250 (epoch 0.206), train_loss = 3.12376640, grad/param norm = 7.9138e-01, time/batch = 0.6795s	
138/33250 (epoch 0.208), train_loss = 3.37828255, grad/param norm = 5.6321e-01, time/batch = 0.6777s	
139/33250 (epoch 0.209), train_loss = 3.09153559, grad/param norm = 5.0626e-01, time/batch = 0.6718s	
140/33250 (epoch 0.211), train_loss = 3.25129247, grad/param norm = 4.5262e-01, time/batch = 0.6705s	
141/33250 (epoch 0.212), train_loss = 3.13923962, grad/param norm = 5.5444e-01, time/batch = 0.6739s	
142/33250 (epoch 0.214), train_loss = 3.13868496, grad/param norm = 6.3789e-01, time/batch = 0.6628s	
143/33250 (epoch 0.215), train_loss = 3.27658725, grad/param norm = 7.0115e-01, time/batch = 0.6645s	
144/33250 (epoch 0.217), train_loss = 3.16363679, grad/param norm = 5.8312e-01, time/batch = 0.6676s	
145/33250 (epoch 0.218), train_loss = 3.10868221, grad/param norm = 4.8333e-01, time/batch = 0.6783s	
146/33250 (epoch 0.220), train_loss = 3.22678427, grad/param norm = 8.7506e-01, time/batch = 0.6851s	
147/33250 (epoch 0.221), train_loss = 3.20854852, grad/param norm = 1.6531e+00, time/batch = 0.6883s	
148/33250 (epoch 0.223), train_loss = 3.27180415, grad/param norm = 1.6248e+00, time/batch = 0.6877s	
149/33250 (epoch 0.224), train_loss = 3.18988836, grad/param norm = 9.9372e-01, time/batch = 0.6764s	
150/33250 (epoch 0.226), train_loss = 3.12181552, grad/param norm = 5.7420e-01, time/batch = 0.6852s	
151/33250 (epoch 0.227), train_loss = 3.10831251, grad/param norm = 5.1370e-01, time/batch = 0.6897s	
152/33250 (epoch 0.229), train_loss = 3.02658263, grad/param norm = 4.1001e-01, time/batch = 0.6952s	
153/33250 (epoch 0.230), train_loss = 3.11596162, grad/param norm = 4.6056e-01, time/batch = 0.7022s	
154/33250 (epoch 0.232), train_loss = 3.08353440, grad/param norm = 3.8041e-01, time/batch = 0.7038s	
155/33250 (epoch 0.233), train_loss = 3.02282199, grad/param norm = 2.9188e-01, time/batch = 0.7057s	
156/33250 (epoch 0.235), train_loss = 3.03050272, grad/param norm = 3.1913e-01, time/batch = 0.6932s	
157/33250 (epoch 0.236), train_loss = 2.96905296, grad/param norm = 4.7729e-01, time/batch = 0.6916s	
158/33250 (epoch 0.238), train_loss = 3.01481938, grad/param norm = 5.8575e-01, time/batch = 0.7028s	
159/33250 (epoch 0.239), train_loss = 3.26746111, grad/param norm = 1.2129e+00, time/batch = 0.7029s	
160/33250 (epoch 0.241), train_loss = 3.08123850, grad/param norm = 1.2536e+00, time/batch = 0.7043s	
161/33250 (epoch 0.242), train_loss = 3.03230670, grad/param norm = 7.6058e-01, time/batch = 0.6854s	
162/33250 (epoch 0.244), train_loss = 3.10828288, grad/param norm = 5.3382e-01, time/batch = 0.6779s	
163/33250 (epoch 0.245), train_loss = 3.02213602, grad/param norm = 4.3480e-01, time/batch = 0.6894s	
164/33250 (epoch 0.247), train_loss = 3.11205435, grad/param norm = 5.7878e-01, time/batch = 0.6901s	
165/33250 (epoch 0.248), train_loss = 3.04694179, grad/param norm = 7.9263e-01, time/batch = 0.6933s	
166/33250 (epoch 0.250), train_loss = 3.04706769, grad/param norm = 1.1358e+00, time/batch = 0.6863s	
167/33250 (epoch 0.251), train_loss = 3.09401675, grad/param norm = 9.7311e-01, time/batch = 0.6889s	
168/33250 (epoch 0.253), train_loss = 3.02932615, grad/param norm = 8.6119e-01, time/batch = 0.6816s	
169/33250 (epoch 0.254), train_loss = 3.03732076, grad/param norm = 9.0191e-01, time/batch = 0.6743s	
170/33250 (epoch 0.256), train_loss = 3.04617958, grad/param norm = 7.9393e-01, time/batch = 0.6736s	
171/33250 (epoch 0.257), train_loss = 3.10111643, grad/param norm = 6.2620e-01, time/batch = 0.6727s	
172/33250 (epoch 0.259), train_loss = 3.16025369, grad/param norm = 7.3087e-01, time/batch = 0.6797s	
173/33250 (epoch 0.260), train_loss = 3.12800371, grad/param norm = 5.5528e-01, time/batch = 0.6961s	
174/33250 (epoch 0.262), train_loss = 2.98719909, grad/param norm = 4.1628e-01, time/batch = 0.6880s	
175/33250 (epoch 0.263), train_loss = 2.92141976, grad/param norm = 4.8086e-01, time/batch = 0.6834s	
176/33250 (epoch 0.265), train_loss = 3.02630437, grad/param norm = 6.4340e-01, time/batch = 0.6827s	
177/33250 (epoch 0.266), train_loss = 2.98367492, grad/param norm = 1.0570e+00, time/batch = 0.6904s	
178/33250 (epoch 0.268), train_loss = 3.31525129, grad/param norm = 1.1855e+00, time/batch = 0.6729s	
179/33250 (epoch 0.269), train_loss = 3.00957860, grad/param norm = 8.5273e-01, time/batch = 0.6685s	
180/33250 (epoch 0.271), train_loss = 2.92710557, grad/param norm = 9.1060e-01, time/batch = 0.6645s	
181/33250 (epoch 0.272), train_loss = 3.02230980, grad/param norm = 1.0174e+00, time/batch = 0.6855s	
182/33250 (epoch 0.274), train_loss = 2.89707589, grad/param norm = 7.5701e-01, time/batch = 0.6663s	
183/33250 (epoch 0.275), train_loss = 3.12225072, grad/param norm = 9.3219e-01, time/batch = 0.6661s	
184/33250 (epoch 0.277), train_loss = 3.03608036, grad/param norm = 1.1214e+00, time/batch = 0.6718s	
185/33250 (epoch 0.278), train_loss = 2.96375074, grad/param norm = 7.4544e-01, time/batch = 0.6632s	
186/33250 (epoch 0.280), train_loss = 2.93426870, grad/param norm = 3.6445e-01, time/batch = 0.6653s	
187/33250 (epoch 0.281), train_loss = 2.98077825, grad/param norm = 4.2948e-01, time/batch = 0.6873s	
188/33250 (epoch 0.283), train_loss = 2.99224283, grad/param norm = 3.5911e-01, time/batch = 0.6818s	
189/33250 (epoch 0.284), train_loss = 3.13044444, grad/param norm = 3.8226e-01, time/batch = 0.6789s	
190/33250 (epoch 0.286), train_loss = 3.00960697, grad/param norm = 5.3318e-01, time/batch = 0.6763s	
191/33250 (epoch 0.287), train_loss = 3.13473548, grad/param norm = 7.8623e-01, time/batch = 0.6699s	
192/33250 (epoch 0.289), train_loss = 3.05114929, grad/param norm = 1.0539e+00, time/batch = 0.6711s	
193/33250 (epoch 0.290), train_loss = 2.94387208, grad/param norm = 7.8000e-01, time/batch = 0.6717s	
194/33250 (epoch 0.292), train_loss = 2.96093691, grad/param norm = 7.4053e-01, time/batch = 0.6717s	
195/33250 (epoch 0.293), train_loss = 3.03217146, grad/param norm = 6.6986e-01, time/batch = 0.6756s	
196/33250 (epoch 0.295), train_loss = 2.90529313, grad/param norm = 4.9427e-01, time/batch = 0.6713s	
197/33250 (epoch 0.296), train_loss = 2.82960519, grad/param norm = 5.3751e-01, time/batch = 0.6807s	
198/33250 (epoch 0.298), train_loss = 2.95908641, grad/param norm = 4.8841e-01, time/batch = 0.6893s	
199/33250 (epoch 0.299), train_loss = 2.79664358, grad/param norm = 5.4451e-01, time/batch = 0.6738s	
200/33250 (epoch 0.301), train_loss = 2.92027798, grad/param norm = 6.7302e-01, time/batch = 0.6732s	
201/33250 (epoch 0.302), train_loss = 2.88550407, grad/param norm = 9.9034e-01, time/batch = 0.6736s	
202/33250 (epoch 0.304), train_loss = 2.95837400, grad/param norm = 1.1711e+00, time/batch = 0.6770s	
203/33250 (epoch 0.305), train_loss = 3.01162487, grad/param norm = 8.1715e-01, time/batch = 0.6748s	
204/33250 (epoch 0.307), train_loss = 2.86027820, grad/param norm = 6.1887e-01, time/batch = 0.6726s	
205/33250 (epoch 0.308), train_loss = 2.94140639, grad/param norm = 5.6947e-01, time/batch = 0.6738s	
206/33250 (epoch 0.310), train_loss = 2.80036419, grad/param norm = 6.5769e-01, time/batch = 0.6649s	
207/33250 (epoch 0.311), train_loss = 2.88517620, grad/param norm = 4.3341e-01, time/batch = 0.6652s	
208/33250 (epoch 0.313), train_loss = 2.96364577, grad/param norm = 4.5898e-01, time/batch = 0.6737s	
209/33250 (epoch 0.314), train_loss = 2.83277373, grad/param norm = 6.7173e-01, time/batch = 0.6662s	
210/33250 (epoch 0.316), train_loss = 2.92983915, grad/param norm = 9.0429e-01, time/batch = 0.6639s	
211/33250 (epoch 0.317), train_loss = 2.88064083, grad/param norm = 8.5675e-01, time/batch = 0.6698s	
212/33250 (epoch 0.319), train_loss = 2.86182645, grad/param norm = 5.2045e-01, time/batch = 0.6708s	
213/33250 (epoch 0.320), train_loss = 2.96226342, grad/param norm = 5.3420e-01, time/batch = 0.6715s	
214/33250 (epoch 0.322), train_loss = 2.83623779, grad/param norm = 6.6658e-01, time/batch = 0.6645s	
215/33250 (epoch 0.323), train_loss = 2.95611678, grad/param norm = 7.7519e-01, time/batch = 0.6680s	
216/33250 (epoch 0.325), train_loss = 2.81293051, grad/param norm = 6.7594e-01, time/batch = 0.6704s	
217/33250 (epoch 0.326), train_loss = 2.78914315, grad/param norm = 4.3685e-01, time/batch = 0.6683s	
218/33250 (epoch 0.328), train_loss = 2.78492411, grad/param norm = 3.6163e-01, time/batch = 0.6715s	
219/33250 (epoch 0.329), train_loss = 2.85200686, grad/param norm = 3.2844e-01, time/batch = 0.6669s	
220/33250 (epoch 0.331), train_loss = 2.70823043, grad/param norm = 4.4267e-01, time/batch = 0.6645s	
221/33250 (epoch 0.332), train_loss = 2.83077093, grad/param norm = 6.6995e-01, time/batch = 0.6632s	
222/33250 (epoch 0.334), train_loss = 2.88519262, grad/param norm = 7.9840e-01, time/batch = 0.6623s	
223/33250 (epoch 0.335), train_loss = 2.82859117, grad/param norm = 7.4207e-01, time/batch = 0.6629s	
224/33250 (epoch 0.337), train_loss = 2.85780230, grad/param norm = 8.3298e-01, time/batch = 0.6867s	
225/33250 (epoch 0.338), train_loss = 2.84054826, grad/param norm = 8.6090e-01, time/batch = 0.6774s	
226/33250 (epoch 0.340), train_loss = 2.93910390, grad/param norm = 8.7201e-01, time/batch = 0.6685s	
227/33250 (epoch 0.341), train_loss = 2.83208824, grad/param norm = 9.2205e-01, time/batch = 0.6690s	
228/33250 (epoch 0.343), train_loss = 2.97042449, grad/param norm = 8.2810e-01, time/batch = 0.6653s	
229/33250 (epoch 0.344), train_loss = 2.71372966, grad/param norm = 5.6474e-01, time/batch = 0.6797s	
230/33250 (epoch 0.346), train_loss = 2.67406658, grad/param norm = 5.3078e-01, time/batch = 0.6821s	
231/33250 (epoch 0.347), train_loss = 2.96911377, grad/param norm = 4.7133e-01, time/batch = 0.6776s	
232/33250 (epoch 0.349), train_loss = 2.94748421, grad/param norm = 8.4068e-01, time/batch = 0.6718s	
233/33250 (epoch 0.350), train_loss = 2.79414689, grad/param norm = 9.3616e-01, time/batch = 0.6657s	
234/33250 (epoch 0.352), train_loss = 2.79395998, grad/param norm = 6.0763e-01, time/batch = 0.6622s	
235/33250 (epoch 0.353), train_loss = 2.78289976, grad/param norm = 5.3345e-01, time/batch = 0.6611s	
236/33250 (epoch 0.355), train_loss = 2.74555083, grad/param norm = 8.3323e-01, time/batch = 0.6623s	
237/33250 (epoch 0.356), train_loss = 2.75183840, grad/param norm = 9.2005e-01, time/batch = 0.6629s	
238/33250 (epoch 0.358), train_loss = 2.70325251, grad/param norm = 8.6001e-01, time/batch = 0.6615s	
239/33250 (epoch 0.359), train_loss = 2.77753104, grad/param norm = 7.4373e-01, time/batch = 0.6643s	
240/33250 (epoch 0.361), train_loss = 2.83027041, grad/param norm = 5.5686e-01, time/batch = 0.6836s	
241/33250 (epoch 0.362), train_loss = 2.74449731, grad/param norm = 5.5756e-01, time/batch = 0.6626s	
242/33250 (epoch 0.364), train_loss = 2.81906834, grad/param norm = 5.8137e-01, time/batch = 0.6635s	
243/33250 (epoch 0.365), train_loss = 2.71622083, grad/param norm = 4.2994e-01, time/batch = 0.6613s	
244/33250 (epoch 0.367), train_loss = 2.73188888, grad/param norm = 3.6312e-01, time/batch = 0.6618s	
245/33250 (epoch 0.368), train_loss = 2.73786655, grad/param norm = 3.7226e-01, time/batch = 0.6653s	
246/33250 (epoch 0.370), train_loss = 2.67027029, grad/param norm = 4.4828e-01, time/batch = 0.6671s	
247/33250 (epoch 0.371), train_loss = 2.74832622, grad/param norm = 4.7378e-01, time/batch = 0.6754s	
248/33250 (epoch 0.373), train_loss = 2.66094096, grad/param norm = 5.7264e-01, time/batch = 0.6777s	
249/33250 (epoch 0.374), train_loss = 2.85388804, grad/param norm = 1.0492e+00, time/batch = 0.6638s	
250/33250 (epoch 0.376), train_loss = 2.70718759, grad/param norm = 9.8660e-01, time/batch = 0.6670s	
251/33250 (epoch 0.377), train_loss = 2.72161172, grad/param norm = 7.6831e-01, time/batch = 0.6895s	
252/33250 (epoch 0.379), train_loss = 2.70366056, grad/param norm = 6.7336e-01, time/batch = 0.6914s	
253/33250 (epoch 0.380), train_loss = 2.63831556, grad/param norm = 5.2098e-01, time/batch = 0.6976s	
254/33250 (epoch 0.382), train_loss = 2.77585067, grad/param norm = 4.6845e-01, time/batch = 0.6922s	
255/33250 (epoch 0.383), train_loss = 2.62012058, grad/param norm = 3.3078e-01, time/batch = 0.6907s	
256/33250 (epoch 0.385), train_loss = 2.76639642, grad/param norm = 4.3718e-01, time/batch = 0.6925s	
257/33250 (epoch 0.386), train_loss = 2.66489922, grad/param norm = 5.1069e-01, time/batch = 0.6803s	
258/33250 (epoch 0.388), train_loss = 2.68855662, grad/param norm = 5.2767e-01, time/batch = 0.6672s	
259/33250 (epoch 0.389), train_loss = 2.71732189, grad/param norm = 8.0684e-01, time/batch = 0.6554s	
260/33250 (epoch 0.391), train_loss = 2.61256784, grad/param norm = 6.7502e-01, time/batch = 0.6554s	
261/33250 (epoch 0.392), train_loss = 2.80547025, grad/param norm = 5.7534e-01, time/batch = 0.6595s	
262/33250 (epoch 0.394), train_loss = 2.78246818, grad/param norm = 6.8564e-01, time/batch = 0.6690s	
263/33250 (epoch 0.395), train_loss = 2.84227445, grad/param norm = 4.8866e-01, time/batch = 0.6542s	
264/33250 (epoch 0.397), train_loss = 2.86920446, grad/param norm = 4.2117e-01, time/batch = 0.6504s	
265/33250 (epoch 0.398), train_loss = 2.66288762, grad/param norm = 4.4561e-01, time/batch = 0.6482s	
266/33250 (epoch 0.400), train_loss = 2.68776091, grad/param norm = 5.0309e-01, time/batch = 0.6480s	
267/33250 (epoch 0.402), train_loss = 2.61879101, grad/param norm = 6.6991e-01, time/batch = 0.6482s	
268/33250 (epoch 0.403), train_loss = 2.68874962, grad/param norm = 6.9270e-01, time/batch = 0.6511s	
269/33250 (epoch 0.405), train_loss = 2.66562927, grad/param norm = 6.1532e-01, time/batch = 0.6713s	
270/33250 (epoch 0.406), train_loss = 2.65941447, grad/param norm = 7.3680e-01, time/batch = 0.6697s	
271/33250 (epoch 0.408), train_loss = 2.73150229, grad/param norm = 6.1155e-01, time/batch = 0.6451s	
272/33250 (epoch 0.409), train_loss = 2.63989507, grad/param norm = 6.0138e-01, time/batch = 0.6427s	
273/33250 (epoch 0.411), train_loss = 2.56507576, grad/param norm = 6.6137e-01, time/batch = 0.6435s	
274/33250 (epoch 0.412), train_loss = 2.50559856, grad/param norm = 7.2175e-01, time/batch = 0.6437s	
275/33250 (epoch 0.414), train_loss = 2.80489532, grad/param norm = 8.3604e-01, time/batch = 0.6424s	
276/33250 (epoch 0.415), train_loss = 2.63589561, grad/param norm = 8.6135e-01, time/batch = 0.6460s	
277/33250 (epoch 0.417), train_loss = 2.68925800, grad/param norm = 9.1770e-01, time/batch = 0.6488s	
278/33250 (epoch 0.418), train_loss = 2.80866981, grad/param norm = 7.7331e-01, time/batch = 0.6448s	
279/33250 (epoch 0.420), train_loss = 2.74876553, grad/param norm = 5.3315e-01, time/batch = 0.6501s	
280/33250 (epoch 0.421), train_loss = 2.50843652, grad/param norm = 3.1567e-01, time/batch = 0.6493s	
281/33250 (epoch 0.423), train_loss = 2.57427068, grad/param norm = 4.0375e-01, time/batch = 0.6575s	
282/33250 (epoch 0.424), train_loss = 2.64357907, grad/param norm = 4.6534e-01, time/batch = 0.6500s	
283/33250 (epoch 0.426), train_loss = 2.64414749, grad/param norm = 4.4646e-01, time/batch = 0.6461s	
284/33250 (epoch 0.427), train_loss = 2.55452145, grad/param norm = 4.7751e-01, time/batch = 0.6559s	
285/33250 (epoch 0.429), train_loss = 2.66940126, grad/param norm = 4.0738e-01, time/batch = 0.6560s	
286/33250 (epoch 0.430), train_loss = 2.57160883, grad/param norm = 5.0696e-01, time/batch = 0.6531s	
287/33250 (epoch 0.432), train_loss = 2.65254903, grad/param norm = 7.8628e-01, time/batch = 0.6665s	
288/33250 (epoch 0.433), train_loss = 2.61869279, grad/param norm = 6.4520e-01, time/batch = 0.6573s	
289/33250 (epoch 0.435), train_loss = 2.70921879, grad/param norm = 5.9293e-01, time/batch = 0.6631s	
290/33250 (epoch 0.436), train_loss = 2.69606538, grad/param norm = 3.9744e-01, time/batch = 0.6680s	
291/33250 (epoch 0.438), train_loss = 2.51050755, grad/param norm = 5.1990e-01, time/batch = 0.6628s	
292/33250 (epoch 0.439), train_loss = 2.55082851, grad/param norm = 4.1891e-01, time/batch = 0.6529s	
293/33250 (epoch 0.441), train_loss = 2.53280872, grad/param norm = 4.6198e-01, time/batch = 0.6529s	
294/33250 (epoch 0.442), train_loss = 2.57610564, grad/param norm = 5.4838e-01, time/batch = 0.6442s	
295/33250 (epoch 0.444), train_loss = 2.56361545, grad/param norm = 7.2800e-01, time/batch = 0.6725s	
296/33250 (epoch 0.445), train_loss = 2.66197456, grad/param norm = 8.9709e-01, time/batch = 0.6682s	
297/33250 (epoch 0.447), train_loss = 2.69063926, grad/param norm = 6.1495e-01, time/batch = 0.6438s	
298/33250 (epoch 0.448), train_loss = 2.58691761, grad/param norm = 5.6209e-01, time/batch = 0.6573s	
299/33250 (epoch 0.450), train_loss = 2.65467578, grad/param norm = 4.8446e-01, time/batch = 0.6639s	
300/33250 (epoch 0.451), train_loss = 2.64985094, grad/param norm = 4.8090e-01, time/batch = 0.6584s	
301/33250 (epoch 0.453), train_loss = 2.48831819, grad/param norm = 5.7577e-01, time/batch = 0.6611s	
302/33250 (epoch 0.454), train_loss = 2.61780800, grad/param norm = 7.8300e-01, time/batch = 0.6627s	
303/33250 (epoch 0.456), train_loss = 2.45837432, grad/param norm = 4.7671e-01, time/batch = 0.6615s	
304/33250 (epoch 0.457), train_loss = 2.53978801, grad/param norm = 5.2912e-01, time/batch = 0.6778s	
305/33250 (epoch 0.459), train_loss = 2.66799333, grad/param norm = 6.2942e-01, time/batch = 0.6650s	
306/33250 (epoch 0.460), train_loss = 2.53308536, grad/param norm = 6.2905e-01, time/batch = 0.6581s	
307/33250 (epoch 0.462), train_loss = 2.57649163, grad/param norm = 6.7684e-01, time/batch = 0.6604s	
308/33250 (epoch 0.463), train_loss = 2.51064493, grad/param norm = 5.0427e-01, time/batch = 0.6668s	
309/33250 (epoch 0.465), train_loss = 2.27044958, grad/param norm = 5.2421e-01, time/batch = 0.6572s	
310/33250 (epoch 0.466), train_loss = 2.44673246, grad/param norm = 6.5715e-01, time/batch = 0.6518s	
311/33250 (epoch 0.468), train_loss = 2.47160492, grad/param norm = 5.4583e-01, time/batch = 0.6749s	
312/33250 (epoch 0.469), train_loss = 2.62655566, grad/param norm = 5.2310e-01, time/batch = 0.6751s	
313/33250 (epoch 0.471), train_loss = 2.70705334, grad/param norm = 5.5811e-01, time/batch = 0.6927s	
314/33250 (epoch 0.472), train_loss = 2.58955487, grad/param norm = 5.0039e-01, time/batch = 0.6616s	
315/33250 (epoch 0.474), train_loss = 2.63325610, grad/param norm = 4.8018e-01, time/batch = 0.6649s	
316/33250 (epoch 0.475), train_loss = 2.51356521, grad/param norm = 3.9004e-01, time/batch = 0.6663s	
317/33250 (epoch 0.477), train_loss = 2.53940223, grad/param norm = 4.0783e-01, time/batch = 0.6602s	
318/33250 (epoch 0.478), train_loss = 2.60027099, grad/param norm = 4.7734e-01, time/batch = 0.6757s	
319/33250 (epoch 0.480), train_loss = 2.71097902, grad/param norm = 6.3519e-01, time/batch = 0.6797s	
320/33250 (epoch 0.481), train_loss = 2.55512577, grad/param norm = 7.1004e-01, time/batch = 0.6731s	
321/33250 (epoch 0.483), train_loss = 2.62367545, grad/param norm = 5.3325e-01, time/batch = 0.6847s	
322/33250 (epoch 0.484), train_loss = 2.56090269, grad/param norm = 4.1022e-01, time/batch = 0.6831s	
323/33250 (epoch 0.486), train_loss = 2.51579103, grad/param norm = 4.8814e-01, time/batch = 0.7070s	
324/33250 (epoch 0.487), train_loss = 2.61164150, grad/param norm = 7.5211e-01, time/batch = 0.7043s	
325/33250 (epoch 0.489), train_loss = 2.59363679, grad/param norm = 5.9360e-01, time/batch = 0.6894s	
326/33250 (epoch 0.490), train_loss = 2.55890763, grad/param norm = 3.0717e-01, time/batch = 0.6791s	
327/33250 (epoch 0.492), train_loss = 2.55385894, grad/param norm = 4.0093e-01, time/batch = 0.6827s	
328/33250 (epoch 0.493), train_loss = 2.56370042, grad/param norm = 3.7346e-01, time/batch = 0.6821s	
329/33250 (epoch 0.495), train_loss = 2.56821668, grad/param norm = 3.7587e-01, time/batch = 0.6856s	
330/33250 (epoch 0.496), train_loss = 2.51657089, grad/param norm = 4.4864e-01, time/batch = 0.6827s	
331/33250 (epoch 0.498), train_loss = 2.54819255, grad/param norm = 6.3977e-01, time/batch = 0.6763s	
332/33250 (epoch 0.499), train_loss = 2.60909221, grad/param norm = 8.0623e-01, time/batch = 0.6725s	
333/33250 (epoch 0.501), train_loss = 2.52981066, grad/param norm = 8.8166e-01, time/batch = 0.6658s	
334/33250 (epoch 0.502), train_loss = 2.54649226, grad/param norm = 1.0864e+00, time/batch = 0.6649s	
335/33250 (epoch 0.504), train_loss = 2.63281763, grad/param norm = 6.8976e-01, time/batch = 0.6755s	
336/33250 (epoch 0.505), train_loss = 2.47896737, grad/param norm = 4.0384e-01, time/batch = 0.6675s	
337/33250 (epoch 0.507), train_loss = 2.58026221, grad/param norm = 5.0228e-01, time/batch = 0.6822s	
338/33250 (epoch 0.508), train_loss = 2.46583433, grad/param norm = 5.0653e-01, time/batch = 0.6824s	
339/33250 (epoch 0.510), train_loss = 2.52363536, grad/param norm = 4.7295e-01, time/batch = 0.6868s	
340/33250 (epoch 0.511), train_loss = 2.57862797, grad/param norm = 5.2549e-01, time/batch = 0.6921s	
341/33250 (epoch 0.513), train_loss = 2.70108543, grad/param norm = 4.5330e-01, time/batch = 0.6932s	
342/33250 (epoch 0.514), train_loss = 2.59091548, grad/param norm = 3.9177e-01, time/batch = 0.6952s	
343/33250 (epoch 0.516), train_loss = 2.54140580, grad/param norm = 4.0272e-01, time/batch = 0.6976s	
344/33250 (epoch 0.517), train_loss = 2.60944927, grad/param norm = 4.3810e-01, time/batch = 0.7013s	
345/33250 (epoch 0.519), train_loss = 2.29892158, grad/param norm = 4.7574e-01, time/batch = 0.6915s	
346/33250 (epoch 0.520), train_loss = 2.65716009, grad/param norm = 5.1564e-01, time/batch = 0.6964s	
347/33250 (epoch 0.522), train_loss = 2.58380874, grad/param norm = 4.3475e-01, time/batch = 0.6934s	
348/33250 (epoch 0.523), train_loss = 2.44386621, grad/param norm = 4.4678e-01, time/batch = 0.6882s	
349/33250 (epoch 0.525), train_loss = 2.54245328, grad/param norm = 5.2735e-01, time/batch = 0.6939s	
350/33250 (epoch 0.526), train_loss = 2.49384700, grad/param norm = 6.2733e-01, time/batch = 0.6925s	
351/33250 (epoch 0.528), train_loss = 2.51185792, grad/param norm = 5.4473e-01, time/batch = 0.6874s	
352/33250 (epoch 0.529), train_loss = 2.50181988, grad/param norm = 5.4261e-01, time/batch = 0.6841s	
353/33250 (epoch 0.531), train_loss = 2.37928485, grad/param norm = 6.0754e-01, time/batch = 0.6848s	
354/33250 (epoch 0.532), train_loss = 2.53826114, grad/param norm = 4.4143e-01, time/batch = 0.6842s	
355/33250 (epoch 0.534), train_loss = 2.43537645, grad/param norm = 4.1386e-01, time/batch = 0.6992s	
356/33250 (epoch 0.535), train_loss = 2.50786816, grad/param norm = 5.1400e-01, time/batch = 0.6960s	
357/33250 (epoch 0.537), train_loss = 2.56921216, grad/param norm = 4.9591e-01, time/batch = 0.6922s	
358/33250 (epoch 0.538), train_loss = 2.42574308, grad/param norm = 5.8466e-01, time/batch = 0.6842s	
359/33250 (epoch 0.540), train_loss = 2.59334665, grad/param norm = 5.2177e-01, time/batch = 0.6851s	
360/33250 (epoch 0.541), train_loss = 2.50633934, grad/param norm = 4.0157e-01, time/batch = 0.6864s	
361/33250 (epoch 0.543), train_loss = 2.63204824, grad/param norm = 3.8911e-01, time/batch = 0.6845s	
362/33250 (epoch 0.544), train_loss = 2.60567113, grad/param norm = 3.6810e-01, time/batch = 0.6858s	
363/33250 (epoch 0.546), train_loss = 2.53459256, grad/param norm = 3.7562e-01, time/batch = 0.6807s	
364/33250 (epoch 0.547), train_loss = 2.34034985, grad/param norm = 4.9696e-01, time/batch = 0.6778s	
365/33250 (epoch 0.549), train_loss = 2.54255784, grad/param norm = 5.5623e-01, time/batch = 0.6856s	
366/33250 (epoch 0.550), train_loss = 2.40604375, grad/param norm = 5.8206e-01, time/batch = 0.6814s	
367/33250 (epoch 0.552), train_loss = 2.44015109, grad/param norm = 6.2244e-01, time/batch = 0.6887s	
368/33250 (epoch 0.553), train_loss = 2.40173139, grad/param norm = 6.1117e-01, time/batch = 0.6913s	
369/33250 (epoch 0.555), train_loss = 2.45122086, grad/param norm = 4.9780e-01, time/batch = 0.6878s	
370/33250 (epoch 0.556), train_loss = 2.60744463, grad/param norm = 4.3281e-01, time/batch = 0.6645s	
371/33250 (epoch 0.558), train_loss = 2.60579367, grad/param norm = 4.4084e-01, time/batch = 0.6770s	
372/33250 (epoch 0.559), train_loss = 2.50781206, grad/param norm = 4.7101e-01, time/batch = 0.6895s	
373/33250 (epoch 0.561), train_loss = 2.58773446, grad/param norm = 5.0094e-01, time/batch = 0.6886s	
374/33250 (epoch 0.562), train_loss = 2.60765742, grad/param norm = 7.1117e-01, time/batch = 0.6881s	
375/33250 (epoch 0.564), train_loss = 2.59403850, grad/param norm = 8.7467e-01, time/batch = 0.6878s	
376/33250 (epoch 0.565), train_loss = 2.42848981, grad/param norm = 5.9333e-01, time/batch = 0.6850s	
377/33250 (epoch 0.567), train_loss = 2.45708430, grad/param norm = 4.5872e-01, time/batch = 0.6891s	
378/33250 (epoch 0.568), train_loss = 2.45717862, grad/param norm = 3.6678e-01, time/batch = 0.6830s	
379/33250 (epoch 0.570), train_loss = 2.56206041, grad/param norm = 4.4542e-01, time/batch = 0.6863s	
380/33250 (epoch 0.571), train_loss = 2.59012951, grad/param norm = 4.3151e-01, time/batch = 0.6903s	
381/33250 (epoch 0.573), train_loss = 2.51560067, grad/param norm = 4.3838e-01, time/batch = 0.6939s	
382/33250 (epoch 0.574), train_loss = 2.44188370, grad/param norm = 4.6068e-01, time/batch = 0.7029s	
383/33250 (epoch 0.576), train_loss = 2.60207969, grad/param norm = 4.7163e-01, time/batch = 0.7063s	
384/33250 (epoch 0.577), train_loss = 2.55720728, grad/param norm = 4.6338e-01, time/batch = 0.6892s	
385/33250 (epoch 0.579), train_loss = 2.34417650, grad/param norm = 3.7232e-01, time/batch = 0.6901s	
386/33250 (epoch 0.580), train_loss = 2.41486474, grad/param norm = 3.8091e-01, time/batch = 0.6948s	
387/33250 (epoch 0.582), train_loss = 2.47275421, grad/param norm = 5.3078e-01, time/batch = 0.6933s	
388/33250 (epoch 0.583), train_loss = 2.47095297, grad/param norm = 8.5716e-01, time/batch = 0.6914s	
389/33250 (epoch 0.585), train_loss = 2.48270533, grad/param norm = 6.6773e-01, time/batch = 0.6908s	
390/33250 (epoch 0.586), train_loss = 2.44244510, grad/param norm = 4.0869e-01, time/batch = 0.6945s	
391/33250 (epoch 0.588), train_loss = 2.46276712, grad/param norm = 4.0761e-01, time/batch = 0.6903s	
392/33250 (epoch 0.589), train_loss = 2.62239560, grad/param norm = 5.9042e-01, time/batch = 0.6925s	
393/33250 (epoch 0.591), train_loss = 2.50422135, grad/param norm = 5.5217e-01, time/batch = 0.6887s	
394/33250 (epoch 0.592), train_loss = 2.46209724, grad/param norm = 3.5382e-01, time/batch = 0.6883s	
395/33250 (epoch 0.594), train_loss = 2.59210043, grad/param norm = 3.3097e-01, time/batch = 0.6867s	
396/33250 (epoch 0.595), train_loss = 2.46359967, grad/param norm = 3.3607e-01, time/batch = 0.6833s	
397/33250 (epoch 0.597), train_loss = 2.46439641, grad/param norm = 4.5120e-01, time/batch = 0.6660s	
398/33250 (epoch 0.598), train_loss = 2.43177083, grad/param norm = 4.1478e-01, time/batch = 0.6663s	
399/33250 (epoch 0.600), train_loss = 2.47572332, grad/param norm = 3.6663e-01, time/batch = 0.6659s	
400/33250 (epoch 0.602), train_loss = 2.58763599, grad/param norm = 4.5809e-01, time/batch = 0.6760s	
401/33250 (epoch 0.603), train_loss = 2.36329002, grad/param norm = 5.0454e-01, time/batch = 0.6819s	
402/33250 (epoch 0.605), train_loss = 2.51233409, grad/param norm = 4.7867e-01, time/batch = 0.6865s	
403/33250 (epoch 0.606), train_loss = 2.47714941, grad/param norm = 5.3431e-01, time/batch = 0.6741s	
404/33250 (epoch 0.608), train_loss = 2.45036277, grad/param norm = 4.5151e-01, time/batch = 0.6594s	
405/33250 (epoch 0.609), train_loss = 2.38412998, grad/param norm = 4.2911e-01, time/batch = 0.6632s	
406/33250 (epoch 0.611), train_loss = 2.55088386, grad/param norm = 6.3708e-01, time/batch = 0.6733s	
407/33250 (epoch 0.612), train_loss = 2.67669418, grad/param norm = 6.0683e-01, time/batch = 0.6686s	
408/33250 (epoch 0.614), train_loss = 2.54266400, grad/param norm = 4.9563e-01, time/batch = 0.6634s	
409/33250 (epoch 0.615), train_loss = 2.58842185, grad/param norm = 3.9391e-01, time/batch = 0.6667s	
410/33250 (epoch 0.617), train_loss = 2.67755894, grad/param norm = 3.8351e-01, time/batch = 0.6685s	
411/33250 (epoch 0.618), train_loss = 2.54093994, grad/param norm = 3.0475e-01, time/batch = 0.6712s	
412/33250 (epoch 0.620), train_loss = 2.53844065, grad/param norm = 3.4929e-01, time/batch = 0.6617s	
413/33250 (epoch 0.621), train_loss = 2.32584329, grad/param norm = 4.1029e-01, time/batch = 0.6631s	
414/33250 (epoch 0.623), train_loss = 2.49705265, grad/param norm = 5.3846e-01, time/batch = 0.6697s	
415/33250 (epoch 0.624), train_loss = 2.53953807, grad/param norm = 6.8901e-01, time/batch = 0.6677s	
416/33250 (epoch 0.626), train_loss = 2.43144353, grad/param norm = 6.8248e-01, time/batch = 0.6598s	
417/33250 (epoch 0.627), train_loss = 2.65266595, grad/param norm = 5.2190e-01, time/batch = 0.6799s	
418/33250 (epoch 0.629), train_loss = 2.53260129, grad/param norm = 6.0658e-01, time/batch = 0.6606s	
419/33250 (epoch 0.630), train_loss = 2.53049816, grad/param norm = 4.9974e-01, time/batch = 0.6687s	
420/33250 (epoch 0.632), train_loss = 2.22918569, grad/param norm = 3.4730e-01, time/batch = 0.6738s	
421/33250 (epoch 0.633), train_loss = 2.56925659, grad/param norm = 4.0411e-01, time/batch = 0.6689s	
422/33250 (epoch 0.635), train_loss = 2.31354645, grad/param norm = 4.0443e-01, time/batch = 0.6685s	
423/33250 (epoch 0.636), train_loss = 2.43891963, grad/param norm = 4.4082e-01, time/batch = 0.6667s	
424/33250 (epoch 0.638), train_loss = 2.38783368, grad/param norm = 4.3515e-01, time/batch = 0.6693s	
425/33250 (epoch 0.639), train_loss = 2.55039908, grad/param norm = 4.4502e-01, time/batch = 0.6696s	
426/33250 (epoch 0.641), train_loss = 2.36791520, grad/param norm = 5.4627e-01, time/batch = 0.6692s	
427/33250 (epoch 0.642), train_loss = 2.39771143, grad/param norm = 5.8946e-01, time/batch = 0.6650s	
428/33250 (epoch 0.644), train_loss = 2.38121946, grad/param norm = 6.5179e-01, time/batch = 0.6732s	
429/33250 (epoch 0.645), train_loss = 2.39262684, grad/param norm = 5.8786e-01, time/batch = 0.6885s	
430/33250 (epoch 0.647), train_loss = 2.43709067, grad/param norm = 4.4535e-01, time/batch = 0.6978s	
431/33250 (epoch 0.648), train_loss = 2.40075912, grad/param norm = 4.2677e-01, time/batch = 0.6900s	
432/33250 (epoch 0.650), train_loss = 2.51965765, grad/param norm = 4.2580e-01, time/batch = 0.6883s	
433/33250 (epoch 0.651), train_loss = 2.46850345, grad/param norm = 4.0823e-01, time/batch = 0.6978s	
434/33250 (epoch 0.653), train_loss = 2.28619687, grad/param norm = 3.9111e-01, time/batch = 0.6885s	
435/33250 (epoch 0.654), train_loss = 2.27529473, grad/param norm = 3.9451e-01, time/batch = 0.6890s	
436/33250 (epoch 0.656), train_loss = 2.42360983, grad/param norm = 4.5767e-01, time/batch = 0.6843s	
437/33250 (epoch 0.657), train_loss = 2.37578111, grad/param norm = 4.9119e-01, time/batch = 0.6701s	
438/33250 (epoch 0.659), train_loss = 2.21816692, grad/param norm = 4.9206e-01, time/batch = 0.6693s	
439/33250 (epoch 0.660), train_loss = 2.37153136, grad/param norm = 4.1228e-01, time/batch = 0.6663s	
440/33250 (epoch 0.662), train_loss = 2.46341446, grad/param norm = 4.2398e-01, time/batch = 0.6751s	
441/33250 (epoch 0.663), train_loss = 2.25570437, grad/param norm = 3.0818e-01, time/batch = 0.6860s	
442/33250 (epoch 0.665), train_loss = 2.49809339, grad/param norm = 4.4962e-01, time/batch = 0.6903s	
443/33250 (epoch 0.666), train_loss = 2.38731514, grad/param norm = 4.9377e-01, time/batch = 0.6901s	
444/33250 (epoch 0.668), train_loss = 2.48302101, grad/param norm = 4.8796e-01, time/batch = 0.6737s	
445/33250 (epoch 0.669), train_loss = 2.56264768, grad/param norm = 4.9155e-01, time/batch = 0.6766s	
446/33250 (epoch 0.671), train_loss = 2.44810039, grad/param norm = 4.8022e-01, time/batch = 0.6693s	
447/33250 (epoch 0.672), train_loss = 2.41892974, grad/param norm = 5.2577e-01, time/batch = 0.6663s	
448/33250 (epoch 0.674), train_loss = 2.36367109, grad/param norm = 4.9199e-01, time/batch = 0.6684s	
449/33250 (epoch 0.675), train_loss = 2.36989205, grad/param norm = 3.6892e-01, time/batch = 0.6658s	
450/33250 (epoch 0.677), train_loss = 2.39809578, grad/param norm = 4.1421e-01, time/batch = 0.6670s	
451/33250 (epoch 0.678), train_loss = 2.55420386, grad/param norm = 4.4461e-01, time/batch = 0.6698s	
452/33250 (epoch 0.680), train_loss = 2.45897374, grad/param norm = 3.7772e-01, time/batch = 0.6671s	
453/33250 (epoch 0.681), train_loss = 2.25676846, grad/param norm = 4.4734e-01, time/batch = 0.6701s	
454/33250 (epoch 0.683), train_loss = 2.40379003, grad/param norm = 3.9241e-01, time/batch = 0.6709s	
455/33250 (epoch 0.684), train_loss = 2.41303213, grad/param norm = 3.6041e-01, time/batch = 0.6664s	
456/33250 (epoch 0.686), train_loss = 2.30750438, grad/param norm = 3.3973e-01, time/batch = 0.6620s	
457/33250 (epoch 0.687), train_loss = 2.24576163, grad/param norm = 3.8818e-01, time/batch = 0.6675s	
458/33250 (epoch 0.689), train_loss = 2.29541988, grad/param norm = 4.7342e-01, time/batch = 0.6735s	
459/33250 (epoch 0.690), train_loss = 2.44423023, grad/param norm = 5.4694e-01, time/batch = 0.6667s	
460/33250 (epoch 0.692), train_loss = 2.49380434, grad/param norm = 6.4598e-01, time/batch = 0.6662s	
461/33250 (epoch 0.693), train_loss = 2.31881498, grad/param norm = 3.7109e-01, time/batch = 0.6689s	
462/33250 (epoch 0.695), train_loss = 2.55941155, grad/param norm = 3.1957e-01, time/batch = 0.6694s	
463/33250 (epoch 0.696), train_loss = 2.37223676, grad/param norm = 3.2296e-01, time/batch = 0.6630s	
464/33250 (epoch 0.698), train_loss = 2.16863809, grad/param norm = 3.3754e-01, time/batch = 0.6660s	
465/33250 (epoch 0.699), train_loss = 2.35447017, grad/param norm = 3.8939e-01, time/batch = 0.6701s	
466/33250 (epoch 0.701), train_loss = 2.36450663, grad/param norm = 4.3420e-01, time/batch = 0.6677s	
467/33250 (epoch 0.702), train_loss = 2.49034051, grad/param norm = 5.6102e-01, time/batch = 0.6731s	
468/33250 (epoch 0.704), train_loss = 2.50413591, grad/param norm = 6.3363e-01, time/batch = 0.6739s	
469/33250 (epoch 0.705), train_loss = 2.45314620, grad/param norm = 6.8111e-01, time/batch = 0.6763s	
470/33250 (epoch 0.707), train_loss = 2.33196534, grad/param norm = 4.4125e-01, time/batch = 0.6761s	
471/33250 (epoch 0.708), train_loss = 2.29197718, grad/param norm = 3.3052e-01, time/batch = 0.6787s	
472/33250 (epoch 0.710), train_loss = 2.44712410, grad/param norm = 4.1374e-01, time/batch = 0.6825s	
473/33250 (epoch 0.711), train_loss = 2.43210830, grad/param norm = 4.0196e-01, time/batch = 0.6798s	
474/33250 (epoch 0.713), train_loss = 2.37742951, grad/param norm = 2.8111e-01, time/batch = 0.6723s	
475/33250 (epoch 0.714), train_loss = 2.41247673, grad/param norm = 2.8777e-01, time/batch = 0.6800s	
476/33250 (epoch 0.716), train_loss = 2.33302637, grad/param norm = 4.0490e-01, time/batch = 0.6908s	
477/33250 (epoch 0.717), train_loss = 2.22146242, grad/param norm = 4.3880e-01, time/batch = 0.6896s	
478/33250 (epoch 0.719), train_loss = 2.49205009, grad/param norm = 3.2598e-01, time/batch = 0.6923s	
479/33250 (epoch 0.720), train_loss = 2.52196432, grad/param norm = 4.1754e-01, time/batch = 0.6907s	
480/33250 (epoch 0.722), train_loss = 2.29978252, grad/param norm = 4.4708e-01, time/batch = 0.6910s	
481/33250 (epoch 0.723), train_loss = 2.32915886, grad/param norm = 4.7790e-01, time/batch = 0.6940s	
482/33250 (epoch 0.725), train_loss = 2.07095442, grad/param norm = 5.6364e-01, time/batch = 0.6888s	
483/33250 (epoch 0.726), train_loss = 2.33533178, grad/param norm = 5.2076e-01, time/batch = 0.6875s	
484/33250 (epoch 0.728), train_loss = 2.43807743, grad/param norm = 5.6179e-01, time/batch = 0.6786s	
485/33250 (epoch 0.729), train_loss = 2.36688049, grad/param norm = 6.0323e-01, time/batch = 0.6987s	
486/33250 (epoch 0.731), train_loss = 2.36022029, grad/param norm = 5.3077e-01, time/batch = 0.6792s	
487/33250 (epoch 0.732), train_loss = 2.27551312, grad/param norm = 3.7958e-01, time/batch = 0.6660s	
488/33250 (epoch 0.734), train_loss = 2.28726081, grad/param norm = 4.7005e-01, time/batch = 0.6814s	
489/33250 (epoch 0.735), train_loss = 2.32296893, grad/param norm = 5.2633e-01, time/batch = 0.6850s	
490/33250 (epoch 0.737), train_loss = 2.43085114, grad/param norm = 3.8608e-01, time/batch = 0.6883s	
491/33250 (epoch 0.738), train_loss = 2.31659006, grad/param norm = 3.8654e-01, time/batch = 0.6931s	
492/33250 (epoch 0.740), train_loss = 2.60257334, grad/param norm = 4.1508e-01, time/batch = 0.6865s	
493/33250 (epoch 0.741), train_loss = 2.25361816, grad/param norm = 4.8880e-01, time/batch = 0.6772s	
494/33250 (epoch 0.743), train_loss = 2.37623398, grad/param norm = 4.3015e-01, time/batch = 0.6671s	
495/33250 (epoch 0.744), train_loss = 2.29248734, grad/param norm = 2.9875e-01, time/batch = 0.6538s	
496/33250 (epoch 0.746), train_loss = 2.40309897, grad/param norm = 3.2239e-01, time/batch = 0.6405s	
497/33250 (epoch 0.747), train_loss = 2.29063287, grad/param norm = 3.6510e-01, time/batch = 0.6518s	
498/33250 (epoch 0.749), train_loss = 2.38002767, grad/param norm = 4.3639e-01, time/batch = 0.6465s	
499/33250 (epoch 0.750), train_loss = 2.28991442, grad/param norm = 5.1972e-01, time/batch = 0.6469s	
500/33250 (epoch 0.752), train_loss = 2.29572021, grad/param norm = 5.6404e-01, time/batch = 0.6459s	
501/33250 (epoch 0.753), train_loss = 2.40220236, grad/param norm = 5.1145e-01, time/batch = 0.6413s	
502/33250 (epoch 0.755), train_loss = 2.23812128, grad/param norm = 4.5515e-01, time/batch = 0.6497s	
503/33250 (epoch 0.756), train_loss = 2.37690374, grad/param norm = 3.8685e-01, time/batch = 0.6439s	
504/33250 (epoch 0.758), train_loss = 2.30243358, grad/param norm = 3.7224e-01, time/batch = 0.6433s	
505/33250 (epoch 0.759), train_loss = 2.19079565, grad/param norm = 3.3810e-01, time/batch = 0.6433s	
506/33250 (epoch 0.761), train_loss = 2.33805619, grad/param norm = 4.3405e-01, time/batch = 0.6516s	
507/33250 (epoch 0.762), train_loss = 2.37419519, grad/param norm = 3.9610e-01, time/batch = 0.6561s	
508/33250 (epoch 0.764), train_loss = 2.24848160, grad/param norm = 3.5744e-01, time/batch = 0.6535s	
509/33250 (epoch 0.765), train_loss = 2.28463688, grad/param norm = 3.8690e-01, time/batch = 0.6519s	
510/33250 (epoch 0.767), train_loss = 2.27064159, grad/param norm = 4.4896e-01, time/batch = 0.6542s	
511/33250 (epoch 0.768), train_loss = 2.40959636, grad/param norm = 5.1613e-01, time/batch = 0.6609s	
512/33250 (epoch 0.770), train_loss = 2.25161363, grad/param norm = 5.1673e-01, time/batch = 0.6576s	
513/33250 (epoch 0.771), train_loss = 2.32473021, grad/param norm = 3.7835e-01, time/batch = 0.6620s	
514/33250 (epoch 0.773), train_loss = 2.25154109, grad/param norm = 4.1469e-01, time/batch = 0.6572s	
515/33250 (epoch 0.774), train_loss = 2.11351664, grad/param norm = 4.5096e-01, time/batch = 0.6566s	
516/33250 (epoch 0.776), train_loss = 2.35406474, grad/param norm = 6.0829e-01, time/batch = 0.6611s	
517/33250 (epoch 0.777), train_loss = 2.47915264, grad/param norm = 4.9742e-01, time/batch = 0.6739s	
518/33250 (epoch 0.779), train_loss = 2.12585652, grad/param norm = 3.3848e-01, time/batch = 0.6860s	
519/33250 (epoch 0.780), train_loss = 2.40413349, grad/param norm = 3.3557e-01, time/batch = 0.6873s	
520/33250 (epoch 0.782), train_loss = 2.46892587, grad/param norm = 3.7345e-01, time/batch = 0.6760s	
521/33250 (epoch 0.783), train_loss = 2.21343495, grad/param norm = 5.2996e-01, time/batch = 0.6668s	
522/33250 (epoch 0.785), train_loss = 2.25227801, grad/param norm = 4.9649e-01, time/batch = 0.6593s	
523/33250 (epoch 0.786), train_loss = 2.40261790, grad/param norm = 4.2788e-01, time/batch = 0.6623s	
524/33250 (epoch 0.788), train_loss = 2.30028755, grad/param norm = 3.8804e-01, time/batch = 0.6707s	
525/33250 (epoch 0.789), train_loss = 2.21504141, grad/param norm = 4.0039e-01, time/batch = 0.6654s	
526/33250 (epoch 0.791), train_loss = 2.45025024, grad/param norm = 4.8328e-01, time/batch = 0.6661s	
527/33250 (epoch 0.792), train_loss = 2.43808907, grad/param norm = 3.9380e-01, time/batch = 0.6707s	
528/33250 (epoch 0.794), train_loss = 2.13750450, grad/param norm = 4.0176e-01, time/batch = 0.6563s	
529/33250 (epoch 0.795), train_loss = 2.40582797, grad/param norm = 4.8405e-01, time/batch = 0.6593s	
530/33250 (epoch 0.797), train_loss = 2.39863716, grad/param norm = 4.6337e-01, time/batch = 0.6696s	
531/33250 (epoch 0.798), train_loss = 2.44534822, grad/param norm = 5.4771e-01, time/batch = 0.6682s	
532/33250 (epoch 0.800), train_loss = 2.38209562, grad/param norm = 4.5694e-01, time/batch = 0.6818s	
533/33250 (epoch 0.802), train_loss = 2.16057736, grad/param norm = 3.5715e-01, time/batch = 0.6692s	
534/33250 (epoch 0.803), train_loss = 2.26620681, grad/param norm = 3.7301e-01, time/batch = 0.6625s	
535/33250 (epoch 0.805), train_loss = 2.22744689, grad/param norm = 3.1127e-01, time/batch = 0.6621s	
536/33250 (epoch 0.806), train_loss = 2.35695621, grad/param norm = 3.2464e-01, time/batch = 0.6715s	
537/33250 (epoch 0.808), train_loss = 2.30474204, grad/param norm = 3.4261e-01, time/batch = 0.6616s	
538/33250 (epoch 0.809), train_loss = 2.07987741, grad/param norm = 3.2764e-01, time/batch = 0.6607s	
539/33250 (epoch 0.811), train_loss = 2.33858510, grad/param norm = 4.4118e-01, time/batch = 0.6605s	
540/33250 (epoch 0.812), train_loss = 2.20594894, grad/param norm = 5.9834e-01, time/batch = 0.6728s	
541/33250 (epoch 0.814), train_loss = 2.24761670, grad/param norm = 3.8450e-01, time/batch = 0.6671s	
542/33250 (epoch 0.815), train_loss = 2.34134012, grad/param norm = 3.9185e-01, time/batch = 0.6735s	
543/33250 (epoch 0.817), train_loss = 2.28619832, grad/param norm = 3.2536e-01, time/batch = 0.6707s	
544/33250 (epoch 0.818), train_loss = 2.16293616, grad/param norm = 2.8885e-01, time/batch = 0.6735s	
545/33250 (epoch 0.820), train_loss = 2.18485001, grad/param norm = 3.9454e-01, time/batch = 0.6770s	
546/33250 (epoch 0.821), train_loss = 2.16314994, grad/param norm = 4.8112e-01, time/batch = 0.6843s	
547/33250 (epoch 0.823), train_loss = 2.40113064, grad/param norm = 4.4935e-01, time/batch = 0.6744s	
548/33250 (epoch 0.824), train_loss = 2.22390086, grad/param norm = 3.1142e-01, time/batch = 0.6733s	
549/33250 (epoch 0.826), train_loss = 2.18734342, grad/param norm = 3.4775e-01, time/batch = 0.6704s	
550/33250 (epoch 0.827), train_loss = 2.12504906, grad/param norm = 3.2979e-01, time/batch = 0.6731s	
551/33250 (epoch 0.829), train_loss = 2.24338096, grad/param norm = 3.1213e-01, time/batch = 0.6782s	
552/33250 (epoch 0.830), train_loss = 2.56227994, grad/param norm = 4.6750e-01, time/batch = 0.6721s	
553/33250 (epoch 0.832), train_loss = 2.23263214, grad/param norm = 4.2400e-01, time/batch = 0.6862s	
554/33250 (epoch 0.833), train_loss = 2.28521892, grad/param norm = 4.8351e-01, time/batch = 0.6808s	
555/33250 (epoch 0.835), train_loss = 2.32532860, grad/param norm = 5.6440e-01, time/batch = 0.6681s	
556/33250 (epoch 0.836), train_loss = 2.23217486, grad/param norm = 5.1905e-01, time/batch = 0.6572s	
557/33250 (epoch 0.838), train_loss = 2.14406767, grad/param norm = 4.4192e-01, time/batch = 0.6674s	
558/33250 (epoch 0.839), train_loss = 2.26738928, grad/param norm = 4.8141e-01, time/batch = 0.6629s	
559/33250 (epoch 0.841), train_loss = 2.17864221, grad/param norm = 4.0680e-01, time/batch = 0.6611s	
560/33250 (epoch 0.842), train_loss = 2.19530994, grad/param norm = 3.1043e-01, time/batch = 0.6554s	
561/33250 (epoch 0.844), train_loss = 2.37718079, grad/param norm = 3.1620e-01, time/batch = 0.6636s	
562/33250 (epoch 0.845), train_loss = 2.40987864, grad/param norm = 4.3524e-01, time/batch = 0.6708s	
563/33250 (epoch 0.847), train_loss = 2.26869551, grad/param norm = 3.9627e-01, time/batch = 0.6659s	
564/33250 (epoch 0.848), train_loss = 2.34039471, grad/param norm = 3.5145e-01, time/batch = 0.6590s	
565/33250 (epoch 0.850), train_loss = 2.29624419, grad/param norm = 3.3408e-01, time/batch = 0.6777s	
566/33250 (epoch 0.851), train_loss = 2.14482573, grad/param norm = 4.1068e-01, time/batch = 0.6780s	
567/33250 (epoch 0.853), train_loss = 2.27173822, grad/param norm = 4.7154e-01, time/batch = 0.6738s	
568/33250 (epoch 0.854), train_loss = 2.12006213, grad/param norm = 4.1493e-01, time/batch = 0.6741s	
569/33250 (epoch 0.856), train_loss = 2.19955111, grad/param norm = 3.5982e-01, time/batch = 0.6808s	
570/33250 (epoch 0.857), train_loss = 1.96384454, grad/param norm = 3.3710e-01, time/batch = 0.6788s	
571/33250 (epoch 0.859), train_loss = 2.08175332, grad/param norm = 4.2270e-01, time/batch = 0.6794s	
572/33250 (epoch 0.860), train_loss = 2.09148738, grad/param norm = 4.1453e-01, time/batch = 0.6991s	
573/33250 (epoch 0.862), train_loss = 2.16931460, grad/param norm = 3.3516e-01, time/batch = 0.6959s	
574/33250 (epoch 0.863), train_loss = 2.10883431, grad/param norm = 2.7185e-01, time/batch = 0.6873s	
575/33250 (epoch 0.865), train_loss = 2.22013674, grad/param norm = 3.6144e-01, time/batch = 0.6842s	
576/33250 (epoch 0.866), train_loss = 2.23995572, grad/param norm = 3.9466e-01, time/batch = 0.6816s	
577/33250 (epoch 0.868), train_loss = 2.57602188, grad/param norm = 4.2528e-01, time/batch = 0.6758s	
578/33250 (epoch 0.869), train_loss = 2.32920340, grad/param norm = 3.7662e-01, time/batch = 0.6631s	
579/33250 (epoch 0.871), train_loss = 1.93547272, grad/param norm = 4.7480e-01, time/batch = 0.6723s	
580/33250 (epoch 0.872), train_loss = 2.32798891, grad/param norm = 4.0751e-01, time/batch = 0.6730s	
581/33250 (epoch 0.874), train_loss = 2.25225004, grad/param norm = 4.0290e-01, time/batch = 0.6771s	
582/33250 (epoch 0.875), train_loss = 2.14160350, grad/param norm = 4.1090e-01, time/batch = 0.6683s	
583/33250 (epoch 0.877), train_loss = 2.19343020, grad/param norm = 3.5309e-01, time/batch = 0.6747s	
584/33250 (epoch 0.878), train_loss = 2.14122235, grad/param norm = 2.7369e-01, time/batch = 0.6734s	
585/33250 (epoch 0.880), train_loss = 2.37633603, grad/param norm = 3.1948e-01, time/batch = 0.6671s	
586/33250 (epoch 0.881), train_loss = 2.28192208, grad/param norm = 4.4211e-01, time/batch = 0.6759s	
587/33250 (epoch 0.883), train_loss = 2.29882788, grad/param norm = 4.9335e-01, time/batch = 0.6636s	
588/33250 (epoch 0.884), train_loss = 2.09939218, grad/param norm = 4.9184e-01, time/batch = 0.6725s	
589/33250 (epoch 0.886), train_loss = 2.13758233, grad/param norm = 3.7503e-01, time/batch = 0.6646s	
590/33250 (epoch 0.887), train_loss = 2.19477941, grad/param norm = 3.7802e-01, time/batch = 0.6553s	
591/33250 (epoch 0.889), train_loss = 2.00777170, grad/param norm = 3.3198e-01, time/batch = 0.6644s	
592/33250 (epoch 0.890), train_loss = 2.10442039, grad/param norm = 3.7334e-01, time/batch = 0.6653s	
593/33250 (epoch 0.892), train_loss = 2.28737138, grad/param norm = 3.7695e-01, time/batch = 0.6638s	
594/33250 (epoch 0.893), train_loss = 2.21049814, grad/param norm = 3.3172e-01, time/batch = 0.6662s	
595/33250 (epoch 0.895), train_loss = 2.26501666, grad/param norm = 3.8996e-01, time/batch = 0.6632s	
596/33250 (epoch 0.896), train_loss = 2.26643156, grad/param norm = 3.4112e-01, time/batch = 0.6609s	
597/33250 (epoch 0.898), train_loss = 2.19269867, grad/param norm = 3.1457e-01, time/batch = 0.6603s	
598/33250 (epoch 0.899), train_loss = 2.25435007, grad/param norm = 3.7057e-01, time/batch = 0.6621s	
599/33250 (epoch 0.901), train_loss = 2.08126481, grad/param norm = 3.2562e-01, time/batch = 0.6633s	
600/33250 (epoch 0.902), train_loss = 2.09881507, grad/param norm = 3.5538e-01, time/batch = 0.6804s	
601/33250 (epoch 0.904), train_loss = 2.21681112, grad/param norm = 4.6968e-01, time/batch = 0.6754s	
602/33250 (epoch 0.905), train_loss = 2.16079737, grad/param norm = 3.8990e-01, time/batch = 0.6695s	
603/33250 (epoch 0.907), train_loss = 2.21632210, grad/param norm = 4.1566e-01, time/batch = 0.6639s	
604/33250 (epoch 0.908), train_loss = 2.21380921, grad/param norm = 4.8939e-01, time/batch = 0.6588s	
605/33250 (epoch 0.910), train_loss = 2.32684699, grad/param norm = 4.8606e-01, time/batch = 0.6609s	
606/33250 (epoch 0.911), train_loss = 2.10206296, grad/param norm = 4.0216e-01, time/batch = 0.6755s	
607/33250 (epoch 0.913), train_loss = 2.10642506, grad/param norm = 3.3915e-01, time/batch = 0.6850s	
608/33250 (epoch 0.914), train_loss = 2.06069916, grad/param norm = 4.0502e-01, time/batch = 0.6944s	
609/33250 (epoch 0.916), train_loss = 2.08596806, grad/param norm = 4.1664e-01, time/batch = 0.6782s	
610/33250 (epoch 0.917), train_loss = 2.19637168, grad/param norm = 3.5770e-01, time/batch = 0.6962s	
611/33250 (epoch 0.919), train_loss = 2.25661412, grad/param norm = 3.6609e-01, time/batch = 0.6808s	
612/33250 (epoch 0.920), train_loss = 2.15581081, grad/param norm = 3.6727e-01, time/batch = 0.6691s	
613/33250 (epoch 0.922), train_loss = 2.18155920, grad/param norm = 3.7409e-01, time/batch = 0.6761s	
614/33250 (epoch 0.923), train_loss = 2.26029447, grad/param norm = 3.9722e-01, time/batch = 0.6770s	
615/33250 (epoch 0.925), train_loss = 2.09272947, grad/param norm = 3.6552e-01, time/batch = 0.6679s	
616/33250 (epoch 0.926), train_loss = 2.20399653, grad/param norm = 5.0566e-01, time/batch = 0.6609s	
617/33250 (epoch 0.928), train_loss = 2.31822618, grad/param norm = 6.1411e-01, time/batch = 0.6694s	
618/33250 (epoch 0.929), train_loss = 1.85883268, grad/param norm = 4.1532e-01, time/batch = 0.6637s	
619/33250 (epoch 0.931), train_loss = 2.12737142, grad/param norm = 3.3725e-01, time/batch = 0.6650s	
620/33250 (epoch 0.932), train_loss = 2.25164303, grad/param norm = 2.9378e-01, time/batch = 0.6661s	
621/33250 (epoch 0.934), train_loss = 2.10353844, grad/param norm = 2.8142e-01, time/batch = 0.6708s	
622/33250 (epoch 0.935), train_loss = 2.13549438, grad/param norm = 3.2093e-01, time/batch = 0.6852s	
623/33250 (epoch 0.937), train_loss = 2.13303972, grad/param norm = 3.1791e-01, time/batch = 0.6814s	
624/33250 (epoch 0.938), train_loss = 2.28563274, grad/param norm = 3.4458e-01, time/batch = 0.6683s	
625/33250 (epoch 0.940), train_loss = 2.19889017, grad/param norm = 3.8133e-01, time/batch = 0.6748s	
626/33250 (epoch 0.941), train_loss = 2.30091988, grad/param norm = 5.7907e-01, time/batch = 0.6663s	
627/33250 (epoch 0.943), train_loss = 2.25343878, grad/param norm = 4.4942e-01, time/batch = 0.6664s	
628/33250 (epoch 0.944), train_loss = 2.08443205, grad/param norm = 4.2161e-01, time/batch = 0.6724s	
629/33250 (epoch 0.946), train_loss = 2.37983278, grad/param norm = 3.6179e-01, time/batch = 0.6696s	
630/33250 (epoch 0.947), train_loss = 2.14634753, grad/param norm = 3.4629e-01, time/batch = 0.6802s	
631/33250 (epoch 0.949), train_loss = 2.40988741, grad/param norm = 3.6587e-01, time/batch = 0.6629s	
632/33250 (epoch 0.950), train_loss = 2.19022750, grad/param norm = 3.9037e-01, time/batch = 0.6650s	
633/33250 (epoch 0.952), train_loss = 2.27086580, grad/param norm = 3.9709e-01, time/batch = 0.6633s	
634/33250 (epoch 0.953), train_loss = 2.16664584, grad/param norm = 4.0674e-01, time/batch = 0.6642s	
635/33250 (epoch 0.955), train_loss = 2.29751513, grad/param norm = 3.9376e-01, time/batch = 0.6660s	
636/33250 (epoch 0.956), train_loss = 2.34375610, grad/param norm = 3.7316e-01, time/batch = 0.6737s	
637/33250 (epoch 0.958), train_loss = 2.16864660, grad/param norm = 3.4767e-01, time/batch = 0.6644s	
638/33250 (epoch 0.959), train_loss = 2.07501810, grad/param norm = 3.7533e-01, time/batch = 0.6874s	
639/33250 (epoch 0.961), train_loss = 2.16792375, grad/param norm = 4.1043e-01, time/batch = 0.6826s	
640/33250 (epoch 0.962), train_loss = 2.30038713, grad/param norm = 4.6304e-01, time/batch = 0.6753s	
641/33250 (epoch 0.964), train_loss = 2.19960334, grad/param norm = 4.0745e-01, time/batch = 0.6712s	
642/33250 (epoch 0.965), train_loss = 2.27499237, grad/param norm = 3.5695e-01, time/batch = 0.6728s	
643/33250 (epoch 0.967), train_loss = 2.24042021, grad/param norm = 3.0357e-01, time/batch = 0.6725s	
644/33250 (epoch 0.968), train_loss = 2.18573109, grad/param norm = 2.9666e-01, time/batch = 0.6643s	
645/33250 (epoch 0.970), train_loss = 2.37051834, grad/param norm = 4.2361e-01, time/batch = 0.6709s	
646/33250 (epoch 0.971), train_loss = 2.32987983, grad/param norm = 3.6346e-01, time/batch = 0.6601s	
647/33250 (epoch 0.973), train_loss = 2.11383965, grad/param norm = 3.0272e-01, time/batch = 0.6644s	
648/33250 (epoch 0.974), train_loss = 2.18786772, grad/param norm = 3.2603e-01, time/batch = 0.6636s	
649/33250 (epoch 0.976), train_loss = 2.05953254, grad/param norm = 3.3184e-01, time/batch = 0.6605s	
650/33250 (epoch 0.977), train_loss = 1.96010944, grad/param norm = 3.7347e-01, time/batch = 0.6613s	
651/33250 (epoch 0.979), train_loss = 2.07915308, grad/param norm = 4.3101e-01, time/batch = 0.6699s	
652/33250 (epoch 0.980), train_loss = 2.10943499, grad/param norm = 5.1837e-01, time/batch = 0.6665s	
653/33250 (epoch 0.982), train_loss = 2.07044183, grad/param norm = 3.8483e-01, time/batch = 0.6659s	
654/33250 (epoch 0.983), train_loss = 2.25602200, grad/param norm = 3.3883e-01, time/batch = 0.6685s	
655/33250 (epoch 0.985), train_loss = 2.06108308, grad/param norm = 3.0536e-01, time/batch = 0.6651s	
656/33250 (epoch 0.986), train_loss = 2.37529220, grad/param norm = 3.1208e-01, time/batch = 0.6615s	
657/33250 (epoch 0.988), train_loss = 2.09095106, grad/param norm = 3.4860e-01, time/batch = 0.6635s	
658/33250 (epoch 0.989), train_loss = 2.14493906, grad/param norm = 3.1509e-01, time/batch = 0.6696s	
659/33250 (epoch 0.991), train_loss = 2.17145343, grad/param norm = 3.4678e-01, time/batch = 0.6629s	
660/33250 (epoch 0.992), train_loss = 2.12465914, grad/param norm = 3.7555e-01, time/batch = 0.6566s	
661/33250 (epoch 0.994), train_loss = 2.02574672, grad/param norm = 4.0253e-01, time/batch = 0.6688s	
662/33250 (epoch 0.995), train_loss = 2.14365378, grad/param norm = 3.4439e-01, time/batch = 0.6657s	
663/33250 (epoch 0.997), train_loss = 1.87612587, grad/param norm = 3.3588e-01, time/batch = 0.6657s	
664/33250 (epoch 0.998), train_loss = 2.12523459, grad/param norm = 3.3487e-01, time/batch = 0.6676s	
665/33250 (epoch 1.000), train_loss = 2.16120003, grad/param norm = 3.1388e-01, time/batch = 0.6665s	
666/33250 (epoch 1.002), train_loss = 2.22318722, grad/param norm = 3.1036e-01, time/batch = 0.6669s	
667/33250 (epoch 1.003), train_loss = 2.15272357, grad/param norm = 3.5778e-01, time/batch = 0.6586s	
668/33250 (epoch 1.005), train_loss = 2.07062183, grad/param norm = 3.5768e-01, time/batch = 0.6639s	
669/33250 (epoch 1.006), train_loss = 1.95773756, grad/param norm = 3.1888e-01, time/batch = 0.6641s	
670/33250 (epoch 1.008), train_loss = 2.20486590, grad/param norm = 3.5040e-01, time/batch = 0.6631s	
671/33250 (epoch 1.009), train_loss = 2.19081535, grad/param norm = 3.1056e-01, time/batch = 0.6679s	
672/33250 (epoch 1.011), train_loss = 2.17628588, grad/param norm = 3.2711e-01, time/batch = 0.6619s	
673/33250 (epoch 1.012), train_loss = 2.30453347, grad/param norm = 3.7405e-01, time/batch = 0.6625s	
674/33250 (epoch 1.014), train_loss = 2.05916533, grad/param norm = 3.0733e-01, time/batch = 0.6654s	
675/33250 (epoch 1.015), train_loss = 2.20434326, grad/param norm = 3.5518e-01, time/batch = 0.6686s	
676/33250 (epoch 1.017), train_loss = 2.16361617, grad/param norm = 3.7943e-01, time/batch = 0.6609s	
677/33250 (epoch 1.018), train_loss = 2.09739464, grad/param norm = 3.8993e-01, time/batch = 0.6581s	
678/33250 (epoch 1.020), train_loss = 1.99949696, grad/param norm = 3.3709e-01, time/batch = 0.6599s	
679/33250 (epoch 1.021), train_loss = 2.15545420, grad/param norm = 3.0483e-01, time/batch = 0.6626s	
680/33250 (epoch 1.023), train_loss = 2.06708450, grad/param norm = 3.8355e-01, time/batch = 0.6628s	
681/33250 (epoch 1.024), train_loss = 2.17095270, grad/param norm = 4.4041e-01, time/batch = 0.6664s	
682/33250 (epoch 1.026), train_loss = 2.05198130, grad/param norm = 4.0912e-01, time/batch = 0.6616s	
683/33250 (epoch 1.027), train_loss = 2.13940756, grad/param norm = 4.6684e-01, time/batch = 0.6641s	
684/33250 (epoch 1.029), train_loss = 2.16354346, grad/param norm = 4.5559e-01, time/batch = 0.6628s	
685/33250 (epoch 1.030), train_loss = 2.23724719, grad/param norm = 3.9010e-01, time/batch = 0.6763s	
686/33250 (epoch 1.032), train_loss = 2.27615828, grad/param norm = 3.7732e-01, time/batch = 0.6624s	
687/33250 (epoch 1.033), train_loss = 2.10227772, grad/param norm = 3.8780e-01, time/batch = 0.6634s	
688/33250 (epoch 1.035), train_loss = 2.01508514, grad/param norm = 3.1510e-01, time/batch = 0.6620s	
689/33250 (epoch 1.036), train_loss = 2.04772040, grad/param norm = 2.9147e-01, time/batch = 0.6575s	
690/33250 (epoch 1.038), train_loss = 1.98975632, grad/param norm = 3.5827e-01, time/batch = 0.6629s	
691/33250 (epoch 1.039), train_loss = 2.03739277, grad/param norm = 4.2688e-01, time/batch = 0.6685s	
692/33250 (epoch 1.041), train_loss = 2.28820962, grad/param norm = 3.3175e-01, time/batch = 0.6658s	
693/33250 (epoch 1.042), train_loss = 1.91869767, grad/param norm = 3.0879e-01, time/batch = 0.6697s	
694/33250 (epoch 1.044), train_loss = 2.28043161, grad/param norm = 3.0055e-01, time/batch = 0.6680s	
695/33250 (epoch 1.045), train_loss = 2.11606465, grad/param norm = 2.9396e-01, time/batch = 0.6630s	
696/33250 (epoch 1.047), train_loss = 2.27491775, grad/param norm = 2.8896e-01, time/batch = 0.6841s	
697/33250 (epoch 1.048), train_loss = 2.24839256, grad/param norm = 3.2324e-01, time/batch = 0.6865s	
698/33250 (epoch 1.050), train_loss = 2.17141910, grad/param norm = 3.6622e-01, time/batch = 0.6843s	
699/33250 (epoch 1.051), train_loss = 2.06272347, grad/param norm = 3.8798e-01, time/batch = 0.6671s	
700/33250 (epoch 1.053), train_loss = 2.24529722, grad/param norm = 3.6376e-01, time/batch = 0.6879s	
701/33250 (epoch 1.054), train_loss = 1.94860363, grad/param norm = 3.7391e-01, time/batch = 0.6710s	
702/33250 (epoch 1.056), train_loss = 2.16269460, grad/param norm = 4.5345e-01, time/batch = 0.6700s	
703/33250 (epoch 1.057), train_loss = 2.11908389, grad/param norm = 4.0069e-01, time/batch = 0.6930s	
704/33250 (epoch 1.059), train_loss = 2.03819685, grad/param norm = 3.6911e-01, time/batch = 0.6949s	
705/33250 (epoch 1.060), train_loss = 2.20806290, grad/param norm = 4.0419e-01, time/batch = 0.6789s	
706/33250 (epoch 1.062), train_loss = 2.20794116, grad/param norm = 3.4740e-01, time/batch = 0.6649s	
707/33250 (epoch 1.063), train_loss = 2.21405839, grad/param norm = 2.9772e-01, time/batch = 0.6623s	
708/33250 (epoch 1.065), train_loss = 2.20226629, grad/param norm = 2.9062e-01, time/batch = 0.6608s	
709/33250 (epoch 1.066), train_loss = 2.22563360, grad/param norm = 2.7638e-01, time/batch = 0.6751s	
710/33250 (epoch 1.068), train_loss = 2.05865675, grad/param norm = 2.7661e-01, time/batch = 0.6759s	
711/33250 (epoch 1.069), train_loss = 2.10111122, grad/param norm = 2.8939e-01, time/batch = 0.6729s	
712/33250 (epoch 1.071), train_loss = 2.04622560, grad/param norm = 3.3810e-01, time/batch = 0.6595s	
713/33250 (epoch 1.072), train_loss = 2.05974511, grad/param norm = 3.1370e-01, time/batch = 0.6602s	
714/33250 (epoch 1.074), train_loss = 2.06062721, grad/param norm = 2.9908e-01, time/batch = 0.6593s	
715/33250 (epoch 1.075), train_loss = 2.09429913, grad/param norm = 3.2628e-01, time/batch = 0.6588s	
716/33250 (epoch 1.077), train_loss = 2.20913142, grad/param norm = 3.4222e-01, time/batch = 0.6670s	
717/33250 (epoch 1.078), train_loss = 2.01997613, grad/param norm = 3.0086e-01, time/batch = 0.6623s	
718/33250 (epoch 1.080), train_loss = 2.13872968, grad/param norm = 3.0364e-01, time/batch = 0.6610s	
719/33250 (epoch 1.081), train_loss = 2.20369739, grad/param norm = 3.5124e-01, time/batch = 0.6603s	
720/33250 (epoch 1.083), train_loss = 2.17539588, grad/param norm = 4.2053e-01, time/batch = 0.6626s	
721/33250 (epoch 1.084), train_loss = 2.11373388, grad/param norm = 4.3065e-01, time/batch = 0.6579s	
722/33250 (epoch 1.086), train_loss = 2.10059914, grad/param norm = 3.3319e-01, time/batch = 0.6636s	
723/33250 (epoch 1.087), train_loss = 1.89837809, grad/param norm = 3.3365e-01, time/batch = 0.6585s	
724/33250 (epoch 1.089), train_loss = 2.13885597, grad/param norm = 3.5610e-01, time/batch = 0.6595s	
725/33250 (epoch 1.090), train_loss = 2.12091392, grad/param norm = 3.8828e-01, time/batch = 0.6605s	
726/33250 (epoch 1.092), train_loss = 2.01247316, grad/param norm = 3.9640e-01, time/batch = 0.6572s	
727/33250 (epoch 1.093), train_loss = 2.00770736, grad/param norm = 4.5534e-01, time/batch = 0.6610s	
728/33250 (epoch 1.095), train_loss = 2.18279543, grad/param norm = 4.1050e-01, time/batch = 0.6593s	
729/33250 (epoch 1.096), train_loss = 2.05795679, grad/param norm = 4.3552e-01, time/batch = 0.6605s	
730/33250 (epoch 1.098), train_loss = 1.96788524, grad/param norm = 3.9220e-01, time/batch = 0.6595s	
731/33250 (epoch 1.099), train_loss = 1.98372564, grad/param norm = 3.7276e-01, time/batch = 0.6611s	
732/33250 (epoch 1.101), train_loss = 2.16355645, grad/param norm = 3.5137e-01, time/batch = 0.6661s	
733/33250 (epoch 1.102), train_loss = 1.93944030, grad/param norm = 2.8683e-01, time/batch = 0.6625s	
734/33250 (epoch 1.104), train_loss = 1.88627248, grad/param norm = 2.6180e-01, time/batch = 0.6656s	
735/33250 (epoch 1.105), train_loss = 2.05185936, grad/param norm = 2.7271e-01, time/batch = 0.6624s	
736/33250 (epoch 1.107), train_loss = 1.82910938, grad/param norm = 2.9510e-01, time/batch = 0.6766s	
737/33250 (epoch 1.108), train_loss = 2.10559287, grad/param norm = 3.5050e-01, time/batch = 0.6683s	
738/33250 (epoch 1.110), train_loss = 2.02375034, grad/param norm = 3.3038e-01, time/batch = 0.6630s	
739/33250 (epoch 1.111), train_loss = 1.93618585, grad/param norm = 3.1386e-01, time/batch = 0.6657s	
740/33250 (epoch 1.113), train_loss = 2.04438729, grad/param norm = 3.6551e-01, time/batch = 0.6600s	
741/33250 (epoch 1.114), train_loss = 2.10563758, grad/param norm = 4.0278e-01, time/batch = 0.6762s	
742/33250 (epoch 1.116), train_loss = 2.15751192, grad/param norm = 4.6349e-01, time/batch = 0.6640s	
743/33250 (epoch 1.117), train_loss = 2.10220371, grad/param norm = 4.4836e-01, time/batch = 0.6573s	
744/33250 (epoch 1.119), train_loss = 2.02022251, grad/param norm = 3.6338e-01, time/batch = 0.6546s	
745/33250 (epoch 1.120), train_loss = 1.86583805, grad/param norm = 3.8110e-01, time/batch = 0.6591s	
746/33250 (epoch 1.122), train_loss = 2.06246141, grad/param norm = 2.6080e-01, time/batch = 0.6583s	
747/33250 (epoch 1.123), train_loss = 2.01383074, grad/param norm = 2.5188e-01, time/batch = 0.6570s	
748/33250 (epoch 1.125), train_loss = 1.94589222, grad/param norm = 3.1723e-01, time/batch = 0.6566s	
749/33250 (epoch 1.126), train_loss = 2.10707036, grad/param norm = 3.7541e-01, time/batch = 0.6637s	
750/33250 (epoch 1.128), train_loss = 1.90550054, grad/param norm = 3.4224e-01, time/batch = 0.6602s	
751/33250 (epoch 1.129), train_loss = 2.04086408, grad/param norm = 3.8557e-01, time/batch = 0.6579s	
752/33250 (epoch 1.131), train_loss = 2.01145951, grad/param norm = 3.3976e-01, time/batch = 0.6574s	
753/33250 (epoch 1.132), train_loss = 1.98102602, grad/param norm = 3.0621e-01, time/batch = 0.6594s	
754/33250 (epoch 1.134), train_loss = 2.17089584, grad/param norm = 2.8477e-01, time/batch = 0.6557s	
755/33250 (epoch 1.135), train_loss = 2.12613071, grad/param norm = 3.2369e-01, time/batch = 0.6566s	
756/33250 (epoch 1.137), train_loss = 1.89003932, grad/param norm = 3.7580e-01, time/batch = 0.6582s	
757/33250 (epoch 1.138), train_loss = 1.96958688, grad/param norm = 3.2787e-01, time/batch = 0.6550s	
758/33250 (epoch 1.140), train_loss = 1.93451384, grad/param norm = 3.1156e-01, time/batch = 0.6562s	
759/33250 (epoch 1.141), train_loss = 2.42382094, grad/param norm = 3.7796e-01, time/batch = 0.6643s	
760/33250 (epoch 1.143), train_loss = 1.90198964, grad/param norm = 3.8291e-01, time/batch = 0.6606s	
761/33250 (epoch 1.144), train_loss = 1.92783548, grad/param norm = 3.4635e-01, time/batch = 0.6566s	
762/33250 (epoch 1.146), train_loss = 1.87675154, grad/param norm = 3.1625e-01, time/batch = 0.6618s	
763/33250 (epoch 1.147), train_loss = 1.98239375, grad/param norm = 3.4456e-01, time/batch = 0.6602s	
764/33250 (epoch 1.149), train_loss = 2.10737475, grad/param norm = 3.3926e-01, time/batch = 0.6654s	
765/33250 (epoch 1.150), train_loss = 1.86401625, grad/param norm = 3.5738e-01, time/batch = 0.6865s	
766/33250 (epoch 1.152), train_loss = 1.86401311, grad/param norm = 2.8179e-01, time/batch = 0.6803s	
767/33250 (epoch 1.153), train_loss = 1.94754270, grad/param norm = 3.1351e-01, time/batch = 0.6717s	
768/33250 (epoch 1.155), train_loss = 1.99782697, grad/param norm = 3.0189e-01, time/batch = 0.6709s	
769/33250 (epoch 1.156), train_loss = 1.97656055, grad/param norm = 3.7035e-01, time/batch = 0.6665s	
770/33250 (epoch 1.158), train_loss = 2.33158198, grad/param norm = 3.6985e-01, time/batch = 0.6605s	
771/33250 (epoch 1.159), train_loss = 2.03343125, grad/param norm = 3.6541e-01, time/batch = 0.6642s	
772/33250 (epoch 1.161), train_loss = 2.05927020, grad/param norm = 3.0913e-01, time/batch = 0.6593s	
773/33250 (epoch 1.162), train_loss = 1.97790926, grad/param norm = 3.6358e-01, time/batch = 0.6579s	
774/33250 (epoch 1.164), train_loss = 2.09192014, grad/param norm = 3.4408e-01, time/batch = 0.6775s	
775/33250 (epoch 1.165), train_loss = 2.07478105, grad/param norm = 3.3873e-01, time/batch = 0.6576s	
776/33250 (epoch 1.167), train_loss = 2.04984032, grad/param norm = 3.4356e-01, time/batch = 0.6565s	
777/33250 (epoch 1.168), train_loss = 1.72375358, grad/param norm = 2.8507e-01, time/batch = 0.6532s	
778/33250 (epoch 1.170), train_loss = 1.99110586, grad/param norm = 2.8743e-01, time/batch = 0.6576s	
779/33250 (epoch 1.171), train_loss = 1.83288061, grad/param norm = 2.6877e-01, time/batch = 0.6571s	
780/33250 (epoch 1.173), train_loss = 1.86326177, grad/param norm = 4.2003e-01, time/batch = 0.6538s	
781/33250 (epoch 1.174), train_loss = 2.01193431, grad/param norm = 5.3259e-01, time/batch = 0.6617s	
782/33250 (epoch 1.176), train_loss = 2.14038862, grad/param norm = 5.0289e-01, time/batch = 0.6713s	
783/33250 (epoch 1.177), train_loss = 1.78618319, grad/param norm = 3.4000e-01, time/batch = 0.6586s	
784/33250 (epoch 1.179), train_loss = 1.97873603, grad/param norm = 3.0905e-01, time/batch = 0.6781s	
785/33250 (epoch 1.180), train_loss = 1.87246052, grad/param norm = 3.1597e-01, time/batch = 0.6829s	
786/33250 (epoch 1.182), train_loss = 1.96889767, grad/param norm = 3.7913e-01, time/batch = 0.6859s	
787/33250 (epoch 1.183), train_loss = 2.17792454, grad/param norm = 3.0733e-01, time/batch = 0.6901s	
788/33250 (epoch 1.185), train_loss = 2.04799138, grad/param norm = 3.7467e-01, time/batch = 0.6870s	
789/33250 (epoch 1.186), train_loss = 1.89424628, grad/param norm = 3.6995e-01, time/batch = 0.6857s	
790/33250 (epoch 1.188), train_loss = 2.16492123, grad/param norm = 3.0614e-01, time/batch = 0.6837s	
791/33250 (epoch 1.189), train_loss = 1.83966623, grad/param norm = 2.9288e-01, time/batch = 0.6887s	
792/33250 (epoch 1.191), train_loss = 1.91037851, grad/param norm = 2.8553e-01, time/batch = 0.6676s	
793/33250 (epoch 1.192), train_loss = 1.89323398, grad/param norm = 4.5191e-01, time/batch = 0.6650s	
794/33250 (epoch 1.194), train_loss = 1.77132665, grad/param norm = 3.6009e-01, time/batch = 0.6604s	
795/33250 (epoch 1.195), train_loss = 2.12491058, grad/param norm = 3.0111e-01, time/batch = 0.6708s	
796/33250 (epoch 1.197), train_loss = 2.01065007, grad/param norm = 3.3520e-01, time/batch = 0.6573s	
797/33250 (epoch 1.198), train_loss = 2.09281491, grad/param norm = 3.2494e-01, time/batch = 0.6603s	
798/33250 (epoch 1.200), train_loss = 1.96759686, grad/param norm = 3.0301e-01, time/batch = 0.6567s	
799/33250 (epoch 1.202), train_loss = 2.01438621, grad/param norm = 3.9231e-01, time/batch = 0.6614s	
800/33250 (epoch 1.203), train_loss = 2.03616449, grad/param norm = 3.0475e-01, time/batch = 0.6575s	
801/33250 (epoch 1.205), train_loss = 2.04290650, grad/param norm = 3.5635e-01, time/batch = 0.6946s	
802/33250 (epoch 1.206), train_loss = 1.96265046, grad/param norm = 3.8340e-01, time/batch = 0.6847s	
803/33250 (epoch 1.208), train_loss = 2.23043669, grad/param norm = 3.1292e-01, time/batch = 0.6822s	
804/33250 (epoch 1.209), train_loss = 1.87192836, grad/param norm = 3.3761e-01, time/batch = 0.6731s	
805/33250 (epoch 1.211), train_loss = 2.14437272, grad/param norm = 2.9357e-01, time/batch = 0.6659s	
806/33250 (epoch 1.212), train_loss = 2.11589556, grad/param norm = 3.5994e-01, time/batch = 0.6621s	
807/33250 (epoch 1.214), train_loss = 1.93536003, grad/param norm = 3.4389e-01, time/batch = 0.6586s	
808/33250 (epoch 1.215), train_loss = 2.37128377, grad/param norm = 3.3611e-01, time/batch = 0.6567s	
809/33250 (epoch 1.217), train_loss = 2.06236178, grad/param norm = 2.9352e-01, time/batch = 0.6661s	
810/33250 (epoch 1.218), train_loss = 2.08593801, grad/param norm = 3.3844e-01, time/batch = 0.6650s	
811/33250 (epoch 1.220), train_loss = 2.12176702, grad/param norm = 3.4966e-01, time/batch = 0.6721s	
812/33250 (epoch 1.221), train_loss = 2.28508293, grad/param norm = 3.1731e-01, time/batch = 0.6704s	
813/33250 (epoch 1.223), train_loss = 2.10674681, grad/param norm = 3.2803e-01, time/batch = 0.6593s	
814/33250 (epoch 1.224), train_loss = 2.12920597, grad/param norm = 3.5964e-01, time/batch = 0.6593s	
815/33250 (epoch 1.226), train_loss = 2.07690915, grad/param norm = 2.9318e-01, time/batch = 0.6588s	
816/33250 (epoch 1.227), train_loss = 2.13670086, grad/param norm = 3.2267e-01, time/batch = 0.6636s	
817/33250 (epoch 1.229), train_loss = 1.95447599, grad/param norm = 3.0012e-01, time/batch = 0.6616s	
818/33250 (epoch 1.230), train_loss = 2.05370507, grad/param norm = 3.1600e-01, time/batch = 0.6627s	
819/33250 (epoch 1.232), train_loss = 1.87221078, grad/param norm = 3.1613e-01, time/batch = 0.6861s	
820/33250 (epoch 1.233), train_loss = 1.95975652, grad/param norm = 2.9330e-01, time/batch = 0.6871s	
821/33250 (epoch 1.235), train_loss = 2.06972037, grad/param norm = 3.3987e-01, time/batch = 0.7018s	
822/33250 (epoch 1.236), train_loss = 1.89679379, grad/param norm = 3.7335e-01, time/batch = 0.6994s	
823/33250 (epoch 1.238), train_loss = 1.90461123, grad/param norm = 3.3166e-01, time/batch = 0.6951s	
824/33250 (epoch 1.239), train_loss = 2.26652860, grad/param norm = 3.5031e-01, time/batch = 0.6851s	
825/33250 (epoch 1.241), train_loss = 2.07305635, grad/param norm = 3.3856e-01, time/batch = 0.6829s	
826/33250 (epoch 1.242), train_loss = 1.92218079, grad/param norm = 3.7380e-01, time/batch = 0.6838s	
827/33250 (epoch 1.244), train_loss = 2.02620797, grad/param norm = 3.2664e-01, time/batch = 0.6836s	
828/33250 (epoch 1.245), train_loss = 1.96044451, grad/param norm = 2.9594e-01, time/batch = 0.6530s	
829/33250 (epoch 1.247), train_loss = 2.17814316, grad/param norm = 2.7436e-01, time/batch = 0.6491s	
830/33250 (epoch 1.248), train_loss = 2.24607966, grad/param norm = 2.4640e-01, time/batch = 0.6539s	
831/33250 (epoch 1.250), train_loss = 1.91975236, grad/param norm = 2.6687e-01, time/batch = 0.6601s	
832/33250 (epoch 1.251), train_loss = 2.09361787, grad/param norm = 4.1184e-01, time/batch = 0.6549s	
833/33250 (epoch 1.253), train_loss = 1.86361074, grad/param norm = 4.0840e-01, time/batch = 0.6532s	
834/33250 (epoch 1.254), train_loss = 1.95759101, grad/param norm = 4.2542e-01, time/batch = 0.6526s	
835/33250 (epoch 1.256), train_loss = 2.19029280, grad/param norm = 3.8510e-01, time/batch = 0.6614s	
836/33250 (epoch 1.257), train_loss = 2.20226167, grad/param norm = 3.1356e-01, time/batch = 0.6516s	
837/33250 (epoch 1.259), train_loss = 2.23314360, grad/param norm = 3.5549e-01, time/batch = 0.6561s	
838/33250 (epoch 1.260), train_loss = 1.95998975, grad/param norm = 3.7529e-01, time/batch = 0.6576s	
839/33250 (epoch 1.262), train_loss = 2.02849978, grad/param norm = 2.4806e-01, time/batch = 0.6492s	
840/33250 (epoch 1.263), train_loss = 1.91744750, grad/param norm = 2.5063e-01, time/batch = 0.6517s	
841/33250 (epoch 1.265), train_loss = 1.99822101, grad/param norm = 3.3518e-01, time/batch = 0.6490s	
842/33250 (epoch 1.266), train_loss = 1.98454483, grad/param norm = 3.1653e-01, time/batch = 0.6522s	
843/33250 (epoch 1.268), train_loss = 1.91361589, grad/param norm = 2.9830e-01, time/batch = 0.6524s	
844/33250 (epoch 1.269), train_loss = 1.70063478, grad/param norm = 2.8428e-01, time/batch = 0.6483s	
845/33250 (epoch 1.271), train_loss = 1.98086066, grad/param norm = 2.4370e-01, time/batch = 0.6574s	
846/33250 (epoch 1.272), train_loss = 1.61129325, grad/param norm = 2.1914e-01, time/batch = 0.6539s	
847/33250 (epoch 1.274), train_loss = 1.70920690, grad/param norm = 2.6539e-01, time/batch = 0.6535s	
848/33250 (epoch 1.275), train_loss = 1.86512722, grad/param norm = 3.0416e-01, time/batch = 0.6502s	
849/33250 (epoch 1.277), train_loss = 1.74476111, grad/param norm = 3.0679e-01, time/batch = 0.6517s	
850/33250 (epoch 1.278), train_loss = 1.73649937, grad/param norm = 2.7462e-01, time/batch = 0.6592s	
851/33250 (epoch 1.280), train_loss = 1.76684455, grad/param norm = 2.9452e-01, time/batch = 0.6578s	
852/33250 (epoch 1.281), train_loss = 1.89127494, grad/param norm = 3.2957e-01, time/batch = 0.6572s	
853/33250 (epoch 1.283), train_loss = 1.91006800, grad/param norm = 3.2466e-01, time/batch = 0.6522s	
854/33250 (epoch 1.284), train_loss = 1.94932960, grad/param norm = 3.0102e-01, time/batch = 0.6525s	
855/33250 (epoch 1.286), train_loss = 2.01079720, grad/param norm = 3.4349e-01, time/batch = 0.6533s	
856/33250 (epoch 1.287), train_loss = 1.85825979, grad/param norm = 3.2107e-01, time/batch = 0.6477s	
857/33250 (epoch 1.289), train_loss = 1.85435202, grad/param norm = 3.4240e-01, time/batch = 0.6537s	
858/33250 (epoch 1.290), train_loss = 1.82699026, grad/param norm = 3.3625e-01, time/batch = 0.6490s	
859/33250 (epoch 1.292), train_loss = 1.95173375, grad/param norm = 3.2875e-01, time/batch = 0.6499s	
860/33250 (epoch 1.293), train_loss = 2.07522413, grad/param norm = 3.7620e-01, time/batch = 0.6545s	
861/33250 (epoch 1.295), train_loss = 1.92326977, grad/param norm = 3.4406e-01, time/batch = 0.6497s	
862/33250 (epoch 1.296), train_loss = 1.87044568, grad/param norm = 2.7992e-01, time/batch = 0.6471s	
863/33250 (epoch 1.298), train_loss = 1.69465121, grad/param norm = 2.7452e-01, time/batch = 0.6506s	
864/33250 (epoch 1.299), train_loss = 1.67373743, grad/param norm = 2.6339e-01, time/batch = 0.6527s	
865/33250 (epoch 1.301), train_loss = 1.96248888, grad/param norm = 2.7014e-01, time/batch = 0.6508s	
866/33250 (epoch 1.302), train_loss = 1.85563293, grad/param norm = 3.0783e-01, time/batch = 0.6503s	
867/33250 (epoch 1.304), train_loss = 1.81261530, grad/param norm = 3.0760e-01, time/batch = 0.6400s	
868/33250 (epoch 1.305), train_loss = 1.79628610, grad/param norm = 2.7840e-01, time/batch = 0.6525s	
869/33250 (epoch 1.307), train_loss = 2.02151081, grad/param norm = 2.8513e-01, time/batch = 0.6478s	
870/33250 (epoch 1.308), train_loss = 2.04532718, grad/param norm = 3.0494e-01, time/batch = 0.6452s	
871/33250 (epoch 1.310), train_loss = 1.92499050, grad/param norm = 3.3118e-01, time/batch = 0.6534s	
872/33250 (epoch 1.311), train_loss = 2.00522197, grad/param norm = 3.3110e-01, time/batch = 0.6509s	
873/33250 (epoch 1.313), train_loss = 1.97850380, grad/param norm = 4.1732e-01, time/batch = 0.6515s	
874/33250 (epoch 1.314), train_loss = 1.91653238, grad/param norm = 3.1862e-01, time/batch = 0.6516s	
875/33250 (epoch 1.316), train_loss = 2.10550673, grad/param norm = 2.7333e-01, time/batch = 0.6553s	
876/33250 (epoch 1.317), train_loss = 1.83324655, grad/param norm = 2.8852e-01, time/batch = 0.6714s	
877/33250 (epoch 1.319), train_loss = 2.01694095, grad/param norm = 3.3187e-01, time/batch = 0.6767s	
878/33250 (epoch 1.320), train_loss = 2.13997785, grad/param norm = 3.4543e-01, time/batch = 0.6740s	
879/33250 (epoch 1.322), train_loss = 2.11121152, grad/param norm = 3.8213e-01, time/batch = 0.6715s	
880/33250 (epoch 1.323), train_loss = 2.16108807, grad/param norm = 3.8999e-01, time/batch = 0.6834s	
881/33250 (epoch 1.325), train_loss = 1.92627595, grad/param norm = 3.2698e-01, time/batch = 0.6721s	
882/33250 (epoch 1.326), train_loss = 2.04391900, grad/param norm = 3.0315e-01, time/batch = 0.6687s	
883/33250 (epoch 1.328), train_loss = 1.91565676, grad/param norm = 2.9126e-01, time/batch = 0.6722s	
884/33250 (epoch 1.329), train_loss = 2.04564844, grad/param norm = 2.8016e-01, time/batch = 0.6617s	
885/33250 (epoch 1.331), train_loss = 1.79153118, grad/param norm = 3.1752e-01, time/batch = 0.6549s	
886/33250 (epoch 1.332), train_loss = 1.86742641, grad/param norm = 3.3016e-01, time/batch = 0.6538s	
887/33250 (epoch 1.334), train_loss = 2.02518217, grad/param norm = 3.0573e-01, time/batch = 0.6750s	
888/33250 (epoch 1.335), train_loss = 1.70358216, grad/param norm = 3.3118e-01, time/batch = 0.6748s	
889/33250 (epoch 1.337), train_loss = 1.95380836, grad/param norm = 3.4496e-01, time/batch = 0.6679s	
890/33250 (epoch 1.338), train_loss = 1.98560324, grad/param norm = 2.7320e-01, time/batch = 0.6520s	
891/33250 (epoch 1.340), train_loss = 1.98118691, grad/param norm = 2.5833e-01, time/batch = 0.6550s	
892/33250 (epoch 1.341), train_loss = 1.97340637, grad/param norm = 3.1952e-01, time/batch = 0.6777s	
893/33250 (epoch 1.343), train_loss = 2.08964247, grad/param norm = 4.2864e-01, time/batch = 0.6740s	
894/33250 (epoch 1.344), train_loss = 1.93092595, grad/param norm = 4.2406e-01, time/batch = 0.6758s	
895/33250 (epoch 1.346), train_loss = 1.66278594, grad/param norm = 2.9410e-01, time/batch = 0.6640s	
896/33250 (epoch 1.347), train_loss = 2.24993020, grad/param norm = 3.0445e-01, time/batch = 0.6659s	
897/33250 (epoch 1.349), train_loss = 2.00569055, grad/param norm = 3.5594e-01, time/batch = 0.6518s	
898/33250 (epoch 1.350), train_loss = 1.93459973, grad/param norm = 3.2941e-01, time/batch = 0.6525s	
899/33250 (epoch 1.352), train_loss = 1.83268867, grad/param norm = 3.1074e-01, time/batch = 0.6529s	
900/33250 (epoch 1.353), train_loss = 1.89551676, grad/param norm = 3.0564e-01, time/batch = 0.6498s	
901/33250 (epoch 1.355), train_loss = 1.80770577, grad/param norm = 3.2808e-01, time/batch = 0.6525s	
902/33250 (epoch 1.356), train_loss = 1.79420553, grad/param norm = 2.8635e-01, time/batch = 0.6645s	
903/33250 (epoch 1.358), train_loss = 1.83295383, grad/param norm = 2.9869e-01, time/batch = 0.6647s	
904/33250 (epoch 1.359), train_loss = 1.73917989, grad/param norm = 2.8950e-01, time/batch = 0.6607s	
905/33250 (epoch 1.361), train_loss = 2.15202372, grad/param norm = 2.8490e-01, time/batch = 0.6650s	
906/33250 (epoch 1.362), train_loss = 1.86749255, grad/param norm = 3.3172e-01, time/batch = 0.6544s	
907/33250 (epoch 1.364), train_loss = 2.08163138, grad/param norm = 2.8845e-01, time/batch = 0.6626s	
908/33250 (epoch 1.365), train_loss = 1.89786508, grad/param norm = 2.6476e-01, time/batch = 0.6617s	
909/33250 (epoch 1.367), train_loss = 1.75561478, grad/param norm = 2.3591e-01, time/batch = 0.6640s	
910/33250 (epoch 1.368), train_loss = 1.87082569, grad/param norm = 2.7210e-01, time/batch = 0.6755s	
911/33250 (epoch 1.370), train_loss = 1.75626961, grad/param norm = 2.6470e-01, time/batch = 0.6870s	
912/33250 (epoch 1.371), train_loss = 2.00946762, grad/param norm = 2.9985e-01, time/batch = 0.6825s	
913/33250 (epoch 1.373), train_loss = 1.80304435, grad/param norm = 2.7022e-01, time/batch = 0.6870s	
914/33250 (epoch 1.374), train_loss = 2.01877576, grad/param norm = 3.0658e-01, time/batch = 0.6913s	
915/33250 (epoch 1.376), train_loss = 1.88541222, grad/param norm = 2.9306e-01, time/batch = 0.6916s	
916/33250 (epoch 1.377), train_loss = 1.79985705, grad/param norm = 3.4548e-01, time/batch = 0.6811s	
917/33250 (epoch 1.379), train_loss = 1.84279727, grad/param norm = 2.7745e-01, time/batch = 0.7007s	
918/33250 (epoch 1.380), train_loss = 1.97516416, grad/param norm = 2.6008e-01, time/batch = 0.6900s	
919/33250 (epoch 1.382), train_loss = 2.04356750, grad/param norm = 3.4003e-01, time/batch = 0.6910s	
920/33250 (epoch 1.383), train_loss = 1.98613095, grad/param norm = 3.1403e-01, time/batch = 0.6765s	
921/33250 (epoch 1.385), train_loss = 1.81471303, grad/param norm = 3.0238e-01, time/batch = 0.6757s	
922/33250 (epoch 1.386), train_loss = 1.84994486, grad/param norm = 2.8194e-01, time/batch = 0.6786s	
923/33250 (epoch 1.388), train_loss = 1.89486704, grad/param norm = 2.5506e-01, time/batch = 0.6798s	
924/33250 (epoch 1.389), train_loss = 1.86813801, grad/param norm = 2.9157e-01, time/batch = 0.6957s	
925/33250 (epoch 1.391), train_loss = 1.78413728, grad/param norm = 2.8020e-01, time/batch = 0.6866s	
926/33250 (epoch 1.392), train_loss = 2.07980324, grad/param norm = 2.8829e-01, time/batch = 0.6791s	
927/33250 (epoch 1.394), train_loss = 2.16739699, grad/param norm = 3.6542e-01, time/batch = 0.6826s	
928/33250 (epoch 1.395), train_loss = 2.22100789, grad/param norm = 3.7183e-01, time/batch = 0.6875s	
929/33250 (epoch 1.397), train_loss = 2.10041601, grad/param norm = 3.8904e-01, time/batch = 0.6847s	
930/33250 (epoch 1.398), train_loss = 1.95602226, grad/param norm = 3.1977e-01, time/batch = 0.6775s	
931/33250 (epoch 1.400), train_loss = 1.95051080, grad/param norm = 2.7331e-01, time/batch = 0.6793s	
932/33250 (epoch 1.402), train_loss = 1.77385648, grad/param norm = 2.8945e-01, time/batch = 0.6879s	
933/33250 (epoch 1.403), train_loss = 1.71445438, grad/param norm = 2.7375e-01, time/batch = 0.6862s	
934/33250 (epoch 1.405), train_loss = 1.74916543, grad/param norm = 2.9468e-01, time/batch = 0.6771s	
935/33250 (epoch 1.406), train_loss = 1.87758623, grad/param norm = 2.5521e-01, time/batch = 0.6755s	
936/33250 (epoch 1.408), train_loss = 2.10530614, grad/param norm = 2.8811e-01, time/batch = 0.6767s	
937/33250 (epoch 1.409), train_loss = 1.96663500, grad/param norm = 2.8305e-01, time/batch = 0.6869s	
938/33250 (epoch 1.411), train_loss = 1.66337830, grad/param norm = 3.5026e-01, time/batch = 0.6819s	
939/33250 (epoch 1.412), train_loss = 1.60734311, grad/param norm = 2.4051e-01, time/batch = 0.6829s	
940/33250 (epoch 1.414), train_loss = 2.02669755, grad/param norm = 2.9739e-01, time/batch = 0.6767s	
941/33250 (epoch 1.415), train_loss = 1.87078252, grad/param norm = 2.8043e-01, time/batch = 0.6884s	
942/33250 (epoch 1.417), train_loss = 2.00891361, grad/param norm = 3.2313e-01, time/batch = 0.6798s	
943/33250 (epoch 1.418), train_loss = 2.09562373, grad/param norm = 3.1978e-01, time/batch = 0.6915s	
944/33250 (epoch 1.420), train_loss = 1.98716979, grad/param norm = 3.1482e-01, time/batch = 0.6945s	
945/33250 (epoch 1.421), train_loss = 1.74673193, grad/param norm = 3.3882e-01, time/batch = 0.6799s	
946/33250 (epoch 1.423), train_loss = 1.96875287, grad/param norm = 2.7142e-01, time/batch = 0.6821s	
947/33250 (epoch 1.424), train_loss = 2.08773301, grad/param norm = 3.0403e-01, time/batch = 0.6814s	
948/33250 (epoch 1.426), train_loss = 1.87223555, grad/param norm = 2.5685e-01, time/batch = 0.6837s	
949/33250 (epoch 1.427), train_loss = 1.74119879, grad/param norm = 2.8315e-01, time/batch = 0.6857s	
950/33250 (epoch 1.429), train_loss = 1.98944902, grad/param norm = 3.0648e-01, time/batch = 0.6832s	
951/33250 (epoch 1.430), train_loss = 1.91783778, grad/param norm = 3.4113e-01, time/batch = 0.6821s	
952/33250 (epoch 1.432), train_loss = 1.92843411, grad/param norm = 2.9742e-01, time/batch = 0.6863s	
953/33250 (epoch 1.433), train_loss = 1.85183275, grad/param norm = 2.7030e-01, time/batch = 0.6883s	
954/33250 (epoch 1.435), train_loss = 1.99640727, grad/param norm = 2.9904e-01, time/batch = 0.6822s	
955/33250 (epoch 1.436), train_loss = 1.93292150, grad/param norm = 2.7977e-01, time/batch = 0.6843s	
956/33250 (epoch 1.438), train_loss = 1.82257668, grad/param norm = 3.3847e-01, time/batch = 0.6857s	
957/33250 (epoch 1.439), train_loss = 1.83073427, grad/param norm = 2.6883e-01, time/batch = 0.6801s	
958/33250 (epoch 1.441), train_loss = 1.92186861, grad/param norm = 2.7456e-01, time/batch = 0.6830s	
959/33250 (epoch 1.442), train_loss = 1.88025487, grad/param norm = 2.7540e-01, time/batch = 0.6818s	
960/33250 (epoch 1.444), train_loss = 1.75108048, grad/param norm = 3.0596e-01, time/batch = 0.6822s	
961/33250 (epoch 1.445), train_loss = 1.88910237, grad/param norm = 2.5530e-01, time/batch = 0.6865s	
962/33250 (epoch 1.447), train_loss = 1.89955616, grad/param norm = 2.7419e-01, time/batch = 0.6878s	
963/33250 (epoch 1.448), train_loss = 1.82290568, grad/param norm = 3.5893e-01, time/batch = 0.6894s	
964/33250 (epoch 1.450), train_loss = 2.10760086, grad/param norm = 2.8564e-01, time/batch = 0.6960s	
965/33250 (epoch 1.451), train_loss = 1.96145181, grad/param norm = 3.1575e-01, time/batch = 0.7043s	
966/33250 (epoch 1.453), train_loss = 1.66471470, grad/param norm = 2.7684e-01, time/batch = 0.7157s	
967/33250 (epoch 1.454), train_loss = 1.99457981, grad/param norm = 2.9029e-01, time/batch = 0.6950s	
968/33250 (epoch 1.456), train_loss = 1.93908672, grad/param norm = 3.4003e-01, time/batch = 0.6951s	
969/33250 (epoch 1.457), train_loss = 1.94919227, grad/param norm = 3.1438e-01, time/batch = 0.6901s	
970/33250 (epoch 1.459), train_loss = 1.93976669, grad/param norm = 2.6723e-01, time/batch = 0.6857s	
971/33250 (epoch 1.460), train_loss = 1.86003694, grad/param norm = 3.0166e-01, time/batch = 0.6881s	
972/33250 (epoch 1.462), train_loss = 1.81815350, grad/param norm = 2.8419e-01, time/batch = 0.6860s	
973/33250 (epoch 1.463), train_loss = 1.74533651, grad/param norm = 2.4363e-01, time/batch = 0.6901s	
974/33250 (epoch 1.465), train_loss = 1.53329301, grad/param norm = 2.5611e-01, time/batch = 0.7271s	
975/33250 (epoch 1.466), train_loss = 1.58825774, grad/param norm = 2.9013e-01, time/batch = 0.6966s	
976/33250 (epoch 1.468), train_loss = 1.71381077, grad/param norm = 2.8473e-01, time/batch = 0.6795s	
977/33250 (epoch 1.469), train_loss = 1.99581413, grad/param norm = 2.9489e-01, time/batch = 0.6796s	
978/33250 (epoch 1.471), train_loss = 1.95418847, grad/param norm = 2.8907e-01, time/batch = 0.6811s	
979/33250 (epoch 1.472), train_loss = 1.94303140, grad/param norm = 3.5973e-01, time/batch = 0.6794s	
980/33250 (epoch 1.474), train_loss = 2.12186507, grad/param norm = 3.9605e-01, time/batch = 0.6771s	
981/33250 (epoch 1.475), train_loss = 1.93816162, grad/param norm = 3.8019e-01, time/batch = 0.6820s	
982/33250 (epoch 1.477), train_loss = 1.85623763, grad/param norm = 2.9953e-01, time/batch = 0.6801s	
983/33250 (epoch 1.478), train_loss = 1.81544224, grad/param norm = 2.4619e-01, time/batch = 0.6762s	
984/33250 (epoch 1.480), train_loss = 2.07128980, grad/param norm = 2.8365e-01, time/batch = 0.6779s	
985/33250 (epoch 1.481), train_loss = 1.80548569, grad/param norm = 3.3142e-01, time/batch = 0.6776s	
986/33250 (epoch 1.483), train_loss = 1.98013385, grad/param norm = 2.8381e-01, time/batch = 0.6813s	
987/33250 (epoch 1.484), train_loss = 1.82285422, grad/param norm = 2.8830e-01, time/batch = 0.6852s	
988/33250 (epoch 1.486), train_loss = 1.67702514, grad/param norm = 2.5220e-01, time/batch = 0.6805s	
989/33250 (epoch 1.487), train_loss = 1.88841768, grad/param norm = 3.3793e-01, time/batch = 0.6750s	
990/33250 (epoch 1.489), train_loss = 2.03352674, grad/param norm = 2.9425e-01, time/batch = 0.6828s	
991/33250 (epoch 1.490), train_loss = 2.00531957, grad/param norm = 3.0841e-01, time/batch = 0.6777s	
992/33250 (epoch 1.492), train_loss = 1.83419492, grad/param norm = 2.6861e-01, time/batch = 0.6761s	
993/33250 (epoch 1.493), train_loss = 1.86456073, grad/param norm = 2.5471e-01, time/batch = 0.6792s	
994/33250 (epoch 1.495), train_loss = 1.89559146, grad/param norm = 2.7677e-01, time/batch = 0.6721s	
995/33250 (epoch 1.496), train_loss = 1.85666173, grad/param norm = 2.8437e-01, time/batch = 0.6722s	
996/33250 (epoch 1.498), train_loss = 1.91835230, grad/param norm = 2.6791e-01, time/batch = 0.6772s	
997/33250 (epoch 1.499), train_loss = 1.93348128, grad/param norm = 2.8132e-01, time/batch = 0.6757s	
998/33250 (epoch 1.501), train_loss = 1.78077683, grad/param norm = 2.6618e-01, time/batch = 0.6784s	
999/33250 (epoch 1.502), train_loss = 1.85838712, grad/param norm = 3.4261e-01, time/batch = 0.6815s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch1.50_1.9623.t7	
1000/33250 (epoch 1.504), train_loss = 2.06009318, grad/param norm = 3.2027e-01, time/batch = 0.6776s	
1001/33250 (epoch 1.505), train_loss = 1.71012037, grad/param norm = 2.5295e-01, time/batch = 0.6845s	
1002/33250 (epoch 1.507), train_loss = 1.99087011, grad/param norm = 2.7372e-01, time/batch = 0.6842s	
1003/33250 (epoch 1.508), train_loss = 1.75768601, grad/param norm = 2.4740e-01, time/batch = 0.6712s	
1004/33250 (epoch 1.510), train_loss = 1.78167723, grad/param norm = 3.1085e-01, time/batch = 0.6726s	
1005/33250 (epoch 1.511), train_loss = 1.93268577, grad/param norm = 3.4455e-01, time/batch = 0.6772s	
1006/33250 (epoch 1.513), train_loss = 2.18646521, grad/param norm = 3.8603e-01, time/batch = 0.6871s	
1007/33250 (epoch 1.514), train_loss = 1.95604410, grad/param norm = 3.6403e-01, time/batch = 0.6724s	
1008/33250 (epoch 1.516), train_loss = 1.85460720, grad/param norm = 2.7878e-01, time/batch = 0.6780s	
1009/33250 (epoch 1.517), train_loss = 1.96019649, grad/param norm = 2.4565e-01, time/batch = 0.6789s	
1010/33250 (epoch 1.519), train_loss = 1.60546663, grad/param norm = 2.5459e-01, time/batch = 0.6781s	
1011/33250 (epoch 1.520), train_loss = 2.10186814, grad/param norm = 2.8349e-01, time/batch = 0.6782s	
1012/33250 (epoch 1.522), train_loss = 1.95346274, grad/param norm = 3.0587e-01, time/batch = 0.6900s	
1013/33250 (epoch 1.523), train_loss = 1.76123898, grad/param norm = 2.7964e-01, time/batch = 0.6757s	
1014/33250 (epoch 1.525), train_loss = 1.74546750, grad/param norm = 3.1392e-01, time/batch = 0.6752s	
1015/33250 (epoch 1.526), train_loss = 1.73979280, grad/param norm = 3.5694e-01, time/batch = 0.6769s	
1016/33250 (epoch 1.528), train_loss = 1.87152505, grad/param norm = 2.9209e-01, time/batch = 0.6769s	
1017/33250 (epoch 1.529), train_loss = 1.76432156, grad/param norm = 3.2092e-01, time/batch = 0.6866s	
1018/33250 (epoch 1.531), train_loss = 1.65049653, grad/param norm = 3.3122e-01, time/batch = 0.6856s	
1019/33250 (epoch 1.532), train_loss = 1.98487543, grad/param norm = 2.8315e-01, time/batch = 0.6874s	
1020/33250 (epoch 1.534), train_loss = 1.88895769, grad/param norm = 2.5465e-01, time/batch = 0.6779s	
1021/33250 (epoch 1.535), train_loss = 1.82348095, grad/param norm = 2.2510e-01, time/batch = 0.7015s	
1022/33250 (epoch 1.537), train_loss = 1.98751949, grad/param norm = 2.8696e-01, time/batch = 0.6973s	
1023/33250 (epoch 1.538), train_loss = 1.80388098, grad/param norm = 2.9341e-01, time/batch = 0.6965s	
1024/33250 (epoch 1.540), train_loss = 2.01811810, grad/param norm = 2.7402e-01, time/batch = 0.6953s	
1025/33250 (epoch 1.541), train_loss = 1.95798802, grad/param norm = 2.5865e-01, time/batch = 0.6879s	
1026/33250 (epoch 1.543), train_loss = 1.99717100, grad/param norm = 2.6638e-01, time/batch = 0.6998s	
1027/33250 (epoch 1.544), train_loss = 1.84481520, grad/param norm = 2.6539e-01, time/batch = 0.7146s	
1028/33250 (epoch 1.546), train_loss = 1.91438678, grad/param norm = 3.3921e-01, time/batch = 0.7201s	
1029/33250 (epoch 1.547), train_loss = 1.72393107, grad/param norm = 3.2887e-01, time/batch = 0.7199s	
1030/33250 (epoch 1.549), train_loss = 1.90571764, grad/param norm = 2.8105e-01, time/batch = 0.7339s	
1031/33250 (epoch 1.550), train_loss = 1.75635064, grad/param norm = 2.7109e-01, time/batch = 0.7328s	
1032/33250 (epoch 1.552), train_loss = 1.91201982, grad/param norm = 2.6470e-01, time/batch = 0.7286s	
1033/33250 (epoch 1.553), train_loss = 1.72502338, grad/param norm = 2.5852e-01, time/batch = 0.7283s	
1034/33250 (epoch 1.555), train_loss = 1.72822309, grad/param norm = 2.6395e-01, time/batch = 0.7185s	
1035/33250 (epoch 1.556), train_loss = 2.00015622, grad/param norm = 3.1605e-01, time/batch = 0.7166s	
1036/33250 (epoch 1.558), train_loss = 1.98826369, grad/param norm = 3.1399e-01, time/batch = 0.7046s	
1037/33250 (epoch 1.559), train_loss = 1.84656969, grad/param norm = 2.7744e-01, time/batch = 0.6977s	
1038/33250 (epoch 1.561), train_loss = 1.88499047, grad/param norm = 2.8384e-01, time/batch = 0.7099s	
1039/33250 (epoch 1.562), train_loss = 1.99527342, grad/param norm = 3.1338e-01, time/batch = 0.6896s	
1040/33250 (epoch 1.564), train_loss = 1.93190901, grad/param norm = 2.9090e-01, time/batch = 0.6908s	
1041/33250 (epoch 1.565), train_loss = 1.93618357, grad/param norm = 2.7756e-01, time/batch = 0.7124s	
1042/33250 (epoch 1.567), train_loss = 1.81631177, grad/param norm = 2.4820e-01, time/batch = 0.7157s	
1043/33250 (epoch 1.568), train_loss = 1.80484238, grad/param norm = 2.5613e-01, time/batch = 0.7162s	
1044/33250 (epoch 1.570), train_loss = 2.00725520, grad/param norm = 3.0998e-01, time/batch = 0.6929s	
1045/33250 (epoch 1.571), train_loss = 2.00869747, grad/param norm = 2.7138e-01, time/batch = 0.6972s	
1046/33250 (epoch 1.573), train_loss = 1.99916339, grad/param norm = 2.4104e-01, time/batch = 0.7110s	
1047/33250 (epoch 1.574), train_loss = 1.70171809, grad/param norm = 2.3004e-01, time/batch = 0.6942s	
1048/33250 (epoch 1.576), train_loss = 1.92779216, grad/param norm = 3.0180e-01, time/batch = 0.6971s	
1049/33250 (epoch 1.577), train_loss = 1.88490190, grad/param norm = 3.0837e-01, time/batch = 0.7002s	
1050/33250 (epoch 1.579), train_loss = 1.68655694, grad/param norm = 2.5632e-01, time/batch = 0.7162s	
1051/33250 (epoch 1.580), train_loss = 1.61636673, grad/param norm = 2.4255e-01, time/batch = 0.7220s	
1052/33250 (epoch 1.582), train_loss = 1.78104514, grad/param norm = 2.5697e-01, time/batch = 0.6975s	
1053/33250 (epoch 1.583), train_loss = 1.88369162, grad/param norm = 2.5562e-01, time/batch = 0.6962s	
1054/33250 (epoch 1.585), train_loss = 1.97843197, grad/param norm = 3.1382e-01, time/batch = 0.6956s	
1055/33250 (epoch 1.586), train_loss = 1.82038973, grad/param norm = 3.4210e-01, time/batch = 0.6988s	
1056/33250 (epoch 1.588), train_loss = 1.89309683, grad/param norm = 2.8845e-01, time/batch = 0.6954s	
1057/33250 (epoch 1.589), train_loss = 2.05549563, grad/param norm = 3.5453e-01, time/batch = 0.6919s	
1058/33250 (epoch 1.591), train_loss = 1.94724943, grad/param norm = 3.1910e-01, time/batch = 0.7020s	
1059/33250 (epoch 1.592), train_loss = 1.82654445, grad/param norm = 2.4886e-01, time/batch = 0.6961s	
1060/33250 (epoch 1.594), train_loss = 2.10138339, grad/param norm = 2.9294e-01, time/batch = 0.6955s	
1061/33250 (epoch 1.595), train_loss = 2.00080393, grad/param norm = 2.9086e-01, time/batch = 0.6982s	
1062/33250 (epoch 1.597), train_loss = 1.84590652, grad/param norm = 3.1927e-01, time/batch = 0.7005s	
1063/33250 (epoch 1.598), train_loss = 1.94216576, grad/param norm = 2.6469e-01, time/batch = 0.6917s	
1064/33250 (epoch 1.600), train_loss = 1.82764855, grad/param norm = 3.0708e-01, time/batch = 0.6936s	
1065/33250 (epoch 1.602), train_loss = 2.05130330, grad/param norm = 3.1311e-01, time/batch = 0.6926s	
1066/33250 (epoch 1.603), train_loss = 1.80730604, grad/param norm = 2.8870e-01, time/batch = 0.6932s	
1067/33250 (epoch 1.605), train_loss = 1.90163783, grad/param norm = 2.9939e-01, time/batch = 0.6904s	
1068/33250 (epoch 1.606), train_loss = 1.92181030, grad/param norm = 2.7972e-01, time/batch = 0.6891s	
1069/33250 (epoch 1.608), train_loss = 1.92645802, grad/param norm = 2.5114e-01, time/batch = 0.6914s	
1070/33250 (epoch 1.609), train_loss = 1.74338139, grad/param norm = 2.7095e-01, time/batch = 0.6890s	
1071/33250 (epoch 1.611), train_loss = 2.04358159, grad/param norm = 2.9755e-01, time/batch = 0.6899s	
1072/33250 (epoch 1.612), train_loss = 2.05174738, grad/param norm = 3.1040e-01, time/batch = 0.6902s	
1073/33250 (epoch 1.614), train_loss = 2.18996517, grad/param norm = 3.2002e-01, time/batch = 0.6919s	
1074/33250 (epoch 1.615), train_loss = 1.96964787, grad/param norm = 3.1934e-01, time/batch = 0.6896s	
1075/33250 (epoch 1.617), train_loss = 2.26279367, grad/param norm = 2.8107e-01, time/batch = 0.6901s	
1076/33250 (epoch 1.618), train_loss = 2.13212130, grad/param norm = 3.1129e-01, time/batch = 0.6931s	
1077/33250 (epoch 1.620), train_loss = 2.02234604, grad/param norm = 3.1496e-01, time/batch = 0.6902s	
1078/33250 (epoch 1.621), train_loss = 1.74529124, grad/param norm = 2.2609e-01, time/batch = 0.6877s	
1079/33250 (epoch 1.623), train_loss = 1.82882045, grad/param norm = 2.8810e-01, time/batch = 0.6964s	
1080/33250 (epoch 1.624), train_loss = 1.90543342, grad/param norm = 3.0702e-01, time/batch = 0.6955s	
1081/33250 (epoch 1.626), train_loss = 1.93290875, grad/param norm = 3.1817e-01, time/batch = 0.6918s	
1082/33250 (epoch 1.627), train_loss = 2.00783291, grad/param norm = 2.8513e-01, time/batch = 0.6905s	
1083/33250 (epoch 1.629), train_loss = 1.86151420, grad/param norm = 3.4333e-01, time/batch = 0.6896s	
1084/33250 (epoch 1.630), train_loss = 1.91880130, grad/param norm = 3.8620e-01, time/batch = 0.6923s	
1085/33250 (epoch 1.632), train_loss = 1.60914888, grad/param norm = 2.5288e-01, time/batch = 0.6942s	
1086/33250 (epoch 1.633), train_loss = 2.01216516, grad/param norm = 3.2652e-01, time/batch = 0.6993s	
1087/33250 (epoch 1.635), train_loss = 1.72564106, grad/param norm = 2.9226e-01, time/batch = 0.6898s	
1088/33250 (epoch 1.636), train_loss = 1.83696273, grad/param norm = 2.7570e-01, time/batch = 0.6927s	
1089/33250 (epoch 1.638), train_loss = 1.81850367, grad/param norm = 2.7369e-01, time/batch = 0.6891s	
1090/33250 (epoch 1.639), train_loss = 1.87574105, grad/param norm = 2.8312e-01, time/batch = 0.6862s	
1091/33250 (epoch 1.641), train_loss = 1.73007480, grad/param norm = 2.7129e-01, time/batch = 0.7061s	
1092/33250 (epoch 1.642), train_loss = 1.76832784, grad/param norm = 2.6144e-01, time/batch = 0.6915s	
1093/33250 (epoch 1.644), train_loss = 1.68361502, grad/param norm = 2.9511e-01, time/batch = 0.6909s	
1094/33250 (epoch 1.645), train_loss = 1.95066235, grad/param norm = 3.2702e-01, time/batch = 0.6906s	
1095/33250 (epoch 1.647), train_loss = 1.80779070, grad/param norm = 3.0936e-01, time/batch = 0.6916s	
1096/33250 (epoch 1.648), train_loss = 1.84935191, grad/param norm = 2.8187e-01, time/batch = 0.6870s	
1097/33250 (epoch 1.650), train_loss = 1.97606296, grad/param norm = 2.9263e-01, time/batch = 0.6904s	
1098/33250 (epoch 1.651), train_loss = 1.89378344, grad/param norm = 3.1780e-01, time/batch = 0.6977s	
1099/33250 (epoch 1.653), train_loss = 1.67720160, grad/param norm = 2.5937e-01, time/batch = 0.7163s	
1100/33250 (epoch 1.654), train_loss = 1.66813032, grad/param norm = 2.5149e-01, time/batch = 0.7146s	
1101/33250 (epoch 1.656), train_loss = 1.88215525, grad/param norm = 2.7634e-01, time/batch = 0.7038s	
1102/33250 (epoch 1.657), train_loss = 1.79840934, grad/param norm = 2.8518e-01, time/batch = 0.6989s	
1103/33250 (epoch 1.659), train_loss = 1.63549057, grad/param norm = 2.7677e-01, time/batch = 0.6820s	
1104/33250 (epoch 1.660), train_loss = 1.80069871, grad/param norm = 2.7156e-01, time/batch = 0.6938s	
1105/33250 (epoch 1.662), train_loss = 1.88102670, grad/param norm = 3.5519e-01, time/batch = 0.6830s	
1106/33250 (epoch 1.663), train_loss = 1.75814737, grad/param norm = 3.3902e-01, time/batch = 0.7095s	
1107/33250 (epoch 1.665), train_loss = 1.97560580, grad/param norm = 3.3773e-01, time/batch = 0.6770s	
1108/33250 (epoch 1.666), train_loss = 1.80482106, grad/param norm = 3.2954e-01, time/batch = 0.6807s	
1109/33250 (epoch 1.668), train_loss = 1.94837409, grad/param norm = 2.7249e-01, time/batch = 0.6744s	
1110/33250 (epoch 1.669), train_loss = 1.98229727, grad/param norm = 2.7720e-01, time/batch = 0.6749s	
1111/33250 (epoch 1.671), train_loss = 1.89642519, grad/param norm = 2.5984e-01, time/batch = 0.6788s	
1112/33250 (epoch 1.672), train_loss = 1.97475849, grad/param norm = 2.7198e-01, time/batch = 0.6795s	
1113/33250 (epoch 1.674), train_loss = 1.74270464, grad/param norm = 2.4593e-01, time/batch = 0.6808s	
1114/33250 (epoch 1.675), train_loss = 1.86949561, grad/param norm = 2.6494e-01, time/batch = 0.6785s	
1115/33250 (epoch 1.677), train_loss = 1.84959816, grad/param norm = 3.0290e-01, time/batch = 0.6786s	
1116/33250 (epoch 1.678), train_loss = 1.95393450, grad/param norm = 3.0461e-01, time/batch = 0.6844s	
1117/33250 (epoch 1.680), train_loss = 1.90644269, grad/param norm = 2.6475e-01, time/batch = 0.6767s	
1118/33250 (epoch 1.681), train_loss = 1.67700136, grad/param norm = 2.7265e-01, time/batch = 0.6772s	
1119/33250 (epoch 1.683), train_loss = 1.76189172, grad/param norm = 2.7440e-01, time/batch = 0.6743s	
1120/33250 (epoch 1.684), train_loss = 1.90610893, grad/param norm = 3.3841e-01, time/batch = 0.6757s	
1121/33250 (epoch 1.686), train_loss = 1.75460500, grad/param norm = 3.0327e-01, time/batch = 0.6777s	
1122/33250 (epoch 1.687), train_loss = 1.76223888, grad/param norm = 2.4796e-01, time/batch = 0.6810s	
1123/33250 (epoch 1.689), train_loss = 1.68827976, grad/param norm = 2.2281e-01, time/batch = 0.6813s	
1124/33250 (epoch 1.690), train_loss = 1.92936945, grad/param norm = 2.9237e-01, time/batch = 0.6856s	
1125/33250 (epoch 1.692), train_loss = 1.94965332, grad/param norm = 3.3040e-01, time/batch = 0.6841s	
1126/33250 (epoch 1.693), train_loss = 1.79517045, grad/param norm = 2.4014e-01, time/batch = 0.6827s	
1127/33250 (epoch 1.695), train_loss = 1.99259706, grad/param norm = 3.1731e-01, time/batch = 0.6936s	
1128/33250 (epoch 1.696), train_loss = 1.91403425, grad/param norm = 2.6945e-01, time/batch = 0.7018s	
1129/33250 (epoch 1.698), train_loss = 1.65918491, grad/param norm = 2.3703e-01, time/batch = 0.7081s	
1130/33250 (epoch 1.699), train_loss = 1.96724303, grad/param norm = 2.3718e-01, time/batch = 0.6910s	
1131/33250 (epoch 1.701), train_loss = 1.73673664, grad/param norm = 2.4289e-01, time/batch = 0.7090s	
1132/33250 (epoch 1.702), train_loss = 1.93346332, grad/param norm = 2.7208e-01, time/batch = 0.7051s	
1133/33250 (epoch 1.704), train_loss = 2.00161647, grad/param norm = 3.1623e-01, time/batch = 0.7030s	
1134/33250 (epoch 1.705), train_loss = 1.82859709, grad/param norm = 3.4602e-01, time/batch = 0.7014s	
1135/33250 (epoch 1.707), train_loss = 1.77209725, grad/param norm = 3.2827e-01, time/batch = 0.7184s	
1136/33250 (epoch 1.708), train_loss = 1.85992971, grad/param norm = 2.7709e-01, time/batch = 0.7042s	
1137/33250 (epoch 1.710), train_loss = 1.98207235, grad/param norm = 2.8467e-01, time/batch = 0.7041s	
1138/33250 (epoch 1.711), train_loss = 1.97652746, grad/param norm = 3.0451e-01, time/batch = 0.7112s	
1139/33250 (epoch 1.713), train_loss = 1.90803446, grad/param norm = 2.8736e-01, time/batch = 0.7149s	
1140/33250 (epoch 1.714), train_loss = 1.97042476, grad/param norm = 2.7814e-01, time/batch = 0.6995s	
1141/33250 (epoch 1.716), train_loss = 1.93452686, grad/param norm = 2.7432e-01, time/batch = 0.7068s	
1142/33250 (epoch 1.717), train_loss = 1.75459573, grad/param norm = 2.6432e-01, time/batch = 0.7019s	
1143/33250 (epoch 1.719), train_loss = 1.93019524, grad/param norm = 2.6969e-01, time/batch = 0.6975s	
1144/33250 (epoch 1.720), train_loss = 2.02546953, grad/param norm = 2.6979e-01, time/batch = 0.7018s	
1145/33250 (epoch 1.722), train_loss = 1.73606648, grad/param norm = 2.4222e-01, time/batch = 0.7046s	
1146/33250 (epoch 1.723), train_loss = 1.70932602, grad/param norm = 2.5896e-01, time/batch = 0.6986s	
1147/33250 (epoch 1.725), train_loss = 1.48814267, grad/param norm = 2.3531e-01, time/batch = 0.7035s	
1148/33250 (epoch 1.726), train_loss = 1.75648708, grad/param norm = 2.5941e-01, time/batch = 0.7242s	
1149/33250 (epoch 1.728), train_loss = 1.88413414, grad/param norm = 2.6441e-01, time/batch = 0.7058s	
1150/33250 (epoch 1.729), train_loss = 1.87832209, grad/param norm = 2.7278e-01, time/batch = 0.7036s	
1151/33250 (epoch 1.731), train_loss = 1.73847025, grad/param norm = 2.6934e-01, time/batch = 0.7144s	
1152/33250 (epoch 1.732), train_loss = 1.74407911, grad/param norm = 2.8863e-01, time/batch = 0.7077s	
1153/33250 (epoch 1.734), train_loss = 1.86520231, grad/param norm = 3.6781e-01, time/batch = 0.7020s	
1154/33250 (epoch 1.735), train_loss = 1.85545696, grad/param norm = 3.5885e-01, time/batch = 0.6995s	
1155/33250 (epoch 1.737), train_loss = 1.96978579, grad/param norm = 2.8531e-01, time/batch = 0.7015s	
1156/33250 (epoch 1.738), train_loss = 1.87524981, grad/param norm = 2.7302e-01, time/batch = 0.7004s	
1157/33250 (epoch 1.740), train_loss = 2.07957094, grad/param norm = 2.7379e-01, time/batch = 0.7003s	
1158/33250 (epoch 1.741), train_loss = 1.79370214, grad/param norm = 2.9468e-01, time/batch = 0.7107s	
1159/33250 (epoch 1.743), train_loss = 1.86468804, grad/param norm = 2.8251e-01, time/batch = 0.7013s	
1160/33250 (epoch 1.744), train_loss = 1.86134746, grad/param norm = 2.6828e-01, time/batch = 0.7010s	
1161/33250 (epoch 1.746), train_loss = 1.89477485, grad/param norm = 2.9562e-01, time/batch = 0.7029s	
1162/33250 (epoch 1.747), train_loss = 1.80946944, grad/param norm = 2.3703e-01, time/batch = 0.6998s	
1163/33250 (epoch 1.749), train_loss = 1.95247955, grad/param norm = 2.5572e-01, time/batch = 0.6932s	
1164/33250 (epoch 1.750), train_loss = 1.81767201, grad/param norm = 2.8850e-01, time/batch = 0.6924s	
1165/33250 (epoch 1.752), train_loss = 1.74525084, grad/param norm = 2.8018e-01, time/batch = 0.6992s	
1166/33250 (epoch 1.753), train_loss = 1.83825003, grad/param norm = 2.9746e-01, time/batch = 0.6970s	
1167/33250 (epoch 1.755), train_loss = 1.68536989, grad/param norm = 2.8312e-01, time/batch = 0.6978s	
1168/33250 (epoch 1.756), train_loss = 1.93526150, grad/param norm = 2.5589e-01, time/batch = 0.6948s	
1169/33250 (epoch 1.758), train_loss = 1.87566214, grad/param norm = 2.9662e-01, time/batch = 0.6982s	
1170/33250 (epoch 1.759), train_loss = 1.63444532, grad/param norm = 2.4742e-01, time/batch = 0.6993s	
1171/33250 (epoch 1.761), train_loss = 1.83263626, grad/param norm = 2.9758e-01, time/batch = 0.7011s	
1172/33250 (epoch 1.762), train_loss = 1.85632675, grad/param norm = 2.6810e-01, time/batch = 0.7052s	
1173/33250 (epoch 1.764), train_loss = 1.73410539, grad/param norm = 2.9435e-01, time/batch = 0.7030s	
1174/33250 (epoch 1.765), train_loss = 1.82279784, grad/param norm = 3.0160e-01, time/batch = 0.6989s	
1175/33250 (epoch 1.767), train_loss = 1.66088825, grad/param norm = 3.2309e-01, time/batch = 0.7042s	
1176/33250 (epoch 1.768), train_loss = 1.76596204, grad/param norm = 2.8627e-01, time/batch = 0.6963s	
1177/33250 (epoch 1.770), train_loss = 1.76302194, grad/param norm = 2.5827e-01, time/batch = 0.7026s	
1178/33250 (epoch 1.771), train_loss = 1.86732682, grad/param norm = 2.4664e-01, time/batch = 0.6990s	
1179/33250 (epoch 1.773), train_loss = 1.82256912, grad/param norm = 2.9852e-01, time/batch = 0.6982s	
1180/33250 (epoch 1.774), train_loss = 1.63428697, grad/param norm = 2.8638e-01, time/batch = 0.7000s	
1181/33250 (epoch 1.776), train_loss = 1.84438359, grad/param norm = 2.9850e-01, time/batch = 0.7048s	
1182/33250 (epoch 1.777), train_loss = 1.98068350, grad/param norm = 2.8593e-01, time/batch = 0.7022s	
1183/33250 (epoch 1.779), train_loss = 1.63297428, grad/param norm = 2.7538e-01, time/batch = 0.7005s	
1184/33250 (epoch 1.780), train_loss = 1.98182240, grad/param norm = 2.7886e-01, time/batch = 0.6948s	
1185/33250 (epoch 1.782), train_loss = 1.94848498, grad/param norm = 3.0281e-01, time/batch = 0.6973s	
1186/33250 (epoch 1.783), train_loss = 1.67813754, grad/param norm = 3.0992e-01, time/batch = 0.6986s	
1187/33250 (epoch 1.785), train_loss = 1.73901924, grad/param norm = 3.4966e-01, time/batch = 0.7069s	
1188/33250 (epoch 1.786), train_loss = 1.96739733, grad/param norm = 2.9057e-01, time/batch = 0.7116s	
1189/33250 (epoch 1.788), train_loss = 1.72200755, grad/param norm = 2.5645e-01, time/batch = 0.6988s	
1190/33250 (epoch 1.789), train_loss = 1.82589456, grad/param norm = 3.0585e-01, time/batch = 0.7053s	
1191/33250 (epoch 1.791), train_loss = 1.94667683, grad/param norm = 3.4691e-01, time/batch = 0.7020s	
1192/33250 (epoch 1.792), train_loss = 1.99685582, grad/param norm = 2.8690e-01, time/batch = 0.7051s	
1193/33250 (epoch 1.794), train_loss = 1.67008465, grad/param norm = 2.8794e-01, time/batch = 0.6985s	
1194/33250 (epoch 1.795), train_loss = 1.87034373, grad/param norm = 2.7064e-01, time/batch = 0.6984s	
1195/33250 (epoch 1.797), train_loss = 1.97395396, grad/param norm = 2.8520e-01, time/batch = 0.7016s	
1196/33250 (epoch 1.798), train_loss = 1.98521527, grad/param norm = 3.5759e-01, time/batch = 0.6955s	
1197/33250 (epoch 1.800), train_loss = 1.94982830, grad/param norm = 3.1979e-01, time/batch = 0.7047s	
1198/33250 (epoch 1.802), train_loss = 1.72714990, grad/param norm = 2.5237e-01, time/batch = 0.6952s	
1199/33250 (epoch 1.803), train_loss = 1.76778245, grad/param norm = 2.4931e-01, time/batch = 0.6974s	
1200/33250 (epoch 1.805), train_loss = 1.78988268, grad/param norm = 2.4338e-01, time/batch = 0.6947s	
1201/33250 (epoch 1.806), train_loss = 1.91537145, grad/param norm = 2.5813e-01, time/batch = 0.7038s	
1202/33250 (epoch 1.808), train_loss = 1.87118926, grad/param norm = 2.4596e-01, time/batch = 0.6968s	
1203/33250 (epoch 1.809), train_loss = 1.61967301, grad/param norm = 2.4992e-01, time/batch = 0.6972s	
1204/33250 (epoch 1.811), train_loss = 1.80133169, grad/param norm = 3.1635e-01, time/batch = 0.6930s	
1205/33250 (epoch 1.812), train_loss = 1.74547048, grad/param norm = 3.1432e-01, time/batch = 0.6986s	
1206/33250 (epoch 1.814), train_loss = 1.78235773, grad/param norm = 2.7957e-01, time/batch = 0.6962s	
1207/33250 (epoch 1.815), train_loss = 1.87569760, grad/param norm = 3.2070e-01, time/batch = 0.6931s	
1208/33250 (epoch 1.817), train_loss = 1.79958447, grad/param norm = 2.4743e-01, time/batch = 0.6972s	
1209/33250 (epoch 1.818), train_loss = 1.66204516, grad/param norm = 2.4518e-01, time/batch = 0.7020s	
1210/33250 (epoch 1.820), train_loss = 1.81144672, grad/param norm = 2.6756e-01, time/batch = 0.6993s	
1211/33250 (epoch 1.821), train_loss = 1.61605342, grad/param norm = 2.6183e-01, time/batch = 0.7014s	
1212/33250 (epoch 1.823), train_loss = 1.97535394, grad/param norm = 2.8108e-01, time/batch = 0.7130s	
1213/33250 (epoch 1.824), train_loss = 1.77360015, grad/param norm = 3.2963e-01, time/batch = 0.7213s	
1214/33250 (epoch 1.826), train_loss = 1.77515269, grad/param norm = 3.0342e-01, time/batch = 0.7228s	
1215/33250 (epoch 1.827), train_loss = 1.60580617, grad/param norm = 2.4407e-01, time/batch = 0.7020s	
1216/33250 (epoch 1.829), train_loss = 1.78329523, grad/param norm = 2.3535e-01, time/batch = 0.6821s	
1217/33250 (epoch 1.830), train_loss = 2.12240642, grad/param norm = 3.1863e-01, time/batch = 0.6824s	
1218/33250 (epoch 1.832), train_loss = 1.70293260, grad/param norm = 2.4994e-01, time/batch = 0.6877s	
1219/33250 (epoch 1.833), train_loss = 1.85547749, grad/param norm = 2.9100e-01, time/batch = 0.6921s	
1220/33250 (epoch 1.835), train_loss = 1.84651437, grad/param norm = 3.0969e-01, time/batch = 0.6971s	
1221/33250 (epoch 1.836), train_loss = 1.84025813, grad/param norm = 2.6791e-01, time/batch = 0.6828s	
1222/33250 (epoch 1.838), train_loss = 1.67586800, grad/param norm = 2.3450e-01, time/batch = 0.6803s	
1223/33250 (epoch 1.839), train_loss = 1.74815378, grad/param norm = 2.7145e-01, time/batch = 0.6823s	
1224/33250 (epoch 1.841), train_loss = 1.57302634, grad/param norm = 2.4568e-01, time/batch = 0.6818s	
1225/33250 (epoch 1.842), train_loss = 1.81570297, grad/param norm = 2.4173e-01, time/batch = 0.6777s	
1226/33250 (epoch 1.844), train_loss = 1.98527072, grad/param norm = 2.8062e-01, time/batch = 0.6747s	
1227/33250 (epoch 1.845), train_loss = 2.03227864, grad/param norm = 3.2592e-01, time/batch = 0.6927s	
1228/33250 (epoch 1.847), train_loss = 1.92170142, grad/param norm = 2.8373e-01, time/batch = 0.6958s	
1229/33250 (epoch 1.848), train_loss = 1.99000459, grad/param norm = 3.0198e-01, time/batch = 0.6947s	
1230/33250 (epoch 1.850), train_loss = 1.82293036, grad/param norm = 2.8282e-01, time/batch = 0.6983s	
1231/33250 (epoch 1.851), train_loss = 1.69663939, grad/param norm = 2.7646e-01, time/batch = 0.6968s	
1232/33250 (epoch 1.853), train_loss = 1.85404239, grad/param norm = 2.5162e-01, time/batch = 0.6941s	
1233/33250 (epoch 1.854), train_loss = 1.62432409, grad/param norm = 2.6509e-01, time/batch = 0.6897s	
1234/33250 (epoch 1.856), train_loss = 1.71585897, grad/param norm = 2.8160e-01, time/batch = 0.6904s	
1235/33250 (epoch 1.857), train_loss = 1.50842373, grad/param norm = 2.3011e-01, time/batch = 0.6910s	
1236/33250 (epoch 1.859), train_loss = 1.57412957, grad/param norm = 2.4705e-01, time/batch = 0.6946s	
1237/33250 (epoch 1.860), train_loss = 1.62936539, grad/param norm = 2.3270e-01, time/batch = 0.6930s	
1238/33250 (epoch 1.862), train_loss = 1.70201026, grad/param norm = 2.4156e-01, time/batch = 0.6969s	
1239/33250 (epoch 1.863), train_loss = 1.66322280, grad/param norm = 2.5075e-01, time/batch = 0.6958s	
1240/33250 (epoch 1.865), train_loss = 1.75238282, grad/param norm = 2.4180e-01, time/batch = 0.7162s	
1241/33250 (epoch 1.866), train_loss = 1.78383880, grad/param norm = 2.5772e-01, time/batch = 0.7182s	
1242/33250 (epoch 1.868), train_loss = 2.14360559, grad/param norm = 3.0170e-01, time/batch = 0.7038s	
1243/33250 (epoch 1.869), train_loss = 1.84974573, grad/param norm = 2.3737e-01, time/batch = 0.7139s	
1244/33250 (epoch 1.871), train_loss = 1.47889252, grad/param norm = 2.2298e-01, time/batch = 0.7014s	
1245/33250 (epoch 1.872), train_loss = 1.91628523, grad/param norm = 2.5179e-01, time/batch = 0.6996s	
1246/33250 (epoch 1.874), train_loss = 1.70009686, grad/param norm = 2.5428e-01, time/batch = 0.6990s	
1247/33250 (epoch 1.875), train_loss = 1.73583762, grad/param norm = 3.1685e-01, time/batch = 0.7008s	
1248/33250 (epoch 1.877), train_loss = 1.82280231, grad/param norm = 2.7555e-01, time/batch = 0.6925s	
1249/33250 (epoch 1.878), train_loss = 1.73356452, grad/param norm = 2.2565e-01, time/batch = 0.6982s	
1250/33250 (epoch 1.880), train_loss = 1.91779597, grad/param norm = 2.8434e-01, time/batch = 0.6905s	
1251/33250 (epoch 1.881), train_loss = 1.92056414, grad/param norm = 2.7298e-01, time/batch = 0.7007s	
1252/33250 (epoch 1.883), train_loss = 1.90256192, grad/param norm = 3.0983e-01, time/batch = 0.6958s	
1253/33250 (epoch 1.884), train_loss = 1.69778825, grad/param norm = 2.9173e-01, time/batch = 0.6929s	
1254/33250 (epoch 1.886), train_loss = 1.62077960, grad/param norm = 2.4116e-01, time/batch = 0.6950s	
1255/33250 (epoch 1.887), train_loss = 1.74564157, grad/param norm = 2.8058e-01, time/batch = 0.6941s	
1256/33250 (epoch 1.889), train_loss = 1.60820792, grad/param norm = 1.9630e-01, time/batch = 0.6977s	
1257/33250 (epoch 1.890), train_loss = 1.58463424, grad/param norm = 2.6332e-01, time/batch = 0.6962s	
1258/33250 (epoch 1.892), train_loss = 1.83344121, grad/param norm = 2.6938e-01, time/batch = 0.7067s	
1259/33250 (epoch 1.893), train_loss = 1.80758830, grad/param norm = 2.5058e-01, time/batch = 0.6802s	
1260/33250 (epoch 1.895), train_loss = 1.73849068, grad/param norm = 2.7862e-01, time/batch = 0.6770s	
1261/33250 (epoch 1.896), train_loss = 1.88655373, grad/param norm = 2.8399e-01, time/batch = 0.6889s	
1262/33250 (epoch 1.898), train_loss = 1.69881162, grad/param norm = 2.4377e-01, time/batch = 0.6981s	
1263/33250 (epoch 1.899), train_loss = 1.79162651, grad/param norm = 2.5103e-01, time/batch = 0.6819s	
1264/33250 (epoch 1.901), train_loss = 1.60849043, grad/param norm = 2.1525e-01, time/batch = 0.6840s	
1265/33250 (epoch 1.902), train_loss = 1.63461437, grad/param norm = 2.5658e-01, time/batch = 0.6822s	
1266/33250 (epoch 1.904), train_loss = 1.66775990, grad/param norm = 2.5204e-01, time/batch = 0.6831s	
1267/33250 (epoch 1.905), train_loss = 1.69667511, grad/param norm = 2.5327e-01, time/batch = 0.6840s	
1268/33250 (epoch 1.907), train_loss = 1.75711086, grad/param norm = 2.7520e-01, time/batch = 0.6814s	
1269/33250 (epoch 1.908), train_loss = 1.76427986, grad/param norm = 2.3714e-01, time/batch = 0.6857s	
1270/33250 (epoch 1.910), train_loss = 1.91803127, grad/param norm = 3.0408e-01, time/batch = 0.6814s	
1271/33250 (epoch 1.911), train_loss = 1.63550387, grad/param norm = 3.0488e-01, time/batch = 0.6819s	
1272/33250 (epoch 1.913), train_loss = 1.65892069, grad/param norm = 2.4557e-01, time/batch = 0.6797s	
1273/33250 (epoch 1.914), train_loss = 1.57703806, grad/param norm = 2.8335e-01, time/batch = 0.6793s	
1274/33250 (epoch 1.916), train_loss = 1.62040101, grad/param norm = 2.4627e-01, time/batch = 0.6917s	
1275/33250 (epoch 1.917), train_loss = 1.74547239, grad/param norm = 2.5248e-01, time/batch = 0.6783s	
1276/33250 (epoch 1.919), train_loss = 1.78874743, grad/param norm = 2.8842e-01, time/batch = 0.6871s	
1277/33250 (epoch 1.920), train_loss = 1.76380920, grad/param norm = 2.8379e-01, time/batch = 0.6775s	
1278/33250 (epoch 1.922), train_loss = 1.78927535, grad/param norm = 2.6951e-01, time/batch = 0.6831s	
1279/33250 (epoch 1.923), train_loss = 1.74391137, grad/param norm = 2.7782e-01, time/batch = 0.6788s	
1280/33250 (epoch 1.925), train_loss = 1.70835848, grad/param norm = 2.6844e-01, time/batch = 0.6785s	
1281/33250 (epoch 1.926), train_loss = 1.77423275, grad/param norm = 3.4476e-01, time/batch = 0.6857s	
1282/33250 (epoch 1.928), train_loss = 1.83617386, grad/param norm = 3.3576e-01, time/batch = 0.6781s	
1283/33250 (epoch 1.929), train_loss = 1.40085766, grad/param norm = 2.2859e-01, time/batch = 0.6789s	
1284/33250 (epoch 1.931), train_loss = 1.75375974, grad/param norm = 2.6913e-01, time/batch = 0.6822s	
1285/33250 (epoch 1.932), train_loss = 1.87610934, grad/param norm = 2.6390e-01, time/batch = 0.6770s	
1286/33250 (epoch 1.934), train_loss = 1.68064635, grad/param norm = 2.5215e-01, time/batch = 0.6756s	
1287/33250 (epoch 1.935), train_loss = 1.75073607, grad/param norm = 2.7119e-01, time/batch = 0.6871s	
1288/33250 (epoch 1.937), train_loss = 1.73400634, grad/param norm = 2.5061e-01, time/batch = 0.6892s	
1289/33250 (epoch 1.938), train_loss = 1.88399112, grad/param norm = 2.5296e-01, time/batch = 0.6806s	
1290/33250 (epoch 1.940), train_loss = 1.76624437, grad/param norm = 2.7784e-01, time/batch = 0.6832s	
1291/33250 (epoch 1.941), train_loss = 1.83260996, grad/param norm = 3.1291e-01, time/batch = 0.6892s	
1292/33250 (epoch 1.943), train_loss = 1.91933604, grad/param norm = 2.5131e-01, time/batch = 0.6799s	
1293/33250 (epoch 1.944), train_loss = 1.60186756, grad/param norm = 2.7468e-01, time/batch = 0.6820s	
1294/33250 (epoch 1.946), train_loss = 2.02314625, grad/param norm = 2.6509e-01, time/batch = 0.6875s	
1295/33250 (epoch 1.947), train_loss = 1.69448153, grad/param norm = 2.3700e-01, time/batch = 0.6866s	
1296/33250 (epoch 1.949), train_loss = 1.92996191, grad/param norm = 2.7140e-01, time/batch = 0.6897s	
1297/33250 (epoch 1.950), train_loss = 1.78143212, grad/param norm = 2.7200e-01, time/batch = 0.6865s	
1298/33250 (epoch 1.952), train_loss = 1.82484794, grad/param norm = 2.4633e-01, time/batch = 0.6865s	
1299/33250 (epoch 1.953), train_loss = 1.82877988, grad/param norm = 2.5333e-01, time/batch = 0.6965s	
1300/33250 (epoch 1.955), train_loss = 1.88564679, grad/param norm = 2.8103e-01, time/batch = 0.7134s	
1301/33250 (epoch 1.956), train_loss = 1.95519645, grad/param norm = 2.7137e-01, time/batch = 0.7379s	
1302/33250 (epoch 1.958), train_loss = 1.69162357, grad/param norm = 2.3408e-01, time/batch = 0.7363s	
1303/33250 (epoch 1.959), train_loss = 1.63806060, grad/param norm = 2.1836e-01, time/batch = 0.7276s	
1304/33250 (epoch 1.961), train_loss = 1.82671882, grad/param norm = 2.6493e-01, time/batch = 0.7113s	
1305/33250 (epoch 1.962), train_loss = 1.85416003, grad/param norm = 2.8902e-01, time/batch = 0.7134s	
1306/33250 (epoch 1.964), train_loss = 1.80471350, grad/param norm = 2.6778e-01, time/batch = 0.7124s	
1307/33250 (epoch 1.965), train_loss = 1.84660433, grad/param norm = 2.6207e-01, time/batch = 0.7050s	
1308/33250 (epoch 1.967), train_loss = 1.88880034, grad/param norm = 2.4845e-01, time/batch = 0.7003s	
1309/33250 (epoch 1.968), train_loss = 1.87041366, grad/param norm = 2.5920e-01, time/batch = 0.6933s	
1310/33250 (epoch 1.970), train_loss = 2.05249082, grad/param norm = 3.1471e-01, time/batch = 0.6960s	
1311/33250 (epoch 1.971), train_loss = 1.97447112, grad/param norm = 2.4428e-01, time/batch = 0.7002s	
1312/33250 (epoch 1.973), train_loss = 1.74823912, grad/param norm = 2.2707e-01, time/batch = 0.6988s	
1313/33250 (epoch 1.974), train_loss = 1.81794024, grad/param norm = 2.6072e-01, time/batch = 0.7085s	
1314/33250 (epoch 1.976), train_loss = 1.66195200, grad/param norm = 2.5356e-01, time/batch = 0.7053s	
1315/33250 (epoch 1.977), train_loss = 1.62491853, grad/param norm = 2.7826e-01, time/batch = 0.7090s	
1316/33250 (epoch 1.979), train_loss = 1.72761052, grad/param norm = 3.1155e-01, time/batch = 0.7129s	
1317/33250 (epoch 1.980), train_loss = 1.69614159, grad/param norm = 2.6026e-01, time/batch = 0.7409s	
1318/33250 (epoch 1.982), train_loss = 1.60805908, grad/param norm = 2.3544e-01, time/batch = 0.7244s	
1319/33250 (epoch 1.983), train_loss = 1.85899398, grad/param norm = 2.4652e-01, time/batch = 0.7175s	
1320/33250 (epoch 1.985), train_loss = 1.62974678, grad/param norm = 2.6058e-01, time/batch = 0.7167s	
1321/33250 (epoch 1.986), train_loss = 1.96308551, grad/param norm = 2.9193e-01, time/batch = 0.7002s	
1322/33250 (epoch 1.988), train_loss = 1.74257407, grad/param norm = 3.6361e-01, time/batch = 0.6909s	
1323/33250 (epoch 1.989), train_loss = 1.85700809, grad/param norm = 2.4825e-01, time/batch = 0.6902s	
1324/33250 (epoch 1.991), train_loss = 1.74852453, grad/param norm = 2.3226e-01, time/batch = 0.6905s	
1325/33250 (epoch 1.992), train_loss = 1.69952428, grad/param norm = 2.4899e-01, time/batch = 0.6882s	
1326/33250 (epoch 1.994), train_loss = 1.60809597, grad/param norm = 2.4472e-01, time/batch = 0.6913s	
1327/33250 (epoch 1.995), train_loss = 1.79769145, grad/param norm = 2.7895e-01, time/batch = 0.6897s	
1328/33250 (epoch 1.997), train_loss = 1.44503144, grad/param norm = 2.4076e-01, time/batch = 0.6897s	
1329/33250 (epoch 1.998), train_loss = 1.77262291, grad/param norm = 2.6543e-01, time/batch = 0.6917s	
1330/33250 (epoch 2.000), train_loss = 1.75952659, grad/param norm = 2.6630e-01, time/batch = 0.6931s	
1331/33250 (epoch 2.002), train_loss = 1.89391080, grad/param norm = 2.5029e-01, time/batch = 0.6892s	
1332/33250 (epoch 2.003), train_loss = 1.79001900, grad/param norm = 2.6403e-01, time/batch = 0.6857s	
1333/33250 (epoch 2.005), train_loss = 1.61356421, grad/param norm = 2.7977e-01, time/batch = 0.6894s	
1334/33250 (epoch 2.006), train_loss = 1.51870088, grad/param norm = 2.4907e-01, time/batch = 0.7159s	
1335/33250 (epoch 2.008), train_loss = 1.79660282, grad/param norm = 2.5562e-01, time/batch = 0.7139s	
1336/33250 (epoch 2.009), train_loss = 1.86446878, grad/param norm = 2.7012e-01, time/batch = 0.6943s	
1337/33250 (epoch 2.011), train_loss = 1.73454211, grad/param norm = 2.4818e-01, time/batch = 0.6892s	
1338/33250 (epoch 2.012), train_loss = 1.87140357, grad/param norm = 2.6733e-01, time/batch = 0.6882s	
1339/33250 (epoch 2.014), train_loss = 1.76823349, grad/param norm = 2.2708e-01, time/batch = 0.6897s	
1340/33250 (epoch 2.015), train_loss = 1.78064731, grad/param norm = 2.8510e-01, time/batch = 0.6881s	
1341/33250 (epoch 2.017), train_loss = 1.80508811, grad/param norm = 2.6442e-01, time/batch = 0.6942s	
1342/33250 (epoch 2.018), train_loss = 1.61542826, grad/param norm = 2.6516e-01, time/batch = 0.6924s	
1343/33250 (epoch 2.020), train_loss = 1.68294859, grad/param norm = 2.3774e-01, time/batch = 0.6871s	
1344/33250 (epoch 2.021), train_loss = 1.74402913, grad/param norm = 2.6039e-01, time/batch = 0.6859s	
1345/33250 (epoch 2.023), train_loss = 1.61124035, grad/param norm = 2.7738e-01, time/batch = 0.6968s	
1346/33250 (epoch 2.024), train_loss = 1.82884233, grad/param norm = 2.9016e-01, time/batch = 0.6813s	
1347/33250 (epoch 2.026), train_loss = 1.66183431, grad/param norm = 2.8967e-01, time/batch = 0.6776s	
1348/33250 (epoch 2.027), train_loss = 1.66802921, grad/param norm = 2.8810e-01, time/batch = 0.6806s	
1349/33250 (epoch 2.029), train_loss = 1.71332110, grad/param norm = 2.6370e-01, time/batch = 0.6901s	
1350/33250 (epoch 2.030), train_loss = 1.77917216, grad/param norm = 2.7785e-01, time/batch = 0.6821s	
1351/33250 (epoch 2.032), train_loss = 1.96758753, grad/param norm = 2.7441e-01, time/batch = 0.6843s	
1352/33250 (epoch 2.033), train_loss = 1.64827272, grad/param norm = 2.6986e-01, time/batch = 0.6824s	
1353/33250 (epoch 2.035), train_loss = 1.63566939, grad/param norm = 2.4656e-01, time/batch = 0.7009s	
1354/33250 (epoch 2.036), train_loss = 1.73035690, grad/param norm = 2.5409e-01, time/batch = 0.7239s	
1355/33250 (epoch 2.038), train_loss = 1.57812378, grad/param norm = 2.7633e-01, time/batch = 0.7253s	
1356/33250 (epoch 2.039), train_loss = 1.60876897, grad/param norm = 2.9085e-01, time/batch = 0.7044s	
1357/33250 (epoch 2.041), train_loss = 1.85242855, grad/param norm = 2.7097e-01, time/batch = 0.6972s	
1358/33250 (epoch 2.042), train_loss = 1.50560800, grad/param norm = 2.1501e-01, time/batch = 0.6916s	
1359/33250 (epoch 2.044), train_loss = 1.92266335, grad/param norm = 2.3486e-01, time/batch = 0.6921s	
1360/33250 (epoch 2.045), train_loss = 1.75242963, grad/param norm = 2.3189e-01, time/batch = 0.7012s	
1361/33250 (epoch 2.047), train_loss = 1.89550961, grad/param norm = 2.7176e-01, time/batch = 0.6880s	
1362/33250 (epoch 2.048), train_loss = 1.93694025, grad/param norm = 2.5917e-01, time/batch = 0.6813s	
1363/33250 (epoch 2.050), train_loss = 1.75232893, grad/param norm = 2.5083e-01, time/batch = 0.6744s	
1364/33250 (epoch 2.051), train_loss = 1.70699711, grad/param norm = 2.2278e-01, time/batch = 0.6818s	
1365/33250 (epoch 2.053), train_loss = 1.81659508, grad/param norm = 2.4244e-01, time/batch = 0.6928s	
1366/33250 (epoch 2.054), train_loss = 1.53688649, grad/param norm = 2.4930e-01, time/batch = 0.6888s	
1367/33250 (epoch 2.056), train_loss = 1.68139591, grad/param norm = 2.9795e-01, time/batch = 0.6822s	
1368/33250 (epoch 2.057), train_loss = 1.66359253, grad/param norm = 2.6968e-01, time/batch = 0.6806s	
1369/33250 (epoch 2.059), train_loss = 1.62337892, grad/param norm = 2.5627e-01, time/batch = 0.6793s	
1370/33250 (epoch 2.060), train_loss = 1.78471722, grad/param norm = 2.7620e-01, time/batch = 0.6830s	
1371/33250 (epoch 2.062), train_loss = 1.85783117, grad/param norm = 2.5470e-01, time/batch = 0.6855s	
1372/33250 (epoch 2.063), train_loss = 1.85214507, grad/param norm = 2.4825e-01, time/batch = 0.6795s	
1373/33250 (epoch 2.065), train_loss = 1.79054818, grad/param norm = 2.5307e-01, time/batch = 0.6808s	
1374/33250 (epoch 2.066), train_loss = 1.83587139, grad/param norm = 2.4200e-01, time/batch = 0.6800s	
1375/33250 (epoch 2.068), train_loss = 1.72781391, grad/param norm = 2.5077e-01, time/batch = 0.6790s	
1376/33250 (epoch 2.069), train_loss = 1.75649234, grad/param norm = 2.3113e-01, time/batch = 0.6770s	
1377/33250 (epoch 2.071), train_loss = 1.57287519, grad/param norm = 2.2184e-01, time/batch = 0.6777s	
1378/33250 (epoch 2.072), train_loss = 1.63593368, grad/param norm = 2.1894e-01, time/batch = 0.6775s	
1379/33250 (epoch 2.074), train_loss = 1.72597125, grad/param norm = 2.4148e-01, time/batch = 0.6797s	
1380/33250 (epoch 2.075), train_loss = 1.62802845, grad/param norm = 2.1872e-01, time/batch = 0.6790s	
1381/33250 (epoch 2.077), train_loss = 1.79652715, grad/param norm = 2.3409e-01, time/batch = 0.6824s	
1382/33250 (epoch 2.078), train_loss = 1.58604460, grad/param norm = 2.2430e-01, time/batch = 0.6813s	
1383/33250 (epoch 2.080), train_loss = 1.77152949, grad/param norm = 2.6686e-01, time/batch = 0.6883s	
1384/33250 (epoch 2.081), train_loss = 1.79783428, grad/param norm = 2.9057e-01, time/batch = 0.6913s	
1385/33250 (epoch 2.083), train_loss = 1.80214018, grad/param norm = 3.0757e-01, time/batch = 0.6983s	
1386/33250 (epoch 2.084), train_loss = 1.69536014, grad/param norm = 2.4115e-01, time/batch = 0.7084s	
1387/33250 (epoch 2.086), train_loss = 1.71491920, grad/param norm = 2.3491e-01, time/batch = 0.6936s	
1388/33250 (epoch 2.087), train_loss = 1.56350066, grad/param norm = 2.5766e-01, time/batch = 0.6820s	
1389/33250 (epoch 2.089), train_loss = 1.77040469, grad/param norm = 2.3820e-01, time/batch = 0.6809s	
1390/33250 (epoch 2.090), train_loss = 1.66955556, grad/param norm = 2.7386e-01, time/batch = 0.6856s	
1391/33250 (epoch 2.092), train_loss = 1.56438437, grad/param norm = 2.5069e-01, time/batch = 0.6905s	
1392/33250 (epoch 2.093), train_loss = 1.64605038, grad/param norm = 2.7376e-01, time/batch = 0.6820s	
1393/33250 (epoch 2.095), train_loss = 1.69232364, grad/param norm = 2.5096e-01, time/batch = 0.6809s	
1394/33250 (epoch 2.096), train_loss = 1.59841370, grad/param norm = 2.2711e-01, time/batch = 0.6836s	
1395/33250 (epoch 2.098), train_loss = 1.55845329, grad/param norm = 2.5447e-01, time/batch = 0.7127s	
1396/33250 (epoch 2.099), train_loss = 1.50774174, grad/param norm = 2.8280e-01, time/batch = 0.7266s	
1397/33250 (epoch 2.101), train_loss = 1.71874667, grad/param norm = 2.8191e-01, time/batch = 0.6929s	
1398/33250 (epoch 2.102), train_loss = 1.53360842, grad/param norm = 2.1615e-01, time/batch = 0.6870s	
1399/33250 (epoch 2.104), train_loss = 1.48553558, grad/param norm = 2.1381e-01, time/batch = 0.6811s	
1400/33250 (epoch 2.105), train_loss = 1.65043701, grad/param norm = 2.2621e-01, time/batch = 0.6792s	
1401/33250 (epoch 2.107), train_loss = 1.38692880, grad/param norm = 2.2113e-01, time/batch = 0.6804s	
1402/33250 (epoch 2.108), train_loss = 1.68598504, grad/param norm = 2.6418e-01, time/batch = 0.6856s	
1403/33250 (epoch 2.110), train_loss = 1.52621621, grad/param norm = 2.3565e-01, time/batch = 0.6954s	
1404/33250 (epoch 2.111), train_loss = 1.61616634, grad/param norm = 2.3379e-01, time/batch = 0.6966s	
1405/33250 (epoch 2.113), train_loss = 1.62057773, grad/param norm = 2.5171e-01, time/batch = 0.6892s	
1406/33250 (epoch 2.114), train_loss = 1.65587181, grad/param norm = 2.6266e-01, time/batch = 0.6856s	
1407/33250 (epoch 2.116), train_loss = 1.72493024, grad/param norm = 2.5788e-01, time/batch = 0.6837s	
1408/33250 (epoch 2.117), train_loss = 1.68336030, grad/param norm = 2.6345e-01, time/batch = 0.6839s	
1409/33250 (epoch 2.119), train_loss = 1.59590163, grad/param norm = 2.1344e-01, time/batch = 0.6823s	
1410/33250 (epoch 2.120), train_loss = 1.37277287, grad/param norm = 2.8294e-01, time/batch = 0.6943s	
1411/33250 (epoch 2.122), train_loss = 1.76160429, grad/param norm = 2.4237e-01, time/batch = 0.6848s	
1412/33250 (epoch 2.123), train_loss = 1.73704161, grad/param norm = 2.4807e-01, time/batch = 0.7035s	
1413/33250 (epoch 2.125), train_loss = 1.52983506, grad/param norm = 2.5370e-01, time/batch = 0.7128s	
1414/33250 (epoch 2.126), train_loss = 1.73243836, grad/param norm = 2.6040e-01, time/batch = 0.7135s	
1415/33250 (epoch 2.128), train_loss = 1.56946730, grad/param norm = 2.4787e-01, time/batch = 0.7284s	
1416/33250 (epoch 2.129), train_loss = 1.60499977, grad/param norm = 2.5855e-01, time/batch = 0.7266s	
1417/33250 (epoch 2.131), train_loss = 1.70701494, grad/param norm = 2.3859e-01, time/batch = 0.7186s	
1418/33250 (epoch 2.132), train_loss = 1.62566673, grad/param norm = 2.1455e-01, time/batch = 0.7102s	
1419/33250 (epoch 2.134), train_loss = 1.75012119, grad/param norm = 2.5147e-01, time/batch = 0.7084s	
1420/33250 (epoch 2.135), train_loss = 1.75207438, grad/param norm = 2.3041e-01, time/batch = 0.7032s	
1421/33250 (epoch 2.137), train_loss = 1.50814216, grad/param norm = 2.3674e-01, time/batch = 0.7092s	
1422/33250 (epoch 2.138), train_loss = 1.57442310, grad/param norm = 2.3651e-01, time/batch = 0.6862s	
1423/33250 (epoch 2.140), train_loss = 1.55828667, grad/param norm = 2.5109e-01, time/batch = 0.6821s	
1424/33250 (epoch 2.141), train_loss = 2.04855586, grad/param norm = 2.7220e-01, time/batch = 0.6920s	
1425/33250 (epoch 2.143), train_loss = 1.42561159, grad/param norm = 2.8502e-01, time/batch = 0.6905s	
1426/33250 (epoch 2.144), train_loss = 1.55797227, grad/param norm = 2.1267e-01, time/batch = 0.6870s	
1427/33250 (epoch 2.146), train_loss = 1.51484879, grad/param norm = 2.3045e-01, time/batch = 0.7049s	
1428/33250 (epoch 2.147), train_loss = 1.57395022, grad/param norm = 2.8040e-01, time/batch = 0.6851s	
1429/33250 (epoch 2.149), train_loss = 1.71080371, grad/param norm = 2.3676e-01, time/batch = 0.6916s	
1430/33250 (epoch 2.150), train_loss = 1.47267709, grad/param norm = 2.5126e-01, time/batch = 0.7045s	
1431/33250 (epoch 2.152), train_loss = 1.50440633, grad/param norm = 2.2571e-01, time/batch = 0.6943s	
1432/33250 (epoch 2.153), train_loss = 1.71320915, grad/param norm = 2.8677e-01, time/batch = 0.6902s	
1433/33250 (epoch 2.155), train_loss = 1.70474401, grad/param norm = 2.4783e-01, time/batch = 0.6928s	
1434/33250 (epoch 2.156), train_loss = 1.65307435, grad/param norm = 2.7022e-01, time/batch = 0.6859s	
1435/33250 (epoch 2.158), train_loss = 2.05474442, grad/param norm = 2.8970e-01, time/batch = 0.6890s	
1436/33250 (epoch 2.159), train_loss = 1.67977570, grad/param norm = 2.4058e-01, time/batch = 0.6847s	
1437/33250 (epoch 2.161), train_loss = 1.75337408, grad/param norm = 2.6597e-01, time/batch = 0.6843s	
1438/33250 (epoch 2.162), train_loss = 1.64037769, grad/param norm = 2.6036e-01, time/batch = 0.6883s	
1439/33250 (epoch 2.164), train_loss = 1.75271418, grad/param norm = 2.4641e-01, time/batch = 0.6881s	
1440/33250 (epoch 2.165), train_loss = 1.70736164, grad/param norm = 2.4256e-01, time/batch = 0.7024s	
1441/33250 (epoch 2.167), train_loss = 1.71787477, grad/param norm = 2.4575e-01, time/batch = 0.7179s	
1442/33250 (epoch 2.168), train_loss = 1.45922660, grad/param norm = 2.0963e-01, time/batch = 0.7168s	
1443/33250 (epoch 2.170), train_loss = 1.62164467, grad/param norm = 2.5808e-01, time/batch = 0.7140s	
1444/33250 (epoch 2.171), train_loss = 1.56336240, grad/param norm = 2.1985e-01, time/batch = 0.7134s	
1445/33250 (epoch 2.173), train_loss = 1.52458776, grad/param norm = 2.7182e-01, time/batch = 0.7109s	
1446/33250 (epoch 2.174), train_loss = 1.64112104, grad/param norm = 3.0623e-01, time/batch = 0.7208s	
1447/33250 (epoch 2.176), train_loss = 1.76405231, grad/param norm = 2.7970e-01, time/batch = 0.7094s	
1448/33250 (epoch 2.177), train_loss = 1.39157018, grad/param norm = 1.9931e-01, time/batch = 0.7123s	
1449/33250 (epoch 2.179), train_loss = 1.63532306, grad/param norm = 2.4129e-01, time/batch = 0.7091s	
1450/33250 (epoch 2.180), train_loss = 1.54897524, grad/param norm = 2.2226e-01, time/batch = 0.7077s	
1451/33250 (epoch 2.182), train_loss = 1.63022925, grad/param norm = 2.6664e-01, time/batch = 0.7095s	
1452/33250 (epoch 2.183), train_loss = 1.88651456, grad/param norm = 2.5410e-01, time/batch = 0.7017s	
1453/33250 (epoch 2.185), train_loss = 1.73306599, grad/param norm = 2.7512e-01, time/batch = 0.7005s	
1454/33250 (epoch 2.186), train_loss = 1.54437123, grad/param norm = 2.3922e-01, time/batch = 0.7003s	
1455/33250 (epoch 2.188), train_loss = 1.76791254, grad/param norm = 2.4072e-01, time/batch = 0.6992s	
1456/33250 (epoch 2.189), train_loss = 1.44223536, grad/param norm = 2.3187e-01, time/batch = 0.7007s	
1457/33250 (epoch 2.191), train_loss = 1.56211830, grad/param norm = 2.2686e-01, time/batch = 0.6998s	
1458/33250 (epoch 2.192), train_loss = 1.54963306, grad/param norm = 2.4642e-01, time/batch = 0.6943s	
1459/33250 (epoch 2.194), train_loss = 1.39735663, grad/param norm = 2.5204e-01, time/batch = 0.7184s	
1460/33250 (epoch 2.195), train_loss = 1.77622506, grad/param norm = 2.5236e-01, time/batch = 0.6919s	
1461/33250 (epoch 2.197), train_loss = 1.66936520, grad/param norm = 2.6224e-01, time/batch = 0.6979s	
1462/33250 (epoch 2.198), train_loss = 1.80962942, grad/param norm = 3.0584e-01, time/batch = 0.6921s	
1463/33250 (epoch 2.200), train_loss = 1.63653926, grad/param norm = 2.5588e-01, time/batch = 0.6940s	
1464/33250 (epoch 2.202), train_loss = 1.61984109, grad/param norm = 2.5451e-01, time/batch = 0.7011s	
1465/33250 (epoch 2.203), train_loss = 1.69416306, grad/param norm = 2.4853e-01, time/batch = 0.6914s	
1466/33250 (epoch 2.205), train_loss = 1.70518097, grad/param norm = 2.5608e-01, time/batch = 0.6902s	
1467/33250 (epoch 2.206), train_loss = 1.67601918, grad/param norm = 2.7615e-01, time/batch = 0.6930s	
1468/33250 (epoch 2.208), train_loss = 1.96422909, grad/param norm = 2.6390e-01, time/batch = 0.6967s	
1469/33250 (epoch 2.209), train_loss = 1.53714641, grad/param norm = 2.6327e-01, time/batch = 0.6966s	
1470/33250 (epoch 2.211), train_loss = 1.81438587, grad/param norm = 2.3999e-01, time/batch = 0.7015s	
1471/33250 (epoch 2.212), train_loss = 1.86311519, grad/param norm = 3.0999e-01, time/batch = 0.7153s	
1472/33250 (epoch 2.214), train_loss = 1.65052901, grad/param norm = 2.7351e-01, time/batch = 0.7226s	
1473/33250 (epoch 2.215), train_loss = 2.07408014, grad/param norm = 2.6885e-01, time/batch = 0.6963s	
1474/33250 (epoch 2.217), train_loss = 1.75749738, grad/param norm = 2.3850e-01, time/batch = 0.6995s	
1475/33250 (epoch 2.218), train_loss = 1.75563035, grad/param norm = 2.5022e-01, time/batch = 0.7027s	
1476/33250 (epoch 2.220), train_loss = 1.85065180, grad/param norm = 2.5721e-01, time/batch = 0.6953s	
1477/33250 (epoch 2.221), train_loss = 1.99659060, grad/param norm = 2.4962e-01, time/batch = 0.6965s	
1478/33250 (epoch 2.223), train_loss = 1.73400883, grad/param norm = 2.7772e-01, time/batch = 0.6950s	
1479/33250 (epoch 2.224), train_loss = 1.78195293, grad/param norm = 2.6095e-01, time/batch = 0.6949s	
1480/33250 (epoch 2.226), train_loss = 1.80593006, grad/param norm = 2.3916e-01, time/batch = 0.7000s	
1481/33250 (epoch 2.227), train_loss = 1.76168332, grad/param norm = 2.4540e-01, time/batch = 0.7019s	
1482/33250 (epoch 2.229), train_loss = 1.65142339, grad/param norm = 2.3145e-01, time/batch = 0.6990s	
1483/33250 (epoch 2.230), train_loss = 1.65997924, grad/param norm = 2.5787e-01, time/batch = 0.7006s	
1484/33250 (epoch 2.232), train_loss = 1.56961502, grad/param norm = 2.3018e-01, time/batch = 0.6972s	
1485/33250 (epoch 2.233), train_loss = 1.63857498, grad/param norm = 2.1614e-01, time/batch = 0.7031s	
1486/33250 (epoch 2.235), train_loss = 1.75240499, grad/param norm = 2.6203e-01, time/batch = 0.7041s	
1487/33250 (epoch 2.236), train_loss = 1.60006619, grad/param norm = 3.0532e-01, time/batch = 0.7045s	
1488/33250 (epoch 2.238), train_loss = 1.68615057, grad/param norm = 2.5386e-01, time/batch = 0.7047s	
1489/33250 (epoch 2.239), train_loss = 1.90897643, grad/param norm = 2.8010e-01, time/batch = 0.7118s	
1490/33250 (epoch 2.241), train_loss = 1.83552828, grad/param norm = 3.1203e-01, time/batch = 0.7032s	
1491/33250 (epoch 2.242), train_loss = 1.65237216, grad/param norm = 2.5447e-01, time/batch = 0.7125s	
1492/33250 (epoch 2.244), train_loss = 1.78181035, grad/param norm = 2.4655e-01, time/batch = 0.7059s	
1493/33250 (epoch 2.245), train_loss = 1.63833507, grad/param norm = 2.4109e-01, time/batch = 0.6911s	
1494/33250 (epoch 2.247), train_loss = 1.80851163, grad/param norm = 2.2350e-01, time/batch = 0.6982s	
1495/33250 (epoch 2.248), train_loss = 1.97135852, grad/param norm = 2.2963e-01, time/batch = 0.6973s	
1496/33250 (epoch 2.250), train_loss = 1.67778484, grad/param norm = 2.2037e-01, time/batch = 0.6991s	
1497/33250 (epoch 2.251), train_loss = 1.72711236, grad/param norm = 2.6118e-01, time/batch = 0.7006s	
1498/33250 (epoch 2.253), train_loss = 1.52367883, grad/param norm = 2.4380e-01, time/batch = 0.7004s	
1499/33250 (epoch 2.254), train_loss = 1.60797958, grad/param norm = 2.6129e-01, time/batch = 0.6983s	
1500/33250 (epoch 2.256), train_loss = 1.84697496, grad/param norm = 2.8781e-01, time/batch = 0.6959s	
1501/33250 (epoch 2.257), train_loss = 1.89118284, grad/param norm = 2.7516e-01, time/batch = 0.7048s	
1502/33250 (epoch 2.259), train_loss = 1.88210159, grad/param norm = 2.3856e-01, time/batch = 0.6966s	
1503/33250 (epoch 2.260), train_loss = 1.53621304, grad/param norm = 2.1853e-01, time/batch = 0.6909s	
1504/33250 (epoch 2.262), train_loss = 1.72833643, grad/param norm = 2.0414e-01, time/batch = 0.6990s	
1505/33250 (epoch 2.263), train_loss = 1.62863508, grad/param norm = 2.1582e-01, time/batch = 0.7028s	
1506/33250 (epoch 2.265), train_loss = 1.71678456, grad/param norm = 2.2973e-01, time/batch = 0.7078s	
1507/33250 (epoch 2.266), train_loss = 1.66361899, grad/param norm = 2.5541e-01, time/batch = 0.7165s	
1508/33250 (epoch 2.268), train_loss = 1.55759717, grad/param norm = 2.2826e-01, time/batch = 0.7085s	
1509/33250 (epoch 2.269), train_loss = 1.39684326, grad/param norm = 2.2205e-01, time/batch = 0.7095s	
1510/33250 (epoch 2.271), train_loss = 1.70563284, grad/param norm = 2.2242e-01, time/batch = 0.7129s	
1511/33250 (epoch 2.272), train_loss = 1.32766642, grad/param norm = 1.8404e-01, time/batch = 0.7007s	
1512/33250 (epoch 2.274), train_loss = 1.35797972, grad/param norm = 2.0640e-01, time/batch = 0.6983s	
1513/33250 (epoch 2.275), train_loss = 1.51608219, grad/param norm = 2.1329e-01, time/batch = 0.6956s	
1514/33250 (epoch 2.277), train_loss = 1.40002336, grad/param norm = 2.2752e-01, time/batch = 0.7221s	
1515/33250 (epoch 2.278), train_loss = 1.43120883, grad/param norm = 2.0542e-01, time/batch = 0.6947s	
1516/33250 (epoch 2.280), train_loss = 1.42417790, grad/param norm = 2.3930e-01, time/batch = 0.7101s	
1517/33250 (epoch 2.281), train_loss = 1.54888851, grad/param norm = 2.4163e-01, time/batch = 0.7109s	
1518/33250 (epoch 2.283), train_loss = 1.64852078, grad/param norm = 2.4120e-01, time/batch = 0.7116s	
1519/33250 (epoch 2.284), train_loss = 1.59197975, grad/param norm = 2.1866e-01, time/batch = 0.7088s	
1520/33250 (epoch 2.286), train_loss = 1.70676436, grad/param norm = 2.4356e-01, time/batch = 0.7138s	
1521/33250 (epoch 2.287), train_loss = 1.50659291, grad/param norm = 2.3300e-01, time/batch = 0.7132s	
1522/33250 (epoch 2.289), train_loss = 1.50471404, grad/param norm = 2.5526e-01, time/batch = 0.7117s	
1523/33250 (epoch 2.290), train_loss = 1.53897900, grad/param norm = 2.0269e-01, time/batch = 0.7152s	
1524/33250 (epoch 2.292), train_loss = 1.61494644, grad/param norm = 2.3729e-01, time/batch = 0.7217s	
1525/33250 (epoch 2.293), train_loss = 1.77724230, grad/param norm = 2.6477e-01, time/batch = 0.7289s	
1526/33250 (epoch 2.295), train_loss = 1.61351284, grad/param norm = 2.2173e-01, time/batch = 0.7133s	
1527/33250 (epoch 2.296), train_loss = 1.58909595, grad/param norm = 2.1509e-01, time/batch = 0.7216s	
1528/33250 (epoch 2.298), train_loss = 1.36734545, grad/param norm = 2.0570e-01, time/batch = 0.7293s	
1529/33250 (epoch 2.299), train_loss = 1.35968709, grad/param norm = 2.2244e-01, time/batch = 0.7218s	
1530/33250 (epoch 2.301), train_loss = 1.68106401, grad/param norm = 2.1533e-01, time/batch = 0.7121s	
1531/33250 (epoch 2.302), train_loss = 1.56594065, grad/param norm = 2.5969e-01, time/batch = 0.7103s	
1532/33250 (epoch 2.304), train_loss = 1.52645552, grad/param norm = 2.2106e-01, time/batch = 0.7040s	
1533/33250 (epoch 2.305), train_loss = 1.51886331, grad/param norm = 1.9574e-01, time/batch = 0.7075s	
1534/33250 (epoch 2.307), train_loss = 1.78394375, grad/param norm = 2.2961e-01, time/batch = 0.6889s	
1535/33250 (epoch 2.308), train_loss = 1.84343330, grad/param norm = 2.5689e-01, time/batch = 0.6811s	
1536/33250 (epoch 2.310), train_loss = 1.64814993, grad/param norm = 2.5516e-01, time/batch = 0.6823s	
1537/33250 (epoch 2.311), train_loss = 1.69914124, grad/param norm = 2.3463e-01, time/batch = 0.6782s	
1538/33250 (epoch 2.313), train_loss = 1.58606255, grad/param norm = 2.7357e-01, time/batch = 0.6807s	
1539/33250 (epoch 2.314), train_loss = 1.61877388, grad/param norm = 2.3706e-01, time/batch = 0.6817s	
1540/33250 (epoch 2.316), train_loss = 1.77948150, grad/param norm = 2.1220e-01, time/batch = 0.6801s	
1541/33250 (epoch 2.317), train_loss = 1.55658017, grad/param norm = 2.4250e-01, time/batch = 0.6825s	
1542/33250 (epoch 2.319), train_loss = 1.81209582, grad/param norm = 2.6529e-01, time/batch = 0.6811s	
1543/33250 (epoch 2.320), train_loss = 1.91183758, grad/param norm = 2.8683e-01, time/batch = 0.6786s	
1544/33250 (epoch 2.322), train_loss = 1.87022781, grad/param norm = 2.7630e-01, time/batch = 0.6796s	
1545/33250 (epoch 2.323), train_loss = 1.91879584, grad/param norm = 2.6942e-01, time/batch = 0.6786s	
1546/33250 (epoch 2.325), train_loss = 1.64095375, grad/param norm = 2.3348e-01, time/batch = 0.6776s	
1547/33250 (epoch 2.326), train_loss = 1.85958850, grad/param norm = 2.6869e-01, time/batch = 0.6763s	
1548/33250 (epoch 2.328), train_loss = 1.62619412, grad/param norm = 2.4064e-01, time/batch = 0.6779s	
1549/33250 (epoch 2.329), train_loss = 1.75867865, grad/param norm = 2.3748e-01, time/batch = 0.6764s	
1550/33250 (epoch 2.331), train_loss = 1.52850776, grad/param norm = 2.1033e-01, time/batch = 0.6753s	
1551/33250 (epoch 2.332), train_loss = 1.55145070, grad/param norm = 2.2699e-01, time/batch = 0.6844s	
1552/33250 (epoch 2.334), train_loss = 1.76741194, grad/param norm = 2.5322e-01, time/batch = 0.6833s	
1553/33250 (epoch 2.335), train_loss = 1.33120002, grad/param norm = 2.1905e-01, time/batch = 0.6784s	
1554/33250 (epoch 2.337), train_loss = 1.65475704, grad/param norm = 2.2055e-01, time/batch = 0.6814s	
1555/33250 (epoch 2.338), train_loss = 1.71853578, grad/param norm = 2.3650e-01, time/batch = 0.6905s	
1556/33250 (epoch 2.340), train_loss = 1.65245069, grad/param norm = 2.5056e-01, time/batch = 0.6934s	
1557/33250 (epoch 2.341), train_loss = 1.64580268, grad/param norm = 2.5975e-01, time/batch = 0.7154s	
1558/33250 (epoch 2.343), train_loss = 1.76478248, grad/param norm = 3.0638e-01, time/batch = 0.6856s	
1559/33250 (epoch 2.344), train_loss = 1.63037258, grad/param norm = 2.4633e-01, time/batch = 0.6819s	
1560/33250 (epoch 2.346), train_loss = 1.41412344, grad/param norm = 2.1940e-01, time/batch = 0.6783s	
1561/33250 (epoch 2.347), train_loss = 1.97607902, grad/param norm = 2.5032e-01, time/batch = 0.6819s	
1562/33250 (epoch 2.349), train_loss = 1.68362061, grad/param norm = 2.7312e-01, time/batch = 0.6864s	
1563/33250 (epoch 2.350), train_loss = 1.66572636, grad/param norm = 2.6036e-01, time/batch = 0.6810s	
1564/33250 (epoch 2.352), train_loss = 1.54603181, grad/param norm = 2.5251e-01, time/batch = 0.7101s	
1565/33250 (epoch 2.353), train_loss = 1.59428635, grad/param norm = 2.1504e-01, time/batch = 0.7015s	
1566/33250 (epoch 2.355), train_loss = 1.54382846, grad/param norm = 2.2774e-01, time/batch = 0.6947s	
1567/33250 (epoch 2.356), train_loss = 1.51842360, grad/param norm = 2.3518e-01, time/batch = 0.7037s	
1568/33250 (epoch 2.358), train_loss = 1.56499701, grad/param norm = 2.4877e-01, time/batch = 0.7374s	
1569/33250 (epoch 2.359), train_loss = 1.48512360, grad/param norm = 2.3875e-01, time/batch = 0.7190s	
1570/33250 (epoch 2.361), train_loss = 1.85819060, grad/param norm = 2.3876e-01, time/batch = 0.6957s	
1571/33250 (epoch 2.362), train_loss = 1.57739734, grad/param norm = 2.1992e-01, time/batch = 0.7024s	
1572/33250 (epoch 2.364), train_loss = 1.79575212, grad/param norm = 2.1679e-01, time/batch = 0.6988s	
1573/33250 (epoch 2.365), train_loss = 1.60413234, grad/param norm = 2.4443e-01, time/batch = 0.6990s	
1574/33250 (epoch 2.367), train_loss = 1.52776958, grad/param norm = 2.1076e-01, time/batch = 0.6976s	
1575/33250 (epoch 2.368), train_loss = 1.61728732, grad/param norm = 2.1597e-01, time/batch = 0.6948s	
1576/33250 (epoch 2.370), train_loss = 1.44466879, grad/param norm = 2.3728e-01, time/batch = 0.6947s	
1577/33250 (epoch 2.371), train_loss = 1.70155220, grad/param norm = 2.3455e-01, time/batch = 0.7001s	
1578/33250 (epoch 2.373), train_loss = 1.55266025, grad/param norm = 2.2983e-01, time/batch = 0.7023s	
1579/33250 (epoch 2.374), train_loss = 1.72964130, grad/param norm = 2.7196e-01, time/batch = 0.7244s	
1580/33250 (epoch 2.376), train_loss = 1.58686872, grad/param norm = 2.4467e-01, time/batch = 0.7342s	
1581/33250 (epoch 2.377), train_loss = 1.52626668, grad/param norm = 2.7151e-01, time/batch = 0.7080s	
1582/33250 (epoch 2.379), train_loss = 1.55627817, grad/param norm = 2.4373e-01, time/batch = 0.7086s	
1583/33250 (epoch 2.380), train_loss = 1.69950394, grad/param norm = 2.4056e-01, time/batch = 0.7076s	
1584/33250 (epoch 2.382), train_loss = 1.75769966, grad/param norm = 2.6218e-01, time/batch = 0.7062s	
1585/33250 (epoch 2.383), train_loss = 1.65814554, grad/param norm = 2.3274e-01, time/batch = 0.6979s	
1586/33250 (epoch 2.385), train_loss = 1.48761998, grad/param norm = 2.4748e-01, time/batch = 0.6961s	
1587/33250 (epoch 2.386), train_loss = 1.55956653, grad/param norm = 2.4180e-01, time/batch = 0.6961s	
1588/33250 (epoch 2.388), train_loss = 1.58943760, grad/param norm = 2.3540e-01, time/batch = 0.7272s	
1589/33250 (epoch 2.389), train_loss = 1.60407453, grad/param norm = 2.5218e-01, time/batch = 0.6952s	
1590/33250 (epoch 2.391), train_loss = 1.59395335, grad/param norm = 2.4545e-01, time/batch = 0.6982s	
1591/33250 (epoch 2.392), train_loss = 1.80977946, grad/param norm = 2.3805e-01, time/batch = 0.6985s	
1592/33250 (epoch 2.394), train_loss = 1.92358862, grad/param norm = 2.8822e-01, time/batch = 0.7007s	
1593/33250 (epoch 2.395), train_loss = 1.88329983, grad/param norm = 2.5597e-01, time/batch = 0.6927s	
1594/33250 (epoch 2.397), train_loss = 1.76359614, grad/param norm = 2.5625e-01, time/batch = 0.6949s	
1595/33250 (epoch 2.398), train_loss = 1.65782936, grad/param norm = 2.5761e-01, time/batch = 0.6960s	
1596/33250 (epoch 2.400), train_loss = 1.60931064, grad/param norm = 2.2490e-01, time/batch = 0.6925s	
1597/33250 (epoch 2.402), train_loss = 1.50638414, grad/param norm = 2.4845e-01, time/batch = 0.6969s	
1598/33250 (epoch 2.403), train_loss = 1.49484616, grad/param norm = 2.3251e-01, time/batch = 0.6958s	
1599/33250 (epoch 2.405), train_loss = 1.49483751, grad/param norm = 2.5148e-01, time/batch = 0.6957s	
1600/33250 (epoch 2.406), train_loss = 1.65199836, grad/param norm = 2.3257e-01, time/batch = 0.6933s	
1601/33250 (epoch 2.408), train_loss = 1.80962731, grad/param norm = 2.4141e-01, time/batch = 0.6980s	
1602/33250 (epoch 2.409), train_loss = 1.74706584, grad/param norm = 2.9735e-01, time/batch = 0.6957s	
1603/33250 (epoch 2.411), train_loss = 1.35561025, grad/param norm = 2.8546e-01, time/batch = 0.7007s	
1604/33250 (epoch 2.412), train_loss = 1.38684790, grad/param norm = 2.0623e-01, time/batch = 0.6956s	
1605/33250 (epoch 2.414), train_loss = 1.71431439, grad/param norm = 2.3171e-01, time/batch = 0.7087s	
1606/33250 (epoch 2.415), train_loss = 1.64298675, grad/param norm = 2.3959e-01, time/batch = 0.7007s	
1607/33250 (epoch 2.417), train_loss = 1.70980334, grad/param norm = 2.4960e-01, time/batch = 0.6963s	
1608/33250 (epoch 2.418), train_loss = 1.86900522, grad/param norm = 2.8335e-01, time/batch = 0.6938s	
1609/33250 (epoch 2.420), train_loss = 1.73082479, grad/param norm = 2.4789e-01, time/batch = 0.6992s	
1610/33250 (epoch 2.421), train_loss = 1.51221806, grad/param norm = 2.9669e-01, time/batch = 0.7004s	
1611/33250 (epoch 2.423), train_loss = 1.73290667, grad/param norm = 2.3574e-01, time/batch = 0.7007s	
1612/33250 (epoch 2.424), train_loss = 1.89411711, grad/param norm = 3.0366e-01, time/batch = 0.7000s	
1613/33250 (epoch 2.426), train_loss = 1.54111934, grad/param norm = 2.0524e-01, time/batch = 0.7087s	
1614/33250 (epoch 2.427), train_loss = 1.48439295, grad/param norm = 2.4889e-01, time/batch = 0.7011s	
1615/33250 (epoch 2.429), train_loss = 1.71519173, grad/param norm = 2.7095e-01, time/batch = 0.7040s	
1616/33250 (epoch 2.430), train_loss = 1.57248503, grad/param norm = 2.5532e-01, time/batch = 0.7078s	
1617/33250 (epoch 2.432), train_loss = 1.61511700, grad/param norm = 2.1711e-01, time/batch = 0.6996s	
1618/33250 (epoch 2.433), train_loss = 1.61146841, grad/param norm = 2.3624e-01, time/batch = 0.7003s	
1619/33250 (epoch 2.435), train_loss = 1.72856425, grad/param norm = 2.7966e-01, time/batch = 0.7018s	
1620/33250 (epoch 2.436), train_loss = 1.65030482, grad/param norm = 2.3785e-01, time/batch = 0.6973s	
1621/33250 (epoch 2.438), train_loss = 1.57414326, grad/param norm = 2.7678e-01, time/batch = 0.7026s	
1622/33250 (epoch 2.439), train_loss = 1.59321370, grad/param norm = 2.2851e-01, time/batch = 0.6978s	
1623/33250 (epoch 2.441), train_loss = 1.64148135, grad/param norm = 2.3187e-01, time/batch = 0.7062s	
1624/33250 (epoch 2.442), train_loss = 1.61100213, grad/param norm = 2.3156e-01, time/batch = 0.7047s	
1625/33250 (epoch 2.444), train_loss = 1.47246233, grad/param norm = 2.6962e-01, time/batch = 0.7040s	
1626/33250 (epoch 2.445), train_loss = 1.61844952, grad/param norm = 2.0798e-01, time/batch = 0.7050s	
1627/33250 (epoch 2.447), train_loss = 1.63797815, grad/param norm = 2.3628e-01, time/batch = 0.7033s	
1628/33250 (epoch 2.448), train_loss = 1.52135468, grad/param norm = 2.3221e-01, time/batch = 0.7020s	
1629/33250 (epoch 2.450), train_loss = 1.87483110, grad/param norm = 2.5153e-01, time/batch = 0.6957s	
1630/33250 (epoch 2.451), train_loss = 1.71251621, grad/param norm = 2.4502e-01, time/batch = 0.6979s	
1631/33250 (epoch 2.453), train_loss = 1.39716362, grad/param norm = 2.1481e-01, time/batch = 0.6977s	
1632/33250 (epoch 2.454), train_loss = 1.74086546, grad/param norm = 2.3982e-01, time/batch = 0.6982s	
1633/33250 (epoch 2.456), train_loss = 1.73055267, grad/param norm = 2.8000e-01, time/batch = 0.6979s	
1634/33250 (epoch 2.457), train_loss = 1.68050041, grad/param norm = 2.4968e-01, time/batch = 0.6981s	
1635/33250 (epoch 2.459), train_loss = 1.64927744, grad/param norm = 2.3833e-01, time/batch = 0.6977s	
1636/33250 (epoch 2.460), train_loss = 1.63071254, grad/param norm = 2.6079e-01, time/batch = 0.7006s	
1637/33250 (epoch 2.462), train_loss = 1.54818811, grad/param norm = 2.3311e-01, time/batch = 0.7038s	
1638/33250 (epoch 2.463), train_loss = 1.46013742, grad/param norm = 2.1450e-01, time/batch = 0.6969s	
1639/33250 (epoch 2.465), train_loss = 1.31759061, grad/param norm = 2.2149e-01, time/batch = 0.7007s	
1640/33250 (epoch 2.466), train_loss = 1.31886214, grad/param norm = 2.0664e-01, time/batch = 0.7054s	
1641/33250 (epoch 2.468), train_loss = 1.40761461, grad/param norm = 2.0958e-01, time/batch = 0.7176s	
1642/33250 (epoch 2.469), train_loss = 1.71676916, grad/param norm = 2.5221e-01, time/batch = 0.7242s	
1643/33250 (epoch 2.471), train_loss = 1.70598750, grad/param norm = 2.4035e-01, time/batch = 0.7303s	
1644/33250 (epoch 2.472), train_loss = 1.66872291, grad/param norm = 3.0086e-01, time/batch = 0.7262s	
1645/33250 (epoch 2.474), train_loss = 1.90666607, grad/param norm = 2.7398e-01, time/batch = 0.7199s	
1646/33250 (epoch 2.475), train_loss = 1.67228900, grad/param norm = 2.6673e-01, time/batch = 0.7112s	
1647/33250 (epoch 2.477), train_loss = 1.62062798, grad/param norm = 2.3366e-01, time/batch = 0.7062s	
1648/33250 (epoch 2.478), train_loss = 1.56454939, grad/param norm = 2.2304e-01, time/batch = 0.7084s	
1649/33250 (epoch 2.480), train_loss = 1.83253447, grad/param norm = 2.4057e-01, time/batch = 0.7078s	
1650/33250 (epoch 2.481), train_loss = 1.55024641, grad/param norm = 2.4656e-01, time/batch = 0.7035s	
1651/33250 (epoch 2.483), train_loss = 1.69123398, grad/param norm = 2.5770e-01, time/batch = 0.7048s	
1652/33250 (epoch 2.484), train_loss = 1.55182792, grad/param norm = 2.3309e-01, time/batch = 0.7061s	
1653/33250 (epoch 2.486), train_loss = 1.42611604, grad/param norm = 2.1806e-01, time/batch = 0.7014s	
1654/33250 (epoch 2.487), train_loss = 1.60007537, grad/param norm = 2.5242e-01, time/batch = 0.7011s	
1655/33250 (epoch 2.489), train_loss = 1.80589165, grad/param norm = 2.6984e-01, time/batch = 0.7036s	
1656/33250 (epoch 2.490), train_loss = 1.73773097, grad/param norm = 2.5891e-01, time/batch = 0.7041s	
1657/33250 (epoch 2.492), train_loss = 1.61087872, grad/param norm = 2.1945e-01, time/batch = 0.7301s	
1658/33250 (epoch 2.493), train_loss = 1.60672307, grad/param norm = 2.2776e-01, time/batch = 0.7272s	
1659/33250 (epoch 2.495), train_loss = 1.63096826, grad/param norm = 2.3340e-01, time/batch = 0.7121s	
1660/33250 (epoch 2.496), train_loss = 1.57941466, grad/param norm = 2.3589e-01, time/batch = 0.6975s	
1661/33250 (epoch 2.498), train_loss = 1.66987859, grad/param norm = 2.4639e-01, time/batch = 0.7109s	
1662/33250 (epoch 2.499), train_loss = 1.63280548, grad/param norm = 2.3015e-01, time/batch = 0.6946s	
1663/33250 (epoch 2.501), train_loss = 1.53371298, grad/param norm = 2.2088e-01, time/batch = 0.6982s	
1664/33250 (epoch 2.502), train_loss = 1.61240668, grad/param norm = 2.4165e-01, time/batch = 0.6980s	
1665/33250 (epoch 2.504), train_loss = 1.84365940, grad/param norm = 2.3803e-01, time/batch = 0.6978s	
1666/33250 (epoch 2.505), train_loss = 1.32701893, grad/param norm = 2.0375e-01, time/batch = 0.7006s	
1667/33250 (epoch 2.507), train_loss = 1.71535523, grad/param norm = 2.2918e-01, time/batch = 0.7014s	
1668/33250 (epoch 2.508), train_loss = 1.52493082, grad/param norm = 2.4655e-01, time/batch = 0.6976s	
1669/33250 (epoch 2.510), train_loss = 1.48196017, grad/param norm = 2.4731e-01, time/batch = 0.6978s	
1670/33250 (epoch 2.511), train_loss = 1.67635584, grad/param norm = 2.2541e-01, time/batch = 0.6938s	
1671/33250 (epoch 2.513), train_loss = 1.92198267, grad/param norm = 2.4942e-01, time/batch = 0.6985s	
1672/33250 (epoch 2.514), train_loss = 1.61256138, grad/param norm = 2.2532e-01, time/batch = 0.6963s	
1673/33250 (epoch 2.516), train_loss = 1.59120663, grad/param norm = 2.2485e-01, time/batch = 0.6925s	
1674/33250 (epoch 2.517), train_loss = 1.66633100, grad/param norm = 2.4569e-01, time/batch = 0.6929s	
1675/33250 (epoch 2.519), train_loss = 1.38342906, grad/param norm = 2.3162e-01, time/batch = 0.6986s	
1676/33250 (epoch 2.520), train_loss = 1.89845960, grad/param norm = 2.3855e-01, time/batch = 0.6903s	
1677/33250 (epoch 2.522), train_loss = 1.71768702, grad/param norm = 2.3433e-01, time/batch = 0.6949s	
1678/33250 (epoch 2.523), train_loss = 1.55873206, grad/param norm = 2.3219e-01, time/batch = 0.6897s	
1679/33250 (epoch 2.525), train_loss = 1.43574617, grad/param norm = 2.2661e-01, time/batch = 0.6909s	
1680/33250 (epoch 2.526), train_loss = 1.44417389, grad/param norm = 2.6512e-01, time/batch = 0.6939s	
1681/33250 (epoch 2.528), train_loss = 1.59908393, grad/param norm = 2.3861e-01, time/batch = 0.6914s	
1682/33250 (epoch 2.529), train_loss = 1.49296242, grad/param norm = 2.2040e-01, time/batch = 0.6914s	
1683/33250 (epoch 2.531), train_loss = 1.37967190, grad/param norm = 2.4066e-01, time/batch = 0.6885s	
1684/33250 (epoch 2.532), train_loss = 1.75003506, grad/param norm = 2.1504e-01, time/batch = 0.6890s	
1685/33250 (epoch 2.534), train_loss = 1.61665881, grad/param norm = 2.2513e-01, time/batch = 0.6879s	
1686/33250 (epoch 2.535), train_loss = 1.57812482, grad/param norm = 1.9976e-01, time/batch = 0.6889s	
1687/33250 (epoch 2.537), train_loss = 1.74525395, grad/param norm = 2.2717e-01, time/batch = 0.7092s	
1688/33250 (epoch 2.538), train_loss = 1.62921939, grad/param norm = 2.4034e-01, time/batch = 0.7093s	
1689/33250 (epoch 2.540), train_loss = 1.75610516, grad/param norm = 2.3455e-01, time/batch = 0.6931s	
1690/33250 (epoch 2.541), train_loss = 1.73119405, grad/param norm = 2.5526e-01, time/batch = 0.6914s	
1691/33250 (epoch 2.543), train_loss = 1.75748201, grad/param norm = 2.4616e-01, time/batch = 0.7012s	
1692/33250 (epoch 2.544), train_loss = 1.61758068, grad/param norm = 2.4502e-01, time/batch = 0.6993s	
1693/33250 (epoch 2.546), train_loss = 1.63426082, grad/param norm = 2.3666e-01, time/batch = 0.7110s	
1694/33250 (epoch 2.547), train_loss = 1.46604051, grad/param norm = 2.2863e-01, time/batch = 0.7087s	
1695/33250 (epoch 2.549), train_loss = 1.62306539, grad/param norm = 2.2678e-01, time/batch = 0.7041s	
1696/33250 (epoch 2.550), train_loss = 1.52219021, grad/param norm = 2.2160e-01, time/batch = 0.7007s	
1697/33250 (epoch 2.552), train_loss = 1.69622700, grad/param norm = 2.4061e-01, time/batch = 0.7078s	
1698/33250 (epoch 2.553), train_loss = 1.47446016, grad/param norm = 2.2637e-01, time/batch = 0.7072s	
1699/33250 (epoch 2.555), train_loss = 1.51147026, grad/param norm = 2.1354e-01, time/batch = 0.7055s	
1700/33250 (epoch 2.556), train_loss = 1.75961204, grad/param norm = 2.4964e-01, time/batch = 0.6968s	
1701/33250 (epoch 2.558), train_loss = 1.71264110, grad/param norm = 2.3904e-01, time/batch = 0.7038s	
1702/33250 (epoch 2.559), train_loss = 1.51081825, grad/param norm = 2.4644e-01, time/batch = 0.6915s	
1703/33250 (epoch 2.561), train_loss = 1.61860417, grad/param norm = 2.4161e-01, time/batch = 0.6937s	
1704/33250 (epoch 2.562), train_loss = 1.78323561, grad/param norm = 2.5291e-01, time/batch = 0.7352s	
1705/33250 (epoch 2.564), train_loss = 1.74105039, grad/param norm = 2.2876e-01, time/batch = 0.7343s	
1706/33250 (epoch 2.565), train_loss = 1.75201193, grad/param norm = 2.4585e-01, time/batch = 0.7112s	
1707/33250 (epoch 2.567), train_loss = 1.61948452, grad/param norm = 2.1115e-01, time/batch = 0.7092s	
1708/33250 (epoch 2.568), train_loss = 1.53394745, grad/param norm = 2.2954e-01, time/batch = 0.7071s	
1709/33250 (epoch 2.570), train_loss = 1.79945469, grad/param norm = 2.6551e-01, time/batch = 0.7020s	
1710/33250 (epoch 2.571), train_loss = 1.79626431, grad/param norm = 2.3018e-01, time/batch = 0.6933s	
1711/33250 (epoch 2.573), train_loss = 1.74234174, grad/param norm = 2.0086e-01, time/batch = 0.7034s	
1712/33250 (epoch 2.574), train_loss = 1.47504123, grad/param norm = 2.0402e-01, time/batch = 0.7021s	
1713/33250 (epoch 2.576), train_loss = 1.66897206, grad/param norm = 2.3427e-01, time/batch = 0.7264s	
1714/33250 (epoch 2.577), train_loss = 1.61014638, grad/param norm = 2.1176e-01, time/batch = 0.6994s	
1715/33250 (epoch 2.579), train_loss = 1.43984699, grad/param norm = 2.1949e-01, time/batch = 0.6973s	
1716/33250 (epoch 2.580), train_loss = 1.38245108, grad/param norm = 2.0090e-01, time/batch = 0.6930s	
1717/33250 (epoch 2.582), train_loss = 1.54043987, grad/param norm = 2.0508e-01, time/batch = 0.6917s	
1718/33250 (epoch 2.583), train_loss = 1.60637574, grad/param norm = 2.0688e-01, time/batch = 0.6916s	
1719/33250 (epoch 2.585), train_loss = 1.74923840, grad/param norm = 2.7827e-01, time/batch = 0.6892s	
1720/33250 (epoch 2.586), train_loss = 1.56396974, grad/param norm = 2.6280e-01, time/batch = 0.6914s	
1721/33250 (epoch 2.588), train_loss = 1.65298049, grad/param norm = 2.4082e-01, time/batch = 0.6972s	
1722/33250 (epoch 2.589), train_loss = 1.77055267, grad/param norm = 2.5030e-01, time/batch = 0.6939s	
1723/33250 (epoch 2.591), train_loss = 1.71431724, grad/param norm = 2.2712e-01, time/batch = 0.6952s	
1724/33250 (epoch 2.592), train_loss = 1.56513705, grad/param norm = 2.0715e-01, time/batch = 0.6888s	
1725/33250 (epoch 2.594), train_loss = 1.85029101, grad/param norm = 2.6157e-01, time/batch = 0.7030s	
1726/33250 (epoch 2.595), train_loss = 1.79379313, grad/param norm = 2.2997e-01, time/batch = 0.7104s	
1727/33250 (epoch 2.597), train_loss = 1.53396568, grad/param norm = 2.2869e-01, time/batch = 0.7414s	
1728/33250 (epoch 2.598), train_loss = 1.71750905, grad/param norm = 2.2057e-01, time/batch = 0.7179s	
1729/33250 (epoch 2.600), train_loss = 1.60389951, grad/param norm = 2.2062e-01, time/batch = 0.7044s	
1730/33250 (epoch 2.602), train_loss = 1.73988292, grad/param norm = 2.8292e-01, time/batch = 0.7255s	
1731/33250 (epoch 2.603), train_loss = 1.56019087, grad/param norm = 2.1244e-01, time/batch = 0.7203s	
1732/33250 (epoch 2.605), train_loss = 1.63977252, grad/param norm = 2.4533e-01, time/batch = 0.7428s	
1733/33250 (epoch 2.606), train_loss = 1.65974323, grad/param norm = 2.3274e-01, time/batch = 0.7107s	
1734/33250 (epoch 2.608), train_loss = 1.65312085, grad/param norm = 2.2966e-01, time/batch = 0.7016s	
1735/33250 (epoch 2.609), train_loss = 1.51573717, grad/param norm = 2.4016e-01, time/batch = 0.7129s	
1736/33250 (epoch 2.611), train_loss = 1.78667177, grad/param norm = 2.3029e-01, time/batch = 0.7182s	
1737/33250 (epoch 2.612), train_loss = 1.70033947, grad/param norm = 2.4598e-01, time/batch = 0.7218s	
1738/33250 (epoch 2.614), train_loss = 1.94426318, grad/param norm = 2.6388e-01, time/batch = 0.7069s	
1739/33250 (epoch 2.615), train_loss = 1.77098550, grad/param norm = 2.5009e-01, time/batch = 0.7017s	
1740/33250 (epoch 2.617), train_loss = 2.05559898, grad/param norm = 2.2759e-01, time/batch = 0.6958s	
1741/33250 (epoch 2.618), train_loss = 1.95083269, grad/param norm = 2.8421e-01, time/batch = 0.7014s	
1742/33250 (epoch 2.620), train_loss = 1.80461946, grad/param norm = 2.4726e-01, time/batch = 0.7025s	
1743/33250 (epoch 2.621), train_loss = 1.55464840, grad/param norm = 2.1247e-01, time/batch = 0.7094s	
1744/33250 (epoch 2.623), train_loss = 1.57195732, grad/param norm = 2.6703e-01, time/batch = 0.7052s	
1745/33250 (epoch 2.624), train_loss = 1.66143320, grad/param norm = 2.7167e-01, time/batch = 0.6999s	
1746/33250 (epoch 2.626), train_loss = 1.68568545, grad/param norm = 2.3988e-01, time/batch = 0.6980s	
1747/33250 (epoch 2.627), train_loss = 1.69659259, grad/param norm = 2.4011e-01, time/batch = 0.6837s	
1748/33250 (epoch 2.629), train_loss = 1.60342832, grad/param norm = 2.6265e-01, time/batch = 0.6873s	
1749/33250 (epoch 2.630), train_loss = 1.65201870, grad/param norm = 2.5923e-01, time/batch = 0.6866s	
1750/33250 (epoch 2.632), train_loss = 1.38301353, grad/param norm = 2.0115e-01, time/batch = 0.6895s	
1751/33250 (epoch 2.633), train_loss = 1.75319920, grad/param norm = 2.7416e-01, time/batch = 0.7066s	
1752/33250 (epoch 2.635), train_loss = 1.46378229, grad/param norm = 2.1351e-01, time/batch = 0.7003s	
1753/33250 (epoch 2.636), train_loss = 1.55572746, grad/param norm = 2.2792e-01, time/batch = 0.6961s	
1754/33250 (epoch 2.638), train_loss = 1.58415016, grad/param norm = 2.2226e-01, time/batch = 0.7233s	
1755/33250 (epoch 2.639), train_loss = 1.62217625, grad/param norm = 2.6161e-01, time/batch = 0.7204s	
1756/33250 (epoch 2.641), train_loss = 1.52020787, grad/param norm = 2.2032e-01, time/batch = 0.7424s	
1757/33250 (epoch 2.642), train_loss = 1.53777934, grad/param norm = 2.4311e-01, time/batch = 0.7385s	
1758/33250 (epoch 2.644), train_loss = 1.41026309, grad/param norm = 2.3117e-01, time/batch = 0.7327s	
1759/33250 (epoch 2.645), train_loss = 1.75373025, grad/param norm = 2.5959e-01, time/batch = 0.7317s	
1760/33250 (epoch 2.647), train_loss = 1.51439493, grad/param norm = 2.2462e-01, time/batch = 0.7407s	
1761/33250 (epoch 2.648), train_loss = 1.58765256, grad/param norm = 2.5519e-01, time/batch = 0.7533s	
1762/33250 (epoch 2.650), train_loss = 1.75377696, grad/param norm = 2.7047e-01, time/batch = 0.7287s	
1763/33250 (epoch 2.651), train_loss = 1.64380524, grad/param norm = 2.6004e-01, time/batch = 0.7211s	
1764/33250 (epoch 2.653), train_loss = 1.42315460, grad/param norm = 2.0062e-01, time/batch = 0.7233s	
1765/33250 (epoch 2.654), train_loss = 1.43585580, grad/param norm = 1.9156e-01, time/batch = 0.7278s	
1766/33250 (epoch 2.656), train_loss = 1.66358835, grad/param norm = 2.3285e-01, time/batch = 0.7142s	
1767/33250 (epoch 2.657), train_loss = 1.47379992, grad/param norm = 2.4029e-01, time/batch = 0.7080s	
1768/33250 (epoch 2.659), train_loss = 1.43862378, grad/param norm = 2.0187e-01, time/batch = 0.7219s	
1769/33250 (epoch 2.660), train_loss = 1.51781982, grad/param norm = 2.4770e-01, time/batch = 0.7193s	
1770/33250 (epoch 2.662), train_loss = 1.63496974, grad/param norm = 2.6099e-01, time/batch = 0.7154s	
1771/33250 (epoch 2.663), train_loss = 1.49843906, grad/param norm = 2.3792e-01, time/batch = 0.7215s	
1772/33250 (epoch 2.665), train_loss = 1.76979797, grad/param norm = 2.6560e-01, time/batch = 0.7209s	
1773/33250 (epoch 2.666), train_loss = 1.57087502, grad/param norm = 2.5125e-01, time/batch = 0.7032s	
1774/33250 (epoch 2.668), train_loss = 1.70684387, grad/param norm = 2.1629e-01, time/batch = 0.7044s	
1775/33250 (epoch 2.669), train_loss = 1.72115040, grad/param norm = 2.2432e-01, time/batch = 0.6976s	
1776/33250 (epoch 2.671), train_loss = 1.62517503, grad/param norm = 2.2700e-01, time/batch = 0.6908s	
1777/33250 (epoch 2.672), train_loss = 1.75728926, grad/param norm = 2.3576e-01, time/batch = 0.6886s	
1778/33250 (epoch 2.674), train_loss = 1.54395183, grad/param norm = 2.0879e-01, time/batch = 0.7016s	
1779/33250 (epoch 2.675), train_loss = 1.69560033, grad/param norm = 2.4434e-01, time/batch = 0.6995s	
1780/33250 (epoch 2.677), train_loss = 1.60978391, grad/param norm = 2.4915e-01, time/batch = 0.7145s	
1781/33250 (epoch 2.678), train_loss = 1.66620666, grad/param norm = 2.3087e-01, time/batch = 0.7092s	
1782/33250 (epoch 2.680), train_loss = 1.67319177, grad/param norm = 2.2183e-01, time/batch = 0.7030s	
1783/33250 (epoch 2.681), train_loss = 1.42128147, grad/param norm = 2.1797e-01, time/batch = 0.7012s	
1784/33250 (epoch 2.683), train_loss = 1.48662900, grad/param norm = 2.2869e-01, time/batch = 0.7015s	
1785/33250 (epoch 2.684), train_loss = 1.60891571, grad/param norm = 2.5495e-01, time/batch = 0.6949s	
1786/33250 (epoch 2.686), train_loss = 1.46393577, grad/param norm = 1.9858e-01, time/batch = 0.7003s	
1787/33250 (epoch 2.687), train_loss = 1.51590806, grad/param norm = 2.3324e-01, time/batch = 0.7030s	
1788/33250 (epoch 2.689), train_loss = 1.47717345, grad/param norm = 2.0627e-01, time/batch = 0.7056s	
1789/33250 (epoch 2.690), train_loss = 1.70927187, grad/param norm = 2.4566e-01, time/batch = 0.7004s	
1790/33250 (epoch 2.692), train_loss = 1.73716835, grad/param norm = 2.5485e-01, time/batch = 0.7042s	
1791/33250 (epoch 2.693), train_loss = 1.55881581, grad/param norm = 1.9790e-01, time/batch = 0.7046s	
1792/33250 (epoch 2.695), train_loss = 1.70278671, grad/param norm = 2.3547e-01, time/batch = 0.7018s	
1793/33250 (epoch 2.696), train_loss = 1.61406583, grad/param norm = 2.0461e-01, time/batch = 0.7025s	
1794/33250 (epoch 2.698), train_loss = 1.46388945, grad/param norm = 2.2698e-01, time/batch = 0.6994s	
1795/33250 (epoch 2.699), train_loss = 1.77521428, grad/param norm = 2.2194e-01, time/batch = 0.6966s	
1796/33250 (epoch 2.701), train_loss = 1.51072638, grad/param norm = 2.0655e-01, time/batch = 0.7038s	
1797/33250 (epoch 2.702), train_loss = 1.71554466, grad/param norm = 2.5170e-01, time/batch = 0.7017s	
1798/33250 (epoch 2.704), train_loss = 1.78211019, grad/param norm = 2.4697e-01, time/batch = 0.6994s	
1799/33250 (epoch 2.705), train_loss = 1.51541877, grad/param norm = 2.1452e-01, time/batch = 0.7145s	
1800/33250 (epoch 2.707), train_loss = 1.49088880, grad/param norm = 2.5330e-01, time/batch = 0.6966s	
1801/33250 (epoch 2.708), train_loss = 1.64099261, grad/param norm = 2.2786e-01, time/batch = 0.7031s	
1802/33250 (epoch 2.710), train_loss = 1.75362027, grad/param norm = 2.3440e-01, time/batch = 0.6961s	
1803/33250 (epoch 2.711), train_loss = 1.73110603, grad/param norm = 2.5093e-01, time/batch = 0.6923s	
1804/33250 (epoch 2.713), train_loss = 1.70357241, grad/param norm = 2.4921e-01, time/batch = 0.6942s	
1805/33250 (epoch 2.714), train_loss = 1.71354574, grad/param norm = 2.2196e-01, time/batch = 0.6981s	
1806/33250 (epoch 2.716), train_loss = 1.75872997, grad/param norm = 2.4868e-01, time/batch = 0.6807s	
1807/33250 (epoch 2.717), train_loss = 1.52594516, grad/param norm = 2.1385e-01, time/batch = 0.6811s	
1808/33250 (epoch 2.719), train_loss = 1.67792620, grad/param norm = 2.3199e-01, time/batch = 0.6800s	
1809/33250 (epoch 2.720), train_loss = 1.80449103, grad/param norm = 2.1607e-01, time/batch = 0.6871s	
1810/33250 (epoch 2.722), train_loss = 1.49532996, grad/param norm = 1.8813e-01, time/batch = 0.7006s	
1811/33250 (epoch 2.723), train_loss = 1.40591991, grad/param norm = 1.9881e-01, time/batch = 0.7122s	
1812/33250 (epoch 2.725), train_loss = 1.29842011, grad/param norm = 1.8701e-01, time/batch = 0.7072s	
1813/33250 (epoch 2.726), train_loss = 1.50745696, grad/param norm = 2.1422e-01, time/batch = 0.6866s	
1814/33250 (epoch 2.728), train_loss = 1.64643314, grad/param norm = 2.3338e-01, time/batch = 0.6879s	
1815/33250 (epoch 2.729), train_loss = 1.70234472, grad/param norm = 2.2656e-01, time/batch = 0.6859s	
1816/33250 (epoch 2.731), train_loss = 1.51819632, grad/param norm = 2.1980e-01, time/batch = 0.6835s	
1817/33250 (epoch 2.732), train_loss = 1.51135275, grad/param norm = 2.2349e-01, time/batch = 0.7071s	
1818/33250 (epoch 2.734), train_loss = 1.63699460, grad/param norm = 2.4185e-01, time/batch = 0.7054s	
1819/33250 (epoch 2.735), train_loss = 1.62459464, grad/param norm = 2.3480e-01, time/batch = 0.6796s	
1820/33250 (epoch 2.737), train_loss = 1.70908423, grad/param norm = 2.0779e-01, time/batch = 0.6766s	
1821/33250 (epoch 2.738), train_loss = 1.64538953, grad/param norm = 2.1165e-01, time/batch = 0.6821s	
1822/33250 (epoch 2.740), train_loss = 1.83791672, grad/param norm = 2.2886e-01, time/batch = 0.6874s	
1823/33250 (epoch 2.741), train_loss = 1.60395235, grad/param norm = 2.4183e-01, time/batch = 0.6881s	
1824/33250 (epoch 2.743), train_loss = 1.60169598, grad/param norm = 2.2660e-01, time/batch = 0.7016s	
1825/33250 (epoch 2.744), train_loss = 1.62400731, grad/param norm = 2.2526e-01, time/batch = 0.7075s	
1826/33250 (epoch 2.746), train_loss = 1.63240241, grad/param norm = 2.2235e-01, time/batch = 0.7121s	
1827/33250 (epoch 2.747), train_loss = 1.56752631, grad/param norm = 2.2494e-01, time/batch = 0.7195s	
1828/33250 (epoch 2.749), train_loss = 1.75863887, grad/param norm = 2.2909e-01, time/batch = 0.7417s	
1829/33250 (epoch 2.750), train_loss = 1.62519575, grad/param norm = 2.4784e-01, time/batch = 0.7090s	
1830/33250 (epoch 2.752), train_loss = 1.48475862, grad/param norm = 2.0748e-01, time/batch = 0.7073s	
1831/33250 (epoch 2.753), train_loss = 1.57311965, grad/param norm = 2.1001e-01, time/batch = 0.7294s	
1832/33250 (epoch 2.755), train_loss = 1.45871383, grad/param norm = 2.2312e-01, time/batch = 0.7291s	
1833/33250 (epoch 2.756), train_loss = 1.70125258, grad/param norm = 2.1776e-01, time/batch = 0.7168s	
1834/33250 (epoch 2.758), train_loss = 1.64853487, grad/param norm = 2.1695e-01, time/batch = 0.6982s	
1835/33250 (epoch 2.759), train_loss = 1.43251770, grad/param norm = 1.9763e-01, time/batch = 0.7240s	
1836/33250 (epoch 2.761), train_loss = 1.58463299, grad/param norm = 2.5335e-01, time/batch = 0.7246s	
1837/33250 (epoch 2.762), train_loss = 1.64060107, grad/param norm = 2.6502e-01, time/batch = 0.7068s	
1838/33250 (epoch 2.764), train_loss = 1.52188050, grad/param norm = 2.7669e-01, time/batch = 0.7033s	
1839/33250 (epoch 2.765), train_loss = 1.60646227, grad/param norm = 2.4659e-01, time/batch = 0.7057s	
1840/33250 (epoch 2.767), train_loss = 1.42824652, grad/param norm = 2.8392e-01, time/batch = 0.7186s	
1841/33250 (epoch 2.768), train_loss = 1.51261937, grad/param norm = 2.3626e-01, time/batch = 0.7257s	
1842/33250 (epoch 2.770), train_loss = 1.56996231, grad/param norm = 2.2951e-01, time/batch = 0.7299s	
1843/33250 (epoch 2.771), train_loss = 1.67857126, grad/param norm = 2.3284e-01, time/batch = 0.7116s	
1844/33250 (epoch 2.773), train_loss = 1.57462502, grad/param norm = 2.2998e-01, time/batch = 0.7420s	
1845/33250 (epoch 2.774), train_loss = 1.41145642, grad/param norm = 2.3394e-01, time/batch = 0.7392s	
1846/33250 (epoch 2.776), train_loss = 1.58158512, grad/param norm = 2.4836e-01, time/batch = 0.7293s	
1847/33250 (epoch 2.777), train_loss = 1.75131324, grad/param norm = 2.6812e-01, time/batch = 0.7122s	
1848/33250 (epoch 2.779), train_loss = 1.44224249, grad/param norm = 2.3509e-01, time/batch = 0.7093s	
1849/33250 (epoch 2.780), train_loss = 1.78678626, grad/param norm = 2.4317e-01, time/batch = 0.7088s	
1850/33250 (epoch 2.782), train_loss = 1.66093537, grad/param norm = 2.4901e-01, time/batch = 0.7067s	
1851/33250 (epoch 2.783), train_loss = 1.42472049, grad/param norm = 2.2138e-01, time/batch = 0.7160s	
1852/33250 (epoch 2.785), train_loss = 1.50113236, grad/param norm = 2.3471e-01, time/batch = 0.7134s	
1853/33250 (epoch 2.786), train_loss = 1.71845977, grad/param norm = 2.4989e-01, time/batch = 0.7209s	
1854/33250 (epoch 2.788), train_loss = 1.51591655, grad/param norm = 2.1285e-01, time/batch = 0.7110s	
1855/33250 (epoch 2.789), train_loss = 1.65327315, grad/param norm = 2.3636e-01, time/batch = 0.7087s	
1856/33250 (epoch 2.791), train_loss = 1.69930171, grad/param norm = 2.3371e-01, time/batch = 0.7119s	
1857/33250 (epoch 2.792), train_loss = 1.78262905, grad/param norm = 2.1496e-01, time/batch = 0.7134s	
1858/33250 (epoch 2.794), train_loss = 1.45726871, grad/param norm = 2.1702e-01, time/batch = 0.7060s	
1859/33250 (epoch 2.795), train_loss = 1.65016909, grad/param norm = 2.3279e-01, time/batch = 0.6975s	
1860/33250 (epoch 2.797), train_loss = 1.74773286, grad/param norm = 2.4238e-01, time/batch = 0.7034s	
1861/33250 (epoch 2.798), train_loss = 1.76370974, grad/param norm = 3.1232e-01, time/batch = 0.7055s	
1862/33250 (epoch 2.800), train_loss = 1.73870007, grad/param norm = 2.5953e-01, time/batch = 0.6980s	
1863/33250 (epoch 2.802), train_loss = 1.53674344, grad/param norm = 2.2744e-01, time/batch = 0.6992s	
1864/33250 (epoch 2.803), train_loss = 1.53447970, grad/param norm = 2.1218e-01, time/batch = 0.6984s	
1865/33250 (epoch 2.805), train_loss = 1.61352299, grad/param norm = 2.3746e-01, time/batch = 0.6973s	
1866/33250 (epoch 2.806), train_loss = 1.69707436, grad/param norm = 2.3034e-01, time/batch = 0.6993s	
1867/33250 (epoch 2.808), train_loss = 1.65368534, grad/param norm = 2.1629e-01, time/batch = 0.7003s	
1868/33250 (epoch 2.809), train_loss = 1.41208258, grad/param norm = 2.0752e-01, time/batch = 0.6984s	
1869/33250 (epoch 2.811), train_loss = 1.55597936, grad/param norm = 2.5455e-01, time/batch = 0.6978s	
1870/33250 (epoch 2.812), train_loss = 1.55664192, grad/param norm = 2.3715e-01, time/batch = 0.7082s	
1871/33250 (epoch 2.814), train_loss = 1.53979588, grad/param norm = 2.2844e-01, time/batch = 0.7007s	
1872/33250 (epoch 2.815), train_loss = 1.64442519, grad/param norm = 2.5690e-01, time/batch = 0.6992s	
1873/33250 (epoch 2.817), train_loss = 1.57235188, grad/param norm = 2.3311e-01, time/batch = 0.7003s	
1874/33250 (epoch 2.818), train_loss = 1.45636913, grad/param norm = 2.0632e-01, time/batch = 0.6946s	
1875/33250 (epoch 2.820), train_loss = 1.63851004, grad/param norm = 2.5430e-01, time/batch = 0.7040s	
1876/33250 (epoch 2.821), train_loss = 1.43272752, grad/param norm = 2.1524e-01, time/batch = 0.7014s	
1877/33250 (epoch 2.823), train_loss = 1.82030396, grad/param norm = 2.3475e-01, time/batch = 0.6980s	
1878/33250 (epoch 2.824), train_loss = 1.60962094, grad/param norm = 2.2818e-01, time/batch = 0.6972s	
1879/33250 (epoch 2.826), train_loss = 1.55704715, grad/param norm = 2.4903e-01, time/batch = 0.6945s	
1880/33250 (epoch 2.827), train_loss = 1.40016738, grad/param norm = 2.2828e-01, time/batch = 0.6991s	
1881/33250 (epoch 2.829), train_loss = 1.58659973, grad/param norm = 2.1465e-01, time/batch = 0.6998s	
1882/33250 (epoch 2.830), train_loss = 1.87755433, grad/param norm = 2.7952e-01, time/batch = 0.6949s	
1883/33250 (epoch 2.832), train_loss = 1.51860700, grad/param norm = 2.2555e-01, time/batch = 0.6973s	
1884/33250 (epoch 2.833), train_loss = 1.64486638, grad/param norm = 2.3587e-01, time/batch = 0.6977s	
1885/33250 (epoch 2.835), train_loss = 1.62578293, grad/param norm = 2.3773e-01, time/batch = 0.6970s	
1886/33250 (epoch 2.836), train_loss = 1.61850743, grad/param norm = 2.2247e-01, time/batch = 0.7029s	
1887/33250 (epoch 2.838), train_loss = 1.48280512, grad/param norm = 1.9772e-01, time/batch = 0.6970s	
1888/33250 (epoch 2.839), train_loss = 1.52929496, grad/param norm = 2.1781e-01, time/batch = 0.6962s	
1889/33250 (epoch 2.841), train_loss = 1.35453408, grad/param norm = 1.9890e-01, time/batch = 0.6940s	
1890/33250 (epoch 2.842), train_loss = 1.66040619, grad/param norm = 2.1586e-01, time/batch = 0.6989s	
1891/33250 (epoch 2.844), train_loss = 1.76926465, grad/param norm = 2.4086e-01, time/batch = 0.7017s	
1892/33250 (epoch 2.845), train_loss = 1.84090412, grad/param norm = 2.6590e-01, time/batch = 0.6994s	
1893/33250 (epoch 2.847), train_loss = 1.74026172, grad/param norm = 2.2208e-01, time/batch = 0.6919s	
1894/33250 (epoch 2.848), train_loss = 1.84381557, grad/param norm = 2.5838e-01, time/batch = 0.7017s	
1895/33250 (epoch 2.850), train_loss = 1.62315685, grad/param norm = 2.2867e-01, time/batch = 0.7157s	
1896/33250 (epoch 2.851), train_loss = 1.49908026, grad/param norm = 2.2701e-01, time/batch = 0.7300s	
1897/33250 (epoch 2.853), train_loss = 1.65238781, grad/param norm = 2.4457e-01, time/batch = 0.7468s	
1898/33250 (epoch 2.854), train_loss = 1.43642596, grad/param norm = 2.0628e-01, time/batch = 0.7258s	
1899/33250 (epoch 2.856), train_loss = 1.47890892, grad/param norm = 2.2835e-01, time/batch = 0.7239s	
1900/33250 (epoch 2.857), train_loss = 1.34637761, grad/param norm = 2.0193e-01, time/batch = 0.7062s	
1901/33250 (epoch 2.859), train_loss = 1.36892540, grad/param norm = 2.2874e-01, time/batch = 0.6961s	
1902/33250 (epoch 2.860), train_loss = 1.47164549, grad/param norm = 1.8494e-01, time/batch = 0.6832s	
1903/33250 (epoch 2.862), train_loss = 1.44760033, grad/param norm = 1.9772e-01, time/batch = 0.6855s	
1904/33250 (epoch 2.863), train_loss = 1.46019464, grad/param norm = 2.1249e-01, time/batch = 0.6865s	
1905/33250 (epoch 2.865), train_loss = 1.57817569, grad/param norm = 2.2381e-01, time/batch = 0.6879s	
1906/33250 (epoch 2.866), train_loss = 1.51286154, grad/param norm = 2.3311e-01, time/batch = 0.6918s	
1907/33250 (epoch 2.868), train_loss = 1.92373407, grad/param norm = 2.8262e-01, time/batch = 0.6897s	
1908/33250 (epoch 2.869), train_loss = 1.61376928, grad/param norm = 2.3080e-01, time/batch = 0.6872s	
1909/33250 (epoch 2.871), train_loss = 1.31481573, grad/param norm = 2.0968e-01, time/batch = 0.6898s	
1910/33250 (epoch 2.872), train_loss = 1.69262906, grad/param norm = 2.3017e-01, time/batch = 0.6917s	
1911/33250 (epoch 2.874), train_loss = 1.48633087, grad/param norm = 2.1136e-01, time/batch = 0.6892s	
1912/33250 (epoch 2.875), train_loss = 1.53327671, grad/param norm = 2.6003e-01, time/batch = 0.7065s	
1913/33250 (epoch 2.877), train_loss = 1.60142752, grad/param norm = 2.5528e-01, time/batch = 0.6955s	
1914/33250 (epoch 2.878), train_loss = 1.53899827, grad/param norm = 2.0603e-01, time/batch = 0.7005s	
1915/33250 (epoch 2.880), train_loss = 1.64454436, grad/param norm = 2.5520e-01, time/batch = 0.6858s	
1916/33250 (epoch 2.881), train_loss = 1.75739009, grad/param norm = 2.2158e-01, time/batch = 0.6815s	
1917/33250 (epoch 2.883), train_loss = 1.67374428, grad/param norm = 2.5843e-01, time/batch = 0.6825s	
1918/33250 (epoch 2.884), train_loss = 1.53515065, grad/param norm = 2.3698e-01, time/batch = 0.6820s	
1919/33250 (epoch 2.886), train_loss = 1.42028635, grad/param norm = 2.1281e-01, time/batch = 0.6857s	
1920/33250 (epoch 2.887), train_loss = 1.50380223, grad/param norm = 2.0582e-01, time/batch = 0.6875s	
1921/33250 (epoch 2.889), train_loss = 1.43196775, grad/param norm = 1.7733e-01, time/batch = 0.6845s	
1922/33250 (epoch 2.890), train_loss = 1.35025878, grad/param norm = 2.2235e-01, time/batch = 0.6856s	
1923/33250 (epoch 2.892), train_loss = 1.62985574, grad/param norm = 2.1904e-01, time/batch = 0.6882s	
1924/33250 (epoch 2.893), train_loss = 1.63819603, grad/param norm = 2.1385e-01, time/batch = 0.6807s	
1925/33250 (epoch 2.895), train_loss = 1.51052800, grad/param norm = 2.1742e-01, time/batch = 0.6818s	
1926/33250 (epoch 2.896), train_loss = 1.66569768, grad/param norm = 2.2408e-01, time/batch = 0.6827s	
1927/33250 (epoch 2.898), train_loss = 1.48155512, grad/param norm = 2.1591e-01, time/batch = 0.6779s	
1928/33250 (epoch 2.899), train_loss = 1.53095150, grad/param norm = 2.3813e-01, time/batch = 0.6813s	
1929/33250 (epoch 2.901), train_loss = 1.39290984, grad/param norm = 2.0395e-01, time/batch = 0.6845s	
1930/33250 (epoch 2.902), train_loss = 1.45656982, grad/param norm = 2.1042e-01, time/batch = 0.6900s	
1931/33250 (epoch 2.904), train_loss = 1.42832149, grad/param norm = 2.1544e-01, time/batch = 0.6908s	
1932/33250 (epoch 2.905), train_loss = 1.49168993, grad/param norm = 2.2504e-01, time/batch = 0.6876s	
1933/33250 (epoch 2.907), train_loss = 1.51855367, grad/param norm = 2.3473e-01, time/batch = 0.6832s	
1934/33250 (epoch 2.908), train_loss = 1.54916262, grad/param norm = 1.9575e-01, time/batch = 0.6876s	
1935/33250 (epoch 2.910), train_loss = 1.68427061, grad/param norm = 2.5199e-01, time/batch = 0.6905s	
1936/33250 (epoch 2.911), train_loss = 1.35274958, grad/param norm = 2.1608e-01, time/batch = 0.6831s	
1937/33250 (epoch 2.913), train_loss = 1.47371198, grad/param norm = 2.1253e-01, time/batch = 0.6866s	
1938/33250 (epoch 2.914), train_loss = 1.35428247, grad/param norm = 2.1590e-01, time/batch = 0.6871s	
1939/33250 (epoch 2.916), train_loss = 1.42058204, grad/param norm = 2.0621e-01, time/batch = 0.6906s	
1940/33250 (epoch 2.917), train_loss = 1.50355480, grad/param norm = 2.2144e-01, time/batch = 0.6939s	
1941/33250 (epoch 2.919), train_loss = 1.56494136, grad/param norm = 2.3302e-01, time/batch = 0.6873s	
1942/33250 (epoch 2.920), train_loss = 1.56847693, grad/param norm = 2.2500e-01, time/batch = 0.6828s	
1943/33250 (epoch 2.922), train_loss = 1.59918136, grad/param norm = 2.2457e-01, time/batch = 0.6822s	
1944/33250 (epoch 2.923), train_loss = 1.53469549, grad/param norm = 2.3688e-01, time/batch = 0.6888s	
1945/33250 (epoch 2.925), train_loss = 1.52269813, grad/param norm = 2.2335e-01, time/batch = 0.6905s	
1946/33250 (epoch 2.926), train_loss = 1.53411107, grad/param norm = 2.5616e-01, time/batch = 0.6802s	
1947/33250 (epoch 2.928), train_loss = 1.57405850, grad/param norm = 2.3068e-01, time/batch = 0.6971s	
1948/33250 (epoch 2.929), train_loss = 1.21933480, grad/param norm = 1.9605e-01, time/batch = 0.6984s	
1949/33250 (epoch 2.931), train_loss = 1.57970753, grad/param norm = 2.2967e-01, time/batch = 0.6943s	
1950/33250 (epoch 2.932), train_loss = 1.67145083, grad/param norm = 2.4177e-01, time/batch = 0.6867s	
1951/33250 (epoch 2.934), train_loss = 1.49595972, grad/param norm = 2.3506e-01, time/batch = 0.6842s	
1952/33250 (epoch 2.935), train_loss = 1.57750508, grad/param norm = 2.4244e-01, time/batch = 0.6867s	
1953/33250 (epoch 2.937), train_loss = 1.55051660, grad/param norm = 2.1734e-01, time/batch = 0.6891s	
1954/33250 (epoch 2.938), train_loss = 1.68818188, grad/param norm = 2.2595e-01, time/batch = 0.6837s	
1955/33250 (epoch 2.940), train_loss = 1.52664585, grad/param norm = 2.3188e-01, time/batch = 0.6833s	
1956/33250 (epoch 2.941), train_loss = 1.59792743, grad/param norm = 2.5348e-01, time/batch = 0.6934s	
1957/33250 (epoch 2.943), train_loss = 1.75373290, grad/param norm = 2.3076e-01, time/batch = 0.6808s	
1958/33250 (epoch 2.944), train_loss = 1.40442658, grad/param norm = 2.1825e-01, time/batch = 0.6800s	
1959/33250 (epoch 2.946), train_loss = 1.81789805, grad/param norm = 2.3547e-01, time/batch = 0.6877s	
1960/33250 (epoch 2.947), train_loss = 1.51361246, grad/param norm = 2.2280e-01, time/batch = 0.6807s	
1961/33250 (epoch 2.949), train_loss = 1.68297325, grad/param norm = 2.4132e-01, time/batch = 0.6890s	
1962/33250 (epoch 2.950), train_loss = 1.55574924, grad/param norm = 2.2405e-01, time/batch = 0.6868s	
1963/33250 (epoch 2.952), train_loss = 1.60534831, grad/param norm = 2.3381e-01, time/batch = 0.6876s	
1964/33250 (epoch 2.953), train_loss = 1.64746791, grad/param norm = 2.2876e-01, time/batch = 0.6851s	
1965/33250 (epoch 2.955), train_loss = 1.64809007, grad/param norm = 2.4964e-01, time/batch = 0.6805s	
1966/33250 (epoch 2.956), train_loss = 1.75265237, grad/param norm = 2.3876e-01, time/batch = 0.6879s	
1967/33250 (epoch 2.958), train_loss = 1.46428929, grad/param norm = 2.0976e-01, time/batch = 0.6952s	
1968/33250 (epoch 2.959), train_loss = 1.41499559, grad/param norm = 2.0745e-01, time/batch = 0.7137s	
1969/33250 (epoch 2.961), train_loss = 1.66520430, grad/param norm = 2.3940e-01, time/batch = 0.7132s	
1970/33250 (epoch 2.962), train_loss = 1.61056790, grad/param norm = 2.4527e-01, time/batch = 0.7244s	
1971/33250 (epoch 2.964), train_loss = 1.65358095, grad/param norm = 2.3013e-01, time/batch = 0.7185s	
1972/33250 (epoch 2.965), train_loss = 1.63161856, grad/param norm = 2.3593e-01, time/batch = 0.7138s	
1973/33250 (epoch 2.967), train_loss = 1.71035476, grad/param norm = 2.1537e-01, time/batch = 0.7033s	
1974/33250 (epoch 2.968), train_loss = 1.72841190, grad/param norm = 2.2449e-01, time/batch = 0.6951s	
1975/33250 (epoch 2.970), train_loss = 1.87676405, grad/param norm = 2.5712e-01, time/batch = 0.6759s	
1976/33250 (epoch 2.971), train_loss = 1.74702280, grad/param norm = 2.3550e-01, time/batch = 0.6782s	
1977/33250 (epoch 2.973), train_loss = 1.53080884, grad/param norm = 2.0451e-01, time/batch = 0.6784s	
1978/33250 (epoch 2.974), train_loss = 1.58919384, grad/param norm = 2.3282e-01, time/batch = 0.6819s	
1979/33250 (epoch 2.976), train_loss = 1.47453156, grad/param norm = 2.2211e-01, time/batch = 0.6864s	
1980/33250 (epoch 2.977), train_loss = 1.44553183, grad/param norm = 2.2105e-01, time/batch = 0.6950s	
1981/33250 (epoch 2.979), train_loss = 1.56853984, grad/param norm = 2.4017e-01, time/batch = 0.7096s	
1982/33250 (epoch 2.980), train_loss = 1.49338768, grad/param norm = 1.9460e-01, time/batch = 0.7173s	
1983/33250 (epoch 2.982), train_loss = 1.37142790, grad/param norm = 1.9848e-01, time/batch = 0.7038s	
1984/33250 (epoch 2.983), train_loss = 1.64737511, grad/param norm = 2.4504e-01, time/batch = 0.6856s	
1985/33250 (epoch 2.985), train_loss = 1.43939187, grad/param norm = 2.3402e-01, time/batch = 0.6855s	
1986/33250 (epoch 2.986), train_loss = 1.72814705, grad/param norm = 2.5686e-01, time/batch = 0.7032s	
1987/33250 (epoch 2.988), train_loss = 1.56284464, grad/param norm = 2.5814e-01, time/batch = 0.7305s	
1988/33250 (epoch 2.989), train_loss = 1.70206862, grad/param norm = 2.3137e-01, time/batch = 0.6908s	
1989/33250 (epoch 2.991), train_loss = 1.56515086, grad/param norm = 2.4170e-01, time/batch = 0.6899s	
1990/33250 (epoch 2.992), train_loss = 1.50071649, grad/param norm = 2.1818e-01, time/batch = 0.6791s	
1991/33250 (epoch 2.994), train_loss = 1.40255435, grad/param norm = 1.9605e-01, time/batch = 0.6819s	
1992/33250 (epoch 2.995), train_loss = 1.62056786, grad/param norm = 2.4991e-01, time/batch = 0.6837s	
1993/33250 (epoch 2.997), train_loss = 1.22839402, grad/param norm = 1.9614e-01, time/batch = 0.6782s	
1994/33250 (epoch 2.998), train_loss = 1.55608176, grad/param norm = 2.1860e-01, time/batch = 0.6813s	
1995/33250 (epoch 3.000), train_loss = 1.54230380, grad/param norm = 2.2259e-01, time/batch = 0.6866s	
1996/33250 (epoch 3.002), train_loss = 1.71432283, grad/param norm = 2.1926e-01, time/batch = 0.6807s	
1997/33250 (epoch 3.003), train_loss = 1.59520863, grad/param norm = 2.3105e-01, time/batch = 0.6826s	
1998/33250 (epoch 3.005), train_loss = 1.38968876, grad/param norm = 2.2029e-01, time/batch = 0.6880s	
1999/33250 (epoch 3.006), train_loss = 1.32134798, grad/param norm = 2.0192e-01, time/batch = 0.6846s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch3.01_1.6259.t7	
2000/33250 (epoch 3.008), train_loss = 1.62077662, grad/param norm = 2.4072e-01, time/batch = 0.6845s	
2001/33250 (epoch 3.009), train_loss = 1.73555300, grad/param norm = 2.4252e-01, time/batch = 0.6881s	
2002/33250 (epoch 3.011), train_loss = 1.50301920, grad/param norm = 2.3440e-01, time/batch = 0.6847s	
2003/33250 (epoch 3.012), train_loss = 1.69983573, grad/param norm = 2.6268e-01, time/batch = 0.6828s	
2004/33250 (epoch 3.014), train_loss = 1.62152411, grad/param norm = 2.0820e-01, time/batch = 0.6794s	
2005/33250 (epoch 3.015), train_loss = 1.54411376, grad/param norm = 2.2570e-01, time/batch = 0.6937s	
2006/33250 (epoch 3.017), train_loss = 1.59999163, grad/param norm = 2.3621e-01, time/batch = 0.6910s	
2007/33250 (epoch 3.018), train_loss = 1.40761493, grad/param norm = 2.2202e-01, time/batch = 0.6992s	
2008/33250 (epoch 3.020), train_loss = 1.48224714, grad/param norm = 2.0088e-01, time/batch = 0.6897s	
2009/33250 (epoch 3.021), train_loss = 1.52126625, grad/param norm = 2.1451e-01, time/batch = 0.6973s	
2010/33250 (epoch 3.023), train_loss = 1.38348786, grad/param norm = 2.2669e-01, time/batch = 0.6901s	
2011/33250 (epoch 3.024), train_loss = 1.66307162, grad/param norm = 2.3308e-01, time/batch = 0.6834s	
2012/33250 (epoch 3.026), train_loss = 1.48445737, grad/param norm = 1.9635e-01, time/batch = 0.6767s	
2013/33250 (epoch 3.027), train_loss = 1.44630899, grad/param norm = 2.2514e-01, time/batch = 0.6783s	
2014/33250 (epoch 3.029), train_loss = 1.51932234, grad/param norm = 2.0744e-01, time/batch = 0.6797s	
2015/33250 (epoch 3.030), train_loss = 1.55646922, grad/param norm = 2.4841e-01, time/batch = 0.6847s	
2016/33250 (epoch 3.032), train_loss = 1.81461412, grad/param norm = 2.6121e-01, time/batch = 0.7242s	
2017/33250 (epoch 3.033), train_loss = 1.44159997, grad/param norm = 2.4935e-01, time/batch = 0.7097s	
2018/33250 (epoch 3.035), train_loss = 1.45864887, grad/param norm = 2.1088e-01, time/batch = 0.6863s	
2019/33250 (epoch 3.036), train_loss = 1.56696595, grad/param norm = 2.4149e-01, time/batch = 0.6972s	
2020/33250 (epoch 3.038), train_loss = 1.39772402, grad/param norm = 2.0711e-01, time/batch = 0.6984s	
2021/33250 (epoch 3.039), train_loss = 1.38657751, grad/param norm = 2.1665e-01, time/batch = 0.7050s	
2022/33250 (epoch 3.041), train_loss = 1.66155890, grad/param norm = 2.2900e-01, time/batch = 0.6884s	
2023/33250 (epoch 3.042), train_loss = 1.32004402, grad/param norm = 1.9723e-01, time/batch = 0.6879s	
2024/33250 (epoch 3.044), train_loss = 1.73724604, grad/param norm = 2.0145e-01, time/batch = 0.6904s	
2025/33250 (epoch 3.045), train_loss = 1.58296478, grad/param norm = 2.0204e-01, time/batch = 0.6886s	
2026/33250 (epoch 3.047), train_loss = 1.67974468, grad/param norm = 2.3051e-01, time/batch = 0.6879s	
2027/33250 (epoch 3.048), train_loss = 1.76670836, grad/param norm = 2.4194e-01, time/batch = 0.6864s	
2028/33250 (epoch 3.050), train_loss = 1.51215294, grad/param norm = 2.1903e-01, time/batch = 0.6843s	
2029/33250 (epoch 3.051), train_loss = 1.53515804, grad/param norm = 2.0716e-01, time/batch = 0.6814s	
2030/33250 (epoch 3.053), train_loss = 1.62818556, grad/param norm = 2.3069e-01, time/batch = 0.6819s	
2031/33250 (epoch 3.054), train_loss = 1.34337865, grad/param norm = 2.0183e-01, time/batch = 0.6889s	
2032/33250 (epoch 3.056), train_loss = 1.41031774, grad/param norm = 2.2379e-01, time/batch = 0.6810s	
2033/33250 (epoch 3.057), train_loss = 1.47514494, grad/param norm = 2.2379e-01, time/batch = 0.6919s	
2034/33250 (epoch 3.059), train_loss = 1.45733591, grad/param norm = 2.1912e-01, time/batch = 0.6893s	
2035/33250 (epoch 3.060), train_loss = 1.62156843, grad/param norm = 2.3535e-01, time/batch = 0.6889s	
2036/33250 (epoch 3.062), train_loss = 1.68630861, grad/param norm = 2.2429e-01, time/batch = 0.6893s	
2037/33250 (epoch 3.063), train_loss = 1.64467922, grad/param norm = 2.0833e-01, time/batch = 0.6894s	
2038/33250 (epoch 3.065), train_loss = 1.58278482, grad/param norm = 2.1332e-01, time/batch = 0.6799s	
2039/33250 (epoch 3.066), train_loss = 1.64928436, grad/param norm = 2.1679e-01, time/batch = 0.6861s	
2040/33250 (epoch 3.068), train_loss = 1.55683114, grad/param norm = 2.5604e-01, time/batch = 0.6850s	
2041/33250 (epoch 3.069), train_loss = 1.57990674, grad/param norm = 1.9941e-01, time/batch = 0.6918s	
2042/33250 (epoch 3.071), train_loss = 1.37631192, grad/param norm = 2.0104e-01, time/batch = 0.6891s	
2043/33250 (epoch 3.072), train_loss = 1.46257217, grad/param norm = 2.1374e-01, time/batch = 0.6862s	
2044/33250 (epoch 3.074), train_loss = 1.56614280, grad/param norm = 2.1211e-01, time/batch = 0.6846s	
2045/33250 (epoch 3.075), train_loss = 1.41695702, grad/param norm = 2.0509e-01, time/batch = 0.6852s	
2046/33250 (epoch 3.077), train_loss = 1.57244236, grad/param norm = 2.0311e-01, time/batch = 0.6855s	
2047/33250 (epoch 3.078), train_loss = 1.40991418, grad/param norm = 2.0108e-01, time/batch = 0.6864s	
2048/33250 (epoch 3.080), train_loss = 1.60357952, grad/param norm = 2.6801e-01, time/batch = 0.6852s	
2049/33250 (epoch 3.081), train_loss = 1.60505769, grad/param norm = 2.4960e-01, time/batch = 0.6850s	
2050/33250 (epoch 3.083), train_loss = 1.62106817, grad/param norm = 2.3612e-01, time/batch = 0.6827s	
2051/33250 (epoch 3.084), train_loss = 1.47969008, grad/param norm = 2.0408e-01, time/batch = 0.6853s	
2052/33250 (epoch 3.086), train_loss = 1.50620890, grad/param norm = 2.0898e-01, time/batch = 0.6865s	
2053/33250 (epoch 3.087), train_loss = 1.36315580, grad/param norm = 1.9801e-01, time/batch = 0.6841s	
2054/33250 (epoch 3.089), train_loss = 1.58916115, grad/param norm = 2.3063e-01, time/batch = 0.6823s	
2055/33250 (epoch 3.090), train_loss = 1.45113913, grad/param norm = 2.3595e-01, time/batch = 0.6850s	
2056/33250 (epoch 3.092), train_loss = 1.37609548, grad/param norm = 2.0601e-01, time/batch = 0.6826s	
2057/33250 (epoch 3.093), train_loss = 1.47268953, grad/param norm = 2.1181e-01, time/batch = 0.6844s	
2058/33250 (epoch 3.095), train_loss = 1.46704966, grad/param norm = 2.2278e-01, time/batch = 0.6986s	
2059/33250 (epoch 3.096), train_loss = 1.35269714, grad/param norm = 2.0117e-01, time/batch = 0.7112s	
2060/33250 (epoch 3.098), train_loss = 1.39809320, grad/param norm = 2.2176e-01, time/batch = 0.7135s	
2061/33250 (epoch 3.099), train_loss = 1.26267760, grad/param norm = 2.1696e-01, time/batch = 0.7138s	
2062/33250 (epoch 3.101), train_loss = 1.48405800, grad/param norm = 2.3196e-01, time/batch = 0.7100s	
2063/33250 (epoch 3.102), train_loss = 1.35288516, grad/param norm = 1.8866e-01, time/batch = 0.7209s	
2064/33250 (epoch 3.104), train_loss = 1.29869350, grad/param norm = 1.9249e-01, time/batch = 0.7046s	
2065/33250 (epoch 3.105), train_loss = 1.44547708, grad/param norm = 2.1147e-01, time/batch = 0.7210s	
2066/33250 (epoch 3.107), train_loss = 1.20531878, grad/param norm = 1.8610e-01, time/batch = 0.7158s	
2067/33250 (epoch 3.108), train_loss = 1.48370703, grad/param norm = 2.0539e-01, time/batch = 0.7148s	
2068/33250 (epoch 3.110), train_loss = 1.30637355, grad/param norm = 1.9923e-01, time/batch = 0.6965s	
2069/33250 (epoch 3.111), train_loss = 1.47078750, grad/param norm = 2.1347e-01, time/batch = 0.6897s	
2070/33250 (epoch 3.113), train_loss = 1.45182330, grad/param norm = 2.1760e-01, time/batch = 0.6924s	
2071/33250 (epoch 3.114), train_loss = 1.43471030, grad/param norm = 2.3563e-01, time/batch = 0.6901s	
2072/33250 (epoch 3.116), train_loss = 1.55296694, grad/param norm = 2.3476e-01, time/batch = 0.6879s	
2073/33250 (epoch 3.117), train_loss = 1.47063868, grad/param norm = 2.0716e-01, time/batch = 0.7001s	
2074/33250 (epoch 3.119), train_loss = 1.42797512, grad/param norm = 1.9833e-01, time/batch = 0.6892s	
2075/33250 (epoch 3.120), train_loss = 1.18817734, grad/param norm = 1.8925e-01, time/batch = 0.6875s	
2076/33250 (epoch 3.122), train_loss = 1.58925955, grad/param norm = 2.0580e-01, time/batch = 0.6852s	
2077/33250 (epoch 3.123), train_loss = 1.58805030, grad/param norm = 2.1593e-01, time/batch = 0.6866s	
2078/33250 (epoch 3.125), train_loss = 1.29933471, grad/param norm = 1.9840e-01, time/batch = 0.6833s	
2079/33250 (epoch 3.126), train_loss = 1.53962641, grad/param norm = 2.4469e-01, time/batch = 0.6820s	
2080/33250 (epoch 3.128), train_loss = 1.38335266, grad/param norm = 2.0454e-01, time/batch = 0.6846s	
2081/33250 (epoch 3.129), train_loss = 1.43377717, grad/param norm = 2.1636e-01, time/batch = 0.6919s	
2082/33250 (epoch 3.131), train_loss = 1.53058080, grad/param norm = 2.2047e-01, time/batch = 0.6860s	
2083/33250 (epoch 3.132), train_loss = 1.47039978, grad/param norm = 2.0249e-01, time/batch = 0.6925s	
2084/33250 (epoch 3.134), train_loss = 1.53477632, grad/param norm = 2.1867e-01, time/batch = 0.6895s	
2085/33250 (epoch 3.135), train_loss = 1.55853497, grad/param norm = 2.0365e-01, time/batch = 0.7047s	
2086/33250 (epoch 3.137), train_loss = 1.33106168, grad/param norm = 1.9588e-01, time/batch = 0.7009s	
2087/33250 (epoch 3.138), train_loss = 1.40887752, grad/param norm = 2.0566e-01, time/batch = 0.7018s	
2088/33250 (epoch 3.140), train_loss = 1.35501085, grad/param norm = 2.1892e-01, time/batch = 0.7027s	
2089/33250 (epoch 3.141), train_loss = 1.86304999, grad/param norm = 2.3088e-01, time/batch = 0.6878s	
2090/33250 (epoch 3.143), train_loss = 1.25194307, grad/param norm = 2.0877e-01, time/batch = 0.6883s	
2091/33250 (epoch 3.144), train_loss = 1.37597967, grad/param norm = 2.0136e-01, time/batch = 0.6906s	
2092/33250 (epoch 3.146), train_loss = 1.34985289, grad/param norm = 1.9291e-01, time/batch = 0.6919s	
2093/33250 (epoch 3.147), train_loss = 1.39325197, grad/param norm = 2.2390e-01, time/batch = 0.6910s	
2094/33250 (epoch 3.149), train_loss = 1.51643613, grad/param norm = 2.1495e-01, time/batch = 0.6843s	
2095/33250 (epoch 3.150), train_loss = 1.31243553, grad/param norm = 2.1625e-01, time/batch = 0.6909s	
2096/33250 (epoch 3.152), train_loss = 1.33244172, grad/param norm = 2.0802e-01, time/batch = 0.6861s	
2097/33250 (epoch 3.153), train_loss = 1.60554525, grad/param norm = 2.4505e-01, time/batch = 0.6838s	
2098/33250 (epoch 3.155), train_loss = 1.55210649, grad/param norm = 2.4116e-01, time/batch = 0.6871s	
2099/33250 (epoch 3.156), train_loss = 1.54915989, grad/param norm = 2.2587e-01, time/batch = 0.6873s	
2100/33250 (epoch 3.158), train_loss = 1.85679874, grad/param norm = 2.4813e-01, time/batch = 0.6850s	
2101/33250 (epoch 3.159), train_loss = 1.52695766, grad/param norm = 2.3036e-01, time/batch = 0.6884s	
2102/33250 (epoch 3.161), train_loss = 1.57556617, grad/param norm = 2.3692e-01, time/batch = 0.6945s	
2103/33250 (epoch 3.162), train_loss = 1.45372147, grad/param norm = 2.2800e-01, time/batch = 0.6859s	
2104/33250 (epoch 3.164), train_loss = 1.59039783, grad/param norm = 2.2096e-01, time/batch = 0.6815s	
2105/33250 (epoch 3.165), train_loss = 1.54348111, grad/param norm = 2.0570e-01, time/batch = 0.6965s	
2106/33250 (epoch 3.167), train_loss = 1.54134140, grad/param norm = 2.0543e-01, time/batch = 0.7015s	
2107/33250 (epoch 3.168), train_loss = 1.31533306, grad/param norm = 1.8862e-01, time/batch = 0.6985s	
2108/33250 (epoch 3.170), train_loss = 1.43124030, grad/param norm = 2.0161e-01, time/batch = 0.7025s	
2109/33250 (epoch 3.171), train_loss = 1.45208486, grad/param norm = 1.9482e-01, time/batch = 0.6973s	
2110/33250 (epoch 3.173), train_loss = 1.37661800, grad/param norm = 2.1076e-01, time/batch = 0.6971s	
2111/33250 (epoch 3.174), train_loss = 1.47539706, grad/param norm = 2.3188e-01, time/batch = 0.7103s	
2112/33250 (epoch 3.176), train_loss = 1.57131623, grad/param norm = 2.2808e-01, time/batch = 0.7017s	
2113/33250 (epoch 3.177), train_loss = 1.24921149, grad/param norm = 1.7467e-01, time/batch = 0.6875s	
2114/33250 (epoch 3.179), train_loss = 1.44944810, grad/param norm = 2.1565e-01, time/batch = 0.6846s	
2115/33250 (epoch 3.180), train_loss = 1.35138684, grad/param norm = 1.9686e-01, time/batch = 0.6829s	
2116/33250 (epoch 3.182), train_loss = 1.45852274, grad/param norm = 2.3649e-01, time/batch = 0.6832s	
2117/33250 (epoch 3.183), train_loss = 1.71904989, grad/param norm = 2.2094e-01, time/batch = 0.6888s	
2118/33250 (epoch 3.185), train_loss = 1.58921258, grad/param norm = 2.3978e-01, time/batch = 0.6857s	
2119/33250 (epoch 3.186), train_loss = 1.40145363, grad/param norm = 1.9103e-01, time/batch = 0.6961s	
2120/33250 (epoch 3.188), train_loss = 1.56650121, grad/param norm = 2.0587e-01, time/batch = 0.6853s	
2121/33250 (epoch 3.189), train_loss = 1.28343158, grad/param norm = 1.9703e-01, time/batch = 0.6927s	
2122/33250 (epoch 3.191), train_loss = 1.38670800, grad/param norm = 1.9800e-01, time/batch = 0.6932s	
2123/33250 (epoch 3.192), train_loss = 1.37321866, grad/param norm = 1.9749e-01, time/batch = 0.6929s	
2124/33250 (epoch 3.194), train_loss = 1.26732690, grad/param norm = 2.1280e-01, time/batch = 0.6921s	
2125/33250 (epoch 3.195), train_loss = 1.60786919, grad/param norm = 2.0316e-01, time/batch = 0.6855s	
2126/33250 (epoch 3.197), train_loss = 1.49411610, grad/param norm = 2.3377e-01, time/batch = 0.6855s	
2127/33250 (epoch 3.198), train_loss = 1.61352297, grad/param norm = 2.5114e-01, time/batch = 0.6837s	
2128/33250 (epoch 3.200), train_loss = 1.47277066, grad/param norm = 2.1775e-01, time/batch = 0.6818s	
2129/33250 (epoch 3.202), train_loss = 1.44096844, grad/param norm = 2.0861e-01, time/batch = 0.6834s	
2130/33250 (epoch 3.203), train_loss = 1.50992947, grad/param norm = 2.1320e-01, time/batch = 0.6803s	
2131/33250 (epoch 3.205), train_loss = 1.54744130, grad/param norm = 2.4049e-01, time/batch = 0.6878s	
2132/33250 (epoch 3.206), train_loss = 1.50367112, grad/param norm = 2.2060e-01, time/batch = 0.6878s	
2133/33250 (epoch 3.208), train_loss = 1.77029752, grad/param norm = 2.5858e-01, time/batch = 0.6858s	
2134/33250 (epoch 3.209), train_loss = 1.37509177, grad/param norm = 2.2701e-01, time/batch = 0.6851s	
2135/33250 (epoch 3.211), train_loss = 1.64485075, grad/param norm = 2.0716e-01, time/batch = 0.6867s	
2136/33250 (epoch 3.212), train_loss = 1.72584865, grad/param norm = 2.6437e-01, time/batch = 0.6812s	
2137/33250 (epoch 3.214), train_loss = 1.49345259, grad/param norm = 2.1616e-01, time/batch = 0.6824s	
2138/33250 (epoch 3.215), train_loss = 1.90754357, grad/param norm = 2.4701e-01, time/batch = 0.6789s	
2139/33250 (epoch 3.217), train_loss = 1.64153859, grad/param norm = 2.1939e-01, time/batch = 0.6771s	
2140/33250 (epoch 3.218), train_loss = 1.57730535, grad/param norm = 2.2762e-01, time/batch = 0.6754s	
2141/33250 (epoch 3.220), train_loss = 1.69827028, grad/param norm = 2.2669e-01, time/batch = 0.6850s	
2142/33250 (epoch 3.221), train_loss = 1.81088566, grad/param norm = 2.3303e-01, time/batch = 0.6842s	
2143/33250 (epoch 3.223), train_loss = 1.50211815, grad/param norm = 2.2943e-01, time/batch = 0.6893s	
2144/33250 (epoch 3.224), train_loss = 1.63699951, grad/param norm = 2.4916e-01, time/batch = 0.6991s	
2145/33250 (epoch 3.226), train_loss = 1.64547666, grad/param norm = 2.1741e-01, time/batch = 0.7153s	
2146/33250 (epoch 3.227), train_loss = 1.55317756, grad/param norm = 2.0033e-01, time/batch = 0.7253s	
2147/33250 (epoch 3.229), train_loss = 1.49715708, grad/param norm = 1.9501e-01, time/batch = 0.7027s	
2148/33250 (epoch 3.230), train_loss = 1.45509999, grad/param norm = 2.2670e-01, time/batch = 0.7032s	
2149/33250 (epoch 3.232), train_loss = 1.40390137, grad/param norm = 1.8702e-01, time/batch = 0.7190s	
2150/33250 (epoch 3.233), train_loss = 1.44699395, grad/param norm = 1.9914e-01, time/batch = 0.7138s	
2151/33250 (epoch 3.235), train_loss = 1.60135144, grad/param norm = 2.1878e-01, time/batch = 0.7057s	
2152/33250 (epoch 3.236), train_loss = 1.41758970, grad/param norm = 2.5630e-01, time/batch = 0.7013s	
2153/33250 (epoch 3.238), train_loss = 1.56200515, grad/param norm = 2.1791e-01, time/batch = 0.7129s	
2154/33250 (epoch 3.239), train_loss = 1.74580272, grad/param norm = 2.4329e-01, time/batch = 0.7177s	
2155/33250 (epoch 3.241), train_loss = 1.65424877, grad/param norm = 2.4484e-01, time/batch = 0.6962s	
2156/33250 (epoch 3.242), train_loss = 1.54537170, grad/param norm = 2.0998e-01, time/batch = 0.6971s	
2157/33250 (epoch 3.244), train_loss = 1.63421117, grad/param norm = 2.3443e-01, time/batch = 0.7045s	
2158/33250 (epoch 3.245), train_loss = 1.47546110, grad/param norm = 2.2049e-01, time/batch = 0.7088s	
2159/33250 (epoch 3.247), train_loss = 1.58465813, grad/param norm = 2.0840e-01, time/batch = 0.7064s	
2160/33250 (epoch 3.248), train_loss = 1.80596500, grad/param norm = 2.3310e-01, time/batch = 0.7029s	
2161/33250 (epoch 3.250), train_loss = 1.52566601, grad/param norm = 1.9654e-01, time/batch = 0.7082s	
2162/33250 (epoch 3.251), train_loss = 1.53858594, grad/param norm = 2.3405e-01, time/batch = 0.7012s	
2163/33250 (epoch 3.253), train_loss = 1.34293807, grad/param norm = 2.0916e-01, time/batch = 0.7104s	
2164/33250 (epoch 3.254), train_loss = 1.45183047, grad/param norm = 2.1564e-01, time/batch = 0.7109s	
2165/33250 (epoch 3.256), train_loss = 1.63772941, grad/param norm = 2.2530e-01, time/batch = 0.7059s	
2166/33250 (epoch 3.257), train_loss = 1.70819373, grad/param norm = 2.2418e-01, time/batch = 0.7027s	
2167/33250 (epoch 3.259), train_loss = 1.70863524, grad/param norm = 2.0765e-01, time/batch = 0.7034s	
2168/33250 (epoch 3.260), train_loss = 1.37503886, grad/param norm = 1.9055e-01, time/batch = 0.6953s	
2169/33250 (epoch 3.262), train_loss = 1.56950991, grad/param norm = 1.9715e-01, time/batch = 0.6946s	
2170/33250 (epoch 3.263), train_loss = 1.47509051, grad/param norm = 2.1835e-01, time/batch = 0.6919s	
2171/33250 (epoch 3.265), train_loss = 1.58728219, grad/param norm = 2.0106e-01, time/batch = 0.6953s	
2172/33250 (epoch 3.266), train_loss = 1.50465083, grad/param norm = 2.2352e-01, time/batch = 0.6939s	
2173/33250 (epoch 3.268), train_loss = 1.39711717, grad/param norm = 1.8950e-01, time/batch = 0.6983s	
2174/33250 (epoch 3.269), train_loss = 1.23740599, grad/param norm = 1.9567e-01, time/batch = 0.6891s	
2175/33250 (epoch 3.271), train_loss = 1.53277848, grad/param norm = 1.9606e-01, time/batch = 0.7200s	
2176/33250 (epoch 3.272), train_loss = 1.19999749, grad/param norm = 1.6752e-01, time/batch = 0.6964s	
2177/33250 (epoch 3.274), train_loss = 1.18815683, grad/param norm = 1.9135e-01, time/batch = 0.6958s	
2178/33250 (epoch 3.275), train_loss = 1.34688220, grad/param norm = 1.8249e-01, time/batch = 0.6931s	
2179/33250 (epoch 3.277), train_loss = 1.21390360, grad/param norm = 1.9148e-01, time/batch = 0.7011s	
2180/33250 (epoch 3.278), train_loss = 1.27908777, grad/param norm = 1.8148e-01, time/batch = 0.7222s	
2181/33250 (epoch 3.280), train_loss = 1.26489853, grad/param norm = 1.9439e-01, time/batch = 0.7300s	
2182/33250 (epoch 3.281), train_loss = 1.42780893, grad/param norm = 2.1839e-01, time/batch = 0.7023s	
2183/33250 (epoch 3.283), train_loss = 1.53109697, grad/param norm = 2.1732e-01, time/batch = 0.7034s	
2184/33250 (epoch 3.284), train_loss = 1.41832562, grad/param norm = 2.0086e-01, time/batch = 0.7014s	
2185/33250 (epoch 3.286), train_loss = 1.55754825, grad/param norm = 2.2086e-01, time/batch = 0.7003s	
2186/33250 (epoch 3.287), train_loss = 1.32376824, grad/param norm = 1.9736e-01, time/batch = 0.7086s	
2187/33250 (epoch 3.289), train_loss = 1.34135421, grad/param norm = 2.1317e-01, time/batch = 0.7092s	
2188/33250 (epoch 3.290), train_loss = 1.41084089, grad/param norm = 1.7012e-01, time/batch = 0.7021s	
2189/33250 (epoch 3.292), train_loss = 1.45929378, grad/param norm = 2.1864e-01, time/batch = 0.6994s	
2190/33250 (epoch 3.293), train_loss = 1.63679646, grad/param norm = 2.5883e-01, time/batch = 0.6986s	
2191/33250 (epoch 3.295), train_loss = 1.48514967, grad/param norm = 1.9714e-01, time/batch = 0.7094s	
2192/33250 (epoch 3.296), train_loss = 1.45648308, grad/param norm = 1.9315e-01, time/batch = 0.6913s	
2193/33250 (epoch 3.298), train_loss = 1.22252689, grad/param norm = 1.7092e-01, time/batch = 0.6926s	
2194/33250 (epoch 3.299), train_loss = 1.19845560, grad/param norm = 1.7830e-01, time/batch = 0.7025s	
2195/33250 (epoch 3.301), train_loss = 1.55320424, grad/param norm = 2.0266e-01, time/batch = 0.6951s	
2196/33250 (epoch 3.302), train_loss = 1.40281353, grad/param norm = 2.0815e-01, time/batch = 0.6941s	
2197/33250 (epoch 3.304), train_loss = 1.38326708, grad/param norm = 1.8520e-01, time/batch = 0.6934s	
2198/33250 (epoch 3.305), train_loss = 1.39305303, grad/param norm = 1.8027e-01, time/batch = 0.6918s	
2199/33250 (epoch 3.307), train_loss = 1.62769116, grad/param norm = 2.0427e-01, time/batch = 0.6873s	
2200/33250 (epoch 3.308), train_loss = 1.73348963, grad/param norm = 2.3156e-01, time/batch = 0.6955s	
2201/33250 (epoch 3.310), train_loss = 1.49974488, grad/param norm = 2.2153e-01, time/batch = 0.7010s	
2202/33250 (epoch 3.311), train_loss = 1.56462996, grad/param norm = 2.0697e-01, time/batch = 0.6912s	
2203/33250 (epoch 3.313), train_loss = 1.37234169, grad/param norm = 2.2216e-01, time/batch = 0.6987s	
2204/33250 (epoch 3.314), train_loss = 1.45074380, grad/param norm = 2.0046e-01, time/batch = 0.6889s	
2205/33250 (epoch 3.316), train_loss = 1.64453848, grad/param norm = 2.1909e-01, time/batch = 0.6944s	
2206/33250 (epoch 3.317), train_loss = 1.41601131, grad/param norm = 2.2685e-01, time/batch = 0.6902s	
2207/33250 (epoch 3.319), train_loss = 1.66118958, grad/param norm = 2.2996e-01, time/batch = 0.6904s	
2208/33250 (epoch 3.320), train_loss = 1.77674077, grad/param norm = 2.6514e-01, time/batch = 0.6886s	
2209/33250 (epoch 3.322), train_loss = 1.72711105, grad/param norm = 2.4309e-01, time/batch = 0.6976s	
2210/33250 (epoch 3.323), train_loss = 1.81701849, grad/param norm = 2.3664e-01, time/batch = 0.6970s	
2211/33250 (epoch 3.325), train_loss = 1.48151420, grad/param norm = 2.0938e-01, time/batch = 0.6956s	
2212/33250 (epoch 3.326), train_loss = 1.75130114, grad/param norm = 2.3695e-01, time/batch = 0.6911s	
2213/33250 (epoch 3.328), train_loss = 1.43617343, grad/param norm = 2.0661e-01, time/batch = 0.6939s	
2214/33250 (epoch 3.329), train_loss = 1.57928582, grad/param norm = 2.1379e-01, time/batch = 0.6933s	
2215/33250 (epoch 3.331), train_loss = 1.40373995, grad/param norm = 1.9730e-01, time/batch = 0.6929s	
2216/33250 (epoch 3.332), train_loss = 1.40638465, grad/param norm = 2.1069e-01, time/batch = 0.6943s	
2217/33250 (epoch 3.334), train_loss = 1.61604362, grad/param norm = 2.1038e-01, time/batch = 0.6925s	
2218/33250 (epoch 3.335), train_loss = 1.16374245, grad/param norm = 1.8777e-01, time/batch = 0.6950s	
2219/33250 (epoch 3.337), train_loss = 1.49654020, grad/param norm = 1.9801e-01, time/batch = 0.6942s	
2220/33250 (epoch 3.338), train_loss = 1.59061742, grad/param norm = 2.0793e-01, time/batch = 0.6947s	
2221/33250 (epoch 3.340), train_loss = 1.46271911, grad/param norm = 2.1462e-01, time/batch = 0.6956s	
2222/33250 (epoch 3.341), train_loss = 1.45972067, grad/param norm = 2.1147e-01, time/batch = 0.6927s	
2223/33250 (epoch 3.343), train_loss = 1.55951396, grad/param norm = 2.2664e-01, time/batch = 0.6962s	
2224/33250 (epoch 3.344), train_loss = 1.46279981, grad/param norm = 2.2029e-01, time/batch = 0.6915s	
2225/33250 (epoch 3.346), train_loss = 1.28448258, grad/param norm = 1.8764e-01, time/batch = 0.6944s	
2226/33250 (epoch 3.347), train_loss = 1.84001469, grad/param norm = 2.2830e-01, time/batch = 0.6938s	
2227/33250 (epoch 3.349), train_loss = 1.50854995, grad/param norm = 2.3617e-01, time/batch = 0.6886s	
2228/33250 (epoch 3.350), train_loss = 1.52980901, grad/param norm = 2.2788e-01, time/batch = 0.6954s	
2229/33250 (epoch 3.352), train_loss = 1.40112146, grad/param norm = 2.1354e-01, time/batch = 0.7084s	
2230/33250 (epoch 3.353), train_loss = 1.44524553, grad/param norm = 1.9402e-01, time/batch = 0.7173s	
2231/33250 (epoch 3.355), train_loss = 1.43677999, grad/param norm = 2.1409e-01, time/batch = 0.7203s	
2232/33250 (epoch 3.356), train_loss = 1.36980373, grad/param norm = 1.9748e-01, time/batch = 0.7012s	
2233/33250 (epoch 3.358), train_loss = 1.41693463, grad/param norm = 1.9939e-01, time/batch = 0.6974s	
2234/33250 (epoch 3.359), train_loss = 1.34420677, grad/param norm = 1.8565e-01, time/batch = 0.6898s	
2235/33250 (epoch 3.361), train_loss = 1.69116857, grad/param norm = 2.1572e-01, time/batch = 0.6945s	
2236/33250 (epoch 3.362), train_loss = 1.44364275, grad/param norm = 2.1667e-01, time/batch = 0.7269s	
2237/33250 (epoch 3.364), train_loss = 1.63896837, grad/param norm = 2.1037e-01, time/batch = 0.7298s	
2238/33250 (epoch 3.365), train_loss = 1.43469685, grad/param norm = 2.0434e-01, time/batch = 0.7123s	
2239/33250 (epoch 3.367), train_loss = 1.41323998, grad/param norm = 1.9048e-01, time/batch = 0.7211s	
2240/33250 (epoch 3.368), train_loss = 1.46030913, grad/param norm = 1.8592e-01, time/batch = 0.7357s	
2241/33250 (epoch 3.370), train_loss = 1.27869919, grad/param norm = 1.9793e-01, time/batch = 0.7430s	
2242/33250 (epoch 3.371), train_loss = 1.56881682, grad/param norm = 2.0592e-01, time/batch = 0.7381s	
2243/33250 (epoch 3.373), train_loss = 1.42682637, grad/param norm = 2.0901e-01, time/batch = 0.7434s	
2244/33250 (epoch 3.374), train_loss = 1.55641683, grad/param norm = 2.3161e-01, time/batch = 0.7434s	
2245/33250 (epoch 3.376), train_loss = 1.43913613, grad/param norm = 2.1584e-01, time/batch = 0.7458s	
2246/33250 (epoch 3.377), train_loss = 1.38800107, grad/param norm = 2.5078e-01, time/batch = 0.7266s	
2247/33250 (epoch 3.379), train_loss = 1.38205452, grad/param norm = 1.9015e-01, time/batch = 0.7092s	
2248/33250 (epoch 3.380), train_loss = 1.55060684, grad/param norm = 2.2447e-01, time/batch = 0.7409s	
2249/33250 (epoch 3.382), train_loss = 1.60598979, grad/param norm = 2.3890e-01, time/batch = 0.7431s	
2250/33250 (epoch 3.383), train_loss = 1.45341858, grad/param norm = 2.0781e-01, time/batch = 0.7308s	
2251/33250 (epoch 3.385), train_loss = 1.34691292, grad/param norm = 2.0751e-01, time/batch = 0.7248s	
2252/33250 (epoch 3.386), train_loss = 1.37738569, grad/param norm = 2.1318e-01, time/batch = 0.7172s	
2253/33250 (epoch 3.388), train_loss = 1.42995791, grad/param norm = 2.2206e-01, time/batch = 0.7199s	
2254/33250 (epoch 3.389), train_loss = 1.47284162, grad/param norm = 2.2131e-01, time/batch = 0.6971s	
2255/33250 (epoch 3.391), train_loss = 1.45843540, grad/param norm = 2.1295e-01, time/batch = 0.6992s	
2256/33250 (epoch 3.392), train_loss = 1.63886987, grad/param norm = 2.2739e-01, time/batch = 0.7045s	
2257/33250 (epoch 3.394), train_loss = 1.76041559, grad/param norm = 2.5103e-01, time/batch = 0.7005s	
2258/33250 (epoch 3.395), train_loss = 1.68573257, grad/param norm = 2.2352e-01, time/batch = 0.7032s	
2259/33250 (epoch 3.397), train_loss = 1.59763935, grad/param norm = 2.3038e-01, time/batch = 0.6989s	
2260/33250 (epoch 3.398), train_loss = 1.48904550, grad/param norm = 2.2085e-01, time/batch = 0.6959s	
2261/33250 (epoch 3.400), train_loss = 1.41153085, grad/param norm = 1.9070e-01, time/batch = 0.7031s	
2262/33250 (epoch 3.402), train_loss = 1.34909630, grad/param norm = 2.1777e-01, time/batch = 0.6984s	
2263/33250 (epoch 3.403), train_loss = 1.37579386, grad/param norm = 2.0176e-01, time/batch = 0.6960s	
2264/33250 (epoch 3.405), train_loss = 1.35463662, grad/param norm = 2.1852e-01, time/batch = 0.7016s	
2265/33250 (epoch 3.406), train_loss = 1.51225679, grad/param norm = 2.2464e-01, time/batch = 0.6998s	
2266/33250 (epoch 3.408), train_loss = 1.62542078, grad/param norm = 2.0640e-01, time/batch = 0.7043s	
2267/33250 (epoch 3.409), train_loss = 1.59953378, grad/param norm = 2.5364e-01, time/batch = 0.7107s	
2268/33250 (epoch 3.411), train_loss = 1.19459313, grad/param norm = 2.4285e-01, time/batch = 0.6995s	
2269/33250 (epoch 3.412), train_loss = 1.27805672, grad/param norm = 1.8974e-01, time/batch = 0.7004s	
2270/33250 (epoch 3.414), train_loss = 1.53810629, grad/param norm = 2.0496e-01, time/batch = 0.6979s	
2271/33250 (epoch 3.415), train_loss = 1.54371852, grad/param norm = 2.2135e-01, time/batch = 0.6988s	
2272/33250 (epoch 3.417), train_loss = 1.55095304, grad/param norm = 2.1640e-01, time/batch = 0.7005s	
2273/33250 (epoch 3.418), train_loss = 1.75916654, grad/param norm = 2.6881e-01, time/batch = 0.6974s	
2274/33250 (epoch 3.420), train_loss = 1.58902831, grad/param norm = 2.2259e-01, time/batch = 0.6990s	
2275/33250 (epoch 3.421), train_loss = 1.33993821, grad/param norm = 2.2007e-01, time/batch = 0.6942s	
2276/33250 (epoch 3.423), train_loss = 1.58516188, grad/param norm = 2.1796e-01, time/batch = 0.6984s	
2277/33250 (epoch 3.424), train_loss = 1.77648728, grad/param norm = 2.7571e-01, time/batch = 0.6943s	
2278/33250 (epoch 3.426), train_loss = 1.36068751, grad/param norm = 1.8689e-01, time/batch = 0.6956s	
2279/33250 (epoch 3.427), train_loss = 1.35037659, grad/param norm = 2.2302e-01, time/batch = 0.7072s	
2280/33250 (epoch 3.429), train_loss = 1.57554357, grad/param norm = 2.3346e-01, time/batch = 0.6972s	
2281/33250 (epoch 3.430), train_loss = 1.39857314, grad/param norm = 2.2582e-01, time/batch = 0.7017s	
2282/33250 (epoch 3.432), train_loss = 1.42893462, grad/param norm = 1.8802e-01, time/batch = 0.7020s	
2283/33250 (epoch 3.433), train_loss = 1.46761272, grad/param norm = 2.0431e-01, time/batch = 0.6985s	
2284/33250 (epoch 3.435), train_loss = 1.54657765, grad/param norm = 2.4498e-01, time/batch = 0.6976s	
2285/33250 (epoch 3.436), train_loss = 1.47841992, grad/param norm = 2.2030e-01, time/batch = 0.6972s	
2286/33250 (epoch 3.438), train_loss = 1.42876468, grad/param norm = 2.2276e-01, time/batch = 0.6963s	
2287/33250 (epoch 3.439), train_loss = 1.46380504, grad/param norm = 2.1114e-01, time/batch = 0.6939s	
2288/33250 (epoch 3.441), train_loss = 1.47042598, grad/param norm = 2.1003e-01, time/batch = 0.6962s	
2289/33250 (epoch 3.442), train_loss = 1.44705305, grad/param norm = 2.0624e-01, time/batch = 0.7036s	
2290/33250 (epoch 3.444), train_loss = 1.31500042, grad/param norm = 2.2739e-01, time/batch = 0.7033s	
2291/33250 (epoch 3.445), train_loss = 1.48640311, grad/param norm = 1.9498e-01, time/batch = 0.7014s	
2292/33250 (epoch 3.447), train_loss = 1.48746332, grad/param norm = 1.9874e-01, time/batch = 0.7237s	
2293/33250 (epoch 3.448), train_loss = 1.36608953, grad/param norm = 1.9506e-01, time/batch = 0.7362s	
2294/33250 (epoch 3.450), train_loss = 1.72448997, grad/param norm = 2.4458e-01, time/batch = 0.7109s	
2295/33250 (epoch 3.451), train_loss = 1.55609925, grad/param norm = 2.2698e-01, time/batch = 0.7020s	
2296/33250 (epoch 3.453), train_loss = 1.26377675, grad/param norm = 1.8771e-01, time/batch = 0.6972s	
2297/33250 (epoch 3.454), train_loss = 1.60220119, grad/param norm = 2.2461e-01, time/batch = 0.6958s	
2298/33250 (epoch 3.456), train_loss = 1.62492146, grad/param norm = 2.3702e-01, time/batch = 0.6941s	
2299/33250 (epoch 3.457), train_loss = 1.48752004, grad/param norm = 2.1109e-01, time/batch = 0.6952s	
2300/33250 (epoch 3.459), train_loss = 1.49393812, grad/param norm = 1.9391e-01, time/batch = 0.6922s	
2301/33250 (epoch 3.460), train_loss = 1.50995219, grad/param norm = 2.2614e-01, time/batch = 0.6979s	
2302/33250 (epoch 3.462), train_loss = 1.41433250, grad/param norm = 1.9862e-01, time/batch = 0.7028s	
2303/33250 (epoch 3.463), train_loss = 1.28914733, grad/param norm = 1.7966e-01, time/batch = 0.7064s	
2304/33250 (epoch 3.465), train_loss = 1.19777206, grad/param norm = 1.8383e-01, time/batch = 0.6996s	
2305/33250 (epoch 3.466), train_loss = 1.17631335, grad/param norm = 1.7429e-01, time/batch = 0.7000s	
2306/33250 (epoch 3.468), train_loss = 1.28365156, grad/param norm = 1.8917e-01, time/batch = 0.6969s	
2307/33250 (epoch 3.469), train_loss = 1.55888486, grad/param norm = 2.1464e-01, time/batch = 0.6950s	
2308/33250 (epoch 3.471), train_loss = 1.58715971, grad/param norm = 2.0677e-01, time/batch = 0.6918s	
2309/33250 (epoch 3.472), train_loss = 1.51515078, grad/param norm = 2.4689e-01, time/batch = 0.6936s	
2310/33250 (epoch 3.474), train_loss = 1.79744139, grad/param norm = 2.6077e-01, time/batch = 0.6916s	
2311/33250 (epoch 3.475), train_loss = 1.50673200, grad/param norm = 2.2432e-01, time/batch = 0.6958s	
2312/33250 (epoch 3.477), train_loss = 1.47279641, grad/param norm = 2.0149e-01, time/batch = 0.6962s	
2313/33250 (epoch 3.478), train_loss = 1.42964412, grad/param norm = 1.9870e-01, time/batch = 0.7056s	
2314/33250 (epoch 3.480), train_loss = 1.68059139, grad/param norm = 2.0156e-01, time/batch = 0.7160s	
2315/33250 (epoch 3.481), train_loss = 1.42432242, grad/param norm = 2.2897e-01, time/batch = 0.7253s	
2316/33250 (epoch 3.483), train_loss = 1.51917204, grad/param norm = 2.1689e-01, time/batch = 0.7075s	
2317/33250 (epoch 3.484), train_loss = 1.39496807, grad/param norm = 2.0652e-01, time/batch = 0.7006s	
2318/33250 (epoch 3.486), train_loss = 1.26133360, grad/param norm = 1.8998e-01, time/batch = 0.7029s	
2319/33250 (epoch 3.487), train_loss = 1.44635299, grad/param norm = 2.2192e-01, time/batch = 0.6933s	
2320/33250 (epoch 3.489), train_loss = 1.64873081, grad/param norm = 2.4985e-01, time/batch = 0.6956s	
2321/33250 (epoch 3.490), train_loss = 1.57673810, grad/param norm = 2.2763e-01, time/batch = 0.7000s	
2322/33250 (epoch 3.492), train_loss = 1.50031677, grad/param norm = 2.2167e-01, time/batch = 0.7020s	
2323/33250 (epoch 3.493), train_loss = 1.47908659, grad/param norm = 2.0998e-01, time/batch = 0.6990s	
2324/33250 (epoch 3.495), train_loss = 1.48086483, grad/param norm = 2.0106e-01, time/batch = 0.6889s	
2325/33250 (epoch 3.496), train_loss = 1.41302090, grad/param norm = 1.9709e-01, time/batch = 0.7029s	
2326/33250 (epoch 3.498), train_loss = 1.54258056, grad/param norm = 2.3305e-01, time/batch = 0.7064s	
2327/33250 (epoch 3.499), train_loss = 1.46717158, grad/param norm = 2.1138e-01, time/batch = 0.7019s	
2328/33250 (epoch 3.501), train_loss = 1.39095819, grad/param norm = 2.3597e-01, time/batch = 0.6974s	
2329/33250 (epoch 3.502), train_loss = 1.47390847, grad/param norm = 2.2641e-01, time/batch = 0.6996s	
2330/33250 (epoch 3.504), train_loss = 1.70031938, grad/param norm = 2.2407e-01, time/batch = 0.6933s	
2331/33250 (epoch 3.505), train_loss = 1.19167510, grad/param norm = 1.9201e-01, time/batch = 0.6923s	
2332/33250 (epoch 3.507), train_loss = 1.54613486, grad/param norm = 2.0557e-01, time/batch = 0.6916s	
2333/33250 (epoch 3.508), train_loss = 1.39719163, grad/param norm = 2.0046e-01, time/batch = 0.6925s	
2334/33250 (epoch 3.510), train_loss = 1.32251041, grad/param norm = 1.9789e-01, time/batch = 0.6902s	
2335/33250 (epoch 3.511), train_loss = 1.52771222, grad/param norm = 2.0149e-01, time/batch = 0.6897s	
2336/33250 (epoch 3.513), train_loss = 1.74148377, grad/param norm = 2.2045e-01, time/batch = 0.6938s	
2337/33250 (epoch 3.514), train_loss = 1.42616588, grad/param norm = 1.8908e-01, time/batch = 0.6941s	
2338/33250 (epoch 3.516), train_loss = 1.43793897, grad/param norm = 2.0016e-01, time/batch = 0.6946s	
2339/33250 (epoch 3.517), train_loss = 1.48698186, grad/param norm = 2.1136e-01, time/batch = 0.6988s	
2340/33250 (epoch 3.519), train_loss = 1.27020598, grad/param norm = 1.8928e-01, time/batch = 0.7055s	
2341/33250 (epoch 3.520), train_loss = 1.77668550, grad/param norm = 2.3083e-01, time/batch = 0.7162s	
2342/33250 (epoch 3.522), train_loss = 1.56527773, grad/param norm = 2.1382e-01, time/batch = 0.7028s	
2343/33250 (epoch 3.523), train_loss = 1.42752216, grad/param norm = 2.1567e-01, time/batch = 0.7100s	
2344/33250 (epoch 3.525), train_loss = 1.28598700, grad/param norm = 2.0212e-01, time/batch = 0.7063s	
2345/33250 (epoch 3.526), train_loss = 1.29990053, grad/param norm = 2.2020e-01, time/batch = 0.7097s	
2346/33250 (epoch 3.528), train_loss = 1.43125682, grad/param norm = 2.0680e-01, time/batch = 0.7089s	
2347/33250 (epoch 3.529), train_loss = 1.36726845, grad/param norm = 1.9383e-01, time/batch = 0.7106s	
2348/33250 (epoch 3.531), train_loss = 1.24972648, grad/param norm = 2.0851e-01, time/batch = 0.7101s	
2349/33250 (epoch 3.532), train_loss = 1.61041158, grad/param norm = 1.9707e-01, time/batch = 0.7113s	
2350/33250 (epoch 3.534), train_loss = 1.44730555, grad/param norm = 1.9532e-01, time/batch = 0.7088s	
2351/33250 (epoch 3.535), train_loss = 1.46264478, grad/param norm = 1.8975e-01, time/batch = 0.7125s	
2352/33250 (epoch 3.537), train_loss = 1.58583172, grad/param norm = 1.9917e-01, time/batch = 0.7013s	
2353/33250 (epoch 3.538), train_loss = 1.53564061, grad/param norm = 2.1889e-01, time/batch = 0.7044s	
2354/33250 (epoch 3.540), train_loss = 1.60947119, grad/param norm = 2.0796e-01, time/batch = 0.7015s	
2355/33250 (epoch 3.541), train_loss = 1.61106957, grad/param norm = 2.3008e-01, time/batch = 0.7131s	
2356/33250 (epoch 3.543), train_loss = 1.63353809, grad/param norm = 2.3107e-01, time/batch = 0.7054s	
2357/33250 (epoch 3.544), train_loss = 1.48777402, grad/param norm = 2.4393e-01, time/batch = 0.6972s	
2358/33250 (epoch 3.546), train_loss = 1.48595046, grad/param norm = 2.0283e-01, time/batch = 0.6996s	
2359/33250 (epoch 3.547), train_loss = 1.34578684, grad/param norm = 2.0073e-01, time/batch = 0.6956s	
2360/33250 (epoch 3.549), train_loss = 1.48138273, grad/param norm = 2.0729e-01, time/batch = 0.6984s	
2361/33250 (epoch 3.550), train_loss = 1.39469776, grad/param norm = 1.9594e-01, time/batch = 0.7019s	
2362/33250 (epoch 3.552), train_loss = 1.55521673, grad/param norm = 2.3339e-01, time/batch = 0.6940s	
2363/33250 (epoch 3.553), train_loss = 1.35207265, grad/param norm = 2.0342e-01, time/batch = 0.6999s	
2364/33250 (epoch 3.555), train_loss = 1.42993100, grad/param norm = 1.9113e-01, time/batch = 0.7001s	
2365/33250 (epoch 3.556), train_loss = 1.63927116, grad/param norm = 2.2430e-01, time/batch = 0.6975s	
2366/33250 (epoch 3.558), train_loss = 1.55890935, grad/param norm = 2.0737e-01, time/batch = 0.6981s	
2367/33250 (epoch 3.559), train_loss = 1.33060539, grad/param norm = 2.0329e-01, time/batch = 0.6964s	
2368/33250 (epoch 3.561), train_loss = 1.46451163, grad/param norm = 2.1107e-01, time/batch = 0.6952s	
2369/33250 (epoch 3.562), train_loss = 1.64104492, grad/param norm = 2.2374e-01, time/batch = 0.6944s	
2370/33250 (epoch 3.564), train_loss = 1.66149232, grad/param norm = 2.2835e-01, time/batch = 0.6979s	
2371/33250 (epoch 3.565), train_loss = 1.64850642, grad/param norm = 2.1902e-01, time/batch = 0.6957s	
2372/33250 (epoch 3.567), train_loss = 1.53602384, grad/param norm = 2.0262e-01, time/batch = 0.6912s	
2373/33250 (epoch 3.568), train_loss = 1.40631688, grad/param norm = 2.0673e-01, time/batch = 0.6925s	
2374/33250 (epoch 3.570), train_loss = 1.65986935, grad/param norm = 2.3622e-01, time/batch = 0.6999s	
2375/33250 (epoch 3.571), train_loss = 1.68173571, grad/param norm = 2.0015e-01, time/batch = 0.6972s	
2376/33250 (epoch 3.573), train_loss = 1.58959343, grad/param norm = 1.9513e-01, time/batch = 0.6945s	
2377/33250 (epoch 3.574), train_loss = 1.34807215, grad/param norm = 1.9409e-01, time/batch = 0.6968s	
2378/33250 (epoch 3.576), train_loss = 1.51768072, grad/param norm = 2.0472e-01, time/batch = 0.6979s	
2379/33250 (epoch 3.577), train_loss = 1.46348815, grad/param norm = 1.8811e-01, time/batch = 0.6993s	
2380/33250 (epoch 3.579), train_loss = 1.31515367, grad/param norm = 1.9470e-01, time/batch = 0.6960s	
2381/33250 (epoch 3.580), train_loss = 1.27267847, grad/param norm = 1.8709e-01, time/batch = 0.6967s	
2382/33250 (epoch 3.582), train_loss = 1.41074462, grad/param norm = 1.8844e-01, time/batch = 0.6943s	
2383/33250 (epoch 3.583), train_loss = 1.45794356, grad/param norm = 1.8623e-01, time/batch = 0.6941s	
2384/33250 (epoch 3.585), train_loss = 1.58549998, grad/param norm = 2.3094e-01, time/batch = 0.6980s	
2385/33250 (epoch 3.586), train_loss = 1.40344906, grad/param norm = 2.2992e-01, time/batch = 0.6929s	
2386/33250 (epoch 3.588), train_loss = 1.50063973, grad/param norm = 2.0984e-01, time/batch = 0.6980s	
2387/33250 (epoch 3.589), train_loss = 1.57325988, grad/param norm = 2.1432e-01, time/batch = 0.7012s	
2388/33250 (epoch 3.591), train_loss = 1.59634831, grad/param norm = 2.2005e-01, time/batch = 0.6916s	
2389/33250 (epoch 3.592), train_loss = 1.44094120, grad/param norm = 1.8831e-01, time/batch = 0.6927s	
2390/33250 (epoch 3.594), train_loss = 1.69544842, grad/param norm = 2.2240e-01, time/batch = 0.6908s	
2391/33250 (epoch 3.595), train_loss = 1.67083308, grad/param norm = 2.0488e-01, time/batch = 0.6918s	
2392/33250 (epoch 3.597), train_loss = 1.38210468, grad/param norm = 1.9655e-01, time/batch = 0.6905s	
2393/33250 (epoch 3.598), train_loss = 1.57586577, grad/param norm = 1.9896e-01, time/batch = 0.6868s	
2394/33250 (epoch 3.600), train_loss = 1.48129375, grad/param norm = 2.0347e-01, time/batch = 0.6867s	
2395/33250 (epoch 3.602), train_loss = 1.58621815, grad/param norm = 2.5045e-01, time/batch = 0.6995s	
2396/33250 (epoch 3.603), train_loss = 1.43296012, grad/param norm = 1.9061e-01, time/batch = 0.7186s	
2397/33250 (epoch 3.605), train_loss = 1.49621653, grad/param norm = 2.1069e-01, time/batch = 0.7043s	
2398/33250 (epoch 3.606), train_loss = 1.53045935, grad/param norm = 2.0427e-01, time/batch = 0.7116s	
2399/33250 (epoch 3.608), train_loss = 1.47593728, grad/param norm = 2.0878e-01, time/batch = 0.7200s	
2400/33250 (epoch 3.609), train_loss = 1.39924069, grad/param norm = 2.1556e-01, time/batch = 0.7318s	
2401/33250 (epoch 3.611), train_loss = 1.61651620, grad/param norm = 2.1632e-01, time/batch = 0.7451s	
2402/33250 (epoch 3.612), train_loss = 1.52643900, grad/param norm = 2.1064e-01, time/batch = 0.7374s	
2403/33250 (epoch 3.614), train_loss = 1.80648784, grad/param norm = 2.4859e-01, time/batch = 0.7244s	
2404/33250 (epoch 3.615), train_loss = 1.62796196, grad/param norm = 2.1886e-01, time/batch = 0.7261s	
2405/33250 (epoch 3.617), train_loss = 1.92729667, grad/param norm = 2.0416e-01, time/batch = 0.7195s	
2406/33250 (epoch 3.618), train_loss = 1.83119025, grad/param norm = 2.7180e-01, time/batch = 0.7352s	
2407/33250 (epoch 3.620), train_loss = 1.67253312, grad/param norm = 2.2811e-01, time/batch = 0.7344s	
2408/33250 (epoch 3.621), train_loss = 1.43470834, grad/param norm = 1.8461e-01, time/batch = 0.7182s	
2409/33250 (epoch 3.623), train_loss = 1.42575466, grad/param norm = 2.2345e-01, time/batch = 0.7258s	
2410/33250 (epoch 3.624), train_loss = 1.50539869, grad/param norm = 2.2557e-01, time/batch = 0.7253s	
2411/33250 (epoch 3.626), train_loss = 1.54335869, grad/param norm = 2.0295e-01, time/batch = 0.7216s	
2412/33250 (epoch 3.627), train_loss = 1.48995416, grad/param norm = 1.9078e-01, time/batch = 0.7218s	
2413/33250 (epoch 3.629), train_loss = 1.46386680, grad/param norm = 2.2865e-01, time/batch = 0.7054s	
2414/33250 (epoch 3.630), train_loss = 1.48229539, grad/param norm = 2.0912e-01, time/batch = 0.7120s	
2415/33250 (epoch 3.632), train_loss = 1.26010084, grad/param norm = 1.8158e-01, time/batch = 0.6968s	
2416/33250 (epoch 3.633), train_loss = 1.59639417, grad/param norm = 2.2638e-01, time/batch = 0.6994s	
2417/33250 (epoch 3.635), train_loss = 1.33611002, grad/param norm = 1.8642e-01, time/batch = 0.7033s	
2418/33250 (epoch 3.636), train_loss = 1.41018625, grad/param norm = 2.0102e-01, time/batch = 0.7086s	
2419/33250 (epoch 3.638), train_loss = 1.43367557, grad/param norm = 2.0355e-01, time/batch = 0.7078s	
2420/33250 (epoch 3.639), train_loss = 1.44675436, grad/param norm = 2.3220e-01, time/batch = 0.6964s	
2421/33250 (epoch 3.641), train_loss = 1.36142053, grad/param norm = 1.8954e-01, time/batch = 0.6966s	
2422/33250 (epoch 3.642), train_loss = 1.37592330, grad/param norm = 1.8672e-01, time/batch = 0.7037s	
2423/33250 (epoch 3.644), train_loss = 1.23771858, grad/param norm = 1.9131e-01, time/batch = 0.6965s	
2424/33250 (epoch 3.645), train_loss = 1.63006831, grad/param norm = 2.3408e-01, time/batch = 0.7009s	
2425/33250 (epoch 3.647), train_loss = 1.35343091, grad/param norm = 1.9077e-01, time/batch = 0.6949s	
2426/33250 (epoch 3.648), train_loss = 1.44183306, grad/param norm = 2.2589e-01, time/batch = 0.6911s	
2427/33250 (epoch 3.650), train_loss = 1.64960119, grad/param norm = 2.4031e-01, time/batch = 0.6943s	
2428/33250 (epoch 3.651), train_loss = 1.50016620, grad/param norm = 2.3469e-01, time/batch = 0.6873s	
2429/33250 (epoch 3.653), train_loss = 1.30161850, grad/param norm = 1.7609e-01, time/batch = 0.6952s	
2430/33250 (epoch 3.654), train_loss = 1.32529827, grad/param norm = 1.7396e-01, time/batch = 0.6944s	
2431/33250 (epoch 3.656), train_loss = 1.51840802, grad/param norm = 2.0100e-01, time/batch = 0.6907s	
2432/33250 (epoch 3.657), train_loss = 1.28759780, grad/param norm = 1.9561e-01, time/batch = 0.6910s	
2433/33250 (epoch 3.659), train_loss = 1.34381134, grad/param norm = 1.8563e-01, time/batch = 0.6989s	
2434/33250 (epoch 3.660), train_loss = 1.37093670, grad/param norm = 2.2598e-01, time/batch = 0.6919s	
2435/33250 (epoch 3.662), train_loss = 1.49387458, grad/param norm = 2.1114e-01, time/batch = 0.6892s	
2436/33250 (epoch 3.663), train_loss = 1.38104293, grad/param norm = 1.9847e-01, time/batch = 0.6925s	
2437/33250 (epoch 3.665), train_loss = 1.60732086, grad/param norm = 2.1833e-01, time/batch = 0.6908s	
2438/33250 (epoch 3.666), train_loss = 1.44208207, grad/param norm = 2.2969e-01, time/batch = 0.7003s	
2439/33250 (epoch 3.668), train_loss = 1.59095955, grad/param norm = 2.0424e-01, time/batch = 0.6905s	
2440/33250 (epoch 3.669), train_loss = 1.56838148, grad/param norm = 2.1072e-01, time/batch = 0.6926s	
2441/33250 (epoch 3.671), train_loss = 1.48815761, grad/param norm = 2.1021e-01, time/batch = 0.6998s	
2442/33250 (epoch 3.672), train_loss = 1.63383199, grad/param norm = 2.2279e-01, time/batch = 0.6961s	
2443/33250 (epoch 3.674), train_loss = 1.42892232, grad/param norm = 1.8344e-01, time/batch = 0.6915s	
2444/33250 (epoch 3.675), train_loss = 1.55436294, grad/param norm = 2.1419e-01, time/batch = 0.6931s	
2445/33250 (epoch 3.677), train_loss = 1.47954895, grad/param norm = 2.0370e-01, time/batch = 0.6942s	
2446/33250 (epoch 3.678), train_loss = 1.52650462, grad/param norm = 2.0625e-01, time/batch = 0.6944s	
2447/33250 (epoch 3.680), train_loss = 1.55535717, grad/param norm = 2.0882e-01, time/batch = 0.6960s	
2448/33250 (epoch 3.681), train_loss = 1.28215053, grad/param norm = 1.9008e-01, time/batch = 0.7083s	
2449/33250 (epoch 3.683), train_loss = 1.37708917, grad/param norm = 2.3721e-01, time/batch = 0.7107s	
2450/33250 (epoch 3.684), train_loss = 1.45394537, grad/param norm = 2.5573e-01, time/batch = 0.7107s	
2451/33250 (epoch 3.686), train_loss = 1.33526747, grad/param norm = 1.8206e-01, time/batch = 0.7063s	
2452/33250 (epoch 3.687), train_loss = 1.36697280, grad/param norm = 1.9757e-01, time/batch = 0.7089s	
2453/33250 (epoch 3.689), train_loss = 1.37476043, grad/param norm = 2.0013e-01, time/batch = 0.7033s	
2454/33250 (epoch 3.690), train_loss = 1.57465796, grad/param norm = 2.2494e-01, time/batch = 0.7087s	
2455/33250 (epoch 3.692), train_loss = 1.59762758, grad/param norm = 2.4042e-01, time/batch = 0.6979s	
2456/33250 (epoch 3.693), train_loss = 1.43877844, grad/param norm = 1.8254e-01, time/batch = 0.6921s	
2457/33250 (epoch 3.695), train_loss = 1.55101263, grad/param norm = 2.1800e-01, time/batch = 0.6921s	
2458/33250 (epoch 3.696), train_loss = 1.44408234, grad/param norm = 1.8425e-01, time/batch = 0.6931s	
2459/33250 (epoch 3.698), train_loss = 1.35381948, grad/param norm = 2.0655e-01, time/batch = 0.6994s	
2460/33250 (epoch 3.699), train_loss = 1.65608912, grad/param norm = 2.0631e-01, time/batch = 0.7124s	
2461/33250 (epoch 3.701), train_loss = 1.38554969, grad/param norm = 1.8595e-01, time/batch = 0.7012s	
2462/33250 (epoch 3.702), train_loss = 1.55885311, grad/param norm = 2.3202e-01, time/batch = 0.6962s	
2463/33250 (epoch 3.704), train_loss = 1.65150312, grad/param norm = 2.3133e-01, time/batch = 0.6961s	
2464/33250 (epoch 3.705), train_loss = 1.34268416, grad/param norm = 1.8813e-01, time/batch = 0.6979s	
2465/33250 (epoch 3.707), train_loss = 1.32501278, grad/param norm = 2.1056e-01, time/batch = 0.6952s	
2466/33250 (epoch 3.708), train_loss = 1.51015201, grad/param norm = 2.0657e-01, time/batch = 0.6962s	
2467/33250 (epoch 3.710), train_loss = 1.60232104, grad/param norm = 2.2795e-01, time/batch = 0.6970s	
2468/33250 (epoch 3.711), train_loss = 1.57681962, grad/param norm = 2.2668e-01, time/batch = 0.6942s	
2469/33250 (epoch 3.713), train_loss = 1.59469805, grad/param norm = 2.5132e-01, time/batch = 0.6997s	
2470/33250 (epoch 3.714), train_loss = 1.55623261, grad/param norm = 1.9822e-01, time/batch = 0.6910s	
2471/33250 (epoch 3.716), train_loss = 1.64484624, grad/param norm = 2.2452e-01, time/batch = 0.6954s	
2472/33250 (epoch 3.717), train_loss = 1.39739768, grad/param norm = 1.9320e-01, time/batch = 0.6955s	
2473/33250 (epoch 3.719), train_loss = 1.52331705, grad/param norm = 2.1775e-01, time/batch = 0.6934s	
2474/33250 (epoch 3.720), train_loss = 1.69938711, grad/param norm = 2.0237e-01, time/batch = 0.6917s	
2475/33250 (epoch 3.722), train_loss = 1.36646811, grad/param norm = 1.7579e-01, time/batch = 0.6893s	
2476/33250 (epoch 3.723), train_loss = 1.24303536, grad/param norm = 1.7895e-01, time/batch = 0.7078s	
2477/33250 (epoch 3.725), train_loss = 1.19342882, grad/param norm = 1.6043e-01, time/batch = 0.7090s	
2478/33250 (epoch 3.726), train_loss = 1.36632460, grad/param norm = 1.8606e-01, time/batch = 0.6971s	
2479/33250 (epoch 3.728), train_loss = 1.52191923, grad/param norm = 2.1098e-01, time/batch = 0.7170s	
2480/33250 (epoch 3.729), train_loss = 1.62014158, grad/param norm = 2.1887e-01, time/batch = 0.7122s	
2481/33250 (epoch 3.731), train_loss = 1.39126557, grad/param norm = 1.9749e-01, time/batch = 0.7025s	
2482/33250 (epoch 3.732), train_loss = 1.36641984, grad/param norm = 1.9273e-01, time/batch = 0.6955s	
2483/33250 (epoch 3.734), train_loss = 1.50835523, grad/param norm = 1.9784e-01, time/batch = 0.7046s	
2484/33250 (epoch 3.735), train_loss = 1.50340502, grad/param norm = 1.9622e-01, time/batch = 0.7096s	
2485/33250 (epoch 3.737), train_loss = 1.54744268, grad/param norm = 1.8482e-01, time/batch = 0.7225s	
2486/33250 (epoch 3.738), train_loss = 1.50202353, grad/param norm = 1.8654e-01, time/batch = 0.7124s	
2487/33250 (epoch 3.740), train_loss = 1.68580229, grad/param norm = 2.0846e-01, time/batch = 0.7032s	
2488/33250 (epoch 3.741), train_loss = 1.50383389, grad/param norm = 2.1052e-01, time/batch = 0.7164s	
2489/33250 (epoch 3.743), train_loss = 1.44361358, grad/param norm = 1.8787e-01, time/batch = 0.7172s	
2490/33250 (epoch 3.744), train_loss = 1.47815582, grad/param norm = 1.9954e-01, time/batch = 0.7070s	
2491/33250 (epoch 3.746), train_loss = 1.49589703, grad/param norm = 1.8199e-01, time/batch = 0.7064s	
2492/33250 (epoch 3.747), train_loss = 1.43886462, grad/param norm = 2.0427e-01, time/batch = 0.7003s	
2493/33250 (epoch 3.749), train_loss = 1.66391933, grad/param norm = 2.3682e-01, time/batch = 0.6990s	
2494/33250 (epoch 3.750), train_loss = 1.49708104, grad/param norm = 2.2176e-01, time/batch = 0.6960s	
2495/33250 (epoch 3.752), train_loss = 1.33911606, grad/param norm = 1.8032e-01, time/batch = 0.6979s	
2496/33250 (epoch 3.753), train_loss = 1.44616934, grad/param norm = 1.9149e-01, time/batch = 0.7130s	
2497/33250 (epoch 3.755), train_loss = 1.35717127, grad/param norm = 2.0101e-01, time/batch = 0.7055s	
2498/33250 (epoch 3.756), train_loss = 1.56861068, grad/param norm = 2.0035e-01, time/batch = 0.7082s	
2499/33250 (epoch 3.758), train_loss = 1.53213771, grad/param norm = 1.9504e-01, time/batch = 0.6959s	
2500/33250 (epoch 3.759), train_loss = 1.31619133, grad/param norm = 1.8289e-01, time/batch = 0.6947s	
2501/33250 (epoch 3.761), train_loss = 1.43311452, grad/param norm = 2.1754e-01, time/batch = 0.7005s	
2502/33250 (epoch 3.762), train_loss = 1.50681869, grad/param norm = 2.2272e-01, time/batch = 0.6991s	
2503/33250 (epoch 3.764), train_loss = 1.39477212, grad/param norm = 2.6588e-01, time/batch = 0.6981s	
2504/33250 (epoch 3.765), train_loss = 1.48960531, grad/param norm = 2.2554e-01, time/batch = 0.6952s	
2505/33250 (epoch 3.767), train_loss = 1.26444754, grad/param norm = 2.3276e-01, time/batch = 0.6933s	
2506/33250 (epoch 3.768), train_loss = 1.36024216, grad/param norm = 2.1022e-01, time/batch = 0.6973s	
2507/33250 (epoch 3.770), train_loss = 1.47670097, grad/param norm = 2.2091e-01, time/batch = 0.6966s	
2508/33250 (epoch 3.771), train_loss = 1.55008619, grad/param norm = 2.1190e-01, time/batch = 0.6966s	
2509/33250 (epoch 3.773), train_loss = 1.43979743, grad/param norm = 2.1684e-01, time/batch = 0.6977s	
2510/33250 (epoch 3.774), train_loss = 1.26928022, grad/param norm = 2.0540e-01, time/batch = 0.6951s	
2511/33250 (epoch 3.776), train_loss = 1.41661054, grad/param norm = 2.0727e-01, time/batch = 0.7032s	
2512/33250 (epoch 3.777), train_loss = 1.60317458, grad/param norm = 2.4555e-01, time/batch = 0.6990s	
2513/33250 (epoch 3.779), train_loss = 1.31830593, grad/param norm = 1.9823e-01, time/batch = 0.6950s	
2514/33250 (epoch 3.780), train_loss = 1.67331117, grad/param norm = 2.3338e-01, time/batch = 0.6952s	
2515/33250 (epoch 3.782), train_loss = 1.49191528, grad/param norm = 2.1374e-01, time/batch = 0.6976s	
2516/33250 (epoch 3.783), train_loss = 1.26911353, grad/param norm = 1.9291e-01, time/batch = 0.6931s	
2517/33250 (epoch 3.785), train_loss = 1.36787475, grad/param norm = 2.0240e-01, time/batch = 0.6982s	
2518/33250 (epoch 3.786), train_loss = 1.57707732, grad/param norm = 2.1785e-01, time/batch = 0.6958s	
2519/33250 (epoch 3.788), train_loss = 1.41439127, grad/param norm = 1.8729e-01, time/batch = 0.6994s	
2520/33250 (epoch 3.789), train_loss = 1.54912988, grad/param norm = 2.0858e-01, time/batch = 0.6900s	
2521/33250 (epoch 3.791), train_loss = 1.58437849, grad/param norm = 2.0128e-01, time/batch = 0.7000s	
2522/33250 (epoch 3.792), train_loss = 1.65578904, grad/param norm = 1.9569e-01, time/batch = 0.6964s	
2523/33250 (epoch 3.794), train_loss = 1.36031962, grad/param norm = 2.0546e-01, time/batch = 0.6979s	
2524/33250 (epoch 3.795), train_loss = 1.52963370, grad/param norm = 1.9677e-01, time/batch = 0.6985s	
2525/33250 (epoch 3.797), train_loss = 1.60897558, grad/param norm = 2.1177e-01, time/batch = 0.7082s	
2526/33250 (epoch 3.798), train_loss = 1.58179683, grad/param norm = 2.7162e-01, time/batch = 0.6921s	
2527/33250 (epoch 3.800), train_loss = 1.60794656, grad/param norm = 2.4123e-01, time/batch = 0.6954s	
2528/33250 (epoch 3.802), train_loss = 1.41726992, grad/param norm = 2.0894e-01, time/batch = 0.6934s	
2529/33250 (epoch 3.803), train_loss = 1.41226598, grad/param norm = 1.8977e-01, time/batch = 0.6952s	
2530/33250 (epoch 3.805), train_loss = 1.49766626, grad/param norm = 2.0926e-01, time/batch = 0.6931s	
2531/33250 (epoch 3.806), train_loss = 1.55536375, grad/param norm = 1.9998e-01, time/batch = 0.6976s	
2532/33250 (epoch 3.808), train_loss = 1.50013970, grad/param norm = 2.0186e-01, time/batch = 0.6969s	
2533/33250 (epoch 3.809), train_loss = 1.30277950, grad/param norm = 1.8874e-01, time/batch = 0.7031s	
2534/33250 (epoch 3.811), train_loss = 1.39043954, grad/param norm = 2.1452e-01, time/batch = 0.7035s	
2535/33250 (epoch 3.812), train_loss = 1.46305258, grad/param norm = 2.0237e-01, time/batch = 0.7042s	
2536/33250 (epoch 3.814), train_loss = 1.41200263, grad/param norm = 2.0415e-01, time/batch = 0.7022s	
2537/33250 (epoch 3.815), train_loss = 1.51575699, grad/param norm = 2.2617e-01, time/batch = 0.7077s	
2538/33250 (epoch 3.817), train_loss = 1.44876563, grad/param norm = 2.1133e-01, time/batch = 0.6942s	
2539/33250 (epoch 3.818), train_loss = 1.33018611, grad/param norm = 1.9736e-01, time/batch = 0.6953s	
2540/33250 (epoch 3.820), train_loss = 1.52911102, grad/param norm = 2.2333e-01, time/batch = 0.6943s	
2541/33250 (epoch 3.821), train_loss = 1.33130409, grad/param norm = 1.8746e-01, time/batch = 0.6999s	
2542/33250 (epoch 3.823), train_loss = 1.72332674, grad/param norm = 2.2464e-01, time/batch = 0.6942s	
2543/33250 (epoch 3.824), train_loss = 1.48883820, grad/param norm = 1.9616e-01, time/batch = 0.7094s	
2544/33250 (epoch 3.826), train_loss = 1.43714719, grad/param norm = 2.2627e-01, time/batch = 0.7016s	
2545/33250 (epoch 3.827), train_loss = 1.26413186, grad/param norm = 2.0403e-01, time/batch = 0.6988s	
2546/33250 (epoch 3.829), train_loss = 1.45847613, grad/param norm = 2.0510e-01, time/batch = 0.6981s	
2547/33250 (epoch 3.830), train_loss = 1.71706156, grad/param norm = 2.5354e-01, time/batch = 0.7138s	
2548/33250 (epoch 3.832), train_loss = 1.39954928, grad/param norm = 2.0110e-01, time/batch = 0.7003s	
2549/33250 (epoch 3.833), train_loss = 1.52194830, grad/param norm = 2.0939e-01, time/batch = 0.7020s	
2550/33250 (epoch 3.835), train_loss = 1.47895464, grad/param norm = 2.3040e-01, time/batch = 0.7079s	
2551/33250 (epoch 3.836), train_loss = 1.48177212, grad/param norm = 2.0138e-01, time/batch = 0.7138s	
2552/33250 (epoch 3.838), train_loss = 1.36543019, grad/param norm = 1.8181e-01, time/batch = 0.7119s	
2553/33250 (epoch 3.839), train_loss = 1.40998034, grad/param norm = 2.0272e-01, time/batch = 0.7125s	
2554/33250 (epoch 3.841), train_loss = 1.23446764, grad/param norm = 1.7931e-01, time/batch = 0.7142s	
2555/33250 (epoch 3.842), train_loss = 1.55190506, grad/param norm = 2.0087e-01, time/batch = 0.7143s	
2556/33250 (epoch 3.844), train_loss = 1.62690673, grad/param norm = 2.2866e-01, time/batch = 0.7194s	
2557/33250 (epoch 3.845), train_loss = 1.72522056, grad/param norm = 2.5170e-01, time/batch = 0.7476s	
2558/33250 (epoch 3.847), train_loss = 1.62864243, grad/param norm = 1.9973e-01, time/batch = 0.7395s	
2559/33250 (epoch 3.848), train_loss = 1.74410208, grad/param norm = 2.3873e-01, time/batch = 0.7241s	
2560/33250 (epoch 3.850), train_loss = 1.53861202, grad/param norm = 2.1632e-01, time/batch = 0.7243s	
2561/33250 (epoch 3.851), train_loss = 1.40740762, grad/param norm = 2.0157e-01, time/batch = 0.7295s	
2562/33250 (epoch 3.853), train_loss = 1.52697484, grad/param norm = 2.1885e-01, time/batch = 0.7070s	
2563/33250 (epoch 3.854), train_loss = 1.32289607, grad/param norm = 1.8820e-01, time/batch = 0.7007s	
2564/33250 (epoch 3.856), train_loss = 1.33678069, grad/param norm = 1.8734e-01, time/batch = 0.6972s	
2565/33250 (epoch 3.857), train_loss = 1.23941958, grad/param norm = 1.7877e-01, time/batch = 0.6959s	
2566/33250 (epoch 3.859), train_loss = 1.24590197, grad/param norm = 1.9873e-01, time/batch = 0.7012s	
2567/33250 (epoch 3.860), train_loss = 1.38722607, grad/param norm = 1.6563e-01, time/batch = 0.6980s	
2568/33250 (epoch 3.862), train_loss = 1.31594199, grad/param norm = 1.8133e-01, time/batch = 0.7150s	
2569/33250 (epoch 3.863), train_loss = 1.32689219, grad/param norm = 1.8413e-01, time/batch = 0.7290s	
2570/33250 (epoch 3.865), train_loss = 1.47047294, grad/param norm = 2.0100e-01, time/batch = 1.7343s	
2571/33250 (epoch 3.866), train_loss = 1.36831783, grad/param norm = 2.1097e-01, time/batch = 0.7698s	
2572/33250 (epoch 3.868), train_loss = 1.80429575, grad/param norm = 2.7066e-01, time/batch = 0.7525s	
2573/33250 (epoch 3.869), train_loss = 1.49443286, grad/param norm = 2.2257e-01, time/batch = 0.7465s	
2574/33250 (epoch 3.871), train_loss = 1.20075401, grad/param norm = 1.8499e-01, time/batch = 0.7515s	
2575/33250 (epoch 3.872), train_loss = 1.53138464, grad/param norm = 1.9940e-01, time/batch = 0.7923s	
2576/33250 (epoch 3.874), train_loss = 1.37370814, grad/param norm = 1.8932e-01, time/batch = 0.7705s	
2577/33250 (epoch 3.875), train_loss = 1.39665861, grad/param norm = 2.3845e-01, time/batch = 0.7421s	
2578/33250 (epoch 3.877), train_loss = 1.49631816, grad/param norm = 2.0734e-01, time/batch = 0.7473s	
2579/33250 (epoch 3.878), train_loss = 1.42171820, grad/param norm = 1.8703e-01, time/batch = 0.7399s	
2580/33250 (epoch 3.880), train_loss = 1.49943042, grad/param norm = 2.1830e-01, time/batch = 0.7457s	
2581/33250 (epoch 3.881), train_loss = 1.66743816, grad/param norm = 1.9974e-01, time/batch = 0.7315s	
2582/33250 (epoch 3.883), train_loss = 1.52136411, grad/param norm = 2.2094e-01, time/batch = 0.6955s	
2583/33250 (epoch 3.884), train_loss = 1.42634396, grad/param norm = 2.3145e-01, time/batch = 0.7089s	
2584/33250 (epoch 3.886), train_loss = 1.32176690, grad/param norm = 2.0255e-01, time/batch = 0.6997s	
2585/33250 (epoch 3.887), train_loss = 1.38806119, grad/param norm = 1.8245e-01, time/batch = 0.7008s	
2586/33250 (epoch 3.889), train_loss = 1.32942039, grad/param norm = 1.6491e-01, time/batch = 0.6998s	
2587/33250 (epoch 3.890), train_loss = 1.23563936, grad/param norm = 1.8753e-01, time/batch = 0.7165s	
2588/33250 (epoch 3.892), train_loss = 1.52306809, grad/param norm = 2.0528e-01, time/batch = 0.7064s	
2589/33250 (epoch 3.893), train_loss = 1.54106838, grad/param norm = 1.9770e-01, time/batch = 0.6924s	
2590/33250 (epoch 3.895), train_loss = 1.38075616, grad/param norm = 1.8797e-01, time/batch = 0.6800s	
2591/33250 (epoch 3.896), train_loss = 1.51585631, grad/param norm = 2.0540e-01, time/batch = 0.6839s	
2592/33250 (epoch 3.898), train_loss = 1.35660483, grad/param norm = 1.9270e-01, time/batch = 0.6870s	
2593/33250 (epoch 3.899), train_loss = 1.38584077, grad/param norm = 2.0981e-01, time/batch = 0.6846s	
2594/33250 (epoch 3.901), train_loss = 1.25805790, grad/param norm = 1.7513e-01, time/batch = 0.6824s	
2595/33250 (epoch 3.902), train_loss = 1.35523830, grad/param norm = 1.9138e-01, time/batch = 0.6773s	
2596/33250 (epoch 3.904), train_loss = 1.32148781, grad/param norm = 1.9223e-01, time/batch = 0.6724s	
2597/33250 (epoch 3.905), train_loss = 1.37464796, grad/param norm = 2.0213e-01, time/batch = 0.6683s	
2598/33250 (epoch 3.907), train_loss = 1.38871056, grad/param norm = 2.0190e-01, time/batch = 0.6733s	
2599/33250 (epoch 3.908), train_loss = 1.42510843, grad/param norm = 1.7833e-01, time/batch = 0.6804s	
2600/33250 (epoch 3.910), train_loss = 1.56584945, grad/param norm = 2.3323e-01, time/batch = 0.6841s	
2601/33250 (epoch 3.911), train_loss = 1.21440126, grad/param norm = 1.8837e-01, time/batch = 0.6906s	
2602/33250 (epoch 3.913), train_loss = 1.36488644, grad/param norm = 1.8015e-01, time/batch = 0.6890s	
2603/33250 (epoch 3.914), train_loss = 1.23997992, grad/param norm = 1.9503e-01, time/batch = 0.6934s	
2604/33250 (epoch 3.916), train_loss = 1.30719066, grad/param norm = 1.8011e-01, time/batch = 0.6841s	
2605/33250 (epoch 3.917), train_loss = 1.37409895, grad/param norm = 1.9300e-01, time/batch = 0.6677s	
2606/33250 (epoch 3.919), train_loss = 1.41691783, grad/param norm = 1.9917e-01, time/batch = 0.6677s	
2607/33250 (epoch 3.920), train_loss = 1.44935565, grad/param norm = 2.0855e-01, time/batch = 0.6658s	
2608/33250 (epoch 3.922), train_loss = 1.47052134, grad/param norm = 1.9573e-01, time/batch = 0.6648s	
2609/33250 (epoch 3.923), train_loss = 1.41664727, grad/param norm = 2.0478e-01, time/batch = 0.6763s	
2610/33250 (epoch 3.925), train_loss = 1.39638243, grad/param norm = 2.0274e-01, time/batch = 0.6752s	
2611/33250 (epoch 3.926), train_loss = 1.38970204, grad/param norm = 2.1832e-01, time/batch = 0.6745s	
2612/33250 (epoch 3.928), train_loss = 1.44300995, grad/param norm = 1.9990e-01, time/batch = 0.7046s	
2613/33250 (epoch 3.929), train_loss = 1.11574775, grad/param norm = 1.7208e-01, time/batch = 0.7102s	
2614/33250 (epoch 3.931), train_loss = 1.47788970, grad/param norm = 2.0297e-01, time/batch = 0.7015s	
2615/33250 (epoch 3.932), train_loss = 1.54284212, grad/param norm = 2.1845e-01, time/batch = 0.7041s	
2616/33250 (epoch 3.934), train_loss = 1.37240720, grad/param norm = 2.1075e-01, time/batch = 0.7022s	
2617/33250 (epoch 3.935), train_loss = 1.45750879, grad/param norm = 2.1664e-01, time/batch = 0.6957s	
2618/33250 (epoch 3.937), train_loss = 1.43982995, grad/param norm = 2.0282e-01, time/batch = 0.6810s	
2619/33250 (epoch 3.938), train_loss = 1.57041725, grad/param norm = 2.0605e-01, time/batch = 0.6980s	
2620/33250 (epoch 3.940), train_loss = 1.38731553, grad/param norm = 1.9817e-01, time/batch = 0.6910s	
2621/33250 (epoch 3.941), train_loss = 1.46659264, grad/param norm = 2.1189e-01, time/batch = 0.6933s	
2622/33250 (epoch 3.943), train_loss = 1.63396767, grad/param norm = 2.0305e-01, time/batch = 0.6925s	
2623/33250 (epoch 3.944), train_loss = 1.29997357, grad/param norm = 1.8847e-01, time/batch = 0.6817s	
2624/33250 (epoch 3.946), train_loss = 1.67295715, grad/param norm = 2.0113e-01, time/batch = 0.6852s	
2625/33250 (epoch 3.947), train_loss = 1.39386640, grad/param norm = 1.9603e-01, time/batch = 0.6746s	
2626/33250 (epoch 3.949), train_loss = 1.54651672, grad/param norm = 2.0044e-01, time/batch = 0.6950s	
2627/33250 (epoch 3.950), train_loss = 1.44077737, grad/param norm = 1.9796e-01, time/batch = 0.6999s	
2628/33250 (epoch 3.952), train_loss = 1.45843992, grad/param norm = 2.0777e-01, time/batch = 0.6824s	
2629/33250 (epoch 3.953), train_loss = 1.54257847, grad/param norm = 2.0641e-01, time/batch = 0.6639s	
2630/33250 (epoch 3.955), train_loss = 1.51561701, grad/param norm = 2.0528e-01, time/batch = 0.6653s	
2631/33250 (epoch 3.956), train_loss = 1.62377956, grad/param norm = 2.1996e-01, time/batch = 0.6755s	
2632/33250 (epoch 3.958), train_loss = 1.32659064, grad/param norm = 1.8171e-01, time/batch = 0.6722s	
2633/33250 (epoch 3.959), train_loss = 1.29265289, grad/param norm = 1.8213e-01, time/batch = 0.6763s	
2634/33250 (epoch 3.961), train_loss = 1.56639811, grad/param norm = 2.0591e-01, time/batch = 0.6937s	
2635/33250 (epoch 3.962), train_loss = 1.48769365, grad/param norm = 2.1107e-01, time/batch = 0.6838s	
2636/33250 (epoch 3.964), train_loss = 1.57248195, grad/param norm = 2.1131e-01, time/batch = 0.6854s	
2637/33250 (epoch 3.965), train_loss = 1.48752956, grad/param norm = 2.1954e-01, time/batch = 0.6904s	
2638/33250 (epoch 3.967), train_loss = 1.56807501, grad/param norm = 2.0410e-01, time/batch = 0.6907s	
2639/33250 (epoch 3.968), train_loss = 1.63547277, grad/param norm = 1.9957e-01, time/batch = 0.7005s	
2640/33250 (epoch 3.970), train_loss = 1.76554425, grad/param norm = 2.3421e-01, time/batch = 0.7006s	
2641/33250 (epoch 3.971), train_loss = 1.60963826, grad/param norm = 2.1368e-01, time/batch = 0.6951s	
2642/33250 (epoch 3.973), train_loss = 1.39082756, grad/param norm = 1.8657e-01, time/batch = 0.6934s	
2643/33250 (epoch 3.974), train_loss = 1.47366784, grad/param norm = 2.1943e-01, time/batch = 0.6889s	
2644/33250 (epoch 3.976), train_loss = 1.36785690, grad/param norm = 2.0077e-01, time/batch = 0.6883s	
2645/33250 (epoch 3.977), train_loss = 1.34952453, grad/param norm = 2.1038e-01, time/batch = 0.6924s	
2646/33250 (epoch 3.979), train_loss = 1.47501195, grad/param norm = 2.2038e-01, time/batch = 0.6959s	
2647/33250 (epoch 3.980), train_loss = 1.40169818, grad/param norm = 1.8147e-01, time/batch = 0.6925s	
2648/33250 (epoch 3.982), train_loss = 1.23777917, grad/param norm = 1.6820e-01, time/batch = 0.6917s	
2649/33250 (epoch 3.983), train_loss = 1.52926193, grad/param norm = 2.1538e-01, time/batch = 0.6955s	
2650/33250 (epoch 3.985), train_loss = 1.33661744, grad/param norm = 2.1621e-01, time/batch = 0.6888s	
2651/33250 (epoch 3.986), train_loss = 1.59352822, grad/param norm = 2.3161e-01, time/batch = 0.6859s	
2652/33250 (epoch 3.988), train_loss = 1.46375962, grad/param norm = 2.1819e-01, time/batch = 0.6922s	
2653/33250 (epoch 3.989), train_loss = 1.60980847, grad/param norm = 2.3126e-01, time/batch = 0.7057s	
2654/33250 (epoch 3.991), train_loss = 1.43813699, grad/param norm = 2.1085e-01, time/batch = 0.7095s	
2655/33250 (epoch 3.992), train_loss = 1.37740293, grad/param norm = 1.9062e-01, time/batch = 0.6956s	
2656/33250 (epoch 3.994), train_loss = 1.29698638, grad/param norm = 1.9912e-01, time/batch = 0.6869s	
2657/33250 (epoch 3.995), train_loss = 1.49722820, grad/param norm = 2.3966e-01, time/batch = 0.6909s	
2658/33250 (epoch 3.997), train_loss = 1.10936620, grad/param norm = 1.7019e-01, time/batch = 0.6890s	
2659/33250 (epoch 3.998), train_loss = 1.42512924, grad/param norm = 2.0073e-01, time/batch = 0.6767s	
2660/33250 (epoch 4.000), train_loss = 1.42686794, grad/param norm = 1.8540e-01, time/batch = 0.6835s	
2661/33250 (epoch 4.002), train_loss = 1.59314120, grad/param norm = 2.1070e-01, time/batch = 0.6931s	
2662/33250 (epoch 4.003), train_loss = 1.49140652, grad/param norm = 2.0972e-01, time/batch = 0.6914s	
2663/33250 (epoch 4.005), train_loss = 1.26677739, grad/param norm = 1.9582e-01, time/batch = 0.6924s	
2664/33250 (epoch 4.006), train_loss = 1.21130913, grad/param norm = 1.7496e-01, time/batch = 0.6913s	
2665/33250 (epoch 4.008), train_loss = 1.49983052, grad/param norm = 2.1896e-01, time/batch = 0.6914s	
2666/33250 (epoch 4.009), train_loss = 1.56965270, grad/param norm = 2.1331e-01, time/batch = 0.6844s	
2667/33250 (epoch 4.011), train_loss = 1.37835586, grad/param norm = 1.8419e-01, time/batch = 0.6886s	
2668/33250 (epoch 4.012), train_loss = 1.56814584, grad/param norm = 2.3289e-01, time/batch = 0.6718s	
2669/33250 (epoch 4.014), train_loss = 1.53644749, grad/param norm = 1.9792e-01, time/batch = 0.6722s	
2670/33250 (epoch 4.015), train_loss = 1.40591028, grad/param norm = 2.0397e-01, time/batch = 0.6890s	
2671/33250 (epoch 4.017), train_loss = 1.47656420, grad/param norm = 2.0336e-01, time/batch = 0.6877s	
2672/33250 (epoch 4.018), train_loss = 1.27904649, grad/param norm = 2.0653e-01, time/batch = 0.6770s	
2673/33250 (epoch 4.020), train_loss = 1.36208758, grad/param norm = 1.8190e-01, time/batch = 0.6910s	
2674/33250 (epoch 4.021), train_loss = 1.41031506, grad/param norm = 1.9751e-01, time/batch = 0.6869s	
2675/33250 (epoch 4.023), train_loss = 1.26031170, grad/param norm = 2.0992e-01, time/batch = 0.6899s	
2676/33250 (epoch 4.024), train_loss = 1.55831015, grad/param norm = 2.0627e-01, time/batch = 0.6895s	
2677/33250 (epoch 4.026), train_loss = 1.39621304, grad/param norm = 1.7324e-01, time/batch = 0.6861s	
2678/33250 (epoch 4.027), train_loss = 1.32592420, grad/param norm = 1.9322e-01, time/batch = 0.6816s	
2679/33250 (epoch 4.029), train_loss = 1.41349275, grad/param norm = 1.8445e-01, time/batch = 0.6834s	
2680/33250 (epoch 4.030), train_loss = 1.42452677, grad/param norm = 2.0404e-01, time/batch = 0.6845s	
2681/33250 (epoch 4.032), train_loss = 1.70505250, grad/param norm = 2.4199e-01, time/batch = 0.6845s	
2682/33250 (epoch 4.033), train_loss = 1.34845604, grad/param norm = 2.2446e-01, time/batch = 0.6809s	
2683/33250 (epoch 4.035), train_loss = 1.35759333, grad/param norm = 2.0017e-01, time/batch = 0.6791s	
2684/33250 (epoch 4.036), train_loss = 1.46034826, grad/param norm = 2.0300e-01, time/batch = 0.6839s	
2685/33250 (epoch 4.038), train_loss = 1.31316582, grad/param norm = 1.9281e-01, time/batch = 0.6857s	
2686/33250 (epoch 4.039), train_loss = 1.26197054, grad/param norm = 1.8280e-01, time/batch = 0.7019s	
2687/33250 (epoch 4.041), train_loss = 1.54304475, grad/param norm = 2.1930e-01, time/batch = 0.6993s	
2688/33250 (epoch 4.042), train_loss = 1.21969362, grad/param norm = 1.9324e-01, time/batch = 0.6785s	
2689/33250 (epoch 4.044), train_loss = 1.61039559, grad/param norm = 1.9694e-01, time/batch = 0.6793s	
2690/33250 (epoch 4.045), train_loss = 1.49936461, grad/param norm = 1.8466e-01, time/batch = 0.6749s	
2691/33250 (epoch 4.047), train_loss = 1.54708904, grad/param norm = 2.0458e-01, time/batch = 0.6827s	
2692/33250 (epoch 4.048), train_loss = 1.67047501, grad/param norm = 2.3134e-01, time/batch = 0.6619s	
2693/33250 (epoch 4.050), train_loss = 1.38106708, grad/param norm = 1.9930e-01, time/batch = 0.6550s	
2694/33250 (epoch 4.051), train_loss = 1.42719806, grad/param norm = 1.8828e-01, time/batch = 0.6681s	
2695/33250 (epoch 4.053), train_loss = 1.50961592, grad/param norm = 2.1173e-01, time/batch = 0.6762s	
2696/33250 (epoch 4.054), train_loss = 1.24081350, grad/param norm = 1.7676e-01, time/batch = 0.6761s	
2697/33250 (epoch 4.056), train_loss = 1.27878878, grad/param norm = 1.9327e-01, time/batch = 0.6678s	
2698/33250 (epoch 4.057), train_loss = 1.37537035, grad/param norm = 1.8877e-01, time/batch = 0.6782s	
2699/33250 (epoch 4.059), train_loss = 1.34541161, grad/param norm = 1.9373e-01, time/batch = 0.6904s	
2700/33250 (epoch 4.060), train_loss = 1.50215646, grad/param norm = 2.0742e-01, time/batch = 0.6860s	
2701/33250 (epoch 4.062), train_loss = 1.57861712, grad/param norm = 1.9470e-01, time/batch = 0.6834s	
2702/33250 (epoch 4.063), train_loss = 1.52629727, grad/param norm = 1.8786e-01, time/batch = 0.6772s	
2703/33250 (epoch 4.065), train_loss = 1.44572513, grad/param norm = 1.9546e-01, time/batch = 0.6731s	
2704/33250 (epoch 4.066), train_loss = 1.53832121, grad/param norm = 2.0744e-01, time/batch = 0.6736s	
2705/33250 (epoch 4.068), train_loss = 1.44400359, grad/param norm = 2.0862e-01, time/batch = 0.6699s	
2706/33250 (epoch 4.069), train_loss = 1.45311433, grad/param norm = 1.7844e-01, time/batch = 0.6672s	
2707/33250 (epoch 4.071), train_loss = 1.26897958, grad/param norm = 1.8952e-01, time/batch = 0.6673s	
2708/33250 (epoch 4.072), train_loss = 1.35411821, grad/param norm = 1.9360e-01, time/batch = 0.6691s	
2709/33250 (epoch 4.074), train_loss = 1.47496666, grad/param norm = 1.9529e-01, time/batch = 0.6720s	
2710/33250 (epoch 4.075), train_loss = 1.30287337, grad/param norm = 1.9145e-01, time/batch = 0.6761s	
2711/33250 (epoch 4.077), train_loss = 1.44866494, grad/param norm = 1.9000e-01, time/batch = 0.6770s	
2712/33250 (epoch 4.078), train_loss = 1.31484899, grad/param norm = 1.8720e-01, time/batch = 0.6572s	
2713/33250 (epoch 4.080), train_loss = 1.51232367, grad/param norm = 2.2755e-01, time/batch = 0.6652s	
2714/33250 (epoch 4.081), train_loss = 1.48680116, grad/param norm = 2.1208e-01, time/batch = 0.6753s	
2715/33250 (epoch 4.083), train_loss = 1.50601442, grad/param norm = 1.9850e-01, time/batch = 0.6763s	
2716/33250 (epoch 4.084), train_loss = 1.38773179, grad/param norm = 2.0740e-01, time/batch = 0.6761s	
2717/33250 (epoch 4.086), train_loss = 1.36607833, grad/param norm = 1.8031e-01, time/batch = 0.6756s	
2718/33250 (epoch 4.087), train_loss = 1.24882173, grad/param norm = 1.8469e-01, time/batch = 0.6752s	
2719/33250 (epoch 4.089), train_loss = 1.46661319, grad/param norm = 2.0487e-01, time/batch = 0.6756s	
2720/33250 (epoch 4.090), train_loss = 1.33437515, grad/param norm = 2.1041e-01, time/batch = 0.6796s	
2721/33250 (epoch 4.092), train_loss = 1.25943663, grad/param norm = 1.8610e-01, time/batch = 0.6772s	
2722/33250 (epoch 4.093), train_loss = 1.37707107, grad/param norm = 1.9665e-01, time/batch = 0.6729s	
2723/33250 (epoch 4.095), train_loss = 1.34688001, grad/param norm = 1.9014e-01, time/batch = 0.6775s	
2724/33250 (epoch 4.096), train_loss = 1.21255323, grad/param norm = 1.7722e-01, time/batch = 0.6762s	
2725/33250 (epoch 4.098), train_loss = 1.31626787, grad/param norm = 1.9268e-01, time/batch = 0.6705s	
2726/33250 (epoch 4.099), train_loss = 1.12691436, grad/param norm = 1.8316e-01, time/batch = 0.6652s	
2727/33250 (epoch 4.101), train_loss = 1.36490027, grad/param norm = 1.9348e-01, time/batch = 0.6636s	
2728/33250 (epoch 4.102), train_loss = 1.25266397, grad/param norm = 1.7739e-01, time/batch = 0.6690s	
2729/33250 (epoch 4.104), train_loss = 1.19803859, grad/param norm = 1.8328e-01, time/batch = 0.6744s	
2730/33250 (epoch 4.105), train_loss = 1.32752725, grad/param norm = 1.8974e-01, time/batch = 0.6925s	
2731/33250 (epoch 4.107), train_loss = 1.12345506, grad/param norm = 1.6715e-01, time/batch = 0.6932s	
2732/33250 (epoch 4.108), train_loss = 1.37592225, grad/param norm = 1.8758e-01, time/batch = 0.6912s	
2733/33250 (epoch 4.110), train_loss = 1.17771430, grad/param norm = 1.7263e-01, time/batch = 0.6904s	
2734/33250 (epoch 4.111), train_loss = 1.36409083, grad/param norm = 1.9114e-01, time/batch = 0.6893s	
2735/33250 (epoch 4.113), train_loss = 1.34951693, grad/param norm = 2.0335e-01, time/batch = 0.6919s	
2736/33250 (epoch 4.114), train_loss = 1.30345040, grad/param norm = 2.1681e-01, time/batch = 0.6903s	
2737/33250 (epoch 4.116), train_loss = 1.44471169, grad/param norm = 2.1096e-01, time/batch = 0.6912s	
2738/33250 (epoch 4.117), train_loss = 1.35315433, grad/param norm = 1.7863e-01, time/batch = 0.6640s	
2739/33250 (epoch 4.119), train_loss = 1.34298151, grad/param norm = 1.8159e-01, time/batch = 0.6644s	
2740/33250 (epoch 4.120), train_loss = 1.09729306, grad/param norm = 1.6797e-01, time/batch = 0.6752s	
2741/33250 (epoch 4.122), train_loss = 1.49348437, grad/param norm = 1.8325e-01, time/batch = 0.6829s	
2742/33250 (epoch 4.123), train_loss = 1.48550763, grad/param norm = 1.9353e-01, time/batch = 0.6798s	
2743/33250 (epoch 4.125), train_loss = 1.18046922, grad/param norm = 1.7890e-01, time/batch = 0.6692s	
2744/33250 (epoch 4.126), train_loss = 1.40859339, grad/param norm = 2.0573e-01, time/batch = 0.6712s	
2745/33250 (epoch 4.128), train_loss = 1.27400538, grad/param norm = 1.8288e-01, time/batch = 0.6796s	
2746/33250 (epoch 4.129), train_loss = 1.34424856, grad/param norm = 1.9253e-01, time/batch = 0.6754s	
2747/33250 (epoch 4.131), train_loss = 1.41552757, grad/param norm = 2.1149e-01, time/batch = 0.6713s	
2748/33250 (epoch 4.132), train_loss = 1.37018586, grad/param norm = 1.9354e-01, time/batch = 0.6932s	
2749/33250 (epoch 4.134), train_loss = 1.40416410, grad/param norm = 1.9156e-01, time/batch = 0.6768s	
2750/33250 (epoch 4.135), train_loss = 1.45323127, grad/param norm = 1.9340e-01, time/batch = 0.6647s	
2751/33250 (epoch 4.137), train_loss = 1.24104812, grad/param norm = 1.8647e-01, time/batch = 0.6676s	
2752/33250 (epoch 4.138), train_loss = 1.30553338, grad/param norm = 1.8274e-01, time/batch = 0.6701s	
2753/33250 (epoch 4.140), train_loss = 1.21451926, grad/param norm = 1.8617e-01, time/batch = 0.6623s	
2754/33250 (epoch 4.141), train_loss = 1.76382131, grad/param norm = 2.4414e-01, time/batch = 0.6573s	
2755/33250 (epoch 4.143), train_loss = 1.16017286, grad/param norm = 1.9841e-01, time/batch = 0.6590s	
2756/33250 (epoch 4.144), train_loss = 1.27280621, grad/param norm = 1.8605e-01, time/batch = 0.6756s	
2757/33250 (epoch 4.146), train_loss = 1.26257829, grad/param norm = 1.7023e-01, time/batch = 0.6752s	
2758/33250 (epoch 4.147), train_loss = 1.28316417, grad/param norm = 1.9407e-01, time/batch = 0.6739s	
2759/33250 (epoch 4.149), train_loss = 1.41391725, grad/param norm = 1.9685e-01, time/batch = 0.6685s	
2760/33250 (epoch 4.150), train_loss = 1.21791818, grad/param norm = 2.0146e-01, time/batch = 0.6664s	
2761/33250 (epoch 4.152), train_loss = 1.23444014, grad/param norm = 2.0056e-01, time/batch = 0.6628s	
2762/33250 (epoch 4.153), train_loss = 1.52177676, grad/param norm = 2.1829e-01, time/batch = 0.6565s	
2763/33250 (epoch 4.155), train_loss = 1.44396234, grad/param norm = 2.1668e-01, time/batch = 0.6569s	
2764/33250 (epoch 4.156), train_loss = 1.47891896, grad/param norm = 2.0504e-01, time/batch = 0.6569s	
2765/33250 (epoch 4.158), train_loss = 1.71565258, grad/param norm = 2.3606e-01, time/batch = 0.6637s	
2766/33250 (epoch 4.159), train_loss = 1.41491614, grad/param norm = 2.1378e-01, time/batch = 0.6748s	
2767/33250 (epoch 4.161), train_loss = 1.47086585, grad/param norm = 2.0405e-01, time/batch = 0.6760s	
2768/33250 (epoch 4.162), train_loss = 1.31425750, grad/param norm = 1.9757e-01, time/batch = 0.6768s	
2769/33250 (epoch 4.164), train_loss = 1.47967401, grad/param norm = 2.1120e-01, time/batch = 0.6748s	
2770/33250 (epoch 4.165), train_loss = 1.45780968, grad/param norm = 1.9441e-01, time/batch = 0.6716s	
2771/33250 (epoch 4.167), train_loss = 1.45915317, grad/param norm = 1.8754e-01, time/batch = 0.6554s	
2772/33250 (epoch 4.168), train_loss = 1.21877729, grad/param norm = 1.7489e-01, time/batch = 0.6530s	
2773/33250 (epoch 4.170), train_loss = 1.31771907, grad/param norm = 1.8222e-01, time/batch = 0.6603s	
2774/33250 (epoch 4.171), train_loss = 1.35540044, grad/param norm = 1.9192e-01, time/batch = 0.6601s	
2775/33250 (epoch 4.173), train_loss = 1.30304084, grad/param norm = 2.0638e-01, time/batch = 0.6612s	
2776/33250 (epoch 4.174), train_loss = 1.37478980, grad/param norm = 2.0883e-01, time/batch = 0.6619s	
2777/33250 (epoch 4.176), train_loss = 1.44769982, grad/param norm = 2.0146e-01, time/batch = 0.6599s	
2778/33250 (epoch 4.177), train_loss = 1.18161071, grad/param norm = 1.6141e-01, time/batch = 0.6571s	
2779/33250 (epoch 4.179), train_loss = 1.33807752, grad/param norm = 1.9683e-01, time/batch = 0.6528s	
2780/33250 (epoch 4.180), train_loss = 1.23953045, grad/param norm = 1.8200e-01, time/batch = 0.6630s	
2781/33250 (epoch 4.182), train_loss = 1.35817342, grad/param norm = 2.1342e-01, time/batch = 0.6623s	
2782/33250 (epoch 4.183), train_loss = 1.59368667, grad/param norm = 2.0354e-01, time/batch = 0.6662s	
2783/33250 (epoch 4.185), train_loss = 1.48657815, grad/param norm = 2.1431e-01, time/batch = 0.6678s	
2784/33250 (epoch 4.186), train_loss = 1.32716701, grad/param norm = 1.6914e-01, time/batch = 0.6627s	
2785/33250 (epoch 4.188), train_loss = 1.45885792, grad/param norm = 1.9321e-01, time/batch = 0.6589s	
2786/33250 (epoch 4.189), train_loss = 1.20442285, grad/param norm = 1.9004e-01, time/batch = 0.6618s	
2787/33250 (epoch 4.191), train_loss = 1.29368901, grad/param norm = 1.8488e-01, time/batch = 0.6605s	
2788/33250 (epoch 4.192), train_loss = 1.26639854, grad/param norm = 1.7270e-01, time/batch = 0.6604s	
2789/33250 (epoch 4.194), train_loss = 1.20341101, grad/param norm = 1.9620e-01, time/batch = 0.6573s	
2790/33250 (epoch 4.195), train_loss = 1.52138853, grad/param norm = 1.9307e-01, time/batch = 0.6572s	
2791/33250 (epoch 4.197), train_loss = 1.37857344, grad/param norm = 1.9983e-01, time/batch = 0.6713s	
2792/33250 (epoch 4.198), train_loss = 1.49144791, grad/param norm = 2.2122e-01, time/batch = 0.6751s	
2793/33250 (epoch 4.200), train_loss = 1.35844859, grad/param norm = 1.9084e-01, time/batch = 0.6729s	
2794/33250 (epoch 4.202), train_loss = 1.32633081, grad/param norm = 1.9302e-01, time/batch = 0.6605s	
2795/33250 (epoch 4.203), train_loss = 1.38984614, grad/param norm = 2.0602e-01, time/batch = 0.6636s	
2796/33250 (epoch 4.205), train_loss = 1.43173853, grad/param norm = 2.1905e-01, time/batch = 0.6640s	
2797/33250 (epoch 4.206), train_loss = 1.39724396, grad/param norm = 1.9745e-01, time/batch = 0.6569s	
2798/33250 (epoch 4.208), train_loss = 1.64238123, grad/param norm = 2.4404e-01, time/batch = 0.6549s	
2799/33250 (epoch 4.209), train_loss = 1.28490551, grad/param norm = 2.0503e-01, time/batch = 0.6587s	
2800/33250 (epoch 4.211), train_loss = 1.54159590, grad/param norm = 1.9936e-01, time/batch = 0.6575s	
2801/33250 (epoch 4.212), train_loss = 1.63792042, grad/param norm = 2.2445e-01, time/batch = 0.6633s	
2802/33250 (epoch 4.214), train_loss = 1.38151777, grad/param norm = 1.7857e-01, time/batch = 0.6568s	
2803/33250 (epoch 4.215), train_loss = 1.78376593, grad/param norm = 2.3449e-01, time/batch = 0.6559s	
2804/33250 (epoch 4.217), train_loss = 1.57399569, grad/param norm = 2.1973e-01, time/batch = 0.6555s	
2805/33250 (epoch 4.218), train_loss = 1.46297357, grad/param norm = 2.0327e-01, time/batch = 0.6583s	
2806/33250 (epoch 4.220), train_loss = 1.58821984, grad/param norm = 2.1531e-01, time/batch = 0.6612s	
2807/33250 (epoch 4.221), train_loss = 1.68924109, grad/param norm = 2.2491e-01, time/batch = 0.6600s	
2808/33250 (epoch 4.223), train_loss = 1.38154641, grad/param norm = 2.0761e-01, time/batch = 0.6566s	
2809/33250 (epoch 4.224), train_loss = 1.53281898, grad/param norm = 2.1990e-01, time/batch = 0.6530s	
2810/33250 (epoch 4.226), train_loss = 1.54902233, grad/param norm = 1.8998e-01, time/batch = 0.6623s	
2811/33250 (epoch 4.227), train_loss = 1.42635228, grad/param norm = 1.8196e-01, time/batch = 0.6702s	
2812/33250 (epoch 4.229), train_loss = 1.40404137, grad/param norm = 1.8140e-01, time/batch = 0.6649s	
2813/33250 (epoch 4.230), train_loss = 1.34623536, grad/param norm = 1.9844e-01, time/batch = 0.6749s	
2814/33250 (epoch 4.232), train_loss = 1.30522509, grad/param norm = 1.7096e-01, time/batch = 0.6566s	
2815/33250 (epoch 4.233), train_loss = 1.34317469, grad/param norm = 1.8360e-01, time/batch = 0.6602s	
2816/33250 (epoch 4.235), train_loss = 1.50477223, grad/param norm = 2.0270e-01, time/batch = 0.6650s	
2817/33250 (epoch 4.236), train_loss = 1.32603058, grad/param norm = 2.3200e-01, time/batch = 0.6615s	
2818/33250 (epoch 4.238), train_loss = 1.47882036, grad/param norm = 2.0377e-01, time/batch = 0.6727s	
2819/33250 (epoch 4.239), train_loss = 1.63815188, grad/param norm = 2.1663e-01, time/batch = 0.6697s	
2820/33250 (epoch 4.241), train_loss = 1.54223403, grad/param norm = 2.2384e-01, time/batch = 0.6579s	
2821/33250 (epoch 4.242), train_loss = 1.46059494, grad/param norm = 1.9988e-01, time/batch = 0.6618s	
2822/33250 (epoch 4.244), train_loss = 1.53995399, grad/param norm = 2.1983e-01, time/batch = 0.6558s	
2823/33250 (epoch 4.245), train_loss = 1.37641380, grad/param norm = 2.0300e-01, time/batch = 0.6587s	
2824/33250 (epoch 4.247), train_loss = 1.45250937, grad/param norm = 1.7870e-01, time/batch = 0.6621s	
2825/33250 (epoch 4.248), train_loss = 1.70544081, grad/param norm = 2.2395e-01, time/batch = 0.6601s	
2826/33250 (epoch 4.250), train_loss = 1.43793030, grad/param norm = 1.7927e-01, time/batch = 0.6542s	
2827/33250 (epoch 4.251), train_loss = 1.41928416, grad/param norm = 2.1837e-01, time/batch = 0.6550s	
2828/33250 (epoch 4.253), train_loss = 1.24297346, grad/param norm = 1.8468e-01, time/batch = 0.6555s	
2829/33250 (epoch 4.254), train_loss = 1.35688715, grad/param norm = 1.9519e-01, time/batch = 0.6626s	
2830/33250 (epoch 4.256), train_loss = 1.49864009, grad/param norm = 1.9259e-01, time/batch = 0.6744s	
2831/33250 (epoch 4.257), train_loss = 1.59663989, grad/param norm = 2.0620e-01, time/batch = 0.6785s	
2832/33250 (epoch 4.259), train_loss = 1.61016217, grad/param norm = 1.8456e-01, time/batch = 0.6803s	
2833/33250 (epoch 4.260), train_loss = 1.27966772, grad/param norm = 1.7322e-01, time/batch = 0.6631s	
2834/33250 (epoch 4.262), train_loss = 1.47656205, grad/param norm = 1.8823e-01, time/batch = 0.6688s	
2835/33250 (epoch 4.263), train_loss = 1.35114533, grad/param norm = 1.7275e-01, time/batch = 0.6743s	
2836/33250 (epoch 4.265), train_loss = 1.49994138, grad/param norm = 1.8271e-01, time/batch = 0.6642s	
2837/33250 (epoch 4.266), train_loss = 1.40598877, grad/param norm = 1.9722e-01, time/batch = 0.6650s	
2838/33250 (epoch 4.268), train_loss = 1.30840024, grad/param norm = 1.7436e-01, time/batch = 0.6673s	
2839/33250 (epoch 4.269), train_loss = 1.13551461, grad/param norm = 1.7429e-01, time/batch = 0.6697s	
2840/33250 (epoch 4.271), train_loss = 1.41708314, grad/param norm = 1.8377e-01, time/batch = 0.6637s	
2841/33250 (epoch 4.272), train_loss = 1.13166002, grad/param norm = 1.5430e-01, time/batch = 0.6775s	
2842/33250 (epoch 4.274), train_loss = 1.09426742, grad/param norm = 1.6502e-01, time/batch = 0.6669s	
2843/33250 (epoch 4.275), train_loss = 1.25186472, grad/param norm = 1.7051e-01, time/batch = 0.6755s	
2844/33250 (epoch 4.277), train_loss = 1.11324499, grad/param norm = 1.7209e-01, time/batch = 0.6653s	
2845/33250 (epoch 4.278), train_loss = 1.20676278, grad/param norm = 1.6852e-01, time/batch = 0.6582s	
2846/33250 (epoch 4.280), train_loss = 1.18401899, grad/param norm = 1.8009e-01, time/batch = 0.6676s	
2847/33250 (epoch 4.281), train_loss = 1.36246749, grad/param norm = 1.9964e-01, time/batch = 0.6604s	
2848/33250 (epoch 4.283), train_loss = 1.46468829, grad/param norm = 2.0536e-01, time/batch = 0.6624s	
2849/33250 (epoch 4.284), train_loss = 1.31495681, grad/param norm = 1.7879e-01, time/batch = 0.6588s	
2850/33250 (epoch 4.286), train_loss = 1.45972780, grad/param norm = 2.1168e-01, time/batch = 0.6556s	
2851/33250 (epoch 4.287), train_loss = 1.21861397, grad/param norm = 1.7280e-01, time/batch = 0.6762s	
2852/33250 (epoch 4.289), train_loss = 1.25438739, grad/param norm = 1.8420e-01, time/batch = 0.6792s	
2853/33250 (epoch 4.290), train_loss = 1.35097980, grad/param norm = 1.7081e-01, time/batch = 0.6769s	
2854/33250 (epoch 4.292), train_loss = 1.38019980, grad/param norm = 2.0358e-01, time/batch = 0.6950s	
2855/33250 (epoch 4.293), train_loss = 1.53850633, grad/param norm = 2.4349e-01, time/batch = 0.6980s	
2856/33250 (epoch 4.295), train_loss = 1.41950288, grad/param norm = 1.8385e-01, time/batch = 0.6881s	
2857/33250 (epoch 4.296), train_loss = 1.36142146, grad/param norm = 1.7676e-01, time/batch = 0.6841s	
2858/33250 (epoch 4.298), train_loss = 1.12174497, grad/param norm = 1.5551e-01, time/batch = 0.6804s	
2859/33250 (epoch 4.299), train_loss = 1.10420955, grad/param norm = 1.5818e-01, time/batch = 0.6902s	
2860/33250 (epoch 4.301), train_loss = 1.45563217, grad/param norm = 1.8286e-01, time/batch = 0.6794s	
2861/33250 (epoch 4.302), train_loss = 1.33061316, grad/param norm = 1.8036e-01, time/batch = 0.6830s	
2862/33250 (epoch 4.304), train_loss = 1.29969149, grad/param norm = 1.7033e-01, time/batch = 0.6749s	
2863/33250 (epoch 4.305), train_loss = 1.32762320, grad/param norm = 1.7543e-01, time/batch = 0.6781s	
2864/33250 (epoch 4.307), train_loss = 1.51541739, grad/param norm = 1.9018e-01, time/batch = 0.6747s	
2865/33250 (epoch 4.308), train_loss = 1.64039659, grad/param norm = 2.1470e-01, time/batch = 0.6675s	
2866/33250 (epoch 4.310), train_loss = 1.40909280, grad/param norm = 2.0467e-01, time/batch = 0.6711s	
2867/33250 (epoch 4.311), train_loss = 1.48219199, grad/param norm = 1.7814e-01, time/batch = 0.6646s	
2868/33250 (epoch 4.313), train_loss = 1.24194036, grad/param norm = 1.9320e-01, time/batch = 0.6717s	
2869/33250 (epoch 4.314), train_loss = 1.33478006, grad/param norm = 1.8358e-01, time/batch = 0.6665s	
2870/33250 (epoch 4.316), train_loss = 1.56987319, grad/param norm = 2.1534e-01, time/batch = 0.6711s	
2871/33250 (epoch 4.317), train_loss = 1.30258147, grad/param norm = 1.9358e-01, time/batch = 0.6863s	
2872/33250 (epoch 4.319), train_loss = 1.54265744, grad/param norm = 2.1184e-01, time/batch = 0.6798s	
2873/33250 (epoch 4.320), train_loss = 1.66719827, grad/param norm = 2.5431e-01, time/batch = 0.6808s	
2874/33250 (epoch 4.322), train_loss = 1.62774203, grad/param norm = 2.2545e-01, time/batch = 0.6817s	
2875/33250 (epoch 4.323), train_loss = 1.71795709, grad/param norm = 2.2053e-01, time/batch = 0.6828s	
2876/33250 (epoch 4.325), train_loss = 1.39035272, grad/param norm = 2.0581e-01, time/batch = 0.6877s	
2877/33250 (epoch 4.326), train_loss = 1.67499840, grad/param norm = 2.2398e-01, time/batch = 0.6616s	
2878/33250 (epoch 4.328), train_loss = 1.31705156, grad/param norm = 1.9063e-01, time/batch = 0.6850s	
2879/33250 (epoch 4.329), train_loss = 1.46967803, grad/param norm = 1.9236e-01, time/batch = 0.6857s	
2880/33250 (epoch 4.331), train_loss = 1.33408431, grad/param norm = 1.8943e-01, time/batch = 0.6712s	
2881/33250 (epoch 4.332), train_loss = 1.31317632, grad/param norm = 1.9874e-01, time/batch = 0.6688s	
2882/33250 (epoch 4.334), train_loss = 1.52434065, grad/param norm = 1.9512e-01, time/batch = 0.6743s	
2883/33250 (epoch 4.335), train_loss = 1.06577673, grad/param norm = 1.6263e-01, time/batch = 0.6688s	
2884/33250 (epoch 4.337), train_loss = 1.40286364, grad/param norm = 1.9010e-01, time/batch = 0.6657s	
2885/33250 (epoch 4.338), train_loss = 1.50415760, grad/param norm = 1.9675e-01, time/batch = 0.6686s	
2886/33250 (epoch 4.340), train_loss = 1.37149751, grad/param norm = 1.9266e-01, time/batch = 0.6831s	
2887/33250 (epoch 4.341), train_loss = 1.33849141, grad/param norm = 1.8627e-01, time/batch = 0.6688s	
2888/33250 (epoch 4.343), train_loss = 1.43530417, grad/param norm = 1.9984e-01, time/batch = 0.6735s	
2889/33250 (epoch 4.344), train_loss = 1.36598325, grad/param norm = 1.9530e-01, time/batch = 0.6798s	
2890/33250 (epoch 4.346), train_loss = 1.19236644, grad/param norm = 1.7076e-01, time/batch = 0.6730s	
2891/33250 (epoch 4.347), train_loss = 1.74054760, grad/param norm = 2.0860e-01, time/batch = 0.6676s	
2892/33250 (epoch 4.349), train_loss = 1.39358330, grad/param norm = 1.9528e-01, time/batch = 0.6690s	
2893/33250 (epoch 4.350), train_loss = 1.42291480, grad/param norm = 2.0629e-01, time/batch = 0.6698s	
2894/33250 (epoch 4.352), train_loss = 1.31469386, grad/param norm = 2.0930e-01, time/batch = 0.6745s	
2895/33250 (epoch 4.353), train_loss = 1.35408204, grad/param norm = 1.8305e-01, time/batch = 0.6664s	
2896/33250 (epoch 4.355), train_loss = 1.35470115, grad/param norm = 1.9553e-01, time/batch = 0.6666s	
2897/33250 (epoch 4.356), train_loss = 1.27812900, grad/param norm = 1.9267e-01, time/batch = 0.6782s	
2898/33250 (epoch 4.358), train_loss = 1.32031223, grad/param norm = 1.8610e-01, time/batch = 0.6794s	
2899/33250 (epoch 4.359), train_loss = 1.27101694, grad/param norm = 1.7149e-01, time/batch = 0.6704s	
2900/33250 (epoch 4.361), train_loss = 1.57392957, grad/param norm = 2.0339e-01, time/batch = 0.6650s	
2901/33250 (epoch 4.362), train_loss = 1.35022830, grad/param norm = 1.9840e-01, time/batch = 0.6736s	
2902/33250 (epoch 4.364), train_loss = 1.52559666, grad/param norm = 2.0236e-01, time/batch = 0.6796s	
2903/33250 (epoch 4.365), train_loss = 1.33723346, grad/param norm = 1.8597e-01, time/batch = 0.6850s	
2904/33250 (epoch 4.367), train_loss = 1.31904422, grad/param norm = 1.7586e-01, time/batch = 0.6851s	
2905/33250 (epoch 4.368), train_loss = 1.37086008, grad/param norm = 1.7851e-01, time/batch = 0.6701s	
2906/33250 (epoch 4.370), train_loss = 1.18642697, grad/param norm = 1.8015e-01, time/batch = 0.6755s	
2907/33250 (epoch 4.371), train_loss = 1.47848468, grad/param norm = 1.8183e-01, time/batch = 0.6879s	
2908/33250 (epoch 4.373), train_loss = 1.32921480, grad/param norm = 1.8588e-01, time/batch = 0.6925s	
2909/33250 (epoch 4.374), train_loss = 1.45377265, grad/param norm = 2.0812e-01, time/batch = 0.6919s	
2910/33250 (epoch 4.376), train_loss = 1.34379402, grad/param norm = 1.9511e-01, time/batch = 0.6901s	
2911/33250 (epoch 4.377), train_loss = 1.29996981, grad/param norm = 2.2529e-01, time/batch = 0.6949s	
2912/33250 (epoch 4.379), train_loss = 1.30170957, grad/param norm = 1.9851e-01, time/batch = 0.6843s	
2913/33250 (epoch 4.380), train_loss = 1.45887365, grad/param norm = 2.1454e-01, time/batch = 0.6769s	
2914/33250 (epoch 4.382), train_loss = 1.50716757, grad/param norm = 2.2513e-01, time/batch = 0.6585s	
2915/33250 (epoch 4.383), train_loss = 1.32354131, grad/param norm = 1.8684e-01, time/batch = 0.6553s	
2916/33250 (epoch 4.385), train_loss = 1.26297117, grad/param norm = 1.9580e-01, time/batch = 0.6553s	
2917/33250 (epoch 4.386), train_loss = 1.25964809, grad/param norm = 1.9599e-01, time/batch = 0.6505s	
2918/33250 (epoch 4.388), train_loss = 1.32727483, grad/param norm = 2.0676e-01, time/batch = 0.6564s	
2919/33250 (epoch 4.389), train_loss = 1.36268605, grad/param norm = 2.0601e-01, time/batch = 0.6723s	
2920/33250 (epoch 4.391), train_loss = 1.37227210, grad/param norm = 1.9347e-01, time/batch = 0.6767s	
2921/33250 (epoch 4.392), train_loss = 1.52774701, grad/param norm = 2.0656e-01, time/batch = 0.6773s	
2922/33250 (epoch 4.394), train_loss = 1.62827175, grad/param norm = 2.1433e-01, time/batch = 0.6604s	
2923/33250 (epoch 4.395), train_loss = 1.55901301, grad/param norm = 1.9702e-01, time/batch = 0.6582s	
2924/33250 (epoch 4.397), train_loss = 1.49539893, grad/param norm = 2.1513e-01, time/batch = 0.6506s	
2925/33250 (epoch 4.398), train_loss = 1.37679111, grad/param norm = 1.9703e-01, time/batch = 0.6518s	
2926/33250 (epoch 4.400), train_loss = 1.30597888, grad/param norm = 1.8489e-01, time/batch = 0.6579s	
2927/33250 (epoch 4.402), train_loss = 1.23848528, grad/param norm = 1.9356e-01, time/batch = 0.6527s	
2928/33250 (epoch 4.403), train_loss = 1.29396812, grad/param norm = 1.8424e-01, time/batch = 0.6520s	
2929/33250 (epoch 4.405), train_loss = 1.27133252, grad/param norm = 1.9297e-01, time/batch = 0.6532s	
2930/33250 (epoch 4.406), train_loss = 1.41463991, grad/param norm = 2.0440e-01, time/batch = 0.6520s	
2931/33250 (epoch 4.408), train_loss = 1.51969808, grad/param norm = 1.9414e-01, time/batch = 0.6870s	
2932/33250 (epoch 4.409), train_loss = 1.51149081, grad/param norm = 2.3473e-01, time/batch = 0.6708s	
2933/33250 (epoch 4.411), train_loss = 1.09436668, grad/param norm = 2.0346e-01, time/batch = 0.6630s	
2934/33250 (epoch 4.412), train_loss = 1.19372416, grad/param norm = 1.7981e-01, time/batch = 0.6598s	
2935/33250 (epoch 4.414), train_loss = 1.43071601, grad/param norm = 1.9115e-01, time/batch = 0.6518s	
2936/33250 (epoch 4.415), train_loss = 1.48467849, grad/param norm = 2.0254e-01, time/batch = 0.6504s	
2937/33250 (epoch 4.417), train_loss = 1.45035685, grad/param norm = 1.9669e-01, time/batch = 0.6490s	
2938/33250 (epoch 4.418), train_loss = 1.67067954, grad/param norm = 2.4116e-01, time/batch = 0.6559s	
2939/33250 (epoch 4.420), train_loss = 1.50022032, grad/param norm = 1.9902e-01, time/batch = 0.6585s	
2940/33250 (epoch 4.421), train_loss = 1.24523576, grad/param norm = 1.9424e-01, time/batch = 0.6685s	
2941/33250 (epoch 4.423), train_loss = 1.48251114, grad/param norm = 2.1019e-01, time/batch = 0.6533s	
2942/33250 (epoch 4.424), train_loss = 1.69374229, grad/param norm = 2.6081e-01, time/batch = 0.6549s	
2943/33250 (epoch 4.426), train_loss = 1.25574702, grad/param norm = 1.7438e-01, time/batch = 0.6492s	
2944/33250 (epoch 4.427), train_loss = 1.28021598, grad/param norm = 2.0961e-01, time/batch = 0.6554s	
2945/33250 (epoch 4.429), train_loss = 1.48365225, grad/param norm = 2.1021e-01, time/batch = 0.6747s	
2946/33250 (epoch 4.430), train_loss = 1.31060933, grad/param norm = 2.1874e-01, time/batch = 0.6747s	
2947/33250 (epoch 4.432), train_loss = 1.32798178, grad/param norm = 1.7252e-01, time/batch = 0.6696s	
2948/33250 (epoch 4.433), train_loss = 1.36231385, grad/param norm = 1.8359e-01, time/batch = 0.6653s	
2949/33250 (epoch 4.435), train_loss = 1.42415861, grad/param norm = 2.1624e-01, time/batch = 0.6692s	
2950/33250 (epoch 4.436), train_loss = 1.34810696, grad/param norm = 1.8904e-01, time/batch = 0.6741s	
2951/33250 (epoch 4.438), train_loss = 1.36943759, grad/param norm = 2.0099e-01, time/batch = 0.6774s	
2952/33250 (epoch 4.439), train_loss = 1.37193032, grad/param norm = 2.0446e-01, time/batch = 0.6750s	
2953/33250 (epoch 4.441), train_loss = 1.36682130, grad/param norm = 1.9676e-01, time/batch = 0.6699s	
2954/33250 (epoch 4.442), train_loss = 1.33423426, grad/param norm = 1.8051e-01, time/batch = 0.6589s	
2955/33250 (epoch 4.444), train_loss = 1.23783546, grad/param norm = 2.0024e-01, time/batch = 0.6744s	
2956/33250 (epoch 4.445), train_loss = 1.39155939, grad/param norm = 1.8476e-01, time/batch = 0.6759s	
2957/33250 (epoch 4.447), train_loss = 1.39822616, grad/param norm = 1.8533e-01, time/batch = 0.6705s	
2958/33250 (epoch 4.448), train_loss = 1.26509421, grad/param norm = 1.7351e-01, time/batch = 0.6663s	
2959/33250 (epoch 4.450), train_loss = 1.61951751, grad/param norm = 2.3077e-01, time/batch = 0.6661s	
2960/33250 (epoch 4.451), train_loss = 1.45329521, grad/param norm = 2.0865e-01, time/batch = 0.6720s	
2961/33250 (epoch 4.453), train_loss = 1.18706464, grad/param norm = 1.6998e-01, time/batch = 0.6656s	
2962/33250 (epoch 4.454), train_loss = 1.50668144, grad/param norm = 2.0543e-01, time/batch = 0.6500s	
2963/33250 (epoch 4.456), train_loss = 1.54106411, grad/param norm = 2.1931e-01, time/batch = 0.6514s	
2964/33250 (epoch 4.457), train_loss = 1.36734652, grad/param norm = 1.9779e-01, time/batch = 0.6473s	
2965/33250 (epoch 4.459), train_loss = 1.38394590, grad/param norm = 1.7411e-01, time/batch = 0.6660s	
2966/33250 (epoch 4.460), train_loss = 1.43779281, grad/param norm = 2.0435e-01, time/batch = 0.6615s	
2967/33250 (epoch 4.462), train_loss = 1.31213173, grad/param norm = 1.7921e-01, time/batch = 0.6481s	
2968/33250 (epoch 4.463), train_loss = 1.20674465, grad/param norm = 1.6088e-01, time/batch = 0.6496s	
2969/33250 (epoch 4.465), train_loss = 1.11603791, grad/param norm = 1.6132e-01, time/batch = 0.6555s	
2970/33250 (epoch 4.466), train_loss = 1.08603149, grad/param norm = 1.5536e-01, time/batch = 0.6566s	
2971/33250 (epoch 4.468), train_loss = 1.19972174, grad/param norm = 1.7187e-01, time/batch = 0.6599s	
2972/33250 (epoch 4.469), train_loss = 1.45948769, grad/param norm = 2.0434e-01, time/batch = 0.6537s	
2973/33250 (epoch 4.471), train_loss = 1.49985487, grad/param norm = 1.9786e-01, time/batch = 0.6516s	
2974/33250 (epoch 4.472), train_loss = 1.41673769, grad/param norm = 2.3526e-01, time/batch = 0.6515s	
2975/33250 (epoch 4.474), train_loss = 1.69240464, grad/param norm = 2.5290e-01, time/batch = 0.6500s	
2976/33250 (epoch 4.475), train_loss = 1.40895114, grad/param norm = 1.9876e-01, time/batch = 0.6625s	
2977/33250 (epoch 4.477), train_loss = 1.37645113, grad/param norm = 1.8460e-01, time/batch = 0.6583s	
2978/33250 (epoch 4.478), train_loss = 1.34439528, grad/param norm = 1.8694e-01, time/batch = 0.6506s	
2979/33250 (epoch 4.480), train_loss = 1.58106271, grad/param norm = 1.8998e-01, time/batch = 0.6534s	
2980/33250 (epoch 4.481), train_loss = 1.33585916, grad/param norm = 2.1815e-01, time/batch = 0.6540s	
2981/33250 (epoch 4.483), train_loss = 1.41789292, grad/param norm = 1.9688e-01, time/batch = 0.6513s	
2982/33250 (epoch 4.484), train_loss = 1.28655793, grad/param norm = 1.8378e-01, time/batch = 0.6549s	
2983/33250 (epoch 4.486), train_loss = 1.17138066, grad/param norm = 1.7299e-01, time/batch = 0.6607s	
2984/33250 (epoch 4.487), train_loss = 1.33933020, grad/param norm = 2.0285e-01, time/batch = 0.6834s	
2985/33250 (epoch 4.489), train_loss = 1.54648971, grad/param norm = 2.2478e-01, time/batch = 0.6542s	
2986/33250 (epoch 4.490), train_loss = 1.45754510, grad/param norm = 2.0840e-01, time/batch = 0.6568s	
2987/33250 (epoch 4.492), train_loss = 1.41332140, grad/param norm = 1.9864e-01, time/batch = 0.6597s	
2988/33250 (epoch 4.493), train_loss = 1.39636320, grad/param norm = 1.8956e-01, time/batch = 0.6630s	
2989/33250 (epoch 4.495), train_loss = 1.39275534, grad/param norm = 1.8983e-01, time/batch = 0.6597s	
2990/33250 (epoch 4.496), train_loss = 1.30411326, grad/param norm = 1.7036e-01, time/batch = 0.6530s	
2991/33250 (epoch 4.498), train_loss = 1.44442529, grad/param norm = 1.9655e-01, time/batch = 0.6589s	
2992/33250 (epoch 4.499), train_loss = 1.35686133, grad/param norm = 1.9806e-01, time/batch = 0.6711s	
2993/33250 (epoch 4.501), train_loss = 1.30666129, grad/param norm = 2.0081e-01, time/batch = 0.6542s	
2994/33250 (epoch 4.502), train_loss = 1.36323214, grad/param norm = 1.8309e-01, time/batch = 0.6578s	
2995/33250 (epoch 4.504), train_loss = 1.60116570, grad/param norm = 2.2172e-01, time/batch = 0.6534s	
2996/33250 (epoch 4.505), train_loss = 1.11246156, grad/param norm = 1.7830e-01, time/batch = 0.6486s	
2997/33250 (epoch 4.507), train_loss = 1.42154655, grad/param norm = 1.8333e-01, time/batch = 0.6585s	
2998/33250 (epoch 4.508), train_loss = 1.31336825, grad/param norm = 1.7552e-01, time/batch = 0.6598s	
2999/33250 (epoch 4.510), train_loss = 1.21976032, grad/param norm = 1.7705e-01, time/batch = 0.6502s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch4.51_1.5161.t7	
3000/33250 (epoch 4.511), train_loss = 1.41504054, grad/param norm = 1.8764e-01, time/batch = 0.6608s	
3001/33250 (epoch 4.513), train_loss = 1.74077953, grad/param norm = 2.1943e-01, time/batch = 0.6953s	
3002/33250 (epoch 4.514), train_loss = 1.30992793, grad/param norm = 1.7154e-01, time/batch = 0.6712s	
3003/33250 (epoch 4.516), train_loss = 1.34573283, grad/param norm = 1.9697e-01, time/batch = 0.6625s	
3004/33250 (epoch 4.517), train_loss = 1.38428601, grad/param norm = 1.8359e-01, time/batch = 0.6620s	
3005/33250 (epoch 4.519), train_loss = 1.20000636, grad/param norm = 1.6720e-01, time/batch = 0.6675s	
3006/33250 (epoch 4.520), train_loss = 1.70126077, grad/param norm = 2.1577e-01, time/batch = 0.6587s	
3007/33250 (epoch 4.522), train_loss = 1.48141821, grad/param norm = 1.9513e-01, time/batch = 0.6647s	
3008/33250 (epoch 4.523), train_loss = 1.34329589, grad/param norm = 2.0743e-01, time/batch = 0.6931s	
3009/33250 (epoch 4.525), train_loss = 1.20064029, grad/param norm = 1.7669e-01, time/batch = 0.6776s	
3010/33250 (epoch 4.526), train_loss = 1.22559834, grad/param norm = 1.9581e-01, time/batch = 0.6767s	
3011/33250 (epoch 4.528), train_loss = 1.33058290, grad/param norm = 1.8521e-01, time/batch = 0.6537s	
3012/33250 (epoch 4.529), train_loss = 1.27795489, grad/param norm = 1.7216e-01, time/batch = 0.6532s	
3013/33250 (epoch 4.531), train_loss = 1.17278910, grad/param norm = 1.9034e-01, time/batch = 0.6491s	
3014/33250 (epoch 4.532), train_loss = 1.50621570, grad/param norm = 1.8994e-01, time/batch = 0.6554s	
3015/33250 (epoch 4.534), train_loss = 1.33548030, grad/param norm = 1.7776e-01, time/batch = 0.6530s	
3016/33250 (epoch 4.535), train_loss = 1.37257134, grad/param norm = 1.8978e-01, time/batch = 0.6533s	
3017/33250 (epoch 4.537), train_loss = 1.48836677, grad/param norm = 1.9335e-01, time/batch = 0.6542s	
3018/33250 (epoch 4.538), train_loss = 1.46325281, grad/param norm = 1.9619e-01, time/batch = 0.6552s	
3019/33250 (epoch 4.540), train_loss = 1.51464715, grad/param norm = 1.8079e-01, time/batch = 0.6562s	
3020/33250 (epoch 4.541), train_loss = 1.52697960, grad/param norm = 2.0949e-01, time/batch = 0.6569s	
3021/33250 (epoch 4.543), train_loss = 1.52925240, grad/param norm = 2.1823e-01, time/batch = 0.6670s	
3022/33250 (epoch 4.544), train_loss = 1.37106808, grad/param norm = 2.0140e-01, time/batch = 0.6742s	
3023/33250 (epoch 4.546), train_loss = 1.37698188, grad/param norm = 1.9057e-01, time/batch = 0.6749s	
3024/33250 (epoch 4.547), train_loss = 1.27355717, grad/param norm = 1.8308e-01, time/batch = 0.6743s	
3025/33250 (epoch 4.549), train_loss = 1.39360911, grad/param norm = 1.8758e-01, time/batch = 0.6721s	
3026/33250 (epoch 4.550), train_loss = 1.30821494, grad/param norm = 1.8051e-01, time/batch = 0.6712s	
3027/33250 (epoch 4.552), train_loss = 1.44325055, grad/param norm = 2.0829e-01, time/batch = 0.6682s	
3028/33250 (epoch 4.553), train_loss = 1.28032353, grad/param norm = 1.9132e-01, time/batch = 0.6668s	
3029/33250 (epoch 4.555), train_loss = 1.36130618, grad/param norm = 1.8108e-01, time/batch = 0.6700s	
3030/33250 (epoch 4.556), train_loss = 1.56112355, grad/param norm = 2.1749e-01, time/batch = 0.6672s	
3031/33250 (epoch 4.558), train_loss = 1.47301542, grad/param norm = 1.9606e-01, time/batch = 0.6590s	
3032/33250 (epoch 4.559), train_loss = 1.22748626, grad/param norm = 1.9076e-01, time/batch = 0.6576s	
3033/33250 (epoch 4.561), train_loss = 1.36282035, grad/param norm = 1.9444e-01, time/batch = 0.6516s	
3034/33250 (epoch 4.562), train_loss = 1.55593083, grad/param norm = 2.0999e-01, time/batch = 0.6524s	
3035/33250 (epoch 4.564), train_loss = 1.62265787, grad/param norm = 2.2897e-01, time/batch = 0.6503s	
3036/33250 (epoch 4.565), train_loss = 1.57544479, grad/param norm = 1.9440e-01, time/batch = 0.6490s	
3037/33250 (epoch 4.567), train_loss = 1.46655702, grad/param norm = 1.9533e-01, time/batch = 0.6521s	
3038/33250 (epoch 4.568), train_loss = 1.33304511, grad/param norm = 1.9300e-01, time/batch = 0.6514s	
3039/33250 (epoch 4.570), train_loss = 1.54479442, grad/param norm = 2.1175e-01, time/batch = 0.6573s	
3040/33250 (epoch 4.571), train_loss = 1.59682008, grad/param norm = 1.9096e-01, time/batch = 0.6551s	
3041/33250 (epoch 4.573), train_loss = 1.49036300, grad/param norm = 1.8625e-01, time/batch = 0.6667s	
3042/33250 (epoch 4.574), train_loss = 1.24836612, grad/param norm = 1.7481e-01, time/batch = 0.6617s	
3043/33250 (epoch 4.576), train_loss = 1.40885840, grad/param norm = 1.8087e-01, time/batch = 0.6636s	
3044/33250 (epoch 4.577), train_loss = 1.35984976, grad/param norm = 1.7814e-01, time/batch = 0.6634s	
3045/33250 (epoch 4.579), train_loss = 1.24138855, grad/param norm = 1.8095e-01, time/batch = 0.6648s	
3046/33250 (epoch 4.580), train_loss = 1.20931409, grad/param norm = 1.5947e-01, time/batch = 0.6737s	
3047/33250 (epoch 4.582), train_loss = 1.33483652, grad/param norm = 1.8168e-01, time/batch = 0.6718s	
3048/33250 (epoch 4.583), train_loss = 1.36707263, grad/param norm = 1.6581e-01, time/batch = 0.6588s	
3049/33250 (epoch 4.585), train_loss = 1.48660093, grad/param norm = 2.1083e-01, time/batch = 0.6624s	
3050/33250 (epoch 4.586), train_loss = 1.31013277, grad/param norm = 2.1486e-01, time/batch = 0.6583s	
3051/33250 (epoch 4.588), train_loss = 1.38812792, grad/param norm = 1.8966e-01, time/batch = 0.6524s	
3052/33250 (epoch 4.589), train_loss = 1.46700849, grad/param norm = 1.8921e-01, time/batch = 0.6570s	
3053/33250 (epoch 4.591), train_loss = 1.50490850, grad/param norm = 2.1894e-01, time/batch = 0.6516s	
3054/33250 (epoch 4.592), train_loss = 1.37332549, grad/param norm = 1.7938e-01, time/batch = 0.6524s	
3055/33250 (epoch 4.594), train_loss = 1.60092695, grad/param norm = 2.0213e-01, time/batch = 0.6567s	
3056/33250 (epoch 4.595), train_loss = 1.56231776, grad/param norm = 1.9204e-01, time/batch = 0.6641s	
3057/33250 (epoch 4.597), train_loss = 1.28379306, grad/param norm = 1.7487e-01, time/batch = 0.6711s	
3058/33250 (epoch 4.598), train_loss = 1.48662606, grad/param norm = 1.9274e-01, time/batch = 0.6654s	
3059/33250 (epoch 4.600), train_loss = 1.39361700, grad/param norm = 2.0517e-01, time/batch = 0.6542s	
3060/33250 (epoch 4.602), train_loss = 1.48097773, grad/param norm = 2.1674e-01, time/batch = 0.6470s	
3061/33250 (epoch 4.603), train_loss = 1.37657721, grad/param norm = 1.9469e-01, time/batch = 0.6598s	
3062/33250 (epoch 4.605), train_loss = 1.40385256, grad/param norm = 1.8941e-01, time/batch = 0.6504s	
3063/33250 (epoch 4.606), train_loss = 1.46227367, grad/param norm = 1.9568e-01, time/batch = 0.6629s	
3064/33250 (epoch 4.608), train_loss = 1.37570316, grad/param norm = 1.9620e-01, time/batch = 0.6891s	
3065/33250 (epoch 4.609), train_loss = 1.31367990, grad/param norm = 1.9805e-01, time/batch = 0.6733s	
3066/33250 (epoch 4.611), train_loss = 1.51202101, grad/param norm = 2.0434e-01, time/batch = 0.6640s	
3067/33250 (epoch 4.612), train_loss = 1.43212477, grad/param norm = 1.8790e-01, time/batch = 0.6604s	
3068/33250 (epoch 4.614), train_loss = 1.71172388, grad/param norm = 2.2301e-01, time/batch = 0.6591s	
3069/33250 (epoch 4.615), train_loss = 1.53223877, grad/param norm = 1.9590e-01, time/batch = 0.6611s	
3070/33250 (epoch 4.617), train_loss = 1.84260804, grad/param norm = 2.0090e-01, time/batch = 0.6651s	
3071/33250 (epoch 4.618), train_loss = 1.74267727, grad/param norm = 2.5475e-01, time/batch = 0.6654s	
3072/33250 (epoch 4.620), train_loss = 1.57172532, grad/param norm = 2.1579e-01, time/batch = 0.6591s	
3073/33250 (epoch 4.621), train_loss = 1.34175597, grad/param norm = 1.7343e-01, time/batch = 0.6663s	
3074/33250 (epoch 4.623), train_loss = 1.33352940, grad/param norm = 2.1012e-01, time/batch = 0.6758s	
3075/33250 (epoch 4.624), train_loss = 1.39549149, grad/param norm = 2.0293e-01, time/batch = 0.6738s	
3076/33250 (epoch 4.626), train_loss = 1.45010598, grad/param norm = 2.0202e-01, time/batch = 0.6870s	
3077/33250 (epoch 4.627), train_loss = 1.36215703, grad/param norm = 1.7664e-01, time/batch = 0.6821s	
3078/33250 (epoch 4.629), train_loss = 1.38357574, grad/param norm = 2.1982e-01, time/batch = 0.6710s	
3079/33250 (epoch 4.630), train_loss = 1.38778823, grad/param norm = 1.9127e-01, time/batch = 0.6677s	
3080/33250 (epoch 4.632), train_loss = 1.17940791, grad/param norm = 1.7035e-01, time/batch = 0.6711s	
3081/33250 (epoch 4.633), train_loss = 1.49121434, grad/param norm = 1.9915e-01, time/batch = 0.6852s	
3082/33250 (epoch 4.635), train_loss = 1.25230189, grad/param norm = 1.6773e-01, time/batch = 0.6589s	
3083/33250 (epoch 4.636), train_loss = 1.29649769, grad/param norm = 1.7849e-01, time/batch = 0.6583s	
3084/33250 (epoch 4.638), train_loss = 1.34518645, grad/param norm = 1.9184e-01, time/batch = 0.6898s	
3085/33250 (epoch 4.639), train_loss = 1.32519939, grad/param norm = 2.0552e-01, time/batch = 0.6913s	
3086/33250 (epoch 4.641), train_loss = 1.25395916, grad/param norm = 1.7073e-01, time/batch = 0.6632s	
3087/33250 (epoch 4.642), train_loss = 1.26520978, grad/param norm = 1.6938e-01, time/batch = 0.6721s	
3088/33250 (epoch 4.644), train_loss = 1.12543495, grad/param norm = 1.7057e-01, time/batch = 0.6925s	
3089/33250 (epoch 4.645), train_loss = 1.54395726, grad/param norm = 2.1086e-01, time/batch = 0.6870s	
3090/33250 (epoch 4.647), train_loss = 1.23912697, grad/param norm = 1.7685e-01, time/batch = 0.6883s	
3091/33250 (epoch 4.648), train_loss = 1.34446387, grad/param norm = 2.0427e-01, time/batch = 0.6925s	
3092/33250 (epoch 4.650), train_loss = 1.57572173, grad/param norm = 2.2639e-01, time/batch = 0.6687s	
3093/33250 (epoch 4.651), train_loss = 1.39633437, grad/param norm = 2.0152e-01, time/batch = 0.6655s	
3094/33250 (epoch 4.653), train_loss = 1.23019645, grad/param norm = 1.6739e-01, time/batch = 0.6672s	
3095/33250 (epoch 4.654), train_loss = 1.25926582, grad/param norm = 1.7715e-01, time/batch = 0.6652s	
3096/33250 (epoch 4.656), train_loss = 1.41888419, grad/param norm = 1.8353e-01, time/batch = 0.6627s	
3097/33250 (epoch 4.657), train_loss = 1.16633550, grad/param norm = 1.9940e-01, time/batch = 0.6642s	
3098/33250 (epoch 4.659), train_loss = 1.29946960, grad/param norm = 1.8318e-01, time/batch = 0.6572s	
3099/33250 (epoch 4.660), train_loss = 1.29506817, grad/param norm = 2.0811e-01, time/batch = 0.6677s	
3100/33250 (epoch 4.662), train_loss = 1.40468374, grad/param norm = 1.9390e-01, time/batch = 0.6608s	
3101/33250 (epoch 4.663), train_loss = 1.30456476, grad/param norm = 1.8384e-01, time/batch = 0.6694s	
3102/33250 (epoch 4.665), train_loss = 1.50392453, grad/param norm = 1.9848e-01, time/batch = 0.6976s	
3103/33250 (epoch 4.666), train_loss = 1.34342241, grad/param norm = 2.0754e-01, time/batch = 0.6787s	
3104/33250 (epoch 4.668), train_loss = 1.50830907, grad/param norm = 1.8839e-01, time/batch = 0.6691s	
3105/33250 (epoch 4.669), train_loss = 1.46875558, grad/param norm = 1.9379e-01, time/batch = 0.6513s	
3106/33250 (epoch 4.671), train_loss = 1.40786501, grad/param norm = 2.0423e-01, time/batch = 0.6538s	
3107/33250 (epoch 4.672), train_loss = 1.52922554, grad/param norm = 2.0884e-01, time/batch = 0.6538s	
3108/33250 (epoch 4.674), train_loss = 1.35078516, grad/param norm = 1.6700e-01, time/batch = 0.6516s	
3109/33250 (epoch 4.675), train_loss = 1.43414304, grad/param norm = 1.9643e-01, time/batch = 0.6565s	
3110/33250 (epoch 4.677), train_loss = 1.40460472, grad/param norm = 1.8028e-01, time/batch = 0.6527s	
3111/33250 (epoch 4.678), train_loss = 1.44683865, grad/param norm = 1.9908e-01, time/batch = 0.6568s	
3112/33250 (epoch 4.680), train_loss = 1.47613780, grad/param norm = 1.9105e-01, time/batch = 0.6533s	
3113/33250 (epoch 4.681), train_loss = 1.19136849, grad/param norm = 1.7304e-01, time/batch = 0.6698s	
3114/33250 (epoch 4.683), train_loss = 1.30086517, grad/param norm = 1.9840e-01, time/batch = 0.6539s	
3115/33250 (epoch 4.684), train_loss = 1.34278236, grad/param norm = 2.0728e-01, time/batch = 0.6537s	
3116/33250 (epoch 4.686), train_loss = 1.25444489, grad/param norm = 1.8011e-01, time/batch = 0.6707s	
3117/33250 (epoch 4.687), train_loss = 1.28525937, grad/param norm = 1.8023e-01, time/batch = 0.6532s	
3118/33250 (epoch 4.689), train_loss = 1.30636865, grad/param norm = 1.8146e-01, time/batch = 0.6479s	
3119/33250 (epoch 4.690), train_loss = 1.46760381, grad/param norm = 2.0398e-01, time/batch = 0.6482s	
3120/33250 (epoch 4.692), train_loss = 1.48130180, grad/param norm = 2.2789e-01, time/batch = 0.6484s	
3121/33250 (epoch 4.693), train_loss = 1.35606375, grad/param norm = 1.7675e-01, time/batch = 0.6460s	
3122/33250 (epoch 4.695), train_loss = 1.43133327, grad/param norm = 1.8991e-01, time/batch = 0.6458s	
3123/33250 (epoch 4.696), train_loss = 1.34565157, grad/param norm = 1.7224e-01, time/batch = 0.6468s	
3124/33250 (epoch 4.698), train_loss = 1.29128811, grad/param norm = 1.9000e-01, time/batch = 0.6479s	
3125/33250 (epoch 4.699), train_loss = 1.58270754, grad/param norm = 1.9687e-01, time/batch = 0.6431s	
3126/33250 (epoch 4.701), train_loss = 1.29185233, grad/param norm = 1.7173e-01, time/batch = 0.6450s	
3127/33250 (epoch 4.702), train_loss = 1.46543061, grad/param norm = 2.3943e-01, time/batch = 0.6421s	
3128/33250 (epoch 4.704), train_loss = 1.57072564, grad/param norm = 2.2675e-01, time/batch = 0.6445s	
3129/33250 (epoch 4.705), train_loss = 1.23967090, grad/param norm = 1.7541e-01, time/batch = 0.6524s	
3130/33250 (epoch 4.707), train_loss = 1.22678411, grad/param norm = 1.9587e-01, time/batch = 0.6472s	
3131/33250 (epoch 4.708), train_loss = 1.42701499, grad/param norm = 2.0595e-01, time/batch = 0.6520s	
3132/33250 (epoch 4.710), train_loss = 1.48821284, grad/param norm = 2.0927e-01, time/batch = 0.6522s	
3133/33250 (epoch 4.711), train_loss = 1.46571802, grad/param norm = 2.1525e-01, time/batch = 0.6486s	
3134/33250 (epoch 4.713), train_loss = 1.49266612, grad/param norm = 2.1676e-01, time/batch = 0.6484s	
3135/33250 (epoch 4.714), train_loss = 1.43179746, grad/param norm = 1.7775e-01, time/batch = 0.6473s	
3136/33250 (epoch 4.716), train_loss = 1.56249161, grad/param norm = 2.1938e-01, time/batch = 0.6593s	
3137/33250 (epoch 4.717), train_loss = 1.30323997, grad/param norm = 1.7568e-01, time/batch = 0.6496s	
3138/33250 (epoch 4.719), train_loss = 1.41602273, grad/param norm = 2.1772e-01, time/batch = 0.6554s	
3139/33250 (epoch 4.720), train_loss = 1.63548489, grad/param norm = 1.8830e-01, time/batch = 0.6546s	
3140/33250 (epoch 4.722), train_loss = 1.28047754, grad/param norm = 1.7041e-01, time/batch = 0.6547s	
3141/33250 (epoch 4.723), train_loss = 1.14875727, grad/param norm = 1.6517e-01, time/batch = 0.6505s	
3142/33250 (epoch 4.725), train_loss = 1.13142047, grad/param norm = 1.5867e-01, time/batch = 0.6735s	
3143/33250 (epoch 4.726), train_loss = 1.27624216, grad/param norm = 1.6797e-01, time/batch = 0.6639s	
3144/33250 (epoch 4.728), train_loss = 1.42889597, grad/param norm = 1.8669e-01, time/batch = 0.6563s	
3145/33250 (epoch 4.729), train_loss = 1.55245588, grad/param norm = 2.0319e-01, time/batch = 0.6468s	
3146/33250 (epoch 4.731), train_loss = 1.31569634, grad/param norm = 1.8932e-01, time/batch = 0.6512s	
3147/33250 (epoch 4.732), train_loss = 1.26754656, grad/param norm = 1.7398e-01, time/batch = 0.6475s	
3148/33250 (epoch 4.734), train_loss = 1.41971752, grad/param norm = 1.8105e-01, time/batch = 0.6543s	
3149/33250 (epoch 4.735), train_loss = 1.40837808, grad/param norm = 1.8296e-01, time/batch = 0.6497s	
3150/33250 (epoch 4.737), train_loss = 1.45673827, grad/param norm = 1.7967e-01, time/batch = 0.6480s	
3151/33250 (epoch 4.738), train_loss = 1.39385720, grad/param norm = 1.7847e-01, time/batch = 0.6522s	
3152/33250 (epoch 4.740), train_loss = 1.58461465, grad/param norm = 1.9588e-01, time/batch = 0.6511s	
3153/33250 (epoch 4.741), train_loss = 1.42957293, grad/param norm = 1.8896e-01, time/batch = 0.6465s	
3154/33250 (epoch 4.743), train_loss = 1.34806507, grad/param norm = 1.7461e-01, time/batch = 0.6557s	
3155/33250 (epoch 4.744), train_loss = 1.38000786, grad/param norm = 1.8557e-01, time/batch = 0.6491s	
3156/33250 (epoch 4.746), train_loss = 1.40213264, grad/param norm = 1.6825e-01, time/batch = 0.6477s	
3157/33250 (epoch 4.747), train_loss = 1.34556588, grad/param norm = 1.8980e-01, time/batch = 0.6526s	
3158/33250 (epoch 4.749), train_loss = 1.58957696, grad/param norm = 2.1860e-01, time/batch = 0.6516s	
3159/33250 (epoch 4.750), train_loss = 1.40208333, grad/param norm = 1.9700e-01, time/batch = 0.6478s	
3160/33250 (epoch 4.752), train_loss = 1.23559552, grad/param norm = 1.6373e-01, time/batch = 0.6539s	
3161/33250 (epoch 4.753), train_loss = 1.35675362, grad/param norm = 1.7577e-01, time/batch = 0.6493s	
3162/33250 (epoch 4.755), train_loss = 1.28155024, grad/param norm = 1.7861e-01, time/batch = 0.6547s	
3163/33250 (epoch 4.756), train_loss = 1.48335254, grad/param norm = 1.9299e-01, time/batch = 0.6540s	
3164/33250 (epoch 4.758), train_loss = 1.46186392, grad/param norm = 1.8799e-01, time/batch = 0.6472s	
3165/33250 (epoch 4.759), train_loss = 1.23980734, grad/param norm = 1.6576e-01, time/batch = 0.6483s	
3166/33250 (epoch 4.761), train_loss = 1.32380121, grad/param norm = 1.9593e-01, time/batch = 0.6520s	
3167/33250 (epoch 4.762), train_loss = 1.41809552, grad/param norm = 1.8980e-01, time/batch = 0.6525s	
3168/33250 (epoch 4.764), train_loss = 1.30636685, grad/param norm = 2.4055e-01, time/batch = 0.6459s	
3169/33250 (epoch 4.765), train_loss = 1.40138854, grad/param norm = 2.0090e-01, time/batch = 0.6494s	
3170/33250 (epoch 4.767), train_loss = 1.16774259, grad/param norm = 1.9257e-01, time/batch = 0.6426s	
3171/33250 (epoch 4.768), train_loss = 1.25723591, grad/param norm = 1.9327e-01, time/batch = 0.6555s	
3172/33250 (epoch 4.770), train_loss = 1.42592329, grad/param norm = 2.1443e-01, time/batch = 0.6665s	
3173/33250 (epoch 4.771), train_loss = 1.46225517, grad/param norm = 2.0460e-01, time/batch = 0.6594s	
3174/33250 (epoch 4.773), train_loss = 1.35864849, grad/param norm = 1.9674e-01, time/batch = 0.6716s	
3175/33250 (epoch 4.774), train_loss = 1.17088652, grad/param norm = 1.8276e-01, time/batch = 0.6598s	
3176/33250 (epoch 4.776), train_loss = 1.31785261, grad/param norm = 1.8577e-01, time/batch = 0.6506s	
3177/33250 (epoch 4.777), train_loss = 1.50798811, grad/param norm = 2.2874e-01, time/batch = 0.6504s	
3178/33250 (epoch 4.779), train_loss = 1.25673449, grad/param norm = 1.8191e-01, time/batch = 0.6498s	
3179/33250 (epoch 4.780), train_loss = 1.59574934, grad/param norm = 2.1753e-01, time/batch = 0.6501s	
3180/33250 (epoch 4.782), train_loss = 1.41638911, grad/param norm = 2.0711e-01, time/batch = 0.6671s	
3181/33250 (epoch 4.783), train_loss = 1.16809993, grad/param norm = 1.7205e-01, time/batch = 0.6820s	
3182/33250 (epoch 4.785), train_loss = 1.27140438, grad/param norm = 1.9678e-01, time/batch = 0.6638s	
3183/33250 (epoch 4.786), train_loss = 1.48303954, grad/param norm = 1.9241e-01, time/batch = 0.6544s	
3184/33250 (epoch 4.788), train_loss = 1.36764003, grad/param norm = 1.8588e-01, time/batch = 0.6575s	
3185/33250 (epoch 4.789), train_loss = 1.47018583, grad/param norm = 1.9273e-01, time/batch = 0.6711s	
3186/33250 (epoch 4.791), train_loss = 1.51623319, grad/param norm = 1.9231e-01, time/batch = 0.6565s	
3187/33250 (epoch 4.792), train_loss = 1.57267951, grad/param norm = 1.8210e-01, time/batch = 0.6492s	
3188/33250 (epoch 4.794), train_loss = 1.29528766, grad/param norm = 1.9767e-01, time/batch = 0.6522s	
3189/33250 (epoch 4.795), train_loss = 1.44032674, grad/param norm = 1.8591e-01, time/batch = 0.6771s	
3190/33250 (epoch 4.797), train_loss = 1.51755421, grad/param norm = 2.0338e-01, time/batch = 0.6611s	
3191/33250 (epoch 4.798), train_loss = 1.46639897, grad/param norm = 2.4500e-01, time/batch = 0.6545s	
3192/33250 (epoch 4.800), train_loss = 1.50372760, grad/param norm = 2.1131e-01, time/batch = 0.6651s	
3193/33250 (epoch 4.802), train_loss = 1.33266093, grad/param norm = 1.9148e-01, time/batch = 0.6601s	
3194/33250 (epoch 4.803), train_loss = 1.32425382, grad/param norm = 1.7973e-01, time/batch = 0.6740s	
3195/33250 (epoch 4.805), train_loss = 1.42551372, grad/param norm = 2.0062e-01, time/batch = 0.6717s	
3196/33250 (epoch 4.806), train_loss = 1.46090682, grad/param norm = 1.8756e-01, time/batch = 0.6723s	
3197/33250 (epoch 4.808), train_loss = 1.39425901, grad/param norm = 1.9631e-01, time/batch = 0.6496s	
3198/33250 (epoch 4.809), train_loss = 1.23666923, grad/param norm = 1.8319e-01, time/batch = 0.6434s	
3199/33250 (epoch 4.811), train_loss = 1.29568620, grad/param norm = 1.9503e-01, time/batch = 0.6448s	
3200/33250 (epoch 4.812), train_loss = 1.39805160, grad/param norm = 1.8803e-01, time/batch = 0.6437s	
3201/33250 (epoch 4.814), train_loss = 1.33744128, grad/param norm = 1.9146e-01, time/batch = 0.6505s	
3202/33250 (epoch 4.815), train_loss = 1.43348426, grad/param norm = 2.1033e-01, time/batch = 0.6489s	
3203/33250 (epoch 4.817), train_loss = 1.36536016, grad/param norm = 2.0268e-01, time/batch = 0.6464s	
3204/33250 (epoch 4.818), train_loss = 1.25457645, grad/param norm = 1.9437e-01, time/batch = 0.6484s	
3205/33250 (epoch 4.820), train_loss = 1.42443934, grad/param norm = 2.0523e-01, time/batch = 0.6463s	
3206/33250 (epoch 4.821), train_loss = 1.26359312, grad/param norm = 1.8624e-01, time/batch = 0.6475s	
3207/33250 (epoch 4.823), train_loss = 1.66407959, grad/param norm = 2.2763e-01, time/batch = 0.6498s	
3208/33250 (epoch 4.824), train_loss = 1.38939310, grad/param norm = 1.8266e-01, time/batch = 0.6514s	
3209/33250 (epoch 4.826), train_loss = 1.36359488, grad/param norm = 2.0037e-01, time/batch = 0.6521s	
3210/33250 (epoch 4.827), train_loss = 1.15489437, grad/param norm = 1.6686e-01, time/batch = 0.6551s	
3211/33250 (epoch 4.829), train_loss = 1.36907806, grad/param norm = 1.9646e-01, time/batch = 0.6551s	
3212/33250 (epoch 4.830), train_loss = 1.59408687, grad/param norm = 2.2664e-01, time/batch = 0.6481s	
3213/33250 (epoch 4.832), train_loss = 1.31963616, grad/param norm = 1.7611e-01, time/batch = 0.6484s	
3214/33250 (epoch 4.833), train_loss = 1.42924354, grad/param norm = 1.8626e-01, time/batch = 0.6533s	
3215/33250 (epoch 4.835), train_loss = 1.36902736, grad/param norm = 2.0677e-01, time/batch = 0.6499s	
3216/33250 (epoch 4.836), train_loss = 1.38325810, grad/param norm = 1.7407e-01, time/batch = 0.6697s	
3217/33250 (epoch 4.838), train_loss = 1.29206898, grad/param norm = 1.6919e-01, time/batch = 0.6701s	
3218/33250 (epoch 4.839), train_loss = 1.33389186, grad/param norm = 1.9460e-01, time/batch = 0.6661s	
3219/33250 (epoch 4.841), train_loss = 1.15488926, grad/param norm = 1.5879e-01, time/batch = 0.6770s	
3220/33250 (epoch 4.842), train_loss = 1.48101095, grad/param norm = 1.8182e-01, time/batch = 0.6814s	
3221/33250 (epoch 4.844), train_loss = 1.52785791, grad/param norm = 2.0176e-01, time/batch = 0.6899s	
3222/33250 (epoch 4.845), train_loss = 1.66377754, grad/param norm = 2.4056e-01, time/batch = 0.6861s	
3223/33250 (epoch 4.847), train_loss = 1.56242149, grad/param norm = 1.9413e-01, time/batch = 0.6872s	
3224/33250 (epoch 4.848), train_loss = 1.67840846, grad/param norm = 2.2946e-01, time/batch = 0.6697s	
3225/33250 (epoch 4.850), train_loss = 1.46046778, grad/param norm = 1.9772e-01, time/batch = 0.6678s	
3226/33250 (epoch 4.851), train_loss = 1.33095686, grad/param norm = 1.9013e-01, time/batch = 0.6718s	
3227/33250 (epoch 4.853), train_loss = 1.44385544, grad/param norm = 2.0909e-01, time/batch = 0.6879s	
3228/33250 (epoch 4.854), train_loss = 1.24610828, grad/param norm = 1.7323e-01, time/batch = 0.6779s	
3229/33250 (epoch 4.856), train_loss = 1.25379579, grad/param norm = 1.7068e-01, time/batch = 0.6713s	
3230/33250 (epoch 4.857), train_loss = 1.16926790, grad/param norm = 1.6755e-01, time/batch = 0.6668s	
3231/33250 (epoch 4.859), train_loss = 1.16622094, grad/param norm = 1.7548e-01, time/batch = 0.6744s	
3232/33250 (epoch 4.860), train_loss = 1.32664325, grad/param norm = 1.5469e-01, time/batch = 0.6752s	
3233/33250 (epoch 4.862), train_loss = 1.22358676, grad/param norm = 1.6344e-01, time/batch = 0.6923s	
3234/33250 (epoch 4.863), train_loss = 1.24868039, grad/param norm = 1.7495e-01, time/batch = 0.6845s	
3235/33250 (epoch 4.865), train_loss = 1.40599279, grad/param norm = 1.9269e-01, time/batch = 0.6742s	
3236/33250 (epoch 4.866), train_loss = 1.27837512, grad/param norm = 2.0016e-01, time/batch = 0.6684s	
3237/33250 (epoch 4.868), train_loss = 1.70795649, grad/param norm = 2.5495e-01, time/batch = 0.6713s	
3238/33250 (epoch 4.869), train_loss = 1.41236210, grad/param norm = 1.9759e-01, time/batch = 0.6696s	
3239/33250 (epoch 4.871), train_loss = 1.12615046, grad/param norm = 1.7058e-01, time/batch = 0.6749s	
3240/33250 (epoch 4.872), train_loss = 1.43316135, grad/param norm = 1.9367e-01, time/batch = 0.6699s	
3241/33250 (epoch 4.874), train_loss = 1.31059007, grad/param norm = 1.8316e-01, time/batch = 0.6670s	
3242/33250 (epoch 4.875), train_loss = 1.30526363, grad/param norm = 2.1026e-01, time/batch = 0.6702s	
3243/33250 (epoch 4.877), train_loss = 1.41260758, grad/param norm = 1.9134e-01, time/batch = 0.6682s	
3244/33250 (epoch 4.878), train_loss = 1.35525884, grad/param norm = 1.8145e-01, time/batch = 0.6711s	
3245/33250 (epoch 4.880), train_loss = 1.40815177, grad/param norm = 1.9834e-01, time/batch = 0.6723s	
3246/33250 (epoch 4.881), train_loss = 1.59256477, grad/param norm = 1.9034e-01, time/batch = 0.6704s	
3247/33250 (epoch 4.883), train_loss = 1.42016095, grad/param norm = 1.9911e-01, time/batch = 0.6673s	
3248/33250 (epoch 4.884), train_loss = 1.35586991, grad/param norm = 2.0642e-01, time/batch = 0.6712s	
3249/33250 (epoch 4.886), train_loss = 1.24067381, grad/param norm = 1.7686e-01, time/batch = 0.6730s	
3250/33250 (epoch 4.887), train_loss = 1.31847509, grad/param norm = 1.7941e-01, time/batch = 0.6749s	
3251/33250 (epoch 4.889), train_loss = 1.26927343, grad/param norm = 1.5463e-01, time/batch = 0.6731s	
3252/33250 (epoch 4.890), train_loss = 1.16948149, grad/param norm = 1.6406e-01, time/batch = 0.6682s	
3253/33250 (epoch 4.892), train_loss = 1.44359046, grad/param norm = 1.8721e-01, time/batch = 0.6633s	
3254/33250 (epoch 4.893), train_loss = 1.46461360, grad/param norm = 1.8472e-01, time/batch = 0.6657s	
3255/33250 (epoch 4.895), train_loss = 1.30173237, grad/param norm = 1.7373e-01, time/batch = 0.6653s	
3256/33250 (epoch 4.896), train_loss = 1.42694359, grad/param norm = 1.9520e-01, time/batch = 0.6628s	
3257/33250 (epoch 4.898), train_loss = 1.27460906, grad/param norm = 1.8174e-01, time/batch = 0.6661s	
3258/33250 (epoch 4.899), train_loss = 1.30012804, grad/param norm = 1.8510e-01, time/batch = 0.6777s	
3259/33250 (epoch 4.901), train_loss = 1.17080349, grad/param norm = 1.6320e-01, time/batch = 0.6739s	
3260/33250 (epoch 4.902), train_loss = 1.29613706, grad/param norm = 1.8360e-01, time/batch = 0.6692s	
3261/33250 (epoch 4.904), train_loss = 1.24398023, grad/param norm = 1.7314e-01, time/batch = 0.6818s	
3262/33250 (epoch 4.905), train_loss = 1.30027146, grad/param norm = 1.8571e-01, time/batch = 0.6861s	
3263/33250 (epoch 4.907), train_loss = 1.30826350, grad/param norm = 1.8278e-01, time/batch = 0.6738s	
3264/33250 (epoch 4.908), train_loss = 1.35370058, grad/param norm = 1.7120e-01, time/batch = 0.6733s	
3265/33250 (epoch 4.910), train_loss = 1.48367051, grad/param norm = 2.0781e-01, time/batch = 0.6741s	
3266/33250 (epoch 4.911), train_loss = 1.13341969, grad/param norm = 1.7858e-01, time/batch = 0.6713s	
3267/33250 (epoch 4.913), train_loss = 1.29392035, grad/param norm = 1.6543e-01, time/batch = 0.6655s	
3268/33250 (epoch 4.914), train_loss = 1.15776017, grad/param norm = 1.7552e-01, time/batch = 0.6650s	
3269/33250 (epoch 4.916), train_loss = 1.23336408, grad/param norm = 1.6241e-01, time/batch = 0.6701s	
3270/33250 (epoch 4.917), train_loss = 1.27338863, grad/param norm = 1.7307e-01, time/batch = 0.6733s	
3271/33250 (epoch 4.919), train_loss = 1.32191890, grad/param norm = 1.9074e-01, time/batch = 0.6798s	
3272/33250 (epoch 4.920), train_loss = 1.37239102, grad/param norm = 1.9826e-01, time/batch = 0.6677s	
3273/33250 (epoch 4.922), train_loss = 1.37384728, grad/param norm = 1.8495e-01, time/batch = 0.6510s	
3274/33250 (epoch 4.923), train_loss = 1.34243849, grad/param norm = 2.1009e-01, time/batch = 0.6571s	
3275/33250 (epoch 4.925), train_loss = 1.30558387, grad/param norm = 1.8058e-01, time/batch = 0.6654s	
3276/33250 (epoch 4.926), train_loss = 1.29677038, grad/param norm = 1.8994e-01, time/batch = 0.6718s	
3277/33250 (epoch 4.928), train_loss = 1.34983397, grad/param norm = 1.8060e-01, time/batch = 0.6726s	
3278/33250 (epoch 4.929), train_loss = 1.04692260, grad/param norm = 1.6103e-01, time/batch = 0.6881s	
3279/33250 (epoch 4.931), train_loss = 1.40691541, grad/param norm = 1.7971e-01, time/batch = 0.6720s	
3280/33250 (epoch 4.932), train_loss = 1.45207251, grad/param norm = 2.0084e-01, time/batch = 0.6728s	
3281/33250 (epoch 4.934), train_loss = 1.27751974, grad/param norm = 1.8363e-01, time/batch = 0.6764s	
3282/33250 (epoch 4.935), train_loss = 1.37331118, grad/param norm = 2.0007e-01, time/batch = 0.6741s	
3283/33250 (epoch 4.937), train_loss = 1.37543421, grad/param norm = 1.8966e-01, time/batch = 0.6579s	
3284/33250 (epoch 4.938), train_loss = 1.47907015, grad/param norm = 1.9227e-01, time/batch = 0.6560s	
3285/33250 (epoch 4.940), train_loss = 1.30115080, grad/param norm = 1.8322e-01, time/batch = 0.6536s	
3286/33250 (epoch 4.941), train_loss = 1.38055446, grad/param norm = 1.8181e-01, time/batch = 0.6592s	
3287/33250 (epoch 4.943), train_loss = 1.54913149, grad/param norm = 1.8885e-01, time/batch = 0.6585s	
3288/33250 (epoch 4.944), train_loss = 1.21388594, grad/param norm = 1.6585e-01, time/batch = 0.6507s	
3289/33250 (epoch 4.946), train_loss = 1.57248938, grad/param norm = 1.8172e-01, time/batch = 0.6665s	
3290/33250 (epoch 4.947), train_loss = 1.31978444, grad/param norm = 1.8655e-01, time/batch = 0.6631s	
3291/33250 (epoch 4.949), train_loss = 1.47539531, grad/param norm = 1.8840e-01, time/batch = 0.6497s	
3292/33250 (epoch 4.950), train_loss = 1.36328372, grad/param norm = 1.8215e-01, time/batch = 0.6570s	
3293/33250 (epoch 4.952), train_loss = 1.35496116, grad/param norm = 1.9095e-01, time/batch = 0.6539s	
3294/33250 (epoch 4.953), train_loss = 1.46500057, grad/param norm = 1.9565e-01, time/batch = 0.6499s	
3295/33250 (epoch 4.955), train_loss = 1.43227115, grad/param norm = 1.8893e-01, time/batch = 0.6530s	
3296/33250 (epoch 4.956), train_loss = 1.53213489, grad/param norm = 2.1032e-01, time/batch = 0.6523s	
3297/33250 (epoch 4.958), train_loss = 1.24718827, grad/param norm = 1.6970e-01, time/batch = 0.6527s	
3298/33250 (epoch 4.959), train_loss = 1.21691117, grad/param norm = 1.6056e-01, time/batch = 0.6520s	
3299/33250 (epoch 4.961), train_loss = 1.50371623, grad/param norm = 1.9191e-01, time/batch = 0.6503s	
3300/33250 (epoch 4.962), train_loss = 1.42139051, grad/param norm = 1.9646e-01, time/batch = 0.6538s	
3301/33250 (epoch 4.964), train_loss = 1.51401160, grad/param norm = 2.0278e-01, time/batch = 0.6520s	
3302/33250 (epoch 4.965), train_loss = 1.40121729, grad/param norm = 1.9034e-01, time/batch = 0.6491s	
3303/33250 (epoch 4.967), train_loss = 1.45417833, grad/param norm = 1.8437e-01, time/batch = 0.6533s	
3304/33250 (epoch 4.968), train_loss = 1.57060463, grad/param norm = 1.9210e-01, time/batch = 0.6530s	
3305/33250 (epoch 4.970), train_loss = 1.69047260, grad/param norm = 2.1627e-01, time/batch = 0.6561s	
3306/33250 (epoch 4.971), train_loss = 1.52182571, grad/param norm = 1.9833e-01, time/batch = 0.6570s	
3307/33250 (epoch 4.973), train_loss = 1.30521679, grad/param norm = 1.7642e-01, time/batch = 0.6563s	
3308/33250 (epoch 4.974), train_loss = 1.38593857, grad/param norm = 1.9668e-01, time/batch = 0.6551s	
3309/33250 (epoch 4.976), train_loss = 1.29523109, grad/param norm = 1.8577e-01, time/batch = 0.6519s	
3310/33250 (epoch 4.977), train_loss = 1.29312253, grad/param norm = 1.9651e-01, time/batch = 0.6591s	
3311/33250 (epoch 4.979), train_loss = 1.39169787, grad/param norm = 1.9395e-01, time/batch = 0.6523s	
3312/33250 (epoch 4.980), train_loss = 1.33853998, grad/param norm = 1.7251e-01, time/batch = 0.6569s	
3313/33250 (epoch 4.982), train_loss = 1.14539077, grad/param norm = 1.5404e-01, time/batch = 0.6494s	
3314/33250 (epoch 4.983), train_loss = 1.44471859, grad/param norm = 2.0597e-01, time/batch = 0.6540s	
3315/33250 (epoch 4.985), train_loss = 1.27290968, grad/param norm = 2.0132e-01, time/batch = 0.6527s	
3316/33250 (epoch 4.986), train_loss = 1.50466598, grad/param norm = 2.1321e-01, time/batch = 0.6624s	
3317/33250 (epoch 4.988), train_loss = 1.41034529, grad/param norm = 2.0163e-01, time/batch = 0.6684s	
3318/33250 (epoch 4.989), train_loss = 1.52763217, grad/param norm = 2.0448e-01, time/batch = 0.6500s	
3319/33250 (epoch 4.991), train_loss = 1.36510159, grad/param norm = 2.0117e-01, time/batch = 0.6504s	
3320/33250 (epoch 4.992), train_loss = 1.30406280, grad/param norm = 1.7765e-01, time/batch = 0.6562s	
3321/33250 (epoch 4.994), train_loss = 1.22276165, grad/param norm = 1.8027e-01, time/batch = 0.6531s	
3322/33250 (epoch 4.995), train_loss = 1.41496806, grad/param norm = 2.2734e-01, time/batch = 0.6543s	
3323/33250 (epoch 4.997), train_loss = 1.03213855, grad/param norm = 1.5593e-01, time/batch = 0.6567s	
3324/33250 (epoch 4.998), train_loss = 1.33841522, grad/param norm = 1.7437e-01, time/batch = 0.6542s	
3325/33250 (epoch 5.000), train_loss = 1.35395475, grad/param norm = 1.8017e-01, time/batch = 0.6549s	
3326/33250 (epoch 5.002), train_loss = 1.51063330, grad/param norm = 2.0170e-01, time/batch = 0.6538s	
3327/33250 (epoch 5.003), train_loss = 1.40968135, grad/param norm = 1.9045e-01, time/batch = 0.6552s	
3328/33250 (epoch 5.005), train_loss = 1.16952786, grad/param norm = 1.7949e-01, time/batch = 0.6488s	
3329/33250 (epoch 5.006), train_loss = 1.13962969, grad/param norm = 1.5755e-01, time/batch = 0.6551s	
3330/33250 (epoch 5.008), train_loss = 1.43350211, grad/param norm = 1.9937e-01, time/batch = 0.6571s	
3331/33250 (epoch 5.009), train_loss = 1.48559257, grad/param norm = 1.9852e-01, time/batch = 0.6617s	
3332/33250 (epoch 5.011), train_loss = 1.29250795, grad/param norm = 1.7571e-01, time/batch = 0.6506s	
3333/33250 (epoch 5.012), train_loss = 1.47473903, grad/param norm = 2.2803e-01, time/batch = 0.6516s	
3334/33250 (epoch 5.014), train_loss = 1.47028413, grad/param norm = 1.9124e-01, time/batch = 0.6493s	
3335/33250 (epoch 5.015), train_loss = 1.33679146, grad/param norm = 1.9665e-01, time/batch = 0.6651s	
3336/33250 (epoch 5.017), train_loss = 1.39942686, grad/param norm = 1.8581e-01, time/batch = 0.6651s	
3337/33250 (epoch 5.018), train_loss = 1.17524913, grad/param norm = 1.8793e-01, time/batch = 0.6575s	
3338/33250 (epoch 5.020), train_loss = 1.27413703, grad/param norm = 1.6806e-01, time/batch = 0.6624s	
3339/33250 (epoch 5.021), train_loss = 1.33516859, grad/param norm = 1.8208e-01, time/batch = 0.6611s	
3340/33250 (epoch 5.023), train_loss = 1.17739156, grad/param norm = 1.8920e-01, time/batch = 0.6668s	
3341/33250 (epoch 5.024), train_loss = 1.46421110, grad/param norm = 1.8532e-01, time/batch = 0.6617s	
3342/33250 (epoch 5.026), train_loss = 1.34108583, grad/param norm = 1.6017e-01, time/batch = 0.6658s	
3343/33250 (epoch 5.027), train_loss = 1.26417734, grad/param norm = 1.7359e-01, time/batch = 0.6659s	
3344/33250 (epoch 5.029), train_loss = 1.35544574, grad/param norm = 1.7428e-01, time/batch = 0.6606s	
3345/33250 (epoch 5.030), train_loss = 1.34121835, grad/param norm = 1.8849e-01, time/batch = 0.6695s	
3346/33250 (epoch 5.032), train_loss = 1.62790183, grad/param norm = 2.2353e-01, time/batch = 0.6648s	
3347/33250 (epoch 5.033), train_loss = 1.30117811, grad/param norm = 2.1299e-01, time/batch = 0.6683s	
3348/33250 (epoch 5.035), train_loss = 1.28712828, grad/param norm = 1.9863e-01, time/batch = 0.6612s	
3349/33250 (epoch 5.036), train_loss = 1.40911609, grad/param norm = 1.9499e-01, time/batch = 0.6839s	
3350/33250 (epoch 5.038), train_loss = 1.25736332, grad/param norm = 1.7679e-01, time/batch = 0.6650s	
3351/33250 (epoch 5.039), train_loss = 1.19049619, grad/param norm = 1.8399e-01, time/batch = 0.6682s	
3352/33250 (epoch 5.041), train_loss = 1.46156736, grad/param norm = 2.0902e-01, time/batch = 0.6610s	
3353/33250 (epoch 5.042), train_loss = 1.14824714, grad/param norm = 1.6308e-01, time/batch = 0.6639s	
3354/33250 (epoch 5.044), train_loss = 1.50812172, grad/param norm = 1.8428e-01, time/batch = 0.6639s	
3355/33250 (epoch 5.045), train_loss = 1.44731634, grad/param norm = 1.6939e-01, time/batch = 0.6662s	
3356/33250 (epoch 5.047), train_loss = 1.46839640, grad/param norm = 1.8913e-01, time/batch = 0.6643s	
3357/33250 (epoch 5.048), train_loss = 1.59716826, grad/param norm = 2.1877e-01, time/batch = 0.6687s	
3358/33250 (epoch 5.050), train_loss = 1.29544632, grad/param norm = 1.8390e-01, time/batch = 0.6693s	
3359/33250 (epoch 5.051), train_loss = 1.34394159, grad/param norm = 1.6990e-01, time/batch = 0.6612s	
3360/33250 (epoch 5.053), train_loss = 1.42018857, grad/param norm = 1.8437e-01, time/batch = 0.6820s	
3361/33250 (epoch 5.054), train_loss = 1.17008545, grad/param norm = 1.5888e-01, time/batch = 0.6881s	
3362/33250 (epoch 5.056), train_loss = 1.20555773, grad/param norm = 1.8047e-01, time/batch = 0.6877s	
3363/33250 (epoch 5.057), train_loss = 1.31632051, grad/param norm = 1.6394e-01, time/batch = 0.6604s	
3364/33250 (epoch 5.059), train_loss = 1.28290733, grad/param norm = 1.7787e-01, time/batch = 0.6663s	
3365/33250 (epoch 5.060), train_loss = 1.42302422, grad/param norm = 1.9767e-01, time/batch = 0.6734s	
3366/33250 (epoch 5.062), train_loss = 1.50151846, grad/param norm = 1.7642e-01, time/batch = 0.6811s	
3367/33250 (epoch 5.063), train_loss = 1.44328458, grad/param norm = 1.7183e-01, time/batch = 0.7053s	
3368/33250 (epoch 5.065), train_loss = 1.34516212, grad/param norm = 1.7979e-01, time/batch = 0.6920s	
3369/33250 (epoch 5.066), train_loss = 1.45400154, grad/param norm = 1.9505e-01, time/batch = 0.6687s	
3370/33250 (epoch 5.068), train_loss = 1.37121714, grad/param norm = 1.8953e-01, time/batch = 0.6775s	
3371/33250 (epoch 5.069), train_loss = 1.37329824, grad/param norm = 1.7739e-01, time/batch = 0.6716s	
3372/33250 (epoch 5.071), train_loss = 1.19982475, grad/param norm = 1.7457e-01, time/batch = 0.6699s	
3373/33250 (epoch 5.072), train_loss = 1.26817785, grad/param norm = 1.7460e-01, time/batch = 0.6713s	
3374/33250 (epoch 5.074), train_loss = 1.39976500, grad/param norm = 1.8086e-01, time/batch = 0.6668s	
3375/33250 (epoch 5.075), train_loss = 1.22690122, grad/param norm = 1.7801e-01, time/batch = 0.6675s	
3376/33250 (epoch 5.077), train_loss = 1.36339447, grad/param norm = 1.7746e-01, time/batch = 0.6716s	
3377/33250 (epoch 5.078), train_loss = 1.25142671, grad/param norm = 1.7886e-01, time/batch = 0.6707s	
3378/33250 (epoch 5.080), train_loss = 1.44222166, grad/param norm = 2.1157e-01, time/batch = 0.6657s	
3379/33250 (epoch 5.081), train_loss = 1.39419042, grad/param norm = 1.9015e-01, time/batch = 0.6699s	
3380/33250 (epoch 5.083), train_loss = 1.43843468, grad/param norm = 1.8361e-01, time/batch = 0.6706s	
3381/33250 (epoch 5.084), train_loss = 1.31410009, grad/param norm = 1.8904e-01, time/batch = 0.6643s	
3382/33250 (epoch 5.086), train_loss = 1.26836926, grad/param norm = 1.5678e-01, time/batch = 0.6658s	
3383/33250 (epoch 5.087), train_loss = 1.16979448, grad/param norm = 1.6684e-01, time/batch = 0.6623s	
3384/33250 (epoch 5.089), train_loss = 1.38075822, grad/param norm = 1.8382e-01, time/batch = 0.6653s	
3385/33250 (epoch 5.090), train_loss = 1.27029680, grad/param norm = 1.9642e-01, time/batch = 0.6671s	
3386/33250 (epoch 5.092), train_loss = 1.19670464, grad/param norm = 1.6781e-01, time/batch = 0.6643s	
3387/33250 (epoch 5.093), train_loss = 1.31576856, grad/param norm = 1.8495e-01, time/batch = 0.6723s	
3388/33250 (epoch 5.095), train_loss = 1.26650827, grad/param norm = 1.8161e-01, time/batch = 0.6684s	
3389/33250 (epoch 5.096), train_loss = 1.11900236, grad/param norm = 1.6176e-01, time/batch = 0.6727s	
3390/33250 (epoch 5.098), train_loss = 1.24068049, grad/param norm = 1.7999e-01, time/batch = 0.6843s	
3391/33250 (epoch 5.099), train_loss = 1.04503968, grad/param norm = 1.6798e-01, time/batch = 0.6692s	
3392/33250 (epoch 5.101), train_loss = 1.28867671, grad/param norm = 1.7892e-01, time/batch = 0.6681s	
3393/33250 (epoch 5.102), train_loss = 1.18244584, grad/param norm = 1.7093e-01, time/batch = 0.6644s	
3394/33250 (epoch 5.104), train_loss = 1.11697510, grad/param norm = 1.7067e-01, time/batch = 0.6646s	
3395/33250 (epoch 5.105), train_loss = 1.25425266, grad/param norm = 1.7915e-01, time/batch = 0.6867s	
3396/33250 (epoch 5.107), train_loss = 1.07371238, grad/param norm = 1.5856e-01, time/batch = 0.6895s	
3397/33250 (epoch 5.108), train_loss = 1.30509527, grad/param norm = 1.7767e-01, time/batch = 0.6659s	
3398/33250 (epoch 5.110), train_loss = 1.09596282, grad/param norm = 1.5982e-01, time/batch = 0.6761s	
3399/33250 (epoch 5.111), train_loss = 1.28887000, grad/param norm = 1.7685e-01, time/batch = 0.6721s	
3400/33250 (epoch 5.113), train_loss = 1.27401709, grad/param norm = 1.8356e-01, time/batch = 0.6740s	
3401/33250 (epoch 5.114), train_loss = 1.21407568, grad/param norm = 1.8369e-01, time/batch = 0.6706s	
3402/33250 (epoch 5.116), train_loss = 1.37448482, grad/param norm = 1.9280e-01, time/batch = 0.6689s	
3403/33250 (epoch 5.117), train_loss = 1.27755924, grad/param norm = 1.6977e-01, time/batch = 0.6821s	
3404/33250 (epoch 5.119), train_loss = 1.28051909, grad/param norm = 1.6266e-01, time/batch = 0.6662s	
3405/33250 (epoch 5.120), train_loss = 1.02936806, grad/param norm = 1.5803e-01, time/batch = 0.6667s	
3406/33250 (epoch 5.122), train_loss = 1.43085873, grad/param norm = 1.7329e-01, time/batch = 0.6665s	
3407/33250 (epoch 5.123), train_loss = 1.40613733, grad/param norm = 1.7995e-01, time/batch = 0.6712s	
3408/33250 (epoch 5.125), train_loss = 1.10761079, grad/param norm = 1.7135e-01, time/batch = 0.6709s	
3409/33250 (epoch 5.126), train_loss = 1.32922250, grad/param norm = 1.9382e-01, time/batch = 0.6684s	
3410/33250 (epoch 5.128), train_loss = 1.19696272, grad/param norm = 1.7183e-01, time/batch = 0.6699s	
3411/33250 (epoch 5.129), train_loss = 1.27154685, grad/param norm = 1.7722e-01, time/batch = 0.6702s	
3412/33250 (epoch 5.131), train_loss = 1.32248387, grad/param norm = 1.9604e-01, time/batch = 0.6729s	
3413/33250 (epoch 5.132), train_loss = 1.29612551, grad/param norm = 1.8033e-01, time/batch = 0.6709s	
3414/33250 (epoch 5.134), train_loss = 1.33055652, grad/param norm = 1.7526e-01, time/batch = 0.6666s	
3415/33250 (epoch 5.135), train_loss = 1.38348247, grad/param norm = 1.8454e-01, time/batch = 0.6667s	
3416/33250 (epoch 5.137), train_loss = 1.17885176, grad/param norm = 1.7993e-01, time/batch = 0.6621s	
3417/33250 (epoch 5.138), train_loss = 1.23258099, grad/param norm = 1.5944e-01, time/batch = 0.6633s	
3418/33250 (epoch 5.140), train_loss = 1.11505499, grad/param norm = 1.7236e-01, time/batch = 0.6655s	
3419/33250 (epoch 5.141), train_loss = 1.68609030, grad/param norm = 2.4024e-01, time/batch = 0.6687s	
3420/33250 (epoch 5.143), train_loss = 1.07819778, grad/param norm = 1.7687e-01, time/batch = 0.6647s	
3421/33250 (epoch 5.144), train_loss = 1.21054302, grad/param norm = 1.7238e-01, time/batch = 0.6801s	
3422/33250 (epoch 5.146), train_loss = 1.19566784, grad/param norm = 1.5859e-01, time/batch = 0.6808s	
3423/33250 (epoch 5.147), train_loss = 1.21047371, grad/param norm = 1.7267e-01, time/batch = 0.6747s	
3424/33250 (epoch 5.149), train_loss = 1.32373443, grad/param norm = 1.8153e-01, time/batch = 0.6745s	
3425/33250 (epoch 5.150), train_loss = 1.14088688, grad/param norm = 1.7008e-01, time/batch = 0.6837s	
3426/33250 (epoch 5.152), train_loss = 1.15923451, grad/param norm = 1.8815e-01, time/batch = 0.6889s	
3427/33250 (epoch 5.153), train_loss = 1.47602547, grad/param norm = 2.0603e-01, time/batch = 0.6865s	
3428/33250 (epoch 5.155), train_loss = 1.37516922, grad/param norm = 2.0258e-01, time/batch = 0.6724s	
3429/33250 (epoch 5.156), train_loss = 1.42303794, grad/param norm = 1.8694e-01, time/batch = 0.6698s	
3430/33250 (epoch 5.158), train_loss = 1.60172852, grad/param norm = 2.2067e-01, time/batch = 0.6850s	
3431/33250 (epoch 5.159), train_loss = 1.34093884, grad/param norm = 1.9084e-01, time/batch = 0.6893s	
3432/33250 (epoch 5.161), train_loss = 1.39893653, grad/param norm = 1.9842e-01, time/batch = 0.6766s	
3433/33250 (epoch 5.162), train_loss = 1.22989673, grad/param norm = 1.8249e-01, time/batch = 0.6700s	
3434/33250 (epoch 5.164), train_loss = 1.39242920, grad/param norm = 1.9342e-01, time/batch = 0.6695s	
3435/33250 (epoch 5.165), train_loss = 1.39228806, grad/param norm = 1.9178e-01, time/batch = 0.6675s	
3436/33250 (epoch 5.167), train_loss = 1.39968650, grad/param norm = 1.7961e-01, time/batch = 0.6712s	
3437/33250 (epoch 5.168), train_loss = 1.14030038, grad/param norm = 1.6481e-01, time/batch = 0.6694s	
3438/33250 (epoch 5.170), train_loss = 1.24207824, grad/param norm = 1.6899e-01, time/batch = 0.6686s	
3439/33250 (epoch 5.171), train_loss = 1.27576727, grad/param norm = 1.7249e-01, time/batch = 0.6639s	
3440/33250 (epoch 5.173), train_loss = 1.23260340, grad/param norm = 1.8587e-01, time/batch = 0.6645s	
3441/33250 (epoch 5.174), train_loss = 1.30184399, grad/param norm = 1.8934e-01, time/batch = 0.6688s	
3442/33250 (epoch 5.176), train_loss = 1.35142443, grad/param norm = 1.8446e-01, time/batch = 0.6648s	
3443/33250 (epoch 5.177), train_loss = 1.13491437, grad/param norm = 1.4920e-01, time/batch = 0.6718s	
3444/33250 (epoch 5.179), train_loss = 1.25741341, grad/param norm = 1.8011e-01, time/batch = 0.6643s	
3445/33250 (epoch 5.180), train_loss = 1.17031416, grad/param norm = 1.7309e-01, time/batch = 0.6660s	
3446/33250 (epoch 5.182), train_loss = 1.29043398, grad/param norm = 2.0603e-01, time/batch = 0.6668s	
3447/33250 (epoch 5.183), train_loss = 1.50042870, grad/param norm = 1.9018e-01, time/batch = 0.6758s	
3448/33250 (epoch 5.185), train_loss = 1.41431763, grad/param norm = 1.9991e-01, time/batch = 0.6640s	
3449/33250 (epoch 5.186), train_loss = 1.27865112, grad/param norm = 1.6525e-01, time/batch = 0.6839s	
3450/33250 (epoch 5.188), train_loss = 1.38914422, grad/param norm = 1.9148e-01, time/batch = 0.6969s	
3451/33250 (epoch 5.189), train_loss = 1.13710232, grad/param norm = 1.8848e-01, time/batch = 0.7083s	
3452/33250 (epoch 5.191), train_loss = 1.23021251, grad/param norm = 1.7771e-01, time/batch = 0.7167s	
3453/33250 (epoch 5.192), train_loss = 1.19221286, grad/param norm = 1.5918e-01, time/batch = 0.7177s	
3454/33250 (epoch 5.194), train_loss = 1.16087313, grad/param norm = 1.9171e-01, time/batch = 0.6984s	
3455/33250 (epoch 5.195), train_loss = 1.46075566, grad/param norm = 1.7895e-01, time/batch = 0.6918s	
3456/33250 (epoch 5.197), train_loss = 1.30091795, grad/param norm = 1.8086e-01, time/batch = 0.6914s	
3457/33250 (epoch 5.198), train_loss = 1.40539057, grad/param norm = 1.9266e-01, time/batch = 0.6693s	
3458/33250 (epoch 5.200), train_loss = 1.29414953, grad/param norm = 1.7670e-01, time/batch = 0.6702s	
3459/33250 (epoch 5.202), train_loss = 1.25203991, grad/param norm = 1.7658e-01, time/batch = 0.6838s	
3460/33250 (epoch 5.203), train_loss = 1.29940071, grad/param norm = 1.8302e-01, time/batch = 0.6884s	
3461/33250 (epoch 5.205), train_loss = 1.33788264, grad/param norm = 1.8420e-01, time/batch = 0.7051s	
3462/33250 (epoch 5.206), train_loss = 1.32856940, grad/param norm = 1.9252e-01, time/batch = 0.7014s	
3463/33250 (epoch 5.208), train_loss = 1.54876968, grad/param norm = 2.1757e-01, time/batch = 0.6939s	
3464/33250 (epoch 5.209), train_loss = 1.21337381, grad/param norm = 1.9186e-01, time/batch = 0.6912s	
3465/33250 (epoch 5.211), train_loss = 1.46273109, grad/param norm = 1.9522e-01, time/batch = 0.6895s	
3466/33250 (epoch 5.212), train_loss = 1.57481184, grad/param norm = 1.9944e-01, time/batch = 0.6918s	
3467/33250 (epoch 5.214), train_loss = 1.30003023, grad/param norm = 1.6447e-01, time/batch = 0.6831s	
3468/33250 (epoch 5.215), train_loss = 1.68613999, grad/param norm = 2.2442e-01, time/batch = 0.6678s	
3469/33250 (epoch 5.217), train_loss = 1.50575350, grad/param norm = 2.0322e-01, time/batch = 0.6786s	
3470/33250 (epoch 5.218), train_loss = 1.39070250, grad/param norm = 1.8768e-01, time/batch = 0.6811s	
3471/33250 (epoch 5.220), train_loss = 1.48567331, grad/param norm = 1.9816e-01, time/batch = 0.6904s	
3472/33250 (epoch 5.221), train_loss = 1.59342655, grad/param norm = 2.1117e-01, time/batch = 0.6733s	
3473/33250 (epoch 5.223), train_loss = 1.30264176, grad/param norm = 1.8897e-01, time/batch = 0.6744s	
3474/33250 (epoch 5.224), train_loss = 1.46204179, grad/param norm = 2.0434e-01, time/batch = 0.6869s	
3475/33250 (epoch 5.226), train_loss = 1.48112629, grad/param norm = 1.7788e-01, time/batch = 0.6715s	
3476/33250 (epoch 5.227), train_loss = 1.34681649, grad/param norm = 1.7503e-01, time/batch = 0.6475s	
3477/33250 (epoch 5.229), train_loss = 1.33101865, grad/param norm = 1.7383e-01, time/batch = 0.6498s	
3478/33250 (epoch 5.230), train_loss = 1.26992454, grad/param norm = 1.8255e-01, time/batch = 0.6673s	
3479/33250 (epoch 5.232), train_loss = 1.23061380, grad/param norm = 1.5605e-01, time/batch = 0.6631s	
3480/33250 (epoch 5.233), train_loss = 1.26620779, grad/param norm = 1.7232e-01, time/batch = 0.6629s	
3481/33250 (epoch 5.235), train_loss = 1.43544661, grad/param norm = 1.8689e-01, time/batch = 0.6660s	
3482/33250 (epoch 5.236), train_loss = 1.25099819, grad/param norm = 2.0545e-01, time/batch = 0.6659s	
3483/33250 (epoch 5.238), train_loss = 1.41515750, grad/param norm = 1.9088e-01, time/batch = 0.6598s	
3484/33250 (epoch 5.239), train_loss = 1.55566927, grad/param norm = 2.0251e-01, time/batch = 0.6660s	
3485/33250 (epoch 5.241), train_loss = 1.46091786, grad/param norm = 2.0690e-01, time/batch = 0.6650s	
3486/33250 (epoch 5.242), train_loss = 1.40134615, grad/param norm = 1.9076e-01, time/batch = 0.6660s	
3487/33250 (epoch 5.244), train_loss = 1.47089568, grad/param norm = 2.1415e-01, time/batch = 0.6669s	
3488/33250 (epoch 5.245), train_loss = 1.30806617, grad/param norm = 1.7333e-01, time/batch = 0.6728s	
3489/33250 (epoch 5.247), train_loss = 1.37331951, grad/param norm = 1.6313e-01, time/batch = 0.6828s	
3490/33250 (epoch 5.248), train_loss = 1.63404624, grad/param norm = 2.0720e-01, time/batch = 0.6780s	
3491/33250 (epoch 5.250), train_loss = 1.37721896, grad/param norm = 1.6840e-01, time/batch = 0.6862s	
3492/33250 (epoch 5.251), train_loss = 1.34502731, grad/param norm = 1.9815e-01, time/batch = 0.6838s	
3493/33250 (epoch 5.253), train_loss = 1.17421708, grad/param norm = 1.6940e-01, time/batch = 0.6815s	
3494/33250 (epoch 5.254), train_loss = 1.28558847, grad/param norm = 1.8061e-01, time/batch = 0.6851s	
3495/33250 (epoch 5.256), train_loss = 1.41044999, grad/param norm = 1.7071e-01, time/batch = 0.6808s	
3496/33250 (epoch 5.257), train_loss = 1.51309280, grad/param norm = 1.8972e-01, time/batch = 0.6808s	
3497/33250 (epoch 5.259), train_loss = 1.54382362, grad/param norm = 1.8188e-01, time/batch = 0.6821s	
3498/33250 (epoch 5.260), train_loss = 1.22318044, grad/param norm = 1.6816e-01, time/batch = 0.6827s	
3499/33250 (epoch 5.262), train_loss = 1.39665546, grad/param norm = 1.7510e-01, time/batch = 0.6833s	
3500/33250 (epoch 5.263), train_loss = 1.26209056, grad/param norm = 1.6487e-01, time/batch = 0.6782s	
3501/33250 (epoch 5.265), train_loss = 1.44408306, grad/param norm = 1.8198e-01, time/batch = 0.6788s	
3502/33250 (epoch 5.266), train_loss = 1.34969495, grad/param norm = 1.8593e-01, time/batch = 0.6624s	
3503/33250 (epoch 5.268), train_loss = 1.23496293, grad/param norm = 1.6260e-01, time/batch = 0.6631s	
3504/33250 (epoch 5.269), train_loss = 1.05785362, grad/param norm = 1.5670e-01, time/batch = 0.6664s	
3505/33250 (epoch 5.271), train_loss = 1.33201004, grad/param norm = 1.6797e-01, time/batch = 0.6751s	
3506/33250 (epoch 5.272), train_loss = 1.08289504, grad/param norm = 1.4601e-01, time/batch = 0.6633s	
3507/33250 (epoch 5.274), train_loss = 1.03571958, grad/param norm = 1.5172e-01, time/batch = 0.6688s	
3508/33250 (epoch 5.275), train_loss = 1.18608360, grad/param norm = 1.6094e-01, time/batch = 0.6651s	
3509/33250 (epoch 5.277), train_loss = 1.06050780, grad/param norm = 1.5809e-01, time/batch = 0.6622s	
3510/33250 (epoch 5.278), train_loss = 1.16151281, grad/param norm = 1.5983e-01, time/batch = 0.6640s	
3511/33250 (epoch 5.280), train_loss = 1.12312125, grad/param norm = 1.5992e-01, time/batch = 0.6734s	
3512/33250 (epoch 5.281), train_loss = 1.30834384, grad/param norm = 1.8851e-01, time/batch = 0.6749s	
3513/33250 (epoch 5.283), train_loss = 1.40242054, grad/param norm = 1.8751e-01, time/batch = 0.6749s	
3514/33250 (epoch 5.284), train_loss = 1.24054253, grad/param norm = 1.6928e-01, time/batch = 0.6826s	
3515/33250 (epoch 5.286), train_loss = 1.39848523, grad/param norm = 2.0269e-01, time/batch = 0.6668s	
3516/33250 (epoch 5.287), train_loss = 1.15131815, grad/param norm = 1.6368e-01, time/batch = 0.6640s	
3517/33250 (epoch 5.289), train_loss = 1.19540063, grad/param norm = 1.7133e-01, time/batch = 0.6640s	
3518/33250 (epoch 5.290), train_loss = 1.30405673, grad/param norm = 1.6210e-01, time/batch = 0.6668s	
3519/33250 (epoch 5.292), train_loss = 1.33696430, grad/param norm = 1.8998e-01, time/batch = 0.6694s	
3520/33250 (epoch 5.293), train_loss = 1.45515945, grad/param norm = 2.1284e-01, time/batch = 0.6767s	
3521/33250 (epoch 5.295), train_loss = 1.38116615, grad/param norm = 1.8256e-01, time/batch = 0.6838s	
3522/33250 (epoch 5.296), train_loss = 1.29883111, grad/param norm = 1.6824e-01, time/batch = 0.6841s	
3523/33250 (epoch 5.298), train_loss = 1.05732271, grad/param norm = 1.4172e-01, time/batch = 0.6839s	
3524/33250 (epoch 5.299), train_loss = 1.04032683, grad/param norm = 1.4947e-01, time/batch = 0.6819s	
3525/33250 (epoch 5.301), train_loss = 1.39027886, grad/param norm = 1.7870e-01, time/batch = 0.6732s	
3526/33250 (epoch 5.302), train_loss = 1.27587186, grad/param norm = 1.7195e-01, time/batch = 0.6722s	
3527/33250 (epoch 5.304), train_loss = 1.24302476, grad/param norm = 1.6034e-01, time/batch = 0.6745s	
3528/33250 (epoch 5.305), train_loss = 1.28374316, grad/param norm = 1.6598e-01, time/batch = 0.6634s	
3529/33250 (epoch 5.307), train_loss = 1.42178171, grad/param norm = 1.8307e-01, time/batch = 0.6589s	
3530/33250 (epoch 5.308), train_loss = 1.57169075, grad/param norm = 2.1009e-01, time/batch = 0.6715s	
3531/33250 (epoch 5.310), train_loss = 1.33486533, grad/param norm = 1.8690e-01, time/batch = 0.6773s	
3532/33250 (epoch 5.311), train_loss = 1.42713764, grad/param norm = 1.7861e-01, time/batch = 0.6717s	
3533/33250 (epoch 5.313), train_loss = 1.15922278, grad/param norm = 1.7760e-01, time/batch = 0.6681s	
3534/33250 (epoch 5.314), train_loss = 1.27123487, grad/param norm = 1.7437e-01, time/batch = 0.6775s	
3535/33250 (epoch 5.316), train_loss = 1.50801716, grad/param norm = 2.0884e-01, time/batch = 0.6633s	
3536/33250 (epoch 5.317), train_loss = 1.21761339, grad/param norm = 1.7321e-01, time/batch = 0.6590s	
3537/33250 (epoch 5.319), train_loss = 1.46031030, grad/param norm = 1.9829e-01, time/batch = 0.6788s	
3538/33250 (epoch 5.320), train_loss = 1.58897331, grad/param norm = 2.3816e-01, time/batch = 0.6850s	
3539/33250 (epoch 5.322), train_loss = 1.55104073, grad/param norm = 2.1189e-01, time/batch = 0.6784s	
3540/33250 (epoch 5.323), train_loss = 1.62781315, grad/param norm = 2.1350e-01, time/batch = 0.6730s	
3541/33250 (epoch 5.325), train_loss = 1.32134198, grad/param norm = 1.9766e-01, time/batch = 0.6770s	
3542/33250 (epoch 5.326), train_loss = 1.59806961, grad/param norm = 2.0751e-01, time/batch = 0.6764s	
3543/33250 (epoch 5.328), train_loss = 1.23711355, grad/param norm = 1.7169e-01, time/batch = 0.6761s	
3544/33250 (epoch 5.329), train_loss = 1.38752872, grad/param norm = 1.8085e-01, time/batch = 0.6755s	
3545/33250 (epoch 5.331), train_loss = 1.28242137, grad/param norm = 1.8074e-01, time/batch = 0.6694s	
3546/33250 (epoch 5.332), train_loss = 1.25052847, grad/param norm = 1.8949e-01, time/batch = 0.6771s	
3547/33250 (epoch 5.334), train_loss = 1.45152972, grad/param norm = 1.7872e-01, time/batch = 0.6755s	
3548/33250 (epoch 5.335), train_loss = 0.99909829, grad/param norm = 1.5312e-01, time/batch = 0.6674s	
3549/33250 (epoch 5.337), train_loss = 1.32868330, grad/param norm = 1.7901e-01, time/batch = 0.6660s	
3550/33250 (epoch 5.338), train_loss = 1.43172362, grad/param norm = 1.8856e-01, time/batch = 0.6487s	
3551/33250 (epoch 5.340), train_loss = 1.32218786, grad/param norm = 1.8482e-01, time/batch = 0.6549s	
3552/33250 (epoch 5.341), train_loss = 1.25916962, grad/param norm = 1.7660e-01, time/batch = 0.6504s	
3553/33250 (epoch 5.343), train_loss = 1.35648023, grad/param norm = 1.9138e-01, time/batch = 0.6551s	
3554/33250 (epoch 5.344), train_loss = 1.29211132, grad/param norm = 1.8248e-01, time/batch = 0.6560s	
3555/33250 (epoch 5.346), train_loss = 1.13434884, grad/param norm = 1.6178e-01, time/batch = 0.6533s	
3556/33250 (epoch 5.347), train_loss = 1.66540136, grad/param norm = 1.9267e-01, time/batch = 0.6491s	
3557/33250 (epoch 5.349), train_loss = 1.31774807, grad/param norm = 1.7960e-01, time/batch = 0.6479s	
3558/33250 (epoch 5.350), train_loss = 1.34430181, grad/param norm = 1.8993e-01, time/batch = 0.6501s	
3559/33250 (epoch 5.352), train_loss = 1.24458751, grad/param norm = 1.9470e-01, time/batch = 0.6532s	
3560/33250 (epoch 5.353), train_loss = 1.29202180, grad/param norm = 1.6841e-01, time/batch = 0.6505s	
3561/33250 (epoch 5.355), train_loss = 1.28827419, grad/param norm = 1.8171e-01, time/batch = 0.6613s	
3562/33250 (epoch 5.356), train_loss = 1.21112311, grad/param norm = 1.9137e-01, time/batch = 0.6539s	
3563/33250 (epoch 5.358), train_loss = 1.25352917, grad/param norm = 1.6678e-01, time/batch = 0.6491s	
3564/33250 (epoch 5.359), train_loss = 1.21557559, grad/param norm = 1.6103e-01, time/batch = 0.6521s	
3565/33250 (epoch 5.361), train_loss = 1.49190823, grad/param norm = 1.9413e-01, time/batch = 0.6532s	
3566/33250 (epoch 5.362), train_loss = 1.27599184, grad/param norm = 1.8038e-01, time/batch = 0.6502s	
3567/33250 (epoch 5.364), train_loss = 1.44097231, grad/param norm = 1.9378e-01, time/batch = 0.6530s	
3568/33250 (epoch 5.365), train_loss = 1.26941061, grad/param norm = 1.7564e-01, time/batch = 0.6527s	
3569/33250 (epoch 5.367), train_loss = 1.24823878, grad/param norm = 1.5872e-01, time/batch = 0.6529s	
3570/33250 (epoch 5.368), train_loss = 1.30260003, grad/param norm = 1.7351e-01, time/batch = 0.6526s	
3571/33250 (epoch 5.370), train_loss = 1.11639176, grad/param norm = 1.6514e-01, time/batch = 0.6569s	
3572/33250 (epoch 5.371), train_loss = 1.41517990, grad/param norm = 1.7520e-01, time/batch = 0.6683s	
3573/33250 (epoch 5.373), train_loss = 1.25780038, grad/param norm = 1.7386e-01, time/batch = 0.6726s	
3574/33250 (epoch 5.374), train_loss = 1.38618406, grad/param norm = 1.9693e-01, time/batch = 0.6580s	
3575/33250 (epoch 5.376), train_loss = 1.28314832, grad/param norm = 1.7724e-01, time/batch = 0.6476s	
3576/33250 (epoch 5.377), train_loss = 1.23711166, grad/param norm = 2.2010e-01, time/batch = 0.6623s	
3577/33250 (epoch 5.379), train_loss = 1.23167104, grad/param norm = 1.8690e-01, time/batch = 0.6697s	
3578/33250 (epoch 5.380), train_loss = 1.38895166, grad/param norm = 2.0399e-01, time/batch = 0.6796s	
3579/33250 (epoch 5.382), train_loss = 1.43899374, grad/param norm = 2.0891e-01, time/batch = 0.6640s	
3580/33250 (epoch 5.383), train_loss = 1.23798382, grad/param norm = 1.8004e-01, time/batch = 0.6479s	
3581/33250 (epoch 5.385), train_loss = 1.19188912, grad/param norm = 1.8793e-01, time/batch = 0.6510s	
3582/33250 (epoch 5.386), train_loss = 1.17510004, grad/param norm = 1.8199e-01, time/batch = 0.6537s	
3583/33250 (epoch 5.388), train_loss = 1.24592577, grad/param norm = 1.9497e-01, time/batch = 0.6463s	
3584/33250 (epoch 5.389), train_loss = 1.29259268, grad/param norm = 1.9594e-01, time/batch = 0.6544s	
3585/33250 (epoch 5.391), train_loss = 1.31739480, grad/param norm = 1.8882e-01, time/batch = 0.6610s	
3586/33250 (epoch 5.392), train_loss = 1.45357522, grad/param norm = 1.9626e-01, time/batch = 0.6493s	
3587/33250 (epoch 5.394), train_loss = 1.55698338, grad/param norm = 2.0847e-01, time/batch = 0.6562s	
3588/33250 (epoch 5.395), train_loss = 1.46812760, grad/param norm = 1.8412e-01, time/batch = 0.6486s	
3589/33250 (epoch 5.397), train_loss = 1.44173792, grad/param norm = 2.0555e-01, time/batch = 0.6558s	
3590/33250 (epoch 5.398), train_loss = 1.27647767, grad/param norm = 1.7408e-01, time/batch = 0.6533s	
3591/33250 (epoch 5.400), train_loss = 1.23362117, grad/param norm = 1.7706e-01, time/batch = 0.6535s	
3592/33250 (epoch 5.402), train_loss = 1.16726879, grad/param norm = 1.7243e-01, time/batch = 0.6516s	
3593/33250 (epoch 5.403), train_loss = 1.24117543, grad/param norm = 1.8820e-01, time/batch = 0.6603s	
3594/33250 (epoch 5.405), train_loss = 1.21476009, grad/param norm = 1.9058e-01, time/batch = 0.6627s	
3595/33250 (epoch 5.406), train_loss = 1.35505783, grad/param norm = 1.9021e-01, time/batch = 0.6638s	
3596/33250 (epoch 5.408), train_loss = 1.46105370, grad/param norm = 1.8452e-01, time/batch = 0.6576s	
3597/33250 (epoch 5.409), train_loss = 1.43586665, grad/param norm = 2.2485e-01, time/batch = 0.6499s	
3598/33250 (epoch 5.411), train_loss = 1.01325714, grad/param norm = 1.6161e-01, time/batch = 0.6547s	
3599/33250 (epoch 5.412), train_loss = 1.12826153, grad/param norm = 1.7049e-01, time/batch = 0.6591s	
3600/33250 (epoch 5.414), train_loss = 1.35262045, grad/param norm = 1.8068e-01, time/batch = 0.6517s	
3601/33250 (epoch 5.415), train_loss = 1.43388073, grad/param norm = 1.8823e-01, time/batch = 0.6566s	
3602/33250 (epoch 5.417), train_loss = 1.38217463, grad/param norm = 1.8286e-01, time/batch = 0.6587s	
3603/33250 (epoch 5.418), train_loss = 1.60750868, grad/param norm = 2.4242e-01, time/batch = 0.6526s	
3604/33250 (epoch 5.420), train_loss = 1.43187258, grad/param norm = 1.8048e-01, time/batch = 0.6499s	
3605/33250 (epoch 5.421), train_loss = 1.18653856, grad/param norm = 1.8420e-01, time/batch = 0.6520s	
3606/33250 (epoch 5.423), train_loss = 1.42681483, grad/param norm = 2.1231e-01, time/batch = 0.6477s	
3607/33250 (epoch 5.424), train_loss = 1.63730583, grad/param norm = 2.5666e-01, time/batch = 0.6488s	
3608/33250 (epoch 5.426), train_loss = 1.18580660, grad/param norm = 1.6695e-01, time/batch = 0.6508s	
3609/33250 (epoch 5.427), train_loss = 1.21237137, grad/param norm = 1.8353e-01, time/batch = 0.6467s	
3610/33250 (epoch 5.429), train_loss = 1.41095398, grad/param norm = 1.9955e-01, time/batch = 0.6504s	
3611/33250 (epoch 5.430), train_loss = 1.24017128, grad/param norm = 2.0283e-01, time/batch = 0.6481s	
3612/33250 (epoch 5.432), train_loss = 1.26450103, grad/param norm = 1.6122e-01, time/batch = 0.6469s	
3613/33250 (epoch 5.433), train_loss = 1.29100688, grad/param norm = 1.7833e-01, time/batch = 0.6474s	
3614/33250 (epoch 5.435), train_loss = 1.34305378, grad/param norm = 1.9504e-01, time/batch = 0.6528s	
3615/33250 (epoch 5.436), train_loss = 1.25436331, grad/param norm = 1.7575e-01, time/batch = 0.6527s	
3616/33250 (epoch 5.438), train_loss = 1.31679731, grad/param norm = 1.7852e-01, time/batch = 0.6618s	
3617/33250 (epoch 5.439), train_loss = 1.30236597, grad/param norm = 1.9682e-01, time/batch = 0.6734s	
3618/33250 (epoch 5.441), train_loss = 1.29301474, grad/param norm = 1.8221e-01, time/batch = 0.6680s	
3619/33250 (epoch 5.442), train_loss = 1.25539236, grad/param norm = 1.7293e-01, time/batch = 0.6488s	
3620/33250 (epoch 5.444), train_loss = 1.18422918, grad/param norm = 1.8501e-01, time/batch = 0.6630s	
3621/33250 (epoch 5.445), train_loss = 1.32662420, grad/param norm = 1.7187e-01, time/batch = 0.6660s	
3622/33250 (epoch 5.447), train_loss = 1.33563888, grad/param norm = 1.7877e-01, time/batch = 0.6421s	
3623/33250 (epoch 5.448), train_loss = 1.19990825, grad/param norm = 1.5740e-01, time/batch = 0.6454s	
3624/33250 (epoch 5.450), train_loss = 1.54071189, grad/param norm = 2.2585e-01, time/batch = 0.6414s	
3625/33250 (epoch 5.451), train_loss = 1.37804544, grad/param norm = 2.0213e-01, time/batch = 0.6464s	
3626/33250 (epoch 5.453), train_loss = 1.14260747, grad/param norm = 1.6916e-01, time/batch = 0.6457s	
3627/33250 (epoch 5.454), train_loss = 1.45055031, grad/param norm = 2.0396e-01, time/batch = 0.6484s	
3628/33250 (epoch 5.456), train_loss = 1.47137081, grad/param norm = 2.0588e-01, time/batch = 0.6712s	
3629/33250 (epoch 5.457), train_loss = 1.27870473, grad/param norm = 1.7937e-01, time/batch = 0.6748s	
3630/33250 (epoch 5.459), train_loss = 1.31552635, grad/param norm = 1.6069e-01, time/batch = 0.6715s	
3631/33250 (epoch 5.460), train_loss = 1.39061782, grad/param norm = 1.9691e-01, time/batch = 0.6762s	
3632/33250 (epoch 5.462), train_loss = 1.23351110, grad/param norm = 1.6615e-01, time/batch = 0.6627s	
3633/33250 (epoch 5.463), train_loss = 1.15490856, grad/param norm = 1.4911e-01, time/batch = 0.6539s	
3634/33250 (epoch 5.465), train_loss = 1.05294662, grad/param norm = 1.4751e-01, time/batch = 0.6526s	
3635/33250 (epoch 5.466), train_loss = 1.02327018, grad/param norm = 1.3870e-01, time/batch = 0.6675s	
3636/33250 (epoch 5.468), train_loss = 1.13966129, grad/param norm = 1.5562e-01, time/batch = 0.6596s	
3637/33250 (epoch 5.469), train_loss = 1.37634244, grad/param norm = 1.9737e-01, time/batch = 0.6557s	
3638/33250 (epoch 5.471), train_loss = 1.43761530, grad/param norm = 1.9421e-01, time/batch = 0.6464s	
3639/33250 (epoch 5.472), train_loss = 1.35072340, grad/param norm = 2.1856e-01, time/batch = 0.6428s	
3640/33250 (epoch 5.474), train_loss = 1.59867675, grad/param norm = 2.3565e-01, time/batch = 0.6431s	
3641/33250 (epoch 5.475), train_loss = 1.32406018, grad/param norm = 1.8095e-01, time/batch = 0.6566s	
3642/33250 (epoch 5.477), train_loss = 1.30652087, grad/param norm = 1.8060e-01, time/batch = 0.6432s	
3643/33250 (epoch 5.478), train_loss = 1.27204306, grad/param norm = 1.8075e-01, time/batch = 0.6454s	
3644/33250 (epoch 5.480), train_loss = 1.52054895, grad/param norm = 1.8952e-01, time/batch = 0.6455s	
3645/33250 (epoch 5.481), train_loss = 1.27421085, grad/param norm = 2.0537e-01, time/batch = 0.6443s	
3646/33250 (epoch 5.483), train_loss = 1.34413495, grad/param norm = 1.8062e-01, time/batch = 0.6609s	
3647/33250 (epoch 5.484), train_loss = 1.20955185, grad/param norm = 1.6603e-01, time/batch = 0.6630s	
3648/33250 (epoch 5.486), train_loss = 1.11503886, grad/param norm = 1.6886e-01, time/batch = 0.6468s	
3649/33250 (epoch 5.487), train_loss = 1.24942302, grad/param norm = 1.8296e-01, time/batch = 0.6431s	
3650/33250 (epoch 5.489), train_loss = 1.46984585, grad/param norm = 1.9767e-01, time/batch = 0.6610s	
3651/33250 (epoch 5.490), train_loss = 1.37703966, grad/param norm = 1.9901e-01, time/batch = 0.6729s	
3652/33250 (epoch 5.492), train_loss = 1.35959223, grad/param norm = 1.8255e-01, time/batch = 0.6706s	
3653/33250 (epoch 5.493), train_loss = 1.33303408, grad/param norm = 1.7970e-01, time/batch = 0.6598s	
3654/33250 (epoch 5.495), train_loss = 1.32027915, grad/param norm = 1.7624e-01, time/batch = 0.6503s	
3655/33250 (epoch 5.496), train_loss = 1.23469098, grad/param norm = 1.5453e-01, time/batch = 0.6501s	
3656/33250 (epoch 5.498), train_loss = 1.38837936, grad/param norm = 1.7955e-01, time/batch = 0.6490s	
3657/33250 (epoch 5.499), train_loss = 1.28782170, grad/param norm = 1.8407e-01, time/batch = 0.6525s	
3658/33250 (epoch 5.501), train_loss = 1.24483012, grad/param norm = 1.9023e-01, time/batch = 0.6475s	
3659/33250 (epoch 5.502), train_loss = 1.28664464, grad/param norm = 1.7318e-01, time/batch = 0.6457s	
3660/33250 (epoch 5.504), train_loss = 1.51988321, grad/param norm = 2.1566e-01, time/batch = 0.6480s	
3661/33250 (epoch 5.505), train_loss = 1.05379041, grad/param norm = 1.4696e-01, time/batch = 0.6489s	
3662/33250 (epoch 5.507), train_loss = 1.33518779, grad/param norm = 1.7730e-01, time/batch = 0.6462s	
3663/33250 (epoch 5.508), train_loss = 1.25274888, grad/param norm = 1.6558e-01, time/batch = 0.6493s	
3664/33250 (epoch 5.510), train_loss = 1.13930877, grad/param norm = 1.6914e-01, time/batch = 0.6715s	
3665/33250 (epoch 5.511), train_loss = 1.33190939, grad/param norm = 1.8141e-01, time/batch = 0.6567s	
3666/33250 (epoch 5.513), train_loss = 1.53830197, grad/param norm = 1.9356e-01, time/batch = 0.6463s	
3667/33250 (epoch 5.514), train_loss = 1.24367833, grad/param norm = 1.6421e-01, time/batch = 0.6623s	
3668/33250 (epoch 5.516), train_loss = 1.25744772, grad/param norm = 1.8487e-01, time/batch = 0.6539s	
3669/33250 (epoch 5.517), train_loss = 1.31857712, grad/param norm = 1.6971e-01, time/batch = 0.6636s	
3670/33250 (epoch 5.519), train_loss = 1.14413192, grad/param norm = 1.5752e-01, time/batch = 0.6662s	
3671/33250 (epoch 5.520), train_loss = 1.64315173, grad/param norm = 2.2049e-01, time/batch = 0.6693s	
3672/33250 (epoch 5.522), train_loss = 1.42914134, grad/param norm = 1.8687e-01, time/batch = 0.6692s	
3673/33250 (epoch 5.523), train_loss = 1.29152776, grad/param norm = 1.9117e-01, time/batch = 0.6620s	
3674/33250 (epoch 5.525), train_loss = 1.14506452, grad/param norm = 1.7157e-01, time/batch = 0.6653s	
3675/33250 (epoch 5.526), train_loss = 1.17107781, grad/param norm = 1.7646e-01, time/batch = 0.6650s	
3676/33250 (epoch 5.528), train_loss = 1.27477122, grad/param norm = 1.7697e-01, time/batch = 0.6581s	
3677/33250 (epoch 5.529), train_loss = 1.21594742, grad/param norm = 1.6114e-01, time/batch = 0.6592s	
3678/33250 (epoch 5.531), train_loss = 1.11550893, grad/param norm = 1.7379e-01, time/batch = 0.6508s	
3679/33250 (epoch 5.532), train_loss = 1.41699462, grad/param norm = 1.7788e-01, time/batch = 0.6486s	
3680/33250 (epoch 5.534), train_loss = 1.25252688, grad/param norm = 1.6671e-01, time/batch = 0.6459s	
3681/33250 (epoch 5.535), train_loss = 1.29865181, grad/param norm = 1.7952e-01, time/batch = 0.6452s	
3682/33250 (epoch 5.537), train_loss = 1.41863449, grad/param norm = 1.7822e-01, time/batch = 0.6482s	
3683/33250 (epoch 5.538), train_loss = 1.40069622, grad/param norm = 1.8208e-01, time/batch = 0.6467s	
3684/33250 (epoch 5.540), train_loss = 1.44803720, grad/param norm = 1.6857e-01, time/batch = 0.6474s	
3685/33250 (epoch 5.541), train_loss = 1.45909392, grad/param norm = 2.0089e-01, time/batch = 0.6502s	
3686/33250 (epoch 5.543), train_loss = 1.43866184, grad/param norm = 1.9217e-01, time/batch = 0.6464s	
3687/33250 (epoch 5.544), train_loss = 1.29255009, grad/param norm = 1.8338e-01, time/batch = 0.6463s	
3688/33250 (epoch 5.546), train_loss = 1.30392582, grad/param norm = 1.8652e-01, time/batch = 0.6603s	
3689/33250 (epoch 5.547), train_loss = 1.21615633, grad/param norm = 1.7505e-01, time/batch = 0.6493s	
3690/33250 (epoch 5.549), train_loss = 1.33487061, grad/param norm = 1.7650e-01, time/batch = 0.6527s	
3691/33250 (epoch 5.550), train_loss = 1.25080554, grad/param norm = 1.7240e-01, time/batch = 0.6513s	
3692/33250 (epoch 5.552), train_loss = 1.36841764, grad/param norm = 1.9436e-01, time/batch = 0.6539s	
3693/33250 (epoch 5.553), train_loss = 1.22895352, grad/param norm = 1.7981e-01, time/batch = 0.6535s	
3694/33250 (epoch 5.555), train_loss = 1.30483656, grad/param norm = 1.7222e-01, time/batch = 0.6500s	
3695/33250 (epoch 5.556), train_loss = 1.50561890, grad/param norm = 2.0887e-01, time/batch = 0.6537s	
3696/33250 (epoch 5.558), train_loss = 1.40650267, grad/param norm = 1.8267e-01, time/batch = 0.6745s	
3697/33250 (epoch 5.559), train_loss = 1.15638757, grad/param norm = 1.7843e-01, time/batch = 0.6659s	
3698/33250 (epoch 5.561), train_loss = 1.27754303, grad/param norm = 1.7409e-01, time/batch = 0.6702s	
3699/33250 (epoch 5.562), train_loss = 1.48950031, grad/param norm = 1.9569e-01, time/batch = 0.6669s	
3700/33250 (epoch 5.564), train_loss = 1.57344016, grad/param norm = 2.1855e-01, time/batch = 0.6667s	
3701/33250 (epoch 5.565), train_loss = 1.51612848, grad/param norm = 1.8964e-01, time/batch = 0.6684s	
3702/33250 (epoch 5.567), train_loss = 1.41443256, grad/param norm = 1.9509e-01, time/batch = 0.6662s	
3703/33250 (epoch 5.568), train_loss = 1.28638180, grad/param norm = 1.8530e-01, time/batch = 0.6697s	
3704/33250 (epoch 5.570), train_loss = 1.45846469, grad/param norm = 1.9178e-01, time/batch = 0.6642s	
3705/33250 (epoch 5.571), train_loss = 1.54028810, grad/param norm = 1.8445e-01, time/batch = 0.6754s	
3706/33250 (epoch 5.573), train_loss = 1.41164837, grad/param norm = 1.7494e-01, time/batch = 0.6786s	
3707/33250 (epoch 5.574), train_loss = 1.17807262, grad/param norm = 1.6424e-01, time/batch = 0.6784s	
3708/33250 (epoch 5.576), train_loss = 1.33497696, grad/param norm = 1.6285e-01, time/batch = 0.6887s	
3709/33250 (epoch 5.577), train_loss = 1.28901853, grad/param norm = 1.6604e-01, time/batch = 0.6901s	
3710/33250 (epoch 5.579), train_loss = 1.17741610, grad/param norm = 1.6694e-01, time/batch = 0.6913s	
3711/33250 (epoch 5.580), train_loss = 1.16953921, grad/param norm = 1.5428e-01, time/batch = 0.6941s	
3712/33250 (epoch 5.582), train_loss = 1.27085660, grad/param norm = 1.6953e-01, time/batch = 0.6939s	
3713/33250 (epoch 5.583), train_loss = 1.29882973, grad/param norm = 1.5237e-01, time/batch = 0.6812s	
3714/33250 (epoch 5.585), train_loss = 1.39762757, grad/param norm = 1.9071e-01, time/batch = 0.6838s	
3715/33250 (epoch 5.586), train_loss = 1.25123608, grad/param norm = 2.0922e-01, time/batch = 0.6917s	
3716/33250 (epoch 5.588), train_loss = 1.30695732, grad/param norm = 1.7714e-01, time/batch = 0.6851s	
3717/33250 (epoch 5.589), train_loss = 1.39013596, grad/param norm = 1.8187e-01, time/batch = 0.6749s	
3718/33250 (epoch 5.591), train_loss = 1.42649017, grad/param norm = 1.9797e-01, time/batch = 0.6812s	
3719/33250 (epoch 5.592), train_loss = 1.31435445, grad/param norm = 1.6732e-01, time/batch = 0.6879s	
3720/33250 (epoch 5.594), train_loss = 1.52957540, grad/param norm = 1.9572e-01, time/batch = 0.6887s	
3721/33250 (epoch 5.595), train_loss = 1.47879847, grad/param norm = 1.9252e-01, time/batch = 0.6866s	
3722/33250 (epoch 5.597), train_loss = 1.19627678, grad/param norm = 1.5525e-01, time/batch = 0.6688s	
3723/33250 (epoch 5.598), train_loss = 1.40092218, grad/param norm = 1.8252e-01, time/batch = 0.6729s	
3724/33250 (epoch 5.600), train_loss = 1.32773726, grad/param norm = 1.9311e-01, time/batch = 0.6619s	
3725/33250 (epoch 5.602), train_loss = 1.39171434, grad/param norm = 1.9774e-01, time/batch = 0.6748s	
3726/33250 (epoch 5.603), train_loss = 1.33618216, grad/param norm = 1.8845e-01, time/batch = 0.6874s	
3727/33250 (epoch 5.605), train_loss = 1.32864860, grad/param norm = 1.7362e-01, time/batch = 0.6711s	
3728/33250 (epoch 5.606), train_loss = 1.39676615, grad/param norm = 1.8441e-01, time/batch = 0.6717s	
3729/33250 (epoch 5.608), train_loss = 1.30523300, grad/param norm = 1.7442e-01, time/batch = 0.6804s	
3730/33250 (epoch 5.609), train_loss = 1.23755440, grad/param norm = 1.8635e-01, time/batch = 0.6858s	
3731/33250 (epoch 5.611), train_loss = 1.42851730, grad/param norm = 1.8731e-01, time/batch = 0.6789s	
3732/33250 (epoch 5.612), train_loss = 1.37590259, grad/param norm = 1.8028e-01, time/batch = 0.6671s	
3733/33250 (epoch 5.614), train_loss = 1.63174137, grad/param norm = 2.0478e-01, time/batch = 0.6625s	
3734/33250 (epoch 5.615), train_loss = 1.45302268, grad/param norm = 1.8402e-01, time/batch = 0.6684s	
3735/33250 (epoch 5.617), train_loss = 1.75776180, grad/param norm = 1.9684e-01, time/batch = 0.6630s	
3736/33250 (epoch 5.618), train_loss = 1.68961130, grad/param norm = 2.3283e-01, time/batch = 0.6828s	
3737/33250 (epoch 5.620), train_loss = 1.50004882, grad/param norm = 1.9884e-01, time/batch = 0.6829s	
3738/33250 (epoch 5.621), train_loss = 1.28132570, grad/param norm = 1.6504e-01, time/batch = 0.6877s	
3739/33250 (epoch 5.623), train_loss = 1.25836371, grad/param norm = 1.8802e-01, time/batch = 0.6672s	
3740/33250 (epoch 5.624), train_loss = 1.32033904, grad/param norm = 1.8253e-01, time/batch = 0.6666s	
3741/33250 (epoch 5.626), train_loss = 1.36047131, grad/param norm = 1.8908e-01, time/batch = 0.6631s	
3742/33250 (epoch 5.627), train_loss = 1.28144606, grad/param norm = 1.6803e-01, time/batch = 0.6666s	
3743/33250 (epoch 5.629), train_loss = 1.32341606, grad/param norm = 2.0818e-01, time/batch = 0.6666s	
3744/33250 (epoch 5.630), train_loss = 1.30453810, grad/param norm = 1.7165e-01, time/batch = 0.6652s	
3745/33250 (epoch 5.632), train_loss = 1.11847226, grad/param norm = 1.6013e-01, time/batch = 0.6686s	
3746/33250 (epoch 5.633), train_loss = 1.41485674, grad/param norm = 1.8939e-01, time/batch = 0.6720s	
3747/33250 (epoch 5.635), train_loss = 1.19493923, grad/param norm = 1.6032e-01, time/batch = 0.6807s	
3748/33250 (epoch 5.636), train_loss = 1.21708906, grad/param norm = 1.6553e-01, time/batch = 0.6676s	
3749/33250 (epoch 5.638), train_loss = 1.27427064, grad/param norm = 1.8348e-01, time/batch = 0.6656s	
3750/33250 (epoch 5.639), train_loss = 1.22519415, grad/param norm = 1.8833e-01, time/batch = 0.6596s	
3751/33250 (epoch 5.641), train_loss = 1.19520333, grad/param norm = 1.6415e-01, time/batch = 0.6670s	
3752/33250 (epoch 5.642), train_loss = 1.18141139, grad/param norm = 1.6216e-01, time/batch = 0.6647s	
3753/33250 (epoch 5.644), train_loss = 1.05086665, grad/param norm = 1.5368e-01, time/batch = 0.6626s	
3754/33250 (epoch 5.645), train_loss = 1.46994442, grad/param norm = 1.9729e-01, time/batch = 0.6656s	
3755/33250 (epoch 5.647), train_loss = 1.15974831, grad/param norm = 1.5847e-01, time/batch = 0.6660s	
3756/33250 (epoch 5.648), train_loss = 1.27370798, grad/param norm = 1.8459e-01, time/batch = 0.6661s	
3757/33250 (epoch 5.650), train_loss = 1.49899168, grad/param norm = 2.0725e-01, time/batch = 0.6851s	
3758/33250 (epoch 5.651), train_loss = 1.33496811, grad/param norm = 1.9593e-01, time/batch = 0.6793s	
3759/33250 (epoch 5.653), train_loss = 1.16991944, grad/param norm = 1.5873e-01, time/batch = 0.6691s	
3760/33250 (epoch 5.654), train_loss = 1.20476942, grad/param norm = 1.7076e-01, time/batch = 0.6894s	
3761/33250 (epoch 5.656), train_loss = 1.34738207, grad/param norm = 1.7407e-01, time/batch = 0.6617s	
3762/33250 (epoch 5.657), train_loss = 1.08338035, grad/param norm = 1.7831e-01, time/batch = 0.6737s	
3763/33250 (epoch 5.659), train_loss = 1.25756833, grad/param norm = 1.8103e-01, time/batch = 0.6693s	
3764/33250 (epoch 5.660), train_loss = 1.22840807, grad/param norm = 1.9460e-01, time/batch = 0.6687s	
3765/33250 (epoch 5.662), train_loss = 1.34446832, grad/param norm = 1.8167e-01, time/batch = 0.6651s	
3766/33250 (epoch 5.663), train_loss = 1.25164623, grad/param norm = 1.7623e-01, time/batch = 0.6703s	
3767/33250 (epoch 5.665), train_loss = 1.42975572, grad/param norm = 1.8663e-01, time/batch = 0.6703s	
3768/33250 (epoch 5.666), train_loss = 1.27201539, grad/param norm = 1.9217e-01, time/batch = 0.6621s	
3769/33250 (epoch 5.668), train_loss = 1.43990302, grad/param norm = 1.7843e-01, time/batch = 0.6646s	
3770/33250 (epoch 5.669), train_loss = 1.39050954, grad/param norm = 1.8644e-01, time/batch = 0.6742s	
3771/33250 (epoch 5.671), train_loss = 1.34152834, grad/param norm = 1.9255e-01, time/batch = 0.6677s	
3772/33250 (epoch 5.672), train_loss = 1.45397578, grad/param norm = 2.0089e-01, time/batch = 0.6630s	
3773/33250 (epoch 5.674), train_loss = 1.28619035, grad/param norm = 1.5786e-01, time/batch = 0.6667s	
3774/33250 (epoch 5.675), train_loss = 1.34915919, grad/param norm = 1.8264e-01, time/batch = 0.6683s	
3775/33250 (epoch 5.677), train_loss = 1.35928735, grad/param norm = 1.7263e-01, time/batch = 0.6657s	
3776/33250 (epoch 5.678), train_loss = 1.38109644, grad/param norm = 1.8657e-01, time/batch = 0.6851s	
3777/33250 (epoch 5.680), train_loss = 1.42430743, grad/param norm = 1.7907e-01, time/batch = 0.6865s	
3778/33250 (epoch 5.681), train_loss = 1.13025889, grad/param norm = 1.6296e-01, time/batch = 0.6830s	
3779/33250 (epoch 5.683), train_loss = 1.24073687, grad/param norm = 1.8648e-01, time/batch = 0.6843s	
3780/33250 (epoch 5.684), train_loss = 1.26043839, grad/param norm = 1.8848e-01, time/batch = 0.6836s	
3781/33250 (epoch 5.686), train_loss = 1.19878265, grad/param norm = 1.7197e-01, time/batch = 0.6847s	
3782/33250 (epoch 5.687), train_loss = 1.23089753, grad/param norm = 1.6815e-01, time/batch = 0.6873s	
3783/33250 (epoch 5.689), train_loss = 1.24407200, grad/param norm = 1.7711e-01, time/batch = 0.6743s	
3784/33250 (epoch 5.690), train_loss = 1.38884305, grad/param norm = 1.9617e-01, time/batch = 0.6665s	
3785/33250 (epoch 5.692), train_loss = 1.38637621, grad/param norm = 2.0345e-01, time/batch = 0.6652s	
3786/33250 (epoch 5.693), train_loss = 1.29467114, grad/param norm = 1.6578e-01, time/batch = 0.6653s	
3787/33250 (epoch 5.695), train_loss = 1.36100823, grad/param norm = 1.7555e-01, time/batch = 0.6667s	
3788/33250 (epoch 5.696), train_loss = 1.28501425, grad/param norm = 1.6599e-01, time/batch = 0.6680s	
3789/33250 (epoch 5.698), train_loss = 1.23345966, grad/param norm = 1.7987e-01, time/batch = 0.6653s	
3790/33250 (epoch 5.699), train_loss = 1.51721699, grad/param norm = 1.8626e-01, time/batch = 0.6664s	
3791/33250 (epoch 5.701), train_loss = 1.22880462, grad/param norm = 1.5993e-01, time/batch = 0.6740s	
3792/33250 (epoch 5.702), train_loss = 1.37437450, grad/param norm = 1.9079e-01, time/batch = 0.6669s	
3793/33250 (epoch 5.704), train_loss = 1.51393943, grad/param norm = 3.1303e-01, time/batch = 0.6664s	
3794/33250 (epoch 5.705), train_loss = 1.17724947, grad/param norm = 1.7437e-01, time/batch = 0.6689s	
3795/33250 (epoch 5.707), train_loss = 1.15910098, grad/param norm = 1.7911e-01, time/batch = 0.6621s	
3796/33250 (epoch 5.708), train_loss = 1.35782279, grad/param norm = 1.8201e-01, time/batch = 0.6866s	
3797/33250 (epoch 5.710), train_loss = 1.41084982, grad/param norm = 1.7799e-01, time/batch = 0.6879s	
3798/33250 (epoch 5.711), train_loss = 1.37802969, grad/param norm = 2.0577e-01, time/batch = 0.6895s	
3799/33250 (epoch 5.713), train_loss = 1.41203012, grad/param norm = 1.8707e-01, time/batch = 0.6849s	
3800/33250 (epoch 5.714), train_loss = 1.35730443, grad/param norm = 2.0334e-01, time/batch = 0.6670s	
3801/33250 (epoch 5.716), train_loss = 1.47964728, grad/param norm = 2.0434e-01, time/batch = 0.6696s	
3802/33250 (epoch 5.717), train_loss = 1.23517384, grad/param norm = 1.6166e-01, time/batch = 0.6631s	
3803/33250 (epoch 5.719), train_loss = 1.33473339, grad/param norm = 1.8354e-01, time/batch = 0.6674s	
3804/33250 (epoch 5.720), train_loss = 1.57535496, grad/param norm = 1.7617e-01, time/batch = 0.6722s	
3805/33250 (epoch 5.722), train_loss = 1.21516623, grad/param norm = 1.6307e-01, time/batch = 0.6727s	
3806/33250 (epoch 5.723), train_loss = 1.08606335, grad/param norm = 1.5885e-01, time/batch = 0.6680s	
3807/33250 (epoch 5.725), train_loss = 1.09017277, grad/param norm = 1.4769e-01, time/batch = 0.6887s	
3808/33250 (epoch 5.726), train_loss = 1.21820236, grad/param norm = 1.6127e-01, time/batch = 0.6938s	
3809/33250 (epoch 5.728), train_loss = 1.37037821, grad/param norm = 1.8162e-01, time/batch = 0.6876s	
3810/33250 (epoch 5.729), train_loss = 1.50168404, grad/param norm = 1.9368e-01, time/batch = 0.6730s	
3811/33250 (epoch 5.731), train_loss = 1.25637274, grad/param norm = 1.7841e-01, time/batch = 0.6707s	
3812/33250 (epoch 5.732), train_loss = 1.19957117, grad/param norm = 1.6704e-01, time/batch = 0.6704s	
3813/33250 (epoch 5.734), train_loss = 1.35069761, grad/param norm = 1.7067e-01, time/batch = 0.6694s	
3814/33250 (epoch 5.735), train_loss = 1.34015261, grad/param norm = 1.8462e-01, time/batch = 0.6786s	
3815/33250 (epoch 5.737), train_loss = 1.37775611, grad/param norm = 1.7139e-01, time/batch = 0.6745s	
3816/33250 (epoch 5.738), train_loss = 1.31317213, grad/param norm = 1.6735e-01, time/batch = 0.6812s	
3817/33250 (epoch 5.740), train_loss = 1.50540064, grad/param norm = 1.8473e-01, time/batch = 0.6829s	
3818/33250 (epoch 5.741), train_loss = 1.37169523, grad/param norm = 1.7824e-01, time/batch = 0.6854s	
3819/33250 (epoch 5.743), train_loss = 1.28275000, grad/param norm = 1.7170e-01, time/batch = 0.6876s	
3820/33250 (epoch 5.744), train_loss = 1.29931274, grad/param norm = 1.7049e-01, time/batch = 0.6766s	
3821/33250 (epoch 5.746), train_loss = 1.33453037, grad/param norm = 1.5713e-01, time/batch = 0.6699s	
3822/33250 (epoch 5.747), train_loss = 1.27027320, grad/param norm = 1.7999e-01, time/batch = 0.6691s	
3823/33250 (epoch 5.749), train_loss = 1.51576792, grad/param norm = 1.9411e-01, time/batch = 0.6744s	
3824/33250 (epoch 5.750), train_loss = 1.33125412, grad/param norm = 1.7952e-01, time/batch = 0.6717s	
3825/33250 (epoch 5.752), train_loss = 1.18131471, grad/param norm = 1.6765e-01, time/batch = 0.6685s	
3826/33250 (epoch 5.753), train_loss = 1.29017872, grad/param norm = 1.6667e-01, time/batch = 0.6697s	
3827/33250 (epoch 5.755), train_loss = 1.22873336, grad/param norm = 1.7775e-01, time/batch = 0.6641s	
3828/33250 (epoch 5.756), train_loss = 1.41728847, grad/param norm = 1.9134e-01, time/batch = 0.6704s	
3829/33250 (epoch 5.758), train_loss = 1.41404306, grad/param norm = 1.8493e-01, time/batch = 0.6644s	
3830/33250 (epoch 5.759), train_loss = 1.18131687, grad/param norm = 1.5579e-01, time/batch = 0.6631s	
3831/33250 (epoch 5.761), train_loss = 1.24683389, grad/param norm = 1.8356e-01, time/batch = 0.6668s	
3832/33250 (epoch 5.762), train_loss = 1.36648674, grad/param norm = 1.7690e-01, time/batch = 0.6688s	
3833/33250 (epoch 5.764), train_loss = 1.24670140, grad/param norm = 2.2171e-01, time/batch = 0.6668s	
3834/33250 (epoch 5.765), train_loss = 1.33789947, grad/param norm = 1.8384e-01, time/batch = 0.6677s	
3835/33250 (epoch 5.767), train_loss = 1.10539707, grad/param norm = 1.7154e-01, time/batch = 0.6655s	
3836/33250 (epoch 5.768), train_loss = 1.18134747, grad/param norm = 1.7439e-01, time/batch = 0.6665s	
3837/33250 (epoch 5.770), train_loss = 1.37889674, grad/param norm = 2.0830e-01, time/batch = 0.6683s	
3838/33250 (epoch 5.771), train_loss = 1.38555854, grad/param norm = 1.8898e-01, time/batch = 0.6691s	
3839/33250 (epoch 5.773), train_loss = 1.29239747, grad/param norm = 1.8560e-01, time/batch = 0.6600s	
3840/33250 (epoch 5.774), train_loss = 1.11397945, grad/param norm = 1.7151e-01, time/batch = 0.6689s	
3841/33250 (epoch 5.776), train_loss = 1.24878871, grad/param norm = 1.7404e-01, time/batch = 0.6690s	
3842/33250 (epoch 5.777), train_loss = 1.43446429, grad/param norm = 2.2182e-01, time/batch = 0.6642s	
3843/33250 (epoch 5.779), train_loss = 1.20076426, grad/param norm = 1.6722e-01, time/batch = 0.6664s	
3844/33250 (epoch 5.780), train_loss = 1.54046290, grad/param norm = 2.0454e-01, time/batch = 0.6664s	
3845/33250 (epoch 5.782), train_loss = 1.34168769, grad/param norm = 1.7517e-01, time/batch = 0.6723s	
3846/33250 (epoch 5.783), train_loss = 1.08546634, grad/param norm = 1.5928e-01, time/batch = 0.6905s	
3847/33250 (epoch 5.785), train_loss = 1.19035047, grad/param norm = 1.7835e-01, time/batch = 0.6761s	
3848/33250 (epoch 5.786), train_loss = 1.41364359, grad/param norm = 1.7957e-01, time/batch = 0.6744s	
3849/33250 (epoch 5.788), train_loss = 1.32649265, grad/param norm = 1.7615e-01, time/batch = 0.6755s	
3850/33250 (epoch 5.789), train_loss = 1.41365773, grad/param norm = 1.8560e-01, time/batch = 0.6790s	
3851/33250 (epoch 5.791), train_loss = 1.45691632, grad/param norm = 1.7934e-01, time/batch = 0.6707s	
3852/33250 (epoch 5.792), train_loss = 1.51622327, grad/param norm = 1.7505e-01, time/batch = 0.6648s	
3853/33250 (epoch 5.794), train_loss = 1.26242579, grad/param norm = 1.9673e-01, time/batch = 0.6667s	
3854/33250 (epoch 5.795), train_loss = 1.36724050, grad/param norm = 1.7952e-01, time/batch = 0.6671s	
3855/33250 (epoch 5.797), train_loss = 1.46049352, grad/param norm = 2.0116e-01, time/batch = 0.6655s	
3856/33250 (epoch 5.798), train_loss = 1.39345900, grad/param norm = 2.2630e-01, time/batch = 0.6733s	
3857/33250 (epoch 5.800), train_loss = 1.43031029, grad/param norm = 1.9827e-01, time/batch = 0.6637s	
3858/33250 (epoch 5.802), train_loss = 1.26407765, grad/param norm = 1.7811e-01, time/batch = 0.6639s	
3859/33250 (epoch 5.803), train_loss = 1.26406630, grad/param norm = 1.7222e-01, time/batch = 0.6743s	
3860/33250 (epoch 5.805), train_loss = 1.36803427, grad/param norm = 1.9144e-01, time/batch = 0.6666s	
3861/33250 (epoch 5.806), train_loss = 1.39695672, grad/param norm = 1.8222e-01, time/batch = 0.6703s	
3862/33250 (epoch 5.808), train_loss = 1.32211246, grad/param norm = 1.8892e-01, time/batch = 0.6810s	
3863/33250 (epoch 5.809), train_loss = 1.18401894, grad/param norm = 1.7619e-01, time/batch = 0.6930s	
3864/33250 (epoch 5.811), train_loss = 1.22142916, grad/param norm = 1.8144e-01, time/batch = 0.6832s	
3865/33250 (epoch 5.812), train_loss = 1.35367543, grad/param norm = 1.8036e-01, time/batch = 0.6803s	
3866/33250 (epoch 5.814), train_loss = 1.29689689, grad/param norm = 1.7716e-01, time/batch = 0.6701s	
3867/33250 (epoch 5.815), train_loss = 1.36704614, grad/param norm = 1.9206e-01, time/batch = 0.6674s	
3868/33250 (epoch 5.817), train_loss = 1.30148179, grad/param norm = 1.8034e-01, time/batch = 0.6688s	
3869/33250 (epoch 5.818), train_loss = 1.20140988, grad/param norm = 1.7705e-01, time/batch = 0.6644s	
3870/33250 (epoch 5.820), train_loss = 1.34203899, grad/param norm = 1.9228e-01, time/batch = 0.6615s	
3871/33250 (epoch 5.821), train_loss = 1.22101971, grad/param norm = 1.8317e-01, time/batch = 0.6707s	
3872/33250 (epoch 5.823), train_loss = 1.60780522, grad/param norm = 2.2143e-01, time/batch = 0.6622s	
3873/33250 (epoch 5.824), train_loss = 1.32017713, grad/param norm = 1.7554e-01, time/batch = 0.6613s	
3874/33250 (epoch 5.826), train_loss = 1.30738754, grad/param norm = 1.8207e-01, time/batch = 0.6639s	
3875/33250 (epoch 5.827), train_loss = 1.08228654, grad/param norm = 1.5727e-01, time/batch = 0.6632s	
3876/33250 (epoch 5.829), train_loss = 1.30475059, grad/param norm = 1.8816e-01, time/batch = 0.6634s	
3877/33250 (epoch 5.830), train_loss = 1.51470566, grad/param norm = 2.0942e-01, time/batch = 0.6652s	
3878/33250 (epoch 5.832), train_loss = 1.26551550, grad/param norm = 1.6522e-01, time/batch = 0.6646s	
3879/33250 (epoch 5.833), train_loss = 1.35853863, grad/param norm = 1.7469e-01, time/batch = 0.6604s	
3880/33250 (epoch 5.835), train_loss = 1.30058418, grad/param norm = 2.0062e-01, time/batch = 0.6644s	
3881/33250 (epoch 5.836), train_loss = 1.31816921, grad/param norm = 1.6182e-01, time/batch = 0.6714s	
3882/33250 (epoch 5.838), train_loss = 1.24282599, grad/param norm = 1.6678e-01, time/batch = 0.6622s	
3883/33250 (epoch 5.839), train_loss = 1.27770300, grad/param norm = 1.8051e-01, time/batch = 0.6633s	
3884/33250 (epoch 5.841), train_loss = 1.10547463, grad/param norm = 1.4813e-01, time/batch = 0.6624s	
3885/33250 (epoch 5.842), train_loss = 1.43048270, grad/param norm = 1.7406e-01, time/batch = 0.6657s	
3886/33250 (epoch 5.844), train_loss = 1.44749384, grad/param norm = 1.8777e-01, time/batch = 0.6667s	
3887/33250 (epoch 5.845), train_loss = 1.60658233, grad/param norm = 2.2445e-01, time/batch = 0.6702s	
3888/33250 (epoch 5.847), train_loss = 1.51334936, grad/param norm = 1.8860e-01, time/batch = 0.6642s	
3889/33250 (epoch 5.848), train_loss = 1.61921740, grad/param norm = 2.1522e-01, time/batch = 0.6631s	
3890/33250 (epoch 5.850), train_loss = 1.40508169, grad/param norm = 1.8696e-01, time/batch = 0.6617s	
3891/33250 (epoch 5.851), train_loss = 1.25956681, grad/param norm = 1.7754e-01, time/batch = 0.6629s	
3892/33250 (epoch 5.853), train_loss = 1.37694354, grad/param norm = 2.1592e-01, time/batch = 0.6695s	
3893/33250 (epoch 5.854), train_loss = 1.18273166, grad/param norm = 1.6144e-01, time/batch = 0.6666s	
3894/33250 (epoch 5.856), train_loss = 1.20177179, grad/param norm = 4.5644e-01, time/batch = 0.6636s	
3895/33250 (epoch 5.857), train_loss = 1.13610352, grad/param norm = 1.9926e-01, time/batch = 0.6639s	
3896/33250 (epoch 5.859), train_loss = 1.11304880, grad/param norm = 1.7152e-01, time/batch = 0.6823s	
3897/33250 (epoch 5.860), train_loss = 1.28078399, grad/param norm = 1.5244e-01, time/batch = 0.6916s	
3898/33250 (epoch 5.862), train_loss = 1.16613714, grad/param norm = 1.5843e-01, time/batch = 0.6986s	
3899/33250 (epoch 5.863), train_loss = 1.18844336, grad/param norm = 1.6381e-01, time/batch = 0.6799s	
3900/33250 (epoch 5.865), train_loss = 1.35057359, grad/param norm = 1.8051e-01, time/batch = 0.6799s	
3901/33250 (epoch 5.866), train_loss = 1.22494705, grad/param norm = 1.8772e-01, time/batch = 0.6806s	
3902/33250 (epoch 5.868), train_loss = 1.61052085, grad/param norm = 2.3917e-01, time/batch = 0.6812s	
3903/33250 (epoch 5.869), train_loss = 1.36830995, grad/param norm = 1.9190e-01, time/batch = 0.6669s	
3904/33250 (epoch 5.871), train_loss = 1.07949254, grad/param norm = 1.6537e-01, time/batch = 0.6708s	
3905/33250 (epoch 5.872), train_loss = 1.36238365, grad/param norm = 1.7492e-01, time/batch = 0.6824s	
3906/33250 (epoch 5.874), train_loss = 1.24016787, grad/param norm = 1.7569e-01, time/batch = 0.6974s	
3907/33250 (epoch 5.875), train_loss = 1.24404756, grad/param norm = 1.9440e-01, time/batch = 0.6970s	
3908/33250 (epoch 5.877), train_loss = 1.35986249, grad/param norm = 1.9416e-01, time/batch = 0.6938s	
3909/33250 (epoch 5.878), train_loss = 1.31118883, grad/param norm = 1.7326e-01, time/batch = 0.6877s	
3910/33250 (epoch 5.880), train_loss = 1.33799546, grad/param norm = 1.9027e-01, time/batch = 0.6874s	
3911/33250 (epoch 5.881), train_loss = 1.52500324, grad/param norm = 1.8201e-01, time/batch = 0.6803s	
3912/33250 (epoch 5.883), train_loss = 1.33887220, grad/param norm = 1.8328e-01, time/batch = 0.6667s	
3913/33250 (epoch 5.884), train_loss = 1.30858238, grad/param norm = 1.9959e-01, time/batch = 0.6750s	
3914/33250 (epoch 5.886), train_loss = 1.17972661, grad/param norm = 1.5403e-01, time/batch = 0.6903s	
3915/33250 (epoch 5.887), train_loss = 1.26764358, grad/param norm = 1.7004e-01, time/batch = 0.6719s	
3916/33250 (epoch 5.889), train_loss = 1.21715799, grad/param norm = 1.4272e-01, time/batch = 0.6668s	
3917/33250 (epoch 5.890), train_loss = 1.11430321, grad/param norm = 1.5096e-01, time/batch = 0.6648s	
3918/33250 (epoch 5.892), train_loss = 1.39632855, grad/param norm = 1.7362e-01, time/batch = 0.6648s	
3919/33250 (epoch 5.893), train_loss = 1.40080625, grad/param norm = 1.7680e-01, time/batch = 0.6659s	
3920/33250 (epoch 5.895), train_loss = 1.24741577, grad/param norm = 1.7023e-01, time/batch = 0.6672s	
3921/33250 (epoch 5.896), train_loss = 1.36757277, grad/param norm = 1.8719e-01, time/batch = 0.6700s	
3922/33250 (epoch 5.898), train_loss = 1.21255962, grad/param norm = 1.6888e-01, time/batch = 0.6663s	
3923/33250 (epoch 5.899), train_loss = 1.23918236, grad/param norm = 1.7400e-01, time/batch = 0.6766s	
3924/33250 (epoch 5.901), train_loss = 1.11225100, grad/param norm = 1.5314e-01, time/batch = 0.6887s	
3925/33250 (epoch 5.902), train_loss = 1.25406831, grad/param norm = 1.7978e-01, time/batch = 0.6839s	
3926/33250 (epoch 5.904), train_loss = 1.18593719, grad/param norm = 1.5600e-01, time/batch = 0.6746s	
3927/33250 (epoch 5.905), train_loss = 1.23853004, grad/param norm = 1.7415e-01, time/batch = 0.6874s	
3928/33250 (epoch 5.907), train_loss = 1.23555188, grad/param norm = 1.6898e-01, time/batch = 0.6721s	
3929/33250 (epoch 5.908), train_loss = 1.30739936, grad/param norm = 1.6368e-01, time/batch = 0.6776s	
3930/33250 (epoch 5.910), train_loss = 1.42544323, grad/param norm = 1.9114e-01, time/batch = 0.6905s	
3931/33250 (epoch 5.911), train_loss = 1.06746701, grad/param norm = 1.6134e-01, time/batch = 0.6907s	
3932/33250 (epoch 5.913), train_loss = 1.24460255, grad/param norm = 1.6017e-01, time/batch = 0.6903s	
3933/33250 (epoch 5.914), train_loss = 1.09777977, grad/param norm = 1.6931e-01, time/batch = 0.6754s	
3934/33250 (epoch 5.916), train_loss = 1.18228278, grad/param norm = 1.5251e-01, time/batch = 0.6821s	
3935/33250 (epoch 5.917), train_loss = 1.19856810, grad/param norm = 1.5631e-01, time/batch = 0.6680s	
3936/33250 (epoch 5.919), train_loss = 1.24612866, grad/param norm = 1.7916e-01, time/batch = 0.6984s	
3937/33250 (epoch 5.920), train_loss = 1.31454010, grad/param norm = 1.8371e-01, time/batch = 0.6831s	
3938/33250 (epoch 5.922), train_loss = 1.31379879, grad/param norm = 1.8290e-01, time/batch = 0.6726s	
3939/33250 (epoch 5.923), train_loss = 1.28679030, grad/param norm = 1.8965e-01, time/batch = 0.6727s	
3940/33250 (epoch 5.925), train_loss = 1.24123082, grad/param norm = 1.6447e-01, time/batch = 0.6735s	
3941/33250 (epoch 5.926), train_loss = 1.22982248, grad/param norm = 1.7375e-01, time/batch = 0.6812s	
3942/33250 (epoch 5.928), train_loss = 1.28655514, grad/param norm = 1.7522e-01, time/batch = 0.6835s	
3943/33250 (epoch 5.929), train_loss = 0.99648128, grad/param norm = 1.4468e-01, time/batch = 0.6778s	
3944/33250 (epoch 5.931), train_loss = 1.34657435, grad/param norm = 1.7595e-01, time/batch = 0.6777s	
3945/33250 (epoch 5.932), train_loss = 1.37588907, grad/param norm = 1.9129e-01, time/batch = 0.6775s	
3946/33250 (epoch 5.934), train_loss = 1.21367595, grad/param norm = 1.6334e-01, time/batch = 0.6761s	
3947/33250 (epoch 5.935), train_loss = 1.30813038, grad/param norm = 1.9106e-01, time/batch = 0.6731s	
3948/33250 (epoch 5.937), train_loss = 1.32719892, grad/param norm = 1.8712e-01, time/batch = 0.6729s	
3949/33250 (epoch 5.938), train_loss = 1.39858731, grad/param norm = 1.7880e-01, time/batch = 0.6720s	
3950/33250 (epoch 5.940), train_loss = 1.25299407, grad/param norm = 1.7444e-01, time/batch = 0.6714s	
3951/33250 (epoch 5.941), train_loss = 1.30725502, grad/param norm = 1.7140e-01, time/batch = 0.6779s	
3952/33250 (epoch 5.943), train_loss = 1.49096525, grad/param norm = 1.8010e-01, time/batch = 0.6873s	
3953/33250 (epoch 5.944), train_loss = 1.15564336, grad/param norm = 1.5459e-01, time/batch = 0.6724s	
3954/33250 (epoch 5.946), train_loss = 1.50135913, grad/param norm = 1.7518e-01, time/batch = 0.6656s	
3955/33250 (epoch 5.947), train_loss = 1.25837349, grad/param norm = 1.7492e-01, time/batch = 0.6668s	
3956/33250 (epoch 5.949), train_loss = 1.42188787, grad/param norm = 1.7547e-01, time/batch = 0.6694s	
3957/33250 (epoch 5.950), train_loss = 1.29312844, grad/param norm = 1.6400e-01, time/batch = 0.6804s	
3958/33250 (epoch 5.952), train_loss = 1.27773814, grad/param norm = 1.7676e-01, time/batch = 0.6703s	
3959/33250 (epoch 5.953), train_loss = 1.40757874, grad/param norm = 1.9248e-01, time/batch = 0.6703s	
3960/33250 (epoch 5.955), train_loss = 1.37733376, grad/param norm = 1.8146e-01, time/batch = 0.6691s	
3961/33250 (epoch 5.956), train_loss = 1.45749085, grad/param norm = 1.9968e-01, time/batch = 0.6930s	
3962/33250 (epoch 5.958), train_loss = 1.19482772, grad/param norm = 1.6155e-01, time/batch = 0.6811s	
3963/33250 (epoch 5.959), train_loss = 1.16869269, grad/param norm = 1.5107e-01, time/batch = 0.6758s	
3964/33250 (epoch 5.961), train_loss = 1.45583217, grad/param norm = 1.8215e-01, time/batch = 0.6736s	
3965/33250 (epoch 5.962), train_loss = 1.36466601, grad/param norm = 1.8273e-01, time/batch = 0.6753s	
3966/33250 (epoch 5.964), train_loss = 1.46931440, grad/param norm = 1.8062e-01, time/batch = 0.6694s	
3967/33250 (epoch 5.965), train_loss = 1.34826552, grad/param norm = 2.0315e-01, time/batch = 0.6686s	
3968/33250 (epoch 5.967), train_loss = 1.37180538, grad/param norm = 1.7686e-01, time/batch = 0.6785s	
3969/33250 (epoch 5.968), train_loss = 1.52380139, grad/param norm = 1.7358e-01, time/batch = 0.6659s	
3970/33250 (epoch 5.970), train_loss = 1.62706884, grad/param norm = 2.1317e-01, time/batch = 0.6687s	
3971/33250 (epoch 5.971), train_loss = 1.46089745, grad/param norm = 1.9547e-01, time/batch = 0.6717s	
3972/33250 (epoch 5.973), train_loss = 1.25064837, grad/param norm = 1.6583e-01, time/batch = 0.6696s	
3973/33250 (epoch 5.974), train_loss = 1.33260093, grad/param norm = 1.8241e-01, time/batch = 0.6693s	
3974/33250 (epoch 5.976), train_loss = 1.24652157, grad/param norm = 1.8322e-01, time/batch = 0.6705s	
3975/33250 (epoch 5.977), train_loss = 1.22730997, grad/param norm = 1.8070e-01, time/batch = 0.6656s	
3976/33250 (epoch 5.979), train_loss = 1.32924790, grad/param norm = 1.7746e-01, time/batch = 0.6676s	
3977/33250 (epoch 5.980), train_loss = 1.28020924, grad/param norm = 1.6294e-01, time/batch = 0.6659s	
3978/33250 (epoch 5.982), train_loss = 1.08368166, grad/param norm = 1.4315e-01, time/batch = 0.6697s	
3979/33250 (epoch 5.983), train_loss = 1.37789376, grad/param norm = 1.9351e-01, time/batch = 0.6663s	
3980/33250 (epoch 5.985), train_loss = 1.21128791, grad/param norm = 1.8579e-01, time/batch = 0.6684s	
3981/33250 (epoch 5.986), train_loss = 1.43343781, grad/param norm = 1.9367e-01, time/batch = 0.6690s	
3982/33250 (epoch 5.988), train_loss = 1.37049259, grad/param norm = 2.0167e-01, time/batch = 0.6724s	
3983/33250 (epoch 5.989), train_loss = 1.46701417, grad/param norm = 1.9714e-01, time/batch = 0.6693s	
3984/33250 (epoch 5.991), train_loss = 1.30327487, grad/param norm = 1.8211e-01, time/batch = 0.6760s	
3985/33250 (epoch 5.992), train_loss = 1.25721574, grad/param norm = 1.6703e-01, time/batch = 0.6855s	
3986/33250 (epoch 5.994), train_loss = 1.18463976, grad/param norm = 1.7807e-01, time/batch = 0.6916s	
3987/33250 (epoch 5.995), train_loss = 1.34832067, grad/param norm = 2.0965e-01, time/batch = 0.6669s	
3988/33250 (epoch 5.997), train_loss = 0.96972895, grad/param norm = 1.4752e-01, time/batch = 0.6673s	
3989/33250 (epoch 5.998), train_loss = 1.27747022, grad/param norm = 1.5954e-01, time/batch = 0.6683s	
3990/33250 (epoch 6.000), train_loss = 1.30000255, grad/param norm = 1.7199e-01, time/batch = 0.6649s	
3991/33250 (epoch 6.002), train_loss = 1.45154701, grad/param norm = 1.8674e-01, time/batch = 0.6659s	
3992/33250 (epoch 6.003), train_loss = 1.35654774, grad/param norm = 1.7842e-01, time/batch = 0.6682s	
3993/33250 (epoch 6.005), train_loss = 1.10254199, grad/param norm = 1.6728e-01, time/batch = 0.6708s	
3994/33250 (epoch 6.006), train_loss = 1.09351604, grad/param norm = 1.4757e-01, time/batch = 0.6921s	
3995/33250 (epoch 6.008), train_loss = 1.39974403, grad/param norm = 1.8701e-01, time/batch = 0.6935s	
3996/33250 (epoch 6.009), train_loss = 1.43143491, grad/param norm = 1.9173e-01, time/batch = 0.6859s	
3997/33250 (epoch 6.011), train_loss = 1.22447707, grad/param norm = 1.6704e-01, time/batch = 0.6799s	
3998/33250 (epoch 6.012), train_loss = 1.39512661, grad/param norm = 2.0452e-01, time/batch = 0.6625s	
3999/33250 (epoch 6.014), train_loss = 1.41061991, grad/param norm = 1.8048e-01, time/batch = 0.6632s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch6.02_1.4469.t7	
4000/33250 (epoch 6.015), train_loss = 1.28654933, grad/param norm = 1.7896e-01, time/batch = 0.6598s	
4001/33250 (epoch 6.017), train_loss = 1.64393442, grad/param norm = 2.0262e-01, time/batch = 0.6768s	
4002/33250 (epoch 6.018), train_loss = 1.10240707, grad/param norm = 1.8349e-01, time/batch = 0.6801s	
4003/33250 (epoch 6.020), train_loss = 1.22541279, grad/param norm = 1.6189e-01, time/batch = 0.6863s	
4004/33250 (epoch 6.021), train_loss = 1.27124560, grad/param norm = 1.7060e-01, time/batch = 0.6705s	
4005/33250 (epoch 6.023), train_loss = 1.11211615, grad/param norm = 1.7388e-01, time/batch = 0.6678s	
4006/33250 (epoch 6.024), train_loss = 1.38040169, grad/param norm = 1.7694e-01, time/batch = 0.6800s	
4007/33250 (epoch 6.026), train_loss = 1.29070674, grad/param norm = 1.5345e-01, time/batch = 0.6714s	
4008/33250 (epoch 6.027), train_loss = 1.22645763, grad/param norm = 1.6024e-01, time/batch = 0.6728s	
4009/33250 (epoch 6.029), train_loss = 1.30600279, grad/param norm = 1.6781e-01, time/batch = 0.6693s	
4010/33250 (epoch 6.030), train_loss = 1.27123138, grad/param norm = 1.7469e-01, time/batch = 0.6644s	
4011/33250 (epoch 6.032), train_loss = 1.56153141, grad/param norm = 2.1210e-01, time/batch = 0.6607s	
4012/33250 (epoch 6.033), train_loss = 1.25801881, grad/param norm = 1.9261e-01, time/batch = 0.6626s	
4013/33250 (epoch 6.035), train_loss = 1.22786143, grad/param norm = 1.9513e-01, time/batch = 0.6644s	
4014/33250 (epoch 6.036), train_loss = 1.37564376, grad/param norm = 1.9518e-01, time/batch = 0.6640s	
4015/33250 (epoch 6.038), train_loss = 1.20918009, grad/param norm = 1.6563e-01, time/batch = 0.6664s	
4016/33250 (epoch 6.039), train_loss = 1.13722199, grad/param norm = 1.6381e-01, time/batch = 0.6684s	
4017/33250 (epoch 6.041), train_loss = 1.37781356, grad/param norm = 1.9077e-01, time/batch = 0.6698s	
4018/33250 (epoch 6.042), train_loss = 1.09950296, grad/param norm = 1.5761e-01, time/batch = 0.6633s	
4019/33250 (epoch 6.044), train_loss = 1.44022567, grad/param norm = 1.8027e-01, time/batch = 0.6658s	
4020/33250 (epoch 6.045), train_loss = 1.39834330, grad/param norm = 1.6250e-01, time/batch = 0.6627s	
4021/33250 (epoch 6.047), train_loss = 1.41014002, grad/param norm = 1.9047e-01, time/batch = 0.6659s	
4022/33250 (epoch 6.048), train_loss = 1.52305874, grad/param norm = 2.0531e-01, time/batch = 0.6699s	
4023/33250 (epoch 6.050), train_loss = 1.23656846, grad/param norm = 1.7201e-01, time/batch = 0.6759s	
4024/33250 (epoch 6.051), train_loss = 1.28318970, grad/param norm = 1.5851e-01, time/batch = 0.6848s	
4025/33250 (epoch 6.053), train_loss = 1.34609937, grad/param norm = 1.7691e-01, time/batch = 0.6692s	
4026/33250 (epoch 6.054), train_loss = 1.11575330, grad/param norm = 1.5303e-01, time/batch = 0.6647s	
4027/33250 (epoch 6.056), train_loss = 1.15114727, grad/param norm = 1.7306e-01, time/batch = 0.6690s	
4028/33250 (epoch 6.057), train_loss = 1.27352056, grad/param norm = 1.5558e-01, time/batch = 0.6635s	
4029/33250 (epoch 6.059), train_loss = 1.22956627, grad/param norm = 1.6873e-01, time/batch = 0.6613s	
4030/33250 (epoch 6.060), train_loss = 1.35742843, grad/param norm = 1.8611e-01, time/batch = 0.6639s	
4031/33250 (epoch 6.062), train_loss = 1.44536855, grad/param norm = 1.7335e-01, time/batch = 0.6716s	
4032/33250 (epoch 6.063), train_loss = 1.39665866, grad/param norm = 1.6229e-01, time/batch = 0.6641s	
4033/33250 (epoch 6.065), train_loss = 1.27987096, grad/param norm = 1.7192e-01, time/batch = 0.6635s	
4034/33250 (epoch 6.066), train_loss = 1.37954057, grad/param norm = 1.8505e-01, time/batch = 0.6621s	
4035/33250 (epoch 6.068), train_loss = 1.30897083, grad/param norm = 1.7990e-01, time/batch = 0.6599s	
4036/33250 (epoch 6.069), train_loss = 1.32202421, grad/param norm = 1.7494e-01, time/batch = 0.6735s	
4037/33250 (epoch 6.071), train_loss = 1.13898105, grad/param norm = 1.6435e-01, time/batch = 0.6702s	
4038/33250 (epoch 6.072), train_loss = 1.19930400, grad/param norm = 1.6092e-01, time/batch = 0.6694s	
4039/33250 (epoch 6.074), train_loss = 1.33849361, grad/param norm = 1.6801e-01, time/batch = 0.6752s	
4040/33250 (epoch 6.075), train_loss = 1.17478575, grad/param norm = 1.6262e-01, time/batch = 0.6614s	
4041/33250 (epoch 6.077), train_loss = 1.30703815, grad/param norm = 1.7695e-01, time/batch = 0.6688s	
4042/33250 (epoch 6.078), train_loss = 1.20815225, grad/param norm = 1.7165e-01, time/batch = 0.6589s	
4043/33250 (epoch 6.080), train_loss = 1.38029125, grad/param norm = 1.9650e-01, time/batch = 0.6700s	
4044/33250 (epoch 6.081), train_loss = 1.34275113, grad/param norm = 1.7883e-01, time/batch = 0.6577s	
4045/33250 (epoch 6.083), train_loss = 1.39012917, grad/param norm = 1.7314e-01, time/batch = 0.6541s	
4046/33250 (epoch 6.084), train_loss = 1.26032095, grad/param norm = 1.8458e-01, time/batch = 0.6599s	
4047/33250 (epoch 6.086), train_loss = 1.19424018, grad/param norm = 1.4902e-01, time/batch = 0.6524s	
4048/33250 (epoch 6.087), train_loss = 1.11593122, grad/param norm = 1.5494e-01, time/batch = 0.6474s	
4049/33250 (epoch 6.089), train_loss = 1.32526182, grad/param norm = 1.7285e-01, time/batch = 0.6533s	
4050/33250 (epoch 6.090), train_loss = 1.21455601, grad/param norm = 1.7849e-01, time/batch = 0.6468s	
4051/33250 (epoch 6.092), train_loss = 1.15520071, grad/param norm = 1.5347e-01, time/batch = 0.6542s	
4052/33250 (epoch 6.093), train_loss = 1.26940051, grad/param norm = 1.7052e-01, time/batch = 0.6526s	
4053/33250 (epoch 6.095), train_loss = 1.21681016, grad/param norm = 1.5835e-01, time/batch = 0.6751s	
4054/33250 (epoch 6.096), train_loss = 1.06279661, grad/param norm = 1.5744e-01, time/batch = 0.6711s	
4055/33250 (epoch 6.098), train_loss = 1.18173083, grad/param norm = 1.7343e-01, time/batch = 0.6706s	
4056/33250 (epoch 6.099), train_loss = 0.98498922, grad/param norm = 1.5997e-01, time/batch = 0.6635s	
4057/33250 (epoch 6.101), train_loss = 1.23004105, grad/param norm = 1.7075e-01, time/batch = 0.6495s	
4058/33250 (epoch 6.102), train_loss = 1.13771806, grad/param norm = 1.6414e-01, time/batch = 0.6487s	
4059/33250 (epoch 6.104), train_loss = 1.05405061, grad/param norm = 1.5790e-01, time/batch = 0.6458s	
4060/33250 (epoch 6.105), train_loss = 1.20297424, grad/param norm = 1.7662e-01, time/batch = 0.6486s	
4061/33250 (epoch 6.107), train_loss = 1.03697805, grad/param norm = 1.5316e-01, time/batch = 0.6521s	
4062/33250 (epoch 6.108), train_loss = 1.24987143, grad/param norm = 1.6563e-01, time/batch = 0.6540s	
4063/33250 (epoch 6.110), train_loss = 1.03002951, grad/param norm = 1.4699e-01, time/batch = 0.6550s	
4064/33250 (epoch 6.111), train_loss = 1.23961467, grad/param norm = 1.6837e-01, time/batch = 0.6653s	
4065/33250 (epoch 6.113), train_loss = 1.22168032, grad/param norm = 1.7144e-01, time/batch = 0.6719s	
4066/33250 (epoch 6.114), train_loss = 1.15904114, grad/param norm = 1.7464e-01, time/batch = 0.6811s	
4067/33250 (epoch 6.116), train_loss = 1.31438018, grad/param norm = 1.8419e-01, time/batch = 0.6620s	
4068/33250 (epoch 6.117), train_loss = 1.23249709, grad/param norm = 1.6581e-01, time/batch = 0.6647s	
4069/33250 (epoch 6.119), train_loss = 1.22617915, grad/param norm = 1.6128e-01, time/batch = 0.6731s	
4070/33250 (epoch 6.120), train_loss = 0.97676178, grad/param norm = 1.4702e-01, time/batch = 0.6693s	
4071/33250 (epoch 6.122), train_loss = 1.38061865, grad/param norm = 1.6832e-01, time/batch = 0.6506s	
4072/33250 (epoch 6.123), train_loss = 1.33728685, grad/param norm = 1.6801e-01, time/batch = 0.6563s	
4073/33250 (epoch 6.125), train_loss = 1.05595963, grad/param norm = 1.6051e-01, time/batch = 0.6518s	
4074/33250 (epoch 6.126), train_loss = 1.26565737, grad/param norm = 1.9025e-01, time/batch = 0.6554s	
4075/33250 (epoch 6.128), train_loss = 1.13884621, grad/param norm = 1.6461e-01, time/batch = 0.6631s	
4076/33250 (epoch 6.129), train_loss = 1.22185866, grad/param norm = 1.6581e-01, time/batch = 0.6812s	
4077/33250 (epoch 6.131), train_loss = 1.25403510, grad/param norm = 1.8721e-01, time/batch = 0.6539s	
4078/33250 (epoch 6.132), train_loss = 1.24857893, grad/param norm = 1.6984e-01, time/batch = 0.6483s	
4079/33250 (epoch 6.134), train_loss = 1.27217456, grad/param norm = 1.6451e-01, time/batch = 0.6501s	
4080/33250 (epoch 6.135), train_loss = 1.32997959, grad/param norm = 1.7301e-01, time/batch = 0.6505s	
4081/33250 (epoch 6.137), train_loss = 1.13531957, grad/param norm = 1.7003e-01, time/batch = 0.6574s	
4082/33250 (epoch 6.138), train_loss = 1.17946379, grad/param norm = 1.5120e-01, time/batch = 0.6494s	
4083/33250 (epoch 6.140), train_loss = 1.05054952, grad/param norm = 1.7274e-01, time/batch = 0.6518s	
4084/33250 (epoch 6.141), train_loss = 1.60168031, grad/param norm = 2.2454e-01, time/batch = 0.6495s	
4085/33250 (epoch 6.143), train_loss = 1.01930874, grad/param norm = 1.6535e-01, time/batch = 0.6446s	
4086/33250 (epoch 6.144), train_loss = 1.16061400, grad/param norm = 1.6099e-01, time/batch = 0.6460s	
4087/33250 (epoch 6.146), train_loss = 1.14395027, grad/param norm = 1.5199e-01, time/batch = 0.6486s	
4088/33250 (epoch 6.147), train_loss = 1.15870093, grad/param norm = 1.6408e-01, time/batch = 0.6465s	
4089/33250 (epoch 6.149), train_loss = 1.24739853, grad/param norm = 1.6831e-01, time/batch = 0.6464s	
4090/33250 (epoch 6.150), train_loss = 1.09447860, grad/param norm = 1.6396e-01, time/batch = 0.6451s	
4091/33250 (epoch 6.152), train_loss = 1.09950217, grad/param norm = 1.7342e-01, time/batch = 0.6511s	
4092/33250 (epoch 6.153), train_loss = 1.43832912, grad/param norm = 1.9254e-01, time/batch = 0.6491s	
4093/33250 (epoch 6.155), train_loss = 1.31611737, grad/param norm = 1.9326e-01, time/batch = 0.6528s	
4094/33250 (epoch 6.156), train_loss = 1.39287386, grad/param norm = 1.7874e-01, time/batch = 0.6528s	
4095/33250 (epoch 6.158), train_loss = 1.53269029, grad/param norm = 2.0404e-01, time/batch = 0.6504s	
4096/33250 (epoch 6.159), train_loss = 1.28062840, grad/param norm = 1.9256e-01, time/batch = 0.6512s	
4097/33250 (epoch 6.161), train_loss = 1.34552277, grad/param norm = 1.9272e-01, time/batch = 0.6477s	
4098/33250 (epoch 6.162), train_loss = 1.17554100, grad/param norm = 1.7308e-01, time/batch = 0.6513s	
4099/33250 (epoch 6.164), train_loss = 1.31989061, grad/param norm = 1.7855e-01, time/batch = 0.6508s	
4100/33250 (epoch 6.165), train_loss = 1.35319411, grad/param norm = 1.8059e-01, time/batch = 0.6467s	
4101/33250 (epoch 6.167), train_loss = 1.35577896, grad/param norm = 1.7147e-01, time/batch = 0.6498s	
4102/33250 (epoch 6.168), train_loss = 1.08715412, grad/param norm = 1.5364e-01, time/batch = 0.6535s	
4103/33250 (epoch 6.170), train_loss = 1.18308167, grad/param norm = 1.5975e-01, time/batch = 0.6473s	
4104/33250 (epoch 6.171), train_loss = 1.22199873, grad/param norm = 1.8808e-01, time/batch = 0.6504s	
4105/33250 (epoch 6.173), train_loss = 1.18569255, grad/param norm = 1.7406e-01, time/batch = 0.6485s	
4106/33250 (epoch 6.174), train_loss = 1.25092337, grad/param norm = 1.8146e-01, time/batch = 0.6493s	
4107/33250 (epoch 6.176), train_loss = 1.29383253, grad/param norm = 1.8470e-01, time/batch = 0.6510s	
4108/33250 (epoch 6.177), train_loss = 1.10106512, grad/param norm = 1.4317e-01, time/batch = 0.6476s	
4109/33250 (epoch 6.179), train_loss = 1.18924625, grad/param norm = 1.6640e-01, time/batch = 0.6492s	
4110/33250 (epoch 6.180), train_loss = 1.11256295, grad/param norm = 1.5987e-01, time/batch = 0.6488s	
4111/33250 (epoch 6.182), train_loss = 1.23628432, grad/param norm = 1.8443e-01, time/batch = 0.6529s	
4112/33250 (epoch 6.183), train_loss = 1.42270162, grad/param norm = 1.6920e-01, time/batch = 0.6474s	
4113/33250 (epoch 6.185), train_loss = 1.35741423, grad/param norm = 1.9487e-01, time/batch = 0.6490s	
4114/33250 (epoch 6.186), train_loss = 1.23891440, grad/param norm = 1.6295e-01, time/batch = 0.6487s	
4115/33250 (epoch 6.188), train_loss = 1.34596863, grad/param norm = 1.8530e-01, time/batch = 0.6518s	
4116/33250 (epoch 6.189), train_loss = 1.07397535, grad/param norm = 1.7507e-01, time/batch = 0.6517s	
4117/33250 (epoch 6.191), train_loss = 1.18634727, grad/param norm = 1.8195e-01, time/batch = 0.6484s	
4118/33250 (epoch 6.192), train_loss = 1.14120471, grad/param norm = 1.5166e-01, time/batch = 0.6609s	
4119/33250 (epoch 6.194), train_loss = 1.13018264, grad/param norm = 1.8422e-01, time/batch = 0.6678s	
4120/33250 (epoch 6.195), train_loss = 1.40743748, grad/param norm = 1.6755e-01, time/batch = 0.6678s	
4121/33250 (epoch 6.197), train_loss = 1.24212058, grad/param norm = 1.7007e-01, time/batch = 0.6708s	
4122/33250 (epoch 6.198), train_loss = 1.34641227, grad/param norm = 1.7833e-01, time/batch = 0.6685s	
4123/33250 (epoch 6.200), train_loss = 1.25239134, grad/param norm = 1.6971e-01, time/batch = 0.6674s	
4124/33250 (epoch 6.202), train_loss = 1.19422897, grad/param norm = 1.6663e-01, time/batch = 0.6711s	
4125/33250 (epoch 6.203), train_loss = 1.24290329, grad/param norm = 1.7675e-01, time/batch = 0.6694s	
4126/33250 (epoch 6.205), train_loss = 1.27820515, grad/param norm = 1.6892e-01, time/batch = 0.6577s	
4127/33250 (epoch 6.206), train_loss = 1.28516752, grad/param norm = 1.7876e-01, time/batch = 0.6569s	
4128/33250 (epoch 6.208), train_loss = 1.47498135, grad/param norm = 2.1117e-01, time/batch = 0.6790s	
4129/33250 (epoch 6.209), train_loss = 1.15670068, grad/param norm = 1.7178e-01, time/batch = 0.6472s	
4130/33250 (epoch 6.211), train_loss = 1.39756554, grad/param norm = 1.8835e-01, time/batch = 0.6642s	
4131/33250 (epoch 6.212), train_loss = 1.51907888, grad/param norm = 1.8402e-01, time/batch = 0.6680s	
4132/33250 (epoch 6.214), train_loss = 1.24099962, grad/param norm = 1.5376e-01, time/batch = 0.6494s	
4133/33250 (epoch 6.215), train_loss = 1.60101564, grad/param norm = 2.1721e-01, time/batch = 0.6486s	
4134/33250 (epoch 6.217), train_loss = 1.45054552, grad/param norm = 1.9739e-01, time/batch = 0.6542s	
4135/33250 (epoch 6.218), train_loss = 1.35143869, grad/param norm = 1.7806e-01, time/batch = 0.6615s	
4136/33250 (epoch 6.220), train_loss = 1.41240094, grad/param norm = 1.8726e-01, time/batch = 0.6488s	
4137/33250 (epoch 6.221), train_loss = 1.52781304, grad/param norm = 1.9170e-01, time/batch = 0.6512s	
4138/33250 (epoch 6.223), train_loss = 1.24434177, grad/param norm = 1.8000e-01, time/batch = 0.6452s	
4139/33250 (epoch 6.224), train_loss = 1.42064754, grad/param norm = 2.0270e-01, time/batch = 0.6423s	
4140/33250 (epoch 6.226), train_loss = 1.43163807, grad/param norm = 1.7352e-01, time/batch = 0.6464s	
4141/33250 (epoch 6.227), train_loss = 1.29233261, grad/param norm = 1.6813e-01, time/batch = 0.6485s	
4142/33250 (epoch 6.229), train_loss = 1.27198038, grad/param norm = 1.6441e-01, time/batch = 0.6646s	
4143/33250 (epoch 6.230), train_loss = 1.21275844, grad/param norm = 1.7628e-01, time/batch = 0.6670s	
4144/33250 (epoch 6.232), train_loss = 1.16454797, grad/param norm = 1.4615e-01, time/batch = 0.6650s	
4145/33250 (epoch 6.233), train_loss = 1.20130782, grad/param norm = 1.6438e-01, time/batch = 0.6626s	
4146/33250 (epoch 6.235), train_loss = 1.38541031, grad/param norm = 1.7550e-01, time/batch = 0.6624s	
4147/33250 (epoch 6.236), train_loss = 1.18869917, grad/param norm = 1.8185e-01, time/batch = 0.6575s	
4148/33250 (epoch 6.238), train_loss = 1.36326188, grad/param norm = 1.8077e-01, time/batch = 0.6614s	
4149/33250 (epoch 6.239), train_loss = 1.48890959, grad/param norm = 1.8859e-01, time/batch = 0.6602s	
4150/33250 (epoch 6.241), train_loss = 1.38638739, grad/param norm = 1.9070e-01, time/batch = 0.6637s	
4151/33250 (epoch 6.242), train_loss = 1.35588068, grad/param norm = 1.8184e-01, time/batch = 0.6646s	
4152/33250 (epoch 6.244), train_loss = 1.40651235, grad/param norm = 1.9765e-01, time/batch = 0.6651s	
4153/33250 (epoch 6.245), train_loss = 1.25821202, grad/param norm = 1.5931e-01, time/batch = 0.6645s	
4154/33250 (epoch 6.247), train_loss = 1.31639141, grad/param norm = 1.5819e-01, time/batch = 0.6580s	
4155/33250 (epoch 6.248), train_loss = 1.57823510, grad/param norm = 1.9805e-01, time/batch = 0.6837s	
4156/33250 (epoch 6.250), train_loss = 1.33013737, grad/param norm = 1.5835e-01, time/batch = 0.6896s	
4157/33250 (epoch 6.251), train_loss = 1.28905484, grad/param norm = 1.8291e-01, time/batch = 0.6841s	
4158/33250 (epoch 6.253), train_loss = 1.12731410, grad/param norm = 1.5844e-01, time/batch = 0.6856s	
4159/33250 (epoch 6.254), train_loss = 1.23008415, grad/param norm = 1.7510e-01, time/batch = 0.6795s	
4160/33250 (epoch 6.256), train_loss = 1.34995393, grad/param norm = 1.6728e-01, time/batch = 0.6682s	
4161/33250 (epoch 6.257), train_loss = 1.44913474, grad/param norm = 1.7322e-01, time/batch = 0.6746s	
4162/33250 (epoch 6.259), train_loss = 1.48152089, grad/param norm = 1.7410e-01, time/batch = 0.6717s	
4163/33250 (epoch 6.260), train_loss = 1.17416847, grad/param norm = 1.6222e-01, time/batch = 0.6714s	
4164/33250 (epoch 6.262), train_loss = 1.34076115, grad/param norm = 1.6291e-01, time/batch = 0.6723s	
4165/33250 (epoch 6.263), train_loss = 1.20493778, grad/param norm = 1.5595e-01, time/batch = 0.6658s	
4166/33250 (epoch 6.265), train_loss = 1.38759497, grad/param norm = 1.7122e-01, time/batch = 0.6695s	
4167/33250 (epoch 6.266), train_loss = 1.30351164, grad/param norm = 1.7590e-01, time/batch = 0.6702s	
4168/33250 (epoch 6.268), train_loss = 1.17087754, grad/param norm = 1.5212e-01, time/batch = 0.6614s	
4169/33250 (epoch 6.269), train_loss = 1.00907339, grad/param norm = 1.4703e-01, time/batch = 0.6752s	
4170/33250 (epoch 6.271), train_loss = 1.26210758, grad/param norm = 1.5475e-01, time/batch = 0.6613s	
4171/33250 (epoch 6.272), train_loss = 1.04274879, grad/param norm = 1.3985e-01, time/batch = 0.6534s	
4172/33250 (epoch 6.274), train_loss = 0.98153782, grad/param norm = 1.4532e-01, time/batch = 0.6601s	
4173/33250 (epoch 6.275), train_loss = 1.13934999, grad/param norm = 1.4986e-01, time/batch = 0.6578s	
4174/33250 (epoch 6.277), train_loss = 1.02064327, grad/param norm = 1.4906e-01, time/batch = 0.6645s	
4175/33250 (epoch 6.278), train_loss = 1.13076810, grad/param norm = 1.5207e-01, time/batch = 0.6482s	
4176/33250 (epoch 6.280), train_loss = 1.07592203, grad/param norm = 1.4713e-01, time/batch = 0.6459s	
4177/33250 (epoch 6.281), train_loss = 1.27436808, grad/param norm = 1.7881e-01, time/batch = 0.6443s	
4178/33250 (epoch 6.283), train_loss = 1.34901256, grad/param norm = 1.6718e-01, time/batch = 0.6500s	
4179/33250 (epoch 6.284), train_loss = 1.17725971, grad/param norm = 1.6174e-01, time/batch = 0.6434s	
4180/33250 (epoch 6.286), train_loss = 1.33673785, grad/param norm = 1.8149e-01, time/batch = 0.6444s	
4181/33250 (epoch 6.287), train_loss = 1.09526371, grad/param norm = 1.4350e-01, time/batch = 0.6504s	
4182/33250 (epoch 6.289), train_loss = 1.14177039, grad/param norm = 1.5924e-01, time/batch = 0.6509s	
4183/33250 (epoch 6.290), train_loss = 1.25893864, grad/param norm = 1.5418e-01, time/batch = 0.6509s	
4184/33250 (epoch 6.292), train_loss = 1.29725282, grad/param norm = 1.8401e-01, time/batch = 0.6482s	
4185/33250 (epoch 6.293), train_loss = 1.40553197, grad/param norm = 1.9454e-01, time/batch = 0.6501s	
4186/33250 (epoch 6.295), train_loss = 1.32327182, grad/param norm = 1.7745e-01, time/batch = 0.6594s	
4187/33250 (epoch 6.296), train_loss = 1.25837419, grad/param norm = 1.6158e-01, time/batch = 0.6805s	
4188/33250 (epoch 6.298), train_loss = 1.01587594, grad/param norm = 1.3372e-01, time/batch = 0.6885s	
4189/33250 (epoch 6.299), train_loss = 0.99461797, grad/param norm = 1.4660e-01, time/batch = 0.6889s	
4190/33250 (epoch 6.301), train_loss = 1.33785720, grad/param norm = 1.6692e-01, time/batch = 0.6895s	
4191/33250 (epoch 6.302), train_loss = 1.23513410, grad/param norm = 1.6897e-01, time/batch = 0.6931s	
4192/33250 (epoch 6.304), train_loss = 1.20083275, grad/param norm = 1.4888e-01, time/batch = 0.6855s	
4193/33250 (epoch 6.305), train_loss = 1.24530019, grad/param norm = 1.5842e-01, time/batch = 0.6923s	
4194/33250 (epoch 6.307), train_loss = 1.35607320, grad/param norm = 1.6905e-01, time/batch = 0.6952s	
4195/33250 (epoch 6.308), train_loss = 1.51772095, grad/param norm = 1.9647e-01, time/batch = 0.6888s	
4196/33250 (epoch 6.310), train_loss = 1.27406323, grad/param norm = 1.7158e-01, time/batch = 0.6896s	
4197/33250 (epoch 6.311), train_loss = 1.38119503, grad/param norm = 1.7481e-01, time/batch = 0.6871s	
4198/33250 (epoch 6.313), train_loss = 1.10616510, grad/param norm = 1.6866e-01, time/batch = 0.6855s	
4199/33250 (epoch 6.314), train_loss = 1.22299724, grad/param norm = 1.6785e-01, time/batch = 0.6725s	
4200/33250 (epoch 6.316), train_loss = 1.45667275, grad/param norm = 1.9402e-01, time/batch = 0.6721s	
4201/33250 (epoch 6.317), train_loss = 1.16261638, grad/param norm = 1.6303e-01, time/batch = 0.6785s	
4202/33250 (epoch 6.319), train_loss = 1.40361147, grad/param norm = 1.9680e-01, time/batch = 0.6742s	
4203/33250 (epoch 6.320), train_loss = 1.51293770, grad/param norm = 2.2912e-01, time/batch = 0.6798s	
4204/33250 (epoch 6.322), train_loss = 1.49689395, grad/param norm = 2.0385e-01, time/batch = 0.6728s	
4205/33250 (epoch 6.323), train_loss = 1.55208538, grad/param norm = 2.0262e-01, time/batch = 0.6715s	
4206/33250 (epoch 6.325), train_loss = 1.26775261, grad/param norm = 1.8251e-01, time/batch = 0.6723s	
4207/33250 (epoch 6.326), train_loss = 1.53328116, grad/param norm = 1.9078e-01, time/batch = 0.6685s	
4208/33250 (epoch 6.328), train_loss = 1.18628410, grad/param norm = 1.6240e-01, time/batch = 0.6636s	
4209/33250 (epoch 6.329), train_loss = 1.32729392, grad/param norm = 1.8224e-01, time/batch = 0.6626s	
4210/33250 (epoch 6.331), train_loss = 1.23999413, grad/param norm = 1.7816e-01, time/batch = 0.6769s	
4211/33250 (epoch 6.332), train_loss = 1.21132104, grad/param norm = 1.8375e-01, time/batch = 0.6812s	
4212/33250 (epoch 6.334), train_loss = 1.39656454, grad/param norm = 1.7245e-01, time/batch = 0.6643s	
4213/33250 (epoch 6.335), train_loss = 0.96227831, grad/param norm = 1.6324e-01, time/batch = 0.6597s	
4214/33250 (epoch 6.337), train_loss = 1.26896724, grad/param norm = 1.6650e-01, time/batch = 0.6664s	
4215/33250 (epoch 6.338), train_loss = 1.37490261, grad/param norm = 1.6688e-01, time/batch = 0.6654s	
4216/33250 (epoch 6.340), train_loss = 1.27810163, grad/param norm = 1.7463e-01, time/batch = 0.6611s	
4217/33250 (epoch 6.341), train_loss = 1.20371767, grad/param norm = 1.6626e-01, time/batch = 0.6645s	
4218/33250 (epoch 6.343), train_loss = 1.28816980, grad/param norm = 1.8490e-01, time/batch = 0.6729s	
4219/33250 (epoch 6.344), train_loss = 1.24358323, grad/param norm = 1.7638e-01, time/batch = 0.6677s	
4220/33250 (epoch 6.346), train_loss = 1.09212922, grad/param norm = 1.5693e-01, time/batch = 0.6709s	
4221/33250 (epoch 6.347), train_loss = 1.60510782, grad/param norm = 1.8127e-01, time/batch = 0.6857s	
4222/33250 (epoch 6.349), train_loss = 1.25923305, grad/param norm = 1.7070e-01, time/batch = 0.6714s	
4223/33250 (epoch 6.350), train_loss = 1.29112242, grad/param norm = 1.8306e-01, time/batch = 0.6645s	
4224/33250 (epoch 6.352), train_loss = 1.18509059, grad/param norm = 1.9653e-01, time/batch = 0.6699s	
4225/33250 (epoch 6.353), train_loss = 1.24972216, grad/param norm = 1.5851e-01, time/batch = 0.6730s	
4226/33250 (epoch 6.355), train_loss = 1.23537031, grad/param norm = 1.7364e-01, time/batch = 0.6658s	
4227/33250 (epoch 6.356), train_loss = 1.15257299, grad/param norm = 1.8052e-01, time/batch = 0.6631s	
4228/33250 (epoch 6.358), train_loss = 1.18958992, grad/param norm = 1.5578e-01, time/batch = 0.6594s	
4229/33250 (epoch 6.359), train_loss = 1.16888471, grad/param norm = 1.5029e-01, time/batch = 0.6720s	
4230/33250 (epoch 6.361), train_loss = 1.42831312, grad/param norm = 1.8438e-01, time/batch = 0.6701s	
4231/33250 (epoch 6.362), train_loss = 1.22757749, grad/param norm = 1.6578e-01, time/batch = 0.6839s	
4232/33250 (epoch 6.364), train_loss = 1.38420536, grad/param norm = 1.8657e-01, time/batch = 0.6730s	
4233/33250 (epoch 6.365), train_loss = 1.22561633, grad/param norm = 1.6717e-01, time/batch = 0.6674s	
4234/33250 (epoch 6.367), train_loss = 1.19400761, grad/param norm = 1.5024e-01, time/batch = 0.6614s	
4235/33250 (epoch 6.368), train_loss = 1.24295932, grad/param norm = 1.6207e-01, time/batch = 0.6659s	
4236/33250 (epoch 6.370), train_loss = 1.07306888, grad/param norm = 1.5082e-01, time/batch = 0.6634s	
4237/33250 (epoch 6.371), train_loss = 1.37275623, grad/param norm = 1.7934e-01, time/batch = 0.6636s	
4238/33250 (epoch 6.373), train_loss = 1.20191127, grad/param norm = 1.6457e-01, time/batch = 0.6631s	
4239/33250 (epoch 6.374), train_loss = 1.33671279, grad/param norm = 1.9229e-01, time/batch = 0.6658s	
4240/33250 (epoch 6.376), train_loss = 1.22927372, grad/param norm = 1.6396e-01, time/batch = 0.6667s	
4241/33250 (epoch 6.377), train_loss = 1.15817774, grad/param norm = 2.0447e-01, time/batch = 0.6674s	
4242/33250 (epoch 6.379), train_loss = 1.17162402, grad/param norm = 1.7433e-01, time/batch = 0.6657s	
4243/33250 (epoch 6.380), train_loss = 1.34505823, grad/param norm = 1.9646e-01, time/batch = 0.6677s	
4244/33250 (epoch 6.382), train_loss = 1.38524973, grad/param norm = 2.0678e-01, time/batch = 0.6787s	
4245/33250 (epoch 6.383), train_loss = 1.17250010, grad/param norm = 1.6903e-01, time/batch = 0.6864s	
4246/33250 (epoch 6.385), train_loss = 1.12925468, grad/param norm = 1.7740e-01, time/batch = 0.6843s	
4247/33250 (epoch 6.386), train_loss = 1.12135073, grad/param norm = 1.7400e-01, time/batch = 0.6917s	
4248/33250 (epoch 6.388), train_loss = 1.18446986, grad/param norm = 1.7480e-01, time/batch = 0.6942s	
4249/33250 (epoch 6.389), train_loss = 1.22585716, grad/param norm = 1.8017e-01, time/batch = 0.6774s	
4250/33250 (epoch 6.391), train_loss = 1.26710937, grad/param norm = 1.8974e-01, time/batch = 0.6788s	
4251/33250 (epoch 6.392), train_loss = 1.38977803, grad/param norm = 1.8786e-01, time/batch = 0.6639s	
4252/33250 (epoch 6.394), train_loss = 1.49890053, grad/param norm = 2.0199e-01, time/batch = 0.6838s	
4253/33250 (epoch 6.395), train_loss = 1.40345797, grad/param norm = 1.7432e-01, time/batch = 0.6707s	
4254/33250 (epoch 6.397), train_loss = 1.39385900, grad/param norm = 1.9423e-01, time/batch = 0.6664s	
4255/33250 (epoch 6.398), train_loss = 1.21288807, grad/param norm = 1.6936e-01, time/batch = 0.6711s	
4256/33250 (epoch 6.400), train_loss = 1.18511261, grad/param norm = 1.6723e-01, time/batch = 0.6677s	
4257/33250 (epoch 6.402), train_loss = 1.10460369, grad/param norm = 1.6329e-01, time/batch = 0.6642s	
4258/33250 (epoch 6.403), train_loss = 1.18827205, grad/param norm = 1.8617e-01, time/batch = 0.6608s	
4259/33250 (epoch 6.405), train_loss = 1.15754545, grad/param norm = 1.7484e-01, time/batch = 0.6720s	
4260/33250 (epoch 6.406), train_loss = 1.30579313, grad/param norm = 1.7301e-01, time/batch = 0.6727s	
4261/33250 (epoch 6.408), train_loss = 1.40946349, grad/param norm = 1.8145e-01, time/batch = 0.6804s	
4262/33250 (epoch 6.409), train_loss = 1.38838328, grad/param norm = 2.2237e-01, time/batch = 0.6656s	
4263/33250 (epoch 6.411), train_loss = 0.94831333, grad/param norm = 1.3636e-01, time/batch = 0.6707s	
4264/33250 (epoch 6.412), train_loss = 1.07975019, grad/param norm = 1.6085e-01, time/batch = 0.6858s	
4265/33250 (epoch 6.414), train_loss = 1.29463180, grad/param norm = 1.6857e-01, time/batch = 0.6824s	
4266/33250 (epoch 6.415), train_loss = 1.38699691, grad/param norm = 1.7632e-01, time/batch = 0.6798s	
4267/33250 (epoch 6.417), train_loss = 1.33694206, grad/param norm = 1.8225e-01, time/batch = 0.6812s	
4268/33250 (epoch 6.418), train_loss = 1.53275722, grad/param norm = 2.2533e-01, time/batch = 0.6678s	
4269/33250 (epoch 6.420), train_loss = 1.37141081, grad/param norm = 1.7036e-01, time/batch = 0.6634s	
4270/33250 (epoch 6.421), train_loss = 1.14119844, grad/param norm = 1.8356e-01, time/batch = 0.6620s	
4271/33250 (epoch 6.423), train_loss = 1.37512152, grad/param norm = 2.1175e-01, time/batch = 0.6664s	
4272/33250 (epoch 6.424), train_loss = 1.57731471, grad/param norm = 2.2926e-01, time/batch = 0.6729s	
4273/33250 (epoch 6.426), train_loss = 1.14014528, grad/param norm = 1.5523e-01, time/batch = 0.6847s	
4274/33250 (epoch 6.427), train_loss = 1.16679110, grad/param norm = 1.6912e-01, time/batch = 0.6607s	
4275/33250 (epoch 6.429), train_loss = 1.35278164, grad/param norm = 1.9147e-01, time/batch = 0.6594s	
4276/33250 (epoch 6.430), train_loss = 1.17546898, grad/param norm = 1.8541e-01, time/batch = 0.6625s	
4277/33250 (epoch 6.432), train_loss = 1.22533883, grad/param norm = 1.6230e-01, time/batch = 0.6600s	
4278/33250 (epoch 6.433), train_loss = 1.23113134, grad/param norm = 1.7571e-01, time/batch = 0.6663s	
4279/33250 (epoch 6.435), train_loss = 1.28742746, grad/param norm = 1.8926e-01, time/batch = 0.6641s	
4280/33250 (epoch 6.436), train_loss = 1.18353890, grad/param norm = 1.6592e-01, time/batch = 0.6584s	
4281/33250 (epoch 6.438), train_loss = 1.27542367, grad/param norm = 1.6642e-01, time/batch = 0.6663s	
4282/33250 (epoch 6.439), train_loss = 1.25536213, grad/param norm = 1.8310e-01, time/batch = 0.6652s	
4283/33250 (epoch 6.441), train_loss = 1.24100136, grad/param norm = 1.6712e-01, time/batch = 0.6639s	
4284/33250 (epoch 6.442), train_loss = 1.19811754, grad/param norm = 1.7258e-01, time/batch = 0.6655s	
4285/33250 (epoch 6.444), train_loss = 1.14530969, grad/param norm = 1.7620e-01, time/batch = 0.6654s	
4286/33250 (epoch 6.445), train_loss = 1.27247408, grad/param norm = 1.6106e-01, time/batch = 0.6709s	
4287/33250 (epoch 6.447), train_loss = 1.29651194, grad/param norm = 1.7326e-01, time/batch = 0.6677s	
4288/33250 (epoch 6.448), train_loss = 1.15474131, grad/param norm = 1.3909e-01, time/batch = 0.6695s	
4289/33250 (epoch 6.450), train_loss = 1.46836153, grad/param norm = 2.0843e-01, time/batch = 0.6620s	
4290/33250 (epoch 6.451), train_loss = 1.31659786, grad/param norm = 1.8712e-01, time/batch = 0.6640s	
4291/33250 (epoch 6.453), train_loss = 1.09660459, grad/param norm = 1.6043e-01, time/batch = 0.6670s	
4292/33250 (epoch 6.454), train_loss = 1.40461336, grad/param norm = 1.9406e-01, time/batch = 0.6620s	
4293/33250 (epoch 6.456), train_loss = 1.41814787, grad/param norm = 1.9706e-01, time/batch = 0.6649s	
4294/33250 (epoch 6.457), train_loss = 1.21874235, grad/param norm = 1.7161e-01, time/batch = 0.6653s	
4295/33250 (epoch 6.459), train_loss = 1.27238775, grad/param norm = 1.5869e-01, time/batch = 0.6617s	
4296/33250 (epoch 6.460), train_loss = 1.34898977, grad/param norm = 1.8621e-01, time/batch = 0.6621s	
4297/33250 (epoch 6.462), train_loss = 1.16875825, grad/param norm = 1.5666e-01, time/batch = 0.6664s	
4298/33250 (epoch 6.463), train_loss = 1.12237729, grad/param norm = 1.4428e-01, time/batch = 0.6610s	
4299/33250 (epoch 6.465), train_loss = 1.00966117, grad/param norm = 1.3801e-01, time/batch = 0.6635s	
4300/33250 (epoch 6.466), train_loss = 0.98134512, grad/param norm = 1.3348e-01, time/batch = 0.6622s	
4301/33250 (epoch 6.468), train_loss = 1.09844444, grad/param norm = 1.4174e-01, time/batch = 0.6649s	
4302/33250 (epoch 6.469), train_loss = 1.31349640, grad/param norm = 1.9022e-01, time/batch = 0.6835s	
4303/33250 (epoch 6.471), train_loss = 1.37866693, grad/param norm = 1.8035e-01, time/batch = 0.6850s	
4304/33250 (epoch 6.472), train_loss = 1.30456140, grad/param norm = 2.0555e-01, time/batch = 0.6983s	
4305/33250 (epoch 6.474), train_loss = 1.52371688, grad/param norm = 2.3308e-01, time/batch = 0.6868s	
4306/33250 (epoch 6.475), train_loss = 1.25539737, grad/param norm = 1.6795e-01, time/batch = 0.6733s	
4307/33250 (epoch 6.477), train_loss = 1.25094828, grad/param norm = 1.7720e-01, time/batch = 0.6757s	
4308/33250 (epoch 6.478), train_loss = 1.20942451, grad/param norm = 1.6284e-01, time/batch = 0.6808s	
4309/33250 (epoch 6.480), train_loss = 1.47397393, grad/param norm = 1.8539e-01, time/batch = 0.6830s	
4310/33250 (epoch 6.481), train_loss = 1.22620645, grad/param norm = 1.9723e-01, time/batch = 0.6697s	
4311/33250 (epoch 6.483), train_loss = 1.28939092, grad/param norm = 1.6439e-01, time/batch = 0.6820s	
4312/33250 (epoch 6.484), train_loss = 1.14734322, grad/param norm = 1.5099e-01, time/batch = 0.6637s	
4313/33250 (epoch 6.486), train_loss = 1.06897901, grad/param norm = 1.6567e-01, time/batch = 0.6705s	
4314/33250 (epoch 6.487), train_loss = 1.19107922, grad/param norm = 1.6807e-01, time/batch = 0.6800s	
4315/33250 (epoch 6.489), train_loss = 1.40388193, grad/param norm = 1.8775e-01, time/batch = 0.6805s	
4316/33250 (epoch 6.490), train_loss = 1.32629499, grad/param norm = 1.9438e-01, time/batch = 0.6667s	
4317/33250 (epoch 6.492), train_loss = 1.31669225, grad/param norm = 1.9267e-01, time/batch = 0.6631s	
4318/33250 (epoch 6.493), train_loss = 1.28079111, grad/param norm = 1.7407e-01, time/batch = 0.6615s	
4319/33250 (epoch 6.495), train_loss = 1.27035249, grad/param norm = 1.6483e-01, time/batch = 0.6767s	
4320/33250 (epoch 6.496), train_loss = 1.18970262, grad/param norm = 1.4609e-01, time/batch = 0.6809s	
4321/33250 (epoch 6.498), train_loss = 1.34623024, grad/param norm = 1.7346e-01, time/batch = 0.6801s	
4322/33250 (epoch 6.499), train_loss = 1.23671263, grad/param norm = 1.7228e-01, time/batch = 0.6784s	
4323/33250 (epoch 6.501), train_loss = 1.19453279, grad/param norm = 1.8029e-01, time/batch = 0.6785s	
4324/33250 (epoch 6.502), train_loss = 1.23226128, grad/param norm = 1.6566e-01, time/batch = 0.6823s	
4325/33250 (epoch 6.504), train_loss = 1.44159122, grad/param norm = 1.9842e-01, time/batch = 0.6782s	
4326/33250 (epoch 6.505), train_loss = 1.01298059, grad/param norm = 1.3602e-01, time/batch = 0.6792s	
4327/33250 (epoch 6.507), train_loss = 1.25463603, grad/param norm = 1.7156e-01, time/batch = 0.6601s	
4328/33250 (epoch 6.508), train_loss = 1.20309354, grad/param norm = 1.6220e-01, time/batch = 0.6612s	
4329/33250 (epoch 6.510), train_loss = 1.07648768, grad/param norm = 1.5549e-01, time/batch = 0.6653s	
4330/33250 (epoch 6.511), train_loss = 1.26863636, grad/param norm = 1.6484e-01, time/batch = 0.6622s	
4331/33250 (epoch 6.513), train_loss = 1.48096025, grad/param norm = 1.7917e-01, time/batch = 0.6655s	
4332/33250 (epoch 6.514), train_loss = 1.19814916, grad/param norm = 1.5893e-01, time/batch = 0.6649s	
4333/33250 (epoch 6.516), train_loss = 1.18188721, grad/param norm = 1.6148e-01, time/batch = 0.6791s	
4334/33250 (epoch 6.517), train_loss = 1.26066044, grad/param norm = 1.5673e-01, time/batch = 0.6858s	
4335/33250 (epoch 6.519), train_loss = 1.09926669, grad/param norm = 1.4717e-01, time/batch = 0.6858s	
4336/33250 (epoch 6.520), train_loss = 1.58605809, grad/param norm = 1.9696e-01, time/batch = 0.6821s	
4337/33250 (epoch 6.522), train_loss = 1.38275568, grad/param norm = 1.8837e-01, time/batch = 0.6683s	
4338/33250 (epoch 6.523), train_loss = 1.25416764, grad/param norm = 1.8498e-01, time/batch = 0.6679s	
4339/33250 (epoch 6.525), train_loss = 1.10582278, grad/param norm = 1.6450e-01, time/batch = 0.6769s	
4340/33250 (epoch 6.526), train_loss = 1.12159593, grad/param norm = 1.5623e-01, time/batch = 0.6751s	
4341/33250 (epoch 6.528), train_loss = 1.23111791, grad/param norm = 1.6471e-01, time/batch = 0.6657s	
4342/33250 (epoch 6.529), train_loss = 1.17060899, grad/param norm = 1.5310e-01, time/batch = 0.6816s	
4343/33250 (epoch 6.531), train_loss = 1.08055184, grad/param norm = 1.6355e-01, time/batch = 0.6896s	
4344/33250 (epoch 6.532), train_loss = 1.35063693, grad/param norm = 1.7210e-01, time/batch = 0.6821s	
4345/33250 (epoch 6.534), train_loss = 1.18734994, grad/param norm = 1.5829e-01, time/batch = 0.6801s	
4346/33250 (epoch 6.535), train_loss = 1.24917176, grad/param norm = 1.7116e-01, time/batch = 0.6829s	
4347/33250 (epoch 6.537), train_loss = 1.36143904, grad/param norm = 1.6955e-01, time/batch = 0.6852s	
4348/33250 (epoch 6.538), train_loss = 1.35014451, grad/param norm = 1.7123e-01, time/batch = 0.6694s	
4349/33250 (epoch 6.540), train_loss = 1.40232351, grad/param norm = 1.6298e-01, time/batch = 0.6661s	
4350/33250 (epoch 6.541), train_loss = 1.40748308, grad/param norm = 1.9800e-01, time/batch = 0.6802s	
4351/33250 (epoch 6.543), train_loss = 1.37589625, grad/param norm = 1.8104e-01, time/batch = 0.6604s	
4352/33250 (epoch 6.544), train_loss = 1.22799343, grad/param norm = 1.6820e-01, time/batch = 0.6625s	
4353/33250 (epoch 6.546), train_loss = 1.24991783, grad/param norm = 1.8429e-01, time/batch = 0.6577s	
4354/33250 (epoch 6.547), train_loss = 1.17987882, grad/param norm = 1.7920e-01, time/batch = 0.6809s	
4355/33250 (epoch 6.549), train_loss = 1.29024605, grad/param norm = 1.6635e-01, time/batch = 0.6835s	
4356/33250 (epoch 6.550), train_loss = 1.20762965, grad/param norm = 1.6061e-01, time/batch = 0.6842s	
4357/33250 (epoch 6.552), train_loss = 1.31125838, grad/param norm = 1.8598e-01, time/batch = 0.6636s	
4358/33250 (epoch 6.553), train_loss = 1.19014694, grad/param norm = 1.7224e-01, time/batch = 0.6549s	
4359/33250 (epoch 6.555), train_loss = 1.25826171, grad/param norm = 1.6669e-01, time/batch = 0.6546s	
4360/33250 (epoch 6.556), train_loss = 1.44186648, grad/param norm = 1.9828e-01, time/batch = 0.6626s	
4361/33250 (epoch 6.558), train_loss = 1.35382171, grad/param norm = 1.7434e-01, time/batch = 0.6580s	
4362/33250 (epoch 6.559), train_loss = 1.10471199, grad/param norm = 1.6284e-01, time/batch = 0.6572s	
4363/33250 (epoch 6.561), train_loss = 1.21205007, grad/param norm = 1.6748e-01, time/batch = 0.6624s	
4364/33250 (epoch 6.562), train_loss = 1.43840054, grad/param norm = 1.8448e-01, time/batch = 0.6623s	
4365/33250 (epoch 6.564), train_loss = 1.51732921, grad/param norm = 2.1204e-01, time/batch = 0.6591s	
4366/33250 (epoch 6.565), train_loss = 1.45216565, grad/param norm = 1.8606e-01, time/batch = 0.6623s	
4367/33250 (epoch 6.567), train_loss = 1.37303551, grad/param norm = 1.8260e-01, time/batch = 0.6610s	
4368/33250 (epoch 6.568), train_loss = 1.24241434, grad/param norm = 1.7661e-01, time/batch = 0.6611s	
4369/33250 (epoch 6.570), train_loss = 1.39726688, grad/param norm = 1.7903e-01, time/batch = 0.6669s	
4370/33250 (epoch 6.571), train_loss = 1.49007660, grad/param norm = 1.8031e-01, time/batch = 0.6635s	
4371/33250 (epoch 6.573), train_loss = 1.35827405, grad/param norm = 1.7426e-01, time/batch = 0.6647s	
4372/33250 (epoch 6.574), train_loss = 1.14047285, grad/param norm = 1.7306e-01, time/batch = 0.6835s	
4373/33250 (epoch 6.576), train_loss = 1.29081267, grad/param norm = 1.6407e-01, time/batch = 0.6770s	
4374/33250 (epoch 6.577), train_loss = 1.24413162, grad/param norm = 1.6014e-01, time/batch = 0.6876s	
4375/33250 (epoch 6.579), train_loss = 1.12501106, grad/param norm = 1.5766e-01, time/batch = 0.6752s	
4376/33250 (epoch 6.580), train_loss = 1.13554729, grad/param norm = 1.5035e-01, time/batch = 0.6714s	
4377/33250 (epoch 6.582), train_loss = 1.23019235, grad/param norm = 1.6259e-01, time/batch = 0.6736s	
4378/33250 (epoch 6.583), train_loss = 1.25195952, grad/param norm = 1.4598e-01, time/batch = 0.6715s	
4379/33250 (epoch 6.585), train_loss = 1.33702390, grad/param norm = 1.7632e-01, time/batch = 0.6734s	
4380/33250 (epoch 6.586), train_loss = 1.20961071, grad/param norm = 1.9789e-01, time/batch = 0.6715s	
4381/33250 (epoch 6.588), train_loss = 1.25283143, grad/param norm = 1.6639e-01, time/batch = 0.6753s	
4382/33250 (epoch 6.589), train_loss = 1.33122713, grad/param norm = 1.7571e-01, time/batch = 0.6631s	
4383/33250 (epoch 6.591), train_loss = 1.36394992, grad/param norm = 1.8815e-01, time/batch = 0.6629s	
4384/33250 (epoch 6.592), train_loss = 1.26829928, grad/param norm = 1.5769e-01, time/batch = 0.6462s	
4385/33250 (epoch 6.594), train_loss = 1.46967321, grad/param norm = 1.8856e-01, time/batch = 0.6447s	
4386/33250 (epoch 6.595), train_loss = 1.42493086, grad/param norm = 1.9419e-01, time/batch = 0.6488s	
4387/33250 (epoch 6.597), train_loss = 1.12962076, grad/param norm = 1.5197e-01, time/batch = 0.6420s	
4388/33250 (epoch 6.598), train_loss = 1.33932713, grad/param norm = 1.7507e-01, time/batch = 0.6434s	
4389/33250 (epoch 6.600), train_loss = 1.27505303, grad/param norm = 1.7504e-01, time/batch = 0.6456s	
4390/33250 (epoch 6.602), train_loss = 1.31218219, grad/param norm = 1.8487e-01, time/batch = 0.6497s	
4391/33250 (epoch 6.603), train_loss = 1.29887650, grad/param norm = 1.8132e-01, time/batch = 0.6643s	
4392/33250 (epoch 6.605), train_loss = 1.26776495, grad/param norm = 1.6780e-01, time/batch = 0.6605s	
4393/33250 (epoch 6.606), train_loss = 1.33948749, grad/param norm = 1.7014e-01, time/batch = 0.6459s	
4394/33250 (epoch 6.608), train_loss = 1.25577005, grad/param norm = 1.6005e-01, time/batch = 0.6473s	
4395/33250 (epoch 6.609), train_loss = 1.17870345, grad/param norm = 1.7361e-01, time/batch = 0.6463s	
4396/33250 (epoch 6.611), train_loss = 1.36014004, grad/param norm = 1.7970e-01, time/batch = 0.6445s	
4397/33250 (epoch 6.612), train_loss = 1.33270614, grad/param norm = 1.8089e-01, time/batch = 0.6582s	
4398/33250 (epoch 6.614), train_loss = 1.57590810, grad/param norm = 1.9580e-01, time/batch = 0.6574s	
4399/33250 (epoch 6.615), train_loss = 1.39849781, grad/param norm = 1.7464e-01, time/batch = 0.6465s	
4400/33250 (epoch 6.617), train_loss = 1.68957603, grad/param norm = 1.9301e-01, time/batch = 0.6468s	
4401/33250 (epoch 6.618), train_loss = 1.64083744, grad/param norm = 2.2168e-01, time/batch = 0.6537s	
4402/33250 (epoch 6.620), train_loss = 1.43623536, grad/param norm = 1.9017e-01, time/batch = 0.6483s	
4403/33250 (epoch 6.621), train_loss = 1.23825099, grad/param norm = 1.5797e-01, time/batch = 0.6526s	
4404/33250 (epoch 6.623), train_loss = 1.18918555, grad/param norm = 1.6668e-01, time/batch = 0.6520s	
4405/33250 (epoch 6.624), train_loss = 1.26158595, grad/param norm = 1.8233e-01, time/batch = 0.6481s	
4406/33250 (epoch 6.626), train_loss = 1.28904213, grad/param norm = 1.8269e-01, time/batch = 0.6476s	
4407/33250 (epoch 6.627), train_loss = 1.21958653, grad/param norm = 1.6800e-01, time/batch = 0.6455s	
4408/33250 (epoch 6.629), train_loss = 1.27795387, grad/param norm = 2.0626e-01, time/batch = 0.6480s	
4409/33250 (epoch 6.630), train_loss = 1.24340896, grad/param norm = 1.6421e-01, time/batch = 0.6453s	
4410/33250 (epoch 6.632), train_loss = 1.06745533, grad/param norm = 1.5541e-01, time/batch = 0.6463s	
4411/33250 (epoch 6.633), train_loss = 1.34643453, grad/param norm = 1.7986e-01, time/batch = 0.6464s	
4412/33250 (epoch 6.635), train_loss = 1.14113340, grad/param norm = 1.5199e-01, time/batch = 0.6756s	
4413/33250 (epoch 6.636), train_loss = 1.15575333, grad/param norm = 1.5821e-01, time/batch = 0.6684s	
4414/33250 (epoch 6.638), train_loss = 1.21278094, grad/param norm = 1.7092e-01, time/batch = 0.6702s	
4415/33250 (epoch 6.639), train_loss = 1.15884112, grad/param norm = 1.7264e-01, time/batch = 0.6717s	
4416/33250 (epoch 6.641), train_loss = 1.14399228, grad/param norm = 1.5552e-01, time/batch = 0.6695s	
4417/33250 (epoch 6.642), train_loss = 1.11567856, grad/param norm = 1.5739e-01, time/batch = 0.6551s	
4418/33250 (epoch 6.644), train_loss = 1.00290603, grad/param norm = 1.4309e-01, time/batch = 0.6456s	
4419/33250 (epoch 6.645), train_loss = 1.40421049, grad/param norm = 1.9367e-01, time/batch = 0.6493s	
4420/33250 (epoch 6.647), train_loss = 1.11614169, grad/param norm = 1.5417e-01, time/batch = 0.6467s	
4421/33250 (epoch 6.648), train_loss = 1.23080969, grad/param norm = 1.7627e-01, time/batch = 0.6432s	
4422/33250 (epoch 6.650), train_loss = 1.43161643, grad/param norm = 1.8779e-01, time/batch = 0.6464s	
4423/33250 (epoch 6.651), train_loss = 1.28277712, grad/param norm = 1.8702e-01, time/batch = 0.6541s	
4424/33250 (epoch 6.653), train_loss = 1.11480619, grad/param norm = 1.5066e-01, time/batch = 0.6700s	
4425/33250 (epoch 6.654), train_loss = 1.15208319, grad/param norm = 1.6203e-01, time/batch = 0.6767s	
4426/33250 (epoch 6.656), train_loss = 1.29811553, grad/param norm = 1.6984e-01, time/batch = 0.6648s	
4427/33250 (epoch 6.657), train_loss = 1.04099959, grad/param norm = 1.7294e-01, time/batch = 0.6462s	
4428/33250 (epoch 6.659), train_loss = 1.22436260, grad/param norm = 1.8290e-01, time/batch = 0.6490s	
4429/33250 (epoch 6.660), train_loss = 1.18083618, grad/param norm = 1.8473e-01, time/batch = 0.6519s	
4430/33250 (epoch 6.662), train_loss = 1.29808618, grad/param norm = 1.7732e-01, time/batch = 0.6489s	
4431/33250 (epoch 6.663), train_loss = 1.20600955, grad/param norm = 1.7417e-01, time/batch = 0.6528s	
4432/33250 (epoch 6.665), train_loss = 1.36533571, grad/param norm = 1.8167e-01, time/batch = 0.6548s	
4433/33250 (epoch 6.666), train_loss = 1.22115366, grad/param norm = 1.8071e-01, time/batch = 0.6511s	
4434/33250 (epoch 6.668), train_loss = 1.38469771, grad/param norm = 1.7179e-01, time/batch = 0.6497s	
4435/33250 (epoch 6.669), train_loss = 1.32291171, grad/param norm = 1.8680e-01, time/batch = 0.6537s	
4436/33250 (epoch 6.671), train_loss = 1.28163197, grad/param norm = 1.8628e-01, time/batch = 0.6555s	
4437/33250 (epoch 6.672), train_loss = 1.38995762, grad/param norm = 1.8957e-01, time/batch = 0.6545s	
4438/33250 (epoch 6.674), train_loss = 1.24166459, grad/param norm = 1.5538e-01, time/batch = 0.6465s	
4439/33250 (epoch 6.675), train_loss = 1.28473279, grad/param norm = 1.6804e-01, time/batch = 0.6513s	
4440/33250 (epoch 6.677), train_loss = 1.32700517, grad/param norm = 1.6569e-01, time/batch = 0.6503s	
4441/33250 (epoch 6.678), train_loss = 1.32365979, grad/param norm = 1.7196e-01, time/batch = 0.6571s	
4442/33250 (epoch 6.680), train_loss = 1.38252643, grad/param norm = 1.7886e-01, time/batch = 0.6576s	
4443/33250 (epoch 6.681), train_loss = 1.08889908, grad/param norm = 1.5570e-01, time/batch = 0.6521s	
4444/33250 (epoch 6.683), train_loss = 1.19530132, grad/param norm = 1.6889e-01, time/batch = 0.6539s	
4445/33250 (epoch 6.684), train_loss = 1.18640928, grad/param norm = 1.7401e-01, time/batch = 0.6533s	
4446/33250 (epoch 6.686), train_loss = 1.15844921, grad/param norm = 1.6971e-01, time/batch = 0.6514s	
4447/33250 (epoch 6.687), train_loss = 1.18131497, grad/param norm = 1.5966e-01, time/batch = 0.6537s	
4448/33250 (epoch 6.689), train_loss = 1.20360890, grad/param norm = 1.7476e-01, time/batch = 0.6546s	
4449/33250 (epoch 6.690), train_loss = 1.33657187, grad/param norm = 1.8986e-01, time/batch = 0.6497s	
4450/33250 (epoch 6.692), train_loss = 1.31678588, grad/param norm = 1.8484e-01, time/batch = 0.6553s	
4451/33250 (epoch 6.693), train_loss = 1.24887221, grad/param norm = 1.5764e-01, time/batch = 0.6591s	
4452/33250 (epoch 6.695), train_loss = 1.30909921, grad/param norm = 1.6908e-01, time/batch = 0.6565s	
4453/33250 (epoch 6.696), train_loss = 1.23680230, grad/param norm = 1.5677e-01, time/batch = 0.6555s	
4454/33250 (epoch 6.698), train_loss = 1.17654138, grad/param norm = 1.7039e-01, time/batch = 0.6545s	
4455/33250 (epoch 6.699), train_loss = 1.46307893, grad/param norm = 1.7776e-01, time/batch = 0.6502s	
4456/33250 (epoch 6.701), train_loss = 1.19390643, grad/param norm = 1.5713e-01, time/batch = 0.6542s	
4457/33250 (epoch 6.702), train_loss = 1.31577137, grad/param norm = 1.8782e-01, time/batch = 0.6474s	
4458/33250 (epoch 6.704), train_loss = 1.47365832, grad/param norm = 1.9761e-01, time/batch = 0.6558s	
4459/33250 (epoch 6.705), train_loss = 1.12752460, grad/param norm = 1.5925e-01, time/batch = 0.6509s	
4460/33250 (epoch 6.707), train_loss = 1.09140598, grad/param norm = 1.6268e-01, time/batch = 0.6535s	
4461/33250 (epoch 6.708), train_loss = 1.31040495, grad/param norm = 1.7524e-01, time/batch = 0.6519s	
4462/33250 (epoch 6.710), train_loss = 1.35946131, grad/param norm = 1.6761e-01, time/batch = 0.6510s	
4463/33250 (epoch 6.711), train_loss = 1.31698890, grad/param norm = 2.0133e-01, time/batch = 0.6496s	
4464/33250 (epoch 6.713), train_loss = 1.35587037, grad/param norm = 1.7788e-01, time/batch = 0.6550s	
4465/33250 (epoch 6.714), train_loss = 1.30122970, grad/param norm = 1.7329e-01, time/batch = 0.6572s	
4466/33250 (epoch 6.716), train_loss = 1.41405204, grad/param norm = 1.9091e-01, time/batch = 0.6487s	
4467/33250 (epoch 6.717), train_loss = 1.19067645, grad/param norm = 1.5809e-01, time/batch = 0.6485s	
4468/33250 (epoch 6.719), train_loss = 1.27172084, grad/param norm = 1.6761e-01, time/batch = 0.6508s	
4469/33250 (epoch 6.720), train_loss = 1.51810124, grad/param norm = 1.6958e-01, time/batch = 0.6549s	
4470/33250 (epoch 6.722), train_loss = 1.16421625, grad/param norm = 1.5635e-01, time/batch = 0.6706s	
4471/33250 (epoch 6.723), train_loss = 1.04134292, grad/param norm = 1.5677e-01, time/batch = 0.6662s	
4472/33250 (epoch 6.725), train_loss = 1.05611814, grad/param norm = 1.4441e-01, time/batch = 0.6614s	
4473/33250 (epoch 6.726), train_loss = 1.16755080, grad/param norm = 1.4842e-01, time/batch = 0.6559s	
4474/33250 (epoch 6.728), train_loss = 1.32331981, grad/param norm = 1.6792e-01, time/batch = 0.6474s	
4475/33250 (epoch 6.729), train_loss = 1.45108345, grad/param norm = 1.8836e-01, time/batch = 0.6529s	
4476/33250 (epoch 6.731), train_loss = 1.21380367, grad/param norm = 1.7202e-01, time/batch = 0.6509s	
4477/33250 (epoch 6.732), train_loss = 1.15444467, grad/param norm = 1.5805e-01, time/batch = 0.6614s	
4478/33250 (epoch 6.734), train_loss = 1.29939016, grad/param norm = 1.6404e-01, time/batch = 0.6564s	
4479/33250 (epoch 6.735), train_loss = 1.28259276, grad/param norm = 1.7671e-01, time/batch = 0.6552s	
4480/33250 (epoch 6.737), train_loss = 1.30287968, grad/param norm = 1.5499e-01, time/batch = 0.6593s	
4481/33250 (epoch 6.738), train_loss = 1.25597526, grad/param norm = 1.6078e-01, time/batch = 0.6584s	
4482/33250 (epoch 6.740), train_loss = 1.43877047, grad/param norm = 1.7662e-01, time/batch = 0.6475s	
4483/33250 (epoch 6.741), train_loss = 1.32705897, grad/param norm = 1.6768e-01, time/batch = 0.6543s	
4484/33250 (epoch 6.743), train_loss = 1.22273133, grad/param norm = 1.6702e-01, time/batch = 0.6500s	
4485/33250 (epoch 6.744), train_loss = 1.23712341, grad/param norm = 1.5523e-01, time/batch = 0.6463s	
4486/33250 (epoch 6.746), train_loss = 1.27143660, grad/param norm = 1.5049e-01, time/batch = 0.6511s	
4487/33250 (epoch 6.747), train_loss = 1.21028513, grad/param norm = 1.6739e-01, time/batch = 0.6540s	
4488/33250 (epoch 6.749), train_loss = 1.45202973, grad/param norm = 1.9417e-01, time/batch = 0.6521s	
4489/33250 (epoch 6.750), train_loss = 1.28436386, grad/param norm = 1.7089e-01, time/batch = 0.6745s	
4490/33250 (epoch 6.752), train_loss = 1.13894864, grad/param norm = 1.6542e-01, time/batch = 0.6648s	
4491/33250 (epoch 6.753), train_loss = 1.23440718, grad/param norm = 1.5779e-01, time/batch = 0.6523s	
4492/33250 (epoch 6.755), train_loss = 1.18599601, grad/param norm = 1.5882e-01, time/batch = 0.6535s	
4493/33250 (epoch 6.756), train_loss = 1.37043951, grad/param norm = 1.8588e-01, time/batch = 0.6503s	
4494/33250 (epoch 6.758), train_loss = 1.37791761, grad/param norm = 1.8034e-01, time/batch = 0.6556s	
4495/33250 (epoch 6.759), train_loss = 1.14333345, grad/param norm = 1.5140e-01, time/batch = 0.6485s	
4496/33250 (epoch 6.761), train_loss = 1.19518167, grad/param norm = 1.6593e-01, time/batch = 0.6521s	
4497/33250 (epoch 6.762), train_loss = 1.32796926, grad/param norm = 1.6550e-01, time/batch = 0.6468s	
4498/33250 (epoch 6.764), train_loss = 1.19755640, grad/param norm = 1.9440e-01, time/batch = 0.6565s	
4499/33250 (epoch 6.765), train_loss = 1.29128468, grad/param norm = 1.7796e-01, time/batch = 0.6564s	
4500/33250 (epoch 6.767), train_loss = 1.05583193, grad/param norm = 1.6167e-01, time/batch = 0.6657s	
4501/33250 (epoch 6.768), train_loss = 1.12940856, grad/param norm = 1.6866e-01, time/batch = 0.6761s	
4502/33250 (epoch 6.770), train_loss = 1.32807810, grad/param norm = 1.9335e-01, time/batch = 0.6631s	
4503/33250 (epoch 6.771), train_loss = 1.33310447, grad/param norm = 1.7908e-01, time/batch = 0.6734s	
4504/33250 (epoch 6.773), train_loss = 1.24907805, grad/param norm = 1.7958e-01, time/batch = 0.6737s	
4505/33250 (epoch 6.774), train_loss = 1.07159647, grad/param norm = 1.6267e-01, time/batch = 0.6722s	
4506/33250 (epoch 6.776), train_loss = 1.20394162, grad/param norm = 1.7520e-01, time/batch = 0.6690s	
4507/33250 (epoch 6.777), train_loss = 1.37125299, grad/param norm = 2.1053e-01, time/batch = 0.6607s	
4508/33250 (epoch 6.779), train_loss = 1.15726771, grad/param norm = 1.5761e-01, time/batch = 0.6565s	
4509/33250 (epoch 6.780), train_loss = 1.49048290, grad/param norm = 1.9463e-01, time/batch = 0.6547s	
4510/33250 (epoch 6.782), train_loss = 1.28352278, grad/param norm = 1.5963e-01, time/batch = 0.6565s	
4511/33250 (epoch 6.783), train_loss = 1.02388658, grad/param norm = 1.5432e-01, time/batch = 0.6534s	
4512/33250 (epoch 6.785), train_loss = 1.14634028, grad/param norm = 1.7582e-01, time/batch = 0.6501s	
4513/33250 (epoch 6.786), train_loss = 1.35514005, grad/param norm = 1.7218e-01, time/batch = 0.6755s	
4514/33250 (epoch 6.788), train_loss = 1.28609446, grad/param norm = 1.6252e-01, time/batch = 0.6696s	
4515/33250 (epoch 6.789), train_loss = 1.36732348, grad/param norm = 1.7805e-01, time/batch = 0.6707s	
4516/33250 (epoch 6.791), train_loss = 1.41019478, grad/param norm = 1.7335e-01, time/batch = 0.6775s	
4517/33250 (epoch 6.792), train_loss = 1.47424531, grad/param norm = 1.6622e-01, time/batch = 0.6568s	
4518/33250 (epoch 6.794), train_loss = 1.23497407, grad/param norm = 1.8730e-01, time/batch = 0.6513s	
4519/33250 (epoch 6.795), train_loss = 1.31349762, grad/param norm = 1.7197e-01, time/batch = 0.6481s	
4520/33250 (epoch 6.797), train_loss = 1.41065075, grad/param norm = 2.0255e-01, time/batch = 0.6699s	
4521/33250 (epoch 6.798), train_loss = 1.32602773, grad/param norm = 2.0310e-01, time/batch = 0.6788s	
4522/33250 (epoch 6.800), train_loss = 1.37120312, grad/param norm = 1.9491e-01, time/batch = 0.6802s	
4523/33250 (epoch 6.802), train_loss = 1.20461986, grad/param norm = 1.6595e-01, time/batch = 0.6690s	
4524/33250 (epoch 6.803), train_loss = 1.21920698, grad/param norm = 1.6696e-01, time/batch = 0.6649s	
4525/33250 (epoch 6.805), train_loss = 1.30752275, grad/param norm = 1.7314e-01, time/batch = 0.6472s	
4526/33250 (epoch 6.806), train_loss = 1.34247439, grad/param norm = 1.7347e-01, time/batch = 0.6496s	
4527/33250 (epoch 6.808), train_loss = 1.26954649, grad/param norm = 1.7839e-01, time/batch = 0.6469s	
4528/33250 (epoch 6.809), train_loss = 1.13558811, grad/param norm = 1.6748e-01, time/batch = 0.6477s	
4529/33250 (epoch 6.811), train_loss = 1.16748969, grad/param norm = 1.6885e-01, time/batch = 0.6464s	
4530/33250 (epoch 6.812), train_loss = 1.31883710, grad/param norm = 1.7488e-01, time/batch = 0.6563s	
4531/33250 (epoch 6.814), train_loss = 1.26878096, grad/param norm = 1.7470e-01, time/batch = 0.6551s	
4532/33250 (epoch 6.815), train_loss = 1.32198207, grad/param norm = 1.8069e-01, time/batch = 0.6562s	
4533/33250 (epoch 6.817), train_loss = 1.25849204, grad/param norm = 1.7134e-01, time/batch = 0.6465s	
4534/33250 (epoch 6.818), train_loss = 1.15668929, grad/param norm = 1.6029e-01, time/batch = 0.6520s	
4535/33250 (epoch 6.820), train_loss = 1.28158309, grad/param norm = 1.7178e-01, time/batch = 0.6525s	
4536/33250 (epoch 6.821), train_loss = 1.16496539, grad/param norm = 1.5952e-01, time/batch = 0.6495s	
4537/33250 (epoch 6.823), train_loss = 1.56382745, grad/param norm = 2.0986e-01, time/batch = 0.6529s	
4538/33250 (epoch 6.824), train_loss = 1.26968152, grad/param norm = 1.6718e-01, time/batch = 0.6511s	
4539/33250 (epoch 6.826), train_loss = 1.27322234, grad/param norm = 1.8690e-01, time/batch = 0.6468s	
4540/33250 (epoch 6.827), train_loss = 1.02532324, grad/param norm = 1.5374e-01, time/batch = 0.6518s	
4541/33250 (epoch 6.829), train_loss = 1.25835707, grad/param norm = 1.8048e-01, time/batch = 0.6524s	
4542/33250 (epoch 6.830), train_loss = 1.44235980, grad/param norm = 1.9717e-01, time/batch = 0.6622s	
4543/33250 (epoch 6.832), train_loss = 1.22514766, grad/param norm = 1.5977e-01, time/batch = 0.6538s	
4544/33250 (epoch 6.833), train_loss = 1.31008496, grad/param norm = 1.6600e-01, time/batch = 0.6526s	
4545/33250 (epoch 6.835), train_loss = 1.24727467, grad/param norm = 2.1944e-01, time/batch = 0.6641s	
4546/33250 (epoch 6.836), train_loss = 1.26847973, grad/param norm = 1.5925e-01, time/batch = 0.6512s	
4547/33250 (epoch 6.838), train_loss = 1.20391738, grad/param norm = 1.6797e-01, time/batch = 0.6552s	
4548/33250 (epoch 6.839), train_loss = 1.22335223, grad/param norm = 1.7299e-01, time/batch = 0.6541s	
4549/33250 (epoch 6.841), train_loss = 1.06648108, grad/param norm = 1.4401e-01, time/batch = 0.6508s	
4550/33250 (epoch 6.842), train_loss = 1.40075217, grad/param norm = 1.6683e-01, time/batch = 0.6540s	
4551/33250 (epoch 6.844), train_loss = 1.39240035, grad/param norm = 1.7993e-01, time/batch = 0.6554s	
4552/33250 (epoch 6.845), train_loss = 1.55504510, grad/param norm = 2.1496e-01, time/batch = 0.6508s	
4553/33250 (epoch 6.847), train_loss = 1.46482949, grad/param norm = 1.8383e-01, time/batch = 0.6563s	
4554/33250 (epoch 6.848), train_loss = 1.56561750, grad/param norm = 2.0002e-01, time/batch = 0.6555s	
4555/33250 (epoch 6.850), train_loss = 1.35522696, grad/param norm = 1.7558e-01, time/batch = 0.6608s	
4556/33250 (epoch 6.851), train_loss = 1.19740719, grad/param norm = 1.6835e-01, time/batch = 0.6555s	
4557/33250 (epoch 6.853), train_loss = 1.32791050, grad/param norm = 1.9682e-01, time/batch = 0.6493s	
4558/33250 (epoch 6.854), train_loss = 1.14058124, grad/param norm = 1.5614e-01, time/batch = 0.6506s	
4559/33250 (epoch 6.856), train_loss = 1.16258404, grad/param norm = 1.6049e-01, time/batch = 0.6527s	
4560/33250 (epoch 6.857), train_loss = 1.06820902, grad/param norm = 1.5001e-01, time/batch = 0.6544s	
4561/33250 (epoch 6.859), train_loss = 1.07483511, grad/param norm = 1.5041e-01, time/batch = 0.6606s	
4562/33250 (epoch 6.860), train_loss = 1.24656386, grad/param norm = 1.4878e-01, time/batch = 0.6550s	
4563/33250 (epoch 6.862), train_loss = 1.12190333, grad/param norm = 1.4103e-01, time/batch = 0.6505s	
4564/33250 (epoch 6.863), train_loss = 1.15183717, grad/param norm = 1.5468e-01, time/batch = 0.6531s	
4565/33250 (epoch 6.865), train_loss = 1.31419710, grad/param norm = 1.6871e-01, time/batch = 0.6504s	
4566/33250 (epoch 6.866), train_loss = 1.17800137, grad/param norm = 1.6885e-01, time/batch = 0.6521s	
4567/33250 (epoch 6.868), train_loss = 1.53625343, grad/param norm = 2.3493e-01, time/batch = 0.6473s	
4568/33250 (epoch 6.869), train_loss = 1.33601475, grad/param norm = 1.8485e-01, time/batch = 0.6550s	
4569/33250 (epoch 6.871), train_loss = 1.03307113, grad/param norm = 1.5050e-01, time/batch = 0.6510s	
4570/33250 (epoch 6.872), train_loss = 1.30305673, grad/param norm = 1.7172e-01, time/batch = 0.6513s	
4571/33250 (epoch 6.874), train_loss = 1.18967100, grad/param norm = 1.6890e-01, time/batch = 0.6509s	
4572/33250 (epoch 6.875), train_loss = 1.19814551, grad/param norm = 1.8533e-01, time/batch = 0.6538s	
4573/33250 (epoch 6.877), train_loss = 1.32547878, grad/param norm = 1.7659e-01, time/batch = 0.6477s	
4574/33250 (epoch 6.878), train_loss = 1.27309887, grad/param norm = 1.6015e-01, time/batch = 0.6481s	
4575/33250 (epoch 6.880), train_loss = 1.28560150, grad/param norm = 1.8655e-01, time/batch = 0.6484s	
4576/33250 (epoch 6.881), train_loss = 1.47446759, grad/param norm = 1.7639e-01, time/batch = 0.6461s	
4577/33250 (epoch 6.883), train_loss = 1.28542733, grad/param norm = 1.7392e-01, time/batch = 0.6489s	
4578/33250 (epoch 6.884), train_loss = 1.26621210, grad/param norm = 1.9313e-01, time/batch = 0.6478s	
4579/33250 (epoch 6.886), train_loss = 1.13283077, grad/param norm = 1.4000e-01, time/batch = 0.6664s	
4580/33250 (epoch 6.887), train_loss = 1.21715256, grad/param norm = 1.6063e-01, time/batch = 0.6815s	
4581/33250 (epoch 6.889), train_loss = 1.16585553, grad/param norm = 1.3435e-01, time/batch = 0.6670s	
4582/33250 (epoch 6.890), train_loss = 1.06280899, grad/param norm = 1.4003e-01, time/batch = 0.6569s	
4583/33250 (epoch 6.892), train_loss = 1.34506688, grad/param norm = 1.6327e-01, time/batch = 0.6554s	
4584/33250 (epoch 6.893), train_loss = 1.35700158, grad/param norm = 1.7471e-01, time/batch = 0.6505s	
4585/33250 (epoch 6.895), train_loss = 1.20626614, grad/param norm = 1.6737e-01, time/batch = 0.6485s	
4586/33250 (epoch 6.896), train_loss = 1.32146545, grad/param norm = 1.7303e-01, time/batch = 0.6488s	
4587/33250 (epoch 6.898), train_loss = 1.18415779, grad/param norm = 1.6978e-01, time/batch = 0.6659s	
4588/33250 (epoch 6.899), train_loss = 1.19292510, grad/param norm = 1.7029e-01, time/batch = 0.6432s	
4589/33250 (epoch 6.901), train_loss = 1.06684311, grad/param norm = 1.4825e-01, time/batch = 0.6503s	
4590/33250 (epoch 6.902), train_loss = 1.20996524, grad/param norm = 1.6941e-01, time/batch = 0.6465s	
4591/33250 (epoch 6.904), train_loss = 1.15100968, grad/param norm = 1.4911e-01, time/batch = 0.6443s	
4592/33250 (epoch 6.905), train_loss = 1.17546761, grad/param norm = 1.6098e-01, time/batch = 0.6467s	
4593/33250 (epoch 6.907), train_loss = 1.17887242, grad/param norm = 1.6353e-01, time/batch = 0.6430s	
4594/33250 (epoch 6.908), train_loss = 1.25971546, grad/param norm = 1.5663e-01, time/batch = 0.6490s	
4595/33250 (epoch 6.910), train_loss = 1.36273622, grad/param norm = 1.8396e-01, time/batch = 0.6468s	
4596/33250 (epoch 6.911), train_loss = 1.02000999, grad/param norm = 1.5228e-01, time/batch = 0.6489s	
4597/33250 (epoch 6.913), train_loss = 1.20515753, grad/param norm = 1.5682e-01, time/batch = 0.6484s	
4598/33250 (epoch 6.914), train_loss = 1.04441959, grad/param norm = 1.6318e-01, time/batch = 0.6467s	
4599/33250 (epoch 6.916), train_loss = 1.15120868, grad/param norm = 1.5343e-01, time/batch = 0.6469s	
4600/33250 (epoch 6.917), train_loss = 1.14836632, grad/param norm = 1.4269e-01, time/batch = 0.6439s	
4601/33250 (epoch 6.919), train_loss = 1.18742540, grad/param norm = 1.7411e-01, time/batch = 0.6482s	
4602/33250 (epoch 6.920), train_loss = 1.26586779, grad/param norm = 1.7106e-01, time/batch = 0.6465s	
4603/33250 (epoch 6.922), train_loss = 1.26575908, grad/param norm = 1.7460e-01, time/batch = 0.6456s	
4604/33250 (epoch 6.923), train_loss = 1.23030626, grad/param norm = 1.7587e-01, time/batch = 0.6476s	
4605/33250 (epoch 6.925), train_loss = 1.18737865, grad/param norm = 1.5373e-01, time/batch = 0.6446s	
4606/33250 (epoch 6.926), train_loss = 1.18248289, grad/param norm = 1.6776e-01, time/batch = 0.6661s	
4607/33250 (epoch 6.928), train_loss = 1.23079081, grad/param norm = 1.6519e-01, time/batch = 0.6745s	
4608/33250 (epoch 6.929), train_loss = 0.96820149, grad/param norm = 1.3618e-01, time/batch = 0.6654s	
4609/33250 (epoch 6.931), train_loss = 1.29284740, grad/param norm = 1.6454e-01, time/batch = 0.6532s	
4610/33250 (epoch 6.932), train_loss = 1.31746005, grad/param norm = 1.8407e-01, time/batch = 0.6507s	
4611/33250 (epoch 6.934), train_loss = 1.15442738, grad/param norm = 1.4586e-01, time/batch = 0.6549s	
4612/33250 (epoch 6.935), train_loss = 1.24924705, grad/param norm = 1.8729e-01, time/batch = 0.6510s	
4613/33250 (epoch 6.937), train_loss = 1.29678752, grad/param norm = 1.8869e-01, time/batch = 0.6840s	
4614/33250 (epoch 6.938), train_loss = 1.32851992, grad/param norm = 1.6686e-01, time/batch = 0.6593s	
4615/33250 (epoch 6.940), train_loss = 1.21556089, grad/param norm = 1.7258e-01, time/batch = 0.6518s	
4616/33250 (epoch 6.941), train_loss = 1.24866875, grad/param norm = 1.6559e-01, time/batch = 0.6762s	
4617/33250 (epoch 6.943), train_loss = 1.44361250, grad/param norm = 1.7599e-01, time/batch = 0.6622s	
4618/33250 (epoch 6.944), train_loss = 1.11452312, grad/param norm = 1.4619e-01, time/batch = 0.6669s	
4619/33250 (epoch 6.946), train_loss = 1.43954705, grad/param norm = 1.6646e-01, time/batch = 0.6566s	
4620/33250 (epoch 6.947), train_loss = 1.19391453, grad/param norm = 1.6398e-01, time/batch = 0.6543s	
4621/33250 (epoch 6.949), train_loss = 1.38573220, grad/param norm = 1.6932e-01, time/batch = 0.6553s	
4622/33250 (epoch 6.950), train_loss = 1.24459722, grad/param norm = 1.5430e-01, time/batch = 0.6882s	
4623/33250 (epoch 6.952), train_loss = 1.22524572, grad/param norm = 1.6814e-01, time/batch = 0.6668s	
4624/33250 (epoch 6.953), train_loss = 1.36489187, grad/param norm = 1.9145e-01, time/batch = 0.6598s	
4625/33250 (epoch 6.955), train_loss = 1.33480133, grad/param norm = 1.7287e-01, time/batch = 0.6533s	
4626/33250 (epoch 6.956), train_loss = 1.39138464, grad/param norm = 1.9595e-01, time/batch = 0.6605s	
4627/33250 (epoch 6.958), train_loss = 1.14519600, grad/param norm = 1.5620e-01, time/batch = 0.6838s	
4628/33250 (epoch 6.959), train_loss = 1.14021537, grad/param norm = 1.4618e-01, time/batch = 0.6834s	
4629/33250 (epoch 6.961), train_loss = 1.41760879, grad/param norm = 1.7063e-01, time/batch = 0.6650s	
4630/33250 (epoch 6.962), train_loss = 1.31371620, grad/param norm = 1.7328e-01, time/batch = 0.6539s	
4631/33250 (epoch 6.964), train_loss = 1.43095573, grad/param norm = 1.7123e-01, time/batch = 0.6609s	
4632/33250 (epoch 6.965), train_loss = 1.30458963, grad/param norm = 1.9788e-01, time/batch = 0.6592s	
4633/33250 (epoch 6.967), train_loss = 1.31285658, grad/param norm = 1.7340e-01, time/batch = 0.6590s	
4634/33250 (epoch 6.968), train_loss = 1.49131576, grad/param norm = 1.6669e-01, time/batch = 0.6637s	
4635/33250 (epoch 6.970), train_loss = 1.57660907, grad/param norm = 1.9572e-01, time/batch = 0.6751s	
4636/33250 (epoch 6.971), train_loss = 1.40845578, grad/param norm = 1.8928e-01, time/batch = 0.6565s	
4637/33250 (epoch 6.973), train_loss = 1.20390083, grad/param norm = 1.6171e-01, time/batch = 0.6558s	
4638/33250 (epoch 6.974), train_loss = 1.28734246, grad/param norm = 1.7363e-01, time/batch = 0.6537s	
4639/33250 (epoch 6.976), train_loss = 1.20098021, grad/param norm = 1.6638e-01, time/batch = 0.6603s	
4640/33250 (epoch 6.977), train_loss = 1.17452964, grad/param norm = 1.6670e-01, time/batch = 0.6578s	
4641/33250 (epoch 6.979), train_loss = 1.28628225, grad/param norm = 1.7348e-01, time/batch = 0.6562s	
4642/33250 (epoch 6.980), train_loss = 1.23366124, grad/param norm = 1.5332e-01, time/batch = 0.6572s	
4643/33250 (epoch 6.982), train_loss = 1.04343802, grad/param norm = 1.3931e-01, time/batch = 0.6597s	
4644/33250 (epoch 6.983), train_loss = 1.32298800, grad/param norm = 1.8677e-01, time/batch = 0.6541s	
4645/33250 (epoch 6.985), train_loss = 1.16367645, grad/param norm = 1.7245e-01, time/batch = 0.6554s	
4646/33250 (epoch 6.986), train_loss = 1.36449603, grad/param norm = 1.8156e-01, time/batch = 0.6559s	
4647/33250 (epoch 6.988), train_loss = 1.33789035, grad/param norm = 1.9360e-01, time/batch = 0.6586s	
4648/33250 (epoch 6.989), train_loss = 1.41203532, grad/param norm = 1.9027e-01, time/batch = 0.6567s	
4649/33250 (epoch 6.991), train_loss = 1.24882865, grad/param norm = 1.7034e-01, time/batch = 0.6559s	
4650/33250 (epoch 6.992), train_loss = 1.21598474, grad/param norm = 1.5877e-01, time/batch = 0.6557s	
4651/33250 (epoch 6.994), train_loss = 1.14643522, grad/param norm = 1.6448e-01, time/batch = 0.6620s	
4652/33250 (epoch 6.995), train_loss = 1.29654350, grad/param norm = 1.9964e-01, time/batch = 0.6581s	
4653/33250 (epoch 6.997), train_loss = 0.93325394, grad/param norm = 1.4488e-01, time/batch = 0.6564s	
4654/33250 (epoch 6.998), train_loss = 1.22515679, grad/param norm = 1.5376e-01, time/batch = 0.6594s	
4655/33250 (epoch 7.000), train_loss = 1.25682925, grad/param norm = 1.6515e-01, time/batch = 0.6578s	
4656/33250 (epoch 7.002), train_loss = 1.41367034, grad/param norm = 1.7970e-01, time/batch = 0.6603s	
4657/33250 (epoch 7.003), train_loss = 1.31966198, grad/param norm = 1.7054e-01, time/batch = 0.6612s	
4658/33250 (epoch 7.005), train_loss = 1.04659979, grad/param norm = 1.5578e-01, time/batch = 0.6594s	
4659/33250 (epoch 7.006), train_loss = 1.05569459, grad/param norm = 1.4218e-01, time/batch = 0.6651s	
4660/33250 (epoch 7.008), train_loss = 1.37088943, grad/param norm = 1.7846e-01, time/batch = 0.6590s	
4661/33250 (epoch 7.009), train_loss = 1.38961112, grad/param norm = 1.8079e-01, time/batch = 0.6614s	
4662/33250 (epoch 7.011), train_loss = 1.17308504, grad/param norm = 1.6278e-01, time/batch = 0.6630s	
4663/33250 (epoch 7.012), train_loss = 1.34061957, grad/param norm = 1.9377e-01, time/batch = 0.6627s	
4664/33250 (epoch 7.014), train_loss = 1.36999621, grad/param norm = 1.8229e-01, time/batch = 0.6574s	
4665/33250 (epoch 7.015), train_loss = 1.23754344, grad/param norm = 1.6678e-01, time/batch = 0.6574s	
4666/33250 (epoch 7.017), train_loss = 1.31001903, grad/param norm = 1.7919e-01, time/batch = 0.6463s	
4667/33250 (epoch 7.018), train_loss = 1.05297486, grad/param norm = 1.6427e-01, time/batch = 0.6451s	
4668/33250 (epoch 7.020), train_loss = 1.17567091, grad/param norm = 1.5519e-01, time/batch = 0.6451s	
4669/33250 (epoch 7.021), train_loss = 1.22635228, grad/param norm = 1.7156e-01, time/batch = 0.6469s	
4670/33250 (epoch 7.023), train_loss = 1.06560919, grad/param norm = 1.7852e-01, time/batch = 0.6443s	
4671/33250 (epoch 7.024), train_loss = 1.32062604, grad/param norm = 1.7032e-01, time/batch = 0.6539s	
4672/33250 (epoch 7.026), train_loss = 1.24168487, grad/param norm = 1.5007e-01, time/batch = 0.6570s	
4673/33250 (epoch 7.027), train_loss = 1.18996237, grad/param norm = 1.5367e-01, time/batch = 0.6472s	
4674/33250 (epoch 7.029), train_loss = 1.26336850, grad/param norm = 1.6756e-01, time/batch = 0.6461s	
4675/33250 (epoch 7.030), train_loss = 1.22369696, grad/param norm = 1.7014e-01, time/batch = 0.6432s	
4676/33250 (epoch 7.032), train_loss = 1.50250732, grad/param norm = 2.0126e-01, time/batch = 0.6480s	
4677/33250 (epoch 7.033), train_loss = 1.21215794, grad/param norm = 1.7460e-01, time/batch = 0.6445s	
4678/33250 (epoch 7.035), train_loss = 1.17331095, grad/param norm = 1.7940e-01, time/batch = 0.6518s	
4679/33250 (epoch 7.036), train_loss = 1.33611367, grad/param norm = 1.8799e-01, time/batch = 0.6433s	
4680/33250 (epoch 7.038), train_loss = 1.17540915, grad/param norm = 1.6462e-01, time/batch = 0.6429s	
4681/33250 (epoch 7.039), train_loss = 1.08911989, grad/param norm = 1.4711e-01, time/batch = 0.6485s	
4682/33250 (epoch 7.041), train_loss = 1.32440979, grad/param norm = 1.7675e-01, time/batch = 0.6754s	
4683/33250 (epoch 7.042), train_loss = 1.05583431, grad/param norm = 1.4696e-01, time/batch = 0.6639s	
4684/33250 (epoch 7.044), train_loss = 1.39425284, grad/param norm = 1.7905e-01, time/batch = 0.6670s	
4685/33250 (epoch 7.045), train_loss = 1.35131112, grad/param norm = 1.5838e-01, time/batch = 0.6652s	
4686/33250 (epoch 7.047), train_loss = 1.36936439, grad/param norm = 1.8851e-01, time/batch = 0.6586s	
4687/33250 (epoch 7.048), train_loss = 1.47073963, grad/param norm = 1.9513e-01, time/batch = 0.6451s	
4688/33250 (epoch 7.050), train_loss = 1.19974893, grad/param norm = 1.6234e-01, time/batch = 0.6501s	
4689/33250 (epoch 7.051), train_loss = 1.23509454, grad/param norm = 1.5107e-01, time/batch = 0.6552s	
4690/33250 (epoch 7.053), train_loss = 1.29492348, grad/param norm = 1.7379e-01, time/batch = 0.6430s	
4691/33250 (epoch 7.054), train_loss = 1.06541078, grad/param norm = 1.4463e-01, time/batch = 0.6501s	
4692/33250 (epoch 7.056), train_loss = 1.09818833, grad/param norm = 1.6197e-01, time/batch = 0.6485s	
4693/33250 (epoch 7.057), train_loss = 1.24019512, grad/param norm = 1.5060e-01, time/batch = 0.6629s	
4694/33250 (epoch 7.059), train_loss = 1.18449417, grad/param norm = 1.5859e-01, time/batch = 0.6576s	
4695/33250 (epoch 7.060), train_loss = 1.30563142, grad/param norm = 1.7591e-01, time/batch = 0.6628s	
4696/33250 (epoch 7.062), train_loss = 1.40299829, grad/param norm = 1.7050e-01, time/batch = 0.6680s	
4697/33250 (epoch 7.063), train_loss = 1.36663971, grad/param norm = 1.5417e-01, time/batch = 0.6738s	
4698/33250 (epoch 7.065), train_loss = 1.22457864, grad/param norm = 1.5957e-01, time/batch = 0.6742s	
4699/33250 (epoch 7.066), train_loss = 1.31932202, grad/param norm = 1.7066e-01, time/batch = 0.6689s	
4700/33250 (epoch 7.068), train_loss = 1.25230387, grad/param norm = 1.6996e-01, time/batch = 0.6662s	
4701/33250 (epoch 7.069), train_loss = 1.27181767, grad/param norm = 1.6515e-01, time/batch = 0.6703s	
4702/33250 (epoch 7.071), train_loss = 1.09930701, grad/param norm = 1.5880e-01, time/batch = 0.6750s	
4703/33250 (epoch 7.072), train_loss = 1.14452959, grad/param norm = 1.5329e-01, time/batch = 0.6734s	
4704/33250 (epoch 7.074), train_loss = 1.28538430, grad/param norm = 1.6180e-01, time/batch = 0.6650s	
4705/33250 (epoch 7.075), train_loss = 1.12790667, grad/param norm = 1.4834e-01, time/batch = 0.6566s	
4706/33250 (epoch 7.077), train_loss = 1.25759788, grad/param norm = 1.6901e-01, time/batch = 0.6561s	
4707/33250 (epoch 7.078), train_loss = 1.17373082, grad/param norm = 1.6320e-01, time/batch = 0.6709s	
4708/33250 (epoch 7.080), train_loss = 1.33717252, grad/param norm = 1.9586e-01, time/batch = 0.6648s	
4709/33250 (epoch 7.081), train_loss = 1.30042407, grad/param norm = 1.7350e-01, time/batch = 0.6673s	
4710/33250 (epoch 7.083), train_loss = 1.34787120, grad/param norm = 1.6315e-01, time/batch = 0.6617s	
4711/33250 (epoch 7.084), train_loss = 1.22306197, grad/param norm = 1.8410e-01, time/batch = 0.6577s	
4712/33250 (epoch 7.086), train_loss = 1.14759634, grad/param norm = 1.4390e-01, time/batch = 0.6520s	
4713/33250 (epoch 7.087), train_loss = 1.07600980, grad/param norm = 1.5492e-01, time/batch = 0.6551s	
4714/33250 (epoch 7.089), train_loss = 1.28651083, grad/param norm = 1.6868e-01, time/batch = 0.6594s	
4715/33250 (epoch 7.090), train_loss = 1.17903409, grad/param norm = 1.7218e-01, time/batch = 0.6495s	
4716/33250 (epoch 7.092), train_loss = 1.12226425, grad/param norm = 1.4386e-01, time/batch = 0.6722s	
4717/33250 (epoch 7.093), train_loss = 1.23769111, grad/param norm = 1.6226e-01, time/batch = 0.6678s	
4718/33250 (epoch 7.095), train_loss = 1.18130958, grad/param norm = 1.5322e-01, time/batch = 0.6582s	
4719/33250 (epoch 7.096), train_loss = 1.02282605, grad/param norm = 1.4837e-01, time/batch = 0.6517s	
4720/33250 (epoch 7.098), train_loss = 1.12562013, grad/param norm = 1.6803e-01, time/batch = 0.6575s	
4721/33250 (epoch 7.099), train_loss = 0.93354401, grad/param norm = 1.4819e-01, time/batch = 0.6531s	
4722/33250 (epoch 7.101), train_loss = 1.18287501, grad/param norm = 1.5407e-01, time/batch = 0.6639s	
4723/33250 (epoch 7.102), train_loss = 1.09932759, grad/param norm = 1.6134e-01, time/batch = 0.6618s	
4724/33250 (epoch 7.104), train_loss = 1.00327838, grad/param norm = 1.4878e-01, time/batch = 0.6548s	
4725/33250 (epoch 7.105), train_loss = 1.15320265, grad/param norm = 1.6413e-01, time/batch = 0.6554s	
4726/33250 (epoch 7.107), train_loss = 1.01600642, grad/param norm = 1.5877e-01, time/batch = 0.6505s	
4727/33250 (epoch 7.108), train_loss = 1.21803714, grad/param norm = 1.6517e-01, time/batch = 0.6509s	
4728/33250 (epoch 7.110), train_loss = 0.97786215, grad/param norm = 1.3859e-01, time/batch = 0.6500s	
4729/33250 (epoch 7.111), train_loss = 1.19639744, grad/param norm = 1.6537e-01, time/batch = 0.6517s	
4730/33250 (epoch 7.113), train_loss = 1.19314561, grad/param norm = 1.6570e-01, time/batch = 0.6599s	
4731/33250 (epoch 7.114), train_loss = 1.10889631, grad/param norm = 1.6573e-01, time/batch = 0.6564s	
4732/33250 (epoch 7.116), train_loss = 1.25827811, grad/param norm = 1.7430e-01, time/batch = 0.6693s	
4733/33250 (epoch 7.117), train_loss = 1.19309236, grad/param norm = 1.5828e-01, time/batch = 0.6741s	
4734/33250 (epoch 7.119), train_loss = 1.17908835, grad/param norm = 1.6101e-01, time/batch = 0.6630s	
4735/33250 (epoch 7.120), train_loss = 0.94054271, grad/param norm = 1.4386e-01, time/batch = 0.6483s	
4736/33250 (epoch 7.122), train_loss = 1.34549440, grad/param norm = 1.6035e-01, time/batch = 0.6566s	
4737/33250 (epoch 7.123), train_loss = 1.28606886, grad/param norm = 1.6023e-01, time/batch = 0.6563s	
4738/33250 (epoch 7.125), train_loss = 1.00927872, grad/param norm = 1.5187e-01, time/batch = 0.6605s	
4739/33250 (epoch 7.126), train_loss = 1.21614059, grad/param norm = 1.8297e-01, time/batch = 0.6544s	
4740/33250 (epoch 7.128), train_loss = 1.10262896, grad/param norm = 1.6443e-01, time/batch = 0.6573s	
4741/33250 (epoch 7.129), train_loss = 1.18215492, grad/param norm = 1.5698e-01, time/batch = 0.6537s	
4742/33250 (epoch 7.131), train_loss = 1.21537339, grad/param norm = 1.8358e-01, time/batch = 0.6565s	
4743/33250 (epoch 7.132), train_loss = 1.21228604, grad/param norm = 1.6927e-01, time/batch = 0.6587s	
4744/33250 (epoch 7.134), train_loss = 1.23156530, grad/param norm = 1.5676e-01, time/batch = 0.6593s	
4745/33250 (epoch 7.135), train_loss = 1.28658109, grad/param norm = 1.6844e-01, time/batch = 0.6568s	
4746/33250 (epoch 7.137), train_loss = 1.09603113, grad/param norm = 1.6370e-01, time/batch = 0.6553s	
4747/33250 (epoch 7.138), train_loss = 1.14258237, grad/param norm = 1.4410e-01, time/batch = 0.6499s	
4748/33250 (epoch 7.140), train_loss = 0.99508680, grad/param norm = 1.5987e-01, time/batch = 0.6534s	
4749/33250 (epoch 7.141), train_loss = 1.54558908, grad/param norm = 2.1595e-01, time/batch = 0.6555s	
4750/33250 (epoch 7.143), train_loss = 0.97342793, grad/param norm = 1.5603e-01, time/batch = 0.6572s	
4751/33250 (epoch 7.144), train_loss = 1.11981678, grad/param norm = 1.5962e-01, time/batch = 0.6532s	
4752/33250 (epoch 7.146), train_loss = 1.11037107, grad/param norm = 1.4926e-01, time/batch = 0.6484s	
4753/33250 (epoch 7.147), train_loss = 1.11116882, grad/param norm = 1.5704e-01, time/batch = 0.6494s	
4754/33250 (epoch 7.149), train_loss = 1.19399387, grad/param norm = 1.5849e-01, time/batch = 0.6740s	
4755/33250 (epoch 7.150), train_loss = 1.06116221, grad/param norm = 1.5869e-01, time/batch = 0.6649s	
4756/33250 (epoch 7.152), train_loss = 1.05963322, grad/param norm = 1.6698e-01, time/batch = 0.6525s	
4757/33250 (epoch 7.153), train_loss = 1.40232031, grad/param norm = 1.8529e-01, time/batch = 0.6502s	
4758/33250 (epoch 7.155), train_loss = 1.27697279, grad/param norm = 1.9349e-01, time/batch = 0.6501s	
4759/33250 (epoch 7.156), train_loss = 1.36786430, grad/param norm = 1.7461e-01, time/batch = 0.6546s	
4760/33250 (epoch 7.158), train_loss = 1.48620479, grad/param norm = 1.9447e-01, time/batch = 0.6564s	
4761/33250 (epoch 7.159), train_loss = 1.23135820, grad/param norm = 1.8297e-01, time/batch = 0.6583s	
4762/33250 (epoch 7.161), train_loss = 1.29873434, grad/param norm = 1.8484e-01, time/batch = 0.6555s	
4763/33250 (epoch 7.162), train_loss = 1.12812284, grad/param norm = 1.6361e-01, time/batch = 0.6674s	
4764/33250 (epoch 7.164), train_loss = 1.26283138, grad/param norm = 1.7090e-01, time/batch = 0.6611s	
4765/33250 (epoch 7.165), train_loss = 1.32056781, grad/param norm = 1.7497e-01, time/batch = 0.6811s	
4766/33250 (epoch 7.167), train_loss = 1.31580086, grad/param norm = 1.6297e-01, time/batch = 0.6643s	
4767/33250 (epoch 7.168), train_loss = 1.04565651, grad/param norm = 1.4154e-01, time/batch = 0.6638s	
4768/33250 (epoch 7.170), train_loss = 1.14131839, grad/param norm = 1.5385e-01, time/batch = 0.6689s	
4769/33250 (epoch 7.171), train_loss = 1.16810464, grad/param norm = 1.5377e-01, time/batch = 0.6670s	
4770/33250 (epoch 7.173), train_loss = 1.14774624, grad/param norm = 1.5950e-01, time/batch = 0.6620s	
4771/33250 (epoch 7.174), train_loss = 1.19717390, grad/param norm = 1.6544e-01, time/batch = 0.6627s	
4772/33250 (epoch 7.176), train_loss = 1.24382956, grad/param norm = 1.6411e-01, time/batch = 0.6684s	
4773/33250 (epoch 7.177), train_loss = 1.07477899, grad/param norm = 1.3581e-01, time/batch = 0.6718s	
4774/33250 (epoch 7.179), train_loss = 1.13831860, grad/param norm = 1.6114e-01, time/batch = 0.6690s	
4775/33250 (epoch 7.180), train_loss = 1.05711417, grad/param norm = 1.5005e-01, time/batch = 0.6793s	
4776/33250 (epoch 7.182), train_loss = 1.18890030, grad/param norm = 1.7841e-01, time/batch = 0.6867s	
4777/33250 (epoch 7.183), train_loss = 1.37189929, grad/param norm = 1.6471e-01, time/batch = 0.6841s	
4778/33250 (epoch 7.185), train_loss = 1.31250372, grad/param norm = 1.8968e-01, time/batch = 0.6845s	
4779/33250 (epoch 7.186), train_loss = 1.19911430, grad/param norm = 1.5678e-01, time/batch = 0.6823s	
4780/33250 (epoch 7.188), train_loss = 1.31482580, grad/param norm = 1.7565e-01, time/batch = 0.6766s	
4781/33250 (epoch 7.189), train_loss = 1.03310473, grad/param norm = 1.7362e-01, time/batch = 0.6624s	
4782/33250 (epoch 7.191), train_loss = 1.15086581, grad/param norm = 1.7714e-01, time/batch = 0.6605s	
4783/33250 (epoch 7.192), train_loss = 1.09935352, grad/param norm = 1.4668e-01, time/batch = 0.6567s	
4784/33250 (epoch 7.194), train_loss = 1.10445006, grad/param norm = 1.7494e-01, time/batch = 0.6618s	
4785/33250 (epoch 7.195), train_loss = 1.35788490, grad/param norm = 1.5683e-01, time/batch = 0.6704s	
4786/33250 (epoch 7.197), train_loss = 1.19791493, grad/param norm = 1.6560e-01, time/batch = 0.6801s	
4787/33250 (epoch 7.198), train_loss = 1.30270323, grad/param norm = 1.7148e-01, time/batch = 0.6865s	
4788/33250 (epoch 7.200), train_loss = 1.21201638, grad/param norm = 1.6226e-01, time/batch = 0.6968s	
4789/33250 (epoch 7.202), train_loss = 1.13199099, grad/param norm = 1.5811e-01, time/batch = 0.6965s	
4790/33250 (epoch 7.203), train_loss = 1.19536488, grad/param norm = 1.7376e-01, time/batch = 0.6869s	
4791/33250 (epoch 7.205), train_loss = 1.24433741, grad/param norm = 1.6292e-01, time/batch = 0.6871s	
4792/33250 (epoch 7.206), train_loss = 1.25644809, grad/param norm = 1.6818e-01, time/batch = 0.6878s	
4793/33250 (epoch 7.208), train_loss = 1.41752283, grad/param norm = 2.0348e-01, time/batch = 0.6887s	
4794/33250 (epoch 7.209), train_loss = 1.11733975, grad/param norm = 1.6209e-01, time/batch = 0.6890s	
4795/33250 (epoch 7.211), train_loss = 1.34059368, grad/param norm = 1.7370e-01, time/batch = 0.7015s	
4796/33250 (epoch 7.212), train_loss = 1.47448641, grad/param norm = 1.7715e-01, time/batch = 0.6946s	
4797/33250 (epoch 7.214), train_loss = 1.19127237, grad/param norm = 1.4404e-01, time/batch = 0.6924s	
4798/33250 (epoch 7.215), train_loss = 1.53895048, grad/param norm = 2.0313e-01, time/batch = 0.6862s	
4799/33250 (epoch 7.217), train_loss = 1.39819134, grad/param norm = 1.8527e-01, time/batch = 0.6790s	
4800/33250 (epoch 7.218), train_loss = 1.31132622, grad/param norm = 1.6486e-01, time/batch = 0.6817s	
4801/33250 (epoch 7.220), train_loss = 1.35070392, grad/param norm = 1.7679e-01, time/batch = 0.6884s	
4802/33250 (epoch 7.221), train_loss = 1.47549447, grad/param norm = 1.9326e-01, time/batch = 0.6842s	
4803/33250 (epoch 7.223), train_loss = 1.21095286, grad/param norm = 1.7710e-01, time/batch = 0.6800s	
4804/33250 (epoch 7.224), train_loss = 1.38287647, grad/param norm = 1.9926e-01, time/batch = 0.6707s	
4805/33250 (epoch 7.226), train_loss = 1.40298458, grad/param norm = 1.7229e-01, time/batch = 0.6706s	
4806/33250 (epoch 7.227), train_loss = 1.24590402, grad/param norm = 1.6370e-01, time/batch = 0.6713s	
4807/33250 (epoch 7.229), train_loss = 1.23077341, grad/param norm = 1.5216e-01, time/batch = 0.6637s	
4808/33250 (epoch 7.230), train_loss = 1.17020696, grad/param norm = 1.6692e-01, time/batch = 0.6659s	
4809/33250 (epoch 7.232), train_loss = 1.12136160, grad/param norm = 1.4112e-01, time/batch = 0.6823s	
4810/33250 (epoch 7.233), train_loss = 1.15717247, grad/param norm = 1.6162e-01, time/batch = 0.6747s	
4811/33250 (epoch 7.235), train_loss = 1.34472764, grad/param norm = 1.6747e-01, time/batch = 0.6806s	
4812/33250 (epoch 7.236), train_loss = 1.14243026, grad/param norm = 1.7177e-01, time/batch = 0.6776s	
4813/33250 (epoch 7.238), train_loss = 1.31669747, grad/param norm = 1.7380e-01, time/batch = 0.6711s	
4814/33250 (epoch 7.239), train_loss = 1.43108594, grad/param norm = 1.7962e-01, time/batch = 0.6722s	
4815/33250 (epoch 7.241), train_loss = 1.32906766, grad/param norm = 1.7909e-01, time/batch = 0.6612s	
4816/33250 (epoch 7.242), train_loss = 1.32792868, grad/param norm = 1.8145e-01, time/batch = 0.6636s	
4817/33250 (epoch 7.244), train_loss = 1.35325992, grad/param norm = 1.8570e-01, time/batch = 0.6504s	
4818/33250 (epoch 7.245), train_loss = 1.21810116, grad/param norm = 1.5249e-01, time/batch = 0.6550s	
4819/33250 (epoch 7.247), train_loss = 1.27187657, grad/param norm = 1.5447e-01, time/batch = 0.6496s	
4820/33250 (epoch 7.248), train_loss = 1.53070066, grad/param norm = 2.0028e-01, time/batch = 0.6510s	
4821/33250 (epoch 7.250), train_loss = 1.29186006, grad/param norm = 1.5250e-01, time/batch = 0.6536s	
4822/33250 (epoch 7.251), train_loss = 1.24203983, grad/param norm = 1.7700e-01, time/batch = 0.6568s	
4823/33250 (epoch 7.253), train_loss = 1.09473513, grad/param norm = 1.5378e-01, time/batch = 0.6595s	
4824/33250 (epoch 7.254), train_loss = 1.18412291, grad/param norm = 1.7274e-01, time/batch = 0.6609s	
4825/33250 (epoch 7.256), train_loss = 1.30374070, grad/param norm = 1.5918e-01, time/batch = 0.6558s	
4826/33250 (epoch 7.257), train_loss = 1.40178073, grad/param norm = 1.6677e-01, time/batch = 0.6587s	
4827/33250 (epoch 7.259), train_loss = 1.41778394, grad/param norm = 1.6372e-01, time/batch = 0.6776s	
4828/33250 (epoch 7.260), train_loss = 1.12984647, grad/param norm = 1.5278e-01, time/batch = 0.6655s	
4829/33250 (epoch 7.262), train_loss = 1.29524745, grad/param norm = 1.5928e-01, time/batch = 0.6643s	
4830/33250 (epoch 7.263), train_loss = 1.16273776, grad/param norm = 1.5034e-01, time/batch = 0.6646s	
4831/33250 (epoch 7.265), train_loss = 1.33745536, grad/param norm = 1.6040e-01, time/batch = 0.6657s	
4832/33250 (epoch 7.266), train_loss = 1.25608137, grad/param norm = 1.6785e-01, time/batch = 0.6682s	
4833/33250 (epoch 7.268), train_loss = 1.12885962, grad/param norm = 1.4672e-01, time/batch = 0.6757s	
4834/33250 (epoch 7.269), train_loss = 0.97876873, grad/param norm = 1.4819e-01, time/batch = 0.6694s	
4835/33250 (epoch 7.271), train_loss = 1.20928986, grad/param norm = 1.4969e-01, time/batch = 0.6688s	
4836/33250 (epoch 7.272), train_loss = 1.01662381, grad/param norm = 1.3463e-01, time/batch = 0.6682s	
4837/33250 (epoch 7.274), train_loss = 0.93827586, grad/param norm = 1.4100e-01, time/batch = 0.6579s	
4838/33250 (epoch 7.275), train_loss = 1.10394413, grad/param norm = 1.4012e-01, time/batch = 0.6461s	
4839/33250 (epoch 7.277), train_loss = 0.98208130, grad/param norm = 1.4381e-01, time/batch = 0.6517s	
4840/33250 (epoch 7.278), train_loss = 1.10401986, grad/param norm = 1.4595e-01, time/batch = 0.6489s	
4841/33250 (epoch 7.280), train_loss = 1.04243058, grad/param norm = 1.4267e-01, time/batch = 0.6515s	
4842/33250 (epoch 7.281), train_loss = 1.24572811, grad/param norm = 1.7335e-01, time/batch = 0.6516s	
4843/33250 (epoch 7.283), train_loss = 1.31066571, grad/param norm = 1.6250e-01, time/batch = 0.6691s	
4844/33250 (epoch 7.284), train_loss = 1.13084531, grad/param norm = 1.5157e-01, time/batch = 0.6673s	
4845/33250 (epoch 7.286), train_loss = 1.29305852, grad/param norm = 1.7560e-01, time/batch = 0.6486s	
4846/33250 (epoch 7.287), train_loss = 1.05573793, grad/param norm = 1.3943e-01, time/batch = 0.6541s	
4847/33250 (epoch 7.289), train_loss = 1.08296618, grad/param norm = 1.4493e-01, time/batch = 0.6592s	
4848/33250 (epoch 7.290), train_loss = 1.22095428, grad/param norm = 1.4946e-01, time/batch = 0.6524s	
4849/33250 (epoch 7.292), train_loss = 1.26365434, grad/param norm = 1.8684e-01, time/batch = 0.6551s	
4850/33250 (epoch 7.293), train_loss = 1.36648827, grad/param norm = 1.8471e-01, time/batch = 0.6498s	
4851/33250 (epoch 7.295), train_loss = 1.27589609, grad/param norm = 1.6616e-01, time/batch = 0.6535s	
4852/33250 (epoch 7.296), train_loss = 1.22153288, grad/param norm = 1.5437e-01, time/batch = 0.6510s	
4853/33250 (epoch 7.298), train_loss = 0.98770204, grad/param norm = 1.3040e-01, time/batch = 0.6509s	
4854/33250 (epoch 7.299), train_loss = 0.95705442, grad/param norm = 1.4220e-01, time/batch = 0.6486s	
4855/33250 (epoch 7.301), train_loss = 1.29042270, grad/param norm = 1.5796e-01, time/batch = 0.6522s	
4856/33250 (epoch 7.302), train_loss = 1.20161299, grad/param norm = 1.6091e-01, time/batch = 0.6517s	
4857/33250 (epoch 7.304), train_loss = 1.16374660, grad/param norm = 1.4016e-01, time/batch = 0.6502s	
4858/33250 (epoch 7.305), train_loss = 1.21414983, grad/param norm = 1.5425e-01, time/batch = 0.6565s	
4859/33250 (epoch 7.307), train_loss = 1.30579585, grad/param norm = 1.5714e-01, time/batch = 0.6498s	
4860/33250 (epoch 7.308), train_loss = 1.45969470, grad/param norm = 1.8693e-01, time/batch = 0.6500s	
4861/33250 (epoch 7.310), train_loss = 1.22169455, grad/param norm = 1.6464e-01, time/batch = 0.6528s	
4862/33250 (epoch 7.311), train_loss = 1.34487162, grad/param norm = 1.7220e-01, time/batch = 0.6495s	
4863/33250 (epoch 7.313), train_loss = 1.06657208, grad/param norm = 1.6308e-01, time/batch = 0.6476s	
4864/33250 (epoch 7.314), train_loss = 1.18089608, grad/param norm = 1.6387e-01, time/batch = 0.6455s	
4865/33250 (epoch 7.316), train_loss = 1.42343223, grad/param norm = 1.8791e-01, time/batch = 0.6507s	
4866/33250 (epoch 7.317), train_loss = 1.11051261, grad/param norm = 1.5333e-01, time/batch = 0.6491s	
4867/33250 (epoch 7.319), train_loss = 1.35405147, grad/param norm = 1.9309e-01, time/batch = 0.6495s	
4868/33250 (epoch 7.320), train_loss = 1.44653285, grad/param norm = 2.0783e-01, time/batch = 0.6504s	
4869/33250 (epoch 7.322), train_loss = 1.45329617, grad/param norm = 1.9880e-01, time/batch = 0.6461s	
4870/33250 (epoch 7.323), train_loss = 1.49414908, grad/param norm = 1.9233e-01, time/batch = 0.6454s	
4871/33250 (epoch 7.325), train_loss = 1.23196994, grad/param norm = 1.7470e-01, time/batch = 0.6695s	
4872/33250 (epoch 7.326), train_loss = 1.48530141, grad/param norm = 1.8299e-01, time/batch = 0.6621s	
4873/33250 (epoch 7.328), train_loss = 1.14625743, grad/param norm = 1.6311e-01, time/batch = 0.6487s	
4874/33250 (epoch 7.329), train_loss = 1.28311065, grad/param norm = 1.7927e-01, time/batch = 0.6486s	
4875/33250 (epoch 7.331), train_loss = 1.20422317, grad/param norm = 1.7946e-01, time/batch = 0.6487s	
4876/33250 (epoch 7.332), train_loss = 1.17992155, grad/param norm = 1.7776e-01, time/batch = 0.6602s	
4877/33250 (epoch 7.334), train_loss = 1.34507501, grad/param norm = 1.5546e-01, time/batch = 0.6707s	
4878/33250 (epoch 7.335), train_loss = 0.92858839, grad/param norm = 1.6966e-01, time/batch = 0.6769s	
4879/33250 (epoch 7.337), train_loss = 1.22357414, grad/param norm = 1.6197e-01, time/batch = 0.6686s	
4880/33250 (epoch 7.338), train_loss = 1.33646876, grad/param norm = 1.5935e-01, time/batch = 0.6759s	
4881/33250 (epoch 7.340), train_loss = 1.23214479, grad/param norm = 1.6295e-01, time/batch = 0.6592s	
4882/33250 (epoch 7.341), train_loss = 1.15753692, grad/param norm = 1.6067e-01, time/batch = 0.6564s	
4883/33250 (epoch 7.343), train_loss = 1.24065661, grad/param norm = 1.7283e-01, time/batch = 0.6511s	
4884/33250 (epoch 7.344), train_loss = 1.20128370, grad/param norm = 1.7216e-01, time/batch = 0.6606s	
4885/33250 (epoch 7.346), train_loss = 1.05332469, grad/param norm = 1.4876e-01, time/batch = 0.6512s	
4886/33250 (epoch 7.347), train_loss = 1.56231323, grad/param norm = 1.7702e-01, time/batch = 0.6690s	
4887/33250 (epoch 7.349), train_loss = 1.21916856, grad/param norm = 1.6688e-01, time/batch = 0.6556s	
4888/33250 (epoch 7.350), train_loss = 1.25128883, grad/param norm = 1.7665e-01, time/batch = 0.6534s	
4889/33250 (epoch 7.352), train_loss = 1.13842863, grad/param norm = 1.8712e-01, time/batch = 0.6576s	
4890/33250 (epoch 7.353), train_loss = 1.20867725, grad/param norm = 1.4842e-01, time/batch = 0.6767s	
4891/33250 (epoch 7.355), train_loss = 1.18781165, grad/param norm = 1.6592e-01, time/batch = 0.6995s	
4892/33250 (epoch 7.356), train_loss = 1.11654884, grad/param norm = 1.7135e-01, time/batch = 0.6616s	
4893/33250 (epoch 7.358), train_loss = 1.14665045, grad/param norm = 1.5768e-01, time/batch = 0.6588s	
4894/33250 (epoch 7.359), train_loss = 1.13247719, grad/param norm = 1.4201e-01, time/batch = 0.6723s	
4895/33250 (epoch 7.361), train_loss = 1.38922058, grad/param norm = 1.8411e-01, time/batch = 0.6858s	
4896/33250 (epoch 7.362), train_loss = 1.18916846, grad/param norm = 1.5792e-01, time/batch = 0.6673s	
4897/33250 (epoch 7.364), train_loss = 1.33563905, grad/param norm = 1.7999e-01, time/batch = 0.6599s	
4898/33250 (epoch 7.365), train_loss = 1.18369175, grad/param norm = 1.5675e-01, time/batch = 0.6617s	
4899/33250 (epoch 7.367), train_loss = 1.15837303, grad/param norm = 1.4621e-01, time/batch = 0.6643s	
4900/33250 (epoch 7.368), train_loss = 1.20125290, grad/param norm = 1.5718e-01, time/batch = 0.6695s	
4901/33250 (epoch 7.370), train_loss = 1.04469726, grad/param norm = 1.4697e-01, time/batch = 0.6827s	
4902/33250 (epoch 7.371), train_loss = 1.34137335, grad/param norm = 1.8515e-01, time/batch = 0.6666s	
4903/33250 (epoch 7.373), train_loss = 1.15319717, grad/param norm = 1.5761e-01, time/batch = 0.6702s	
4904/33250 (epoch 7.374), train_loss = 1.30628013, grad/param norm = 1.8234e-01, time/batch = 0.6795s	
4905/33250 (epoch 7.376), train_loss = 1.19247618, grad/param norm = 1.5939e-01, time/batch = 0.6792s	
4906/33250 (epoch 7.377), train_loss = 1.11113626, grad/param norm = 2.0523e-01, time/batch = 0.6797s	
4907/33250 (epoch 7.379), train_loss = 1.13105441, grad/param norm = 1.6631e-01, time/batch = 0.6721s	
4908/33250 (epoch 7.380), train_loss = 1.29999800, grad/param norm = 2.0471e-01, time/batch = 0.6789s	
4909/33250 (epoch 7.382), train_loss = 1.33896872, grad/param norm = 1.9096e-01, time/batch = 0.6790s	
4910/33250 (epoch 7.383), train_loss = 1.12273708, grad/param norm = 1.5943e-01, time/batch = 0.6790s	
4911/33250 (epoch 7.385), train_loss = 1.07447543, grad/param norm = 1.6753e-01, time/batch = 0.6729s	
4912/33250 (epoch 7.386), train_loss = 1.08369735, grad/param norm = 1.7056e-01, time/batch = 0.6618s	
4913/33250 (epoch 7.388), train_loss = 1.14071756, grad/param norm = 1.6441e-01, time/batch = 0.6593s	
4914/33250 (epoch 7.389), train_loss = 1.18370690, grad/param norm = 1.7899e-01, time/batch = 0.6617s	
4915/33250 (epoch 7.391), train_loss = 1.22491240, grad/param norm = 1.8397e-01, time/batch = 0.6609s	
4916/33250 (epoch 7.392), train_loss = 1.33671067, grad/param norm = 1.7895e-01, time/batch = 0.6626s	
4917/33250 (epoch 7.394), train_loss = 1.43732972, grad/param norm = 1.9439e-01, time/batch = 0.6612s	
4918/33250 (epoch 7.395), train_loss = 1.33673252, grad/param norm = 1.6003e-01, time/batch = 0.6816s	
4919/33250 (epoch 7.397), train_loss = 1.34993333, grad/param norm = 1.8231e-01, time/batch = 0.6866s	
4920/33250 (epoch 7.398), train_loss = 1.15305588, grad/param norm = 1.5843e-01, time/batch = 0.6706s	
4921/33250 (epoch 7.400), train_loss = 1.14805344, grad/param norm = 1.6554e-01, time/batch = 0.6779s	
4922/33250 (epoch 7.402), train_loss = 1.05623971, grad/param norm = 1.5861e-01, time/batch = 0.6837s	
4923/33250 (epoch 7.403), train_loss = 1.14638281, grad/param norm = 1.8056e-01, time/batch = 0.6756s	
4924/33250 (epoch 7.405), train_loss = 1.11414105, grad/param norm = 1.7340e-01, time/batch = 0.6840s	
4925/33250 (epoch 7.406), train_loss = 1.26944386, grad/param norm = 1.6799e-01, time/batch = 0.6820s	
4926/33250 (epoch 7.408), train_loss = 1.36622029, grad/param norm = 1.7929e-01, time/batch = 0.6682s	
4927/33250 (epoch 7.409), train_loss = 1.32992857, grad/param norm = 2.0092e-01, time/batch = 0.6659s	
4928/33250 (epoch 7.411), train_loss = 0.90907121, grad/param norm = 1.2810e-01, time/batch = 0.6594s	
4929/33250 (epoch 7.412), train_loss = 1.04607565, grad/param norm = 1.5455e-01, time/batch = 0.6657s	
4930/33250 (epoch 7.414), train_loss = 1.24576725, grad/param norm = 1.5600e-01, time/batch = 0.6724s	
4931/33250 (epoch 7.415), train_loss = 1.34194020, grad/param norm = 1.6978e-01, time/batch = 0.6643s	
4932/33250 (epoch 7.417), train_loss = 1.30349483, grad/param norm = 1.7741e-01, time/batch = 0.6808s	
4933/33250 (epoch 7.418), train_loss = 1.48301673, grad/param norm = 2.0626e-01, time/batch = 0.6684s	
4934/33250 (epoch 7.420), train_loss = 1.32280523, grad/param norm = 1.6148e-01, time/batch = 0.6580s	
4935/33250 (epoch 7.421), train_loss = 1.09917687, grad/param norm = 1.7308e-01, time/batch = 0.6582s	
4936/33250 (epoch 7.423), train_loss = 1.33732502, grad/param norm = 2.0679e-01, time/batch = 0.6589s	
4937/33250 (epoch 7.424), train_loss = 1.52649031, grad/param norm = 2.2193e-01, time/batch = 0.6597s	
4938/33250 (epoch 7.426), train_loss = 1.11664480, grad/param norm = 1.5190e-01, time/batch = 0.6577s	
4939/33250 (epoch 7.427), train_loss = 1.13418569, grad/param norm = 1.6208e-01, time/batch = 0.6596s	
4940/33250 (epoch 7.429), train_loss = 1.29708057, grad/param norm = 1.7848e-01, time/batch = 0.6605s	
4941/33250 (epoch 7.430), train_loss = 1.12482722, grad/param norm = 1.7448e-01, time/batch = 0.6702s	
4942/33250 (epoch 7.432), train_loss = 1.19956773, grad/param norm = 1.5821e-01, time/batch = 0.6622s	
4943/33250 (epoch 7.433), train_loss = 1.17425187, grad/param norm = 1.6688e-01, time/batch = 0.6768s	
4944/33250 (epoch 7.435), train_loss = 1.25159342, grad/param norm = 1.9121e-01, time/batch = 0.6624s	
4945/33250 (epoch 7.436), train_loss = 1.13215086, grad/param norm = 1.6334e-01, time/batch = 0.6615s	
4946/33250 (epoch 7.438), train_loss = 1.24773720, grad/param norm = 1.5798e-01, time/batch = 0.6704s	
4947/33250 (epoch 7.439), train_loss = 1.21344929, grad/param norm = 1.7219e-01, time/batch = 0.6679s	
4948/33250 (epoch 7.441), train_loss = 1.19169571, grad/param norm = 1.5723e-01, time/batch = 0.6746s	
4949/33250 (epoch 7.442), train_loss = 1.15207445, grad/param norm = 1.7245e-01, time/batch = 0.6672s	
4950/33250 (epoch 7.444), train_loss = 1.11928113, grad/param norm = 1.7348e-01, time/batch = 0.6725s	
4951/33250 (epoch 7.445), train_loss = 1.22413723, grad/param norm = 1.5334e-01, time/batch = 0.6660s	
4952/33250 (epoch 7.447), train_loss = 1.25643848, grad/param norm = 1.6764e-01, time/batch = 0.6686s	
4953/33250 (epoch 7.448), train_loss = 1.11801304, grad/param norm = 1.3172e-01, time/batch = 0.6648s	
4954/33250 (epoch 7.450), train_loss = 1.40633521, grad/param norm = 1.8911e-01, time/batch = 0.6712s	
4955/33250 (epoch 7.451), train_loss = 1.27456580, grad/param norm = 1.7454e-01, time/batch = 0.6909s	
4956/33250 (epoch 7.453), train_loss = 1.06004294, grad/param norm = 1.4988e-01, time/batch = 0.6851s	
4957/33250 (epoch 7.454), train_loss = 1.35878357, grad/param norm = 1.7931e-01, time/batch = 0.6850s	
4958/33250 (epoch 7.456), train_loss = 1.37448276, grad/param norm = 1.8758e-01, time/batch = 0.6850s	
4959/33250 (epoch 7.457), train_loss = 1.17475066, grad/param norm = 1.6561e-01, time/batch = 0.6798s	
4960/33250 (epoch 7.459), train_loss = 1.23230762, grad/param norm = 1.5564e-01, time/batch = 0.6715s	
4961/33250 (epoch 7.460), train_loss = 1.30717584, grad/param norm = 1.7556e-01, time/batch = 0.6706s	
4962/33250 (epoch 7.462), train_loss = 1.12429146, grad/param norm = 1.5483e-01, time/batch = 0.6747s	
4963/33250 (epoch 7.463), train_loss = 1.09828457, grad/param norm = 1.3998e-01, time/batch = 0.6725s	
4964/33250 (epoch 7.465), train_loss = 0.97108325, grad/param norm = 1.2866e-01, time/batch = 0.6689s	
4965/33250 (epoch 7.466), train_loss = 0.95077172, grad/param norm = 1.2809e-01, time/batch = 0.6782s	
4966/33250 (epoch 7.468), train_loss = 1.06943104, grad/param norm = 1.3861e-01, time/batch = 0.6902s	
4967/33250 (epoch 7.469), train_loss = 1.25259177, grad/param norm = 1.8117e-01, time/batch = 0.6920s	
4968/33250 (epoch 7.471), train_loss = 1.32736908, grad/param norm = 1.6704e-01, time/batch = 0.6924s	
4969/33250 (epoch 7.472), train_loss = 1.26244281, grad/param norm = 2.2123e-01, time/batch = 0.6699s	
4970/33250 (epoch 7.474), train_loss = 1.46064889, grad/param norm = 2.2391e-01, time/batch = 0.6713s	
4971/33250 (epoch 7.475), train_loss = 1.21964037, grad/param norm = 1.6424e-01, time/batch = 0.6810s	
4972/33250 (epoch 7.477), train_loss = 1.21115555, grad/param norm = 1.7487e-01, time/batch = 0.6733s	
4973/33250 (epoch 7.478), train_loss = 1.16281263, grad/param norm = 1.5222e-01, time/batch = 0.6708s	
4974/33250 (epoch 7.480), train_loss = 1.42169746, grad/param norm = 1.7227e-01, time/batch = 0.6879s	
4975/33250 (epoch 7.481), train_loss = 1.19264358, grad/param norm = 1.9282e-01, time/batch = 0.6892s	
4976/33250 (epoch 7.483), train_loss = 1.24333081, grad/param norm = 1.5302e-01, time/batch = 0.6780s	
4977/33250 (epoch 7.484), train_loss = 1.11119638, grad/param norm = 1.4812e-01, time/batch = 0.6857s	
4978/33250 (epoch 7.486), train_loss = 1.02580811, grad/param norm = 1.5910e-01, time/batch = 0.6814s	
4979/33250 (epoch 7.487), train_loss = 1.14339376, grad/param norm = 1.6052e-01, time/batch = 0.6684s	
4980/33250 (epoch 7.489), train_loss = 1.35815595, grad/param norm = 1.8922e-01, time/batch = 0.6691s	
4981/33250 (epoch 7.490), train_loss = 1.27782951, grad/param norm = 1.7683e-01, time/batch = 0.6702s	
4982/33250 (epoch 7.492), train_loss = 1.27528534, grad/param norm = 1.7048e-01, time/batch = 0.6783s	
4983/33250 (epoch 7.493), train_loss = 1.22655896, grad/param norm = 1.6510e-01, time/batch = 0.6812s	
4984/33250 (epoch 7.495), train_loss = 1.23259912, grad/param norm = 1.5695e-01, time/batch = 0.6904s	
4985/33250 (epoch 7.496), train_loss = 1.15104386, grad/param norm = 1.3984e-01, time/batch = 0.6748s	
4986/33250 (epoch 7.498), train_loss = 1.30700665, grad/param norm = 1.7220e-01, time/batch = 0.6745s	
4987/33250 (epoch 7.499), train_loss = 1.18956100, grad/param norm = 1.6176e-01, time/batch = 0.6565s	
4988/33250 (epoch 7.501), train_loss = 1.16341314, grad/param norm = 1.7678e-01, time/batch = 0.6548s	
4989/33250 (epoch 7.502), train_loss = 1.18444548, grad/param norm = 1.5536e-01, time/batch = 0.6489s	
4990/33250 (epoch 7.504), train_loss = 1.37862913, grad/param norm = 1.8959e-01, time/batch = 0.6541s	
4991/33250 (epoch 7.505), train_loss = 0.98207138, grad/param norm = 1.3350e-01, time/batch = 0.6575s	
4992/33250 (epoch 7.507), train_loss = 1.19293721, grad/param norm = 1.6162e-01, time/batch = 0.6577s	
4993/33250 (epoch 7.508), train_loss = 1.15803291, grad/param norm = 1.5358e-01, time/batch = 0.6577s	
4994/33250 (epoch 7.510), train_loss = 1.02965052, grad/param norm = 1.4853e-01, time/batch = 0.6742s	
4995/33250 (epoch 7.511), train_loss = 1.22011444, grad/param norm = 1.5964e-01, time/batch = 0.6661s	
4996/33250 (epoch 7.513), train_loss = 1.42918701, grad/param norm = 1.7111e-01, time/batch = 0.6509s	
4997/33250 (epoch 7.514), train_loss = 1.16004549, grad/param norm = 1.6190e-01, time/batch = 0.6465s	
4998/33250 (epoch 7.516), train_loss = 1.13079828, grad/param norm = 1.5552e-01, time/batch = 0.6485s	
4999/33250 (epoch 7.517), train_loss = 1.21833856, grad/param norm = 1.5080e-01, time/batch = 0.6495s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch7.52_1.4321.t7	
5000/33250 (epoch 7.519), train_loss = 1.07044185, grad/param norm = 1.4444e-01, time/batch = 0.6485s	
5001/33250 (epoch 7.520), train_loss = 1.69501671, grad/param norm = 2.0079e-01, time/batch = 0.6611s	
5002/33250 (epoch 7.522), train_loss = 1.34168636, grad/param norm = 1.8391e-01, time/batch = 0.6532s	
5003/33250 (epoch 7.523), train_loss = 1.20418866, grad/param norm = 1.7319e-01, time/batch = 0.6520s	
5004/33250 (epoch 7.525), train_loss = 1.07201467, grad/param norm = 1.5918e-01, time/batch = 0.6536s	
5005/33250 (epoch 7.526), train_loss = 1.08287809, grad/param norm = 1.5132e-01, time/batch = 0.6524s	
5006/33250 (epoch 7.528), train_loss = 1.19166250, grad/param norm = 1.5757e-01, time/batch = 0.6605s	
5007/33250 (epoch 7.529), train_loss = 1.13895766, grad/param norm = 1.5082e-01, time/batch = 0.6653s	
5008/33250 (epoch 7.531), train_loss = 1.04779786, grad/param norm = 1.5318e-01, time/batch = 0.6561s	
5009/33250 (epoch 7.532), train_loss = 1.29331432, grad/param norm = 1.7073e-01, time/batch = 0.6619s	
5010/33250 (epoch 7.534), train_loss = 1.13518424, grad/param norm = 1.5216e-01, time/batch = 0.6552s	
5011/33250 (epoch 7.535), train_loss = 1.20778413, grad/param norm = 1.6544e-01, time/batch = 0.6524s	
5012/33250 (epoch 7.537), train_loss = 1.31089907, grad/param norm = 1.6208e-01, time/batch = 0.6528s	
5013/33250 (epoch 7.538), train_loss = 1.30535234, grad/param norm = 1.6441e-01, time/batch = 0.6528s	
5014/33250 (epoch 7.540), train_loss = 1.36546780, grad/param norm = 1.5691e-01, time/batch = 0.6527s	
5015/33250 (epoch 7.541), train_loss = 1.35533641, grad/param norm = 1.7936e-01, time/batch = 0.6503s	
5016/33250 (epoch 7.543), train_loss = 1.33526992, grad/param norm = 1.7089e-01, time/batch = 0.6530s	
5017/33250 (epoch 7.544), train_loss = 1.18342592, grad/param norm = 1.6106e-01, time/batch = 0.6517s	
5018/33250 (epoch 7.546), train_loss = 1.21768304, grad/param norm = 1.8416e-01, time/batch = 0.6642s	
5019/33250 (epoch 7.547), train_loss = 1.14375672, grad/param norm = 1.7056e-01, time/batch = 0.6545s	
5020/33250 (epoch 7.549), train_loss = 1.25336037, grad/param norm = 1.5785e-01, time/batch = 0.6560s	
5021/33250 (epoch 7.550), train_loss = 1.17680830, grad/param norm = 1.5431e-01, time/batch = 0.6587s	
5022/33250 (epoch 7.552), train_loss = 1.26232964, grad/param norm = 1.7045e-01, time/batch = 0.6505s	
5023/33250 (epoch 7.553), train_loss = 1.15734233, grad/param norm = 1.6672e-01, time/batch = 0.6616s	
5024/33250 (epoch 7.555), train_loss = 1.21085294, grad/param norm = 1.6017e-01, time/batch = 0.6575s	
5025/33250 (epoch 7.556), train_loss = 1.38310935, grad/param norm = 1.9116e-01, time/batch = 0.6569s	
5026/33250 (epoch 7.558), train_loss = 1.31730578, grad/param norm = 1.6749e-01, time/batch = 0.6579s	
5027/33250 (epoch 7.559), train_loss = 1.07136786, grad/param norm = 1.5364e-01, time/batch = 0.6483s	
5028/33250 (epoch 7.561), train_loss = 1.16052345, grad/param norm = 1.5904e-01, time/batch = 0.6583s	
5029/33250 (epoch 7.562), train_loss = 1.39213509, grad/param norm = 1.7996e-01, time/batch = 0.6542s	
5030/33250 (epoch 7.564), train_loss = 1.47610599, grad/param norm = 1.9645e-01, time/batch = 0.6532s	
5031/33250 (epoch 7.565), train_loss = 1.40416377, grad/param norm = 1.8489e-01, time/batch = 0.6521s	
5032/33250 (epoch 7.567), train_loss = 1.34537879, grad/param norm = 1.7013e-01, time/batch = 0.6481s	
5033/33250 (epoch 7.568), train_loss = 1.20781189, grad/param norm = 1.6644e-01, time/batch = 0.6473s	
5034/33250 (epoch 7.570), train_loss = 1.34464144, grad/param norm = 1.6762e-01, time/batch = 0.6512s	
5035/33250 (epoch 7.571), train_loss = 1.44407150, grad/param norm = 1.7908e-01, time/batch = 0.6518s	
5036/33250 (epoch 7.573), train_loss = 1.31707083, grad/param norm = 1.7611e-01, time/batch = 0.6484s	
5037/33250 (epoch 7.574), train_loss = 1.11322983, grad/param norm = 1.6853e-01, time/batch = 0.6504s	
5038/33250 (epoch 7.576), train_loss = 1.25841860, grad/param norm = 1.6443e-01, time/batch = 0.6465s	
5039/33250 (epoch 7.577), train_loss = 1.20646188, grad/param norm = 1.5235e-01, time/batch = 0.6507s	
5040/33250 (epoch 7.579), train_loss = 1.08539074, grad/param norm = 1.5431e-01, time/batch = 0.6454s	
5041/33250 (epoch 7.580), train_loss = 1.10685283, grad/param norm = 1.4460e-01, time/batch = 0.6665s	
5042/33250 (epoch 7.582), train_loss = 1.18934415, grad/param norm = 1.5756e-01, time/batch = 0.6464s	
5043/33250 (epoch 7.583), train_loss = 1.22564024, grad/param norm = 1.4551e-01, time/batch = 0.6513s	
5044/33250 (epoch 7.585), train_loss = 1.30299829, grad/param norm = 1.7014e-01, time/batch = 0.6500s	
5045/33250 (epoch 7.586), train_loss = 1.17227501, grad/param norm = 1.9141e-01, time/batch = 0.6554s	
5046/33250 (epoch 7.588), train_loss = 1.21409078, grad/param norm = 1.6070e-01, time/batch = 0.6639s	
5047/33250 (epoch 7.589), train_loss = 1.28618233, grad/param norm = 1.6905e-01, time/batch = 0.6738s	
5048/33250 (epoch 7.591), train_loss = 1.31455534, grad/param norm = 1.8425e-01, time/batch = 0.6760s	
5049/33250 (epoch 7.592), train_loss = 1.23882404, grad/param norm = 1.5439e-01, time/batch = 0.6535s	
5050/33250 (epoch 7.594), train_loss = 1.42712240, grad/param norm = 1.8380e-01, time/batch = 0.6516s	
5051/33250 (epoch 7.595), train_loss = 1.35539426, grad/param norm = 1.8203e-01, time/batch = 0.6523s	
5052/33250 (epoch 7.597), train_loss = 1.07244661, grad/param norm = 1.4663e-01, time/batch = 0.6531s	
5053/33250 (epoch 7.598), train_loss = 1.28160419, grad/param norm = 1.6712e-01, time/batch = 0.6479s	
5054/33250 (epoch 7.600), train_loss = 1.23219999, grad/param norm = 1.6963e-01, time/batch = 0.6610s	
5055/33250 (epoch 7.602), train_loss = 1.25791267, grad/param norm = 1.7586e-01, time/batch = 0.6526s	
5056/33250 (epoch 7.603), train_loss = 1.25988974, grad/param norm = 1.7329e-01, time/batch = 0.6563s	
5057/33250 (epoch 7.605), train_loss = 1.21921305, grad/param norm = 1.6095e-01, time/batch = 0.6645s	
5058/33250 (epoch 7.606), train_loss = 1.29084543, grad/param norm = 1.5814e-01, time/batch = 0.6832s	
5059/33250 (epoch 7.608), train_loss = 1.22481929, grad/param norm = 1.6004e-01, time/batch = 0.6745s	
5060/33250 (epoch 7.609), train_loss = 1.13387912, grad/param norm = 1.6646e-01, time/batch = 0.6654s	
5061/33250 (epoch 7.611), train_loss = 1.30710487, grad/param norm = 1.7307e-01, time/batch = 0.6575s	
5062/33250 (epoch 7.612), train_loss = 1.28095325, grad/param norm = 1.7555e-01, time/batch = 0.6514s	
5063/33250 (epoch 7.614), train_loss = 1.52803709, grad/param norm = 1.8610e-01, time/batch = 0.6533s	
5064/33250 (epoch 7.615), train_loss = 1.36120146, grad/param norm = 1.6709e-01, time/batch = 0.6532s	
5065/33250 (epoch 7.617), train_loss = 1.64162375, grad/param norm = 1.9473e-01, time/batch = 0.6501s	
5066/33250 (epoch 7.618), train_loss = 1.59638012, grad/param norm = 2.2197e-01, time/batch = 0.6532s	
5067/33250 (epoch 7.620), train_loss = 1.38661997, grad/param norm = 1.8682e-01, time/batch = 0.6526s	
5068/33250 (epoch 7.621), train_loss = 1.20240029, grad/param norm = 1.5632e-01, time/batch = 0.6501s	
5069/33250 (epoch 7.623), train_loss = 1.15382906, grad/param norm = 1.7600e-01, time/batch = 0.6463s	
5070/33250 (epoch 7.624), train_loss = 1.21077683, grad/param norm = 1.7235e-01, time/batch = 0.6535s	
5071/33250 (epoch 7.626), train_loss = 1.22985460, grad/param norm = 1.9867e-01, time/batch = 0.6556s	
5072/33250 (epoch 7.627), train_loss = 1.16790353, grad/param norm = 1.6536e-01, time/batch = 0.6518s	
5073/33250 (epoch 7.629), train_loss = 1.23101551, grad/param norm = 1.8745e-01, time/batch = 0.6527s	
5074/33250 (epoch 7.630), train_loss = 1.19631334, grad/param norm = 1.6421e-01, time/batch = 0.6531s	
5075/33250 (epoch 7.632), train_loss = 1.01958442, grad/param norm = 1.4654e-01, time/batch = 0.6548s	
5076/33250 (epoch 7.633), train_loss = 1.30284560, grad/param norm = 1.7653e-01, time/batch = 0.6473s	
5077/33250 (epoch 7.635), train_loss = 1.09795103, grad/param norm = 1.4726e-01, time/batch = 0.6459s	
5078/33250 (epoch 7.636), train_loss = 1.10856000, grad/param norm = 1.4909e-01, time/batch = 0.6470s	
5079/33250 (epoch 7.638), train_loss = 1.16205025, grad/param norm = 1.5440e-01, time/batch = 0.6485s	
5080/33250 (epoch 7.639), train_loss = 1.10284364, grad/param norm = 1.5566e-01, time/batch = 0.6518s	
5081/33250 (epoch 7.641), train_loss = 1.10570495, grad/param norm = 1.5077e-01, time/batch = 0.6490s	
5082/33250 (epoch 7.642), train_loss = 1.05446493, grad/param norm = 1.5092e-01, time/batch = 0.6530s	
5083/33250 (epoch 7.644), train_loss = 0.96082695, grad/param norm = 1.3488e-01, time/batch = 0.6516s	
5084/33250 (epoch 7.645), train_loss = 1.35044392, grad/param norm = 1.8336e-01, time/batch = 0.6436s	
5085/33250 (epoch 7.647), train_loss = 1.07480773, grad/param norm = 1.4895e-01, time/batch = 0.6420s	
5086/33250 (epoch 7.648), train_loss = 1.20056209, grad/param norm = 1.7760e-01, time/batch = 0.6437s	
5087/33250 (epoch 7.650), train_loss = 1.37838646, grad/param norm = 1.7718e-01, time/batch = 0.6467s	
5088/33250 (epoch 7.651), train_loss = 1.23979769, grad/param norm = 1.8227e-01, time/batch = 0.6526s	
5089/33250 (epoch 7.653), train_loss = 1.07316737, grad/param norm = 1.4379e-01, time/batch = 0.6578s	
5090/33250 (epoch 7.654), train_loss = 1.11565297, grad/param norm = 1.5076e-01, time/batch = 0.6726s	
5091/33250 (epoch 7.656), train_loss = 1.26539537, grad/param norm = 1.6831e-01, time/batch = 0.6803s	
5092/33250 (epoch 7.657), train_loss = 1.00182943, grad/param norm = 1.8426e-01, time/batch = 0.6677s	
5093/33250 (epoch 7.659), train_loss = 1.19815102, grad/param norm = 1.7955e-01, time/batch = 0.6590s	
5094/33250 (epoch 7.660), train_loss = 1.14887563, grad/param norm = 1.7444e-01, time/batch = 0.6664s	
5095/33250 (epoch 7.662), train_loss = 1.25642085, grad/param norm = 1.7234e-01, time/batch = 0.6641s	
5096/33250 (epoch 7.663), train_loss = 1.15878235, grad/param norm = 1.6234e-01, time/batch = 0.6627s	
5097/33250 (epoch 7.665), train_loss = 1.31676427, grad/param norm = 1.7642e-01, time/batch = 0.6724s	
5098/33250 (epoch 7.666), train_loss = 1.17509822, grad/param norm = 1.7141e-01, time/batch = 0.6677s	
5099/33250 (epoch 7.668), train_loss = 1.35593876, grad/param norm = 1.6915e-01, time/batch = 0.6647s	
5100/33250 (epoch 7.669), train_loss = 1.27331505, grad/param norm = 1.6788e-01, time/batch = 0.6571s	
5101/33250 (epoch 7.671), train_loss = 1.22741530, grad/param norm = 1.8148e-01, time/batch = 0.6737s	
5102/33250 (epoch 7.672), train_loss = 1.34152806, grad/param norm = 1.7997e-01, time/batch = 0.6607s	
5103/33250 (epoch 7.674), train_loss = 1.19268551, grad/param norm = 1.5304e-01, time/batch = 0.6453s	
5104/33250 (epoch 7.675), train_loss = 1.22629469, grad/param norm = 1.6066e-01, time/batch = 0.6481s	
5105/33250 (epoch 7.677), train_loss = 1.30547037, grad/param norm = 1.6278e-01, time/batch = 0.6468s	
5106/33250 (epoch 7.678), train_loss = 1.28120781, grad/param norm = 1.6820e-01, time/batch = 0.6473s	
5107/33250 (epoch 7.680), train_loss = 1.34126975, grad/param norm = 1.7568e-01, time/batch = 0.6463s	
5108/33250 (epoch 7.681), train_loss = 1.05349768, grad/param norm = 1.5102e-01, time/batch = 0.6467s	
5109/33250 (epoch 7.683), train_loss = 1.15862853, grad/param norm = 1.6468e-01, time/batch = 0.6482s	
5110/33250 (epoch 7.684), train_loss = 1.13228115, grad/param norm = 1.6430e-01, time/batch = 0.6481s	
5111/33250 (epoch 7.686), train_loss = 1.11203570, grad/param norm = 1.5792e-01, time/batch = 0.6492s	
5112/33250 (epoch 7.687), train_loss = 1.14487684, grad/param norm = 1.5833e-01, time/batch = 0.6489s	
5113/33250 (epoch 7.689), train_loss = 1.16522077, grad/param norm = 1.6004e-01, time/batch = 0.6473s	
5114/33250 (epoch 7.690), train_loss = 1.29087820, grad/param norm = 1.8100e-01, time/batch = 0.6485s	
5115/33250 (epoch 7.692), train_loss = 1.25543369, grad/param norm = 1.7778e-01, time/batch = 0.6675s	
5116/33250 (epoch 7.693), train_loss = 1.21314434, grad/param norm = 1.5255e-01, time/batch = 0.6598s	
5117/33250 (epoch 7.695), train_loss = 1.26833750, grad/param norm = 1.6375e-01, time/batch = 0.6648s	
5118/33250 (epoch 7.696), train_loss = 1.19883358, grad/param norm = 1.5037e-01, time/batch = 0.6582s	
5119/33250 (epoch 7.698), train_loss = 1.13858062, grad/param norm = 1.6388e-01, time/batch = 0.6663s	
5120/33250 (epoch 7.699), train_loss = 1.41722803, grad/param norm = 1.6741e-01, time/batch = 0.6596s	
5121/33250 (epoch 7.701), train_loss = 1.15984194, grad/param norm = 1.5003e-01, time/batch = 0.6638s	
5122/33250 (epoch 7.702), train_loss = 1.25978108, grad/param norm = 1.7511e-01, time/batch = 0.6606s	
5123/33250 (epoch 7.704), train_loss = 1.42803937, grad/param norm = 1.8294e-01, time/batch = 0.6577s	
5124/33250 (epoch 7.705), train_loss = 1.08562172, grad/param norm = 1.5096e-01, time/batch = 0.6591s	
5125/33250 (epoch 7.707), train_loss = 1.04040784, grad/param norm = 1.5901e-01, time/batch = 0.6617s	
5126/33250 (epoch 7.708), train_loss = 1.27437050, grad/param norm = 1.7049e-01, time/batch = 0.6758s	
5127/33250 (epoch 7.710), train_loss = 1.31933694, grad/param norm = 1.6673e-01, time/batch = 0.6596s	
5128/33250 (epoch 7.711), train_loss = 1.25212661, grad/param norm = 2.0079e-01, time/batch = 0.6624s	
5129/33250 (epoch 7.713), train_loss = 1.31427450, grad/param norm = 1.7154e-01, time/batch = 0.6562s	
5130/33250 (epoch 7.714), train_loss = 1.24964062, grad/param norm = 1.6553e-01, time/batch = 0.6570s	
5131/33250 (epoch 7.716), train_loss = 1.35674032, grad/param norm = 1.7809e-01, time/batch = 0.6579s	
5132/33250 (epoch 7.717), train_loss = 1.15383554, grad/param norm = 1.5084e-01, time/batch = 0.6574s	
5133/33250 (epoch 7.719), train_loss = 1.22581302, grad/param norm = 1.5678e-01, time/batch = 0.6634s	
5134/33250 (epoch 7.720), train_loss = 1.47123000, grad/param norm = 1.6594e-01, time/batch = 0.6667s	
5135/33250 (epoch 7.722), train_loss = 1.11015424, grad/param norm = 1.5219e-01, time/batch = 0.6507s	
5136/33250 (epoch 7.723), train_loss = 1.00218311, grad/param norm = 1.4627e-01, time/batch = 0.6448s	
5137/33250 (epoch 7.725), train_loss = 1.02403880, grad/param norm = 1.3731e-01, time/batch = 0.6678s	
5138/33250 (epoch 7.726), train_loss = 1.13379672, grad/param norm = 1.4471e-01, time/batch = 0.6732s	
5139/33250 (epoch 7.728), train_loss = 1.28134906, grad/param norm = 1.6286e-01, time/batch = 0.6684s	
5140/33250 (epoch 7.729), train_loss = 1.40055617, grad/param norm = 1.8049e-01, time/batch = 0.6667s	
5141/33250 (epoch 7.731), train_loss = 1.17633252, grad/param norm = 1.6299e-01, time/batch = 0.6617s	
5142/33250 (epoch 7.732), train_loss = 1.11592105, grad/param norm = 1.5223e-01, time/batch = 0.6489s	
5143/33250 (epoch 7.734), train_loss = 1.25416701, grad/param norm = 1.5826e-01, time/batch = 0.6525s	
5144/33250 (epoch 7.735), train_loss = 1.23456915, grad/param norm = 1.6724e-01, time/batch = 0.6634s	
5145/33250 (epoch 7.737), train_loss = 1.24072316, grad/param norm = 1.4359e-01, time/batch = 0.6623s	
5146/33250 (epoch 7.738), train_loss = 1.21481403, grad/param norm = 1.5843e-01, time/batch = 0.6575s	
5147/33250 (epoch 7.740), train_loss = 1.38416604, grad/param norm = 1.7142e-01, time/batch = 0.6495s	
5148/33250 (epoch 7.741), train_loss = 1.28762304, grad/param norm = 1.6129e-01, time/batch = 0.6701s	
5149/33250 (epoch 7.743), train_loss = 1.17687902, grad/param norm = 1.6081e-01, time/batch = 0.6575s	
5150/33250 (epoch 7.744), train_loss = 1.19803552, grad/param norm = 1.4871e-01, time/batch = 0.6481s	
5151/33250 (epoch 7.746), train_loss = 1.21619228, grad/param norm = 1.4401e-01, time/batch = 0.6773s	
5152/33250 (epoch 7.747), train_loss = 1.17204491, grad/param norm = 1.6398e-01, time/batch = 0.6688s	
5153/33250 (epoch 7.749), train_loss = 1.39575932, grad/param norm = 1.9496e-01, time/batch = 0.6782s	
5154/33250 (epoch 7.750), train_loss = 1.25179213, grad/param norm = 1.6537e-01, time/batch = 0.6617s	
5155/33250 (epoch 7.752), train_loss = 1.10921837, grad/param norm = 1.6303e-01, time/batch = 0.6689s	
5156/33250 (epoch 7.753), train_loss = 1.19504572, grad/param norm = 1.5277e-01, time/batch = 0.6617s	
5157/33250 (epoch 7.755), train_loss = 1.16243380, grad/param norm = 1.5749e-01, time/batch = 0.6620s	
5158/33250 (epoch 7.756), train_loss = 1.32664900, grad/param norm = 1.7572e-01, time/batch = 0.6617s	
5159/33250 (epoch 7.758), train_loss = 1.33967920, grad/param norm = 1.7005e-01, time/batch = 0.6640s	
5160/33250 (epoch 7.759), train_loss = 1.10715229, grad/param norm = 1.5143e-01, time/batch = 0.6814s	
5161/33250 (epoch 7.761), train_loss = 1.15000051, grad/param norm = 1.5375e-01, time/batch = 0.6867s	
5162/33250 (epoch 7.762), train_loss = 1.30072769, grad/param norm = 1.6125e-01, time/batch = 0.6807s	
5163/33250 (epoch 7.764), train_loss = 1.16080003, grad/param norm = 1.8727e-01, time/batch = 0.6677s	
5164/33250 (epoch 7.765), train_loss = 1.25038340, grad/param norm = 1.6684e-01, time/batch = 0.6703s	
5165/33250 (epoch 7.767), train_loss = 1.01800734, grad/param norm = 1.5680e-01, time/batch = 0.6653s	
5166/33250 (epoch 7.768), train_loss = 1.07805154, grad/param norm = 1.5604e-01, time/batch = 0.6640s	
5167/33250 (epoch 7.770), train_loss = 1.29717314, grad/param norm = 1.8676e-01, time/batch = 0.6630s	
5168/33250 (epoch 7.771), train_loss = 1.28184632, grad/param norm = 1.6923e-01, time/batch = 0.6602s	
5169/33250 (epoch 7.773), train_loss = 1.20632984, grad/param norm = 1.7566e-01, time/batch = 0.6601s	
5170/33250 (epoch 7.774), train_loss = 1.03376450, grad/param norm = 1.5501e-01, time/batch = 0.6656s	
5171/33250 (epoch 7.776), train_loss = 1.16481751, grad/param norm = 1.6792e-01, time/batch = 0.6783s	
5172/33250 (epoch 7.777), train_loss = 1.31407647, grad/param norm = 1.9871e-01, time/batch = 0.6734s	
5173/33250 (epoch 7.779), train_loss = 1.13295854, grad/param norm = 1.5587e-01, time/batch = 0.6658s	
5174/33250 (epoch 7.780), train_loss = 1.44336949, grad/param norm = 1.8587e-01, time/batch = 0.6679s	
5175/33250 (epoch 7.782), train_loss = 1.24459717, grad/param norm = 1.5481e-01, time/batch = 0.6758s	
5176/33250 (epoch 7.783), train_loss = 0.99204323, grad/param norm = 1.4784e-01, time/batch = 0.6691s	
5177/33250 (epoch 7.785), train_loss = 1.10544975, grad/param norm = 1.7033e-01, time/batch = 0.6771s	
5178/33250 (epoch 7.786), train_loss = 1.30329519, grad/param norm = 1.6305e-01, time/batch = 0.6738s	
5179/33250 (epoch 7.788), train_loss = 1.25606143, grad/param norm = 1.5370e-01, time/batch = 0.6730s	
5180/33250 (epoch 7.789), train_loss = 1.32542384, grad/param norm = 1.7740e-01, time/batch = 0.6726s	
5181/33250 (epoch 7.791), train_loss = 1.37929336, grad/param norm = 1.7034e-01, time/batch = 0.6656s	
5182/33250 (epoch 7.792), train_loss = 1.44497842, grad/param norm = 1.6053e-01, time/batch = 0.6701s	
5183/33250 (epoch 7.794), train_loss = 1.19999012, grad/param norm = 1.7515e-01, time/batch = 0.6785s	
5184/33250 (epoch 7.795), train_loss = 1.27633905, grad/param norm = 1.6187e-01, time/batch = 0.6631s	
5185/33250 (epoch 7.797), train_loss = 1.36201631, grad/param norm = 1.9237e-01, time/batch = 0.6631s	
5186/33250 (epoch 7.798), train_loss = 1.26754258, grad/param norm = 1.9608e-01, time/batch = 0.6679s	
5187/33250 (epoch 7.800), train_loss = 1.31987330, grad/param norm = 1.7942e-01, time/batch = 0.6686s	
5188/33250 (epoch 7.802), train_loss = 1.16231740, grad/param norm = 1.5929e-01, time/batch = 0.6643s	
5189/33250 (epoch 7.803), train_loss = 1.18811556, grad/param norm = 1.6272e-01, time/batch = 0.6690s	
5190/33250 (epoch 7.805), train_loss = 1.26800641, grad/param norm = 1.6346e-01, time/batch = 0.6666s	
5191/33250 (epoch 7.806), train_loss = 1.29551700, grad/param norm = 1.6547e-01, time/batch = 0.6743s	
5192/33250 (epoch 7.808), train_loss = 1.22284824, grad/param norm = 1.6673e-01, time/batch = 0.6665s	
5193/33250 (epoch 7.809), train_loss = 1.09121750, grad/param norm = 1.6019e-01, time/batch = 0.6685s	
5194/33250 (epoch 7.811), train_loss = 1.12619918, grad/param norm = 1.6213e-01, time/batch = 0.6738s	
5195/33250 (epoch 7.812), train_loss = 1.28217390, grad/param norm = 1.7081e-01, time/batch = 0.6665s	
5196/33250 (epoch 7.814), train_loss = 1.23552520, grad/param norm = 1.7178e-01, time/batch = 0.6666s	
5197/33250 (epoch 7.815), train_loss = 1.28381405, grad/param norm = 1.7258e-01, time/batch = 0.6649s	
5198/33250 (epoch 7.817), train_loss = 1.21457243, grad/param norm = 1.5917e-01, time/batch = 0.6672s	
5199/33250 (epoch 7.818), train_loss = 1.12332581, grad/param norm = 1.5160e-01, time/batch = 0.6747s	
5200/33250 (epoch 7.820), train_loss = 1.23782866, grad/param norm = 1.6447e-01, time/batch = 0.6777s	
5201/33250 (epoch 7.821), train_loss = 1.12454631, grad/param norm = 1.4788e-01, time/batch = 0.6813s	
5202/33250 (epoch 7.823), train_loss = 1.51724284, grad/param norm = 1.9750e-01, time/batch = 0.6849s	
5203/33250 (epoch 7.824), train_loss = 1.22213152, grad/param norm = 1.6224e-01, time/batch = 0.6880s	
5204/33250 (epoch 7.826), train_loss = 1.23565468, grad/param norm = 1.7251e-01, time/batch = 0.6677s	
5205/33250 (epoch 7.827), train_loss = 0.98478257, grad/param norm = 1.5081e-01, time/batch = 0.6640s	
5206/33250 (epoch 7.829), train_loss = 1.22012702, grad/param norm = 1.7873e-01, time/batch = 0.6588s	
5207/33250 (epoch 7.830), train_loss = 1.38493265, grad/param norm = 1.8465e-01, time/batch = 0.6638s	
5208/33250 (epoch 7.832), train_loss = 1.18851979, grad/param norm = 1.5732e-01, time/batch = 0.6627s	
5209/33250 (epoch 7.833), train_loss = 1.27552925, grad/param norm = 1.6564e-01, time/batch = 0.6578s	
5210/33250 (epoch 7.835), train_loss = 1.19455562, grad/param norm = 1.8257e-01, time/batch = 0.6574s	
5211/33250 (epoch 7.836), train_loss = 1.22337950, grad/param norm = 1.5089e-01, time/batch = 0.6559s	
5212/33250 (epoch 7.838), train_loss = 1.16508884, grad/param norm = 1.6003e-01, time/batch = 0.6539s	
5213/33250 (epoch 7.839), train_loss = 1.17036410, grad/param norm = 1.6495e-01, time/batch = 0.6491s	
5214/33250 (epoch 7.841), train_loss = 1.04044535, grad/param norm = 1.3998e-01, time/batch = 0.6521s	
5215/33250 (epoch 7.842), train_loss = 1.37099664, grad/param norm = 1.5862e-01, time/batch = 0.6672s	
5216/33250 (epoch 7.844), train_loss = 1.36231729, grad/param norm = 1.7713e-01, time/batch = 0.6554s	
5217/33250 (epoch 7.845), train_loss = 1.49930852, grad/param norm = 2.0478e-01, time/batch = 0.6534s	
5218/33250 (epoch 7.847), train_loss = 1.41418156, grad/param norm = 1.7942e-01, time/batch = 0.6480s	
5219/33250 (epoch 7.848), train_loss = 1.52793888, grad/param norm = 1.9444e-01, time/batch = 0.6497s	
5220/33250 (epoch 7.850), train_loss = 1.32111244, grad/param norm = 1.6234e-01, time/batch = 0.6519s	
5221/33250 (epoch 7.851), train_loss = 1.14365837, grad/param norm = 1.6333e-01, time/batch = 0.6563s	
5222/33250 (epoch 7.853), train_loss = 1.28093500, grad/param norm = 1.9522e-01, time/batch = 0.6544s	
5223/33250 (epoch 7.854), train_loss = 1.09308141, grad/param norm = 1.4353e-01, time/batch = 0.6594s	
5224/33250 (epoch 7.856), train_loss = 1.12975157, grad/param norm = 1.5564e-01, time/batch = 0.6522s	
5225/33250 (epoch 7.857), train_loss = 1.04408582, grad/param norm = 1.5322e-01, time/batch = 0.6492s	
5226/33250 (epoch 7.859), train_loss = 1.03882669, grad/param norm = 1.5457e-01, time/batch = 0.6540s	
5227/33250 (epoch 7.860), train_loss = 1.20259155, grad/param norm = 1.4871e-01, time/batch = 0.6722s	
5228/33250 (epoch 7.862), train_loss = 1.09009107, grad/param norm = 1.3872e-01, time/batch = 0.6757s	
5229/33250 (epoch 7.863), train_loss = 1.12298146, grad/param norm = 1.5130e-01, time/batch = 0.6970s	
5230/33250 (epoch 7.865), train_loss = 1.27169593, grad/param norm = 1.6377e-01, time/batch = 0.6757s	
5231/33250 (epoch 7.866), train_loss = 1.15109081, grad/param norm = 1.6277e-01, time/batch = 0.6580s	
5232/33250 (epoch 7.868), train_loss = 1.46328953, grad/param norm = 2.1190e-01, time/batch = 0.6488s	
5233/33250 (epoch 7.869), train_loss = 1.30556350, grad/param norm = 1.7762e-01, time/batch = 0.6544s	
5234/33250 (epoch 7.871), train_loss = 0.99965780, grad/param norm = 1.4841e-01, time/batch = 0.6516s	
5235/33250 (epoch 7.872), train_loss = 1.25221966, grad/param norm = 1.8153e-01, time/batch = 0.6563s	
5236/33250 (epoch 7.874), train_loss = 1.13062851, grad/param norm = 1.5754e-01, time/batch = 0.6558s	
5237/33250 (epoch 7.875), train_loss = 1.14661906, grad/param norm = 1.6979e-01, time/batch = 0.6618s	
5238/33250 (epoch 7.877), train_loss = 1.29031325, grad/param norm = 1.6662e-01, time/batch = 0.6537s	
5239/33250 (epoch 7.878), train_loss = 1.24456140, grad/param norm = 1.5952e-01, time/batch = 0.6602s	
5240/33250 (epoch 7.880), train_loss = 1.24379996, grad/param norm = 1.8272e-01, time/batch = 0.6683s	
5241/33250 (epoch 7.881), train_loss = 1.43977237, grad/param norm = 1.7435e-01, time/batch = 0.6708s	
5242/33250 (epoch 7.883), train_loss = 1.25396624, grad/param norm = 1.7694e-01, time/batch = 0.6522s	
5243/33250 (epoch 7.884), train_loss = 1.22226750, grad/param norm = 1.9347e-01, time/batch = 0.6472s	
5244/33250 (epoch 7.886), train_loss = 1.10057352, grad/param norm = 1.3425e-01, time/batch = 0.6503s	
5245/33250 (epoch 7.887), train_loss = 1.18093481, grad/param norm = 1.5673e-01, time/batch = 0.6768s	
5246/33250 (epoch 7.889), train_loss = 1.13572549, grad/param norm = 1.3463e-01, time/batch = 0.6475s	
5247/33250 (epoch 7.890), train_loss = 1.02474522, grad/param norm = 1.3131e-01, time/batch = 0.6520s	
5248/33250 (epoch 7.892), train_loss = 1.30553519, grad/param norm = 1.5975e-01, time/batch = 0.6511s	
5249/33250 (epoch 7.893), train_loss = 1.32250610, grad/param norm = 1.6909e-01, time/batch = 0.6467s	
5250/33250 (epoch 7.895), train_loss = 1.17778351, grad/param norm = 1.6379e-01, time/batch = 0.6488s	
5251/33250 (epoch 7.896), train_loss = 1.28499705, grad/param norm = 1.6890e-01, time/batch = 0.6537s	
5252/33250 (epoch 7.898), train_loss = 1.15285450, grad/param norm = 1.5869e-01, time/batch = 0.6526s	
5253/33250 (epoch 7.899), train_loss = 1.14055649, grad/param norm = 1.5505e-01, time/batch = 0.6530s	
5254/33250 (epoch 7.901), train_loss = 1.03163861, grad/param norm = 1.4152e-01, time/batch = 0.6568s	
5255/33250 (epoch 7.902), train_loss = 1.17402479, grad/param norm = 1.6612e-01, time/batch = 0.6478s	
5256/33250 (epoch 7.904), train_loss = 1.11853658, grad/param norm = 1.4494e-01, time/batch = 0.6490s	
5257/33250 (epoch 7.905), train_loss = 1.13364390, grad/param norm = 1.6257e-01, time/batch = 0.6461s	
5258/33250 (epoch 7.907), train_loss = 1.12670015, grad/param norm = 1.5611e-01, time/batch = 0.6502s	
5259/33250 (epoch 7.908), train_loss = 1.21474255, grad/param norm = 1.5025e-01, time/batch = 0.6474s	
5260/33250 (epoch 7.910), train_loss = 1.31703288, grad/param norm = 1.7318e-01, time/batch = 0.6511s	
5261/33250 (epoch 7.911), train_loss = 0.98631977, grad/param norm = 1.4515e-01, time/batch = 0.6570s	
5262/33250 (epoch 7.913), train_loss = 1.16266873, grad/param norm = 1.5116e-01, time/batch = 0.6518s	
5263/33250 (epoch 7.914), train_loss = 1.00318215, grad/param norm = 1.5220e-01, time/batch = 0.6518s	
5264/33250 (epoch 7.916), train_loss = 1.12405111, grad/param norm = 1.4823e-01, time/batch = 0.6483s	
5265/33250 (epoch 7.917), train_loss = 1.11848905, grad/param norm = 1.4015e-01, time/batch = 0.6568s	
5266/33250 (epoch 7.919), train_loss = 1.15227139, grad/param norm = 1.8213e-01, time/batch = 0.6640s	
5267/33250 (epoch 7.920), train_loss = 1.21666345, grad/param norm = 1.6230e-01, time/batch = 0.6591s	
5268/33250 (epoch 7.922), train_loss = 1.22439448, grad/param norm = 1.6685e-01, time/batch = 0.6706s	
5269/33250 (epoch 7.923), train_loss = 1.18514398, grad/param norm = 1.5749e-01, time/batch = 0.6651s	
5270/33250 (epoch 7.925), train_loss = 1.13848478, grad/param norm = 1.4545e-01, time/batch = 0.6596s	
5271/33250 (epoch 7.926), train_loss = 1.14213621, grad/param norm = 1.6066e-01, time/batch = 0.6736s	
5272/33250 (epoch 7.928), train_loss = 1.19062412, grad/param norm = 1.5526e-01, time/batch = 0.6593s	
5273/33250 (epoch 7.929), train_loss = 0.93545967, grad/param norm = 1.2953e-01, time/batch = 0.6552s	
5274/33250 (epoch 7.931), train_loss = 1.24936104, grad/param norm = 1.5847e-01, time/batch = 0.6563s	
5275/33250 (epoch 7.932), train_loss = 1.26643483, grad/param norm = 1.8329e-01, time/batch = 0.6645s	
5276/33250 (epoch 7.934), train_loss = 1.11425140, grad/param norm = 1.3939e-01, time/batch = 0.6714s	
5277/33250 (epoch 7.935), train_loss = 1.20203792, grad/param norm = 1.7935e-01, time/batch = 0.6587s	
5278/33250 (epoch 7.937), train_loss = 1.25974830, grad/param norm = 1.7795e-01, time/batch = 0.6533s	
5279/33250 (epoch 7.938), train_loss = 1.28363837, grad/param norm = 1.6219e-01, time/batch = 0.6445s	
5280/33250 (epoch 7.940), train_loss = 1.18112990, grad/param norm = 1.6872e-01, time/batch = 0.6518s	
5281/33250 (epoch 7.941), train_loss = 1.21639154, grad/param norm = 1.6082e-01, time/batch = 0.6508s	
5282/33250 (epoch 7.943), train_loss = 1.40337931, grad/param norm = 1.6963e-01, time/batch = 0.6470s	
5283/33250 (epoch 7.944), train_loss = 1.08212941, grad/param norm = 1.4174e-01, time/batch = 0.6510s	
5284/33250 (epoch 7.946), train_loss = 1.39014167, grad/param norm = 1.5884e-01, time/batch = 0.6517s	
5285/33250 (epoch 7.947), train_loss = 1.13637119, grad/param norm = 1.5824e-01, time/batch = 0.6709s	
5286/33250 (epoch 7.949), train_loss = 1.34631078, grad/param norm = 1.6599e-01, time/batch = 0.6543s	
5287/33250 (epoch 7.950), train_loss = 1.21423085, grad/param norm = 1.5123e-01, time/batch = 0.6546s	
5288/33250 (epoch 7.952), train_loss = 1.18410785, grad/param norm = 1.6109e-01, time/batch = 0.6735s	
5289/33250 (epoch 7.953), train_loss = 1.31015183, grad/param norm = 1.8142e-01, time/batch = 0.6608s	
5290/33250 (epoch 7.955), train_loss = 1.29433727, grad/param norm = 1.6673e-01, time/batch = 0.6556s	
5291/33250 (epoch 7.956), train_loss = 1.33609267, grad/param norm = 1.9172e-01, time/batch = 0.6518s	
5292/33250 (epoch 7.958), train_loss = 1.09813267, grad/param norm = 1.5106e-01, time/batch = 0.6576s	
5293/33250 (epoch 7.959), train_loss = 1.10919974, grad/param norm = 1.4047e-01, time/batch = 0.6723s	
5294/33250 (epoch 7.961), train_loss = 1.38275441, grad/param norm = 1.6373e-01, time/batch = 0.6690s	
5295/33250 (epoch 7.962), train_loss = 1.26407154, grad/param norm = 1.6521e-01, time/batch = 0.6674s	
5296/33250 (epoch 7.964), train_loss = 1.39145531, grad/param norm = 1.6654e-01, time/batch = 0.6773s	
5297/33250 (epoch 7.965), train_loss = 1.27492847, grad/param norm = 1.9765e-01, time/batch = 0.6737s	
5298/33250 (epoch 7.967), train_loss = 1.25362847, grad/param norm = 1.7312e-01, time/batch = 0.6772s	
5299/33250 (epoch 7.968), train_loss = 1.46427843, grad/param norm = 1.6329e-01, time/batch = 0.6755s	
5300/33250 (epoch 7.970), train_loss = 1.54006218, grad/param norm = 1.9063e-01, time/batch = 0.6731s	
5301/33250 (epoch 7.971), train_loss = 1.36111621, grad/param norm = 1.9309e-01, time/batch = 0.6676s	
5302/33250 (epoch 7.973), train_loss = 1.17153316, grad/param norm = 1.6498e-01, time/batch = 0.6685s	
5303/33250 (epoch 7.974), train_loss = 1.25227405, grad/param norm = 1.6662e-01, time/batch = 0.6695s	
5304/33250 (epoch 7.976), train_loss = 1.15396770, grad/param norm = 1.5529e-01, time/batch = 0.6669s	
5305/33250 (epoch 7.977), train_loss = 1.13158162, grad/param norm = 1.6239e-01, time/batch = 0.6753s	
5306/33250 (epoch 7.979), train_loss = 1.23930888, grad/param norm = 1.6890e-01, time/batch = 0.6713s	
5307/33250 (epoch 7.980), train_loss = 1.19439364, grad/param norm = 1.4353e-01, time/batch = 0.6860s	
5308/33250 (epoch 7.982), train_loss = 1.00845058, grad/param norm = 1.3562e-01, time/batch = 0.6794s	
5309/33250 (epoch 7.983), train_loss = 1.27945097, grad/param norm = 1.7698e-01, time/batch = 0.6664s	
5310/33250 (epoch 7.985), train_loss = 1.12863520, grad/param norm = 1.6870e-01, time/batch = 0.6666s	
5311/33250 (epoch 7.986), train_loss = 1.31867600, grad/param norm = 1.7518e-01, time/batch = 0.6650s	
5312/33250 (epoch 7.988), train_loss = 1.30452681, grad/param norm = 1.8461e-01, time/batch = 0.6659s	
5313/33250 (epoch 7.989), train_loss = 1.36206560, grad/param norm = 1.8311e-01, time/batch = 0.6761s	
5314/33250 (epoch 7.991), train_loss = 1.21214521, grad/param norm = 1.6812e-01, time/batch = 0.6740s	
5315/33250 (epoch 7.992), train_loss = 1.18245682, grad/param norm = 1.5386e-01, time/batch = 0.6738s	
5316/33250 (epoch 7.994), train_loss = 1.11462457, grad/param norm = 1.5859e-01, time/batch = 0.6714s	
5317/33250 (epoch 7.995), train_loss = 1.25049845, grad/param norm = 1.8616e-01, time/batch = 0.6865s	
5318/33250 (epoch 7.997), train_loss = 0.90251766, grad/param norm = 1.4196e-01, time/batch = 0.6889s	
5319/33250 (epoch 7.998), train_loss = 1.18592699, grad/param norm = 1.5267e-01, time/batch = 0.6889s	
5320/33250 (epoch 8.000), train_loss = 1.21717633, grad/param norm = 1.5931e-01, time/batch = 0.6752s	
5321/33250 (epoch 8.002), train_loss = 1.38348331, grad/param norm = 1.8037e-01, time/batch = 0.6701s	
5322/33250 (epoch 8.003), train_loss = 1.27516694, grad/param norm = 1.6244e-01, time/batch = 0.6718s	
5323/33250 (epoch 8.005), train_loss = 1.00164476, grad/param norm = 1.4635e-01, time/batch = 0.6716s	
5324/33250 (epoch 8.006), train_loss = 1.02925916, grad/param norm = 1.4099e-01, time/batch = 0.6673s	
5325/33250 (epoch 8.008), train_loss = 1.34438325, grad/param norm = 1.6977e-01, time/batch = 0.6683s	
5326/33250 (epoch 8.009), train_loss = 1.34953809, grad/param norm = 1.7911e-01, time/batch = 0.6706s	
5327/33250 (epoch 8.011), train_loss = 1.12081658, grad/param norm = 1.5392e-01, time/batch = 0.6772s	
5328/33250 (epoch 8.012), train_loss = 1.29013330, grad/param norm = 1.9761e-01, time/batch = 0.6882s	
5329/33250 (epoch 8.014), train_loss = 1.33878743, grad/param norm = 1.8201e-01, time/batch = 0.6762s	
5330/33250 (epoch 8.015), train_loss = 1.20575457, grad/param norm = 1.5463e-01, time/batch = 0.6704s	
5331/33250 (epoch 8.017), train_loss = 1.26627529, grad/param norm = 1.6771e-01, time/batch = 0.6695s	
5332/33250 (epoch 8.018), train_loss = 1.01773431, grad/param norm = 1.5391e-01, time/batch = 0.6721s	
5333/33250 (epoch 8.020), train_loss = 1.14156610, grad/param norm = 1.4889e-01, time/batch = 0.6763s	
5334/33250 (epoch 8.021), train_loss = 1.18080743, grad/param norm = 1.5770e-01, time/batch = 0.6896s	
5335/33250 (epoch 8.023), train_loss = 1.02034090, grad/param norm = 1.6399e-01, time/batch = 0.6856s	
5336/33250 (epoch 8.024), train_loss = 1.27605554, grad/param norm = 1.6855e-01, time/batch = 0.6705s	
5337/33250 (epoch 8.026), train_loss = 1.19902168, grad/param norm = 1.5482e-01, time/batch = 0.6666s	
5338/33250 (epoch 8.027), train_loss = 1.16232729, grad/param norm = 1.4736e-01, time/batch = 0.6900s	
5339/33250 (epoch 8.029), train_loss = 1.21470951, grad/param norm = 1.6358e-01, time/batch = 0.6796s	
5340/33250 (epoch 8.030), train_loss = 1.19248863, grad/param norm = 1.7083e-01, time/batch = 0.6642s	
5341/33250 (epoch 8.032), train_loss = 1.45341855, grad/param norm = 1.9044e-01, time/batch = 0.6604s	
5342/33250 (epoch 8.033), train_loss = 1.16372507, grad/param norm = 1.6524e-01, time/batch = 0.6655s	
5343/33250 (epoch 8.035), train_loss = 1.14510312, grad/param norm = 1.7208e-01, time/batch = 0.6766s	
5344/33250 (epoch 8.036), train_loss = 1.28925334, grad/param norm = 1.8081e-01, time/batch = 0.6825s	
5345/33250 (epoch 8.038), train_loss = 1.14387155, grad/param norm = 1.5755e-01, time/batch = 0.6790s	
5346/33250 (epoch 8.039), train_loss = 1.05331784, grad/param norm = 1.3857e-01, time/batch = 0.6892s	
5347/33250 (epoch 8.041), train_loss = 1.27589769, grad/param norm = 1.7695e-01, time/batch = 0.6897s	
5348/33250 (epoch 8.042), train_loss = 1.02050916, grad/param norm = 1.4012e-01, time/batch = 0.6755s	
5349/33250 (epoch 8.044), train_loss = 1.35666610, grad/param norm = 1.7691e-01, time/batch = 0.6713s	
5350/33250 (epoch 8.045), train_loss = 1.31627458, grad/param norm = 1.5727e-01, time/batch = 0.6897s	
5351/33250 (epoch 8.047), train_loss = 1.31833455, grad/param norm = 1.7621e-01, time/batch = 0.6932s	
5352/33250 (epoch 8.048), train_loss = 1.41988356, grad/param norm = 1.8364e-01, time/batch = 0.6885s	
5353/33250 (epoch 8.050), train_loss = 1.17313222, grad/param norm = 1.5595e-01, time/batch = 0.6863s	
5354/33250 (epoch 8.051), train_loss = 1.19337583, grad/param norm = 1.4832e-01, time/batch = 0.6707s	
5355/33250 (epoch 8.053), train_loss = 1.25672320, grad/param norm = 1.7248e-01, time/batch = 0.6575s	
5356/33250 (epoch 8.054), train_loss = 1.03091764, grad/param norm = 1.3904e-01, time/batch = 0.6469s	
5357/33250 (epoch 8.056), train_loss = 1.06119181, grad/param norm = 1.5357e-01, time/batch = 0.6532s	
5358/33250 (epoch 8.057), train_loss = 1.22045133, grad/param norm = 1.4911e-01, time/batch = 0.6518s	
5359/33250 (epoch 8.059), train_loss = 1.14604460, grad/param norm = 1.4778e-01, time/batch = 0.6504s	
5360/33250 (epoch 8.060), train_loss = 1.27523208, grad/param norm = 1.7401e-01, time/batch = 0.6466s	
5361/33250 (epoch 8.062), train_loss = 1.36670575, grad/param norm = 1.6344e-01, time/batch = 0.6480s	
5362/33250 (epoch 8.063), train_loss = 1.33192900, grad/param norm = 1.5168e-01, time/batch = 0.6451s	
5363/33250 (epoch 8.065), train_loss = 1.17766113, grad/param norm = 1.5187e-01, time/batch = 0.6459s	
5364/33250 (epoch 8.066), train_loss = 1.26864379, grad/param norm = 1.6005e-01, time/batch = 0.6469s	
5365/33250 (epoch 8.068), train_loss = 1.19813194, grad/param norm = 1.5792e-01, time/batch = 0.6423s	
5366/33250 (epoch 8.069), train_loss = 1.22744170, grad/param norm = 1.6053e-01, time/batch = 0.6461s	
5367/33250 (epoch 8.071), train_loss = 1.06400383, grad/param norm = 1.5390e-01, time/batch = 0.6452s	
5368/33250 (epoch 8.072), train_loss = 1.09695481, grad/param norm = 1.4595e-01, time/batch = 0.6436s	
5369/33250 (epoch 8.074), train_loss = 1.24409435, grad/param norm = 1.5527e-01, time/batch = 0.6436s	
5370/33250 (epoch 8.075), train_loss = 1.08476533, grad/param norm = 1.4303e-01, time/batch = 0.6482s	
5371/33250 (epoch 8.077), train_loss = 1.20881443, grad/param norm = 1.6184e-01, time/batch = 0.6725s	
5372/33250 (epoch 8.078), train_loss = 1.14605575, grad/param norm = 1.5998e-01, time/batch = 0.6493s	
5373/33250 (epoch 8.080), train_loss = 1.28757888, grad/param norm = 1.8582e-01, time/batch = 0.6449s	
5374/33250 (epoch 8.081), train_loss = 1.25927124, grad/param norm = 1.7116e-01, time/batch = 0.6456s	
5375/33250 (epoch 8.083), train_loss = 1.31020344, grad/param norm = 1.5486e-01, time/batch = 0.6622s	
5376/33250 (epoch 8.084), train_loss = 1.18600598, grad/param norm = 1.6687e-01, time/batch = 0.6722s	
5377/33250 (epoch 8.086), train_loss = 1.11282125, grad/param norm = 1.3704e-01, time/batch = 0.6622s	
5378/33250 (epoch 8.087), train_loss = 1.04207862, grad/param norm = 1.4159e-01, time/batch = 0.6549s	
5379/33250 (epoch 8.089), train_loss = 1.24618010, grad/param norm = 1.6184e-01, time/batch = 0.6534s	
5380/33250 (epoch 8.090), train_loss = 1.14809757, grad/param norm = 1.6908e-01, time/batch = 0.6486s	
5381/33250 (epoch 8.092), train_loss = 1.09470890, grad/param norm = 1.4108e-01, time/batch = 0.6544s	
5382/33250 (epoch 8.093), train_loss = 1.20828347, grad/param norm = 1.5632e-01, time/batch = 0.6479s	
5383/33250 (epoch 8.095), train_loss = 1.14382080, grad/param norm = 1.4376e-01, time/batch = 0.6565s	
5384/33250 (epoch 8.096), train_loss = 0.99448237, grad/param norm = 1.4619e-01, time/batch = 0.6524s	
5385/33250 (epoch 8.098), train_loss = 1.08867239, grad/param norm = 1.6917e-01, time/batch = 0.6499s	
5386/33250 (epoch 8.099), train_loss = 0.89748213, grad/param norm = 1.4576e-01, time/batch = 0.6558s	
5387/33250 (epoch 8.101), train_loss = 1.14589819, grad/param norm = 1.4544e-01, time/batch = 0.6495s	
5388/33250 (epoch 8.102), train_loss = 1.06739613, grad/param norm = 1.5935e-01, time/batch = 0.6460s	
5389/33250 (epoch 8.104), train_loss = 0.96896920, grad/param norm = 1.4066e-01, time/batch = 0.6519s	
5390/33250 (epoch 8.105), train_loss = 1.10870882, grad/param norm = 1.5989e-01, time/batch = 0.6484s	
5391/33250 (epoch 8.107), train_loss = 0.98487072, grad/param norm = 1.5249e-01, time/batch = 0.6505s	
5392/33250 (epoch 8.108), train_loss = 1.18654452, grad/param norm = 1.5889e-01, time/batch = 0.6481s	
5393/33250 (epoch 8.110), train_loss = 0.94023872, grad/param norm = 1.3640e-01, time/batch = 0.6454s	
5394/33250 (epoch 8.111), train_loss = 1.15571644, grad/param norm = 1.5835e-01, time/batch = 0.6516s	
5395/33250 (epoch 8.113), train_loss = 1.16329381, grad/param norm = 1.6583e-01, time/batch = 0.6476s	
5396/33250 (epoch 8.114), train_loss = 1.07708673, grad/param norm = 1.6181e-01, time/batch = 0.6544s	
5397/33250 (epoch 8.116), train_loss = 1.20739653, grad/param norm = 1.6034e-01, time/batch = 0.6868s	
5398/33250 (epoch 8.117), train_loss = 1.16398496, grad/param norm = 1.5511e-01, time/batch = 0.7006s	
5399/33250 (epoch 8.119), train_loss = 1.12793803, grad/param norm = 1.5393e-01, time/batch = 0.7019s	
5400/33250 (epoch 8.120), train_loss = 0.91037095, grad/param norm = 1.4034e-01, time/batch = 0.7000s	
5401/33250 (epoch 8.122), train_loss = 1.30865134, grad/param norm = 1.5206e-01, time/batch = 0.7019s	
5402/33250 (epoch 8.123), train_loss = 1.23859887, grad/param norm = 1.5175e-01, time/batch = 0.6975s	
5403/33250 (epoch 8.125), train_loss = 0.97631697, grad/param norm = 1.4737e-01, time/batch = 0.6946s	
5404/33250 (epoch 8.126), train_loss = 1.17492609, grad/param norm = 1.7570e-01, time/batch = 0.6891s	
5405/33250 (epoch 8.128), train_loss = 1.07613537, grad/param norm = 1.4838e-01, time/batch = 0.6759s	
5406/33250 (epoch 8.129), train_loss = 1.15176839, grad/param norm = 1.5056e-01, time/batch = 0.6769s	
5407/33250 (epoch 8.131), train_loss = 1.17239874, grad/param norm = 1.7304e-01, time/batch = 0.6847s	
5408/33250 (epoch 8.132), train_loss = 1.17081867, grad/param norm = 1.6865e-01, time/batch = 0.6894s	
5409/33250 (epoch 8.134), train_loss = 1.19975667, grad/param norm = 1.5723e-01, time/batch = 0.6795s	
5410/33250 (epoch 8.135), train_loss = 1.24026623, grad/param norm = 1.5745e-01, time/batch = 0.6622s	
5411/33250 (epoch 8.137), train_loss = 1.05480859, grad/param norm = 1.5512e-01, time/batch = 0.6747s	
5412/33250 (epoch 8.138), train_loss = 1.11648696, grad/param norm = 1.4006e-01, time/batch = 0.6623s	
5413/33250 (epoch 8.140), train_loss = 0.95311059, grad/param norm = 1.4728e-01, time/batch = 0.6591s	
5414/33250 (epoch 8.141), train_loss = 1.49034269, grad/param norm = 1.9930e-01, time/batch = 0.6442s	
5415/33250 (epoch 8.143), train_loss = 0.93476863, grad/param norm = 1.5184e-01, time/batch = 0.6433s	
5416/33250 (epoch 8.144), train_loss = 1.09661818, grad/param norm = 1.5540e-01, time/batch = 0.6413s	
5417/33250 (epoch 8.146), train_loss = 1.08349439, grad/param norm = 1.5312e-01, time/batch = 0.6609s	
5418/33250 (epoch 8.147), train_loss = 1.07142036, grad/param norm = 1.5500e-01, time/batch = 0.6712s	
5419/33250 (epoch 8.149), train_loss = 1.14528085, grad/param norm = 1.5587e-01, time/batch = 0.6611s	
5420/33250 (epoch 8.150), train_loss = 1.03049885, grad/param norm = 1.4812e-01, time/batch = 0.6587s	
5421/33250 (epoch 8.152), train_loss = 1.01523487, grad/param norm = 1.5209e-01, time/batch = 0.6850s	
5422/33250 (epoch 8.153), train_loss = 1.37474378, grad/param norm = 1.8413e-01, time/batch = 0.6544s	
5423/33250 (epoch 8.155), train_loss = 1.22994841, grad/param norm = 1.9047e-01, time/batch = 0.6542s	
5424/33250 (epoch 8.156), train_loss = 1.34471277, grad/param norm = 1.6565e-01, time/batch = 0.6459s	
5425/33250 (epoch 8.158), train_loss = 1.44086485, grad/param norm = 1.8766e-01, time/batch = 0.6510s	
5426/33250 (epoch 8.159), train_loss = 1.19502974, grad/param norm = 1.6395e-01, time/batch = 0.6532s	
5427/33250 (epoch 8.161), train_loss = 1.25180986, grad/param norm = 1.7749e-01, time/batch = 0.6484s	
5428/33250 (epoch 8.162), train_loss = 1.08909521, grad/param norm = 1.5725e-01, time/batch = 0.6463s	
5429/33250 (epoch 8.164), train_loss = 1.21115525, grad/param norm = 1.6409e-01, time/batch = 0.6478s	
5430/33250 (epoch 8.165), train_loss = 1.28988278, grad/param norm = 1.7462e-01, time/batch = 0.6446s	
5431/33250 (epoch 8.167), train_loss = 1.28552462, grad/param norm = 1.6395e-01, time/batch = 0.6481s	
5432/33250 (epoch 8.168), train_loss = 1.01065199, grad/param norm = 1.3385e-01, time/batch = 0.6492s	
5433/33250 (epoch 8.170), train_loss = 1.11143329, grad/param norm = 1.5430e-01, time/batch = 0.6504s	
5434/33250 (epoch 8.171), train_loss = 1.12263901, grad/param norm = 1.4325e-01, time/batch = 0.6531s	
5435/33250 (epoch 8.173), train_loss = 1.11886473, grad/param norm = 1.5600e-01, time/batch = 0.6512s	
5436/33250 (epoch 8.174), train_loss = 1.16137416, grad/param norm = 1.5987e-01, time/batch = 0.6455s	
5437/33250 (epoch 8.176), train_loss = 1.20410255, grad/param norm = 1.5746e-01, time/batch = 0.6485s	
5438/33250 (epoch 8.177), train_loss = 1.05546444, grad/param norm = 1.3497e-01, time/batch = 0.6480s	
5439/33250 (epoch 8.179), train_loss = 1.09720140, grad/param norm = 1.5768e-01, time/batch = 0.6669s	
5440/33250 (epoch 8.180), train_loss = 1.02073340, grad/param norm = 1.4811e-01, time/batch = 0.6609s	
5441/33250 (epoch 8.182), train_loss = 1.13905080, grad/param norm = 1.7441e-01, time/batch = 0.6516s	
5442/33250 (epoch 8.183), train_loss = 1.32900253, grad/param norm = 1.6299e-01, time/batch = 0.6533s	
5443/33250 (epoch 8.185), train_loss = 1.27205540, grad/param norm = 1.8313e-01, time/batch = 0.6506s	
5444/33250 (epoch 8.186), train_loss = 1.17303790, grad/param norm = 1.5659e-01, time/batch = 0.6500s	
5445/33250 (epoch 8.188), train_loss = 1.28897757, grad/param norm = 1.7248e-01, time/batch = 0.6534s	
5446/33250 (epoch 8.189), train_loss = 1.00237892, grad/param norm = 1.6884e-01, time/batch = 0.6545s	
5447/33250 (epoch 8.191), train_loss = 1.11003580, grad/param norm = 1.7224e-01, time/batch = 0.6545s	
5448/33250 (epoch 8.192), train_loss = 1.06050159, grad/param norm = 1.3772e-01, time/batch = 0.6530s	
5449/33250 (epoch 8.194), train_loss = 1.08130128, grad/param norm = 1.6969e-01, time/batch = 0.6577s	
5450/33250 (epoch 8.195), train_loss = 1.32258415, grad/param norm = 1.5249e-01, time/batch = 0.6538s	
5451/33250 (epoch 8.197), train_loss = 1.14766918, grad/param norm = 1.5703e-01, time/batch = 0.6569s	
5452/33250 (epoch 8.198), train_loss = 1.26939061, grad/param norm = 1.6641e-01, time/batch = 0.6604s	
5453/33250 (epoch 8.200), train_loss = 1.17620185, grad/param norm = 1.5944e-01, time/batch = 0.6835s	
5454/33250 (epoch 8.202), train_loss = 1.09199391, grad/param norm = 1.5408e-01, time/batch = 0.6577s	
5455/33250 (epoch 8.203), train_loss = 1.15010437, grad/param norm = 1.6769e-01, time/batch = 0.6605s	
5456/33250 (epoch 8.205), train_loss = 1.20836392, grad/param norm = 1.5964e-01, time/batch = 0.6624s	
5457/33250 (epoch 8.206), train_loss = 1.22034269, grad/param norm = 1.5986e-01, time/batch = 0.6628s	
5458/33250 (epoch 8.208), train_loss = 1.37212147, grad/param norm = 1.9445e-01, time/batch = 0.6508s	
5459/33250 (epoch 8.209), train_loss = 1.08053065, grad/param norm = 1.5608e-01, time/batch = 0.6495s	
5460/33250 (epoch 8.211), train_loss = 1.29364723, grad/param norm = 1.6368e-01, time/batch = 0.6724s	
5461/33250 (epoch 8.212), train_loss = 1.43543654, grad/param norm = 1.6917e-01, time/batch = 0.6687s	
5462/33250 (epoch 8.214), train_loss = 1.14787203, grad/param norm = 1.3648e-01, time/batch = 0.6529s	
5463/33250 (epoch 8.215), train_loss = 1.49698876, grad/param norm = 2.0546e-01, time/batch = 0.6537s	
5464/33250 (epoch 8.217), train_loss = 1.36334907, grad/param norm = 1.7977e-01, time/batch = 0.6694s	
5465/33250 (epoch 8.218), train_loss = 1.27422973, grad/param norm = 1.5553e-01, time/batch = 0.6683s	
5466/33250 (epoch 8.220), train_loss = 1.29879089, grad/param norm = 1.7439e-01, time/batch = 0.6668s	
5467/33250 (epoch 8.221), train_loss = 1.43246479, grad/param norm = 1.8566e-01, time/batch = 0.6652s	
5468/33250 (epoch 8.223), train_loss = 1.16484604, grad/param norm = 1.6064e-01, time/batch = 0.6604s	
5469/33250 (epoch 8.224), train_loss = 1.33487856, grad/param norm = 1.9604e-01, time/batch = 0.6572s	
5470/33250 (epoch 8.226), train_loss = 1.37151448, grad/param norm = 1.7020e-01, time/batch = 0.6622s	
5471/33250 (epoch 8.227), train_loss = 1.20989492, grad/param norm = 1.5999e-01, time/batch = 0.6606s	
5472/33250 (epoch 8.229), train_loss = 1.20478235, grad/param norm = 1.4868e-01, time/batch = 0.6682s	
5473/33250 (epoch 8.230), train_loss = 1.13864403, grad/param norm = 1.6107e-01, time/batch = 0.6644s	
5474/33250 (epoch 8.232), train_loss = 1.09550618, grad/param norm = 1.4142e-01, time/batch = 0.6624s	
5475/33250 (epoch 8.233), train_loss = 1.12022588, grad/param norm = 1.5655e-01, time/batch = 0.6673s	
5476/33250 (epoch 8.235), train_loss = 1.31230971, grad/param norm = 1.5815e-01, time/batch = 0.6726s	
5477/33250 (epoch 8.236), train_loss = 1.10979032, grad/param norm = 1.6556e-01, time/batch = 0.6670s	
5478/33250 (epoch 8.238), train_loss = 1.27030195, grad/param norm = 1.6744e-01, time/batch = 0.6612s	
5479/33250 (epoch 8.239), train_loss = 1.38379885, grad/param norm = 1.8303e-01, time/batch = 0.6700s	
5480/33250 (epoch 8.241), train_loss = 1.28821482, grad/param norm = 1.7494e-01, time/batch = 0.6639s	
5481/33250 (epoch 8.242), train_loss = 1.30005026, grad/param norm = 1.7235e-01, time/batch = 0.6623s	
5482/33250 (epoch 8.244), train_loss = 1.30695574, grad/param norm = 1.7916e-01, time/batch = 0.6671s	
5483/33250 (epoch 8.245), train_loss = 1.18592605, grad/param norm = 1.5648e-01, time/batch = 0.6634s	
5484/33250 (epoch 8.247), train_loss = 1.22701956, grad/param norm = 1.5146e-01, time/batch = 0.6597s	
5485/33250 (epoch 8.248), train_loss = 1.48358232, grad/param norm = 1.9430e-01, time/batch = 0.6646s	
5486/33250 (epoch 8.250), train_loss = 1.25800619, grad/param norm = 1.4790e-01, time/batch = 0.6882s	
5487/33250 (epoch 8.251), train_loss = 1.19724172, grad/param norm = 1.6506e-01, time/batch = 0.6872s	
5488/33250 (epoch 8.253), train_loss = 1.07417440, grad/param norm = 1.4558e-01, time/batch = 0.6874s	
5489/33250 (epoch 8.254), train_loss = 1.15572474, grad/param norm = 1.7136e-01, time/batch = 0.6810s	
5490/33250 (epoch 8.256), train_loss = 1.27052772, grad/param norm = 1.5457e-01, time/batch = 0.6637s	
5491/33250 (epoch 8.257), train_loss = 1.36311863, grad/param norm = 1.6384e-01, time/batch = 0.6635s	
5492/33250 (epoch 8.259), train_loss = 1.37313726, grad/param norm = 1.5790e-01, time/batch = 0.6662s	
5493/33250 (epoch 8.260), train_loss = 1.09721707, grad/param norm = 1.4721e-01, time/batch = 0.6661s	
5494/33250 (epoch 8.262), train_loss = 1.26333015, grad/param norm = 1.5734e-01, time/batch = 0.6731s	
5495/33250 (epoch 8.263), train_loss = 1.13214811, grad/param norm = 1.4366e-01, time/batch = 0.6661s	
5496/33250 (epoch 8.265), train_loss = 1.29999521, grad/param norm = 1.5707e-01, time/batch = 0.6563s	
5497/33250 (epoch 8.266), train_loss = 1.21449748, grad/param norm = 1.6369e-01, time/batch = 0.6857s	
5498/33250 (epoch 8.268), train_loss = 1.09768552, grad/param norm = 1.3994e-01, time/batch = 0.6851s	
5499/33250 (epoch 8.269), train_loss = 0.95518413, grad/param norm = 1.4535e-01, time/batch = 0.6807s	
5500/33250 (epoch 8.271), train_loss = 1.16602495, grad/param norm = 1.4633e-01, time/batch = 0.6751s	
5501/33250 (epoch 8.272), train_loss = 0.99359565, grad/param norm = 1.2912e-01, time/batch = 0.6822s	
5502/33250 (epoch 8.274), train_loss = 0.90584617, grad/param norm = 1.3970e-01, time/batch = 0.6835s	
5503/33250 (epoch 8.275), train_loss = 1.07691952, grad/param norm = 1.3688e-01, time/batch = 0.6832s	
5504/33250 (epoch 8.277), train_loss = 0.95521139, grad/param norm = 1.4137e-01, time/batch = 0.6765s	
5505/33250 (epoch 8.278), train_loss = 1.07390092, grad/param norm = 1.3966e-01, time/batch = 0.6795s	
5506/33250 (epoch 8.280), train_loss = 1.01695479, grad/param norm = 1.3614e-01, time/batch = 0.6787s	
5507/33250 (epoch 8.281), train_loss = 1.21019949, grad/param norm = 1.6454e-01, time/batch = 0.6834s	
5508/33250 (epoch 8.283), train_loss = 1.27099574, grad/param norm = 1.5653e-01, time/batch = 0.6678s	
5509/33250 (epoch 8.284), train_loss = 1.10315123, grad/param norm = 1.5198e-01, time/batch = 0.6826s	
5510/33250 (epoch 8.286), train_loss = 1.25905599, grad/param norm = 1.6463e-01, time/batch = 0.6660s	
5511/33250 (epoch 8.287), train_loss = 1.02935457, grad/param norm = 1.3735e-01, time/batch = 0.6932s	
5512/33250 (epoch 8.289), train_loss = 1.03422219, grad/param norm = 1.4042e-01, time/batch = 0.6803s	
5513/33250 (epoch 8.290), train_loss = 1.19225380, grad/param norm = 1.4732e-01, time/batch = 0.6656s	
5514/33250 (epoch 8.292), train_loss = 1.22668523, grad/param norm = 1.6963e-01, time/batch = 0.6820s	
5515/33250 (epoch 8.293), train_loss = 1.33337694, grad/param norm = 1.8792e-01, time/batch = 0.6914s	
5516/33250 (epoch 8.295), train_loss = 1.23992459, grad/param norm = 1.6121e-01, time/batch = 0.6753s	
5517/33250 (epoch 8.296), train_loss = 1.18981631, grad/param norm = 1.5390e-01, time/batch = 0.6661s	
5518/33250 (epoch 8.298), train_loss = 0.95816964, grad/param norm = 1.2712e-01, time/batch = 0.6672s	
5519/33250 (epoch 8.299), train_loss = 0.93371980, grad/param norm = 1.4282e-01, time/batch = 0.6711s	
5520/33250 (epoch 8.301), train_loss = 1.25573982, grad/param norm = 1.5158e-01, time/batch = 0.6684s	
5521/33250 (epoch 8.302), train_loss = 1.17101880, grad/param norm = 1.5569e-01, time/batch = 0.6771s	
5522/33250 (epoch 8.304), train_loss = 1.12587226, grad/param norm = 1.3996e-01, time/batch = 0.6727s	
5523/33250 (epoch 8.305), train_loss = 1.18250027, grad/param norm = 1.5178e-01, time/batch = 0.6712s	
5524/33250 (epoch 8.307), train_loss = 1.26034053, grad/param norm = 1.5024e-01, time/batch = 0.6676s	
5525/33250 (epoch 8.308), train_loss = 1.42713118, grad/param norm = 1.8599e-01, time/batch = 0.6698s	
5526/33250 (epoch 8.310), train_loss = 1.18682933, grad/param norm = 1.6501e-01, time/batch = 0.6674s	
5527/33250 (epoch 8.311), train_loss = 1.31688453, grad/param norm = 1.7143e-01, time/batch = 0.6681s	
5528/33250 (epoch 8.313), train_loss = 1.02083344, grad/param norm = 1.5494e-01, time/batch = 0.6668s	
5529/33250 (epoch 8.314), train_loss = 1.14517451, grad/param norm = 1.5611e-01, time/batch = 0.6687s	
5530/33250 (epoch 8.316), train_loss = 1.38497328, grad/param norm = 1.8180e-01, time/batch = 0.6710s	
5531/33250 (epoch 8.317), train_loss = 1.06461645, grad/param norm = 1.4162e-01, time/batch = 0.6737s	
5532/33250 (epoch 8.319), train_loss = 1.31413692, grad/param norm = 1.8540e-01, time/batch = 0.6732s	
5533/33250 (epoch 8.320), train_loss = 1.39702333, grad/param norm = 2.0106e-01, time/batch = 0.6727s	
5534/33250 (epoch 8.322), train_loss = 1.40637541, grad/param norm = 1.8731e-01, time/batch = 0.6688s	
5535/33250 (epoch 8.323), train_loss = 1.45340766, grad/param norm = 1.8684e-01, time/batch = 0.6760s	
5536/33250 (epoch 8.325), train_loss = 1.21123237, grad/param norm = 1.6967e-01, time/batch = 0.6710s	
5537/33250 (epoch 8.326), train_loss = 1.44546394, grad/param norm = 1.8312e-01, time/batch = 0.6744s	
5538/33250 (epoch 8.328), train_loss = 1.11764305, grad/param norm = 1.7103e-01, time/batch = 0.6740s	
5539/33250 (epoch 8.329), train_loss = 1.24225457, grad/param norm = 1.7095e-01, time/batch = 0.6701s	
5540/33250 (epoch 8.331), train_loss = 1.16970776, grad/param norm = 1.7338e-01, time/batch = 0.6716s	
5541/33250 (epoch 8.332), train_loss = 1.14930532, grad/param norm = 1.6339e-01, time/batch = 0.6735s	
5542/33250 (epoch 8.334), train_loss = 1.31409272, grad/param norm = 1.5893e-01, time/batch = 0.6678s	
5543/33250 (epoch 8.335), train_loss = 0.90203541, grad/param norm = 1.6132e-01, time/batch = 0.6667s	
5544/33250 (epoch 8.337), train_loss = 1.18837366, grad/param norm = 1.5547e-01, time/batch = 0.6607s	
5545/33250 (epoch 8.338), train_loss = 1.29482864, grad/param norm = 1.5858e-01, time/batch = 0.6679s	
5546/33250 (epoch 8.340), train_loss = 1.19268679, grad/param norm = 1.5572e-01, time/batch = 0.6698s	
5547/33250 (epoch 8.341), train_loss = 1.11823795, grad/param norm = 1.5878e-01, time/batch = 0.6647s	
5548/33250 (epoch 8.343), train_loss = 1.20500355, grad/param norm = 1.6416e-01, time/batch = 0.6855s	
5549/33250 (epoch 8.344), train_loss = 1.16661230, grad/param norm = 1.6605e-01, time/batch = 0.6874s	
5550/33250 (epoch 8.346), train_loss = 1.01976201, grad/param norm = 1.3925e-01, time/batch = 0.6667s	
5551/33250 (epoch 8.347), train_loss = 1.51692396, grad/param norm = 1.7583e-01, time/batch = 0.6719s	
5552/33250 (epoch 8.349), train_loss = 1.18191764, grad/param norm = 1.6465e-01, time/batch = 0.6865s	
5553/33250 (epoch 8.350), train_loss = 1.21595875, grad/param norm = 1.6509e-01, time/batch = 0.6893s	
5554/33250 (epoch 8.352), train_loss = 1.09952318, grad/param norm = 1.7225e-01, time/batch = 0.6897s	
5555/33250 (epoch 8.353), train_loss = 1.16754053, grad/param norm = 1.4663e-01, time/batch = 0.6764s	
5556/33250 (epoch 8.355), train_loss = 1.15534581, grad/param norm = 1.5925e-01, time/batch = 0.6720s	
5557/33250 (epoch 8.356), train_loss = 1.09281529, grad/param norm = 1.6286e-01, time/batch = 0.6711s	
5558/33250 (epoch 8.358), train_loss = 1.11811915, grad/param norm = 1.5752e-01, time/batch = 0.6698s	
5559/33250 (epoch 8.359), train_loss = 1.10734922, grad/param norm = 1.4170e-01, time/batch = 0.6740s	
5560/33250 (epoch 8.361), train_loss = 1.35611211, grad/param norm = 1.7405e-01, time/batch = 0.6708s	
5561/33250 (epoch 8.362), train_loss = 1.15894876, grad/param norm = 1.4844e-01, time/batch = 0.6804s	
5562/33250 (epoch 8.364), train_loss = 1.29305878, grad/param norm = 1.7080e-01, time/batch = 0.6720s	
5563/33250 (epoch 8.365), train_loss = 1.15538941, grad/param norm = 1.5150e-01, time/batch = 0.6752s	
5564/33250 (epoch 8.367), train_loss = 1.12817710, grad/param norm = 1.4242e-01, time/batch = 0.6695s	
5565/33250 (epoch 8.368), train_loss = 1.17070281, grad/param norm = 1.5455e-01, time/batch = 0.6798s	
5566/33250 (epoch 8.370), train_loss = 1.01375026, grad/param norm = 1.4137e-01, time/batch = 0.6764s	
5567/33250 (epoch 8.371), train_loss = 1.31270489, grad/param norm = 1.7453e-01, time/batch = 0.6693s	
5568/33250 (epoch 8.373), train_loss = 1.11319884, grad/param norm = 1.5143e-01, time/batch = 0.6789s	
5569/33250 (epoch 8.374), train_loss = 1.27540878, grad/param norm = 1.7993e-01, time/batch = 0.6664s	
5570/33250 (epoch 8.376), train_loss = 1.15990745, grad/param norm = 1.6384e-01, time/batch = 0.6697s	
5571/33250 (epoch 8.377), train_loss = 1.06602244, grad/param norm = 1.6785e-01, time/batch = 0.6734s	
5572/33250 (epoch 8.379), train_loss = 1.10631734, grad/param norm = 1.6251e-01, time/batch = 0.6675s	
5573/33250 (epoch 8.380), train_loss = 1.25055631, grad/param norm = 1.8654e-01, time/batch = 0.6694s	
5574/33250 (epoch 8.382), train_loss = 1.30217425, grad/param norm = 1.7773e-01, time/batch = 0.6718s	
5575/33250 (epoch 8.383), train_loss = 1.08045796, grad/param norm = 1.5238e-01, time/batch = 0.6670s	
5576/33250 (epoch 8.385), train_loss = 1.03578237, grad/param norm = 1.6134e-01, time/batch = 0.6669s	
5577/33250 (epoch 8.386), train_loss = 1.03353310, grad/param norm = 1.4887e-01, time/batch = 0.6698s	
5578/33250 (epoch 8.388), train_loss = 1.09351807, grad/param norm = 1.5357e-01, time/batch = 0.6712s	
5579/33250 (epoch 8.389), train_loss = 1.15375133, grad/param norm = 1.7618e-01, time/batch = 0.6758s	
5580/33250 (epoch 8.391), train_loss = 1.19255434, grad/param norm = 1.8310e-01, time/batch = 0.6791s	
5581/33250 (epoch 8.392), train_loss = 1.28797128, grad/param norm = 1.6751e-01, time/batch = 0.6854s	
5582/33250 (epoch 8.394), train_loss = 1.39976597, grad/param norm = 1.9135e-01, time/batch = 0.7033s	
5583/33250 (epoch 8.395), train_loss = 1.28811444, grad/param norm = 1.5221e-01, time/batch = 0.6987s	
5584/33250 (epoch 8.397), train_loss = 1.30376401, grad/param norm = 1.7009e-01, time/batch = 0.6796s	
5585/33250 (epoch 8.398), train_loss = 1.10216394, grad/param norm = 1.5271e-01, time/batch = 0.6851s	
5586/33250 (epoch 8.400), train_loss = 1.11125655, grad/param norm = 1.6156e-01, time/batch = 0.6910s	
5587/33250 (epoch 8.402), train_loss = 1.01646383, grad/param norm = 1.5607e-01, time/batch = 0.6947s	
5588/33250 (epoch 8.403), train_loss = 1.11504913, grad/param norm = 1.7511e-01, time/batch = 0.6931s	
5589/33250 (epoch 8.405), train_loss = 1.07976394, grad/param norm = 1.6529e-01, time/batch = 0.6893s	
5590/33250 (epoch 8.406), train_loss = 1.23588397, grad/param norm = 1.6322e-01, time/batch = 0.6865s	
5591/33250 (epoch 8.408), train_loss = 1.32736150, grad/param norm = 1.7352e-01, time/batch = 0.6800s	
5592/33250 (epoch 8.409), train_loss = 1.27341513, grad/param norm = 1.7637e-01, time/batch = 0.6628s	
5593/33250 (epoch 8.411), train_loss = 0.87790280, grad/param norm = 1.2312e-01, time/batch = 0.6631s	
5594/33250 (epoch 8.412), train_loss = 1.01251412, grad/param norm = 1.4808e-01, time/batch = 0.6741s	
5595/33250 (epoch 8.414), train_loss = 1.20239786, grad/param norm = 1.5316e-01, time/batch = 0.6893s	
5596/33250 (epoch 8.415), train_loss = 1.30310543, grad/param norm = 1.6856e-01, time/batch = 0.6629s	
5597/33250 (epoch 8.417), train_loss = 1.27276217, grad/param norm = 1.7037e-01, time/batch = 0.6668s	
5598/33250 (epoch 8.418), train_loss = 1.44006377, grad/param norm = 1.9405e-01, time/batch = 0.6621s	
5599/33250 (epoch 8.420), train_loss = 1.29357774, grad/param norm = 1.5846e-01, time/batch = 0.6601s	
5600/33250 (epoch 8.421), train_loss = 1.05712946, grad/param norm = 1.5977e-01, time/batch = 0.6723s	
5601/33250 (epoch 8.423), train_loss = 1.27473402, grad/param norm = 1.9017e-01, time/batch = 0.6711s	
5602/33250 (epoch 8.424), train_loss = 1.46054957, grad/param norm = 2.1242e-01, time/batch = 0.6635s	
5603/33250 (epoch 8.426), train_loss = 1.08521074, grad/param norm = 1.4865e-01, time/batch = 0.6671s	
5604/33250 (epoch 8.427), train_loss = 1.09373632, grad/param norm = 1.5086e-01, time/batch = 0.6688s	
5605/33250 (epoch 8.429), train_loss = 1.26210054, grad/param norm = 1.7493e-01, time/batch = 0.6887s	
5606/33250 (epoch 8.430), train_loss = 1.09867028, grad/param norm = 1.7539e-01, time/batch = 0.6872s	
5607/33250 (epoch 8.432), train_loss = 1.16513372, grad/param norm = 1.4935e-01, time/batch = 0.6809s	
5608/33250 (epoch 8.433), train_loss = 1.12849080, grad/param norm = 1.5432e-01, time/batch = 0.6708s	
5609/33250 (epoch 8.435), train_loss = 1.21532134, grad/param norm = 1.7591e-01, time/batch = 0.6625s	
5610/33250 (epoch 8.436), train_loss = 1.09786423, grad/param norm = 1.6268e-01, time/batch = 0.6636s	
5611/33250 (epoch 8.438), train_loss = 1.22857947, grad/param norm = 1.5609e-01, time/batch = 0.6637s	
5612/33250 (epoch 8.439), train_loss = 1.18238970, grad/param norm = 1.6226e-01, time/batch = 0.6673s	
5613/33250 (epoch 8.441), train_loss = 1.14889918, grad/param norm = 1.5080e-01, time/batch = 0.6617s	
5614/33250 (epoch 8.442), train_loss = 1.10345467, grad/param norm = 1.7092e-01, time/batch = 0.6628s	
5615/33250 (epoch 8.444), train_loss = 1.08924251, grad/param norm = 1.7090e-01, time/batch = 0.6807s	
5616/33250 (epoch 8.445), train_loss = 1.17843356, grad/param norm = 1.7373e-01, time/batch = 0.6836s	
5617/33250 (epoch 8.447), train_loss = 1.23359906, grad/param norm = 1.6764e-01, time/batch = 0.6613s	
5618/33250 (epoch 8.448), train_loss = 1.08855301, grad/param norm = 1.2972e-01, time/batch = 0.6643s	
5619/33250 (epoch 8.450), train_loss = 1.35704140, grad/param norm = 1.7618e-01, time/batch = 0.6628s	
5620/33250 (epoch 8.451), train_loss = 1.24829923, grad/param norm = 1.7004e-01, time/batch = 0.6662s	
5621/33250 (epoch 8.453), train_loss = 1.03143657, grad/param norm = 1.4823e-01, time/batch = 0.6676s	
5622/33250 (epoch 8.454), train_loss = 1.32048461, grad/param norm = 1.6975e-01, time/batch = 0.6649s	
5623/33250 (epoch 8.456), train_loss = 1.33993978, grad/param norm = 1.7974e-01, time/batch = 0.6608s	
5624/33250 (epoch 8.457), train_loss = 1.13699325, grad/param norm = 1.6279e-01, time/batch = 0.6612s	
5625/33250 (epoch 8.459), train_loss = 1.20000577, grad/param norm = 1.5870e-01, time/batch = 0.6680s	
5626/33250 (epoch 8.460), train_loss = 1.27079418, grad/param norm = 1.7091e-01, time/batch = 0.6658s	
5627/33250 (epoch 8.462), train_loss = 1.08742987, grad/param norm = 1.5206e-01, time/batch = 0.6711s	
5628/33250 (epoch 8.463), train_loss = 1.07417935, grad/param norm = 1.3732e-01, time/batch = 0.6635s	
5629/33250 (epoch 8.465), train_loss = 0.94386613, grad/param norm = 1.2325e-01, time/batch = 0.6609s	
5630/33250 (epoch 8.466), train_loss = 0.92216270, grad/param norm = 1.2405e-01, time/batch = 0.6610s	
5631/33250 (epoch 8.468), train_loss = 1.03601726, grad/param norm = 1.3287e-01, time/batch = 0.6630s	
5632/33250 (epoch 8.469), train_loss = 1.20322855, grad/param norm = 1.7310e-01, time/batch = 0.6666s	
5633/33250 (epoch 8.471), train_loss = 1.27639072, grad/param norm = 1.5674e-01, time/batch = 0.6597s	
5634/33250 (epoch 8.472), train_loss = 1.21558971, grad/param norm = 2.0929e-01, time/batch = 0.6608s	
5635/33250 (epoch 8.474), train_loss = 1.41904780, grad/param norm = 2.1809e-01, time/batch = 0.6611s	
5636/33250 (epoch 8.475), train_loss = 1.18912532, grad/param norm = 1.5854e-01, time/batch = 0.6610s	
5637/33250 (epoch 8.477), train_loss = 1.16195183, grad/param norm = 1.5533e-01, time/batch = 0.6638s	
5638/33250 (epoch 8.478), train_loss = 1.12565565, grad/param norm = 1.4705e-01, time/batch = 0.6659s	
5639/33250 (epoch 8.480), train_loss = 1.38834310, grad/param norm = 1.6920e-01, time/batch = 0.6624s	
5640/33250 (epoch 8.481), train_loss = 1.16006129, grad/param norm = 1.7367e-01, time/batch = 0.6573s	
5641/33250 (epoch 8.483), train_loss = 1.21452958, grad/param norm = 1.4651e-01, time/batch = 0.6621s	
5642/33250 (epoch 8.484), train_loss = 1.07409034, grad/param norm = 1.4263e-01, time/batch = 0.6646s	
5643/33250 (epoch 8.486), train_loss = 0.99777364, grad/param norm = 1.5707e-01, time/batch = 0.6607s	
5644/33250 (epoch 8.487), train_loss = 1.10848983, grad/param norm = 1.5620e-01, time/batch = 0.6641s	
5645/33250 (epoch 8.489), train_loss = 1.32198067, grad/param norm = 2.0532e-01, time/batch = 0.6616s	
5646/33250 (epoch 8.490), train_loss = 1.26495630, grad/param norm = 1.9205e-01, time/batch = 0.6616s	
5647/33250 (epoch 8.492), train_loss = 1.22751739, grad/param norm = 1.6354e-01, time/batch = 0.6636s	
5648/33250 (epoch 8.493), train_loss = 1.19078770, grad/param norm = 1.8060e-01, time/batch = 0.6618s	
5649/33250 (epoch 8.495), train_loss = 1.21252886, grad/param norm = 1.5388e-01, time/batch = 0.6703s	
5650/33250 (epoch 8.496), train_loss = 1.12219695, grad/param norm = 1.3925e-01, time/batch = 0.6750s	
5651/33250 (epoch 8.498), train_loss = 1.27434267, grad/param norm = 1.6835e-01, time/batch = 0.6496s	
5652/33250 (epoch 8.499), train_loss = 1.15644484, grad/param norm = 1.5630e-01, time/batch = 0.6490s	
5653/33250 (epoch 8.501), train_loss = 1.14195506, grad/param norm = 1.7153e-01, time/batch = 0.6521s	
5654/33250 (epoch 8.502), train_loss = 1.15127312, grad/param norm = 1.4987e-01, time/batch = 0.6496s	
5655/33250 (epoch 8.504), train_loss = 1.32646398, grad/param norm = 1.8291e-01, time/batch = 0.6708s	
5656/33250 (epoch 8.505), train_loss = 0.95538897, grad/param norm = 1.2929e-01, time/batch = 0.6669s	
5657/33250 (epoch 8.507), train_loss = 1.14540893, grad/param norm = 1.5432e-01, time/batch = 0.6588s	
5658/33250 (epoch 8.508), train_loss = 1.11385200, grad/param norm = 1.4636e-01, time/batch = 0.6487s	
5659/33250 (epoch 8.510), train_loss = 0.98824935, grad/param norm = 1.4392e-01, time/batch = 0.6487s	
5660/33250 (epoch 8.511), train_loss = 1.17687880, grad/param norm = 1.6060e-01, time/batch = 0.6467s	
5661/33250 (epoch 8.513), train_loss = 1.38229438, grad/param norm = 1.6757e-01, time/batch = 0.6481s	
5662/33250 (epoch 8.514), train_loss = 1.12913714, grad/param norm = 1.5553e-01, time/batch = 0.6471s	
5663/33250 (epoch 8.516), train_loss = 1.09657077, grad/param norm = 1.5117e-01, time/batch = 0.6466s	
5664/33250 (epoch 8.517), train_loss = 1.18208742, grad/param norm = 1.4866e-01, time/batch = 0.6487s	
5665/33250 (epoch 8.519), train_loss = 1.03390601, grad/param norm = 1.3849e-01, time/batch = 0.6462s	
5666/33250 (epoch 8.520), train_loss = 1.49379344, grad/param norm = 1.8661e-01, time/batch = 0.6489s	
5667/33250 (epoch 8.522), train_loss = 1.28984578, grad/param norm = 1.8006e-01, time/batch = 0.6481s	
5668/33250 (epoch 8.523), train_loss = 1.16450711, grad/param norm = 1.6647e-01, time/batch = 0.6487s	
5669/33250 (epoch 8.525), train_loss = 1.03652358, grad/param norm = 1.5648e-01, time/batch = 0.6473s	
5670/33250 (epoch 8.526), train_loss = 1.04345157, grad/param norm = 1.4896e-01, time/batch = 0.6510s	
5671/33250 (epoch 8.528), train_loss = 1.15178709, grad/param norm = 1.5201e-01, time/batch = 0.6518s	
5672/33250 (epoch 8.529), train_loss = 1.11200958, grad/param norm = 1.5258e-01, time/batch = 0.6544s	
5673/33250 (epoch 8.531), train_loss = 1.02382744, grad/param norm = 1.4727e-01, time/batch = 0.6519s	
5674/33250 (epoch 8.532), train_loss = 1.25426922, grad/param norm = 1.7067e-01, time/batch = 0.6458s	
5675/33250 (epoch 8.534), train_loss = 1.07937635, grad/param norm = 1.4185e-01, time/batch = 0.6631s	
5676/33250 (epoch 8.535), train_loss = 1.16945522, grad/param norm = 1.5854e-01, time/batch = 0.6691s	
5677/33250 (epoch 8.537), train_loss = 1.27415027, grad/param norm = 1.5486e-01, time/batch = 0.6826s	
5678/33250 (epoch 8.538), train_loss = 1.26855210, grad/param norm = 1.6205e-01, time/batch = 0.6823s	
5679/33250 (epoch 8.540), train_loss = 1.32934537, grad/param norm = 1.5385e-01, time/batch = 0.6753s	
5680/33250 (epoch 8.541), train_loss = 1.31817904, grad/param norm = 1.7506e-01, time/batch = 0.6697s	
5681/33250 (epoch 8.543), train_loss = 1.29140747, grad/param norm = 1.6429e-01, time/batch = 0.6826s	
5682/33250 (epoch 8.544), train_loss = 1.14105479, grad/param norm = 1.5612e-01, time/batch = 0.6654s	
5683/33250 (epoch 8.546), train_loss = 1.18416511, grad/param norm = 1.8957e-01, time/batch = 0.6526s	
5684/33250 (epoch 8.547), train_loss = 1.10341241, grad/param norm = 1.5801e-01, time/batch = 0.6542s	
5685/33250 (epoch 8.549), train_loss = 1.23732675, grad/param norm = 1.6165e-01, time/batch = 0.6647s	
5686/33250 (epoch 8.550), train_loss = 1.14401428, grad/param norm = 1.5491e-01, time/batch = 0.6680s	
5687/33250 (epoch 8.552), train_loss = 1.22439792, grad/param norm = 1.6435e-01, time/batch = 0.6602s	
5688/33250 (epoch 8.553), train_loss = 1.12755622, grad/param norm = 1.6175e-01, time/batch = 0.6502s	
5689/33250 (epoch 8.555), train_loss = 1.16934114, grad/param norm = 1.5145e-01, time/batch = 0.6497s	
5690/33250 (epoch 8.556), train_loss = 1.34259318, grad/param norm = 1.8382e-01, time/batch = 0.6608s	
5691/33250 (epoch 8.558), train_loss = 1.28719018, grad/param norm = 1.6219e-01, time/batch = 0.6721s	
5692/33250 (epoch 8.559), train_loss = 1.04812967, grad/param norm = 1.4865e-01, time/batch = 0.6666s	
5693/33250 (epoch 8.561), train_loss = 1.12723350, grad/param norm = 1.5645e-01, time/batch = 0.6749s	
5694/33250 (epoch 8.562), train_loss = 1.35192859, grad/param norm = 1.7875e-01, time/batch = 0.6638s	
5695/33250 (epoch 8.564), train_loss = 1.43291625, grad/param norm = 1.8309e-01, time/batch = 0.6565s	
5696/33250 (epoch 8.565), train_loss = 1.36703602, grad/param norm = 1.8869e-01, time/batch = 0.6531s	
5697/33250 (epoch 8.567), train_loss = 1.31002129, grad/param norm = 1.5864e-01, time/batch = 0.6622s	
5698/33250 (epoch 8.568), train_loss = 1.17912280, grad/param norm = 1.6546e-01, time/batch = 0.6681s	
5699/33250 (epoch 8.570), train_loss = 1.30025686, grad/param norm = 1.6668e-01, time/batch = 0.6575s	
5700/33250 (epoch 8.571), train_loss = 1.40618791, grad/param norm = 1.7264e-01, time/batch = 0.6711s	
5701/33250 (epoch 8.573), train_loss = 1.26498747, grad/param norm = 1.6748e-01, time/batch = 0.6551s	
5702/33250 (epoch 8.574), train_loss = 1.07998231, grad/param norm = 1.5756e-01, time/batch = 0.6533s	
5703/33250 (epoch 8.576), train_loss = 1.23093481, grad/param norm = 1.5933e-01, time/batch = 0.6525s	
5704/33250 (epoch 8.577), train_loss = 1.17489888, grad/param norm = 1.5094e-01, time/batch = 0.6595s	
5705/33250 (epoch 8.579), train_loss = 1.05307562, grad/param norm = 1.4896e-01, time/batch = 0.6538s	
5706/33250 (epoch 8.580), train_loss = 1.09160132, grad/param norm = 1.4403e-01, time/batch = 0.6467s	
5707/33250 (epoch 8.582), train_loss = 1.14855798, grad/param norm = 1.5326e-01, time/batch = 0.6531s	
5708/33250 (epoch 8.583), train_loss = 1.20176340, grad/param norm = 1.5090e-01, time/batch = 0.6498s	
5709/33250 (epoch 8.585), train_loss = 1.27317131, grad/param norm = 1.6773e-01, time/batch = 0.6538s	
5710/33250 (epoch 8.586), train_loss = 1.13881379, grad/param norm = 1.8756e-01, time/batch = 0.6490s	
5711/33250 (epoch 8.588), train_loss = 1.17961190, grad/param norm = 1.5559e-01, time/batch = 0.6548s	
5712/33250 (epoch 8.589), train_loss = 1.25872341, grad/param norm = 1.6349e-01, time/batch = 0.6522s	
5713/33250 (epoch 8.591), train_loss = 1.27195686, grad/param norm = 1.8686e-01, time/batch = 0.6508s	
5714/33250 (epoch 8.592), train_loss = 1.20861604, grad/param norm = 1.5211e-01, time/batch = 0.6485s	
5715/33250 (epoch 8.594), train_loss = 1.39181038, grad/param norm = 1.8605e-01, time/batch = 0.6504s	
5716/33250 (epoch 8.595), train_loss = 1.30049067, grad/param norm = 1.7199e-01, time/batch = 0.6610s	
5717/33250 (epoch 8.597), train_loss = 1.03569175, grad/param norm = 1.4220e-01, time/batch = 0.6633s	
5718/33250 (epoch 8.598), train_loss = 1.22328072, grad/param norm = 1.6350e-01, time/batch = 0.6632s	
5719/33250 (epoch 8.600), train_loss = 1.20191781, grad/param norm = 1.7932e-01, time/batch = 0.6607s	
5720/33250 (epoch 8.602), train_loss = 1.23729609, grad/param norm = 1.8261e-01, time/batch = 0.6627s	
5721/33250 (epoch 8.603), train_loss = 1.22251175, grad/param norm = 1.6886e-01, time/batch = 0.6724s	
5722/33250 (epoch 8.605), train_loss = 1.18945389, grad/param norm = 1.6002e-01, time/batch = 0.6654s	
5723/33250 (epoch 8.606), train_loss = 1.24961624, grad/param norm = 1.5516e-01, time/batch = 0.6603s	
5724/33250 (epoch 8.608), train_loss = 1.19340850, grad/param norm = 1.5701e-01, time/batch = 0.6543s	
5725/33250 (epoch 8.609), train_loss = 1.09574475, grad/param norm = 1.6139e-01, time/batch = 0.6570s	
5726/33250 (epoch 8.611), train_loss = 1.27377488, grad/param norm = 1.6857e-01, time/batch = 0.6541s	
5727/33250 (epoch 8.612), train_loss = 1.23979867, grad/param norm = 1.6755e-01, time/batch = 0.6489s	
5728/33250 (epoch 8.614), train_loss = 1.47867096, grad/param norm = 1.8650e-01, time/batch = 0.6511s	
5729/33250 (epoch 8.615), train_loss = 1.32394982, grad/param norm = 1.6175e-01, time/batch = 0.6588s	
5730/33250 (epoch 8.617), train_loss = 1.60385120, grad/param norm = 1.9861e-01, time/batch = 0.6510s	
5731/33250 (epoch 8.618), train_loss = 1.56037791, grad/param norm = 2.1895e-01, time/batch = 0.6469s	
5732/33250 (epoch 8.620), train_loss = 1.33972781, grad/param norm = 1.7351e-01, time/batch = 0.6490s	
5733/33250 (epoch 8.621), train_loss = 1.16231826, grad/param norm = 1.5180e-01, time/batch = 0.6580s	
5734/33250 (epoch 8.623), train_loss = 1.11582374, grad/param norm = 1.6190e-01, time/batch = 0.6503s	
5735/33250 (epoch 8.624), train_loss = 1.17785187, grad/param norm = 1.7865e-01, time/batch = 0.6552s	
5736/33250 (epoch 8.626), train_loss = 1.16637626, grad/param norm = 1.6611e-01, time/batch = 0.6573s	
5737/33250 (epoch 8.627), train_loss = 1.11881809, grad/param norm = 1.4698e-01, time/batch = 0.6492s	
5738/33250 (epoch 8.629), train_loss = 1.19593655, grad/param norm = 1.8344e-01, time/batch = 0.6553s	
5739/33250 (epoch 8.630), train_loss = 1.15513019, grad/param norm = 1.5658e-01, time/batch = 0.6580s	
5740/33250 (epoch 8.632), train_loss = 0.98053822, grad/param norm = 1.3528e-01, time/batch = 0.6581s	
5741/33250 (epoch 8.633), train_loss = 1.26645258, grad/param norm = 1.6960e-01, time/batch = 0.6630s	
5742/33250 (epoch 8.635), train_loss = 1.06309161, grad/param norm = 1.4400e-01, time/batch = 0.6697s	
5743/33250 (epoch 8.636), train_loss = 1.07325325, grad/param norm = 1.4604e-01, time/batch = 0.6653s	
5744/33250 (epoch 8.638), train_loss = 1.12711509, grad/param norm = 1.5451e-01, time/batch = 0.6602s	
5745/33250 (epoch 8.639), train_loss = 1.06432304, grad/param norm = 1.4852e-01, time/batch = 0.6592s	
5746/33250 (epoch 8.641), train_loss = 1.07392734, grad/param norm = 1.5148e-01, time/batch = 0.6645s	
5747/33250 (epoch 8.642), train_loss = 1.00708454, grad/param norm = 1.4761e-01, time/batch = 0.6545s	
5748/33250 (epoch 8.644), train_loss = 0.92113063, grad/param norm = 1.3403e-01, time/batch = 0.6585s	
5749/33250 (epoch 8.645), train_loss = 1.30749370, grad/param norm = 1.7050e-01, time/batch = 0.6499s	
5750/33250 (epoch 8.647), train_loss = 1.04762287, grad/param norm = 1.4965e-01, time/batch = 0.6528s	
5751/33250 (epoch 8.648), train_loss = 1.15795236, grad/param norm = 1.7322e-01, time/batch = 0.6488s	
5752/33250 (epoch 8.650), train_loss = 1.33189138, grad/param norm = 1.7090e-01, time/batch = 0.6495s	
5753/33250 (epoch 8.651), train_loss = 1.20772447, grad/param norm = 1.7678e-01, time/batch = 0.6476s	
5754/33250 (epoch 8.653), train_loss = 1.04867811, grad/param norm = 1.4171e-01, time/batch = 0.6589s	
5755/33250 (epoch 8.654), train_loss = 1.09390362, grad/param norm = 1.5040e-01, time/batch = 0.6735s	
5756/33250 (epoch 8.656), train_loss = 1.23794906, grad/param norm = 1.6519e-01, time/batch = 0.6722s	
5757/33250 (epoch 8.657), train_loss = 0.95767712, grad/param norm = 1.5453e-01, time/batch = 0.6693s	
5758/33250 (epoch 8.659), train_loss = 1.16500525, grad/param norm = 1.6659e-01, time/batch = 0.6677s	
5759/33250 (epoch 8.660), train_loss = 1.12659658, grad/param norm = 1.6636e-01, time/batch = 0.6648s	
5760/33250 (epoch 8.662), train_loss = 1.21870910, grad/param norm = 1.5652e-01, time/batch = 0.6663s	
5761/33250 (epoch 8.663), train_loss = 1.12119504, grad/param norm = 1.5640e-01, time/batch = 0.6700s	
5762/33250 (epoch 8.665), train_loss = 1.27004827, grad/param norm = 1.7005e-01, time/batch = 0.6677s	
5763/33250 (epoch 8.666), train_loss = 1.13851138, grad/param norm = 1.6376e-01, time/batch = 0.6665s	
5764/33250 (epoch 8.668), train_loss = 1.34212315, grad/param norm = 1.7037e-01, time/batch = 0.6462s	
5765/33250 (epoch 8.669), train_loss = 1.23919436, grad/param norm = 1.5933e-01, time/batch = 0.6558s	
5766/33250 (epoch 8.671), train_loss = 1.17501636, grad/param norm = 1.7538e-01, time/batch = 0.6733s	
5767/33250 (epoch 8.672), train_loss = 1.31723736, grad/param norm = 1.7787e-01, time/batch = 0.6774s	
5768/33250 (epoch 8.674), train_loss = 1.15233029, grad/param norm = 1.4978e-01, time/batch = 0.6774s	
5769/33250 (epoch 8.675), train_loss = 1.17986470, grad/param norm = 1.5609e-01, time/batch = 0.6729s	
5770/33250 (epoch 8.677), train_loss = 1.28747842, grad/param norm = 1.6293e-01, time/batch = 0.6716s	
5771/33250 (epoch 8.678), train_loss = 1.25012480, grad/param norm = 1.6427e-01, time/batch = 0.6736s	
5772/33250 (epoch 8.680), train_loss = 1.30240857, grad/param norm = 1.6903e-01, time/batch = 0.6694s	
5773/33250 (epoch 8.681), train_loss = 1.02745549, grad/param norm = 1.4834e-01, time/batch = 0.6702s	
5774/33250 (epoch 8.683), train_loss = 1.12490805, grad/param norm = 1.6617e-01, time/batch = 0.6643s	
5775/33250 (epoch 8.684), train_loss = 1.08550193, grad/param norm = 1.6063e-01, time/batch = 0.6682s	
5776/33250 (epoch 8.686), train_loss = 1.07814139, grad/param norm = 1.4945e-01, time/batch = 0.6598s	
5777/33250 (epoch 8.687), train_loss = 1.11729651, grad/param norm = 1.5799e-01, time/batch = 0.6471s	
5778/33250 (epoch 8.689), train_loss = 1.12884602, grad/param norm = 1.5228e-01, time/batch = 0.6541s	
5779/33250 (epoch 8.690), train_loss = 1.24090847, grad/param norm = 1.6883e-01, time/batch = 0.6539s	
5780/33250 (epoch 8.692), train_loss = 1.21130132, grad/param norm = 1.7437e-01, time/batch = 0.6562s	
5781/33250 (epoch 8.693), train_loss = 1.18558754, grad/param norm = 1.4840e-01, time/batch = 0.6705s	
5782/33250 (epoch 8.695), train_loss = 1.23080111, grad/param norm = 1.5817e-01, time/batch = 0.6680s	
5783/33250 (epoch 8.696), train_loss = 1.17220086, grad/param norm = 1.5115e-01, time/batch = 0.6608s	
5784/33250 (epoch 8.698), train_loss = 1.10931412, grad/param norm = 1.5889e-01, time/batch = 0.6585s	
5785/33250 (epoch 8.699), train_loss = 1.38664915, grad/param norm = 1.5987e-01, time/batch = 0.6468s	
5786/33250 (epoch 8.701), train_loss = 1.12539264, grad/param norm = 1.4251e-01, time/batch = 0.6522s	
5787/33250 (epoch 8.702), train_loss = 1.21110441, grad/param norm = 1.8084e-01, time/batch = 0.6563s	
5788/33250 (epoch 8.704), train_loss = 1.39492331, grad/param norm = 1.7384e-01, time/batch = 0.6541s	
5789/33250 (epoch 8.705), train_loss = 1.04355993, grad/param norm = 1.4347e-01, time/batch = 0.6522s	
5790/33250 (epoch 8.707), train_loss = 0.99254094, grad/param norm = 1.4426e-01, time/batch = 0.6624s	
5791/33250 (epoch 8.708), train_loss = 1.24853090, grad/param norm = 1.7057e-01, time/batch = 0.6671s	
5792/33250 (epoch 8.710), train_loss = 1.27371530, grad/param norm = 1.6077e-01, time/batch = 0.6603s	
5793/33250 (epoch 8.711), train_loss = 1.19133867, grad/param norm = 1.8742e-01, time/batch = 0.6638s	
5794/33250 (epoch 8.713), train_loss = 1.27479961, grad/param norm = 1.6562e-01, time/batch = 0.6567s	
5795/33250 (epoch 8.714), train_loss = 1.20264230, grad/param norm = 1.5635e-01, time/batch = 0.6519s	
5796/33250 (epoch 8.716), train_loss = 1.30889565, grad/param norm = 1.6904e-01, time/batch = 0.6543s	
5797/33250 (epoch 8.717), train_loss = 1.11829634, grad/param norm = 1.4622e-01, time/batch = 0.6597s	
5798/33250 (epoch 8.719), train_loss = 1.18822963, grad/param norm = 1.5344e-01, time/batch = 0.6629s	
5799/33250 (epoch 8.720), train_loss = 1.42890562, grad/param norm = 1.6320e-01, time/batch = 0.6549s	
5800/33250 (epoch 8.722), train_loss = 1.06725623, grad/param norm = 1.4685e-01, time/batch = 0.6511s	
5801/33250 (epoch 8.723), train_loss = 0.97246531, grad/param norm = 1.3654e-01, time/batch = 0.6490s	
5802/33250 (epoch 8.725), train_loss = 0.99964456, grad/param norm = 1.3387e-01, time/batch = 0.6545s	
5803/33250 (epoch 8.726), train_loss = 1.10559654, grad/param norm = 1.3783e-01, time/batch = 0.6650s	
5804/33250 (epoch 8.728), train_loss = 1.24605532, grad/param norm = 1.5726e-01, time/batch = 0.6494s	
5805/33250 (epoch 8.729), train_loss = 1.35786209, grad/param norm = 1.7571e-01, time/batch = 0.6448s	
5806/33250 (epoch 8.731), train_loss = 1.13525014, grad/param norm = 1.5967e-01, time/batch = 0.6486s	
5807/33250 (epoch 8.732), train_loss = 1.07638289, grad/param norm = 1.5073e-01, time/batch = 0.6549s	
5808/33250 (epoch 8.734), train_loss = 1.21993532, grad/param norm = 1.5799e-01, time/batch = 0.6504s	
5809/33250 (epoch 8.735), train_loss = 1.19623150, grad/param norm = 1.6165e-01, time/batch = 0.6496s	
5810/33250 (epoch 8.737), train_loss = 1.19298339, grad/param norm = 1.3640e-01, time/batch = 0.6482s	
5811/33250 (epoch 8.738), train_loss = 1.17401736, grad/param norm = 1.5451e-01, time/batch = 0.6586s	
5812/33250 (epoch 8.740), train_loss = 1.32817635, grad/param norm = 1.6038e-01, time/batch = 0.6530s	
5813/33250 (epoch 8.741), train_loss = 1.24446611, grad/param norm = 1.5196e-01, time/batch = 0.6563s	
5814/33250 (epoch 8.743), train_loss = 1.14173889, grad/param norm = 1.5237e-01, time/batch = 0.6536s	
5815/33250 (epoch 8.744), train_loss = 1.17655172, grad/param norm = 1.4660e-01, time/batch = 0.6449s	
5816/33250 (epoch 8.746), train_loss = 1.17075524, grad/param norm = 1.3734e-01, time/batch = 0.6510s	
5817/33250 (epoch 8.747), train_loss = 1.13660054, grad/param norm = 1.6005e-01, time/batch = 0.6467s	
5818/33250 (epoch 8.749), train_loss = 1.34756899, grad/param norm = 1.9716e-01, time/batch = 0.6439s	
5819/33250 (epoch 8.750), train_loss = 1.21854305, grad/param norm = 1.6160e-01, time/batch = 0.6540s	
5820/33250 (epoch 8.752), train_loss = 1.07323256, grad/param norm = 1.5189e-01, time/batch = 0.6528s	
5821/33250 (epoch 8.753), train_loss = 1.15976092, grad/param norm = 1.5001e-01, time/batch = 0.6490s	
5822/33250 (epoch 8.755), train_loss = 1.13966259, grad/param norm = 1.5967e-01, time/batch = 0.6487s	
5823/33250 (epoch 8.756), train_loss = 1.28938811, grad/param norm = 1.7096e-01, time/batch = 0.6479s	
5824/33250 (epoch 8.758), train_loss = 1.30375437, grad/param norm = 1.6007e-01, time/batch = 0.6475s	
5825/33250 (epoch 8.759), train_loss = 1.08096072, grad/param norm = 1.5036e-01, time/batch = 0.6491s	
5826/33250 (epoch 8.761), train_loss = 1.11449640, grad/param norm = 1.5005e-01, time/batch = 0.6472s	
5827/33250 (epoch 8.762), train_loss = 1.27409531, grad/param norm = 1.5834e-01, time/batch = 0.6480s	
5828/33250 (epoch 8.764), train_loss = 1.12330928, grad/param norm = 1.8284e-01, time/batch = 0.6493s	
5829/33250 (epoch 8.765), train_loss = 1.21847566, grad/param norm = 1.6064e-01, time/batch = 0.6478s	
5830/33250 (epoch 8.767), train_loss = 0.99088697, grad/param norm = 1.5270e-01, time/batch = 0.6474s	
5831/33250 (epoch 8.768), train_loss = 1.04123453, grad/param norm = 1.4931e-01, time/batch = 0.6547s	
5832/33250 (epoch 8.770), train_loss = 1.26350181, grad/param norm = 1.7483e-01, time/batch = 0.6510s	
5833/33250 (epoch 8.771), train_loss = 1.23977409, grad/param norm = 1.6570e-01, time/batch = 0.6575s	
5834/33250 (epoch 8.773), train_loss = 1.15295575, grad/param norm = 1.7013e-01, time/batch = 0.6517s	
5835/33250 (epoch 8.774), train_loss = 1.00944599, grad/param norm = 1.5428e-01, time/batch = 0.6475s	
5836/33250 (epoch 8.776), train_loss = 1.13132691, grad/param norm = 1.5880e-01, time/batch = 0.6509s	
5837/33250 (epoch 8.777), train_loss = 1.27958157, grad/param norm = 1.9676e-01, time/batch = 0.6525s	
5838/33250 (epoch 8.779), train_loss = 1.11459843, grad/param norm = 1.5493e-01, time/batch = 0.6578s	
5839/33250 (epoch 8.780), train_loss = 1.39203830, grad/param norm = 1.7591e-01, time/batch = 0.6602s	
5840/33250 (epoch 8.782), train_loss = 1.21136338, grad/param norm = 1.4085e-01, time/batch = 0.6445s	
5841/33250 (epoch 8.783), train_loss = 0.96449191, grad/param norm = 1.4195e-01, time/batch = 0.6533s	
5842/33250 (epoch 8.785), train_loss = 1.06387740, grad/param norm = 1.5214e-01, time/batch = 0.6454s	
5843/33250 (epoch 8.786), train_loss = 1.25245196, grad/param norm = 1.5598e-01, time/batch = 0.6474s	
5844/33250 (epoch 8.788), train_loss = 1.23422204, grad/param norm = 1.5212e-01, time/batch = 0.6521s	
5845/33250 (epoch 8.789), train_loss = 1.29742556, grad/param norm = 1.8781e-01, time/batch = 0.6468s	
5846/33250 (epoch 8.791), train_loss = 1.34503588, grad/param norm = 1.6259e-01, time/batch = 0.6453s	
5847/33250 (epoch 8.792), train_loss = 1.41508156, grad/param norm = 1.5645e-01, time/batch = 0.6400s	
5848/33250 (epoch 8.794), train_loss = 1.16660243, grad/param norm = 1.6764e-01, time/batch = 0.6458s	
5849/33250 (epoch 8.795), train_loss = 1.24758695, grad/param norm = 1.5555e-01, time/batch = 0.6450s	
5850/33250 (epoch 8.797), train_loss = 1.31636745, grad/param norm = 1.8428e-01, time/batch = 0.6445s	
5851/33250 (epoch 8.798), train_loss = 1.21895115, grad/param norm = 1.8514e-01, time/batch = 0.6442s	
5852/33250 (epoch 8.800), train_loss = 1.27583100, grad/param norm = 1.7615e-01, time/batch = 0.6434s	
5853/33250 (epoch 8.802), train_loss = 1.13761233, grad/param norm = 1.6068e-01, time/batch = 0.6472s	
5854/33250 (epoch 8.803), train_loss = 1.15995624, grad/param norm = 1.5514e-01, time/batch = 0.6486s	
5855/33250 (epoch 8.805), train_loss = 1.23951985, grad/param norm = 1.6438e-01, time/batch = 0.6499s	
5856/33250 (epoch 8.806), train_loss = 1.25080671, grad/param norm = 1.5388e-01, time/batch = 0.6478s	
5857/33250 (epoch 8.808), train_loss = 1.17828939, grad/param norm = 1.5396e-01, time/batch = 0.6655s	
5858/33250 (epoch 8.809), train_loss = 1.05834007, grad/param norm = 1.5208e-01, time/batch = 0.6684s	
5859/33250 (epoch 8.811), train_loss = 1.08951692, grad/param norm = 1.4971e-01, time/batch = 0.6738s	
5860/33250 (epoch 8.812), train_loss = 1.24307708, grad/param norm = 1.6341e-01, time/batch = 0.6565s	
5861/33250 (epoch 8.814), train_loss = 1.20366310, grad/param norm = 1.6438e-01, time/batch = 0.6615s	
5862/33250 (epoch 8.815), train_loss = 1.25874128, grad/param norm = 1.6951e-01, time/batch = 0.6527s	
5863/33250 (epoch 8.817), train_loss = 1.17850617, grad/param norm = 1.5405e-01, time/batch = 0.6502s	
5864/33250 (epoch 8.818), train_loss = 1.09447893, grad/param norm = 1.5198e-01, time/batch = 0.6399s	
5865/33250 (epoch 8.820), train_loss = 1.19987984, grad/param norm = 1.5610e-01, time/batch = 0.6415s	
5866/33250 (epoch 8.821), train_loss = 1.10042874, grad/param norm = 1.3946e-01, time/batch = 0.6620s	
5867/33250 (epoch 8.823), train_loss = 1.48761051, grad/param norm = 1.9497e-01, time/batch = 0.6628s	
5868/33250 (epoch 8.824), train_loss = 1.18271008, grad/param norm = 1.6029e-01, time/batch = 0.6476s	
5869/33250 (epoch 8.826), train_loss = 1.20155128, grad/param norm = 1.6479e-01, time/batch = 0.6476s	
5870/33250 (epoch 8.827), train_loss = 0.94744399, grad/param norm = 1.4726e-01, time/batch = 0.6474s	
5871/33250 (epoch 8.829), train_loss = 1.19117933, grad/param norm = 1.7972e-01, time/batch = 0.6467s	
5872/33250 (epoch 8.830), train_loss = 1.33184562, grad/param norm = 1.7780e-01, time/batch = 0.6460s	
5873/33250 (epoch 8.832), train_loss = 1.16167787, grad/param norm = 1.5152e-01, time/batch = 0.6454s	
5874/33250 (epoch 8.833), train_loss = 1.24747010, grad/param norm = 1.6244e-01, time/batch = 0.6439s	
5875/33250 (epoch 8.835), train_loss = 1.15106735, grad/param norm = 1.7792e-01, time/batch = 0.6447s	
5876/33250 (epoch 8.836), train_loss = 1.18570957, grad/param norm = 1.4764e-01, time/batch = 0.6489s	
5877/33250 (epoch 8.838), train_loss = 1.13299585, grad/param norm = 1.5824e-01, time/batch = 0.6446s	
5878/33250 (epoch 8.839), train_loss = 1.13621615, grad/param norm = 1.6750e-01, time/batch = 0.6578s	
5879/33250 (epoch 8.841), train_loss = 1.01846093, grad/param norm = 1.3155e-01, time/batch = 0.6496s	
5880/33250 (epoch 8.842), train_loss = 1.34741370, grad/param norm = 1.5909e-01, time/batch = 0.6523s	
5881/33250 (epoch 8.844), train_loss = 1.32565267, grad/param norm = 1.7899e-01, time/batch = 0.6451s	
5882/33250 (epoch 8.845), train_loss = 1.45097621, grad/param norm = 1.9920e-01, time/batch = 0.6419s	
5883/33250 (epoch 8.847), train_loss = 1.37066779, grad/param norm = 1.7897e-01, time/batch = 0.6524s	
5884/33250 (epoch 8.848), train_loss = 1.50069662, grad/param norm = 1.9021e-01, time/batch = 0.6436s	
5885/33250 (epoch 8.850), train_loss = 1.30299553, grad/param norm = 1.5321e-01, time/batch = 0.6494s	
5886/33250 (epoch 8.851), train_loss = 1.10339683, grad/param norm = 1.5986e-01, time/batch = 0.6591s	
5887/33250 (epoch 8.853), train_loss = 1.24132889, grad/param norm = 1.7008e-01, time/batch = 0.6750s	
5888/33250 (epoch 8.854), train_loss = 1.06404933, grad/param norm = 1.4264e-01, time/batch = 0.6464s	
5889/33250 (epoch 8.856), train_loss = 1.11350808, grad/param norm = 1.6528e-01, time/batch = 0.6482s	
5890/33250 (epoch 8.857), train_loss = 1.01765636, grad/param norm = 1.4552e-01, time/batch = 0.6426s	
5891/33250 (epoch 8.859), train_loss = 1.00459207, grad/param norm = 1.3661e-01, time/batch = 0.6476s	
5892/33250 (epoch 8.860), train_loss = 1.17332018, grad/param norm = 1.4172e-01, time/batch = 0.6449s	
5893/33250 (epoch 8.862), train_loss = 1.06397445, grad/param norm = 1.3614e-01, time/batch = 0.6449s	
5894/33250 (epoch 8.863), train_loss = 1.09865235, grad/param norm = 1.4546e-01, time/batch = 0.6464s	
5895/33250 (epoch 8.865), train_loss = 1.23191225, grad/param norm = 1.5877e-01, time/batch = 0.6440s	
5896/33250 (epoch 8.866), train_loss = 1.12117436, grad/param norm = 1.5986e-01, time/batch = 0.6431s	
5897/33250 (epoch 8.868), train_loss = 1.40870919, grad/param norm = 2.0855e-01, time/batch = 0.6604s	
5898/33250 (epoch 8.869), train_loss = 1.27905046, grad/param norm = 1.7526e-01, time/batch = 0.6522s	
5899/33250 (epoch 8.871), train_loss = 0.96094213, grad/param norm = 1.4335e-01, time/batch = 0.6473s	
5900/33250 (epoch 8.872), train_loss = 1.19817117, grad/param norm = 1.5154e-01, time/batch = 0.6492s	
5901/33250 (epoch 8.874), train_loss = 1.10406165, grad/param norm = 1.6304e-01, time/batch = 0.6482s	
5902/33250 (epoch 8.875), train_loss = 1.09817538, grad/param norm = 1.5879e-01, time/batch = 0.6421s	
5903/33250 (epoch 8.877), train_loss = 1.26562813, grad/param norm = 1.6403e-01, time/batch = 0.6483s	
5904/33250 (epoch 8.878), train_loss = 1.21274440, grad/param norm = 1.5311e-01, time/batch = 0.6445s	
5905/33250 (epoch 8.880), train_loss = 1.19548931, grad/param norm = 1.8005e-01, time/batch = 0.6446s	
5906/33250 (epoch 8.881), train_loss = 1.41078630, grad/param norm = 1.8168e-01, time/batch = 0.6447s	
5907/33250 (epoch 8.883), train_loss = 1.22773407, grad/param norm = 1.7553e-01, time/batch = 0.6442s	
5908/33250 (epoch 8.884), train_loss = 1.19016729, grad/param norm = 1.7917e-01, time/batch = 0.6688s	
5909/33250 (epoch 8.886), train_loss = 1.07439193, grad/param norm = 1.3370e-01, time/batch = 0.6610s	
5910/33250 (epoch 8.887), train_loss = 1.14819233, grad/param norm = 1.4956e-01, time/batch = 0.6439s	
5911/33250 (epoch 8.889), train_loss = 1.10361575, grad/param norm = 1.3129e-01, time/batch = 0.6463s	
5912/33250 (epoch 8.890), train_loss = 0.99551291, grad/param norm = 1.2820e-01, time/batch = 0.6517s	
5913/33250 (epoch 8.892), train_loss = 1.25597717, grad/param norm = 1.4997e-01, time/batch = 0.6459s	
5914/33250 (epoch 8.893), train_loss = 1.29154532, grad/param norm = 1.7044e-01, time/batch = 0.6443s	
5915/33250 (epoch 8.895), train_loss = 1.15340679, grad/param norm = 1.6601e-01, time/batch = 0.6485s	
5916/33250 (epoch 8.896), train_loss = 1.26358397, grad/param norm = 1.6774e-01, time/batch = 0.6484s	
5917/33250 (epoch 8.898), train_loss = 1.13132545, grad/param norm = 1.5822e-01, time/batch = 0.6464s	
5918/33250 (epoch 8.899), train_loss = 1.09627329, grad/param norm = 1.4600e-01, time/batch = 0.6459s	
5919/33250 (epoch 8.901), train_loss = 1.00937943, grad/param norm = 1.3849e-01, time/batch = 0.6453s	
5920/33250 (epoch 8.902), train_loss = 1.14238953, grad/param norm = 1.5982e-01, time/batch = 0.6628s	
5921/33250 (epoch 8.904), train_loss = 1.09106978, grad/param norm = 1.3978e-01, time/batch = 0.6771s	
5922/33250 (epoch 8.905), train_loss = 1.09589912, grad/param norm = 1.5185e-01, time/batch = 0.6748s	
5923/33250 (epoch 8.907), train_loss = 1.08655323, grad/param norm = 1.5109e-01, time/batch = 0.6731s	
5924/33250 (epoch 8.908), train_loss = 1.18257100, grad/param norm = 1.4618e-01, time/batch = 0.6664s	
5925/33250 (epoch 8.910), train_loss = 1.27216224, grad/param norm = 1.6880e-01, time/batch = 0.6464s	
5926/33250 (epoch 8.911), train_loss = 0.96153913, grad/param norm = 1.4926e-01, time/batch = 0.6465s	
5927/33250 (epoch 8.913), train_loss = 1.13331828, grad/param norm = 1.4970e-01, time/batch = 0.6605s	
5928/33250 (epoch 8.914), train_loss = 0.97145288, grad/param norm = 1.5039e-01, time/batch = 0.6597s	
5929/33250 (epoch 8.916), train_loss = 1.08804564, grad/param norm = 1.3611e-01, time/batch = 0.6486s	
5930/33250 (epoch 8.917), train_loss = 1.09277765, grad/param norm = 1.3674e-01, time/batch = 0.6540s	
5931/33250 (epoch 8.919), train_loss = 1.12421702, grad/param norm = 1.7241e-01, time/batch = 0.6498s	
5932/33250 (epoch 8.920), train_loss = 1.18605556, grad/param norm = 1.5993e-01, time/batch = 0.6682s	
5933/33250 (epoch 8.922), train_loss = 1.19394039, grad/param norm = 1.5950e-01, time/batch = 0.6514s	
5934/33250 (epoch 8.923), train_loss = 1.15096247, grad/param norm = 1.5170e-01, time/batch = 0.6482s	
5935/33250 (epoch 8.925), train_loss = 1.10530147, grad/param norm = 1.4133e-01, time/batch = 0.6499s	
5936/33250 (epoch 8.926), train_loss = 1.11638846, grad/param norm = 1.6117e-01, time/batch = 0.6470s	
5937/33250 (epoch 8.928), train_loss = 1.16021000, grad/param norm = 1.5330e-01, time/batch = 0.6490s	
5938/33250 (epoch 8.929), train_loss = 0.90701209, grad/param norm = 1.2262e-01, time/batch = 0.6521s	
5939/33250 (epoch 8.931), train_loss = 1.21178283, grad/param norm = 1.5568e-01, time/batch = 0.6537s	
5940/33250 (epoch 8.932), train_loss = 1.21993367, grad/param norm = 1.7019e-01, time/batch = 0.6479s	
5941/33250 (epoch 8.934), train_loss = 1.08266940, grad/param norm = 1.3191e-01, time/batch = 0.6565s	
5942/33250 (epoch 8.935), train_loss = 1.15731925, grad/param norm = 1.7234e-01, time/batch = 0.6704s	
5943/33250 (epoch 8.937), train_loss = 1.22674989, grad/param norm = 1.7096e-01, time/batch = 0.6704s	
5944/33250 (epoch 8.938), train_loss = 1.24132720, grad/param norm = 1.5655e-01, time/batch = 0.6650s	
5945/33250 (epoch 8.940), train_loss = 1.14040698, grad/param norm = 1.7160e-01, time/batch = 0.6637s	
5946/33250 (epoch 8.941), train_loss = 1.19245316, grad/param norm = 1.5995e-01, time/batch = 0.6705s	
5947/33250 (epoch 8.943), train_loss = 1.37688183, grad/param norm = 1.7010e-01, time/batch = 0.6623s	
5948/33250 (epoch 8.944), train_loss = 1.04924494, grad/param norm = 1.3944e-01, time/batch = 0.6678s	
5949/33250 (epoch 8.946), train_loss = 1.34612585, grad/param norm = 1.5334e-01, time/batch = 0.6840s	
5950/33250 (epoch 8.947), train_loss = 1.09519231, grad/param norm = 1.5404e-01, time/batch = 0.6871s	
5951/33250 (epoch 8.949), train_loss = 1.30691355, grad/param norm = 1.5789e-01, time/batch = 0.6780s	
5952/33250 (epoch 8.950), train_loss = 1.18829337, grad/param norm = 1.4858e-01, time/batch = 0.6647s	
5953/33250 (epoch 8.952), train_loss = 1.14100554, grad/param norm = 1.5369e-01, time/batch = 0.6639s	
5954/33250 (epoch 8.953), train_loss = 1.26836439, grad/param norm = 1.7080e-01, time/batch = 0.6562s	
5955/33250 (epoch 8.955), train_loss = 1.26338076, grad/param norm = 1.6006e-01, time/batch = 0.6635s	
5956/33250 (epoch 8.956), train_loss = 1.29521823, grad/param norm = 1.7908e-01, time/batch = 0.6649s	
5957/33250 (epoch 8.958), train_loss = 1.06444586, grad/param norm = 1.5157e-01, time/batch = 0.6624s	
5958/33250 (epoch 8.959), train_loss = 1.08977323, grad/param norm = 1.4052e-01, time/batch = 0.6636s	
5959/33250 (epoch 8.961), train_loss = 1.35131331, grad/param norm = 1.5739e-01, time/batch = 0.6706s	
5960/33250 (epoch 8.962), train_loss = 1.21882427, grad/param norm = 1.5555e-01, time/batch = 0.6703s	
5961/33250 (epoch 8.964), train_loss = 1.36266223, grad/param norm = 1.6648e-01, time/batch = 0.6693s	
5962/33250 (epoch 8.965), train_loss = 1.24291422, grad/param norm = 1.8908e-01, time/batch = 0.6700s	
5963/33250 (epoch 8.967), train_loss = 1.20412076, grad/param norm = 1.6932e-01, time/batch = 0.6623s	
5964/33250 (epoch 8.968), train_loss = 1.43156146, grad/param norm = 1.5833e-01, time/batch = 0.6612s	
5965/33250 (epoch 8.970), train_loss = 1.50886803, grad/param norm = 1.8400e-01, time/batch = 0.6579s	
5966/33250 (epoch 8.971), train_loss = 1.32595520, grad/param norm = 1.7971e-01, time/batch = 0.6592s	
5967/33250 (epoch 8.973), train_loss = 1.12753624, grad/param norm = 1.5672e-01, time/batch = 0.6696s	
5968/33250 (epoch 8.974), train_loss = 1.21935938, grad/param norm = 1.6434e-01, time/batch = 0.6685s	
5969/33250 (epoch 8.976), train_loss = 1.12854515, grad/param norm = 1.6272e-01, time/batch = 0.6659s	
5970/33250 (epoch 8.977), train_loss = 1.10240370, grad/param norm = 1.6154e-01, time/batch = 0.6651s	
5971/33250 (epoch 8.979), train_loss = 1.20683371, grad/param norm = 1.6613e-01, time/batch = 0.6671s	
5972/33250 (epoch 8.980), train_loss = 1.16248510, grad/param norm = 1.3836e-01, time/batch = 0.6627s	
5973/33250 (epoch 8.982), train_loss = 0.98041016, grad/param norm = 1.3388e-01, time/batch = 0.6642s	
5974/33250 (epoch 8.983), train_loss = 1.23818227, grad/param norm = 1.7100e-01, time/batch = 0.6631s	
5975/33250 (epoch 8.985), train_loss = 1.09549086, grad/param norm = 1.5759e-01, time/batch = 0.6669s	
5976/33250 (epoch 8.986), train_loss = 1.28264964, grad/param norm = 1.7860e-01, time/batch = 0.6604s	
5977/33250 (epoch 8.988), train_loss = 1.27791835, grad/param norm = 1.8230e-01, time/batch = 0.6657s	
5978/33250 (epoch 8.989), train_loss = 1.31725260, grad/param norm = 1.7930e-01, time/batch = 0.6808s	
5979/33250 (epoch 8.991), train_loss = 1.18031029, grad/param norm = 1.6480e-01, time/batch = 0.6743s	
5980/33250 (epoch 8.992), train_loss = 1.15935792, grad/param norm = 1.5620e-01, time/batch = 0.6868s	
5981/33250 (epoch 8.994), train_loss = 1.09411413, grad/param norm = 1.5291e-01, time/batch = 0.6889s	
5982/33250 (epoch 8.995), train_loss = 1.21176468, grad/param norm = 1.8626e-01, time/batch = 0.6934s	
5983/33250 (epoch 8.997), train_loss = 0.87956385, grad/param norm = 1.4419e-01, time/batch = 0.6965s	
5984/33250 (epoch 8.998), train_loss = 1.15304550, grad/param norm = 1.4925e-01, time/batch = 0.6907s	
5985/33250 (epoch 9.000), train_loss = 1.18513281, grad/param norm = 1.5612e-01, time/batch = 0.6945s	
5986/33250 (epoch 9.002), train_loss = 1.34686881, grad/param norm = 1.7661e-01, time/batch = 0.6898s	
5987/33250 (epoch 9.003), train_loss = 1.24347199, grad/param norm = 1.5841e-01, time/batch = 0.6715s	
5988/33250 (epoch 9.005), train_loss = 0.95921707, grad/param norm = 1.3245e-01, time/batch = 0.8105s	
5989/33250 (epoch 9.006), train_loss = 1.00583710, grad/param norm = 1.4212e-01, time/batch = 0.9961s	
5990/33250 (epoch 9.008), train_loss = 1.32515457, grad/param norm = 1.6412e-01, time/batch = 0.9750s	
5991/33250 (epoch 9.009), train_loss = 1.31612097, grad/param norm = 1.7313e-01, time/batch = 0.9844s	
5992/33250 (epoch 9.011), train_loss = 1.07051185, grad/param norm = 1.4335e-01, time/batch = 0.9756s	
5993/33250 (epoch 9.012), train_loss = 1.24401991, grad/param norm = 1.8608e-01, time/batch = 1.2986s	
5994/33250 (epoch 9.014), train_loss = 1.31859507, grad/param norm = 1.8076e-01, time/batch = 1.8141s	
5995/33250 (epoch 9.015), train_loss = 1.17849616, grad/param norm = 1.5387e-01, time/batch = 1.8198s	
5996/33250 (epoch 9.017), train_loss = 1.22490684, grad/param norm = 1.6808e-01, time/batch = 10.5114s	
5997/33250 (epoch 9.018), train_loss = 0.97587582, grad/param norm = 1.4708e-01, time/batch = 15.2820s	
5998/33250 (epoch 9.020), train_loss = 1.10762942, grad/param norm = 1.4707e-01, time/batch = 15.5909s	
5999/33250 (epoch 9.021), train_loss = 1.14522770, grad/param norm = 1.5089e-01, time/batch = 17.9255s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch9.02_1.3929.t7	
6000/33250 (epoch 9.023), train_loss = 0.98400002, grad/param norm = 1.4968e-01, time/batch = 17.4549s	
6001/33250 (epoch 9.024), train_loss = 1.52769335, grad/param norm = 2.0498e-01, time/batch = 0.9945s	
6002/33250 (epoch 9.026), train_loss = 1.16905867, grad/param norm = 1.9495e-01, time/batch = 0.9759s	
6003/33250 (epoch 9.027), train_loss = 1.14727826, grad/param norm = 1.4485e-01, time/batch = 0.9704s	
6004/33250 (epoch 9.029), train_loss = 1.17576054, grad/param norm = 1.5562e-01, time/batch = 1.3011s	
6005/33250 (epoch 9.030), train_loss = 1.15746790, grad/param norm = 1.5781e-01, time/batch = 1.8001s	
6006/33250 (epoch 9.032), train_loss = 1.41635848, grad/param norm = 1.8631e-01, time/batch = 1.8425s	
6007/33250 (epoch 9.033), train_loss = 1.12088456, grad/param norm = 1.7062e-01, time/batch = 10.5466s	
6008/33250 (epoch 9.035), train_loss = 1.11882681, grad/param norm = 1.6558e-01, time/batch = 16.7795s	
6009/33250 (epoch 9.036), train_loss = 1.25273769, grad/param norm = 1.7681e-01, time/batch = 17.0113s	
6010/33250 (epoch 9.038), train_loss = 1.12493391, grad/param norm = 1.5150e-01, time/batch = 17.0152s	
6011/33250 (epoch 9.039), train_loss = 1.03067981, grad/param norm = 1.3521e-01, time/batch = 17.3416s	
6012/33250 (epoch 9.041), train_loss = 1.22865786, grad/param norm = 1.7149e-01, time/batch = 16.8479s	
6013/33250 (epoch 9.042), train_loss = 0.99908240, grad/param norm = 1.4373e-01, time/batch = 15.5101s	
6014/33250 (epoch 9.044), train_loss = 1.32342060, grad/param norm = 1.7225e-01, time/batch = 19.1797s	
6015/33250 (epoch 9.045), train_loss = 1.28394910, grad/param norm = 1.5681e-01, time/batch = 19.2795s	
6016/33250 (epoch 9.047), train_loss = 1.27173379, grad/param norm = 1.6516e-01, time/batch = 16.7836s	
6017/33250 (epoch 9.048), train_loss = 1.37886836, grad/param norm = 1.8279e-01, time/batch = 17.8482s	
6018/33250 (epoch 9.050), train_loss = 1.14573670, grad/param norm = 1.5076e-01, time/batch = 17.7230s	
6019/33250 (epoch 9.051), train_loss = 1.16125110, grad/param norm = 1.4767e-01, time/batch = 17.4320s	
6020/33250 (epoch 9.053), train_loss = 1.22433752, grad/param norm = 1.6893e-01, time/batch = 15.5267s	
6021/33250 (epoch 9.054), train_loss = 0.99991359, grad/param norm = 1.3307e-01, time/batch = 18.3299s	
6022/33250 (epoch 9.056), train_loss = 1.03586022, grad/param norm = 1.5418e-01, time/batch = 16.7637s	
6023/33250 (epoch 9.057), train_loss = 1.18945912, grad/param norm = 1.4365e-01, time/batch = 16.5886s	
6024/33250 (epoch 9.059), train_loss = 1.11498551, grad/param norm = 1.4229e-01, time/batch = 16.9280s	
6025/33250 (epoch 9.060), train_loss = 1.24673456, grad/param norm = 1.7557e-01, time/batch = 16.9468s	
6026/33250 (epoch 9.062), train_loss = 1.32802486, grad/param norm = 1.5544e-01, time/batch = 18.2728s	
6027/33250 (epoch 9.063), train_loss = 1.30012308, grad/param norm = 1.5179e-01, time/batch = 15.8662s	
6028/33250 (epoch 9.065), train_loss = 1.14503917, grad/param norm = 1.4985e-01, time/batch = 17.5337s	
6029/33250 (epoch 9.066), train_loss = 1.22979906, grad/param norm = 1.5219e-01, time/batch = 16.5997s	
6030/33250 (epoch 9.068), train_loss = 1.15035973, grad/param norm = 1.5516e-01, time/batch = 14.8399s	
6031/33250 (epoch 9.069), train_loss = 1.18297983, grad/param norm = 1.5173e-01, time/batch = 14.8538s	
6032/33250 (epoch 9.071), train_loss = 1.03710984, grad/param norm = 1.5063e-01, time/batch = 16.2573s	
6033/33250 (epoch 9.072), train_loss = 1.06063409, grad/param norm = 1.3977e-01, time/batch = 16.8437s	
6034/33250 (epoch 9.074), train_loss = 1.21504904, grad/param norm = 1.5220e-01, time/batch = 15.9322s	
6035/33250 (epoch 9.075), train_loss = 1.05660552, grad/param norm = 1.4280e-01, time/batch = 16.5352s	
6036/33250 (epoch 9.077), train_loss = 1.16836649, grad/param norm = 1.5776e-01, time/batch = 17.0382s	
6037/33250 (epoch 9.078), train_loss = 1.11303422, grad/param norm = 1.4520e-01, time/batch = 18.7676s	
6038/33250 (epoch 9.080), train_loss = 1.23499166, grad/param norm = 1.7732e-01, time/batch = 15.6848s	
6039/33250 (epoch 9.081), train_loss = 1.22112343, grad/param norm = 1.6828e-01, time/batch = 16.8335s	
6040/33250 (epoch 9.083), train_loss = 1.27340860, grad/param norm = 1.4996e-01, time/batch = 16.2854s	
6041/33250 (epoch 9.084), train_loss = 1.15275206, grad/param norm = 1.5147e-01, time/batch = 16.1005s	
6042/33250 (epoch 9.086), train_loss = 1.09612076, grad/param norm = 1.4197e-01, time/batch = 16.0936s	
6043/33250 (epoch 9.087), train_loss = 1.02133349, grad/param norm = 1.4455e-01, time/batch = 15.4432s	
6044/33250 (epoch 9.089), train_loss = 1.20573588, grad/param norm = 1.5507e-01, time/batch = 15.4027s	
6045/33250 (epoch 9.090), train_loss = 1.12158940, grad/param norm = 1.5884e-01, time/batch = 16.1844s	
6046/33250 (epoch 9.092), train_loss = 1.07421094, grad/param norm = 1.4469e-01, time/batch = 19.2634s	
6047/33250 (epoch 9.093), train_loss = 1.17813405, grad/param norm = 1.4941e-01, time/batch = 18.6893s	
6048/33250 (epoch 9.095), train_loss = 1.11596253, grad/param norm = 1.3894e-01, time/batch = 17.0386s	
6049/33250 (epoch 9.096), train_loss = 0.97111617, grad/param norm = 1.4115e-01, time/batch = 16.8568s	
6050/33250 (epoch 9.098), train_loss = 1.05678078, grad/param norm = 1.6742e-01, time/batch = 17.3617s	
6051/33250 (epoch 9.099), train_loss = 0.87031471, grad/param norm = 1.3870e-01, time/batch = 16.9309s	
6052/33250 (epoch 9.101), train_loss = 1.11424762, grad/param norm = 1.3890e-01, time/batch = 16.7717s	
6053/33250 (epoch 9.102), train_loss = 1.04417890, grad/param norm = 1.5219e-01, time/batch = 16.5025s	
6054/33250 (epoch 9.104), train_loss = 0.93296216, grad/param norm = 1.3772e-01, time/batch = 17.9315s	
6055/33250 (epoch 9.105), train_loss = 1.07278926, grad/param norm = 1.5265e-01, time/batch = 17.1111s	
6056/33250 (epoch 9.107), train_loss = 0.95851444, grad/param norm = 1.4567e-01, time/batch = 18.0600s	
6057/33250 (epoch 9.108), train_loss = 1.15216388, grad/param norm = 1.5195e-01, time/batch = 17.4464s	
6058/33250 (epoch 9.110), train_loss = 0.91077679, grad/param norm = 1.3098e-01, time/batch = 17.4545s	
6059/33250 (epoch 9.111), train_loss = 1.11393164, grad/param norm = 1.4733e-01, time/batch = 16.5761s	
6060/33250 (epoch 9.113), train_loss = 1.14001090, grad/param norm = 1.7029e-01, time/batch = 16.4243s	
6061/33250 (epoch 9.114), train_loss = 1.05032372, grad/param norm = 1.5432e-01, time/batch = 17.1005s	
6062/33250 (epoch 9.116), train_loss = 1.17398773, grad/param norm = 1.5459e-01, time/batch = 16.4048s	
6063/33250 (epoch 9.117), train_loss = 1.14305713, grad/param norm = 1.5492e-01, time/batch = 15.9366s	
6064/33250 (epoch 9.119), train_loss = 1.08046522, grad/param norm = 1.4404e-01, time/batch = 17.6846s	
6065/33250 (epoch 9.120), train_loss = 0.88795575, grad/param norm = 1.4008e-01, time/batch = 17.0391s	
6066/33250 (epoch 9.122), train_loss = 1.27691606, grad/param norm = 1.5031e-01, time/batch = 18.3397s	
6067/33250 (epoch 9.123), train_loss = 1.19862150, grad/param norm = 1.4765e-01, time/batch = 18.1336s	
6068/33250 (epoch 9.125), train_loss = 0.95671344, grad/param norm = 1.4532e-01, time/batch = 18.6031s	
6069/33250 (epoch 9.126), train_loss = 1.13112732, grad/param norm = 1.5825e-01, time/batch = 15.9396s	
6070/33250 (epoch 9.128), train_loss = 1.05135032, grad/param norm = 1.3935e-01, time/batch = 16.3611s	
6071/33250 (epoch 9.129), train_loss = 1.12933246, grad/param norm = 1.4650e-01, time/batch = 18.6666s	
6072/33250 (epoch 9.131), train_loss = 1.13910752, grad/param norm = 1.6320e-01, time/batch = 16.3335s	
6073/33250 (epoch 9.132), train_loss = 1.13151866, grad/param norm = 1.6901e-01, time/batch = 16.4394s	
6074/33250 (epoch 9.134), train_loss = 1.15816857, grad/param norm = 1.5907e-01, time/batch = 16.0695s	
6075/33250 (epoch 9.135), train_loss = 1.19941444, grad/param norm = 1.4866e-01, time/batch = 18.8708s	
6076/33250 (epoch 9.137), train_loss = 1.03748256, grad/param norm = 1.5372e-01, time/batch = 24.5950s	
6077/33250 (epoch 9.138), train_loss = 1.08093074, grad/param norm = 1.3354e-01, time/batch = 21.5443s	
6078/33250 (epoch 9.140), train_loss = 0.92067867, grad/param norm = 1.4096e-01, time/batch = 17.6942s	
6079/33250 (epoch 9.141), train_loss = 1.44422155, grad/param norm = 1.8469e-01, time/batch = 15.8486s	
6080/33250 (epoch 9.143), train_loss = 0.89710864, grad/param norm = 1.4781e-01, time/batch = 15.7853s	
6081/33250 (epoch 9.144), train_loss = 1.08039140, grad/param norm = 1.5087e-01, time/batch = 15.7046s	
6082/33250 (epoch 9.146), train_loss = 1.05114899, grad/param norm = 1.4079e-01, time/batch = 16.6007s	
6083/33250 (epoch 9.147), train_loss = 1.04188632, grad/param norm = 1.5122e-01, time/batch = 15.1997s	
6084/33250 (epoch 9.149), train_loss = 1.10553085, grad/param norm = 1.5147e-01, time/batch = 19.8418s	
6085/33250 (epoch 9.150), train_loss = 1.01422797, grad/param norm = 1.6190e-01, time/batch = 19.1743s	
6086/33250 (epoch 9.152), train_loss = 0.98991611, grad/param norm = 1.4785e-01, time/batch = 16.1145s	
6087/33250 (epoch 9.153), train_loss = 1.33703768, grad/param norm = 1.7900e-01, time/batch = 18.8461s	
6088/33250 (epoch 9.155), train_loss = 1.17871968, grad/param norm = 1.8528e-01, time/batch = 15.9395s	
6089/33250 (epoch 9.156), train_loss = 1.32134362, grad/param norm = 1.6474e-01, time/batch = 17.1651s	
6090/33250 (epoch 9.158), train_loss = 1.40722871, grad/param norm = 1.8374e-01, time/batch = 17.2599s	
6091/33250 (epoch 9.159), train_loss = 1.16345729, grad/param norm = 1.5916e-01, time/batch = 18.0971s	
6092/33250 (epoch 9.161), train_loss = 1.21062254, grad/param norm = 1.6473e-01, time/batch = 17.2699s	
6093/33250 (epoch 9.162), train_loss = 1.05020296, grad/param norm = 1.5287e-01, time/batch = 16.1636s	
6094/33250 (epoch 9.164), train_loss = 1.17483039, grad/param norm = 1.5974e-01, time/batch = 16.8231s	
6095/33250 (epoch 9.165), train_loss = 1.25421150, grad/param norm = 1.7789e-01, time/batch = 17.4514s	
6096/33250 (epoch 9.167), train_loss = 1.25367774, grad/param norm = 1.6081e-01, time/batch = 16.5342s	
6097/33250 (epoch 9.168), train_loss = 0.97941554, grad/param norm = 1.3201e-01, time/batch = 19.4373s	
6098/33250 (epoch 9.170), train_loss = 1.08353076, grad/param norm = 1.4790e-01, time/batch = 17.5995s	
6099/33250 (epoch 9.171), train_loss = 1.09292194, grad/param norm = 1.4264e-01, time/batch = 18.0035s	
6100/33250 (epoch 9.173), train_loss = 1.09147874, grad/param norm = 1.5329e-01, time/batch = 16.6815s	
6101/33250 (epoch 9.174), train_loss = 1.13724189, grad/param norm = 1.5681e-01, time/batch = 18.5950s	
6102/33250 (epoch 9.176), train_loss = 1.17128007, grad/param norm = 1.5456e-01, time/batch = 17.0223s	
6103/33250 (epoch 9.177), train_loss = 1.04107162, grad/param norm = 1.3148e-01, time/batch = 17.2588s	
6104/33250 (epoch 9.179), train_loss = 1.06217420, grad/param norm = 1.5697e-01, time/batch = 19.5365s	
6105/33250 (epoch 9.180), train_loss = 0.99161962, grad/param norm = 1.4499e-01, time/batch = 16.2870s	
6106/33250 (epoch 9.182), train_loss = 1.08989048, grad/param norm = 1.6876e-01, time/batch = 17.4294s	
6107/33250 (epoch 9.183), train_loss = 1.29130753, grad/param norm = 1.5928e-01, time/batch = 16.7628s	
6108/33250 (epoch 9.185), train_loss = 1.24405879, grad/param norm = 1.8076e-01, time/batch = 18.3499s	
6109/33250 (epoch 9.186), train_loss = 1.15788007, grad/param norm = 1.4893e-01, time/batch = 16.8488s	
6110/33250 (epoch 9.188), train_loss = 1.25689552, grad/param norm = 1.7458e-01, time/batch = 15.6590s	
6111/33250 (epoch 9.189), train_loss = 0.97609910, grad/param norm = 1.6050e-01, time/batch = 16.7503s	
6112/33250 (epoch 9.191), train_loss = 1.06960603, grad/param norm = 1.5693e-01, time/batch = 16.2690s	
6113/33250 (epoch 9.192), train_loss = 1.03785000, grad/param norm = 1.3188e-01, time/batch = 18.5077s	
6114/33250 (epoch 9.194), train_loss = 1.06343790, grad/param norm = 1.6140e-01, time/batch = 16.9547s	
6115/33250 (epoch 9.195), train_loss = 1.28675077, grad/param norm = 1.4589e-01, time/batch = 19.8634s	
6116/33250 (epoch 9.197), train_loss = 1.10740934, grad/param norm = 1.5005e-01, time/batch = 16.3587s	
6117/33250 (epoch 9.198), train_loss = 1.24263698, grad/param norm = 1.5964e-01, time/batch = 16.1007s	
6118/33250 (epoch 9.200), train_loss = 1.14709694, grad/param norm = 1.5993e-01, time/batch = 17.0916s	
6119/33250 (epoch 9.202), train_loss = 1.05746439, grad/param norm = 1.5115e-01, time/batch = 17.1841s	
6120/33250 (epoch 9.203), train_loss = 1.10809294, grad/param norm = 1.5832e-01, time/batch = 16.4105s	
6121/33250 (epoch 9.205), train_loss = 1.17634763, grad/param norm = 1.5529e-01, time/batch = 14.7888s	
6122/33250 (epoch 9.206), train_loss = 1.18667605, grad/param norm = 1.5646e-01, time/batch = 16.2768s	
6123/33250 (epoch 9.208), train_loss = 1.32964965, grad/param norm = 1.8585e-01, time/batch = 17.8467s	
6124/33250 (epoch 9.209), train_loss = 1.06293123, grad/param norm = 1.5935e-01, time/batch = 16.4578s	
6125/33250 (epoch 9.211), train_loss = 1.25623476, grad/param norm = 1.5441e-01, time/batch = 17.1271s	
6126/33250 (epoch 9.212), train_loss = 1.39526031, grad/param norm = 1.6047e-01, time/batch = 18.5268s	
6127/33250 (epoch 9.214), train_loss = 1.11307239, grad/param norm = 1.3088e-01, time/batch = 15.9295s	
6128/33250 (epoch 9.215), train_loss = 1.45208367, grad/param norm = 1.9870e-01, time/batch = 17.0034s	
6129/33250 (epoch 9.217), train_loss = 1.31525063, grad/param norm = 1.7268e-01, time/batch = 16.2685s	
6130/33250 (epoch 9.218), train_loss = 1.23552733, grad/param norm = 1.4976e-01, time/batch = 17.2690s	
6131/33250 (epoch 9.220), train_loss = 1.26152592, grad/param norm = 1.7561e-01, time/batch = 16.2665s	
6132/33250 (epoch 9.221), train_loss = 1.38940491, grad/param norm = 1.8394e-01, time/batch = 16.2733s	
6133/33250 (epoch 9.223), train_loss = 1.12897498, grad/param norm = 1.4318e-01, time/batch = 19.4509s	
6134/33250 (epoch 9.224), train_loss = 1.28821294, grad/param norm = 1.8576e-01, time/batch = 17.6150s	
6135/33250 (epoch 9.226), train_loss = 1.32989270, grad/param norm = 1.5969e-01, time/batch = 18.3290s	
6136/33250 (epoch 9.227), train_loss = 1.18406025, grad/param norm = 1.6474e-01, time/batch = 16.4187s	
6137/33250 (epoch 9.229), train_loss = 1.17672318, grad/param norm = 1.4719e-01, time/batch = 18.3438s	
6138/33250 (epoch 9.230), train_loss = 1.10486341, grad/param norm = 1.5835e-01, time/batch = 16.3518s	
6139/33250 (epoch 9.232), train_loss = 1.07188260, grad/param norm = 1.4264e-01, time/batch = 17.3419s	
6140/33250 (epoch 9.233), train_loss = 1.07951996, grad/param norm = 1.4669e-01, time/batch = 17.7602s	
6141/33250 (epoch 9.235), train_loss = 1.27988853, grad/param norm = 1.5458e-01, time/batch = 17.3275s	
6142/33250 (epoch 9.236), train_loss = 1.07348870, grad/param norm = 1.5929e-01, time/batch = 17.2630s	
6143/33250 (epoch 9.238), train_loss = 1.23574181, grad/param norm = 1.6566e-01, time/batch = 18.2854s	
6144/33250 (epoch 9.239), train_loss = 1.34675971, grad/param norm = 1.8641e-01, time/batch = 18.1907s	
6145/33250 (epoch 9.241), train_loss = 1.24389585, grad/param norm = 1.6509e-01, time/batch = 16.1780s	
6146/33250 (epoch 9.242), train_loss = 1.25656990, grad/param norm = 1.6228e-01, time/batch = 17.0857s	
6147/33250 (epoch 9.244), train_loss = 1.27440782, grad/param norm = 1.7948e-01, time/batch = 17.0936s	
6148/33250 (epoch 9.245), train_loss = 1.15987107, grad/param norm = 1.5378e-01, time/batch = 15.7343s	
6149/33250 (epoch 9.247), train_loss = 1.18739128, grad/param norm = 1.4878e-01, time/batch = 15.8292s	
6150/33250 (epoch 9.248), train_loss = 1.44212188, grad/param norm = 1.9845e-01, time/batch = 17.6804s	
6151/33250 (epoch 9.250), train_loss = 1.23505832, grad/param norm = 1.4627e-01, time/batch = 18.1666s	
6152/33250 (epoch 9.251), train_loss = 1.16796734, grad/param norm = 1.5450e-01, time/batch = 17.2797s	
6153/33250 (epoch 9.253), train_loss = 1.05042459, grad/param norm = 1.3765e-01, time/batch = 19.2001s	
6154/33250 (epoch 9.254), train_loss = 1.11371112, grad/param norm = 1.6298e-01, time/batch = 17.2690s	
6155/33250 (epoch 9.256), train_loss = 1.24182652, grad/param norm = 1.5945e-01, time/batch = 16.1076s	
6156/33250 (epoch 9.257), train_loss = 1.31826932, grad/param norm = 1.5472e-01, time/batch = 16.5915s	
6157/33250 (epoch 9.259), train_loss = 1.33804226, grad/param norm = 1.5802e-01, time/batch = 17.5241s	
6158/33250 (epoch 9.260), train_loss = 1.06920597, grad/param norm = 1.4608e-01, time/batch = 17.0882s	
6159/33250 (epoch 9.262), train_loss = 1.23088067, grad/param norm = 1.5893e-01, time/batch = 16.1849s	
6160/33250 (epoch 9.263), train_loss = 1.10332240, grad/param norm = 1.4532e-01, time/batch = 18.0855s	
6161/33250 (epoch 9.265), train_loss = 1.27325641, grad/param norm = 1.5819e-01, time/batch = 17.6200s	
6162/33250 (epoch 9.266), train_loss = 1.17950941, grad/param norm = 1.6057e-01, time/batch = 18.1106s	
6163/33250 (epoch 9.268), train_loss = 1.07615026, grad/param norm = 1.3550e-01, time/batch = 18.6989s	
6164/33250 (epoch 9.269), train_loss = 0.94518197, grad/param norm = 1.4401e-01, time/batch = 15.9452s	
6165/33250 (epoch 9.271), train_loss = 1.13273975, grad/param norm = 1.4431e-01, time/batch = 16.9937s	
6166/33250 (epoch 9.272), train_loss = 0.97801440, grad/param norm = 1.2477e-01, time/batch = 16.0230s	
6167/33250 (epoch 9.274), train_loss = 0.88356066, grad/param norm = 1.3851e-01, time/batch = 17.7281s	
6168/33250 (epoch 9.275), train_loss = 1.04354054, grad/param norm = 1.3031e-01, time/batch = 15.6745s	
6169/33250 (epoch 9.277), train_loss = 0.93228026, grad/param norm = 1.3771e-01, time/batch = 17.0054s	
6170/33250 (epoch 9.278), train_loss = 1.05170532, grad/param norm = 1.3408e-01, time/batch = 17.5947s	
6171/33250 (epoch 9.280), train_loss = 0.99362237, grad/param norm = 1.2966e-01, time/batch = 19.2607s	
6172/33250 (epoch 9.281), train_loss = 1.17426440, grad/param norm = 1.5852e-01, time/batch = 18.5274s	
6173/33250 (epoch 9.283), train_loss = 1.23826643, grad/param norm = 1.5738e-01, time/batch = 16.5401s	
6174/33250 (epoch 9.284), train_loss = 1.07321247, grad/param norm = 1.4202e-01, time/batch = 19.1993s	
6175/33250 (epoch 9.286), train_loss = 1.23880635, grad/param norm = 1.7084e-01, time/batch = 18.2710s	
6176/33250 (epoch 9.287), train_loss = 1.00564845, grad/param norm = 1.3434e-01, time/batch = 16.6026s	
6177/33250 (epoch 9.289), train_loss = 0.99340345, grad/param norm = 1.3710e-01, time/batch = 16.8548s	
6178/33250 (epoch 9.290), train_loss = 1.15538603, grad/param norm = 1.4020e-01, time/batch = 17.0893s	
6179/33250 (epoch 9.292), train_loss = 1.19728377, grad/param norm = 1.6680e-01, time/batch = 16.7502s	
6180/33250 (epoch 9.293), train_loss = 1.30225730, grad/param norm = 1.7864e-01, time/batch = 16.7710s	
6181/33250 (epoch 9.295), train_loss = 1.21536876, grad/param norm = 1.5953e-01, time/batch = 15.4384s	
6182/33250 (epoch 9.296), train_loss = 1.16740742, grad/param norm = 1.5580e-01, time/batch = 16.8008s	
6183/33250 (epoch 9.298), train_loss = 0.93627129, grad/param norm = 1.2661e-01, time/batch = 15.1875s	
6184/33250 (epoch 9.299), train_loss = 0.91126107, grad/param norm = 1.4455e-01, time/batch = 18.8665s	
6185/33250 (epoch 9.301), train_loss = 1.22813984, grad/param norm = 1.5022e-01, time/batch = 16.5231s	
6186/33250 (epoch 9.302), train_loss = 1.14601134, grad/param norm = 1.4970e-01, time/batch = 16.1858s	
6187/33250 (epoch 9.304), train_loss = 1.08870387, grad/param norm = 1.3407e-01, time/batch = 16.7591s	
6188/33250 (epoch 9.305), train_loss = 1.15050151, grad/param norm = 1.4887e-01, time/batch = 17.6040s	
6189/33250 (epoch 9.307), train_loss = 1.21983930, grad/param norm = 1.4607e-01, time/batch = 16.6064s	
6190/33250 (epoch 9.308), train_loss = 1.39646658, grad/param norm = 1.7445e-01, time/batch = 16.6822s	
6191/33250 (epoch 9.310), train_loss = 1.15539088, grad/param norm = 1.6037e-01, time/batch = 17.6182s	
6192/33250 (epoch 9.311), train_loss = 1.29211043, grad/param norm = 1.6671e-01, time/batch = 17.6273s	
6193/33250 (epoch 9.313), train_loss = 0.97475080, grad/param norm = 1.4854e-01, time/batch = 17.2914s	
6194/33250 (epoch 9.314), train_loss = 1.12359538, grad/param norm = 1.5889e-01, time/batch = 17.1197s	
6195/33250 (epoch 9.316), train_loss = 1.34950644, grad/param norm = 1.7399e-01, time/batch = 16.5302s	
6196/33250 (epoch 9.317), train_loss = 1.02808863, grad/param norm = 1.3618e-01, time/batch = 16.9287s	
6197/33250 (epoch 9.319), train_loss = 1.27970972, grad/param norm = 1.9063e-01, time/batch = 15.7535s	
6198/33250 (epoch 9.320), train_loss = 1.35367758, grad/param norm = 1.9794e-01, time/batch = 15.1889s	
6199/33250 (epoch 9.322), train_loss = 1.36421710, grad/param norm = 1.8240e-01, time/batch = 15.5781s	
6200/33250 (epoch 9.323), train_loss = 1.40829340, grad/param norm = 1.8591e-01, time/batch = 17.5064s	
6201/33250 (epoch 9.325), train_loss = 1.18015067, grad/param norm = 1.6490e-01, time/batch = 16.4480s	
6202/33250 (epoch 9.326), train_loss = 1.39575554, grad/param norm = 1.7212e-01, time/batch = 19.1103s	
6203/33250 (epoch 9.328), train_loss = 1.09347233, grad/param norm = 1.6738e-01, time/batch = 17.8742s	
6204/33250 (epoch 9.329), train_loss = 1.21093525, grad/param norm = 1.6826e-01, time/batch = 16.6112s	
6205/33250 (epoch 9.331), train_loss = 1.13324453, grad/param norm = 1.6555e-01, time/batch = 15.9432s	
6206/33250 (epoch 9.332), train_loss = 1.11959673, grad/param norm = 1.5631e-01, time/batch = 16.0215s	
6207/33250 (epoch 9.334), train_loss = 1.27787292, grad/param norm = 1.5398e-01, time/batch = 18.0037s	
6208/33250 (epoch 9.335), train_loss = 0.85928092, grad/param norm = 1.3905e-01, time/batch = 15.6142s	
6209/33250 (epoch 9.337), train_loss = 1.15623930, grad/param norm = 1.4538e-01, time/batch = 17.6811s	
6210/33250 (epoch 9.338), train_loss = 1.26617985, grad/param norm = 1.6072e-01, time/batch = 17.9328s	
6211/33250 (epoch 9.340), train_loss = 1.16305852, grad/param norm = 1.5417e-01, time/batch = 17.2839s	
6212/33250 (epoch 9.341), train_loss = 1.09259246, grad/param norm = 1.6201e-01, time/batch = 17.7034s	
6213/33250 (epoch 9.343), train_loss = 1.16865342, grad/param norm = 1.6051e-01, time/batch = 17.9621s	
6214/33250 (epoch 9.344), train_loss = 1.13796182, grad/param norm = 1.5943e-01, time/batch = 17.6816s	
6215/33250 (epoch 9.346), train_loss = 0.99783995, grad/param norm = 1.3485e-01, time/batch = 15.5076s	
6216/33250 (epoch 9.347), train_loss = 1.48036774, grad/param norm = 1.7177e-01, time/batch = 16.7568s	
6217/33250 (epoch 9.349), train_loss = 1.14291185, grad/param norm = 1.6034e-01, time/batch = 16.2239s	
6218/33250 (epoch 9.350), train_loss = 1.17839632, grad/param norm = 1.5952e-01, time/batch = 16.5067s	
6219/33250 (epoch 9.352), train_loss = 1.06031304, grad/param norm = 1.5915e-01, time/batch = 16.6047s	
6220/33250 (epoch 9.353), train_loss = 1.13024579, grad/param norm = 1.4373e-01, time/batch = 18.5295s	
6221/33250 (epoch 9.355), train_loss = 1.12812000, grad/param norm = 1.5542e-01, time/batch = 17.3586s	
6222/33250 (epoch 9.356), train_loss = 1.06320154, grad/param norm = 1.5255e-01, time/batch = 16.2684s	
6223/33250 (epoch 9.358), train_loss = 1.09129114, grad/param norm = 1.4863e-01, time/batch = 19.2725s	
6224/33250 (epoch 9.359), train_loss = 1.08722006, grad/param norm = 1.4288e-01, time/batch = 18.0904s	
6225/33250 (epoch 9.361), train_loss = 1.32307109, grad/param norm = 1.6638e-01, time/batch = 16.1020s	
6226/33250 (epoch 9.362), train_loss = 1.13976947, grad/param norm = 1.4662e-01, time/batch = 16.3570s	
6227/33250 (epoch 9.364), train_loss = 1.25510353, grad/param norm = 1.6521e-01, time/batch = 16.9488s	
6228/33250 (epoch 9.365), train_loss = 1.12723130, grad/param norm = 1.4777e-01, time/batch = 16.6870s	
6229/33250 (epoch 9.367), train_loss = 1.10208549, grad/param norm = 1.4152e-01, time/batch = 15.5198s	
6230/33250 (epoch 9.368), train_loss = 1.13870830, grad/param norm = 1.5703e-01, time/batch = 19.2749s	
6231/33250 (epoch 9.370), train_loss = 0.98700827, grad/param norm = 1.3555e-01, time/batch = 16.6345s	
6232/33250 (epoch 9.371), train_loss = 1.28544324, grad/param norm = 1.6870e-01, time/batch = 16.6114s	
6233/33250 (epoch 9.373), train_loss = 1.08209149, grad/param norm = 1.4778e-01, time/batch = 17.7787s	
6234/33250 (epoch 9.374), train_loss = 1.24100040, grad/param norm = 1.7571e-01, time/batch = 15.0758s	
6235/33250 (epoch 9.376), train_loss = 1.12402691, grad/param norm = 1.5839e-01, time/batch = 17.4403s	
6236/33250 (epoch 9.377), train_loss = 1.03297504, grad/param norm = 1.8606e-01, time/batch = 16.4454s	
6237/33250 (epoch 9.379), train_loss = 1.07473780, grad/param norm = 1.6759e-01, time/batch = 16.1150s	
6238/33250 (epoch 9.380), train_loss = 1.21282869, grad/param norm = 1.8918e-01, time/batch = 18.6768s	
6239/33250 (epoch 9.382), train_loss = 1.26239077, grad/param norm = 1.7034e-01, time/batch = 15.6026s	
6240/33250 (epoch 9.383), train_loss = 1.04000651, grad/param norm = 1.5064e-01, time/batch = 19.0305s	
6241/33250 (epoch 9.385), train_loss = 1.00116667, grad/param norm = 1.5343e-01, time/batch = 18.2910s	
6242/33250 (epoch 9.386), train_loss = 1.00577347, grad/param norm = 1.5158e-01, time/batch = 17.5443s	
6243/33250 (epoch 9.388), train_loss = 1.05859815, grad/param norm = 1.5188e-01, time/batch = 16.0432s	
6244/33250 (epoch 9.389), train_loss = 1.11965557, grad/param norm = 1.6169e-01, time/batch = 15.6842s	
6245/33250 (epoch 9.391), train_loss = 1.15783179, grad/param norm = 1.6646e-01, time/batch = 15.9958s	
6246/33250 (epoch 9.392), train_loss = 1.26138596, grad/param norm = 1.7251e-01, time/batch = 15.6099s	
6247/33250 (epoch 9.394), train_loss = 1.34783313, grad/param norm = 1.8346e-01, time/batch = 16.3609s	
6248/33250 (epoch 9.395), train_loss = 1.24087321, grad/param norm = 1.4574e-01, time/batch = 15.5355s	
6249/33250 (epoch 9.397), train_loss = 1.27904845, grad/param norm = 1.6434e-01, time/batch = 16.5103s	
6250/33250 (epoch 9.398), train_loss = 1.06294889, grad/param norm = 1.4537e-01, time/batch = 15.8439s	
6251/33250 (epoch 9.400), train_loss = 1.06905398, grad/param norm = 1.5195e-01, time/batch = 19.7676s	
6252/33250 (epoch 9.402), train_loss = 0.97843091, grad/param norm = 1.4830e-01, time/batch = 16.6972s	
6253/33250 (epoch 9.403), train_loss = 1.08664179, grad/param norm = 1.6721e-01, time/batch = 17.6085s	
6254/33250 (epoch 9.405), train_loss = 1.04699154, grad/param norm = 1.5715e-01, time/batch = 16.5013s	
6255/33250 (epoch 9.406), train_loss = 1.20874751, grad/param norm = 1.6545e-01, time/batch = 16.3477s	
6256/33250 (epoch 9.408), train_loss = 1.28936950, grad/param norm = 1.6636e-01, time/batch = 16.1062s	
6257/33250 (epoch 9.409), train_loss = 1.24872369, grad/param norm = 2.5536e-01, time/batch = 15.4118s	
6258/33250 (epoch 9.411), train_loss = 0.86385040, grad/param norm = 1.2790e-01, time/batch = 18.0961s	
6259/33250 (epoch 9.412), train_loss = 0.98483130, grad/param norm = 1.4676e-01, time/batch = 16.7787s	
6260/33250 (epoch 9.414), train_loss = 1.16980455, grad/param norm = 1.5499e-01, time/batch = 18.1068s	
6261/33250 (epoch 9.415), train_loss = 1.28466927, grad/param norm = 1.7309e-01, time/batch = 15.8817s	
6262/33250 (epoch 9.417), train_loss = 1.23789491, grad/param norm = 1.6112e-01, time/batch = 18.0362s	
6263/33250 (epoch 9.418), train_loss = 1.41519802, grad/param norm = 1.9287e-01, time/batch = 18.2972s	
6264/33250 (epoch 9.420), train_loss = 1.27887954, grad/param norm = 1.5786e-01, time/batch = 15.6092s	
6265/33250 (epoch 9.421), train_loss = 1.02925303, grad/param norm = 1.5406e-01, time/batch = 17.2721s	
6266/33250 (epoch 9.423), train_loss = 1.22644129, grad/param norm = 1.7954e-01, time/batch = 14.6747s	
6267/33250 (epoch 9.424), train_loss = 1.40791116, grad/param norm = 2.0075e-01, time/batch = 15.1234s	
6268/33250 (epoch 9.426), train_loss = 1.05233759, grad/param norm = 1.4416e-01, time/batch = 15.5392s	
6269/33250 (epoch 9.427), train_loss = 1.07282319, grad/param norm = 1.6263e-01, time/batch = 16.6602s	
6270/33250 (epoch 9.429), train_loss = 1.22449666, grad/param norm = 1.7164e-01, time/batch = 16.2660s	
6271/33250 (epoch 9.430), train_loss = 1.06023788, grad/param norm = 1.6875e-01, time/batch = 18.0127s	
6272/33250 (epoch 9.432), train_loss = 1.14044370, grad/param norm = 1.4610e-01, time/batch = 17.0259s	
6273/33250 (epoch 9.433), train_loss = 1.08470364, grad/param norm = 1.5585e-01, time/batch = 18.4524s	
6274/33250 (epoch 9.435), train_loss = 1.17151375, grad/param norm = 1.6608e-01, time/batch = 20.1569s	
6275/33250 (epoch 9.436), train_loss = 1.06725076, grad/param norm = 1.6242e-01, time/batch = 16.8490s	
6276/33250 (epoch 9.438), train_loss = 1.20425688, grad/param norm = 1.6154e-01, time/batch = 16.8213s	
6277/33250 (epoch 9.439), train_loss = 1.15483041, grad/param norm = 1.5480e-01, time/batch = 16.4196s	
6278/33250 (epoch 9.441), train_loss = 1.11881516, grad/param norm = 1.4377e-01, time/batch = 17.1747s	
6279/33250 (epoch 9.442), train_loss = 1.05958744, grad/param norm = 1.5830e-01, time/batch = 16.9380s	
6280/33250 (epoch 9.444), train_loss = 1.06448771, grad/param norm = 1.6047e-01, time/batch = 17.2732s	
6281/33250 (epoch 9.445), train_loss = 1.14292684, grad/param norm = 1.4477e-01, time/batch = 19.4385s	
6282/33250 (epoch 9.447), train_loss = 1.19419706, grad/param norm = 1.5567e-01, time/batch = 16.2600s	
6283/33250 (epoch 9.448), train_loss = 1.07271869, grad/param norm = 1.2902e-01, time/batch = 19.7004s	
6284/33250 (epoch 9.450), train_loss = 1.32669019, grad/param norm = 1.7415e-01, time/batch = 17.6071s	
6285/33250 (epoch 9.451), train_loss = 1.21690975, grad/param norm = 1.6756e-01, time/batch = 30.8955s	
6286/33250 (epoch 9.453), train_loss = 1.00643735, grad/param norm = 1.4466e-01, time/batch = 16.4236s	
6287/33250 (epoch 9.454), train_loss = 1.29623563, grad/param norm = 1.6709e-01, time/batch = 16.3335s	
6288/33250 (epoch 9.456), train_loss = 1.30869053, grad/param norm = 1.7444e-01, time/batch = 17.5871s	
6289/33250 (epoch 9.457), train_loss = 1.11285139, grad/param norm = 1.6097e-01, time/batch = 17.4153s	
6290/33250 (epoch 9.459), train_loss = 1.15167693, grad/param norm = 1.4340e-01, time/batch = 18.1121s	
6291/33250 (epoch 9.460), train_loss = 1.24927789, grad/param norm = 1.7442e-01, time/batch = 17.0260s	
6292/33250 (epoch 9.462), train_loss = 1.05354393, grad/param norm = 1.4374e-01, time/batch = 19.4525s	
6293/33250 (epoch 9.463), train_loss = 1.04078255, grad/param norm = 1.3349e-01, time/batch = 19.1796s	
6294/33250 (epoch 9.465), train_loss = 0.91786534, grad/param norm = 1.1448e-01, time/batch = 16.5064s	
6295/33250 (epoch 9.466), train_loss = 0.90794317, grad/param norm = 1.2313e-01, time/batch = 17.8431s	
6296/33250 (epoch 9.468), train_loss = 1.01312644, grad/param norm = 1.2889e-01, time/batch = 18.6765s	
6297/33250 (epoch 9.469), train_loss = 1.16128436, grad/param norm = 1.7264e-01, time/batch = 16.0084s	
6298/33250 (epoch 9.471), train_loss = 1.24408659, grad/param norm = 1.4548e-01, time/batch = 16.9975s	
6299/33250 (epoch 9.472), train_loss = 1.16650432, grad/param norm = 1.9416e-01, time/batch = 17.5906s	
6300/33250 (epoch 9.474), train_loss = 1.36984570, grad/param norm = 1.9708e-01, time/batch = 18.2797s	
6301/33250 (epoch 9.475), train_loss = 1.15069807, grad/param norm = 1.5051e-01, time/batch = 17.5963s	
6302/33250 (epoch 9.477), train_loss = 1.12636206, grad/param norm = 1.5283e-01, time/batch = 16.7777s	
6303/33250 (epoch 9.478), train_loss = 1.09898390, grad/param norm = 1.3891e-01, time/batch = 15.3652s	
6304/33250 (epoch 9.480), train_loss = 1.37390185, grad/param norm = 1.6997e-01, time/batch = 18.2588s	
6305/33250 (epoch 9.481), train_loss = 1.12714498, grad/param norm = 1.5962e-01, time/batch = 16.6049s	
6306/33250 (epoch 9.483), train_loss = 1.19059831, grad/param norm = 1.4165e-01, time/batch = 16.5966s	
6307/33250 (epoch 9.484), train_loss = 1.05395752, grad/param norm = 1.4471e-01, time/batch = 18.5088s	
6308/33250 (epoch 9.486), train_loss = 0.95917219, grad/param norm = 1.5202e-01, time/batch = 15.0248s	
6309/33250 (epoch 9.487), train_loss = 1.07993744, grad/param norm = 1.5614e-01, time/batch = 15.4264s	
6310/33250 (epoch 9.489), train_loss = 1.28504132, grad/param norm = 2.0101e-01, time/batch = 16.5786s	
6311/33250 (epoch 9.490), train_loss = 1.22801908, grad/param norm = 1.6894e-01, time/batch = 19.4337s	
6312/33250 (epoch 9.492), train_loss = 1.19315488, grad/param norm = 1.5910e-01, time/batch = 18.9395s	
6313/33250 (epoch 9.493), train_loss = 1.15834326, grad/param norm = 1.7996e-01, time/batch = 18.3733s	
6314/33250 (epoch 9.495), train_loss = 1.18471072, grad/param norm = 1.5016e-01, time/batch = 17.1901s	
6315/33250 (epoch 9.496), train_loss = 1.10055163, grad/param norm = 1.4081e-01, time/batch = 16.1754s	
6316/33250 (epoch 9.498), train_loss = 1.25096448, grad/param norm = 1.6424e-01, time/batch = 18.5061s	
6317/33250 (epoch 9.499), train_loss = 1.12545637, grad/param norm = 1.4798e-01, time/batch = 17.6835s	
6318/33250 (epoch 9.501), train_loss = 1.11045513, grad/param norm = 1.6928e-01, time/batch = 17.2573s	
6319/33250 (epoch 9.502), train_loss = 1.11783130, grad/param norm = 1.4486e-01, time/batch = 16.1094s	
6320/33250 (epoch 9.504), train_loss = 1.28977816, grad/param norm = 1.7949e-01, time/batch = 16.1085s	
6321/33250 (epoch 9.505), train_loss = 0.93097678, grad/param norm = 1.2741e-01, time/batch = 18.2763s	
6322/33250 (epoch 9.507), train_loss = 1.10744568, grad/param norm = 1.4779e-01, time/batch = 17.5289s	
6323/33250 (epoch 9.508), train_loss = 1.07658076, grad/param norm = 1.4160e-01, time/batch = 18.4585s	
6324/33250 (epoch 9.510), train_loss = 0.95811628, grad/param norm = 1.3819e-01, time/batch = 16.3605s	
6325/33250 (epoch 9.511), train_loss = 1.14302381, grad/param norm = 1.5187e-01, time/batch = 15.5945s	
6326/33250 (epoch 9.513), train_loss = 1.34197268, grad/param norm = 1.6177e-01, time/batch = 15.3578s	
6327/33250 (epoch 9.514), train_loss = 1.08968587, grad/param norm = 2.1132e-01, time/batch = 19.1680s	
6328/33250 (epoch 9.516), train_loss = 1.06213381, grad/param norm = 1.4810e-01, time/batch = 17.6039s	
6329/33250 (epoch 9.517), train_loss = 1.15010927, grad/param norm = 1.5287e-01, time/batch = 17.2586s	
6330/33250 (epoch 9.519), train_loss = 1.00924696, grad/param norm = 1.3348e-01, time/batch = 17.5228s	
6331/33250 (epoch 9.520), train_loss = 1.44802801, grad/param norm = 1.7965e-01, time/batch = 17.1063s	
6332/33250 (epoch 9.522), train_loss = 1.23913270, grad/param norm = 1.6596e-01, time/batch = 16.6655s	
6333/33250 (epoch 9.523), train_loss = 1.12299975, grad/param norm = 1.5690e-01, time/batch = 18.0337s	
6334/33250 (epoch 9.525), train_loss = 1.00589491, grad/param norm = 1.5254e-01, time/batch = 15.8402s	
6335/33250 (epoch 9.526), train_loss = 1.00954212, grad/param norm = 1.4326e-01, time/batch = 18.1671s	
6336/33250 (epoch 9.528), train_loss = 1.11250265, grad/param norm = 1.4969e-01, time/batch = 16.0765s	
6337/33250 (epoch 9.529), train_loss = 1.07623961, grad/param norm = 1.5171e-01, time/batch = 17.8507s	
6338/33250 (epoch 9.531), train_loss = 0.99551421, grad/param norm = 1.4182e-01, time/batch = 16.0920s	
6339/33250 (epoch 9.532), train_loss = 1.23233783, grad/param norm = 1.6454e-01, time/batch = 16.3308s	
6340/33250 (epoch 9.534), train_loss = 1.04236043, grad/param norm = 1.4190e-01, time/batch = 17.1029s	
6341/33250 (epoch 9.535), train_loss = 1.13280186, grad/param norm = 1.4965e-01, time/batch = 18.7016s	
6342/33250 (epoch 9.537), train_loss = 1.22845023, grad/param norm = 1.4803e-01, time/batch = 15.8855s	
6343/33250 (epoch 9.538), train_loss = 1.23744035, grad/param norm = 1.5713e-01, time/batch = 15.5945s	
6344/33250 (epoch 9.540), train_loss = 1.29389459, grad/param norm = 1.4920e-01, time/batch = 14.8828s	
6345/33250 (epoch 9.541), train_loss = 1.27342903, grad/param norm = 1.6021e-01, time/batch = 17.5838s	
6346/33250 (epoch 9.543), train_loss = 1.24377433, grad/param norm = 1.5277e-01, time/batch = 16.5094s	
6347/33250 (epoch 9.544), train_loss = 1.09790314, grad/param norm = 1.4823e-01, time/batch = 15.1928s	
6348/33250 (epoch 9.546), train_loss = 1.15788592, grad/param norm = 1.9557e-01, time/batch = 15.6139s	
6349/33250 (epoch 9.547), train_loss = 1.07293826, grad/param norm = 1.5419e-01, time/batch = 16.7728s	
6350/33250 (epoch 9.549), train_loss = 1.21510906, grad/param norm = 1.6088e-01, time/batch = 17.3409s	
6351/33250 (epoch 9.550), train_loss = 1.10921441, grad/param norm = 1.5304e-01, time/batch = 17.3739s	
6352/33250 (epoch 9.552), train_loss = 1.18635766, grad/param norm = 1.5476e-01, time/batch = 17.3598s	
6353/33250 (epoch 9.553), train_loss = 1.09647384, grad/param norm = 1.5487e-01, time/batch = 18.6982s	
6354/33250 (epoch 9.555), train_loss = 1.13276030, grad/param norm = 1.4028e-01, time/batch = 17.1789s	
6355/33250 (epoch 9.556), train_loss = 1.30276510, grad/param norm = 1.8076e-01, time/batch = 16.5317s	
6356/33250 (epoch 9.558), train_loss = 1.25282764, grad/param norm = 1.5618e-01, time/batch = 16.3532s	
6357/33250 (epoch 9.559), train_loss = 1.03034382, grad/param norm = 1.4631e-01, time/batch = 16.4137s	
6358/33250 (epoch 9.561), train_loss = 1.10002932, grad/param norm = 1.5621e-01, time/batch = 15.9958s	
6359/33250 (epoch 9.562), train_loss = 1.32223259, grad/param norm = 1.7450e-01, time/batch = 16.8585s	
6360/33250 (epoch 9.564), train_loss = 1.39375849, grad/param norm = 1.7969e-01, time/batch = 18.5142s	
6361/33250 (epoch 9.565), train_loss = 1.33140809, grad/param norm = 1.8079e-01, time/batch = 17.7706s	
6362/33250 (epoch 9.567), train_loss = 1.27890141, grad/param norm = 1.5429e-01, time/batch = 18.4493s	
6363/33250 (epoch 9.568), train_loss = 1.15166546, grad/param norm = 1.6113e-01, time/batch = 17.5161s	
6364/33250 (epoch 9.570), train_loss = 1.28107183, grad/param norm = 1.6942e-01, time/batch = 16.5182s	
6365/33250 (epoch 9.571), train_loss = 1.36833508, grad/param norm = 1.6366e-01, time/batch = 16.1998s	
6366/33250 (epoch 9.573), train_loss = 1.22028582, grad/param norm = 1.5912e-01, time/batch = 16.3525s	
6367/33250 (epoch 9.574), train_loss = 1.05193860, grad/param norm = 1.5337e-01, time/batch = 17.5965s	
6368/33250 (epoch 9.576), train_loss = 1.20155917, grad/param norm = 1.5102e-01, time/batch = 17.3267s	
6369/33250 (epoch 9.577), train_loss = 1.13638731, grad/param norm = 1.4605e-01, time/batch = 17.3588s	
6370/33250 (epoch 9.579), train_loss = 1.03189188, grad/param norm = 1.4358e-01, time/batch = 18.7048s	
6371/33250 (epoch 9.580), train_loss = 1.06897287, grad/param norm = 1.3848e-01, time/batch = 16.5207s	
6372/33250 (epoch 9.582), train_loss = 1.12124971, grad/param norm = 1.5139e-01, time/batch = 19.0136s	
6373/33250 (epoch 9.583), train_loss = 1.17453172, grad/param norm = 1.5121e-01, time/batch = 15.4958s	
6374/33250 (epoch 9.585), train_loss = 1.24715795, grad/param norm = 1.6485e-01, time/batch = 16.6793s	
6375/33250 (epoch 9.586), train_loss = 1.10526535, grad/param norm = 1.7845e-01, time/batch = 16.0421s	
6376/33250 (epoch 9.588), train_loss = 1.14928141, grad/param norm = 1.4812e-01, time/batch = 18.0091s	
6377/33250 (epoch 9.589), train_loss = 1.22940891, grad/param norm = 1.5893e-01, time/batch = 17.5941s	
6378/33250 (epoch 9.591), train_loss = 1.23292109, grad/param norm = 1.8167e-01, time/batch = 15.9270s	
6379/33250 (epoch 9.592), train_loss = 1.17624194, grad/param norm = 1.4902e-01, time/batch = 17.0321s	
6380/33250 (epoch 9.594), train_loss = 1.35367712, grad/param norm = 1.8055e-01, time/batch = 18.3789s	
6381/33250 (epoch 9.595), train_loss = 1.26578412, grad/param norm = 1.7307e-01, time/batch = 16.7550s	
6382/33250 (epoch 9.597), train_loss = 1.00450638, grad/param norm = 1.3701e-01, time/batch = 16.1976s	
6383/33250 (epoch 9.598), train_loss = 1.17684927, grad/param norm = 1.5930e-01, time/batch = 16.4391s	
6384/33250 (epoch 9.600), train_loss = 1.16652122, grad/param norm = 1.6836e-01, time/batch = 16.3476s	
6385/33250 (epoch 9.602), train_loss = 1.20734599, grad/param norm = 1.7205e-01, time/batch = 16.4219s	
6386/33250 (epoch 9.603), train_loss = 1.18817670, grad/param norm = 1.6082e-01, time/batch = 15.5890s	
6387/33250 (epoch 9.605), train_loss = 1.17259255, grad/param norm = 1.6299e-01, time/batch = 17.3442s	
6388/33250 (epoch 9.606), train_loss = 1.21494382, grad/param norm = 1.5158e-01, time/batch = 18.2670s	
6389/33250 (epoch 9.608), train_loss = 1.16712631, grad/param norm = 1.5345e-01, time/batch = 16.4401s	
6390/33250 (epoch 9.609), train_loss = 1.06036111, grad/param norm = 1.5322e-01, time/batch = 15.7022s	
6391/33250 (epoch 9.611), train_loss = 1.23925410, grad/param norm = 1.6562e-01, time/batch = 15.7135s	
6392/33250 (epoch 9.612), train_loss = 1.20566921, grad/param norm = 1.6232e-01, time/batch = 16.4401s	
6393/33250 (epoch 9.614), train_loss = 1.43856561, grad/param norm = 1.9089e-01, time/batch = 15.2636s	
6394/33250 (epoch 9.615), train_loss = 1.28278119, grad/param norm = 1.6015e-01, time/batch = 15.5916s	
6395/33250 (epoch 9.617), train_loss = 1.56917420, grad/param norm = 1.9527e-01, time/batch = 15.0368s	
6396/33250 (epoch 9.618), train_loss = 1.51321837, grad/param norm = 2.1125e-01, time/batch = 15.4371s	
6397/33250 (epoch 9.620), train_loss = 1.31026438, grad/param norm = 1.6873e-01, time/batch = 15.3541s	
6398/33250 (epoch 9.621), train_loss = 1.12108091, grad/param norm = 1.4272e-01, time/batch = 15.1779s	
6399/33250 (epoch 9.623), train_loss = 1.08495796, grad/param norm = 1.4819e-01, time/batch = 18.5229s	
6400/33250 (epoch 9.624), train_loss = 1.14937111, grad/param norm = 1.7155e-01, time/batch = 16.7915s	
6401/33250 (epoch 9.626), train_loss = 1.12682763, grad/param norm = 1.7269e-01, time/batch = 18.6263s	
6402/33250 (epoch 9.627), train_loss = 1.08501828, grad/param norm = 1.4843e-01, time/batch = 17.5035s	
6403/33250 (epoch 9.629), train_loss = 1.15691430, grad/param norm = 1.7351e-01, time/batch = 16.6667s	
6404/33250 (epoch 9.630), train_loss = 1.13107708, grad/param norm = 1.6014e-01, time/batch = 18.0858s	
6405/33250 (epoch 9.632), train_loss = 0.95216452, grad/param norm = 1.2810e-01, time/batch = 16.9273s	
6406/33250 (epoch 9.633), train_loss = 1.22935505, grad/param norm = 1.6120e-01, time/batch = 18.0804s	
6407/33250 (epoch 9.635), train_loss = 1.03725425, grad/param norm = 1.4430e-01, time/batch = 15.6824s	
6408/33250 (epoch 9.636), train_loss = 1.04407870, grad/param norm = 1.4113e-01, time/batch = 17.8591s	
6409/33250 (epoch 9.638), train_loss = 1.09826759, grad/param norm = 1.4485e-01, time/batch = 17.0234s	
6410/33250 (epoch 9.639), train_loss = 1.02218255, grad/param norm = 1.4636e-01, time/batch = 18.0335s	
6411/33250 (epoch 9.641), train_loss = 1.04400820, grad/param norm = 1.4910e-01, time/batch = 17.3461s	
6412/33250 (epoch 9.642), train_loss = 0.97937888, grad/param norm = 1.4840e-01, time/batch = 17.0801s	
6413/33250 (epoch 9.644), train_loss = 0.88812768, grad/param norm = 1.3283e-01, time/batch = 14.8767s	
6414/33250 (epoch 9.645), train_loss = 1.26774219, grad/param norm = 1.6743e-01, time/batch = 16.5001s	
6415/33250 (epoch 9.647), train_loss = 1.01879067, grad/param norm = 1.4695e-01, time/batch = 18.9110s	
6416/33250 (epoch 9.648), train_loss = 1.11124665, grad/param norm = 1.5378e-01, time/batch = 17.2575s	
6417/33250 (epoch 9.650), train_loss = 1.29188544, grad/param norm = 1.6771e-01, time/batch = 15.5313s	
6418/33250 (epoch 9.651), train_loss = 1.17253876, grad/param norm = 1.7956e-01, time/batch = 18.6886s	
6419/33250 (epoch 9.653), train_loss = 1.02629596, grad/param norm = 1.4628e-01, time/batch = 18.6975s	
6420/33250 (epoch 9.654), train_loss = 1.07325340, grad/param norm = 1.4414e-01, time/batch = 18.5327s	
6421/33250 (epoch 9.656), train_loss = 1.20587526, grad/param norm = 1.5814e-01, time/batch = 16.1034s	
6422/33250 (epoch 9.657), train_loss = 0.92496564, grad/param norm = 1.4935e-01, time/batch = 16.7704s	
6423/33250 (epoch 9.659), train_loss = 1.12887243, grad/param norm = 1.5435e-01, time/batch = 17.3198s	
6424/33250 (epoch 9.660), train_loss = 1.11314428, grad/param norm = 1.5980e-01, time/batch = 15.8487s	
6425/33250 (epoch 9.662), train_loss = 1.18186081, grad/param norm = 1.5120e-01, time/batch = 16.9185s	
6426/33250 (epoch 9.663), train_loss = 1.08080596, grad/param norm = 1.5203e-01, time/batch = 15.9101s	
6427/33250 (epoch 9.665), train_loss = 1.22563791, grad/param norm = 1.7046e-01, time/batch = 17.9335s	
6428/33250 (epoch 9.666), train_loss = 1.10439429, grad/param norm = 1.6010e-01, time/batch = 15.9275s	
6429/33250 (epoch 9.668), train_loss = 1.31927760, grad/param norm = 1.6642e-01, time/batch = 16.9766s	
6430/33250 (epoch 9.669), train_loss = 1.20776163, grad/param norm = 1.5799e-01, time/batch = 19.2917s	
6431/33250 (epoch 9.671), train_loss = 1.11773566, grad/param norm = 1.6777e-01, time/batch = 17.1815s	
6432/33250 (epoch 9.672), train_loss = 1.28767222, grad/param norm = 1.6698e-01, time/batch = 16.4430s	
6433/33250 (epoch 9.674), train_loss = 1.10420546, grad/param norm = 1.4403e-01, time/batch = 15.1802s	
6434/33250 (epoch 9.675), train_loss = 1.14442907, grad/param norm = 1.5054e-01, time/batch = 19.3323s	
6435/33250 (epoch 9.677), train_loss = 1.26596881, grad/param norm = 1.6310e-01, time/batch = 15.8334s	
6436/33250 (epoch 9.678), train_loss = 1.21364751, grad/param norm = 1.6888e-01, time/batch = 17.0166s	
6437/33250 (epoch 9.680), train_loss = 1.25930120, grad/param norm = 1.6123e-01, time/batch = 18.0237s	
6438/33250 (epoch 9.681), train_loss = 1.00502826, grad/param norm = 1.4319e-01, time/batch = 16.8740s	
6439/33250 (epoch 9.683), train_loss = 1.10314495, grad/param norm = 1.5717e-01, time/batch = 16.9645s	
6440/33250 (epoch 9.684), train_loss = 1.05622419, grad/param norm = 1.6378e-01, time/batch = 18.3749s	
6441/33250 (epoch 9.686), train_loss = 1.05178864, grad/param norm = 1.5319e-01, time/batch = 18.2487s	
6442/33250 (epoch 9.687), train_loss = 1.08955092, grad/param norm = 1.5409e-01, time/batch = 15.9237s	
6443/33250 (epoch 9.689), train_loss = 1.09605105, grad/param norm = 1.5153e-01, time/batch = 17.3285s	
6444/33250 (epoch 9.690), train_loss = 1.20476896, grad/param norm = 1.5984e-01, time/batch = 16.1874s	
6445/33250 (epoch 9.692), train_loss = 1.16889246, grad/param norm = 1.6960e-01, time/batch = 15.5852s	
6446/33250 (epoch 9.693), train_loss = 1.16465285, grad/param norm = 1.4331e-01, time/batch = 17.4328s	
6447/33250 (epoch 9.695), train_loss = 1.20419510, grad/param norm = 1.6303e-01, time/batch = 17.9352s	
6448/33250 (epoch 9.696), train_loss = 1.15138525, grad/param norm = 1.4645e-01, time/batch = 18.9292s	
6449/33250 (epoch 9.698), train_loss = 1.07054144, grad/param norm = 1.5337e-01, time/batch = 15.9721s	
6450/33250 (epoch 9.699), train_loss = 1.36060227, grad/param norm = 1.5739e-01, time/batch = 18.7776s	
6451/33250 (epoch 9.701), train_loss = 1.10185109, grad/param norm = 1.4302e-01, time/batch = 16.8660s	
6452/33250 (epoch 9.702), train_loss = 1.16799826, grad/param norm = 1.7705e-01, time/batch = 16.4300s	
6453/33250 (epoch 9.704), train_loss = 1.36050229, grad/param norm = 1.7394e-01, time/batch = 15.0249s	
6454/33250 (epoch 9.705), train_loss = 1.01351629, grad/param norm = 1.3974e-01, time/batch = 17.8428s	
6455/33250 (epoch 9.707), train_loss = 0.96471984, grad/param norm = 1.4035e-01, time/batch = 17.0354s	
6456/33250 (epoch 9.708), train_loss = 1.23322294, grad/param norm = 1.7466e-01, time/batch = 16.2761s	
6457/33250 (epoch 9.710), train_loss = 1.22829497, grad/param norm = 1.5652e-01, time/batch = 19.0217s	
6458/33250 (epoch 9.711), train_loss = 1.14059633, grad/param norm = 1.8235e-01, time/batch = 17.1274s	
6459/33250 (epoch 9.713), train_loss = 1.24439933, grad/param norm = 1.6476e-01, time/batch = 15.9567s	
6460/33250 (epoch 9.714), train_loss = 1.16263499, grad/param norm = 1.5406e-01, time/batch = 16.1953s	
6461/33250 (epoch 9.716), train_loss = 1.27635827, grad/param norm = 1.6784e-01, time/batch = 16.2543s	
6462/33250 (epoch 9.717), train_loss = 1.08327003, grad/param norm = 1.4335e-01, time/batch = 17.8465s	
6463/33250 (epoch 9.719), train_loss = 1.14793543, grad/param norm = 1.5063e-01, time/batch = 16.3414s	
6464/33250 (epoch 9.720), train_loss = 1.39082065, grad/param norm = 1.5915e-01, time/batch = 17.3472s	
6465/33250 (epoch 9.722), train_loss = 1.03641349, grad/param norm = 1.4461e-01, time/batch = 15.0380s	
6466/33250 (epoch 9.723), train_loss = 0.93965300, grad/param norm = 1.2787e-01, time/batch = 17.0890s	
6467/33250 (epoch 9.725), train_loss = 0.98215664, grad/param norm = 1.3124e-01, time/batch = 16.3936s	
6468/33250 (epoch 9.726), train_loss = 1.08067795, grad/param norm = 1.3586e-01, time/batch = 19.6177s	
6469/33250 (epoch 9.728), train_loss = 1.21507918, grad/param norm = 1.5610e-01, time/batch = 19.6011s	
6470/33250 (epoch 9.729), train_loss = 1.32127566, grad/param norm = 1.6910e-01, time/batch = 17.1170s	
6471/33250 (epoch 9.731), train_loss = 1.09738136, grad/param norm = 1.5505e-01, time/batch = 17.7593s	
6472/33250 (epoch 9.732), train_loss = 1.03848672, grad/param norm = 1.4528e-01, time/batch = 17.2710s	
6473/33250 (epoch 9.734), train_loss = 1.18772235, grad/param norm = 1.5351e-01, time/batch = 15.4057s	
6474/33250 (epoch 9.735), train_loss = 1.16005575, grad/param norm = 1.5153e-01, time/batch = 16.6863s	
6475/33250 (epoch 9.737), train_loss = 1.15450280, grad/param norm = 1.3230e-01, time/batch = 17.4153s	
6476/33250 (epoch 9.738), train_loss = 1.14295206, grad/param norm = 1.5847e-01, time/batch = 17.2721s	
6477/33250 (epoch 9.740), train_loss = 1.29016999, grad/param norm = 1.5387e-01, time/batch = 16.1063s	
6478/33250 (epoch 9.741), train_loss = 1.21540398, grad/param norm = 1.5332e-01, time/batch = 16.1205s	
6479/33250 (epoch 9.743), train_loss = 1.11513716, grad/param norm = 1.4608e-01, time/batch = 18.1014s	
6480/33250 (epoch 9.744), train_loss = 1.14370311, grad/param norm = 1.5500e-01, time/batch = 15.5998s	
6481/33250 (epoch 9.746), train_loss = 1.13422193, grad/param norm = 1.3515e-01, time/batch = 16.9234s	
6482/33250 (epoch 9.747), train_loss = 1.10510356, grad/param norm = 1.6103e-01, time/batch = 18.9931s	
6483/33250 (epoch 9.749), train_loss = 1.30398103, grad/param norm = 1.9324e-01, time/batch = 18.0075s	
6484/33250 (epoch 9.750), train_loss = 1.19184377, grad/param norm = 1.5584e-01, time/batch = 17.0987s	
6485/33250 (epoch 9.752), train_loss = 1.04868016, grad/param norm = 1.4655e-01, time/batch = 16.4198s	
6486/33250 (epoch 9.753), train_loss = 1.13620794, grad/param norm = 1.4598e-01, time/batch = 18.6810s	
6487/33250 (epoch 9.755), train_loss = 1.11163044, grad/param norm = 1.5542e-01, time/batch = 15.8579s	
6488/33250 (epoch 9.756), train_loss = 1.24359449, grad/param norm = 1.6008e-01, time/batch = 18.4620s	
6489/33250 (epoch 9.758), train_loss = 1.26331425, grad/param norm = 1.5511e-01, time/batch = 18.3675s	
6490/33250 (epoch 9.759), train_loss = 1.05821121, grad/param norm = 1.4854e-01, time/batch = 17.9301s	
6491/33250 (epoch 9.761), train_loss = 1.09141298, grad/param norm = 1.4790e-01, time/batch = 15.5231s	
6492/33250 (epoch 9.762), train_loss = 1.25479539, grad/param norm = 1.5988e-01, time/batch = 18.0193s	
6493/33250 (epoch 9.764), train_loss = 1.09914582, grad/param norm = 1.8301e-01, time/batch = 17.5174s	
6494/33250 (epoch 9.765), train_loss = 1.19107408, grad/param norm = 1.5595e-01, time/batch = 30.8967s	
6495/33250 (epoch 9.767), train_loss = 0.95850708, grad/param norm = 1.4672e-01, time/batch = 16.9322s	
6496/33250 (epoch 9.768), train_loss = 1.01597276, grad/param norm = 1.5007e-01, time/batch = 16.1238s	
6497/33250 (epoch 9.770), train_loss = 1.22693253, grad/param norm = 1.6573e-01, time/batch = 15.3528s	
6498/33250 (epoch 9.771), train_loss = 1.19914955, grad/param norm = 1.5761e-01, time/batch = 17.4446s	
6499/33250 (epoch 9.773), train_loss = 1.11444229, grad/param norm = 1.6753e-01, time/batch = 17.7699s	
6500/33250 (epoch 9.774), train_loss = 0.98218885, grad/param norm = 1.5444e-01, time/batch = 15.9292s	
6501/33250 (epoch 9.776), train_loss = 1.09413607, grad/param norm = 1.5279e-01, time/batch = 15.6120s	
6502/33250 (epoch 9.777), train_loss = 1.25162766, grad/param norm = 1.9432e-01, time/batch = 15.1138s	
6503/33250 (epoch 9.779), train_loss = 1.09420316, grad/param norm = 1.5917e-01, time/batch = 16.0160s	
6504/33250 (epoch 9.780), train_loss = 1.35827919, grad/param norm = 1.7519e-01, time/batch = 15.2860s	
6505/33250 (epoch 9.782), train_loss = 1.17765117, grad/param norm = 1.3696e-01, time/batch = 16.9345s	
6506/33250 (epoch 9.783), train_loss = 0.93615646, grad/param norm = 1.3550e-01, time/batch = 17.5407s	
6507/33250 (epoch 9.785), train_loss = 1.02979761, grad/param norm = 1.4865e-01, time/batch = 16.5257s	
6508/33250 (epoch 9.786), train_loss = 1.20906951, grad/param norm = 1.5423e-01, time/batch = 17.5725s	
6509/33250 (epoch 9.788), train_loss = 1.21509767, grad/param norm = 1.5142e-01, time/batch = 16.7967s	
6510/33250 (epoch 9.789), train_loss = 1.26666474, grad/param norm = 1.7376e-01, time/batch = 17.0203s	
6511/33250 (epoch 9.791), train_loss = 1.31583231, grad/param norm = 1.5822e-01, time/batch = 16.4257s	
6512/33250 (epoch 9.792), train_loss = 1.39618993, grad/param norm = 1.5555e-01, time/batch = 16.4954s	
6513/33250 (epoch 9.794), train_loss = 1.13409142, grad/param norm = 1.5576e-01, time/batch = 15.6509s	
6514/33250 (epoch 9.795), train_loss = 1.22347672, grad/param norm = 1.5469e-01, time/batch = 15.6839s	
6515/33250 (epoch 9.797), train_loss = 1.27543446, grad/param norm = 1.7351e-01, time/batch = 16.9272s	
6516/33250 (epoch 9.798), train_loss = 1.18950696, grad/param norm = 1.7726e-01, time/batch = 16.3738s	
6517/33250 (epoch 9.800), train_loss = 1.22909365, grad/param norm = 1.6242e-01, time/batch = 16.6429s	
6518/33250 (epoch 9.802), train_loss = 1.09667339, grad/param norm = 1.5107e-01, time/batch = 17.8623s	
6519/33250 (epoch 9.803), train_loss = 1.12750411, grad/param norm = 1.4947e-01, time/batch = 17.3886s	
6520/33250 (epoch 9.805), train_loss = 1.21924932, grad/param norm = 1.6759e-01, time/batch = 17.5137s	
6521/33250 (epoch 9.806), train_loss = 1.21425064, grad/param norm = 1.5164e-01, time/batch = 17.0885s	
6522/33250 (epoch 9.808), train_loss = 1.14034326, grad/param norm = 1.5524e-01, time/batch = 16.7419s	
6523/33250 (epoch 9.809), train_loss = 1.03705035, grad/param norm = 1.5697e-01, time/batch = 15.6091s	
6524/33250 (epoch 9.811), train_loss = 1.05659532, grad/param norm = 1.4122e-01, time/batch = 17.9412s	
6525/33250 (epoch 9.812), train_loss = 1.22769252, grad/param norm = 1.5883e-01, time/batch = 16.6788s	
6526/33250 (epoch 9.814), train_loss = 1.16989126, grad/param norm = 1.6017e-01, time/batch = 16.4457s	
6527/33250 (epoch 9.815), train_loss = 1.23454399, grad/param norm = 1.6183e-01, time/batch = 17.2091s	
6528/33250 (epoch 9.817), train_loss = 1.14477385, grad/param norm = 1.5112e-01, time/batch = 18.7880s	
6529/33250 (epoch 9.818), train_loss = 1.07115180, grad/param norm = 1.5272e-01, time/batch = 17.5176s	
6530/33250 (epoch 9.820), train_loss = 1.16475683, grad/param norm = 1.5506e-01, time/batch = 17.1954s	
6531/33250 (epoch 9.821), train_loss = 1.08392590, grad/param norm = 1.3766e-01, time/batch = 15.5968s	
6532/33250 (epoch 9.823), train_loss = 1.46014281, grad/param norm = 1.8759e-01, time/batch = 16.7444s	
6533/33250 (epoch 9.824), train_loss = 1.14981399, grad/param norm = 1.6055e-01, time/batch = 18.6572s	
6534/33250 (epoch 9.826), train_loss = 1.18134368, grad/param norm = 1.6649e-01, time/batch = 18.1826s	
6535/33250 (epoch 9.827), train_loss = 0.91553926, grad/param norm = 1.3674e-01, time/batch = 15.3669s	
6536/33250 (epoch 9.829), train_loss = 1.16802761, grad/param norm = 1.8395e-01, time/batch = 16.1848s	
6537/33250 (epoch 9.830), train_loss = 1.29263954, grad/param norm = 1.7110e-01, time/batch = 19.0864s	
6538/33250 (epoch 9.832), train_loss = 1.13920640, grad/param norm = 1.4555e-01, time/batch = 17.1983s	
6539/33250 (epoch 9.833), train_loss = 1.21431788, grad/param norm = 1.6380e-01, time/batch = 15.8835s	
6540/33250 (epoch 9.835), train_loss = 1.11137737, grad/param norm = 1.8103e-01, time/batch = 16.0449s	
6541/33250 (epoch 9.836), train_loss = 1.15078462, grad/param norm = 1.4575e-01, time/batch = 17.2696s	
6542/33250 (epoch 9.838), train_loss = 1.10570118, grad/param norm = 1.5731e-01, time/batch = 17.7549s	
6543/33250 (epoch 9.839), train_loss = 1.09500165, grad/param norm = 1.6145e-01, time/batch = 16.0968s	
6544/33250 (epoch 9.841), train_loss = 1.00542410, grad/param norm = 1.2841e-01, time/batch = 16.0106s	
6545/33250 (epoch 9.842), train_loss = 1.33080057, grad/param norm = 1.5831e-01, time/batch = 17.1865s	
6546/33250 (epoch 9.844), train_loss = 1.29549108, grad/param norm = 1.7718e-01, time/batch = 16.8404s	
6547/33250 (epoch 9.845), train_loss = 1.41454593, grad/param norm = 1.8998e-01, time/batch = 18.3711s	
6548/33250 (epoch 9.847), train_loss = 1.33941076, grad/param norm = 1.7439e-01, time/batch = 16.7855s	
6549/33250 (epoch 9.848), train_loss = 1.48441287, grad/param norm = 1.8843e-01, time/batch = 18.2825s	
6550/33250 (epoch 9.850), train_loss = 1.27481452, grad/param norm = 1.4778e-01, time/batch = 17.4208s	
6551/33250 (epoch 9.851), train_loss = 1.07439531, grad/param norm = 1.5767e-01, time/batch = 16.0347s	
6552/33250 (epoch 9.853), train_loss = 1.21598312, grad/param norm = 1.6768e-01, time/batch = 19.0065s	
6553/33250 (epoch 9.854), train_loss = 1.04253868, grad/param norm = 1.4237e-01, time/batch = 16.3516s	
6554/33250 (epoch 9.856), train_loss = 1.08674002, grad/param norm = 1.6013e-01, time/batch = 15.4105s	
6555/33250 (epoch 9.857), train_loss = 0.97864314, grad/param norm = 1.3920e-01, time/batch = 16.6946s	
6556/33250 (epoch 9.859), train_loss = 0.98163860, grad/param norm = 1.3510e-01, time/batch = 17.8412s	
6557/33250 (epoch 9.860), train_loss = 1.14753227, grad/param norm = 1.3506e-01, time/batch = 17.1939s	
6558/33250 (epoch 9.862), train_loss = 1.03708505, grad/param norm = 1.3714e-01, time/batch = 19.1877s	
6559/33250 (epoch 9.863), train_loss = 1.07756847, grad/param norm = 1.4431e-01, time/batch = 17.1111s	
6560/33250 (epoch 9.865), train_loss = 1.20360124, grad/param norm = 1.5115e-01, time/batch = 16.5369s	
6561/33250 (epoch 9.866), train_loss = 1.09203423, grad/param norm = 1.5341e-01, time/batch = 17.6041s	
6562/33250 (epoch 9.868), train_loss = 1.35149551, grad/param norm = 1.9574e-01, time/batch = 16.6917s	
6563/33250 (epoch 9.869), train_loss = 1.24661699, grad/param norm = 1.7149e-01, time/batch = 17.6756s	
6564/33250 (epoch 9.871), train_loss = 0.93611109, grad/param norm = 1.4019e-01, time/batch = 16.9964s	
6565/33250 (epoch 9.872), train_loss = 1.18272640, grad/param norm = 1.5806e-01, time/batch = 16.4160s	
6566/33250 (epoch 9.874), train_loss = 1.06530816, grad/param norm = 1.6293e-01, time/batch = 16.5270s	
6567/33250 (epoch 9.875), train_loss = 1.06051957, grad/param norm = 1.6317e-01, time/batch = 18.7756s	
6568/33250 (epoch 9.877), train_loss = 1.23597793, grad/param norm = 1.6384e-01, time/batch = 15.6904s	
6569/33250 (epoch 9.878), train_loss = 1.18367060, grad/param norm = 1.5167e-01, time/batch = 19.0223s	
6570/33250 (epoch 9.880), train_loss = 1.15663248, grad/param norm = 1.7318e-01, time/batch = 17.5984s	
6571/33250 (epoch 9.881), train_loss = 1.37689428, grad/param norm = 1.8052e-01, time/batch = 15.8348s	
6572/33250 (epoch 9.883), train_loss = 1.18104067, grad/param norm = 1.7063e-01, time/batch = 17.4196s	
6573/33250 (epoch 9.884), train_loss = 1.16023598, grad/param norm = 1.6703e-01, time/batch = 17.3545s	
6574/33250 (epoch 9.886), train_loss = 1.05520664, grad/param norm = 1.3669e-01, time/batch = 16.8488s	
6575/33250 (epoch 9.887), train_loss = 1.11409075, grad/param norm = 1.4745e-01, time/batch = 16.1771s	
6576/33250 (epoch 9.889), train_loss = 1.08287477, grad/param norm = 1.3678e-01, time/batch = 17.9379s	
6577/33250 (epoch 9.890), train_loss = 0.96631313, grad/param norm = 1.2932e-01, time/batch = 18.1974s	
6578/33250 (epoch 9.892), train_loss = 1.22381621, grad/param norm = 1.4457e-01, time/batch = 16.3583s	
6579/33250 (epoch 9.893), train_loss = 1.25845905, grad/param norm = 1.6968e-01, time/batch = 17.7105s	
6580/33250 (epoch 9.895), train_loss = 1.12062385, grad/param norm = 1.6095e-01, time/batch = 18.7711s	
6581/33250 (epoch 9.896), train_loss = 1.23871462, grad/param norm = 1.6627e-01, time/batch = 16.4073s	
6582/33250 (epoch 9.898), train_loss = 1.11379928, grad/param norm = 1.6026e-01, time/batch = 16.8395s	
6583/33250 (epoch 9.899), train_loss = 1.06541575, grad/param norm = 1.3992e-01, time/batch = 15.9307s	
6584/33250 (epoch 9.901), train_loss = 0.98749272, grad/param norm = 1.3424e-01, time/batch = 16.9898s	
6585/33250 (epoch 9.902), train_loss = 1.11156806, grad/param norm = 1.4652e-01, time/batch = 16.5278s	
6586/33250 (epoch 9.904), train_loss = 1.07226376, grad/param norm = 1.4329e-01, time/batch = 19.5171s	
6587/33250 (epoch 9.905), train_loss = 1.06479901, grad/param norm = 1.4595e-01, time/batch = 19.2719s	
6588/33250 (epoch 9.907), train_loss = 1.05037861, grad/param norm = 1.4581e-01, time/batch = 15.4703s	
6589/33250 (epoch 9.908), train_loss = 1.16118138, grad/param norm = 1.4674e-01, time/batch = 19.1192s	
6590/33250 (epoch 9.910), train_loss = 1.23933627, grad/param norm = 1.5886e-01, time/batch = 16.5855s	
6591/33250 (epoch 9.911), train_loss = 0.94271981, grad/param norm = 1.4288e-01, time/batch = 16.8455s	
6592/33250 (epoch 9.913), train_loss = 1.09812538, grad/param norm = 1.4358e-01, time/batch = 15.7586s	
6593/33250 (epoch 9.914), train_loss = 0.95472976, grad/param norm = 1.4406e-01, time/batch = 18.1854s	
6594/33250 (epoch 9.916), train_loss = 1.05849166, grad/param norm = 1.2697e-01, time/batch = 16.6900s	
6595/33250 (epoch 9.917), train_loss = 1.06416971, grad/param norm = 1.3261e-01, time/batch = 17.0811s	
6596/33250 (epoch 9.919), train_loss = 1.09267929, grad/param norm = 1.6515e-01, time/batch = 18.5366s	
6597/33250 (epoch 9.920), train_loss = 1.16591694, grad/param norm = 1.5534e-01, time/batch = 16.4589s	
6598/33250 (epoch 9.922), train_loss = 1.16553910, grad/param norm = 1.5787e-01, time/batch = 15.9542s	
6599/33250 (epoch 9.923), train_loss = 1.12856502, grad/param norm = 1.5185e-01, time/batch = 16.2765s	
6600/33250 (epoch 9.925), train_loss = 1.07498796, grad/param norm = 1.4295e-01, time/batch = 15.7663s	
6601/33250 (epoch 9.926), train_loss = 1.08545803, grad/param norm = 1.5795e-01, time/batch = 17.4384s	
6602/33250 (epoch 9.928), train_loss = 1.12984234, grad/param norm = 1.5591e-01, time/batch = 16.2765s	
6603/33250 (epoch 9.929), train_loss = 0.88690171, grad/param norm = 1.1913e-01, time/batch = 17.0967s	
6604/33250 (epoch 9.931), train_loss = 1.18083989, grad/param norm = 1.5491e-01, time/batch = 17.8349s	
6605/33250 (epoch 9.932), train_loss = 1.18914435, grad/param norm = 1.7012e-01, time/batch = 16.1884s	
6606/33250 (epoch 9.934), train_loss = 1.05803160, grad/param norm = 1.3133e-01, time/batch = 17.5298s	
6607/33250 (epoch 9.935), train_loss = 1.10893027, grad/param norm = 1.6841e-01, time/batch = 18.4470s	
6608/33250 (epoch 9.937), train_loss = 1.20006527, grad/param norm = 1.6999e-01, time/batch = 19.7577s	
6609/33250 (epoch 9.938), train_loss = 1.20193210, grad/param norm = 1.5383e-01, time/batch = 16.9506s	
6610/33250 (epoch 9.940), train_loss = 1.11176360, grad/param norm = 1.7294e-01, time/batch = 16.1782s	
6611/33250 (epoch 9.941), train_loss = 1.16745796, grad/param norm = 1.6652e-01, time/batch = 17.1908s	
6612/33250 (epoch 9.943), train_loss = 1.33783668, grad/param norm = 1.6033e-01, time/batch = 16.2759s	
6613/33250 (epoch 9.944), train_loss = 1.02790060, grad/param norm = 1.3728e-01, time/batch = 16.9249s	
6614/33250 (epoch 9.946), train_loss = 1.30739726, grad/param norm = 1.5354e-01, time/batch = 16.9334s	
6615/33250 (epoch 9.947), train_loss = 1.05571035, grad/param norm = 1.5483e-01, time/batch = 17.4395s	
6616/33250 (epoch 9.949), train_loss = 1.27185276, grad/param norm = 1.5029e-01, time/batch = 16.4420s	
6617/33250 (epoch 9.950), train_loss = 1.17260439, grad/param norm = 1.4824e-01, time/batch = 16.3316s	
6618/33250 (epoch 9.952), train_loss = 1.11035953, grad/param norm = 1.5516e-01, time/batch = 17.4472s	
6619/33250 (epoch 9.953), train_loss = 1.23866335, grad/param norm = 1.6490e-01, time/batch = 17.0320s	
6620/33250 (epoch 9.955), train_loss = 1.23410970, grad/param norm = 1.5162e-01, time/batch = 16.4135s	
6621/33250 (epoch 9.956), train_loss = 1.25431829, grad/param norm = 1.7563e-01, time/batch = 17.9248s	
6622/33250 (epoch 9.958), train_loss = 1.03637334, grad/param norm = 1.4822e-01, time/batch = 18.5034s	
6623/33250 (epoch 9.959), train_loss = 1.06218836, grad/param norm = 1.4154e-01, time/batch = 16.1628s	
6624/33250 (epoch 9.961), train_loss = 1.32501213, grad/param norm = 1.5259e-01, time/batch = 17.5184s	
6625/33250 (epoch 9.962), train_loss = 1.18643969, grad/param norm = 1.5378e-01, time/batch = 17.1088s	
6626/33250 (epoch 9.964), train_loss = 1.33953719, grad/param norm = 1.6894e-01, time/batch = 18.1104s	
6627/33250 (epoch 9.965), train_loss = 1.20246243, grad/param norm = 1.8188e-01, time/batch = 19.6119s	
6628/33250 (epoch 9.967), train_loss = 1.15802024, grad/param norm = 1.6151e-01, time/batch = 15.7915s	
6629/33250 (epoch 9.968), train_loss = 1.39455088, grad/param norm = 1.5385e-01, time/batch = 18.3441s	
6630/33250 (epoch 9.970), train_loss = 1.47668477, grad/param norm = 1.8558e-01, time/batch = 16.3596s	
6631/33250 (epoch 9.971), train_loss = 1.30584906, grad/param norm = 1.7950e-01, time/batch = 16.7692s	
6632/33250 (epoch 9.973), train_loss = 1.08973661, grad/param norm = 1.5595e-01, time/batch = 19.0000s	
6633/33250 (epoch 9.974), train_loss = 1.19659991, grad/param norm = 1.6038e-01, time/batch = 16.9946s	
6634/33250 (epoch 9.976), train_loss = 1.11675007, grad/param norm = 1.7110e-01, time/batch = 15.9373s	
6635/33250 (epoch 9.977), train_loss = 1.07517567, grad/param norm = 1.5965e-01, time/batch = 15.7719s	
6636/33250 (epoch 9.979), train_loss = 1.17155024, grad/param norm = 1.6413e-01, time/batch = 17.4581s	
6637/33250 (epoch 9.980), train_loss = 1.13814619, grad/param norm = 1.3532e-01, time/batch = 17.0329s	
6638/33250 (epoch 9.982), train_loss = 0.96133324, grad/param norm = 1.3467e-01, time/batch = 19.0323s	
6639/33250 (epoch 9.983), train_loss = 1.20581887, grad/param norm = 1.7013e-01, time/batch = 15.3628s	
6640/33250 (epoch 9.985), train_loss = 1.06908460, grad/param norm = 1.6044e-01, time/batch = 16.7560s	
6641/33250 (epoch 9.986), train_loss = 1.26459040, grad/param norm = 1.8587e-01, time/batch = 17.0185s	
6642/33250 (epoch 9.988), train_loss = 1.26164338, grad/param norm = 1.8126e-01, time/batch = 17.1744s	
6643/33250 (epoch 9.989), train_loss = 1.28010269, grad/param norm = 1.7715e-01, time/batch = 16.7518s	
6644/33250 (epoch 9.991), train_loss = 1.15597671, grad/param norm = 1.6344e-01, time/batch = 16.7713s	
6645/33250 (epoch 9.992), train_loss = 1.13827569, grad/param norm = 1.5401e-01, time/batch = 18.5206s	
6646/33250 (epoch 9.994), train_loss = 1.07349693, grad/param norm = 1.5318e-01, time/batch = 16.2628s	
6647/33250 (epoch 9.995), train_loss = 1.17714895, grad/param norm = 1.8125e-01, time/batch = 18.1697s	
6648/33250 (epoch 9.997), train_loss = 0.84884227, grad/param norm = 1.3614e-01, time/batch = 17.5311s	
6649/33250 (epoch 9.998), train_loss = 1.12666474, grad/param norm = 1.4303e-01, time/batch = 18.1846s	
decayed learning rate by a factor 0.97 to 0.00194	
6650/33250 (epoch 10.000), train_loss = 1.15094963, grad/param norm = 1.4844e-01, time/batch = 16.5680s	
6651/33250 (epoch 10.002), train_loss = 1.32946740, grad/param norm = 1.7502e-01, time/batch = 17.2493s	
6652/33250 (epoch 10.003), train_loss = 1.22041518, grad/param norm = 1.5395e-01, time/batch = 15.1904s	
6653/33250 (epoch 10.005), train_loss = 0.92225264, grad/param norm = 1.2243e-01, time/batch = 15.8614s	
6654/33250 (epoch 10.006), train_loss = 0.98575797, grad/param norm = 1.4201e-01, time/batch = 15.5082s	
6655/33250 (epoch 10.008), train_loss = 1.30698936, grad/param norm = 1.6006e-01, time/batch = 17.1935s	
6656/33250 (epoch 10.009), train_loss = 1.28146027, grad/param norm = 1.6308e-01, time/batch = 17.9508s	
6657/33250 (epoch 10.011), train_loss = 1.03064684, grad/param norm = 1.3981e-01, time/batch = 16.8092s	
6658/33250 (epoch 10.012), train_loss = 1.19530494, grad/param norm = 1.9398e-01, time/batch = 15.5728s	
6659/33250 (epoch 10.014), train_loss = 1.28169550, grad/param norm = 1.6578e-01, time/batch = 15.6920s	
6660/33250 (epoch 10.015), train_loss = 1.14932188, grad/param norm = 1.5187e-01, time/batch = 16.3395s	
6661/33250 (epoch 10.017), train_loss = 1.19670547, grad/param norm = 1.6733e-01, time/batch = 16.5090s	
6662/33250 (epoch 10.018), train_loss = 0.94141425, grad/param norm = 1.3337e-01, time/batch = 16.1987s	
6663/33250 (epoch 10.020), train_loss = 1.08612603, grad/param norm = 1.3909e-01, time/batch = 15.0335s	
6664/33250 (epoch 10.021), train_loss = 1.11867357, grad/param norm = 1.4754e-01, time/batch = 15.5129s	
6665/33250 (epoch 10.023), train_loss = 0.95026292, grad/param norm = 1.4607e-01, time/batch = 16.4261s	
6666/33250 (epoch 10.024), train_loss = 1.23727677, grad/param norm = 1.6719e-01, time/batch = 17.6937s	
6667/33250 (epoch 10.026), train_loss = 1.13049054, grad/param norm = 1.3447e-01, time/batch = 17.3686s	
6668/33250 (epoch 10.027), train_loss = 1.12354694, grad/param norm = 1.4460e-01, time/batch = 18.2113s	
6669/33250 (epoch 10.029), train_loss = 1.14812142, grad/param norm = 1.4859e-01, time/batch = 15.5748s	
6670/33250 (epoch 10.030), train_loss = 1.12869584, grad/param norm = 1.5526e-01, time/batch = 17.1882s	
6671/33250 (epoch 10.032), train_loss = 1.38808339, grad/param norm = 1.8648e-01, time/batch = 17.5131s	
6672/33250 (epoch 10.033), train_loss = 1.09004752, grad/param norm = 1.6073e-01, time/batch = 15.7720s	
6673/33250 (epoch 10.035), train_loss = 1.08684071, grad/param norm = 1.5218e-01, time/batch = 16.1142s	
6674/33250 (epoch 10.036), train_loss = 1.23305217, grad/param norm = 1.7036e-01, time/batch = 16.7553s	
6675/33250 (epoch 10.038), train_loss = 1.09721205, grad/param norm = 1.4916e-01, time/batch = 19.5867s	
6676/33250 (epoch 10.039), train_loss = 1.01079110, grad/param norm = 1.3765e-01, time/batch = 16.6901s	
6677/33250 (epoch 10.041), train_loss = 1.16985821, grad/param norm = 1.6482e-01, time/batch = 18.1279s	
6678/33250 (epoch 10.042), train_loss = 0.97459746, grad/param norm = 1.3705e-01, time/batch = 19.4441s	
6679/33250 (epoch 10.044), train_loss = 1.29529706, grad/param norm = 1.6778e-01, time/batch = 16.1832s	
6680/33250 (epoch 10.045), train_loss = 1.25417439, grad/param norm = 1.5289e-01, time/batch = 16.2848s	
6681/33250 (epoch 10.047), train_loss = 1.22762471, grad/param norm = 1.6292e-01, time/batch = 17.3444s	
6682/33250 (epoch 10.048), train_loss = 1.34199540, grad/param norm = 1.8558e-01, time/batch = 15.5219s	
6683/33250 (epoch 10.050), train_loss = 1.11901716, grad/param norm = 1.4383e-01, time/batch = 15.3125s	
6684/33250 (epoch 10.051), train_loss = 1.13053827, grad/param norm = 1.4537e-01, time/batch = 16.8471s	
6685/33250 (epoch 10.053), train_loss = 1.19203408, grad/param norm = 1.6086e-01, time/batch = 17.2011s	
6686/33250 (epoch 10.054), train_loss = 0.97128923, grad/param norm = 1.2958e-01, time/batch = 17.3506s	
6687/33250 (epoch 10.056), train_loss = 1.01226034, grad/param norm = 1.4666e-01, time/batch = 19.2074s	
6688/33250 (epoch 10.057), train_loss = 1.16861366, grad/param norm = 1.3981e-01, time/batch = 15.5181s	
6689/33250 (epoch 10.059), train_loss = 1.08754763, grad/param norm = 1.4228e-01, time/batch = 17.9045s	
6690/33250 (epoch 10.060), train_loss = 1.21430916, grad/param norm = 1.7857e-01, time/batch = 16.6766s	
6691/33250 (epoch 10.062), train_loss = 1.30128368, grad/param norm = 1.5303e-01, time/batch = 17.5074s	
6692/33250 (epoch 10.063), train_loss = 1.27308611, grad/param norm = 1.5511e-01, time/batch = 16.9419s	
6693/33250 (epoch 10.065), train_loss = 1.12068383, grad/param norm = 1.4900e-01, time/batch = 16.4214s	
6694/33250 (epoch 10.066), train_loss = 1.20590150, grad/param norm = 1.4807e-01, time/batch = 16.4412s	
6695/33250 (epoch 10.068), train_loss = 1.11534733, grad/param norm = 1.5494e-01, time/batch = 18.5121s	
6696/33250 (epoch 10.069), train_loss = 1.14673029, grad/param norm = 1.5191e-01, time/batch = 17.4659s	
6697/33250 (epoch 10.071), train_loss = 1.01823138, grad/param norm = 1.5027e-01, time/batch = 18.1066s	
6698/33250 (epoch 10.072), train_loss = 1.02726621, grad/param norm = 1.3216e-01, time/batch = 17.3484s	
6699/33250 (epoch 10.074), train_loss = 1.18605514, grad/param norm = 1.4926e-01, time/batch = 18.1001s	
6700/33250 (epoch 10.075), train_loss = 1.03330249, grad/param norm = 1.3500e-01, time/batch = 15.2410s	
6701/33250 (epoch 10.077), train_loss = 1.12838103, grad/param norm = 1.5179e-01, time/batch = 16.4561s	
6702/33250 (epoch 10.078), train_loss = 1.09012362, grad/param norm = 1.4156e-01, time/batch = 16.1222s	
6703/33250 (epoch 10.080), train_loss = 1.19801069, grad/param norm = 1.7579e-01, time/batch = 15.3358s	
6704/33250 (epoch 10.081), train_loss = 1.19929939, grad/param norm = 1.6410e-01, time/batch = 31.5651s	
6705/33250 (epoch 10.083), train_loss = 1.23594391, grad/param norm = 1.4584e-01, time/batch = 16.6228s	
6706/33250 (epoch 10.084), train_loss = 1.12991937, grad/param norm = 1.4324e-01, time/batch = 15.8612s	
6707/33250 (epoch 10.086), train_loss = 1.07378216, grad/param norm = 1.4684e-01, time/batch = 16.7733s	
6708/33250 (epoch 10.087), train_loss = 0.99751727, grad/param norm = 1.4907e-01, time/batch = 18.8268s	
6709/33250 (epoch 10.089), train_loss = 1.17010155, grad/param norm = 1.5132e-01, time/batch = 17.4317s	
6710/33250 (epoch 10.090), train_loss = 1.10089275, grad/param norm = 1.5233e-01, time/batch = 15.4821s	
6711/33250 (epoch 10.092), train_loss = 1.04515667, grad/param norm = 1.3646e-01, time/batch = 18.2502s	
6712/33250 (epoch 10.093), train_loss = 1.15002912, grad/param norm = 1.4601e-01, time/batch = 17.6027s	
6713/33250 (epoch 10.095), train_loss = 1.10037264, grad/param norm = 1.4419e-01, time/batch = 17.0067s	
6714/33250 (epoch 10.096), train_loss = 0.95036332, grad/param norm = 1.4295e-01, time/batch = 19.1067s	
6715/33250 (epoch 10.098), train_loss = 1.03189872, grad/param norm = 1.6850e-01, time/batch = 17.6298s	
6716/33250 (epoch 10.099), train_loss = 0.85545326, grad/param norm = 1.4507e-01, time/batch = 16.6217s	
6717/33250 (epoch 10.101), train_loss = 1.09247235, grad/param norm = 1.3441e-01, time/batch = 17.1881s	
6718/33250 (epoch 10.102), train_loss = 1.02034500, grad/param norm = 1.4917e-01, time/batch = 16.5308s	
6719/33250 (epoch 10.104), train_loss = 0.90709392, grad/param norm = 1.3139e-01, time/batch = 17.1026s	
6720/33250 (epoch 10.105), train_loss = 1.03950999, grad/param norm = 1.3781e-01, time/batch = 16.7577s	
6721/33250 (epoch 10.107), train_loss = 0.93549180, grad/param norm = 1.4266e-01, time/batch = 16.7648s	
6722/33250 (epoch 10.108), train_loss = 1.12392130, grad/param norm = 1.4994e-01, time/batch = 15.6961s	
6723/33250 (epoch 10.110), train_loss = 0.88629647, grad/param norm = 1.2874e-01, time/batch = 18.0821s	
6724/33250 (epoch 10.111), train_loss = 1.08802534, grad/param norm = 1.4796e-01, time/batch = 16.5210s	
6725/33250 (epoch 10.113), train_loss = 1.11797452, grad/param norm = 1.6409e-01, time/batch = 19.1915s	
6726/33250 (epoch 10.114), train_loss = 1.02225291, grad/param norm = 1.5040e-01, time/batch = 19.2752s	
6727/33250 (epoch 10.116), train_loss = 1.13944277, grad/param norm = 1.4978e-01, time/batch = 16.2796s	
6728/33250 (epoch 10.117), train_loss = 1.10883182, grad/param norm = 1.4913e-01, time/batch = 18.5014s	
6729/33250 (epoch 10.119), train_loss = 1.04826341, grad/param norm = 1.4422e-01, time/batch = 16.6797s	
6730/33250 (epoch 10.120), train_loss = 0.87060680, grad/param norm = 1.3259e-01, time/batch = 18.3223s	
6731/33250 (epoch 10.122), train_loss = 1.24607008, grad/param norm = 1.4655e-01, time/batch = 17.1480s	
6732/33250 (epoch 10.123), train_loss = 1.17096674, grad/param norm = 1.6548e-01, time/batch = 15.5159s	
6733/33250 (epoch 10.125), train_loss = 0.94384818, grad/param norm = 1.4621e-01, time/batch = 16.8546s	
6734/33250 (epoch 10.126), train_loss = 1.10150675, grad/param norm = 1.5583e-01, time/batch = 16.9565s	
6735/33250 (epoch 10.128), train_loss = 1.02211419, grad/param norm = 1.3246e-01, time/batch = 17.4629s	
6736/33250 (epoch 10.129), train_loss = 1.09329926, grad/param norm = 1.4329e-01, time/batch = 19.3677s	
6737/33250 (epoch 10.131), train_loss = 1.11223015, grad/param norm = 1.5898e-01, time/batch = 16.9332s	
6738/33250 (epoch 10.132), train_loss = 1.10903747, grad/param norm = 1.7224e-01, time/batch = 15.9178s	
6739/33250 (epoch 10.134), train_loss = 1.11945076, grad/param norm = 1.5151e-01, time/batch = 16.3455s	
6740/33250 (epoch 10.135), train_loss = 1.16484605, grad/param norm = 1.4627e-01, time/batch = 17.8277s	
6741/33250 (epoch 10.137), train_loss = 1.01931277, grad/param norm = 1.5680e-01, time/batch = 16.0214s	
6742/33250 (epoch 10.138), train_loss = 1.04759568, grad/param norm = 1.2882e-01, time/batch = 17.0134s	
6743/33250 (epoch 10.140), train_loss = 0.88673039, grad/param norm = 1.3636e-01, time/batch = 17.5239s	
6744/33250 (epoch 10.141), train_loss = 1.41663538, grad/param norm = 1.9499e-01, time/batch = 18.0396s	
6745/33250 (epoch 10.143), train_loss = 0.87651645, grad/param norm = 1.4550e-01, time/batch = 17.4430s	
6746/33250 (epoch 10.144), train_loss = 1.05098465, grad/param norm = 1.4506e-01, time/batch = 15.7480s	
6747/33250 (epoch 10.146), train_loss = 1.02517879, grad/param norm = 1.3746e-01, time/batch = 18.6637s	
6748/33250 (epoch 10.147), train_loss = 1.02217263, grad/param norm = 1.5054e-01, time/batch = 15.2891s	
6749/33250 (epoch 10.149), train_loss = 1.07030526, grad/param norm = 1.4805e-01, time/batch = 16.7770s	
6750/33250 (epoch 10.150), train_loss = 0.99346921, grad/param norm = 1.4532e-01, time/batch = 17.0102s	
6751/33250 (epoch 10.152), train_loss = 0.96020949, grad/param norm = 1.4661e-01, time/batch = 17.1855s	
6752/33250 (epoch 10.153), train_loss = 1.29092264, grad/param norm = 1.6938e-01, time/batch = 15.3461s	
6753/33250 (epoch 10.155), train_loss = 1.13976571, grad/param norm = 1.7838e-01, time/batch = 18.6978s	
6754/33250 (epoch 10.156), train_loss = 1.30050159, grad/param norm = 1.6021e-01, time/batch = 17.8801s	
6755/33250 (epoch 10.158), train_loss = 1.37080653, grad/param norm = 1.8030e-01, time/batch = 16.9394s	
6756/33250 (epoch 10.159), train_loss = 1.12371187, grad/param norm = 1.5460e-01, time/batch = 16.1854s	
6757/33250 (epoch 10.161), train_loss = 1.17295365, grad/param norm = 1.5945e-01, time/batch = 15.2697s	
6758/33250 (epoch 10.162), train_loss = 1.01782631, grad/param norm = 1.4770e-01, time/batch = 16.7716s	
6759/33250 (epoch 10.164), train_loss = 1.14606734, grad/param norm = 1.5859e-01, time/batch = 17.3447s	
6760/33250 (epoch 10.165), train_loss = 1.21448988, grad/param norm = 1.6966e-01, time/batch = 16.7740s	
6761/33250 (epoch 10.167), train_loss = 1.23038457, grad/param norm = 1.5537e-01, time/batch = 16.8442s	
6762/33250 (epoch 10.168), train_loss = 0.94674769, grad/param norm = 1.2863e-01, time/batch = 16.9153s	
6763/33250 (epoch 10.170), train_loss = 1.06711793, grad/param norm = 1.5405e-01, time/batch = 18.1139s	
6764/33250 (epoch 10.171), train_loss = 1.07142429, grad/param norm = 1.4337e-01, time/batch = 17.1427s	
6765/33250 (epoch 10.173), train_loss = 1.05701758, grad/param norm = 1.4498e-01, time/batch = 17.1984s	
6766/33250 (epoch 10.174), train_loss = 1.10218309, grad/param norm = 1.5111e-01, time/batch = 17.3603s	
6767/33250 (epoch 10.176), train_loss = 1.12760744, grad/param norm = 1.5078e-01, time/batch = 18.1829s	
6768/33250 (epoch 10.177), train_loss = 1.02784546, grad/param norm = 1.2911e-01, time/batch = 15.9291s	
6769/33250 (epoch 10.179), train_loss = 1.03631635, grad/param norm = 1.5708e-01, time/batch = 16.3376s	
6770/33250 (epoch 10.180), train_loss = 0.95731858, grad/param norm = 1.3778e-01, time/batch = 17.5928s	
6771/33250 (epoch 10.182), train_loss = 1.06052252, grad/param norm = 1.6660e-01, time/batch = 17.8462s	
6772/33250 (epoch 10.183), train_loss = 1.26559772, grad/param norm = 1.6029e-01, time/batch = 17.7537s	
6773/33250 (epoch 10.185), train_loss = 1.21597769, grad/param norm = 1.7936e-01, time/batch = 18.3505s	
6774/33250 (epoch 10.186), train_loss = 1.13393472, grad/param norm = 1.5026e-01, time/batch = 15.8445s	
6775/33250 (epoch 10.188), train_loss = 1.22313317, grad/param norm = 1.7302e-01, time/batch = 18.8608s	
6776/33250 (epoch 10.189), train_loss = 0.94571589, grad/param norm = 1.5547e-01, time/batch = 17.5181s	
6777/33250 (epoch 10.191), train_loss = 1.03437169, grad/param norm = 1.5401e-01, time/batch = 17.2476s	
6778/33250 (epoch 10.192), train_loss = 1.01837991, grad/param norm = 1.3279e-01, time/batch = 17.5144s	
6779/33250 (epoch 10.194), train_loss = 1.05052722, grad/param norm = 1.5938e-01, time/batch = 17.0961s	
6780/33250 (epoch 10.195), train_loss = 1.25556062, grad/param norm = 1.4143e-01, time/batch = 18.0009s	
6781/33250 (epoch 10.197), train_loss = 1.07408300, grad/param norm = 1.4428e-01, time/batch = 17.9214s	
6782/33250 (epoch 10.198), train_loss = 1.22060582, grad/param norm = 1.5720e-01, time/batch = 18.4964s	
6783/33250 (epoch 10.200), train_loss = 1.12176631, grad/param norm = 1.5619e-01, time/batch = 17.3644s	
6784/33250 (epoch 10.202), train_loss = 1.02731042, grad/param norm = 1.4722e-01, time/batch = 17.3411s	
6785/33250 (epoch 10.203), train_loss = 1.06813524, grad/param norm = 1.5281e-01, time/batch = 18.8562s	
6786/33250 (epoch 10.205), train_loss = 1.14765940, grad/param norm = 1.5836e-01, time/batch = 15.1697s	
6787/33250 (epoch 10.206), train_loss = 1.15917350, grad/param norm = 1.5689e-01, time/batch = 17.1135s	
6788/33250 (epoch 10.208), train_loss = 1.29402221, grad/param norm = 1.8692e-01, time/batch = 17.5977s	
6789/33250 (epoch 10.209), train_loss = 1.04021752, grad/param norm = 1.6119e-01, time/batch = 18.1686s	
6790/33250 (epoch 10.211), train_loss = 1.22615918, grad/param norm = 1.5347e-01, time/batch = 15.6728s	
6791/33250 (epoch 10.212), train_loss = 1.35893170, grad/param norm = 1.5494e-01, time/batch = 15.6842s	
6792/33250 (epoch 10.214), train_loss = 1.08697055, grad/param norm = 1.3123e-01, time/batch = 17.4544s	
6793/33250 (epoch 10.215), train_loss = 1.42378974, grad/param norm = 1.9842e-01, time/batch = 16.3830s	
6794/33250 (epoch 10.217), train_loss = 1.27582653, grad/param norm = 1.6768e-01, time/batch = 19.0294s	
6795/33250 (epoch 10.218), train_loss = 1.20043901, grad/param norm = 1.4842e-01, time/batch = 16.0392s	
6796/33250 (epoch 10.220), train_loss = 1.22632881, grad/param norm = 1.7110e-01, time/batch = 15.5042s	
6797/33250 (epoch 10.221), train_loss = 1.35840840, grad/param norm = 1.9009e-01, time/batch = 15.7541s	
6798/33250 (epoch 10.223), train_loss = 1.09695155, grad/param norm = 1.3774e-01, time/batch = 19.3300s	
6799/33250 (epoch 10.224), train_loss = 1.25202795, grad/param norm = 1.7952e-01, time/batch = 17.7592s	
6800/33250 (epoch 10.226), train_loss = 1.29844569, grad/param norm = 1.6312e-01, time/batch = 17.7535s	
6801/33250 (epoch 10.227), train_loss = 1.16308407, grad/param norm = 1.5793e-01, time/batch = 17.4213s	
6802/33250 (epoch 10.229), train_loss = 1.14889801, grad/param norm = 1.4395e-01, time/batch = 17.4529s	
6803/33250 (epoch 10.230), train_loss = 1.07009016, grad/param norm = 1.5763e-01, time/batch = 15.7793s	
6804/33250 (epoch 10.232), train_loss = 1.04944412, grad/param norm = 1.3947e-01, time/batch = 16.9673s	
6805/33250 (epoch 10.233), train_loss = 1.03981955, grad/param norm = 1.3486e-01, time/batch = 18.5138s	
6806/33250 (epoch 10.235), train_loss = 1.25587547, grad/param norm = 1.4928e-01, time/batch = 16.1127s	
6807/33250 (epoch 10.236), train_loss = 1.05097921, grad/param norm = 1.5765e-01, time/batch = 16.3300s	
6808/33250 (epoch 10.238), train_loss = 1.19392809, grad/param norm = 1.6013e-01, time/batch = 16.5886s	
6809/33250 (epoch 10.239), train_loss = 1.30697039, grad/param norm = 1.8906e-01, time/batch = 15.6085s	
6810/33250 (epoch 10.241), train_loss = 1.21408719, grad/param norm = 1.6506e-01, time/batch = 14.9410s	
6811/33250 (epoch 10.242), train_loss = 1.22486080, grad/param norm = 1.5932e-01, time/batch = 16.5997s	
6812/33250 (epoch 10.244), train_loss = 1.24920794, grad/param norm = 1.7458e-01, time/batch = 18.2887s	
6813/33250 (epoch 10.245), train_loss = 1.12825798, grad/param norm = 1.4254e-01, time/batch = 15.9549s	
6814/33250 (epoch 10.247), train_loss = 1.16369683, grad/param norm = 1.5734e-01, time/batch = 15.6158s	
6815/33250 (epoch 10.248), train_loss = 1.40013892, grad/param norm = 2.0292e-01, time/batch = 15.4316s	
6816/33250 (epoch 10.250), train_loss = 1.21482025, grad/param norm = 1.4359e-01, time/batch = 14.9512s	
6817/33250 (epoch 10.251), train_loss = 1.15118683, grad/param norm = 1.5082e-01, time/batch = 16.6075s	
6818/33250 (epoch 10.253), train_loss = 1.03057127, grad/param norm = 1.3749e-01, time/batch = 15.4447s	
6819/33250 (epoch 10.254), train_loss = 1.06877351, grad/param norm = 1.5355e-01, time/batch = 17.4342s	
6820/33250 (epoch 10.256), train_loss = 1.20167729, grad/param norm = 1.5651e-01, time/batch = 17.0094s	
6821/33250 (epoch 10.257), train_loss = 1.28008450, grad/param norm = 1.4895e-01, time/batch = 16.4954s	
6822/33250 (epoch 10.259), train_loss = 1.30371837, grad/param norm = 1.5891e-01, time/batch = 15.9330s	
6823/33250 (epoch 10.260), train_loss = 1.04273954, grad/param norm = 1.5777e-01, time/batch = 18.0331s	
6824/33250 (epoch 10.262), train_loss = 1.19308052, grad/param norm = 1.5270e-01, time/batch = 18.0444s	
6825/33250 (epoch 10.263), train_loss = 1.07124163, grad/param norm = 1.4533e-01, time/batch = 15.6153s	
6826/33250 (epoch 10.265), train_loss = 1.24259237, grad/param norm = 1.5454e-01, time/batch = 16.6142s	
6827/33250 (epoch 10.266), train_loss = 1.15201606, grad/param norm = 1.5998e-01, time/batch = 15.7672s	
6828/33250 (epoch 10.268), train_loss = 1.05493216, grad/param norm = 1.3597e-01, time/batch = 16.7714s	
6829/33250 (epoch 10.269), train_loss = 0.92783341, grad/param norm = 1.4033e-01, time/batch = 16.1909s	
6830/33250 (epoch 10.271), train_loss = 1.09185429, grad/param norm = 1.4064e-01, time/batch = 15.4957s	
6831/33250 (epoch 10.272), train_loss = 0.95997557, grad/param norm = 1.2403e-01, time/batch = 16.1758s	
6832/33250 (epoch 10.274), train_loss = 0.86755439, grad/param norm = 1.3630e-01, time/batch = 18.1088s	
6833/33250 (epoch 10.275), train_loss = 1.01828424, grad/param norm = 1.3063e-01, time/batch = 17.1280s	
6834/33250 (epoch 10.277), train_loss = 0.91503873, grad/param norm = 1.3733e-01, time/batch = 19.1137s	
6835/33250 (epoch 10.278), train_loss = 1.03680370, grad/param norm = 1.3362e-01, time/batch = 18.9491s	
6836/33250 (epoch 10.280), train_loss = 0.97720338, grad/param norm = 1.2956e-01, time/batch = 15.3489s	
6837/33250 (epoch 10.281), train_loss = 1.13699402, grad/param norm = 1.5353e-01, time/batch = 17.4271s	
6838/33250 (epoch 10.283), train_loss = 1.20086996, grad/param norm = 1.6243e-01, time/batch = 18.4197s	
6839/33250 (epoch 10.284), train_loss = 1.04058813, grad/param norm = 1.4818e-01, time/batch = 16.0949s	
6840/33250 (epoch 10.286), train_loss = 1.20768734, grad/param norm = 1.6538e-01, time/batch = 16.8468s	
6841/33250 (epoch 10.287), train_loss = 0.97606913, grad/param norm = 1.3165e-01, time/batch = 17.6810s	
6842/33250 (epoch 10.289), train_loss = 0.95162168, grad/param norm = 1.3896e-01, time/batch = 19.2143s	
6843/33250 (epoch 10.290), train_loss = 1.12637981, grad/param norm = 1.3806e-01, time/batch = 10.4696s	
6844/33250 (epoch 10.292), train_loss = 1.17003700, grad/param norm = 1.6675e-01, time/batch = 0.6616s	
6845/33250 (epoch 10.293), train_loss = 1.27996591, grad/param norm = 1.8318e-01, time/batch = 0.6721s	
6846/33250 (epoch 10.295), train_loss = 1.18314370, grad/param norm = 1.5717e-01, time/batch = 0.6845s	
6847/33250 (epoch 10.296), train_loss = 1.13562833, grad/param norm = 1.4350e-01, time/batch = 0.6835s	
6848/33250 (epoch 10.298), train_loss = 0.92843877, grad/param norm = 1.3493e-01, time/batch = 0.6682s	
6849/33250 (epoch 10.299), train_loss = 0.88349259, grad/param norm = 1.4352e-01, time/batch = 0.6639s	
6850/33250 (epoch 10.301), train_loss = 1.20418928, grad/param norm = 1.5510e-01, time/batch = 0.6572s	
6851/33250 (epoch 10.302), train_loss = 1.12195705, grad/param norm = 1.4108e-01, time/batch = 0.9299s	
6852/33250 (epoch 10.304), train_loss = 1.05457459, grad/param norm = 1.3164e-01, time/batch = 0.9580s	
6853/33250 (epoch 10.305), train_loss = 1.12237830, grad/param norm = 1.4701e-01, time/batch = 0.9753s	
6854/33250 (epoch 10.307), train_loss = 1.19689115, grad/param norm = 1.4658e-01, time/batch = 0.9746s	
6855/33250 (epoch 10.308), train_loss = 1.37106576, grad/param norm = 1.6762e-01, time/batch = 0.9724s	
6856/33250 (epoch 10.310), train_loss = 1.11640598, grad/param norm = 1.5093e-01, time/batch = 1.6352s	
6857/33250 (epoch 10.311), train_loss = 1.25946182, grad/param norm = 1.6438e-01, time/batch = 1.7853s	
6858/33250 (epoch 10.313), train_loss = 0.94750967, grad/param norm = 1.4907e-01, time/batch = 1.7768s	
6859/33250 (epoch 10.314), train_loss = 1.11107222, grad/param norm = 1.4971e-01, time/batch = 15.8520s	
6860/33250 (epoch 10.316), train_loss = 1.31031384, grad/param norm = 1.6323e-01, time/batch = 17.9978s	
6861/33250 (epoch 10.317), train_loss = 0.99614311, grad/param norm = 1.3402e-01, time/batch = 16.5118s	
6862/33250 (epoch 10.319), train_loss = 1.24308427, grad/param norm = 1.8088e-01, time/batch = 17.0305s	
6863/33250 (epoch 10.320), train_loss = 1.28785455, grad/param norm = 1.8597e-01, time/batch = 15.8589s	
6864/33250 (epoch 10.322), train_loss = 1.33027718, grad/param norm = 1.7819e-01, time/batch = 16.4844s	
6865/33250 (epoch 10.323), train_loss = 1.37314182, grad/param norm = 1.8575e-01, time/batch = 16.0776s	
6866/33250 (epoch 10.325), train_loss = 1.15237401, grad/param norm = 1.6525e-01, time/batch = 18.6045s	
6867/33250 (epoch 10.326), train_loss = 1.34000908, grad/param norm = 1.6351e-01, time/batch = 16.4417s	
6868/33250 (epoch 10.328), train_loss = 1.07215592, grad/param norm = 1.7091e-01, time/batch = 16.8692s	
6869/33250 (epoch 10.329), train_loss = 1.17280256, grad/param norm = 1.6218e-01, time/batch = 16.5284s	
6870/33250 (epoch 10.331), train_loss = 1.09554724, grad/param norm = 1.5147e-01, time/batch = 18.3535s	
6871/33250 (epoch 10.332), train_loss = 1.09072773, grad/param norm = 1.5192e-01, time/batch = 17.3437s	
6872/33250 (epoch 10.334), train_loss = 1.25201320, grad/param norm = 1.4582e-01, time/batch = 16.4298s	
6873/33250 (epoch 10.335), train_loss = 0.82433564, grad/param norm = 1.2982e-01, time/batch = 16.7640s	
6874/33250 (epoch 10.337), train_loss = 1.13237451, grad/param norm = 1.3964e-01, time/batch = 17.5986s	
6875/33250 (epoch 10.338), train_loss = 1.23965717, grad/param norm = 1.6214e-01, time/batch = 17.0794s	
6876/33250 (epoch 10.340), train_loss = 1.13183682, grad/param norm = 1.4636e-01, time/batch = 18.5172s	
6877/33250 (epoch 10.341), train_loss = 1.05715351, grad/param norm = 1.5598e-01, time/batch = 17.7018s	
6878/33250 (epoch 10.343), train_loss = 1.12773101, grad/param norm = 1.5527e-01, time/batch = 16.0360s	
6879/33250 (epoch 10.344), train_loss = 1.11328233, grad/param norm = 1.5633e-01, time/batch = 17.0356s	
6880/33250 (epoch 10.346), train_loss = 0.96660315, grad/param norm = 1.3432e-01, time/batch = 16.9329s	
6881/33250 (epoch 10.347), train_loss = 1.43203331, grad/param norm = 1.7387e-01, time/batch = 17.0797s	
6882/33250 (epoch 10.349), train_loss = 1.10611811, grad/param norm = 1.6395e-01, time/batch = 16.5958s	
6883/33250 (epoch 10.350), train_loss = 1.13822921, grad/param norm = 1.5669e-01, time/batch = 16.3668s	
6884/33250 (epoch 10.352), train_loss = 1.01738794, grad/param norm = 1.5117e-01, time/batch = 18.5908s	
6885/33250 (epoch 10.353), train_loss = 1.09867332, grad/param norm = 1.4855e-01, time/batch = 17.0204s	
6886/33250 (epoch 10.355), train_loss = 1.09663739, grad/param norm = 1.5464e-01, time/batch = 17.2552s	
6887/33250 (epoch 10.356), train_loss = 1.03726500, grad/param norm = 1.5638e-01, time/batch = 16.5411s	
6888/33250 (epoch 10.358), train_loss = 1.06372450, grad/param norm = 1.4352e-01, time/batch = 17.7569s	
6889/33250 (epoch 10.359), train_loss = 1.06342745, grad/param norm = 1.3654e-01, time/batch = 16.7740s	
6890/33250 (epoch 10.361), train_loss = 1.30649580, grad/param norm = 1.6382e-01, time/batch = 17.5148s	
6891/33250 (epoch 10.362), train_loss = 1.11892229, grad/param norm = 1.4574e-01, time/batch = 17.3459s	
6892/33250 (epoch 10.364), train_loss = 1.22450718, grad/param norm = 1.6105e-01, time/batch = 16.6694s	
6893/33250 (epoch 10.365), train_loss = 1.09950026, grad/param norm = 1.4477e-01, time/batch = 16.8407s	
6894/33250 (epoch 10.367), train_loss = 1.08613742, grad/param norm = 1.3777e-01, time/batch = 16.1080s	
6895/33250 (epoch 10.368), train_loss = 1.10754738, grad/param norm = 1.4642e-01, time/batch = 16.7816s	
6896/33250 (epoch 10.370), train_loss = 0.96756585, grad/param norm = 1.2911e-01, time/batch = 16.5041s	
6897/33250 (epoch 10.371), train_loss = 1.25195232, grad/param norm = 1.6395e-01, time/batch = 17.9518s	
6898/33250 (epoch 10.373), train_loss = 1.05900355, grad/param norm = 1.3637e-01, time/batch = 18.2084s	
6899/33250 (epoch 10.374), train_loss = 1.21830878, grad/param norm = 1.7188e-01, time/batch = 14.3194s	
6900/33250 (epoch 10.376), train_loss = 1.09362994, grad/param norm = 1.5198e-01, time/batch = 18.1788s	
6901/33250 (epoch 10.377), train_loss = 1.01410226, grad/param norm = 1.7389e-01, time/batch = 15.8369s	
6902/33250 (epoch 10.379), train_loss = 1.03524406, grad/param norm = 1.4865e-01, time/batch = 15.7504s	
6903/33250 (epoch 10.380), train_loss = 1.17694042, grad/param norm = 1.8401e-01, time/batch = 16.1080s	
6904/33250 (epoch 10.382), train_loss = 1.23730281, grad/param norm = 1.7910e-01, time/batch = 17.2714s	
6905/33250 (epoch 10.383), train_loss = 1.00877101, grad/param norm = 1.4987e-01, time/batch = 16.3572s	
6906/33250 (epoch 10.385), train_loss = 0.96391430, grad/param norm = 1.5056e-01, time/batch = 18.8358s	
6907/33250 (epoch 10.386), train_loss = 0.95963705, grad/param norm = 1.4276e-01, time/batch = 18.1030s	
6908/33250 (epoch 10.388), train_loss = 1.02797425, grad/param norm = 1.4820e-01, time/batch = 18.1936s	
6909/33250 (epoch 10.389), train_loss = 1.08861751, grad/param norm = 1.5887e-01, time/batch = 18.2103s	
6910/33250 (epoch 10.391), train_loss = 1.13150872, grad/param norm = 1.6327e-01, time/batch = 16.7407s	
6911/33250 (epoch 10.392), train_loss = 1.22637844, grad/param norm = 1.6793e-01, time/batch = 18.1694s	
6912/33250 (epoch 10.394), train_loss = 1.31344741, grad/param norm = 1.7886e-01, time/batch = 17.2675s	
6913/33250 (epoch 10.395), train_loss = 1.20314431, grad/param norm = 1.4205e-01, time/batch = 17.4183s	
6914/33250 (epoch 10.397), train_loss = 1.24705015, grad/param norm = 1.5774e-01, time/batch = 18.5748s	
6915/33250 (epoch 10.398), train_loss = 1.04068750, grad/param norm = 1.4568e-01, time/batch = 17.0846s	
6916/33250 (epoch 10.400), train_loss = 1.03993387, grad/param norm = 1.4719e-01, time/batch = 18.6927s	
6917/33250 (epoch 10.402), train_loss = 0.95047248, grad/param norm = 1.4323e-01, time/batch = 17.1997s	
6918/33250 (epoch 10.403), train_loss = 1.06541997, grad/param norm = 1.7446e-01, time/batch = 19.1250s	
6919/33250 (epoch 10.405), train_loss = 1.02386430, grad/param norm = 1.4826e-01, time/batch = 18.9408s	
6920/33250 (epoch 10.406), train_loss = 1.18923279, grad/param norm = 1.6560e-01, time/batch = 15.9312s	
6921/33250 (epoch 10.408), train_loss = 1.24967967, grad/param norm = 1.5942e-01, time/batch = 15.3466s	
6922/33250 (epoch 10.409), train_loss = 1.21447721, grad/param norm = 1.8353e-01, time/batch = 17.3508s	
6923/33250 (epoch 10.411), train_loss = 0.83382590, grad/param norm = 1.1936e-01, time/batch = 15.4271s	
6924/33250 (epoch 10.412), train_loss = 0.95644358, grad/param norm = 1.5092e-01, time/batch = 15.2388s	
6925/33250 (epoch 10.414), train_loss = 1.14837823, grad/param norm = 1.5618e-01, time/batch = 15.5024s	
6926/33250 (epoch 10.415), train_loss = 1.26026260, grad/param norm = 1.7140e-01, time/batch = 15.5298s	
6927/33250 (epoch 10.417), train_loss = 1.21329176, grad/param norm = 1.5802e-01, time/batch = 18.5194s	
6928/33250 (epoch 10.418), train_loss = 1.39125903, grad/param norm = 1.8263e-01, time/batch = 26.1885s	
6929/33250 (epoch 10.420), train_loss = 1.25977703, grad/param norm = 1.6121e-01, time/batch = 16.2463s	
6930/33250 (epoch 10.421), train_loss = 1.01797861, grad/param norm = 1.6055e-01, time/batch = 17.2619s	
6931/33250 (epoch 10.423), train_loss = 1.18534310, grad/param norm = 1.7505e-01, time/batch = 17.2554s	
6932/33250 (epoch 10.424), train_loss = 1.37746166, grad/param norm = 2.7509e-01, time/batch = 15.5188s	
6933/33250 (epoch 10.426), train_loss = 1.01863326, grad/param norm = 1.3531e-01, time/batch = 17.1800s	
6934/33250 (epoch 10.427), train_loss = 1.06277860, grad/param norm = 1.9050e-01, time/batch = 17.1695s	
6935/33250 (epoch 10.429), train_loss = 1.19348829, grad/param norm = 1.7707e-01, time/batch = 18.6295s	
6936/33250 (epoch 10.430), train_loss = 1.03171160, grad/param norm = 1.6352e-01, time/batch = 17.1330s	
6937/33250 (epoch 10.432), train_loss = 1.12055932, grad/param norm = 1.3999e-01, time/batch = 17.8648s	
6938/33250 (epoch 10.433), train_loss = 1.04695272, grad/param norm = 1.5173e-01, time/batch = 18.1913s	
6939/33250 (epoch 10.435), train_loss = 1.15056739, grad/param norm = 1.6367e-01, time/batch = 16.4296s	
6940/33250 (epoch 10.436), train_loss = 1.04652208, grad/param norm = 1.6049e-01, time/batch = 16.0183s	
6941/33250 (epoch 10.438), train_loss = 1.18442786, grad/param norm = 1.5255e-01, time/batch = 16.1670s	
6942/33250 (epoch 10.439), train_loss = 1.12532312, grad/param norm = 1.4431e-01, time/batch = 16.7593s	
6943/33250 (epoch 10.441), train_loss = 1.09273352, grad/param norm = 1.3894e-01, time/batch = 17.5989s	
6944/33250 (epoch 10.442), train_loss = 1.02260337, grad/param norm = 1.5237e-01, time/batch = 16.5150s	
6945/33250 (epoch 10.444), train_loss = 1.03580469, grad/param norm = 1.4996e-01, time/batch = 17.6213s	
6946/33250 (epoch 10.445), train_loss = 1.11739946, grad/param norm = 1.4745e-01, time/batch = 17.0168s	
6947/33250 (epoch 10.447), train_loss = 1.16195405, grad/param norm = 1.5314e-01, time/batch = 18.5356s	
6948/33250 (epoch 10.448), train_loss = 1.06760690, grad/param norm = 1.2907e-01, time/batch = 17.2718s	
6949/33250 (epoch 10.450), train_loss = 1.30168259, grad/param norm = 1.7424e-01, time/batch = 16.3558s	
6950/33250 (epoch 10.451), train_loss = 1.19268788, grad/param norm = 1.6394e-01, time/batch = 18.4163s	
6951/33250 (epoch 10.453), train_loss = 0.98380503, grad/param norm = 1.3960e-01, time/batch = 16.7565s	
6952/33250 (epoch 10.454), train_loss = 1.27304447, grad/param norm = 1.7002e-01, time/batch = 16.1765s	
6953/33250 (epoch 10.456), train_loss = 1.26912609, grad/param norm = 1.6578e-01, time/batch = 17.8511s	
6954/33250 (epoch 10.457), train_loss = 1.08707858, grad/param norm = 1.6293e-01, time/batch = 16.7394s	
6955/33250 (epoch 10.459), train_loss = 1.13276838, grad/param norm = 1.4770e-01, time/batch = 17.6891s	
6956/33250 (epoch 10.460), train_loss = 1.21606326, grad/param norm = 1.7513e-01, time/batch = 16.0531s	
6957/33250 (epoch 10.462), train_loss = 1.03365479, grad/param norm = 1.4351e-01, time/batch = 18.3611s	
6958/33250 (epoch 10.463), train_loss = 1.01099165, grad/param norm = 1.3273e-01, time/batch = 15.6075s	
6959/33250 (epoch 10.465), train_loss = 0.90296092, grad/param norm = 1.1408e-01, time/batch = 17.5874s	
6960/33250 (epoch 10.466), train_loss = 0.87677765, grad/param norm = 1.1246e-01, time/batch = 17.0980s	
6961/33250 (epoch 10.468), train_loss = 0.98539041, grad/param norm = 1.2965e-01, time/batch = 18.3236s	
6962/33250 (epoch 10.469), train_loss = 1.11924380, grad/param norm = 1.6186e-01, time/batch = 16.0918s	
6963/33250 (epoch 10.471), train_loss = 1.22040973, grad/param norm = 1.4438e-01, time/batch = 17.4212s	
6964/33250 (epoch 10.472), train_loss = 1.12067661, grad/param norm = 1.7241e-01, time/batch = 17.0193s	
6965/33250 (epoch 10.474), train_loss = 1.34501046, grad/param norm = 1.9338e-01, time/batch = 17.3777s	
6966/33250 (epoch 10.475), train_loss = 1.12331874, grad/param norm = 1.4392e-01, time/batch = 17.8748s	
6967/33250 (epoch 10.477), train_loss = 1.10423305, grad/param norm = 1.4437e-01, time/batch = 17.5381s	
6968/33250 (epoch 10.478), train_loss = 1.06796719, grad/param norm = 1.3706e-01, time/batch = 17.6002s	
6969/33250 (epoch 10.480), train_loss = 1.34677549, grad/param norm = 1.6910e-01, time/batch = 15.4358s	
6970/33250 (epoch 10.481), train_loss = 1.10237296, grad/param norm = 1.5333e-01, time/batch = 16.5129s	
6971/33250 (epoch 10.483), train_loss = 1.16798191, grad/param norm = 1.4123e-01, time/batch = 16.7593s	
6972/33250 (epoch 10.484), train_loss = 1.02409765, grad/param norm = 1.4317e-01, time/batch = 16.4282s	
6973/33250 (epoch 10.486), train_loss = 0.92687169, grad/param norm = 1.4082e-01, time/batch = 16.8587s	
6974/33250 (epoch 10.487), train_loss = 1.05361480, grad/param norm = 1.5811e-01, time/batch = 15.9311s	
6975/33250 (epoch 10.489), train_loss = 1.25650470, grad/param norm = 1.7920e-01, time/batch = 19.8467s	
6976/33250 (epoch 10.490), train_loss = 1.19666949, grad/param norm = 1.6465e-01, time/batch = 18.6262s	
6977/33250 (epoch 10.492), train_loss = 1.17413658, grad/param norm = 1.5604e-01, time/batch = 17.2030s	
6978/33250 (epoch 10.493), train_loss = 1.12413947, grad/param norm = 1.5698e-01, time/batch = 17.4251s	
6979/33250 (epoch 10.495), train_loss = 1.15265502, grad/param norm = 1.4783e-01, time/batch = 16.0932s	
6980/33250 (epoch 10.496), train_loss = 1.07596215, grad/param norm = 1.3961e-01, time/batch = 19.0695s	
6981/33250 (epoch 10.498), train_loss = 1.23302314, grad/param norm = 1.6439e-01, time/batch = 15.4285s	
6982/33250 (epoch 10.499), train_loss = 1.10323225, grad/param norm = 1.4506e-01, time/batch = 15.0295s	
6983/33250 (epoch 10.501), train_loss = 1.08003369, grad/param norm = 1.6797e-01, time/batch = 15.1850s	
6984/33250 (epoch 10.502), train_loss = 1.08293955, grad/param norm = 1.3654e-01, time/batch = 16.5855s	
6985/33250 (epoch 10.504), train_loss = 1.25316815, grad/param norm = 1.6809e-01, time/batch = 18.2828s	
6986/33250 (epoch 10.505), train_loss = 0.90936810, grad/param norm = 1.2327e-01, time/batch = 17.1703s	
6987/33250 (epoch 10.507), train_loss = 1.07741983, grad/param norm = 1.5971e-01, time/batch = 16.2153s	
6988/33250 (epoch 10.508), train_loss = 1.05340557, grad/param norm = 1.4138e-01, time/batch = 16.9299s	
6989/33250 (epoch 10.510), train_loss = 0.92715858, grad/param norm = 1.3644e-01, time/batch = 18.0091s	
6990/33250 (epoch 10.511), train_loss = 1.10607297, grad/param norm = 1.4429e-01, time/batch = 16.8539s	
6991/33250 (epoch 10.513), train_loss = 1.30472363, grad/param norm = 1.6747e-01, time/batch = 16.7534s	
6992/33250 (epoch 10.514), train_loss = 1.05542844, grad/param norm = 1.4193e-01, time/batch = 17.4412s	
6993/33250 (epoch 10.516), train_loss = 1.03661769, grad/param norm = 1.3992e-01, time/batch = 16.3465s	
6994/33250 (epoch 10.517), train_loss = 1.10957421, grad/param norm = 1.4868e-01, time/batch = 17.1197s	
6995/33250 (epoch 10.519), train_loss = 0.97732507, grad/param norm = 1.3020e-01, time/batch = 17.5194s	
6996/33250 (epoch 10.520), train_loss = 1.40370659, grad/param norm = 1.7579e-01, time/batch = 18.5141s	
6997/33250 (epoch 10.522), train_loss = 1.19381737, grad/param norm = 1.5477e-01, time/batch = 16.0092s	
6998/33250 (epoch 10.523), train_loss = 1.09263059, grad/param norm = 1.6113e-01, time/batch = 17.0155s	
6999/33250 (epoch 10.525), train_loss = 0.98186024, grad/param norm = 1.5044e-01, time/batch = 17.0149s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch10.53_1.4192.t7	
7000/33250 (epoch 10.526), train_loss = 0.98450029, grad/param norm = 1.4314e-01, time/batch = 16.3610s	
7001/33250 (epoch 10.528), train_loss = 1.34833683, grad/param norm = 1.7048e-01, time/batch = 17.1822s	
7002/33250 (epoch 10.529), train_loss = 1.03401924, grad/param norm = 1.4705e-01, time/batch = 17.4354s	
7003/33250 (epoch 10.531), train_loss = 0.96936377, grad/param norm = 1.3770e-01, time/batch = 16.0278s	
7004/33250 (epoch 10.532), train_loss = 1.20289136, grad/param norm = 1.5967e-01, time/batch = 16.7698s	
7005/33250 (epoch 10.534), train_loss = 1.00487233, grad/param norm = 1.3628e-01, time/batch = 16.5880s	
7006/33250 (epoch 10.535), train_loss = 1.09257710, grad/param norm = 1.4768e-01, time/batch = 15.6715s	
7007/33250 (epoch 10.537), train_loss = 1.19628842, grad/param norm = 1.4719e-01, time/batch = 15.9845s	
7008/33250 (epoch 10.538), train_loss = 1.20897760, grad/param norm = 1.5822e-01, time/batch = 16.8608s	
7009/33250 (epoch 10.540), train_loss = 1.27303456, grad/param norm = 1.4714e-01, time/batch = 18.1143s	
7010/33250 (epoch 10.541), train_loss = 1.25424503, grad/param norm = 1.5930e-01, time/batch = 15.8738s	
7011/33250 (epoch 10.543), train_loss = 1.20031385, grad/param norm = 1.5297e-01, time/batch = 16.2379s	
7012/33250 (epoch 10.544), train_loss = 1.06500994, grad/param norm = 1.4600e-01, time/batch = 15.0476s	
7013/33250 (epoch 10.546), train_loss = 1.11837967, grad/param norm = 1.8162e-01, time/batch = 15.9328s	
7014/33250 (epoch 10.547), train_loss = 1.05886530, grad/param norm = 1.5692e-01, time/batch = 17.4334s	
7015/33250 (epoch 10.549), train_loss = 1.18952647, grad/param norm = 1.5934e-01, time/batch = 15.9311s	
7016/33250 (epoch 10.550), train_loss = 1.08004339, grad/param norm = 1.5314e-01, time/batch = 19.5952s	
7017/33250 (epoch 10.552), train_loss = 1.15283003, grad/param norm = 1.5081e-01, time/batch = 17.7798s	
7018/33250 (epoch 10.553), train_loss = 1.06522467, grad/param norm = 1.5235e-01, time/batch = 18.1095s	
7019/33250 (epoch 10.555), train_loss = 1.11125498, grad/param norm = 1.3766e-01, time/batch = 17.8131s	
7020/33250 (epoch 10.556), train_loss = 1.26356907, grad/param norm = 1.7856e-01, time/batch = 16.1167s	
7021/33250 (epoch 10.558), train_loss = 1.22369040, grad/param norm = 1.5922e-01, time/batch = 17.6047s	
7022/33250 (epoch 10.559), train_loss = 1.01033806, grad/param norm = 1.4648e-01, time/batch = 16.1125s	
7023/33250 (epoch 10.561), train_loss = 1.06743642, grad/param norm = 1.5398e-01, time/batch = 17.0229s	
7024/33250 (epoch 10.562), train_loss = 1.28458412, grad/param norm = 1.6961e-01, time/batch = 16.9858s	
7025/33250 (epoch 10.564), train_loss = 1.35166065, grad/param norm = 1.7254e-01, time/batch = 15.4331s	
7026/33250 (epoch 10.565), train_loss = 1.29730182, grad/param norm = 1.6997e-01, time/batch = 17.3660s	
7027/33250 (epoch 10.567), train_loss = 1.24053524, grad/param norm = 1.5266e-01, time/batch = 17.6252s	
7028/33250 (epoch 10.568), train_loss = 1.11807146, grad/param norm = 1.5527e-01, time/batch = 18.4467s	
7029/33250 (epoch 10.570), train_loss = 1.25508495, grad/param norm = 1.6319e-01, time/batch = 16.6914s	
7030/33250 (epoch 10.571), train_loss = 1.33461049, grad/param norm = 1.6639e-01, time/batch = 16.5165s	
7031/33250 (epoch 10.573), train_loss = 1.18281201, grad/param norm = 1.5295e-01, time/batch = 16.1655s	
7032/33250 (epoch 10.574), train_loss = 1.02725061, grad/param norm = 1.4431e-01, time/batch = 17.9189s	
7033/33250 (epoch 10.576), train_loss = 1.16531577, grad/param norm = 1.4022e-01, time/batch = 18.7644s	
7034/33250 (epoch 10.577), train_loss = 1.10866093, grad/param norm = 1.4540e-01, time/batch = 16.0142s	
7035/33250 (epoch 10.579), train_loss = 1.00666535, grad/param norm = 1.4181e-01, time/batch = 18.1113s	
7036/33250 (epoch 10.580), train_loss = 1.04922281, grad/param norm = 1.3125e-01, time/batch = 17.9564s	
7037/33250 (epoch 10.582), train_loss = 1.09057914, grad/param norm = 1.4334e-01, time/batch = 18.1084s	
7038/33250 (epoch 10.583), train_loss = 1.14645334, grad/param norm = 1.4507e-01, time/batch = 19.4375s	
7039/33250 (epoch 10.585), train_loss = 1.22055723, grad/param norm = 1.5436e-01, time/batch = 17.5237s	
7040/33250 (epoch 10.586), train_loss = 1.08050079, grad/param norm = 1.7480e-01, time/batch = 15.4314s	
7041/33250 (epoch 10.588), train_loss = 1.12639729, grad/param norm = 1.3740e-01, time/batch = 16.2392s	
7042/33250 (epoch 10.589), train_loss = 1.19845956, grad/param norm = 1.6326e-01, time/batch = 18.6017s	
7043/33250 (epoch 10.591), train_loss = 1.20163729, grad/param norm = 1.8072e-01, time/batch = 16.4219s	
7044/33250 (epoch 10.592), train_loss = 1.14137115, grad/param norm = 1.4253e-01, time/batch = 16.0809s	
7045/33250 (epoch 10.594), train_loss = 1.32595955, grad/param norm = 1.7738e-01, time/batch = 17.7026s	
7046/33250 (epoch 10.595), train_loss = 1.22763458, grad/param norm = 1.6497e-01, time/batch = 17.5246s	
7047/33250 (epoch 10.597), train_loss = 0.98106604, grad/param norm = 1.3383e-01, time/batch = 18.9500s	
7048/33250 (epoch 10.598), train_loss = 1.13908167, grad/param norm = 1.5703e-01, time/batch = 17.4835s	
7049/33250 (epoch 10.600), train_loss = 1.13818252, grad/param norm = 1.8204e-01, time/batch = 25.2249s	
7050/33250 (epoch 10.602), train_loss = 1.17815591, grad/param norm = 1.7492e-01, time/batch = 18.8207s	
7051/33250 (epoch 10.603), train_loss = 1.16261316, grad/param norm = 1.5559e-01, time/batch = 18.3306s	
7052/33250 (epoch 10.605), train_loss = 1.14841879, grad/param norm = 1.6077e-01, time/batch = 17.4408s	
7053/33250 (epoch 10.606), train_loss = 1.18179846, grad/param norm = 1.5011e-01, time/batch = 16.4401s	
7054/33250 (epoch 10.608), train_loss = 1.13951956, grad/param norm = 1.4845e-01, time/batch = 17.2061s	
7055/33250 (epoch 10.609), train_loss = 1.01740798, grad/param norm = 1.5108e-01, time/batch = 17.8755s	
7056/33250 (epoch 10.611), train_loss = 1.19947366, grad/param norm = 1.4828e-01, time/batch = 16.3725s	
7057/33250 (epoch 10.612), train_loss = 1.16807872, grad/param norm = 1.5272e-01, time/batch = 17.7441s	
7058/33250 (epoch 10.614), train_loss = 1.38874747, grad/param norm = 1.8709e-01, time/batch = 16.4262s	
7059/33250 (epoch 10.615), train_loss = 1.25185787, grad/param norm = 1.6398e-01, time/batch = 16.2787s	
7060/33250 (epoch 10.617), train_loss = 1.52650682, grad/param norm = 1.9026e-01, time/batch = 15.9449s	
7061/33250 (epoch 10.618), train_loss = 1.46523828, grad/param norm = 2.0337e-01, time/batch = 17.0051s	
7062/33250 (epoch 10.620), train_loss = 1.28189050, grad/param norm = 1.7658e-01, time/batch = 17.8502s	
7063/33250 (epoch 10.621), train_loss = 1.09956626, grad/param norm = 1.4389e-01, time/batch = 16.8576s	
7064/33250 (epoch 10.623), train_loss = 1.06002737, grad/param norm = 1.4676e-01, time/batch = 17.8796s	
7065/33250 (epoch 10.624), train_loss = 1.12056915, grad/param norm = 1.6484e-01, time/batch = 16.3396s	
7066/33250 (epoch 10.626), train_loss = 1.09760285, grad/param norm = 1.6474e-01, time/batch = 18.3821s	
7067/33250 (epoch 10.627), train_loss = 1.05701000, grad/param norm = 1.4224e-01, time/batch = 17.1079s	
7068/33250 (epoch 10.629), train_loss = 1.16335744, grad/param norm = 1.8349e-01, time/batch = 15.4301s	
7069/33250 (epoch 10.630), train_loss = 1.09231250, grad/param norm = 1.6250e-01, time/batch = 17.5813s	
7070/33250 (epoch 10.632), train_loss = 0.93207289, grad/param norm = 1.2530e-01, time/batch = 17.0228s	
7071/33250 (epoch 10.633), train_loss = 1.19491020, grad/param norm = 1.5845e-01, time/batch = 17.9054s	
7072/33250 (epoch 10.635), train_loss = 1.01265815, grad/param norm = 1.4408e-01, time/batch = 16.5031s	
7073/33250 (epoch 10.636), train_loss = 1.02391301, grad/param norm = 1.3690e-01, time/batch = 19.0191s	
7074/33250 (epoch 10.638), train_loss = 1.07883600, grad/param norm = 1.4359e-01, time/batch = 17.6980s	
7075/33250 (epoch 10.639), train_loss = 0.98800471, grad/param norm = 1.4106e-01, time/batch = 16.2609s	
7076/33250 (epoch 10.641), train_loss = 1.01176918, grad/param norm = 1.3724e-01, time/batch = 18.7071s	
7077/33250 (epoch 10.642), train_loss = 0.95494214, grad/param norm = 1.4866e-01, time/batch = 15.2680s	
7078/33250 (epoch 10.644), train_loss = 0.85672760, grad/param norm = 1.2890e-01, time/batch = 17.7555s	
7079/33250 (epoch 10.645), train_loss = 1.23498352, grad/param norm = 1.6632e-01, time/batch = 16.7780s	
7080/33250 (epoch 10.647), train_loss = 0.98785416, grad/param norm = 1.4376e-01, time/batch = 17.5939s	
7081/33250 (epoch 10.648), train_loss = 1.08426191, grad/param norm = 1.5643e-01, time/batch = 17.2619s	
7082/33250 (epoch 10.650), train_loss = 1.25673911, grad/param norm = 1.6637e-01, time/batch = 16.4224s	
7083/33250 (epoch 10.651), train_loss = 1.13934722, grad/param norm = 1.6809e-01, time/batch = 19.6891s	
7084/33250 (epoch 10.653), train_loss = 1.00497331, grad/param norm = 1.4334e-01, time/batch = 16.0041s	
7085/33250 (epoch 10.654), train_loss = 1.04627676, grad/param norm = 1.3750e-01, time/batch = 17.5057s	
7086/33250 (epoch 10.656), train_loss = 1.18736588, grad/param norm = 1.5743e-01, time/batch = 18.4349s	
7087/33250 (epoch 10.657), train_loss = 0.89948530, grad/param norm = 1.4685e-01, time/batch = 16.8604s	
7088/33250 (epoch 10.659), train_loss = 1.09845724, grad/param norm = 1.5433e-01, time/batch = 19.0753s	
7089/33250 (epoch 10.660), train_loss = 1.11076687, grad/param norm = 1.6242e-01, time/batch = 17.0835s	
7090/33250 (epoch 10.662), train_loss = 1.14345745, grad/param norm = 1.4688e-01, time/batch = 17.7689s	
7091/33250 (epoch 10.663), train_loss = 1.04131116, grad/param norm = 1.4699e-01, time/batch = 17.2678s	
7092/33250 (epoch 10.665), train_loss = 1.18351807, grad/param norm = 1.6109e-01, time/batch = 15.7707s	
7093/33250 (epoch 10.666), train_loss = 1.07815699, grad/param norm = 1.5885e-01, time/batch = 19.7755s	
7094/33250 (epoch 10.668), train_loss = 1.29820301, grad/param norm = 1.6422e-01, time/batch = 15.6924s	
7095/33250 (epoch 10.669), train_loss = 1.17826827, grad/param norm = 1.5632e-01, time/batch = 16.9440s	
7096/33250 (epoch 10.671), train_loss = 1.07237536, grad/param norm = 1.6350e-01, time/batch = 15.7523s	
7097/33250 (epoch 10.672), train_loss = 1.25426414, grad/param norm = 1.6306e-01, time/batch = 16.0352s	
7098/33250 (epoch 10.674), train_loss = 1.06375723, grad/param norm = 1.4443e-01, time/batch = 17.1861s	
7099/33250 (epoch 10.675), train_loss = 1.10798069, grad/param norm = 1.4434e-01, time/batch = 16.6810s	
7100/33250 (epoch 10.677), train_loss = 1.24067877, grad/param norm = 1.6238e-01, time/batch = 16.1748s	
7101/33250 (epoch 10.678), train_loss = 1.15911708, grad/param norm = 1.6902e-01, time/batch = 15.7787s	
7102/33250 (epoch 10.680), train_loss = 1.22789967, grad/param norm = 1.5896e-01, time/batch = 18.6849s	
7103/33250 (epoch 10.681), train_loss = 0.97946466, grad/param norm = 1.3537e-01, time/batch = 16.0421s	
7104/33250 (epoch 10.683), train_loss = 1.07877989, grad/param norm = 1.5074e-01, time/batch = 19.5155s	
7105/33250 (epoch 10.684), train_loss = 1.01997328, grad/param norm = 1.6019e-01, time/batch = 17.8820s	
7106/33250 (epoch 10.686), train_loss = 1.02114142, grad/param norm = 1.5212e-01, time/batch = 16.0149s	
7107/33250 (epoch 10.687), train_loss = 1.06757033, grad/param norm = 1.4678e-01, time/batch = 17.4302s	
7108/33250 (epoch 10.689), train_loss = 1.05950365, grad/param norm = 1.5296e-01, time/batch = 16.0358s	
7109/33250 (epoch 10.690), train_loss = 1.17319147, grad/param norm = 1.5593e-01, time/batch = 18.2556s	
7110/33250 (epoch 10.692), train_loss = 1.12244143, grad/param norm = 1.5667e-01, time/batch = 16.9002s	
7111/33250 (epoch 10.693), train_loss = 1.14256660, grad/param norm = 1.3519e-01, time/batch = 17.8432s	
7112/33250 (epoch 10.695), train_loss = 1.16923912, grad/param norm = 1.5231e-01, time/batch = 17.2076s	
7113/33250 (epoch 10.696), train_loss = 1.12794057, grad/param norm = 1.3643e-01, time/batch = 17.8650s	
7114/33250 (epoch 10.698), train_loss = 1.03715268, grad/param norm = 1.4901e-01, time/batch = 17.1079s	
7115/33250 (epoch 10.699), train_loss = 1.34527070, grad/param norm = 1.6206e-01, time/batch = 15.6879s	
7116/33250 (epoch 10.701), train_loss = 1.07793031, grad/param norm = 1.4255e-01, time/batch = 16.7591s	
7117/33250 (epoch 10.702), train_loss = 1.12164980, grad/param norm = 1.6841e-01, time/batch = 16.1852s	
7118/33250 (epoch 10.704), train_loss = 1.32454116, grad/param norm = 1.7534e-01, time/batch = 17.5225s	
7119/33250 (epoch 10.705), train_loss = 1.00064402, grad/param norm = 1.3816e-01, time/batch = 17.5042s	
7120/33250 (epoch 10.707), train_loss = 0.92474155, grad/param norm = 1.3473e-01, time/batch = 15.4423s	
7121/33250 (epoch 10.708), train_loss = 1.20148351, grad/param norm = 1.5954e-01, time/batch = 17.9466s	
7122/33250 (epoch 10.710), train_loss = 1.19371013, grad/param norm = 1.5666e-01, time/batch = 15.4689s	
7123/33250 (epoch 10.711), train_loss = 1.09028388, grad/param norm = 1.6896e-01, time/batch = 15.2244s	
7124/33250 (epoch 10.713), train_loss = 1.20475682, grad/param norm = 1.6330e-01, time/batch = 16.8492s	
7125/33250 (epoch 10.714), train_loss = 1.12263037, grad/param norm = 1.5278e-01, time/batch = 16.1151s	
7126/33250 (epoch 10.716), train_loss = 1.23858594, grad/param norm = 1.6296e-01, time/batch = 17.5988s	
7127/33250 (epoch 10.717), train_loss = 1.04735858, grad/param norm = 1.3844e-01, time/batch = 20.0369s	
7128/33250 (epoch 10.719), train_loss = 1.10714561, grad/param norm = 1.4613e-01, time/batch = 25.4568s	
7129/33250 (epoch 10.720), train_loss = 1.35366829, grad/param norm = 1.5916e-01, time/batch = 15.5091s	
7130/33250 (epoch 10.722), train_loss = 1.00889877, grad/param norm = 1.3931e-01, time/batch = 15.1038s	
7131/33250 (epoch 10.723), train_loss = 0.91467167, grad/param norm = 1.2750e-01, time/batch = 16.0211s	
7132/33250 (epoch 10.725), train_loss = 0.96274592, grad/param norm = 1.2566e-01, time/batch = 15.3759s	
7133/33250 (epoch 10.726), train_loss = 1.06897758, grad/param norm = 1.3720e-01, time/batch = 18.7068s	
7134/33250 (epoch 10.728), train_loss = 1.17651672, grad/param norm = 1.5071e-01, time/batch = 16.6766s	
7135/33250 (epoch 10.729), train_loss = 1.28963547, grad/param norm = 1.6674e-01, time/batch = 16.4309s	
7136/33250 (epoch 10.731), train_loss = 1.06333489, grad/param norm = 1.5257e-01, time/batch = 15.9269s	
7137/33250 (epoch 10.732), train_loss = 1.00700888, grad/param norm = 1.4535e-01, time/batch = 18.4952s	
7138/33250 (epoch 10.734), train_loss = 1.14952245, grad/param norm = 1.5019e-01, time/batch = 15.2008s	
7139/33250 (epoch 10.735), train_loss = 1.13881691, grad/param norm = 1.5146e-01, time/batch = 16.9325s	
7140/33250 (epoch 10.737), train_loss = 1.12323593, grad/param norm = 1.3510e-01, time/batch = 16.5191s	
7141/33250 (epoch 10.738), train_loss = 1.11614576, grad/param norm = 1.5672e-01, time/batch = 17.3593s	
7142/33250 (epoch 10.740), train_loss = 1.25539784, grad/param norm = 1.5580e-01, time/batch = 17.1983s	
7143/33250 (epoch 10.741), train_loss = 1.19855641, grad/param norm = 1.5662e-01, time/batch = 16.6989s	
7144/33250 (epoch 10.743), train_loss = 1.08676427, grad/param norm = 1.4038e-01, time/batch = 16.8469s	
7145/33250 (epoch 10.744), train_loss = 1.11523854, grad/param norm = 1.5247e-01, time/batch = 15.3288s	
7146/33250 (epoch 10.746), train_loss = 1.10390633, grad/param norm = 1.4550e-01, time/batch = 17.4402s	
7147/33250 (epoch 10.747), train_loss = 1.06965915, grad/param norm = 1.5322e-01, time/batch = 15.5243s	
7148/33250 (epoch 10.749), train_loss = 1.26832813, grad/param norm = 1.8684e-01, time/batch = 16.1135s	
7149/33250 (epoch 10.750), train_loss = 1.17144697, grad/param norm = 1.5569e-01, time/batch = 16.5997s	
7150/33250 (epoch 10.752), train_loss = 1.02067400, grad/param norm = 1.4369e-01, time/batch = 16.9379s	
7151/33250 (epoch 10.753), train_loss = 1.10577145, grad/param norm = 1.4738e-01, time/batch = 19.0287s	
7152/33250 (epoch 10.755), train_loss = 1.08628899, grad/param norm = 1.5529e-01, time/batch = 17.2017s	
7153/33250 (epoch 10.756), train_loss = 1.20346912, grad/param norm = 1.5447e-01, time/batch = 16.6651s	
7154/33250 (epoch 10.758), train_loss = 1.24282904, grad/param norm = 1.5302e-01, time/batch = 17.4381s	
7155/33250 (epoch 10.759), train_loss = 1.03248923, grad/param norm = 1.4323e-01, time/batch = 15.7533s	
7156/33250 (epoch 10.761), train_loss = 1.06368355, grad/param norm = 1.4515e-01, time/batch = 15.5849s	
7157/33250 (epoch 10.762), train_loss = 1.22175139, grad/param norm = 1.5529e-01, time/batch = 16.1524s	
7158/33250 (epoch 10.764), train_loss = 1.06054738, grad/param norm = 1.7685e-01, time/batch = 17.1721s	
7159/33250 (epoch 10.765), train_loss = 1.15477268, grad/param norm = 1.5174e-01, time/batch = 16.6034s	
7160/33250 (epoch 10.767), train_loss = 0.93037445, grad/param norm = 1.5202e-01, time/batch = 16.2712s	
7161/33250 (epoch 10.768), train_loss = 0.99133011, grad/param norm = 1.5636e-01, time/batch = 18.6221s	
7162/33250 (epoch 10.770), train_loss = 1.19442233, grad/param norm = 1.6600e-01, time/batch = 18.0231s	
7163/33250 (epoch 10.771), train_loss = 1.17142658, grad/param norm = 1.5366e-01, time/batch = 18.7659s	
7164/33250 (epoch 10.773), train_loss = 1.08793291, grad/param norm = 1.7266e-01, time/batch = 16.2671s	
7165/33250 (epoch 10.774), train_loss = 0.95086689, grad/param norm = 1.5212e-01, time/batch = 17.0106s	
7166/33250 (epoch 10.776), train_loss = 1.06974080, grad/param norm = 1.4903e-01, time/batch = 15.4478s	
7167/33250 (epoch 10.777), train_loss = 1.22483579, grad/param norm = 1.9307e-01, time/batch = 17.5957s	
7168/33250 (epoch 10.779), train_loss = 1.07657030, grad/param norm = 1.5575e-01, time/batch = 15.3527s	
7169/33250 (epoch 10.780), train_loss = 1.32359718, grad/param norm = 1.7856e-01, time/batch = 17.3465s	
7170/33250 (epoch 10.782), train_loss = 1.15355737, grad/param norm = 1.3645e-01, time/batch = 19.1670s	
7171/33250 (epoch 10.783), train_loss = 0.91122257, grad/param norm = 1.3346e-01, time/batch = 18.6095s	
7172/33250 (epoch 10.785), train_loss = 1.00241422, grad/param norm = 1.4571e-01, time/batch = 18.7090s	
7173/33250 (epoch 10.786), train_loss = 1.17637509, grad/param norm = 1.5230e-01, time/batch = 16.2634s	
7174/33250 (epoch 10.788), train_loss = 1.19220919, grad/param norm = 1.4945e-01, time/batch = 16.5014s	
7175/33250 (epoch 10.789), train_loss = 1.24062376, grad/param norm = 1.7919e-01, time/batch = 18.7546s	
7176/33250 (epoch 10.791), train_loss = 1.29230642, grad/param norm = 1.5481e-01, time/batch = 15.4341s	
7177/33250 (epoch 10.792), train_loss = 1.36552124, grad/param norm = 1.6102e-01, time/batch = 17.5048s	
7178/33250 (epoch 10.794), train_loss = 1.10273320, grad/param norm = 1.5169e-01, time/batch = 17.1736s	
7179/33250 (epoch 10.795), train_loss = 1.19053905, grad/param norm = 1.5441e-01, time/batch = 17.8605s	
7180/33250 (epoch 10.797), train_loss = 1.24119979, grad/param norm = 1.7462e-01, time/batch = 15.5066s	
7181/33250 (epoch 10.798), train_loss = 1.14816548, grad/param norm = 1.6925e-01, time/batch = 17.2139s	
7182/33250 (epoch 10.800), train_loss = 1.19714277, grad/param norm = 1.5867e-01, time/batch = 16.5458s	
7183/33250 (epoch 10.802), train_loss = 1.06233891, grad/param norm = 1.4055e-01, time/batch = 16.6813s	
7184/33250 (epoch 10.803), train_loss = 1.09754016, grad/param norm = 1.4443e-01, time/batch = 15.2744s	
7185/33250 (epoch 10.805), train_loss = 1.18994459, grad/param norm = 1.6136e-01, time/batch = 16.5238s	
7186/33250 (epoch 10.806), train_loss = 1.17706752, grad/param norm = 1.4951e-01, time/batch = 16.3352s	
7187/33250 (epoch 10.808), train_loss = 1.09922726, grad/param norm = 1.4389e-01, time/batch = 16.0203s	
7188/33250 (epoch 10.809), train_loss = 1.00937057, grad/param norm = 1.5218e-01, time/batch = 15.0497s	
7189/33250 (epoch 10.811), train_loss = 1.02652735, grad/param norm = 1.4177e-01, time/batch = 14.7153s	
7190/33250 (epoch 10.812), train_loss = 1.19777036, grad/param norm = 1.5131e-01, time/batch = 18.4473s	
7191/33250 (epoch 10.814), train_loss = 1.12883791, grad/param norm = 1.5324e-01, time/batch = 17.2978s	
7192/33250 (epoch 10.815), train_loss = 1.20116649, grad/param norm = 1.5423e-01, time/batch = 17.6971s	
7193/33250 (epoch 10.817), train_loss = 1.11118540, grad/param norm = 1.4593e-01, time/batch = 19.1169s	
7194/33250 (epoch 10.818), train_loss = 1.04694548, grad/param norm = 1.5345e-01, time/batch = 16.4366s	
7195/33250 (epoch 10.820), train_loss = 1.13491500, grad/param norm = 1.5840e-01, time/batch = 16.9362s	
7196/33250 (epoch 10.821), train_loss = 1.06350624, grad/param norm = 1.3555e-01, time/batch = 16.5176s	
7197/33250 (epoch 10.823), train_loss = 1.43024140, grad/param norm = 1.7866e-01, time/batch = 18.5064s	
7198/33250 (epoch 10.824), train_loss = 1.10489268, grad/param norm = 1.5799e-01, time/batch = 16.0804s	
7199/33250 (epoch 10.826), train_loss = 1.15952569, grad/param norm = 1.5822e-01, time/batch = 17.0101s	
7200/33250 (epoch 10.827), train_loss = 0.88795436, grad/param norm = 1.3352e-01, time/batch = 16.6790s	
7201/33250 (epoch 10.829), train_loss = 1.13717722, grad/param norm = 1.7282e-01, time/batch = 17.5350s	
7202/33250 (epoch 10.830), train_loss = 1.25164962, grad/param norm = 1.7640e-01, time/batch = 17.5371s	
7203/33250 (epoch 10.832), train_loss = 1.11934224, grad/param norm = 1.4626e-01, time/batch = 17.8612s	
7204/33250 (epoch 10.833), train_loss = 1.18877945, grad/param norm = 1.6473e-01, time/batch = 17.5055s	
7205/33250 (epoch 10.835), train_loss = 1.09072333, grad/param norm = 1.8407e-01, time/batch = 16.5168s	
7206/33250 (epoch 10.836), train_loss = 1.11212074, grad/param norm = 1.3906e-01, time/batch = 16.1688s	
7207/33250 (epoch 10.838), train_loss = 1.08304523, grad/param norm = 1.5777e-01, time/batch = 17.5998s	
7208/33250 (epoch 10.839), train_loss = 1.06696500, grad/param norm = 1.6015e-01, time/batch = 15.8614s	
7209/33250 (epoch 10.841), train_loss = 0.99021671, grad/param norm = 1.2927e-01, time/batch = 18.8392s	
7210/33250 (epoch 10.842), train_loss = 1.31491765, grad/param norm = 1.5411e-01, time/batch = 17.5486s	
7211/33250 (epoch 10.844), train_loss = 1.26034010, grad/param norm = 1.7354e-01, time/batch = 17.6007s	
7212/33250 (epoch 10.845), train_loss = 1.37983494, grad/param norm = 1.7726e-01, time/batch = 15.7021s	
7213/33250 (epoch 10.847), train_loss = 1.30663817, grad/param norm = 1.6252e-01, time/batch = 18.1091s	
7214/33250 (epoch 10.848), train_loss = 1.46150220, grad/param norm = 1.8232e-01, time/batch = 19.3361s	
7215/33250 (epoch 10.850), train_loss = 1.24420768, grad/param norm = 1.5138e-01, time/batch = 16.0132s	
7216/33250 (epoch 10.851), train_loss = 1.04989183, grad/param norm = 1.5727e-01, time/batch = 17.5097s	
7217/33250 (epoch 10.853), train_loss = 1.20328250, grad/param norm = 3.0057e-01, time/batch = 15.6083s	
7218/33250 (epoch 10.854), train_loss = 1.04285608, grad/param norm = 1.5005e-01, time/batch = 16.7697s	
7219/33250 (epoch 10.856), train_loss = 1.08289095, grad/param norm = 1.7558e-01, time/batch = 17.9498s	
7220/33250 (epoch 10.857), train_loss = 0.94895220, grad/param norm = 1.3993e-01, time/batch = 18.9439s	
7221/33250 (epoch 10.859), train_loss = 0.96817505, grad/param norm = 1.3873e-01, time/batch = 16.5948s	
7222/33250 (epoch 10.860), train_loss = 1.12869404, grad/param norm = 1.3259e-01, time/batch = 16.7705s	
7223/33250 (epoch 10.862), train_loss = 1.01390564, grad/param norm = 1.3776e-01, time/batch = 16.8443s	
7224/33250 (epoch 10.863), train_loss = 1.05035141, grad/param norm = 1.4817e-01, time/batch = 17.5996s	
7225/33250 (epoch 10.865), train_loss = 1.17794562, grad/param norm = 1.5415e-01, time/batch = 17.1627s	
7226/33250 (epoch 10.866), train_loss = 1.07464852, grad/param norm = 1.5310e-01, time/batch = 18.4946s	
7227/33250 (epoch 10.868), train_loss = 1.30470627, grad/param norm = 1.9461e-01, time/batch = 18.0069s	
7228/33250 (epoch 10.869), train_loss = 1.21251304, grad/param norm = 1.6968e-01, time/batch = 15.0594s	
7229/33250 (epoch 10.871), train_loss = 0.91435818, grad/param norm = 1.3956e-01, time/batch = 15.6183s	
7230/33250 (epoch 10.872), train_loss = 1.16142144, grad/param norm = 1.7703e-01, time/batch = 17.5248s	
7231/33250 (epoch 10.874), train_loss = 1.01169075, grad/param norm = 1.4708e-01, time/batch = 17.3035s	
7232/33250 (epoch 10.875), train_loss = 1.02894467, grad/param norm = 1.6508e-01, time/batch = 16.5934s	
7233/33250 (epoch 10.877), train_loss = 1.21412939, grad/param norm = 1.6068e-01, time/batch = 15.7445s	
7234/33250 (epoch 10.878), train_loss = 1.16061182, grad/param norm = 1.5238e-01, time/batch = 17.0039s	
7235/33250 (epoch 10.880), train_loss = 1.12255631, grad/param norm = 1.6775e-01, time/batch = 16.5991s	
7236/33250 (epoch 10.881), train_loss = 1.34216259, grad/param norm = 1.7435e-01, time/batch = 15.9438s	
7237/33250 (epoch 10.883), train_loss = 1.13901311, grad/param norm = 1.6773e-01, time/batch = 17.4260s	
7238/33250 (epoch 10.884), train_loss = 1.14242687, grad/param norm = 1.7731e-01, time/batch = 18.2886s	
7239/33250 (epoch 10.886), train_loss = 1.03881240, grad/param norm = 1.4357e-01, time/batch = 17.9328s	
7240/33250 (epoch 10.887), train_loss = 1.09030075, grad/param norm = 1.4570e-01, time/batch = 14.9743s	
7241/33250 (epoch 10.889), train_loss = 1.05651861, grad/param norm = 1.3369e-01, time/batch = 19.3580s	
7242/33250 (epoch 10.890), train_loss = 0.93971112, grad/param norm = 1.2742e-01, time/batch = 17.9214s	
7243/33250 (epoch 10.892), train_loss = 1.20097200, grad/param norm = 1.4529e-01, time/batch = 16.0180s	
7244/33250 (epoch 10.893), train_loss = 1.22340423, grad/param norm = 1.6460e-01, time/batch = 16.2002s	
7245/33250 (epoch 10.895), train_loss = 1.09186257, grad/param norm = 1.5382e-01, time/batch = 16.8333s	
7246/33250 (epoch 10.896), train_loss = 1.21734312, grad/param norm = 1.6385e-01, time/batch = 16.3927s	
7247/33250 (epoch 10.898), train_loss = 1.09426735, grad/param norm = 1.5449e-01, time/batch = 15.9351s	
7248/33250 (epoch 10.899), train_loss = 1.03735078, grad/param norm = 1.3950e-01, time/batch = 17.7229s	
7249/33250 (epoch 10.901), train_loss = 0.96388166, grad/param norm = 1.3177e-01, time/batch = 18.1232s	
7250/33250 (epoch 10.902), train_loss = 1.08568553, grad/param norm = 1.4089e-01, time/batch = 16.4091s	
7251/33250 (epoch 10.904), train_loss = 1.04116932, grad/param norm = 1.3711e-01, time/batch = 16.9325s	
7252/33250 (epoch 10.905), train_loss = 1.04256967, grad/param norm = 1.4177e-01, time/batch = 15.6083s	
7253/33250 (epoch 10.907), train_loss = 1.02641243, grad/param norm = 1.4169e-01, time/batch = 18.0021s	
7254/33250 (epoch 10.908), train_loss = 1.12242697, grad/param norm = 1.3654e-01, time/batch = 19.5827s	
7255/33250 (epoch 10.910), train_loss = 1.20716411, grad/param norm = 1.5805e-01, time/batch = 16.7775s	
7256/33250 (epoch 10.911), train_loss = 0.93064629, grad/param norm = 1.3831e-01, time/batch = 18.7463s	
7257/33250 (epoch 10.913), train_loss = 1.06008139, grad/param norm = 1.3799e-01, time/batch = 16.6986s	
7258/33250 (epoch 10.914), train_loss = 0.93508303, grad/param norm = 1.5027e-01, time/batch = 18.2019s	
7259/33250 (epoch 10.916), train_loss = 1.02682996, grad/param norm = 1.2403e-01, time/batch = 16.3755s	
7260/33250 (epoch 10.917), train_loss = 1.03939160, grad/param norm = 1.3651e-01, time/batch = 17.2886s	
7261/33250 (epoch 10.919), train_loss = 1.05811388, grad/param norm = 1.5789e-01, time/batch = 18.5034s	
7262/33250 (epoch 10.920), train_loss = 1.15108901, grad/param norm = 1.6392e-01, time/batch = 15.2713s	
7263/33250 (epoch 10.922), train_loss = 1.14426931, grad/param norm = 1.6272e-01, time/batch = 18.9960s	
7264/33250 (epoch 10.923), train_loss = 1.10304846, grad/param norm = 1.5706e-01, time/batch = 15.9453s	
7265/33250 (epoch 10.925), train_loss = 1.04448599, grad/param norm = 1.4296e-01, time/batch = 16.8647s	
7266/33250 (epoch 10.926), train_loss = 1.05336604, grad/param norm = 1.4653e-01, time/batch = 16.3587s	
7267/33250 (epoch 10.928), train_loss = 1.09252920, grad/param norm = 1.5523e-01, time/batch = 17.7751s	
7268/33250 (epoch 10.929), train_loss = 0.87192581, grad/param norm = 1.1959e-01, time/batch = 17.5299s	
7269/33250 (epoch 10.931), train_loss = 1.16523228, grad/param norm = 1.5091e-01, time/batch = 15.8723s	
7270/33250 (epoch 10.932), train_loss = 1.15377217, grad/param norm = 1.7021e-01, time/batch = 17.2874s	
7271/33250 (epoch 10.934), train_loss = 1.02865886, grad/param norm = 1.2790e-01, time/batch = 15.5184s	
7272/33250 (epoch 10.935), train_loss = 1.05719270, grad/param norm = 1.6100e-01, time/batch = 17.5768s	
7273/33250 (epoch 10.937), train_loss = 1.15625921, grad/param norm = 1.6892e-01, time/batch = 18.0054s	
7274/33250 (epoch 10.938), train_loss = 1.16302412, grad/param norm = 1.5314e-01, time/batch = 17.4996s	
7275/33250 (epoch 10.940), train_loss = 1.09213868, grad/param norm = 1.6589e-01, time/batch = 18.0225s	
7276/33250 (epoch 10.941), train_loss = 1.14381645, grad/param norm = 1.6773e-01, time/batch = 16.0847s	
7277/33250 (epoch 10.943), train_loss = 1.30274800, grad/param norm = 1.5626e-01, time/batch = 19.8645s	
7278/33250 (epoch 10.944), train_loss = 1.00217220, grad/param norm = 1.3221e-01, time/batch = 17.6264s	
7279/33250 (epoch 10.946), train_loss = 1.28119027, grad/param norm = 1.5554e-01, time/batch = 18.4473s	
7280/33250 (epoch 10.947), train_loss = 1.02662485, grad/param norm = 1.5285e-01, time/batch = 19.2633s	
7281/33250 (epoch 10.949), train_loss = 1.24203208, grad/param norm = 1.4859e-01, time/batch = 15.6827s	
7282/33250 (epoch 10.950), train_loss = 1.16091122, grad/param norm = 1.4749e-01, time/batch = 17.0202s	
7283/33250 (epoch 10.952), train_loss = 1.07492903, grad/param norm = 1.5654e-01, time/batch = 16.8678s	
7284/33250 (epoch 10.953), train_loss = 1.21099281, grad/param norm = 1.5840e-01, time/batch = 18.2222s	
7285/33250 (epoch 10.955), train_loss = 1.21254681, grad/param norm = 1.4983e-01, time/batch = 15.7710s	
7286/33250 (epoch 10.956), train_loss = 1.21453265, grad/param norm = 1.7932e-01, time/batch = 16.7709s	
7287/33250 (epoch 10.958), train_loss = 1.01806010, grad/param norm = 1.4972e-01, time/batch = 15.9291s	
7288/33250 (epoch 10.959), train_loss = 1.03530492, grad/param norm = 1.3962e-01, time/batch = 16.7678s	
7289/33250 (epoch 10.961), train_loss = 1.30113734, grad/param norm = 1.5518e-01, time/batch = 17.6260s	
7290/33250 (epoch 10.962), train_loss = 1.15891472, grad/param norm = 1.4896e-01, time/batch = 17.0564s	
7291/33250 (epoch 10.964), train_loss = 1.31275076, grad/param norm = 1.7151e-01, time/batch = 16.7399s	
7292/33250 (epoch 10.965), train_loss = 1.18781228, grad/param norm = 1.9562e-01, time/batch = 15.1947s	
7293/33250 (epoch 10.967), train_loss = 1.13487311, grad/param norm = 1.6918e-01, time/batch = 15.4312s	
7294/33250 (epoch 10.968), train_loss = 1.35809806, grad/param norm = 1.4574e-01, time/batch = 17.0305s	
7295/33250 (epoch 10.970), train_loss = 1.43763321, grad/param norm = 1.9069e-01, time/batch = 17.0859s	
7296/33250 (epoch 10.971), train_loss = 1.27820052, grad/param norm = 1.7748e-01, time/batch = 16.7605s	
7297/33250 (epoch 10.973), train_loss = 1.06509787, grad/param norm = 1.4502e-01, time/batch = 18.1144s	
7298/33250 (epoch 10.974), train_loss = 1.17206047, grad/param norm = 1.6097e-01, time/batch = 17.8713s	
7299/33250 (epoch 10.976), train_loss = 1.10671538, grad/param norm = 1.7016e-01, time/batch = 17.5201s	
7300/33250 (epoch 10.977), train_loss = 1.04911695, grad/param norm = 1.5523e-01, time/batch = 16.2038s	
7301/33250 (epoch 10.979), train_loss = 1.13314009, grad/param norm = 1.5722e-01, time/batch = 18.0900s	
7302/33250 (epoch 10.980), train_loss = 1.11865695, grad/param norm = 1.3496e-01, time/batch = 16.6719s	
7303/33250 (epoch 10.982), train_loss = 0.94066902, grad/param norm = 1.2686e-01, time/batch = 15.7599s	
7304/33250 (epoch 10.983), train_loss = 1.16673559, grad/param norm = 1.6839e-01, time/batch = 15.1074s	
7305/33250 (epoch 10.985), train_loss = 1.04650402, grad/param norm = 1.6366e-01, time/batch = 16.4355s	
7306/33250 (epoch 10.986), train_loss = 1.22875013, grad/param norm = 1.8313e-01, time/batch = 16.3654s	
7307/33250 (epoch 10.988), train_loss = 1.24439181, grad/param norm = 1.7278e-01, time/batch = 17.2019s	
7308/33250 (epoch 10.989), train_loss = 1.24065457, grad/param norm = 1.6371e-01, time/batch = 19.3682s	
7309/33250 (epoch 10.991), train_loss = 1.13818639, grad/param norm = 1.6474e-01, time/batch = 16.6242s	
7310/33250 (epoch 10.992), train_loss = 1.11775038, grad/param norm = 1.5638e-01, time/batch = 17.5892s	
7311/33250 (epoch 10.994), train_loss = 1.04528035, grad/param norm = 1.5506e-01, time/batch = 16.5275s	
7312/33250 (epoch 10.995), train_loss = 1.15545911, grad/param norm = 1.8355e-01, time/batch = 17.1635s	
7313/33250 (epoch 10.997), train_loss = 0.82445145, grad/param norm = 1.3610e-01, time/batch = 15.5896s	
7314/33250 (epoch 10.998), train_loss = 1.10570217, grad/param norm = 1.3550e-01, time/batch = 17.0142s	
decayed learning rate by a factor 0.97 to 0.0018818	
7315/33250 (epoch 11.000), train_loss = 1.12313245, grad/param norm = 1.4599e-01, time/batch = 18.3433s	
7316/33250 (epoch 11.002), train_loss = 1.29822857, grad/param norm = 1.7201e-01, time/batch = 16.8720s	
7317/33250 (epoch 11.003), train_loss = 1.18926124, grad/param norm = 1.4679e-01, time/batch = 19.6048s	
7318/33250 (epoch 11.005), train_loss = 0.90219067, grad/param norm = 1.3352e-01, time/batch = 16.4434s	
7319/33250 (epoch 11.006), train_loss = 0.96583931, grad/param norm = 1.3838e-01, time/batch = 18.0922s	
7320/33250 (epoch 11.008), train_loss = 1.28468793, grad/param norm = 1.5855e-01, time/batch = 16.7670s	
7321/33250 (epoch 11.009), train_loss = 1.25695294, grad/param norm = 1.6647e-01, time/batch = 17.1049s	
7322/33250 (epoch 11.011), train_loss = 1.00157690, grad/param norm = 1.4134e-01, time/batch = 16.2502s	
7323/33250 (epoch 11.012), train_loss = 1.15065164, grad/param norm = 1.8183e-01, time/batch = 15.5313s	
7324/33250 (epoch 11.014), train_loss = 1.25049317, grad/param norm = 1.6539e-01, time/batch = 17.4364s	
7325/33250 (epoch 11.015), train_loss = 1.11875191, grad/param norm = 1.4752e-01, time/batch = 15.5176s	
7326/33250 (epoch 11.017), train_loss = 1.15598974, grad/param norm = 1.6928e-01, time/batch = 18.6212s	
7327/33250 (epoch 11.018), train_loss = 0.92289034, grad/param norm = 1.4001e-01, time/batch = 18.2006s	
7328/33250 (epoch 11.020), train_loss = 1.06411070, grad/param norm = 1.4092e-01, time/batch = 19.4326s	
7329/33250 (epoch 11.021), train_loss = 1.09794303, grad/param norm = 1.4848e-01, time/batch = 16.4440s	
7330/33250 (epoch 11.023), train_loss = 0.92397378, grad/param norm = 1.4127e-01, time/batch = 16.2534s	
7331/33250 (epoch 11.024), train_loss = 1.19735692, grad/param norm = 1.5804e-01, time/batch = 15.8288s	
7332/33250 (epoch 11.026), train_loss = 1.09907806, grad/param norm = 1.4003e-01, time/batch = 16.8570s	
7333/33250 (epoch 11.027), train_loss = 1.10145456, grad/param norm = 1.4315e-01, time/batch = 18.3386s	
7334/33250 (epoch 11.029), train_loss = 1.12324740, grad/param norm = 1.4391e-01, time/batch = 15.4345s	
7335/33250 (epoch 11.030), train_loss = 1.10861289, grad/param norm = 1.6508e-01, time/batch = 16.5202s	
7336/33250 (epoch 11.032), train_loss = 1.36487075, grad/param norm = 1.8965e-01, time/batch = 19.2750s	
7337/33250 (epoch 11.033), train_loss = 1.05824547, grad/param norm = 1.4456e-01, time/batch = 30.3600s	
7338/33250 (epoch 11.035), train_loss = 1.05622850, grad/param norm = 1.5039e-01, time/batch = 18.5765s	
7339/33250 (epoch 11.036), train_loss = 1.19591909, grad/param norm = 1.6152e-01, time/batch = 18.2595s	
7340/33250 (epoch 11.038), train_loss = 1.06571382, grad/param norm = 1.4503e-01, time/batch = 17.0928s	
7341/33250 (epoch 11.039), train_loss = 0.99061670, grad/param norm = 1.3931e-01, time/batch = 17.7452s	
7342/33250 (epoch 11.041), train_loss = 1.13065551, grad/param norm = 1.5598e-01, time/batch = 16.9391s	
7343/33250 (epoch 11.042), train_loss = 0.94980032, grad/param norm = 1.3231e-01, time/batch = 16.0881s	
7344/33250 (epoch 11.044), train_loss = 1.26871273, grad/param norm = 1.6819e-01, time/batch = 18.4292s	
7345/33250 (epoch 11.045), train_loss = 1.22189317, grad/param norm = 1.5197e-01, time/batch = 16.7657s	
7346/33250 (epoch 11.047), train_loss = 1.19481929, grad/param norm = 1.6504e-01, time/batch = 17.1091s	
7347/33250 (epoch 11.048), train_loss = 1.29424648, grad/param norm = 1.7864e-01, time/batch = 17.4541s	
7348/33250 (epoch 11.050), train_loss = 1.10521480, grad/param norm = 1.4694e-01, time/batch = 18.1851s	
7349/33250 (epoch 11.051), train_loss = 1.10146577, grad/param norm = 1.4243e-01, time/batch = 16.7616s	
7350/33250 (epoch 11.053), train_loss = 1.16419962, grad/param norm = 1.6181e-01, time/batch = 15.7713s	
7351/33250 (epoch 11.054), train_loss = 0.94072768, grad/param norm = 1.2955e-01, time/batch = 18.1707s	
7352/33250 (epoch 11.056), train_loss = 0.98953304, grad/param norm = 1.4114e-01, time/batch = 18.1735s	
7353/33250 (epoch 11.057), train_loss = 1.14736917, grad/param norm = 1.3738e-01, time/batch = 15.4215s	
7354/33250 (epoch 11.059), train_loss = 1.06871166, grad/param norm = 1.4094e-01, time/batch = 17.8507s	
7355/33250 (epoch 11.060), train_loss = 1.19511546, grad/param norm = 1.7288e-01, time/batch = 17.8792s	
7356/33250 (epoch 11.062), train_loss = 1.26999856, grad/param norm = 1.5403e-01, time/batch = 17.6860s	
7357/33250 (epoch 11.063), train_loss = 1.25275702, grad/param norm = 1.5451e-01, time/batch = 16.7034s	
7358/33250 (epoch 11.065), train_loss = 1.09363465, grad/param norm = 1.4380e-01, time/batch = 18.0114s	
7359/33250 (epoch 11.066), train_loss = 1.17958221, grad/param norm = 1.4910e-01, time/batch = 16.5258s	
7360/33250 (epoch 11.068), train_loss = 1.08691006, grad/param norm = 1.4966e-01, time/batch = 16.8448s	
7361/33250 (epoch 11.069), train_loss = 1.11250099, grad/param norm = 1.4444e-01, time/batch = 17.5025s	
7362/33250 (epoch 11.071), train_loss = 0.99459106, grad/param norm = 1.4984e-01, time/batch = 16.0997s	
7363/33250 (epoch 11.072), train_loss = 0.99344924, grad/param norm = 1.2742e-01, time/batch = 18.8412s	
7364/33250 (epoch 11.074), train_loss = 1.15401640, grad/param norm = 1.4716e-01, time/batch = 17.5109s	
7365/33250 (epoch 11.075), train_loss = 1.00930565, grad/param norm = 1.3208e-01, time/batch = 18.9408s	
7366/33250 (epoch 11.077), train_loss = 1.09968851, grad/param norm = 1.6433e-01, time/batch = 17.6344s	
7367/33250 (epoch 11.078), train_loss = 1.08514293, grad/param norm = 1.4537e-01, time/batch = 16.6785s	
7368/33250 (epoch 11.080), train_loss = 1.17471355, grad/param norm = 1.8262e-01, time/batch = 18.4145s	
7369/33250 (epoch 11.081), train_loss = 1.17334545, grad/param norm = 1.5761e-01, time/batch = 16.9381s	
7370/33250 (epoch 11.083), train_loss = 1.20424678, grad/param norm = 1.4416e-01, time/batch = 18.6604s	
7371/33250 (epoch 11.084), train_loss = 1.11138109, grad/param norm = 1.5123e-01, time/batch = 16.7586s	
7372/33250 (epoch 11.086), train_loss = 1.05314302, grad/param norm = 1.3932e-01, time/batch = 16.5971s	
7373/33250 (epoch 11.087), train_loss = 0.97029212, grad/param norm = 1.4453e-01, time/batch = 18.5758s	
7374/33250 (epoch 11.089), train_loss = 1.14399432, grad/param norm = 1.5185e-01, time/batch = 16.7160s	
7375/33250 (epoch 11.090), train_loss = 1.08779237, grad/param norm = 1.4772e-01, time/batch = 20.1816s	
7376/33250 (epoch 11.092), train_loss = 1.01199101, grad/param norm = 1.3226e-01, time/batch = 17.4511s	
7377/33250 (epoch 11.093), train_loss = 1.13160893, grad/param norm = 1.4371e-01, time/batch = 15.1993s	
7378/33250 (epoch 11.095), train_loss = 1.07186430, grad/param norm = 1.4841e-01, time/batch = 17.5064s	
7379/33250 (epoch 11.096), train_loss = 0.93096770, grad/param norm = 1.4556e-01, time/batch = 15.1803s	
7380/33250 (epoch 11.098), train_loss = 1.00671664, grad/param norm = 1.5730e-01, time/batch = 17.3436s	
7381/33250 (epoch 11.099), train_loss = 0.83263060, grad/param norm = 1.2935e-01, time/batch = 15.5194s	
7382/33250 (epoch 11.101), train_loss = 1.07284768, grad/param norm = 1.4704e-01, time/batch = 17.5937s	
7383/33250 (epoch 11.102), train_loss = 1.00050984, grad/param norm = 1.4293e-01, time/batch = 17.4603s	
7384/33250 (epoch 11.104), train_loss = 0.89535086, grad/param norm = 1.3292e-01, time/batch = 18.1104s	
7385/33250 (epoch 11.105), train_loss = 1.01789829, grad/param norm = 1.3887e-01, time/batch = 18.0354s	
7386/33250 (epoch 11.107), train_loss = 0.91078403, grad/param norm = 1.3709e-01, time/batch = 17.5930s	
7387/33250 (epoch 11.108), train_loss = 1.09949911, grad/param norm = 1.5228e-01, time/batch = 17.6102s	
7388/33250 (epoch 11.110), train_loss = 0.87428325, grad/param norm = 1.2617e-01, time/batch = 16.7286s	
7389/33250 (epoch 11.111), train_loss = 1.06611258, grad/param norm = 1.4727e-01, time/batch = 15.5269s	
7390/33250 (epoch 11.113), train_loss = 1.08863538, grad/param norm = 1.5204e-01, time/batch = 15.5142s	
7391/33250 (epoch 11.114), train_loss = 0.99537595, grad/param norm = 1.4574e-01, time/batch = 17.0059s	
7392/33250 (epoch 11.116), train_loss = 1.12123437, grad/param norm = 1.4837e-01, time/batch = 19.1671s	
7393/33250 (epoch 11.117), train_loss = 1.07487508, grad/param norm = 1.4331e-01, time/batch = 18.3531s	
7394/33250 (epoch 11.119), train_loss = 1.02521860, grad/param norm = 1.3989e-01, time/batch = 19.6218s	
7395/33250 (epoch 11.120), train_loss = 0.84562966, grad/param norm = 1.2803e-01, time/batch = 17.8633s	
7396/33250 (epoch 11.122), train_loss = 1.22469912, grad/param norm = 1.5027e-01, time/batch = 18.1772s	
7397/33250 (epoch 11.123), train_loss = 1.13702179, grad/param norm = 1.5484e-01, time/batch = 17.5100s	
7398/33250 (epoch 11.125), train_loss = 0.91241080, grad/param norm = 1.3697e-01, time/batch = 16.0108s	
7399/33250 (epoch 11.126), train_loss = 1.08279084, grad/param norm = 1.5502e-01, time/batch = 18.4202s	
7400/33250 (epoch 11.128), train_loss = 1.00172351, grad/param norm = 1.3468e-01, time/batch = 18.0878s	
7401/33250 (epoch 11.129), train_loss = 1.07293482, grad/param norm = 1.4691e-01, time/batch = 16.8412s	
7402/33250 (epoch 11.131), train_loss = 1.08136577, grad/param norm = 1.5189e-01, time/batch = 16.6972s	
7403/33250 (epoch 11.132), train_loss = 1.07541500, grad/param norm = 1.6215e-01, time/batch = 18.7044s	
7404/33250 (epoch 11.134), train_loss = 1.08515623, grad/param norm = 1.4339e-01, time/batch = 18.0322s	
7405/33250 (epoch 11.135), train_loss = 1.13268557, grad/param norm = 1.4260e-01, time/batch = 17.5005s	
7406/33250 (epoch 11.137), train_loss = 0.98948402, grad/param norm = 1.4798e-01, time/batch = 17.7620s	
7407/33250 (epoch 11.138), train_loss = 1.02242468, grad/param norm = 1.2376e-01, time/batch = 16.5807s	
7408/33250 (epoch 11.140), train_loss = 0.84718698, grad/param norm = 1.2384e-01, time/batch = 15.6774s	
7409/33250 (epoch 11.141), train_loss = 1.36753662, grad/param norm = 1.8718e-01, time/batch = 15.7578s	
7410/33250 (epoch 11.143), train_loss = 0.85645709, grad/param norm = 1.4815e-01, time/batch = 15.1955s	
7411/33250 (epoch 11.144), train_loss = 1.02750225, grad/param norm = 1.3543e-01, time/batch = 18.5950s	
7412/33250 (epoch 11.146), train_loss = 1.00556991, grad/param norm = 1.3527e-01, time/batch = 17.0144s	
7413/33250 (epoch 11.147), train_loss = 1.00445210, grad/param norm = 1.4900e-01, time/batch = 16.8773s	
7414/33250 (epoch 11.149), train_loss = 1.04562210, grad/param norm = 1.4752e-01, time/batch = 19.7730s	
7415/33250 (epoch 11.150), train_loss = 0.99040457, grad/param norm = 1.5341e-01, time/batch = 17.2502s	
7416/33250 (epoch 11.152), train_loss = 0.93369723, grad/param norm = 1.4041e-01, time/batch = 17.0092s	
7417/33250 (epoch 11.153), train_loss = 1.27107020, grad/param norm = 1.6696e-01, time/batch = 17.8434s	
7418/33250 (epoch 11.155), train_loss = 1.11219581, grad/param norm = 1.7266e-01, time/batch = 17.1006s	
7419/33250 (epoch 11.156), train_loss = 1.29085409, grad/param norm = 1.5590e-01, time/batch = 16.9953s	
7420/33250 (epoch 11.158), train_loss = 1.32620777, grad/param norm = 1.7206e-01, time/batch = 18.4969s	
7421/33250 (epoch 11.159), train_loss = 1.10135424, grad/param norm = 1.5484e-01, time/batch = 18.0210s	
7422/33250 (epoch 11.161), train_loss = 1.14420138, grad/param norm = 1.5598e-01, time/batch = 16.4359s	
7423/33250 (epoch 11.162), train_loss = 0.98153749, grad/param norm = 1.4106e-01, time/batch = 20.8445s	
7424/33250 (epoch 11.164), train_loss = 1.11805969, grad/param norm = 1.5890e-01, time/batch = 15.6929s	
7425/33250 (epoch 11.165), train_loss = 1.18154659, grad/param norm = 1.6515e-01, time/batch = 17.9993s	
7426/33250 (epoch 11.167), train_loss = 1.21212159, grad/param norm = 1.5626e-01, time/batch = 15.6662s	
7427/33250 (epoch 11.168), train_loss = 0.92581116, grad/param norm = 1.2280e-01, time/batch = 17.4326s	
7428/33250 (epoch 11.170), train_loss = 1.05398917, grad/param norm = 1.4944e-01, time/batch = 18.0898s	
7429/33250 (epoch 11.171), train_loss = 1.05148062, grad/param norm = 1.4076e-01, time/batch = 16.6724s	
7430/33250 (epoch 11.173), train_loss = 1.03679349, grad/param norm = 1.4314e-01, time/batch = 17.1069s	
7431/33250 (epoch 11.174), train_loss = 1.06816226, grad/param norm = 1.4182e-01, time/batch = 17.4583s	
7432/33250 (epoch 11.176), train_loss = 1.10282714, grad/param norm = 1.4925e-01, time/batch = 18.1956s	
7433/33250 (epoch 11.177), train_loss = 1.01112160, grad/param norm = 1.2988e-01, time/batch = 16.7030s	
7434/33250 (epoch 11.179), train_loss = 1.00866707, grad/param norm = 1.5004e-01, time/batch = 17.7557s	
7435/33250 (epoch 11.180), train_loss = 0.92367690, grad/param norm = 1.3363e-01, time/batch = 18.4061s	
7436/33250 (epoch 11.182), train_loss = 1.01975738, grad/param norm = 1.7037e-01, time/batch = 16.9297s	
7437/33250 (epoch 11.183), train_loss = 1.23564857, grad/param norm = 1.6258e-01, time/batch = 16.1169s	
7438/33250 (epoch 11.185), train_loss = 1.18910203, grad/param norm = 1.8280e-01, time/batch = 16.2012s	
7439/33250 (epoch 11.186), train_loss = 1.09355398, grad/param norm = 1.4701e-01, time/batch = 16.4264s	
7440/33250 (epoch 11.188), train_loss = 1.21135722, grad/param norm = 1.8091e-01, time/batch = 15.4566s	
7441/33250 (epoch 11.189), train_loss = 0.91788987, grad/param norm = 1.5423e-01, time/batch = 18.0316s	
7442/33250 (epoch 11.191), train_loss = 1.00767751, grad/param norm = 1.4695e-01, time/batch = 18.2704s	
7443/33250 (epoch 11.192), train_loss = 0.99673310, grad/param norm = 1.3401e-01, time/batch = 15.3643s	
7444/33250 (epoch 11.194), train_loss = 1.01582744, grad/param norm = 1.5122e-01, time/batch = 17.0971s	
7445/33250 (epoch 11.195), train_loss = 1.24286627, grad/param norm = 1.4206e-01, time/batch = 15.6877s	
7446/33250 (epoch 11.197), train_loss = 1.03749857, grad/param norm = 1.3443e-01, time/batch = 15.0820s	
7447/33250 (epoch 11.198), train_loss = 1.19759270, grad/param norm = 1.5458e-01, time/batch = 15.2549s	
7448/33250 (epoch 11.200), train_loss = 1.08876715, grad/param norm = 1.6236e-01, time/batch = 15.9464s	
7449/33250 (epoch 11.202), train_loss = 0.99654521, grad/param norm = 1.4169e-01, time/batch = 15.7000s	
7450/33250 (epoch 11.203), train_loss = 1.03350712, grad/param norm = 1.4698e-01, time/batch = 18.5144s	
7451/33250 (epoch 11.205), train_loss = 1.11992186, grad/param norm = 1.5174e-01, time/batch = 18.3520s	
7452/33250 (epoch 11.206), train_loss = 1.13815104, grad/param norm = 1.5498e-01, time/batch = 16.0077s	
7453/33250 (epoch 11.208), train_loss = 1.25755327, grad/param norm = 1.7904e-01, time/batch = 15.5242s	
7454/33250 (epoch 11.209), train_loss = 1.02121376, grad/param norm = 1.4711e-01, time/batch = 15.3413s	
7455/33250 (epoch 11.211), train_loss = 1.19197675, grad/param norm = 1.4959e-01, time/batch = 15.2821s	
7456/33250 (epoch 11.212), train_loss = 1.33290451, grad/param norm = 1.5405e-01, time/batch = 15.4190s	
7457/33250 (epoch 11.214), train_loss = 1.06747182, grad/param norm = 1.3364e-01, time/batch = 14.7139s	
7458/33250 (epoch 11.215), train_loss = 1.37849694, grad/param norm = 1.9507e-01, time/batch = 15.8485s	
7459/33250 (epoch 11.217), train_loss = 1.23825237, grad/param norm = 1.6243e-01, time/batch = 16.9937s	
7460/33250 (epoch 11.218), train_loss = 1.17388372, grad/param norm = 1.4282e-01, time/batch = 16.0141s	
7461/33250 (epoch 11.220), train_loss = 1.18715446, grad/param norm = 1.6812e-01, time/batch = 17.8521s	
7462/33250 (epoch 11.221), train_loss = 1.33541908, grad/param norm = 1.8317e-01, time/batch = 15.8517s	
7463/33250 (epoch 11.223), train_loss = 1.07706887, grad/param norm = 1.3697e-01, time/batch = 16.8690s	
7464/33250 (epoch 11.224), train_loss = 1.20789199, grad/param norm = 1.7186e-01, time/batch = 17.2620s	
7465/33250 (epoch 11.226), train_loss = 1.27626252, grad/param norm = 1.6343e-01, time/batch = 16.5971s	
7466/33250 (epoch 11.227), train_loss = 1.14390958, grad/param norm = 1.5980e-01, time/batch = 15.8366s	
7467/33250 (epoch 11.229), train_loss = 1.12400297, grad/param norm = 1.4350e-01, time/batch = 15.5161s	
7468/33250 (epoch 11.230), train_loss = 1.04052634, grad/param norm = 1.5497e-01, time/batch = 15.3575s	
7469/33250 (epoch 11.232), train_loss = 1.03308143, grad/param norm = 1.3647e-01, time/batch = 15.2537s	
7470/33250 (epoch 11.233), train_loss = 1.01770403, grad/param norm = 1.3638e-01, time/batch = 17.3504s	
7471/33250 (epoch 11.235), train_loss = 1.22639468, grad/param norm = 1.4904e-01, time/batch = 16.6033s	
7472/33250 (epoch 11.236), train_loss = 1.02495796, grad/param norm = 1.5497e-01, time/batch = 16.3661s	
7473/33250 (epoch 11.238), train_loss = 1.16390217, grad/param norm = 1.5743e-01, time/batch = 20.0058s	
7474/33250 (epoch 11.239), train_loss = 1.27096730, grad/param norm = 1.7780e-01, time/batch = 16.1869s	
7475/33250 (epoch 11.241), train_loss = 1.18354263, grad/param norm = 1.6396e-01, time/batch = 15.8424s	
7476/33250 (epoch 11.242), train_loss = 1.19064878, grad/param norm = 1.5320e-01, time/batch = 15.5181s	
7477/33250 (epoch 11.244), train_loss = 1.21944333, grad/param norm = 1.7769e-01, time/batch = 15.7744s	
7478/33250 (epoch 11.245), train_loss = 1.09684376, grad/param norm = 1.3733e-01, time/batch = 15.4330s	
7479/33250 (epoch 11.247), train_loss = 1.12655549, grad/param norm = 1.4929e-01, time/batch = 15.0370s	
7480/33250 (epoch 11.248), train_loss = 1.36687464, grad/param norm = 1.9646e-01, time/batch = 16.3397s	
7481/33250 (epoch 11.250), train_loss = 1.19357177, grad/param norm = 1.4307e-01, time/batch = 18.7705s	
7482/33250 (epoch 11.251), train_loss = 1.12441654, grad/param norm = 1.4668e-01, time/batch = 19.0306s	
7483/33250 (epoch 11.253), train_loss = 1.00829826, grad/param norm = 1.3735e-01, time/batch = 16.4273s	
7484/33250 (epoch 11.254), train_loss = 1.03972574, grad/param norm = 1.5262e-01, time/batch = 18.0010s	
7485/33250 (epoch 11.256), train_loss = 1.16124287, grad/param norm = 1.5076e-01, time/batch = 16.1770s	
7486/33250 (epoch 11.257), train_loss = 1.25357764, grad/param norm = 1.4972e-01, time/batch = 17.5093s	
7487/33250 (epoch 11.259), train_loss = 1.27386088, grad/param norm = 1.6391e-01, time/batch = 17.1709s	
7488/33250 (epoch 11.260), train_loss = 1.01780688, grad/param norm = 1.4813e-01, time/batch = 16.1938s	
7489/33250 (epoch 11.262), train_loss = 1.16168915, grad/param norm = 1.5006e-01, time/batch = 15.8656s	
7490/33250 (epoch 11.263), train_loss = 1.04434960, grad/param norm = 1.5348e-01, time/batch = 15.4292s	
7491/33250 (epoch 11.265), train_loss = 1.21375096, grad/param norm = 1.5088e-01, time/batch = 16.7703s	
7492/33250 (epoch 11.266), train_loss = 1.11694137, grad/param norm = 1.5474e-01, time/batch = 15.7019s	
7493/33250 (epoch 11.268), train_loss = 1.03460692, grad/param norm = 1.3803e-01, time/batch = 18.4438s	
7494/33250 (epoch 11.269), train_loss = 0.90510326, grad/param norm = 1.3716e-01, time/batch = 15.5906s	
7495/33250 (epoch 11.271), train_loss = 1.07491945, grad/param norm = 1.4864e-01, time/batch = 17.6735s	
7496/33250 (epoch 11.272), train_loss = 0.94555982, grad/param norm = 1.2140e-01, time/batch = 16.1043s	
7497/33250 (epoch 11.274), train_loss = 0.85547605, grad/param norm = 1.3655e-01, time/batch = 18.0020s	
7498/33250 (epoch 11.275), train_loss = 0.99604902, grad/param norm = 1.2805e-01, time/batch = 16.4191s	
7499/33250 (epoch 11.277), train_loss = 0.89150518, grad/param norm = 1.3531e-01, time/batch = 17.0172s	
7500/33250 (epoch 11.278), train_loss = 1.01082650, grad/param norm = 1.3166e-01, time/batch = 17.3615s	
7501/33250 (epoch 11.280), train_loss = 0.95548701, grad/param norm = 1.3029e-01, time/batch = 16.7952s	
7502/33250 (epoch 11.281), train_loss = 1.10541583, grad/param norm = 1.4432e-01, time/batch = 16.0272s	
7503/33250 (epoch 11.283), train_loss = 1.16972970, grad/param norm = 1.5405e-01, time/batch = 18.2922s	
7504/33250 (epoch 11.284), train_loss = 1.00961727, grad/param norm = 1.4351e-01, time/batch = 17.5209s	
7505/33250 (epoch 11.286), train_loss = 1.17062889, grad/param norm = 1.6059e-01, time/batch = 15.6767s	
7506/33250 (epoch 11.287), train_loss = 0.94787141, grad/param norm = 1.2771e-01, time/batch = 15.1248s	
7507/33250 (epoch 11.289), train_loss = 0.91231992, grad/param norm = 1.3451e-01, time/batch = 15.1229s	
7508/33250 (epoch 11.290), train_loss = 1.09573699, grad/param norm = 1.3428e-01, time/batch = 16.2542s	
7509/33250 (epoch 11.292), train_loss = 1.14187594, grad/param norm = 1.6373e-01, time/batch = 15.6708s	
7510/33250 (epoch 11.293), train_loss = 1.24393016, grad/param norm = 1.7563e-01, time/batch = 16.6103s	
7511/33250 (epoch 11.295), train_loss = 1.15676719, grad/param norm = 1.5733e-01, time/batch = 19.5081s	
7512/33250 (epoch 11.296), train_loss = 1.09977804, grad/param norm = 1.4074e-01, time/batch = 9.9396s	
7513/33250 (epoch 11.298), train_loss = 0.90975345, grad/param norm = 1.2801e-01, time/batch = 0.6703s	
7514/33250 (epoch 11.299), train_loss = 0.86418475, grad/param norm = 1.3872e-01, time/batch = 0.6810s	
7515/33250 (epoch 11.301), train_loss = 1.16713530, grad/param norm = 1.4785e-01, time/batch = 0.7010s	
7516/33250 (epoch 11.302), train_loss = 1.10791755, grad/param norm = 1.4717e-01, time/batch = 0.6829s	
7517/33250 (epoch 11.304), train_loss = 1.02649823, grad/param norm = 1.3263e-01, time/batch = 0.6779s	
7518/33250 (epoch 11.305), train_loss = 1.09593437, grad/param norm = 1.4580e-01, time/batch = 0.6665s	
7519/33250 (epoch 11.307), train_loss = 1.17279143, grad/param norm = 1.4719e-01, time/batch = 0.7263s	
7520/33250 (epoch 11.308), train_loss = 1.36090738, grad/param norm = 1.7014e-01, time/batch = 1.0170s	
7521/33250 (epoch 11.310), train_loss = 1.08562191, grad/param norm = 1.4476e-01, time/batch = 0.9941s	
7522/33250 (epoch 11.311), train_loss = 1.23624303, grad/param norm = 1.6020e-01, time/batch = 0.9968s	
7523/33250 (epoch 11.313), train_loss = 0.91855216, grad/param norm = 1.4167e-01, time/batch = 0.9892s	
7524/33250 (epoch 11.314), train_loss = 1.09102885, grad/param norm = 1.4691e-01, time/batch = 1.0852s	
7525/33250 (epoch 11.316), train_loss = 1.26658864, grad/param norm = 1.5713e-01, time/batch = 1.8165s	
7526/33250 (epoch 11.317), train_loss = 0.98140834, grad/param norm = 1.3755e-01, time/batch = 1.8045s	
7527/33250 (epoch 11.319), train_loss = 1.21430236, grad/param norm = 1.7292e-01, time/batch = 8.8500s	
7528/33250 (epoch 11.320), train_loss = 1.25590657, grad/param norm = 1.8925e-01, time/batch = 16.1799s	
7529/33250 (epoch 11.322), train_loss = 1.28568596, grad/param norm = 1.7501e-01, time/batch = 17.3225s	
7530/33250 (epoch 11.323), train_loss = 1.34231531, grad/param norm = 1.7889e-01, time/batch = 15.5834s	
7531/33250 (epoch 11.325), train_loss = 1.12854772, grad/param norm = 1.6844e-01, time/batch = 15.3569s	
7532/33250 (epoch 11.326), train_loss = 1.30310697, grad/param norm = 1.5872e-01, time/batch = 16.1118s	
7533/33250 (epoch 11.328), train_loss = 1.04852257, grad/param norm = 1.5530e-01, time/batch = 15.2718s	
7534/33250 (epoch 11.329), train_loss = 1.13441850, grad/param norm = 1.5803e-01, time/batch = 17.2576s	
7535/33250 (epoch 11.331), train_loss = 1.07473754, grad/param norm = 1.5201e-01, time/batch = 16.9169s	
7536/33250 (epoch 11.332), train_loss = 1.06449900, grad/param norm = 1.4494e-01, time/batch = 18.5383s	
7537/33250 (epoch 11.334), train_loss = 1.23269333, grad/param norm = 1.4481e-01, time/batch = 16.9590s	
7538/33250 (epoch 11.335), train_loss = 0.81248030, grad/param norm = 1.3357e-01, time/batch = 16.4392s	
7539/33250 (epoch 11.337), train_loss = 1.11221231, grad/param norm = 1.4163e-01, time/batch = 17.2492s	
7540/33250 (epoch 11.338), train_loss = 1.22029193, grad/param norm = 1.6779e-01, time/batch = 15.4330s	
7541/33250 (epoch 11.340), train_loss = 1.10053085, grad/param norm = 1.4753e-01, time/batch = 16.6638s	
7542/33250 (epoch 11.341), train_loss = 1.02425527, grad/param norm = 1.5812e-01, time/batch = 16.3657s	
7543/33250 (epoch 11.343), train_loss = 1.09688807, grad/param norm = 1.5865e-01, time/batch = 15.2031s	
7544/33250 (epoch 11.344), train_loss = 1.08951316, grad/param norm = 1.5458e-01, time/batch = 15.5837s	
7545/33250 (epoch 11.346), train_loss = 0.93410096, grad/param norm = 1.3754e-01, time/batch = 16.9924s	
7546/33250 (epoch 11.347), train_loss = 1.39234644, grad/param norm = 1.6541e-01, time/batch = 16.6098s	
7547/33250 (epoch 11.349), train_loss = 1.06351512, grad/param norm = 1.7049e-01, time/batch = 15.5247s	
7548/33250 (epoch 11.350), train_loss = 1.09716414, grad/param norm = 1.5248e-01, time/batch = 16.9333s	
7549/33250 (epoch 11.352), train_loss = 0.98389525, grad/param norm = 1.4543e-01, time/batch = 15.1934s	
7550/33250 (epoch 11.353), train_loss = 1.07408807, grad/param norm = 1.5235e-01, time/batch = 16.0193s	
7551/33250 (epoch 11.355), train_loss = 1.06822617, grad/param norm = 1.5489e-01, time/batch = 15.1912s	
7552/33250 (epoch 11.356), train_loss = 1.01308125, grad/param norm = 1.6268e-01, time/batch = 14.9528s	
7553/33250 (epoch 11.358), train_loss = 1.03389709, grad/param norm = 1.4402e-01, time/batch = 16.0364s	
7554/33250 (epoch 11.359), train_loss = 1.04134428, grad/param norm = 1.4526e-01, time/batch = 15.2844s	
7555/33250 (epoch 11.361), train_loss = 1.28064289, grad/param norm = 1.6915e-01, time/batch = 15.8557s	
7556/33250 (epoch 11.362), train_loss = 1.09074341, grad/param norm = 1.4259e-01, time/batch = 17.5009s	
7557/33250 (epoch 11.364), train_loss = 1.19885854, grad/param norm = 1.6812e-01, time/batch = 15.6988s	
7558/33250 (epoch 11.365), train_loss = 1.07379993, grad/param norm = 1.4531e-01, time/batch = 18.0401s	
7559/33250 (epoch 11.367), train_loss = 1.06916707, grad/param norm = 1.3720e-01, time/batch = 15.4189s	
7560/33250 (epoch 11.368), train_loss = 1.08877636, grad/param norm = 1.4985e-01, time/batch = 15.8617s	
7561/33250 (epoch 11.370), train_loss = 0.94800407, grad/param norm = 1.2931e-01, time/batch = 15.1917s	
7562/33250 (epoch 11.371), train_loss = 1.22711515, grad/param norm = 1.6091e-01, time/batch = 17.5552s	
7563/33250 (epoch 11.373), train_loss = 1.03868186, grad/param norm = 1.3968e-01, time/batch = 28.3155s	
7564/33250 (epoch 11.374), train_loss = 1.18690465, grad/param norm = 1.8001e-01, time/batch = 15.6685s	
7565/33250 (epoch 11.376), train_loss = 1.06962708, grad/param norm = 1.4988e-01, time/batch = 17.1124s	
7566/33250 (epoch 11.377), train_loss = 0.99540916, grad/param norm = 1.7179e-01, time/batch = 16.0541s	
7567/33250 (epoch 11.379), train_loss = 1.01401937, grad/param norm = 1.4848e-01, time/batch = 17.1927s	
7568/33250 (epoch 11.380), train_loss = 1.14259455, grad/param norm = 1.8206e-01, time/batch = 17.0367s	
7569/33250 (epoch 11.382), train_loss = 1.20544199, grad/param norm = 1.6846e-01, time/batch = 15.3464s	
7570/33250 (epoch 11.383), train_loss = 0.98139419, grad/param norm = 1.3927e-01, time/batch = 16.6070s	
7571/33250 (epoch 11.385), train_loss = 0.94319717, grad/param norm = 1.4431e-01, time/batch = 15.2652s	
7572/33250 (epoch 11.386), train_loss = 0.93549716, grad/param norm = 1.3379e-01, time/batch = 15.4437s	
7573/33250 (epoch 11.388), train_loss = 1.02112997, grad/param norm = 1.5688e-01, time/batch = 15.5143s	
7574/33250 (epoch 11.389), train_loss = 1.06225387, grad/param norm = 1.6246e-01, time/batch = 16.0126s	
7575/33250 (epoch 11.391), train_loss = 1.10868369, grad/param norm = 1.5812e-01, time/batch = 17.2554s	
7576/33250 (epoch 11.392), train_loss = 1.20036951, grad/param norm = 1.6795e-01, time/batch = 16.2048s	
7577/33250 (epoch 11.394), train_loss = 1.27898808, grad/param norm = 1.7409e-01, time/batch = 16.5291s	
7578/33250 (epoch 11.395), train_loss = 1.17622931, grad/param norm = 1.3944e-01, time/batch = 16.7108s	
7579/33250 (epoch 11.397), train_loss = 1.21488887, grad/param norm = 1.5445e-01, time/batch = 15.7875s	
7580/33250 (epoch 11.398), train_loss = 1.02741817, grad/param norm = 1.4918e-01, time/batch = 15.8413s	
7581/33250 (epoch 11.400), train_loss = 1.00908176, grad/param norm = 1.4626e-01, time/batch = 16.7682s	
7582/33250 (epoch 11.402), train_loss = 0.92477802, grad/param norm = 1.4695e-01, time/batch = 15.5737s	
7583/33250 (epoch 11.403), train_loss = 1.04119545, grad/param norm = 1.8512e-01, time/batch = 16.0263s	
7584/33250 (epoch 11.405), train_loss = 0.99435152, grad/param norm = 1.4858e-01, time/batch = 15.7732s	
7585/33250 (epoch 11.406), train_loss = 1.16533544, grad/param norm = 1.7297e-01, time/batch = 23.2768s	
7586/33250 (epoch 11.408), train_loss = 1.23246052, grad/param norm = 1.6590e-01, time/batch = 16.7582s	
7587/33250 (epoch 11.409), train_loss = 1.17971039, grad/param norm = 2.3397e-01, time/batch = 15.4678s	
7588/33250 (epoch 11.411), train_loss = 0.81261632, grad/param norm = 1.2327e-01, time/batch = 14.7205s	
7589/33250 (epoch 11.412), train_loss = 0.92998799, grad/param norm = 1.4057e-01, time/batch = 15.0192s	
7590/33250 (epoch 11.414), train_loss = 1.12259758, grad/param norm = 1.5980e-01, time/batch = 15.6619s	
7591/33250 (epoch 11.415), train_loss = 1.24801419, grad/param norm = 1.7018e-01, time/batch = 15.2682s	
7592/33250 (epoch 11.417), train_loss = 1.17809000, grad/param norm = 1.5612e-01, time/batch = 15.2885s	
7593/33250 (epoch 11.418), train_loss = 1.36084003, grad/param norm = 1.7755e-01, time/batch = 15.7037s	
7594/33250 (epoch 11.420), train_loss = 1.22168569, grad/param norm = 1.5564e-01, time/batch = 15.3527s	
7595/33250 (epoch 11.421), train_loss = 1.00701629, grad/param norm = 1.6628e-01, time/batch = 15.1954s	
7596/33250 (epoch 11.423), train_loss = 1.15259913, grad/param norm = 1.6871e-01, time/batch = 14.5457s	
7597/33250 (epoch 11.424), train_loss = 1.34198686, grad/param norm = 2.0405e-01, time/batch = 16.0345s	
7598/33250 (epoch 11.426), train_loss = 1.00140394, grad/param norm = 1.3821e-01, time/batch = 18.3609s	
7599/33250 (epoch 11.427), train_loss = 1.02707792, grad/param norm = 1.5536e-01, time/batch = 15.5248s	
7600/33250 (epoch 11.429), train_loss = 1.16380551, grad/param norm = 1.6487e-01, time/batch = 16.2702s	
7601/33250 (epoch 11.430), train_loss = 1.00523867, grad/param norm = 1.6032e-01, time/batch = 16.2436s	
7602/33250 (epoch 11.432), train_loss = 1.09247142, grad/param norm = 1.3357e-01, time/batch = 16.4205s	
7603/33250 (epoch 11.433), train_loss = 1.03385746, grad/param norm = 1.7250e-01, time/batch = 16.2701s	
7604/33250 (epoch 11.435), train_loss = 1.13623375, grad/param norm = 1.6275e-01, time/batch = 18.4222s	
7605/33250 (epoch 11.436), train_loss = 1.02902634, grad/param norm = 1.5936e-01, time/batch = 16.2650s	
7606/33250 (epoch 11.438), train_loss = 1.15971692, grad/param norm = 1.5091e-01, time/batch = 16.9400s	
7607/33250 (epoch 11.439), train_loss = 1.10296786, grad/param norm = 1.4296e-01, time/batch = 17.5898s	
7608/33250 (epoch 11.441), train_loss = 1.07904136, grad/param norm = 1.3734e-01, time/batch = 17.4378s	
7609/33250 (epoch 11.442), train_loss = 0.99719545, grad/param norm = 1.5006e-01, time/batch = 15.6191s	
7610/33250 (epoch 11.444), train_loss = 1.00490339, grad/param norm = 1.4335e-01, time/batch = 15.4446s	
7611/33250 (epoch 11.445), train_loss = 1.09495694, grad/param norm = 1.4365e-01, time/batch = 17.0895s	
7612/33250 (epoch 11.447), train_loss = 1.12647590, grad/param norm = 1.5267e-01, time/batch = 16.9378s	
7613/33250 (epoch 11.448), train_loss = 1.05253947, grad/param norm = 1.2523e-01, time/batch = 15.2678s	
7614/33250 (epoch 11.450), train_loss = 1.27734959, grad/param norm = 1.7537e-01, time/batch = 15.6065s	
7615/33250 (epoch 11.451), train_loss = 1.17480578, grad/param norm = 1.6659e-01, time/batch = 14.7844s	
7616/33250 (epoch 11.453), train_loss = 0.96313725, grad/param norm = 1.3811e-01, time/batch = 15.2708s	
7617/33250 (epoch 11.454), train_loss = 1.25791045, grad/param norm = 1.6512e-01, time/batch = 15.6038s	
7618/33250 (epoch 11.456), train_loss = 1.24330111, grad/param norm = 1.6192e-01, time/batch = 18.6864s	
7619/33250 (epoch 11.457), train_loss = 1.06749422, grad/param norm = 1.5980e-01, time/batch = 15.2791s	
7620/33250 (epoch 11.459), train_loss = 1.10213641, grad/param norm = 1.4244e-01, time/batch = 15.1159s	
7621/33250 (epoch 11.460), train_loss = 1.19598368, grad/param norm = 1.6899e-01, time/batch = 15.7708s	
7622/33250 (epoch 11.462), train_loss = 1.02078722, grad/param norm = 1.4504e-01, time/batch = 18.1727s	
7623/33250 (epoch 11.463), train_loss = 0.98874680, grad/param norm = 1.3126e-01, time/batch = 16.0084s	
7624/33250 (epoch 11.465), train_loss = 0.88092788, grad/param norm = 1.1587e-01, time/batch = 15.1719s	
7625/33250 (epoch 11.466), train_loss = 0.85925934, grad/param norm = 1.0910e-01, time/batch = 15.1730s	
7626/33250 (epoch 11.468), train_loss = 0.95940162, grad/param norm = 1.2599e-01, time/batch = 16.2084s	
7627/33250 (epoch 11.469), train_loss = 1.07601212, grad/param norm = 1.5622e-01, time/batch = 17.3520s	
7628/33250 (epoch 11.471), train_loss = 1.19082558, grad/param norm = 1.3982e-01, time/batch = 16.1170s	
7629/33250 (epoch 11.472), train_loss = 1.08644740, grad/param norm = 1.8099e-01, time/batch = 17.5275s	
7630/33250 (epoch 11.474), train_loss = 1.31357009, grad/param norm = 1.8470e-01, time/batch = 15.8442s	
7631/33250 (epoch 11.475), train_loss = 1.10739433, grad/param norm = 1.4290e-01, time/batch = 16.2620s	
7632/33250 (epoch 11.477), train_loss = 1.09137293, grad/param norm = 1.4171e-01, time/batch = 15.3636s	
7633/33250 (epoch 11.478), train_loss = 1.04290508, grad/param norm = 1.3869e-01, time/batch = 16.1790s	
7634/33250 (epoch 11.480), train_loss = 1.33301229, grad/param norm = 1.7039e-01, time/batch = 15.9440s	
7635/33250 (epoch 11.481), train_loss = 1.07474899, grad/param norm = 1.4495e-01, time/batch = 15.3466s	
7636/33250 (epoch 11.483), train_loss = 1.14559998, grad/param norm = 1.3813e-01, time/batch = 15.7821s	
7637/33250 (epoch 11.484), train_loss = 0.99661404, grad/param norm = 1.4622e-01, time/batch = 16.8643s	
7638/33250 (epoch 11.486), train_loss = 0.89272021, grad/param norm = 1.3640e-01, time/batch = 18.1909s	
7639/33250 (epoch 11.487), train_loss = 1.03275336, grad/param norm = 1.5858e-01, time/batch = 16.1602s	
7640/33250 (epoch 11.489), train_loss = 1.21650038, grad/param norm = 1.7149e-01, time/batch = 16.2674s	
7641/33250 (epoch 11.490), train_loss = 1.16232181, grad/param norm = 1.6336e-01, time/batch = 16.1734s	
7642/33250 (epoch 11.492), train_loss = 1.13498385, grad/param norm = 1.4869e-01, time/batch = 15.8531s	
7643/33250 (epoch 11.493), train_loss = 1.09941744, grad/param norm = 1.6471e-01, time/batch = 15.2688s	
7644/33250 (epoch 11.495), train_loss = 1.12059828, grad/param norm = 1.4395e-01, time/batch = 16.4392s	
7645/33250 (epoch 11.496), train_loss = 1.05226751, grad/param norm = 1.2709e-01, time/batch = 15.1233s	
7646/33250 (epoch 11.498), train_loss = 1.20834607, grad/param norm = 1.6176e-01, time/batch = 16.1119s	
7647/33250 (epoch 11.499), train_loss = 1.06982300, grad/param norm = 1.4046e-01, time/batch = 17.5298s	
7648/33250 (epoch 11.501), train_loss = 1.05028376, grad/param norm = 1.6502e-01, time/batch = 16.7667s	
7649/33250 (epoch 11.502), train_loss = 1.05321336, grad/param norm = 1.3084e-01, time/batch = 15.6294s	
7650/33250 (epoch 11.504), train_loss = 1.23722726, grad/param norm = 1.7100e-01, time/batch = 15.4546s	
7651/33250 (epoch 11.505), train_loss = 0.88598735, grad/param norm = 1.2414e-01, time/batch = 15.2680s	
7652/33250 (epoch 11.507), train_loss = 1.04538609, grad/param norm = 1.4129e-01, time/batch = 16.5267s	
7653/33250 (epoch 11.508), train_loss = 1.02655907, grad/param norm = 1.3950e-01, time/batch = 15.3658s	
7654/33250 (epoch 11.510), train_loss = 0.89497934, grad/param norm = 1.2621e-01, time/batch = 15.4967s	
7655/33250 (epoch 11.511), train_loss = 1.08914285, grad/param norm = 1.4816e-01, time/batch = 15.4508s	
7656/33250 (epoch 11.513), train_loss = 1.26874353, grad/param norm = 1.5352e-01, time/batch = 15.6019s	
7657/33250 (epoch 11.514), train_loss = 1.02705415, grad/param norm = 1.3737e-01, time/batch = 16.3626s	
7658/33250 (epoch 11.516), train_loss = 1.01886551, grad/param norm = 1.3817e-01, time/batch = 15.3556s	
7659/33250 (epoch 11.517), train_loss = 1.08143798, grad/param norm = 1.4513e-01, time/batch = 18.2754s	
7660/33250 (epoch 11.519), train_loss = 0.94882079, grad/param norm = 1.2107e-01, time/batch = 17.2029s	
7661/33250 (epoch 11.520), train_loss = 1.37661370, grad/param norm = 1.8882e-01, time/batch = 15.4143s	
7662/33250 (epoch 11.522), train_loss = 1.16235606, grad/param norm = 1.5544e-01, time/batch = 16.6721s	
7663/33250 (epoch 11.523), train_loss = 1.05441672, grad/param norm = 1.4812e-01, time/batch = 15.8655s	
7664/33250 (epoch 11.525), train_loss = 0.96638285, grad/param norm = 1.5655e-01, time/batch = 15.4423s	
7665/33250 (epoch 11.526), train_loss = 0.96145958, grad/param norm = 1.4229e-01, time/batch = 15.4249s	
7666/33250 (epoch 11.528), train_loss = 1.05880829, grad/param norm = 1.4416e-01, time/batch = 15.1794s	
7667/33250 (epoch 11.529), train_loss = 1.00752302, grad/param norm = 1.5006e-01, time/batch = 15.9552s	
7668/33250 (epoch 11.531), train_loss = 0.95185930, grad/param norm = 1.3052e-01, time/batch = 16.1381s	
7669/33250 (epoch 11.532), train_loss = 1.16873145, grad/param norm = 1.5035e-01, time/batch = 16.4465s	
7670/33250 (epoch 11.534), train_loss = 0.97498877, grad/param norm = 1.3217e-01, time/batch = 17.2059s	
7671/33250 (epoch 11.535), train_loss = 1.06221755, grad/param norm = 1.4509e-01, time/batch = 15.6112s	
7672/33250 (epoch 11.537), train_loss = 1.16059441, grad/param norm = 1.4495e-01, time/batch = 15.6598s	
7673/33250 (epoch 11.538), train_loss = 1.16726293, grad/param norm = 1.5087e-01, time/batch = 15.1064s	
7674/33250 (epoch 11.540), train_loss = 1.25444795, grad/param norm = 1.4637e-01, time/batch = 16.4234s	
7675/33250 (epoch 11.541), train_loss = 1.22799694, grad/param norm = 1.6073e-01, time/batch = 16.3525s	
7676/33250 (epoch 11.543), train_loss = 1.17340419, grad/param norm = 1.4840e-01, time/batch = 15.2775s	
7677/33250 (epoch 11.544), train_loss = 1.03387782, grad/param norm = 1.4714e-01, time/batch = 17.2395s	
7678/33250 (epoch 11.546), train_loss = 1.08499293, grad/param norm = 1.7523e-01, time/batch = 16.3521s	
7679/33250 (epoch 11.547), train_loss = 1.04355764, grad/param norm = 1.7340e-01, time/batch = 18.2491s	
7680/33250 (epoch 11.549), train_loss = 1.16229424, grad/param norm = 1.6006e-01, time/batch = 15.4620s	
7681/33250 (epoch 11.550), train_loss = 1.05570726, grad/param norm = 1.5507e-01, time/batch = 17.7813s	
7682/33250 (epoch 11.552), train_loss = 1.12195005, grad/param norm = 1.4881e-01, time/batch = 16.0268s	
7683/33250 (epoch 11.553), train_loss = 1.03830180, grad/param norm = 1.5284e-01, time/batch = 15.4398s	
7684/33250 (epoch 11.555), train_loss = 1.07955524, grad/param norm = 1.3148e-01, time/batch = 15.2771s	
7685/33250 (epoch 11.556), train_loss = 1.22918037, grad/param norm = 1.7673e-01, time/batch = 16.5304s	
7686/33250 (epoch 11.558), train_loss = 1.19824312, grad/param norm = 1.5764e-01, time/batch = 16.1747s	
7687/33250 (epoch 11.559), train_loss = 0.99055780, grad/param norm = 1.4535e-01, time/batch = 15.7487s	
7688/33250 (epoch 11.561), train_loss = 1.03608198, grad/param norm = 1.5239e-01, time/batch = 15.7177s	
7689/33250 (epoch 11.562), train_loss = 1.25314219, grad/param norm = 1.6817e-01, time/batch = 15.6608s	
7690/33250 (epoch 11.564), train_loss = 1.31244594, grad/param norm = 1.7010e-01, time/batch = 16.0406s	
7691/33250 (epoch 11.565), train_loss = 1.27417595, grad/param norm = 1.6805e-01, time/batch = 16.3756s	
7692/33250 (epoch 11.567), train_loss = 1.21657348, grad/param norm = 1.5008e-01, time/batch = 15.7398s	
7693/33250 (epoch 11.568), train_loss = 1.09910761, grad/param norm = 1.6034e-01, time/batch = 15.6708s	
7694/33250 (epoch 11.570), train_loss = 1.22841436, grad/param norm = 1.6635e-01, time/batch = 15.8258s	
7695/33250 (epoch 11.571), train_loss = 1.30279346, grad/param norm = 1.5642e-01, time/batch = 15.9362s	
7696/33250 (epoch 11.573), train_loss = 1.14942409, grad/param norm = 1.5243e-01, time/batch = 16.0274s	
7697/33250 (epoch 11.574), train_loss = 1.01037411, grad/param norm = 1.4429e-01, time/batch = 15.8484s	
7698/33250 (epoch 11.576), train_loss = 1.14417980, grad/param norm = 1.4144e-01, time/batch = 15.9945s	
7699/33250 (epoch 11.577), train_loss = 1.08495908, grad/param norm = 1.4361e-01, time/batch = 15.8269s	
7700/33250 (epoch 11.579), train_loss = 0.98509794, grad/param norm = 1.4545e-01, time/batch = 15.9656s	
7701/33250 (epoch 11.580), train_loss = 1.03162686, grad/param norm = 1.2903e-01, time/batch = 16.3478s	
7702/33250 (epoch 11.582), train_loss = 1.07061247, grad/param norm = 1.4749e-01, time/batch = 15.8855s	
7703/33250 (epoch 11.583), train_loss = 1.13375014, grad/param norm = 1.4287e-01, time/batch = 16.1623s	
7704/33250 (epoch 11.585), train_loss = 1.18793033, grad/param norm = 1.4483e-01, time/batch = 15.9257s	
7705/33250 (epoch 11.586), train_loss = 1.05180076, grad/param norm = 1.7854e-01, time/batch = 15.9831s	
7706/33250 (epoch 11.588), train_loss = 1.10672013, grad/param norm = 1.4007e-01, time/batch = 15.7366s	
7707/33250 (epoch 11.589), train_loss = 1.16357087, grad/param norm = 1.5934e-01, time/batch = 15.9228s	
7708/33250 (epoch 11.591), train_loss = 1.16383881, grad/param norm = 1.7371e-01, time/batch = 15.9278s	
7709/33250 (epoch 11.592), train_loss = 1.10867007, grad/param norm = 1.3922e-01, time/batch = 15.8498s	
7710/33250 (epoch 11.594), train_loss = 1.29252698, grad/param norm = 1.7008e-01, time/batch = 16.1059s	
7711/33250 (epoch 11.595), train_loss = 1.19231438, grad/param norm = 1.5902e-01, time/batch = 16.3576s	
7712/33250 (epoch 11.597), train_loss = 0.95326207, grad/param norm = 1.2670e-01, time/batch = 16.2667s	
7713/33250 (epoch 11.598), train_loss = 1.10492687, grad/param norm = 1.5657e-01, time/batch = 16.1619s	
7714/33250 (epoch 11.600), train_loss = 1.09568429, grad/param norm = 1.7109e-01, time/batch = 16.0500s	
7715/33250 (epoch 11.602), train_loss = 1.14819292, grad/param norm = 1.7086e-01, time/batch = 16.0265s	
7716/33250 (epoch 11.603), train_loss = 1.13561502, grad/param norm = 1.5402e-01, time/batch = 15.7782s	
7717/33250 (epoch 11.605), train_loss = 1.11273294, grad/param norm = 1.5822e-01, time/batch = 16.0861s	
7718/33250 (epoch 11.606), train_loss = 1.15515285, grad/param norm = 1.5290e-01, time/batch = 16.1839s	
7719/33250 (epoch 11.608), train_loss = 1.10969016, grad/param norm = 1.4128e-01, time/batch = 16.1009s	
7720/33250 (epoch 11.609), train_loss = 0.99358758, grad/param norm = 1.4891e-01, time/batch = 16.1941s	
7721/33250 (epoch 11.611), train_loss = 1.16083927, grad/param norm = 1.5460e-01, time/batch = 16.3571s	
7722/33250 (epoch 11.612), train_loss = 1.13791641, grad/param norm = 1.5902e-01, time/batch = 16.2033s	
7723/33250 (epoch 11.614), train_loss = 1.35406588, grad/param norm = 1.8903e-01, time/batch = 16.1567s	
7724/33250 (epoch 11.615), train_loss = 1.21560692, grad/param norm = 1.6237e-01, time/batch = 16.1342s	
7725/33250 (epoch 11.617), train_loss = 1.49629449, grad/param norm = 1.8821e-01, time/batch = 15.9940s	
7726/33250 (epoch 11.618), train_loss = 1.43753025, grad/param norm = 2.1926e-01, time/batch = 15.9784s	
7727/33250 (epoch 11.620), train_loss = 1.24920602, grad/param norm = 1.7122e-01, time/batch = 16.0551s	
7728/33250 (epoch 11.621), train_loss = 1.08496773, grad/param norm = 1.4562e-01, time/batch = 16.1527s	
7729/33250 (epoch 11.623), train_loss = 1.03300610, grad/param norm = 1.4873e-01, time/batch = 15.8305s	
7730/33250 (epoch 11.624), train_loss = 1.09062945, grad/param norm = 1.6217e-01, time/batch = 15.8269s	
7731/33250 (epoch 11.626), train_loss = 1.06712860, grad/param norm = 1.6330e-01, time/batch = 16.1108s	
7732/33250 (epoch 11.627), train_loss = 1.04971976, grad/param norm = 1.4762e-01, time/batch = 16.0966s	
7733/33250 (epoch 11.629), train_loss = 1.13662270, grad/param norm = 1.7188e-01, time/batch = 16.0744s	
7734/33250 (epoch 11.630), train_loss = 1.07306319, grad/param norm = 1.6245e-01, time/batch = 15.7581s	
7735/33250 (epoch 11.632), train_loss = 0.90787505, grad/param norm = 1.2201e-01, time/batch = 15.9222s	
7736/33250 (epoch 11.633), train_loss = 1.17236021, grad/param norm = 1.5778e-01, time/batch = 15.9829s	
7737/33250 (epoch 11.635), train_loss = 0.99875929, grad/param norm = 1.4600e-01, time/batch = 16.0139s	
7738/33250 (epoch 11.636), train_loss = 1.00589222, grad/param norm = 1.3827e-01, time/batch = 16.0969s	
7739/33250 (epoch 11.638), train_loss = 1.05039872, grad/param norm = 1.3897e-01, time/batch = 16.0141s	
7740/33250 (epoch 11.639), train_loss = 0.96465311, grad/param norm = 1.4683e-01, time/batch = 16.0903s	
7741/33250 (epoch 11.641), train_loss = 0.98937206, grad/param norm = 1.3162e-01, time/batch = 15.9338s	
7742/33250 (epoch 11.642), train_loss = 0.93129230, grad/param norm = 1.4704e-01, time/batch = 16.0194s	
7743/33250 (epoch 11.644), train_loss = 0.84564675, grad/param norm = 1.3123e-01, time/batch = 15.9192s	
7744/33250 (epoch 11.645), train_loss = 1.20663015, grad/param norm = 1.7051e-01, time/batch = 15.9542s	
7745/33250 (epoch 11.647), train_loss = 0.96230268, grad/param norm = 1.4300e-01, time/batch = 15.9282s	
7746/33250 (epoch 11.648), train_loss = 1.04426483, grad/param norm = 1.5206e-01, time/batch = 15.9275s	
7747/33250 (epoch 11.650), train_loss = 1.23159708, grad/param norm = 1.6493e-01, time/batch = 15.8322s	
7748/33250 (epoch 11.651), train_loss = 1.11212344, grad/param norm = 1.7641e-01, time/batch = 15.8335s	
7749/33250 (epoch 11.653), train_loss = 0.97380954, grad/param norm = 1.3943e-01, time/batch = 15.6493s	
7750/33250 (epoch 11.654), train_loss = 1.03309050, grad/param norm = 1.3970e-01, time/batch = 15.7702s	
7751/33250 (epoch 11.656), train_loss = 1.16181173, grad/param norm = 1.5704e-01, time/batch = 15.7672s	
7752/33250 (epoch 11.657), train_loss = 0.87465659, grad/param norm = 1.3957e-01, time/batch = 15.7695s	
7753/33250 (epoch 11.659), train_loss = 1.06478687, grad/param norm = 1.5468e-01, time/batch = 15.6841s	
7754/33250 (epoch 11.660), train_loss = 1.08668888, grad/param norm = 1.5696e-01, time/batch = 15.9406s	
7755/33250 (epoch 11.662), train_loss = 1.12118443, grad/param norm = 1.5156e-01, time/batch = 15.8479s	
7756/33250 (epoch 11.663), train_loss = 1.01917626, grad/param norm = 1.4837e-01, time/batch = 15.8562s	
7757/33250 (epoch 11.665), train_loss = 1.14302136, grad/param norm = 1.5230e-01, time/batch = 16.0940s	
7758/33250 (epoch 11.666), train_loss = 1.05172565, grad/param norm = 1.5765e-01, time/batch = 16.0034s	
7759/33250 (epoch 11.668), train_loss = 1.26489669, grad/param norm = 1.6082e-01, time/batch = 15.8401s	
7760/33250 (epoch 11.669), train_loss = 1.13925978, grad/param norm = 1.5145e-01, time/batch = 16.0129s	
7761/33250 (epoch 11.671), train_loss = 1.02826443, grad/param norm = 1.6275e-01, time/batch = 15.8599s	
7762/33250 (epoch 11.672), train_loss = 1.21902589, grad/param norm = 1.5955e-01, time/batch = 16.0196s	
7763/33250 (epoch 11.674), train_loss = 1.04333492, grad/param norm = 1.3941e-01, time/batch = 15.7046s	
7764/33250 (epoch 11.675), train_loss = 1.08218558, grad/param norm = 1.4128e-01, time/batch = 15.9623s	
7765/33250 (epoch 11.677), train_loss = 1.21692217, grad/param norm = 1.6161e-01, time/batch = 16.0197s	
7766/33250 (epoch 11.678), train_loss = 1.11663255, grad/param norm = 1.6271e-01, time/batch = 15.8461s	
7767/33250 (epoch 11.680), train_loss = 1.20460143, grad/param norm = 1.5920e-01, time/batch = 15.6639s	
7768/33250 (epoch 11.681), train_loss = 0.95805884, grad/param norm = 1.3977e-01, time/batch = 15.7546s	
7769/33250 (epoch 11.683), train_loss = 1.06751289, grad/param norm = 1.6221e-01, time/batch = 15.7608s	
7770/33250 (epoch 11.684), train_loss = 0.99668792, grad/param norm = 1.5884e-01, time/batch = 15.8610s	
7771/33250 (epoch 11.686), train_loss = 0.99387397, grad/param norm = 1.5001e-01, time/batch = 15.7681s	
7772/33250 (epoch 11.687), train_loss = 1.04391768, grad/param norm = 1.4640e-01, time/batch = 15.8743s	
7773/33250 (epoch 11.689), train_loss = 1.02867283, grad/param norm = 1.5156e-01, time/batch = 15.6879s	
7774/33250 (epoch 11.690), train_loss = 1.13896178, grad/param norm = 1.5129e-01, time/batch = 15.6321s	
7775/33250 (epoch 11.692), train_loss = 1.09374899, grad/param norm = 1.6260e-01, time/batch = 16.0212s	
7776/33250 (epoch 11.693), train_loss = 1.12710526, grad/param norm = 1.3747e-01, time/batch = 15.7854s	
7777/33250 (epoch 11.695), train_loss = 1.12857520, grad/param norm = 1.4909e-01, time/batch = 15.6968s	
7778/33250 (epoch 11.696), train_loss = 1.11983527, grad/param norm = 1.4015e-01, time/batch = 15.6897s	
7779/33250 (epoch 11.698), train_loss = 1.01245488, grad/param norm = 1.5168e-01, time/batch = 15.6870s	
7780/33250 (epoch 11.699), train_loss = 1.31039675, grad/param norm = 1.5908e-01, time/batch = 15.7010s	
7781/33250 (epoch 11.701), train_loss = 1.05703211, grad/param norm = 1.3705e-01, time/batch = 16.0152s	
7782/33250 (epoch 11.702), train_loss = 1.09121569, grad/param norm = 1.8161e-01, time/batch = 15.7739s	
7783/33250 (epoch 11.704), train_loss = 1.30266357, grad/param norm = 1.7913e-01, time/batch = 15.9461s	
7784/33250 (epoch 11.705), train_loss = 0.97650528, grad/param norm = 1.3488e-01, time/batch = 19.5574s	
7785/33250 (epoch 11.707), train_loss = 0.90058291, grad/param norm = 1.3529e-01, time/batch = 26.5607s	
7786/33250 (epoch 11.708), train_loss = 1.16958876, grad/param norm = 1.6176e-01, time/batch = 16.1584s	
7787/33250 (epoch 11.710), train_loss = 1.16528287, grad/param norm = 1.5692e-01, time/batch = 15.5830s	
7788/33250 (epoch 11.711), train_loss = 1.05623076, grad/param norm = 1.6474e-01, time/batch = 15.8305s	
7789/33250 (epoch 11.713), train_loss = 1.16909652, grad/param norm = 1.6435e-01, time/batch = 15.5252s	
7790/33250 (epoch 11.714), train_loss = 1.09408741, grad/param norm = 1.5059e-01, time/batch = 15.6819s	
7791/33250 (epoch 11.716), train_loss = 1.20737766, grad/param norm = 1.6200e-01, time/batch = 16.0036s	
7792/33250 (epoch 11.717), train_loss = 1.02650355, grad/param norm = 1.4059e-01, time/batch = 15.7879s	
7793/33250 (epoch 11.719), train_loss = 1.07258357, grad/param norm = 1.4403e-01, time/batch = 15.7761s	
7794/33250 (epoch 11.720), train_loss = 1.31820527, grad/param norm = 1.5925e-01, time/batch = 15.8713s	
7795/33250 (epoch 11.722), train_loss = 0.98148157, grad/param norm = 1.3459e-01, time/batch = 15.7780s	
7796/33250 (epoch 11.723), train_loss = 0.88809363, grad/param norm = 1.2758e-01, time/batch = 15.7845s	
7797/33250 (epoch 11.725), train_loss = 0.93658461, grad/param norm = 1.2095e-01, time/batch = 15.7025s	
7798/33250 (epoch 11.726), train_loss = 1.04395739, grad/param norm = 1.3147e-01, time/batch = 15.7015s	
7799/33250 (epoch 11.728), train_loss = 1.13823824, grad/param norm = 1.4550e-01, time/batch = 15.8301s	
7800/33250 (epoch 11.729), train_loss = 1.25280922, grad/param norm = 1.6093e-01, time/batch = 15.7819s	
7801/33250 (epoch 11.731), train_loss = 1.03995548, grad/param norm = 1.4756e-01, time/batch = 15.7771s	
7802/33250 (epoch 11.732), train_loss = 0.97736293, grad/param norm = 1.4141e-01, time/batch = 15.6858s	
7803/33250 (epoch 11.734), train_loss = 1.12314207, grad/param norm = 1.5535e-01, time/batch = 15.9312s	
7804/33250 (epoch 11.735), train_loss = 1.10165979, grad/param norm = 1.4787e-01, time/batch = 15.7836s	
7805/33250 (epoch 11.737), train_loss = 1.09316841, grad/param norm = 1.3242e-01, time/batch = 15.9320s	
7806/33250 (epoch 11.738), train_loss = 1.10117404, grad/param norm = 1.5325e-01, time/batch = 15.7521s	
7807/33250 (epoch 11.740), train_loss = 1.22016359, grad/param norm = 1.5176e-01, time/batch = 15.6852s	
7808/33250 (epoch 11.741), train_loss = 1.18455319, grad/param norm = 1.5640e-01, time/batch = 15.7732s	
7809/33250 (epoch 11.743), train_loss = 1.06333138, grad/param norm = 1.4131e-01, time/batch = 15.5073s	
7810/33250 (epoch 11.744), train_loss = 1.08930458, grad/param norm = 1.5513e-01, time/batch = 15.5735s	
7811/33250 (epoch 11.746), train_loss = 1.06739142, grad/param norm = 1.3569e-01, time/batch = 15.1391s	
7812/33250 (epoch 11.747), train_loss = 1.05056017, grad/param norm = 1.5605e-01, time/batch = 15.5521s	
7813/33250 (epoch 11.749), train_loss = 1.23330497, grad/param norm = 1.7874e-01, time/batch = 15.2212s	
7814/33250 (epoch 11.750), train_loss = 1.15990513, grad/param norm = 1.6281e-01, time/batch = 15.7539s	
7815/33250 (epoch 11.752), train_loss = 1.00752399, grad/param norm = 1.3738e-01, time/batch = 15.6935s	
7816/33250 (epoch 11.753), train_loss = 1.07531987, grad/param norm = 1.4778e-01, time/batch = 15.7316s	
7817/33250 (epoch 11.755), train_loss = 1.06260171, grad/param norm = 1.4471e-01, time/batch = 15.7010s	
7818/33250 (epoch 11.756), train_loss = 1.17261835, grad/param norm = 1.4783e-01, time/batch = 15.8115s	
7819/33250 (epoch 11.758), train_loss = 1.22418141, grad/param norm = 1.5746e-01, time/batch = 15.5753s	
7820/33250 (epoch 11.759), train_loss = 1.00126739, grad/param norm = 1.4675e-01, time/batch = 15.3979s	
7821/33250 (epoch 11.761), train_loss = 1.04071113, grad/param norm = 1.4071e-01, time/batch = 15.6520s	
7822/33250 (epoch 11.762), train_loss = 1.20274090, grad/param norm = 1.5315e-01, time/batch = 15.7450s	
7823/33250 (epoch 11.764), train_loss = 1.00776035, grad/param norm = 1.7368e-01, time/batch = 15.7394s	
7824/33250 (epoch 11.765), train_loss = 1.13353430, grad/param norm = 1.5410e-01, time/batch = 15.9109s	
7825/33250 (epoch 11.767), train_loss = 0.89075132, grad/param norm = 1.3817e-01, time/batch = 15.6026s	
7826/33250 (epoch 11.768), train_loss = 0.95234669, grad/param norm = 1.5039e-01, time/batch = 16.0217s	
7827/33250 (epoch 11.770), train_loss = 1.16253465, grad/param norm = 1.7004e-01, time/batch = 15.5600s	
7828/33250 (epoch 11.771), train_loss = 1.15694637, grad/param norm = 1.5815e-01, time/batch = 15.7035s	
7829/33250 (epoch 11.773), train_loss = 1.06336091, grad/param norm = 1.6387e-01, time/batch = 15.7464s	
7830/33250 (epoch 11.774), train_loss = 0.92157501, grad/param norm = 1.4763e-01, time/batch = 15.6532s	
7831/33250 (epoch 11.776), train_loss = 1.04258353, grad/param norm = 1.4977e-01, time/batch = 15.5742s	
7832/33250 (epoch 11.777), train_loss = 1.19903555, grad/param norm = 1.8610e-01, time/batch = 15.4895s	
7833/33250 (epoch 11.779), train_loss = 1.05550612, grad/param norm = 1.5389e-01, time/batch = 15.7163s	
7834/33250 (epoch 11.780), train_loss = 1.30252186, grad/param norm = 1.9636e-01, time/batch = 15.3953s	
7835/33250 (epoch 11.782), train_loss = 1.13508966, grad/param norm = 1.4451e-01, time/batch = 15.3127s	
7836/33250 (epoch 11.783), train_loss = 0.90462564, grad/param norm = 1.4027e-01, time/batch = 15.3194s	
7837/33250 (epoch 11.785), train_loss = 0.98790402, grad/param norm = 1.4695e-01, time/batch = 15.8405s	
7838/33250 (epoch 11.786), train_loss = 1.15616534, grad/param norm = 1.5255e-01, time/batch = 16.0070s	
7839/33250 (epoch 11.788), train_loss = 1.17838582, grad/param norm = 1.4886e-01, time/batch = 15.6214s	
7840/33250 (epoch 11.789), train_loss = 1.20163409, grad/param norm = 1.6538e-01, time/batch = 15.7659s	
7841/33250 (epoch 11.791), train_loss = 1.26670960, grad/param norm = 1.5790e-01, time/batch = 15.8323s	
7842/33250 (epoch 11.792), train_loss = 1.33471479, grad/param norm = 1.5532e-01, time/batch = 15.6798s	
7843/33250 (epoch 11.794), train_loss = 1.08322704, grad/param norm = 1.5337e-01, time/batch = 15.9955s	
7844/33250 (epoch 11.795), train_loss = 1.15909575, grad/param norm = 1.6481e-01, time/batch = 15.5985s	
7845/33250 (epoch 11.797), train_loss = 1.21584268, grad/param norm = 1.7266e-01, time/batch = 15.7462s	
7846/33250 (epoch 11.798), train_loss = 1.12011898, grad/param norm = 1.7652e-01, time/batch = 15.8006s	
7847/33250 (epoch 11.800), train_loss = 1.15819805, grad/param norm = 1.5728e-01, time/batch = 15.7105s	
7848/33250 (epoch 11.802), train_loss = 1.03960506, grad/param norm = 1.3558e-01, time/batch = 15.7844s	
7849/33250 (epoch 11.803), train_loss = 1.08063020, grad/param norm = 1.4042e-01, time/batch = 15.5228s	
7850/33250 (epoch 11.805), train_loss = 1.15253807, grad/param norm = 1.5376e-01, time/batch = 15.4510s	
7851/33250 (epoch 11.806), train_loss = 1.14829626, grad/param norm = 1.5016e-01, time/batch = 15.8572s	
7852/33250 (epoch 11.808), train_loss = 1.07923506, grad/param norm = 1.4370e-01, time/batch = 15.9331s	
7853/33250 (epoch 11.809), train_loss = 0.99506679, grad/param norm = 1.5034e-01, time/batch = 15.9426s	
7854/33250 (epoch 11.811), train_loss = 1.00166181, grad/param norm = 1.3805e-01, time/batch = 15.6922s	
7855/33250 (epoch 11.812), train_loss = 1.18070088, grad/param norm = 1.5277e-01, time/batch = 15.8547s	
7856/33250 (epoch 11.814), train_loss = 1.09706422, grad/param norm = 1.4995e-01, time/batch = 15.9170s	
7857/33250 (epoch 11.815), train_loss = 1.17489072, grad/param norm = 1.5483e-01, time/batch = 15.8794s	
7858/33250 (epoch 11.817), train_loss = 1.09048949, grad/param norm = 1.5191e-01, time/batch = 15.7937s	
7859/33250 (epoch 11.818), train_loss = 1.01929222, grad/param norm = 1.4935e-01, time/batch = 15.7835s	
7860/33250 (epoch 11.820), train_loss = 1.12393690, grad/param norm = 1.8498e-01, time/batch = 15.8385s	
7861/33250 (epoch 11.821), train_loss = 1.04969722, grad/param norm = 1.4056e-01, time/batch = 16.0242s	
7862/33250 (epoch 11.823), train_loss = 1.41075595, grad/param norm = 1.7751e-01, time/batch = 15.7699s	
7863/33250 (epoch 11.824), train_loss = 1.06951433, grad/param norm = 1.5083e-01, time/batch = 15.7657s	
7864/33250 (epoch 11.826), train_loss = 1.14259587, grad/param norm = 1.6878e-01, time/batch = 15.8553s	
7865/33250 (epoch 11.827), train_loss = 0.86333265, grad/param norm = 1.2947e-01, time/batch = 15.9229s	
7866/33250 (epoch 11.829), train_loss = 1.10678798, grad/param norm = 1.7094e-01, time/batch = 15.6051s	
7867/33250 (epoch 11.830), train_loss = 1.21546950, grad/param norm = 1.7546e-01, time/batch = 15.7810s	
7868/33250 (epoch 11.832), train_loss = 1.09749290, grad/param norm = 1.4518e-01, time/batch = 15.8838s	
7869/33250 (epoch 11.833), train_loss = 1.16480095, grad/param norm = 1.6837e-01, time/batch = 16.0270s	
7870/33250 (epoch 11.835), train_loss = 1.03821532, grad/param norm = 1.7473e-01, time/batch = 16.0352s	
7871/33250 (epoch 11.836), train_loss = 1.08378360, grad/param norm = 1.3772e-01, time/batch = 16.0034s	
7872/33250 (epoch 11.838), train_loss = 1.05673201, grad/param norm = 1.5018e-01, time/batch = 15.7799s	
7873/33250 (epoch 11.839), train_loss = 1.04282070, grad/param norm = 1.5978e-01, time/batch = 15.8684s	
7874/33250 (epoch 11.841), train_loss = 0.97541338, grad/param norm = 1.2564e-01, time/batch = 15.9313s	
7875/33250 (epoch 11.842), train_loss = 1.29010747, grad/param norm = 1.5402e-01, time/batch = 16.0112s	
7876/33250 (epoch 11.844), train_loss = 1.23107474, grad/param norm = 1.7728e-01, time/batch = 15.6892s	
7877/33250 (epoch 11.845), train_loss = 1.34815859, grad/param norm = 1.6901e-01, time/batch = 15.6093s	
7878/33250 (epoch 11.847), train_loss = 1.26793482, grad/param norm = 1.5486e-01, time/batch = 16.0137s	
7879/33250 (epoch 11.848), train_loss = 1.43218715, grad/param norm = 1.7526e-01, time/batch = 15.7084s	
7880/33250 (epoch 11.850), train_loss = 1.22183163, grad/param norm = 1.5579e-01, time/batch = 15.9424s	
7881/33250 (epoch 11.851), train_loss = 1.03595353, grad/param norm = 1.5678e-01, time/batch = 15.8729s	
7882/33250 (epoch 11.853), train_loss = 1.18373320, grad/param norm = 1.7155e-01, time/batch = 15.7434s	
7883/33250 (epoch 11.854), train_loss = 1.00656935, grad/param norm = 1.3343e-01, time/batch = 15.6440s	
7884/33250 (epoch 11.856), train_loss = 1.05295095, grad/param norm = 1.5915e-01, time/batch = 15.7134s	
7885/33250 (epoch 11.857), train_loss = 0.93125468, grad/param norm = 1.3177e-01, time/batch = 15.6453s	
7886/33250 (epoch 11.859), train_loss = 0.93555330, grad/param norm = 1.3118e-01, time/batch = 15.8389s	
7887/33250 (epoch 11.860), train_loss = 1.10380019, grad/param norm = 1.2804e-01, time/batch = 15.6801s	
7888/33250 (epoch 11.862), train_loss = 0.97936121, grad/param norm = 1.2412e-01, time/batch = 15.6193s	
7889/33250 (epoch 11.863), train_loss = 1.03079508, grad/param norm = 1.5561e-01, time/batch = 15.7731s	
7890/33250 (epoch 11.865), train_loss = 1.15025482, grad/param norm = 1.4958e-01, time/batch = 15.6363s	
7891/33250 (epoch 11.866), train_loss = 1.05402992, grad/param norm = 1.4763e-01, time/batch = 15.6318s	
7892/33250 (epoch 11.868), train_loss = 1.25223182, grad/param norm = 1.7889e-01, time/batch = 15.7272s	
7893/33250 (epoch 11.869), train_loss = 1.18042935, grad/param norm = 1.6282e-01, time/batch = 15.5615s	
7894/33250 (epoch 11.871), train_loss = 0.88258457, grad/param norm = 1.4140e-01, time/batch = 15.9303s	
7895/33250 (epoch 11.872), train_loss = 1.13012682, grad/param norm = 1.7412e-01, time/batch = 15.7733s	
7896/33250 (epoch 11.874), train_loss = 1.00248880, grad/param norm = 1.5245e-01, time/batch = 15.8509s	
7897/33250 (epoch 11.875), train_loss = 1.01164300, grad/param norm = 1.7180e-01, time/batch = 15.8427s	
7898/33250 (epoch 11.877), train_loss = 1.19239375, grad/param norm = 1.5790e-01, time/batch = 16.0970s	
7899/33250 (epoch 11.878), train_loss = 1.13740340, grad/param norm = 1.4990e-01, time/batch = 15.7600s	
7900/33250 (epoch 11.880), train_loss = 1.10030010, grad/param norm = 1.7244e-01, time/batch = 15.6803s	
7901/33250 (epoch 11.881), train_loss = 1.32631139, grad/param norm = 1.8256e-01, time/batch = 15.9390s	
7902/33250 (epoch 11.883), train_loss = 1.10702326, grad/param norm = 1.4809e-01, time/batch = 15.9397s	
7903/33250 (epoch 11.884), train_loss = 1.11688179, grad/param norm = 1.6918e-01, time/batch = 15.9613s	
7904/33250 (epoch 11.886), train_loss = 1.00955733, grad/param norm = 1.3494e-01, time/batch = 15.4440s	
7905/33250 (epoch 11.887), train_loss = 1.05594986, grad/param norm = 1.4195e-01, time/batch = 15.6811s	
7906/33250 (epoch 11.889), train_loss = 1.02410468, grad/param norm = 1.2673e-01, time/batch = 15.5344s	
7907/33250 (epoch 11.890), train_loss = 0.92255214, grad/param norm = 1.2867e-01, time/batch = 15.8574s	
7908/33250 (epoch 11.892), train_loss = 1.16914140, grad/param norm = 1.4800e-01, time/batch = 15.7606s	
7909/33250 (epoch 11.893), train_loss = 1.19031314, grad/param norm = 1.6050e-01, time/batch = 15.8227s	
7910/33250 (epoch 11.895), train_loss = 1.07210926, grad/param norm = 1.5440e-01, time/batch = 15.7045s	
7911/33250 (epoch 11.896), train_loss = 1.18843999, grad/param norm = 1.6504e-01, time/batch = 16.0998s	
7912/33250 (epoch 11.898), train_loss = 1.08291730, grad/param norm = 1.6470e-01, time/batch = 16.1081s	
7913/33250 (epoch 11.899), train_loss = 1.00343230, grad/param norm = 1.3528e-01, time/batch = 16.1285s	
7914/33250 (epoch 11.901), train_loss = 0.94494187, grad/param norm = 1.3162e-01, time/batch = 15.8712s	
7915/33250 (epoch 11.902), train_loss = 1.06474970, grad/param norm = 1.3773e-01, time/batch = 16.0223s	
7916/33250 (epoch 11.904), train_loss = 1.00467831, grad/param norm = 1.3866e-01, time/batch = 15.8508s	
7917/33250 (epoch 11.905), train_loss = 1.02140617, grad/param norm = 1.3828e-01, time/batch = 15.8426s	
7918/33250 (epoch 11.907), train_loss = 1.00713485, grad/param norm = 1.4897e-01, time/batch = 15.9239s	
7919/33250 (epoch 11.908), train_loss = 1.09417266, grad/param norm = 1.3347e-01, time/batch = 15.6859s	
7920/33250 (epoch 11.910), train_loss = 1.17467483, grad/param norm = 1.5759e-01, time/batch = 15.7758s	
7921/33250 (epoch 11.911), train_loss = 0.92684770, grad/param norm = 1.3686e-01, time/batch = 16.1189s	
7922/33250 (epoch 11.913), train_loss = 1.02873860, grad/param norm = 1.4102e-01, time/batch = 15.9702s	
7923/33250 (epoch 11.914), train_loss = 0.91230284, grad/param norm = 1.4736e-01, time/batch = 15.8747s	
7924/33250 (epoch 11.916), train_loss = 0.99579097, grad/param norm = 1.2327e-01, time/batch = 15.8520s	
7925/33250 (epoch 11.917), train_loss = 1.02602743, grad/param norm = 1.3041e-01, time/batch = 15.9445s	
7926/33250 (epoch 11.919), train_loss = 1.02780179, grad/param norm = 1.5592e-01, time/batch = 15.6144s	
7927/33250 (epoch 11.920), train_loss = 1.12847891, grad/param norm = 1.6022e-01, time/batch = 15.8637s	
7928/33250 (epoch 11.922), train_loss = 1.11956675, grad/param norm = 1.5388e-01, time/batch = 15.7836s	
7929/33250 (epoch 11.923), train_loss = 1.07645177, grad/param norm = 1.6062e-01, time/batch = 15.6874s	
7930/33250 (epoch 11.925), train_loss = 1.02900903, grad/param norm = 1.4753e-01, time/batch = 15.8590s	
7931/33250 (epoch 11.926), train_loss = 1.02418585, grad/param norm = 1.4313e-01, time/batch = 15.9227s	
7932/33250 (epoch 11.928), train_loss = 1.06389517, grad/param norm = 1.5314e-01, time/batch = 15.7695s	
7933/33250 (epoch 11.929), train_loss = 0.85355505, grad/param norm = 1.1785e-01, time/batch = 15.8587s	
7934/33250 (epoch 11.931), train_loss = 1.14791539, grad/param norm = 1.5602e-01, time/batch = 15.7632s	
7935/33250 (epoch 11.932), train_loss = 1.11695710, grad/param norm = 1.6563e-01, time/batch = 15.9817s	
7936/33250 (epoch 11.934), train_loss = 1.01071845, grad/param norm = 1.3082e-01, time/batch = 15.7522s	
7937/33250 (epoch 11.935), train_loss = 1.02099615, grad/param norm = 1.5451e-01, time/batch = 15.7525s	
7938/33250 (epoch 11.937), train_loss = 1.11877291, grad/param norm = 1.7502e-01, time/batch = 15.5176s	
7939/33250 (epoch 11.938), train_loss = 1.13697930, grad/param norm = 1.5400e-01, time/batch = 15.8570s	
7940/33250 (epoch 11.940), train_loss = 1.05825647, grad/param norm = 1.5379e-01, time/batch = 15.5378s	
7941/33250 (epoch 11.941), train_loss = 1.10956731, grad/param norm = 1.5814e-01, time/batch = 15.8633s	
7942/33250 (epoch 11.943), train_loss = 1.26278637, grad/param norm = 1.5520e-01, time/batch = 15.7639s	
7943/33250 (epoch 11.944), train_loss = 0.99207824, grad/param norm = 1.3450e-01, time/batch = 15.8524s	
7944/33250 (epoch 11.946), train_loss = 1.24827848, grad/param norm = 1.7542e-01, time/batch = 15.8902s	
7945/33250 (epoch 11.947), train_loss = 0.99926400, grad/param norm = 1.5538e-01, time/batch = 15.7761s	
7946/33250 (epoch 11.949), train_loss = 1.22253470, grad/param norm = 1.5646e-01, time/batch = 15.7152s	
7947/33250 (epoch 11.950), train_loss = 1.13848974, grad/param norm = 1.4038e-01, time/batch = 15.8654s	
7948/33250 (epoch 11.952), train_loss = 1.05887765, grad/param norm = 1.5897e-01, time/batch = 15.8573s	
7949/33250 (epoch 11.953), train_loss = 1.17807301, grad/param norm = 1.5817e-01, time/batch = 15.9399s	
7950/33250 (epoch 11.955), train_loss = 1.19084873, grad/param norm = 1.5270e-01, time/batch = 16.0019s	
7951/33250 (epoch 11.956), train_loss = 1.17746236, grad/param norm = 1.8256e-01, time/batch = 15.7844s	
7952/33250 (epoch 11.958), train_loss = 1.00795824, grad/param norm = 1.5180e-01, time/batch = 15.6989s	
7953/33250 (epoch 11.959), train_loss = 1.01396710, grad/param norm = 1.4100e-01, time/batch = 15.7792s	
7954/33250 (epoch 11.961), train_loss = 1.28952524, grad/param norm = 1.5817e-01, time/batch = 15.8985s	
7955/33250 (epoch 11.962), train_loss = 1.12312417, grad/param norm = 1.4448e-01, time/batch = 15.5969s	
7956/33250 (epoch 11.964), train_loss = 1.29289171, grad/param norm = 1.6851e-01, time/batch = 15.7355s	
7957/33250 (epoch 11.965), train_loss = 1.16416077, grad/param norm = 2.0188e-01, time/batch = 15.6813s	
7958/33250 (epoch 11.967), train_loss = 1.09399399, grad/param norm = 1.6283e-01, time/batch = 15.8492s	
7959/33250 (epoch 11.968), train_loss = 1.32448087, grad/param norm = 1.4506e-01, time/batch = 15.6000s	
7960/33250 (epoch 11.970), train_loss = 1.41142605, grad/param norm = 2.0904e-01, time/batch = 15.6031s	
7961/33250 (epoch 11.971), train_loss = 1.25130199, grad/param norm = 1.6796e-01, time/batch = 15.5958s	
7962/33250 (epoch 11.973), train_loss = 1.04584773, grad/param norm = 1.5442e-01, time/batch = 16.0024s	
7963/33250 (epoch 11.974), train_loss = 1.16143232, grad/param norm = 1.6380e-01, time/batch = 15.6970s	
7964/33250 (epoch 11.976), train_loss = 1.08502550, grad/param norm = 1.7719e-01, time/batch = 15.7945s	
7965/33250 (epoch 11.977), train_loss = 1.02814400, grad/param norm = 1.5500e-01, time/batch = 15.7934s	
7966/33250 (epoch 11.979), train_loss = 1.10291603, grad/param norm = 1.5940e-01, time/batch = 15.7709s	
7967/33250 (epoch 11.980), train_loss = 1.09478434, grad/param norm = 1.3656e-01, time/batch = 15.8587s	
7968/33250 (epoch 11.982), train_loss = 0.93531658, grad/param norm = 1.2511e-01, time/batch = 15.6886s	
7969/33250 (epoch 11.983), train_loss = 1.13663023, grad/param norm = 1.6377e-01, time/batch = 15.7634s	
7970/33250 (epoch 11.985), train_loss = 1.02147795, grad/param norm = 1.4794e-01, time/batch = 15.6803s	
7971/33250 (epoch 11.986), train_loss = 1.18736286, grad/param norm = 1.6203e-01, time/batch = 15.9431s	
7972/33250 (epoch 11.988), train_loss = 1.21307421, grad/param norm = 1.6635e-01, time/batch = 15.8492s	
7973/33250 (epoch 11.989), train_loss = 1.21006923, grad/param norm = 1.6322e-01, time/batch = 15.7583s	
7974/33250 (epoch 11.991), train_loss = 1.12654174, grad/param norm = 1.7769e-01, time/batch = 15.7770s	
7975/33250 (epoch 11.992), train_loss = 1.08810513, grad/param norm = 1.5542e-01, time/batch = 15.8271s	
7976/33250 (epoch 11.994), train_loss = 1.02143385, grad/param norm = 1.5009e-01, time/batch = 15.8541s	
7977/33250 (epoch 11.995), train_loss = 1.11448859, grad/param norm = 1.8690e-01, time/batch = 15.6867s	
7978/33250 (epoch 11.997), train_loss = 0.80776064, grad/param norm = 1.3397e-01, time/batch = 16.0110s	
7979/33250 (epoch 11.998), train_loss = 1.09640864, grad/param norm = 1.3956e-01, time/batch = 15.6743s	
decayed learning rate by a factor 0.97 to 0.001825346	
7980/33250 (epoch 12.000), train_loss = 1.10195329, grad/param norm = 1.4336e-01, time/batch = 15.7720s	
7981/33250 (epoch 12.002), train_loss = 1.27148877, grad/param norm = 1.6723e-01, time/batch = 15.8472s	
7982/33250 (epoch 12.003), train_loss = 1.17829930, grad/param norm = 1.5207e-01, time/batch = 15.8602s	
7983/33250 (epoch 12.005), train_loss = 0.88940394, grad/param norm = 1.2897e-01, time/batch = 15.9433s	
7984/33250 (epoch 12.006), train_loss = 0.94287416, grad/param norm = 1.4117e-01, time/batch = 15.8484s	
7985/33250 (epoch 12.008), train_loss = 1.27242215, grad/param norm = 1.6296e-01, time/batch = 15.7838s	
7986/33250 (epoch 12.009), train_loss = 1.24600668, grad/param norm = 1.6470e-01, time/batch = 16.2675s	
7987/33250 (epoch 12.011), train_loss = 0.97750679, grad/param norm = 1.4139e-01, time/batch = 15.8564s	
7988/33250 (epoch 12.012), train_loss = 1.14185010, grad/param norm = 1.9070e-01, time/batch = 16.0191s	
7989/33250 (epoch 12.014), train_loss = 1.22705629, grad/param norm = 1.6209e-01, time/batch = 15.7654s	
7990/33250 (epoch 12.015), train_loss = 1.08509345, grad/param norm = 1.4443e-01, time/batch = 15.8542s	
7991/33250 (epoch 12.017), train_loss = 1.12381293, grad/param norm = 1.6662e-01, time/batch = 16.1658s	
7992/33250 (epoch 12.018), train_loss = 0.89411773, grad/param norm = 1.3813e-01, time/batch = 15.9344s	
7993/33250 (epoch 12.020), train_loss = 1.04479300, grad/param norm = 1.3713e-01, time/batch = 15.7633s	
7994/33250 (epoch 12.021), train_loss = 1.08184134, grad/param norm = 1.5035e-01, time/batch = 15.9109s	
7995/33250 (epoch 12.023), train_loss = 0.89943727, grad/param norm = 1.3898e-01, time/batch = 15.8564s	
7996/33250 (epoch 12.024), train_loss = 1.16699810, grad/param norm = 1.5381e-01, time/batch = 16.0242s	
7997/33250 (epoch 12.026), train_loss = 1.07438507, grad/param norm = 1.3967e-01, time/batch = 16.0052s	
7998/33250 (epoch 12.027), train_loss = 1.06142557, grad/param norm = 1.3825e-01, time/batch = 16.1361s	
7999/33250 (epoch 12.029), train_loss = 1.10447410, grad/param norm = 1.4793e-01, time/batch = 15.9517s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch12.03_1.4019.t7	
8000/33250 (epoch 12.030), train_loss = 1.08946139, grad/param norm = 1.6441e-01, time/batch = 15.9421s	
8001/33250 (epoch 12.032), train_loss = 1.58803587, grad/param norm = 2.0458e-01, time/batch = 28.8253s	
8002/33250 (epoch 12.033), train_loss = 1.03696947, grad/param norm = 1.5557e-01, time/batch = 17.4828s	
8003/33250 (epoch 12.035), train_loss = 1.03643853, grad/param norm = 1.5107e-01, time/batch = 15.8617s	
8004/33250 (epoch 12.036), train_loss = 1.16443742, grad/param norm = 1.5415e-01, time/batch = 15.7643s	
8005/33250 (epoch 12.038), train_loss = 1.04877389, grad/param norm = 1.4635e-01, time/batch = 15.8559s	
8006/33250 (epoch 12.039), train_loss = 0.98351217, grad/param norm = 1.3860e-01, time/batch = 16.1122s	
8007/33250 (epoch 12.041), train_loss = 1.09806406, grad/param norm = 1.5435e-01, time/batch = 15.9570s	
8008/33250 (epoch 12.042), train_loss = 0.92144290, grad/param norm = 1.2886e-01, time/batch = 15.9729s	
8009/33250 (epoch 12.044), train_loss = 1.23845443, grad/param norm = 1.6257e-01, time/batch = 16.0224s	
8010/33250 (epoch 12.045), train_loss = 1.20135666, grad/param norm = 1.5252e-01, time/batch = 15.8685s	
8011/33250 (epoch 12.047), train_loss = 1.17453013, grad/param norm = 1.5914e-01, time/batch = 15.9467s	
8012/33250 (epoch 12.048), train_loss = 1.25858627, grad/param norm = 1.8489e-01, time/batch = 15.6808s	
8013/33250 (epoch 12.050), train_loss = 1.08667409, grad/param norm = 1.4095e-01, time/batch = 15.6325s	
8014/33250 (epoch 12.051), train_loss = 1.07602930, grad/param norm = 1.3933e-01, time/batch = 15.4602s	
8015/33250 (epoch 12.053), train_loss = 1.14245534, grad/param norm = 1.5731e-01, time/batch = 15.6095s	
8016/33250 (epoch 12.054), train_loss = 0.91550222, grad/param norm = 1.3445e-01, time/batch = 15.8719s	
8017/33250 (epoch 12.056), train_loss = 0.96065339, grad/param norm = 1.3697e-01, time/batch = 15.7553s	
8018/33250 (epoch 12.057), train_loss = 1.13832473, grad/param norm = 1.4512e-01, time/batch = 15.8067s	
8019/33250 (epoch 12.059), train_loss = 1.05542869, grad/param norm = 1.4032e-01, time/batch = 16.0984s	
8020/33250 (epoch 12.060), train_loss = 1.17609966, grad/param norm = 1.7410e-01, time/batch = 15.8924s	
8021/33250 (epoch 12.062), train_loss = 1.24548923, grad/param norm = 1.5369e-01, time/batch = 15.8626s	
8022/33250 (epoch 12.063), train_loss = 1.22261185, grad/param norm = 1.5648e-01, time/batch = 15.8669s	
8023/33250 (epoch 12.065), train_loss = 1.07504885, grad/param norm = 1.3918e-01, time/batch = 15.8517s	
8024/33250 (epoch 12.066), train_loss = 1.15116573, grad/param norm = 1.5261e-01, time/batch = 15.7844s	
8025/33250 (epoch 12.068), train_loss = 1.05507226, grad/param norm = 1.4320e-01, time/batch = 15.6790s	
8026/33250 (epoch 12.069), train_loss = 1.09332713, grad/param norm = 1.4846e-01, time/batch = 15.5894s	
8027/33250 (epoch 12.071), train_loss = 0.97495483, grad/param norm = 1.4694e-01, time/batch = 15.7044s	
8028/33250 (epoch 12.072), train_loss = 0.97221849, grad/param norm = 1.3265e-01, time/batch = 15.7037s	
8029/33250 (epoch 12.074), train_loss = 1.14355448, grad/param norm = 1.5603e-01, time/batch = 15.8742s	
8030/33250 (epoch 12.075), train_loss = 0.99897140, grad/param norm = 1.3170e-01, time/batch = 15.6351s	
8031/33250 (epoch 12.077), train_loss = 1.06876544, grad/param norm = 1.5252e-01, time/batch = 15.9715s	
8032/33250 (epoch 12.078), train_loss = 1.07497140, grad/param norm = 1.4295e-01, time/batch = 15.7775s	
8033/33250 (epoch 12.080), train_loss = 1.12249480, grad/param norm = 1.6798e-01, time/batch = 15.8660s	
8034/33250 (epoch 12.081), train_loss = 1.14054905, grad/param norm = 1.5708e-01, time/batch = 16.0113s	
8035/33250 (epoch 12.083), train_loss = 1.18779258, grad/param norm = 1.4466e-01, time/batch = 15.7965s	
8036/33250 (epoch 12.084), train_loss = 1.09439868, grad/param norm = 1.5555e-01, time/batch = 15.7053s	
8037/33250 (epoch 12.086), train_loss = 1.04265420, grad/param norm = 1.3923e-01, time/batch = 15.8650s	
8038/33250 (epoch 12.087), train_loss = 0.95516785, grad/param norm = 1.4372e-01, time/batch = 15.9292s	
8039/33250 (epoch 12.089), train_loss = 1.12794213, grad/param norm = 1.5545e-01, time/batch = 15.5471s	
8040/33250 (epoch 12.090), train_loss = 1.07020321, grad/param norm = 1.4659e-01, time/batch = 15.6812s	
8041/33250 (epoch 12.092), train_loss = 0.98773797, grad/param norm = 1.2645e-01, time/batch = 15.8659s	
8042/33250 (epoch 12.093), train_loss = 1.11784933, grad/param norm = 1.4550e-01, time/batch = 15.8674s	
8043/33250 (epoch 12.095), train_loss = 1.04942157, grad/param norm = 1.4066e-01, time/batch = 15.6819s	
8044/33250 (epoch 12.096), train_loss = 0.90861491, grad/param norm = 1.4419e-01, time/batch = 15.6993s	
8045/33250 (epoch 12.098), train_loss = 0.99363167, grad/param norm = 1.5953e-01, time/batch = 15.9097s	
8046/33250 (epoch 12.099), train_loss = 0.81274880, grad/param norm = 1.3384e-01, time/batch = 15.6783s	
8047/33250 (epoch 12.101), train_loss = 1.04760283, grad/param norm = 1.3840e-01, time/batch = 15.7643s	
8048/33250 (epoch 12.102), train_loss = 0.97331866, grad/param norm = 1.4596e-01, time/batch = 15.3763s	
8049/33250 (epoch 12.104), train_loss = 0.87771239, grad/param norm = 1.3373e-01, time/batch = 15.7727s	
8050/33250 (epoch 12.105), train_loss = 0.99658008, grad/param norm = 1.4087e-01, time/batch = 15.5620s	
8051/33250 (epoch 12.107), train_loss = 0.89448904, grad/param norm = 1.3073e-01, time/batch = 15.9742s	
8052/33250 (epoch 12.108), train_loss = 1.07379403, grad/param norm = 1.6106e-01, time/batch = 15.9562s	
8053/33250 (epoch 12.110), train_loss = 0.86598261, grad/param norm = 1.3180e-01, time/batch = 16.0080s	
8054/33250 (epoch 12.111), train_loss = 1.04737802, grad/param norm = 1.4552e-01, time/batch = 15.7019s	
8055/33250 (epoch 12.113), train_loss = 1.06426157, grad/param norm = 1.4975e-01, time/batch = 15.6141s	
8056/33250 (epoch 12.114), train_loss = 0.96822103, grad/param norm = 1.4365e-01, time/batch = 15.7093s	
8057/33250 (epoch 12.116), train_loss = 1.08685467, grad/param norm = 1.4696e-01, time/batch = 16.0189s	
8058/33250 (epoch 12.117), train_loss = 1.05152915, grad/param norm = 1.4178e-01, time/batch = 15.7853s	
8059/33250 (epoch 12.119), train_loss = 1.00542020, grad/param norm = 1.3769e-01, time/batch = 16.0028s	
8060/33250 (epoch 12.120), train_loss = 0.82409419, grad/param norm = 1.2733e-01, time/batch = 15.7863s	
8061/33250 (epoch 12.122), train_loss = 1.19661956, grad/param norm = 1.4451e-01, time/batch = 15.9835s	
8062/33250 (epoch 12.123), train_loss = 1.09844120, grad/param norm = 1.4895e-01, time/batch = 15.8616s	
8063/33250 (epoch 12.125), train_loss = 0.90422322, grad/param norm = 1.4864e-01, time/batch = 15.9056s	
8064/33250 (epoch 12.126), train_loss = 1.06164837, grad/param norm = 1.5469e-01, time/batch = 16.0166s	
8065/33250 (epoch 12.128), train_loss = 0.99380642, grad/param norm = 1.3789e-01, time/batch = 15.5387s	
8066/33250 (epoch 12.129), train_loss = 1.04712878, grad/param norm = 1.4329e-01, time/batch = 15.9262s	
8067/33250 (epoch 12.131), train_loss = 1.04965459, grad/param norm = 1.4625e-01, time/batch = 15.8675s	
8068/33250 (epoch 12.132), train_loss = 1.04046404, grad/param norm = 1.5429e-01, time/batch = 15.8564s	
8069/33250 (epoch 12.134), train_loss = 1.05734074, grad/param norm = 1.4061e-01, time/batch = 15.6138s	
8070/33250 (epoch 12.135), train_loss = 1.10204095, grad/param norm = 1.4204e-01, time/batch = 15.9624s	
8071/33250 (epoch 12.137), train_loss = 0.96463261, grad/param norm = 1.4559e-01, time/batch = 15.8199s	
8072/33250 (epoch 12.138), train_loss = 0.99940741, grad/param norm = 1.2580e-01, time/batch = 15.7992s	
8073/33250 (epoch 12.140), train_loss = 0.82279629, grad/param norm = 1.2588e-01, time/batch = 15.8697s	
8074/33250 (epoch 12.141), train_loss = 1.32367909, grad/param norm = 1.9074e-01, time/batch = 15.8602s	
8075/33250 (epoch 12.143), train_loss = 0.83826164, grad/param norm = 1.5021e-01, time/batch = 15.6751s	
8076/33250 (epoch 12.144), train_loss = 1.01239308, grad/param norm = 1.3536e-01, time/batch = 15.7705s	
8077/33250 (epoch 12.146), train_loss = 0.97846929, grad/param norm = 1.3537e-01, time/batch = 15.6186s	
8078/33250 (epoch 12.147), train_loss = 0.97953068, grad/param norm = 1.4872e-01, time/batch = 16.0018s	
8079/33250 (epoch 12.149), train_loss = 1.01559921, grad/param norm = 1.4798e-01, time/batch = 15.6088s	
8080/33250 (epoch 12.150), train_loss = 0.96606130, grad/param norm = 1.4842e-01, time/batch = 15.7872s	
8081/33250 (epoch 12.152), train_loss = 0.92043344, grad/param norm = 1.5783e-01, time/batch = 16.4317s	
8082/33250 (epoch 12.153), train_loss = 1.23207712, grad/param norm = 1.5676e-01, time/batch = 15.8970s	
8083/33250 (epoch 12.155), train_loss = 1.09228930, grad/param norm = 1.8291e-01, time/batch = 15.6956s	
8084/33250 (epoch 12.156), train_loss = 1.27348747, grad/param norm = 1.5542e-01, time/batch = 15.6363s	
8085/33250 (epoch 12.158), train_loss = 1.29836878, grad/param norm = 1.7219e-01, time/batch = 15.7697s	
8086/33250 (epoch 12.159), train_loss = 1.07497493, grad/param norm = 1.5338e-01, time/batch = 15.6727s	
8087/33250 (epoch 12.161), train_loss = 1.10450932, grad/param norm = 1.6181e-01, time/batch = 15.6968s	
8088/33250 (epoch 12.162), train_loss = 0.94158476, grad/param norm = 1.3372e-01, time/batch = 15.6801s	
8089/33250 (epoch 12.164), train_loss = 1.08745218, grad/param norm = 1.6106e-01, time/batch = 15.5237s	
8090/33250 (epoch 12.165), train_loss = 1.15661812, grad/param norm = 1.6173e-01, time/batch = 15.7578s	
8091/33250 (epoch 12.167), train_loss = 1.21017324, grad/param norm = 1.6246e-01, time/batch = 15.8566s	
8092/33250 (epoch 12.168), train_loss = 0.90117045, grad/param norm = 1.2294e-01, time/batch = 15.7937s	
8093/33250 (epoch 12.170), train_loss = 1.02952720, grad/param norm = 1.4641e-01, time/batch = 15.6166s	
8094/33250 (epoch 12.171), train_loss = 1.03321085, grad/param norm = 1.4241e-01, time/batch = 15.6932s	
8095/33250 (epoch 12.173), train_loss = 1.02156576, grad/param norm = 1.4251e-01, time/batch = 15.7729s	
8096/33250 (epoch 12.174), train_loss = 1.05013055, grad/param norm = 1.4530e-01, time/batch = 15.7436s	
8097/33250 (epoch 12.176), train_loss = 1.07170868, grad/param norm = 1.4389e-01, time/batch = 15.7735s	
8098/33250 (epoch 12.177), train_loss = 0.99974631, grad/param norm = 1.5502e-01, time/batch = 15.8630s	
8099/33250 (epoch 12.179), train_loss = 0.98582456, grad/param norm = 1.5039e-01, time/batch = 15.8741s	
8100/33250 (epoch 12.180), train_loss = 0.88716569, grad/param norm = 1.2621e-01, time/batch = 15.7774s	
8101/33250 (epoch 12.182), train_loss = 0.99635683, grad/param norm = 1.6542e-01, time/batch = 15.8755s	
8102/33250 (epoch 12.183), train_loss = 1.20947813, grad/param norm = 1.6442e-01, time/batch = 15.7756s	
8103/33250 (epoch 12.185), train_loss = 1.15982626, grad/param norm = 1.7812e-01, time/batch = 15.7960s	
8104/33250 (epoch 12.186), train_loss = 1.07237446, grad/param norm = 1.5268e-01, time/batch = 15.7893s	
8105/33250 (epoch 12.188), train_loss = 1.18351334, grad/param norm = 1.7544e-01, time/batch = 15.5536s	
8106/33250 (epoch 12.189), train_loss = 0.88756584, grad/param norm = 1.5124e-01, time/batch = 15.7007s	
8107/33250 (epoch 12.191), train_loss = 0.98363834, grad/param norm = 1.4674e-01, time/batch = 15.9317s	
8108/33250 (epoch 12.192), train_loss = 0.98063592, grad/param norm = 1.3852e-01, time/batch = 15.8352s	
8109/33250 (epoch 12.194), train_loss = 0.99238878, grad/param norm = 1.4908e-01, time/batch = 15.6053s	
8110/33250 (epoch 12.195), train_loss = 1.23406720, grad/param norm = 1.4716e-01, time/batch = 15.8360s	
8111/33250 (epoch 12.197), train_loss = 1.00936563, grad/param norm = 1.3291e-01, time/batch = 15.8576s	
8112/33250 (epoch 12.198), train_loss = 1.18679009, grad/param norm = 1.6008e-01, time/batch = 15.8603s	
8113/33250 (epoch 12.200), train_loss = 1.06223823, grad/param norm = 1.5654e-01, time/batch = 15.8629s	
8114/33250 (epoch 12.202), train_loss = 0.96955161, grad/param norm = 1.3548e-01, time/batch = 15.7847s	
8115/33250 (epoch 12.203), train_loss = 1.00022017, grad/param norm = 1.4308e-01, time/batch = 15.7911s	
8116/33250 (epoch 12.205), train_loss = 1.09692133, grad/param norm = 1.5244e-01, time/batch = 15.9478s	
8117/33250 (epoch 12.206), train_loss = 1.12142567, grad/param norm = 1.5240e-01, time/batch = 15.9355s	
8118/33250 (epoch 12.208), train_loss = 1.22502892, grad/param norm = 1.7517e-01, time/batch = 15.3778s	
8119/33250 (epoch 12.209), train_loss = 1.00255652, grad/param norm = 1.4317e-01, time/batch = 15.6156s	
8120/33250 (epoch 12.211), train_loss = 1.16719996, grad/param norm = 1.5808e-01, time/batch = 15.8571s	
8121/33250 (epoch 12.212), train_loss = 1.31228986, grad/param norm = 1.5167e-01, time/batch = 16.0952s	
8122/33250 (epoch 12.214), train_loss = 1.04568362, grad/param norm = 1.3337e-01, time/batch = 15.7717s	
8123/33250 (epoch 12.215), train_loss = 1.33261279, grad/param norm = 1.9147e-01, time/batch = 15.6870s	
8124/33250 (epoch 12.217), train_loss = 1.22609003, grad/param norm = 1.7965e-01, time/batch = 15.7008s	
8125/33250 (epoch 12.218), train_loss = 1.15241975, grad/param norm = 1.3673e-01, time/batch = 15.8674s	
8126/33250 (epoch 12.220), train_loss = 1.14710213, grad/param norm = 1.5658e-01, time/batch = 15.8845s	
8127/33250 (epoch 12.221), train_loss = 1.31037730, grad/param norm = 1.7709e-01, time/batch = 15.9240s	
8128/33250 (epoch 12.223), train_loss = 1.06706344, grad/param norm = 1.4390e-01, time/batch = 15.6888s	
8129/33250 (epoch 12.224), train_loss = 1.17140187, grad/param norm = 1.7008e-01, time/batch = 15.9315s	
8130/33250 (epoch 12.226), train_loss = 1.25593157, grad/param norm = 1.6515e-01, time/batch = 15.6097s	
8131/33250 (epoch 12.227), train_loss = 1.11458774, grad/param norm = 1.5253e-01, time/batch = 15.8565s	
8132/33250 (epoch 12.229), train_loss = 1.11485928, grad/param norm = 1.4121e-01, time/batch = 15.9185s	
8133/33250 (epoch 12.230), train_loss = 1.01576933, grad/param norm = 1.5244e-01, time/batch = 15.7017s	
8134/33250 (epoch 12.232), train_loss = 1.01906237, grad/param norm = 1.3461e-01, time/batch = 15.7707s	
8135/33250 (epoch 12.233), train_loss = 0.99646230, grad/param norm = 1.3461e-01, time/batch = 15.9536s	
8136/33250 (epoch 12.235), train_loss = 1.21246988, grad/param norm = 1.4979e-01, time/batch = 15.7838s	
8137/33250 (epoch 12.236), train_loss = 1.01042104, grad/param norm = 1.6104e-01, time/batch = 15.8677s	
8138/33250 (epoch 12.238), train_loss = 1.15088683, grad/param norm = 1.6260e-01, time/batch = 15.7842s	
8139/33250 (epoch 12.239), train_loss = 1.23770151, grad/param norm = 1.7586e-01, time/batch = 15.6081s	
8140/33250 (epoch 12.241), train_loss = 1.17021313, grad/param norm = 1.7290e-01, time/batch = 16.0004s	
8141/33250 (epoch 12.242), train_loss = 1.16503422, grad/param norm = 1.4879e-01, time/batch = 15.7021s	
8142/33250 (epoch 12.244), train_loss = 1.19818438, grad/param norm = 1.6849e-01, time/batch = 15.8536s	
8143/33250 (epoch 12.245), train_loss = 1.08277280, grad/param norm = 1.4191e-01, time/batch = 15.6205s	
8144/33250 (epoch 12.247), train_loss = 1.11790620, grad/param norm = 1.5565e-01, time/batch = 15.8563s	
8145/33250 (epoch 12.248), train_loss = 1.33649286, grad/param norm = 1.8634e-01, time/batch = 15.6261s	
8146/33250 (epoch 12.250), train_loss = 1.17271979, grad/param norm = 1.4378e-01, time/batch = 15.6956s	
8147/33250 (epoch 12.251), train_loss = 1.10545104, grad/param norm = 1.4402e-01, time/batch = 15.7799s	
8148/33250 (epoch 12.253), train_loss = 0.98850426, grad/param norm = 1.2915e-01, time/batch = 15.9338s	
8149/33250 (epoch 12.254), train_loss = 1.01663016, grad/param norm = 1.4749e-01, time/batch = 15.6890s	
8150/33250 (epoch 12.256), train_loss = 1.11865083, grad/param norm = 1.3751e-01, time/batch = 15.6197s	
8151/33250 (epoch 12.257), train_loss = 1.23332128, grad/param norm = 1.4554e-01, time/batch = 15.9931s	
8152/33250 (epoch 12.259), train_loss = 1.23714434, grad/param norm = 1.6118e-01, time/batch = 15.6743s	
8153/33250 (epoch 12.260), train_loss = 0.99381599, grad/param norm = 1.4006e-01, time/batch = 15.6879s	
8154/33250 (epoch 12.262), train_loss = 1.12720643, grad/param norm = 1.4257e-01, time/batch = 15.5194s	
8155/33250 (epoch 12.263), train_loss = 1.01910748, grad/param norm = 1.5115e-01, time/batch = 15.7681s	
8156/33250 (epoch 12.265), train_loss = 1.18276272, grad/param norm = 1.4913e-01, time/batch = 15.8874s	
8157/33250 (epoch 12.266), train_loss = 1.08161426, grad/param norm = 1.5514e-01, time/batch = 15.7657s	
8158/33250 (epoch 12.268), train_loss = 1.00645296, grad/param norm = 1.3873e-01, time/batch = 15.7070s	
8159/33250 (epoch 12.269), train_loss = 0.88678021, grad/param norm = 1.3361e-01, time/batch = 15.8643s	
8160/33250 (epoch 12.271), train_loss = 1.04754099, grad/param norm = 1.4352e-01, time/batch = 15.9377s	
8161/33250 (epoch 12.272), train_loss = 0.92442377, grad/param norm = 1.2045e-01, time/batch = 15.7055s	
8162/33250 (epoch 12.274), train_loss = 0.83215713, grad/param norm = 1.2888e-01, time/batch = 15.7693s	
8163/33250 (epoch 12.275), train_loss = 0.98089980, grad/param norm = 1.2795e-01, time/batch = 15.6891s	
8164/33250 (epoch 12.277), train_loss = 0.87665480, grad/param norm = 1.3699e-01, time/batch = 15.8396s	
8165/33250 (epoch 12.278), train_loss = 0.99380278, grad/param norm = 1.3102e-01, time/batch = 15.9035s	
8166/33250 (epoch 12.280), train_loss = 0.93566053, grad/param norm = 1.3235e-01, time/batch = 15.8321s	
8167/33250 (epoch 12.281), train_loss = 1.07049090, grad/param norm = 1.3383e-01, time/batch = 15.9447s	
8168/33250 (epoch 12.283), train_loss = 1.13676592, grad/param norm = 1.6484e-01, time/batch = 15.9881s	
8169/33250 (epoch 12.284), train_loss = 0.98940101, grad/param norm = 1.4270e-01, time/batch = 15.7504s	
8170/33250 (epoch 12.286), train_loss = 1.13900397, grad/param norm = 1.5933e-01, time/batch = 15.8193s	
8171/33250 (epoch 12.287), train_loss = 0.92098962, grad/param norm = 1.2544e-01, time/batch = 15.6561s	
8172/33250 (epoch 12.289), train_loss = 0.89366230, grad/param norm = 1.4248e-01, time/batch = 15.8285s	
8173/33250 (epoch 12.290), train_loss = 1.07739165, grad/param norm = 1.3148e-01, time/batch = 15.7711s	
8174/33250 (epoch 12.292), train_loss = 1.11740291, grad/param norm = 1.5856e-01, time/batch = 15.9249s	
8175/33250 (epoch 12.293), train_loss = 1.20921121, grad/param norm = 1.7319e-01, time/batch = 15.8546s	
8176/33250 (epoch 12.295), train_loss = 1.12739153, grad/param norm = 1.4994e-01, time/batch = 15.6857s	
8177/33250 (epoch 12.296), train_loss = 1.07770542, grad/param norm = 1.3777e-01, time/batch = 15.9550s	
8178/33250 (epoch 12.298), train_loss = 0.89261547, grad/param norm = 1.2265e-01, time/batch = 16.0095s	
8179/33250 (epoch 12.299), train_loss = 0.84753845, grad/param norm = 1.4030e-01, time/batch = 15.6412s	
8180/33250 (epoch 12.301), train_loss = 1.13595380, grad/param norm = 1.4380e-01, time/batch = 15.8957s	
8181/33250 (epoch 12.302), train_loss = 1.10268677, grad/param norm = 1.5196e-01, time/batch = 16.0194s	
8182/33250 (epoch 12.304), train_loss = 1.00545326, grad/param norm = 1.3454e-01, time/batch = 15.8588s	
8183/33250 (epoch 12.305), train_loss = 1.06797138, grad/param norm = 1.4420e-01, time/batch = 15.7772s	
8184/33250 (epoch 12.307), train_loss = 1.14072013, grad/param norm = 1.4802e-01, time/batch = 15.4491s	
8185/33250 (epoch 12.308), train_loss = 1.33797223, grad/param norm = 1.7969e-01, time/batch = 15.7525s	
8186/33250 (epoch 12.310), train_loss = 1.06606978, grad/param norm = 1.5335e-01, time/batch = 15.7900s	
8187/33250 (epoch 12.311), train_loss = 1.20331141, grad/param norm = 1.5578e-01, time/batch = 15.7710s	
8188/33250 (epoch 12.313), train_loss = 0.89903232, grad/param norm = 1.4329e-01, time/batch = 16.0330s	
8189/33250 (epoch 12.314), train_loss = 1.06578379, grad/param norm = 1.4574e-01, time/batch = 15.9407s	
8190/33250 (epoch 12.316), train_loss = 1.23824207, grad/param norm = 1.7384e-01, time/batch = 15.8436s	
8191/33250 (epoch 12.317), train_loss = 0.96070618, grad/param norm = 1.3749e-01, time/batch = 15.9272s	
8192/33250 (epoch 12.319), train_loss = 1.18242138, grad/param norm = 1.7103e-01, time/batch = 15.8519s	
8193/33250 (epoch 12.320), train_loss = 1.22512967, grad/param norm = 1.9246e-01, time/batch = 15.9414s	
8194/33250 (epoch 12.322), train_loss = 1.26464268, grad/param norm = 1.7293e-01, time/batch = 15.6160s	
8195/33250 (epoch 12.323), train_loss = 1.30919020, grad/param norm = 1.7809e-01, time/batch = 15.6133s	
8196/33250 (epoch 12.325), train_loss = 1.12033344, grad/param norm = 1.7089e-01, time/batch = 15.8491s	
8197/33250 (epoch 12.326), train_loss = 1.27489635, grad/param norm = 1.5619e-01, time/batch = 15.8515s	
8198/33250 (epoch 12.328), train_loss = 1.03175963, grad/param norm = 1.5883e-01, time/batch = 15.8677s	
8199/33250 (epoch 12.329), train_loss = 1.10879055, grad/param norm = 1.6114e-01, time/batch = 15.8059s	
8200/33250 (epoch 12.331), train_loss = 1.06445892, grad/param norm = 1.5627e-01, time/batch = 15.8731s	
8201/33250 (epoch 12.332), train_loss = 1.04226175, grad/param norm = 1.4262e-01, time/batch = 15.9747s	
8202/33250 (epoch 12.334), train_loss = 1.21889546, grad/param norm = 1.4013e-01, time/batch = 16.0084s	
8203/33250 (epoch 12.335), train_loss = 0.79963969, grad/param norm = 1.3117e-01, time/batch = 15.9450s	
8204/33250 (epoch 12.337), train_loss = 1.10429674, grad/param norm = 1.4582e-01, time/batch = 16.0993s	
8205/33250 (epoch 12.338), train_loss = 1.20524159, grad/param norm = 1.8351e-01, time/batch = 15.8585s	
8206/33250 (epoch 12.340), train_loss = 1.06526756, grad/param norm = 1.4243e-01, time/batch = 15.5340s	
8207/33250 (epoch 12.341), train_loss = 1.00387521, grad/param norm = 1.5760e-01, time/batch = 15.7662s	
8208/33250 (epoch 12.343), train_loss = 1.05746008, grad/param norm = 1.5104e-01, time/batch = 15.8329s	
8209/33250 (epoch 12.344), train_loss = 1.07003476, grad/param norm = 1.4824e-01, time/batch = 15.6244s	
8210/33250 (epoch 12.346), train_loss = 0.91208114, grad/param norm = 1.3794e-01, time/batch = 16.0295s	
8211/33250 (epoch 12.347), train_loss = 1.35061131, grad/param norm = 1.6826e-01, time/batch = 15.7897s	
8212/33250 (epoch 12.349), train_loss = 1.03155475, grad/param norm = 1.5349e-01, time/batch = 15.8034s	
8213/33250 (epoch 12.350), train_loss = 1.06858232, grad/param norm = 1.4596e-01, time/batch = 15.8631s	
8214/33250 (epoch 12.352), train_loss = 0.95441557, grad/param norm = 1.4744e-01, time/batch = 15.6226s	
8215/33250 (epoch 12.353), train_loss = 1.03760491, grad/param norm = 1.3995e-01, time/batch = 15.6799s	
8216/33250 (epoch 12.355), train_loss = 1.04642149, grad/param norm = 1.5702e-01, time/batch = 15.9404s	
8217/33250 (epoch 12.356), train_loss = 0.99267123, grad/param norm = 1.5724e-01, time/batch = 15.8428s	
8218/33250 (epoch 12.358), train_loss = 1.00640618, grad/param norm = 1.3576e-01, time/batch = 15.6115s	
8219/33250 (epoch 12.359), train_loss = 1.02008476, grad/param norm = 1.3233e-01, time/batch = 15.8435s	
8220/33250 (epoch 12.361), train_loss = 1.24966663, grad/param norm = 1.6751e-01, time/batch = 15.8864s	
8221/33250 (epoch 12.362), train_loss = 1.06706185, grad/param norm = 1.4583e-01, time/batch = 15.8110s	
8222/33250 (epoch 12.364), train_loss = 1.16921048, grad/param norm = 1.6325e-01, time/batch = 15.8036s	
8223/33250 (epoch 12.365), train_loss = 1.05363072, grad/param norm = 1.4244e-01, time/batch = 15.6889s	
8224/33250 (epoch 12.367), train_loss = 1.05798551, grad/param norm = 1.3818e-01, time/batch = 15.7670s	
8225/33250 (epoch 12.368), train_loss = 1.06877714, grad/param norm = 1.5161e-01, time/batch = 15.7063s	
8226/33250 (epoch 12.370), train_loss = 0.93096238, grad/param norm = 1.2698e-01, time/batch = 17.0263s	
8227/33250 (epoch 12.371), train_loss = 1.19902523, grad/param norm = 1.6164e-01, time/batch = 1.2255s	
8228/33250 (epoch 12.373), train_loss = 1.00776826, grad/param norm = 1.3304e-01, time/batch = 0.6988s	
8229/33250 (epoch 12.374), train_loss = 1.15691417, grad/param norm = 1.8143e-01, time/batch = 0.7032s	
8230/33250 (epoch 12.376), train_loss = 1.04327376, grad/param norm = 1.5279e-01, time/batch = 0.7046s	
8231/33250 (epoch 12.377), train_loss = 0.98223684, grad/param norm = 1.8992e-01, time/batch = 0.7036s	
8232/33250 (epoch 12.379), train_loss = 0.99211742, grad/param norm = 1.5309e-01, time/batch = 0.7119s	
8233/33250 (epoch 12.380), train_loss = 1.12007721, grad/param norm = 1.8123e-01, time/batch = 0.9616s	
8234/33250 (epoch 12.382), train_loss = 1.19175973, grad/param norm = 1.6997e-01, time/batch = 1.0020s	
8235/33250 (epoch 12.383), train_loss = 0.96774144, grad/param norm = 1.4348e-01, time/batch = 1.0060s	
8236/33250 (epoch 12.385), train_loss = 0.92261441, grad/param norm = 1.5193e-01, time/batch = 1.0173s	
8237/33250 (epoch 12.386), train_loss = 0.92576879, grad/param norm = 1.3567e-01, time/batch = 1.0175s	
8238/33250 (epoch 12.388), train_loss = 0.99403841, grad/param norm = 1.5356e-01, time/batch = 1.7783s	
8239/33250 (epoch 12.389), train_loss = 1.03642513, grad/param norm = 1.5600e-01, time/batch = 1.9196s	
8240/33250 (epoch 12.391), train_loss = 1.07339964, grad/param norm = 1.5028e-01, time/batch = 5.1191s	
8241/33250 (epoch 12.392), train_loss = 1.17564210, grad/param norm = 1.6534e-01, time/batch = 15.9412s	
8242/33250 (epoch 12.394), train_loss = 1.24222060, grad/param norm = 1.7166e-01, time/batch = 15.6141s	
8243/33250 (epoch 12.395), train_loss = 1.16259794, grad/param norm = 1.4355e-01, time/batch = 15.7724s	
8244/33250 (epoch 12.397), train_loss = 1.18706785, grad/param norm = 1.5620e-01, time/batch = 15.7849s	
8245/33250 (epoch 12.398), train_loss = 1.00645605, grad/param norm = 1.4919e-01, time/batch = 15.8087s	
8246/33250 (epoch 12.400), train_loss = 0.97851450, grad/param norm = 1.4106e-01, time/batch = 15.7841s	
8247/33250 (epoch 12.402), train_loss = 0.89702962, grad/param norm = 1.4278e-01, time/batch = 15.8566s	
8248/33250 (epoch 12.403), train_loss = 1.00862015, grad/param norm = 1.7339e-01, time/batch = 16.0270s	
8249/33250 (epoch 12.405), train_loss = 0.98124457, grad/param norm = 1.4644e-01, time/batch = 15.9526s	
8250/33250 (epoch 12.406), train_loss = 1.12597505, grad/param norm = 1.5078e-01, time/batch = 15.6775s	
8251/33250 (epoch 12.408), train_loss = 1.21841141, grad/param norm = 1.6646e-01, time/batch = 16.1091s	
8252/33250 (epoch 12.409), train_loss = 1.15624842, grad/param norm = 1.7623e-01, time/batch = 15.9469s	
8253/33250 (epoch 12.411), train_loss = 0.78125406, grad/param norm = 1.1789e-01, time/batch = 16.0224s	
8254/33250 (epoch 12.412), train_loss = 0.91075441, grad/param norm = 1.5287e-01, time/batch = 15.8417s	
8255/33250 (epoch 12.414), train_loss = 1.10175972, grad/param norm = 1.6057e-01, time/batch = 16.1283s	
8256/33250 (epoch 12.415), train_loss = 1.20547124, grad/param norm = 1.6098e-01, time/batch = 15.8841s	
8257/33250 (epoch 12.417), train_loss = 1.15211142, grad/param norm = 1.6080e-01, time/batch = 15.9437s	
8258/33250 (epoch 12.418), train_loss = 1.33897459, grad/param norm = 1.7797e-01, time/batch = 15.7626s	
8259/33250 (epoch 12.420), train_loss = 1.20201720, grad/param norm = 1.6378e-01, time/batch = 16.1828s	
8260/33250 (epoch 12.421), train_loss = 0.99953367, grad/param norm = 1.6349e-01, time/batch = 15.8499s	
8261/33250 (epoch 12.423), train_loss = 1.13932158, grad/param norm = 1.7249e-01, time/batch = 16.0196s	
8262/33250 (epoch 12.424), train_loss = 1.32169645, grad/param norm = 2.0835e-01, time/batch = 15.6074s	
8263/33250 (epoch 12.426), train_loss = 0.97347625, grad/param norm = 1.2979e-01, time/batch = 15.8566s	
8264/33250 (epoch 12.427), train_loss = 1.00213585, grad/param norm = 1.5151e-01, time/batch = 15.9476s	
8265/33250 (epoch 12.429), train_loss = 1.14840419, grad/param norm = 1.7305e-01, time/batch = 15.7865s	
8266/33250 (epoch 12.430), train_loss = 0.98122464, grad/param norm = 1.5622e-01, time/batch = 16.1344s	
8267/33250 (epoch 12.432), train_loss = 1.07606747, grad/param norm = 1.3391e-01, time/batch = 15.7646s	
8268/33250 (epoch 12.433), train_loss = 1.01077292, grad/param norm = 1.6395e-01, time/batch = 15.7872s	
8269/33250 (epoch 12.435), train_loss = 1.13396083, grad/param norm = 1.9187e-01, time/batch = 15.8652s	
8270/33250 (epoch 12.436), train_loss = 1.01001725, grad/param norm = 1.5270e-01, time/batch = 15.6999s	
8271/33250 (epoch 12.438), train_loss = 1.14025969, grad/param norm = 1.4791e-01, time/batch = 16.0173s	
8272/33250 (epoch 12.439), train_loss = 1.09018850, grad/param norm = 1.4047e-01, time/batch = 16.0185s	
8273/33250 (epoch 12.441), train_loss = 1.06103812, grad/param norm = 1.4279e-01, time/batch = 15.6864s	
8274/33250 (epoch 12.442), train_loss = 0.98281676, grad/param norm = 1.4644e-01, time/batch = 15.7749s	
8275/33250 (epoch 12.444), train_loss = 0.97996431, grad/param norm = 1.3617e-01, time/batch = 15.7943s	
8276/33250 (epoch 12.445), train_loss = 1.07362624, grad/param norm = 1.4218e-01, time/batch = 15.9668s	
8277/33250 (epoch 12.447), train_loss = 1.11586226, grad/param norm = 1.5866e-01, time/batch = 15.9411s	
8278/33250 (epoch 12.448), train_loss = 1.03971016, grad/param norm = 1.2777e-01, time/batch = 15.6261s	
8279/33250 (epoch 12.450), train_loss = 1.25104046, grad/param norm = 1.7259e-01, time/batch = 15.8374s	
8280/33250 (epoch 12.451), train_loss = 1.13715509, grad/param norm = 1.5860e-01, time/batch = 15.8656s	
8281/33250 (epoch 12.453), train_loss = 0.95178851, grad/param norm = 1.3753e-01, time/batch = 15.6174s	
8282/33250 (epoch 12.454), train_loss = 1.23358546, grad/param norm = 1.6693e-01, time/batch = 15.8908s	
8283/33250 (epoch 12.456), train_loss = 1.22333127, grad/param norm = 1.5983e-01, time/batch = 15.7866s	
8284/33250 (epoch 12.457), train_loss = 1.04507285, grad/param norm = 1.5861e-01, time/batch = 15.8529s	
8285/33250 (epoch 12.459), train_loss = 1.07735326, grad/param norm = 1.3464e-01, time/batch = 15.9482s	
8286/33250 (epoch 12.460), train_loss = 1.17015283, grad/param norm = 1.6429e-01, time/batch = 15.7244s	
8287/33250 (epoch 12.462), train_loss = 1.00407878, grad/param norm = 1.3965e-01, time/batch = 15.8015s	
8288/33250 (epoch 12.463), train_loss = 0.97200403, grad/param norm = 1.3710e-01, time/batch = 15.9424s	
8289/33250 (epoch 12.465), train_loss = 0.86430296, grad/param norm = 1.1437e-01, time/batch = 15.7586s	
8290/33250 (epoch 12.466), train_loss = 0.84455366, grad/param norm = 1.1383e-01, time/batch = 15.5138s	
8291/33250 (epoch 12.468), train_loss = 0.93985623, grad/param norm = 1.2296e-01, time/batch = 15.7806s	
8292/33250 (epoch 12.469), train_loss = 1.05451794, grad/param norm = 1.4809e-01, time/batch = 15.8506s	
8293/33250 (epoch 12.471), train_loss = 1.16628138, grad/param norm = 1.3740e-01, time/batch = 15.5354s	
8294/33250 (epoch 12.472), train_loss = 1.05172553, grad/param norm = 1.8387e-01, time/batch = 15.7775s	
8295/33250 (epoch 12.474), train_loss = 1.29134487, grad/param norm = 1.8765e-01, time/batch = 16.2096s	
8296/33250 (epoch 12.475), train_loss = 1.08596702, grad/param norm = 1.4219e-01, time/batch = 16.1069s	
8297/33250 (epoch 12.477), train_loss = 1.05650314, grad/param norm = 1.4034e-01, time/batch = 15.8563s	
8298/33250 (epoch 12.478), train_loss = 1.02241154, grad/param norm = 1.4277e-01, time/batch = 16.0218s	
8299/33250 (epoch 12.480), train_loss = 1.31409917, grad/param norm = 1.7181e-01, time/batch = 15.7841s	
8300/33250 (epoch 12.481), train_loss = 1.06262664, grad/param norm = 1.4705e-01, time/batch = 15.9316s	
8301/33250 (epoch 12.483), train_loss = 1.11418401, grad/param norm = 1.3553e-01, time/batch = 15.9252s	
8302/33250 (epoch 12.484), train_loss = 0.97307916, grad/param norm = 1.4007e-01, time/batch = 15.8555s	
8303/33250 (epoch 12.486), train_loss = 0.87434034, grad/param norm = 1.3505e-01, time/batch = 15.9367s	
8304/33250 (epoch 12.487), train_loss = 1.01767994, grad/param norm = 1.5770e-01, time/batch = 15.9391s	
8305/33250 (epoch 12.489), train_loss = 1.16523755, grad/param norm = 1.9808e-01, time/batch = 15.8721s	
8306/33250 (epoch 12.490), train_loss = 1.14751294, grad/param norm = 1.6522e-01, time/batch = 15.7053s	
8307/33250 (epoch 12.492), train_loss = 1.12383671, grad/param norm = 1.5883e-01, time/batch = 15.7880s	
8308/33250 (epoch 12.493), train_loss = 1.07950993, grad/param norm = 1.7133e-01, time/batch = 15.7208s	
8309/33250 (epoch 12.495), train_loss = 1.09498154, grad/param norm = 1.4287e-01, time/batch = 15.7862s	
8310/33250 (epoch 12.496), train_loss = 1.03391494, grad/param norm = 1.2617e-01, time/batch = 15.7730s	
8311/33250 (epoch 12.498), train_loss = 1.17822769, grad/param norm = 1.6075e-01, time/batch = 16.0108s	
8312/33250 (epoch 12.499), train_loss = 1.04682743, grad/param norm = 1.4300e-01, time/batch = 15.6049s	
8313/33250 (epoch 12.501), train_loss = 1.03748885, grad/param norm = 1.6436e-01, time/batch = 15.6163s	
8314/33250 (epoch 12.502), train_loss = 1.02904558, grad/param norm = 1.3000e-01, time/batch = 15.7648s	
8315/33250 (epoch 12.504), train_loss = 1.21819611, grad/param norm = 1.8072e-01, time/batch = 15.7155s	
8316/33250 (epoch 12.505), train_loss = 0.86834013, grad/param norm = 1.2097e-01, time/batch = 15.7964s	
8317/33250 (epoch 12.507), train_loss = 1.02802563, grad/param norm = 1.4578e-01, time/batch = 15.9377s	
8318/33250 (epoch 12.508), train_loss = 1.00221116, grad/param norm = 1.4359e-01, time/batch = 15.9587s	
8319/33250 (epoch 12.510), train_loss = 0.87377672, grad/param norm = 1.3300e-01, time/batch = 16.0255s	
8320/33250 (epoch 12.511), train_loss = 1.06179386, grad/param norm = 1.4835e-01, time/batch = 15.8616s	
8321/33250 (epoch 12.513), train_loss = 1.23084484, grad/param norm = 1.4875e-01, time/batch = 15.8616s	
8322/33250 (epoch 12.514), train_loss = 0.99519072, grad/param norm = 1.3313e-01, time/batch = 15.8547s	
8323/33250 (epoch 12.516), train_loss = 0.99770948, grad/param norm = 1.4318e-01, time/batch = 15.9296s	
8324/33250 (epoch 12.517), train_loss = 1.05586068, grad/param norm = 1.4288e-01, time/batch = 15.9401s	
8325/33250 (epoch 12.519), train_loss = 0.92598961, grad/param norm = 1.1870e-01, time/batch = 15.8714s	
8326/33250 (epoch 12.520), train_loss = 1.33932626, grad/param norm = 1.7304e-01, time/batch = 16.0405s	
8327/33250 (epoch 12.522), train_loss = 1.12974776, grad/param norm = 1.5485e-01, time/batch = 15.8090s	
8328/33250 (epoch 12.523), train_loss = 1.01095265, grad/param norm = 1.4079e-01, time/batch = 15.9003s	
8329/33250 (epoch 12.525), train_loss = 0.94444525, grad/param norm = 1.5290e-01, time/batch = 15.9174s	
8330/33250 (epoch 12.526), train_loss = 0.93978705, grad/param norm = 1.4083e-01, time/batch = 15.8689s	
8331/33250 (epoch 12.528), train_loss = 1.03118323, grad/param norm = 1.3790e-01, time/batch = 15.8612s	
8332/33250 (epoch 12.529), train_loss = 0.98722182, grad/param norm = 1.4732e-01, time/batch = 15.8713s	
8333/33250 (epoch 12.531), train_loss = 0.93150223, grad/param norm = 1.2833e-01, time/batch = 16.0940s	
8334/33250 (epoch 12.532), train_loss = 1.13330810, grad/param norm = 1.4741e-01, time/batch = 15.8660s	
8335/33250 (epoch 12.534), train_loss = 0.94625042, grad/param norm = 1.2612e-01, time/batch = 15.9489s	
8336/33250 (epoch 12.535), train_loss = 1.03509918, grad/param norm = 1.4112e-01, time/batch = 16.0365s	
8337/33250 (epoch 12.537), train_loss = 1.12178534, grad/param norm = 1.4712e-01, time/batch = 15.9464s	
8338/33250 (epoch 12.538), train_loss = 1.14078519, grad/param norm = 1.5096e-01, time/batch = 15.8735s	
8339/33250 (epoch 12.540), train_loss = 1.22227753, grad/param norm = 1.3985e-01, time/batch = 15.7073s	
8340/33250 (epoch 12.541), train_loss = 1.20148812, grad/param norm = 1.6061e-01, time/batch = 15.7670s	
8341/33250 (epoch 12.543), train_loss = 1.14455074, grad/param norm = 1.4970e-01, time/batch = 16.0960s	
8342/33250 (epoch 12.544), train_loss = 1.01657083, grad/param norm = 1.4747e-01, time/batch = 15.8666s	
8343/33250 (epoch 12.546), train_loss = 1.05862524, grad/param norm = 1.6623e-01, time/batch = 15.6861s	
8344/33250 (epoch 12.547), train_loss = 1.01693673, grad/param norm = 1.5171e-01, time/batch = 15.8472s	
8345/33250 (epoch 12.549), train_loss = 1.14100154, grad/param norm = 1.5803e-01, time/batch = 15.7704s	
8346/33250 (epoch 12.550), train_loss = 1.02653106, grad/param norm = 1.4992e-01, time/batch = 15.8781s	
8347/33250 (epoch 12.552), train_loss = 1.09571029, grad/param norm = 1.4513e-01, time/batch = 15.8897s	
8348/33250 (epoch 12.553), train_loss = 0.99813836, grad/param norm = 1.4645e-01, time/batch = 15.9676s	
8349/33250 (epoch 12.555), train_loss = 1.06177389, grad/param norm = 1.2605e-01, time/batch = 15.7317s	
8350/33250 (epoch 12.556), train_loss = 1.19159525, grad/param norm = 1.7502e-01, time/batch = 15.7033s	
8351/33250 (epoch 12.558), train_loss = 1.17407947, grad/param norm = 1.5402e-01, time/batch = 15.9425s	
8352/33250 (epoch 12.559), train_loss = 0.96541774, grad/param norm = 1.4471e-01, time/batch = 15.8469s	
8353/33250 (epoch 12.561), train_loss = 1.00322169, grad/param norm = 1.5177e-01, time/batch = 15.7729s	
8354/33250 (epoch 12.562), train_loss = 1.22453411, grad/param norm = 1.6798e-01, time/batch = 15.8447s	
8355/33250 (epoch 12.564), train_loss = 1.27718786, grad/param norm = 1.6714e-01, time/batch = 15.6931s	
8356/33250 (epoch 12.565), train_loss = 1.25534550, grad/param norm = 1.7929e-01, time/batch = 15.7836s	
8357/33250 (epoch 12.567), train_loss = 1.19549119, grad/param norm = 1.4941e-01, time/batch = 15.8086s	
8358/33250 (epoch 12.568), train_loss = 1.06926658, grad/param norm = 1.4767e-01, time/batch = 15.8072s	
8359/33250 (epoch 12.570), train_loss = 1.20974260, grad/param norm = 1.7123e-01, time/batch = 16.0182s	
8360/33250 (epoch 12.571), train_loss = 1.27518936, grad/param norm = 1.5298e-01, time/batch = 16.0171s	
8361/33250 (epoch 12.573), train_loss = 1.12277475, grad/param norm = 1.5459e-01, time/batch = 15.8689s	
8362/33250 (epoch 12.574), train_loss = 0.98814034, grad/param norm = 1.4075e-01, time/batch = 15.7949s	
8363/33250 (epoch 12.576), train_loss = 1.12368032, grad/param norm = 1.4678e-01, time/batch = 15.8630s	
8364/33250 (epoch 12.577), train_loss = 1.06448675, grad/param norm = 1.4377e-01, time/batch = 15.8608s	
8365/33250 (epoch 12.579), train_loss = 0.98164123, grad/param norm = 1.7068e-01, time/batch = 16.0199s	
8366/33250 (epoch 12.580), train_loss = 1.01583319, grad/param norm = 1.2643e-01, time/batch = 15.6245s	
8367/33250 (epoch 12.582), train_loss = 1.05778147, grad/param norm = 1.4280e-01, time/batch = 15.6025s	
8368/33250 (epoch 12.583), train_loss = 1.11738556, grad/param norm = 1.4064e-01, time/batch = 15.9455s	
8369/33250 (epoch 12.585), train_loss = 1.15992946, grad/param norm = 1.5165e-01, time/batch = 15.9507s	
8370/33250 (epoch 12.586), train_loss = 1.04727298, grad/param norm = 1.8009e-01, time/batch = 15.8855s	
8371/33250 (epoch 12.588), train_loss = 1.08614211, grad/param norm = 1.3889e-01, time/batch = 16.0075s	
8372/33250 (epoch 12.589), train_loss = 1.12892179, grad/param norm = 1.5172e-01, time/batch = 15.7727s	
8373/33250 (epoch 12.591), train_loss = 1.13275282, grad/param norm = 1.6906e-01, time/batch = 15.9223s	
8374/33250 (epoch 12.592), train_loss = 1.07649659, grad/param norm = 1.3778e-01, time/batch = 15.7758s	
8375/33250 (epoch 12.594), train_loss = 1.26371102, grad/param norm = 1.7561e-01, time/batch = 15.9519s	
8376/33250 (epoch 12.595), train_loss = 1.15234931, grad/param norm = 1.5640e-01, time/batch = 15.9428s	
8377/33250 (epoch 12.597), train_loss = 0.93426632, grad/param norm = 1.3345e-01, time/batch = 15.8765s	
8378/33250 (epoch 12.598), train_loss = 1.07237593, grad/param norm = 1.5418e-01, time/batch = 15.7156s	
8379/33250 (epoch 12.600), train_loss = 1.07357846, grad/param norm = 1.7060e-01, time/batch = 15.6360s	
8380/33250 (epoch 12.602), train_loss = 1.12591801, grad/param norm = 1.7516e-01, time/batch = 15.7689s	
8381/33250 (epoch 12.603), train_loss = 1.12005995, grad/param norm = 1.5411e-01, time/batch = 15.8703s	
8382/33250 (epoch 12.605), train_loss = 1.08330962, grad/param norm = 1.5411e-01, time/batch = 15.8571s	
8383/33250 (epoch 12.606), train_loss = 1.12181709, grad/param norm = 1.5454e-01, time/batch = 15.9497s	
8384/33250 (epoch 12.608), train_loss = 1.09047410, grad/param norm = 1.4816e-01, time/batch = 15.7499s	
8385/33250 (epoch 12.609), train_loss = 0.96951354, grad/param norm = 1.4501e-01, time/batch = 15.6830s	
8386/33250 (epoch 12.611), train_loss = 1.12550331, grad/param norm = 1.5264e-01, time/batch = 15.9293s	
8387/33250 (epoch 12.612), train_loss = 1.10528547, grad/param norm = 1.6393e-01, time/batch = 15.8575s	
8388/33250 (epoch 12.614), train_loss = 1.31442909, grad/param norm = 1.7429e-01, time/batch = 15.8545s	
8389/33250 (epoch 12.615), train_loss = 1.19498908, grad/param norm = 1.5912e-01, time/batch = 15.7963s	
8390/33250 (epoch 12.617), train_loss = 1.45323406, grad/param norm = 1.8196e-01, time/batch = 15.9544s	
8391/33250 (epoch 12.618), train_loss = 1.39623470, grad/param norm = 2.1008e-01, time/batch = 16.2161s	
8392/33250 (epoch 12.620), train_loss = 1.21461511, grad/param norm = 1.7051e-01, time/batch = 16.0031s	
8393/33250 (epoch 12.621), train_loss = 1.05939792, grad/param norm = 1.4617e-01, time/batch = 15.8620s	
8394/33250 (epoch 12.623), train_loss = 1.00608057, grad/param norm = 1.5253e-01, time/batch = 15.8684s	
8395/33250 (epoch 12.624), train_loss = 1.05398143, grad/param norm = 1.5790e-01, time/batch = 15.7027s	
8396/33250 (epoch 12.626), train_loss = 1.04414872, grad/param norm = 1.6504e-01, time/batch = 15.9150s	
8397/33250 (epoch 12.627), train_loss = 1.01649136, grad/param norm = 1.4208e-01, time/batch = 15.8547s	
8398/33250 (epoch 12.629), train_loss = 1.12899904, grad/param norm = 1.7165e-01, time/batch = 16.0267s	
8399/33250 (epoch 12.630), train_loss = 1.06914799, grad/param norm = 1.8093e-01, time/batch = 15.8835s	
8400/33250 (epoch 12.632), train_loss = 0.89415120, grad/param norm = 1.2554e-01, time/batch = 15.7902s	
8401/33250 (epoch 12.633), train_loss = 1.14504791, grad/param norm = 1.5285e-01, time/batch = 16.0454s	
8402/33250 (epoch 12.635), train_loss = 0.97412865, grad/param norm = 1.4026e-01, time/batch = 16.0356s	
8403/33250 (epoch 12.636), train_loss = 0.98897874, grad/param norm = 1.3713e-01, time/batch = 15.9421s	
8404/33250 (epoch 12.638), train_loss = 1.02648607, grad/param norm = 1.4268e-01, time/batch = 15.8590s	
8405/33250 (epoch 12.639), train_loss = 0.93756872, grad/param norm = 1.4191e-01, time/batch = 16.0221s	
8406/33250 (epoch 12.641), train_loss = 0.97111005, grad/param norm = 1.3138e-01, time/batch = 15.7769s	
8407/33250 (epoch 12.642), train_loss = 0.90576950, grad/param norm = 1.4593e-01, time/batch = 15.8568s	
8408/33250 (epoch 12.644), train_loss = 0.81307086, grad/param norm = 1.2679e-01, time/batch = 16.0072s	
8409/33250 (epoch 12.645), train_loss = 1.19375047, grad/param norm = 1.7626e-01, time/batch = 15.9349s	
8410/33250 (epoch 12.647), train_loss = 0.93883170, grad/param norm = 1.4475e-01, time/batch = 16.0421s	
8411/33250 (epoch 12.648), train_loss = 1.01554763, grad/param norm = 1.4907e-01, time/batch = 16.0249s	
8412/33250 (epoch 12.650), train_loss = 1.19935035, grad/param norm = 1.6186e-01, time/batch = 16.0783s	
8413/33250 (epoch 12.651), train_loss = 1.09696146, grad/param norm = 1.7504e-01, time/batch = 15.9479s	
8414/33250 (epoch 12.653), train_loss = 0.95798857, grad/param norm = 1.4436e-01, time/batch = 15.8779s	
8415/33250 (epoch 12.654), train_loss = 1.00632897, grad/param norm = 1.3624e-01, time/batch = 15.7775s	
8416/33250 (epoch 12.656), train_loss = 1.14242326, grad/param norm = 1.5738e-01, time/batch = 15.9419s	
8417/33250 (epoch 12.657), train_loss = 0.86416031, grad/param norm = 1.4191e-01, time/batch = 15.6944s	
8418/33250 (epoch 12.659), train_loss = 1.03909059, grad/param norm = 1.5271e-01, time/batch = 15.6984s	
8419/33250 (epoch 12.660), train_loss = 1.05825278, grad/param norm = 1.4975e-01, time/batch = 15.9464s	
8420/33250 (epoch 12.662), train_loss = 1.09660078, grad/param norm = 1.4823e-01, time/batch = 15.9566s	
8421/33250 (epoch 12.663), train_loss = 0.99632300, grad/param norm = 1.5199e-01, time/batch = 15.9758s	
8422/33250 (epoch 12.665), train_loss = 1.11243497, grad/param norm = 1.4751e-01, time/batch = 16.3031s	
8423/33250 (epoch 12.666), train_loss = 1.03374102, grad/param norm = 1.5151e-01, time/batch = 16.0313s	
8424/33250 (epoch 12.668), train_loss = 1.24226538, grad/param norm = 1.5889e-01, time/batch = 15.7070s	
8425/33250 (epoch 12.669), train_loss = 1.11910917, grad/param norm = 1.5527e-01, time/batch = 15.9291s	
8426/33250 (epoch 12.671), train_loss = 1.01254436, grad/param norm = 1.7171e-01, time/batch = 15.6963s	
8427/33250 (epoch 12.672), train_loss = 1.19316498, grad/param norm = 1.5867e-01, time/batch = 15.7605s	
8428/33250 (epoch 12.674), train_loss = 1.02586796, grad/param norm = 1.4118e-01, time/batch = 15.7659s	
8429/33250 (epoch 12.675), train_loss = 1.05645016, grad/param norm = 1.4104e-01, time/batch = 15.6674s	
8430/33250 (epoch 12.677), train_loss = 1.18962369, grad/param norm = 1.5824e-01, time/batch = 15.9416s	
8431/33250 (epoch 12.678), train_loss = 1.07576942, grad/param norm = 1.6230e-01, time/batch = 16.1771s	
8432/33250 (epoch 12.680), train_loss = 1.19350885, grad/param norm = 2.0793e-01, time/batch = 15.9767s	
8433/33250 (epoch 12.681), train_loss = 0.93542219, grad/param norm = 1.3812e-01, time/batch = 15.8836s	
8434/33250 (epoch 12.683), train_loss = 1.05886848, grad/param norm = 1.5453e-01, time/batch = 16.0304s	
8435/33250 (epoch 12.684), train_loss = 0.97503823, grad/param norm = 1.6578e-01, time/batch = 15.9479s	
8436/33250 (epoch 12.686), train_loss = 0.96231829, grad/param norm = 1.4288e-01, time/batch = 15.7980s	
8437/33250 (epoch 12.687), train_loss = 1.02510892, grad/param norm = 1.4379e-01, time/batch = 15.7801s	
8438/33250 (epoch 12.689), train_loss = 1.01058453, grad/param norm = 1.5180e-01, time/batch = 15.6888s	
8439/33250 (epoch 12.690), train_loss = 1.11974705, grad/param norm = 1.5192e-01, time/batch = 15.7805s	
8440/33250 (epoch 12.692), train_loss = 1.06188389, grad/param norm = 1.5834e-01, time/batch = 15.4464s	
8441/33250 (epoch 12.693), train_loss = 1.11850994, grad/param norm = 1.3996e-01, time/batch = 16.0401s	
8442/33250 (epoch 12.695), train_loss = 1.09994019, grad/param norm = 1.4908e-01, time/batch = 15.8800s	
8443/33250 (epoch 12.696), train_loss = 1.09785700, grad/param norm = 1.4371e-01, time/batch = 16.0548s	
8444/33250 (epoch 12.698), train_loss = 0.98944285, grad/param norm = 1.5543e-01, time/batch = 15.7893s	
8445/33250 (epoch 12.699), train_loss = 1.28621478, grad/param norm = 1.6283e-01, time/batch = 16.0182s	
8446/33250 (epoch 12.701), train_loss = 1.04556339, grad/param norm = 1.3722e-01, time/batch = 15.8375s	
8447/33250 (epoch 12.702), train_loss = 1.05079970, grad/param norm = 1.6284e-01, time/batch = 15.7869s	
8448/33250 (epoch 12.704), train_loss = 1.27426421, grad/param norm = 1.8428e-01, time/batch = 15.9289s	
8449/33250 (epoch 12.705), train_loss = 0.95447340, grad/param norm = 1.3675e-01, time/batch = 15.6993s	
8450/33250 (epoch 12.707), train_loss = 0.87587075, grad/param norm = 1.3020e-01, time/batch = 15.9389s	
8451/33250 (epoch 12.708), train_loss = 1.13773634, grad/param norm = 1.5149e-01, time/batch = 16.0003s	
8452/33250 (epoch 12.710), train_loss = 1.13619099, grad/param norm = 1.5283e-01, time/batch = 15.8722s	
8453/33250 (epoch 12.711), train_loss = 1.01598979, grad/param norm = 1.6653e-01, time/batch = 15.6280s	
8454/33250 (epoch 12.713), train_loss = 1.13677875, grad/param norm = 1.6468e-01, time/batch = 15.8820s	
8455/33250 (epoch 12.714), train_loss = 1.07081592, grad/param norm = 1.5089e-01, time/batch = 15.7754s	
8456/33250 (epoch 12.716), train_loss = 1.18734227, grad/param norm = 1.6785e-01, time/batch = 15.6172s	
8457/33250 (epoch 12.717), train_loss = 0.99423374, grad/param norm = 1.3759e-01, time/batch = 15.6820s	
8458/33250 (epoch 12.719), train_loss = 1.04418662, grad/param norm = 1.4558e-01, time/batch = 15.6939s	
8459/33250 (epoch 12.720), train_loss = 1.30111735, grad/param norm = 1.6371e-01, time/batch = 15.8607s	
8460/33250 (epoch 12.722), train_loss = 0.96495841, grad/param norm = 1.3536e-01, time/batch = 15.6140s	
8461/33250 (epoch 12.723), train_loss = 0.86111532, grad/param norm = 1.2262e-01, time/batch = 15.9288s	
8462/33250 (epoch 12.725), train_loss = 0.91513532, grad/param norm = 1.2274e-01, time/batch = 15.8818s	
8463/33250 (epoch 12.726), train_loss = 1.03390554, grad/param norm = 1.3444e-01, time/batch = 16.0436s	
8464/33250 (epoch 12.728), train_loss = 1.11518681, grad/param norm = 1.4877e-01, time/batch = 15.8977s	
8465/33250 (epoch 12.729), train_loss = 1.21675994, grad/param norm = 1.5743e-01, time/batch = 29.5684s	
8466/33250 (epoch 12.731), train_loss = 1.00900149, grad/param norm = 1.4279e-01, time/batch = 15.6836s	
8467/33250 (epoch 12.732), train_loss = 0.95187539, grad/param norm = 1.3347e-01, time/batch = 15.6148s	
8468/33250 (epoch 12.734), train_loss = 1.08435367, grad/param norm = 1.5272e-01, time/batch = 15.6024s	
8469/33250 (epoch 12.735), train_loss = 1.07795725, grad/param norm = 1.4893e-01, time/batch = 15.6951s	
8470/33250 (epoch 12.737), train_loss = 1.06678681, grad/param norm = 1.2889e-01, time/batch = 15.5338s	
8471/33250 (epoch 12.738), train_loss = 1.07286432, grad/param norm = 1.5381e-01, time/batch = 15.7551s	
8472/33250 (epoch 12.740), train_loss = 1.21063782, grad/param norm = 1.5442e-01, time/batch = 15.6251s	
8473/33250 (epoch 12.741), train_loss = 1.16389314, grad/param norm = 1.5506e-01, time/batch = 15.7080s	
8474/33250 (epoch 12.743), train_loss = 1.03911789, grad/param norm = 1.4007e-01, time/batch = 15.6540s	
8475/33250 (epoch 12.744), train_loss = 1.04833196, grad/param norm = 1.5134e-01, time/batch = 15.8481s	
8476/33250 (epoch 12.746), train_loss = 1.03354955, grad/param norm = 1.3468e-01, time/batch = 15.7634s	
8477/33250 (epoch 12.747), train_loss = 1.02001384, grad/param norm = 1.5618e-01, time/batch = 15.6185s	
8478/33250 (epoch 12.749), train_loss = 1.20138596, grad/param norm = 1.7483e-01, time/batch = 15.3670s	
8479/33250 (epoch 12.750), train_loss = 1.14330568, grad/param norm = 1.6255e-01, time/batch = 15.6810s	
8480/33250 (epoch 12.752), train_loss = 0.99609955, grad/param norm = 1.3407e-01, time/batch = 15.6975s	
8481/33250 (epoch 12.753), train_loss = 1.05514747, grad/param norm = 1.4783e-01, time/batch = 15.6881s	
8482/33250 (epoch 12.755), train_loss = 1.04180897, grad/param norm = 1.4933e-01, time/batch = 15.8759s	
8483/33250 (epoch 12.756), train_loss = 1.14513206, grad/param norm = 1.5075e-01, time/batch = 15.7647s	
8484/33250 (epoch 12.758), train_loss = 1.19662934, grad/param norm = 1.5717e-01, time/batch = 15.5491s	
8485/33250 (epoch 12.759), train_loss = 0.96995571, grad/param norm = 1.3691e-01, time/batch = 15.9157s	
8486/33250 (epoch 12.761), train_loss = 1.02380868, grad/param norm = 1.4139e-01, time/batch = 15.9469s	
8487/33250 (epoch 12.762), train_loss = 1.18897587, grad/param norm = 1.5016e-01, time/batch = 15.8537s	
8488/33250 (epoch 12.764), train_loss = 0.98234717, grad/param norm = 1.7076e-01, time/batch = 15.7708s	
8489/33250 (epoch 12.765), train_loss = 1.10944827, grad/param norm = 1.5996e-01, time/batch = 15.7801s	
8490/33250 (epoch 12.767), train_loss = 0.88087927, grad/param norm = 1.3930e-01, time/batch = 15.7788s	
8491/33250 (epoch 12.768), train_loss = 0.93363940, grad/param norm = 1.5490e-01, time/batch = 15.7774s	
8492/33250 (epoch 12.770), train_loss = 1.13756821, grad/param norm = 1.7156e-01, time/batch = 16.0287s	
8493/33250 (epoch 12.771), train_loss = 1.13533076, grad/param norm = 1.6091e-01, time/batch = 15.8911s	
8494/33250 (epoch 12.773), train_loss = 1.03584314, grad/param norm = 1.5495e-01, time/batch = 15.7827s	
8495/33250 (epoch 12.774), train_loss = 0.90752940, grad/param norm = 1.4992e-01, time/batch = 15.9472s	
8496/33250 (epoch 12.776), train_loss = 1.01214785, grad/param norm = 1.5115e-01, time/batch = 15.7990s	
8497/33250 (epoch 12.777), train_loss = 1.17131017, grad/param norm = 1.7097e-01, time/batch = 15.8701s	
8498/33250 (epoch 12.779), train_loss = 1.04157300, grad/param norm = 1.5383e-01, time/batch = 15.6837s	
8499/33250 (epoch 12.780), train_loss = 1.25981250, grad/param norm = 1.8489e-01, time/batch = 15.9311s	
8500/33250 (epoch 12.782), train_loss = 1.12055630, grad/param norm = 1.4816e-01, time/batch = 15.7857s	
8501/33250 (epoch 12.783), train_loss = 0.88667077, grad/param norm = 1.4166e-01, time/batch = 15.8534s	
8502/33250 (epoch 12.785), train_loss = 0.96120021, grad/param norm = 1.4596e-01, time/batch = 16.0745s	
8503/33250 (epoch 12.786), train_loss = 1.14793886, grad/param norm = 1.5715e-01, time/batch = 15.9657s	
8504/33250 (epoch 12.788), train_loss = 1.15860771, grad/param norm = 1.4934e-01, time/batch = 16.1119s	
8505/33250 (epoch 12.789), train_loss = 1.17655998, grad/param norm = 1.7077e-01, time/batch = 15.9770s	
8506/33250 (epoch 12.791), train_loss = 1.24344427, grad/param norm = 1.6323e-01, time/batch = 15.8629s	
8507/33250 (epoch 12.792), train_loss = 1.31529374, grad/param norm = 1.5846e-01, time/batch = 15.7803s	
8508/33250 (epoch 12.794), train_loss = 1.06662211, grad/param norm = 1.5746e-01, time/batch = 15.7700s	
8509/33250 (epoch 12.795), train_loss = 1.13643492, grad/param norm = 1.7575e-01, time/batch = 15.8560s	
8510/33250 (epoch 12.797), train_loss = 1.18993307, grad/param norm = 1.7707e-01, time/batch = 15.9854s	
8511/33250 (epoch 12.798), train_loss = 1.09620824, grad/param norm = 1.7914e-01, time/batch = 15.6919s	
8512/33250 (epoch 12.800), train_loss = 1.12696796, grad/param norm = 1.5241e-01, time/batch = 15.6970s	
8513/33250 (epoch 12.802), train_loss = 1.01605958, grad/param norm = 1.3051e-01, time/batch = 16.0226s	
8514/33250 (epoch 12.803), train_loss = 1.05779771, grad/param norm = 1.4246e-01, time/batch = 15.8806s	
8515/33250 (epoch 12.805), train_loss = 1.13146532, grad/param norm = 1.5813e-01, time/batch = 16.0482s	
8516/33250 (epoch 12.806), train_loss = 1.12427970, grad/param norm = 1.5309e-01, time/batch = 15.9766s	
8517/33250 (epoch 12.808), train_loss = 1.06057879, grad/param norm = 1.5120e-01, time/batch = 15.9520s	
8518/33250 (epoch 12.809), train_loss = 0.97862621, grad/param norm = 1.4661e-01, time/batch = 15.7770s	
8519/33250 (epoch 12.811), train_loss = 0.98734390, grad/param norm = 1.3678e-01, time/batch = 15.8712s	
8520/33250 (epoch 12.812), train_loss = 1.16241867, grad/param norm = 1.5739e-01, time/batch = 15.9411s	
8521/33250 (epoch 12.814), train_loss = 1.07287569, grad/param norm = 1.4802e-01, time/batch = 16.0097s	
8522/33250 (epoch 12.815), train_loss = 1.14263015, grad/param norm = 1.4692e-01, time/batch = 15.7062s	
8523/33250 (epoch 12.817), train_loss = 1.06711309, grad/param norm = 1.4878e-01, time/batch = 15.9138s	
8524/33250 (epoch 12.818), train_loss = 0.99385238, grad/param norm = 1.4323e-01, time/batch = 15.9587s	
8525/33250 (epoch 12.820), train_loss = 1.09516708, grad/param norm = 1.5348e-01, time/batch = 15.9470s	
8526/33250 (epoch 12.821), train_loss = 1.02034738, grad/param norm = 1.3438e-01, time/batch = 16.0339s	
8527/33250 (epoch 12.823), train_loss = 1.39493999, grad/param norm = 1.8770e-01, time/batch = 15.7204s	
8528/33250 (epoch 12.824), train_loss = 1.04231524, grad/param norm = 1.4967e-01, time/batch = 15.9334s	
8529/33250 (epoch 12.826), train_loss = 1.11985929, grad/param norm = 1.5749e-01, time/batch = 15.8602s	
8530/33250 (epoch 12.827), train_loss = 0.85440415, grad/param norm = 1.3406e-01, time/batch = 15.7037s	
8531/33250 (epoch 12.829), train_loss = 1.09013714, grad/param norm = 1.7580e-01, time/batch = 15.8802s	
8532/33250 (epoch 12.830), train_loss = 1.20244082, grad/param norm = 1.8930e-01, time/batch = 15.8464s	
8533/33250 (epoch 12.832), train_loss = 1.07781236, grad/param norm = 1.3856e-01, time/batch = 15.8399s	
8534/33250 (epoch 12.833), train_loss = 1.12657292, grad/param norm = 1.6220e-01, time/batch = 15.8927s	
8535/33250 (epoch 12.835), train_loss = 1.00604178, grad/param norm = 1.7719e-01, time/batch = 15.7870s	
8536/33250 (epoch 12.836), train_loss = 1.06044874, grad/param norm = 1.4097e-01, time/batch = 15.8802s	
8537/33250 (epoch 12.838), train_loss = 1.04500939, grad/param norm = 1.5203e-01, time/batch = 15.7977s	
8538/33250 (epoch 12.839), train_loss = 1.03765895, grad/param norm = 1.6740e-01, time/batch = 15.7640s	
8539/33250 (epoch 12.841), train_loss = 0.96592561, grad/param norm = 1.4163e-01, time/batch = 15.7693s	
8540/33250 (epoch 12.842), train_loss = 1.26287028, grad/param norm = 1.5098e-01, time/batch = 16.0236s	
8541/33250 (epoch 12.844), train_loss = 1.21241833, grad/param norm = 1.8311e-01, time/batch = 16.1080s	
8542/33250 (epoch 12.845), train_loss = 1.32068330, grad/param norm = 1.7350e-01, time/batch = 16.2500s	
8543/33250 (epoch 12.847), train_loss = 1.23632433, grad/param norm = 1.5622e-01, time/batch = 15.9405s	
8544/33250 (epoch 12.848), train_loss = 1.41134460, grad/param norm = 1.7660e-01, time/batch = 15.9731s	
8545/33250 (epoch 12.850), train_loss = 1.19639172, grad/param norm = 1.6073e-01, time/batch = 15.8723s	
8546/33250 (epoch 12.851), train_loss = 1.00222251, grad/param norm = 1.5266e-01, time/batch = 15.9402s	
8547/33250 (epoch 12.853), train_loss = 1.17195206, grad/param norm = 1.7304e-01, time/batch = 15.8779s	
8548/33250 (epoch 12.854), train_loss = 0.98620948, grad/param norm = 1.3645e-01, time/batch = 15.6894s	
8549/33250 (epoch 12.856), train_loss = 1.02133229, grad/param norm = 1.6291e-01, time/batch = 15.7763s	
8550/33250 (epoch 12.857), train_loss = 0.90574278, grad/param norm = 1.3169e-01, time/batch = 15.7697s	
8551/33250 (epoch 12.859), train_loss = 0.92065909, grad/param norm = 1.3189e-01, time/batch = 16.0993s	
8552/33250 (epoch 12.860), train_loss = 1.07522379, grad/param norm = 1.3153e-01, time/batch = 15.7786s	
8553/33250 (epoch 12.862), train_loss = 0.96050552, grad/param norm = 1.2452e-01, time/batch = 15.5920s	
8554/33250 (epoch 12.863), train_loss = 1.00265332, grad/param norm = 1.5806e-01, time/batch = 15.9515s	
8555/33250 (epoch 12.865), train_loss = 1.13176758, grad/param norm = 1.4626e-01, time/batch = 16.0627s	
8556/33250 (epoch 12.866), train_loss = 1.03404112, grad/param norm = 1.6059e-01, time/batch = 15.6344s	
8557/33250 (epoch 12.868), train_loss = 1.22544827, grad/param norm = 1.8060e-01, time/batch = 15.7150s	
8558/33250 (epoch 12.869), train_loss = 1.14715961, grad/param norm = 1.6158e-01, time/batch = 15.8347s	
8559/33250 (epoch 12.871), train_loss = 0.86131283, grad/param norm = 1.4093e-01, time/batch = 15.8627s	
8560/33250 (epoch 12.872), train_loss = 1.10263804, grad/param norm = 1.5003e-01, time/batch = 15.7603s	
8561/33250 (epoch 12.874), train_loss = 0.97422036, grad/param norm = 1.4097e-01, time/batch = 15.7709s	
8562/33250 (epoch 12.875), train_loss = 0.98311180, grad/param norm = 1.4908e-01, time/batch = 15.9256s	
8563/33250 (epoch 12.877), train_loss = 1.18085502, grad/param norm = 1.4916e-01, time/batch = 15.7043s	
8564/33250 (epoch 12.878), train_loss = 1.11479073, grad/param norm = 1.5201e-01, time/batch = 15.7072s	
8565/33250 (epoch 12.880), train_loss = 1.07861503, grad/param norm = 1.6732e-01, time/batch = 15.8024s	
8566/33250 (epoch 12.881), train_loss = 1.27891763, grad/param norm = 1.7683e-01, time/batch = 15.8971s	
8567/33250 (epoch 12.883), train_loss = 1.08905377, grad/param norm = 1.4690e-01, time/batch = 15.7816s	
8568/33250 (epoch 12.884), train_loss = 1.09222304, grad/param norm = 1.7116e-01, time/batch = 15.7231s	
8569/33250 (epoch 12.886), train_loss = 0.98461546, grad/param norm = 1.3281e-01, time/batch = 15.6087s	
8570/33250 (epoch 12.887), train_loss = 1.04145148, grad/param norm = 1.4554e-01, time/batch = 15.7020s	
8571/33250 (epoch 12.889), train_loss = 1.00486946, grad/param norm = 1.3446e-01, time/batch = 15.9641s	
8572/33250 (epoch 12.890), train_loss = 0.89229994, grad/param norm = 1.2264e-01, time/batch = 15.9367s	
8573/33250 (epoch 12.892), train_loss = 1.13875351, grad/param norm = 1.5834e-01, time/batch = 15.9228s	
8574/33250 (epoch 12.893), train_loss = 1.15593893, grad/param norm = 1.5671e-01, time/batch = 15.8683s	
8575/33250 (epoch 12.895), train_loss = 1.04289086, grad/param norm = 1.5213e-01, time/batch = 16.0216s	
8576/33250 (epoch 12.896), train_loss = 1.15370465, grad/param norm = 1.6580e-01, time/batch = 15.8950s	
8577/33250 (epoch 12.898), train_loss = 1.06006831, grad/param norm = 1.5149e-01, time/batch = 15.7558s	
8578/33250 (epoch 12.899), train_loss = 0.99025853, grad/param norm = 1.5479e-01, time/batch = 15.8789s	
8579/33250 (epoch 12.901), train_loss = 0.92710388, grad/param norm = 1.2994e-01, time/batch = 15.9296s	
8580/33250 (epoch 12.902), train_loss = 1.04478885, grad/param norm = 1.3654e-01, time/batch = 15.8607s	
8581/33250 (epoch 12.904), train_loss = 0.98475226, grad/param norm = 1.3488e-01, time/batch = 16.1135s	
8582/33250 (epoch 12.905), train_loss = 1.00785381, grad/param norm = 1.3891e-01, time/batch = 15.7096s	
8583/33250 (epoch 12.907), train_loss = 0.98705344, grad/param norm = 1.4363e-01, time/batch = 15.7878s	
8584/33250 (epoch 12.908), train_loss = 1.06536563, grad/param norm = 1.3348e-01, time/batch = 15.6899s	
8585/33250 (epoch 12.910), train_loss = 1.14750637, grad/param norm = 1.6168e-01, time/batch = 15.8706s	
8586/33250 (epoch 12.911), train_loss = 0.92148451, grad/param norm = 1.3761e-01, time/batch = 15.8843s	
8587/33250 (epoch 12.913), train_loss = 0.99967859, grad/param norm = 1.3556e-01, time/batch = 15.8693s	
8588/33250 (epoch 12.914), train_loss = 0.89415725, grad/param norm = 1.4804e-01, time/batch = 15.9314s	
8589/33250 (epoch 12.916), train_loss = 0.99035324, grad/param norm = 1.2671e-01, time/batch = 16.0382s	
8590/33250 (epoch 12.917), train_loss = 1.00592919, grad/param norm = 1.2761e-01, time/batch = 15.9349s	
8591/33250 (epoch 12.919), train_loss = 1.00853544, grad/param norm = 1.5967e-01, time/batch = 16.0371s	
8592/33250 (epoch 12.920), train_loss = 1.09144058, grad/param norm = 1.5758e-01, time/batch = 16.3482s	
8593/33250 (epoch 12.922), train_loss = 1.10025404, grad/param norm = 1.5962e-01, time/batch = 15.6164s	
8594/33250 (epoch 12.923), train_loss = 1.05792117, grad/param norm = 1.5945e-01, time/batch = 15.7612s	
8595/33250 (epoch 12.925), train_loss = 1.00838737, grad/param norm = 1.4004e-01, time/batch = 16.0729s	
8596/33250 (epoch 12.926), train_loss = 1.02433326, grad/param norm = 1.4584e-01, time/batch = 15.9979s	
8597/33250 (epoch 12.928), train_loss = 1.04327046, grad/param norm = 1.5257e-01, time/batch = 15.9570s	
8598/33250 (epoch 12.929), train_loss = 0.84089961, grad/param norm = 1.1481e-01, time/batch = 15.9346s	
8599/33250 (epoch 12.931), train_loss = 1.12361604, grad/param norm = 1.4521e-01, time/batch = 15.7131s	
8600/33250 (epoch 12.932), train_loss = 1.08997282, grad/param norm = 1.5955e-01, time/batch = 15.9274s	
8601/33250 (epoch 12.934), train_loss = 0.99306393, grad/param norm = 1.3220e-01, time/batch = 16.0281s	
8602/33250 (epoch 12.935), train_loss = 0.99601738, grad/param norm = 1.4579e-01, time/batch = 15.8581s	
8603/33250 (epoch 12.937), train_loss = 1.08416220, grad/param norm = 1.6960e-01, time/batch = 15.7852s	
8604/33250 (epoch 12.938), train_loss = 1.11111622, grad/param norm = 1.5778e-01, time/batch = 15.8705s	
8605/33250 (epoch 12.940), train_loss = 1.05031674, grad/param norm = 1.5905e-01, time/batch = 15.6945s	
8606/33250 (epoch 12.941), train_loss = 1.09763108, grad/param norm = 1.6371e-01, time/batch = 15.6100s	
8607/33250 (epoch 12.943), train_loss = 1.22400731, grad/param norm = 1.5950e-01, time/batch = 15.9380s	
8608/33250 (epoch 12.944), train_loss = 0.97404407, grad/param norm = 1.2986e-01, time/batch = 15.8971s	
8609/33250 (epoch 12.946), train_loss = 1.20823903, grad/param norm = 1.5098e-01, time/batch = 15.7726s	
8610/33250 (epoch 12.947), train_loss = 0.97082850, grad/param norm = 1.4281e-01, time/batch = 15.8761s	
8611/33250 (epoch 12.949), train_loss = 1.19322264, grad/param norm = 1.5807e-01, time/batch = 16.1222s	
8612/33250 (epoch 12.950), train_loss = 1.10834403, grad/param norm = 1.4314e-01, time/batch = 15.8534s	
8613/33250 (epoch 12.952), train_loss = 1.03997834, grad/param norm = 1.5742e-01, time/batch = 15.9329s	
8614/33250 (epoch 12.953), train_loss = 1.14728185, grad/param norm = 1.4845e-01, time/batch = 15.9301s	
8615/33250 (epoch 12.955), train_loss = 1.16999716, grad/param norm = 1.5557e-01, time/batch = 15.7669s	
8616/33250 (epoch 12.956), train_loss = 1.14182973, grad/param norm = 1.7649e-01, time/batch = 15.7550s	
8617/33250 (epoch 12.958), train_loss = 0.97867713, grad/param norm = 1.4197e-01, time/batch = 15.8455s	
8618/33250 (epoch 12.959), train_loss = 0.99359606, grad/param norm = 1.4021e-01, time/batch = 15.8599s	
8619/33250 (epoch 12.961), train_loss = 1.27148441, grad/param norm = 1.5540e-01, time/batch = 15.8553s	
8620/33250 (epoch 12.962), train_loss = 1.08729743, grad/param norm = 1.4472e-01, time/batch = 15.8979s	
8621/33250 (epoch 12.964), train_loss = 1.26887304, grad/param norm = 1.7851e-01, time/batch = 15.7177s	
8622/33250 (epoch 12.965), train_loss = 1.14764347, grad/param norm = 1.8104e-01, time/batch = 16.0281s	
8623/33250 (epoch 12.967), train_loss = 1.09000932, grad/param norm = 1.7163e-01, time/batch = 15.7055s	
8624/33250 (epoch 12.968), train_loss = 1.29049829, grad/param norm = 1.4682e-01, time/batch = 15.7909s	
8625/33250 (epoch 12.970), train_loss = 1.39431189, grad/param norm = 2.1609e-01, time/batch = 15.7894s	
8626/33250 (epoch 12.971), train_loss = 1.24296083, grad/param norm = 1.7044e-01, time/batch = 15.7799s	
8627/33250 (epoch 12.973), train_loss = 1.02070857, grad/param norm = 1.5455e-01, time/batch = 15.6033s	
8628/33250 (epoch 12.974), train_loss = 1.14123813, grad/param norm = 1.6107e-01, time/batch = 15.7089s	
8629/33250 (epoch 12.976), train_loss = 1.06265421, grad/param norm = 1.7265e-01, time/batch = 15.7994s	
8630/33250 (epoch 12.977), train_loss = 0.99580421, grad/param norm = 1.4665e-01, time/batch = 15.8824s	
8631/33250 (epoch 12.979), train_loss = 1.08286539, grad/param norm = 1.5764e-01, time/batch = 15.8042s	
8632/33250 (epoch 12.980), train_loss = 1.07484779, grad/param norm = 1.3679e-01, time/batch = 15.8781s	
8633/33250 (epoch 12.982), train_loss = 0.93251039, grad/param norm = 1.2608e-01, time/batch = 15.9377s	
8634/33250 (epoch 12.983), train_loss = 1.10054989, grad/param norm = 1.6323e-01, time/batch = 15.7666s	
8635/33250 (epoch 12.985), train_loss = 1.00473621, grad/param norm = 1.6010e-01, time/batch = 15.9215s	
8636/33250 (epoch 12.986), train_loss = 1.16003702, grad/param norm = 1.5889e-01, time/batch = 15.7654s	
8637/33250 (epoch 12.988), train_loss = 1.19409371, grad/param norm = 1.6853e-01, time/batch = 15.6081s	
8638/33250 (epoch 12.989), train_loss = 1.20106768, grad/param norm = 1.7892e-01, time/batch = 15.7870s	
8639/33250 (epoch 12.991), train_loss = 1.10781377, grad/param norm = 1.6735e-01, time/batch = 15.8568s	
8640/33250 (epoch 12.992), train_loss = 1.05989970, grad/param norm = 1.5168e-01, time/batch = 15.7763s	
8641/33250 (epoch 12.994), train_loss = 1.00078922, grad/param norm = 1.4779e-01, time/batch = 16.0188s	
8642/33250 (epoch 12.995), train_loss = 1.08544488, grad/param norm = 1.8264e-01, time/batch = 15.8748s	
8643/33250 (epoch 12.997), train_loss = 0.79086314, grad/param norm = 1.3640e-01, time/batch = 15.9424s	
8644/33250 (epoch 12.998), train_loss = 1.08043520, grad/param norm = 1.3817e-01, time/batch = 15.6123s	
decayed learning rate by a factor 0.97 to 0.00177058562	
8645/33250 (epoch 13.000), train_loss = 1.08237993, grad/param norm = 1.3968e-01, time/batch = 15.7539s	
8646/33250 (epoch 13.002), train_loss = 1.24127397, grad/param norm = 1.5882e-01, time/batch = 15.7844s	
8647/33250 (epoch 13.003), train_loss = 1.16678357, grad/param norm = 1.5770e-01, time/batch = 15.9495s	
8648/33250 (epoch 13.005), train_loss = 0.87842112, grad/param norm = 1.3084e-01, time/batch = 15.8488s	
8649/33250 (epoch 13.006), train_loss = 0.92784737, grad/param norm = 1.4529e-01, time/batch = 15.9509s	
8650/33250 (epoch 13.008), train_loss = 1.23822700, grad/param norm = 1.5331e-01, time/batch = 15.6457s	
8651/33250 (epoch 13.009), train_loss = 1.23947056, grad/param norm = 1.6585e-01, time/batch = 15.8748s	
8652/33250 (epoch 13.011), train_loss = 0.95920969, grad/param norm = 1.4166e-01, time/batch = 15.7882s	
8653/33250 (epoch 13.012), train_loss = 1.11834949, grad/param norm = 1.8523e-01, time/batch = 15.7784s	
8654/33250 (epoch 13.014), train_loss = 1.20894962, grad/param norm = 1.6373e-01, time/batch = 15.8494s	
8655/33250 (epoch 13.015), train_loss = 1.06331519, grad/param norm = 1.4850e-01, time/batch = 15.5317s	
8656/33250 (epoch 13.017), train_loss = 1.09510725, grad/param norm = 1.5677e-01, time/batch = 15.6124s	
8657/33250 (epoch 13.018), train_loss = 0.87994752, grad/param norm = 1.3738e-01, time/batch = 15.7623s	
8658/33250 (epoch 13.020), train_loss = 1.03356141, grad/param norm = 1.3922e-01, time/batch = 15.8554s	
8659/33250 (epoch 13.021), train_loss = 1.07015430, grad/param norm = 1.5138e-01, time/batch = 15.5406s	
8660/33250 (epoch 13.023), train_loss = 0.88542692, grad/param norm = 1.4067e-01, time/batch = 16.0291s	
8661/33250 (epoch 13.024), train_loss = 1.14554313, grad/param norm = 1.5029e-01, time/batch = 15.8744s	
8662/33250 (epoch 13.026), train_loss = 1.04706726, grad/param norm = 1.3390e-01, time/batch = 16.0563s	
8663/33250 (epoch 13.027), train_loss = 1.03759347, grad/param norm = 1.4413e-01, time/batch = 15.7697s	
8664/33250 (epoch 13.029), train_loss = 1.08413467, grad/param norm = 1.4619e-01, time/batch = 15.9439s	
8665/33250 (epoch 13.030), train_loss = 1.06507398, grad/param norm = 1.6084e-01, time/batch = 15.8585s	
8666/33250 (epoch 13.032), train_loss = 1.30325326, grad/param norm = 1.8028e-01, time/batch = 15.8603s	
8667/33250 (epoch 13.033), train_loss = 1.02041671, grad/param norm = 1.6050e-01, time/batch = 15.8482s	
8668/33250 (epoch 13.035), train_loss = 1.01512105, grad/param norm = 1.4793e-01, time/batch = 15.9439s	
8669/33250 (epoch 13.036), train_loss = 1.14318674, grad/param norm = 1.6064e-01, time/batch = 15.6948s	
8670/33250 (epoch 13.038), train_loss = 1.03233518, grad/param norm = 1.4321e-01, time/batch = 15.6916s	
8671/33250 (epoch 13.039), train_loss = 0.96274277, grad/param norm = 1.3876e-01, time/batch = 15.9974s	
8672/33250 (epoch 13.041), train_loss = 1.08255881, grad/param norm = 1.6133e-01, time/batch = 15.9356s	
8673/33250 (epoch 13.042), train_loss = 0.90288318, grad/param norm = 1.2824e-01, time/batch = 15.8546s	
8674/33250 (epoch 13.044), train_loss = 1.22011800, grad/param norm = 1.7737e-01, time/batch = 15.8686s	
8675/33250 (epoch 13.045), train_loss = 1.17987833, grad/param norm = 1.4952e-01, time/batch = 15.7707s	
8676/33250 (epoch 13.047), train_loss = 1.14348867, grad/param norm = 1.5946e-01, time/batch = 16.0346s	
8677/33250 (epoch 13.048), train_loss = 1.23377703, grad/param norm = 2.3258e-01, time/batch = 15.9494s	
8678/33250 (epoch 13.050), train_loss = 1.07102237, grad/param norm = 1.4533e-01, time/batch = 15.9473s	
8679/33250 (epoch 13.051), train_loss = 1.06221622, grad/param norm = 1.4389e-01, time/batch = 15.7774s	
8680/33250 (epoch 13.053), train_loss = 1.11254302, grad/param norm = 1.5983e-01, time/batch = 15.7577s	
8681/33250 (epoch 13.054), train_loss = 0.89223360, grad/param norm = 1.2977e-01, time/batch = 15.9631s	
8682/33250 (epoch 13.056), train_loss = 0.94472663, grad/param norm = 1.3654e-01, time/batch = 15.8590s	
8683/33250 (epoch 13.057), train_loss = 1.11981109, grad/param norm = 1.4194e-01, time/batch = 15.8657s	
8684/33250 (epoch 13.059), train_loss = 1.04033695, grad/param norm = 1.4058e-01, time/batch = 15.9135s	
8685/33250 (epoch 13.060), train_loss = 1.14311190, grad/param norm = 1.7140e-01, time/batch = 15.8669s	
8686/33250 (epoch 13.062), train_loss = 1.22564842, grad/param norm = 1.5674e-01, time/batch = 16.2382s	
8687/33250 (epoch 13.063), train_loss = 1.19843693, grad/param norm = 1.5357e-01, time/batch = 15.7811s	
8688/33250 (epoch 13.065), train_loss = 1.05830280, grad/param norm = 1.3808e-01, time/batch = 15.7957s	
8689/33250 (epoch 13.066), train_loss = 1.13117367, grad/param norm = 1.5575e-01, time/batch = 15.6986s	
8690/33250 (epoch 13.068), train_loss = 1.02834550, grad/param norm = 1.4344e-01, time/batch = 30.3135s	
8691/33250 (epoch 13.069), train_loss = 1.07733671, grad/param norm = 1.5100e-01, time/batch = 16.1676s	
8692/33250 (epoch 13.071), train_loss = 0.95199833, grad/param norm = 1.3603e-01, time/batch = 16.0391s	
8693/33250 (epoch 13.072), train_loss = 0.95260929, grad/param norm = 1.2972e-01, time/batch = 15.6290s	
8694/33250 (epoch 13.074), train_loss = 1.11776136, grad/param norm = 1.4640e-01, time/batch = 15.9603s	
8695/33250 (epoch 13.075), train_loss = 0.98963825, grad/param norm = 1.3128e-01, time/batch = 15.7670s	
8696/33250 (epoch 13.077), train_loss = 1.04983033, grad/param norm = 1.5953e-01, time/batch = 15.7595s	
8697/33250 (epoch 13.078), train_loss = 1.06148658, grad/param norm = 1.4176e-01, time/batch = 15.7733s	
8698/33250 (epoch 13.080), train_loss = 1.11001541, grad/param norm = 1.8617e-01, time/batch = 15.7783s	
8699/33250 (epoch 13.081), train_loss = 1.10895038, grad/param norm = 1.5428e-01, time/batch = 15.5303s	
8700/33250 (epoch 13.083), train_loss = 1.16521323, grad/param norm = 1.4443e-01, time/batch = 15.7762s	
8701/33250 (epoch 13.084), train_loss = 1.05965240, grad/param norm = 1.4759e-01, time/batch = 15.7948s	
8702/33250 (epoch 13.086), train_loss = 1.02711588, grad/param norm = 1.3802e-01, time/batch = 15.7015s	
8703/33250 (epoch 13.087), train_loss = 0.93639930, grad/param norm = 1.5951e-01, time/batch = 15.8093s	
8704/33250 (epoch 13.089), train_loss = 1.11233258, grad/param norm = 1.5871e-01, time/batch = 15.8481s	
8705/33250 (epoch 13.090), train_loss = 1.05980757, grad/param norm = 1.4949e-01, time/batch = 15.9624s	
8706/33250 (epoch 13.092), train_loss = 0.97799517, grad/param norm = 1.3238e-01, time/batch = 15.6231s	
8707/33250 (epoch 13.093), train_loss = 1.10190638, grad/param norm = 1.4352e-01, time/batch = 15.9469s	
8708/33250 (epoch 13.095), train_loss = 1.01513034, grad/param norm = 1.3847e-01, time/batch = 16.0723s	
8709/33250 (epoch 13.096), train_loss = 0.88325023, grad/param norm = 1.4436e-01, time/batch = 15.7012s	
8710/33250 (epoch 13.098), train_loss = 0.96516798, grad/param norm = 1.5676e-01, time/batch = 15.9253s	
8711/33250 (epoch 13.099), train_loss = 0.79638462, grad/param norm = 1.2035e-01, time/batch = 15.7753s	
8712/33250 (epoch 13.101), train_loss = 1.03167440, grad/param norm = 1.4126e-01, time/batch = 15.9681s	
8713/33250 (epoch 13.102), train_loss = 0.94690416, grad/param norm = 1.4648e-01, time/batch = 15.9719s	
8714/33250 (epoch 13.104), train_loss = 0.85382561, grad/param norm = 1.3119e-01, time/batch = 16.0541s	
8715/33250 (epoch 13.105), train_loss = 0.98333080, grad/param norm = 1.3946e-01, time/batch = 15.9571s	
8716/33250 (epoch 13.107), train_loss = 0.87831333, grad/param norm = 1.2740e-01, time/batch = 15.6950s	
8717/33250 (epoch 13.108), train_loss = 1.03960745, grad/param norm = 1.4146e-01, time/batch = 15.7832s	
8718/33250 (epoch 13.110), train_loss = 0.85106727, grad/param norm = 1.3515e-01, time/batch = 15.6945s	
8719/33250 (epoch 13.111), train_loss = 1.02202629, grad/param norm = 1.4868e-01, time/batch = 15.7664s	
8720/33250 (epoch 13.113), train_loss = 1.05138058, grad/param norm = 1.6312e-01, time/batch = 16.0117s	
8721/33250 (epoch 13.114), train_loss = 0.95853561, grad/param norm = 1.6297e-01, time/batch = 16.0988s	
8722/33250 (epoch 13.116), train_loss = 1.06264673, grad/param norm = 1.5308e-01, time/batch = 15.7767s	
8723/33250 (epoch 13.117), train_loss = 1.02781948, grad/param norm = 1.4180e-01, time/batch = 16.2036s	
8724/33250 (epoch 13.119), train_loss = 1.00395812, grad/param norm = 1.4494e-01, time/batch = 15.8563s	
8725/33250 (epoch 13.120), train_loss = 0.80780547, grad/param norm = 1.3378e-01, time/batch = 15.8047s	
8726/33250 (epoch 13.122), train_loss = 1.17213840, grad/param norm = 1.4621e-01, time/batch = 15.7707s	
8727/33250 (epoch 13.123), train_loss = 1.07281473, grad/param norm = 1.4824e-01, time/batch = 15.9216s	
8728/33250 (epoch 13.125), train_loss = 0.87394427, grad/param norm = 1.3906e-01, time/batch = 15.8646s	
8729/33250 (epoch 13.126), train_loss = 1.03235183, grad/param norm = 1.5079e-01, time/batch = 15.8474s	
8730/33250 (epoch 13.128), train_loss = 0.97129461, grad/param norm = 1.3272e-01, time/batch = 15.7705s	
8731/33250 (epoch 13.129), train_loss = 1.03274709, grad/param norm = 1.4474e-01, time/batch = 15.6170s	
8732/33250 (epoch 13.131), train_loss = 1.02476426, grad/param norm = 1.4323e-01, time/batch = 15.9407s	
8733/33250 (epoch 13.132), train_loss = 1.01950423, grad/param norm = 1.4661e-01, time/batch = 15.7981s	
8734/33250 (epoch 13.134), train_loss = 1.04229564, grad/param norm = 1.4070e-01, time/batch = 15.8755s	
8735/33250 (epoch 13.135), train_loss = 1.08002745, grad/param norm = 1.4566e-01, time/batch = 15.7177s	
8736/33250 (epoch 13.137), train_loss = 0.93350238, grad/param norm = 1.3761e-01, time/batch = 15.7933s	
8737/33250 (epoch 13.138), train_loss = 0.97909171, grad/param norm = 1.2537e-01, time/batch = 15.5393s	
8738/33250 (epoch 13.140), train_loss = 0.80718845, grad/param norm = 1.3182e-01, time/batch = 15.6701s	
8739/33250 (epoch 13.141), train_loss = 1.29132178, grad/param norm = 1.9467e-01, time/batch = 15.6581s	
8740/33250 (epoch 13.143), train_loss = 0.81928650, grad/param norm = 1.4396e-01, time/batch = 15.5243s	
8741/33250 (epoch 13.144), train_loss = 1.00056798, grad/param norm = 1.3669e-01, time/batch = 15.8619s	
8742/33250 (epoch 13.146), train_loss = 0.96589403, grad/param norm = 1.3272e-01, time/batch = 15.9418s	
8743/33250 (epoch 13.147), train_loss = 0.95102535, grad/param norm = 1.4260e-01, time/batch = 15.7928s	
8744/33250 (epoch 13.149), train_loss = 1.00400087, grad/param norm = 1.5088e-01, time/batch = 15.8855s	
8745/33250 (epoch 13.150), train_loss = 0.94514528, grad/param norm = 1.4064e-01, time/batch = 16.0077s	
8746/33250 (epoch 13.152), train_loss = 0.88983110, grad/param norm = 1.2875e-01, time/batch = 15.9504s	
8747/33250 (epoch 13.153), train_loss = 1.19712155, grad/param norm = 1.5469e-01, time/batch = 15.7202s	
8748/33250 (epoch 13.155), train_loss = 1.05004809, grad/param norm = 1.7041e-01, time/batch = 15.9386s	
8749/33250 (epoch 13.156), train_loss = 1.25330683, grad/param norm = 1.5870e-01, time/batch = 15.9422s	
8750/33250 (epoch 13.158), train_loss = 1.26098535, grad/param norm = 1.6905e-01, time/batch = 15.6907s	
8751/33250 (epoch 13.159), train_loss = 1.06174231, grad/param norm = 1.5771e-01, time/batch = 15.9166s	
8752/33250 (epoch 13.161), train_loss = 1.08348590, grad/param norm = 1.6083e-01, time/batch = 15.7908s	
8753/33250 (epoch 13.162), train_loss = 0.92424559, grad/param norm = 1.3658e-01, time/batch = 16.1007s	
8754/33250 (epoch 13.164), train_loss = 1.04960252, grad/param norm = 1.5640e-01, time/batch = 15.8558s	
8755/33250 (epoch 13.165), train_loss = 1.13220970, grad/param norm = 1.5876e-01, time/batch = 16.0478s	
8756/33250 (epoch 13.167), train_loss = 1.17961670, grad/param norm = 1.5743e-01, time/batch = 16.0245s	
8757/33250 (epoch 13.168), train_loss = 0.88094241, grad/param norm = 1.1775e-01, time/batch = 16.0435s	
8758/33250 (epoch 13.170), train_loss = 1.00897232, grad/param norm = 1.4712e-01, time/batch = 15.8018s	
8759/33250 (epoch 13.171), train_loss = 1.01239629, grad/param norm = 1.3818e-01, time/batch = 15.9317s	
8760/33250 (epoch 13.173), train_loss = 1.00001372, grad/param norm = 1.4230e-01, time/batch = 15.9149s	
8761/33250 (epoch 13.174), train_loss = 1.03728136, grad/param norm = 1.4358e-01, time/batch = 15.9400s	
8762/33250 (epoch 13.176), train_loss = 1.03616882, grad/param norm = 1.5377e-01, time/batch = 15.8726s	
8763/33250 (epoch 13.177), train_loss = 0.98372474, grad/param norm = 1.2993e-01, time/batch = 15.9529s	
8764/33250 (epoch 13.179), train_loss = 0.95708336, grad/param norm = 1.3766e-01, time/batch = 15.7647s	
8765/33250 (epoch 13.180), train_loss = 0.87185149, grad/param norm = 1.2393e-01, time/batch = 15.9528s	
8766/33250 (epoch 13.182), train_loss = 0.96364008, grad/param norm = 1.5858e-01, time/batch = 15.7051s	
8767/33250 (epoch 13.183), train_loss = 1.18395454, grad/param norm = 1.6492e-01, time/batch = 15.9513s	
8768/33250 (epoch 13.185), train_loss = 1.12520875, grad/param norm = 1.7424e-01, time/batch = 15.9539s	
8769/33250 (epoch 13.186), train_loss = 1.05992173, grad/param norm = 1.5684e-01, time/batch = 15.8721s	
8770/33250 (epoch 13.188), train_loss = 1.15741977, grad/param norm = 1.7980e-01, time/batch = 16.0295s	
8771/33250 (epoch 13.189), train_loss = 0.86670569, grad/param norm = 1.6246e-01, time/batch = 15.9132s	
8772/33250 (epoch 13.191), train_loss = 0.96170079, grad/param norm = 1.3559e-01, time/batch = 16.1953s	
8773/33250 (epoch 13.192), train_loss = 0.96330920, grad/param norm = 1.3643e-01, time/batch = 15.7736s	
8774/33250 (epoch 13.194), train_loss = 0.96931326, grad/param norm = 1.5337e-01, time/batch = 15.7810s	
8775/33250 (epoch 13.195), train_loss = 1.21839934, grad/param norm = 1.5214e-01, time/batch = 15.7910s	
8776/33250 (epoch 13.197), train_loss = 0.98852029, grad/param norm = 1.3387e-01, time/batch = 15.8602s	
8777/33250 (epoch 13.198), train_loss = 1.16060782, grad/param norm = 1.5555e-01, time/batch = 16.0174s	
8778/33250 (epoch 13.200), train_loss = 1.05147963, grad/param norm = 1.4560e-01, time/batch = 15.7166s	
8779/33250 (epoch 13.202), train_loss = 0.95387152, grad/param norm = 1.3425e-01, time/batch = 15.9618s	
8780/33250 (epoch 13.203), train_loss = 0.98146637, grad/param norm = 1.4533e-01, time/batch = 15.6958s	
8781/33250 (epoch 13.205), train_loss = 1.06743843, grad/param norm = 1.4867e-01, time/batch = 15.9458s	
8782/33250 (epoch 13.206), train_loss = 1.11232438, grad/param norm = 1.5656e-01, time/batch = 15.7860s	
8783/33250 (epoch 13.208), train_loss = 1.18836086, grad/param norm = 1.6113e-01, time/batch = 16.2561s	
8784/33250 (epoch 13.209), train_loss = 0.97715236, grad/param norm = 1.4152e-01, time/batch = 15.6988s	
8785/33250 (epoch 13.211), train_loss = 1.13425907, grad/param norm = 1.5018e-01, time/batch = 16.2431s	
8786/33250 (epoch 13.212), train_loss = 1.29891565, grad/param norm = 1.5654e-01, time/batch = 15.9454s	
8787/33250 (epoch 13.214), train_loss = 1.02640346, grad/param norm = 1.2904e-01, time/batch = 16.0117s	
8788/33250 (epoch 13.215), train_loss = 1.28540408, grad/param norm = 1.9656e-01, time/batch = 15.8570s	
8789/33250 (epoch 13.217), train_loss = 1.19366343, grad/param norm = 1.7023e-01, time/batch = 15.7894s	
8790/33250 (epoch 13.218), train_loss = 1.12923358, grad/param norm = 1.3664e-01, time/batch = 15.7896s	
8791/33250 (epoch 13.220), train_loss = 1.12142756, grad/param norm = 1.5270e-01, time/batch = 16.0227s	
8792/33250 (epoch 13.221), train_loss = 1.28996640, grad/param norm = 1.7844e-01, time/batch = 15.4663s	
8793/33250 (epoch 13.223), train_loss = 1.04942390, grad/param norm = 1.6178e-01, time/batch = 15.6201s	
8794/33250 (epoch 13.224), train_loss = 1.13897642, grad/param norm = 1.6696e-01, time/batch = 15.8565s	
8795/33250 (epoch 13.226), train_loss = 1.23469021, grad/param norm = 1.5946e-01, time/batch = 15.6977s	
8796/33250 (epoch 13.227), train_loss = 1.09643501, grad/param norm = 1.4931e-01, time/batch = 15.7701s	
8797/33250 (epoch 13.229), train_loss = 1.09700912, grad/param norm = 1.4136e-01, time/batch = 16.2967s	
8798/33250 (epoch 13.230), train_loss = 0.99914627, grad/param norm = 1.4996e-01, time/batch = 15.8726s	
8799/33250 (epoch 13.232), train_loss = 0.99432671, grad/param norm = 1.2718e-01, time/batch = 15.8728s	
8800/33250 (epoch 13.233), train_loss = 0.97962522, grad/param norm = 1.3461e-01, time/batch = 15.8036s	
8801/33250 (epoch 13.235), train_loss = 1.20853920, grad/param norm = 1.5435e-01, time/batch = 15.8592s	
8802/33250 (epoch 13.236), train_loss = 0.99263910, grad/param norm = 1.5522e-01, time/batch = 15.9312s	
8803/33250 (epoch 13.238), train_loss = 1.13808687, grad/param norm = 1.5924e-01, time/batch = 15.6098s	
8804/33250 (epoch 13.239), train_loss = 1.22048459, grad/param norm = 1.7178e-01, time/batch = 15.7509s	
8805/33250 (epoch 13.241), train_loss = 1.15229574, grad/param norm = 1.7265e-01, time/batch = 15.7810s	
8806/33250 (epoch 13.242), train_loss = 1.14203178, grad/param norm = 1.5558e-01, time/batch = 15.8319s	
8807/33250 (epoch 13.244), train_loss = 1.17205870, grad/param norm = 1.7749e-01, time/batch = 15.8606s	
8808/33250 (epoch 13.245), train_loss = 1.06413379, grad/param norm = 1.4019e-01, time/batch = 15.8744s	
8809/33250 (epoch 13.247), train_loss = 1.09328175, grad/param norm = 1.4911e-01, time/batch = 15.6115s	
8810/33250 (epoch 13.248), train_loss = 1.31531647, grad/param norm = 1.8423e-01, time/batch = 15.9634s	
8811/33250 (epoch 13.250), train_loss = 1.14743729, grad/param norm = 1.3966e-01, time/batch = 15.8634s	
8812/33250 (epoch 13.251), train_loss = 1.09272740, grad/param norm = 1.4760e-01, time/batch = 15.6919s	
8813/33250 (epoch 13.253), train_loss = 0.96821478, grad/param norm = 1.2952e-01, time/batch = 15.7428s	
8814/33250 (epoch 13.254), train_loss = 0.99723833, grad/param norm = 1.4842e-01, time/batch = 15.8623s	
8815/33250 (epoch 13.256), train_loss = 1.08242221, grad/param norm = 1.3786e-01, time/batch = 15.9490s	
8816/33250 (epoch 13.257), train_loss = 1.20903521, grad/param norm = 1.4689e-01, time/batch = 15.7691s	
8817/33250 (epoch 13.259), train_loss = 1.19855762, grad/param norm = 1.5992e-01, time/batch = 16.0173s	
8818/33250 (epoch 13.260), train_loss = 0.97230487, grad/param norm = 1.4301e-01, time/batch = 15.7856s	
8819/33250 (epoch 13.262), train_loss = 1.10588664, grad/param norm = 1.4235e-01, time/batch = 15.8683s	
8820/33250 (epoch 13.263), train_loss = 0.99700907, grad/param norm = 1.5031e-01, time/batch = 15.9471s	
8821/33250 (epoch 13.265), train_loss = 1.15167860, grad/param norm = 1.4504e-01, time/batch = 16.0059s	
8822/33250 (epoch 13.266), train_loss = 1.07143815, grad/param norm = 1.5962e-01, time/batch = 15.7051s	
8823/33250 (epoch 13.268), train_loss = 0.98514061, grad/param norm = 1.4280e-01, time/batch = 15.7698s	
8824/33250 (epoch 13.269), train_loss = 0.87041698, grad/param norm = 1.3729e-01, time/batch = 16.0177s	
8825/33250 (epoch 13.271), train_loss = 1.02787037, grad/param norm = 1.4070e-01, time/batch = 16.1043s	
8826/33250 (epoch 13.272), train_loss = 0.90854578, grad/param norm = 1.1945e-01, time/batch = 15.9379s	
8827/33250 (epoch 13.274), train_loss = 0.81373419, grad/param norm = 1.2777e-01, time/batch = 15.7841s	
8828/33250 (epoch 13.275), train_loss = 0.96885927, grad/param norm = 1.2846e-01, time/batch = 15.9284s	
8829/33250 (epoch 13.277), train_loss = 0.84359266, grad/param norm = 1.3122e-01, time/batch = 15.8894s	
8830/33250 (epoch 13.278), train_loss = 0.97255172, grad/param norm = 1.3888e-01, time/batch = 15.7217s	
8831/33250 (epoch 13.280), train_loss = 0.92160315, grad/param norm = 1.2802e-01, time/batch = 15.8692s	
8832/33250 (epoch 13.281), train_loss = 1.05884921, grad/param norm = 1.4464e-01, time/batch = 15.9575s	
8833/33250 (epoch 13.283), train_loss = 1.11365116, grad/param norm = 1.8121e-01, time/batch = 15.8696s	
8834/33250 (epoch 13.284), train_loss = 0.96443789, grad/param norm = 1.4248e-01, time/batch = 15.6930s	
8835/33250 (epoch 13.286), train_loss = 1.11787792, grad/param norm = 1.5649e-01, time/batch = 15.8291s	
8836/33250 (epoch 13.287), train_loss = 0.89657200, grad/param norm = 1.2566e-01, time/batch = 16.0927s	
8837/33250 (epoch 13.289), train_loss = 0.86615142, grad/param norm = 1.3971e-01, time/batch = 15.7091s	
8838/33250 (epoch 13.290), train_loss = 1.05783624, grad/param norm = 1.3354e-01, time/batch = 15.7025s	
8839/33250 (epoch 13.292), train_loss = 1.09653351, grad/param norm = 1.5240e-01, time/batch = 15.7754s	
8840/33250 (epoch 13.293), train_loss = 1.17441216, grad/param norm = 1.6452e-01, time/batch = 15.9683s	
8841/33250 (epoch 13.295), train_loss = 1.10864578, grad/param norm = 1.5313e-01, time/batch = 16.1417s	
8842/33250 (epoch 13.296), train_loss = 1.06116077, grad/param norm = 1.4105e-01, time/batch = 15.9620s	
8843/33250 (epoch 13.298), train_loss = 0.88946468, grad/param norm = 1.2651e-01, time/batch = 15.9130s	
8844/33250 (epoch 13.299), train_loss = 0.82979122, grad/param norm = 1.3641e-01, time/batch = 15.7843s	
8845/33250 (epoch 13.301), train_loss = 1.10715158, grad/param norm = 1.4187e-01, time/batch = 15.8435s	
8846/33250 (epoch 13.302), train_loss = 1.09362061, grad/param norm = 1.5341e-01, time/batch = 15.7954s	
8847/33250 (epoch 13.304), train_loss = 0.97634352, grad/param norm = 1.3934e-01, time/batch = 15.9323s	
8848/33250 (epoch 13.305), train_loss = 1.05508285, grad/param norm = 1.4634e-01, time/batch = 15.8429s	
8849/33250 (epoch 13.307), train_loss = 1.11670422, grad/param norm = 1.4708e-01, time/batch = 15.6208s	
8850/33250 (epoch 13.308), train_loss = 1.30824465, grad/param norm = 1.7104e-01, time/batch = 15.7772s	
8851/33250 (epoch 13.310), train_loss = 1.04468942, grad/param norm = 1.4777e-01, time/batch = 16.0284s	
8852/33250 (epoch 13.311), train_loss = 1.18897396, grad/param norm = 1.5845e-01, time/batch = 15.7295s	
8853/33250 (epoch 13.313), train_loss = 0.87036330, grad/param norm = 1.3218e-01, time/batch = 15.9697s	
8854/33250 (epoch 13.314), train_loss = 1.04393863, grad/param norm = 1.4313e-01, time/batch = 15.7859s	
8855/33250 (epoch 13.316), train_loss = 1.21116765, grad/param norm = 1.5660e-01, time/batch = 15.7858s	
8856/33250 (epoch 13.317), train_loss = 0.94365366, grad/param norm = 1.4026e-01, time/batch = 15.8615s	
8857/33250 (epoch 13.319), train_loss = 1.15393671, grad/param norm = 1.7386e-01, time/batch = 15.7852s	
8858/33250 (epoch 13.320), train_loss = 1.19573453, grad/param norm = 1.9066e-01, time/batch = 16.1551s	
8859/33250 (epoch 13.322), train_loss = 1.23939501, grad/param norm = 1.9830e-01, time/batch = 16.0875s	
8860/33250 (epoch 13.323), train_loss = 1.29030816, grad/param norm = 1.8081e-01, time/batch = 15.9255s	
8861/33250 (epoch 13.325), train_loss = 1.10118631, grad/param norm = 1.6773e-01, time/batch = 16.1877s	
8862/33250 (epoch 13.326), train_loss = 1.24247040, grad/param norm = 1.5988e-01, time/batch = 15.9242s	
8863/33250 (epoch 13.328), train_loss = 1.00808131, grad/param norm = 1.4315e-01, time/batch = 15.7060s	
8864/33250 (epoch 13.329), train_loss = 1.07888814, grad/param norm = 1.6039e-01, time/batch = 15.9535s	
8865/33250 (epoch 13.331), train_loss = 1.04422626, grad/param norm = 1.6350e-01, time/batch = 15.8631s	
8866/33250 (epoch 13.332), train_loss = 1.01815973, grad/param norm = 1.4549e-01, time/batch = 15.9215s	
8867/33250 (epoch 13.334), train_loss = 1.20046882, grad/param norm = 1.4730e-01, time/batch = 15.6184s	
8868/33250 (epoch 13.335), train_loss = 0.78130484, grad/param norm = 1.2994e-01, time/batch = 15.8468s	
8869/33250 (epoch 13.337), train_loss = 1.09632527, grad/param norm = 1.4570e-01, time/batch = 15.8621s	
8870/33250 (epoch 13.338), train_loss = 1.19511213, grad/param norm = 1.7869e-01, time/batch = 15.8598s	
8871/33250 (epoch 13.340), train_loss = 1.05190129, grad/param norm = 1.4169e-01, time/batch = 15.8839s	
8872/33250 (epoch 13.341), train_loss = 0.97963781, grad/param norm = 1.4513e-01, time/batch = 16.0595s	
8873/33250 (epoch 13.343), train_loss = 1.02003488, grad/param norm = 1.4941e-01, time/batch = 15.8743s	
8874/33250 (epoch 13.344), train_loss = 1.05037154, grad/param norm = 1.4397e-01, time/batch = 15.9763s	
8875/33250 (epoch 13.346), train_loss = 0.89253287, grad/param norm = 1.2755e-01, time/batch = 15.7049s	
8876/33250 (epoch 13.347), train_loss = 1.32552723, grad/param norm = 1.6546e-01, time/batch = 15.6965s	
8877/33250 (epoch 13.349), train_loss = 1.00380413, grad/param norm = 1.4513e-01, time/batch = 15.8469s	
8878/33250 (epoch 13.350), train_loss = 1.04083326, grad/param norm = 1.4251e-01, time/batch = 15.7659s	
8879/33250 (epoch 13.352), train_loss = 0.91928390, grad/param norm = 1.3872e-01, time/batch = 15.7668s	
8880/33250 (epoch 13.353), train_loss = 1.01057795, grad/param norm = 1.3881e-01, time/batch = 15.5283s	
8881/33250 (epoch 13.355), train_loss = 1.02294913, grad/param norm = 1.5294e-01, time/batch = 15.8707s	
8882/33250 (epoch 13.356), train_loss = 0.96869355, grad/param norm = 1.5922e-01, time/batch = 15.8793s	
8883/33250 (epoch 13.358), train_loss = 0.99403579, grad/param norm = 1.4221e-01, time/batch = 15.9778s	
8884/33250 (epoch 13.359), train_loss = 0.99634369, grad/param norm = 1.3045e-01, time/batch = 15.9662s	
8885/33250 (epoch 13.361), train_loss = 1.22462862, grad/param norm = 1.6353e-01, time/batch = 15.8691s	
8886/33250 (epoch 13.362), train_loss = 1.05343375, grad/param norm = 1.4752e-01, time/batch = 15.8748s	
8887/33250 (epoch 13.364), train_loss = 1.13772534, grad/param norm = 1.5986e-01, time/batch = 15.8736s	
8888/33250 (epoch 13.365), train_loss = 1.03885625, grad/param norm = 1.4404e-01, time/batch = 15.9444s	
8889/33250 (epoch 13.367), train_loss = 1.04647237, grad/param norm = 1.3877e-01, time/batch = 16.0587s	
8890/33250 (epoch 13.368), train_loss = 1.03470922, grad/param norm = 1.4199e-01, time/batch = 15.8435s	
8891/33250 (epoch 13.370), train_loss = 0.91673384, grad/param norm = 1.2526e-01, time/batch = 15.9516s	
8892/33250 (epoch 13.371), train_loss = 1.17270932, grad/param norm = 1.5641e-01, time/batch = 15.9439s	
8893/33250 (epoch 13.373), train_loss = 0.99194699, grad/param norm = 1.3331e-01, time/batch = 15.9703s	
8894/33250 (epoch 13.374), train_loss = 1.14184024, grad/param norm = 1.8190e-01, time/batch = 16.0546s	
8895/33250 (epoch 13.376), train_loss = 1.01559361, grad/param norm = 1.4888e-01, time/batch = 15.9716s	
8896/33250 (epoch 13.377), train_loss = 0.95563911, grad/param norm = 1.7552e-01, time/batch = 15.7663s	
8897/33250 (epoch 13.379), train_loss = 0.95973911, grad/param norm = 1.4574e-01, time/batch = 15.6946s	
8898/33250 (epoch 13.380), train_loss = 1.08814274, grad/param norm = 1.7563e-01, time/batch = 16.0060s	
8899/33250 (epoch 13.382), train_loss = 1.16097963, grad/param norm = 1.7731e-01, time/batch = 15.7505s	
8900/33250 (epoch 13.383), train_loss = 0.93586267, grad/param norm = 1.3294e-01, time/batch = 15.7665s	
8901/33250 (epoch 13.385), train_loss = 0.90004822, grad/param norm = 1.4485e-01, time/batch = 15.8636s	
8902/33250 (epoch 13.386), train_loss = 0.90226824, grad/param norm = 1.3723e-01, time/batch = 15.9586s	
8903/33250 (epoch 13.388), train_loss = 0.96793042, grad/param norm = 1.5236e-01, time/batch = 16.0465s	
8904/33250 (epoch 13.389), train_loss = 1.01294602, grad/param norm = 1.5957e-01, time/batch = 15.9797s	
8905/33250 (epoch 13.391), train_loss = 1.05772199, grad/param norm = 1.5213e-01, time/batch = 15.9546s	
8906/33250 (epoch 13.392), train_loss = 1.15064881, grad/param norm = 1.6249e-01, time/batch = 15.9074s	
8907/33250 (epoch 13.394), train_loss = 1.19932080, grad/param norm = 1.6179e-01, time/batch = 15.7620s	
8908/33250 (epoch 13.395), train_loss = 1.13876370, grad/param norm = 1.3897e-01, time/batch = 15.7754s	
8909/33250 (epoch 13.397), train_loss = 1.16536746, grad/param norm = 1.4781e-01, time/batch = 15.7764s	
8910/33250 (epoch 13.398), train_loss = 0.99405900, grad/param norm = 1.4956e-01, time/batch = 15.8544s	
8911/33250 (epoch 13.400), train_loss = 0.96527945, grad/param norm = 1.4181e-01, time/batch = 16.0228s	
8912/33250 (epoch 13.402), train_loss = 0.87482430, grad/param norm = 1.4124e-01, time/batch = 15.7951s	
8913/33250 (epoch 13.403), train_loss = 0.97876656, grad/param norm = 1.6793e-01, time/batch = 15.9565s	
8914/33250 (epoch 13.405), train_loss = 0.96821858, grad/param norm = 1.4305e-01, time/batch = 20.0549s	
8915/33250 (epoch 13.406), train_loss = 1.10101953, grad/param norm = 1.6124e-01, time/batch = 26.0798s	
8916/33250 (epoch 13.408), train_loss = 1.19909679, grad/param norm = 1.6835e-01, time/batch = 15.8430s	
8917/33250 (epoch 13.409), train_loss = 1.13550419, grad/param norm = 1.8897e-01, time/batch = 15.8618s	
8918/33250 (epoch 13.411), train_loss = 0.77109346, grad/param norm = 1.1818e-01, time/batch = 15.6860s	
8919/33250 (epoch 13.412), train_loss = 0.89397179, grad/param norm = 1.5403e-01, time/batch = 15.6179s	
8920/33250 (epoch 13.414), train_loss = 1.09391305, grad/param norm = 1.6383e-01, time/batch = 15.9423s	
8921/33250 (epoch 13.415), train_loss = 1.17915102, grad/param norm = 1.6612e-01, time/batch = 15.8439s	
8922/33250 (epoch 13.417), train_loss = 1.14506387, grad/param norm = 1.6460e-01, time/batch = 15.9618s	
8923/33250 (epoch 13.418), train_loss = 1.31175735, grad/param norm = 1.7192e-01, time/batch = 15.7547s	
8924/33250 (epoch 13.420), train_loss = 1.17537580, grad/param norm = 1.5138e-01, time/batch = 15.8144s	
8925/33250 (epoch 13.421), train_loss = 0.97011188, grad/param norm = 1.4987e-01, time/batch = 15.9421s	
8926/33250 (epoch 13.423), train_loss = 1.10853466, grad/param norm = 1.5578e-01, time/batch = 15.8698s	
8927/33250 (epoch 13.424), train_loss = 1.27941995, grad/param norm = 1.9740e-01, time/batch = 16.1099s	
8928/33250 (epoch 13.426), train_loss = 0.95942010, grad/param norm = 1.3428e-01, time/batch = 15.9293s	
8929/33250 (epoch 13.427), train_loss = 0.99150876, grad/param norm = 1.5245e-01, time/batch = 15.8670s	
8930/33250 (epoch 13.429), train_loss = 1.11129651, grad/param norm = 1.6770e-01, time/batch = 15.7849s	
8931/33250 (epoch 13.430), train_loss = 0.96669868, grad/param norm = 1.6055e-01, time/batch = 15.8669s	
8932/33250 (epoch 13.432), train_loss = 1.05806663, grad/param norm = 1.4117e-01, time/batch = 15.9305s	
8933/33250 (epoch 13.433), train_loss = 0.99864925, grad/param norm = 1.6526e-01, time/batch = 15.7204s	
8934/33250 (epoch 13.435), train_loss = 1.10304315, grad/param norm = 1.6033e-01, time/batch = 15.7103s	
8935/33250 (epoch 13.436), train_loss = 0.98755440, grad/param norm = 1.4891e-01, time/batch = 15.9444s	
8936/33250 (epoch 13.438), train_loss = 1.12285128, grad/param norm = 1.4194e-01, time/batch = 15.7771s	
8937/33250 (epoch 13.439), train_loss = 1.07093602, grad/param norm = 1.4538e-01, time/batch = 15.7833s	
8938/33250 (epoch 13.441), train_loss = 1.04003019, grad/param norm = 1.3899e-01, time/batch = 15.7801s	
8939/33250 (epoch 13.442), train_loss = 0.95902840, grad/param norm = 1.4435e-01, time/batch = 15.8668s	
8940/33250 (epoch 13.444), train_loss = 0.95542083, grad/param norm = 1.3651e-01, time/batch = 16.0057s	
8941/33250 (epoch 13.445), train_loss = 1.04962349, grad/param norm = 1.4565e-01, time/batch = 16.1102s	
8942/33250 (epoch 13.447), train_loss = 1.08439923, grad/param norm = 1.4979e-01, time/batch = 15.9473s	
8943/33250 (epoch 13.448), train_loss = 1.03024454, grad/param norm = 1.2976e-01, time/batch = 16.0167s	
8944/33250 (epoch 13.450), train_loss = 1.22700500, grad/param norm = 1.7502e-01, time/batch = 15.9662s	
8945/33250 (epoch 13.451), train_loss = 1.10044364, grad/param norm = 1.5163e-01, time/batch = 15.8070s	
8946/33250 (epoch 13.453), train_loss = 0.93591169, grad/param norm = 1.3407e-01, time/batch = 15.8687s	
8947/33250 (epoch 13.454), train_loss = 1.21246652, grad/param norm = 1.6947e-01, time/batch = 15.6022s	
8948/33250 (epoch 13.456), train_loss = 1.20382968, grad/param norm = 1.6162e-01, time/batch = 15.8724s	
8949/33250 (epoch 13.457), train_loss = 1.02920941, grad/param norm = 1.6855e-01, time/batch = 15.8489s	
8950/33250 (epoch 13.459), train_loss = 1.06308638, grad/param norm = 1.3864e-01, time/batch = 15.8666s	
8951/33250 (epoch 13.460), train_loss = 1.14986629, grad/param norm = 1.6589e-01, time/batch = 10.9742s	
8952/33250 (epoch 13.462), train_loss = 0.98320243, grad/param norm = 1.3879e-01, time/batch = 0.7016s	
8953/33250 (epoch 13.463), train_loss = 0.95620020, grad/param norm = 1.3403e-01, time/batch = 0.7057s	
8954/33250 (epoch 13.465), train_loss = 0.84895936, grad/param norm = 1.2308e-01, time/batch = 0.7047s	
8955/33250 (epoch 13.466), train_loss = 0.82723979, grad/param norm = 1.0909e-01, time/batch = 0.6996s	
8956/33250 (epoch 13.468), train_loss = 0.92841618, grad/param norm = 1.2235e-01, time/batch = 0.6966s	
8957/33250 (epoch 13.469), train_loss = 1.03720468, grad/param norm = 1.5411e-01, time/batch = 0.6916s	
8958/33250 (epoch 13.471), train_loss = 1.14603415, grad/param norm = 1.4154e-01, time/batch = 0.7664s	
8959/33250 (epoch 13.472), train_loss = 1.01840111, grad/param norm = 1.6779e-01, time/batch = 1.0233s	
8960/33250 (epoch 13.474), train_loss = 1.25902558, grad/param norm = 1.8261e-01, time/batch = 1.0236s	
8961/33250 (epoch 13.475), train_loss = 1.06963303, grad/param norm = 1.4066e-01, time/batch = 1.0124s	
8962/33250 (epoch 13.477), train_loss = 1.03704132, grad/param norm = 1.3891e-01, time/batch = 1.0057s	
8963/33250 (epoch 13.478), train_loss = 0.99229320, grad/param norm = 1.4186e-01, time/batch = 1.3062s	
8964/33250 (epoch 13.480), train_loss = 1.28722481, grad/param norm = 1.6662e-01, time/batch = 1.9079s	
8965/33250 (epoch 13.481), train_loss = 1.04927558, grad/param norm = 1.5083e-01, time/batch = 1.9226s	
8966/33250 (epoch 13.483), train_loss = 1.09147159, grad/param norm = 1.3961e-01, time/batch = 11.8330s	
8967/33250 (epoch 13.484), train_loss = 0.94901166, grad/param norm = 1.3943e-01, time/batch = 15.8448s	
8968/33250 (epoch 13.486), train_loss = 0.86283349, grad/param norm = 1.4458e-01, time/batch = 15.7045s	
8969/33250 (epoch 13.487), train_loss = 0.99814267, grad/param norm = 1.4908e-01, time/batch = 15.8530s	
8970/33250 (epoch 13.489), train_loss = 1.12777258, grad/param norm = 1.7280e-01, time/batch = 15.9730s	
8971/33250 (epoch 13.490), train_loss = 1.11923018, grad/param norm = 1.6195e-01, time/batch = 15.7071s	
8972/33250 (epoch 13.492), train_loss = 1.10201617, grad/param norm = 1.5612e-01, time/batch = 15.7572s	
8973/33250 (epoch 13.493), train_loss = 1.05326705, grad/param norm = 1.5847e-01, time/batch = 15.7819s	
8974/33250 (epoch 13.495), train_loss = 1.07625940, grad/param norm = 1.3887e-01, time/batch = 15.8391s	
8975/33250 (epoch 13.496), train_loss = 1.01689811, grad/param norm = 1.3079e-01, time/batch = 15.7157s	
8976/33250 (epoch 13.498), train_loss = 1.14991498, grad/param norm = 1.6063e-01, time/batch = 15.6922s	
8977/33250 (epoch 13.499), train_loss = 1.02197785, grad/param norm = 1.4709e-01, time/batch = 15.7867s	
8978/33250 (epoch 13.501), train_loss = 1.01228437, grad/param norm = 1.5954e-01, time/batch = 15.8017s	
8979/33250 (epoch 13.502), train_loss = 1.00986668, grad/param norm = 1.3662e-01, time/batch = 15.6433s	
8980/33250 (epoch 13.504), train_loss = 1.19194536, grad/param norm = 1.7887e-01, time/batch = 15.9607s	
8981/33250 (epoch 13.505), train_loss = 0.84864154, grad/param norm = 1.1962e-01, time/batch = 15.9365s	
8982/33250 (epoch 13.507), train_loss = 1.00427484, grad/param norm = 1.4296e-01, time/batch = 15.6080s	
8983/33250 (epoch 13.508), train_loss = 0.98308783, grad/param norm = 1.4006e-01, time/batch = 15.8624s	
8984/33250 (epoch 13.510), train_loss = 0.85909447, grad/param norm = 1.2597e-01, time/batch = 15.8324s	
8985/33250 (epoch 13.511), train_loss = 1.04212532, grad/param norm = 1.4699e-01, time/batch = 15.5281s	
8986/33250 (epoch 13.513), train_loss = 1.19894500, grad/param norm = 1.4972e-01, time/batch = 15.9901s	
8987/33250 (epoch 13.514), train_loss = 0.97565283, grad/param norm = 1.3191e-01, time/batch = 15.7772s	
8988/33250 (epoch 13.516), train_loss = 0.97595653, grad/param norm = 1.4359e-01, time/batch = 15.8894s	
8989/33250 (epoch 13.517), train_loss = 1.03652984, grad/param norm = 1.4515e-01, time/batch = 15.8758s	
8990/33250 (epoch 13.519), train_loss = 0.90555122, grad/param norm = 1.1673e-01, time/batch = 15.7251s	
8991/33250 (epoch 13.520), train_loss = 1.30282869, grad/param norm = 1.6172e-01, time/batch = 16.0425s	
8992/33250 (epoch 13.522), train_loss = 1.09973068, grad/param norm = 1.5083e-01, time/batch = 15.9366s	
8993/33250 (epoch 13.523), train_loss = 0.98614122, grad/param norm = 1.3993e-01, time/batch = 15.6888s	
8994/33250 (epoch 13.525), train_loss = 0.90742415, grad/param norm = 1.5369e-01, time/batch = 15.6933s	
8995/33250 (epoch 13.526), train_loss = 0.91141199, grad/param norm = 1.3693e-01, time/batch = 15.9288s	
8996/33250 (epoch 13.528), train_loss = 1.00771533, grad/param norm = 1.3842e-01, time/batch = 15.7535s	
8997/33250 (epoch 13.529), train_loss = 0.97690461, grad/param norm = 1.4960e-01, time/batch = 15.7694s	
8998/33250 (epoch 13.531), train_loss = 0.91882368, grad/param norm = 1.2736e-01, time/batch = 15.7921s	
8999/33250 (epoch 13.532), train_loss = 1.10879882, grad/param norm = 1.5142e-01, time/batch = 15.9104s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch13.53_1.4308.t7	
9000/33250 (epoch 13.534), train_loss = 0.92611467, grad/param norm = 1.2536e-01, time/batch = 15.9001s	
9001/33250 (epoch 13.535), train_loss = 1.21147697, grad/param norm = 1.5732e-01, time/batch = 16.1899s	
9002/33250 (epoch 13.537), train_loss = 1.10034170, grad/param norm = 1.4402e-01, time/batch = 15.9719s	
9003/33250 (epoch 13.538), train_loss = 1.12706447, grad/param norm = 1.4888e-01, time/batch = 15.7997s	
9004/33250 (epoch 13.540), train_loss = 1.21090865, grad/param norm = 1.3799e-01, time/batch = 16.0191s	
9005/33250 (epoch 13.541), train_loss = 1.16294277, grad/param norm = 1.4753e-01, time/batch = 15.8656s	
9006/33250 (epoch 13.543), train_loss = 1.12295658, grad/param norm = 1.5105e-01, time/batch = 16.0880s	
9007/33250 (epoch 13.544), train_loss = 0.99194267, grad/param norm = 1.4618e-01, time/batch = 16.0333s	
9008/33250 (epoch 13.546), train_loss = 1.03723403, grad/param norm = 1.6733e-01, time/batch = 15.7784s	
9009/33250 (epoch 13.547), train_loss = 0.99292757, grad/param norm = 1.5416e-01, time/batch = 16.1133s	
9010/33250 (epoch 13.549), train_loss = 1.11554347, grad/param norm = 1.5942e-01, time/batch = 15.9448s	
9011/33250 (epoch 13.550), train_loss = 1.01171039, grad/param norm = 1.5130e-01, time/batch = 15.7938s	
9012/33250 (epoch 13.552), train_loss = 1.06761250, grad/param norm = 1.3940e-01, time/batch = 16.1027s	
9013/33250 (epoch 13.553), train_loss = 0.96862871, grad/param norm = 1.4071e-01, time/batch = 15.8043s	
9014/33250 (epoch 13.555), train_loss = 1.04060582, grad/param norm = 1.3076e-01, time/batch = 15.9485s	
9015/33250 (epoch 13.556), train_loss = 1.16601611, grad/param norm = 1.7041e-01, time/batch = 15.7609s	
9016/33250 (epoch 13.558), train_loss = 1.15221554, grad/param norm = 1.5967e-01, time/batch = 16.0242s	
9017/33250 (epoch 13.559), train_loss = 0.94461381, grad/param norm = 1.4058e-01, time/batch = 16.0230s	
9018/33250 (epoch 13.561), train_loss = 0.97669097, grad/param norm = 1.4881e-01, time/batch = 16.0192s	
9019/33250 (epoch 13.562), train_loss = 1.18820887, grad/param norm = 1.6317e-01, time/batch = 15.6194s	
9020/33250 (epoch 13.564), train_loss = 1.26339400, grad/param norm = 1.6960e-01, time/batch = 15.8611s	
9021/33250 (epoch 13.565), train_loss = 1.22127515, grad/param norm = 1.7700e-01, time/batch = 15.7931s	
9022/33250 (epoch 13.567), train_loss = 1.16160009, grad/param norm = 1.4570e-01, time/batch = 15.7788s	
9023/33250 (epoch 13.568), train_loss = 1.05150830, grad/param norm = 1.6287e-01, time/batch = 15.7112s	
9024/33250 (epoch 13.570), train_loss = 1.20456326, grad/param norm = 1.7897e-01, time/batch = 15.8476s	
9025/33250 (epoch 13.571), train_loss = 1.24552978, grad/param norm = 1.5069e-01, time/batch = 15.6279s	
9026/33250 (epoch 13.573), train_loss = 1.10467153, grad/param norm = 1.5297e-01, time/batch = 15.8647s	
9027/33250 (epoch 13.574), train_loss = 0.96080057, grad/param norm = 1.3768e-01, time/batch = 15.8348s	
9028/33250 (epoch 13.576), train_loss = 1.09473896, grad/param norm = 1.3671e-01, time/batch = 15.8682s	
9029/33250 (epoch 13.577), train_loss = 1.04839070, grad/param norm = 1.4703e-01, time/batch = 15.6989s	
9030/33250 (epoch 13.579), train_loss = 0.94763750, grad/param norm = 1.5052e-01, time/batch = 15.7781s	
9031/33250 (epoch 13.580), train_loss = 0.99836805, grad/param norm = 1.2903e-01, time/batch = 16.0765s	
9032/33250 (epoch 13.582), train_loss = 1.03844403, grad/param norm = 1.3985e-01, time/batch = 15.8717s	
9033/33250 (epoch 13.583), train_loss = 1.10257656, grad/param norm = 1.3821e-01, time/batch = 15.9365s	
9034/33250 (epoch 13.585), train_loss = 1.14492208, grad/param norm = 1.5934e-01, time/batch = 15.7096s	
9035/33250 (epoch 13.586), train_loss = 1.03403047, grad/param norm = 1.8414e-01, time/batch = 15.8716s	
9036/33250 (epoch 13.588), train_loss = 1.06086867, grad/param norm = 1.3683e-01, time/batch = 15.8585s	
9037/33250 (epoch 13.589), train_loss = 1.11178154, grad/param norm = 1.5270e-01, time/batch = 15.7058s	
9038/33250 (epoch 13.591), train_loss = 1.10962301, grad/param norm = 1.6634e-01, time/batch = 15.9141s	
9039/33250 (epoch 13.592), train_loss = 1.05967688, grad/param norm = 1.3799e-01, time/batch = 15.6969s	
9040/33250 (epoch 13.594), train_loss = 1.25332636, grad/param norm = 1.8134e-01, time/batch = 15.6060s	
9041/33250 (epoch 13.595), train_loss = 1.12094727, grad/param norm = 1.4946e-01, time/batch = 15.8652s	
9042/33250 (epoch 13.597), train_loss = 0.91751747, grad/param norm = 1.3070e-01, time/batch = 15.6118s	
9043/33250 (epoch 13.598), train_loss = 1.04962961, grad/param norm = 1.5665e-01, time/batch = 15.9613s	
9044/33250 (epoch 13.600), train_loss = 1.05138529, grad/param norm = 1.6721e-01, time/batch = 15.7966s	
9045/33250 (epoch 13.602), train_loss = 1.10025134, grad/param norm = 1.7510e-01, time/batch = 15.7238s	
9046/33250 (epoch 13.603), train_loss = 1.09927770, grad/param norm = 1.5479e-01, time/batch = 15.7762s	
9047/33250 (epoch 13.605), train_loss = 1.06255970, grad/param norm = 1.5607e-01, time/batch = 15.7020s	
9048/33250 (epoch 13.606), train_loss = 1.10458081, grad/param norm = 1.5133e-01, time/batch = 15.7948s	
9049/33250 (epoch 13.608), train_loss = 1.06107972, grad/param norm = 1.4561e-01, time/batch = 15.3724s	
9050/33250 (epoch 13.609), train_loss = 0.95636711, grad/param norm = 1.4536e-01, time/batch = 15.9228s	
9051/33250 (epoch 13.611), train_loss = 1.09595259, grad/param norm = 1.5590e-01, time/batch = 15.9266s	
9052/33250 (epoch 13.612), train_loss = 1.08253192, grad/param norm = 1.6751e-01, time/batch = 15.8467s	
9053/33250 (epoch 13.614), train_loss = 1.28882602, grad/param norm = 1.7031e-01, time/batch = 15.8638s	
9054/33250 (epoch 13.615), train_loss = 1.16336778, grad/param norm = 1.5379e-01, time/batch = 15.9491s	
9055/33250 (epoch 13.617), train_loss = 1.41176543, grad/param norm = 1.8419e-01, time/batch = 15.8624s	
9056/33250 (epoch 13.618), train_loss = 1.36136339, grad/param norm = 2.1738e-01, time/batch = 15.8668s	
9057/33250 (epoch 13.620), train_loss = 1.18842684, grad/param norm = 1.8126e-01, time/batch = 15.8709s	
9058/33250 (epoch 13.621), train_loss = 1.04400913, grad/param norm = 1.4502e-01, time/batch = 15.7781s	
9059/33250 (epoch 13.623), train_loss = 0.98664309, grad/param norm = 1.4527e-01, time/batch = 15.6967s	
9060/33250 (epoch 13.624), train_loss = 1.02550418, grad/param norm = 1.5588e-01, time/batch = 15.7870s	
9061/33250 (epoch 13.626), train_loss = 1.01493016, grad/param norm = 1.6542e-01, time/batch = 15.9279s	
9062/33250 (epoch 13.627), train_loss = 1.01286838, grad/param norm = 1.5262e-01, time/batch = 15.7147s	
9063/33250 (epoch 13.629), train_loss = 1.11637399, grad/param norm = 1.6900e-01, time/batch = 15.7890s	
9064/33250 (epoch 13.630), train_loss = 1.03650321, grad/param norm = 1.6889e-01, time/batch = 15.8815s	
9065/33250 (epoch 13.632), train_loss = 0.87690220, grad/param norm = 1.2783e-01, time/batch = 16.0076s	
9066/33250 (epoch 13.633), train_loss = 1.12120413, grad/param norm = 1.5653e-01, time/batch = 15.8904s	
9067/33250 (epoch 13.635), train_loss = 0.95217535, grad/param norm = 1.4030e-01, time/batch = 15.8136s	
9068/33250 (epoch 13.636), train_loss = 0.96498021, grad/param norm = 1.3381e-01, time/batch = 15.6294s	
9069/33250 (epoch 13.638), train_loss = 1.00948772, grad/param norm = 1.3999e-01, time/batch = 15.8617s	
9070/33250 (epoch 13.639), train_loss = 0.90693588, grad/param norm = 1.4125e-01, time/batch = 15.6901s	
9071/33250 (epoch 13.641), train_loss = 0.96296185, grad/param norm = 1.3498e-01, time/batch = 15.9914s	
9072/33250 (epoch 13.642), train_loss = 0.87866390, grad/param norm = 1.4484e-01, time/batch = 15.4444s	
9073/33250 (epoch 13.644), train_loss = 0.79965229, grad/param norm = 1.3201e-01, time/batch = 15.6998s	
9074/33250 (epoch 13.645), train_loss = 1.17060797, grad/param norm = 1.7251e-01, time/batch = 15.6891s	
9075/33250 (epoch 13.647), train_loss = 0.92023672, grad/param norm = 1.5350e-01, time/batch = 15.9691s	
9076/33250 (epoch 13.648), train_loss = 0.99343146, grad/param norm = 1.5015e-01, time/batch = 15.9529s	
9077/33250 (epoch 13.650), train_loss = 1.17518048, grad/param norm = 1.5898e-01, time/batch = 15.7913s	
9078/33250 (epoch 13.651), train_loss = 1.07582698, grad/param norm = 1.8156e-01, time/batch = 15.8843s	
9079/33250 (epoch 13.653), train_loss = 0.94438163, grad/param norm = 1.4006e-01, time/batch = 15.6197s	
9080/33250 (epoch 13.654), train_loss = 0.98889421, grad/param norm = 1.4166e-01, time/batch = 15.9351s	
9081/33250 (epoch 13.656), train_loss = 1.10918675, grad/param norm = 1.5111e-01, time/batch = 15.7846s	
9082/33250 (epoch 13.657), train_loss = 0.84720440, grad/param norm = 1.4467e-01, time/batch = 15.7596s	
9083/33250 (epoch 13.659), train_loss = 1.00855932, grad/param norm = 1.4965e-01, time/batch = 15.6799s	
9084/33250 (epoch 13.660), train_loss = 1.02343839, grad/param norm = 1.4442e-01, time/batch = 15.7852s	
9085/33250 (epoch 13.662), train_loss = 1.07711360, grad/param norm = 1.5251e-01, time/batch = 15.7818s	
9086/33250 (epoch 13.663), train_loss = 0.98265233, grad/param norm = 1.4754e-01, time/batch = 15.6284s	
9087/33250 (epoch 13.665), train_loss = 1.09092479, grad/param norm = 1.5188e-01, time/batch = 15.8671s	
9088/33250 (epoch 13.666), train_loss = 1.00661263, grad/param norm = 1.4684e-01, time/batch = 15.9703s	
9089/33250 (epoch 13.668), train_loss = 1.21108347, grad/param norm = 1.5427e-01, time/batch = 15.7351s	
9090/33250 (epoch 13.669), train_loss = 1.08750455, grad/param norm = 1.5222e-01, time/batch = 16.0826s	
9091/33250 (epoch 13.671), train_loss = 0.97628703, grad/param norm = 1.6012e-01, time/batch = 15.8548s	
9092/33250 (epoch 13.672), train_loss = 1.16288667, grad/param norm = 1.5122e-01, time/batch = 15.9282s	
9093/33250 (epoch 13.674), train_loss = 0.99420824, grad/param norm = 1.3410e-01, time/batch = 15.8686s	
9094/33250 (epoch 13.675), train_loss = 1.03029958, grad/param norm = 1.3867e-01, time/batch = 15.8478s	
9095/33250 (epoch 13.677), train_loss = 1.17271742, grad/param norm = 1.6388e-01, time/batch = 15.9298s	
9096/33250 (epoch 13.678), train_loss = 1.04925756, grad/param norm = 1.5853e-01, time/batch = 15.7133s	
9097/33250 (epoch 13.680), train_loss = 1.17482010, grad/param norm = 2.2379e-01, time/batch = 15.7246s	
9098/33250 (epoch 13.681), train_loss = 0.92017790, grad/param norm = 1.4530e-01, time/batch = 15.7907s	
9099/33250 (epoch 13.683), train_loss = 1.03771658, grad/param norm = 1.5557e-01, time/batch = 15.8854s	
9100/33250 (epoch 13.684), train_loss = 0.94222663, grad/param norm = 1.5426e-01, time/batch = 15.7003s	
9101/33250 (epoch 13.686), train_loss = 0.95973141, grad/param norm = 1.5026e-01, time/batch = 15.8669s	
9102/33250 (epoch 13.687), train_loss = 1.01041779, grad/param norm = 1.4733e-01, time/batch = 15.8549s	
9103/33250 (epoch 13.689), train_loss = 0.98845550, grad/param norm = 1.5609e-01, time/batch = 15.7737s	
9104/33250 (epoch 13.690), train_loss = 1.09382620, grad/param norm = 1.5697e-01, time/batch = 15.6165s	
9105/33250 (epoch 13.692), train_loss = 1.03437779, grad/param norm = 1.5226e-01, time/batch = 15.6009s	
9106/33250 (epoch 13.693), train_loss = 1.10782840, grad/param norm = 1.4054e-01, time/batch = 15.9266s	
9107/33250 (epoch 13.695), train_loss = 1.08166653, grad/param norm = 1.5098e-01, time/batch = 16.0446s	
9108/33250 (epoch 13.696), train_loss = 1.08630548, grad/param norm = 1.4391e-01, time/batch = 15.9428s	
9109/33250 (epoch 13.698), train_loss = 0.96523441, grad/param norm = 1.5373e-01, time/batch = 16.1219s	
9110/33250 (epoch 13.699), train_loss = 1.26235380, grad/param norm = 1.5967e-01, time/batch = 15.9517s	
9111/33250 (epoch 13.701), train_loss = 1.02760086, grad/param norm = 1.4006e-01, time/batch = 15.9105s	
9112/33250 (epoch 13.702), train_loss = 1.02953308, grad/param norm = 1.8701e-01, time/batch = 15.9463s	
9113/33250 (epoch 13.704), train_loss = 1.27062807, grad/param norm = 2.1158e-01, time/batch = 15.6837s	
9114/33250 (epoch 13.705), train_loss = 0.94196147, grad/param norm = 1.3814e-01, time/batch = 15.7710s	
9115/33250 (epoch 13.707), train_loss = 0.86217738, grad/param norm = 1.3813e-01, time/batch = 15.7893s	
9116/33250 (epoch 13.708), train_loss = 1.12301179, grad/param norm = 1.5784e-01, time/batch = 15.7895s	
9117/33250 (epoch 13.710), train_loss = 1.12020837, grad/param norm = 1.5447e-01, time/batch = 15.7857s	
9118/33250 (epoch 13.711), train_loss = 0.98959226, grad/param norm = 1.6445e-01, time/batch = 15.9378s	
9119/33250 (epoch 13.713), train_loss = 1.10224065, grad/param norm = 1.5633e-01, time/batch = 15.8868s	
9120/33250 (epoch 13.714), train_loss = 1.04770820, grad/param norm = 1.4963e-01, time/batch = 15.8981s	
9121/33250 (epoch 13.716), train_loss = 1.14541425, grad/param norm = 1.5812e-01, time/batch = 15.8741s	
9122/33250 (epoch 13.717), train_loss = 0.97137635, grad/param norm = 1.3044e-01, time/batch = 16.0336s	
9123/33250 (epoch 13.719), train_loss = 1.02962880, grad/param norm = 1.4410e-01, time/batch = 15.8597s	
9124/33250 (epoch 13.720), train_loss = 1.27121266, grad/param norm = 1.6336e-01, time/batch = 15.8401s	
9125/33250 (epoch 13.722), train_loss = 0.95135379, grad/param norm = 1.3882e-01, time/batch = 15.8596s	
9126/33250 (epoch 13.723), train_loss = 0.84169181, grad/param norm = 1.2314e-01, time/batch = 15.9420s	
9127/33250 (epoch 13.725), train_loss = 0.88798809, grad/param norm = 1.2363e-01, time/batch = 15.7743s	
9128/33250 (epoch 13.726), train_loss = 1.01368571, grad/param norm = 1.3308e-01, time/batch = 16.0217s	
9129/33250 (epoch 13.728), train_loss = 1.10112660, grad/param norm = 1.5422e-01, time/batch = 15.9603s	
9130/33250 (epoch 13.729), train_loss = 1.18451505, grad/param norm = 1.5435e-01, time/batch = 15.8632s	
9131/33250 (epoch 13.731), train_loss = 0.99244502, grad/param norm = 1.4477e-01, time/batch = 15.9530s	
9132/33250 (epoch 13.732), train_loss = 0.92971846, grad/param norm = 1.3204e-01, time/batch = 15.9417s	
9133/33250 (epoch 13.734), train_loss = 1.06348725, grad/param norm = 1.5053e-01, time/batch = 15.7854s	
9134/33250 (epoch 13.735), train_loss = 1.05164901, grad/param norm = 1.4626e-01, time/batch = 15.7568s	
9135/33250 (epoch 13.737), train_loss = 1.03822260, grad/param norm = 1.2928e-01, time/batch = 15.7812s	
9136/33250 (epoch 13.738), train_loss = 1.04937370, grad/param norm = 1.4359e-01, time/batch = 15.5350s	
9137/33250 (epoch 13.740), train_loss = 1.18512525, grad/param norm = 1.5169e-01, time/batch = 15.9314s	
9138/33250 (epoch 13.741), train_loss = 1.14768068, grad/param norm = 1.5612e-01, time/batch = 15.6933s	
9139/33250 (epoch 13.743), train_loss = 1.01066120, grad/param norm = 1.3785e-01, time/batch = 15.9648s	
9140/33250 (epoch 13.744), train_loss = 1.02405262, grad/param norm = 1.5651e-01, time/batch = 15.9475s	
9141/33250 (epoch 13.746), train_loss = 0.99944733, grad/param norm = 1.3181e-01, time/batch = 15.7942s	
9142/33250 (epoch 13.747), train_loss = 1.01045032, grad/param norm = 1.5635e-01, time/batch = 15.8832s	
9143/33250 (epoch 13.749), train_loss = 1.16943137, grad/param norm = 1.7655e-01, time/batch = 15.7909s	
9144/33250 (epoch 13.750), train_loss = 1.13472941, grad/param norm = 1.6571e-01, time/batch = 29.1959s	
9145/33250 (epoch 13.752), train_loss = 0.99411519, grad/param norm = 1.4160e-01, time/batch = 15.9906s	
9146/33250 (epoch 13.753), train_loss = 1.03730659, grad/param norm = 1.5242e-01, time/batch = 15.7752s	
9147/33250 (epoch 13.755), train_loss = 1.02677394, grad/param norm = 1.4881e-01, time/batch = 15.9425s	
9148/33250 (epoch 13.756), train_loss = 1.11938088, grad/param norm = 1.4502e-01, time/batch = 15.5291s	
9149/33250 (epoch 13.758), train_loss = 1.17063759, grad/param norm = 1.5212e-01, time/batch = 15.7929s	
9150/33250 (epoch 13.759), train_loss = 0.94715111, grad/param norm = 1.3521e-01, time/batch = 15.6967s	
9151/33250 (epoch 13.761), train_loss = 1.00145142, grad/param norm = 1.4144e-01, time/batch = 15.9407s	
9152/33250 (epoch 13.762), train_loss = 1.17138791, grad/param norm = 1.4703e-01, time/batch = 15.8815s	
9153/33250 (epoch 13.764), train_loss = 0.96521851, grad/param norm = 1.7969e-01, time/batch = 15.7013s	
9154/33250 (epoch 13.765), train_loss = 1.08947606, grad/param norm = 1.5382e-01, time/batch = 15.7759s	
9155/33250 (epoch 13.767), train_loss = 0.86567920, grad/param norm = 1.4141e-01, time/batch = 15.9342s	
9156/33250 (epoch 13.768), train_loss = 0.91272005, grad/param norm = 1.5235e-01, time/batch = 15.8545s	
9157/33250 (epoch 13.770), train_loss = 1.11536027, grad/param norm = 1.6547e-01, time/batch = 16.0287s	
9158/33250 (epoch 13.771), train_loss = 1.11127986, grad/param norm = 1.6025e-01, time/batch = 16.1796s	
9159/33250 (epoch 13.773), train_loss = 1.02102321, grad/param norm = 1.5907e-01, time/batch = 15.9244s	
9160/33250 (epoch 13.774), train_loss = 0.88353840, grad/param norm = 1.4501e-01, time/batch = 15.9531s	
9161/33250 (epoch 13.776), train_loss = 0.99006203, grad/param norm = 1.4818e-01, time/batch = 16.0442s	
9162/33250 (epoch 13.777), train_loss = 1.15731015, grad/param norm = 1.7747e-01, time/batch = 16.1745s	
9163/33250 (epoch 13.779), train_loss = 1.02644053, grad/param norm = 1.5326e-01, time/batch = 15.9653s	
9164/33250 (epoch 13.780), train_loss = 1.23715350, grad/param norm = 1.9572e-01, time/batch = 15.9208s	
9165/33250 (epoch 13.782), train_loss = 1.10445209, grad/param norm = 1.4399e-01, time/batch = 15.7661s	
9166/33250 (epoch 13.783), train_loss = 0.87396966, grad/param norm = 1.4085e-01, time/batch = 15.8547s	
9167/33250 (epoch 13.785), train_loss = 0.94710814, grad/param norm = 1.4591e-01, time/batch = 15.7890s	
9168/33250 (epoch 13.786), train_loss = 1.13231505, grad/param norm = 1.6080e-01, time/batch = 15.8459s	
9169/33250 (epoch 13.788), train_loss = 1.13831282, grad/param norm = 1.5133e-01, time/batch = 15.7789s	
9170/33250 (epoch 13.789), train_loss = 1.15703683, grad/param norm = 1.7530e-01, time/batch = 15.8802s	
9171/33250 (epoch 13.791), train_loss = 1.21658130, grad/param norm = 1.5802e-01, time/batch = 16.2020s	
9172/33250 (epoch 13.792), train_loss = 1.29128144, grad/param norm = 1.6067e-01, time/batch = 15.8091s	
9173/33250 (epoch 13.794), train_loss = 1.04318638, grad/param norm = 1.5495e-01, time/batch = 15.9525s	
9174/33250 (epoch 13.795), train_loss = 1.09996771, grad/param norm = 1.6520e-01, time/batch = 15.8607s	
9175/33250 (epoch 13.797), train_loss = 1.17089274, grad/param norm = 1.7929e-01, time/batch = 15.8576s	
9176/33250 (epoch 13.798), train_loss = 1.06867857, grad/param norm = 1.7313e-01, time/batch = 15.8634s	
9177/33250 (epoch 13.800), train_loss = 1.10697039, grad/param norm = 1.6662e-01, time/batch = 15.9964s	
9178/33250 (epoch 13.802), train_loss = 0.99659043, grad/param norm = 1.2686e-01, time/batch = 15.6124s	
9179/33250 (epoch 13.803), train_loss = 1.03668589, grad/param norm = 1.3755e-01, time/batch = 15.7844s	
9180/33250 (epoch 13.805), train_loss = 1.11710527, grad/param norm = 1.5373e-01, time/batch = 15.7767s	
9181/33250 (epoch 13.806), train_loss = 1.08907404, grad/param norm = 1.5150e-01, time/batch = 16.0279s	
9182/33250 (epoch 13.808), train_loss = 1.03551983, grad/param norm = 1.3972e-01, time/batch = 16.0402s	
9183/33250 (epoch 13.809), train_loss = 0.96850908, grad/param norm = 1.4429e-01, time/batch = 16.0341s	
9184/33250 (epoch 13.811), train_loss = 0.96321622, grad/param norm = 1.3665e-01, time/batch = 15.8529s	
9185/33250 (epoch 13.812), train_loss = 1.14619381, grad/param norm = 1.6128e-01, time/batch = 15.7865s	
9186/33250 (epoch 13.814), train_loss = 1.05899308, grad/param norm = 1.5439e-01, time/batch = 15.6868s	
9187/33250 (epoch 13.815), train_loss = 1.12123032, grad/param norm = 1.4711e-01, time/batch = 15.8396s	
9188/33250 (epoch 13.817), train_loss = 1.04937709, grad/param norm = 1.5373e-01, time/batch = 15.7461s	
9189/33250 (epoch 13.818), train_loss = 0.98813277, grad/param norm = 1.4670e-01, time/batch = 15.6583s	
9190/33250 (epoch 13.820), train_loss = 1.06268485, grad/param norm = 1.4081e-01, time/batch = 15.8275s	
9191/33250 (epoch 13.821), train_loss = 0.99641119, grad/param norm = 1.3046e-01, time/batch = 15.8353s	
9192/33250 (epoch 13.823), train_loss = 1.36678258, grad/param norm = 1.8209e-01, time/batch = 16.0070s	
9193/33250 (epoch 13.824), train_loss = 1.01712995, grad/param norm = 1.5563e-01, time/batch = 15.5642s	
9194/33250 (epoch 13.826), train_loss = 1.10017316, grad/param norm = 1.6002e-01, time/batch = 15.8133s	
9195/33250 (epoch 13.827), train_loss = 0.83435314, grad/param norm = 1.3080e-01, time/batch = 15.7063s	
9196/33250 (epoch 13.829), train_loss = 1.07455104, grad/param norm = 1.7866e-01, time/batch = 15.9379s	
9197/33250 (epoch 13.830), train_loss = 1.17527955, grad/param norm = 1.8066e-01, time/batch = 15.8597s	
9198/33250 (epoch 13.832), train_loss = 1.05691310, grad/param norm = 1.4586e-01, time/batch = 15.7116s	
9199/33250 (epoch 13.833), train_loss = 1.09149709, grad/param norm = 1.6032e-01, time/batch = 15.7679s	
9200/33250 (epoch 13.835), train_loss = 0.97456300, grad/param norm = 1.7962e-01, time/batch = 15.8532s	
9201/33250 (epoch 13.836), train_loss = 1.03511963, grad/param norm = 1.3924e-01, time/batch = 15.8640s	
9202/33250 (epoch 13.838), train_loss = 1.02656590, grad/param norm = 1.4850e-01, time/batch = 16.0049s	
9203/33250 (epoch 13.839), train_loss = 1.02017336, grad/param norm = 1.5888e-01, time/batch = 16.0274s	
9204/33250 (epoch 13.841), train_loss = 0.97137112, grad/param norm = 1.5010e-01, time/batch = 15.8843s	
9205/33250 (epoch 13.842), train_loss = 1.23003888, grad/param norm = 1.4995e-01, time/batch = 15.7806s	
9206/33250 (epoch 13.844), train_loss = 1.18216080, grad/param norm = 1.8143e-01, time/batch = 15.8648s	
9207/33250 (epoch 13.845), train_loss = 1.29087939, grad/param norm = 1.8219e-01, time/batch = 16.2371s	
9208/33250 (epoch 13.847), train_loss = 1.21388550, grad/param norm = 1.6257e-01, time/batch = 15.7590s	
9209/33250 (epoch 13.848), train_loss = 1.38129611, grad/param norm = 1.7865e-01, time/batch = 15.5342s	
9210/33250 (epoch 13.850), train_loss = 1.17512654, grad/param norm = 1.6108e-01, time/batch = 15.3604s	
9211/33250 (epoch 13.851), train_loss = 0.98182462, grad/param norm = 1.5914e-01, time/batch = 16.0645s	
9212/33250 (epoch 13.853), train_loss = 1.15595220, grad/param norm = 1.7967e-01, time/batch = 15.9395s	
9213/33250 (epoch 13.854), train_loss = 0.97362785, grad/param norm = 1.3643e-01, time/batch = 15.6998s	
9214/33250 (epoch 13.856), train_loss = 1.00054011, grad/param norm = 1.6550e-01, time/batch = 15.7849s	
9215/33250 (epoch 13.857), train_loss = 0.89826878, grad/param norm = 1.3141e-01, time/batch = 16.0420s	
9216/33250 (epoch 13.859), train_loss = 0.91738618, grad/param norm = 1.3697e-01, time/batch = 15.8586s	
9217/33250 (epoch 13.860), train_loss = 1.05819818, grad/param norm = 1.3327e-01, time/batch = 15.8396s	
9218/33250 (epoch 13.862), train_loss = 0.93906642, grad/param norm = 1.2382e-01, time/batch = 15.7546s	
9219/33250 (epoch 13.863), train_loss = 0.97931885, grad/param norm = 1.5581e-01, time/batch = 15.3861s	
9220/33250 (epoch 13.865), train_loss = 1.11790261, grad/param norm = 1.5091e-01, time/batch = 15.3958s	
9221/33250 (epoch 13.866), train_loss = 1.02077816, grad/param norm = 1.5645e-01, time/batch = 15.8848s	
9222/33250 (epoch 13.868), train_loss = 1.18459728, grad/param norm = 1.7908e-01, time/batch = 15.8170s	
9223/33250 (epoch 13.869), train_loss = 1.11926741, grad/param norm = 1.5915e-01, time/batch = 15.5310s	
9224/33250 (epoch 13.871), train_loss = 0.83453122, grad/param norm = 1.3163e-01, time/batch = 15.8881s	
9225/33250 (epoch 13.872), train_loss = 1.08411620, grad/param norm = 1.5907e-01, time/batch = 15.7964s	
9226/33250 (epoch 13.874), train_loss = 0.97274618, grad/param norm = 1.7880e-01, time/batch = 16.0080s	
9227/33250 (epoch 13.875), train_loss = 0.97496896, grad/param norm = 1.6063e-01, time/batch = 15.7094s	
9228/33250 (epoch 13.877), train_loss = 1.15996616, grad/param norm = 1.5220e-01, time/batch = 15.8540s	
9229/33250 (epoch 13.878), train_loss = 1.09767180, grad/param norm = 1.4608e-01, time/batch = 15.7042s	
9230/33250 (epoch 13.880), train_loss = 1.03694402, grad/param norm = 1.6659e-01, time/batch = 16.0069s	
9231/33250 (epoch 13.881), train_loss = 1.25487350, grad/param norm = 1.8419e-01, time/batch = 15.7836s	
9232/33250 (epoch 13.883), train_loss = 1.08594529, grad/param norm = 1.6199e-01, time/batch = 15.6170s	
9233/33250 (epoch 13.884), train_loss = 1.07269750, grad/param norm = 1.6586e-01, time/batch = 15.7723s	
9234/33250 (epoch 13.886), train_loss = 0.97665695, grad/param norm = 1.3696e-01, time/batch = 15.9577s	
9235/33250 (epoch 13.887), train_loss = 1.01905334, grad/param norm = 1.6037e-01, time/batch = 16.0488s	
9236/33250 (epoch 13.889), train_loss = 0.99089430, grad/param norm = 1.3420e-01, time/batch = 15.7129s	
9237/33250 (epoch 13.890), train_loss = 0.87932793, grad/param norm = 1.2766e-01, time/batch = 16.0263s	
9238/33250 (epoch 13.892), train_loss = 1.11957623, grad/param norm = 1.5324e-01, time/batch = 15.9231s	
9239/33250 (epoch 13.893), train_loss = 1.12804251, grad/param norm = 1.5664e-01, time/batch = 15.9344s	
9240/33250 (epoch 13.895), train_loss = 1.02699621, grad/param norm = 1.6335e-01, time/batch = 15.5223s	
9241/33250 (epoch 13.896), train_loss = 1.14008783, grad/param norm = 1.6102e-01, time/batch = 16.0110s	
9242/33250 (epoch 13.898), train_loss = 1.04323581, grad/param norm = 1.5979e-01, time/batch = 15.7009s	
9243/33250 (epoch 13.899), train_loss = 0.95166052, grad/param norm = 1.3239e-01, time/batch = 15.7768s	
9244/33250 (epoch 13.901), train_loss = 0.91463904, grad/param norm = 1.3590e-01, time/batch = 15.9311s	
9245/33250 (epoch 13.902), train_loss = 1.02632534, grad/param norm = 1.4807e-01, time/batch = 15.8563s	
9246/33250 (epoch 13.904), train_loss = 0.95769002, grad/param norm = 1.3106e-01, time/batch = 15.6317s	
9247/33250 (epoch 13.905), train_loss = 0.98555497, grad/param norm = 1.3864e-01, time/batch = 15.7943s	
9248/33250 (epoch 13.907), train_loss = 0.96391167, grad/param norm = 1.3708e-01, time/batch = 15.7714s	
9249/33250 (epoch 13.908), train_loss = 1.03977252, grad/param norm = 1.3010e-01, time/batch = 15.3201s	
9250/33250 (epoch 13.910), train_loss = 1.10821812, grad/param norm = 1.6084e-01, time/batch = 15.4072s	
9251/33250 (epoch 13.911), train_loss = 0.91504838, grad/param norm = 1.3963e-01, time/batch = 15.7972s	
9252/33250 (epoch 13.913), train_loss = 0.97327539, grad/param norm = 1.3558e-01, time/batch = 15.5731s	
9253/33250 (epoch 13.914), train_loss = 0.87501980, grad/param norm = 1.4848e-01, time/batch = 16.0262s	
9254/33250 (epoch 13.916), train_loss = 0.97730844, grad/param norm = 1.2737e-01, time/batch = 15.7726s	
9255/33250 (epoch 13.917), train_loss = 0.98841369, grad/param norm = 1.2054e-01, time/batch = 15.8739s	
9256/33250 (epoch 13.919), train_loss = 0.98238332, grad/param norm = 1.6638e-01, time/batch = 15.6889s	
9257/33250 (epoch 13.920), train_loss = 1.06768269, grad/param norm = 1.6550e-01, time/batch = 15.6270s	
9258/33250 (epoch 13.922), train_loss = 1.09321585, grad/param norm = 1.7305e-01, time/batch = 15.7898s	
9259/33250 (epoch 13.923), train_loss = 1.03913162, grad/param norm = 1.6609e-01, time/batch = 15.9443s	
9260/33250 (epoch 13.925), train_loss = 0.98145991, grad/param norm = 1.4054e-01, time/batch = 15.8808s	
9261/33250 (epoch 13.926), train_loss = 1.00353659, grad/param norm = 1.4056e-01, time/batch = 15.6445s	
9262/33250 (epoch 13.928), train_loss = 1.01919734, grad/param norm = 1.4809e-01, time/batch = 15.7150s	
9263/33250 (epoch 13.929), train_loss = 0.82450509, grad/param norm = 1.1660e-01, time/batch = 15.8042s	
9264/33250 (epoch 13.931), train_loss = 1.11236669, grad/param norm = 1.4893e-01, time/batch = 16.0044s	
9265/33250 (epoch 13.932), train_loss = 1.06424951, grad/param norm = 1.6946e-01, time/batch = 15.8525s	
9266/33250 (epoch 13.934), train_loss = 0.96690730, grad/param norm = 1.3139e-01, time/batch = 15.8655s	
9267/33250 (epoch 13.935), train_loss = 0.96971523, grad/param norm = 1.4889e-01, time/batch = 15.6771s	
9268/33250 (epoch 13.937), train_loss = 1.04998008, grad/param norm = 1.7498e-01, time/batch = 15.8516s	
9269/33250 (epoch 13.938), train_loss = 1.08262657, grad/param norm = 1.5808e-01, time/batch = 15.8522s	
9270/33250 (epoch 13.940), train_loss = 1.02650604, grad/param norm = 1.5200e-01, time/batch = 15.9284s	
9271/33250 (epoch 13.941), train_loss = 1.06985232, grad/param norm = 1.5167e-01, time/batch = 15.9114s	
9272/33250 (epoch 13.943), train_loss = 1.19670246, grad/param norm = 1.5551e-01, time/batch = 15.7594s	
9273/33250 (epoch 13.944), train_loss = 0.96085478, grad/param norm = 1.3480e-01, time/batch = 15.6813s	
9274/33250 (epoch 13.946), train_loss = 1.18015310, grad/param norm = 1.5241e-01, time/batch = 15.6906s	
9275/33250 (epoch 13.947), train_loss = 0.94772609, grad/param norm = 1.4273e-01, time/batch = 15.9684s	
9276/33250 (epoch 13.949), train_loss = 1.16347710, grad/param norm = 1.5951e-01, time/batch = 15.9668s	
9277/33250 (epoch 13.950), train_loss = 1.08573137, grad/param norm = 1.4759e-01, time/batch = 15.8867s	
9278/33250 (epoch 13.952), train_loss = 1.01654477, grad/param norm = 1.6262e-01, time/batch = 16.0496s	
9279/33250 (epoch 13.953), train_loss = 1.12269199, grad/param norm = 1.5213e-01, time/batch = 16.0580s	
9280/33250 (epoch 13.955), train_loss = 1.14782451, grad/param norm = 1.5782e-01, time/batch = 16.1478s	
9281/33250 (epoch 13.956), train_loss = 1.12328323, grad/param norm = 1.7998e-01, time/batch = 16.1515s	
9282/33250 (epoch 13.958), train_loss = 0.95420062, grad/param norm = 1.3696e-01, time/batch = 15.7238s	
9283/33250 (epoch 13.959), train_loss = 0.96721663, grad/param norm = 1.3570e-01, time/batch = 15.6340s	
9284/33250 (epoch 13.961), train_loss = 1.25761779, grad/param norm = 1.5388e-01, time/batch = 15.4007s	
9285/33250 (epoch 13.962), train_loss = 1.06310660, grad/param norm = 1.4235e-01, time/batch = 15.3101s	
9286/33250 (epoch 13.964), train_loss = 1.23897457, grad/param norm = 1.6451e-01, time/batch = 15.7448s	
9287/33250 (epoch 13.965), train_loss = 1.12276586, grad/param norm = 1.8234e-01, time/batch = 15.7880s	
9288/33250 (epoch 13.967), train_loss = 1.05786459, grad/param norm = 1.5733e-01, time/batch = 15.8633s	
9289/33250 (epoch 13.968), train_loss = 1.25709833, grad/param norm = 1.4844e-01, time/batch = 15.7970s	
9290/33250 (epoch 13.970), train_loss = 1.34374873, grad/param norm = 2.1199e-01, time/batch = 15.8583s	
9291/33250 (epoch 13.971), train_loss = 1.22711693, grad/param norm = 1.8532e-01, time/batch = 15.8494s	
9292/33250 (epoch 13.973), train_loss = 1.00539351, grad/param norm = 1.6845e-01, time/batch = 15.6891s	
9293/33250 (epoch 13.974), train_loss = 1.13157714, grad/param norm = 1.5847e-01, time/batch = 15.5953s	
9294/33250 (epoch 13.976), train_loss = 1.04691991, grad/param norm = 1.6402e-01, time/batch = 15.9149s	
9295/33250 (epoch 13.977), train_loss = 0.97967879, grad/param norm = 1.4826e-01, time/batch = 15.5362s	
9296/33250 (epoch 13.979), train_loss = 1.06688837, grad/param norm = 1.6852e-01, time/batch = 15.6779s	
9297/33250 (epoch 13.980), train_loss = 1.05145492, grad/param norm = 1.4044e-01, time/batch = 15.7693s	
9298/33250 (epoch 13.982), train_loss = 0.92123650, grad/param norm = 1.3157e-01, time/batch = 15.7559s	
9299/33250 (epoch 13.983), train_loss = 1.08274480, grad/param norm = 1.5480e-01, time/batch = 15.4210s	
9300/33250 (epoch 13.985), train_loss = 0.99322506, grad/param norm = 1.5719e-01, time/batch = 15.4283s	
9301/33250 (epoch 13.986), train_loss = 1.13639292, grad/param norm = 1.6927e-01, time/batch = 15.6752s	
9302/33250 (epoch 13.988), train_loss = 1.16835464, grad/param norm = 1.6274e-01, time/batch = 15.8488s	
9303/33250 (epoch 13.989), train_loss = 1.16051077, grad/param norm = 1.6593e-01, time/batch = 15.7747s	
9304/33250 (epoch 13.991), train_loss = 1.09441520, grad/param norm = 1.5965e-01, time/batch = 15.8549s	
9305/33250 (epoch 13.992), train_loss = 1.02973014, grad/param norm = 1.4999e-01, time/batch = 15.7804s	
9306/33250 (epoch 13.994), train_loss = 0.97556304, grad/param norm = 1.4388e-01, time/batch = 15.5378s	
9307/33250 (epoch 13.995), train_loss = 1.03958393, grad/param norm = 1.6508e-01, time/batch = 15.7043s	
9308/33250 (epoch 13.997), train_loss = 0.78247347, grad/param norm = 1.4612e-01, time/batch = 15.8461s	
9309/33250 (epoch 13.998), train_loss = 1.07060911, grad/param norm = 1.3818e-01, time/batch = 15.6839s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
9310/33250 (epoch 14.000), train_loss = 1.06726168, grad/param norm = 1.4297e-01, time/batch = 15.5862s	
9311/33250 (epoch 14.002), train_loss = 1.21544479, grad/param norm = 1.6058e-01, time/batch = 15.6581s	
9312/33250 (epoch 14.003), train_loss = 1.15120830, grad/param norm = 1.6754e-01, time/batch = 15.4282s	
9313/33250 (epoch 14.005), train_loss = 0.86142076, grad/param norm = 1.2491e-01, time/batch = 15.8989s	
9314/33250 (epoch 14.006), train_loss = 0.92121904, grad/param norm = 1.4644e-01, time/batch = 15.5945s	
9315/33250 (epoch 14.008), train_loss = 1.21370317, grad/param norm = 1.5300e-01, time/batch = 15.6555s	
9316/33250 (epoch 14.009), train_loss = 1.21101384, grad/param norm = 1.6252e-01, time/batch = 15.7439s	
9317/33250 (epoch 14.011), train_loss = 0.94780076, grad/param norm = 1.4334e-01, time/batch = 15.8343s	
9318/33250 (epoch 14.012), train_loss = 1.09945587, grad/param norm = 2.0029e-01, time/batch = 15.6012s	
9319/33250 (epoch 14.014), train_loss = 1.17908746, grad/param norm = 1.6605e-01, time/batch = 15.9705s	
9320/33250 (epoch 14.015), train_loss = 1.04674778, grad/param norm = 1.5127e-01, time/batch = 15.6355s	
9321/33250 (epoch 14.017), train_loss = 1.06888092, grad/param norm = 1.5431e-01, time/batch = 16.0454s	
9322/33250 (epoch 14.018), train_loss = 0.87041554, grad/param norm = 1.4310e-01, time/batch = 15.7041s	
9323/33250 (epoch 14.020), train_loss = 1.02890572, grad/param norm = 1.4024e-01, time/batch = 15.7911s	
9324/33250 (epoch 14.021), train_loss = 1.05242942, grad/param norm = 1.5227e-01, time/batch = 15.7686s	
9325/33250 (epoch 14.023), train_loss = 0.88117815, grad/param norm = 1.4211e-01, time/batch = 15.7815s	
9326/33250 (epoch 14.024), train_loss = 1.12448267, grad/param norm = 1.4843e-01, time/batch = 15.7776s	
9327/33250 (epoch 14.026), train_loss = 1.03339473, grad/param norm = 1.3714e-01, time/batch = 15.7631s	
9328/33250 (epoch 14.027), train_loss = 1.01790532, grad/param norm = 1.4510e-01, time/batch = 15.8301s	
9329/33250 (epoch 14.029), train_loss = 1.06176510, grad/param norm = 1.4926e-01, time/batch = 15.5499s	
9330/33250 (epoch 14.030), train_loss = 1.03443542, grad/param norm = 1.5006e-01, time/batch = 15.8017s	
9331/33250 (epoch 14.032), train_loss = 1.27398678, grad/param norm = 1.8438e-01, time/batch = 15.7988s	
9332/33250 (epoch 14.033), train_loss = 0.99201545, grad/param norm = 1.3285e-01, time/batch = 16.0700s	
9333/33250 (epoch 14.035), train_loss = 1.00987425, grad/param norm = 1.5572e-01, time/batch = 15.7013s	
9334/33250 (epoch 14.036), train_loss = 1.12398952, grad/param norm = 1.6646e-01, time/batch = 15.8480s	
9335/33250 (epoch 14.038), train_loss = 1.01948376, grad/param norm = 1.3890e-01, time/batch = 15.7658s	
9336/33250 (epoch 14.039), train_loss = 0.94565569, grad/param norm = 1.4652e-01, time/batch = 15.6154s	
9337/33250 (epoch 14.041), train_loss = 1.07172507, grad/param norm = 1.5727e-01, time/batch = 15.6209s	
9338/33250 (epoch 14.042), train_loss = 0.88376035, grad/param norm = 1.2814e-01, time/batch = 15.9147s	
9339/33250 (epoch 14.044), train_loss = 1.20369855, grad/param norm = 1.6572e-01, time/batch = 15.5379s	
9340/33250 (epoch 14.045), train_loss = 1.15766217, grad/param norm = 1.4477e-01, time/batch = 15.7233s	
9341/33250 (epoch 14.047), train_loss = 1.12391495, grad/param norm = 1.6716e-01, time/batch = 15.6361s	
9342/33250 (epoch 14.048), train_loss = 1.19954514, grad/param norm = 1.7589e-01, time/batch = 15.8773s	
9343/33250 (epoch 14.050), train_loss = 1.05766163, grad/param norm = 1.4609e-01, time/batch = 15.7778s	
9344/33250 (epoch 14.051), train_loss = 1.03164128, grad/param norm = 1.4148e-01, time/batch = 15.7054s	
9345/33250 (epoch 14.053), train_loss = 1.08189070, grad/param norm = 1.5903e-01, time/batch = 15.6781s	
9346/33250 (epoch 14.054), train_loss = 0.87116539, grad/param norm = 1.2296e-01, time/batch = 15.5394s	
9347/33250 (epoch 14.056), train_loss = 0.94009149, grad/param norm = 1.4003e-01, time/batch = 15.8367s	
9348/33250 (epoch 14.057), train_loss = 1.10388077, grad/param norm = 1.4485e-01, time/batch = 15.7842s	
9349/33250 (epoch 14.059), train_loss = 1.02388521, grad/param norm = 1.4565e-01, time/batch = 15.6993s	
9350/33250 (epoch 14.060), train_loss = 1.10859486, grad/param norm = 1.6142e-01, time/batch = 15.7121s	
9351/33250 (epoch 14.062), train_loss = 1.19385693, grad/param norm = 1.5583e-01, time/batch = 15.9527s	
9352/33250 (epoch 14.063), train_loss = 1.17058524, grad/param norm = 1.5233e-01, time/batch = 15.8869s	
9353/33250 (epoch 14.065), train_loss = 1.03272744, grad/param norm = 1.3774e-01, time/batch = 15.8649s	
9354/33250 (epoch 14.066), train_loss = 1.11181512, grad/param norm = 1.5596e-01, time/batch = 15.6921s	
9355/33250 (epoch 14.068), train_loss = 1.00583649, grad/param norm = 1.4886e-01, time/batch = 15.8623s	
9356/33250 (epoch 14.069), train_loss = 1.06228294, grad/param norm = 1.4795e-01, time/batch = 15.6864s	
9357/33250 (epoch 14.071), train_loss = 0.94527783, grad/param norm = 1.4479e-01, time/batch = 15.5392s	
9358/33250 (epoch 14.072), train_loss = 0.94002384, grad/param norm = 1.2786e-01, time/batch = 15.6781s	
9359/33250 (epoch 14.074), train_loss = 1.11230877, grad/param norm = 1.6194e-01, time/batch = 15.9333s	
9360/33250 (epoch 14.075), train_loss = 0.98557799, grad/param norm = 1.3594e-01, time/batch = 15.7032s	
9361/33250 (epoch 14.077), train_loss = 1.03181067, grad/param norm = 1.5342e-01, time/batch = 15.9722s	
9362/33250 (epoch 14.078), train_loss = 1.04615083, grad/param norm = 1.4365e-01, time/batch = 15.9532s	
9363/33250 (epoch 14.080), train_loss = 1.07013660, grad/param norm = 1.7452e-01, time/batch = 15.7566s	
9364/33250 (epoch 14.081), train_loss = 1.08012818, grad/param norm = 1.4988e-01, time/batch = 15.8447s	
9365/33250 (epoch 14.083), train_loss = 1.13733149, grad/param norm = 1.4371e-01, time/batch = 15.7042s	
9366/33250 (epoch 14.084), train_loss = 1.04896658, grad/param norm = 1.5630e-01, time/batch = 15.8548s	
9367/33250 (epoch 14.086), train_loss = 1.00103652, grad/param norm = 1.3658e-01, time/batch = 15.7625s	
9368/33250 (epoch 14.087), train_loss = 0.92485645, grad/param norm = 1.4037e-01, time/batch = 15.7712s	
9369/33250 (epoch 14.089), train_loss = 1.09948942, grad/param norm = 1.5509e-01, time/batch = 17.7380s	
9370/33250 (epoch 14.090), train_loss = 1.05118258, grad/param norm = 1.4664e-01, time/batch = 27.8858s	
9371/33250 (epoch 14.092), train_loss = 0.96733278, grad/param norm = 1.2752e-01, time/batch = 15.9451s	
9372/33250 (epoch 14.093), train_loss = 1.08194271, grad/param norm = 1.4696e-01, time/batch = 15.7912s	
9373/33250 (epoch 14.095), train_loss = 0.99007781, grad/param norm = 1.3606e-01, time/batch = 15.7126s	
9374/33250 (epoch 14.096), train_loss = 0.86482567, grad/param norm = 1.4864e-01, time/batch = 15.6183s	
9375/33250 (epoch 14.098), train_loss = 0.93437145, grad/param norm = 1.5423e-01, time/batch = 15.7773s	
9376/33250 (epoch 14.099), train_loss = 0.78326959, grad/param norm = 1.2743e-01, time/batch = 15.6007s	
9377/33250 (epoch 14.101), train_loss = 1.01169593, grad/param norm = 1.4371e-01, time/batch = 15.8672s	
9378/33250 (epoch 14.102), train_loss = 0.93084754, grad/param norm = 1.5367e-01, time/batch = 15.7817s	
9379/33250 (epoch 14.104), train_loss = 0.83582042, grad/param norm = 1.3109e-01, time/batch = 15.6202s	
9380/33250 (epoch 14.105), train_loss = 0.96828721, grad/param norm = 1.3805e-01, time/batch = 15.8765s	
9381/33250 (epoch 14.107), train_loss = 0.85519236, grad/param norm = 1.2393e-01, time/batch = 15.8717s	
9382/33250 (epoch 14.108), train_loss = 1.01451445, grad/param norm = 1.4460e-01, time/batch = 15.8483s	
9383/33250 (epoch 14.110), train_loss = 0.83973972, grad/param norm = 1.4171e-01, time/batch = 15.7127s	
9384/33250 (epoch 14.111), train_loss = 1.00795881, grad/param norm = 1.4696e-01, time/batch = 15.7822s	
9385/33250 (epoch 14.113), train_loss = 1.02411548, grad/param norm = 1.4975e-01, time/batch = 15.7812s	
9386/33250 (epoch 14.114), train_loss = 0.93891340, grad/param norm = 1.4706e-01, time/batch = 15.6960s	
9387/33250 (epoch 14.116), train_loss = 1.03369719, grad/param norm = 1.4886e-01, time/batch = 15.8596s	
9388/33250 (epoch 14.117), train_loss = 0.99981991, grad/param norm = 1.4104e-01, time/batch = 15.8525s	
9389/33250 (epoch 14.119), train_loss = 0.99183466, grad/param norm = 1.4436e-01, time/batch = 15.5438s	
9390/33250 (epoch 14.120), train_loss = 0.78958505, grad/param norm = 1.3164e-01, time/batch = 15.9211s	
9391/33250 (epoch 14.122), train_loss = 1.14689047, grad/param norm = 1.4422e-01, time/batch = 15.8669s	
9392/33250 (epoch 14.123), train_loss = 1.04355624, grad/param norm = 1.4551e-01, time/batch = 15.8613s	
9393/33250 (epoch 14.125), train_loss = 0.86759402, grad/param norm = 1.4556e-01, time/batch = 15.7326s	
9394/33250 (epoch 14.126), train_loss = 1.00699059, grad/param norm = 1.4367e-01, time/batch = 15.7266s	
9395/33250 (epoch 14.128), train_loss = 0.95736213, grad/param norm = 1.3481e-01, time/batch = 15.4560s	
9396/33250 (epoch 14.129), train_loss = 1.01641757, grad/param norm = 1.4582e-01, time/batch = 15.8712s	
9397/33250 (epoch 14.131), train_loss = 1.00578674, grad/param norm = 1.5337e-01, time/batch = 15.6720s	
9398/33250 (epoch 14.132), train_loss = 0.99689113, grad/param norm = 1.5007e-01, time/batch = 16.0718s	
9399/33250 (epoch 14.134), train_loss = 1.02652849, grad/param norm = 1.4839e-01, time/batch = 16.0598s	
9400/33250 (epoch 14.135), train_loss = 1.06809594, grad/param norm = 1.4368e-01, time/batch = 15.7100s	
9401/33250 (epoch 14.137), train_loss = 0.92423811, grad/param norm = 1.4227e-01, time/batch = 15.6916s	
9402/33250 (epoch 14.138), train_loss = 0.95047693, grad/param norm = 1.2469e-01, time/batch = 16.0581s	
9403/33250 (epoch 14.140), train_loss = 0.79278015, grad/param norm = 1.2496e-01, time/batch = 16.2421s	
9404/33250 (epoch 14.141), train_loss = 1.24434482, grad/param norm = 1.9571e-01, time/batch = 15.6352s	
9405/33250 (epoch 14.143), train_loss = 0.81884031, grad/param norm = 1.5053e-01, time/batch = 15.7118s	
9406/33250 (epoch 14.144), train_loss = 0.99194545, grad/param norm = 1.4084e-01, time/batch = 15.8332s	
9407/33250 (epoch 14.146), train_loss = 0.95627290, grad/param norm = 1.3459e-01, time/batch = 15.7675s	
9408/33250 (epoch 14.147), train_loss = 0.94292417, grad/param norm = 1.4758e-01, time/batch = 15.9410s	
9409/33250 (epoch 14.149), train_loss = 0.98024511, grad/param norm = 1.4807e-01, time/batch = 16.0880s	
9410/33250 (epoch 14.150), train_loss = 0.91748845, grad/param norm = 1.3385e-01, time/batch = 16.0809s	
9411/33250 (epoch 14.152), train_loss = 0.87422260, grad/param norm = 1.3568e-01, time/batch = 16.0145s	
9412/33250 (epoch 14.153), train_loss = 1.16888635, grad/param norm = 1.5689e-01, time/batch = 16.0172s	
9413/33250 (epoch 14.155), train_loss = 1.02955074, grad/param norm = 1.6246e-01, time/batch = 15.7258s	
9414/33250 (epoch 14.156), train_loss = 1.22396970, grad/param norm = 1.5005e-01, time/batch = 15.9462s	
9415/33250 (epoch 14.158), train_loss = 1.23580969, grad/param norm = 1.6979e-01, time/batch = 16.0208s	
9416/33250 (epoch 14.159), train_loss = 1.04071240, grad/param norm = 1.6179e-01, time/batch = 15.9237s	
9417/33250 (epoch 14.161), train_loss = 1.07676227, grad/param norm = 1.6057e-01, time/batch = 15.8955s	
9418/33250 (epoch 14.162), train_loss = 0.91355828, grad/param norm = 1.4035e-01, time/batch = 15.8334s	
9419/33250 (epoch 14.164), train_loss = 1.01170276, grad/param norm = 1.5293e-01, time/batch = 16.0799s	
9420/33250 (epoch 14.165), train_loss = 1.10659617, grad/param norm = 1.5516e-01, time/batch = 15.4514s	
9421/33250 (epoch 14.167), train_loss = 1.17357211, grad/param norm = 1.5712e-01, time/batch = 16.1310s	
9422/33250 (epoch 14.168), train_loss = 0.86502853, grad/param norm = 1.1906e-01, time/batch = 16.0790s	
9423/33250 (epoch 14.170), train_loss = 0.99578810, grad/param norm = 1.5107e-01, time/batch = 15.7221s	
9424/33250 (epoch 14.171), train_loss = 0.99121370, grad/param norm = 1.3609e-01, time/batch = 15.7013s	
9425/33250 (epoch 14.173), train_loss = 0.97056344, grad/param norm = 1.3776e-01, time/batch = 16.0283s	
9426/33250 (epoch 14.174), train_loss = 1.02183126, grad/param norm = 1.4409e-01, time/batch = 15.4396s	
9427/33250 (epoch 14.176), train_loss = 0.99853729, grad/param norm = 1.4089e-01, time/batch = 15.8873s	
9428/33250 (epoch 14.177), train_loss = 0.97046804, grad/param norm = 1.2776e-01, time/batch = 16.1389s	
9429/33250 (epoch 14.179), train_loss = 0.93997931, grad/param norm = 1.3467e-01, time/batch = 15.6922s	
9430/33250 (epoch 14.180), train_loss = 0.86054881, grad/param norm = 1.2805e-01, time/batch = 15.1956s	
9431/33250 (epoch 14.182), train_loss = 0.94903170, grad/param norm = 1.5866e-01, time/batch = 15.6694s	
9432/33250 (epoch 14.183), train_loss = 1.15762937, grad/param norm = 1.5448e-01, time/batch = 15.2042s	
9433/33250 (epoch 14.185), train_loss = 1.10772331, grad/param norm = 1.7329e-01, time/batch = 15.6963s	
9434/33250 (epoch 14.186), train_loss = 1.03535558, grad/param norm = 1.5248e-01, time/batch = 15.2278s	
9435/33250 (epoch 14.188), train_loss = 1.14253955, grad/param norm = 1.6941e-01, time/batch = 15.4712s	
9436/33250 (epoch 14.189), train_loss = 0.84322092, grad/param norm = 1.6886e-01, time/batch = 15.1375s	
9437/33250 (epoch 14.191), train_loss = 0.94224802, grad/param norm = 1.4357e-01, time/batch = 15.5781s	
9438/33250 (epoch 14.192), train_loss = 0.95367566, grad/param norm = 1.3822e-01, time/batch = 14.9649s	
9439/33250 (epoch 14.194), train_loss = 0.94483463, grad/param norm = 1.4653e-01, time/batch = 15.4857s	
9440/33250 (epoch 14.195), train_loss = 1.19951487, grad/param norm = 1.5020e-01, time/batch = 16.0557s	
9441/33250 (epoch 14.197), train_loss = 0.97569035, grad/param norm = 1.4292e-01, time/batch = 16.0703s	
9442/33250 (epoch 14.198), train_loss = 1.15319261, grad/param norm = 1.5857e-01, time/batch = 15.3485s	
9443/33250 (epoch 14.200), train_loss = 1.03184920, grad/param norm = 1.5416e-01, time/batch = 15.2950s	
9444/33250 (epoch 14.202), train_loss = 0.94660507, grad/param norm = 1.3673e-01, time/batch = 15.3828s	
9445/33250 (epoch 14.203), train_loss = 0.95300373, grad/param norm = 1.4808e-01, time/batch = 15.1469s	
9446/33250 (epoch 14.205), train_loss = 1.04903819, grad/param norm = 1.4912e-01, time/batch = 15.3863s	
9447/33250 (epoch 14.206), train_loss = 1.10078310, grad/param norm = 1.5496e-01, time/batch = 15.4967s	
9448/33250 (epoch 14.208), train_loss = 1.17411812, grad/param norm = 1.7227e-01, time/batch = 15.2848s	
9449/33250 (epoch 14.209), train_loss = 0.96333208, grad/param norm = 1.3760e-01, time/batch = 15.1304s	
9450/33250 (epoch 14.211), train_loss = 1.11344421, grad/param norm = 1.5599e-01, time/batch = 15.4193s	
9451/33250 (epoch 14.212), train_loss = 1.26355151, grad/param norm = 1.5558e-01, time/batch = 15.2886s	
9452/33250 (epoch 14.214), train_loss = 1.01440738, grad/param norm = 1.3178e-01, time/batch = 15.5302s	
9453/33250 (epoch 14.215), train_loss = 1.26232324, grad/param norm = 1.9739e-01, time/batch = 15.3740s	
9454/33250 (epoch 14.217), train_loss = 1.17470172, grad/param norm = 1.6994e-01, time/batch = 15.9873s	
9455/33250 (epoch 14.218), train_loss = 1.11448338, grad/param norm = 1.4056e-01, time/batch = 15.1749s	
9456/33250 (epoch 14.220), train_loss = 1.09673040, grad/param norm = 1.5468e-01, time/batch = 15.6605s	
9457/33250 (epoch 14.221), train_loss = 1.25378624, grad/param norm = 1.7296e-01, time/batch = 15.3907s	
9458/33250 (epoch 14.223), train_loss = 1.03362702, grad/param norm = 1.5127e-01, time/batch = 15.3969s	
9459/33250 (epoch 14.224), train_loss = 1.10142880, grad/param norm = 1.6156e-01, time/batch = 14.6346s	
9460/33250 (epoch 14.226), train_loss = 1.21021398, grad/param norm = 1.5500e-01, time/batch = 15.1953s	
9461/33250 (epoch 14.227), train_loss = 1.07108058, grad/param norm = 1.4891e-01, time/batch = 15.1068s	
9462/33250 (epoch 14.229), train_loss = 1.07944152, grad/param norm = 1.3682e-01, time/batch = 15.2140s	
9463/33250 (epoch 14.230), train_loss = 0.99365391, grad/param norm = 1.4966e-01, time/batch = 15.3570s	
9464/33250 (epoch 14.232), train_loss = 0.98261565, grad/param norm = 1.2882e-01, time/batch = 15.5019s	
9465/33250 (epoch 14.233), train_loss = 0.96097138, grad/param norm = 1.3955e-01, time/batch = 15.6721s	
9466/33250 (epoch 14.235), train_loss = 1.19690819, grad/param norm = 1.4991e-01, time/batch = 15.4333s	
9467/33250 (epoch 14.236), train_loss = 0.97354635, grad/param norm = 1.5268e-01, time/batch = 16.2727s	
9468/33250 (epoch 14.238), train_loss = 1.12078675, grad/param norm = 1.5825e-01, time/batch = 16.9525s	
9469/33250 (epoch 14.239), train_loss = 1.19807900, grad/param norm = 1.6542e-01, time/batch = 15.1116s	
9470/33250 (epoch 14.241), train_loss = 1.13496010, grad/param norm = 1.6789e-01, time/batch = 17.2688s	
9471/33250 (epoch 14.242), train_loss = 1.10695804, grad/param norm = 1.5209e-01, time/batch = 15.2655s	
9472/33250 (epoch 14.244), train_loss = 1.15387552, grad/param norm = 1.7499e-01, time/batch = 17.0892s	
9473/33250 (epoch 14.245), train_loss = 1.04186486, grad/param norm = 1.4866e-01, time/batch = 15.6650s	
9474/33250 (epoch 14.247), train_loss = 1.07613081, grad/param norm = 1.4545e-01, time/batch = 15.6915s	
9475/33250 (epoch 14.248), train_loss = 1.28313737, grad/param norm = 1.8281e-01, time/batch = 15.2929s	
9476/33250 (epoch 14.250), train_loss = 1.12626993, grad/param norm = 1.4569e-01, time/batch = 16.7212s	
9477/33250 (epoch 14.251), train_loss = 1.06915778, grad/param norm = 1.4952e-01, time/batch = 18.1243s	
9478/33250 (epoch 14.253), train_loss = 0.95733648, grad/param norm = 1.3086e-01, time/batch = 16.9680s	
9479/33250 (epoch 14.254), train_loss = 0.99367184, grad/param norm = 1.5739e-01, time/batch = 18.3316s	
9480/33250 (epoch 14.256), train_loss = 1.05877594, grad/param norm = 1.3870e-01, time/batch = 15.2039s	
9481/33250 (epoch 14.257), train_loss = 1.19125445, grad/param norm = 1.5150e-01, time/batch = 16.6880s	
9482/33250 (epoch 14.259), train_loss = 1.16719717, grad/param norm = 1.5693e-01, time/batch = 15.6850s	
9483/33250 (epoch 14.260), train_loss = 0.95014201, grad/param norm = 1.4334e-01, time/batch = 16.8515s	
9484/33250 (epoch 14.262), train_loss = 1.09331599, grad/param norm = 1.4201e-01, time/batch = 15.6146s	
9485/33250 (epoch 14.263), train_loss = 0.97911591, grad/param norm = 1.5757e-01, time/batch = 15.5166s	
9486/33250 (epoch 14.265), train_loss = 1.10879491, grad/param norm = 1.4445e-01, time/batch = 17.0271s	
9487/33250 (epoch 14.266), train_loss = 1.05052216, grad/param norm = 1.5841e-01, time/batch = 17.2946s	
9488/33250 (epoch 14.268), train_loss = 0.96380495, grad/param norm = 1.4414e-01, time/batch = 17.1025s	
9489/33250 (epoch 14.269), train_loss = 0.85005155, grad/param norm = 1.3916e-01, time/batch = 16.8328s	
9490/33250 (epoch 14.271), train_loss = 1.00936331, grad/param norm = 1.4430e-01, time/batch = 18.5070s	
9491/33250 (epoch 14.272), train_loss = 0.89593169, grad/param norm = 1.2568e-01, time/batch = 16.9457s	
9492/33250 (epoch 14.274), train_loss = 0.79825835, grad/param norm = 1.3092e-01, time/batch = 16.0373s	
9493/33250 (epoch 14.275), train_loss = 0.95900394, grad/param norm = 1.3293e-01, time/batch = 15.4355s	
9494/33250 (epoch 14.277), train_loss = 0.83183977, grad/param norm = 1.2892e-01, time/batch = 15.5856s	
9495/33250 (epoch 14.278), train_loss = 0.96772122, grad/param norm = 1.4391e-01, time/batch = 15.6883s	
9496/33250 (epoch 14.280), train_loss = 0.91026093, grad/param norm = 1.2924e-01, time/batch = 15.7023s	
9497/33250 (epoch 14.281), train_loss = 1.04160341, grad/param norm = 1.4455e-01, time/batch = 16.2124s	
9498/33250 (epoch 14.283), train_loss = 1.08758220, grad/param norm = 1.8916e-01, time/batch = 18.8576s	
9499/33250 (epoch 14.284), train_loss = 0.93749172, grad/param norm = 1.5172e-01, time/batch = 16.7885s	
9500/33250 (epoch 14.286), train_loss = 1.09388353, grad/param norm = 1.5442e-01, time/batch = 16.1506s	
9501/33250 (epoch 14.287), train_loss = 0.89006392, grad/param norm = 1.3031e-01, time/batch = 16.4415s	
9502/33250 (epoch 14.289), train_loss = 0.86125643, grad/param norm = 1.4744e-01, time/batch = 16.4405s	
9503/33250 (epoch 14.290), train_loss = 1.04171694, grad/param norm = 1.3469e-01, time/batch = 16.0300s	
9504/33250 (epoch 14.292), train_loss = 1.07760153, grad/param norm = 1.5183e-01, time/batch = 15.7590s	
9505/33250 (epoch 14.293), train_loss = 1.15323577, grad/param norm = 1.6901e-01, time/batch = 16.1715s	
9506/33250 (epoch 14.295), train_loss = 1.08373624, grad/param norm = 1.5052e-01, time/batch = 18.0279s	
9507/33250 (epoch 14.296), train_loss = 1.05730674, grad/param norm = 1.5178e-01, time/batch = 17.4560s	
9508/33250 (epoch 14.298), train_loss = 0.87157178, grad/param norm = 1.2800e-01, time/batch = 18.1203s	
9509/33250 (epoch 14.299), train_loss = 0.81792893, grad/param norm = 1.3728e-01, time/batch = 15.6923s	
9510/33250 (epoch 14.301), train_loss = 1.07709217, grad/param norm = 1.3831e-01, time/batch = 17.6746s	
9511/33250 (epoch 14.302), train_loss = 1.08132982, grad/param norm = 1.6845e-01, time/batch = 17.4253s	
9512/33250 (epoch 14.304), train_loss = 0.94495481, grad/param norm = 1.3056e-01, time/batch = 15.1233s	
9513/33250 (epoch 14.305), train_loss = 1.02979351, grad/param norm = 1.4711e-01, time/batch = 15.6222s	
9514/33250 (epoch 14.307), train_loss = 1.09204230, grad/param norm = 1.4946e-01, time/batch = 15.5042s	
9515/33250 (epoch 14.308), train_loss = 1.27566715, grad/param norm = 1.7038e-01, time/batch = 15.6185s	
9516/33250 (epoch 14.310), train_loss = 1.02459713, grad/param norm = 1.5495e-01, time/batch = 16.9476s	
9517/33250 (epoch 14.311), train_loss = 1.16389104, grad/param norm = 1.5324e-01, time/batch = 16.7990s	
9518/33250 (epoch 14.313), train_loss = 0.85721609, grad/param norm = 1.3973e-01, time/batch = 16.6158s	
9519/33250 (epoch 14.314), train_loss = 1.02277510, grad/param norm = 1.4530e-01, time/batch = 15.9571s	
9520/33250 (epoch 14.316), train_loss = 1.19429633, grad/param norm = 1.6506e-01, time/batch = 15.1121s	
9521/33250 (epoch 14.317), train_loss = 0.92081440, grad/param norm = 1.3601e-01, time/batch = 15.6542s	
9522/33250 (epoch 14.319), train_loss = 1.13137494, grad/param norm = 1.7151e-01, time/batch = 15.7711s	
9523/33250 (epoch 14.320), train_loss = 1.17188186, grad/param norm = 1.8863e-01, time/batch = 15.7689s	
9524/33250 (epoch 14.322), train_loss = 1.21473632, grad/param norm = 1.7007e-01, time/batch = 17.5319s	
9525/33250 (epoch 14.323), train_loss = 1.26818421, grad/param norm = 1.7713e-01, time/batch = 16.1123s	
9526/33250 (epoch 14.325), train_loss = 1.08445885, grad/param norm = 1.7272e-01, time/batch = 18.1839s	
9527/33250 (epoch 14.326), train_loss = 1.21698329, grad/param norm = 1.5437e-01, time/batch = 16.8107s	
9528/33250 (epoch 14.328), train_loss = 0.97863296, grad/param norm = 1.3179e-01, time/batch = 18.4695s	
9529/33250 (epoch 14.329), train_loss = 1.05540042, grad/param norm = 1.6700e-01, time/batch = 15.9521s	
9530/33250 (epoch 14.331), train_loss = 1.03586346, grad/param norm = 1.7112e-01, time/batch = 16.1412s	
9531/33250 (epoch 14.332), train_loss = 0.99254777, grad/param norm = 1.3933e-01, time/batch = 17.4386s	
9532/33250 (epoch 14.334), train_loss = 1.18635349, grad/param norm = 1.5071e-01, time/batch = 16.1011s	
9533/33250 (epoch 14.335), train_loss = 0.77051612, grad/param norm = 1.3320e-01, time/batch = 15.3747s	
9534/33250 (epoch 14.337), train_loss = 1.07016388, grad/param norm = 1.4205e-01, time/batch = 16.5365s	
9535/33250 (epoch 14.338), train_loss = 1.17207336, grad/param norm = 1.6491e-01, time/batch = 15.9457s	
9536/33250 (epoch 14.340), train_loss = 1.03568051, grad/param norm = 1.4290e-01, time/batch = 16.8440s	
9537/33250 (epoch 14.341), train_loss = 0.96423899, grad/param norm = 1.5211e-01, time/batch = 19.2004s	
9538/33250 (epoch 14.343), train_loss = 0.99653295, grad/param norm = 1.5024e-01, time/batch = 16.3863s	
9539/33250 (epoch 14.344), train_loss = 1.02215759, grad/param norm = 1.3886e-01, time/batch = 16.0034s	
9540/33250 (epoch 14.346), train_loss = 0.87713674, grad/param norm = 1.3141e-01, time/batch = 15.5692s	
9541/33250 (epoch 14.347), train_loss = 1.31342525, grad/param norm = 1.7012e-01, time/batch = 16.8498s	
9542/33250 (epoch 14.349), train_loss = 0.97876154, grad/param norm = 1.4263e-01, time/batch = 16.3488s	
9543/33250 (epoch 14.350), train_loss = 1.00807637, grad/param norm = 1.4306e-01, time/batch = 16.1002s	
9544/33250 (epoch 14.352), train_loss = 0.90784823, grad/param norm = 1.5492e-01, time/batch = 16.6086s	
9545/33250 (epoch 14.353), train_loss = 0.99222911, grad/param norm = 1.3794e-01, time/batch = 17.5129s	
9546/33250 (epoch 14.355), train_loss = 0.99829730, grad/param norm = 1.6201e-01, time/batch = 18.0965s	
9547/33250 (epoch 14.356), train_loss = 0.94975570, grad/param norm = 1.6163e-01, time/batch = 16.3835s	
9548/33250 (epoch 14.358), train_loss = 0.97882347, grad/param norm = 1.4200e-01, time/batch = 19.2828s	
9549/33250 (epoch 14.359), train_loss = 0.97655187, grad/param norm = 1.3015e-01, time/batch = 16.7021s	
9550/33250 (epoch 14.361), train_loss = 1.21507743, grad/param norm = 1.7574e-01, time/batch = 16.5888s	
9551/33250 (epoch 14.362), train_loss = 1.04119669, grad/param norm = 1.5170e-01, time/batch = 17.6758s	
9552/33250 (epoch 14.364), train_loss = 1.10931023, grad/param norm = 1.6510e-01, time/batch = 15.5354s	
9553/33250 (epoch 14.365), train_loss = 1.02221362, grad/param norm = 1.4617e-01, time/batch = 15.8441s	
9554/33250 (epoch 14.367), train_loss = 1.01994185, grad/param norm = 1.3512e-01, time/batch = 15.6886s	
9555/33250 (epoch 14.368), train_loss = 1.00717041, grad/param norm = 1.4064e-01, time/batch = 16.1076s	
9556/33250 (epoch 14.370), train_loss = 0.90132631, grad/param norm = 1.2644e-01, time/batch = 16.2761s	
9557/33250 (epoch 14.371), train_loss = 1.16611188, grad/param norm = 1.6417e-01, time/batch = 17.6006s	
9558/33250 (epoch 14.373), train_loss = 0.97159742, grad/param norm = 1.2764e-01, time/batch = 15.5268s	
9559/33250 (epoch 14.374), train_loss = 1.12035433, grad/param norm = 1.9153e-01, time/batch = 16.4546s	
9560/33250 (epoch 14.376), train_loss = 1.00576278, grad/param norm = 1.5773e-01, time/batch = 16.2084s	
9561/33250 (epoch 14.377), train_loss = 0.92216772, grad/param norm = 1.6190e-01, time/batch = 16.2835s	
9562/33250 (epoch 14.379), train_loss = 0.94600857, grad/param norm = 1.5211e-01, time/batch = 17.2636s	
9563/33250 (epoch 14.380), train_loss = 1.07063045, grad/param norm = 1.7578e-01, time/batch = 16.8491s	
9564/33250 (epoch 14.382), train_loss = 1.14087851, grad/param norm = 1.7007e-01, time/batch = 15.8740s	
9565/33250 (epoch 14.383), train_loss = 0.92946237, grad/param norm = 1.4011e-01, time/batch = 15.1967s	
9566/33250 (epoch 14.385), train_loss = 0.88985344, grad/param norm = 1.5112e-01, time/batch = 17.7639s	
9567/33250 (epoch 14.386), train_loss = 0.88755143, grad/param norm = 1.3862e-01, time/batch = 18.4457s	
9568/33250 (epoch 14.388), train_loss = 0.93954309, grad/param norm = 1.4375e-01, time/batch = 16.9572s	
9569/33250 (epoch 14.389), train_loss = 0.99174148, grad/param norm = 1.5203e-01, time/batch = 15.8696s	
9570/33250 (epoch 14.391), train_loss = 1.02889253, grad/param norm = 1.4556e-01, time/batch = 17.6087s	
9571/33250 (epoch 14.392), train_loss = 1.13609747, grad/param norm = 1.6278e-01, time/batch = 17.8448s	
9572/33250 (epoch 14.394), train_loss = 1.17257574, grad/param norm = 1.5454e-01, time/batch = 15.4237s	
9573/33250 (epoch 14.395), train_loss = 1.11790212, grad/param norm = 1.3609e-01, time/batch = 15.7701s	
9574/33250 (epoch 14.397), train_loss = 1.14619014, grad/param norm = 1.5464e-01, time/batch = 16.1107s	
9575/33250 (epoch 14.398), train_loss = 0.97419047, grad/param norm = 1.4884e-01, time/batch = 16.7606s	
9576/33250 (epoch 14.400), train_loss = 0.93242314, grad/param norm = 1.4201e-01, time/batch = 15.4523s	
9577/33250 (epoch 14.402), train_loss = 0.86655505, grad/param norm = 1.4128e-01, time/batch = 18.9414s	
9578/33250 (epoch 14.403), train_loss = 0.95644528, grad/param norm = 1.6108e-01, time/batch = 18.2172s	
9579/33250 (epoch 14.405), train_loss = 0.95854263, grad/param norm = 1.4899e-01, time/batch = 16.2027s	
9580/33250 (epoch 14.406), train_loss = 1.06543486, grad/param norm = 1.5482e-01, time/batch = 16.4471s	
9581/33250 (epoch 14.408), train_loss = 1.18461610, grad/param norm = 1.6693e-01, time/batch = 15.4473s	
9582/33250 (epoch 14.409), train_loss = 1.11300989, grad/param norm = 2.2464e-01, time/batch = 17.0064s	
9583/33250 (epoch 14.411), train_loss = 0.75313293, grad/param norm = 1.1692e-01, time/batch = 15.1774s	
9584/33250 (epoch 14.412), train_loss = 0.86605679, grad/param norm = 1.4142e-01, time/batch = 15.3261s	
9585/33250 (epoch 14.414), train_loss = 1.05672674, grad/param norm = 1.4552e-01, time/batch = 15.5390s	
9586/33250 (epoch 14.415), train_loss = 1.16236113, grad/param norm = 1.6486e-01, time/batch = 15.9423s	
9587/33250 (epoch 14.417), train_loss = 1.11740931, grad/param norm = 1.6015e-01, time/batch = 16.0917s	
9588/33250 (epoch 14.418), train_loss = 1.27661819, grad/param norm = 1.7292e-01, time/batch = 16.8438s	
9589/33250 (epoch 14.420), train_loss = 1.15336571, grad/param norm = 1.5584e-01, time/batch = 16.8791s	
9590/33250 (epoch 14.421), train_loss = 0.95425326, grad/param norm = 1.5299e-01, time/batch = 22.5725s	
9591/33250 (epoch 14.423), train_loss = 1.08572116, grad/param norm = 1.6154e-01, time/batch = 22.7508s	
9592/33250 (epoch 14.424), train_loss = 1.25884689, grad/param norm = 2.3668e-01, time/batch = 15.6785s	
9593/33250 (epoch 14.426), train_loss = 0.94405379, grad/param norm = 1.3355e-01, time/batch = 15.9565s	
9594/33250 (epoch 14.427), train_loss = 0.96816027, grad/param norm = 1.5103e-01, time/batch = 16.0157s	
9595/33250 (epoch 14.429), train_loss = 1.09161281, grad/param norm = 1.5795e-01, time/batch = 16.0267s	
9596/33250 (epoch 14.430), train_loss = 0.94865300, grad/param norm = 1.6442e-01, time/batch = 15.6865s	
9597/33250 (epoch 14.432), train_loss = 1.03965804, grad/param norm = 1.4074e-01, time/batch = 18.8563s	
9598/33250 (epoch 14.433), train_loss = 0.97681081, grad/param norm = 1.5237e-01, time/batch = 16.7905s	
9599/33250 (epoch 14.435), train_loss = 1.09879559, grad/param norm = 1.6795e-01, time/batch = 18.2054s	
9600/33250 (epoch 14.436), train_loss = 0.97516095, grad/param norm = 1.4961e-01, time/batch = 15.1264s	
9601/33250 (epoch 14.438), train_loss = 1.09299463, grad/param norm = 1.4243e-01, time/batch = 15.2745s	
9602/33250 (epoch 14.439), train_loss = 1.05593410, grad/param norm = 1.4308e-01, time/batch = 15.6834s	
9603/33250 (epoch 14.441), train_loss = 1.01240809, grad/param norm = 1.2563e-01, time/batch = 15.5144s	
9604/33250 (epoch 14.442), train_loss = 0.94699280, grad/param norm = 1.4597e-01, time/batch = 15.2903s	
9605/33250 (epoch 14.444), train_loss = 0.94322362, grad/param norm = 1.3746e-01, time/batch = 14.8757s	
9606/33250 (epoch 14.445), train_loss = 1.03168277, grad/param norm = 1.4082e-01, time/batch = 15.5704s	
9607/33250 (epoch 14.447), train_loss = 1.06424465, grad/param norm = 1.4828e-01, time/batch = 16.6174s	
9608/33250 (epoch 14.448), train_loss = 1.01921699, grad/param norm = 1.3263e-01, time/batch = 15.4403s	
9609/33250 (epoch 14.450), train_loss = 1.21315671, grad/param norm = 1.8234e-01, time/batch = 18.2683s	
9610/33250 (epoch 14.451), train_loss = 1.08102480, grad/param norm = 1.5251e-01, time/batch = 16.4596s	
9611/33250 (epoch 14.453), train_loss = 0.93639245, grad/param norm = 1.3969e-01, time/batch = 16.0908s	
9612/33250 (epoch 14.454), train_loss = 1.19143450, grad/param norm = 1.6571e-01, time/batch = 17.3434s	
9613/33250 (epoch 14.456), train_loss = 1.18547782, grad/param norm = 1.5768e-01, time/batch = 16.9298s	
9614/33250 (epoch 14.457), train_loss = 1.01172589, grad/param norm = 1.6649e-01, time/batch = 17.1069s	
9615/33250 (epoch 14.459), train_loss = 1.05214600, grad/param norm = 1.4219e-01, time/batch = 15.5268s	
9616/33250 (epoch 14.460), train_loss = 1.13480302, grad/param norm = 1.6433e-01, time/batch = 17.4901s	
9617/33250 (epoch 14.462), train_loss = 0.96511808, grad/param norm = 1.3500e-01, time/batch = 16.5258s	
9618/33250 (epoch 14.463), train_loss = 0.94359025, grad/param norm = 1.3653e-01, time/batch = 18.3586s	
9619/33250 (epoch 14.465), train_loss = 0.83480703, grad/param norm = 1.2161e-01, time/batch = 18.4563s	
9620/33250 (epoch 14.466), train_loss = 0.80975582, grad/param norm = 1.0777e-01, time/batch = 17.8638s	
9621/33250 (epoch 14.468), train_loss = 0.92110681, grad/param norm = 1.3558e-01, time/batch = 15.1899s	
9622/33250 (epoch 14.469), train_loss = 1.00852941, grad/param norm = 1.4711e-01, time/batch = 15.6663s	
9623/33250 (epoch 14.471), train_loss = 1.13038749, grad/param norm = 1.4542e-01, time/batch = 17.3461s	
9624/33250 (epoch 14.472), train_loss = 0.99102614, grad/param norm = 1.7206e-01, time/batch = 16.8626s	
9625/33250 (epoch 14.474), train_loss = 1.20566283, grad/param norm = 1.7490e-01, time/batch = 16.6820s	
9626/33250 (epoch 14.475), train_loss = 1.05441734, grad/param norm = 1.4078e-01, time/batch = 15.5983s	
9627/33250 (epoch 14.477), train_loss = 1.00816559, grad/param norm = 1.3032e-01, time/batch = 17.0338s	
9628/33250 (epoch 14.478), train_loss = 0.97608114, grad/param norm = 1.4967e-01, time/batch = 15.9605s	
9629/33250 (epoch 14.480), train_loss = 1.26082651, grad/param norm = 1.6450e-01, time/batch = 16.8653s	
9630/33250 (epoch 14.481), train_loss = 1.04355555, grad/param norm = 1.6149e-01, time/batch = 17.2764s	
9631/33250 (epoch 14.483), train_loss = 1.07299707, grad/param norm = 1.4328e-01, time/batch = 16.1903s	
9632/33250 (epoch 14.484), train_loss = 0.93472979, grad/param norm = 1.4009e-01, time/batch = 15.4506s	
9633/33250 (epoch 14.486), train_loss = 0.85231141, grad/param norm = 1.4515e-01, time/batch = 14.7834s	
9634/33250 (epoch 14.487), train_loss = 0.98410605, grad/param norm = 1.4847e-01, time/batch = 17.5258s	
9635/33250 (epoch 14.489), train_loss = 1.11020851, grad/param norm = 1.5879e-01, time/batch = 16.1181s	
9636/33250 (epoch 14.490), train_loss = 1.08443571, grad/param norm = 1.5981e-01, time/batch = 16.7369s	
9637/33250 (epoch 14.492), train_loss = 1.08755091, grad/param norm = 1.6405e-01, time/batch = 17.2606s	
9638/33250 (epoch 14.493), train_loss = 1.03541421, grad/param norm = 1.6157e-01, time/batch = 17.7829s	
9639/33250 (epoch 14.495), train_loss = 1.04853454, grad/param norm = 1.3930e-01, time/batch = 18.7895s	
9640/33250 (epoch 14.496), train_loss = 1.00620521, grad/param norm = 1.2900e-01, time/batch = 17.0262s	
9641/33250 (epoch 14.498), train_loss = 1.12453724, grad/param norm = 1.6314e-01, time/batch = 17.5205s	
9642/33250 (epoch 14.499), train_loss = 0.99370641, grad/param norm = 1.4069e-01, time/batch = 15.3574s	
9643/33250 (epoch 14.501), train_loss = 0.99076791, grad/param norm = 1.5153e-01, time/batch = 16.1048s	
9644/33250 (epoch 14.502), train_loss = 0.99470501, grad/param norm = 1.3699e-01, time/batch = 16.9370s	
9645/33250 (epoch 14.504), train_loss = 1.16994770, grad/param norm = 1.7329e-01, time/batch = 16.6190s	
9646/33250 (epoch 14.505), train_loss = 0.83021571, grad/param norm = 1.1766e-01, time/batch = 15.2660s	
9647/33250 (epoch 14.507), train_loss = 0.99045951, grad/param norm = 1.5043e-01, time/batch = 15.6541s	
9648/33250 (epoch 14.508), train_loss = 0.97076665, grad/param norm = 1.5498e-01, time/batch = 17.0533s	
9649/33250 (epoch 14.510), train_loss = 0.83311652, grad/param norm = 1.2366e-01, time/batch = 17.2140s	
9650/33250 (epoch 14.511), train_loss = 1.02303707, grad/param norm = 1.5434e-01, time/batch = 17.3754s	
9651/33250 (epoch 14.513), train_loss = 1.17595123, grad/param norm = 1.5567e-01, time/batch = 16.1956s	
9652/33250 (epoch 14.514), train_loss = 0.95555176, grad/param norm = 1.2743e-01, time/batch = 17.3451s	
9653/33250 (epoch 14.516), train_loss = 0.95561858, grad/param norm = 1.4157e-01, time/batch = 15.6005s	
9654/33250 (epoch 14.517), train_loss = 1.02792587, grad/param norm = 1.4993e-01, time/batch = 15.4487s	
9655/33250 (epoch 14.519), train_loss = 0.89701775, grad/param norm = 1.1912e-01, time/batch = 15.1984s	
9656/33250 (epoch 14.520), train_loss = 1.28118728, grad/param norm = 1.7208e-01, time/batch = 16.5350s	
9657/33250 (epoch 14.522), train_loss = 1.07260838, grad/param norm = 1.4380e-01, time/batch = 15.7116s	
9658/33250 (epoch 14.523), train_loss = 0.96292856, grad/param norm = 1.4061e-01, time/batch = 16.2827s	
9659/33250 (epoch 14.525), train_loss = 0.90136337, grad/param norm = 1.5507e-01, time/batch = 17.4443s	
9660/33250 (epoch 14.526), train_loss = 0.88971699, grad/param norm = 1.4230e-01, time/batch = 18.0428s	
9661/33250 (epoch 14.528), train_loss = 0.99849878, grad/param norm = 1.4226e-01, time/batch = 16.0440s	
9662/33250 (epoch 14.529), train_loss = 0.96147086, grad/param norm = 1.5292e-01, time/batch = 4.2738s	
9663/33250 (epoch 14.531), train_loss = 0.90160317, grad/param norm = 1.2475e-01, time/batch = 0.6666s	
9664/33250 (epoch 14.532), train_loss = 1.09522088, grad/param norm = 1.5628e-01, time/batch = 0.6687s	
9665/33250 (epoch 14.534), train_loss = 0.90872734, grad/param norm = 1.1934e-01, time/batch = 0.6714s	
9666/33250 (epoch 14.535), train_loss = 0.99160096, grad/param norm = 1.3741e-01, time/batch = 0.6749s	
9667/33250 (epoch 14.537), train_loss = 1.08171381, grad/param norm = 1.4707e-01, time/batch = 0.6832s	
9668/33250 (epoch 14.538), train_loss = 1.10212247, grad/param norm = 1.4833e-01, time/batch = 0.6633s	
9669/33250 (epoch 14.540), train_loss = 1.17969706, grad/param norm = 1.3471e-01, time/batch = 0.7582s	
9670/33250 (epoch 14.541), train_loss = 1.13518157, grad/param norm = 1.5140e-01, time/batch = 0.9836s	
9671/33250 (epoch 14.543), train_loss = 1.08681951, grad/param norm = 1.4420e-01, time/batch = 0.9905s	
9672/33250 (epoch 14.544), train_loss = 0.97409928, grad/param norm = 1.5076e-01, time/batch = 0.9811s	
9673/33250 (epoch 14.546), train_loss = 1.01433238, grad/param norm = 1.6916e-01, time/batch = 0.9842s	
9674/33250 (epoch 14.547), train_loss = 0.97421856, grad/param norm = 1.4463e-01, time/batch = 1.1791s	
9675/33250 (epoch 14.549), train_loss = 1.10032456, grad/param norm = 1.5902e-01, time/batch = 1.8129s	
9676/33250 (epoch 14.550), train_loss = 0.99645039, grad/param norm = 1.5317e-01, time/batch = 1.8250s	
9677/33250 (epoch 14.552), train_loss = 1.05370901, grad/param norm = 1.5104e-01, time/batch = 9.5024s	
9678/33250 (epoch 14.553), train_loss = 0.94508364, grad/param norm = 1.3342e-01, time/batch = 16.1822s	
9679/33250 (epoch 14.555), train_loss = 1.03155589, grad/param norm = 1.3408e-01, time/batch = 15.9264s	
9680/33250 (epoch 14.556), train_loss = 1.14957816, grad/param norm = 1.6917e-01, time/batch = 15.2935s	
9681/33250 (epoch 14.558), train_loss = 1.13163808, grad/param norm = 1.6185e-01, time/batch = 15.0186s	
9682/33250 (epoch 14.559), train_loss = 0.92865959, grad/param norm = 1.4456e-01, time/batch = 16.4490s	
9683/33250 (epoch 14.561), train_loss = 0.95802937, grad/param norm = 1.5690e-01, time/batch = 16.7022s	
9684/33250 (epoch 14.562), train_loss = 1.17021950, grad/param norm = 1.7321e-01, time/batch = 16.5246s	
9685/33250 (epoch 14.564), train_loss = 1.23879648, grad/param norm = 1.7708e-01, time/batch = 18.2039s	
9686/33250 (epoch 14.565), train_loss = 1.19269730, grad/param norm = 1.8421e-01, time/batch = 18.0162s	
9687/33250 (epoch 14.567), train_loss = 1.14688660, grad/param norm = 1.5140e-01, time/batch = 16.5120s	
9688/33250 (epoch 14.568), train_loss = 1.03615486, grad/param norm = 1.5836e-01, time/batch = 15.2638s	
9689/33250 (epoch 14.570), train_loss = 1.19114035, grad/param norm = 1.7785e-01, time/batch = 17.1964s	
9690/33250 (epoch 14.571), train_loss = 1.21661153, grad/param norm = 1.5746e-01, time/batch = 16.6072s	
9691/33250 (epoch 14.573), train_loss = 1.08700942, grad/param norm = 1.6620e-01, time/batch = 18.2637s	
9692/33250 (epoch 14.574), train_loss = 0.94434769, grad/param norm = 1.3813e-01, time/batch = 16.0320s	
9693/33250 (epoch 14.576), train_loss = 1.07142919, grad/param norm = 1.4113e-01, time/batch = 16.5328s	
9694/33250 (epoch 14.577), train_loss = 1.02666808, grad/param norm = 1.4884e-01, time/batch = 16.3570s	
9695/33250 (epoch 14.579), train_loss = 0.92889274, grad/param norm = 1.5583e-01, time/batch = 19.1050s	
9696/33250 (epoch 14.580), train_loss = 0.99306649, grad/param norm = 1.3273e-01, time/batch = 15.5348s	
9697/33250 (epoch 14.582), train_loss = 1.01515592, grad/param norm = 1.4081e-01, time/batch = 16.7493s	
9698/33250 (epoch 14.583), train_loss = 1.09828778, grad/param norm = 1.4021e-01, time/batch = 17.7472s	
9699/33250 (epoch 14.585), train_loss = 1.12336809, grad/param norm = 1.5624e-01, time/batch = 15.4384s	
9700/33250 (epoch 14.586), train_loss = 1.01395050, grad/param norm = 1.7577e-01, time/batch = 16.4392s	
9701/33250 (epoch 14.588), train_loss = 1.05810284, grad/param norm = 1.4219e-01, time/batch = 15.7506s	
9702/33250 (epoch 14.589), train_loss = 1.07365192, grad/param norm = 1.4890e-01, time/batch = 17.6177s	
9703/33250 (epoch 14.591), train_loss = 1.06575045, grad/param norm = 1.5823e-01, time/batch = 16.7132s	
9704/33250 (epoch 14.592), train_loss = 1.03719878, grad/param norm = 1.3903e-01, time/batch = 18.7690s	
9705/33250 (epoch 14.594), train_loss = 1.22190009, grad/param norm = 1.7769e-01, time/batch = 15.8575s	
9706/33250 (epoch 14.595), train_loss = 1.08661915, grad/param norm = 1.4946e-01, time/batch = 17.2833s	
9707/33250 (epoch 14.597), train_loss = 0.89876858, grad/param norm = 1.3291e-01, time/batch = 16.1893s	
9708/33250 (epoch 14.598), train_loss = 1.04290654, grad/param norm = 1.6194e-01, time/batch = 16.1812s	
9709/33250 (epoch 14.600), train_loss = 1.02590498, grad/param norm = 1.5650e-01, time/batch = 16.5207s	
9710/33250 (epoch 14.602), train_loss = 1.08325123, grad/param norm = 1.9274e-01, time/batch = 16.1885s	
9711/33250 (epoch 14.603), train_loss = 1.07655348, grad/param norm = 1.5359e-01, time/batch = 16.2574s	
9712/33250 (epoch 14.605), train_loss = 1.04401390, grad/param norm = 1.6235e-01, time/batch = 15.9880s	
9713/33250 (epoch 14.606), train_loss = 1.08902304, grad/param norm = 1.4913e-01, time/batch = 18.3716s	
9714/33250 (epoch 14.608), train_loss = 1.04328090, grad/param norm = 1.4949e-01, time/batch = 15.7285s	
9715/33250 (epoch 14.609), train_loss = 0.93294859, grad/param norm = 1.5170e-01, time/batch = 16.6227s	
9716/33250 (epoch 14.611), train_loss = 1.06743780, grad/param norm = 1.4828e-01, time/batch = 16.1703s	
9717/33250 (epoch 14.612), train_loss = 1.05667488, grad/param norm = 1.6059e-01, time/batch = 14.7973s	
9718/33250 (epoch 14.614), train_loss = 1.26481053, grad/param norm = 1.6940e-01, time/batch = 16.7710s	
9719/33250 (epoch 14.615), train_loss = 1.14662962, grad/param norm = 1.6314e-01, time/batch = 15.8388s	
9720/33250 (epoch 14.617), train_loss = 1.37918612, grad/param norm = 1.7430e-01, time/batch = 16.8614s	
9721/33250 (epoch 14.618), train_loss = 1.34125499, grad/param norm = 2.0793e-01, time/batch = 16.6752s	
9722/33250 (epoch 14.620), train_loss = 1.14033849, grad/param norm = 1.6816e-01, time/batch = 18.0312s	
9723/33250 (epoch 14.621), train_loss = 1.02996750, grad/param norm = 1.5764e-01, time/batch = 15.7302s	
9724/33250 (epoch 14.623), train_loss = 0.97575746, grad/param norm = 1.5073e-01, time/batch = 19.6129s	
9725/33250 (epoch 14.624), train_loss = 1.01914539, grad/param norm = 1.5362e-01, time/batch = 15.7800s	
9726/33250 (epoch 14.626), train_loss = 0.99467739, grad/param norm = 1.6772e-01, time/batch = 15.2655s	
9727/33250 (epoch 14.627), train_loss = 0.98366603, grad/param norm = 1.4173e-01, time/batch = 15.4635s	
9728/33250 (epoch 14.629), train_loss = 1.09123468, grad/param norm = 1.6961e-01, time/batch = 17.4338s	
9729/33250 (epoch 14.630), train_loss = 1.02615032, grad/param norm = 1.7539e-01, time/batch = 16.2756s	
9730/33250 (epoch 14.632), train_loss = 0.85701489, grad/param norm = 1.2983e-01, time/batch = 16.3162s	
9731/33250 (epoch 14.633), train_loss = 1.11003263, grad/param norm = 1.6182e-01, time/batch = 15.6054s	
9732/33250 (epoch 14.635), train_loss = 0.92892110, grad/param norm = 1.4290e-01, time/batch = 15.9477s	
9733/33250 (epoch 14.636), train_loss = 0.95358202, grad/param norm = 1.3773e-01, time/batch = 17.0222s	
9734/33250 (epoch 14.638), train_loss = 0.98677745, grad/param norm = 1.4199e-01, time/batch = 17.9547s	
9735/33250 (epoch 14.639), train_loss = 0.87911959, grad/param norm = 1.4105e-01, time/batch = 17.6932s	
9736/33250 (epoch 14.641), train_loss = 0.95412330, grad/param norm = 1.3822e-01, time/batch = 16.9357s	
9737/33250 (epoch 14.642), train_loss = 0.85811128, grad/param norm = 1.4415e-01, time/batch = 15.5919s	
9738/33250 (epoch 14.644), train_loss = 0.78599565, grad/param norm = 1.3371e-01, time/batch = 15.3737s	
9739/33250 (epoch 14.645), train_loss = 1.15662702, grad/param norm = 1.8020e-01, time/batch = 16.1079s	
9740/33250 (epoch 14.647), train_loss = 0.90421642, grad/param norm = 1.5794e-01, time/batch = 16.8652s	
9741/33250 (epoch 14.648), train_loss = 0.96778349, grad/param norm = 1.4666e-01, time/batch = 16.7725s	
9742/33250 (epoch 14.650), train_loss = 1.15580936, grad/param norm = 1.6093e-01, time/batch = 18.0173s	
9743/33250 (epoch 14.651), train_loss = 1.06268252, grad/param norm = 1.7925e-01, time/batch = 17.8737s	
9744/33250 (epoch 14.653), train_loss = 0.92846820, grad/param norm = 1.4048e-01, time/batch = 16.6201s	
9745/33250 (epoch 14.654), train_loss = 0.97613143, grad/param norm = 1.3912e-01, time/batch = 17.2066s	
9746/33250 (epoch 14.656), train_loss = 1.08097529, grad/param norm = 1.4635e-01, time/batch = 16.0937s	
9747/33250 (epoch 14.657), train_loss = 0.82587633, grad/param norm = 1.3856e-01, time/batch = 16.4441s	
9748/33250 (epoch 14.659), train_loss = 0.98032870, grad/param norm = 1.5993e-01, time/batch = 16.8257s	
9749/33250 (epoch 14.660), train_loss = 1.01192125, grad/param norm = 1.4807e-01, time/batch = 16.5088s	
9750/33250 (epoch 14.662), train_loss = 1.05048046, grad/param norm = 1.5024e-01, time/batch = 16.0767s	
9751/33250 (epoch 14.663), train_loss = 0.95013618, grad/param norm = 1.4856e-01, time/batch = 17.0204s	
9752/33250 (epoch 14.665), train_loss = 1.07201005, grad/param norm = 1.5422e-01, time/batch = 15.6661s	
9753/33250 (epoch 14.666), train_loss = 0.98788854, grad/param norm = 1.4611e-01, time/batch = 18.6974s	
9754/33250 (epoch 14.668), train_loss = 1.19724804, grad/param norm = 1.5517e-01, time/batch = 18.7787s	
9755/33250 (epoch 14.669), train_loss = 1.06048559, grad/param norm = 1.5176e-01, time/batch = 16.8463s	
9756/33250 (epoch 14.671), train_loss = 0.95377477, grad/param norm = 1.6030e-01, time/batch = 18.0955s	
9757/33250 (epoch 14.672), train_loss = 1.13759975, grad/param norm = 1.5065e-01, time/batch = 17.4344s	
9758/33250 (epoch 14.674), train_loss = 0.96275913, grad/param norm = 1.3499e-01, time/batch = 15.9558s	
9759/33250 (epoch 14.675), train_loss = 1.00608797, grad/param norm = 1.3486e-01, time/batch = 18.0106s	
9760/33250 (epoch 14.677), train_loss = 1.14930988, grad/param norm = 1.6693e-01, time/batch = 16.7668s	
9761/33250 (epoch 14.678), train_loss = 1.01848886, grad/param norm = 1.5318e-01, time/batch = 15.8431s	
9762/33250 (epoch 14.680), train_loss = 1.15513350, grad/param norm = 1.8140e-01, time/batch = 16.5533s	
9763/33250 (epoch 14.681), train_loss = 0.89230816, grad/param norm = 1.4187e-01, time/batch = 17.3687s	
9764/33250 (epoch 14.683), train_loss = 1.01565623, grad/param norm = 1.5597e-01, time/batch = 19.2096s	
9765/33250 (epoch 14.684), train_loss = 0.93326743, grad/param norm = 1.6475e-01, time/batch = 16.3500s	
9766/33250 (epoch 14.686), train_loss = 0.94038457, grad/param norm = 1.4917e-01, time/batch = 15.8396s	
9767/33250 (epoch 14.687), train_loss = 1.00045041, grad/param norm = 1.4766e-01, time/batch = 15.9484s	
9768/33250 (epoch 14.689), train_loss = 0.97394717, grad/param norm = 1.5596e-01, time/batch = 17.2508s	
9769/33250 (epoch 14.690), train_loss = 1.05917106, grad/param norm = 1.5338e-01, time/batch = 15.3352s	
9770/33250 (epoch 14.692), train_loss = 1.01019700, grad/param norm = 1.4938e-01, time/batch = 17.4248s	
9771/33250 (epoch 14.693), train_loss = 1.09387526, grad/param norm = 1.4102e-01, time/batch = 16.3686s	
9772/33250 (epoch 14.695), train_loss = 1.05206590, grad/param norm = 1.4906e-01, time/batch = 17.3638s	
9773/33250 (epoch 14.696), train_loss = 1.07506068, grad/param norm = 1.5305e-01, time/batch = 18.5331s	
9774/33250 (epoch 14.698), train_loss = 0.94499127, grad/param norm = 1.5203e-01, time/batch = 15.8609s	
9775/33250 (epoch 14.699), train_loss = 1.25018482, grad/param norm = 1.6299e-01, time/batch = 17.6894s	
9776/33250 (epoch 14.701), train_loss = 1.00149768, grad/param norm = 1.3653e-01, time/batch = 16.9234s	
9777/33250 (epoch 14.702), train_loss = 0.99584387, grad/param norm = 1.7655e-01, time/batch = 19.1696s	
9778/33250 (epoch 14.704), train_loss = 1.24280559, grad/param norm = 2.1231e-01, time/batch = 16.3681s	
9779/33250 (epoch 14.705), train_loss = 0.92380692, grad/param norm = 1.2917e-01, time/batch = 15.6900s	
9780/33250 (epoch 14.707), train_loss = 0.84931009, grad/param norm = 1.3274e-01, time/batch = 16.7836s	
9781/33250 (epoch 14.708), train_loss = 1.11600438, grad/param norm = 1.6386e-01, time/batch = 18.1250s	
9782/33250 (epoch 14.710), train_loss = 1.09738513, grad/param norm = 1.5627e-01, time/batch = 17.3746s	
9783/33250 (epoch 14.711), train_loss = 0.96414786, grad/param norm = 1.6389e-01, time/batch = 16.0327s	
9784/33250 (epoch 14.713), train_loss = 1.07870548, grad/param norm = 1.5418e-01, time/batch = 18.2098s	
9785/33250 (epoch 14.714), train_loss = 1.03577755, grad/param norm = 1.5342e-01, time/batch = 15.2833s	
9786/33250 (epoch 14.716), train_loss = 1.12532343, grad/param norm = 1.6088e-01, time/batch = 15.1665s	
9787/33250 (epoch 14.717), train_loss = 0.94833719, grad/param norm = 1.2898e-01, time/batch = 16.2862s	
9788/33250 (epoch 14.719), train_loss = 1.00514123, grad/param norm = 1.4529e-01, time/batch = 15.0063s	
9789/33250 (epoch 14.720), train_loss = 1.24744372, grad/param norm = 1.6092e-01, time/batch = 15.9380s	
9790/33250 (epoch 14.722), train_loss = 0.93942714, grad/param norm = 1.3831e-01, time/batch = 16.1059s	
9791/33250 (epoch 14.723), train_loss = 0.82422308, grad/param norm = 1.1992e-01, time/batch = 16.4312s	
9792/33250 (epoch 14.725), train_loss = 0.88441193, grad/param norm = 1.2897e-01, time/batch = 18.0531s	
9793/33250 (epoch 14.726), train_loss = 0.99214091, grad/param norm = 1.4295e-01, time/batch = 17.8698s	
9794/33250 (epoch 14.728), train_loss = 1.08361164, grad/param norm = 1.5299e-01, time/batch = 16.8051s	
9795/33250 (epoch 14.729), train_loss = 1.14948359, grad/param norm = 1.5239e-01, time/batch = 16.1147s	
9796/33250 (epoch 14.731), train_loss = 0.97312855, grad/param norm = 1.4616e-01, time/batch = 17.5964s	
9797/33250 (epoch 14.732), train_loss = 0.91461026, grad/param norm = 1.3533e-01, time/batch = 16.3341s	
9798/33250 (epoch 14.734), train_loss = 1.04161986, grad/param norm = 1.6286e-01, time/batch = 17.0258s	
9799/33250 (epoch 14.735), train_loss = 1.04312630, grad/param norm = 1.5748e-01, time/batch = 16.1178s	
9800/33250 (epoch 14.737), train_loss = 1.01772100, grad/param norm = 1.2851e-01, time/batch = 15.6205s	
9801/33250 (epoch 14.738), train_loss = 1.02976734, grad/param norm = 1.4399e-01, time/batch = 15.5989s	
9802/33250 (epoch 14.740), train_loss = 1.17864973, grad/param norm = 1.5628e-01, time/batch = 18.1972s	
9803/33250 (epoch 14.741), train_loss = 1.11708893, grad/param norm = 1.5356e-01, time/batch = 15.7702s	
9804/33250 (epoch 14.743), train_loss = 0.97684805, grad/param norm = 1.2937e-01, time/batch = 17.1978s	
9805/33250 (epoch 14.744), train_loss = 1.00172703, grad/param norm = 1.6217e-01, time/batch = 14.9458s	
9806/33250 (epoch 14.746), train_loss = 0.96801081, grad/param norm = 1.3224e-01, time/batch = 16.8527s	
9807/33250 (epoch 14.747), train_loss = 0.98248229, grad/param norm = 1.5188e-01, time/batch = 16.4474s	
9808/33250 (epoch 14.749), train_loss = 1.15037300, grad/param norm = 1.7845e-01, time/batch = 15.0222s	
9809/33250 (epoch 14.750), train_loss = 1.11494326, grad/param norm = 1.6527e-01, time/batch = 15.6175s	
9810/33250 (epoch 14.752), train_loss = 0.98687200, grad/param norm = 1.4770e-01, time/batch = 16.4483s	
9811/33250 (epoch 14.753), train_loss = 1.01458556, grad/param norm = 1.4849e-01, time/batch = 16.1927s	
9812/33250 (epoch 14.755), train_loss = 1.01747589, grad/param norm = 1.5409e-01, time/batch = 16.3511s	
9813/33250 (epoch 14.756), train_loss = 1.09919623, grad/param norm = 1.5098e-01, time/batch = 17.7009s	
9814/33250 (epoch 14.758), train_loss = 1.15952459, grad/param norm = 1.4918e-01, time/batch = 18.7764s	
9815/33250 (epoch 14.759), train_loss = 0.93383575, grad/param norm = 1.3995e-01, time/batch = 15.1092s	
9816/33250 (epoch 14.761), train_loss = 0.98376994, grad/param norm = 1.3737e-01, time/batch = 16.6174s	
9817/33250 (epoch 14.762), train_loss = 1.14990854, grad/param norm = 1.5344e-01, time/batch = 16.1973s	
9818/33250 (epoch 14.764), train_loss = 0.95027315, grad/param norm = 1.7947e-01, time/batch = 16.7762s	
9819/33250 (epoch 14.765), train_loss = 1.06167521, grad/param norm = 1.5620e-01, time/batch = 25.7007s	
9820/33250 (epoch 14.767), train_loss = 0.84876996, grad/param norm = 1.3853e-01, time/batch = 22.7935s	
9821/33250 (epoch 14.768), train_loss = 0.89416178, grad/param norm = 1.4935e-01, time/batch = 17.9419s	
9822/33250 (epoch 14.770), train_loss = 1.08357121, grad/param norm = 1.6422e-01, time/batch = 15.7698s	
9823/33250 (epoch 14.771), train_loss = 1.09022947, grad/param norm = 1.6102e-01, time/batch = 15.7467s	
9824/33250 (epoch 14.773), train_loss = 0.99748386, grad/param norm = 1.5237e-01, time/batch = 15.0144s	
9825/33250 (epoch 14.774), train_loss = 0.87267289, grad/param norm = 1.4814e-01, time/batch = 16.0132s	
9826/33250 (epoch 14.776), train_loss = 0.96887112, grad/param norm = 1.5365e-01, time/batch = 15.3638s	
9827/33250 (epoch 14.777), train_loss = 1.14450459, grad/param norm = 1.7055e-01, time/batch = 15.1346s	
9828/33250 (epoch 14.779), train_loss = 1.02322956, grad/param norm = 1.5539e-01, time/batch = 16.7818s	
9829/33250 (epoch 14.780), train_loss = 1.20806195, grad/param norm = 1.7216e-01, time/batch = 16.0166s	
9830/33250 (epoch 14.782), train_loss = 1.06970907, grad/param norm = 1.4296e-01, time/batch = 15.8642s	
9831/33250 (epoch 14.783), train_loss = 0.85633345, grad/param norm = 1.3476e-01, time/batch = 17.7934s	
9832/33250 (epoch 14.785), train_loss = 0.92592842, grad/param norm = 1.4510e-01, time/batch = 17.2196s	
9833/33250 (epoch 14.786), train_loss = 1.10430351, grad/param norm = 1.6511e-01, time/batch = 15.3492s	
9834/33250 (epoch 14.788), train_loss = 1.11804824, grad/param norm = 1.5583e-01, time/batch = 17.6061s	
9835/33250 (epoch 14.789), train_loss = 1.14267267, grad/param norm = 1.7292e-01, time/batch = 15.6961s	
9836/33250 (epoch 14.791), train_loss = 1.20422592, grad/param norm = 1.6606e-01, time/batch = 16.5976s	
9837/33250 (epoch 14.792), train_loss = 1.27232116, grad/param norm = 1.5754e-01, time/batch = 15.4279s	
9838/33250 (epoch 14.794), train_loss = 1.02731075, grad/param norm = 1.5252e-01, time/batch = 16.2835s	
9839/33250 (epoch 14.795), train_loss = 1.07010773, grad/param norm = 1.5308e-01, time/batch = 15.5130s	
9840/33250 (epoch 14.797), train_loss = 1.15254837, grad/param norm = 1.7383e-01, time/batch = 17.6144s	
9841/33250 (epoch 14.798), train_loss = 1.04674609, grad/param norm = 1.7769e-01, time/batch = 17.0977s	
9842/33250 (epoch 14.800), train_loss = 1.07520291, grad/param norm = 1.5234e-01, time/batch = 17.7798s	
9843/33250 (epoch 14.802), train_loss = 0.97128092, grad/param norm = 1.2585e-01, time/batch = 17.0324s	
9844/33250 (epoch 14.803), train_loss = 1.02633096, grad/param norm = 1.4340e-01, time/batch = 15.0778s	
9845/33250 (epoch 14.805), train_loss = 1.10068915, grad/param norm = 1.5640e-01, time/batch = 16.7778s	
9846/33250 (epoch 14.806), train_loss = 1.06261996, grad/param norm = 1.5489e-01, time/batch = 15.7033s	
9847/33250 (epoch 14.808), train_loss = 1.00866316, grad/param norm = 1.3947e-01, time/batch = 16.1080s	
9848/33250 (epoch 14.809), train_loss = 0.95869349, grad/param norm = 1.4959e-01, time/batch = 15.7003s	
9849/33250 (epoch 14.811), train_loss = 0.95006090, grad/param norm = 1.4086e-01, time/batch = 15.7878s	
9850/33250 (epoch 14.812), train_loss = 1.11904423, grad/param norm = 1.6046e-01, time/batch = 17.7974s	
9851/33250 (epoch 14.814), train_loss = 1.03221029, grad/param norm = 1.5022e-01, time/batch = 16.6287s	
9852/33250 (epoch 14.815), train_loss = 1.09585234, grad/param norm = 1.5218e-01, time/batch = 16.6924s	
9853/33250 (epoch 14.817), train_loss = 1.02555416, grad/param norm = 1.6621e-01, time/batch = 14.7236s	
9854/33250 (epoch 14.818), train_loss = 0.96180857, grad/param norm = 1.4145e-01, time/batch = 15.8501s	
9855/33250 (epoch 14.820), train_loss = 1.04555291, grad/param norm = 1.5076e-01, time/batch = 16.2562s	
9856/33250 (epoch 14.821), train_loss = 0.99039004, grad/param norm = 1.2933e-01, time/batch = 16.6095s	
9857/33250 (epoch 14.823), train_loss = 1.34280845, grad/param norm = 1.7499e-01, time/batch = 15.4401s	
9858/33250 (epoch 14.824), train_loss = 0.99554688, grad/param norm = 1.6150e-01, time/batch = 15.5316s	
9859/33250 (epoch 14.826), train_loss = 1.07885402, grad/param norm = 1.6611e-01, time/batch = 15.5194s	
9860/33250 (epoch 14.827), train_loss = 0.82202699, grad/param norm = 1.3116e-01, time/batch = 17.1820s	
9861/33250 (epoch 14.829), train_loss = 1.05315028, grad/param norm = 1.7389e-01, time/batch = 16.7054s	
9862/33250 (epoch 14.830), train_loss = 1.16333728, grad/param norm = 1.7617e-01, time/batch = 16.6800s	
9863/33250 (epoch 14.832), train_loss = 1.04242911, grad/param norm = 1.4985e-01, time/batch = 18.1270s	
9864/33250 (epoch 14.833), train_loss = 1.06891500, grad/param norm = 1.5778e-01, time/batch = 16.3481s	
9865/33250 (epoch 14.835), train_loss = 0.95022974, grad/param norm = 1.8907e-01, time/batch = 15.5950s	
9866/33250 (epoch 14.836), train_loss = 1.01964234, grad/param norm = 1.4451e-01, time/batch = 15.1958s	
9867/33250 (epoch 14.838), train_loss = 1.01533190, grad/param norm = 1.4696e-01, time/batch = 16.4584s	
9868/33250 (epoch 14.839), train_loss = 1.00541681, grad/param norm = 1.5623e-01, time/batch = 16.1896s	
9869/33250 (epoch 14.841), train_loss = 0.94912220, grad/param norm = 1.3571e-01, time/batch = 15.3555s	
9870/33250 (epoch 14.842), train_loss = 1.20719353, grad/param norm = 1.4783e-01, time/batch = 16.7643s	
9871/33250 (epoch 14.844), train_loss = 1.17637034, grad/param norm = 1.8434e-01, time/batch = 18.3634s	
9872/33250 (epoch 14.845), train_loss = 1.26012768, grad/param norm = 1.6122e-01, time/batch = 16.3035s	
9873/33250 (epoch 14.847), train_loss = 1.18646060, grad/param norm = 1.5565e-01, time/batch = 16.4333s	
9874/33250 (epoch 14.848), train_loss = 1.33657828, grad/param norm = 1.7331e-01, time/batch = 17.5099s	
9875/33250 (epoch 14.850), train_loss = 1.16844239, grad/param norm = 1.6987e-01, time/batch = 16.3473s	
9876/33250 (epoch 14.851), train_loss = 0.96424486, grad/param norm = 1.5211e-01, time/batch = 16.2623s	
9877/33250 (epoch 14.853), train_loss = 1.11826506, grad/param norm = 1.6455e-01, time/batch = 16.6045s	
9878/33250 (epoch 14.854), train_loss = 0.96093212, grad/param norm = 1.3927e-01, time/batch = 17.2632s	
9879/33250 (epoch 14.856), train_loss = 0.98420947, grad/param norm = 1.8140e-01, time/batch = 18.5058s	
9880/33250 (epoch 14.857), train_loss = 0.88178942, grad/param norm = 1.3602e-01, time/batch = 16.5203s	
9881/33250 (epoch 14.859), train_loss = 0.90974054, grad/param norm = 1.4373e-01, time/batch = 17.8481s	
9882/33250 (epoch 14.860), train_loss = 1.03434013, grad/param norm = 1.3915e-01, time/batch = 19.6160s	
9883/33250 (epoch 14.862), train_loss = 0.93481951, grad/param norm = 1.3478e-01, time/batch = 17.1347s	
9884/33250 (epoch 14.863), train_loss = 0.97059343, grad/param norm = 1.6015e-01, time/batch = 17.9493s	
9885/33250 (epoch 14.865), train_loss = 1.10234355, grad/param norm = 1.5755e-01, time/batch = 15.1332s	
9886/33250 (epoch 14.866), train_loss = 0.99656821, grad/param norm = 1.5852e-01, time/batch = 16.4481s	
9887/33250 (epoch 14.868), train_loss = 1.16129654, grad/param norm = 1.7762e-01, time/batch = 15.1605s	
9888/33250 (epoch 14.869), train_loss = 1.09013769, grad/param norm = 1.5380e-01, time/batch = 16.1819s	
9889/33250 (epoch 14.871), train_loss = 0.80382787, grad/param norm = 1.3084e-01, time/batch = 15.5121s	
9890/33250 (epoch 14.872), train_loss = 1.06009031, grad/param norm = 1.6072e-01, time/batch = 16.5115s	
9891/33250 (epoch 14.874), train_loss = 0.96132159, grad/param norm = 1.5273e-01, time/batch = 17.9317s	
9892/33250 (epoch 14.875), train_loss = 0.95317316, grad/param norm = 1.6038e-01, time/batch = 16.9621s	
9893/33250 (epoch 14.877), train_loss = 1.14044872, grad/param norm = 1.4717e-01, time/batch = 16.4523s	
9894/33250 (epoch 14.878), train_loss = 1.08614556, grad/param norm = 1.5478e-01, time/batch = 16.0383s	
9895/33250 (epoch 14.880), train_loss = 1.02878833, grad/param norm = 1.7426e-01, time/batch = 15.4362s	
9896/33250 (epoch 14.881), train_loss = 1.23156816, grad/param norm = 1.8744e-01, time/batch = 17.3584s	
9897/33250 (epoch 14.883), train_loss = 1.05803222, grad/param norm = 1.5191e-01, time/batch = 17.1729s	
9898/33250 (epoch 14.884), train_loss = 1.06165796, grad/param norm = 1.7125e-01, time/batch = 16.2543s	
9899/33250 (epoch 14.886), train_loss = 0.95388843, grad/param norm = 1.3279e-01, time/batch = 16.7642s	
9900/33250 (epoch 14.887), train_loss = 1.00876077, grad/param norm = 1.4716e-01, time/batch = 16.0277s	
9901/33250 (epoch 14.889), train_loss = 0.97140371, grad/param norm = 1.2923e-01, time/batch = 17.2757s	
9902/33250 (epoch 14.890), train_loss = 0.86548184, grad/param norm = 1.2554e-01, time/batch = 17.8621s	
9903/33250 (epoch 14.892), train_loss = 1.08892397, grad/param norm = 1.4982e-01, time/batch = 15.7783s	
9904/33250 (epoch 14.893), train_loss = 1.10050623, grad/param norm = 1.5651e-01, time/batch = 15.5436s	
9905/33250 (epoch 14.895), train_loss = 0.99699090, grad/param norm = 1.4806e-01, time/batch = 16.2898s	
9906/33250 (epoch 14.896), train_loss = 1.13509677, grad/param norm = 1.6652e-01, time/batch = 17.7554s	
9907/33250 (epoch 14.898), train_loss = 1.02033442, grad/param norm = 1.5215e-01, time/batch = 16.7888s	
9908/33250 (epoch 14.899), train_loss = 0.93877007, grad/param norm = 1.4157e-01, time/batch = 18.3243s	
9909/33250 (epoch 14.901), train_loss = 0.90206568, grad/param norm = 1.3844e-01, time/batch = 19.4923s	
9910/33250 (epoch 14.902), train_loss = 1.01602587, grad/param norm = 1.4744e-01, time/batch = 18.8757s	
9911/33250 (epoch 14.904), train_loss = 0.93785937, grad/param norm = 1.3122e-01, time/batch = 19.7640s	
9912/33250 (epoch 14.905), train_loss = 0.97957485, grad/param norm = 1.3132e-01, time/batch = 21.4504s	
9913/33250 (epoch 14.907), train_loss = 0.93346775, grad/param norm = 1.3558e-01, time/batch = 20.5440s	
9914/33250 (epoch 14.908), train_loss = 1.02789884, grad/param norm = 1.3467e-01, time/batch = 18.4647s	
9915/33250 (epoch 14.910), train_loss = 1.08121631, grad/param norm = 1.5557e-01, time/batch = 20.1081s	
9916/33250 (epoch 14.911), train_loss = 0.90128439, grad/param norm = 1.3772e-01, time/batch = 21.3387s	
9917/33250 (epoch 14.913), train_loss = 0.96389111, grad/param norm = 1.4073e-01, time/batch = 22.2275s	
9918/33250 (epoch 14.914), train_loss = 0.85954912, grad/param norm = 1.4390e-01, time/batch = 19.7627s	
9919/33250 (epoch 14.916), train_loss = 0.96186026, grad/param norm = 1.2928e-01, time/batch = 21.3589s	
9920/33250 (epoch 14.917), train_loss = 0.97972599, grad/param norm = 1.3061e-01, time/batch = 19.7795s	
9921/33250 (epoch 14.919), train_loss = 0.94240001, grad/param norm = 1.5843e-01, time/batch = 21.3484s	
9922/33250 (epoch 14.920), train_loss = 1.03605612, grad/param norm = 1.7271e-01, time/batch = 20.5361s	
9923/33250 (epoch 14.922), train_loss = 1.07439044, grad/param norm = 1.5883e-01, time/batch = 17.8721s	
9924/33250 (epoch 14.923), train_loss = 1.02192626, grad/param norm = 1.6780e-01, time/batch = 18.3949s	
9925/33250 (epoch 14.925), train_loss = 0.96773372, grad/param norm = 1.3912e-01, time/batch = 19.6198s	
9926/33250 (epoch 14.926), train_loss = 0.98135434, grad/param norm = 1.4361e-01, time/batch = 18.3675s	
9927/33250 (epoch 14.928), train_loss = 0.99728792, grad/param norm = 1.5049e-01, time/batch = 19.2220s	
9928/33250 (epoch 14.929), train_loss = 0.81847341, grad/param norm = 1.2706e-01, time/batch = 21.6160s	
9929/33250 (epoch 14.931), train_loss = 1.09939483, grad/param norm = 1.4880e-01, time/batch = 27.6358s	
9930/33250 (epoch 14.932), train_loss = 1.04503528, grad/param norm = 1.6683e-01, time/batch = 16.2822s	
9931/33250 (epoch 14.934), train_loss = 0.95321963, grad/param norm = 1.3295e-01, time/batch = 15.4626s	
9932/33250 (epoch 14.935), train_loss = 0.94897126, grad/param norm = 1.5646e-01, time/batch = 15.8593s	
9933/33250 (epoch 14.937), train_loss = 1.01497276, grad/param norm = 1.6320e-01, time/batch = 14.3011s	
9934/33250 (epoch 14.938), train_loss = 1.05720334, grad/param norm = 1.5938e-01, time/batch = 15.8535s	
9935/33250 (epoch 14.940), train_loss = 1.00202715, grad/param norm = 1.6121e-01, time/batch = 17.8493s	
9936/33250 (epoch 14.941), train_loss = 1.06232761, grad/param norm = 1.5795e-01, time/batch = 16.3534s	
9937/33250 (epoch 14.943), train_loss = 1.15891596, grad/param norm = 1.5581e-01, time/batch = 17.6773s	
9938/33250 (epoch 14.944), train_loss = 0.93979872, grad/param norm = 1.3292e-01, time/batch = 16.2043s	
9939/33250 (epoch 14.946), train_loss = 1.14696714, grad/param norm = 1.4714e-01, time/batch = 19.5351s	
9940/33250 (epoch 14.947), train_loss = 0.93267428, grad/param norm = 1.4186e-01, time/batch = 16.9977s	
9941/33250 (epoch 14.949), train_loss = 1.13923361, grad/param norm = 1.5351e-01, time/batch = 17.4479s	
9942/33250 (epoch 14.950), train_loss = 1.06379286, grad/param norm = 1.5407e-01, time/batch = 15.6868s	
9943/33250 (epoch 14.952), train_loss = 0.99905688, grad/param norm = 1.6683e-01, time/batch = 16.6068s	
9944/33250 (epoch 14.953), train_loss = 1.10607469, grad/param norm = 1.5317e-01, time/batch = 15.2696s	
9945/33250 (epoch 14.955), train_loss = 1.14186299, grad/param norm = 1.6202e-01, time/batch = 16.7611s	
9946/33250 (epoch 14.956), train_loss = 1.10142107, grad/param norm = 1.8281e-01, time/batch = 18.6890s	
9947/33250 (epoch 14.958), train_loss = 0.93023574, grad/param norm = 1.3858e-01, time/batch = 16.6256s	
9948/33250 (epoch 14.959), train_loss = 0.94625840, grad/param norm = 1.3736e-01, time/batch = 18.8640s	
9949/33250 (epoch 14.961), train_loss = 1.22722404, grad/param norm = 1.4832e-01, time/batch = 16.5093s	
9950/33250 (epoch 14.962), train_loss = 1.04521697, grad/param norm = 1.4089e-01, time/batch = 16.8351s	
9951/33250 (epoch 14.964), train_loss = 1.21872517, grad/param norm = 1.6892e-01, time/batch = 17.3608s	
9952/33250 (epoch 14.965), train_loss = 1.10401671, grad/param norm = 1.6235e-01, time/batch = 16.1026s	
9953/33250 (epoch 14.967), train_loss = 1.03858184, grad/param norm = 1.5631e-01, time/batch = 15.8550s	
9954/33250 (epoch 14.968), train_loss = 1.23092949, grad/param norm = 1.4992e-01, time/batch = 15.8320s	
9955/33250 (epoch 14.970), train_loss = 1.32187299, grad/param norm = 2.2394e-01, time/batch = 17.2764s	
9956/33250 (epoch 14.971), train_loss = 1.19095298, grad/param norm = 1.8227e-01, time/batch = 17.8716s	
9957/33250 (epoch 14.973), train_loss = 0.99104514, grad/param norm = 1.5185e-01, time/batch = 16.3561s	
9958/33250 (epoch 14.974), train_loss = 1.10993367, grad/param norm = 1.5660e-01, time/batch = 15.7928s	
9959/33250 (epoch 14.976), train_loss = 1.02559845, grad/param norm = 1.6601e-01, time/batch = 17.5993s	
9960/33250 (epoch 14.977), train_loss = 0.95326267, grad/param norm = 1.4547e-01, time/batch = 16.2666s	
9961/33250 (epoch 14.979), train_loss = 1.05285395, grad/param norm = 1.5866e-01, time/batch = 16.1875s	
9962/33250 (epoch 14.980), train_loss = 1.04531930, grad/param norm = 1.3892e-01, time/batch = 16.5242s	
9963/33250 (epoch 14.982), train_loss = 0.90720433, grad/param norm = 1.2811e-01, time/batch = 17.2770s	
9964/33250 (epoch 14.983), train_loss = 1.07471885, grad/param norm = 1.6822e-01, time/batch = 16.3396s	
9965/33250 (epoch 14.985), train_loss = 0.97907639, grad/param norm = 1.5490e-01, time/batch = 16.5273s	
9966/33250 (epoch 14.986), train_loss = 1.13261019, grad/param norm = 1.5960e-01, time/batch = 19.2883s	
9967/33250 (epoch 14.988), train_loss = 1.15773984, grad/param norm = 1.6588e-01, time/batch = 16.7816s	
9968/33250 (epoch 14.989), train_loss = 1.13748276, grad/param norm = 1.6631e-01, time/batch = 16.3791s	
9969/33250 (epoch 14.991), train_loss = 1.06671367, grad/param norm = 1.5945e-01, time/batch = 15.7681s	
9970/33250 (epoch 14.992), train_loss = 1.01986395, grad/param norm = 1.5226e-01, time/batch = 15.4576s	
9971/33250 (epoch 14.994), train_loss = 0.96282366, grad/param norm = 1.4644e-01, time/batch = 15.6994s	
9972/33250 (epoch 14.995), train_loss = 1.02584387, grad/param norm = 1.7209e-01, time/batch = 15.1802s	
9973/33250 (epoch 14.997), train_loss = 0.76608045, grad/param norm = 1.3377e-01, time/batch = 15.4506s	
9974/33250 (epoch 14.998), train_loss = 1.04452364, grad/param norm = 1.3105e-01, time/batch = 15.8672s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
9975/33250 (epoch 15.000), train_loss = 1.05478506, grad/param norm = 1.4283e-01, time/batch = 16.6858s	
9976/33250 (epoch 15.002), train_loss = 1.19542254, grad/param norm = 1.6077e-01, time/batch = 17.1909s	
9977/33250 (epoch 15.003), train_loss = 1.13639039, grad/param norm = 1.7230e-01, time/batch = 15.2576s	
9978/33250 (epoch 15.005), train_loss = 0.83997262, grad/param norm = 1.3602e-01, time/batch = 15.5745s	
9979/33250 (epoch 15.006), train_loss = 0.90120918, grad/param norm = 1.4426e-01, time/batch = 15.2849s	
9980/33250 (epoch 15.008), train_loss = 1.19400327, grad/param norm = 1.5210e-01, time/batch = 15.9462s	
9981/33250 (epoch 15.009), train_loss = 1.18304693, grad/param norm = 1.5807e-01, time/batch = 16.3576s	
9982/33250 (epoch 15.011), train_loss = 0.92950682, grad/param norm = 1.4067e-01, time/batch = 16.5018s	
9983/33250 (epoch 15.012), train_loss = 1.08446193, grad/param norm = 2.1110e-01, time/batch = 15.5296s	
9984/33250 (epoch 15.014), train_loss = 1.16240455, grad/param norm = 1.7024e-01, time/batch = 16.1966s	
9985/33250 (epoch 15.015), train_loss = 1.03048023, grad/param norm = 1.5327e-01, time/batch = 15.8662s	
9986/33250 (epoch 15.017), train_loss = 1.06061625, grad/param norm = 1.9148e-01, time/batch = 17.7093s	
9987/33250 (epoch 15.018), train_loss = 0.85309928, grad/param norm = 1.4485e-01, time/batch = 14.9883s	
9988/33250 (epoch 15.020), train_loss = 1.01501895, grad/param norm = 1.4553e-01, time/batch = 14.6374s	
9989/33250 (epoch 15.021), train_loss = 1.04001435, grad/param norm = 1.5213e-01, time/batch = 14.9548s	
9990/33250 (epoch 15.023), train_loss = 0.86288137, grad/param norm = 1.5296e-01, time/batch = 14.8703s	
9991/33250 (epoch 15.024), train_loss = 1.12049293, grad/param norm = 1.4772e-01, time/batch = 14.8689s	
9992/33250 (epoch 15.026), train_loss = 1.01315596, grad/param norm = 1.3962e-01, time/batch = 14.8461s	
9993/33250 (epoch 15.027), train_loss = 1.00444367, grad/param norm = 1.4533e-01, time/batch = 14.7180s	
9994/33250 (epoch 15.029), train_loss = 1.05141021, grad/param norm = 1.5137e-01, time/batch = 15.1166s	
9995/33250 (epoch 15.030), train_loss = 1.02141883, grad/param norm = 1.5321e-01, time/batch = 15.2062s	
9996/33250 (epoch 15.032), train_loss = 1.25265895, grad/param norm = 1.8157e-01, time/batch = 14.5466s	
9997/33250 (epoch 15.033), train_loss = 0.97797471, grad/param norm = 1.3947e-01, time/batch = 14.6263s	
9998/33250 (epoch 15.035), train_loss = 0.97975812, grad/param norm = 1.5029e-01, time/batch = 14.8736s	
9999/33250 (epoch 15.036), train_loss = 1.10284109, grad/param norm = 1.8120e-01, time/batch = 15.2747s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch15.04_1.4188.t7	
10000/33250 (epoch 15.038), train_loss = 1.01079669, grad/param norm = 1.4023e-01, time/batch = 14.6240s	
10001/33250 (epoch 15.039), train_loss = 1.24372048, grad/param norm = 1.6641e-01, time/batch = 15.1214s	
10002/33250 (epoch 15.041), train_loss = 1.05806150, grad/param norm = 1.6145e-01, time/batch = 14.5470s	
10003/33250 (epoch 15.042), train_loss = 0.88610389, grad/param norm = 1.4655e-01, time/batch = 14.7056s	
10004/33250 (epoch 15.044), train_loss = 1.19273078, grad/param norm = 1.6926e-01, time/batch = 14.6099s	
10005/33250 (epoch 15.045), train_loss = 1.14599778, grad/param norm = 1.5144e-01, time/batch = 15.0300s	
10006/33250 (epoch 15.047), train_loss = 1.09785751, grad/param norm = 1.6306e-01, time/batch = 15.1114s	
10007/33250 (epoch 15.048), train_loss = 1.17683843, grad/param norm = 1.7569e-01, time/batch = 16.2774s	
10008/33250 (epoch 15.050), train_loss = 1.04029846, grad/param norm = 1.5291e-01, time/batch = 15.9147s	
10009/33250 (epoch 15.051), train_loss = 1.01940906, grad/param norm = 1.4471e-01, time/batch = 16.2749s	
10010/33250 (epoch 15.053), train_loss = 1.06079770, grad/param norm = 1.6184e-01, time/batch = 19.9199s	
10011/33250 (epoch 15.054), train_loss = 0.86908196, grad/param norm = 1.2813e-01, time/batch = 18.2894s	
10012/33250 (epoch 15.056), train_loss = 0.93652106, grad/param norm = 1.4841e-01, time/batch = 17.4512s	
10013/33250 (epoch 15.057), train_loss = 1.08878562, grad/param norm = 1.4600e-01, time/batch = 15.7061s	
10014/33250 (epoch 15.059), train_loss = 1.01567733, grad/param norm = 1.4879e-01, time/batch = 15.9842s	
10015/33250 (epoch 15.060), train_loss = 1.07778486, grad/param norm = 1.6225e-01, time/batch = 14.9926s	
10016/33250 (epoch 15.062), train_loss = 1.16643417, grad/param norm = 1.5470e-01, time/batch = 17.0203s	
10017/33250 (epoch 15.063), train_loss = 1.15439452, grad/param norm = 1.5383e-01, time/batch = 17.0118s	
10018/33250 (epoch 15.065), train_loss = 1.01626437, grad/param norm = 1.3860e-01, time/batch = 16.3500s	
10019/33250 (epoch 15.066), train_loss = 1.09043466, grad/param norm = 1.5773e-01, time/batch = 17.6113s	
10020/33250 (epoch 15.068), train_loss = 0.98818720, grad/param norm = 1.5105e-01, time/batch = 16.1499s	
10021/33250 (epoch 15.069), train_loss = 1.05413182, grad/param norm = 1.5403e-01, time/batch = 17.1260s	
10022/33250 (epoch 15.071), train_loss = 0.93041689, grad/param norm = 1.4297e-01, time/batch = 16.7713s	
10023/33250 (epoch 15.072), train_loss = 0.92022030, grad/param norm = 1.2559e-01, time/batch = 18.4577s	
10024/33250 (epoch 15.074), train_loss = 1.09501297, grad/param norm = 1.5400e-01, time/batch = 24.5436s	
10025/33250 (epoch 15.075), train_loss = 0.96646153, grad/param norm = 1.5593e-01, time/batch = 19.7876s	
10026/33250 (epoch 15.077), train_loss = 1.01036356, grad/param norm = 1.4903e-01, time/batch = 15.4421s	
10027/33250 (epoch 15.078), train_loss = 1.03787747, grad/param norm = 1.4749e-01, time/batch = 17.3604s	
10028/33250 (epoch 15.080), train_loss = 1.04231587, grad/param norm = 1.6491e-01, time/batch = 17.4593s	
10029/33250 (epoch 15.081), train_loss = 1.05337549, grad/param norm = 1.4384e-01, time/batch = 16.3715s	
10030/33250 (epoch 15.083), train_loss = 1.12407750, grad/param norm = 1.4249e-01, time/batch = 15.2085s	
10031/33250 (epoch 15.084), train_loss = 1.03439732, grad/param norm = 1.4984e-01, time/batch = 19.2854s	
10032/33250 (epoch 15.086), train_loss = 0.97935695, grad/param norm = 1.3127e-01, time/batch = 16.8540s	
10033/33250 (epoch 15.087), train_loss = 0.90800859, grad/param norm = 1.3408e-01, time/batch = 15.6083s	
10034/33250 (epoch 15.089), train_loss = 1.08600628, grad/param norm = 1.5450e-01, time/batch = 16.1944s	
10035/33250 (epoch 15.090), train_loss = 1.04339731, grad/param norm = 1.5210e-01, time/batch = 15.7514s	
10036/33250 (epoch 15.092), train_loss = 0.95839305, grad/param norm = 1.3009e-01, time/batch = 15.4318s	
10037/33250 (epoch 15.093), train_loss = 1.06290754, grad/param norm = 1.5034e-01, time/batch = 16.0094s	
10038/33250 (epoch 15.095), train_loss = 0.96649469, grad/param norm = 1.3502e-01, time/batch = 17.5263s	
10039/33250 (epoch 15.096), train_loss = 0.85604516, grad/param norm = 1.4784e-01, time/batch = 17.3851s	
10040/33250 (epoch 15.098), train_loss = 0.90433011, grad/param norm = 1.4675e-01, time/batch = 17.6900s	
10041/33250 (epoch 15.099), train_loss = 0.77118632, grad/param norm = 1.2207e-01, time/batch = 16.6039s	
10042/33250 (epoch 15.101), train_loss = 1.00380533, grad/param norm = 1.4065e-01, time/batch = 16.7008s	
10043/33250 (epoch 15.102), train_loss = 0.92471854, grad/param norm = 1.5710e-01, time/batch = 15.4188s	
10044/33250 (epoch 15.104), train_loss = 0.81069001, grad/param norm = 1.2929e-01, time/batch = 15.1066s	
10045/33250 (epoch 15.105), train_loss = 0.94768555, grad/param norm = 1.3995e-01, time/batch = 16.2021s	
10046/33250 (epoch 15.107), train_loss = 0.84289372, grad/param norm = 1.2926e-01, time/batch = 16.6117s	
10047/33250 (epoch 15.108), train_loss = 0.99689287, grad/param norm = 1.4399e-01, time/batch = 15.7141s	
10048/33250 (epoch 15.110), train_loss = 0.82635629, grad/param norm = 1.3718e-01, time/batch = 15.0848s	
10049/33250 (epoch 15.111), train_loss = 0.99544204, grad/param norm = 1.4248e-01, time/batch = 16.9658s	
10050/33250 (epoch 15.113), train_loss = 0.99754100, grad/param norm = 1.4706e-01, time/batch = 19.0432s	
10051/33250 (epoch 15.114), train_loss = 0.91286188, grad/param norm = 1.4745e-01, time/batch = 17.7054s	
10052/33250 (epoch 15.116), train_loss = 1.00908378, grad/param norm = 1.4373e-01, time/batch = 18.0962s	
10053/33250 (epoch 15.117), train_loss = 0.98427493, grad/param norm = 1.4213e-01, time/batch = 17.3432s	
10054/33250 (epoch 15.119), train_loss = 0.97220631, grad/param norm = 1.4386e-01, time/batch = 16.9386s	
10055/33250 (epoch 15.120), train_loss = 0.77275177, grad/param norm = 1.3507e-01, time/batch = 16.3493s	
10056/33250 (epoch 15.122), train_loss = 1.12976613, grad/param norm = 1.4901e-01, time/batch = 17.1912s	
10057/33250 (epoch 15.123), train_loss = 1.02058008, grad/param norm = 1.4793e-01, time/batch = 17.3672s	
10058/33250 (epoch 15.125), train_loss = 0.84381865, grad/param norm = 1.4889e-01, time/batch = 15.7649s	
10059/33250 (epoch 15.126), train_loss = 0.99890823, grad/param norm = 1.4805e-01, time/batch = 18.2821s	
10060/33250 (epoch 15.128), train_loss = 0.93351298, grad/param norm = 1.3318e-01, time/batch = 16.7131s	
10061/33250 (epoch 15.129), train_loss = 0.99862418, grad/param norm = 1.4577e-01, time/batch = 17.4301s	
10062/33250 (epoch 15.131), train_loss = 0.98931191, grad/param norm = 1.4806e-01, time/batch = 17.7724s	
10063/33250 (epoch 15.132), train_loss = 0.98283719, grad/param norm = 1.5042e-01, time/batch = 18.4221s	
10064/33250 (epoch 15.134), train_loss = 1.01284252, grad/param norm = 1.5178e-01, time/batch = 15.2606s	
10065/33250 (epoch 15.135), train_loss = 1.04011980, grad/param norm = 1.4702e-01, time/batch = 17.0828s	
10066/33250 (epoch 15.137), train_loss = 0.90589684, grad/param norm = 1.4960e-01, time/batch = 16.3632s	
10067/33250 (epoch 15.138), train_loss = 0.93403958, grad/param norm = 1.2425e-01, time/batch = 15.9264s	
10068/33250 (epoch 15.140), train_loss = 0.78167970, grad/param norm = 1.4575e-01, time/batch = 18.0957s	
10069/33250 (epoch 15.141), train_loss = 1.21591348, grad/param norm = 1.9679e-01, time/batch = 17.0287s	
10070/33250 (epoch 15.143), train_loss = 0.80092913, grad/param norm = 1.5233e-01, time/batch = 18.3504s	
10071/33250 (epoch 15.144), train_loss = 0.96445973, grad/param norm = 1.3749e-01, time/batch = 18.8026s	
10072/33250 (epoch 15.146), train_loss = 0.95355393, grad/param norm = 1.3586e-01, time/batch = 15.6810s	
10073/33250 (epoch 15.147), train_loss = 0.92661397, grad/param norm = 1.3820e-01, time/batch = 17.3395s	
10074/33250 (epoch 15.149), train_loss = 0.96481550, grad/param norm = 1.5027e-01, time/batch = 15.9328s	
10075/33250 (epoch 15.150), train_loss = 0.89555473, grad/param norm = 1.3734e-01, time/batch = 18.4156s	
10076/33250 (epoch 15.152), train_loss = 0.85775910, grad/param norm = 1.4254e-01, time/batch = 16.8236s	
10077/33250 (epoch 15.153), train_loss = 1.15132059, grad/param norm = 1.5707e-01, time/batch = 16.3634s	
10078/33250 (epoch 15.155), train_loss = 0.99696968, grad/param norm = 1.5504e-01, time/batch = 15.4486s	
10079/33250 (epoch 15.156), train_loss = 1.19451994, grad/param norm = 1.4727e-01, time/batch = 17.2089s	
10080/33250 (epoch 15.158), train_loss = 1.20566986, grad/param norm = 1.6973e-01, time/batch = 18.8624s	
10081/33250 (epoch 15.159), train_loss = 1.00215669, grad/param norm = 1.5107e-01, time/batch = 17.3820s	
10082/33250 (epoch 15.161), train_loss = 1.05151343, grad/param norm = 1.6000e-01, time/batch = 14.3958s	
10083/33250 (epoch 15.162), train_loss = 0.88734233, grad/param norm = 1.3169e-01, time/batch = 16.3385s	
10084/33250 (epoch 15.164), train_loss = 1.00415956, grad/param norm = 1.6512e-01, time/batch = 18.1629s	
10085/33250 (epoch 15.165), train_loss = 1.08595024, grad/param norm = 1.6020e-01, time/batch = 16.3615s	
10086/33250 (epoch 15.167), train_loss = 1.14791288, grad/param norm = 1.6186e-01, time/batch = 16.4075s	
10087/33250 (epoch 15.168), train_loss = 0.84855073, grad/param norm = 1.1860e-01, time/batch = 15.7905s	
10088/33250 (epoch 15.170), train_loss = 0.97961545, grad/param norm = 1.5860e-01, time/batch = 17.6762s	
10089/33250 (epoch 15.171), train_loss = 0.97526148, grad/param norm = 1.4050e-01, time/batch = 16.5399s	
10090/33250 (epoch 15.173), train_loss = 0.94790712, grad/param norm = 1.4078e-01, time/batch = 15.7447s	
10091/33250 (epoch 15.174), train_loss = 0.99825173, grad/param norm = 1.4495e-01, time/batch = 16.9743s	
10092/33250 (epoch 15.176), train_loss = 0.97475118, grad/param norm = 1.4467e-01, time/batch = 17.6816s	
10093/33250 (epoch 15.177), train_loss = 0.96018843, grad/param norm = 1.3151e-01, time/batch = 16.1021s	
10094/33250 (epoch 15.179), train_loss = 0.92297132, grad/param norm = 1.3173e-01, time/batch = 15.2873s	
10095/33250 (epoch 15.180), train_loss = 0.84302437, grad/param norm = 1.2915e-01, time/batch = 16.4541s	
10096/33250 (epoch 15.182), train_loss = 0.93291875, grad/param norm = 1.6556e-01, time/batch = 15.3493s	
10097/33250 (epoch 15.183), train_loss = 1.14703032, grad/param norm = 1.6237e-01, time/batch = 16.3569s	
10098/33250 (epoch 15.185), train_loss = 1.08577523, grad/param norm = 1.7128e-01, time/batch = 15.4482s	
10099/33250 (epoch 15.186), train_loss = 1.00802092, grad/param norm = 1.4562e-01, time/batch = 15.6241s	
10100/33250 (epoch 15.188), train_loss = 1.13031324, grad/param norm = 1.6386e-01, time/batch = 17.0464s	
10101/33250 (epoch 15.189), train_loss = 0.80783157, grad/param norm = 1.5876e-01, time/batch = 16.3729s	
10102/33250 (epoch 15.191), train_loss = 0.91823974, grad/param norm = 1.4595e-01, time/batch = 17.7813s	
10103/33250 (epoch 15.192), train_loss = 0.93589943, grad/param norm = 1.4160e-01, time/batch = 16.2055s	
10104/33250 (epoch 15.194), train_loss = 0.93786619, grad/param norm = 1.4756e-01, time/batch = 17.3471s	
10105/33250 (epoch 15.195), train_loss = 1.17441891, grad/param norm = 1.4597e-01, time/batch = 15.5870s	
10106/33250 (epoch 15.197), train_loss = 0.95347933, grad/param norm = 1.3764e-01, time/batch = 16.1657s	
10107/33250 (epoch 15.198), train_loss = 1.12513241, grad/param norm = 1.5275e-01, time/batch = 15.5280s	
10108/33250 (epoch 15.200), train_loss = 1.00584031, grad/param norm = 1.4734e-01, time/batch = 16.5158s	
10109/33250 (epoch 15.202), train_loss = 0.93402062, grad/param norm = 1.3597e-01, time/batch = 18.1187s	
10110/33250 (epoch 15.203), train_loss = 0.92257412, grad/param norm = 1.4514e-01, time/batch = 18.4556s	
10111/33250 (epoch 15.205), train_loss = 1.03378007, grad/param norm = 1.4797e-01, time/batch = 17.6211s	
10112/33250 (epoch 15.206), train_loss = 1.08039376, grad/param norm = 1.5027e-01, time/batch = 15.8536s	
10113/33250 (epoch 15.208), train_loss = 1.14911439, grad/param norm = 1.5713e-01, time/batch = 16.4215s	
10114/33250 (epoch 15.209), train_loss = 0.95085238, grad/param norm = 1.4072e-01, time/batch = 15.8568s	
10115/33250 (epoch 15.211), train_loss = 1.09193193, grad/param norm = 1.5814e-01, time/batch = 15.9244s	
10116/33250 (epoch 15.212), train_loss = 1.24796618, grad/param norm = 1.5855e-01, time/batch = 16.6996s	
10117/33250 (epoch 15.214), train_loss = 0.99548761, grad/param norm = 1.3125e-01, time/batch = 17.0164s	
10118/33250 (epoch 15.215), train_loss = 1.22248363, grad/param norm = 1.9154e-01, time/batch = 16.9361s	
10119/33250 (epoch 15.217), train_loss = 1.16467199, grad/param norm = 1.7754e-01, time/batch = 16.1820s	
10120/33250 (epoch 15.218), train_loss = 1.10505432, grad/param norm = 1.4389e-01, time/batch = 16.7083s	
10121/33250 (epoch 15.220), train_loss = 1.07468624, grad/param norm = 1.5569e-01, time/batch = 17.6203s	
10122/33250 (epoch 15.221), train_loss = 1.23453470, grad/param norm = 1.7263e-01, time/batch = 17.2039s	
10123/33250 (epoch 15.223), train_loss = 1.00967996, grad/param norm = 1.4002e-01, time/batch = 17.7822s	
10124/33250 (epoch 15.224), train_loss = 1.07489507, grad/param norm = 1.5927e-01, time/batch = 16.6805s	
10125/33250 (epoch 15.226), train_loss = 1.19458337, grad/param norm = 1.5901e-01, time/batch = 16.9492s	
10126/33250 (epoch 15.227), train_loss = 1.05381300, grad/param norm = 1.4914e-01, time/batch = 16.5024s	
10127/33250 (epoch 15.229), train_loss = 1.05758853, grad/param norm = 1.4739e-01, time/batch = 18.3403s	
10128/33250 (epoch 15.230), train_loss = 0.98026870, grad/param norm = 1.4208e-01, time/batch = 16.2694s	
10129/33250 (epoch 15.232), train_loss = 0.95993392, grad/param norm = 1.2506e-01, time/batch = 16.1656s	
10130/33250 (epoch 15.233), train_loss = 0.95148817, grad/param norm = 1.3316e-01, time/batch = 16.4364s	
10131/33250 (epoch 15.235), train_loss = 1.16419644, grad/param norm = 1.4186e-01, time/batch = 16.2848s	
10132/33250 (epoch 15.236), train_loss = 0.94802238, grad/param norm = 1.4606e-01, time/batch = 15.4297s	
10133/33250 (epoch 15.238), train_loss = 1.11405901, grad/param norm = 1.6621e-01, time/batch = 15.1872s	
10134/33250 (epoch 15.239), train_loss = 1.17736908, grad/param norm = 1.7201e-01, time/batch = 15.0503s	
10135/33250 (epoch 15.241), train_loss = 1.11628283, grad/param norm = 1.6303e-01, time/batch = 15.9407s	
10136/33250 (epoch 15.242), train_loss = 1.08914832, grad/param norm = 1.4983e-01, time/batch = 15.1303s	
10137/33250 (epoch 15.244), train_loss = 1.13104339, grad/param norm = 1.8312e-01, time/batch = 15.0862s	
10138/33250 (epoch 15.245), train_loss = 1.01730055, grad/param norm = 1.4049e-01, time/batch = 15.0275s	
10139/33250 (epoch 15.247), train_loss = 1.05962507, grad/param norm = 1.4878e-01, time/batch = 15.7576s	
10140/33250 (epoch 15.248), train_loss = 1.24741374, grad/param norm = 1.9849e-01, time/batch = 15.7176s	
10141/33250 (epoch 15.250), train_loss = 1.09771016, grad/param norm = 1.3830e-01, time/batch = 15.9354s	
10142/33250 (epoch 15.251), train_loss = 1.04533090, grad/param norm = 1.4739e-01, time/batch = 16.3019s	
10143/33250 (epoch 15.253), train_loss = 0.94539483, grad/param norm = 1.3051e-01, time/batch = 17.8737s	
10144/33250 (epoch 15.254), train_loss = 0.96114353, grad/param norm = 1.6157e-01, time/batch = 16.3568s	
10145/33250 (epoch 15.256), train_loss = 1.04138158, grad/param norm = 1.4019e-01, time/batch = 16.0987s	
10146/33250 (epoch 15.257), train_loss = 1.17376883, grad/param norm = 1.5729e-01, time/batch = 16.1989s	
10147/33250 (epoch 15.259), train_loss = 1.12978240, grad/param norm = 1.4831e-01, time/batch = 15.2024s	
10148/33250 (epoch 15.260), train_loss = 0.92812139, grad/param norm = 1.4801e-01, time/batch = 16.0863s	
10149/33250 (epoch 15.262), train_loss = 1.06176077, grad/param norm = 1.3994e-01, time/batch = 16.3407s	
10150/33250 (epoch 15.263), train_loss = 0.93893655, grad/param norm = 1.3785e-01, time/batch = 16.7879s	
10151/33250 (epoch 15.265), train_loss = 1.09078440, grad/param norm = 1.4677e-01, time/batch = 16.2875s	
10152/33250 (epoch 15.266), train_loss = 1.03598838, grad/param norm = 1.6549e-01, time/batch = 16.3728s	
10153/33250 (epoch 15.268), train_loss = 0.94925041, grad/param norm = 1.3722e-01, time/batch = 18.8713s	
10154/33250 (epoch 15.269), train_loss = 0.83196631, grad/param norm = 1.4013e-01, time/batch = 15.2847s	
10155/33250 (epoch 15.271), train_loss = 0.99078839, grad/param norm = 1.4229e-01, time/batch = 15.4406s	
10156/33250 (epoch 15.272), train_loss = 0.87044639, grad/param norm = 1.2673e-01, time/batch = 15.6175s	
10157/33250 (epoch 15.274), train_loss = 0.78408261, grad/param norm = 1.3009e-01, time/batch = 15.9465s	
10158/33250 (epoch 15.275), train_loss = 0.94423556, grad/param norm = 1.3694e-01, time/batch = 15.4319s	
10159/33250 (epoch 15.277), train_loss = 0.81720714, grad/param norm = 1.2945e-01, time/batch = 15.2590s	
10160/33250 (epoch 15.278), train_loss = 0.95675708, grad/param norm = 1.5571e-01, time/batch = 15.4752s	
10161/33250 (epoch 15.280), train_loss = 0.88476264, grad/param norm = 1.2712e-01, time/batch = 15.6993s	
10162/33250 (epoch 15.281), train_loss = 1.03338150, grad/param norm = 1.5429e-01, time/batch = 15.3297s	
10163/33250 (epoch 15.283), train_loss = 1.05558023, grad/param norm = 1.7739e-01, time/batch = 14.9398s	
10164/33250 (epoch 15.284), train_loss = 0.92789010, grad/param norm = 1.5583e-01, time/batch = 15.2604s	
10165/33250 (epoch 15.286), train_loss = 1.07666269, grad/param norm = 1.5672e-01, time/batch = 17.1759s	
10166/33250 (epoch 15.287), train_loss = 0.87283148, grad/param norm = 1.3325e-01, time/batch = 16.3619s	
10167/33250 (epoch 15.289), train_loss = 0.84659510, grad/param norm = 1.4864e-01, time/batch = 15.3212s	
10168/33250 (epoch 15.290), train_loss = 1.01942069, grad/param norm = 1.3089e-01, time/batch = 15.7096s	
10169/33250 (epoch 15.292), train_loss = 1.05267974, grad/param norm = 1.5495e-01, time/batch = 15.2702s	
10170/33250 (epoch 15.293), train_loss = 1.13320856, grad/param norm = 1.6952e-01, time/batch = 16.2630s	
10171/33250 (epoch 15.295), train_loss = 1.06697388, grad/param norm = 1.5135e-01, time/batch = 14.8778s	
10172/33250 (epoch 15.296), train_loss = 1.03735740, grad/param norm = 1.4293e-01, time/batch = 16.8838s	
10173/33250 (epoch 15.298), train_loss = 0.85068355, grad/param norm = 1.2484e-01, time/batch = 18.6193s	
10174/33250 (epoch 15.299), train_loss = 0.79841014, grad/param norm = 1.3297e-01, time/batch = 16.7589s	
10175/33250 (epoch 15.301), train_loss = 1.05543833, grad/param norm = 1.4406e-01, time/batch = 15.0299s	
10176/33250 (epoch 15.302), train_loss = 1.07949817, grad/param norm = 2.1119e-01, time/batch = 15.7739s	
10177/33250 (epoch 15.304), train_loss = 0.94152898, grad/param norm = 1.5537e-01, time/batch = 16.5110s	
10178/33250 (epoch 15.305), train_loss = 1.00774157, grad/param norm = 1.4730e-01, time/batch = 15.3376s	
10179/33250 (epoch 15.307), train_loss = 1.08260513, grad/param norm = 1.5502e-01, time/batch = 16.1137s	
10180/33250 (epoch 15.308), train_loss = 1.26457742, grad/param norm = 1.7331e-01, time/batch = 17.0864s	
10181/33250 (epoch 15.310), train_loss = 1.01657211, grad/param norm = 1.5514e-01, time/batch = 15.6081s	
10182/33250 (epoch 15.311), train_loss = 1.14231259, grad/param norm = 1.5445e-01, time/batch = 16.9618s	
10183/33250 (epoch 15.313), train_loss = 0.84196605, grad/param norm = 1.3110e-01, time/batch = 16.4655s	
10184/33250 (epoch 15.314), train_loss = 1.00681382, grad/param norm = 1.4250e-01, time/batch = 16.8564s	
10185/33250 (epoch 15.316), train_loss = 1.18687095, grad/param norm = 1.9943e-01, time/batch = 17.2680s	
10186/33250 (epoch 15.317), train_loss = 0.91330916, grad/param norm = 1.3256e-01, time/batch = 15.1754s	
10187/33250 (epoch 15.319), train_loss = 1.11291488, grad/param norm = 1.7964e-01, time/batch = 16.6815s	
10188/33250 (epoch 15.320), train_loss = 1.15103904, grad/param norm = 1.8746e-01, time/batch = 14.9348s	
10189/33250 (epoch 15.322), train_loss = 1.20341506, grad/param norm = 1.8809e-01, time/batch = 15.4429s	
10190/33250 (epoch 15.323), train_loss = 1.25409610, grad/param norm = 1.8675e-01, time/batch = 16.8427s	
10191/33250 (epoch 15.325), train_loss = 1.05135988, grad/param norm = 1.7292e-01, time/batch = 16.5794s	
10192/33250 (epoch 15.326), train_loss = 1.18562551, grad/param norm = 1.5328e-01, time/batch = 14.9539s	
10193/33250 (epoch 15.328), train_loss = 0.95688588, grad/param norm = 1.3134e-01, time/batch = 18.3463s	
10194/33250 (epoch 15.329), train_loss = 1.02957630, grad/param norm = 1.6575e-01, time/batch = 17.9538s	
10195/33250 (epoch 15.331), train_loss = 1.01201525, grad/param norm = 1.7539e-01, time/batch = 17.5296s	
10196/33250 (epoch 15.332), train_loss = 0.97663021, grad/param norm = 1.3864e-01, time/batch = 16.5145s	
10197/33250 (epoch 15.334), train_loss = 1.16522429, grad/param norm = 1.4617e-01, time/batch = 16.3423s	
10198/33250 (epoch 15.335), train_loss = 0.75685341, grad/param norm = 1.3477e-01, time/batch = 17.2628s	
10199/33250 (epoch 15.337), train_loss = 1.05822101, grad/param norm = 1.4097e-01, time/batch = 17.3493s	
10200/33250 (epoch 15.338), train_loss = 1.14180826, grad/param norm = 1.5904e-01, time/batch = 17.0915s	
10201/33250 (epoch 15.340), train_loss = 1.02139975, grad/param norm = 1.4356e-01, time/batch = 18.0006s	
10202/33250 (epoch 15.341), train_loss = 0.95141429, grad/param norm = 1.4831e-01, time/batch = 18.4273s	
10203/33250 (epoch 15.343), train_loss = 0.97617381, grad/param norm = 1.5045e-01, time/batch = 16.4229s	
10204/33250 (epoch 15.344), train_loss = 1.00853780, grad/param norm = 1.3731e-01, time/batch = 18.7828s	
10205/33250 (epoch 15.346), train_loss = 0.87611249, grad/param norm = 1.5405e-01, time/batch = 15.7986s	
10206/33250 (epoch 15.347), train_loss = 1.29353189, grad/param norm = 1.6765e-01, time/batch = 17.0521s	
10207/33250 (epoch 15.349), train_loss = 0.96846924, grad/param norm = 1.5425e-01, time/batch = 15.6112s	
10208/33250 (epoch 15.350), train_loss = 0.98455065, grad/param norm = 1.5187e-01, time/batch = 16.9407s	
10209/33250 (epoch 15.352), train_loss = 0.88443345, grad/param norm = 1.4521e-01, time/batch = 16.7720s	
10210/33250 (epoch 15.353), train_loss = 0.97986082, grad/param norm = 1.4749e-01, time/batch = 15.7800s	
10211/33250 (epoch 15.355), train_loss = 0.98707879, grad/param norm = 1.5923e-01, time/batch = 17.1784s	
10212/33250 (epoch 15.356), train_loss = 0.92997112, grad/param norm = 1.5280e-01, time/batch = 16.9562s	
10213/33250 (epoch 15.358), train_loss = 0.96169785, grad/param norm = 1.4045e-01, time/batch = 18.5366s	
10214/33250 (epoch 15.359), train_loss = 0.95936082, grad/param norm = 1.3071e-01, time/batch = 17.6134s	
10215/33250 (epoch 15.361), train_loss = 1.17868554, grad/param norm = 1.6478e-01, time/batch = 18.4374s	
10216/33250 (epoch 15.362), train_loss = 1.02366173, grad/param norm = 1.5130e-01, time/batch = 16.0939s	
10217/33250 (epoch 15.364), train_loss = 1.08728797, grad/param norm = 1.6433e-01, time/batch = 15.6926s	
10218/33250 (epoch 15.365), train_loss = 1.00473659, grad/param norm = 1.4054e-01, time/batch = 17.4324s	
10219/33250 (epoch 15.367), train_loss = 1.01016052, grad/param norm = 1.3628e-01, time/batch = 16.6956s	
10220/33250 (epoch 15.368), train_loss = 0.99799416, grad/param norm = 1.4225e-01, time/batch = 16.7706s	
10221/33250 (epoch 15.370), train_loss = 0.89048753, grad/param norm = 1.2556e-01, time/batch = 17.6727s	
10222/33250 (epoch 15.371), train_loss = 1.15480658, grad/param norm = 1.5843e-01, time/batch = 17.5408s	
10223/33250 (epoch 15.373), train_loss = 0.95995993, grad/param norm = 1.2669e-01, time/batch = 15.9425s	
10224/33250 (epoch 15.374), train_loss = 1.09465212, grad/param norm = 2.0383e-01, time/batch = 16.0234s	
10225/33250 (epoch 15.376), train_loss = 0.97425324, grad/param norm = 1.5270e-01, time/batch = 17.9443s	
10226/33250 (epoch 15.377), train_loss = 0.90367345, grad/param norm = 1.7242e-01, time/batch = 15.7052s	
10227/33250 (epoch 15.379), train_loss = 0.92579690, grad/param norm = 1.5037e-01, time/batch = 17.4265s	
10228/33250 (epoch 15.380), train_loss = 1.04985392, grad/param norm = 1.8138e-01, time/batch = 16.0894s	
10229/33250 (epoch 15.382), train_loss = 1.10880166, grad/param norm = 1.6920e-01, time/batch = 16.1081s	
10230/33250 (epoch 15.383), train_loss = 0.92481528, grad/param norm = 1.4194e-01, time/batch = 16.5369s	
10231/33250 (epoch 15.385), train_loss = 0.85870195, grad/param norm = 1.4732e-01, time/batch = 16.6877s	
10232/33250 (epoch 15.386), train_loss = 0.87284161, grad/param norm = 1.4062e-01, time/batch = 17.3510s	
10233/33250 (epoch 15.388), train_loss = 0.91922455, grad/param norm = 1.5203e-01, time/batch = 17.2821s	
10234/33250 (epoch 15.389), train_loss = 0.96474588, grad/param norm = 1.5351e-01, time/batch = 17.0651s	
10235/33250 (epoch 15.391), train_loss = 1.01207423, grad/param norm = 1.4925e-01, time/batch = 16.8732s	
10236/33250 (epoch 15.392), train_loss = 1.11031575, grad/param norm = 1.5522e-01, time/batch = 18.0994s	
10237/33250 (epoch 15.394), train_loss = 1.15716254, grad/param norm = 1.7520e-01, time/batch = 16.1092s	
10238/33250 (epoch 15.395), train_loss = 1.09838001, grad/param norm = 1.3766e-01, time/batch = 20.5039s	
10239/33250 (epoch 15.397), train_loss = 1.13098289, grad/param norm = 1.5574e-01, time/batch = 24.6286s	
10240/33250 (epoch 15.398), train_loss = 0.95421697, grad/param norm = 1.3947e-01, time/batch = 15.4363s	
10241/33250 (epoch 15.400), train_loss = 0.92184307, grad/param norm = 1.4346e-01, time/batch = 16.5157s	
10242/33250 (epoch 15.402), train_loss = 0.85900740, grad/param norm = 1.5775e-01, time/batch = 16.9650s	
10243/33250 (epoch 15.403), train_loss = 0.94493283, grad/param norm = 1.7774e-01, time/batch = 17.8756s	
10244/33250 (epoch 15.405), train_loss = 0.94550440, grad/param norm = 1.4768e-01, time/batch = 16.2000s	
10245/33250 (epoch 15.406), train_loss = 1.04009788, grad/param norm = 1.4894e-01, time/batch = 15.1114s	
10246/33250 (epoch 15.408), train_loss = 1.16245543, grad/param norm = 1.6699e-01, time/batch = 15.8980s	
10247/33250 (epoch 15.409), train_loss = 1.09358036, grad/param norm = 1.8311e-01, time/batch = 15.6492s	
10248/33250 (epoch 15.411), train_loss = 0.73723561, grad/param norm = 1.1046e-01, time/batch = 16.7671s	
10249/33250 (epoch 15.412), train_loss = 0.86676845, grad/param norm = 1.5379e-01, time/batch = 15.4376s	
10250/33250 (epoch 15.414), train_loss = 1.04149258, grad/param norm = 1.4810e-01, time/batch = 15.6964s	
10251/33250 (epoch 15.415), train_loss = 1.14040903, grad/param norm = 1.6524e-01, time/batch = 17.5080s	
10252/33250 (epoch 15.417), train_loss = 1.09747657, grad/param norm = 1.6432e-01, time/batch = 15.8730s	
10253/33250 (epoch 15.418), train_loss = 1.25716739, grad/param norm = 1.8332e-01, time/batch = 18.0349s	
10254/33250 (epoch 15.420), train_loss = 1.13542103, grad/param norm = 1.6112e-01, time/batch = 17.9514s	
10255/33250 (epoch 15.421), train_loss = 0.94476111, grad/param norm = 1.6286e-01, time/batch = 18.0238s	
10256/33250 (epoch 15.423), train_loss = 1.07174895, grad/param norm = 1.5962e-01, time/batch = 15.1726s	
10257/33250 (epoch 15.424), train_loss = 1.25496994, grad/param norm = 2.5240e-01, time/batch = 16.5934s	
10258/33250 (epoch 15.426), train_loss = 0.93726316, grad/param norm = 1.4422e-01, time/batch = 15.6885s	
10259/33250 (epoch 15.427), train_loss = 0.95159159, grad/param norm = 1.5376e-01, time/batch = 16.5834s	
10260/33250 (epoch 15.429), train_loss = 1.07785512, grad/param norm = 1.6502e-01, time/batch = 15.1185s	
10261/33250 (epoch 15.430), train_loss = 0.93870108, grad/param norm = 1.6601e-01, time/batch = 16.5914s	
10262/33250 (epoch 15.432), train_loss = 1.03501704, grad/param norm = 1.4537e-01, time/batch = 18.2668s	
10263/33250 (epoch 15.433), train_loss = 0.95211206, grad/param norm = 1.4760e-01, time/batch = 16.2742s	
10264/33250 (epoch 15.435), train_loss = 1.08417117, grad/param norm = 1.7717e-01, time/batch = 17.4349s	
10265/33250 (epoch 15.436), train_loss = 0.95254432, grad/param norm = 1.4773e-01, time/batch = 16.5182s	
10266/33250 (epoch 15.438), train_loss = 1.07237952, grad/param norm = 1.4144e-01, time/batch = 15.5043s	
10267/33250 (epoch 15.439), train_loss = 1.02985789, grad/param norm = 1.3999e-01, time/batch = 16.8445s	
10268/33250 (epoch 15.441), train_loss = 1.00182341, grad/param norm = 1.3207e-01, time/batch = 16.7550s	
10269/33250 (epoch 15.442), train_loss = 0.92309921, grad/param norm = 1.4893e-01, time/batch = 15.3347s	
10270/33250 (epoch 15.444), train_loss = 0.91830559, grad/param norm = 1.3605e-01, time/batch = 15.8405s	
10271/33250 (epoch 15.445), train_loss = 1.01781510, grad/param norm = 1.4662e-01, time/batch = 17.5882s	
10272/33250 (epoch 15.447), train_loss = 1.04194144, grad/param norm = 1.5609e-01, time/batch = 18.0270s	
10273/33250 (epoch 15.448), train_loss = 1.00197781, grad/param norm = 1.2950e-01, time/batch = 17.2057s	
10274/33250 (epoch 15.450), train_loss = 1.19682155, grad/param norm = 1.7305e-01, time/batch = 17.1079s	
10275/33250 (epoch 15.451), train_loss = 1.06874065, grad/param norm = 1.5463e-01, time/batch = 16.5247s	
10276/33250 (epoch 15.453), train_loss = 0.92694049, grad/param norm = 1.4121e-01, time/batch = 15.8601s	
10277/33250 (epoch 15.454), train_loss = 1.17179540, grad/param norm = 1.6120e-01, time/batch = 17.4868s	
10278/33250 (epoch 15.456), train_loss = 1.17201142, grad/param norm = 1.5370e-01, time/batch = 18.7465s	
10279/33250 (epoch 15.457), train_loss = 0.98687195, grad/param norm = 1.5599e-01, time/batch = 15.2691s	
10280/33250 (epoch 15.459), train_loss = 1.03150338, grad/param norm = 1.4274e-01, time/batch = 15.8575s	
10281/33250 (epoch 15.460), train_loss = 1.11888835, grad/param norm = 1.6419e-01, time/batch = 16.5067s	
10282/33250 (epoch 15.462), train_loss = 0.95145876, grad/param norm = 1.4077e-01, time/batch = 18.1201s	
10283/33250 (epoch 15.463), train_loss = 0.94034879, grad/param norm = 1.4539e-01, time/batch = 14.5544s	
10284/33250 (epoch 15.465), train_loss = 0.82171267, grad/param norm = 1.1815e-01, time/batch = 16.8737s	
10285/33250 (epoch 15.466), train_loss = 0.80019246, grad/param norm = 1.1358e-01, time/batch = 16.1370s	
10286/33250 (epoch 15.468), train_loss = 0.91031891, grad/param norm = 1.2891e-01, time/batch = 15.2689s	
10287/33250 (epoch 15.469), train_loss = 0.99427158, grad/param norm = 1.6608e-01, time/batch = 16.3650s	
10288/33250 (epoch 15.471), train_loss = 1.11183367, grad/param norm = 1.4530e-01, time/batch = 16.4333s	
10289/33250 (epoch 15.472), train_loss = 0.98724335, grad/param norm = 1.8355e-01, time/batch = 16.1905s	
10290/33250 (epoch 15.474), train_loss = 1.18082776, grad/param norm = 1.7428e-01, time/batch = 17.5839s	
10291/33250 (epoch 15.475), train_loss = 1.03404581, grad/param norm = 1.3669e-01, time/batch = 16.2534s	
10292/33250 (epoch 15.477), train_loss = 0.99780776, grad/param norm = 1.2804e-01, time/batch = 17.0899s	
10293/33250 (epoch 15.478), train_loss = 0.95665750, grad/param norm = 1.5333e-01, time/batch = 16.4666s	
10294/33250 (epoch 15.480), train_loss = 1.24454020, grad/param norm = 1.7027e-01, time/batch = 15.5469s	
10295/33250 (epoch 15.481), train_loss = 1.01957199, grad/param norm = 1.5040e-01, time/batch = 16.6938s	
10296/33250 (epoch 15.483), train_loss = 1.05438310, grad/param norm = 1.4671e-01, time/batch = 15.3690s	
10297/33250 (epoch 15.484), train_loss = 0.91814934, grad/param norm = 1.4837e-01, time/batch = 16.6191s	
10298/33250 (epoch 15.486), train_loss = 0.84343435, grad/param norm = 1.3769e-01, time/batch = 15.6940s	
10299/33250 (epoch 15.487), train_loss = 0.98198664, grad/param norm = 1.5541e-01, time/batch = 15.7723s	
10300/33250 (epoch 15.489), train_loss = 1.09725426, grad/param norm = 1.6677e-01, time/batch = 15.1058s	
10301/33250 (epoch 15.490), train_loss = 1.07034966, grad/param norm = 1.6387e-01, time/batch = 15.6182s	
10302/33250 (epoch 15.492), train_loss = 1.06478864, grad/param norm = 1.6557e-01, time/batch = 15.7643s	
10303/33250 (epoch 15.493), train_loss = 1.01751800, grad/param norm = 1.5579e-01, time/batch = 15.9624s	
10304/33250 (epoch 15.495), train_loss = 1.03020387, grad/param norm = 1.3791e-01, time/batch = 18.2149s	
10305/33250 (epoch 15.496), train_loss = 0.99108540, grad/param norm = 1.2703e-01, time/batch = 18.1898s	
10306/33250 (epoch 15.498), train_loss = 1.09999829, grad/param norm = 1.6111e-01, time/batch = 16.3599s	
10307/33250 (epoch 15.499), train_loss = 0.97651321, grad/param norm = 1.4463e-01, time/batch = 15.8640s	
10308/33250 (epoch 15.501), train_loss = 0.97230181, grad/param norm = 1.5455e-01, time/batch = 16.8600s	
10309/33250 (epoch 15.502), train_loss = 0.96637389, grad/param norm = 1.3109e-01, time/batch = 15.9438s	
10310/33250 (epoch 15.504), train_loss = 1.15011938, grad/param norm = 1.6491e-01, time/batch = 15.9338s	
10311/33250 (epoch 15.505), train_loss = 0.81805882, grad/param norm = 1.1833e-01, time/batch = 15.8578s	
10312/33250 (epoch 15.507), train_loss = 0.96453332, grad/param norm = 1.4798e-01, time/batch = 16.6966s	
10313/33250 (epoch 15.508), train_loss = 0.95950394, grad/param norm = 1.5163e-01, time/batch = 16.1957s	
10314/33250 (epoch 15.510), train_loss = 0.81510843, grad/param norm = 1.2538e-01, time/batch = 17.0118s	
10315/33250 (epoch 15.511), train_loss = 1.02233945, grad/param norm = 1.5460e-01, time/batch = 16.2745s	
10316/33250 (epoch 15.513), train_loss = 1.15210228, grad/param norm = 1.5273e-01, time/batch = 17.2835s	
10317/33250 (epoch 15.514), train_loss = 0.94131049, grad/param norm = 1.3101e-01, time/batch = 15.2651s	
10318/33250 (epoch 15.516), train_loss = 0.94855829, grad/param norm = 1.4514e-01, time/batch = 16.5260s	
10319/33250 (epoch 15.517), train_loss = 1.00628645, grad/param norm = 1.4593e-01, time/batch = 17.0167s	
10320/33250 (epoch 15.519), train_loss = 0.88249525, grad/param norm = 1.1865e-01, time/batch = 17.0201s	
10321/33250 (epoch 15.520), train_loss = 1.25939018, grad/param norm = 1.5917e-01, time/batch = 15.5266s	
10322/33250 (epoch 15.522), train_loss = 1.06286142, grad/param norm = 1.4683e-01, time/batch = 15.9149s	
10323/33250 (epoch 15.523), train_loss = 0.94761364, grad/param norm = 1.4276e-01, time/batch = 17.6346s	
10324/33250 (epoch 15.525), train_loss = 0.87412239, grad/param norm = 1.5317e-01, time/batch = 16.2065s	
10325/33250 (epoch 15.526), train_loss = 0.87384377, grad/param norm = 1.3950e-01, time/batch = 16.2269s	
10326/33250 (epoch 15.528), train_loss = 0.97401084, grad/param norm = 1.4444e-01, time/batch = 17.3700s	
10327/33250 (epoch 15.529), train_loss = 0.93148599, grad/param norm = 1.5033e-01, time/batch = 16.6955s	
10328/33250 (epoch 15.531), train_loss = 0.88691242, grad/param norm = 1.2570e-01, time/batch = 15.3346s	
10329/33250 (epoch 15.532), train_loss = 1.07458650, grad/param norm = 1.5896e-01, time/batch = 17.0093s	
10330/33250 (epoch 15.534), train_loss = 0.89703775, grad/param norm = 1.2313e-01, time/batch = 16.5377s	
10331/33250 (epoch 15.535), train_loss = 0.97791541, grad/param norm = 1.3816e-01, time/batch = 15.7771s	
10332/33250 (epoch 15.537), train_loss = 1.06198161, grad/param norm = 1.4829e-01, time/batch = 15.0185s	
10333/33250 (epoch 15.538), train_loss = 1.08232048, grad/param norm = 1.4622e-01, time/batch = 18.8642s	
10334/33250 (epoch 15.540), train_loss = 1.16005785, grad/param norm = 1.3547e-01, time/batch = 18.4430s	
10335/33250 (epoch 15.541), train_loss = 1.12014019, grad/param norm = 1.5809e-01, time/batch = 16.2930s	
10336/33250 (epoch 15.543), train_loss = 1.06898408, grad/param norm = 1.4583e-01, time/batch = 15.4903s	
10337/33250 (epoch 15.544), train_loss = 0.94641784, grad/param norm = 1.4907e-01, time/batch = 15.8641s	
10338/33250 (epoch 15.546), train_loss = 0.98999987, grad/param norm = 1.6178e-01, time/batch = 16.8544s	
10339/33250 (epoch 15.547), train_loss = 0.95721151, grad/param norm = 1.4410e-01, time/batch = 15.8461s	
10340/33250 (epoch 15.549), train_loss = 1.07558773, grad/param norm = 1.6200e-01, time/batch = 16.7626s	
10341/33250 (epoch 15.550), train_loss = 0.97724060, grad/param norm = 1.5110e-01, time/batch = 15.7961s	
10342/33250 (epoch 15.552), train_loss = 1.03152569, grad/param norm = 1.4338e-01, time/batch = 16.1194s	
10343/33250 (epoch 15.553), train_loss = 0.92957323, grad/param norm = 1.3369e-01, time/batch = 17.5337s	
10344/33250 (epoch 15.555), train_loss = 1.02247709, grad/param norm = 1.4132e-01, time/batch = 16.4627s	
10345/33250 (epoch 15.556), train_loss = 1.13363769, grad/param norm = 1.6991e-01, time/batch = 18.4498s	
10346/33250 (epoch 15.558), train_loss = 1.11054460, grad/param norm = 1.6180e-01, time/batch = 16.1725s	
10347/33250 (epoch 15.559), train_loss = 0.91109661, grad/param norm = 1.3911e-01, time/batch = 14.9473s	
10348/33250 (epoch 15.561), train_loss = 0.92646113, grad/param norm = 1.5200e-01, time/batch = 15.4529s	
10349/33250 (epoch 15.562), train_loss = 1.14215787, grad/param norm = 1.6359e-01, time/batch = 15.1923s	
10350/33250 (epoch 15.564), train_loss = 1.22125407, grad/param norm = 1.7755e-01, time/batch = 15.8502s	
10351/33250 (epoch 15.565), train_loss = 1.17520866, grad/param norm = 1.8116e-01, time/batch = 16.1894s	
10352/33250 (epoch 15.567), train_loss = 1.13899922, grad/param norm = 1.5591e-01, time/batch = 17.1068s	
10353/33250 (epoch 15.568), train_loss = 1.01773118, grad/param norm = 1.5380e-01, time/batch = 17.7682s	
10354/33250 (epoch 15.570), train_loss = 1.16595499, grad/param norm = 1.6856e-01, time/batch = 17.2178s	
10355/33250 (epoch 15.571), train_loss = 1.18567468, grad/param norm = 1.5811e-01, time/batch = 19.0329s	
10356/33250 (epoch 15.573), train_loss = 1.05524467, grad/param norm = 1.5859e-01, time/batch = 17.0494s	
10357/33250 (epoch 15.574), train_loss = 0.92378335, grad/param norm = 1.4277e-01, time/batch = 15.3712s	
10358/33250 (epoch 15.576), train_loss = 1.05462220, grad/param norm = 1.5142e-01, time/batch = 15.3470s	
10359/33250 (epoch 15.577), train_loss = 1.01215761, grad/param norm = 1.5377e-01, time/batch = 15.5076s	
10360/33250 (epoch 15.579), train_loss = 0.92274909, grad/param norm = 1.4980e-01, time/batch = 15.9432s	
10361/33250 (epoch 15.580), train_loss = 0.97145028, grad/param norm = 1.3486e-01, time/batch = 15.7650s	
10362/33250 (epoch 15.582), train_loss = 0.98654623, grad/param norm = 1.3499e-01, time/batch = 15.2815s	
10363/33250 (epoch 15.583), train_loss = 1.10051269, grad/param norm = 1.4692e-01, time/batch = 16.7057s	
10364/33250 (epoch 15.585), train_loss = 1.11356514, grad/param norm = 1.6094e-01, time/batch = 16.9487s	
10365/33250 (epoch 15.586), train_loss = 1.00230294, grad/param norm = 1.8622e-01, time/batch = 17.3564s	
10366/33250 (epoch 15.588), train_loss = 1.03929651, grad/param norm = 1.4630e-01, time/batch = 18.1281s	
10367/33250 (epoch 15.589), train_loss = 1.06078250, grad/param norm = 1.4705e-01, time/batch = 15.1890s	
10368/33250 (epoch 15.591), train_loss = 1.04305114, grad/param norm = 1.5912e-01, time/batch = 15.2776s	
10369/33250 (epoch 15.592), train_loss = 1.01546020, grad/param norm = 1.3414e-01, time/batch = 15.6263s	
10370/33250 (epoch 15.594), train_loss = 1.19685209, grad/param norm = 1.7909e-01, time/batch = 16.6794s	
10371/33250 (epoch 15.595), train_loss = 1.07547080, grad/param norm = 1.5461e-01, time/batch = 15.6222s	
10372/33250 (epoch 15.597), train_loss = 0.88735054, grad/param norm = 1.4219e-01, time/batch = 15.5907s	
10373/33250 (epoch 15.598), train_loss = 1.00811465, grad/param norm = 1.5657e-01, time/batch = 18.5868s	
10374/33250 (epoch 15.600), train_loss = 1.01280904, grad/param norm = 1.6529e-01, time/batch = 17.9485s	
10375/33250 (epoch 15.602), train_loss = 1.05865173, grad/param norm = 1.9513e-01, time/batch = 17.5367s	
10376/33250 (epoch 15.603), train_loss = 1.06441868, grad/param norm = 1.5609e-01, time/batch = 17.2866s	
10377/33250 (epoch 15.605), train_loss = 1.02815977, grad/param norm = 1.6210e-01, time/batch = 17.5137s	
10378/33250 (epoch 15.606), train_loss = 1.05952301, grad/param norm = 1.5054e-01, time/batch = 16.6062s	
10379/33250 (epoch 15.608), train_loss = 1.02773171, grad/param norm = 1.4460e-01, time/batch = 16.3559s	
10380/33250 (epoch 15.609), train_loss = 0.91459482, grad/param norm = 1.5054e-01, time/batch = 16.8543s	
10381/33250 (epoch 15.611), train_loss = 1.05460964, grad/param norm = 1.5363e-01, time/batch = 16.3451s	
10382/33250 (epoch 15.612), train_loss = 1.03490331, grad/param norm = 1.5662e-01, time/batch = 16.7279s	
10383/33250 (epoch 15.614), train_loss = 1.25098172, grad/param norm = 1.7354e-01, time/batch = 18.6852s	
10384/33250 (epoch 15.615), train_loss = 1.12356685, grad/param norm = 1.5834e-01, time/batch = 18.2002s	
10385/33250 (epoch 15.617), train_loss = 1.34441250, grad/param norm = 1.8207e-01, time/batch = 16.2812s	
10386/33250 (epoch 15.618), train_loss = 1.31652335, grad/param norm = 2.0457e-01, time/batch = 16.0141s	
10387/33250 (epoch 15.620), train_loss = 1.13417411, grad/param norm = 1.7603e-01, time/batch = 16.7756s	
10388/33250 (epoch 15.621), train_loss = 1.02434022, grad/param norm = 1.4729e-01, time/batch = 16.1918s	
10389/33250 (epoch 15.623), train_loss = 0.95054025, grad/param norm = 1.5502e-01, time/batch = 15.7723s	
10390/33250 (epoch 15.624), train_loss = 1.01168599, grad/param norm = 1.5964e-01, time/batch = 17.6020s	
10391/33250 (epoch 15.626), train_loss = 0.98730070, grad/param norm = 1.6822e-01, time/batch = 15.6047s	
10392/33250 (epoch 15.627), train_loss = 0.97053200, grad/param norm = 1.4344e-01, time/batch = 18.2786s	
10393/33250 (epoch 15.629), train_loss = 1.08886639, grad/param norm = 1.6853e-01, time/batch = 16.9535s	
10394/33250 (epoch 15.630), train_loss = 1.00978918, grad/param norm = 1.7615e-01, time/batch = 17.1213s	
10395/33250 (epoch 15.632), train_loss = 0.83952287, grad/param norm = 1.3084e-01, time/batch = 16.0310s	
10396/33250 (epoch 15.633), train_loss = 1.07796304, grad/param norm = 1.5683e-01, time/batch = 16.9382s	
10397/33250 (epoch 15.635), train_loss = 0.91089172, grad/param norm = 1.4022e-01, time/batch = 16.9368s	
10398/33250 (epoch 15.636), train_loss = 0.93693444, grad/param norm = 1.4157e-01, time/batch = 16.7730s	
10399/33250 (epoch 15.638), train_loss = 0.96910826, grad/param norm = 1.4517e-01, time/batch = 15.2117s	
10400/33250 (epoch 15.639), train_loss = 0.85109169, grad/param norm = 1.4164e-01, time/batch = 15.8320s	
10401/33250 (epoch 15.641), train_loss = 0.94583380, grad/param norm = 1.3338e-01, time/batch = 15.8458s	
10402/33250 (epoch 15.642), train_loss = 0.83259284, grad/param norm = 1.3979e-01, time/batch = 15.9544s	
10403/33250 (epoch 15.644), train_loss = 0.76864646, grad/param norm = 1.3730e-01, time/batch = 16.5360s	
10404/33250 (epoch 15.645), train_loss = 1.12322700, grad/param norm = 1.7471e-01, time/batch = 17.5119s	
10405/33250 (epoch 15.647), train_loss = 0.87951156, grad/param norm = 1.4357e-01, time/batch = 18.7050s	
10406/33250 (epoch 15.648), train_loss = 0.94027616, grad/param norm = 1.4787e-01, time/batch = 17.2616s	
10407/33250 (epoch 15.650), train_loss = 1.14593864, grad/param norm = 1.6691e-01, time/batch = 16.0025s	
10408/33250 (epoch 15.651), train_loss = 1.05608001, grad/param norm = 1.8610e-01, time/batch = 16.1796s	
10409/33250 (epoch 15.653), train_loss = 0.91646011, grad/param norm = 1.4219e-01, time/batch = 16.8417s	
10410/33250 (epoch 15.654), train_loss = 0.96724501, grad/param norm = 1.4461e-01, time/batch = 16.3492s	
10411/33250 (epoch 15.656), train_loss = 1.06814757, grad/param norm = 1.4875e-01, time/batch = 16.0200s	
10412/33250 (epoch 15.657), train_loss = 0.81066886, grad/param norm = 1.3960e-01, time/batch = 18.5163s	
10413/33250 (epoch 15.659), train_loss = 0.96418628, grad/param norm = 1.4904e-01, time/batch = 17.9492s	
10414/33250 (epoch 15.660), train_loss = 0.98876233, grad/param norm = 1.4928e-01, time/batch = 16.5432s	
10415/33250 (epoch 15.662), train_loss = 1.03077116, grad/param norm = 1.4877e-01, time/batch = 16.4582s	
10416/33250 (epoch 15.663), train_loss = 0.93247989, grad/param norm = 1.4702e-01, time/batch = 17.0276s	
10417/33250 (epoch 15.665), train_loss = 1.05366868, grad/param norm = 1.5854e-01, time/batch = 16.3633s	
10418/33250 (epoch 15.666), train_loss = 0.95512549, grad/param norm = 1.4290e-01, time/batch = 15.5683s	
10419/33250 (epoch 15.668), train_loss = 1.17072066, grad/param norm = 1.5351e-01, time/batch = 17.1715s	
10420/33250 (epoch 15.669), train_loss = 1.04938497, grad/param norm = 1.5707e-01, time/batch = 16.0332s	
10421/33250 (epoch 15.671), train_loss = 0.94380304, grad/param norm = 1.6983e-01, time/batch = 16.1576s	
10422/33250 (epoch 15.672), train_loss = 1.12137014, grad/param norm = 1.5900e-01, time/batch = 17.9549s	
10423/33250 (epoch 15.674), train_loss = 0.93587165, grad/param norm = 1.3230e-01, time/batch = 18.3621s	
10424/33250 (epoch 15.675), train_loss = 0.98685082, grad/param norm = 1.3395e-01, time/batch = 17.8731s	
10425/33250 (epoch 15.677), train_loss = 1.11819739, grad/param norm = 1.6119e-01, time/batch = 15.0581s	
10426/33250 (epoch 15.678), train_loss = 0.99716559, grad/param norm = 1.4958e-01, time/batch = 15.7056s	
10427/33250 (epoch 15.680), train_loss = 1.13861240, grad/param norm = 1.6642e-01, time/batch = 15.5913s	
10428/33250 (epoch 15.681), train_loss = 0.87485111, grad/param norm = 1.3906e-01, time/batch = 17.5143s	
10429/33250 (epoch 15.683), train_loss = 0.98812216, grad/param norm = 1.5649e-01, time/batch = 15.1951s	
10430/33250 (epoch 15.684), train_loss = 0.91541353, grad/param norm = 1.6735e-01, time/batch = 16.1189s	
10431/33250 (epoch 15.686), train_loss = 0.91546235, grad/param norm = 1.5438e-01, time/batch = 16.2045s	
10432/33250 (epoch 15.687), train_loss = 0.98737755, grad/param norm = 1.4614e-01, time/batch = 16.7969s	
10433/33250 (epoch 15.689), train_loss = 0.95417347, grad/param norm = 1.5255e-01, time/batch = 16.7839s	
10434/33250 (epoch 15.690), train_loss = 1.04535529, grad/param norm = 1.5691e-01, time/batch = 18.3689s	
10435/33250 (epoch 15.692), train_loss = 1.00109762, grad/param norm = 1.5286e-01, time/batch = 17.5361s	
10436/33250 (epoch 15.693), train_loss = 1.08389151, grad/param norm = 1.4692e-01, time/batch = 15.8130s	
10437/33250 (epoch 15.695), train_loss = 1.03268939, grad/param norm = 1.4115e-01, time/batch = 17.0180s	
10438/33250 (epoch 15.696), train_loss = 1.05687741, grad/param norm = 1.4772e-01, time/batch = 16.6823s	
10439/33250 (epoch 15.698), train_loss = 0.93951880, grad/param norm = 1.5075e-01, time/batch = 15.4328s	
10440/33250 (epoch 15.699), train_loss = 1.22149375, grad/param norm = 1.5868e-01, time/batch = 15.7713s	
10441/33250 (epoch 15.701), train_loss = 0.98804786, grad/param norm = 1.3590e-01, time/batch = 16.7468s	
10442/33250 (epoch 15.702), train_loss = 0.96853069, grad/param norm = 1.9055e-01, time/batch = 18.1962s	
10443/33250 (epoch 15.704), train_loss = 1.20543904, grad/param norm = 1.9289e-01, time/batch = 17.5047s	
10444/33250 (epoch 15.705), train_loss = 0.91355955, grad/param norm = 1.2760e-01, time/batch = 17.3801s	
10445/33250 (epoch 15.707), train_loss = 0.84197383, grad/param norm = 1.5656e-01, time/batch = 18.0285s	
10446/33250 (epoch 15.708), train_loss = 1.10848461, grad/param norm = 1.5420e-01, time/batch = 16.5245s	
10447/33250 (epoch 15.710), train_loss = 1.08482122, grad/param norm = 1.5929e-01, time/batch = 17.0232s	
10448/33250 (epoch 15.711), train_loss = 0.93848547, grad/param norm = 1.5167e-01, time/batch = 16.4353s	
10449/33250 (epoch 15.713), train_loss = 1.05535960, grad/param norm = 1.4993e-01, time/batch = 18.1772s	
10450/33250 (epoch 15.714), train_loss = 1.03093534, grad/param norm = 1.5620e-01, time/batch = 15.4468s	
10451/33250 (epoch 15.716), train_loss = 1.10565360, grad/param norm = 1.6054e-01, time/batch = 15.5922s	
10452/33250 (epoch 15.717), train_loss = 0.93554231, grad/param norm = 1.3021e-01, time/batch = 18.3771s	
10453/33250 (epoch 15.719), train_loss = 0.99631846, grad/param norm = 1.4344e-01, time/batch = 21.4734s	
10454/33250 (epoch 15.720), train_loss = 1.23777393, grad/param norm = 1.7124e-01, time/batch = 27.2046s	
10455/33250 (epoch 15.722), train_loss = 0.93031405, grad/param norm = 1.4399e-01, time/batch = 15.3666s	
10456/33250 (epoch 15.723), train_loss = 0.80284913, grad/param norm = 1.2085e-01, time/batch = 16.1774s	
10457/33250 (epoch 15.725), train_loss = 0.86462371, grad/param norm = 1.3115e-01, time/batch = 15.6997s	
10458/33250 (epoch 15.726), train_loss = 0.97047014, grad/param norm = 1.3395e-01, time/batch = 15.9540s	
10459/33250 (epoch 15.728), train_loss = 1.06503577, grad/param norm = 1.5467e-01, time/batch = 15.4098s	
10460/33250 (epoch 15.729), train_loss = 1.13057508, grad/param norm = 1.5371e-01, time/batch = 15.1978s	
10461/33250 (epoch 15.731), train_loss = 0.95097368, grad/param norm = 1.5160e-01, time/batch = 14.9666s	
10462/33250 (epoch 15.732), train_loss = 0.90482516, grad/param norm = 1.3580e-01, time/batch = 14.8856s	
10463/33250 (epoch 15.734), train_loss = 1.02405973, grad/param norm = 1.5035e-01, time/batch = 16.2940s	
10464/33250 (epoch 15.735), train_loss = 1.01924434, grad/param norm = 1.6771e-01, time/batch = 15.3721s	
10465/33250 (epoch 15.737), train_loss = 0.98652960, grad/param norm = 1.3189e-01, time/batch = 15.1106s	
10466/33250 (epoch 15.738), train_loss = 1.01678496, grad/param norm = 1.4660e-01, time/batch = 16.2675s	
10467/33250 (epoch 15.740), train_loss = 1.15298781, grad/param norm = 1.5969e-01, time/batch = 16.9117s	
10468/33250 (epoch 15.741), train_loss = 1.09884005, grad/param norm = 1.5260e-01, time/batch = 16.1768s	
10469/33250 (epoch 15.743), train_loss = 0.94886723, grad/param norm = 1.2917e-01, time/batch = 16.2804s	
10470/33250 (epoch 15.744), train_loss = 0.97162773, grad/param norm = 1.5639e-01, time/batch = 16.5313s	
10471/33250 (epoch 15.746), train_loss = 0.94622808, grad/param norm = 1.3659e-01, time/batch = 15.7470s	
10472/33250 (epoch 15.747), train_loss = 0.96400964, grad/param norm = 1.6248e-01, time/batch = 16.6880s	
10473/33250 (epoch 15.749), train_loss = 1.12014627, grad/param norm = 1.7197e-01, time/batch = 17.8732s	
10474/33250 (epoch 15.750), train_loss = 1.09384901, grad/param norm = 1.6754e-01, time/batch = 16.0428s	
10475/33250 (epoch 15.752), train_loss = 0.97020522, grad/param norm = 1.3993e-01, time/batch = 16.4328s	
10476/33250 (epoch 15.753), train_loss = 0.99447774, grad/param norm = 1.5089e-01, time/batch = 17.9337s	
10477/33250 (epoch 15.755), train_loss = 1.00044526, grad/param norm = 1.6145e-01, time/batch = 15.7491s	
10478/33250 (epoch 15.756), train_loss = 1.07574755, grad/param norm = 1.5135e-01, time/batch = 15.4453s	
10479/33250 (epoch 15.758), train_loss = 1.13275607, grad/param norm = 1.4982e-01, time/batch = 15.0316s	
10480/33250 (epoch 15.759), train_loss = 0.91695251, grad/param norm = 1.3554e-01, time/batch = 16.9333s	
10481/33250 (epoch 15.761), train_loss = 0.97256837, grad/param norm = 1.3602e-01, time/batch = 15.9371s	
10482/33250 (epoch 15.762), train_loss = 1.13141864, grad/param norm = 1.4642e-01, time/batch = 15.0531s	
10483/33250 (epoch 15.764), train_loss = 0.91370661, grad/param norm = 1.6506e-01, time/batch = 17.6135s	
10484/33250 (epoch 15.765), train_loss = 1.05217445, grad/param norm = 1.5018e-01, time/batch = 19.1077s	
10485/33250 (epoch 15.767), train_loss = 0.84162779, grad/param norm = 1.5112e-01, time/batch = 16.1862s	
10486/33250 (epoch 15.768), train_loss = 0.87412205, grad/param norm = 1.4465e-01, time/batch = 16.2600s	
10487/33250 (epoch 15.770), train_loss = 1.06908874, grad/param norm = 1.6485e-01, time/batch = 15.6889s	
10488/33250 (epoch 15.771), train_loss = 1.06709229, grad/param norm = 1.6280e-01, time/batch = 17.2794s	
10489/33250 (epoch 15.773), train_loss = 0.99176113, grad/param norm = 1.6055e-01, time/batch = 16.4256s	
10490/33250 (epoch 15.774), train_loss = 0.85221811, grad/param norm = 1.3697e-01, time/batch = 16.3452s	
10491/33250 (epoch 15.776), train_loss = 0.94496160, grad/param norm = 1.5157e-01, time/batch = 16.1184s	
10492/33250 (epoch 15.777), train_loss = 1.11089651, grad/param norm = 1.6931e-01, time/batch = 16.0368s	
10493/33250 (epoch 15.779), train_loss = 1.00774522, grad/param norm = 1.5477e-01, time/batch = 16.7658s	
10494/33250 (epoch 15.780), train_loss = 1.18457095, grad/param norm = 1.6662e-01, time/batch = 18.0379s	
10495/33250 (epoch 15.782), train_loss = 1.04862247, grad/param norm = 1.4372e-01, time/batch = 16.0931s	
10496/33250 (epoch 15.783), train_loss = 0.84138332, grad/param norm = 1.3482e-01, time/batch = 15.7014s	
10497/33250 (epoch 15.785), train_loss = 0.89868223, grad/param norm = 1.4030e-01, time/batch = 16.0172s	
10498/33250 (epoch 15.786), train_loss = 1.07779361, grad/param norm = 1.5608e-01, time/batch = 16.1180s	
10499/33250 (epoch 15.788), train_loss = 1.09536998, grad/param norm = 1.5578e-01, time/batch = 15.8010s	
10500/33250 (epoch 15.789), train_loss = 1.11313715, grad/param norm = 1.8082e-01, time/batch = 15.3526s	
10501/33250 (epoch 15.791), train_loss = 1.16729134, grad/param norm = 1.5479e-01, time/batch = 16.1831s	
10502/33250 (epoch 15.792), train_loss = 1.24750780, grad/param norm = 1.5678e-01, time/batch = 17.7950s	
10503/33250 (epoch 15.794), train_loss = 1.01485273, grad/param norm = 1.6203e-01, time/batch = 17.9498s	
10504/33250 (epoch 15.795), train_loss = 1.04346344, grad/param norm = 1.4673e-01, time/batch = 16.8562s	
10505/33250 (epoch 15.797), train_loss = 1.12101037, grad/param norm = 1.6885e-01, time/batch = 15.8754s	
10506/33250 (epoch 15.798), train_loss = 1.02329462, grad/param norm = 1.7702e-01, time/batch = 16.1018s	
10507/33250 (epoch 15.800), train_loss = 1.07247163, grad/param norm = 1.5864e-01, time/batch = 17.4217s	
10508/33250 (epoch 15.802), train_loss = 0.95457964, grad/param norm = 1.2300e-01, time/batch = 15.0248s	
10509/33250 (epoch 15.803), train_loss = 1.01091210, grad/param norm = 1.3575e-01, time/batch = 16.7597s	
10510/33250 (epoch 15.805), train_loss = 1.08042284, grad/param norm = 1.6142e-01, time/batch = 15.4465s	
10511/33250 (epoch 15.806), train_loss = 1.04125194, grad/param norm = 1.5666e-01, time/batch = 15.5786s	
10512/33250 (epoch 15.808), train_loss = 0.98508323, grad/param norm = 1.3347e-01, time/batch = 18.1817s	
10513/33250 (epoch 15.809), train_loss = 0.94173436, grad/param norm = 1.5025e-01, time/batch = 17.1961s	
10514/33250 (epoch 15.811), train_loss = 0.94112997, grad/param norm = 1.4949e-01, time/batch = 18.2154s	
10515/33250 (epoch 15.812), train_loss = 1.10651997, grad/param norm = 1.6674e-01, time/batch = 16.1816s	
10516/33250 (epoch 15.814), train_loss = 1.02361804, grad/param norm = 1.5006e-01, time/batch = 16.8500s	
10517/33250 (epoch 15.815), train_loss = 1.07850427, grad/param norm = 1.4983e-01, time/batch = 16.0403s	
10518/33250 (epoch 15.817), train_loss = 1.00008019, grad/param norm = 1.5165e-01, time/batch = 15.8623s	
10519/33250 (epoch 15.818), train_loss = 0.94316832, grad/param norm = 1.4138e-01, time/batch = 18.8364s	
10520/33250 (epoch 15.820), train_loss = 1.01927585, grad/param norm = 1.3995e-01, time/batch = 15.6177s	
10521/33250 (epoch 15.821), train_loss = 0.98666978, grad/param norm = 1.3944e-01, time/batch = 17.1017s	
10522/33250 (epoch 15.823), train_loss = 1.32346617, grad/param norm = 1.8154e-01, time/batch = 16.4538s	
10523/33250 (epoch 15.824), train_loss = 0.97114432, grad/param norm = 1.5505e-01, time/batch = 17.6268s	
10524/33250 (epoch 15.826), train_loss = 1.05456173, grad/param norm = 1.6466e-01, time/batch = 17.3832s	
10525/33250 (epoch 15.827), train_loss = 0.82105386, grad/param norm = 1.3867e-01, time/batch = 17.0193s	
10526/33250 (epoch 15.829), train_loss = 1.03996240, grad/param norm = 1.7330e-01, time/batch = 15.1013s	
10527/33250 (epoch 15.830), train_loss = 1.14938238, grad/param norm = 1.9721e-01, time/batch = 17.8592s	
10528/33250 (epoch 15.832), train_loss = 1.02238360, grad/param norm = 1.5717e-01, time/batch = 15.5903s	
10529/33250 (epoch 15.833), train_loss = 1.04651585, grad/param norm = 1.5808e-01, time/batch = 15.9968s	
10530/33250 (epoch 15.835), train_loss = 0.93693340, grad/param norm = 1.9969e-01, time/batch = 16.0294s	
10531/33250 (epoch 15.836), train_loss = 0.99454247, grad/param norm = 1.5215e-01, time/batch = 16.0974s	
10532/33250 (epoch 15.838), train_loss = 1.00106236, grad/param norm = 1.4832e-01, time/batch = 18.1851s	
10533/33250 (epoch 15.839), train_loss = 0.99482221, grad/param norm = 1.6065e-01, time/batch = 16.8767s	
10534/33250 (epoch 15.841), train_loss = 0.94049179, grad/param norm = 1.3685e-01, time/batch = 18.8772s	
10535/33250 (epoch 15.842), train_loss = 1.18039227, grad/param norm = 1.5310e-01, time/batch = 17.9528s	
10536/33250 (epoch 15.844), train_loss = 1.14586845, grad/param norm = 1.8110e-01, time/batch = 15.8536s	
10537/33250 (epoch 15.845), train_loss = 1.23574073, grad/param norm = 1.7071e-01, time/batch = 17.0221s	
10538/33250 (epoch 15.847), train_loss = 1.16883510, grad/param norm = 1.6026e-01, time/batch = 15.3652s	
10539/33250 (epoch 15.848), train_loss = 1.32198835, grad/param norm = 1.9378e-01, time/batch = 16.8536s	
10540/33250 (epoch 15.850), train_loss = 1.14202821, grad/param norm = 1.5968e-01, time/batch = 15.5295s	
10541/33250 (epoch 15.851), train_loss = 0.95658642, grad/param norm = 1.5571e-01, time/batch = 16.7847s	
10542/33250 (epoch 15.853), train_loss = 1.09793446, grad/param norm = 1.6439e-01, time/batch = 17.6189s	
10543/33250 (epoch 15.854), train_loss = 0.93326447, grad/param norm = 1.3565e-01, time/batch = 17.0043s	
10544/33250 (epoch 15.856), train_loss = 0.95511599, grad/param norm = 1.5732e-01, time/batch = 19.1001s	
10545/33250 (epoch 15.857), train_loss = 0.87730677, grad/param norm = 1.3883e-01, time/batch = 17.1147s	
10546/33250 (epoch 15.859), train_loss = 0.88425448, grad/param norm = 1.3998e-01, time/batch = 15.6116s	
10547/33250 (epoch 15.860), train_loss = 1.01900546, grad/param norm = 1.3996e-01, time/batch = 15.7717s	
10548/33250 (epoch 15.862), train_loss = 0.92538229, grad/param norm = 1.3834e-01, time/batch = 15.7012s	
10549/33250 (epoch 15.863), train_loss = 0.96306660, grad/param norm = 1.6117e-01, time/batch = 16.7749s	
10550/33250 (epoch 15.865), train_loss = 1.07805365, grad/param norm = 1.5848e-01, time/batch = 16.1915s	
10551/33250 (epoch 15.866), train_loss = 0.99748562, grad/param norm = 1.6572e-01, time/batch = 16.9349s	
10552/33250 (epoch 15.868), train_loss = 1.12974255, grad/param norm = 1.8652e-01, time/batch = 18.1982s	
10553/33250 (epoch 15.869), train_loss = 1.06593193, grad/param norm = 1.5256e-01, time/batch = 16.1242s	
10554/33250 (epoch 15.871), train_loss = 0.79672585, grad/param norm = 1.3352e-01, time/batch = 16.2571s	
10555/33250 (epoch 15.872), train_loss = 1.05551319, grad/param norm = 1.6638e-01, time/batch = 16.4499s	
10556/33250 (epoch 15.874), train_loss = 0.92874076, grad/param norm = 1.4512e-01, time/batch = 16.1166s	
10557/33250 (epoch 15.875), train_loss = 0.92684422, grad/param norm = 1.5944e-01, time/batch = 15.9534s	
10558/33250 (epoch 15.877), train_loss = 1.12872285, grad/param norm = 1.5366e-01, time/batch = 15.9474s	
10559/33250 (epoch 15.878), train_loss = 1.06848363, grad/param norm = 1.5642e-01, time/batch = 16.3589s	
10560/33250 (epoch 15.880), train_loss = 1.01274039, grad/param norm = 1.7693e-01, time/batch = 16.4450s	
10561/33250 (epoch 15.881), train_loss = 1.19298196, grad/param norm = 1.8058e-01, time/batch = 15.7615s	
10562/33250 (epoch 15.883), train_loss = 1.04899215, grad/param norm = 1.5718e-01, time/batch = 17.8598s	
10563/33250 (epoch 15.884), train_loss = 1.04852021, grad/param norm = 1.6239e-01, time/batch = 15.8576s	
10564/33250 (epoch 15.886), train_loss = 0.94773270, grad/param norm = 1.3215e-01, time/batch = 15.3596s	
10565/33250 (epoch 15.887), train_loss = 1.00124923, grad/param norm = 1.6053e-01, time/batch = 15.5294s	
10566/33250 (epoch 15.889), train_loss = 0.97009267, grad/param norm = 1.4201e-01, time/batch = 16.1293s	
10567/33250 (epoch 15.890), train_loss = 0.84258078, grad/param norm = 1.1777e-01, time/batch = 16.8442s	
10568/33250 (epoch 15.892), train_loss = 1.07630144, grad/param norm = 1.4921e-01, time/batch = 16.5274s	
10569/33250 (epoch 15.893), train_loss = 1.07737319, grad/param norm = 1.5923e-01, time/batch = 17.3424s	
10570/33250 (epoch 15.895), train_loss = 0.97003145, grad/param norm = 1.4564e-01, time/batch = 17.2664s	
10571/33250 (epoch 15.896), train_loss = 1.11468451, grad/param norm = 1.6960e-01, time/batch = 17.4326s	
10572/33250 (epoch 15.898), train_loss = 1.00643807, grad/param norm = 1.5232e-01, time/batch = 16.6013s	
10573/33250 (epoch 15.899), train_loss = 0.92003580, grad/param norm = 1.3517e-01, time/batch = 19.4406s	
10574/33250 (epoch 15.901), train_loss = 0.87894694, grad/param norm = 1.3334e-01, time/batch = 16.5241s	
10575/33250 (epoch 15.902), train_loss = 1.00275802, grad/param norm = 1.4514e-01, time/batch = 17.4573s	
10576/33250 (epoch 15.904), train_loss = 0.92404460, grad/param norm = 1.3330e-01, time/batch = 16.1092s	
10577/33250 (epoch 15.905), train_loss = 0.97061346, grad/param norm = 1.3603e-01, time/batch = 17.4398s	
10578/33250 (epoch 15.907), train_loss = 0.92621023, grad/param norm = 1.5008e-01, time/batch = 15.9226s	
10579/33250 (epoch 15.908), train_loss = 1.01171558, grad/param norm = 1.3383e-01, time/batch = 15.4080s	
10580/33250 (epoch 15.910), train_loss = 1.06618251, grad/param norm = 1.5379e-01, time/batch = 17.2535s	
10581/33250 (epoch 15.911), train_loss = 0.88609868, grad/param norm = 1.3562e-01, time/batch = 16.7652s	
10582/33250 (epoch 15.913), train_loss = 0.93799876, grad/param norm = 1.3826e-01, time/batch = 16.7750s	
10583/33250 (epoch 15.914), train_loss = 0.84481957, grad/param norm = 1.3973e-01, time/batch = 17.4471s	
10584/33250 (epoch 15.916), train_loss = 0.94568944, grad/param norm = 1.2669e-01, time/batch = 17.2189s	
10585/33250 (epoch 15.917), train_loss = 0.95894554, grad/param norm = 1.2419e-01, time/batch = 17.3709s	
10586/33250 (epoch 15.919), train_loss = 0.91610623, grad/param norm = 1.5796e-01, time/batch = 16.2706s	
10587/33250 (epoch 15.920), train_loss = 0.99906471, grad/param norm = 1.4783e-01, time/batch = 15.3513s	
10588/33250 (epoch 15.922), train_loss = 1.05866001, grad/param norm = 1.7119e-01, time/batch = 17.0259s	
10589/33250 (epoch 15.923), train_loss = 1.00832583, grad/param norm = 1.6163e-01, time/batch = 16.2612s	
10590/33250 (epoch 15.925), train_loss = 0.96257769, grad/param norm = 1.4355e-01, time/batch = 15.6909s	
10591/33250 (epoch 15.926), train_loss = 0.96491975, grad/param norm = 1.3953e-01, time/batch = 16.3598s	
10592/33250 (epoch 15.928), train_loss = 0.97615291, grad/param norm = 1.5380e-01, time/batch = 17.1867s	
10593/33250 (epoch 15.929), train_loss = 0.80042686, grad/param norm = 1.1814e-01, time/batch = 17.2082s	
10594/33250 (epoch 15.931), train_loss = 1.08575902, grad/param norm = 1.5246e-01, time/batch = 18.7821s	
10595/33250 (epoch 15.932), train_loss = 1.02045152, grad/param norm = 1.6405e-01, time/batch = 16.2994s	
10596/33250 (epoch 15.934), train_loss = 0.93366073, grad/param norm = 1.3120e-01, time/batch = 15.8683s	
10597/33250 (epoch 15.935), train_loss = 0.92810802, grad/param norm = 1.5287e-01, time/batch = 15.5926s	
10598/33250 (epoch 15.937), train_loss = 1.00339638, grad/param norm = 1.6765e-01, time/batch = 18.3411s	
10599/33250 (epoch 15.938), train_loss = 1.02881668, grad/param norm = 1.6778e-01, time/batch = 15.9467s	
10600/33250 (epoch 15.940), train_loss = 0.98613987, grad/param norm = 1.5582e-01, time/batch = 15.3129s	
10601/33250 (epoch 15.941), train_loss = 1.05346576, grad/param norm = 1.6528e-01, time/batch = 16.2647s	
10602/33250 (epoch 15.943), train_loss = 1.14421637, grad/param norm = 1.5207e-01, time/batch = 19.0266s	
10603/33250 (epoch 15.944), train_loss = 0.92806521, grad/param norm = 1.3901e-01, time/batch = 16.5470s	
10604/33250 (epoch 15.946), train_loss = 1.12260564, grad/param norm = 1.4752e-01, time/batch = 17.2007s	
10605/33250 (epoch 15.947), train_loss = 0.92425989, grad/param norm = 1.4538e-01, time/batch = 18.1963s	
10606/33250 (epoch 15.949), train_loss = 1.11800144, grad/param norm = 1.6053e-01, time/batch = 16.1103s	
10607/33250 (epoch 15.950), train_loss = 1.05412157, grad/param norm = 1.5123e-01, time/batch = 16.6108s	
10608/33250 (epoch 15.952), train_loss = 0.98650992, grad/param norm = 1.7324e-01, time/batch = 15.3604s	
10609/33250 (epoch 15.953), train_loss = 1.09420459, grad/param norm = 1.6168e-01, time/batch = 17.9177s	
10610/33250 (epoch 15.955), train_loss = 1.11823314, grad/param norm = 1.6686e-01, time/batch = 16.3600s	
10611/33250 (epoch 15.956), train_loss = 1.05896811, grad/param norm = 1.7212e-01, time/batch = 16.0204s	
10612/33250 (epoch 15.958), train_loss = 0.92185166, grad/param norm = 1.6765e-01, time/batch = 17.6938s	
10613/33250 (epoch 15.959), train_loss = 0.94098853, grad/param norm = 1.4468e-01, time/batch = 19.1195s	
10614/33250 (epoch 15.961), train_loss = 1.21128951, grad/param norm = 1.4825e-01, time/batch = 17.7753s	
10615/33250 (epoch 15.962), train_loss = 1.02599230, grad/param norm = 1.4454e-01, time/batch = 17.8494s	
10616/33250 (epoch 15.964), train_loss = 1.19447646, grad/param norm = 1.7295e-01, time/batch = 15.6919s	
10617/33250 (epoch 15.965), train_loss = 1.08025054, grad/param norm = 1.6128e-01, time/batch = 15.0178s	
10618/33250 (epoch 15.967), train_loss = 1.02958163, grad/param norm = 1.5589e-01, time/batch = 15.1018s	
10619/33250 (epoch 15.968), train_loss = 1.19585493, grad/param norm = 1.4787e-01, time/batch = 15.8774s	
10620/33250 (epoch 15.970), train_loss = 1.30093259, grad/param norm = 2.4282e-01, time/batch = 15.8295s	
10621/33250 (epoch 15.971), train_loss = 1.17204764, grad/param norm = 1.8494e-01, time/batch = 16.7689s	
10622/33250 (epoch 15.973), train_loss = 0.98008197, grad/param norm = 1.4500e-01, time/batch = 15.6246s	
10623/33250 (epoch 15.974), train_loss = 1.09143540, grad/param norm = 1.5510e-01, time/batch = 16.4744s	
10624/33250 (epoch 15.976), train_loss = 0.98592319, grad/param norm = 1.6602e-01, time/batch = 16.3585s	
10625/33250 (epoch 15.977), train_loss = 0.95609211, grad/param norm = 1.4747e-01, time/batch = 17.1218s	
10626/33250 (epoch 15.979), train_loss = 1.04631729, grad/param norm = 1.6506e-01, time/batch = 14.8928s	
10627/33250 (epoch 15.980), train_loss = 1.03040152, grad/param norm = 1.4182e-01, time/batch = 16.1077s	
10628/33250 (epoch 15.982), train_loss = 0.89206495, grad/param norm = 1.3078e-01, time/batch = 17.1962s	
10629/33250 (epoch 15.983), train_loss = 1.05537940, grad/param norm = 1.6628e-01, time/batch = 15.2786s	
10630/33250 (epoch 15.985), train_loss = 0.96082657, grad/param norm = 1.4847e-01, time/batch = 16.1225s	
10631/33250 (epoch 15.986), train_loss = 1.09943488, grad/param norm = 1.5099e-01, time/batch = 15.5253s	
10632/33250 (epoch 15.988), train_loss = 1.13732678, grad/param norm = 1.6818e-01, time/batch = 17.4219s	
10633/33250 (epoch 15.989), train_loss = 1.10402935, grad/param norm = 1.6221e-01, time/batch = 15.7705s	
10634/33250 (epoch 15.991), train_loss = 1.06052101, grad/param norm = 1.5905e-01, time/batch = 18.4499s	
10635/33250 (epoch 15.992), train_loss = 0.99587123, grad/param norm = 1.5775e-01, time/batch = 18.2855s	
10636/33250 (epoch 15.994), train_loss = 0.94986295, grad/param norm = 1.5375e-01, time/batch = 16.0934s	
10637/33250 (epoch 15.995), train_loss = 1.00027461, grad/param norm = 1.7090e-01, time/batch = 16.1847s	
10638/33250 (epoch 15.997), train_loss = 0.76274505, grad/param norm = 1.4175e-01, time/batch = 16.4490s	
10639/33250 (epoch 15.998), train_loss = 1.02796445, grad/param norm = 1.3634e-01, time/batch = 15.4417s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
10640/33250 (epoch 16.000), train_loss = 1.02997512, grad/param norm = 1.4945e-01, time/batch = 15.6806s	
10641/33250 (epoch 16.002), train_loss = 1.19535429, grad/param norm = 1.6365e-01, time/batch = 17.7456s	
10642/33250 (epoch 16.003), train_loss = 1.11242199, grad/param norm = 1.7435e-01, time/batch = 16.0173s	
10643/33250 (epoch 16.005), train_loss = 0.82443690, grad/param norm = 1.2825e-01, time/batch = 18.2773s	
10644/33250 (epoch 16.006), train_loss = 0.88090923, grad/param norm = 1.4608e-01, time/batch = 15.9288s	
10645/33250 (epoch 16.008), train_loss = 1.17079748, grad/param norm = 1.5069e-01, time/batch = 18.8454s	
10646/33250 (epoch 16.009), train_loss = 1.16817042, grad/param norm = 1.6292e-01, time/batch = 17.1136s	
10647/33250 (epoch 16.011), train_loss = 0.91043990, grad/param norm = 1.4343e-01, time/batch = 16.1844s	
10648/33250 (epoch 16.012), train_loss = 1.04634208, grad/param norm = 2.1110e-01, time/batch = 17.4364s	
10649/33250 (epoch 16.014), train_loss = 1.14754842, grad/param norm = 1.7248e-01, time/batch = 16.2715s	
10650/33250 (epoch 16.015), train_loss = 1.00748994, grad/param norm = 1.3993e-01, time/batch = 15.3744s	
10651/33250 (epoch 16.017), train_loss = 1.04056728, grad/param norm = 1.7330e-01, time/batch = 15.5064s	
10652/33250 (epoch 16.018), train_loss = 0.84905249, grad/param norm = 1.4898e-01, time/batch = 17.1677s	
10653/33250 (epoch 16.020), train_loss = 1.01279047, grad/param norm = 1.4534e-01, time/batch = 16.7759s	
10654/33250 (epoch 16.021), train_loss = 1.02171333, grad/param norm = 1.4947e-01, time/batch = 16.0905s	
10655/33250 (epoch 16.023), train_loss = 0.84328783, grad/param norm = 1.5232e-01, time/batch = 18.1244s	
10656/33250 (epoch 16.024), train_loss = 1.11007390, grad/param norm = 1.5893e-01, time/batch = 16.9547s	
10657/33250 (epoch 16.026), train_loss = 1.01189054, grad/param norm = 1.4137e-01, time/batch = 15.7500s	
10658/33250 (epoch 16.027), train_loss = 0.99061428, grad/param norm = 1.3727e-01, time/batch = 15.3434s	
10659/33250 (epoch 16.029), train_loss = 1.02764856, grad/param norm = 1.4471e-01, time/batch = 16.1721s	
10660/33250 (epoch 16.030), train_loss = 1.01150143, grad/param norm = 1.6042e-01, time/batch = 16.5985s	
10661/33250 (epoch 16.032), train_loss = 1.22965450, grad/param norm = 1.7239e-01, time/batch = 17.1812s	
10662/33250 (epoch 16.033), train_loss = 0.96136600, grad/param norm = 1.5615e-01, time/batch = 16.5209s	
10663/33250 (epoch 16.035), train_loss = 0.96397303, grad/param norm = 1.5135e-01, time/batch = 17.4366s	
10664/33250 (epoch 16.036), train_loss = 1.08260688, grad/param norm = 1.6389e-01, time/batch = 16.9476s	
10665/33250 (epoch 16.038), train_loss = 1.00080145, grad/param norm = 1.4135e-01, time/batch = 16.4579s	
10666/33250 (epoch 16.039), train_loss = 0.91204344, grad/param norm = 1.3954e-01, time/batch = 18.5224s	
10667/33250 (epoch 16.041), train_loss = 1.05406175, grad/param norm = 1.6773e-01, time/batch = 16.9316s	
10668/33250 (epoch 16.042), train_loss = 0.85153395, grad/param norm = 1.3267e-01, time/batch = 15.5392s	
10669/33250 (epoch 16.044), train_loss = 1.16704084, grad/param norm = 1.7105e-01, time/batch = 29.0507s	
10670/33250 (epoch 16.045), train_loss = 1.11823387, grad/param norm = 1.4540e-01, time/batch = 15.7812s	
10671/33250 (epoch 16.047), train_loss = 1.06897216, grad/param norm = 1.5705e-01, time/batch = 15.4261s	
10672/33250 (epoch 16.048), train_loss = 1.17042981, grad/param norm = 3.1336e-01, time/batch = 17.0321s	
10673/33250 (epoch 16.050), train_loss = 1.03698296, grad/param norm = 1.5231e-01, time/batch = 18.5430s	
10674/33250 (epoch 16.051), train_loss = 1.02297656, grad/param norm = 1.5576e-01, time/batch = 18.3784s	
10675/33250 (epoch 16.053), train_loss = 1.05389648, grad/param norm = 1.7024e-01, time/batch = 16.3601s	
10676/33250 (epoch 16.054), train_loss = 0.85765953, grad/param norm = 1.3745e-01, time/batch = 15.7049s	
10677/33250 (epoch 16.056), train_loss = 0.91924269, grad/param norm = 1.4881e-01, time/batch = 17.3632s	
10678/33250 (epoch 16.057), train_loss = 1.08386109, grad/param norm = 1.4039e-01, time/batch = 14.8059s	
10679/33250 (epoch 16.059), train_loss = 1.00257707, grad/param norm = 1.5120e-01, time/batch = 15.4986s	
10680/33250 (epoch 16.060), train_loss = 1.06269227, grad/param norm = 1.6192e-01, time/batch = 15.7581s	
10681/33250 (epoch 16.062), train_loss = 1.14902615, grad/param norm = 1.5962e-01, time/batch = 15.1875s	
10682/33250 (epoch 16.063), train_loss = 1.15247571, grad/param norm = 1.5906e-01, time/batch = 15.4410s	
10683/33250 (epoch 16.065), train_loss = 1.00366146, grad/param norm = 1.4609e-01, time/batch = 18.1157s	
10684/33250 (epoch 16.066), train_loss = 1.07239241, grad/param norm = 1.5327e-01, time/batch = 16.9535s	
10685/33250 (epoch 16.068), train_loss = 0.97081196, grad/param norm = 1.4897e-01, time/batch = 17.8782s	
10686/33250 (epoch 16.069), train_loss = 1.03309219, grad/param norm = 1.5503e-01, time/batch = 15.5109s	
10687/33250 (epoch 16.071), train_loss = 0.91829134, grad/param norm = 1.3697e-01, time/batch = 15.1926s	
10688/33250 (epoch 16.072), train_loss = 0.90763678, grad/param norm = 1.2687e-01, time/batch = 16.0375s	
10689/33250 (epoch 16.074), train_loss = 1.08054003, grad/param norm = 1.4841e-01, time/batch = 15.2059s	
10690/33250 (epoch 16.075), train_loss = 0.95779485, grad/param norm = 1.3600e-01, time/batch = 15.7698s	
10691/33250 (epoch 16.077), train_loss = 1.00175242, grad/param norm = 1.4943e-01, time/batch = 17.6776s	
10692/33250 (epoch 16.078), train_loss = 1.03239034, grad/param norm = 1.4534e-01, time/batch = 17.0235s	
10693/33250 (epoch 16.080), train_loss = 1.03463912, grad/param norm = 1.8258e-01, time/batch = 16.6947s	
10694/33250 (epoch 16.081), train_loss = 1.04934932, grad/param norm = 1.5801e-01, time/batch = 18.2040s	
10695/33250 (epoch 16.083), train_loss = 1.11140990, grad/param norm = 1.4401e-01, time/batch = 18.0533s	
10696/33250 (epoch 16.084), train_loss = 1.03148276, grad/param norm = 1.5852e-01, time/batch = 18.4336s	
10697/33250 (epoch 16.086), train_loss = 0.96635228, grad/param norm = 1.3046e-01, time/batch = 15.7814s	
10698/33250 (epoch 16.087), train_loss = 0.89879591, grad/param norm = 1.3281e-01, time/batch = 15.7478s	
10699/33250 (epoch 16.089), train_loss = 1.06060743, grad/param norm = 1.4786e-01, time/batch = 17.0940s	
10700/33250 (epoch 16.090), train_loss = 1.02577571, grad/param norm = 1.4202e-01, time/batch = 16.5129s	
10701/33250 (epoch 16.092), train_loss = 0.94557351, grad/param norm = 1.3437e-01, time/batch = 17.4289s	
10702/33250 (epoch 16.093), train_loss = 1.04505812, grad/param norm = 1.5465e-01, time/batch = 15.8750s	
10703/33250 (epoch 16.095), train_loss = 0.95104141, grad/param norm = 1.3662e-01, time/batch = 19.1959s	
10704/33250 (epoch 16.096), train_loss = 0.84282076, grad/param norm = 1.4865e-01, time/batch = 15.6761s	
10705/33250 (epoch 16.098), train_loss = 0.88832713, grad/param norm = 1.4487e-01, time/batch = 19.0273s	
10706/33250 (epoch 16.099), train_loss = 0.75658005, grad/param norm = 1.2884e-01, time/batch = 16.5475s	
10707/33250 (epoch 16.101), train_loss = 0.98685094, grad/param norm = 1.4720e-01, time/batch = 15.8504s	
10708/33250 (epoch 16.102), train_loss = 0.89825793, grad/param norm = 1.4932e-01, time/batch = 17.2725s	
10709/33250 (epoch 16.104), train_loss = 0.79408795, grad/param norm = 1.3438e-01, time/batch = 15.3465s	
10710/33250 (epoch 16.105), train_loss = 0.94330431, grad/param norm = 1.3860e-01, time/batch = 18.6665s	
10711/33250 (epoch 16.107), train_loss = 0.83224457, grad/param norm = 1.3413e-01, time/batch = 15.4437s	
10712/33250 (epoch 16.108), train_loss = 0.98127115, grad/param norm = 1.5283e-01, time/batch = 17.0096s	
10713/33250 (epoch 16.110), train_loss = 0.81649487, grad/param norm = 1.3951e-01, time/batch = 16.2631s	
10714/33250 (epoch 16.111), train_loss = 0.96758677, grad/param norm = 1.5543e-01, time/batch = 18.2701s	
10715/33250 (epoch 16.113), train_loss = 0.97460386, grad/param norm = 1.6755e-01, time/batch = 17.1256s	
10716/33250 (epoch 16.114), train_loss = 0.90100560, grad/param norm = 1.5293e-01, time/batch = 15.7771s	
10717/33250 (epoch 16.116), train_loss = 0.99684552, grad/param norm = 1.5844e-01, time/batch = 17.5161s	
10718/33250 (epoch 16.117), train_loss = 0.96652348, grad/param norm = 1.4253e-01, time/batch = 15.5285s	
10719/33250 (epoch 16.119), train_loss = 0.95316925, grad/param norm = 1.5958e-01, time/batch = 17.4338s	
10720/33250 (epoch 16.120), train_loss = 0.77033702, grad/param norm = 1.3072e-01, time/batch = 16.5261s	
10721/33250 (epoch 16.122), train_loss = 1.11242822, grad/param norm = 1.4999e-01, time/batch = 16.1929s	
10722/33250 (epoch 16.123), train_loss = 1.01844339, grad/param norm = 1.5323e-01, time/batch = 15.9924s	
10723/33250 (epoch 16.125), train_loss = 0.83183234, grad/param norm = 1.5176e-01, time/batch = 19.1062s	
10724/33250 (epoch 16.126), train_loss = 0.98835362, grad/param norm = 1.4973e-01, time/batch = 15.4590s	
10725/33250 (epoch 16.128), train_loss = 0.91275065, grad/param norm = 1.3352e-01, time/batch = 17.2728s	
10726/33250 (epoch 16.129), train_loss = 0.98207089, grad/param norm = 1.4938e-01, time/batch = 18.4255s	
10727/33250 (epoch 16.131), train_loss = 0.96596042, grad/param norm = 1.4280e-01, time/batch = 16.4306s	
10728/33250 (epoch 16.132), train_loss = 0.97256812, grad/param norm = 1.5407e-01, time/batch = 16.7616s	
10729/33250 (epoch 16.134), train_loss = 1.00539429, grad/param norm = 1.4973e-01, time/batch = 15.5207s	
10730/33250 (epoch 16.135), train_loss = 1.02572158, grad/param norm = 1.5253e-01, time/batch = 17.7602s	
10731/33250 (epoch 16.137), train_loss = 0.89422225, grad/param norm = 1.4691e-01, time/batch = 15.8579s	
10732/33250 (epoch 16.138), train_loss = 0.92666366, grad/param norm = 1.2800e-01, time/batch = 16.9369s	
10733/33250 (epoch 16.140), train_loss = 0.76784707, grad/param norm = 1.3528e-01, time/batch = 16.6386s	
10734/33250 (epoch 16.141), train_loss = 1.18331089, grad/param norm = 2.3113e-01, time/batch = 18.6690s	
10735/33250 (epoch 16.143), train_loss = 0.78131084, grad/param norm = 1.5499e-01, time/batch = 16.8004s	
10736/33250 (epoch 16.144), train_loss = 0.95560071, grad/param norm = 1.4787e-01, time/batch = 15.0941s	
10737/33250 (epoch 16.146), train_loss = 0.93934729, grad/param norm = 1.3741e-01, time/batch = 16.1876s	
10738/33250 (epoch 16.147), train_loss = 0.91906521, grad/param norm = 1.4505e-01, time/batch = 17.5163s	
10739/33250 (epoch 16.149), train_loss = 0.94134895, grad/param norm = 1.4991e-01, time/batch = 16.1963s	
10740/33250 (epoch 16.150), train_loss = 0.88367579, grad/param norm = 1.3778e-01, time/batch = 15.2562s	
10741/33250 (epoch 16.152), train_loss = 0.84083932, grad/param norm = 1.3120e-01, time/batch = 15.3414s	
10742/33250 (epoch 16.153), train_loss = 1.14007310, grad/param norm = 1.5709e-01, time/batch = 17.1914s	
10743/33250 (epoch 16.155), train_loss = 0.98054010, grad/param norm = 1.6613e-01, time/batch = 16.3688s	
10744/33250 (epoch 16.156), train_loss = 1.17808690, grad/param norm = 1.4952e-01, time/batch = 17.3701s	
10745/33250 (epoch 16.158), train_loss = 1.17910421, grad/param norm = 1.6270e-01, time/batch = 18.2904s	
10746/33250 (epoch 16.159), train_loss = 0.97692858, grad/param norm = 1.4820e-01, time/batch = 16.6920s	
10747/33250 (epoch 16.161), train_loss = 1.03633210, grad/param norm = 1.5827e-01, time/batch = 16.3532s	
10748/33250 (epoch 16.162), train_loss = 0.86952517, grad/param norm = 1.2845e-01, time/batch = 17.2737s	
10749/33250 (epoch 16.164), train_loss = 0.97288218, grad/param norm = 1.5374e-01, time/batch = 15.9376s	
10750/33250 (epoch 16.165), train_loss = 1.05395092, grad/param norm = 1.5648e-01, time/batch = 16.0828s	
10751/33250 (epoch 16.167), train_loss = 1.13663685, grad/param norm = 1.5992e-01, time/batch = 17.2717s	
10752/33250 (epoch 16.168), train_loss = 0.84218990, grad/param norm = 1.2808e-01, time/batch = 17.7062s	
10753/33250 (epoch 16.170), train_loss = 0.95554148, grad/param norm = 1.5252e-01, time/batch = 17.7160s	
10754/33250 (epoch 16.171), train_loss = 0.95956906, grad/param norm = 1.4159e-01, time/batch = 16.1248s	
10755/33250 (epoch 16.173), train_loss = 0.93116252, grad/param norm = 1.4164e-01, time/batch = 17.8741s	
10756/33250 (epoch 16.174), train_loss = 0.98176760, grad/param norm = 1.5141e-01, time/batch = 17.9319s	
10757/33250 (epoch 16.176), train_loss = 0.97411009, grad/param norm = 1.5052e-01, time/batch = 15.8486s	
10758/33250 (epoch 16.177), train_loss = 0.94816015, grad/param norm = 1.6604e-01, time/batch = 17.4143s	
10759/33250 (epoch 16.179), train_loss = 0.90735304, grad/param norm = 1.4074e-01, time/batch = 17.2699s	
10760/33250 (epoch 16.180), train_loss = 0.82670536, grad/param norm = 1.3545e-01, time/batch = 15.3479s	
10761/33250 (epoch 16.182), train_loss = 0.92597306, grad/param norm = 1.7292e-01, time/batch = 16.5888s	
10762/33250 (epoch 16.183), train_loss = 1.12201278, grad/param norm = 1.6458e-01, time/batch = 17.2039s	
10763/33250 (epoch 16.185), train_loss = 1.05899368, grad/param norm = 1.5889e-01, time/batch = 17.5401s	
10764/33250 (epoch 16.186), train_loss = 1.00308331, grad/param norm = 1.5168e-01, time/batch = 16.1598s	
10765/33250 (epoch 16.188), train_loss = 1.10738938, grad/param norm = 1.6819e-01, time/batch = 17.5328s	
10766/33250 (epoch 16.189), train_loss = 0.80589441, grad/param norm = 1.5392e-01, time/batch = 17.0204s	
10767/33250 (epoch 16.191), train_loss = 0.90254273, grad/param norm = 1.4818e-01, time/batch = 18.0939s	
10768/33250 (epoch 16.192), train_loss = 0.92685717, grad/param norm = 1.3993e-01, time/batch = 15.5210s	
10769/33250 (epoch 16.194), train_loss = 0.92547971, grad/param norm = 1.5261e-01, time/batch = 17.6742s	
10770/33250 (epoch 16.195), train_loss = 1.16309452, grad/param norm = 1.6175e-01, time/batch = 16.0240s	
10771/33250 (epoch 16.197), train_loss = 0.94126170, grad/param norm = 1.5058e-01, time/batch = 15.8561s	
10772/33250 (epoch 16.198), train_loss = 1.11057226, grad/param norm = 1.5189e-01, time/batch = 16.8735s	
10773/33250 (epoch 16.200), train_loss = 0.99447071, grad/param norm = 1.4781e-01, time/batch = 18.8829s	
10774/33250 (epoch 16.202), train_loss = 0.91993935, grad/param norm = 1.3446e-01, time/batch = 17.6948s	
10775/33250 (epoch 16.203), train_loss = 0.91089640, grad/param norm = 1.4501e-01, time/batch = 15.7311s	
10776/33250 (epoch 16.205), train_loss = 1.01719028, grad/param norm = 1.4676e-01, time/batch = 17.9236s	
10777/33250 (epoch 16.206), train_loss = 1.05957062, grad/param norm = 1.4712e-01, time/batch = 16.4412s	
10778/33250 (epoch 16.208), train_loss = 1.13641003, grad/param norm = 1.7140e-01, time/batch = 15.3135s	
10779/33250 (epoch 16.209), train_loss = 0.93414192, grad/param norm = 1.5228e-01, time/batch = 14.8132s	
10780/33250 (epoch 16.211), train_loss = 1.06641689, grad/param norm = 1.5643e-01, time/batch = 14.5700s	
10781/33250 (epoch 16.212), train_loss = 1.22460445, grad/param norm = 1.5252e-01, time/batch = 15.3098s	
10782/33250 (epoch 16.214), train_loss = 0.97576152, grad/param norm = 1.3287e-01, time/batch = 15.0662s	
10783/33250 (epoch 16.215), train_loss = 1.19879387, grad/param norm = 2.0321e-01, time/batch = 14.8465s	
10784/33250 (epoch 16.217), train_loss = 1.14395573, grad/param norm = 1.7074e-01, time/batch = 14.4291s	
10785/33250 (epoch 16.218), train_loss = 1.07784559, grad/param norm = 1.4321e-01, time/batch = 14.8295s	
10786/33250 (epoch 16.220), train_loss = 1.04201122, grad/param norm = 1.5357e-01, time/batch = 14.9274s	
10787/33250 (epoch 16.221), train_loss = 1.19374928, grad/param norm = 1.7651e-01, time/batch = 15.3014s	
10788/33250 (epoch 16.223), train_loss = 0.99477793, grad/param norm = 1.4941e-01, time/batch = 14.7353s	
10789/33250 (epoch 16.224), train_loss = 1.04204093, grad/param norm = 1.4925e-01, time/batch = 14.9096s	
10790/33250 (epoch 16.226), train_loss = 1.16782867, grad/param norm = 1.5430e-01, time/batch = 15.1449s	
10791/33250 (epoch 16.227), train_loss = 1.03367300, grad/param norm = 1.5267e-01, time/batch = 16.5807s	
10792/33250 (epoch 16.229), train_loss = 1.04607576, grad/param norm = 1.5232e-01, time/batch = 16.3630s	
10793/33250 (epoch 16.230), train_loss = 0.97237028, grad/param norm = 1.4068e-01, time/batch = 16.7835s	
10794/33250 (epoch 16.232), train_loss = 0.94797167, grad/param norm = 1.2498e-01, time/batch = 15.8466s	
10795/33250 (epoch 16.233), train_loss = 0.94076152, grad/param norm = 1.3433e-01, time/batch = 15.8172s	
10796/33250 (epoch 16.235), train_loss = 1.15485941, grad/param norm = 1.4038e-01, time/batch = 16.2252s	
10797/33250 (epoch 16.236), train_loss = 0.93352268, grad/param norm = 1.4899e-01, time/batch = 16.0324s	
10798/33250 (epoch 16.238), train_loss = 1.09811120, grad/param norm = 1.6436e-01, time/batch = 15.2766s	
10799/33250 (epoch 16.239), train_loss = 1.15382301, grad/param norm = 1.6971e-01, time/batch = 15.6814s	
10800/33250 (epoch 16.241), train_loss = 1.10905774, grad/param norm = 1.7900e-01, time/batch = 15.9533s	
10801/33250 (epoch 16.242), train_loss = 1.07718871, grad/param norm = 1.5463e-01, time/batch = 15.9385s	
10802/33250 (epoch 16.244), train_loss = 1.12163642, grad/param norm = 1.8898e-01, time/batch = 15.0517s	
10803/33250 (epoch 16.245), train_loss = 1.00587634, grad/param norm = 1.4132e-01, time/batch = 15.7579s	
10804/33250 (epoch 16.247), train_loss = 1.03142374, grad/param norm = 1.4487e-01, time/batch = 16.9361s	
10805/33250 (epoch 16.248), train_loss = 1.23999127, grad/param norm = 2.0319e-01, time/batch = 17.5223s	
10806/33250 (epoch 16.250), train_loss = 1.08369408, grad/param norm = 1.4830e-01, time/batch = 17.6292s	
10807/33250 (epoch 16.251), train_loss = 1.01988798, grad/param norm = 1.4898e-01, time/batch = 15.5536s	
10808/33250 (epoch 16.253), train_loss = 0.93071872, grad/param norm = 1.2684e-01, time/batch = 17.4410s	
10809/33250 (epoch 16.254), train_loss = 0.95934975, grad/param norm = 1.6199e-01, time/batch = 15.4245s	
10810/33250 (epoch 16.256), train_loss = 1.01544573, grad/param norm = 1.4048e-01, time/batch = 16.3611s	
10811/33250 (epoch 16.257), train_loss = 1.16055400, grad/param norm = 1.5575e-01, time/batch = 15.7783s	
10812/33250 (epoch 16.259), train_loss = 1.09622709, grad/param norm = 1.4393e-01, time/batch = 16.5127s	
10813/33250 (epoch 16.260), train_loss = 0.90407767, grad/param norm = 1.4638e-01, time/batch = 16.0904s	
10814/33250 (epoch 16.262), train_loss = 1.03936011, grad/param norm = 1.4191e-01, time/batch = 16.9523s	
10815/33250 (epoch 16.263), train_loss = 0.92013051, grad/param norm = 1.3225e-01, time/batch = 16.3713s	
10816/33250 (epoch 16.265), train_loss = 1.08194440, grad/param norm = 1.5835e-01, time/batch = 16.1143s	
10817/33250 (epoch 16.266), train_loss = 1.01204317, grad/param norm = 1.6218e-01, time/batch = 18.5149s	
10818/33250 (epoch 16.268), train_loss = 0.93302439, grad/param norm = 1.4192e-01, time/batch = 16.9351s	
10819/33250 (epoch 16.269), train_loss = 0.81992229, grad/param norm = 1.4842e-01, time/batch = 16.6706s	
10820/33250 (epoch 16.271), train_loss = 0.98074290, grad/param norm = 1.3815e-01, time/batch = 15.4343s	
10821/33250 (epoch 16.272), train_loss = 0.87033000, grad/param norm = 1.2755e-01, time/batch = 15.1893s	
10822/33250 (epoch 16.274), train_loss = 0.77513420, grad/param norm = 1.3692e-01, time/batch = 16.4405s	
10823/33250 (epoch 16.275), train_loss = 0.92334852, grad/param norm = 1.3357e-01, time/batch = 16.2550s	
10824/33250 (epoch 16.277), train_loss = 0.79891914, grad/param norm = 1.2948e-01, time/batch = 18.1903s	
10825/33250 (epoch 16.278), train_loss = 0.93704548, grad/param norm = 1.4765e-01, time/batch = 18.3655s	
10826/33250 (epoch 16.280), train_loss = 0.87560389, grad/param norm = 1.3086e-01, time/batch = 17.2405s	
10827/33250 (epoch 16.281), train_loss = 1.02604682, grad/param norm = 1.7069e-01, time/batch = 16.1975s	
10828/33250 (epoch 16.283), train_loss = 1.04875219, grad/param norm = 2.0964e-01, time/batch = 17.2698s	
10829/33250 (epoch 16.284), train_loss = 0.91076427, grad/param norm = 1.5480e-01, time/batch = 17.3513s	
10830/33250 (epoch 16.286), train_loss = 1.07520658, grad/param norm = 1.6066e-01, time/batch = 16.5004s	
10831/33250 (epoch 16.287), train_loss = 0.86379212, grad/param norm = 1.3282e-01, time/batch = 15.5948s	
10832/33250 (epoch 16.289), train_loss = 0.83262572, grad/param norm = 1.5025e-01, time/batch = 16.4275s	
10833/33250 (epoch 16.290), train_loss = 0.99156017, grad/param norm = 1.2994e-01, time/batch = 15.0345s	
10834/33250 (epoch 16.292), train_loss = 1.03574294, grad/param norm = 1.5627e-01, time/batch = 16.3697s	
10835/33250 (epoch 16.293), train_loss = 1.11250619, grad/param norm = 1.7193e-01, time/batch = 18.7829s	
10836/33250 (epoch 16.295), train_loss = 1.05283010, grad/param norm = 1.5367e-01, time/batch = 15.9324s	
10837/33250 (epoch 16.296), train_loss = 1.03640690, grad/param norm = 1.5560e-01, time/batch = 18.4341s	
10838/33250 (epoch 16.298), train_loss = 0.84748252, grad/param norm = 1.3194e-01, time/batch = 17.4276s	
10839/33250 (epoch 16.299), train_loss = 0.78614068, grad/param norm = 1.3093e-01, time/batch = 16.6995s	
10840/33250 (epoch 16.301), train_loss = 1.03146564, grad/param norm = 1.4551e-01, time/batch = 15.0441s	
10841/33250 (epoch 16.302), train_loss = 1.04258614, grad/param norm = 1.5745e-01, time/batch = 16.5955s	
10842/33250 (epoch 16.304), train_loss = 0.90339585, grad/param norm = 1.3811e-01, time/batch = 16.2023s	
10843/33250 (epoch 16.305), train_loss = 0.97892754, grad/param norm = 1.4421e-01, time/batch = 16.2714s	
10844/33250 (epoch 16.307), train_loss = 1.07320919, grad/param norm = 1.6132e-01, time/batch = 17.9545s	
10845/33250 (epoch 16.308), train_loss = 1.21889227, grad/param norm = 1.7132e-01, time/batch = 17.3603s	
10846/33250 (epoch 16.310), train_loss = 0.99407888, grad/param norm = 1.5388e-01, time/batch = 17.7050s	
10847/33250 (epoch 16.311), train_loss = 1.12624861, grad/param norm = 1.5760e-01, time/batch = 17.0229s	
10848/33250 (epoch 16.313), train_loss = 0.84896787, grad/param norm = 1.4140e-01, time/batch = 16.5088s	
10849/33250 (epoch 16.314), train_loss = 0.99500256, grad/param norm = 1.4929e-01, time/batch = 16.9338s	
10850/33250 (epoch 16.316), train_loss = 1.17075129, grad/param norm = 1.6092e-01, time/batch = 16.5227s	
10851/33250 (epoch 16.317), train_loss = 0.89244527, grad/param norm = 1.3045e-01, time/batch = 16.7561s	
10852/33250 (epoch 16.319), train_loss = 1.08573794, grad/param norm = 1.8011e-01, time/batch = 15.5841s	
10853/33250 (epoch 16.320), train_loss = 1.12036502, grad/param norm = 1.9071e-01, time/batch = 18.3571s	
10854/33250 (epoch 16.322), train_loss = 1.18170758, grad/param norm = 1.8039e-01, time/batch = 16.7731s	
10855/33250 (epoch 16.323), train_loss = 1.23254594, grad/param norm = 1.8219e-01, time/batch = 16.7879s	
10856/33250 (epoch 16.325), train_loss = 1.01767413, grad/param norm = 1.6902e-01, time/batch = 17.5085s	
10857/33250 (epoch 16.326), train_loss = 1.17746180, grad/param norm = 1.6541e-01, time/batch = 16.6961s	
10858/33250 (epoch 16.328), train_loss = 0.94735098, grad/param norm = 1.2868e-01, time/batch = 17.6893s	
10859/33250 (epoch 16.329), train_loss = 1.00856553, grad/param norm = 1.7059e-01, time/batch = 15.3545s	
10860/33250 (epoch 16.331), train_loss = 0.99807040, grad/param norm = 1.6674e-01, time/batch = 16.1884s	
10861/33250 (epoch 16.332), train_loss = 0.96644767, grad/param norm = 1.4130e-01, time/batch = 17.9061s	
10862/33250 (epoch 16.334), train_loss = 1.15020925, grad/param norm = 1.4107e-01, time/batch = 16.1065s	
10863/33250 (epoch 16.335), train_loss = 0.74595866, grad/param norm = 1.3420e-01, time/batch = 17.2812s	
10864/33250 (epoch 16.337), train_loss = 1.04037808, grad/param norm = 1.4040e-01, time/batch = 19.5367s	
10865/33250 (epoch 16.338), train_loss = 1.13191179, grad/param norm = 1.7116e-01, time/batch = 18.6215s	
10866/33250 (epoch 16.340), train_loss = 1.00698599, grad/param norm = 1.5044e-01, time/batch = 17.7687s	
10867/33250 (epoch 16.341), train_loss = 0.93761321, grad/param norm = 1.5133e-01, time/batch = 16.0112s	
10868/33250 (epoch 16.343), train_loss = 0.96146800, grad/param norm = 1.5196e-01, time/batch = 16.5095s	
10869/33250 (epoch 16.344), train_loss = 0.98765735, grad/param norm = 1.3825e-01, time/batch = 15.5648s	
10870/33250 (epoch 16.346), train_loss = 0.85671419, grad/param norm = 1.2401e-01, time/batch = 16.3494s	
10871/33250 (epoch 16.347), train_loss = 1.27617631, grad/param norm = 1.7082e-01, time/batch = 17.5201s	
10872/33250 (epoch 16.349), train_loss = 0.93573457, grad/param norm = 1.3950e-01, time/batch = 17.1121s	
10873/33250 (epoch 16.350), train_loss = 0.96695653, grad/param norm = 1.4830e-01, time/batch = 17.6784s	
10874/33250 (epoch 16.352), train_loss = 0.85888781, grad/param norm = 1.4239e-01, time/batch = 18.2110s	
10875/33250 (epoch 16.353), train_loss = 0.96520713, grad/param norm = 1.3740e-01, time/batch = 16.5405s	
10876/33250 (epoch 16.355), train_loss = 0.96527179, grad/param norm = 1.5469e-01, time/batch = 17.1221s	
10877/33250 (epoch 16.356), train_loss = 0.90463824, grad/param norm = 1.5415e-01, time/batch = 15.5877s	
10878/33250 (epoch 16.358), train_loss = 0.94550159, grad/param norm = 1.3856e-01, time/batch = 17.1083s	
10879/33250 (epoch 16.359), train_loss = 0.95641709, grad/param norm = 1.4901e-01, time/batch = 17.3596s	
10880/33250 (epoch 16.361), train_loss = 1.16051673, grad/param norm = 1.6499e-01, time/batch = 16.0193s	
10881/33250 (epoch 16.362), train_loss = 1.02470441, grad/param norm = 1.6829e-01, time/batch = 16.3648s	
10882/33250 (epoch 16.364), train_loss = 1.08215803, grad/param norm = 1.7182e-01, time/batch = 15.5990s	
10883/33250 (epoch 16.365), train_loss = 0.99422809, grad/param norm = 1.3915e-01, time/batch = 16.9115s	
10884/33250 (epoch 16.367), train_loss = 0.99872713, grad/param norm = 1.3624e-01, time/batch = 30.6288s	
10885/33250 (epoch 16.368), train_loss = 0.98729127, grad/param norm = 1.5921e-01, time/batch = 16.6201s	
10886/33250 (epoch 16.370), train_loss = 0.87598075, grad/param norm = 1.3076e-01, time/batch = 15.5026s	
10887/33250 (epoch 16.371), train_loss = 1.14739229, grad/param norm = 1.5612e-01, time/batch = 18.0042s	
10888/33250 (epoch 16.373), train_loss = 0.96234749, grad/param norm = 1.3287e-01, time/batch = 17.2678s	
10889/33250 (epoch 16.374), train_loss = 1.08896106, grad/param norm = 2.2799e-01, time/batch = 17.5881s	
10890/33250 (epoch 16.376), train_loss = 0.95034268, grad/param norm = 1.3949e-01, time/batch = 16.5923s	
10891/33250 (epoch 16.377), train_loss = 0.89665722, grad/param norm = 1.7260e-01, time/batch = 17.0120s	
10892/33250 (epoch 16.379), train_loss = 0.91612501, grad/param norm = 1.4730e-01, time/batch = 15.6116s	
10893/33250 (epoch 16.380), train_loss = 1.04591726, grad/param norm = 1.8017e-01, time/batch = 16.6841s	
10894/33250 (epoch 16.382), train_loss = 1.09993184, grad/param norm = 1.5807e-01, time/batch = 17.1901s	
10895/33250 (epoch 16.383), train_loss = 0.90696762, grad/param norm = 1.4316e-01, time/batch = 19.1070s	
10896/33250 (epoch 16.385), train_loss = 0.84633011, grad/param norm = 1.5177e-01, time/batch = 17.8375s	
10897/33250 (epoch 16.386), train_loss = 0.87419281, grad/param norm = 1.5960e-01, time/batch = 15.5016s	
10898/33250 (epoch 16.388), train_loss = 0.92102781, grad/param norm = 1.5659e-01, time/batch = 18.4260s	
10899/33250 (epoch 16.389), train_loss = 0.95851965, grad/param norm = 1.7422e-01, time/batch = 17.1852s	
10900/33250 (epoch 16.391), train_loss = 0.99933603, grad/param norm = 1.4856e-01, time/batch = 16.5178s	
10901/33250 (epoch 16.392), train_loss = 1.10044894, grad/param norm = 1.6310e-01, time/batch = 16.0687s	
10902/33250 (epoch 16.394), train_loss = 1.13258643, grad/param norm = 1.6902e-01, time/batch = 16.5895s	
10903/33250 (epoch 16.395), train_loss = 1.06899108, grad/param norm = 1.3411e-01, time/batch = 15.9541s	
10904/33250 (epoch 16.397), train_loss = 1.11032698, grad/param norm = 1.6253e-01, time/batch = 16.9386s	
10905/33250 (epoch 16.398), train_loss = 0.94176418, grad/param norm = 1.4631e-01, time/batch = 18.8680s	
10906/33250 (epoch 16.400), train_loss = 0.90116515, grad/param norm = 1.4234e-01, time/batch = 17.1668s	
10907/33250 (epoch 16.402), train_loss = 0.84165686, grad/param norm = 1.4588e-01, time/batch = 16.5918s	
10908/33250 (epoch 16.403), train_loss = 0.93935335, grad/param norm = 1.9126e-01, time/batch = 16.4531s	
10909/33250 (epoch 16.405), train_loss = 0.92481326, grad/param norm = 1.4498e-01, time/batch = 15.5395s	
10910/33250 (epoch 16.406), train_loss = 1.00645529, grad/param norm = 1.4878e-01, time/batch = 17.5020s	
10911/33250 (epoch 16.408), train_loss = 1.14253849, grad/param norm = 1.6821e-01, time/batch = 15.6882s	
10912/33250 (epoch 16.409), train_loss = 1.07179362, grad/param norm = 1.8420e-01, time/batch = 17.2725s	
10913/33250 (epoch 16.411), train_loss = 0.72923721, grad/param norm = 1.2102e-01, time/batch = 16.6848s	
10914/33250 (epoch 16.412), train_loss = 0.85184480, grad/param norm = 1.4900e-01, time/batch = 16.6223s	
10915/33250 (epoch 16.414), train_loss = 1.01424179, grad/param norm = 1.4408e-01, time/batch = 18.5371s	
10916/33250 (epoch 16.415), train_loss = 1.10802283, grad/param norm = 1.5872e-01, time/batch = 18.3586s	
10917/33250 (epoch 16.417), train_loss = 1.07731416, grad/param norm = 1.6714e-01, time/batch = 18.2664s	
10918/33250 (epoch 16.418), train_loss = 1.23661328, grad/param norm = 1.8877e-01, time/batch = 15.4819s	
10919/33250 (epoch 16.420), train_loss = 1.11758789, grad/param norm = 1.6050e-01, time/batch = 16.1896s	
10920/33250 (epoch 16.421), train_loss = 0.93549498, grad/param norm = 1.6202e-01, time/batch = 16.1925s	
10921/33250 (epoch 16.423), train_loss = 1.06542908, grad/param norm = 1.6843e-01, time/batch = 16.0958s	
10922/33250 (epoch 16.424), train_loss = 1.20102050, grad/param norm = 2.1193e-01, time/batch = 16.6936s	
10923/33250 (epoch 16.426), train_loss = 0.92747234, grad/param norm = 1.4010e-01, time/batch = 17.6957s	
10924/33250 (epoch 16.427), train_loss = 0.92182749, grad/param norm = 1.4121e-01, time/batch = 18.1212s	
10925/33250 (epoch 16.429), train_loss = 1.06267518, grad/param norm = 1.6893e-01, time/batch = 16.8744s	
10926/33250 (epoch 16.430), train_loss = 0.92796881, grad/param norm = 1.7341e-01, time/batch = 16.3420s	
10927/33250 (epoch 16.432), train_loss = 1.02238481, grad/param norm = 1.4597e-01, time/batch = 17.8432s	
10928/33250 (epoch 16.433), train_loss = 0.93593830, grad/param norm = 1.4461e-01, time/batch = 15.2764s	
10929/33250 (epoch 16.435), train_loss = 1.05303708, grad/param norm = 1.5916e-01, time/batch = 16.9430s	
10930/33250 (epoch 16.436), train_loss = 0.93032545, grad/param norm = 1.4867e-01, time/batch = 16.4397s	
10931/33250 (epoch 16.438), train_loss = 1.05340695, grad/param norm = 1.3883e-01, time/batch = 17.6144s	
10932/33250 (epoch 16.439), train_loss = 1.02217526, grad/param norm = 1.3787e-01, time/batch = 15.6705s	
10933/33250 (epoch 16.441), train_loss = 0.98381142, grad/param norm = 1.3396e-01, time/batch = 17.2442s	
10934/33250 (epoch 16.442), train_loss = 0.90651126, grad/param norm = 1.5121e-01, time/batch = 17.8044s	
10935/33250 (epoch 16.444), train_loss = 0.90508017, grad/param norm = 1.3584e-01, time/batch = 17.6179s	
10936/33250 (epoch 16.445), train_loss = 1.00367056, grad/param norm = 1.4902e-01, time/batch = 17.4565s	
10937/33250 (epoch 16.447), train_loss = 1.02805499, grad/param norm = 1.5969e-01, time/batch = 15.8637s	
10938/33250 (epoch 16.448), train_loss = 1.00168905, grad/param norm = 1.3490e-01, time/batch = 15.9349s	
10939/33250 (epoch 16.450), train_loss = 1.18302114, grad/param norm = 1.7959e-01, time/batch = 15.3491s	
10940/33250 (epoch 16.451), train_loss = 1.05030759, grad/param norm = 1.5301e-01, time/batch = 14.9470s	
10941/33250 (epoch 16.453), train_loss = 0.91282662, grad/param norm = 1.4142e-01, time/batch = 16.4210s	
10942/33250 (epoch 16.454), train_loss = 1.15265278, grad/param norm = 1.6442e-01, time/batch = 16.2876s	
10943/33250 (epoch 16.456), train_loss = 1.14641206, grad/param norm = 1.4410e-01, time/batch = 15.1930s	
10944/33250 (epoch 16.457), train_loss = 0.96436159, grad/param norm = 1.4903e-01, time/batch = 18.0277s	
10945/33250 (epoch 16.459), train_loss = 1.00961745, grad/param norm = 1.4072e-01, time/batch = 17.1347s	
10946/33250 (epoch 16.460), train_loss = 1.09848810, grad/param norm = 1.6410e-01, time/batch = 17.3615s	
10947/33250 (epoch 16.462), train_loss = 0.93977466, grad/param norm = 1.3691e-01, time/batch = 16.9988s	
10948/33250 (epoch 16.463), train_loss = 0.92129366, grad/param norm = 1.4145e-01, time/batch = 15.5930s	
10949/33250 (epoch 16.465), train_loss = 0.82284546, grad/param norm = 1.2506e-01, time/batch = 15.7804s	
10950/33250 (epoch 16.466), train_loss = 0.78139997, grad/param norm = 1.0457e-01, time/batch = 15.4287s	
10951/33250 (epoch 16.468), train_loss = 0.89713084, grad/param norm = 1.2697e-01, time/batch = 16.3616s	
10952/33250 (epoch 16.469), train_loss = 0.98356359, grad/param norm = 1.5307e-01, time/batch = 16.2720s	
10953/33250 (epoch 16.471), train_loss = 1.09938113, grad/param norm = 1.4729e-01, time/batch = 16.6952s	
10954/33250 (epoch 16.472), train_loss = 0.97010438, grad/param norm = 1.7438e-01, time/batch = 16.1769s	
10955/33250 (epoch 16.474), train_loss = 1.14654363, grad/param norm = 1.7231e-01, time/batch = 17.4499s	
10956/33250 (epoch 16.475), train_loss = 1.01404210, grad/param norm = 1.4301e-01, time/batch = 15.7617s	
10957/33250 (epoch 16.477), train_loss = 0.98402617, grad/param norm = 1.4189e-01, time/batch = 16.1179s	
10958/33250 (epoch 16.478), train_loss = 0.92800090, grad/param norm = 1.4335e-01, time/batch = 16.2818s	
10959/33250 (epoch 16.480), train_loss = 1.22016692, grad/param norm = 1.6744e-01, time/batch = 17.5174s	
10960/33250 (epoch 16.481), train_loss = 1.01219302, grad/param norm = 1.4898e-01, time/batch = 15.8667s	
10961/33250 (epoch 16.483), train_loss = 1.03484353, grad/param norm = 1.4877e-01, time/batch = 16.0208s	
10962/33250 (epoch 16.484), train_loss = 0.90529112, grad/param norm = 1.4624e-01, time/batch = 17.5176s	
10963/33250 (epoch 16.486), train_loss = 0.84054942, grad/param norm = 1.5535e-01, time/batch = 15.5009s	
10964/33250 (epoch 16.487), train_loss = 0.95521628, grad/param norm = 1.4966e-01, time/batch = 17.7579s	
10965/33250 (epoch 16.489), train_loss = 1.09709389, grad/param norm = 1.8420e-01, time/batch = 16.4590s	
10966/33250 (epoch 16.490), train_loss = 1.03813589, grad/param norm = 1.7736e-01, time/batch = 16.7988s	
10967/33250 (epoch 16.492), train_loss = 1.05980715, grad/param norm = 1.6957e-01, time/batch = 14.8831s	
10968/33250 (epoch 16.493), train_loss = 0.99581555, grad/param norm = 1.7094e-01, time/batch = 16.1969s	
10969/33250 (epoch 16.495), train_loss = 1.01768348, grad/param norm = 1.4944e-01, time/batch = 15.5373s	
10970/33250 (epoch 16.496), train_loss = 0.96462512, grad/param norm = 1.2102e-01, time/batch = 16.3533s	
10971/33250 (epoch 16.498), train_loss = 1.08212981, grad/param norm = 1.6094e-01, time/batch = 16.1702s	
10972/33250 (epoch 16.499), train_loss = 0.97047898, grad/param norm = 1.4851e-01, time/batch = 16.0144s	
10973/33250 (epoch 16.501), train_loss = 0.94307941, grad/param norm = 1.5064e-01, time/batch = 15.7749s	
10974/33250 (epoch 16.502), train_loss = 0.94759092, grad/param norm = 1.2914e-01, time/batch = 16.4605s	
10975/33250 (epoch 16.504), train_loss = 1.13767322, grad/param norm = 1.6773e-01, time/batch = 16.6199s	
10976/33250 (epoch 16.505), train_loss = 0.80029549, grad/param norm = 1.2134e-01, time/batch = 15.7476s	
10977/33250 (epoch 16.507), train_loss = 0.95927682, grad/param norm = 1.4904e-01, time/batch = 17.6161s	
10978/33250 (epoch 16.508), train_loss = 0.94164331, grad/param norm = 1.6019e-01, time/batch = 16.8728s	
10979/33250 (epoch 16.510), train_loss = 0.80979279, grad/param norm = 1.3410e-01, time/batch = 15.9448s	
10980/33250 (epoch 16.511), train_loss = 1.00042620, grad/param norm = 1.4983e-01, time/batch = 15.4406s	
10981/33250 (epoch 16.513), train_loss = 1.12984581, grad/param norm = 1.5143e-01, time/batch = 16.4493s	
10982/33250 (epoch 16.514), train_loss = 0.93285875, grad/param norm = 1.3563e-01, time/batch = 15.8707s	
10983/33250 (epoch 16.516), train_loss = 0.92804276, grad/param norm = 1.4445e-01, time/batch = 16.6751s	
10984/33250 (epoch 16.517), train_loss = 0.98684982, grad/param norm = 1.5132e-01, time/batch = 15.5334s	
10985/33250 (epoch 16.519), train_loss = 0.86341042, grad/param norm = 1.1581e-01, time/batch = 18.3713s	
10986/33250 (epoch 16.520), train_loss = 1.24603786, grad/param norm = 1.6941e-01, time/batch = 16.8768s	
10987/33250 (epoch 16.522), train_loss = 1.06089494, grad/param norm = 1.4888e-01, time/batch = 18.1165s	
10988/33250 (epoch 16.523), train_loss = 0.91914709, grad/param norm = 1.3603e-01, time/batch = 16.6239s	
10989/33250 (epoch 16.525), train_loss = 0.87663825, grad/param norm = 1.6092e-01, time/batch = 15.1139s	
10990/33250 (epoch 16.526), train_loss = 0.85597286, grad/param norm = 1.3735e-01, time/batch = 16.7518s	
10991/33250 (epoch 16.528), train_loss = 0.97346053, grad/param norm = 1.4800e-01, time/batch = 15.6065s	
10992/33250 (epoch 16.529), train_loss = 0.92328507, grad/param norm = 1.5805e-01, time/batch = 16.0272s	
10993/33250 (epoch 16.531), train_loss = 0.86959485, grad/param norm = 1.2757e-01, time/batch = 15.6056s	
10994/33250 (epoch 16.532), train_loss = 1.05196291, grad/param norm = 1.4249e-01, time/batch = 15.2735s	
10995/33250 (epoch 16.534), train_loss = 0.88231804, grad/param norm = 1.2386e-01, time/batch = 16.9496s	
10996/33250 (epoch 16.535), train_loss = 0.96000863, grad/param norm = 1.3173e-01, time/batch = 18.4508s	
10997/33250 (epoch 16.537), train_loss = 1.04005313, grad/param norm = 1.4270e-01, time/batch = 16.5896s	
10998/33250 (epoch 16.538), train_loss = 1.06474559, grad/param norm = 1.5088e-01, time/batch = 17.2842s	
10999/33250 (epoch 16.540), train_loss = 1.15335502, grad/param norm = 1.3826e-01, time/batch = 16.1033s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch16.54_1.4584.t7	
11000/33250 (epoch 16.541), train_loss = 1.09424863, grad/param norm = 1.5644e-01, time/batch = 17.1893s	
11001/33250 (epoch 16.543), train_loss = 1.35479899, grad/param norm = 1.5957e-01, time/batch = 17.1113s	
11002/33250 (epoch 16.544), train_loss = 0.92691704, grad/param norm = 1.4845e-01, time/batch = 16.0209s	
11003/33250 (epoch 16.546), train_loss = 0.97389186, grad/param norm = 1.6737e-01, time/batch = 15.8546s	
11004/33250 (epoch 16.547), train_loss = 0.94078384, grad/param norm = 1.6697e-01, time/batch = 15.4210s	
11005/33250 (epoch 16.549), train_loss = 1.05563502, grad/param norm = 1.5057e-01, time/batch = 16.3387s	
11006/33250 (epoch 16.550), train_loss = 0.95413954, grad/param norm = 1.4838e-01, time/batch = 18.7024s	
11007/33250 (epoch 16.552), train_loss = 1.01818623, grad/param norm = 1.4802e-01, time/batch = 16.1926s	
11008/33250 (epoch 16.553), train_loss = 0.91434181, grad/param norm = 1.3089e-01, time/batch = 19.0225s	
11009/33250 (epoch 16.555), train_loss = 1.01866339, grad/param norm = 1.4204e-01, time/batch = 18.0214s	
11010/33250 (epoch 16.556), train_loss = 1.11574113, grad/param norm = 1.7223e-01, time/batch = 17.0983s	
11011/33250 (epoch 16.558), train_loss = 1.09588517, grad/param norm = 1.6241e-01, time/batch = 17.6028s	
11012/33250 (epoch 16.559), train_loss = 0.89410622, grad/param norm = 1.3662e-01, time/batch = 17.0167s	
11013/33250 (epoch 16.561), train_loss = 0.90555570, grad/param norm = 1.4833e-01, time/batch = 17.2667s	
11014/33250 (epoch 16.562), train_loss = 1.10771499, grad/param norm = 1.5812e-01, time/batch = 15.4321s	
11015/33250 (epoch 16.564), train_loss = 1.20756602, grad/param norm = 1.7653e-01, time/batch = 16.2572s	
11016/33250 (epoch 16.565), train_loss = 1.15432690, grad/param norm = 1.8607e-01, time/batch = 17.0407s	
11017/33250 (epoch 16.567), train_loss = 1.12636042, grad/param norm = 1.5641e-01, time/batch = 16.8435s	
11018/33250 (epoch 16.568), train_loss = 1.00726170, grad/param norm = 1.5896e-01, time/batch = 18.7534s	
11019/33250 (epoch 16.570), train_loss = 1.13726205, grad/param norm = 1.7377e-01, time/batch = 17.1009s	
11020/33250 (epoch 16.571), train_loss = 1.16277510, grad/param norm = 1.5846e-01, time/batch = 15.9452s	
11021/33250 (epoch 16.573), train_loss = 1.04706927, grad/param norm = 1.5774e-01, time/batch = 15.6891s	
11022/33250 (epoch 16.574), train_loss = 0.89981137, grad/param norm = 1.4120e-01, time/batch = 16.5093s	
11023/33250 (epoch 16.576), train_loss = 1.03695589, grad/param norm = 1.4716e-01, time/batch = 16.5915s	
11024/33250 (epoch 16.577), train_loss = 0.98838921, grad/param norm = 1.5428e-01, time/batch = 16.7723s	
11025/33250 (epoch 16.579), train_loss = 0.90280315, grad/param norm = 1.4297e-01, time/batch = 17.1879s	
11026/33250 (epoch 16.580), train_loss = 0.95019159, grad/param norm = 1.3895e-01, time/batch = 17.2861s	
11027/33250 (epoch 16.582), train_loss = 0.97317663, grad/param norm = 1.3983e-01, time/batch = 16.2068s	
11028/33250 (epoch 16.583), train_loss = 1.07864380, grad/param norm = 1.4158e-01, time/batch = 15.8749s	
11029/33250 (epoch 16.585), train_loss = 1.08330857, grad/param norm = 1.4726e-01, time/batch = 18.5182s	
11030/33250 (epoch 16.586), train_loss = 0.95763163, grad/param norm = 1.7353e-01, time/batch = 17.3615s	
11031/33250 (epoch 16.588), train_loss = 1.01914000, grad/param norm = 1.3925e-01, time/batch = 17.0904s	
11032/33250 (epoch 16.589), train_loss = 1.04326713, grad/param norm = 1.4979e-01, time/batch = 17.1091s	
11033/33250 (epoch 16.591), train_loss = 1.02091415, grad/param norm = 1.5276e-01, time/batch = 16.0332s	
11034/33250 (epoch 16.592), train_loss = 1.00616691, grad/param norm = 1.3647e-01, time/batch = 16.4384s	
11035/33250 (epoch 16.594), train_loss = 1.16342648, grad/param norm = 1.7146e-01, time/batch = 16.3466s	
11036/33250 (epoch 16.595), train_loss = 1.06385378, grad/param norm = 1.6036e-01, time/batch = 17.0207s	
11037/33250 (epoch 16.597), train_loss = 0.86923383, grad/param norm = 1.4368e-01, time/batch = 17.3958s	
11038/33250 (epoch 16.598), train_loss = 0.97856161, grad/param norm = 1.5095e-01, time/batch = 15.8326s	
11039/33250 (epoch 16.600), train_loss = 0.98444094, grad/param norm = 1.5981e-01, time/batch = 17.3708s	
11040/33250 (epoch 16.602), train_loss = 1.03148962, grad/param norm = 1.8280e-01, time/batch = 15.5153s	
11041/33250 (epoch 16.603), train_loss = 1.04594866, grad/param norm = 1.6387e-01, time/batch = 17.5195s	
11042/33250 (epoch 16.605), train_loss = 1.01614565, grad/param norm = 1.5921e-01, time/batch = 15.0348s	
11043/33250 (epoch 16.606), train_loss = 1.04438900, grad/param norm = 1.5967e-01, time/batch = 17.1824s	
11044/33250 (epoch 16.608), train_loss = 1.01197941, grad/param norm = 1.4139e-01, time/batch = 15.3342s	
11045/33250 (epoch 16.609), train_loss = 0.89871958, grad/param norm = 1.5089e-01, time/batch = 16.3473s	
11046/33250 (epoch 16.611), train_loss = 1.02893041, grad/param norm = 1.5696e-01, time/batch = 16.2988s	
11047/33250 (epoch 16.612), train_loss = 1.01313399, grad/param norm = 1.5280e-01, time/batch = 18.7079s	
11048/33250 (epoch 16.614), train_loss = 1.22345931, grad/param norm = 1.7822e-01, time/batch = 17.2873s	
11049/33250 (epoch 16.615), train_loss = 1.10451207, grad/param norm = 1.6036e-01, time/batch = 16.5478s	
11050/33250 (epoch 16.617), train_loss = 1.31597822, grad/param norm = 1.7339e-01, time/batch = 16.8583s	
11051/33250 (epoch 16.618), train_loss = 1.30280699, grad/param norm = 2.2090e-01, time/batch = 16.7735s	
11052/33250 (epoch 16.620), train_loss = 1.10358339, grad/param norm = 1.6010e-01, time/batch = 16.4381s	
11053/33250 (epoch 16.621), train_loss = 1.01843280, grad/param norm = 1.5550e-01, time/batch = 15.8330s	
11054/33250 (epoch 16.623), train_loss = 0.93068523, grad/param norm = 1.4651e-01, time/batch = 16.5176s	
11055/33250 (epoch 16.624), train_loss = 1.00054462, grad/param norm = 1.5814e-01, time/batch = 15.5993s	
11056/33250 (epoch 16.626), train_loss = 0.97479696, grad/param norm = 1.7704e-01, time/batch = 15.3368s	
11057/33250 (epoch 16.627), train_loss = 0.95091281, grad/param norm = 1.4109e-01, time/batch = 15.2689s	
11058/33250 (epoch 16.629), train_loss = 1.07037265, grad/param norm = 1.6940e-01, time/batch = 15.4241s	
11059/33250 (epoch 16.630), train_loss = 0.98919379, grad/param norm = 1.7184e-01, time/batch = 15.2672s	
11060/33250 (epoch 16.632), train_loss = 0.83008732, grad/param norm = 1.2459e-01, time/batch = 15.1884s	
11061/33250 (epoch 16.633), train_loss = 1.04521719, grad/param norm = 1.5383e-01, time/batch = 14.8634s	
11062/33250 (epoch 16.635), train_loss = 0.89538829, grad/param norm = 1.3825e-01, time/batch = 15.0758s	
11063/33250 (epoch 16.636), train_loss = 0.93537097, grad/param norm = 1.5404e-01, time/batch = 15.3397s	
11064/33250 (epoch 16.638), train_loss = 0.96425439, grad/param norm = 1.5334e-01, time/batch = 16.0101s	
11065/33250 (epoch 16.639), train_loss = 0.82846639, grad/param norm = 1.3372e-01, time/batch = 16.0176s	
11066/33250 (epoch 16.641), train_loss = 0.92717954, grad/param norm = 1.3349e-01, time/batch = 16.2786s	
11067/33250 (epoch 16.642), train_loss = 0.81801250, grad/param norm = 1.3682e-01, time/batch = 17.4497s	
11068/33250 (epoch 16.644), train_loss = 0.75142674, grad/param norm = 1.3651e-01, time/batch = 16.6311s	
11069/33250 (epoch 16.645), train_loss = 1.09916420, grad/param norm = 1.7273e-01, time/batch = 16.8820s	
11070/33250 (epoch 16.647), train_loss = 0.86580927, grad/param norm = 1.4432e-01, time/batch = 16.2851s	
11071/33250 (epoch 16.648), train_loss = 0.90919844, grad/param norm = 1.5266e-01, time/batch = 18.3351s	
11072/33250 (epoch 16.650), train_loss = 1.12866037, grad/param norm = 1.7563e-01, time/batch = 16.3502s	
11073/33250 (epoch 16.651), train_loss = 1.03248863, grad/param norm = 1.7001e-01, time/batch = 17.2584s	
11074/33250 (epoch 16.653), train_loss = 0.90205819, grad/param norm = 1.4606e-01, time/batch = 16.7696s	
11075/33250 (epoch 16.654), train_loss = 0.95663203, grad/param norm = 1.3999e-01, time/batch = 15.7589s	
11076/33250 (epoch 16.656), train_loss = 1.04543492, grad/param norm = 1.4845e-01, time/batch = 16.1128s	
11077/33250 (epoch 16.657), train_loss = 0.79615948, grad/param norm = 1.4421e-01, time/batch = 16.1103s	
11078/33250 (epoch 16.659), train_loss = 0.93069937, grad/param norm = 1.4291e-01, time/batch = 17.6655s	
11079/33250 (epoch 16.660), train_loss = 0.97683641, grad/param norm = 1.5396e-01, time/batch = 16.6105s	
11080/33250 (epoch 16.662), train_loss = 1.01012296, grad/param norm = 1.4264e-01, time/batch = 18.2193s	
11081/33250 (epoch 16.663), train_loss = 0.91445999, grad/param norm = 1.4418e-01, time/batch = 16.9459s	
11082/33250 (epoch 16.665), train_loss = 1.03924075, grad/param norm = 1.4851e-01, time/batch = 17.4366s	
11083/33250 (epoch 16.666), train_loss = 0.94271406, grad/param norm = 1.4243e-01, time/batch = 16.5871s	
11084/33250 (epoch 16.668), train_loss = 1.15169911, grad/param norm = 1.5715e-01, time/batch = 16.4427s	
11085/33250 (epoch 16.669), train_loss = 1.02456122, grad/param norm = 1.5389e-01, time/batch = 16.6145s	
11086/33250 (epoch 16.671), train_loss = 0.91117593, grad/param norm = 1.5907e-01, time/batch = 15.2585s	
11087/33250 (epoch 16.672), train_loss = 1.09014176, grad/param norm = 1.6086e-01, time/batch = 17.7729s	
11088/33250 (epoch 16.674), train_loss = 0.91294212, grad/param norm = 1.3687e-01, time/batch = 17.3710s	
11089/33250 (epoch 16.675), train_loss = 0.96977993, grad/param norm = 1.3637e-01, time/batch = 22.0435s	
11090/33250 (epoch 16.677), train_loss = 1.10083967, grad/param norm = 1.6086e-01, time/batch = 27.8114s	
11091/33250 (epoch 16.678), train_loss = 0.96231248, grad/param norm = 1.4813e-01, time/batch = 15.5090s	
11092/33250 (epoch 16.680), train_loss = 1.11575786, grad/param norm = 1.6406e-01, time/batch = 16.5766s	
11093/33250 (epoch 16.681), train_loss = 0.87010867, grad/param norm = 1.3997e-01, time/batch = 15.6939s	
11094/33250 (epoch 16.683), train_loss = 0.96631308, grad/param norm = 1.5042e-01, time/batch = 16.3279s	
11095/33250 (epoch 16.684), train_loss = 0.88785138, grad/param norm = 1.5512e-01, time/batch = 15.6955s	
11096/33250 (epoch 16.686), train_loss = 0.90789479, grad/param norm = 1.4742e-01, time/batch = 16.8384s	
11097/33250 (epoch 16.687), train_loss = 0.98576903, grad/param norm = 1.4686e-01, time/batch = 18.4439s	
11098/33250 (epoch 16.689), train_loss = 0.91963804, grad/param norm = 1.5114e-01, time/batch = 17.2054s	
11099/33250 (epoch 16.690), train_loss = 1.00833441, grad/param norm = 1.4971e-01, time/batch = 16.5422s	
11100/33250 (epoch 16.692), train_loss = 0.97299844, grad/param norm = 1.5169e-01, time/batch = 16.4571s	
11101/33250 (epoch 16.693), train_loss = 1.06837215, grad/param norm = 1.4812e-01, time/batch = 15.4218s	
11102/33250 (epoch 16.695), train_loss = 1.02150190, grad/param norm = 1.4292e-01, time/batch = 16.0319s	
11103/33250 (epoch 16.696), train_loss = 1.03190367, grad/param norm = 1.4918e-01, time/batch = 15.1212s	
11104/33250 (epoch 16.698), train_loss = 0.91876141, grad/param norm = 1.4582e-01, time/batch = 16.0025s	
11105/33250 (epoch 16.699), train_loss = 1.19951756, grad/param norm = 1.6054e-01, time/batch = 15.1752s	
11106/33250 (epoch 16.701), train_loss = 0.97141109, grad/param norm = 1.3714e-01, time/batch = 16.6126s	
11107/33250 (epoch 16.702), train_loss = 0.95020465, grad/param norm = 2.1175e-01, time/batch = 16.8547s	
11108/33250 (epoch 16.704), train_loss = 1.18305953, grad/param norm = 2.0352e-01, time/batch = 16.8529s	
11109/33250 (epoch 16.705), train_loss = 0.90844478, grad/param norm = 1.3347e-01, time/batch = 16.6273s	
11110/33250 (epoch 16.707), train_loss = 0.81384349, grad/param norm = 1.2809e-01, time/batch = 16.4218s	
11111/33250 (epoch 16.708), train_loss = 1.09117364, grad/param norm = 1.6502e-01, time/batch = 16.6821s	
11112/33250 (epoch 16.710), train_loss = 1.06869171, grad/param norm = 1.6178e-01, time/batch = 16.4463s	
11113/33250 (epoch 16.711), train_loss = 0.92639744, grad/param norm = 1.5298e-01, time/batch = 15.9526s	
11114/33250 (epoch 16.713), train_loss = 1.02457244, grad/param norm = 1.4339e-01, time/batch = 15.7620s	
11115/33250 (epoch 16.714), train_loss = 1.02085463, grad/param norm = 1.5683e-01, time/batch = 15.5114s	
11116/33250 (epoch 16.716), train_loss = 1.08518499, grad/param norm = 1.5986e-01, time/batch = 15.7007s	
11117/33250 (epoch 16.717), train_loss = 0.91985530, grad/param norm = 1.3254e-01, time/batch = 17.7718s	
11118/33250 (epoch 16.719), train_loss = 0.98740180, grad/param norm = 1.4913e-01, time/batch = 16.7749s	
11119/33250 (epoch 16.720), train_loss = 1.22739402, grad/param norm = 1.6613e-01, time/batch = 17.7111s	
11120/33250 (epoch 16.722), train_loss = 0.90040417, grad/param norm = 1.4026e-01, time/batch = 18.9514s	
11121/33250 (epoch 16.723), train_loss = 0.78531587, grad/param norm = 1.1986e-01, time/batch = 15.7738s	
11122/33250 (epoch 16.725), train_loss = 0.86211363, grad/param norm = 1.3039e-01, time/batch = 16.5256s	
11123/33250 (epoch 16.726), train_loss = 0.95977237, grad/param norm = 1.4300e-01, time/batch = 16.0195s	
11124/33250 (epoch 16.728), train_loss = 1.04119887, grad/param norm = 1.4916e-01, time/batch = 17.0916s	
11125/33250 (epoch 16.729), train_loss = 1.10722088, grad/param norm = 1.4955e-01, time/batch = 15.3348s	
11126/33250 (epoch 16.731), train_loss = 0.93227523, grad/param norm = 1.4847e-01, time/batch = 17.5237s	
11127/33250 (epoch 16.732), train_loss = 0.88527695, grad/param norm = 1.3794e-01, time/batch = 15.7967s	
11128/33250 (epoch 16.734), train_loss = 1.00706618, grad/param norm = 1.5066e-01, time/batch = 16.0238s	
11129/33250 (epoch 16.735), train_loss = 1.00879570, grad/param norm = 1.6227e-01, time/batch = 16.4663s	
11130/33250 (epoch 16.737), train_loss = 0.97575818, grad/param norm = 1.3422e-01, time/batch = 18.0510s	
11131/33250 (epoch 16.738), train_loss = 1.00147080, grad/param norm = 1.4526e-01, time/batch = 16.6890s	
11132/33250 (epoch 16.740), train_loss = 1.12319283, grad/param norm = 1.5886e-01, time/batch = 15.6944s	
11133/33250 (epoch 16.741), train_loss = 1.07913184, grad/param norm = 1.4896e-01, time/batch = 15.2446s	
11134/33250 (epoch 16.743), train_loss = 0.93259285, grad/param norm = 1.3654e-01, time/batch = 15.8629s	
11135/33250 (epoch 16.744), train_loss = 0.95520014, grad/param norm = 1.6591e-01, time/batch = 17.0093s	
11136/33250 (epoch 16.746), train_loss = 0.92042229, grad/param norm = 1.3476e-01, time/batch = 15.7619s	
11137/33250 (epoch 16.747), train_loss = 0.94528983, grad/param norm = 1.5291e-01, time/batch = 16.2002s	
11138/33250 (epoch 16.749), train_loss = 1.10441305, grad/param norm = 1.7810e-01, time/batch = 17.3030s	
11139/33250 (epoch 16.750), train_loss = 1.06924973, grad/param norm = 1.5554e-01, time/batch = 16.8772s	
11140/33250 (epoch 16.752), train_loss = 0.94283396, grad/param norm = 1.3864e-01, time/batch = 17.6179s	
11141/33250 (epoch 16.753), train_loss = 0.97026475, grad/param norm = 1.5302e-01, time/batch = 17.4381s	
11142/33250 (epoch 16.755), train_loss = 0.98242509, grad/param norm = 1.6164e-01, time/batch = 16.6976s	
11143/33250 (epoch 16.756), train_loss = 1.05918824, grad/param norm = 1.5221e-01, time/batch = 15.5155s	
11144/33250 (epoch 16.758), train_loss = 1.12645993, grad/param norm = 1.4934e-01, time/batch = 17.1731s	
11145/33250 (epoch 16.759), train_loss = 0.90273130, grad/param norm = 1.3774e-01, time/batch = 15.5559s	
11146/33250 (epoch 16.761), train_loss = 0.97391574, grad/param norm = 1.4694e-01, time/batch = 15.6442s	
11147/33250 (epoch 16.762), train_loss = 1.11992426, grad/param norm = 1.5148e-01, time/batch = 15.3565s	
11148/33250 (epoch 16.764), train_loss = 0.90059946, grad/param norm = 1.6838e-01, time/batch = 17.2972s	
11149/33250 (epoch 16.765), train_loss = 1.03239450, grad/param norm = 1.5000e-01, time/batch = 16.5479s	
11150/33250 (epoch 16.767), train_loss = 0.83286309, grad/param norm = 1.4335e-01, time/batch = 15.7485s	
11151/33250 (epoch 16.768), train_loss = 0.86245437, grad/param norm = 1.4334e-01, time/batch = 18.9131s	
11152/33250 (epoch 16.770), train_loss = 1.05110265, grad/param norm = 1.8176e-01, time/batch = 15.6277s	
11153/33250 (epoch 16.771), train_loss = 1.05681352, grad/param norm = 1.6817e-01, time/batch = 16.2578s	
11154/33250 (epoch 16.773), train_loss = 0.96955832, grad/param norm = 1.6593e-01, time/batch = 15.7734s	
11155/33250 (epoch 16.774), train_loss = 0.83162939, grad/param norm = 1.3946e-01, time/batch = 18.7470s	
11156/33250 (epoch 16.776), train_loss = 0.93900231, grad/param norm = 1.5775e-01, time/batch = 16.5368s	
11157/33250 (epoch 16.777), train_loss = 1.10148043, grad/param norm = 1.7156e-01, time/batch = 16.1107s	
11158/33250 (epoch 16.779), train_loss = 0.99008422, grad/param norm = 1.5383e-01, time/batch = 16.1976s	
11159/33250 (epoch 16.780), train_loss = 1.17013749, grad/param norm = 1.7302e-01, time/batch = 16.7078s	
11160/33250 (epoch 16.782), train_loss = 1.03184286, grad/param norm = 1.4925e-01, time/batch = 18.2063s	
11161/33250 (epoch 16.783), train_loss = 0.83412490, grad/param norm = 1.3931e-01, time/batch = 15.4385s	
11162/33250 (epoch 16.785), train_loss = 0.87645665, grad/param norm = 1.3661e-01, time/batch = 15.5109s	
11163/33250 (epoch 16.786), train_loss = 1.07197736, grad/param norm = 1.6134e-01, time/batch = 16.2004s	
11164/33250 (epoch 16.788), train_loss = 1.06538534, grad/param norm = 1.5631e-01, time/batch = 15.9395s	
11165/33250 (epoch 16.789), train_loss = 1.09422174, grad/param norm = 1.6550e-01, time/batch = 15.6257s	
11166/33250 (epoch 16.791), train_loss = 1.15205471, grad/param norm = 1.5272e-01, time/batch = 16.0913s	
11167/33250 (epoch 16.792), train_loss = 1.23217269, grad/param norm = 1.5456e-01, time/batch = 15.6433s	
11168/33250 (epoch 16.794), train_loss = 0.99587062, grad/param norm = 1.6368e-01, time/batch = 15.6694s	
11169/33250 (epoch 16.795), train_loss = 1.02965708, grad/param norm = 1.5534e-01, time/batch = 15.8722s	
11170/33250 (epoch 16.797), train_loss = 1.10926579, grad/param norm = 1.7440e-01, time/batch = 15.6361s	
11171/33250 (epoch 16.798), train_loss = 1.01674569, grad/param norm = 1.8357e-01, time/batch = 15.6855s	
11172/33250 (epoch 16.800), train_loss = 1.06002146, grad/param norm = 2.2546e-01, time/batch = 15.6854s	
11173/33250 (epoch 16.802), train_loss = 0.94452347, grad/param norm = 1.2458e-01, time/batch = 15.7355s	
11174/33250 (epoch 16.803), train_loss = 1.00291272, grad/param norm = 1.3573e-01, time/batch = 15.9046s	
11175/33250 (epoch 16.805), train_loss = 1.06116778, grad/param norm = 1.7103e-01, time/batch = 15.5189s	
11176/33250 (epoch 16.806), train_loss = 1.02308184, grad/param norm = 1.5954e-01, time/batch = 15.6836s	
11177/33250 (epoch 16.808), train_loss = 0.97160401, grad/param norm = 1.4417e-01, time/batch = 16.2616s	
11178/33250 (epoch 16.809), train_loss = 0.90883956, grad/param norm = 1.4402e-01, time/batch = 15.6169s	
11179/33250 (epoch 16.811), train_loss = 0.91714036, grad/param norm = 1.4344e-01, time/batch = 16.7037s	
11180/33250 (epoch 16.812), train_loss = 1.07483087, grad/param norm = 1.5930e-01, time/batch = 16.1373s	
11181/33250 (epoch 16.814), train_loss = 1.00224621, grad/param norm = 1.4655e-01, time/batch = 17.7920s	
11182/33250 (epoch 16.815), train_loss = 1.05250886, grad/param norm = 1.4691e-01, time/batch = 15.9538s	
11183/33250 (epoch 16.817), train_loss = 0.96786139, grad/param norm = 1.4089e-01, time/batch = 15.2659s	
11184/33250 (epoch 16.818), train_loss = 0.91991629, grad/param norm = 1.4310e-01, time/batch = 15.5685s	
11185/33250 (epoch 16.820), train_loss = 1.00264000, grad/param norm = 1.4028e-01, time/batch = 16.1129s	
11186/33250 (epoch 16.821), train_loss = 0.97365647, grad/param norm = 1.3379e-01, time/batch = 15.6101s	
11187/33250 (epoch 16.823), train_loss = 1.31566225, grad/param norm = 1.8100e-01, time/batch = 15.7008s	
11188/33250 (epoch 16.824), train_loss = 0.95770812, grad/param norm = 1.5608e-01, time/batch = 15.7017s	
11189/33250 (epoch 16.826), train_loss = 1.03904472, grad/param norm = 1.5877e-01, time/batch = 18.3605s	
11190/33250 (epoch 16.827), train_loss = 0.81484076, grad/param norm = 1.3230e-01, time/batch = 16.2085s	
11191/33250 (epoch 16.829), train_loss = 1.02685946, grad/param norm = 1.7193e-01, time/batch = 15.8183s	
11192/33250 (epoch 16.830), train_loss = 1.12110392, grad/param norm = 1.8407e-01, time/batch = 15.7340s	
11193/33250 (epoch 16.832), train_loss = 1.01199983, grad/param norm = 1.5688e-01, time/batch = 15.4728s	
11194/33250 (epoch 16.833), train_loss = 1.03599206, grad/param norm = 1.6172e-01, time/batch = 15.7708s	
11195/33250 (epoch 16.835), train_loss = 0.93216959, grad/param norm = 1.8062e-01, time/batch = 15.3649s	
11196/33250 (epoch 16.836), train_loss = 0.98545440, grad/param norm = 1.5355e-01, time/batch = 15.4543s	
11197/33250 (epoch 16.838), train_loss = 0.98725989, grad/param norm = 1.4558e-01, time/batch = 15.4079s	
11198/33250 (epoch 16.839), train_loss = 0.97310809, grad/param norm = 1.5826e-01, time/batch = 15.8173s	
11199/33250 (epoch 16.841), train_loss = 0.92701430, grad/param norm = 1.4283e-01, time/batch = 16.0160s	
11200/33250 (epoch 16.842), train_loss = 1.14780106, grad/param norm = 1.4574e-01, time/batch = 15.3116s	
11201/33250 (epoch 16.844), train_loss = 1.13102359, grad/param norm = 1.8489e-01, time/batch = 16.0128s	
11202/33250 (epoch 16.845), train_loss = 1.21728138, grad/param norm = 1.6771e-01, time/batch = 16.0993s	
11203/33250 (epoch 16.847), train_loss = 1.15320884, grad/param norm = 1.6003e-01, time/batch = 16.1883s	
11204/33250 (epoch 16.848), train_loss = 1.29112897, grad/param norm = 1.8483e-01, time/batch = 15.6844s	
11205/33250 (epoch 16.850), train_loss = 1.12676569, grad/param norm = 1.7150e-01, time/batch = 15.4294s	
11206/33250 (epoch 16.851), train_loss = 0.93953164, grad/param norm = 1.5764e-01, time/batch = 15.1866s	
11207/33250 (epoch 16.853), train_loss = 1.08304707, grad/param norm = 1.6827e-01, time/batch = 15.7901s	
11208/33250 (epoch 16.854), train_loss = 0.92261927, grad/param norm = 1.3943e-01, time/batch = 15.8096s	
11209/33250 (epoch 16.856), train_loss = 0.95266132, grad/param norm = 1.6518e-01, time/batch = 15.8280s	
11210/33250 (epoch 16.857), train_loss = 0.86683046, grad/param norm = 1.3731e-01, time/batch = 15.5290s	
11211/33250 (epoch 16.859), train_loss = 0.86635363, grad/param norm = 1.3189e-01, time/batch = 15.9255s	
11212/33250 (epoch 16.860), train_loss = 0.99178936, grad/param norm = 1.4129e-01, time/batch = 16.7066s	
11213/33250 (epoch 16.862), train_loss = 0.90368353, grad/param norm = 1.2947e-01, time/batch = 16.4262s	
11214/33250 (epoch 16.863), train_loss = 0.96727712, grad/param norm = 1.6310e-01, time/batch = 17.4105s	
11215/33250 (epoch 16.865), train_loss = 1.05345874, grad/param norm = 1.5828e-01, time/batch = 16.6911s	
11216/33250 (epoch 16.866), train_loss = 0.98679106, grad/param norm = 1.7173e-01, time/batch = 16.2756s	
11217/33250 (epoch 16.868), train_loss = 1.09456971, grad/param norm = 1.8757e-01, time/batch = 15.7529s	
11218/33250 (epoch 16.869), train_loss = 1.04089149, grad/param norm = 1.5529e-01, time/batch = 15.5850s	
11219/33250 (epoch 16.871), train_loss = 0.78025962, grad/param norm = 1.3883e-01, time/batch = 15.5653s	
11220/33250 (epoch 16.872), train_loss = 1.05806596, grad/param norm = 2.1963e-01, time/batch = 15.7885s	
11221/33250 (epoch 16.874), train_loss = 0.91115593, grad/param norm = 1.6033e-01, time/batch = 16.2217s	
11222/33250 (epoch 16.875), train_loss = 0.90750211, grad/param norm = 1.5798e-01, time/batch = 18.9462s	
11223/33250 (epoch 16.877), train_loss = 1.11547539, grad/param norm = 1.5295e-01, time/batch = 17.7718s	
11224/33250 (epoch 16.878), train_loss = 1.03695832, grad/param norm = 1.5403e-01, time/batch = 15.7316s	
11225/33250 (epoch 16.880), train_loss = 0.99869961, grad/param norm = 1.7828e-01, time/batch = 15.1929s	
11226/33250 (epoch 16.881), train_loss = 1.15101878, grad/param norm = 1.8025e-01, time/batch = 15.2643s	
11227/33250 (epoch 16.883), train_loss = 1.02927129, grad/param norm = 1.5252e-01, time/batch = 15.1908s	
11228/33250 (epoch 16.884), train_loss = 1.02428381, grad/param norm = 1.5930e-01, time/batch = 15.5259s	
11229/33250 (epoch 16.886), train_loss = 0.93020746, grad/param norm = 1.2906e-01, time/batch = 16.5232s	
11230/33250 (epoch 16.887), train_loss = 0.98772799, grad/param norm = 1.6111e-01, time/batch = 16.0899s	
11231/33250 (epoch 16.889), train_loss = 0.94548422, grad/param norm = 1.3346e-01, time/batch = 17.4454s	
11232/33250 (epoch 16.890), train_loss = 0.82688106, grad/param norm = 1.1782e-01, time/batch = 16.1290s	
11233/33250 (epoch 16.892), train_loss = 1.05697120, grad/param norm = 1.5434e-01, time/batch = 16.2860s	
11234/33250 (epoch 16.893), train_loss = 1.06789898, grad/param norm = 1.6576e-01, time/batch = 15.3598s	
11235/33250 (epoch 16.895), train_loss = 0.95303955, grad/param norm = 1.5599e-01, time/batch = 15.4439s	
11236/33250 (epoch 16.896), train_loss = 1.07935450, grad/param norm = 1.5828e-01, time/batch = 2.5904s	
11237/33250 (epoch 16.898), train_loss = 0.98994475, grad/param norm = 1.4817e-01, time/batch = 0.6821s	
11238/33250 (epoch 16.899), train_loss = 0.91546548, grad/param norm = 1.6051e-01, time/batch = 0.6842s	
11239/33250 (epoch 16.901), train_loss = 0.86845171, grad/param norm = 1.3167e-01, time/batch = 0.6787s	
11240/33250 (epoch 16.902), train_loss = 0.98603740, grad/param norm = 1.5193e-01, time/batch = 0.6701s	
11241/33250 (epoch 16.904), train_loss = 0.90403136, grad/param norm = 1.2975e-01, time/batch = 0.6690s	
11242/33250 (epoch 16.905), train_loss = 0.94978893, grad/param norm = 1.3651e-01, time/batch = 0.6753s	
11243/33250 (epoch 16.907), train_loss = 0.90534173, grad/param norm = 1.4714e-01, time/batch = 0.6812s	
11244/33250 (epoch 16.908), train_loss = 0.98857429, grad/param norm = 1.3210e-01, time/batch = 0.6783s	
11245/33250 (epoch 16.910), train_loss = 1.04824611, grad/param norm = 1.5137e-01, time/batch = 0.6757s	
11246/33250 (epoch 16.911), train_loss = 0.88148614, grad/param norm = 1.3915e-01, time/batch = 0.6773s	
11247/33250 (epoch 16.913), train_loss = 0.91952385, grad/param norm = 1.3887e-01, time/batch = 0.6814s	
11248/33250 (epoch 16.914), train_loss = 0.83094358, grad/param norm = 1.3824e-01, time/batch = 0.6735s	
11249/33250 (epoch 16.916), train_loss = 0.92359167, grad/param norm = 1.3361e-01, time/batch = 0.6650s	
11250/33250 (epoch 16.917), train_loss = 0.94870391, grad/param norm = 1.2626e-01, time/batch = 0.6935s	
11251/33250 (epoch 16.919), train_loss = 0.90541913, grad/param norm = 1.5121e-01, time/batch = 0.9733s	
11252/33250 (epoch 16.920), train_loss = 0.99410870, grad/param norm = 1.5425e-01, time/batch = 0.9779s	
11253/33250 (epoch 16.922), train_loss = 1.03176776, grad/param norm = 1.7095e-01, time/batch = 0.9745s	
11254/33250 (epoch 16.923), train_loss = 0.98968125, grad/param norm = 1.6652e-01, time/batch = 0.9714s	
11255/33250 (epoch 16.925), train_loss = 0.94543763, grad/param norm = 1.4922e-01, time/batch = 1.0185s	
11256/33250 (epoch 16.926), train_loss = 0.95006296, grad/param norm = 1.3889e-01, time/batch = 1.8179s	
11257/33250 (epoch 16.928), train_loss = 0.97113906, grad/param norm = 1.5701e-01, time/batch = 1.8108s	
11258/33250 (epoch 16.929), train_loss = 0.80183398, grad/param norm = 1.2447e-01, time/batch = 6.3037s	
11259/33250 (epoch 16.931), train_loss = 1.08313170, grad/param norm = 1.5582e-01, time/batch = 15.6764s	
11260/33250 (epoch 16.932), train_loss = 1.00545440, grad/param norm = 1.5829e-01, time/batch = 15.7483s	
11261/33250 (epoch 16.934), train_loss = 0.92318127, grad/param norm = 1.3739e-01, time/batch = 16.1209s	
11262/33250 (epoch 16.935), train_loss = 0.91294050, grad/param norm = 1.5837e-01, time/batch = 16.7067s	
11263/33250 (epoch 16.937), train_loss = 0.97654482, grad/param norm = 1.5441e-01, time/batch = 16.7104s	
11264/33250 (epoch 16.938), train_loss = 1.01025120, grad/param norm = 1.5826e-01, time/batch = 17.2093s	
11265/33250 (epoch 16.940), train_loss = 0.96924290, grad/param norm = 1.5727e-01, time/batch = 18.4368s	
11266/33250 (epoch 16.941), train_loss = 1.03808776, grad/param norm = 1.5145e-01, time/batch = 15.4397s	
11267/33250 (epoch 16.943), train_loss = 1.11341657, grad/param norm = 1.5204e-01, time/batch = 15.7880s	
11268/33250 (epoch 16.944), train_loss = 0.92106486, grad/param norm = 1.4468e-01, time/batch = 15.7610s	
11269/33250 (epoch 16.946), train_loss = 1.08807434, grad/param norm = 1.4343e-01, time/batch = 14.9554s	
11270/33250 (epoch 16.947), train_loss = 0.89955716, grad/param norm = 1.4578e-01, time/batch = 14.8686s	
11271/33250 (epoch 16.949), train_loss = 1.08774056, grad/param norm = 1.6518e-01, time/batch = 15.2928s	
11272/33250 (epoch 16.950), train_loss = 1.02997826, grad/param norm = 1.4233e-01, time/batch = 15.1940s	
11273/33250 (epoch 16.952), train_loss = 0.96987347, grad/param norm = 1.8123e-01, time/batch = 16.8607s	
11274/33250 (epoch 16.953), train_loss = 1.07697189, grad/param norm = 1.5578e-01, time/batch = 18.2912s	
11275/33250 (epoch 16.955), train_loss = 1.10663627, grad/param norm = 1.6055e-01, time/batch = 16.2861s	
11276/33250 (epoch 16.956), train_loss = 1.03501450, grad/param norm = 1.7271e-01, time/batch = 15.6434s	
11277/33250 (epoch 16.958), train_loss = 0.89731544, grad/param norm = 1.3863e-01, time/batch = 14.8691s	
11278/33250 (epoch 16.959), train_loss = 0.94147620, grad/param norm = 1.4612e-01, time/batch = 15.9457s	
11279/33250 (epoch 16.961), train_loss = 1.18728082, grad/param norm = 1.5417e-01, time/batch = 15.2806s	
11280/33250 (epoch 16.962), train_loss = 1.01177447, grad/param norm = 1.5121e-01, time/batch = 15.0367s	
11281/33250 (epoch 16.964), train_loss = 1.17537022, grad/param norm = 1.6682e-01, time/batch = 16.1138s	
11282/33250 (epoch 16.965), train_loss = 1.07400763, grad/param norm = 1.7021e-01, time/batch = 15.3404s	
11283/33250 (epoch 16.967), train_loss = 1.00874131, grad/param norm = 1.5999e-01, time/batch = 16.0874s	
11284/33250 (epoch 16.968), train_loss = 1.16962828, grad/param norm = 1.4624e-01, time/batch = 15.1970s	
11285/33250 (epoch 16.970), train_loss = 1.28326602, grad/param norm = 2.1923e-01, time/batch = 15.5231s	
11286/33250 (epoch 16.971), train_loss = 1.14505834, grad/param norm = 1.7588e-01, time/batch = 16.8566s	
11287/33250 (epoch 16.973), train_loss = 0.97067238, grad/param norm = 1.4714e-01, time/batch = 15.1885s	
11288/33250 (epoch 16.974), train_loss = 1.07889823, grad/param norm = 1.6071e-01, time/batch = 15.9362s	
11289/33250 (epoch 16.976), train_loss = 0.97141604, grad/param norm = 1.6376e-01, time/batch = 16.1141s	
11290/33250 (epoch 16.977), train_loss = 0.93923139, grad/param norm = 1.5891e-01, time/batch = 15.7747s	
11291/33250 (epoch 16.979), train_loss = 1.03357227, grad/param norm = 1.5550e-01, time/batch = 16.5995s	
11292/33250 (epoch 16.980), train_loss = 1.01318596, grad/param norm = 1.4244e-01, time/batch = 17.3496s	
11293/33250 (epoch 16.982), train_loss = 0.89531460, grad/param norm = 1.3555e-01, time/batch = 17.7561s	
11294/33250 (epoch 16.983), train_loss = 1.03907162, grad/param norm = 1.6371e-01, time/batch = 15.6111s	
11295/33250 (epoch 16.985), train_loss = 0.95700489, grad/param norm = 1.7127e-01, time/batch = 18.7576s	
11296/33250 (epoch 16.986), train_loss = 1.08813868, grad/param norm = 1.6169e-01, time/batch = 17.1300s	
11297/33250 (epoch 16.988), train_loss = 1.12659517, grad/param norm = 1.6196e-01, time/batch = 15.5138s	
11298/33250 (epoch 16.989), train_loss = 1.08666395, grad/param norm = 1.6359e-01, time/batch = 15.3576s	
11299/33250 (epoch 16.991), train_loss = 1.03705874, grad/param norm = 1.5745e-01, time/batch = 16.7333s	
11300/33250 (epoch 16.992), train_loss = 0.97282273, grad/param norm = 1.6874e-01, time/batch = 15.7932s	
11301/33250 (epoch 16.994), train_loss = 0.92469259, grad/param norm = 1.3645e-01, time/batch = 15.3030s	
11302/33250 (epoch 16.995), train_loss = 0.98313744, grad/param norm = 1.8396e-01, time/batch = 15.6128s	
11303/33250 (epoch 16.997), train_loss = 0.74378264, grad/param norm = 1.3739e-01, time/batch = 17.1830s	
11304/33250 (epoch 16.998), train_loss = 1.02213995, grad/param norm = 1.3830e-01, time/batch = 18.2692s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
11305/33250 (epoch 17.000), train_loss = 1.01668605, grad/param norm = 1.6060e-01, time/batch = 16.2052s	
11306/33250 (epoch 17.002), train_loss = 1.18362849, grad/param norm = 1.7099e-01, time/batch = 17.1078s	
11307/33250 (epoch 17.003), train_loss = 1.09969861, grad/param norm = 1.8017e-01, time/batch = 18.0249s	
11308/33250 (epoch 17.005), train_loss = 0.80765100, grad/param norm = 1.3633e-01, time/batch = 15.4349s	
11309/33250 (epoch 17.006), train_loss = 0.86309423, grad/param norm = 1.3503e-01, time/batch = 15.4250s	
11310/33250 (epoch 17.008), train_loss = 1.15252348, grad/param norm = 1.5022e-01, time/batch = 15.8222s	
11311/33250 (epoch 17.009), train_loss = 1.15190442, grad/param norm = 1.6882e-01, time/batch = 14.8475s	
11312/33250 (epoch 17.011), train_loss = 0.90469622, grad/param norm = 1.4792e-01, time/batch = 14.9396s	
11313/33250 (epoch 17.012), train_loss = 1.02681372, grad/param norm = 1.9026e-01, time/batch = 14.9335s	
11314/33250 (epoch 17.014), train_loss = 1.13393524, grad/param norm = 1.9335e-01, time/batch = 15.1125s	
11315/33250 (epoch 17.015), train_loss = 0.99416033, grad/param norm = 1.4441e-01, time/batch = 15.3683s	
11316/33250 (epoch 17.017), train_loss = 1.02547180, grad/param norm = 1.8151e-01, time/batch = 16.1025s	
11317/33250 (epoch 17.018), train_loss = 0.82203512, grad/param norm = 1.4091e-01, time/batch = 17.4664s	
11318/33250 (epoch 17.020), train_loss = 0.99622774, grad/param norm = 1.4851e-01, time/batch = 15.3712s	
11319/33250 (epoch 17.021), train_loss = 1.01907143, grad/param norm = 1.5588e-01, time/batch = 15.4339s	
11320/33250 (epoch 17.023), train_loss = 0.84275407, grad/param norm = 1.6900e-01, time/batch = 15.2768s	
11321/33250 (epoch 17.024), train_loss = 1.09213996, grad/param norm = 1.6475e-01, time/batch = 16.2709s	
11322/33250 (epoch 17.026), train_loss = 0.99856890, grad/param norm = 1.4231e-01, time/batch = 15.4543s	
11323/33250 (epoch 17.027), train_loss = 0.98360054, grad/param norm = 1.4235e-01, time/batch = 15.4631s	
11324/33250 (epoch 17.029), train_loss = 1.01727853, grad/param norm = 1.4836e-01, time/batch = 15.4453s	
11325/33250 (epoch 17.030), train_loss = 1.00014360, grad/param norm = 1.6247e-01, time/batch = 15.5013s	
11326/33250 (epoch 17.032), train_loss = 1.22035120, grad/param norm = 1.7246e-01, time/batch = 18.1832s	
11327/33250 (epoch 17.033), train_loss = 0.95280084, grad/param norm = 1.7980e-01, time/batch = 17.8616s	
11328/33250 (epoch 17.035), train_loss = 0.96014078, grad/param norm = 1.6773e-01, time/batch = 17.8691s	
11329/33250 (epoch 17.036), train_loss = 1.07226717, grad/param norm = 1.6652e-01, time/batch = 16.6212s	
11330/33250 (epoch 17.038), train_loss = 0.99015113, grad/param norm = 1.3731e-01, time/batch = 15.7706s	
11331/33250 (epoch 17.039), train_loss = 0.89849935, grad/param norm = 1.3959e-01, time/batch = 29.8037s	
11332/33250 (epoch 17.041), train_loss = 1.03206438, grad/param norm = 1.7819e-01, time/batch = 15.8592s	
11333/33250 (epoch 17.042), train_loss = 0.83681379, grad/param norm = 1.3703e-01, time/batch = 15.7188s	
11334/33250 (epoch 17.044), train_loss = 1.15539597, grad/param norm = 1.6764e-01, time/batch = 15.3322s	
11335/33250 (epoch 17.045), train_loss = 1.09481589, grad/param norm = 1.4478e-01, time/batch = 14.8046s	
11336/33250 (epoch 17.047), train_loss = 1.04788464, grad/param norm = 1.6376e-01, time/batch = 14.0757s	
11337/33250 (epoch 17.048), train_loss = 1.14503443, grad/param norm = 1.8480e-01, time/batch = 14.3792s	
11338/33250 (epoch 17.050), train_loss = 1.01164385, grad/param norm = 1.5291e-01, time/batch = 15.3335s	
11339/33250 (epoch 17.051), train_loss = 0.98824903, grad/param norm = 1.5383e-01, time/batch = 14.8408s	
11340/33250 (epoch 17.053), train_loss = 1.01840755, grad/param norm = 1.7175e-01, time/batch = 14.4769s	
11341/33250 (epoch 17.054), train_loss = 0.84667493, grad/param norm = 1.3603e-01, time/batch = 14.7980s	
11342/33250 (epoch 17.056), train_loss = 0.90889909, grad/param norm = 1.4320e-01, time/batch = 15.2393s	
11343/33250 (epoch 17.057), train_loss = 1.07529014, grad/param norm = 1.4036e-01, time/batch = 14.8700s	
11344/33250 (epoch 17.059), train_loss = 0.98085733, grad/param norm = 1.5426e-01, time/batch = 14.9399s	
11345/33250 (epoch 17.060), train_loss = 1.03760366, grad/param norm = 1.6211e-01, time/batch = 14.6434s	
11346/33250 (epoch 17.062), train_loss = 1.12585448, grad/param norm = 1.5911e-01, time/batch = 15.5655s	
11347/33250 (epoch 17.063), train_loss = 1.14090837, grad/param norm = 1.6947e-01, time/batch = 14.8768s	
11348/33250 (epoch 17.065), train_loss = 0.99361901, grad/param norm = 1.4737e-01, time/batch = 14.5645s	
11349/33250 (epoch 17.066), train_loss = 1.06287143, grad/param norm = 1.5580e-01, time/batch = 14.6493s	
11350/33250 (epoch 17.068), train_loss = 0.95392756, grad/param norm = 1.4995e-01, time/batch = 15.1053s	
11351/33250 (epoch 17.069), train_loss = 1.01225149, grad/param norm = 1.4853e-01, time/batch = 14.6309s	
11352/33250 (epoch 17.071), train_loss = 0.90763655, grad/param norm = 1.3998e-01, time/batch = 14.8699s	
11353/33250 (epoch 17.072), train_loss = 0.90606909, grad/param norm = 1.3020e-01, time/batch = 15.0225s	
11354/33250 (epoch 17.074), train_loss = 1.05391739, grad/param norm = 1.5332e-01, time/batch = 14.5231s	
11355/33250 (epoch 17.075), train_loss = 0.93895348, grad/param norm = 1.5094e-01, time/batch = 14.9297s	
11356/33250 (epoch 17.077), train_loss = 0.99670772, grad/param norm = 1.5106e-01, time/batch = 14.7951s	
11357/33250 (epoch 17.078), train_loss = 1.01152087, grad/param norm = 1.4247e-01, time/batch = 14.8801s	
11358/33250 (epoch 17.080), train_loss = 1.01458966, grad/param norm = 1.7392e-01, time/batch = 14.8771s	
11359/33250 (epoch 17.081), train_loss = 1.04145575, grad/param norm = 1.5417e-01, time/batch = 14.8811s	
11360/33250 (epoch 17.083), train_loss = 1.09841956, grad/param norm = 1.3725e-01, time/batch = 14.6548s	
11361/33250 (epoch 17.084), train_loss = 1.00742896, grad/param norm = 1.5224e-01, time/batch = 14.7259s	
11362/33250 (epoch 17.086), train_loss = 0.95533460, grad/param norm = 1.3161e-01, time/batch = 14.7927s	
11363/33250 (epoch 17.087), train_loss = 0.88416533, grad/param norm = 1.3955e-01, time/batch = 14.5600s	
11364/33250 (epoch 17.089), train_loss = 1.04606888, grad/param norm = 1.5007e-01, time/batch = 14.6382s	
11365/33250 (epoch 17.090), train_loss = 1.01693489, grad/param norm = 1.4771e-01, time/batch = 15.6439s	
11366/33250 (epoch 17.092), train_loss = 0.92269239, grad/param norm = 1.2918e-01, time/batch = 15.0140s	
11367/33250 (epoch 17.093), train_loss = 1.03353415, grad/param norm = 1.5264e-01, time/batch = 14.5347s	
11368/33250 (epoch 17.095), train_loss = 0.93632783, grad/param norm = 1.3849e-01, time/batch = 14.8666s	
11369/33250 (epoch 17.096), train_loss = 0.85230625, grad/param norm = 1.5475e-01, time/batch = 14.1609s	
11370/33250 (epoch 17.098), train_loss = 0.86977860, grad/param norm = 1.5435e-01, time/batch = 14.9448s	
11371/33250 (epoch 17.099), train_loss = 0.74671128, grad/param norm = 1.2129e-01, time/batch = 14.6354s	
11372/33250 (epoch 17.101), train_loss = 0.99088858, grad/param norm = 1.5636e-01, time/batch = 14.4646s	
11373/33250 (epoch 17.102), train_loss = 0.89447942, grad/param norm = 1.4697e-01, time/batch = 14.8587s	
11374/33250 (epoch 17.104), train_loss = 0.77814228, grad/param norm = 1.2836e-01, time/batch = 14.8638s	
11375/33250 (epoch 17.105), train_loss = 0.92697609, grad/param norm = 1.4186e-01, time/batch = 15.0021s	
11376/33250 (epoch 17.107), train_loss = 0.82146498, grad/param norm = 1.3257e-01, time/batch = 14.8763s	
11377/33250 (epoch 17.108), train_loss = 0.97036773, grad/param norm = 1.4706e-01, time/batch = 14.5522s	
11378/33250 (epoch 17.110), train_loss = 0.81272697, grad/param norm = 1.4078e-01, time/batch = 14.8580s	
11379/33250 (epoch 17.111), train_loss = 0.95318280, grad/param norm = 1.4295e-01, time/batch = 14.6297s	
11380/33250 (epoch 17.113), train_loss = 0.95488445, grad/param norm = 1.6757e-01, time/batch = 14.7079s	
11381/33250 (epoch 17.114), train_loss = 0.88829301, grad/param norm = 1.6105e-01, time/batch = 14.5015s	
11382/33250 (epoch 17.116), train_loss = 0.97456169, grad/param norm = 1.4674e-01, time/batch = 15.4172s	
11383/33250 (epoch 17.117), train_loss = 0.95133296, grad/param norm = 1.4386e-01, time/batch = 15.4073s	
11384/33250 (epoch 17.119), train_loss = 0.93767426, grad/param norm = 1.4778e-01, time/batch = 15.1703s	
11385/33250 (epoch 17.120), train_loss = 0.76079611, grad/param norm = 1.3786e-01, time/batch = 14.9437s	
11386/33250 (epoch 17.122), train_loss = 1.09269220, grad/param norm = 1.5612e-01, time/batch = 15.4105s	
11387/33250 (epoch 17.123), train_loss = 1.00005990, grad/param norm = 1.5708e-01, time/batch = 15.6961s	
11388/33250 (epoch 17.125), train_loss = 0.81918160, grad/param norm = 1.5708e-01, time/batch = 15.3505s	
11389/33250 (epoch 17.126), train_loss = 0.97053983, grad/param norm = 1.5529e-01, time/batch = 15.1162s	
11390/33250 (epoch 17.128), train_loss = 0.90112989, grad/param norm = 1.3213e-01, time/batch = 15.6547s	
11391/33250 (epoch 17.129), train_loss = 0.95748356, grad/param norm = 1.5004e-01, time/batch = 14.8750s	
11392/33250 (epoch 17.131), train_loss = 0.94448915, grad/param norm = 1.4783e-01, time/batch = 14.8163s	
11393/33250 (epoch 17.132), train_loss = 0.96662593, grad/param norm = 1.5879e-01, time/batch = 15.0293s	
11394/33250 (epoch 17.134), train_loss = 0.97867811, grad/param norm = 1.5090e-01, time/batch = 15.3709s	
11395/33250 (epoch 17.135), train_loss = 0.99605516, grad/param norm = 1.4517e-01, time/batch = 15.0649s	
11396/33250 (epoch 17.137), train_loss = 0.88021976, grad/param norm = 1.5079e-01, time/batch = 15.3303s	
11397/33250 (epoch 17.138), train_loss = 0.90489710, grad/param norm = 1.2722e-01, time/batch = 14.8579s	
11398/33250 (epoch 17.140), train_loss = 0.75726660, grad/param norm = 1.4525e-01, time/batch = 15.1589s	
11399/33250 (epoch 17.141), train_loss = 1.15330480, grad/param norm = 1.9132e-01, time/batch = 14.6775s	
11400/33250 (epoch 17.143), train_loss = 0.79262355, grad/param norm = 1.6987e-01, time/batch = 14.3830s	
11401/33250 (epoch 17.144), train_loss = 0.94023142, grad/param norm = 1.4630e-01, time/batch = 14.8070s	
11402/33250 (epoch 17.146), train_loss = 0.93234856, grad/param norm = 1.4370e-01, time/batch = 15.0307s	
11403/33250 (epoch 17.147), train_loss = 0.90021750, grad/param norm = 1.4833e-01, time/batch = 14.7278s	
11404/33250 (epoch 17.149), train_loss = 0.91903198, grad/param norm = 1.4545e-01, time/batch = 14.6605s	
11405/33250 (epoch 17.150), train_loss = 0.87706886, grad/param norm = 1.3867e-01, time/batch = 14.4246s	
11406/33250 (epoch 17.152), train_loss = 0.82557385, grad/param norm = 1.3752e-01, time/batch = 15.0505s	
11407/33250 (epoch 17.153), train_loss = 1.12555567, grad/param norm = 1.5160e-01, time/batch = 15.2367s	
11408/33250 (epoch 17.155), train_loss = 0.95076755, grad/param norm = 1.5785e-01, time/batch = 15.0142s	
11409/33250 (epoch 17.156), train_loss = 1.15379399, grad/param norm = 1.5338e-01, time/batch = 14.7963s	
11410/33250 (epoch 17.158), train_loss = 1.15827172, grad/param norm = 1.6582e-01, time/batch = 15.4195s	
11411/33250 (epoch 17.159), train_loss = 0.95250422, grad/param norm = 1.4534e-01, time/batch = 15.5807s	
11412/33250 (epoch 17.161), train_loss = 1.02741822, grad/param norm = 1.6046e-01, time/batch = 15.3572s	
11413/33250 (epoch 17.162), train_loss = 0.85151385, grad/param norm = 1.3204e-01, time/batch = 15.6639s	
11414/33250 (epoch 17.164), train_loss = 0.96058579, grad/param norm = 1.5544e-01, time/batch = 15.5333s	
11415/33250 (epoch 17.165), train_loss = 1.04661436, grad/param norm = 1.6121e-01, time/batch = 15.3966s	
11416/33250 (epoch 17.167), train_loss = 1.11920964, grad/param norm = 1.5509e-01, time/batch = 15.2861s	
11417/33250 (epoch 17.168), train_loss = 0.82522123, grad/param norm = 1.2607e-01, time/batch = 15.6660s	
11418/33250 (epoch 17.170), train_loss = 0.94815053, grad/param norm = 1.6993e-01, time/batch = 15.4395s	
11419/33250 (epoch 17.171), train_loss = 0.94030660, grad/param norm = 1.3591e-01, time/batch = 15.7989s	
11420/33250 (epoch 17.173), train_loss = 0.91344328, grad/param norm = 1.4011e-01, time/batch = 16.1007s	
11421/33250 (epoch 17.174), train_loss = 0.97467018, grad/param norm = 1.5683e-01, time/batch = 16.1720s	
11422/33250 (epoch 17.176), train_loss = 0.95056842, grad/param norm = 1.6458e-01, time/batch = 16.0913s	
11423/33250 (epoch 17.177), train_loss = 0.92983494, grad/param norm = 1.3182e-01, time/batch = 16.0200s	
11424/33250 (epoch 17.179), train_loss = 0.89110326, grad/param norm = 1.3452e-01, time/batch = 15.9691s	
11425/33250 (epoch 17.180), train_loss = 0.80814365, grad/param norm = 1.3560e-01, time/batch = 16.0297s	
11426/33250 (epoch 17.182), train_loss = 0.90099332, grad/param norm = 1.5743e-01, time/batch = 15.9697s	
11427/33250 (epoch 17.183), train_loss = 1.09734323, grad/param norm = 1.5808e-01, time/batch = 16.0310s	
11428/33250 (epoch 17.185), train_loss = 1.03464749, grad/param norm = 1.7044e-01, time/batch = 16.1075s	
11429/33250 (epoch 17.186), train_loss = 0.98607277, grad/param norm = 1.4547e-01, time/batch = 16.2245s	
11430/33250 (epoch 17.188), train_loss = 1.09457803, grad/param norm = 1.8605e-01, time/batch = 16.0840s	
11431/33250 (epoch 17.189), train_loss = 0.78997551, grad/param norm = 1.7016e-01, time/batch = 16.0285s	
11432/33250 (epoch 17.191), train_loss = 0.89571131, grad/param norm = 1.6335e-01, time/batch = 16.0495s	
11433/33250 (epoch 17.192), train_loss = 0.91298429, grad/param norm = 1.4718e-01, time/batch = 16.1652s	
11434/33250 (epoch 17.194), train_loss = 0.91791256, grad/param norm = 1.4808e-01, time/batch = 16.1989s	
11435/33250 (epoch 17.195), train_loss = 1.15034234, grad/param norm = 1.5646e-01, time/batch = 15.9077s	
11436/33250 (epoch 17.197), train_loss = 0.92100316, grad/param norm = 1.4488e-01, time/batch = 16.1012s	
11437/33250 (epoch 17.198), train_loss = 1.08381734, grad/param norm = 1.5262e-01, time/batch = 16.0513s	
11438/33250 (epoch 17.200), train_loss = 0.97263520, grad/param norm = 1.3858e-01, time/batch = 16.1129s	
11439/33250 (epoch 17.202), train_loss = 0.90324685, grad/param norm = 1.3904e-01, time/batch = 16.0016s	
11440/33250 (epoch 17.203), train_loss = 0.89726229, grad/param norm = 1.4932e-01, time/batch = 16.1730s	
11441/33250 (epoch 17.205), train_loss = 1.00529678, grad/param norm = 1.4863e-01, time/batch = 16.0928s	
11442/33250 (epoch 17.206), train_loss = 1.04953267, grad/param norm = 1.4825e-01, time/batch = 16.0119s	
11443/33250 (epoch 17.208), train_loss = 1.12647725, grad/param norm = 1.8410e-01, time/batch = 16.1405s	
11444/33250 (epoch 17.209), train_loss = 0.91654122, grad/param norm = 1.4759e-01, time/batch = 16.2123s	
11445/33250 (epoch 17.211), train_loss = 1.05151628, grad/param norm = 1.5309e-01, time/batch = 16.0568s	
11446/33250 (epoch 17.212), train_loss = 1.20754581, grad/param norm = 1.5802e-01, time/batch = 15.7903s	
11447/33250 (epoch 17.214), train_loss = 0.95028610, grad/param norm = 1.2775e-01, time/batch = 16.0960s	
11448/33250 (epoch 17.215), train_loss = 1.17222983, grad/param norm = 2.1121e-01, time/batch = 16.2328s	
11449/33250 (epoch 17.217), train_loss = 1.11669404, grad/param norm = 1.6924e-01, time/batch = 16.1038s	
11450/33250 (epoch 17.218), train_loss = 1.06775464, grad/param norm = 1.4358e-01, time/batch = 16.1641s	
11451/33250 (epoch 17.220), train_loss = 1.02916732, grad/param norm = 1.5772e-01, time/batch = 15.9103s	
11452/33250 (epoch 17.221), train_loss = 1.19775246, grad/param norm = 1.9232e-01, time/batch = 16.0264s	
11453/33250 (epoch 17.223), train_loss = 0.98575749, grad/param norm = 1.3633e-01, time/batch = 16.2185s	
11454/33250 (epoch 17.224), train_loss = 1.01901747, grad/param norm = 1.5036e-01, time/batch = 16.1420s	
11455/33250 (epoch 17.226), train_loss = 1.14793076, grad/param norm = 1.5650e-01, time/batch = 16.2036s	
11456/33250 (epoch 17.227), train_loss = 1.02001815, grad/param norm = 1.5470e-01, time/batch = 16.1713s	
11457/33250 (epoch 17.229), train_loss = 1.02260146, grad/param norm = 1.4441e-01, time/batch = 16.0449s	
11458/33250 (epoch 17.230), train_loss = 0.96096005, grad/param norm = 1.4261e-01, time/batch = 16.0174s	
11459/33250 (epoch 17.232), train_loss = 0.93555306, grad/param norm = 1.2925e-01, time/batch = 15.8320s	
11460/33250 (epoch 17.233), train_loss = 0.92695082, grad/param norm = 1.3786e-01, time/batch = 15.8197s	
11461/33250 (epoch 17.235), train_loss = 1.14061566, grad/param norm = 1.4431e-01, time/batch = 15.9672s	
11462/33250 (epoch 17.236), train_loss = 0.92864684, grad/param norm = 1.4929e-01, time/batch = 16.1181s	
11463/33250 (epoch 17.238), train_loss = 1.09288969, grad/param norm = 1.6885e-01, time/batch = 15.9901s	
11464/33250 (epoch 17.239), train_loss = 1.14888235, grad/param norm = 1.8407e-01, time/batch = 15.8298s	
11465/33250 (epoch 17.241), train_loss = 1.09262752, grad/param norm = 1.7519e-01, time/batch = 16.0479s	
11466/33250 (epoch 17.242), train_loss = 1.06737862, grad/param norm = 1.7188e-01, time/batch = 8.5116s	
11467/33250 (epoch 17.244), train_loss = 1.09551642, grad/param norm = 1.8466e-01, time/batch = 0.7082s	
11468/33250 (epoch 17.245), train_loss = 0.99838154, grad/param norm = 1.5047e-01, time/batch = 0.7040s	
11469/33250 (epoch 17.247), train_loss = 1.02266207, grad/param norm = 1.5011e-01, time/batch = 0.7083s	
11470/33250 (epoch 17.248), train_loss = 1.21867457, grad/param norm = 1.8620e-01, time/batch = 0.7039s	
11471/33250 (epoch 17.250), train_loss = 1.06810224, grad/param norm = 1.3571e-01, time/batch = 0.7371s	
11472/33250 (epoch 17.251), train_loss = 0.99914676, grad/param norm = 1.5880e-01, time/batch = 0.7441s	
11473/33250 (epoch 17.253), train_loss = 0.92160701, grad/param norm = 1.2750e-01, time/batch = 0.9103s	
11474/33250 (epoch 17.254), train_loss = 0.93821064, grad/param norm = 1.5190e-01, time/batch = 1.0500s	
11475/33250 (epoch 17.256), train_loss = 0.98711798, grad/param norm = 1.3960e-01, time/batch = 1.0531s	
11476/33250 (epoch 17.257), train_loss = 1.13580706, grad/param norm = 1.5358e-01, time/batch = 1.0510s	
11477/33250 (epoch 17.259), train_loss = 1.07031729, grad/param norm = 1.5392e-01, time/batch = 1.0571s	
11478/33250 (epoch 17.260), train_loss = 0.89215339, grad/param norm = 1.5076e-01, time/batch = 1.8706s	
11479/33250 (epoch 17.262), train_loss = 1.02443839, grad/param norm = 1.4561e-01, time/batch = 1.9832s	
11480/33250 (epoch 17.263), train_loss = 0.91500423, grad/param norm = 1.4579e-01, time/batch = 6.5423s	
11481/33250 (epoch 17.265), train_loss = 1.06682511, grad/param norm = 1.5455e-01, time/batch = 16.1406s	
11482/33250 (epoch 17.266), train_loss = 0.98326298, grad/param norm = 1.6007e-01, time/batch = 15.8750s	
11483/33250 (epoch 17.268), train_loss = 0.92000167, grad/param norm = 1.4058e-01, time/batch = 16.1796s	
11484/33250 (epoch 17.269), train_loss = 0.80617724, grad/param norm = 1.4678e-01, time/batch = 15.9553s	
11485/33250 (epoch 17.271), train_loss = 0.97054207, grad/param norm = 1.3544e-01, time/batch = 16.1203s	
11486/33250 (epoch 17.272), train_loss = 0.86222116, grad/param norm = 1.2798e-01, time/batch = 16.0538s	
11487/33250 (epoch 17.274), train_loss = 0.75997965, grad/param norm = 1.3328e-01, time/batch = 16.0656s	
11488/33250 (epoch 17.275), train_loss = 0.90587264, grad/param norm = 1.3331e-01, time/batch = 15.9692s	
11489/33250 (epoch 17.277), train_loss = 0.78137262, grad/param norm = 1.3347e-01, time/batch = 15.9638s	
11490/33250 (epoch 17.278), train_loss = 0.91356393, grad/param norm = 1.4781e-01, time/batch = 15.9604s	
11491/33250 (epoch 17.280), train_loss = 0.87373758, grad/param norm = 1.2835e-01, time/batch = 16.1697s	
11492/33250 (epoch 17.281), train_loss = 1.01427681, grad/param norm = 1.5126e-01, time/batch = 16.0808s	
11493/33250 (epoch 17.283), train_loss = 1.03827332, grad/param norm = 1.9279e-01, time/batch = 15.9036s	
11494/33250 (epoch 17.284), train_loss = 0.90061227, grad/param norm = 1.6961e-01, time/batch = 16.0392s	
11495/33250 (epoch 17.286), train_loss = 1.05543003, grad/param norm = 1.5866e-01, time/batch = 15.8799s	
11496/33250 (epoch 17.287), train_loss = 0.85031223, grad/param norm = 1.3396e-01, time/batch = 15.9622s	
11497/33250 (epoch 17.289), train_loss = 0.80763942, grad/param norm = 1.4575e-01, time/batch = 16.1223s	
11498/33250 (epoch 17.290), train_loss = 0.97378534, grad/param norm = 1.2994e-01, time/batch = 16.0735s	
11499/33250 (epoch 17.292), train_loss = 1.02035420, grad/param norm = 1.6649e-01, time/batch = 16.1455s	
11500/33250 (epoch 17.293), train_loss = 1.08898546, grad/param norm = 1.6071e-01, time/batch = 16.0772s	
11501/33250 (epoch 17.295), train_loss = 1.03778997, grad/param norm = 1.5214e-01, time/batch = 16.2374s	
11502/33250 (epoch 17.296), train_loss = 1.02066901, grad/param norm = 1.5368e-01, time/batch = 16.0868s	
11503/33250 (epoch 17.298), train_loss = 0.82575965, grad/param norm = 1.2443e-01, time/batch = 16.0309s	
11504/33250 (epoch 17.299), train_loss = 0.77551192, grad/param norm = 1.3551e-01, time/batch = 15.9971s	
11505/33250 (epoch 17.301), train_loss = 1.01978785, grad/param norm = 1.3947e-01, time/batch = 15.9245s	
11506/33250 (epoch 17.302), train_loss = 1.03475614, grad/param norm = 1.6691e-01, time/batch = 15.9901s	
11507/33250 (epoch 17.304), train_loss = 0.88840432, grad/param norm = 1.4558e-01, time/batch = 15.9960s	
11508/33250 (epoch 17.305), train_loss = 0.94868890, grad/param norm = 1.3728e-01, time/batch = 16.0872s	
11509/33250 (epoch 17.307), train_loss = 1.05555277, grad/param norm = 1.5572e-01, time/batch = 15.9069s	
11510/33250 (epoch 17.308), train_loss = 1.18764011, grad/param norm = 1.7493e-01, time/batch = 16.1920s	
11511/33250 (epoch 17.310), train_loss = 0.98217679, grad/param norm = 1.5870e-01, time/batch = 16.0405s	
11512/33250 (epoch 17.311), train_loss = 1.10510788, grad/param norm = 1.5152e-01, time/batch = 16.0165s	
11513/33250 (epoch 17.313), train_loss = 0.83043533, grad/param norm = 1.3822e-01, time/batch = 16.0986s	
11514/33250 (epoch 17.314), train_loss = 0.97186613, grad/param norm = 1.3723e-01, time/batch = 15.8169s	
11515/33250 (epoch 17.316), train_loss = 1.16670986, grad/param norm = 1.6576e-01, time/batch = 15.6754s	
11516/33250 (epoch 17.317), train_loss = 0.87936796, grad/param norm = 1.3608e-01, time/batch = 15.8477s	
11517/33250 (epoch 17.319), train_loss = 1.06911028, grad/param norm = 1.8706e-01, time/batch = 16.0809s	
11518/33250 (epoch 17.320), train_loss = 1.09467354, grad/param norm = 1.8975e-01, time/batch = 15.9143s	
11519/33250 (epoch 17.322), train_loss = 1.16564343, grad/param norm = 1.7525e-01, time/batch = 15.9179s	
11520/33250 (epoch 17.323), train_loss = 1.23652710, grad/param norm = 2.0850e-01, time/batch = 17.0125s	
11521/33250 (epoch 17.325), train_loss = 1.01500608, grad/param norm = 1.7614e-01, time/batch = 16.5225s	
11522/33250 (epoch 17.326), train_loss = 1.15181628, grad/param norm = 1.6510e-01, time/batch = 18.6192s	
11523/33250 (epoch 17.328), train_loss = 0.93908988, grad/param norm = 1.2957e-01, time/batch = 16.8590s	
11524/33250 (epoch 17.329), train_loss = 0.98683025, grad/param norm = 1.6270e-01, time/batch = 16.6983s	
11525/33250 (epoch 17.331), train_loss = 0.97736952, grad/param norm = 1.6433e-01, time/batch = 16.1873s	
11526/33250 (epoch 17.332), train_loss = 0.94727223, grad/param norm = 1.3988e-01, time/batch = 15.3643s	
11527/33250 (epoch 17.334), train_loss = 1.13246770, grad/param norm = 1.4500e-01, time/batch = 15.5079s	
11528/33250 (epoch 17.335), train_loss = 0.73621824, grad/param norm = 1.3593e-01, time/batch = 16.5076s	
11529/33250 (epoch 17.337), train_loss = 1.02652629, grad/param norm = 1.4118e-01, time/batch = 15.4365s	
11530/33250 (epoch 17.338), train_loss = 1.11409716, grad/param norm = 1.7703e-01, time/batch = 18.6131s	
11531/33250 (epoch 17.340), train_loss = 0.99551359, grad/param norm = 1.5287e-01, time/batch = 17.5162s	
11532/33250 (epoch 17.341), train_loss = 0.91780171, grad/param norm = 1.5066e-01, time/batch = 17.6935s	
11533/33250 (epoch 17.343), train_loss = 0.95040191, grad/param norm = 1.5491e-01, time/batch = 18.3584s	
11534/33250 (epoch 17.344), train_loss = 0.96993739, grad/param norm = 1.3826e-01, time/batch = 15.5721s	
11535/33250 (epoch 17.346), train_loss = 0.85192693, grad/param norm = 1.3442e-01, time/batch = 15.2904s	
11536/33250 (epoch 17.347), train_loss = 1.24443967, grad/param norm = 1.8004e-01, time/batch = 15.4641s	
11537/33250 (epoch 17.349), train_loss = 0.92871076, grad/param norm = 1.4458e-01, time/batch = 15.1821s	
11538/33250 (epoch 17.350), train_loss = 0.95205313, grad/param norm = 1.5203e-01, time/batch = 15.4282s	
11539/33250 (epoch 17.352), train_loss = 0.86170362, grad/param norm = 1.5273e-01, time/batch = 15.2655s	
11540/33250 (epoch 17.353), train_loss = 0.94410083, grad/param norm = 1.3216e-01, time/batch = 16.2591s	
11541/33250 (epoch 17.355), train_loss = 0.95354806, grad/param norm = 1.5848e-01, time/batch = 18.0207s	
11542/33250 (epoch 17.356), train_loss = 0.88725902, grad/param norm = 1.4525e-01, time/batch = 17.2955s	
11543/33250 (epoch 17.358), train_loss = 0.93059078, grad/param norm = 1.3799e-01, time/batch = 17.2872s	
11544/33250 (epoch 17.359), train_loss = 0.93362392, grad/param norm = 1.4214e-01, time/batch = 16.2847s	
11545/33250 (epoch 17.361), train_loss = 1.12985265, grad/param norm = 1.6306e-01, time/batch = 15.6957s	
11546/33250 (epoch 17.362), train_loss = 1.00120371, grad/param norm = 1.6869e-01, time/batch = 15.5187s	
11547/33250 (epoch 17.364), train_loss = 1.05032952, grad/param norm = 1.5677e-01, time/batch = 16.6965s	
11548/33250 (epoch 17.365), train_loss = 0.97429576, grad/param norm = 1.3508e-01, time/batch = 17.4390s	
11549/33250 (epoch 17.367), train_loss = 0.98294595, grad/param norm = 1.3436e-01, time/batch = 15.2606s	
11550/33250 (epoch 17.368), train_loss = 0.96562733, grad/param norm = 1.4666e-01, time/batch = 17.0286s	
11551/33250 (epoch 17.370), train_loss = 0.86310474, grad/param norm = 1.4040e-01, time/batch = 18.5329s	
11552/33250 (epoch 17.371), train_loss = 1.12440601, grad/param norm = 1.7876e-01, time/batch = 17.8605s	
11553/33250 (epoch 17.373), train_loss = 0.94717126, grad/param norm = 1.3008e-01, time/batch = 18.0132s	
11554/33250 (epoch 17.374), train_loss = 1.06291181, grad/param norm = 1.9023e-01, time/batch = 15.3769s	
11555/33250 (epoch 17.376), train_loss = 0.93300646, grad/param norm = 1.4679e-01, time/batch = 15.5344s	
11556/33250 (epoch 17.377), train_loss = 0.88721339, grad/param norm = 1.8653e-01, time/batch = 15.7624s	
11557/33250 (epoch 17.379), train_loss = 0.90548882, grad/param norm = 1.5880e-01, time/batch = 16.9494s	
11558/33250 (epoch 17.380), train_loss = 1.02341438, grad/param norm = 1.6920e-01, time/batch = 15.0920s	
11559/33250 (epoch 17.382), train_loss = 1.07415641, grad/param norm = 1.6341e-01, time/batch = 16.7671s	
11560/33250 (epoch 17.383), train_loss = 0.89410600, grad/param norm = 1.4907e-01, time/batch = 16.8613s	
11561/33250 (epoch 17.385), train_loss = 0.82934261, grad/param norm = 1.5653e-01, time/batch = 16.7682s	
11562/33250 (epoch 17.386), train_loss = 0.85860457, grad/param norm = 1.5403e-01, time/batch = 18.7856s	
11563/33250 (epoch 17.388), train_loss = 0.90072110, grad/param norm = 1.6351e-01, time/batch = 16.3004s	
11564/33250 (epoch 17.389), train_loss = 0.93645818, grad/param norm = 1.6111e-01, time/batch = 17.1182s	
11565/33250 (epoch 17.391), train_loss = 1.00953392, grad/param norm = 1.6980e-01, time/batch = 16.6874s	
11566/33250 (epoch 17.392), train_loss = 1.08981374, grad/param norm = 1.6732e-01, time/batch = 15.6073s	
11567/33250 (epoch 17.394), train_loss = 1.13963439, grad/param norm = 1.7862e-01, time/batch = 16.4420s	
11568/33250 (epoch 17.395), train_loss = 1.06884994, grad/param norm = 1.4142e-01, time/batch = 16.8580s	
11569/33250 (epoch 17.397), train_loss = 1.09387872, grad/param norm = 1.6557e-01, time/batch = 16.0989s	
11570/33250 (epoch 17.398), train_loss = 0.92431745, grad/param norm = 1.4445e-01, time/batch = 21.9315s	
11571/33250 (epoch 17.400), train_loss = 0.89015492, grad/param norm = 1.3886e-01, time/batch = 25.3496s	
11572/33250 (epoch 17.402), train_loss = 0.83654954, grad/param norm = 1.6539e-01, time/batch = 15.5161s	
11573/33250 (epoch 17.403), train_loss = 0.93205776, grad/param norm = 1.9364e-01, time/batch = 15.6041s	
11574/33250 (epoch 17.405), train_loss = 0.92278526, grad/param norm = 1.4823e-01, time/batch = 17.0982s	
11575/33250 (epoch 17.406), train_loss = 0.99194975, grad/param norm = 1.6361e-01, time/batch = 17.5182s	
11576/33250 (epoch 17.408), train_loss = 1.12563584, grad/param norm = 1.6543e-01, time/batch = 16.8488s	
11577/33250 (epoch 17.409), train_loss = 1.06503331, grad/param norm = 1.9145e-01, time/batch = 15.6851s	
11578/33250 (epoch 17.411), train_loss = 0.71868920, grad/param norm = 1.1880e-01, time/batch = 16.5196s	
11579/33250 (epoch 17.412), train_loss = 0.84448525, grad/param norm = 1.4482e-01, time/batch = 16.5098s	
11580/33250 (epoch 17.414), train_loss = 1.00118112, grad/param norm = 1.4095e-01, time/batch = 15.6162s	
11581/33250 (epoch 17.415), train_loss = 1.08401768, grad/param norm = 1.5741e-01, time/batch = 17.1003s	
11582/33250 (epoch 17.417), train_loss = 1.05736013, grad/param norm = 1.5981e-01, time/batch = 18.0452s	
11583/33250 (epoch 17.418), train_loss = 1.21788018, grad/param norm = 1.8815e-01, time/batch = 18.0259s	
11584/33250 (epoch 17.420), train_loss = 1.10502257, grad/param norm = 1.6462e-01, time/batch = 16.0868s	
11585/33250 (epoch 17.421), train_loss = 0.92004462, grad/param norm = 1.7880e-01, time/batch = 17.6002s	
11586/33250 (epoch 17.423), train_loss = 1.05416733, grad/param norm = 1.7756e-01, time/batch = 16.4509s	
11587/33250 (epoch 17.424), train_loss = 1.19406582, grad/param norm = 2.3182e-01, time/batch = 15.9379s	
11588/33250 (epoch 17.426), train_loss = 0.90274301, grad/param norm = 1.3915e-01, time/batch = 16.0201s	
11589/33250 (epoch 17.427), train_loss = 0.91322265, grad/param norm = 1.4956e-01, time/batch = 16.4522s	
11590/33250 (epoch 17.429), train_loss = 1.04902950, grad/param norm = 1.7767e-01, time/batch = 16.2730s	
11591/33250 (epoch 17.430), train_loss = 0.91923822, grad/param norm = 1.7486e-01, time/batch = 16.0148s	
11592/33250 (epoch 17.432), train_loss = 1.00633179, grad/param norm = 1.3957e-01, time/batch = 18.6137s	
11593/33250 (epoch 17.433), train_loss = 0.92592421, grad/param norm = 1.4403e-01, time/batch = 17.1106s	
11594/33250 (epoch 17.435), train_loss = 1.06018728, grad/param norm = 1.8743e-01, time/batch = 16.1814s	
11595/33250 (epoch 17.436), train_loss = 0.91584010, grad/param norm = 1.5528e-01, time/batch = 16.2660s	
11596/33250 (epoch 17.438), train_loss = 1.03919097, grad/param norm = 1.3674e-01, time/batch = 16.3626s	
11597/33250 (epoch 17.439), train_loss = 1.00054537, grad/param norm = 1.4074e-01, time/batch = 17.3616s	
11598/33250 (epoch 17.441), train_loss = 0.96278114, grad/param norm = 1.2971e-01, time/batch = 15.6604s	
11599/33250 (epoch 17.442), train_loss = 0.89023134, grad/param norm = 1.5350e-01, time/batch = 15.5053s	
11600/33250 (epoch 17.444), train_loss = 0.89264717, grad/param norm = 1.3297e-01, time/batch = 18.6970s	
11601/33250 (epoch 17.445), train_loss = 0.97788397, grad/param norm = 1.5108e-01, time/batch = 17.2112s	
11602/33250 (epoch 17.447), train_loss = 1.01102342, grad/param norm = 1.5724e-01, time/batch = 16.5668s	
11603/33250 (epoch 17.448), train_loss = 0.96940587, grad/param norm = 1.3091e-01, time/batch = 17.9315s	
11604/33250 (epoch 17.450), train_loss = 1.15616163, grad/param norm = 1.7520e-01, time/batch = 17.5160s	
11605/33250 (epoch 17.451), train_loss = 1.03798772, grad/param norm = 1.5694e-01, time/batch = 15.7735s	
11606/33250 (epoch 17.453), train_loss = 0.89772881, grad/param norm = 1.3980e-01, time/batch = 16.0964s	
11607/33250 (epoch 17.454), train_loss = 1.14133006, grad/param norm = 1.6136e-01, time/batch = 15.6835s	
11608/33250 (epoch 17.456), train_loss = 1.13048815, grad/param norm = 1.4849e-01, time/batch = 15.2788s	
11609/33250 (epoch 17.457), train_loss = 0.93906195, grad/param norm = 1.5118e-01, time/batch = 15.5227s	
11610/33250 (epoch 17.459), train_loss = 0.99132005, grad/param norm = 1.4072e-01, time/batch = 17.8232s	
11611/33250 (epoch 17.460), train_loss = 1.07407380, grad/param norm = 1.6149e-01, time/batch = 17.7906s	
11612/33250 (epoch 17.462), train_loss = 0.91663710, grad/param norm = 1.4138e-01, time/batch = 17.2675s	
11613/33250 (epoch 17.463), train_loss = 0.91500655, grad/param norm = 1.4006e-01, time/batch = 16.7930s	
11614/33250 (epoch 17.465), train_loss = 0.81935024, grad/param norm = 1.2757e-01, time/batch = 16.7723s	
11615/33250 (epoch 17.466), train_loss = 0.76455459, grad/param norm = 1.1101e-01, time/batch = 17.4345s	
11616/33250 (epoch 17.468), train_loss = 0.88595764, grad/param norm = 1.2977e-01, time/batch = 15.2003s	
11617/33250 (epoch 17.469), train_loss = 0.97341838, grad/param norm = 1.5667e-01, time/batch = 15.9481s	
11618/33250 (epoch 17.471), train_loss = 1.06839246, grad/param norm = 1.4868e-01, time/batch = 17.4331s	
11619/33250 (epoch 17.472), train_loss = 0.96279083, grad/param norm = 1.7435e-01, time/batch = 16.1997s	
11620/33250 (epoch 17.474), train_loss = 1.12411903, grad/param norm = 1.7285e-01, time/batch = 17.2860s	
11621/33250 (epoch 17.475), train_loss = 1.00857612, grad/param norm = 1.4433e-01, time/batch = 17.4537s	
11622/33250 (epoch 17.477), train_loss = 0.97531380, grad/param norm = 1.4060e-01, time/batch = 18.2895s	
11623/33250 (epoch 17.478), train_loss = 0.90451509, grad/param norm = 1.5031e-01, time/batch = 15.5982s	
11624/33250 (epoch 17.480), train_loss = 1.19834289, grad/param norm = 1.6588e-01, time/batch = 16.4492s	
11625/33250 (epoch 17.481), train_loss = 0.99558856, grad/param norm = 1.4266e-01, time/batch = 15.1012s	
11626/33250 (epoch 17.483), train_loss = 1.01039062, grad/param norm = 1.4389e-01, time/batch = 15.1836s	
11627/33250 (epoch 17.484), train_loss = 0.89103524, grad/param norm = 1.4060e-01, time/batch = 15.0274s	
11628/33250 (epoch 17.486), train_loss = 0.82089681, grad/param norm = 1.4639e-01, time/batch = 16.0903s	
11629/33250 (epoch 17.487), train_loss = 0.93048721, grad/param norm = 1.5177e-01, time/batch = 14.9569s	
11630/33250 (epoch 17.489), train_loss = 1.07797736, grad/param norm = 1.7030e-01, time/batch = 16.7864s	
11631/33250 (epoch 17.490), train_loss = 1.01027566, grad/param norm = 1.5900e-01, time/batch = 16.4136s	
11632/33250 (epoch 17.492), train_loss = 1.04862960, grad/param norm = 1.7931e-01, time/batch = 16.8694s	
11633/33250 (epoch 17.493), train_loss = 0.97346394, grad/param norm = 1.4570e-01, time/batch = 18.3576s	
11634/33250 (epoch 17.495), train_loss = 1.01184612, grad/param norm = 1.5138e-01, time/batch = 15.2657s	
11635/33250 (epoch 17.496), train_loss = 0.96172024, grad/param norm = 1.2435e-01, time/batch = 17.5202s	
11636/33250 (epoch 17.498), train_loss = 1.07129537, grad/param norm = 1.6316e-01, time/batch = 17.1898s	
11637/33250 (epoch 17.499), train_loss = 0.94731615, grad/param norm = 1.4817e-01, time/batch = 16.8450s	
11638/33250 (epoch 17.501), train_loss = 0.92394898, grad/param norm = 1.5846e-01, time/batch = 15.1918s	
11639/33250 (epoch 17.502), train_loss = 0.93775407, grad/param norm = 1.2942e-01, time/batch = 16.4451s	
11640/33250 (epoch 17.504), train_loss = 1.10967935, grad/param norm = 1.5955e-01, time/batch = 18.2834s	
11641/33250 (epoch 17.505), train_loss = 0.79599064, grad/param norm = 1.2168e-01, time/batch = 17.0968s	
11642/33250 (epoch 17.507), train_loss = 0.93859455, grad/param norm = 1.4754e-01, time/batch = 18.3010s	
11643/33250 (epoch 17.508), train_loss = 0.93170125, grad/param norm = 1.5534e-01, time/batch = 16.2165s	
11644/33250 (epoch 17.510), train_loss = 0.79923089, grad/param norm = 1.2891e-01, time/batch = 15.4336s	
11645/33250 (epoch 17.511), train_loss = 0.98980890, grad/param norm = 1.5303e-01, time/batch = 15.6054s	
11646/33250 (epoch 17.513), train_loss = 1.11621924, grad/param norm = 1.5397e-01, time/batch = 17.3504s	
11647/33250 (epoch 17.514), train_loss = 0.92495611, grad/param norm = 1.3985e-01, time/batch = 17.5885s	
11648/33250 (epoch 17.516), train_loss = 0.91936842, grad/param norm = 1.4130e-01, time/batch = 15.5981s	
11649/33250 (epoch 17.517), train_loss = 0.96130893, grad/param norm = 1.5348e-01, time/batch = 15.6181s	
11650/33250 (epoch 17.519), train_loss = 0.85507548, grad/param norm = 1.2619e-01, time/batch = 17.9474s	
11651/33250 (epoch 17.520), train_loss = 1.21000823, grad/param norm = 1.7233e-01, time/batch = 17.4526s	
11652/33250 (epoch 17.522), train_loss = 1.04115394, grad/param norm = 1.4587e-01, time/batch = 17.2855s	
11653/33250 (epoch 17.523), train_loss = 0.90654184, grad/param norm = 1.3635e-01, time/batch = 17.7967s	
11654/33250 (epoch 17.525), train_loss = 0.86118679, grad/param norm = 1.6251e-01, time/batch = 16.3613s	
11655/33250 (epoch 17.526), train_loss = 0.83951273, grad/param norm = 1.3923e-01, time/batch = 15.8437s	
11656/33250 (epoch 17.528), train_loss = 0.94383687, grad/param norm = 1.4408e-01, time/batch = 16.2014s	
11657/33250 (epoch 17.529), train_loss = 0.89936603, grad/param norm = 1.5294e-01, time/batch = 16.2612s	
11658/33250 (epoch 17.531), train_loss = 0.86635347, grad/param norm = 1.2811e-01, time/batch = 16.6911s	
11659/33250 (epoch 17.532), train_loss = 1.03778128, grad/param norm = 1.4417e-01, time/batch = 15.5872s	
11660/33250 (epoch 17.534), train_loss = 0.87516834, grad/param norm = 1.2675e-01, time/batch = 15.6091s	
11661/33250 (epoch 17.535), train_loss = 0.94978266, grad/param norm = 1.3366e-01, time/batch = 17.3019s	
11662/33250 (epoch 17.537), train_loss = 1.02794192, grad/param norm = 1.4539e-01, time/batch = 15.9462s	
11663/33250 (epoch 17.538), train_loss = 1.06542405, grad/param norm = 1.7104e-01, time/batch = 16.7790s	
11664/33250 (epoch 17.540), train_loss = 1.12762454, grad/param norm = 1.3858e-01, time/batch = 17.0321s	
11665/33250 (epoch 17.541), train_loss = 1.07669423, grad/param norm = 1.5647e-01, time/batch = 15.6264s	
11666/33250 (epoch 17.543), train_loss = 1.04731546, grad/param norm = 1.4221e-01, time/batch = 15.7815s	
11667/33250 (epoch 17.544), train_loss = 0.91332218, grad/param norm = 1.5293e-01, time/batch = 15.6245s	
11668/33250 (epoch 17.546), train_loss = 0.96238525, grad/param norm = 1.7743e-01, time/batch = 17.6816s	
11669/33250 (epoch 17.547), train_loss = 0.93595142, grad/param norm = 1.4956e-01, time/batch = 16.8635s	
11670/33250 (epoch 17.549), train_loss = 1.03578718, grad/param norm = 1.5408e-01, time/batch = 15.4894s	
11671/33250 (epoch 17.550), train_loss = 0.93651575, grad/param norm = 1.4908e-01, time/batch = 17.6200s	
11672/33250 (epoch 17.552), train_loss = 1.00902229, grad/param norm = 1.4907e-01, time/batch = 17.0458s	
11673/33250 (epoch 17.553), train_loss = 0.89101866, grad/param norm = 1.3382e-01, time/batch = 17.2850s	
11674/33250 (epoch 17.555), train_loss = 1.00679065, grad/param norm = 1.4230e-01, time/batch = 17.2740s	
11675/33250 (epoch 17.556), train_loss = 1.09329454, grad/param norm = 1.6923e-01, time/batch = 15.8640s	
11676/33250 (epoch 17.558), train_loss = 1.08150127, grad/param norm = 1.5654e-01, time/batch = 16.5916s	
11677/33250 (epoch 17.559), train_loss = 0.88495903, grad/param norm = 1.3800e-01, time/batch = 15.9294s	
11678/33250 (epoch 17.561), train_loss = 0.88505307, grad/param norm = 1.3825e-01, time/batch = 15.1122s	
11679/33250 (epoch 17.562), train_loss = 1.09358365, grad/param norm = 1.6583e-01, time/batch = 15.0264s	
11680/33250 (epoch 17.564), train_loss = 1.20283286, grad/param norm = 1.7752e-01, time/batch = 15.5040s	
11681/33250 (epoch 17.565), train_loss = 1.13346986, grad/param norm = 1.8436e-01, time/batch = 16.2823s	
11682/33250 (epoch 17.567), train_loss = 1.11396857, grad/param norm = 1.6026e-01, time/batch = 18.7762s	
11683/33250 (epoch 17.568), train_loss = 0.98830651, grad/param norm = 1.6279e-01, time/batch = 16.5124s	
11684/33250 (epoch 17.570), train_loss = 1.12034915, grad/param norm = 1.7547e-01, time/batch = 16.0025s	
11685/33250 (epoch 17.571), train_loss = 1.13941669, grad/param norm = 1.5473e-01, time/batch = 14.6234s	
11686/33250 (epoch 17.573), train_loss = 1.02617485, grad/param norm = 1.5441e-01, time/batch = 14.7155s	
11687/33250 (epoch 17.574), train_loss = 0.88032712, grad/param norm = 1.3725e-01, time/batch = 14.8528s	
11688/33250 (epoch 17.576), train_loss = 1.02001230, grad/param norm = 1.4620e-01, time/batch = 15.2707s	
11689/33250 (epoch 17.577), train_loss = 0.96477924, grad/param norm = 1.4533e-01, time/batch = 15.0344s	
11690/33250 (epoch 17.579), train_loss = 0.88635230, grad/param norm = 2.1304e-01, time/batch = 16.2007s	
11691/33250 (epoch 17.580), train_loss = 0.93585000, grad/param norm = 1.2970e-01, time/batch = 17.9536s	
11692/33250 (epoch 17.582), train_loss = 0.94988822, grad/param norm = 1.3422e-01, time/batch = 15.4356s	
11693/33250 (epoch 17.583), train_loss = 1.07997670, grad/param norm = 1.6788e-01, time/batch = 18.0358s	
11694/33250 (epoch 17.585), train_loss = 1.07847073, grad/param norm = 1.5125e-01, time/batch = 17.6159s	
11695/33250 (epoch 17.586), train_loss = 0.94845748, grad/param norm = 1.8864e-01, time/batch = 16.7604s	
11696/33250 (epoch 17.588), train_loss = 1.00340673, grad/param norm = 1.4254e-01, time/batch = 15.5208s	
11697/33250 (epoch 17.589), train_loss = 1.03558335, grad/param norm = 1.5327e-01, time/batch = 17.3507s	
11698/33250 (epoch 17.591), train_loss = 1.00103930, grad/param norm = 1.5934e-01, time/batch = 16.6799s	
11699/33250 (epoch 17.592), train_loss = 0.99806813, grad/param norm = 1.4104e-01, time/batch = 16.0551s	
11700/33250 (epoch 17.594), train_loss = 1.14654232, grad/param norm = 1.8904e-01, time/batch = 18.3373s	
11701/33250 (epoch 17.595), train_loss = 1.04684971, grad/param norm = 1.7028e-01, time/batch = 18.0442s	
11702/33250 (epoch 17.597), train_loss = 0.84761472, grad/param norm = 1.3029e-01, time/batch = 18.4226s	
11703/33250 (epoch 17.598), train_loss = 0.97197103, grad/param norm = 1.6566e-01, time/batch = 18.0423s	
11704/33250 (epoch 17.600), train_loss = 0.97061743, grad/param norm = 1.6096e-01, time/batch = 17.0188s	
11705/33250 (epoch 17.602), train_loss = 1.01191239, grad/param norm = 1.8616e-01, time/batch = 16.3379s	
11706/33250 (epoch 17.603), train_loss = 1.01993558, grad/param norm = 1.5781e-01, time/batch = 16.0240s	
11707/33250 (epoch 17.605), train_loss = 0.99068055, grad/param norm = 1.4820e-01, time/batch = 15.0157s	
11708/33250 (epoch 17.606), train_loss = 1.03856972, grad/param norm = 1.5753e-01, time/batch = 16.8541s	
11709/33250 (epoch 17.608), train_loss = 1.00441072, grad/param norm = 1.4809e-01, time/batch = 15.9324s	
11710/33250 (epoch 17.609), train_loss = 0.88436548, grad/param norm = 1.4744e-01, time/batch = 16.2735s	
11711/33250 (epoch 17.611), train_loss = 1.00836259, grad/param norm = 1.5450e-01, time/batch = 18.5171s	
11712/33250 (epoch 17.612), train_loss = 1.00364057, grad/param norm = 1.5564e-01, time/batch = 18.1952s	
11713/33250 (epoch 17.614), train_loss = 1.19309072, grad/param norm = 1.7786e-01, time/batch = 16.3624s	
11714/33250 (epoch 17.615), train_loss = 1.08834848, grad/param norm = 1.5404e-01, time/batch = 17.0163s	
11715/33250 (epoch 17.617), train_loss = 1.29857505, grad/param norm = 1.9067e-01, time/batch = 15.6867s	
11716/33250 (epoch 17.618), train_loss = 1.27756481, grad/param norm = 2.0964e-01, time/batch = 15.1908s	
11717/33250 (epoch 17.620), train_loss = 1.09682864, grad/param norm = 1.6523e-01, time/batch = 15.5915s	
11718/33250 (epoch 17.621), train_loss = 1.00427733, grad/param norm = 1.4255e-01, time/batch = 17.0123s	
11719/33250 (epoch 17.623), train_loss = 0.91681824, grad/param norm = 1.4948e-01, time/batch = 15.8653s	
11720/33250 (epoch 17.624), train_loss = 0.98100527, grad/param norm = 1.5895e-01, time/batch = 17.2635s	
11721/33250 (epoch 17.626), train_loss = 0.94826639, grad/param norm = 1.7427e-01, time/batch = 16.7559s	
11722/33250 (epoch 17.627), train_loss = 0.93937463, grad/param norm = 1.4931e-01, time/batch = 16.6101s	
11723/33250 (epoch 17.629), train_loss = 1.04173524, grad/param norm = 1.6870e-01, time/batch = 15.5950s	
11724/33250 (epoch 17.630), train_loss = 0.97201048, grad/param norm = 1.7641e-01, time/batch = 16.2616s	
11725/33250 (epoch 17.632), train_loss = 0.82426409, grad/param norm = 1.2724e-01, time/batch = 17.1157s	
11726/33250 (epoch 17.633), train_loss = 1.01734936, grad/param norm = 1.4806e-01, time/batch = 17.5906s	
11727/33250 (epoch 17.635), train_loss = 0.89156880, grad/param norm = 1.5364e-01, time/batch = 15.4612s	
11728/33250 (epoch 17.636), train_loss = 0.91622793, grad/param norm = 1.5142e-01, time/batch = 16.6836s	
11729/33250 (epoch 17.638), train_loss = 0.93979272, grad/param norm = 1.4965e-01, time/batch = 15.9378s	
11730/33250 (epoch 17.639), train_loss = 0.81823141, grad/param norm = 1.3957e-01, time/batch = 15.2969s	
11731/33250 (epoch 17.641), train_loss = 0.92154386, grad/param norm = 1.3100e-01, time/batch = 17.1773s	
11732/33250 (epoch 17.642), train_loss = 0.80300069, grad/param norm = 1.3805e-01, time/batch = 15.8559s	
11733/33250 (epoch 17.644), train_loss = 0.72667785, grad/param norm = 1.3826e-01, time/batch = 15.4619s	
11734/33250 (epoch 17.645), train_loss = 1.07708329, grad/param norm = 1.7157e-01, time/batch = 15.1325s	
11735/33250 (epoch 17.647), train_loss = 0.86286568, grad/param norm = 1.5636e-01, time/batch = 15.9513s	
11736/33250 (epoch 17.648), train_loss = 0.88656200, grad/param norm = 1.4920e-01, time/batch = 15.6921s	
11737/33250 (epoch 17.650), train_loss = 1.10844289, grad/param norm = 1.6787e-01, time/batch = 16.9282s	
11738/33250 (epoch 17.651), train_loss = 1.01543477, grad/param norm = 1.6977e-01, time/batch = 14.5565s	
11739/33250 (epoch 17.653), train_loss = 0.88582010, grad/param norm = 1.5167e-01, time/batch = 15.4451s	
11740/33250 (epoch 17.654), train_loss = 0.95553944, grad/param norm = 1.4489e-01, time/batch = 16.3457s	
11741/33250 (epoch 17.656), train_loss = 1.03801595, grad/param norm = 1.5448e-01, time/batch = 17.5203s	
11742/33250 (epoch 17.657), train_loss = 0.78565442, grad/param norm = 1.4881e-01, time/batch = 16.9189s	
11743/33250 (epoch 17.659), train_loss = 0.93146766, grad/param norm = 1.5426e-01, time/batch = 17.4432s	
11744/33250 (epoch 17.660), train_loss = 0.97474285, grad/param norm = 1.6298e-01, time/batch = 17.9463s	
11745/33250 (epoch 17.662), train_loss = 0.99633457, grad/param norm = 1.4620e-01, time/batch = 14.9525s	
11746/33250 (epoch 17.663), train_loss = 0.90800001, grad/param norm = 1.4836e-01, time/batch = 15.7823s	
11747/33250 (epoch 17.665), train_loss = 1.01827930, grad/param norm = 1.5592e-01, time/batch = 15.5840s	
11748/33250 (epoch 17.666), train_loss = 0.93247708, grad/param norm = 1.4748e-01, time/batch = 17.1878s	
11749/33250 (epoch 17.668), train_loss = 1.12481798, grad/param norm = 1.5575e-01, time/batch = 16.3644s	
11750/33250 (epoch 17.669), train_loss = 1.01201910, grad/param norm = 1.6488e-01, time/batch = 15.6822s	
11751/33250 (epoch 17.671), train_loss = 0.90579098, grad/param norm = 1.6386e-01, time/batch = 15.1755s	
11752/33250 (epoch 17.672), train_loss = 1.06552429, grad/param norm = 1.6028e-01, time/batch = 16.6062s	
11753/33250 (epoch 17.674), train_loss = 0.90751218, grad/param norm = 1.4527e-01, time/batch = 15.7911s	
11754/33250 (epoch 17.675), train_loss = 0.95807424, grad/param norm = 1.3750e-01, time/batch = 15.2702s	
11755/33250 (epoch 17.677), train_loss = 1.08321275, grad/param norm = 1.6552e-01, time/batch = 15.6050s	
11756/33250 (epoch 17.678), train_loss = 0.94151411, grad/param norm = 1.5013e-01, time/batch = 17.5341s	
11757/33250 (epoch 17.680), train_loss = 1.09956397, grad/param norm = 1.5968e-01, time/batch = 15.6809s	
11758/33250 (epoch 17.681), train_loss = 0.85005987, grad/param norm = 1.3712e-01, time/batch = 16.5977s	
11759/33250 (epoch 17.683), train_loss = 0.96535524, grad/param norm = 1.5319e-01, time/batch = 16.6200s	
11760/33250 (epoch 17.684), train_loss = 0.86717892, grad/param norm = 1.5405e-01, time/batch = 17.0900s	
11761/33250 (epoch 17.686), train_loss = 0.89534773, grad/param norm = 1.4951e-01, time/batch = 15.8432s	
11762/33250 (epoch 17.687), train_loss = 0.97045396, grad/param norm = 1.4626e-01, time/batch = 17.8546s	
11763/33250 (epoch 17.689), train_loss = 0.91677381, grad/param norm = 1.6364e-01, time/batch = 17.6025s	
11764/33250 (epoch 17.690), train_loss = 0.99229076, grad/param norm = 1.5140e-01, time/batch = 17.3605s	
11765/33250 (epoch 17.692), train_loss = 0.95751469, grad/param norm = 1.5053e-01, time/batch = 15.9302s	
11766/33250 (epoch 17.693), train_loss = 1.05913661, grad/param norm = 1.5335e-01, time/batch = 16.0227s	
11767/33250 (epoch 17.695), train_loss = 1.01494456, grad/param norm = 1.5031e-01, time/batch = 15.5432s	
11768/33250 (epoch 17.696), train_loss = 1.01632405, grad/param norm = 1.4310e-01, time/batch = 16.6738s	
11769/33250 (epoch 17.698), train_loss = 0.91213204, grad/param norm = 1.5717e-01, time/batch = 16.7721s	
11770/33250 (epoch 17.699), train_loss = 1.17946993, grad/param norm = 1.5882e-01, time/batch = 15.4481s	
11771/33250 (epoch 17.701), train_loss = 0.96311315, grad/param norm = 1.4033e-01, time/batch = 15.6704s	
11772/33250 (epoch 17.702), train_loss = 0.93058614, grad/param norm = 1.8628e-01, time/batch = 16.6946s	
11773/33250 (epoch 17.704), train_loss = 1.15638761, grad/param norm = 1.9324e-01, time/batch = 18.7782s	
11774/33250 (epoch 17.705), train_loss = 0.90750452, grad/param norm = 1.4709e-01, time/batch = 18.7980s	
11775/33250 (epoch 17.707), train_loss = 0.81654804, grad/param norm = 1.4669e-01, time/batch = 15.7634s	
11776/33250 (epoch 17.708), train_loss = 1.07644235, grad/param norm = 1.5807e-01, time/batch = 17.0285s	
11777/33250 (epoch 17.710), train_loss = 1.05869441, grad/param norm = 1.6597e-01, time/batch = 16.2739s	
11778/33250 (epoch 17.711), train_loss = 0.92007418, grad/param norm = 1.5088e-01, time/batch = 17.5922s	
11779/33250 (epoch 17.713), train_loss = 1.01115702, grad/param norm = 1.4630e-01, time/batch = 16.5166s	
11780/33250 (epoch 17.714), train_loss = 1.00437893, grad/param norm = 1.5388e-01, time/batch = 15.9058s	
11781/33250 (epoch 17.716), train_loss = 1.05921548, grad/param norm = 1.5582e-01, time/batch = 16.5056s	
11782/33250 (epoch 17.717), train_loss = 0.90969050, grad/param norm = 1.3586e-01, time/batch = 17.5188s	
11783/33250 (epoch 17.719), train_loss = 0.96253523, grad/param norm = 1.5440e-01, time/batch = 18.9489s	
11784/33250 (epoch 17.720), train_loss = 1.19604399, grad/param norm = 1.5426e-01, time/batch = 18.5455s	
11785/33250 (epoch 17.722), train_loss = 0.87514993, grad/param norm = 1.4132e-01, time/batch = 18.5081s	
11786/33250 (epoch 17.723), train_loss = 0.78018010, grad/param norm = 1.2239e-01, time/batch = 28.3712s	
11787/33250 (epoch 17.725), train_loss = 0.86505943, grad/param norm = 1.2949e-01, time/batch = 15.0285s	
11788/33250 (epoch 17.726), train_loss = 0.94632578, grad/param norm = 1.5030e-01, time/batch = 15.2439s	
11789/33250 (epoch 17.728), train_loss = 1.00921072, grad/param norm = 1.4581e-01, time/batch = 14.9989s	
11790/33250 (epoch 17.729), train_loss = 1.09925026, grad/param norm = 1.6309e-01, time/batch = 15.1172s	
11791/33250 (epoch 17.731), train_loss = 0.91032858, grad/param norm = 1.6130e-01, time/batch = 17.6837s	
11792/33250 (epoch 17.732), train_loss = 0.87407504, grad/param norm = 1.4290e-01, time/batch = 17.3654s	
11793/33250 (epoch 17.734), train_loss = 0.99773485, grad/param norm = 1.7280e-01, time/batch = 15.3599s	
11794/33250 (epoch 17.735), train_loss = 0.98690990, grad/param norm = 1.4703e-01, time/batch = 17.1159s	
11795/33250 (epoch 17.737), train_loss = 0.95516700, grad/param norm = 1.3343e-01, time/batch = 15.9388s	
11796/33250 (epoch 17.738), train_loss = 0.98836697, grad/param norm = 1.4287e-01, time/batch = 16.2359s	
11797/33250 (epoch 17.740), train_loss = 1.09784359, grad/param norm = 1.5374e-01, time/batch = 15.8637s	
11798/33250 (epoch 17.741), train_loss = 1.05794154, grad/param norm = 1.4886e-01, time/batch = 15.2742s	
11799/33250 (epoch 17.743), train_loss = 0.92589504, grad/param norm = 1.3556e-01, time/batch = 15.4619s	
11800/33250 (epoch 17.744), train_loss = 0.94737026, grad/param norm = 1.6634e-01, time/batch = 15.6060s	
11801/33250 (epoch 17.746), train_loss = 0.90495117, grad/param norm = 1.3532e-01, time/batch = 15.8626s	
11802/33250 (epoch 17.747), train_loss = 0.91669148, grad/param norm = 1.5808e-01, time/batch = 17.3071s	
11803/33250 (epoch 17.749), train_loss = 1.08539989, grad/param norm = 1.8203e-01, time/batch = 16.9510s	
11804/33250 (epoch 17.750), train_loss = 1.06289294, grad/param norm = 1.5628e-01, time/batch = 17.0458s	
11805/33250 (epoch 17.752), train_loss = 0.93342012, grad/param norm = 1.3947e-01, time/batch = 15.7828s	
11806/33250 (epoch 17.753), train_loss = 0.95777785, grad/param norm = 1.5965e-01, time/batch = 15.7600s	
11807/33250 (epoch 17.755), train_loss = 0.95498354, grad/param norm = 1.5358e-01, time/batch = 15.6817s	
11808/33250 (epoch 17.756), train_loss = 1.04794356, grad/param norm = 1.5909e-01, time/batch = 15.5426s	
11809/33250 (epoch 17.758), train_loss = 1.12323776, grad/param norm = 1.5251e-01, time/batch = 15.3780s	
11810/33250 (epoch 17.759), train_loss = 0.89307540, grad/param norm = 1.4364e-01, time/batch = 15.7787s	
11811/33250 (epoch 17.761), train_loss = 0.96752591, grad/param norm = 1.5628e-01, time/batch = 15.6641s	
11812/33250 (epoch 17.762), train_loss = 1.09557972, grad/param norm = 1.5151e-01, time/batch = 15.9347s	
11813/33250 (epoch 17.764), train_loss = 0.90089291, grad/param norm = 1.8877e-01, time/batch = 18.1229s	
11814/33250 (epoch 17.765), train_loss = 1.02654574, grad/param norm = 1.5333e-01, time/batch = 17.2866s	
11815/33250 (epoch 17.767), train_loss = 0.82192625, grad/param norm = 1.4638e-01, time/batch = 18.5124s	
11816/33250 (epoch 17.768), train_loss = 0.84185268, grad/param norm = 1.4049e-01, time/batch = 16.7777s	
11817/33250 (epoch 17.770), train_loss = 1.02691506, grad/param norm = 1.7646e-01, time/batch = 15.5073s	
11818/33250 (epoch 17.771), train_loss = 1.03967926, grad/param norm = 1.6061e-01, time/batch = 15.6098s	
11819/33250 (epoch 17.773), train_loss = 0.95002879, grad/param norm = 1.5770e-01, time/batch = 15.5371s	
11820/33250 (epoch 17.774), train_loss = 0.82700208, grad/param norm = 1.4517e-01, time/batch = 15.5360s	
11821/33250 (epoch 17.776), train_loss = 0.91763638, grad/param norm = 1.4752e-01, time/batch = 16.6897s	
11822/33250 (epoch 17.777), train_loss = 1.08734894, grad/param norm = 1.7221e-01, time/batch = 16.2646s	
11823/33250 (epoch 17.779), train_loss = 0.96454676, grad/param norm = 1.6403e-01, time/batch = 16.5396s	
11824/33250 (epoch 17.780), train_loss = 1.14806507, grad/param norm = 1.6436e-01, time/batch = 17.8746s	
11825/33250 (epoch 17.782), train_loss = 1.00251123, grad/param norm = 1.4381e-01, time/batch = 14.9402s	
11826/33250 (epoch 17.783), train_loss = 0.82211825, grad/param norm = 1.3953e-01, time/batch = 15.5162s	
11827/33250 (epoch 17.785), train_loss = 0.86198929, grad/param norm = 1.4130e-01, time/batch = 17.4117s	
11828/33250 (epoch 17.786), train_loss = 1.05509092, grad/param norm = 1.5272e-01, time/batch = 16.6924s	
11829/33250 (epoch 17.788), train_loss = 1.04405058, grad/param norm = 1.5562e-01, time/batch = 15.0365s	
11830/33250 (epoch 17.789), train_loss = 1.08070503, grad/param norm = 1.6532e-01, time/batch = 15.8697s	
11831/33250 (epoch 17.791), train_loss = 1.12871193, grad/param norm = 1.5656e-01, time/batch = 17.0195s	
11832/33250 (epoch 17.792), train_loss = 1.21130024, grad/param norm = 1.5341e-01, time/batch = 18.0068s	
11833/33250 (epoch 17.794), train_loss = 0.96773326, grad/param norm = 1.5602e-01, time/batch = 15.2962s	
11834/33250 (epoch 17.795), train_loss = 1.01303535, grad/param norm = 1.5420e-01, time/batch = 17.5505s	
11835/33250 (epoch 17.797), train_loss = 1.08943034, grad/param norm = 1.8574e-01, time/batch = 18.2124s	
11836/33250 (epoch 17.798), train_loss = 0.98438248, grad/param norm = 1.5388e-01, time/batch = 15.4266s	
11837/33250 (epoch 17.800), train_loss = 1.02722183, grad/param norm = 1.5619e-01, time/batch = 16.1085s	
11838/33250 (epoch 17.802), train_loss = 0.93745595, grad/param norm = 1.2633e-01, time/batch = 16.0344s	
11839/33250 (epoch 17.803), train_loss = 0.99077018, grad/param norm = 1.3563e-01, time/batch = 16.8627s	
11840/33250 (epoch 17.805), train_loss = 1.03950968, grad/param norm = 1.6920e-01, time/batch = 15.2711s	
11841/33250 (epoch 17.806), train_loss = 1.00470403, grad/param norm = 1.5869e-01, time/batch = 15.9392s	
11842/33250 (epoch 17.808), train_loss = 0.95297953, grad/param norm = 1.4804e-01, time/batch = 15.2497s	
11843/33250 (epoch 17.809), train_loss = 0.90688794, grad/param norm = 1.4882e-01, time/batch = 16.1046s	
11844/33250 (epoch 17.811), train_loss = 0.90344023, grad/param norm = 1.4558e-01, time/batch = 15.6566s	
11845/33250 (epoch 17.812), train_loss = 1.05746541, grad/param norm = 1.6142e-01, time/batch = 16.5509s	
11846/33250 (epoch 17.814), train_loss = 0.98216286, grad/param norm = 1.4392e-01, time/batch = 15.5288s	
11847/33250 (epoch 17.815), train_loss = 1.03999955, grad/param norm = 1.4740e-01, time/batch = 15.7611s	
11848/33250 (epoch 17.817), train_loss = 0.94917878, grad/param norm = 1.4327e-01, time/batch = 16.6872s	
11849/33250 (epoch 17.818), train_loss = 0.90639120, grad/param norm = 1.4787e-01, time/batch = 16.5068s	
11850/33250 (epoch 17.820), train_loss = 0.98800752, grad/param norm = 1.4506e-01, time/batch = 17.3545s	
11851/33250 (epoch 17.821), train_loss = 0.95895594, grad/param norm = 1.3340e-01, time/batch = 15.6029s	
11852/33250 (epoch 17.823), train_loss = 1.30672734, grad/param norm = 1.8871e-01, time/batch = 16.1122s	
11853/33250 (epoch 17.824), train_loss = 0.94918116, grad/param norm = 1.5657e-01, time/batch = 17.2819s	
11854/33250 (epoch 17.826), train_loss = 1.02238090, grad/param norm = 1.7328e-01, time/batch = 17.8567s	
11855/33250 (epoch 17.827), train_loss = 0.80179126, grad/param norm = 1.3652e-01, time/batch = 17.1888s	
11856/33250 (epoch 17.829), train_loss = 1.00647898, grad/param norm = 2.0869e-01, time/batch = 16.5243s	
11857/33250 (epoch 17.830), train_loss = 1.10434802, grad/param norm = 1.8980e-01, time/batch = 16.4474s	
11858/33250 (epoch 17.832), train_loss = 0.99914296, grad/param norm = 1.4914e-01, time/batch = 16.0979s	
11859/33250 (epoch 17.833), train_loss = 1.01463967, grad/param norm = 1.6366e-01, time/batch = 15.1196s	
11860/33250 (epoch 17.835), train_loss = 0.91738479, grad/param norm = 1.7263e-01, time/batch = 16.6030s	
11861/33250 (epoch 17.836), train_loss = 0.96415083, grad/param norm = 1.5434e-01, time/batch = 15.5211s	
11862/33250 (epoch 17.838), train_loss = 0.98284511, grad/param norm = 1.4562e-01, time/batch = 16.1814s	
11863/33250 (epoch 17.839), train_loss = 0.94754751, grad/param norm = 1.5528e-01, time/batch = 17.7816s	
11864/33250 (epoch 17.841), train_loss = 0.91221215, grad/param norm = 1.4101e-01, time/batch = 17.7807s	
11865/33250 (epoch 17.842), train_loss = 1.14001998, grad/param norm = 1.4798e-01, time/batch = 15.3474s	
11866/33250 (epoch 17.844), train_loss = 1.11093869, grad/param norm = 1.7894e-01, time/batch = 16.3591s	
11867/33250 (epoch 17.845), train_loss = 1.18590555, grad/param norm = 1.6787e-01, time/batch = 15.5845s	
11868/33250 (epoch 17.847), train_loss = 1.13466306, grad/param norm = 1.6313e-01, time/batch = 16.1816s	
11869/33250 (epoch 17.848), train_loss = 1.26725568, grad/param norm = 1.9310e-01, time/batch = 16.0112s	
11870/33250 (epoch 17.850), train_loss = 1.09643983, grad/param norm = 1.7032e-01, time/batch = 15.6627s	
11871/33250 (epoch 17.851), train_loss = 0.92649230, grad/param norm = 1.6010e-01, time/batch = 15.5865s	
11872/33250 (epoch 17.853), train_loss = 1.06612626, grad/param norm = 1.6784e-01, time/batch = 16.1020s	
11873/33250 (epoch 17.854), train_loss = 0.91001815, grad/param norm = 1.3635e-01, time/batch = 15.8730s	
11874/33250 (epoch 17.856), train_loss = 0.91696961, grad/param norm = 1.5934e-01, time/batch = 17.3838s	
11875/33250 (epoch 17.857), train_loss = 0.85947911, grad/param norm = 1.3763e-01, time/batch = 16.8667s	
11876/33250 (epoch 17.859), train_loss = 0.85792513, grad/param norm = 1.3439e-01, time/batch = 17.8619s	
11877/33250 (epoch 17.860), train_loss = 0.98445869, grad/param norm = 1.4137e-01, time/batch = 15.8429s	
11878/33250 (epoch 17.862), train_loss = 0.89507880, grad/param norm = 1.3408e-01, time/batch = 15.6702s	
11879/33250 (epoch 17.863), train_loss = 0.94317999, grad/param norm = 1.5512e-01, time/batch = 15.4166s	
11880/33250 (epoch 17.865), train_loss = 1.03610687, grad/param norm = 1.5532e-01, time/batch = 15.3311s	
11881/33250 (epoch 17.866), train_loss = 0.95455012, grad/param norm = 1.6786e-01, time/batch = 15.7778s	
11882/33250 (epoch 17.868), train_loss = 1.05894874, grad/param norm = 1.7944e-01, time/batch = 15.3269s	
11883/33250 (epoch 17.869), train_loss = 1.02330975, grad/param norm = 1.6790e-01, time/batch = 15.8175s	
11884/33250 (epoch 17.871), train_loss = 0.77383719, grad/param norm = 1.3721e-01, time/batch = 15.5443s	
11885/33250 (epoch 17.872), train_loss = 1.03705657, grad/param norm = 1.6949e-01, time/batch = 15.4592s	
11886/33250 (epoch 17.874), train_loss = 0.88737445, grad/param norm = 1.4775e-01, time/batch = 15.5907s	
11887/33250 (epoch 17.875), train_loss = 0.89189051, grad/param norm = 1.5719e-01, time/batch = 15.6969s	
11888/33250 (epoch 17.877), train_loss = 1.10037862, grad/param norm = 1.5432e-01, time/batch = 15.4383s	
11889/33250 (epoch 17.878), train_loss = 1.01238804, grad/param norm = 1.4466e-01, time/batch = 15.3630s	
11890/33250 (epoch 17.880), train_loss = 0.98772402, grad/param norm = 1.8113e-01, time/batch = 15.6061s	
11891/33250 (epoch 17.881), train_loss = 1.13418892, grad/param norm = 1.7953e-01, time/batch = 15.5154s	
11892/33250 (epoch 17.883), train_loss = 1.01822958, grad/param norm = 1.5432e-01, time/batch = 15.9038s	
11893/33250 (epoch 17.884), train_loss = 1.00206593, grad/param norm = 1.5931e-01, time/batch = 15.8301s	
11894/33250 (epoch 17.886), train_loss = 0.91342108, grad/param norm = 1.2995e-01, time/batch = 15.9971s	
11895/33250 (epoch 17.887), train_loss = 0.95042768, grad/param norm = 1.5987e-01, time/batch = 23.4754s	
11896/33250 (epoch 17.889), train_loss = 0.92816361, grad/param norm = 1.3296e-01, time/batch = 31.2291s	
11897/33250 (epoch 17.890), train_loss = 0.80785058, grad/param norm = 1.2266e-01, time/batch = 27.2040s	
11898/33250 (epoch 17.892), train_loss = 1.02900025, grad/param norm = 1.4814e-01, time/batch = 32.1809s	
11899/33250 (epoch 17.893), train_loss = 1.06838507, grad/param norm = 1.7522e-01, time/batch = 31.9830s	
11900/33250 (epoch 17.895), train_loss = 0.94481610, grad/param norm = 1.5705e-01, time/batch = 28.9364s	
11901/33250 (epoch 17.896), train_loss = 1.08340135, grad/param norm = 1.6930e-01, time/batch = 32.2929s	
11902/33250 (epoch 17.898), train_loss = 0.97961433, grad/param norm = 1.5546e-01, time/batch = 30.1417s	
11903/33250 (epoch 17.899), train_loss = 0.91410767, grad/param norm = 1.5742e-01, time/batch = 31.8634s	
11904/33250 (epoch 17.901), train_loss = 0.84930044, grad/param norm = 1.3480e-01, time/batch = 31.3988s	
11905/33250 (epoch 17.902), train_loss = 0.96215261, grad/param norm = 1.3967e-01, time/batch = 32.0125s	
11906/33250 (epoch 17.904), train_loss = 0.89286157, grad/param norm = 1.3433e-01, time/batch = 31.2624s	
11907/33250 (epoch 17.905), train_loss = 0.92750211, grad/param norm = 1.3947e-01, time/batch = 19.0711s	
11908/33250 (epoch 17.907), train_loss = 0.88856792, grad/param norm = 1.5858e-01, time/batch = 15.5870s	
11909/33250 (epoch 17.908), train_loss = 0.97473221, grad/param norm = 1.3190e-01, time/batch = 15.6781s	
11910/33250 (epoch 17.910), train_loss = 1.04050345, grad/param norm = 1.6468e-01, time/batch = 15.3461s	
11911/33250 (epoch 17.911), train_loss = 0.86695956, grad/param norm = 1.4297e-01, time/batch = 15.6696s	
11912/33250 (epoch 17.913), train_loss = 0.91440642, grad/param norm = 1.4220e-01, time/batch = 15.3618s	
11913/33250 (epoch 17.914), train_loss = 0.82383134, grad/param norm = 1.4469e-01, time/batch = 15.4921s	
11914/33250 (epoch 17.916), train_loss = 0.91829883, grad/param norm = 1.2925e-01, time/batch = 15.5805s	
11915/33250 (epoch 17.917), train_loss = 0.93730843, grad/param norm = 1.3334e-01, time/batch = 15.6824s	
11916/33250 (epoch 17.919), train_loss = 0.88878121, grad/param norm = 1.5010e-01, time/batch = 15.7194s	
11917/33250 (epoch 17.920), train_loss = 0.98001137, grad/param norm = 1.5096e-01, time/batch = 15.4650s	
11918/33250 (epoch 17.922), train_loss = 1.02720682, grad/param norm = 1.6296e-01, time/batch = 15.3050s	
11919/33250 (epoch 17.923), train_loss = 0.96086360, grad/param norm = 1.6473e-01, time/batch = 15.5989s	
11920/33250 (epoch 17.925), train_loss = 0.94635979, grad/param norm = 1.4755e-01, time/batch = 15.6000s	
11921/33250 (epoch 17.926), train_loss = 0.93964336, grad/param norm = 1.4218e-01, time/batch = 15.5294s	
11922/33250 (epoch 17.928), train_loss = 0.95640059, grad/param norm = 1.5908e-01, time/batch = 15.6700s	
11923/33250 (epoch 17.929), train_loss = 0.79764661, grad/param norm = 1.3094e-01, time/batch = 15.5074s	
11924/33250 (epoch 17.931), train_loss = 1.05399474, grad/param norm = 1.5411e-01, time/batch = 15.4424s	
11925/33250 (epoch 17.932), train_loss = 0.99594939, grad/param norm = 1.6015e-01, time/batch = 15.6715s	
11926/33250 (epoch 17.934), train_loss = 0.89295797, grad/param norm = 1.3394e-01, time/batch = 15.6983s	
11927/33250 (epoch 17.935), train_loss = 0.88577311, grad/param norm = 1.4621e-01, time/batch = 15.5297s	
11928/33250 (epoch 17.937), train_loss = 0.94492049, grad/param norm = 1.5193e-01, time/batch = 15.3772s	
11929/33250 (epoch 17.938), train_loss = 0.99055873, grad/param norm = 1.5062e-01, time/batch = 15.6119s	
11930/33250 (epoch 17.940), train_loss = 0.96008491, grad/param norm = 1.5765e-01, time/batch = 15.7480s	
11931/33250 (epoch 17.941), train_loss = 1.02584023, grad/param norm = 1.4628e-01, time/batch = 15.4533s	
11932/33250 (epoch 17.943), train_loss = 1.09982854, grad/param norm = 1.5518e-01, time/batch = 15.5934s	
11933/33250 (epoch 17.944), train_loss = 0.90088927, grad/param norm = 1.4215e-01, time/batch = 15.8842s	
11934/33250 (epoch 17.946), train_loss = 1.06550660, grad/param norm = 1.5352e-01, time/batch = 15.6459s	
11935/33250 (epoch 17.947), train_loss = 0.88929248, grad/param norm = 1.4610e-01, time/batch = 15.7697s	
11936/33250 (epoch 17.949), train_loss = 1.06580966, grad/param norm = 1.6245e-01, time/batch = 15.8578s	
11937/33250 (epoch 17.950), train_loss = 1.01913083, grad/param norm = 1.3974e-01, time/batch = 15.5936s	
11938/33250 (epoch 17.952), train_loss = 0.96600976, grad/param norm = 1.8455e-01, time/batch = 15.3930s	
11939/33250 (epoch 17.953), train_loss = 1.05363885, grad/param norm = 1.5366e-01, time/batch = 15.2178s	
11940/33250 (epoch 17.955), train_loss = 1.08314952, grad/param norm = 1.5873e-01, time/batch = 15.0133s	
11941/33250 (epoch 17.956), train_loss = 1.01701826, grad/param norm = 1.8338e-01, time/batch = 15.3518s	
11942/33250 (epoch 17.958), train_loss = 0.89608445, grad/param norm = 1.5055e-01, time/batch = 15.0289s	
11943/33250 (epoch 17.959), train_loss = 0.93284560, grad/param norm = 1.5487e-01, time/batch = 15.2637s	
11944/33250 (epoch 17.961), train_loss = 1.16185603, grad/param norm = 1.4621e-01, time/batch = 15.3250s	
11945/33250 (epoch 17.962), train_loss = 0.98619604, grad/param norm = 1.4750e-01, time/batch = 15.5897s	
11946/33250 (epoch 17.964), train_loss = 1.15649502, grad/param norm = 1.7079e-01, time/batch = 15.3591s	
11947/33250 (epoch 17.965), train_loss = 1.03352005, grad/param norm = 1.5424e-01, time/batch = 15.3019s	
11948/33250 (epoch 17.967), train_loss = 0.99031224, grad/param norm = 1.5577e-01, time/batch = 15.3770s	
11949/33250 (epoch 17.968), train_loss = 1.13968772, grad/param norm = 1.4489e-01, time/batch = 15.3563s	
11950/33250 (epoch 17.970), train_loss = 1.26502506, grad/param norm = 2.2222e-01, time/batch = 15.6709s	
11951/33250 (epoch 17.971), train_loss = 1.12597331, grad/param norm = 1.7504e-01, time/batch = 15.4359s	
11952/33250 (epoch 17.973), train_loss = 0.96105728, grad/param norm = 1.5543e-01, time/batch = 15.0442s	
11953/33250 (epoch 17.974), train_loss = 1.05974265, grad/param norm = 1.6042e-01, time/batch = 15.8866s	
11954/33250 (epoch 17.976), train_loss = 0.95435298, grad/param norm = 1.8073e-01, time/batch = 15.5191s	
11955/33250 (epoch 17.977), train_loss = 0.92983853, grad/param norm = 1.5363e-01, time/batch = 15.2079s	
11956/33250 (epoch 17.979), train_loss = 1.01817289, grad/param norm = 1.8485e-01, time/batch = 15.5136s	
11957/33250 (epoch 17.980), train_loss = 1.00619721, grad/param norm = 1.4633e-01, time/batch = 15.4360s	
11958/33250 (epoch 17.982), train_loss = 0.88577970, grad/param norm = 1.4196e-01, time/batch = 15.2982s	
11959/33250 (epoch 17.983), train_loss = 1.02401535, grad/param norm = 1.6609e-01, time/batch = 15.3738s	
11960/33250 (epoch 17.985), train_loss = 0.94102655, grad/param norm = 1.6642e-01, time/batch = 15.1559s	
11961/33250 (epoch 17.986), train_loss = 1.06394409, grad/param norm = 1.5549e-01, time/batch = 15.7560s	
11962/33250 (epoch 17.988), train_loss = 1.12879270, grad/param norm = 1.7464e-01, time/batch = 15.3572s	
11963/33250 (epoch 17.989), train_loss = 1.08471404, grad/param norm = 1.7813e-01, time/batch = 15.2075s	
11964/33250 (epoch 17.991), train_loss = 1.02908182, grad/param norm = 1.7373e-01, time/batch = 15.4952s	
11965/33250 (epoch 17.992), train_loss = 0.94769118, grad/param norm = 1.5777e-01, time/batch = 15.7534s	
11966/33250 (epoch 17.994), train_loss = 0.90935757, grad/param norm = 1.4265e-01, time/batch = 15.7400s	
11967/33250 (epoch 17.995), train_loss = 0.96163475, grad/param norm = 1.8522e-01, time/batch = 15.3457s	
11968/33250 (epoch 17.997), train_loss = 0.72677820, grad/param norm = 1.3601e-01, time/batch = 15.4245s	
11969/33250 (epoch 17.998), train_loss = 1.01141753, grad/param norm = 1.4103e-01, time/batch = 15.3493s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
11970/33250 (epoch 18.000), train_loss = 0.98772900, grad/param norm = 1.6073e-01, time/batch = 14.7250s	
11971/33250 (epoch 18.002), train_loss = 1.16286001, grad/param norm = 1.6281e-01, time/batch = 14.6300s	
11972/33250 (epoch 18.003), train_loss = 1.06465966, grad/param norm = 1.6823e-01, time/batch = 14.3149s	
11973/33250 (epoch 18.005), train_loss = 0.79666651, grad/param norm = 1.3871e-01, time/batch = 15.0312s	
11974/33250 (epoch 18.006), train_loss = 0.83656988, grad/param norm = 1.4288e-01, time/batch = 14.5525s	
11975/33250 (epoch 18.008), train_loss = 1.13909525, grad/param norm = 1.5650e-01, time/batch = 14.7116s	
11976/33250 (epoch 18.009), train_loss = 1.14286832, grad/param norm = 1.7168e-01, time/batch = 14.5403s	
11977/33250 (epoch 18.011), train_loss = 0.89475047, grad/param norm = 1.4779e-01, time/batch = 14.7865s	
11978/33250 (epoch 18.012), train_loss = 0.99790659, grad/param norm = 2.0051e-01, time/batch = 15.1350s	
11979/33250 (epoch 18.014), train_loss = 1.12130436, grad/param norm = 1.7428e-01, time/batch = 15.0258s	
11980/33250 (epoch 18.015), train_loss = 0.97433702, grad/param norm = 1.5134e-01, time/batch = 15.8082s	
11981/33250 (epoch 18.017), train_loss = 1.00384130, grad/param norm = 1.7579e-01, time/batch = 15.7354s	
11982/33250 (epoch 18.018), train_loss = 0.80613320, grad/param norm = 1.3741e-01, time/batch = 15.3766s	
11983/33250 (epoch 18.020), train_loss = 0.98219370, grad/param norm = 1.4176e-01, time/batch = 15.8610s	
11984/33250 (epoch 18.021), train_loss = 1.02295647, grad/param norm = 1.5564e-01, time/batch = 15.7467s	
11985/33250 (epoch 18.023), train_loss = 0.81624809, grad/param norm = 1.5226e-01, time/batch = 15.6213s	
11986/33250 (epoch 18.024), train_loss = 1.08992908, grad/param norm = 1.6073e-01, time/batch = 15.7598s	
11987/33250 (epoch 18.026), train_loss = 0.98910903, grad/param norm = 1.3726e-01, time/batch = 15.7553s	
11988/33250 (epoch 18.027), train_loss = 0.97949973, grad/param norm = 1.4235e-01, time/batch = 15.8958s	
11989/33250 (epoch 18.029), train_loss = 1.00310785, grad/param norm = 1.4912e-01, time/batch = 15.5179s	
11990/33250 (epoch 18.030), train_loss = 0.99467431, grad/param norm = 1.6471e-01, time/batch = 15.4158s	
11991/33250 (epoch 18.032), train_loss = 1.20037569, grad/param norm = 1.7449e-01, time/batch = 15.6961s	
11992/33250 (epoch 18.033), train_loss = 0.93636147, grad/param norm = 1.4958e-01, time/batch = 15.8684s	
11993/33250 (epoch 18.035), train_loss = 0.95411159, grad/param norm = 1.6707e-01, time/batch = 15.9351s	
11994/33250 (epoch 18.036), train_loss = 1.05712164, grad/param norm = 1.6381e-01, time/batch = 15.6301s	
11995/33250 (epoch 18.038), train_loss = 0.98052054, grad/param norm = 1.4029e-01, time/batch = 15.1980s	
11996/33250 (epoch 18.039), train_loss = 0.87571308, grad/param norm = 1.3402e-01, time/batch = 15.4224s	
11997/33250 (epoch 18.041), train_loss = 1.00402600, grad/param norm = 1.6359e-01, time/batch = 15.2695s	
11998/33250 (epoch 18.042), train_loss = 0.80699641, grad/param norm = 1.2984e-01, time/batch = 15.2749s	
11999/33250 (epoch 18.044), train_loss = 1.12773577, grad/param norm = 1.8791e-01, time/batch = 15.1845s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch18.05_1.4460.t7	
12000/33250 (epoch 18.045), train_loss = 1.09120344, grad/param norm = 1.5858e-01, time/batch = 23.7385s	
12001/33250 (epoch 18.047), train_loss = 1.26042988, grad/param norm = 1.7454e-01, time/batch = 15.9310s	
12002/33250 (epoch 18.048), train_loss = 1.12773919, grad/param norm = 1.9364e-01, time/batch = 15.4426s	
12003/33250 (epoch 18.050), train_loss = 0.98182347, grad/param norm = 1.4825e-01, time/batch = 15.5378s	
12004/33250 (epoch 18.051), train_loss = 0.99242553, grad/param norm = 1.6148e-01, time/batch = 15.3602s	
12005/33250 (epoch 18.053), train_loss = 0.99828652, grad/param norm = 1.7377e-01, time/batch = 15.3650s	
12006/33250 (epoch 18.054), train_loss = 0.82440210, grad/param norm = 1.2959e-01, time/batch = 15.2060s	
12007/33250 (epoch 18.056), train_loss = 0.89587908, grad/param norm = 1.4313e-01, time/batch = 15.2832s	
12008/33250 (epoch 18.057), train_loss = 1.05300928, grad/param norm = 1.3802e-01, time/batch = 15.7622s	
12009/33250 (epoch 18.059), train_loss = 0.96105100, grad/param norm = 1.4744e-01, time/batch = 15.6024s	
12010/33250 (epoch 18.060), train_loss = 1.02387508, grad/param norm = 1.6816e-01, time/batch = 15.5276s	
12011/33250 (epoch 18.062), train_loss = 1.10608520, grad/param norm = 1.6448e-01, time/batch = 15.5093s	
12012/33250 (epoch 18.063), train_loss = 1.11389677, grad/param norm = 1.5452e-01, time/batch = 15.7557s	
12013/33250 (epoch 18.065), train_loss = 0.98257249, grad/param norm = 1.5287e-01, time/batch = 15.5210s	
12014/33250 (epoch 18.066), train_loss = 1.04498078, grad/param norm = 1.5510e-01, time/batch = 15.0638s	
12015/33250 (epoch 18.068), train_loss = 0.94805729, grad/param norm = 1.4888e-01, time/batch = 15.3481s	
12016/33250 (epoch 18.069), train_loss = 0.99902597, grad/param norm = 1.5645e-01, time/batch = 15.6210s	
12017/33250 (epoch 18.071), train_loss = 0.89128893, grad/param norm = 1.4781e-01, time/batch = 15.3039s	
12018/33250 (epoch 18.072), train_loss = 0.89093142, grad/param norm = 1.3374e-01, time/batch = 15.1161s	
12019/33250 (epoch 18.074), train_loss = 1.04537961, grad/param norm = 1.5356e-01, time/batch = 15.2076s	
12020/33250 (epoch 18.075), train_loss = 0.91820075, grad/param norm = 1.3529e-01, time/batch = 15.4353s	
12021/33250 (epoch 18.077), train_loss = 0.97529722, grad/param norm = 1.5448e-01, time/batch = 15.3595s	
12022/33250 (epoch 18.078), train_loss = 1.00306362, grad/param norm = 1.4748e-01, time/batch = 15.1954s	
12023/33250 (epoch 18.080), train_loss = 0.98968587, grad/param norm = 1.7673e-01, time/batch = 15.4401s	
12024/33250 (epoch 18.081), train_loss = 1.01848743, grad/param norm = 1.5011e-01, time/batch = 15.5852s	
12025/33250 (epoch 18.083), train_loss = 1.09630935, grad/param norm = 1.4818e-01, time/batch = 15.3433s	
12026/33250 (epoch 18.084), train_loss = 0.99209615, grad/param norm = 1.5162e-01, time/batch = 15.8235s	
12027/33250 (epoch 18.086), train_loss = 0.94918609, grad/param norm = 1.3797e-01, time/batch = 15.8522s	
12028/33250 (epoch 18.087), train_loss = 0.87346513, grad/param norm = 1.3586e-01, time/batch = 15.8803s	
12029/33250 (epoch 18.089), train_loss = 1.01652097, grad/param norm = 1.4724e-01, time/batch = 15.7616s	
12030/33250 (epoch 18.090), train_loss = 1.00291533, grad/param norm = 1.5217e-01, time/batch = 15.5272s	
12031/33250 (epoch 18.092), train_loss = 0.91035203, grad/param norm = 1.3247e-01, time/batch = 15.8398s	
12032/33250 (epoch 18.093), train_loss = 1.01447796, grad/param norm = 1.4914e-01, time/batch = 15.8294s	
12033/33250 (epoch 18.095), train_loss = 0.92303390, grad/param norm = 1.4173e-01, time/batch = 15.6757s	
12034/33250 (epoch 18.096), train_loss = 0.84757475, grad/param norm = 1.5134e-01, time/batch = 15.5975s	
12035/33250 (epoch 18.098), train_loss = 0.84143653, grad/param norm = 1.4477e-01, time/batch = 15.6015s	
12036/33250 (epoch 18.099), train_loss = 0.73195953, grad/param norm = 1.3415e-01, time/batch = 15.6317s	
12037/33250 (epoch 18.101), train_loss = 0.97594716, grad/param norm = 1.5001e-01, time/batch = 15.5569s	
12038/33250 (epoch 18.102), train_loss = 0.90299400, grad/param norm = 1.4746e-01, time/batch = 15.4778s	
12039/33250 (epoch 18.104), train_loss = 0.75814249, grad/param norm = 1.2873e-01, time/batch = 15.5358s	
12040/33250 (epoch 18.105), train_loss = 0.91933936, grad/param norm = 1.3548e-01, time/batch = 14.9530s	
12041/33250 (epoch 18.107), train_loss = 0.81754593, grad/param norm = 1.3144e-01, time/batch = 15.2853s	
12042/33250 (epoch 18.108), train_loss = 0.97168519, grad/param norm = 1.6798e-01, time/batch = 15.1948s	
12043/33250 (epoch 18.110), train_loss = 0.79555842, grad/param norm = 1.3582e-01, time/batch = 15.2635s	
12044/33250 (epoch 18.111), train_loss = 0.93852979, grad/param norm = 1.4467e-01, time/batch = 15.8245s	
12045/33250 (epoch 18.113), train_loss = 0.93475383, grad/param norm = 1.5833e-01, time/batch = 15.1779s	
12046/33250 (epoch 18.114), train_loss = 0.87214017, grad/param norm = 1.5121e-01, time/batch = 15.4220s	
12047/33250 (epoch 18.116), train_loss = 0.96386045, grad/param norm = 1.6160e-01, time/batch = 15.7502s	
12048/33250 (epoch 18.117), train_loss = 0.93339381, grad/param norm = 1.5201e-01, time/batch = 15.3042s	
12049/33250 (epoch 18.119), train_loss = 0.93483998, grad/param norm = 1.4695e-01, time/batch = 15.5219s	
12050/33250 (epoch 18.120), train_loss = 0.74190790, grad/param norm = 1.2757e-01, time/batch = 15.6713s	
12051/33250 (epoch 18.122), train_loss = 1.08061191, grad/param norm = 1.5706e-01, time/batch = 15.6597s	
12052/33250 (epoch 18.123), train_loss = 0.98497169, grad/param norm = 1.6398e-01, time/batch = 15.4385s	
12053/33250 (epoch 18.125), train_loss = 0.81245462, grad/param norm = 1.5686e-01, time/batch = 15.6771s	
12054/33250 (epoch 18.126), train_loss = 0.94643844, grad/param norm = 1.5432e-01, time/batch = 15.5108s	
12055/33250 (epoch 18.128), train_loss = 0.89903053, grad/param norm = 1.4325e-01, time/batch = 15.6266s	
12056/33250 (epoch 18.129), train_loss = 0.94142549, grad/param norm = 1.5150e-01, time/batch = 15.4785s	
12057/33250 (epoch 18.131), train_loss = 0.93018616, grad/param norm = 1.4638e-01, time/batch = 15.6680s	
12058/33250 (epoch 18.132), train_loss = 0.95413953, grad/param norm = 1.6492e-01, time/batch = 15.7538s	
12059/33250 (epoch 18.134), train_loss = 0.96436339, grad/param norm = 1.5504e-01, time/batch = 15.5395s	
12060/33250 (epoch 18.135), train_loss = 0.96977641, grad/param norm = 1.3863e-01, time/batch = 15.7584s	
12061/33250 (epoch 18.137), train_loss = 0.86047469, grad/param norm = 1.5634e-01, time/batch = 15.8940s	
12062/33250 (epoch 18.138), train_loss = 0.89304429, grad/param norm = 1.3465e-01, time/batch = 15.4198s	
12063/33250 (epoch 18.140), train_loss = 0.73807861, grad/param norm = 1.5364e-01, time/batch = 15.2048s	
12064/33250 (epoch 18.141), train_loss = 1.13289236, grad/param norm = 1.9601e-01, time/batch = 15.3415s	
12065/33250 (epoch 18.143), train_loss = 0.76677254, grad/param norm = 1.5836e-01, time/batch = 15.1101s	
12066/33250 (epoch 18.144), train_loss = 0.92469270, grad/param norm = 1.5368e-01, time/batch = 15.4212s	
12067/33250 (epoch 18.146), train_loss = 0.90531188, grad/param norm = 1.4087e-01, time/batch = 15.4949s	
12068/33250 (epoch 18.147), train_loss = 0.88634335, grad/param norm = 1.3684e-01, time/batch = 14.6487s	
12069/33250 (epoch 18.149), train_loss = 0.89347791, grad/param norm = 1.3544e-01, time/batch = 14.4728s	
12070/33250 (epoch 18.150), train_loss = 0.86377734, grad/param norm = 1.4346e-01, time/batch = 14.8043s	
12071/33250 (epoch 18.152), train_loss = 0.80714627, grad/param norm = 1.3587e-01, time/batch = 14.7962s	
12072/33250 (epoch 18.153), train_loss = 1.10578741, grad/param norm = 1.6051e-01, time/batch = 14.7859s	
12073/33250 (epoch 18.155), train_loss = 0.93486339, grad/param norm = 1.5657e-01, time/batch = 14.4639s	
12074/33250 (epoch 18.156), train_loss = 1.14132765, grad/param norm = 1.5441e-01, time/batch = 15.0175s	
12075/33250 (epoch 18.158), train_loss = 1.14531362, grad/param norm = 1.7552e-01, time/batch = 14.9456s	
12076/33250 (epoch 18.159), train_loss = 0.94374228, grad/param norm = 1.5230e-01, time/batch = 14.5546s	
12077/33250 (epoch 18.161), train_loss = 0.99752076, grad/param norm = 1.5670e-01, time/batch = 14.4730s	
12078/33250 (epoch 18.162), train_loss = 0.84068623, grad/param norm = 1.3586e-01, time/batch = 14.6354s	
12079/33250 (epoch 18.164), train_loss = 0.93057057, grad/param norm = 1.5205e-01, time/batch = 14.2449s	
12080/33250 (epoch 18.165), train_loss = 1.03729523, grad/param norm = 1.6303e-01, time/batch = 14.4833s	
12081/33250 (epoch 18.167), train_loss = 1.09278076, grad/param norm = 1.5749e-01, time/batch = 15.1041s	
12082/33250 (epoch 18.168), train_loss = 0.82329674, grad/param norm = 1.2165e-01, time/batch = 14.5748s	
12083/33250 (epoch 18.170), train_loss = 0.92625904, grad/param norm = 1.5924e-01, time/batch = 14.6338s	
12084/33250 (epoch 18.171), train_loss = 0.92070502, grad/param norm = 1.3365e-01, time/batch = 15.5660s	
12085/33250 (epoch 18.173), train_loss = 0.89589618, grad/param norm = 1.3853e-01, time/batch = 14.9315s	
12086/33250 (epoch 18.174), train_loss = 0.95231614, grad/param norm = 1.6861e-01, time/batch = 15.1785s	
12087/33250 (epoch 18.176), train_loss = 0.92957494, grad/param norm = 1.5260e-01, time/batch = 14.6955s	
12088/33250 (epoch 18.177), train_loss = 0.92625859, grad/param norm = 1.3944e-01, time/batch = 15.0890s	
12089/33250 (epoch 18.179), train_loss = 0.88175609, grad/param norm = 1.4197e-01, time/batch = 15.8143s	
12090/33250 (epoch 18.180), train_loss = 0.79328649, grad/param norm = 1.3671e-01, time/batch = 15.8323s	
12091/33250 (epoch 18.182), train_loss = 0.89108786, grad/param norm = 1.5928e-01, time/batch = 15.3839s	
12092/33250 (epoch 18.183), train_loss = 1.07832458, grad/param norm = 1.6861e-01, time/batch = 15.8785s	
12093/33250 (epoch 18.185), train_loss = 1.01192844, grad/param norm = 1.6558e-01, time/batch = 16.0082s	
12094/33250 (epoch 18.186), train_loss = 0.97509395, grad/param norm = 1.3870e-01, time/batch = 16.0105s	
12095/33250 (epoch 18.188), train_loss = 1.07143699, grad/param norm = 1.6084e-01, time/batch = 16.1980s	
12096/33250 (epoch 18.189), train_loss = 0.77742556, grad/param norm = 1.5593e-01, time/batch = 15.1952s	
12097/33250 (epoch 18.191), train_loss = 0.88566366, grad/param norm = 1.6191e-01, time/batch = 15.7089s	
12098/33250 (epoch 18.192), train_loss = 0.88921409, grad/param norm = 1.3595e-01, time/batch = 16.0333s	
12099/33250 (epoch 18.194), train_loss = 0.91586692, grad/param norm = 1.4628e-01, time/batch = 15.6928s	
12100/33250 (epoch 18.195), train_loss = 1.13437986, grad/param norm = 1.4686e-01, time/batch = 15.9277s	
12101/33250 (epoch 18.197), train_loss = 0.90182438, grad/param norm = 1.4103e-01, time/batch = 17.9527s	
12102/33250 (epoch 18.198), train_loss = 1.06481308, grad/param norm = 1.5432e-01, time/batch = 18.0322s	
12103/33250 (epoch 18.200), train_loss = 0.95422876, grad/param norm = 1.4155e-01, time/batch = 17.2061s	
12104/33250 (epoch 18.202), train_loss = 0.88808215, grad/param norm = 1.3326e-01, time/batch = 15.6399s	
12105/33250 (epoch 18.203), train_loss = 0.89391293, grad/param norm = 1.5582e-01, time/batch = 15.5005s	
12106/33250 (epoch 18.205), train_loss = 0.99286946, grad/param norm = 1.4302e-01, time/batch = 15.4589s	
12107/33250 (epoch 18.206), train_loss = 1.03520143, grad/param norm = 1.5192e-01, time/batch = 15.0353s	
12108/33250 (epoch 18.208), train_loss = 1.10062770, grad/param norm = 1.7600e-01, time/batch = 15.7279s	
12109/33250 (epoch 18.209), train_loss = 0.88299954, grad/param norm = 1.3704e-01, time/batch = 15.5789s	
12110/33250 (epoch 18.211), train_loss = 1.04563573, grad/param norm = 1.7013e-01, time/batch = 14.7069s	
12111/33250 (epoch 18.212), train_loss = 1.17747278, grad/param norm = 1.5719e-01, time/batch = 15.2731s	
12112/33250 (epoch 18.214), train_loss = 0.94314639, grad/param norm = 1.3919e-01, time/batch = 14.5585s	
12113/33250 (epoch 18.215), train_loss = 1.14596113, grad/param norm = 1.9438e-01, time/batch = 15.5323s	
12114/33250 (epoch 18.217), train_loss = 1.10025474, grad/param norm = 1.7024e-01, time/batch = 15.4126s	
12115/33250 (epoch 18.218), train_loss = 1.04824889, grad/param norm = 1.4051e-01, time/batch = 15.1887s	
12116/33250 (epoch 18.220), train_loss = 1.00604544, grad/param norm = 1.5889e-01, time/batch = 15.1934s	
12117/33250 (epoch 18.221), train_loss = 1.16989531, grad/param norm = 1.7654e-01, time/batch = 15.8626s	
12118/33250 (epoch 18.223), train_loss = 0.96195748, grad/param norm = 1.4931e-01, time/batch = 15.4801s	
12119/33250 (epoch 18.224), train_loss = 1.00874648, grad/param norm = 1.4854e-01, time/batch = 15.1791s	
12120/33250 (epoch 18.226), train_loss = 1.13220333, grad/param norm = 1.5305e-01, time/batch = 14.8609s	
12121/33250 (epoch 18.227), train_loss = 1.01115624, grad/param norm = 1.5761e-01, time/batch = 15.6837s	
12122/33250 (epoch 18.229), train_loss = 1.01381149, grad/param norm = 1.5116e-01, time/batch = 15.3641s	
12123/33250 (epoch 18.230), train_loss = 0.95097497, grad/param norm = 1.4417e-01, time/batch = 15.2102s	
12124/33250 (epoch 18.232), train_loss = 0.92237266, grad/param norm = 1.3057e-01, time/batch = 15.3533s	
12125/33250 (epoch 18.233), train_loss = 0.89768519, grad/param norm = 1.3768e-01, time/batch = 15.5777s	
12126/33250 (epoch 18.235), train_loss = 1.12541314, grad/param norm = 1.4424e-01, time/batch = 15.1190s	
12127/33250 (epoch 18.236), train_loss = 0.89736341, grad/param norm = 1.4425e-01, time/batch = 15.2571s	
12128/33250 (epoch 18.238), train_loss = 1.08845492, grad/param norm = 1.7146e-01, time/batch = 15.4363s	
12129/33250 (epoch 18.239), train_loss = 1.12878804, grad/param norm = 1.8314e-01, time/batch = 15.2723s	
12130/33250 (epoch 18.241), train_loss = 1.07490702, grad/param norm = 1.8682e-01, time/batch = 14.9742s	
12131/33250 (epoch 18.242), train_loss = 1.05915291, grad/param norm = 1.5750e-01, time/batch = 15.2139s	
12132/33250 (epoch 18.244), train_loss = 1.07396769, grad/param norm = 1.9353e-01, time/batch = 15.1969s	
12133/33250 (epoch 18.245), train_loss = 0.99296688, grad/param norm = 1.4581e-01, time/batch = 14.9537s	
12134/33250 (epoch 18.247), train_loss = 1.00562563, grad/param norm = 1.5128e-01, time/batch = 14.7859s	
12135/33250 (epoch 18.248), train_loss = 1.19634068, grad/param norm = 1.8097e-01, time/batch = 15.0286s	
12136/33250 (epoch 18.250), train_loss = 1.06373110, grad/param norm = 1.4183e-01, time/batch = 15.4312s	
12137/33250 (epoch 18.251), train_loss = 0.97390192, grad/param norm = 1.4862e-01, time/batch = 14.7794s	
12138/33250 (epoch 18.253), train_loss = 0.89922997, grad/param norm = 1.2556e-01, time/batch = 14.8357s	
12139/33250 (epoch 18.254), train_loss = 0.92681833, grad/param norm = 1.5128e-01, time/batch = 14.8786s	
12140/33250 (epoch 18.256), train_loss = 0.97065279, grad/param norm = 1.3425e-01, time/batch = 15.3594s	
12141/33250 (epoch 18.257), train_loss = 1.11956670, grad/param norm = 1.5979e-01, time/batch = 15.1958s	
12142/33250 (epoch 18.259), train_loss = 1.06524680, grad/param norm = 1.7046e-01, time/batch = 15.1996s	
12143/33250 (epoch 18.260), train_loss = 0.85995682, grad/param norm = 1.4940e-01, time/batch = 15.4235s	
12144/33250 (epoch 18.262), train_loss = 0.99077453, grad/param norm = 1.4212e-01, time/batch = 15.4835s	
12145/33250 (epoch 18.263), train_loss = 0.89224819, grad/param norm = 1.4696e-01, time/batch = 15.5759s	
12146/33250 (epoch 18.265), train_loss = 1.05148009, grad/param norm = 1.5265e-01, time/batch = 15.4823s	
12147/33250 (epoch 18.266), train_loss = 0.96947408, grad/param norm = 1.6866e-01, time/batch = 15.3520s	
12148/33250 (epoch 18.268), train_loss = 0.88485514, grad/param norm = 1.3659e-01, time/batch = 15.2619s	
12149/33250 (epoch 18.269), train_loss = 0.78827954, grad/param norm = 1.4784e-01, time/batch = 15.3442s	
12150/33250 (epoch 18.271), train_loss = 0.97425950, grad/param norm = 1.4507e-01, time/batch = 15.1159s	
12151/33250 (epoch 18.272), train_loss = 0.85054125, grad/param norm = 1.3875e-01, time/batch = 15.1300s	
12152/33250 (epoch 18.274), train_loss = 0.75624161, grad/param norm = 1.4676e-01, time/batch = 15.8144s	
12153/33250 (epoch 18.275), train_loss = 0.89563696, grad/param norm = 1.4434e-01, time/batch = 15.5246s	
12154/33250 (epoch 18.277), train_loss = 0.76191347, grad/param norm = 1.2677e-01, time/batch = 15.3478s	
12155/33250 (epoch 18.278), train_loss = 0.91923202, grad/param norm = 1.5849e-01, time/batch = 15.0119s	
12156/33250 (epoch 18.280), train_loss = 0.86668324, grad/param norm = 1.3779e-01, time/batch = 15.2615s	
12157/33250 (epoch 18.281), train_loss = 0.98987776, grad/param norm = 1.5083e-01, time/batch = 14.9252s	
12158/33250 (epoch 18.283), train_loss = 1.00048621, grad/param norm = 1.9195e-01, time/batch = 15.1888s	
12159/33250 (epoch 18.284), train_loss = 0.87936969, grad/param norm = 1.5779e-01, time/batch = 14.6758s	
12160/33250 (epoch 18.286), train_loss = 1.02601491, grad/param norm = 1.5555e-01, time/batch = 15.0301s	
12161/33250 (epoch 18.287), train_loss = 0.82695698, grad/param norm = 1.2602e-01, time/batch = 15.0375s	
12162/33250 (epoch 18.289), train_loss = 0.80471243, grad/param norm = 1.4496e-01, time/batch = 14.7215s	
12163/33250 (epoch 18.290), train_loss = 0.95843873, grad/param norm = 1.3904e-01, time/batch = 15.4070s	
12164/33250 (epoch 18.292), train_loss = 1.02267055, grad/param norm = 1.8381e-01, time/batch = 15.7158s	
12165/33250 (epoch 18.293), train_loss = 1.07924952, grad/param norm = 1.5962e-01, time/batch = 15.1778s	
12166/33250 (epoch 18.295), train_loss = 1.02526652, grad/param norm = 1.5550e-01, time/batch = 15.0819s	
12167/33250 (epoch 18.296), train_loss = 1.00844536, grad/param norm = 1.5666e-01, time/batch = 15.3550s	
12168/33250 (epoch 18.298), train_loss = 0.81236087, grad/param norm = 1.3260e-01, time/batch = 15.4385s	
12169/33250 (epoch 18.299), train_loss = 0.76623651, grad/param norm = 1.3085e-01, time/batch = 15.1993s	
12170/33250 (epoch 18.301), train_loss = 1.02212939, grad/param norm = 1.4095e-01, time/batch = 15.8462s	
12171/33250 (epoch 18.302), train_loss = 1.02775675, grad/param norm = 1.5933e-01, time/batch = 15.8310s	
12172/33250 (epoch 18.304), train_loss = 0.87682605, grad/param norm = 1.5484e-01, time/batch = 15.7709s	
12173/33250 (epoch 18.305), train_loss = 0.93471600, grad/param norm = 1.4404e-01, time/batch = 15.7021s	
12174/33250 (epoch 18.307), train_loss = 1.03937745, grad/param norm = 1.5617e-01, time/batch = 15.2130s	
12175/33250 (epoch 18.308), train_loss = 1.14914467, grad/param norm = 1.6369e-01, time/batch = 15.3640s	
12176/33250 (epoch 18.310), train_loss = 0.95834888, grad/param norm = 1.6110e-01, time/batch = 15.2103s	
12177/33250 (epoch 18.311), train_loss = 1.08429399, grad/param norm = 1.5828e-01, time/batch = 14.8611s	
12178/33250 (epoch 18.313), train_loss = 0.81300485, grad/param norm = 1.3626e-01, time/batch = 14.8656s	
12179/33250 (epoch 18.314), train_loss = 0.96133755, grad/param norm = 1.4666e-01, time/batch = 15.4262s	
12180/33250 (epoch 18.316), train_loss = 1.13706679, grad/param norm = 1.6809e-01, time/batch = 15.0822s	
12181/33250 (epoch 18.317), train_loss = 0.86123025, grad/param norm = 1.2830e-01, time/batch = 15.2719s	
12182/33250 (epoch 18.319), train_loss = 1.03861315, grad/param norm = 1.7541e-01, time/batch = 15.3294s	
12183/33250 (epoch 18.320), train_loss = 1.07379670, grad/param norm = 1.7758e-01, time/batch = 15.4087s	
12184/33250 (epoch 18.322), train_loss = 1.15126967, grad/param norm = 1.8753e-01, time/batch = 15.4783s	
12185/33250 (epoch 18.323), train_loss = 1.20468173, grad/param norm = 1.9488e-01, time/batch = 15.2763s	
12186/33250 (epoch 18.325), train_loss = 0.99463639, grad/param norm = 1.8455e-01, time/batch = 15.2857s	
12187/33250 (epoch 18.326), train_loss = 1.12809211, grad/param norm = 1.5524e-01, time/batch = 15.1238s	
12188/33250 (epoch 18.328), train_loss = 0.93731640, grad/param norm = 1.3502e-01, time/batch = 14.6967s	
12189/33250 (epoch 18.329), train_loss = 0.96712768, grad/param norm = 1.6807e-01, time/batch = 15.1699s	
12190/33250 (epoch 18.331), train_loss = 0.94370112, grad/param norm = 1.6777e-01, time/batch = 14.9436s	
12191/33250 (epoch 18.332), train_loss = 0.93596653, grad/param norm = 1.3721e-01, time/batch = 15.3276s	
12192/33250 (epoch 18.334), train_loss = 1.12979421, grad/param norm = 1.6027e-01, time/batch = 15.0336s	
12193/33250 (epoch 18.335), train_loss = 0.73035627, grad/param norm = 1.3915e-01, time/batch = 14.7726s	
12194/33250 (epoch 18.337), train_loss = 1.01596822, grad/param norm = 1.4406e-01, time/batch = 14.9607s	
12195/33250 (epoch 18.338), train_loss = 1.08978550, grad/param norm = 1.5992e-01, time/batch = 15.5923s	
12196/33250 (epoch 18.340), train_loss = 0.99233285, grad/param norm = 1.4914e-01, time/batch = 15.0538s	
12197/33250 (epoch 18.341), train_loss = 0.92169654, grad/param norm = 1.5836e-01, time/batch = 15.5129s	
12198/33250 (epoch 18.343), train_loss = 0.92998543, grad/param norm = 1.5450e-01, time/batch = 15.0979s	
12199/33250 (epoch 18.344), train_loss = 0.95414091, grad/param norm = 1.3420e-01, time/batch = 15.0938s	
12200/33250 (epoch 18.346), train_loss = 0.84743987, grad/param norm = 1.4782e-01, time/batch = 15.5064s	
12201/33250 (epoch 18.347), train_loss = 1.21771269, grad/param norm = 1.7484e-01, time/batch = 14.9545s	
12202/33250 (epoch 18.349), train_loss = 0.90990799, grad/param norm = 1.4942e-01, time/batch = 14.9386s	
12203/33250 (epoch 18.350), train_loss = 0.94232027, grad/param norm = 1.5315e-01, time/batch = 15.2658s	
12204/33250 (epoch 18.352), train_loss = 0.83773571, grad/param norm = 1.5694e-01, time/batch = 15.0859s	
12205/33250 (epoch 18.353), train_loss = 0.93293816, grad/param norm = 1.5593e-01, time/batch = 15.5719s	
12206/33250 (epoch 18.355), train_loss = 0.93267075, grad/param norm = 1.5923e-01, time/batch = 15.2871s	
12207/33250 (epoch 18.356), train_loss = 0.87485058, grad/param norm = 1.5787e-01, time/batch = 15.2229s	
12208/33250 (epoch 18.358), train_loss = 0.94079172, grad/param norm = 1.4384e-01, time/batch = 15.2943s	
12209/33250 (epoch 18.359), train_loss = 0.92960980, grad/param norm = 1.4809e-01, time/batch = 15.5492s	
12210/33250 (epoch 18.361), train_loss = 1.12294835, grad/param norm = 1.7059e-01, time/batch = 14.9457s	
12211/33250 (epoch 18.362), train_loss = 0.98340130, grad/param norm = 1.5780e-01, time/batch = 15.2008s	
12212/33250 (epoch 18.364), train_loss = 1.04555950, grad/param norm = 1.6322e-01, time/batch = 14.7211s	
12213/33250 (epoch 18.365), train_loss = 0.96766963, grad/param norm = 1.4312e-01, time/batch = 15.1298s	
12214/33250 (epoch 18.367), train_loss = 0.97763708, grad/param norm = 1.3312e-01, time/batch = 15.3538s	
12215/33250 (epoch 18.368), train_loss = 0.95486833, grad/param norm = 1.5481e-01, time/batch = 15.1059s	
12216/33250 (epoch 18.370), train_loss = 0.84496814, grad/param norm = 1.3741e-01, time/batch = 15.2039s	
12217/33250 (epoch 18.371), train_loss = 1.10470126, grad/param norm = 1.5395e-01, time/batch = 15.1378s	
12218/33250 (epoch 18.373), train_loss = 0.93054597, grad/param norm = 1.3017e-01, time/batch = 15.2926s	
12219/33250 (epoch 18.374), train_loss = 1.05491276, grad/param norm = 2.6252e-01, time/batch = 14.7095s	
12220/33250 (epoch 18.376), train_loss = 0.92224585, grad/param norm = 1.5080e-01, time/batch = 14.8786s	
12221/33250 (epoch 18.377), train_loss = 0.86078298, grad/param norm = 1.6522e-01, time/batch = 14.4782s	
12222/33250 (epoch 18.379), train_loss = 0.89318031, grad/param norm = 1.5570e-01, time/batch = 15.2795s	
12223/33250 (epoch 18.380), train_loss = 1.01028905, grad/param norm = 1.7994e-01, time/batch = 28.9191s	
12224/33250 (epoch 18.382), train_loss = 1.04619945, grad/param norm = 1.6451e-01, time/batch = 14.4514s	
12225/33250 (epoch 18.383), train_loss = 0.87864192, grad/param norm = 1.5641e-01, time/batch = 15.4156s	
12226/33250 (epoch 18.385), train_loss = 0.82762147, grad/param norm = 1.6715e-01, time/batch = 15.4133s	
12227/33250 (epoch 18.386), train_loss = 0.84822282, grad/param norm = 1.7917e-01, time/batch = 15.1952s	
12228/33250 (epoch 18.388), train_loss = 0.87989840, grad/param norm = 1.5778e-01, time/batch = 14.7293s	
12229/33250 (epoch 18.389), train_loss = 0.93992596, grad/param norm = 1.7850e-01, time/batch = 15.0477s	
12230/33250 (epoch 18.391), train_loss = 0.98671131, grad/param norm = 1.5993e-01, time/batch = 15.0270s	
12231/33250 (epoch 18.392), train_loss = 1.06947216, grad/param norm = 1.7263e-01, time/batch = 14.8023s	
12232/33250 (epoch 18.394), train_loss = 1.10106046, grad/param norm = 1.6968e-01, time/batch = 15.0494s	
12233/33250 (epoch 18.395), train_loss = 1.05028238, grad/param norm = 1.3989e-01, time/batch = 15.3515s	
12234/33250 (epoch 18.397), train_loss = 1.07399474, grad/param norm = 1.5358e-01, time/batch = 15.1950s	
12235/33250 (epoch 18.398), train_loss = 0.92552345, grad/param norm = 1.5475e-01, time/batch = 15.4368s	
12236/33250 (epoch 18.400), train_loss = 0.86490541, grad/param norm = 1.3419e-01, time/batch = 15.0407s	
12237/33250 (epoch 18.402), train_loss = 0.82128367, grad/param norm = 1.4489e-01, time/batch = 15.3889s	
12238/33250 (epoch 18.403), train_loss = 0.92259226, grad/param norm = 1.7394e-01, time/batch = 15.1714s	
12239/33250 (epoch 18.405), train_loss = 0.89987812, grad/param norm = 1.3953e-01, time/batch = 14.8857s	
12240/33250 (epoch 18.406), train_loss = 0.97143635, grad/param norm = 1.5124e-01, time/batch = 15.2032s	
12241/33250 (epoch 18.408), train_loss = 1.12292682, grad/param norm = 1.7904e-01, time/batch = 15.3557s	
12242/33250 (epoch 18.409), train_loss = 1.05228165, grad/param norm = 2.0567e-01, time/batch = 15.0442s	
12243/33250 (epoch 18.411), train_loss = 0.70816397, grad/param norm = 1.1297e-01, time/batch = 14.7908s	
12244/33250 (epoch 18.412), train_loss = 0.83861291, grad/param norm = 1.5310e-01, time/batch = 14.7071s	
12245/33250 (epoch 18.414), train_loss = 0.98404979, grad/param norm = 1.4395e-01, time/batch = 15.4190s	
12246/33250 (epoch 18.415), train_loss = 1.07586882, grad/param norm = 1.7383e-01, time/batch = 15.0208s	
12247/33250 (epoch 18.417), train_loss = 1.04120855, grad/param norm = 1.5858e-01, time/batch = 14.9401s	
12248/33250 (epoch 18.418), train_loss = 1.19903987, grad/param norm = 1.9414e-01, time/batch = 15.7402s	
12249/33250 (epoch 18.420), train_loss = 1.09475728, grad/param norm = 1.6422e-01, time/batch = 15.3552s	
12250/33250 (epoch 18.421), train_loss = 0.90098633, grad/param norm = 1.5412e-01, time/batch = 15.2067s	
12251/33250 (epoch 18.423), train_loss = 1.03139761, grad/param norm = 1.7495e-01, time/batch = 15.9354s	
12252/33250 (epoch 18.424), train_loss = 1.16407522, grad/param norm = 2.3046e-01, time/batch = 15.3072s	
12253/33250 (epoch 18.426), train_loss = 0.89289766, grad/param norm = 1.4046e-01, time/batch = 15.7098s	
12254/33250 (epoch 18.427), train_loss = 0.90037950, grad/param norm = 1.5030e-01, time/batch = 15.7035s	
12255/33250 (epoch 18.429), train_loss = 1.02537338, grad/param norm = 1.6977e-01, time/batch = 15.7731s	
12256/33250 (epoch 18.430), train_loss = 0.89547378, grad/param norm = 1.6549e-01, time/batch = 15.8298s	
12257/33250 (epoch 18.432), train_loss = 1.01066936, grad/param norm = 1.5079e-01, time/batch = 15.2631s	
12258/33250 (epoch 18.433), train_loss = 0.91646412, grad/param norm = 1.6381e-01, time/batch = 15.0232s	
12259/33250 (epoch 18.435), train_loss = 1.05732189, grad/param norm = 1.7262e-01, time/batch = 14.7008s	
12260/33250 (epoch 18.436), train_loss = 0.90366871, grad/param norm = 1.6093e-01, time/batch = 15.2466s	
12261/33250 (epoch 18.438), train_loss = 1.03294025, grad/param norm = 1.3821e-01, time/batch = 15.4304s	
12262/33250 (epoch 18.439), train_loss = 0.97795522, grad/param norm = 1.4237e-01, time/batch = 15.5870s	
12263/33250 (epoch 18.441), train_loss = 0.94310899, grad/param norm = 1.3896e-01, time/batch = 15.1877s	
12264/33250 (epoch 18.442), train_loss = 0.89621925, grad/param norm = 1.6444e-01, time/batch = 14.8761s	
12265/33250 (epoch 18.444), train_loss = 0.87273241, grad/param norm = 1.3382e-01, time/batch = 15.0280s	
12266/33250 (epoch 18.445), train_loss = 0.96088019, grad/param norm = 1.3929e-01, time/batch = 15.3572s	
12267/33250 (epoch 18.447), train_loss = 0.99798610, grad/param norm = 1.5778e-01, time/batch = 15.5180s	
12268/33250 (epoch 18.448), train_loss = 0.96823926, grad/param norm = 1.3962e-01, time/batch = 15.2843s	
12269/33250 (epoch 18.450), train_loss = 1.14018159, grad/param norm = 1.6935e-01, time/batch = 15.6752s	
12270/33250 (epoch 18.451), train_loss = 1.02465658, grad/param norm = 1.5041e-01, time/batch = 15.1944s	
12271/33250 (epoch 18.453), train_loss = 0.89173835, grad/param norm = 1.5020e-01, time/batch = 15.4356s	
12272/33250 (epoch 18.454), train_loss = 1.11628628, grad/param norm = 1.5760e-01, time/batch = 15.8416s	
12273/33250 (epoch 18.456), train_loss = 1.11326703, grad/param norm = 1.4858e-01, time/batch = 15.3435s	
12274/33250 (epoch 18.457), train_loss = 0.91232549, grad/param norm = 1.4852e-01, time/batch = 15.2202s	
12275/33250 (epoch 18.459), train_loss = 0.99190173, grad/param norm = 1.4144e-01, time/batch = 15.1910s	
12276/33250 (epoch 18.460), train_loss = 1.06833159, grad/param norm = 1.6824e-01, time/batch = 15.1058s	
12277/33250 (epoch 18.462), train_loss = 0.90381881, grad/param norm = 1.4319e-01, time/batch = 15.6019s	
12278/33250 (epoch 18.463), train_loss = 0.89874230, grad/param norm = 1.3674e-01, time/batch = 15.2776s	
12279/33250 (epoch 18.465), train_loss = 0.80726229, grad/param norm = 1.2688e-01, time/batch = 15.0178s	
12280/33250 (epoch 18.466), train_loss = 0.75332330, grad/param norm = 1.0682e-01, time/batch = 15.5053s	
12281/33250 (epoch 18.468), train_loss = 0.87124403, grad/param norm = 1.3234e-01, time/batch = 14.7855s	
12282/33250 (epoch 18.469), train_loss = 0.95967290, grad/param norm = 1.8507e-01, time/batch = 15.0199s	
12283/33250 (epoch 18.471), train_loss = 1.04958247, grad/param norm = 1.5029e-01, time/batch = 15.1120s	
12284/33250 (epoch 18.472), train_loss = 0.95403303, grad/param norm = 1.8620e-01, time/batch = 15.2760s	
12285/33250 (epoch 18.474), train_loss = 1.11066651, grad/param norm = 1.8032e-01, time/batch = 15.4201s	
12286/33250 (epoch 18.475), train_loss = 0.99096238, grad/param norm = 1.4147e-01, time/batch = 15.4042s	
12287/33250 (epoch 18.477), train_loss = 0.97328534, grad/param norm = 1.3556e-01, time/batch = 14.9984s	
12288/33250 (epoch 18.478), train_loss = 0.88832349, grad/param norm = 1.4723e-01, time/batch = 15.3302s	
12289/33250 (epoch 18.480), train_loss = 1.17056705, grad/param norm = 1.6819e-01, time/batch = 15.0194s	
12290/33250 (epoch 18.481), train_loss = 0.99751424, grad/param norm = 1.4385e-01, time/batch = 14.8589s	
12291/33250 (epoch 18.483), train_loss = 0.99883930, grad/param norm = 1.4417e-01, time/batch = 15.4344s	
12292/33250 (epoch 18.484), train_loss = 0.87949883, grad/param norm = 1.3860e-01, time/batch = 15.2603s	
12293/33250 (epoch 18.486), train_loss = 0.80786630, grad/param norm = 1.4377e-01, time/batch = 14.8757s	
12294/33250 (epoch 18.487), train_loss = 0.90571495, grad/param norm = 1.5191e-01, time/batch = 14.9468s	
12295/33250 (epoch 18.489), train_loss = 1.08305795, grad/param norm = 1.8167e-01, time/batch = 14.9809s	
12296/33250 (epoch 18.490), train_loss = 0.99011812, grad/param norm = 1.5460e-01, time/batch = 15.1101s	
12297/33250 (epoch 18.492), train_loss = 1.03215100, grad/param norm = 1.6310e-01, time/batch = 15.4345s	
12298/33250 (epoch 18.493), train_loss = 0.97736168, grad/param norm = 1.6398e-01, time/batch = 15.3501s	
12299/33250 (epoch 18.495), train_loss = 0.99900723, grad/param norm = 1.4287e-01, time/batch = 15.0284s	
12300/33250 (epoch 18.496), train_loss = 0.94904507, grad/param norm = 1.2565e-01, time/batch = 15.9434s	
12301/33250 (epoch 18.498), train_loss = 1.06174744, grad/param norm = 1.5766e-01, time/batch = 14.9399s	
12302/33250 (epoch 18.499), train_loss = 0.92654249, grad/param norm = 1.3552e-01, time/batch = 14.9471s	
12303/33250 (epoch 18.501), train_loss = 0.90374721, grad/param norm = 1.5603e-01, time/batch = 15.0287s	
12304/33250 (epoch 18.502), train_loss = 0.91535401, grad/param norm = 1.2729e-01, time/batch = 15.3306s	
12305/33250 (epoch 18.504), train_loss = 1.10158798, grad/param norm = 1.5900e-01, time/batch = 14.9529s	
12306/33250 (epoch 18.505), train_loss = 0.78532222, grad/param norm = 1.2031e-01, time/batch = 17.4417s	
12307/33250 (epoch 18.507), train_loss = 0.90444532, grad/param norm = 1.4690e-01, time/batch = 15.8148s	
12308/33250 (epoch 18.508), train_loss = 0.91583664, grad/param norm = 1.5323e-01, time/batch = 15.6631s	
12309/33250 (epoch 18.510), train_loss = 0.78971296, grad/param norm = 1.4157e-01, time/batch = 14.9552s	
12310/33250 (epoch 18.511), train_loss = 0.96567655, grad/param norm = 1.4829e-01, time/batch = 15.0374s	
12311/33250 (epoch 18.513), train_loss = 1.09386301, grad/param norm = 1.6012e-01, time/batch = 15.4937s	
12312/33250 (epoch 18.514), train_loss = 0.91715708, grad/param norm = 1.4068e-01, time/batch = 15.5818s	
12313/33250 (epoch 18.516), train_loss = 0.89759293, grad/param norm = 1.5029e-01, time/batch = 15.5550s	
12314/33250 (epoch 18.517), train_loss = 0.94275784, grad/param norm = 1.5408e-01, time/batch = 15.5655s	
12315/33250 (epoch 18.519), train_loss = 0.84678870, grad/param norm = 1.4892e-01, time/batch = 15.8521s	
12316/33250 (epoch 18.520), train_loss = 1.21631231, grad/param norm = 3.0292e-01, time/batch = 16.7587s	
12317/33250 (epoch 18.522), train_loss = 1.04372795, grad/param norm = 1.6333e-01, time/batch = 16.6989s	
12318/33250 (epoch 18.523), train_loss = 0.90144518, grad/param norm = 1.4788e-01, time/batch = 16.9509s	
12319/33250 (epoch 18.525), train_loss = 0.84658643, grad/param norm = 1.6016e-01, time/batch = 15.5179s	
12320/33250 (epoch 18.526), train_loss = 0.83007154, grad/param norm = 1.4294e-01, time/batch = 15.6239s	
12321/33250 (epoch 18.528), train_loss = 0.93633631, grad/param norm = 1.5502e-01, time/batch = 15.6039s	
12322/33250 (epoch 18.529), train_loss = 0.89190779, grad/param norm = 1.5281e-01, time/batch = 15.5942s	
12323/33250 (epoch 18.531), train_loss = 0.85248729, grad/param norm = 1.2959e-01, time/batch = 15.8165s	
12324/33250 (epoch 18.532), train_loss = 1.01346970, grad/param norm = 1.4379e-01, time/batch = 16.2859s	
12325/33250 (epoch 18.534), train_loss = 0.86037513, grad/param norm = 1.2801e-01, time/batch = 15.7617s	
12326/33250 (epoch 18.535), train_loss = 0.93926919, grad/param norm = 1.2990e-01, time/batch = 15.7700s	
12327/33250 (epoch 18.537), train_loss = 1.00262255, grad/param norm = 1.4768e-01, time/batch = 16.5510s	
12328/33250 (epoch 18.538), train_loss = 1.03566369, grad/param norm = 1.5701e-01, time/batch = 17.5308s	
12329/33250 (epoch 18.540), train_loss = 1.11628373, grad/param norm = 1.3742e-01, time/batch = 17.1134s	
12330/33250 (epoch 18.541), train_loss = 1.05756493, grad/param norm = 1.7262e-01, time/batch = 15.8317s	
12331/33250 (epoch 18.543), train_loss = 1.02775272, grad/param norm = 1.4684e-01, time/batch = 15.3591s	
12332/33250 (epoch 18.544), train_loss = 0.90448235, grad/param norm = 1.5547e-01, time/batch = 15.6064s	
12333/33250 (epoch 18.546), train_loss = 0.95455318, grad/param norm = 1.6707e-01, time/batch = 17.3404s	
12334/33250 (epoch 18.547), train_loss = 0.93616027, grad/param norm = 1.5179e-01, time/batch = 15.6892s	
12335/33250 (epoch 18.549), train_loss = 1.03605346, grad/param norm = 1.5435e-01, time/batch = 17.6964s	
12336/33250 (epoch 18.550), train_loss = 0.92417110, grad/param norm = 1.4827e-01, time/batch = 17.3729s	
12337/33250 (epoch 18.552), train_loss = 0.99499488, grad/param norm = 1.4872e-01, time/batch = 16.2502s	
12338/33250 (epoch 18.553), train_loss = 0.88042914, grad/param norm = 1.4602e-01, time/batch = 15.5730s	
12339/33250 (epoch 18.555), train_loss = 1.00310144, grad/param norm = 1.4894e-01, time/batch = 15.7951s	
12340/33250 (epoch 18.556), train_loss = 1.05839596, grad/param norm = 1.6004e-01, time/batch = 15.1140s	
12341/33250 (epoch 18.558), train_loss = 1.07254136, grad/param norm = 1.6634e-01, time/batch = 15.7255s	
12342/33250 (epoch 18.559), train_loss = 0.86116647, grad/param norm = 1.2966e-01, time/batch = 14.8740s	
12343/33250 (epoch 18.561), train_loss = 0.86054214, grad/param norm = 1.3822e-01, time/batch = 15.0263s	
12344/33250 (epoch 18.562), train_loss = 1.08177964, grad/param norm = 1.6502e-01, time/batch = 15.1791s	
12345/33250 (epoch 18.564), train_loss = 1.18312675, grad/param norm = 1.7717e-01, time/batch = 14.8292s	
12346/33250 (epoch 18.565), train_loss = 1.11004337, grad/param norm = 1.7588e-01, time/batch = 14.2375s	
12347/33250 (epoch 18.567), train_loss = 1.10377228, grad/param norm = 1.6274e-01, time/batch = 14.6276s	
12348/33250 (epoch 18.568), train_loss = 0.98023283, grad/param norm = 1.5361e-01, time/batch = 14.4014s	
12349/33250 (epoch 18.570), train_loss = 1.10194144, grad/param norm = 1.7465e-01, time/batch = 15.0172s	
12350/33250 (epoch 18.571), train_loss = 1.12675223, grad/param norm = 1.5991e-01, time/batch = 14.3136s	
12351/33250 (epoch 18.573), train_loss = 1.02646054, grad/param norm = 1.6680e-01, time/batch = 14.4718s	
12352/33250 (epoch 18.574), train_loss = 0.86817487, grad/param norm = 1.3807e-01, time/batch = 14.3993s	
12353/33250 (epoch 18.576), train_loss = 0.99824138, grad/param norm = 1.4681e-01, time/batch = 14.8538s	
12354/33250 (epoch 18.577), train_loss = 0.95074567, grad/param norm = 1.4540e-01, time/batch = 14.5520s	
12355/33250 (epoch 18.579), train_loss = 0.88891500, grad/param norm = 1.4785e-01, time/batch = 14.3142s	
12356/33250 (epoch 18.580), train_loss = 0.91381157, grad/param norm = 1.2253e-01, time/batch = 15.4881s	
12357/33250 (epoch 18.582), train_loss = 0.95169160, grad/param norm = 1.4680e-01, time/batch = 15.1021s	
12358/33250 (epoch 18.583), train_loss = 1.05830481, grad/param norm = 1.5956e-01, time/batch = 14.7694s	
12359/33250 (epoch 18.585), train_loss = 1.05670219, grad/param norm = 1.4786e-01, time/batch = 13.9259s	
12360/33250 (epoch 18.586), train_loss = 0.93820339, grad/param norm = 1.8825e-01, time/batch = 14.6360s	
12361/33250 (epoch 18.588), train_loss = 0.99597475, grad/param norm = 1.3987e-01, time/batch = 14.7931s	
12362/33250 (epoch 18.589), train_loss = 0.99480526, grad/param norm = 1.4606e-01, time/batch = 14.3162s	
12363/33250 (epoch 18.591), train_loss = 0.99211513, grad/param norm = 1.5925e-01, time/batch = 14.3859s	
12364/33250 (epoch 18.592), train_loss = 0.97990749, grad/param norm = 1.3844e-01, time/batch = 14.5324s	
12365/33250 (epoch 18.594), train_loss = 1.11753576, grad/param norm = 1.7727e-01, time/batch = 14.6188s	
12366/33250 (epoch 18.595), train_loss = 1.02791994, grad/param norm = 1.5939e-01, time/batch = 14.6171s	
12367/33250 (epoch 18.597), train_loss = 0.82642077, grad/param norm = 1.3150e-01, time/batch = 14.4579s	
12368/33250 (epoch 18.598), train_loss = 0.94330320, grad/param norm = 1.5617e-01, time/batch = 14.5463s	
12369/33250 (epoch 18.600), train_loss = 0.96955637, grad/param norm = 1.7857e-01, time/batch = 14.1488s	
12370/33250 (epoch 18.602), train_loss = 1.00460548, grad/param norm = 1.8479e-01, time/batch = 14.2452s	
12371/33250 (epoch 18.603), train_loss = 1.00374140, grad/param norm = 1.6337e-01, time/batch = 14.3270s	
12372/33250 (epoch 18.605), train_loss = 0.98031494, grad/param norm = 1.5416e-01, time/batch = 14.7348s	
12373/33250 (epoch 18.606), train_loss = 1.02155628, grad/param norm = 1.5293e-01, time/batch = 14.7084s	
12374/33250 (epoch 18.608), train_loss = 0.98284973, grad/param norm = 1.4714e-01, time/batch = 15.1000s	
12375/33250 (epoch 18.609), train_loss = 0.87233101, grad/param norm = 1.4647e-01, time/batch = 15.0124s	
12376/33250 (epoch 18.611), train_loss = 1.00604675, grad/param norm = 1.6844e-01, time/batch = 14.6898s	
12377/33250 (epoch 18.612), train_loss = 0.98380837, grad/param norm = 1.5477e-01, time/batch = 14.7108s	
12378/33250 (epoch 18.614), train_loss = 1.19465370, grad/param norm = 1.9940e-01, time/batch = 15.0171s	
12379/33250 (epoch 18.615), train_loss = 1.09041823, grad/param norm = 1.6583e-01, time/batch = 15.0799s	
12380/33250 (epoch 18.617), train_loss = 1.25934113, grad/param norm = 1.7365e-01, time/batch = 14.6180s	
12381/33250 (epoch 18.618), train_loss = 1.26787191, grad/param norm = 2.0643e-01, time/batch = 14.8682s	
12382/33250 (epoch 18.620), train_loss = 1.08684984, grad/param norm = 1.7061e-01, time/batch = 14.7968s	
12383/33250 (epoch 18.621), train_loss = 1.00477040, grad/param norm = 1.5101e-01, time/batch = 14.4788s	
12384/33250 (epoch 18.623), train_loss = 0.90712347, grad/param norm = 1.5063e-01, time/batch = 14.4125s	
12385/33250 (epoch 18.624), train_loss = 0.97769228, grad/param norm = 1.8696e-01, time/batch = 14.3152s	
12386/33250 (epoch 18.626), train_loss = 0.94315079, grad/param norm = 1.8227e-01, time/batch = 14.7881s	
12387/33250 (epoch 18.627), train_loss = 0.92432742, grad/param norm = 1.4670e-01, time/batch = 14.0618s	
12388/33250 (epoch 18.629), train_loss = 1.04605222, grad/param norm = 2.0107e-01, time/batch = 15.1724s	
12389/33250 (epoch 18.630), train_loss = 0.93426380, grad/param norm = 1.6861e-01, time/batch = 14.7875s	
12390/33250 (epoch 18.632), train_loss = 0.80342034, grad/param norm = 1.2773e-01, time/batch = 15.2422s	
12391/33250 (epoch 18.633), train_loss = 1.00378530, grad/param norm = 1.5692e-01, time/batch = 15.0244s	
12392/33250 (epoch 18.635), train_loss = 0.88359631, grad/param norm = 1.4396e-01, time/batch = 14.5648s	
12393/33250 (epoch 18.636), train_loss = 0.90605412, grad/param norm = 1.4881e-01, time/batch = 14.7299s	
12394/33250 (epoch 18.638), train_loss = 0.92688103, grad/param norm = 1.4889e-01, time/batch = 15.1928s	
12395/33250 (epoch 18.639), train_loss = 0.80936829, grad/param norm = 1.4729e-01, time/batch = 14.5636s	
12396/33250 (epoch 18.641), train_loss = 0.92608121, grad/param norm = 1.3878e-01, time/batch = 15.2042s	
12397/33250 (epoch 18.642), train_loss = 0.79061540, grad/param norm = 1.3598e-01, time/batch = 14.8014s	
12398/33250 (epoch 18.644), train_loss = 0.71559829, grad/param norm = 1.3151e-01, time/batch = 15.1075s	
12399/33250 (epoch 18.645), train_loss = 1.04579197, grad/param norm = 1.6865e-01, time/batch = 14.8672s	
12400/33250 (epoch 18.647), train_loss = 0.84965822, grad/param norm = 1.5273e-01, time/batch = 15.2525s	
12401/33250 (epoch 18.648), train_loss = 0.88602713, grad/param norm = 1.5271e-01, time/batch = 15.1924s	
12402/33250 (epoch 18.650), train_loss = 1.09168436, grad/param norm = 1.7505e-01, time/batch = 14.6215s	
12403/33250 (epoch 18.651), train_loss = 1.01113288, grad/param norm = 1.7579e-01, time/batch = 14.2263s	
12404/33250 (epoch 18.653), train_loss = 0.87131468, grad/param norm = 1.4528e-01, time/batch = 14.3051s	
12405/33250 (epoch 18.654), train_loss = 0.94313801, grad/param norm = 1.4374e-01, time/batch = 14.3330s	
12406/33250 (epoch 18.656), train_loss = 1.01902551, grad/param norm = 1.5378e-01, time/batch = 14.3227s	
12407/33250 (epoch 18.657), train_loss = 0.76819165, grad/param norm = 1.4349e-01, time/batch = 14.4090s	
12408/33250 (epoch 18.659), train_loss = 0.91465740, grad/param norm = 1.4508e-01, time/batch = 14.6986s	
12409/33250 (epoch 18.660), train_loss = 0.94878188, grad/param norm = 1.6224e-01, time/batch = 14.4692s	
12410/33250 (epoch 18.662), train_loss = 0.97459698, grad/param norm = 1.4104e-01, time/batch = 14.5498s	
12411/33250 (epoch 18.663), train_loss = 0.88391049, grad/param norm = 1.4460e-01, time/batch = 15.3334s	
12412/33250 (epoch 18.665), train_loss = 0.99606937, grad/param norm = 1.4325e-01, time/batch = 15.3300s	
12413/33250 (epoch 18.666), train_loss = 0.92781322, grad/param norm = 1.5194e-01, time/batch = 14.5467s	
12414/33250 (epoch 18.668), train_loss = 1.10555796, grad/param norm = 1.4947e-01, time/batch = 14.9391s	
12415/33250 (epoch 18.669), train_loss = 0.99789365, grad/param norm = 1.6432e-01, time/batch = 14.3926s	
12416/33250 (epoch 18.671), train_loss = 0.88732793, grad/param norm = 1.7798e-01, time/batch = 14.4929s	
12417/33250 (epoch 18.672), train_loss = 1.05846673, grad/param norm = 1.6841e-01, time/batch = 14.6515s	
12418/33250 (epoch 18.674), train_loss = 0.87493225, grad/param norm = 1.3880e-01, time/batch = 14.8770s	
12419/33250 (epoch 18.675), train_loss = 0.94450942, grad/param norm = 1.4481e-01, time/batch = 15.1172s	
12420/33250 (epoch 18.677), train_loss = 1.04728612, grad/param norm = 1.5670e-01, time/batch = 14.9747s	
12421/33250 (epoch 18.678), train_loss = 0.91921611, grad/param norm = 1.4777e-01, time/batch = 15.0511s	
12422/33250 (epoch 18.680), train_loss = 1.07334169, grad/param norm = 1.5079e-01, time/batch = 15.5811s	
12423/33250 (epoch 18.681), train_loss = 0.84021419, grad/param norm = 1.4279e-01, time/batch = 14.8695s	
12424/33250 (epoch 18.683), train_loss = 0.95725639, grad/param norm = 1.6687e-01, time/batch = 15.3380s	
12425/33250 (epoch 18.684), train_loss = 0.86204386, grad/param norm = 1.5562e-01, time/batch = 15.2369s	
12426/33250 (epoch 18.686), train_loss = 0.89344506, grad/param norm = 1.4768e-01, time/batch = 15.2547s	
12427/33250 (epoch 18.687), train_loss = 0.95599819, grad/param norm = 1.4572e-01, time/batch = 15.6546s	
12428/33250 (epoch 18.689), train_loss = 0.89087829, grad/param norm = 1.5697e-01, time/batch = 15.7667s	
12429/33250 (epoch 18.690), train_loss = 0.96909730, grad/param norm = 1.4424e-01, time/batch = 14.3330s	
12430/33250 (epoch 18.692), train_loss = 0.93249813, grad/param norm = 1.4204e-01, time/batch = 14.6474s	
12431/33250 (epoch 18.693), train_loss = 1.04555042, grad/param norm = 1.5330e-01, time/batch = 15.0283s	
12432/33250 (epoch 18.695), train_loss = 1.00303660, grad/param norm = 1.6730e-01, time/batch = 14.5512s	
12433/33250 (epoch 18.696), train_loss = 0.99425689, grad/param norm = 1.4408e-01, time/batch = 14.5578s	
12434/33250 (epoch 18.698), train_loss = 0.89793150, grad/param norm = 1.5696e-01, time/batch = 15.2620s	
12435/33250 (epoch 18.699), train_loss = 1.16258751, grad/param norm = 1.5833e-01, time/batch = 14.5538s	
12436/33250 (epoch 18.701), train_loss = 0.96437026, grad/param norm = 1.3986e-01, time/batch = 14.7960s	
12437/33250 (epoch 18.702), train_loss = 0.91582873, grad/param norm = 2.0054e-01, time/batch = 15.6167s	
12438/33250 (epoch 18.704), train_loss = 1.13240326, grad/param norm = 1.8788e-01, time/batch = 15.1026s	
12439/33250 (epoch 18.705), train_loss = 0.87648885, grad/param norm = 1.3167e-01, time/batch = 16.9479s	
12440/33250 (epoch 18.707), train_loss = 0.79353798, grad/param norm = 1.3705e-01, time/batch = 16.7305s	
12441/33250 (epoch 18.708), train_loss = 1.05823664, grad/param norm = 1.6951e-01, time/batch = 16.1036s	
12442/33250 (epoch 18.710), train_loss = 1.03443374, grad/param norm = 1.5671e-01, time/batch = 15.8681s	
12443/33250 (epoch 18.711), train_loss = 0.89143128, grad/param norm = 1.5159e-01, time/batch = 15.9593s	
12444/33250 (epoch 18.713), train_loss = 0.99381974, grad/param norm = 1.4883e-01, time/batch = 15.5316s	
12445/33250 (epoch 18.714), train_loss = 0.97861621, grad/param norm = 1.5330e-01, time/batch = 15.8636s	
12446/33250 (epoch 18.716), train_loss = 1.03163207, grad/param norm = 1.5389e-01, time/batch = 15.3274s	
12447/33250 (epoch 18.717), train_loss = 0.88780473, grad/param norm = 1.3087e-01, time/batch = 15.2702s	
12448/33250 (epoch 18.719), train_loss = 0.94166402, grad/param norm = 1.4572e-01, time/batch = 15.6674s	
12449/33250 (epoch 18.720), train_loss = 1.20744315, grad/param norm = 1.7987e-01, time/batch = 18.1881s	
12450/33250 (epoch 18.722), train_loss = 0.85341527, grad/param norm = 1.3656e-01, time/batch = 15.9263s	
12451/33250 (epoch 18.723), train_loss = 0.76666596, grad/param norm = 1.2686e-01, time/batch = 18.1905s	
12452/33250 (epoch 18.725), train_loss = 0.83720395, grad/param norm = 1.2662e-01, time/batch = 17.7716s	
12453/33250 (epoch 18.726), train_loss = 0.92656810, grad/param norm = 1.3362e-01, time/batch = 15.9335s	
12454/33250 (epoch 18.728), train_loss = 0.98752359, grad/param norm = 1.4115e-01, time/batch = 15.6456s	
12455/33250 (epoch 18.729), train_loss = 1.08313089, grad/param norm = 1.6645e-01, time/batch = 15.2675s	
12456/33250 (epoch 18.731), train_loss = 0.90522402, grad/param norm = 1.5889e-01, time/batch = 17.3904s	
12457/33250 (epoch 18.732), train_loss = 0.85813285, grad/param norm = 1.4354e-01, time/batch = 27.7111s	
12458/33250 (epoch 18.734), train_loss = 0.98092284, grad/param norm = 1.4389e-01, time/batch = 15.6947s	
12459/33250 (epoch 18.735), train_loss = 0.96747095, grad/param norm = 1.6375e-01, time/batch = 15.4494s	
12460/33250 (epoch 18.737), train_loss = 0.94056799, grad/param norm = 1.3698e-01, time/batch = 15.5263s	
12461/33250 (epoch 18.738), train_loss = 0.97641321, grad/param norm = 1.4177e-01, time/batch = 17.2023s	
12462/33250 (epoch 18.740), train_loss = 1.07092568, grad/param norm = 1.5188e-01, time/batch = 15.5601s	
12463/33250 (epoch 18.741), train_loss = 1.05110751, grad/param norm = 1.6086e-01, time/batch = 15.3591s	
12464/33250 (epoch 18.743), train_loss = 0.90622107, grad/param norm = 1.3734e-01, time/batch = 15.2798s	
12465/33250 (epoch 18.744), train_loss = 0.92498925, grad/param norm = 1.5419e-01, time/batch = 15.9546s	
12466/33250 (epoch 18.746), train_loss = 0.88733401, grad/param norm = 1.4876e-01, time/batch = 15.7015s	
12467/33250 (epoch 18.747), train_loss = 0.89582623, grad/param norm = 1.5937e-01, time/batch = 15.3974s	
12468/33250 (epoch 18.749), train_loss = 1.07326461, grad/param norm = 1.6591e-01, time/batch = 15.3358s	
12469/33250 (epoch 18.750), train_loss = 1.05236025, grad/param norm = 1.6501e-01, time/batch = 15.0531s	
12470/33250 (epoch 18.752), train_loss = 0.90926994, grad/param norm = 1.3297e-01, time/batch = 15.4666s	
12471/33250 (epoch 18.753), train_loss = 0.92709220, grad/param norm = 1.4994e-01, time/batch = 15.9519s	
12472/33250 (epoch 18.755), train_loss = 0.94567107, grad/param norm = 1.6476e-01, time/batch = 15.4683s	
12473/33250 (epoch 18.756), train_loss = 1.01793155, grad/param norm = 1.5626e-01, time/batch = 15.4558s	
12474/33250 (epoch 18.758), train_loss = 1.09451196, grad/param norm = 1.5303e-01, time/batch = 15.6277s	
12475/33250 (epoch 18.759), train_loss = 0.88290760, grad/param norm = 1.4079e-01, time/batch = 15.2615s	
12476/33250 (epoch 18.761), train_loss = 0.94675398, grad/param norm = 1.4004e-01, time/batch = 15.3837s	
12477/33250 (epoch 18.762), train_loss = 1.06917138, grad/param norm = 1.4733e-01, time/batch = 16.1154s	
12478/33250 (epoch 18.764), train_loss = 0.88123585, grad/param norm = 1.8597e-01, time/batch = 16.0882s	
12479/33250 (epoch 18.765), train_loss = 1.00892475, grad/param norm = 1.5089e-01, time/batch = 15.3400s	
12480/33250 (epoch 18.767), train_loss = 0.80414779, grad/param norm = 1.4422e-01, time/batch = 16.8005s	
12481/33250 (epoch 18.768), train_loss = 0.82494836, grad/param norm = 1.4792e-01, time/batch = 15.4466s	
12482/33250 (epoch 18.770), train_loss = 1.01016152, grad/param norm = 1.8686e-01, time/batch = 15.4665s	
12483/33250 (epoch 18.771), train_loss = 1.02415189, grad/param norm = 1.6414e-01, time/batch = 16.8750s	
12484/33250 (epoch 18.773), train_loss = 0.92365124, grad/param norm = 1.5770e-01, time/batch = 15.5314s	
12485/33250 (epoch 18.774), train_loss = 0.80772631, grad/param norm = 1.5170e-01, time/batch = 15.8612s	
12486/33250 (epoch 18.776), train_loss = 0.90440822, grad/param norm = 1.4814e-01, time/batch = 15.3647s	
12487/33250 (epoch 18.777), train_loss = 1.05846151, grad/param norm = 1.7155e-01, time/batch = 15.6004s	
12488/33250 (epoch 18.779), train_loss = 0.94789764, grad/param norm = 1.5464e-01, time/batch = 15.4806s	
12489/33250 (epoch 18.780), train_loss = 1.12482801, grad/param norm = 1.6305e-01, time/batch = 15.2861s	
12490/33250 (epoch 18.782), train_loss = 0.99133272, grad/param norm = 1.5147e-01, time/batch = 15.2661s	
12491/33250 (epoch 18.783), train_loss = 0.81491667, grad/param norm = 1.4297e-01, time/batch = 15.7795s	
12492/33250 (epoch 18.785), train_loss = 0.84348100, grad/param norm = 1.3915e-01, time/batch = 15.6526s	
12493/33250 (epoch 18.786), train_loss = 1.04403927, grad/param norm = 1.4976e-01, time/batch = 16.1061s	
12494/33250 (epoch 18.788), train_loss = 1.01937261, grad/param norm = 1.4930e-01, time/batch = 15.4986s	
12495/33250 (epoch 18.789), train_loss = 1.06891381, grad/param norm = 1.7837e-01, time/batch = 15.2420s	
12496/33250 (epoch 18.791), train_loss = 1.12946830, grad/param norm = 1.6254e-01, time/batch = 15.8173s	
12497/33250 (epoch 18.792), train_loss = 1.19668416, grad/param norm = 1.4907e-01, time/batch = 15.4849s	
12498/33250 (epoch 18.794), train_loss = 0.95667739, grad/param norm = 1.7430e-01, time/batch = 15.6213s	
12499/33250 (epoch 18.795), train_loss = 1.00427392, grad/param norm = 1.6919e-01, time/batch = 15.6292s	
12500/33250 (epoch 18.797), train_loss = 1.07411171, grad/param norm = 2.0039e-01, time/batch = 15.7028s	
12501/33250 (epoch 18.798), train_loss = 0.97220886, grad/param norm = 1.7975e-01, time/batch = 16.1311s	
12502/33250 (epoch 18.800), train_loss = 1.01671836, grad/param norm = 1.6583e-01, time/batch = 16.9476s	
12503/33250 (epoch 18.802), train_loss = 0.92265173, grad/param norm = 1.2768e-01, time/batch = 17.6836s	
12504/33250 (epoch 18.803), train_loss = 0.98074056, grad/param norm = 1.3987e-01, time/batch = 16.1972s	
12505/33250 (epoch 18.805), train_loss = 1.01139390, grad/param norm = 1.5831e-01, time/batch = 15.6593s	
12506/33250 (epoch 18.806), train_loss = 0.98555752, grad/param norm = 1.6076e-01, time/batch = 16.9388s	
12507/33250 (epoch 18.808), train_loss = 0.94042880, grad/param norm = 1.4032e-01, time/batch = 16.1150s	
12508/33250 (epoch 18.809), train_loss = 0.89390612, grad/param norm = 1.4876e-01, time/batch = 16.3507s	
12509/33250 (epoch 18.811), train_loss = 0.89236784, grad/param norm = 1.4742e-01, time/batch = 16.5158s	
12510/33250 (epoch 18.812), train_loss = 1.03612255, grad/param norm = 1.6817e-01, time/batch = 15.7308s	
12511/33250 (epoch 18.814), train_loss = 0.96565577, grad/param norm = 1.4651e-01, time/batch = 16.0310s	
12512/33250 (epoch 18.815), train_loss = 1.02117194, grad/param norm = 1.4241e-01, time/batch = 15.6051s	
12513/33250 (epoch 18.817), train_loss = 0.94172257, grad/param norm = 1.4532e-01, time/batch = 1.2955s	
12514/33250 (epoch 18.818), train_loss = 0.88627268, grad/param norm = 1.4868e-01, time/batch = 0.6673s	
12515/33250 (epoch 18.820), train_loss = 0.96572744, grad/param norm = 1.4507e-01, time/batch = 0.6676s	
12516/33250 (epoch 18.821), train_loss = 0.94749636, grad/param norm = 1.3315e-01, time/batch = 0.6689s	
12517/33250 (epoch 18.823), train_loss = 1.29271275, grad/param norm = 1.7707e-01, time/batch = 0.6633s	
12518/33250 (epoch 18.824), train_loss = 0.93881019, grad/param norm = 1.7258e-01, time/batch = 0.6853s	
12519/33250 (epoch 18.826), train_loss = 1.00531550, grad/param norm = 1.7238e-01, time/batch = 0.6835s	
12520/33250 (epoch 18.827), train_loss = 0.80051283, grad/param norm = 1.4679e-01, time/batch = 0.8418s	
12521/33250 (epoch 18.829), train_loss = 1.00825209, grad/param norm = 1.9744e-01, time/batch = 1.0111s	
12522/33250 (epoch 18.830), train_loss = 1.08385958, grad/param norm = 2.0221e-01, time/batch = 0.9926s	
12523/33250 (epoch 18.832), train_loss = 0.98653015, grad/param norm = 1.5925e-01, time/batch = 0.9829s	
12524/33250 (epoch 18.833), train_loss = 0.98644503, grad/param norm = 1.6616e-01, time/batch = 0.9681s	
12525/33250 (epoch 18.835), train_loss = 0.90169287, grad/param norm = 1.6234e-01, time/batch = 1.3826s	
12526/33250 (epoch 18.836), train_loss = 0.94237711, grad/param norm = 1.5650e-01, time/batch = 1.8231s	
12527/33250 (epoch 18.838), train_loss = 0.97263229, grad/param norm = 1.4956e-01, time/batch = 1.8311s	
12528/33250 (epoch 18.839), train_loss = 0.92636150, grad/param norm = 1.5221e-01, time/batch = 13.3876s	
12529/33250 (epoch 18.841), train_loss = 0.89587177, grad/param norm = 1.3800e-01, time/batch = 15.8332s	
12530/33250 (epoch 18.842), train_loss = 1.11801944, grad/param norm = 1.4983e-01, time/batch = 15.5917s	
12531/33250 (epoch 18.844), train_loss = 1.10237097, grad/param norm = 1.7612e-01, time/batch = 15.5866s	
12532/33250 (epoch 18.845), train_loss = 1.17157265, grad/param norm = 1.7489e-01, time/batch = 15.0535s	
12533/33250 (epoch 18.847), train_loss = 1.12571227, grad/param norm = 1.6241e-01, time/batch = 15.2053s	
12534/33250 (epoch 18.848), train_loss = 1.23837592, grad/param norm = 1.8002e-01, time/batch = 15.2827s	
12535/33250 (epoch 18.850), train_loss = 1.08937659, grad/param norm = 1.7120e-01, time/batch = 16.0355s	
12536/33250 (epoch 18.851), train_loss = 0.91038249, grad/param norm = 1.6734e-01, time/batch = 16.2206s	
12537/33250 (epoch 18.853), train_loss = 1.05783872, grad/param norm = 1.8829e-01, time/batch = 15.4741s	
12538/33250 (epoch 18.854), train_loss = 0.90062436, grad/param norm = 1.4111e-01, time/batch = 16.2865s	
12539/33250 (epoch 18.856), train_loss = 0.91528654, grad/param norm = 1.6330e-01, time/batch = 15.9780s	
12540/33250 (epoch 18.857), train_loss = 0.84128353, grad/param norm = 1.4138e-01, time/batch = 15.6884s	
12541/33250 (epoch 18.859), train_loss = 0.84703506, grad/param norm = 1.3884e-01, time/batch = 16.1694s	
12542/33250 (epoch 18.860), train_loss = 0.98383068, grad/param norm = 1.4507e-01, time/batch = 15.9009s	
12543/33250 (epoch 18.862), train_loss = 0.87324929, grad/param norm = 1.2850e-01, time/batch = 15.1232s	
12544/33250 (epoch 18.863), train_loss = 0.93224676, grad/param norm = 1.6589e-01, time/batch = 15.3515s	
12545/33250 (epoch 18.865), train_loss = 1.02279323, grad/param norm = 1.5316e-01, time/batch = 15.4332s	
12546/33250 (epoch 18.866), train_loss = 0.93481571, grad/param norm = 1.5622e-01, time/batch = 15.9486s	
12547/33250 (epoch 18.868), train_loss = 1.04344521, grad/param norm = 1.8813e-01, time/batch = 16.1354s	
12548/33250 (epoch 18.869), train_loss = 1.01119038, grad/param norm = 1.6740e-01, time/batch = 15.2292s	
12549/33250 (epoch 18.871), train_loss = 0.75554875, grad/param norm = 1.4309e-01, time/batch = 15.5292s	
12550/33250 (epoch 18.872), train_loss = 1.01525875, grad/param norm = 1.6545e-01, time/batch = 15.1959s	
12551/33250 (epoch 18.874), train_loss = 0.87793730, grad/param norm = 1.6573e-01, time/batch = 15.3526s	
12552/33250 (epoch 18.875), train_loss = 0.86149394, grad/param norm = 1.5467e-01, time/batch = 16.1226s	
12553/33250 (epoch 18.877), train_loss = 1.09718540, grad/param norm = 1.5534e-01, time/batch = 15.6564s	
12554/33250 (epoch 18.878), train_loss = 1.00473464, grad/param norm = 1.5257e-01, time/batch = 15.4323s	
12555/33250 (epoch 18.880), train_loss = 0.98599994, grad/param norm = 2.0207e-01, time/batch = 14.9576s	
12556/33250 (epoch 18.881), train_loss = 1.11154930, grad/param norm = 1.7740e-01, time/batch = 15.1097s	
12557/33250 (epoch 18.883), train_loss = 1.01093310, grad/param norm = 1.5212e-01, time/batch = 15.2712s	
12558/33250 (epoch 18.884), train_loss = 0.98560177, grad/param norm = 1.6353e-01, time/batch = 15.5289s	
12559/33250 (epoch 18.886), train_loss = 0.90618305, grad/param norm = 1.2998e-01, time/batch = 15.8910s	
12560/33250 (epoch 18.887), train_loss = 0.93235041, grad/param norm = 1.5640e-01, time/batch = 18.2074s	
12561/33250 (epoch 18.889), train_loss = 0.91145546, grad/param norm = 1.3457e-01, time/batch = 16.2622s	
12562/33250 (epoch 18.890), train_loss = 0.79739212, grad/param norm = 1.2665e-01, time/batch = 15.6429s	
12563/33250 (epoch 18.892), train_loss = 1.01309821, grad/param norm = 1.5033e-01, time/batch = 15.0208s	
12564/33250 (epoch 18.893), train_loss = 1.03398712, grad/param norm = 1.6961e-01, time/batch = 15.3273s	
12565/33250 (epoch 18.895), train_loss = 0.92131278, grad/param norm = 1.5313e-01, time/batch = 14.9358s	
12566/33250 (epoch 18.896), train_loss = 1.06708778, grad/param norm = 1.7027e-01, time/batch = 14.8724s	
12567/33250 (epoch 18.898), train_loss = 0.96065213, grad/param norm = 1.4697e-01, time/batch = 15.6148s	
12568/33250 (epoch 18.899), train_loss = 0.89060988, grad/param norm = 1.4203e-01, time/batch = 15.6915s	
12569/33250 (epoch 18.901), train_loss = 0.82739216, grad/param norm = 1.3176e-01, time/batch = 18.4465s	
12570/33250 (epoch 18.902), train_loss = 0.95393652, grad/param norm = 1.5241e-01, time/batch = 15.2859s	
12571/33250 (epoch 18.904), train_loss = 0.87440673, grad/param norm = 1.3059e-01, time/batch = 15.9733s	
12572/33250 (epoch 18.905), train_loss = 0.91855046, grad/param norm = 1.3849e-01, time/batch = 15.2684s	
12573/33250 (epoch 18.907), train_loss = 0.88326656, grad/param norm = 1.5301e-01, time/batch = 17.2692s	
12574/33250 (epoch 18.908), train_loss = 0.96218754, grad/param norm = 1.3515e-01, time/batch = 15.6135s	
12575/33250 (epoch 18.910), train_loss = 1.01606680, grad/param norm = 1.4973e-01, time/batch = 15.9921s	
12576/33250 (epoch 18.911), train_loss = 0.85809436, grad/param norm = 1.3800e-01, time/batch = 16.5828s	
12577/33250 (epoch 18.913), train_loss = 0.91052858, grad/param norm = 1.4626e-01, time/batch = 18.4239s	
12578/33250 (epoch 18.914), train_loss = 0.80937085, grad/param norm = 1.4328e-01, time/batch = 17.7724s	
12579/33250 (epoch 18.916), train_loss = 0.88981112, grad/param norm = 1.2976e-01, time/batch = 16.7159s	
12580/33250 (epoch 18.917), train_loss = 0.92893543, grad/param norm = 1.3410e-01, time/batch = 16.7848s	
12581/33250 (epoch 18.919), train_loss = 0.87938600, grad/param norm = 1.5901e-01, time/batch = 15.8319s	
12582/33250 (epoch 18.920), train_loss = 0.95820485, grad/param norm = 1.5436e-01, time/batch = 16.1784s	
12583/33250 (epoch 18.922), train_loss = 1.00737034, grad/param norm = 1.6450e-01, time/batch = 15.5101s	
12584/33250 (epoch 18.923), train_loss = 0.94467021, grad/param norm = 1.6889e-01, time/batch = 15.5004s	
12585/33250 (epoch 18.925), train_loss = 0.92723749, grad/param norm = 1.4228e-01, time/batch = 15.4304s	
12586/33250 (epoch 18.926), train_loss = 0.92391553, grad/param norm = 1.4010e-01, time/batch = 15.4318s	
12587/33250 (epoch 18.928), train_loss = 0.92117419, grad/param norm = 1.5383e-01, time/batch = 16.5857s	
12588/33250 (epoch 18.929), train_loss = 0.77695543, grad/param norm = 1.2649e-01, time/batch = 16.7782s	
12589/33250 (epoch 18.931), train_loss = 1.05015314, grad/param norm = 1.6309e-01, time/batch = 17.1144s	
12590/33250 (epoch 18.932), train_loss = 0.96551172, grad/param norm = 1.5328e-01, time/batch = 16.7116s	
12591/33250 (epoch 18.934), train_loss = 0.87726689, grad/param norm = 1.3224e-01, time/batch = 15.6705s	
12592/33250 (epoch 18.935), train_loss = 0.87880576, grad/param norm = 1.5320e-01, time/batch = 16.2825s	
12593/33250 (epoch 18.937), train_loss = 0.92362356, grad/param norm = 1.6331e-01, time/batch = 17.4397s	
12594/33250 (epoch 18.938), train_loss = 0.97624472, grad/param norm = 1.6268e-01, time/batch = 15.6227s	
12595/33250 (epoch 18.940), train_loss = 0.95128472, grad/param norm = 1.6132e-01, time/batch = 15.4410s	
12596/33250 (epoch 18.941), train_loss = 1.01508966, grad/param norm = 1.5446e-01, time/batch = 15.5835s	
12597/33250 (epoch 18.943), train_loss = 1.09378482, grad/param norm = 1.5466e-01, time/batch = 15.6583s	
12598/33250 (epoch 18.944), train_loss = 0.88264897, grad/param norm = 1.4112e-01, time/batch = 15.2422s	
12599/33250 (epoch 18.946), train_loss = 1.05362074, grad/param norm = 1.5605e-01, time/batch = 15.5279s	
12600/33250 (epoch 18.947), train_loss = 0.87524200, grad/param norm = 1.5360e-01, time/batch = 14.7768s	
12601/33250 (epoch 18.949), train_loss = 1.03039062, grad/param norm = 1.8143e-01, time/batch = 16.1798s	
12602/33250 (epoch 18.950), train_loss = 1.00341368, grad/param norm = 1.5055e-01, time/batch = 18.5933s	
12603/33250 (epoch 18.952), train_loss = 0.95764756, grad/param norm = 1.9412e-01, time/batch = 16.5929s	
12604/33250 (epoch 18.953), train_loss = 1.02980295, grad/param norm = 1.5771e-01, time/batch = 16.4450s	
12605/33250 (epoch 18.955), train_loss = 1.06715559, grad/param norm = 1.6445e-01, time/batch = 15.5861s	
12606/33250 (epoch 18.956), train_loss = 0.98749780, grad/param norm = 1.7173e-01, time/batch = 16.1224s	
12607/33250 (epoch 18.958), train_loss = 0.89132369, grad/param norm = 1.4122e-01, time/batch = 15.3787s	
12608/33250 (epoch 18.959), train_loss = 0.91791581, grad/param norm = 1.5356e-01, time/batch = 15.9452s	
12609/33250 (epoch 18.961), train_loss = 1.15567444, grad/param norm = 1.5603e-01, time/batch = 15.5317s	
12610/33250 (epoch 18.962), train_loss = 0.97403086, grad/param norm = 1.5695e-01, time/batch = 16.9383s	
12611/33250 (epoch 18.964), train_loss = 1.13054530, grad/param norm = 1.6976e-01, time/batch = 16.0901s	
12612/33250 (epoch 18.965), train_loss = 1.02366142, grad/param norm = 1.6262e-01, time/batch = 16.7690s	
12613/33250 (epoch 18.967), train_loss = 0.99112455, grad/param norm = 1.6059e-01, time/batch = 16.8557s	
12614/33250 (epoch 18.968), train_loss = 1.11400051, grad/param norm = 1.3959e-01, time/batch = 16.7856s	
12615/33250 (epoch 18.970), train_loss = 1.24935714, grad/param norm = 2.1129e-01, time/batch = 18.4932s	
12616/33250 (epoch 18.971), train_loss = 1.11827099, grad/param norm = 1.8581e-01, time/batch = 15.5175s	
12617/33250 (epoch 18.973), train_loss = 0.93078261, grad/param norm = 1.6461e-01, time/batch = 17.2847s	
12618/33250 (epoch 18.974), train_loss = 1.04909692, grad/param norm = 1.6019e-01, time/batch = 15.6809s	
12619/33250 (epoch 18.976), train_loss = 0.95237151, grad/param norm = 1.8587e-01, time/batch = 16.0058s	
12620/33250 (epoch 18.977), train_loss = 0.90828487, grad/param norm = 1.5466e-01, time/batch = 15.5775s	
12621/33250 (epoch 18.979), train_loss = 0.99900317, grad/param norm = 1.6597e-01, time/batch = 15.7445s	
12622/33250 (epoch 18.980), train_loss = 0.99397102, grad/param norm = 1.4938e-01, time/batch = 15.9858s	
12623/33250 (epoch 18.982), train_loss = 0.86790504, grad/param norm = 1.3919e-01, time/batch = 15.5024s	
12624/33250 (epoch 18.983), train_loss = 1.00092576, grad/param norm = 1.5400e-01, time/batch = 15.5903s	
12625/33250 (epoch 18.985), train_loss = 0.92401619, grad/param norm = 1.4388e-01, time/batch = 15.4398s	
12626/33250 (epoch 18.986), train_loss = 1.04316381, grad/param norm = 1.5296e-01, time/batch = 15.4384s	
12627/33250 (epoch 18.988), train_loss = 1.10704235, grad/param norm = 1.7744e-01, time/batch = 15.6795s	
12628/33250 (epoch 18.989), train_loss = 1.05520254, grad/param norm = 1.6889e-01, time/batch = 15.4188s	
12629/33250 (epoch 18.991), train_loss = 1.01407523, grad/param norm = 1.5878e-01, time/batch = 15.0885s	
12630/33250 (epoch 18.992), train_loss = 0.91826967, grad/param norm = 1.5782e-01, time/batch = 14.4217s	
12631/33250 (epoch 18.994), train_loss = 0.90527719, grad/param norm = 1.4844e-01, time/batch = 15.4323s	
12632/33250 (epoch 18.995), train_loss = 0.93443665, grad/param norm = 2.0380e-01, time/batch = 18.2789s	
12633/33250 (epoch 18.997), train_loss = 0.71408249, grad/param norm = 1.3718e-01, time/batch = 17.9383s	
12634/33250 (epoch 18.998), train_loss = 0.99759120, grad/param norm = 1.4968e-01, time/batch = 17.7874s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
12635/33250 (epoch 19.000), train_loss = 0.98421747, grad/param norm = 1.6009e-01, time/batch = 16.4303s	
12636/33250 (epoch 19.002), train_loss = 1.16065766, grad/param norm = 1.7800e-01, time/batch = 16.5351s	
12637/33250 (epoch 19.003), train_loss = 1.05901448, grad/param norm = 1.6432e-01, time/batch = 18.2770s	
12638/33250 (epoch 19.005), train_loss = 0.78573926, grad/param norm = 1.2740e-01, time/batch = 15.9272s	
12639/33250 (epoch 19.006), train_loss = 0.82123132, grad/param norm = 1.3223e-01, time/batch = 17.5101s	
12640/33250 (epoch 19.008), train_loss = 1.12976388, grad/param norm = 1.6036e-01, time/batch = 16.0010s	
12641/33250 (epoch 19.009), train_loss = 1.11840708, grad/param norm = 1.5527e-01, time/batch = 15.3223s	
12642/33250 (epoch 19.011), train_loss = 0.87181455, grad/param norm = 1.5094e-01, time/batch = 14.6864s	
12643/33250 (epoch 19.012), train_loss = 1.01061802, grad/param norm = 2.0784e-01, time/batch = 15.0165s	
12644/33250 (epoch 19.014), train_loss = 1.09899377, grad/param norm = 1.7212e-01, time/batch = 16.2992s	
12645/33250 (epoch 19.015), train_loss = 0.96001871, grad/param norm = 1.4812e-01, time/batch = 15.5516s	
12646/33250 (epoch 19.017), train_loss = 1.00600073, grad/param norm = 1.8260e-01, time/batch = 15.3562s	
12647/33250 (epoch 19.018), train_loss = 0.79779501, grad/param norm = 1.3495e-01, time/batch = 15.2861s	
12648/33250 (epoch 19.020), train_loss = 0.96454530, grad/param norm = 1.3455e-01, time/batch = 16.3608s	
12649/33250 (epoch 19.021), train_loss = 1.00890985, grad/param norm = 1.5023e-01, time/batch = 15.2767s	
12650/33250 (epoch 19.023), train_loss = 0.82340189, grad/param norm = 1.8948e-01, time/batch = 15.1774s	
12651/33250 (epoch 19.024), train_loss = 1.06540712, grad/param norm = 1.5282e-01, time/batch = 15.2978s	
12652/33250 (epoch 19.026), train_loss = 0.96540784, grad/param norm = 1.4153e-01, time/batch = 16.1103s	
12653/33250 (epoch 19.027), train_loss = 0.95625294, grad/param norm = 1.4474e-01, time/batch = 15.0355s	
12654/33250 (epoch 19.029), train_loss = 0.98567721, grad/param norm = 1.4119e-01, time/batch = 16.6115s	
12655/33250 (epoch 19.030), train_loss = 0.97813749, grad/param norm = 1.5981e-01, time/batch = 17.6120s	
12656/33250 (epoch 19.032), train_loss = 1.20162340, grad/param norm = 1.8753e-01, time/batch = 18.1086s	
12657/33250 (epoch 19.033), train_loss = 0.92049419, grad/param norm = 1.4076e-01, time/batch = 15.5075s	
12658/33250 (epoch 19.035), train_loss = 0.93570131, grad/param norm = 1.5059e-01, time/batch = 16.5056s	
12659/33250 (epoch 19.036), train_loss = 1.03272112, grad/param norm = 1.6919e-01, time/batch = 15.5655s	
12660/33250 (epoch 19.038), train_loss = 0.96397227, grad/param norm = 1.3643e-01, time/batch = 14.7760s	
12661/33250 (epoch 19.039), train_loss = 0.86113211, grad/param norm = 1.3985e-01, time/batch = 15.5800s	
12662/33250 (epoch 19.041), train_loss = 0.98486082, grad/param norm = 1.6633e-01, time/batch = 15.2732s	
12663/33250 (epoch 19.042), train_loss = 0.79659243, grad/param norm = 1.3038e-01, time/batch = 15.4124s	
12664/33250 (epoch 19.044), train_loss = 1.10513922, grad/param norm = 1.6326e-01, time/batch = 15.6559s	
12665/33250 (epoch 19.045), train_loss = 1.07583910, grad/param norm = 1.5337e-01, time/batch = 15.3421s	
12666/33250 (epoch 19.047), train_loss = 1.00965758, grad/param norm = 1.6541e-01, time/batch = 15.2294s	
12667/33250 (epoch 19.048), train_loss = 1.11449739, grad/param norm = 1.8536e-01, time/batch = 15.5373s	
12668/33250 (epoch 19.050), train_loss = 0.96316925, grad/param norm = 1.4770e-01, time/batch = 15.6625s	
12669/33250 (epoch 19.051), train_loss = 0.95918598, grad/param norm = 1.5118e-01, time/batch = 16.8449s	
12670/33250 (epoch 19.053), train_loss = 0.98019337, grad/param norm = 1.7813e-01, time/batch = 15.2807s	
12671/33250 (epoch 19.054), train_loss = 0.81144342, grad/param norm = 1.3722e-01, time/batch = 15.2070s	
12672/33250 (epoch 19.056), train_loss = 0.86571014, grad/param norm = 1.3885e-01, time/batch = 15.2648s	
12673/33250 (epoch 19.057), train_loss = 1.05188638, grad/param norm = 1.4608e-01, time/batch = 15.3513s	
12674/33250 (epoch 19.059), train_loss = 0.95313368, grad/param norm = 1.5651e-01, time/batch = 15.3658s	
12675/33250 (epoch 19.060), train_loss = 1.00080707, grad/param norm = 1.7218e-01, time/batch = 15.6607s	
12676/33250 (epoch 19.062), train_loss = 1.08738538, grad/param norm = 1.5588e-01, time/batch = 16.1849s	
12677/33250 (epoch 19.063), train_loss = 1.11314923, grad/param norm = 1.6179e-01, time/batch = 19.2650s	
12678/33250 (epoch 19.065), train_loss = 0.96530282, grad/param norm = 1.5179e-01, time/batch = 15.3849s	
12679/33250 (epoch 19.066), train_loss = 1.02038349, grad/param norm = 1.5110e-01, time/batch = 16.5030s	
12680/33250 (epoch 19.068), train_loss = 0.92850649, grad/param norm = 1.5394e-01, time/batch = 16.0157s	
12681/33250 (epoch 19.069), train_loss = 0.97481139, grad/param norm = 1.4552e-01, time/batch = 15.4401s	
12682/33250 (epoch 19.071), train_loss = 0.88282900, grad/param norm = 1.4662e-01, time/batch = 15.4807s	
12683/33250 (epoch 19.072), train_loss = 0.87555754, grad/param norm = 1.3222e-01, time/batch = 15.1818s	
12684/33250 (epoch 19.074), train_loss = 1.02381647, grad/param norm = 1.5801e-01, time/batch = 15.4208s	
12685/33250 (epoch 19.075), train_loss = 0.91079054, grad/param norm = 1.3890e-01, time/batch = 14.9691s	
12686/33250 (epoch 19.077), train_loss = 0.96674877, grad/param norm = 1.6700e-01, time/batch = 16.7148s	
12687/33250 (epoch 19.078), train_loss = 0.98606192, grad/param norm = 1.4018e-01, time/batch = 16.7938s	
12688/33250 (epoch 19.080), train_loss = 0.97493654, grad/param norm = 1.7270e-01, time/batch = 16.4541s	
12689/33250 (epoch 19.081), train_loss = 1.00787705, grad/param norm = 1.4771e-01, time/batch = 15.5205s	
12690/33250 (epoch 19.083), train_loss = 1.08763746, grad/param norm = 1.4919e-01, time/batch = 15.4582s	
12691/33250 (epoch 19.084), train_loss = 0.97826944, grad/param norm = 1.5589e-01, time/batch = 15.6653s	
12692/33250 (epoch 19.086), train_loss = 0.94821234, grad/param norm = 1.4559e-01, time/batch = 15.8148s	
12693/33250 (epoch 19.087), train_loss = 0.86265339, grad/param norm = 1.3803e-01, time/batch = 15.2952s	
12694/33250 (epoch 19.089), train_loss = 0.99110737, grad/param norm = 1.4586e-01, time/batch = 15.2010s	
12695/33250 (epoch 19.090), train_loss = 0.98768622, grad/param norm = 1.4894e-01, time/batch = 29.3449s	
12696/33250 (epoch 19.092), train_loss = 0.89354213, grad/param norm = 1.3590e-01, time/batch = 15.7568s	
12697/33250 (epoch 19.093), train_loss = 1.00575440, grad/param norm = 1.6126e-01, time/batch = 15.2701s	
12698/33250 (epoch 19.095), train_loss = 0.92053978, grad/param norm = 1.4782e-01, time/batch = 15.7532s	
12699/33250 (epoch 19.096), train_loss = 0.84750352, grad/param norm = 1.6356e-01, time/batch = 15.1057s	
12700/33250 (epoch 19.098), train_loss = 0.85028635, grad/param norm = 1.5488e-01, time/batch = 15.0323s	
12701/33250 (epoch 19.099), train_loss = 0.72841823, grad/param norm = 1.3149e-01, time/batch = 15.0969s	
12702/33250 (epoch 19.101), train_loss = 0.97718246, grad/param norm = 1.5712e-01, time/batch = 15.5119s	
12703/33250 (epoch 19.102), train_loss = 0.88788395, grad/param norm = 1.5552e-01, time/batch = 14.7901s	
12704/33250 (epoch 19.104), train_loss = 0.75255346, grad/param norm = 1.3472e-01, time/batch = 14.8737s	
12705/33250 (epoch 19.105), train_loss = 0.90853701, grad/param norm = 1.4818e-01, time/batch = 14.9453s	
12706/33250 (epoch 19.107), train_loss = 0.80528377, grad/param norm = 1.3378e-01, time/batch = 15.4918s	
12707/33250 (epoch 19.108), train_loss = 0.95807769, grad/param norm = 1.5336e-01, time/batch = 15.3345s	
12708/33250 (epoch 19.110), train_loss = 0.79984529, grad/param norm = 1.3334e-01, time/batch = 15.2624s	
12709/33250 (epoch 19.111), train_loss = 0.92330400, grad/param norm = 1.4665e-01, time/batch = 14.8625s	
12710/33250 (epoch 19.113), train_loss = 0.92266288, grad/param norm = 1.6263e-01, time/batch = 15.7332s	
12711/33250 (epoch 19.114), train_loss = 0.85290672, grad/param norm = 1.4859e-01, time/batch = 15.0900s	
12712/33250 (epoch 19.116), train_loss = 0.93886104, grad/param norm = 1.5698e-01, time/batch = 15.0201s	
12713/33250 (epoch 19.117), train_loss = 0.91726747, grad/param norm = 1.5631e-01, time/batch = 15.3401s	
12714/33250 (epoch 19.119), train_loss = 0.90971344, grad/param norm = 1.4454e-01, time/batch = 15.2289s	
12715/33250 (epoch 19.120), train_loss = 0.73532133, grad/param norm = 1.2667e-01, time/batch = 15.1786s	
12716/33250 (epoch 19.122), train_loss = 1.05807566, grad/param norm = 1.5519e-01, time/batch = 14.6155s	
12717/33250 (epoch 19.123), train_loss = 0.95627890, grad/param norm = 1.5433e-01, time/batch = 15.5673s	
12718/33250 (epoch 19.125), train_loss = 0.77760844, grad/param norm = 1.4815e-01, time/batch = 15.1148s	
12719/33250 (epoch 19.126), train_loss = 0.92645914, grad/param norm = 1.5430e-01, time/batch = 15.1327s	
12720/33250 (epoch 19.128), train_loss = 0.88732502, grad/param norm = 1.4517e-01, time/batch = 15.2749s	
12721/33250 (epoch 19.129), train_loss = 0.93557957, grad/param norm = 1.4301e-01, time/batch = 15.5062s	
12722/33250 (epoch 19.131), train_loss = 0.89901209, grad/param norm = 1.4359e-01, time/batch = 14.9480s	
12723/33250 (epoch 19.132), train_loss = 0.94812165, grad/param norm = 1.7037e-01, time/batch = 14.9441s	
12724/33250 (epoch 19.134), train_loss = 0.94161464, grad/param norm = 1.5903e-01, time/batch = 14.7927s	
12725/33250 (epoch 19.135), train_loss = 0.94970189, grad/param norm = 1.4749e-01, time/batch = 15.4180s	
12726/33250 (epoch 19.137), train_loss = 0.83753512, grad/param norm = 1.5917e-01, time/batch = 15.8083s	
12727/33250 (epoch 19.138), train_loss = 0.88473133, grad/param norm = 1.3713e-01, time/batch = 15.4402s	
12728/33250 (epoch 19.140), train_loss = 0.73581194, grad/param norm = 1.4525e-01, time/batch = 15.0520s	
12729/33250 (epoch 19.141), train_loss = 1.11743404, grad/param norm = 2.0114e-01, time/batch = 15.3739s	
12730/33250 (epoch 19.143), train_loss = 0.75258636, grad/param norm = 1.4603e-01, time/batch = 15.0515s	
12731/33250 (epoch 19.144), train_loss = 0.89739957, grad/param norm = 1.5251e-01, time/batch = 15.1899s	
12732/33250 (epoch 19.146), train_loss = 0.89817848, grad/param norm = 1.4200e-01, time/batch = 15.0368s	
12733/33250 (epoch 19.147), train_loss = 0.88343521, grad/param norm = 1.3977e-01, time/batch = 15.3471s	
12734/33250 (epoch 19.149), train_loss = 0.87797810, grad/param norm = 1.3868e-01, time/batch = 15.3711s	
12735/33250 (epoch 19.150), train_loss = 0.85780387, grad/param norm = 1.4374e-01, time/batch = 15.5791s	
12736/33250 (epoch 19.152), train_loss = 0.80600570, grad/param norm = 1.3561e-01, time/batch = 15.0278s	
12737/33250 (epoch 19.153), train_loss = 1.08792163, grad/param norm = 1.5543e-01, time/batch = 15.2643s	
12738/33250 (epoch 19.155), train_loss = 0.91942657, grad/param norm = 1.5797e-01, time/batch = 15.1190s	
12739/33250 (epoch 19.156), train_loss = 1.11376445, grad/param norm = 1.5062e-01, time/batch = 15.1165s	
12740/33250 (epoch 19.158), train_loss = 1.13147483, grad/param norm = 1.8023e-01, time/batch = 14.7973s	
12741/33250 (epoch 19.159), train_loss = 0.92347523, grad/param norm = 1.5705e-01, time/batch = 15.4439s	
12742/33250 (epoch 19.161), train_loss = 1.00991383, grad/param norm = 1.6374e-01, time/batch = 15.1977s	
12743/33250 (epoch 19.162), train_loss = 0.84745886, grad/param norm = 1.4046e-01, time/batch = 14.9562s	
12744/33250 (epoch 19.164), train_loss = 0.91613527, grad/param norm = 1.5313e-01, time/batch = 14.7782s	
12745/33250 (epoch 19.165), train_loss = 1.01734302, grad/param norm = 1.6302e-01, time/batch = 15.2676s	
12746/33250 (epoch 19.167), train_loss = 1.07254570, grad/param norm = 1.5561e-01, time/batch = 15.0373s	
12747/33250 (epoch 19.168), train_loss = 0.81185760, grad/param norm = 1.2534e-01, time/batch = 15.3423s	
12748/33250 (epoch 19.170), train_loss = 0.91190889, grad/param norm = 1.5577e-01, time/batch = 14.9653s	
12749/33250 (epoch 19.171), train_loss = 0.91201400, grad/param norm = 1.4580e-01, time/batch = 15.3602s	
12750/33250 (epoch 19.173), train_loss = 0.88170970, grad/param norm = 1.4434e-01, time/batch = 15.4454s	
12751/33250 (epoch 19.174), train_loss = 0.93223057, grad/param norm = 1.4809e-01, time/batch = 15.5839s	
12752/33250 (epoch 19.176), train_loss = 0.92631162, grad/param norm = 1.6191e-01, time/batch = 15.2933s	
12753/33250 (epoch 19.177), train_loss = 0.92246618, grad/param norm = 1.5645e-01, time/batch = 15.2743s	
12754/33250 (epoch 19.179), train_loss = 0.86185869, grad/param norm = 1.3895e-01, time/batch = 15.4246s	
12755/33250 (epoch 19.180), train_loss = 0.79147068, grad/param norm = 1.4146e-01, time/batch = 15.8916s	
12756/33250 (epoch 19.182), train_loss = 0.90092175, grad/param norm = 1.6245e-01, time/batch = 15.5061s	
12757/33250 (epoch 19.183), train_loss = 1.07350656, grad/param norm = 1.6565e-01, time/batch = 15.4075s	
12758/33250 (epoch 19.185), train_loss = 0.99088433, grad/param norm = 1.8440e-01, time/batch = 15.3902s	
12759/33250 (epoch 19.186), train_loss = 0.96217665, grad/param norm = 1.4308e-01, time/batch = 15.0320s	
12760/33250 (epoch 19.188), train_loss = 1.04584133, grad/param norm = 1.5880e-01, time/batch = 15.1760s	
12761/33250 (epoch 19.189), train_loss = 0.76736552, grad/param norm = 1.6447e-01, time/batch = 15.2146s	
12762/33250 (epoch 19.191), train_loss = 0.88410915, grad/param norm = 1.6479e-01, time/batch = 15.4291s	
12763/33250 (epoch 19.192), train_loss = 0.88000076, grad/param norm = 1.3576e-01, time/batch = 15.0331s	
12764/33250 (epoch 19.194), train_loss = 0.90758249, grad/param norm = 1.4986e-01, time/batch = 15.0299s	
12765/33250 (epoch 19.195), train_loss = 1.11856255, grad/param norm = 1.5019e-01, time/batch = 15.1802s	
12766/33250 (epoch 19.197), train_loss = 0.89231443, grad/param norm = 1.4005e-01, time/batch = 14.6887s	
12767/33250 (epoch 19.198), train_loss = 1.05842335, grad/param norm = 1.5887e-01, time/batch = 15.0063s	
12768/33250 (epoch 19.200), train_loss = 0.94415896, grad/param norm = 1.3713e-01, time/batch = 15.0251s	
12769/33250 (epoch 19.202), train_loss = 0.88180727, grad/param norm = 1.3763e-01, time/batch = 15.1938s	
12770/33250 (epoch 19.203), train_loss = 0.87682813, grad/param norm = 1.5245e-01, time/batch = 15.0159s	
12771/33250 (epoch 19.205), train_loss = 0.98186724, grad/param norm = 1.5155e-01, time/batch = 14.8728s	
12772/33250 (epoch 19.206), train_loss = 1.02664737, grad/param norm = 1.4960e-01, time/batch = 15.1045s	
12773/33250 (epoch 19.208), train_loss = 1.06811593, grad/param norm = 1.7564e-01, time/batch = 15.0077s	
12774/33250 (epoch 19.209), train_loss = 0.86034333, grad/param norm = 1.4203e-01, time/batch = 14.9359s	
12775/33250 (epoch 19.211), train_loss = 1.02657168, grad/param norm = 1.5632e-01, time/batch = 15.7967s	
12776/33250 (epoch 19.212), train_loss = 1.17074465, grad/param norm = 1.6108e-01, time/batch = 15.6684s	
12777/33250 (epoch 19.214), train_loss = 0.93368435, grad/param norm = 1.4007e-01, time/batch = 15.4840s	
12778/33250 (epoch 19.215), train_loss = 1.12920992, grad/param norm = 2.0050e-01, time/batch = 15.3140s	
12779/33250 (epoch 19.217), train_loss = 1.07403626, grad/param norm = 1.6849e-01, time/batch = 15.2542s	
12780/33250 (epoch 19.218), train_loss = 1.04102762, grad/param norm = 1.4382e-01, time/batch = 15.8926s	
12781/33250 (epoch 19.220), train_loss = 0.98572040, grad/param norm = 1.6949e-01, time/batch = 15.1961s	
12782/33250 (epoch 19.221), train_loss = 1.16531981, grad/param norm = 1.8716e-01, time/batch = 15.0595s	
12783/33250 (epoch 19.223), train_loss = 0.95173131, grad/param norm = 1.4397e-01, time/batch = 15.0291s	
12784/33250 (epoch 19.224), train_loss = 0.98746390, grad/param norm = 1.6495e-01, time/batch = 15.3683s	
12785/33250 (epoch 19.226), train_loss = 1.12761476, grad/param norm = 1.6566e-01, time/batch = 15.5003s	
12786/33250 (epoch 19.227), train_loss = 1.00007365, grad/param norm = 1.6749e-01, time/batch = 15.4409s	
12787/33250 (epoch 19.229), train_loss = 0.99110949, grad/param norm = 1.4249e-01, time/batch = 15.1006s	
12788/33250 (epoch 19.230), train_loss = 0.95433798, grad/param norm = 1.5220e-01, time/batch = 15.3368s	
12789/33250 (epoch 19.232), train_loss = 0.90169323, grad/param norm = 1.2948e-01, time/batch = 14.8710s	
12790/33250 (epoch 19.233), train_loss = 0.89459092, grad/param norm = 1.4799e-01, time/batch = 14.9530s	
12791/33250 (epoch 19.235), train_loss = 1.11243906, grad/param norm = 1.4969e-01, time/batch = 14.9569s	
12792/33250 (epoch 19.236), train_loss = 0.89374154, grad/param norm = 1.5126e-01, time/batch = 15.5133s	
12793/33250 (epoch 19.238), train_loss = 1.06269632, grad/param norm = 1.6402e-01, time/batch = 14.8175s	
12794/33250 (epoch 19.239), train_loss = 1.09675182, grad/param norm = 1.7891e-01, time/batch = 14.8077s	
12795/33250 (epoch 19.241), train_loss = 1.05533647, grad/param norm = 1.7797e-01, time/batch = 14.7327s	
12796/33250 (epoch 19.242), train_loss = 1.05028745, grad/param norm = 1.6063e-01, time/batch = 15.2761s	
12797/33250 (epoch 19.244), train_loss = 1.05574542, grad/param norm = 1.9675e-01, time/batch = 14.7194s	
12798/33250 (epoch 19.245), train_loss = 0.99106104, grad/param norm = 1.5576e-01, time/batch = 14.9564s	
12799/33250 (epoch 19.247), train_loss = 0.97183345, grad/param norm = 1.4589e-01, time/batch = 15.1116s	
12800/33250 (epoch 19.248), train_loss = 1.16036293, grad/param norm = 1.7098e-01, time/batch = 15.2642s	
12801/33250 (epoch 19.250), train_loss = 1.06206957, grad/param norm = 1.6100e-01, time/batch = 15.1822s	
12802/33250 (epoch 19.251), train_loss = 0.95710662, grad/param norm = 1.4764e-01, time/batch = 15.1731s	
12803/33250 (epoch 19.253), train_loss = 0.89602633, grad/param norm = 1.2994e-01, time/batch = 15.1113s	
12804/33250 (epoch 19.254), train_loss = 0.91303232, grad/param norm = 1.4789e-01, time/batch = 15.2030s	
12805/33250 (epoch 19.256), train_loss = 0.95769822, grad/param norm = 1.3650e-01, time/batch = 15.6108s	
12806/33250 (epoch 19.257), train_loss = 1.11054211, grad/param norm = 1.6006e-01, time/batch = 15.3605s	
12807/33250 (epoch 19.259), train_loss = 1.03869192, grad/param norm = 1.6023e-01, time/batch = 14.8862s	
12808/33250 (epoch 19.260), train_loss = 0.84093788, grad/param norm = 1.4288e-01, time/batch = 15.2870s	
12809/33250 (epoch 19.262), train_loss = 0.97535294, grad/param norm = 1.3966e-01, time/batch = 15.2716s	
12810/33250 (epoch 19.263), train_loss = 0.87946469, grad/param norm = 1.4244e-01, time/batch = 15.9396s	
12811/33250 (epoch 19.265), train_loss = 1.04948259, grad/param norm = 1.6646e-01, time/batch = 15.3373s	
12812/33250 (epoch 19.266), train_loss = 0.95188437, grad/param norm = 1.6617e-01, time/batch = 15.2670s	
12813/33250 (epoch 19.268), train_loss = 0.87357614, grad/param norm = 1.4774e-01, time/batch = 15.1043s	
12814/33250 (epoch 19.269), train_loss = 0.78453708, grad/param norm = 1.4745e-01, time/batch = 14.8606s	
12815/33250 (epoch 19.271), train_loss = 0.96224230, grad/param norm = 1.4660e-01, time/batch = 15.1795s	
12816/33250 (epoch 19.272), train_loss = 0.84357440, grad/param norm = 1.2765e-01, time/batch = 15.1919s	
12817/33250 (epoch 19.274), train_loss = 0.74447707, grad/param norm = 1.3309e-01, time/batch = 15.6430s	
12818/33250 (epoch 19.275), train_loss = 0.88011031, grad/param norm = 1.3755e-01, time/batch = 14.8786s	
12819/33250 (epoch 19.277), train_loss = 0.76603384, grad/param norm = 1.4702e-01, time/batch = 15.1089s	
12820/33250 (epoch 19.278), train_loss = 0.89589304, grad/param norm = 1.4737e-01, time/batch = 14.6211s	
12821/33250 (epoch 19.280), train_loss = 0.86378844, grad/param norm = 1.3905e-01, time/batch = 14.7032s	
12822/33250 (epoch 19.281), train_loss = 0.97342560, grad/param norm = 1.5545e-01, time/batch = 14.6250s	
12823/33250 (epoch 19.283), train_loss = 1.01641124, grad/param norm = 2.1265e-01, time/batch = 15.0297s	
12824/33250 (epoch 19.284), train_loss = 0.87559643, grad/param norm = 1.7231e-01, time/batch = 15.0287s	
12825/33250 (epoch 19.286), train_loss = 1.02706177, grad/param norm = 1.6424e-01, time/batch = 14.6196s	
12826/33250 (epoch 19.287), train_loss = 0.82251261, grad/param norm = 1.2882e-01, time/batch = 14.6346s	
12827/33250 (epoch 19.289), train_loss = 0.78153229, grad/param norm = 1.4853e-01, time/batch = 15.1842s	
12828/33250 (epoch 19.290), train_loss = 0.93951891, grad/param norm = 1.3694e-01, time/batch = 15.7947s	
12829/33250 (epoch 19.292), train_loss = 1.00111453, grad/param norm = 1.8551e-01, time/batch = 15.5978s	
12830/33250 (epoch 19.293), train_loss = 1.05674635, grad/param norm = 1.6870e-01, time/batch = 14.8891s	
12831/33250 (epoch 19.295), train_loss = 1.01548666, grad/param norm = 1.5377e-01, time/batch = 15.2603s	
12832/33250 (epoch 19.296), train_loss = 0.98359031, grad/param norm = 1.5525e-01, time/batch = 15.1045s	
12833/33250 (epoch 19.298), train_loss = 0.80140432, grad/param norm = 1.3043e-01, time/batch = 14.7091s	
12834/33250 (epoch 19.299), train_loss = 0.76215799, grad/param norm = 1.3265e-01, time/batch = 14.6258s	
12835/33250 (epoch 19.301), train_loss = 1.00913620, grad/param norm = 1.4293e-01, time/batch = 15.3431s	
12836/33250 (epoch 19.302), train_loss = 1.00409342, grad/param norm = 1.4413e-01, time/batch = 14.8769s	
12837/33250 (epoch 19.304), train_loss = 0.87024850, grad/param norm = 1.5195e-01, time/batch = 15.1809s	
12838/33250 (epoch 19.305), train_loss = 0.92144977, grad/param norm = 1.3981e-01, time/batch = 15.3266s	
12839/33250 (epoch 19.307), train_loss = 1.01677110, grad/param norm = 1.5874e-01, time/batch = 14.9666s	
12840/33250 (epoch 19.308), train_loss = 1.11973423, grad/param norm = 1.6726e-01, time/batch = 15.0288s	
12841/33250 (epoch 19.310), train_loss = 0.93164525, grad/param norm = 1.5344e-01, time/batch = 14.7332s	
12842/33250 (epoch 19.311), train_loss = 1.07683201, grad/param norm = 1.6520e-01, time/batch = 14.7934s	
12843/33250 (epoch 19.313), train_loss = 0.81021150, grad/param norm = 1.5059e-01, time/batch = 14.6239s	
12844/33250 (epoch 19.314), train_loss = 0.94721508, grad/param norm = 1.5208e-01, time/batch = 14.8725s	
12845/33250 (epoch 19.316), train_loss = 1.12800462, grad/param norm = 1.8025e-01, time/batch = 14.7980s	
12846/33250 (epoch 19.317), train_loss = 0.84628008, grad/param norm = 1.2997e-01, time/batch = 14.7897s	
12847/33250 (epoch 19.319), train_loss = 1.03158184, grad/param norm = 1.8245e-01, time/batch = 15.3279s	
12848/33250 (epoch 19.320), train_loss = 1.05192062, grad/param norm = 1.9063e-01, time/batch = 15.0937s	
12849/33250 (epoch 19.322), train_loss = 1.12140762, grad/param norm = 1.8349e-01, time/batch = 14.8627s	
12850/33250 (epoch 19.323), train_loss = 1.18870324, grad/param norm = 2.0440e-01, time/batch = 15.0428s	
12851/33250 (epoch 19.325), train_loss = 0.97354206, grad/param norm = 1.7517e-01, time/batch = 15.3560s	
12852/33250 (epoch 19.326), train_loss = 1.11125520, grad/param norm = 1.5841e-01, time/batch = 15.7951s	
12853/33250 (epoch 19.328), train_loss = 0.92224785, grad/param norm = 1.3864e-01, time/batch = 15.4101s	
12854/33250 (epoch 19.329), train_loss = 0.95214031, grad/param norm = 1.6286e-01, time/batch = 15.0262s	
12855/33250 (epoch 19.331), train_loss = 0.93172449, grad/param norm = 1.6429e-01, time/batch = 15.4945s	
12856/33250 (epoch 19.332), train_loss = 0.92538709, grad/param norm = 1.4101e-01, time/batch = 15.4883s	
12857/33250 (epoch 19.334), train_loss = 1.11004765, grad/param norm = 1.5223e-01, time/batch = 15.1853s	
12858/33250 (epoch 19.335), train_loss = 0.71255478, grad/param norm = 1.2747e-01, time/batch = 14.7189s	
12859/33250 (epoch 19.337), train_loss = 1.00264280, grad/param norm = 1.4317e-01, time/batch = 14.9644s	
12860/33250 (epoch 19.338), train_loss = 1.06244035, grad/param norm = 1.4935e-01, time/batch = 14.9617s	
12861/33250 (epoch 19.340), train_loss = 0.97239865, grad/param norm = 1.5254e-01, time/batch = 14.9748s	
12862/33250 (epoch 19.341), train_loss = 0.91186519, grad/param norm = 1.5920e-01, time/batch = 14.8247s	
12863/33250 (epoch 19.343), train_loss = 0.90164506, grad/param norm = 1.4217e-01, time/batch = 14.8842s	
12864/33250 (epoch 19.344), train_loss = 0.94250048, grad/param norm = 1.3578e-01, time/batch = 14.9614s	
12865/33250 (epoch 19.346), train_loss = 0.84234673, grad/param norm = 1.3347e-01, time/batch = 14.7204s	
12866/33250 (epoch 19.347), train_loss = 1.20273667, grad/param norm = 1.8230e-01, time/batch = 14.5522s	
12867/33250 (epoch 19.349), train_loss = 0.90819963, grad/param norm = 1.4881e-01, time/batch = 15.0207s	
12868/33250 (epoch 19.350), train_loss = 0.92939837, grad/param norm = 1.6420e-01, time/batch = 14.6347s	
12869/33250 (epoch 19.352), train_loss = 0.81447121, grad/param norm = 1.3757e-01, time/batch = 14.6348s	
12870/33250 (epoch 19.353), train_loss = 0.91168366, grad/param norm = 1.3147e-01, time/batch = 14.4698s	
12871/33250 (epoch 19.355), train_loss = 0.92413190, grad/param norm = 1.6491e-01, time/batch = 15.1954s	
12872/33250 (epoch 19.356), train_loss = 0.85847810, grad/param norm = 1.3903e-01, time/batch = 14.6357s	
12873/33250 (epoch 19.358), train_loss = 0.91526517, grad/param norm = 1.4246e-01, time/batch = 14.4796s	
12874/33250 (epoch 19.359), train_loss = 0.91690888, grad/param norm = 1.5194e-01, time/batch = 14.4917s	
12875/33250 (epoch 19.361), train_loss = 1.09319095, grad/param norm = 1.6510e-01, time/batch = 14.9546s	
12876/33250 (epoch 19.362), train_loss = 0.96918844, grad/param norm = 1.5685e-01, time/batch = 15.4106s	
12877/33250 (epoch 19.364), train_loss = 1.03227799, grad/param norm = 1.6463e-01, time/batch = 15.1731s	
12878/33250 (epoch 19.365), train_loss = 0.95047543, grad/param norm = 1.4645e-01, time/batch = 14.7868s	
12879/33250 (epoch 19.367), train_loss = 0.95985500, grad/param norm = 1.3149e-01, time/batch = 14.8621s	
12880/33250 (epoch 19.368), train_loss = 0.93966187, grad/param norm = 1.4037e-01, time/batch = 15.0890s	
12881/33250 (epoch 19.370), train_loss = 0.83477681, grad/param norm = 1.3463e-01, time/batch = 15.1308s	
12882/33250 (epoch 19.371), train_loss = 1.09167832, grad/param norm = 1.5715e-01, time/batch = 14.3205s	
12883/33250 (epoch 19.373), train_loss = 0.90964122, grad/param norm = 1.2429e-01, time/batch = 14.9771s	
12884/33250 (epoch 19.374), train_loss = 1.05558819, grad/param norm = 2.7137e-01, time/batch = 15.0526s	
12885/33250 (epoch 19.376), train_loss = 0.92078399, grad/param norm = 1.5068e-01, time/batch = 14.7811s	
12886/33250 (epoch 19.377), train_loss = 0.88196175, grad/param norm = 1.9938e-01, time/batch = 14.7757s	
12887/33250 (epoch 19.379), train_loss = 0.90070607, grad/param norm = 1.7267e-01, time/batch = 15.2591s	
12888/33250 (epoch 19.380), train_loss = 0.99598249, grad/param norm = 1.8198e-01, time/batch = 15.5705s	
12889/33250 (epoch 19.382), train_loss = 1.01443725, grad/param norm = 1.6411e-01, time/batch = 15.0389s	
12890/33250 (epoch 19.383), train_loss = 0.86352106, grad/param norm = 1.5521e-01, time/batch = 14.5379s	
12891/33250 (epoch 19.385), train_loss = 0.82323007, grad/param norm = 1.6319e-01, time/batch = 15.5783s	
12892/33250 (epoch 19.386), train_loss = 0.84085011, grad/param norm = 1.5325e-01, time/batch = 14.7814s	
12893/33250 (epoch 19.388), train_loss = 0.87704597, grad/param norm = 1.4534e-01, time/batch = 14.7067s	
12894/33250 (epoch 19.389), train_loss = 0.92802369, grad/param norm = 1.8501e-01, time/batch = 14.4888s	
12895/33250 (epoch 19.391), train_loss = 0.97919255, grad/param norm = 1.6656e-01, time/batch = 15.2569s	
12896/33250 (epoch 19.392), train_loss = 1.05327649, grad/param norm = 1.7839e-01, time/batch = 15.9639s	
12897/33250 (epoch 19.394), train_loss = 1.09580941, grad/param norm = 1.7822e-01, time/batch = 14.7185s	
12898/33250 (epoch 19.395), train_loss = 1.06998434, grad/param norm = 1.6867e-01, time/batch = 15.0945s	
12899/33250 (epoch 19.397), train_loss = 1.05203666, grad/param norm = 1.6174e-01, time/batch = 15.4050s	
12900/33250 (epoch 19.398), train_loss = 0.91084762, grad/param norm = 1.5460e-01, time/batch = 15.4029s	
12901/33250 (epoch 19.400), train_loss = 0.86358826, grad/param norm = 1.4147e-01, time/batch = 15.2592s	
12902/33250 (epoch 19.402), train_loss = 0.81070906, grad/param norm = 1.4610e-01, time/batch = 15.0121s	
12903/33250 (epoch 19.403), train_loss = 0.91523885, grad/param norm = 1.7977e-01, time/batch = 14.9414s	
12904/33250 (epoch 19.405), train_loss = 0.89212328, grad/param norm = 1.5066e-01, time/batch = 14.6288s	
12905/33250 (epoch 19.406), train_loss = 0.96244213, grad/param norm = 1.5032e-01, time/batch = 15.1691s	
12906/33250 (epoch 19.408), train_loss = 1.10126133, grad/param norm = 1.6812e-01, time/batch = 14.4666s	
12907/33250 (epoch 19.409), train_loss = 1.03237840, grad/param norm = 1.9158e-01, time/batch = 15.0258s	
12908/33250 (epoch 19.411), train_loss = 0.71358926, grad/param norm = 1.2936e-01, time/batch = 17.0485s	
12909/33250 (epoch 19.412), train_loss = 0.82857910, grad/param norm = 1.5571e-01, time/batch = 15.0472s	
12910/33250 (epoch 19.414), train_loss = 0.96953047, grad/param norm = 1.4013e-01, time/batch = 14.2227s	
12911/33250 (epoch 19.415), train_loss = 1.04412810, grad/param norm = 1.5622e-01, time/batch = 15.0952s	
12912/33250 (epoch 19.417), train_loss = 1.02617458, grad/param norm = 1.6015e-01, time/batch = 15.0118s	
12913/33250 (epoch 19.418), train_loss = 1.19505708, grad/param norm = 2.1545e-01, time/batch = 15.4431s	
12914/33250 (epoch 19.420), train_loss = 1.08293753, grad/param norm = 1.6819e-01, time/batch = 15.5745s	
12915/33250 (epoch 19.421), train_loss = 0.88854355, grad/param norm = 1.5835e-01, time/batch = 15.8329s	
12916/33250 (epoch 19.423), train_loss = 1.01494927, grad/param norm = 1.8149e-01, time/batch = 16.0382s	
12917/33250 (epoch 19.424), train_loss = 1.13429063, grad/param norm = 2.0867e-01, time/batch = 15.6108s	
12918/33250 (epoch 19.426), train_loss = 0.88376920, grad/param norm = 1.3607e-01, time/batch = 16.6805s	
12919/33250 (epoch 19.427), train_loss = 0.88048563, grad/param norm = 1.4799e-01, time/batch = 15.1963s	
12920/33250 (epoch 19.429), train_loss = 1.01607603, grad/param norm = 1.7179e-01, time/batch = 15.2941s	
12921/33250 (epoch 19.430), train_loss = 0.90701062, grad/param norm = 1.7949e-01, time/batch = 15.5856s	
12922/33250 (epoch 19.432), train_loss = 1.00267758, grad/param norm = 1.4049e-01, time/batch = 15.6713s	
12923/33250 (epoch 19.433), train_loss = 0.89625424, grad/param norm = 1.4900e-01, time/batch = 15.6901s	
12924/33250 (epoch 19.435), train_loss = 1.03807188, grad/param norm = 1.6850e-01, time/batch = 15.3487s	
12925/33250 (epoch 19.436), train_loss = 0.89452265, grad/param norm = 1.6706e-01, time/batch = 15.6038s	
12926/33250 (epoch 19.438), train_loss = 1.03248559, grad/param norm = 1.5420e-01, time/batch = 15.3311s	
12927/33250 (epoch 19.439), train_loss = 0.96084454, grad/param norm = 1.3407e-01, time/batch = 16.4353s	
12928/33250 (epoch 19.441), train_loss = 0.92518734, grad/param norm = 1.3133e-01, time/batch = 15.2159s	
12929/33250 (epoch 19.442), train_loss = 0.87642562, grad/param norm = 1.5837e-01, time/batch = 15.5193s	
12930/33250 (epoch 19.444), train_loss = 0.88025809, grad/param norm = 1.4056e-01, time/batch = 28.7925s	
12931/33250 (epoch 19.445), train_loss = 0.95700955, grad/param norm = 1.4848e-01, time/batch = 16.1937s	
12932/33250 (epoch 19.447), train_loss = 0.98749441, grad/param norm = 1.5795e-01, time/batch = 16.8350s	
12933/33250 (epoch 19.448), train_loss = 0.95902104, grad/param norm = 1.4064e-01, time/batch = 15.7484s	
12934/33250 (epoch 19.450), train_loss = 1.13526261, grad/param norm = 1.8843e-01, time/batch = 15.0914s	
12935/33250 (epoch 19.451), train_loss = 1.01213324, grad/param norm = 1.5993e-01, time/batch = 16.6837s	
12936/33250 (epoch 19.453), train_loss = 0.87064105, grad/param norm = 1.3745e-01, time/batch = 16.1487s	
12937/33250 (epoch 19.454), train_loss = 1.09823711, grad/param norm = 1.5745e-01, time/batch = 15.5533s	
12938/33250 (epoch 19.456), train_loss = 1.10214399, grad/param norm = 1.4935e-01, time/batch = 16.3676s	
12939/33250 (epoch 19.457), train_loss = 0.90026390, grad/param norm = 1.4936e-01, time/batch = 15.4366s	
12940/33250 (epoch 19.459), train_loss = 0.99908998, grad/param norm = 1.5956e-01, time/batch = 15.5212s	
12941/33250 (epoch 19.460), train_loss = 1.05637237, grad/param norm = 1.7386e-01, time/batch = 15.5280s	
12942/33250 (epoch 19.462), train_loss = 0.88044888, grad/param norm = 1.4194e-01, time/batch = 16.1995s	
12943/33250 (epoch 19.463), train_loss = 0.88351533, grad/param norm = 1.2921e-01, time/batch = 15.5467s	
12944/33250 (epoch 19.465), train_loss = 0.79647129, grad/param norm = 1.2745e-01, time/batch = 15.5083s	
12945/33250 (epoch 19.466), train_loss = 0.75050918, grad/param norm = 1.0568e-01, time/batch = 15.5412s	
12946/33250 (epoch 19.468), train_loss = 0.86045289, grad/param norm = 1.2987e-01, time/batch = 15.1105s	
12947/33250 (epoch 19.469), train_loss = 0.93152540, grad/param norm = 1.4911e-01, time/batch = 15.1737s	
12948/33250 (epoch 19.471), train_loss = 1.02811372, grad/param norm = 1.4284e-01, time/batch = 15.2773s	
12949/33250 (epoch 19.472), train_loss = 0.94122683, grad/param norm = 1.8882e-01, time/batch = 15.2260s	
12950/33250 (epoch 19.474), train_loss = 1.07774308, grad/param norm = 1.7491e-01, time/batch = 14.8754s	
12951/33250 (epoch 19.475), train_loss = 0.98679020, grad/param norm = 1.4542e-01, time/batch = 15.3323s	
12952/33250 (epoch 19.477), train_loss = 0.95911038, grad/param norm = 1.3973e-01, time/batch = 15.4119s	
12953/33250 (epoch 19.478), train_loss = 0.87120713, grad/param norm = 1.4790e-01, time/batch = 15.9505s	
12954/33250 (epoch 19.480), train_loss = 1.14454163, grad/param norm = 1.6970e-01, time/batch = 15.0209s	
12955/33250 (epoch 19.481), train_loss = 0.96498624, grad/param norm = 1.4507e-01, time/batch = 14.9610s	
12956/33250 (epoch 19.483), train_loss = 0.97922344, grad/param norm = 1.4790e-01, time/batch = 15.0241s	
12957/33250 (epoch 19.484), train_loss = 0.86504019, grad/param norm = 1.4022e-01, time/batch = 15.0227s	
12958/33250 (epoch 19.486), train_loss = 0.80855649, grad/param norm = 1.4366e-01, time/batch = 15.6299s	
12959/33250 (epoch 19.487), train_loss = 0.89558806, grad/param norm = 1.5347e-01, time/batch = 17.2643s	
12960/33250 (epoch 19.489), train_loss = 1.05875066, grad/param norm = 1.6683e-01, time/batch = 16.8503s	
12961/33250 (epoch 19.490), train_loss = 0.98290353, grad/param norm = 1.6321e-01, time/batch = 15.6712s	
12962/33250 (epoch 19.492), train_loss = 1.01407573, grad/param norm = 1.6266e-01, time/batch = 15.6278s	
12963/33250 (epoch 19.493), train_loss = 0.96244059, grad/param norm = 1.6419e-01, time/batch = 15.4343s	
12964/33250 (epoch 19.495), train_loss = 0.99031472, grad/param norm = 1.4582e-01, time/batch = 14.9582s	
12965/33250 (epoch 19.496), train_loss = 0.95525582, grad/param norm = 1.3723e-01, time/batch = 14.8644s	
12966/33250 (epoch 19.498), train_loss = 1.03825530, grad/param norm = 1.5864e-01, time/batch = 14.8728s	
12967/33250 (epoch 19.499), train_loss = 0.91428356, grad/param norm = 1.4850e-01, time/batch = 15.0997s	
12968/33250 (epoch 19.501), train_loss = 0.88092440, grad/param norm = 1.4592e-01, time/batch = 15.4046s	
12969/33250 (epoch 19.502), train_loss = 0.89737074, grad/param norm = 1.2947e-01, time/batch = 14.9463s	
12970/33250 (epoch 19.504), train_loss = 1.08077529, grad/param norm = 1.6525e-01, time/batch = 15.7450s	
12971/33250 (epoch 19.505), train_loss = 0.78183833, grad/param norm = 1.2107e-01, time/batch = 16.4211s	
12972/33250 (epoch 19.507), train_loss = 0.89038669, grad/param norm = 1.5210e-01, time/batch = 15.4929s	
12973/33250 (epoch 19.508), train_loss = 0.90117964, grad/param norm = 1.5104e-01, time/batch = 16.1948s	
12974/33250 (epoch 19.510), train_loss = 0.79243804, grad/param norm = 1.6690e-01, time/batch = 14.9541s	
12975/33250 (epoch 19.511), train_loss = 0.97364070, grad/param norm = 1.7695e-01, time/batch = 15.0935s	
12976/33250 (epoch 19.513), train_loss = 1.09248836, grad/param norm = 1.6955e-01, time/batch = 15.2891s	
12977/33250 (epoch 19.514), train_loss = 0.90553196, grad/param norm = 1.3543e-01, time/batch = 15.1178s	
12978/33250 (epoch 19.516), train_loss = 0.89110821, grad/param norm = 1.4936e-01, time/batch = 14.8645s	
12979/33250 (epoch 19.517), train_loss = 0.93090745, grad/param norm = 1.5523e-01, time/batch = 15.2629s	
12980/33250 (epoch 19.519), train_loss = 0.82920503, grad/param norm = 1.1139e-01, time/batch = 15.4809s	
12981/33250 (epoch 19.520), train_loss = 1.19663540, grad/param norm = 1.9215e-01, time/batch = 15.0975s	
12982/33250 (epoch 19.522), train_loss = 1.02465214, grad/param norm = 1.5657e-01, time/batch = 15.3851s	
12983/33250 (epoch 19.523), train_loss = 0.87019207, grad/param norm = 1.3854e-01, time/batch = 15.3578s	
12984/33250 (epoch 19.525), train_loss = 0.82844677, grad/param norm = 1.5378e-01, time/batch = 15.5009s	
12985/33250 (epoch 19.526), train_loss = 0.82116717, grad/param norm = 1.3919e-01, time/batch = 14.9493s	
12986/33250 (epoch 19.528), train_loss = 0.90681836, grad/param norm = 1.4555e-01, time/batch = 16.6452s	
12987/33250 (epoch 19.529), train_loss = 0.87152130, grad/param norm = 1.5427e-01, time/batch = 16.3379s	
12988/33250 (epoch 19.531), train_loss = 0.83124484, grad/param norm = 1.2753e-01, time/batch = 16.0199s	
12989/33250 (epoch 19.532), train_loss = 0.99482255, grad/param norm = 1.5084e-01, time/batch = 15.3493s	
12990/33250 (epoch 19.534), train_loss = 0.86026068, grad/param norm = 1.3143e-01, time/batch = 15.4152s	
12991/33250 (epoch 19.535), train_loss = 0.93374548, grad/param norm = 1.3209e-01, time/batch = 15.5414s	
12992/33250 (epoch 19.537), train_loss = 0.98565041, grad/param norm = 1.3874e-01, time/batch = 17.5391s	
12993/33250 (epoch 19.538), train_loss = 1.01382325, grad/param norm = 1.5972e-01, time/batch = 17.3467s	
12994/33250 (epoch 19.540), train_loss = 1.09324206, grad/param norm = 1.3967e-01, time/batch = 15.7596s	
12995/33250 (epoch 19.541), train_loss = 1.03902751, grad/param norm = 1.6395e-01, time/batch = 15.4530s	
12996/33250 (epoch 19.543), train_loss = 1.00861370, grad/param norm = 1.4563e-01, time/batch = 14.8720s	
12997/33250 (epoch 19.544), train_loss = 0.89384820, grad/param norm = 1.5907e-01, time/batch = 15.9500s	
12998/33250 (epoch 19.546), train_loss = 0.95683207, grad/param norm = 2.0148e-01, time/batch = 15.2537s	
12999/33250 (epoch 19.547), train_loss = 0.91730066, grad/param norm = 1.5615e-01, time/batch = 15.0165s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch19.55_1.4849.t7	
13000/33250 (epoch 19.549), train_loss = 1.01923411, grad/param norm = 1.6743e-01, time/batch = 14.9393s	
13001/33250 (epoch 19.550), train_loss = 1.25523498, grad/param norm = 1.8041e-01, time/batch = 16.1139s	
13002/33250 (epoch 19.552), train_loss = 0.98191197, grad/param norm = 1.5315e-01, time/batch = 16.7673s	
13003/33250 (epoch 19.553), train_loss = 0.87997663, grad/param norm = 1.3703e-01, time/batch = 16.1738s	
13004/33250 (epoch 19.555), train_loss = 0.99404708, grad/param norm = 1.4735e-01, time/batch = 15.8131s	
13005/33250 (epoch 19.556), train_loss = 1.04664707, grad/param norm = 1.8175e-01, time/batch = 15.7950s	
13006/33250 (epoch 19.558), train_loss = 1.05230259, grad/param norm = 1.5872e-01, time/batch = 15.1090s	
13007/33250 (epoch 19.559), train_loss = 0.85510582, grad/param norm = 1.3169e-01, time/batch = 15.1776s	
13008/33250 (epoch 19.561), train_loss = 0.84958673, grad/param norm = 1.3389e-01, time/batch = 15.1685s	
13009/33250 (epoch 19.562), train_loss = 1.05197875, grad/param norm = 1.6303e-01, time/batch = 15.8335s	
13010/33250 (epoch 19.564), train_loss = 1.15601250, grad/param norm = 1.7681e-01, time/batch = 15.3394s	
13011/33250 (epoch 19.565), train_loss = 1.06930099, grad/param norm = 1.7028e-01, time/batch = 15.4367s	
13012/33250 (epoch 19.567), train_loss = 1.08738778, grad/param norm = 1.7268e-01, time/batch = 15.2560s	
13013/33250 (epoch 19.568), train_loss = 0.97317446, grad/param norm = 1.5639e-01, time/batch = 14.8726s	
13014/33250 (epoch 19.570), train_loss = 1.06248990, grad/param norm = 1.6283e-01, time/batch = 15.3639s	
13015/33250 (epoch 19.571), train_loss = 1.10004661, grad/param norm = 1.4911e-01, time/batch = 16.3662s	
13016/33250 (epoch 19.573), train_loss = 1.01230971, grad/param norm = 1.9048e-01, time/batch = 15.4305s	
13017/33250 (epoch 19.574), train_loss = 0.85797780, grad/param norm = 1.3403e-01, time/batch = 15.5305s	
13018/33250 (epoch 19.576), train_loss = 1.00816114, grad/param norm = 1.5428e-01, time/batch = 15.3692s	
13019/33250 (epoch 19.577), train_loss = 0.94626649, grad/param norm = 1.5173e-01, time/batch = 15.0116s	
13020/33250 (epoch 19.579), train_loss = 0.85694508, grad/param norm = 1.5617e-01, time/batch = 16.1094s	
13021/33250 (epoch 19.580), train_loss = 0.90930468, grad/param norm = 1.2329e-01, time/batch = 16.3466s	
13022/33250 (epoch 19.582), train_loss = 0.92662126, grad/param norm = 1.4033e-01, time/batch = 15.3558s	
13023/33250 (epoch 19.583), train_loss = 1.04156872, grad/param norm = 1.5256e-01, time/batch = 15.2405s	
13024/33250 (epoch 19.585), train_loss = 1.03315864, grad/param norm = 1.4551e-01, time/batch = 15.2681s	
13025/33250 (epoch 19.586), train_loss = 0.90159245, grad/param norm = 1.7517e-01, time/batch = 17.1024s	
13026/33250 (epoch 19.588), train_loss = 0.98524137, grad/param norm = 1.4888e-01, time/batch = 18.1904s	
13027/33250 (epoch 19.589), train_loss = 1.00072554, grad/param norm = 1.5317e-01, time/batch = 16.7782s	
13028/33250 (epoch 19.591), train_loss = 0.97933463, grad/param norm = 1.6548e-01, time/batch = 15.3833s	
13029/33250 (epoch 19.592), train_loss = 0.96187147, grad/param norm = 1.4674e-01, time/batch = 15.7269s	
13030/33250 (epoch 19.594), train_loss = 1.10208733, grad/param norm = 1.8432e-01, time/batch = 15.2554s	
13031/33250 (epoch 19.595), train_loss = 1.01566233, grad/param norm = 1.7049e-01, time/batch = 15.4236s	
13032/33250 (epoch 19.597), train_loss = 0.81172301, grad/param norm = 1.2295e-01, time/batch = 15.3605s	
13033/33250 (epoch 19.598), train_loss = 0.92971592, grad/param norm = 1.5643e-01, time/batch = 15.0263s	
13034/33250 (epoch 19.600), train_loss = 0.94633264, grad/param norm = 1.6065e-01, time/batch = 16.0216s	
13035/33250 (epoch 19.602), train_loss = 0.99301480, grad/param norm = 1.8852e-01, time/batch = 15.4348s	
13036/33250 (epoch 19.603), train_loss = 0.99545079, grad/param norm = 1.6264e-01, time/batch = 16.2864s	
13037/33250 (epoch 19.605), train_loss = 0.97897712, grad/param norm = 1.5323e-01, time/batch = 16.0147s	
13038/33250 (epoch 19.606), train_loss = 1.01660064, grad/param norm = 1.5687e-01, time/batch = 15.6612s	
13039/33250 (epoch 19.608), train_loss = 0.96835789, grad/param norm = 1.4782e-01, time/batch = 15.8394s	
13040/33250 (epoch 19.609), train_loss = 0.87488740, grad/param norm = 1.5016e-01, time/batch = 15.8981s	
13041/33250 (epoch 19.611), train_loss = 0.98771154, grad/param norm = 1.6127e-01, time/batch = 16.5059s	
13042/33250 (epoch 19.612), train_loss = 0.96357894, grad/param norm = 1.5137e-01, time/batch = 15.5205s	
13043/33250 (epoch 19.614), train_loss = 1.17600175, grad/param norm = 2.0933e-01, time/batch = 15.7027s	
13044/33250 (epoch 19.615), train_loss = 1.07349364, grad/param norm = 1.7109e-01, time/batch = 15.6875s	
13045/33250 (epoch 19.617), train_loss = 1.23086320, grad/param norm = 1.6777e-01, time/batch = 16.4405s	
13046/33250 (epoch 19.618), train_loss = 1.24441705, grad/param norm = 1.9102e-01, time/batch = 15.5151s	
13047/33250 (epoch 19.620), train_loss = 1.04847262, grad/param norm = 1.6865e-01, time/batch = 16.1944s	
13048/33250 (epoch 19.621), train_loss = 0.98335641, grad/param norm = 1.4679e-01, time/batch = 17.1052s	
13049/33250 (epoch 19.623), train_loss = 0.90175443, grad/param norm = 1.5515e-01, time/batch = 16.5055s	
13050/33250 (epoch 19.624), train_loss = 0.96426657, grad/param norm = 1.8770e-01, time/batch = 15.3261s	
13051/33250 (epoch 19.626), train_loss = 0.92721919, grad/param norm = 1.6491e-01, time/batch = 15.4823s	
13052/33250 (epoch 19.627), train_loss = 0.90577978, grad/param norm = 1.4902e-01, time/batch = 15.5702s	
13053/33250 (epoch 19.629), train_loss = 1.01863035, grad/param norm = 1.8235e-01, time/batch = 15.6024s	
13054/33250 (epoch 19.630), train_loss = 0.93336032, grad/param norm = 1.7858e-01, time/batch = 15.3513s	
13055/33250 (epoch 19.632), train_loss = 0.78978621, grad/param norm = 1.2513e-01, time/batch = 15.0998s	
13056/33250 (epoch 19.633), train_loss = 0.96540898, grad/param norm = 1.4888e-01, time/batch = 15.6208s	
13057/33250 (epoch 19.635), train_loss = 0.87290168, grad/param norm = 1.5165e-01, time/batch = 15.5038s	
13058/33250 (epoch 19.636), train_loss = 0.89651549, grad/param norm = 1.5189e-01, time/batch = 16.4584s	
13059/33250 (epoch 19.638), train_loss = 0.90262523, grad/param norm = 1.4191e-01, time/batch = 15.8071s	
13060/33250 (epoch 19.639), train_loss = 0.79867064, grad/param norm = 1.3819e-01, time/batch = 17.0445s	
13061/33250 (epoch 19.641), train_loss = 0.91449749, grad/param norm = 1.4512e-01, time/batch = 15.3471s	
13062/33250 (epoch 19.642), train_loss = 0.77505376, grad/param norm = 1.4198e-01, time/batch = 15.1001s	
13063/33250 (epoch 19.644), train_loss = 0.69368081, grad/param norm = 1.2800e-01, time/batch = 15.7793s	
13064/33250 (epoch 19.645), train_loss = 1.04105648, grad/param norm = 1.7240e-01, time/batch = 15.6665s	
13065/33250 (epoch 19.647), train_loss = 0.83854656, grad/param norm = 1.6030e-01, time/batch = 15.2437s	
13066/33250 (epoch 19.648), train_loss = 0.88043380, grad/param norm = 1.6507e-01, time/batch = 15.4540s	
13067/33250 (epoch 19.650), train_loss = 1.07082890, grad/param norm = 1.7014e-01, time/batch = 17.1157s	
13068/33250 (epoch 19.651), train_loss = 1.00129980, grad/param norm = 1.7167e-01, time/batch = 17.2733s	
13069/33250 (epoch 19.653), train_loss = 0.86138356, grad/param norm = 1.6094e-01, time/batch = 15.6893s	
13070/33250 (epoch 19.654), train_loss = 0.94059586, grad/param norm = 1.4902e-01, time/batch = 16.6251s	
13071/33250 (epoch 19.656), train_loss = 0.99442304, grad/param norm = 1.4944e-01, time/batch = 15.1938s	
13072/33250 (epoch 19.657), train_loss = 0.75218053, grad/param norm = 1.4564e-01, time/batch = 15.6747s	
13073/33250 (epoch 19.659), train_loss = 0.89227889, grad/param norm = 1.4421e-01, time/batch = 16.0155s	
13074/33250 (epoch 19.660), train_loss = 0.94290846, grad/param norm = 1.5888e-01, time/batch = 15.3549s	
13075/33250 (epoch 19.662), train_loss = 0.95455451, grad/param norm = 1.5124e-01, time/batch = 15.7605s	
13076/33250 (epoch 19.663), train_loss = 0.87185409, grad/param norm = 1.5164e-01, time/batch = 15.7476s	
13077/33250 (epoch 19.665), train_loss = 0.97888817, grad/param norm = 1.4469e-01, time/batch = 15.2777s	
13078/33250 (epoch 19.666), train_loss = 0.90915296, grad/param norm = 1.4521e-01, time/batch = 16.0333s	
13079/33250 (epoch 19.668), train_loss = 1.09346090, grad/param norm = 1.5536e-01, time/batch = 16.0240s	
13080/33250 (epoch 19.669), train_loss = 0.99273287, grad/param norm = 1.6963e-01, time/batch = 16.6092s	
13081/33250 (epoch 19.671), train_loss = 0.87720722, grad/param norm = 1.5378e-01, time/batch = 15.7380s	
13082/33250 (epoch 19.672), train_loss = 1.03945629, grad/param norm = 1.6298e-01, time/batch = 15.8703s	
13083/33250 (epoch 19.674), train_loss = 0.86275570, grad/param norm = 1.4419e-01, time/batch = 15.1146s	
13084/33250 (epoch 19.675), train_loss = 0.93971369, grad/param norm = 1.5502e-01, time/batch = 15.5513s	
13085/33250 (epoch 19.677), train_loss = 1.04013777, grad/param norm = 1.6077e-01, time/batch = 15.3126s	
13086/33250 (epoch 19.678), train_loss = 0.91112854, grad/param norm = 1.5150e-01, time/batch = 15.4239s	
13087/33250 (epoch 19.680), train_loss = 1.05153193, grad/param norm = 1.7679e-01, time/batch = 15.2578s	
13088/33250 (epoch 19.681), train_loss = 0.82811584, grad/param norm = 1.4768e-01, time/batch = 14.9393s	
13089/33250 (epoch 19.683), train_loss = 0.93113560, grad/param norm = 1.4683e-01, time/batch = 16.2001s	
13090/33250 (epoch 19.684), train_loss = 0.84626551, grad/param norm = 1.6513e-01, time/batch = 15.3681s	
13091/33250 (epoch 19.686), train_loss = 0.87074679, grad/param norm = 1.5509e-01, time/batch = 15.4318s	
13092/33250 (epoch 19.687), train_loss = 0.94846291, grad/param norm = 1.4553e-01, time/batch = 15.4593s	
13093/33250 (epoch 19.689), train_loss = 0.87904169, grad/param norm = 1.6338e-01, time/batch = 15.1800s	
13094/33250 (epoch 19.690), train_loss = 0.96117670, grad/param norm = 1.4889e-01, time/batch = 15.1277s	
13095/33250 (epoch 19.692), train_loss = 0.91470734, grad/param norm = 1.4498e-01, time/batch = 15.1909s	
13096/33250 (epoch 19.693), train_loss = 1.01304576, grad/param norm = 1.4550e-01, time/batch = 15.4133s	
13097/33250 (epoch 19.695), train_loss = 0.97959480, grad/param norm = 1.5416e-01, time/batch = 15.0149s	
13098/33250 (epoch 19.696), train_loss = 0.97205907, grad/param norm = 1.3641e-01, time/batch = 14.7925s	
13099/33250 (epoch 19.698), train_loss = 0.88469145, grad/param norm = 1.5394e-01, time/batch = 15.4215s	
13100/33250 (epoch 19.699), train_loss = 1.15644505, grad/param norm = 1.5914e-01, time/batch = 16.0258s	
13101/33250 (epoch 19.701), train_loss = 0.95311123, grad/param norm = 1.4097e-01, time/batch = 17.2924s	
13102/33250 (epoch 19.702), train_loss = 0.90107798, grad/param norm = 1.6064e-01, time/batch = 17.6886s	
13103/33250 (epoch 19.704), train_loss = 1.11467886, grad/param norm = 1.7712e-01, time/batch = 15.5302s	
13104/33250 (epoch 19.705), train_loss = 0.88552476, grad/param norm = 1.3618e-01, time/batch = 15.9462s	
13105/33250 (epoch 19.707), train_loss = 0.79084455, grad/param norm = 1.3163e-01, time/batch = 15.8322s	
13106/33250 (epoch 19.708), train_loss = 1.04752847, grad/param norm = 1.5851e-01, time/batch = 16.0980s	
13107/33250 (epoch 19.710), train_loss = 1.02064143, grad/param norm = 1.7037e-01, time/batch = 16.1824s	
13108/33250 (epoch 19.711), train_loss = 0.88664124, grad/param norm = 1.6165e-01, time/batch = 15.3589s	
13109/33250 (epoch 19.713), train_loss = 0.98333871, grad/param norm = 1.4996e-01, time/batch = 15.6987s	
13110/33250 (epoch 19.714), train_loss = 0.95695991, grad/param norm = 1.5336e-01, time/batch = 16.2648s	
13111/33250 (epoch 19.716), train_loss = 1.00770351, grad/param norm = 1.5336e-01, time/batch = 16.0237s	
13112/33250 (epoch 19.717), train_loss = 0.87977206, grad/param norm = 1.3490e-01, time/batch = 16.2924s	
13113/33250 (epoch 19.719), train_loss = 0.91270551, grad/param norm = 1.5181e-01, time/batch = 16.2744s	
13114/33250 (epoch 19.720), train_loss = 1.18468275, grad/param norm = 1.7241e-01, time/batch = 15.6230s	
13115/33250 (epoch 19.722), train_loss = 0.82610358, grad/param norm = 1.3456e-01, time/batch = 14.4573s	
13116/33250 (epoch 19.723), train_loss = 0.75176421, grad/param norm = 1.1907e-01, time/batch = 15.0695s	
13117/33250 (epoch 19.725), train_loss = 0.84269348, grad/param norm = 1.3313e-01, time/batch = 15.2296s	
13118/33250 (epoch 19.726), train_loss = 0.92092179, grad/param norm = 1.6236e-01, time/batch = 15.2197s	
13119/33250 (epoch 19.728), train_loss = 0.99612916, grad/param norm = 1.6343e-01, time/batch = 15.2666s	
13120/33250 (epoch 19.729), train_loss = 1.07194749, grad/param norm = 1.6243e-01, time/batch = 15.2428s	
13121/33250 (epoch 19.731), train_loss = 0.88939419, grad/param norm = 1.5427e-01, time/batch = 16.4862s	
13122/33250 (epoch 19.732), train_loss = 0.84878392, grad/param norm = 1.5206e-01, time/batch = 16.0183s	
13123/33250 (epoch 19.734), train_loss = 0.97604912, grad/param norm = 1.4956e-01, time/batch = 15.3154s	
13124/33250 (epoch 19.735), train_loss = 0.94641721, grad/param norm = 1.5801e-01, time/batch = 15.4411s	
13125/33250 (epoch 19.737), train_loss = 0.91911348, grad/param norm = 1.3908e-01, time/batch = 15.4165s	
13126/33250 (epoch 19.738), train_loss = 0.97654323, grad/param norm = 1.5393e-01, time/batch = 15.3493s	
13127/33250 (epoch 19.740), train_loss = 1.05523159, grad/param norm = 1.5033e-01, time/batch = 15.0168s	
13128/33250 (epoch 19.741), train_loss = 1.02908860, grad/param norm = 1.6255e-01, time/batch = 14.8414s	
13129/33250 (epoch 19.743), train_loss = 0.89046117, grad/param norm = 1.3686e-01, time/batch = 14.9885s	
13130/33250 (epoch 19.744), train_loss = 0.91504960, grad/param norm = 1.5458e-01, time/batch = 15.2570s	
13131/33250 (epoch 19.746), train_loss = 0.86292750, grad/param norm = 1.2914e-01, time/batch = 15.1827s	
13132/33250 (epoch 19.747), train_loss = 0.88850620, grad/param norm = 1.6090e-01, time/batch = 15.2631s	
13133/33250 (epoch 19.749), train_loss = 1.04362542, grad/param norm = 1.6419e-01, time/batch = 15.4001s	
13134/33250 (epoch 19.750), train_loss = 1.03785090, grad/param norm = 1.8416e-01, time/batch = 16.5053s	
13135/33250 (epoch 19.752), train_loss = 0.90177163, grad/param norm = 1.3617e-01, time/batch = 15.3135s	
13136/33250 (epoch 19.753), train_loss = 0.91899931, grad/param norm = 1.6585e-01, time/batch = 15.4049s	
13137/33250 (epoch 19.755), train_loss = 0.92415258, grad/param norm = 1.5516e-01, time/batch = 15.4163s	
13138/33250 (epoch 19.756), train_loss = 0.99807118, grad/param norm = 1.6380e-01, time/batch = 15.2958s	
13139/33250 (epoch 19.758), train_loss = 1.08564256, grad/param norm = 1.4882e-01, time/batch = 15.0216s	
13140/33250 (epoch 19.759), train_loss = 0.86691346, grad/param norm = 1.4252e-01, time/batch = 14.6712s	
13141/33250 (epoch 19.761), train_loss = 0.94466725, grad/param norm = 1.5574e-01, time/batch = 15.5098s	
13142/33250 (epoch 19.762), train_loss = 1.04814196, grad/param norm = 1.5086e-01, time/batch = 16.3589s	
13143/33250 (epoch 19.764), train_loss = 0.86749610, grad/param norm = 1.9815e-01, time/batch = 15.4165s	
13144/33250 (epoch 19.765), train_loss = 1.01403328, grad/param norm = 1.6483e-01, time/batch = 16.6685s	
13145/33250 (epoch 19.767), train_loss = 0.78455909, grad/param norm = 1.4329e-01, time/batch = 15.5522s	
13146/33250 (epoch 19.768), train_loss = 0.80365641, grad/param norm = 1.3769e-01, time/batch = 14.7846s	
13147/33250 (epoch 19.770), train_loss = 0.98937360, grad/param norm = 1.6733e-01, time/batch = 14.6954s	
13148/33250 (epoch 19.771), train_loss = 1.01914833, grad/param norm = 1.6515e-01, time/batch = 14.5308s	
13149/33250 (epoch 19.773), train_loss = 0.91646798, grad/param norm = 1.7317e-01, time/batch = 29.6427s	
13150/33250 (epoch 19.774), train_loss = 0.78686375, grad/param norm = 1.5974e-01, time/batch = 15.2655s	
13151/33250 (epoch 19.776), train_loss = 0.88909084, grad/param norm = 1.5397e-01, time/batch = 15.1828s	
13152/33250 (epoch 19.777), train_loss = 1.05879681, grad/param norm = 1.8411e-01, time/batch = 15.3540s	
13153/33250 (epoch 19.779), train_loss = 0.94123214, grad/param norm = 1.5786e-01, time/batch = 15.6957s	
13154/33250 (epoch 19.780), train_loss = 1.11169557, grad/param norm = 1.7315e-01, time/batch = 15.1375s	
13155/33250 (epoch 19.782), train_loss = 0.97638801, grad/param norm = 1.5883e-01, time/batch = 16.6033s	
13156/33250 (epoch 19.783), train_loss = 0.80225991, grad/param norm = 1.3880e-01, time/batch = 16.5283s	
13157/33250 (epoch 19.785), train_loss = 0.83121633, grad/param norm = 1.3767e-01, time/batch = 15.2838s	
13158/33250 (epoch 19.786), train_loss = 1.02280618, grad/param norm = 1.4656e-01, time/batch = 16.1844s	
13159/33250 (epoch 19.788), train_loss = 1.02278818, grad/param norm = 1.5946e-01, time/batch = 15.4288s	
13160/33250 (epoch 19.789), train_loss = 1.04964172, grad/param norm = 1.6620e-01, time/batch = 15.0054s	
13161/33250 (epoch 19.791), train_loss = 1.11372800, grad/param norm = 1.6174e-01, time/batch = 15.4442s	
13162/33250 (epoch 19.792), train_loss = 1.17323811, grad/param norm = 1.5300e-01, time/batch = 15.4420s	
13163/33250 (epoch 19.794), train_loss = 0.93782199, grad/param norm = 1.6046e-01, time/batch = 15.5162s	
13164/33250 (epoch 19.795), train_loss = 0.98604208, grad/param norm = 1.5669e-01, time/batch = 15.4385s	
13165/33250 (epoch 19.797), train_loss = 1.04019162, grad/param norm = 1.7387e-01, time/batch = 15.4519s	
13166/33250 (epoch 19.798), train_loss = 0.95133814, grad/param norm = 1.7229e-01, time/batch = 15.4274s	
13167/33250 (epoch 19.800), train_loss = 1.00293636, grad/param norm = 1.6191e-01, time/batch = 15.1231s	
13168/33250 (epoch 19.802), train_loss = 0.92723340, grad/param norm = 1.3450e-01, time/batch = 16.2080s	
13169/33250 (epoch 19.803), train_loss = 0.97381244, grad/param norm = 1.4229e-01, time/batch = 15.9121s	
13170/33250 (epoch 19.805), train_loss = 0.99706610, grad/param norm = 1.5746e-01, time/batch = 16.8288s	
13171/33250 (epoch 19.806), train_loss = 0.97398212, grad/param norm = 1.6285e-01, time/batch = 15.4177s	
13172/33250 (epoch 19.808), train_loss = 0.92512603, grad/param norm = 1.5283e-01, time/batch = 15.4361s	
13173/33250 (epoch 19.809), train_loss = 0.87802911, grad/param norm = 1.4914e-01, time/batch = 15.6649s	
13174/33250 (epoch 19.811), train_loss = 0.87956855, grad/param norm = 1.4161e-01, time/batch = 15.2374s	
13175/33250 (epoch 19.812), train_loss = 1.00909616, grad/param norm = 1.6274e-01, time/batch = 15.1940s	
13176/33250 (epoch 19.814), train_loss = 0.94739092, grad/param norm = 1.4532e-01, time/batch = 15.1788s	
13177/33250 (epoch 19.815), train_loss = 1.00134677, grad/param norm = 1.4119e-01, time/batch = 15.4776s	
13178/33250 (epoch 19.817), train_loss = 0.93294152, grad/param norm = 1.5058e-01, time/batch = 15.7725s	
13179/33250 (epoch 19.818), train_loss = 0.87061317, grad/param norm = 1.4362e-01, time/batch = 16.0313s	
13180/33250 (epoch 19.820), train_loss = 0.97108103, grad/param norm = 1.5105e-01, time/batch = 16.2054s	
13181/33250 (epoch 19.821), train_loss = 0.94298125, grad/param norm = 1.4191e-01, time/batch = 15.3649s	
13182/33250 (epoch 19.823), train_loss = 1.28751122, grad/param norm = 1.7518e-01, time/batch = 15.6732s	
13183/33250 (epoch 19.824), train_loss = 0.93275438, grad/param norm = 1.6365e-01, time/batch = 15.2662s	
13184/33250 (epoch 19.826), train_loss = 0.99125767, grad/param norm = 1.7039e-01, time/batch = 15.4988s	
13185/33250 (epoch 19.827), train_loss = 0.78084711, grad/param norm = 1.4192e-01, time/batch = 14.8870s	
13186/33250 (epoch 19.829), train_loss = 0.98669038, grad/param norm = 1.9670e-01, time/batch = 15.4801s	
13187/33250 (epoch 19.830), train_loss = 1.07099015, grad/param norm = 1.9456e-01, time/batch = 15.2873s	
13188/33250 (epoch 19.832), train_loss = 0.98167907, grad/param norm = 1.5808e-01, time/batch = 16.3758s	
13189/33250 (epoch 19.833), train_loss = 0.98093525, grad/param norm = 1.5649e-01, time/batch = 18.5290s	
13190/33250 (epoch 19.835), train_loss = 0.89948616, grad/param norm = 1.8199e-01, time/batch = 16.6839s	
13191/33250 (epoch 19.836), train_loss = 0.93342329, grad/param norm = 1.5191e-01, time/batch = 18.9490s	
13192/33250 (epoch 19.838), train_loss = 0.96069037, grad/param norm = 1.4684e-01, time/batch = 15.4117s	
13193/33250 (epoch 19.839), train_loss = 0.91128812, grad/param norm = 1.4514e-01, time/batch = 16.4205s	
13194/33250 (epoch 19.841), train_loss = 0.88291878, grad/param norm = 1.3200e-01, time/batch = 15.6490s	
13195/33250 (epoch 19.842), train_loss = 1.09270925, grad/param norm = 1.4720e-01, time/batch = 16.1882s	
13196/33250 (epoch 19.844), train_loss = 1.07423970, grad/param norm = 1.6936e-01, time/batch = 15.4117s	
13197/33250 (epoch 19.845), train_loss = 1.15575724, grad/param norm = 1.7906e-01, time/batch = 15.2761s	
13198/33250 (epoch 19.847), train_loss = 1.10842762, grad/param norm = 1.6283e-01, time/batch = 15.8697s	
13199/33250 (epoch 19.848), train_loss = 1.21869844, grad/param norm = 1.8057e-01, time/batch = 16.0859s	
13200/33250 (epoch 19.850), train_loss = 1.06930318, grad/param norm = 1.6221e-01, time/batch = 16.7048s	
13201/33250 (epoch 19.851), train_loss = 0.88606380, grad/param norm = 1.6100e-01, time/batch = 17.1969s	
13202/33250 (epoch 19.853), train_loss = 1.04903476, grad/param norm = 1.9102e-01, time/batch = 17.4318s	
13203/33250 (epoch 19.854), train_loss = 0.87659812, grad/param norm = 1.3361e-01, time/batch = 15.0883s	
13204/33250 (epoch 19.856), train_loss = 0.90917426, grad/param norm = 1.5859e-01, time/batch = 15.6011s	
13205/33250 (epoch 19.857), train_loss = 0.83850474, grad/param norm = 1.4438e-01, time/batch = 15.6055s	
13206/33250 (epoch 19.859), train_loss = 0.83312587, grad/param norm = 1.3859e-01, time/batch = 16.6927s	
13207/33250 (epoch 19.860), train_loss = 0.97245623, grad/param norm = 1.4858e-01, time/batch = 15.8531s	
13208/33250 (epoch 19.862), train_loss = 0.86183934, grad/param norm = 1.4513e-01, time/batch = 15.6101s	
13209/33250 (epoch 19.863), train_loss = 0.91289798, grad/param norm = 1.5861e-01, time/batch = 19.5185s	
13210/33250 (epoch 19.865), train_loss = 1.00540291, grad/param norm = 1.5873e-01, time/batch = 17.5302s	
13211/33250 (epoch 19.866), train_loss = 0.90803517, grad/param norm = 1.5887e-01, time/batch = 17.0121s	
13212/33250 (epoch 19.868), train_loss = 1.02585802, grad/param norm = 1.8759e-01, time/batch = 17.4333s	
13213/33250 (epoch 19.869), train_loss = 0.99074753, grad/param norm = 1.6318e-01, time/batch = 16.5217s	
13214/33250 (epoch 19.871), train_loss = 0.74620830, grad/param norm = 1.2574e-01, time/batch = 15.7016s	
13215/33250 (epoch 19.872), train_loss = 1.00125978, grad/param norm = 1.5654e-01, time/batch = 15.4387s	
13216/33250 (epoch 19.874), train_loss = 0.86384527, grad/param norm = 1.5053e-01, time/batch = 17.1770s	
13217/33250 (epoch 19.875), train_loss = 0.84650018, grad/param norm = 1.6288e-01, time/batch = 15.5563s	
13218/33250 (epoch 19.877), train_loss = 1.08672379, grad/param norm = 1.6160e-01, time/batch = 16.5187s	
13219/33250 (epoch 19.878), train_loss = 0.99640890, grad/param norm = 1.5014e-01, time/batch = 15.5962s	
13220/33250 (epoch 19.880), train_loss = 0.96535206, grad/param norm = 1.7960e-01, time/batch = 16.4471s	
13221/33250 (epoch 19.881), train_loss = 1.08632030, grad/param norm = 1.6873e-01, time/batch = 15.7823s	
13222/33250 (epoch 19.883), train_loss = 0.97340981, grad/param norm = 1.5609e-01, time/batch = 16.1898s	
13223/33250 (epoch 19.884), train_loss = 0.99525662, grad/param norm = 1.8972e-01, time/batch = 15.2688s	
13224/33250 (epoch 19.886), train_loss = 0.88943252, grad/param norm = 1.2853e-01, time/batch = 15.2696s	
13225/33250 (epoch 19.887), train_loss = 0.91586406, grad/param norm = 1.6142e-01, time/batch = 15.2534s	
13226/33250 (epoch 19.889), train_loss = 0.88831236, grad/param norm = 1.3493e-01, time/batch = 15.4381s	
13227/33250 (epoch 19.890), train_loss = 0.78724775, grad/param norm = 1.2978e-01, time/batch = 14.8419s	
13228/33250 (epoch 19.892), train_loss = 1.00791399, grad/param norm = 1.5111e-01, time/batch = 15.9287s	
13229/33250 (epoch 19.893), train_loss = 1.02448191, grad/param norm = 1.7854e-01, time/batch = 17.1312s	
13230/33250 (epoch 19.895), train_loss = 0.90692216, grad/param norm = 1.6835e-01, time/batch = 15.5189s	
13231/33250 (epoch 19.896), train_loss = 1.07298883, grad/param norm = 1.9922e-01, time/batch = 16.9594s	
13232/33250 (epoch 19.898), train_loss = 0.96752468, grad/param norm = 1.5903e-01, time/batch = 17.2902s	
13233/33250 (epoch 19.899), train_loss = 0.87274721, grad/param norm = 1.3757e-01, time/batch = 16.0195s	
13234/33250 (epoch 19.901), train_loss = 0.81368563, grad/param norm = 1.3684e-01, time/batch = 18.5418s	
13235/33250 (epoch 19.902), train_loss = 0.92664242, grad/param norm = 1.4505e-01, time/batch = 19.8881s	
13236/33250 (epoch 19.904), train_loss = 0.86891124, grad/param norm = 1.3944e-01, time/batch = 15.2659s	
13237/33250 (epoch 19.905), train_loss = 0.90818637, grad/param norm = 1.4447e-01, time/batch = 15.4246s	
13238/33250 (epoch 19.907), train_loss = 0.86195044, grad/param norm = 1.5072e-01, time/batch = 16.4486s	
13239/33250 (epoch 19.908), train_loss = 0.95237166, grad/param norm = 1.3856e-01, time/batch = 17.6181s	
13240/33250 (epoch 19.910), train_loss = 1.01183705, grad/param norm = 1.5657e-01, time/batch = 18.9367s	
13241/33250 (epoch 19.911), train_loss = 0.84550466, grad/param norm = 1.4497e-01, time/batch = 5.6200s	
13242/33250 (epoch 19.913), train_loss = 0.89370121, grad/param norm = 1.5451e-01, time/batch = 0.6732s	
13243/33250 (epoch 19.914), train_loss = 0.81744389, grad/param norm = 1.5994e-01, time/batch = 0.6715s	
13244/33250 (epoch 19.916), train_loss = 0.87675641, grad/param norm = 1.3567e-01, time/batch = 0.6676s	
13245/33250 (epoch 19.917), train_loss = 0.91000557, grad/param norm = 1.2896e-01, time/batch = 0.6642s	
13246/33250 (epoch 19.919), train_loss = 0.86607300, grad/param norm = 1.5806e-01, time/batch = 0.6698s	
13247/33250 (epoch 19.920), train_loss = 0.95084093, grad/param norm = 1.5671e-01, time/batch = 0.6793s	
13248/33250 (epoch 19.922), train_loss = 0.99038877, grad/param norm = 1.6351e-01, time/batch = 0.7575s	
13249/33250 (epoch 19.923), train_loss = 0.92757833, grad/param norm = 1.7337e-01, time/batch = 0.9730s	
13250/33250 (epoch 19.925), train_loss = 0.91768951, grad/param norm = 1.5183e-01, time/batch = 0.9824s	
13251/33250 (epoch 19.926), train_loss = 0.90402721, grad/param norm = 1.3767e-01, time/batch = 0.9696s	
13252/33250 (epoch 19.928), train_loss = 0.91826916, grad/param norm = 1.6019e-01, time/batch = 0.9700s	
13253/33250 (epoch 19.929), train_loss = 0.77311300, grad/param norm = 1.2715e-01, time/batch = 1.1264s	
13254/33250 (epoch 19.931), train_loss = 1.03921715, grad/param norm = 1.5375e-01, time/batch = 1.8393s	
13255/33250 (epoch 19.932), train_loss = 0.95356526, grad/param norm = 1.6484e-01, time/batch = 1.8038s	
13256/33250 (epoch 19.934), train_loss = 0.87103674, grad/param norm = 1.3488e-01, time/batch = 7.9829s	
13257/33250 (epoch 19.935), train_loss = 0.86856094, grad/param norm = 1.6039e-01, time/batch = 14.9374s	
13258/33250 (epoch 19.937), train_loss = 0.89935629, grad/param norm = 1.6097e-01, time/batch = 16.5856s	
13259/33250 (epoch 19.938), train_loss = 0.96093305, grad/param norm = 1.6550e-01, time/batch = 15.4218s	
13260/33250 (epoch 19.940), train_loss = 0.93054839, grad/param norm = 1.5334e-01, time/batch = 15.7762s	
13261/33250 (epoch 19.941), train_loss = 0.99937583, grad/param norm = 1.5089e-01, time/batch = 15.7035s	
13262/33250 (epoch 19.943), train_loss = 1.07983925, grad/param norm = 1.5804e-01, time/batch = 15.7704s	
13263/33250 (epoch 19.944), train_loss = 0.88466795, grad/param norm = 1.4329e-01, time/batch = 15.7918s	
13264/33250 (epoch 19.946), train_loss = 1.03767569, grad/param norm = 1.5952e-01, time/batch = 15.4797s	
13265/33250 (epoch 19.947), train_loss = 0.86716474, grad/param norm = 1.5272e-01, time/batch = 15.2935s	
13266/33250 (epoch 19.949), train_loss = 1.00509514, grad/param norm = 1.6577e-01, time/batch = 15.2886s	
13267/33250 (epoch 19.950), train_loss = 0.99661441, grad/param norm = 1.5143e-01, time/batch = 15.3407s	
13268/33250 (epoch 19.952), train_loss = 0.93701347, grad/param norm = 1.8288e-01, time/batch = 15.2795s	
13269/33250 (epoch 19.953), train_loss = 1.01725307, grad/param norm = 1.5287e-01, time/batch = 15.5254s	
13270/33250 (epoch 19.955), train_loss = 1.06081750, grad/param norm = 1.6632e-01, time/batch = 15.2820s	
13271/33250 (epoch 19.956), train_loss = 0.98474102, grad/param norm = 1.8653e-01, time/batch = 15.2034s	
13272/33250 (epoch 19.958), train_loss = 0.88755456, grad/param norm = 1.4618e-01, time/batch = 15.1103s	
13273/33250 (epoch 19.959), train_loss = 0.90219215, grad/param norm = 1.5064e-01, time/batch = 14.9594s	
13274/33250 (epoch 19.961), train_loss = 1.13138113, grad/param norm = 1.5705e-01, time/batch = 15.4834s	
13275/33250 (epoch 19.962), train_loss = 0.95050474, grad/param norm = 1.5884e-01, time/batch = 15.2099s	
13276/33250 (epoch 19.964), train_loss = 1.11475931, grad/param norm = 1.8275e-01, time/batch = 15.9509s	
13277/33250 (epoch 19.965), train_loss = 1.01731176, grad/param norm = 1.7457e-01, time/batch = 16.2179s	
13278/33250 (epoch 19.967), train_loss = 0.96992921, grad/param norm = 1.5516e-01, time/batch = 15.9268s	
13279/33250 (epoch 19.968), train_loss = 1.10409542, grad/param norm = 1.5247e-01, time/batch = 15.9306s	
13280/33250 (epoch 19.970), train_loss = 1.22474169, grad/param norm = 2.0886e-01, time/batch = 15.5243s	
13281/33250 (epoch 19.971), train_loss = 1.10609296, grad/param norm = 1.9048e-01, time/batch = 15.9106s	
13282/33250 (epoch 19.973), train_loss = 0.91536645, grad/param norm = 1.4747e-01, time/batch = 15.4251s	
13283/33250 (epoch 19.974), train_loss = 1.03115829, grad/param norm = 1.5879e-01, time/batch = 16.3559s	
13284/33250 (epoch 19.976), train_loss = 0.92395129, grad/param norm = 1.5353e-01, time/batch = 16.8774s	
13285/33250 (epoch 19.977), train_loss = 0.89438439, grad/param norm = 1.4889e-01, time/batch = 16.9556s	
13286/33250 (epoch 19.979), train_loss = 0.96743386, grad/param norm = 1.6243e-01, time/batch = 16.4421s	
13287/33250 (epoch 19.980), train_loss = 0.99442725, grad/param norm = 1.5201e-01, time/batch = 16.6138s	
13288/33250 (epoch 19.982), train_loss = 0.87182085, grad/param norm = 1.3861e-01, time/batch = 15.2115s	
13289/33250 (epoch 19.983), train_loss = 0.98846542, grad/param norm = 1.6059e-01, time/batch = 15.1706s	
13290/33250 (epoch 19.985), train_loss = 0.90862392, grad/param norm = 1.4159e-01, time/batch = 15.1701s	
13291/33250 (epoch 19.986), train_loss = 1.02789406, grad/param norm = 1.5941e-01, time/batch = 15.2623s	
13292/33250 (epoch 19.988), train_loss = 1.08423822, grad/param norm = 1.6848e-01, time/batch = 15.1164s	
13293/33250 (epoch 19.989), train_loss = 1.04503483, grad/param norm = 1.9649e-01, time/batch = 15.3274s	
13294/33250 (epoch 19.991), train_loss = 0.99417571, grad/param norm = 1.5764e-01, time/batch = 15.4619s	
13295/33250 (epoch 19.992), train_loss = 0.91774306, grad/param norm = 1.6830e-01, time/batch = 15.4875s	
13296/33250 (epoch 19.994), train_loss = 0.90478201, grad/param norm = 1.4202e-01, time/batch = 15.4301s	
13297/33250 (epoch 19.995), train_loss = 0.91864026, grad/param norm = 2.0268e-01, time/batch = 15.2496s	
13298/33250 (epoch 19.997), train_loss = 0.69799089, grad/param norm = 1.3438e-01, time/batch = 15.0236s	
13299/33250 (epoch 19.998), train_loss = 0.98659978, grad/param norm = 1.4304e-01, time/batch = 15.4167s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
13300/33250 (epoch 20.000), train_loss = 0.96057896, grad/param norm = 1.5724e-01, time/batch = 15.5753s	
13301/33250 (epoch 20.002), train_loss = 1.14203675, grad/param norm = 1.6499e-01, time/batch = 15.2576s	
13302/33250 (epoch 20.003), train_loss = 1.03765998, grad/param norm = 1.5417e-01, time/batch = 15.2754s	
13303/33250 (epoch 20.005), train_loss = 0.79303230, grad/param norm = 1.4455e-01, time/batch = 15.2017s	
13304/33250 (epoch 20.006), train_loss = 0.80919124, grad/param norm = 1.3617e-01, time/batch = 14.9392s	
13305/33250 (epoch 20.008), train_loss = 1.10789716, grad/param norm = 1.5868e-01, time/batch = 15.0307s	
13306/33250 (epoch 20.009), train_loss = 1.11118563, grad/param norm = 1.6651e-01, time/batch = 17.5979s	
13307/33250 (epoch 20.011), train_loss = 0.85754190, grad/param norm = 1.4497e-01, time/batch = 16.7824s	
13308/33250 (epoch 20.012), train_loss = 0.97443769, grad/param norm = 1.7058e-01, time/batch = 15.6604s	
13309/33250 (epoch 20.014), train_loss = 1.08426212, grad/param norm = 1.7630e-01, time/batch = 15.6109s	
13310/33250 (epoch 20.015), train_loss = 0.96033381, grad/param norm = 1.4840e-01, time/batch = 15.0881s	
13311/33250 (epoch 20.017), train_loss = 0.98038588, grad/param norm = 1.8292e-01, time/batch = 15.5173s	
13312/33250 (epoch 20.018), train_loss = 0.80449402, grad/param norm = 1.5233e-01, time/batch = 15.4101s	
13313/33250 (epoch 20.020), train_loss = 0.96541836, grad/param norm = 1.4088e-01, time/batch = 15.0786s	
13314/33250 (epoch 20.021), train_loss = 0.98277293, grad/param norm = 1.4983e-01, time/batch = 14.9387s	
13315/33250 (epoch 20.023), train_loss = 0.80632910, grad/param norm = 1.6443e-01, time/batch = 15.2930s	
13316/33250 (epoch 20.024), train_loss = 1.04766000, grad/param norm = 1.4792e-01, time/batch = 15.4132s	
13317/33250 (epoch 20.026), train_loss = 0.96781387, grad/param norm = 1.4559e-01, time/batch = 15.5869s	
13318/33250 (epoch 20.027), train_loss = 0.95238927, grad/param norm = 1.3724e-01, time/batch = 16.0981s	
13319/33250 (epoch 20.029), train_loss = 0.97700435, grad/param norm = 1.4992e-01, time/batch = 15.9501s	
13320/33250 (epoch 20.030), train_loss = 0.96537205, grad/param norm = 1.6020e-01, time/batch = 15.5143s	
13321/33250 (epoch 20.032), train_loss = 1.16984000, grad/param norm = 1.8528e-01, time/batch = 15.5020s	
13322/33250 (epoch 20.033), train_loss = 0.90122328, grad/param norm = 1.4326e-01, time/batch = 15.4237s	
13323/33250 (epoch 20.035), train_loss = 0.94303059, grad/param norm = 1.7792e-01, time/batch = 15.0789s	
13324/33250 (epoch 20.036), train_loss = 1.01871296, grad/param norm = 1.6019e-01, time/batch = 15.3541s	
13325/33250 (epoch 20.038), train_loss = 0.95514383, grad/param norm = 1.4082e-01, time/batch = 15.2473s	
13326/33250 (epoch 20.039), train_loss = 0.85381295, grad/param norm = 1.4439e-01, time/batch = 15.8485s	
13327/33250 (epoch 20.041), train_loss = 0.98063209, grad/param norm = 1.7822e-01, time/batch = 17.1173s	
13328/33250 (epoch 20.042), train_loss = 0.77575358, grad/param norm = 1.2645e-01, time/batch = 15.7627s	
13329/33250 (epoch 20.044), train_loss = 1.08412000, grad/param norm = 1.6849e-01, time/batch = 16.2599s	
13330/33250 (epoch 20.045), train_loss = 1.06214162, grad/param norm = 1.6024e-01, time/batch = 17.9274s	
13331/33250 (epoch 20.047), train_loss = 0.97578274, grad/param norm = 1.6431e-01, time/batch = 15.8406s	
13332/33250 (epoch 20.048), train_loss = 1.09274696, grad/param norm = 1.9510e-01, time/batch = 15.8535s	
13333/33250 (epoch 20.050), train_loss = 0.93745325, grad/param norm = 1.4489e-01, time/batch = 15.6146s	
13334/33250 (epoch 20.051), train_loss = 0.94847628, grad/param norm = 1.5146e-01, time/batch = 15.6708s	
13335/33250 (epoch 20.053), train_loss = 0.96159292, grad/param norm = 1.8236e-01, time/batch = 15.3271s	
13336/33250 (epoch 20.054), train_loss = 0.81370810, grad/param norm = 1.4504e-01, time/batch = 14.8785s	
13337/33250 (epoch 20.056), train_loss = 0.85982967, grad/param norm = 1.4265e-01, time/batch = 15.5153s	
13338/33250 (epoch 20.057), train_loss = 1.02737922, grad/param norm = 1.4017e-01, time/batch = 16.3067s	
13339/33250 (epoch 20.059), train_loss = 0.93584145, grad/param norm = 1.5053e-01, time/batch = 17.0736s	
13340/33250 (epoch 20.060), train_loss = 0.98542485, grad/param norm = 1.6079e-01, time/batch = 17.9471s	
13341/33250 (epoch 20.062), train_loss = 1.05890622, grad/param norm = 1.5913e-01, time/batch = 16.2706s	
13342/33250 (epoch 20.063), train_loss = 1.09479327, grad/param norm = 1.5548e-01, time/batch = 15.7172s	
13343/33250 (epoch 20.065), train_loss = 0.95793773, grad/param norm = 1.4955e-01, time/batch = 14.9399s	
13344/33250 (epoch 20.066), train_loss = 1.01418158, grad/param norm = 1.5907e-01, time/batch = 15.0940s	
13345/33250 (epoch 20.068), train_loss = 0.92472155, grad/param norm = 1.6479e-01, time/batch = 15.3228s	
13346/33250 (epoch 20.069), train_loss = 0.97220870, grad/param norm = 1.5102e-01, time/batch = 15.2521s	
13347/33250 (epoch 20.071), train_loss = 0.86575926, grad/param norm = 1.3873e-01, time/batch = 14.7714s	
13348/33250 (epoch 20.072), train_loss = 0.86293589, grad/param norm = 1.3006e-01, time/batch = 15.1658s	
13349/33250 (epoch 20.074), train_loss = 1.02059007, grad/param norm = 1.5388e-01, time/batch = 16.3403s	
13350/33250 (epoch 20.075), train_loss = 0.90389048, grad/param norm = 1.5075e-01, time/batch = 15.7525s	
13351/33250 (epoch 20.077), train_loss = 0.94599070, grad/param norm = 1.9287e-01, time/batch = 14.9466s	
13352/33250 (epoch 20.078), train_loss = 0.97971151, grad/param norm = 1.4309e-01, time/batch = 15.0280s	
13353/33250 (epoch 20.080), train_loss = 0.95583329, grad/param norm = 1.6551e-01, time/batch = 15.1680s	
13354/33250 (epoch 20.081), train_loss = 0.99790889, grad/param norm = 1.4819e-01, time/batch = 15.4007s	
13355/33250 (epoch 20.083), train_loss = 1.07999400, grad/param norm = 1.5408e-01, time/batch = 14.7896s	
13356/33250 (epoch 20.084), train_loss = 0.96258768, grad/param norm = 1.5703e-01, time/batch = 14.8375s	
13357/33250 (epoch 20.086), train_loss = 0.92586321, grad/param norm = 1.3843e-01, time/batch = 15.1125s	
13358/33250 (epoch 20.087), train_loss = 0.84139859, grad/param norm = 1.4079e-01, time/batch = 15.2378s	
13359/33250 (epoch 20.089), train_loss = 0.99514653, grad/param norm = 1.4849e-01, time/batch = 16.0274s	
13360/33250 (epoch 20.090), train_loss = 0.98040137, grad/param norm = 1.5996e-01, time/batch = 15.8494s	
13361/33250 (epoch 20.092), train_loss = 0.88025766, grad/param norm = 1.3523e-01, time/batch = 16.3769s	
13362/33250 (epoch 20.093), train_loss = 0.97672317, grad/param norm = 1.5342e-01, time/batch = 16.1535s	
13363/33250 (epoch 20.095), train_loss = 0.91275057, grad/param norm = 1.5511e-01, time/batch = 15.1135s	
13364/33250 (epoch 20.096), train_loss = 0.83780395, grad/param norm = 1.6306e-01, time/batch = 15.1882s	
13365/33250 (epoch 20.098), train_loss = 0.82639106, grad/param norm = 1.6403e-01, time/batch = 15.0131s	
13366/33250 (epoch 20.099), train_loss = 0.72088993, grad/param norm = 1.3137e-01, time/batch = 15.4127s	
13367/33250 (epoch 20.101), train_loss = 0.96697514, grad/param norm = 1.5333e-01, time/batch = 14.9446s	
13368/33250 (epoch 20.102), train_loss = 0.87504192, grad/param norm = 1.3810e-01, time/batch = 15.2598s	
13369/33250 (epoch 20.104), train_loss = 0.73428075, grad/param norm = 1.3399e-01, time/batch = 15.7516s	
13370/33250 (epoch 20.105), train_loss = 0.89344066, grad/param norm = 1.4413e-01, time/batch = 15.8419s	
13371/33250 (epoch 20.107), train_loss = 0.80667086, grad/param norm = 1.3554e-01, time/batch = 17.2145s	
13372/33250 (epoch 20.108), train_loss = 0.95031269, grad/param norm = 1.6733e-01, time/batch = 15.4493s	
13373/33250 (epoch 20.110), train_loss = 0.78782888, grad/param norm = 1.3518e-01, time/batch = 15.8117s	
13374/33250 (epoch 20.111), train_loss = 0.91734353, grad/param norm = 1.4755e-01, time/batch = 15.1138s	
13375/33250 (epoch 20.113), train_loss = 0.90216635, grad/param norm = 1.4631e-01, time/batch = 15.0037s	
13376/33250 (epoch 20.114), train_loss = 0.84124018, grad/param norm = 1.5471e-01, time/batch = 15.5427s	
13377/33250 (epoch 20.116), train_loss = 0.93619610, grad/param norm = 1.6266e-01, time/batch = 15.5802s	
13378/33250 (epoch 20.117), train_loss = 0.90275455, grad/param norm = 1.6171e-01, time/batch = 15.0211s	
13379/33250 (epoch 20.119), train_loss = 0.91158465, grad/param norm = 1.5173e-01, time/batch = 15.2056s	
13380/33250 (epoch 20.120), train_loss = 0.72812400, grad/param norm = 1.2738e-01, time/batch = 15.8554s	
13381/33250 (epoch 20.122), train_loss = 1.04756954, grad/param norm = 1.6971e-01, time/batch = 15.6254s	
13382/33250 (epoch 20.123), train_loss = 0.94383484, grad/param norm = 1.6889e-01, time/batch = 15.3798s	
13383/33250 (epoch 20.125), train_loss = 0.76204348, grad/param norm = 1.4975e-01, time/batch = 16.1994s	
13384/33250 (epoch 20.126), train_loss = 0.91546911, grad/param norm = 1.5818e-01, time/batch = 15.8121s	
13385/33250 (epoch 20.128), train_loss = 0.87903025, grad/param norm = 1.4211e-01, time/batch = 14.8589s	
13386/33250 (epoch 20.129), train_loss = 0.92242974, grad/param norm = 1.5555e-01, time/batch = 14.9457s	
13387/33250 (epoch 20.131), train_loss = 0.89120764, grad/param norm = 1.4141e-01, time/batch = 14.9515s	
13388/33250 (epoch 20.132), train_loss = 0.92834656, grad/param norm = 1.5939e-01, time/batch = 15.3663s	
13389/33250 (epoch 20.134), train_loss = 0.94069533, grad/param norm = 1.7038e-01, time/batch = 28.9001s	
13390/33250 (epoch 20.135), train_loss = 0.93620226, grad/param norm = 1.4713e-01, time/batch = 15.4973s	
13391/33250 (epoch 20.137), train_loss = 0.83280742, grad/param norm = 1.6508e-01, time/batch = 15.9073s	
13392/33250 (epoch 20.138), train_loss = 0.87574555, grad/param norm = 1.3841e-01, time/batch = 15.6510s	
13393/33250 (epoch 20.140), train_loss = 0.72487660, grad/param norm = 1.6577e-01, time/batch = 15.0159s	
13394/33250 (epoch 20.141), train_loss = 1.11436955, grad/param norm = 2.1265e-01, time/batch = 14.3985s	
13395/33250 (epoch 20.143), train_loss = 0.73245195, grad/param norm = 1.4628e-01, time/batch = 14.7036s	
13396/33250 (epoch 20.144), train_loss = 0.89013756, grad/param norm = 1.5561e-01, time/batch = 15.3487s	
13397/33250 (epoch 20.146), train_loss = 0.88311204, grad/param norm = 1.4225e-01, time/batch = 14.4663s	
13398/33250 (epoch 20.147), train_loss = 0.87141373, grad/param norm = 1.4022e-01, time/batch = 14.5460s	
13399/33250 (epoch 20.149), train_loss = 0.86234301, grad/param norm = 1.3980e-01, time/batch = 14.6244s	
13400/33250 (epoch 20.150), train_loss = 0.84226129, grad/param norm = 1.4855e-01, time/batch = 15.1721s	
13401/33250 (epoch 20.152), train_loss = 0.77638461, grad/param norm = 1.3420e-01, time/batch = 15.0296s	
13402/33250 (epoch 20.153), train_loss = 1.09210916, grad/param norm = 1.7338e-01, time/batch = 14.5665s	
13403/33250 (epoch 20.155), train_loss = 0.90357268, grad/param norm = 1.5287e-01, time/batch = 14.4052s	
13404/33250 (epoch 20.156), train_loss = 1.11483568, grad/param norm = 1.5669e-01, time/batch = 15.1124s	
13405/33250 (epoch 20.158), train_loss = 1.11764520, grad/param norm = 1.6048e-01, time/batch = 14.4078s	
13406/33250 (epoch 20.159), train_loss = 0.92969975, grad/param norm = 1.5545e-01, time/batch = 14.7866s	
13407/33250 (epoch 20.161), train_loss = 0.99471647, grad/param norm = 1.6494e-01, time/batch = 14.7123s	
13408/33250 (epoch 20.162), train_loss = 0.82185928, grad/param norm = 1.2980e-01, time/batch = 15.0127s	
13409/33250 (epoch 20.164), train_loss = 0.90406085, grad/param norm = 1.7154e-01, time/batch = 14.6921s	
13410/33250 (epoch 20.165), train_loss = 0.99008967, grad/param norm = 1.5762e-01, time/batch = 14.6290s	
13411/33250 (epoch 20.167), train_loss = 1.05711380, grad/param norm = 1.5788e-01, time/batch = 14.7038s	
13412/33250 (epoch 20.168), train_loss = 0.79543170, grad/param norm = 1.1788e-01, time/batch = 15.0169s	
13413/33250 (epoch 20.170), train_loss = 0.90362333, grad/param norm = 1.5672e-01, time/batch = 14.5780s	
13414/33250 (epoch 20.171), train_loss = 0.90224906, grad/param norm = 1.4521e-01, time/batch = 15.0243s	
13415/33250 (epoch 20.173), train_loss = 0.86797784, grad/param norm = 1.5178e-01, time/batch = 14.4905s	
13416/33250 (epoch 20.174), train_loss = 0.92989068, grad/param norm = 1.5433e-01, time/batch = 15.0427s	
13417/33250 (epoch 20.176), train_loss = 0.90345418, grad/param norm = 1.5978e-01, time/batch = 14.5641s	
13418/33250 (epoch 20.177), train_loss = 0.90234762, grad/param norm = 1.4481e-01, time/batch = 14.4682s	
13419/33250 (epoch 20.179), train_loss = 0.85074270, grad/param norm = 1.3668e-01, time/batch = 14.3995s	
13420/33250 (epoch 20.180), train_loss = 0.77720760, grad/param norm = 1.3717e-01, time/batch = 15.1730s	
13421/33250 (epoch 20.182), train_loss = 0.87173701, grad/param norm = 1.5779e-01, time/batch = 14.8735s	
13422/33250 (epoch 20.183), train_loss = 1.05898848, grad/param norm = 1.6503e-01, time/batch = 14.7032s	
13423/33250 (epoch 20.185), train_loss = 0.98472402, grad/param norm = 1.6545e-01, time/batch = 14.7901s	
13424/33250 (epoch 20.186), train_loss = 0.95275690, grad/param norm = 1.5641e-01, time/batch = 15.2617s	
13425/33250 (epoch 20.188), train_loss = 1.05214612, grad/param norm = 1.7273e-01, time/batch = 14.8977s	
13426/33250 (epoch 20.189), train_loss = 0.75212275, grad/param norm = 1.5243e-01, time/batch = 15.0350s	
13427/33250 (epoch 20.191), train_loss = 0.87511194, grad/param norm = 1.7314e-01, time/batch = 14.8943s	
13428/33250 (epoch 20.192), train_loss = 0.87250491, grad/param norm = 1.4022e-01, time/batch = 15.3507s	
13429/33250 (epoch 20.194), train_loss = 0.88718378, grad/param norm = 1.4553e-01, time/batch = 15.2620s	
13430/33250 (epoch 20.195), train_loss = 1.10990210, grad/param norm = 1.4865e-01, time/batch = 15.6106s	
13431/33250 (epoch 20.197), train_loss = 0.87545498, grad/param norm = 1.3596e-01, time/batch = 14.8451s	
13432/33250 (epoch 20.198), train_loss = 1.03480022, grad/param norm = 1.6039e-01, time/batch = 15.2613s	
13433/33250 (epoch 20.200), train_loss = 0.93955501, grad/param norm = 1.4520e-01, time/batch = 14.9557s	
13434/33250 (epoch 20.202), train_loss = 0.87353196, grad/param norm = 1.3285e-01, time/batch = 15.1090s	
13435/33250 (epoch 20.203), train_loss = 0.85555957, grad/param norm = 1.5448e-01, time/batch = 15.5060s	
13436/33250 (epoch 20.205), train_loss = 0.96086856, grad/param norm = 1.4457e-01, time/batch = 15.3602s	
13437/33250 (epoch 20.206), train_loss = 1.01372401, grad/param norm = 1.5156e-01, time/batch = 14.8938s	
13438/33250 (epoch 20.208), train_loss = 1.05863777, grad/param norm = 1.6866e-01, time/batch = 14.9410s	
13439/33250 (epoch 20.209), train_loss = 0.84445076, grad/param norm = 1.4484e-01, time/batch = 15.0420s	
13440/33250 (epoch 20.211), train_loss = 1.01118863, grad/param norm = 1.5748e-01, time/batch = 15.0968s	
13441/33250 (epoch 20.212), train_loss = 1.14732487, grad/param norm = 1.5710e-01, time/batch = 14.9525s	
13442/33250 (epoch 20.214), train_loss = 0.91942731, grad/param norm = 1.4126e-01, time/batch = 14.7016s	
13443/33250 (epoch 20.215), train_loss = 1.10716295, grad/param norm = 2.0035e-01, time/batch = 14.6271s	
13444/33250 (epoch 20.217), train_loss = 1.05876548, grad/param norm = 1.6288e-01, time/batch = 15.3358s	
13445/33250 (epoch 20.218), train_loss = 1.02763240, grad/param norm = 1.4194e-01, time/batch = 14.5250s	
13446/33250 (epoch 20.220), train_loss = 0.96877024, grad/param norm = 1.5643e-01, time/batch = 14.6329s	
13447/33250 (epoch 20.221), train_loss = 1.12426632, grad/param norm = 1.8155e-01, time/batch = 14.4756s	
13448/33250 (epoch 20.223), train_loss = 0.93663164, grad/param norm = 1.4537e-01, time/batch = 15.4372s	
13449/33250 (epoch 20.224), train_loss = 0.97014353, grad/param norm = 1.5831e-01, time/batch = 14.9594s	
13450/33250 (epoch 20.226), train_loss = 1.10192792, grad/param norm = 1.6051e-01, time/batch = 14.8527s	
13451/33250 (epoch 20.227), train_loss = 0.98902058, grad/param norm = 1.6835e-01, time/batch = 14.8667s	
13452/33250 (epoch 20.229), train_loss = 0.97947702, grad/param norm = 1.4433e-01, time/batch = 15.4712s	
13453/33250 (epoch 20.230), train_loss = 0.94660960, grad/param norm = 1.5283e-01, time/batch = 15.5647s	
13454/33250 (epoch 20.232), train_loss = 0.88427186, grad/param norm = 1.3184e-01, time/batch = 15.2589s	
13455/33250 (epoch 20.233), train_loss = 0.87207869, grad/param norm = 1.4492e-01, time/batch = 15.1072s	
13456/33250 (epoch 20.235), train_loss = 1.09938998, grad/param norm = 1.5470e-01, time/batch = 15.3573s	
13457/33250 (epoch 20.236), train_loss = 0.88247627, grad/param norm = 1.5358e-01, time/batch = 15.4190s	
13458/33250 (epoch 20.238), train_loss = 1.05471233, grad/param norm = 1.6748e-01, time/batch = 14.8046s	
13459/33250 (epoch 20.239), train_loss = 1.08593981, grad/param norm = 1.7156e-01, time/batch = 15.4839s	
13460/33250 (epoch 20.241), train_loss = 1.03402854, grad/param norm = 1.8239e-01, time/batch = 15.3475s	
13461/33250 (epoch 20.242), train_loss = 1.03434881, grad/param norm = 1.6418e-01, time/batch = 15.4258s	
13462/33250 (epoch 20.244), train_loss = 1.03454629, grad/param norm = 1.9461e-01, time/batch = 14.8630s	
13463/33250 (epoch 20.245), train_loss = 0.98102329, grad/param norm = 1.5325e-01, time/batch = 14.7083s	
13464/33250 (epoch 20.247), train_loss = 0.96632574, grad/param norm = 1.4766e-01, time/batch = 14.9448s	
13465/33250 (epoch 20.248), train_loss = 1.14056074, grad/param norm = 1.6836e-01, time/batch = 14.7186s	
13466/33250 (epoch 20.250), train_loss = 1.03385376, grad/param norm = 1.4399e-01, time/batch = 14.6264s	
13467/33250 (epoch 20.251), train_loss = 0.94748683, grad/param norm = 1.4580e-01, time/batch = 14.7677s	
13468/33250 (epoch 20.253), train_loss = 0.88832925, grad/param norm = 1.3411e-01, time/batch = 14.8733s	
13469/33250 (epoch 20.254), train_loss = 0.89746514, grad/param norm = 1.4898e-01, time/batch = 14.4977s	
13470/33250 (epoch 20.256), train_loss = 0.95381783, grad/param norm = 1.4532e-01, time/batch = 14.6621s	
13471/33250 (epoch 20.257), train_loss = 1.09097726, grad/param norm = 1.6830e-01, time/batch = 15.4192s	
13472/33250 (epoch 20.259), train_loss = 1.01531404, grad/param norm = 1.6566e-01, time/batch = 15.0242s	
13473/33250 (epoch 20.260), train_loss = 0.82632211, grad/param norm = 1.4522e-01, time/batch = 15.3403s	
13474/33250 (epoch 20.262), train_loss = 0.96442652, grad/param norm = 1.4492e-01, time/batch = 14.9306s	
13475/33250 (epoch 20.263), train_loss = 0.86949298, grad/param norm = 1.5935e-01, time/batch = 15.3488s	
13476/33250 (epoch 20.265), train_loss = 1.02200160, grad/param norm = 1.6033e-01, time/batch = 14.8584s	
13477/33250 (epoch 20.266), train_loss = 0.93627446, grad/param norm = 1.6038e-01, time/batch = 14.7190s	
13478/33250 (epoch 20.268), train_loss = 0.86388345, grad/param norm = 1.5429e-01, time/batch = 14.9643s	
13479/33250 (epoch 20.269), train_loss = 0.78301209, grad/param norm = 1.5753e-01, time/batch = 14.8885s	
13480/33250 (epoch 20.271), train_loss = 0.95598491, grad/param norm = 1.4866e-01, time/batch = 14.9893s	
13481/33250 (epoch 20.272), train_loss = 0.84722946, grad/param norm = 1.3006e-01, time/batch = 15.1035s	
13482/33250 (epoch 20.274), train_loss = 0.72478924, grad/param norm = 1.3213e-01, time/batch = 15.0592s	
13483/33250 (epoch 20.275), train_loss = 0.87286703, grad/param norm = 1.4078e-01, time/batch = 14.9621s	
13484/33250 (epoch 20.277), train_loss = 0.75447992, grad/param norm = 1.4166e-01, time/batch = 15.0374s	
13485/33250 (epoch 20.278), train_loss = 0.88540687, grad/param norm = 1.5509e-01, time/batch = 14.2251s	
13486/33250 (epoch 20.280), train_loss = 0.84040847, grad/param norm = 1.3083e-01, time/batch = 14.4762s	
13487/33250 (epoch 20.281), train_loss = 0.96385430, grad/param norm = 1.4312e-01, time/batch = 14.4444s	
13488/33250 (epoch 20.283), train_loss = 0.99097818, grad/param norm = 2.3740e-01, time/batch = 14.6882s	
13489/33250 (epoch 20.284), train_loss = 0.86922188, grad/param norm = 1.7341e-01, time/batch = 14.4687s	
13490/33250 (epoch 20.286), train_loss = 0.99328846, grad/param norm = 1.5114e-01, time/batch = 14.7932s	
13491/33250 (epoch 20.287), train_loss = 0.81237450, grad/param norm = 1.3816e-01, time/batch = 14.5582s	
13492/33250 (epoch 20.289), train_loss = 0.76916744, grad/param norm = 1.6141e-01, time/batch = 14.8441s	
13493/33250 (epoch 20.290), train_loss = 0.93228157, grad/param norm = 1.4516e-01, time/batch = 15.1596s	
13494/33250 (epoch 20.292), train_loss = 1.01203062, grad/param norm = 2.0238e-01, time/batch = 15.5049s	
13495/33250 (epoch 20.293), train_loss = 1.04825433, grad/param norm = 1.8504e-01, time/batch = 15.2608s	
13496/33250 (epoch 20.295), train_loss = 1.00765327, grad/param norm = 1.6246e-01, time/batch = 15.3544s	
13497/33250 (epoch 20.296), train_loss = 0.97604675, grad/param norm = 2.1576e-01, time/batch = 14.7115s	
13498/33250 (epoch 20.298), train_loss = 0.80006931, grad/param norm = 1.3702e-01, time/batch = 14.5426s	
13499/33250 (epoch 20.299), train_loss = 0.76348188, grad/param norm = 1.3822e-01, time/batch = 14.6985s	
13500/33250 (epoch 20.301), train_loss = 1.00526648, grad/param norm = 1.5070e-01, time/batch = 15.7316s	
13501/33250 (epoch 20.302), train_loss = 1.00636940, grad/param norm = 1.5318e-01, time/batch = 15.8175s	
13502/33250 (epoch 20.304), train_loss = 0.86444846, grad/param norm = 1.4925e-01, time/batch = 15.6760s	
13503/33250 (epoch 20.305), train_loss = 0.91337451, grad/param norm = 1.5238e-01, time/batch = 15.7731s	
13504/33250 (epoch 20.307), train_loss = 0.99495508, grad/param norm = 1.5441e-01, time/batch = 16.0378s	
13505/33250 (epoch 20.308), train_loss = 1.10266522, grad/param norm = 1.7960e-01, time/batch = 16.1194s	
13506/33250 (epoch 20.310), train_loss = 0.92108459, grad/param norm = 1.6055e-01, time/batch = 15.8402s	
13507/33250 (epoch 20.311), train_loss = 1.07166083, grad/param norm = 1.6963e-01, time/batch = 15.7287s	
13508/33250 (epoch 20.313), train_loss = 0.81485610, grad/param norm = 1.4319e-01, time/batch = 15.5083s	
13509/33250 (epoch 20.314), train_loss = 0.94963751, grad/param norm = 1.4978e-01, time/batch = 15.2857s	
13510/33250 (epoch 20.316), train_loss = 1.09613593, grad/param norm = 1.5956e-01, time/batch = 15.9078s	
13511/33250 (epoch 20.317), train_loss = 0.82330122, grad/param norm = 1.2843e-01, time/batch = 16.1223s	
13512/33250 (epoch 20.319), train_loss = 1.02592942, grad/param norm = 1.9090e-01, time/batch = 16.0698s	
13513/33250 (epoch 20.320), train_loss = 1.03722813, grad/param norm = 1.9110e-01, time/batch = 15.8958s	
13514/33250 (epoch 20.322), train_loss = 1.10775626, grad/param norm = 2.0267e-01, time/batch = 15.7617s	
13515/33250 (epoch 20.323), train_loss = 1.16364848, grad/param norm = 2.0933e-01, time/batch = 16.0770s	
13516/33250 (epoch 20.325), train_loss = 0.96329093, grad/param norm = 1.7210e-01, time/batch = 15.3053s	
13517/33250 (epoch 20.326), train_loss = 1.10122968, grad/param norm = 1.7231e-01, time/batch = 15.3622s	
13518/33250 (epoch 20.328), train_loss = 0.91616331, grad/param norm = 1.3939e-01, time/batch = 15.4371s	
13519/33250 (epoch 20.329), train_loss = 0.94083833, grad/param norm = 1.6397e-01, time/batch = 15.6590s	
13520/33250 (epoch 20.331), train_loss = 0.90288817, grad/param norm = 1.6200e-01, time/batch = 15.5254s	
13521/33250 (epoch 20.332), train_loss = 0.90626871, grad/param norm = 1.4084e-01, time/batch = 15.5985s	
13522/33250 (epoch 20.334), train_loss = 1.11644289, grad/param norm = 1.6440e-01, time/batch = 15.7377s	
13523/33250 (epoch 20.335), train_loss = 0.70496555, grad/param norm = 1.3622e-01, time/batch = 15.7525s	
13524/33250 (epoch 20.337), train_loss = 1.00435539, grad/param norm = 1.5129e-01, time/batch = 15.7597s	
13525/33250 (epoch 20.338), train_loss = 1.06189099, grad/param norm = 1.4966e-01, time/batch = 15.7014s	
13526/33250 (epoch 20.340), train_loss = 0.96027532, grad/param norm = 1.5240e-01, time/batch = 16.1448s	
13527/33250 (epoch 20.341), train_loss = 0.89505712, grad/param norm = 1.5695e-01, time/batch = 15.5955s	
13528/33250 (epoch 20.343), train_loss = 0.89350950, grad/param norm = 1.5683e-01, time/batch = 16.1175s	
13529/33250 (epoch 20.344), train_loss = 0.92487883, grad/param norm = 1.3205e-01, time/batch = 15.3444s	
13530/33250 (epoch 20.346), train_loss = 0.82884385, grad/param norm = 1.3754e-01, time/batch = 15.8087s	
13531/33250 (epoch 20.347), train_loss = 1.17583963, grad/param norm = 1.6946e-01, time/batch = 15.4295s	
13532/33250 (epoch 20.349), train_loss = 0.88298399, grad/param norm = 1.4862e-01, time/batch = 15.4496s	
13533/33250 (epoch 20.350), train_loss = 0.91634934, grad/param norm = 1.6165e-01, time/batch = 15.4411s	
13534/33250 (epoch 20.352), train_loss = 0.80765223, grad/param norm = 1.5596e-01, time/batch = 15.7548s	
13535/33250 (epoch 20.353), train_loss = 0.90613355, grad/param norm = 1.4285e-01, time/batch = 15.3675s	
13536/33250 (epoch 20.355), train_loss = 0.91424441, grad/param norm = 1.5903e-01, time/batch = 15.2244s	
13537/33250 (epoch 20.356), train_loss = 0.84081858, grad/param norm = 1.4725e-01, time/batch = 15.2898s	
13538/33250 (epoch 20.358), train_loss = 0.92593655, grad/param norm = 1.5422e-01, time/batch = 15.6003s	
13539/33250 (epoch 20.359), train_loss = 0.90334756, grad/param norm = 1.5435e-01, time/batch = 15.2906s	
13540/33250 (epoch 20.361), train_loss = 1.08987438, grad/param norm = 1.7697e-01, time/batch = 15.6571s	
13541/33250 (epoch 20.362), train_loss = 0.95141583, grad/param norm = 1.5022e-01, time/batch = 15.5131s	
13542/33250 (epoch 20.364), train_loss = 1.03104117, grad/param norm = 1.7559e-01, time/batch = 15.6015s	
13543/33250 (epoch 20.365), train_loss = 0.93690128, grad/param norm = 1.4728e-01, time/batch = 15.3746s	
13544/33250 (epoch 20.367), train_loss = 0.94090656, grad/param norm = 1.3120e-01, time/batch = 15.5210s	
13545/33250 (epoch 20.368), train_loss = 0.92403607, grad/param norm = 1.7942e-01, time/batch = 15.1946s	
13546/33250 (epoch 20.370), train_loss = 0.82234300, grad/param norm = 1.3455e-01, time/batch = 15.5090s	
13547/33250 (epoch 20.371), train_loss = 1.06892883, grad/param norm = 1.5067e-01, time/batch = 15.2797s	
13548/33250 (epoch 20.373), train_loss = 0.89311622, grad/param norm = 1.2810e-01, time/batch = 15.2813s	
13549/33250 (epoch 20.374), train_loss = 1.03664020, grad/param norm = 2.1643e-01, time/batch = 15.4990s	
13550/33250 (epoch 20.376), train_loss = 0.89710026, grad/param norm = 1.5084e-01, time/batch = 15.3011s	
13551/33250 (epoch 20.377), train_loss = 0.85222402, grad/param norm = 2.1148e-01, time/batch = 15.3826s	
13552/33250 (epoch 20.379), train_loss = 0.87785368, grad/param norm = 1.6419e-01, time/batch = 15.6783s	
13553/33250 (epoch 20.380), train_loss = 0.97472401, grad/param norm = 1.8624e-01, time/batch = 15.7679s	
13554/33250 (epoch 20.382), train_loss = 1.00563998, grad/param norm = 1.6097e-01, time/batch = 15.4425s	
13555/33250 (epoch 20.383), train_loss = 0.84701755, grad/param norm = 1.6952e-01, time/batch = 15.3629s	
13556/33250 (epoch 20.385), train_loss = 0.80342632, grad/param norm = 1.5750e-01, time/batch = 15.5056s	
13557/33250 (epoch 20.386), train_loss = 0.83486798, grad/param norm = 1.6802e-01, time/batch = 15.7928s	
13558/33250 (epoch 20.388), train_loss = 0.84502276, grad/param norm = 1.5014e-01, time/batch = 15.9085s	
13559/33250 (epoch 20.389), train_loss = 0.90028608, grad/param norm = 1.7975e-01, time/batch = 15.8621s	
13560/33250 (epoch 20.391), train_loss = 0.94740630, grad/param norm = 1.4060e-01, time/batch = 15.8217s	
13561/33250 (epoch 20.392), train_loss = 1.02745577, grad/param norm = 1.7732e-01, time/batch = 16.0792s	
13562/33250 (epoch 20.394), train_loss = 1.08607803, grad/param norm = 1.8340e-01, time/batch = 15.5349s	
13563/33250 (epoch 20.395), train_loss = 1.03950635, grad/param norm = 1.5167e-01, time/batch = 15.6566s	
13564/33250 (epoch 20.397), train_loss = 1.05077976, grad/param norm = 1.5306e-01, time/batch = 15.7070s	
13565/33250 (epoch 20.398), train_loss = 0.88820076, grad/param norm = 1.4252e-01, time/batch = 15.8524s	
13566/33250 (epoch 20.400), train_loss = 0.83313880, grad/param norm = 1.3403e-01, time/batch = 15.7665s	
13567/33250 (epoch 20.402), train_loss = 0.78955210, grad/param norm = 1.4579e-01, time/batch = 15.7759s	
13568/33250 (epoch 20.403), train_loss = 0.88896044, grad/param norm = 1.7753e-01, time/batch = 15.8416s	
13569/33250 (epoch 20.405), train_loss = 0.86818253, grad/param norm = 1.4308e-01, time/batch = 15.9257s	
13570/33250 (epoch 20.406), train_loss = 0.94125218, grad/param norm = 1.5987e-01, time/batch = 15.5062s	
13571/33250 (epoch 20.408), train_loss = 1.08908158, grad/param norm = 1.6881e-01, time/batch = 15.5375s	
13572/33250 (epoch 20.409), train_loss = 1.00809152, grad/param norm = 1.9590e-01, time/batch = 15.7519s	
13573/33250 (epoch 20.411), train_loss = 0.69633774, grad/param norm = 1.2157e-01, time/batch = 15.5903s	
13574/33250 (epoch 20.412), train_loss = 0.80705695, grad/param norm = 1.6118e-01, time/batch = 15.5124s	
13575/33250 (epoch 20.414), train_loss = 0.96794952, grad/param norm = 1.4530e-01, time/batch = 15.2810s	
13576/33250 (epoch 20.415), train_loss = 1.03892311, grad/param norm = 1.6656e-01, time/batch = 15.4339s	
13577/33250 (epoch 20.417), train_loss = 1.01719592, grad/param norm = 1.5652e-01, time/batch = 15.1123s	
13578/33250 (epoch 20.418), train_loss = 1.17964703, grad/param norm = 2.0384e-01, time/batch = 15.1996s	
13579/33250 (epoch 20.420), train_loss = 1.06912461, grad/param norm = 1.6955e-01, time/batch = 15.1933s	
13580/33250 (epoch 20.421), train_loss = 0.87447445, grad/param norm = 1.4240e-01, time/batch = 15.6648s	
13581/33250 (epoch 20.423), train_loss = 1.02406995, grad/param norm = 1.9670e-01, time/batch = 15.6886s	
13582/33250 (epoch 20.424), train_loss = 1.13741648, grad/param norm = 2.8245e-01, time/batch = 15.3692s	
13583/33250 (epoch 20.426), train_loss = 0.86953136, grad/param norm = 1.3896e-01, time/batch = 15.3022s	
13584/33250 (epoch 20.427), train_loss = 0.87777394, grad/param norm = 1.5419e-01, time/batch = 15.6816s	
13585/33250 (epoch 20.429), train_loss = 1.01614449, grad/param norm = 1.7933e-01, time/batch = 15.2987s	
13586/33250 (epoch 20.430), train_loss = 0.87979205, grad/param norm = 1.5919e-01, time/batch = 15.5344s	
13587/33250 (epoch 20.432), train_loss = 0.99446585, grad/param norm = 1.4021e-01, time/batch = 15.4845s	
13588/33250 (epoch 20.433), train_loss = 0.87561041, grad/param norm = 1.5567e-01, time/batch = 15.8323s	
13589/33250 (epoch 20.435), train_loss = 1.01727222, grad/param norm = 1.7202e-01, time/batch = 17.2784s	
13590/33250 (epoch 20.436), train_loss = 0.87502980, grad/param norm = 1.6370e-01, time/batch = 15.6790s	
13591/33250 (epoch 20.438), train_loss = 1.03867556, grad/param norm = 1.5835e-01, time/batch = 15.9708s	
13592/33250 (epoch 20.439), train_loss = 0.96465027, grad/param norm = 1.4883e-01, time/batch = 17.7515s	
13593/33250 (epoch 20.441), train_loss = 0.91814214, grad/param norm = 1.3054e-01, time/batch = 17.4335s	
13594/33250 (epoch 20.442), train_loss = 0.86097972, grad/param norm = 1.5869e-01, time/batch = 18.1121s	
13595/33250 (epoch 20.444), train_loss = 0.87346938, grad/param norm = 1.3978e-01, time/batch = 16.9627s	
13596/33250 (epoch 20.445), train_loss = 0.94088963, grad/param norm = 1.4817e-01, time/batch = 16.9310s	
13597/33250 (epoch 20.447), train_loss = 0.96279957, grad/param norm = 1.6059e-01, time/batch = 15.9997s	
13598/33250 (epoch 20.448), train_loss = 0.94772952, grad/param norm = 1.3946e-01, time/batch = 15.6959s	
13599/33250 (epoch 20.450), train_loss = 1.12099769, grad/param norm = 1.6784e-01, time/batch = 15.4261s	
13600/33250 (epoch 20.451), train_loss = 0.99745420, grad/param norm = 1.5757e-01, time/batch = 17.0783s	
13601/33250 (epoch 20.453), train_loss = 0.84919956, grad/param norm = 1.3101e-01, time/batch = 17.1942s	
13602/33250 (epoch 20.454), train_loss = 1.08841900, grad/param norm = 1.5970e-01, time/batch = 15.2505s	
13603/33250 (epoch 20.456), train_loss = 1.08592309, grad/param norm = 1.5165e-01, time/batch = 17.3567s	
13604/33250 (epoch 20.457), train_loss = 0.88889137, grad/param norm = 1.5034e-01, time/batch = 17.7056s	
13605/33250 (epoch 20.459), train_loss = 0.98204666, grad/param norm = 1.4853e-01, time/batch = 15.2623s	
13606/33250 (epoch 20.460), train_loss = 1.03670293, grad/param norm = 1.6197e-01, time/batch = 16.0519s	
13607/33250 (epoch 20.462), train_loss = 0.87110047, grad/param norm = 1.5329e-01, time/batch = 17.1254s	
13608/33250 (epoch 20.463), train_loss = 0.86641543, grad/param norm = 1.2695e-01, time/batch = 15.2722s	
13609/33250 (epoch 20.465), train_loss = 0.79378360, grad/param norm = 1.2854e-01, time/batch = 16.2643s	
13610/33250 (epoch 20.466), train_loss = 0.74160564, grad/param norm = 1.0675e-01, time/batch = 16.7711s	
13611/33250 (epoch 20.468), train_loss = 0.83633096, grad/param norm = 1.2620e-01, time/batch = 17.1090s	
13612/33250 (epoch 20.469), train_loss = 0.92247585, grad/param norm = 1.6277e-01, time/batch = 17.0116s	
13613/33250 (epoch 20.471), train_loss = 1.01345839, grad/param norm = 1.3980e-01, time/batch = 16.1866s	
13614/33250 (epoch 20.472), train_loss = 0.92301899, grad/param norm = 1.8088e-01, time/batch = 17.2057s	
13615/33250 (epoch 20.474), train_loss = 1.05598641, grad/param norm = 1.6893e-01, time/batch = 17.1137s	
13616/33250 (epoch 20.475), train_loss = 0.97191574, grad/param norm = 1.4908e-01, time/batch = 16.3863s	
13617/33250 (epoch 20.477), train_loss = 0.94972145, grad/param norm = 1.4017e-01, time/batch = 15.8097s	
13618/33250 (epoch 20.478), train_loss = 0.87000607, grad/param norm = 1.5084e-01, time/batch = 16.0218s	
13619/33250 (epoch 20.480), train_loss = 1.11978723, grad/param norm = 1.6753e-01, time/batch = 15.3971s	
13620/33250 (epoch 20.481), train_loss = 0.96836596, grad/param norm = 1.5171e-01, time/batch = 25.8153s	
13621/33250 (epoch 20.483), train_loss = 0.96691401, grad/param norm = 1.5872e-01, time/batch = 17.4740s	
13622/33250 (epoch 20.484), train_loss = 0.86188890, grad/param norm = 1.4309e-01, time/batch = 15.4528s	
13623/33250 (epoch 20.486), train_loss = 0.79701480, grad/param norm = 1.4215e-01, time/batch = 15.2415s	
13624/33250 (epoch 20.487), train_loss = 0.88555070, grad/param norm = 1.4272e-01, time/batch = 16.8709s	
13625/33250 (epoch 20.489), train_loss = 1.07096731, grad/param norm = 2.2314e-01, time/batch = 18.3828s	
13626/33250 (epoch 20.490), train_loss = 0.97437241, grad/param norm = 1.6266e-01, time/batch = 16.2886s	
13627/33250 (epoch 20.492), train_loss = 1.00161318, grad/param norm = 1.7060e-01, time/batch = 15.2132s	
13628/33250 (epoch 20.493), train_loss = 0.95214805, grad/param norm = 1.7136e-01, time/batch = 16.2072s	
13629/33250 (epoch 20.495), train_loss = 0.97633974, grad/param norm = 1.4127e-01, time/batch = 15.3647s	
13630/33250 (epoch 20.496), train_loss = 0.94726386, grad/param norm = 1.3642e-01, time/batch = 14.7940s	
13631/33250 (epoch 20.498), train_loss = 1.03681689, grad/param norm = 1.5949e-01, time/batch = 15.3686s	
13632/33250 (epoch 20.499), train_loss = 0.89621559, grad/param norm = 1.4431e-01, time/batch = 16.7719s	
13633/33250 (epoch 20.501), train_loss = 0.87168019, grad/param norm = 1.4466e-01, time/batch = 17.0131s	
13634/33250 (epoch 20.502), train_loss = 0.89428542, grad/param norm = 1.3743e-01, time/batch = 16.2794s	
13635/33250 (epoch 20.504), train_loss = 1.07486710, grad/param norm = 1.7557e-01, time/batch = 16.6345s	
13636/33250 (epoch 20.505), train_loss = 0.77211023, grad/param norm = 1.2337e-01, time/batch = 18.0542s	
13637/33250 (epoch 20.507), train_loss = 0.86787143, grad/param norm = 1.5050e-01, time/batch = 17.8420s	
13638/33250 (epoch 20.508), train_loss = 0.89554508, grad/param norm = 1.5227e-01, time/batch = 16.6852s	
13639/33250 (epoch 20.510), train_loss = 0.78657226, grad/param norm = 1.4429e-01, time/batch = 17.3520s	
13640/33250 (epoch 20.511), train_loss = 0.93758713, grad/param norm = 1.5826e-01, time/batch = 16.0843s	
13641/33250 (epoch 20.513), train_loss = 1.07438264, grad/param norm = 1.6288e-01, time/batch = 15.3453s	
13642/33250 (epoch 20.514), train_loss = 0.89496245, grad/param norm = 1.3748e-01, time/batch = 15.7768s	
13643/33250 (epoch 20.516), train_loss = 0.86335896, grad/param norm = 1.4893e-01, time/batch = 17.8435s	
13644/33250 (epoch 20.517), train_loss = 0.92352049, grad/param norm = 1.7205e-01, time/batch = 17.6201s	
13645/33250 (epoch 20.519), train_loss = 0.82339229, grad/param norm = 1.1607e-01, time/batch = 17.2808s	
13646/33250 (epoch 20.520), train_loss = 1.17628249, grad/param norm = 1.8931e-01, time/batch = 18.2432s	
13647/33250 (epoch 20.522), train_loss = 1.01003051, grad/param norm = 1.5910e-01, time/batch = 16.5971s	
13648/33250 (epoch 20.523), train_loss = 0.85587221, grad/param norm = 1.4513e-01, time/batch = 15.0253s	
13649/33250 (epoch 20.525), train_loss = 0.81859194, grad/param norm = 1.6473e-01, time/batch = 15.4568s	
13650/33250 (epoch 20.526), train_loss = 0.80602058, grad/param norm = 1.4036e-01, time/batch = 15.2594s	
13651/33250 (epoch 20.528), train_loss = 0.90457925, grad/param norm = 1.5249e-01, time/batch = 15.6851s	
13652/33250 (epoch 20.529), train_loss = 0.85671348, grad/param norm = 1.5649e-01, time/batch = 15.4114s	
13653/33250 (epoch 20.531), train_loss = 0.81893531, grad/param norm = 1.3131e-01, time/batch = 16.2826s	
13654/33250 (epoch 20.532), train_loss = 0.97491802, grad/param norm = 1.4060e-01, time/batch = 16.2870s	
13655/33250 (epoch 20.534), train_loss = 0.84352329, grad/param norm = 1.3480e-01, time/batch = 15.1847s	
13656/33250 (epoch 20.535), train_loss = 0.92149646, grad/param norm = 1.3993e-01, time/batch = 15.7251s	
13657/33250 (epoch 20.537), train_loss = 0.98166875, grad/param norm = 1.4196e-01, time/batch = 16.2550s	
13658/33250 (epoch 20.538), train_loss = 0.99715897, grad/param norm = 1.5242e-01, time/batch = 15.6666s	
13659/33250 (epoch 20.540), train_loss = 1.07472178, grad/param norm = 1.3773e-01, time/batch = 14.9407s	
13660/33250 (epoch 20.541), train_loss = 1.02935548, grad/param norm = 1.6641e-01, time/batch = 14.8441s	
13661/33250 (epoch 20.543), train_loss = 0.99149768, grad/param norm = 1.4475e-01, time/batch = 14.9302s	
13662/33250 (epoch 20.544), train_loss = 0.87914325, grad/param norm = 1.6097e-01, time/batch = 16.1875s	
13663/33250 (epoch 20.546), train_loss = 0.93138500, grad/param norm = 1.7124e-01, time/batch = 16.7646s	
13664/33250 (epoch 20.547), train_loss = 0.91326981, grad/param norm = 1.6304e-01, time/batch = 18.1897s	
13665/33250 (epoch 20.549), train_loss = 1.00524293, grad/param norm = 1.6368e-01, time/batch = 17.2071s	
13666/33250 (epoch 20.550), train_loss = 0.90599286, grad/param norm = 1.5402e-01, time/batch = 20.0100s	
13667/33250 (epoch 20.552), train_loss = 0.97178746, grad/param norm = 1.5045e-01, time/batch = 15.6111s	
13668/33250 (epoch 20.553), train_loss = 0.87241864, grad/param norm = 1.4864e-01, time/batch = 14.9422s	
13669/33250 (epoch 20.555), train_loss = 0.97772597, grad/param norm = 1.5063e-01, time/batch = 16.8535s	
13670/33250 (epoch 20.556), train_loss = 1.01385071, grad/param norm = 1.7393e-01, time/batch = 15.3314s	
13671/33250 (epoch 20.558), train_loss = 1.04123679, grad/param norm = 1.6750e-01, time/batch = 16.3505s	
13672/33250 (epoch 20.559), train_loss = 0.84892866, grad/param norm = 1.3632e-01, time/batch = 17.0851s	
13673/33250 (epoch 20.561), train_loss = 0.83467349, grad/param norm = 1.3958e-01, time/batch = 16.1853s	
13674/33250 (epoch 20.562), train_loss = 1.03714961, grad/param norm = 1.5505e-01, time/batch = 16.7558s	
13675/33250 (epoch 20.564), train_loss = 1.14070179, grad/param norm = 1.8056e-01, time/batch = 16.7887s	
13676/33250 (epoch 20.565), train_loss = 1.06914907, grad/param norm = 1.8107e-01, time/batch = 17.1348s	
13677/33250 (epoch 20.567), train_loss = 1.07581126, grad/param norm = 1.6324e-01, time/batch = 16.6254s	
13678/33250 (epoch 20.568), train_loss = 0.94784965, grad/param norm = 1.5378e-01, time/batch = 15.3596s	
13679/33250 (epoch 20.570), train_loss = 1.05856496, grad/param norm = 1.6952e-01, time/batch = 15.6233s	
13680/33250 (epoch 20.571), train_loss = 1.08583896, grad/param norm = 1.6130e-01, time/batch = 17.2749s	
13681/33250 (epoch 20.573), train_loss = 0.99224542, grad/param norm = 1.5969e-01, time/batch = 15.3650s	
13682/33250 (epoch 20.574), train_loss = 0.84967975, grad/param norm = 1.3808e-01, time/batch = 15.3711s	
13683/33250 (epoch 20.576), train_loss = 0.99031339, grad/param norm = 1.6113e-01, time/batch = 15.6694s	
13684/33250 (epoch 20.577), train_loss = 0.92384977, grad/param norm = 1.4328e-01, time/batch = 15.6242s	
13685/33250 (epoch 20.579), train_loss = 0.86626529, grad/param norm = 1.5094e-01, time/batch = 15.5369s	
13686/33250 (epoch 20.580), train_loss = 0.90051602, grad/param norm = 1.2350e-01, time/batch = 14.9595s	
13687/33250 (epoch 20.582), train_loss = 0.92391112, grad/param norm = 1.4667e-01, time/batch = 14.7888s	
13688/33250 (epoch 20.583), train_loss = 1.03073465, grad/param norm = 1.5410e-01, time/batch = 14.7993s	
13689/33250 (epoch 20.585), train_loss = 1.01725662, grad/param norm = 1.4698e-01, time/batch = 15.5440s	
13690/33250 (epoch 20.586), train_loss = 0.88447485, grad/param norm = 1.8338e-01, time/batch = 14.9346s	
13691/33250 (epoch 20.588), train_loss = 0.97668425, grad/param norm = 1.4881e-01, time/batch = 16.6832s	
13692/33250 (epoch 20.589), train_loss = 0.97406374, grad/param norm = 1.5269e-01, time/batch = 15.9503s	
13693/33250 (epoch 20.591), train_loss = 0.96202585, grad/param norm = 1.6341e-01, time/batch = 15.2706s	
13694/33250 (epoch 20.592), train_loss = 0.94813188, grad/param norm = 1.5136e-01, time/batch = 15.5359s	
13695/33250 (epoch 20.594), train_loss = 1.07159000, grad/param norm = 1.7124e-01, time/batch = 15.6849s	
13696/33250 (epoch 20.595), train_loss = 0.98306050, grad/param norm = 1.5737e-01, time/batch = 17.4410s	
13697/33250 (epoch 20.597), train_loss = 0.79665281, grad/param norm = 1.3396e-01, time/batch = 15.7607s	
13698/33250 (epoch 20.598), train_loss = 0.91951945, grad/param norm = 1.5433e-01, time/batch = 18.2029s	
13699/33250 (epoch 20.600), train_loss = 0.93057540, grad/param norm = 1.5933e-01, time/batch = 14.6228s	
13700/33250 (epoch 20.602), train_loss = 0.96731764, grad/param norm = 1.8073e-01, time/batch = 16.1123s	
13701/33250 (epoch 20.603), train_loss = 0.96829877, grad/param norm = 1.5921e-01, time/batch = 15.2812s	
13702/33250 (epoch 20.605), train_loss = 0.95522781, grad/param norm = 1.4687e-01, time/batch = 16.1965s	
13703/33250 (epoch 20.606), train_loss = 1.00465476, grad/param norm = 1.5834e-01, time/batch = 16.5262s	
13704/33250 (epoch 20.608), train_loss = 0.95813773, grad/param norm = 1.4827e-01, time/batch = 15.5264s	
13705/33250 (epoch 20.609), train_loss = 0.87172307, grad/param norm = 1.4585e-01, time/batch = 16.8672s	
13706/33250 (epoch 20.611), train_loss = 0.98897142, grad/param norm = 1.6516e-01, time/batch = 17.1095s	
13707/33250 (epoch 20.612), train_loss = 0.94550441, grad/param norm = 1.5616e-01, time/batch = 16.8817s	
13708/33250 (epoch 20.614), train_loss = 1.16712205, grad/param norm = 1.9280e-01, time/batch = 16.9529s	
13709/33250 (epoch 20.615), train_loss = 1.05716662, grad/param norm = 1.5892e-01, time/batch = 17.2797s	
13710/33250 (epoch 20.617), train_loss = 1.20100725, grad/param norm = 1.7323e-01, time/batch = 16.1881s	
13711/33250 (epoch 20.618), train_loss = 1.23277479, grad/param norm = 2.3350e-01, time/batch = 16.0769s	
13712/33250 (epoch 20.620), train_loss = 1.03195125, grad/param norm = 1.8729e-01, time/batch = 18.0163s	
13713/33250 (epoch 20.621), train_loss = 0.98180995, grad/param norm = 1.5748e-01, time/batch = 15.9545s	
13714/33250 (epoch 20.623), train_loss = 0.88211194, grad/param norm = 1.4952e-01, time/batch = 15.7970s	
13715/33250 (epoch 20.624), train_loss = 0.94833449, grad/param norm = 1.7596e-01, time/batch = 15.4258s	
13716/33250 (epoch 20.626), train_loss = 0.91904661, grad/param norm = 1.9434e-01, time/batch = 15.5536s	
13717/33250 (epoch 20.627), train_loss = 0.91375704, grad/param norm = 1.6260e-01, time/batch = 15.9562s	
13718/33250 (epoch 20.629), train_loss = 1.00693364, grad/param norm = 2.0569e-01, time/batch = 15.7767s	
13719/33250 (epoch 20.630), train_loss = 0.92208053, grad/param norm = 1.8759e-01, time/batch = 16.7051s	
13720/33250 (epoch 20.632), train_loss = 0.78941019, grad/param norm = 1.3374e-01, time/batch = 18.2860s	
13721/33250 (epoch 20.633), train_loss = 0.95644602, grad/param norm = 1.5466e-01, time/batch = 17.2136s	
13722/33250 (epoch 20.635), train_loss = 0.85737224, grad/param norm = 1.4693e-01, time/batch = 16.2833s	
13723/33250 (epoch 20.636), train_loss = 0.88360858, grad/param norm = 1.4072e-01, time/batch = 16.4987s	
13724/33250 (epoch 20.638), train_loss = 0.88349847, grad/param norm = 1.4537e-01, time/batch = 17.1935s	
13725/33250 (epoch 20.639), train_loss = 0.79782334, grad/param norm = 1.4519e-01, time/batch = 15.7975s	
13726/33250 (epoch 20.641), train_loss = 0.90593644, grad/param norm = 1.4123e-01, time/batch = 15.2619s	
13727/33250 (epoch 20.642), train_loss = 0.76794573, grad/param norm = 1.4656e-01, time/batch = 17.2903s	
13728/33250 (epoch 20.644), train_loss = 0.69523913, grad/param norm = 1.3555e-01, time/batch = 16.1984s	
13729/33250 (epoch 20.645), train_loss = 1.01922702, grad/param norm = 1.7577e-01, time/batch = 16.9383s	
13730/33250 (epoch 20.647), train_loss = 0.82537709, grad/param norm = 1.4708e-01, time/batch = 15.4929s	
13731/33250 (epoch 20.648), train_loss = 0.85097642, grad/param norm = 1.5812e-01, time/batch = 17.1114s	
13732/33250 (epoch 20.650), train_loss = 1.05970592, grad/param norm = 1.7294e-01, time/batch = 17.1942s	
13733/33250 (epoch 20.651), train_loss = 0.99900865, grad/param norm = 1.7879e-01, time/batch = 15.8552s	
13734/33250 (epoch 20.653), train_loss = 0.85122109, grad/param norm = 1.4183e-01, time/batch = 15.7311s	
13735/33250 (epoch 20.654), train_loss = 0.93475647, grad/param norm = 1.4939e-01, time/batch = 15.3740s	
13736/33250 (epoch 20.656), train_loss = 0.98373116, grad/param norm = 1.5198e-01, time/batch = 15.2923s	
13737/33250 (epoch 20.657), train_loss = 0.75883374, grad/param norm = 1.4319e-01, time/batch = 15.2520s	
13738/33250 (epoch 20.659), train_loss = 0.88087754, grad/param norm = 1.4068e-01, time/batch = 15.3506s	
13739/33250 (epoch 20.660), train_loss = 0.92226392, grad/param norm = 1.6020e-01, time/batch = 16.1028s	
13740/33250 (epoch 20.662), train_loss = 0.94639639, grad/param norm = 1.5455e-01, time/batch = 17.0341s	
13741/33250 (epoch 20.663), train_loss = 0.85144546, grad/param norm = 1.5994e-01, time/batch = 15.5323s	
13742/33250 (epoch 20.665), train_loss = 0.96922142, grad/param norm = 1.5908e-01, time/batch = 16.8592s	
13743/33250 (epoch 20.666), train_loss = 0.89521308, grad/param norm = 1.5140e-01, time/batch = 15.6216s	
13744/33250 (epoch 20.668), train_loss = 1.07347815, grad/param norm = 1.5894e-01, time/batch = 15.7599s	
13745/33250 (epoch 20.669), train_loss = 0.96461691, grad/param norm = 1.5725e-01, time/batch = 15.5851s	
13746/33250 (epoch 20.671), train_loss = 0.86584026, grad/param norm = 1.5494e-01, time/batch = 15.6989s	
13747/33250 (epoch 20.672), train_loss = 1.02911326, grad/param norm = 1.6757e-01, time/batch = 15.4189s	
13748/33250 (epoch 20.674), train_loss = 0.84020940, grad/param norm = 1.4763e-01, time/batch = 15.7381s	
13749/33250 (epoch 20.675), train_loss = 0.91804516, grad/param norm = 1.4356e-01, time/batch = 15.6713s	
13750/33250 (epoch 20.677), train_loss = 1.01784658, grad/param norm = 1.6186e-01, time/batch = 16.1884s	
13751/33250 (epoch 20.678), train_loss = 0.89786307, grad/param norm = 1.5114e-01, time/batch = 15.7906s	
13752/33250 (epoch 20.680), train_loss = 1.02621304, grad/param norm = 1.6364e-01, time/batch = 15.8218s	
13753/33250 (epoch 20.681), train_loss = 0.80768561, grad/param norm = 1.3756e-01, time/batch = 16.8641s	
13754/33250 (epoch 20.683), train_loss = 0.91812479, grad/param norm = 1.6879e-01, time/batch = 17.6102s	
13755/33250 (epoch 20.684), train_loss = 0.83659342, grad/param norm = 1.5771e-01, time/batch = 15.5275s	
13756/33250 (epoch 20.686), train_loss = 0.84601014, grad/param norm = 1.4291e-01, time/batch = 16.7085s	
13757/33250 (epoch 20.687), train_loss = 0.92356373, grad/param norm = 1.4429e-01, time/batch = 18.1268s	
13758/33250 (epoch 20.689), train_loss = 0.85287050, grad/param norm = 1.5004e-01, time/batch = 16.4237s	
13759/33250 (epoch 20.690), train_loss = 0.94595341, grad/param norm = 1.5839e-01, time/batch = 15.3187s	
13760/33250 (epoch 20.692), train_loss = 0.90909358, grad/param norm = 1.5468e-01, time/batch = 15.3329s	
13761/33250 (epoch 20.693), train_loss = 1.00890366, grad/param norm = 1.4486e-01, time/batch = 15.5886s	
13762/33250 (epoch 20.695), train_loss = 0.95868765, grad/param norm = 1.4560e-01, time/batch = 15.3903s	
13763/33250 (epoch 20.696), train_loss = 0.96145493, grad/param norm = 1.4337e-01, time/batch = 15.0254s	
13764/33250 (epoch 20.698), train_loss = 0.88669097, grad/param norm = 1.5590e-01, time/batch = 15.3524s	
13765/33250 (epoch 20.699), train_loss = 1.13554532, grad/param norm = 1.5520e-01, time/batch = 15.1806s	
13766/33250 (epoch 20.701), train_loss = 0.94101761, grad/param norm = 1.4329e-01, time/batch = 15.5158s	
13767/33250 (epoch 20.702), train_loss = 0.89026061, grad/param norm = 1.8223e-01, time/batch = 15.6660s	
13768/33250 (epoch 20.704), train_loss = 1.10015514, grad/param norm = 1.8291e-01, time/batch = 15.8011s	
13769/33250 (epoch 20.705), train_loss = 0.86575993, grad/param norm = 1.3408e-01, time/batch = 15.6595s	
13770/33250 (epoch 20.707), train_loss = 0.77977163, grad/param norm = 1.4329e-01, time/batch = 15.0863s	
13771/33250 (epoch 20.708), train_loss = 1.03142312, grad/param norm = 1.6236e-01, time/batch = 15.6510s	
13772/33250 (epoch 20.710), train_loss = 0.99831537, grad/param norm = 1.6066e-01, time/batch = 15.5859s	
13773/33250 (epoch 20.711), train_loss = 0.86010139, grad/param norm = 1.5231e-01, time/batch = 14.9670s	
13774/33250 (epoch 20.713), train_loss = 0.96688874, grad/param norm = 1.4537e-01, time/batch = 15.4933s	
13775/33250 (epoch 20.714), train_loss = 0.94300321, grad/param norm = 1.5888e-01, time/batch = 15.8021s	
13776/33250 (epoch 20.716), train_loss = 0.98148203, grad/param norm = 1.5264e-01, time/batch = 15.8869s	
13777/33250 (epoch 20.717), train_loss = 0.85737570, grad/param norm = 1.2959e-01, time/batch = 15.5024s	
13778/33250 (epoch 20.719), train_loss = 0.88879287, grad/param norm = 1.4952e-01, time/batch = 15.8859s	
13779/33250 (epoch 20.720), train_loss = 1.17130276, grad/param norm = 1.7022e-01, time/batch = 15.2848s	
13780/33250 (epoch 20.722), train_loss = 0.81027474, grad/param norm = 1.2878e-01, time/batch = 15.1259s	
13781/33250 (epoch 20.723), train_loss = 0.73895406, grad/param norm = 1.2172e-01, time/batch = 16.0744s	
13782/33250 (epoch 20.725), train_loss = 0.81755156, grad/param norm = 1.2426e-01, time/batch = 16.0497s	
13783/33250 (epoch 20.726), train_loss = 0.91383035, grad/param norm = 1.7252e-01, time/batch = 15.8427s	
13784/33250 (epoch 20.728), train_loss = 0.96794769, grad/param norm = 1.6175e-01, time/batch = 15.3575s	
13785/33250 (epoch 20.729), train_loss = 1.05849767, grad/param norm = 1.6340e-01, time/batch = 15.8443s	
13786/33250 (epoch 20.731), train_loss = 0.87696576, grad/param norm = 1.6102e-01, time/batch = 15.9900s	
13787/33250 (epoch 20.732), train_loss = 0.83524189, grad/param norm = 1.5047e-01, time/batch = 15.8783s	
13788/33250 (epoch 20.734), train_loss = 0.96729839, grad/param norm = 1.5772e-01, time/batch = 15.9244s	
13789/33250 (epoch 20.735), train_loss = 0.94149250, grad/param norm = 1.5039e-01, time/batch = 15.9386s	
13790/33250 (epoch 20.737), train_loss = 0.90742054, grad/param norm = 1.3693e-01, time/batch = 16.0770s	
13791/33250 (epoch 20.738), train_loss = 0.95341312, grad/param norm = 1.4351e-01, time/batch = 16.3032s	
13792/33250 (epoch 20.740), train_loss = 1.03570820, grad/param norm = 1.5100e-01, time/batch = 15.9718s	
13793/33250 (epoch 20.741), train_loss = 1.01484737, grad/param norm = 1.5979e-01, time/batch = 16.0545s	
13794/33250 (epoch 20.743), train_loss = 0.86928836, grad/param norm = 1.3483e-01, time/batch = 16.2083s	
13795/33250 (epoch 20.744), train_loss = 0.89867880, grad/param norm = 1.6272e-01, time/batch = 16.0047s	
13796/33250 (epoch 20.746), train_loss = 0.85507802, grad/param norm = 1.3631e-01, time/batch = 16.0052s	
13797/33250 (epoch 20.747), train_loss = 0.86853236, grad/param norm = 1.6038e-01, time/batch = 15.9981s	
13798/33250 (epoch 20.749), train_loss = 1.03570274, grad/param norm = 1.7604e-01, time/batch = 16.2053s	
13799/33250 (epoch 20.750), train_loss = 1.02348437, grad/param norm = 1.6985e-01, time/batch = 15.9126s	
13800/33250 (epoch 20.752), train_loss = 0.89925148, grad/param norm = 1.4801e-01, time/batch = 15.9073s	
13801/33250 (epoch 20.753), train_loss = 0.89007838, grad/param norm = 1.5913e-01, time/batch = 16.2923s	
13802/33250 (epoch 20.755), train_loss = 0.91273583, grad/param norm = 1.6339e-01, time/batch = 16.0570s	
13803/33250 (epoch 20.756), train_loss = 0.97943997, grad/param norm = 1.6503e-01, time/batch = 16.0632s	
13804/33250 (epoch 20.758), train_loss = 1.06055459, grad/param norm = 1.4459e-01, time/batch = 16.0750s	
13805/33250 (epoch 20.759), train_loss = 0.86005422, grad/param norm = 1.3993e-01, time/batch = 15.9974s	
13806/33250 (epoch 20.761), train_loss = 0.92457342, grad/param norm = 1.5068e-01, time/batch = 15.9439s	
13807/33250 (epoch 20.762), train_loss = 1.02532232, grad/param norm = 1.4660e-01, time/batch = 15.9313s	
13808/33250 (epoch 20.764), train_loss = 0.84855220, grad/param norm = 1.7816e-01, time/batch = 15.9166s	
13809/33250 (epoch 20.765), train_loss = 0.97572475, grad/param norm = 1.5891e-01, time/batch = 16.0612s	
13810/33250 (epoch 20.767), train_loss = 0.77288800, grad/param norm = 1.4831e-01, time/batch = 15.9409s	
13811/33250 (epoch 20.768), train_loss = 0.80629730, grad/param norm = 1.5825e-01, time/batch = 15.9597s	
13812/33250 (epoch 20.770), train_loss = 0.97945217, grad/param norm = 1.6843e-01, time/batch = 15.9198s	
13813/33250 (epoch 20.771), train_loss = 1.00511825, grad/param norm = 1.7345e-01, time/batch = 15.7843s	
13814/33250 (epoch 20.773), train_loss = 0.89435326, grad/param norm = 1.5214e-01, time/batch = 15.9320s	
13815/33250 (epoch 20.774), train_loss = 0.77893235, grad/param norm = 1.5221e-01, time/batch = 15.8583s	
13816/33250 (epoch 20.776), train_loss = 0.88712330, grad/param norm = 1.4769e-01, time/batch = 15.7593s	
13817/33250 (epoch 20.777), train_loss = 1.03724089, grad/param norm = 1.7702e-01, time/batch = 15.7714s	
13818/33250 (epoch 20.779), train_loss = 0.91659500, grad/param norm = 1.5088e-01, time/batch = 15.7706s	
13819/33250 (epoch 20.780), train_loss = 1.09300557, grad/param norm = 1.7627e-01, time/batch = 16.0220s	
13820/33250 (epoch 20.782), train_loss = 0.95739231, grad/param norm = 1.5663e-01, time/batch = 15.9279s	
13821/33250 (epoch 20.783), train_loss = 0.79371148, grad/param norm = 1.4261e-01, time/batch = 16.1726s	
13822/33250 (epoch 20.785), train_loss = 0.82404026, grad/param norm = 1.4407e-01, time/batch = 15.8620s	
13823/33250 (epoch 20.786), train_loss = 1.00108485, grad/param norm = 1.5052e-01, time/batch = 16.0029s	
13824/33250 (epoch 20.788), train_loss = 1.01127331, grad/param norm = 1.5947e-01, time/batch = 15.9344s	
13825/33250 (epoch 20.789), train_loss = 1.04920318, grad/param norm = 1.8084e-01, time/batch = 15.7663s	
13826/33250 (epoch 20.791), train_loss = 1.11101408, grad/param norm = 1.7032e-01, time/batch = 15.7707s	
13827/33250 (epoch 20.792), train_loss = 1.15258347, grad/param norm = 1.5471e-01, time/batch = 15.9211s	
13828/33250 (epoch 20.794), train_loss = 0.91840117, grad/param norm = 1.6359e-01, time/batch = 15.5279s	
13829/33250 (epoch 20.795), train_loss = 0.95924603, grad/param norm = 1.4962e-01, time/batch = 15.8569s	
13830/33250 (epoch 20.797), train_loss = 1.03597678, grad/param norm = 1.8325e-01, time/batch = 15.8738s	
13831/33250 (epoch 20.798), train_loss = 0.93739434, grad/param norm = 1.7715e-01, time/batch = 16.0117s	
13832/33250 (epoch 20.800), train_loss = 0.99099746, grad/param norm = 1.7349e-01, time/batch = 15.6129s	
13833/33250 (epoch 20.802), train_loss = 0.90730407, grad/param norm = 1.3486e-01, time/batch = 15.8576s	
13834/33250 (epoch 20.803), train_loss = 0.96256316, grad/param norm = 1.4579e-01, time/batch = 15.5872s	
13835/33250 (epoch 20.805), train_loss = 0.98644654, grad/param norm = 1.7071e-01, time/batch = 15.6931s	
13836/33250 (epoch 20.806), train_loss = 0.96993515, grad/param norm = 1.6242e-01, time/batch = 15.7558s	
13837/33250 (epoch 20.808), train_loss = 0.90131889, grad/param norm = 1.3718e-01, time/batch = 15.6125s	
13838/33250 (epoch 20.809), train_loss = 0.86328280, grad/param norm = 1.4511e-01, time/batch = 15.8477s	
13839/33250 (epoch 20.811), train_loss = 0.87429645, grad/param norm = 1.4613e-01, time/batch = 15.7537s	
13840/33250 (epoch 20.812), train_loss = 0.98655331, grad/param norm = 1.6317e-01, time/batch = 15.5390s	
13841/33250 (epoch 20.814), train_loss = 0.94113524, grad/param norm = 1.5771e-01, time/batch = 15.8781s	
13842/33250 (epoch 20.815), train_loss = 0.98852655, grad/param norm = 1.4581e-01, time/batch = 24.6966s	
13843/33250 (epoch 20.817), train_loss = 0.92749151, grad/param norm = 1.5634e-01, time/batch = 20.5588s	
13844/33250 (epoch 20.818), train_loss = 0.84753798, grad/param norm = 1.4564e-01, time/batch = 15.6786s	
13845/33250 (epoch 20.820), train_loss = 0.95610306, grad/param norm = 1.5358e-01, time/batch = 15.7316s	
13846/33250 (epoch 20.821), train_loss = 0.91264018, grad/param norm = 1.3406e-01, time/batch = 15.6801s	
13847/33250 (epoch 20.823), train_loss = 1.29204730, grad/param norm = 1.8207e-01, time/batch = 15.6093s	
13848/33250 (epoch 20.824), train_loss = 0.91522745, grad/param norm = 1.6311e-01, time/batch = 15.6069s	
13849/33250 (epoch 20.826), train_loss = 0.97452042, grad/param norm = 1.5831e-01, time/batch = 15.9306s	
13850/33250 (epoch 20.827), train_loss = 0.77158900, grad/param norm = 1.4936e-01, time/batch = 15.7552s	
13851/33250 (epoch 20.829), train_loss = 0.97736426, grad/param norm = 2.0694e-01, time/batch = 16.0119s	
13852/33250 (epoch 20.830), train_loss = 1.06367695, grad/param norm = 2.2057e-01, time/batch = 15.5407s	
13853/33250 (epoch 20.832), train_loss = 0.96838913, grad/param norm = 1.5474e-01, time/batch = 15.6889s	
13854/33250 (epoch 20.833), train_loss = 0.96641359, grad/param norm = 1.6568e-01, time/batch = 15.7545s	
13855/33250 (epoch 20.835), train_loss = 0.87305835, grad/param norm = 1.7507e-01, time/batch = 15.3723s	
13856/33250 (epoch 20.836), train_loss = 0.91530380, grad/param norm = 1.5129e-01, time/batch = 15.4430s	
13857/33250 (epoch 20.838), train_loss = 0.95083418, grad/param norm = 1.5553e-01, time/batch = 15.8583s	
13858/33250 (epoch 20.839), train_loss = 0.91840286, grad/param norm = 1.4926e-01, time/batch = 15.4522s	
13859/33250 (epoch 20.841), train_loss = 0.86715279, grad/param norm = 1.4274e-01, time/batch = 15.4429s	
13860/33250 (epoch 20.842), train_loss = 1.08757333, grad/param norm = 1.5618e-01, time/batch = 15.7552s	
13861/33250 (epoch 20.844), train_loss = 1.07353363, grad/param norm = 1.7669e-01, time/batch = 15.7751s	
13862/33250 (epoch 20.845), train_loss = 1.11910918, grad/param norm = 1.6903e-01, time/batch = 15.5397s	
13863/33250 (epoch 20.847), train_loss = 1.10129365, grad/param norm = 1.5857e-01, time/batch = 15.6337s	
13864/33250 (epoch 20.848), train_loss = 1.20267442, grad/param norm = 1.8555e-01, time/batch = 15.6776s	
13865/33250 (epoch 20.850), train_loss = 1.04097988, grad/param norm = 1.5938e-01, time/batch = 15.7740s	
13866/33250 (epoch 20.851), train_loss = 0.85696083, grad/param norm = 1.6223e-01, time/batch = 15.7088s	
13867/33250 (epoch 20.853), train_loss = 1.01464632, grad/param norm = 1.6235e-01, time/batch = 15.9576s	
13868/33250 (epoch 20.854), train_loss = 0.86656773, grad/param norm = 1.3312e-01, time/batch = 15.9359s	
13869/33250 (epoch 20.856), train_loss = 0.89057600, grad/param norm = 1.5585e-01, time/batch = 15.6820s	
13870/33250 (epoch 20.857), train_loss = 0.83603638, grad/param norm = 1.4576e-01, time/batch = 15.6186s	
13871/33250 (epoch 20.859), train_loss = 0.82386430, grad/param norm = 1.4286e-01, time/batch = 15.7027s	
13872/33250 (epoch 20.860), train_loss = 0.95237780, grad/param norm = 1.4737e-01, time/batch = 15.7721s	
13873/33250 (epoch 20.862), train_loss = 0.84470616, grad/param norm = 1.3597e-01, time/batch = 15.6893s	
13874/33250 (epoch 20.863), train_loss = 0.90536642, grad/param norm = 1.5448e-01, time/batch = 15.8307s	
13875/33250 (epoch 20.865), train_loss = 0.99667107, grad/param norm = 1.5966e-01, time/batch = 15.7642s	
13876/33250 (epoch 20.866), train_loss = 0.88233490, grad/param norm = 1.7213e-01, time/batch = 15.7625s	
13877/33250 (epoch 20.868), train_loss = 1.00953233, grad/param norm = 2.0153e-01, time/batch = 15.6900s	
13878/33250 (epoch 20.869), train_loss = 0.97570731, grad/param norm = 1.6287e-01, time/batch = 15.6224s	
13879/33250 (epoch 20.871), train_loss = 0.73231534, grad/param norm = 1.3572e-01, time/batch = 15.8381s	
13880/33250 (epoch 20.872), train_loss = 0.98481500, grad/param norm = 2.0766e-01, time/batch = 15.7540s	
13881/33250 (epoch 20.874), train_loss = 0.86603225, grad/param norm = 1.7962e-01, time/batch = 15.4585s	
13882/33250 (epoch 20.875), train_loss = 0.84281850, grad/param norm = 1.7131e-01, time/batch = 15.7003s	
13883/33250 (epoch 20.877), train_loss = 1.08350101, grad/param norm = 1.6670e-01, time/batch = 15.5073s	
13884/33250 (epoch 20.878), train_loss = 0.96713476, grad/param norm = 1.5293e-01, time/batch = 15.6842s	
13885/33250 (epoch 20.880), train_loss = 0.95535875, grad/param norm = 1.8996e-01, time/batch = 15.5254s	
13886/33250 (epoch 20.881), train_loss = 1.05861352, grad/param norm = 1.6743e-01, time/batch = 15.6664s	
13887/33250 (epoch 20.883), train_loss = 0.96852601, grad/param norm = 1.5579e-01, time/batch = 15.7465s	
13888/33250 (epoch 20.884), train_loss = 0.98634652, grad/param norm = 1.8527e-01, time/batch = 15.6814s	
13889/33250 (epoch 20.886), train_loss = 0.87284110, grad/param norm = 1.2756e-01, time/batch = 15.7024s	
13890/33250 (epoch 20.887), train_loss = 0.91769285, grad/param norm = 1.6878e-01, time/batch = 15.6289s	
13891/33250 (epoch 20.889), train_loss = 0.89110350, grad/param norm = 1.4312e-01, time/batch = 15.7728s	
13892/33250 (epoch 20.890), train_loss = 0.77034204, grad/param norm = 1.3625e-01, time/batch = 15.5383s	
13893/33250 (epoch 20.892), train_loss = 0.99962869, grad/param norm = 1.5732e-01, time/batch = 15.6962s	
13894/33250 (epoch 20.893), train_loss = 0.99466985, grad/param norm = 1.8415e-01, time/batch = 15.7691s	
13895/33250 (epoch 20.895), train_loss = 0.89974578, grad/param norm = 1.6171e-01, time/batch = 15.7161s	
13896/33250 (epoch 20.896), train_loss = 1.03352805, grad/param norm = 1.6529e-01, time/batch = 15.6454s	
13897/33250 (epoch 20.898), train_loss = 0.95927420, grad/param norm = 1.5943e-01, time/batch = 15.8453s	
13898/33250 (epoch 20.899), train_loss = 0.87231683, grad/param norm = 1.5165e-01, time/batch = 15.8480s	
13899/33250 (epoch 20.901), train_loss = 0.79422400, grad/param norm = 1.2811e-01, time/batch = 15.7492s	
13900/33250 (epoch 20.902), train_loss = 0.91528630, grad/param norm = 1.5141e-01, time/batch = 15.2579s	
13901/33250 (epoch 20.904), train_loss = 0.85034552, grad/param norm = 1.3374e-01, time/batch = 15.5937s	
13902/33250 (epoch 20.905), train_loss = 0.89761312, grad/param norm = 1.4014e-01, time/batch = 15.6530s	
13903/33250 (epoch 20.907), train_loss = 0.84271990, grad/param norm = 1.5321e-01, time/batch = 15.5026s	
13904/33250 (epoch 20.908), train_loss = 0.93189668, grad/param norm = 1.4221e-01, time/batch = 15.4502s	
13905/33250 (epoch 20.910), train_loss = 1.00182932, grad/param norm = 1.5424e-01, time/batch = 15.6375s	
13906/33250 (epoch 20.911), train_loss = 0.82654563, grad/param norm = 1.3254e-01, time/batch = 16.0158s	
13907/33250 (epoch 20.913), train_loss = 0.89358632, grad/param norm = 1.4895e-01, time/batch = 15.6323s	
13908/33250 (epoch 20.914), train_loss = 0.81562127, grad/param norm = 1.5806e-01, time/batch = 15.5590s	
13909/33250 (epoch 20.916), train_loss = 0.86643949, grad/param norm = 1.4410e-01, time/batch = 15.5207s	
13910/33250 (epoch 20.917), train_loss = 0.89379332, grad/param norm = 1.2792e-01, time/batch = 15.6802s	
13911/33250 (epoch 20.919), train_loss = 0.85308768, grad/param norm = 1.5097e-01, time/batch = 15.6056s	
13912/33250 (epoch 20.920), train_loss = 0.93202719, grad/param norm = 1.6757e-01, time/batch = 15.6830s	
13913/33250 (epoch 20.922), train_loss = 0.97130999, grad/param norm = 1.7437e-01, time/batch = 15.5264s	
13914/33250 (epoch 20.923), train_loss = 0.89922387, grad/param norm = 1.6806e-01, time/batch = 16.0065s	
13915/33250 (epoch 20.925), train_loss = 0.90784115, grad/param norm = 1.6154e-01, time/batch = 15.8532s	
13916/33250 (epoch 20.926), train_loss = 0.88300683, grad/param norm = 1.3523e-01, time/batch = 15.7996s	
13917/33250 (epoch 20.928), train_loss = 0.90125583, grad/param norm = 1.5505e-01, time/batch = 15.7645s	
13918/33250 (epoch 20.929), train_loss = 0.76702987, grad/param norm = 1.3335e-01, time/batch = 15.6806s	
13919/33250 (epoch 20.931), train_loss = 1.01942474, grad/param norm = 1.5251e-01, time/batch = 15.5781s	
13920/33250 (epoch 20.932), train_loss = 0.92833831, grad/param norm = 1.6505e-01, time/batch = 15.4918s	
13921/33250 (epoch 20.934), train_loss = 0.85882625, grad/param norm = 1.3341e-01, time/batch = 15.7312s	
13922/33250 (epoch 20.935), train_loss = 0.85655012, grad/param norm = 1.5532e-01, time/batch = 15.6670s	
13923/33250 (epoch 20.937), train_loss = 0.88124707, grad/param norm = 1.7254e-01, time/batch = 15.6110s	
13924/33250 (epoch 20.938), train_loss = 0.94572421, grad/param norm = 1.6645e-01, time/batch = 15.6916s	
13925/33250 (epoch 20.940), train_loss = 0.91923977, grad/param norm = 1.5992e-01, time/batch = 15.7798s	
13926/33250 (epoch 20.941), train_loss = 0.99414438, grad/param norm = 1.6140e-01, time/batch = 15.8648s	
13927/33250 (epoch 20.943), train_loss = 1.05529001, grad/param norm = 1.5499e-01, time/batch = 15.6319s	
13928/33250 (epoch 20.944), train_loss = 0.88589334, grad/param norm = 1.5188e-01, time/batch = 15.6543s	
13929/33250 (epoch 20.946), train_loss = 1.02400675, grad/param norm = 1.6231e-01, time/batch = 15.7805s	
13930/33250 (epoch 20.947), train_loss = 0.84557285, grad/param norm = 1.3649e-01, time/batch = 15.5368s	
13931/33250 (epoch 20.949), train_loss = 0.99063504, grad/param norm = 1.5767e-01, time/batch = 15.7112s	
13932/33250 (epoch 20.950), train_loss = 0.98086661, grad/param norm = 1.4382e-01, time/batch = 15.7095s	
13933/33250 (epoch 20.952), train_loss = 0.92562809, grad/param norm = 1.9921e-01, time/batch = 15.7782s	
13934/33250 (epoch 20.953), train_loss = 0.99545430, grad/param norm = 1.5202e-01, time/batch = 15.7098s	
13935/33250 (epoch 20.955), train_loss = 1.03254843, grad/param norm = 1.5784e-01, time/batch = 15.7587s	
13936/33250 (epoch 20.956), train_loss = 0.97607827, grad/param norm = 1.9422e-01, time/batch = 15.7744s	
13937/33250 (epoch 20.958), train_loss = 0.86946345, grad/param norm = 1.3617e-01, time/batch = 15.8099s	
13938/33250 (epoch 20.959), train_loss = 0.88078471, grad/param norm = 1.5261e-01, time/batch = 15.7929s	
13939/33250 (epoch 20.961), train_loss = 1.11592501, grad/param norm = 1.6101e-01, time/batch = 15.7225s	
13940/33250 (epoch 20.962), train_loss = 0.93406353, grad/param norm = 1.6076e-01, time/batch = 15.6090s	
13941/33250 (epoch 20.964), train_loss = 1.11107892, grad/param norm = 1.8767e-01, time/batch = 15.9252s	
13942/33250 (epoch 20.965), train_loss = 1.00574509, grad/param norm = 1.7270e-01, time/batch = 15.9494s	
13943/33250 (epoch 20.967), train_loss = 0.96292976, grad/param norm = 1.5675e-01, time/batch = 15.8546s	
13944/33250 (epoch 20.968), train_loss = 1.07599099, grad/param norm = 1.4389e-01, time/batch = 15.5819s	
13945/33250 (epoch 20.970), train_loss = 1.21477605, grad/param norm = 2.2328e-01, time/batch = 15.5560s	
13946/33250 (epoch 20.971), train_loss = 1.09407175, grad/param norm = 1.8853e-01, time/batch = 15.5770s	
13947/33250 (epoch 20.973), train_loss = 0.90542479, grad/param norm = 1.4255e-01, time/batch = 15.3239s	
13948/33250 (epoch 20.974), train_loss = 1.02399853, grad/param norm = 1.5932e-01, time/batch = 15.6349s	
13949/33250 (epoch 20.976), train_loss = 0.91321083, grad/param norm = 1.6072e-01, time/batch = 15.7305s	
13950/33250 (epoch 20.977), train_loss = 0.89021237, grad/param norm = 1.5624e-01, time/batch = 15.7252s	
13951/33250 (epoch 20.979), train_loss = 0.96908978, grad/param norm = 1.7521e-01, time/batch = 15.6501s	
13952/33250 (epoch 20.980), train_loss = 0.97139051, grad/param norm = 1.5148e-01, time/batch = 15.6846s	
13953/33250 (epoch 20.982), train_loss = 0.85869203, grad/param norm = 1.4612e-01, time/batch = 15.6284s	
13954/33250 (epoch 20.983), train_loss = 0.96817897, grad/param norm = 1.5836e-01, time/batch = 15.6129s	
13955/33250 (epoch 20.985), train_loss = 0.90255702, grad/param norm = 1.4286e-01, time/batch = 15.6818s	
13956/33250 (epoch 20.986), train_loss = 1.01284590, grad/param norm = 1.5948e-01, time/batch = 15.7092s	
13957/33250 (epoch 20.988), train_loss = 1.06600705, grad/param norm = 1.6768e-01, time/batch = 15.7233s	
13958/33250 (epoch 20.989), train_loss = 1.01354117, grad/param norm = 1.6050e-01, time/batch = 16.0462s	
13959/33250 (epoch 20.991), train_loss = 0.96794372, grad/param norm = 1.5314e-01, time/batch = 15.7747s	
13960/33250 (epoch 20.992), train_loss = 0.89243056, grad/param norm = 1.7705e-01, time/batch = 15.7106s	
13961/33250 (epoch 20.994), train_loss = 0.90071744, grad/param norm = 1.4387e-01, time/batch = 15.8550s	
13962/33250 (epoch 20.995), train_loss = 0.90343746, grad/param norm = 1.8147e-01, time/batch = 15.6918s	
13963/33250 (epoch 20.997), train_loss = 0.67852623, grad/param norm = 1.3982e-01, time/batch = 15.7627s	
13964/33250 (epoch 20.998), train_loss = 0.95930825, grad/param norm = 1.3688e-01, time/batch = 15.6175s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
13965/33250 (epoch 21.000), train_loss = 0.94274866, grad/param norm = 1.5448e-01, time/batch = 15.7917s	
13966/33250 (epoch 21.002), train_loss = 1.12644380, grad/param norm = 1.6552e-01, time/batch = 15.6892s	
13967/33250 (epoch 21.003), train_loss = 1.02325309, grad/param norm = 1.6420e-01, time/batch = 15.8557s	
13968/33250 (epoch 21.005), train_loss = 0.78329525, grad/param norm = 1.4422e-01, time/batch = 15.7011s	
13969/33250 (epoch 21.006), train_loss = 0.81128439, grad/param norm = 1.4454e-01, time/batch = 15.8684s	
13970/33250 (epoch 21.008), train_loss = 1.10946235, grad/param norm = 1.6470e-01, time/batch = 15.8479s	
13971/33250 (epoch 21.009), train_loss = 1.10416134, grad/param norm = 1.6396e-01, time/batch = 15.9565s	
13972/33250 (epoch 21.011), train_loss = 0.84843093, grad/param norm = 1.5553e-01, time/batch = 15.7075s	
13973/33250 (epoch 21.012), train_loss = 0.96163368, grad/param norm = 1.8372e-01, time/batch = 15.6186s	
13974/33250 (epoch 21.014), train_loss = 1.07118204, grad/param norm = 1.6855e-01, time/batch = 15.8523s	
13975/33250 (epoch 21.015), train_loss = 0.93706666, grad/param norm = 1.5108e-01, time/batch = 1.2765s	
13976/33250 (epoch 21.017), train_loss = 0.96537949, grad/param norm = 1.8185e-01, time/batch = 0.6839s	
13977/33250 (epoch 21.018), train_loss = 0.77066116, grad/param norm = 1.4349e-01, time/batch = 0.6883s	
13978/33250 (epoch 21.020), train_loss = 0.93807000, grad/param norm = 1.4367e-01, time/batch = 0.6830s	
13979/33250 (epoch 21.021), train_loss = 0.97009317, grad/param norm = 1.5593e-01, time/batch = 0.6812s	
13980/33250 (epoch 21.023), train_loss = 0.79546278, grad/param norm = 1.6658e-01, time/batch = 0.6894s	
13981/33250 (epoch 21.024), train_loss = 1.03678888, grad/param norm = 1.5869e-01, time/batch = 0.6912s	
13982/33250 (epoch 21.026), train_loss = 0.94599512, grad/param norm = 1.4587e-01, time/batch = 0.9239s	
13983/33250 (epoch 21.027), train_loss = 0.93564702, grad/param norm = 1.3608e-01, time/batch = 0.9968s	
13984/33250 (epoch 21.029), train_loss = 0.95635803, grad/param norm = 1.5011e-01, time/batch = 0.9941s	
13985/33250 (epoch 21.030), train_loss = 0.94364087, grad/param norm = 1.6455e-01, time/batch = 0.9967s	
13986/33250 (epoch 21.032), train_loss = 1.16701000, grad/param norm = 1.8878e-01, time/batch = 0.9975s	
13987/33250 (epoch 21.033), train_loss = 0.89691755, grad/param norm = 2.2247e-01, time/batch = 1.6597s	
13988/33250 (epoch 21.035), train_loss = 0.93307400, grad/param norm = 1.6909e-01, time/batch = 1.8902s	
13989/33250 (epoch 21.036), train_loss = 1.00327525, grad/param norm = 1.8882e-01, time/batch = 3.1547s	
13990/33250 (epoch 21.038), train_loss = 0.93634498, grad/param norm = 1.3766e-01, time/batch = 15.6251s	
13991/33250 (epoch 21.039), train_loss = 0.84995220, grad/param norm = 1.4667e-01, time/batch = 15.6033s	
13992/33250 (epoch 21.041), train_loss = 0.96192017, grad/param norm = 1.8832e-01, time/batch = 15.7671s	
13993/33250 (epoch 21.042), train_loss = 0.76303587, grad/param norm = 1.2986e-01, time/batch = 15.5419s	
13994/33250 (epoch 21.044), train_loss = 1.07795114, grad/param norm = 1.8124e-01, time/batch = 15.8141s	
13995/33250 (epoch 21.045), train_loss = 1.04509426, grad/param norm = 1.5718e-01, time/batch = 15.8005s	
13996/33250 (epoch 21.047), train_loss = 0.95656182, grad/param norm = 1.6854e-01, time/batch = 15.8364s	
13997/33250 (epoch 21.048), train_loss = 1.07685209, grad/param norm = 1.8771e-01, time/batch = 15.4572s	
13998/33250 (epoch 21.050), train_loss = 0.93390434, grad/param norm = 1.4817e-01, time/batch = 15.5236s	
13999/33250 (epoch 21.051), train_loss = 0.94173574, grad/param norm = 1.6692e-01, time/batch = 15.4512s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch21.05_1.4765.t7	
14000/33250 (epoch 21.053), train_loss = 0.93688929, grad/param norm = 1.8984e-01, time/batch = 15.7625s	
14001/33250 (epoch 21.054), train_loss = 1.13444706, grad/param norm = 1.5725e-01, time/batch = 15.8606s	
14002/33250 (epoch 21.056), train_loss = 0.84910404, grad/param norm = 1.4579e-01, time/batch = 15.9880s	
14003/33250 (epoch 21.057), train_loss = 1.01935195, grad/param norm = 1.4287e-01, time/batch = 15.6037s	
14004/33250 (epoch 21.059), train_loss = 0.93436950, grad/param norm = 1.5753e-01, time/batch = 15.7074s	
14005/33250 (epoch 21.060), train_loss = 0.97696664, grad/param norm = 1.6194e-01, time/batch = 15.7048s	
14006/33250 (epoch 21.062), train_loss = 1.05388417, grad/param norm = 1.5411e-01, time/batch = 15.7144s	
14007/33250 (epoch 21.063), train_loss = 1.08647857, grad/param norm = 1.6014e-01, time/batch = 15.7945s	
14008/33250 (epoch 21.065), train_loss = 0.94046147, grad/param norm = 1.4330e-01, time/batch = 15.6300s	
14009/33250 (epoch 21.066), train_loss = 0.98713596, grad/param norm = 1.5333e-01, time/batch = 15.9277s	
14010/33250 (epoch 21.068), train_loss = 0.91149591, grad/param norm = 1.8102e-01, time/batch = 15.9367s	
14011/33250 (epoch 21.069), train_loss = 0.97007969, grad/param norm = 1.5362e-01, time/batch = 15.6088s	
14012/33250 (epoch 21.071), train_loss = 0.85564916, grad/param norm = 1.4798e-01, time/batch = 15.7841s	
14013/33250 (epoch 21.072), train_loss = 0.85548638, grad/param norm = 1.3953e-01, time/batch = 15.7680s	
14014/33250 (epoch 21.074), train_loss = 1.01033530, grad/param norm = 1.6206e-01, time/batch = 15.6989s	
14015/33250 (epoch 21.075), train_loss = 0.88298651, grad/param norm = 1.4429e-01, time/batch = 15.6318s	
14016/33250 (epoch 21.077), train_loss = 0.96091296, grad/param norm = 1.9252e-01, time/batch = 15.5598s	
14017/33250 (epoch 21.078), train_loss = 0.96556702, grad/param norm = 1.4310e-01, time/batch = 16.0928s	
14018/33250 (epoch 21.080), train_loss = 0.94949554, grad/param norm = 1.8706e-01, time/batch = 15.7163s	
14019/33250 (epoch 21.081), train_loss = 0.98407382, grad/param norm = 1.5092e-01, time/batch = 15.8489s	
14020/33250 (epoch 21.083), train_loss = 1.06001142, grad/param norm = 1.5387e-01, time/batch = 15.7798s	
14021/33250 (epoch 21.084), train_loss = 0.93686534, grad/param norm = 1.6100e-01, time/batch = 16.0004s	
14022/33250 (epoch 21.086), train_loss = 0.90393217, grad/param norm = 1.4287e-01, time/batch = 15.7023s	
14023/33250 (epoch 21.087), train_loss = 0.83900073, grad/param norm = 1.5048e-01, time/batch = 15.7700s	
14024/33250 (epoch 21.089), train_loss = 0.97859955, grad/param norm = 1.5044e-01, time/batch = 15.6001s	
14025/33250 (epoch 21.090), train_loss = 0.95561374, grad/param norm = 1.5493e-01, time/batch = 15.7679s	
14026/33250 (epoch 21.092), train_loss = 0.87475153, grad/param norm = 1.3765e-01, time/batch = 15.7139s	
14027/33250 (epoch 21.093), train_loss = 0.95224210, grad/param norm = 1.5032e-01, time/batch = 15.8125s	
14028/33250 (epoch 21.095), train_loss = 0.91255119, grad/param norm = 1.5819e-01, time/batch = 15.8087s	
14029/33250 (epoch 21.096), train_loss = 0.82866191, grad/param norm = 1.6596e-01, time/batch = 15.9587s	
14030/33250 (epoch 21.098), train_loss = 0.81048454, grad/param norm = 1.5481e-01, time/batch = 15.8544s	
14031/33250 (epoch 21.099), train_loss = 0.71974665, grad/param norm = 1.3511e-01, time/batch = 15.8532s	
14032/33250 (epoch 21.101), train_loss = 0.93885862, grad/param norm = 1.5049e-01, time/batch = 15.8454s	
14033/33250 (epoch 21.102), train_loss = 0.86297128, grad/param norm = 1.4906e-01, time/batch = 15.5144s	
14034/33250 (epoch 21.104), train_loss = 0.72515646, grad/param norm = 1.3400e-01, time/batch = 15.6094s	
14035/33250 (epoch 21.105), train_loss = 0.87933181, grad/param norm = 1.5031e-01, time/batch = 15.6134s	
14036/33250 (epoch 21.107), train_loss = 0.79299214, grad/param norm = 1.3285e-01, time/batch = 15.8284s	
14037/33250 (epoch 21.108), train_loss = 0.94945096, grad/param norm = 1.5949e-01, time/batch = 15.7823s	
14038/33250 (epoch 21.110), train_loss = 0.76806259, grad/param norm = 1.3792e-01, time/batch = 15.6254s	
14039/33250 (epoch 21.111), train_loss = 0.90009898, grad/param norm = 1.4457e-01, time/batch = 15.6101s	
14040/33250 (epoch 21.113), train_loss = 0.89585153, grad/param norm = 1.6472e-01, time/batch = 15.7798s	
14041/33250 (epoch 21.114), train_loss = 0.82334642, grad/param norm = 1.5015e-01, time/batch = 15.7620s	
14042/33250 (epoch 21.116), train_loss = 0.91771702, grad/param norm = 1.5980e-01, time/batch = 15.6210s	
14043/33250 (epoch 21.117), train_loss = 0.87087559, grad/param norm = 1.4343e-01, time/batch = 15.6947s	
14044/33250 (epoch 21.119), train_loss = 0.88676353, grad/param norm = 1.5416e-01, time/batch = 15.5301s	
14045/33250 (epoch 21.120), train_loss = 0.71828827, grad/param norm = 1.2989e-01, time/batch = 15.6860s	
14046/33250 (epoch 21.122), train_loss = 1.02034448, grad/param norm = 1.5511e-01, time/batch = 15.7023s	
14047/33250 (epoch 21.123), train_loss = 0.92740392, grad/param norm = 1.5928e-01, time/batch = 15.7044s	
14048/33250 (epoch 21.125), train_loss = 0.75969852, grad/param norm = 1.4630e-01, time/batch = 15.7245s	
14049/33250 (epoch 21.126), train_loss = 0.90621088, grad/param norm = 1.5892e-01, time/batch = 15.7012s	
14050/33250 (epoch 21.128), train_loss = 0.86420149, grad/param norm = 1.4143e-01, time/batch = 15.7218s	
14051/33250 (epoch 21.129), train_loss = 0.92326294, grad/param norm = 1.4977e-01, time/batch = 15.9389s	
14052/33250 (epoch 21.131), train_loss = 0.89629549, grad/param norm = 1.4682e-01, time/batch = 15.7022s	
14053/33250 (epoch 21.132), train_loss = 0.91392637, grad/param norm = 1.7245e-01, time/batch = 15.5461s	
14054/33250 (epoch 21.134), train_loss = 0.91034970, grad/param norm = 1.6054e-01, time/batch = 15.8659s	
14055/33250 (epoch 21.135), train_loss = 0.91412563, grad/param norm = 1.4507e-01, time/batch = 15.6650s	
14056/33250 (epoch 21.137), train_loss = 0.81897581, grad/param norm = 1.6303e-01, time/batch = 15.5349s	
14057/33250 (epoch 21.138), train_loss = 0.86973382, grad/param norm = 1.3812e-01, time/batch = 15.8644s	
14058/33250 (epoch 21.140), train_loss = 0.72972251, grad/param norm = 1.5457e-01, time/batch = 15.9174s	
14059/33250 (epoch 21.141), train_loss = 1.05976356, grad/param norm = 1.8308e-01, time/batch = 15.8686s	
14060/33250 (epoch 21.143), train_loss = 0.74073003, grad/param norm = 1.6098e-01, time/batch = 15.7264s	
14061/33250 (epoch 21.144), train_loss = 0.88764063, grad/param norm = 1.5313e-01, time/batch = 15.7791s	
14062/33250 (epoch 21.146), train_loss = 0.87145031, grad/param norm = 1.4443e-01, time/batch = 15.6856s	
14063/33250 (epoch 21.147), train_loss = 0.87704971, grad/param norm = 1.4737e-01, time/batch = 15.7005s	
14064/33250 (epoch 21.149), train_loss = 0.86027153, grad/param norm = 1.4492e-01, time/batch = 15.6104s	
14065/33250 (epoch 21.150), train_loss = 0.81413478, grad/param norm = 1.4095e-01, time/batch = 15.5395s	
14066/33250 (epoch 21.152), train_loss = 0.78312376, grad/param norm = 1.4215e-01, time/batch = 15.5243s	
14067/33250 (epoch 21.153), train_loss = 1.06367584, grad/param norm = 1.6463e-01, time/batch = 15.7839s	
14068/33250 (epoch 21.155), train_loss = 0.89375177, grad/param norm = 1.5561e-01, time/batch = 15.7783s	
14069/33250 (epoch 21.156), train_loss = 1.08904262, grad/param norm = 1.4513e-01, time/batch = 15.6360s	
14070/33250 (epoch 21.158), train_loss = 1.10014440, grad/param norm = 1.5558e-01, time/batch = 15.7729s	
14071/33250 (epoch 21.159), train_loss = 0.89810062, grad/param norm = 1.5132e-01, time/batch = 15.7979s	
14072/33250 (epoch 21.161), train_loss = 0.98010361, grad/param norm = 1.6220e-01, time/batch = 15.6314s	
14073/33250 (epoch 21.162), train_loss = 0.82530951, grad/param norm = 1.3875e-01, time/batch = 16.1099s	
14074/33250 (epoch 21.164), train_loss = 0.89210248, grad/param norm = 1.6370e-01, time/batch = 29.1734s	
14075/33250 (epoch 21.165), train_loss = 0.99089369, grad/param norm = 1.6717e-01, time/batch = 15.7771s	
14076/33250 (epoch 21.167), train_loss = 1.03791826, grad/param norm = 1.5410e-01, time/batch = 15.7734s	
14077/33250 (epoch 21.168), train_loss = 0.77920740, grad/param norm = 1.2156e-01, time/batch = 15.9243s	
14078/33250 (epoch 21.170), train_loss = 0.88409377, grad/param norm = 1.5576e-01, time/batch = 15.6726s	
14079/33250 (epoch 21.171), train_loss = 0.89238708, grad/param norm = 1.5229e-01, time/batch = 15.6260s	
14080/33250 (epoch 21.173), train_loss = 0.84964572, grad/param norm = 1.4139e-01, time/batch = 15.7883s	
14081/33250 (epoch 21.174), train_loss = 0.92648060, grad/param norm = 1.4512e-01, time/batch = 16.0437s	
14082/33250 (epoch 21.176), train_loss = 0.89516922, grad/param norm = 1.5739e-01, time/batch = 15.6262s	
14083/33250 (epoch 21.177), train_loss = 0.88782691, grad/param norm = 1.4382e-01, time/batch = 15.7130s	
14084/33250 (epoch 21.179), train_loss = 0.83821889, grad/param norm = 1.4430e-01, time/batch = 15.5260s	
14085/33250 (epoch 21.180), train_loss = 0.76503597, grad/param norm = 1.4121e-01, time/batch = 15.5183s	
14086/33250 (epoch 21.182), train_loss = 0.86237486, grad/param norm = 1.5611e-01, time/batch = 15.6094s	
14087/33250 (epoch 21.183), train_loss = 1.04041859, grad/param norm = 1.6110e-01, time/batch = 15.6237s	
14088/33250 (epoch 21.185), train_loss = 0.97573280, grad/param norm = 1.7144e-01, time/batch = 16.0944s	
14089/33250 (epoch 21.186), train_loss = 0.93899672, grad/param norm = 1.4759e-01, time/batch = 15.7092s	
14090/33250 (epoch 21.188), train_loss = 1.02204592, grad/param norm = 1.6999e-01, time/batch = 15.7903s	
14091/33250 (epoch 21.189), train_loss = 0.74702721, grad/param norm = 1.7273e-01, time/batch = 15.7954s	
14092/33250 (epoch 21.191), train_loss = 0.84985206, grad/param norm = 1.6860e-01, time/batch = 16.0388s	
14093/33250 (epoch 21.192), train_loss = 0.86060502, grad/param norm = 1.4354e-01, time/batch = 15.6305s	
14094/33250 (epoch 21.194), train_loss = 0.88062161, grad/param norm = 1.4706e-01, time/batch = 15.7022s	
14095/33250 (epoch 21.195), train_loss = 1.09398077, grad/param norm = 1.5060e-01, time/batch = 15.6986s	
14096/33250 (epoch 21.197), train_loss = 0.86400822, grad/param norm = 1.4032e-01, time/batch = 15.9350s	
14097/33250 (epoch 21.198), train_loss = 1.03365018, grad/param norm = 1.6125e-01, time/batch = 15.5496s	
14098/33250 (epoch 21.200), train_loss = 0.92850008, grad/param norm = 1.4164e-01, time/batch = 15.7626s	
14099/33250 (epoch 21.202), train_loss = 0.86145783, grad/param norm = 1.4057e-01, time/batch = 15.7706s	
14100/33250 (epoch 21.203), train_loss = 0.83162816, grad/param norm = 1.5305e-01, time/batch = 15.8553s	
14101/33250 (epoch 21.205), train_loss = 0.95586867, grad/param norm = 1.5617e-01, time/batch = 15.6213s	
14102/33250 (epoch 21.206), train_loss = 0.99333497, grad/param norm = 1.5024e-01, time/batch = 15.7250s	
14103/33250 (epoch 21.208), train_loss = 1.03808346, grad/param norm = 1.6660e-01, time/batch = 15.8498s	
14104/33250 (epoch 21.209), train_loss = 0.82329415, grad/param norm = 1.4088e-01, time/batch = 15.8753s	
14105/33250 (epoch 21.211), train_loss = 1.00349020, grad/param norm = 1.7781e-01, time/batch = 15.3717s	
14106/33250 (epoch 21.212), train_loss = 1.12867423, grad/param norm = 1.6161e-01, time/batch = 15.4557s	
14107/33250 (epoch 21.214), train_loss = 0.92099059, grad/param norm = 1.4006e-01, time/batch = 15.6762s	
14108/33250 (epoch 21.215), train_loss = 1.08630438, grad/param norm = 1.9487e-01, time/batch = 15.6158s	
14109/33250 (epoch 21.217), train_loss = 1.05095494, grad/param norm = 1.8138e-01, time/batch = 15.6223s	
14110/33250 (epoch 21.218), train_loss = 1.01790349, grad/param norm = 1.4827e-01, time/batch = 15.7115s	
14111/33250 (epoch 21.220), train_loss = 0.96181414, grad/param norm = 1.8095e-01, time/batch = 16.0903s	
14112/33250 (epoch 21.221), train_loss = 1.11003244, grad/param norm = 1.8816e-01, time/batch = 15.6262s	
14113/33250 (epoch 21.223), train_loss = 0.92352370, grad/param norm = 1.4605e-01, time/batch = 15.7775s	
14114/33250 (epoch 21.224), train_loss = 0.97336550, grad/param norm = 1.7176e-01, time/batch = 15.8495s	
14115/33250 (epoch 21.226), train_loss = 1.08242372, grad/param norm = 1.6388e-01, time/batch = 15.8618s	
14116/33250 (epoch 21.227), train_loss = 0.98700496, grad/param norm = 1.6959e-01, time/batch = 15.5322s	
14117/33250 (epoch 21.229), train_loss = 0.96236223, grad/param norm = 1.4761e-01, time/batch = 15.6139s	
14118/33250 (epoch 21.230), train_loss = 0.93246855, grad/param norm = 1.6151e-01, time/batch = 15.6238s	
14119/33250 (epoch 21.232), train_loss = 0.88287204, grad/param norm = 1.3212e-01, time/batch = 15.8562s	
14120/33250 (epoch 21.233), train_loss = 0.85581002, grad/param norm = 1.5647e-01, time/batch = 15.5422s	
14121/33250 (epoch 21.235), train_loss = 1.07864005, grad/param norm = 1.4544e-01, time/batch = 15.8587s	
14122/33250 (epoch 21.236), train_loss = 0.86527251, grad/param norm = 1.4970e-01, time/batch = 15.5235s	
14123/33250 (epoch 21.238), train_loss = 1.05025668, grad/param norm = 1.6822e-01, time/batch = 15.7848s	
14124/33250 (epoch 21.239), train_loss = 1.05686993, grad/param norm = 1.7977e-01, time/batch = 15.6431s	
14125/33250 (epoch 21.241), train_loss = 1.02157701, grad/param norm = 1.9140e-01, time/batch = 15.6378s	
14126/33250 (epoch 21.242), train_loss = 1.02492290, grad/param norm = 1.6716e-01, time/batch = 15.8576s	
14127/33250 (epoch 21.244), train_loss = 1.00386591, grad/param norm = 2.0316e-01, time/batch = 15.5960s	
14128/33250 (epoch 21.245), train_loss = 0.97414981, grad/param norm = 1.5702e-01, time/batch = 15.3693s	
14129/33250 (epoch 21.247), train_loss = 0.95194786, grad/param norm = 1.4643e-01, time/batch = 15.4640s	
14130/33250 (epoch 21.248), train_loss = 1.13543400, grad/param norm = 1.8224e-01, time/batch = 15.9045s	
14131/33250 (epoch 21.250), train_loss = 1.03742975, grad/param norm = 1.5218e-01, time/batch = 15.6886s	
14132/33250 (epoch 21.251), train_loss = 0.94066785, grad/param norm = 1.5549e-01, time/batch = 15.3722s	
14133/33250 (epoch 21.253), train_loss = 0.88092209, grad/param norm = 1.3917e-01, time/batch = 15.7714s	
14134/33250 (epoch 21.254), train_loss = 0.88404826, grad/param norm = 1.5131e-01, time/batch = 15.9415s	
14135/33250 (epoch 21.256), train_loss = 0.94015667, grad/param norm = 1.3757e-01, time/batch = 15.6129s	
14136/33250 (epoch 21.257), train_loss = 1.07418208, grad/param norm = 1.6893e-01, time/batch = 15.6360s	
14137/33250 (epoch 21.259), train_loss = 1.00148806, grad/param norm = 1.6878e-01, time/batch = 15.8674s	
14138/33250 (epoch 21.260), train_loss = 0.82154064, grad/param norm = 1.4534e-01, time/batch = 15.9392s	
14139/33250 (epoch 21.262), train_loss = 0.95314370, grad/param norm = 1.4559e-01, time/batch = 15.8633s	
14140/33250 (epoch 21.263), train_loss = 0.84111078, grad/param norm = 1.4175e-01, time/batch = 15.7837s	
14141/33250 (epoch 21.265), train_loss = 1.01481859, grad/param norm = 1.6648e-01, time/batch = 15.9442s	
14142/33250 (epoch 21.266), train_loss = 0.92501312, grad/param norm = 1.7089e-01, time/batch = 15.7814s	
14143/33250 (epoch 21.268), train_loss = 0.83837352, grad/param norm = 1.4638e-01, time/batch = 15.5284s	
14144/33250 (epoch 21.269), train_loss = 0.77488671, grad/param norm = 1.5502e-01, time/batch = 15.6267s	
14145/33250 (epoch 21.271), train_loss = 0.93927363, grad/param norm = 1.5020e-01, time/batch = 15.5343s	
14146/33250 (epoch 21.272), train_loss = 0.84377016, grad/param norm = 1.3510e-01, time/batch = 15.7116s	
14147/33250 (epoch 21.274), train_loss = 0.70873475, grad/param norm = 1.3177e-01, time/batch = 15.6357s	
14148/33250 (epoch 21.275), train_loss = 0.85401448, grad/param norm = 1.4013e-01, time/batch = 15.5300s	
14149/33250 (epoch 21.277), train_loss = 0.73909837, grad/param norm = 1.3652e-01, time/batch = 15.6184s	
14150/33250 (epoch 21.278), train_loss = 0.86416725, grad/param norm = 1.4867e-01, time/batch = 15.5373s	
14151/33250 (epoch 21.280), train_loss = 0.84046376, grad/param norm = 1.4183e-01, time/batch = 15.6928s	
14152/33250 (epoch 21.281), train_loss = 0.97342458, grad/param norm = 1.6353e-01, time/batch = 15.6933s	
14153/33250 (epoch 21.283), train_loss = 0.97202695, grad/param norm = 2.0303e-01, time/batch = 15.7695s	
14154/33250 (epoch 21.284), train_loss = 0.84297660, grad/param norm = 1.6188e-01, time/batch = 15.5281s	
14155/33250 (epoch 21.286), train_loss = 1.00163762, grad/param norm = 1.6555e-01, time/batch = 15.7769s	
14156/33250 (epoch 21.287), train_loss = 0.80919291, grad/param norm = 1.4376e-01, time/batch = 15.5285s	
14157/33250 (epoch 21.289), train_loss = 0.75662743, grad/param norm = 1.4787e-01, time/batch = 15.8789s	
14158/33250 (epoch 21.290), train_loss = 0.92031564, grad/param norm = 1.6800e-01, time/batch = 15.7190s	
14159/33250 (epoch 21.292), train_loss = 0.98203144, grad/param norm = 1.7332e-01, time/batch = 15.6842s	
14160/33250 (epoch 21.293), train_loss = 1.01449644, grad/param norm = 1.6348e-01, time/batch = 15.6148s	
14161/33250 (epoch 21.295), train_loss = 0.99615977, grad/param norm = 1.6304e-01, time/batch = 16.0023s	
14162/33250 (epoch 21.296), train_loss = 0.96503446, grad/param norm = 1.5608e-01, time/batch = 15.6182s	
14163/33250 (epoch 21.298), train_loss = 0.78466995, grad/param norm = 1.3959e-01, time/batch = 15.6962s	
14164/33250 (epoch 21.299), train_loss = 0.73963675, grad/param norm = 1.2858e-01, time/batch = 15.6939s	
14165/33250 (epoch 21.301), train_loss = 1.00374880, grad/param norm = 1.5057e-01, time/batch = 15.6033s	
14166/33250 (epoch 21.302), train_loss = 0.99217399, grad/param norm = 1.5335e-01, time/batch = 15.6332s	
14167/33250 (epoch 21.304), train_loss = 0.84178945, grad/param norm = 1.4312e-01, time/batch = 15.7296s	
14168/33250 (epoch 21.305), train_loss = 0.89683046, grad/param norm = 1.5631e-01, time/batch = 16.0960s	
14169/33250 (epoch 21.307), train_loss = 0.97493712, grad/param norm = 1.5528e-01, time/batch = 16.0097s	
14170/33250 (epoch 21.308), train_loss = 1.08487128, grad/param norm = 1.8473e-01, time/batch = 15.5453s	
14171/33250 (epoch 21.310), train_loss = 0.90785601, grad/param norm = 1.6333e-01, time/batch = 15.9398s	
14172/33250 (epoch 21.311), train_loss = 1.05234432, grad/param norm = 1.7012e-01, time/batch = 15.8399s	
14173/33250 (epoch 21.313), train_loss = 0.81090903, grad/param norm = 1.5036e-01, time/batch = 15.7875s	
14174/33250 (epoch 21.314), train_loss = 0.93365261, grad/param norm = 1.5757e-01, time/batch = 15.7952s	
14175/33250 (epoch 21.316), train_loss = 1.09927723, grad/param norm = 1.7177e-01, time/batch = 15.6924s	
14176/33250 (epoch 21.317), train_loss = 0.82347635, grad/param norm = 1.3111e-01, time/batch = 15.6209s	
14177/33250 (epoch 21.319), train_loss = 0.99912592, grad/param norm = 2.0063e-01, time/batch = 15.8748s	
14178/33250 (epoch 21.320), train_loss = 1.03315450, grad/param norm = 1.9270e-01, time/batch = 15.6898s	
14179/33250 (epoch 21.322), train_loss = 1.08073688, grad/param norm = 1.7572e-01, time/batch = 15.7839s	
14180/33250 (epoch 21.323), train_loss = 1.15040084, grad/param norm = 2.0319e-01, time/batch = 15.6308s	
14181/33250 (epoch 21.325), train_loss = 0.94689929, grad/param norm = 1.8019e-01, time/batch = 15.6230s	
14182/33250 (epoch 21.326), train_loss = 1.08518957, grad/param norm = 1.6869e-01, time/batch = 15.7028s	
14183/33250 (epoch 21.328), train_loss = 0.91255694, grad/param norm = 1.4734e-01, time/batch = 15.7720s	
14184/33250 (epoch 21.329), train_loss = 0.93502114, grad/param norm = 1.7400e-01, time/batch = 15.6149s	
14185/33250 (epoch 21.331), train_loss = 0.88388127, grad/param norm = 1.6214e-01, time/batch = 15.6920s	
14186/33250 (epoch 21.332), train_loss = 0.88654850, grad/param norm = 1.3715e-01, time/batch = 15.5357s	
14187/33250 (epoch 21.334), train_loss = 1.10562262, grad/param norm = 1.5787e-01, time/batch = 15.9235s	
14188/33250 (epoch 21.335), train_loss = 0.70289760, grad/param norm = 1.3806e-01, time/batch = 15.3901s	
14189/33250 (epoch 21.337), train_loss = 0.97210388, grad/param norm = 1.5326e-01, time/batch = 15.6401s	
14190/33250 (epoch 21.338), train_loss = 1.04869928, grad/param norm = 1.4870e-01, time/batch = 15.6947s	
14191/33250 (epoch 21.340), train_loss = 0.93122283, grad/param norm = 1.3781e-01, time/batch = 15.5851s	
14192/33250 (epoch 21.341), train_loss = 0.88058931, grad/param norm = 1.6032e-01, time/batch = 15.6062s	
14193/33250 (epoch 21.343), train_loss = 0.87968052, grad/param norm = 1.4135e-01, time/batch = 15.7018s	
14194/33250 (epoch 21.344), train_loss = 0.92124375, grad/param norm = 1.4192e-01, time/batch = 15.7719s	
14195/33250 (epoch 21.346), train_loss = 0.81755154, grad/param norm = 1.3245e-01, time/batch = 15.7728s	
14196/33250 (epoch 21.347), train_loss = 1.16158497, grad/param norm = 1.7989e-01, time/batch = 15.6136s	
14197/33250 (epoch 21.349), train_loss = 0.87256981, grad/param norm = 1.5489e-01, time/batch = 15.6968s	
14198/33250 (epoch 21.350), train_loss = 0.90645573, grad/param norm = 1.6415e-01, time/batch = 15.9943s	
14199/33250 (epoch 21.352), train_loss = 0.80484419, grad/param norm = 1.4620e-01, time/batch = 15.7226s	
14200/33250 (epoch 21.353), train_loss = 0.89350701, grad/param norm = 1.3855e-01, time/batch = 15.4007s	
14201/33250 (epoch 21.355), train_loss = 0.89793334, grad/param norm = 1.6733e-01, time/batch = 15.7928s	
14202/33250 (epoch 21.356), train_loss = 0.83643333, grad/param norm = 1.5405e-01, time/batch = 15.7646s	
14203/33250 (epoch 21.358), train_loss = 0.90665114, grad/param norm = 1.4499e-01, time/batch = 15.6897s	
14204/33250 (epoch 21.359), train_loss = 0.89796170, grad/param norm = 1.5556e-01, time/batch = 15.5284s	
14205/33250 (epoch 21.361), train_loss = 1.06735143, grad/param norm = 1.9044e-01, time/batch = 15.3516s	
14206/33250 (epoch 21.362), train_loss = 0.93022408, grad/param norm = 1.4723e-01, time/batch = 15.7507s	
14207/33250 (epoch 21.364), train_loss = 1.02110581, grad/param norm = 1.7644e-01, time/batch = 15.5436s	
14208/33250 (epoch 21.365), train_loss = 0.93128998, grad/param norm = 1.4585e-01, time/batch = 15.6375s	
14209/33250 (epoch 21.367), train_loss = 0.92720194, grad/param norm = 1.3335e-01, time/batch = 15.5475s	
14210/33250 (epoch 21.368), train_loss = 0.92023974, grad/param norm = 1.5171e-01, time/batch = 16.0236s	
14211/33250 (epoch 21.370), train_loss = 0.82165106, grad/param norm = 1.3718e-01, time/batch = 15.8924s	
14212/33250 (epoch 21.371), train_loss = 1.04580082, grad/param norm = 1.4936e-01, time/batch = 15.7811s	
14213/33250 (epoch 21.373), train_loss = 0.88175793, grad/param norm = 1.2971e-01, time/batch = 15.6205s	
14214/33250 (epoch 21.374), train_loss = 1.00544358, grad/param norm = 2.0959e-01, time/batch = 15.6983s	
14215/33250 (epoch 21.376), train_loss = 0.89531845, grad/param norm = 1.5028e-01, time/batch = 15.6200s	
14216/33250 (epoch 21.377), train_loss = 0.84439846, grad/param norm = 1.9839e-01, time/batch = 15.4377s	
14217/33250 (epoch 21.379), train_loss = 0.87102459, grad/param norm = 1.5311e-01, time/batch = 15.7592s	
14218/33250 (epoch 21.380), train_loss = 0.97695275, grad/param norm = 1.7713e-01, time/batch = 15.5212s	
14219/33250 (epoch 21.382), train_loss = 0.97131591, grad/param norm = 1.5668e-01, time/batch = 15.5504s	
14220/33250 (epoch 21.383), train_loss = 0.83009652, grad/param norm = 1.4778e-01, time/batch = 15.6976s	
14221/33250 (epoch 21.385), train_loss = 0.78574903, grad/param norm = 1.4860e-01, time/batch = 15.7867s	
14222/33250 (epoch 21.386), train_loss = 0.82838876, grad/param norm = 1.5392e-01, time/batch = 15.3799s	
14223/33250 (epoch 21.388), train_loss = 0.83432832, grad/param norm = 1.4641e-01, time/batch = 15.6266s	
14224/33250 (epoch 21.389), train_loss = 0.89396410, grad/param norm = 1.6456e-01, time/batch = 15.7871s	
14225/33250 (epoch 21.391), train_loss = 0.94184137, grad/param norm = 1.5572e-01, time/batch = 16.0022s	
14226/33250 (epoch 21.392), train_loss = 1.00196216, grad/param norm = 1.5664e-01, time/batch = 15.9380s	
14227/33250 (epoch 21.394), train_loss = 1.06010850, grad/param norm = 1.8323e-01, time/batch = 16.0363s	
14228/33250 (epoch 21.395), train_loss = 1.02280380, grad/param norm = 1.5791e-01, time/batch = 15.7469s	
14229/33250 (epoch 21.397), train_loss = 1.05500568, grad/param norm = 1.6821e-01, time/batch = 15.9284s	
14230/33250 (epoch 21.398), train_loss = 0.87095727, grad/param norm = 1.4460e-01, time/batch = 15.7206s	
14231/33250 (epoch 21.400), train_loss = 0.82771458, grad/param norm = 1.3764e-01, time/batch = 15.8009s	
14232/33250 (epoch 21.402), train_loss = 0.78913974, grad/param norm = 1.6677e-01, time/batch = 15.6311s	
14233/33250 (epoch 21.403), train_loss = 0.85893339, grad/param norm = 1.5005e-01, time/batch = 15.5296s	
14234/33250 (epoch 21.405), train_loss = 0.85201312, grad/param norm = 1.3528e-01, time/batch = 15.7691s	
14235/33250 (epoch 21.406), train_loss = 0.93450743, grad/param norm = 1.6793e-01, time/batch = 15.5285s	
14236/33250 (epoch 21.408), train_loss = 1.06224034, grad/param norm = 1.5991e-01, time/batch = 15.4426s	
14237/33250 (epoch 21.409), train_loss = 0.97790282, grad/param norm = 1.8217e-01, time/batch = 15.6200s	
14238/33250 (epoch 21.411), train_loss = 0.69195168, grad/param norm = 1.2482e-01, time/batch = 15.6121s	
14239/33250 (epoch 21.412), train_loss = 0.78816293, grad/param norm = 1.6684e-01, time/batch = 15.6311s	
14240/33250 (epoch 21.414), train_loss = 0.96150152, grad/param norm = 1.4873e-01, time/batch = 15.7977s	
14241/33250 (epoch 21.415), train_loss = 1.01689300, grad/param norm = 1.6739e-01, time/batch = 15.7223s	
14242/33250 (epoch 21.417), train_loss = 0.99091021, grad/param norm = 1.5543e-01, time/batch = 15.7995s	
14243/33250 (epoch 21.418), train_loss = 1.16192813, grad/param norm = 1.9839e-01, time/batch = 15.7946s	
14244/33250 (epoch 21.420), train_loss = 1.04658848, grad/param norm = 1.8239e-01, time/batch = 15.6790s	
14245/33250 (epoch 21.421), train_loss = 0.86751902, grad/param norm = 1.5689e-01, time/batch = 15.7920s	
14246/33250 (epoch 21.423), train_loss = 0.99195199, grad/param norm = 1.7852e-01, time/batch = 15.7684s	
14247/33250 (epoch 21.424), train_loss = 1.11214911, grad/param norm = 2.3222e-01, time/batch = 15.6936s	
14248/33250 (epoch 21.426), train_loss = 0.84627131, grad/param norm = 1.3689e-01, time/batch = 15.7668s	
14249/33250 (epoch 21.427), train_loss = 0.86877423, grad/param norm = 1.5674e-01, time/batch = 15.5324s	
14250/33250 (epoch 21.429), train_loss = 0.99108364, grad/param norm = 1.8697e-01, time/batch = 15.7964s	
14251/33250 (epoch 21.430), train_loss = 0.88539886, grad/param norm = 1.7032e-01, time/batch = 15.6927s	
14252/33250 (epoch 21.432), train_loss = 0.97833518, grad/param norm = 1.4570e-01, time/batch = 16.0257s	
14253/33250 (epoch 21.433), train_loss = 0.86799087, grad/param norm = 1.5499e-01, time/batch = 15.8737s	
14254/33250 (epoch 21.435), train_loss = 1.01207917, grad/param norm = 1.6102e-01, time/batch = 15.7877s	
14255/33250 (epoch 21.436), train_loss = 0.85320022, grad/param norm = 1.6156e-01, time/batch = 15.7675s	
14256/33250 (epoch 21.438), train_loss = 1.01755724, grad/param norm = 1.6182e-01, time/batch = 15.6094s	
14257/33250 (epoch 21.439), train_loss = 0.95144171, grad/param norm = 1.5622e-01, time/batch = 15.7804s	
14258/33250 (epoch 21.441), train_loss = 0.90845704, grad/param norm = 1.3386e-01, time/batch = 15.7037s	
14259/33250 (epoch 21.442), train_loss = 0.85769428, grad/param norm = 2.0343e-01, time/batch = 15.6825s	
14260/33250 (epoch 21.444), train_loss = 0.87656251, grad/param norm = 1.4766e-01, time/batch = 15.4497s	
14261/33250 (epoch 21.445), train_loss = 0.94099292, grad/param norm = 1.5121e-01, time/batch = 16.2105s	
14262/33250 (epoch 21.447), train_loss = 0.93800771, grad/param norm = 1.6132e-01, time/batch = 15.7768s	
14263/33250 (epoch 21.448), train_loss = 0.94524632, grad/param norm = 1.4079e-01, time/batch = 15.9190s	
14264/33250 (epoch 21.450), train_loss = 1.09633271, grad/param norm = 1.7529e-01, time/batch = 15.5426s	
14265/33250 (epoch 21.451), train_loss = 0.99362091, grad/param norm = 1.6630e-01, time/batch = 15.7819s	
14266/33250 (epoch 21.453), train_loss = 0.83775737, grad/param norm = 1.3484e-01, time/batch = 15.7768s	
14267/33250 (epoch 21.454), train_loss = 1.06340610, grad/param norm = 1.5655e-01, time/batch = 15.6934s	
14268/33250 (epoch 21.456), train_loss = 1.06942733, grad/param norm = 1.5319e-01, time/batch = 15.4526s	
14269/33250 (epoch 21.457), train_loss = 0.88882927, grad/param norm = 1.5667e-01, time/batch = 15.8442s	
14270/33250 (epoch 21.459), train_loss = 0.98259869, grad/param norm = 1.6150e-01, time/batch = 15.9378s	
14271/33250 (epoch 21.460), train_loss = 1.02856542, grad/param norm = 1.7895e-01, time/batch = 15.8651s	
14272/33250 (epoch 21.462), train_loss = 0.86346253, grad/param norm = 1.5138e-01, time/batch = 15.7962s	
14273/33250 (epoch 21.463), train_loss = 0.85964776, grad/param norm = 1.3108e-01, time/batch = 15.6550s	
14274/33250 (epoch 21.465), train_loss = 0.78357773, grad/param norm = 1.3027e-01, time/batch = 15.7760s	
14275/33250 (epoch 21.466), train_loss = 0.73530149, grad/param norm = 1.0497e-01, time/batch = 15.7729s	
14276/33250 (epoch 21.468), train_loss = 0.83313548, grad/param norm = 1.3155e-01, time/batch = 15.7092s	
14277/33250 (epoch 21.469), train_loss = 0.90535635, grad/param norm = 1.6503e-01, time/batch = 15.6854s	
14278/33250 (epoch 21.471), train_loss = 1.00173689, grad/param norm = 1.4392e-01, time/batch = 15.6085s	
14279/33250 (epoch 21.472), train_loss = 0.90657022, grad/param norm = 1.6189e-01, time/batch = 15.7064s	
14280/33250 (epoch 21.474), train_loss = 1.04040162, grad/param norm = 1.7566e-01, time/batch = 15.6055s	
14281/33250 (epoch 21.475), train_loss = 0.94893390, grad/param norm = 1.3787e-01, time/batch = 15.7728s	
14282/33250 (epoch 21.477), train_loss = 0.93424420, grad/param norm = 1.4049e-01, time/batch = 15.8064s	
14283/33250 (epoch 21.478), train_loss = 0.84784313, grad/param norm = 1.5048e-01, time/batch = 15.6382s	
14284/33250 (epoch 21.480), train_loss = 1.11541538, grad/param norm = 1.7570e-01, time/batch = 15.8607s	
14285/33250 (epoch 21.481), train_loss = 0.95529387, grad/param norm = 1.4961e-01, time/batch = 15.8384s	
14286/33250 (epoch 21.483), train_loss = 0.93787373, grad/param norm = 1.3651e-01, time/batch = 15.6567s	
14287/33250 (epoch 21.484), train_loss = 0.84781973, grad/param norm = 1.4415e-01, time/batch = 15.7735s	
14288/33250 (epoch 21.486), train_loss = 0.79996263, grad/param norm = 1.5096e-01, time/batch = 15.7165s	
14289/33250 (epoch 21.487), train_loss = 0.87335757, grad/param norm = 1.4216e-01, time/batch = 15.7686s	
14290/33250 (epoch 21.489), train_loss = 1.03487125, grad/param norm = 1.9563e-01, time/batch = 15.8668s	
14291/33250 (epoch 21.490), train_loss = 0.96818898, grad/param norm = 1.7180e-01, time/batch = 15.8567s	
14292/33250 (epoch 21.492), train_loss = 0.99474414, grad/param norm = 1.7433e-01, time/batch = 15.7979s	
14293/33250 (epoch 21.493), train_loss = 0.92485074, grad/param norm = 1.6042e-01, time/batch = 16.1016s	
14294/33250 (epoch 21.495), train_loss = 0.95558610, grad/param norm = 1.3978e-01, time/batch = 15.7224s	
14295/33250 (epoch 21.496), train_loss = 0.94318630, grad/param norm = 1.5803e-01, time/batch = 15.7269s	
14296/33250 (epoch 21.498), train_loss = 1.02351259, grad/param norm = 1.7503e-01, time/batch = 15.5395s	
14297/33250 (epoch 21.499), train_loss = 0.89157662, grad/param norm = 1.5806e-01, time/batch = 15.7821s	
14298/33250 (epoch 21.501), train_loss = 0.86620683, grad/param norm = 1.5208e-01, time/batch = 15.6174s	
14299/33250 (epoch 21.502), train_loss = 0.89735473, grad/param norm = 1.4514e-01, time/batch = 15.7709s	
14300/33250 (epoch 21.504), train_loss = 1.06648161, grad/param norm = 1.7834e-01, time/batch = 19.2167s	
14301/33250 (epoch 21.505), train_loss = 0.78240709, grad/param norm = 1.2853e-01, time/batch = 25.3878s	
14302/33250 (epoch 21.507), train_loss = 0.86201357, grad/param norm = 1.7065e-01, time/batch = 15.7972s	
14303/33250 (epoch 21.508), train_loss = 0.88086939, grad/param norm = 1.5807e-01, time/batch = 15.7836s	
14304/33250 (epoch 21.510), train_loss = 0.77028802, grad/param norm = 1.5164e-01, time/batch = 15.9533s	
14305/33250 (epoch 21.511), train_loss = 0.92754157, grad/param norm = 1.5562e-01, time/batch = 15.5550s	
14306/33250 (epoch 21.513), train_loss = 1.06724489, grad/param norm = 1.5995e-01, time/batch = 15.6205s	
14307/33250 (epoch 21.514), train_loss = 0.89000728, grad/param norm = 1.3359e-01, time/batch = 15.6059s	
14308/33250 (epoch 21.516), train_loss = 0.85257879, grad/param norm = 1.4202e-01, time/batch = 15.7078s	
14309/33250 (epoch 21.517), train_loss = 0.90423768, grad/param norm = 1.6742e-01, time/batch = 15.6148s	
14310/33250 (epoch 21.519), train_loss = 0.80045993, grad/param norm = 1.0931e-01, time/batch = 15.5450s	
14311/33250 (epoch 21.520), train_loss = 1.15707215, grad/param norm = 1.9349e-01, time/batch = 15.8522s	
14312/33250 (epoch 21.522), train_loss = 0.99953661, grad/param norm = 1.5642e-01, time/batch = 15.5421s	
14313/33250 (epoch 21.523), train_loss = 0.85368441, grad/param norm = 1.4469e-01, time/batch = 15.8578s	
14314/33250 (epoch 21.525), train_loss = 0.80935597, grad/param norm = 1.6065e-01, time/batch = 15.6416s	
14315/33250 (epoch 21.526), train_loss = 0.80611756, grad/param norm = 1.4487e-01, time/batch = 16.0414s	
14316/33250 (epoch 21.528), train_loss = 0.89525949, grad/param norm = 1.5822e-01, time/batch = 15.5580s	
14317/33250 (epoch 21.529), train_loss = 0.85220089, grad/param norm = 1.6040e-01, time/batch = 15.5307s	
14318/33250 (epoch 21.531), train_loss = 0.79620752, grad/param norm = 1.2986e-01, time/batch = 15.6035s	
14319/33250 (epoch 21.532), train_loss = 0.95672062, grad/param norm = 1.4725e-01, time/batch = 15.5181s	
14320/33250 (epoch 21.534), train_loss = 0.82699889, grad/param norm = 1.3440e-01, time/batch = 15.5997s	
14321/33250 (epoch 21.535), train_loss = 0.91353088, grad/param norm = 1.4300e-01, time/batch = 15.6898s	
14322/33250 (epoch 21.537), train_loss = 0.97580706, grad/param norm = 1.4900e-01, time/batch = 15.6817s	
14323/33250 (epoch 21.538), train_loss = 0.98922252, grad/param norm = 1.5383e-01, time/batch = 15.7677s	
14324/33250 (epoch 21.540), train_loss = 1.08310116, grad/param norm = 1.4354e-01, time/batch = 15.8005s	
14325/33250 (epoch 21.541), train_loss = 1.00473907, grad/param norm = 1.6117e-01, time/batch = 15.7929s	
14326/33250 (epoch 21.543), train_loss = 0.98755871, grad/param norm = 1.5442e-01, time/batch = 15.6957s	
14327/33250 (epoch 21.544), train_loss = 0.86677575, grad/param norm = 1.6476e-01, time/batch = 15.5437s	
14328/33250 (epoch 21.546), train_loss = 0.92075437, grad/param norm = 1.7472e-01, time/batch = 15.6078s	
14329/33250 (epoch 21.547), train_loss = 0.89487477, grad/param norm = 1.5741e-01, time/batch = 15.7825s	
14330/33250 (epoch 21.549), train_loss = 0.98722389, grad/param norm = 1.6600e-01, time/batch = 15.8455s	
14331/33250 (epoch 21.550), train_loss = 0.88928112, grad/param norm = 1.5559e-01, time/batch = 15.9435s	
14332/33250 (epoch 21.552), train_loss = 0.97389101, grad/param norm = 1.6028e-01, time/batch = 15.6137s	
14333/33250 (epoch 21.553), train_loss = 0.87306370, grad/param norm = 1.4804e-01, time/batch = 15.5292s	
14334/33250 (epoch 21.555), train_loss = 0.96612326, grad/param norm = 1.4376e-01, time/batch = 15.7803s	
14335/33250 (epoch 21.556), train_loss = 0.98996532, grad/param norm = 1.6816e-01, time/batch = 15.5621s	
14336/33250 (epoch 21.558), train_loss = 1.02488943, grad/param norm = 1.6191e-01, time/batch = 15.8049s	
14337/33250 (epoch 21.559), train_loss = 0.83743808, grad/param norm = 1.3966e-01, time/batch = 15.6917s	
14338/33250 (epoch 21.561), train_loss = 0.83009131, grad/param norm = 1.3920e-01, time/batch = 15.8508s	
14339/33250 (epoch 21.562), train_loss = 0.98991095, grad/param norm = 1.4856e-01, time/batch = 15.6210s	
14340/33250 (epoch 21.564), train_loss = 1.12858336, grad/param norm = 1.9079e-01, time/batch = 15.7671s	
14341/33250 (epoch 21.565), train_loss = 1.05525568, grad/param norm = 1.8291e-01, time/batch = 15.9188s	
14342/33250 (epoch 21.567), train_loss = 1.06862117, grad/param norm = 1.6981e-01, time/batch = 15.7779s	
14343/33250 (epoch 21.568), train_loss = 0.92783294, grad/param norm = 1.6975e-01, time/batch = 15.7036s	
14344/33250 (epoch 21.570), train_loss = 1.03885073, grad/param norm = 2.2222e-01, time/batch = 15.6891s	
14345/33250 (epoch 21.571), train_loss = 1.07199625, grad/param norm = 1.6033e-01, time/batch = 15.7838s	
14346/33250 (epoch 21.573), train_loss = 0.97623740, grad/param norm = 1.7589e-01, time/batch = 15.8649s	
14347/33250 (epoch 21.574), train_loss = 0.84219938, grad/param norm = 1.3898e-01, time/batch = 15.5475s	
14348/33250 (epoch 21.576), train_loss = 0.97896591, grad/param norm = 1.7558e-01, time/batch = 15.6416s	
14349/33250 (epoch 21.577), train_loss = 0.91897074, grad/param norm = 1.4470e-01, time/batch = 15.5307s	
14350/33250 (epoch 21.579), train_loss = 0.84935426, grad/param norm = 1.5869e-01, time/batch = 15.8324s	
14351/33250 (epoch 21.580), train_loss = 0.87925465, grad/param norm = 1.2671e-01, time/batch = 15.7617s	
14352/33250 (epoch 21.582), train_loss = 0.91143525, grad/param norm = 1.4577e-01, time/batch = 15.6125s	
14353/33250 (epoch 21.583), train_loss = 1.01533385, grad/param norm = 1.4657e-01, time/batch = 15.8509s	
14354/33250 (epoch 21.585), train_loss = 1.01184424, grad/param norm = 1.4483e-01, time/batch = 15.6894s	
14355/33250 (epoch 21.586), train_loss = 0.86848006, grad/param norm = 1.7538e-01, time/batch = 15.5456s	
14356/33250 (epoch 21.588), train_loss = 0.96663352, grad/param norm = 1.5356e-01, time/batch = 15.7027s	
14357/33250 (epoch 21.589), train_loss = 0.96402467, grad/param norm = 1.6797e-01, time/batch = 15.7941s	
14358/33250 (epoch 21.591), train_loss = 0.95092065, grad/param norm = 1.7880e-01, time/batch = 15.4761s	
14359/33250 (epoch 21.592), train_loss = 0.93249315, grad/param norm = 1.4727e-01, time/batch = 15.7129s	
14360/33250 (epoch 21.594), train_loss = 1.06465495, grad/param norm = 1.7567e-01, time/batch = 15.7014s	
14361/33250 (epoch 21.595), train_loss = 0.98286894, grad/param norm = 1.7002e-01, time/batch = 16.0059s	
14362/33250 (epoch 21.597), train_loss = 0.78575399, grad/param norm = 1.2924e-01, time/batch = 15.6211s	
14363/33250 (epoch 21.598), train_loss = 0.89309911, grad/param norm = 1.5573e-01, time/batch = 15.6155s	
14364/33250 (epoch 21.600), train_loss = 0.91846311, grad/param norm = 1.7923e-01, time/batch = 15.9861s	
14365/33250 (epoch 21.602), train_loss = 0.93841214, grad/param norm = 1.7864e-01, time/batch = 15.7660s	
14366/33250 (epoch 21.603), train_loss = 0.95946882, grad/param norm = 1.5525e-01, time/batch = 15.6110s	
14367/33250 (epoch 21.605), train_loss = 0.96244022, grad/param norm = 1.5919e-01, time/batch = 15.5538s	
14368/33250 (epoch 21.606), train_loss = 0.99361236, grad/param norm = 1.5505e-01, time/batch = 15.8543s	
14369/33250 (epoch 21.608), train_loss = 0.95571648, grad/param norm = 1.4567e-01, time/batch = 15.6431s	
14370/33250 (epoch 21.609), train_loss = 0.85319981, grad/param norm = 1.4490e-01, time/batch = 15.5537s	
14371/33250 (epoch 21.611), train_loss = 0.97315161, grad/param norm = 1.6451e-01, time/batch = 15.8523s	
14372/33250 (epoch 21.612), train_loss = 0.93363457, grad/param norm = 1.5786e-01, time/batch = 15.7660s	
14373/33250 (epoch 21.614), train_loss = 1.16031723, grad/param norm = 1.9803e-01, time/batch = 15.6166s	
14374/33250 (epoch 21.615), train_loss = 1.03978510, grad/param norm = 1.6326e-01, time/batch = 15.6076s	
14375/33250 (epoch 21.617), train_loss = 1.19343321, grad/param norm = 1.8270e-01, time/batch = 15.6850s	
14376/33250 (epoch 21.618), train_loss = 1.21047943, grad/param norm = 2.0751e-01, time/batch = 15.9288s	
14377/33250 (epoch 21.620), train_loss = 1.02219100, grad/param norm = 1.6261e-01, time/batch = 15.6286s	
14378/33250 (epoch 21.621), train_loss = 0.97847932, grad/param norm = 1.5782e-01, time/batch = 15.7227s	
14379/33250 (epoch 21.623), train_loss = 0.87113015, grad/param norm = 1.5480e-01, time/batch = 15.7806s	
14380/33250 (epoch 21.624), train_loss = 0.93117533, grad/param norm = 1.6766e-01, time/batch = 15.6908s	
14381/33250 (epoch 21.626), train_loss = 0.89381042, grad/param norm = 1.6371e-01, time/batch = 15.8809s	
14382/33250 (epoch 21.627), train_loss = 0.88553072, grad/param norm = 1.5902e-01, time/batch = 15.7710s	
14383/33250 (epoch 21.629), train_loss = 0.99506786, grad/param norm = 1.7670e-01, time/batch = 15.7734s	
14384/33250 (epoch 21.630), train_loss = 0.90450261, grad/param norm = 1.6912e-01, time/batch = 15.7825s	
14385/33250 (epoch 21.632), train_loss = 0.77950234, grad/param norm = 1.3722e-01, time/batch = 15.7122s	
14386/33250 (epoch 21.633), train_loss = 0.94394167, grad/param norm = 1.5965e-01, time/batch = 15.6199s	
14387/33250 (epoch 21.635), train_loss = 0.85313064, grad/param norm = 1.3989e-01, time/batch = 15.7777s	
14388/33250 (epoch 21.636), train_loss = 0.87241318, grad/param norm = 1.4773e-01, time/batch = 15.7654s	
14389/33250 (epoch 21.638), train_loss = 0.86435423, grad/param norm = 1.4494e-01, time/batch = 15.6953s	
14390/33250 (epoch 21.639), train_loss = 0.78030397, grad/param norm = 1.4496e-01, time/batch = 15.5360s	
14391/33250 (epoch 21.641), train_loss = 0.89757354, grad/param norm = 1.4692e-01, time/batch = 15.8547s	
14392/33250 (epoch 21.642), train_loss = 0.76687809, grad/param norm = 1.5550e-01, time/batch = 15.6893s	
14393/33250 (epoch 21.644), train_loss = 0.67221058, grad/param norm = 1.3338e-01, time/batch = 15.6132s	
14394/33250 (epoch 21.645), train_loss = 1.01054853, grad/param norm = 1.7182e-01, time/batch = 15.9256s	
14395/33250 (epoch 21.647), train_loss = 0.81936080, grad/param norm = 1.6643e-01, time/batch = 15.5991s	
14396/33250 (epoch 21.648), train_loss = 0.85005183, grad/param norm = 1.6897e-01, time/batch = 15.4662s	
14397/33250 (epoch 21.650), train_loss = 1.05252302, grad/param norm = 1.6087e-01, time/batch = 15.6099s	
14398/33250 (epoch 21.651), train_loss = 0.97251553, grad/param norm = 1.7280e-01, time/batch = 15.8236s	
14399/33250 (epoch 21.653), train_loss = 0.83440516, grad/param norm = 1.5465e-01, time/batch = 15.8247s	
14400/33250 (epoch 21.654), train_loss = 0.91478502, grad/param norm = 1.4910e-01, time/batch = 15.4785s	
14401/33250 (epoch 21.656), train_loss = 0.96682334, grad/param norm = 1.5307e-01, time/batch = 15.7232s	
14402/33250 (epoch 21.657), train_loss = 0.73643092, grad/param norm = 1.4775e-01, time/batch = 15.6690s	
14403/33250 (epoch 21.659), train_loss = 0.86251770, grad/param norm = 1.4882e-01, time/batch = 15.6466s	
14404/33250 (epoch 21.660), train_loss = 0.91942084, grad/param norm = 1.6032e-01, time/batch = 15.7689s	
14405/33250 (epoch 21.662), train_loss = 0.92686725, grad/param norm = 1.4694e-01, time/batch = 15.4562s	
14406/33250 (epoch 21.663), train_loss = 0.84283763, grad/param norm = 1.5072e-01, time/batch = 15.6157s	
14407/33250 (epoch 21.665), train_loss = 0.95255348, grad/param norm = 1.5758e-01, time/batch = 15.7004s	
14408/33250 (epoch 21.666), train_loss = 0.88891172, grad/param norm = 1.4608e-01, time/batch = 15.4516s	
14409/33250 (epoch 21.668), train_loss = 1.06289233, grad/param norm = 1.6208e-01, time/batch = 15.8495s	
14410/33250 (epoch 21.669), train_loss = 0.96328163, grad/param norm = 1.6040e-01, time/batch = 15.7719s	
14411/33250 (epoch 21.671), train_loss = 0.84576838, grad/param norm = 1.6025e-01, time/batch = 16.1210s	
14412/33250 (epoch 21.672), train_loss = 1.01745443, grad/param norm = 1.6325e-01, time/batch = 15.7080s	
14413/33250 (epoch 21.674), train_loss = 0.81266988, grad/param norm = 1.3991e-01, time/batch = 15.7104s	
14414/33250 (epoch 21.675), train_loss = 0.91255511, grad/param norm = 1.6031e-01, time/batch = 15.6929s	
14415/33250 (epoch 21.677), train_loss = 1.00718834, grad/param norm = 1.6850e-01, time/batch = 15.7823s	
14416/33250 (epoch 21.678), train_loss = 0.88053001, grad/param norm = 1.5396e-01, time/batch = 15.5203s	
14417/33250 (epoch 21.680), train_loss = 0.99976105, grad/param norm = 1.6848e-01, time/batch = 15.7669s	
14418/33250 (epoch 21.681), train_loss = 0.79987296, grad/param norm = 1.3729e-01, time/batch = 15.7014s	
14419/33250 (epoch 21.683), train_loss = 0.89905918, grad/param norm = 1.6408e-01, time/batch = 15.6902s	
14420/33250 (epoch 21.684), train_loss = 0.82621875, grad/param norm = 1.5908e-01, time/batch = 15.7070s	
14421/33250 (epoch 21.686), train_loss = 0.83606920, grad/param norm = 1.4985e-01, time/batch = 15.6148s	
14422/33250 (epoch 21.687), train_loss = 0.94086135, grad/param norm = 1.6060e-01, time/batch = 15.7308s	
14423/33250 (epoch 21.689), train_loss = 0.84749341, grad/param norm = 1.6405e-01, time/batch = 15.5678s	
14424/33250 (epoch 21.690), train_loss = 0.94061822, grad/param norm = 1.5893e-01, time/batch = 15.5464s	
14425/33250 (epoch 21.692), train_loss = 0.90358302, grad/param norm = 1.4861e-01, time/batch = 15.6095s	
14426/33250 (epoch 21.693), train_loss = 1.00168514, grad/param norm = 1.6392e-01, time/batch = 15.5311s	
14427/33250 (epoch 21.695), train_loss = 0.94581547, grad/param norm = 1.4544e-01, time/batch = 15.3764s	
14428/33250 (epoch 21.696), train_loss = 0.95829949, grad/param norm = 1.3821e-01, time/batch = 15.5357s	
14429/33250 (epoch 21.698), train_loss = 0.87253326, grad/param norm = 1.5632e-01, time/batch = 15.5239s	
14430/33250 (epoch 21.699), train_loss = 1.12554721, grad/param norm = 1.5499e-01, time/batch = 15.7027s	
14431/33250 (epoch 21.701), train_loss = 0.92495535, grad/param norm = 1.4286e-01, time/batch = 15.6138s	
14432/33250 (epoch 21.702), train_loss = 0.89944267, grad/param norm = 2.0975e-01, time/batch = 15.8548s	
14433/33250 (epoch 21.704), train_loss = 1.10180159, grad/param norm = 2.2045e-01, time/batch = 15.7906s	
14434/33250 (epoch 21.705), train_loss = 0.87042393, grad/param norm = 1.3724e-01, time/batch = 15.7011s	
14435/33250 (epoch 21.707), train_loss = 0.77291564, grad/param norm = 1.3333e-01, time/batch = 15.5625s	
14436/33250 (epoch 21.708), train_loss = 1.01490196, grad/param norm = 1.6589e-01, time/batch = 15.7855s	
14437/33250 (epoch 21.710), train_loss = 0.99780885, grad/param norm = 1.6968e-01, time/batch = 15.9441s	
14438/33250 (epoch 21.711), train_loss = 0.84833816, grad/param norm = 1.5982e-01, time/batch = 15.7752s	
14439/33250 (epoch 21.713), train_loss = 0.96713119, grad/param norm = 1.5153e-01, time/batch = 15.8450s	
14440/33250 (epoch 21.714), train_loss = 0.93544457, grad/param norm = 1.5633e-01, time/batch = 15.6903s	
14441/33250 (epoch 21.716), train_loss = 0.96651852, grad/param norm = 1.5961e-01, time/batch = 15.7089s	
14442/33250 (epoch 21.717), train_loss = 0.84805004, grad/param norm = 1.3074e-01, time/batch = 15.9268s	
14443/33250 (epoch 21.719), train_loss = 0.87526140, grad/param norm = 1.5655e-01, time/batch = 15.7122s	
14444/33250 (epoch 21.720), train_loss = 1.16506350, grad/param norm = 1.7949e-01, time/batch = 15.7915s	
14445/33250 (epoch 21.722), train_loss = 0.80337258, grad/param norm = 1.2968e-01, time/batch = 15.6231s	
14446/33250 (epoch 21.723), train_loss = 0.73852257, grad/param norm = 1.3506e-01, time/batch = 15.6996s	
14447/33250 (epoch 21.725), train_loss = 0.81451762, grad/param norm = 1.2490e-01, time/batch = 15.6053s	
14448/33250 (epoch 21.726), train_loss = 0.90383217, grad/param norm = 1.6019e-01, time/batch = 15.9217s	
14449/33250 (epoch 21.728), train_loss = 0.97068175, grad/param norm = 1.7402e-01, time/batch = 15.6978s	
14450/33250 (epoch 21.729), train_loss = 1.04249259, grad/param norm = 1.6924e-01, time/batch = 15.4620s	
14451/33250 (epoch 21.731), train_loss = 0.87551119, grad/param norm = 1.6585e-01, time/batch = 15.6952s	
14452/33250 (epoch 21.732), train_loss = 0.82310994, grad/param norm = 1.4639e-01, time/batch = 15.6124s	
14453/33250 (epoch 21.734), train_loss = 0.96218850, grad/param norm = 1.6753e-01, time/batch = 15.6213s	
14454/33250 (epoch 21.735), train_loss = 0.92922727, grad/param norm = 1.5077e-01, time/batch = 15.7231s	
14455/33250 (epoch 21.737), train_loss = 0.89964606, grad/param norm = 1.4567e-01, time/batch = 15.7030s	
14456/33250 (epoch 21.738), train_loss = 0.92901497, grad/param norm = 1.4178e-01, time/batch = 15.9340s	
14457/33250 (epoch 21.740), train_loss = 1.02508150, grad/param norm = 1.5622e-01, time/batch = 15.7110s	
14458/33250 (epoch 21.741), train_loss = 0.99629876, grad/param norm = 1.6049e-01, time/batch = 15.5441s	
14459/33250 (epoch 21.743), train_loss = 0.85983013, grad/param norm = 1.3842e-01, time/batch = 15.5991s	
14460/33250 (epoch 21.744), train_loss = 0.89657559, grad/param norm = 1.6149e-01, time/batch = 15.7030s	
14461/33250 (epoch 21.746), train_loss = 0.83848553, grad/param norm = 1.3591e-01, time/batch = 15.8683s	
14462/33250 (epoch 21.747), train_loss = 0.86931545, grad/param norm = 1.6908e-01, time/batch = 15.6789s	
14463/33250 (epoch 21.749), train_loss = 1.01758730, grad/param norm = 1.7464e-01, time/batch = 15.7678s	
14464/33250 (epoch 21.750), train_loss = 0.99074934, grad/param norm = 1.6059e-01, time/batch = 15.6149s	
14465/33250 (epoch 21.752), train_loss = 0.89483235, grad/param norm = 1.5225e-01, time/batch = 15.7233s	
14466/33250 (epoch 21.753), train_loss = 0.88316752, grad/param norm = 1.5185e-01, time/batch = 15.6412s	
14467/33250 (epoch 21.755), train_loss = 0.89216512, grad/param norm = 1.6271e-01, time/batch = 15.7888s	
14468/33250 (epoch 21.756), train_loss = 0.97751503, grad/param norm = 1.7277e-01, time/batch = 15.5529s	
14469/33250 (epoch 21.758), train_loss = 1.04669453, grad/param norm = 1.4855e-01, time/batch = 15.7804s	
14470/33250 (epoch 21.759), train_loss = 0.85218980, grad/param norm = 1.3999e-01, time/batch = 16.0154s	
14471/33250 (epoch 21.761), train_loss = 0.92768133, grad/param norm = 1.5491e-01, time/batch = 15.9376s	
14472/33250 (epoch 21.762), train_loss = 1.01439754, grad/param norm = 1.6230e-01, time/batch = 15.7125s	
14473/33250 (epoch 21.764), train_loss = 0.83654978, grad/param norm = 1.8177e-01, time/batch = 15.6074s	
14474/33250 (epoch 21.765), train_loss = 0.96929773, grad/param norm = 1.6004e-01, time/batch = 15.7660s	
14475/33250 (epoch 21.767), train_loss = 0.76659742, grad/param norm = 1.4712e-01, time/batch = 15.8355s	
14476/33250 (epoch 21.768), train_loss = 0.79095290, grad/param norm = 1.5098e-01, time/batch = 15.8778s	
14477/33250 (epoch 21.770), train_loss = 0.96142175, grad/param norm = 1.7855e-01, time/batch = 15.6311s	
14478/33250 (epoch 21.771), train_loss = 0.97907904, grad/param norm = 1.6631e-01, time/batch = 15.6370s	
14479/33250 (epoch 21.773), train_loss = 0.90081845, grad/param norm = 1.6899e-01, time/batch = 15.7849s	
14480/33250 (epoch 21.774), train_loss = 0.77510108, grad/param norm = 1.6467e-01, time/batch = 15.6884s	
14481/33250 (epoch 21.776), train_loss = 0.87455902, grad/param norm = 1.5637e-01, time/batch = 15.7902s	
14482/33250 (epoch 21.777), train_loss = 1.03677718, grad/param norm = 1.7982e-01, time/batch = 15.7581s	
14483/33250 (epoch 21.779), train_loss = 0.91572246, grad/param norm = 1.6404e-01, time/batch = 15.7737s	
14484/33250 (epoch 21.780), train_loss = 1.07300849, grad/param norm = 1.7861e-01, time/batch = 15.5499s	
14485/33250 (epoch 21.782), train_loss = 0.93394767, grad/param norm = 1.5340e-01, time/batch = 15.7022s	
14486/33250 (epoch 21.783), train_loss = 0.79144499, grad/param norm = 1.4364e-01, time/batch = 15.6165s	
14487/33250 (epoch 21.785), train_loss = 0.81004310, grad/param norm = 1.4554e-01, time/batch = 15.6412s	
14488/33250 (epoch 21.786), train_loss = 1.00090677, grad/param norm = 1.5937e-01, time/batch = 15.6945s	
14489/33250 (epoch 21.788), train_loss = 0.99578074, grad/param norm = 1.5511e-01, time/batch = 15.7108s	
14490/33250 (epoch 21.789), train_loss = 1.02471588, grad/param norm = 1.7862e-01, time/batch = 15.7911s	
14491/33250 (epoch 21.791), train_loss = 1.09511936, grad/param norm = 1.7322e-01, time/batch = 15.8579s	
14492/33250 (epoch 21.792), train_loss = 1.13079179, grad/param norm = 1.5833e-01, time/batch = 15.6955s	
14493/33250 (epoch 21.794), train_loss = 0.90777268, grad/param norm = 1.5194e-01, time/batch = 15.7657s	
14494/33250 (epoch 21.795), train_loss = 0.95300321, grad/param norm = 1.5268e-01, time/batch = 15.7540s	
14495/33250 (epoch 21.797), train_loss = 1.01276651, grad/param norm = 1.8374e-01, time/batch = 15.5346s	
14496/33250 (epoch 21.798), train_loss = 0.93343483, grad/param norm = 2.0139e-01, time/batch = 15.8387s	
14497/33250 (epoch 21.800), train_loss = 0.99232534, grad/param norm = 1.8039e-01, time/batch = 15.7798s	
14498/33250 (epoch 21.802), train_loss = 0.90354942, grad/param norm = 1.4195e-01, time/batch = 15.8077s	
14499/33250 (epoch 21.803), train_loss = 0.96441377, grad/param norm = 1.4874e-01, time/batch = 15.7142s	
14500/33250 (epoch 21.805), train_loss = 0.96438886, grad/param norm = 1.6098e-01, time/batch = 15.6551s	
14501/33250 (epoch 21.806), train_loss = 0.93990667, grad/param norm = 1.5502e-01, time/batch = 15.6975s	
14502/33250 (epoch 21.808), train_loss = 0.89429036, grad/param norm = 1.5326e-01, time/batch = 15.6218s	
14503/33250 (epoch 21.809), train_loss = 0.84901081, grad/param norm = 1.4770e-01, time/batch = 15.6093s	
14504/33250 (epoch 21.811), train_loss = 0.86500874, grad/param norm = 1.4630e-01, time/batch = 15.6128s	
14505/33250 (epoch 21.812), train_loss = 0.98286741, grad/param norm = 1.6930e-01, time/batch = 15.7713s	
14506/33250 (epoch 21.814), train_loss = 0.93144867, grad/param norm = 1.6743e-01, time/batch = 15.6227s	
14507/33250 (epoch 21.815), train_loss = 0.97231509, grad/param norm = 1.4226e-01, time/batch = 15.7702s	
14508/33250 (epoch 21.817), train_loss = 0.91731187, grad/param norm = 1.5410e-01, time/batch = 16.0156s	
14509/33250 (epoch 21.818), train_loss = 0.84924750, grad/param norm = 1.5473e-01, time/batch = 15.9534s	
14510/33250 (epoch 21.820), train_loss = 0.94632804, grad/param norm = 2.0569e-01, time/batch = 15.7869s	
14511/33250 (epoch 21.821), train_loss = 0.90801829, grad/param norm = 1.3646e-01, time/batch = 15.7241s	
14512/33250 (epoch 21.823), train_loss = 1.27924297, grad/param norm = 1.8699e-01, time/batch = 15.7610s	
14513/33250 (epoch 21.824), train_loss = 0.90224558, grad/param norm = 1.8225e-01, time/batch = 15.7684s	
14514/33250 (epoch 21.826), train_loss = 0.96796985, grad/param norm = 1.6332e-01, time/batch = 15.7682s	
14515/33250 (epoch 21.827), train_loss = 0.76444817, grad/param norm = 1.5195e-01, time/batch = 15.6142s	
14516/33250 (epoch 21.829), train_loss = 0.95481819, grad/param norm = 1.8181e-01, time/batch = 15.6947s	
14517/33250 (epoch 21.830), train_loss = 1.03160127, grad/param norm = 1.9231e-01, time/batch = 15.5322s	
14518/33250 (epoch 21.832), train_loss = 0.95394391, grad/param norm = 1.6236e-01, time/batch = 15.8664s	
14519/33250 (epoch 21.833), train_loss = 0.94674418, grad/param norm = 1.6120e-01, time/batch = 15.6364s	
14520/33250 (epoch 21.835), train_loss = 0.87290423, grad/param norm = 2.0142e-01, time/batch = 15.7730s	
14521/33250 (epoch 21.836), train_loss = 0.91018918, grad/param norm = 1.5923e-01, time/batch = 15.6378s	
14522/33250 (epoch 21.838), train_loss = 0.94400266, grad/param norm = 1.5045e-01, time/batch = 15.7787s	
14523/33250 (epoch 21.839), train_loss = 0.88952227, grad/param norm = 1.4549e-01, time/batch = 15.5226s	
14524/33250 (epoch 21.841), train_loss = 0.85840907, grad/param norm = 1.4681e-01, time/batch = 15.9063s	
14525/33250 (epoch 21.842), train_loss = 1.07354585, grad/param norm = 1.5452e-01, time/batch = 15.4616s	
14526/33250 (epoch 21.844), train_loss = 1.05927851, grad/param norm = 1.7039e-01, time/batch = 15.7721s	
14527/33250 (epoch 21.845), train_loss = 1.11373449, grad/param norm = 1.7649e-01, time/batch = 20.7802s	
14528/33250 (epoch 21.847), train_loss = 1.09527958, grad/param norm = 1.6126e-01, time/batch = 24.6634s	
14529/33250 (epoch 21.848), train_loss = 1.18715885, grad/param norm = 1.9460e-01, time/batch = 15.7285s	
14530/33250 (epoch 21.850), train_loss = 1.02403120, grad/param norm = 1.5541e-01, time/batch = 15.6885s	
14531/33250 (epoch 21.851), train_loss = 0.83865214, grad/param norm = 1.6086e-01, time/batch = 15.8495s	
14532/33250 (epoch 21.853), train_loss = 0.99362622, grad/param norm = 1.8599e-01, time/batch = 15.6271s	
14533/33250 (epoch 21.854), train_loss = 0.86471033, grad/param norm = 1.3839e-01, time/batch = 15.5414s	
14534/33250 (epoch 21.856), train_loss = 0.87430146, grad/param norm = 1.5330e-01, time/batch = 15.9270s	
14535/33250 (epoch 21.857), train_loss = 0.80813198, grad/param norm = 1.4074e-01, time/batch = 15.6073s	
14536/33250 (epoch 21.859), train_loss = 0.82463189, grad/param norm = 1.6292e-01, time/batch = 15.7008s	
14537/33250 (epoch 21.860), train_loss = 0.95611911, grad/param norm = 1.5673e-01, time/batch = 15.6230s	
14538/33250 (epoch 21.862), train_loss = 0.84356015, grad/param norm = 1.5931e-01, time/batch = 16.0520s	
14539/33250 (epoch 21.863), train_loss = 0.88723955, grad/param norm = 1.5782e-01, time/batch = 15.8709s	
14540/33250 (epoch 21.865), train_loss = 0.97549359, grad/param norm = 1.6160e-01, time/batch = 15.9453s	
14541/33250 (epoch 21.866), train_loss = 0.86807031, grad/param norm = 1.6063e-01, time/batch = 15.8899s	
14542/33250 (epoch 21.868), train_loss = 0.98609541, grad/param norm = 1.8634e-01, time/batch = 16.0230s	
14543/33250 (epoch 21.869), train_loss = 0.95521069, grad/param norm = 1.5542e-01, time/batch = 15.5312s	
14544/33250 (epoch 21.871), train_loss = 0.74635500, grad/param norm = 1.6412e-01, time/batch = 15.6891s	
14545/33250 (epoch 21.872), train_loss = 0.97173751, grad/param norm = 1.4699e-01, time/batch = 15.9231s	
14546/33250 (epoch 21.874), train_loss = 0.83814577, grad/param norm = 1.5006e-01, time/batch = 15.6096s	
14547/33250 (epoch 21.875), train_loss = 0.82013675, grad/param norm = 1.7453e-01, time/batch = 15.6241s	
14548/33250 (epoch 21.877), train_loss = 1.06014266, grad/param norm = 1.7080e-01, time/batch = 15.6171s	
14549/33250 (epoch 21.878), train_loss = 0.95876520, grad/param norm = 1.5188e-01, time/batch = 15.7727s	
14550/33250 (epoch 21.880), train_loss = 0.91682857, grad/param norm = 1.7120e-01, time/batch = 15.9458s	
14551/33250 (epoch 21.881), train_loss = 1.05805242, grad/param norm = 1.6688e-01, time/batch = 15.8106s	
14552/33250 (epoch 21.883), train_loss = 0.95527840, grad/param norm = 1.7333e-01, time/batch = 15.8632s	
14553/33250 (epoch 21.884), train_loss = 0.99284761, grad/param norm = 1.9105e-01, time/batch = 15.9275s	
14554/33250 (epoch 21.886), train_loss = 0.85258614, grad/param norm = 1.2807e-01, time/batch = 15.5418s	
14555/33250 (epoch 21.887), train_loss = 0.89669224, grad/param norm = 1.7795e-01, time/batch = 15.6155s	
14556/33250 (epoch 21.889), train_loss = 0.87907902, grad/param norm = 1.3660e-01, time/batch = 15.6119s	
14557/33250 (epoch 21.890), train_loss = 0.75703638, grad/param norm = 1.2948e-01, time/batch = 15.8530s	
14558/33250 (epoch 21.892), train_loss = 0.99287773, grad/param norm = 1.5837e-01, time/batch = 15.6153s	
14559/33250 (epoch 21.893), train_loss = 0.98957975, grad/param norm = 1.7450e-01, time/batch = 15.5419s	
14560/33250 (epoch 21.895), train_loss = 0.86866582, grad/param norm = 1.5496e-01, time/batch = 15.7855s	
14561/33250 (epoch 21.896), train_loss = 1.05815699, grad/param norm = 2.0872e-01, time/batch = 16.2434s	
14562/33250 (epoch 21.898), train_loss = 0.94538176, grad/param norm = 1.6514e-01, time/batch = 15.7024s	
14563/33250 (epoch 21.899), train_loss = 0.83981964, grad/param norm = 1.3392e-01, time/batch = 15.5718s	
14564/33250 (epoch 21.901), train_loss = 0.79355502, grad/param norm = 1.3096e-01, time/batch = 15.7727s	
14565/33250 (epoch 21.902), train_loss = 0.90178825, grad/param norm = 1.4719e-01, time/batch = 15.7590s	
14566/33250 (epoch 21.904), train_loss = 0.85075633, grad/param norm = 1.4726e-01, time/batch = 15.6004s	
14567/33250 (epoch 21.905), train_loss = 0.88865121, grad/param norm = 1.4725e-01, time/batch = 15.5396s	
14568/33250 (epoch 21.907), train_loss = 0.84007959, grad/param norm = 1.5626e-01, time/batch = 15.8445s	
14569/33250 (epoch 21.908), train_loss = 0.91217821, grad/param norm = 1.3487e-01, time/batch = 15.6947s	
14570/33250 (epoch 21.910), train_loss = 0.98957682, grad/param norm = 1.6216e-01, time/batch = 15.6819s	
14571/33250 (epoch 21.911), train_loss = 0.82689200, grad/param norm = 1.3777e-01, time/batch = 15.8001s	
14572/33250 (epoch 21.913), train_loss = 0.87078356, grad/param norm = 1.5759e-01, time/batch = 15.7552s	
14573/33250 (epoch 21.914), train_loss = 0.80144370, grad/param norm = 1.6572e-01, time/batch = 15.8264s	
14574/33250 (epoch 21.916), train_loss = 0.85954215, grad/param norm = 1.6669e-01, time/batch = 15.9964s	
14575/33250 (epoch 21.917), train_loss = 0.88348914, grad/param norm = 1.2264e-01, time/batch = 16.0689s	
14576/33250 (epoch 21.919), train_loss = 0.85011504, grad/param norm = 1.5743e-01, time/batch = 15.9880s	
14577/33250 (epoch 21.920), train_loss = 0.91750425, grad/param norm = 1.6162e-01, time/batch = 16.0663s	
14578/33250 (epoch 21.922), train_loss = 0.93897658, grad/param norm = 1.6270e-01, time/batch = 16.1540s	
14579/33250 (epoch 21.923), train_loss = 0.88413951, grad/param norm = 1.7951e-01, time/batch = 15.5928s	
14580/33250 (epoch 21.925), train_loss = 0.89402859, grad/param norm = 1.5284e-01, time/batch = 15.6166s	
14581/33250 (epoch 21.926), train_loss = 0.87697465, grad/param norm = 1.3654e-01, time/batch = 15.8662s	
14582/33250 (epoch 21.928), train_loss = 0.88920175, grad/param norm = 1.5788e-01, time/batch = 15.5525s	
14583/33250 (epoch 21.929), train_loss = 0.75851205, grad/param norm = 1.3551e-01, time/batch = 16.0119s	
14584/33250 (epoch 21.931), train_loss = 1.01048002, grad/param norm = 1.5605e-01, time/batch = 15.7095s	
14585/33250 (epoch 21.932), train_loss = 0.91180443, grad/param norm = 1.6309e-01, time/batch = 15.7152s	
14586/33250 (epoch 21.934), train_loss = 0.84000859, grad/param norm = 1.3080e-01, time/batch = 15.5300s	
14587/33250 (epoch 21.935), train_loss = 0.84191492, grad/param norm = 1.6175e-01, time/batch = 15.8372s	
14588/33250 (epoch 21.937), train_loss = 0.86851949, grad/param norm = 1.8688e-01, time/batch = 15.6851s	
14589/33250 (epoch 21.938), train_loss = 0.94215783, grad/param norm = 1.8102e-01, time/batch = 15.6742s	
14590/33250 (epoch 21.940), train_loss = 0.90323644, grad/param norm = 1.6356e-01, time/batch = 15.6941s	
14591/33250 (epoch 21.941), train_loss = 0.98047940, grad/param norm = 1.6753e-01, time/batch = 16.0856s	
14592/33250 (epoch 21.943), train_loss = 1.05440975, grad/param norm = 1.6738e-01, time/batch = 15.6329s	
14593/33250 (epoch 21.944), train_loss = 0.87020189, grad/param norm = 1.5392e-01, time/batch = 15.8086s	
14594/33250 (epoch 21.946), train_loss = 1.00706176, grad/param norm = 1.5617e-01, time/batch = 15.6275s	
14595/33250 (epoch 21.947), train_loss = 0.83744436, grad/param norm = 1.4546e-01, time/batch = 15.7208s	
14596/33250 (epoch 21.949), train_loss = 0.98649053, grad/param norm = 1.7164e-01, time/batch = 15.6408s	
14597/33250 (epoch 21.950), train_loss = 0.97030716, grad/param norm = 1.4953e-01, time/batch = 15.7090s	
14598/33250 (epoch 21.952), train_loss = 0.90966470, grad/param norm = 1.8295e-01, time/batch = 15.6657s	
14599/33250 (epoch 21.953), train_loss = 0.98684586, grad/param norm = 1.6164e-01, time/batch = 15.7041s	
14600/33250 (epoch 21.955), train_loss = 1.03541477, grad/param norm = 1.7462e-01, time/batch = 15.8559s	
14601/33250 (epoch 21.956), train_loss = 0.95628966, grad/param norm = 1.9489e-01, time/batch = 15.7094s	
14602/33250 (epoch 21.958), train_loss = 0.86095557, grad/param norm = 1.4235e-01, time/batch = 15.8510s	
14603/33250 (epoch 21.959), train_loss = 0.86707498, grad/param norm = 1.4867e-01, time/batch = 15.7167s	
14604/33250 (epoch 21.961), train_loss = 1.11050302, grad/param norm = 1.6934e-01, time/batch = 15.6374s	
14605/33250 (epoch 21.962), train_loss = 0.91300110, grad/param norm = 1.6273e-01, time/batch = 15.8052s	
14606/33250 (epoch 21.964), train_loss = 1.09706649, grad/param norm = 1.7959e-01, time/batch = 15.9179s	
14607/33250 (epoch 21.965), train_loss = 0.98897882, grad/param norm = 1.7180e-01, time/batch = 15.7862s	
14608/33250 (epoch 21.967), train_loss = 0.93969395, grad/param norm = 1.5036e-01, time/batch = 15.5411s	
14609/33250 (epoch 21.968), train_loss = 1.06061244, grad/param norm = 1.4960e-01, time/batch = 15.7897s	
14610/33250 (epoch 21.970), train_loss = 1.19814406, grad/param norm = 2.1916e-01, time/batch = 15.8440s	
14611/33250 (epoch 21.971), train_loss = 1.09137632, grad/param norm = 1.9960e-01, time/batch = 15.7726s	
14612/33250 (epoch 21.973), train_loss = 0.89379352, grad/param norm = 1.4926e-01, time/batch = 15.7083s	
14613/33250 (epoch 21.974), train_loss = 1.01089548, grad/param norm = 1.6319e-01, time/batch = 15.6986s	
14614/33250 (epoch 21.976), train_loss = 0.91098337, grad/param norm = 2.0912e-01, time/batch = 15.7678s	
14615/33250 (epoch 21.977), train_loss = 0.88894157, grad/param norm = 1.6692e-01, time/batch = 15.6214s	
14616/33250 (epoch 21.979), train_loss = 0.95207546, grad/param norm = 1.6170e-01, time/batch = 15.7271s	
14617/33250 (epoch 21.980), train_loss = 0.97270870, grad/param norm = 1.5276e-01, time/batch = 15.7167s	
14618/33250 (epoch 21.982), train_loss = 0.85680409, grad/param norm = 1.4811e-01, time/batch = 15.7158s	
14619/33250 (epoch 21.983), train_loss = 0.96586335, grad/param norm = 1.6623e-01, time/batch = 15.8379s	
14620/33250 (epoch 21.985), train_loss = 0.88122332, grad/param norm = 1.5878e-01, time/batch = 15.5414s	
14621/33250 (epoch 21.986), train_loss = 1.00577396, grad/param norm = 1.7238e-01, time/batch = 15.9280s	
14622/33250 (epoch 21.988), train_loss = 1.03812310, grad/param norm = 1.6223e-01, time/batch = 15.7867s	
14623/33250 (epoch 21.989), train_loss = 1.00743982, grad/param norm = 1.7921e-01, time/batch = 15.4575s	
14624/33250 (epoch 21.991), train_loss = 0.97025130, grad/param norm = 1.8604e-01, time/batch = 15.5357s	
14625/33250 (epoch 21.992), train_loss = 0.88709295, grad/param norm = 1.6456e-01, time/batch = 15.9341s	
14626/33250 (epoch 21.994), train_loss = 0.90100619, grad/param norm = 1.6061e-01, time/batch = 15.8055s	
14627/33250 (epoch 21.995), train_loss = 0.89135660, grad/param norm = 1.7079e-01, time/batch = 15.7258s	
14628/33250 (epoch 21.997), train_loss = 0.67710010, grad/param norm = 1.3995e-01, time/batch = 15.6224s	
14629/33250 (epoch 21.998), train_loss = 0.94840604, grad/param norm = 1.4383e-01, time/batch = 15.7742s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
14630/33250 (epoch 22.000), train_loss = 0.93541267, grad/param norm = 1.5435e-01, time/batch = 15.6173s	
14631/33250 (epoch 22.002), train_loss = 1.09493886, grad/param norm = 1.5667e-01, time/batch = 15.6859s	
14632/33250 (epoch 22.003), train_loss = 1.01013938, grad/param norm = 1.7519e-01, time/batch = 15.7835s	
14633/33250 (epoch 22.005), train_loss = 0.77041085, grad/param norm = 1.4588e-01, time/batch = 15.7817s	
14634/33250 (epoch 22.006), train_loss = 0.79431954, grad/param norm = 1.4298e-01, time/batch = 15.5313s	
14635/33250 (epoch 22.008), train_loss = 1.07975321, grad/param norm = 1.6377e-01, time/batch = 15.3943s	
14636/33250 (epoch 22.009), train_loss = 1.08677823, grad/param norm = 1.7281e-01, time/batch = 15.8053s	
14637/33250 (epoch 22.011), train_loss = 0.85125159, grad/param norm = 1.5572e-01, time/batch = 15.6383s	
14638/33250 (epoch 22.012), train_loss = 0.94486466, grad/param norm = 1.8839e-01, time/batch = 15.6140s	
14639/33250 (epoch 22.014), train_loss = 1.06071629, grad/param norm = 1.7303e-01, time/batch = 15.7841s	
14640/33250 (epoch 22.015), train_loss = 0.94467842, grad/param norm = 1.5093e-01, time/batch = 15.7631s	
14641/33250 (epoch 22.017), train_loss = 0.93971412, grad/param norm = 1.8580e-01, time/batch = 15.7850s	
14642/33250 (epoch 22.018), train_loss = 0.78032710, grad/param norm = 1.5314e-01, time/batch = 15.8403s	
14643/33250 (epoch 22.020), train_loss = 0.93889677, grad/param norm = 1.5209e-01, time/batch = 15.9209s	
14644/33250 (epoch 22.021), train_loss = 0.97581833, grad/param norm = 1.5472e-01, time/batch = 15.9816s	
14645/33250 (epoch 22.023), train_loss = 0.78537426, grad/param norm = 1.7444e-01, time/batch = 15.6913s	
14646/33250 (epoch 22.024), train_loss = 1.01571338, grad/param norm = 1.6755e-01, time/batch = 15.7081s	
14647/33250 (epoch 22.026), train_loss = 0.93822719, grad/param norm = 1.4839e-01, time/batch = 15.4544s	
14648/33250 (epoch 22.027), train_loss = 0.93176611, grad/param norm = 1.4218e-01, time/batch = 15.8644s	
14649/33250 (epoch 22.029), train_loss = 0.94632640, grad/param norm = 1.5563e-01, time/batch = 15.8087s	
14650/33250 (epoch 22.030), train_loss = 0.92066683, grad/param norm = 1.6317e-01, time/batch = 15.7065s	
14651/33250 (epoch 22.032), train_loss = 1.13308269, grad/param norm = 1.8482e-01, time/batch = 15.8619s	
14652/33250 (epoch 22.033), train_loss = 0.89958723, grad/param norm = 1.5805e-01, time/batch = 15.7014s	
14653/33250 (epoch 22.035), train_loss = 0.92728122, grad/param norm = 1.7527e-01, time/batch = 15.7793s	
14654/33250 (epoch 22.036), train_loss = 0.98730819, grad/param norm = 1.7482e-01, time/batch = 15.8570s	
14655/33250 (epoch 22.038), train_loss = 0.93126516, grad/param norm = 1.3902e-01, time/batch = 15.8492s	
14656/33250 (epoch 22.039), train_loss = 0.84774726, grad/param norm = 1.4982e-01, time/batch = 15.8695s	
14657/33250 (epoch 22.041), train_loss = 0.96388871, grad/param norm = 1.7578e-01, time/batch = 15.5258s	
14658/33250 (epoch 22.042), train_loss = 0.76603559, grad/param norm = 1.3558e-01, time/batch = 15.7187s	
14659/33250 (epoch 22.044), train_loss = 1.04665742, grad/param norm = 1.5528e-01, time/batch = 15.7720s	
14660/33250 (epoch 22.045), train_loss = 1.03444513, grad/param norm = 1.5798e-01, time/batch = 15.7759s	
14661/33250 (epoch 22.047), train_loss = 0.93971291, grad/param norm = 1.8078e-01, time/batch = 15.7864s	
14662/33250 (epoch 22.048), train_loss = 1.06626307, grad/param norm = 1.9169e-01, time/batch = 15.7636s	
14663/33250 (epoch 22.050), train_loss = 0.92666476, grad/param norm = 1.4817e-01, time/batch = 16.0148s	
14664/33250 (epoch 22.051), train_loss = 0.93352796, grad/param norm = 1.5709e-01, time/batch = 15.7111s	
14665/33250 (epoch 22.053), train_loss = 0.93814452, grad/param norm = 1.7908e-01, time/batch = 15.6013s	
14666/33250 (epoch 22.054), train_loss = 0.80732686, grad/param norm = 1.3861e-01, time/batch = 15.6923s	
14667/33250 (epoch 22.056), train_loss = 0.83837578, grad/param norm = 1.5332e-01, time/batch = 15.7913s	
14668/33250 (epoch 22.057), train_loss = 1.01869733, grad/param norm = 1.4744e-01, time/batch = 15.7914s	
14669/33250 (epoch 22.059), train_loss = 0.91739488, grad/param norm = 1.5409e-01, time/batch = 15.7183s	
14670/33250 (epoch 22.060), train_loss = 0.96232472, grad/param norm = 1.6985e-01, time/batch = 15.7255s	
14671/33250 (epoch 22.062), train_loss = 1.02958855, grad/param norm = 1.5325e-01, time/batch = 16.0393s	
14672/33250 (epoch 22.063), train_loss = 1.07110668, grad/param norm = 1.6473e-01, time/batch = 15.4486s	
14673/33250 (epoch 22.065), train_loss = 0.94503362, grad/param norm = 1.5729e-01, time/batch = 15.8731s	
14674/33250 (epoch 22.066), train_loss = 0.96806279, grad/param norm = 1.5604e-01, time/batch = 15.7759s	
14675/33250 (epoch 22.068), train_loss = 0.89511078, grad/param norm = 1.6861e-01, time/batch = 15.9536s	
14676/33250 (epoch 22.069), train_loss = 0.94794861, grad/param norm = 1.5323e-01, time/batch = 15.9713s	
14677/33250 (epoch 22.071), train_loss = 0.85325077, grad/param norm = 1.3221e-01, time/batch = 15.7808s	
14678/33250 (epoch 22.072), train_loss = 0.83065510, grad/param norm = 1.3704e-01, time/batch = 15.7902s	
14679/33250 (epoch 22.074), train_loss = 1.00088604, grad/param norm = 1.6114e-01, time/batch = 15.6866s	
14680/33250 (epoch 22.075), train_loss = 0.86856761, grad/param norm = 1.4557e-01, time/batch = 15.7102s	
14681/33250 (epoch 22.077), train_loss = 0.94513544, grad/param norm = 1.7968e-01, time/batch = 15.6260s	
14682/33250 (epoch 22.078), train_loss = 0.95444132, grad/param norm = 1.4650e-01, time/batch = 15.6678s	
14683/33250 (epoch 22.080), train_loss = 0.96150336, grad/param norm = 2.3983e-01, time/batch = 15.6926s	
14684/33250 (epoch 22.081), train_loss = 0.96930305, grad/param norm = 1.4888e-01, time/batch = 15.7783s	
14685/33250 (epoch 22.083), train_loss = 1.04331424, grad/param norm = 1.5667e-01, time/batch = 15.6120s	
14686/33250 (epoch 22.084), train_loss = 0.92786019, grad/param norm = 1.9164e-01, time/batch = 15.8602s	
14687/33250 (epoch 22.086), train_loss = 0.90337446, grad/param norm = 1.3957e-01, time/batch = 15.6971s	
14688/33250 (epoch 22.087), train_loss = 0.83106882, grad/param norm = 1.4811e-01, time/batch = 15.6242s	
14689/33250 (epoch 22.089), train_loss = 0.97082045, grad/param norm = 1.5017e-01, time/batch = 15.5473s	
14690/33250 (epoch 22.090), train_loss = 0.94828517, grad/param norm = 1.5656e-01, time/batch = 15.6506s	
14691/33250 (epoch 22.092), train_loss = 0.87330112, grad/param norm = 1.4436e-01, time/batch = 15.8855s	
14692/33250 (epoch 22.093), train_loss = 0.94790927, grad/param norm = 1.4783e-01, time/batch = 15.5559s	
14693/33250 (epoch 22.095), train_loss = 0.90907887, grad/param norm = 1.6665e-01, time/batch = 15.7835s	
14694/33250 (epoch 22.096), train_loss = 0.81279642, grad/param norm = 1.6110e-01, time/batch = 15.3793s	
14695/33250 (epoch 22.098), train_loss = 0.81098081, grad/param norm = 1.7167e-01, time/batch = 15.6055s	
14696/33250 (epoch 22.099), train_loss = 0.71873852, grad/param norm = 2.0214e-01, time/batch = 15.4549s	
14697/33250 (epoch 22.101), train_loss = 0.93993968, grad/param norm = 1.5557e-01, time/batch = 11.3612s	
14698/33250 (epoch 22.102), train_loss = 0.84892964, grad/param norm = 1.4551e-01, time/batch = 0.6810s	
14699/33250 (epoch 22.104), train_loss = 0.71013367, grad/param norm = 1.2476e-01, time/batch = 0.6806s	
14700/33250 (epoch 22.105), train_loss = 0.87193684, grad/param norm = 1.5298e-01, time/batch = 0.6858s	
14701/33250 (epoch 22.107), train_loss = 0.77765097, grad/param norm = 1.2750e-01, time/batch = 0.6847s	
14702/33250 (epoch 22.108), train_loss = 0.93993104, grad/param norm = 1.5897e-01, time/batch = 0.6844s	
14703/33250 (epoch 22.110), train_loss = 0.78167368, grad/param norm = 1.3767e-01, time/batch = 0.6856s	
14704/33250 (epoch 22.111), train_loss = 0.89386909, grad/param norm = 1.5706e-01, time/batch = 0.6781s	
14705/33250 (epoch 22.113), train_loss = 0.88169212, grad/param norm = 1.6924e-01, time/batch = 0.9925s	
14706/33250 (epoch 22.114), train_loss = 0.80900046, grad/param norm = 1.4579e-01, time/batch = 0.9905s	
14707/33250 (epoch 22.116), train_loss = 0.90715127, grad/param norm = 1.6042e-01, time/batch = 0.9860s	
14708/33250 (epoch 22.117), train_loss = 0.86353111, grad/param norm = 1.5265e-01, time/batch = 1.0014s	
14709/33250 (epoch 22.119), train_loss = 0.87633974, grad/param norm = 1.6405e-01, time/batch = 1.0077s	
14710/33250 (epoch 22.120), train_loss = 0.70734795, grad/param norm = 1.2580e-01, time/batch = 1.8712s	
14711/33250 (epoch 22.122), train_loss = 1.00518544, grad/param norm = 1.5253e-01, time/batch = 1.9047s	
14712/33250 (epoch 22.123), train_loss = 0.90921136, grad/param norm = 1.7191e-01, time/batch = 7.3770s	
14713/33250 (epoch 22.125), train_loss = 0.76013865, grad/param norm = 1.6515e-01, time/batch = 15.6268s	
14714/33250 (epoch 22.126), train_loss = 0.90167774, grad/param norm = 1.6252e-01, time/batch = 15.5359s	
14715/33250 (epoch 22.128), train_loss = 0.85614248, grad/param norm = 1.4748e-01, time/batch = 15.8574s	
14716/33250 (epoch 22.129), train_loss = 0.90409402, grad/param norm = 1.5004e-01, time/batch = 15.7191s	
14717/33250 (epoch 22.131), train_loss = 0.87956133, grad/param norm = 1.5190e-01, time/batch = 15.6238s	
14718/33250 (epoch 22.132), train_loss = 0.90273785, grad/param norm = 1.7600e-01, time/batch = 15.6702s	
14719/33250 (epoch 22.134), train_loss = 0.92020793, grad/param norm = 1.7745e-01, time/batch = 15.8419s	
14720/33250 (epoch 22.135), train_loss = 0.89535678, grad/param norm = 1.3603e-01, time/batch = 15.6067s	
14721/33250 (epoch 22.137), train_loss = 0.82083175, grad/param norm = 1.5890e-01, time/batch = 15.7854s	
14722/33250 (epoch 22.138), train_loss = 0.85074593, grad/param norm = 1.3693e-01, time/batch = 15.6951s	
14723/33250 (epoch 22.140), train_loss = 0.72531983, grad/param norm = 1.3909e-01, time/batch = 15.7111s	
14724/33250 (epoch 22.141), train_loss = 1.06529082, grad/param norm = 2.2098e-01, time/batch = 15.7925s	
14725/33250 (epoch 22.143), train_loss = 0.71726278, grad/param norm = 1.5897e-01, time/batch = 15.6524s	
14726/33250 (epoch 22.144), train_loss = 0.85943545, grad/param norm = 1.4885e-01, time/batch = 15.6881s	
14727/33250 (epoch 22.146), train_loss = 0.86162479, grad/param norm = 1.4582e-01, time/batch = 15.6267s	
14728/33250 (epoch 22.147), train_loss = 0.86374206, grad/param norm = 1.4958e-01, time/batch = 15.6154s	
14729/33250 (epoch 22.149), train_loss = 0.84025762, grad/param norm = 1.4728e-01, time/batch = 15.7799s	
14730/33250 (epoch 22.150), train_loss = 0.80950101, grad/param norm = 1.5071e-01, time/batch = 15.5227s	
14731/33250 (epoch 22.152), train_loss = 0.75522552, grad/param norm = 1.4297e-01, time/batch = 15.7132s	
14732/33250 (epoch 22.153), train_loss = 1.04431735, grad/param norm = 1.6391e-01, time/batch = 15.5432s	
14733/33250 (epoch 22.155), train_loss = 0.87731074, grad/param norm = 1.6926e-01, time/batch = 15.6074s	
14734/33250 (epoch 22.156), train_loss = 1.09059042, grad/param norm = 1.5185e-01, time/batch = 15.8532s	
14735/33250 (epoch 22.158), train_loss = 1.10027180, grad/param norm = 1.6038e-01, time/batch = 15.5551s	
14736/33250 (epoch 22.159), train_loss = 0.88550543, grad/param norm = 1.6870e-01, time/batch = 15.5536s	
14737/33250 (epoch 22.161), train_loss = 0.96376691, grad/param norm = 1.7232e-01, time/batch = 15.7921s	
14738/33250 (epoch 22.162), train_loss = 0.82121723, grad/param norm = 1.4464e-01, time/batch = 15.8543s	
14739/33250 (epoch 22.164), train_loss = 0.88453859, grad/param norm = 1.5464e-01, time/batch = 15.4562s	
14740/33250 (epoch 22.165), train_loss = 0.96335254, grad/param norm = 1.5707e-01, time/batch = 15.8557s	
14741/33250 (epoch 22.167), train_loss = 1.04974594, grad/param norm = 1.7304e-01, time/batch = 15.7024s	
14742/33250 (epoch 22.168), train_loss = 0.76963760, grad/param norm = 1.2102e-01, time/batch = 15.7647s	
14743/33250 (epoch 22.170), train_loss = 0.88380608, grad/param norm = 1.6583e-01, time/batch = 15.8515s	
14744/33250 (epoch 22.171), train_loss = 0.88524328, grad/param norm = 1.4778e-01, time/batch = 15.6231s	
14745/33250 (epoch 22.173), train_loss = 0.84721794, grad/param norm = 1.4585e-01, time/batch = 15.6179s	
14746/33250 (epoch 22.174), train_loss = 0.90565701, grad/param norm = 1.4146e-01, time/batch = 15.8590s	
14747/33250 (epoch 22.176), train_loss = 0.87575782, grad/param norm = 1.6015e-01, time/batch = 15.7127s	
14748/33250 (epoch 22.177), train_loss = 0.87956202, grad/param norm = 1.5011e-01, time/batch = 15.6454s	
14749/33250 (epoch 22.179), train_loss = 0.82500178, grad/param norm = 1.4593e-01, time/batch = 15.7600s	
14750/33250 (epoch 22.180), train_loss = 0.74751207, grad/param norm = 1.4119e-01, time/batch = 15.5999s	
14751/33250 (epoch 22.182), train_loss = 0.85201716, grad/param norm = 1.5344e-01, time/batch = 15.6841s	
14752/33250 (epoch 22.183), train_loss = 1.02230390, grad/param norm = 1.6612e-01, time/batch = 15.6086s	
14753/33250 (epoch 22.185), train_loss = 0.96307036, grad/param norm = 1.6911e-01, time/batch = 15.6622s	
14754/33250 (epoch 22.186), train_loss = 0.93370032, grad/param norm = 1.5180e-01, time/batch = 15.5215s	
14755/33250 (epoch 22.188), train_loss = 1.02263360, grad/param norm = 1.7278e-01, time/batch = 15.5412s	
14756/33250 (epoch 22.189), train_loss = 0.73213153, grad/param norm = 1.5095e-01, time/batch = 15.7125s	
14757/33250 (epoch 22.191), train_loss = 0.83041296, grad/param norm = 1.6568e-01, time/batch = 15.7094s	
14758/33250 (epoch 22.192), train_loss = 0.85800814, grad/param norm = 1.4558e-01, time/batch = 15.7215s	
14759/33250 (epoch 22.194), train_loss = 0.86420062, grad/param norm = 1.4630e-01, time/batch = 15.8575s	
14760/33250 (epoch 22.195), train_loss = 1.08241062, grad/param norm = 1.5634e-01, time/batch = 15.8134s	
14761/33250 (epoch 22.197), train_loss = 0.84155732, grad/param norm = 1.4224e-01, time/batch = 15.8380s	
14762/33250 (epoch 22.198), train_loss = 1.00722168, grad/param norm = 1.5970e-01, time/batch = 15.6376s	
14763/33250 (epoch 22.200), train_loss = 0.91376266, grad/param norm = 1.4372e-01, time/batch = 15.5317s	
14764/33250 (epoch 22.202), train_loss = 0.85706365, grad/param norm = 1.4206e-01, time/batch = 15.8642s	
14765/33250 (epoch 22.203), train_loss = 0.82584087, grad/param norm = 1.4812e-01, time/batch = 15.6973s	
14766/33250 (epoch 22.205), train_loss = 0.94562055, grad/param norm = 1.5361e-01, time/batch = 15.5332s	
14767/33250 (epoch 22.206), train_loss = 0.97355314, grad/param norm = 1.5853e-01, time/batch = 15.7220s	
14768/33250 (epoch 22.208), train_loss = 1.01666620, grad/param norm = 1.6936e-01, time/batch = 29.8594s	
14769/33250 (epoch 22.209), train_loss = 0.81683575, grad/param norm = 1.4943e-01, time/batch = 15.7283s	
14770/33250 (epoch 22.211), train_loss = 0.97968459, grad/param norm = 1.6776e-01, time/batch = 15.8380s	
14771/33250 (epoch 22.212), train_loss = 1.10613654, grad/param norm = 1.5835e-01, time/batch = 16.0759s	
14772/33250 (epoch 22.214), train_loss = 0.91364961, grad/param norm = 1.4894e-01, time/batch = 15.9913s	
14773/33250 (epoch 22.215), train_loss = 1.04995963, grad/param norm = 1.8373e-01, time/batch = 15.6969s	
14774/33250 (epoch 22.217), train_loss = 1.03166717, grad/param norm = 1.7359e-01, time/batch = 15.6279s	
14775/33250 (epoch 22.218), train_loss = 0.99920524, grad/param norm = 1.4449e-01, time/batch = 15.5300s	
14776/33250 (epoch 22.220), train_loss = 0.93079481, grad/param norm = 1.5999e-01, time/batch = 15.4559s	
14777/33250 (epoch 22.221), train_loss = 1.10203897, grad/param norm = 1.9177e-01, time/batch = 15.4767s	
14778/33250 (epoch 22.223), train_loss = 0.92126431, grad/param norm = 1.5219e-01, time/batch = 15.6317s	
14779/33250 (epoch 22.224), train_loss = 0.96696939, grad/param norm = 1.6897e-01, time/batch = 15.6335s	
14780/33250 (epoch 22.226), train_loss = 1.05564425, grad/param norm = 1.5793e-01, time/batch = 15.7058s	
14781/33250 (epoch 22.227), train_loss = 0.96050856, grad/param norm = 1.5154e-01, time/batch = 15.5371s	
14782/33250 (epoch 22.229), train_loss = 0.94970005, grad/param norm = 1.4286e-01, time/batch = 15.6128s	
14783/33250 (epoch 22.230), train_loss = 0.92364568, grad/param norm = 1.5893e-01, time/batch = 15.7545s	
14784/33250 (epoch 22.232), train_loss = 0.87776142, grad/param norm = 1.3283e-01, time/batch = 15.4431s	
14785/33250 (epoch 22.233), train_loss = 0.84371206, grad/param norm = 1.4345e-01, time/batch = 15.5319s	
14786/33250 (epoch 22.235), train_loss = 1.05861145, grad/param norm = 1.4837e-01, time/batch = 15.6921s	
14787/33250 (epoch 22.236), train_loss = 0.84985139, grad/param norm = 1.5870e-01, time/batch = 15.7056s	
14788/33250 (epoch 22.238), train_loss = 1.02537750, grad/param norm = 1.6502e-01, time/batch = 15.5643s	
14789/33250 (epoch 22.239), train_loss = 1.04854025, grad/param norm = 1.9185e-01, time/batch = 15.5537s	
14790/33250 (epoch 22.241), train_loss = 1.00866843, grad/param norm = 1.9348e-01, time/batch = 15.7593s	
14791/33250 (epoch 22.242), train_loss = 1.01892383, grad/param norm = 1.7430e-01, time/batch = 15.6139s	
14792/33250 (epoch 22.244), train_loss = 1.01072654, grad/param norm = 2.1148e-01, time/batch = 15.5348s	
14793/33250 (epoch 22.245), train_loss = 0.96187116, grad/param norm = 1.6771e-01, time/batch = 15.5287s	
14794/33250 (epoch 22.247), train_loss = 0.95284924, grad/param norm = 1.6271e-01, time/batch = 15.6864s	
14795/33250 (epoch 22.248), train_loss = 1.13199485, grad/param norm = 1.7493e-01, time/batch = 15.4568s	
14796/33250 (epoch 22.250), train_loss = 1.01452423, grad/param norm = 1.4111e-01, time/batch = 15.3006s	
14797/33250 (epoch 22.251), train_loss = 0.92178556, grad/param norm = 1.5097e-01, time/batch = 15.4466s	
14798/33250 (epoch 22.253), train_loss = 0.88183439, grad/param norm = 1.3982e-01, time/batch = 15.4621s	
14799/33250 (epoch 22.254), train_loss = 0.86316847, grad/param norm = 1.4881e-01, time/batch = 15.4674s	
14800/33250 (epoch 22.256), train_loss = 0.93104704, grad/param norm = 1.4195e-01, time/batch = 15.6212s	
14801/33250 (epoch 22.257), train_loss = 1.06827035, grad/param norm = 1.6969e-01, time/batch = 15.6254s	
14802/33250 (epoch 22.259), train_loss = 0.98958176, grad/param norm = 1.6716e-01, time/batch = 15.6975s	
14803/33250 (epoch 22.260), train_loss = 0.80660558, grad/param norm = 1.4281e-01, time/batch = 15.5467s	
14804/33250 (epoch 22.262), train_loss = 0.94239243, grad/param norm = 1.5491e-01, time/batch = 15.6966s	
14805/33250 (epoch 22.263), train_loss = 0.83531539, grad/param norm = 1.4947e-01, time/batch = 15.6837s	
14806/33250 (epoch 22.265), train_loss = 0.99770163, grad/param norm = 1.7547e-01, time/batch = 15.3729s	
14807/33250 (epoch 22.266), train_loss = 0.89635798, grad/param norm = 1.5854e-01, time/batch = 15.7631s	
14808/33250 (epoch 22.268), train_loss = 0.83352932, grad/param norm = 1.4486e-01, time/batch = 15.5567s	
14809/33250 (epoch 22.269), train_loss = 0.75395723, grad/param norm = 1.4973e-01, time/batch = 15.8526s	
14810/33250 (epoch 22.271), train_loss = 0.92533589, grad/param norm = 1.5066e-01, time/batch = 15.3147s	
14811/33250 (epoch 22.272), train_loss = 0.82626725, grad/param norm = 1.2996e-01, time/batch = 15.6403s	
14812/33250 (epoch 22.274), train_loss = 0.69325341, grad/param norm = 1.2885e-01, time/batch = 15.6174s	
14813/33250 (epoch 22.275), train_loss = 0.83956068, grad/param norm = 1.3813e-01, time/batch = 15.6886s	
14814/33250 (epoch 22.277), train_loss = 0.73860888, grad/param norm = 1.4722e-01, time/batch = 15.6875s	
14815/33250 (epoch 22.278), train_loss = 0.84502787, grad/param norm = 1.5143e-01, time/batch = 15.3775s	
14816/33250 (epoch 22.280), train_loss = 0.82002349, grad/param norm = 1.3739e-01, time/batch = 15.3807s	
14817/33250 (epoch 22.281), train_loss = 0.95496115, grad/param norm = 1.5883e-01, time/batch = 15.6014s	
14818/33250 (epoch 22.283), train_loss = 0.97721759, grad/param norm = 2.3097e-01, time/batch = 15.5266s	
14819/33250 (epoch 22.284), train_loss = 0.83441100, grad/param norm = 1.7262e-01, time/batch = 15.5471s	
14820/33250 (epoch 22.286), train_loss = 0.97436988, grad/param norm = 1.5635e-01, time/batch = 15.6298s	
14821/33250 (epoch 22.287), train_loss = 0.79678230, grad/param norm = 1.4097e-01, time/batch = 15.8036s	
14822/33250 (epoch 22.289), train_loss = 0.74655294, grad/param norm = 1.4553e-01, time/batch = 15.7842s	
14823/33250 (epoch 22.290), train_loss = 0.90222283, grad/param norm = 1.4927e-01, time/batch = 15.6183s	
14824/33250 (epoch 22.292), train_loss = 0.98018526, grad/param norm = 1.8198e-01, time/batch = 15.7762s	
14825/33250 (epoch 22.293), train_loss = 1.00726161, grad/param norm = 1.5246e-01, time/batch = 15.2872s	
14826/33250 (epoch 22.295), train_loss = 0.98287035, grad/param norm = 1.5347e-01, time/batch = 15.6965s	
14827/33250 (epoch 22.296), train_loss = 0.96575308, grad/param norm = 1.7111e-01, time/batch = 15.3830s	
14828/33250 (epoch 22.298), train_loss = 0.77869937, grad/param norm = 1.4291e-01, time/batch = 15.6007s	
14829/33250 (epoch 22.299), train_loss = 0.73611835, grad/param norm = 1.2297e-01, time/batch = 15.6353s	
14830/33250 (epoch 22.301), train_loss = 0.98077293, grad/param norm = 1.4710e-01, time/batch = 15.5574s	
14831/33250 (epoch 22.302), train_loss = 0.98313398, grad/param norm = 1.5261e-01, time/batch = 15.6368s	
14832/33250 (epoch 22.304), train_loss = 0.82786384, grad/param norm = 1.4329e-01, time/batch = 15.9511s	
14833/33250 (epoch 22.305), train_loss = 0.87847906, grad/param norm = 1.4767e-01, time/batch = 15.6199s	
14834/33250 (epoch 22.307), train_loss = 0.95814063, grad/param norm = 1.5118e-01, time/batch = 15.4681s	
14835/33250 (epoch 22.308), train_loss = 1.07611544, grad/param norm = 2.0757e-01, time/batch = 15.9171s	
14836/33250 (epoch 22.310), train_loss = 0.89945554, grad/param norm = 1.6411e-01, time/batch = 15.8306s	
14837/33250 (epoch 22.311), train_loss = 1.04434152, grad/param norm = 1.7515e-01, time/batch = 16.0112s	
14838/33250 (epoch 22.313), train_loss = 0.79650426, grad/param norm = 1.4777e-01, time/batch = 15.6278s	
14839/33250 (epoch 22.314), train_loss = 0.92355410, grad/param norm = 1.6111e-01, time/batch = 15.4501s	
14840/33250 (epoch 22.316), train_loss = 1.08347226, grad/param norm = 1.6911e-01, time/batch = 15.8720s	
14841/33250 (epoch 22.317), train_loss = 0.81025589, grad/param norm = 1.3274e-01, time/batch = 15.8877s	
14842/33250 (epoch 22.319), train_loss = 0.97310977, grad/param norm = 1.7965e-01, time/batch = 15.7268s	
14843/33250 (epoch 22.320), train_loss = 0.99754954, grad/param norm = 1.8953e-01, time/batch = 15.7803s	
14844/33250 (epoch 22.322), train_loss = 1.04905976, grad/param norm = 1.7853e-01, time/batch = 15.7030s	
14845/33250 (epoch 22.323), train_loss = 1.11322964, grad/param norm = 1.8607e-01, time/batch = 15.6892s	
14846/33250 (epoch 22.325), train_loss = 0.92866588, grad/param norm = 1.6688e-01, time/batch = 15.6250s	
14847/33250 (epoch 22.326), train_loss = 1.07167661, grad/param norm = 1.7013e-01, time/batch = 15.6774s	
14848/33250 (epoch 22.328), train_loss = 0.89935018, grad/param norm = 1.4692e-01, time/batch = 15.7750s	
14849/33250 (epoch 22.329), train_loss = 0.92501167, grad/param norm = 1.5964e-01, time/batch = 15.6138s	
14850/33250 (epoch 22.331), train_loss = 0.87791208, grad/param norm = 1.6140e-01, time/batch = 15.5578s	
14851/33250 (epoch 22.332), train_loss = 0.88354082, grad/param norm = 1.4412e-01, time/batch = 16.0441s	
14852/33250 (epoch 22.334), train_loss = 1.08099332, grad/param norm = 1.6548e-01, time/batch = 15.8004s	
14853/33250 (epoch 22.335), train_loss = 0.68955591, grad/param norm = 1.3709e-01, time/batch = 15.7228s	
14854/33250 (epoch 22.337), train_loss = 0.95513878, grad/param norm = 1.4604e-01, time/batch = 15.7819s	
14855/33250 (epoch 22.338), train_loss = 1.03680788, grad/param norm = 1.5314e-01, time/batch = 15.9465s	
14856/33250 (epoch 22.340), train_loss = 0.93208099, grad/param norm = 1.5325e-01, time/batch = 15.6863s	
14857/33250 (epoch 22.341), train_loss = 0.86966395, grad/param norm = 1.6364e-01, time/batch = 15.9424s	
14858/33250 (epoch 22.343), train_loss = 0.87450792, grad/param norm = 1.4506e-01, time/batch = 15.9204s	
14859/33250 (epoch 22.344), train_loss = 0.91082627, grad/param norm = 1.4601e-01, time/batch = 15.9301s	
14860/33250 (epoch 22.346), train_loss = 0.80955748, grad/param norm = 1.2768e-01, time/batch = 15.6214s	
14861/33250 (epoch 22.347), train_loss = 1.12983120, grad/param norm = 1.8906e-01, time/batch = 16.0588s	
14862/33250 (epoch 22.349), train_loss = 0.86947953, grad/param norm = 1.5901e-01, time/batch = 16.0325s	
14863/33250 (epoch 22.350), train_loss = 0.90208967, grad/param norm = 1.6768e-01, time/batch = 16.0382s	
14864/33250 (epoch 22.352), train_loss = 0.79220080, grad/param norm = 1.4878e-01, time/batch = 15.7218s	
14865/33250 (epoch 22.353), train_loss = 0.87775811, grad/param norm = 1.4023e-01, time/batch = 15.9551s	
14866/33250 (epoch 22.355), train_loss = 0.88704627, grad/param norm = 1.6943e-01, time/batch = 16.0004s	
14867/33250 (epoch 22.356), train_loss = 0.82405297, grad/param norm = 1.6270e-01, time/batch = 16.0805s	
14868/33250 (epoch 22.358), train_loss = 0.89234140, grad/param norm = 1.5200e-01, time/batch = 16.0106s	
14869/33250 (epoch 22.359), train_loss = 0.87166670, grad/param norm = 1.6046e-01, time/batch = 15.8558s	
14870/33250 (epoch 22.361), train_loss = 1.04967535, grad/param norm = 1.7759e-01, time/batch = 16.3858s	
14871/33250 (epoch 22.362), train_loss = 0.93263834, grad/param norm = 1.6807e-01, time/batch = 16.0451s	
14872/33250 (epoch 22.364), train_loss = 1.00440538, grad/param norm = 1.7201e-01, time/batch = 15.9729s	
14873/33250 (epoch 22.365), train_loss = 0.92347813, grad/param norm = 1.5197e-01, time/batch = 16.1218s	
14874/33250 (epoch 22.367), train_loss = 0.91637367, grad/param norm = 1.3537e-01, time/batch = 15.8918s	
14875/33250 (epoch 22.368), train_loss = 0.91666501, grad/param norm = 1.5683e-01, time/batch = 15.8803s	
14876/33250 (epoch 22.370), train_loss = 0.81258789, grad/param norm = 1.4170e-01, time/batch = 15.9534s	
14877/33250 (epoch 22.371), train_loss = 1.03126581, grad/param norm = 1.5821e-01, time/batch = 15.6964s	
14878/33250 (epoch 22.373), train_loss = 0.86237546, grad/param norm = 1.2459e-01, time/batch = 15.9404s	
14879/33250 (epoch 22.374), train_loss = 1.00774614, grad/param norm = 2.2092e-01, time/batch = 15.8658s	
14880/33250 (epoch 22.376), train_loss = 0.88001428, grad/param norm = 1.5089e-01, time/batch = 15.8569s	
14881/33250 (epoch 22.377), train_loss = 0.82585394, grad/param norm = 1.8265e-01, time/batch = 15.9998s	
14882/33250 (epoch 22.379), train_loss = 0.86595301, grad/param norm = 1.5602e-01, time/batch = 15.8219s	
14883/33250 (epoch 22.380), train_loss = 0.95480485, grad/param norm = 1.8201e-01, time/batch = 15.8345s	
14884/33250 (epoch 22.382), train_loss = 0.95084072, grad/param norm = 1.5624e-01, time/batch = 15.9825s	
14885/33250 (epoch 22.383), train_loss = 0.81619393, grad/param norm = 1.5075e-01, time/batch = 16.0095s	
14886/33250 (epoch 22.385), train_loss = 0.77414651, grad/param norm = 1.5020e-01, time/batch = 15.6175s	
14887/33250 (epoch 22.386), train_loss = 0.81362001, grad/param norm = 1.5997e-01, time/batch = 15.7585s	
14888/33250 (epoch 22.388), train_loss = 0.81388497, grad/param norm = 1.4119e-01, time/batch = 15.8402s	
14889/33250 (epoch 22.389), train_loss = 0.88123508, grad/param norm = 1.8889e-01, time/batch = 15.7417s	
14890/33250 (epoch 22.391), train_loss = 0.95238813, grad/param norm = 1.6626e-01, time/batch = 15.7576s	
14891/33250 (epoch 22.392), train_loss = 0.97774556, grad/param norm = 1.5977e-01, time/batch = 15.7720s	
14892/33250 (epoch 22.394), train_loss = 1.02925697, grad/param norm = 1.8151e-01, time/batch = 15.9486s	
14893/33250 (epoch 22.395), train_loss = 0.99706347, grad/param norm = 1.4534e-01, time/batch = 15.8723s	
14894/33250 (epoch 22.397), train_loss = 1.02827117, grad/param norm = 1.5971e-01, time/batch = 15.9546s	
14895/33250 (epoch 22.398), train_loss = 0.85782043, grad/param norm = 1.4619e-01, time/batch = 15.5661s	
14896/33250 (epoch 22.400), train_loss = 0.81691882, grad/param norm = 1.3367e-01, time/batch = 15.7691s	
14897/33250 (epoch 22.402), train_loss = 0.77332862, grad/param norm = 1.6394e-01, time/batch = 15.6853s	
14898/33250 (epoch 22.403), train_loss = 0.87272362, grad/param norm = 1.8050e-01, time/batch = 15.6136s	
14899/33250 (epoch 22.405), train_loss = 0.83467735, grad/param norm = 1.3684e-01, time/batch = 15.6983s	
14900/33250 (epoch 22.406), train_loss = 0.91919770, grad/param norm = 1.6047e-01, time/batch = 15.9202s	
14901/33250 (epoch 22.408), train_loss = 1.05940281, grad/param norm = 1.7041e-01, time/batch = 15.7000s	
14902/33250 (epoch 22.409), train_loss = 0.96933414, grad/param norm = 1.7785e-01, time/batch = 15.5512s	
14903/33250 (epoch 22.411), train_loss = 0.68261049, grad/param norm = 1.2320e-01, time/batch = 15.7057s	
14904/33250 (epoch 22.412), train_loss = 0.76927168, grad/param norm = 1.5549e-01, time/batch = 15.8698s	
14905/33250 (epoch 22.414), train_loss = 0.94406460, grad/param norm = 1.5249e-01, time/batch = 15.7768s	
14906/33250 (epoch 22.415), train_loss = 1.00244029, grad/param norm = 1.7378e-01, time/batch = 15.5447s	
14907/33250 (epoch 22.417), train_loss = 0.98703464, grad/param norm = 1.6679e-01, time/batch = 15.6953s	
14908/33250 (epoch 22.418), train_loss = 1.14205728, grad/param norm = 1.8924e-01, time/batch = 15.6097s	
14909/33250 (epoch 22.420), train_loss = 1.03516009, grad/param norm = 1.6381e-01, time/batch = 15.8435s	
14910/33250 (epoch 22.421), train_loss = 0.84817199, grad/param norm = 1.4432e-01, time/batch = 15.5360s	
14911/33250 (epoch 22.423), train_loss = 0.98309516, grad/param norm = 1.9689e-01, time/batch = 15.8624s	
14912/33250 (epoch 22.424), train_loss = 1.10018165, grad/param norm = 2.5937e-01, time/batch = 15.6998s	
14913/33250 (epoch 22.426), train_loss = 0.85055591, grad/param norm = 1.4245e-01, time/batch = 15.6347s	
14914/33250 (epoch 22.427), train_loss = 0.85442218, grad/param norm = 1.5629e-01, time/batch = 15.7989s	
14915/33250 (epoch 22.429), train_loss = 0.96884523, grad/param norm = 1.7767e-01, time/batch = 15.8535s	
14916/33250 (epoch 22.430), train_loss = 0.87142093, grad/param norm = 1.7079e-01, time/batch = 15.4618s	
14917/33250 (epoch 22.432), train_loss = 0.96380171, grad/param norm = 1.4135e-01, time/batch = 15.6853s	
14918/33250 (epoch 22.433), train_loss = 0.84659960, grad/param norm = 1.4193e-01, time/batch = 15.6830s	
14919/33250 (epoch 22.435), train_loss = 1.00298643, grad/param norm = 1.5487e-01, time/batch = 15.8273s	
14920/33250 (epoch 22.436), train_loss = 0.84434009, grad/param norm = 1.6249e-01, time/batch = 15.5312s	
14921/33250 (epoch 22.438), train_loss = 1.00524190, grad/param norm = 1.5508e-01, time/batch = 15.7166s	
14922/33250 (epoch 22.439), train_loss = 0.94282120, grad/param norm = 1.4740e-01, time/batch = 15.7717s	
14923/33250 (epoch 22.441), train_loss = 0.89304481, grad/param norm = 1.3645e-01, time/batch = 15.9195s	
14924/33250 (epoch 22.442), train_loss = 0.83308464, grad/param norm = 1.5021e-01, time/batch = 15.8612s	
14925/33250 (epoch 22.444), train_loss = 0.87336414, grad/param norm = 1.4911e-01, time/batch = 15.6984s	
14926/33250 (epoch 22.445), train_loss = 0.92097006, grad/param norm = 1.3554e-01, time/batch = 15.8673s	
14927/33250 (epoch 22.447), train_loss = 0.92145709, grad/param norm = 1.7582e-01, time/batch = 15.7899s	
14928/33250 (epoch 22.448), train_loss = 0.93705439, grad/param norm = 1.4144e-01, time/batch = 15.7020s	
14929/33250 (epoch 22.450), train_loss = 1.07500287, grad/param norm = 1.8113e-01, time/batch = 15.8522s	
14930/33250 (epoch 22.451), train_loss = 0.97013001, grad/param norm = 1.6662e-01, time/batch = 15.7801s	
14931/33250 (epoch 22.453), train_loss = 0.81527898, grad/param norm = 1.3708e-01, time/batch = 15.6873s	
14932/33250 (epoch 22.454), train_loss = 1.05504436, grad/param norm = 1.6424e-01, time/batch = 15.7764s	
14933/33250 (epoch 22.456), train_loss = 1.04967530, grad/param norm = 1.4330e-01, time/batch = 15.9497s	
14934/33250 (epoch 22.457), train_loss = 0.88177142, grad/param norm = 1.6393e-01, time/batch = 15.9305s	
14935/33250 (epoch 22.459), train_loss = 0.97526118, grad/param norm = 2.0339e-01, time/batch = 15.7955s	
14936/33250 (epoch 22.460), train_loss = 1.02136346, grad/param norm = 1.8066e-01, time/batch = 15.7215s	
14937/33250 (epoch 22.462), train_loss = 0.84263520, grad/param norm = 1.4137e-01, time/batch = 15.9685s	
14938/33250 (epoch 22.463), train_loss = 0.84828103, grad/param norm = 1.2504e-01, time/batch = 15.9379s	
14939/33250 (epoch 22.465), train_loss = 0.77385841, grad/param norm = 1.3263e-01, time/batch = 15.7745s	
14940/33250 (epoch 22.466), train_loss = 0.73757654, grad/param norm = 1.1572e-01, time/batch = 15.6230s	
14941/33250 (epoch 22.468), train_loss = 0.80726498, grad/param norm = 1.2832e-01, time/batch = 15.7605s	
14942/33250 (epoch 22.469), train_loss = 0.88367110, grad/param norm = 1.5728e-01, time/batch = 15.9867s	
14943/33250 (epoch 22.471), train_loss = 0.98027755, grad/param norm = 1.4529e-01, time/batch = 15.9142s	
14944/33250 (epoch 22.472), train_loss = 0.88883609, grad/param norm = 1.7950e-01, time/batch = 15.8436s	
14945/33250 (epoch 22.474), train_loss = 1.02807220, grad/param norm = 1.5694e-01, time/batch = 15.7708s	
14946/33250 (epoch 22.475), train_loss = 0.95071021, grad/param norm = 1.4859e-01, time/batch = 15.8001s	
14947/33250 (epoch 22.477), train_loss = 0.91830063, grad/param norm = 1.4559e-01, time/batch = 15.8839s	
14948/33250 (epoch 22.478), train_loss = 0.83523029, grad/param norm = 1.5018e-01, time/batch = 16.1287s	
14949/33250 (epoch 22.480), train_loss = 1.10301347, grad/param norm = 1.7261e-01, time/batch = 16.0441s	
14950/33250 (epoch 22.481), train_loss = 0.94818105, grad/param norm = 1.4889e-01, time/batch = 15.9456s	
14951/33250 (epoch 22.483), train_loss = 0.91624534, grad/param norm = 1.4206e-01, time/batch = 15.9512s	
14952/33250 (epoch 22.484), train_loss = 0.83606766, grad/param norm = 1.4775e-01, time/batch = 15.9399s	
14953/33250 (epoch 22.486), train_loss = 0.77889993, grad/param norm = 1.4955e-01, time/batch = 15.9290s	
14954/33250 (epoch 22.487), train_loss = 0.85490273, grad/param norm = 1.3998e-01, time/batch = 15.8726s	
14955/33250 (epoch 22.489), train_loss = 1.02626505, grad/param norm = 1.9140e-01, time/batch = 15.7064s	
14956/33250 (epoch 22.490), train_loss = 0.94122640, grad/param norm = 1.6406e-01, time/batch = 15.6895s	
14957/33250 (epoch 22.492), train_loss = 0.98240654, grad/param norm = 1.6339e-01, time/batch = 15.8778s	
14958/33250 (epoch 22.493), train_loss = 0.91916817, grad/param norm = 1.7626e-01, time/batch = 15.8656s	
14959/33250 (epoch 22.495), train_loss = 0.95308604, grad/param norm = 1.4013e-01, time/batch = 15.6348s	
14960/33250 (epoch 22.496), train_loss = 0.93249207, grad/param norm = 1.4238e-01, time/batch = 15.9098s	
14961/33250 (epoch 22.498), train_loss = 1.00138672, grad/param norm = 1.5328e-01, time/batch = 15.8527s	
14962/33250 (epoch 22.499), train_loss = 0.88350381, grad/param norm = 1.6079e-01, time/batch = 15.6988s	
14963/33250 (epoch 22.501), train_loss = 0.85373747, grad/param norm = 1.4938e-01, time/batch = 15.6258s	
14964/33250 (epoch 22.502), train_loss = 0.88997756, grad/param norm = 1.3752e-01, time/batch = 15.8559s	
14965/33250 (epoch 22.504), train_loss = 1.05661463, grad/param norm = 1.7549e-01, time/batch = 15.9607s	
14966/33250 (epoch 22.505), train_loss = 0.77270927, grad/param norm = 1.3014e-01, time/batch = 15.7628s	
14967/33250 (epoch 22.507), train_loss = 0.83944072, grad/param norm = 1.4416e-01, time/batch = 15.7100s	
14968/33250 (epoch 22.508), train_loss = 0.87796383, grad/param norm = 1.5632e-01, time/batch = 15.8585s	
14969/33250 (epoch 22.510), train_loss = 0.75778562, grad/param norm = 1.3656e-01, time/batch = 15.7213s	
14970/33250 (epoch 22.511), train_loss = 0.91703856, grad/param norm = 1.7039e-01, time/batch = 15.7286s	
14971/33250 (epoch 22.513), train_loss = 1.05377935, grad/param norm = 1.5838e-01, time/batch = 15.9455s	
14972/33250 (epoch 22.514), train_loss = 0.88938362, grad/param norm = 1.5426e-01, time/batch = 15.9362s	
14973/33250 (epoch 22.516), train_loss = 0.83898789, grad/param norm = 1.4398e-01, time/batch = 15.9341s	
14974/33250 (epoch 22.517), train_loss = 0.86952409, grad/param norm = 1.5945e-01, time/batch = 15.6211s	
14975/33250 (epoch 22.519), train_loss = 0.79390874, grad/param norm = 1.1428e-01, time/batch = 15.9126s	
14976/33250 (epoch 22.520), train_loss = 1.13949238, grad/param norm = 1.8981e-01, time/batch = 15.6011s	
14977/33250 (epoch 22.522), train_loss = 0.99252320, grad/param norm = 1.5411e-01, time/batch = 15.8500s	
14978/33250 (epoch 22.523), train_loss = 0.84207902, grad/param norm = 1.4014e-01, time/batch = 15.7865s	
14979/33250 (epoch 22.525), train_loss = 0.80098681, grad/param norm = 1.5644e-01, time/batch = 15.6773s	
14980/33250 (epoch 22.526), train_loss = 0.78873046, grad/param norm = 1.4511e-01, time/batch = 15.6850s	
14981/33250 (epoch 22.528), train_loss = 0.88880865, grad/param norm = 1.5419e-01, time/batch = 15.8007s	
14982/33250 (epoch 22.529), train_loss = 0.84056925, grad/param norm = 1.5660e-01, time/batch = 15.6996s	
14983/33250 (epoch 22.531), train_loss = 0.78704941, grad/param norm = 1.2789e-01, time/batch = 16.0870s	
14984/33250 (epoch 22.532), train_loss = 0.95267189, grad/param norm = 1.3915e-01, time/batch = 15.9369s	
14985/33250 (epoch 22.534), train_loss = 0.82915468, grad/param norm = 1.4289e-01, time/batch = 15.7891s	
14986/33250 (epoch 22.535), train_loss = 0.90482465, grad/param norm = 1.4545e-01, time/batch = 15.6145s	
14987/33250 (epoch 22.537), train_loss = 0.95951974, grad/param norm = 1.4577e-01, time/batch = 15.6934s	
14988/33250 (epoch 22.538), train_loss = 0.96954528, grad/param norm = 1.6287e-01, time/batch = 15.5474s	
14989/33250 (epoch 22.540), train_loss = 1.07182500, grad/param norm = 1.4542e-01, time/batch = 15.7100s	
14990/33250 (epoch 22.541), train_loss = 1.00340536, grad/param norm = 1.8338e-01, time/batch = 15.6367s	
14991/33250 (epoch 22.543), train_loss = 0.96857543, grad/param norm = 1.4262e-01, time/batch = 15.7931s	
14992/33250 (epoch 22.544), train_loss = 0.85658697, grad/param norm = 1.6143e-01, time/batch = 15.7060s	
14993/33250 (epoch 22.546), train_loss = 0.90555889, grad/param norm = 1.7246e-01, time/batch = 15.6137s	
14994/33250 (epoch 22.547), train_loss = 0.88648434, grad/param norm = 1.7115e-01, time/batch = 23.5010s	
14995/33250 (epoch 22.549), train_loss = 0.98957239, grad/param norm = 1.6585e-01, time/batch = 22.0924s	
14996/33250 (epoch 22.550), train_loss = 0.88088867, grad/param norm = 1.6012e-01, time/batch = 15.7732s	
14997/33250 (epoch 22.552), train_loss = 0.96470377, grad/param norm = 1.7140e-01, time/batch = 15.6746s	
14998/33250 (epoch 22.553), train_loss = 0.86866462, grad/param norm = 1.5209e-01, time/batch = 15.9379s	
14999/33250 (epoch 22.555), train_loss = 0.95924463, grad/param norm = 1.4964e-01, time/batch = 15.9979s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch22.56_1.5180.t7	
15000/33250 (epoch 22.556), train_loss = 0.96384532, grad/param norm = 1.8980e-01, time/batch = 15.7830s	
15001/33250 (epoch 22.558), train_loss = 1.32928806, grad/param norm = 1.9718e-01, time/batch = 16.1283s	
15002/33250 (epoch 22.559), train_loss = 0.84453348, grad/param norm = 1.4027e-01, time/batch = 16.0454s	
15003/33250 (epoch 22.561), train_loss = 0.81974821, grad/param norm = 1.3704e-01, time/batch = 15.9294s	
15004/33250 (epoch 22.562), train_loss = 1.00176962, grad/param norm = 1.5998e-01, time/batch = 15.7782s	
15005/33250 (epoch 22.564), train_loss = 1.11149686, grad/param norm = 1.8330e-01, time/batch = 15.7008s	
15006/33250 (epoch 22.565), train_loss = 1.04935889, grad/param norm = 1.8113e-01, time/batch = 15.7651s	
15007/33250 (epoch 22.567), train_loss = 1.03492203, grad/param norm = 1.6681e-01, time/batch = 15.8222s	
15008/33250 (epoch 22.568), train_loss = 0.92267583, grad/param norm = 1.6104e-01, time/batch = 15.6979s	
15009/33250 (epoch 22.570), train_loss = 1.01940420, grad/param norm = 1.8223e-01, time/batch = 15.9676s	
15010/33250 (epoch 22.571), train_loss = 1.05535824, grad/param norm = 1.6119e-01, time/batch = 16.2872s	
15011/33250 (epoch 22.573), train_loss = 0.96517786, grad/param norm = 1.6219e-01, time/batch = 16.1196s	
15012/33250 (epoch 22.574), train_loss = 0.83696519, grad/param norm = 1.3974e-01, time/batch = 15.7897s	
15013/33250 (epoch 22.576), train_loss = 0.97131333, grad/param norm = 1.6102e-01, time/batch = 15.6035s	
15014/33250 (epoch 22.577), train_loss = 0.91255450, grad/param norm = 1.4663e-01, time/batch = 15.6904s	
15015/33250 (epoch 22.579), train_loss = 0.84704485, grad/param norm = 2.4137e-01, time/batch = 15.6196s	
15016/33250 (epoch 22.580), train_loss = 0.87715360, grad/param norm = 1.2926e-01, time/batch = 15.7792s	
15017/33250 (epoch 22.582), train_loss = 0.89976203, grad/param norm = 1.5058e-01, time/batch = 15.6154s	
15018/33250 (epoch 22.583), train_loss = 1.00358618, grad/param norm = 1.4591e-01, time/batch = 15.8587s	
15019/33250 (epoch 22.585), train_loss = 1.01156794, grad/param norm = 1.4930e-01, time/batch = 15.8030s	
15020/33250 (epoch 22.586), train_loss = 0.85120841, grad/param norm = 1.7847e-01, time/batch = 15.9616s	
15021/33250 (epoch 22.588), train_loss = 0.94790397, grad/param norm = 1.5328e-01, time/batch = 15.9511s	
15022/33250 (epoch 22.589), train_loss = 0.94856652, grad/param norm = 1.4047e-01, time/batch = 15.8498s	
15023/33250 (epoch 22.591), train_loss = 0.93748455, grad/param norm = 1.7316e-01, time/batch = 15.6929s	
15024/33250 (epoch 22.592), train_loss = 0.91877153, grad/param norm = 1.5511e-01, time/batch = 15.7466s	
15025/33250 (epoch 22.594), train_loss = 1.04606736, grad/param norm = 1.8537e-01, time/batch = 15.8487s	
15026/33250 (epoch 22.595), train_loss = 0.96991678, grad/param norm = 1.6703e-01, time/batch = 15.7544s	
15027/33250 (epoch 22.597), train_loss = 0.78449266, grad/param norm = 1.3644e-01, time/batch = 15.6247s	
15028/33250 (epoch 22.598), train_loss = 0.88502444, grad/param norm = 1.5565e-01, time/batch = 15.7699s	
15029/33250 (epoch 22.600), train_loss = 0.89148202, grad/param norm = 1.7253e-01, time/batch = 15.7787s	
15030/33250 (epoch 22.602), train_loss = 0.93240296, grad/param norm = 1.8911e-01, time/batch = 15.7751s	
15031/33250 (epoch 22.603), train_loss = 0.95225472, grad/param norm = 1.5205e-01, time/batch = 15.7249s	
15032/33250 (epoch 22.605), train_loss = 0.94973723, grad/param norm = 1.6045e-01, time/batch = 15.7110s	
15033/33250 (epoch 22.606), train_loss = 0.98961233, grad/param norm = 1.6001e-01, time/batch = 15.7006s	
15034/33250 (epoch 22.608), train_loss = 0.93943137, grad/param norm = 1.5398e-01, time/batch = 15.5460s	
15035/33250 (epoch 22.609), train_loss = 0.85101131, grad/param norm = 1.4997e-01, time/batch = 15.7560s	
15036/33250 (epoch 22.611), train_loss = 0.96151606, grad/param norm = 1.5709e-01, time/batch = 15.6319s	
15037/33250 (epoch 22.612), train_loss = 0.91292064, grad/param norm = 1.5719e-01, time/batch = 15.6972s	
15038/33250 (epoch 22.614), train_loss = 1.15439733, grad/param norm = 1.9495e-01, time/batch = 15.5132s	
15039/33250 (epoch 22.615), train_loss = 1.02393699, grad/param norm = 1.5522e-01, time/batch = 15.4628s	
15040/33250 (epoch 22.617), train_loss = 1.15677022, grad/param norm = 1.7093e-01, time/batch = 15.6899s	
15041/33250 (epoch 22.618), train_loss = 1.19148692, grad/param norm = 2.1150e-01, time/batch = 15.7814s	
15042/33250 (epoch 22.620), train_loss = 1.01450886, grad/param norm = 1.7592e-01, time/batch = 15.6466s	
15043/33250 (epoch 22.621), train_loss = 0.98305881, grad/param norm = 1.6508e-01, time/batch = 15.7331s	
15044/33250 (epoch 22.623), train_loss = 0.84370061, grad/param norm = 1.5284e-01, time/batch = 15.5143s	
15045/33250 (epoch 22.624), train_loss = 0.92238704, grad/param norm = 1.8022e-01, time/batch = 15.7652s	
15046/33250 (epoch 22.626), train_loss = 0.89319728, grad/param norm = 1.7832e-01, time/batch = 15.8617s	
15047/33250 (epoch 22.627), train_loss = 0.88626166, grad/param norm = 1.5323e-01, time/batch = 15.6128s	
15048/33250 (epoch 22.629), train_loss = 0.98961178, grad/param norm = 1.8715e-01, time/batch = 15.6890s	
15049/33250 (epoch 22.630), train_loss = 0.89765714, grad/param norm = 1.9236e-01, time/batch = 15.7000s	
15050/33250 (epoch 22.632), train_loss = 0.77891825, grad/param norm = 1.4019e-01, time/batch = 15.6149s	
15051/33250 (epoch 22.633), train_loss = 0.92421410, grad/param norm = 1.5783e-01, time/batch = 15.7876s	
15052/33250 (epoch 22.635), train_loss = 0.83880064, grad/param norm = 1.4155e-01, time/batch = 15.8613s	
15053/33250 (epoch 22.636), train_loss = 0.85808110, grad/param norm = 1.3999e-01, time/batch = 15.7257s	
15054/33250 (epoch 22.638), train_loss = 0.85332656, grad/param norm = 1.5103e-01, time/batch = 15.7186s	
15055/33250 (epoch 22.639), train_loss = 0.77955107, grad/param norm = 1.4621e-01, time/batch = 15.8353s	
15056/33250 (epoch 22.641), train_loss = 0.88326224, grad/param norm = 1.5014e-01, time/batch = 15.8292s	
15057/33250 (epoch 22.642), train_loss = 0.75092943, grad/param norm = 1.6164e-01, time/batch = 15.7595s	
15058/33250 (epoch 22.644), train_loss = 0.66269471, grad/param norm = 1.3537e-01, time/batch = 15.7616s	
15059/33250 (epoch 22.645), train_loss = 0.99943572, grad/param norm = 1.8507e-01, time/batch = 15.8369s	
15060/33250 (epoch 22.647), train_loss = 0.80777848, grad/param norm = 1.6236e-01, time/batch = 15.6918s	
15061/33250 (epoch 22.648), train_loss = 0.82948585, grad/param norm = 1.7141e-01, time/batch = 15.8775s	
15062/33250 (epoch 22.650), train_loss = 1.05048570, grad/param norm = 1.6894e-01, time/batch = 15.8045s	
15063/33250 (epoch 22.651), train_loss = 0.97895804, grad/param norm = 1.8210e-01, time/batch = 15.9443s	
15064/33250 (epoch 22.653), train_loss = 0.84600515, grad/param norm = 1.5981e-01, time/batch = 15.9224s	
15065/33250 (epoch 22.654), train_loss = 0.90494276, grad/param norm = 1.4973e-01, time/batch = 15.8778s	
15066/33250 (epoch 22.656), train_loss = 0.94063369, grad/param norm = 1.4847e-01, time/batch = 15.6025s	
15067/33250 (epoch 22.657), train_loss = 0.73297226, grad/param norm = 1.6259e-01, time/batch = 15.7612s	
15068/33250 (epoch 22.659), train_loss = 0.84808432, grad/param norm = 1.4119e-01, time/batch = 15.8531s	
15069/33250 (epoch 22.660), train_loss = 0.91528431, grad/param norm = 1.6740e-01, time/batch = 15.7086s	
15070/33250 (epoch 22.662), train_loss = 0.91565565, grad/param norm = 1.5378e-01, time/batch = 15.6142s	
15071/33250 (epoch 22.663), train_loss = 0.82126346, grad/param norm = 1.4558e-01, time/batch = 15.9910s	
15072/33250 (epoch 22.665), train_loss = 0.93392570, grad/param norm = 1.4527e-01, time/batch = 15.8574s	
15073/33250 (epoch 22.666), train_loss = 0.87449914, grad/param norm = 1.5165e-01, time/batch = 15.7159s	
15074/33250 (epoch 22.668), train_loss = 1.05117373, grad/param norm = 1.6194e-01, time/batch = 15.7121s	
15075/33250 (epoch 22.669), train_loss = 0.93807363, grad/param norm = 1.5913e-01, time/batch = 15.8681s	
15076/33250 (epoch 22.671), train_loss = 0.83028888, grad/param norm = 1.5605e-01, time/batch = 15.6993s	
15077/33250 (epoch 22.672), train_loss = 0.99761865, grad/param norm = 1.6164e-01, time/batch = 15.6158s	
15078/33250 (epoch 22.674), train_loss = 0.79746792, grad/param norm = 1.4966e-01, time/batch = 15.8477s	
15079/33250 (epoch 22.675), train_loss = 0.90381130, grad/param norm = 1.4886e-01, time/batch = 15.9102s	
15080/33250 (epoch 22.677), train_loss = 0.99012375, grad/param norm = 1.6858e-01, time/batch = 15.8377s	
15081/33250 (epoch 22.678), train_loss = 0.87504827, grad/param norm = 1.5648e-01, time/batch = 16.0094s	
15082/33250 (epoch 22.680), train_loss = 0.98341642, grad/param norm = 1.7332e-01, time/batch = 15.8351s	
15083/33250 (epoch 22.681), train_loss = 0.80932545, grad/param norm = 1.4541e-01, time/batch = 15.8540s	
15084/33250 (epoch 22.683), train_loss = 0.88527951, grad/param norm = 1.6150e-01, time/batch = 15.7701s	
15085/33250 (epoch 22.684), train_loss = 0.81536191, grad/param norm = 1.6503e-01, time/batch = 15.6988s	
15086/33250 (epoch 22.686), train_loss = 0.83572419, grad/param norm = 1.5101e-01, time/batch = 16.0227s	
15087/33250 (epoch 22.687), train_loss = 0.92620230, grad/param norm = 1.5510e-01, time/batch = 15.7815s	
15088/33250 (epoch 22.689), train_loss = 0.82257347, grad/param norm = 1.5890e-01, time/batch = 15.7761s	
15089/33250 (epoch 22.690), train_loss = 0.91702911, grad/param norm = 1.5837e-01, time/batch = 15.8433s	
15090/33250 (epoch 22.692), train_loss = 0.88597668, grad/param norm = 1.3664e-01, time/batch = 15.9114s	
15091/33250 (epoch 22.693), train_loss = 0.98342344, grad/param norm = 1.5159e-01, time/batch = 15.7040s	
15092/33250 (epoch 22.695), train_loss = 0.92681562, grad/param norm = 1.5537e-01, time/batch = 15.5217s	
15093/33250 (epoch 22.696), train_loss = 0.95437664, grad/param norm = 1.4820e-01, time/batch = 15.8508s	
15094/33250 (epoch 22.698), train_loss = 0.85850686, grad/param norm = 1.5643e-01, time/batch = 15.8007s	
15095/33250 (epoch 22.699), train_loss = 1.11754652, grad/param norm = 1.6057e-01, time/batch = 15.8594s	
15096/33250 (epoch 22.701), train_loss = 0.91140434, grad/param norm = 1.3897e-01, time/batch = 15.7211s	
15097/33250 (epoch 22.702), train_loss = 0.87192996, grad/param norm = 1.7818e-01, time/batch = 15.7538s	
15098/33250 (epoch 22.704), train_loss = 1.08715922, grad/param norm = 2.4975e-01, time/batch = 15.6012s	
15099/33250 (epoch 22.705), train_loss = 0.86745913, grad/param norm = 1.5827e-01, time/batch = 15.7047s	
15100/33250 (epoch 22.707), train_loss = 0.76200752, grad/param norm = 1.4853e-01, time/batch = 15.7749s	
15101/33250 (epoch 22.708), train_loss = 1.00603364, grad/param norm = 1.6784e-01, time/batch = 15.9192s	
15102/33250 (epoch 22.710), train_loss = 0.98363784, grad/param norm = 1.8281e-01, time/batch = 15.5460s	
15103/33250 (epoch 22.711), train_loss = 0.83694839, grad/param norm = 1.5193e-01, time/batch = 15.3770s	
15104/33250 (epoch 22.713), train_loss = 0.95979896, grad/param norm = 1.5777e-01, time/batch = 15.4778s	
15105/33250 (epoch 22.714), train_loss = 0.91609308, grad/param norm = 1.5943e-01, time/batch = 15.7747s	
15106/33250 (epoch 22.716), train_loss = 0.95623208, grad/param norm = 1.5479e-01, time/batch = 15.4485s	
15107/33250 (epoch 22.717), train_loss = 0.84218462, grad/param norm = 1.3186e-01, time/batch = 15.5611s	
15108/33250 (epoch 22.719), train_loss = 0.87121661, grad/param norm = 1.4938e-01, time/batch = 15.6931s	
15109/33250 (epoch 22.720), train_loss = 1.16162575, grad/param norm = 1.8367e-01, time/batch = 15.6946s	
15110/33250 (epoch 22.722), train_loss = 0.80146297, grad/param norm = 1.3457e-01, time/batch = 15.3725s	
15111/33250 (epoch 22.723), train_loss = 0.72401436, grad/param norm = 1.2879e-01, time/batch = 15.6921s	
15112/33250 (epoch 22.725), train_loss = 0.80365036, grad/param norm = 1.2501e-01, time/batch = 15.5301s	
15113/33250 (epoch 22.726), train_loss = 0.89688871, grad/param norm = 1.5728e-01, time/batch = 15.5380s	
15114/33250 (epoch 22.728), train_loss = 0.95211232, grad/param norm = 1.7202e-01, time/batch = 15.5500s	
15115/33250 (epoch 22.729), train_loss = 1.00477940, grad/param norm = 1.5619e-01, time/batch = 15.5636s	
15116/33250 (epoch 22.731), train_loss = 0.85342869, grad/param norm = 1.5758e-01, time/batch = 15.6152s	
15117/33250 (epoch 22.732), train_loss = 0.81035532, grad/param norm = 1.3829e-01, time/batch = 15.6287s	
15118/33250 (epoch 22.734), train_loss = 0.95421056, grad/param norm = 1.6622e-01, time/batch = 15.6365s	
15119/33250 (epoch 22.735), train_loss = 0.92083808, grad/param norm = 1.4833e-01, time/batch = 15.7797s	
15120/33250 (epoch 22.737), train_loss = 0.87764277, grad/param norm = 1.3557e-01, time/batch = 15.4451s	
15121/33250 (epoch 22.738), train_loss = 0.93070489, grad/param norm = 1.4430e-01, time/batch = 16.0180s	
15122/33250 (epoch 22.740), train_loss = 1.01980287, grad/param norm = 1.5943e-01, time/batch = 15.6235s	
15123/33250 (epoch 22.741), train_loss = 0.97116865, grad/param norm = 1.5150e-01, time/batch = 15.5460s	
15124/33250 (epoch 22.743), train_loss = 0.84431350, grad/param norm = 1.2996e-01, time/batch = 15.6837s	
15125/33250 (epoch 22.744), train_loss = 0.88447635, grad/param norm = 1.7274e-01, time/batch = 15.9069s	
15126/33250 (epoch 22.746), train_loss = 0.82825619, grad/param norm = 1.4768e-01, time/batch = 15.5453s	
15127/33250 (epoch 22.747), train_loss = 0.84768501, grad/param norm = 1.5192e-01, time/batch = 15.4789s	
15128/33250 (epoch 22.749), train_loss = 1.00205079, grad/param norm = 1.7013e-01, time/batch = 15.7028s	
15129/33250 (epoch 22.750), train_loss = 0.98459906, grad/param norm = 1.5455e-01, time/batch = 15.7853s	
15130/33250 (epoch 22.752), train_loss = 0.88401787, grad/param norm = 1.5223e-01, time/batch = 15.7652s	
15131/33250 (epoch 22.753), train_loss = 0.88252249, grad/param norm = 1.7497e-01, time/batch = 15.6221s	
15132/33250 (epoch 22.755), train_loss = 0.88074291, grad/param norm = 1.6963e-01, time/batch = 15.8628s	
15133/33250 (epoch 22.756), train_loss = 0.94816746, grad/param norm = 1.7719e-01, time/batch = 15.7124s	
15134/33250 (epoch 22.758), train_loss = 1.04419638, grad/param norm = 1.5043e-01, time/batch = 15.9241s	
15135/33250 (epoch 22.759), train_loss = 0.83665584, grad/param norm = 1.3345e-01, time/batch = 15.9937s	
15136/33250 (epoch 22.761), train_loss = 0.90840779, grad/param norm = 1.5372e-01, time/batch = 15.9354s	
15137/33250 (epoch 22.762), train_loss = 1.01458831, grad/param norm = 1.8519e-01, time/batch = 15.7836s	
15138/33250 (epoch 22.764), train_loss = 0.83545650, grad/param norm = 1.8770e-01, time/batch = 15.6938s	
15139/33250 (epoch 22.765), train_loss = 0.96033935, grad/param norm = 1.6824e-01, time/batch = 15.9235s	
15140/33250 (epoch 22.767), train_loss = 0.74186999, grad/param norm = 1.4770e-01, time/batch = 15.9889s	
15141/33250 (epoch 22.768), train_loss = 0.76838926, grad/param norm = 1.5135e-01, time/batch = 16.1757s	
15142/33250 (epoch 22.770), train_loss = 0.94739521, grad/param norm = 1.6612e-01, time/batch = 15.8491s	
15143/33250 (epoch 22.771), train_loss = 0.99806889, grad/param norm = 1.8080e-01, time/batch = 15.9283s	
15144/33250 (epoch 22.773), train_loss = 0.87798202, grad/param norm = 1.5487e-01, time/batch = 15.8546s	
15145/33250 (epoch 22.774), train_loss = 0.76950066, grad/param norm = 1.5334e-01, time/batch = 16.0108s	
15146/33250 (epoch 22.776), train_loss = 0.85489498, grad/param norm = 1.4235e-01, time/batch = 16.0020s	
15147/33250 (epoch 22.777), train_loss = 1.02966919, grad/param norm = 2.0304e-01, time/batch = 15.8527s	
15148/33250 (epoch 22.779), train_loss = 0.90276384, grad/param norm = 1.5753e-01, time/batch = 15.8549s	
15149/33250 (epoch 22.780), train_loss = 1.06696188, grad/param norm = 1.8903e-01, time/batch = 15.9313s	
15150/33250 (epoch 22.782), train_loss = 0.92368305, grad/param norm = 1.6622e-01, time/batch = 15.8948s	
15151/33250 (epoch 22.783), train_loss = 0.77296964, grad/param norm = 1.3916e-01, time/batch = 15.9275s	
15152/33250 (epoch 22.785), train_loss = 0.79265809, grad/param norm = 1.4535e-01, time/batch = 15.9872s	
15153/33250 (epoch 22.786), train_loss = 1.01016644, grad/param norm = 1.6966e-01, time/batch = 15.9309s	
15154/33250 (epoch 22.788), train_loss = 0.99111558, grad/param norm = 1.5559e-01, time/batch = 16.0918s	
15155/33250 (epoch 22.789), train_loss = 1.01390976, grad/param norm = 1.7735e-01, time/batch = 15.9209s	
15156/33250 (epoch 22.791), train_loss = 1.08528435, grad/param norm = 1.7265e-01, time/batch = 15.9318s	
15157/33250 (epoch 22.792), train_loss = 1.11678121, grad/param norm = 1.6669e-01, time/batch = 15.8635s	
15158/33250 (epoch 22.794), train_loss = 0.89018616, grad/param norm = 1.6096e-01, time/batch = 16.0720s	
15159/33250 (epoch 22.795), train_loss = 0.93969992, grad/param norm = 1.6203e-01, time/batch = 15.9392s	
15160/33250 (epoch 22.797), train_loss = 1.00148125, grad/param norm = 1.9489e-01, time/batch = 15.7601s	
15161/33250 (epoch 22.798), train_loss = 0.92747759, grad/param norm = 2.0038e-01, time/batch = 16.0911s	
15162/33250 (epoch 22.800), train_loss = 0.96349738, grad/param norm = 1.8235e-01, time/batch = 15.9408s	
15163/33250 (epoch 22.802), train_loss = 0.89415760, grad/param norm = 1.3436e-01, time/batch = 15.7660s	
15164/33250 (epoch 22.803), train_loss = 0.94988707, grad/param norm = 1.4806e-01, time/batch = 15.9069s	
15165/33250 (epoch 22.805), train_loss = 0.94932486, grad/param norm = 1.6138e-01, time/batch = 15.8450s	
15166/33250 (epoch 22.806), train_loss = 0.92872823, grad/param norm = 1.5370e-01, time/batch = 15.7025s	
15167/33250 (epoch 22.808), train_loss = 0.86688667, grad/param norm = 1.3921e-01, time/batch = 15.6176s	
15168/33250 (epoch 22.809), train_loss = 0.83264510, grad/param norm = 1.4507e-01, time/batch = 15.6294s	
15169/33250 (epoch 22.811), train_loss = 0.85054363, grad/param norm = 1.5112e-01, time/batch = 15.7804s	
15170/33250 (epoch 22.812), train_loss = 0.97296870, grad/param norm = 1.6698e-01, time/batch = 15.8630s	
15171/33250 (epoch 22.814), train_loss = 0.91890770, grad/param norm = 1.6450e-01, time/batch = 15.5421s	
15172/33250 (epoch 22.815), train_loss = 0.96948278, grad/param norm = 1.4934e-01, time/batch = 15.3723s	
15173/33250 (epoch 22.817), train_loss = 0.91555257, grad/param norm = 1.6011e-01, time/batch = 15.8389s	
15174/33250 (epoch 22.818), train_loss = 0.83637547, grad/param norm = 1.5301e-01, time/batch = 15.5180s	
15175/33250 (epoch 22.820), train_loss = 0.93106448, grad/param norm = 1.5577e-01, time/batch = 15.4643s	
15176/33250 (epoch 22.821), train_loss = 0.89375248, grad/param norm = 1.3677e-01, time/batch = 15.4487s	
15177/33250 (epoch 22.823), train_loss = 1.26660888, grad/param norm = 2.0073e-01, time/batch = 15.8357s	
15178/33250 (epoch 22.824), train_loss = 0.87208818, grad/param norm = 1.7661e-01, time/batch = 15.4712s	
15179/33250 (epoch 22.826), train_loss = 0.95342674, grad/param norm = 1.6880e-01, time/batch = 15.7756s	
15180/33250 (epoch 22.827), train_loss = 0.76369178, grad/param norm = 1.5298e-01, time/batch = 15.6356s	
15181/33250 (epoch 22.829), train_loss = 0.93664029, grad/param norm = 2.2403e-01, time/batch = 15.9626s	
15182/33250 (epoch 22.830), train_loss = 1.01706131, grad/param norm = 1.9054e-01, time/batch = 15.4496s	
15183/33250 (epoch 22.832), train_loss = 0.93183103, grad/param norm = 1.6082e-01, time/batch = 15.8441s	
15184/33250 (epoch 22.833), train_loss = 0.93589046, grad/param norm = 1.6653e-01, time/batch = 15.8400s	
15185/33250 (epoch 22.835), train_loss = 0.83141614, grad/param norm = 1.6408e-01, time/batch = 15.4575s	
15186/33250 (epoch 22.836), train_loss = 0.89305209, grad/param norm = 1.6264e-01, time/batch = 15.4538s	
15187/33250 (epoch 22.838), train_loss = 0.92779839, grad/param norm = 1.4533e-01, time/batch = 15.4622s	
15188/33250 (epoch 22.839), train_loss = 0.88159910, grad/param norm = 1.4609e-01, time/batch = 15.4608s	
15189/33250 (epoch 22.841), train_loss = 0.84701665, grad/param norm = 1.5642e-01, time/batch = 15.6428s	
15190/33250 (epoch 22.842), train_loss = 1.07190021, grad/param norm = 1.5179e-01, time/batch = 15.5507s	
15191/33250 (epoch 22.844), train_loss = 1.04642152, grad/param norm = 1.7194e-01, time/batch = 15.5554s	
15192/33250 (epoch 22.845), train_loss = 1.09372333, grad/param norm = 1.7467e-01, time/batch = 15.9375s	
15193/33250 (epoch 22.847), train_loss = 1.07851589, grad/param norm = 1.6296e-01, time/batch = 15.7662s	
15194/33250 (epoch 22.848), train_loss = 1.16235172, grad/param norm = 1.7971e-01, time/batch = 15.7085s	
15195/33250 (epoch 22.850), train_loss = 1.00849249, grad/param norm = 1.5484e-01, time/batch = 15.5466s	
15196/33250 (epoch 22.851), train_loss = 0.82721988, grad/param norm = 1.7992e-01, time/batch = 15.9152s	
15197/33250 (epoch 22.853), train_loss = 0.97016559, grad/param norm = 1.6437e-01, time/batch = 15.8475s	
15198/33250 (epoch 22.854), train_loss = 0.85202114, grad/param norm = 1.4268e-01, time/batch = 15.8676s	
15199/33250 (epoch 22.856), train_loss = 0.87480644, grad/param norm = 1.6460e-01, time/batch = 15.6074s	
15200/33250 (epoch 22.857), train_loss = 0.80802582, grad/param norm = 1.5379e-01, time/batch = 15.8770s	
15201/33250 (epoch 22.859), train_loss = 0.81087420, grad/param norm = 1.4605e-01, time/batch = 15.9545s	
15202/33250 (epoch 22.860), train_loss = 0.93051856, grad/param norm = 1.4427e-01, time/batch = 16.0343s	
15203/33250 (epoch 22.862), train_loss = 0.82180219, grad/param norm = 1.5217e-01, time/batch = 15.6974s	
15204/33250 (epoch 22.863), train_loss = 0.87271187, grad/param norm = 1.6178e-01, time/batch = 15.8773s	
15205/33250 (epoch 22.865), train_loss = 0.95776354, grad/param norm = 1.5256e-01, time/batch = 15.8596s	
15206/33250 (epoch 22.866), train_loss = 0.84929412, grad/param norm = 1.6995e-01, time/batch = 15.7973s	
15207/33250 (epoch 22.868), train_loss = 0.97079003, grad/param norm = 1.9641e-01, time/batch = 15.6930s	
15208/33250 (epoch 22.869), train_loss = 0.94577561, grad/param norm = 1.7158e-01, time/batch = 15.6934s	
15209/33250 (epoch 22.871), train_loss = 0.73377591, grad/param norm = 1.4477e-01, time/batch = 15.7082s	
15210/33250 (epoch 22.872), train_loss = 0.96854710, grad/param norm = 1.7449e-01, time/batch = 15.7806s	
15211/33250 (epoch 22.874), train_loss = 0.82160789, grad/param norm = 1.5426e-01, time/batch = 29.2401s	
15212/33250 (epoch 22.875), train_loss = 0.82035190, grad/param norm = 1.6774e-01, time/batch = 16.6789s	
15213/33250 (epoch 22.877), train_loss = 1.04934843, grad/param norm = 1.6432e-01, time/batch = 15.4471s	
15214/33250 (epoch 22.878), train_loss = 0.94953511, grad/param norm = 1.5029e-01, time/batch = 15.7428s	
15215/33250 (epoch 22.880), train_loss = 0.90431601, grad/param norm = 1.9138e-01, time/batch = 15.5874s	
15216/33250 (epoch 22.881), train_loss = 1.02808529, grad/param norm = 1.6581e-01, time/batch = 15.6799s	
15217/33250 (epoch 22.883), train_loss = 0.93765046, grad/param norm = 1.6274e-01, time/batch = 15.9053s	
15218/33250 (epoch 22.884), train_loss = 0.97272276, grad/param norm = 1.7667e-01, time/batch = 15.9841s	
15219/33250 (epoch 22.886), train_loss = 0.84240513, grad/param norm = 1.2710e-01, time/batch = 15.5516s	
15220/33250 (epoch 22.887), train_loss = 0.89026638, grad/param norm = 1.6647e-01, time/batch = 15.6427s	
15221/33250 (epoch 22.889), train_loss = 0.85711034, grad/param norm = 1.3309e-01, time/batch = 15.8041s	
15222/33250 (epoch 22.890), train_loss = 0.73486685, grad/param norm = 1.2395e-01, time/batch = 15.5515s	
15223/33250 (epoch 22.892), train_loss = 0.96700771, grad/param norm = 1.4896e-01, time/batch = 15.4591s	
15224/33250 (epoch 22.893), train_loss = 0.96648655, grad/param norm = 1.6759e-01, time/batch = 15.3618s	
15225/33250 (epoch 22.895), train_loss = 0.86129275, grad/param norm = 1.6566e-01, time/batch = 15.5350s	
15226/33250 (epoch 22.896), train_loss = 1.01243806, grad/param norm = 1.6546e-01, time/batch = 27.8696s	
15227/33250 (epoch 22.898), train_loss = 0.92304446, grad/param norm = 1.5510e-01, time/batch = 33.1961s	
15228/33250 (epoch 22.899), train_loss = 0.84398290, grad/param norm = 1.4277e-01, time/batch = 28.8896s	
15229/33250 (epoch 22.901), train_loss = 0.77506419, grad/param norm = 1.2747e-01, time/batch = 33.1138s	
15230/33250 (epoch 22.902), train_loss = 0.88693907, grad/param norm = 1.5061e-01, time/batch = 31.1117s	
15231/33250 (epoch 22.904), train_loss = 0.82828159, grad/param norm = 1.3613e-01, time/batch = 31.8501s	
15232/33250 (epoch 22.905), train_loss = 0.86945635, grad/param norm = 1.4418e-01, time/batch = 29.9293s	
15233/33250 (epoch 22.907), train_loss = 0.82487945, grad/param norm = 1.6070e-01, time/batch = 30.7405s	
15234/33250 (epoch 22.908), train_loss = 0.90679557, grad/param norm = 1.4788e-01, time/batch = 32.3614s	
15235/33250 (epoch 22.910), train_loss = 0.97674767, grad/param norm = 1.5326e-01, time/batch = 32.6439s	
15236/33250 (epoch 22.911), train_loss = 0.80765242, grad/param norm = 1.3504e-01, time/batch = 31.0606s	
15237/33250 (epoch 22.913), train_loss = 0.86501633, grad/param norm = 1.4810e-01, time/batch = 31.8590s	
15238/33250 (epoch 22.914), train_loss = 0.78591533, grad/param norm = 1.6020e-01, time/batch = 29.9336s	
15239/33250 (epoch 22.916), train_loss = 0.84790487, grad/param norm = 1.5288e-01, time/batch = 24.6114s	
15240/33250 (epoch 22.917), train_loss = 0.87120318, grad/param norm = 1.2475e-01, time/batch = 25.8725s	
15241/33250 (epoch 22.919), train_loss = 0.83960737, grad/param norm = 1.5872e-01, time/batch = 27.0718s	
15242/33250 (epoch 22.920), train_loss = 0.89009393, grad/param norm = 1.5617e-01, time/batch = 31.1548s	
15243/33250 (epoch 22.922), train_loss = 0.93196802, grad/param norm = 1.7214e-01, time/batch = 31.9645s	
15244/33250 (epoch 22.923), train_loss = 0.85433174, grad/param norm = 1.5588e-01, time/batch = 31.6698s	
15245/33250 (epoch 22.925), train_loss = 0.87581872, grad/param norm = 1.5709e-01, time/batch = 32.6560s	
15246/33250 (epoch 22.926), train_loss = 0.86032630, grad/param norm = 1.3862e-01, time/batch = 29.0341s	
15247/33250 (epoch 22.928), train_loss = 0.87576875, grad/param norm = 1.6061e-01, time/batch = 17.4051s	
15248/33250 (epoch 22.929), train_loss = 0.75953429, grad/param norm = 1.2749e-01, time/batch = 15.5304s	
15249/33250 (epoch 22.931), train_loss = 0.99436957, grad/param norm = 1.5690e-01, time/batch = 16.2225s	
15250/33250 (epoch 22.932), train_loss = 0.88965319, grad/param norm = 1.6565e-01, time/batch = 15.9309s	
15251/33250 (epoch 22.934), train_loss = 0.82438812, grad/param norm = 1.2673e-01, time/batch = 16.0039s	
15252/33250 (epoch 22.935), train_loss = 0.83534926, grad/param norm = 1.7139e-01, time/batch = 15.6946s	
15253/33250 (epoch 22.937), train_loss = 0.85440260, grad/param norm = 1.7751e-01, time/batch = 15.8788s	
15254/33250 (epoch 22.938), train_loss = 0.92940015, grad/param norm = 1.8963e-01, time/batch = 15.8107s	
15255/33250 (epoch 22.940), train_loss = 0.89572412, grad/param norm = 1.7434e-01, time/batch = 16.0358s	
15256/33250 (epoch 22.941), train_loss = 0.97077270, grad/param norm = 1.6501e-01, time/batch = 15.6079s	
15257/33250 (epoch 22.943), train_loss = 1.04210177, grad/param norm = 1.6718e-01, time/batch = 15.7000s	
15258/33250 (epoch 22.944), train_loss = 0.87119413, grad/param norm = 1.6646e-01, time/batch = 15.6890s	
15259/33250 (epoch 22.946), train_loss = 0.99967069, grad/param norm = 1.5929e-01, time/batch = 15.7726s	
15260/33250 (epoch 22.947), train_loss = 0.83474666, grad/param norm = 1.5245e-01, time/batch = 15.5468s	
15261/33250 (epoch 22.949), train_loss = 0.97451954, grad/param norm = 1.7485e-01, time/batch = 15.9384s	
15262/33250 (epoch 22.950), train_loss = 0.95064919, grad/param norm = 1.4424e-01, time/batch = 15.8347s	
15263/33250 (epoch 22.952), train_loss = 0.89596042, grad/param norm = 1.8147e-01, time/batch = 16.0097s	
15264/33250 (epoch 22.953), train_loss = 0.96218070, grad/param norm = 1.5651e-01, time/batch = 16.2083s	
15265/33250 (epoch 22.955), train_loss = 1.01164224, grad/param norm = 1.7047e-01, time/batch = 15.9206s	
15266/33250 (epoch 22.956), train_loss = 0.95092963, grad/param norm = 2.0305e-01, time/batch = 15.6941s	
15267/33250 (epoch 22.958), train_loss = 0.84782614, grad/param norm = 1.4708e-01, time/batch = 15.7026s	
15268/33250 (epoch 22.959), train_loss = 0.85388017, grad/param norm = 1.4887e-01, time/batch = 15.5338s	
15269/33250 (epoch 22.961), train_loss = 1.08873022, grad/param norm = 1.6405e-01, time/batch = 15.5273s	
15270/33250 (epoch 22.962), train_loss = 0.90530810, grad/param norm = 1.6323e-01, time/batch = 16.1327s	
15271/33250 (epoch 22.964), train_loss = 1.09110240, grad/param norm = 1.8094e-01, time/batch = 15.9045s	
15272/33250 (epoch 22.965), train_loss = 0.97635759, grad/param norm = 1.7741e-01, time/batch = 15.6917s	
15273/33250 (epoch 22.967), train_loss = 0.94030297, grad/param norm = 1.6113e-01, time/batch = 15.3834s	
15274/33250 (epoch 22.968), train_loss = 1.06345504, grad/param norm = 1.5672e-01, time/batch = 16.0253s	
15275/33250 (epoch 22.970), train_loss = 1.18434077, grad/param norm = 2.1625e-01, time/batch = 15.6411s	
15276/33250 (epoch 22.971), train_loss = 1.05819826, grad/param norm = 1.8607e-01, time/batch = 15.8740s	
15277/33250 (epoch 22.973), train_loss = 0.89387082, grad/param norm = 1.6197e-01, time/batch = 15.2094s	
15278/33250 (epoch 22.974), train_loss = 0.99786048, grad/param norm = 1.6740e-01, time/batch = 15.5815s	
15279/33250 (epoch 22.976), train_loss = 0.88890932, grad/param norm = 1.8089e-01, time/batch = 16.0489s	
15280/33250 (epoch 22.977), train_loss = 0.88530349, grad/param norm = 1.5526e-01, time/batch = 15.3666s	
15281/33250 (epoch 22.979), train_loss = 0.95374072, grad/param norm = 1.8622e-01, time/batch = 16.2168s	
15282/33250 (epoch 22.980), train_loss = 0.96458133, grad/param norm = 1.5562e-01, time/batch = 16.4171s	
15283/33250 (epoch 22.982), train_loss = 0.84743345, grad/param norm = 1.4939e-01, time/batch = 15.8193s	
15284/33250 (epoch 22.983), train_loss = 0.95374725, grad/param norm = 1.7214e-01, time/batch = 15.6833s	
15285/33250 (epoch 22.985), train_loss = 0.87660200, grad/param norm = 1.5303e-01, time/batch = 20.4705s	
15286/33250 (epoch 22.986), train_loss = 1.00232667, grad/param norm = 1.9080e-01, time/batch = 18.4569s	
15287/33250 (epoch 22.988), train_loss = 1.02290100, grad/param norm = 1.6520e-01, time/batch = 18.2358s	
15288/33250 (epoch 22.989), train_loss = 1.00209451, grad/param norm = 1.9014e-01, time/batch = 19.2031s	
15289/33250 (epoch 22.991), train_loss = 0.94006111, grad/param norm = 1.5231e-01, time/batch = 18.7264s	
15290/33250 (epoch 22.992), train_loss = 0.88292043, grad/param norm = 1.6451e-01, time/batch = 18.8853s	
15291/33250 (epoch 22.994), train_loss = 0.89807950, grad/param norm = 1.4611e-01, time/batch = 19.2669s	
15292/33250 (epoch 22.995), train_loss = 0.88691967, grad/param norm = 2.0797e-01, time/batch = 19.3030s	
15293/33250 (epoch 22.997), train_loss = 0.64054783, grad/param norm = 1.1941e-01, time/batch = 18.8099s	
15294/33250 (epoch 22.998), train_loss = 0.95262787, grad/param norm = 1.5002e-01, time/batch = 18.1820s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
15295/33250 (epoch 23.000), train_loss = 0.90923182, grad/param norm = 1.4552e-01, time/batch = 18.6582s	
15296/33250 (epoch 23.002), train_loss = 1.08451198, grad/param norm = 1.6339e-01, time/batch = 19.2082s	
15297/33250 (epoch 23.003), train_loss = 1.00501120, grad/param norm = 1.7168e-01, time/batch = 18.8826s	
15298/33250 (epoch 23.005), train_loss = 0.75164907, grad/param norm = 1.4104e-01, time/batch = 18.9635s	
15299/33250 (epoch 23.006), train_loss = 0.78494906, grad/param norm = 1.4779e-01, time/batch = 19.1255s	
15300/33250 (epoch 23.008), train_loss = 1.06335618, grad/param norm = 1.6118e-01, time/batch = 18.7839s	
15301/33250 (epoch 23.009), train_loss = 1.07017233, grad/param norm = 1.6693e-01, time/batch = 19.6669s	
15302/33250 (epoch 23.011), train_loss = 0.84530608, grad/param norm = 1.5190e-01, time/batch = 19.1447s	
15303/33250 (epoch 23.012), train_loss = 0.92048214, grad/param norm = 1.7900e-01, time/batch = 18.8184s	
15304/33250 (epoch 23.014), train_loss = 1.03580209, grad/param norm = 1.7501e-01, time/batch = 19.3949s	
15305/33250 (epoch 23.015), train_loss = 0.91956479, grad/param norm = 1.4464e-01, time/batch = 25.8604s	
15306/33250 (epoch 23.017), train_loss = 0.91388808, grad/param norm = 1.6634e-01, time/batch = 17.4256s	
15307/33250 (epoch 23.018), train_loss = 0.75799141, grad/param norm = 1.4348e-01, time/batch = 16.0375s	
15308/33250 (epoch 23.020), train_loss = 0.91160120, grad/param norm = 1.3776e-01, time/batch = 15.7828s	
15309/33250 (epoch 23.021), train_loss = 0.96634795, grad/param norm = 1.6082e-01, time/batch = 15.7067s	
15310/33250 (epoch 23.023), train_loss = 0.78057984, grad/param norm = 1.7593e-01, time/batch = 16.0301s	
15311/33250 (epoch 23.024), train_loss = 0.99882674, grad/param norm = 1.4793e-01, time/batch = 15.9493s	
15312/33250 (epoch 23.026), train_loss = 0.93117497, grad/param norm = 1.4382e-01, time/batch = 15.6299s	
15313/33250 (epoch 23.027), train_loss = 0.92715638, grad/param norm = 1.4103e-01, time/batch = 15.7038s	
15314/33250 (epoch 23.029), train_loss = 0.92523048, grad/param norm = 1.4894e-01, time/batch = 15.7915s	
15315/33250 (epoch 23.030), train_loss = 0.91948426, grad/param norm = 1.6929e-01, time/batch = 15.9223s	
15316/33250 (epoch 23.032), train_loss = 1.12215857, grad/param norm = 1.9091e-01, time/batch = 15.6729s	
15317/33250 (epoch 23.033), train_loss = 0.88182262, grad/param norm = 1.7243e-01, time/batch = 15.6791s	
15318/33250 (epoch 23.035), train_loss = 0.90526084, grad/param norm = 1.8697e-01, time/batch = 16.0661s	
15319/33250 (epoch 23.036), train_loss = 0.96990896, grad/param norm = 1.5867e-01, time/batch = 15.8497s	
15320/33250 (epoch 23.038), train_loss = 0.90861232, grad/param norm = 1.3363e-01, time/batch = 15.7671s	
15321/33250 (epoch 23.039), train_loss = 0.82687807, grad/param norm = 1.4328e-01, time/batch = 15.8559s	
15322/33250 (epoch 23.041), train_loss = 0.93967800, grad/param norm = 1.8077e-01, time/batch = 16.0181s	
15323/33250 (epoch 23.042), train_loss = 0.76086885, grad/param norm = 1.3169e-01, time/batch = 15.7754s	
15324/33250 (epoch 23.044), train_loss = 1.05366303, grad/param norm = 1.7243e-01, time/batch = 15.6425s	
15325/33250 (epoch 23.045), train_loss = 1.02976251, grad/param norm = 1.5472e-01, time/batch = 15.8712s	
15326/33250 (epoch 23.047), train_loss = 0.91398274, grad/param norm = 1.6783e-01, time/batch = 15.9928s	
15327/33250 (epoch 23.048), train_loss = 1.04423256, grad/param norm = 1.8283e-01, time/batch = 15.9980s	
15328/33250 (epoch 23.050), train_loss = 0.90673391, grad/param norm = 1.4137e-01, time/batch = 15.8544s	
15329/33250 (epoch 23.051), train_loss = 0.91211036, grad/param norm = 1.5010e-01, time/batch = 15.7633s	
15330/33250 (epoch 23.053), train_loss = 0.92264794, grad/param norm = 1.8408e-01, time/batch = 15.9243s	
15331/33250 (epoch 23.054), train_loss = 0.80037379, grad/param norm = 1.4232e-01, time/batch = 16.4951s	
15332/33250 (epoch 23.056), train_loss = 0.82686531, grad/param norm = 1.4992e-01, time/batch = 16.1220s	
15333/33250 (epoch 23.057), train_loss = 0.99049748, grad/param norm = 1.3910e-01, time/batch = 15.8598s	
15334/33250 (epoch 23.059), train_loss = 0.89839938, grad/param norm = 1.5415e-01, time/batch = 15.8330s	
15335/33250 (epoch 23.060), train_loss = 0.94896737, grad/param norm = 1.6461e-01, time/batch = 15.6637s	
15336/33250 (epoch 23.062), train_loss = 1.02622263, grad/param norm = 1.8032e-01, time/batch = 15.6409s	
15337/33250 (epoch 23.063), train_loss = 1.06359907, grad/param norm = 1.5823e-01, time/batch = 16.0092s	
15338/33250 (epoch 23.065), train_loss = 0.94364627, grad/param norm = 1.5244e-01, time/batch = 15.8491s	
15339/33250 (epoch 23.066), train_loss = 0.96933455, grad/param norm = 1.5454e-01, time/batch = 16.0590s	
15340/33250 (epoch 23.068), train_loss = 0.88823132, grad/param norm = 2.0525e-01, time/batch = 15.6772s	
15341/33250 (epoch 23.069), train_loss = 0.92564314, grad/param norm = 1.5305e-01, time/batch = 16.3072s	
15342/33250 (epoch 23.071), train_loss = 0.84395927, grad/param norm = 1.4097e-01, time/batch = 16.0463s	
15343/33250 (epoch 23.072), train_loss = 0.83779861, grad/param norm = 1.4753e-01, time/batch = 16.0383s	
15344/33250 (epoch 23.074), train_loss = 0.98902140, grad/param norm = 1.6157e-01, time/batch = 16.0243s	
15345/33250 (epoch 23.075), train_loss = 0.86275730, grad/param norm = 1.4789e-01, time/batch = 15.8799s	
15346/33250 (epoch 23.077), train_loss = 0.92434305, grad/param norm = 1.7073e-01, time/batch = 16.0199s	
15347/33250 (epoch 23.078), train_loss = 0.94082645, grad/param norm = 1.5704e-01, time/batch = 15.8178s	
15348/33250 (epoch 23.080), train_loss = 0.93644200, grad/param norm = 1.9062e-01, time/batch = 15.6915s	
15349/33250 (epoch 23.081), train_loss = 0.95902872, grad/param norm = 1.5251e-01, time/batch = 15.5231s	
15350/33250 (epoch 23.083), train_loss = 1.03930568, grad/param norm = 1.5870e-01, time/batch = 15.6758s	
15351/33250 (epoch 23.084), train_loss = 0.90841692, grad/param norm = 1.6289e-01, time/batch = 16.0174s	
15352/33250 (epoch 23.086), train_loss = 0.89564709, grad/param norm = 1.5182e-01, time/batch = 16.1012s	
15353/33250 (epoch 23.087), train_loss = 0.80233097, grad/param norm = 1.3818e-01, time/batch = 15.9523s	
15354/33250 (epoch 23.089), train_loss = 0.95568042, grad/param norm = 1.5457e-01, time/batch = 16.0357s	
15355/33250 (epoch 23.090), train_loss = 0.94333317, grad/param norm = 1.5486e-01, time/batch = 16.2733s	
15356/33250 (epoch 23.092), train_loss = 0.86640633, grad/param norm = 1.4350e-01, time/batch = 15.8697s	
15357/33250 (epoch 23.093), train_loss = 0.92395256, grad/param norm = 1.5521e-01, time/batch = 15.9394s	
15358/33250 (epoch 23.095), train_loss = 0.89533788, grad/param norm = 1.5046e-01, time/batch = 15.9976s	
15359/33250 (epoch 23.096), train_loss = 0.79006637, grad/param norm = 1.5950e-01, time/batch = 16.0015s	
15360/33250 (epoch 23.098), train_loss = 0.80659622, grad/param norm = 1.6881e-01, time/batch = 15.9151s	
15361/33250 (epoch 23.099), train_loss = 0.70235925, grad/param norm = 1.3824e-01, time/batch = 16.0801s	
15362/33250 (epoch 23.101), train_loss = 0.91429429, grad/param norm = 1.5272e-01, time/batch = 15.9329s	
15363/33250 (epoch 23.102), train_loss = 0.84301901, grad/param norm = 1.4279e-01, time/batch = 16.0116s	
15364/33250 (epoch 23.104), train_loss = 0.70541821, grad/param norm = 1.2929e-01, time/batch = 15.7771s	
15365/33250 (epoch 23.105), train_loss = 0.86877476, grad/param norm = 1.5310e-01, time/batch = 15.7110s	
15366/33250 (epoch 23.107), train_loss = 0.77491518, grad/param norm = 1.2956e-01, time/batch = 15.9458s	
15367/33250 (epoch 23.108), train_loss = 0.92576442, grad/param norm = 1.6336e-01, time/batch = 15.6932s	
15368/33250 (epoch 23.110), train_loss = 0.75790012, grad/param norm = 1.3320e-01, time/batch = 15.8327s	
15369/33250 (epoch 23.111), train_loss = 0.88373078, grad/param norm = 1.5429e-01, time/batch = 16.1607s	
15370/33250 (epoch 23.113), train_loss = 0.86382362, grad/param norm = 1.5148e-01, time/batch = 16.0782s	
15371/33250 (epoch 23.114), train_loss = 0.80818885, grad/param norm = 1.5649e-01, time/batch = 15.8083s	
15372/33250 (epoch 23.116), train_loss = 0.90442057, grad/param norm = 1.6186e-01, time/batch = 15.8230s	
15373/33250 (epoch 23.117), train_loss = 0.84777932, grad/param norm = 1.5500e-01, time/batch = 15.9140s	
15374/33250 (epoch 23.119), train_loss = 0.85980902, grad/param norm = 1.5325e-01, time/batch = 15.7604s	
15375/33250 (epoch 23.120), train_loss = 0.69466324, grad/param norm = 1.2706e-01, time/batch = 18.5898s	
15376/33250 (epoch 23.122), train_loss = 0.98670723, grad/param norm = 1.5105e-01, time/batch = 15.6129s	
15377/33250 (epoch 23.123), train_loss = 0.89286529, grad/param norm = 1.6054e-01, time/batch = 16.0145s	
15378/33250 (epoch 23.125), train_loss = 0.74236718, grad/param norm = 1.5159e-01, time/batch = 15.8043s	
15379/33250 (epoch 23.126), train_loss = 0.89075811, grad/param norm = 1.5776e-01, time/batch = 17.0082s	
15380/33250 (epoch 23.128), train_loss = 0.84228916, grad/param norm = 1.3945e-01, time/batch = 17.5047s	
15381/33250 (epoch 23.129), train_loss = 0.90275535, grad/param norm = 1.5487e-01, time/batch = 15.1811s	
15382/33250 (epoch 23.131), train_loss = 0.86716114, grad/param norm = 1.4754e-01, time/batch = 15.3681s	
15383/33250 (epoch 23.132), train_loss = 0.88999487, grad/param norm = 1.6184e-01, time/batch = 15.2047s	
15384/33250 (epoch 23.134), train_loss = 0.89718305, grad/param norm = 1.7142e-01, time/batch = 16.2086s	
15385/33250 (epoch 23.135), train_loss = 0.88334326, grad/param norm = 1.4075e-01, time/batch = 15.5598s	
15386/33250 (epoch 23.137), train_loss = 0.81261638, grad/param norm = 1.6741e-01, time/batch = 17.6923s	
15387/33250 (epoch 23.138), train_loss = 0.83894348, grad/param norm = 1.3737e-01, time/batch = 17.5273s	
15388/33250 (epoch 23.140), train_loss = 0.72067347, grad/param norm = 1.5440e-01, time/batch = 16.5317s	
15389/33250 (epoch 23.141), train_loss = 1.01455329, grad/param norm = 2.0154e-01, time/batch = 16.6130s	
15390/33250 (epoch 23.143), train_loss = 0.72247598, grad/param norm = 1.6681e-01, time/batch = 17.0214s	
15391/33250 (epoch 23.144), train_loss = 0.86125239, grad/param norm = 1.5687e-01, time/batch = 15.2610s	
15392/33250 (epoch 23.146), train_loss = 0.84936663, grad/param norm = 1.4301e-01, time/batch = 16.9169s	
15393/33250 (epoch 23.147), train_loss = 0.86226741, grad/param norm = 1.5381e-01, time/batch = 18.0983s	
15394/33250 (epoch 23.149), train_loss = 0.82247520, grad/param norm = 1.4598e-01, time/batch = 17.0392s	
15395/33250 (epoch 23.150), train_loss = 0.79065343, grad/param norm = 1.4129e-01, time/batch = 18.1218s	
15396/33250 (epoch 23.152), train_loss = 0.76604614, grad/param norm = 1.4662e-01, time/batch = 15.6099s	
15397/33250 (epoch 23.153), train_loss = 1.02670033, grad/param norm = 1.6586e-01, time/batch = 17.7737s	
15398/33250 (epoch 23.155), train_loss = 0.88325760, grad/param norm = 1.8200e-01, time/batch = 16.2840s	
15399/33250 (epoch 23.156), train_loss = 1.06889865, grad/param norm = 1.6045e-01, time/batch = 16.2717s	
15400/33250 (epoch 23.158), train_loss = 1.07417736, grad/param norm = 1.6633e-01, time/batch = 15.6820s	
15401/33250 (epoch 23.159), train_loss = 0.88777212, grad/param norm = 1.5805e-01, time/batch = 15.7826s	
15402/33250 (epoch 23.161), train_loss = 0.95610763, grad/param norm = 1.5878e-01, time/batch = 14.7278s	
15403/33250 (epoch 23.162), train_loss = 0.80726743, grad/param norm = 1.3476e-01, time/batch = 15.9321s	
15404/33250 (epoch 23.164), train_loss = 0.87863807, grad/param norm = 1.6036e-01, time/batch = 18.5214s	
15405/33250 (epoch 23.165), train_loss = 0.95055554, grad/param norm = 1.5445e-01, time/batch = 18.2786s	
15406/33250 (epoch 23.167), train_loss = 1.05227603, grad/param norm = 1.7496e-01, time/batch = 16.3399s	
15407/33250 (epoch 23.168), train_loss = 0.75094302, grad/param norm = 1.2667e-01, time/batch = 18.4580s	
15408/33250 (epoch 23.170), train_loss = 0.86205085, grad/param norm = 1.5107e-01, time/batch = 18.5812s	
15409/33250 (epoch 23.171), train_loss = 0.87661352, grad/param norm = 1.5100e-01, time/batch = 15.9527s	
15410/33250 (epoch 23.173), train_loss = 0.83409531, grad/param norm = 1.4067e-01, time/batch = 23.1351s	
15411/33250 (epoch 23.174), train_loss = 0.90202464, grad/param norm = 1.4594e-01, time/batch = 27.1300s	
15412/33250 (epoch 23.176), train_loss = 0.86856629, grad/param norm = 1.6714e-01, time/batch = 15.5030s	
15413/33250 (epoch 23.177), train_loss = 0.85657399, grad/param norm = 1.4367e-01, time/batch = 16.6764s	
15414/33250 (epoch 23.179), train_loss = 0.80401403, grad/param norm = 1.4720e-01, time/batch = 18.0533s	
15415/33250 (epoch 23.180), train_loss = 0.74286419, grad/param norm = 1.4068e-01, time/batch = 16.1613s	
15416/33250 (epoch 23.182), train_loss = 0.83622908, grad/param norm = 1.6202e-01, time/batch = 15.2806s	
15417/33250 (epoch 23.183), train_loss = 1.01695227, grad/param norm = 1.8062e-01, time/batch = 15.8612s	
15418/33250 (epoch 23.185), train_loss = 0.95336448, grad/param norm = 1.8079e-01, time/batch = 15.1945s	
15419/33250 (epoch 23.186), train_loss = 0.92666345, grad/param norm = 1.5082e-01, time/batch = 16.1930s	
15420/33250 (epoch 23.188), train_loss = 1.01398662, grad/param norm = 1.8339e-01, time/batch = 15.3453s	
15421/33250 (epoch 23.189), train_loss = 0.74593112, grad/param norm = 1.8455e-01, time/batch = 17.8557s	
15422/33250 (epoch 23.191), train_loss = 0.82480210, grad/param norm = 1.5989e-01, time/batch = 15.9369s	
15423/33250 (epoch 23.192), train_loss = 0.84914110, grad/param norm = 1.4398e-01, time/batch = 17.4158s	
15424/33250 (epoch 23.194), train_loss = 0.87244395, grad/param norm = 1.5413e-01, time/batch = 16.3775s	
15425/33250 (epoch 23.195), train_loss = 1.06606348, grad/param norm = 1.5471e-01, time/batch = 17.2067s	
15426/33250 (epoch 23.197), train_loss = 0.83484247, grad/param norm = 1.6296e-01, time/batch = 16.7024s	
15427/33250 (epoch 23.198), train_loss = 1.00399138, grad/param norm = 1.5862e-01, time/batch = 18.2391s	
15428/33250 (epoch 23.200), train_loss = 0.90277035, grad/param norm = 1.5060e-01, time/batch = 16.6653s	
15429/33250 (epoch 23.202), train_loss = 0.83910517, grad/param norm = 1.4533e-01, time/batch = 15.2045s	
15430/33250 (epoch 23.203), train_loss = 0.82224231, grad/param norm = 1.5641e-01, time/batch = 17.7370s	
15431/33250 (epoch 23.205), train_loss = 0.93645595, grad/param norm = 1.5627e-01, time/batch = 15.5934s	
15432/33250 (epoch 23.206), train_loss = 0.96703053, grad/param norm = 1.6140e-01, time/batch = 14.9616s	
15433/33250 (epoch 23.208), train_loss = 1.00818458, grad/param norm = 1.7554e-01, time/batch = 15.7684s	
15434/33250 (epoch 23.209), train_loss = 0.80689657, grad/param norm = 1.3992e-01, time/batch = 15.6063s	
15435/33250 (epoch 23.211), train_loss = 0.95642544, grad/param norm = 1.5757e-01, time/batch = 15.3977s	
15436/33250 (epoch 23.212), train_loss = 1.09794126, grad/param norm = 1.6284e-01, time/batch = 17.7877s	
15437/33250 (epoch 23.214), train_loss = 0.90780737, grad/param norm = 1.4315e-01, time/batch = 16.6924s	
15438/33250 (epoch 23.215), train_loss = 1.02084202, grad/param norm = 2.0279e-01, time/batch = 15.1227s	
15439/33250 (epoch 23.217), train_loss = 1.01710201, grad/param norm = 1.7214e-01, time/batch = 16.2711s	
15440/33250 (epoch 23.218), train_loss = 0.99350220, grad/param norm = 1.5270e-01, time/batch = 15.5095s	
15441/33250 (epoch 23.220), train_loss = 0.92796836, grad/param norm = 1.6947e-01, time/batch = 15.7587s	
15442/33250 (epoch 23.221), train_loss = 1.08404699, grad/param norm = 1.8266e-01, time/batch = 16.2460s	
15443/33250 (epoch 23.223), train_loss = 0.90604106, grad/param norm = 1.4477e-01, time/batch = 18.0265s	
15444/33250 (epoch 23.224), train_loss = 0.96063080, grad/param norm = 1.7770e-01, time/batch = 16.6794s	
15445/33250 (epoch 23.226), train_loss = 1.03057075, grad/param norm = 1.6123e-01, time/batch = 16.5899s	
15446/33250 (epoch 23.227), train_loss = 0.94851056, grad/param norm = 1.5989e-01, time/batch = 18.5328s	
15447/33250 (epoch 23.229), train_loss = 0.92393056, grad/param norm = 1.4114e-01, time/batch = 16.6222s	
15448/33250 (epoch 23.230), train_loss = 0.90668649, grad/param norm = 1.5847e-01, time/batch = 17.9545s	
15449/33250 (epoch 23.232), train_loss = 0.87498603, grad/param norm = 1.4188e-01, time/batch = 16.1641s	
15450/33250 (epoch 23.233), train_loss = 0.82899729, grad/param norm = 1.4523e-01, time/batch = 18.9169s	
15451/33250 (epoch 23.235), train_loss = 1.04628733, grad/param norm = 1.4909e-01, time/batch = 16.6931s	
15452/33250 (epoch 23.236), train_loss = 0.84441624, grad/param norm = 1.5017e-01, time/batch = 16.6837s	
15453/33250 (epoch 23.238), train_loss = 1.03125032, grad/param norm = 1.6619e-01, time/batch = 17.0038s	
15454/33250 (epoch 23.239), train_loss = 1.04541031, grad/param norm = 1.7926e-01, time/batch = 16.1780s	
15455/33250 (epoch 23.241), train_loss = 1.01452526, grad/param norm = 1.9714e-01, time/batch = 18.9379s	
15456/33250 (epoch 23.242), train_loss = 1.00301325, grad/param norm = 1.6583e-01, time/batch = 17.9675s	
15457/33250 (epoch 23.244), train_loss = 0.98545999, grad/param norm = 2.8037e-01, time/batch = 18.0986s	
15458/33250 (epoch 23.245), train_loss = 0.95383330, grad/param norm = 1.6646e-01, time/batch = 16.6670s	
15459/33250 (epoch 23.247), train_loss = 0.92981344, grad/param norm = 1.6031e-01, time/batch = 17.4238s	
15460/33250 (epoch 23.248), train_loss = 1.12113363, grad/param norm = 1.8495e-01, time/batch = 17.1751s	
15461/33250 (epoch 23.250), train_loss = 1.01586601, grad/param norm = 1.5669e-01, time/batch = 17.1080s	
15462/33250 (epoch 23.251), train_loss = 0.90288956, grad/param norm = 1.5057e-01, time/batch = 18.1417s	
15463/33250 (epoch 23.253), train_loss = 0.85843514, grad/param norm = 1.4098e-01, time/batch = 15.7511s	
15464/33250 (epoch 23.254), train_loss = 0.86049791, grad/param norm = 1.5523e-01, time/batch = 18.5263s	
15465/33250 (epoch 23.256), train_loss = 0.92307693, grad/param norm = 1.4160e-01, time/batch = 18.9630s	
15466/33250 (epoch 23.257), train_loss = 1.03782254, grad/param norm = 1.7066e-01, time/batch = 15.3612s	
15467/33250 (epoch 23.259), train_loss = 0.97176965, grad/param norm = 1.6290e-01, time/batch = 19.6049s	
15468/33250 (epoch 23.260), train_loss = 0.78997429, grad/param norm = 1.5082e-01, time/batch = 17.4278s	
15469/33250 (epoch 23.262), train_loss = 0.93041325, grad/param norm = 1.5385e-01, time/batch = 16.4411s	
15470/33250 (epoch 23.263), train_loss = 0.81230522, grad/param norm = 1.4899e-01, time/batch = 17.3598s	
15471/33250 (epoch 23.265), train_loss = 0.98366034, grad/param norm = 1.6780e-01, time/batch = 16.6868s	
15472/33250 (epoch 23.266), train_loss = 0.89135575, grad/param norm = 1.6959e-01, time/batch = 18.5920s	
15473/33250 (epoch 23.268), train_loss = 0.81669332, grad/param norm = 1.4727e-01, time/batch = 17.7672s	
15474/33250 (epoch 23.269), train_loss = 0.74299911, grad/param norm = 1.4516e-01, time/batch = 16.8591s	
15475/33250 (epoch 23.271), train_loss = 0.91500996, grad/param norm = 1.5105e-01, time/batch = 16.3491s	
15476/33250 (epoch 23.272), train_loss = 0.82131140, grad/param norm = 1.3749e-01, time/batch = 17.9338s	
15477/33250 (epoch 23.274), train_loss = 0.68479073, grad/param norm = 1.3245e-01, time/batch = 19.2687s	
15478/33250 (epoch 23.275), train_loss = 0.82340547, grad/param norm = 1.2829e-01, time/batch = 16.3579s	
15479/33250 (epoch 23.277), train_loss = 0.72687660, grad/param norm = 1.7265e-01, time/batch = 17.4356s	
15480/33250 (epoch 23.278), train_loss = 0.82805965, grad/param norm = 1.4821e-01, time/batch = 16.6894s	
15481/33250 (epoch 23.280), train_loss = 0.81343081, grad/param norm = 1.4080e-01, time/batch = 17.2734s	
15482/33250 (epoch 23.281), train_loss = 0.93553518, grad/param norm = 1.5077e-01, time/batch = 17.0320s	
15483/33250 (epoch 23.283), train_loss = 0.96102719, grad/param norm = 2.4340e-01, time/batch = 15.9297s	
15484/33250 (epoch 23.284), train_loss = 0.82067368, grad/param norm = 1.7249e-01, time/batch = 17.8359s	
15485/33250 (epoch 23.286), train_loss = 0.96624615, grad/param norm = 1.6348e-01, time/batch = 18.4130s	
15486/33250 (epoch 23.287), train_loss = 0.78560399, grad/param norm = 1.4177e-01, time/batch = 17.4638s	
15487/33250 (epoch 23.289), train_loss = 0.73937705, grad/param norm = 1.5785e-01, time/batch = 16.2910s	
15488/33250 (epoch 23.290), train_loss = 0.89986993, grad/param norm = 1.6647e-01, time/batch = 17.6134s	
15489/33250 (epoch 23.292), train_loss = 0.95285979, grad/param norm = 1.9175e-01, time/batch = 16.3700s	
15490/33250 (epoch 23.293), train_loss = 1.00953157, grad/param norm = 1.6840e-01, time/batch = 15.7771s	
15491/33250 (epoch 23.295), train_loss = 0.97452253, grad/param norm = 1.6102e-01, time/batch = 18.4261s	
15492/33250 (epoch 23.296), train_loss = 0.92991910, grad/param norm = 1.7344e-01, time/batch = 17.3482s	
15493/33250 (epoch 23.298), train_loss = 0.75832001, grad/param norm = 1.3782e-01, time/batch = 17.5013s	
15494/33250 (epoch 23.299), train_loss = 0.73945328, grad/param norm = 1.5137e-01, time/batch = 18.1947s	
15495/33250 (epoch 23.301), train_loss = 0.98079524, grad/param norm = 1.4778e-01, time/batch = 18.6159s	
15496/33250 (epoch 23.302), train_loss = 0.97386801, grad/param norm = 1.5737e-01, time/batch = 17.2816s	
15497/33250 (epoch 23.304), train_loss = 0.82674718, grad/param norm = 1.4913e-01, time/batch = 17.2470s	
15498/33250 (epoch 23.305), train_loss = 0.85956188, grad/param norm = 1.4928e-01, time/batch = 16.6068s	
15499/33250 (epoch 23.307), train_loss = 0.94975082, grad/param norm = 1.6586e-01, time/batch = 16.0055s	
15500/33250 (epoch 23.308), train_loss = 1.03916743, grad/param norm = 1.9385e-01, time/batch = 16.0351s	
15501/33250 (epoch 23.310), train_loss = 0.88864763, grad/param norm = 1.6950e-01, time/batch = 15.8470s	
15502/33250 (epoch 23.311), train_loss = 1.02850167, grad/param norm = 1.7926e-01, time/batch = 17.7685s	
15503/33250 (epoch 23.313), train_loss = 0.78133186, grad/param norm = 1.5078e-01, time/batch = 17.3468s	
15504/33250 (epoch 23.314), train_loss = 0.91952111, grad/param norm = 1.5515e-01, time/batch = 17.1133s	
15505/33250 (epoch 23.316), train_loss = 1.06155059, grad/param norm = 1.7479e-01, time/batch = 16.2792s	
15506/33250 (epoch 23.317), train_loss = 0.79711552, grad/param norm = 1.3439e-01, time/batch = 19.1105s	
15507/33250 (epoch 23.319), train_loss = 0.97865054, grad/param norm = 2.0566e-01, time/batch = 17.2130s	
15508/33250 (epoch 23.320), train_loss = 1.00476674, grad/param norm = 1.9407e-01, time/batch = 17.5075s	
15509/33250 (epoch 23.322), train_loss = 1.02541918, grad/param norm = 1.6152e-01, time/batch = 16.3458s	
15510/33250 (epoch 23.323), train_loss = 1.11258496, grad/param norm = 2.1323e-01, time/batch = 18.4237s	
15511/33250 (epoch 23.325), train_loss = 0.93377242, grad/param norm = 1.8233e-01, time/batch = 16.9424s	
15512/33250 (epoch 23.326), train_loss = 1.06501210, grad/param norm = 1.6441e-01, time/batch = 18.0803s	
15513/33250 (epoch 23.328), train_loss = 0.87103942, grad/param norm = 1.3754e-01, time/batch = 17.4430s	
15514/33250 (epoch 23.329), train_loss = 0.92250472, grad/param norm = 1.7197e-01, time/batch = 17.7625s	
15515/33250 (epoch 23.331), train_loss = 0.87432092, grad/param norm = 1.5924e-01, time/batch = 19.3576s	
15516/33250 (epoch 23.332), train_loss = 0.87309475, grad/param norm = 1.3742e-01, time/batch = 16.7916s	
15517/33250 (epoch 23.334), train_loss = 1.08138848, grad/param norm = 1.6564e-01, time/batch = 16.1866s	
15518/33250 (epoch 23.335), train_loss = 0.68277422, grad/param norm = 1.4599e-01, time/batch = 15.2503s	
15519/33250 (epoch 23.337), train_loss = 0.95289722, grad/param norm = 1.4795e-01, time/batch = 16.7638s	
15520/33250 (epoch 23.338), train_loss = 1.00689425, grad/param norm = 1.5073e-01, time/batch = 17.5972s	
15521/33250 (epoch 23.340), train_loss = 0.90881273, grad/param norm = 1.4612e-01, time/batch = 16.6687s	
15522/33250 (epoch 23.341), train_loss = 0.86466971, grad/param norm = 1.6291e-01, time/batch = 15.9322s	
15523/33250 (epoch 23.343), train_loss = 0.85850294, grad/param norm = 1.5119e-01, time/batch = 15.6931s	
15524/33250 (epoch 23.344), train_loss = 0.89758826, grad/param norm = 1.5313e-01, time/batch = 17.7631s	
15525/33250 (epoch 23.346), train_loss = 0.79579881, grad/param norm = 1.3682e-01, time/batch = 15.3210s	
15526/33250 (epoch 23.347), train_loss = 1.11272932, grad/param norm = 1.8979e-01, time/batch = 16.2641s	
15527/33250 (epoch 23.349), train_loss = 0.84954520, grad/param norm = 1.5294e-01, time/batch = 16.5890s	
15528/33250 (epoch 23.350), train_loss = 0.87994085, grad/param norm = 1.6617e-01, time/batch = 15.5782s	
15529/33250 (epoch 23.352), train_loss = 0.78861590, grad/param norm = 1.4236e-01, time/batch = 16.2591s	
15530/33250 (epoch 23.353), train_loss = 0.86745008, grad/param norm = 1.3547e-01, time/batch = 17.9972s	
15531/33250 (epoch 23.355), train_loss = 0.86421012, grad/param norm = 1.6892e-01, time/batch = 16.8598s	
15532/33250 (epoch 23.356), train_loss = 0.81765558, grad/param norm = 1.5770e-01, time/batch = 15.8267s	
15533/33250 (epoch 23.358), train_loss = 0.86940192, grad/param norm = 1.4786e-01, time/batch = 15.9418s	
15534/33250 (epoch 23.359), train_loss = 0.85712651, grad/param norm = 1.5339e-01, time/batch = 16.5189s	
15535/33250 (epoch 23.361), train_loss = 1.03726068, grad/param norm = 1.8457e-01, time/batch = 17.2665s	
15536/33250 (epoch 23.362), train_loss = 0.92476283, grad/param norm = 1.5685e-01, time/batch = 16.0978s	
15537/33250 (epoch 23.364), train_loss = 0.97654311, grad/param norm = 1.6802e-01, time/batch = 19.7489s	
15538/33250 (epoch 23.365), train_loss = 0.91750880, grad/param norm = 1.4831e-01, time/batch = 15.5176s	
15539/33250 (epoch 23.367), train_loss = 0.89902144, grad/param norm = 1.3335e-01, time/batch = 15.9345s	
15540/33250 (epoch 23.368), train_loss = 0.91340642, grad/param norm = 1.5395e-01, time/batch = 15.8605s	
15541/33250 (epoch 23.370), train_loss = 0.80236232, grad/param norm = 1.4341e-01, time/batch = 18.5789s	
15542/33250 (epoch 23.371), train_loss = 1.02359145, grad/param norm = 1.5950e-01, time/batch = 17.5954s	
15543/33250 (epoch 23.373), train_loss = 0.84789507, grad/param norm = 1.3262e-01, time/batch = 17.0343s	
15544/33250 (epoch 23.374), train_loss = 0.98324209, grad/param norm = 2.2997e-01, time/batch = 18.1051s	
15545/33250 (epoch 23.376), train_loss = 0.87378488, grad/param norm = 1.5027e-01, time/batch = 17.1330s	
15546/33250 (epoch 23.377), train_loss = 0.79971756, grad/param norm = 1.6965e-01, time/batch = 16.4654s	
15547/33250 (epoch 23.379), train_loss = 0.87003418, grad/param norm = 1.6819e-01, time/batch = 16.1934s	
15548/33250 (epoch 23.380), train_loss = 0.93210178, grad/param norm = 1.6025e-01, time/batch = 16.3597s	
15549/33250 (epoch 23.382), train_loss = 0.94793046, grad/param norm = 1.7556e-01, time/batch = 16.9181s	
15550/33250 (epoch 23.383), train_loss = 0.80561802, grad/param norm = 1.6334e-01, time/batch = 16.5822s	
15551/33250 (epoch 23.385), train_loss = 0.79177257, grad/param norm = 1.7428e-01, time/batch = 16.5380s	
15552/33250 (epoch 23.386), train_loss = 0.81442978, grad/param norm = 1.8188e-01, time/batch = 15.1997s	
15553/33250 (epoch 23.388), train_loss = 0.81089727, grad/param norm = 1.4340e-01, time/batch = 15.7815s	
15554/33250 (epoch 23.389), train_loss = 0.87299275, grad/param norm = 1.6846e-01, time/batch = 16.0089s	
15555/33250 (epoch 23.391), train_loss = 0.94972958, grad/param norm = 1.7921e-01, time/batch = 17.5108s	
15556/33250 (epoch 23.392), train_loss = 0.97673651, grad/param norm = 1.7679e-01, time/batch = 15.2841s	
15557/33250 (epoch 23.394), train_loss = 1.01757951, grad/param norm = 1.9437e-01, time/batch = 16.0211s	
15558/33250 (epoch 23.395), train_loss = 0.98826973, grad/param norm = 1.5382e-01, time/batch = 16.9248s	
15559/33250 (epoch 23.397), train_loss = 1.01695547, grad/param norm = 1.6872e-01, time/batch = 16.7684s	
15560/33250 (epoch 23.398), train_loss = 0.85259712, grad/param norm = 1.5289e-01, time/batch = 16.0399s	
15561/33250 (epoch 23.400), train_loss = 0.79989675, grad/param norm = 1.3799e-01, time/batch = 16.8532s	
15562/33250 (epoch 23.402), train_loss = 0.76636722, grad/param norm = 1.5244e-01, time/batch = 18.2537s	
15563/33250 (epoch 23.403), train_loss = 0.87188063, grad/param norm = 1.8829e-01, time/batch = 16.7555s	
15564/33250 (epoch 23.405), train_loss = 0.82184249, grad/param norm = 1.3363e-01, time/batch = 16.2975s	
15565/33250 (epoch 23.406), train_loss = 0.91762598, grad/param norm = 1.7216e-01, time/batch = 15.6233s	
15566/33250 (epoch 23.408), train_loss = 1.03927555, grad/param norm = 1.7123e-01, time/batch = 18.4649s	
15567/33250 (epoch 23.409), train_loss = 0.95514437, grad/param norm = 1.7820e-01, time/batch = 17.8503s	
15568/33250 (epoch 23.411), train_loss = 0.68469102, grad/param norm = 1.2358e-01, time/batch = 15.4817s	
15569/33250 (epoch 23.412), train_loss = 0.75485608, grad/param norm = 1.4835e-01, time/batch = 17.0178s	
15570/33250 (epoch 23.414), train_loss = 0.93915570, grad/param norm = 1.4992e-01, time/batch = 16.2894s	
15571/33250 (epoch 23.415), train_loss = 0.99342905, grad/param norm = 1.6741e-01, time/batch = 16.5082s	
15572/33250 (epoch 23.417), train_loss = 0.97988129, grad/param norm = 1.6941e-01, time/batch = 15.8619s	
15573/33250 (epoch 23.418), train_loss = 1.14572015, grad/param norm = 2.0968e-01, time/batch = 16.4505s	
15574/33250 (epoch 23.420), train_loss = 1.01659425, grad/param norm = 1.5807e-01, time/batch = 18.2135s	
15575/33250 (epoch 23.421), train_loss = 0.83399873, grad/param norm = 1.4135e-01, time/batch = 16.3666s	
15576/33250 (epoch 23.423), train_loss = 0.96059642, grad/param norm = 1.8690e-01, time/batch = 17.5313s	
15577/33250 (epoch 23.424), train_loss = 1.07104526, grad/param norm = 2.3472e-01, time/batch = 17.3546s	
15578/33250 (epoch 23.426), train_loss = 0.84499979, grad/param norm = 1.5169e-01, time/batch = 17.5197s	
15579/33250 (epoch 23.427), train_loss = 0.84945019, grad/param norm = 1.5523e-01, time/batch = 16.3566s	
15580/33250 (epoch 23.429), train_loss = 0.96422279, grad/param norm = 1.8183e-01, time/batch = 17.3339s	
15581/33250 (epoch 23.430), train_loss = 0.86421272, grad/param norm = 1.7307e-01, time/batch = 16.5994s	
15582/33250 (epoch 23.432), train_loss = 0.95140167, grad/param norm = 1.5064e-01, time/batch = 15.5723s	
15583/33250 (epoch 23.433), train_loss = 0.86382665, grad/param norm = 1.9801e-01, time/batch = 17.2063s	
15584/33250 (epoch 23.435), train_loss = 1.00579643, grad/param norm = 1.8417e-01, time/batch = 16.0454s	
15585/33250 (epoch 23.436), train_loss = 0.84325962, grad/param norm = 1.6520e-01, time/batch = 18.4361s	
15586/33250 (epoch 23.438), train_loss = 0.99213674, grad/param norm = 1.6485e-01, time/batch = 17.2109s	
15587/33250 (epoch 23.439), train_loss = 0.91628267, grad/param norm = 1.4635e-01, time/batch = 18.3358s	
15588/33250 (epoch 23.441), train_loss = 0.88681644, grad/param norm = 1.3157e-01, time/batch = 16.1067s	
15589/33250 (epoch 23.442), train_loss = 0.83282777, grad/param norm = 1.6795e-01, time/batch = 15.2705s	
15590/33250 (epoch 23.444), train_loss = 0.85772869, grad/param norm = 1.5296e-01, time/batch = 16.1042s	
15591/33250 (epoch 23.445), train_loss = 0.91807746, grad/param norm = 1.4328e-01, time/batch = 16.5408s	
15592/33250 (epoch 23.447), train_loss = 0.90545279, grad/param norm = 1.6912e-01, time/batch = 16.3493s	
15593/33250 (epoch 23.448), train_loss = 0.91779273, grad/param norm = 1.3479e-01, time/batch = 16.4400s	
15594/33250 (epoch 23.450), train_loss = 1.06868955, grad/param norm = 1.9313e-01, time/batch = 18.2091s	
15595/33250 (epoch 23.451), train_loss = 0.95489606, grad/param norm = 1.8361e-01, time/batch = 16.1757s	
15596/33250 (epoch 23.453), train_loss = 0.80249329, grad/param norm = 1.2901e-01, time/batch = 18.1627s	
15597/33250 (epoch 23.454), train_loss = 1.02902092, grad/param norm = 1.5334e-01, time/batch = 18.6076s	
15598/33250 (epoch 23.456), train_loss = 1.03806760, grad/param norm = 1.4120e-01, time/batch = 17.5026s	
15599/33250 (epoch 23.457), train_loss = 0.87995673, grad/param norm = 1.6679e-01, time/batch = 15.9422s	
15600/33250 (epoch 23.459), train_loss = 0.95427364, grad/param norm = 1.4870e-01, time/batch = 16.6877s	
15601/33250 (epoch 23.460), train_loss = 0.99622121, grad/param norm = 1.7742e-01, time/batch = 16.8596s	
15602/33250 (epoch 23.462), train_loss = 0.84547011, grad/param norm = 1.4604e-01, time/batch = 17.2681s	
15603/33250 (epoch 23.463), train_loss = 0.83330100, grad/param norm = 1.2589e-01, time/batch = 16.0850s	
15604/33250 (epoch 23.465), train_loss = 0.76046678, grad/param norm = 1.2731e-01, time/batch = 18.7747s	
15605/33250 (epoch 23.466), train_loss = 0.72824132, grad/param norm = 1.1190e-01, time/batch = 16.8603s	
15606/33250 (epoch 23.468), train_loss = 0.80620515, grad/param norm = 1.2241e-01, time/batch = 17.7032s	
15607/33250 (epoch 23.469), train_loss = 0.87315358, grad/param norm = 1.6033e-01, time/batch = 15.5036s	
15608/33250 (epoch 23.471), train_loss = 0.96871853, grad/param norm = 1.4226e-01, time/batch = 19.2324s	
15609/33250 (epoch 23.472), train_loss = 0.88574477, grad/param norm = 1.8612e-01, time/batch = 17.7648s	
15610/33250 (epoch 23.474), train_loss = 1.01789267, grad/param norm = 1.6535e-01, time/batch = 15.7782s	
15611/33250 (epoch 23.475), train_loss = 0.93914215, grad/param norm = 1.5125e-01, time/batch = 18.1749s	
15612/33250 (epoch 23.477), train_loss = 0.89412540, grad/param norm = 1.3108e-01, time/batch = 17.6922s	
15613/33250 (epoch 23.478), train_loss = 0.82867461, grad/param norm = 1.5399e-01, time/batch = 16.2696s	
15614/33250 (epoch 23.480), train_loss = 1.07481618, grad/param norm = 1.6989e-01, time/batch = 17.7035s	
15615/33250 (epoch 23.481), train_loss = 0.92757788, grad/param norm = 1.4706e-01, time/batch = 19.4507s	
15616/33250 (epoch 23.483), train_loss = 0.89877977, grad/param norm = 1.4052e-01, time/batch = 18.9530s	
15617/33250 (epoch 23.484), train_loss = 0.82482855, grad/param norm = 1.4323e-01, time/batch = 17.4096s	
15618/33250 (epoch 23.486), train_loss = 0.76855050, grad/param norm = 1.5638e-01, time/batch = 15.8466s	
15619/33250 (epoch 23.487), train_loss = 0.86638535, grad/param norm = 1.5960e-01, time/batch = 17.7452s	
15620/33250 (epoch 23.489), train_loss = 1.01981915, grad/param norm = 1.8314e-01, time/batch = 23.2211s	
15621/33250 (epoch 23.490), train_loss = 0.95883524, grad/param norm = 1.7626e-01, time/batch = 23.6910s	
15622/33250 (epoch 23.492), train_loss = 0.97176187, grad/param norm = 1.6629e-01, time/batch = 18.7681s	
15623/33250 (epoch 23.493), train_loss = 0.91717082, grad/param norm = 1.8224e-01, time/batch = 16.0167s	
15624/33250 (epoch 23.495), train_loss = 0.94694757, grad/param norm = 1.3934e-01, time/batch = 15.5258s	
15625/33250 (epoch 23.496), train_loss = 0.91591949, grad/param norm = 1.3689e-01, time/batch = 16.8738s	
15626/33250 (epoch 23.498), train_loss = 0.98753632, grad/param norm = 1.5689e-01, time/batch = 17.0075s	
15627/33250 (epoch 23.499), train_loss = 0.86582479, grad/param norm = 1.5425e-01, time/batch = 15.4870s	
15628/33250 (epoch 23.501), train_loss = 0.83521129, grad/param norm = 1.4531e-01, time/batch = 15.8400s	
15629/33250 (epoch 23.502), train_loss = 0.87406029, grad/param norm = 1.3515e-01, time/batch = 15.9986s	
15630/33250 (epoch 23.504), train_loss = 1.04413531, grad/param norm = 1.6877e-01, time/batch = 15.0193s	
15631/33250 (epoch 23.505), train_loss = 0.76645646, grad/param norm = 1.2669e-01, time/batch = 14.6959s	
15632/33250 (epoch 23.507), train_loss = 0.82581631, grad/param norm = 1.4592e-01, time/batch = 14.5480s	
15633/33250 (epoch 23.508), train_loss = 0.87231738, grad/param norm = 1.6069e-01, time/batch = 14.7168s	
15634/33250 (epoch 23.510), train_loss = 0.74393814, grad/param norm = 1.2434e-01, time/batch = 14.8828s	
15635/33250 (epoch 23.511), train_loss = 0.89902017, grad/param norm = 1.6507e-01, time/batch = 14.7316s	
15636/33250 (epoch 23.513), train_loss = 1.05039383, grad/param norm = 1.5649e-01, time/batch = 14.4853s	
15637/33250 (epoch 23.514), train_loss = 0.88233487, grad/param norm = 1.3044e-01, time/batch = 14.9419s	
15638/33250 (epoch 23.516), train_loss = 0.84822785, grad/param norm = 1.5105e-01, time/batch = 15.1778s	
15639/33250 (epoch 23.517), train_loss = 0.85902471, grad/param norm = 1.5856e-01, time/batch = 15.0858s	
15640/33250 (epoch 23.519), train_loss = 0.77852481, grad/param norm = 1.1685e-01, time/batch = 14.7656s	
15641/33250 (epoch 23.520), train_loss = 1.11379031, grad/param norm = 1.8904e-01, time/batch = 14.8400s	
15642/33250 (epoch 23.522), train_loss = 0.97328829, grad/param norm = 1.5436e-01, time/batch = 15.1822s	
15643/33250 (epoch 23.523), train_loss = 0.82423537, grad/param norm = 1.3841e-01, time/batch = 15.2503s	
15644/33250 (epoch 23.525), train_loss = 0.77592551, grad/param norm = 1.5970e-01, time/batch = 14.9614s	
15645/33250 (epoch 23.526), train_loss = 0.78122204, grad/param norm = 1.4032e-01, time/batch = 14.5542s	
15646/33250 (epoch 23.528), train_loss = 0.86844331, grad/param norm = 1.4786e-01, time/batch = 14.8697s	
15647/33250 (epoch 23.529), train_loss = 0.84790336, grad/param norm = 1.5379e-01, time/batch = 15.4303s	
15648/33250 (epoch 23.531), train_loss = 0.77672626, grad/param norm = 1.2822e-01, time/batch = 14.7870s	
15649/33250 (epoch 23.532), train_loss = 0.94716451, grad/param norm = 1.5105e-01, time/batch = 14.6918s	
15650/33250 (epoch 23.534), train_loss = 0.80964091, grad/param norm = 1.4045e-01, time/batch = 15.1662s	
15651/33250 (epoch 23.535), train_loss = 0.89493716, grad/param norm = 1.4401e-01, time/batch = 15.3474s	
15652/33250 (epoch 23.537), train_loss = 0.93441500, grad/param norm = 1.4457e-01, time/batch = 14.8614s	
15653/33250 (epoch 23.538), train_loss = 0.95368716, grad/param norm = 1.5971e-01, time/batch = 14.7666s	
15654/33250 (epoch 23.540), train_loss = 1.05486861, grad/param norm = 1.4488e-01, time/batch = 15.0083s	
15655/33250 (epoch 23.541), train_loss = 0.99837364, grad/param norm = 1.7577e-01, time/batch = 14.9572s	
15656/33250 (epoch 23.543), train_loss = 0.96473179, grad/param norm = 1.5040e-01, time/batch = 14.7254s	
15657/33250 (epoch 23.544), train_loss = 0.84350248, grad/param norm = 1.5516e-01, time/batch = 14.7237s	
15658/33250 (epoch 23.546), train_loss = 0.87623978, grad/param norm = 1.5767e-01, time/batch = 15.2705s	
15659/33250 (epoch 23.547), train_loss = 0.89030118, grad/param norm = 1.7798e-01, time/batch = 14.8756s	
15660/33250 (epoch 23.549), train_loss = 0.95830836, grad/param norm = 1.7221e-01, time/batch = 14.8726s	
15661/33250 (epoch 23.550), train_loss = 0.86505902, grad/param norm = 1.5592e-01, time/batch = 14.9456s	
15662/33250 (epoch 23.552), train_loss = 0.96028055, grad/param norm = 1.6522e-01, time/batch = 14.7747s	
15663/33250 (epoch 23.553), train_loss = 0.85660628, grad/param norm = 1.4784e-01, time/batch = 15.5746s	
15664/33250 (epoch 23.555), train_loss = 0.94589220, grad/param norm = 1.5163e-01, time/batch = 14.7885s	
15665/33250 (epoch 23.556), train_loss = 0.96337526, grad/param norm = 1.7663e-01, time/batch = 14.7115s	
15666/33250 (epoch 23.558), train_loss = 1.01661271, grad/param norm = 1.7465e-01, time/batch = 15.0465s	
15667/33250 (epoch 23.559), train_loss = 0.82311988, grad/param norm = 1.3966e-01, time/batch = 14.9749s	
15668/33250 (epoch 23.561), train_loss = 0.80936399, grad/param norm = 1.3787e-01, time/batch = 14.7339s	
15669/33250 (epoch 23.562), train_loss = 0.96017365, grad/param norm = 1.5055e-01, time/batch = 14.9575s	
15670/33250 (epoch 23.564), train_loss = 1.10222965, grad/param norm = 1.8037e-01, time/batch = 15.4943s	
15671/33250 (epoch 23.565), train_loss = 1.04077165, grad/param norm = 1.9304e-01, time/batch = 15.0280s	
15672/33250 (epoch 23.567), train_loss = 1.04348872, grad/param norm = 1.7323e-01, time/batch = 14.8706s	
15673/33250 (epoch 23.568), train_loss = 0.91244568, grad/param norm = 1.6503e-01, time/batch = 14.8673s	
15674/33250 (epoch 23.570), train_loss = 0.99749732, grad/param norm = 1.6404e-01, time/batch = 15.4183s	
15675/33250 (epoch 23.571), train_loss = 1.05389510, grad/param norm = 1.5489e-01, time/batch = 15.0295s	
15676/33250 (epoch 23.573), train_loss = 0.95769246, grad/param norm = 1.7828e-01, time/batch = 14.7939s	
15677/33250 (epoch 23.574), train_loss = 0.81828116, grad/param norm = 1.3347e-01, time/batch = 14.6953s	
15678/33250 (epoch 23.576), train_loss = 0.98130097, grad/param norm = 1.7757e-01, time/batch = 15.2785s	
15679/33250 (epoch 23.577), train_loss = 0.89900172, grad/param norm = 1.4686e-01, time/batch = 14.5541s	
15680/33250 (epoch 23.579), train_loss = 0.82165271, grad/param norm = 1.5138e-01, time/batch = 15.1959s	
15681/33250 (epoch 23.580), train_loss = 0.86370531, grad/param norm = 1.3043e-01, time/batch = 15.0458s	
15682/33250 (epoch 23.582), train_loss = 0.88464206, grad/param norm = 1.5559e-01, time/batch = 15.0994s	
15683/33250 (epoch 23.583), train_loss = 1.01244964, grad/param norm = 1.5333e-01, time/batch = 15.5721s	
15684/33250 (epoch 23.585), train_loss = 0.99759780, grad/param norm = 1.4648e-01, time/batch = 14.7122s	
15685/33250 (epoch 23.586), train_loss = 0.82520114, grad/param norm = 1.6418e-01, time/batch = 14.7829s	
15686/33250 (epoch 23.588), train_loss = 0.95095198, grad/param norm = 1.6079e-01, time/batch = 15.3417s	
15687/33250 (epoch 23.589), train_loss = 0.94083375, grad/param norm = 1.4702e-01, time/batch = 15.0246s	
15688/33250 (epoch 23.591), train_loss = 0.91592793, grad/param norm = 1.8071e-01, time/batch = 15.1836s	
15689/33250 (epoch 23.592), train_loss = 0.89491276, grad/param norm = 1.4647e-01, time/batch = 14.7272s	
15690/33250 (epoch 23.594), train_loss = 1.04582685, grad/param norm = 1.8269e-01, time/batch = 14.8896s	
15691/33250 (epoch 23.595), train_loss = 0.93232260, grad/param norm = 1.5485e-01, time/batch = 15.2281s	
15692/33250 (epoch 23.597), train_loss = 0.77244362, grad/param norm = 1.3799e-01, time/batch = 15.2804s	
15693/33250 (epoch 23.598), train_loss = 0.86925140, grad/param norm = 1.6232e-01, time/batch = 14.7819s	
15694/33250 (epoch 23.600), train_loss = 0.88221339, grad/param norm = 1.7460e-01, time/batch = 15.2705s	
15695/33250 (epoch 23.602), train_loss = 0.91492727, grad/param norm = 1.8434e-01, time/batch = 15.0207s	
15696/33250 (epoch 23.603), train_loss = 0.94705646, grad/param norm = 1.5036e-01, time/batch = 14.7852s	
15697/33250 (epoch 23.605), train_loss = 0.91360716, grad/param norm = 1.5249e-01, time/batch = 14.9382s	
15698/33250 (epoch 23.606), train_loss = 0.97978912, grad/param norm = 1.6086e-01, time/batch = 14.9363s	
15699/33250 (epoch 23.608), train_loss = 0.93425065, grad/param norm = 1.4789e-01, time/batch = 14.5466s	
15700/33250 (epoch 23.609), train_loss = 0.83557383, grad/param norm = 1.4820e-01, time/batch = 14.7144s	
15701/33250 (epoch 23.611), train_loss = 0.96214206, grad/param norm = 1.6842e-01, time/batch = 14.5568s	
15702/33250 (epoch 23.612), train_loss = 0.89221428, grad/param norm = 1.5235e-01, time/batch = 15.1212s	
15703/33250 (epoch 23.614), train_loss = 1.13488621, grad/param norm = 2.0182e-01, time/batch = 15.1990s	
15704/33250 (epoch 23.615), train_loss = 1.01202052, grad/param norm = 1.6509e-01, time/batch = 14.8611s	
15705/33250 (epoch 23.617), train_loss = 1.16381706, grad/param norm = 1.9367e-01, time/batch = 14.6278s	
15706/33250 (epoch 23.618), train_loss = 1.16751443, grad/param norm = 2.1175e-01, time/batch = 15.0325s	
15707/33250 (epoch 23.620), train_loss = 0.99557954, grad/param norm = 1.8000e-01, time/batch = 15.4152s	
15708/33250 (epoch 23.621), train_loss = 0.96934815, grad/param norm = 1.6971e-01, time/batch = 14.7094s	
15709/33250 (epoch 23.623), train_loss = 0.83399495, grad/param norm = 1.6072e-01, time/batch = 14.8668s	
15710/33250 (epoch 23.624), train_loss = 0.90535000, grad/param norm = 1.6520e-01, time/batch = 15.4675s	
15711/33250 (epoch 23.626), train_loss = 0.86501077, grad/param norm = 1.7518e-01, time/batch = 15.3600s	
15712/33250 (epoch 23.627), train_loss = 0.87161751, grad/param norm = 1.5852e-01, time/batch = 15.2000s	
15713/33250 (epoch 23.629), train_loss = 0.97013049, grad/param norm = 1.9543e-01, time/batch = 14.7846s	
15714/33250 (epoch 23.630), train_loss = 0.87598323, grad/param norm = 1.7182e-01, time/batch = 15.3511s	
15715/33250 (epoch 23.632), train_loss = 0.77592785, grad/param norm = 1.3870e-01, time/batch = 18.5925s	
15716/33250 (epoch 23.633), train_loss = 0.91069247, grad/param norm = 1.6292e-01, time/batch = 16.5118s	
15717/33250 (epoch 23.635), train_loss = 0.83199203, grad/param norm = 1.3977e-01, time/batch = 18.0677s	
15718/33250 (epoch 23.636), train_loss = 0.84316079, grad/param norm = 1.3958e-01, time/batch = 15.2507s	
15719/33250 (epoch 23.638), train_loss = 0.83615474, grad/param norm = 1.4763e-01, time/batch = 17.0022s	
15720/33250 (epoch 23.639), train_loss = 0.76397430, grad/param norm = 1.3772e-01, time/batch = 16.7806s	
15721/33250 (epoch 23.641), train_loss = 0.87774479, grad/param norm = 1.4777e-01, time/batch = 16.5258s	
15722/33250 (epoch 23.642), train_loss = 0.73300772, grad/param norm = 1.5821e-01, time/batch = 18.5166s	
15723/33250 (epoch 23.644), train_loss = 0.65620419, grad/param norm = 1.3468e-01, time/batch = 16.1977s	
15724/33250 (epoch 23.645), train_loss = 0.98181343, grad/param norm = 1.7898e-01, time/batch = 18.4364s	
15725/33250 (epoch 23.647), train_loss = 0.78603731, grad/param norm = 1.6836e-01, time/batch = 16.9406s	
15726/33250 (epoch 23.648), train_loss = 0.83485035, grad/param norm = 1.8587e-01, time/batch = 18.0051s	
15727/33250 (epoch 23.650), train_loss = 1.04598035, grad/param norm = 1.7878e-01, time/batch = 18.2620s	
15728/33250 (epoch 23.651), train_loss = 0.96641827, grad/param norm = 1.8099e-01, time/batch = 17.4154s	
15729/33250 (epoch 23.653), train_loss = 0.83242964, grad/param norm = 1.5599e-01, time/batch = 18.0097s	
15730/33250 (epoch 23.654), train_loss = 0.90235816, grad/param norm = 1.4614e-01, time/batch = 15.7867s	
15731/33250 (epoch 23.656), train_loss = 0.92899867, grad/param norm = 1.4213e-01, time/batch = 16.3459s	
15732/33250 (epoch 23.657), train_loss = 0.72115446, grad/param norm = 1.6400e-01, time/batch = 16.7913s	
15733/33250 (epoch 23.659), train_loss = 0.84078566, grad/param norm = 1.4094e-01, time/batch = 19.2708s	
15734/33250 (epoch 23.660), train_loss = 0.91033790, grad/param norm = 1.6895e-01, time/batch = 18.5434s	
15735/33250 (epoch 23.662), train_loss = 0.90791692, grad/param norm = 1.5929e-01, time/batch = 18.2337s	
15736/33250 (epoch 23.663), train_loss = 0.82500424, grad/param norm = 1.5121e-01, time/batch = 19.2435s	
15737/33250 (epoch 23.665), train_loss = 0.92862090, grad/param norm = 1.5602e-01, time/batch = 16.5292s	
15738/33250 (epoch 23.666), train_loss = 0.85733298, grad/param norm = 1.5031e-01, time/batch = 16.1766s	
15739/33250 (epoch 23.668), train_loss = 1.03505874, grad/param norm = 1.5625e-01, time/batch = 16.2467s	
15740/33250 (epoch 23.669), train_loss = 0.93526454, grad/param norm = 1.7317e-01, time/batch = 17.0254s	
15741/33250 (epoch 23.671), train_loss = 0.82282824, grad/param norm = 1.8385e-01, time/batch = 18.5171s	
15742/33250 (epoch 23.672), train_loss = 0.98374440, grad/param norm = 1.6522e-01, time/batch = 17.3743s	
15743/33250 (epoch 23.674), train_loss = 0.79788173, grad/param norm = 1.4769e-01, time/batch = 15.2015s	
15744/33250 (epoch 23.675), train_loss = 0.89346807, grad/param norm = 1.5530e-01, time/batch = 15.4501s	
15745/33250 (epoch 23.677), train_loss = 0.97318640, grad/param norm = 1.6622e-01, time/batch = 16.4249s	
15746/33250 (epoch 23.678), train_loss = 0.87132048, grad/param norm = 1.7575e-01, time/batch = 16.4964s	
15747/33250 (epoch 23.680), train_loss = 0.97594175, grad/param norm = 1.8997e-01, time/batch = 17.9444s	
15748/33250 (epoch 23.681), train_loss = 0.80675178, grad/param norm = 1.4754e-01, time/batch = 15.7023s	
15749/33250 (epoch 23.683), train_loss = 0.86641943, grad/param norm = 1.6135e-01, time/batch = 15.3254s	
15750/33250 (epoch 23.684), train_loss = 0.80790137, grad/param norm = 1.6126e-01, time/batch = 15.9168s	
15751/33250 (epoch 23.686), train_loss = 0.82435311, grad/param norm = 1.4890e-01, time/batch = 16.5405s	
15752/33250 (epoch 23.687), train_loss = 0.90956543, grad/param norm = 1.5932e-01, time/batch = 15.8463s	
15753/33250 (epoch 23.689), train_loss = 0.81718745, grad/param norm = 1.5949e-01, time/batch = 19.1880s	
15754/33250 (epoch 23.690), train_loss = 0.91504267, grad/param norm = 1.7613e-01, time/batch = 15.9593s	
15755/33250 (epoch 23.692), train_loss = 0.88090669, grad/param norm = 1.5682e-01, time/batch = 17.3559s	
15756/33250 (epoch 23.693), train_loss = 0.97370268, grad/param norm = 1.6923e-01, time/batch = 15.9211s	
15757/33250 (epoch 23.695), train_loss = 0.92275779, grad/param norm = 1.5082e-01, time/batch = 16.6747s	
15758/33250 (epoch 23.696), train_loss = 0.93638416, grad/param norm = 1.4592e-01, time/batch = 18.0923s	
15759/33250 (epoch 23.698), train_loss = 0.85409723, grad/param norm = 1.6395e-01, time/batch = 16.1953s	
15760/33250 (epoch 23.699), train_loss = 1.10116505, grad/param norm = 1.5916e-01, time/batch = 16.1841s	
15761/33250 (epoch 23.701), train_loss = 0.90033179, grad/param norm = 1.3569e-01, time/batch = 18.2928s	
15762/33250 (epoch 23.702), train_loss = 0.86806896, grad/param norm = 2.2155e-01, time/batch = 19.8643s	
15763/33250 (epoch 23.704), train_loss = 1.07025758, grad/param norm = 2.7613e-01, time/batch = 15.6954s	
15764/33250 (epoch 23.705), train_loss = 0.83987751, grad/param norm = 1.4365e-01, time/batch = 19.1010s	
15765/33250 (epoch 23.707), train_loss = 0.74514023, grad/param norm = 1.3533e-01, time/batch = 16.2451s	
15766/33250 (epoch 23.708), train_loss = 0.97472771, grad/param norm = 1.6511e-01, time/batch = 17.2558s	
15767/33250 (epoch 23.710), train_loss = 0.96356818, grad/param norm = 1.7585e-01, time/batch = 18.0166s	
15768/33250 (epoch 23.711), train_loss = 0.81524680, grad/param norm = 1.6848e-01, time/batch = 16.9987s	
15769/33250 (epoch 23.713), train_loss = 0.95275304, grad/param norm = 1.6021e-01, time/batch = 17.9295s	
15770/33250 (epoch 23.714), train_loss = 0.91515823, grad/param norm = 1.5536e-01, time/batch = 16.8358s	
15771/33250 (epoch 23.716), train_loss = 0.94079650, grad/param norm = 1.6509e-01, time/batch = 19.3594s	
15772/33250 (epoch 23.717), train_loss = 0.82994074, grad/param norm = 1.3005e-01, time/batch = 16.6907s	
15773/33250 (epoch 23.719), train_loss = 0.85767525, grad/param norm = 1.5508e-01, time/batch = 17.2029s	
15774/33250 (epoch 23.720), train_loss = 1.14170191, grad/param norm = 1.7113e-01, time/batch = 16.6706s	
15775/33250 (epoch 23.722), train_loss = 0.79805820, grad/param norm = 1.3954e-01, time/batch = 17.7461s	
15776/33250 (epoch 23.723), train_loss = 0.70992988, grad/param norm = 1.2738e-01, time/batch = 16.5102s	
15777/33250 (epoch 23.725), train_loss = 0.80627427, grad/param norm = 1.3021e-01, time/batch = 16.2831s	
15778/33250 (epoch 23.726), train_loss = 0.88596073, grad/param norm = 1.6386e-01, time/batch = 16.8504s	
15779/33250 (epoch 23.728), train_loss = 0.93619969, grad/param norm = 1.6377e-01, time/batch = 17.6032s	
15780/33250 (epoch 23.729), train_loss = 1.00516756, grad/param norm = 1.5682e-01, time/batch = 15.7731s	
15781/33250 (epoch 23.731), train_loss = 0.84487424, grad/param norm = 1.6308e-01, time/batch = 19.7787s	
15782/33250 (epoch 23.732), train_loss = 0.79935880, grad/param norm = 1.3157e-01, time/batch = 18.4521s	
15783/33250 (epoch 23.734), train_loss = 0.93688541, grad/param norm = 1.7172e-01, time/batch = 17.5378s	
15784/33250 (epoch 23.735), train_loss = 0.90283579, grad/param norm = 1.6658e-01, time/batch = 15.8587s	
15785/33250 (epoch 23.737), train_loss = 0.86967176, grad/param norm = 1.4567e-01, time/batch = 16.4505s	
15786/33250 (epoch 23.738), train_loss = 0.93118185, grad/param norm = 1.5682e-01, time/batch = 16.8706s	
15787/33250 (epoch 23.740), train_loss = 0.99925269, grad/param norm = 1.5971e-01, time/batch = 15.1737s	
15788/33250 (epoch 23.741), train_loss = 0.97489765, grad/param norm = 1.6268e-01, time/batch = 16.9155s	
15789/33250 (epoch 23.743), train_loss = 0.82128587, grad/param norm = 1.3097e-01, time/batch = 16.6197s	
15790/33250 (epoch 23.744), train_loss = 0.86447824, grad/param norm = 1.5829e-01, time/batch = 18.1103s	
15791/33250 (epoch 23.746), train_loss = 0.80870451, grad/param norm = 1.3174e-01, time/batch = 15.7104s	
15792/33250 (epoch 23.747), train_loss = 0.84849169, grad/param norm = 1.5880e-01, time/batch = 19.1150s	
15793/33250 (epoch 23.749), train_loss = 0.99594031, grad/param norm = 1.7217e-01, time/batch = 18.8690s	
15794/33250 (epoch 23.750), train_loss = 0.96380336, grad/param norm = 1.5228e-01, time/batch = 16.1886s	
15795/33250 (epoch 23.752), train_loss = 0.86326426, grad/param norm = 1.4358e-01, time/batch = 16.8472s	
15796/33250 (epoch 23.753), train_loss = 0.85599098, grad/param norm = 1.5109e-01, time/batch = 15.5238s	
15797/33250 (epoch 23.755), train_loss = 0.86386914, grad/param norm = 1.7373e-01, time/batch = 16.5895s	
15798/33250 (epoch 23.756), train_loss = 0.93894317, grad/param norm = 1.7012e-01, time/batch = 16.1818s	
15799/33250 (epoch 23.758), train_loss = 1.04030509, grad/param norm = 1.5256e-01, time/batch = 17.5975s	
15800/33250 (epoch 23.759), train_loss = 0.82595824, grad/param norm = 1.4517e-01, time/batch = 17.0925s	
15801/33250 (epoch 23.761), train_loss = 0.90762739, grad/param norm = 1.6843e-01, time/batch = 16.5172s	
15802/33250 (epoch 23.762), train_loss = 0.98420339, grad/param norm = 1.5390e-01, time/batch = 17.3621s	
15803/33250 (epoch 23.764), train_loss = 0.82137459, grad/param norm = 1.9749e-01, time/batch = 17.6131s	
15804/33250 (epoch 23.765), train_loss = 0.95233462, grad/param norm = 1.6263e-01, time/batch = 14.8088s	
15805/33250 (epoch 23.767), train_loss = 0.72952080, grad/param norm = 1.5475e-01, time/batch = 15.3418s	
15806/33250 (epoch 23.768), train_loss = 0.76918696, grad/param norm = 1.6331e-01, time/batch = 17.6826s	
15807/33250 (epoch 23.770), train_loss = 0.94546666, grad/param norm = 1.8161e-01, time/batch = 15.9517s	
15808/33250 (epoch 23.771), train_loss = 0.96995513, grad/param norm = 1.7745e-01, time/batch = 16.8372s	
15809/33250 (epoch 23.773), train_loss = 0.87604206, grad/param norm = 1.8704e-01, time/batch = 15.9919s	
15810/33250 (epoch 23.774), train_loss = 0.75580388, grad/param norm = 1.4397e-01, time/batch = 17.3332s	
15811/33250 (epoch 23.776), train_loss = 0.84640794, grad/param norm = 1.4619e-01, time/batch = 18.7985s	
15812/33250 (epoch 23.777), train_loss = 1.00103295, grad/param norm = 1.7668e-01, time/batch = 16.4512s	
15813/33250 (epoch 23.779), train_loss = 0.89477187, grad/param norm = 1.6284e-01, time/batch = 19.5985s	
15814/33250 (epoch 23.780), train_loss = 1.05339369, grad/param norm = 1.7308e-01, time/batch = 16.6016s	
15815/33250 (epoch 23.782), train_loss = 0.91213290, grad/param norm = 1.6863e-01, time/batch = 16.1949s	
15816/33250 (epoch 23.783), train_loss = 0.77447277, grad/param norm = 1.5073e-01, time/batch = 16.0342s	
15817/33250 (epoch 23.785), train_loss = 0.77949666, grad/param norm = 1.4188e-01, time/batch = 17.7704s	
15818/33250 (epoch 23.786), train_loss = 1.00186107, grad/param norm = 1.6608e-01, time/batch = 16.1732s	
15819/33250 (epoch 23.788), train_loss = 0.98642088, grad/param norm = 1.6227e-01, time/batch = 15.2681s	
15820/33250 (epoch 23.789), train_loss = 1.00592588, grad/param norm = 1.9358e-01, time/batch = 17.6309s	
15821/33250 (epoch 23.791), train_loss = 1.06823542, grad/param norm = 1.7589e-01, time/batch = 19.9411s	
15822/33250 (epoch 23.792), train_loss = 1.10061777, grad/param norm = 1.6497e-01, time/batch = 17.5291s	
15823/33250 (epoch 23.794), train_loss = 0.88026134, grad/param norm = 1.6514e-01, time/batch = 18.2760s	
15824/33250 (epoch 23.795), train_loss = 0.91910158, grad/param norm = 1.5841e-01, time/batch = 16.5152s	
15825/33250 (epoch 23.797), train_loss = 0.98756060, grad/param norm = 1.8746e-01, time/batch = 15.1789s	
15826/33250 (epoch 23.798), train_loss = 0.90757279, grad/param norm = 1.8852e-01, time/batch = 15.5785s	
15827/33250 (epoch 23.800), train_loss = 0.96353229, grad/param norm = 1.7737e-01, time/batch = 16.4897s	
15828/33250 (epoch 23.802), train_loss = 0.88669039, grad/param norm = 1.4228e-01, time/batch = 17.2576s	
15829/33250 (epoch 23.803), train_loss = 0.93677570, grad/param norm = 1.5073e-01, time/batch = 17.7692s	
15830/33250 (epoch 23.805), train_loss = 0.94419151, grad/param norm = 1.5825e-01, time/batch = 16.1112s	
15831/33250 (epoch 23.806), train_loss = 0.92101611, grad/param norm = 1.5999e-01, time/batch = 18.7121s	
15832/33250 (epoch 23.808), train_loss = 0.86377094, grad/param norm = 1.4679e-01, time/batch = 19.3712s	
15833/33250 (epoch 23.809), train_loss = 0.83004810, grad/param norm = 1.4552e-01, time/batch = 17.2815s	
15834/33250 (epoch 23.811), train_loss = 0.83058008, grad/param norm = 1.4875e-01, time/batch = 16.6818s	
15835/33250 (epoch 23.812), train_loss = 0.95210481, grad/param norm = 1.7432e-01, time/batch = 17.5133s	
15836/33250 (epoch 23.814), train_loss = 0.90750327, grad/param norm = 1.6938e-01, time/batch = 15.9335s	
15837/33250 (epoch 23.815), train_loss = 0.96029126, grad/param norm = 1.5653e-01, time/batch = 17.5217s	
15838/33250 (epoch 23.817), train_loss = 0.90555504, grad/param norm = 1.6860e-01, time/batch = 18.0135s	
15839/33250 (epoch 23.818), train_loss = 0.82647832, grad/param norm = 1.5813e-01, time/batch = 17.4295s	
15840/33250 (epoch 23.820), train_loss = 0.93256149, grad/param norm = 1.6373e-01, time/batch = 32.9004s	
15841/33250 (epoch 23.821), train_loss = 0.87921180, grad/param norm = 1.3606e-01, time/batch = 18.2142s	
15842/33250 (epoch 23.823), train_loss = 1.24335317, grad/param norm = 1.9790e-01, time/batch = 15.8688s	
15843/33250 (epoch 23.824), train_loss = 0.85545593, grad/param norm = 1.7983e-01, time/batch = 15.6790s	
15844/33250 (epoch 23.826), train_loss = 0.95304331, grad/param norm = 1.7049e-01, time/batch = 15.5191s	
15845/33250 (epoch 23.827), train_loss = 0.75749003, grad/param norm = 1.5870e-01, time/batch = 17.6939s	
15846/33250 (epoch 23.829), train_loss = 0.92234446, grad/param norm = 1.9413e-01, time/batch = 15.5867s	
15847/33250 (epoch 23.830), train_loss = 1.00987299, grad/param norm = 2.0593e-01, time/batch = 15.9371s	
15848/33250 (epoch 23.832), train_loss = 0.92703645, grad/param norm = 1.5938e-01, time/batch = 16.3612s	
15849/33250 (epoch 23.833), train_loss = 0.91902568, grad/param norm = 1.6901e-01, time/batch = 17.2744s	
15850/33250 (epoch 23.835), train_loss = 0.84512178, grad/param norm = 2.0595e-01, time/batch = 16.1358s	
15851/33250 (epoch 23.836), train_loss = 0.87820506, grad/param norm = 1.5797e-01, time/batch = 17.0084s	
15852/33250 (epoch 23.838), train_loss = 0.92103160, grad/param norm = 1.4923e-01, time/batch = 15.6725s	
15853/33250 (epoch 23.839), train_loss = 0.87253220, grad/param norm = 1.4853e-01, time/batch = 17.1911s	
15854/33250 (epoch 23.841), train_loss = 0.83530612, grad/param norm = 1.4288e-01, time/batch = 16.2536s	
15855/33250 (epoch 23.842), train_loss = 1.05594065, grad/param norm = 1.5707e-01, time/batch = 17.3469s	
15856/33250 (epoch 23.844), train_loss = 1.02685472, grad/param norm = 1.7650e-01, time/batch = 17.2632s	
15857/33250 (epoch 23.845), train_loss = 1.08387112, grad/param norm = 1.8358e-01, time/batch = 15.2681s	
15858/33250 (epoch 23.847), train_loss = 1.07688564, grad/param norm = 1.8260e-01, time/batch = 18.5922s	
15859/33250 (epoch 23.848), train_loss = 1.15414134, grad/param norm = 1.9424e-01, time/batch = 16.2146s	
15860/33250 (epoch 23.850), train_loss = 0.99071452, grad/param norm = 1.5745e-01, time/batch = 16.6822s	
15861/33250 (epoch 23.851), train_loss = 0.81751553, grad/param norm = 1.5889e-01, time/batch = 17.1880s	
15862/33250 (epoch 23.853), train_loss = 0.94556629, grad/param norm = 1.6984e-01, time/batch = 18.5162s	
15863/33250 (epoch 23.854), train_loss = 0.85957850, grad/param norm = 1.5109e-01, time/batch = 17.6793s	
15864/33250 (epoch 23.856), train_loss = 0.85904634, grad/param norm = 1.6273e-01, time/batch = 15.6070s	
15865/33250 (epoch 23.857), train_loss = 0.78054371, grad/param norm = 1.4550e-01, time/batch = 15.5313s	
15866/33250 (epoch 23.859), train_loss = 0.80896563, grad/param norm = 1.6354e-01, time/batch = 16.5997s	
15867/33250 (epoch 23.860), train_loss = 0.92417987, grad/param norm = 1.5230e-01, time/batch = 15.6919s	
15868/33250 (epoch 23.862), train_loss = 0.82061509, grad/param norm = 1.6455e-01, time/batch = 15.5444s	
15869/33250 (epoch 23.863), train_loss = 0.84939302, grad/param norm = 1.5729e-01, time/batch = 18.2845s	
15870/33250 (epoch 23.865), train_loss = 0.93502677, grad/param norm = 1.4940e-01, time/batch = 18.5465s	
15871/33250 (epoch 23.866), train_loss = 0.82684638, grad/param norm = 1.7658e-01, time/batch = 16.2745s	
15872/33250 (epoch 23.868), train_loss = 0.97162644, grad/param norm = 2.0993e-01, time/batch = 18.7538s	
15873/33250 (epoch 23.869), train_loss = 0.94324975, grad/param norm = 1.7495e-01, time/batch = 16.6883s	
15874/33250 (epoch 23.871), train_loss = 0.72043867, grad/param norm = 1.4091e-01, time/batch = 16.0186s	
15875/33250 (epoch 23.872), train_loss = 0.94580308, grad/param norm = 1.4933e-01, time/batch = 15.2572s	
15876/33250 (epoch 23.874), train_loss = 0.82610728, grad/param norm = 1.5461e-01, time/batch = 16.3564s	
15877/33250 (epoch 23.875), train_loss = 0.80687933, grad/param norm = 1.8019e-01, time/batch = 16.2705s	
15878/33250 (epoch 23.877), train_loss = 1.03647609, grad/param norm = 1.7054e-01, time/batch = 15.7024s	
15879/33250 (epoch 23.878), train_loss = 0.93643820, grad/param norm = 1.4972e-01, time/batch = 15.4218s	
15880/33250 (epoch 23.880), train_loss = 0.90366440, grad/param norm = 2.2148e-01, time/batch = 18.2947s	
15881/33250 (epoch 23.881), train_loss = 1.02282258, grad/param norm = 1.7677e-01, time/batch = 18.3696s	
15882/33250 (epoch 23.883), train_loss = 0.92677371, grad/param norm = 1.5907e-01, time/batch = 16.2667s	
15883/33250 (epoch 23.884), train_loss = 0.96808687, grad/param norm = 1.7268e-01, time/batch = 18.5122s	
15884/33250 (epoch 23.886), train_loss = 0.83842873, grad/param norm = 1.3426e-01, time/batch = 16.7638s	
15885/33250 (epoch 23.887), train_loss = 0.87192324, grad/param norm = 1.8684e-01, time/batch = 15.1170s	
15886/33250 (epoch 23.889), train_loss = 0.86300441, grad/param norm = 1.4207e-01, time/batch = 16.9289s	
15887/33250 (epoch 23.890), train_loss = 0.73150625, grad/param norm = 1.3645e-01, time/batch = 17.5981s	
15888/33250 (epoch 23.892), train_loss = 0.95924495, grad/param norm = 1.5784e-01, time/batch = 18.4385s	
15889/33250 (epoch 23.893), train_loss = 0.95412287, grad/param norm = 1.7057e-01, time/batch = 17.2072s	
15890/33250 (epoch 23.895), train_loss = 0.85575468, grad/param norm = 1.5980e-01, time/batch = 19.0329s	
15891/33250 (epoch 23.896), train_loss = 0.99932962, grad/param norm = 1.8190e-01, time/batch = 17.1949s	
15892/33250 (epoch 23.898), train_loss = 0.92832508, grad/param norm = 1.6302e-01, time/batch = 15.5899s	
15893/33250 (epoch 23.899), train_loss = 0.84323867, grad/param norm = 1.5616e-01, time/batch = 16.8536s	
15894/33250 (epoch 23.901), train_loss = 0.77812808, grad/param norm = 1.3275e-01, time/batch = 16.2683s	
15895/33250 (epoch 23.902), train_loss = 0.87125331, grad/param norm = 1.5560e-01, time/batch = 17.0845s	
15896/33250 (epoch 23.904), train_loss = 0.82645491, grad/param norm = 1.3556e-01, time/batch = 15.5992s	
15897/33250 (epoch 23.905), train_loss = 0.86102789, grad/param norm = 1.4325e-01, time/batch = 16.4348s	
15898/33250 (epoch 23.907), train_loss = 0.80010785, grad/param norm = 1.4690e-01, time/batch = 18.8640s	
15899/33250 (epoch 23.908), train_loss = 0.89207288, grad/param norm = 1.4279e-01, time/batch = 16.3835s	
15900/33250 (epoch 23.910), train_loss = 0.96718372, grad/param norm = 1.6792e-01, time/batch = 16.5219s	
15901/33250 (epoch 23.911), train_loss = 0.79290138, grad/param norm = 1.4173e-01, time/batch = 19.2638s	
15902/33250 (epoch 23.913), train_loss = 0.85324404, grad/param norm = 1.4122e-01, time/batch = 16.2536s	
15903/33250 (epoch 23.914), train_loss = 0.78297735, grad/param norm = 1.5661e-01, time/batch = 16.1615s	
15904/33250 (epoch 23.916), train_loss = 0.83684846, grad/param norm = 1.4913e-01, time/batch = 17.2646s	
15905/33250 (epoch 23.917), train_loss = 0.87098893, grad/param norm = 1.2911e-01, time/batch = 18.6624s	
15906/33250 (epoch 23.919), train_loss = 0.83381204, grad/param norm = 1.6014e-01, time/batch = 15.4456s	
15907/33250 (epoch 23.920), train_loss = 0.88830482, grad/param norm = 1.6320e-01, time/batch = 17.4306s	
15908/33250 (epoch 23.922), train_loss = 0.93083263, grad/param norm = 1.7296e-01, time/batch = 18.1216s	
15909/33250 (epoch 23.923), train_loss = 0.84531544, grad/param norm = 1.6673e-01, time/batch = 18.0932s	
15910/33250 (epoch 23.925), train_loss = 0.85533061, grad/param norm = 1.6352e-01, time/batch = 17.6163s	
15911/33250 (epoch 23.926), train_loss = 0.85281024, grad/param norm = 1.4558e-01, time/batch = 16.9926s	
15912/33250 (epoch 23.928), train_loss = 0.87940314, grad/param norm = 1.7371e-01, time/batch = 18.9158s	
15913/33250 (epoch 23.929), train_loss = 0.74719336, grad/param norm = 1.3513e-01, time/batch = 15.4876s	
15914/33250 (epoch 23.931), train_loss = 0.99149477, grad/param norm = 1.6206e-01, time/batch = 18.4189s	
15915/33250 (epoch 23.932), train_loss = 0.86718442, grad/param norm = 1.6119e-01, time/batch = 16.6165s	
15916/33250 (epoch 23.934), train_loss = 0.82060858, grad/param norm = 1.3468e-01, time/batch = 16.0237s	
15917/33250 (epoch 23.935), train_loss = 0.82293237, grad/param norm = 1.7340e-01, time/batch = 16.9600s	
15918/33250 (epoch 23.937), train_loss = 0.82305896, grad/param norm = 1.8178e-01, time/batch = 18.4467s	
15919/33250 (epoch 23.938), train_loss = 0.91287261, grad/param norm = 1.7320e-01, time/batch = 19.2862s	
15920/33250 (epoch 23.940), train_loss = 0.85785970, grad/param norm = 1.5101e-01, time/batch = 16.7813s	
15921/33250 (epoch 23.941), train_loss = 0.94938111, grad/param norm = 1.6150e-01, time/batch = 16.0253s	
15922/33250 (epoch 23.943), train_loss = 1.04122018, grad/param norm = 1.7513e-01, time/batch = 15.5983s	
15923/33250 (epoch 23.944), train_loss = 0.84499633, grad/param norm = 1.3856e-01, time/batch = 16.7523s	
15924/33250 (epoch 23.946), train_loss = 0.99562608, grad/param norm = 1.6185e-01, time/batch = 16.9295s	
15925/33250 (epoch 23.947), train_loss = 0.81345566, grad/param norm = 1.4868e-01, time/batch = 15.3716s	
15926/33250 (epoch 23.949), train_loss = 0.95932671, grad/param norm = 1.5681e-01, time/batch = 18.2753s	
15927/33250 (epoch 23.950), train_loss = 0.94851134, grad/param norm = 1.5552e-01, time/batch = 17.1802s	
15928/33250 (epoch 23.952), train_loss = 0.88066326, grad/param norm = 1.7677e-01, time/batch = 18.5872s	
15929/33250 (epoch 23.953), train_loss = 0.95616168, grad/param norm = 1.5622e-01, time/batch = 16.8904s	
15930/33250 (epoch 23.955), train_loss = 1.00302925, grad/param norm = 1.8602e-01, time/batch = 16.3584s	
15931/33250 (epoch 23.956), train_loss = 0.93642721, grad/param norm = 1.9445e-01, time/batch = 15.7796s	
15932/33250 (epoch 23.958), train_loss = 0.84565088, grad/param norm = 1.4554e-01, time/batch = 18.1797s	
15933/33250 (epoch 23.959), train_loss = 0.84844329, grad/param norm = 1.5860e-01, time/batch = 16.3553s	
15934/33250 (epoch 23.961), train_loss = 1.08612802, grad/param norm = 1.5790e-01, time/batch = 17.4326s	
15935/33250 (epoch 23.962), train_loss = 0.88573413, grad/param norm = 1.5590e-01, time/batch = 16.0375s	
15936/33250 (epoch 23.964), train_loss = 1.06528758, grad/param norm = 1.8325e-01, time/batch = 17.5882s	
15937/33250 (epoch 23.965), train_loss = 0.95505316, grad/param norm = 1.7378e-01, time/batch = 18.0353s	
15938/33250 (epoch 23.967), train_loss = 0.93547801, grad/param norm = 1.5773e-01, time/batch = 17.8659s	
15939/33250 (epoch 23.968), train_loss = 1.05013033, grad/param norm = 1.5942e-01, time/batch = 18.5383s	
15940/33250 (epoch 23.970), train_loss = 1.15538924, grad/param norm = 1.9054e-01, time/batch = 16.0357s	
15941/33250 (epoch 23.971), train_loss = 1.03082118, grad/param norm = 1.7000e-01, time/batch = 17.8430s	
15942/33250 (epoch 23.973), train_loss = 0.86503262, grad/param norm = 1.5000e-01, time/batch = 15.6746s	
15943/33250 (epoch 23.974), train_loss = 0.99555102, grad/param norm = 1.7577e-01, time/batch = 17.2423s	
15944/33250 (epoch 23.976), train_loss = 0.86960339, grad/param norm = 1.5925e-01, time/batch = 16.1919s	
15945/33250 (epoch 23.977), train_loss = 0.87318257, grad/param norm = 1.5749e-01, time/batch = 15.9400s	
15946/33250 (epoch 23.979), train_loss = 0.94136446, grad/param norm = 1.7276e-01, time/batch = 17.1116s	
15947/33250 (epoch 23.980), train_loss = 0.94504190, grad/param norm = 1.5325e-01, time/batch = 18.4647s	
15948/33250 (epoch 23.982), train_loss = 0.82789521, grad/param norm = 1.4222e-01, time/batch = 16.1901s	
15949/33250 (epoch 23.983), train_loss = 0.94318269, grad/param norm = 1.7111e-01, time/batch = 19.7684s	
15950/33250 (epoch 23.985), train_loss = 0.87259703, grad/param norm = 1.7600e-01, time/batch = 17.1876s	
15951/33250 (epoch 23.986), train_loss = 0.97664368, grad/param norm = 1.6101e-01, time/batch = 15.2608s	
15952/33250 (epoch 23.988), train_loss = 1.00555479, grad/param norm = 1.5918e-01, time/batch = 16.8330s	
15953/33250 (epoch 23.989), train_loss = 0.98384437, grad/param norm = 1.8084e-01, time/batch = 17.1765s	
15954/33250 (epoch 23.991), train_loss = 0.93435655, grad/param norm = 1.6057e-01, time/batch = 17.4889s	
15955/33250 (epoch 23.992), train_loss = 0.86805644, grad/param norm = 1.5581e-01, time/batch = 15.2463s	
15956/33250 (epoch 23.994), train_loss = 0.88459154, grad/param norm = 1.4701e-01, time/batch = 17.6925s	
15957/33250 (epoch 23.995), train_loss = 0.86909456, grad/param norm = 1.9209e-01, time/batch = 17.6784s	
15958/33250 (epoch 23.997), train_loss = 0.66350456, grad/param norm = 1.4481e-01, time/batch = 18.0179s	
15959/33250 (epoch 23.998), train_loss = 0.95257570, grad/param norm = 1.5344e-01, time/batch = 19.5143s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
15960/33250 (epoch 24.000), train_loss = 0.92130675, grad/param norm = 1.5931e-01, time/batch = 15.5963s	
15961/33250 (epoch 24.002), train_loss = 1.07229256, grad/param norm = 1.6362e-01, time/batch = 18.0874s	
15962/33250 (epoch 24.003), train_loss = 0.98650438, grad/param norm = 1.8081e-01, time/batch = 16.4047s	
15963/33250 (epoch 24.005), train_loss = 0.74338716, grad/param norm = 1.4169e-01, time/batch = 18.2558s	
15964/33250 (epoch 24.006), train_loss = 0.77898100, grad/param norm = 1.4737e-01, time/batch = 16.8553s	
15965/33250 (epoch 24.008), train_loss = 1.03282446, grad/param norm = 1.5590e-01, time/batch = 16.6108s	
15966/33250 (epoch 24.009), train_loss = 1.06771010, grad/param norm = 1.8028e-01, time/batch = 15.7670s	
15967/33250 (epoch 24.011), train_loss = 0.83304132, grad/param norm = 1.5886e-01, time/batch = 16.0268s	
15968/33250 (epoch 24.012), train_loss = 0.92355538, grad/param norm = 1.8500e-01, time/batch = 18.7850s	
15969/33250 (epoch 24.014), train_loss = 1.02151240, grad/param norm = 1.6803e-01, time/batch = 15.7979s	
15970/33250 (epoch 24.015), train_loss = 0.90585478, grad/param norm = 1.4743e-01, time/batch = 19.5316s	
15971/33250 (epoch 24.017), train_loss = 0.92920457, grad/param norm = 1.9055e-01, time/batch = 17.4396s	
15972/33250 (epoch 24.018), train_loss = 0.74717390, grad/param norm = 1.3761e-01, time/batch = 15.7682s	
15973/33250 (epoch 24.020), train_loss = 0.90203350, grad/param norm = 1.4220e-01, time/batch = 16.2839s	
15974/33250 (epoch 24.021), train_loss = 0.94676466, grad/param norm = 1.5805e-01, time/batch = 15.7566s	
15975/33250 (epoch 24.023), train_loss = 0.77256184, grad/param norm = 1.8947e-01, time/batch = 18.4228s	
15976/33250 (epoch 24.024), train_loss = 0.99412256, grad/param norm = 1.6372e-01, time/batch = 16.1005s	
15977/33250 (epoch 24.026), train_loss = 0.92917424, grad/param norm = 1.6238e-01, time/batch = 19.4190s	
15978/33250 (epoch 24.027), train_loss = 0.91847515, grad/param norm = 1.4398e-01, time/batch = 18.9499s	
15979/33250 (epoch 24.029), train_loss = 0.90514487, grad/param norm = 1.5159e-01, time/batch = 16.6891s	
15980/33250 (epoch 24.030), train_loss = 0.90366991, grad/param norm = 1.7761e-01, time/batch = 15.9148s	
15981/33250 (epoch 24.032), train_loss = 1.09938176, grad/param norm = 1.8822e-01, time/batch = 17.2859s	
15982/33250 (epoch 24.033), train_loss = 0.86438889, grad/param norm = 1.4868e-01, time/batch = 15.8336s	
15983/33250 (epoch 24.035), train_loss = 0.89508871, grad/param norm = 1.7718e-01, time/batch = 15.8438s	
15984/33250 (epoch 24.036), train_loss = 0.96726880, grad/param norm = 1.8381e-01, time/batch = 15.2779s	
15985/33250 (epoch 24.038), train_loss = 0.92129591, grad/param norm = 1.3952e-01, time/batch = 18.4252s	
15986/33250 (epoch 24.039), train_loss = 0.82835895, grad/param norm = 1.4919e-01, time/batch = 16.6065s	
15987/33250 (epoch 24.041), train_loss = 0.92122000, grad/param norm = 1.8267e-01, time/batch = 15.8668s	
15988/33250 (epoch 24.042), train_loss = 0.75362775, grad/param norm = 1.3505e-01, time/batch = 18.3631s	
15989/33250 (epoch 24.044), train_loss = 1.02563309, grad/param norm = 1.7465e-01, time/batch = 18.9523s	
15990/33250 (epoch 24.045), train_loss = 1.01034488, grad/param norm = 1.6027e-01, time/batch = 18.3373s	
15991/33250 (epoch 24.047), train_loss = 0.90669428, grad/param norm = 1.8703e-01, time/batch = 16.9251s	
15992/33250 (epoch 24.048), train_loss = 1.02364794, grad/param norm = 1.8336e-01, time/batch = 17.2008s	
15993/33250 (epoch 24.050), train_loss = 0.90664291, grad/param norm = 1.5237e-01, time/batch = 16.4388s	
15994/33250 (epoch 24.051), train_loss = 0.89284506, grad/param norm = 1.4199e-01, time/batch = 15.9376s	
15995/33250 (epoch 24.053), train_loss = 0.90907581, grad/param norm = 1.8649e-01, time/batch = 16.8519s	
15996/33250 (epoch 24.054), train_loss = 0.80040932, grad/param norm = 1.4432e-01, time/batch = 18.0141s	
15997/33250 (epoch 24.056), train_loss = 0.82367206, grad/param norm = 1.4966e-01, time/batch = 18.4398s	
15998/33250 (epoch 24.057), train_loss = 0.98693200, grad/param norm = 1.4350e-01, time/batch = 17.8690s	
15999/33250 (epoch 24.059), train_loss = 0.87493861, grad/param norm = 1.4305e-01, time/batch = 16.1108s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch24.06_1.5007.t7	
16000/33250 (epoch 24.060), train_loss = 0.92216438, grad/param norm = 1.6440e-01, time/batch = 16.2893s	
16001/33250 (epoch 24.062), train_loss = 1.41572929, grad/param norm = 2.1389e-01, time/batch = 17.3855s	
16002/33250 (epoch 24.063), train_loss = 1.06077075, grad/param norm = 1.6100e-01, time/batch = 14.8665s	
16003/33250 (epoch 24.065), train_loss = 0.92637952, grad/param norm = 1.5724e-01, time/batch = 16.0227s	
16004/33250 (epoch 24.066), train_loss = 0.96347795, grad/param norm = 1.6439e-01, time/batch = 16.9263s	
16005/33250 (epoch 24.068), train_loss = 0.87812630, grad/param norm = 1.7921e-01, time/batch = 16.4441s	
16006/33250 (epoch 24.069), train_loss = 0.91785023, grad/param norm = 1.5969e-01, time/batch = 15.6775s	
16007/33250 (epoch 24.071), train_loss = 0.82153744, grad/param norm = 1.3920e-01, time/batch = 16.6022s	
16008/33250 (epoch 24.072), train_loss = 0.82517502, grad/param norm = 1.3807e-01, time/batch = 17.2061s	
16009/33250 (epoch 24.074), train_loss = 0.97616148, grad/param norm = 1.6151e-01, time/batch = 17.6118s	
16010/33250 (epoch 24.075), train_loss = 0.85114557, grad/param norm = 1.5005e-01, time/batch = 15.9449s	
16011/33250 (epoch 24.077), train_loss = 0.92091951, grad/param norm = 1.7178e-01, time/batch = 16.2247s	
16012/33250 (epoch 24.078), train_loss = 0.92472425, grad/param norm = 1.5249e-01, time/batch = 16.9260s	
16013/33250 (epoch 24.080), train_loss = 0.92052793, grad/param norm = 1.8623e-01, time/batch = 15.8300s	
16014/33250 (epoch 24.081), train_loss = 0.94505832, grad/param norm = 1.5529e-01, time/batch = 16.5093s	
16015/33250 (epoch 24.083), train_loss = 1.01596837, grad/param norm = 1.5727e-01, time/batch = 17.2745s	
16016/33250 (epoch 24.084), train_loss = 0.90270178, grad/param norm = 1.6869e-01, time/batch = 18.3391s	
16017/33250 (epoch 24.086), train_loss = 0.90352148, grad/param norm = 1.5249e-01, time/batch = 14.9531s	
16018/33250 (epoch 24.087), train_loss = 0.80555040, grad/param norm = 1.5168e-01, time/batch = 17.6079s	
16019/33250 (epoch 24.089), train_loss = 0.94491686, grad/param norm = 1.5713e-01, time/batch = 18.9589s	
16020/33250 (epoch 24.090), train_loss = 0.93828310, grad/param norm = 1.5758e-01, time/batch = 16.4577s	
16021/33250 (epoch 24.092), train_loss = 0.85746394, grad/param norm = 1.3803e-01, time/batch = 19.5220s	
16022/33250 (epoch 24.093), train_loss = 0.90939496, grad/param norm = 1.4836e-01, time/batch = 16.4440s	
16023/33250 (epoch 24.095), train_loss = 0.88584275, grad/param norm = 1.5762e-01, time/batch = 17.0754s	
16024/33250 (epoch 24.096), train_loss = 0.76029453, grad/param norm = 1.4845e-01, time/batch = 15.7588s	
16025/33250 (epoch 24.098), train_loss = 0.78766461, grad/param norm = 1.6037e-01, time/batch = 17.7525s	
16026/33250 (epoch 24.099), train_loss = 0.68610759, grad/param norm = 1.4180e-01, time/batch = 16.3590s	
16027/33250 (epoch 24.101), train_loss = 0.90305114, grad/param norm = 1.5488e-01, time/batch = 15.8469s	
16028/33250 (epoch 24.102), train_loss = 0.83823183, grad/param norm = 1.4583e-01, time/batch = 16.1147s	
16029/33250 (epoch 24.104), train_loss = 0.69326007, grad/param norm = 1.2328e-01, time/batch = 17.4440s	
16030/33250 (epoch 24.105), train_loss = 0.84929515, grad/param norm = 1.5314e-01, time/batch = 17.9522s	
16031/33250 (epoch 24.107), train_loss = 0.77138486, grad/param norm = 1.2783e-01, time/batch = 17.9549s	
16032/33250 (epoch 24.108), train_loss = 0.91026525, grad/param norm = 1.6305e-01, time/batch = 16.2848s	
16033/33250 (epoch 24.110), train_loss = 0.74821929, grad/param norm = 1.4624e-01, time/batch = 16.0987s	
16034/33250 (epoch 24.111), train_loss = 0.87625218, grad/param norm = 1.5422e-01, time/batch = 15.8364s	
16035/33250 (epoch 24.113), train_loss = 0.85931924, grad/param norm = 1.6284e-01, time/batch = 18.3309s	
16036/33250 (epoch 24.114), train_loss = 0.80164956, grad/param norm = 1.5777e-01, time/batch = 16.9343s	
16037/33250 (epoch 24.116), train_loss = 0.86955856, grad/param norm = 1.5364e-01, time/batch = 17.4269s	
16038/33250 (epoch 24.117), train_loss = 0.83937384, grad/param norm = 1.5468e-01, time/batch = 16.3693s	
16039/33250 (epoch 24.119), train_loss = 0.85717880, grad/param norm = 1.5176e-01, time/batch = 18.4474s	
16040/33250 (epoch 24.120), train_loss = 0.68968299, grad/param norm = 1.2418e-01, time/batch = 17.7857s	
16041/33250 (epoch 24.122), train_loss = 0.97228228, grad/param norm = 1.5709e-01, time/batch = 11.9304s	
16042/33250 (epoch 24.123), train_loss = 0.87797412, grad/param norm = 1.5419e-01, time/batch = 0.8052s	
16043/33250 (epoch 24.125), train_loss = 0.72841240, grad/param norm = 1.4947e-01, time/batch = 0.6554s	
16044/33250 (epoch 24.126), train_loss = 0.87456942, grad/param norm = 1.5013e-01, time/batch = 0.6559s	
16045/33250 (epoch 24.128), train_loss = 0.83541142, grad/param norm = 1.4214e-01, time/batch = 0.6648s	
16046/33250 (epoch 24.129), train_loss = 0.89639469, grad/param norm = 1.5288e-01, time/batch = 0.6546s	
16047/33250 (epoch 24.131), train_loss = 0.87311260, grad/param norm = 1.6449e-01, time/batch = 0.6548s	
16048/33250 (epoch 24.132), train_loss = 0.88427889, grad/param norm = 1.7003e-01, time/batch = 0.8369s	
16049/33250 (epoch 24.134), train_loss = 0.87480177, grad/param norm = 1.5855e-01, time/batch = 0.9620s	
16050/33250 (epoch 24.135), train_loss = 0.86575456, grad/param norm = 1.4626e-01, time/batch = 0.9721s	
16051/33250 (epoch 24.137), train_loss = 0.80444144, grad/param norm = 1.6264e-01, time/batch = 0.9610s	
16052/33250 (epoch 24.138), train_loss = 0.83257017, grad/param norm = 1.4310e-01, time/batch = 0.9498s	
16053/33250 (epoch 24.140), train_loss = 0.70432720, grad/param norm = 1.4802e-01, time/batch = 1.3429s	
16054/33250 (epoch 24.141), train_loss = 1.01269811, grad/param norm = 2.0526e-01, time/batch = 1.7733s	
16055/33250 (epoch 24.143), train_loss = 0.71179411, grad/param norm = 1.6696e-01, time/batch = 1.8392s	
16056/33250 (epoch 24.144), train_loss = 0.85177361, grad/param norm = 1.5908e-01, time/batch = 13.0405s	
16057/33250 (epoch 24.146), train_loss = 0.83188235, grad/param norm = 1.4026e-01, time/batch = 15.5203s	
16058/33250 (epoch 24.147), train_loss = 0.86091715, grad/param norm = 1.6073e-01, time/batch = 16.7521s	
16059/33250 (epoch 24.149), train_loss = 0.82357079, grad/param norm = 1.5657e-01, time/batch = 15.3511s	
16060/33250 (epoch 24.150), train_loss = 0.78446948, grad/param norm = 1.5018e-01, time/batch = 17.1974s	
16061/33250 (epoch 24.152), train_loss = 0.74598222, grad/param norm = 1.6014e-01, time/batch = 16.7789s	
16062/33250 (epoch 24.153), train_loss = 1.01002929, grad/param norm = 1.6167e-01, time/batch = 15.3552s	
16063/33250 (epoch 24.155), train_loss = 0.85829868, grad/param norm = 1.6281e-01, time/batch = 18.7041s	
16064/33250 (epoch 24.156), train_loss = 1.07493377, grad/param norm = 1.5472e-01, time/batch = 19.7748s	
16065/33250 (epoch 24.158), train_loss = 1.04822160, grad/param norm = 1.5891e-01, time/batch = 17.3439s	
16066/33250 (epoch 24.159), train_loss = 0.86811612, grad/param norm = 1.6907e-01, time/batch = 16.0718s	
16067/33250 (epoch 24.161), train_loss = 0.93078124, grad/param norm = 1.6084e-01, time/batch = 16.1859s	
16068/33250 (epoch 24.162), train_loss = 0.78879668, grad/param norm = 1.4950e-01, time/batch = 17.9322s	
16069/33250 (epoch 24.164), train_loss = 0.85336812, grad/param norm = 1.5187e-01, time/batch = 15.0232s	
16070/33250 (epoch 24.165), train_loss = 0.95212358, grad/param norm = 1.8006e-01, time/batch = 17.7620s	
16071/33250 (epoch 24.167), train_loss = 1.03700380, grad/param norm = 1.8083e-01, time/batch = 18.8441s	
16072/33250 (epoch 24.168), train_loss = 0.73870933, grad/param norm = 1.2222e-01, time/batch = 17.7581s	
16073/33250 (epoch 24.170), train_loss = 0.85693931, grad/param norm = 1.8383e-01, time/batch = 16.6987s	
16074/33250 (epoch 24.171), train_loss = 0.85772099, grad/param norm = 1.5054e-01, time/batch = 17.4531s	
16075/33250 (epoch 24.173), train_loss = 0.82286397, grad/param norm = 1.4396e-01, time/batch = 17.5201s	
16076/33250 (epoch 24.174), train_loss = 0.89519931, grad/param norm = 1.4719e-01, time/batch = 15.0915s	
16077/33250 (epoch 24.176), train_loss = 0.85551102, grad/param norm = 1.8171e-01, time/batch = 17.0141s	
16078/33250 (epoch 24.177), train_loss = 0.84399045, grad/param norm = 1.4336e-01, time/batch = 14.8658s	
16079/33250 (epoch 24.179), train_loss = 0.78955717, grad/param norm = 1.4541e-01, time/batch = 17.0141s	
16080/33250 (epoch 24.180), train_loss = 0.72961340, grad/param norm = 1.4243e-01, time/batch = 15.2102s	
16081/33250 (epoch 24.182), train_loss = 0.82230211, grad/param norm = 1.5286e-01, time/batch = 17.2894s	
16082/33250 (epoch 24.183), train_loss = 1.01092500, grad/param norm = 1.7590e-01, time/batch = 19.4410s	
16083/33250 (epoch 24.185), train_loss = 0.94117526, grad/param norm = 1.7765e-01, time/batch = 16.3027s	
16084/33250 (epoch 24.186), train_loss = 0.92689452, grad/param norm = 2.1088e-01, time/batch = 16.7539s	
16085/33250 (epoch 24.188), train_loss = 1.00834113, grad/param norm = 1.8544e-01, time/batch = 17.4294s	
16086/33250 (epoch 24.189), train_loss = 0.71238411, grad/param norm = 1.5747e-01, time/batch = 17.9023s	
16087/33250 (epoch 24.191), train_loss = 0.81477776, grad/param norm = 1.6641e-01, time/batch = 17.2591s	
16088/33250 (epoch 24.192), train_loss = 0.83428466, grad/param norm = 1.4913e-01, time/batch = 16.6894s	
16089/33250 (epoch 24.194), train_loss = 0.86031922, grad/param norm = 1.5420e-01, time/batch = 17.9981s	
16090/33250 (epoch 24.195), train_loss = 1.04391148, grad/param norm = 1.5361e-01, time/batch = 15.1080s	
16091/33250 (epoch 24.197), train_loss = 0.82480260, grad/param norm = 1.4365e-01, time/batch = 18.3476s	
16092/33250 (epoch 24.198), train_loss = 1.00185764, grad/param norm = 1.5518e-01, time/batch = 17.3917s	
16093/33250 (epoch 24.200), train_loss = 0.89936419, grad/param norm = 1.5184e-01, time/batch = 16.6804s	
16094/33250 (epoch 24.202), train_loss = 0.82281218, grad/param norm = 1.3498e-01, time/batch = 16.3394s	
16095/33250 (epoch 24.203), train_loss = 0.80258869, grad/param norm = 1.5356e-01, time/batch = 16.3711s	
16096/33250 (epoch 24.205), train_loss = 0.91853947, grad/param norm = 1.5667e-01, time/batch = 19.2586s	
16097/33250 (epoch 24.206), train_loss = 0.94630834, grad/param norm = 1.6111e-01, time/batch = 15.3623s	
16098/33250 (epoch 24.208), train_loss = 0.98744402, grad/param norm = 1.6649e-01, time/batch = 17.3590s	
16099/33250 (epoch 24.209), train_loss = 0.80444282, grad/param norm = 1.5113e-01, time/batch = 16.7664s	
16100/33250 (epoch 24.211), train_loss = 0.94085460, grad/param norm = 1.6647e-01, time/batch = 16.1861s	
16101/33250 (epoch 24.212), train_loss = 1.07868579, grad/param norm = 1.6205e-01, time/batch = 17.2652s	
16102/33250 (epoch 24.214), train_loss = 0.89400493, grad/param norm = 1.4758e-01, time/batch = 19.0454s	
16103/33250 (epoch 24.215), train_loss = 1.01870218, grad/param norm = 2.1171e-01, time/batch = 19.0233s	
16104/33250 (epoch 24.217), train_loss = 1.01366112, grad/param norm = 2.1210e-01, time/batch = 15.6145s	
16105/33250 (epoch 24.218), train_loss = 0.98233282, grad/param norm = 1.5122e-01, time/batch = 16.8615s	
16106/33250 (epoch 24.220), train_loss = 0.92679373, grad/param norm = 1.7868e-01, time/batch = 18.8346s	
16107/33250 (epoch 24.221), train_loss = 1.07728042, grad/param norm = 1.9332e-01, time/batch = 16.7366s	
16108/33250 (epoch 24.223), train_loss = 0.89807884, grad/param norm = 1.4926e-01, time/batch = 16.2782s	
16109/33250 (epoch 24.224), train_loss = 0.94772377, grad/param norm = 1.7905e-01, time/batch = 15.7687s	
16110/33250 (epoch 24.226), train_loss = 1.02733934, grad/param norm = 1.7204e-01, time/batch = 15.2833s	
16111/33250 (epoch 24.227), train_loss = 0.94899683, grad/param norm = 1.6617e-01, time/batch = 15.4561s	
16112/33250 (epoch 24.229), train_loss = 0.91449532, grad/param norm = 1.5083e-01, time/batch = 17.3471s	
16113/33250 (epoch 24.230), train_loss = 0.89927309, grad/param norm = 1.6544e-01, time/batch = 17.3652s	
16114/33250 (epoch 24.232), train_loss = 0.85549446, grad/param norm = 1.4482e-01, time/batch = 16.7589s	
16115/33250 (epoch 24.233), train_loss = 0.81680596, grad/param norm = 1.4730e-01, time/batch = 17.1080s	
16116/33250 (epoch 24.235), train_loss = 1.04360626, grad/param norm = 1.5279e-01, time/batch = 16.6070s	
16117/33250 (epoch 24.236), train_loss = 0.82106041, grad/param norm = 1.4657e-01, time/batch = 17.6834s	
16118/33250 (epoch 24.238), train_loss = 1.01551712, grad/param norm = 1.6500e-01, time/batch = 15.9363s	
16119/33250 (epoch 24.239), train_loss = 1.01831764, grad/param norm = 1.7904e-01, time/batch = 16.2658s	
16120/33250 (epoch 24.241), train_loss = 1.00283594, grad/param norm = 1.8841e-01, time/batch = 18.5934s	
16121/33250 (epoch 24.242), train_loss = 0.99117951, grad/param norm = 1.6267e-01, time/batch = 16.0067s	
16122/33250 (epoch 24.244), train_loss = 0.97610215, grad/param norm = 2.0071e-01, time/batch = 17.2865s	
16123/33250 (epoch 24.245), train_loss = 0.94514876, grad/param norm = 1.6649e-01, time/batch = 16.7237s	
16124/33250 (epoch 24.247), train_loss = 0.91854040, grad/param norm = 1.6672e-01, time/batch = 16.6044s	
16125/33250 (epoch 24.248), train_loss = 1.08939278, grad/param norm = 1.8328e-01, time/batch = 15.8340s	
16126/33250 (epoch 24.250), train_loss = 1.00192870, grad/param norm = 1.5354e-01, time/batch = 16.5169s	
16127/33250 (epoch 24.251), train_loss = 0.87582729, grad/param norm = 1.4643e-01, time/batch = 17.1859s	
16128/33250 (epoch 24.253), train_loss = 0.86134936, grad/param norm = 1.3452e-01, time/batch = 17.3540s	
16129/33250 (epoch 24.254), train_loss = 0.84156159, grad/param norm = 1.5374e-01, time/batch = 15.5022s	
16130/33250 (epoch 24.256), train_loss = 0.92069701, grad/param norm = 1.4855e-01, time/batch = 17.4190s	
16131/33250 (epoch 24.257), train_loss = 1.03418732, grad/param norm = 1.6845e-01, time/batch = 16.8711s	
16132/33250 (epoch 24.259), train_loss = 0.94696386, grad/param norm = 1.5548e-01, time/batch = 18.2016s	
16133/33250 (epoch 24.260), train_loss = 0.77511142, grad/param norm = 1.4997e-01, time/batch = 18.1790s	
16134/33250 (epoch 24.262), train_loss = 0.92526374, grad/param norm = 1.4845e-01, time/batch = 17.6178s	
16135/33250 (epoch 24.263), train_loss = 0.79829817, grad/param norm = 1.4584e-01, time/batch = 17.6007s	
16136/33250 (epoch 24.265), train_loss = 0.97079221, grad/param norm = 1.7236e-01, time/batch = 15.4439s	
16137/33250 (epoch 24.266), train_loss = 0.88163431, grad/param norm = 1.6478e-01, time/batch = 18.9200s	
16138/33250 (epoch 24.268), train_loss = 0.81395262, grad/param norm = 1.5864e-01, time/batch = 17.6840s	
16139/33250 (epoch 24.269), train_loss = 0.73329787, grad/param norm = 1.4526e-01, time/batch = 16.1520s	
16140/33250 (epoch 24.271), train_loss = 0.89901712, grad/param norm = 1.4372e-01, time/batch = 18.1921s	
16141/33250 (epoch 24.272), train_loss = 0.81698859, grad/param norm = 1.3826e-01, time/batch = 18.3729s	
16142/33250 (epoch 24.274), train_loss = 0.68486675, grad/param norm = 1.2576e-01, time/batch = 16.6016s	
16143/33250 (epoch 24.275), train_loss = 0.81705716, grad/param norm = 1.2509e-01, time/batch = 16.6941s	
16144/33250 (epoch 24.277), train_loss = 0.71227052, grad/param norm = 1.4231e-01, time/batch = 16.4331s	
16145/33250 (epoch 24.278), train_loss = 0.81811292, grad/param norm = 1.4711e-01, time/batch = 15.3717s	
16146/33250 (epoch 24.280), train_loss = 0.79914732, grad/param norm = 1.4723e-01, time/batch = 14.9558s	
16147/33250 (epoch 24.281), train_loss = 0.92259898, grad/param norm = 1.6719e-01, time/batch = 15.3483s	
16148/33250 (epoch 24.283), train_loss = 0.93582324, grad/param norm = 2.0898e-01, time/batch = 18.7463s	
16149/33250 (epoch 24.284), train_loss = 0.82846817, grad/param norm = 1.9133e-01, time/batch = 17.2491s	
16150/33250 (epoch 24.286), train_loss = 0.95601167, grad/param norm = 1.6976e-01, time/batch = 16.0913s	
16151/33250 (epoch 24.287), train_loss = 0.78449346, grad/param norm = 1.5203e-01, time/batch = 17.6913s	
16152/33250 (epoch 24.289), train_loss = 0.73446352, grad/param norm = 1.5710e-01, time/batch = 19.4487s	
16153/33250 (epoch 24.290), train_loss = 0.89368093, grad/param norm = 1.6745e-01, time/batch = 16.6269s	
16154/33250 (epoch 24.292), train_loss = 0.95375778, grad/param norm = 1.8680e-01, time/batch = 17.6033s	
16155/33250 (epoch 24.293), train_loss = 1.01201225, grad/param norm = 1.6884e-01, time/batch = 18.1699s	
16156/33250 (epoch 24.295), train_loss = 0.97433284, grad/param norm = 1.7633e-01, time/batch = 18.6600s	
16157/33250 (epoch 24.296), train_loss = 0.91712387, grad/param norm = 1.5796e-01, time/batch = 15.6015s	
16158/33250 (epoch 24.298), train_loss = 0.75411626, grad/param norm = 1.5766e-01, time/batch = 17.7625s	
16159/33250 (epoch 24.299), train_loss = 0.71537464, grad/param norm = 1.3864e-01, time/batch = 17.0998s	
16160/33250 (epoch 24.301), train_loss = 0.97673908, grad/param norm = 1.5635e-01, time/batch = 16.5311s	
16161/33250 (epoch 24.302), train_loss = 0.96188186, grad/param norm = 1.7474e-01, time/batch = 16.6080s	
16162/33250 (epoch 24.304), train_loss = 0.80663652, grad/param norm = 1.4747e-01, time/batch = 14.8633s	
16163/33250 (epoch 24.305), train_loss = 0.84914418, grad/param norm = 1.4683e-01, time/batch = 16.6927s	
16164/33250 (epoch 24.307), train_loss = 0.94419861, grad/param norm = 1.5449e-01, time/batch = 14.9788s	
16165/33250 (epoch 24.308), train_loss = 1.03318435, grad/param norm = 1.9521e-01, time/batch = 14.7410s	
16166/33250 (epoch 24.310), train_loss = 0.87727832, grad/param norm = 1.6670e-01, time/batch = 14.5686s	
16167/33250 (epoch 24.311), train_loss = 1.01470759, grad/param norm = 1.5710e-01, time/batch = 14.6488s	
16168/33250 (epoch 24.313), train_loss = 0.77111924, grad/param norm = 1.6539e-01, time/batch = 15.3802s	
16169/33250 (epoch 24.314), train_loss = 0.90618846, grad/param norm = 1.5784e-01, time/batch = 14.8258s	
16170/33250 (epoch 24.316), train_loss = 1.07374410, grad/param norm = 1.9471e-01, time/batch = 14.6281s	
16171/33250 (epoch 24.317), train_loss = 0.79574434, grad/param norm = 1.3863e-01, time/batch = 14.5798s	
16172/33250 (epoch 24.319), train_loss = 0.94539395, grad/param norm = 1.8517e-01, time/batch = 14.6689s	
16173/33250 (epoch 24.320), train_loss = 1.00039410, grad/param norm = 2.1525e-01, time/batch = 14.4197s	
16174/33250 (epoch 24.322), train_loss = 1.02557756, grad/param norm = 1.7482e-01, time/batch = 14.5792s	
16175/33250 (epoch 24.323), train_loss = 1.09507332, grad/param norm = 2.1732e-01, time/batch = 14.3502s	
16176/33250 (epoch 24.325), train_loss = 0.89505833, grad/param norm = 1.8021e-01, time/batch = 15.0717s	
16177/33250 (epoch 24.326), train_loss = 1.06341842, grad/param norm = 1.8813e-01, time/batch = 16.3612s	
16178/33250 (epoch 24.328), train_loss = 0.87994152, grad/param norm = 1.4802e-01, time/batch = 17.0150s	
16179/33250 (epoch 24.329), train_loss = 0.91405796, grad/param norm = 1.8612e-01, time/batch = 16.7583s	
16180/33250 (epoch 24.331), train_loss = 0.87479160, grad/param norm = 1.7018e-01, time/batch = 17.9155s	
16181/33250 (epoch 24.332), train_loss = 0.86414910, grad/param norm = 1.4383e-01, time/batch = 17.5915s	
16182/33250 (epoch 24.334), train_loss = 1.05780771, grad/param norm = 1.5936e-01, time/batch = 18.0468s	
16183/33250 (epoch 24.335), train_loss = 0.67257793, grad/param norm = 1.4879e-01, time/batch = 16.9395s	
16184/33250 (epoch 24.337), train_loss = 0.95017360, grad/param norm = 1.5439e-01, time/batch = 17.9426s	
16185/33250 (epoch 24.338), train_loss = 1.01198179, grad/param norm = 1.5521e-01, time/batch = 16.7697s	
16186/33250 (epoch 24.340), train_loss = 0.91159283, grad/param norm = 1.4894e-01, time/batch = 15.4237s	
16187/33250 (epoch 24.341), train_loss = 0.83560637, grad/param norm = 1.5663e-01, time/batch = 16.4317s	
16188/33250 (epoch 24.343), train_loss = 0.85120465, grad/param norm = 1.5723e-01, time/batch = 16.6950s	
16189/33250 (epoch 24.344), train_loss = 0.89311312, grad/param norm = 1.5062e-01, time/batch = 17.7670s	
16190/33250 (epoch 24.346), train_loss = 0.78733327, grad/param norm = 1.3404e-01, time/batch = 16.3490s	
16191/33250 (epoch 24.347), train_loss = 1.10443163, grad/param norm = 2.2615e-01, time/batch = 16.9609s	
16192/33250 (epoch 24.349), train_loss = 0.83883693, grad/param norm = 1.5806e-01, time/batch = 18.4225s	
16193/33250 (epoch 24.350), train_loss = 0.87067530, grad/param norm = 1.6188e-01, time/batch = 17.5248s	
16194/33250 (epoch 24.352), train_loss = 0.78494783, grad/param norm = 1.5486e-01, time/batch = 17.4469s	
16195/33250 (epoch 24.353), train_loss = 0.85730590, grad/param norm = 1.4588e-01, time/batch = 17.1107s	
16196/33250 (epoch 24.355), train_loss = 0.87108161, grad/param norm = 1.8169e-01, time/batch = 16.6836s	
16197/33250 (epoch 24.356), train_loss = 0.80796149, grad/param norm = 1.6229e-01, time/batch = 15.8505s	
16198/33250 (epoch 24.358), train_loss = 0.86940132, grad/param norm = 1.4877e-01, time/batch = 17.6745s	
16199/33250 (epoch 24.359), train_loss = 0.85122731, grad/param norm = 1.6461e-01, time/batch = 15.7772s	
16200/33250 (epoch 24.361), train_loss = 1.01855853, grad/param norm = 1.8290e-01, time/batch = 18.0819s	
16201/33250 (epoch 24.362), train_loss = 0.91776840, grad/param norm = 1.7451e-01, time/batch = 15.6828s	
16202/33250 (epoch 24.364), train_loss = 0.97423124, grad/param norm = 1.7480e-01, time/batch = 19.0318s	
16203/33250 (epoch 24.365), train_loss = 0.90213547, grad/param norm = 1.5728e-01, time/batch = 18.9499s	
16204/33250 (epoch 24.367), train_loss = 0.89519392, grad/param norm = 1.3336e-01, time/batch = 17.6007s	
16205/33250 (epoch 24.368), train_loss = 0.90114248, grad/param norm = 1.9756e-01, time/batch = 16.2651s	
16206/33250 (epoch 24.370), train_loss = 0.79607712, grad/param norm = 1.4616e-01, time/batch = 16.2754s	
16207/33250 (epoch 24.371), train_loss = 1.00745060, grad/param norm = 1.5790e-01, time/batch = 17.1841s	
16208/33250 (epoch 24.373), train_loss = 0.83858602, grad/param norm = 1.3827e-01, time/batch = 16.4417s	
16209/33250 (epoch 24.374), train_loss = 0.96643309, grad/param norm = 2.3157e-01, time/batch = 18.8357s	
16210/33250 (epoch 24.376), train_loss = 0.86747648, grad/param norm = 1.5663e-01, time/batch = 17.9220s	
16211/33250 (epoch 24.377), train_loss = 0.79827422, grad/param norm = 1.7492e-01, time/batch = 16.1073s	
16212/33250 (epoch 24.379), train_loss = 0.85930662, grad/param norm = 1.7157e-01, time/batch = 17.3837s	
16213/33250 (epoch 24.380), train_loss = 0.94235964, grad/param norm = 2.1897e-01, time/batch = 17.0454s	
16214/33250 (epoch 24.382), train_loss = 0.92280367, grad/param norm = 1.5640e-01, time/batch = 17.4507s	
16215/33250 (epoch 24.383), train_loss = 0.80253853, grad/param norm = 1.7476e-01, time/batch = 18.5102s	
16216/33250 (epoch 24.385), train_loss = 0.78091545, grad/param norm = 1.7130e-01, time/batch = 16.4348s	
16217/33250 (epoch 24.386), train_loss = 0.80699289, grad/param norm = 1.5575e-01, time/batch = 16.2580s	
16218/33250 (epoch 24.388), train_loss = 0.81129706, grad/param norm = 1.5018e-01, time/batch = 16.0847s	
16219/33250 (epoch 24.389), train_loss = 0.86896960, grad/param norm = 1.8418e-01, time/batch = 18.1510s	
16220/33250 (epoch 24.391), train_loss = 0.94253901, grad/param norm = 1.6197e-01, time/batch = 17.2563s	
16221/33250 (epoch 24.392), train_loss = 0.94784556, grad/param norm = 1.6633e-01, time/batch = 17.9310s	
16222/33250 (epoch 24.394), train_loss = 1.00429465, grad/param norm = 1.8928e-01, time/batch = 17.8689s	
16223/33250 (epoch 24.395), train_loss = 0.96924761, grad/param norm = 1.4983e-01, time/batch = 18.8756s	
16224/33250 (epoch 24.397), train_loss = 0.99381913, grad/param norm = 1.6533e-01, time/batch = 18.0232s	
16225/33250 (epoch 24.398), train_loss = 0.83149641, grad/param norm = 1.5748e-01, time/batch = 17.3518s	
16226/33250 (epoch 24.400), train_loss = 0.78571325, grad/param norm = 1.3515e-01, time/batch = 15.7544s	
16227/33250 (epoch 24.402), train_loss = 0.75792648, grad/param norm = 1.6935e-01, time/batch = 15.6760s	
16228/33250 (epoch 24.403), train_loss = 0.87381525, grad/param norm = 1.6716e-01, time/batch = 16.2755s	
16229/33250 (epoch 24.405), train_loss = 0.81782499, grad/param norm = 1.4759e-01, time/batch = 18.1912s	
16230/33250 (epoch 24.406), train_loss = 0.90645305, grad/param norm = 1.6667e-01, time/batch = 17.6831s	
16231/33250 (epoch 24.408), train_loss = 1.05207430, grad/param norm = 1.7801e-01, time/batch = 17.4501s	
16232/33250 (epoch 24.409), train_loss = 0.92711999, grad/param norm = 1.7905e-01, time/batch = 17.9427s	
16233/33250 (epoch 24.411), train_loss = 0.66435361, grad/param norm = 1.1858e-01, time/batch = 16.1978s	
16234/33250 (epoch 24.412), train_loss = 0.75637854, grad/param norm = 1.4481e-01, time/batch = 17.7846s	
16235/33250 (epoch 24.414), train_loss = 0.92984645, grad/param norm = 1.5084e-01, time/batch = 15.7616s	
16236/33250 (epoch 24.415), train_loss = 0.98558943, grad/param norm = 1.9077e-01, time/batch = 16.0216s	
16237/33250 (epoch 24.417), train_loss = 0.95778727, grad/param norm = 1.5695e-01, time/batch = 16.6042s	
16238/33250 (epoch 24.418), train_loss = 1.14055804, grad/param norm = 2.2306e-01, time/batch = 16.0186s	
16239/33250 (epoch 24.420), train_loss = 0.99985671, grad/param norm = 1.6458e-01, time/batch = 17.4268s	
16240/33250 (epoch 24.421), train_loss = 0.83521977, grad/param norm = 1.8201e-01, time/batch = 17.0207s	
16241/33250 (epoch 24.423), train_loss = 0.95973237, grad/param norm = 2.1838e-01, time/batch = 19.8613s	
16242/33250 (epoch 24.424), train_loss = 1.07068457, grad/param norm = 3.0419e-01, time/batch = 16.3647s	
16243/33250 (epoch 24.426), train_loss = 0.82982323, grad/param norm = 1.4215e-01, time/batch = 19.2769s	
16244/33250 (epoch 24.427), train_loss = 0.83818998, grad/param norm = 1.5468e-01, time/batch = 16.4069s	
16245/33250 (epoch 24.429), train_loss = 0.95223877, grad/param norm = 1.8631e-01, time/batch = 17.6716s	
16246/33250 (epoch 24.430), train_loss = 0.87812106, grad/param norm = 1.8422e-01, time/batch = 17.6734s	
16247/33250 (epoch 24.432), train_loss = 0.93717735, grad/param norm = 1.4423e-01, time/batch = 18.2580s	
16248/33250 (epoch 24.433), train_loss = 0.83970820, grad/param norm = 1.7176e-01, time/batch = 18.0128s	
16249/33250 (epoch 24.435), train_loss = 0.98805420, grad/param norm = 1.7185e-01, time/batch = 15.7696s	
16250/33250 (epoch 24.436), train_loss = 0.83311909, grad/param norm = 1.7102e-01, time/batch = 16.9356s	
16251/33250 (epoch 24.438), train_loss = 0.98011240, grad/param norm = 1.6052e-01, time/batch = 17.7028s	
16252/33250 (epoch 24.439), train_loss = 0.91496362, grad/param norm = 1.5012e-01, time/batch = 16.8572s	
16253/33250 (epoch 24.441), train_loss = 0.87752345, grad/param norm = 1.3760e-01, time/batch = 15.0986s	
16254/33250 (epoch 24.442), train_loss = 0.83518962, grad/param norm = 1.7050e-01, time/batch = 15.6962s	
16255/33250 (epoch 24.444), train_loss = 0.85120740, grad/param norm = 1.4629e-01, time/batch = 16.6019s	
16256/33250 (epoch 24.445), train_loss = 0.90407043, grad/param norm = 1.3567e-01, time/batch = 15.5158s	
16257/33250 (epoch 24.447), train_loss = 0.86432320, grad/param norm = 1.6060e-01, time/batch = 16.7598s	
16258/33250 (epoch 24.448), train_loss = 0.92298581, grad/param norm = 1.4496e-01, time/batch = 17.5319s	
16259/33250 (epoch 24.450), train_loss = 1.05559590, grad/param norm = 1.9098e-01, time/batch = 16.6817s	
16260/33250 (epoch 24.451), train_loss = 0.95932197, grad/param norm = 1.9301e-01, time/batch = 16.3473s	
16261/33250 (epoch 24.453), train_loss = 0.80342095, grad/param norm = 1.3610e-01, time/batch = 19.7740s	
16262/33250 (epoch 24.454), train_loss = 1.02934359, grad/param norm = 1.8262e-01, time/batch = 18.5346s	
16263/33250 (epoch 24.456), train_loss = 1.03633811, grad/param norm = 1.4623e-01, time/batch = 16.0415s	
16264/33250 (epoch 24.457), train_loss = 0.86890203, grad/param norm = 1.7308e-01, time/batch = 16.5243s	
16265/33250 (epoch 24.459), train_loss = 0.94662029, grad/param norm = 1.9053e-01, time/batch = 18.1845s	
16266/33250 (epoch 24.460), train_loss = 1.00469227, grad/param norm = 1.8788e-01, time/batch = 20.9587s	
16267/33250 (epoch 24.462), train_loss = 0.83818837, grad/param norm = 1.4649e-01, time/batch = 28.3637s	
16268/33250 (epoch 24.463), train_loss = 0.82306264, grad/param norm = 1.2718e-01, time/batch = 16.0989s	
16269/33250 (epoch 24.465), train_loss = 0.75573768, grad/param norm = 1.2996e-01, time/batch = 15.9437s	
16270/33250 (epoch 24.466), train_loss = 0.71991425, grad/param norm = 1.2403e-01, time/batch = 15.5204s	
16271/33250 (epoch 24.468), train_loss = 0.79088552, grad/param norm = 1.2253e-01, time/batch = 18.9562s	
16272/33250 (epoch 24.469), train_loss = 0.86968397, grad/param norm = 1.7240e-01, time/batch = 17.9486s	
16273/33250 (epoch 24.471), train_loss = 0.95938997, grad/param norm = 1.5277e-01, time/batch = 16.9077s	
16274/33250 (epoch 24.472), train_loss = 0.86989297, grad/param norm = 1.7922e-01, time/batch = 17.2421s	
16275/33250 (epoch 24.474), train_loss = 1.00732810, grad/param norm = 1.6743e-01, time/batch = 16.7694s	
16276/33250 (epoch 24.475), train_loss = 0.92992706, grad/param norm = 1.4965e-01, time/batch = 15.5204s	
16277/33250 (epoch 24.477), train_loss = 0.88139289, grad/param norm = 1.3792e-01, time/batch = 16.9437s	
16278/33250 (epoch 24.478), train_loss = 0.81032169, grad/param norm = 1.5703e-01, time/batch = 17.3441s	
16279/33250 (epoch 24.480), train_loss = 1.07371556, grad/param norm = 1.8144e-01, time/batch = 17.9940s	
16280/33250 (epoch 24.481), train_loss = 0.91873483, grad/param norm = 1.5284e-01, time/batch = 17.6158s	
16281/33250 (epoch 24.483), train_loss = 0.89783748, grad/param norm = 1.5993e-01, time/batch = 19.8659s	
16282/33250 (epoch 24.484), train_loss = 0.80595684, grad/param norm = 1.3940e-01, time/batch = 18.8620s	
16283/33250 (epoch 24.486), train_loss = 0.75871503, grad/param norm = 1.5377e-01, time/batch = 15.6729s	
16284/33250 (epoch 24.487), train_loss = 0.85268773, grad/param norm = 1.5946e-01, time/batch = 18.8101s	
16285/33250 (epoch 24.489), train_loss = 1.00148400, grad/param norm = 1.8307e-01, time/batch = 17.5175s	
16286/33250 (epoch 24.490), train_loss = 0.95828202, grad/param norm = 1.8002e-01, time/batch = 16.7562s	
16287/33250 (epoch 24.492), train_loss = 0.97854557, grad/param norm = 1.6658e-01, time/batch = 16.0079s	
16288/33250 (epoch 24.493), train_loss = 0.90814923, grad/param norm = 1.8430e-01, time/batch = 17.0914s	
16289/33250 (epoch 24.495), train_loss = 0.95946828, grad/param norm = 1.5039e-01, time/batch = 19.4354s	
16290/33250 (epoch 24.496), train_loss = 0.91274466, grad/param norm = 1.4030e-01, time/batch = 16.9401s	
16291/33250 (epoch 24.498), train_loss = 0.98126464, grad/param norm = 1.6531e-01, time/batch = 15.2623s	
16292/33250 (epoch 24.499), train_loss = 0.85300226, grad/param norm = 1.5796e-01, time/batch = 18.8609s	
16293/33250 (epoch 24.501), train_loss = 0.83449620, grad/param norm = 1.5387e-01, time/batch = 16.4390s	
16294/33250 (epoch 24.502), train_loss = 0.86707507, grad/param norm = 1.3757e-01, time/batch = 17.5259s	
16295/33250 (epoch 24.504), train_loss = 1.03782478, grad/param norm = 1.8342e-01, time/batch = 16.6869s	
16296/33250 (epoch 24.505), train_loss = 0.75324822, grad/param norm = 1.3487e-01, time/batch = 17.1856s	
16297/33250 (epoch 24.507), train_loss = 0.80686317, grad/param norm = 1.5520e-01, time/batch = 16.0154s	
16298/33250 (epoch 24.508), train_loss = 0.84926283, grad/param norm = 1.5442e-01, time/batch = 18.6051s	
16299/33250 (epoch 24.510), train_loss = 0.72845047, grad/param norm = 1.3117e-01, time/batch = 18.7014s	
16300/33250 (epoch 24.511), train_loss = 0.89687901, grad/param norm = 1.6496e-01, time/batch = 16.9391s	
16301/33250 (epoch 24.513), train_loss = 1.02620601, grad/param norm = 1.5953e-01, time/batch = 17.5363s	
16302/33250 (epoch 24.514), train_loss = 0.88510352, grad/param norm = 1.4667e-01, time/batch = 17.9234s	
16303/33250 (epoch 24.516), train_loss = 0.82384890, grad/param norm = 1.5583e-01, time/batch = 17.6678s	
16304/33250 (epoch 24.517), train_loss = 0.85041092, grad/param norm = 1.4872e-01, time/batch = 16.2426s	
16305/33250 (epoch 24.519), train_loss = 0.76479282, grad/param norm = 1.1547e-01, time/batch = 15.5148s	
16306/33250 (epoch 24.520), train_loss = 1.09747145, grad/param norm = 1.7343e-01, time/batch = 16.4635s	
16307/33250 (epoch 24.522), train_loss = 0.95889091, grad/param norm = 1.5709e-01, time/batch = 16.9300s	
16308/33250 (epoch 24.523), train_loss = 0.82209575, grad/param norm = 1.4036e-01, time/batch = 18.4255s	
16309/33250 (epoch 24.525), train_loss = 0.77224471, grad/param norm = 1.4481e-01, time/batch = 17.8512s	
16310/33250 (epoch 24.526), train_loss = 0.77343413, grad/param norm = 1.4315e-01, time/batch = 17.6980s	
16311/33250 (epoch 24.528), train_loss = 0.86340652, grad/param norm = 1.5815e-01, time/batch = 19.0993s	
16312/33250 (epoch 24.529), train_loss = 0.81665107, grad/param norm = 1.4760e-01, time/batch = 16.5976s	
16313/33250 (epoch 24.531), train_loss = 0.77132243, grad/param norm = 1.2944e-01, time/batch = 18.0158s	
16314/33250 (epoch 24.532), train_loss = 0.92940204, grad/param norm = 1.5018e-01, time/batch = 16.4400s	
16315/33250 (epoch 24.534), train_loss = 0.80058596, grad/param norm = 1.4736e-01, time/batch = 17.8415s	
16316/33250 (epoch 24.535), train_loss = 0.86761141, grad/param norm = 1.3734e-01, time/batch = 16.0199s	
16317/33250 (epoch 24.537), train_loss = 0.93124769, grad/param norm = 1.5510e-01, time/batch = 17.5830s	
16318/33250 (epoch 24.538), train_loss = 0.94536510, grad/param norm = 1.5920e-01, time/batch = 17.7791s	
16319/33250 (epoch 24.540), train_loss = 1.03816620, grad/param norm = 1.4258e-01, time/batch = 16.8716s	
16320/33250 (epoch 24.541), train_loss = 0.98266662, grad/param norm = 1.8397e-01, time/batch = 19.2907s	
16321/33250 (epoch 24.543), train_loss = 0.94381389, grad/param norm = 1.3546e-01, time/batch = 16.1124s	
16322/33250 (epoch 24.544), train_loss = 0.83139707, grad/param norm = 1.6337e-01, time/batch = 15.5048s	
16323/33250 (epoch 24.546), train_loss = 0.86138598, grad/param norm = 1.6052e-01, time/batch = 17.5906s	
16324/33250 (epoch 24.547), train_loss = 0.88379628, grad/param norm = 1.8323e-01, time/batch = 15.7439s	
16325/33250 (epoch 24.549), train_loss = 0.93967805, grad/param norm = 1.5324e-01, time/batch = 15.5401s	
16326/33250 (epoch 24.550), train_loss = 0.86484935, grad/param norm = 1.5811e-01, time/batch = 17.3367s	
16327/33250 (epoch 24.552), train_loss = 0.95546976, grad/param norm = 1.6597e-01, time/batch = 18.5796s	
16328/33250 (epoch 24.553), train_loss = 0.85214576, grad/param norm = 1.6097e-01, time/batch = 17.2882s	
16329/33250 (epoch 24.555), train_loss = 0.92733709, grad/param norm = 1.4764e-01, time/batch = 18.3590s	
16330/33250 (epoch 24.556), train_loss = 0.92585633, grad/param norm = 1.6439e-01, time/batch = 15.8738s	
16331/33250 (epoch 24.558), train_loss = 0.99211371, grad/param norm = 1.7088e-01, time/batch = 16.5920s	
16332/33250 (epoch 24.559), train_loss = 0.81546239, grad/param norm = 1.3925e-01, time/batch = 16.7772s	
16333/33250 (epoch 24.561), train_loss = 0.80143117, grad/param norm = 1.4217e-01, time/batch = 16.1067s	
16334/33250 (epoch 24.562), train_loss = 0.96091597, grad/param norm = 1.6712e-01, time/batch = 14.9526s	
16335/33250 (epoch 24.564), train_loss = 1.09464128, grad/param norm = 1.7771e-01, time/batch = 16.2515s	
16336/33250 (epoch 24.565), train_loss = 1.02997397, grad/param norm = 1.8525e-01, time/batch = 17.0199s	
16337/33250 (epoch 24.567), train_loss = 1.02281510, grad/param norm = 1.7809e-01, time/batch = 17.1230s	
16338/33250 (epoch 24.568), train_loss = 0.88442538, grad/param norm = 1.6535e-01, time/batch = 18.1032s	
16339/33250 (epoch 24.570), train_loss = 0.99321465, grad/param norm = 1.8084e-01, time/batch = 16.5897s	
16340/33250 (epoch 24.571), train_loss = 1.04679592, grad/param norm = 1.7151e-01, time/batch = 17.8445s	
16341/33250 (epoch 24.573), train_loss = 0.94277653, grad/param norm = 1.5506e-01, time/batch = 18.4995s	
16342/33250 (epoch 24.574), train_loss = 0.80935085, grad/param norm = 1.3675e-01, time/batch = 15.6903s	
16343/33250 (epoch 24.576), train_loss = 0.95623870, grad/param norm = 1.6367e-01, time/batch = 16.4360s	
16344/33250 (epoch 24.577), train_loss = 0.87569796, grad/param norm = 1.4426e-01, time/batch = 15.5913s	
16345/33250 (epoch 24.579), train_loss = 0.80992028, grad/param norm = 1.5514e-01, time/batch = 17.8274s	
16346/33250 (epoch 24.580), train_loss = 0.85834550, grad/param norm = 1.3083e-01, time/batch = 16.6887s	
16347/33250 (epoch 24.582), train_loss = 0.87440384, grad/param norm = 1.4703e-01, time/batch = 17.3641s	
16348/33250 (epoch 24.583), train_loss = 1.01954334, grad/param norm = 1.6476e-01, time/batch = 18.3793s	
16349/33250 (epoch 24.585), train_loss = 0.99700574, grad/param norm = 1.5555e-01, time/batch = 17.1085s	
16350/33250 (epoch 24.586), train_loss = 0.81662444, grad/param norm = 1.6608e-01, time/batch = 17.6227s	
16351/33250 (epoch 24.588), train_loss = 0.92852828, grad/param norm = 1.4947e-01, time/batch = 17.9270s	
16352/33250 (epoch 24.589), train_loss = 0.92289495, grad/param norm = 1.4330e-01, time/batch = 16.5884s	
16353/33250 (epoch 24.591), train_loss = 0.88631923, grad/param norm = 1.6460e-01, time/batch = 16.2690s	
16354/33250 (epoch 24.592), train_loss = 0.88211959, grad/param norm = 1.4992e-01, time/batch = 15.4250s	
16355/33250 (epoch 24.594), train_loss = 1.03093199, grad/param norm = 1.9163e-01, time/batch = 17.6811s	
16356/33250 (epoch 24.595), train_loss = 0.92810200, grad/param norm = 1.6417e-01, time/batch = 15.6055s	
16357/33250 (epoch 24.597), train_loss = 0.77216588, grad/param norm = 1.4331e-01, time/batch = 17.1016s	
16358/33250 (epoch 24.598), train_loss = 0.86047942, grad/param norm = 1.5416e-01, time/batch = 19.1216s	
16359/33250 (epoch 24.600), train_loss = 0.85791536, grad/param norm = 1.6654e-01, time/batch = 18.3624s	
16360/33250 (epoch 24.602), train_loss = 0.92010969, grad/param norm = 1.9572e-01, time/batch = 16.5983s	
16361/33250 (epoch 24.603), train_loss = 0.94034837, grad/param norm = 1.4677e-01, time/batch = 16.7723s	
16362/33250 (epoch 24.605), train_loss = 0.90784839, grad/param norm = 1.5670e-01, time/batch = 18.0179s	
16363/33250 (epoch 24.606), train_loss = 0.95829044, grad/param norm = 1.5657e-01, time/batch = 15.6025s	
16364/33250 (epoch 24.608), train_loss = 0.91432793, grad/param norm = 1.5414e-01, time/batch = 17.9203s	
16365/33250 (epoch 24.609), train_loss = 0.82537707, grad/param norm = 1.4446e-01, time/batch = 16.3526s	
16366/33250 (epoch 24.611), train_loss = 0.93913601, grad/param norm = 1.6795e-01, time/batch = 17.8337s	
16367/33250 (epoch 24.612), train_loss = 0.87743101, grad/param norm = 1.5795e-01, time/batch = 16.3667s	
16368/33250 (epoch 24.614), train_loss = 1.12865832, grad/param norm = 2.0346e-01, time/batch = 19.1951s	
16369/33250 (epoch 24.615), train_loss = 1.00124101, grad/param norm = 1.8137e-01, time/batch = 18.8679s	
16370/33250 (epoch 24.617), train_loss = 1.13639211, grad/param norm = 1.7003e-01, time/batch = 15.6803s	
16371/33250 (epoch 24.618), train_loss = 1.16218091, grad/param norm = 2.4179e-01, time/batch = 16.2795s	
16372/33250 (epoch 24.620), train_loss = 0.98593378, grad/param norm = 1.7423e-01, time/batch = 16.1137s	
16373/33250 (epoch 24.621), train_loss = 0.96235228, grad/param norm = 1.7929e-01, time/batch = 17.3466s	
16374/33250 (epoch 24.623), train_loss = 0.81520941, grad/param norm = 1.6180e-01, time/batch = 16.4983s	
16375/33250 (epoch 24.624), train_loss = 0.90119357, grad/param norm = 1.9094e-01, time/batch = 17.5862s	
16376/33250 (epoch 24.626), train_loss = 0.85615644, grad/param norm = 1.8266e-01, time/batch = 18.4336s	
16377/33250 (epoch 24.627), train_loss = 0.87125737, grad/param norm = 1.6122e-01, time/batch = 15.9874s	
16378/33250 (epoch 24.629), train_loss = 0.95813978, grad/param norm = 2.2407e-01, time/batch = 17.5174s	
16379/33250 (epoch 24.630), train_loss = 0.88406197, grad/param norm = 1.8764e-01, time/batch = 17.7890s	
16380/33250 (epoch 24.632), train_loss = 0.77039958, grad/param norm = 1.3938e-01, time/batch = 16.1831s	
16381/33250 (epoch 24.633), train_loss = 0.90289120, grad/param norm = 1.6372e-01, time/batch = 17.8438s	
16382/33250 (epoch 24.635), train_loss = 0.83381294, grad/param norm = 1.5694e-01, time/batch = 17.5119s	
16383/33250 (epoch 24.636), train_loss = 0.84641967, grad/param norm = 1.5623e-01, time/batch = 16.3595s	
16384/33250 (epoch 24.638), train_loss = 0.83435389, grad/param norm = 1.6084e-01, time/batch = 17.0145s	
16385/33250 (epoch 24.639), train_loss = 0.77444191, grad/param norm = 1.4800e-01, time/batch = 16.9888s	
16386/33250 (epoch 24.641), train_loss = 0.86652380, grad/param norm = 1.5792e-01, time/batch = 18.1232s	
16387/33250 (epoch 24.642), train_loss = 0.71809727, grad/param norm = 1.5493e-01, time/batch = 16.9523s	
16388/33250 (epoch 24.644), train_loss = 0.64474470, grad/param norm = 1.3315e-01, time/batch = 19.1843s	
16389/33250 (epoch 24.645), train_loss = 0.97792956, grad/param norm = 1.8743e-01, time/batch = 15.4373s	
16390/33250 (epoch 24.647), train_loss = 0.77039085, grad/param norm = 1.5648e-01, time/batch = 17.4300s	
16391/33250 (epoch 24.648), train_loss = 0.79920008, grad/param norm = 1.7320e-01, time/batch = 17.3265s	
16392/33250 (epoch 24.650), train_loss = 1.05020354, grad/param norm = 2.2312e-01, time/batch = 16.8210s	
16393/33250 (epoch 24.651), train_loss = 0.95054084, grad/param norm = 1.7953e-01, time/batch = 17.1766s	
16394/33250 (epoch 24.653), train_loss = 0.82008573, grad/param norm = 1.5807e-01, time/batch = 15.2883s	
16395/33250 (epoch 24.654), train_loss = 0.89939928, grad/param norm = 1.5578e-01, time/batch = 16.1042s	
16396/33250 (epoch 24.656), train_loss = 0.92676940, grad/param norm = 1.4960e-01, time/batch = 18.4569s	
16397/33250 (epoch 24.657), train_loss = 0.73129212, grad/param norm = 1.6705e-01, time/batch = 17.6102s	
16398/33250 (epoch 24.659), train_loss = 0.82282288, grad/param norm = 1.4558e-01, time/batch = 14.7166s	
16399/33250 (epoch 24.660), train_loss = 0.89501005, grad/param norm = 1.7054e-01, time/batch = 15.6224s	
16400/33250 (epoch 24.662), train_loss = 0.88026966, grad/param norm = 1.5178e-01, time/batch = 17.4220s	
16401/33250 (epoch 24.663), train_loss = 0.82424390, grad/param norm = 1.5379e-01, time/batch = 16.7717s	
16402/33250 (epoch 24.665), train_loss = 0.91630452, grad/param norm = 1.5586e-01, time/batch = 16.8508s	
16403/33250 (epoch 24.666), train_loss = 0.85724216, grad/param norm = 1.5061e-01, time/batch = 19.4076s	
16404/33250 (epoch 24.668), train_loss = 1.02993711, grad/param norm = 1.6578e-01, time/batch = 18.0070s	
16405/33250 (epoch 24.669), train_loss = 0.90740371, grad/param norm = 1.6356e-01, time/batch = 16.7478s	
16406/33250 (epoch 24.671), train_loss = 0.82486861, grad/param norm = 1.4892e-01, time/batch = 15.7852s	
16407/33250 (epoch 24.672), train_loss = 0.97310078, grad/param norm = 1.7097e-01, time/batch = 17.3051s	
16408/33250 (epoch 24.674), train_loss = 0.77478761, grad/param norm = 1.3886e-01, time/batch = 17.5338s	
16409/33250 (epoch 24.675), train_loss = 0.89030706, grad/param norm = 1.5238e-01, time/batch = 16.1042s	
16410/33250 (epoch 24.677), train_loss = 0.96994356, grad/param norm = 1.6992e-01, time/batch = 16.4381s	
16411/33250 (epoch 24.678), train_loss = 0.86683628, grad/param norm = 1.7053e-01, time/batch = 18.1742s	
16412/33250 (epoch 24.680), train_loss = 0.95786394, grad/param norm = 1.7207e-01, time/batch = 16.0087s	
16413/33250 (epoch 24.681), train_loss = 0.78872170, grad/param norm = 1.5011e-01, time/batch = 18.5919s	
16414/33250 (epoch 24.683), train_loss = 0.84483752, grad/param norm = 1.6100e-01, time/batch = 17.4319s	
16415/33250 (epoch 24.684), train_loss = 0.80972875, grad/param norm = 1.7852e-01, time/batch = 17.4992s	
16416/33250 (epoch 24.686), train_loss = 0.80999858, grad/param norm = 1.6526e-01, time/batch = 17.5264s	
16417/33250 (epoch 24.687), train_loss = 0.89841592, grad/param norm = 1.5914e-01, time/batch = 17.9406s	
16418/33250 (epoch 24.689), train_loss = 0.81854782, grad/param norm = 1.6829e-01, time/batch = 18.8603s	
16419/33250 (epoch 24.690), train_loss = 0.89673272, grad/param norm = 1.6255e-01, time/batch = 17.1790s	
16420/33250 (epoch 24.692), train_loss = 0.87409479, grad/param norm = 1.4547e-01, time/batch = 17.4279s	
16421/33250 (epoch 24.693), train_loss = 0.95755099, grad/param norm = 1.5686e-01, time/batch = 16.7661s	
16422/33250 (epoch 24.695), train_loss = 0.91571796, grad/param norm = 1.5010e-01, time/batch = 16.5032s	
16423/33250 (epoch 24.696), train_loss = 0.93468342, grad/param norm = 1.3940e-01, time/batch = 18.1717s	
16424/33250 (epoch 24.698), train_loss = 0.83483007, grad/param norm = 1.4746e-01, time/batch = 16.6585s	
16425/33250 (epoch 24.699), train_loss = 1.08380735, grad/param norm = 1.7115e-01, time/batch = 18.0959s	
16426/33250 (epoch 24.701), train_loss = 0.88865098, grad/param norm = 1.3518e-01, time/batch = 16.5296s	
16427/33250 (epoch 24.702), train_loss = 0.89465691, grad/param norm = 2.3116e-01, time/batch = 16.7574s	
16428/33250 (epoch 24.704), train_loss = 1.06972105, grad/param norm = 2.4077e-01, time/batch = 16.8576s	
16429/33250 (epoch 24.705), train_loss = 0.84511634, grad/param norm = 1.4633e-01, time/batch = 16.4437s	
16430/33250 (epoch 24.707), train_loss = 0.75390461, grad/param norm = 1.5482e-01, time/batch = 17.1869s	
16431/33250 (epoch 24.708), train_loss = 0.97866101, grad/param norm = 1.7766e-01, time/batch = 17.3546s	
16432/33250 (epoch 24.710), train_loss = 0.95677665, grad/param norm = 1.7815e-01, time/batch = 17.7665s	
16433/33250 (epoch 24.711), train_loss = 0.79889218, grad/param norm = 1.5659e-01, time/batch = 16.3608s	
16434/33250 (epoch 24.713), train_loss = 0.92177327, grad/param norm = 1.4731e-01, time/batch = 16.4490s	
16435/33250 (epoch 24.714), train_loss = 0.89013620, grad/param norm = 1.5466e-01, time/batch = 17.6935s	
16436/33250 (epoch 24.716), train_loss = 0.94275734, grad/param norm = 1.7280e-01, time/batch = 16.1905s	
16437/33250 (epoch 24.717), train_loss = 0.81605113, grad/param norm = 1.3600e-01, time/batch = 18.9329s	
16438/33250 (epoch 24.719), train_loss = 0.84927648, grad/param norm = 1.5145e-01, time/batch = 18.2775s	
16439/33250 (epoch 24.720), train_loss = 1.12340576, grad/param norm = 1.7544e-01, time/batch = 17.0052s	
16440/33250 (epoch 24.722), train_loss = 0.78813491, grad/param norm = 1.4154e-01, time/batch = 16.0256s	
16441/33250 (epoch 24.723), train_loss = 0.71034421, grad/param norm = 1.3031e-01, time/batch = 16.7534s	
16442/33250 (epoch 24.725), train_loss = 0.79016398, grad/param norm = 1.2553e-01, time/batch = 17.0119s	
16443/33250 (epoch 24.726), train_loss = 0.86580118, grad/param norm = 1.6243e-01, time/batch = 16.5129s	
16444/33250 (epoch 24.728), train_loss = 0.91884422, grad/param norm = 1.6146e-01, time/batch = 15.4975s	
16445/33250 (epoch 24.729), train_loss = 0.98079591, grad/param norm = 1.6484e-01, time/batch = 17.4421s	
16446/33250 (epoch 24.731), train_loss = 0.83135497, grad/param norm = 1.8132e-01, time/batch = 18.3676s	
16447/33250 (epoch 24.732), train_loss = 0.79581319, grad/param norm = 1.3939e-01, time/batch = 17.0326s	
16448/33250 (epoch 24.734), train_loss = 0.93151035, grad/param norm = 1.7524e-01, time/batch = 19.1957s	
16449/33250 (epoch 24.735), train_loss = 0.91020283, grad/param norm = 1.5633e-01, time/batch = 18.5082s	
16450/33250 (epoch 24.737), train_loss = 0.84887832, grad/param norm = 1.3511e-01, time/batch = 16.7740s	
16451/33250 (epoch 24.738), train_loss = 0.90236261, grad/param norm = 1.5403e-01, time/batch = 16.5096s	
16452/33250 (epoch 24.740), train_loss = 0.98209853, grad/param norm = 1.6462e-01, time/batch = 15.4273s	
16453/33250 (epoch 24.741), train_loss = 0.96151956, grad/param norm = 1.6272e-01, time/batch = 16.6131s	
16454/33250 (epoch 24.743), train_loss = 0.81864621, grad/param norm = 1.4008e-01, time/batch = 15.7729s	
16455/33250 (epoch 24.744), train_loss = 0.86581952, grad/param norm = 1.6866e-01, time/batch = 14.3947s	
16456/33250 (epoch 24.746), train_loss = 0.81094371, grad/param norm = 1.4200e-01, time/batch = 19.2884s	
16457/33250 (epoch 24.747), train_loss = 0.83830956, grad/param norm = 1.5367e-01, time/batch = 16.1943s	
16458/33250 (epoch 24.749), train_loss = 0.97406964, grad/param norm = 1.6983e-01, time/batch = 16.6088s	
16459/33250 (epoch 24.750), train_loss = 0.96451485, grad/param norm = 1.6809e-01, time/batch = 17.2051s	
16460/33250 (epoch 24.752), train_loss = 0.87280065, grad/param norm = 1.5037e-01, time/batch = 17.5186s	
16461/33250 (epoch 24.753), train_loss = 0.85221346, grad/param norm = 1.5590e-01, time/batch = 17.3204s	
16462/33250 (epoch 24.755), train_loss = 0.84648033, grad/param norm = 1.6500e-01, time/batch = 16.5183s	
16463/33250 (epoch 24.756), train_loss = 0.91480454, grad/param norm = 1.6029e-01, time/batch = 15.6126s	
16464/33250 (epoch 24.758), train_loss = 1.02886654, grad/param norm = 1.5875e-01, time/batch = 15.1005s	
16465/33250 (epoch 24.759), train_loss = 0.81065113, grad/param norm = 1.3712e-01, time/batch = 16.9429s	
16466/33250 (epoch 24.761), train_loss = 0.90338443, grad/param norm = 1.6938e-01, time/batch = 19.3679s	
16467/33250 (epoch 24.762), train_loss = 0.97423589, grad/param norm = 1.5998e-01, time/batch = 18.9443s	
16468/33250 (epoch 24.764), train_loss = 0.81016504, grad/param norm = 1.9352e-01, time/batch = 17.8607s	
16469/33250 (epoch 24.765), train_loss = 0.92886758, grad/param norm = 1.7025e-01, time/batch = 19.4264s	
16470/33250 (epoch 24.767), train_loss = 0.71496911, grad/param norm = 1.4777e-01, time/batch = 17.5969s	
16471/33250 (epoch 24.768), train_loss = 0.76376499, grad/param norm = 1.6216e-01, time/batch = 18.7297s	
16472/33250 (epoch 24.770), train_loss = 0.93108066, grad/param norm = 1.8674e-01, time/batch = 16.3333s	
16473/33250 (epoch 24.771), train_loss = 0.97358687, grad/param norm = 1.8214e-01, time/batch = 18.8357s	
16474/33250 (epoch 24.773), train_loss = 0.85234770, grad/param norm = 1.6479e-01, time/batch = 28.0882s	
16475/33250 (epoch 24.774), train_loss = 0.75554410, grad/param norm = 1.6401e-01, time/batch = 27.8989s	
16476/33250 (epoch 24.776), train_loss = 0.84355976, grad/param norm = 1.5666e-01, time/batch = 18.0176s	
16477/33250 (epoch 24.777), train_loss = 0.98144808, grad/param norm = 1.7673e-01, time/batch = 16.1171s	
16478/33250 (epoch 24.779), train_loss = 0.88534302, grad/param norm = 1.5824e-01, time/batch = 16.3505s	
16479/33250 (epoch 24.780), train_loss = 1.03114975, grad/param norm = 1.8381e-01, time/batch = 17.0870s	
16480/33250 (epoch 24.782), train_loss = 0.89931407, grad/param norm = 1.5813e-01, time/batch = 15.2361s	
16481/33250 (epoch 24.783), train_loss = 0.76688095, grad/param norm = 1.4817e-01, time/batch = 17.6698s	
16482/33250 (epoch 24.785), train_loss = 0.78792873, grad/param norm = 1.5192e-01, time/batch = 16.4458s	
16483/33250 (epoch 24.786), train_loss = 1.00495500, grad/param norm = 1.7814e-01, time/batch = 17.5182s	
16484/33250 (epoch 24.788), train_loss = 0.97144725, grad/param norm = 1.6128e-01, time/batch = 15.4299s	
16485/33250 (epoch 24.789), train_loss = 0.98864134, grad/param norm = 1.8082e-01, time/batch = 16.1259s	
16486/33250 (epoch 24.791), train_loss = 1.05704508, grad/param norm = 1.8554e-01, time/batch = 18.2096s	
16487/33250 (epoch 24.792), train_loss = 1.06802419, grad/param norm = 1.6371e-01, time/batch = 15.9331s	
16488/33250 (epoch 24.794), train_loss = 0.86716017, grad/param norm = 1.6580e-01, time/batch = 16.6123s	
16489/33250 (epoch 24.795), train_loss = 0.92616754, grad/param norm = 1.7200e-01, time/batch = 15.7579s	
16490/33250 (epoch 24.797), train_loss = 0.96232706, grad/param norm = 1.6656e-01, time/batch = 17.7598s	
16491/33250 (epoch 24.798), train_loss = 0.89915108, grad/param norm = 2.0460e-01, time/batch = 15.8342s	
16492/33250 (epoch 24.800), train_loss = 0.94096233, grad/param norm = 1.7535e-01, time/batch = 17.3439s	
16493/33250 (epoch 24.802), train_loss = 0.87122032, grad/param norm = 1.4539e-01, time/batch = 15.6782s	
16494/33250 (epoch 24.803), train_loss = 0.92962507, grad/param norm = 1.5343e-01, time/batch = 17.2623s	
16495/33250 (epoch 24.805), train_loss = 0.94650281, grad/param norm = 1.7515e-01, time/batch = 16.5176s	
16496/33250 (epoch 24.806), train_loss = 0.90750064, grad/param norm = 1.6060e-01, time/batch = 18.1072s	
16497/33250 (epoch 24.808), train_loss = 0.83867011, grad/param norm = 1.4711e-01, time/batch = 18.7854s	
16498/33250 (epoch 24.809), train_loss = 0.81345419, grad/param norm = 1.4628e-01, time/batch = 15.6800s	
16499/33250 (epoch 24.811), train_loss = 0.81964251, grad/param norm = 1.5023e-01, time/batch = 15.8552s	
16500/33250 (epoch 24.812), train_loss = 0.94489808, grad/param norm = 1.7772e-01, time/batch = 15.3401s	
16501/33250 (epoch 24.814), train_loss = 0.89165392, grad/param norm = 1.6600e-01, time/batch = 16.8463s	
16502/33250 (epoch 24.815), train_loss = 0.94515424, grad/param norm = 1.5347e-01, time/batch = 16.4458s	
16503/33250 (epoch 24.817), train_loss = 0.88054773, grad/param norm = 1.5895e-01, time/batch = 17.2572s	
16504/33250 (epoch 24.818), train_loss = 0.79691332, grad/param norm = 1.4720e-01, time/batch = 17.9749s	
16505/33250 (epoch 24.820), train_loss = 0.91923587, grad/param norm = 1.5886e-01, time/batch = 17.1249s	
16506/33250 (epoch 24.821), train_loss = 0.87765521, grad/param norm = 1.4820e-01, time/batch = 17.1929s	
16507/33250 (epoch 24.823), train_loss = 1.23354651, grad/param norm = 2.0411e-01, time/batch = 17.2908s	
16508/33250 (epoch 24.824), train_loss = 0.87119261, grad/param norm = 2.0823e-01, time/batch = 17.0881s	
16509/33250 (epoch 24.826), train_loss = 0.92423191, grad/param norm = 1.7092e-01, time/batch = 17.6775s	
16510/33250 (epoch 24.827), train_loss = 0.75886189, grad/param norm = 1.5685e-01, time/batch = 17.0148s	
16511/33250 (epoch 24.829), train_loss = 0.90019099, grad/param norm = 1.7636e-01, time/batch = 16.6869s	
16512/33250 (epoch 24.830), train_loss = 1.00455479, grad/param norm = 2.2491e-01, time/batch = 15.8661s	
16513/33250 (epoch 24.832), train_loss = 0.90455040, grad/param norm = 1.5599e-01, time/batch = 15.6085s	
16514/33250 (epoch 24.833), train_loss = 0.90216695, grad/param norm = 1.6550e-01, time/batch = 18.8714s	
16515/33250 (epoch 24.835), train_loss = 0.80803175, grad/param norm = 1.7086e-01, time/batch = 18.2009s	
16516/33250 (epoch 24.836), train_loss = 0.87057221, grad/param norm = 1.6924e-01, time/batch = 16.2676s	
16517/33250 (epoch 24.838), train_loss = 0.93098894, grad/param norm = 1.6234e-01, time/batch = 16.9622s	
16518/33250 (epoch 24.839), train_loss = 0.87111655, grad/param norm = 1.6720e-01, time/batch = 18.0163s	
16519/33250 (epoch 24.841), train_loss = 0.83404273, grad/param norm = 1.5400e-01, time/batch = 15.2573s	
16520/33250 (epoch 24.842), train_loss = 1.03719814, grad/param norm = 1.6430e-01, time/batch = 16.7563s	
16521/33250 (epoch 24.844), train_loss = 1.01044222, grad/param norm = 1.7735e-01, time/batch = 16.6921s	
16522/33250 (epoch 24.845), train_loss = 1.07416607, grad/param norm = 1.7965e-01, time/batch = 16.6699s	
16523/33250 (epoch 24.847), train_loss = 1.05454084, grad/param norm = 1.7847e-01, time/batch = 16.0878s	
16524/33250 (epoch 24.848), train_loss = 1.12589862, grad/param norm = 1.9876e-01, time/batch = 18.0984s	
16525/33250 (epoch 24.850), train_loss = 0.99530763, grad/param norm = 1.6227e-01, time/batch = 20.5202s	
16526/33250 (epoch 24.851), train_loss = 0.81452904, grad/param norm = 2.2183e-01, time/batch = 17.3318s	
16527/33250 (epoch 24.853), train_loss = 0.96745140, grad/param norm = 2.0000e-01, time/batch = 17.3490s	
16528/33250 (epoch 24.854), train_loss = 0.85887050, grad/param norm = 1.5245e-01, time/batch = 16.7713s	
16529/33250 (epoch 24.856), train_loss = 0.86283375, grad/param norm = 1.7577e-01, time/batch = 17.5879s	
16530/33250 (epoch 24.857), train_loss = 0.78197618, grad/param norm = 1.5070e-01, time/batch = 16.1151s	
16531/33250 (epoch 24.859), train_loss = 0.80579699, grad/param norm = 1.7408e-01, time/batch = 16.6015s	
16532/33250 (epoch 24.860), train_loss = 0.91406265, grad/param norm = 1.4857e-01, time/batch = 17.8324s	
16533/33250 (epoch 24.862), train_loss = 0.80020366, grad/param norm = 1.5042e-01, time/batch = 16.1044s	
16534/33250 (epoch 24.863), train_loss = 0.85760334, grad/param norm = 1.7620e-01, time/batch = 17.2909s	
16535/33250 (epoch 24.865), train_loss = 0.94011963, grad/param norm = 1.5406e-01, time/batch = 19.0436s	
16536/33250 (epoch 24.866), train_loss = 0.80502264, grad/param norm = 1.7392e-01, time/batch = 15.6178s	
16537/33250 (epoch 24.868), train_loss = 0.93397422, grad/param norm = 2.0234e-01, time/batch = 16.0990s	
16538/33250 (epoch 24.869), train_loss = 0.91219320, grad/param norm = 1.6983e-01, time/batch = 15.5267s	
16539/33250 (epoch 24.871), train_loss = 0.71800174, grad/param norm = 1.6705e-01, time/batch = 18.8412s	
16540/33250 (epoch 24.872), train_loss = 0.96349934, grad/param norm = 1.8693e-01, time/batch = 15.9327s	
16541/33250 (epoch 24.874), train_loss = 0.82574149, grad/param norm = 1.7439e-01, time/batch = 17.7469s	
16542/33250 (epoch 24.875), train_loss = 0.78389251, grad/param norm = 1.6497e-01, time/batch = 15.9481s	
16543/33250 (epoch 24.877), train_loss = 1.03537643, grad/param norm = 1.6843e-01, time/batch = 17.4234s	
16544/33250 (epoch 24.878), train_loss = 0.92781700, grad/param norm = 1.5554e-01, time/batch = 16.7738s	
16545/33250 (epoch 24.880), train_loss = 0.88586432, grad/param norm = 1.8944e-01, time/batch = 17.9490s	
16546/33250 (epoch 24.881), train_loss = 1.00782930, grad/param norm = 1.5906e-01, time/batch = 18.2992s	
16547/33250 (epoch 24.883), train_loss = 0.92947162, grad/param norm = 1.7531e-01, time/batch = 16.5004s	
16548/33250 (epoch 24.884), train_loss = 0.95724955, grad/param norm = 1.7065e-01, time/batch = 16.0096s	
16549/33250 (epoch 24.886), train_loss = 0.82567467, grad/param norm = 1.3658e-01, time/batch = 17.2599s	
16550/33250 (epoch 24.887), train_loss = 0.84648178, grad/param norm = 1.8316e-01, time/batch = 17.8209s	
16551/33250 (epoch 24.889), train_loss = 0.85853275, grad/param norm = 1.4466e-01, time/batch = 17.3327s	
16552/33250 (epoch 24.890), train_loss = 0.71833161, grad/param norm = 1.2914e-01, time/batch = 16.9990s	
16553/33250 (epoch 24.892), train_loss = 0.94197654, grad/param norm = 1.5812e-01, time/batch = 19.1016s	
16554/33250 (epoch 24.893), train_loss = 0.93826314, grad/param norm = 1.6934e-01, time/batch = 17.8648s	
16555/33250 (epoch 24.895), train_loss = 0.84233292, grad/param norm = 1.5588e-01, time/batch = 18.0479s	
16556/33250 (epoch 24.896), train_loss = 0.97979132, grad/param norm = 1.7932e-01, time/batch = 17.5384s	
16557/33250 (epoch 24.898), train_loss = 0.91374272, grad/param norm = 1.6282e-01, time/batch = 16.5102s	
16558/33250 (epoch 24.899), train_loss = 0.82845275, grad/param norm = 1.5136e-01, time/batch = 16.5892s	
16559/33250 (epoch 24.901), train_loss = 0.77900707, grad/param norm = 1.3990e-01, time/batch = 16.7705s	
16560/33250 (epoch 24.902), train_loss = 0.86402175, grad/param norm = 1.4845e-01, time/batch = 17.9323s	
16561/33250 (epoch 24.904), train_loss = 0.81632335, grad/param norm = 1.3806e-01, time/batch = 15.6767s	
16562/33250 (epoch 24.905), train_loss = 0.84324113, grad/param norm = 1.4085e-01, time/batch = 17.4304s	
16563/33250 (epoch 24.907), train_loss = 0.79391296, grad/param norm = 1.4920e-01, time/batch = 18.0597s	
16564/33250 (epoch 24.908), train_loss = 0.88245743, grad/param norm = 1.4151e-01, time/batch = 17.2079s	
16565/33250 (epoch 24.910), train_loss = 0.93851284, grad/param norm = 1.5406e-01, time/batch = 16.1978s	
16566/33250 (epoch 24.911), train_loss = 0.79285455, grad/param norm = 1.4674e-01, time/batch = 17.4485s	
16567/33250 (epoch 24.913), train_loss = 0.84310113, grad/param norm = 1.4078e-01, time/batch = 17.4327s	
16568/33250 (epoch 24.914), train_loss = 0.76011348, grad/param norm = 1.5929e-01, time/batch = 16.3470s	
16569/33250 (epoch 24.916), train_loss = 0.81404091, grad/param norm = 1.4282e-01, time/batch = 16.3627s	
16570/33250 (epoch 24.917), train_loss = 0.87691941, grad/param norm = 1.3854e-01, time/batch = 16.7574s	
16571/33250 (epoch 24.919), train_loss = 0.82221073, grad/param norm = 1.6423e-01, time/batch = 16.1775s	
16572/33250 (epoch 24.920), train_loss = 0.88114380, grad/param norm = 1.7072e-01, time/batch = 16.6556s	
16573/33250 (epoch 24.922), train_loss = 0.91514560, grad/param norm = 1.7414e-01, time/batch = 19.0213s	
16574/33250 (epoch 24.923), train_loss = 0.82630234, grad/param norm = 1.5778e-01, time/batch = 18.2683s	
16575/33250 (epoch 24.925), train_loss = 0.85122580, grad/param norm = 1.6189e-01, time/batch = 17.2826s	
16576/33250 (epoch 24.926), train_loss = 0.83753310, grad/param norm = 1.4310e-01, time/batch = 17.1928s	
16577/33250 (epoch 24.928), train_loss = 0.85164219, grad/param norm = 1.5981e-01, time/batch = 19.0029s	
16578/33250 (epoch 24.929), train_loss = 0.75700426, grad/param norm = 1.4038e-01, time/batch = 15.8380s	
16579/33250 (epoch 24.931), train_loss = 0.97406726, grad/param norm = 1.5907e-01, time/batch = 19.4077s	
16580/33250 (epoch 24.932), train_loss = 0.86161346, grad/param norm = 1.6195e-01, time/batch = 15.7829s	
16581/33250 (epoch 24.934), train_loss = 0.80347635, grad/param norm = 1.2938e-01, time/batch = 15.0994s	
16582/33250 (epoch 24.935), train_loss = 0.80860427, grad/param norm = 1.6025e-01, time/batch = 16.7869s	
16583/33250 (epoch 24.937), train_loss = 0.83724770, grad/param norm = 1.9213e-01, time/batch = 15.9617s	
16584/33250 (epoch 24.938), train_loss = 0.88373612, grad/param norm = 1.6478e-01, time/batch = 17.8787s	
16585/33250 (epoch 24.940), train_loss = 0.84563271, grad/param norm = 1.4782e-01, time/batch = 16.0721s	
16586/33250 (epoch 24.941), train_loss = 0.94071390, grad/param norm = 1.8171e-01, time/batch = 17.3355s	
16587/33250 (epoch 24.943), train_loss = 1.03291929, grad/param norm = 1.7975e-01, time/batch = 18.1624s	
16588/33250 (epoch 24.944), train_loss = 0.83829556, grad/param norm = 1.5110e-01, time/batch = 17.1685s	
16589/33250 (epoch 24.946), train_loss = 0.99702685, grad/param norm = 2.1537e-01, time/batch = 16.5756s	
16590/33250 (epoch 24.947), train_loss = 0.81820427, grad/param norm = 1.5727e-01, time/batch = 17.9233s	
16591/33250 (epoch 24.949), train_loss = 0.94320100, grad/param norm = 1.5462e-01, time/batch = 18.5077s	
16592/33250 (epoch 24.950), train_loss = 0.94189547, grad/param norm = 1.5056e-01, time/batch = 16.0383s	
16593/33250 (epoch 24.952), train_loss = 0.87772389, grad/param norm = 1.8474e-01, time/batch = 15.9665s	
16594/33250 (epoch 24.953), train_loss = 0.94225299, grad/param norm = 1.5827e-01, time/batch = 19.6134s	
16595/33250 (epoch 24.955), train_loss = 0.97890378, grad/param norm = 1.6090e-01, time/batch = 17.9194s	
16596/33250 (epoch 24.956), train_loss = 0.91048630, grad/param norm = 1.9100e-01, time/batch = 16.5896s	
16597/33250 (epoch 24.958), train_loss = 0.83390189, grad/param norm = 1.4087e-01, time/batch = 17.4292s	
16598/33250 (epoch 24.959), train_loss = 0.82431068, grad/param norm = 1.4652e-01, time/batch = 18.4131s	
16599/33250 (epoch 24.961), train_loss = 1.09197265, grad/param norm = 1.8194e-01, time/batch = 16.0136s	
16600/33250 (epoch 24.962), train_loss = 0.87080408, grad/param norm = 1.7991e-01, time/batch = 17.0690s	
16601/33250 (epoch 24.964), train_loss = 1.06722262, grad/param norm = 1.8419e-01, time/batch = 17.9305s	
16602/33250 (epoch 24.965), train_loss = 0.96019141, grad/param norm = 2.0542e-01, time/batch = 17.7857s	
16603/33250 (epoch 24.967), train_loss = 0.91694622, grad/param norm = 1.5405e-01, time/batch = 16.1077s	
16604/33250 (epoch 24.968), train_loss = 1.03897490, grad/param norm = 1.5489e-01, time/batch = 18.3591s	
16605/33250 (epoch 24.970), train_loss = 1.16018143, grad/param norm = 2.3611e-01, time/batch = 19.2470s	
16606/33250 (epoch 24.971), train_loss = 1.02871634, grad/param norm = 1.7966e-01, time/batch = 17.2704s	
16607/33250 (epoch 24.973), train_loss = 0.87361620, grad/param norm = 1.5558e-01, time/batch = 18.2525s	
16608/33250 (epoch 24.974), train_loss = 0.97801308, grad/param norm = 1.6431e-01, time/batch = 16.8494s	
16609/33250 (epoch 24.976), train_loss = 0.86464559, grad/param norm = 1.6182e-01, time/batch = 16.1013s	
16610/33250 (epoch 24.977), train_loss = 0.85599151, grad/param norm = 1.5797e-01, time/batch = 15.5851s	
16611/33250 (epoch 24.979), train_loss = 0.93145152, grad/param norm = 1.7261e-01, time/batch = 16.9354s	
16612/33250 (epoch 24.980), train_loss = 0.93335168, grad/param norm = 1.6128e-01, time/batch = 16.6177s	
16613/33250 (epoch 24.982), train_loss = 0.81357836, grad/param norm = 1.3848e-01, time/batch = 6.4422s	
16614/33250 (epoch 24.983), train_loss = 0.93446360, grad/param norm = 1.7988e-01, time/batch = 0.6608s	
16615/33250 (epoch 24.985), train_loss = 0.85343802, grad/param norm = 1.5843e-01, time/batch = 0.6611s	
16616/33250 (epoch 24.986), train_loss = 0.95516948, grad/param norm = 1.5108e-01, time/batch = 0.6642s	
16617/33250 (epoch 24.988), train_loss = 0.98192866, grad/param norm = 1.6438e-01, time/batch = 0.6927s	
16618/33250 (epoch 24.989), train_loss = 0.98393094, grad/param norm = 1.8759e-01, time/batch = 0.6804s	
16619/33250 (epoch 24.991), train_loss = 0.93622922, grad/param norm = 1.6633e-01, time/batch = 0.6813s	
16620/33250 (epoch 24.992), train_loss = 0.85781343, grad/param norm = 1.5848e-01, time/batch = 0.7676s	
16621/33250 (epoch 24.994), train_loss = 0.87856313, grad/param norm = 1.5239e-01, time/batch = 0.9945s	
16622/33250 (epoch 24.995), train_loss = 0.85971194, grad/param norm = 1.7824e-01, time/batch = 0.9737s	
16623/33250 (epoch 24.997), train_loss = 0.64184920, grad/param norm = 1.3618e-01, time/batch = 0.9689s	
16624/33250 (epoch 24.998), train_loss = 0.92376184, grad/param norm = 1.5178e-01, time/batch = 0.9665s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
16625/33250 (epoch 25.000), train_loss = 0.90659260, grad/param norm = 1.5497e-01, time/batch = 1.1101s	
16626/33250 (epoch 25.002), train_loss = 1.07792390, grad/param norm = 1.6187e-01, time/batch = 1.8004s	
16627/33250 (epoch 25.003), train_loss = 0.97482949, grad/param norm = 1.7127e-01, time/batch = 1.8056s	
16628/33250 (epoch 25.005), train_loss = 0.73164726, grad/param norm = 1.3820e-01, time/batch = 8.9589s	
16629/33250 (epoch 25.006), train_loss = 0.77241521, grad/param norm = 1.4664e-01, time/batch = 16.0974s	
16630/33250 (epoch 25.008), train_loss = 1.02114153, grad/param norm = 1.5958e-01, time/batch = 18.5836s	
16631/33250 (epoch 25.009), train_loss = 1.03731008, grad/param norm = 1.6653e-01, time/batch = 15.4187s	
16632/33250 (epoch 25.011), train_loss = 0.82712123, grad/param norm = 1.5352e-01, time/batch = 16.6668s	
16633/33250 (epoch 25.012), train_loss = 0.90612117, grad/param norm = 1.8419e-01, time/batch = 16.6022s	
16634/33250 (epoch 25.014), train_loss = 1.00183119, grad/param norm = 1.6680e-01, time/batch = 16.4196s	
16635/33250 (epoch 25.015), train_loss = 0.90461522, grad/param norm = 1.5564e-01, time/batch = 18.6908s	
16636/33250 (epoch 25.017), train_loss = 0.92294132, grad/param norm = 1.9111e-01, time/batch = 18.2956s	
16637/33250 (epoch 25.018), train_loss = 0.73266438, grad/param norm = 1.4501e-01, time/batch = 17.2862s	
16638/33250 (epoch 25.020), train_loss = 0.89940143, grad/param norm = 1.4424e-01, time/batch = 16.3576s	
16639/33250 (epoch 25.021), train_loss = 0.94607855, grad/param norm = 1.6376e-01, time/batch = 18.0924s	
16640/33250 (epoch 25.023), train_loss = 0.76258718, grad/param norm = 1.7230e-01, time/batch = 16.4449s	
16641/33250 (epoch 25.024), train_loss = 0.99668725, grad/param norm = 2.0223e-01, time/batch = 16.2664s	
16642/33250 (epoch 25.026), train_loss = 0.91825943, grad/param norm = 1.6332e-01, time/batch = 18.0130s	
16643/33250 (epoch 25.027), train_loss = 0.91344439, grad/param norm = 1.5082e-01, time/batch = 17.8514s	
16644/33250 (epoch 25.029), train_loss = 0.89421691, grad/param norm = 1.5004e-01, time/batch = 17.0013s	
16645/33250 (epoch 25.030), train_loss = 0.89015852, grad/param norm = 1.7454e-01, time/batch = 17.4521s	
16646/33250 (epoch 25.032), train_loss = 1.10256128, grad/param norm = 1.9830e-01, time/batch = 17.0418s	
16647/33250 (epoch 25.033), train_loss = 0.86373447, grad/param norm = 1.6701e-01, time/batch = 15.7718s	
16648/33250 (epoch 25.035), train_loss = 0.89885235, grad/param norm = 2.0024e-01, time/batch = 16.1025s	
16649/33250 (epoch 25.036), train_loss = 0.96221597, grad/param norm = 1.7521e-01, time/batch = 15.8495s	
16650/33250 (epoch 25.038), train_loss = 0.89154074, grad/param norm = 1.3314e-01, time/batch = 18.0980s	
16651/33250 (epoch 25.039), train_loss = 0.82287819, grad/param norm = 1.5515e-01, time/batch = 16.3662s	
16652/33250 (epoch 25.041), train_loss = 0.90896859, grad/param norm = 2.0068e-01, time/batch = 16.1907s	
16653/33250 (epoch 25.042), train_loss = 0.74500194, grad/param norm = 1.3898e-01, time/batch = 16.6934s	
16654/33250 (epoch 25.044), train_loss = 1.02396131, grad/param norm = 1.8483e-01, time/batch = 17.0064s	
16655/33250 (epoch 25.045), train_loss = 0.99151261, grad/param norm = 1.5116e-01, time/batch = 15.3687s	
16656/33250 (epoch 25.047), train_loss = 0.88330399, grad/param norm = 1.6043e-01, time/batch = 19.7842s	
16657/33250 (epoch 25.048), train_loss = 1.01591311, grad/param norm = 1.8814e-01, time/batch = 16.8861s	
16658/33250 (epoch 25.050), train_loss = 0.90362262, grad/param norm = 1.4784e-01, time/batch = 15.7982s	
16659/33250 (epoch 25.051), train_loss = 0.88826718, grad/param norm = 1.4626e-01, time/batch = 15.2655s	
16660/33250 (epoch 25.053), train_loss = 0.89771820, grad/param norm = 1.7899e-01, time/batch = 16.1880s	
16661/33250 (epoch 25.054), train_loss = 0.78352892, grad/param norm = 1.3876e-01, time/batch = 17.6770s	
16662/33250 (epoch 25.056), train_loss = 0.81545445, grad/param norm = 1.5480e-01, time/batch = 16.1825s	
16663/33250 (epoch 25.057), train_loss = 0.99126287, grad/param norm = 1.5427e-01, time/batch = 16.9426s	
16664/33250 (epoch 25.059), train_loss = 0.87948719, grad/param norm = 1.5677e-01, time/batch = 16.5238s	
16665/33250 (epoch 25.060), train_loss = 0.92283732, grad/param norm = 1.7377e-01, time/batch = 18.1181s	
16666/33250 (epoch 25.062), train_loss = 0.99813733, grad/param norm = 1.7274e-01, time/batch = 16.7045s	
16667/33250 (epoch 25.063), train_loss = 1.04543174, grad/param norm = 1.5361e-01, time/batch = 15.9413s	
16668/33250 (epoch 25.065), train_loss = 0.91044667, grad/param norm = 1.5882e-01, time/batch = 19.0237s	
16669/33250 (epoch 25.066), train_loss = 0.94068986, grad/param norm = 1.6733e-01, time/batch = 15.5061s	
16670/33250 (epoch 25.068), train_loss = 0.85313705, grad/param norm = 1.6331e-01, time/batch = 15.8640s	
16671/33250 (epoch 25.069), train_loss = 0.91091411, grad/param norm = 1.5416e-01, time/batch = 17.1895s	
16672/33250 (epoch 25.071), train_loss = 0.83710636, grad/param norm = 1.5420e-01, time/batch = 17.5122s	
16673/33250 (epoch 25.072), train_loss = 0.82214893, grad/param norm = 1.4555e-01, time/batch = 15.1934s	
16674/33250 (epoch 25.074), train_loss = 0.95633165, grad/param norm = 1.5527e-01, time/batch = 16.0241s	
16675/33250 (epoch 25.075), train_loss = 0.84852925, grad/param norm = 1.7097e-01, time/batch = 16.6702s	
16676/33250 (epoch 25.077), train_loss = 0.90448753, grad/param norm = 1.7711e-01, time/batch = 18.6146s	
16677/33250 (epoch 25.078), train_loss = 0.93582909, grad/param norm = 1.6649e-01, time/batch = 17.8040s	
16678/33250 (epoch 25.080), train_loss = 0.93355466, grad/param norm = 2.0159e-01, time/batch = 17.0390s	
16679/33250 (epoch 25.081), train_loss = 0.93834558, grad/param norm = 1.6029e-01, time/batch = 17.6953s	
16680/33250 (epoch 25.083), train_loss = 1.00439743, grad/param norm = 1.5758e-01, time/batch = 15.4830s	
16681/33250 (epoch 25.084), train_loss = 0.90442440, grad/param norm = 1.9657e-01, time/batch = 15.7603s	
16682/33250 (epoch 25.086), train_loss = 0.90142971, grad/param norm = 1.5096e-01, time/batch = 14.9524s	
16683/33250 (epoch 25.087), train_loss = 0.78971310, grad/param norm = 1.4862e-01, time/batch = 17.9382s	
16684/33250 (epoch 25.089), train_loss = 0.94062567, grad/param norm = 1.6589e-01, time/batch = 15.6721s	
16685/33250 (epoch 25.090), train_loss = 0.93260758, grad/param norm = 1.7043e-01, time/batch = 17.7588s	
16686/33250 (epoch 25.092), train_loss = 0.85932500, grad/param norm = 1.4167e-01, time/batch = 19.6147s	
16687/33250 (epoch 25.093), train_loss = 0.89328550, grad/param norm = 1.4469e-01, time/batch = 17.1929s	
16688/33250 (epoch 25.095), train_loss = 0.88118657, grad/param norm = 1.6593e-01, time/batch = 17.1814s	
16689/33250 (epoch 25.096), train_loss = 0.75250539, grad/param norm = 1.5697e-01, time/batch = 17.7662s	
16690/33250 (epoch 25.098), train_loss = 0.78431102, grad/param norm = 1.6982e-01, time/batch = 18.1673s	
16691/33250 (epoch 25.099), train_loss = 0.69304942, grad/param norm = 1.4488e-01, time/batch = 16.9302s	
16692/33250 (epoch 25.101), train_loss = 0.89289065, grad/param norm = 1.6302e-01, time/batch = 18.2548s	
16693/33250 (epoch 25.102), train_loss = 0.80996592, grad/param norm = 1.4353e-01, time/batch = 16.3535s	
16694/33250 (epoch 25.104), train_loss = 0.68582100, grad/param norm = 1.2864e-01, time/batch = 15.3496s	
16695/33250 (epoch 25.105), train_loss = 0.83549927, grad/param norm = 1.5136e-01, time/batch = 18.4601s	
16696/33250 (epoch 25.107), train_loss = 0.76619896, grad/param norm = 1.3907e-01, time/batch = 18.2868s	
16697/33250 (epoch 25.108), train_loss = 0.89556335, grad/param norm = 1.5479e-01, time/batch = 21.4838s	
16698/33250 (epoch 25.110), train_loss = 0.74389255, grad/param norm = 1.4441e-01, time/batch = 26.7999s	
16699/33250 (epoch 25.111), train_loss = 0.86276496, grad/param norm = 1.4905e-01, time/batch = 16.5153s	
16700/33250 (epoch 25.113), train_loss = 0.83242675, grad/param norm = 1.6190e-01, time/batch = 16.9256s	
16701/33250 (epoch 25.114), train_loss = 0.79358850, grad/param norm = 1.6944e-01, time/batch = 15.3289s	
16702/33250 (epoch 25.116), train_loss = 0.86553198, grad/param norm = 1.6750e-01, time/batch = 17.1799s	
16703/33250 (epoch 25.117), train_loss = 0.83281507, grad/param norm = 1.5349e-01, time/batch = 18.5097s	
16704/33250 (epoch 25.119), train_loss = 0.85197923, grad/param norm = 1.4691e-01, time/batch = 15.7101s	
16705/33250 (epoch 25.120), train_loss = 0.68524350, grad/param norm = 1.3146e-01, time/batch = 17.9433s	
16706/33250 (epoch 25.122), train_loss = 0.96849092, grad/param norm = 1.5851e-01, time/batch = 15.0556s	
16707/33250 (epoch 25.123), train_loss = 0.86197453, grad/param norm = 1.6716e-01, time/batch = 16.6058s	
16708/33250 (epoch 25.125), train_loss = 0.72480048, grad/param norm = 1.4189e-01, time/batch = 16.9248s	
16709/33250 (epoch 25.126), train_loss = 0.87068284, grad/param norm = 1.5962e-01, time/batch = 17.6743s	
16710/33250 (epoch 25.128), train_loss = 0.82502020, grad/param norm = 1.4677e-01, time/batch = 17.9965s	
16711/33250 (epoch 25.129), train_loss = 0.88190447, grad/param norm = 1.4745e-01, time/batch = 15.8172s	
16712/33250 (epoch 25.131), train_loss = 0.85283834, grad/param norm = 1.5362e-01, time/batch = 15.4182s	
16713/33250 (epoch 25.132), train_loss = 0.85908547, grad/param norm = 1.6952e-01, time/batch = 17.0103s	
16714/33250 (epoch 25.134), train_loss = 0.85469752, grad/param norm = 1.6749e-01, time/batch = 15.4421s	
16715/33250 (epoch 25.135), train_loss = 0.86686654, grad/param norm = 1.4486e-01, time/batch = 16.7854s	
16716/33250 (epoch 25.137), train_loss = 0.79180473, grad/param norm = 1.7059e-01, time/batch = 16.7828s	
16717/33250 (epoch 25.138), train_loss = 0.80910991, grad/param norm = 1.3925e-01, time/batch = 15.7808s	
16718/33250 (epoch 25.140), train_loss = 0.69401420, grad/param norm = 1.4341e-01, time/batch = 14.9597s	
16719/33250 (epoch 25.141), train_loss = 0.99616986, grad/param norm = 1.9985e-01, time/batch = 15.5025s	
16720/33250 (epoch 25.143), train_loss = 0.70492424, grad/param norm = 1.5241e-01, time/batch = 17.2648s	
16721/33250 (epoch 25.144), train_loss = 0.84547664, grad/param norm = 1.6409e-01, time/batch = 17.0092s	
16722/33250 (epoch 25.146), train_loss = 0.83257727, grad/param norm = 1.4446e-01, time/batch = 15.5168s	
16723/33250 (epoch 25.147), train_loss = 0.84205182, grad/param norm = 1.5042e-01, time/batch = 15.3267s	
16724/33250 (epoch 25.149), train_loss = 0.80035874, grad/param norm = 1.4439e-01, time/batch = 18.0318s	
16725/33250 (epoch 25.150), train_loss = 0.76525215, grad/param norm = 1.5012e-01, time/batch = 16.3524s	
16726/33250 (epoch 25.152), train_loss = 0.74217501, grad/param norm = 1.5039e-01, time/batch = 18.0507s	
16727/33250 (epoch 25.153), train_loss = 1.02210564, grad/param norm = 1.8271e-01, time/batch = 18.5327s	
16728/33250 (epoch 25.155), train_loss = 0.85826109, grad/param norm = 1.9823e-01, time/batch = 16.2853s	
16729/33250 (epoch 25.156), train_loss = 1.05745945, grad/param norm = 1.5938e-01, time/batch = 15.9280s	
16730/33250 (epoch 25.158), train_loss = 1.03152960, grad/param norm = 1.6280e-01, time/batch = 18.0895s	
16731/33250 (epoch 25.159), train_loss = 0.84631136, grad/param norm = 1.4943e-01, time/batch = 19.8301s	
16732/33250 (epoch 25.161), train_loss = 0.92225583, grad/param norm = 1.6765e-01, time/batch = 16.7557s	
16733/33250 (epoch 25.162), train_loss = 0.78680910, grad/param norm = 1.4610e-01, time/batch = 17.7620s	
16734/33250 (epoch 25.164), train_loss = 0.85136086, grad/param norm = 1.8050e-01, time/batch = 16.9413s	
16735/33250 (epoch 25.165), train_loss = 0.93906402, grad/param norm = 1.7278e-01, time/batch = 18.6968s	
16736/33250 (epoch 25.167), train_loss = 1.03535999, grad/param norm = 1.8662e-01, time/batch = 16.2107s	
16737/33250 (epoch 25.168), train_loss = 0.72796102, grad/param norm = 1.2415e-01, time/batch = 17.6922s	
16738/33250 (epoch 25.170), train_loss = 0.83548563, grad/param norm = 1.5912e-01, time/batch = 18.1005s	
16739/33250 (epoch 25.171), train_loss = 0.84691030, grad/param norm = 1.4706e-01, time/batch = 15.5895s	
16740/33250 (epoch 25.173), train_loss = 0.82022480, grad/param norm = 1.4499e-01, time/batch = 17.9992s	
16741/33250 (epoch 25.174), train_loss = 0.88605165, grad/param norm = 2.1535e-01, time/batch = 16.7842s	
16742/33250 (epoch 25.176), train_loss = 0.82555776, grad/param norm = 1.5799e-01, time/batch = 18.3397s	
16743/33250 (epoch 25.177), train_loss = 0.83308089, grad/param norm = 1.5483e-01, time/batch = 16.3577s	
16744/33250 (epoch 25.179), train_loss = 0.78927940, grad/param norm = 1.5296e-01, time/batch = 16.5148s	
16745/33250 (epoch 25.180), train_loss = 0.71739032, grad/param norm = 1.3722e-01, time/batch = 19.3554s	
16746/33250 (epoch 25.182), train_loss = 0.81440430, grad/param norm = 1.8689e-01, time/batch = 16.7023s	
16747/33250 (epoch 25.183), train_loss = 0.99305618, grad/param norm = 1.7470e-01, time/batch = 18.1120s	
16748/33250 (epoch 25.185), train_loss = 0.92881235, grad/param norm = 1.7981e-01, time/batch = 17.6820s	
16749/33250 (epoch 25.186), train_loss = 0.90382432, grad/param norm = 1.5625e-01, time/batch = 17.1558s	
16750/33250 (epoch 25.188), train_loss = 0.98365892, grad/param norm = 1.6589e-01, time/batch = 17.5139s	
16751/33250 (epoch 25.189), train_loss = 0.70701525, grad/param norm = 1.5120e-01, time/batch = 16.4211s	
16752/33250 (epoch 25.191), train_loss = 0.80444982, grad/param norm = 1.6222e-01, time/batch = 17.2485s	
16753/33250 (epoch 25.192), train_loss = 0.82818366, grad/param norm = 1.5050e-01, time/batch = 17.2438s	
16754/33250 (epoch 25.194), train_loss = 0.84978665, grad/param norm = 1.5928e-01, time/batch = 17.4324s	
16755/33250 (epoch 25.195), train_loss = 1.04466628, grad/param norm = 1.6066e-01, time/batch = 17.2723s	
16756/33250 (epoch 25.197), train_loss = 0.81662732, grad/param norm = 1.4640e-01, time/batch = 17.6684s	
16757/33250 (epoch 25.198), train_loss = 0.98129952, grad/param norm = 1.5623e-01, time/batch = 16.8712s	
16758/33250 (epoch 25.200), train_loss = 0.88415200, grad/param norm = 1.5810e-01, time/batch = 18.0982s	
16759/33250 (epoch 25.202), train_loss = 0.81960569, grad/param norm = 1.4211e-01, time/batch = 18.5001s	
16760/33250 (epoch 25.203), train_loss = 0.80522087, grad/param norm = 1.6564e-01, time/batch = 16.2675s	
16761/33250 (epoch 25.205), train_loss = 0.90856847, grad/param norm = 1.6069e-01, time/batch = 17.2638s	
16762/33250 (epoch 25.206), train_loss = 0.94299593, grad/param norm = 1.6755e-01, time/batch = 16.4385s	
16763/33250 (epoch 25.208), train_loss = 0.99040707, grad/param norm = 1.8136e-01, time/batch = 16.6663s	
16764/33250 (epoch 25.209), train_loss = 0.80656346, grad/param norm = 1.4534e-01, time/batch = 16.7600s	
16765/33250 (epoch 25.211), train_loss = 0.93060410, grad/param norm = 1.7511e-01, time/batch = 16.7752s	
16766/33250 (epoch 25.212), train_loss = 1.06839752, grad/param norm = 1.7458e-01, time/batch = 18.1969s	
16767/33250 (epoch 25.214), train_loss = 0.88632935, grad/param norm = 1.5040e-01, time/batch = 17.1513s	
16768/33250 (epoch 25.215), train_loss = 0.99630447, grad/param norm = 1.8687e-01, time/batch = 17.8395s	
16769/33250 (epoch 25.217), train_loss = 0.99882270, grad/param norm = 2.0523e-01, time/batch = 17.8359s	
16770/33250 (epoch 25.218), train_loss = 0.96771232, grad/param norm = 1.5124e-01, time/batch = 16.2781s	
16771/33250 (epoch 25.220), train_loss = 0.91182849, grad/param norm = 1.8106e-01, time/batch = 16.4081s	
16772/33250 (epoch 25.221), train_loss = 1.07122470, grad/param norm = 1.9616e-01, time/batch = 16.4876s	
16773/33250 (epoch 25.223), train_loss = 0.87107092, grad/param norm = 1.3545e-01, time/batch = 17.4186s	
16774/33250 (epoch 25.224), train_loss = 0.92195565, grad/param norm = 1.7027e-01, time/batch = 18.1995s	
16775/33250 (epoch 25.226), train_loss = 1.00519876, grad/param norm = 1.6680e-01, time/batch = 17.7840s	
16776/33250 (epoch 25.227), train_loss = 0.93364128, grad/param norm = 1.6757e-01, time/batch = 19.9392s	
16777/33250 (epoch 25.229), train_loss = 0.90411355, grad/param norm = 1.5258e-01, time/batch = 15.4258s	
16778/33250 (epoch 25.230), train_loss = 0.89710937, grad/param norm = 1.5922e-01, time/batch = 17.1053s	
16779/33250 (epoch 25.232), train_loss = 0.84844935, grad/param norm = 1.4460e-01, time/batch = 16.9475s	
16780/33250 (epoch 25.233), train_loss = 0.81856084, grad/param norm = 1.5499e-01, time/batch = 17.5172s	
16781/33250 (epoch 25.235), train_loss = 1.03215422, grad/param norm = 1.5460e-01, time/batch = 15.8498s	
16782/33250 (epoch 25.236), train_loss = 0.83307353, grad/param norm = 1.8301e-01, time/batch = 17.0147s	
16783/33250 (epoch 25.238), train_loss = 1.00330415, grad/param norm = 1.6742e-01, time/batch = 17.6949s	
16784/33250 (epoch 25.239), train_loss = 1.02431824, grad/param norm = 1.9383e-01, time/batch = 16.3547s	
16785/33250 (epoch 25.241), train_loss = 1.00190212, grad/param norm = 1.9984e-01, time/batch = 18.2034s	
16786/33250 (epoch 25.242), train_loss = 0.97504399, grad/param norm = 1.6577e-01, time/batch = 17.6272s	
16787/33250 (epoch 25.244), train_loss = 0.95374444, grad/param norm = 1.9476e-01, time/batch = 16.9426s	
16788/33250 (epoch 25.245), train_loss = 0.92961277, grad/param norm = 1.5775e-01, time/batch = 15.9202s	
16789/33250 (epoch 25.247), train_loss = 0.89400980, grad/param norm = 1.4787e-01, time/batch = 16.0283s	
16790/33250 (epoch 25.248), train_loss = 1.06905310, grad/param norm = 1.7977e-01, time/batch = 17.2790s	
16791/33250 (epoch 25.250), train_loss = 0.99970218, grad/param norm = 1.5116e-01, time/batch = 16.2347s	
16792/33250 (epoch 25.251), train_loss = 0.86320056, grad/param norm = 1.5063e-01, time/batch = 18.7385s	
16793/33250 (epoch 25.253), train_loss = 0.84431704, grad/param norm = 1.3526e-01, time/batch = 18.7896s	
16794/33250 (epoch 25.254), train_loss = 0.83734441, grad/param norm = 1.6533e-01, time/batch = 18.2026s	
16795/33250 (epoch 25.256), train_loss = 0.91599051, grad/param norm = 1.5282e-01, time/batch = 15.6713s	
16796/33250 (epoch 25.257), train_loss = 1.00625727, grad/param norm = 1.6487e-01, time/batch = 15.0446s	
16797/33250 (epoch 25.259), train_loss = 0.93339804, grad/param norm = 1.5016e-01, time/batch = 15.5969s	
16798/33250 (epoch 25.260), train_loss = 0.75885519, grad/param norm = 1.5303e-01, time/batch = 15.3334s	
16799/33250 (epoch 25.262), train_loss = 0.92148189, grad/param norm = 1.4983e-01, time/batch = 15.4262s	
16800/33250 (epoch 25.263), train_loss = 0.78592638, grad/param norm = 1.6277e-01, time/batch = 14.8408s	
16801/33250 (epoch 25.265), train_loss = 0.96238206, grad/param norm = 1.6085e-01, time/batch = 15.5077s	
16802/33250 (epoch 25.266), train_loss = 0.86740792, grad/param norm = 1.7361e-01, time/batch = 16.3268s	
16803/33250 (epoch 25.268), train_loss = 0.80622502, grad/param norm = 1.5873e-01, time/batch = 20.1530s	
16804/33250 (epoch 25.269), train_loss = 0.72796060, grad/param norm = 1.4435e-01, time/batch = 16.4329s	
16805/33250 (epoch 25.271), train_loss = 0.89108594, grad/param norm = 1.4622e-01, time/batch = 18.5276s	
16806/33250 (epoch 25.272), train_loss = 0.80501258, grad/param norm = 1.3472e-01, time/batch = 15.8469s	
16807/33250 (epoch 25.274), train_loss = 0.67558967, grad/param norm = 1.2853e-01, time/batch = 16.4372s	
16808/33250 (epoch 25.275), train_loss = 0.80213204, grad/param norm = 1.2351e-01, time/batch = 17.4307s	
16809/33250 (epoch 25.277), train_loss = 0.70627463, grad/param norm = 1.4051e-01, time/batch = 15.2639s	
16810/33250 (epoch 25.278), train_loss = 0.80662010, grad/param norm = 1.5043e-01, time/batch = 16.3574s	
16811/33250 (epoch 25.280), train_loss = 0.77860953, grad/param norm = 1.4280e-01, time/batch = 15.5326s	
16812/33250 (epoch 25.281), train_loss = 0.93108144, grad/param norm = 1.8234e-01, time/batch = 17.4339s	
16813/33250 (epoch 25.283), train_loss = 0.94093452, grad/param norm = 2.5825e-01, time/batch = 16.4327s	
16814/33250 (epoch 25.284), train_loss = 0.81768019, grad/param norm = 2.1162e-01, time/batch = 16.4626s	
16815/33250 (epoch 25.286), train_loss = 0.94059354, grad/param norm = 1.6709e-01, time/batch = 18.3619s	
16816/33250 (epoch 25.287), train_loss = 0.75546078, grad/param norm = 1.3595e-01, time/batch = 16.1763s	
16817/33250 (epoch 25.289), train_loss = 0.71816625, grad/param norm = 1.5217e-01, time/batch = 16.0957s	
16818/33250 (epoch 25.290), train_loss = 0.85966450, grad/param norm = 1.5450e-01, time/batch = 16.6786s	
16819/33250 (epoch 25.292), train_loss = 0.94496523, grad/param norm = 1.9249e-01, time/batch = 16.6721s	
16820/33250 (epoch 25.293), train_loss = 0.98813858, grad/param norm = 1.6873e-01, time/batch = 16.1696s	
16821/33250 (epoch 25.295), train_loss = 0.95917328, grad/param norm = 1.5740e-01, time/batch = 16.1984s	
16822/33250 (epoch 25.296), train_loss = 0.90487176, grad/param norm = 1.5472e-01, time/batch = 15.8603s	
16823/33250 (epoch 25.298), train_loss = 0.74594227, grad/param norm = 1.4689e-01, time/batch = 16.5968s	
16824/33250 (epoch 25.299), train_loss = 0.69832457, grad/param norm = 1.3090e-01, time/batch = 16.8734s	
16825/33250 (epoch 25.301), train_loss = 0.96757798, grad/param norm = 1.5606e-01, time/batch = 19.2110s	
16826/33250 (epoch 25.302), train_loss = 0.92744334, grad/param norm = 1.5931e-01, time/batch = 18.7836s	
16827/33250 (epoch 25.304), train_loss = 0.81321661, grad/param norm = 1.7031e-01, time/batch = 16.6051s	
16828/33250 (epoch 25.305), train_loss = 0.84500458, grad/param norm = 1.6049e-01, time/batch = 16.3593s	
16829/33250 (epoch 25.307), train_loss = 0.93982585, grad/param norm = 1.5460e-01, time/batch = 15.9536s	
16830/33250 (epoch 25.308), train_loss = 1.00584106, grad/param norm = 1.8169e-01, time/batch = 17.2497s	
16831/33250 (epoch 25.310), train_loss = 0.85236777, grad/param norm = 1.6990e-01, time/batch = 16.5207s	
16832/33250 (epoch 25.311), train_loss = 0.99932201, grad/param norm = 1.6484e-01, time/batch = 16.5351s	
16833/33250 (epoch 25.313), train_loss = 0.76997627, grad/param norm = 1.5723e-01, time/batch = 17.0178s	
16834/33250 (epoch 25.314), train_loss = 0.91575659, grad/param norm = 1.5268e-01, time/batch = 16.2471s	
16835/33250 (epoch 25.316), train_loss = 1.04573582, grad/param norm = 1.8046e-01, time/batch = 18.3657s	
16836/33250 (epoch 25.317), train_loss = 0.78658840, grad/param norm = 1.3632e-01, time/batch = 18.8706s	
16837/33250 (epoch 25.319), train_loss = 0.92452102, grad/param norm = 1.8383e-01, time/batch = 17.1767s	
16838/33250 (epoch 25.320), train_loss = 0.97920631, grad/param norm = 2.0688e-01, time/batch = 15.5914s	
16839/33250 (epoch 25.322), train_loss = 1.02504727, grad/param norm = 1.9481e-01, time/batch = 16.1977s	
16840/33250 (epoch 25.323), train_loss = 1.07164009, grad/param norm = 2.1398e-01, time/batch = 17.1023s	
16841/33250 (epoch 25.325), train_loss = 0.89339760, grad/param norm = 1.8036e-01, time/batch = 16.4356s	
16842/33250 (epoch 25.326), train_loss = 1.05289464, grad/param norm = 1.8480e-01, time/batch = 15.2646s	
16843/33250 (epoch 25.328), train_loss = 0.86068957, grad/param norm = 1.4441e-01, time/batch = 18.4307s	
16844/33250 (epoch 25.329), train_loss = 0.90389446, grad/param norm = 1.7842e-01, time/batch = 14.7343s	
16845/33250 (epoch 25.331), train_loss = 0.86319513, grad/param norm = 1.6490e-01, time/batch = 19.6162s	
16846/33250 (epoch 25.332), train_loss = 0.87170390, grad/param norm = 1.4358e-01, time/batch = 16.1366s	
16847/33250 (epoch 25.334), train_loss = 1.05850615, grad/param norm = 1.6918e-01, time/batch = 17.0346s	
16848/33250 (epoch 25.335), train_loss = 0.65827369, grad/param norm = 1.4617e-01, time/batch = 15.7306s	
16849/33250 (epoch 25.337), train_loss = 0.93776867, grad/param norm = 1.4402e-01, time/batch = 16.5880s	
16850/33250 (epoch 25.338), train_loss = 1.00276553, grad/param norm = 1.6468e-01, time/batch = 16.3561s	
16851/33250 (epoch 25.340), train_loss = 0.89759129, grad/param norm = 1.4905e-01, time/batch = 17.7506s	
16852/33250 (epoch 25.341), train_loss = 0.82809376, grad/param norm = 1.5594e-01, time/batch = 16.9294s	
16853/33250 (epoch 25.343), train_loss = 0.83783867, grad/param norm = 1.4850e-01, time/batch = 18.3435s	
16854/33250 (epoch 25.344), train_loss = 0.87296014, grad/param norm = 1.5176e-01, time/batch = 16.8676s	
16855/33250 (epoch 25.346), train_loss = 0.77883585, grad/param norm = 1.4651e-01, time/batch = 16.3674s	
16856/33250 (epoch 25.347), train_loss = 1.07827589, grad/param norm = 1.9624e-01, time/batch = 19.7041s	
16857/33250 (epoch 25.349), train_loss = 0.83464384, grad/param norm = 1.6676e-01, time/batch = 15.8721s	
16858/33250 (epoch 25.350), train_loss = 0.86201938, grad/param norm = 1.5840e-01, time/batch = 16.1609s	
16859/33250 (epoch 25.352), train_loss = 0.79348513, grad/param norm = 1.7139e-01, time/batch = 16.2702s	
16860/33250 (epoch 25.353), train_loss = 0.84056663, grad/param norm = 1.4114e-01, time/batch = 16.7602s	
16861/33250 (epoch 25.355), train_loss = 0.86654260, grad/param norm = 1.9305e-01, time/batch = 16.5044s	
16862/33250 (epoch 25.356), train_loss = 0.80869427, grad/param norm = 1.6533e-01, time/batch = 16.6011s	
16863/33250 (epoch 25.358), train_loss = 0.83515222, grad/param norm = 1.3969e-01, time/batch = 18.9569s	
16864/33250 (epoch 25.359), train_loss = 0.82312774, grad/param norm = 1.5044e-01, time/batch = 18.6971s	
16865/33250 (epoch 25.361), train_loss = 1.02194192, grad/param norm = 2.0333e-01, time/batch = 18.9471s	
16866/33250 (epoch 25.362), train_loss = 0.90090119, grad/param norm = 1.5413e-01, time/batch = 17.1115s	
16867/33250 (epoch 25.364), train_loss = 0.95665837, grad/param norm = 1.7602e-01, time/batch = 15.6952s	
16868/33250 (epoch 25.365), train_loss = 0.89317060, grad/param norm = 1.5903e-01, time/batch = 16.2764s	
16869/33250 (epoch 25.367), train_loss = 0.89308607, grad/param norm = 1.3736e-01, time/batch = 16.3340s	
16870/33250 (epoch 25.368), train_loss = 0.88472901, grad/param norm = 1.6392e-01, time/batch = 16.5124s	
16871/33250 (epoch 25.370), train_loss = 0.78499667, grad/param norm = 1.4820e-01, time/batch = 15.4319s	
16872/33250 (epoch 25.371), train_loss = 0.98993403, grad/param norm = 1.5801e-01, time/batch = 18.1754s	
16873/33250 (epoch 25.373), train_loss = 0.84038942, grad/param norm = 1.4918e-01, time/batch = 16.4459s	
16874/33250 (epoch 25.374), train_loss = 0.95758106, grad/param norm = 3.7323e-01, time/batch = 19.0405s	
16875/33250 (epoch 25.376), train_loss = 0.87311944, grad/param norm = 1.6593e-01, time/batch = 19.0318s	
16876/33250 (epoch 25.377), train_loss = 0.77782622, grad/param norm = 1.6916e-01, time/batch = 17.0957s	
16877/33250 (epoch 25.379), train_loss = 0.86933961, grad/param norm = 1.7604e-01, time/batch = 15.5204s	
16878/33250 (epoch 25.380), train_loss = 0.91752760, grad/param norm = 1.8657e-01, time/batch = 17.6700s	
16879/33250 (epoch 25.382), train_loss = 0.90908867, grad/param norm = 1.7276e-01, time/batch = 17.4399s	
16880/33250 (epoch 25.383), train_loss = 0.80539177, grad/param norm = 1.6876e-01, time/batch = 16.0781s	
16881/33250 (epoch 25.385), train_loss = 0.76457029, grad/param norm = 1.6162e-01, time/batch = 16.7703s	
16882/33250 (epoch 25.386), train_loss = 0.78046299, grad/param norm = 1.4729e-01, time/batch = 18.4447s	
16883/33250 (epoch 25.388), train_loss = 0.80363859, grad/param norm = 1.4624e-01, time/batch = 18.2769s	
16884/33250 (epoch 25.389), train_loss = 0.85555976, grad/param norm = 1.6591e-01, time/batch = 17.5393s	
16885/33250 (epoch 25.391), train_loss = 0.93127271, grad/param norm = 1.6307e-01, time/batch = 18.7085s	
16886/33250 (epoch 25.392), train_loss = 0.93819108, grad/param norm = 1.6941e-01, time/batch = 17.2576s	
16887/33250 (epoch 25.394), train_loss = 0.98456997, grad/param norm = 1.7412e-01, time/batch = 16.6818s	
16888/33250 (epoch 25.395), train_loss = 0.95708520, grad/param norm = 1.5869e-01, time/batch = 15.9356s	
16889/33250 (epoch 25.397), train_loss = 0.99367715, grad/param norm = 1.7357e-01, time/batch = 14.9871s	
16890/33250 (epoch 25.398), train_loss = 0.83269111, grad/param norm = 1.5120e-01, time/batch = 10.2414s	
16891/33250 (epoch 25.400), train_loss = 0.79312958, grad/param norm = 1.4376e-01, time/batch = 0.6996s	
16892/33250 (epoch 25.402), train_loss = 0.75325352, grad/param norm = 1.5874e-01, time/batch = 0.6947s	
16893/33250 (epoch 25.403), train_loss = 0.85932606, grad/param norm = 1.7677e-01, time/batch = 0.6925s	
16894/33250 (epoch 25.405), train_loss = 0.80536258, grad/param norm = 1.3916e-01, time/batch = 0.6943s	
16895/33250 (epoch 25.406), train_loss = 0.89473277, grad/param norm = 1.8542e-01, time/batch = 0.6906s	
16896/33250 (epoch 25.408), train_loss = 1.02516576, grad/param norm = 1.8159e-01, time/batch = 0.6968s	
16897/33250 (epoch 25.409), train_loss = 0.97362111, grad/param norm = 2.0481e-01, time/batch = 0.7541s	
16898/33250 (epoch 25.411), train_loss = 0.64924765, grad/param norm = 1.1711e-01, time/batch = 1.0062s	
16899/33250 (epoch 25.412), train_loss = 0.74216010, grad/param norm = 1.5689e-01, time/batch = 1.0036s	
16900/33250 (epoch 25.414), train_loss = 0.91654831, grad/param norm = 1.5875e-01, time/batch = 1.0068s	
16901/33250 (epoch 25.415), train_loss = 0.98124008, grad/param norm = 1.9354e-01, time/batch = 0.9995s	
16902/33250 (epoch 25.417), train_loss = 0.96202033, grad/param norm = 1.7320e-01, time/batch = 1.2502s	
16903/33250 (epoch 25.418), train_loss = 1.12338323, grad/param norm = 1.8391e-01, time/batch = 1.8808s	
16904/33250 (epoch 25.420), train_loss = 0.99352861, grad/param norm = 1.7733e-01, time/batch = 1.8942s	
16905/33250 (epoch 25.421), train_loss = 0.81758535, grad/param norm = 1.5904e-01, time/batch = 10.4975s	
16906/33250 (epoch 25.423), train_loss = 0.92570512, grad/param norm = 1.7976e-01, time/batch = 16.7841s	
16907/33250 (epoch 25.424), train_loss = 1.03961739, grad/param norm = 2.5453e-01, time/batch = 17.1183s	
16908/33250 (epoch 25.426), train_loss = 0.84965879, grad/param norm = 1.4881e-01, time/batch = 16.9537s	
16909/33250 (epoch 25.427), train_loss = 0.83580881, grad/param norm = 1.5713e-01, time/batch = 17.7044s	
16910/33250 (epoch 25.429), train_loss = 0.93016325, grad/param norm = 1.8365e-01, time/batch = 17.1797s	
16911/33250 (epoch 25.430), train_loss = 0.85512726, grad/param norm = 1.8538e-01, time/batch = 15.7629s	
16912/33250 (epoch 25.432), train_loss = 0.93448640, grad/param norm = 1.6396e-01, time/batch = 16.7013s	
16913/33250 (epoch 25.433), train_loss = 0.82078776, grad/param norm = 1.4188e-01, time/batch = 19.2439s	
16914/33250 (epoch 25.435), train_loss = 0.96581238, grad/param norm = 1.8439e-01, time/batch = 17.1858s	
16915/33250 (epoch 25.436), train_loss = 0.82785292, grad/param norm = 1.7503e-01, time/batch = 16.1153s	
16916/33250 (epoch 25.438), train_loss = 0.96731096, grad/param norm = 1.6834e-01, time/batch = 18.4397s	
16917/33250 (epoch 25.439), train_loss = 0.89150479, grad/param norm = 1.4427e-01, time/batch = 18.2070s	
16918/33250 (epoch 25.441), train_loss = 0.85389190, grad/param norm = 1.3179e-01, time/batch = 16.8733s	
16919/33250 (epoch 25.442), train_loss = 0.81332340, grad/param norm = 1.5987e-01, time/batch = 18.4542s	
16920/33250 (epoch 25.444), train_loss = 0.84526599, grad/param norm = 1.4502e-01, time/batch = 18.3398s	
16921/33250 (epoch 25.445), train_loss = 0.90369512, grad/param norm = 1.4318e-01, time/batch = 24.8634s	
16922/33250 (epoch 25.447), train_loss = 0.84521114, grad/param norm = 1.7409e-01, time/batch = 20.5508s	
16923/33250 (epoch 25.448), train_loss = 0.90675285, grad/param norm = 1.3983e-01, time/batch = 17.4306s	
16924/33250 (epoch 25.450), train_loss = 1.04074629, grad/param norm = 1.8083e-01, time/batch = 15.5121s	
16925/33250 (epoch 25.451), train_loss = 0.93621839, grad/param norm = 1.6680e-01, time/batch = 15.9581s	
16926/33250 (epoch 25.453), train_loss = 0.79706570, grad/param norm = 1.3780e-01, time/batch = 16.1722s	
16927/33250 (epoch 25.454), train_loss = 1.01254635, grad/param norm = 1.6162e-01, time/batch = 18.5324s	
16928/33250 (epoch 25.456), train_loss = 1.01958988, grad/param norm = 1.4304e-01, time/batch = 17.8441s	
16929/33250 (epoch 25.457), train_loss = 0.86507674, grad/param norm = 1.6348e-01, time/batch = 15.5193s	
16930/33250 (epoch 25.459), train_loss = 0.93847651, grad/param norm = 1.5939e-01, time/batch = 18.0825s	
16931/33250 (epoch 25.460), train_loss = 0.98394501, grad/param norm = 1.8253e-01, time/batch = 16.4372s	
16932/33250 (epoch 25.462), train_loss = 0.83845893, grad/param norm = 1.5861e-01, time/batch = 19.4208s	
16933/33250 (epoch 25.463), train_loss = 0.80933108, grad/param norm = 1.2890e-01, time/batch = 17.2535s	
16934/33250 (epoch 25.465), train_loss = 0.74653845, grad/param norm = 1.4026e-01, time/batch = 17.0716s	
16935/33250 (epoch 25.466), train_loss = 0.71353658, grad/param norm = 1.1689e-01, time/batch = 17.4577s	
16936/33250 (epoch 25.468), train_loss = 0.77952695, grad/param norm = 1.2522e-01, time/batch = 18.7734s	
16937/33250 (epoch 25.469), train_loss = 0.85440306, grad/param norm = 1.6529e-01, time/batch = 17.8723s	
16938/33250 (epoch 25.471), train_loss = 0.95655565, grad/param norm = 1.5026e-01, time/batch = 15.9206s	
16939/33250 (epoch 25.472), train_loss = 0.84676960, grad/param norm = 1.8369e-01, time/batch = 18.0176s	
16940/33250 (epoch 25.474), train_loss = 1.01627100, grad/param norm = 1.9557e-01, time/batch = 16.5303s	
16941/33250 (epoch 25.475), train_loss = 0.91072805, grad/param norm = 1.4593e-01, time/batch = 15.2523s	
16942/33250 (epoch 25.477), train_loss = 0.86547062, grad/param norm = 1.4738e-01, time/batch = 15.8548s	
16943/33250 (epoch 25.478), train_loss = 0.80789745, grad/param norm = 1.5106e-01, time/batch = 16.7454s	
16944/33250 (epoch 25.480), train_loss = 1.04885911, grad/param norm = 1.8215e-01, time/batch = 15.5002s	
16945/33250 (epoch 25.481), train_loss = 0.90233743, grad/param norm = 1.4948e-01, time/batch = 16.0071s	
16946/33250 (epoch 25.483), train_loss = 0.86645247, grad/param norm = 1.5898e-01, time/batch = 16.7159s	
16947/33250 (epoch 25.484), train_loss = 0.79278847, grad/param norm = 1.4275e-01, time/batch = 15.6098s	
16948/33250 (epoch 25.486), train_loss = 0.75833902, grad/param norm = 1.7254e-01, time/batch = 15.9392s	
16949/33250 (epoch 25.487), train_loss = 0.83180636, grad/param norm = 1.4760e-01, time/batch = 16.5833s	
16950/33250 (epoch 25.489), train_loss = 0.98746122, grad/param norm = 1.8953e-01, time/batch = 16.0167s	
16951/33250 (epoch 25.490), train_loss = 0.94326968, grad/param norm = 1.8052e-01, time/batch = 16.7599s	
16952/33250 (epoch 25.492), train_loss = 0.96629694, grad/param norm = 1.6737e-01, time/batch = 17.5898s	
16953/33250 (epoch 25.493), train_loss = 0.87268925, grad/param norm = 1.6243e-01, time/batch = 17.4332s	
16954/33250 (epoch 25.495), train_loss = 0.93597444, grad/param norm = 1.4050e-01, time/batch = 16.0911s	
16955/33250 (epoch 25.496), train_loss = 0.90173673, grad/param norm = 1.4178e-01, time/batch = 18.9467s	
16956/33250 (epoch 25.498), train_loss = 0.96083240, grad/param norm = 1.5602e-01, time/batch = 16.1711s	
16957/33250 (epoch 25.499), train_loss = 0.82602402, grad/param norm = 1.4760e-01, time/batch = 18.7898s	
16958/33250 (epoch 25.501), train_loss = 0.83084307, grad/param norm = 1.5967e-01, time/batch = 16.7129s	
16959/33250 (epoch 25.502), train_loss = 0.86120186, grad/param norm = 1.4326e-01, time/batch = 17.5767s	
16960/33250 (epoch 25.504), train_loss = 1.02548283, grad/param norm = 1.8061e-01, time/batch = 15.2639s	
16961/33250 (epoch 25.505), train_loss = 0.75034281, grad/param norm = 1.3537e-01, time/batch = 16.1060s	
16962/33250 (epoch 25.507), train_loss = 0.81471316, grad/param norm = 1.7340e-01, time/batch = 16.5145s	
16963/33250 (epoch 25.508), train_loss = 0.84873698, grad/param norm = 1.4829e-01, time/batch = 16.1918s	
16964/33250 (epoch 25.510), train_loss = 0.72374325, grad/param norm = 1.3453e-01, time/batch = 16.9372s	
16965/33250 (epoch 25.511), train_loss = 0.87395160, grad/param norm = 1.5311e-01, time/batch = 19.1901s	
16966/33250 (epoch 25.513), train_loss = 1.01688831, grad/param norm = 1.4913e-01, time/batch = 17.1962s	
16967/33250 (epoch 25.514), train_loss = 0.86940470, grad/param norm = 1.4255e-01, time/batch = 18.2780s	
16968/33250 (epoch 25.516), train_loss = 0.82192258, grad/param norm = 2.5641e-01, time/batch = 18.1121s	
16969/33250 (epoch 25.517), train_loss = 0.86534423, grad/param norm = 1.6162e-01, time/batch = 17.5112s	
16970/33250 (epoch 25.519), train_loss = 0.76586302, grad/param norm = 1.1795e-01, time/batch = 17.2473s	
16971/33250 (epoch 25.520), train_loss = 1.08693810, grad/param norm = 1.7318e-01, time/batch = 17.7604s	
16972/33250 (epoch 25.522), train_loss = 0.94532174, grad/param norm = 1.5666e-01, time/batch = 15.9554s	
16973/33250 (epoch 25.523), train_loss = 0.79945073, grad/param norm = 1.3937e-01, time/batch = 16.2685s	
16974/33250 (epoch 25.525), train_loss = 0.76280938, grad/param norm = 1.5571e-01, time/batch = 18.4400s	
16975/33250 (epoch 25.526), train_loss = 0.77722033, grad/param norm = 1.3939e-01, time/batch = 16.3711s	
16976/33250 (epoch 25.528), train_loss = 0.84876179, grad/param norm = 1.5188e-01, time/batch = 18.2746s	
16977/33250 (epoch 25.529), train_loss = 0.82533027, grad/param norm = 1.6975e-01, time/batch = 16.8369s	
16978/33250 (epoch 25.531), train_loss = 0.75999918, grad/param norm = 1.3104e-01, time/batch = 16.5007s	
16979/33250 (epoch 25.532), train_loss = 0.91967745, grad/param norm = 1.5146e-01, time/batch = 15.1016s	
16980/33250 (epoch 25.534), train_loss = 0.78655322, grad/param norm = 1.4595e-01, time/batch = 15.2800s	
16981/33250 (epoch 25.535), train_loss = 0.86659144, grad/param norm = 1.5089e-01, time/batch = 17.2600s	
16982/33250 (epoch 25.537), train_loss = 0.90991114, grad/param norm = 1.5285e-01, time/batch = 17.4251s	
16983/33250 (epoch 25.538), train_loss = 0.93049009, grad/param norm = 1.5498e-01, time/batch = 17.9218s	
16984/33250 (epoch 25.540), train_loss = 1.02949264, grad/param norm = 1.4858e-01, time/batch = 16.5249s	
16985/33250 (epoch 25.541), train_loss = 0.97396647, grad/param norm = 1.7157e-01, time/batch = 17.9518s	
16986/33250 (epoch 25.543), train_loss = 0.93531306, grad/param norm = 1.4603e-01, time/batch = 18.2005s	
16987/33250 (epoch 25.544), train_loss = 0.82325204, grad/param norm = 1.6285e-01, time/batch = 16.6115s	
16988/33250 (epoch 25.546), train_loss = 0.84469206, grad/param norm = 1.5724e-01, time/batch = 16.6759s	
16989/33250 (epoch 25.547), train_loss = 0.85979360, grad/param norm = 1.5915e-01, time/batch = 16.7715s	
16990/33250 (epoch 25.549), train_loss = 0.91673700, grad/param norm = 1.5454e-01, time/batch = 16.5945s	
16991/33250 (epoch 25.550), train_loss = 0.84691116, grad/param norm = 1.6000e-01, time/batch = 16.3308s	
16992/33250 (epoch 25.552), train_loss = 0.94521634, grad/param norm = 1.7108e-01, time/batch = 18.1692s	
16993/33250 (epoch 25.553), train_loss = 0.83390224, grad/param norm = 1.3779e-01, time/batch = 16.3564s	
16994/33250 (epoch 25.555), train_loss = 0.92319143, grad/param norm = 1.5482e-01, time/batch = 16.8484s	
16995/33250 (epoch 25.556), train_loss = 0.93436472, grad/param norm = 1.8393e-01, time/batch = 16.4520s	
16996/33250 (epoch 25.558), train_loss = 0.96567428, grad/param norm = 1.6889e-01, time/batch = 17.7513s	
16997/33250 (epoch 25.559), train_loss = 0.80860680, grad/param norm = 1.4826e-01, time/batch = 19.1105s	
16998/33250 (epoch 25.561), train_loss = 0.77710783, grad/param norm = 1.3670e-01, time/batch = 16.2859s	
16999/33250 (epoch 25.562), train_loss = 0.93551412, grad/param norm = 1.7539e-01, time/batch = 17.0080s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch25.56_1.5537.t7	
17000/33250 (epoch 25.564), train_loss = 1.07383492, grad/param norm = 1.8537e-01, time/batch = 17.3532s	
17001/33250 (epoch 25.565), train_loss = 1.52275677, grad/param norm = 2.3483e-01, time/batch = 18.0162s	
17002/33250 (epoch 25.567), train_loss = 1.01317056, grad/param norm = 1.6549e-01, time/batch = 15.9353s	
17003/33250 (epoch 25.568), train_loss = 0.88781010, grad/param norm = 1.6334e-01, time/batch = 15.5135s	
17004/33250 (epoch 25.570), train_loss = 0.97444728, grad/param norm = 1.7303e-01, time/batch = 16.3456s	
17005/33250 (epoch 25.571), train_loss = 1.03824178, grad/param norm = 1.7051e-01, time/batch = 17.9356s	
17006/33250 (epoch 25.573), train_loss = 0.94724278, grad/param norm = 1.7452e-01, time/batch = 18.0348s	
17007/33250 (epoch 25.574), train_loss = 0.79354759, grad/param norm = 1.4167e-01, time/batch = 17.6932s	
17008/33250 (epoch 25.576), train_loss = 0.95537722, grad/param norm = 1.6768e-01, time/batch = 18.3707s	
17009/33250 (epoch 25.577), train_loss = 0.87219981, grad/param norm = 1.4844e-01, time/batch = 18.2874s	
17010/33250 (epoch 25.579), train_loss = 0.80778226, grad/param norm = 2.0916e-01, time/batch = 16.5026s	
17011/33250 (epoch 25.580), train_loss = 0.85309145, grad/param norm = 1.2768e-01, time/batch = 16.8567s	
17012/33250 (epoch 25.582), train_loss = 0.86750367, grad/param norm = 1.4856e-01, time/batch = 17.2664s	
17013/33250 (epoch 25.583), train_loss = 0.99703032, grad/param norm = 1.5586e-01, time/batch = 17.0215s	
17014/33250 (epoch 25.585), train_loss = 0.98633662, grad/param norm = 1.5796e-01, time/batch = 16.7793s	
17015/33250 (epoch 25.586), train_loss = 0.80501991, grad/param norm = 1.7985e-01, time/batch = 15.8674s	
17016/33250 (epoch 25.588), train_loss = 0.91860543, grad/param norm = 1.5342e-01, time/batch = 15.7156s	
17017/33250 (epoch 25.589), train_loss = 0.91065222, grad/param norm = 1.5764e-01, time/batch = 15.7618s	
17018/33250 (epoch 25.591), train_loss = 0.86325880, grad/param norm = 1.7110e-01, time/batch = 15.3628s	
17019/33250 (epoch 25.592), train_loss = 0.87681763, grad/param norm = 1.5792e-01, time/batch = 15.2661s	
17020/33250 (epoch 25.594), train_loss = 1.01239378, grad/param norm = 1.8169e-01, time/batch = 14.8616s	
17021/33250 (epoch 25.595), train_loss = 0.91122367, grad/param norm = 1.5964e-01, time/batch = 14.9414s	
17022/33250 (epoch 25.597), train_loss = 0.75777708, grad/param norm = 1.3448e-01, time/batch = 15.5603s	
17023/33250 (epoch 25.598), train_loss = 0.84312910, grad/param norm = 1.5718e-01, time/batch = 14.9290s	
17024/33250 (epoch 25.600), train_loss = 0.85984545, grad/param norm = 1.7860e-01, time/batch = 14.8573s	
17025/33250 (epoch 25.602), train_loss = 0.90782270, grad/param norm = 1.7409e-01, time/batch = 14.8537s	
17026/33250 (epoch 25.603), train_loss = 0.94791932, grad/param norm = 1.7321e-01, time/batch = 14.8522s	
17027/33250 (epoch 25.605), train_loss = 0.89932056, grad/param norm = 1.6392e-01, time/batch = 14.8722s	
17028/33250 (epoch 25.606), train_loss = 0.95164765, grad/param norm = 1.5867e-01, time/batch = 14.7148s	
17029/33250 (epoch 25.608), train_loss = 0.90872097, grad/param norm = 1.4789e-01, time/batch = 15.1673s	
17030/33250 (epoch 25.609), train_loss = 0.82240737, grad/param norm = 1.5836e-01, time/batch = 15.0958s	
17031/33250 (epoch 25.611), train_loss = 0.92877407, grad/param norm = 1.7407e-01, time/batch = 14.7032s	
17032/33250 (epoch 25.612), train_loss = 0.88117141, grad/param norm = 1.7045e-01, time/batch = 14.6112s	
17033/33250 (epoch 25.614), train_loss = 1.10594652, grad/param norm = 1.9153e-01, time/batch = 15.0243s	
17034/33250 (epoch 25.615), train_loss = 0.98222250, grad/param norm = 1.5158e-01, time/batch = 15.3378s	
17035/33250 (epoch 25.617), train_loss = 1.13442134, grad/param norm = 1.9633e-01, time/batch = 14.5403s	
17036/33250 (epoch 25.618), train_loss = 1.14378509, grad/param norm = 2.1212e-01, time/batch = 14.6182s	
17037/33250 (epoch 25.620), train_loss = 0.98149815, grad/param norm = 1.7685e-01, time/batch = 15.3941s	
17038/33250 (epoch 25.621), train_loss = 0.93931928, grad/param norm = 1.6902e-01, time/batch = 14.6177s	
17039/33250 (epoch 25.623), train_loss = 0.80952896, grad/param norm = 1.5286e-01, time/batch = 14.8011s	
17040/33250 (epoch 25.624), train_loss = 0.90010026, grad/param norm = 2.1706e-01, time/batch = 15.0617s	
17041/33250 (epoch 25.626), train_loss = 0.85913376, grad/param norm = 1.8186e-01, time/batch = 15.1363s	
17042/33250 (epoch 25.627), train_loss = 0.85143069, grad/param norm = 1.5441e-01, time/batch = 15.6736s	
17043/33250 (epoch 25.629), train_loss = 0.93802341, grad/param norm = 1.8111e-01, time/batch = 15.1068s	
17044/33250 (epoch 25.630), train_loss = 0.85692241, grad/param norm = 1.7508e-01, time/batch = 14.7945s	
17045/33250 (epoch 25.632), train_loss = 0.76379799, grad/param norm = 1.5358e-01, time/batch = 15.1781s	
17046/33250 (epoch 25.633), train_loss = 0.89415483, grad/param norm = 1.5892e-01, time/batch = 15.6495s	
17047/33250 (epoch 25.635), train_loss = 0.83087632, grad/param norm = 1.5935e-01, time/batch = 15.5869s	
17048/33250 (epoch 25.636), train_loss = 0.81948187, grad/param norm = 1.4546e-01, time/batch = 15.2578s	
17049/33250 (epoch 25.638), train_loss = 0.81927349, grad/param norm = 1.6952e-01, time/batch = 15.2682s	
17050/33250 (epoch 25.639), train_loss = 0.75803713, grad/param norm = 1.4499e-01, time/batch = 14.8739s	
17051/33250 (epoch 25.641), train_loss = 0.86034523, grad/param norm = 1.5590e-01, time/batch = 14.8806s	
17052/33250 (epoch 25.642), train_loss = 0.71051517, grad/param norm = 1.5161e-01, time/batch = 14.8017s	
17053/33250 (epoch 25.644), train_loss = 0.63086734, grad/param norm = 1.3868e-01, time/batch = 15.1110s	
17054/33250 (epoch 25.645), train_loss = 0.94680548, grad/param norm = 1.8064e-01, time/batch = 14.8673s	
17055/33250 (epoch 25.647), train_loss = 0.77164902, grad/param norm = 1.7075e-01, time/batch = 15.1094s	
17056/33250 (epoch 25.648), train_loss = 0.79341666, grad/param norm = 1.6990e-01, time/batch = 14.7864s	
17057/33250 (epoch 25.650), train_loss = 1.01838654, grad/param norm = 1.6476e-01, time/batch = 15.2584s	
17058/33250 (epoch 25.651), train_loss = 0.93470806, grad/param norm = 1.7816e-01, time/batch = 15.0103s	
17059/33250 (epoch 25.653), train_loss = 0.80516977, grad/param norm = 1.5685e-01, time/batch = 14.9455s	
17060/33250 (epoch 25.654), train_loss = 0.88479326, grad/param norm = 1.4648e-01, time/batch = 15.0945s	
17061/33250 (epoch 25.656), train_loss = 0.92673377, grad/param norm = 1.5583e-01, time/batch = 15.5884s	
17062/33250 (epoch 25.657), train_loss = 0.69213623, grad/param norm = 1.4996e-01, time/batch = 15.2842s	
17063/33250 (epoch 25.659), train_loss = 0.80318784, grad/param norm = 1.4261e-01, time/batch = 15.2021s	
17064/33250 (epoch 25.660), train_loss = 0.89899737, grad/param norm = 1.9103e-01, time/batch = 14.8780s	
17065/33250 (epoch 25.662), train_loss = 0.87419203, grad/param norm = 1.6175e-01, time/batch = 15.1822s	
17066/33250 (epoch 25.663), train_loss = 0.81598532, grad/param norm = 1.5096e-01, time/batch = 14.9399s	
17067/33250 (epoch 25.665), train_loss = 0.92416491, grad/param norm = 1.6168e-01, time/batch = 14.8680s	
17068/33250 (epoch 25.666), train_loss = 0.83843002, grad/param norm = 1.4072e-01, time/batch = 15.2642s	
17069/33250 (epoch 25.668), train_loss = 1.00664596, grad/param norm = 1.6182e-01, time/batch = 15.2812s	
17070/33250 (epoch 25.669), train_loss = 0.89389935, grad/param norm = 1.6126e-01, time/batch = 15.1138s	
17071/33250 (epoch 25.671), train_loss = 0.80741364, grad/param norm = 1.4941e-01, time/batch = 14.9567s	
17072/33250 (epoch 25.672), train_loss = 0.95825902, grad/param norm = 1.6406e-01, time/batch = 14.8936s	
17073/33250 (epoch 25.674), train_loss = 0.76912016, grad/param norm = 1.3901e-01, time/batch = 15.1095s	
17074/33250 (epoch 25.675), train_loss = 0.88007519, grad/param norm = 1.5614e-01, time/batch = 14.8976s	
17075/33250 (epoch 25.677), train_loss = 0.96035496, grad/param norm = 1.7057e-01, time/batch = 14.6262s	
17076/33250 (epoch 25.678), train_loss = 0.85756405, grad/param norm = 1.7535e-01, time/batch = 14.7750s	
17077/33250 (epoch 25.680), train_loss = 0.96560252, grad/param norm = 1.9473e-01, time/batch = 15.6568s	
17078/33250 (epoch 25.681), train_loss = 0.78843490, grad/param norm = 1.4227e-01, time/batch = 14.5441s	
17079/33250 (epoch 25.683), train_loss = 0.82513590, grad/param norm = 1.5294e-01, time/batch = 14.7775s	
17080/33250 (epoch 25.684), train_loss = 0.79189986, grad/param norm = 1.6946e-01, time/batch = 14.5454s	
17081/33250 (epoch 25.686), train_loss = 0.78645835, grad/param norm = 1.6371e-01, time/batch = 15.0159s	
17082/33250 (epoch 25.687), train_loss = 0.88712968, grad/param norm = 1.5692e-01, time/batch = 15.1891s	
17083/33250 (epoch 25.689), train_loss = 0.80056932, grad/param norm = 1.6517e-01, time/batch = 15.1202s	
17084/33250 (epoch 25.690), train_loss = 0.89805488, grad/param norm = 1.7747e-01, time/batch = 14.7184s	
17085/33250 (epoch 25.692), train_loss = 0.85084807, grad/param norm = 1.4710e-01, time/batch = 14.8812s	
17086/33250 (epoch 25.693), train_loss = 0.94423273, grad/param norm = 1.5958e-01, time/batch = 14.4744s	
17087/33250 (epoch 25.695), train_loss = 0.91100784, grad/param norm = 1.5857e-01, time/batch = 14.7960s	
17088/33250 (epoch 25.696), train_loss = 0.93265688, grad/param norm = 1.5063e-01, time/batch = 15.0284s	
17089/33250 (epoch 25.698), train_loss = 0.84310497, grad/param norm = 1.6409e-01, time/batch = 15.5115s	
17090/33250 (epoch 25.699), train_loss = 1.07509598, grad/param norm = 1.6465e-01, time/batch = 15.3972s	
17091/33250 (epoch 25.701), train_loss = 0.87843194, grad/param norm = 1.4641e-01, time/batch = 15.3380s	
17092/33250 (epoch 25.702), train_loss = 0.83228478, grad/param norm = 1.6467e-01, time/batch = 14.8697s	
17093/33250 (epoch 25.704), train_loss = 1.07039638, grad/param norm = 2.5128e-01, time/batch = 15.3455s	
17094/33250 (epoch 25.705), train_loss = 0.83049936, grad/param norm = 1.4537e-01, time/batch = 14.7831s	
17095/33250 (epoch 25.707), train_loss = 0.72914223, grad/param norm = 1.4239e-01, time/batch = 15.0541s	
17096/33250 (epoch 25.708), train_loss = 0.96259824, grad/param norm = 1.7704e-01, time/batch = 14.8882s	
17097/33250 (epoch 25.710), train_loss = 0.93225992, grad/param norm = 1.7784e-01, time/batch = 15.5148s	
17098/33250 (epoch 25.711), train_loss = 0.78439927, grad/param norm = 1.5786e-01, time/batch = 14.9618s	
17099/33250 (epoch 25.713), train_loss = 0.91739373, grad/param norm = 1.5094e-01, time/batch = 14.9381s	
17100/33250 (epoch 25.714), train_loss = 0.89061425, grad/param norm = 1.6869e-01, time/batch = 15.3410s	
17101/33250 (epoch 25.716), train_loss = 0.91695437, grad/param norm = 1.7259e-01, time/batch = 15.1926s	
17102/33250 (epoch 25.717), train_loss = 0.81023878, grad/param norm = 1.3463e-01, time/batch = 15.3378s	
17103/33250 (epoch 25.719), train_loss = 0.85321871, grad/param norm = 1.5235e-01, time/batch = 14.8579s	
17104/33250 (epoch 25.720), train_loss = 1.11450643, grad/param norm = 1.8171e-01, time/batch = 14.6121s	
17105/33250 (epoch 25.722), train_loss = 0.77172181, grad/param norm = 1.3593e-01, time/batch = 15.0337s	
17106/33250 (epoch 25.723), train_loss = 0.70404757, grad/param norm = 1.4141e-01, time/batch = 15.0510s	
17107/33250 (epoch 25.725), train_loss = 0.78673911, grad/param norm = 1.2807e-01, time/batch = 14.8867s	
17108/33250 (epoch 25.726), train_loss = 0.85884640, grad/param norm = 1.5242e-01, time/batch = 14.8918s	
17109/33250 (epoch 25.728), train_loss = 0.92474513, grad/param norm = 1.7179e-01, time/batch = 15.1287s	
17110/33250 (epoch 25.729), train_loss = 0.96849051, grad/param norm = 1.5206e-01, time/batch = 14.6087s	
17111/33250 (epoch 25.731), train_loss = 0.82929091, grad/param norm = 1.6135e-01, time/batch = 14.9495s	
17112/33250 (epoch 25.732), train_loss = 0.77716531, grad/param norm = 1.3066e-01, time/batch = 14.9538s	
17113/33250 (epoch 25.734), train_loss = 0.91759234, grad/param norm = 2.0346e-01, time/batch = 15.2711s	
17114/33250 (epoch 25.735), train_loss = 0.89290170, grad/param norm = 1.9296e-01, time/batch = 14.8568s	
17115/33250 (epoch 25.737), train_loss = 0.84190201, grad/param norm = 1.4733e-01, time/batch = 17.0912s	
17116/33250 (epoch 25.738), train_loss = 0.90568351, grad/param norm = 1.5578e-01, time/batch = 15.2063s	
17117/33250 (epoch 25.740), train_loss = 0.97067952, grad/param norm = 1.7721e-01, time/batch = 17.0189s	
17118/33250 (epoch 25.741), train_loss = 0.93393338, grad/param norm = 1.5814e-01, time/batch = 18.7799s	
17119/33250 (epoch 25.743), train_loss = 0.80769379, grad/param norm = 1.4387e-01, time/batch = 18.7593s	
17120/33250 (epoch 25.744), train_loss = 0.85091813, grad/param norm = 1.7633e-01, time/batch = 16.1813s	
17121/33250 (epoch 25.746), train_loss = 0.78957371, grad/param norm = 1.4058e-01, time/batch = 15.4121s	
17122/33250 (epoch 25.747), train_loss = 0.82657634, grad/param norm = 1.6496e-01, time/batch = 18.2506s	
17123/33250 (epoch 25.749), train_loss = 0.98237809, grad/param norm = 1.7974e-01, time/batch = 17.2665s	
17124/33250 (epoch 25.750), train_loss = 0.95909572, grad/param norm = 1.6619e-01, time/batch = 16.6905s	
17125/33250 (epoch 25.752), train_loss = 0.84112832, grad/param norm = 1.4887e-01, time/batch = 17.0881s	
17126/33250 (epoch 25.753), train_loss = 0.82594734, grad/param norm = 1.5189e-01, time/batch = 17.6002s	
17127/33250 (epoch 25.755), train_loss = 0.83052750, grad/param norm = 1.6893e-01, time/batch = 17.6891s	
17128/33250 (epoch 25.756), train_loss = 0.89905837, grad/param norm = 1.6849e-01, time/batch = 19.5209s	
17129/33250 (epoch 25.758), train_loss = 1.01760821, grad/param norm = 1.5355e-01, time/batch = 17.6955s	
17130/33250 (epoch 25.759), train_loss = 0.80754094, grad/param norm = 1.4592e-01, time/batch = 16.1082s	
17131/33250 (epoch 25.761), train_loss = 0.87982234, grad/param norm = 1.5394e-01, time/batch = 16.6820s	
17132/33250 (epoch 25.762), train_loss = 0.96160391, grad/param norm = 1.5704e-01, time/batch = 16.9273s	
17133/33250 (epoch 25.764), train_loss = 0.80061305, grad/param norm = 2.0101e-01, time/batch = 16.8559s	
17134/33250 (epoch 25.765), train_loss = 0.92117152, grad/param norm = 1.6359e-01, time/batch = 29.6162s	
17135/33250 (epoch 25.767), train_loss = 0.70720206, grad/param norm = 1.4467e-01, time/batch = 15.0350s	
17136/33250 (epoch 25.768), train_loss = 0.74033323, grad/param norm = 1.6438e-01, time/batch = 15.0456s	
17137/33250 (epoch 25.770), train_loss = 0.91595872, grad/param norm = 1.7284e-01, time/batch = 15.0395s	
17138/33250 (epoch 25.771), train_loss = 0.93199997, grad/param norm = 1.6453e-01, time/batch = 16.0011s	
17139/33250 (epoch 25.773), train_loss = 0.85853933, grad/param norm = 1.7324e-01, time/batch = 16.4436s	
17140/33250 (epoch 25.774), train_loss = 0.73273012, grad/param norm = 1.4833e-01, time/batch = 15.9292s	
17141/33250 (epoch 25.776), train_loss = 0.84298910, grad/param norm = 1.5340e-01, time/batch = 15.0061s	
17142/33250 (epoch 25.777), train_loss = 0.97103535, grad/param norm = 1.8012e-01, time/batch = 15.5134s	
17143/33250 (epoch 25.779), train_loss = 0.86560552, grad/param norm = 1.6592e-01, time/batch = 16.5056s	
17144/33250 (epoch 25.780), train_loss = 1.01853558, grad/param norm = 1.7977e-01, time/batch = 16.9410s	
17145/33250 (epoch 25.782), train_loss = 0.87639063, grad/param norm = 1.7064e-01, time/batch = 18.6076s	
17146/33250 (epoch 25.783), train_loss = 0.74484869, grad/param norm = 1.4501e-01, time/batch = 17.8673s	
17147/33250 (epoch 25.785), train_loss = 0.76173431, grad/param norm = 1.4461e-01, time/batch = 17.2105s	
17148/33250 (epoch 25.786), train_loss = 1.00112894, grad/param norm = 1.8476e-01, time/batch = 17.1838s	
17149/33250 (epoch 25.788), train_loss = 0.97096944, grad/param norm = 1.6601e-01, time/batch = 15.1260s	
17150/33250 (epoch 25.789), train_loss = 1.00002159, grad/param norm = 1.9109e-01, time/batch = 16.5170s	
17151/33250 (epoch 25.791), train_loss = 1.04185741, grad/param norm = 1.8786e-01, time/batch = 15.5898s	
17152/33250 (epoch 25.792), train_loss = 1.06496102, grad/param norm = 1.6701e-01, time/batch = 16.4949s	
17153/33250 (epoch 25.794), train_loss = 0.84993397, grad/param norm = 1.5677e-01, time/batch = 16.0112s	
17154/33250 (epoch 25.795), train_loss = 0.90817334, grad/param norm = 1.7704e-01, time/batch = 15.7655s	
17155/33250 (epoch 25.797), train_loss = 0.95585540, grad/param norm = 1.7548e-01, time/batch = 17.0392s	
17156/33250 (epoch 25.798), train_loss = 0.89689978, grad/param norm = 1.9220e-01, time/batch = 16.1093s	
17157/33250 (epoch 25.800), train_loss = 0.94186541, grad/param norm = 2.0561e-01, time/batch = 18.5362s	
17158/33250 (epoch 25.802), train_loss = 0.84832219, grad/param norm = 1.4236e-01, time/batch = 15.6135s	
17159/33250 (epoch 25.803), train_loss = 0.90938492, grad/param norm = 1.4883e-01, time/batch = 16.8462s	
17160/33250 (epoch 25.805), train_loss = 0.93689596, grad/param norm = 1.7673e-01, time/batch = 15.9395s	
17161/33250 (epoch 25.806), train_loss = 0.90026288, grad/param norm = 1.7564e-01, time/batch = 16.1674s	
17162/33250 (epoch 25.808), train_loss = 0.83459157, grad/param norm = 1.5690e-01, time/batch = 16.5135s	
17163/33250 (epoch 25.809), train_loss = 0.79759107, grad/param norm = 1.4498e-01, time/batch = 16.7687s	
17164/33250 (epoch 25.811), train_loss = 0.80380257, grad/param norm = 1.4529e-01, time/batch = 16.4416s	
17165/33250 (epoch 25.812), train_loss = 0.93668324, grad/param norm = 1.9042e-01, time/batch = 18.7803s	
17166/33250 (epoch 25.814), train_loss = 0.88023315, grad/param norm = 1.6710e-01, time/batch = 15.9420s	
17167/33250 (epoch 25.815), train_loss = 0.94742372, grad/param norm = 1.5934e-01, time/batch = 17.8697s	
17168/33250 (epoch 25.817), train_loss = 0.87275517, grad/param norm = 1.6043e-01, time/batch = 16.3739s	
17169/33250 (epoch 25.818), train_loss = 0.79900175, grad/param norm = 1.5451e-01, time/batch = 16.0830s	
17170/33250 (epoch 25.820), train_loss = 0.90509760, grad/param norm = 1.6464e-01, time/batch = 16.5183s	
17171/33250 (epoch 25.821), train_loss = 0.85878034, grad/param norm = 1.4600e-01, time/batch = 15.9399s	
17172/33250 (epoch 25.823), train_loss = 1.19942891, grad/param norm = 2.1697e-01, time/batch = 16.9436s	
17173/33250 (epoch 25.824), train_loss = 0.82039995, grad/param norm = 1.6604e-01, time/batch = 16.1782s	
17174/33250 (epoch 25.826), train_loss = 0.92208912, grad/param norm = 1.7575e-01, time/batch = 15.7560s	
17175/33250 (epoch 25.827), train_loss = 0.75444881, grad/param norm = 1.6348e-01, time/batch = 18.5293s	
17176/33250 (epoch 25.829), train_loss = 0.88755101, grad/param norm = 1.8481e-01, time/batch = 17.4444s	
17177/33250 (epoch 25.830), train_loss = 0.98330270, grad/param norm = 2.3090e-01, time/batch = 16.0340s	
17178/33250 (epoch 25.832), train_loss = 0.89845025, grad/param norm = 1.7032e-01, time/batch = 14.9758s	
17179/33250 (epoch 25.833), train_loss = 0.88165571, grad/param norm = 1.7562e-01, time/batch = 17.5971s	
17180/33250 (epoch 25.835), train_loss = 0.80325924, grad/param norm = 2.1405e-01, time/batch = 15.4434s	
17181/33250 (epoch 25.836), train_loss = 0.85900652, grad/param norm = 1.5835e-01, time/batch = 18.6708s	
17182/33250 (epoch 25.838), train_loss = 0.91108363, grad/param norm = 1.5892e-01, time/batch = 18.1813s	
17183/33250 (epoch 25.839), train_loss = 0.84761204, grad/param norm = 1.5384e-01, time/batch = 17.0882s	
17184/33250 (epoch 25.841), train_loss = 0.81134223, grad/param norm = 1.4012e-01, time/batch = 16.2628s	
17185/33250 (epoch 25.842), train_loss = 1.02640177, grad/param norm = 1.5510e-01, time/batch = 19.1083s	
17186/33250 (epoch 25.844), train_loss = 1.00967998, grad/param norm = 1.8159e-01, time/batch = 16.8691s	
17187/33250 (epoch 25.845), train_loss = 1.06376111, grad/param norm = 1.8443e-01, time/batch = 16.5971s	
17188/33250 (epoch 25.847), train_loss = 1.06144238, grad/param norm = 1.8230e-01, time/batch = 18.8614s	
17189/33250 (epoch 25.848), train_loss = 1.11387301, grad/param norm = 1.9838e-01, time/batch = 15.4622s	
17190/33250 (epoch 25.850), train_loss = 0.99064712, grad/param norm = 1.6764e-01, time/batch = 17.6081s	
17191/33250 (epoch 25.851), train_loss = 0.81186563, grad/param norm = 1.8561e-01, time/batch = 16.5802s	
17192/33250 (epoch 25.853), train_loss = 0.95151395, grad/param norm = 2.0247e-01, time/batch = 15.7473s	
17193/33250 (epoch 25.854), train_loss = 0.84713905, grad/param norm = 1.4921e-01, time/batch = 17.1095s	
17194/33250 (epoch 25.856), train_loss = 0.83706154, grad/param norm = 1.6478e-01, time/batch = 16.3528s	
17195/33250 (epoch 25.857), train_loss = 0.76059705, grad/param norm = 1.5300e-01, time/batch = 16.3571s	
17196/33250 (epoch 25.859), train_loss = 0.79516189, grad/param norm = 1.5665e-01, time/batch = 19.5337s	
17197/33250 (epoch 25.860), train_loss = 0.90312053, grad/param norm = 1.4770e-01, time/batch = 16.9394s	
17198/33250 (epoch 25.862), train_loss = 0.80142847, grad/param norm = 1.6792e-01, time/batch = 17.6060s	
17199/33250 (epoch 25.863), train_loss = 0.85177260, grad/param norm = 1.7210e-01, time/batch = 18.6699s	
17200/33250 (epoch 25.865), train_loss = 0.91929850, grad/param norm = 1.5606e-01, time/batch = 18.1633s	
17201/33250 (epoch 25.866), train_loss = 0.79363841, grad/param norm = 1.6676e-01, time/batch = 18.1691s	
17202/33250 (epoch 25.868), train_loss = 0.91404670, grad/param norm = 1.8251e-01, time/batch = 17.1843s	
17203/33250 (epoch 25.869), train_loss = 0.90692098, grad/param norm = 1.6543e-01, time/batch = 18.5880s	
17204/33250 (epoch 25.871), train_loss = 0.70822500, grad/param norm = 1.4684e-01, time/batch = 15.5967s	
17205/33250 (epoch 25.872), train_loss = 0.96210282, grad/param norm = 1.8923e-01, time/batch = 15.3702s	
17206/33250 (epoch 25.874), train_loss = 0.80826419, grad/param norm = 1.5539e-01, time/batch = 17.5211s	
17207/33250 (epoch 25.875), train_loss = 0.79960440, grad/param norm = 2.1707e-01, time/batch = 18.2089s	
17208/33250 (epoch 25.877), train_loss = 1.01198853, grad/param norm = 1.6172e-01, time/batch = 16.5923s	
17209/33250 (epoch 25.878), train_loss = 0.91880381, grad/param norm = 1.5379e-01, time/batch = 15.3195s	
17210/33250 (epoch 25.880), train_loss = 0.86907683, grad/param norm = 1.8827e-01, time/batch = 18.8480s	
17211/33250 (epoch 25.881), train_loss = 1.00439935, grad/param norm = 1.6462e-01, time/batch = 16.1853s	
17212/33250 (epoch 25.883), train_loss = 0.91300862, grad/param norm = 1.6140e-01, time/batch = 15.7465s	
17213/33250 (epoch 25.884), train_loss = 0.96973593, grad/param norm = 2.0067e-01, time/batch = 19.0042s	
17214/33250 (epoch 25.886), train_loss = 0.83114012, grad/param norm = 1.4089e-01, time/batch = 17.3515s	
17215/33250 (epoch 25.887), train_loss = 0.84303351, grad/param norm = 1.6720e-01, time/batch = 16.7677s	
17216/33250 (epoch 25.889), train_loss = 0.84458608, grad/param norm = 1.4459e-01, time/batch = 15.8047s	
17217/33250 (epoch 25.890), train_loss = 0.70948532, grad/param norm = 1.2791e-01, time/batch = 19.6062s	
17218/33250 (epoch 25.892), train_loss = 0.94262563, grad/param norm = 1.6229e-01, time/batch = 15.8763s	
17219/33250 (epoch 25.893), train_loss = 0.94240460, grad/param norm = 1.8760e-01, time/batch = 16.6870s	
17220/33250 (epoch 25.895), train_loss = 0.81358052, grad/param norm = 1.7355e-01, time/batch = 16.1117s	
17221/33250 (epoch 25.896), train_loss = 0.96373458, grad/param norm = 1.8474e-01, time/batch = 18.3229s	
17222/33250 (epoch 25.898), train_loss = 0.90763871, grad/param norm = 1.7195e-01, time/batch = 16.6569s	
17223/33250 (epoch 25.899), train_loss = 0.82282057, grad/param norm = 1.4042e-01, time/batch = 17.0815s	
17224/33250 (epoch 25.901), train_loss = 0.75714745, grad/param norm = 1.4181e-01, time/batch = 15.7139s	
17225/33250 (epoch 25.902), train_loss = 0.85640817, grad/param norm = 1.5473e-01, time/batch = 17.6175s	
17226/33250 (epoch 25.904), train_loss = 0.79619247, grad/param norm = 1.4268e-01, time/batch = 17.2645s	
17227/33250 (epoch 25.905), train_loss = 0.84080976, grad/param norm = 1.4662e-01, time/batch = 16.1182s	
17228/33250 (epoch 25.907), train_loss = 0.78049475, grad/param norm = 1.3906e-01, time/batch = 18.3637s	
17229/33250 (epoch 25.908), train_loss = 0.87420630, grad/param norm = 1.4178e-01, time/batch = 16.2025s	
17230/33250 (epoch 25.910), train_loss = 0.93946272, grad/param norm = 1.7905e-01, time/batch = 17.9996s	
17231/33250 (epoch 25.911), train_loss = 0.77366177, grad/param norm = 1.3999e-01, time/batch = 18.3990s	
17232/33250 (epoch 25.913), train_loss = 0.83543585, grad/param norm = 1.4482e-01, time/batch = 16.1898s	
17233/33250 (epoch 25.914), train_loss = 0.75775334, grad/param norm = 1.6734e-01, time/batch = 15.2974s	
17234/33250 (epoch 25.916), train_loss = 0.80954780, grad/param norm = 1.5226e-01, time/batch = 16.4304s	
17235/33250 (epoch 25.917), train_loss = 0.86852838, grad/param norm = 1.3809e-01, time/batch = 17.9542s	
17236/33250 (epoch 25.919), train_loss = 0.81886110, grad/param norm = 1.6703e-01, time/batch = 15.8131s	
17237/33250 (epoch 25.920), train_loss = 0.87766387, grad/param norm = 1.5620e-01, time/batch = 19.1931s	
17238/33250 (epoch 25.922), train_loss = 0.90160628, grad/param norm = 1.6748e-01, time/batch = 16.1703s	
17239/33250 (epoch 25.923), train_loss = 0.81382613, grad/param norm = 1.6891e-01, time/batch = 16.9240s	
17240/33250 (epoch 25.925), train_loss = 0.83522186, grad/param norm = 1.6808e-01, time/batch = 16.2462s	
17241/33250 (epoch 25.926), train_loss = 0.82352886, grad/param norm = 1.4883e-01, time/batch = 16.6037s	
17242/33250 (epoch 25.928), train_loss = 0.84294839, grad/param norm = 1.6286e-01, time/batch = 16.7695s	
17243/33250 (epoch 25.929), train_loss = 0.73644888, grad/param norm = 1.3557e-01, time/batch = 15.8683s	
17244/33250 (epoch 25.931), train_loss = 0.98052049, grad/param norm = 1.6819e-01, time/batch = 16.4318s	
17245/33250 (epoch 25.932), train_loss = 0.83702408, grad/param norm = 1.6561e-01, time/batch = 17.5482s	
17246/33250 (epoch 25.934), train_loss = 0.81029600, grad/param norm = 1.3697e-01, time/batch = 18.4427s	
17247/33250 (epoch 25.935), train_loss = 0.81811425, grad/param norm = 1.7392e-01, time/batch = 16.6966s	
17248/33250 (epoch 25.937), train_loss = 0.81954264, grad/param norm = 1.8377e-01, time/batch = 18.7561s	
17249/33250 (epoch 25.938), train_loss = 0.88334387, grad/param norm = 1.6234e-01, time/batch = 18.7449s	
17250/33250 (epoch 25.940), train_loss = 0.84606187, grad/param norm = 1.5021e-01, time/batch = 17.7391s	
17251/33250 (epoch 25.941), train_loss = 0.91830735, grad/param norm = 1.6007e-01, time/batch = 16.0037s	
17252/33250 (epoch 25.943), train_loss = 1.00408342, grad/param norm = 1.6414e-01, time/batch = 18.5861s	
17253/33250 (epoch 25.944), train_loss = 0.83867455, grad/param norm = 1.5241e-01, time/batch = 15.1913s	
17254/33250 (epoch 25.946), train_loss = 0.97900661, grad/param norm = 1.7872e-01, time/batch = 18.6350s	
17255/33250 (epoch 25.947), train_loss = 0.80493177, grad/param norm = 1.7130e-01, time/batch = 15.2888s	
17256/33250 (epoch 25.949), train_loss = 0.94823457, grad/param norm = 1.6329e-01, time/batch = 18.5947s	
17257/33250 (epoch 25.950), train_loss = 0.92366758, grad/param norm = 1.5008e-01, time/batch = 16.4379s	
17258/33250 (epoch 25.952), train_loss = 0.86795284, grad/param norm = 1.7306e-01, time/batch = 16.9892s	
17259/33250 (epoch 25.953), train_loss = 0.93572333, grad/param norm = 1.5890e-01, time/batch = 16.1919s	
17260/33250 (epoch 25.955), train_loss = 0.95326305, grad/param norm = 1.6489e-01, time/batch = 16.5242s	
17261/33250 (epoch 25.956), train_loss = 0.90477538, grad/param norm = 1.9405e-01, time/batch = 16.0298s	
17262/33250 (epoch 25.958), train_loss = 0.80987514, grad/param norm = 1.5858e-01, time/batch = 18.4236s	
17263/33250 (epoch 25.959), train_loss = 0.82097556, grad/param norm = 1.6074e-01, time/batch = 17.1027s	
17264/33250 (epoch 25.961), train_loss = 1.08818303, grad/param norm = 1.8019e-01, time/batch = 18.9429s	
17265/33250 (epoch 25.962), train_loss = 0.86418289, grad/param norm = 1.6438e-01, time/batch = 17.5836s	
17266/33250 (epoch 25.964), train_loss = 1.04977850, grad/param norm = 1.8453e-01, time/batch = 18.5264s	
17267/33250 (epoch 25.965), train_loss = 0.93986263, grad/param norm = 1.9388e-01, time/batch = 16.1254s	
17268/33250 (epoch 25.967), train_loss = 0.91332085, grad/param norm = 1.5653e-01, time/batch = 16.8451s	
17269/33250 (epoch 25.968), train_loss = 1.03644821, grad/param norm = 1.5504e-01, time/batch = 16.6988s	
17270/33250 (epoch 25.970), train_loss = 1.14726332, grad/param norm = 1.9317e-01, time/batch = 16.5233s	
17271/33250 (epoch 25.971), train_loss = 1.02430905, grad/param norm = 1.9103e-01, time/batch = 17.3523s	
17272/33250 (epoch 25.973), train_loss = 0.84381210, grad/param norm = 1.4611e-01, time/batch = 17.1045s	
17273/33250 (epoch 25.974), train_loss = 0.96315014, grad/param norm = 1.7334e-01, time/batch = 17.7689s	
17274/33250 (epoch 25.976), train_loss = 0.86602223, grad/param norm = 1.7752e-01, time/batch = 17.2667s	
17275/33250 (epoch 25.977), train_loss = 0.85100737, grad/param norm = 1.5345e-01, time/batch = 17.5907s	
17276/33250 (epoch 25.979), train_loss = 0.92779233, grad/param norm = 1.8168e-01, time/batch = 17.7175s	
17277/33250 (epoch 25.980), train_loss = 0.91218871, grad/param norm = 1.5719e-01, time/batch = 16.8620s	
17278/33250 (epoch 25.982), train_loss = 0.82436487, grad/param norm = 1.4735e-01, time/batch = 17.3498s	
17279/33250 (epoch 25.983), train_loss = 0.92969840, grad/param norm = 1.8889e-01, time/batch = 16.1587s	
17280/33250 (epoch 25.985), train_loss = 0.84275963, grad/param norm = 1.5198e-01, time/batch = 15.8485s	
17281/33250 (epoch 25.986), train_loss = 0.95730286, grad/param norm = 1.6892e-01, time/batch = 15.9257s	
17282/33250 (epoch 25.988), train_loss = 0.96655175, grad/param norm = 1.6757e-01, time/batch = 15.6866s	
17283/33250 (epoch 25.989), train_loss = 0.97696460, grad/param norm = 1.6852e-01, time/batch = 18.6724s	
17284/33250 (epoch 25.991), train_loss = 0.91912663, grad/param norm = 1.5965e-01, time/batch = 18.1189s	
17285/33250 (epoch 25.992), train_loss = 0.86028579, grad/param norm = 1.6979e-01, time/batch = 18.3716s	
17286/33250 (epoch 25.994), train_loss = 0.87990734, grad/param norm = 1.5323e-01, time/batch = 17.4437s	
17287/33250 (epoch 25.995), train_loss = 0.84536911, grad/param norm = 1.6384e-01, time/batch = 17.7605s	
17288/33250 (epoch 25.997), train_loss = 0.65067737, grad/param norm = 1.3841e-01, time/batch = 15.5291s	
17289/33250 (epoch 25.998), train_loss = 0.91884723, grad/param norm = 1.5389e-01, time/batch = 16.5984s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
17290/33250 (epoch 26.000), train_loss = 0.89209633, grad/param norm = 1.4939e-01, time/batch = 18.1022s	
17291/33250 (epoch 26.002), train_loss = 1.06301746, grad/param norm = 1.6543e-01, time/batch = 17.2547s	
17292/33250 (epoch 26.003), train_loss = 0.96251100, grad/param norm = 1.7311e-01, time/batch = 17.9141s	
17293/33250 (epoch 26.005), train_loss = 0.74175618, grad/param norm = 1.5041e-01, time/batch = 17.2003s	
17294/33250 (epoch 26.006), train_loss = 0.74831854, grad/param norm = 1.3994e-01, time/batch = 18.8665s	
17295/33250 (epoch 26.008), train_loss = 0.99986086, grad/param norm = 1.6104e-01, time/batch = 16.5177s	
17296/33250 (epoch 26.009), train_loss = 1.03143192, grad/param norm = 1.7145e-01, time/batch = 16.6114s	
17297/33250 (epoch 26.011), train_loss = 0.81460906, grad/param norm = 1.6656e-01, time/batch = 15.0347s	
17298/33250 (epoch 26.012), train_loss = 0.90575807, grad/param norm = 1.9421e-01, time/batch = 15.2713s	
17299/33250 (epoch 26.014), train_loss = 1.00860021, grad/param norm = 1.8206e-01, time/batch = 15.6088s	
17300/33250 (epoch 26.015), train_loss = 0.87949593, grad/param norm = 1.5946e-01, time/batch = 17.9147s	
17301/33250 (epoch 26.017), train_loss = 0.92717127, grad/param norm = 2.1227e-01, time/batch = 16.2410s	
17302/33250 (epoch 26.018), train_loss = 0.73425690, grad/param norm = 1.5429e-01, time/batch = 15.2609s	
17303/33250 (epoch 26.020), train_loss = 0.89556373, grad/param norm = 1.4200e-01, time/batch = 18.7648s	
17304/33250 (epoch 26.021), train_loss = 0.93091982, grad/param norm = 1.5642e-01, time/batch = 17.9527s	
17305/33250 (epoch 26.023), train_loss = 0.76141502, grad/param norm = 2.1526e-01, time/batch = 18.2728s	
17306/33250 (epoch 26.024), train_loss = 0.99652356, grad/param norm = 1.7962e-01, time/batch = 15.5864s	
17307/33250 (epoch 26.026), train_loss = 0.89180381, grad/param norm = 1.5040e-01, time/batch = 18.1521s	
17308/33250 (epoch 26.027), train_loss = 0.91324048, grad/param norm = 1.6175e-01, time/batch = 17.0144s	
17309/33250 (epoch 26.029), train_loss = 0.87469541, grad/param norm = 1.5303e-01, time/batch = 15.6708s	
17310/33250 (epoch 26.030), train_loss = 0.87707912, grad/param norm = 1.7201e-01, time/batch = 17.4174s	
17311/33250 (epoch 26.032), train_loss = 1.07983948, grad/param norm = 1.9922e-01, time/batch = 17.5857s	
17312/33250 (epoch 26.033), train_loss = 0.84103222, grad/param norm = 1.5481e-01, time/batch = 16.7602s	
17313/33250 (epoch 26.035), train_loss = 0.88196045, grad/param norm = 1.8076e-01, time/batch = 15.6669s	
17314/33250 (epoch 26.036), train_loss = 0.94956779, grad/param norm = 1.8490e-01, time/batch = 16.1802s	
17315/33250 (epoch 26.038), train_loss = 0.89995987, grad/param norm = 1.4234e-01, time/batch = 19.6858s	
17316/33250 (epoch 26.039), train_loss = 0.80265158, grad/param norm = 1.4876e-01, time/batch = 16.6984s	
17317/33250 (epoch 26.041), train_loss = 0.90530957, grad/param norm = 1.8741e-01, time/batch = 17.3626s	
17318/33250 (epoch 26.042), train_loss = 0.74088971, grad/param norm = 1.3866e-01, time/batch = 17.1857s	
17319/33250 (epoch 26.044), train_loss = 1.00768131, grad/param norm = 1.6094e-01, time/batch = 17.5047s	
17320/33250 (epoch 26.045), train_loss = 0.98715239, grad/param norm = 1.6944e-01, time/batch = 15.6761s	
17321/33250 (epoch 26.047), train_loss = 0.89641460, grad/param norm = 1.8251e-01, time/batch = 17.5149s	
17322/33250 (epoch 26.048), train_loss = 1.01388629, grad/param norm = 1.8626e-01, time/batch = 15.7843s	
17323/33250 (epoch 26.050), train_loss = 0.88513156, grad/param norm = 1.4401e-01, time/batch = 15.6142s	
17324/33250 (epoch 26.051), train_loss = 0.89010499, grad/param norm = 1.4752e-01, time/batch = 15.6289s	
17325/33250 (epoch 26.053), train_loss = 0.90854624, grad/param norm = 1.7742e-01, time/batch = 17.1945s	
17326/33250 (epoch 26.054), train_loss = 0.77575965, grad/param norm = 1.4036e-01, time/batch = 17.6943s	
17327/33250 (epoch 26.056), train_loss = 0.81387705, grad/param norm = 1.4966e-01, time/batch = 15.5912s	
17328/33250 (epoch 26.057), train_loss = 0.98113171, grad/param norm = 1.5444e-01, time/batch = 16.5032s	
17329/33250 (epoch 26.059), train_loss = 0.85565808, grad/param norm = 1.4312e-01, time/batch = 17.1062s	
17330/33250 (epoch 26.060), train_loss = 0.88378273, grad/param norm = 1.5766e-01, time/batch = 16.9298s	
17331/33250 (epoch 26.062), train_loss = 0.98519814, grad/param norm = 1.8111e-01, time/batch = 16.3237s	
17332/33250 (epoch 26.063), train_loss = 1.03449683, grad/param norm = 1.5301e-01, time/batch = 17.4992s	
17333/33250 (epoch 26.065), train_loss = 0.90283488, grad/param norm = 1.5311e-01, time/batch = 16.8433s	
17334/33250 (epoch 26.066), train_loss = 0.93349423, grad/param norm = 1.6910e-01, time/batch = 15.6736s	
17335/33250 (epoch 26.068), train_loss = 0.84844839, grad/param norm = 1.7525e-01, time/batch = 16.7846s	
17336/33250 (epoch 26.069), train_loss = 0.88560132, grad/param norm = 1.4306e-01, time/batch = 17.4378s	
17337/33250 (epoch 26.071), train_loss = 0.81103423, grad/param norm = 1.4889e-01, time/batch = 18.3701s	
17338/33250 (epoch 26.072), train_loss = 0.82760158, grad/param norm = 1.4577e-01, time/batch = 15.6291s	
17339/33250 (epoch 26.074), train_loss = 0.93684660, grad/param norm = 1.5963e-01, time/batch = 15.9545s	
17340/33250 (epoch 26.075), train_loss = 0.83257802, grad/param norm = 1.5089e-01, time/batch = 17.2589s	
17341/33250 (epoch 26.077), train_loss = 0.89561853, grad/param norm = 1.7626e-01, time/batch = 15.5013s	
17342/33250 (epoch 26.078), train_loss = 0.90788226, grad/param norm = 1.5710e-01, time/batch = 15.7811s	
17343/33250 (epoch 26.080), train_loss = 0.90131590, grad/param norm = 1.8886e-01, time/batch = 15.7667s	
17344/33250 (epoch 26.081), train_loss = 0.93405803, grad/param norm = 1.5503e-01, time/batch = 18.0072s	
17345/33250 (epoch 26.083), train_loss = 0.99326855, grad/param norm = 1.5958e-01, time/batch = 33.9109s	
17346/33250 (epoch 26.084), train_loss = 0.88298625, grad/param norm = 1.5703e-01, time/batch = 16.9538s	
17347/33250 (epoch 26.086), train_loss = 0.87745597, grad/param norm = 1.4063e-01, time/batch = 15.3526s	
17348/33250 (epoch 26.087), train_loss = 0.77837293, grad/param norm = 1.5545e-01, time/batch = 16.6662s	
17349/33250 (epoch 26.089), train_loss = 0.91539657, grad/param norm = 1.4981e-01, time/batch = 16.0177s	
17350/33250 (epoch 26.090), train_loss = 0.92331456, grad/param norm = 1.6345e-01, time/batch = 15.5784s	
17351/33250 (epoch 26.092), train_loss = 0.85005548, grad/param norm = 1.3933e-01, time/batch = 15.6710s	
17352/33250 (epoch 26.093), train_loss = 0.88759521, grad/param norm = 1.4844e-01, time/batch = 18.1805s	
17353/33250 (epoch 26.095), train_loss = 0.86699078, grad/param norm = 1.7204e-01, time/batch = 18.6180s	
17354/33250 (epoch 26.096), train_loss = 0.73746011, grad/param norm = 1.5487e-01, time/batch = 17.1297s	
17355/33250 (epoch 26.098), train_loss = 0.76781422, grad/param norm = 1.6884e-01, time/batch = 18.5194s	
17356/33250 (epoch 26.099), train_loss = 0.69092597, grad/param norm = 1.4947e-01, time/batch = 17.1286s	
17357/33250 (epoch 26.101), train_loss = 0.89032579, grad/param norm = 1.5733e-01, time/batch = 16.2658s	
17358/33250 (epoch 26.102), train_loss = 0.80476794, grad/param norm = 1.4078e-01, time/batch = 15.3486s	
17359/33250 (epoch 26.104), train_loss = 0.67595858, grad/param norm = 1.2652e-01, time/batch = 18.4318s	
17360/33250 (epoch 26.105), train_loss = 0.81931973, grad/param norm = 1.4866e-01, time/batch = 16.1689s	
17361/33250 (epoch 26.107), train_loss = 0.75975517, grad/param norm = 1.3792e-01, time/batch = 16.5956s	
17362/33250 (epoch 26.108), train_loss = 0.88463384, grad/param norm = 1.6458e-01, time/batch = 16.6813s	
17363/33250 (epoch 26.110), train_loss = 0.72677069, grad/param norm = 1.4384e-01, time/batch = 17.2734s	
17364/33250 (epoch 26.111), train_loss = 0.85410900, grad/param norm = 1.5029e-01, time/batch = 17.8757s	
17365/33250 (epoch 26.113), train_loss = 0.82735574, grad/param norm = 1.4956e-01, time/batch = 16.1152s	
17366/33250 (epoch 26.114), train_loss = 0.78536897, grad/param norm = 1.6016e-01, time/batch = 16.7679s	
17367/33250 (epoch 26.116), train_loss = 0.84853223, grad/param norm = 1.6710e-01, time/batch = 16.6857s	
17368/33250 (epoch 26.117), train_loss = 0.83252842, grad/param norm = 1.5190e-01, time/batch = 17.3462s	
17369/33250 (epoch 26.119), train_loss = 0.83959065, grad/param norm = 1.8419e-01, time/batch = 16.4410s	
17370/33250 (epoch 26.120), train_loss = 0.67266869, grad/param norm = 1.3448e-01, time/batch = 15.7758s	
17371/33250 (epoch 26.122), train_loss = 0.96014710, grad/param norm = 1.6160e-01, time/batch = 15.4530s	
17372/33250 (epoch 26.123), train_loss = 0.85256148, grad/param norm = 1.9942e-01, time/batch = 17.9171s	
17373/33250 (epoch 26.125), train_loss = 0.73192900, grad/param norm = 1.6215e-01, time/batch = 17.2563s	
17374/33250 (epoch 26.126), train_loss = 0.85311767, grad/param norm = 1.6142e-01, time/batch = 15.6836s	
17375/33250 (epoch 26.128), train_loss = 0.81765827, grad/param norm = 1.4030e-01, time/batch = 17.9990s	
17376/33250 (epoch 26.129), train_loss = 0.87235811, grad/param norm = 1.4837e-01, time/batch = 16.6307s	
17377/33250 (epoch 26.131), train_loss = 0.82886710, grad/param norm = 1.5358e-01, time/batch = 18.0277s	
17378/33250 (epoch 26.132), train_loss = 0.85439639, grad/param norm = 1.7749e-01, time/batch = 17.1029s	
17379/33250 (epoch 26.134), train_loss = 0.85278206, grad/param norm = 1.6877e-01, time/batch = 15.6816s	
17380/33250 (epoch 26.135), train_loss = 0.85882636, grad/param norm = 1.4824e-01, time/batch = 15.8639s	
17381/33250 (epoch 26.137), train_loss = 0.76969087, grad/param norm = 1.5504e-01, time/batch = 16.2726s	
17382/33250 (epoch 26.138), train_loss = 0.81171134, grad/param norm = 1.5614e-01, time/batch = 16.4433s	
17383/33250 (epoch 26.140), train_loss = 0.69737000, grad/param norm = 1.5383e-01, time/batch = 16.4469s	
17384/33250 (epoch 26.141), train_loss = 0.97242262, grad/param norm = 2.1496e-01, time/batch = 15.6131s	
17385/33250 (epoch 26.143), train_loss = 0.70970836, grad/param norm = 1.7329e-01, time/batch = 18.1244s	
17386/33250 (epoch 26.144), train_loss = 0.82134606, grad/param norm = 1.4881e-01, time/batch = 17.2008s	
17387/33250 (epoch 26.146), train_loss = 0.83282646, grad/param norm = 1.4650e-01, time/batch = 15.5061s	
17388/33250 (epoch 26.147), train_loss = 0.84568877, grad/param norm = 1.6070e-01, time/batch = 18.2555s	
17389/33250 (epoch 26.149), train_loss = 0.79005395, grad/param norm = 1.4087e-01, time/batch = 18.0913s	
17390/33250 (epoch 26.150), train_loss = 0.76965990, grad/param norm = 1.5431e-01, time/batch = 15.6728s	
17391/33250 (epoch 26.152), train_loss = 0.72499572, grad/param norm = 1.4848e-01, time/batch = 15.5798s	
17392/33250 (epoch 26.153), train_loss = 0.99285339, grad/param norm = 1.7561e-01, time/batch = 17.9357s	
17393/33250 (epoch 26.155), train_loss = 0.83670129, grad/param norm = 1.8925e-01, time/batch = 17.1090s	
17394/33250 (epoch 26.156), train_loss = 1.05726246, grad/param norm = 1.5469e-01, time/batch = 18.8760s	
17395/33250 (epoch 26.158), train_loss = 1.00873362, grad/param norm = 1.6657e-01, time/batch = 16.9638s	
17396/33250 (epoch 26.159), train_loss = 0.83586261, grad/param norm = 1.5017e-01, time/batch = 18.8369s	
17397/33250 (epoch 26.161), train_loss = 0.91469665, grad/param norm = 1.6780e-01, time/batch = 15.9285s	
17398/33250 (epoch 26.162), train_loss = 0.76498153, grad/param norm = 1.4254e-01, time/batch = 15.9511s	
17399/33250 (epoch 26.164), train_loss = 0.83041717, grad/param norm = 1.5028e-01, time/batch = 16.5341s	
17400/33250 (epoch 26.165), train_loss = 0.92015640, grad/param norm = 1.6364e-01, time/batch = 17.0211s	
17401/33250 (epoch 26.167), train_loss = 1.01830625, grad/param norm = 1.8297e-01, time/batch = 15.7668s	
17402/33250 (epoch 26.168), train_loss = 0.72739157, grad/param norm = 1.2984e-01, time/batch = 15.2688s	
17403/33250 (epoch 26.170), train_loss = 0.82762180, grad/param norm = 1.7709e-01, time/batch = 17.1061s	
17404/33250 (epoch 26.171), train_loss = 0.85332433, grad/param norm = 1.5336e-01, time/batch = 16.9407s	
17405/33250 (epoch 26.173), train_loss = 0.81353002, grad/param norm = 1.6124e-01, time/batch = 18.7712s	
17406/33250 (epoch 26.174), train_loss = 0.87867862, grad/param norm = 1.6335e-01, time/batch = 15.3220s	
17407/33250 (epoch 26.176), train_loss = 0.83836457, grad/param norm = 1.6897e-01, time/batch = 18.0800s	
17408/33250 (epoch 26.177), train_loss = 0.83413268, grad/param norm = 1.6075e-01, time/batch = 15.5174s	
17409/33250 (epoch 26.179), train_loss = 0.78240986, grad/param norm = 1.5372e-01, time/batch = 16.7659s	
17410/33250 (epoch 26.180), train_loss = 0.70595730, grad/param norm = 1.4884e-01, time/batch = 17.5132s	
17411/33250 (epoch 26.182), train_loss = 0.80360040, grad/param norm = 1.5742e-01, time/batch = 15.7849s	
17412/33250 (epoch 26.183), train_loss = 0.97816120, grad/param norm = 1.7201e-01, time/batch = 15.7720s	
17413/33250 (epoch 26.185), train_loss = 0.91466867, grad/param norm = 2.1533e-01, time/batch = 18.6993s	
17414/33250 (epoch 26.186), train_loss = 0.89009957, grad/param norm = 1.6794e-01, time/batch = 18.8569s	
17415/33250 (epoch 26.188), train_loss = 0.96763465, grad/param norm = 1.8457e-01, time/batch = 18.1147s	
17416/33250 (epoch 26.189), train_loss = 0.69843564, grad/param norm = 1.6420e-01, time/batch = 16.7766s	
17417/33250 (epoch 26.191), train_loss = 0.78704784, grad/param norm = 1.5175e-01, time/batch = 16.2006s	
17418/33250 (epoch 26.192), train_loss = 0.83282206, grad/param norm = 1.5461e-01, time/batch = 16.0124s	
17419/33250 (epoch 26.194), train_loss = 0.85790540, grad/param norm = 1.6579e-01, time/batch = 16.4942s	
17420/33250 (epoch 26.195), train_loss = 1.03677416, grad/param norm = 1.7752e-01, time/batch = 16.3601s	
17421/33250 (epoch 26.197), train_loss = 0.80390590, grad/param norm = 1.4778e-01, time/batch = 17.9999s	
17422/33250 (epoch 26.198), train_loss = 0.98657568, grad/param norm = 1.6231e-01, time/batch = 15.9545s	
17423/33250 (epoch 26.200), train_loss = 0.87228852, grad/param norm = 1.5092e-01, time/batch = 20.0237s	
17424/33250 (epoch 26.202), train_loss = 0.80612097, grad/param norm = 1.4010e-01, time/batch = 19.6910s	
17425/33250 (epoch 26.203), train_loss = 0.78976378, grad/param norm = 1.6625e-01, time/batch = 16.7096s	
17426/33250 (epoch 26.205), train_loss = 0.89931809, grad/param norm = 1.5644e-01, time/batch = 18.3334s	
17427/33250 (epoch 26.206), train_loss = 0.91978528, grad/param norm = 1.5818e-01, time/batch = 16.7445s	
17428/33250 (epoch 26.208), train_loss = 0.97705264, grad/param norm = 1.6331e-01, time/batch = 16.1882s	
17429/33250 (epoch 26.209), train_loss = 0.78308580, grad/param norm = 1.3896e-01, time/batch = 15.4292s	
17430/33250 (epoch 26.211), train_loss = 0.91300242, grad/param norm = 1.9632e-01, time/batch = 17.8357s	
17431/33250 (epoch 26.212), train_loss = 1.03961133, grad/param norm = 1.6475e-01, time/batch = 17.1035s	
17432/33250 (epoch 26.214), train_loss = 0.88761647, grad/param norm = 1.5557e-01, time/batch = 18.0106s	
17433/33250 (epoch 26.215), train_loss = 0.99322380, grad/param norm = 2.0047e-01, time/batch = 18.6010s	
17434/33250 (epoch 26.217), train_loss = 0.98349128, grad/param norm = 1.7148e-01, time/batch = 18.0513s	
17435/33250 (epoch 26.218), train_loss = 0.97067105, grad/param norm = 1.6114e-01, time/batch = 17.6018s	
17436/33250 (epoch 26.220), train_loss = 0.90318257, grad/param norm = 1.8633e-01, time/batch = 16.4265s	
17437/33250 (epoch 26.221), train_loss = 1.06230788, grad/param norm = 1.9665e-01, time/batch = 17.5607s	
17438/33250 (epoch 26.223), train_loss = 0.87308406, grad/param norm = 1.4578e-01, time/batch = 17.4338s	
17439/33250 (epoch 26.224), train_loss = 0.92469283, grad/param norm = 1.7053e-01, time/batch = 15.0949s	
17440/33250 (epoch 26.226), train_loss = 1.01732656, grad/param norm = 1.8381e-01, time/batch = 16.4386s	
17441/33250 (epoch 26.227), train_loss = 0.91617273, grad/param norm = 1.6326e-01, time/batch = 17.5184s	
17442/33250 (epoch 26.229), train_loss = 0.87905604, grad/param norm = 1.4866e-01, time/batch = 17.2661s	
17443/33250 (epoch 26.230), train_loss = 0.89070107, grad/param norm = 1.6713e-01, time/batch = 19.4403s	
17444/33250 (epoch 26.232), train_loss = 0.82823085, grad/param norm = 1.4160e-01, time/batch = 17.9710s	
17445/33250 (epoch 26.233), train_loss = 0.80943477, grad/param norm = 1.5320e-01, time/batch = 16.6109s	
17446/33250 (epoch 26.235), train_loss = 1.00606662, grad/param norm = 1.7041e-01, time/batch = 16.2734s	
17447/33250 (epoch 26.236), train_loss = 0.81827349, grad/param norm = 1.5498e-01, time/batch = 17.3536s	
17448/33250 (epoch 26.238), train_loss = 0.98620535, grad/param norm = 1.6810e-01, time/batch = 18.3350s	
17449/33250 (epoch 26.239), train_loss = 1.00656059, grad/param norm = 1.9849e-01, time/batch = 17.0818s	
17450/33250 (epoch 26.241), train_loss = 0.99104033, grad/param norm = 1.9697e-01, time/batch = 16.7713s	
17451/33250 (epoch 26.242), train_loss = 0.97185190, grad/param norm = 1.6781e-01, time/batch = 17.2031s	
17452/33250 (epoch 26.244), train_loss = 0.95950112, grad/param norm = 2.0815e-01, time/batch = 16.7895s	
17453/33250 (epoch 26.245), train_loss = 0.91274276, grad/param norm = 1.6828e-01, time/batch = 17.6944s	
17454/33250 (epoch 26.247), train_loss = 0.89066357, grad/param norm = 1.6361e-01, time/batch = 16.2689s	
17455/33250 (epoch 26.248), train_loss = 1.06806532, grad/param norm = 1.8022e-01, time/batch = 16.2529s	
17456/33250 (epoch 26.250), train_loss = 0.96914304, grad/param norm = 1.5197e-01, time/batch = 15.0251s	
17457/33250 (epoch 26.251), train_loss = 0.85610972, grad/param norm = 1.4187e-01, time/batch = 15.2766s	
17458/33250 (epoch 26.253), train_loss = 0.83197362, grad/param norm = 1.3273e-01, time/batch = 16.9278s	
17459/33250 (epoch 26.254), train_loss = 0.83045705, grad/param norm = 1.6692e-01, time/batch = 15.7647s	
17460/33250 (epoch 26.256), train_loss = 0.89947509, grad/param norm = 1.5424e-01, time/batch = 15.9296s	
17461/33250 (epoch 26.257), train_loss = 1.00818338, grad/param norm = 1.8609e-01, time/batch = 16.0312s	
17462/33250 (epoch 26.259), train_loss = 0.93134921, grad/param norm = 1.6376e-01, time/batch = 16.4511s	
17463/33250 (epoch 26.260), train_loss = 0.75074700, grad/param norm = 1.5242e-01, time/batch = 17.9940s	
17464/33250 (epoch 26.262), train_loss = 0.91330213, grad/param norm = 1.5336e-01, time/batch = 16.1152s	
17465/33250 (epoch 26.263), train_loss = 0.76786593, grad/param norm = 1.4666e-01, time/batch = 17.7783s	
17466/33250 (epoch 26.265), train_loss = 0.95583124, grad/param norm = 1.7939e-01, time/batch = 18.5902s	
17467/33250 (epoch 26.266), train_loss = 0.85614603, grad/param norm = 1.5643e-01, time/batch = 15.5955s	
17468/33250 (epoch 26.268), train_loss = 0.79674481, grad/param norm = 1.5457e-01, time/batch = 15.0906s	
17469/33250 (epoch 26.269), train_loss = 0.73518655, grad/param norm = 1.4330e-01, time/batch = 16.5293s	
17470/33250 (epoch 26.271), train_loss = 0.87452189, grad/param norm = 1.4172e-01, time/batch = 16.2748s	
17471/33250 (epoch 26.272), train_loss = 0.79360793, grad/param norm = 1.4022e-01, time/batch = 16.9301s	
17472/33250 (epoch 26.274), train_loss = 0.68063627, grad/param norm = 1.4150e-01, time/batch = 17.8323s	
17473/33250 (epoch 26.275), train_loss = 0.79796350, grad/param norm = 1.2290e-01, time/batch = 18.6098s	
17474/33250 (epoch 26.277), train_loss = 0.68905488, grad/param norm = 1.3677e-01, time/batch = 16.7104s	
17475/33250 (epoch 26.278), train_loss = 0.79996650, grad/param norm = 1.5054e-01, time/batch = 16.7720s	
17476/33250 (epoch 26.280), train_loss = 0.76643835, grad/param norm = 1.3882e-01, time/batch = 16.8611s	
17477/33250 (epoch 26.281), train_loss = 0.90379386, grad/param norm = 1.6766e-01, time/batch = 17.8304s	
17478/33250 (epoch 26.283), train_loss = 0.92716514, grad/param norm = 2.3012e-01, time/batch = 15.2825s	
17479/33250 (epoch 26.284), train_loss = 0.81531941, grad/param norm = 2.0287e-01, time/batch = 16.3631s	
17480/33250 (epoch 26.286), train_loss = 0.92953149, grad/param norm = 1.7723e-01, time/batch = 15.4566s	
17481/33250 (epoch 26.287), train_loss = 0.75620494, grad/param norm = 1.4193e-01, time/batch = 17.2707s	
17482/33250 (epoch 26.289), train_loss = 0.70090189, grad/param norm = 1.6873e-01, time/batch = 18.1930s	
17483/33250 (epoch 26.290), train_loss = 0.86626741, grad/param norm = 1.7124e-01, time/batch = 16.6142s	
17484/33250 (epoch 26.292), train_loss = 0.94483881, grad/param norm = 2.0939e-01, time/batch = 18.7745s	
17485/33250 (epoch 26.293), train_loss = 0.97220090, grad/param norm = 1.6450e-01, time/batch = 15.8298s	
17486/33250 (epoch 26.295), train_loss = 0.96307576, grad/param norm = 1.8181e-01, time/batch = 16.1107s	
17487/33250 (epoch 26.296), train_loss = 0.87934017, grad/param norm = 1.4631e-01, time/batch = 15.8711s	
17488/33250 (epoch 26.298), train_loss = 0.73210610, grad/param norm = 1.4841e-01, time/batch = 16.8457s	
17489/33250 (epoch 26.299), train_loss = 0.69582704, grad/param norm = 1.2983e-01, time/batch = 15.4453s	
17490/33250 (epoch 26.301), train_loss = 0.95181357, grad/param norm = 1.5652e-01, time/batch = 15.6779s	
17491/33250 (epoch 26.302), train_loss = 0.91610509, grad/param norm = 1.5460e-01, time/batch = 17.8530s	
17492/33250 (epoch 26.304), train_loss = 0.79795234, grad/param norm = 1.4969e-01, time/batch = 16.2081s	
17493/33250 (epoch 26.305), train_loss = 0.83102306, grad/param norm = 1.5966e-01, time/batch = 17.7881s	
17494/33250 (epoch 26.307), train_loss = 0.91960884, grad/param norm = 1.4897e-01, time/batch = 17.9541s	
17495/33250 (epoch 26.308), train_loss = 0.98988164, grad/param norm = 2.0123e-01, time/batch = 15.8409s	
17496/33250 (epoch 26.310), train_loss = 0.83310750, grad/param norm = 1.7233e-01, time/batch = 16.0306s	
17497/33250 (epoch 26.311), train_loss = 1.00433544, grad/param norm = 1.8077e-01, time/batch = 17.1048s	
17498/33250 (epoch 26.313), train_loss = 0.75193919, grad/param norm = 1.6279e-01, time/batch = 15.5814s	
17499/33250 (epoch 26.314), train_loss = 0.89494936, grad/param norm = 1.6787e-01, time/batch = 16.8449s	
17500/33250 (epoch 26.316), train_loss = 1.04140743, grad/param norm = 1.6827e-01, time/batch = 15.7834s	
17501/33250 (epoch 26.317), train_loss = 0.78412489, grad/param norm = 1.4449e-01, time/batch = 18.4352s	
17502/33250 (epoch 26.319), train_loss = 0.93048240, grad/param norm = 1.9797e-01, time/batch = 18.4471s	
17503/33250 (epoch 26.320), train_loss = 0.95973653, grad/param norm = 2.0265e-01, time/batch = 18.0172s	
17504/33250 (epoch 26.322), train_loss = 0.99382111, grad/param norm = 1.7593e-01, time/batch = 16.9519s	
17505/33250 (epoch 26.323), train_loss = 1.06484514, grad/param norm = 2.2909e-01, time/batch = 16.7772s	
17506/33250 (epoch 26.325), train_loss = 0.88279546, grad/param norm = 1.9120e-01, time/batch = 16.2714s	
17507/33250 (epoch 26.326), train_loss = 1.04249097, grad/param norm = 1.8208e-01, time/batch = 15.3462s	
17508/33250 (epoch 26.328), train_loss = 0.85994935, grad/param norm = 1.5429e-01, time/batch = 16.2759s	
17509/33250 (epoch 26.329), train_loss = 0.88649416, grad/param norm = 1.7031e-01, time/batch = 17.2612s	
17510/33250 (epoch 26.331), train_loss = 0.85861293, grad/param norm = 1.6371e-01, time/batch = 16.2665s	
17511/33250 (epoch 26.332), train_loss = 0.85993830, grad/param norm = 1.4278e-01, time/batch = 16.1957s	
17512/33250 (epoch 26.334), train_loss = 1.02709010, grad/param norm = 1.6538e-01, time/batch = 18.9516s	
17513/33250 (epoch 26.335), train_loss = 0.65292352, grad/param norm = 1.4525e-01, time/batch = 18.6950s	
17514/33250 (epoch 26.337), train_loss = 0.93901174, grad/param norm = 1.5926e-01, time/batch = 19.7619s	
17515/33250 (epoch 26.338), train_loss = 0.99508835, grad/param norm = 1.5718e-01, time/batch = 17.1710s	
17516/33250 (epoch 26.340), train_loss = 0.88373428, grad/param norm = 1.5409e-01, time/batch = 17.1010s	
17517/33250 (epoch 26.341), train_loss = 0.82557601, grad/param norm = 1.6050e-01, time/batch = 17.3352s	
17518/33250 (epoch 26.343), train_loss = 0.83108499, grad/param norm = 1.5883e-01, time/batch = 17.3478s	
17519/33250 (epoch 26.344), train_loss = 0.86099505, grad/param norm = 1.4845e-01, time/batch = 18.9107s	
17520/33250 (epoch 26.346), train_loss = 0.77158198, grad/param norm = 1.4654e-01, time/batch = 16.0227s	
17521/33250 (epoch 26.347), train_loss = 1.07250939, grad/param norm = 2.0782e-01, time/batch = 18.2801s	
17522/33250 (epoch 26.349), train_loss = 0.82196662, grad/param norm = 1.6218e-01, time/batch = 17.5457s	
17523/33250 (epoch 26.350), train_loss = 0.85331593, grad/param norm = 1.6464e-01, time/batch = 15.6665s	
17524/33250 (epoch 26.352), train_loss = 0.77778745, grad/param norm = 1.4581e-01, time/batch = 17.0861s	
17525/33250 (epoch 26.353), train_loss = 0.84580950, grad/param norm = 1.4810e-01, time/batch = 15.2726s	
17526/33250 (epoch 26.355), train_loss = 0.83570812, grad/param norm = 1.8408e-01, time/batch = 18.0092s	
17527/33250 (epoch 26.356), train_loss = 0.77479834, grad/param norm = 1.5303e-01, time/batch = 15.2814s	
17528/33250 (epoch 26.358), train_loss = 0.83181356, grad/param norm = 1.4081e-01, time/batch = 17.4297s	
17529/33250 (epoch 26.359), train_loss = 0.81834146, grad/param norm = 1.5348e-01, time/batch = 16.1955s	
17530/33250 (epoch 26.361), train_loss = 0.99424518, grad/param norm = 1.7447e-01, time/batch = 17.5247s	
17531/33250 (epoch 26.362), train_loss = 0.89847009, grad/param norm = 1.6419e-01, time/batch = 17.7087s	
17532/33250 (epoch 26.364), train_loss = 0.95163085, grad/param norm = 1.7103e-01, time/batch = 18.9538s	
17533/33250 (epoch 26.365), train_loss = 0.88742825, grad/param norm = 1.6195e-01, time/batch = 18.6910s	
17534/33250 (epoch 26.367), train_loss = 0.88660829, grad/param norm = 1.5433e-01, time/batch = 15.9257s	
17535/33250 (epoch 26.368), train_loss = 0.86812501, grad/param norm = 1.6144e-01, time/batch = 15.6955s	
17536/33250 (epoch 26.370), train_loss = 0.77595721, grad/param norm = 1.3852e-01, time/batch = 17.2668s	
17537/33250 (epoch 26.371), train_loss = 0.99512805, grad/param norm = 1.8112e-01, time/batch = 17.1732s	
17538/33250 (epoch 26.373), train_loss = 0.82936615, grad/param norm = 1.3558e-01, time/batch = 17.0944s	
17539/33250 (epoch 26.374), train_loss = 0.94685978, grad/param norm = 2.6505e-01, time/batch = 16.6959s	
17540/33250 (epoch 26.376), train_loss = 0.84485909, grad/param norm = 1.5385e-01, time/batch = 18.5850s	
17541/33250 (epoch 26.377), train_loss = 0.78450924, grad/param norm = 1.8368e-01, time/batch = 17.1912s	
17542/33250 (epoch 26.379), train_loss = 0.85761734, grad/param norm = 1.7315e-01, time/batch = 17.1088s	
17543/33250 (epoch 26.380), train_loss = 0.89545772, grad/param norm = 1.8511e-01, time/batch = 18.2830s	
17544/33250 (epoch 26.382), train_loss = 0.90974826, grad/param norm = 1.7609e-01, time/batch = 17.0902s	
17545/33250 (epoch 26.383), train_loss = 0.77947205, grad/param norm = 1.5226e-01, time/batch = 17.5111s	
17546/33250 (epoch 26.385), train_loss = 0.75265699, grad/param norm = 1.6409e-01, time/batch = 16.6751s	
17547/33250 (epoch 26.386), train_loss = 0.78484733, grad/param norm = 1.6081e-01, time/batch = 15.5084s	
17548/33250 (epoch 26.388), train_loss = 0.79208756, grad/param norm = 1.4794e-01, time/batch = 15.6137s	
17549/33250 (epoch 26.389), train_loss = 0.85433280, grad/param norm = 1.9836e-01, time/batch = 16.9416s	
17550/33250 (epoch 26.391), train_loss = 0.92205802, grad/param norm = 1.7502e-01, time/batch = 16.7777s	
17551/33250 (epoch 26.392), train_loss = 0.93459238, grad/param norm = 1.6455e-01, time/batch = 16.2727s	
17552/33250 (epoch 26.394), train_loss = 0.96478408, grad/param norm = 1.8205e-01, time/batch = 18.2904s	
17553/33250 (epoch 26.395), train_loss = 0.96004572, grad/param norm = 1.5737e-01, time/batch = 17.9608s	
17554/33250 (epoch 26.397), train_loss = 0.98596215, grad/param norm = 1.6785e-01, time/batch = 17.1806s	
17555/33250 (epoch 26.398), train_loss = 0.82526085, grad/param norm = 1.4734e-01, time/batch = 30.1508s	
17556/33250 (epoch 26.400), train_loss = 0.77361246, grad/param norm = 1.3106e-01, time/batch = 17.2689s	
17557/33250 (epoch 26.402), train_loss = 0.74842953, grad/param norm = 1.6252e-01, time/batch = 16.6770s	
17558/33250 (epoch 26.403), train_loss = 0.86148532, grad/param norm = 1.7140e-01, time/batch = 16.6657s	
17559/33250 (epoch 26.405), train_loss = 0.80077385, grad/param norm = 1.3879e-01, time/batch = 16.5036s	
17560/33250 (epoch 26.406), train_loss = 0.87939179, grad/param norm = 1.6360e-01, time/batch = 18.5276s	
17561/33250 (epoch 26.408), train_loss = 1.03001143, grad/param norm = 1.7795e-01, time/batch = 15.1845s	
17562/33250 (epoch 26.409), train_loss = 0.94246691, grad/param norm = 1.9872e-01, time/batch = 14.9482s	
17563/33250 (epoch 26.411), train_loss = 0.65469513, grad/param norm = 1.3773e-01, time/batch = 15.0225s	
17564/33250 (epoch 26.412), train_loss = 0.73454736, grad/param norm = 1.5211e-01, time/batch = 18.7509s	
17565/33250 (epoch 26.414), train_loss = 0.91596255, grad/param norm = 1.6110e-01, time/batch = 15.2635s	
17566/33250 (epoch 26.415), train_loss = 0.96789235, grad/param norm = 1.8656e-01, time/batch = 16.0888s	
17567/33250 (epoch 26.417), train_loss = 0.95925555, grad/param norm = 1.6968e-01, time/batch = 16.3708s	
17568/33250 (epoch 26.418), train_loss = 1.12173352, grad/param norm = 2.0418e-01, time/batch = 16.7658s	
17569/33250 (epoch 26.420), train_loss = 0.98692732, grad/param norm = 1.5926e-01, time/batch = 16.7634s	
17570/33250 (epoch 26.421), train_loss = 0.80341930, grad/param norm = 1.4238e-01, time/batch = 18.2695s	
17571/33250 (epoch 26.423), train_loss = 0.92070758, grad/param norm = 1.9256e-01, time/batch = 18.2090s	
17572/33250 (epoch 26.424), train_loss = 1.01422301, grad/param norm = 2.4682e-01, time/batch = 15.7690s	
17573/33250 (epoch 26.426), train_loss = 0.82547066, grad/param norm = 1.4656e-01, time/batch = 16.7069s	
17574/33250 (epoch 26.427), train_loss = 0.83348728, grad/param norm = 1.6619e-01, time/batch = 17.3572s	
17575/33250 (epoch 26.429), train_loss = 0.91516212, grad/param norm = 1.8447e-01, time/batch = 17.0024s	
17576/33250 (epoch 26.430), train_loss = 0.84261968, grad/param norm = 1.8674e-01, time/batch = 16.8560s	
17577/33250 (epoch 26.432), train_loss = 0.93042824, grad/param norm = 1.5096e-01, time/batch = 16.4154s	
17578/33250 (epoch 26.433), train_loss = 0.82471353, grad/param norm = 1.5563e-01, time/batch = 18.1780s	
17579/33250 (epoch 26.435), train_loss = 0.98136441, grad/param norm = 1.9141e-01, time/batch = 15.8546s	
17580/33250 (epoch 26.436), train_loss = 0.81223309, grad/param norm = 1.7552e-01, time/batch = 17.0849s	
17581/33250 (epoch 26.438), train_loss = 0.96495455, grad/param norm = 1.6342e-01, time/batch = 17.3556s	
17582/33250 (epoch 26.439), train_loss = 0.89051809, grad/param norm = 1.5434e-01, time/batch = 18.2830s	
17583/33250 (epoch 26.441), train_loss = 0.86215100, grad/param norm = 1.5746e-01, time/batch = 17.8633s	
17584/33250 (epoch 26.442), train_loss = 0.80411478, grad/param norm = 1.6852e-01, time/batch = 16.6950s	
17585/33250 (epoch 26.444), train_loss = 0.84111167, grad/param norm = 1.5211e-01, time/batch = 18.7511s	
17586/33250 (epoch 26.445), train_loss = 0.89328299, grad/param norm = 1.4812e-01, time/batch = 15.8447s	
17587/33250 (epoch 26.447), train_loss = 0.82701055, grad/param norm = 1.5612e-01, time/batch = 17.5250s	
17588/33250 (epoch 26.448), train_loss = 0.89145685, grad/param norm = 1.4109e-01, time/batch = 15.7815s	
17589/33250 (epoch 26.450), train_loss = 1.01886587, grad/param norm = 1.8322e-01, time/batch = 15.3352s	
17590/33250 (epoch 26.451), train_loss = 0.92501659, grad/param norm = 1.7172e-01, time/batch = 17.8486s	
17591/33250 (epoch 26.453), train_loss = 0.78914167, grad/param norm = 1.4416e-01, time/batch = 18.0479s	
17592/33250 (epoch 26.454), train_loss = 1.00480129, grad/param norm = 1.6726e-01, time/batch = 18.2081s	
17593/33250 (epoch 26.456), train_loss = 1.00884574, grad/param norm = 1.4308e-01, time/batch = 16.3565s	
17594/33250 (epoch 26.457), train_loss = 0.83378359, grad/param norm = 1.6447e-01, time/batch = 15.9262s	
17595/33250 (epoch 26.459), train_loss = 0.93523602, grad/param norm = 1.6167e-01, time/batch = 15.2975s	
17596/33250 (epoch 26.460), train_loss = 0.95758627, grad/param norm = 1.7152e-01, time/batch = 16.0115s	
17597/33250 (epoch 26.462), train_loss = 0.83996319, grad/param norm = 1.5153e-01, time/batch = 15.6929s	
17598/33250 (epoch 26.463), train_loss = 0.80972136, grad/param norm = 1.3419e-01, time/batch = 17.1822s	
17599/33250 (epoch 26.465), train_loss = 0.73511118, grad/param norm = 1.3126e-01, time/batch = 16.8704s	
17600/33250 (epoch 26.466), train_loss = 0.69869203, grad/param norm = 1.1693e-01, time/batch = 16.0990s	
17601/33250 (epoch 26.468), train_loss = 0.76127217, grad/param norm = 1.2045e-01, time/batch = 19.3640s	
17602/33250 (epoch 26.469), train_loss = 0.84738929, grad/param norm = 1.6541e-01, time/batch = 17.2840s	
17603/33250 (epoch 26.471), train_loss = 0.94347183, grad/param norm = 1.5348e-01, time/batch = 17.8381s	
17604/33250 (epoch 26.472), train_loss = 0.83910598, grad/param norm = 1.8657e-01, time/batch = 17.8450s	
17605/33250 (epoch 26.474), train_loss = 0.99896682, grad/param norm = 1.7304e-01, time/batch = 16.8659s	
17606/33250 (epoch 26.475), train_loss = 0.90825276, grad/param norm = 1.4309e-01, time/batch = 15.3535s	
17607/33250 (epoch 26.477), train_loss = 0.86804086, grad/param norm = 1.5314e-01, time/batch = 16.9179s	
17608/33250 (epoch 26.478), train_loss = 0.79506328, grad/param norm = 1.6135e-01, time/batch = 15.0874s	
17609/33250 (epoch 26.480), train_loss = 1.03065574, grad/param norm = 1.6892e-01, time/batch = 14.6233s	
17610/33250 (epoch 26.481), train_loss = 0.90800870, grad/param norm = 1.7237e-01, time/batch = 17.4581s	
17611/33250 (epoch 26.483), train_loss = 0.86462914, grad/param norm = 1.5390e-01, time/batch = 17.6027s	
17612/33250 (epoch 26.484), train_loss = 0.77606736, grad/param norm = 1.3512e-01, time/batch = 16.7068s	
17613/33250 (epoch 26.486), train_loss = 0.74481239, grad/param norm = 1.4780e-01, time/batch = 16.9441s	
17614/33250 (epoch 26.487), train_loss = 0.82472197, grad/param norm = 1.6371e-01, time/batch = 15.1661s	
17615/33250 (epoch 26.489), train_loss = 0.98720307, grad/param norm = 1.9987e-01, time/batch = 16.6144s	
17616/33250 (epoch 26.490), train_loss = 0.92735301, grad/param norm = 1.7786e-01, time/batch = 16.9329s	
17617/33250 (epoch 26.492), train_loss = 0.95958266, grad/param norm = 1.7751e-01, time/batch = 17.3576s	
17618/33250 (epoch 26.493), train_loss = 0.86935717, grad/param norm = 1.6325e-01, time/batch = 16.6575s	
17619/33250 (epoch 26.495), train_loss = 0.91565592, grad/param norm = 1.3492e-01, time/batch = 17.6787s	
17620/33250 (epoch 26.496), train_loss = 0.89661709, grad/param norm = 1.3731e-01, time/batch = 16.5092s	
17621/33250 (epoch 26.498), train_loss = 0.96254306, grad/param norm = 1.6732e-01, time/batch = 18.1179s	
17622/33250 (epoch 26.499), train_loss = 0.82762521, grad/param norm = 1.5344e-01, time/batch = 17.6982s	
17623/33250 (epoch 26.501), train_loss = 0.82278322, grad/param norm = 1.7046e-01, time/batch = 17.9501s	
17624/33250 (epoch 26.502), train_loss = 0.83164971, grad/param norm = 1.3700e-01, time/batch = 17.6078s	
17625/33250 (epoch 26.504), train_loss = 1.01194156, grad/param norm = 1.8169e-01, time/batch = 15.8351s	
17626/33250 (epoch 26.505), train_loss = 0.73308128, grad/param norm = 1.3006e-01, time/batch = 15.6852s	
17627/33250 (epoch 26.507), train_loss = 0.80453553, grad/param norm = 1.7923e-01, time/batch = 17.1075s	
17628/33250 (epoch 26.508), train_loss = 0.84092120, grad/param norm = 1.5578e-01, time/batch = 16.1815s	
17629/33250 (epoch 26.510), train_loss = 0.71735637, grad/param norm = 1.3318e-01, time/batch = 17.5013s	
17630/33250 (epoch 26.511), train_loss = 0.85953394, grad/param norm = 1.6068e-01, time/batch = 16.5273s	
17631/33250 (epoch 26.513), train_loss = 1.00188520, grad/param norm = 1.4964e-01, time/batch = 17.9506s	
17632/33250 (epoch 26.514), train_loss = 0.86414235, grad/param norm = 1.5129e-01, time/batch = 18.5229s	
17633/33250 (epoch 26.516), train_loss = 0.80240891, grad/param norm = 1.5602e-01, time/batch = 17.5121s	
17634/33250 (epoch 26.517), train_loss = 0.84279596, grad/param norm = 1.5197e-01, time/batch = 17.1829s	
17635/33250 (epoch 26.519), train_loss = 0.75632820, grad/param norm = 1.1746e-01, time/batch = 16.3691s	
17636/33250 (epoch 26.520), train_loss = 1.07351803, grad/param norm = 1.7903e-01, time/batch = 18.7534s	
17637/33250 (epoch 26.522), train_loss = 0.93336155, grad/param norm = 1.5280e-01, time/batch = 15.6792s	
17638/33250 (epoch 26.523), train_loss = 0.79940783, grad/param norm = 1.5571e-01, time/batch = 15.4323s	
17639/33250 (epoch 26.525), train_loss = 0.75792054, grad/param norm = 1.4516e-01, time/batch = 16.5961s	
17640/33250 (epoch 26.526), train_loss = 0.76833523, grad/param norm = 1.3999e-01, time/batch = 17.6273s	
17641/33250 (epoch 26.528), train_loss = 0.82303647, grad/param norm = 1.4457e-01, time/batch = 18.8744s	
17642/33250 (epoch 26.529), train_loss = 0.82596767, grad/param norm = 1.7203e-01, time/batch = 16.7627s	
17643/33250 (epoch 26.531), train_loss = 0.76163153, grad/param norm = 1.3297e-01, time/batch = 15.6755s	
17644/33250 (epoch 26.532), train_loss = 0.90358816, grad/param norm = 1.4567e-01, time/batch = 16.6157s	
17645/33250 (epoch 26.534), train_loss = 0.77086946, grad/param norm = 1.3907e-01, time/batch = 17.3527s	
17646/33250 (epoch 26.535), train_loss = 0.85089617, grad/param norm = 1.4369e-01, time/batch = 16.5166s	
17647/33250 (epoch 26.537), train_loss = 0.89398198, grad/param norm = 1.4867e-01, time/batch = 15.6821s	
17648/33250 (epoch 26.538), train_loss = 0.92477223, grad/param norm = 1.5139e-01, time/batch = 16.6008s	
17649/33250 (epoch 26.540), train_loss = 1.01815307, grad/param norm = 1.4710e-01, time/batch = 17.8494s	
17650/33250 (epoch 26.541), train_loss = 0.97494869, grad/param norm = 1.8816e-01, time/batch = 17.2530s	
17651/33250 (epoch 26.543), train_loss = 0.92863086, grad/param norm = 1.4914e-01, time/batch = 18.7844s	
17652/33250 (epoch 26.544), train_loss = 0.81505746, grad/param norm = 1.6438e-01, time/batch = 16.8556s	
17653/33250 (epoch 26.546), train_loss = 0.83804685, grad/param norm = 1.6079e-01, time/batch = 16.6877s	
17654/33250 (epoch 26.547), train_loss = 0.85198842, grad/param norm = 1.7063e-01, time/batch = 17.2635s	
17655/33250 (epoch 26.549), train_loss = 0.89887863, grad/param norm = 1.5177e-01, time/batch = 15.6053s	
17656/33250 (epoch 26.550), train_loss = 0.82989525, grad/param norm = 1.4815e-01, time/batch = 17.4209s	
17657/33250 (epoch 26.552), train_loss = 0.92599703, grad/param norm = 1.5689e-01, time/batch = 16.1068s	
17658/33250 (epoch 26.553), train_loss = 0.82285409, grad/param norm = 1.4148e-01, time/batch = 15.4309s	
17659/33250 (epoch 26.555), train_loss = 0.90818665, grad/param norm = 1.5132e-01, time/batch = 16.2674s	
17660/33250 (epoch 26.556), train_loss = 0.90239152, grad/param norm = 1.7426e-01, time/batch = 15.5143s	
17661/33250 (epoch 26.558), train_loss = 0.93494374, grad/param norm = 1.6922e-01, time/batch = 16.8036s	
17662/33250 (epoch 26.559), train_loss = 0.80049059, grad/param norm = 1.4148e-01, time/batch = 15.2046s	
17663/33250 (epoch 26.561), train_loss = 0.76789603, grad/param norm = 1.3351e-01, time/batch = 14.8717s	
17664/33250 (epoch 26.562), train_loss = 0.91877424, grad/param norm = 1.6623e-01, time/batch = 15.1699s	
17665/33250 (epoch 26.564), train_loss = 1.05366590, grad/param norm = 1.9797e-01, time/batch = 14.7593s	
17666/33250 (epoch 26.565), train_loss = 1.03494402, grad/param norm = 1.9163e-01, time/batch = 15.0895s	
17667/33250 (epoch 26.567), train_loss = 1.00938692, grad/param norm = 1.8283e-01, time/batch = 14.8691s	
17668/33250 (epoch 26.568), train_loss = 0.87866318, grad/param norm = 1.7619e-01, time/batch = 14.9234s	
17669/33250 (epoch 26.570), train_loss = 0.96696993, grad/param norm = 1.7302e-01, time/batch = 14.9304s	
17670/33250 (epoch 26.571), train_loss = 1.02121126, grad/param norm = 1.6284e-01, time/batch = 14.5504s	
17671/33250 (epoch 26.573), train_loss = 0.93639148, grad/param norm = 1.7898e-01, time/batch = 14.5572s	
17672/33250 (epoch 26.574), train_loss = 0.79837414, grad/param norm = 1.4123e-01, time/batch = 15.2830s	
17673/33250 (epoch 26.576), train_loss = 0.95577342, grad/param norm = 1.6952e-01, time/batch = 14.7083s	
17674/33250 (epoch 26.577), train_loss = 0.85784138, grad/param norm = 1.3783e-01, time/batch = 15.1871s	
17675/33250 (epoch 26.579), train_loss = 0.78813804, grad/param norm = 1.6046e-01, time/batch = 15.0261s	
17676/33250 (epoch 26.580), train_loss = 0.83095964, grad/param norm = 1.2714e-01, time/batch = 15.4313s	
17677/33250 (epoch 26.582), train_loss = 0.84625588, grad/param norm = 1.6377e-01, time/batch = 14.9389s	
17678/33250 (epoch 26.583), train_loss = 0.97651112, grad/param norm = 1.5637e-01, time/batch = 14.6252s	
17679/33250 (epoch 26.585), train_loss = 0.98530616, grad/param norm = 1.5778e-01, time/batch = 14.6129s	
17680/33250 (epoch 26.586), train_loss = 0.80510780, grad/param norm = 1.8009e-01, time/batch = 15.1714s	
17681/33250 (epoch 26.588), train_loss = 0.91060990, grad/param norm = 1.6050e-01, time/batch = 14.9572s	
17682/33250 (epoch 26.589), train_loss = 0.90311842, grad/param norm = 1.6031e-01, time/batch = 14.5701s	
17683/33250 (epoch 26.591), train_loss = 0.86393851, grad/param norm = 1.8157e-01, time/batch = 14.4051s	
17684/33250 (epoch 26.592), train_loss = 0.86135415, grad/param norm = 1.5210e-01, time/batch = 14.9560s	
17685/33250 (epoch 26.594), train_loss = 0.99253400, grad/param norm = 1.7027e-01, time/batch = 15.2743s	
17686/33250 (epoch 26.595), train_loss = 0.90313013, grad/param norm = 1.6160e-01, time/batch = 15.3438s	
17687/33250 (epoch 26.597), train_loss = 0.74655166, grad/param norm = 1.3473e-01, time/batch = 14.6958s	
17688/33250 (epoch 26.598), train_loss = 0.83580185, grad/param norm = 1.5656e-01, time/batch = 15.0995s	
17689/33250 (epoch 26.600), train_loss = 0.85909219, grad/param norm = 1.9007e-01, time/batch = 14.7080s	
17690/33250 (epoch 26.602), train_loss = 0.90541175, grad/param norm = 1.7321e-01, time/batch = 14.9428s	
17691/33250 (epoch 26.603), train_loss = 0.92128187, grad/param norm = 1.6121e-01, time/batch = 14.5386s	
17692/33250 (epoch 26.605), train_loss = 0.88321221, grad/param norm = 1.5279e-01, time/batch = 14.8683s	
17693/33250 (epoch 26.606), train_loss = 0.93921416, grad/param norm = 1.5864e-01, time/batch = 14.7082s	
17694/33250 (epoch 26.608), train_loss = 0.88810878, grad/param norm = 1.5126e-01, time/batch = 14.5607s	
17695/33250 (epoch 26.609), train_loss = 0.79738154, grad/param norm = 1.4966e-01, time/batch = 14.5589s	
17696/33250 (epoch 26.611), train_loss = 0.91816552, grad/param norm = 1.8457e-01, time/batch = 14.9559s	
17697/33250 (epoch 26.612), train_loss = 0.86964422, grad/param norm = 1.5885e-01, time/batch = 14.8680s	
17698/33250 (epoch 26.614), train_loss = 1.09308231, grad/param norm = 1.8919e-01, time/batch = 14.8752s	
17699/33250 (epoch 26.615), train_loss = 0.98954021, grad/param norm = 1.7797e-01, time/batch = 14.9584s	
17700/33250 (epoch 26.617), train_loss = 1.10398977, grad/param norm = 1.9834e-01, time/batch = 15.1605s	
17701/33250 (epoch 26.618), train_loss = 1.13959316, grad/param norm = 2.3764e-01, time/batch = 14.7794s	
17702/33250 (epoch 26.620), train_loss = 0.97746008, grad/param norm = 1.7576e-01, time/batch = 15.0235s	
17703/33250 (epoch 26.621), train_loss = 0.93610226, grad/param norm = 1.7252e-01, time/batch = 14.6167s	
17704/33250 (epoch 26.623), train_loss = 0.80396478, grad/param norm = 1.5849e-01, time/batch = 14.9603s	
17705/33250 (epoch 26.624), train_loss = 0.86635800, grad/param norm = 1.6590e-01, time/batch = 15.0364s	
17706/33250 (epoch 26.626), train_loss = 0.84658076, grad/param norm = 2.0912e-01, time/batch = 14.9582s	
17707/33250 (epoch 26.627), train_loss = 0.84223643, grad/param norm = 1.5866e-01, time/batch = 14.8142s	
17708/33250 (epoch 26.629), train_loss = 0.93150832, grad/param norm = 1.7681e-01, time/batch = 15.2553s	
17709/33250 (epoch 26.630), train_loss = 0.85398833, grad/param norm = 1.8188e-01, time/batch = 14.7810s	
17710/33250 (epoch 26.632), train_loss = 0.75395202, grad/param norm = 1.5257e-01, time/batch = 14.9410s	
17711/33250 (epoch 26.633), train_loss = 0.88925459, grad/param norm = 1.7011e-01, time/batch = 15.0251s	
17712/33250 (epoch 26.635), train_loss = 0.80767205, grad/param norm = 1.4742e-01, time/batch = 15.1930s	
17713/33250 (epoch 26.636), train_loss = 0.81181736, grad/param norm = 1.4186e-01, time/batch = 14.9582s	
17714/33250 (epoch 26.638), train_loss = 0.79043111, grad/param norm = 1.5251e-01, time/batch = 15.0167s	
17715/33250 (epoch 26.639), train_loss = 0.76347336, grad/param norm = 1.4832e-01, time/batch = 14.9595s	
17716/33250 (epoch 26.641), train_loss = 0.85468612, grad/param norm = 1.5003e-01, time/batch = 14.8708s	
17717/33250 (epoch 26.642), train_loss = 0.68678059, grad/param norm = 1.5579e-01, time/batch = 14.5746s	
17718/33250 (epoch 26.644), train_loss = 0.61941507, grad/param norm = 1.4237e-01, time/batch = 14.6430s	
17719/33250 (epoch 26.645), train_loss = 0.92036155, grad/param norm = 1.9773e-01, time/batch = 14.7837s	
17720/33250 (epoch 26.647), train_loss = 0.76320222, grad/param norm = 1.6225e-01, time/batch = 15.2573s	
17721/33250 (epoch 26.648), train_loss = 0.78286515, grad/param norm = 1.8838e-01, time/batch = 15.3431s	
17722/33250 (epoch 26.650), train_loss = 1.02345705, grad/param norm = 2.0242e-01, time/batch = 14.7051s	
17723/33250 (epoch 26.651), train_loss = 0.92731547, grad/param norm = 1.7133e-01, time/batch = 14.4358s	
17724/33250 (epoch 26.653), train_loss = 0.81516648, grad/param norm = 1.7089e-01, time/batch = 14.9375s	
17725/33250 (epoch 26.654), train_loss = 0.87817041, grad/param norm = 1.5042e-01, time/batch = 15.0944s	
17726/33250 (epoch 26.656), train_loss = 0.90906156, grad/param norm = 1.5713e-01, time/batch = 14.7856s	
17727/33250 (epoch 26.657), train_loss = 0.69141925, grad/param norm = 1.5287e-01, time/batch = 14.4858s	
17728/33250 (epoch 26.659), train_loss = 0.79431337, grad/param norm = 1.5077e-01, time/batch = 14.8070s	
17729/33250 (epoch 26.660), train_loss = 0.87617545, grad/param norm = 1.7265e-01, time/batch = 14.5622s	
17730/33250 (epoch 26.662), train_loss = 0.87053408, grad/param norm = 1.6264e-01, time/batch = 14.8801s	
17731/33250 (epoch 26.663), train_loss = 0.80429202, grad/param norm = 1.5310e-01, time/batch = 15.1085s	
17732/33250 (epoch 26.665), train_loss = 0.90653708, grad/param norm = 1.6190e-01, time/batch = 15.1808s	
17733/33250 (epoch 26.666), train_loss = 0.81773542, grad/param norm = 1.4268e-01, time/batch = 14.8647s	
17734/33250 (epoch 26.668), train_loss = 0.99706933, grad/param norm = 1.6354e-01, time/batch = 14.9397s	
17735/33250 (epoch 26.669), train_loss = 0.88821570, grad/param norm = 1.7275e-01, time/batch = 15.0374s	
17736/33250 (epoch 26.671), train_loss = 0.80467374, grad/param norm = 1.5384e-01, time/batch = 15.3354s	
17737/33250 (epoch 26.672), train_loss = 0.94283118, grad/param norm = 1.8341e-01, time/batch = 15.0275s	
17738/33250 (epoch 26.674), train_loss = 0.76207071, grad/param norm = 1.4652e-01, time/batch = 14.8018s	
17739/33250 (epoch 26.675), train_loss = 0.86657487, grad/param norm = 1.4618e-01, time/batch = 14.8026s	
17740/33250 (epoch 26.677), train_loss = 0.95470020, grad/param norm = 1.6864e-01, time/batch = 15.2781s	
17741/33250 (epoch 26.678), train_loss = 0.84108759, grad/param norm = 1.6896e-01, time/batch = 14.8893s	
17742/33250 (epoch 26.680), train_loss = 0.95556630, grad/param norm = 1.6849e-01, time/batch = 14.7954s	
17743/33250 (epoch 26.681), train_loss = 0.78796159, grad/param norm = 1.7439e-01, time/batch = 15.0212s	
17744/33250 (epoch 26.683), train_loss = 0.81068000, grad/param norm = 1.5423e-01, time/batch = 15.0245s	
17745/33250 (epoch 26.684), train_loss = 0.79807101, grad/param norm = 1.9354e-01, time/batch = 15.5886s	
17746/33250 (epoch 26.686), train_loss = 0.78788816, grad/param norm = 1.6002e-01, time/batch = 15.2559s	
17747/33250 (epoch 26.687), train_loss = 0.87258253, grad/param norm = 1.5805e-01, time/batch = 14.7857s	
17748/33250 (epoch 26.689), train_loss = 0.78699483, grad/param norm = 1.6778e-01, time/batch = 15.1067s	
17749/33250 (epoch 26.690), train_loss = 0.87897816, grad/param norm = 1.7136e-01, time/batch = 14.6356s	
17750/33250 (epoch 26.692), train_loss = 0.83932955, grad/param norm = 1.4977e-01, time/batch = 14.6345s	
17751/33250 (epoch 26.693), train_loss = 0.92960770, grad/param norm = 1.5464e-01, time/batch = 14.9648s	
17752/33250 (epoch 26.695), train_loss = 0.89980893, grad/param norm = 1.5240e-01, time/batch = 15.2002s	
17753/33250 (epoch 26.696), train_loss = 0.93470698, grad/param norm = 1.6242e-01, time/batch = 14.7031s	
17754/33250 (epoch 26.698), train_loss = 0.82894726, grad/param norm = 1.6578e-01, time/batch = 14.6266s	
17755/33250 (epoch 26.699), train_loss = 1.07716150, grad/param norm = 1.7919e-01, time/batch = 14.7873s	
17756/33250 (epoch 26.701), train_loss = 0.86476614, grad/param norm = 1.3405e-01, time/batch = 14.9385s	
17757/33250 (epoch 26.702), train_loss = 0.82865494, grad/param norm = 2.0391e-01, time/batch = 16.1180s	
17758/33250 (epoch 26.704), train_loss = 1.04942317, grad/param norm = 2.1328e-01, time/batch = 17.7595s	
17759/33250 (epoch 26.705), train_loss = 0.82604949, grad/param norm = 1.4859e-01, time/batch = 15.9316s	
17760/33250 (epoch 26.707), train_loss = 0.72622544, grad/param norm = 1.6127e-01, time/batch = 16.1739s	
17761/33250 (epoch 26.708), train_loss = 0.95297998, grad/param norm = 1.8081e-01, time/batch = 18.0100s	
17762/33250 (epoch 26.710), train_loss = 0.93575623, grad/param norm = 2.0869e-01, time/batch = 18.0349s	
17763/33250 (epoch 26.711), train_loss = 0.77747497, grad/param norm = 1.7627e-01, time/batch = 17.6149s	
17764/33250 (epoch 26.713), train_loss = 0.90640188, grad/param norm = 1.5152e-01, time/batch = 16.7760s	
17765/33250 (epoch 26.714), train_loss = 0.87853446, grad/param norm = 1.6341e-01, time/batch = 17.6804s	
17766/33250 (epoch 26.716), train_loss = 0.91296907, grad/param norm = 1.7004e-01, time/batch = 15.4452s	
17767/33250 (epoch 26.717), train_loss = 0.80592215, grad/param norm = 1.4091e-01, time/batch = 16.7644s	
17768/33250 (epoch 26.719), train_loss = 0.83543803, grad/param norm = 1.5323e-01, time/batch = 16.1905s	
17769/33250 (epoch 26.720), train_loss = 1.10990468, grad/param norm = 1.8360e-01, time/batch = 16.7496s	
17770/33250 (epoch 26.722), train_loss = 0.76387232, grad/param norm = 1.4756e-01, time/batch = 18.2523s	
17771/33250 (epoch 26.723), train_loss = 0.69672376, grad/param norm = 1.4021e-01, time/batch = 18.5537s	
17772/33250 (epoch 26.725), train_loss = 0.79179013, grad/param norm = 1.3225e-01, time/batch = 16.8715s	
17773/33250 (epoch 26.726), train_loss = 0.85098750, grad/param norm = 1.7024e-01, time/batch = 16.7844s	
17774/33250 (epoch 26.728), train_loss = 0.90853071, grad/param norm = 1.6685e-01, time/batch = 16.8623s	
17775/33250 (epoch 26.729), train_loss = 0.96707704, grad/param norm = 1.6781e-01, time/batch = 16.2764s	
17776/33250 (epoch 26.731), train_loss = 0.80699308, grad/param norm = 1.7621e-01, time/batch = 15.3727s	
17777/33250 (epoch 26.732), train_loss = 0.77436224, grad/param norm = 1.4062e-01, time/batch = 22.4616s	
17778/33250 (epoch 26.734), train_loss = 0.90475238, grad/param norm = 1.7800e-01, time/batch = 23.9850s	
17779/33250 (epoch 26.735), train_loss = 0.88094097, grad/param norm = 1.5595e-01, time/batch = 16.3482s	
17780/33250 (epoch 26.737), train_loss = 0.82458154, grad/param norm = 1.4482e-01, time/batch = 15.2861s	
17781/33250 (epoch 26.738), train_loss = 0.88996960, grad/param norm = 1.4776e-01, time/batch = 16.3297s	
17782/33250 (epoch 26.740), train_loss = 0.94126710, grad/param norm = 1.8322e-01, time/batch = 17.5287s	
17783/33250 (epoch 26.741), train_loss = 0.93496180, grad/param norm = 1.6399e-01, time/batch = 17.1013s	
17784/33250 (epoch 26.743), train_loss = 0.79782663, grad/param norm = 1.4089e-01, time/batch = 15.2745s	
17785/33250 (epoch 26.744), train_loss = 0.84043621, grad/param norm = 1.6592e-01, time/batch = 15.4508s	
17786/33250 (epoch 26.746), train_loss = 0.78407274, grad/param norm = 1.4339e-01, time/batch = 16.7746s	
17787/33250 (epoch 26.747), train_loss = 0.81651865, grad/param norm = 1.5108e-01, time/batch = 15.8294s	
17788/33250 (epoch 26.749), train_loss = 0.96606533, grad/param norm = 1.6684e-01, time/batch = 16.5252s	
17789/33250 (epoch 26.750), train_loss = 0.96208752, grad/param norm = 1.7215e-01, time/batch = 15.0208s	
17790/33250 (epoch 26.752), train_loss = 0.84156658, grad/param norm = 1.5572e-01, time/batch = 17.9523s	
17791/33250 (epoch 26.753), train_loss = 0.82765930, grad/param norm = 1.8190e-01, time/batch = 17.1928s	
17792/33250 (epoch 26.755), train_loss = 0.82380422, grad/param norm = 1.6796e-01, time/batch = 17.7002s	
17793/33250 (epoch 26.756), train_loss = 0.88554600, grad/param norm = 1.6904e-01, time/batch = 16.2901s	
17794/33250 (epoch 26.758), train_loss = 1.00585977, grad/param norm = 1.4985e-01, time/batch = 16.8417s	
17795/33250 (epoch 26.759), train_loss = 0.79621230, grad/param norm = 1.5251e-01, time/batch = 15.6953s	
17796/33250 (epoch 26.761), train_loss = 0.88634830, grad/param norm = 1.6899e-01, time/batch = 17.0243s	
17797/33250 (epoch 26.762), train_loss = 0.94964027, grad/param norm = 1.6011e-01, time/batch = 16.5915s	
17798/33250 (epoch 26.764), train_loss = 0.79314133, grad/param norm = 1.9353e-01, time/batch = 17.0007s	
17799/33250 (epoch 26.765), train_loss = 0.91627044, grad/param norm = 1.6636e-01, time/batch = 15.8235s	
17800/33250 (epoch 26.767), train_loss = 0.69223213, grad/param norm = 1.4980e-01, time/batch = 16.6041s	
17801/33250 (epoch 26.768), train_loss = 0.73900445, grad/param norm = 1.6403e-01, time/batch = 18.9391s	
17802/33250 (epoch 26.770), train_loss = 0.91901144, grad/param norm = 1.7818e-01, time/batch = 17.2852s	
17803/33250 (epoch 26.771), train_loss = 0.93990932, grad/param norm = 1.7197e-01, time/batch = 15.8571s	
17804/33250 (epoch 26.773), train_loss = 0.83992813, grad/param norm = 1.8069e-01, time/batch = 16.7633s	
17805/33250 (epoch 26.774), train_loss = 0.73057407, grad/param norm = 1.4847e-01, time/batch = 16.7705s	
17806/33250 (epoch 26.776), train_loss = 0.82158167, grad/param norm = 1.5884e-01, time/batch = 16.6713s	
17807/33250 (epoch 26.777), train_loss = 0.96305319, grad/param norm = 1.8489e-01, time/batch = 18.0989s	
17808/33250 (epoch 26.779), train_loss = 0.85560218, grad/param norm = 1.7529e-01, time/batch = 16.5155s	
17809/33250 (epoch 26.780), train_loss = 1.00927917, grad/param norm = 1.7894e-01, time/batch = 15.6965s	
17810/33250 (epoch 26.782), train_loss = 0.87320874, grad/param norm = 1.6956e-01, time/batch = 16.9474s	
17811/33250 (epoch 26.783), train_loss = 0.73606175, grad/param norm = 1.4623e-01, time/batch = 15.6514s	
17812/33250 (epoch 26.785), train_loss = 0.75993685, grad/param norm = 1.5081e-01, time/batch = 17.1931s	
17813/33250 (epoch 26.786), train_loss = 0.99160690, grad/param norm = 1.7676e-01, time/batch = 16.0334s	
17814/33250 (epoch 26.788), train_loss = 0.94949528, grad/param norm = 1.5914e-01, time/batch = 16.3382s	
17815/33250 (epoch 26.789), train_loss = 0.98318496, grad/param norm = 2.0366e-01, time/batch = 17.8404s	
17816/33250 (epoch 26.791), train_loss = 1.01680020, grad/param norm = 1.9863e-01, time/batch = 16.0151s	
17817/33250 (epoch 26.792), train_loss = 1.04162558, grad/param norm = 1.6349e-01, time/batch = 15.2805s	
17818/33250 (epoch 26.794), train_loss = 0.85414664, grad/param norm = 1.6044e-01, time/batch = 17.6027s	
17819/33250 (epoch 26.795), train_loss = 0.87637621, grad/param norm = 1.6145e-01, time/batch = 16.2376s	
17820/33250 (epoch 26.797), train_loss = 0.95120246, grad/param norm = 1.9303e-01, time/batch = 17.2782s	
17821/33250 (epoch 26.798), train_loss = 0.88883808, grad/param norm = 2.1689e-01, time/batch = 18.5163s	
17822/33250 (epoch 26.800), train_loss = 0.91796456, grad/param norm = 1.7784e-01, time/batch = 18.4487s	
17823/33250 (epoch 26.802), train_loss = 0.85152608, grad/param norm = 1.4018e-01, time/batch = 17.6813s	
17824/33250 (epoch 26.803), train_loss = 0.89763527, grad/param norm = 1.5019e-01, time/batch = 16.4374s	
17825/33250 (epoch 26.805), train_loss = 0.92032218, grad/param norm = 1.7676e-01, time/batch = 17.6727s	
17826/33250 (epoch 26.806), train_loss = 0.86996298, grad/param norm = 1.7165e-01, time/batch = 16.0809s	
17827/33250 (epoch 26.808), train_loss = 0.81982420, grad/param norm = 1.5036e-01, time/batch = 16.7689s	
17828/33250 (epoch 26.809), train_loss = 0.78565214, grad/param norm = 1.4258e-01, time/batch = 18.4152s	
17829/33250 (epoch 26.811), train_loss = 0.79124169, grad/param norm = 1.4968e-01, time/batch = 16.4355s	
17830/33250 (epoch 26.812), train_loss = 0.92781246, grad/param norm = 1.7982e-01, time/batch = 16.0207s	
17831/33250 (epoch 26.814), train_loss = 0.87488760, grad/param norm = 1.7714e-01, time/batch = 16.5892s	
17832/33250 (epoch 26.815), train_loss = 0.92922565, grad/param norm = 1.5861e-01, time/batch = 17.1247s	
17833/33250 (epoch 26.817), train_loss = 0.87015073, grad/param norm = 1.8109e-01, time/batch = 16.7820s	
17834/33250 (epoch 26.818), train_loss = 0.79384451, grad/param norm = 1.5309e-01, time/batch = 17.4213s	
17835/33250 (epoch 26.820), train_loss = 0.90157173, grad/param norm = 1.5984e-01, time/batch = 15.2714s	
17836/33250 (epoch 26.821), train_loss = 0.84840761, grad/param norm = 1.5106e-01, time/batch = 18.0177s	
17837/33250 (epoch 26.823), train_loss = 1.18685258, grad/param norm = 1.8950e-01, time/batch = 17.0162s	
17838/33250 (epoch 26.824), train_loss = 0.82756780, grad/param norm = 1.7237e-01, time/batch = 17.6832s	
17839/33250 (epoch 26.826), train_loss = 0.90048089, grad/param norm = 1.5993e-01, time/batch = 16.2753s	
17840/33250 (epoch 26.827), train_loss = 0.75237910, grad/param norm = 1.5544e-01, time/batch = 18.0283s	
17841/33250 (epoch 26.829), train_loss = 0.88527413, grad/param norm = 1.6749e-01, time/batch = 19.0250s	
17842/33250 (epoch 26.830), train_loss = 0.96635781, grad/param norm = 2.2622e-01, time/batch = 18.1113s	
17843/33250 (epoch 26.832), train_loss = 0.87959395, grad/param norm = 1.6428e-01, time/batch = 16.5879s	
17844/33250 (epoch 26.833), train_loss = 0.86689351, grad/param norm = 1.6194e-01, time/batch = 15.5972s	
17845/33250 (epoch 26.835), train_loss = 0.80590599, grad/param norm = 2.0658e-01, time/batch = 17.2643s	
17846/33250 (epoch 26.836), train_loss = 0.84439191, grad/param norm = 1.6164e-01, time/batch = 15.3602s	
17847/33250 (epoch 26.838), train_loss = 0.91022224, grad/param norm = 1.5989e-01, time/batch = 17.7454s	
17848/33250 (epoch 26.839), train_loss = 0.84436838, grad/param norm = 1.5419e-01, time/batch = 16.7672s	
17849/33250 (epoch 26.841), train_loss = 0.81666234, grad/param norm = 1.4383e-01, time/batch = 16.8517s	
17850/33250 (epoch 26.842), train_loss = 1.01474529, grad/param norm = 1.6029e-01, time/batch = 17.4421s	
17851/33250 (epoch 26.844), train_loss = 0.97258370, grad/param norm = 1.7944e-01, time/batch = 16.9306s	
17852/33250 (epoch 26.845), train_loss = 1.07081767, grad/param norm = 2.3214e-01, time/batch = 15.8695s	
17853/33250 (epoch 26.847), train_loss = 1.05280339, grad/param norm = 2.0593e-01, time/batch = 17.1966s	
17854/33250 (epoch 26.848), train_loss = 1.08489369, grad/param norm = 1.8716e-01, time/batch = 16.7615s	
17855/33250 (epoch 26.850), train_loss = 0.98910444, grad/param norm = 1.8384e-01, time/batch = 18.9045s	
17856/33250 (epoch 26.851), train_loss = 0.81290545, grad/param norm = 1.9203e-01, time/batch = 15.9358s	
17857/33250 (epoch 26.853), train_loss = 0.93208508, grad/param norm = 1.8986e-01, time/batch = 18.0024s	
17858/33250 (epoch 26.854), train_loss = 0.84202421, grad/param norm = 1.4591e-01, time/batch = 15.7774s	
17859/33250 (epoch 26.856), train_loss = 0.85007055, grad/param norm = 1.9846e-01, time/batch = 28.2141s	
17860/33250 (epoch 26.857), train_loss = 0.75808305, grad/param norm = 1.4970e-01, time/batch = 19.0333s	
17861/33250 (epoch 26.859), train_loss = 0.79289102, grad/param norm = 1.5004e-01, time/batch = 16.7625s	
17862/33250 (epoch 26.860), train_loss = 0.90717939, grad/param norm = 1.6247e-01, time/batch = 17.2826s	
17863/33250 (epoch 26.862), train_loss = 0.77231462, grad/param norm = 1.4961e-01, time/batch = 17.6006s	
17864/33250 (epoch 26.863), train_loss = 0.82075274, grad/param norm = 1.6578e-01, time/batch = 16.9177s	
17865/33250 (epoch 26.865), train_loss = 0.91569877, grad/param norm = 1.8493e-01, time/batch = 15.6909s	
17866/33250 (epoch 26.866), train_loss = 0.78438291, grad/param norm = 1.8831e-01, time/batch = 17.1590s	
17867/33250 (epoch 26.868), train_loss = 0.90101359, grad/param norm = 1.8480e-01, time/batch = 16.7036s	
17868/33250 (epoch 26.869), train_loss = 0.89837902, grad/param norm = 1.6538e-01, time/batch = 16.6766s	
17869/33250 (epoch 26.871), train_loss = 0.68869420, grad/param norm = 1.3827e-01, time/batch = 15.5847s	
17870/33250 (epoch 26.872), train_loss = 0.93599734, grad/param norm = 1.5717e-01, time/batch = 17.8810s	
17871/33250 (epoch 26.874), train_loss = 0.78539585, grad/param norm = 1.5180e-01, time/batch = 19.0223s	
17872/33250 (epoch 26.875), train_loss = 0.77826828, grad/param norm = 2.0513e-01, time/batch = 16.6240s	
17873/33250 (epoch 26.877), train_loss = 1.00325535, grad/param norm = 1.7215e-01, time/batch = 18.5960s	
17874/33250 (epoch 26.878), train_loss = 0.92227155, grad/param norm = 1.6315e-01, time/batch = 16.0929s	
17875/33250 (epoch 26.880), train_loss = 0.86912423, grad/param norm = 1.9974e-01, time/batch = 17.5915s	
17876/33250 (epoch 26.881), train_loss = 0.97882240, grad/param norm = 1.7114e-01, time/batch = 15.9991s	
17877/33250 (epoch 26.883), train_loss = 0.89285905, grad/param norm = 1.7997e-01, time/batch = 18.4352s	
17878/33250 (epoch 26.884), train_loss = 0.94369762, grad/param norm = 1.7710e-01, time/batch = 16.5150s	
17879/33250 (epoch 26.886), train_loss = 0.81326160, grad/param norm = 1.3811e-01, time/batch = 15.9799s	
17880/33250 (epoch 26.887), train_loss = 0.83555079, grad/param norm = 1.9671e-01, time/batch = 18.2013s	
17881/33250 (epoch 26.889), train_loss = 0.82656880, grad/param norm = 1.4365e-01, time/batch = 17.4649s	
17882/33250 (epoch 26.890), train_loss = 0.69728213, grad/param norm = 1.2872e-01, time/batch = 17.5007s	
17883/33250 (epoch 26.892), train_loss = 0.90886986, grad/param norm = 1.5385e-01, time/batch = 15.2493s	
17884/33250 (epoch 26.893), train_loss = 0.92622597, grad/param norm = 1.7832e-01, time/batch = 15.9432s	
17885/33250 (epoch 26.895), train_loss = 0.81987360, grad/param norm = 1.6249e-01, time/batch = 15.3373s	
17886/33250 (epoch 26.896), train_loss = 0.94487577, grad/param norm = 1.7088e-01, time/batch = 17.3359s	
17887/33250 (epoch 26.898), train_loss = 0.88022519, grad/param norm = 1.6019e-01, time/batch = 16.9185s	
17888/33250 (epoch 26.899), train_loss = 0.81156659, grad/param norm = 1.4474e-01, time/batch = 17.4276s	
17889/33250 (epoch 26.901), train_loss = 0.75200674, grad/param norm = 1.4210e-01, time/batch = 16.9285s	
17890/33250 (epoch 26.902), train_loss = 0.83582207, grad/param norm = 1.5035e-01, time/batch = 17.4531s	
17891/33250 (epoch 26.904), train_loss = 0.78674803, grad/param norm = 1.6461e-01, time/batch = 19.6128s	
17892/33250 (epoch 26.905), train_loss = 0.83484815, grad/param norm = 1.4581e-01, time/batch = 16.5036s	
17893/33250 (epoch 26.907), train_loss = 0.77609314, grad/param norm = 1.5600e-01, time/batch = 18.3248s	
17894/33250 (epoch 26.908), train_loss = 0.86496440, grad/param norm = 1.3852e-01, time/batch = 16.9225s	
17895/33250 (epoch 26.910), train_loss = 0.92707013, grad/param norm = 1.8201e-01, time/batch = 18.0829s	
17896/33250 (epoch 26.911), train_loss = 0.77024340, grad/param norm = 1.5113e-01, time/batch = 15.9431s	
17897/33250 (epoch 26.913), train_loss = 0.82428415, grad/param norm = 1.4817e-01, time/batch = 18.0906s	
17898/33250 (epoch 26.914), train_loss = 0.73458428, grad/param norm = 1.5657e-01, time/batch = 18.6940s	
17899/33250 (epoch 26.916), train_loss = 0.78437380, grad/param norm = 1.4605e-01, time/batch = 15.8570s	
17900/33250 (epoch 26.917), train_loss = 0.86972199, grad/param norm = 1.4347e-01, time/batch = 15.5736s	
17901/33250 (epoch 26.919), train_loss = 0.80365169, grad/param norm = 1.6954e-01, time/batch = 16.2707s	
17902/33250 (epoch 26.920), train_loss = 0.86415334, grad/param norm = 1.8126e-01, time/batch = 15.5288s	
17903/33250 (epoch 26.922), train_loss = 0.87848258, grad/param norm = 1.5562e-01, time/batch = 15.7324s	
17904/33250 (epoch 26.923), train_loss = 0.81078627, grad/param norm = 2.2422e-01, time/batch = 15.7698s	
17905/33250 (epoch 26.925), train_loss = 0.82788374, grad/param norm = 1.6129e-01, time/batch = 16.8481s	
17906/33250 (epoch 26.926), train_loss = 0.82642489, grad/param norm = 1.5408e-01, time/batch = 15.5128s	
17907/33250 (epoch 26.928), train_loss = 0.84163828, grad/param norm = 1.7133e-01, time/batch = 16.5171s	
17908/33250 (epoch 26.929), train_loss = 0.73315989, grad/param norm = 1.2751e-01, time/batch = 16.4516s	
17909/33250 (epoch 26.931), train_loss = 0.96061271, grad/param norm = 1.6197e-01, time/batch = 16.3442s	
17910/33250 (epoch 26.932), train_loss = 0.83274676, grad/param norm = 1.6291e-01, time/batch = 16.5979s	
17911/33250 (epoch 26.934), train_loss = 0.80322718, grad/param norm = 1.3782e-01, time/batch = 16.0239s	
17912/33250 (epoch 26.935), train_loss = 0.80413588, grad/param norm = 1.6407e-01, time/batch = 17.1214s	
17913/33250 (epoch 26.937), train_loss = 0.80871478, grad/param norm = 2.0318e-01, time/batch = 17.0039s	
17914/33250 (epoch 26.938), train_loss = 0.87646116, grad/param norm = 1.7449e-01, time/batch = 17.3366s	
17915/33250 (epoch 26.940), train_loss = 0.83616199, grad/param norm = 1.6555e-01, time/batch = 17.1862s	
17916/33250 (epoch 26.941), train_loss = 0.91528708, grad/param norm = 1.8614e-01, time/batch = 17.4352s	
17917/33250 (epoch 26.943), train_loss = 1.00630183, grad/param norm = 1.7093e-01, time/batch = 17.0858s	
17918/33250 (epoch 26.944), train_loss = 0.82018358, grad/param norm = 1.5311e-01, time/batch = 18.5013s	
17919/33250 (epoch 26.946), train_loss = 0.97154318, grad/param norm = 1.7152e-01, time/batch = 17.0568s	
17920/33250 (epoch 26.947), train_loss = 0.78916569, grad/param norm = 1.4851e-01, time/batch = 18.6113s	
17921/33250 (epoch 26.949), train_loss = 0.93304064, grad/param norm = 1.6381e-01, time/batch = 17.9455s	
17922/33250 (epoch 26.950), train_loss = 0.92182681, grad/param norm = 1.5270e-01, time/batch = 15.1778s	
17923/33250 (epoch 26.952), train_loss = 0.85982363, grad/param norm = 1.7651e-01, time/batch = 17.5131s	
17924/33250 (epoch 26.953), train_loss = 0.93124099, grad/param norm = 1.6664e-01, time/batch = 16.1599s	
17925/33250 (epoch 26.955), train_loss = 0.95099898, grad/param norm = 1.6369e-01, time/batch = 17.6176s	
17926/33250 (epoch 26.956), train_loss = 0.89006297, grad/param norm = 2.0478e-01, time/batch = 16.6805s	
17927/33250 (epoch 26.958), train_loss = 0.81008085, grad/param norm = 1.6289e-01, time/batch = 17.6028s	
17928/33250 (epoch 26.959), train_loss = 0.82158797, grad/param norm = 1.6011e-01, time/batch = 16.7791s	
17929/33250 (epoch 26.961), train_loss = 1.06279530, grad/param norm = 1.7022e-01, time/batch = 17.8614s	
17930/33250 (epoch 26.962), train_loss = 0.86405868, grad/param norm = 1.6691e-01, time/batch = 15.9575s	
17931/33250 (epoch 26.964), train_loss = 1.02432939, grad/param norm = 1.9658e-01, time/batch = 16.1236s	
17932/33250 (epoch 26.965), train_loss = 0.94028540, grad/param norm = 1.7939e-01, time/batch = 17.9571s	
17933/33250 (epoch 26.967), train_loss = 0.91023159, grad/param norm = 1.5710e-01, time/batch = 17.0203s	
17934/33250 (epoch 26.968), train_loss = 1.02781661, grad/param norm = 1.6193e-01, time/batch = 17.9459s	
17935/33250 (epoch 26.970), train_loss = 1.13608761, grad/param norm = 1.9289e-01, time/batch = 16.6829s	
17936/33250 (epoch 26.971), train_loss = 1.03020262, grad/param norm = 2.0208e-01, time/batch = 17.6100s	
17937/33250 (epoch 26.973), train_loss = 0.83707077, grad/param norm = 1.4943e-01, time/batch = 15.0191s	
17938/33250 (epoch 26.974), train_loss = 0.97125206, grad/param norm = 1.8795e-01, time/batch = 15.2834s	
17939/33250 (epoch 26.976), train_loss = 0.83938853, grad/param norm = 1.7757e-01, time/batch = 15.1181s	
17940/33250 (epoch 26.977), train_loss = 0.84551338, grad/param norm = 1.6778e-01, time/batch = 15.6962s	
17941/33250 (epoch 26.979), train_loss = 0.91705835, grad/param norm = 1.7891e-01, time/batch = 15.4069s	
17942/33250 (epoch 26.980), train_loss = 0.89721272, grad/param norm = 1.6541e-01, time/batch = 16.3564s	
17943/33250 (epoch 26.982), train_loss = 0.81717551, grad/param norm = 1.5238e-01, time/batch = 16.9487s	
17944/33250 (epoch 26.983), train_loss = 0.89177521, grad/param norm = 1.7311e-01, time/batch = 18.5363s	
17945/33250 (epoch 26.985), train_loss = 0.82915772, grad/param norm = 1.6884e-01, time/batch = 17.7669s	
17946/33250 (epoch 26.986), train_loss = 0.94617868, grad/param norm = 1.6308e-01, time/batch = 15.3544s	
17947/33250 (epoch 26.988), train_loss = 0.97233721, grad/param norm = 1.6656e-01, time/batch = 14.6039s	
17948/33250 (epoch 26.989), train_loss = 0.96404117, grad/param norm = 1.8898e-01, time/batch = 14.3476s	
17949/33250 (epoch 26.991), train_loss = 0.91588766, grad/param norm = 1.5959e-01, time/batch = 14.9148s	
17950/33250 (epoch 26.992), train_loss = 0.84921513, grad/param norm = 1.5941e-01, time/batch = 17.0273s	
17951/33250 (epoch 26.994), train_loss = 0.85811274, grad/param norm = 1.6103e-01, time/batch = 16.0070s	
17952/33250 (epoch 26.995), train_loss = 0.83414372, grad/param norm = 2.5787e-01, time/batch = 19.1852s	
17953/33250 (epoch 26.997), train_loss = 0.62847544, grad/param norm = 1.4032e-01, time/batch = 17.8109s	
17954/33250 (epoch 26.998), train_loss = 0.91726576, grad/param norm = 1.6357e-01, time/batch = 16.2893s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
17955/33250 (epoch 27.000), train_loss = 0.89421158, grad/param norm = 1.5636e-01, time/batch = 17.0388s	
17956/33250 (epoch 27.002), train_loss = 1.06929258, grad/param norm = 1.6318e-01, time/batch = 16.8563s	
17957/33250 (epoch 27.003), train_loss = 0.96738540, grad/param norm = 1.7454e-01, time/batch = 17.8340s	
17958/33250 (epoch 27.005), train_loss = 0.73551954, grad/param norm = 1.5583e-01, time/batch = 15.1785s	
17959/33250 (epoch 27.006), train_loss = 0.75402776, grad/param norm = 1.4580e-01, time/batch = 15.6092s	
17960/33250 (epoch 27.008), train_loss = 0.97631638, grad/param norm = 1.6608e-01, time/batch = 15.4222s	
17961/33250 (epoch 27.009), train_loss = 1.01922870, grad/param norm = 1.7302e-01, time/batch = 16.9396s	
17962/33250 (epoch 27.011), train_loss = 0.80765032, grad/param norm = 1.4945e-01, time/batch = 16.2009s	
17963/33250 (epoch 27.012), train_loss = 0.89144486, grad/param norm = 2.2134e-01, time/batch = 18.6830s	
17964/33250 (epoch 27.014), train_loss = 0.99101029, grad/param norm = 1.9014e-01, time/batch = 17.5778s	
17965/33250 (epoch 27.015), train_loss = 0.86336398, grad/param norm = 1.5298e-01, time/batch = 18.0281s	
17966/33250 (epoch 27.017), train_loss = 0.91417811, grad/param norm = 2.2306e-01, time/batch = 16.5227s	
17967/33250 (epoch 27.018), train_loss = 0.70888575, grad/param norm = 1.5135e-01, time/batch = 15.7797s	
17968/33250 (epoch 27.020), train_loss = 0.88363787, grad/param norm = 1.4121e-01, time/batch = 16.5060s	
17969/33250 (epoch 27.021), train_loss = 0.92484855, grad/param norm = 1.7185e-01, time/batch = 17.6843s	
17970/33250 (epoch 27.023), train_loss = 0.74377309, grad/param norm = 1.6677e-01, time/batch = 17.8404s	
17971/33250 (epoch 27.024), train_loss = 0.97471304, grad/param norm = 1.7002e-01, time/batch = 16.1586s	
17972/33250 (epoch 27.026), train_loss = 0.89866689, grad/param norm = 1.6207e-01, time/batch = 17.6860s	
17973/33250 (epoch 27.027), train_loss = 0.90671288, grad/param norm = 1.5795e-01, time/batch = 17.6346s	
17974/33250 (epoch 27.029), train_loss = 0.85840514, grad/param norm = 1.5139e-01, time/batch = 16.2131s	
17975/33250 (epoch 27.030), train_loss = 0.88380862, grad/param norm = 1.8113e-01, time/batch = 17.4582s	
17976/33250 (epoch 27.032), train_loss = 1.08331845, grad/param norm = 2.0583e-01, time/batch = 15.7723s	
17977/33250 (epoch 27.033), train_loss = 0.84989633, grad/param norm = 1.9258e-01, time/batch = 15.6241s	
17978/33250 (epoch 27.035), train_loss = 0.87890882, grad/param norm = 1.7492e-01, time/batch = 15.2735s	
17979/33250 (epoch 27.036), train_loss = 0.93584860, grad/param norm = 1.7477e-01, time/batch = 18.8248s	
17980/33250 (epoch 27.038), train_loss = 0.87932654, grad/param norm = 1.4614e-01, time/batch = 15.9307s	
17981/33250 (epoch 27.039), train_loss = 0.80589278, grad/param norm = 1.4889e-01, time/batch = 15.6827s	
17982/33250 (epoch 27.041), train_loss = 0.90983821, grad/param norm = 1.9821e-01, time/batch = 16.3390s	
17983/33250 (epoch 27.042), train_loss = 0.73470819, grad/param norm = 1.3435e-01, time/batch = 17.6345s	
17984/33250 (epoch 27.044), train_loss = 0.99759341, grad/param norm = 1.7369e-01, time/batch = 16.8769s	
17985/33250 (epoch 27.045), train_loss = 0.99100173, grad/param norm = 1.6661e-01, time/batch = 17.1984s	
17986/33250 (epoch 27.047), train_loss = 0.87398093, grad/param norm = 1.6675e-01, time/batch = 15.9266s	
17987/33250 (epoch 27.048), train_loss = 1.00631757, grad/param norm = 1.9854e-01, time/batch = 15.5041s	
17988/33250 (epoch 27.050), train_loss = 0.87513674, grad/param norm = 1.5317e-01, time/batch = 15.5278s	
17989/33250 (epoch 27.051), train_loss = 0.87613805, grad/param norm = 1.6231e-01, time/batch = 31.7954s	
17990/33250 (epoch 27.053), train_loss = 0.90591838, grad/param norm = 1.9305e-01, time/batch = 16.5783s	
17991/33250 (epoch 27.054), train_loss = 0.76049206, grad/param norm = 1.4882e-01, time/batch = 17.1692s	
17992/33250 (epoch 27.056), train_loss = 0.79664496, grad/param norm = 1.6187e-01, time/batch = 15.8680s	
17993/33250 (epoch 27.057), train_loss = 0.97299323, grad/param norm = 1.5786e-01, time/batch = 16.8406s	
17994/33250 (epoch 27.059), train_loss = 0.84566462, grad/param norm = 1.5230e-01, time/batch = 16.4635s	
17995/33250 (epoch 27.060), train_loss = 0.88338441, grad/param norm = 1.7473e-01, time/batch = 15.5269s	
17996/33250 (epoch 27.062), train_loss = 0.96935027, grad/param norm = 1.6402e-01, time/batch = 16.6848s	
17997/33250 (epoch 27.063), train_loss = 1.01398555, grad/param norm = 1.5089e-01, time/batch = 15.8660s	
17998/33250 (epoch 27.065), train_loss = 0.87397564, grad/param norm = 1.4579e-01, time/batch = 16.7628s	
17999/33250 (epoch 27.066), train_loss = 0.91772934, grad/param norm = 1.6588e-01, time/batch = 15.9326s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch27.07_1.5350.t7	
18000/33250 (epoch 27.068), train_loss = 0.84713949, grad/param norm = 1.8394e-01, time/batch = 16.8425s	
18001/33250 (epoch 27.069), train_loss = 1.26487638, grad/param norm = 2.0705e-01, time/batch = 16.1738s	
18002/33250 (epoch 27.071), train_loss = 0.81369254, grad/param norm = 1.4422e-01, time/batch = 16.0327s	
18003/33250 (epoch 27.072), train_loss = 0.82215921, grad/param norm = 1.5659e-01, time/batch = 16.9467s	
18004/33250 (epoch 27.074), train_loss = 0.93358816, grad/param norm = 1.5858e-01, time/batch = 17.6960s	
18005/33250 (epoch 27.075), train_loss = 0.82649655, grad/param norm = 1.5322e-01, time/batch = 19.1066s	
18006/33250 (epoch 27.077), train_loss = 0.87705994, grad/param norm = 1.8897e-01, time/batch = 18.3379s	
18007/33250 (epoch 27.078), train_loss = 0.88415680, grad/param norm = 1.5125e-01, time/batch = 17.0970s	
18008/33250 (epoch 27.080), train_loss = 0.89966121, grad/param norm = 2.1672e-01, time/batch = 15.7608s	
18009/33250 (epoch 27.081), train_loss = 0.92272413, grad/param norm = 1.5663e-01, time/batch = 16.5185s	
18010/33250 (epoch 27.083), train_loss = 1.00718462, grad/param norm = 1.7011e-01, time/batch = 16.5718s	
18011/33250 (epoch 27.084), train_loss = 0.88409466, grad/param norm = 1.6967e-01, time/batch = 16.5250s	
18012/33250 (epoch 27.086), train_loss = 0.87301387, grad/param norm = 1.4411e-01, time/batch = 18.7617s	
18013/33250 (epoch 27.087), train_loss = 0.76465632, grad/param norm = 1.3933e-01, time/batch = 15.6310s	
18014/33250 (epoch 27.089), train_loss = 0.90809482, grad/param norm = 1.5797e-01, time/batch = 16.9534s	
18015/33250 (epoch 27.090), train_loss = 0.90281587, grad/param norm = 1.6722e-01, time/batch = 16.9895s	
18016/33250 (epoch 27.092), train_loss = 0.83631488, grad/param norm = 1.3927e-01, time/batch = 17.8604s	
18017/33250 (epoch 27.093), train_loss = 0.86370105, grad/param norm = 1.4533e-01, time/batch = 16.2625s	
18018/33250 (epoch 27.095), train_loss = 0.84742686, grad/param norm = 1.6185e-01, time/batch = 16.2637s	
18019/33250 (epoch 27.096), train_loss = 0.73021585, grad/param norm = 1.5906e-01, time/batch = 15.1218s	
18020/33250 (epoch 27.098), train_loss = 0.74677378, grad/param norm = 1.6268e-01, time/batch = 17.0117s	
18021/33250 (epoch 27.099), train_loss = 0.69265966, grad/param norm = 1.5173e-01, time/batch = 17.9320s	
18022/33250 (epoch 27.101), train_loss = 0.84832720, grad/param norm = 1.4794e-01, time/batch = 17.4262s	
18023/33250 (epoch 27.102), train_loss = 0.80880579, grad/param norm = 1.5698e-01, time/batch = 17.9536s	
18024/33250 (epoch 27.104), train_loss = 0.66991054, grad/param norm = 1.3159e-01, time/batch = 20.0268s	
18025/33250 (epoch 27.105), train_loss = 0.80378179, grad/param norm = 1.4544e-01, time/batch = 16.9358s	
18026/33250 (epoch 27.107), train_loss = 0.74451927, grad/param norm = 1.3707e-01, time/batch = 16.6046s	
18027/33250 (epoch 27.108), train_loss = 0.85683246, grad/param norm = 1.5315e-01, time/batch = 16.1192s	
18028/33250 (epoch 27.110), train_loss = 0.71879238, grad/param norm = 1.3760e-01, time/batch = 16.8502s	
18029/33250 (epoch 27.111), train_loss = 0.83311244, grad/param norm = 1.4163e-01, time/batch = 16.5079s	
18030/33250 (epoch 27.113), train_loss = 0.81367752, grad/param norm = 1.4953e-01, time/batch = 16.8659s	
18031/33250 (epoch 27.114), train_loss = 0.76880241, grad/param norm = 1.6449e-01, time/batch = 16.6157s	
18032/33250 (epoch 27.116), train_loss = 0.83544925, grad/param norm = 1.6576e-01, time/batch = 16.8454s	
18033/33250 (epoch 27.117), train_loss = 0.81435999, grad/param norm = 1.5805e-01, time/batch = 15.5390s	
18034/33250 (epoch 27.119), train_loss = 0.83837079, grad/param norm = 1.5821e-01, time/batch = 17.9721s	
18035/33250 (epoch 27.120), train_loss = 0.67020267, grad/param norm = 1.4476e-01, time/batch = 18.8510s	
18036/33250 (epoch 27.122), train_loss = 0.95151639, grad/param norm = 1.5666e-01, time/batch = 18.5837s	
18037/33250 (epoch 27.123), train_loss = 0.84503036, grad/param norm = 1.6092e-01, time/batch = 15.6859s	
18038/33250 (epoch 27.125), train_loss = 0.70590740, grad/param norm = 1.5300e-01, time/batch = 17.2491s	
18039/33250 (epoch 27.126), train_loss = 0.84533972, grad/param norm = 1.5685e-01, time/batch = 17.3459s	
18040/33250 (epoch 27.128), train_loss = 0.79964673, grad/param norm = 1.3556e-01, time/batch = 18.0141s	
18041/33250 (epoch 27.129), train_loss = 0.86482072, grad/param norm = 1.4823e-01, time/batch = 16.8562s	
18042/33250 (epoch 27.131), train_loss = 0.84198775, grad/param norm = 1.7204e-01, time/batch = 18.2659s	
18043/33250 (epoch 27.132), train_loss = 0.81788025, grad/param norm = 1.6941e-01, time/batch = 18.3450s	
18044/33250 (epoch 27.134), train_loss = 0.82653300, grad/param norm = 1.6396e-01, time/batch = 17.7053s	
18045/33250 (epoch 27.135), train_loss = 0.85401530, grad/param norm = 1.4781e-01, time/batch = 17.5481s	
18046/33250 (epoch 27.137), train_loss = 0.77237859, grad/param norm = 1.6161e-01, time/batch = 15.4850s	
18047/33250 (epoch 27.138), train_loss = 0.78896161, grad/param norm = 1.4289e-01, time/batch = 18.3441s	
18048/33250 (epoch 27.140), train_loss = 0.67612252, grad/param norm = 1.4775e-01, time/batch = 16.1139s	
18049/33250 (epoch 27.141), train_loss = 0.96848915, grad/param norm = 2.3884e-01, time/batch = 16.8423s	
18050/33250 (epoch 27.143), train_loss = 0.68145749, grad/param norm = 1.4574e-01, time/batch = 16.1879s	
18051/33250 (epoch 27.144), train_loss = 0.81960970, grad/param norm = 1.5530e-01, time/batch = 17.0287s	
18052/33250 (epoch 27.146), train_loss = 0.82643136, grad/param norm = 1.5000e-01, time/batch = 18.2581s	
18053/33250 (epoch 27.147), train_loss = 0.81649749, grad/param norm = 1.5489e-01, time/batch = 16.6094s	
18054/33250 (epoch 27.149), train_loss = 0.78772602, grad/param norm = 1.4610e-01, time/batch = 15.3494s	
18055/33250 (epoch 27.150), train_loss = 0.75107964, grad/param norm = 1.4231e-01, time/batch = 17.6095s	
18056/33250 (epoch 27.152), train_loss = 0.71759504, grad/param norm = 1.5191e-01, time/batch = 17.9958s	
18057/33250 (epoch 27.153), train_loss = 0.97936500, grad/param norm = 1.6950e-01, time/batch = 16.7628s	
18058/33250 (epoch 27.155), train_loss = 0.84611918, grad/param norm = 1.9687e-01, time/batch = 16.1587s	
18059/33250 (epoch 27.156), train_loss = 1.03905171, grad/param norm = 1.6048e-01, time/batch = 14.8626s	
18060/33250 (epoch 27.158), train_loss = 0.99978391, grad/param norm = 1.6916e-01, time/batch = 16.6853s	
18061/33250 (epoch 27.159), train_loss = 0.83331914, grad/param norm = 1.6640e-01, time/batch = 17.6642s	
18062/33250 (epoch 27.161), train_loss = 0.89646874, grad/param norm = 1.6496e-01, time/batch = 17.0141s	
18063/33250 (epoch 27.162), train_loss = 0.76143616, grad/param norm = 1.4841e-01, time/batch = 18.1283s	
18064/33250 (epoch 27.164), train_loss = 0.82776047, grad/param norm = 1.6770e-01, time/batch = 17.6295s	
18065/33250 (epoch 27.165), train_loss = 0.91745689, grad/param norm = 1.8028e-01, time/batch = 17.0903s	
18066/33250 (epoch 27.167), train_loss = 1.00359166, grad/param norm = 1.7839e-01, time/batch = 16.6840s	
18067/33250 (epoch 27.168), train_loss = 0.71814952, grad/param norm = 1.2270e-01, time/batch = 16.3541s	
18068/33250 (epoch 27.170), train_loss = 0.80924543, grad/param norm = 1.6257e-01, time/batch = 17.6760s	
18069/33250 (epoch 27.171), train_loss = 0.84549888, grad/param norm = 1.5058e-01, time/batch = 16.1623s	
18070/33250 (epoch 27.173), train_loss = 0.80704972, grad/param norm = 1.4695e-01, time/batch = 17.0159s	
18071/33250 (epoch 27.174), train_loss = 0.86681410, grad/param norm = 1.5209e-01, time/batch = 16.6998s	
18072/33250 (epoch 27.176), train_loss = 0.81073047, grad/param norm = 1.6285e-01, time/batch = 16.0469s	
18073/33250 (epoch 27.177), train_loss = 0.81238134, grad/param norm = 1.4456e-01, time/batch = 18.4563s	
18074/33250 (epoch 27.179), train_loss = 0.77600128, grad/param norm = 1.5515e-01, time/batch = 16.5413s	
18075/33250 (epoch 27.180), train_loss = 0.68782924, grad/param norm = 1.3760e-01, time/batch = 19.1825s	
18076/33250 (epoch 27.182), train_loss = 0.80979797, grad/param norm = 2.0101e-01, time/batch = 16.2827s	
18077/33250 (epoch 27.183), train_loss = 0.96489915, grad/param norm = 2.0591e-01, time/batch = 17.8336s	
18078/33250 (epoch 27.185), train_loss = 0.90211887, grad/param norm = 1.9240e-01, time/batch = 15.4946s	
18079/33250 (epoch 27.186), train_loss = 0.88347562, grad/param norm = 1.7320e-01, time/batch = 17.0248s	
18080/33250 (epoch 27.188), train_loss = 0.96559726, grad/param norm = 1.9977e-01, time/batch = 17.4351s	
18081/33250 (epoch 27.189), train_loss = 0.69354410, grad/param norm = 1.8249e-01, time/batch = 16.0798s	
18082/33250 (epoch 27.191), train_loss = 0.79648454, grad/param norm = 1.7800e-01, time/batch = 15.6334s	
18083/33250 (epoch 27.192), train_loss = 0.82396570, grad/param norm = 1.4854e-01, time/batch = 18.6220s	
18084/33250 (epoch 27.194), train_loss = 0.84384726, grad/param norm = 1.7203e-01, time/batch = 18.6016s	
18085/33250 (epoch 27.195), train_loss = 1.01787108, grad/param norm = 1.7181e-01, time/batch = 18.0114s	
18086/33250 (epoch 27.197), train_loss = 0.79588337, grad/param norm = 1.5716e-01, time/batch = 16.5324s	
18087/33250 (epoch 27.198), train_loss = 0.98553789, grad/param norm = 1.6826e-01, time/batch = 16.1706s	
18088/33250 (epoch 27.200), train_loss = 0.86125981, grad/param norm = 1.5396e-01, time/batch = 15.6278s	
18089/33250 (epoch 27.202), train_loss = 0.80412077, grad/param norm = 1.3860e-01, time/batch = 15.2586s	
18090/33250 (epoch 27.203), train_loss = 0.79000075, grad/param norm = 1.7578e-01, time/batch = 15.4874s	
18091/33250 (epoch 27.205), train_loss = 0.90411425, grad/param norm = 1.5812e-01, time/batch = 16.6834s	
18092/33250 (epoch 27.206), train_loss = 0.90831234, grad/param norm = 1.6033e-01, time/batch = 16.0299s	
18093/33250 (epoch 27.208), train_loss = 0.95382381, grad/param norm = 1.9888e-01, time/batch = 17.9334s	
18094/33250 (epoch 27.209), train_loss = 0.77254739, grad/param norm = 1.3380e-01, time/batch = 15.5532s	
18095/33250 (epoch 27.211), train_loss = 0.88947137, grad/param norm = 1.6470e-01, time/batch = 17.2629s	
18096/33250 (epoch 27.212), train_loss = 1.02906041, grad/param norm = 1.6906e-01, time/batch = 15.0267s	
18097/33250 (epoch 27.214), train_loss = 0.88126669, grad/param norm = 1.5702e-01, time/batch = 15.2615s	
18098/33250 (epoch 27.215), train_loss = 1.00652082, grad/param norm = 2.2747e-01, time/batch = 15.3626s	
18099/33250 (epoch 27.217), train_loss = 0.95847264, grad/param norm = 1.8450e-01, time/batch = 15.2730s	
18100/33250 (epoch 27.218), train_loss = 0.96613097, grad/param norm = 1.6321e-01, time/batch = 15.5152s	
18101/33250 (epoch 27.220), train_loss = 0.89133969, grad/param norm = 1.7061e-01, time/batch = 16.5226s	
18102/33250 (epoch 27.221), train_loss = 1.04880503, grad/param norm = 2.1410e-01, time/batch = 19.1778s	
18103/33250 (epoch 27.223), train_loss = 0.86578249, grad/param norm = 1.4955e-01, time/batch = 16.5084s	
18104/33250 (epoch 27.224), train_loss = 0.93331141, grad/param norm = 1.8249e-01, time/batch = 18.1968s	
18105/33250 (epoch 27.226), train_loss = 1.00224448, grad/param norm = 1.6975e-01, time/batch = 16.4293s	
18106/33250 (epoch 27.227), train_loss = 0.91676198, grad/param norm = 1.6960e-01, time/batch = 17.0795s	
18107/33250 (epoch 27.229), train_loss = 0.86570134, grad/param norm = 1.5497e-01, time/batch = 15.2794s	
18108/33250 (epoch 27.230), train_loss = 0.88209725, grad/param norm = 1.6609e-01, time/batch = 15.4322s	
18109/33250 (epoch 27.232), train_loss = 0.81593556, grad/param norm = 1.4474e-01, time/batch = 16.1715s	
18110/33250 (epoch 27.233), train_loss = 0.79333105, grad/param norm = 1.4895e-01, time/batch = 15.1063s	
18111/33250 (epoch 27.235), train_loss = 0.99669128, grad/param norm = 1.5455e-01, time/batch = 15.6968s	
18112/33250 (epoch 27.236), train_loss = 0.82104035, grad/param norm = 1.7341e-01, time/batch = 15.4245s	
18113/33250 (epoch 27.238), train_loss = 0.96944248, grad/param norm = 1.7808e-01, time/batch = 17.8548s	
18114/33250 (epoch 27.239), train_loss = 0.99337092, grad/param norm = 2.1428e-01, time/batch = 15.7711s	
18115/33250 (epoch 27.241), train_loss = 0.98593381, grad/param norm = 1.9987e-01, time/batch = 17.6017s	
18116/33250 (epoch 27.242), train_loss = 0.98948435, grad/param norm = 1.8800e-01, time/batch = 16.0450s	
18117/33250 (epoch 27.244), train_loss = 0.94090818, grad/param norm = 2.0545e-01, time/batch = 15.2719s	
18118/33250 (epoch 27.245), train_loss = 0.90777202, grad/param norm = 1.6971e-01, time/batch = 15.3544s	
18119/33250 (epoch 27.247), train_loss = 0.88374633, grad/param norm = 1.4757e-01, time/batch = 16.1802s	
18120/33250 (epoch 27.248), train_loss = 1.03599690, grad/param norm = 1.8517e-01, time/batch = 15.3474s	
18121/33250 (epoch 27.250), train_loss = 0.97611713, grad/param norm = 1.5853e-01, time/batch = 16.9205s	
18122/33250 (epoch 27.251), train_loss = 0.84342998, grad/param norm = 1.5006e-01, time/batch = 16.3467s	
18123/33250 (epoch 27.253), train_loss = 0.83532531, grad/param norm = 1.3715e-01, time/batch = 18.2756s	
18124/33250 (epoch 27.254), train_loss = 0.81674940, grad/param norm = 1.6805e-01, time/batch = 15.9448s	
18125/33250 (epoch 27.256), train_loss = 0.87749858, grad/param norm = 1.5315e-01, time/batch = 18.2703s	
18126/33250 (epoch 27.257), train_loss = 1.01062226, grad/param norm = 1.7539e-01, time/batch = 16.2759s	
18127/33250 (epoch 27.259), train_loss = 0.92565988, grad/param norm = 1.8607e-01, time/batch = 16.3288s	
18128/33250 (epoch 27.260), train_loss = 0.72735256, grad/param norm = 1.5231e-01, time/batch = 16.7648s	
18129/33250 (epoch 27.262), train_loss = 0.90335234, grad/param norm = 1.5495e-01, time/batch = 16.9371s	
18130/33250 (epoch 27.263), train_loss = 0.77793292, grad/param norm = 1.7560e-01, time/batch = 16.1708s	
18131/33250 (epoch 27.265), train_loss = 0.93310931, grad/param norm = 1.6985e-01, time/batch = 16.1887s	
18132/33250 (epoch 27.266), train_loss = 0.84981433, grad/param norm = 1.6744e-01, time/batch = 15.4423s	
18133/33250 (epoch 27.268), train_loss = 0.78550964, grad/param norm = 1.5669e-01, time/batch = 17.4933s	
18134/33250 (epoch 27.269), train_loss = 0.72903302, grad/param norm = 1.5018e-01, time/batch = 18.5992s	
18135/33250 (epoch 27.271), train_loss = 0.87001174, grad/param norm = 1.4022e-01, time/batch = 17.8397s	
18136/33250 (epoch 27.272), train_loss = 0.78697088, grad/param norm = 1.3862e-01, time/batch = 16.4566s	
18137/33250 (epoch 27.274), train_loss = 0.65339903, grad/param norm = 1.2943e-01, time/batch = 16.6936s	
18138/33250 (epoch 27.275), train_loss = 0.78778331, grad/param norm = 1.2294e-01, time/batch = 17.1054s	
18139/33250 (epoch 27.277), train_loss = 0.68345696, grad/param norm = 1.5264e-01, time/batch = 15.6793s	
18140/33250 (epoch 27.278), train_loss = 0.78758837, grad/param norm = 1.6157e-01, time/batch = 15.9965s	
18141/33250 (epoch 27.280), train_loss = 0.76591634, grad/param norm = 1.4285e-01, time/batch = 16.0318s	
18142/33250 (epoch 27.281), train_loss = 0.89826721, grad/param norm = 1.7187e-01, time/batch = 17.3395s	
18143/33250 (epoch 27.283), train_loss = 0.90089023, grad/param norm = 2.2569e-01, time/batch = 16.0246s	
18144/33250 (epoch 27.284), train_loss = 0.78609317, grad/param norm = 1.7535e-01, time/batch = 16.3753s	
18145/33250 (epoch 27.286), train_loss = 0.91051072, grad/param norm = 1.7418e-01, time/batch = 19.4423s	
18146/33250 (epoch 27.287), train_loss = 0.74849628, grad/param norm = 1.4111e-01, time/batch = 17.1750s	
18147/33250 (epoch 27.289), train_loss = 0.69376209, grad/param norm = 1.6266e-01, time/batch = 15.9405s	
18148/33250 (epoch 27.290), train_loss = 0.84068513, grad/param norm = 1.7458e-01, time/batch = 15.7833s	
18149/33250 (epoch 27.292), train_loss = 0.92560235, grad/param norm = 1.9803e-01, time/batch = 15.1017s	
18150/33250 (epoch 27.293), train_loss = 0.97172155, grad/param norm = 1.9425e-01, time/batch = 16.1726s	
18151/33250 (epoch 27.295), train_loss = 0.94174528, grad/param norm = 1.6418e-01, time/batch = 17.3168s	
18152/33250 (epoch 27.296), train_loss = 0.86878132, grad/param norm = 1.5679e-01, time/batch = 15.7666s	
18153/33250 (epoch 27.298), train_loss = 0.72136902, grad/param norm = 1.5219e-01, time/batch = 17.4171s	
18154/33250 (epoch 27.299), train_loss = 0.70863799, grad/param norm = 1.4995e-01, time/batch = 16.6062s	
18155/33250 (epoch 27.301), train_loss = 0.94949872, grad/param norm = 1.6323e-01, time/batch = 18.2842s	
18156/33250 (epoch 27.302), train_loss = 0.91429251, grad/param norm = 1.8122e-01, time/batch = 18.0282s	
18157/33250 (epoch 27.304), train_loss = 0.77843242, grad/param norm = 1.3723e-01, time/batch = 15.6581s	
18158/33250 (epoch 27.305), train_loss = 0.81528941, grad/param norm = 1.4739e-01, time/batch = 15.0253s	
18159/33250 (epoch 27.307), train_loss = 0.90892646, grad/param norm = 1.6587e-01, time/batch = 15.3417s	
18160/33250 (epoch 27.308), train_loss = 0.98507962, grad/param norm = 1.9525e-01, time/batch = 15.8418s	
18161/33250 (epoch 27.310), train_loss = 0.82943808, grad/param norm = 1.8035e-01, time/batch = 15.7328s	
18162/33250 (epoch 27.311), train_loss = 0.99559395, grad/param norm = 1.7080e-01, time/batch = 15.9369s	
18163/33250 (epoch 27.313), train_loss = 0.74857139, grad/param norm = 1.6648e-01, time/batch = 15.0362s	
18164/33250 (epoch 27.314), train_loss = 0.88358770, grad/param norm = 1.5397e-01, time/batch = 16.8448s	
18165/33250 (epoch 27.316), train_loss = 1.02769111, grad/param norm = 1.8540e-01, time/batch = 16.6173s	
18166/33250 (epoch 27.317), train_loss = 0.77768202, grad/param norm = 1.4452e-01, time/batch = 15.4359s	
18167/33250 (epoch 27.319), train_loss = 0.92614529, grad/param norm = 1.9680e-01, time/batch = 18.1954s	
18168/33250 (epoch 27.320), train_loss = 0.96387583, grad/param norm = 2.1597e-01, time/batch = 15.9440s	
18169/33250 (epoch 27.322), train_loss = 0.99924457, grad/param norm = 1.9113e-01, time/batch = 15.9565s	
18170/33250 (epoch 27.323), train_loss = 1.02585152, grad/param norm = 2.0613e-01, time/batch = 16.5911s	
18171/33250 (epoch 27.325), train_loss = 0.86590424, grad/param norm = 1.9551e-01, time/batch = 15.6943s	
18172/33250 (epoch 27.326), train_loss = 1.04814452, grad/param norm = 1.8164e-01, time/batch = 15.5070s	
18173/33250 (epoch 27.328), train_loss = 0.84369968, grad/param norm = 1.4373e-01, time/batch = 16.1047s	
18174/33250 (epoch 27.329), train_loss = 0.87700621, grad/param norm = 1.7702e-01, time/batch = 14.7105s	
18175/33250 (epoch 27.331), train_loss = 0.84941530, grad/param norm = 1.6537e-01, time/batch = 17.9287s	
18176/33250 (epoch 27.332), train_loss = 0.85918936, grad/param norm = 1.5581e-01, time/batch = 15.7669s	
18177/33250 (epoch 27.334), train_loss = 1.01877006, grad/param norm = 1.6246e-01, time/batch = 17.2098s	
18178/33250 (epoch 27.335), train_loss = 0.64252462, grad/param norm = 1.4280e-01, time/batch = 17.6281s	
18179/33250 (epoch 27.337), train_loss = 0.91560144, grad/param norm = 1.5097e-01, time/batch = 15.3615s	
18180/33250 (epoch 27.338), train_loss = 0.97477777, grad/param norm = 1.5840e-01, time/batch = 15.0362s	
18181/33250 (epoch 27.340), train_loss = 0.88120769, grad/param norm = 1.5160e-01, time/batch = 15.6067s	
18182/33250 (epoch 27.341), train_loss = 0.81563961, grad/param norm = 1.5565e-01, time/batch = 15.8500s	
18183/33250 (epoch 27.343), train_loss = 0.82823507, grad/param norm = 1.6400e-01, time/batch = 15.0007s	
18184/33250 (epoch 27.344), train_loss = 0.84293303, grad/param norm = 1.4359e-01, time/batch = 16.5895s	
18185/33250 (epoch 27.346), train_loss = 0.77101756, grad/param norm = 1.3957e-01, time/batch = 18.6016s	
18186/33250 (epoch 27.347), train_loss = 1.05930972, grad/param norm = 1.9916e-01, time/batch = 17.4531s	
18187/33250 (epoch 27.349), train_loss = 0.80726209, grad/param norm = 1.7654e-01, time/batch = 16.8832s	
18188/33250 (epoch 27.350), train_loss = 0.85073619, grad/param norm = 1.6597e-01, time/batch = 15.4232s	
18189/33250 (epoch 27.352), train_loss = 0.76885293, grad/param norm = 1.4993e-01, time/batch = 15.2748s	
18190/33250 (epoch 27.353), train_loss = 0.82713975, grad/param norm = 1.5156e-01, time/batch = 15.0239s	
18191/33250 (epoch 27.355), train_loss = 0.83829846, grad/param norm = 1.6704e-01, time/batch = 17.0085s	
18192/33250 (epoch 27.356), train_loss = 0.77628695, grad/param norm = 1.5290e-01, time/batch = 16.8331s	
18193/33250 (epoch 27.358), train_loss = 0.81055006, grad/param norm = 1.3204e-01, time/batch = 17.6793s	
18194/33250 (epoch 27.359), train_loss = 0.81128697, grad/param norm = 1.4912e-01, time/batch = 31.6299s	
18195/33250 (epoch 27.361), train_loss = 0.98917350, grad/param norm = 1.7911e-01, time/batch = 17.5355s	
18196/33250 (epoch 27.362), train_loss = 0.89010569, grad/param norm = 1.6726e-01, time/batch = 18.5103s	
18197/33250 (epoch 27.364), train_loss = 0.93668618, grad/param norm = 1.7542e-01, time/batch = 15.4397s	
18198/33250 (epoch 27.365), train_loss = 0.85872121, grad/param norm = 1.5714e-01, time/batch = 15.1078s	
18199/33250 (epoch 27.367), train_loss = 0.87591044, grad/param norm = 1.5407e-01, time/batch = 15.9413s	
18200/33250 (epoch 27.368), train_loss = 0.86223914, grad/param norm = 1.6455e-01, time/batch = 15.3298s	
18201/33250 (epoch 27.370), train_loss = 0.77736116, grad/param norm = 1.4923e-01, time/batch = 16.5074s	
18202/33250 (epoch 27.371), train_loss = 0.97721969, grad/param norm = 1.5802e-01, time/batch = 15.1075s	
18203/33250 (epoch 27.373), train_loss = 0.81817396, grad/param norm = 1.4131e-01, time/batch = 18.5044s	
18204/33250 (epoch 27.374), train_loss = 0.89563234, grad/param norm = 1.9350e-01, time/batch = 15.3625s	
18205/33250 (epoch 27.376), train_loss = 0.85539210, grad/param norm = 1.6584e-01, time/batch = 17.3403s	
18206/33250 (epoch 27.377), train_loss = 0.74699627, grad/param norm = 1.6262e-01, time/batch = 16.9504s	
18207/33250 (epoch 27.379), train_loss = 0.84666496, grad/param norm = 1.6894e-01, time/batch = 17.4431s	
18208/33250 (epoch 27.380), train_loss = 0.88305815, grad/param norm = 1.8207e-01, time/batch = 17.0179s	
18209/33250 (epoch 27.382), train_loss = 0.89380503, grad/param norm = 1.7833e-01, time/batch = 17.1828s	
18210/33250 (epoch 27.383), train_loss = 0.77690627, grad/param norm = 1.5565e-01, time/batch = 16.6189s	
18211/33250 (epoch 27.385), train_loss = 0.73150911, grad/param norm = 1.5561e-01, time/batch = 15.9038s	
18212/33250 (epoch 27.386), train_loss = 0.77977819, grad/param norm = 1.7348e-01, time/batch = 17.1067s	
18213/33250 (epoch 27.388), train_loss = 0.77568265, grad/param norm = 1.5334e-01, time/batch = 17.0129s	
18214/33250 (epoch 27.389), train_loss = 0.83273594, grad/param norm = 1.7308e-01, time/batch = 16.0970s	
18215/33250 (epoch 27.391), train_loss = 0.91119121, grad/param norm = 1.5234e-01, time/batch = 17.4177s	
18216/33250 (epoch 27.392), train_loss = 0.92037880, grad/param norm = 1.7483e-01, time/batch = 17.4925s	
18217/33250 (epoch 27.394), train_loss = 0.95444391, grad/param norm = 1.6934e-01, time/batch = 17.0196s	
18218/33250 (epoch 27.395), train_loss = 0.93910580, grad/param norm = 1.6642e-01, time/batch = 16.7010s	
18219/33250 (epoch 27.397), train_loss = 0.96246043, grad/param norm = 1.6463e-01, time/batch = 18.4202s	
18220/33250 (epoch 27.398), train_loss = 0.80784713, grad/param norm = 1.5861e-01, time/batch = 15.0996s	
18221/33250 (epoch 27.400), train_loss = 0.75762701, grad/param norm = 1.3535e-01, time/batch = 15.7605s	
18222/33250 (epoch 27.402), train_loss = 0.72485749, grad/param norm = 1.7073e-01, time/batch = 14.8592s	
18223/33250 (epoch 27.403), train_loss = 0.85063449, grad/param norm = 1.8533e-01, time/batch = 15.7039s	
18224/33250 (epoch 27.405), train_loss = 0.79612116, grad/param norm = 1.3711e-01, time/batch = 15.6139s	
18225/33250 (epoch 27.406), train_loss = 0.85893716, grad/param norm = 1.6028e-01, time/batch = 16.1905s	
18226/33250 (epoch 27.408), train_loss = 1.01329867, grad/param norm = 1.8101e-01, time/batch = 16.2826s	
18227/33250 (epoch 27.409), train_loss = 0.89872256, grad/param norm = 2.1173e-01, time/batch = 18.3405s	
18228/33250 (epoch 27.411), train_loss = 0.64504674, grad/param norm = 1.3236e-01, time/batch = 16.7812s	
18229/33250 (epoch 27.412), train_loss = 0.70717021, grad/param norm = 1.4518e-01, time/batch = 15.2711s	
18230/33250 (epoch 27.414), train_loss = 0.89510935, grad/param norm = 1.5980e-01, time/batch = 16.6892s	
18231/33250 (epoch 27.415), train_loss = 0.94937335, grad/param norm = 1.9724e-01, time/batch = 15.4900s	
18232/33250 (epoch 27.417), train_loss = 0.95395761, grad/param norm = 1.7498e-01, time/batch = 15.6873s	
18233/33250 (epoch 27.418), train_loss = 1.10091362, grad/param norm = 1.9510e-01, time/batch = 16.5201s	
18234/33250 (epoch 27.420), train_loss = 0.95613530, grad/param norm = 1.7068e-01, time/batch = 15.5144s	
18235/33250 (epoch 27.421), train_loss = 0.80567197, grad/param norm = 1.6523e-01, time/batch = 16.1030s	
18236/33250 (epoch 27.423), train_loss = 0.91114838, grad/param norm = 2.0586e-01, time/batch = 15.9580s	
18237/33250 (epoch 27.424), train_loss = 1.01479897, grad/param norm = 2.7716e-01, time/batch = 16.1109s	
18238/33250 (epoch 27.426), train_loss = 0.82308379, grad/param norm = 1.4994e-01, time/batch = 17.2700s	
18239/33250 (epoch 27.427), train_loss = 0.81524223, grad/param norm = 1.6841e-01, time/batch = 16.1961s	
18240/33250 (epoch 27.429), train_loss = 0.91319490, grad/param norm = 1.8582e-01, time/batch = 15.2654s	
18241/33250 (epoch 27.430), train_loss = 0.80564294, grad/param norm = 1.6665e-01, time/batch = 16.6032s	
18242/33250 (epoch 27.432), train_loss = 0.91382293, grad/param norm = 1.6201e-01, time/batch = 15.0269s	
18243/33250 (epoch 27.433), train_loss = 0.80253737, grad/param norm = 1.5460e-01, time/batch = 15.5966s	
18244/33250 (epoch 27.435), train_loss = 0.95902142, grad/param norm = 1.8490e-01, time/batch = 15.8216s	
18245/33250 (epoch 27.436), train_loss = 0.81825334, grad/param norm = 1.8153e-01, time/batch = 15.9351s	
18246/33250 (epoch 27.438), train_loss = 0.97006176, grad/param norm = 1.9209e-01, time/batch = 17.1868s	
18247/33250 (epoch 27.439), train_loss = 0.88149150, grad/param norm = 1.4902e-01, time/batch = 17.9319s	
18248/33250 (epoch 27.441), train_loss = 0.83992940, grad/param norm = 1.4154e-01, time/batch = 15.7671s	
18249/33250 (epoch 27.442), train_loss = 0.79054736, grad/param norm = 1.6997e-01, time/batch = 16.7784s	
18250/33250 (epoch 27.444), train_loss = 0.82699382, grad/param norm = 1.4716e-01, time/batch = 15.6898s	
18251/33250 (epoch 27.445), train_loss = 0.88304185, grad/param norm = 1.4493e-01, time/batch = 15.4257s	
18252/33250 (epoch 27.447), train_loss = 0.79689450, grad/param norm = 1.5762e-01, time/batch = 16.3404s	
18253/33250 (epoch 27.448), train_loss = 0.88416177, grad/param norm = 1.4372e-01, time/batch = 16.6000s	
18254/33250 (epoch 27.450), train_loss = 1.01063517, grad/param norm = 1.9919e-01, time/batch = 16.2624s	
18255/33250 (epoch 27.451), train_loss = 0.93082513, grad/param norm = 2.0328e-01, time/batch = 15.5111s	
18256/33250 (epoch 27.453), train_loss = 0.78318642, grad/param norm = 1.3999e-01, time/batch = 17.9457s	
18257/33250 (epoch 27.454), train_loss = 0.99622706, grad/param norm = 1.6687e-01, time/batch = 19.7644s	
18258/33250 (epoch 27.456), train_loss = 0.99130846, grad/param norm = 1.3811e-01, time/batch = 15.7766s	
18259/33250 (epoch 27.457), train_loss = 0.83442321, grad/param norm = 1.7111e-01, time/batch = 17.1805s	
18260/33250 (epoch 27.459), train_loss = 0.91580350, grad/param norm = 1.6088e-01, time/batch = 15.1667s	
18261/33250 (epoch 27.460), train_loss = 0.94364954, grad/param norm = 1.7929e-01, time/batch = 15.4982s	
18262/33250 (epoch 27.462), train_loss = 0.82387077, grad/param norm = 1.4335e-01, time/batch = 15.4731s	
18263/33250 (epoch 27.463), train_loss = 0.79778523, grad/param norm = 1.2917e-01, time/batch = 15.4874s	
18264/33250 (epoch 27.465), train_loss = 0.72409896, grad/param norm = 1.2804e-01, time/batch = 14.8467s	
18265/33250 (epoch 27.466), train_loss = 0.69459470, grad/param norm = 1.1746e-01, time/batch = 14.7324s	
18266/33250 (epoch 27.468), train_loss = 0.76005646, grad/param norm = 1.3350e-01, time/batch = 15.2584s	
18267/33250 (epoch 27.469), train_loss = 0.83186960, grad/param norm = 1.6590e-01, time/batch = 18.8363s	
18268/33250 (epoch 27.471), train_loss = 0.93603150, grad/param norm = 1.5392e-01, time/batch = 16.6822s	
18269/33250 (epoch 27.472), train_loss = 0.81374103, grad/param norm = 1.6310e-01, time/batch = 17.5296s	
18270/33250 (epoch 27.474), train_loss = 0.98995836, grad/param norm = 1.6861e-01, time/batch = 16.4185s	
18271/33250 (epoch 27.475), train_loss = 0.89964413, grad/param norm = 1.5387e-01, time/batch = 16.8343s	
18272/33250 (epoch 27.477), train_loss = 0.85704952, grad/param norm = 1.4473e-01, time/batch = 16.0183s	
18273/33250 (epoch 27.478), train_loss = 0.78463349, grad/param norm = 1.5603e-01, time/batch = 15.3461s	
18274/33250 (epoch 27.480), train_loss = 1.00100874, grad/param norm = 1.7229e-01, time/batch = 15.8656s	
18275/33250 (epoch 27.481), train_loss = 0.88584825, grad/param norm = 1.5343e-01, time/batch = 14.8733s	
18276/33250 (epoch 27.483), train_loss = 0.84701062, grad/param norm = 1.4439e-01, time/batch = 17.2668s	
18277/33250 (epoch 27.484), train_loss = 0.77940432, grad/param norm = 1.3997e-01, time/batch = 16.9224s	
18278/33250 (epoch 27.486), train_loss = 0.74488341, grad/param norm = 1.8469e-01, time/batch = 17.7736s	
18279/33250 (epoch 27.487), train_loss = 0.81536721, grad/param norm = 1.6571e-01, time/batch = 16.8657s	
18280/33250 (epoch 27.489), train_loss = 0.96726330, grad/param norm = 1.9717e-01, time/batch = 15.5289s	
18281/33250 (epoch 27.490), train_loss = 0.91308531, grad/param norm = 1.7545e-01, time/batch = 16.7614s	
18282/33250 (epoch 27.492), train_loss = 0.95672932, grad/param norm = 1.7667e-01, time/batch = 16.7528s	
18283/33250 (epoch 27.493), train_loss = 0.85771732, grad/param norm = 1.6936e-01, time/batch = 15.3623s	
18284/33250 (epoch 27.495), train_loss = 0.92056602, grad/param norm = 1.4963e-01, time/batch = 15.4894s	
18285/33250 (epoch 27.496), train_loss = 0.89191131, grad/param norm = 1.3740e-01, time/batch = 15.6915s	
18286/33250 (epoch 27.498), train_loss = 0.95346378, grad/param norm = 1.5502e-01, time/batch = 17.0187s	
18287/33250 (epoch 27.499), train_loss = 0.81492488, grad/param norm = 1.5186e-01, time/batch = 18.1849s	
18288/33250 (epoch 27.501), train_loss = 0.81257744, grad/param norm = 1.5844e-01, time/batch = 16.9473s	
18289/33250 (epoch 27.502), train_loss = 0.82283055, grad/param norm = 1.4420e-01, time/batch = 16.4905s	
18290/33250 (epoch 27.504), train_loss = 1.01202284, grad/param norm = 1.9025e-01, time/batch = 16.0241s	
18291/33250 (epoch 27.505), train_loss = 0.72094312, grad/param norm = 1.2452e-01, time/batch = 16.0295s	
18292/33250 (epoch 27.507), train_loss = 0.79999972, grad/param norm = 1.6298e-01, time/batch = 15.4448s	
18293/33250 (epoch 27.508), train_loss = 0.82531721, grad/param norm = 1.4290e-01, time/batch = 15.0270s	
18294/33250 (epoch 27.510), train_loss = 0.69826197, grad/param norm = 1.2466e-01, time/batch = 15.1793s	
18295/33250 (epoch 27.511), train_loss = 0.86613368, grad/param norm = 1.7032e-01, time/batch = 15.5096s	
18296/33250 (epoch 27.513), train_loss = 0.98847101, grad/param norm = 1.4803e-01, time/batch = 15.9372s	
18297/33250 (epoch 27.514), train_loss = 0.84395422, grad/param norm = 1.5574e-01, time/batch = 17.6165s	
18298/33250 (epoch 27.516), train_loss = 0.79774233, grad/param norm = 1.6018e-01, time/batch = 17.2002s	
18299/33250 (epoch 27.517), train_loss = 0.82673188, grad/param norm = 1.5132e-01, time/batch = 16.9394s	
18300/33250 (epoch 27.519), train_loss = 0.74778579, grad/param norm = 1.2213e-01, time/batch = 15.8612s	
18301/33250 (epoch 27.520), train_loss = 1.05907210, grad/param norm = 1.8196e-01, time/batch = 15.2030s	
18302/33250 (epoch 27.522), train_loss = 0.94117953, grad/param norm = 1.6764e-01, time/batch = 15.9259s	
18303/33250 (epoch 27.523), train_loss = 0.78351401, grad/param norm = 1.4500e-01, time/batch = 15.1875s	
18304/33250 (epoch 27.525), train_loss = 0.75258213, grad/param norm = 1.6037e-01, time/batch = 15.0380s	
18305/33250 (epoch 27.526), train_loss = 0.77543481, grad/param norm = 1.4552e-01, time/batch = 15.2794s	
18306/33250 (epoch 27.528), train_loss = 0.81747799, grad/param norm = 1.4626e-01, time/batch = 15.2545s	
18307/33250 (epoch 27.529), train_loss = 0.79862832, grad/param norm = 1.5759e-01, time/batch = 16.2030s	
18308/33250 (epoch 27.531), train_loss = 0.75945481, grad/param norm = 1.4156e-01, time/batch = 17.5065s	
18309/33250 (epoch 27.532), train_loss = 0.89382165, grad/param norm = 1.4618e-01, time/batch = 16.7018s	
18310/33250 (epoch 27.534), train_loss = 0.77476741, grad/param norm = 1.4795e-01, time/batch = 15.5690s	
18311/33250 (epoch 27.535), train_loss = 0.83920805, grad/param norm = 1.4875e-01, time/batch = 17.0889s	
18312/33250 (epoch 27.537), train_loss = 0.87831010, grad/param norm = 1.5312e-01, time/batch = 16.9390s	
18313/33250 (epoch 27.538), train_loss = 0.90734008, grad/param norm = 1.5045e-01, time/batch = 16.6080s	
18314/33250 (epoch 27.540), train_loss = 0.99466665, grad/param norm = 1.5436e-01, time/batch = 15.7827s	
18315/33250 (epoch 27.541), train_loss = 0.96268724, grad/param norm = 1.9860e-01, time/batch = 18.0873s	
18316/33250 (epoch 27.543), train_loss = 0.91466467, grad/param norm = 1.5390e-01, time/batch = 16.1549s	
18317/33250 (epoch 27.544), train_loss = 0.79559402, grad/param norm = 1.6040e-01, time/batch = 16.3369s	
18318/33250 (epoch 27.546), train_loss = 0.83762503, grad/param norm = 1.7309e-01, time/batch = 19.0102s	
18319/33250 (epoch 27.547), train_loss = 0.84039909, grad/param norm = 1.7516e-01, time/batch = 16.9489s	
18320/33250 (epoch 27.549), train_loss = 0.88396207, grad/param norm = 1.6159e-01, time/batch = 18.1535s	
18321/33250 (epoch 27.550), train_loss = 0.82045009, grad/param norm = 1.5517e-01, time/batch = 18.4177s	
18322/33250 (epoch 27.552), train_loss = 0.93034493, grad/param norm = 1.8261e-01, time/batch = 16.5453s	
18323/33250 (epoch 27.553), train_loss = 0.82232819, grad/param norm = 1.4744e-01, time/batch = 17.6012s	
18324/33250 (epoch 27.555), train_loss = 0.90014452, grad/param norm = 1.6408e-01, time/batch = 15.2750s	
18325/33250 (epoch 27.556), train_loss = 0.89458624, grad/param norm = 1.9859e-01, time/batch = 15.7631s	
18326/33250 (epoch 27.558), train_loss = 0.92760658, grad/param norm = 1.9736e-01, time/batch = 15.2550s	
18327/33250 (epoch 27.559), train_loss = 0.79534546, grad/param norm = 1.5024e-01, time/batch = 16.3496s	
18328/33250 (epoch 27.561), train_loss = 0.75743334, grad/param norm = 1.3402e-01, time/batch = 15.2721s	
18329/33250 (epoch 27.562), train_loss = 0.90576510, grad/param norm = 1.6880e-01, time/batch = 16.7564s	
18330/33250 (epoch 27.564), train_loss = 1.03888612, grad/param norm = 1.9054e-01, time/batch = 15.0388s	
18331/33250 (epoch 27.565), train_loss = 1.00397812, grad/param norm = 1.8886e-01, time/batch = 17.4309s	
18332/33250 (epoch 27.567), train_loss = 0.98504249, grad/param norm = 1.7663e-01, time/batch = 17.4451s	
18333/33250 (epoch 27.568), train_loss = 0.85263575, grad/param norm = 1.7882e-01, time/batch = 18.2660s	
18334/33250 (epoch 27.570), train_loss = 0.97088970, grad/param norm = 1.9280e-01, time/batch = 18.9366s	
18335/33250 (epoch 27.571), train_loss = 1.00903504, grad/param norm = 1.5884e-01, time/batch = 15.5107s	
18336/33250 (epoch 27.573), train_loss = 0.91104684, grad/param norm = 1.5877e-01, time/batch = 16.2591s	
18337/33250 (epoch 27.574), train_loss = 0.80161814, grad/param norm = 1.5173e-01, time/batch = 16.1025s	
18338/33250 (epoch 27.576), train_loss = 0.93271029, grad/param norm = 1.6899e-01, time/batch = 15.1868s	
18339/33250 (epoch 27.577), train_loss = 0.86401885, grad/param norm = 1.5736e-01, time/batch = 15.4240s	
18340/33250 (epoch 27.579), train_loss = 0.77603891, grad/param norm = 1.7107e-01, time/batch = 15.9501s	
18341/33250 (epoch 27.580), train_loss = 0.82377168, grad/param norm = 1.3665e-01, time/batch = 17.1973s	
18342/33250 (epoch 27.582), train_loss = 0.85159723, grad/param norm = 1.8486e-01, time/batch = 16.6858s	
18343/33250 (epoch 27.583), train_loss = 0.96592496, grad/param norm = 1.7303e-01, time/batch = 16.3517s	
18344/33250 (epoch 27.585), train_loss = 0.97282737, grad/param norm = 1.6003e-01, time/batch = 16.2063s	
18345/33250 (epoch 27.586), train_loss = 0.79806786, grad/param norm = 1.6930e-01, time/batch = 17.6030s	
18346/33250 (epoch 27.588), train_loss = 0.90965158, grad/param norm = 1.7408e-01, time/batch = 15.6864s	
18347/33250 (epoch 27.589), train_loss = 0.88101651, grad/param norm = 1.5288e-01, time/batch = 16.2548s	
18348/33250 (epoch 27.591), train_loss = 0.86389233, grad/param norm = 2.0344e-01, time/batch = 15.1935s	
18349/33250 (epoch 27.592), train_loss = 0.85441714, grad/param norm = 1.5856e-01, time/batch = 14.3032s	
18350/33250 (epoch 27.594), train_loss = 0.98770720, grad/param norm = 1.7483e-01, time/batch = 14.7747s	
18351/33250 (epoch 27.595), train_loss = 0.89035161, grad/param norm = 1.5810e-01, time/batch = 15.9396s	
18352/33250 (epoch 27.597), train_loss = 0.74333858, grad/param norm = 1.4033e-01, time/batch = 18.1999s	
18353/33250 (epoch 27.598), train_loss = 0.82874328, grad/param norm = 1.6860e-01, time/batch = 17.3650s	
18354/33250 (epoch 27.600), train_loss = 0.85621651, grad/param norm = 1.7512e-01, time/batch = 14.8780s	
18355/33250 (epoch 27.602), train_loss = 0.88675561, grad/param norm = 1.7253e-01, time/batch = 15.4380s	
18356/33250 (epoch 27.603), train_loss = 0.93330116, grad/param norm = 1.7171e-01, time/batch = 15.3123s	
18357/33250 (epoch 27.605), train_loss = 0.87775628, grad/param norm = 1.7752e-01, time/batch = 16.2390s	
18358/33250 (epoch 27.606), train_loss = 0.94009720, grad/param norm = 1.7439e-01, time/batch = 15.4336s	
18359/33250 (epoch 27.608), train_loss = 0.88794515, grad/param norm = 1.6067e-01, time/batch = 16.8609s	
18360/33250 (epoch 27.609), train_loss = 0.79055884, grad/param norm = 1.6551e-01, time/batch = 16.7691s	
18361/33250 (epoch 27.611), train_loss = 0.88757002, grad/param norm = 1.8726e-01, time/batch = 15.6225s	
18362/33250 (epoch 27.612), train_loss = 0.85645149, grad/param norm = 1.5541e-01, time/batch = 16.5179s	
18363/33250 (epoch 27.614), train_loss = 1.08202518, grad/param norm = 2.1312e-01, time/batch = 20.1141s	
18364/33250 (epoch 27.615), train_loss = 0.97202601, grad/param norm = 1.6942e-01, time/batch = 17.8602s	
18365/33250 (epoch 27.617), train_loss = 1.08806919, grad/param norm = 1.7414e-01, time/batch = 17.7511s	
18366/33250 (epoch 27.618), train_loss = 1.14073919, grad/param norm = 2.3053e-01, time/batch = 15.6138s	
18367/33250 (epoch 27.620), train_loss = 0.96818179, grad/param norm = 1.9391e-01, time/batch = 14.7965s	
18368/33250 (epoch 27.621), train_loss = 0.93077733, grad/param norm = 1.7371e-01, time/batch = 16.9985s	
18369/33250 (epoch 27.623), train_loss = 0.79184090, grad/param norm = 1.5765e-01, time/batch = 16.1867s	
18370/33250 (epoch 27.624), train_loss = 0.84698285, grad/param norm = 1.7077e-01, time/batch = 15.4526s	
18371/33250 (epoch 27.626), train_loss = 0.83002735, grad/param norm = 1.9191e-01, time/batch = 15.4383s	
18372/33250 (epoch 27.627), train_loss = 0.83195768, grad/param norm = 1.5889e-01, time/batch = 17.5083s	
18373/33250 (epoch 27.629), train_loss = 0.91937786, grad/param norm = 1.9169e-01, time/batch = 17.1012s	
18374/33250 (epoch 27.630), train_loss = 0.84741552, grad/param norm = 1.7820e-01, time/batch = 18.1714s	
18375/33250 (epoch 27.632), train_loss = 0.75819261, grad/param norm = 1.5157e-01, time/batch = 15.2591s	
18376/33250 (epoch 27.633), train_loss = 0.88565817, grad/param norm = 1.7506e-01, time/batch = 16.0727s	
18377/33250 (epoch 27.635), train_loss = 0.80938300, grad/param norm = 1.5426e-01, time/batch = 15.4485s	
18378/33250 (epoch 27.636), train_loss = 0.80878033, grad/param norm = 1.5103e-01, time/batch = 15.1028s	
18379/33250 (epoch 27.638), train_loss = 0.80195983, grad/param norm = 1.8319e-01, time/batch = 15.4994s	
18380/33250 (epoch 27.639), train_loss = 0.75490338, grad/param norm = 1.5801e-01, time/batch = 14.9739s	
18381/33250 (epoch 27.641), train_loss = 0.84668647, grad/param norm = 1.4754e-01, time/batch = 14.6908s	
18382/33250 (epoch 27.642), train_loss = 0.68217029, grad/param norm = 1.5364e-01, time/batch = 15.0978s	
18383/33250 (epoch 27.644), train_loss = 0.61315061, grad/param norm = 1.3724e-01, time/batch = 16.8536s	
18384/33250 (epoch 27.645), train_loss = 0.91511545, grad/param norm = 1.9619e-01, time/batch = 16.5296s	
18385/33250 (epoch 27.647), train_loss = 0.75389876, grad/param norm = 1.6613e-01, time/batch = 15.7872s	
18386/33250 (epoch 27.648), train_loss = 0.76547187, grad/param norm = 1.8138e-01, time/batch = 16.1814s	
18387/33250 (epoch 27.650), train_loss = 1.00641621, grad/param norm = 1.9549e-01, time/batch = 15.1679s	
18388/33250 (epoch 27.651), train_loss = 0.91383701, grad/param norm = 1.7845e-01, time/batch = 15.3604s	
18389/33250 (epoch 27.653), train_loss = 0.79772012, grad/param norm = 1.5750e-01, time/batch = 14.9488s	
18390/33250 (epoch 27.654), train_loss = 0.86613132, grad/param norm = 1.5470e-01, time/batch = 15.9099s	
18391/33250 (epoch 27.656), train_loss = 0.89263393, grad/param norm = 1.5107e-01, time/batch = 15.0318s	
18392/33250 (epoch 27.657), train_loss = 0.70106114, grad/param norm = 1.6994e-01, time/batch = 16.0049s	
18393/33250 (epoch 27.659), train_loss = 0.79106030, grad/param norm = 1.6458e-01, time/batch = 17.9289s	
18394/33250 (epoch 27.660), train_loss = 0.86885472, grad/param norm = 1.6963e-01, time/batch = 16.3348s	
18395/33250 (epoch 27.662), train_loss = 0.86357158, grad/param norm = 1.6419e-01, time/batch = 14.9475s	
18396/33250 (epoch 27.663), train_loss = 0.79264508, grad/param norm = 1.5392e-01, time/batch = 15.3492s	
18397/33250 (epoch 27.665), train_loss = 0.90938605, grad/param norm = 1.6975e-01, time/batch = 15.1216s	
18398/33250 (epoch 27.666), train_loss = 0.81334364, grad/param norm = 1.4393e-01, time/batch = 15.1761s	
18399/33250 (epoch 27.668), train_loss = 0.98354446, grad/param norm = 1.6487e-01, time/batch = 15.5285s	
18400/33250 (epoch 27.669), train_loss = 0.86565111, grad/param norm = 1.6905e-01, time/batch = 15.0241s	
18401/33250 (epoch 27.671), train_loss = 0.79765401, grad/param norm = 1.7154e-01, time/batch = 18.3464s	
18402/33250 (epoch 27.672), train_loss = 0.93621142, grad/param norm = 1.6979e-01, time/batch = 16.3551s	
18403/33250 (epoch 27.674), train_loss = 0.75524603, grad/param norm = 1.5170e-01, time/batch = 17.9232s	
18404/33250 (epoch 27.675), train_loss = 0.85294759, grad/param norm = 1.4757e-01, time/batch = 19.5397s	
18405/33250 (epoch 27.677), train_loss = 0.94826110, grad/param norm = 1.7202e-01, time/batch = 17.9516s	
18406/33250 (epoch 27.678), train_loss = 0.83118452, grad/param norm = 1.8046e-01, time/batch = 19.0374s	
18407/33250 (epoch 27.680), train_loss = 0.95784281, grad/param norm = 1.8014e-01, time/batch = 15.8713s	
18408/33250 (epoch 27.681), train_loss = 0.77161548, grad/param norm = 1.4428e-01, time/batch = 14.6879s	
18409/33250 (epoch 27.683), train_loss = 0.80772180, grad/param norm = 1.6246e-01, time/batch = 16.7615s	
18410/33250 (epoch 27.684), train_loss = 0.77803762, grad/param norm = 1.8717e-01, time/batch = 15.5347s	
18411/33250 (epoch 27.686), train_loss = 0.77901125, grad/param norm = 1.6405e-01, time/batch = 17.2685s	
18412/33250 (epoch 27.687), train_loss = 0.88431725, grad/param norm = 1.7196e-01, time/batch = 27.2793s	
18413/33250 (epoch 27.689), train_loss = 0.78087501, grad/param norm = 1.6822e-01, time/batch = 20.2992s	
18414/33250 (epoch 27.690), train_loss = 0.87986938, grad/param norm = 1.6730e-01, time/batch = 15.0459s	
18415/33250 (epoch 27.692), train_loss = 0.82787526, grad/param norm = 1.5254e-01, time/batch = 15.0413s	
18416/33250 (epoch 27.693), train_loss = 0.92241020, grad/param norm = 1.6214e-01, time/batch = 15.0198s	
18417/33250 (epoch 27.695), train_loss = 0.90269616, grad/param norm = 1.5814e-01, time/batch = 15.7650s	
18418/33250 (epoch 27.696), train_loss = 0.92424997, grad/param norm = 1.6344e-01, time/batch = 16.2707s	
18419/33250 (epoch 27.698), train_loss = 0.83576499, grad/param norm = 1.7652e-01, time/batch = 15.7347s	
18420/33250 (epoch 27.699), train_loss = 1.06441720, grad/param norm = 1.7459e-01, time/batch = 16.2772s	
18421/33250 (epoch 27.701), train_loss = 0.85536735, grad/param norm = 1.4284e-01, time/batch = 16.0153s	
18422/33250 (epoch 27.702), train_loss = 0.82530551, grad/param norm = 2.1424e-01, time/batch = 15.3575s	
18423/33250 (epoch 27.704), train_loss = 1.03254228, grad/param norm = 1.9831e-01, time/batch = 16.2055s	
18424/33250 (epoch 27.705), train_loss = 0.81531410, grad/param norm = 1.5129e-01, time/batch = 16.1155s	
18425/33250 (epoch 27.707), train_loss = 0.70628733, grad/param norm = 1.4563e-01, time/batch = 19.3388s	
18426/33250 (epoch 27.708), train_loss = 0.94086659, grad/param norm = 1.8197e-01, time/batch = 17.1831s	
18427/33250 (epoch 27.710), train_loss = 0.91368305, grad/param norm = 1.7319e-01, time/batch = 17.3365s	
18428/33250 (epoch 27.711), train_loss = 0.77803928, grad/param norm = 1.7858e-01, time/batch = 15.9404s	
18429/33250 (epoch 27.713), train_loss = 0.89591560, grad/param norm = 1.4855e-01, time/batch = 15.2898s	
18430/33250 (epoch 27.714), train_loss = 0.87522760, grad/param norm = 1.7445e-01, time/batch = 16.0097s	
18431/33250 (epoch 27.716), train_loss = 0.90371247, grad/param norm = 1.6235e-01, time/batch = 15.8571s	
18432/33250 (epoch 27.717), train_loss = 0.79240774, grad/param norm = 1.3828e-01, time/batch = 15.4309s	
18433/33250 (epoch 27.719), train_loss = 0.82098154, grad/param norm = 1.5438e-01, time/batch = 16.0203s	
18434/33250 (epoch 27.720), train_loss = 1.10327570, grad/param norm = 1.7932e-01, time/batch = 16.7642s	
18435/33250 (epoch 27.722), train_loss = 0.75351716, grad/param norm = 1.4312e-01, time/batch = 16.2668s	
18436/33250 (epoch 27.723), train_loss = 0.68229616, grad/param norm = 1.4267e-01, time/batch = 19.1944s	
18437/33250 (epoch 27.725), train_loss = 0.78340190, grad/param norm = 1.2886e-01, time/batch = 16.7648s	
18438/33250 (epoch 27.726), train_loss = 0.82974301, grad/param norm = 1.6261e-01, time/batch = 15.3276s	
18439/33250 (epoch 27.728), train_loss = 0.90303616, grad/param norm = 1.6570e-01, time/batch = 16.1023s	
18440/33250 (epoch 27.729), train_loss = 0.95530008, grad/param norm = 1.6046e-01, time/batch = 15.8610s	
18441/33250 (epoch 27.731), train_loss = 0.79605998, grad/param norm = 1.6600e-01, time/batch = 15.4202s	
18442/33250 (epoch 27.732), train_loss = 0.75759405, grad/param norm = 1.3746e-01, time/batch = 15.6138s	
18443/33250 (epoch 27.734), train_loss = 0.90738124, grad/param norm = 2.0459e-01, time/batch = 15.3571s	
18444/33250 (epoch 27.735), train_loss = 0.88362809, grad/param norm = 1.7071e-01, time/batch = 15.2491s	
18445/33250 (epoch 27.737), train_loss = 0.82703800, grad/param norm = 1.4919e-01, time/batch = 15.0090s	
18446/33250 (epoch 27.738), train_loss = 0.88281367, grad/param norm = 1.4855e-01, time/batch = 14.6256s	
18447/33250 (epoch 27.740), train_loss = 0.91747094, grad/param norm = 1.6283e-01, time/batch = 18.4391s	
18448/33250 (epoch 27.741), train_loss = 0.92593477, grad/param norm = 1.5867e-01, time/batch = 16.1747s	
18449/33250 (epoch 27.743), train_loss = 0.79045977, grad/param norm = 1.4653e-01, time/batch = 15.6678s	
18450/33250 (epoch 27.744), train_loss = 0.83365758, grad/param norm = 1.5913e-01, time/batch = 14.8694s	
18451/33250 (epoch 27.746), train_loss = 0.76565982, grad/param norm = 1.3962e-01, time/batch = 16.0105s	
18452/33250 (epoch 27.747), train_loss = 0.80760891, grad/param norm = 1.5791e-01, time/batch = 15.2752s	
18453/33250 (epoch 27.749), train_loss = 0.96937532, grad/param norm = 1.7822e-01, time/batch = 15.2586s	
18454/33250 (epoch 27.750), train_loss = 0.92409311, grad/param norm = 1.5946e-01, time/batch = 14.9445s	
18455/33250 (epoch 27.752), train_loss = 0.81525359, grad/param norm = 1.4813e-01, time/batch = 15.0326s	
18456/33250 (epoch 27.753), train_loss = 0.81775144, grad/param norm = 1.7521e-01, time/batch = 16.0203s	
18457/33250 (epoch 27.755), train_loss = 0.80135559, grad/param norm = 1.6256e-01, time/batch = 19.0229s	
18458/33250 (epoch 27.756), train_loss = 0.88011523, grad/param norm = 1.7853e-01, time/batch = 17.6181s	
18459/33250 (epoch 27.758), train_loss = 1.00991370, grad/param norm = 1.5922e-01, time/batch = 15.9325s	
18460/33250 (epoch 27.759), train_loss = 0.79729240, grad/param norm = 1.5078e-01, time/batch = 15.3588s	
18461/33250 (epoch 27.761), train_loss = 0.87348464, grad/param norm = 1.6741e-01, time/batch = 15.4572s	
18462/33250 (epoch 27.762), train_loss = 0.93903044, grad/param norm = 1.6042e-01, time/batch = 16.6049s	
18463/33250 (epoch 27.764), train_loss = 0.78038701, grad/param norm = 2.0488e-01, time/batch = 15.8604s	
18464/33250 (epoch 27.765), train_loss = 0.91884960, grad/param norm = 1.6931e-01, time/batch = 17.5057s	
18465/33250 (epoch 27.767), train_loss = 0.68283499, grad/param norm = 1.5264e-01, time/batch = 15.7781s	
18466/33250 (epoch 27.768), train_loss = 0.72851387, grad/param norm = 1.6534e-01, time/batch = 17.8381s	
18467/33250 (epoch 27.770), train_loss = 0.89689648, grad/param norm = 1.7653e-01, time/batch = 16.2666s	
18468/33250 (epoch 27.771), train_loss = 0.91868721, grad/param norm = 1.7331e-01, time/batch = 18.3229s	
18469/33250 (epoch 27.773), train_loss = 0.85468295, grad/param norm = 1.8022e-01, time/batch = 15.6179s	
18470/33250 (epoch 27.774), train_loss = 0.73929687, grad/param norm = 1.7361e-01, time/batch = 15.6773s	
18471/33250 (epoch 27.776), train_loss = 0.81028708, grad/param norm = 1.4954e-01, time/batch = 16.1142s	
18472/33250 (epoch 27.777), train_loss = 0.94524634, grad/param norm = 1.9583e-01, time/batch = 15.2500s	
18473/33250 (epoch 27.779), train_loss = 0.84368346, grad/param norm = 1.7362e-01, time/batch = 16.1931s	
18474/33250 (epoch 27.780), train_loss = 1.00022418, grad/param norm = 1.9509e-01, time/batch = 15.8588s	
18475/33250 (epoch 27.782), train_loss = 0.85663881, grad/param norm = 1.8596e-01, time/batch = 15.5749s	
18476/33250 (epoch 27.783), train_loss = 0.72762466, grad/param norm = 1.4282e-01, time/batch = 18.0095s	
18477/33250 (epoch 27.785), train_loss = 0.75024418, grad/param norm = 1.5425e-01, time/batch = 17.0369s	
18478/33250 (epoch 27.786), train_loss = 0.97421394, grad/param norm = 1.6839e-01, time/batch = 16.7724s	
18479/33250 (epoch 27.788), train_loss = 0.93975302, grad/param norm = 1.6826e-01, time/batch = 18.8594s	
18480/33250 (epoch 27.789), train_loss = 0.97828329, grad/param norm = 2.0895e-01, time/batch = 15.7060s	
18481/33250 (epoch 27.791), train_loss = 1.00392512, grad/param norm = 1.8651e-01, time/batch = 15.6786s	
18482/33250 (epoch 27.792), train_loss = 1.03335204, grad/param norm = 1.7180e-01, time/batch = 15.3586s	
18483/33250 (epoch 27.794), train_loss = 0.85590661, grad/param norm = 1.7819e-01, time/batch = 16.5240s	
18484/33250 (epoch 27.795), train_loss = 0.88002403, grad/param norm = 1.6604e-01, time/batch = 15.4548s	
18485/33250 (epoch 27.797), train_loss = 0.93894491, grad/param norm = 1.9722e-01, time/batch = 15.3406s	
18486/33250 (epoch 27.798), train_loss = 0.86830127, grad/param norm = 1.9851e-01, time/batch = 16.1210s	
18487/33250 (epoch 27.800), train_loss = 0.90991643, grad/param norm = 1.7518e-01, time/batch = 15.1124s	
18488/33250 (epoch 27.802), train_loss = 0.83755722, grad/param norm = 1.5835e-01, time/batch = 17.7824s	
18489/33250 (epoch 27.803), train_loss = 0.89923694, grad/param norm = 1.6657e-01, time/batch = 17.0369s	
18490/33250 (epoch 27.805), train_loss = 0.91307000, grad/param norm = 1.7912e-01, time/batch = 15.8696s	
18491/33250 (epoch 27.806), train_loss = 0.88161551, grad/param norm = 1.6999e-01, time/batch = 16.0252s	
18492/33250 (epoch 27.808), train_loss = 0.80453456, grad/param norm = 1.5203e-01, time/batch = 15.2576s	
18493/33250 (epoch 27.809), train_loss = 0.79399523, grad/param norm = 1.5374e-01, time/batch = 15.4385s	
18494/33250 (epoch 27.811), train_loss = 0.77715681, grad/param norm = 1.4261e-01, time/batch = 16.0210s	
18495/33250 (epoch 27.812), train_loss = 0.90223095, grad/param norm = 1.7263e-01, time/batch = 17.1777s	
18496/33250 (epoch 27.814), train_loss = 0.87696982, grad/param norm = 1.9133e-01, time/batch = 15.3601s	
18497/33250 (epoch 27.815), train_loss = 0.92327385, grad/param norm = 1.6311e-01, time/batch = 17.0263s	
18498/33250 (epoch 27.817), train_loss = 0.84964911, grad/param norm = 1.6315e-01, time/batch = 16.3459s	
18499/33250 (epoch 27.818), train_loss = 0.78823918, grad/param norm = 1.5781e-01, time/batch = 16.5215s	
18500/33250 (epoch 27.820), train_loss = 0.87241512, grad/param norm = 1.5360e-01, time/batch = 17.4314s	
18501/33250 (epoch 27.821), train_loss = 0.83555640, grad/param norm = 1.5534e-01, time/batch = 17.1062s	
18502/33250 (epoch 27.823), train_loss = 1.17794465, grad/param norm = 1.9950e-01, time/batch = 15.4373s	
18503/33250 (epoch 27.824), train_loss = 0.81256306, grad/param norm = 1.7606e-01, time/batch = 16.6688s	
18504/33250 (epoch 27.826), train_loss = 0.89055553, grad/param norm = 1.5598e-01, time/batch = 1.1968s	
18505/33250 (epoch 27.827), train_loss = 0.74436989, grad/param norm = 1.5338e-01, time/batch = 0.6696s	
18506/33250 (epoch 27.829), train_loss = 0.86946998, grad/param norm = 1.6981e-01, time/batch = 0.6649s	
18507/33250 (epoch 27.830), train_loss = 0.97301095, grad/param norm = 2.6248e-01, time/batch = 0.6672s	
18508/33250 (epoch 27.832), train_loss = 0.86754128, grad/param norm = 1.6325e-01, time/batch = 0.6860s	
18509/33250 (epoch 27.833), train_loss = 0.86562283, grad/param norm = 1.7601e-01, time/batch = 0.6930s	
18510/33250 (epoch 27.835), train_loss = 0.79261446, grad/param norm = 1.8680e-01, time/batch = 0.6837s	
18511/33250 (epoch 27.836), train_loss = 0.84780975, grad/param norm = 1.6410e-01, time/batch = 0.8908s	
18512/33250 (epoch 27.838), train_loss = 0.89326706, grad/param norm = 1.5413e-01, time/batch = 0.9867s	
18513/33250 (epoch 27.839), train_loss = 0.83725747, grad/param norm = 1.7272e-01, time/batch = 0.9953s	
18514/33250 (epoch 27.841), train_loss = 0.81532557, grad/param norm = 1.5811e-01, time/batch = 0.9960s	
18515/33250 (epoch 27.842), train_loss = 1.00599352, grad/param norm = 1.6297e-01, time/batch = 0.9914s	
18516/33250 (epoch 27.844), train_loss = 0.97737509, grad/param norm = 1.8186e-01, time/batch = 1.5009s	
18517/33250 (epoch 27.845), train_loss = 1.05029401, grad/param norm = 1.8553e-01, time/batch = 1.8053s	
18518/33250 (epoch 27.847), train_loss = 1.03211611, grad/param norm = 1.7290e-01, time/batch = 1.8287s	
18519/33250 (epoch 27.848), train_loss = 1.07345404, grad/param norm = 1.9126e-01, time/batch = 14.3112s	
18520/33250 (epoch 27.850), train_loss = 0.95324099, grad/param norm = 1.7719e-01, time/batch = 15.6273s	
18521/33250 (epoch 27.851), train_loss = 0.79920446, grad/param norm = 1.8286e-01, time/batch = 16.2704s	
18522/33250 (epoch 27.853), train_loss = 0.93155531, grad/param norm = 2.0851e-01, time/batch = 16.6062s	
18523/33250 (epoch 27.854), train_loss = 0.83610657, grad/param norm = 1.5310e-01, time/batch = 16.9558s	
18524/33250 (epoch 27.856), train_loss = 0.82731583, grad/param norm = 1.7838e-01, time/batch = 18.4372s	
18525/33250 (epoch 27.857), train_loss = 0.76256199, grad/param norm = 1.6701e-01, time/batch = 18.0209s	
18526/33250 (epoch 27.859), train_loss = 0.79059730, grad/param norm = 1.6220e-01, time/batch = 16.3379s	
18527/33250 (epoch 27.860), train_loss = 0.88897066, grad/param norm = 1.5055e-01, time/batch = 16.5916s	
18528/33250 (epoch 27.862), train_loss = 0.77912835, grad/param norm = 1.6826e-01, time/batch = 15.8615s	
18529/33250 (epoch 27.863), train_loss = 0.80269677, grad/param norm = 1.5949e-01, time/batch = 17.0976s	
18530/33250 (epoch 27.865), train_loss = 0.90094730, grad/param norm = 1.5925e-01, time/batch = 16.1649s	
18531/33250 (epoch 27.866), train_loss = 0.76498505, grad/param norm = 1.5879e-01, time/batch = 16.1686s	
18532/33250 (epoch 27.868), train_loss = 0.88416190, grad/param norm = 2.0049e-01, time/batch = 15.5238s	
18533/33250 (epoch 27.869), train_loss = 0.89814506, grad/param norm = 1.8057e-01, time/batch = 19.6833s	
18534/33250 (epoch 27.871), train_loss = 0.69250655, grad/param norm = 1.4409e-01, time/batch = 17.1163s	
18535/33250 (epoch 27.872), train_loss = 0.93897531, grad/param norm = 1.9045e-01, time/batch = 17.5882s	
18536/33250 (epoch 27.874), train_loss = 0.78697702, grad/param norm = 1.5365e-01, time/batch = 16.9959s	
18537/33250 (epoch 27.875), train_loss = 0.75200314, grad/param norm = 1.8091e-01, time/batch = 16.6872s	
18538/33250 (epoch 27.877), train_loss = 0.97133263, grad/param norm = 1.6393e-01, time/batch = 15.7255s	
18539/33250 (epoch 27.878), train_loss = 0.89994070, grad/param norm = 1.6091e-01, time/batch = 15.6540s	
18540/33250 (epoch 27.880), train_loss = 0.85377414, grad/param norm = 2.0395e-01, time/batch = 15.1064s	
18541/33250 (epoch 27.881), train_loss = 0.96473540, grad/param norm = 1.7556e-01, time/batch = 15.0364s	
18542/33250 (epoch 27.883), train_loss = 0.89827931, grad/param norm = 1.6601e-01, time/batch = 15.1910s	
18543/33250 (epoch 27.884), train_loss = 0.94777967, grad/param norm = 1.7758e-01, time/batch = 15.4446s	
18544/33250 (epoch 27.886), train_loss = 0.81925601, grad/param norm = 1.4126e-01, time/batch = 15.3557s	
18545/33250 (epoch 27.887), train_loss = 0.83869881, grad/param norm = 1.7597e-01, time/batch = 16.4411s	
18546/33250 (epoch 27.889), train_loss = 0.81608968, grad/param norm = 1.4756e-01, time/batch = 17.4319s	
18547/33250 (epoch 27.890), train_loss = 0.69615515, grad/param norm = 1.3472e-01, time/batch = 15.1056s	
18548/33250 (epoch 27.892), train_loss = 0.90955117, grad/param norm = 1.5728e-01, time/batch = 15.5323s	
18549/33250 (epoch 27.893), train_loss = 0.91738702, grad/param norm = 1.8556e-01, time/batch = 15.9219s	
18550/33250 (epoch 27.895), train_loss = 0.81065283, grad/param norm = 1.6908e-01, time/batch = 15.7069s	
18551/33250 (epoch 27.896), train_loss = 0.93771950, grad/param norm = 1.7703e-01, time/batch = 15.2080s	
18552/33250 (epoch 27.898), train_loss = 0.87881820, grad/param norm = 1.7905e-01, time/batch = 15.1643s	
18553/33250 (epoch 27.899), train_loss = 0.79425878, grad/param norm = 1.6154e-01, time/batch = 15.6802s	
18554/33250 (epoch 27.901), train_loss = 0.75693599, grad/param norm = 1.5140e-01, time/batch = 16.4196s	
18555/33250 (epoch 27.902), train_loss = 0.82855605, grad/param norm = 1.4317e-01, time/batch = 16.0031s	
18556/33250 (epoch 27.904), train_loss = 0.78239884, grad/param norm = 1.4199e-01, time/batch = 16.2972s	
18557/33250 (epoch 27.905), train_loss = 0.82725924, grad/param norm = 1.5563e-01, time/batch = 15.6904s	
18558/33250 (epoch 27.907), train_loss = 0.76383308, grad/param norm = 1.5366e-01, time/batch = 15.4108s	
18559/33250 (epoch 27.908), train_loss = 0.84839708, grad/param norm = 1.3432e-01, time/batch = 15.4299s	
18560/33250 (epoch 27.910), train_loss = 0.94538900, grad/param norm = 2.1258e-01, time/batch = 15.2820s	
18561/33250 (epoch 27.911), train_loss = 0.76213502, grad/param norm = 1.4835e-01, time/batch = 15.0422s	
18562/33250 (epoch 27.913), train_loss = 0.82596920, grad/param norm = 1.4992e-01, time/batch = 15.3562s	
18563/33250 (epoch 27.914), train_loss = 0.73076097, grad/param norm = 1.6541e-01, time/batch = 16.6970s	
18564/33250 (epoch 27.916), train_loss = 0.77300911, grad/param norm = 1.5080e-01, time/batch = 17.2049s	
18565/33250 (epoch 27.917), train_loss = 0.84956664, grad/param norm = 1.4281e-01, time/batch = 17.2104s	
18566/33250 (epoch 27.919), train_loss = 0.79758312, grad/param norm = 1.7913e-01, time/batch = 15.4225s	
18567/33250 (epoch 27.920), train_loss = 0.85250131, grad/param norm = 1.8297e-01, time/batch = 15.7620s	
18568/33250 (epoch 27.922), train_loss = 0.87380560, grad/param norm = 1.6811e-01, time/batch = 16.1083s	
18569/33250 (epoch 27.923), train_loss = 0.81180377, grad/param norm = 1.6908e-01, time/batch = 15.6909s	
18570/33250 (epoch 27.925), train_loss = 0.81248118, grad/param norm = 1.6342e-01, time/batch = 14.7916s	
18571/33250 (epoch 27.926), train_loss = 0.80790561, grad/param norm = 1.4628e-01, time/batch = 15.9518s	
18572/33250 (epoch 27.928), train_loss = 0.81979117, grad/param norm = 1.6803e-01, time/batch = 15.2800s	
18573/33250 (epoch 27.929), train_loss = 0.72382371, grad/param norm = 1.3436e-01, time/batch = 15.1822s	
18574/33250 (epoch 27.931), train_loss = 0.96153628, grad/param norm = 1.6941e-01, time/batch = 15.9243s	
18575/33250 (epoch 27.932), train_loss = 0.81187131, grad/param norm = 1.6470e-01, time/batch = 18.0545s	
18576/33250 (epoch 27.934), train_loss = 0.79910367, grad/param norm = 1.4397e-01, time/batch = 15.9531s	
18577/33250 (epoch 27.935), train_loss = 0.80858038, grad/param norm = 1.7985e-01, time/batch = 17.6035s	
18578/33250 (epoch 27.937), train_loss = 0.80253628, grad/param norm = 1.8888e-01, time/batch = 15.6802s	
18579/33250 (epoch 27.938), train_loss = 0.86888103, grad/param norm = 1.8433e-01, time/batch = 15.5283s	
18580/33250 (epoch 27.940), train_loss = 0.83306263, grad/param norm = 1.6057e-01, time/batch = 14.8730s	
18581/33250 (epoch 27.941), train_loss = 0.90547160, grad/param norm = 1.7361e-01, time/batch = 15.5999s	
18582/33250 (epoch 27.943), train_loss = 0.99464743, grad/param norm = 1.7330e-01, time/batch = 15.3298s	
18583/33250 (epoch 27.944), train_loss = 0.82226914, grad/param norm = 1.5938e-01, time/batch = 16.3589s	
18584/33250 (epoch 27.946), train_loss = 0.96067049, grad/param norm = 1.7646e-01, time/batch = 15.5303s	
18585/33250 (epoch 27.947), train_loss = 0.78763639, grad/param norm = 1.5757e-01, time/batch = 16.1999s	
18586/33250 (epoch 27.949), train_loss = 0.91251925, grad/param norm = 1.7288e-01, time/batch = 18.2752s	
18587/33250 (epoch 27.950), train_loss = 0.92110544, grad/param norm = 1.6336e-01, time/batch = 15.1979s	
18588/33250 (epoch 27.952), train_loss = 0.85960170, grad/param norm = 1.8285e-01, time/batch = 16.5972s	
18589/33250 (epoch 27.953), train_loss = 0.92458409, grad/param norm = 1.9047e-01, time/batch = 18.4471s	
18590/33250 (epoch 27.955), train_loss = 0.93775651, grad/param norm = 1.7890e-01, time/batch = 16.4495s	
18591/33250 (epoch 27.956), train_loss = 0.88034829, grad/param norm = 2.0258e-01, time/batch = 16.5893s	
18592/33250 (epoch 27.958), train_loss = 0.79705532, grad/param norm = 1.4351e-01, time/batch = 17.5914s	
18593/33250 (epoch 27.959), train_loss = 0.79991429, grad/param norm = 1.4669e-01, time/batch = 16.5193s	
18594/33250 (epoch 27.961), train_loss = 1.05908921, grad/param norm = 1.8058e-01, time/batch = 16.6898s	
18595/33250 (epoch 27.962), train_loss = 0.84307643, grad/param norm = 1.6849e-01, time/batch = 15.5897s	
18596/33250 (epoch 27.964), train_loss = 1.01396011, grad/param norm = 1.8952e-01, time/batch = 15.0927s	
18597/33250 (epoch 27.965), train_loss = 0.92447906, grad/param norm = 1.7578e-01, time/batch = 14.8583s	
18598/33250 (epoch 27.967), train_loss = 0.89519385, grad/param norm = 1.6542e-01, time/batch = 14.8728s	
18599/33250 (epoch 27.968), train_loss = 1.01439816, grad/param norm = 1.6764e-01, time/batch = 15.0937s	
18600/33250 (epoch 27.970), train_loss = 1.12589516, grad/param norm = 2.3788e-01, time/batch = 15.5436s	
18601/33250 (epoch 27.971), train_loss = 1.02933725, grad/param norm = 2.0932e-01, time/batch = 16.5912s	
18602/33250 (epoch 27.973), train_loss = 0.83952745, grad/param norm = 1.4827e-01, time/batch = 15.4220s	
18603/33250 (epoch 27.974), train_loss = 0.93537280, grad/param norm = 1.6858e-01, time/batch = 16.3641s	
18604/33250 (epoch 27.976), train_loss = 0.81974684, grad/param norm = 1.7087e-01, time/batch = 17.3708s	
18605/33250 (epoch 27.977), train_loss = 0.83447662, grad/param norm = 1.5521e-01, time/batch = 15.7772s	
18606/33250 (epoch 27.979), train_loss = 0.88965385, grad/param norm = 1.7676e-01, time/batch = 15.0253s	
18607/33250 (epoch 27.980), train_loss = 0.90069829, grad/param norm = 1.6759e-01, time/batch = 14.8595s	
18608/33250 (epoch 27.982), train_loss = 0.80786349, grad/param norm = 1.4164e-01, time/batch = 14.8677s	
18609/33250 (epoch 27.983), train_loss = 0.88973710, grad/param norm = 1.9880e-01, time/batch = 15.7789s	
18610/33250 (epoch 27.985), train_loss = 0.83889832, grad/param norm = 1.7413e-01, time/batch = 15.1683s	
18611/33250 (epoch 27.986), train_loss = 0.93408836, grad/param norm = 1.5697e-01, time/batch = 16.2566s	
18612/33250 (epoch 27.988), train_loss = 0.94299387, grad/param norm = 1.6173e-01, time/batch = 18.0108s	
18613/33250 (epoch 27.989), train_loss = 0.94597379, grad/param norm = 1.6101e-01, time/batch = 15.3892s	
18614/33250 (epoch 27.991), train_loss = 0.90019479, grad/param norm = 1.4909e-01, time/batch = 15.8759s	
18615/33250 (epoch 27.992), train_loss = 0.83967552, grad/param norm = 1.9771e-01, time/batch = 16.5834s	
18616/33250 (epoch 27.994), train_loss = 0.84686649, grad/param norm = 1.5075e-01, time/batch = 15.0324s	
18617/33250 (epoch 27.995), train_loss = 0.83493749, grad/param norm = 2.2580e-01, time/batch = 15.1740s	
18618/33250 (epoch 27.997), train_loss = 0.64527862, grad/param norm = 1.4841e-01, time/batch = 15.0236s	
18619/33250 (epoch 27.998), train_loss = 0.90779851, grad/param norm = 1.6049e-01, time/batch = 15.1206s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
18620/33250 (epoch 28.000), train_loss = 0.87716263, grad/param norm = 1.5568e-01, time/batch = 15.1100s	
18621/33250 (epoch 28.002), train_loss = 1.05753702, grad/param norm = 1.6975e-01, time/batch = 15.4048s	
18622/33250 (epoch 28.003), train_loss = 0.94528394, grad/param norm = 1.6355e-01, time/batch = 14.6175s	
18623/33250 (epoch 28.005), train_loss = 0.71513550, grad/param norm = 1.4019e-01, time/batch = 17.5989s	
18624/33250 (epoch 28.006), train_loss = 0.73676974, grad/param norm = 1.4645e-01, time/batch = 16.0437s	
18625/33250 (epoch 28.008), train_loss = 0.96891817, grad/param norm = 1.6064e-01, time/batch = 18.1031s	
18626/33250 (epoch 28.009), train_loss = 1.00345647, grad/param norm = 1.6859e-01, time/batch = 15.5438s	
18627/33250 (epoch 28.011), train_loss = 0.81047470, grad/param norm = 1.7411e-01, time/batch = 14.7016s	
18628/33250 (epoch 28.012), train_loss = 0.86660846, grad/param norm = 2.3415e-01, time/batch = 14.8697s	
18629/33250 (epoch 28.014), train_loss = 0.96475481, grad/param norm = 1.8459e-01, time/batch = 15.3448s	
18630/33250 (epoch 28.015), train_loss = 0.85532202, grad/param norm = 1.6447e-01, time/batch = 15.8504s	
18631/33250 (epoch 28.017), train_loss = 0.90010956, grad/param norm = 1.8182e-01, time/batch = 15.7840s	
18632/33250 (epoch 28.018), train_loss = 0.71993168, grad/param norm = 1.6403e-01, time/batch = 15.5350s	
18633/33250 (epoch 28.020), train_loss = 0.87236482, grad/param norm = 1.5030e-01, time/batch = 15.2051s	
18634/33250 (epoch 28.021), train_loss = 0.89883945, grad/param norm = 1.5765e-01, time/batch = 14.9505s	
18635/33250 (epoch 28.023), train_loss = 0.75029842, grad/param norm = 1.9685e-01, time/batch = 17.5942s	
18636/33250 (epoch 28.024), train_loss = 0.96299122, grad/param norm = 1.6335e-01, time/batch = 17.3640s	
18637/33250 (epoch 28.026), train_loss = 0.88316266, grad/param norm = 1.6902e-01, time/batch = 16.8434s	
18638/33250 (epoch 28.027), train_loss = 0.89870323, grad/param norm = 1.5855e-01, time/batch = 16.7691s	
18639/33250 (epoch 28.029), train_loss = 0.86718444, grad/param norm = 1.6326e-01, time/batch = 18.1864s	
18640/33250 (epoch 28.030), train_loss = 0.88807827, grad/param norm = 1.9153e-01, time/batch = 16.1152s	
18641/33250 (epoch 28.032), train_loss = 1.07430233, grad/param norm = 2.0095e-01, time/batch = 16.0417s	
18642/33250 (epoch 28.033), train_loss = 0.82073569, grad/param norm = 1.6314e-01, time/batch = 15.6074s	
18643/33250 (epoch 28.035), train_loss = 0.86878976, grad/param norm = 1.6997e-01, time/batch = 17.9347s	
18644/33250 (epoch 28.036), train_loss = 0.94957079, grad/param norm = 1.9064e-01, time/batch = 15.5165s	
18645/33250 (epoch 28.038), train_loss = 0.87750211, grad/param norm = 1.4320e-01, time/batch = 16.1273s	
18646/33250 (epoch 28.039), train_loss = 0.79580568, grad/param norm = 1.5331e-01, time/batch = 17.0371s	
18647/33250 (epoch 28.041), train_loss = 0.89914217, grad/param norm = 1.7483e-01, time/batch = 20.3054s	
18648/33250 (epoch 28.042), train_loss = 0.72460996, grad/param norm = 1.4704e-01, time/batch = 27.1540s	
18649/33250 (epoch 28.044), train_loss = 0.98325272, grad/param norm = 1.7387e-01, time/batch = 16.6364s	
18650/33250 (epoch 28.045), train_loss = 0.96998063, grad/param norm = 1.6978e-01, time/batch = 16.0784s	
18651/33250 (epoch 28.047), train_loss = 0.88077155, grad/param norm = 1.7628e-01, time/batch = 15.1208s	
18652/33250 (epoch 28.048), train_loss = 1.01844636, grad/param norm = 2.3864e-01, time/batch = 15.2424s	
18653/33250 (epoch 28.050), train_loss = 0.87538163, grad/param norm = 1.5271e-01, time/batch = 15.3165s	
18654/33250 (epoch 28.051), train_loss = 0.86288888, grad/param norm = 1.5821e-01, time/batch = 14.8640s	
18655/33250 (epoch 28.053), train_loss = 0.91298625, grad/param norm = 1.9398e-01, time/batch = 14.5456s	
18656/33250 (epoch 28.054), train_loss = 0.76158298, grad/param norm = 1.4512e-01, time/batch = 14.1477s	
18657/33250 (epoch 28.056), train_loss = 0.78882441, grad/param norm = 1.6068e-01, time/batch = 14.0649s	
18658/33250 (epoch 28.057), train_loss = 0.97600136, grad/param norm = 1.6426e-01, time/batch = 14.6315s	
18659/33250 (epoch 28.059), train_loss = 0.84549200, grad/param norm = 1.5462e-01, time/batch = 14.2430s	
18660/33250 (epoch 28.060), train_loss = 0.87266298, grad/param norm = 1.7676e-01, time/batch = 14.5493s	
18661/33250 (epoch 28.062), train_loss = 0.95877463, grad/param norm = 1.5966e-01, time/batch = 14.7154s	
18662/33250 (epoch 28.063), train_loss = 1.02214329, grad/param norm = 1.4956e-01, time/batch = 14.6985s	
18663/33250 (epoch 28.065), train_loss = 0.87219013, grad/param norm = 1.5783e-01, time/batch = 14.8552s	
18664/33250 (epoch 28.066), train_loss = 0.92539172, grad/param norm = 1.9190e-01, time/batch = 14.3069s	
18665/33250 (epoch 28.068), train_loss = 0.82000899, grad/param norm = 1.5629e-01, time/batch = 14.1681s	
18666/33250 (epoch 28.069), train_loss = 0.87087390, grad/param norm = 1.4641e-01, time/batch = 14.8016s	
18667/33250 (epoch 28.071), train_loss = 0.81002882, grad/param norm = 1.4587e-01, time/batch = 14.3106s	
18668/33250 (epoch 28.072), train_loss = 0.82640980, grad/param norm = 1.6345e-01, time/batch = 13.8438s	
18669/33250 (epoch 28.074), train_loss = 0.92745336, grad/param norm = 1.6806e-01, time/batch = 14.8595s	
18670/33250 (epoch 28.075), train_loss = 0.82556028, grad/param norm = 1.8460e-01, time/batch = 14.2262s	
18671/33250 (epoch 28.077), train_loss = 0.87172818, grad/param norm = 1.7729e-01, time/batch = 14.3961s	
18672/33250 (epoch 28.078), train_loss = 0.88703616, grad/param norm = 1.7078e-01, time/batch = 14.8496s	
18673/33250 (epoch 28.080), train_loss = 0.90008012, grad/param norm = 2.2227e-01, time/batch = 14.2312s	
18674/33250 (epoch 28.081), train_loss = 0.92442295, grad/param norm = 1.6306e-01, time/batch = 14.2310s	
18675/33250 (epoch 28.083), train_loss = 0.97864920, grad/param norm = 1.5989e-01, time/batch = 15.0366s	
18676/33250 (epoch 28.084), train_loss = 0.87787908, grad/param norm = 1.7705e-01, time/batch = 14.4729s	
18677/33250 (epoch 28.086), train_loss = 0.85891883, grad/param norm = 1.4874e-01, time/batch = 14.7871s	
18678/33250 (epoch 28.087), train_loss = 0.75955771, grad/param norm = 1.4660e-01, time/batch = 14.3130s	
18679/33250 (epoch 28.089), train_loss = 0.89353759, grad/param norm = 1.5311e-01, time/batch = 14.7837s	
18680/33250 (epoch 28.090), train_loss = 0.91163540, grad/param norm = 1.6675e-01, time/batch = 14.4687s	
18681/33250 (epoch 28.092), train_loss = 0.82808477, grad/param norm = 1.5066e-01, time/batch = 14.8582s	
18682/33250 (epoch 28.093), train_loss = 0.85927945, grad/param norm = 1.5477e-01, time/batch = 14.3117s	
18683/33250 (epoch 28.095), train_loss = 0.85487614, grad/param norm = 1.5939e-01, time/batch = 14.6374s	
18684/33250 (epoch 28.096), train_loss = 0.72114438, grad/param norm = 1.7149e-01, time/batch = 14.0116s	
18685/33250 (epoch 28.098), train_loss = 0.76699719, grad/param norm = 1.9706e-01, time/batch = 14.4826s	
18686/33250 (epoch 28.099), train_loss = 0.70265079, grad/param norm = 1.4451e-01, time/batch = 14.2442s	
18687/33250 (epoch 28.101), train_loss = 0.85475474, grad/param norm = 1.5905e-01, time/batch = 14.8672s	
18688/33250 (epoch 28.102), train_loss = 0.78694637, grad/param norm = 1.4366e-01, time/batch = 14.2268s	
18689/33250 (epoch 28.104), train_loss = 0.66229433, grad/param norm = 1.3314e-01, time/batch = 14.3173s	
18690/33250 (epoch 28.105), train_loss = 0.79787593, grad/param norm = 1.5472e-01, time/batch = 14.3959s	
18691/33250 (epoch 28.107), train_loss = 0.73300403, grad/param norm = 1.3533e-01, time/batch = 15.5729s	
18692/33250 (epoch 28.108), train_loss = 0.85655277, grad/param norm = 1.6145e-01, time/batch = 14.4660s	
18693/33250 (epoch 28.110), train_loss = 0.71649278, grad/param norm = 1.4042e-01, time/batch = 14.7023s	
18694/33250 (epoch 28.111), train_loss = 0.83844344, grad/param norm = 1.4965e-01, time/batch = 15.1704s	
18695/33250 (epoch 28.113), train_loss = 0.80633155, grad/param norm = 1.5093e-01, time/batch = 14.7798s	
18696/33250 (epoch 28.114), train_loss = 0.76164535, grad/param norm = 1.6310e-01, time/batch = 14.7109s	
18697/33250 (epoch 28.116), train_loss = 0.83195759, grad/param norm = 1.6216e-01, time/batch = 14.8699s	
18698/33250 (epoch 28.117), train_loss = 0.80032172, grad/param norm = 1.5268e-01, time/batch = 14.8792s	
18699/33250 (epoch 28.119), train_loss = 0.82451609, grad/param norm = 1.5893e-01, time/batch = 15.2095s	
18700/33250 (epoch 28.120), train_loss = 0.65408968, grad/param norm = 1.2642e-01, time/batch = 15.1164s	
18701/33250 (epoch 28.122), train_loss = 0.93708476, grad/param norm = 1.6233e-01, time/batch = 14.9572s	
18702/33250 (epoch 28.123), train_loss = 0.83731305, grad/param norm = 1.6864e-01, time/batch = 14.6611s	
18703/33250 (epoch 28.125), train_loss = 0.70837698, grad/param norm = 1.5154e-01, time/batch = 15.2743s	
18704/33250 (epoch 28.126), train_loss = 0.82397563, grad/param norm = 1.5296e-01, time/batch = 14.6445s	
18705/33250 (epoch 28.128), train_loss = 0.80101758, grad/param norm = 1.3914e-01, time/batch = 14.7193s	
18706/33250 (epoch 28.129), train_loss = 0.84654070, grad/param norm = 1.5297e-01, time/batch = 14.7883s	
18707/33250 (epoch 28.131), train_loss = 0.84110003, grad/param norm = 1.6629e-01, time/batch = 15.1818s	
18708/33250 (epoch 28.132), train_loss = 0.81374317, grad/param norm = 1.6037e-01, time/batch = 14.3920s	
18709/33250 (epoch 28.134), train_loss = 0.80527267, grad/param norm = 1.6308e-01, time/batch = 14.4868s	
18710/33250 (epoch 28.135), train_loss = 0.85482959, grad/param norm = 1.6068e-01, time/batch = 14.4701s	
18711/33250 (epoch 28.137), train_loss = 0.75624712, grad/param norm = 1.6455e-01, time/batch = 14.9643s	
18712/33250 (epoch 28.138), train_loss = 0.77805665, grad/param norm = 1.3743e-01, time/batch = 14.9658s	
18713/33250 (epoch 28.140), train_loss = 0.66663436, grad/param norm = 1.4019e-01, time/batch = 15.0955s	
18714/33250 (epoch 28.141), train_loss = 0.93623357, grad/param norm = 2.1390e-01, time/batch = 14.4607s	
18715/33250 (epoch 28.143), train_loss = 0.69487723, grad/param norm = 1.7562e-01, time/batch = 15.1070s	
18716/33250 (epoch 28.144), train_loss = 0.81525552, grad/param norm = 1.6409e-01, time/batch = 14.9592s	
18717/33250 (epoch 28.146), train_loss = 0.80293785, grad/param norm = 1.5011e-01, time/batch = 14.4824s	
18718/33250 (epoch 28.147), train_loss = 0.80984186, grad/param norm = 1.5620e-01, time/batch = 14.4095s	
18719/33250 (epoch 28.149), train_loss = 0.78341557, grad/param norm = 1.4923e-01, time/batch = 15.0241s	
18720/33250 (epoch 28.150), train_loss = 0.73773580, grad/param norm = 1.6734e-01, time/batch = 14.6347s	
18721/33250 (epoch 28.152), train_loss = 0.72490726, grad/param norm = 1.5532e-01, time/batch = 14.7130s	
18722/33250 (epoch 28.153), train_loss = 0.99243331, grad/param norm = 1.8992e-01, time/batch = 14.7961s	
18723/33250 (epoch 28.155), train_loss = 0.80540998, grad/param norm = 1.7569e-01, time/batch = 14.9489s	
18724/33250 (epoch 28.156), train_loss = 1.03115368, grad/param norm = 1.7099e-01, time/batch = 14.8713s	
18725/33250 (epoch 28.158), train_loss = 0.99848123, grad/param norm = 2.0309e-01, time/batch = 14.8831s	
18726/33250 (epoch 28.159), train_loss = 0.81165520, grad/param norm = 1.6372e-01, time/batch = 14.9403s	
18727/33250 (epoch 28.161), train_loss = 0.88389315, grad/param norm = 1.6271e-01, time/batch = 15.0337s	
18728/33250 (epoch 28.162), train_loss = 0.75981537, grad/param norm = 1.5136e-01, time/batch = 15.5080s	
18729/33250 (epoch 28.164), train_loss = 0.81077901, grad/param norm = 1.7266e-01, time/batch = 15.1037s	
18730/33250 (epoch 28.165), train_loss = 0.89906895, grad/param norm = 1.7307e-01, time/batch = 14.9439s	
18731/33250 (epoch 28.167), train_loss = 0.99999142, grad/param norm = 1.8094e-01, time/batch = 15.3564s	
18732/33250 (epoch 28.168), train_loss = 0.71596065, grad/param norm = 1.3271e-01, time/batch = 15.2839s	
18733/33250 (epoch 28.170), train_loss = 0.79578107, grad/param norm = 1.5845e-01, time/batch = 15.0124s	
18734/33250 (epoch 28.171), train_loss = 0.85312992, grad/param norm = 1.5932e-01, time/batch = 14.8987s	
18735/33250 (epoch 28.173), train_loss = 0.80865580, grad/param norm = 1.5339e-01, time/batch = 15.1428s	
18736/33250 (epoch 28.174), train_loss = 0.85866227, grad/param norm = 1.5066e-01, time/batch = 18.5135s	
18737/33250 (epoch 28.176), train_loss = 0.80260645, grad/param norm = 1.5455e-01, time/batch = 15.6969s	
18738/33250 (epoch 28.177), train_loss = 0.81479080, grad/param norm = 1.8097e-01, time/batch = 16.0118s	
18739/33250 (epoch 28.179), train_loss = 0.76980715, grad/param norm = 1.4609e-01, time/batch = 15.8445s	
18740/33250 (epoch 28.180), train_loss = 0.67886963, grad/param norm = 1.3368e-01, time/batch = 16.7375s	
18741/33250 (epoch 28.182), train_loss = 0.80802385, grad/param norm = 2.2635e-01, time/batch = 17.2221s	
18742/33250 (epoch 28.183), train_loss = 0.97374332, grad/param norm = 2.0494e-01, time/batch = 15.9254s	
18743/33250 (epoch 28.185), train_loss = 0.89058608, grad/param norm = 1.8853e-01, time/batch = 16.7506s	
18744/33250 (epoch 28.186), train_loss = 0.88824755, grad/param norm = 2.3378e-01, time/batch = 15.8599s	
18745/33250 (epoch 28.188), train_loss = 0.95259003, grad/param norm = 1.9606e-01, time/batch = 17.7059s	
18746/33250 (epoch 28.189), train_loss = 0.70673697, grad/param norm = 1.9109e-01, time/batch = 15.8555s	
18747/33250 (epoch 28.191), train_loss = 0.77432746, grad/param norm = 1.5103e-01, time/batch = 16.8553s	
18748/33250 (epoch 28.192), train_loss = 0.81513440, grad/param norm = 1.4920e-01, time/batch = 16.1135s	
18749/33250 (epoch 28.194), train_loss = 0.84949501, grad/param norm = 1.7489e-01, time/batch = 16.4349s	
18750/33250 (epoch 28.195), train_loss = 1.02367459, grad/param norm = 2.0062e-01, time/batch = 16.0320s	
18751/33250 (epoch 28.197), train_loss = 0.79037312, grad/param norm = 1.5984e-01, time/batch = 16.0080s	
18752/33250 (epoch 28.198), train_loss = 0.97868974, grad/param norm = 1.7195e-01, time/batch = 15.9031s	
18753/33250 (epoch 28.200), train_loss = 0.84989779, grad/param norm = 1.4904e-01, time/batch = 15.6882s	
18754/33250 (epoch 28.202), train_loss = 0.80493234, grad/param norm = 1.6001e-01, time/batch = 18.6889s	
18755/33250 (epoch 28.203), train_loss = 0.77870054, grad/param norm = 1.8035e-01, time/batch = 17.3702s	
18756/33250 (epoch 28.205), train_loss = 0.88776458, grad/param norm = 1.6407e-01, time/batch = 17.2808s	
18757/33250 (epoch 28.206), train_loss = 0.90897947, grad/param norm = 1.6320e-01, time/batch = 16.5889s	
18758/33250 (epoch 28.208), train_loss = 0.96397077, grad/param norm = 1.9594e-01, time/batch = 15.7020s	
18759/33250 (epoch 28.209), train_loss = 0.77614347, grad/param norm = 1.3830e-01, time/batch = 17.1728s	
18760/33250 (epoch 28.211), train_loss = 0.88979129, grad/param norm = 1.6913e-01, time/batch = 16.1702s	
18761/33250 (epoch 28.212), train_loss = 1.01204009, grad/param norm = 1.8615e-01, time/batch = 15.6854s	
18762/33250 (epoch 28.214), train_loss = 0.87262854, grad/param norm = 1.6912e-01, time/batch = 15.4247s	
18763/33250 (epoch 28.215), train_loss = 0.97158492, grad/param norm = 2.0635e-01, time/batch = 15.8590s	
18764/33250 (epoch 28.217), train_loss = 0.95340959, grad/param norm = 2.1163e-01, time/batch = 15.8089s	
18765/33250 (epoch 28.218), train_loss = 0.94687234, grad/param norm = 1.6217e-01, time/batch = 16.6929s	
18766/33250 (epoch 28.220), train_loss = 0.88464634, grad/param norm = 1.8572e-01, time/batch = 17.3578s	
18767/33250 (epoch 28.221), train_loss = 1.05101861, grad/param norm = 2.0920e-01, time/batch = 14.9803s	
18768/33250 (epoch 28.223), train_loss = 0.86464485, grad/param norm = 1.6529e-01, time/batch = 15.8001s	
18769/33250 (epoch 28.224), train_loss = 0.90562607, grad/param norm = 1.7075e-01, time/batch = 15.5830s	
18770/33250 (epoch 28.226), train_loss = 0.99872415, grad/param norm = 1.7798e-01, time/batch = 15.7202s	
18771/33250 (epoch 28.227), train_loss = 0.89285419, grad/param norm = 1.6229e-01, time/batch = 15.9568s	
18772/33250 (epoch 28.229), train_loss = 0.86384672, grad/param norm = 1.6913e-01, time/batch = 16.0400s	
18773/33250 (epoch 28.230), train_loss = 0.87416124, grad/param norm = 1.6747e-01, time/batch = 15.7310s	
18774/33250 (epoch 28.232), train_loss = 0.81221910, grad/param norm = 1.4539e-01, time/batch = 15.7187s	
18775/33250 (epoch 28.233), train_loss = 0.79488415, grad/param norm = 1.6700e-01, time/batch = 15.7266s	
18776/33250 (epoch 28.235), train_loss = 0.97875776, grad/param norm = 1.6240e-01, time/batch = 15.8865s	
18777/33250 (epoch 28.236), train_loss = 0.80096353, grad/param norm = 1.6669e-01, time/batch = 15.7919s	
18778/33250 (epoch 28.238), train_loss = 0.96300205, grad/param norm = 1.8016e-01, time/batch = 15.8834s	
18779/33250 (epoch 28.239), train_loss = 0.97449427, grad/param norm = 2.0371e-01, time/batch = 15.9651s	
18780/33250 (epoch 28.241), train_loss = 0.97809141, grad/param norm = 1.9431e-01, time/batch = 15.8781s	
18781/33250 (epoch 28.242), train_loss = 0.98119170, grad/param norm = 1.7589e-01, time/batch = 15.8734s	
18782/33250 (epoch 28.244), train_loss = 0.93316354, grad/param norm = 2.0638e-01, time/batch = 15.8862s	
18783/33250 (epoch 28.245), train_loss = 0.91290218, grad/param norm = 1.7319e-01, time/batch = 16.0411s	
18784/33250 (epoch 28.247), train_loss = 0.86846798, grad/param norm = 1.5697e-01, time/batch = 15.4799s	
18785/33250 (epoch 28.248), train_loss = 1.03001052, grad/param norm = 1.8215e-01, time/batch = 15.6426s	
18786/33250 (epoch 28.250), train_loss = 0.95677934, grad/param norm = 1.4895e-01, time/batch = 15.9674s	
18787/33250 (epoch 28.251), train_loss = 0.84244567, grad/param norm = 1.5366e-01, time/batch = 15.8876s	
18788/33250 (epoch 28.253), train_loss = 0.83340822, grad/param norm = 1.4334e-01, time/batch = 15.8172s	
18789/33250 (epoch 28.254), train_loss = 0.81362329, grad/param norm = 1.5899e-01, time/batch = 15.8822s	
18790/33250 (epoch 28.256), train_loss = 0.87413356, grad/param norm = 1.6705e-01, time/batch = 15.7354s	
18791/33250 (epoch 28.257), train_loss = 1.01087934, grad/param norm = 1.8044e-01, time/batch = 15.7307s	
18792/33250 (epoch 28.259), train_loss = 0.91515120, grad/param norm = 1.6337e-01, time/batch = 15.6341s	
18793/33250 (epoch 28.260), train_loss = 0.73570405, grad/param norm = 1.5986e-01, time/batch = 15.7214s	
18794/33250 (epoch 28.262), train_loss = 0.89449329, grad/param norm = 1.5852e-01, time/batch = 15.7292s	
18795/33250 (epoch 28.263), train_loss = 0.75906312, grad/param norm = 1.7262e-01, time/batch = 15.8063s	
18796/33250 (epoch 28.265), train_loss = 0.93269184, grad/param norm = 1.7924e-01, time/batch = 15.7967s	
18797/33250 (epoch 28.266), train_loss = 0.85159838, grad/param norm = 1.7478e-01, time/batch = 15.7327s	
18798/33250 (epoch 28.268), train_loss = 0.79181119, grad/param norm = 1.7157e-01, time/batch = 15.8200s	
18799/33250 (epoch 28.269), train_loss = 0.71168557, grad/param norm = 1.4104e-01, time/batch = 15.7344s	
18800/33250 (epoch 28.271), train_loss = 0.85595697, grad/param norm = 1.4501e-01, time/batch = 15.7981s	
18801/33250 (epoch 28.272), train_loss = 0.79284434, grad/param norm = 1.5454e-01, time/batch = 15.8834s	
18802/33250 (epoch 28.274), train_loss = 0.65917969, grad/param norm = 1.4263e-01, time/batch = 15.9469s	
18803/33250 (epoch 28.275), train_loss = 0.80124913, grad/param norm = 1.3048e-01, time/batch = 15.7964s	
18804/33250 (epoch 28.277), train_loss = 0.68266924, grad/param norm = 1.5584e-01, time/batch = 15.7947s	
18805/33250 (epoch 28.278), train_loss = 0.79446466, grad/param norm = 1.6081e-01, time/batch = 15.7962s	
18806/33250 (epoch 28.280), train_loss = 0.75399640, grad/param norm = 1.5161e-01, time/batch = 15.9652s	
18807/33250 (epoch 28.281), train_loss = 0.89572209, grad/param norm = 1.7495e-01, time/batch = 15.5553s	
18808/33250 (epoch 28.283), train_loss = 0.90323243, grad/param norm = 2.2289e-01, time/batch = 15.7250s	
18809/33250 (epoch 28.284), train_loss = 0.77041869, grad/param norm = 1.8081e-01, time/batch = 15.6408s	
18810/33250 (epoch 28.286), train_loss = 0.92190921, grad/param norm = 1.7997e-01, time/batch = 15.7570s	
18811/33250 (epoch 28.287), train_loss = 0.73427722, grad/param norm = 1.4189e-01, time/batch = 15.9631s	
18812/33250 (epoch 28.289), train_loss = 0.66965483, grad/param norm = 1.5182e-01, time/batch = 15.8796s	
18813/33250 (epoch 28.290), train_loss = 0.84650920, grad/param norm = 1.5433e-01, time/batch = 15.8852s	
18814/33250 (epoch 28.292), train_loss = 0.92518543, grad/param norm = 2.0953e-01, time/batch = 15.8856s	
18815/33250 (epoch 28.293), train_loss = 0.96811297, grad/param norm = 1.9004e-01, time/batch = 15.8014s	
18816/33250 (epoch 28.295), train_loss = 0.94581653, grad/param norm = 1.7278e-01, time/batch = 15.6423s	
18817/33250 (epoch 28.296), train_loss = 0.86712952, grad/param norm = 1.4870e-01, time/batch = 15.7988s	
18818/33250 (epoch 28.298), train_loss = 0.72602063, grad/param norm = 1.5854e-01, time/batch = 15.7269s	
18819/33250 (epoch 28.299), train_loss = 0.68510302, grad/param norm = 1.3520e-01, time/batch = 15.7343s	
18820/33250 (epoch 28.301), train_loss = 0.94488021, grad/param norm = 1.8919e-01, time/batch = 15.7301s	
18821/33250 (epoch 28.302), train_loss = 0.89708037, grad/param norm = 1.6534e-01, time/batch = 16.1381s	
18822/33250 (epoch 28.304), train_loss = 0.78487882, grad/param norm = 1.5179e-01, time/batch = 15.8130s	
18823/33250 (epoch 28.305), train_loss = 0.80727336, grad/param norm = 1.5470e-01, time/batch = 15.4803s	
18824/33250 (epoch 28.307), train_loss = 0.91078415, grad/param norm = 1.6564e-01, time/batch = 15.6404s	
18825/33250 (epoch 28.308), train_loss = 0.97411498, grad/param norm = 1.8070e-01, time/batch = 15.6355s	
18826/33250 (epoch 28.310), train_loss = 0.81853165, grad/param norm = 1.7123e-01, time/batch = 15.8019s	
18827/33250 (epoch 28.311), train_loss = 0.98125691, grad/param norm = 1.9001e-01, time/batch = 15.8069s	
18828/33250 (epoch 28.313), train_loss = 0.73059115, grad/param norm = 1.6582e-01, time/batch = 16.0447s	
18829/33250 (epoch 28.314), train_loss = 0.87071547, grad/param norm = 1.5610e-01, time/batch = 15.8944s	
18830/33250 (epoch 28.316), train_loss = 1.01580463, grad/param norm = 1.8187e-01, time/batch = 15.8655s	
18831/33250 (epoch 28.317), train_loss = 0.76363339, grad/param norm = 1.4617e-01, time/batch = 15.7307s	
18832/33250 (epoch 28.319), train_loss = 0.91392732, grad/param norm = 2.1298e-01, time/batch = 15.8891s	
18833/33250 (epoch 28.320), train_loss = 0.92348911, grad/param norm = 2.0801e-01, time/batch = 15.8938s	
18834/33250 (epoch 28.322), train_loss = 0.98514799, grad/param norm = 1.9639e-01, time/batch = 15.6361s	
18835/33250 (epoch 28.323), train_loss = 1.02473573, grad/param norm = 2.2161e-01, time/batch = 15.8080s	
18836/33250 (epoch 28.325), train_loss = 0.85083171, grad/param norm = 1.8450e-01, time/batch = 15.9581s	
18837/33250 (epoch 28.326), train_loss = 1.02579662, grad/param norm = 1.8474e-01, time/batch = 15.7977s	
18838/33250 (epoch 28.328), train_loss = 0.84006380, grad/param norm = 1.6107e-01, time/batch = 15.6490s	
18839/33250 (epoch 28.329), train_loss = 0.88434566, grad/param norm = 2.0627e-01, time/batch = 15.4055s	
18840/33250 (epoch 28.331), train_loss = 0.83435403, grad/param norm = 1.6547e-01, time/batch = 16.3938s	
18841/33250 (epoch 28.332), train_loss = 0.84700150, grad/param norm = 1.5415e-01, time/batch = 15.9735s	
18842/33250 (epoch 28.334), train_loss = 1.01504283, grad/param norm = 1.6995e-01, time/batch = 15.5728s	
18843/33250 (epoch 28.335), train_loss = 0.63624482, grad/param norm = 1.3979e-01, time/batch = 15.9713s	
18844/33250 (epoch 28.337), train_loss = 0.91214469, grad/param norm = 1.5084e-01, time/batch = 15.9532s	
18845/33250 (epoch 28.338), train_loss = 0.99764788, grad/param norm = 1.6954e-01, time/batch = 16.0266s	
18846/33250 (epoch 28.340), train_loss = 0.85254901, grad/param norm = 1.5067e-01, time/batch = 15.7179s	
18847/33250 (epoch 28.341), train_loss = 0.81036744, grad/param norm = 1.6382e-01, time/batch = 15.5594s	
18848/33250 (epoch 28.343), train_loss = 0.82478493, grad/param norm = 1.6635e-01, time/batch = 16.0596s	
18849/33250 (epoch 28.344), train_loss = 0.83664594, grad/param norm = 1.4465e-01, time/batch = 17.2732s	
18850/33250 (epoch 28.346), train_loss = 0.76809989, grad/param norm = 1.4815e-01, time/batch = 17.4423s	
18851/33250 (epoch 28.347), train_loss = 1.05710489, grad/param norm = 2.0936e-01, time/batch = 16.9697s	
18852/33250 (epoch 28.349), train_loss = 0.80648406, grad/param norm = 1.8001e-01, time/batch = 15.8860s	
18853/33250 (epoch 28.350), train_loss = 0.85285160, grad/param norm = 1.7299e-01, time/batch = 16.9469s	
18854/33250 (epoch 28.352), train_loss = 0.75089935, grad/param norm = 1.5494e-01, time/batch = 16.3647s	
18855/33250 (epoch 28.353), train_loss = 0.82113022, grad/param norm = 1.4126e-01, time/batch = 14.8619s	
18856/33250 (epoch 28.355), train_loss = 0.80923680, grad/param norm = 1.7863e-01, time/batch = 17.4329s	
18857/33250 (epoch 28.356), train_loss = 0.76794947, grad/param norm = 1.6128e-01, time/batch = 17.6846s	
18858/33250 (epoch 28.358), train_loss = 0.81758949, grad/param norm = 1.4476e-01, time/batch = 16.0942s	
18859/33250 (epoch 28.359), train_loss = 0.81313050, grad/param norm = 1.5905e-01, time/batch = 16.7542s	
18860/33250 (epoch 28.361), train_loss = 0.97293128, grad/param norm = 1.8510e-01, time/batch = 16.5380s	
18861/33250 (epoch 28.362), train_loss = 0.89082326, grad/param norm = 1.8962e-01, time/batch = 18.6146s	
18862/33250 (epoch 28.364), train_loss = 0.91562797, grad/param norm = 1.7056e-01, time/batch = 18.8685s	
18863/33250 (epoch 28.365), train_loss = 0.85514589, grad/param norm = 1.5404e-01, time/batch = 16.0291s	
18864/33250 (epoch 28.367), train_loss = 0.86992803, grad/param norm = 1.4894e-01, time/batch = 16.5194s	
18865/33250 (epoch 28.368), train_loss = 0.84155132, grad/param norm = 1.6030e-01, time/batch = 16.0965s	
18866/33250 (epoch 28.370), train_loss = 0.75418496, grad/param norm = 1.3355e-01, time/batch = 18.8347s	
18867/33250 (epoch 28.371), train_loss = 0.97461137, grad/param norm = 1.9129e-01, time/batch = 17.4397s	
18868/33250 (epoch 28.373), train_loss = 0.80573972, grad/param norm = 1.3946e-01, time/batch = 17.0250s	
18869/33250 (epoch 28.374), train_loss = 0.88278191, grad/param norm = 2.0769e-01, time/batch = 15.8606s	
18870/33250 (epoch 28.376), train_loss = 0.84075883, grad/param norm = 1.5509e-01, time/batch = 18.5124s	
18871/33250 (epoch 28.377), train_loss = 0.76167564, grad/param norm = 2.0837e-01, time/batch = 18.3829s	
18872/33250 (epoch 28.379), train_loss = 0.85535774, grad/param norm = 1.7956e-01, time/batch = 17.2785s	
18873/33250 (epoch 28.380), train_loss = 0.85642693, grad/param norm = 1.9154e-01, time/batch = 16.8633s	
18874/33250 (epoch 28.382), train_loss = 0.88010637, grad/param norm = 1.7851e-01, time/batch = 18.8485s	
18875/33250 (epoch 28.383), train_loss = 0.76332125, grad/param norm = 1.6857e-01, time/batch = 23.8060s	
18876/33250 (epoch 28.385), train_loss = 0.73072494, grad/param norm = 1.9213e-01, time/batch = 21.7978s	
18877/33250 (epoch 28.386), train_loss = 0.76833645, grad/param norm = 1.6205e-01, time/batch = 17.1023s	
18878/33250 (epoch 28.388), train_loss = 0.77576877, grad/param norm = 1.6852e-01, time/batch = 16.0246s	
18879/33250 (epoch 28.389), train_loss = 0.82340552, grad/param norm = 1.8827e-01, time/batch = 16.4421s	
18880/33250 (epoch 28.391), train_loss = 0.90918315, grad/param norm = 1.6133e-01, time/batch = 16.1921s	
18881/33250 (epoch 28.392), train_loss = 0.92706313, grad/param norm = 1.6665e-01, time/batch = 17.5345s	
18882/33250 (epoch 28.394), train_loss = 0.95311732, grad/param norm = 1.8756e-01, time/batch = 16.5906s	
18883/33250 (epoch 28.395), train_loss = 0.93462230, grad/param norm = 1.6093e-01, time/batch = 17.5943s	
18884/33250 (epoch 28.397), train_loss = 0.95868706, grad/param norm = 1.7415e-01, time/batch = 17.6648s	
18885/33250 (epoch 28.398), train_loss = 0.79433321, grad/param norm = 1.4850e-01, time/batch = 15.4914s	
18886/33250 (epoch 28.400), train_loss = 0.76744687, grad/param norm = 1.3851e-01, time/batch = 15.1875s	
18887/33250 (epoch 28.402), train_loss = 0.72620186, grad/param norm = 1.6868e-01, time/batch = 16.0159s	
18888/33250 (epoch 28.403), train_loss = 0.85439624, grad/param norm = 1.8748e-01, time/batch = 14.7856s	
18889/33250 (epoch 28.405), train_loss = 0.78923921, grad/param norm = 1.4510e-01, time/batch = 15.7668s	
18890/33250 (epoch 28.406), train_loss = 0.85183996, grad/param norm = 1.6450e-01, time/batch = 17.0913s	
18891/33250 (epoch 28.408), train_loss = 1.00781661, grad/param norm = 1.8746e-01, time/batch = 20.0267s	
18892/33250 (epoch 28.409), train_loss = 0.90619774, grad/param norm = 1.9713e-01, time/batch = 16.1995s	
18893/33250 (epoch 28.411), train_loss = 0.63405986, grad/param norm = 1.2517e-01, time/batch = 16.2976s	
18894/33250 (epoch 28.412), train_loss = 0.71490292, grad/param norm = 1.6112e-01, time/batch = 16.3449s	
18895/33250 (epoch 28.414), train_loss = 0.90446628, grad/param norm = 1.7953e-01, time/batch = 16.1977s	
18896/33250 (epoch 28.415), train_loss = 0.94019042, grad/param norm = 1.9172e-01, time/batch = 15.7677s	
18897/33250 (epoch 28.417), train_loss = 0.94849268, grad/param norm = 1.7100e-01, time/batch = 16.9115s	
18898/33250 (epoch 28.418), train_loss = 1.09845430, grad/param norm = 2.0478e-01, time/batch = 15.9897s	
18899/33250 (epoch 28.420), train_loss = 0.95786192, grad/param norm = 1.8199e-01, time/batch = 17.1785s	
18900/33250 (epoch 28.421), train_loss = 0.79172053, grad/param norm = 1.5406e-01, time/batch = 16.6725s	
18901/33250 (epoch 28.423), train_loss = 0.89145881, grad/param norm = 2.1464e-01, time/batch = 18.6990s	
18902/33250 (epoch 28.424), train_loss = 1.01050565, grad/param norm = 2.7772e-01, time/batch = 19.3690s	
18903/33250 (epoch 28.426), train_loss = 0.80818277, grad/param norm = 1.4627e-01, time/batch = 17.1819s	
18904/33250 (epoch 28.427), train_loss = 0.80406219, grad/param norm = 2.3392e-01, time/batch = 16.2761s	
18905/33250 (epoch 28.429), train_loss = 0.92000444, grad/param norm = 2.0655e-01, time/batch = 16.1945s	
18906/33250 (epoch 28.430), train_loss = 0.81579756, grad/param norm = 1.7007e-01, time/batch = 16.5153s	
18907/33250 (epoch 28.432), train_loss = 0.90637790, grad/param norm = 1.5735e-01, time/batch = 15.6159s	
18908/33250 (epoch 28.433), train_loss = 0.81849785, grad/param norm = 2.9134e-01, time/batch = 17.1186s	
18909/33250 (epoch 28.435), train_loss = 0.97862332, grad/param norm = 1.9723e-01, time/batch = 17.4361s	
18910/33250 (epoch 28.436), train_loss = 0.81403790, grad/param norm = 1.7484e-01, time/batch = 15.2738s	
18911/33250 (epoch 28.438), train_loss = 0.95027329, grad/param norm = 1.6873e-01, time/batch = 19.2882s	
18912/33250 (epoch 28.439), train_loss = 0.86810676, grad/param norm = 1.5752e-01, time/batch = 17.5454s	
18913/33250 (epoch 28.441), train_loss = 0.83873767, grad/param norm = 1.4077e-01, time/batch = 16.6212s	
18914/33250 (epoch 28.442), train_loss = 0.79043340, grad/param norm = 1.5714e-01, time/batch = 15.6676s	
18915/33250 (epoch 28.444), train_loss = 0.81425653, grad/param norm = 1.4500e-01, time/batch = 16.1780s	
18916/33250 (epoch 28.445), train_loss = 0.87093535, grad/param norm = 1.4626e-01, time/batch = 17.9279s	
18917/33250 (epoch 28.447), train_loss = 0.79634147, grad/param norm = 1.7077e-01, time/batch = 16.1733s	
18918/33250 (epoch 28.448), train_loss = 0.88770329, grad/param norm = 1.5289e-01, time/batch = 15.4036s	
18919/33250 (epoch 28.450), train_loss = 0.99426241, grad/param norm = 1.8436e-01, time/batch = 16.1823s	
18920/33250 (epoch 28.451), train_loss = 0.92634089, grad/param norm = 2.0398e-01, time/batch = 15.5243s	
18921/33250 (epoch 28.453), train_loss = 0.77560554, grad/param norm = 1.3860e-01, time/batch = 15.3014s	
18922/33250 (epoch 28.454), train_loss = 0.99484389, grad/param norm = 1.6549e-01, time/batch = 14.3377s	
18923/33250 (epoch 28.456), train_loss = 0.97939138, grad/param norm = 1.3976e-01, time/batch = 16.1766s	
18924/33250 (epoch 28.457), train_loss = 0.81911127, grad/param norm = 1.6560e-01, time/batch = 17.3340s	
18925/33250 (epoch 28.459), train_loss = 0.91643408, grad/param norm = 1.7026e-01, time/batch = 17.1004s	
18926/33250 (epoch 28.460), train_loss = 0.94514506, grad/param norm = 1.9310e-01, time/batch = 16.9891s	
18927/33250 (epoch 28.462), train_loss = 0.82268852, grad/param norm = 1.4713e-01, time/batch = 18.3467s	
18928/33250 (epoch 28.463), train_loss = 0.78556214, grad/param norm = 1.3079e-01, time/batch = 17.2498s	
18929/33250 (epoch 28.465), train_loss = 0.72127852, grad/param norm = 1.3155e-01, time/batch = 16.2676s	
18930/33250 (epoch 28.466), train_loss = 0.68246694, grad/param norm = 1.2319e-01, time/batch = 17.1133s	
18931/33250 (epoch 28.468), train_loss = 0.75289719, grad/param norm = 1.3273e-01, time/batch = 18.5304s	
18932/33250 (epoch 28.469), train_loss = 0.82440891, grad/param norm = 1.7894e-01, time/batch = 16.7072s	
18933/33250 (epoch 28.471), train_loss = 0.92095138, grad/param norm = 1.5367e-01, time/batch = 16.9524s	
18934/33250 (epoch 28.472), train_loss = 0.81674190, grad/param norm = 1.8005e-01, time/batch = 14.7458s	
18935/33250 (epoch 28.474), train_loss = 0.98008082, grad/param norm = 1.8477e-01, time/batch = 15.0507s	
18936/33250 (epoch 28.475), train_loss = 0.89723827, grad/param norm = 1.5462e-01, time/batch = 14.7702s	
18937/33250 (epoch 28.477), train_loss = 0.85372069, grad/param norm = 1.5442e-01, time/batch = 15.6770s	
18938/33250 (epoch 28.478), train_loss = 0.78483416, grad/param norm = 1.7690e-01, time/batch = 15.8446s	
18939/33250 (epoch 28.480), train_loss = 0.97722859, grad/param norm = 1.6839e-01, time/batch = 15.2613s	
18940/33250 (epoch 28.481), train_loss = 0.87013208, grad/param norm = 1.5466e-01, time/batch = 17.8267s	
18941/33250 (epoch 28.483), train_loss = 0.84184284, grad/param norm = 1.6722e-01, time/batch = 17.8703s	
18942/33250 (epoch 28.484), train_loss = 0.77036604, grad/param norm = 1.4046e-01, time/batch = 17.6119s	
18943/33250 (epoch 28.486), train_loss = 0.73833372, grad/param norm = 1.4780e-01, time/batch = 17.3897s	
18944/33250 (epoch 28.487), train_loss = 0.82468076, grad/param norm = 1.6230e-01, time/batch = 18.4568s	
18945/33250 (epoch 28.489), train_loss = 0.99064483, grad/param norm = 2.3692e-01, time/batch = 16.5085s	
18946/33250 (epoch 28.490), train_loss = 0.92250769, grad/param norm = 1.9571e-01, time/batch = 16.0886s	
18947/33250 (epoch 28.492), train_loss = 0.94361163, grad/param norm = 1.8278e-01, time/batch = 16.5189s	
18948/33250 (epoch 28.493), train_loss = 0.86272568, grad/param norm = 1.7081e-01, time/batch = 16.1249s	
18949/33250 (epoch 28.495), train_loss = 0.91628207, grad/param norm = 1.4896e-01, time/batch = 15.6076s	
18950/33250 (epoch 28.496), train_loss = 0.87003160, grad/param norm = 1.3475e-01, time/batch = 17.9196s	
18951/33250 (epoch 28.498), train_loss = 0.94955711, grad/param norm = 1.7190e-01, time/batch = 16.5272s	
18952/33250 (epoch 28.499), train_loss = 0.80910776, grad/param norm = 1.6117e-01, time/batch = 18.3585s	
18953/33250 (epoch 28.501), train_loss = 0.81153304, grad/param norm = 1.6821e-01, time/batch = 15.0482s	
18954/33250 (epoch 28.502), train_loss = 0.82297296, grad/param norm = 1.4564e-01, time/batch = 14.9001s	
18955/33250 (epoch 28.504), train_loss = 0.98766693, grad/param norm = 1.8096e-01, time/batch = 14.8916s	
18956/33250 (epoch 28.505), train_loss = 0.71660075, grad/param norm = 1.3031e-01, time/batch = 14.4783s	
18957/33250 (epoch 28.507), train_loss = 0.78711341, grad/param norm = 1.7382e-01, time/batch = 14.7282s	
18958/33250 (epoch 28.508), train_loss = 0.82633872, grad/param norm = 1.5395e-01, time/batch = 14.7288s	
18959/33250 (epoch 28.510), train_loss = 0.70356043, grad/param norm = 1.3541e-01, time/batch = 14.9588s	
18960/33250 (epoch 28.511), train_loss = 0.84897451, grad/param norm = 1.6881e-01, time/batch = 14.6454s	
18961/33250 (epoch 28.513), train_loss = 0.97679231, grad/param norm = 1.6024e-01, time/batch = 15.6061s	
18962/33250 (epoch 28.514), train_loss = 0.84849134, grad/param norm = 1.6544e-01, time/batch = 17.1766s	
18963/33250 (epoch 28.516), train_loss = 0.79500755, grad/param norm = 1.5755e-01, time/batch = 17.1976s	
18964/33250 (epoch 28.517), train_loss = 0.82455800, grad/param norm = 1.5041e-01, time/batch = 15.9694s	
18965/33250 (epoch 28.519), train_loss = 0.73992924, grad/param norm = 1.1857e-01, time/batch = 15.8380s	
18966/33250 (epoch 28.520), train_loss = 1.05268125, grad/param norm = 2.1107e-01, time/batch = 14.9500s	
18967/33250 (epoch 28.522), train_loss = 0.90973035, grad/param norm = 1.5365e-01, time/batch = 14.4671s	
18968/33250 (epoch 28.523), train_loss = 0.78838388, grad/param norm = 1.5399e-01, time/batch = 15.3751s	
18969/33250 (epoch 28.525), train_loss = 0.74709562, grad/param norm = 1.5939e-01, time/batch = 15.2667s	
18970/33250 (epoch 28.526), train_loss = 0.75553828, grad/param norm = 1.4775e-01, time/batch = 15.3739s	
18971/33250 (epoch 28.528), train_loss = 0.80694863, grad/param norm = 1.4337e-01, time/batch = 15.1083s	
18972/33250 (epoch 28.529), train_loss = 0.80180378, grad/param norm = 1.7291e-01, time/batch = 15.1163s	
18973/33250 (epoch 28.531), train_loss = 0.75740517, grad/param norm = 1.4257e-01, time/batch = 16.3741s	
18974/33250 (epoch 28.532), train_loss = 0.89858718, grad/param norm = 1.5547e-01, time/batch = 17.3776s	
18975/33250 (epoch 28.534), train_loss = 0.76819323, grad/param norm = 1.4576e-01, time/batch = 15.1149s	
18976/33250 (epoch 28.535), train_loss = 0.83360685, grad/param norm = 1.4487e-01, time/batch = 16.2037s	
18977/33250 (epoch 28.537), train_loss = 0.87275456, grad/param norm = 1.5004e-01, time/batch = 14.8804s	
18978/33250 (epoch 28.538), train_loss = 0.90361917, grad/param norm = 1.5881e-01, time/batch = 15.6226s	
18979/33250 (epoch 28.540), train_loss = 0.99770784, grad/param norm = 1.4898e-01, time/batch = 14.7960s	
18980/33250 (epoch 28.541), train_loss = 0.93409849, grad/param norm = 1.7520e-01, time/batch = 15.1903s	
18981/33250 (epoch 28.543), train_loss = 0.89955913, grad/param norm = 1.4771e-01, time/batch = 15.0323s	
18982/33250 (epoch 28.544), train_loss = 0.78688406, grad/param norm = 1.6670e-01, time/batch = 15.0217s	
18983/33250 (epoch 28.546), train_loss = 0.82918892, grad/param norm = 1.8559e-01, time/batch = 15.8663s	
18984/33250 (epoch 28.547), train_loss = 0.83351668, grad/param norm = 1.8216e-01, time/batch = 15.8466s	
18985/33250 (epoch 28.549), train_loss = 0.87764298, grad/param norm = 1.5693e-01, time/batch = 15.6492s	
18986/33250 (epoch 28.550), train_loss = 0.81799294, grad/param norm = 1.6233e-01, time/batch = 15.0322s	
18987/33250 (epoch 28.552), train_loss = 0.91509549, grad/param norm = 1.6683e-01, time/batch = 14.9503s	
18988/33250 (epoch 28.553), train_loss = 0.82081625, grad/param norm = 1.5637e-01, time/batch = 14.9384s	
18989/33250 (epoch 28.555), train_loss = 0.88171378, grad/param norm = 1.4593e-01, time/batch = 14.8670s	
18990/33250 (epoch 28.556), train_loss = 0.90028362, grad/param norm = 2.0713e-01, time/batch = 15.1556s	
18991/33250 (epoch 28.558), train_loss = 0.92469825, grad/param norm = 1.6789e-01, time/batch = 15.4823s	
18992/33250 (epoch 28.559), train_loss = 0.78246650, grad/param norm = 1.4527e-01, time/batch = 15.7957s	
18993/33250 (epoch 28.561), train_loss = 0.75386605, grad/param norm = 1.5019e-01, time/batch = 15.3348s	
18994/33250 (epoch 28.562), train_loss = 0.88304523, grad/param norm = 1.7756e-01, time/batch = 14.8718s	
18995/33250 (epoch 28.564), train_loss = 1.03364011, grad/param norm = 1.9251e-01, time/batch = 15.0149s	
18996/33250 (epoch 28.565), train_loss = 0.99974287, grad/param norm = 1.9876e-01, time/batch = 15.2034s	
18997/33250 (epoch 28.567), train_loss = 0.98437206, grad/param norm = 1.8567e-01, time/batch = 14.8821s	
18998/33250 (epoch 28.568), train_loss = 0.82460216, grad/param norm = 1.5198e-01, time/batch = 14.7898s	
18999/33250 (epoch 28.570), train_loss = 0.93813892, grad/param norm = 1.7530e-01, time/batch = 14.9409s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch28.57_1.5929.t7	
19000/33250 (epoch 28.571), train_loss = 0.99994309, grad/param norm = 1.6517e-01, time/batch = 15.5644s	
19001/33250 (epoch 28.573), train_loss = 1.53277892, grad/param norm = 2.3692e-01, time/batch = 16.2292s	
19002/33250 (epoch 28.574), train_loss = 0.79301574, grad/param norm = 1.6128e-01, time/batch = 16.0790s	
19003/33250 (epoch 28.576), train_loss = 0.93186710, grad/param norm = 1.6741e-01, time/batch = 15.9176s	
19004/33250 (epoch 28.577), train_loss = 0.84723874, grad/param norm = 1.4616e-01, time/batch = 15.8430s	
19005/33250 (epoch 28.579), train_loss = 0.77321714, grad/param norm = 1.6845e-01, time/batch = 15.9700s	
19006/33250 (epoch 28.580), train_loss = 0.80869619, grad/param norm = 1.3107e-01, time/batch = 15.8598s	
19007/33250 (epoch 28.582), train_loss = 0.82535650, grad/param norm = 1.6636e-01, time/batch = 16.0399s	
19008/33250 (epoch 28.583), train_loss = 0.96107437, grad/param norm = 1.6172e-01, time/batch = 16.0217s	
19009/33250 (epoch 28.585), train_loss = 0.95842964, grad/param norm = 1.6015e-01, time/batch = 15.7908s	
19010/33250 (epoch 28.586), train_loss = 0.79268201, grad/param norm = 2.0076e-01, time/batch = 15.6777s	
19011/33250 (epoch 28.588), train_loss = 0.89262204, grad/param norm = 1.5568e-01, time/batch = 15.9854s	
19012/33250 (epoch 28.589), train_loss = 0.87905200, grad/param norm = 1.8293e-01, time/batch = 15.9160s	
19013/33250 (epoch 28.591), train_loss = 0.86425749, grad/param norm = 1.8730e-01, time/batch = 15.8345s	
19014/33250 (epoch 28.592), train_loss = 0.84612121, grad/param norm = 1.5481e-01, time/batch = 15.6669s	
19015/33250 (epoch 28.594), train_loss = 0.97934181, grad/param norm = 1.7814e-01, time/batch = 15.9090s	
19016/33250 (epoch 28.595), train_loss = 0.87766767, grad/param norm = 1.6013e-01, time/batch = 15.9895s	
19017/33250 (epoch 28.597), train_loss = 0.73011377, grad/param norm = 1.3974e-01, time/batch = 15.9987s	
19018/33250 (epoch 28.598), train_loss = 0.82808586, grad/param norm = 1.7799e-01, time/batch = 15.9176s	
19019/33250 (epoch 28.600), train_loss = 0.83065078, grad/param norm = 1.6456e-01, time/batch = 15.8971s	
19020/33250 (epoch 28.602), train_loss = 0.87261465, grad/param norm = 1.7727e-01, time/batch = 15.9288s	
19021/33250 (epoch 28.603), train_loss = 0.91677734, grad/param norm = 1.6984e-01, time/batch = 16.2171s	
19022/33250 (epoch 28.605), train_loss = 0.85993879, grad/param norm = 1.5807e-01, time/batch = 15.8384s	
19023/33250 (epoch 28.606), train_loss = 0.92740693, grad/param norm = 1.7415e-01, time/batch = 15.9247s	
19024/33250 (epoch 28.608), train_loss = 0.86669734, grad/param norm = 1.4350e-01, time/batch = 15.9141s	
19025/33250 (epoch 28.609), train_loss = 0.77211466, grad/param norm = 1.4980e-01, time/batch = 16.0114s	
19026/33250 (epoch 28.611), train_loss = 0.88374733, grad/param norm = 1.8162e-01, time/batch = 15.7703s	
19027/33250 (epoch 28.612), train_loss = 0.86161445, grad/param norm = 1.6706e-01, time/batch = 15.8661s	
19028/33250 (epoch 28.614), train_loss = 1.06411671, grad/param norm = 1.9836e-01, time/batch = 15.6950s	
19029/33250 (epoch 28.615), train_loss = 0.96946195, grad/param norm = 1.7509e-01, time/batch = 15.9360s	
19030/33250 (epoch 28.617), train_loss = 1.08254942, grad/param norm = 1.9889e-01, time/batch = 15.9482s	
19031/33250 (epoch 28.618), train_loss = 1.11358782, grad/param norm = 2.1890e-01, time/batch = 16.1068s	
19032/33250 (epoch 28.620), train_loss = 0.96212095, grad/param norm = 1.8211e-01, time/batch = 16.0717s	
19033/33250 (epoch 28.621), train_loss = 0.92164113, grad/param norm = 1.6570e-01, time/batch = 15.8497s	
19034/33250 (epoch 28.623), train_loss = 0.80414684, grad/param norm = 1.6923e-01, time/batch = 15.6807s	
19035/33250 (epoch 28.624), train_loss = 0.83744457, grad/param norm = 1.5722e-01, time/batch = 15.9110s	
19036/33250 (epoch 28.626), train_loss = 0.82654737, grad/param norm = 1.8445e-01, time/batch = 15.8379s	
19037/33250 (epoch 28.627), train_loss = 0.82082801, grad/param norm = 1.6234e-01, time/batch = 15.9216s	
19038/33250 (epoch 28.629), train_loss = 0.91690100, grad/param norm = 2.2824e-01, time/batch = 15.6872s	
19039/33250 (epoch 28.630), train_loss = 0.83737094, grad/param norm = 1.6709e-01, time/batch = 15.6182s	
19040/33250 (epoch 28.632), train_loss = 0.73561797, grad/param norm = 1.4176e-01, time/batch = 15.8562s	
19041/33250 (epoch 28.633), train_loss = 0.86078409, grad/param norm = 1.6666e-01, time/batch = 15.9506s	
19042/33250 (epoch 28.635), train_loss = 0.78603492, grad/param norm = 1.4856e-01, time/batch = 15.7646s	
19043/33250 (epoch 28.636), train_loss = 0.80356258, grad/param norm = 1.5452e-01, time/batch = 15.8469s	
19044/33250 (epoch 28.638), train_loss = 0.78173900, grad/param norm = 1.6708e-01, time/batch = 15.6803s	
19045/33250 (epoch 28.639), train_loss = 0.74883667, grad/param norm = 1.6044e-01, time/batch = 15.8311s	
19046/33250 (epoch 28.641), train_loss = 0.84068463, grad/param norm = 1.5581e-01, time/batch = 15.6845s	
19047/33250 (epoch 28.642), train_loss = 0.65594227, grad/param norm = 1.4775e-01, time/batch = 15.8454s	
19048/33250 (epoch 28.644), train_loss = 0.60717025, grad/param norm = 1.4747e-01, time/batch = 15.8550s	
19049/33250 (epoch 28.645), train_loss = 0.88601311, grad/param norm = 1.8798e-01, time/batch = 15.8670s	
19050/33250 (epoch 28.647), train_loss = 0.74187514, grad/param norm = 1.6238e-01, time/batch = 15.6140s	
19051/33250 (epoch 28.648), train_loss = 0.76041400, grad/param norm = 1.7432e-01, time/batch = 16.0107s	
19052/33250 (epoch 28.650), train_loss = 1.01471957, grad/param norm = 2.0469e-01, time/batch = 15.9375s	
19053/33250 (epoch 28.651), train_loss = 0.90402343, grad/param norm = 1.9966e-01, time/batch = 15.9264s	
19054/33250 (epoch 28.653), train_loss = 0.80253984, grad/param norm = 1.8248e-01, time/batch = 15.9311s	
19055/33250 (epoch 28.654), train_loss = 0.86476220, grad/param norm = 1.5464e-01, time/batch = 15.9379s	
19056/33250 (epoch 28.656), train_loss = 0.88585183, grad/param norm = 1.5801e-01, time/batch = 15.9212s	
19057/33250 (epoch 28.657), train_loss = 0.69188921, grad/param norm = 1.7181e-01, time/batch = 16.0860s	
19058/33250 (epoch 28.659), train_loss = 0.79818478, grad/param norm = 1.7023e-01, time/batch = 15.9183s	
19059/33250 (epoch 28.660), train_loss = 0.86859477, grad/param norm = 1.7878e-01, time/batch = 15.8644s	
19060/33250 (epoch 28.662), train_loss = 0.86034304, grad/param norm = 1.7229e-01, time/batch = 16.0259s	
19061/33250 (epoch 28.663), train_loss = 0.78601529, grad/param norm = 1.5536e-01, time/batch = 15.9583s	
19062/33250 (epoch 28.665), train_loss = 0.90100457, grad/param norm = 1.6940e-01, time/batch = 16.1086s	
19063/33250 (epoch 28.666), train_loss = 0.81159861, grad/param norm = 1.4608e-01, time/batch = 16.0816s	
19064/33250 (epoch 28.668), train_loss = 0.96784224, grad/param norm = 1.7435e-01, time/batch = 15.9224s	
19065/33250 (epoch 28.669), train_loss = 0.85256240, grad/param norm = 1.5941e-01, time/batch = 16.0029s	
19066/33250 (epoch 28.671), train_loss = 0.79045381, grad/param norm = 2.5038e-01, time/batch = 16.1708s	
19067/33250 (epoch 28.672), train_loss = 0.92617197, grad/param norm = 1.7399e-01, time/batch = 16.0211s	
19068/33250 (epoch 28.674), train_loss = 0.75697547, grad/param norm = 1.6206e-01, time/batch = 15.7952s	
19069/33250 (epoch 28.675), train_loss = 0.86033587, grad/param norm = 1.5955e-01, time/batch = 15.9273s	
19070/33250 (epoch 28.677), train_loss = 0.93105263, grad/param norm = 1.6309e-01, time/batch = 16.0469s	
19071/33250 (epoch 28.678), train_loss = 0.82700367, grad/param norm = 1.6704e-01, time/batch = 16.0341s	
19072/33250 (epoch 28.680), train_loss = 0.94415789, grad/param norm = 1.8435e-01, time/batch = 15.8804s	
19073/33250 (epoch 28.681), train_loss = 0.77363665, grad/param norm = 1.5260e-01, time/batch = 15.9518s	
19074/33250 (epoch 28.683), train_loss = 0.80157659, grad/param norm = 1.9219e-01, time/batch = 16.1012s	
19075/33250 (epoch 28.684), train_loss = 0.76757175, grad/param norm = 1.8147e-01, time/batch = 15.9308s	
19076/33250 (epoch 28.686), train_loss = 0.78867631, grad/param norm = 1.6430e-01, time/batch = 15.7063s	
19077/33250 (epoch 28.687), train_loss = 0.85438677, grad/param norm = 1.5935e-01, time/batch = 16.0171s	
19078/33250 (epoch 28.689), train_loss = 0.76430824, grad/param norm = 1.6314e-01, time/batch = 15.6967s	
19079/33250 (epoch 28.690), train_loss = 0.86349104, grad/param norm = 1.6394e-01, time/batch = 15.9344s	
19080/33250 (epoch 28.692), train_loss = 0.81984219, grad/param norm = 1.6458e-01, time/batch = 15.8485s	
19081/33250 (epoch 28.693), train_loss = 0.91764571, grad/param norm = 1.5838e-01, time/batch = 16.4334s	
19082/33250 (epoch 28.695), train_loss = 0.88821971, grad/param norm = 1.5891e-01, time/batch = 16.2804s	
19083/33250 (epoch 28.696), train_loss = 0.91066231, grad/param norm = 1.6424e-01, time/batch = 15.8069s	
19084/33250 (epoch 28.698), train_loss = 0.80444840, grad/param norm = 1.6429e-01, time/batch = 15.8589s	
19085/33250 (epoch 28.699), train_loss = 1.06268137, grad/param norm = 1.7944e-01, time/batch = 15.9474s	
19086/33250 (epoch 28.701), train_loss = 0.84520519, grad/param norm = 1.3840e-01, time/batch = 15.9448s	
19087/33250 (epoch 28.702), train_loss = 0.81389563, grad/param norm = 2.1699e-01, time/batch = 15.9477s	
19088/33250 (epoch 28.704), train_loss = 1.03783421, grad/param norm = 2.1661e-01, time/batch = 26.4905s	
19089/33250 (epoch 28.705), train_loss = 0.80186056, grad/param norm = 1.6566e-01, time/batch = 18.9665s	
19090/33250 (epoch 28.707), train_loss = 0.72404012, grad/param norm = 1.7223e-01, time/batch = 15.6788s	
19091/33250 (epoch 28.708), train_loss = 0.92301171, grad/param norm = 1.6058e-01, time/batch = 15.7840s	
19092/33250 (epoch 28.710), train_loss = 0.91015897, grad/param norm = 1.8667e-01, time/batch = 15.4665s	
19093/33250 (epoch 28.711), train_loss = 0.75878489, grad/param norm = 1.6413e-01, time/batch = 15.8328s	
19094/33250 (epoch 28.713), train_loss = 0.87851201, grad/param norm = 1.5215e-01, time/batch = 15.6700s	
19095/33250 (epoch 28.714), train_loss = 0.84621216, grad/param norm = 1.6216e-01, time/batch = 15.6777s	
19096/33250 (epoch 28.716), train_loss = 0.89513137, grad/param norm = 1.7174e-01, time/batch = 15.4438s	
19097/33250 (epoch 28.717), train_loss = 0.78101270, grad/param norm = 1.4690e-01, time/batch = 15.5332s	
19098/33250 (epoch 28.719), train_loss = 0.82697779, grad/param norm = 1.6216e-01, time/batch = 15.5980s	
19099/33250 (epoch 28.720), train_loss = 1.08577932, grad/param norm = 2.0237e-01, time/batch = 15.4333s	
19100/33250 (epoch 28.722), train_loss = 0.75717884, grad/param norm = 1.6607e-01, time/batch = 15.2642s	
19101/33250 (epoch 28.723), train_loss = 0.68207045, grad/param norm = 1.3004e-01, time/batch = 15.4868s	
19102/33250 (epoch 28.725), train_loss = 0.79046932, grad/param norm = 1.3669e-01, time/batch = 15.5111s	
19103/33250 (epoch 28.726), train_loss = 0.82742681, grad/param norm = 1.4598e-01, time/batch = 15.6772s	
19104/33250 (epoch 28.728), train_loss = 0.89469785, grad/param norm = 1.6868e-01, time/batch = 15.6786s	
19105/33250 (epoch 28.729), train_loss = 0.93849645, grad/param norm = 1.6908e-01, time/batch = 15.5296s	
19106/33250 (epoch 28.731), train_loss = 0.77337470, grad/param norm = 1.7602e-01, time/batch = 15.6801s	
19107/33250 (epoch 28.732), train_loss = 0.77522495, grad/param norm = 1.4154e-01, time/batch = 15.7640s	
19108/33250 (epoch 28.734), train_loss = 0.89585715, grad/param norm = 1.9045e-01, time/batch = 15.5995s	
19109/33250 (epoch 28.735), train_loss = 0.89362883, grad/param norm = 1.8346e-01, time/batch = 15.6747s	
19110/33250 (epoch 28.737), train_loss = 0.81482515, grad/param norm = 1.5465e-01, time/batch = 15.8476s	
19111/33250 (epoch 28.738), train_loss = 0.87356606, grad/param norm = 1.5305e-01, time/batch = 15.9215s	
19112/33250 (epoch 28.740), train_loss = 0.90668892, grad/param norm = 1.7768e-01, time/batch = 15.9975s	
19113/33250 (epoch 28.741), train_loss = 0.92068759, grad/param norm = 1.6767e-01, time/batch = 15.7734s	
19114/33250 (epoch 28.743), train_loss = 0.79166219, grad/param norm = 1.4922e-01, time/batch = 15.7513s	
19115/33250 (epoch 28.744), train_loss = 0.82468289, grad/param norm = 1.8821e-01, time/batch = 15.8577s	
19116/33250 (epoch 28.746), train_loss = 0.75777663, grad/param norm = 1.4508e-01, time/batch = 15.8693s	
19117/33250 (epoch 28.747), train_loss = 0.80699639, grad/param norm = 1.7494e-01, time/batch = 15.6157s	
19118/33250 (epoch 28.749), train_loss = 0.95996530, grad/param norm = 1.7528e-01, time/batch = 15.9305s	
19119/33250 (epoch 28.750), train_loss = 0.92139296, grad/param norm = 1.7528e-01, time/batch = 15.9519s	
19120/33250 (epoch 28.752), train_loss = 0.82050832, grad/param norm = 1.5856e-01, time/batch = 15.7619s	
19121/33250 (epoch 28.753), train_loss = 0.81936262, grad/param norm = 1.7418e-01, time/batch = 15.7661s	
19122/33250 (epoch 28.755), train_loss = 0.77821528, grad/param norm = 1.9843e-01, time/batch = 15.7721s	
19123/33250 (epoch 28.756), train_loss = 0.86600995, grad/param norm = 1.6014e-01, time/batch = 16.0286s	
19124/33250 (epoch 28.758), train_loss = 0.99662636, grad/param norm = 1.6458e-01, time/batch = 15.7976s	
19125/33250 (epoch 28.759), train_loss = 0.79074331, grad/param norm = 1.5224e-01, time/batch = 15.8636s	
19126/33250 (epoch 28.761), train_loss = 0.85583800, grad/param norm = 1.5852e-01, time/batch = 15.7931s	
19127/33250 (epoch 28.762), train_loss = 0.93111936, grad/param norm = 1.6740e-01, time/batch = 15.8652s	
19128/33250 (epoch 28.764), train_loss = 0.77419525, grad/param norm = 2.1802e-01, time/batch = 15.6953s	
19129/33250 (epoch 28.765), train_loss = 0.90845790, grad/param norm = 1.8337e-01, time/batch = 15.8439s	
19130/33250 (epoch 28.767), train_loss = 0.68242560, grad/param norm = 1.4922e-01, time/batch = 15.7657s	
19131/33250 (epoch 28.768), train_loss = 0.72120011, grad/param norm = 1.6005e-01, time/batch = 16.0865s	
19132/33250 (epoch 28.770), train_loss = 0.89508503, grad/param norm = 1.7608e-01, time/batch = 15.7772s	
19133/33250 (epoch 28.771), train_loss = 0.90940017, grad/param norm = 1.7130e-01, time/batch = 15.7772s	
19134/33250 (epoch 28.773), train_loss = 0.81660102, grad/param norm = 1.7650e-01, time/batch = 15.6249s	
19135/33250 (epoch 28.774), train_loss = 0.73079007, grad/param norm = 1.5389e-01, time/batch = 15.8137s	
19136/33250 (epoch 28.776), train_loss = 0.80523364, grad/param norm = 1.6444e-01, time/batch = 15.9491s	
19137/33250 (epoch 28.777), train_loss = 0.91825703, grad/param norm = 1.7608e-01, time/batch = 15.8494s	
19138/33250 (epoch 28.779), train_loss = 0.83968104, grad/param norm = 1.6764e-01, time/batch = 15.7585s	
19139/33250 (epoch 28.780), train_loss = 0.98944521, grad/param norm = 2.0486e-01, time/batch = 15.7004s	
19140/33250 (epoch 28.782), train_loss = 0.85950812, grad/param norm = 2.0169e-01, time/batch = 15.5212s	
19141/33250 (epoch 28.783), train_loss = 0.70260001, grad/param norm = 1.3910e-01, time/batch = 15.8330s	
19142/33250 (epoch 28.785), train_loss = 0.74353258, grad/param norm = 1.7401e-01, time/batch = 15.5782s	
19143/33250 (epoch 28.786), train_loss = 0.97199958, grad/param norm = 1.8254e-01, time/batch = 15.6655s	
19144/33250 (epoch 28.788), train_loss = 0.94850973, grad/param norm = 1.7010e-01, time/batch = 15.9697s	
19145/33250 (epoch 28.789), train_loss = 0.95176525, grad/param norm = 1.9699e-01, time/batch = 15.6613s	
19146/33250 (epoch 28.791), train_loss = 0.98734115, grad/param norm = 2.0900e-01, time/batch = 15.7543s	
19147/33250 (epoch 28.792), train_loss = 1.01430871, grad/param norm = 1.6711e-01, time/batch = 15.8092s	
19148/33250 (epoch 28.794), train_loss = 0.83629583, grad/param norm = 1.6367e-01, time/batch = 15.7811s	
19149/33250 (epoch 28.795), train_loss = 0.86643529, grad/param norm = 1.6900e-01, time/batch = 15.6178s	
19150/33250 (epoch 28.797), train_loss = 0.92158700, grad/param norm = 1.8754e-01, time/batch = 15.9932s	
19151/33250 (epoch 28.798), train_loss = 0.85374670, grad/param norm = 1.9680e-01, time/batch = 16.0306s	
19152/33250 (epoch 28.800), train_loss = 0.90245298, grad/param norm = 1.7670e-01, time/batch = 15.8570s	
19153/33250 (epoch 28.802), train_loss = 0.82993775, grad/param norm = 1.5627e-01, time/batch = 15.6214s	
19154/33250 (epoch 28.803), train_loss = 0.88445641, grad/param norm = 1.5892e-01, time/batch = 15.7845s	
19155/33250 (epoch 28.805), train_loss = 0.89502968, grad/param norm = 1.7333e-01, time/batch = 15.9276s	
19156/33250 (epoch 28.806), train_loss = 0.86884669, grad/param norm = 1.8441e-01, time/batch = 15.8064s	
19157/33250 (epoch 28.808), train_loss = 0.79189023, grad/param norm = 1.6060e-01, time/batch = 15.7923s	
19158/33250 (epoch 28.809), train_loss = 0.76777236, grad/param norm = 1.5357e-01, time/batch = 15.8657s	
19159/33250 (epoch 28.811), train_loss = 0.77752103, grad/param norm = 1.5745e-01, time/batch = 15.7798s	
19160/33250 (epoch 28.812), train_loss = 0.90569601, grad/param norm = 1.8891e-01, time/batch = 15.4957s	
19161/33250 (epoch 28.814), train_loss = 0.84700634, grad/param norm = 1.9517e-01, time/batch = 15.7705s	
19162/33250 (epoch 28.815), train_loss = 0.91307916, grad/param norm = 1.4846e-01, time/batch = 15.9406s	
19163/33250 (epoch 28.817), train_loss = 0.83645806, grad/param norm = 1.5702e-01, time/batch = 16.0831s	
19164/33250 (epoch 28.818), train_loss = 0.77625747, grad/param norm = 1.5914e-01, time/batch = 15.8726s	
19165/33250 (epoch 28.820), train_loss = 0.87632682, grad/param norm = 1.7566e-01, time/batch = 15.8652s	
19166/33250 (epoch 28.821), train_loss = 0.83001842, grad/param norm = 1.5482e-01, time/batch = 15.5454s	
19167/33250 (epoch 28.823), train_loss = 1.17029905, grad/param norm = 2.0831e-01, time/batch = 15.9495s	
19168/33250 (epoch 28.824), train_loss = 0.81901524, grad/param norm = 1.9154e-01, time/batch = 15.7974s	
19169/33250 (epoch 28.826), train_loss = 0.88343545, grad/param norm = 1.6258e-01, time/batch = 15.8504s	
19170/33250 (epoch 28.827), train_loss = 0.75046081, grad/param norm = 1.6568e-01, time/batch = 15.7763s	
19171/33250 (epoch 28.829), train_loss = 0.86128613, grad/param norm = 1.9628e-01, time/batch = 15.6762s	
19172/33250 (epoch 28.830), train_loss = 0.95116544, grad/param norm = 2.1105e-01, time/batch = 15.6995s	
19173/33250 (epoch 28.832), train_loss = 0.85657248, grad/param norm = 1.6907e-01, time/batch = 15.7111s	
19174/33250 (epoch 28.833), train_loss = 0.85711931, grad/param norm = 1.7376e-01, time/batch = 15.7724s	
19175/33250 (epoch 28.835), train_loss = 0.79698337, grad/param norm = 2.2065e-01, time/batch = 15.9439s	
19176/33250 (epoch 28.836), train_loss = 0.84476569, grad/param norm = 1.7753e-01, time/batch = 15.5939s	
19177/33250 (epoch 28.838), train_loss = 0.90130142, grad/param norm = 1.6968e-01, time/batch = 15.5470s	
19178/33250 (epoch 28.839), train_loss = 0.81665811, grad/param norm = 1.6218e-01, time/batch = 15.6839s	
19179/33250 (epoch 28.841), train_loss = 0.78301261, grad/param norm = 1.3780e-01, time/batch = 15.7037s	
19180/33250 (epoch 28.842), train_loss = 0.98619442, grad/param norm = 1.6271e-01, time/batch = 15.5631s	
19181/33250 (epoch 28.844), train_loss = 0.95589721, grad/param norm = 1.7983e-01, time/batch = 15.7731s	
19182/33250 (epoch 28.845), train_loss = 1.03130421, grad/param norm = 1.8850e-01, time/batch = 15.9245s	
19183/33250 (epoch 28.847), train_loss = 1.01830141, grad/param norm = 1.7355e-01, time/batch = 15.6903s	
19184/33250 (epoch 28.848), train_loss = 1.07573847, grad/param norm = 2.0579e-01, time/batch = 15.4509s	
19185/33250 (epoch 28.850), train_loss = 0.95572622, grad/param norm = 1.7148e-01, time/batch = 15.8498s	
19186/33250 (epoch 28.851), train_loss = 0.77650795, grad/param norm = 1.6996e-01, time/batch = 15.7860s	
19187/33250 (epoch 28.853), train_loss = 0.91805376, grad/param norm = 1.8978e-01, time/batch = 15.6865s	
19188/33250 (epoch 28.854), train_loss = 0.83056778, grad/param norm = 1.4653e-01, time/batch = 15.8455s	
19189/33250 (epoch 28.856), train_loss = 0.81891998, grad/param norm = 1.8201e-01, time/batch = 15.8803s	
19190/33250 (epoch 28.857), train_loss = 0.74880048, grad/param norm = 1.6425e-01, time/batch = 15.7124s	
19191/33250 (epoch 28.859), train_loss = 0.78354179, grad/param norm = 2.0291e-01, time/batch = 15.8707s	
19192/33250 (epoch 28.860), train_loss = 0.88646223, grad/param norm = 1.6089e-01, time/batch = 15.5479s	
19193/33250 (epoch 28.862), train_loss = 0.76235520, grad/param norm = 1.7314e-01, time/batch = 15.7060s	
19194/33250 (epoch 28.863), train_loss = 0.80178629, grad/param norm = 1.7556e-01, time/batch = 15.8590s	
19195/33250 (epoch 28.865), train_loss = 0.89413986, grad/param norm = 1.7288e-01, time/batch = 15.5317s	
19196/33250 (epoch 28.866), train_loss = 0.76326837, grad/param norm = 1.6137e-01, time/batch = 15.5976s	
19197/33250 (epoch 28.868), train_loss = 0.88412591, grad/param norm = 1.9489e-01, time/batch = 16.0110s	
19198/33250 (epoch 28.869), train_loss = 0.87762277, grad/param norm = 1.7625e-01, time/batch = 15.6409s	
19199/33250 (epoch 28.871), train_loss = 0.67667238, grad/param norm = 1.3965e-01, time/batch = 15.7861s	
19200/33250 (epoch 28.872), train_loss = 0.93038310, grad/param norm = 1.9722e-01, time/batch = 15.8077s	
19201/33250 (epoch 28.874), train_loss = 0.77650397, grad/param norm = 1.6254e-01, time/batch = 16.0190s	
19202/33250 (epoch 28.875), train_loss = 0.77028237, grad/param norm = 2.3724e-01, time/batch = 15.4595s	
19203/33250 (epoch 28.877), train_loss = 0.98575535, grad/param norm = 1.7494e-01, time/batch = 15.7591s	
19204/33250 (epoch 28.878), train_loss = 0.88955022, grad/param norm = 1.5894e-01, time/batch = 15.6983s	
19205/33250 (epoch 28.880), train_loss = 0.85089844, grad/param norm = 2.2160e-01, time/batch = 15.8238s	
19206/33250 (epoch 28.881), train_loss = 0.96161209, grad/param norm = 1.7107e-01, time/batch = 15.7260s	
19207/33250 (epoch 28.883), train_loss = 0.88959016, grad/param norm = 1.6213e-01, time/batch = 15.5597s	
19208/33250 (epoch 28.884), train_loss = 0.93117520, grad/param norm = 1.7461e-01, time/batch = 15.3900s	
19209/33250 (epoch 28.886), train_loss = 0.80299291, grad/param norm = 1.4592e-01, time/batch = 15.3969s	
19210/33250 (epoch 28.887), train_loss = 0.81457040, grad/param norm = 1.7453e-01, time/batch = 15.3877s	
19211/33250 (epoch 28.889), train_loss = 0.80228964, grad/param norm = 1.4646e-01, time/batch = 15.2829s	
19212/33250 (epoch 28.890), train_loss = 0.67390090, grad/param norm = 1.2504e-01, time/batch = 15.5583s	
19213/33250 (epoch 28.892), train_loss = 0.88900946, grad/param norm = 1.4999e-01, time/batch = 15.6823s	
19214/33250 (epoch 28.893), train_loss = 0.93128573, grad/param norm = 2.0637e-01, time/batch = 15.7757s	
19215/33250 (epoch 28.895), train_loss = 0.79326753, grad/param norm = 1.6001e-01, time/batch = 15.8581s	
19216/33250 (epoch 28.896), train_loss = 0.91111322, grad/param norm = 1.7630e-01, time/batch = 15.9370s	
19217/33250 (epoch 28.898), train_loss = 0.85133764, grad/param norm = 1.5947e-01, time/batch = 15.9297s	
19218/33250 (epoch 28.899), train_loss = 0.79181939, grad/param norm = 1.4711e-01, time/batch = 15.6064s	
19219/33250 (epoch 28.901), train_loss = 0.73627504, grad/param norm = 1.4473e-01, time/batch = 15.8604s	
19220/33250 (epoch 28.902), train_loss = 0.83499221, grad/param norm = 1.6734e-01, time/batch = 9.5841s	
19221/33250 (epoch 28.904), train_loss = 0.76676266, grad/param norm = 1.4862e-01, time/batch = 0.6926s	
19222/33250 (epoch 28.905), train_loss = 0.82302136, grad/param norm = 1.5341e-01, time/batch = 0.6894s	
19223/33250 (epoch 28.907), train_loss = 0.75766394, grad/param norm = 1.4439e-01, time/batch = 0.6900s	
19224/33250 (epoch 28.908), train_loss = 0.84524532, grad/param norm = 1.3949e-01, time/batch = 0.6997s	
19225/33250 (epoch 28.910), train_loss = 0.91880730, grad/param norm = 1.9269e-01, time/batch = 0.6895s	
19226/33250 (epoch 28.911), train_loss = 0.74881849, grad/param norm = 1.4046e-01, time/batch = 0.6876s	
19227/33250 (epoch 28.913), train_loss = 0.81627152, grad/param norm = 1.6273e-01, time/batch = 0.7636s	
19228/33250 (epoch 28.914), train_loss = 0.71936390, grad/param norm = 1.5634e-01, time/batch = 0.9974s	
19229/33250 (epoch 28.916), train_loss = 0.76598083, grad/param norm = 1.4609e-01, time/batch = 1.0072s	
19230/33250 (epoch 28.917), train_loss = 0.85038050, grad/param norm = 1.4461e-01, time/batch = 0.9899s	
19231/33250 (epoch 28.919), train_loss = 0.78967864, grad/param norm = 1.7950e-01, time/batch = 0.9846s	
19232/33250 (epoch 28.920), train_loss = 0.83857975, grad/param norm = 1.6516e-01, time/batch = 1.2285s	
19233/33250 (epoch 28.922), train_loss = 0.87505102, grad/param norm = 1.6995e-01, time/batch = 1.9001s	
19234/33250 (epoch 28.923), train_loss = 0.80786684, grad/param norm = 1.7627e-01, time/batch = 1.8542s	
19235/33250 (epoch 28.925), train_loss = 0.80976041, grad/param norm = 1.5649e-01, time/batch = 10.4575s	
19236/33250 (epoch 28.926), train_loss = 0.79965660, grad/param norm = 1.5372e-01, time/batch = 15.8160s	
19237/33250 (epoch 28.928), train_loss = 0.80323440, grad/param norm = 1.5601e-01, time/batch = 15.7498s	
19238/33250 (epoch 28.929), train_loss = 0.71488566, grad/param norm = 1.3284e-01, time/batch = 15.9919s	
19239/33250 (epoch 28.931), train_loss = 0.95187301, grad/param norm = 1.7668e-01, time/batch = 15.6716s	
19240/33250 (epoch 28.932), train_loss = 0.79462871, grad/param norm = 1.5538e-01, time/batch = 15.6703s	
19241/33250 (epoch 28.934), train_loss = 0.78406415, grad/param norm = 1.3598e-01, time/batch = 15.8321s	
19242/33250 (epoch 28.935), train_loss = 0.78512205, grad/param norm = 1.6606e-01, time/batch = 15.6836s	
19243/33250 (epoch 28.937), train_loss = 0.79673770, grad/param norm = 1.8498e-01, time/batch = 15.7794s	
19244/33250 (epoch 28.938), train_loss = 0.84945844, grad/param norm = 1.7296e-01, time/batch = 15.7102s	
19245/33250 (epoch 28.940), train_loss = 0.81267363, grad/param norm = 1.6488e-01, time/batch = 15.7820s	
19246/33250 (epoch 28.941), train_loss = 0.90812110, grad/param norm = 2.1211e-01, time/batch = 15.8444s	
19247/33250 (epoch 28.943), train_loss = 0.99243097, grad/param norm = 1.7289e-01, time/batch = 15.6986s	
19248/33250 (epoch 28.944), train_loss = 0.80679866, grad/param norm = 1.6129e-01, time/batch = 15.6764s	
19249/33250 (epoch 28.946), train_loss = 0.95347504, grad/param norm = 1.6128e-01, time/batch = 15.6479s	
19250/33250 (epoch 28.947), train_loss = 0.78103530, grad/param norm = 1.5656e-01, time/batch = 15.5551s	
19251/33250 (epoch 28.949), train_loss = 0.90832465, grad/param norm = 1.7406e-01, time/batch = 15.8096s	
19252/33250 (epoch 28.950), train_loss = 0.90108856, grad/param norm = 1.5984e-01, time/batch = 15.7301s	
19253/33250 (epoch 28.952), train_loss = 0.84524216, grad/param norm = 1.7086e-01, time/batch = 16.0569s	
19254/33250 (epoch 28.953), train_loss = 0.92483814, grad/param norm = 1.8062e-01, time/batch = 15.7891s	
19255/33250 (epoch 28.955), train_loss = 0.91722306, grad/param norm = 1.6131e-01, time/batch = 15.6209s	
19256/33250 (epoch 28.956), train_loss = 0.89595314, grad/param norm = 2.5640e-01, time/batch = 15.6934s	
19257/33250 (epoch 28.958), train_loss = 0.78696829, grad/param norm = 1.4901e-01, time/batch = 15.7795s	
19258/33250 (epoch 28.959), train_loss = 0.80452049, grad/param norm = 1.6081e-01, time/batch = 15.6922s	
19259/33250 (epoch 28.961), train_loss = 1.05835077, grad/param norm = 1.8198e-01, time/batch = 15.6986s	
19260/33250 (epoch 28.962), train_loss = 0.83748084, grad/param norm = 1.6737e-01, time/batch = 15.8445s	
19261/33250 (epoch 28.964), train_loss = 1.00539266, grad/param norm = 2.0910e-01, time/batch = 15.6019s	
19262/33250 (epoch 28.965), train_loss = 0.92356491, grad/param norm = 2.1991e-01, time/batch = 15.6179s	
19263/33250 (epoch 28.967), train_loss = 0.89086003, grad/param norm = 1.6053e-01, time/batch = 15.6174s	
19264/33250 (epoch 28.968), train_loss = 1.00046310, grad/param norm = 1.6451e-01, time/batch = 15.7737s	
19265/33250 (epoch 28.970), train_loss = 1.10725846, grad/param norm = 2.2973e-01, time/batch = 15.7141s	
19266/33250 (epoch 28.971), train_loss = 1.01639062, grad/param norm = 2.0904e-01, time/batch = 15.6807s	
19267/33250 (epoch 28.973), train_loss = 0.83364204, grad/param norm = 1.6793e-01, time/batch = 15.6818s	
19268/33250 (epoch 28.974), train_loss = 0.94423198, grad/param norm = 1.8374e-01, time/batch = 15.6443s	
19269/33250 (epoch 28.976), train_loss = 0.80848441, grad/param norm = 1.9486e-01, time/batch = 15.2280s	
19270/33250 (epoch 28.977), train_loss = 0.84002210, grad/param norm = 1.7330e-01, time/batch = 15.1482s	
19271/33250 (epoch 28.979), train_loss = 0.89097139, grad/param norm = 1.6768e-01, time/batch = 15.7122s	
19272/33250 (epoch 28.980), train_loss = 0.87179673, grad/param norm = 1.5938e-01, time/batch = 15.7566s	
19273/33250 (epoch 28.982), train_loss = 0.79336178, grad/param norm = 1.4714e-01, time/batch = 15.5139s	
19274/33250 (epoch 28.983), train_loss = 0.88860115, grad/param norm = 1.9707e-01, time/batch = 15.5137s	
19275/33250 (epoch 28.985), train_loss = 0.82120086, grad/param norm = 1.7751e-01, time/batch = 15.5999s	
19276/33250 (epoch 28.986), train_loss = 0.92616538, grad/param norm = 1.6657e-01, time/batch = 15.7001s	
19277/33250 (epoch 28.988), train_loss = 0.94854418, grad/param norm = 1.7496e-01, time/batch = 15.5407s	
19278/33250 (epoch 28.989), train_loss = 0.94327873, grad/param norm = 1.6916e-01, time/batch = 15.9314s	
19279/33250 (epoch 28.991), train_loss = 0.89172259, grad/param norm = 1.5340e-01, time/batch = 15.5147s	
19280/33250 (epoch 28.992), train_loss = 0.83403028, grad/param norm = 1.4855e-01, time/batch = 15.6002s	
19281/33250 (epoch 28.994), train_loss = 0.82745898, grad/param norm = 1.6107e-01, time/batch = 15.6985s	
19282/33250 (epoch 28.995), train_loss = 0.83484715, grad/param norm = 3.9013e-01, time/batch = 15.6596s	
19283/33250 (epoch 28.997), train_loss = 0.62716781, grad/param norm = 1.3811e-01, time/batch = 15.6839s	
19284/33250 (epoch 28.998), train_loss = 0.89961405, grad/param norm = 1.6373e-01, time/batch = 15.7544s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
19285/33250 (epoch 29.000), train_loss = 0.86996084, grad/param norm = 1.5965e-01, time/batch = 15.5274s	
19286/33250 (epoch 29.002), train_loss = 1.05900442, grad/param norm = 1.7129e-01, time/batch = 15.6852s	
19287/33250 (epoch 29.003), train_loss = 0.95125651, grad/param norm = 1.7915e-01, time/batch = 15.3383s	
19288/33250 (epoch 29.005), train_loss = 0.72233407, grad/param norm = 1.4568e-01, time/batch = 15.0719s	
19289/33250 (epoch 29.006), train_loss = 0.74671146, grad/param norm = 1.5553e-01, time/batch = 15.2376s	
19290/33250 (epoch 29.008), train_loss = 0.97325338, grad/param norm = 1.6990e-01, time/batch = 15.3249s	
19291/33250 (epoch 29.009), train_loss = 1.01225609, grad/param norm = 1.7947e-01, time/batch = 15.9896s	
19292/33250 (epoch 29.011), train_loss = 0.79172385, grad/param norm = 1.6231e-01, time/batch = 15.7502s	
19293/33250 (epoch 29.012), train_loss = 0.84999354, grad/param norm = 1.7849e-01, time/batch = 15.6948s	
19294/33250 (epoch 29.014), train_loss = 0.96433188, grad/param norm = 4.7379e-01, time/batch = 15.6101s	
19295/33250 (epoch 29.015), train_loss = 0.87833829, grad/param norm = 1.6838e-01, time/batch = 15.6887s	
19296/33250 (epoch 29.017), train_loss = 0.90544007, grad/param norm = 2.1534e-01, time/batch = 15.6187s	
19297/33250 (epoch 29.018), train_loss = 0.71526153, grad/param norm = 1.7894e-01, time/batch = 15.8254s	
19298/33250 (epoch 29.020), train_loss = 0.85575039, grad/param norm = 1.4513e-01, time/batch = 15.8429s	
19299/33250 (epoch 29.021), train_loss = 0.90163166, grad/param norm = 1.6605e-01, time/batch = 15.6989s	
19300/33250 (epoch 29.023), train_loss = 0.76268583, grad/param norm = 2.4673e-01, time/batch = 15.5323s	
19301/33250 (epoch 29.024), train_loss = 1.00069547, grad/param norm = 1.8886e-01, time/batch = 15.6035s	
19302/33250 (epoch 29.026), train_loss = 0.90087078, grad/param norm = 1.7322e-01, time/batch = 15.7646s	
19303/33250 (epoch 29.027), train_loss = 0.89412110, grad/param norm = 1.7158e-01, time/batch = 15.6091s	
19304/33250 (epoch 29.029), train_loss = 0.84262346, grad/param norm = 1.5116e-01, time/batch = 15.6035s	
19305/33250 (epoch 29.030), train_loss = 0.86889315, grad/param norm = 1.8930e-01, time/batch = 15.5234s	
19306/33250 (epoch 29.032), train_loss = 1.07059018, grad/param norm = 2.0196e-01, time/batch = 15.7613s	
19307/33250 (epoch 29.033), train_loss = 0.83640140, grad/param norm = 2.1351e-01, time/batch = 15.6936s	
19308/33250 (epoch 29.035), train_loss = 0.86251607, grad/param norm = 1.7683e-01, time/batch = 15.5473s	
19309/33250 (epoch 29.036), train_loss = 0.93056831, grad/param norm = 1.8216e-01, time/batch = 15.5334s	
19310/33250 (epoch 29.038), train_loss = 0.85436565, grad/param norm = 1.4491e-01, time/batch = 15.9806s	
19311/33250 (epoch 29.039), train_loss = 0.78484026, grad/param norm = 1.4763e-01, time/batch = 15.9170s	
19312/33250 (epoch 29.041), train_loss = 0.87704374, grad/param norm = 1.8951e-01, time/batch = 15.6903s	
19313/33250 (epoch 29.042), train_loss = 0.72652391, grad/param norm = 1.4577e-01, time/batch = 15.6131s	
19314/33250 (epoch 29.044), train_loss = 0.96905874, grad/param norm = 1.7016e-01, time/batch = 15.8576s	
19315/33250 (epoch 29.045), train_loss = 0.95593886, grad/param norm = 1.6925e-01, time/batch = 15.6990s	
19316/33250 (epoch 29.047), train_loss = 0.88057862, grad/param norm = 1.7864e-01, time/batch = 15.8553s	
19317/33250 (epoch 29.048), train_loss = 0.97346830, grad/param norm = 2.1893e-01, time/batch = 15.6930s	
19318/33250 (epoch 29.050), train_loss = 0.85599424, grad/param norm = 1.4935e-01, time/batch = 15.6917s	
19319/33250 (epoch 29.051), train_loss = 0.84946319, grad/param norm = 1.5329e-01, time/batch = 15.3649s	
19320/33250 (epoch 29.053), train_loss = 0.89788482, grad/param norm = 1.9375e-01, time/batch = 15.7935s	
19321/33250 (epoch 29.054), train_loss = 0.74882529, grad/param norm = 1.5069e-01, time/batch = 15.7895s	
19322/33250 (epoch 29.056), train_loss = 0.78926581, grad/param norm = 1.5784e-01, time/batch = 15.8735s	
19323/33250 (epoch 29.057), train_loss = 0.97675294, grad/param norm = 1.7474e-01, time/batch = 15.6774s	
19324/33250 (epoch 29.059), train_loss = 0.82803484, grad/param norm = 1.5495e-01, time/batch = 15.7713s	
19325/33250 (epoch 29.060), train_loss = 0.86723614, grad/param norm = 1.8662e-01, time/batch = 15.7746s	
19326/33250 (epoch 29.062), train_loss = 0.97477898, grad/param norm = 1.8300e-01, time/batch = 15.5336s	
19327/33250 (epoch 29.063), train_loss = 0.99868725, grad/param norm = 1.6137e-01, time/batch = 15.7008s	
19328/33250 (epoch 29.065), train_loss = 0.86599346, grad/param norm = 1.6044e-01, time/batch = 15.6946s	
19329/33250 (epoch 29.066), train_loss = 0.89568736, grad/param norm = 1.7081e-01, time/batch = 29.4745s	
19330/33250 (epoch 29.068), train_loss = 0.82183543, grad/param norm = 1.6323e-01, time/batch = 16.2689s	
19331/33250 (epoch 29.069), train_loss = 0.87790640, grad/param norm = 1.7531e-01, time/batch = 15.8579s	
19332/33250 (epoch 29.071), train_loss = 0.79753987, grad/param norm = 1.3766e-01, time/batch = 15.8531s	
19333/33250 (epoch 29.072), train_loss = 0.81575037, grad/param norm = 1.6292e-01, time/batch = 15.7617s	
19334/33250 (epoch 29.074), train_loss = 0.90359511, grad/param norm = 1.7635e-01, time/batch = 15.7583s	
19335/33250 (epoch 29.075), train_loss = 0.82861011, grad/param norm = 1.6945e-01, time/batch = 15.7015s	
19336/33250 (epoch 29.077), train_loss = 0.85210158, grad/param norm = 1.7654e-01, time/batch = 15.6985s	
19337/33250 (epoch 29.078), train_loss = 0.87491200, grad/param norm = 1.6209e-01, time/batch = 15.6088s	
19338/33250 (epoch 29.080), train_loss = 0.87658936, grad/param norm = 1.6934e-01, time/batch = 15.6217s	
19339/33250 (epoch 29.081), train_loss = 0.90966852, grad/param norm = 1.5747e-01, time/batch = 15.6019s	
19340/33250 (epoch 29.083), train_loss = 0.97653374, grad/param norm = 1.5338e-01, time/batch = 15.6908s	
19341/33250 (epoch 29.084), train_loss = 0.85832597, grad/param norm = 1.5838e-01, time/batch = 15.7812s	
19342/33250 (epoch 29.086), train_loss = 0.85034875, grad/param norm = 1.4762e-01, time/batch = 15.7854s	
19343/33250 (epoch 29.087), train_loss = 0.75299913, grad/param norm = 1.4613e-01, time/batch = 15.7644s	
19344/33250 (epoch 29.089), train_loss = 0.86636017, grad/param norm = 1.4347e-01, time/batch = 15.6138s	
19345/33250 (epoch 29.090), train_loss = 0.89148228, grad/param norm = 1.5876e-01, time/batch = 15.7756s	
19346/33250 (epoch 29.092), train_loss = 0.81494206, grad/param norm = 1.4450e-01, time/batch = 15.6199s	
19347/33250 (epoch 29.093), train_loss = 0.85200355, grad/param norm = 1.4710e-01, time/batch = 15.9739s	
19348/33250 (epoch 29.095), train_loss = 0.84579624, grad/param norm = 1.5867e-01, time/batch = 15.6927s	
19349/33250 (epoch 29.096), train_loss = 0.72515687, grad/param norm = 1.6761e-01, time/batch = 15.7760s	
19350/33250 (epoch 29.098), train_loss = 0.73557148, grad/param norm = 1.6920e-01, time/batch = 15.4526s	
19351/33250 (epoch 29.099), train_loss = 0.68477746, grad/param norm = 1.4730e-01, time/batch = 15.8526s	
19352/33250 (epoch 29.101), train_loss = 0.83823734, grad/param norm = 1.5330e-01, time/batch = 15.5950s	
19353/33250 (epoch 29.102), train_loss = 0.78434417, grad/param norm = 1.5378e-01, time/batch = 16.0028s	
19354/33250 (epoch 29.104), train_loss = 0.65331390, grad/param norm = 1.3464e-01, time/batch = 15.7782s	
19355/33250 (epoch 29.105), train_loss = 0.80059109, grad/param norm = 1.7516e-01, time/batch = 15.5384s	
19356/33250 (epoch 29.107), train_loss = 0.73357127, grad/param norm = 1.3986e-01, time/batch = 15.6190s	
19357/33250 (epoch 29.108), train_loss = 0.86055462, grad/param norm = 1.6648e-01, time/batch = 15.6067s	
19358/33250 (epoch 29.110), train_loss = 0.71038035, grad/param norm = 1.4488e-01, time/batch = 15.6171s	
19359/33250 (epoch 29.111), train_loss = 0.83395151, grad/param norm = 1.4968e-01, time/batch = 15.7694s	
19360/33250 (epoch 29.113), train_loss = 0.78537231, grad/param norm = 1.5025e-01, time/batch = 15.7619s	
19361/33250 (epoch 29.114), train_loss = 0.74831576, grad/param norm = 1.6896e-01, time/batch = 15.7696s	
19362/33250 (epoch 29.116), train_loss = 0.81671291, grad/param norm = 1.6954e-01, time/batch = 15.9099s	
19363/33250 (epoch 29.117), train_loss = 0.81878465, grad/param norm = 1.5715e-01, time/batch = 15.9391s	
19364/33250 (epoch 29.119), train_loss = 0.81774054, grad/param norm = 1.5730e-01, time/batch = 15.6857s	
19365/33250 (epoch 29.120), train_loss = 0.64916888, grad/param norm = 1.2840e-01, time/batch = 15.5412s	
19366/33250 (epoch 29.122), train_loss = 0.93569974, grad/param norm = 1.6915e-01, time/batch = 15.6920s	
19367/33250 (epoch 29.123), train_loss = 0.84820411, grad/param norm = 1.8740e-01, time/batch = 15.7080s	
19368/33250 (epoch 29.125), train_loss = 0.70045831, grad/param norm = 1.6878e-01, time/batch = 15.3779s	
19369/33250 (epoch 29.126), train_loss = 0.83417780, grad/param norm = 1.7065e-01, time/batch = 15.5403s	
19370/33250 (epoch 29.128), train_loss = 0.79771521, grad/param norm = 1.4488e-01, time/batch = 15.6660s	
19371/33250 (epoch 29.129), train_loss = 0.84580812, grad/param norm = 1.5228e-01, time/batch = 15.6896s	
19372/33250 (epoch 29.131), train_loss = 0.83062670, grad/param norm = 1.7540e-01, time/batch = 15.8557s	
19373/33250 (epoch 29.132), train_loss = 0.80115034, grad/param norm = 1.7906e-01, time/batch = 15.6067s	
19374/33250 (epoch 29.134), train_loss = 0.81627226, grad/param norm = 1.7416e-01, time/batch = 15.9419s	
19375/33250 (epoch 29.135), train_loss = 0.83802405, grad/param norm = 1.5908e-01, time/batch = 15.5212s	
19376/33250 (epoch 29.137), train_loss = 0.74981733, grad/param norm = 1.5828e-01, time/batch = 15.6136s	
19377/33250 (epoch 29.138), train_loss = 0.75543871, grad/param norm = 1.3618e-01, time/batch = 15.5110s	
19378/33250 (epoch 29.140), train_loss = 0.66523661, grad/param norm = 1.6953e-01, time/batch = 15.5055s	
19379/33250 (epoch 29.141), train_loss = 0.94282703, grad/param norm = 2.5991e-01, time/batch = 15.5848s	
19380/33250 (epoch 29.143), train_loss = 0.68567611, grad/param norm = 1.6846e-01, time/batch = 15.5326s	
19381/33250 (epoch 29.144), train_loss = 0.80720837, grad/param norm = 1.5855e-01, time/batch = 15.8443s	
19382/33250 (epoch 29.146), train_loss = 0.80284795, grad/param norm = 1.5439e-01, time/batch = 15.6942s	
19383/33250 (epoch 29.147), train_loss = 0.83026679, grad/param norm = 1.8088e-01, time/batch = 15.6251s	
19384/33250 (epoch 29.149), train_loss = 0.76823215, grad/param norm = 1.4635e-01, time/batch = 15.6287s	
19385/33250 (epoch 29.150), train_loss = 0.73615372, grad/param norm = 1.4732e-01, time/batch = 15.9914s	
19386/33250 (epoch 29.152), train_loss = 0.71141612, grad/param norm = 1.5489e-01, time/batch = 15.6942s	
19387/33250 (epoch 29.153), train_loss = 0.98191587, grad/param norm = 1.8233e-01, time/batch = 15.6857s	
19388/33250 (epoch 29.155), train_loss = 0.81299395, grad/param norm = 2.0437e-01, time/batch = 15.6160s	
19389/33250 (epoch 29.156), train_loss = 1.02705275, grad/param norm = 1.6665e-01, time/batch = 15.7793s	
19390/33250 (epoch 29.158), train_loss = 0.98971531, grad/param norm = 1.8973e-01, time/batch = 15.3601s	
19391/33250 (epoch 29.159), train_loss = 0.79855701, grad/param norm = 1.5839e-01, time/batch = 15.8298s	
19392/33250 (epoch 29.161), train_loss = 0.87642341, grad/param norm = 1.7160e-01, time/batch = 15.6159s	
19393/33250 (epoch 29.162), train_loss = 0.73846134, grad/param norm = 1.5135e-01, time/batch = 15.6859s	
19394/33250 (epoch 29.164), train_loss = 0.80469798, grad/param norm = 1.8555e-01, time/batch = 15.6804s	
19395/33250 (epoch 29.165), train_loss = 0.88991471, grad/param norm = 1.8332e-01, time/batch = 15.5326s	
19396/33250 (epoch 29.167), train_loss = 0.99390801, grad/param norm = 1.8481e-01, time/batch = 15.6743s	
19397/33250 (epoch 29.168), train_loss = 0.71223125, grad/param norm = 1.3368e-01, time/batch = 15.4616s	
19398/33250 (epoch 29.170), train_loss = 0.79122460, grad/param norm = 1.6657e-01, time/batch = 15.2956s	
19399/33250 (epoch 29.171), train_loss = 0.85128601, grad/param norm = 1.7262e-01, time/batch = 15.6839s	
19400/33250 (epoch 29.173), train_loss = 0.79744792, grad/param norm = 1.5237e-01, time/batch = 15.6060s	
19401/33250 (epoch 29.174), train_loss = 0.84237551, grad/param norm = 1.5678e-01, time/batch = 15.8588s	
19402/33250 (epoch 29.176), train_loss = 0.78977412, grad/param norm = 1.4667e-01, time/batch = 15.6997s	
19403/33250 (epoch 29.177), train_loss = 0.78844564, grad/param norm = 1.4717e-01, time/batch = 15.6911s	
19404/33250 (epoch 29.179), train_loss = 0.78087464, grad/param norm = 1.6620e-01, time/batch = 15.8287s	
19405/33250 (epoch 29.180), train_loss = 0.67786759, grad/param norm = 1.3790e-01, time/batch = 15.6177s	
19406/33250 (epoch 29.182), train_loss = 0.76745591, grad/param norm = 1.8741e-01, time/batch = 15.6921s	
19407/33250 (epoch 29.183), train_loss = 0.93637327, grad/param norm = 1.8556e-01, time/batch = 15.5361s	
19408/33250 (epoch 29.185), train_loss = 0.89078826, grad/param norm = 2.0955e-01, time/batch = 15.7622s	
19409/33250 (epoch 29.186), train_loss = 0.86883334, grad/param norm = 1.7160e-01, time/batch = 15.6934s	
19410/33250 (epoch 29.188), train_loss = 0.94247597, grad/param norm = 1.9202e-01, time/batch = 15.7680s	
19411/33250 (epoch 29.189), train_loss = 0.68358349, grad/param norm = 1.9057e-01, time/batch = 15.6761s	
19412/33250 (epoch 29.191), train_loss = 0.77337880, grad/param norm = 1.7019e-01, time/batch = 15.7034s	
19413/33250 (epoch 29.192), train_loss = 0.81070563, grad/param norm = 1.5293e-01, time/batch = 15.4438s	
19414/33250 (epoch 29.194), train_loss = 0.82149131, grad/param norm = 1.7443e-01, time/batch = 15.7727s	
19415/33250 (epoch 29.195), train_loss = 1.01933034, grad/param norm = 1.7553e-01, time/batch = 15.6147s	
19416/33250 (epoch 29.197), train_loss = 0.77316721, grad/param norm = 1.5605e-01, time/batch = 15.7717s	
19417/33250 (epoch 29.198), train_loss = 0.97182948, grad/param norm = 1.6899e-01, time/batch = 15.7010s	
19418/33250 (epoch 29.200), train_loss = 0.84415092, grad/param norm = 1.7085e-01, time/batch = 15.7080s	
19419/33250 (epoch 29.202), train_loss = 0.78922418, grad/param norm = 1.4240e-01, time/batch = 15.6855s	
19420/33250 (epoch 29.203), train_loss = 0.76560486, grad/param norm = 1.6607e-01, time/batch = 15.6874s	
19421/33250 (epoch 29.205), train_loss = 0.87965421, grad/param norm = 1.6028e-01, time/batch = 15.6127s	
19422/33250 (epoch 29.206), train_loss = 0.91124768, grad/param norm = 1.6968e-01, time/batch = 15.6836s	
19423/33250 (epoch 29.208), train_loss = 0.93939154, grad/param norm = 1.8374e-01, time/batch = 15.5802s	
19424/33250 (epoch 29.209), train_loss = 0.77021960, grad/param norm = 1.5773e-01, time/batch = 15.8290s	
19425/33250 (epoch 29.211), train_loss = 0.87907717, grad/param norm = 1.7102e-01, time/batch = 15.5262s	
19426/33250 (epoch 29.212), train_loss = 0.99796597, grad/param norm = 1.6412e-01, time/batch = 15.5532s	
19427/33250 (epoch 29.214), train_loss = 0.84592840, grad/param norm = 1.5908e-01, time/batch = 15.7733s	
19428/33250 (epoch 29.215), train_loss = 0.95108676, grad/param norm = 2.0016e-01, time/batch = 15.6258s	
19429/33250 (epoch 29.217), train_loss = 0.94752368, grad/param norm = 1.8307e-01, time/batch = 15.8532s	
19430/33250 (epoch 29.218), train_loss = 0.94398971, grad/param norm = 1.6977e-01, time/batch = 15.6084s	
19431/33250 (epoch 29.220), train_loss = 0.86369210, grad/param norm = 1.8354e-01, time/batch = 15.8322s	
19432/33250 (epoch 29.221), train_loss = 1.00495188, grad/param norm = 1.8194e-01, time/batch = 15.5283s	
19433/33250 (epoch 29.223), train_loss = 0.86082308, grad/param norm = 2.0436e-01, time/batch = 15.4361s	
19434/33250 (epoch 29.224), train_loss = 0.91759235, grad/param norm = 1.8228e-01, time/batch = 15.5181s	
19435/33250 (epoch 29.226), train_loss = 0.98772246, grad/param norm = 1.8825e-01, time/batch = 15.6079s	
19436/33250 (epoch 29.227), train_loss = 0.88812763, grad/param norm = 1.6613e-01, time/batch = 15.6868s	
19437/33250 (epoch 29.229), train_loss = 0.86858034, grad/param norm = 1.6051e-01, time/batch = 15.7077s	
19438/33250 (epoch 29.230), train_loss = 0.87442966, grad/param norm = 1.8284e-01, time/batch = 15.6961s	
19439/33250 (epoch 29.232), train_loss = 0.79678780, grad/param norm = 1.4795e-01, time/batch = 15.6908s	
19440/33250 (epoch 29.233), train_loss = 0.78583315, grad/param norm = 1.5317e-01, time/batch = 15.7827s	
19441/33250 (epoch 29.235), train_loss = 0.98159452, grad/param norm = 1.7239e-01, time/batch = 15.6972s	
19442/33250 (epoch 29.236), train_loss = 0.78641940, grad/param norm = 1.6713e-01, time/batch = 15.9815s	
19443/33250 (epoch 29.238), train_loss = 0.95453083, grad/param norm = 1.7590e-01, time/batch = 15.9021s	
19444/33250 (epoch 29.239), train_loss = 0.97696629, grad/param norm = 2.6325e-01, time/batch = 15.5240s	
19445/33250 (epoch 29.241), train_loss = 0.97609942, grad/param norm = 2.1148e-01, time/batch = 15.1965s	
19446/33250 (epoch 29.242), train_loss = 0.96667014, grad/param norm = 1.7469e-01, time/batch = 15.5186s	
19447/33250 (epoch 29.244), train_loss = 0.93723963, grad/param norm = 2.1652e-01, time/batch = 15.2840s	
19448/33250 (epoch 29.245), train_loss = 0.90535288, grad/param norm = 1.9336e-01, time/batch = 15.8433s	
19449/33250 (epoch 29.247), train_loss = 0.84956676, grad/param norm = 1.4939e-01, time/batch = 15.5124s	
19450/33250 (epoch 29.248), train_loss = 1.03852671, grad/param norm = 1.9064e-01, time/batch = 15.5913s	
19451/33250 (epoch 29.250), train_loss = 0.94369185, grad/param norm = 1.5373e-01, time/batch = 15.5270s	
19452/33250 (epoch 29.251), train_loss = 0.83671900, grad/param norm = 1.5168e-01, time/batch = 15.6834s	
19453/33250 (epoch 29.253), train_loss = 0.80874514, grad/param norm = 1.3863e-01, time/batch = 15.5178s	
19454/33250 (epoch 29.254), train_loss = 0.80887879, grad/param norm = 1.8722e-01, time/batch = 15.5260s	
19455/33250 (epoch 29.256), train_loss = 0.86106478, grad/param norm = 1.6196e-01, time/batch = 15.5183s	
19456/33250 (epoch 29.257), train_loss = 0.99572673, grad/param norm = 1.7744e-01, time/batch = 15.3583s	
19457/33250 (epoch 29.259), train_loss = 0.90649863, grad/param norm = 1.6915e-01, time/batch = 15.5193s	
19458/33250 (epoch 29.260), train_loss = 0.72557815, grad/param norm = 1.5028e-01, time/batch = 15.5380s	
19459/33250 (epoch 29.262), train_loss = 0.88931179, grad/param norm = 1.5938e-01, time/batch = 15.2126s	
19460/33250 (epoch 29.263), train_loss = 0.74474743, grad/param norm = 1.7695e-01, time/batch = 15.6095s	
19461/33250 (epoch 29.265), train_loss = 0.92300546, grad/param norm = 1.7786e-01, time/batch = 15.9981s	
19462/33250 (epoch 29.266), train_loss = 0.83865679, grad/param norm = 1.7713e-01, time/batch = 15.5256s	
19463/33250 (epoch 29.268), train_loss = 0.78077351, grad/param norm = 1.7744e-01, time/batch = 15.6803s	
19464/33250 (epoch 29.269), train_loss = 0.71404692, grad/param norm = 1.5356e-01, time/batch = 15.4438s	
19465/33250 (epoch 29.271), train_loss = 0.85679378, grad/param norm = 1.4427e-01, time/batch = 15.5864s	
19466/33250 (epoch 29.272), train_loss = 0.78075807, grad/param norm = 1.4482e-01, time/batch = 15.3623s	
19467/33250 (epoch 29.274), train_loss = 0.64565149, grad/param norm = 1.3633e-01, time/batch = 15.6016s	
19468/33250 (epoch 29.275), train_loss = 0.78414982, grad/param norm = 1.2847e-01, time/batch = 15.4415s	
19469/33250 (epoch 29.277), train_loss = 0.67592004, grad/param norm = 1.4899e-01, time/batch = 15.6870s	
19470/33250 (epoch 29.278), train_loss = 0.78354609, grad/param norm = 1.5435e-01, time/batch = 15.3733s	
19471/33250 (epoch 29.280), train_loss = 0.74990219, grad/param norm = 1.4838e-01, time/batch = 15.5228s	
19472/33250 (epoch 29.281), train_loss = 0.87551037, grad/param norm = 1.7745e-01, time/batch = 15.5298s	
19473/33250 (epoch 29.283), train_loss = 0.88475330, grad/param norm = 2.0805e-01, time/batch = 15.6031s	
19474/33250 (epoch 29.284), train_loss = 0.77079203, grad/param norm = 2.2076e-01, time/batch = 15.4321s	
19475/33250 (epoch 29.286), train_loss = 0.88555305, grad/param norm = 1.7153e-01, time/batch = 15.3532s	
19476/33250 (epoch 29.287), train_loss = 0.72337705, grad/param norm = 1.3891e-01, time/batch = 15.5192s	
19477/33250 (epoch 29.289), train_loss = 0.67216190, grad/param norm = 1.7063e-01, time/batch = 15.6906s	
19478/33250 (epoch 29.290), train_loss = 0.84511322, grad/param norm = 1.6641e-01, time/batch = 15.5123s	
19479/33250 (epoch 29.292), train_loss = 0.91339268, grad/param norm = 2.0413e-01, time/batch = 15.6107s	
19480/33250 (epoch 29.293), train_loss = 0.95693513, grad/param norm = 1.7227e-01, time/batch = 15.6164s	
19481/33250 (epoch 29.295), train_loss = 0.92150581, grad/param norm = 1.5991e-01, time/batch = 15.8607s	
19482/33250 (epoch 29.296), train_loss = 0.86780260, grad/param norm = 1.7215e-01, time/batch = 15.4714s	
19483/33250 (epoch 29.298), train_loss = 0.71037372, grad/param norm = 1.4866e-01, time/batch = 15.2949s	
19484/33250 (epoch 29.299), train_loss = 0.68106944, grad/param norm = 1.2756e-01, time/batch = 15.6771s	
19485/33250 (epoch 29.301), train_loss = 0.92613803, grad/param norm = 1.7298e-01, time/batch = 15.9155s	
19486/33250 (epoch 29.302), train_loss = 0.88512039, grad/param norm = 1.6770e-01, time/batch = 15.7447s	
19487/33250 (epoch 29.304), train_loss = 0.77272749, grad/param norm = 1.4926e-01, time/batch = 15.8489s	
19488/33250 (epoch 29.305), train_loss = 0.79445805, grad/param norm = 1.6857e-01, time/batch = 15.7751s	
19489/33250 (epoch 29.307), train_loss = 0.89527894, grad/param norm = 1.6347e-01, time/batch = 15.7579s	
19490/33250 (epoch 29.308), train_loss = 0.94635072, grad/param norm = 1.8668e-01, time/batch = 15.8455s	
19491/33250 (epoch 29.310), train_loss = 0.80503862, grad/param norm = 1.6313e-01, time/batch = 15.7130s	
19492/33250 (epoch 29.311), train_loss = 0.98674993, grad/param norm = 2.0531e-01, time/batch = 15.9297s	
19493/33250 (epoch 29.313), train_loss = 0.72289454, grad/param norm = 1.7021e-01, time/batch = 15.6350s	
19494/33250 (epoch 29.314), train_loss = 0.85912250, grad/param norm = 1.7391e-01, time/batch = 15.6378s	
19495/33250 (epoch 29.316), train_loss = 1.01717127, grad/param norm = 1.8609e-01, time/batch = 15.6887s	
19496/33250 (epoch 29.317), train_loss = 0.76255919, grad/param norm = 1.4483e-01, time/batch = 15.9318s	
19497/33250 (epoch 29.319), train_loss = 0.90685786, grad/param norm = 1.9254e-01, time/batch = 15.6095s	
19498/33250 (epoch 29.320), train_loss = 0.92593264, grad/param norm = 1.9776e-01, time/batch = 15.7632s	
19499/33250 (epoch 29.322), train_loss = 0.98044352, grad/param norm = 1.9388e-01, time/batch = 15.7571s	
19500/33250 (epoch 29.323), train_loss = 1.02179610, grad/param norm = 2.4881e-01, time/batch = 15.4497s	
19501/33250 (epoch 29.325), train_loss = 0.83424200, grad/param norm = 1.7723e-01, time/batch = 15.6111s	
19502/33250 (epoch 29.326), train_loss = 1.02016142, grad/param norm = 1.7883e-01, time/batch = 15.6992s	
19503/33250 (epoch 29.328), train_loss = 0.82871951, grad/param norm = 1.5931e-01, time/batch = 15.5155s	
19504/33250 (epoch 29.329), train_loss = 0.84943575, grad/param norm = 1.8093e-01, time/batch = 15.5482s	
19505/33250 (epoch 29.331), train_loss = 0.84758480, grad/param norm = 1.8659e-01, time/batch = 15.6897s	
19506/33250 (epoch 29.332), train_loss = 0.84280199, grad/param norm = 1.5727e-01, time/batch = 15.7607s	
19507/33250 (epoch 29.334), train_loss = 0.99538123, grad/param norm = 1.8670e-01, time/batch = 15.4400s	
19508/33250 (epoch 29.335), train_loss = 0.63038373, grad/param norm = 1.3590e-01, time/batch = 15.5224s	
19509/33250 (epoch 29.337), train_loss = 0.90742408, grad/param norm = 1.6496e-01, time/batch = 15.3733s	
19510/33250 (epoch 29.338), train_loss = 0.96878833, grad/param norm = 1.7465e-01, time/batch = 15.6826s	
19511/33250 (epoch 29.340), train_loss = 0.85465257, grad/param norm = 1.6370e-01, time/batch = 15.6807s	
19512/33250 (epoch 29.341), train_loss = 0.81513548, grad/param norm = 1.6228e-01, time/batch = 15.2937s	
19513/33250 (epoch 29.343), train_loss = 0.81159409, grad/param norm = 1.6577e-01, time/batch = 15.5352s	
19514/33250 (epoch 29.344), train_loss = 0.84128897, grad/param norm = 1.5123e-01, time/batch = 15.4610s	
19515/33250 (epoch 29.346), train_loss = 0.75440831, grad/param norm = 1.7068e-01, time/batch = 15.9307s	
19516/33250 (epoch 29.347), train_loss = 1.05478288, grad/param norm = 2.1059e-01, time/batch = 15.4612s	
19517/33250 (epoch 29.349), train_loss = 0.81307706, grad/param norm = 1.9321e-01, time/batch = 15.7609s	
19518/33250 (epoch 29.350), train_loss = 0.83626362, grad/param norm = 1.6026e-01, time/batch = 15.5947s	
19519/33250 (epoch 29.352), train_loss = 0.76823383, grad/param norm = 1.6749e-01, time/batch = 15.9037s	
19520/33250 (epoch 29.353), train_loss = 0.81490940, grad/param norm = 1.4670e-01, time/batch = 15.2872s	
19521/33250 (epoch 29.355), train_loss = 0.80523908, grad/param norm = 1.8595e-01, time/batch = 15.6848s	
19522/33250 (epoch 29.356), train_loss = 0.77979608, grad/param norm = 1.8671e-01, time/batch = 15.6049s	
19523/33250 (epoch 29.358), train_loss = 0.79459694, grad/param norm = 1.4293e-01, time/batch = 15.3791s	
19524/33250 (epoch 29.359), train_loss = 0.79647603, grad/param norm = 1.5297e-01, time/batch = 15.7614s	
19525/33250 (epoch 29.361), train_loss = 0.98574637, grad/param norm = 2.0853e-01, time/batch = 15.6148s	
19526/33250 (epoch 29.362), train_loss = 0.87838253, grad/param norm = 1.6491e-01, time/batch = 15.6930s	
19527/33250 (epoch 29.364), train_loss = 0.92479981, grad/param norm = 1.8918e-01, time/batch = 15.1182s	
19528/33250 (epoch 29.365), train_loss = 0.84536616, grad/param norm = 1.6260e-01, time/batch = 15.6691s	
19529/33250 (epoch 29.367), train_loss = 0.85158930, grad/param norm = 1.4671e-01, time/batch = 15.6869s	
19530/33250 (epoch 29.368), train_loss = 0.85527688, grad/param norm = 1.7571e-01, time/batch = 15.6687s	
19531/33250 (epoch 29.370), train_loss = 0.76095146, grad/param norm = 1.4907e-01, time/batch = 15.6114s	
19532/33250 (epoch 29.371), train_loss = 0.96795939, grad/param norm = 1.8694e-01, time/batch = 15.3639s	
19533/33250 (epoch 29.373), train_loss = 0.80642892, grad/param norm = 1.4768e-01, time/batch = 15.3721s	
19534/33250 (epoch 29.374), train_loss = 0.88136645, grad/param norm = 2.1729e-01, time/batch = 15.7860s	
19535/33250 (epoch 29.376), train_loss = 0.82981993, grad/param norm = 1.5718e-01, time/batch = 15.5445s	
19536/33250 (epoch 29.377), train_loss = 0.75359400, grad/param norm = 2.0434e-01, time/batch = 15.9284s	
19537/33250 (epoch 29.379), train_loss = 0.82750780, grad/param norm = 1.6707e-01, time/batch = 15.5337s	
19538/33250 (epoch 29.380), train_loss = 0.86376660, grad/param norm = 2.1281e-01, time/batch = 15.8342s	
19539/33250 (epoch 29.382), train_loss = 0.88418569, grad/param norm = 1.8985e-01, time/batch = 15.7688s	
19540/33250 (epoch 29.383), train_loss = 0.75891773, grad/param norm = 1.6654e-01, time/batch = 15.8532s	
19541/33250 (epoch 29.385), train_loss = 0.71642502, grad/param norm = 1.5399e-01, time/batch = 15.8561s	
19542/33250 (epoch 29.386), train_loss = 0.73895176, grad/param norm = 1.5018e-01, time/batch = 15.8437s	
19543/33250 (epoch 29.388), train_loss = 0.75498200, grad/param norm = 1.4746e-01, time/batch = 15.6889s	
19544/33250 (epoch 29.389), train_loss = 0.82332669, grad/param norm = 1.8348e-01, time/batch = 15.9942s	
19545/33250 (epoch 29.391), train_loss = 0.90482545, grad/param norm = 1.6983e-01, time/batch = 15.6983s	
19546/33250 (epoch 29.392), train_loss = 0.90804657, grad/param norm = 1.7574e-01, time/batch = 15.9480s	
19547/33250 (epoch 29.394), train_loss = 0.94411703, grad/param norm = 1.8181e-01, time/batch = 15.7967s	
19548/33250 (epoch 29.395), train_loss = 0.91579598, grad/param norm = 1.6162e-01, time/batch = 15.8635s	
19549/33250 (epoch 29.397), train_loss = 0.96022316, grad/param norm = 1.8932e-01, time/batch = 16.0058s	
19550/33250 (epoch 29.398), train_loss = 0.78071576, grad/param norm = 1.4215e-01, time/batch = 15.9228s	
19551/33250 (epoch 29.400), train_loss = 0.75941904, grad/param norm = 1.4987e-01, time/batch = 15.9332s	
19552/33250 (epoch 29.402), train_loss = 0.72324957, grad/param norm = 1.6500e-01, time/batch = 16.0194s	
19553/33250 (epoch 29.403), train_loss = 0.81942561, grad/param norm = 1.6279e-01, time/batch = 16.2516s	
19554/33250 (epoch 29.405), train_loss = 0.76822057, grad/param norm = 1.3233e-01, time/batch = 16.1824s	
19555/33250 (epoch 29.406), train_loss = 0.82738727, grad/param norm = 1.5825e-01, time/batch = 16.0519s	
19556/33250 (epoch 29.408), train_loss = 1.00373341, grad/param norm = 1.7492e-01, time/batch = 20.2710s	
19557/33250 (epoch 29.409), train_loss = 0.90015763, grad/param norm = 2.1854e-01, time/batch = 25.2452s	
19558/33250 (epoch 29.411), train_loss = 0.62204937, grad/param norm = 1.4413e-01, time/batch = 15.9273s	
19559/33250 (epoch 29.412), train_loss = 0.70359363, grad/param norm = 1.7824e-01, time/batch = 15.8445s	
19560/33250 (epoch 29.414), train_loss = 0.86910400, grad/param norm = 1.5631e-01, time/batch = 15.8429s	
19561/33250 (epoch 29.415), train_loss = 0.93094518, grad/param norm = 2.1709e-01, time/batch = 15.8547s	
19562/33250 (epoch 29.417), train_loss = 0.94612537, grad/param norm = 1.8087e-01, time/batch = 15.6875s	
19563/33250 (epoch 29.418), train_loss = 1.08412186, grad/param norm = 2.0238e-01, time/batch = 15.8366s	
19564/33250 (epoch 29.420), train_loss = 0.93865542, grad/param norm = 1.7392e-01, time/batch = 15.7689s	
19565/33250 (epoch 29.421), train_loss = 0.77099490, grad/param norm = 1.3790e-01, time/batch = 15.7669s	
19566/33250 (epoch 29.423), train_loss = 0.90528273, grad/param norm = 2.7731e-01, time/batch = 15.8776s	
19567/33250 (epoch 29.424), train_loss = 0.97661126, grad/param norm = 2.8858e-01, time/batch = 15.7843s	
19568/33250 (epoch 29.426), train_loss = 0.82851283, grad/param norm = 1.6783e-01, time/batch = 15.7801s	
19569/33250 (epoch 29.427), train_loss = 0.80276374, grad/param norm = 1.9701e-01, time/batch = 15.8629s	
19570/33250 (epoch 29.429), train_loss = 0.89889037, grad/param norm = 1.9118e-01, time/batch = 15.4432s	
19571/33250 (epoch 29.430), train_loss = 0.78823040, grad/param norm = 1.6068e-01, time/batch = 15.9248s	
19572/33250 (epoch 29.432), train_loss = 0.90847194, grad/param norm = 1.5437e-01, time/batch = 15.6923s	
19573/33250 (epoch 29.433), train_loss = 0.78278384, grad/param norm = 1.8657e-01, time/batch = 15.7723s	
19574/33250 (epoch 29.435), train_loss = 0.95394101, grad/param norm = 1.8331e-01, time/batch = 15.7464s	
19575/33250 (epoch 29.436), train_loss = 0.78873595, grad/param norm = 1.7443e-01, time/batch = 15.6775s	
19576/33250 (epoch 29.438), train_loss = 0.93960054, grad/param norm = 1.7947e-01, time/batch = 15.7019s	
19577/33250 (epoch 29.439), train_loss = 0.86302511, grad/param norm = 1.4844e-01, time/batch = 15.7082s	
19578/33250 (epoch 29.441), train_loss = 0.83657616, grad/param norm = 1.4867e-01, time/batch = 15.8454s	
19579/33250 (epoch 29.442), train_loss = 0.76437462, grad/param norm = 1.5867e-01, time/batch = 15.8682s	
19580/33250 (epoch 29.444), train_loss = 0.81104852, grad/param norm = 1.5479e-01, time/batch = 15.6918s	
19581/33250 (epoch 29.445), train_loss = 0.86716571, grad/param norm = 1.4279e-01, time/batch = 16.0043s	
19582/33250 (epoch 29.447), train_loss = 0.77036826, grad/param norm = 1.5863e-01, time/batch = 15.9270s	
19583/33250 (epoch 29.448), train_loss = 0.86859064, grad/param norm = 1.4770e-01, time/batch = 15.7685s	
19584/33250 (epoch 29.450), train_loss = 0.96515519, grad/param norm = 1.8169e-01, time/batch = 15.7588s	
19585/33250 (epoch 29.451), train_loss = 0.92033861, grad/param norm = 1.8709e-01, time/batch = 15.6077s	
19586/33250 (epoch 29.453), train_loss = 0.76189968, grad/param norm = 1.3634e-01, time/batch = 15.9074s	
19587/33250 (epoch 29.454), train_loss = 0.98874504, grad/param norm = 1.7996e-01, time/batch = 15.8342s	
19588/33250 (epoch 29.456), train_loss = 0.97331133, grad/param norm = 1.4834e-01, time/batch = 15.7881s	
19589/33250 (epoch 29.457), train_loss = 0.80693479, grad/param norm = 1.6646e-01, time/batch = 15.6138s	
19590/33250 (epoch 29.459), train_loss = 0.90558777, grad/param norm = 1.6894e-01, time/batch = 15.9467s	
19591/33250 (epoch 29.460), train_loss = 0.93410692, grad/param norm = 1.7832e-01, time/batch = 15.8455s	
19592/33250 (epoch 29.462), train_loss = 0.83076320, grad/param norm = 1.4692e-01, time/batch = 15.7501s	
19593/33250 (epoch 29.463), train_loss = 0.78380866, grad/param norm = 1.3275e-01, time/batch = 15.5835s	
19594/33250 (epoch 29.465), train_loss = 0.71026041, grad/param norm = 1.3131e-01, time/batch = 15.7444s	
19595/33250 (epoch 29.466), train_loss = 0.67831394, grad/param norm = 1.2050e-01, time/batch = 15.8145s	
19596/33250 (epoch 29.468), train_loss = 0.73487217, grad/param norm = 1.2909e-01, time/batch = 15.6967s	
19597/33250 (epoch 29.469), train_loss = 0.80419055, grad/param norm = 1.4975e-01, time/batch = 15.7439s	
19598/33250 (epoch 29.471), train_loss = 0.90266260, grad/param norm = 1.4835e-01, time/batch = 16.0276s	
19599/33250 (epoch 29.472), train_loss = 0.82167976, grad/param norm = 2.0064e-01, time/batch = 15.6908s	
19600/33250 (epoch 29.474), train_loss = 0.96843510, grad/param norm = 1.8294e-01, time/batch = 15.7843s	
19601/33250 (epoch 29.475), train_loss = 0.89006596, grad/param norm = 1.5792e-01, time/batch = 16.0199s	
19602/33250 (epoch 29.477), train_loss = 0.84049896, grad/param norm = 1.5171e-01, time/batch = 15.8549s	
19603/33250 (epoch 29.478), train_loss = 0.76408445, grad/param norm = 1.5336e-01, time/batch = 15.8568s	
19604/33250 (epoch 29.480), train_loss = 0.98877881, grad/param norm = 1.6923e-01, time/batch = 15.7566s	
19605/33250 (epoch 29.481), train_loss = 0.85501786, grad/param norm = 1.4846e-01, time/batch = 15.9152s	
19606/33250 (epoch 29.483), train_loss = 0.82639281, grad/param norm = 1.6592e-01, time/batch = 15.9061s	
19607/33250 (epoch 29.484), train_loss = 0.78040284, grad/param norm = 1.5960e-01, time/batch = 15.9350s	
19608/33250 (epoch 29.486), train_loss = 0.72687802, grad/param norm = 1.5957e-01, time/batch = 15.8440s	
19609/33250 (epoch 29.487), train_loss = 0.79992943, grad/param norm = 1.5311e-01, time/batch = 15.7774s	
19610/33250 (epoch 29.489), train_loss = 0.94351991, grad/param norm = 1.8979e-01, time/batch = 15.7863s	
19611/33250 (epoch 29.490), train_loss = 0.90731473, grad/param norm = 1.8879e-01, time/batch = 16.0929s	
19612/33250 (epoch 29.492), train_loss = 0.94566925, grad/param norm = 1.8143e-01, time/batch = 16.0085s	
19613/33250 (epoch 29.493), train_loss = 0.85244547, grad/param norm = 1.8641e-01, time/batch = 15.8441s	
19614/33250 (epoch 29.495), train_loss = 0.91321211, grad/param norm = 1.6017e-01, time/batch = 15.7555s	
19615/33250 (epoch 29.496), train_loss = 0.86507797, grad/param norm = 1.3582e-01, time/batch = 15.8441s	
19616/33250 (epoch 29.498), train_loss = 0.94459917, grad/param norm = 1.6481e-01, time/batch = 16.0047s	
19617/33250 (epoch 29.499), train_loss = 0.79128663, grad/param norm = 1.4552e-01, time/batch = 15.8470s	
19618/33250 (epoch 29.501), train_loss = 0.79224773, grad/param norm = 1.6381e-01, time/batch = 15.8284s	
19619/33250 (epoch 29.502), train_loss = 0.80292672, grad/param norm = 1.4559e-01, time/batch = 15.9421s	
19620/33250 (epoch 29.504), train_loss = 0.98250316, grad/param norm = 1.8644e-01, time/batch = 15.7853s	
19621/33250 (epoch 29.505), train_loss = 0.71050316, grad/param norm = 1.2881e-01, time/batch = 15.8473s	
19622/33250 (epoch 29.507), train_loss = 0.77555325, grad/param norm = 1.7518e-01, time/batch = 15.8570s	
19623/33250 (epoch 29.508), train_loss = 0.81981139, grad/param norm = 1.5442e-01, time/batch = 15.7771s	
19624/33250 (epoch 29.510), train_loss = 0.69491575, grad/param norm = 1.2203e-01, time/batch = 15.8406s	
19625/33250 (epoch 29.511), train_loss = 0.83705728, grad/param norm = 1.7181e-01, time/batch = 15.7677s	
19626/33250 (epoch 29.513), train_loss = 0.96627014, grad/param norm = 1.5254e-01, time/batch = 15.7769s	
19627/33250 (epoch 29.514), train_loss = 0.83987342, grad/param norm = 1.6651e-01, time/batch = 15.8412s	
19628/33250 (epoch 29.516), train_loss = 0.78206350, grad/param norm = 1.6698e-01, time/batch = 15.7560s	
19629/33250 (epoch 29.517), train_loss = 0.81007669, grad/param norm = 1.5223e-01, time/batch = 15.5360s	
19630/33250 (epoch 29.519), train_loss = 0.73140616, grad/param norm = 1.2318e-01, time/batch = 15.9881s	
19631/33250 (epoch 29.520), train_loss = 1.03237003, grad/param norm = 1.9451e-01, time/batch = 15.7559s	
19632/33250 (epoch 29.522), train_loss = 0.91123830, grad/param norm = 1.6700e-01, time/batch = 15.6990s	
19633/33250 (epoch 29.523), train_loss = 0.77896737, grad/param norm = 1.5090e-01, time/batch = 15.5322s	
19634/33250 (epoch 29.525), train_loss = 0.73500568, grad/param norm = 1.5808e-01, time/batch = 15.5392s	
19635/33250 (epoch 29.526), train_loss = 0.74050194, grad/param norm = 1.4246e-01, time/batch = 15.5980s	
19636/33250 (epoch 29.528), train_loss = 0.80569459, grad/param norm = 1.5114e-01, time/batch = 15.7708s	
19637/33250 (epoch 29.529), train_loss = 0.78511308, grad/param norm = 1.6828e-01, time/batch = 15.7599s	
19638/33250 (epoch 29.531), train_loss = 0.74635197, grad/param norm = 1.3814e-01, time/batch = 15.5273s	
19639/33250 (epoch 29.532), train_loss = 0.88872151, grad/param norm = 1.5570e-01, time/batch = 15.6816s	
19640/33250 (epoch 29.534), train_loss = 0.75453537, grad/param norm = 1.4687e-01, time/batch = 15.7058s	
19641/33250 (epoch 29.535), train_loss = 0.82385927, grad/param norm = 1.5099e-01, time/batch = 15.8645s	
19642/33250 (epoch 29.537), train_loss = 0.86780944, grad/param norm = 1.6158e-01, time/batch = 15.8625s	
19643/33250 (epoch 29.538), train_loss = 0.88627065, grad/param norm = 1.5327e-01, time/batch = 15.8737s	
19644/33250 (epoch 29.540), train_loss = 0.98985328, grad/param norm = 1.4427e-01, time/batch = 15.6851s	
19645/33250 (epoch 29.541), train_loss = 0.92750320, grad/param norm = 1.8658e-01, time/batch = 15.6881s	
19646/33250 (epoch 29.543), train_loss = 0.90059192, grad/param norm = 1.7994e-01, time/batch = 15.7551s	
19647/33250 (epoch 29.544), train_loss = 0.78378979, grad/param norm = 1.6753e-01, time/batch = 15.6155s	
19648/33250 (epoch 29.546), train_loss = 0.80756943, grad/param norm = 1.7804e-01, time/batch = 15.6840s	
19649/33250 (epoch 29.547), train_loss = 0.82798229, grad/param norm = 1.7252e-01, time/batch = 15.6870s	
19650/33250 (epoch 29.549), train_loss = 0.85335185, grad/param norm = 1.7450e-01, time/batch = 15.9254s	
19651/33250 (epoch 29.550), train_loss = 0.80827945, grad/param norm = 1.5793e-01, time/batch = 16.3903s	
19652/33250 (epoch 29.552), train_loss = 0.90122490, grad/param norm = 1.7293e-01, time/batch = 15.7009s	
19653/33250 (epoch 29.553), train_loss = 0.79716822, grad/param norm = 1.4390e-01, time/batch = 15.4559s	
19654/33250 (epoch 29.555), train_loss = 0.86858870, grad/param norm = 1.5753e-01, time/batch = 15.9286s	
19655/33250 (epoch 29.556), train_loss = 0.87036299, grad/param norm = 1.8481e-01, time/batch = 15.6912s	
19656/33250 (epoch 29.558), train_loss = 0.91211758, grad/param norm = 1.6705e-01, time/batch = 15.7664s	
19657/33250 (epoch 29.559), train_loss = 0.77790775, grad/param norm = 1.4784e-01, time/batch = 15.6791s	
19658/33250 (epoch 29.561), train_loss = 0.74337573, grad/param norm = 1.3766e-01, time/batch = 15.6861s	
19659/33250 (epoch 29.562), train_loss = 0.88747123, grad/param norm = 1.7478e-01, time/batch = 15.6752s	
19660/33250 (epoch 29.564), train_loss = 1.01556523, grad/param norm = 1.9250e-01, time/batch = 15.6993s	
19661/33250 (epoch 29.565), train_loss = 0.98316026, grad/param norm = 1.9502e-01, time/batch = 15.8502s	
19662/33250 (epoch 29.567), train_loss = 0.95292072, grad/param norm = 1.7169e-01, time/batch = 15.9452s	
19663/33250 (epoch 29.568), train_loss = 0.80402820, grad/param norm = 1.4922e-01, time/batch = 15.7082s	
19664/33250 (epoch 29.570), train_loss = 0.93300991, grad/param norm = 1.7897e-01, time/batch = 15.7852s	
19665/33250 (epoch 29.571), train_loss = 0.98599957, grad/param norm = 1.7305e-01, time/batch = 15.7505s	
19666/33250 (epoch 29.573), train_loss = 0.92656303, grad/param norm = 1.7236e-01, time/batch = 15.5182s	
19667/33250 (epoch 29.574), train_loss = 0.79142544, grad/param norm = 1.4561e-01, time/batch = 15.6928s	
19668/33250 (epoch 29.576), train_loss = 0.92228316, grad/param norm = 1.8089e-01, time/batch = 15.8515s	
19669/33250 (epoch 29.577), train_loss = 0.85039395, grad/param norm = 1.6685e-01, time/batch = 15.9158s	
19670/33250 (epoch 29.579), train_loss = 0.76076137, grad/param norm = 1.9001e-01, time/batch = 15.7425s	
19671/33250 (epoch 29.580), train_loss = 0.81349400, grad/param norm = 1.4225e-01, time/batch = 15.5079s	
19672/33250 (epoch 29.582), train_loss = 0.80902958, grad/param norm = 1.5347e-01, time/batch = 15.8536s	
19673/33250 (epoch 29.583), train_loss = 0.93271410, grad/param norm = 1.6230e-01, time/batch = 15.8188s	
19674/33250 (epoch 29.585), train_loss = 0.95457130, grad/param norm = 1.6668e-01, time/batch = 15.6909s	
19675/33250 (epoch 29.586), train_loss = 0.80120976, grad/param norm = 2.0212e-01, time/batch = 15.9282s	
19676/33250 (epoch 29.588), train_loss = 0.87764426, grad/param norm = 1.6036e-01, time/batch = 15.9933s	
19677/33250 (epoch 29.589), train_loss = 0.85852625, grad/param norm = 1.6146e-01, time/batch = 15.9044s	
19678/33250 (epoch 29.591), train_loss = 0.84681919, grad/param norm = 1.8004e-01, time/batch = 15.5904s	
19679/33250 (epoch 29.592), train_loss = 0.83135926, grad/param norm = 1.5635e-01, time/batch = 15.9310s	
19680/33250 (epoch 29.594), train_loss = 0.97699046, grad/param norm = 1.7563e-01, time/batch = 15.6856s	
19681/33250 (epoch 29.595), train_loss = 0.86358983, grad/param norm = 1.6360e-01, time/batch = 16.0787s	
19682/33250 (epoch 29.597), train_loss = 0.71251452, grad/param norm = 1.4288e-01, time/batch = 15.3449s	
19683/33250 (epoch 29.598), train_loss = 0.81522625, grad/param norm = 1.7567e-01, time/batch = 15.5990s	
19684/33250 (epoch 29.600), train_loss = 0.82192772, grad/param norm = 1.7122e-01, time/batch = 15.8955s	
19685/33250 (epoch 29.602), train_loss = 0.88190671, grad/param norm = 2.0299e-01, time/batch = 16.0408s	
19686/33250 (epoch 29.603), train_loss = 0.90366198, grad/param norm = 1.6639e-01, time/batch = 15.8422s	
19687/33250 (epoch 29.605), train_loss = 0.85618179, grad/param norm = 1.7778e-01, time/batch = 15.5184s	
19688/33250 (epoch 29.606), train_loss = 0.92761755, grad/param norm = 1.8056e-01, time/batch = 16.0817s	
19689/33250 (epoch 29.608), train_loss = 0.87388665, grad/param norm = 1.5503e-01, time/batch = 15.5983s	
19690/33250 (epoch 29.609), train_loss = 0.77718172, grad/param norm = 1.7584e-01, time/batch = 15.6031s	
19691/33250 (epoch 29.611), train_loss = 0.85985606, grad/param norm = 1.8696e-01, time/batch = 15.6826s	
19692/33250 (epoch 29.612), train_loss = 0.84457795, grad/param norm = 1.6443e-01, time/batch = 16.0156s	
19693/33250 (epoch 29.614), train_loss = 1.05061329, grad/param norm = 1.8565e-01, time/batch = 15.6244s	
19694/33250 (epoch 29.615), train_loss = 0.96186225, grad/param norm = 1.8955e-01, time/batch = 15.7582s	
19695/33250 (epoch 29.617), train_loss = 1.08765806, grad/param norm = 2.3004e-01, time/batch = 15.6988s	
19696/33250 (epoch 29.618), train_loss = 1.11886609, grad/param norm = 2.4272e-01, time/batch = 15.7917s	
19697/33250 (epoch 29.620), train_loss = 0.95681828, grad/param norm = 2.4456e-01, time/batch = 15.6848s	
19698/33250 (epoch 29.621), train_loss = 0.90061934, grad/param norm = 1.5944e-01, time/batch = 15.7738s	
19699/33250 (epoch 29.623), train_loss = 0.78601792, grad/param norm = 1.6398e-01, time/batch = 15.6802s	
19700/33250 (epoch 29.624), train_loss = 0.83969576, grad/param norm = 2.1286e-01, time/batch = 15.6706s	
19701/33250 (epoch 29.626), train_loss = 0.84189922, grad/param norm = 2.1094e-01, time/batch = 15.8496s	
19702/33250 (epoch 29.627), train_loss = 0.81449105, grad/param norm = 1.6015e-01, time/batch = 15.8358s	
19703/33250 (epoch 29.629), train_loss = 0.91154925, grad/param norm = 2.1805e-01, time/batch = 15.9231s	
19704/33250 (epoch 29.630), train_loss = 0.84142490, grad/param norm = 1.9209e-01, time/batch = 15.8634s	
19705/33250 (epoch 29.632), train_loss = 0.76220033, grad/param norm = 1.5503e-01, time/batch = 15.6010s	
19706/33250 (epoch 29.633), train_loss = 0.87480014, grad/param norm = 1.8719e-01, time/batch = 15.8928s	
19707/33250 (epoch 29.635), train_loss = 0.79090896, grad/param norm = 1.6771e-01, time/batch = 15.8428s	
19708/33250 (epoch 29.636), train_loss = 0.78227842, grad/param norm = 1.4481e-01, time/batch = 15.5862s	
19709/33250 (epoch 29.638), train_loss = 0.78172045, grad/param norm = 1.5975e-01, time/batch = 15.7574s	
19710/33250 (epoch 29.639), train_loss = 0.73298129, grad/param norm = 1.5733e-01, time/batch = 15.6908s	
19711/33250 (epoch 29.641), train_loss = 0.83931933, grad/param norm = 1.6681e-01, time/batch = 15.6793s	
19712/33250 (epoch 29.642), train_loss = 0.65978270, grad/param norm = 1.5230e-01, time/batch = 15.5959s	
19713/33250 (epoch 29.644), train_loss = 0.59655932, grad/param norm = 1.3674e-01, time/batch = 15.7489s	
19714/33250 (epoch 29.645), train_loss = 0.87870347, grad/param norm = 1.9856e-01, time/batch = 15.6847s	
19715/33250 (epoch 29.647), train_loss = 0.73540406, grad/param norm = 1.7385e-01, time/batch = 15.8548s	
19716/33250 (epoch 29.648), train_loss = 0.73702351, grad/param norm = 1.6828e-01, time/batch = 15.6922s	
19717/33250 (epoch 29.650), train_loss = 0.98527929, grad/param norm = 1.8833e-01, time/batch = 15.4390s	
19718/33250 (epoch 29.651), train_loss = 0.90192227, grad/param norm = 1.7307e-01, time/batch = 15.6940s	
19719/33250 (epoch 29.653), train_loss = 0.78843838, grad/param norm = 1.7392e-01, time/batch = 15.3637s	
19720/33250 (epoch 29.654), train_loss = 0.84455261, grad/param norm = 1.5254e-01, time/batch = 15.6023s	
19721/33250 (epoch 29.656), train_loss = 0.88662161, grad/param norm = 1.6459e-01, time/batch = 15.6947s	
19722/33250 (epoch 29.657), train_loss = 0.68554608, grad/param norm = 1.7270e-01, time/batch = 15.8476s	
19723/33250 (epoch 29.659), train_loss = 0.78380882, grad/param norm = 1.6393e-01, time/batch = 15.7578s	
19724/33250 (epoch 29.660), train_loss = 0.86081148, grad/param norm = 1.7242e-01, time/batch = 15.5310s	
19725/33250 (epoch 29.662), train_loss = 0.84397673, grad/param norm = 1.6553e-01, time/batch = 15.5987s	
19726/33250 (epoch 29.663), train_loss = 0.77091943, grad/param norm = 1.6163e-01, time/batch = 15.9282s	
19727/33250 (epoch 29.665), train_loss = 0.88545673, grad/param norm = 1.7369e-01, time/batch = 15.4538s	
19728/33250 (epoch 29.666), train_loss = 0.80790576, grad/param norm = 1.4568e-01, time/batch = 15.6921s	
19729/33250 (epoch 29.668), train_loss = 0.94902788, grad/param norm = 1.6045e-01, time/batch = 15.6077s	
19730/33250 (epoch 29.669), train_loss = 0.84536911, grad/param norm = 1.6127e-01, time/batch = 15.7525s	
19731/33250 (epoch 29.671), train_loss = 0.76772579, grad/param norm = 1.6301e-01, time/batch = 15.6129s	
19732/33250 (epoch 29.672), train_loss = 0.90787496, grad/param norm = 1.6210e-01, time/batch = 15.8191s	
19733/33250 (epoch 29.674), train_loss = 0.74064722, grad/param norm = 1.4587e-01, time/batch = 15.8353s	
19734/33250 (epoch 29.675), train_loss = 0.84806993, grad/param norm = 1.4897e-01, time/batch = 15.7674s	
19735/33250 (epoch 29.677), train_loss = 0.93174503, grad/param norm = 1.7239e-01, time/batch = 15.6146s	
19736/33250 (epoch 29.678), train_loss = 0.81932272, grad/param norm = 2.0199e-01, time/batch = 15.5348s	
19737/33250 (epoch 29.680), train_loss = 0.94793830, grad/param norm = 1.7842e-01, time/batch = 15.8309s	
19738/33250 (epoch 29.681), train_loss = 0.74698802, grad/param norm = 1.3156e-01, time/batch = 15.7801s	
19739/33250 (epoch 29.683), train_loss = 0.78489066, grad/param norm = 1.6952e-01, time/batch = 15.5354s	
19740/33250 (epoch 29.684), train_loss = 0.74995322, grad/param norm = 1.6825e-01, time/batch = 15.6042s	
19741/33250 (epoch 29.686), train_loss = 0.77301176, grad/param norm = 1.6333e-01, time/batch = 15.9205s	
19742/33250 (epoch 29.687), train_loss = 0.85834682, grad/param norm = 1.6738e-01, time/batch = 15.7714s	
19743/33250 (epoch 29.689), train_loss = 0.75883446, grad/param norm = 1.7106e-01, time/batch = 15.7754s	
19744/33250 (epoch 29.690), train_loss = 0.86719177, grad/param norm = 1.8327e-01, time/batch = 15.6904s	
19745/33250 (epoch 29.692), train_loss = 0.81421943, grad/param norm = 1.5910e-01, time/batch = 15.7465s	
19746/33250 (epoch 29.693), train_loss = 0.90801918, grad/param norm = 1.6100e-01, time/batch = 15.6794s	
19747/33250 (epoch 29.695), train_loss = 0.87350850, grad/param norm = 1.6530e-01, time/batch = 15.6101s	
19748/33250 (epoch 29.696), train_loss = 0.90417059, grad/param norm = 1.5952e-01, time/batch = 15.6774s	
19749/33250 (epoch 29.698), train_loss = 0.79530368, grad/param norm = 1.5816e-01, time/batch = 15.8239s	
19750/33250 (epoch 29.699), train_loss = 1.03620952, grad/param norm = 1.7570e-01, time/batch = 15.6218s	
19751/33250 (epoch 29.701), train_loss = 0.83524687, grad/param norm = 1.3676e-01, time/batch = 15.6044s	
19752/33250 (epoch 29.702), train_loss = 0.81666736, grad/param norm = 2.1342e-01, time/batch = 15.5221s	
19753/33250 (epoch 29.704), train_loss = 1.01046563, grad/param norm = 1.9511e-01, time/batch = 15.5997s	
19754/33250 (epoch 29.705), train_loss = 0.80726377, grad/param norm = 1.6195e-01, time/batch = 15.6895s	
19755/33250 (epoch 29.707), train_loss = 0.69697133, grad/param norm = 1.5548e-01, time/batch = 15.8372s	
19756/33250 (epoch 29.708), train_loss = 0.91842659, grad/param norm = 1.7671e-01, time/batch = 15.9996s	
19757/33250 (epoch 29.710), train_loss = 0.89223309, grad/param norm = 1.8154e-01, time/batch = 15.5984s	
19758/33250 (epoch 29.711), train_loss = 0.75502169, grad/param norm = 1.7469e-01, time/batch = 15.5429s	
19759/33250 (epoch 29.713), train_loss = 0.85833905, grad/param norm = 1.3617e-01, time/batch = 15.6256s	
19760/33250 (epoch 29.714), train_loss = 0.83822290, grad/param norm = 1.6310e-01, time/batch = 15.9286s	
19761/33250 (epoch 29.716), train_loss = 0.87910437, grad/param norm = 1.6837e-01, time/batch = 15.7882s	
19762/33250 (epoch 29.717), train_loss = 0.77079141, grad/param norm = 1.2977e-01, time/batch = 15.3612s	
19763/33250 (epoch 29.719), train_loss = 0.81116961, grad/param norm = 1.6247e-01, time/batch = 15.4530s	
19764/33250 (epoch 29.720), train_loss = 1.07529789, grad/param norm = 1.9610e-01, time/batch = 16.0698s	
19765/33250 (epoch 29.722), train_loss = 0.72884317, grad/param norm = 1.4102e-01, time/batch = 15.8486s	
19766/33250 (epoch 29.723), train_loss = 0.66462557, grad/param norm = 1.3122e-01, time/batch = 15.4463s	
19767/33250 (epoch 29.725), train_loss = 0.78685655, grad/param norm = 1.3283e-01, time/batch = 15.6902s	
19768/33250 (epoch 29.726), train_loss = 0.81825956, grad/param norm = 1.7290e-01, time/batch = 15.8556s	
19769/33250 (epoch 29.728), train_loss = 0.88784304, grad/param norm = 1.7032e-01, time/batch = 15.7006s	
19770/33250 (epoch 29.729), train_loss = 0.92082922, grad/param norm = 1.5729e-01, time/batch = 15.8497s	
19771/33250 (epoch 29.731), train_loss = 0.76769802, grad/param norm = 1.5841e-01, time/batch = 15.6931s	
19772/33250 (epoch 29.732), train_loss = 0.75609806, grad/param norm = 1.4146e-01, time/batch = 15.7722s	
19773/33250 (epoch 29.734), train_loss = 0.87406385, grad/param norm = 1.8702e-01, time/batch = 15.8360s	
19774/33250 (epoch 29.735), train_loss = 0.87999653, grad/param norm = 1.7457e-01, time/batch = 15.6103s	
19775/33250 (epoch 29.737), train_loss = 0.79040615, grad/param norm = 1.4296e-01, time/batch = 15.7496s	
19776/33250 (epoch 29.738), train_loss = 0.86763095, grad/param norm = 1.5753e-01, time/batch = 15.6867s	
19777/33250 (epoch 29.740), train_loss = 0.90079135, grad/param norm = 1.7287e-01, time/batch = 15.6728s	
19778/33250 (epoch 29.741), train_loss = 0.90265676, grad/param norm = 1.6251e-01, time/batch = 15.6916s	
19779/33250 (epoch 29.743), train_loss = 0.77993314, grad/param norm = 1.4636e-01, time/batch = 15.7509s	
19780/33250 (epoch 29.744), train_loss = 0.81432954, grad/param norm = 1.6663e-01, time/batch = 15.5506s	
19781/33250 (epoch 29.746), train_loss = 0.75181015, grad/param norm = 1.4360e-01, time/batch = 15.8663s	
19782/33250 (epoch 29.747), train_loss = 0.79646217, grad/param norm = 1.6131e-01, time/batch = 16.0304s	
19783/33250 (epoch 29.749), train_loss = 0.94599372, grad/param norm = 1.7335e-01, time/batch = 30.0420s	
19784/33250 (epoch 29.750), train_loss = 0.91189474, grad/param norm = 1.5766e-01, time/batch = 15.6092s	
19785/33250 (epoch 29.752), train_loss = 0.81261587, grad/param norm = 1.5898e-01, time/batch = 15.7685s	
19786/33250 (epoch 29.753), train_loss = 0.78699312, grad/param norm = 1.6602e-01, time/batch = 16.0165s	
19787/33250 (epoch 29.755), train_loss = 0.77127388, grad/param norm = 1.7404e-01, time/batch = 15.5873s	
19788/33250 (epoch 29.756), train_loss = 0.86880561, grad/param norm = 1.7055e-01, time/batch = 15.8407s	
19789/33250 (epoch 29.758), train_loss = 0.99701120, grad/param norm = 1.5167e-01, time/batch = 15.8447s	
19790/33250 (epoch 29.759), train_loss = 0.77954055, grad/param norm = 1.4687e-01, time/batch = 15.9785s	
19791/33250 (epoch 29.761), train_loss = 0.84793388, grad/param norm = 1.6737e-01, time/batch = 15.9484s	
19792/33250 (epoch 29.762), train_loss = 0.91448984, grad/param norm = 1.6455e-01, time/batch = 15.6233s	
19793/33250 (epoch 29.764), train_loss = 0.78003269, grad/param norm = 2.0016e-01, time/batch = 15.7556s	
19794/33250 (epoch 29.765), train_loss = 0.89605291, grad/param norm = 1.8288e-01, time/batch = 15.8376s	
19795/33250 (epoch 29.767), train_loss = 0.67128988, grad/param norm = 1.4532e-01, time/batch = 15.9127s	
19796/33250 (epoch 29.768), train_loss = 0.72460632, grad/param norm = 1.7420e-01, time/batch = 15.5249s	
19797/33250 (epoch 29.770), train_loss = 0.87952553, grad/param norm = 1.8351e-01, time/batch = 15.9985s	
19798/33250 (epoch 29.771), train_loss = 0.90291519, grad/param norm = 1.6843e-01, time/batch = 16.0185s	
19799/33250 (epoch 29.773), train_loss = 0.80676591, grad/param norm = 1.6868e-01, time/batch = 15.9306s	
19800/33250 (epoch 29.774), train_loss = 0.71940544, grad/param norm = 1.5075e-01, time/batch = 16.0109s	
19801/33250 (epoch 29.776), train_loss = 0.80323041, grad/param norm = 1.6282e-01, time/batch = 16.1762s	
19802/33250 (epoch 29.777), train_loss = 0.92266902, grad/param norm = 1.8216e-01, time/batch = 15.9981s	
19803/33250 (epoch 29.779), train_loss = 0.80996794, grad/param norm = 1.5612e-01, time/batch = 15.6856s	
19804/33250 (epoch 29.780), train_loss = 0.97052844, grad/param norm = 2.0240e-01, time/batch = 15.6732s	
19805/33250 (epoch 29.782), train_loss = 0.83679156, grad/param norm = 2.2604e-01, time/batch = 15.8456s	
19806/33250 (epoch 29.783), train_loss = 0.70896072, grad/param norm = 1.4488e-01, time/batch = 15.7615s	
19807/33250 (epoch 29.785), train_loss = 0.72905614, grad/param norm = 1.6385e-01, time/batch = 15.6853s	
19808/33250 (epoch 29.786), train_loss = 0.97467901, grad/param norm = 1.8643e-01, time/batch = 15.6786s	
19809/33250 (epoch 29.788), train_loss = 0.92529805, grad/param norm = 1.6128e-01, time/batch = 15.5993s	
19810/33250 (epoch 29.789), train_loss = 0.95416687, grad/param norm = 2.0251e-01, time/batch = 15.7695s	
19811/33250 (epoch 29.791), train_loss = 0.97093065, grad/param norm = 1.8776e-01, time/batch = 15.7032s	
19812/33250 (epoch 29.792), train_loss = 1.00808465, grad/param norm = 1.8135e-01, time/batch = 15.7658s	
19813/33250 (epoch 29.794), train_loss = 0.82270355, grad/param norm = 1.6845e-01, time/batch = 15.9192s	
19814/33250 (epoch 29.795), train_loss = 0.84858189, grad/param norm = 1.6706e-01, time/batch = 15.8464s	
19815/33250 (epoch 29.797), train_loss = 0.92603765, grad/param norm = 1.9187e-01, time/batch = 15.8345s	
19816/33250 (epoch 29.798), train_loss = 0.85064944, grad/param norm = 2.1771e-01, time/batch = 15.8449s	
19817/33250 (epoch 29.800), train_loss = 0.91156496, grad/param norm = 1.8666e-01, time/batch = 15.6129s	
19818/33250 (epoch 29.802), train_loss = 0.83816173, grad/param norm = 1.6742e-01, time/batch = 15.6719s	
19819/33250 (epoch 29.803), train_loss = 0.88156300, grad/param norm = 1.7755e-01, time/batch = 15.6723s	
19820/33250 (epoch 29.805), train_loss = 0.87867086, grad/param norm = 1.7576e-01, time/batch = 15.7507s	
19821/33250 (epoch 29.806), train_loss = 0.85934129, grad/param norm = 1.7232e-01, time/batch = 15.7793s	
19822/33250 (epoch 29.808), train_loss = 0.77567125, grad/param norm = 1.4785e-01, time/batch = 15.6153s	
19823/33250 (epoch 29.809), train_loss = 0.77116536, grad/param norm = 1.5782e-01, time/batch = 15.6110s	
19824/33250 (epoch 29.811), train_loss = 0.76167392, grad/param norm = 1.5320e-01, time/batch = 15.7869s	
19825/33250 (epoch 29.812), train_loss = 0.89652779, grad/param norm = 1.8217e-01, time/batch = 15.6788s	
19826/33250 (epoch 29.814), train_loss = 0.85020457, grad/param norm = 1.7949e-01, time/batch = 15.5211s	
19827/33250 (epoch 29.815), train_loss = 0.89996879, grad/param norm = 1.5736e-01, time/batch = 15.6783s	
19828/33250 (epoch 29.817), train_loss = 0.83545993, grad/param norm = 1.6265e-01, time/batch = 15.5178s	
19829/33250 (epoch 29.818), train_loss = 0.77727730, grad/param norm = 1.5980e-01, time/batch = 15.4490s	
19830/33250 (epoch 29.820), train_loss = 0.85270729, grad/param norm = 1.6338e-01, time/batch = 15.5197s	
19831/33250 (epoch 29.821), train_loss = 0.81998356, grad/param norm = 1.7430e-01, time/batch = 15.7536s	
19832/33250 (epoch 29.823), train_loss = 1.15173052, grad/param norm = 2.0764e-01, time/batch = 15.4620s	
19833/33250 (epoch 29.824), train_loss = 0.79516389, grad/param norm = 1.8599e-01, time/batch = 15.6323s	
19834/33250 (epoch 29.826), train_loss = 0.87880048, grad/param norm = 1.6006e-01, time/batch = 15.6172s	
19835/33250 (epoch 29.827), train_loss = 0.73371183, grad/param norm = 1.6241e-01, time/batch = 15.8656s	
19836/33250 (epoch 29.829), train_loss = 0.84883650, grad/param norm = 1.6280e-01, time/batch = 15.6845s	
19837/33250 (epoch 29.830), train_loss = 0.92780357, grad/param norm = 1.9640e-01, time/batch = 15.6780s	
19838/33250 (epoch 29.832), train_loss = 0.84451242, grad/param norm = 1.5214e-01, time/batch = 15.7528s	
19839/33250 (epoch 29.833), train_loss = 0.83516064, grad/param norm = 1.6465e-01, time/batch = 15.6781s	
19840/33250 (epoch 29.835), train_loss = 0.77915076, grad/param norm = 1.9552e-01, time/batch = 15.5936s	
19841/33250 (epoch 29.836), train_loss = 0.83635194, grad/param norm = 1.7035e-01, time/batch = 15.6881s	
19842/33250 (epoch 29.838), train_loss = 0.87575901, grad/param norm = 1.6035e-01, time/batch = 15.6852s	
19843/33250 (epoch 29.839), train_loss = 0.81685647, grad/param norm = 1.6771e-01, time/batch = 15.8650s	
19844/33250 (epoch 29.841), train_loss = 0.77748788, grad/param norm = 1.4132e-01, time/batch = 15.7030s	
19845/33250 (epoch 29.842), train_loss = 0.98454038, grad/param norm = 1.7252e-01, time/batch = 15.7840s	
19846/33250 (epoch 29.844), train_loss = 0.94162744, grad/param norm = 1.8050e-01, time/batch = 15.7614s	
19847/33250 (epoch 29.845), train_loss = 1.03718009, grad/param norm = 1.8977e-01, time/batch = 15.7602s	
19848/33250 (epoch 29.847), train_loss = 1.01589615, grad/param norm = 1.7791e-01, time/batch = 15.6109s	
19849/33250 (epoch 29.848), train_loss = 1.05335104, grad/param norm = 1.9678e-01, time/batch = 15.4393s	
19850/33250 (epoch 29.850), train_loss = 0.93668079, grad/param norm = 1.6191e-01, time/batch = 15.7581s	
19851/33250 (epoch 29.851), train_loss = 0.75157860, grad/param norm = 1.7402e-01, time/batch = 15.7003s	
19852/33250 (epoch 29.853), train_loss = 0.89104282, grad/param norm = 1.9026e-01, time/batch = 15.7553s	
19853/33250 (epoch 29.854), train_loss = 0.80824883, grad/param norm = 1.4611e-01, time/batch = 15.7014s	
19854/33250 (epoch 29.856), train_loss = 0.81118533, grad/param norm = 1.8621e-01, time/batch = 16.0175s	
19855/33250 (epoch 29.857), train_loss = 0.75057666, grad/param norm = 1.7126e-01, time/batch = 15.6204s	
19856/33250 (epoch 29.859), train_loss = 0.77635239, grad/param norm = 1.5643e-01, time/batch = 15.5467s	
19857/33250 (epoch 29.860), train_loss = 0.89545565, grad/param norm = 1.6594e-01, time/batch = 15.5183s	
19858/33250 (epoch 29.862), train_loss = 0.75002573, grad/param norm = 1.5584e-01, time/batch = 15.5964s	
19859/33250 (epoch 29.863), train_loss = 0.78988622, grad/param norm = 1.6771e-01, time/batch = 15.5974s	
19860/33250 (epoch 29.865), train_loss = 0.88130874, grad/param norm = 1.7023e-01, time/batch = 15.7674s	
19861/33250 (epoch 29.866), train_loss = 0.73422659, grad/param norm = 1.7822e-01, time/batch = 15.8288s	
19862/33250 (epoch 29.868), train_loss = 0.86738123, grad/param norm = 2.1121e-01, time/batch = 15.6774s	
19863/33250 (epoch 29.869), train_loss = 0.87683405, grad/param norm = 1.9613e-01, time/batch = 15.7582s	
19864/33250 (epoch 29.871), train_loss = 0.68295438, grad/param norm = 1.6828e-01, time/batch = 15.6080s	
19865/33250 (epoch 29.872), train_loss = 0.94066526, grad/param norm = 2.5020e-01, time/batch = 15.5927s	
19866/33250 (epoch 29.874), train_loss = 0.77501209, grad/param norm = 1.7224e-01, time/batch = 15.6873s	
19867/33250 (epoch 29.875), train_loss = 0.73155375, grad/param norm = 2.1979e-01, time/batch = 15.8961s	
19868/33250 (epoch 29.877), train_loss = 0.99262611, grad/param norm = 1.9119e-01, time/batch = 15.8315s	
19869/33250 (epoch 29.878), train_loss = 0.87734029, grad/param norm = 1.6247e-01, time/batch = 15.6790s	
19870/33250 (epoch 29.880), train_loss = 0.83825893, grad/param norm = 1.8722e-01, time/batch = 15.7650s	
19871/33250 (epoch 29.881), train_loss = 0.95358470, grad/param norm = 1.8562e-01, time/batch = 15.9317s	
19872/33250 (epoch 29.883), train_loss = 0.86771925, grad/param norm = 1.6425e-01, time/batch = 15.9193s	
19873/33250 (epoch 29.884), train_loss = 0.92083249, grad/param norm = 1.7151e-01, time/batch = 15.9314s	
19874/33250 (epoch 29.886), train_loss = 0.79744365, grad/param norm = 1.4893e-01, time/batch = 15.9394s	
19875/33250 (epoch 29.887), train_loss = 0.80723520, grad/param norm = 1.7220e-01, time/batch = 15.9549s	
19876/33250 (epoch 29.889), train_loss = 0.79847580, grad/param norm = 1.4500e-01, time/batch = 16.0185s	
19877/33250 (epoch 29.890), train_loss = 0.67360193, grad/param norm = 1.3636e-01, time/batch = 15.8603s	
19878/33250 (epoch 29.892), train_loss = 0.89069418, grad/param norm = 1.5517e-01, time/batch = 15.7596s	
19879/33250 (epoch 29.893), train_loss = 0.90404623, grad/param norm = 1.8386e-01, time/batch = 15.7567s	
19880/33250 (epoch 29.895), train_loss = 0.77177306, grad/param norm = 1.5472e-01, time/batch = 15.7627s	
19881/33250 (epoch 29.896), train_loss = 0.92024923, grad/param norm = 2.0678e-01, time/batch = 15.8485s	
19882/33250 (epoch 29.898), train_loss = 0.84610834, grad/param norm = 1.7036e-01, time/batch = 15.8266s	
19883/33250 (epoch 29.899), train_loss = 0.78134577, grad/param norm = 1.4922e-01, time/batch = 15.9330s	
19884/33250 (epoch 29.901), train_loss = 0.73259273, grad/param norm = 1.4121e-01, time/batch = 16.0067s	
19885/33250 (epoch 29.902), train_loss = 0.79992503, grad/param norm = 1.4670e-01, time/batch = 15.7762s	
19886/33250 (epoch 29.904), train_loss = 0.76230194, grad/param norm = 1.4208e-01, time/batch = 15.7881s	
19887/33250 (epoch 29.905), train_loss = 0.82056817, grad/param norm = 1.5530e-01, time/batch = 15.6303s	
19888/33250 (epoch 29.907), train_loss = 0.76859392, grad/param norm = 1.6984e-01, time/batch = 15.7843s	
19889/33250 (epoch 29.908), train_loss = 0.83445362, grad/param norm = 1.3613e-01, time/batch = 15.5395s	
19890/33250 (epoch 29.910), train_loss = 0.91104816, grad/param norm = 1.7714e-01, time/batch = 15.5325s	
19891/33250 (epoch 29.911), train_loss = 0.73926926, grad/param norm = 1.4553e-01, time/batch = 15.5280s	
19892/33250 (epoch 29.913), train_loss = 0.80973979, grad/param norm = 1.4560e-01, time/batch = 15.6144s	
19893/33250 (epoch 29.914), train_loss = 0.71107385, grad/param norm = 1.4858e-01, time/batch = 15.6811s	
19894/33250 (epoch 29.916), train_loss = 0.74806552, grad/param norm = 1.7003e-01, time/batch = 15.6889s	
19895/33250 (epoch 29.917), train_loss = 0.83307967, grad/param norm = 1.4019e-01, time/batch = 15.7628s	
19896/33250 (epoch 29.919), train_loss = 0.78517949, grad/param norm = 2.0443e-01, time/batch = 15.9798s	
19897/33250 (epoch 29.920), train_loss = 0.83407502, grad/param norm = 1.6576e-01, time/batch = 15.9183s	
19898/33250 (epoch 29.922), train_loss = 0.86965115, grad/param norm = 1.7362e-01, time/batch = 15.5404s	
19899/33250 (epoch 29.923), train_loss = 0.79829946, grad/param norm = 1.8055e-01, time/batch = 15.6141s	
19900/33250 (epoch 29.925), train_loss = 0.79779129, grad/param norm = 1.6443e-01, time/batch = 15.7409s	
19901/33250 (epoch 29.926), train_loss = 0.78740726, grad/param norm = 1.4681e-01, time/batch = 15.6846s	
19902/33250 (epoch 29.928), train_loss = 0.80024602, grad/param norm = 1.6631e-01, time/batch = 15.5186s	
19903/33250 (epoch 29.929), train_loss = 0.70301194, grad/param norm = 1.3439e-01, time/batch = 15.7517s	
19904/33250 (epoch 29.931), train_loss = 0.95134252, grad/param norm = 1.9667e-01, time/batch = 15.6885s	
19905/33250 (epoch 29.932), train_loss = 0.79591937, grad/param norm = 1.6870e-01, time/batch = 15.4986s	
19906/33250 (epoch 29.934), train_loss = 0.77933782, grad/param norm = 1.4154e-01, time/batch = 15.5960s	
19907/33250 (epoch 29.935), train_loss = 0.78325022, grad/param norm = 1.8485e-01, time/batch = 15.9114s	
19908/33250 (epoch 29.937), train_loss = 0.79566116, grad/param norm = 1.8075e-01, time/batch = 15.6860s	
19909/33250 (epoch 29.938), train_loss = 0.82423828, grad/param norm = 1.6219e-01, time/batch = 16.0045s	
19910/33250 (epoch 29.940), train_loss = 0.79644848, grad/param norm = 1.5574e-01, time/batch = 15.8362s	
19911/33250 (epoch 29.941), train_loss = 0.88231199, grad/param norm = 1.7457e-01, time/batch = 16.0568s	
19912/33250 (epoch 29.943), train_loss = 0.98606204, grad/param norm = 1.8238e-01, time/batch = 15.9175s	
19913/33250 (epoch 29.944), train_loss = 0.79958227, grad/param norm = 1.5482e-01, time/batch = 15.4774s	
19914/33250 (epoch 29.946), train_loss = 0.93805475, grad/param norm = 1.7734e-01, time/batch = 15.7259s	
19915/33250 (epoch 29.947), train_loss = 0.75250541, grad/param norm = 1.6193e-01, time/batch = 16.0047s	
19916/33250 (epoch 29.949), train_loss = 0.89347894, grad/param norm = 1.8351e-01, time/batch = 15.8585s	
19917/33250 (epoch 29.950), train_loss = 0.89554960, grad/param norm = 1.6453e-01, time/batch = 15.7875s	
19918/33250 (epoch 29.952), train_loss = 0.86141967, grad/param norm = 2.0585e-01, time/batch = 15.7574s	
19919/33250 (epoch 29.953), train_loss = 0.88241216, grad/param norm = 1.7370e-01, time/batch = 15.7035s	
19920/33250 (epoch 29.955), train_loss = 0.91232799, grad/param norm = 1.7127e-01, time/batch = 15.8601s	
19921/33250 (epoch 29.956), train_loss = 0.85039709, grad/param norm = 1.9389e-01, time/batch = 15.5318s	
19922/33250 (epoch 29.958), train_loss = 0.76608542, grad/param norm = 1.3944e-01, time/batch = 15.8447s	
19923/33250 (epoch 29.959), train_loss = 0.78542898, grad/param norm = 1.5585e-01, time/batch = 15.6015s	
19924/33250 (epoch 29.961), train_loss = 1.05023706, grad/param norm = 1.8305e-01, time/batch = 16.0150s	
19925/33250 (epoch 29.962), train_loss = 0.82122479, grad/param norm = 1.5441e-01, time/batch = 15.6878s	
19926/33250 (epoch 29.964), train_loss = 0.98490420, grad/param norm = 1.9860e-01, time/batch = 15.7641s	
19927/33250 (epoch 29.965), train_loss = 0.89538714, grad/param norm = 1.6669e-01, time/batch = 15.8558s	
19928/33250 (epoch 29.967), train_loss = 0.85592212, grad/param norm = 1.5676e-01, time/batch = 15.8570s	
19929/33250 (epoch 29.968), train_loss = 0.98889827, grad/param norm = 1.7583e-01, time/batch = 15.7718s	
19930/33250 (epoch 29.970), train_loss = 1.10615633, grad/param norm = 2.3127e-01, time/batch = 15.7893s	
19931/33250 (epoch 29.971), train_loss = 1.01711557, grad/param norm = 1.9282e-01, time/batch = 15.8694s	
19932/33250 (epoch 29.973), train_loss = 0.83557037, grad/param norm = 1.7407e-01, time/batch = 15.7686s	
19933/33250 (epoch 29.974), train_loss = 0.92442008, grad/param norm = 1.8824e-01, time/batch = 15.7665s	
19934/33250 (epoch 29.976), train_loss = 0.81895223, grad/param norm = 1.7364e-01, time/batch = 15.7758s	
19935/33250 (epoch 29.977), train_loss = 0.81175489, grad/param norm = 1.7921e-01, time/batch = 15.6780s	
19936/33250 (epoch 29.979), train_loss = 0.88531147, grad/param norm = 1.9485e-01, time/batch = 15.7527s	
19937/33250 (epoch 29.980), train_loss = 0.88131429, grad/param norm = 1.7054e-01, time/batch = 15.8438s	
19938/33250 (epoch 29.982), train_loss = 0.78044524, grad/param norm = 1.4254e-01, time/batch = 15.7712s	
19939/33250 (epoch 29.983), train_loss = 0.88838423, grad/param norm = 2.1415e-01, time/batch = 15.9064s	
19940/33250 (epoch 29.985), train_loss = 0.80746378, grad/param norm = 1.6213e-01, time/batch = 15.8371s	
19941/33250 (epoch 29.986), train_loss = 0.91207068, grad/param norm = 1.6850e-01, time/batch = 16.0903s	
19942/33250 (epoch 29.988), train_loss = 0.94992117, grad/param norm = 1.6930e-01, time/batch = 15.6868s	
19943/33250 (epoch 29.989), train_loss = 0.93678021, grad/param norm = 1.7785e-01, time/batch = 15.3690s	
19944/33250 (epoch 29.991), train_loss = 0.87591488, grad/param norm = 1.5358e-01, time/batch = 15.2794s	
19945/33250 (epoch 29.992), train_loss = 0.81588866, grad/param norm = 1.6273e-01, time/batch = 15.6750s	
19946/33250 (epoch 29.994), train_loss = 0.83161591, grad/param norm = 1.5960e-01, time/batch = 15.5146s	
19947/33250 (epoch 29.995), train_loss = 0.81481173, grad/param norm = 1.8660e-01, time/batch = 15.6934s	
19948/33250 (epoch 29.997), train_loss = 0.63202251, grad/param norm = 1.5333e-01, time/batch = 15.8505s	
19949/33250 (epoch 29.998), train_loss = 0.88126551, grad/param norm = 1.6248e-01, time/batch = 15.8346s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
19950/33250 (epoch 30.000), train_loss = 0.87023540, grad/param norm = 1.5571e-01, time/batch = 15.6121s	
19951/33250 (epoch 30.002), train_loss = 1.04583018, grad/param norm = 1.7809e-01, time/batch = 15.7936s	
19952/33250 (epoch 30.003), train_loss = 0.93844663, grad/param norm = 1.6499e-01, time/batch = 13.6802s	
19953/33250 (epoch 30.005), train_loss = 0.70202578, grad/param norm = 1.4599e-01, time/batch = 0.6928s	
19954/33250 (epoch 30.006), train_loss = 0.73607838, grad/param norm = 1.4866e-01, time/batch = 0.6919s	
19955/33250 (epoch 30.008), train_loss = 0.94265873, grad/param norm = 1.6501e-01, time/batch = 0.6894s	
19956/33250 (epoch 30.009), train_loss = 1.00394286, grad/param norm = 1.8498e-01, time/batch = 0.6865s	
19957/33250 (epoch 30.011), train_loss = 0.79855863, grad/param norm = 1.5511e-01, time/batch = 0.6996s	
19958/33250 (epoch 30.012), train_loss = 0.83708704, grad/param norm = 1.9684e-01, time/batch = 0.7012s	
19959/33250 (epoch 30.014), train_loss = 0.94870712, grad/param norm = 1.8865e-01, time/batch = 0.7030s	
19960/33250 (epoch 30.015), train_loss = 0.85116492, grad/param norm = 1.6505e-01, time/batch = 1.0162s	
19961/33250 (epoch 30.017), train_loss = 0.88529017, grad/param norm = 1.9821e-01, time/batch = 1.0178s	
19962/33250 (epoch 30.018), train_loss = 0.70363610, grad/param norm = 1.6038e-01, time/batch = 1.0200s	
19963/33250 (epoch 30.020), train_loss = 0.86769024, grad/param norm = 1.5244e-01, time/batch = 1.0284s	
19964/33250 (epoch 30.021), train_loss = 0.89548512, grad/param norm = 1.6053e-01, time/batch = 1.1525s	
19965/33250 (epoch 30.023), train_loss = 0.71890429, grad/param norm = 1.7676e-01, time/batch = 1.9257s	
19966/33250 (epoch 30.024), train_loss = 0.94973535, grad/param norm = 1.7255e-01, time/batch = 1.9181s	
19967/33250 (epoch 30.026), train_loss = 0.87910316, grad/param norm = 1.6905e-01, time/batch = 9.5143s	
19968/33250 (epoch 30.027), train_loss = 0.89518034, grad/param norm = 1.6756e-01, time/batch = 15.5665s	
19969/33250 (epoch 30.029), train_loss = 0.83450772, grad/param norm = 1.7366e-01, time/batch = 15.7443s	
19970/33250 (epoch 30.030), train_loss = 0.84506332, grad/param norm = 1.8109e-01, time/batch = 15.8350s	
19971/33250 (epoch 30.032), train_loss = 1.03695526, grad/param norm = 1.8174e-01, time/batch = 16.1663s	
19972/33250 (epoch 30.033), train_loss = 0.82555262, grad/param norm = 1.9148e-01, time/batch = 15.6692s	
19973/33250 (epoch 30.035), train_loss = 0.86998503, grad/param norm = 1.9343e-01, time/batch = 15.7653s	
19974/33250 (epoch 30.036), train_loss = 0.92402783, grad/param norm = 1.8499e-01, time/batch = 15.7733s	
19975/33250 (epoch 30.038), train_loss = 0.84124711, grad/param norm = 1.3906e-01, time/batch = 15.7016s	
19976/33250 (epoch 30.039), train_loss = 0.79280121, grad/param norm = 1.6396e-01, time/batch = 15.7769s	
19977/33250 (epoch 30.041), train_loss = 0.86745896, grad/param norm = 1.8526e-01, time/batch = 15.9318s	
19978/33250 (epoch 30.042), train_loss = 0.71388080, grad/param norm = 1.4438e-01, time/batch = 15.8488s	
19979/33250 (epoch 30.044), train_loss = 0.94196225, grad/param norm = 1.6566e-01, time/batch = 15.8220s	
19980/33250 (epoch 30.045), train_loss = 0.94758141, grad/param norm = 1.7794e-01, time/batch = 15.7752s	
19981/33250 (epoch 30.047), train_loss = 0.84718916, grad/param norm = 1.6827e-01, time/batch = 16.1574s	
19982/33250 (epoch 30.048), train_loss = 0.97330271, grad/param norm = 2.1618e-01, time/batch = 15.4319s	
19983/33250 (epoch 30.050), train_loss = 0.86864084, grad/param norm = 1.6481e-01, time/batch = 15.7637s	
19984/33250 (epoch 30.051), train_loss = 0.84268236, grad/param norm = 1.6391e-01, time/batch = 15.7571s	
19985/33250 (epoch 30.053), train_loss = 0.88838863, grad/param norm = 1.9121e-01, time/batch = 15.5576s	
19986/33250 (epoch 30.054), train_loss = 0.73065414, grad/param norm = 1.5405e-01, time/batch = 15.9709s	
19987/33250 (epoch 30.056), train_loss = 0.77724528, grad/param norm = 1.5775e-01, time/batch = 15.8141s	
19988/33250 (epoch 30.057), train_loss = 0.95969844, grad/param norm = 1.6516e-01, time/batch = 16.0649s	
19989/33250 (epoch 30.059), train_loss = 0.81965118, grad/param norm = 1.6187e-01, time/batch = 16.0652s	
19990/33250 (epoch 30.060), train_loss = 0.85607006, grad/param norm = 1.7251e-01, time/batch = 15.9849s	
19991/33250 (epoch 30.062), train_loss = 0.95339389, grad/param norm = 1.6217e-01, time/batch = 15.9018s	
19992/33250 (epoch 30.063), train_loss = 0.99701696, grad/param norm = 1.6191e-01, time/batch = 15.7525s	
19993/33250 (epoch 30.065), train_loss = 0.85004097, grad/param norm = 1.5900e-01, time/batch = 15.5848s	
19994/33250 (epoch 30.066), train_loss = 0.89130067, grad/param norm = 1.7532e-01, time/batch = 15.5987s	
19995/33250 (epoch 30.068), train_loss = 0.80880106, grad/param norm = 1.6484e-01, time/batch = 15.5931s	
19996/33250 (epoch 30.069), train_loss = 0.86789394, grad/param norm = 1.6042e-01, time/batch = 15.6864s	
19997/33250 (epoch 30.071), train_loss = 0.78695748, grad/param norm = 1.4655e-01, time/batch = 15.5362s	
19998/33250 (epoch 30.072), train_loss = 0.79853575, grad/param norm = 1.6485e-01, time/batch = 15.6064s	
19999/33250 (epoch 30.074), train_loss = 0.88559105, grad/param norm = 1.6887e-01, time/batch = 16.0217s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch30.08_1.5708.t7	
20000/33250 (epoch 30.075), train_loss = 0.81348577, grad/param norm = 1.6779e-01, time/batch = 15.9959s	
20001/33250 (epoch 30.077), train_loss = 1.37342600, grad/param norm = 2.8946e-01, time/batch = 15.8640s	
20002/33250 (epoch 30.078), train_loss = 0.89003303, grad/param norm = 1.7352e-01, time/batch = 16.0856s	
20003/33250 (epoch 30.080), train_loss = 0.88303189, grad/param norm = 2.1931e-01, time/batch = 15.6920s	
20004/33250 (epoch 30.081), train_loss = 0.90162469, grad/param norm = 1.5811e-01, time/batch = 15.6121s	
20005/33250 (epoch 30.083), train_loss = 0.97775708, grad/param norm = 1.6720e-01, time/batch = 15.5973s	
20006/33250 (epoch 30.084), train_loss = 0.86635299, grad/param norm = 1.6011e-01, time/batch = 15.8484s	
20007/33250 (epoch 30.086), train_loss = 0.84602661, grad/param norm = 1.4032e-01, time/batch = 15.6845s	
20008/33250 (epoch 30.087), train_loss = 0.74671934, grad/param norm = 1.4062e-01, time/batch = 15.6860s	
20009/33250 (epoch 30.089), train_loss = 0.86634560, grad/param norm = 1.5295e-01, time/batch = 15.9458s	
20010/33250 (epoch 30.090), train_loss = 0.87841326, grad/param norm = 1.6228e-01, time/batch = 15.6283s	
20011/33250 (epoch 30.092), train_loss = 0.80904380, grad/param norm = 1.5549e-01, time/batch = 15.5371s	
20012/33250 (epoch 30.093), train_loss = 0.84404291, grad/param norm = 1.5916e-01, time/batch = 15.6917s	
20013/33250 (epoch 30.095), train_loss = 0.82850339, grad/param norm = 1.5634e-01, time/batch = 26.0529s	
20014/33250 (epoch 30.096), train_loss = 0.72373612, grad/param norm = 1.6470e-01, time/batch = 20.0176s	
20015/33250 (epoch 30.098), train_loss = 0.71902052, grad/param norm = 1.7063e-01, time/batch = 15.9326s	
20016/33250 (epoch 30.099), train_loss = 0.68138928, grad/param norm = 1.5455e-01, time/batch = 15.9972s	
20017/33250 (epoch 30.101), train_loss = 0.83037030, grad/param norm = 1.5599e-01, time/batch = 15.6108s	
20018/33250 (epoch 30.102), train_loss = 0.77871967, grad/param norm = 1.4386e-01, time/batch = 15.7663s	
20019/33250 (epoch 30.104), train_loss = 0.64971424, grad/param norm = 1.3777e-01, time/batch = 15.9372s	
20020/33250 (epoch 30.105), train_loss = 0.79215012, grad/param norm = 1.6919e-01, time/batch = 15.9818s	
20021/33250 (epoch 30.107), train_loss = 0.72110666, grad/param norm = 1.2992e-01, time/batch = 16.0221s	
20022/33250 (epoch 30.108), train_loss = 0.84301418, grad/param norm = 1.7734e-01, time/batch = 15.8506s	
20023/33250 (epoch 30.110), train_loss = 0.71441835, grad/param norm = 1.4709e-01, time/batch = 15.8470s	
20024/33250 (epoch 30.111), train_loss = 0.82191403, grad/param norm = 1.5347e-01, time/batch = 15.7587s	
20025/33250 (epoch 30.113), train_loss = 0.79224961, grad/param norm = 1.6141e-01, time/batch = 15.8464s	
20026/33250 (epoch 30.114), train_loss = 0.72435327, grad/param norm = 1.6585e-01, time/batch = 15.7723s	
20027/33250 (epoch 30.116), train_loss = 0.78740142, grad/param norm = 1.6560e-01, time/batch = 15.6797s	
20028/33250 (epoch 30.117), train_loss = 0.80595985, grad/param norm = 1.7899e-01, time/batch = 15.7717s	
20029/33250 (epoch 30.119), train_loss = 0.80252029, grad/param norm = 1.7850e-01, time/batch = 15.8543s	
20030/33250 (epoch 30.120), train_loss = 0.64336898, grad/param norm = 1.2295e-01, time/batch = 15.6295s	
20031/33250 (epoch 30.122), train_loss = 0.91453943, grad/param norm = 1.5976e-01, time/batch = 15.9271s	
20032/33250 (epoch 30.123), train_loss = 0.81170950, grad/param norm = 1.5867e-01, time/batch = 15.8303s	
20033/33250 (epoch 30.125), train_loss = 0.67396529, grad/param norm = 1.6289e-01, time/batch = 15.8311s	
20034/33250 (epoch 30.126), train_loss = 0.81717064, grad/param norm = 1.6176e-01, time/batch = 15.6116s	
20035/33250 (epoch 30.128), train_loss = 0.78652849, grad/param norm = 1.4306e-01, time/batch = 15.7653s	
20036/33250 (epoch 30.129), train_loss = 0.83617912, grad/param norm = 1.7305e-01, time/batch = 15.5295s	
20037/33250 (epoch 30.131), train_loss = 0.83106632, grad/param norm = 1.6484e-01, time/batch = 15.7584s	
20038/33250 (epoch 30.132), train_loss = 0.79301745, grad/param norm = 1.6419e-01, time/batch = 15.5204s	
20039/33250 (epoch 30.134), train_loss = 0.79827397, grad/param norm = 1.7424e-01, time/batch = 15.8575s	
20040/33250 (epoch 30.135), train_loss = 0.83162653, grad/param norm = 1.5114e-01, time/batch = 15.6272s	
20041/33250 (epoch 30.137), train_loss = 0.75507745, grad/param norm = 1.8498e-01, time/batch = 15.9361s	
20042/33250 (epoch 30.138), train_loss = 0.74845390, grad/param norm = 1.3377e-01, time/batch = 15.7595s	
20043/33250 (epoch 30.140), train_loss = 0.65667358, grad/param norm = 1.5179e-01, time/batch = 15.6157s	
20044/33250 (epoch 30.141), train_loss = 0.91625263, grad/param norm = 2.1574e-01, time/batch = 15.6976s	
20045/33250 (epoch 30.143), train_loss = 0.67604213, grad/param norm = 1.6616e-01, time/batch = 15.9836s	
20046/33250 (epoch 30.144), train_loss = 0.81009422, grad/param norm = 1.6327e-01, time/batch = 15.9081s	
20047/33250 (epoch 30.146), train_loss = 0.79311340, grad/param norm = 1.5415e-01, time/batch = 15.5251s	
20048/33250 (epoch 30.147), train_loss = 0.82106133, grad/param norm = 1.7135e-01, time/batch = 15.6845s	
20049/33250 (epoch 30.149), train_loss = 0.76360920, grad/param norm = 1.5942e-01, time/batch = 15.5921s	
20050/33250 (epoch 30.150), train_loss = 0.73464706, grad/param norm = 1.6874e-01, time/batch = 15.6025s	
20051/33250 (epoch 30.152), train_loss = 0.70934667, grad/param norm = 1.5101e-01, time/batch = 15.9334s	
20052/33250 (epoch 30.153), train_loss = 0.97644970, grad/param norm = 1.9155e-01, time/batch = 15.6958s	
20053/33250 (epoch 30.155), train_loss = 0.78922432, grad/param norm = 1.7519e-01, time/batch = 15.3648s	
20054/33250 (epoch 30.156), train_loss = 1.00935139, grad/param norm = 1.6162e-01, time/batch = 15.9986s	
20055/33250 (epoch 30.158), train_loss = 0.97005390, grad/param norm = 1.8044e-01, time/batch = 15.7608s	
20056/33250 (epoch 30.159), train_loss = 0.79285265, grad/param norm = 1.8487e-01, time/batch = 15.7585s	
20057/33250 (epoch 30.161), train_loss = 0.86643551, grad/param norm = 1.7825e-01, time/batch = 15.7633s	
20058/33250 (epoch 30.162), train_loss = 0.74862309, grad/param norm = 1.5975e-01, time/batch = 15.6845s	
20059/33250 (epoch 30.164), train_loss = 0.80340220, grad/param norm = 1.7555e-01, time/batch = 15.6867s	
20060/33250 (epoch 30.165), train_loss = 0.89078797, grad/param norm = 1.7872e-01, time/batch = 15.5248s	
20061/33250 (epoch 30.167), train_loss = 0.96664558, grad/param norm = 1.8510e-01, time/batch = 16.0019s	
20062/33250 (epoch 30.168), train_loss = 0.70907797, grad/param norm = 1.5473e-01, time/batch = 15.6738s	
20063/33250 (epoch 30.170), train_loss = 0.78989407, grad/param norm = 1.9587e-01, time/batch = 15.6296s	
20064/33250 (epoch 30.171), train_loss = 0.84133992, grad/param norm = 1.6252e-01, time/batch = 15.6918s	
20065/33250 (epoch 30.173), train_loss = 0.80279187, grad/param norm = 1.5011e-01, time/batch = 15.6806s	
20066/33250 (epoch 30.174), train_loss = 0.83409984, grad/param norm = 1.4725e-01, time/batch = 15.7708s	
20067/33250 (epoch 30.176), train_loss = 0.77527420, grad/param norm = 1.4961e-01, time/batch = 15.6779s	
20068/33250 (epoch 30.177), train_loss = 0.77301769, grad/param norm = 1.5313e-01, time/batch = 15.5131s	
20069/33250 (epoch 30.179), train_loss = 0.76916322, grad/param norm = 1.6193e-01, time/batch = 15.8294s	
20070/33250 (epoch 30.180), train_loss = 0.66526570, grad/param norm = 1.3570e-01, time/batch = 15.3407s	
20071/33250 (epoch 30.182), train_loss = 0.76759293, grad/param norm = 1.8082e-01, time/batch = 15.8521s	
20072/33250 (epoch 30.183), train_loss = 0.93367122, grad/param norm = 1.8946e-01, time/batch = 15.7832s	
20073/33250 (epoch 30.185), train_loss = 0.86157212, grad/param norm = 1.8477e-01, time/batch = 15.8613s	
20074/33250 (epoch 30.186), train_loss = 0.87710334, grad/param norm = 1.8165e-01, time/batch = 15.8504s	
20075/33250 (epoch 30.188), train_loss = 0.92366028, grad/param norm = 1.9314e-01, time/batch = 15.7467s	
20076/33250 (epoch 30.189), train_loss = 0.68080114, grad/param norm = 2.0169e-01, time/batch = 15.6892s	
20077/33250 (epoch 30.191), train_loss = 0.77162571, grad/param norm = 1.7695e-01, time/batch = 15.8560s	
20078/33250 (epoch 30.192), train_loss = 0.81058074, grad/param norm = 1.6424e-01, time/batch = 15.7600s	
20079/33250 (epoch 30.194), train_loss = 0.81134835, grad/param norm = 1.7583e-01, time/batch = 15.6140s	
20080/33250 (epoch 30.195), train_loss = 1.00368694, grad/param norm = 1.7572e-01, time/batch = 15.7480s	
20081/33250 (epoch 30.197), train_loss = 0.77229272, grad/param norm = 1.7372e-01, time/batch = 15.5184s	
20082/33250 (epoch 30.198), train_loss = 0.99813630, grad/param norm = 1.9593e-01, time/batch = 15.5348s	
20083/33250 (epoch 30.200), train_loss = 0.83733885, grad/param norm = 1.5594e-01, time/batch = 15.6120s	
20084/33250 (epoch 30.202), train_loss = 0.77503135, grad/param norm = 1.4412e-01, time/batch = 15.5988s	
20085/33250 (epoch 30.203), train_loss = 0.77853483, grad/param norm = 1.8845e-01, time/batch = 15.6220s	
20086/33250 (epoch 30.205), train_loss = 0.87112254, grad/param norm = 1.5839e-01, time/batch = 15.3627s	
20087/33250 (epoch 30.206), train_loss = 0.89539471, grad/param norm = 1.7705e-01, time/batch = 15.6100s	
20088/33250 (epoch 30.208), train_loss = 0.93395837, grad/param norm = 1.7650e-01, time/batch = 15.8267s	
20089/33250 (epoch 30.209), train_loss = 0.76498162, grad/param norm = 1.5860e-01, time/batch = 15.5063s	
20090/33250 (epoch 30.211), train_loss = 0.88226505, grad/param norm = 2.0238e-01, time/batch = 15.5163s	
20091/33250 (epoch 30.212), train_loss = 0.98505037, grad/param norm = 1.7538e-01, time/batch = 15.6981s	
20092/33250 (epoch 30.214), train_loss = 0.83999745, grad/param norm = 1.6208e-01, time/batch = 15.7560s	
20093/33250 (epoch 30.215), train_loss = 0.97583762, grad/param norm = 2.6347e-01, time/batch = 15.6176s	
20094/33250 (epoch 30.217), train_loss = 0.93245847, grad/param norm = 1.9852e-01, time/batch = 15.8491s	
20095/33250 (epoch 30.218), train_loss = 0.92315712, grad/param norm = 1.5678e-01, time/batch = 15.5366s	
20096/33250 (epoch 30.220), train_loss = 0.87338649, grad/param norm = 1.9708e-01, time/batch = 15.9199s	
20097/33250 (epoch 30.221), train_loss = 1.00355123, grad/param norm = 2.2017e-01, time/batch = 15.6040s	
20098/33250 (epoch 30.223), train_loss = 0.84606465, grad/param norm = 1.5135e-01, time/batch = 15.5827s	
20099/33250 (epoch 30.224), train_loss = 0.90156715, grad/param norm = 1.8147e-01, time/batch = 15.6806s	
20100/33250 (epoch 30.226), train_loss = 0.97954030, grad/param norm = 1.8913e-01, time/batch = 15.7490s	
20101/33250 (epoch 30.227), train_loss = 0.87972230, grad/param norm = 1.7027e-01, time/batch = 15.5314s	
20102/33250 (epoch 30.229), train_loss = 0.83880414, grad/param norm = 1.5800e-01, time/batch = 15.6015s	
20103/33250 (epoch 30.230), train_loss = 0.86356876, grad/param norm = 1.8536e-01, time/batch = 15.5954s	
20104/33250 (epoch 30.232), train_loss = 0.78723968, grad/param norm = 1.5031e-01, time/batch = 15.6999s	
20105/33250 (epoch 30.233), train_loss = 0.77231160, grad/param norm = 1.7554e-01, time/batch = 15.4482s	
20106/33250 (epoch 30.235), train_loss = 0.96136370, grad/param norm = 1.6496e-01, time/batch = 15.3763s	
20107/33250 (epoch 30.236), train_loss = 0.79024507, grad/param norm = 1.7892e-01, time/batch = 15.7597s	
20108/33250 (epoch 30.238), train_loss = 0.92184422, grad/param norm = 1.6820e-01, time/batch = 15.7619s	
20109/33250 (epoch 30.239), train_loss = 0.94776202, grad/param norm = 1.9857e-01, time/batch = 15.5208s	
20110/33250 (epoch 30.241), train_loss = 0.96429023, grad/param norm = 1.9663e-01, time/batch = 15.4373s	
20111/33250 (epoch 30.242), train_loss = 0.95603937, grad/param norm = 1.8349e-01, time/batch = 15.9259s	
20112/33250 (epoch 30.244), train_loss = 0.90241826, grad/param norm = 2.0140e-01, time/batch = 15.6075s	
20113/33250 (epoch 30.245), train_loss = 0.87162381, grad/param norm = 1.8323e-01, time/batch = 15.6818s	
20114/33250 (epoch 30.247), train_loss = 0.85229848, grad/param norm = 1.7045e-01, time/batch = 15.4291s	
20115/33250 (epoch 30.248), train_loss = 1.01194628, grad/param norm = 1.8987e-01, time/batch = 15.6789s	
20116/33250 (epoch 30.250), train_loss = 0.94335255, grad/param norm = 1.5708e-01, time/batch = 15.5309s	
20117/33250 (epoch 30.251), train_loss = 0.82749648, grad/param norm = 1.5209e-01, time/batch = 15.7806s	
20118/33250 (epoch 30.253), train_loss = 0.80483245, grad/param norm = 1.4669e-01, time/batch = 15.8399s	
20119/33250 (epoch 30.254), train_loss = 0.79772136, grad/param norm = 1.6771e-01, time/batch = 15.5987s	
20120/33250 (epoch 30.256), train_loss = 0.85538882, grad/param norm = 1.7890e-01, time/batch = 15.5177s	
20121/33250 (epoch 30.257), train_loss = 0.99527432, grad/param norm = 2.0715e-01, time/batch = 15.9082s	
20122/33250 (epoch 30.259), train_loss = 0.89703089, grad/param norm = 1.7289e-01, time/batch = 15.6710s	
20123/33250 (epoch 30.260), train_loss = 0.71120369, grad/param norm = 1.5036e-01, time/batch = 15.6127s	
20124/33250 (epoch 30.262), train_loss = 0.86764083, grad/param norm = 1.6137e-01, time/batch = 15.6044s	
20125/33250 (epoch 30.263), train_loss = 0.73282160, grad/param norm = 1.7319e-01, time/batch = 15.8480s	
20126/33250 (epoch 30.265), train_loss = 0.90189050, grad/param norm = 1.7357e-01, time/batch = 15.8389s	
20127/33250 (epoch 30.266), train_loss = 0.82775999, grad/param norm = 1.6634e-01, time/batch = 15.8508s	
20128/33250 (epoch 30.268), train_loss = 0.76223437, grad/param norm = 1.7544e-01, time/batch = 15.6802s	
20129/33250 (epoch 30.269), train_loss = 0.71507445, grad/param norm = 1.6120e-01, time/batch = 15.9245s	
20130/33250 (epoch 30.271), train_loss = 0.85008546, grad/param norm = 1.6294e-01, time/batch = 15.9257s	
20131/33250 (epoch 30.272), train_loss = 0.76221131, grad/param norm = 1.4399e-01, time/batch = 15.6861s	
20132/33250 (epoch 30.274), train_loss = 0.64492814, grad/param norm = 1.4425e-01, time/batch = 15.6655s	
20133/33250 (epoch 30.275), train_loss = 0.78083325, grad/param norm = 1.4068e-01, time/batch = 15.8559s	
20134/33250 (epoch 30.277), train_loss = 0.66126306, grad/param norm = 1.5947e-01, time/batch = 15.7722s	
20135/33250 (epoch 30.278), train_loss = 0.78224173, grad/param norm = 1.7173e-01, time/batch = 15.8344s	
20136/33250 (epoch 30.280), train_loss = 0.73264795, grad/param norm = 1.5263e-01, time/batch = 15.8640s	
20137/33250 (epoch 30.281), train_loss = 0.87076691, grad/param norm = 1.8273e-01, time/batch = 15.9473s	
20138/33250 (epoch 30.283), train_loss = 0.88130125, grad/param norm = 2.4279e-01, time/batch = 15.7947s	
20139/33250 (epoch 30.284), train_loss = 0.74673505, grad/param norm = 1.8243e-01, time/batch = 15.8726s	
20140/33250 (epoch 30.286), train_loss = 0.87097898, grad/param norm = 1.7967e-01, time/batch = 15.9207s	
20141/33250 (epoch 30.287), train_loss = 0.71221235, grad/param norm = 1.4282e-01, time/batch = 16.1454s	
20142/33250 (epoch 30.289), train_loss = 0.67121668, grad/param norm = 1.6056e-01, time/batch = 15.8956s	
20143/33250 (epoch 30.290), train_loss = 0.83733434, grad/param norm = 1.5841e-01, time/batch = 15.5921s	
20144/33250 (epoch 30.292), train_loss = 0.91758215, grad/param norm = 2.2173e-01, time/batch = 15.6055s	
20145/33250 (epoch 30.293), train_loss = 0.95380910, grad/param norm = 1.8316e-01, time/batch = 15.9054s	
20146/33250 (epoch 30.295), train_loss = 0.91866408, grad/param norm = 1.6331e-01, time/batch = 15.4561s	
20147/33250 (epoch 30.296), train_loss = 0.84968686, grad/param norm = 1.6358e-01, time/batch = 15.7791s	
20148/33250 (epoch 30.298), train_loss = 0.71228868, grad/param norm = 1.7292e-01, time/batch = 15.6086s	
20149/33250 (epoch 30.299), train_loss = 0.67348884, grad/param norm = 1.4303e-01, time/batch = 15.5893s	
20150/33250 (epoch 30.301), train_loss = 0.93660938, grad/param norm = 1.7445e-01, time/batch = 15.7456s	
20151/33250 (epoch 30.302), train_loss = 0.87422173, grad/param norm = 1.6019e-01, time/batch = 15.8365s	
20152/33250 (epoch 30.304), train_loss = 0.77772163, grad/param norm = 1.7090e-01, time/batch = 15.6045s	
20153/33250 (epoch 30.305), train_loss = 0.79003260, grad/param norm = 1.6000e-01, time/batch = 15.7569s	
20154/33250 (epoch 30.307), train_loss = 0.90581796, grad/param norm = 1.9468e-01, time/batch = 15.6787s	
20155/33250 (epoch 30.308), train_loss = 0.96267079, grad/param norm = 2.1271e-01, time/batch = 15.7716s	
20156/33250 (epoch 30.310), train_loss = 0.80588519, grad/param norm = 1.9086e-01, time/batch = 15.6834s	
20157/33250 (epoch 30.311), train_loss = 0.97175963, grad/param norm = 1.8503e-01, time/batch = 15.7628s	
20158/33250 (epoch 30.313), train_loss = 0.71464131, grad/param norm = 1.7318e-01, time/batch = 15.5483s	
20159/33250 (epoch 30.314), train_loss = 0.84374133, grad/param norm = 1.4260e-01, time/batch = 15.6282s	
20160/33250 (epoch 30.316), train_loss = 1.00588459, grad/param norm = 1.9856e-01, time/batch = 15.8597s	
20161/33250 (epoch 30.317), train_loss = 0.75224944, grad/param norm = 1.5106e-01, time/batch = 15.7681s	
20162/33250 (epoch 30.319), train_loss = 0.91259863, grad/param norm = 2.0429e-01, time/batch = 15.6821s	
20163/33250 (epoch 30.320), train_loss = 0.89764320, grad/param norm = 1.8976e-01, time/batch = 15.6851s	
20164/33250 (epoch 30.322), train_loss = 0.98864331, grad/param norm = 2.0137e-01, time/batch = 15.7514s	
20165/33250 (epoch 30.323), train_loss = 1.01014025, grad/param norm = 2.5346e-01, time/batch = 15.5178s	
20166/33250 (epoch 30.325), train_loss = 0.82666005, grad/param norm = 1.8159e-01, time/batch = 15.9292s	
20167/33250 (epoch 30.326), train_loss = 1.02665560, grad/param norm = 1.8839e-01, time/batch = 15.7025s	
20168/33250 (epoch 30.328), train_loss = 0.82549564, grad/param norm = 1.6532e-01, time/batch = 15.8713s	
20169/33250 (epoch 30.329), train_loss = 0.85798962, grad/param norm = 2.1481e-01, time/batch = 15.6263s	
20170/33250 (epoch 30.331), train_loss = 0.84461478, grad/param norm = 1.8983e-01, time/batch = 15.7717s	
20171/33250 (epoch 30.332), train_loss = 0.84352463, grad/param norm = 1.5570e-01, time/batch = 15.4246s	
20172/33250 (epoch 30.334), train_loss = 0.99649516, grad/param norm = 1.7992e-01, time/batch = 15.7636s	
20173/33250 (epoch 30.335), train_loss = 0.62933752, grad/param norm = 1.5958e-01, time/batch = 15.7629s	
20174/33250 (epoch 30.337), train_loss = 0.91070874, grad/param norm = 1.7631e-01, time/batch = 15.8458s	
20175/33250 (epoch 30.338), train_loss = 0.97354939, grad/param norm = 1.8104e-01, time/batch = 15.7595s	
20176/33250 (epoch 30.340), train_loss = 0.83793579, grad/param norm = 1.5630e-01, time/batch = 15.7661s	
20177/33250 (epoch 30.341), train_loss = 0.80989691, grad/param norm = 1.7004e-01, time/batch = 15.6976s	
20178/33250 (epoch 30.343), train_loss = 0.80096982, grad/param norm = 1.5514e-01, time/batch = 15.6378s	
20179/33250 (epoch 30.344), train_loss = 0.82422410, grad/param norm = 1.4830e-01, time/batch = 15.8333s	
20180/33250 (epoch 30.346), train_loss = 0.75005027, grad/param norm = 1.5569e-01, time/batch = 15.7517s	
20181/33250 (epoch 30.347), train_loss = 1.03670620, grad/param norm = 2.1834e-01, time/batch = 15.7708s	
20182/33250 (epoch 30.349), train_loss = 0.79890317, grad/param norm = 1.7827e-01, time/batch = 15.4273s	
20183/33250 (epoch 30.350), train_loss = 0.83278956, grad/param norm = 1.6507e-01, time/batch = 15.8066s	
20184/33250 (epoch 30.352), train_loss = 0.76173349, grad/param norm = 1.5893e-01, time/batch = 15.7264s	
20185/33250 (epoch 30.353), train_loss = 0.81465662, grad/param norm = 1.6242e-01, time/batch = 15.6759s	
20186/33250 (epoch 30.355), train_loss = 0.81669745, grad/param norm = 1.9331e-01, time/batch = 16.0828s	
20187/33250 (epoch 30.356), train_loss = 0.76256565, grad/param norm = 1.9125e-01, time/batch = 16.0118s	
20188/33250 (epoch 30.358), train_loss = 0.81034654, grad/param norm = 1.4275e-01, time/batch = 16.0929s	
20189/33250 (epoch 30.359), train_loss = 0.80104433, grad/param norm = 1.6914e-01, time/batch = 15.8389s	
20190/33250 (epoch 30.361), train_loss = 0.96875102, grad/param norm = 1.9826e-01, time/batch = 15.7922s	
20191/33250 (epoch 30.362), train_loss = 0.86776476, grad/param norm = 1.8471e-01, time/batch = 16.0123s	
20192/33250 (epoch 30.364), train_loss = 0.90812430, grad/param norm = 2.0193e-01, time/batch = 15.7566s	
20193/33250 (epoch 30.365), train_loss = 0.85584850, grad/param norm = 1.7565e-01, time/batch = 15.7513s	
20194/33250 (epoch 30.367), train_loss = 0.86082092, grad/param norm = 1.5952e-01, time/batch = 15.8240s	
20195/33250 (epoch 30.368), train_loss = 0.82601051, grad/param norm = 1.6241e-01, time/batch = 15.7661s	
20196/33250 (epoch 30.370), train_loss = 0.75654495, grad/param norm = 1.4786e-01, time/batch = 15.6050s	
20197/33250 (epoch 30.371), train_loss = 0.94677306, grad/param norm = 1.7327e-01, time/batch = 15.6037s	
20198/33250 (epoch 30.373), train_loss = 0.80210025, grad/param norm = 1.5415e-01, time/batch = 16.0689s	
20199/33250 (epoch 30.374), train_loss = 0.85526736, grad/param norm = 2.2395e-01, time/batch = 15.5464s	
20200/33250 (epoch 30.376), train_loss = 0.82536446, grad/param norm = 1.5943e-01, time/batch = 15.7099s	
20201/33250 (epoch 30.377), train_loss = 0.73676109, grad/param norm = 2.0870e-01, time/batch = 15.6161s	
20202/33250 (epoch 30.379), train_loss = 0.83125903, grad/param norm = 1.7061e-01, time/batch = 15.9890s	
20203/33250 (epoch 30.380), train_loss = 0.86320110, grad/param norm = 2.0314e-01, time/batch = 15.6151s	
20204/33250 (epoch 30.382), train_loss = 0.88168196, grad/param norm = 1.9245e-01, time/batch = 15.3532s	
20205/33250 (epoch 30.383), train_loss = 0.75565246, grad/param norm = 1.6669e-01, time/batch = 15.6148s	
20206/33250 (epoch 30.385), train_loss = 0.71579107, grad/param norm = 1.6102e-01, time/batch = 15.5114s	
20207/33250 (epoch 30.386), train_loss = 0.74327563, grad/param norm = 1.7864e-01, time/batch = 15.4378s	
20208/33250 (epoch 30.388), train_loss = 0.75187506, grad/param norm = 1.4903e-01, time/batch = 15.7453s	
20209/33250 (epoch 30.389), train_loss = 0.81604432, grad/param norm = 1.8521e-01, time/batch = 15.6797s	
20210/33250 (epoch 30.391), train_loss = 0.90586978, grad/param norm = 1.9887e-01, time/batch = 15.8522s	
20211/33250 (epoch 30.392), train_loss = 0.92977981, grad/param norm = 2.0007e-01, time/batch = 15.7768s	
20212/33250 (epoch 30.394), train_loss = 0.94485885, grad/param norm = 2.1154e-01, time/batch = 15.7676s	
20213/33250 (epoch 30.395), train_loss = 0.91521227, grad/param norm = 1.5777e-01, time/batch = 15.6791s	
20214/33250 (epoch 30.397), train_loss = 0.95005595, grad/param norm = 1.6036e-01, time/batch = 15.6853s	
20215/33250 (epoch 30.398), train_loss = 0.76994542, grad/param norm = 1.6677e-01, time/batch = 15.4293s	
20216/33250 (epoch 30.400), train_loss = 0.73999919, grad/param norm = 1.4004e-01, time/batch = 15.2706s	
20217/33250 (epoch 30.402), train_loss = 0.72644722, grad/param norm = 1.8754e-01, time/batch = 15.6884s	
20218/33250 (epoch 30.403), train_loss = 0.83819815, grad/param norm = 2.0986e-01, time/batch = 15.6632s	
20219/33250 (epoch 30.405), train_loss = 0.77526465, grad/param norm = 1.4483e-01, time/batch = 15.5252s	
20220/33250 (epoch 30.406), train_loss = 0.81588194, grad/param norm = 1.8362e-01, time/batch = 15.6236s	
20221/33250 (epoch 30.408), train_loss = 1.00777225, grad/param norm = 1.8194e-01, time/batch = 16.0904s	
20222/33250 (epoch 30.409), train_loss = 0.88950067, grad/param norm = 2.1276e-01, time/batch = 15.6265s	
20223/33250 (epoch 30.411), train_loss = 0.62316408, grad/param norm = 1.3057e-01, time/batch = 15.6391s	
20224/33250 (epoch 30.412), train_loss = 0.69549736, grad/param norm = 1.5239e-01, time/batch = 15.6134s	
20225/33250 (epoch 30.414), train_loss = 0.87216557, grad/param norm = 1.6304e-01, time/batch = 15.7613s	
20226/33250 (epoch 30.415), train_loss = 0.91495332, grad/param norm = 1.7890e-01, time/batch = 15.6897s	
20227/33250 (epoch 30.417), train_loss = 0.93700075, grad/param norm = 1.7122e-01, time/batch = 15.5946s	
20228/33250 (epoch 30.418), train_loss = 1.08463207, grad/param norm = 2.0215e-01, time/batch = 15.2757s	
20229/33250 (epoch 30.420), train_loss = 0.94116398, grad/param norm = 1.8531e-01, time/batch = 15.7429s	
20230/33250 (epoch 30.421), train_loss = 0.78151399, grad/param norm = 1.5302e-01, time/batch = 15.4342s	
20231/33250 (epoch 30.423), train_loss = 0.88492270, grad/param norm = 1.8893e-01, time/batch = 15.7020s	
20232/33250 (epoch 30.424), train_loss = 0.97668151, grad/param norm = 2.3355e-01, time/batch = 15.7801s	
20233/33250 (epoch 30.426), train_loss = 0.82436711, grad/param norm = 1.5388e-01, time/batch = 15.7078s	
20234/33250 (epoch 30.427), train_loss = 0.78170553, grad/param norm = 1.9518e-01, time/batch = 15.6182s	
20235/33250 (epoch 30.429), train_loss = 0.88576602, grad/param norm = 1.9343e-01, time/batch = 15.6119s	
20236/33250 (epoch 30.430), train_loss = 0.79427240, grad/param norm = 1.8580e-01, time/batch = 15.6080s	
20237/33250 (epoch 30.432), train_loss = 0.90084570, grad/param norm = 1.8004e-01, time/batch = 15.6024s	
20238/33250 (epoch 30.433), train_loss = 0.77823864, grad/param norm = 1.8384e-01, time/batch = 15.7708s	
20239/33250 (epoch 30.435), train_loss = 0.92451337, grad/param norm = 1.8754e-01, time/batch = 15.5050s	
20240/33250 (epoch 30.436), train_loss = 0.78489654, grad/param norm = 1.7084e-01, time/batch = 29.2883s	
20241/33250 (epoch 30.438), train_loss = 0.94242602, grad/param norm = 1.7582e-01, time/batch = 15.6243s	
20242/33250 (epoch 30.439), train_loss = 0.85084127, grad/param norm = 1.4931e-01, time/batch = 15.7014s	
20243/33250 (epoch 30.441), train_loss = 0.82459203, grad/param norm = 1.7552e-01, time/batch = 15.8509s	
20244/33250 (epoch 30.442), train_loss = 0.76824670, grad/param norm = 1.6847e-01, time/batch = 15.7003s	
20245/33250 (epoch 30.444), train_loss = 0.80323402, grad/param norm = 1.4734e-01, time/batch = 15.8347s	
20246/33250 (epoch 30.445), train_loss = 0.84506041, grad/param norm = 1.4421e-01, time/batch = 15.6735s	
20247/33250 (epoch 30.447), train_loss = 0.76988121, grad/param norm = 1.5776e-01, time/batch = 15.6933s	
20248/33250 (epoch 30.448), train_loss = 0.86502975, grad/param norm = 1.5926e-01, time/batch = 15.5785s	
20249/33250 (epoch 30.450), train_loss = 0.96622162, grad/param norm = 1.8795e-01, time/batch = 15.7286s	
20250/33250 (epoch 30.451), train_loss = 0.91223423, grad/param norm = 2.1688e-01, time/batch = 15.6698s	
20251/33250 (epoch 30.453), train_loss = 0.75860735, grad/param norm = 1.4098e-01, time/batch = 16.0307s	
20252/33250 (epoch 30.454), train_loss = 0.98479521, grad/param norm = 1.7735e-01, time/batch = 15.7109s	
20253/33250 (epoch 30.456), train_loss = 0.95994201, grad/param norm = 1.4441e-01, time/batch = 15.8546s	
20254/33250 (epoch 30.457), train_loss = 0.80061220, grad/param norm = 1.9451e-01, time/batch = 16.0055s	
20255/33250 (epoch 30.459), train_loss = 0.91383308, grad/param norm = 1.5730e-01, time/batch = 15.5242s	
20256/33250 (epoch 30.460), train_loss = 0.91994158, grad/param norm = 1.8912e-01, time/batch = 16.0029s	
20257/33250 (epoch 30.462), train_loss = 0.82964532, grad/param norm = 1.5792e-01, time/batch = 15.7780s	
20258/33250 (epoch 30.463), train_loss = 0.77054936, grad/param norm = 1.3718e-01, time/batch = 16.0799s	
20259/33250 (epoch 30.465), train_loss = 0.70672029, grad/param norm = 1.3993e-01, time/batch = 15.6880s	
20260/33250 (epoch 30.466), train_loss = 0.67595630, grad/param norm = 1.2631e-01, time/batch = 15.8468s	
20261/33250 (epoch 30.468), train_loss = 0.72986635, grad/param norm = 1.3551e-01, time/batch = 16.1677s	
20262/33250 (epoch 30.469), train_loss = 0.80096070, grad/param norm = 1.5075e-01, time/batch = 15.6342s	
20263/33250 (epoch 30.471), train_loss = 0.91138969, grad/param norm = 1.5916e-01, time/batch = 15.6914s	
20264/33250 (epoch 30.472), train_loss = 0.78896435, grad/param norm = 1.7004e-01, time/batch = 15.9388s	
20265/33250 (epoch 30.474), train_loss = 0.95219153, grad/param norm = 1.7707e-01, time/batch = 15.7743s	
20266/33250 (epoch 30.475), train_loss = 0.85960848, grad/param norm = 1.4748e-01, time/batch = 15.3757s	
20267/33250 (epoch 30.477), train_loss = 0.84242975, grad/param norm = 1.4651e-01, time/batch = 15.6802s	
20268/33250 (epoch 30.478), train_loss = 0.77019344, grad/param norm = 1.7284e-01, time/batch = 15.6159s	
20269/33250 (epoch 30.480), train_loss = 0.97479248, grad/param norm = 1.7922e-01, time/batch = 15.6729s	
20270/33250 (epoch 30.481), train_loss = 0.82802383, grad/param norm = 1.4306e-01, time/batch = 15.6138s	
20271/33250 (epoch 30.483), train_loss = 0.81576399, grad/param norm = 1.5266e-01, time/batch = 15.6807s	
20272/33250 (epoch 30.484), train_loss = 0.75721413, grad/param norm = 1.4449e-01, time/batch = 15.6822s	
20273/33250 (epoch 30.486), train_loss = 0.72354246, grad/param norm = 1.7346e-01, time/batch = 15.6801s	
20274/33250 (epoch 30.487), train_loss = 0.79613636, grad/param norm = 1.5426e-01, time/batch = 15.5530s	
20275/33250 (epoch 30.489), train_loss = 0.93994553, grad/param norm = 1.9524e-01, time/batch = 15.7652s	
20276/33250 (epoch 30.490), train_loss = 0.89140319, grad/param norm = 1.9344e-01, time/batch = 15.7716s	
20277/33250 (epoch 30.492), train_loss = 0.93231820, grad/param norm = 1.8822e-01, time/batch = 15.8335s	
20278/33250 (epoch 30.493), train_loss = 0.84855943, grad/param norm = 1.7938e-01, time/batch = 16.0970s	
20279/33250 (epoch 30.495), train_loss = 0.89690959, grad/param norm = 1.4976e-01, time/batch = 15.7666s	
20280/33250 (epoch 30.496), train_loss = 0.85940234, grad/param norm = 1.4066e-01, time/batch = 15.6119s	
20281/33250 (epoch 30.498), train_loss = 0.92683627, grad/param norm = 1.6496e-01, time/batch = 15.9398s	
20282/33250 (epoch 30.499), train_loss = 0.79565439, grad/param norm = 1.4779e-01, time/batch = 15.9780s	
20283/33250 (epoch 30.501), train_loss = 0.79105985, grad/param norm = 1.6962e-01, time/batch = 15.9830s	
20284/33250 (epoch 30.502), train_loss = 0.79024026, grad/param norm = 1.4318e-01, time/batch = 15.7101s	
20285/33250 (epoch 30.504), train_loss = 0.97875630, grad/param norm = 1.9369e-01, time/batch = 15.7713s	
20286/33250 (epoch 30.505), train_loss = 0.69952226, grad/param norm = 1.3336e-01, time/batch = 15.6303s	
20287/33250 (epoch 30.507), train_loss = 0.76632386, grad/param norm = 1.6325e-01, time/batch = 15.6106s	
20288/33250 (epoch 30.508), train_loss = 0.80763384, grad/param norm = 1.5150e-01, time/batch = 15.4283s	
20289/33250 (epoch 30.510), train_loss = 0.68617217, grad/param norm = 1.2946e-01, time/batch = 15.7548s	
20290/33250 (epoch 30.511), train_loss = 0.83985037, grad/param norm = 1.7681e-01, time/batch = 15.6147s	
20291/33250 (epoch 30.513), train_loss = 0.95707821, grad/param norm = 1.6072e-01, time/batch = 15.5274s	
20292/33250 (epoch 30.514), train_loss = 0.81267355, grad/param norm = 1.4621e-01, time/batch = 15.6934s	
20293/33250 (epoch 30.516), train_loss = 0.79148485, grad/param norm = 1.6794e-01, time/batch = 15.6808s	
20294/33250 (epoch 30.517), train_loss = 0.80695412, grad/param norm = 1.4471e-01, time/batch = 15.5190s	
20295/33250 (epoch 30.519), train_loss = 0.72147289, grad/param norm = 1.2618e-01, time/batch = 15.7025s	
20296/33250 (epoch 30.520), train_loss = 1.02581186, grad/param norm = 1.9066e-01, time/batch = 16.0814s	
20297/33250 (epoch 30.522), train_loss = 0.88750407, grad/param norm = 1.6017e-01, time/batch = 15.7050s	
20298/33250 (epoch 30.523), train_loss = 0.77413984, grad/param norm = 1.4663e-01, time/batch = 15.3498s	
20299/33250 (epoch 30.525), train_loss = 0.72067269, grad/param norm = 1.6444e-01, time/batch = 15.5862s	
20300/33250 (epoch 30.526), train_loss = 0.74990610, grad/param norm = 1.6227e-01, time/batch = 15.8361s	
20301/33250 (epoch 30.528), train_loss = 0.79209505, grad/param norm = 1.5687e-01, time/batch = 15.8368s	
20302/33250 (epoch 30.529), train_loss = 0.78202157, grad/param norm = 1.7380e-01, time/batch = 15.8453s	
20303/33250 (epoch 30.531), train_loss = 0.74876953, grad/param norm = 1.4950e-01, time/batch = 15.7738s	
20304/33250 (epoch 30.532), train_loss = 0.89031060, grad/param norm = 1.5625e-01, time/batch = 15.9937s	
20305/33250 (epoch 30.534), train_loss = 0.74264001, grad/param norm = 1.3873e-01, time/batch = 15.9917s	
20306/33250 (epoch 30.535), train_loss = 0.81445146, grad/param norm = 1.4842e-01, time/batch = 15.9943s	
20307/33250 (epoch 30.537), train_loss = 0.85384852, grad/param norm = 1.5006e-01, time/batch = 16.0190s	
20308/33250 (epoch 30.538), train_loss = 0.89552246, grad/param norm = 1.6762e-01, time/batch = 15.7893s	
20309/33250 (epoch 30.540), train_loss = 0.97080094, grad/param norm = 1.4637e-01, time/batch = 15.8442s	
20310/33250 (epoch 30.541), train_loss = 0.92352790, grad/param norm = 2.1784e-01, time/batch = 15.7558s	
20311/33250 (epoch 30.543), train_loss = 0.88373936, grad/param norm = 1.5757e-01, time/batch = 15.9141s	
20312/33250 (epoch 30.544), train_loss = 0.75511150, grad/param norm = 1.5962e-01, time/batch = 15.6858s	
20313/33250 (epoch 30.546), train_loss = 0.79232534, grad/param norm = 1.7199e-01, time/batch = 15.6940s	
20314/33250 (epoch 30.547), train_loss = 0.80534388, grad/param norm = 1.7002e-01, time/batch = 15.7669s	
20315/33250 (epoch 30.549), train_loss = 0.85854624, grad/param norm = 1.7131e-01, time/batch = 15.9992s	
20316/33250 (epoch 30.550), train_loss = 0.80188074, grad/param norm = 1.5633e-01, time/batch = 15.9404s	
20317/33250 (epoch 30.552), train_loss = 0.88780660, grad/param norm = 1.6199e-01, time/batch = 15.8737s	
20318/33250 (epoch 30.553), train_loss = 0.80985280, grad/param norm = 1.7491e-01, time/batch = 15.6947s	
20319/33250 (epoch 30.555), train_loss = 0.84656344, grad/param norm = 1.5032e-01, time/batch = 15.6224s	
20320/33250 (epoch 30.556), train_loss = 0.85840014, grad/param norm = 1.9675e-01, time/batch = 15.6731s	
20321/33250 (epoch 30.558), train_loss = 0.89471401, grad/param norm = 1.7187e-01, time/batch = 15.9183s	
20322/33250 (epoch 30.559), train_loss = 0.76985656, grad/param norm = 1.4544e-01, time/batch = 15.6836s	
20323/33250 (epoch 30.561), train_loss = 0.74105984, grad/param norm = 1.5002e-01, time/batch = 15.8555s	
20324/33250 (epoch 30.562), train_loss = 0.85680172, grad/param norm = 1.7562e-01, time/batch = 15.4473s	
20325/33250 (epoch 30.564), train_loss = 1.00993074, grad/param norm = 2.1297e-01, time/batch = 15.7736s	
20326/33250 (epoch 30.565), train_loss = 0.95347027, grad/param norm = 1.9187e-01, time/batch = 15.8187s	
20327/33250 (epoch 30.567), train_loss = 0.94172450, grad/param norm = 1.6845e-01, time/batch = 15.6956s	
20328/33250 (epoch 30.568), train_loss = 0.78936182, grad/param norm = 1.6113e-01, time/batch = 15.4448s	
20329/33250 (epoch 30.570), train_loss = 0.91315612, grad/param norm = 1.7744e-01, time/batch = 15.7746s	
20330/33250 (epoch 30.571), train_loss = 0.96411472, grad/param norm = 2.0776e-01, time/batch = 15.9242s	
20331/33250 (epoch 30.573), train_loss = 0.91916010, grad/param norm = 1.9723e-01, time/batch = 16.0057s	
20332/33250 (epoch 30.574), train_loss = 0.77907648, grad/param norm = 1.4556e-01, time/batch = 15.6971s	
20333/33250 (epoch 30.576), train_loss = 0.90153907, grad/param norm = 1.7127e-01, time/batch = 16.0012s	
20334/33250 (epoch 30.577), train_loss = 0.86124769, grad/param norm = 1.7237e-01, time/batch = 15.9174s	
20335/33250 (epoch 30.579), train_loss = 0.73939001, grad/param norm = 2.0711e-01, time/batch = 15.8421s	
20336/33250 (epoch 30.580), train_loss = 0.79663392, grad/param norm = 1.3391e-01, time/batch = 15.9814s	
20337/33250 (epoch 30.582), train_loss = 0.78919130, grad/param norm = 1.6187e-01, time/batch = 15.6981s	
20338/33250 (epoch 30.583), train_loss = 0.91666870, grad/param norm = 1.5283e-01, time/batch = 15.7402s	
20339/33250 (epoch 30.585), train_loss = 0.93225160, grad/param norm = 1.6113e-01, time/batch = 15.7501s	
20340/33250 (epoch 30.586), train_loss = 0.79223755, grad/param norm = 1.7592e-01, time/batch = 15.9208s	
20341/33250 (epoch 30.588), train_loss = 0.86272107, grad/param norm = 1.6182e-01, time/batch = 15.8503s	
20342/33250 (epoch 30.589), train_loss = 0.83948910, grad/param norm = 1.5838e-01, time/batch = 15.7812s	
20343/33250 (epoch 30.591), train_loss = 0.83297599, grad/param norm = 1.7735e-01, time/batch = 15.6951s	
20344/33250 (epoch 30.592), train_loss = 0.80968630, grad/param norm = 1.6374e-01, time/batch = 15.8520s	
20345/33250 (epoch 30.594), train_loss = 0.96009157, grad/param norm = 1.7746e-01, time/batch = 15.7647s	
20346/33250 (epoch 30.595), train_loss = 0.84733779, grad/param norm = 1.7641e-01, time/batch = 15.9242s	
20347/33250 (epoch 30.597), train_loss = 0.71128814, grad/param norm = 1.4329e-01, time/batch = 16.0083s	
20348/33250 (epoch 30.598), train_loss = 0.80930983, grad/param norm = 1.8475e-01, time/batch = 15.8668s	
20349/33250 (epoch 30.600), train_loss = 0.80658698, grad/param norm = 1.8933e-01, time/batch = 16.1678s	
20350/33250 (epoch 30.602), train_loss = 0.86344392, grad/param norm = 1.8211e-01, time/batch = 16.0911s	
20351/33250 (epoch 30.603), train_loss = 0.88703118, grad/param norm = 1.6713e-01, time/batch = 15.6888s	
20352/33250 (epoch 30.605), train_loss = 0.83965776, grad/param norm = 1.6360e-01, time/batch = 15.6556s	
20353/33250 (epoch 30.606), train_loss = 0.89975943, grad/param norm = 1.7831e-01, time/batch = 15.5965s	
20354/33250 (epoch 30.608), train_loss = 0.86549310, grad/param norm = 1.6011e-01, time/batch = 15.7583s	
20355/33250 (epoch 30.609), train_loss = 0.76295224, grad/param norm = 1.6937e-01, time/batch = 15.6813s	
20356/33250 (epoch 30.611), train_loss = 0.84785781, grad/param norm = 1.7628e-01, time/batch = 15.8312s	
20357/33250 (epoch 30.612), train_loss = 0.82264101, grad/param norm = 1.6627e-01, time/batch = 15.6958s	
20358/33250 (epoch 30.614), train_loss = 1.03775907, grad/param norm = 1.8469e-01, time/batch = 15.7848s	
20359/33250 (epoch 30.615), train_loss = 0.94487416, grad/param norm = 1.7417e-01, time/batch = 15.7069s	
20360/33250 (epoch 30.617), train_loss = 1.06211306, grad/param norm = 1.7246e-01, time/batch = 15.8559s	
20361/33250 (epoch 30.618), train_loss = 1.09204284, grad/param norm = 2.1960e-01, time/batch = 15.9334s	
20362/33250 (epoch 30.620), train_loss = 0.96976252, grad/param norm = 2.2695e-01, time/batch = 15.7367s	
20363/33250 (epoch 30.621), train_loss = 0.90145144, grad/param norm = 1.9237e-01, time/batch = 15.7669s	
20364/33250 (epoch 30.623), train_loss = 0.78034286, grad/param norm = 1.6593e-01, time/batch = 15.9236s	
20365/33250 (epoch 30.624), train_loss = 0.81888777, grad/param norm = 1.6995e-01, time/batch = 15.5233s	
20366/33250 (epoch 30.626), train_loss = 0.81011784, grad/param norm = 1.9227e-01, time/batch = 15.4447s	
20367/33250 (epoch 30.627), train_loss = 0.79343819, grad/param norm = 1.6409e-01, time/batch = 15.5971s	
20368/33250 (epoch 30.629), train_loss = 0.89128153, grad/param norm = 2.1953e-01, time/batch = 15.9698s	
20369/33250 (epoch 30.630), train_loss = 0.81609838, grad/param norm = 1.9300e-01, time/batch = 15.8427s	
20370/33250 (epoch 30.632), train_loss = 0.72839257, grad/param norm = 1.4431e-01, time/batch = 16.0318s	
20371/33250 (epoch 30.633), train_loss = 0.83540196, grad/param norm = 1.6588e-01, time/batch = 16.0952s	
20372/33250 (epoch 30.635), train_loss = 0.77145825, grad/param norm = 1.4327e-01, time/batch = 15.6001s	
20373/33250 (epoch 30.636), train_loss = 0.78504052, grad/param norm = 1.5796e-01, time/batch = 15.8130s	
20374/33250 (epoch 30.638), train_loss = 0.76063559, grad/param norm = 1.6242e-01, time/batch = 15.9185s	
20375/33250 (epoch 30.639), train_loss = 0.73470288, grad/param norm = 1.6907e-01, time/batch = 15.4357s	
20376/33250 (epoch 30.641), train_loss = 0.82486776, grad/param norm = 1.6593e-01, time/batch = 15.6102s	
20377/33250 (epoch 30.642), train_loss = 0.64121700, grad/param norm = 1.5323e-01, time/batch = 15.4287s	
20378/33250 (epoch 30.644), train_loss = 0.59342986, grad/param norm = 1.3520e-01, time/batch = 15.7721s	
20379/33250 (epoch 30.645), train_loss = 0.86865409, grad/param norm = 1.9094e-01, time/batch = 15.8601s	
20380/33250 (epoch 30.647), train_loss = 0.71765795, grad/param norm = 1.6082e-01, time/batch = 15.5469s	
20381/33250 (epoch 30.648), train_loss = 0.73075820, grad/param norm = 1.6238e-01, time/batch = 15.3847s	
20382/33250 (epoch 30.650), train_loss = 0.97582101, grad/param norm = 2.1475e-01, time/batch = 15.6127s	
20383/33250 (epoch 30.651), train_loss = 0.88504160, grad/param norm = 1.8612e-01, time/batch = 15.9235s	
20384/33250 (epoch 30.653), train_loss = 0.77387105, grad/param norm = 1.7478e-01, time/batch = 15.6100s	
20385/33250 (epoch 30.654), train_loss = 0.84583503, grad/param norm = 1.5124e-01, time/batch = 15.8385s	
20386/33250 (epoch 30.656), train_loss = 0.86747098, grad/param norm = 1.5016e-01, time/batch = 15.5145s	
20387/33250 (epoch 30.657), train_loss = 0.66621130, grad/param norm = 1.5526e-01, time/batch = 15.6798s	
20388/33250 (epoch 30.659), train_loss = 0.77337836, grad/param norm = 1.5755e-01, time/batch = 15.7797s	
20389/33250 (epoch 30.660), train_loss = 0.85218990, grad/param norm = 1.7715e-01, time/batch = 15.7855s	
20390/33250 (epoch 30.662), train_loss = 0.84666228, grad/param norm = 1.7503e-01, time/batch = 15.6165s	
20391/33250 (epoch 30.663), train_loss = 0.78053497, grad/param norm = 1.6930e-01, time/batch = 15.6930s	
20392/33250 (epoch 30.665), train_loss = 0.87783352, grad/param norm = 1.6896e-01, time/batch = 15.6208s	
20393/33250 (epoch 30.666), train_loss = 0.79478064, grad/param norm = 1.4847e-01, time/batch = 15.6757s	
20394/33250 (epoch 30.668), train_loss = 0.93023706, grad/param norm = 1.6818e-01, time/batch = 15.6785s	
20395/33250 (epoch 30.669), train_loss = 0.83791073, grad/param norm = 1.7324e-01, time/batch = 15.6989s	
20396/33250 (epoch 30.671), train_loss = 0.76016055, grad/param norm = 1.6942e-01, time/batch = 15.5837s	
20397/33250 (epoch 30.672), train_loss = 0.91237660, grad/param norm = 1.6053e-01, time/batch = 15.5044s	
20398/33250 (epoch 30.674), train_loss = 0.73075495, grad/param norm = 1.5007e-01, time/batch = 15.5979s	
20399/33250 (epoch 30.675), train_loss = 0.83718560, grad/param norm = 1.4974e-01, time/batch = 15.5346s	
20400/33250 (epoch 30.677), train_loss = 0.90454930, grad/param norm = 1.7182e-01, time/batch = 15.3808s	
20401/33250 (epoch 30.678), train_loss = 0.81602839, grad/param norm = 1.8459e-01, time/batch = 15.8538s	
20402/33250 (epoch 30.680), train_loss = 0.94650122, grad/param norm = 1.8189e-01, time/batch = 15.7852s	
20403/33250 (epoch 30.681), train_loss = 0.75845622, grad/param norm = 1.6153e-01, time/batch = 15.6782s	
20404/33250 (epoch 30.683), train_loss = 0.77216023, grad/param norm = 1.6582e-01, time/batch = 15.8311s	
20405/33250 (epoch 30.684), train_loss = 0.73652609, grad/param norm = 1.7215e-01, time/batch = 15.5799s	
20406/33250 (epoch 30.686), train_loss = 0.76851713, grad/param norm = 1.6896e-01, time/batch = 15.7723s	
20407/33250 (epoch 30.687), train_loss = 0.83872061, grad/param norm = 1.6397e-01, time/batch = 15.6728s	
20408/33250 (epoch 30.689), train_loss = 0.74021159, grad/param norm = 1.6354e-01, time/batch = 15.6085s	
20409/33250 (epoch 30.690), train_loss = 0.86448943, grad/param norm = 1.7336e-01, time/batch = 15.8497s	
20410/33250 (epoch 30.692), train_loss = 0.80306204, grad/param norm = 1.5106e-01, time/batch = 15.9344s	
20411/33250 (epoch 30.693), train_loss = 0.90297204, grad/param norm = 1.5941e-01, time/batch = 15.8572s	
20412/33250 (epoch 30.695), train_loss = 0.85802631, grad/param norm = 1.5392e-01, time/batch = 15.8756s	
20413/33250 (epoch 30.696), train_loss = 0.89049462, grad/param norm = 1.5957e-01, time/batch = 15.7716s	
20414/33250 (epoch 30.698), train_loss = 0.79718852, grad/param norm = 1.7239e-01, time/batch = 15.9274s	
20415/33250 (epoch 30.699), train_loss = 1.04119437, grad/param norm = 1.7517e-01, time/batch = 15.7569s	
20416/33250 (epoch 30.701), train_loss = 0.82740893, grad/param norm = 1.5116e-01, time/batch = 15.8963s	
20417/33250 (epoch 30.702), train_loss = 0.79774834, grad/param norm = 1.9312e-01, time/batch = 15.7607s	
20418/33250 (epoch 30.704), train_loss = 1.01893929, grad/param norm = 2.3109e-01, time/batch = 15.7584s	
20419/33250 (epoch 30.705), train_loss = 0.78148978, grad/param norm = 1.4537e-01, time/batch = 15.6028s	
20420/33250 (epoch 30.707), train_loss = 0.69107023, grad/param norm = 1.5254e-01, time/batch = 15.7146s	
20421/33250 (epoch 30.708), train_loss = 0.91354797, grad/param norm = 1.8438e-01, time/batch = 16.0178s	
20422/33250 (epoch 30.710), train_loss = 0.88697975, grad/param norm = 1.8899e-01, time/batch = 15.8128s	
20423/33250 (epoch 30.711), train_loss = 0.75016711, grad/param norm = 1.7882e-01, time/batch = 15.8589s	
20424/33250 (epoch 30.713), train_loss = 0.86303011, grad/param norm = 1.4828e-01, time/batch = 15.7633s	
20425/33250 (epoch 30.714), train_loss = 0.83744786, grad/param norm = 1.8424e-01, time/batch = 15.7660s	
20426/33250 (epoch 30.716), train_loss = 0.85311809, grad/param norm = 1.6128e-01, time/batch = 15.6988s	
20427/33250 (epoch 30.717), train_loss = 0.76104755, grad/param norm = 1.4056e-01, time/batch = 15.6119s	
20428/33250 (epoch 30.719), train_loss = 0.79077769, grad/param norm = 1.6189e-01, time/batch = 15.5954s	
20429/33250 (epoch 30.720), train_loss = 1.05306397, grad/param norm = 1.7702e-01, time/batch = 15.6144s	
20430/33250 (epoch 30.722), train_loss = 0.73012217, grad/param norm = 1.6091e-01, time/batch = 15.7509s	
20431/33250 (epoch 30.723), train_loss = 0.65601188, grad/param norm = 1.2754e-01, time/batch = 15.6994s	
20432/33250 (epoch 30.725), train_loss = 0.77377934, grad/param norm = 1.3378e-01, time/batch = 15.6935s	
20433/33250 (epoch 30.726), train_loss = 0.81467344, grad/param norm = 1.5260e-01, time/batch = 15.7087s	
20434/33250 (epoch 30.728), train_loss = 0.85998014, grad/param norm = 1.7548e-01, time/batch = 15.8513s	
20435/33250 (epoch 30.729), train_loss = 0.91227216, grad/param norm = 1.6304e-01, time/batch = 15.6902s	
20436/33250 (epoch 30.731), train_loss = 0.76341377, grad/param norm = 1.7039e-01, time/batch = 15.8548s	
20437/33250 (epoch 30.732), train_loss = 0.75516980, grad/param norm = 1.4674e-01, time/batch = 15.9423s	
20438/33250 (epoch 30.734), train_loss = 0.86985392, grad/param norm = 2.1531e-01, time/batch = 15.6846s	
20439/33250 (epoch 30.735), train_loss = 0.86412606, grad/param norm = 1.6988e-01, time/batch = 15.6744s	
20440/33250 (epoch 30.737), train_loss = 0.79189671, grad/param norm = 1.5215e-01, time/batch = 15.7545s	
20441/33250 (epoch 30.738), train_loss = 0.86370209, grad/param norm = 1.5404e-01, time/batch = 15.7707s	
20442/33250 (epoch 30.740), train_loss = 0.87309136, grad/param norm = 1.6721e-01, time/batch = 15.9185s	
20443/33250 (epoch 30.741), train_loss = 0.89908716, grad/param norm = 1.7644e-01, time/batch = 15.8431s	
20444/33250 (epoch 30.743), train_loss = 0.77634837, grad/param norm = 1.4773e-01, time/batch = 15.7827s	
20445/33250 (epoch 30.744), train_loss = 0.79353314, grad/param norm = 1.6167e-01, time/batch = 15.9981s	
20446/33250 (epoch 30.746), train_loss = 0.74963784, grad/param norm = 1.5444e-01, time/batch = 16.1587s	
20447/33250 (epoch 30.747), train_loss = 0.77941854, grad/param norm = 1.4816e-01, time/batch = 16.2437s	
20448/33250 (epoch 30.749), train_loss = 0.93506572, grad/param norm = 1.7332e-01, time/batch = 16.1098s	
20449/33250 (epoch 30.750), train_loss = 0.91211444, grad/param norm = 1.6147e-01, time/batch = 16.1881s	
20450/33250 (epoch 30.752), train_loss = 0.80129643, grad/param norm = 1.5793e-01, time/batch = 16.0231s	
20451/33250 (epoch 30.753), train_loss = 0.78112781, grad/param norm = 1.6169e-01, time/batch = 16.1726s	
20452/33250 (epoch 30.755), train_loss = 0.75479876, grad/param norm = 1.7697e-01, time/batch = 16.1921s	
20453/33250 (epoch 30.756), train_loss = 0.84317612, grad/param norm = 1.6956e-01, time/batch = 16.1703s	
20454/33250 (epoch 30.758), train_loss = 0.98182624, grad/param norm = 1.4988e-01, time/batch = 16.1065s	
20455/33250 (epoch 30.759), train_loss = 0.78387118, grad/param norm = 1.4966e-01, time/batch = 16.1139s	
20456/33250 (epoch 30.761), train_loss = 0.84533442, grad/param norm = 1.6872e-01, time/batch = 16.0242s	
20457/33250 (epoch 30.762), train_loss = 0.89561023, grad/param norm = 1.5972e-01, time/batch = 15.9514s	
20458/33250 (epoch 30.764), train_loss = 0.76300800, grad/param norm = 2.1082e-01, time/batch = 16.0880s	
20459/33250 (epoch 30.765), train_loss = 0.89507623, grad/param norm = 1.8354e-01, time/batch = 16.0223s	
20460/33250 (epoch 30.767), train_loss = 0.67327768, grad/param norm = 1.5106e-01, time/batch = 16.0767s	
20461/33250 (epoch 30.768), train_loss = 0.67918939, grad/param norm = 1.4010e-01, time/batch = 16.1674s	
20462/33250 (epoch 30.770), train_loss = 0.86024072, grad/param norm = 1.6920e-01, time/batch = 16.1744s	
20463/33250 (epoch 30.771), train_loss = 0.88291393, grad/param norm = 1.7838e-01, time/batch = 16.1065s	
20464/33250 (epoch 30.773), train_loss = 0.81312359, grad/param norm = 1.6639e-01, time/batch = 16.1181s	
20465/33250 (epoch 30.774), train_loss = 0.70947756, grad/param norm = 1.5596e-01, time/batch = 17.3440s	
20466/33250 (epoch 30.776), train_loss = 0.79101936, grad/param norm = 1.5518e-01, time/batch = 28.9835s	
20467/33250 (epoch 30.777), train_loss = 0.90166694, grad/param norm = 1.7701e-01, time/batch = 16.0198s	
20468/33250 (epoch 30.779), train_loss = 0.81935786, grad/param norm = 1.6917e-01, time/batch = 16.0914s	
20469/33250 (epoch 30.780), train_loss = 0.96267630, grad/param norm = 2.0841e-01, time/batch = 16.0595s	
20470/33250 (epoch 30.782), train_loss = 0.81886749, grad/param norm = 1.9905e-01, time/batch = 16.0784s	
20471/33250 (epoch 30.783), train_loss = 0.69713037, grad/param norm = 1.4727e-01, time/batch = 16.2532s	
20472/33250 (epoch 30.785), train_loss = 0.72384231, grad/param norm = 1.6047e-01, time/batch = 16.0862s	
20473/33250 (epoch 30.786), train_loss = 0.93330593, grad/param norm = 1.7131e-01, time/batch = 16.1873s	
20474/33250 (epoch 30.788), train_loss = 0.91810240, grad/param norm = 1.7366e-01, time/batch = 16.1957s	
20475/33250 (epoch 30.789), train_loss = 0.94620414, grad/param norm = 1.9854e-01, time/batch = 16.1196s	
20476/33250 (epoch 30.791), train_loss = 0.95912859, grad/param norm = 2.1219e-01, time/batch = 15.9977s	
20477/33250 (epoch 30.792), train_loss = 0.97523958, grad/param norm = 1.7349e-01, time/batch = 15.9167s	
20478/33250 (epoch 30.794), train_loss = 0.80893915, grad/param norm = 1.7332e-01, time/batch = 15.9323s	
20479/33250 (epoch 30.795), train_loss = 0.84724912, grad/param norm = 1.8453e-01, time/batch = 15.8452s	
20480/33250 (epoch 30.797), train_loss = 0.92285605, grad/param norm = 2.0353e-01, time/batch = 16.1675s	
20481/33250 (epoch 30.798), train_loss = 0.84348979, grad/param norm = 2.1221e-01, time/batch = 16.1797s	
20482/33250 (epoch 30.800), train_loss = 0.88841488, grad/param norm = 1.8988e-01, time/batch = 16.0281s	
20483/33250 (epoch 30.802), train_loss = 0.81765991, grad/param norm = 1.6566e-01, time/batch = 16.1753s	
20484/33250 (epoch 30.803), train_loss = 0.87285802, grad/param norm = 1.5663e-01, time/batch = 16.1028s	
20485/33250 (epoch 30.805), train_loss = 0.86602674, grad/param norm = 1.6404e-01, time/batch = 16.0364s	
20486/33250 (epoch 30.806), train_loss = 0.83907179, grad/param norm = 1.6677e-01, time/batch = 16.1935s	
20487/33250 (epoch 30.808), train_loss = 0.75828719, grad/param norm = 1.5236e-01, time/batch = 16.1694s	
20488/33250 (epoch 30.809), train_loss = 0.75221959, grad/param norm = 1.5213e-01, time/batch = 16.0768s	
20489/33250 (epoch 30.811), train_loss = 0.75270751, grad/param norm = 1.5771e-01, time/batch = 15.9359s	
20490/33250 (epoch 30.812), train_loss = 0.88832873, grad/param norm = 1.8524e-01, time/batch = 15.9239s	
20491/33250 (epoch 30.814), train_loss = 0.83456323, grad/param norm = 1.9422e-01, time/batch = 16.3285s	
20492/33250 (epoch 30.815), train_loss = 0.88507136, grad/param norm = 1.5772e-01, time/batch = 16.0153s	
20493/33250 (epoch 30.817), train_loss = 0.82601111, grad/param norm = 1.8280e-01, time/batch = 16.3649s	
20494/33250 (epoch 30.818), train_loss = 0.76322481, grad/param norm = 1.6499e-01, time/batch = 15.9300s	
20495/33250 (epoch 30.820), train_loss = 0.85435410, grad/param norm = 1.6006e-01, time/batch = 16.0266s	
20496/33250 (epoch 30.821), train_loss = 0.81452433, grad/param norm = 1.5474e-01, time/batch = 15.9444s	
20497/33250 (epoch 30.823), train_loss = 1.13726972, grad/param norm = 1.8652e-01, time/batch = 15.9493s	
20498/33250 (epoch 30.824), train_loss = 0.78435067, grad/param norm = 1.9007e-01, time/batch = 15.9457s	
20499/33250 (epoch 30.826), train_loss = 0.86862896, grad/param norm = 1.7028e-01, time/batch = 16.1684s	
20500/33250 (epoch 30.827), train_loss = 0.73880361, grad/param norm = 1.6620e-01, time/batch = 15.8586s	
20501/33250 (epoch 30.829), train_loss = 0.84439670, grad/param norm = 1.7635e-01, time/batch = 16.1142s	
20502/33250 (epoch 30.830), train_loss = 0.92211665, grad/param norm = 2.1075e-01, time/batch = 16.2440s	
20503/33250 (epoch 30.832), train_loss = 0.84052688, grad/param norm = 1.5264e-01, time/batch = 16.1153s	
20504/33250 (epoch 30.833), train_loss = 0.82970737, grad/param norm = 1.7865e-01, time/batch = 15.9603s	
20505/33250 (epoch 30.835), train_loss = 0.76978647, grad/param norm = 2.1193e-01, time/batch = 15.9544s	
20506/33250 (epoch 30.836), train_loss = 0.81640337, grad/param norm = 1.6038e-01, time/batch = 16.1111s	
20507/33250 (epoch 30.838), train_loss = 0.87484533, grad/param norm = 1.6226e-01, time/batch = 15.9418s	
20508/33250 (epoch 30.839), train_loss = 0.80902125, grad/param norm = 1.6417e-01, time/batch = 16.0030s	
20509/33250 (epoch 30.841), train_loss = 0.77101491, grad/param norm = 1.4578e-01, time/batch = 16.0775s	
20510/33250 (epoch 30.842), train_loss = 0.98018505, grad/param norm = 1.7691e-01, time/batch = 16.1015s	
20511/33250 (epoch 30.844), train_loss = 0.91931528, grad/param norm = 1.9893e-01, time/batch = 16.2402s	
20512/33250 (epoch 30.845), train_loss = 1.01151110, grad/param norm = 1.8947e-01, time/batch = 15.9321s	
20513/33250 (epoch 30.847), train_loss = 0.99684801, grad/param norm = 1.9350e-01, time/batch = 16.0727s	
20514/33250 (epoch 30.848), train_loss = 1.04600011, grad/param norm = 2.0183e-01, time/batch = 16.0364s	
20515/33250 (epoch 30.850), train_loss = 0.92581012, grad/param norm = 1.6674e-01, time/batch = 16.1947s	
20516/33250 (epoch 30.851), train_loss = 0.74534714, grad/param norm = 1.7882e-01, time/batch = 15.9407s	
20517/33250 (epoch 30.853), train_loss = 0.89224157, grad/param norm = 2.0306e-01, time/batch = 16.2735s	
20518/33250 (epoch 30.854), train_loss = 0.79746661, grad/param norm = 1.5235e-01, time/batch = 16.1055s	
20519/33250 (epoch 30.856), train_loss = 0.81161975, grad/param norm = 1.9416e-01, time/batch = 16.1841s	
20520/33250 (epoch 30.857), train_loss = 0.73106047, grad/param norm = 1.5982e-01, time/batch = 16.1800s	
20521/33250 (epoch 30.859), train_loss = 0.76382547, grad/param norm = 1.5122e-01, time/batch = 16.3381s	
20522/33250 (epoch 30.860), train_loss = 0.87117798, grad/param norm = 1.5626e-01, time/batch = 16.0936s	
20523/33250 (epoch 30.862), train_loss = 0.73825770, grad/param norm = 1.6632e-01, time/batch = 16.0224s	
20524/33250 (epoch 30.863), train_loss = 0.76937806, grad/param norm = 1.6435e-01, time/batch = 16.0902s	
20525/33250 (epoch 30.865), train_loss = 0.86867380, grad/param norm = 1.6995e-01, time/batch = 16.1986s	
20526/33250 (epoch 30.866), train_loss = 0.73162410, grad/param norm = 1.6904e-01, time/batch = 15.9547s	
20527/33250 (epoch 30.868), train_loss = 0.86441305, grad/param norm = 1.9197e-01, time/batch = 15.9546s	
20528/33250 (epoch 30.869), train_loss = 0.85287030, grad/param norm = 1.7881e-01, time/batch = 16.1776s	
20529/33250 (epoch 30.871), train_loss = 0.65948983, grad/param norm = 1.4611e-01, time/batch = 16.0999s	
20530/33250 (epoch 30.872), train_loss = 0.90591569, grad/param norm = 1.7886e-01, time/batch = 16.0952s	
20531/33250 (epoch 30.874), train_loss = 0.79308762, grad/param norm = 1.9365e-01, time/batch = 16.1763s	
20532/33250 (epoch 30.875), train_loss = 0.74584162, grad/param norm = 2.1640e-01, time/batch = 16.2461s	
20533/33250 (epoch 30.877), train_loss = 0.95154391, grad/param norm = 1.6902e-01, time/batch = 16.1878s	
20534/33250 (epoch 30.878), train_loss = 0.85985203, grad/param norm = 1.5268e-01, time/batch = 16.1913s	
20535/33250 (epoch 30.880), train_loss = 0.85543605, grad/param norm = 2.3924e-01, time/batch = 16.1159s	
20536/33250 (epoch 30.881), train_loss = 0.94693506, grad/param norm = 1.7107e-01, time/batch = 16.4151s	
20537/33250 (epoch 30.883), train_loss = 0.85997099, grad/param norm = 1.6869e-01, time/batch = 16.3717s	
20538/33250 (epoch 30.884), train_loss = 0.92027339, grad/param norm = 2.0422e-01, time/batch = 16.1074s	
20539/33250 (epoch 30.886), train_loss = 0.77872850, grad/param norm = 1.4060e-01, time/batch = 16.0059s	
20540/33250 (epoch 30.887), train_loss = 0.79666980, grad/param norm = 1.6904e-01, time/batch = 16.1883s	
20541/33250 (epoch 30.889), train_loss = 0.79621857, grad/param norm = 1.5272e-01, time/batch = 16.1829s	
20542/33250 (epoch 30.890), train_loss = 0.65904080, grad/param norm = 1.2669e-01, time/batch = 16.0112s	
20543/33250 (epoch 30.892), train_loss = 0.87627118, grad/param norm = 1.4603e-01, time/batch = 15.8315s	
20544/33250 (epoch 30.893), train_loss = 0.90561769, grad/param norm = 1.8140e-01, time/batch = 15.7658s	
20545/33250 (epoch 30.895), train_loss = 0.79586678, grad/param norm = 1.8210e-01, time/batch = 15.9944s	
20546/33250 (epoch 30.896), train_loss = 0.89409409, grad/param norm = 1.6278e-01, time/batch = 15.8480s	
20547/33250 (epoch 30.898), train_loss = 0.83515390, grad/param norm = 1.6141e-01, time/batch = 15.7852s	
20548/33250 (epoch 30.899), train_loss = 0.78552432, grad/param norm = 1.6972e-01, time/batch = 15.5451s	
20549/33250 (epoch 30.901), train_loss = 0.73004976, grad/param norm = 1.5655e-01, time/batch = 15.7574s	
20550/33250 (epoch 30.902), train_loss = 0.80336502, grad/param norm = 1.6553e-01, time/batch = 15.7511s	
20551/33250 (epoch 30.904), train_loss = 0.74799025, grad/param norm = 1.5464e-01, time/batch = 15.6072s	
20552/33250 (epoch 30.905), train_loss = 0.80568981, grad/param norm = 1.4912e-01, time/batch = 15.8286s	
20553/33250 (epoch 30.907), train_loss = 0.73959484, grad/param norm = 1.5102e-01, time/batch = 15.6833s	
20554/33250 (epoch 30.908), train_loss = 0.82451749, grad/param norm = 1.4942e-01, time/batch = 15.7575s	
20555/33250 (epoch 30.910), train_loss = 0.91203393, grad/param norm = 2.0739e-01, time/batch = 15.4585s	
20556/33250 (epoch 30.911), train_loss = 0.71420315, grad/param norm = 1.4443e-01, time/batch = 15.5594s	
20557/33250 (epoch 30.913), train_loss = 0.80098631, grad/param norm = 1.5723e-01, time/batch = 15.7761s	
20558/33250 (epoch 30.914), train_loss = 0.70482279, grad/param norm = 1.6103e-01, time/batch = 20.9138s	
20559/33250 (epoch 30.916), train_loss = 0.74637628, grad/param norm = 1.6408e-01, time/batch = 18.5343s	
20560/33250 (epoch 30.917), train_loss = 0.83530583, grad/param norm = 1.4778e-01, time/batch = 18.3162s	
20561/33250 (epoch 30.919), train_loss = 0.76208090, grad/param norm = 1.7952e-01, time/batch = 18.7127s	
20562/33250 (epoch 30.920), train_loss = 0.82271340, grad/param norm = 1.7864e-01, time/batch = 18.4806s	
20563/33250 (epoch 30.922), train_loss = 0.86580886, grad/param norm = 1.9125e-01, time/batch = 19.0293s	
20564/33250 (epoch 30.923), train_loss = 0.80579765, grad/param norm = 1.9691e-01, time/batch = 19.1190s	
20565/33250 (epoch 30.925), train_loss = 0.80591595, grad/param norm = 1.7106e-01, time/batch = 18.8251s	
20566/33250 (epoch 30.926), train_loss = 0.78315838, grad/param norm = 1.5636e-01, time/batch = 19.7102s	
20567/33250 (epoch 30.928), train_loss = 0.78495531, grad/param norm = 1.6279e-01, time/batch = 19.4596s	
20568/33250 (epoch 30.929), train_loss = 0.70699857, grad/param norm = 1.3775e-01, time/batch = 19.0347s	
20569/33250 (epoch 30.931), train_loss = 0.93500826, grad/param norm = 1.6986e-01, time/batch = 19.2240s	
20570/33250 (epoch 30.932), train_loss = 0.77818293, grad/param norm = 1.6932e-01, time/batch = 18.9702s	
20571/33250 (epoch 30.934), train_loss = 0.76645897, grad/param norm = 1.3996e-01, time/batch = 18.8991s	
20572/33250 (epoch 30.935), train_loss = 0.79031032, grad/param norm = 1.9079e-01, time/batch = 19.2002s	
20573/33250 (epoch 30.937), train_loss = 0.77045223, grad/param norm = 1.7542e-01, time/batch = 19.0397s	
20574/33250 (epoch 30.938), train_loss = 0.82153533, grad/param norm = 1.6928e-01, time/batch = 18.8362s	
20575/33250 (epoch 30.940), train_loss = 0.80113818, grad/param norm = 1.5588e-01, time/batch = 18.7512s	
20576/33250 (epoch 30.941), train_loss = 0.86692234, grad/param norm = 1.7705e-01, time/batch = 18.3258s	
20577/33250 (epoch 30.943), train_loss = 0.98318335, grad/param norm = 1.9699e-01, time/batch = 25.1266s	
20578/33250 (epoch 30.944), train_loss = 0.80494173, grad/param norm = 1.6305e-01, time/batch = 17.4805s	
20579/33250 (epoch 30.946), train_loss = 0.93352394, grad/param norm = 1.7305e-01, time/batch = 16.0747s	
20580/33250 (epoch 30.947), train_loss = 0.75616203, grad/param norm = 1.9737e-01, time/batch = 15.9107s	
20581/33250 (epoch 30.949), train_loss = 0.88573553, grad/param norm = 1.7395e-01, time/batch = 15.6227s	
20582/33250 (epoch 30.950), train_loss = 0.89331238, grad/param norm = 1.6547e-01, time/batch = 15.9853s	
20583/33250 (epoch 30.952), train_loss = 0.84803731, grad/param norm = 1.9141e-01, time/batch = 16.0681s	
20584/33250 (epoch 30.953), train_loss = 0.88152140, grad/param norm = 2.0907e-01, time/batch = 15.7772s	
20585/33250 (epoch 30.955), train_loss = 0.90444235, grad/param norm = 1.7068e-01, time/batch = 15.9414s	
20586/33250 (epoch 30.956), train_loss = 0.85963724, grad/param norm = 2.1160e-01, time/batch = 15.7846s	
20587/33250 (epoch 30.958), train_loss = 0.77418753, grad/param norm = 1.7290e-01, time/batch = 15.8398s	
20588/33250 (epoch 30.959), train_loss = 0.77200014, grad/param norm = 1.5461e-01, time/batch = 15.7735s	
20589/33250 (epoch 30.961), train_loss = 1.02714515, grad/param norm = 1.7419e-01, time/batch = 15.8589s	
20590/33250 (epoch 30.962), train_loss = 0.82894961, grad/param norm = 1.6485e-01, time/batch = 15.5356s	
20591/33250 (epoch 30.964), train_loss = 0.97077541, grad/param norm = 1.8823e-01, time/batch = 16.1689s	
20592/33250 (epoch 30.965), train_loss = 0.89533310, grad/param norm = 1.8045e-01, time/batch = 15.7775s	
20593/33250 (epoch 30.967), train_loss = 0.84869432, grad/param norm = 1.7653e-01, time/batch = 15.9337s	
20594/33250 (epoch 30.968), train_loss = 0.97618951, grad/param norm = 1.7278e-01, time/batch = 15.7711s	
20595/33250 (epoch 30.970), train_loss = 1.09164656, grad/param norm = 2.2969e-01, time/batch = 15.9387s	
20596/33250 (epoch 30.971), train_loss = 1.01823674, grad/param norm = 2.3141e-01, time/batch = 15.7832s	
20597/33250 (epoch 30.973), train_loss = 0.82606103, grad/param norm = 1.6415e-01, time/batch = 15.8448s	
20598/33250 (epoch 30.974), train_loss = 0.89846265, grad/param norm = 1.6949e-01, time/batch = 15.7755s	
20599/33250 (epoch 30.976), train_loss = 0.80989108, grad/param norm = 1.7472e-01, time/batch = 15.8574s	
20600/33250 (epoch 30.977), train_loss = 0.82032792, grad/param norm = 1.8631e-01, time/batch = 15.5219s	
20601/33250 (epoch 30.979), train_loss = 0.88268224, grad/param norm = 1.8452e-01, time/batch = 15.8367s	
20602/33250 (epoch 30.980), train_loss = 0.88864362, grad/param norm = 1.8459e-01, time/batch = 15.6607s	
20603/33250 (epoch 30.982), train_loss = 0.78165853, grad/param norm = 1.4109e-01, time/batch = 15.7729s	
20604/33250 (epoch 30.983), train_loss = 0.85400655, grad/param norm = 1.7269e-01, time/batch = 15.6018s	
20605/33250 (epoch 30.985), train_loss = 0.79640388, grad/param norm = 1.6463e-01, time/batch = 16.0255s	
20606/33250 (epoch 30.986), train_loss = 0.89821322, grad/param norm = 1.6170e-01, time/batch = 15.9292s	
20607/33250 (epoch 30.988), train_loss = 0.92192437, grad/param norm = 1.7524e-01, time/batch = 15.5530s	
20608/33250 (epoch 30.989), train_loss = 0.91832744, grad/param norm = 1.7813e-01, time/batch = 15.7690s	
20609/33250 (epoch 30.991), train_loss = 0.86194954, grad/param norm = 1.6118e-01, time/batch = 15.7750s	
20610/33250 (epoch 30.992), train_loss = 0.82606987, grad/param norm = 1.7289e-01, time/batch = 15.8451s	
20611/33250 (epoch 30.994), train_loss = 0.80972454, grad/param norm = 1.5070e-01, time/batch = 15.8393s	
20612/33250 (epoch 30.995), train_loss = 0.82192501, grad/param norm = 2.0613e-01, time/batch = 15.7585s	
20613/33250 (epoch 30.997), train_loss = 0.62251080, grad/param norm = 1.4381e-01, time/batch = 15.5695s	
20614/33250 (epoch 30.998), train_loss = 0.86891924, grad/param norm = 1.5923e-01, time/batch = 15.4139s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
20615/33250 (epoch 31.000), train_loss = 0.86470362, grad/param norm = 1.6774e-01, time/batch = 15.5718s	
20616/33250 (epoch 31.002), train_loss = 1.03439488, grad/param norm = 1.8157e-01, time/batch = 15.7164s	
20617/33250 (epoch 31.003), train_loss = 0.93388425, grad/param norm = 1.8895e-01, time/batch = 15.8068s	
20618/33250 (epoch 31.005), train_loss = 0.69759532, grad/param norm = 1.4242e-01, time/batch = 15.3081s	
20619/33250 (epoch 31.006), train_loss = 0.71383873, grad/param norm = 1.5220e-01, time/batch = 15.1501s	
20620/33250 (epoch 31.008), train_loss = 0.92671495, grad/param norm = 1.6736e-01, time/batch = 15.2302s	
20621/33250 (epoch 31.009), train_loss = 0.98510677, grad/param norm = 1.7302e-01, time/batch = 15.3130s	
20622/33250 (epoch 31.011), train_loss = 0.78443585, grad/param norm = 1.6056e-01, time/batch = 15.3183s	
20623/33250 (epoch 31.012), train_loss = 0.81929854, grad/param norm = 1.9701e-01, time/batch = 15.2319s	
20624/33250 (epoch 31.014), train_loss = 0.93842844, grad/param norm = 1.8457e-01, time/batch = 15.1486s	
20625/33250 (epoch 31.015), train_loss = 0.84386118, grad/param norm = 1.6298e-01, time/batch = 15.3857s	
20626/33250 (epoch 31.017), train_loss = 0.86963967, grad/param norm = 1.7824e-01, time/batch = 15.4000s	
20627/33250 (epoch 31.018), train_loss = 0.68480136, grad/param norm = 1.6070e-01, time/batch = 15.2292s	
20628/33250 (epoch 31.020), train_loss = 0.84567167, grad/param norm = 1.4933e-01, time/batch = 15.3207s	
20629/33250 (epoch 31.021), train_loss = 0.88110358, grad/param norm = 1.7037e-01, time/batch = 15.6423s	
20630/33250 (epoch 31.023), train_loss = 0.69660631, grad/param norm = 1.7744e-01, time/batch = 15.3172s	
20631/33250 (epoch 31.024), train_loss = 0.94958977, grad/param norm = 1.7295e-01, time/batch = 15.3123s	
20632/33250 (epoch 31.026), train_loss = 0.85371484, grad/param norm = 1.6401e-01, time/batch = 15.4906s	
20633/33250 (epoch 31.027), train_loss = 0.87798288, grad/param norm = 1.5872e-01, time/batch = 15.6769s	
20634/33250 (epoch 31.029), train_loss = 0.82096541, grad/param norm = 1.6005e-01, time/batch = 15.7639s	
20635/33250 (epoch 31.030), train_loss = 0.83682963, grad/param norm = 1.8829e-01, time/batch = 15.6743s	
20636/33250 (epoch 31.032), train_loss = 1.05229927, grad/param norm = 2.0658e-01, time/batch = 15.8197s	
20637/33250 (epoch 31.033), train_loss = 0.80953266, grad/param norm = 1.7692e-01, time/batch = 16.0120s	
20638/33250 (epoch 31.035), train_loss = 0.85098019, grad/param norm = 1.8194e-01, time/batch = 15.9237s	
20639/33250 (epoch 31.036), train_loss = 0.89922469, grad/param norm = 1.7555e-01, time/batch = 15.7053s	
20640/33250 (epoch 31.038), train_loss = 0.84508346, grad/param norm = 1.4232e-01, time/batch = 15.6748s	
20641/33250 (epoch 31.039), train_loss = 0.77381122, grad/param norm = 1.5701e-01, time/batch = 15.8472s	
20642/33250 (epoch 31.041), train_loss = 0.86067113, grad/param norm = 2.0680e-01, time/batch = 15.8374s	
20643/33250 (epoch 31.042), train_loss = 0.71755276, grad/param norm = 1.5440e-01, time/batch = 15.7686s	
20644/33250 (epoch 31.044), train_loss = 0.93026064, grad/param norm = 1.6662e-01, time/batch = 15.6682s	
20645/33250 (epoch 31.045), train_loss = 0.94300449, grad/param norm = 1.7219e-01, time/batch = 15.5990s	
20646/33250 (epoch 31.047), train_loss = 0.85053410, grad/param norm = 1.6882e-01, time/batch = 15.6675s	
20647/33250 (epoch 31.048), train_loss = 0.94559177, grad/param norm = 2.0931e-01, time/batch = 15.5240s	
20648/33250 (epoch 31.050), train_loss = 0.86263306, grad/param norm = 1.6957e-01, time/batch = 15.9186s	
20649/33250 (epoch 31.051), train_loss = 0.83249126, grad/param norm = 1.6366e-01, time/batch = 15.5344s	
20650/33250 (epoch 31.053), train_loss = 0.89116805, grad/param norm = 1.9429e-01, time/batch = 15.7006s	
20651/33250 (epoch 31.054), train_loss = 0.72781022, grad/param norm = 1.4805e-01, time/batch = 15.9857s	
20652/33250 (epoch 31.056), train_loss = 0.75308996, grad/param norm = 1.4479e-01, time/batch = 15.9002s	
20653/33250 (epoch 31.057), train_loss = 0.94157725, grad/param norm = 1.5971e-01, time/batch = 15.6934s	
20654/33250 (epoch 31.059), train_loss = 0.80483145, grad/param norm = 1.6888e-01, time/batch = 15.8276s	
20655/33250 (epoch 31.060), train_loss = 0.84249023, grad/param norm = 1.6858e-01, time/batch = 15.7634s	
20656/33250 (epoch 31.062), train_loss = 0.94088617, grad/param norm = 1.7150e-01, time/batch = 15.8341s	
20657/33250 (epoch 31.063), train_loss = 0.98275255, grad/param norm = 1.5168e-01, time/batch = 15.5985s	
20658/33250 (epoch 31.065), train_loss = 0.84446809, grad/param norm = 1.6695e-01, time/batch = 15.8542s	
20659/33250 (epoch 31.066), train_loss = 0.89157264, grad/param norm = 1.7786e-01, time/batch = 15.8568s	
20660/33250 (epoch 31.068), train_loss = 0.80452179, grad/param norm = 1.7597e-01, time/batch = 15.6301s	
20661/33250 (epoch 31.069), train_loss = 0.86774115, grad/param norm = 1.7146e-01, time/batch = 15.9370s	
20662/33250 (epoch 31.071), train_loss = 0.77346893, grad/param norm = 1.3463e-01, time/batch = 15.3642s	
20663/33250 (epoch 31.072), train_loss = 0.78996651, grad/param norm = 1.6371e-01, time/batch = 15.7420s	
20664/33250 (epoch 31.074), train_loss = 0.87089184, grad/param norm = 1.6940e-01, time/batch = 15.7725s	
20665/33250 (epoch 31.075), train_loss = 0.79786016, grad/param norm = 1.6661e-01, time/batch = 15.8363s	
20666/33250 (epoch 31.077), train_loss = 0.83854369, grad/param norm = 1.7348e-01, time/batch = 15.5941s	
20667/33250 (epoch 31.078), train_loss = 0.87052088, grad/param norm = 1.6742e-01, time/batch = 15.9973s	
20668/33250 (epoch 31.080), train_loss = 0.86176855, grad/param norm = 1.9832e-01, time/batch = 15.5933s	
20669/33250 (epoch 31.081), train_loss = 0.88542878, grad/param norm = 1.5857e-01, time/batch = 16.0150s	
20670/33250 (epoch 31.083), train_loss = 0.95873330, grad/param norm = 1.6327e-01, time/batch = 15.6187s	
20671/33250 (epoch 31.084), train_loss = 0.86657459, grad/param norm = 1.8647e-01, time/batch = 16.0256s	
20672/33250 (epoch 31.086), train_loss = 0.84815668, grad/param norm = 1.5154e-01, time/batch = 15.6722s	
20673/33250 (epoch 31.087), train_loss = 0.72635846, grad/param norm = 1.4841e-01, time/batch = 15.9241s	
20674/33250 (epoch 31.089), train_loss = 0.84890628, grad/param norm = 1.6214e-01, time/batch = 16.0117s	
20675/33250 (epoch 31.090), train_loss = 0.86256799, grad/param norm = 1.8155e-01, time/batch = 15.9095s	
20676/33250 (epoch 31.092), train_loss = 0.80449270, grad/param norm = 1.5087e-01, time/batch = 15.7549s	
20677/33250 (epoch 31.093), train_loss = 0.83482440, grad/param norm = 1.5915e-01, time/batch = 15.8556s	
20678/33250 (epoch 31.095), train_loss = 0.82612838, grad/param norm = 1.5801e-01, time/batch = 15.7657s	
20679/33250 (epoch 31.096), train_loss = 0.71216708, grad/param norm = 1.7692e-01, time/batch = 15.7030s	
20680/33250 (epoch 31.098), train_loss = 0.72234111, grad/param norm = 1.7578e-01, time/batch = 15.7146s	
20681/33250 (epoch 31.099), train_loss = 0.67053806, grad/param norm = 1.4419e-01, time/batch = 15.6273s	
20682/33250 (epoch 31.101), train_loss = 0.82658472, grad/param norm = 1.5448e-01, time/batch = 15.9185s	
20683/33250 (epoch 31.102), train_loss = 0.76293094, grad/param norm = 1.5074e-01, time/batch = 15.6035s	
20684/33250 (epoch 31.104), train_loss = 0.62932419, grad/param norm = 1.3076e-01, time/batch = 15.6079s	
20685/33250 (epoch 31.105), train_loss = 0.77848919, grad/param norm = 1.5913e-01, time/batch = 15.6156s	
20686/33250 (epoch 31.107), train_loss = 0.70658780, grad/param norm = 1.3131e-01, time/batch = 23.4541s	
20687/33250 (epoch 31.108), train_loss = 0.83142809, grad/param norm = 1.6536e-01, time/batch = 25.1953s	
20688/33250 (epoch 31.110), train_loss = 0.70250865, grad/param norm = 1.4607e-01, time/batch = 15.7624s	
20689/33250 (epoch 31.111), train_loss = 0.81250366, grad/param norm = 1.4987e-01, time/batch = 15.6237s	
20690/33250 (epoch 31.113), train_loss = 0.76431927, grad/param norm = 1.6744e-01, time/batch = 15.6315s	
20691/33250 (epoch 31.114), train_loss = 0.72577309, grad/param norm = 1.6390e-01, time/batch = 15.9374s	
20692/33250 (epoch 31.116), train_loss = 0.77725244, grad/param norm = 1.6882e-01, time/batch = 15.8565s	
20693/33250 (epoch 31.117), train_loss = 0.79270497, grad/param norm = 1.6672e-01, time/batch = 15.8544s	
20694/33250 (epoch 31.119), train_loss = 0.79866429, grad/param norm = 1.6349e-01, time/batch = 15.4341s	
20695/33250 (epoch 31.120), train_loss = 0.64639989, grad/param norm = 1.3263e-01, time/batch = 15.6781s	
20696/33250 (epoch 31.122), train_loss = 0.93154275, grad/param norm = 1.7409e-01, time/batch = 15.8351s	
20697/33250 (epoch 31.123), train_loss = 0.82521165, grad/param norm = 1.7858e-01, time/batch = 15.8429s	
20698/33250 (epoch 31.125), train_loss = 0.67688114, grad/param norm = 1.6655e-01, time/batch = 15.8258s	
20699/33250 (epoch 31.126), train_loss = 0.80523865, grad/param norm = 1.7952e-01, time/batch = 15.9748s	
20700/33250 (epoch 31.128), train_loss = 0.78082711, grad/param norm = 1.4673e-01, time/batch = 15.6752s	
20701/33250 (epoch 31.129), train_loss = 0.81130139, grad/param norm = 1.5590e-01, time/batch = 15.9248s	
20702/33250 (epoch 31.131), train_loss = 0.81785657, grad/param norm = 1.6268e-01, time/batch = 15.7710s	
20703/33250 (epoch 31.132), train_loss = 0.79208156, grad/param norm = 1.7849e-01, time/batch = 15.9386s	
20704/33250 (epoch 31.134), train_loss = 0.79471622, grad/param norm = 1.7144e-01, time/batch = 15.9287s	
20705/33250 (epoch 31.135), train_loss = 0.81101922, grad/param norm = 1.4711e-01, time/batch = 15.8446s	
20706/33250 (epoch 31.137), train_loss = 0.74632368, grad/param norm = 1.7123e-01, time/batch = 15.8649s	
20707/33250 (epoch 31.138), train_loss = 0.74077118, grad/param norm = 1.4294e-01, time/batch = 15.8419s	
20708/33250 (epoch 31.140), train_loss = 0.64911493, grad/param norm = 1.5785e-01, time/batch = 15.9102s	
20709/33250 (epoch 31.141), train_loss = 0.91415189, grad/param norm = 2.1794e-01, time/batch = 15.7625s	
20710/33250 (epoch 31.143), train_loss = 0.66882286, grad/param norm = 1.5323e-01, time/batch = 15.9215s	
20711/33250 (epoch 31.144), train_loss = 0.77860002, grad/param norm = 1.4206e-01, time/batch = 15.7775s	
20712/33250 (epoch 31.146), train_loss = 0.78386086, grad/param norm = 1.4907e-01, time/batch = 15.7712s	
20713/33250 (epoch 31.147), train_loss = 0.80990705, grad/param norm = 1.6141e-01, time/batch = 15.8548s	
20714/33250 (epoch 31.149), train_loss = 0.74314252, grad/param norm = 1.4660e-01, time/batch = 15.8466s	
20715/33250 (epoch 31.150), train_loss = 0.72184457, grad/param norm = 1.5287e-01, time/batch = 15.9928s	
20716/33250 (epoch 31.152), train_loss = 0.68972506, grad/param norm = 1.5741e-01, time/batch = 15.7519s	
20717/33250 (epoch 31.153), train_loss = 0.96656498, grad/param norm = 1.8215e-01, time/batch = 15.8357s	
20718/33250 (epoch 31.155), train_loss = 0.78676439, grad/param norm = 2.0465e-01, time/batch = 15.4377s	
20719/33250 (epoch 31.156), train_loss = 1.01133292, grad/param norm = 1.7698e-01, time/batch = 15.8878s	
20720/33250 (epoch 31.158), train_loss = 0.96448039, grad/param norm = 1.9640e-01, time/batch = 15.8397s	
20721/33250 (epoch 31.159), train_loss = 0.78318383, grad/param norm = 2.2952e-01, time/batch = 15.7000s	
20722/33250 (epoch 31.161), train_loss = 0.85150972, grad/param norm = 1.7965e-01, time/batch = 15.9343s	
20723/33250 (epoch 31.162), train_loss = 0.74067222, grad/param norm = 1.5418e-01, time/batch = 15.9258s	
20724/33250 (epoch 31.164), train_loss = 0.80957797, grad/param norm = 1.8520e-01, time/batch = 15.7019s	
20725/33250 (epoch 31.165), train_loss = 0.87367158, grad/param norm = 1.7733e-01, time/batch = 15.7647s	
20726/33250 (epoch 31.167), train_loss = 0.98395966, grad/param norm = 1.9196e-01, time/batch = 15.9923s	
20727/33250 (epoch 31.168), train_loss = 0.70086573, grad/param norm = 1.3819e-01, time/batch = 15.8509s	
20728/33250 (epoch 31.170), train_loss = 0.76729858, grad/param norm = 1.6124e-01, time/batch = 15.5272s	
20729/33250 (epoch 31.171), train_loss = 0.82854535, grad/param norm = 1.6106e-01, time/batch = 15.6640s	
20730/33250 (epoch 31.173), train_loss = 0.79270266, grad/param norm = 1.4601e-01, time/batch = 15.5984s	
20731/33250 (epoch 31.174), train_loss = 0.83484474, grad/param norm = 1.5058e-01, time/batch = 15.6953s	
20732/33250 (epoch 31.176), train_loss = 0.78560488, grad/param norm = 1.4989e-01, time/batch = 15.8548s	
20733/33250 (epoch 31.177), train_loss = 0.77334756, grad/param norm = 1.6099e-01, time/batch = 15.6870s	
20734/33250 (epoch 31.179), train_loss = 0.75272322, grad/param norm = 1.5282e-01, time/batch = 15.7733s	
20735/33250 (epoch 31.180), train_loss = 0.65645244, grad/param norm = 1.3436e-01, time/batch = 15.5271s	
20736/33250 (epoch 31.182), train_loss = 0.77006057, grad/param norm = 1.9885e-01, time/batch = 15.7597s	
20737/33250 (epoch 31.183), train_loss = 0.92018768, grad/param norm = 1.8066e-01, time/batch = 15.6031s	
20738/33250 (epoch 31.185), train_loss = 0.85380134, grad/param norm = 2.1718e-01, time/batch = 15.7647s	
20739/33250 (epoch 31.186), train_loss = 0.84447336, grad/param norm = 1.6746e-01, time/batch = 15.6177s	
20740/33250 (epoch 31.188), train_loss = 0.92731386, grad/param norm = 2.2475e-01, time/batch = 15.7615s	
20741/33250 (epoch 31.189), train_loss = 0.67990706, grad/param norm = 1.9085e-01, time/batch = 15.8407s	
20742/33250 (epoch 31.191), train_loss = 0.75886781, grad/param norm = 1.6613e-01, time/batch = 15.6856s	
20743/33250 (epoch 31.192), train_loss = 0.79748362, grad/param norm = 1.5000e-01, time/batch = 15.6787s	
20744/33250 (epoch 31.194), train_loss = 0.81951531, grad/param norm = 1.8562e-01, time/batch = 15.9978s	
20745/33250 (epoch 31.195), train_loss = 1.00196481, grad/param norm = 1.8282e-01, time/batch = 15.9264s	
20746/33250 (epoch 31.197), train_loss = 0.76149477, grad/param norm = 1.5864e-01, time/batch = 15.9106s	
20747/33250 (epoch 31.198), train_loss = 0.96568070, grad/param norm = 1.7830e-01, time/batch = 15.9187s	
20748/33250 (epoch 31.200), train_loss = 0.81346341, grad/param norm = 1.5952e-01, time/batch = 15.9118s	
20749/33250 (epoch 31.202), train_loss = 0.77079090, grad/param norm = 1.4281e-01, time/batch = 15.7500s	
20750/33250 (epoch 31.203), train_loss = 0.75917925, grad/param norm = 1.7956e-01, time/batch = 15.7508s	
20751/33250 (epoch 31.205), train_loss = 0.85368349, grad/param norm = 1.6218e-01, time/batch = 15.8344s	
20752/33250 (epoch 31.206), train_loss = 0.90837219, grad/param norm = 1.7277e-01, time/batch = 15.8376s	
20753/33250 (epoch 31.208), train_loss = 0.93440016, grad/param norm = 2.0593e-01, time/batch = 15.9255s	
20754/33250 (epoch 31.209), train_loss = 0.76508610, grad/param norm = 1.4585e-01, time/batch = 15.7657s	
20755/33250 (epoch 31.211), train_loss = 0.87228109, grad/param norm = 1.7760e-01, time/batch = 15.8259s	
20756/33250 (epoch 31.212), train_loss = 0.97655365, grad/param norm = 1.7692e-01, time/batch = 16.0064s	
20757/33250 (epoch 31.214), train_loss = 0.83098549, grad/param norm = 1.6030e-01, time/batch = 15.8381s	
20758/33250 (epoch 31.215), train_loss = 0.91329452, grad/param norm = 1.9856e-01, time/batch = 15.5989s	
20759/33250 (epoch 31.217), train_loss = 0.92324180, grad/param norm = 2.0406e-01, time/batch = 15.5165s	
20760/33250 (epoch 31.218), train_loss = 0.91457639, grad/param norm = 1.5735e-01, time/batch = 15.7465s	
20761/33250 (epoch 31.220), train_loss = 0.83563889, grad/param norm = 1.6615e-01, time/batch = 15.8323s	
20762/33250 (epoch 31.221), train_loss = 0.98927520, grad/param norm = 2.7699e-01, time/batch = 15.7604s	
20763/33250 (epoch 31.223), train_loss = 0.84377011, grad/param norm = 1.6277e-01, time/batch = 15.9266s	
20764/33250 (epoch 31.224), train_loss = 0.89870262, grad/param norm = 1.8238e-01, time/batch = 15.6845s	
20765/33250 (epoch 31.226), train_loss = 0.98307359, grad/param norm = 1.8123e-01, time/batch = 16.0180s	
20766/33250 (epoch 31.227), train_loss = 0.86067847, grad/param norm = 2.1942e-01, time/batch = 15.7661s	
20767/33250 (epoch 31.229), train_loss = 0.83043430, grad/param norm = 1.6713e-01, time/batch = 15.9045s	
20768/33250 (epoch 31.230), train_loss = 0.85274410, grad/param norm = 1.8610e-01, time/batch = 15.6763s	
20769/33250 (epoch 31.232), train_loss = 0.78364464, grad/param norm = 1.5641e-01, time/batch = 15.6805s	
20770/33250 (epoch 31.233), train_loss = 0.76098858, grad/param norm = 1.6455e-01, time/batch = 15.6757s	
20771/33250 (epoch 31.235), train_loss = 0.96154611, grad/param norm = 1.6472e-01, time/batch = 15.8366s	
20772/33250 (epoch 31.236), train_loss = 0.79314749, grad/param norm = 1.8112e-01, time/batch = 15.8504s	
20773/33250 (epoch 31.238), train_loss = 0.92201112, grad/param norm = 1.7053e-01, time/batch = 15.5988s	
20774/33250 (epoch 31.239), train_loss = 0.92680918, grad/param norm = 1.8513e-01, time/batch = 15.7508s	
20775/33250 (epoch 31.241), train_loss = 0.95186647, grad/param norm = 1.9057e-01, time/batch = 15.6580s	
20776/33250 (epoch 31.242), train_loss = 0.95431940, grad/param norm = 1.9991e-01, time/batch = 15.6799s	
20777/33250 (epoch 31.244), train_loss = 0.90769660, grad/param norm = 2.2982e-01, time/batch = 15.5281s	
20778/33250 (epoch 31.245), train_loss = 0.87249142, grad/param norm = 1.7878e-01, time/batch = 15.6075s	
20779/33250 (epoch 31.247), train_loss = 0.83988455, grad/param norm = 1.5100e-01, time/batch = 15.4986s	
20780/33250 (epoch 31.248), train_loss = 1.00120427, grad/param norm = 1.8936e-01, time/batch = 15.6571s	
20781/33250 (epoch 31.250), train_loss = 0.94076123, grad/param norm = 1.5352e-01, time/batch = 15.5206s	
20782/33250 (epoch 31.251), train_loss = 0.81238404, grad/param norm = 1.4966e-01, time/batch = 15.6122s	
20783/33250 (epoch 31.253), train_loss = 0.80120206, grad/param norm = 1.4572e-01, time/batch = 15.6797s	
20784/33250 (epoch 31.254), train_loss = 0.79209149, grad/param norm = 1.9058e-01, time/batch = 15.6165s	
20785/33250 (epoch 31.256), train_loss = 0.83417208, grad/param norm = 1.5911e-01, time/batch = 15.7620s	
20786/33250 (epoch 31.257), train_loss = 0.99632703, grad/param norm = 1.7728e-01, time/batch = 15.6859s	
20787/33250 (epoch 31.259), train_loss = 0.89492731, grad/param norm = 1.7776e-01, time/batch = 15.4548s	
20788/33250 (epoch 31.260), train_loss = 0.71700266, grad/param norm = 1.6597e-01, time/batch = 15.4516s	
20789/33250 (epoch 31.262), train_loss = 0.87064112, grad/param norm = 1.7114e-01, time/batch = 15.7425s	
20790/33250 (epoch 31.263), train_loss = 0.72460663, grad/param norm = 1.5741e-01, time/batch = 15.5880s	
20791/33250 (epoch 31.265), train_loss = 0.90893830, grad/param norm = 1.8862e-01, time/batch = 15.6864s	
20792/33250 (epoch 31.266), train_loss = 0.83449072, grad/param norm = 2.1435e-01, time/batch = 15.6132s	
20793/33250 (epoch 31.268), train_loss = 0.75354015, grad/param norm = 1.6220e-01, time/batch = 15.6057s	
20794/33250 (epoch 31.269), train_loss = 0.70527584, grad/param norm = 1.4762e-01, time/batch = 15.5930s	
20795/33250 (epoch 31.271), train_loss = 0.84465695, grad/param norm = 1.5654e-01, time/batch = 15.5380s	
20796/33250 (epoch 31.272), train_loss = 0.75104093, grad/param norm = 1.3935e-01, time/batch = 15.6137s	
20797/33250 (epoch 31.274), train_loss = 0.63014080, grad/param norm = 1.4563e-01, time/batch = 15.4627s	
20798/33250 (epoch 31.275), train_loss = 0.78515050, grad/param norm = 1.3615e-01, time/batch = 15.9728s	
20799/33250 (epoch 31.277), train_loss = 0.67426266, grad/param norm = 1.6991e-01, time/batch = 15.5069s	
20800/33250 (epoch 31.278), train_loss = 0.77159065, grad/param norm = 1.5756e-01, time/batch = 15.7543s	
20801/33250 (epoch 31.280), train_loss = 0.73101162, grad/param norm = 1.4576e-01, time/batch = 15.7552s	
20802/33250 (epoch 31.281), train_loss = 0.86495576, grad/param norm = 1.8660e-01, time/batch = 15.4453s	
20803/33250 (epoch 31.283), train_loss = 0.86927908, grad/param norm = 2.0619e-01, time/batch = 15.6632s	
20804/33250 (epoch 31.284), train_loss = 0.74911091, grad/param norm = 2.0389e-01, time/batch = 15.6088s	
20805/33250 (epoch 31.286), train_loss = 0.87579782, grad/param norm = 1.8368e-01, time/batch = 15.5972s	
20806/33250 (epoch 31.287), train_loss = 0.69670541, grad/param norm = 1.4973e-01, time/batch = 15.4262s	
20807/33250 (epoch 31.289), train_loss = 0.65434303, grad/param norm = 1.4923e-01, time/batch = 15.5241s	
20808/33250 (epoch 31.290), train_loss = 0.82166775, grad/param norm = 1.5347e-01, time/batch = 15.5335s	
20809/33250 (epoch 31.292), train_loss = 0.89595043, grad/param norm = 1.9745e-01, time/batch = 15.5301s	
20810/33250 (epoch 31.293), train_loss = 0.92256658, grad/param norm = 1.7929e-01, time/batch = 15.6805s	
20811/33250 (epoch 31.295), train_loss = 0.91198900, grad/param norm = 1.7066e-01, time/batch = 15.6207s	
20812/33250 (epoch 31.296), train_loss = 0.84074279, grad/param norm = 1.5991e-01, time/batch = 15.7472s	
20813/33250 (epoch 31.298), train_loss = 0.68417900, grad/param norm = 1.5936e-01, time/batch = 15.5848s	
20814/33250 (epoch 31.299), train_loss = 0.66624519, grad/param norm = 1.4632e-01, time/batch = 15.6877s	
20815/33250 (epoch 31.301), train_loss = 0.91671320, grad/param norm = 1.7719e-01, time/batch = 15.5131s	
20816/33250 (epoch 31.302), train_loss = 0.87977949, grad/param norm = 1.8183e-01, time/batch = 15.6176s	
20817/33250 (epoch 31.304), train_loss = 0.76787060, grad/param norm = 1.6289e-01, time/batch = 15.7743s	
20818/33250 (epoch 31.305), train_loss = 0.78194132, grad/param norm = 1.6789e-01, time/batch = 15.5393s	
20819/33250 (epoch 31.307), train_loss = 0.89469626, grad/param norm = 1.7379e-01, time/batch = 15.4691s	
20820/33250 (epoch 31.308), train_loss = 0.93183085, grad/param norm = 1.8434e-01, time/batch = 15.6229s	
20821/33250 (epoch 31.310), train_loss = 0.78079181, grad/param norm = 1.6544e-01, time/batch = 15.8493s	
20822/33250 (epoch 31.311), train_loss = 0.96638904, grad/param norm = 1.8197e-01, time/batch = 15.7710s	
20823/33250 (epoch 31.313), train_loss = 0.71256400, grad/param norm = 1.9511e-01, time/batch = 15.5215s	
20824/33250 (epoch 31.314), train_loss = 0.85403050, grad/param norm = 1.7794e-01, time/batch = 15.7573s	
20825/33250 (epoch 31.316), train_loss = 1.00667291, grad/param norm = 1.8977e-01, time/batch = 15.5938s	
20826/33250 (epoch 31.317), train_loss = 0.74300562, grad/param norm = 1.5156e-01, time/batch = 15.2781s	
20827/33250 (epoch 31.319), train_loss = 0.89862715, grad/param norm = 1.9804e-01, time/batch = 15.7678s	
20828/33250 (epoch 31.320), train_loss = 0.89397339, grad/param norm = 2.0137e-01, time/batch = 15.5395s	
20829/33250 (epoch 31.322), train_loss = 0.96184434, grad/param norm = 1.8814e-01, time/batch = 15.5357s	
20830/33250 (epoch 31.323), train_loss = 1.01395174, grad/param norm = 2.5934e-01, time/batch = 15.9832s	
20831/33250 (epoch 31.325), train_loss = 0.81510964, grad/param norm = 1.8991e-01, time/batch = 15.6129s	
20832/33250 (epoch 31.326), train_loss = 1.02215704, grad/param norm = 1.8956e-01, time/batch = 15.6001s	
20833/33250 (epoch 31.328), train_loss = 0.82504190, grad/param norm = 1.8242e-01, time/batch = 15.6858s	
20834/33250 (epoch 31.329), train_loss = 0.83428887, grad/param norm = 2.1541e-01, time/batch = 15.5280s	
20835/33250 (epoch 31.331), train_loss = 0.83829654, grad/param norm = 1.9423e-01, time/batch = 15.5318s	
20836/33250 (epoch 31.332), train_loss = 0.83402607, grad/param norm = 1.6087e-01, time/batch = 15.4397s	
20837/33250 (epoch 31.334), train_loss = 0.98574550, grad/param norm = 1.7174e-01, time/batch = 15.5217s	
20838/33250 (epoch 31.335), train_loss = 0.62904025, grad/param norm = 1.5282e-01, time/batch = 15.5349s	
20839/33250 (epoch 31.337), train_loss = 0.89055382, grad/param norm = 1.5807e-01, time/batch = 15.6215s	
20840/33250 (epoch 31.338), train_loss = 0.95312734, grad/param norm = 1.7380e-01, time/batch = 15.6972s	
20841/33250 (epoch 31.340), train_loss = 0.81905480, grad/param norm = 1.5246e-01, time/batch = 15.7832s	
20842/33250 (epoch 31.341), train_loss = 0.77602062, grad/param norm = 1.7678e-01, time/batch = 15.3659s	
20843/33250 (epoch 31.343), train_loss = 0.79378170, grad/param norm = 1.6365e-01, time/batch = 15.6642s	
20844/33250 (epoch 31.344), train_loss = 0.83128942, grad/param norm = 1.5779e-01, time/batch = 15.6007s	
20845/33250 (epoch 31.346), train_loss = 0.74055245, grad/param norm = 1.5436e-01, time/batch = 15.3571s	
20846/33250 (epoch 31.347), train_loss = 1.02842202, grad/param norm = 1.9519e-01, time/batch = 15.5139s	
20847/33250 (epoch 31.349), train_loss = 0.79525344, grad/param norm = 1.8386e-01, time/batch = 15.4319s	
20848/33250 (epoch 31.350), train_loss = 0.84050529, grad/param norm = 1.8656e-01, time/batch = 15.5084s	
20849/33250 (epoch 31.352), train_loss = 0.73475225, grad/param norm = 1.7865e-01, time/batch = 15.4741s	
20850/33250 (epoch 31.353), train_loss = 0.80749913, grad/param norm = 1.6479e-01, time/batch = 15.6113s	
20851/33250 (epoch 31.355), train_loss = 0.79620086, grad/param norm = 2.0251e-01, time/batch = 15.4401s	
20852/33250 (epoch 31.356), train_loss = 0.75974104, grad/param norm = 1.8180e-01, time/batch = 15.7649s	
20853/33250 (epoch 31.358), train_loss = 0.80714113, grad/param norm = 1.4930e-01, time/batch = 15.5143s	
20854/33250 (epoch 31.359), train_loss = 0.79944663, grad/param norm = 1.8213e-01, time/batch = 15.5954s	
20855/33250 (epoch 31.361), train_loss = 0.96247741, grad/param norm = 1.9796e-01, time/batch = 15.6849s	
20856/33250 (epoch 31.362), train_loss = 0.86146053, grad/param norm = 1.5473e-01, time/batch = 15.4381s	
20857/33250 (epoch 31.364), train_loss = 0.91184000, grad/param norm = 1.8050e-01, time/batch = 15.6020s	
20858/33250 (epoch 31.365), train_loss = 0.83654636, grad/param norm = 1.5566e-01, time/batch = 15.3558s	
20859/33250 (epoch 31.367), train_loss = 0.84676727, grad/param norm = 1.4879e-01, time/batch = 15.6856s	
20860/33250 (epoch 31.368), train_loss = 0.83321305, grad/param norm = 1.8042e-01, time/batch = 15.5449s	
20861/33250 (epoch 31.370), train_loss = 0.75229558, grad/param norm = 1.4411e-01, time/batch = 15.7812s	
20862/33250 (epoch 31.371), train_loss = 0.95362351, grad/param norm = 2.0313e-01, time/batch = 15.6853s	
20863/33250 (epoch 31.373), train_loss = 0.79934698, grad/param norm = 1.5491e-01, time/batch = 15.5999s	
20864/33250 (epoch 31.374), train_loss = 0.86064522, grad/param norm = 2.6233e-01, time/batch = 15.4456s	
20865/33250 (epoch 31.376), train_loss = 0.82003297, grad/param norm = 1.5448e-01, time/batch = 15.5162s	
20866/33250 (epoch 31.377), train_loss = 0.74761410, grad/param norm = 3.0126e-01, time/batch = 15.5258s	
20867/33250 (epoch 31.379), train_loss = 0.84152041, grad/param norm = 1.7584e-01, time/batch = 15.4276s	
20868/33250 (epoch 31.380), train_loss = 0.85864858, grad/param norm = 2.3403e-01, time/batch = 15.3581s	
20869/33250 (epoch 31.382), train_loss = 0.86888421, grad/param norm = 1.9486e-01, time/batch = 15.6631s	
20870/33250 (epoch 31.383), train_loss = 0.74416933, grad/param norm = 1.6357e-01, time/batch = 15.6892s	
20871/33250 (epoch 31.385), train_loss = 0.71098960, grad/param norm = 1.7551e-01, time/batch = 15.7700s	
20872/33250 (epoch 31.386), train_loss = 0.72223589, grad/param norm = 1.5534e-01, time/batch = 15.3850s	
20873/33250 (epoch 31.388), train_loss = 0.73456200, grad/param norm = 1.4839e-01, time/batch = 15.5299s	
20874/33250 (epoch 31.389), train_loss = 0.80131596, grad/param norm = 1.7944e-01, time/batch = 15.4342s	
20875/33250 (epoch 31.391), train_loss = 0.88569330, grad/param norm = 1.7283e-01, time/batch = 15.9063s	
20876/33250 (epoch 31.392), train_loss = 0.91283331, grad/param norm = 1.7883e-01, time/batch = 15.7597s	
20877/33250 (epoch 31.394), train_loss = 0.91658420, grad/param norm = 1.8261e-01, time/batch = 15.8981s	
20878/33250 (epoch 31.395), train_loss = 0.91298297, grad/param norm = 1.7547e-01, time/batch = 15.5969s	
20879/33250 (epoch 31.397), train_loss = 0.93772975, grad/param norm = 1.7376e-01, time/batch = 15.4424s	
20880/33250 (epoch 31.398), train_loss = 0.75438796, grad/param norm = 1.4954e-01, time/batch = 15.5994s	
20881/33250 (epoch 31.400), train_loss = 0.73574516, grad/param norm = 1.5317e-01, time/batch = 15.8526s	
20882/33250 (epoch 31.402), train_loss = 0.70517270, grad/param norm = 1.7161e-01, time/batch = 15.5046s	
20883/33250 (epoch 31.403), train_loss = 0.81027573, grad/param norm = 1.8292e-01, time/batch = 15.3823s	
20884/33250 (epoch 31.405), train_loss = 0.75724111, grad/param norm = 1.3976e-01, time/batch = 15.3672s	
20885/33250 (epoch 31.406), train_loss = 0.81983987, grad/param norm = 1.7545e-01, time/batch = 15.7430s	
20886/33250 (epoch 31.408), train_loss = 0.98729321, grad/param norm = 1.8339e-01, time/batch = 16.1357s	
20887/33250 (epoch 31.409), train_loss = 0.87893848, grad/param norm = 2.0845e-01, time/batch = 15.6812s	
20888/33250 (epoch 31.411), train_loss = 0.60600132, grad/param norm = 1.2497e-01, time/batch = 15.3678s	
20889/33250 (epoch 31.412), train_loss = 0.69734708, grad/param norm = 1.9121e-01, time/batch = 15.6044s	
20890/33250 (epoch 31.414), train_loss = 0.86338834, grad/param norm = 1.6184e-01, time/batch = 15.7667s	
20891/33250 (epoch 31.415), train_loss = 0.90803637, grad/param norm = 1.9452e-01, time/batch = 15.4512s	
20892/33250 (epoch 31.417), train_loss = 0.92577747, grad/param norm = 1.7359e-01, time/batch = 15.7144s	
20893/33250 (epoch 31.418), train_loss = 1.05418108, grad/param norm = 1.8212e-01, time/batch = 15.7330s	
20894/33250 (epoch 31.420), train_loss = 0.91116734, grad/param norm = 1.6767e-01, time/batch = 15.9436s	
20895/33250 (epoch 31.421), train_loss = 0.77690606, grad/param norm = 1.6439e-01, time/batch = 15.6292s	
20896/33250 (epoch 31.423), train_loss = 0.87915410, grad/param norm = 1.8562e-01, time/batch = 15.5198s	
20897/33250 (epoch 31.424), train_loss = 0.96172383, grad/param norm = 2.4386e-01, time/batch = 15.5362s	
20898/33250 (epoch 31.426), train_loss = 0.79040644, grad/param norm = 1.4777e-01, time/batch = 16.0567s	
20899/33250 (epoch 31.427), train_loss = 0.77461590, grad/param norm = 1.9411e-01, time/batch = 15.7568s	
20900/33250 (epoch 31.429), train_loss = 0.88815722, grad/param norm = 2.0048e-01, time/batch = 15.6834s	
20901/33250 (epoch 31.430), train_loss = 0.78891535, grad/param norm = 1.7820e-01, time/batch = 15.9066s	
20902/33250 (epoch 31.432), train_loss = 0.89846604, grad/param norm = 1.6135e-01, time/batch = 16.2242s	
20903/33250 (epoch 31.433), train_loss = 0.76244446, grad/param norm = 1.6069e-01, time/batch = 15.9336s	
20904/33250 (epoch 31.435), train_loss = 0.93431206, grad/param norm = 1.7602e-01, time/batch = 15.8594s	
20905/33250 (epoch 31.436), train_loss = 0.77988954, grad/param norm = 1.8045e-01, time/batch = 15.9398s	
20906/33250 (epoch 31.438), train_loss = 0.91873647, grad/param norm = 1.7672e-01, time/batch = 15.6053s	
20907/33250 (epoch 31.439), train_loss = 0.84545524, grad/param norm = 1.4997e-01, time/batch = 15.8220s	
20908/33250 (epoch 31.441), train_loss = 0.82781350, grad/param norm = 1.5073e-01, time/batch = 16.1188s	
20909/33250 (epoch 31.442), train_loss = 0.75845800, grad/param norm = 1.5868e-01, time/batch = 15.9260s	
20910/33250 (epoch 31.444), train_loss = 0.79384721, grad/param norm = 1.5992e-01, time/batch = 15.5409s	
20911/33250 (epoch 31.445), train_loss = 0.84026031, grad/param norm = 1.3993e-01, time/batch = 15.6974s	
20912/33250 (epoch 31.447), train_loss = 0.74377974, grad/param norm = 1.6414e-01, time/batch = 15.4570s	
20913/33250 (epoch 31.448), train_loss = 0.85906573, grad/param norm = 1.5171e-01, time/batch = 30.3448s	
20914/33250 (epoch 31.450), train_loss = 0.94326290, grad/param norm = 1.7769e-01, time/batch = 15.9419s	
20915/33250 (epoch 31.451), train_loss = 0.89505794, grad/param norm = 2.0768e-01, time/batch = 15.9197s	
20916/33250 (epoch 31.453), train_loss = 0.75462410, grad/param norm = 1.3634e-01, time/batch = 16.0621s	
20917/33250 (epoch 31.454), train_loss = 0.96675349, grad/param norm = 1.7169e-01, time/batch = 15.9993s	
20918/33250 (epoch 31.456), train_loss = 0.95970922, grad/param norm = 1.4519e-01, time/batch = 15.8930s	
20919/33250 (epoch 31.457), train_loss = 0.78138493, grad/param norm = 1.8439e-01, time/batch = 15.9066s	
20920/33250 (epoch 31.459), train_loss = 0.89799031, grad/param norm = 1.6412e-01, time/batch = 16.2011s	
20921/33250 (epoch 31.460), train_loss = 0.92234227, grad/param norm = 1.8310e-01, time/batch = 15.6988s	
20922/33250 (epoch 31.462), train_loss = 0.82098428, grad/param norm = 1.5221e-01, time/batch = 15.6472s	
20923/33250 (epoch 31.463), train_loss = 0.76676367, grad/param norm = 1.3483e-01, time/batch = 16.0162s	
20924/33250 (epoch 31.465), train_loss = 0.69687271, grad/param norm = 1.3845e-01, time/batch = 15.6406s	
20925/33250 (epoch 31.466), train_loss = 0.66785953, grad/param norm = 1.3082e-01, time/batch = 15.4032s	
20926/33250 (epoch 31.468), train_loss = 0.72203347, grad/param norm = 1.3694e-01, time/batch = 15.5406s	
20927/33250 (epoch 31.469), train_loss = 0.79950955, grad/param norm = 1.6423e-01, time/batch = 15.8512s	
20928/33250 (epoch 31.471), train_loss = 0.89381371, grad/param norm = 1.5284e-01, time/batch = 15.6669s	
20929/33250 (epoch 31.472), train_loss = 0.77347535, grad/param norm = 1.7285e-01, time/batch = 15.3725s	
20930/33250 (epoch 31.474), train_loss = 0.93490065, grad/param norm = 1.7011e-01, time/batch = 15.6666s	
20931/33250 (epoch 31.475), train_loss = 0.86891729, grad/param norm = 1.7725e-01, time/batch = 16.1355s	
20932/33250 (epoch 31.477), train_loss = 0.83634018, grad/param norm = 1.6523e-01, time/batch = 15.2046s	
20933/33250 (epoch 31.478), train_loss = 0.74126495, grad/param norm = 1.6548e-01, time/batch = 15.6039s	
20934/33250 (epoch 31.480), train_loss = 0.95151552, grad/param norm = 1.5915e-01, time/batch = 15.1286s	
20935/33250 (epoch 31.481), train_loss = 0.83571193, grad/param norm = 1.6805e-01, time/batch = 15.8178s	
20936/33250 (epoch 31.483), train_loss = 0.81003339, grad/param norm = 1.5118e-01, time/batch = 15.8941s	
20937/33250 (epoch 31.484), train_loss = 0.75657986, grad/param norm = 1.4373e-01, time/batch = 15.5087s	
20938/33250 (epoch 31.486), train_loss = 0.72226712, grad/param norm = 1.5430e-01, time/batch = 15.3508s	
20939/33250 (epoch 31.487), train_loss = 0.78724430, grad/param norm = 1.5954e-01, time/batch = 15.1933s	
20940/33250 (epoch 31.489), train_loss = 0.93682809, grad/param norm = 2.1992e-01, time/batch = 15.2611s	
20941/33250 (epoch 31.490), train_loss = 0.88168605, grad/param norm = 1.9183e-01, time/batch = 15.1637s	
20942/33250 (epoch 31.492), train_loss = 0.92423295, grad/param norm = 1.7846e-01, time/batch = 15.6418s	
20943/33250 (epoch 31.493), train_loss = 0.82977239, grad/param norm = 1.7904e-01, time/batch = 15.0365s	
20944/33250 (epoch 31.495), train_loss = 0.89135854, grad/param norm = 1.5584e-01, time/batch = 15.1858s	
20945/33250 (epoch 31.496), train_loss = 0.84445119, grad/param norm = 1.4311e-01, time/batch = 15.4264s	
20946/33250 (epoch 31.498), train_loss = 0.92017833, grad/param norm = 1.6852e-01, time/batch = 15.6464s	
20947/33250 (epoch 31.499), train_loss = 0.78776987, grad/param norm = 1.4235e-01, time/batch = 14.7872s	
20948/33250 (epoch 31.501), train_loss = 0.77440317, grad/param norm = 1.7587e-01, time/batch = 14.4693s	
20949/33250 (epoch 31.502), train_loss = 0.79717250, grad/param norm = 1.5186e-01, time/batch = 14.6444s	
20950/33250 (epoch 31.504), train_loss = 0.95574131, grad/param norm = 1.8511e-01, time/batch = 15.0234s	
20951/33250 (epoch 31.505), train_loss = 0.70082539, grad/param norm = 1.2747e-01, time/batch = 14.7136s	
20952/33250 (epoch 31.507), train_loss = 0.75960607, grad/param norm = 1.6940e-01, time/batch = 14.3938s	
20953/33250 (epoch 31.508), train_loss = 0.79308746, grad/param norm = 1.5010e-01, time/batch = 14.6161s	
20954/33250 (epoch 31.510), train_loss = 0.68818726, grad/param norm = 1.4109e-01, time/batch = 14.3932s	
20955/33250 (epoch 31.511), train_loss = 0.81201995, grad/param norm = 1.6513e-01, time/batch = 14.3223s	
20956/33250 (epoch 31.513), train_loss = 0.93726917, grad/param norm = 1.5492e-01, time/batch = 14.7886s	
20957/33250 (epoch 31.514), train_loss = 0.81414078, grad/param norm = 1.7264e-01, time/batch = 14.5631s	
20958/33250 (epoch 31.516), train_loss = 0.78063880, grad/param norm = 1.7587e-01, time/batch = 14.4794s	
20959/33250 (epoch 31.517), train_loss = 0.80537524, grad/param norm = 1.6886e-01, time/batch = 14.4708s	
20960/33250 (epoch 31.519), train_loss = 0.72258380, grad/param norm = 1.2376e-01, time/batch = 14.0534s	
20961/33250 (epoch 31.520), train_loss = 1.01510317, grad/param norm = 2.2673e-01, time/batch = 14.3904s	
20962/33250 (epoch 31.522), train_loss = 0.88454522, grad/param norm = 1.8728e-01, time/batch = 14.6246s	
20963/33250 (epoch 31.523), train_loss = 0.76783954, grad/param norm = 1.6232e-01, time/batch = 14.7854s	
20964/33250 (epoch 31.525), train_loss = 0.70835169, grad/param norm = 1.6158e-01, time/batch = 14.5515s	
20965/33250 (epoch 31.526), train_loss = 0.73926517, grad/param norm = 1.4787e-01, time/batch = 14.6176s	
20966/33250 (epoch 31.528), train_loss = 0.78071319, grad/param norm = 1.5284e-01, time/batch = 14.5522s	
20967/33250 (epoch 31.529), train_loss = 0.77864337, grad/param norm = 1.9932e-01, time/batch = 15.4255s	
20968/33250 (epoch 31.531), train_loss = 0.73649078, grad/param norm = 1.4699e-01, time/batch = 15.8158s	
20969/33250 (epoch 31.532), train_loss = 0.88122712, grad/param norm = 1.5432e-01, time/batch = 15.2911s	
20970/33250 (epoch 31.534), train_loss = 0.73559282, grad/param norm = 1.4041e-01, time/batch = 15.2691s	
20971/33250 (epoch 31.535), train_loss = 0.80711290, grad/param norm = 1.5218e-01, time/batch = 15.2746s	
20972/33250 (epoch 31.537), train_loss = 0.83234151, grad/param norm = 1.5022e-01, time/batch = 15.0933s	
20973/33250 (epoch 31.538), train_loss = 0.88112218, grad/param norm = 1.7190e-01, time/batch = 15.5594s	
20974/33250 (epoch 31.540), train_loss = 0.95355513, grad/param norm = 1.4462e-01, time/batch = 15.6357s	
20975/33250 (epoch 31.541), train_loss = 0.89662239, grad/param norm = 1.8544e-01, time/batch = 15.5473s	
20976/33250 (epoch 31.543), train_loss = 0.86624941, grad/param norm = 1.6083e-01, time/batch = 14.9434s	
20977/33250 (epoch 31.544), train_loss = 0.75051760, grad/param norm = 1.6949e-01, time/batch = 14.7995s	
20978/33250 (epoch 31.546), train_loss = 0.79561984, grad/param norm = 1.7591e-01, time/batch = 15.5101s	
20979/33250 (epoch 31.547), train_loss = 0.79958058, grad/param norm = 1.6747e-01, time/batch = 15.3381s	
20980/33250 (epoch 31.549), train_loss = 0.84414793, grad/param norm = 1.8054e-01, time/batch = 14.8626s	
20981/33250 (epoch 31.550), train_loss = 0.78042097, grad/param norm = 1.4450e-01, time/batch = 14.7169s	
20982/33250 (epoch 31.552), train_loss = 0.87808721, grad/param norm = 1.6562e-01, time/batch = 14.8517s	
20983/33250 (epoch 31.553), train_loss = 0.80796820, grad/param norm = 1.5094e-01, time/batch = 14.2908s	
20984/33250 (epoch 31.555), train_loss = 0.84853142, grad/param norm = 1.7196e-01, time/batch = 14.4642s	
20985/33250 (epoch 31.556), train_loss = 0.84773353, grad/param norm = 1.8392e-01, time/batch = 15.1627s	
20986/33250 (epoch 31.558), train_loss = 0.88596317, grad/param norm = 1.7511e-01, time/batch = 14.8550s	
20987/33250 (epoch 31.559), train_loss = 0.76504456, grad/param norm = 1.6338e-01, time/batch = 15.0889s	
20988/33250 (epoch 31.561), train_loss = 0.73601682, grad/param norm = 1.5293e-01, time/batch = 14.3288s	
20989/33250 (epoch 31.562), train_loss = 0.84937090, grad/param norm = 1.8398e-01, time/batch = 14.4881s	
20990/33250 (epoch 31.564), train_loss = 0.99643010, grad/param norm = 1.9969e-01, time/batch = 14.7027s	
20991/33250 (epoch 31.565), train_loss = 0.94879118, grad/param norm = 1.9344e-01, time/batch = 14.0739s	
20992/33250 (epoch 31.567), train_loss = 0.94487392, grad/param norm = 1.7722e-01, time/batch = 14.4562s	
20993/33250 (epoch 31.568), train_loss = 0.78490502, grad/param norm = 1.5401e-01, time/batch = 14.2957s	
20994/33250 (epoch 31.570), train_loss = 0.90419310, grad/param norm = 1.9579e-01, time/batch = 14.7802s	
20995/33250 (epoch 31.571), train_loss = 0.95969424, grad/param norm = 1.7465e-01, time/batch = 14.7863s	
20996/33250 (epoch 31.573), train_loss = 0.89399855, grad/param norm = 1.6499e-01, time/batch = 14.4483s	
20997/33250 (epoch 31.574), train_loss = 0.77837261, grad/param norm = 1.5211e-01, time/batch = 15.2663s	
20998/33250 (epoch 31.576), train_loss = 0.88928572, grad/param norm = 1.7362e-01, time/batch = 14.8615s	
20999/33250 (epoch 31.577), train_loss = 0.82842713, grad/param norm = 1.4768e-01, time/batch = 16.6246s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch31.58_1.6062.t7	
21000/33250 (epoch 31.579), train_loss = 0.72734423, grad/param norm = 1.5112e-01, time/batch = 17.7030s	
21001/33250 (epoch 31.580), train_loss = 1.16523308, grad/param norm = 1.9851e-01, time/batch = 16.9377s	
21002/33250 (epoch 31.582), train_loss = 0.80301492, grad/param norm = 1.5973e-01, time/batch = 17.4389s	
21003/33250 (epoch 31.583), train_loss = 0.91020369, grad/param norm = 1.6824e-01, time/batch = 15.5350s	
21004/33250 (epoch 31.585), train_loss = 0.93417258, grad/param norm = 1.5927e-01, time/batch = 17.0128s	
21005/33250 (epoch 31.586), train_loss = 0.78882542, grad/param norm = 1.7752e-01, time/batch = 16.5901s	
21006/33250 (epoch 31.588), train_loss = 0.87380606, grad/param norm = 1.6577e-01, time/batch = 15.6619s	
21007/33250 (epoch 31.589), train_loss = 0.85290294, grad/param norm = 1.7997e-01, time/batch = 16.7279s	
21008/33250 (epoch 31.591), train_loss = 0.81728818, grad/param norm = 1.8686e-01, time/batch = 15.5003s	
21009/33250 (epoch 31.592), train_loss = 0.80428121, grad/param norm = 1.7327e-01, time/batch = 18.5740s	
21010/33250 (epoch 31.594), train_loss = 0.95043675, grad/param norm = 1.7889e-01, time/batch = 18.4334s	
21011/33250 (epoch 31.595), train_loss = 0.81550043, grad/param norm = 1.5266e-01, time/batch = 17.0246s	
21012/33250 (epoch 31.597), train_loss = 0.70034400, grad/param norm = 1.3936e-01, time/batch = 19.6161s	
21013/33250 (epoch 31.598), train_loss = 0.79612924, grad/param norm = 1.7952e-01, time/batch = 16.2959s	
21014/33250 (epoch 31.600), train_loss = 0.79839892, grad/param norm = 1.7984e-01, time/batch = 16.5862s	
21015/33250 (epoch 31.602), train_loss = 0.86603271, grad/param norm = 1.9468e-01, time/batch = 15.7595s	
21016/33250 (epoch 31.603), train_loss = 0.88802913, grad/param norm = 1.7289e-01, time/batch = 16.4256s	
21017/33250 (epoch 31.605), train_loss = 0.82720906, grad/param norm = 1.6061e-01, time/batch = 15.8391s	
21018/33250 (epoch 31.606), train_loss = 0.89560589, grad/param norm = 1.9090e-01, time/batch = 16.3244s	
21019/33250 (epoch 31.608), train_loss = 0.85874683, grad/param norm = 1.6368e-01, time/batch = 15.4038s	
21020/33250 (epoch 31.609), train_loss = 0.74653290, grad/param norm = 1.5630e-01, time/batch = 14.6047s	
21021/33250 (epoch 31.611), train_loss = 0.81966355, grad/param norm = 1.8414e-01, time/batch = 14.4803s	
21022/33250 (epoch 31.612), train_loss = 0.80785979, grad/param norm = 1.6777e-01, time/batch = 14.4770s	
21023/33250 (epoch 31.614), train_loss = 1.03167928, grad/param norm = 1.8082e-01, time/batch = 15.1955s	
21024/33250 (epoch 31.615), train_loss = 0.94806924, grad/param norm = 1.8066e-01, time/batch = 15.2690s	
21025/33250 (epoch 31.617), train_loss = 1.05272048, grad/param norm = 1.9439e-01, time/batch = 15.0151s	
21026/33250 (epoch 31.618), train_loss = 1.07491515, grad/param norm = 2.1848e-01, time/batch = 14.9453s	
21027/33250 (epoch 31.620), train_loss = 0.94596542, grad/param norm = 2.0195e-01, time/batch = 14.8258s	
21028/33250 (epoch 31.621), train_loss = 0.88747605, grad/param norm = 1.6767e-01, time/batch = 14.3114s	
21029/33250 (epoch 31.623), train_loss = 0.77941599, grad/param norm = 1.7155e-01, time/batch = 14.1422s	
21030/33250 (epoch 31.624), train_loss = 0.83046046, grad/param norm = 2.1782e-01, time/batch = 14.3870s	
21031/33250 (epoch 31.626), train_loss = 0.81173631, grad/param norm = 1.8731e-01, time/batch = 14.7857s	
21032/33250 (epoch 31.627), train_loss = 0.81603846, grad/param norm = 1.7189e-01, time/batch = 14.4108s	
21033/33250 (epoch 31.629), train_loss = 0.87457032, grad/param norm = 1.8618e-01, time/batch = 14.1551s	
21034/33250 (epoch 31.630), train_loss = 0.81130982, grad/param norm = 1.9091e-01, time/batch = 14.4840s	
21035/33250 (epoch 31.632), train_loss = 0.73574689, grad/param norm = 1.5114e-01, time/batch = 15.0225s	
21036/33250 (epoch 31.633), train_loss = 0.84723194, grad/param norm = 1.7926e-01, time/batch = 14.7205s	
21037/33250 (epoch 31.635), train_loss = 0.78492022, grad/param norm = 1.6832e-01, time/batch = 15.3261s	
21038/33250 (epoch 31.636), train_loss = 0.77976054, grad/param norm = 1.6372e-01, time/batch = 15.6906s	
21039/33250 (epoch 31.638), train_loss = 0.75461512, grad/param norm = 1.5577e-01, time/batch = 15.1034s	
21040/33250 (epoch 31.639), train_loss = 0.73827650, grad/param norm = 1.8004e-01, time/batch = 14.5401s	
21041/33250 (epoch 31.641), train_loss = 0.82996194, grad/param norm = 1.8592e-01, time/batch = 15.0346s	
21042/33250 (epoch 31.642), train_loss = 0.64623983, grad/param norm = 1.6850e-01, time/batch = 14.8011s	
21043/33250 (epoch 31.644), train_loss = 0.58784988, grad/param norm = 1.5368e-01, time/batch = 14.7425s	
21044/33250 (epoch 31.645), train_loss = 0.86061571, grad/param norm = 1.8492e-01, time/batch = 14.4940s	
21045/33250 (epoch 31.647), train_loss = 0.71903344, grad/param norm = 1.6018e-01, time/batch = 14.6388s	
21046/33250 (epoch 31.648), train_loss = 0.72100270, grad/param norm = 1.6581e-01, time/batch = 14.5694s	
21047/33250 (epoch 31.650), train_loss = 0.96406043, grad/param norm = 1.9981e-01, time/batch = 14.7891s	
21048/33250 (epoch 31.651), train_loss = 0.88763074, grad/param norm = 2.0145e-01, time/batch = 14.3864s	
21049/33250 (epoch 31.653), train_loss = 0.77322928, grad/param norm = 1.7629e-01, time/batch = 14.6171s	
21050/33250 (epoch 31.654), train_loss = 0.83464920, grad/param norm = 1.5318e-01, time/batch = 14.8543s	
21051/33250 (epoch 31.656), train_loss = 0.86461144, grad/param norm = 1.6977e-01, time/batch = 15.1872s	
21052/33250 (epoch 31.657), train_loss = 0.66611444, grad/param norm = 1.7373e-01, time/batch = 14.5375s	
21053/33250 (epoch 31.659), train_loss = 0.78370826, grad/param norm = 1.7816e-01, time/batch = 14.6286s	
21054/33250 (epoch 31.660), train_loss = 0.83368013, grad/param norm = 1.8060e-01, time/batch = 14.5616s	
21055/33250 (epoch 31.662), train_loss = 0.84821533, grad/param norm = 1.7167e-01, time/batch = 14.9599s	
21056/33250 (epoch 31.663), train_loss = 0.75926613, grad/param norm = 1.7538e-01, time/batch = 14.2582s	
21057/33250 (epoch 31.665), train_loss = 0.86287325, grad/param norm = 1.7075e-01, time/batch = 14.2555s	
21058/33250 (epoch 31.666), train_loss = 0.80300073, grad/param norm = 1.6164e-01, time/batch = 14.1703s	
21059/33250 (epoch 31.668), train_loss = 0.92350246, grad/param norm = 1.6505e-01, time/batch = 14.8473s	
21060/33250 (epoch 31.669), train_loss = 0.82818618, grad/param norm = 1.6562e-01, time/batch = 14.4571s	
21061/33250 (epoch 31.671), train_loss = 0.74313496, grad/param norm = 2.0534e-01, time/batch = 14.2971s	
21062/33250 (epoch 31.672), train_loss = 0.91271467, grad/param norm = 1.8257e-01, time/batch = 14.3076s	
21063/33250 (epoch 31.674), train_loss = 0.74110311, grad/param norm = 1.5402e-01, time/batch = 14.7784s	
21064/33250 (epoch 31.675), train_loss = 0.83457742, grad/param norm = 1.4158e-01, time/batch = 14.3738s	
21065/33250 (epoch 31.677), train_loss = 0.90283667, grad/param norm = 1.7217e-01, time/batch = 14.0633s	
21066/33250 (epoch 31.678), train_loss = 0.79808827, grad/param norm = 1.8247e-01, time/batch = 14.8750s	
21067/33250 (epoch 31.680), train_loss = 0.93877905, grad/param norm = 1.8092e-01, time/batch = 14.9415s	
21068/33250 (epoch 31.681), train_loss = 0.73972288, grad/param norm = 1.4289e-01, time/batch = 14.1599s	
21069/33250 (epoch 31.683), train_loss = 0.77368266, grad/param norm = 1.7068e-01, time/batch = 14.1739s	
21070/33250 (epoch 31.684), train_loss = 0.71471501, grad/param norm = 1.7611e-01, time/batch = 14.5366s	
21071/33250 (epoch 31.686), train_loss = 0.74224023, grad/param norm = 1.5494e-01, time/batch = 14.9276s	
21072/33250 (epoch 31.687), train_loss = 0.84382176, grad/param norm = 1.7562e-01, time/batch = 15.0813s	
21073/33250 (epoch 31.689), train_loss = 0.72328918, grad/param norm = 1.5903e-01, time/batch = 14.2892s	
21074/33250 (epoch 31.690), train_loss = 0.85128399, grad/param norm = 1.7944e-01, time/batch = 14.8435s	
21075/33250 (epoch 31.692), train_loss = 0.78270827, grad/param norm = 1.5202e-01, time/batch = 14.2232s	
21076/33250 (epoch 31.693), train_loss = 0.89039453, grad/param norm = 1.6457e-01, time/batch = 14.2199s	
21077/33250 (epoch 31.695), train_loss = 0.85793265, grad/param norm = 1.6855e-01, time/batch = 14.3081s	
21078/33250 (epoch 31.696), train_loss = 0.87809275, grad/param norm = 1.6824e-01, time/batch = 14.2429s	
21079/33250 (epoch 31.698), train_loss = 0.78406286, grad/param norm = 1.6060e-01, time/batch = 14.3986s	
21080/33250 (epoch 31.699), train_loss = 1.02964106, grad/param norm = 1.7155e-01, time/batch = 14.8475s	
21081/33250 (epoch 31.701), train_loss = 0.81020810, grad/param norm = 1.3728e-01, time/batch = 14.8511s	
21082/33250 (epoch 31.702), train_loss = 0.79202992, grad/param norm = 2.4334e-01, time/batch = 14.7906s	
21083/33250 (epoch 31.704), train_loss = 0.99211214, grad/param norm = 1.9003e-01, time/batch = 14.6090s	
21084/33250 (epoch 31.705), train_loss = 0.77789518, grad/param norm = 1.5168e-01, time/batch = 14.9380s	
21085/33250 (epoch 31.707), train_loss = 0.69673858, grad/param norm = 1.6561e-01, time/batch = 14.2960s	
21086/33250 (epoch 31.708), train_loss = 0.90434044, grad/param norm = 1.7450e-01, time/batch = 14.7752s	
21087/33250 (epoch 31.710), train_loss = 0.86317838, grad/param norm = 1.7385e-01, time/batch = 14.4624s	
21088/33250 (epoch 31.711), train_loss = 0.73417257, grad/param norm = 1.6174e-01, time/batch = 14.2130s	
21089/33250 (epoch 31.713), train_loss = 0.87001802, grad/param norm = 1.5935e-01, time/batch = 14.2940s	
21090/33250 (epoch 31.714), train_loss = 0.83265599, grad/param norm = 1.7069e-01, time/batch = 13.8431s	
21091/33250 (epoch 31.716), train_loss = 0.84228128, grad/param norm = 1.6325e-01, time/batch = 14.2304s	
21092/33250 (epoch 31.717), train_loss = 0.76017061, grad/param norm = 1.3409e-01, time/batch = 14.3932s	
21093/33250 (epoch 31.719), train_loss = 0.79133782, grad/param norm = 1.7662e-01, time/batch = 14.1444s	
21094/33250 (epoch 31.720), train_loss = 1.05891277, grad/param norm = 1.9137e-01, time/batch = 14.4649s	
21095/33250 (epoch 31.722), train_loss = 0.71426762, grad/param norm = 1.4688e-01, time/batch = 14.3791s	
21096/33250 (epoch 31.723), train_loss = 0.65749073, grad/param norm = 1.4159e-01, time/batch = 15.2623s	
21097/33250 (epoch 31.725), train_loss = 0.77490812, grad/param norm = 1.3428e-01, time/batch = 15.0779s	
21098/33250 (epoch 31.726), train_loss = 0.82158032, grad/param norm = 1.6786e-01, time/batch = 14.7839s	
21099/33250 (epoch 31.728), train_loss = 0.85504333, grad/param norm = 1.7418e-01, time/batch = 14.8607s	
21100/33250 (epoch 31.729), train_loss = 0.88872639, grad/param norm = 1.5672e-01, time/batch = 15.2215s	
21101/33250 (epoch 31.731), train_loss = 0.75202097, grad/param norm = 1.8715e-01, time/batch = 14.5771s	
21102/33250 (epoch 31.732), train_loss = 0.73831578, grad/param norm = 1.4199e-01, time/batch = 14.6272s	
21103/33250 (epoch 31.734), train_loss = 0.85629545, grad/param norm = 2.1160e-01, time/batch = 14.5636s	
21104/33250 (epoch 31.735), train_loss = 0.85738355, grad/param norm = 1.8730e-01, time/batch = 14.8243s	
21105/33250 (epoch 31.737), train_loss = 0.79871385, grad/param norm = 1.5897e-01, time/batch = 14.4033s	
21106/33250 (epoch 31.738), train_loss = 0.86896797, grad/param norm = 1.6052e-01, time/batch = 14.6266s	
21107/33250 (epoch 31.740), train_loss = 0.86618970, grad/param norm = 1.7568e-01, time/batch = 14.6187s	
21108/33250 (epoch 31.741), train_loss = 0.89023927, grad/param norm = 1.6773e-01, time/batch = 14.7844s	
21109/33250 (epoch 31.743), train_loss = 0.77287874, grad/param norm = 1.4545e-01, time/batch = 14.7769s	
21110/33250 (epoch 31.744), train_loss = 0.78990149, grad/param norm = 1.5899e-01, time/batch = 14.5385s	
21111/33250 (epoch 31.746), train_loss = 0.74074451, grad/param norm = 1.5402e-01, time/batch = 14.5543s	
21112/33250 (epoch 31.747), train_loss = 0.76430150, grad/param norm = 1.5897e-01, time/batch = 14.6403s	
21113/33250 (epoch 31.749), train_loss = 0.93286876, grad/param norm = 1.6729e-01, time/batch = 14.5670s	
21114/33250 (epoch 31.750), train_loss = 0.91963930, grad/param norm = 1.8380e-01, time/batch = 14.6418s	
21115/33250 (epoch 31.752), train_loss = 0.79240728, grad/param norm = 1.5269e-01, time/batch = 14.9575s	
21116/33250 (epoch 31.753), train_loss = 0.77567705, grad/param norm = 1.6372e-01, time/batch = 14.9433s	
21117/33250 (epoch 31.755), train_loss = 0.75745795, grad/param norm = 1.8486e-01, time/batch = 15.0950s	
21118/33250 (epoch 31.756), train_loss = 0.83606886, grad/param norm = 1.6581e-01, time/batch = 15.1718s	
21119/33250 (epoch 31.758), train_loss = 0.97837886, grad/param norm = 1.5472e-01, time/batch = 14.7514s	
21120/33250 (epoch 31.759), train_loss = 0.78314908, grad/param norm = 1.6070e-01, time/batch = 15.0827s	
21121/33250 (epoch 31.761), train_loss = 0.83946560, grad/param norm = 1.5709e-01, time/batch = 14.9440s	
21122/33250 (epoch 31.762), train_loss = 0.89796735, grad/param norm = 1.9578e-01, time/batch = 16.3439s	
21123/33250 (epoch 31.764), train_loss = 0.75587460, grad/param norm = 2.1418e-01, time/batch = 17.1107s	
21124/33250 (epoch 31.765), train_loss = 0.88274878, grad/param norm = 1.8977e-01, time/batch = 15.8895s	
21125/33250 (epoch 31.767), train_loss = 0.65478079, grad/param norm = 1.4781e-01, time/batch = 18.7956s	
21126/33250 (epoch 31.768), train_loss = 0.71200307, grad/param norm = 1.8063e-01, time/batch = 15.1889s	
21127/33250 (epoch 31.770), train_loss = 0.85993647, grad/param norm = 1.7384e-01, time/batch = 15.8299s	
21128/33250 (epoch 31.771), train_loss = 0.87624584, grad/param norm = 1.7806e-01, time/batch = 15.2031s	
21129/33250 (epoch 31.773), train_loss = 0.79514110, grad/param norm = 1.7093e-01, time/batch = 15.4654s	
21130/33250 (epoch 31.774), train_loss = 0.70959042, grad/param norm = 1.8110e-01, time/batch = 17.1000s	
21131/33250 (epoch 31.776), train_loss = 0.77975414, grad/param norm = 1.5575e-01, time/batch = 16.2729s	
21132/33250 (epoch 31.777), train_loss = 0.92165248, grad/param norm = 1.8586e-01, time/batch = 17.4316s	
21133/33250 (epoch 31.779), train_loss = 0.80336309, grad/param norm = 1.7074e-01, time/batch = 16.5372s	
21134/33250 (epoch 31.780), train_loss = 0.94156598, grad/param norm = 2.0723e-01, time/batch = 18.4551s	
21135/33250 (epoch 31.782), train_loss = 0.81769423, grad/param norm = 2.0604e-01, time/batch = 15.1851s	
21136/33250 (epoch 31.783), train_loss = 0.69098847, grad/param norm = 1.5367e-01, time/batch = 14.3997s	
21137/33250 (epoch 31.785), train_loss = 0.71792865, grad/param norm = 1.6932e-01, time/batch = 14.3879s	
21138/33250 (epoch 31.786), train_loss = 0.93632400, grad/param norm = 1.9520e-01, time/batch = 14.8814s	
21139/33250 (epoch 31.788), train_loss = 0.93217649, grad/param norm = 1.7749e-01, time/batch = 28.7190s	
21140/33250 (epoch 31.789), train_loss = 0.93527973, grad/param norm = 2.2139e-01, time/batch = 17.9340s	
21141/33250 (epoch 31.791), train_loss = 0.94549927, grad/param norm = 1.9858e-01, time/batch = 15.8604s	
21142/33250 (epoch 31.792), train_loss = 0.98263718, grad/param norm = 1.7719e-01, time/batch = 15.6424s	
21143/33250 (epoch 31.794), train_loss = 0.80881990, grad/param norm = 1.7033e-01, time/batch = 16.0930s	
21144/33250 (epoch 31.795), train_loss = 0.81583238, grad/param norm = 1.7660e-01, time/batch = 15.0109s	
21145/33250 (epoch 31.797), train_loss = 0.89390872, grad/param norm = 1.9652e-01, time/batch = 14.3219s	
21146/33250 (epoch 31.798), train_loss = 0.82576486, grad/param norm = 2.2317e-01, time/batch = 14.6991s	
21147/33250 (epoch 31.800), train_loss = 0.88833057, grad/param norm = 1.9750e-01, time/batch = 14.7154s	
21148/33250 (epoch 31.802), train_loss = 0.81580268, grad/param norm = 1.5780e-01, time/batch = 14.9295s	
21149/33250 (epoch 31.803), train_loss = 0.86105634, grad/param norm = 1.5983e-01, time/batch = 14.4688s	
21150/33250 (epoch 31.805), train_loss = 0.85014422, grad/param norm = 1.6367e-01, time/batch = 14.7957s	
21151/33250 (epoch 31.806), train_loss = 0.83551751, grad/param norm = 1.5856e-01, time/batch = 14.4708s	
21152/33250 (epoch 31.808), train_loss = 0.76581096, grad/param norm = 1.7430e-01, time/batch = 14.4640s	
21153/33250 (epoch 31.809), train_loss = 0.75168619, grad/param norm = 1.6559e-01, time/batch = 14.2189s	
21154/33250 (epoch 31.811), train_loss = 0.73868065, grad/param norm = 1.7232e-01, time/batch = 14.7088s	
21155/33250 (epoch 31.812), train_loss = 0.88502949, grad/param norm = 1.8840e-01, time/batch = 14.6415s	
21156/33250 (epoch 31.814), train_loss = 0.82242820, grad/param norm = 1.8794e-01, time/batch = 14.2512s	
21157/33250 (epoch 31.815), train_loss = 0.87540863, grad/param norm = 1.5047e-01, time/batch = 14.2384s	
21158/33250 (epoch 31.817), train_loss = 0.81190078, grad/param norm = 1.5775e-01, time/batch = 14.9516s	
21159/33250 (epoch 31.818), train_loss = 0.74622267, grad/param norm = 1.6736e-01, time/batch = 14.3880s	
21160/33250 (epoch 31.820), train_loss = 0.85833294, grad/param norm = 1.7110e-01, time/batch = 14.3092s	
21161/33250 (epoch 31.821), train_loss = 0.79924226, grad/param norm = 1.5926e-01, time/batch = 14.3865s	
21162/33250 (epoch 31.823), train_loss = 1.12346502, grad/param norm = 1.9631e-01, time/batch = 14.7095s	
21163/33250 (epoch 31.824), train_loss = 0.78085256, grad/param norm = 1.8233e-01, time/batch = 14.6195s	
21164/33250 (epoch 31.826), train_loss = 0.86843894, grad/param norm = 1.6857e-01, time/batch = 14.3038s	
21165/33250 (epoch 31.827), train_loss = 0.73526963, grad/param norm = 1.6854e-01, time/batch = 14.6241s	
21166/33250 (epoch 31.829), train_loss = 0.84513660, grad/param norm = 1.7890e-01, time/batch = 14.4886s	
21167/33250 (epoch 31.830), train_loss = 0.90641004, grad/param norm = 2.0841e-01, time/batch = 14.3321s	
21168/33250 (epoch 31.832), train_loss = 0.83660608, grad/param norm = 1.5835e-01, time/batch = 14.4044s	
21169/33250 (epoch 31.833), train_loss = 0.81338391, grad/param norm = 1.6057e-01, time/batch = 14.6401s	
21170/33250 (epoch 31.835), train_loss = 0.75566993, grad/param norm = 2.1439e-01, time/batch = 14.6283s	
21171/33250 (epoch 31.836), train_loss = 0.81465820, grad/param norm = 1.7477e-01, time/batch = 14.7182s	
21172/33250 (epoch 31.838), train_loss = 0.86755452, grad/param norm = 1.6534e-01, time/batch = 14.4590s	
21173/33250 (epoch 31.839), train_loss = 0.79083407, grad/param norm = 1.5906e-01, time/batch = 14.7738s	
21174/33250 (epoch 31.841), train_loss = 0.75012142, grad/param norm = 1.3132e-01, time/batch = 14.8690s	
21175/33250 (epoch 31.842), train_loss = 0.96748023, grad/param norm = 1.7472e-01, time/batch = 14.3895s	
21176/33250 (epoch 31.844), train_loss = 0.92855165, grad/param norm = 2.0994e-01, time/batch = 14.3128s	
21177/33250 (epoch 31.845), train_loss = 1.00534339, grad/param norm = 2.0149e-01, time/batch = 14.8520s	
21178/33250 (epoch 31.847), train_loss = 0.97542776, grad/param norm = 1.8341e-01, time/batch = 14.8608s	
21179/33250 (epoch 31.848), train_loss = 1.03508877, grad/param norm = 2.0594e-01, time/batch = 14.2322s	
21180/33250 (epoch 31.850), train_loss = 0.91477679, grad/param norm = 1.6745e-01, time/batch = 14.1609s	
21181/33250 (epoch 31.851), train_loss = 0.73640160, grad/param norm = 1.6742e-01, time/batch = 14.5632s	
21182/33250 (epoch 31.853), train_loss = 0.85833559, grad/param norm = 1.7924e-01, time/batch = 14.6173s	
21183/33250 (epoch 31.854), train_loss = 0.78759142, grad/param norm = 1.5636e-01, time/batch = 14.4659s	
21184/33250 (epoch 31.856), train_loss = 0.79120672, grad/param norm = 1.8365e-01, time/batch = 14.2235s	
21185/33250 (epoch 31.857), train_loss = 0.73180756, grad/param norm = 1.7487e-01, time/batch = 14.6977s	
21186/33250 (epoch 31.859), train_loss = 0.77493399, grad/param norm = 1.8064e-01, time/batch = 14.6879s	
21187/33250 (epoch 31.860), train_loss = 0.86847744, grad/param norm = 1.6199e-01, time/batch = 14.6307s	
21188/33250 (epoch 31.862), train_loss = 0.73456943, grad/param norm = 1.5395e-01, time/batch = 14.3888s	
21189/33250 (epoch 31.863), train_loss = 0.76967097, grad/param norm = 1.8314e-01, time/batch = 14.2410s	
21190/33250 (epoch 31.865), train_loss = 0.86436386, grad/param norm = 1.7301e-01, time/batch = 14.2488s	
21191/33250 (epoch 31.866), train_loss = 0.72247854, grad/param norm = 1.5854e-01, time/batch = 14.8723s	
21192/33250 (epoch 31.868), train_loss = 0.82900677, grad/param norm = 1.7491e-01, time/batch = 14.3360s	
21193/33250 (epoch 31.869), train_loss = 0.85619773, grad/param norm = 1.9062e-01, time/batch = 14.3243s	
21194/33250 (epoch 31.871), train_loss = 0.65621400, grad/param norm = 1.5220e-01, time/batch = 14.3927s	
21195/33250 (epoch 31.872), train_loss = 0.90593062, grad/param norm = 2.2016e-01, time/batch = 14.8703s	
21196/33250 (epoch 31.874), train_loss = 0.75271207, grad/param norm = 1.6809e-01, time/batch = 14.3087s	
21197/33250 (epoch 31.875), train_loss = 0.70124612, grad/param norm = 1.5788e-01, time/batch = 13.9821s	
21198/33250 (epoch 31.877), train_loss = 0.94885254, grad/param norm = 1.7706e-01, time/batch = 14.2334s	
21199/33250 (epoch 31.878), train_loss = 0.84204166, grad/param norm = 1.6853e-01, time/batch = 15.1148s	
21200/33250 (epoch 31.880), train_loss = 0.84064163, grad/param norm = 1.9325e-01, time/batch = 14.4522s	
21201/33250 (epoch 31.881), train_loss = 0.93464706, grad/param norm = 1.9780e-01, time/batch = 14.3795s	
21202/33250 (epoch 31.883), train_loss = 0.84962054, grad/param norm = 1.6052e-01, time/batch = 13.9264s	
21203/33250 (epoch 31.884), train_loss = 0.90748206, grad/param norm = 1.8668e-01, time/batch = 14.3935s	
21204/33250 (epoch 31.886), train_loss = 0.77765617, grad/param norm = 1.5877e-01, time/batch = 14.8593s	
21205/33250 (epoch 31.887), train_loss = 0.80604091, grad/param norm = 2.0016e-01, time/batch = 14.4028s	
21206/33250 (epoch 31.889), train_loss = 0.77818594, grad/param norm = 1.4809e-01, time/batch = 14.6257s	
21207/33250 (epoch 31.890), train_loss = 0.65675299, grad/param norm = 1.3428e-01, time/batch = 15.0997s	
21208/33250 (epoch 31.892), train_loss = 0.88017712, grad/param norm = 1.5608e-01, time/batch = 14.3113s	
21209/33250 (epoch 31.893), train_loss = 0.91168282, grad/param norm = 1.9986e-01, time/batch = 14.3093s	
21210/33250 (epoch 31.895), train_loss = 0.76193529, grad/param norm = 1.5796e-01, time/batch = 14.3945s	
21211/33250 (epoch 31.896), train_loss = 0.89387089, grad/param norm = 1.7366e-01, time/batch = 14.8745s	
21212/33250 (epoch 31.898), train_loss = 0.81518820, grad/param norm = 1.6375e-01, time/batch = 14.4696s	
21213/33250 (epoch 31.899), train_loss = 0.76287996, grad/param norm = 1.4771e-01, time/batch = 14.7887s	
21214/33250 (epoch 31.901), train_loss = 0.72074104, grad/param norm = 1.4587e-01, time/batch = 14.4155s	
21215/33250 (epoch 31.902), train_loss = 0.80049217, grad/param norm = 1.6029e-01, time/batch = 15.0137s	
21216/33250 (epoch 31.904), train_loss = 0.73934076, grad/param norm = 1.4947e-01, time/batch = 14.4933s	
21217/33250 (epoch 31.905), train_loss = 0.79808021, grad/param norm = 1.4968e-01, time/batch = 14.6297s	
21218/33250 (epoch 31.907), train_loss = 0.74696288, grad/param norm = 1.7472e-01, time/batch = 14.4742s	
21219/33250 (epoch 31.908), train_loss = 0.80566829, grad/param norm = 1.3373e-01, time/batch = 14.7842s	
21220/33250 (epoch 31.910), train_loss = 0.88063475, grad/param norm = 1.6367e-01, time/batch = 5.1626s	
21221/33250 (epoch 31.911), train_loss = 0.72515930, grad/param norm = 1.4613e-01, time/batch = 0.6663s	
21222/33250 (epoch 31.913), train_loss = 0.80026036, grad/param norm = 1.6892e-01, time/batch = 0.6709s	
21223/33250 (epoch 31.914), train_loss = 0.69652619, grad/param norm = 1.4986e-01, time/batch = 0.6674s	
21224/33250 (epoch 31.916), train_loss = 0.73538835, grad/param norm = 1.4902e-01, time/batch = 0.6684s	
21225/33250 (epoch 31.917), train_loss = 0.82697261, grad/param norm = 1.3420e-01, time/batch = 0.6669s	
21226/33250 (epoch 31.919), train_loss = 0.74386998, grad/param norm = 1.8413e-01, time/batch = 0.6454s	
21227/33250 (epoch 31.920), train_loss = 0.81882521, grad/param norm = 1.6641e-01, time/batch = 0.7114s	
21228/33250 (epoch 31.922), train_loss = 0.86171112, grad/param norm = 1.8924e-01, time/batch = 0.9465s	
21229/33250 (epoch 31.923), train_loss = 0.78989041, grad/param norm = 1.6765e-01, time/batch = 0.9515s	
21230/33250 (epoch 31.925), train_loss = 0.79490369, grad/param norm = 1.5987e-01, time/batch = 0.9478s	
21231/33250 (epoch 31.926), train_loss = 0.77474478, grad/param norm = 1.5181e-01, time/batch = 0.9515s	
21232/33250 (epoch 31.928), train_loss = 0.78821672, grad/param norm = 1.6427e-01, time/batch = 0.9669s	
21233/33250 (epoch 31.929), train_loss = 0.69705061, grad/param norm = 1.3252e-01, time/batch = 1.7510s	
21234/33250 (epoch 31.931), train_loss = 0.91855381, grad/param norm = 1.8992e-01, time/batch = 1.7731s	
21235/33250 (epoch 31.932), train_loss = 0.77140164, grad/param norm = 1.7300e-01, time/batch = 3.9896s	
21236/33250 (epoch 31.934), train_loss = 0.75944713, grad/param norm = 1.4695e-01, time/batch = 14.0652s	
21237/33250 (epoch 31.935), train_loss = 0.76047303, grad/param norm = 1.7674e-01, time/batch = 14.2937s	
21238/33250 (epoch 31.937), train_loss = 0.76356445, grad/param norm = 1.9308e-01, time/batch = 15.0265s	
21239/33250 (epoch 31.938), train_loss = 0.81424201, grad/param norm = 1.7633e-01, time/batch = 14.3258s	
21240/33250 (epoch 31.940), train_loss = 0.78913132, grad/param norm = 1.6548e-01, time/batch = 14.2998s	
21241/33250 (epoch 31.941), train_loss = 0.85814781, grad/param norm = 1.6677e-01, time/batch = 14.7187s	
21242/33250 (epoch 31.943), train_loss = 0.96165346, grad/param norm = 1.7321e-01, time/batch = 16.4513s	
21243/33250 (epoch 31.944), train_loss = 0.78977063, grad/param norm = 1.6998e-01, time/batch = 15.7787s	
21244/33250 (epoch 31.946), train_loss = 0.93599251, grad/param norm = 2.1190e-01, time/batch = 16.4425s	
21245/33250 (epoch 31.947), train_loss = 0.75683716, grad/param norm = 1.8004e-01, time/batch = 16.1864s	
21246/33250 (epoch 31.949), train_loss = 0.89095289, grad/param norm = 1.8148e-01, time/batch = 16.1096s	
21247/33250 (epoch 31.950), train_loss = 0.89336474, grad/param norm = 1.5619e-01, time/batch = 16.8557s	
21248/33250 (epoch 31.952), train_loss = 0.82501549, grad/param norm = 1.7857e-01, time/batch = 16.3338s	
21249/33250 (epoch 31.953), train_loss = 0.89234800, grad/param norm = 2.5764e-01, time/batch = 17.8465s	
21250/33250 (epoch 31.955), train_loss = 0.91772372, grad/param norm = 1.8139e-01, time/batch = 16.5457s	
21251/33250 (epoch 31.956), train_loss = 0.84846638, grad/param norm = 2.0296e-01, time/batch = 17.7739s	
21252/33250 (epoch 31.958), train_loss = 0.77697836, grad/param norm = 1.5871e-01, time/batch = 18.3779s	
21253/33250 (epoch 31.959), train_loss = 0.75898023, grad/param norm = 1.5000e-01, time/batch = 15.5699s	
21254/33250 (epoch 31.961), train_loss = 1.03514534, grad/param norm = 1.8597e-01, time/batch = 15.8583s	
21255/33250 (epoch 31.962), train_loss = 0.81652346, grad/param norm = 1.7630e-01, time/batch = 16.1906s	
21256/33250 (epoch 31.964), train_loss = 0.96347996, grad/param norm = 2.0343e-01, time/batch = 16.3522s	
21257/33250 (epoch 31.965), train_loss = 0.89096507, grad/param norm = 2.0848e-01, time/batch = 16.0029s	
21258/33250 (epoch 31.967), train_loss = 0.85266383, grad/param norm = 1.7546e-01, time/batch = 17.1872s	
21259/33250 (epoch 31.968), train_loss = 0.97044219, grad/param norm = 1.7144e-01, time/batch = 17.2583s	
21260/33250 (epoch 31.970), train_loss = 1.07476474, grad/param norm = 2.1865e-01, time/batch = 16.2756s	
21261/33250 (epoch 31.971), train_loss = 0.98387704, grad/param norm = 1.8969e-01, time/batch = 19.4597s	
21262/33250 (epoch 31.973), train_loss = 0.81546381, grad/param norm = 1.6417e-01, time/batch = 18.0403s	
21263/33250 (epoch 31.974), train_loss = 0.90898120, grad/param norm = 1.7412e-01, time/batch = 16.1245s	
21264/33250 (epoch 31.976), train_loss = 0.79973596, grad/param norm = 1.6956e-01, time/batch = 16.4446s	
21265/33250 (epoch 31.977), train_loss = 0.79850583, grad/param norm = 1.7849e-01, time/batch = 16.1026s	
21266/33250 (epoch 31.979), train_loss = 0.86481990, grad/param norm = 1.8313e-01, time/batch = 16.2054s	
21267/33250 (epoch 31.980), train_loss = 0.87914566, grad/param norm = 1.7913e-01, time/batch = 15.2887s	
21268/33250 (epoch 31.982), train_loss = 0.77693137, grad/param norm = 1.4950e-01, time/batch = 15.8455s	
21269/33250 (epoch 31.983), train_loss = 0.84694365, grad/param norm = 1.8602e-01, time/batch = 18.7021s	
21270/33250 (epoch 31.985), train_loss = 0.79612983, grad/param norm = 1.7683e-01, time/batch = 17.2055s	
21271/33250 (epoch 31.986), train_loss = 0.89435014, grad/param norm = 1.8184e-01, time/batch = 18.0170s	
21272/33250 (epoch 31.988), train_loss = 0.91760111, grad/param norm = 1.7171e-01, time/batch = 17.6270s	
21273/33250 (epoch 31.989), train_loss = 0.91832657, grad/param norm = 1.8448e-01, time/batch = 16.8632s	
21274/33250 (epoch 31.991), train_loss = 0.85829274, grad/param norm = 1.8261e-01, time/batch = 15.1065s	
21275/33250 (epoch 31.992), train_loss = 0.83035393, grad/param norm = 1.9240e-01, time/batch = 15.6530s	
21276/33250 (epoch 31.994), train_loss = 0.80089487, grad/param norm = 1.5910e-01, time/batch = 17.0995s	
21277/33250 (epoch 31.995), train_loss = 0.83039173, grad/param norm = 2.1705e-01, time/batch = 17.1788s	
21278/33250 (epoch 31.997), train_loss = 0.60258306, grad/param norm = 1.3653e-01, time/batch = 15.9093s	
21279/33250 (epoch 31.998), train_loss = 0.87653947, grad/param norm = 1.6815e-01, time/batch = 15.6543s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
21280/33250 (epoch 32.000), train_loss = 0.85578384, grad/param norm = 1.7636e-01, time/batch = 15.0878s	
21281/33250 (epoch 32.002), train_loss = 1.03426501, grad/param norm = 1.8978e-01, time/batch = 15.0428s	
21282/33250 (epoch 32.003), train_loss = 0.90759414, grad/param norm = 1.8940e-01, time/batch = 15.9605s	
21283/33250 (epoch 32.005), train_loss = 0.70175754, grad/param norm = 1.5889e-01, time/batch = 15.9212s	
21284/33250 (epoch 32.006), train_loss = 0.71909930, grad/param norm = 1.5580e-01, time/batch = 15.2908s	
21285/33250 (epoch 32.008), train_loss = 0.91779725, grad/param norm = 1.6154e-01, time/batch = 17.0158s	
21286/33250 (epoch 32.009), train_loss = 0.99141043, grad/param norm = 1.7307e-01, time/batch = 16.2642s	
21287/33250 (epoch 32.011), train_loss = 0.77742573, grad/param norm = 1.5469e-01, time/batch = 17.1859s	
21288/33250 (epoch 32.012), train_loss = 0.82057190, grad/param norm = 2.3223e-01, time/batch = 15.5327s	
21289/33250 (epoch 32.014), train_loss = 0.92130664, grad/param norm = 1.8078e-01, time/batch = 15.1946s	
21290/33250 (epoch 32.015), train_loss = 0.82955680, grad/param norm = 1.6121e-01, time/batch = 16.8832s	
21291/33250 (epoch 32.017), train_loss = 0.87766487, grad/param norm = 2.0224e-01, time/batch = 18.5440s	
21292/33250 (epoch 32.018), train_loss = 0.68285726, grad/param norm = 1.5021e-01, time/batch = 17.5382s	
21293/33250 (epoch 32.020), train_loss = 0.85133172, grad/param norm = 1.4648e-01, time/batch = 14.8149s	
21294/33250 (epoch 32.021), train_loss = 0.86502996, grad/param norm = 1.5890e-01, time/batch = 14.8020s	
21295/33250 (epoch 32.023), train_loss = 0.69541484, grad/param norm = 1.8359e-01, time/batch = 16.4858s	
21296/33250 (epoch 32.024), train_loss = 0.94059386, grad/param norm = 1.9987e-01, time/batch = 16.4319s	
21297/33250 (epoch 32.026), train_loss = 0.85572550, grad/param norm = 1.8176e-01, time/batch = 17.4305s	
21298/33250 (epoch 32.027), train_loss = 0.88943544, grad/param norm = 1.6606e-01, time/batch = 16.6141s	
21299/33250 (epoch 32.029), train_loss = 0.84586955, grad/param norm = 1.8447e-01, time/batch = 18.3462s	
21300/33250 (epoch 32.030), train_loss = 0.83406150, grad/param norm = 1.7644e-01, time/batch = 16.0314s	
21301/33250 (epoch 32.032), train_loss = 1.02888594, grad/param norm = 2.0434e-01, time/batch = 17.7021s	
21302/33250 (epoch 32.033), train_loss = 0.80372583, grad/param norm = 1.7231e-01, time/batch = 18.2109s	
21303/33250 (epoch 32.035), train_loss = 0.84771518, grad/param norm = 1.6921e-01, time/batch = 16.6848s	
21304/33250 (epoch 32.036), train_loss = 0.91625457, grad/param norm = 2.0808e-01, time/batch = 17.1077s	
21305/33250 (epoch 32.038), train_loss = 0.83296347, grad/param norm = 1.5080e-01, time/batch = 15.6170s	
21306/33250 (epoch 32.039), train_loss = 0.77785742, grad/param norm = 1.7267e-01, time/batch = 15.0468s	
21307/33250 (epoch 32.041), train_loss = 0.85650324, grad/param norm = 1.7966e-01, time/batch = 15.1981s	
21308/33250 (epoch 32.042), train_loss = 0.71146818, grad/param norm = 1.5735e-01, time/batch = 15.0240s	
21309/33250 (epoch 32.044), train_loss = 0.95744389, grad/param norm = 1.8050e-01, time/batch = 16.6867s	
21310/33250 (epoch 32.045), train_loss = 0.95190881, grad/param norm = 1.9223e-01, time/batch = 18.0374s	
21311/33250 (epoch 32.047), train_loss = 0.84216355, grad/param norm = 1.6695e-01, time/batch = 16.8864s	
21312/33250 (epoch 32.048), train_loss = 0.92658939, grad/param norm = 2.1406e-01, time/batch = 16.6886s	
21313/33250 (epoch 32.050), train_loss = 0.85216196, grad/param norm = 1.5914e-01, time/batch = 15.8333s	
21314/33250 (epoch 32.051), train_loss = 0.82110089, grad/param norm = 1.3941e-01, time/batch = 17.3355s	
21315/33250 (epoch 32.053), train_loss = 0.90482452, grad/param norm = 2.3182e-01, time/batch = 17.9370s	
21316/33250 (epoch 32.054), train_loss = 0.71156708, grad/param norm = 1.4809e-01, time/batch = 16.0047s	
21317/33250 (epoch 32.056), train_loss = 0.75100977, grad/param norm = 1.5165e-01, time/batch = 18.1866s	
21318/33250 (epoch 32.057), train_loss = 0.94636535, grad/param norm = 1.7287e-01, time/batch = 17.0854s	
21319/33250 (epoch 32.059), train_loss = 0.79684096, grad/param norm = 1.6303e-01, time/batch = 17.3492s	
21320/33250 (epoch 32.060), train_loss = 0.84502742, grad/param norm = 1.7510e-01, time/batch = 16.6086s	
21321/33250 (epoch 32.062), train_loss = 0.93632529, grad/param norm = 1.6939e-01, time/batch = 17.7827s	
21322/33250 (epoch 32.063), train_loss = 0.98375934, grad/param norm = 1.6421e-01, time/batch = 15.2189s	
21323/33250 (epoch 32.065), train_loss = 0.83005781, grad/param norm = 1.6264e-01, time/batch = 15.9437s	
21324/33250 (epoch 32.066), train_loss = 0.87237475, grad/param norm = 1.7922e-01, time/batch = 18.7390s	
21325/33250 (epoch 32.068), train_loss = 0.79414951, grad/param norm = 1.7072e-01, time/batch = 17.5700s	
21326/33250 (epoch 32.069), train_loss = 0.85566088, grad/param norm = 1.5390e-01, time/batch = 17.6030s	
21327/33250 (epoch 32.071), train_loss = 0.78441457, grad/param norm = 1.3699e-01, time/batch = 15.5240s	
21328/33250 (epoch 32.072), train_loss = 0.77366755, grad/param norm = 1.5325e-01, time/batch = 16.5885s	
21329/33250 (epoch 32.074), train_loss = 0.86682695, grad/param norm = 1.6861e-01, time/batch = 16.9227s	
21330/33250 (epoch 32.075), train_loss = 0.79996477, grad/param norm = 1.6698e-01, time/batch = 16.2127s	
21331/33250 (epoch 32.077), train_loss = 0.82308420, grad/param norm = 1.6529e-01, time/batch = 17.6993s	
21332/33250 (epoch 32.078), train_loss = 0.84986965, grad/param norm = 1.6981e-01, time/batch = 15.6759s	
21333/33250 (epoch 32.080), train_loss = 0.84189833, grad/param norm = 2.2172e-01, time/batch = 16.6840s	
21334/33250 (epoch 32.081), train_loss = 0.86264240, grad/param norm = 1.5666e-01, time/batch = 16.3649s	
21335/33250 (epoch 32.083), train_loss = 0.96479983, grad/param norm = 1.6668e-01, time/batch = 14.8637s	
21336/33250 (epoch 32.084), train_loss = 0.84864795, grad/param norm = 1.7520e-01, time/batch = 15.3389s	
21337/33250 (epoch 32.086), train_loss = 0.83904042, grad/param norm = 1.4637e-01, time/batch = 14.8629s	
21338/33250 (epoch 32.087), train_loss = 0.73209025, grad/param norm = 1.5313e-01, time/batch = 14.2967s	
21339/33250 (epoch 32.089), train_loss = 0.83479032, grad/param norm = 1.5242e-01, time/batch = 14.6957s	
21340/33250 (epoch 32.090), train_loss = 0.84954891, grad/param norm = 1.4825e-01, time/batch = 14.4509s	
21341/33250 (epoch 32.092), train_loss = 0.77577444, grad/param norm = 1.4532e-01, time/batch = 15.7752s	
21342/33250 (epoch 32.093), train_loss = 0.82421884, grad/param norm = 1.5539e-01, time/batch = 16.9540s	
21343/33250 (epoch 32.095), train_loss = 0.82522387, grad/param norm = 1.6998e-01, time/batch = 16.4488s	
21344/33250 (epoch 32.096), train_loss = 0.70293198, grad/param norm = 1.6571e-01, time/batch = 16.3868s	
21345/33250 (epoch 32.098), train_loss = 0.71170288, grad/param norm = 1.7995e-01, time/batch = 16.2847s	
21346/33250 (epoch 32.099), train_loss = 0.65445882, grad/param norm = 1.4306e-01, time/batch = 14.6873s	
21347/33250 (epoch 32.101), train_loss = 0.83021019, grad/param norm = 1.6874e-01, time/batch = 15.2436s	
21348/33250 (epoch 32.102), train_loss = 0.76767394, grad/param norm = 1.5621e-01, time/batch = 14.5300s	
21349/33250 (epoch 32.104), train_loss = 0.62611167, grad/param norm = 1.3074e-01, time/batch = 14.7147s	
21350/33250 (epoch 32.105), train_loss = 0.77015993, grad/param norm = 1.6269e-01, time/batch = 15.0992s	
21351/33250 (epoch 32.107), train_loss = 0.69647917, grad/param norm = 1.2974e-01, time/batch = 15.1033s	
21352/33250 (epoch 32.108), train_loss = 0.82819403, grad/param norm = 1.6152e-01, time/batch = 15.0372s	
21353/33250 (epoch 32.110), train_loss = 0.70085494, grad/param norm = 1.4980e-01, time/batch = 16.4562s	
21354/33250 (epoch 32.111), train_loss = 0.80836008, grad/param norm = 1.5159e-01, time/batch = 15.8532s	
21355/33250 (epoch 32.113), train_loss = 0.75201532, grad/param norm = 1.4698e-01, time/batch = 16.7822s	
21356/33250 (epoch 32.114), train_loss = 0.72928981, grad/param norm = 1.6771e-01, time/batch = 15.6056s	
21357/33250 (epoch 32.116), train_loss = 0.77415851, grad/param norm = 1.8059e-01, time/batch = 14.9368s	
21358/33250 (epoch 32.117), train_loss = 0.77437537, grad/param norm = 1.7102e-01, time/batch = 15.6482s	
21359/33250 (epoch 32.119), train_loss = 0.78919895, grad/param norm = 1.5994e-01, time/batch = 15.9659s	
21360/33250 (epoch 32.120), train_loss = 0.64540517, grad/param norm = 1.3365e-01, time/batch = 15.8199s	
21361/33250 (epoch 32.122), train_loss = 0.90371232, grad/param norm = 1.7773e-01, time/batch = 15.4822s	
21362/33250 (epoch 32.123), train_loss = 0.80236153, grad/param norm = 1.7154e-01, time/batch = 15.2513s	
21363/33250 (epoch 32.125), train_loss = 0.66715941, grad/param norm = 1.6651e-01, time/batch = 15.4182s	
21364/33250 (epoch 32.126), train_loss = 0.79625826, grad/param norm = 1.7085e-01, time/batch = 15.6814s	
21365/33250 (epoch 32.128), train_loss = 0.76835283, grad/param norm = 1.4951e-01, time/batch = 15.6873s	
21366/33250 (epoch 32.129), train_loss = 0.79178834, grad/param norm = 1.4054e-01, time/batch = 15.7474s	
21367/33250 (epoch 32.131), train_loss = 0.80304298, grad/param norm = 1.7287e-01, time/batch = 15.3509s	
21368/33250 (epoch 32.132), train_loss = 0.79771221, grad/param norm = 1.7949e-01, time/batch = 14.7901s	
21369/33250 (epoch 32.134), train_loss = 0.77266335, grad/param norm = 1.7407e-01, time/batch = 15.8446s	
21370/33250 (epoch 32.135), train_loss = 0.81834022, grad/param norm = 1.5290e-01, time/batch = 15.9170s	
21371/33250 (epoch 32.137), train_loss = 0.73204925, grad/param norm = 1.6262e-01, time/batch = 15.0963s	
21372/33250 (epoch 32.138), train_loss = 0.74085096, grad/param norm = 1.4740e-01, time/batch = 16.8597s	
21373/33250 (epoch 32.140), train_loss = 0.63446519, grad/param norm = 1.4098e-01, time/batch = 16.5338s	
21374/33250 (epoch 32.141), train_loss = 0.90997586, grad/param norm = 2.1243e-01, time/batch = 16.7638s	
21375/33250 (epoch 32.143), train_loss = 0.68307231, grad/param norm = 1.7557e-01, time/batch = 19.5476s	
21376/33250 (epoch 32.144), train_loss = 0.78610126, grad/param norm = 1.6312e-01, time/batch = 17.9645s	
21377/33250 (epoch 32.146), train_loss = 0.77373034, grad/param norm = 1.5151e-01, time/batch = 15.7816s	
21378/33250 (epoch 32.147), train_loss = 0.78450029, grad/param norm = 1.6132e-01, time/batch = 17.9170s	
21379/33250 (epoch 32.149), train_loss = 0.74527547, grad/param norm = 1.5299e-01, time/batch = 18.3291s	
21380/33250 (epoch 32.150), train_loss = 0.70995558, grad/param norm = 1.5655e-01, time/batch = 17.4283s	
21381/33250 (epoch 32.152), train_loss = 0.68933958, grad/param norm = 1.6012e-01, time/batch = 29.7921s	
21382/33250 (epoch 32.153), train_loss = 0.95457096, grad/param norm = 1.8233e-01, time/batch = 16.1099s	
21383/33250 (epoch 32.155), train_loss = 0.78467303, grad/param norm = 2.1396e-01, time/batch = 14.6391s	
21384/33250 (epoch 32.156), train_loss = 0.99505321, grad/param norm = 1.6370e-01, time/batch = 15.5477s	
21385/33250 (epoch 32.158), train_loss = 0.94122320, grad/param norm = 2.0685e-01, time/batch = 16.6903s	
21386/33250 (epoch 32.159), train_loss = 0.76141141, grad/param norm = 1.6019e-01, time/batch = 14.9571s	
21387/33250 (epoch 32.161), train_loss = 0.85846586, grad/param norm = 1.9874e-01, time/batch = 14.6285s	
21388/33250 (epoch 32.162), train_loss = 0.73420090, grad/param norm = 1.6477e-01, time/batch = 14.9551s	
21389/33250 (epoch 32.164), train_loss = 0.79908619, grad/param norm = 1.7033e-01, time/batch = 14.7052s	
21390/33250 (epoch 32.165), train_loss = 0.87907843, grad/param norm = 1.6699e-01, time/batch = 14.3790s	
21391/33250 (epoch 32.167), train_loss = 0.95497278, grad/param norm = 1.8537e-01, time/batch = 14.3902s	
21392/33250 (epoch 32.168), train_loss = 0.69553334, grad/param norm = 1.4225e-01, time/batch = 14.7065s	
21393/33250 (epoch 32.170), train_loss = 0.77105185, grad/param norm = 1.6344e-01, time/batch = 14.2972s	
21394/33250 (epoch 32.171), train_loss = 0.82844624, grad/param norm = 1.8070e-01, time/batch = 14.3978s	
21395/33250 (epoch 32.173), train_loss = 0.77557453, grad/param norm = 1.4984e-01, time/batch = 14.2553s	
21396/33250 (epoch 32.174), train_loss = 0.82521503, grad/param norm = 1.6249e-01, time/batch = 15.3432s	
21397/33250 (epoch 32.176), train_loss = 0.75795385, grad/param norm = 1.5531e-01, time/batch = 14.3356s	
21398/33250 (epoch 32.177), train_loss = 0.76533454, grad/param norm = 1.5266e-01, time/batch = 14.3195s	
21399/33250 (epoch 32.179), train_loss = 0.75296260, grad/param norm = 1.5893e-01, time/batch = 14.3907s	
21400/33250 (epoch 32.180), train_loss = 0.66559895, grad/param norm = 1.4799e-01, time/batch = 15.1085s	
21401/33250 (epoch 32.182), train_loss = 0.75225987, grad/param norm = 1.8803e-01, time/batch = 14.6215s	
21402/33250 (epoch 32.183), train_loss = 0.93167512, grad/param norm = 2.1509e-01, time/batch = 15.0137s	
21403/33250 (epoch 32.185), train_loss = 0.85254995, grad/param norm = 2.0970e-01, time/batch = 14.3908s	
21404/33250 (epoch 32.186), train_loss = 0.85303927, grad/param norm = 1.7427e-01, time/batch = 14.9444s	
21405/33250 (epoch 32.188), train_loss = 0.91548281, grad/param norm = 1.9377e-01, time/batch = 14.1616s	
21406/33250 (epoch 32.189), train_loss = 0.65907476, grad/param norm = 1.7159e-01, time/batch = 14.4073s	
21407/33250 (epoch 32.191), train_loss = 0.75264617, grad/param norm = 1.7168e-01, time/batch = 14.3266s	
21408/33250 (epoch 32.192), train_loss = 0.78257206, grad/param norm = 1.4878e-01, time/batch = 15.0527s	
21409/33250 (epoch 32.194), train_loss = 0.79499533, grad/param norm = 1.8002e-01, time/batch = 14.3285s	
21410/33250 (epoch 32.195), train_loss = 0.99292304, grad/param norm = 1.7599e-01, time/batch = 14.4740s	
21411/33250 (epoch 32.197), train_loss = 0.74905637, grad/param norm = 1.6577e-01, time/batch = 14.4746s	
21412/33250 (epoch 32.198), train_loss = 0.96329300, grad/param norm = 1.7495e-01, time/batch = 14.7981s	
21413/33250 (epoch 32.200), train_loss = 0.82775172, grad/param norm = 1.6771e-01, time/batch = 14.5463s	
21414/33250 (epoch 32.202), train_loss = 0.76776575, grad/param norm = 1.5555e-01, time/batch = 14.6202s	
21415/33250 (epoch 32.203), train_loss = 0.74588780, grad/param norm = 1.6538e-01, time/batch = 14.4674s	
21416/33250 (epoch 32.205), train_loss = 0.84358444, grad/param norm = 1.5676e-01, time/batch = 14.9965s	
21417/33250 (epoch 32.206), train_loss = 0.89347023, grad/param norm = 1.9457e-01, time/batch = 14.1473s	
21418/33250 (epoch 32.208), train_loss = 0.94759879, grad/param norm = 2.2202e-01, time/batch = 13.9995s	
21419/33250 (epoch 32.209), train_loss = 0.76318934, grad/param norm = 1.7611e-01, time/batch = 13.9202s	
21420/33250 (epoch 32.211), train_loss = 0.87375935, grad/param norm = 1.8531e-01, time/batch = 14.5549s	
21421/33250 (epoch 32.212), train_loss = 0.96741049, grad/param norm = 1.7697e-01, time/batch = 14.5711s	
21422/33250 (epoch 32.214), train_loss = 0.83968928, grad/param norm = 1.6902e-01, time/batch = 14.7060s	
21423/33250 (epoch 32.215), train_loss = 0.91804727, grad/param norm = 2.1081e-01, time/batch = 14.4749s	
21424/33250 (epoch 32.217), train_loss = 0.90913227, grad/param norm = 2.0255e-01, time/batch = 14.6918s	
21425/33250 (epoch 32.218), train_loss = 0.89958469, grad/param norm = 1.6557e-01, time/batch = 14.4673s	
21426/33250 (epoch 32.220), train_loss = 0.84975502, grad/param norm = 1.8521e-01, time/batch = 14.3046s	
21427/33250 (epoch 32.221), train_loss = 0.97077789, grad/param norm = 1.9396e-01, time/batch = 14.5323s	
21428/33250 (epoch 32.223), train_loss = 0.83191047, grad/param norm = 1.6903e-01, time/batch = 14.2196s	
21429/33250 (epoch 32.224), train_loss = 0.89279379, grad/param norm = 1.7883e-01, time/batch = 14.6879s	
21430/33250 (epoch 32.226), train_loss = 0.97636110, grad/param norm = 1.9312e-01, time/batch = 14.1485s	
21431/33250 (epoch 32.227), train_loss = 0.86419365, grad/param norm = 1.7169e-01, time/batch = 14.2522s	
21432/33250 (epoch 32.229), train_loss = 0.81856915, grad/param norm = 1.5631e-01, time/batch = 14.0816s	
21433/33250 (epoch 32.230), train_loss = 0.83854696, grad/param norm = 1.8616e-01, time/batch = 14.3064s	
21434/33250 (epoch 32.232), train_loss = 0.77651501, grad/param norm = 1.6112e-01, time/batch = 14.0663s	
21435/33250 (epoch 32.233), train_loss = 0.74709154, grad/param norm = 1.5428e-01, time/batch = 14.1383s	
21436/33250 (epoch 32.235), train_loss = 0.96110106, grad/param norm = 1.6926e-01, time/batch = 14.1394s	
21437/33250 (epoch 32.236), train_loss = 0.77222276, grad/param norm = 1.6738e-01, time/batch = 14.8554s	
21438/33250 (epoch 32.238), train_loss = 0.92306417, grad/param norm = 1.8079e-01, time/batch = 14.4551s	
21439/33250 (epoch 32.239), train_loss = 0.93433811, grad/param norm = 2.5769e-01, time/batch = 14.3046s	
21440/33250 (epoch 32.241), train_loss = 0.94736196, grad/param norm = 1.9519e-01, time/batch = 14.2372s	
21441/33250 (epoch 32.242), train_loss = 0.95098486, grad/param norm = 2.0963e-01, time/batch = 15.1198s	
21442/33250 (epoch 32.244), train_loss = 0.89157189, grad/param norm = 1.9604e-01, time/batch = 14.7967s	
21443/33250 (epoch 32.245), train_loss = 0.89000427, grad/param norm = 1.9574e-01, time/batch = 14.7366s	
21444/33250 (epoch 32.247), train_loss = 0.83262644, grad/param norm = 1.6998e-01, time/batch = 14.3291s	
21445/33250 (epoch 32.248), train_loss = 1.00900809, grad/param norm = 1.9656e-01, time/batch = 14.7069s	
21446/33250 (epoch 32.250), train_loss = 0.93419422, grad/param norm = 1.5761e-01, time/batch = 14.4749s	
21447/33250 (epoch 32.251), train_loss = 0.80837315, grad/param norm = 1.5055e-01, time/batch = 14.3825s	
21448/33250 (epoch 32.253), train_loss = 0.80016626, grad/param norm = 1.5080e-01, time/batch = 14.6173s	
21449/33250 (epoch 32.254), train_loss = 0.77987868, grad/param norm = 1.6733e-01, time/batch = 14.7821s	
21450/33250 (epoch 32.256), train_loss = 0.83061434, grad/param norm = 1.6943e-01, time/batch = 14.6343s	
21451/33250 (epoch 32.257), train_loss = 0.97967803, grad/param norm = 1.7216e-01, time/batch = 14.6358s	
21452/33250 (epoch 32.259), train_loss = 0.88129055, grad/param norm = 1.7378e-01, time/batch = 14.4817s	
21453/33250 (epoch 32.260), train_loss = 0.70401891, grad/param norm = 1.7000e-01, time/batch = 14.6488s	
21454/33250 (epoch 32.262), train_loss = 0.84970983, grad/param norm = 1.6056e-01, time/batch = 14.4044s	
21455/33250 (epoch 32.263), train_loss = 0.72236356, grad/param norm = 1.7430e-01, time/batch = 14.2398s	
21456/33250 (epoch 32.265), train_loss = 0.88761724, grad/param norm = 1.6766e-01, time/batch = 14.4744s	
21457/33250 (epoch 32.266), train_loss = 0.81382973, grad/param norm = 1.6593e-01, time/batch = 14.9408s	
21458/33250 (epoch 32.268), train_loss = 0.75381722, grad/param norm = 1.6221e-01, time/batch = 14.8541s	
21459/33250 (epoch 32.269), train_loss = 0.69134342, grad/param norm = 1.5330e-01, time/batch = 14.3896s	
21460/33250 (epoch 32.271), train_loss = 0.83162367, grad/param norm = 1.5001e-01, time/batch = 14.6993s	
21461/33250 (epoch 32.272), train_loss = 0.75579309, grad/param norm = 1.4267e-01, time/batch = 14.8677s	
21462/33250 (epoch 32.274), train_loss = 0.63771285, grad/param norm = 1.5368e-01, time/batch = 14.5314s	
21463/33250 (epoch 32.275), train_loss = 0.77587625, grad/param norm = 1.3188e-01, time/batch = 14.0840s	
21464/33250 (epoch 32.277), train_loss = 0.64614586, grad/param norm = 1.5971e-01, time/batch = 15.0229s	
21465/33250 (epoch 32.278), train_loss = 0.76919877, grad/param norm = 1.7598e-01, time/batch = 15.0294s	
21466/33250 (epoch 32.280), train_loss = 0.72150081, grad/param norm = 1.5343e-01, time/batch = 14.4690s	
21467/33250 (epoch 32.281), train_loss = 0.85175286, grad/param norm = 1.9006e-01, time/batch = 13.9847s	
21468/33250 (epoch 32.283), train_loss = 0.86808982, grad/param norm = 3.3398e-01, time/batch = 14.6231s	
21469/33250 (epoch 32.284), train_loss = 0.73426908, grad/param norm = 1.9970e-01, time/batch = 14.4721s	
21470/33250 (epoch 32.286), train_loss = 0.87094184, grad/param norm = 1.9365e-01, time/batch = 16.0349s	
21471/33250 (epoch 32.287), train_loss = 0.68751410, grad/param norm = 1.4374e-01, time/batch = 17.0344s	
21472/33250 (epoch 32.289), train_loss = 0.65549540, grad/param norm = 1.6657e-01, time/batch = 15.7607s	
21473/33250 (epoch 32.290), train_loss = 0.83246716, grad/param norm = 1.5661e-01, time/batch = 15.1078s	
21474/33250 (epoch 32.292), train_loss = 0.87744819, grad/param norm = 2.3379e-01, time/batch = 19.2082s	
21475/33250 (epoch 32.293), train_loss = 0.92967228, grad/param norm = 2.0778e-01, time/batch = 18.7081s	
21476/33250 (epoch 32.295), train_loss = 0.91085444, grad/param norm = 1.7268e-01, time/batch = 18.9474s	
21477/33250 (epoch 32.296), train_loss = 0.82716369, grad/param norm = 1.6652e-01, time/batch = 15.2482s	
21478/33250 (epoch 32.298), train_loss = 0.67111912, grad/param norm = 1.4295e-01, time/batch = 18.5016s	
21479/33250 (epoch 32.299), train_loss = 0.65616480, grad/param norm = 1.5381e-01, time/batch = 17.0986s	
21480/33250 (epoch 32.301), train_loss = 0.92334806, grad/param norm = 1.7563e-01, time/batch = 15.9979s	
21481/33250 (epoch 32.302), train_loss = 0.86574415, grad/param norm = 1.7620e-01, time/batch = 18.5875s	
21482/33250 (epoch 32.304), train_loss = 0.77157498, grad/param norm = 1.5605e-01, time/batch = 16.2171s	
21483/33250 (epoch 32.305), train_loss = 0.76418585, grad/param norm = 1.6343e-01, time/batch = 18.2901s	
21484/33250 (epoch 32.307), train_loss = 0.88908965, grad/param norm = 1.7373e-01, time/batch = 17.5349s	
21485/33250 (epoch 32.308), train_loss = 0.93692478, grad/param norm = 2.0629e-01, time/batch = 18.7055s	
21486/33250 (epoch 32.310), train_loss = 0.79873773, grad/param norm = 2.2149e-01, time/batch = 16.6815s	
21487/33250 (epoch 32.311), train_loss = 0.96560250, grad/param norm = 1.9693e-01, time/batch = 15.1797s	
21488/33250 (epoch 32.313), train_loss = 0.68380216, grad/param norm = 1.6565e-01, time/batch = 15.9371s	
21489/33250 (epoch 32.314), train_loss = 0.85332301, grad/param norm = 1.5534e-01, time/batch = 17.3621s	
21490/33250 (epoch 32.316), train_loss = 0.99894899, grad/param norm = 2.2145e-01, time/batch = 17.7558s	
21491/33250 (epoch 32.317), train_loss = 0.74110558, grad/param norm = 1.5397e-01, time/batch = 16.0241s	
21492/33250 (epoch 32.319), train_loss = 0.89542888, grad/param norm = 2.3623e-01, time/batch = 17.1826s	
21493/33250 (epoch 32.320), train_loss = 0.89698844, grad/param norm = 2.1310e-01, time/batch = 19.0394s	
21494/33250 (epoch 32.322), train_loss = 0.96178921, grad/param norm = 1.9773e-01, time/batch = 16.7919s	
21495/33250 (epoch 32.323), train_loss = 0.98546929, grad/param norm = 2.4874e-01, time/batch = 16.9447s	
21496/33250 (epoch 32.325), train_loss = 0.80041947, grad/param norm = 1.8899e-01, time/batch = 17.8577s	
21497/33250 (epoch 32.326), train_loss = 1.01652484, grad/param norm = 1.8502e-01, time/batch = 15.8277s	
21498/33250 (epoch 32.328), train_loss = 0.81164382, grad/param norm = 1.7302e-01, time/batch = 15.1676s	
21499/33250 (epoch 32.329), train_loss = 0.84441209, grad/param norm = 2.3434e-01, time/batch = 15.1701s	
21500/33250 (epoch 32.331), train_loss = 0.83635560, grad/param norm = 1.8500e-01, time/batch = 14.8302s	
21501/33250 (epoch 32.332), train_loss = 0.83194250, grad/param norm = 1.6338e-01, time/batch = 15.4605s	
21502/33250 (epoch 32.334), train_loss = 0.98616546, grad/param norm = 2.2350e-01, time/batch = 15.1585s	
21503/33250 (epoch 32.335), train_loss = 0.63049038, grad/param norm = 1.5372e-01, time/batch = 14.6329s	
21504/33250 (epoch 32.337), train_loss = 0.87904639, grad/param norm = 1.6437e-01, time/batch = 15.4990s	
21505/33250 (epoch 32.338), train_loss = 0.95607473, grad/param norm = 1.6975e-01, time/batch = 14.9606s	
21506/33250 (epoch 32.340), train_loss = 0.81457675, grad/param norm = 1.8951e-01, time/batch = 15.1954s	
21507/33250 (epoch 32.341), train_loss = 0.76406538, grad/param norm = 1.5968e-01, time/batch = 14.8568s	
21508/33250 (epoch 32.343), train_loss = 0.78793488, grad/param norm = 1.8780e-01, time/batch = 14.7018s	
21509/33250 (epoch 32.344), train_loss = 0.82112771, grad/param norm = 1.5307e-01, time/batch = 15.2448s	
21510/33250 (epoch 32.346), train_loss = 0.71673501, grad/param norm = 1.4724e-01, time/batch = 15.1616s	
21511/33250 (epoch 32.347), train_loss = 1.03304670, grad/param norm = 2.1009e-01, time/batch = 14.9211s	
21512/33250 (epoch 32.349), train_loss = 0.78340614, grad/param norm = 1.8822e-01, time/batch = 14.6992s	
21513/33250 (epoch 32.350), train_loss = 0.83815346, grad/param norm = 1.8247e-01, time/batch = 15.1671s	
21514/33250 (epoch 32.352), train_loss = 0.73512941, grad/param norm = 1.6901e-01, time/batch = 15.0204s	
21515/33250 (epoch 32.353), train_loss = 0.79373771, grad/param norm = 1.4960e-01, time/batch = 14.6422s	
21516/33250 (epoch 32.355), train_loss = 0.78011622, grad/param norm = 1.6508e-01, time/batch = 14.6342s	
21517/33250 (epoch 32.356), train_loss = 0.72716787, grad/param norm = 1.6521e-01, time/batch = 15.4098s	
21518/33250 (epoch 32.358), train_loss = 0.78955428, grad/param norm = 1.4426e-01, time/batch = 15.0230s	
21519/33250 (epoch 32.359), train_loss = 0.79133170, grad/param norm = 1.6464e-01, time/batch = 14.6109s	
21520/33250 (epoch 32.361), train_loss = 0.93521673, grad/param norm = 2.1030e-01, time/batch = 14.7669s	
21521/33250 (epoch 32.362), train_loss = 0.86210515, grad/param norm = 1.8375e-01, time/batch = 15.2541s	
21522/33250 (epoch 32.364), train_loss = 0.88184398, grad/param norm = 1.8297e-01, time/batch = 14.8586s	
21523/33250 (epoch 32.365), train_loss = 0.83130128, grad/param norm = 1.9621e-01, time/batch = 14.8591s	
21524/33250 (epoch 32.367), train_loss = 0.85120200, grad/param norm = 1.6688e-01, time/batch = 14.8540s	
21525/33250 (epoch 32.368), train_loss = 0.82048253, grad/param norm = 1.7054e-01, time/batch = 14.8653s	
21526/33250 (epoch 32.370), train_loss = 0.72732319, grad/param norm = 1.3608e-01, time/batch = 14.7864s	
21527/33250 (epoch 32.371), train_loss = 0.92992751, grad/param norm = 1.8263e-01, time/batch = 14.7139s	
21528/33250 (epoch 32.373), train_loss = 0.78187156, grad/param norm = 1.5184e-01, time/batch = 14.3282s	
21529/33250 (epoch 32.374), train_loss = 0.83154263, grad/param norm = 1.9083e-01, time/batch = 15.0838s	
21530/33250 (epoch 32.376), train_loss = 0.81499197, grad/param norm = 1.5701e-01, time/batch = 14.9235s	
21531/33250 (epoch 32.377), train_loss = 0.73342249, grad/param norm = 2.1301e-01, time/batch = 14.4595s	
21532/33250 (epoch 32.379), train_loss = 0.82725007, grad/param norm = 1.8298e-01, time/batch = 14.6187s	
21533/33250 (epoch 32.380), train_loss = 0.84063671, grad/param norm = 1.9844e-01, time/batch = 15.1710s	
21534/33250 (epoch 32.382), train_loss = 0.86035927, grad/param norm = 1.9304e-01, time/batch = 15.2564s	
21535/33250 (epoch 32.383), train_loss = 0.74613853, grad/param norm = 1.7143e-01, time/batch = 15.0027s	
21536/33250 (epoch 32.385), train_loss = 0.70553291, grad/param norm = 1.6240e-01, time/batch = 14.7922s	
21537/33250 (epoch 32.386), train_loss = 0.71470745, grad/param norm = 1.7769e-01, time/batch = 15.2421s	
21538/33250 (epoch 32.388), train_loss = 0.73961729, grad/param norm = 1.5044e-01, time/batch = 14.8775s	
21539/33250 (epoch 32.389), train_loss = 0.80165359, grad/param norm = 1.9039e-01, time/batch = 14.7176s	
21540/33250 (epoch 32.391), train_loss = 0.87601431, grad/param norm = 1.6932e-01, time/batch = 14.7744s	
21541/33250 (epoch 32.392), train_loss = 0.91081448, grad/param norm = 1.7650e-01, time/batch = 15.0154s	
21542/33250 (epoch 32.394), train_loss = 0.90781839, grad/param norm = 1.8972e-01, time/batch = 14.9399s	
21543/33250 (epoch 32.395), train_loss = 0.90633460, grad/param norm = 1.6729e-01, time/batch = 14.7838s	
21544/33250 (epoch 32.397), train_loss = 0.92698531, grad/param norm = 1.6136e-01, time/batch = 15.0906s	
21545/33250 (epoch 32.398), train_loss = 0.74940302, grad/param norm = 1.5539e-01, time/batch = 14.7648s	
21546/33250 (epoch 32.400), train_loss = 0.73331688, grad/param norm = 1.4148e-01, time/batch = 14.2237s	
21547/33250 (epoch 32.402), train_loss = 0.70097417, grad/param norm = 1.6228e-01, time/batch = 14.6210s	
21548/33250 (epoch 32.403), train_loss = 0.81133338, grad/param norm = 1.9423e-01, time/batch = 14.9387s	
21549/33250 (epoch 32.405), train_loss = 0.75113188, grad/param norm = 1.3196e-01, time/batch = 14.9569s	
21550/33250 (epoch 32.406), train_loss = 0.81078127, grad/param norm = 1.8075e-01, time/batch = 15.1020s	
21551/33250 (epoch 32.408), train_loss = 0.97511909, grad/param norm = 1.7475e-01, time/batch = 14.7049s	
21552/33250 (epoch 32.409), train_loss = 0.88676666, grad/param norm = 2.2187e-01, time/batch = 14.9181s	
21553/33250 (epoch 32.411), train_loss = 0.59663996, grad/param norm = 1.3201e-01, time/batch = 14.7766s	
21554/33250 (epoch 32.412), train_loss = 0.68727732, grad/param norm = 1.6097e-01, time/batch = 14.6178s	
21555/33250 (epoch 32.414), train_loss = 0.84734810, grad/param norm = 1.7186e-01, time/batch = 14.6168s	
21556/33250 (epoch 32.415), train_loss = 0.87991681, grad/param norm = 1.8299e-01, time/batch = 14.5269s	
21557/33250 (epoch 32.417), train_loss = 0.90917482, grad/param norm = 1.6114e-01, time/batch = 14.5181s	
21558/33250 (epoch 32.418), train_loss = 1.07636367, grad/param norm = 2.2834e-01, time/batch = 14.6836s	
21559/33250 (epoch 32.420), train_loss = 0.89999766, grad/param norm = 1.8376e-01, time/batch = 14.6463s	
21560/33250 (epoch 32.421), train_loss = 0.77489850, grad/param norm = 1.5547e-01, time/batch = 14.8743s	
21561/33250 (epoch 32.423), train_loss = 0.85739339, grad/param norm = 1.8415e-01, time/batch = 14.8773s	
21562/33250 (epoch 32.424), train_loss = 0.94558190, grad/param norm = 2.3718e-01, time/batch = 15.6658s	
21563/33250 (epoch 32.426), train_loss = 0.79883186, grad/param norm = 1.4038e-01, time/batch = 15.5647s	
21564/33250 (epoch 32.427), train_loss = 0.76190249, grad/param norm = 1.6157e-01, time/batch = 15.2503s	
21565/33250 (epoch 32.429), train_loss = 0.88604821, grad/param norm = 2.0969e-01, time/batch = 15.3271s	
21566/33250 (epoch 32.430), train_loss = 0.76479376, grad/param norm = 1.7013e-01, time/batch = 15.0989s	
21567/33250 (epoch 32.432), train_loss = 0.88158677, grad/param norm = 1.5914e-01, time/batch = 15.0855s	
21568/33250 (epoch 32.433), train_loss = 0.75419312, grad/param norm = 2.0726e-01, time/batch = 14.7760s	
21569/33250 (epoch 32.435), train_loss = 0.91213492, grad/param norm = 1.7959e-01, time/batch = 14.7778s	
21570/33250 (epoch 32.436), train_loss = 0.79382922, grad/param norm = 1.9340e-01, time/batch = 14.9388s	
21571/33250 (epoch 32.438), train_loss = 0.91752127, grad/param norm = 1.6415e-01, time/batch = 15.4007s	
21572/33250 (epoch 32.439), train_loss = 0.85132578, grad/param norm = 1.7956e-01, time/batch = 15.1188s	
21573/33250 (epoch 32.441), train_loss = 0.80705191, grad/param norm = 1.4555e-01, time/batch = 15.0370s	
21574/33250 (epoch 32.442), train_loss = 0.76085100, grad/param norm = 1.7384e-01, time/batch = 14.7030s	
21575/33250 (epoch 32.444), train_loss = 0.77825186, grad/param norm = 1.5148e-01, time/batch = 14.4575s	
21576/33250 (epoch 32.445), train_loss = 0.84959722, grad/param norm = 1.6460e-01, time/batch = 14.6983s	
21577/33250 (epoch 32.447), train_loss = 0.74591021, grad/param norm = 1.6923e-01, time/batch = 14.9328s	
21578/33250 (epoch 32.448), train_loss = 0.84296367, grad/param norm = 1.5244e-01, time/batch = 15.0174s	
21579/33250 (epoch 32.450), train_loss = 0.94912591, grad/param norm = 1.8866e-01, time/batch = 15.0945s	
21580/33250 (epoch 32.451), train_loss = 0.87564849, grad/param norm = 2.1111e-01, time/batch = 15.0279s	
21581/33250 (epoch 32.453), train_loss = 0.74092742, grad/param norm = 1.3919e-01, time/batch = 14.8962s	
21582/33250 (epoch 32.454), train_loss = 0.96138579, grad/param norm = 1.7493e-01, time/batch = 15.0479s	
21583/33250 (epoch 32.456), train_loss = 0.94691510, grad/param norm = 1.5247e-01, time/batch = 14.6426s	
21584/33250 (epoch 32.457), train_loss = 0.76382788, grad/param norm = 1.8221e-01, time/batch = 15.0361s	
21585/33250 (epoch 32.459), train_loss = 0.90087922, grad/param norm = 1.7133e-01, time/batch = 14.9390s	
21586/33250 (epoch 32.460), train_loss = 0.89520259, grad/param norm = 1.7757e-01, time/batch = 14.8578s	
21587/33250 (epoch 32.462), train_loss = 0.81718391, grad/param norm = 1.7598e-01, time/batch = 14.9328s	
21588/33250 (epoch 32.463), train_loss = 0.74672834, grad/param norm = 1.3643e-01, time/batch = 14.7055s	
21589/33250 (epoch 32.465), train_loss = 0.68434195, grad/param norm = 1.4015e-01, time/batch = 15.0192s	
21590/33250 (epoch 32.466), train_loss = 0.66219191, grad/param norm = 1.2346e-01, time/batch = 14.9398s	
21591/33250 (epoch 32.468), train_loss = 0.72221144, grad/param norm = 1.3831e-01, time/batch = 14.9487s	
21592/33250 (epoch 32.469), train_loss = 0.80108823, grad/param norm = 2.0621e-01, time/batch = 15.2590s	
21593/33250 (epoch 32.471), train_loss = 0.89513940, grad/param norm = 1.6006e-01, time/batch = 14.8872s	
21594/33250 (epoch 32.472), train_loss = 0.78221955, grad/param norm = 1.6407e-01, time/batch = 14.9576s	
21595/33250 (epoch 32.474), train_loss = 0.92793539, grad/param norm = 1.8363e-01, time/batch = 15.4506s	
21596/33250 (epoch 32.475), train_loss = 0.85212256, grad/param norm = 1.6060e-01, time/batch = 16.1978s	
21597/33250 (epoch 32.477), train_loss = 0.83797932, grad/param norm = 1.5582e-01, time/batch = 15.2612s	
21598/33250 (epoch 32.478), train_loss = 0.74865437, grad/param norm = 1.8593e-01, time/batch = 16.8497s	
21599/33250 (epoch 32.480), train_loss = 0.95019235, grad/param norm = 1.7807e-01, time/batch = 16.2618s	
21600/33250 (epoch 32.481), train_loss = 0.81135070, grad/param norm = 1.5470e-01, time/batch = 16.9207s	
21601/33250 (epoch 32.483), train_loss = 0.79140589, grad/param norm = 1.4841e-01, time/batch = 17.4298s	
21602/33250 (epoch 32.484), train_loss = 0.74668516, grad/param norm = 1.4679e-01, time/batch = 19.6883s	
21603/33250 (epoch 32.486), train_loss = 0.70650423, grad/param norm = 1.5370e-01, time/batch = 15.9210s	
21604/33250 (epoch 32.487), train_loss = 0.76898056, grad/param norm = 1.6594e-01, time/batch = 16.6986s	
21605/33250 (epoch 32.489), train_loss = 0.92078452, grad/param norm = 2.1356e-01, time/batch = 19.9152s	
21606/33250 (epoch 32.490), train_loss = 0.87987261, grad/param norm = 1.8239e-01, time/batch = 17.0059s	
21607/33250 (epoch 32.492), train_loss = 0.92107127, grad/param norm = 1.8634e-01, time/batch = 18.2406s	
21608/33250 (epoch 32.493), train_loss = 0.83477664, grad/param norm = 1.7359e-01, time/batch = 16.0325s	
21609/33250 (epoch 32.495), train_loss = 0.88577051, grad/param norm = 1.4268e-01, time/batch = 17.6021s	
21610/33250 (epoch 32.496), train_loss = 0.82813491, grad/param norm = 1.3877e-01, time/batch = 17.2660s	
21611/33250 (epoch 32.498), train_loss = 0.91213308, grad/param norm = 1.7542e-01, time/batch = 16.5885s	
21612/33250 (epoch 32.499), train_loss = 0.77628387, grad/param norm = 1.5226e-01, time/batch = 15.7611s	
21613/33250 (epoch 32.501), train_loss = 0.77644439, grad/param norm = 1.8180e-01, time/batch = 19.5976s	
21614/33250 (epoch 32.502), train_loss = 0.77721539, grad/param norm = 1.4692e-01, time/batch = 17.0295s	
21615/33250 (epoch 32.504), train_loss = 0.95668656, grad/param norm = 1.8431e-01, time/batch = 28.5372s	
21616/33250 (epoch 32.505), train_loss = 0.69852777, grad/param norm = 1.3090e-01, time/batch = 16.0334s	
21617/33250 (epoch 32.507), train_loss = 0.74265447, grad/param norm = 1.6007e-01, time/batch = 16.0014s	
21618/33250 (epoch 32.508), train_loss = 0.78055380, grad/param norm = 1.6019e-01, time/batch = 15.2479s	
21619/33250 (epoch 32.510), train_loss = 0.68290097, grad/param norm = 1.3686e-01, time/batch = 15.5244s	
21620/33250 (epoch 32.511), train_loss = 0.81710361, grad/param norm = 1.8754e-01, time/batch = 15.1024s	
21621/33250 (epoch 32.513), train_loss = 0.92785514, grad/param norm = 1.6069e-01, time/batch = 14.9613s	
21622/33250 (epoch 32.514), train_loss = 0.81099498, grad/param norm = 1.7446e-01, time/batch = 15.2569s	
21623/33250 (epoch 32.516), train_loss = 0.77639934, grad/param norm = 1.7626e-01, time/batch = 14.7169s	
21624/33250 (epoch 32.517), train_loss = 0.79810788, grad/param norm = 1.6294e-01, time/batch = 14.7999s	
21625/33250 (epoch 32.519), train_loss = 0.71277935, grad/param norm = 1.1990e-01, time/batch = 15.0150s	
21626/33250 (epoch 32.520), train_loss = 0.99710578, grad/param norm = 1.9096e-01, time/batch = 15.1003s	
21627/33250 (epoch 32.522), train_loss = 0.87305565, grad/param norm = 1.6929e-01, time/batch = 14.7749s	
21628/33250 (epoch 32.523), train_loss = 0.75017875, grad/param norm = 1.5742e-01, time/batch = 15.0864s	
21629/33250 (epoch 32.525), train_loss = 0.70286288, grad/param norm = 1.8119e-01, time/batch = 14.7748s	
21630/33250 (epoch 32.526), train_loss = 0.73602581, grad/param norm = 1.4997e-01, time/batch = 14.7677s	
21631/33250 (epoch 32.528), train_loss = 0.79488251, grad/param norm = 1.6376e-01, time/batch = 14.6141s	
21632/33250 (epoch 32.529), train_loss = 0.76173442, grad/param norm = 1.5274e-01, time/batch = 14.6183s	
21633/33250 (epoch 32.531), train_loss = 0.73229480, grad/param norm = 1.4911e-01, time/batch = 15.4215s	
21634/33250 (epoch 32.532), train_loss = 0.86028995, grad/param norm = 1.6016e-01, time/batch = 14.8776s	
21635/33250 (epoch 32.534), train_loss = 0.73462004, grad/param norm = 1.5760e-01, time/batch = 14.8820s	
21636/33250 (epoch 32.535), train_loss = 0.80765135, grad/param norm = 1.5478e-01, time/batch = 14.6535s	
21637/33250 (epoch 32.537), train_loss = 0.83119045, grad/param norm = 1.5572e-01, time/batch = 14.9413s	
21638/33250 (epoch 32.538), train_loss = 0.85777277, grad/param norm = 1.6301e-01, time/batch = 15.2535s	
21639/33250 (epoch 32.540), train_loss = 0.95229183, grad/param norm = 1.5028e-01, time/batch = 14.6282s	
21640/33250 (epoch 32.541), train_loss = 0.90428451, grad/param norm = 1.9121e-01, time/batch = 15.0947s	
21641/33250 (epoch 32.543), train_loss = 0.86423315, grad/param norm = 1.8031e-01, time/batch = 14.6945s	
21642/33250 (epoch 32.544), train_loss = 0.74446902, grad/param norm = 1.6658e-01, time/batch = 14.9205s	
21643/33250 (epoch 32.546), train_loss = 0.78800507, grad/param norm = 1.9833e-01, time/batch = 14.6288s	
21644/33250 (epoch 32.547), train_loss = 0.79629210, grad/param norm = 1.7313e-01, time/batch = 14.4053s	
21645/33250 (epoch 32.549), train_loss = 0.85012194, grad/param norm = 1.8874e-01, time/batch = 14.8753s	
21646/33250 (epoch 32.550), train_loss = 0.78658876, grad/param norm = 1.5411e-01, time/batch = 15.3559s	
21647/33250 (epoch 32.552), train_loss = 0.86229378, grad/param norm = 1.5812e-01, time/batch = 14.7119s	
21648/33250 (epoch 32.553), train_loss = 0.79753054, grad/param norm = 1.5876e-01, time/batch = 14.7119s	
21649/33250 (epoch 32.555), train_loss = 0.84136907, grad/param norm = 1.8183e-01, time/batch = 15.1796s	
21650/33250 (epoch 32.556), train_loss = 0.84271817, grad/param norm = 2.1600e-01, time/batch = 14.7774s	
21651/33250 (epoch 32.558), train_loss = 0.88977052, grad/param norm = 1.8681e-01, time/batch = 14.8630s	
21652/33250 (epoch 32.559), train_loss = 0.75238681, grad/param norm = 1.5264e-01, time/batch = 14.7851s	
21653/33250 (epoch 32.561), train_loss = 0.72857414, grad/param norm = 1.5265e-01, time/batch = 15.0879s	
21654/33250 (epoch 32.562), train_loss = 0.83228221, grad/param norm = 1.8568e-01, time/batch = 15.0178s	
21655/33250 (epoch 32.564), train_loss = 0.98843761, grad/param norm = 2.1441e-01, time/batch = 15.0191s	
21656/33250 (epoch 32.565), train_loss = 0.93995148, grad/param norm = 2.2548e-01, time/batch = 14.7127s	
21657/33250 (epoch 32.567), train_loss = 0.91643122, grad/param norm = 1.7628e-01, time/batch = 14.8816s	
21658/33250 (epoch 32.568), train_loss = 0.77156443, grad/param norm = 1.5153e-01, time/batch = 15.0423s	
21659/33250 (epoch 32.570), train_loss = 0.89775429, grad/param norm = 1.9206e-01, time/batch = 14.7265s	
21660/33250 (epoch 32.571), train_loss = 0.94776631, grad/param norm = 1.7442e-01, time/batch = 15.1141s	
21661/33250 (epoch 32.573), train_loss = 0.87747797, grad/param norm = 1.9087e-01, time/batch = 15.0997s	
21662/33250 (epoch 32.574), train_loss = 0.77713657, grad/param norm = 1.4347e-01, time/batch = 15.1800s	
21663/33250 (epoch 32.576), train_loss = 0.88747203, grad/param norm = 1.8135e-01, time/batch = 14.8640s	
21664/33250 (epoch 32.577), train_loss = 0.81748658, grad/param norm = 1.5554e-01, time/batch = 14.7878s	
21665/33250 (epoch 32.579), train_loss = 0.71981065, grad/param norm = 1.5956e-01, time/batch = 14.8591s	
21666/33250 (epoch 32.580), train_loss = 0.81386312, grad/param norm = 1.4610e-01, time/batch = 14.8625s	
21667/33250 (epoch 32.582), train_loss = 0.77590987, grad/param norm = 1.5319e-01, time/batch = 15.3424s	
21668/33250 (epoch 32.583), train_loss = 0.90105315, grad/param norm = 1.5981e-01, time/batch = 14.7911s	
21669/33250 (epoch 32.585), train_loss = 0.91760517, grad/param norm = 1.6056e-01, time/batch = 15.1894s	
21670/33250 (epoch 32.586), train_loss = 0.79834089, grad/param norm = 1.9798e-01, time/batch = 15.1053s	
21671/33250 (epoch 32.588), train_loss = 0.86257830, grad/param norm = 1.6891e-01, time/batch = 14.7904s	
21672/33250 (epoch 32.589), train_loss = 0.82436839, grad/param norm = 1.5327e-01, time/batch = 15.7949s	
21673/33250 (epoch 32.591), train_loss = 0.80578794, grad/param norm = 1.7952e-01, time/batch = 15.3400s	
21674/33250 (epoch 32.592), train_loss = 0.79131431, grad/param norm = 1.5950e-01, time/batch = 15.0234s	
21675/33250 (epoch 32.594), train_loss = 0.94429006, grad/param norm = 2.0671e-01, time/batch = 15.1816s	
21676/33250 (epoch 32.595), train_loss = 0.83507817, grad/param norm = 1.6944e-01, time/batch = 15.0720s	
21677/33250 (epoch 32.597), train_loss = 0.70184945, grad/param norm = 1.5286e-01, time/batch = 14.9414s	
21678/33250 (epoch 32.598), train_loss = 0.78911933, grad/param norm = 1.8303e-01, time/batch = 14.8733s	
21679/33250 (epoch 32.600), train_loss = 0.79221304, grad/param norm = 1.7842e-01, time/batch = 14.6391s	
21680/33250 (epoch 32.602), train_loss = 0.84720040, grad/param norm = 2.0089e-01, time/batch = 14.9561s	
21681/33250 (epoch 32.603), train_loss = 0.87154586, grad/param norm = 1.8200e-01, time/batch = 15.1317s	
21682/33250 (epoch 32.605), train_loss = 0.82095320, grad/param norm = 1.6543e-01, time/batch = 14.9497s	
21683/33250 (epoch 32.606), train_loss = 0.89489750, grad/param norm = 1.8691e-01, time/batch = 14.9978s	
21684/33250 (epoch 32.608), train_loss = 0.85732149, grad/param norm = 1.6437e-01, time/batch = 14.8661s	
21685/33250 (epoch 32.609), train_loss = 0.74504892, grad/param norm = 1.7032e-01, time/batch = 15.1821s	
21686/33250 (epoch 32.611), train_loss = 0.82554931, grad/param norm = 1.8435e-01, time/batch = 14.7779s	
21687/33250 (epoch 32.612), train_loss = 0.80790871, grad/param norm = 1.7650e-01, time/batch = 14.8632s	
21688/33250 (epoch 32.614), train_loss = 1.01951634, grad/param norm = 1.9539e-01, time/batch = 14.5508s	
21689/33250 (epoch 32.615), train_loss = 0.92947225, grad/param norm = 1.7381e-01, time/batch = 14.7879s	
21690/33250 (epoch 32.617), train_loss = 1.04113847, grad/param norm = 2.3696e-01, time/batch = 14.8053s	
21691/33250 (epoch 32.618), train_loss = 1.07090587, grad/param norm = 2.3271e-01, time/batch = 14.9450s	
21692/33250 (epoch 32.620), train_loss = 0.93864511, grad/param norm = 2.0488e-01, time/batch = 14.9504s	
21693/33250 (epoch 32.621), train_loss = 0.87617805, grad/param norm = 1.6143e-01, time/batch = 14.9580s	
21694/33250 (epoch 32.623), train_loss = 0.77959114, grad/param norm = 1.7208e-01, time/batch = 15.1742s	
21695/33250 (epoch 32.624), train_loss = 0.81294893, grad/param norm = 2.0732e-01, time/batch = 14.7101s	
21696/33250 (epoch 32.626), train_loss = 0.80854968, grad/param norm = 2.0567e-01, time/batch = 14.8566s	
21697/33250 (epoch 32.627), train_loss = 0.79404311, grad/param norm = 1.6646e-01, time/batch = 15.0251s	
21698/33250 (epoch 32.629), train_loss = 0.86184216, grad/param norm = 1.8441e-01, time/batch = 14.9385s	
21699/33250 (epoch 32.630), train_loss = 0.79665911, grad/param norm = 1.7919e-01, time/batch = 14.9378s	
21700/33250 (epoch 32.632), train_loss = 0.73287900, grad/param norm = 1.5108e-01, time/batch = 15.4384s	
21701/33250 (epoch 32.633), train_loss = 0.83420225, grad/param norm = 1.7531e-01, time/batch = 16.2762s	
21702/33250 (epoch 32.635), train_loss = 0.75599070, grad/param norm = 1.5658e-01, time/batch = 18.9655s	
21703/33250 (epoch 32.636), train_loss = 0.77313590, grad/param norm = 1.6686e-01, time/batch = 16.9280s	
21704/33250 (epoch 32.638), train_loss = 0.75187195, grad/param norm = 1.8076e-01, time/batch = 15.6290s	
21705/33250 (epoch 32.639), train_loss = 0.70966326, grad/param norm = 1.7049e-01, time/batch = 16.2829s	
21706/33250 (epoch 32.641), train_loss = 0.81740278, grad/param norm = 1.7158e-01, time/batch = 17.3522s	
21707/33250 (epoch 32.642), train_loss = 0.63368487, grad/param norm = 1.6297e-01, time/batch = 17.8408s	
21708/33250 (epoch 32.644), train_loss = 0.58398502, grad/param norm = 1.4659e-01, time/batch = 15.1111s	
21709/33250 (epoch 32.645), train_loss = 0.84942288, grad/param norm = 1.9233e-01, time/batch = 16.1880s	
21710/33250 (epoch 32.647), train_loss = 0.72372992, grad/param norm = 1.6498e-01, time/batch = 16.9262s	
21711/33250 (epoch 32.648), train_loss = 0.72170256, grad/param norm = 1.6682e-01, time/batch = 18.9574s	
21712/33250 (epoch 32.650), train_loss = 0.95173045, grad/param norm = 1.8547e-01, time/batch = 17.3533s	
21713/33250 (epoch 32.651), train_loss = 0.86258221, grad/param norm = 1.9020e-01, time/batch = 18.8606s	
21714/33250 (epoch 32.653), train_loss = 0.76850657, grad/param norm = 1.6427e-01, time/batch = 16.7827s	
21715/33250 (epoch 32.654), train_loss = 0.82573569, grad/param norm = 1.6225e-01, time/batch = 17.5836s	
21716/33250 (epoch 32.656), train_loss = 0.87159377, grad/param norm = 1.6911e-01, time/batch = 17.2648s	
21717/33250 (epoch 32.657), train_loss = 0.65755746, grad/param norm = 1.6888e-01, time/batch = 15.7588s	
21718/33250 (epoch 32.659), train_loss = 0.77413797, grad/param norm = 1.9252e-01, time/batch = 16.2494s	
21719/33250 (epoch 32.660), train_loss = 0.82503827, grad/param norm = 1.6604e-01, time/batch = 16.5931s	
21720/33250 (epoch 32.662), train_loss = 0.83266239, grad/param norm = 1.7019e-01, time/batch = 17.5978s	
21721/33250 (epoch 32.663), train_loss = 0.75408365, grad/param norm = 1.6870e-01, time/batch = 19.6115s	
21722/33250 (epoch 32.665), train_loss = 0.85005577, grad/param norm = 1.8381e-01, time/batch = 17.1952s	
21723/33250 (epoch 32.666), train_loss = 0.78026922, grad/param norm = 1.4750e-01, time/batch = 18.9408s	
21724/33250 (epoch 32.668), train_loss = 0.91599963, grad/param norm = 1.6744e-01, time/batch = 15.8673s	
21725/33250 (epoch 32.669), train_loss = 0.82054537, grad/param norm = 1.7063e-01, time/batch = 16.6565s	
21726/33250 (epoch 32.671), train_loss = 0.72507780, grad/param norm = 1.9584e-01, time/batch = 17.6607s	
21727/33250 (epoch 32.672), train_loss = 0.89883621, grad/param norm = 1.5736e-01, time/batch = 17.6904s	
21728/33250 (epoch 32.674), train_loss = 0.72448259, grad/param norm = 1.6484e-01, time/batch = 17.5303s	
21729/33250 (epoch 32.675), train_loss = 0.82982455, grad/param norm = 1.5152e-01, time/batch = 15.3475s	
21730/33250 (epoch 32.677), train_loss = 0.89609831, grad/param norm = 1.7867e-01, time/batch = 17.6098s	
21731/33250 (epoch 32.678), train_loss = 0.77945652, grad/param norm = 1.8303e-01, time/batch = 17.2001s	
21732/33250 (epoch 32.680), train_loss = 0.91786590, grad/param norm = 2.0833e-01, time/batch = 15.8781s	
21733/33250 (epoch 32.681), train_loss = 0.76039826, grad/param norm = 1.6763e-01, time/batch = 15.2418s	
21734/33250 (epoch 32.683), train_loss = 0.76976260, grad/param norm = 1.9620e-01, time/batch = 16.2623s	
21735/33250 (epoch 32.684), train_loss = 0.72772811, grad/param norm = 2.0639e-01, time/batch = 16.0190s	
21736/33250 (epoch 32.686), train_loss = 0.75102356, grad/param norm = 1.6660e-01, time/batch = 16.3604s	
21737/33250 (epoch 32.687), train_loss = 0.83555760, grad/param norm = 1.7193e-01, time/batch = 16.7465s	
21738/33250 (epoch 32.689), train_loss = 0.70498413, grad/param norm = 1.6570e-01, time/batch = 16.0321s	
21739/33250 (epoch 32.690), train_loss = 0.84100740, grad/param norm = 1.9178e-01, time/batch = 16.9135s	
21740/33250 (epoch 32.692), train_loss = 0.77767667, grad/param norm = 1.5236e-01, time/batch = 16.4316s	
21741/33250 (epoch 32.693), train_loss = 0.88368704, grad/param norm = 1.8501e-01, time/batch = 15.9463s	
21742/33250 (epoch 32.695), train_loss = 0.83791954, grad/param norm = 1.6377e-01, time/batch = 18.2630s	
21743/33250 (epoch 32.696), train_loss = 0.87113744, grad/param norm = 1.6885e-01, time/batch = 17.6955s	
21744/33250 (epoch 32.698), train_loss = 0.78235631, grad/param norm = 1.7675e-01, time/batch = 18.2655s	
21745/33250 (epoch 32.699), train_loss = 1.02395665, grad/param norm = 1.7799e-01, time/batch = 17.1751s	
21746/33250 (epoch 32.701), train_loss = 0.80544533, grad/param norm = 1.3553e-01, time/batch = 18.4249s	
21747/33250 (epoch 32.702), train_loss = 0.79214258, grad/param norm = 2.3855e-01, time/batch = 15.4222s	
21748/33250 (epoch 32.704), train_loss = 0.99207464, grad/param norm = 2.1227e-01, time/batch = 17.8283s	
21749/33250 (epoch 32.705), train_loss = 0.77855455, grad/param norm = 1.5536e-01, time/batch = 16.7833s	
21750/33250 (epoch 32.707), train_loss = 0.68269081, grad/param norm = 1.4811e-01, time/batch = 18.1009s	
21751/33250 (epoch 32.708), train_loss = 0.89277009, grad/param norm = 1.7163e-01, time/batch = 18.5250s	
21752/33250 (epoch 32.710), train_loss = 0.86536064, grad/param norm = 1.9610e-01, time/batch = 17.1953s	
21753/33250 (epoch 32.711), train_loss = 0.73319595, grad/param norm = 1.7145e-01, time/batch = 17.5939s	
21754/33250 (epoch 32.713), train_loss = 0.84240137, grad/param norm = 1.5240e-01, time/batch = 15.9441s	
21755/33250 (epoch 32.714), train_loss = 0.81420383, grad/param norm = 1.7136e-01, time/batch = 18.4207s	
21756/33250 (epoch 32.716), train_loss = 0.84481005, grad/param norm = 1.7828e-01, time/batch = 17.1131s	
21757/33250 (epoch 32.717), train_loss = 0.75584137, grad/param norm = 1.3007e-01, time/batch = 16.2769s	
21758/33250 (epoch 32.719), train_loss = 0.75526727, grad/param norm = 1.5429e-01, time/batch = 15.6877s	
21759/33250 (epoch 32.720), train_loss = 1.03473743, grad/param norm = 1.9122e-01, time/batch = 17.4126s	
21760/33250 (epoch 32.722), train_loss = 0.72210482, grad/param norm = 1.6552e-01, time/batch = 17.9364s	
21761/33250 (epoch 32.723), train_loss = 0.63874846, grad/param norm = 1.2213e-01, time/batch = 17.2923s	
21762/33250 (epoch 32.725), train_loss = 0.76924593, grad/param norm = 1.4586e-01, time/batch = 18.7010s	
21763/33250 (epoch 32.726), train_loss = 0.81011867, grad/param norm = 1.5175e-01, time/batch = 16.5509s	
21764/33250 (epoch 32.728), train_loss = 0.85786687, grad/param norm = 1.8773e-01, time/batch = 15.2743s	
21765/33250 (epoch 32.729), train_loss = 0.88893048, grad/param norm = 1.7524e-01, time/batch = 15.6927s	
21766/33250 (epoch 32.731), train_loss = 0.75131286, grad/param norm = 1.7777e-01, time/batch = 15.7844s	
21767/33250 (epoch 32.732), train_loss = 0.73852386, grad/param norm = 1.4503e-01, time/batch = 17.7690s	
21768/33250 (epoch 32.734), train_loss = 0.83696546, grad/param norm = 1.8268e-01, time/batch = 15.6916s	
21769/33250 (epoch 32.735), train_loss = 0.84951313, grad/param norm = 1.8519e-01, time/batch = 17.0088s	
21770/33250 (epoch 32.737), train_loss = 0.77952950, grad/param norm = 1.5173e-01, time/batch = 17.1899s	
21771/33250 (epoch 32.738), train_loss = 0.84767303, grad/param norm = 1.6322e-01, time/batch = 16.2032s	
21772/33250 (epoch 32.740), train_loss = 0.85948365, grad/param norm = 1.7062e-01, time/batch = 17.0901s	
21773/33250 (epoch 32.741), train_loss = 0.86863297, grad/param norm = 1.7486e-01, time/batch = 17.8723s	
21774/33250 (epoch 32.743), train_loss = 0.76318224, grad/param norm = 1.5819e-01, time/batch = 16.2630s	
21775/33250 (epoch 32.744), train_loss = 0.77438147, grad/param norm = 1.5800e-01, time/batch = 16.1878s	
21776/33250 (epoch 32.746), train_loss = 0.73533641, grad/param norm = 1.5951e-01, time/batch = 16.5890s	
21777/33250 (epoch 32.747), train_loss = 0.75911075, grad/param norm = 1.5382e-01, time/batch = 17.5921s	
21778/33250 (epoch 32.749), train_loss = 0.92909741, grad/param norm = 1.9908e-01, time/batch = 15.8546s	
21779/33250 (epoch 32.750), train_loss = 0.91218894, grad/param norm = 1.7457e-01, time/batch = 14.8658s	
21780/33250 (epoch 32.752), train_loss = 0.77893084, grad/param norm = 1.5782e-01, time/batch = 18.1268s	
21781/33250 (epoch 32.753), train_loss = 0.75880720, grad/param norm = 1.6233e-01, time/batch = 19.6878s	
21782/33250 (epoch 32.755), train_loss = 0.73524561, grad/param norm = 1.8436e-01, time/batch = 16.8706s	
21783/33250 (epoch 32.756), train_loss = 0.82021732, grad/param norm = 1.6541e-01, time/batch = 17.8579s	
21784/33250 (epoch 32.758), train_loss = 0.96278516, grad/param norm = 1.5955e-01, time/batch = 16.6791s	
21785/33250 (epoch 32.759), train_loss = 0.76804175, grad/param norm = 1.4984e-01, time/batch = 16.1769s	
21786/33250 (epoch 32.761), train_loss = 0.84885351, grad/param norm = 1.7863e-01, time/batch = 17.1613s	
21787/33250 (epoch 32.762), train_loss = 0.88434841, grad/param norm = 1.7881e-01, time/batch = 17.3527s	
21788/33250 (epoch 32.764), train_loss = 0.73569895, grad/param norm = 1.8975e-01, time/batch = 17.4145s	
21789/33250 (epoch 32.765), train_loss = 0.86565304, grad/param norm = 1.7490e-01, time/batch = 14.9349s	
21790/33250 (epoch 32.767), train_loss = 0.65114180, grad/param norm = 1.5231e-01, time/batch = 20.0264s	
21791/33250 (epoch 32.768), train_loss = 0.68954108, grad/param norm = 1.5824e-01, time/batch = 17.3580s	
21792/33250 (epoch 32.770), train_loss = 0.85355045, grad/param norm = 1.8427e-01, time/batch = 17.4490s	
21793/33250 (epoch 32.771), train_loss = 0.84941583, grad/param norm = 1.6589e-01, time/batch = 16.4346s	
21794/33250 (epoch 32.773), train_loss = 0.79935786, grad/param norm = 1.6151e-01, time/batch = 17.6924s	
21795/33250 (epoch 32.774), train_loss = 0.70211226, grad/param norm = 1.5947e-01, time/batch = 19.0784s	
21796/33250 (epoch 32.776), train_loss = 0.77755502, grad/param norm = 1.6676e-01, time/batch = 15.6055s	
21797/33250 (epoch 32.777), train_loss = 0.90308247, grad/param norm = 1.6922e-01, time/batch = 18.5822s	
21798/33250 (epoch 32.779), train_loss = 0.79458781, grad/param norm = 1.7125e-01, time/batch = 18.8460s	
21799/33250 (epoch 32.780), train_loss = 0.92424306, grad/param norm = 1.9934e-01, time/batch = 17.1854s	
21800/33250 (epoch 32.782), train_loss = 0.80443435, grad/param norm = 1.9984e-01, time/batch = 17.1780s	
21801/33250 (epoch 32.783), train_loss = 0.67449194, grad/param norm = 1.5992e-01, time/batch = 15.3624s	
21802/33250 (epoch 32.785), train_loss = 0.71083940, grad/param norm = 1.6367e-01, time/batch = 16.7559s	
21803/33250 (epoch 32.786), train_loss = 0.91587436, grad/param norm = 1.8122e-01, time/batch = 17.1764s	
21804/33250 (epoch 32.788), train_loss = 0.90359541, grad/param norm = 1.6756e-01, time/batch = 16.8601s	
21805/33250 (epoch 32.789), train_loss = 0.91508527, grad/param norm = 1.9926e-01, time/batch = 15.9356s	
21806/33250 (epoch 32.791), train_loss = 0.94938399, grad/param norm = 2.0836e-01, time/batch = 15.8543s	
21807/33250 (epoch 32.792), train_loss = 0.97595625, grad/param norm = 1.7593e-01, time/batch = 17.5007s	
21808/33250 (epoch 32.794), train_loss = 0.80871004, grad/param norm = 1.6903e-01, time/batch = 17.3497s	
21809/33250 (epoch 32.795), train_loss = 0.80769746, grad/param norm = 1.6298e-01, time/batch = 18.6139s	
21810/33250 (epoch 32.797), train_loss = 0.89932234, grad/param norm = 1.8957e-01, time/batch = 17.5358s	
21811/33250 (epoch 32.798), train_loss = 0.82544379, grad/param norm = 2.2073e-01, time/batch = 18.2126s	
21812/33250 (epoch 32.800), train_loss = 0.85484405, grad/param norm = 1.7809e-01, time/batch = 16.3563s	
21813/33250 (epoch 32.802), train_loss = 0.80597272, grad/param norm = 1.6977e-01, time/batch = 15.7726s	
21814/33250 (epoch 32.803), train_loss = 0.85021300, grad/param norm = 1.6328e-01, time/batch = 17.8498s	
21815/33250 (epoch 32.805), train_loss = 0.85076061, grad/param norm = 1.9157e-01, time/batch = 17.8465s	
21816/33250 (epoch 32.806), train_loss = 0.82565088, grad/param norm = 1.5566e-01, time/batch = 15.5127s	
21817/33250 (epoch 32.808), train_loss = 0.73990513, grad/param norm = 1.6092e-01, time/batch = 16.2571s	
21818/33250 (epoch 32.809), train_loss = 0.73836488, grad/param norm = 1.4648e-01, time/batch = 16.0932s	
21819/33250 (epoch 32.811), train_loss = 0.72808705, grad/param norm = 1.6366e-01, time/batch = 15.5643s	
21820/33250 (epoch 32.812), train_loss = 0.85576584, grad/param norm = 1.7234e-01, time/batch = 18.5301s	
21821/33250 (epoch 32.814), train_loss = 0.81719195, grad/param norm = 2.0659e-01, time/batch = 18.6957s	
21822/33250 (epoch 32.815), train_loss = 0.87322629, grad/param norm = 1.8943e-01, time/batch = 16.8390s	
21823/33250 (epoch 32.817), train_loss = 0.80622963, grad/param norm = 1.6765e-01, time/batch = 17.5781s	
21824/33250 (epoch 32.818), train_loss = 0.75756432, grad/param norm = 1.7125e-01, time/batch = 15.5325s	
21825/33250 (epoch 32.820), train_loss = 0.84207783, grad/param norm = 2.0667e-01, time/batch = 19.4985s	
21826/33250 (epoch 32.821), train_loss = 0.79776983, grad/param norm = 1.5540e-01, time/batch = 17.0178s	
21827/33250 (epoch 32.823), train_loss = 1.12200274, grad/param norm = 2.1351e-01, time/batch = 15.7738s	
21828/33250 (epoch 32.824), train_loss = 0.76290704, grad/param norm = 1.8515e-01, time/batch = 18.7010s	
21829/33250 (epoch 32.826), train_loss = 0.85754687, grad/param norm = 1.7685e-01, time/batch = 18.2863s	
21830/33250 (epoch 32.827), train_loss = 0.72817063, grad/param norm = 1.6467e-01, time/batch = 18.1185s	
21831/33250 (epoch 32.829), train_loss = 0.86139883, grad/param norm = 1.9004e-01, time/batch = 17.1207s	
21832/33250 (epoch 32.830), train_loss = 0.91292798, grad/param norm = 2.2132e-01, time/batch = 15.8461s	
21833/33250 (epoch 32.832), train_loss = 0.82829660, grad/param norm = 1.6467e-01, time/batch = 17.1842s	
21834/33250 (epoch 32.833), train_loss = 0.80291782, grad/param norm = 1.6161e-01, time/batch = 36.6410s	
21835/33250 (epoch 32.835), train_loss = 0.75331180, grad/param norm = 1.9735e-01, time/batch = 22.3565s	
21836/33250 (epoch 32.836), train_loss = 0.80873259, grad/param norm = 1.6431e-01, time/batch = 15.7326s	
21837/33250 (epoch 32.838), train_loss = 0.85812204, grad/param norm = 1.7407e-01, time/batch = 15.5330s	
21838/33250 (epoch 32.839), train_loss = 0.77639877, grad/param norm = 1.5675e-01, time/batch = 16.5265s	
21839/33250 (epoch 32.841), train_loss = 0.76237159, grad/param norm = 1.4124e-01, time/batch = 17.4439s	
21840/33250 (epoch 32.842), train_loss = 0.96236894, grad/param norm = 1.6507e-01, time/batch = 15.4264s	
21841/33250 (epoch 32.844), train_loss = 0.89786885, grad/param norm = 1.7411e-01, time/batch = 17.2620s	
21842/33250 (epoch 32.845), train_loss = 0.98922498, grad/param norm = 1.9535e-01, time/batch = 15.7712s	
21843/33250 (epoch 32.847), train_loss = 0.96617119, grad/param norm = 1.7329e-01, time/batch = 16.2697s	
21844/33250 (epoch 32.848), train_loss = 1.02758111, grad/param norm = 2.2401e-01, time/batch = 15.5077s	
21845/33250 (epoch 32.850), train_loss = 0.91510528, grad/param norm = 1.7612e-01, time/batch = 16.2739s	
21846/33250 (epoch 32.851), train_loss = 0.72411569, grad/param norm = 1.7949e-01, time/batch = 17.8390s	
21847/33250 (epoch 32.853), train_loss = 0.86230723, grad/param norm = 2.0427e-01, time/batch = 17.1820s	
21848/33250 (epoch 32.854), train_loss = 0.79753983, grad/param norm = 1.6296e-01, time/batch = 19.4506s	
21849/33250 (epoch 32.856), train_loss = 0.77580056, grad/param norm = 1.7838e-01, time/batch = 17.2004s	
21850/33250 (epoch 32.857), train_loss = 0.71959005, grad/param norm = 1.6332e-01, time/batch = 17.3562s	
21851/33250 (epoch 32.859), train_loss = 0.76917171, grad/param norm = 1.8661e-01, time/batch = 16.4368s	
21852/33250 (epoch 32.860), train_loss = 0.85920655, grad/param norm = 1.6393e-01, time/batch = 15.4478s	
21853/33250 (epoch 32.862), train_loss = 0.74268489, grad/param norm = 1.9861e-01, time/batch = 15.7555s	
21854/33250 (epoch 32.863), train_loss = 0.75943220, grad/param norm = 1.8693e-01, time/batch = 15.6916s	
21855/33250 (epoch 32.865), train_loss = 0.85585600, grad/param norm = 1.7724e-01, time/batch = 16.6133s	
21856/33250 (epoch 32.866), train_loss = 0.72185937, grad/param norm = 2.2033e-01, time/batch = 17.1017s	
21857/33250 (epoch 32.868), train_loss = 0.81879453, grad/param norm = 1.8985e-01, time/batch = 15.2470s	
21858/33250 (epoch 32.869), train_loss = 0.85108328, grad/param norm = 1.9042e-01, time/batch = 17.6791s	
21859/33250 (epoch 32.871), train_loss = 0.64686150, grad/param norm = 1.4401e-01, time/batch = 18.1315s	
21860/33250 (epoch 32.872), train_loss = 0.88812008, grad/param norm = 1.8863e-01, time/batch = 19.4173s	
21861/33250 (epoch 32.874), train_loss = 0.75937685, grad/param norm = 1.7483e-01, time/batch = 16.1040s	
21862/33250 (epoch 32.875), train_loss = 0.73318066, grad/param norm = 2.8176e-01, time/batch = 17.8547s	
21863/33250 (epoch 32.877), train_loss = 0.93541332, grad/param norm = 1.8947e-01, time/batch = 15.5240s	
21864/33250 (epoch 32.878), train_loss = 0.84280447, grad/param norm = 1.7059e-01, time/batch = 17.6706s	
21865/33250 (epoch 32.880), train_loss = 0.83912223, grad/param norm = 1.8793e-01, time/batch = 16.4386s	
21866/33250 (epoch 32.881), train_loss = 0.94312353, grad/param norm = 2.1129e-01, time/batch = 17.5924s	
21867/33250 (epoch 32.883), train_loss = 0.85262904, grad/param norm = 1.7231e-01, time/batch = 19.1933s	
21868/33250 (epoch 32.884), train_loss = 0.91144648, grad/param norm = 2.1440e-01, time/batch = 15.8622s	
21869/33250 (epoch 32.886), train_loss = 0.75249990, grad/param norm = 1.4413e-01, time/batch = 18.4507s	
21870/33250 (epoch 32.887), train_loss = 0.77671549, grad/param norm = 1.5978e-01, time/batch = 16.4525s	
21871/33250 (epoch 32.889), train_loss = 0.79374369, grad/param norm = 1.5851e-01, time/batch = 16.4195s	
21872/33250 (epoch 32.890), train_loss = 0.63993392, grad/param norm = 1.3002e-01, time/batch = 15.8555s	
21873/33250 (epoch 32.892), train_loss = 0.86167714, grad/param norm = 1.5992e-01, time/batch = 17.7585s	
21874/33250 (epoch 32.893), train_loss = 0.89246789, grad/param norm = 1.9383e-01, time/batch = 16.4241s	
21875/33250 (epoch 32.895), train_loss = 0.77885507, grad/param norm = 1.7040e-01, time/batch = 15.6070s	
21876/33250 (epoch 32.896), train_loss = 0.90494982, grad/param norm = 1.7227e-01, time/batch = 15.2567s	
21877/33250 (epoch 32.898), train_loss = 0.83010780, grad/param norm = 1.6688e-01, time/batch = 15.6959s	
21878/33250 (epoch 32.899), train_loss = 0.76766564, grad/param norm = 1.7449e-01, time/batch = 18.9398s	
21879/33250 (epoch 32.901), train_loss = 0.71381465, grad/param norm = 1.5260e-01, time/batch = 16.0128s	
21880/33250 (epoch 32.902), train_loss = 0.79085997, grad/param norm = 1.5983e-01, time/batch = 15.8523s	
21881/33250 (epoch 32.904), train_loss = 0.73791042, grad/param norm = 1.5274e-01, time/batch = 18.2581s	
21882/33250 (epoch 32.905), train_loss = 0.80163624, grad/param norm = 1.5290e-01, time/batch = 16.2656s	
21883/33250 (epoch 32.907), train_loss = 0.72037910, grad/param norm = 1.5399e-01, time/batch = 15.9307s	
21884/33250 (epoch 32.908), train_loss = 0.81106771, grad/param norm = 1.5025e-01, time/batch = 16.1056s	
21885/33250 (epoch 32.910), train_loss = 0.88528290, grad/param norm = 1.7778e-01, time/batch = 15.7789s	
21886/33250 (epoch 32.911), train_loss = 0.72247763, grad/param norm = 1.5142e-01, time/batch = 15.4425s	
21887/33250 (epoch 32.913), train_loss = 0.77073665, grad/param norm = 1.5437e-01, time/batch = 18.5822s	
21888/33250 (epoch 32.914), train_loss = 0.68805212, grad/param norm = 1.5127e-01, time/batch = 17.8778s	
21889/33250 (epoch 32.916), train_loss = 0.72587909, grad/param norm = 1.5219e-01, time/batch = 15.0118s	
21890/33250 (epoch 32.917), train_loss = 0.80876896, grad/param norm = 1.3300e-01, time/batch = 16.0222s	
21891/33250 (epoch 32.919), train_loss = 0.74979923, grad/param norm = 1.8913e-01, time/batch = 16.1259s	
21892/33250 (epoch 32.920), train_loss = 0.81851667, grad/param norm = 1.7480e-01, time/batch = 16.2553s	
21893/33250 (epoch 32.922), train_loss = 0.85793195, grad/param norm = 1.8392e-01, time/batch = 15.7799s	
21894/33250 (epoch 32.923), train_loss = 0.77079338, grad/param norm = 1.6311e-01, time/batch = 16.5256s	
21895/33250 (epoch 32.925), train_loss = 0.77704440, grad/param norm = 1.5507e-01, time/batch = 17.8498s	
21896/33250 (epoch 32.926), train_loss = 0.76757833, grad/param norm = 1.5373e-01, time/batch = 16.8613s	
21897/33250 (epoch 32.928), train_loss = 0.77409125, grad/param norm = 1.5982e-01, time/batch = 16.6956s	
21898/33250 (epoch 32.929), train_loss = 0.68979808, grad/param norm = 1.2907e-01, time/batch = 17.4573s	
21899/33250 (epoch 32.931), train_loss = 0.91065450, grad/param norm = 1.8259e-01, time/batch = 19.2025s	
21900/33250 (epoch 32.932), train_loss = 0.76698506, grad/param norm = 1.8073e-01, time/batch = 17.1188s	
21901/33250 (epoch 32.934), train_loss = 0.74754614, grad/param norm = 1.4344e-01, time/batch = 17.6667s	
21902/33250 (epoch 32.935), train_loss = 0.76116684, grad/param norm = 1.7593e-01, time/batch = 17.6771s	
21903/33250 (epoch 32.937), train_loss = 0.75042956, grad/param norm = 1.7598e-01, time/batch = 17.1009s	
21904/33250 (epoch 32.938), train_loss = 0.80505377, grad/param norm = 1.7120e-01, time/batch = 18.9060s	
21905/33250 (epoch 32.940), train_loss = 0.78476380, grad/param norm = 1.6731e-01, time/batch = 16.0960s	
21906/33250 (epoch 32.941), train_loss = 0.84973142, grad/param norm = 1.7982e-01, time/batch = 17.5904s	
21907/33250 (epoch 32.943), train_loss = 0.95039678, grad/param norm = 1.8022e-01, time/batch = 16.5932s	
21908/33250 (epoch 32.944), train_loss = 0.78027696, grad/param norm = 1.5662e-01, time/batch = 30.0328s	
21909/33250 (epoch 32.946), train_loss = 0.92297940, grad/param norm = 1.7392e-01, time/batch = 36.2776s	
21910/33250 (epoch 32.947), train_loss = 0.74287086, grad/param norm = 1.7268e-01, time/batch = 26.5675s	
21911/33250 (epoch 32.949), train_loss = 0.88335125, grad/param norm = 1.9137e-01, time/batch = 34.6168s	
21912/33250 (epoch 32.950), train_loss = 0.88570660, grad/param norm = 1.7633e-01, time/batch = 36.7212s	
21913/33250 (epoch 32.952), train_loss = 0.80959807, grad/param norm = 1.7741e-01, time/batch = 33.8891s	
21914/33250 (epoch 32.953), train_loss = 0.85264788, grad/param norm = 1.9184e-01, time/batch = 37.6871s	
21915/33250 (epoch 32.955), train_loss = 0.89902338, grad/param norm = 1.8281e-01, time/batch = 35.0006s	
21916/33250 (epoch 32.956), train_loss = 0.82705903, grad/param norm = 1.8094e-01, time/batch = 34.6952s	
21917/33250 (epoch 32.958), train_loss = 0.76635361, grad/param norm = 1.6302e-01, time/batch = 35.2646s	
21918/33250 (epoch 32.959), train_loss = 0.76511140, grad/param norm = 1.5494e-01, time/batch = 32.2276s	
21919/33250 (epoch 32.961), train_loss = 1.02250339, grad/param norm = 1.7025e-01, time/batch = 29.8950s	
21920/33250 (epoch 32.962), train_loss = 0.79084119, grad/param norm = 1.6508e-01, time/batch = 15.2823s	
21921/33250 (epoch 32.964), train_loss = 0.93449703, grad/param norm = 1.9298e-01, time/batch = 15.5817s	
21922/33250 (epoch 32.965), train_loss = 0.88758697, grad/param norm = 1.9100e-01, time/batch = 16.9354s	
21923/33250 (epoch 32.967), train_loss = 0.83763266, grad/param norm = 1.8249e-01, time/batch = 17.8408s	
21924/33250 (epoch 32.968), train_loss = 0.94913748, grad/param norm = 1.7932e-01, time/batch = 17.3424s	
21925/33250 (epoch 32.970), train_loss = 1.06083500, grad/param norm = 2.7242e-01, time/batch = 14.7279s	
21926/33250 (epoch 32.971), train_loss = 0.98857213, grad/param norm = 1.9562e-01, time/batch = 18.6069s	
21927/33250 (epoch 32.973), train_loss = 0.81661925, grad/param norm = 1.9162e-01, time/batch = 16.3632s	
21928/33250 (epoch 32.974), train_loss = 0.90813535, grad/param norm = 1.8364e-01, time/batch = 17.6713s	
21929/33250 (epoch 32.976), train_loss = 0.80386627, grad/param norm = 1.8737e-01, time/batch = 17.6131s	
21930/33250 (epoch 32.977), train_loss = 0.81152616, grad/param norm = 1.8572e-01, time/batch = 17.0111s	
21931/33250 (epoch 32.979), train_loss = 0.87567379, grad/param norm = 2.1273e-01, time/batch = 15.5933s	
21932/33250 (epoch 32.980), train_loss = 0.88939590, grad/param norm = 1.8537e-01, time/batch = 16.1794s	
21933/33250 (epoch 32.982), train_loss = 0.77239299, grad/param norm = 1.5554e-01, time/batch = 16.2724s	
21934/33250 (epoch 32.983), train_loss = 0.86968526, grad/param norm = 2.2629e-01, time/batch = 16.2705s	
21935/33250 (epoch 32.985), train_loss = 0.79610629, grad/param norm = 1.8739e-01, time/batch = 16.9166s	
21936/33250 (epoch 32.986), train_loss = 0.88154317, grad/param norm = 1.7227e-01, time/batch = 17.5343s	
21937/33250 (epoch 32.988), train_loss = 0.92381306, grad/param norm = 1.7870e-01, time/batch = 19.0292s	
21938/33250 (epoch 32.989), train_loss = 0.91411096, grad/param norm = 1.7896e-01, time/batch = 17.1938s	
21939/33250 (epoch 32.991), train_loss = 0.85660228, grad/param norm = 1.5760e-01, time/batch = 18.0310s	
21940/33250 (epoch 32.992), train_loss = 0.82005751, grad/param norm = 1.8181e-01, time/batch = 15.3687s	
21941/33250 (epoch 32.994), train_loss = 0.78352241, grad/param norm = 1.5415e-01, time/batch = 16.4207s	
21942/33250 (epoch 32.995), train_loss = 0.80534638, grad/param norm = 2.3253e-01, time/batch = 16.2785s	
21943/33250 (epoch 32.997), train_loss = 0.59950530, grad/param norm = 1.4071e-01, time/batch = 15.4430s	
21944/33250 (epoch 32.998), train_loss = 0.86179702, grad/param norm = 1.5662e-01, time/batch = 17.3483s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
21945/33250 (epoch 33.000), train_loss = 0.84529562, grad/param norm = 1.5608e-01, time/batch = 15.1103s	
21946/33250 (epoch 33.002), train_loss = 1.03423241, grad/param norm = 1.8732e-01, time/batch = 17.7716s	
21947/33250 (epoch 33.003), train_loss = 0.89999532, grad/param norm = 1.8767e-01, time/batch = 18.3880s	
21948/33250 (epoch 33.005), train_loss = 0.68100067, grad/param norm = 1.4839e-01, time/batch = 16.1064s	
21949/33250 (epoch 33.006), train_loss = 0.69558844, grad/param norm = 1.4467e-01, time/batch = 17.1224s	
21950/33250 (epoch 33.008), train_loss = 0.92416663, grad/param norm = 1.8100e-01, time/batch = 18.0868s	
21951/33250 (epoch 33.009), train_loss = 0.98813099, grad/param norm = 1.7433e-01, time/batch = 17.3468s	
21952/33250 (epoch 33.011), train_loss = 0.78354400, grad/param norm = 1.6222e-01, time/batch = 15.8533s	
21953/33250 (epoch 33.012), train_loss = 0.81135592, grad/param norm = 1.9305e-01, time/batch = 16.9128s	
21954/33250 (epoch 33.014), train_loss = 0.90378388, grad/param norm = 1.7980e-01, time/batch = 15.5236s	
21955/33250 (epoch 33.015), train_loss = 0.82840462, grad/param norm = 1.6506e-01, time/batch = 16.0996s	
21956/33250 (epoch 33.017), train_loss = 0.86509567, grad/param norm = 2.1303e-01, time/batch = 17.8482s	
21957/33250 (epoch 33.018), train_loss = 0.66994158, grad/param norm = 1.4787e-01, time/batch = 17.2006s	
21958/33250 (epoch 33.020), train_loss = 0.82791251, grad/param norm = 1.4827e-01, time/batch = 17.5473s	
21959/33250 (epoch 33.021), train_loss = 0.86621620, grad/param norm = 1.6771e-01, time/batch = 17.8684s	
21960/33250 (epoch 33.023), train_loss = 0.68238177, grad/param norm = 1.8112e-01, time/batch = 17.9492s	
21961/33250 (epoch 33.024), train_loss = 0.90932476, grad/param norm = 1.8650e-01, time/batch = 18.0977s	
21962/33250 (epoch 33.026), train_loss = 0.84787756, grad/param norm = 1.8931e-01, time/batch = 16.1052s	
21963/33250 (epoch 33.027), train_loss = 0.86357716, grad/param norm = 1.5700e-01, time/batch = 3.3134s	
21964/33250 (epoch 33.029), train_loss = 0.82147785, grad/param norm = 1.7826e-01, time/batch = 0.6688s	
21965/33250 (epoch 33.030), train_loss = 0.80703907, grad/param norm = 1.6856e-01, time/batch = 0.6953s	
21966/33250 (epoch 33.032), train_loss = 1.00270094, grad/param norm = 1.8552e-01, time/batch = 0.6905s	
21967/33250 (epoch 33.033), train_loss = 0.79452026, grad/param norm = 1.7925e-01, time/batch = 0.6870s	
21968/33250 (epoch 33.035), train_loss = 0.83536807, grad/param norm = 1.6837e-01, time/batch = 0.6818s	
21969/33250 (epoch 33.036), train_loss = 0.87446531, grad/param norm = 1.7823e-01, time/batch = 0.6795s	
21970/33250 (epoch 33.038), train_loss = 0.82946480, grad/param norm = 1.4405e-01, time/batch = 0.8258s	
21971/33250 (epoch 33.039), train_loss = 0.77255061, grad/param norm = 1.6032e-01, time/batch = 0.9909s	
21972/33250 (epoch 33.041), train_loss = 0.84460740, grad/param norm = 2.1102e-01, time/batch = 0.9738s	
21973/33250 (epoch 33.042), train_loss = 0.71650765, grad/param norm = 1.6656e-01, time/batch = 0.9612s	
21974/33250 (epoch 33.044), train_loss = 0.94939339, grad/param norm = 1.8714e-01, time/batch = 0.9704s	
21975/33250 (epoch 33.045), train_loss = 0.92232756, grad/param norm = 1.8271e-01, time/batch = 1.2832s	
21976/33250 (epoch 33.047), train_loss = 0.83123274, grad/param norm = 1.6799e-01, time/batch = 1.8060s	
21977/33250 (epoch 33.048), train_loss = 0.92268001, grad/param norm = 2.1387e-01, time/batch = 1.8147s	
21978/33250 (epoch 33.050), train_loss = 0.85554468, grad/param norm = 1.6550e-01, time/batch = 12.1813s	
21979/33250 (epoch 33.051), train_loss = 0.81597467, grad/param norm = 1.4658e-01, time/batch = 15.2718s	
21980/33250 (epoch 33.053), train_loss = 0.89388630, grad/param norm = 2.0788e-01, time/batch = 17.3322s	
21981/33250 (epoch 33.054), train_loss = 0.70794964, grad/param norm = 1.7181e-01, time/batch = 16.9456s	
21982/33250 (epoch 33.056), train_loss = 0.74001055, grad/param norm = 1.5565e-01, time/batch = 17.7891s	
21983/33250 (epoch 33.057), train_loss = 0.92983902, grad/param norm = 1.7006e-01, time/batch = 17.2861s	
21984/33250 (epoch 33.059), train_loss = 0.78830032, grad/param norm = 1.6517e-01, time/batch = 18.8559s	
21985/33250 (epoch 33.060), train_loss = 0.83785022, grad/param norm = 1.7675e-01, time/batch = 17.5886s	
21986/33250 (epoch 33.062), train_loss = 0.92673147, grad/param norm = 1.8681e-01, time/batch = 18.9161s	
21987/33250 (epoch 33.063), train_loss = 0.96685663, grad/param norm = 1.7360e-01, time/batch = 15.9328s	
21988/33250 (epoch 33.065), train_loss = 0.83301911, grad/param norm = 1.7523e-01, time/batch = 15.4360s	
21989/33250 (epoch 33.066), train_loss = 0.87582603, grad/param norm = 1.8824e-01, time/batch = 17.2270s	
21990/33250 (epoch 33.068), train_loss = 0.80020372, grad/param norm = 1.7413e-01, time/batch = 16.5161s	
21991/33250 (epoch 33.069), train_loss = 0.84903683, grad/param norm = 1.7874e-01, time/batch = 18.1955s	
21992/33250 (epoch 33.071), train_loss = 0.78521846, grad/param norm = 1.3916e-01, time/batch = 17.8714s	
21993/33250 (epoch 33.072), train_loss = 0.76936803, grad/param norm = 1.5316e-01, time/batch = 19.2773s	
21994/33250 (epoch 33.074), train_loss = 0.84638067, grad/param norm = 1.6084e-01, time/batch = 11.3898s	
21995/33250 (epoch 33.075), train_loss = 0.78291742, grad/param norm = 1.6915e-01, time/batch = 0.6920s	
21996/33250 (epoch 33.077), train_loss = 0.82448515, grad/param norm = 2.1032e-01, time/batch = 0.6882s	
21997/33250 (epoch 33.078), train_loss = 0.84794989, grad/param norm = 1.7112e-01, time/batch = 0.6751s	
21998/33250 (epoch 33.080), train_loss = 0.84715771, grad/param norm = 2.5244e-01, time/batch = 0.6696s	
21999/33250 (epoch 33.081), train_loss = 0.85130849, grad/param norm = 1.5635e-01, time/batch = 0.6684s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch33.08_1.6112.t7	
22000/33250 (epoch 33.083), train_loss = 0.94924254, grad/param norm = 1.6599e-01, time/batch = 0.6880s	
22001/33250 (epoch 33.084), train_loss = 1.28015138, grad/param norm = 2.1209e-01, time/batch = 16.0244s	
22002/33250 (epoch 33.086), train_loss = 0.83760975, grad/param norm = 1.6273e-01, time/batch = 15.3622s	
22003/33250 (epoch 33.087), train_loss = 0.71084212, grad/param norm = 1.3714e-01, time/batch = 15.5183s	
22004/33250 (epoch 33.089), train_loss = 0.83093210, grad/param norm = 1.6269e-01, time/batch = 15.5893s	
22005/33250 (epoch 33.090), train_loss = 0.87086975, grad/param norm = 1.9627e-01, time/batch = 17.1766s	
22006/33250 (epoch 33.092), train_loss = 0.76802156, grad/param norm = 1.5301e-01, time/batch = 17.0327s	
22007/33250 (epoch 33.093), train_loss = 0.81521165, grad/param norm = 1.5524e-01, time/batch = 18.0425s	
22008/33250 (epoch 33.095), train_loss = 0.82406780, grad/param norm = 1.6996e-01, time/batch = 16.4526s	
22009/33250 (epoch 33.096), train_loss = 0.70207877, grad/param norm = 1.6416e-01, time/batch = 15.6986s	
22010/33250 (epoch 33.098), train_loss = 0.70670230, grad/param norm = 2.0087e-01, time/batch = 15.9524s	
22011/33250 (epoch 33.099), train_loss = 0.65446129, grad/param norm = 1.5403e-01, time/batch = 15.9459s	
22012/33250 (epoch 33.101), train_loss = 0.81971553, grad/param norm = 1.6550e-01, time/batch = 16.8547s	
22013/33250 (epoch 33.102), train_loss = 0.75534072, grad/param norm = 1.5567e-01, time/batch = 15.5099s	
22014/33250 (epoch 33.104), train_loss = 0.60582090, grad/param norm = 1.2990e-01, time/batch = 16.6959s	
22015/33250 (epoch 33.105), train_loss = 0.76940125, grad/param norm = 1.6551e-01, time/batch = 15.4570s	
22016/33250 (epoch 33.107), train_loss = 0.69571034, grad/param norm = 1.3166e-01, time/batch = 18.4351s	
22017/33250 (epoch 33.108), train_loss = 0.83259970, grad/param norm = 1.7757e-01, time/batch = 17.2672s	
22018/33250 (epoch 33.110), train_loss = 0.69816048, grad/param norm = 1.4709e-01, time/batch = 15.8995s	
22019/33250 (epoch 33.111), train_loss = 0.80901941, grad/param norm = 1.5658e-01, time/batch = 15.6287s	
22020/33250 (epoch 33.113), train_loss = 0.75750849, grad/param norm = 1.8351e-01, time/batch = 16.3607s	
22021/33250 (epoch 33.114), train_loss = 0.70884622, grad/param norm = 1.7675e-01, time/batch = 15.2004s	
22022/33250 (epoch 33.116), train_loss = 0.76811480, grad/param norm = 1.9029e-01, time/batch = 17.8493s	
22023/33250 (epoch 33.117), train_loss = 0.77537549, grad/param norm = 1.9115e-01, time/batch = 15.7697s	
22024/33250 (epoch 33.119), train_loss = 0.77389567, grad/param norm = 1.6727e-01, time/batch = 15.4716s	
22025/33250 (epoch 33.120), train_loss = 0.64255576, grad/param norm = 1.4853e-01, time/batch = 15.6006s	
22026/33250 (epoch 33.122), train_loss = 0.88580846, grad/param norm = 1.7619e-01, time/batch = 15.4174s	
22027/33250 (epoch 33.123), train_loss = 0.80054394, grad/param norm = 1.8555e-01, time/batch = 15.5518s	
22028/33250 (epoch 33.125), train_loss = 0.67117015, grad/param norm = 1.9057e-01, time/batch = 15.7767s	
22029/33250 (epoch 33.126), train_loss = 0.79565561, grad/param norm = 1.7065e-01, time/batch = 16.5266s	
22030/33250 (epoch 33.128), train_loss = 0.75597991, grad/param norm = 1.4493e-01, time/batch = 16.8625s	
22031/33250 (epoch 33.129), train_loss = 0.78022123, grad/param norm = 1.4172e-01, time/batch = 16.6818s	
22032/33250 (epoch 33.131), train_loss = 0.80142641, grad/param norm = 1.6929e-01, time/batch = 16.3389s	
22033/33250 (epoch 33.132), train_loss = 0.77276170, grad/param norm = 1.7651e-01, time/batch = 15.6970s	
22034/33250 (epoch 33.134), train_loss = 0.76238526, grad/param norm = 1.7982e-01, time/batch = 16.8651s	
22035/33250 (epoch 33.135), train_loss = 0.80199106, grad/param norm = 1.4258e-01, time/batch = 15.3595s	
22036/33250 (epoch 33.137), train_loss = 0.72946143, grad/param norm = 1.8417e-01, time/batch = 15.0366s	
22037/33250 (epoch 33.138), train_loss = 0.72719647, grad/param norm = 1.4209e-01, time/batch = 15.2255s	
22038/33250 (epoch 33.140), train_loss = 0.63118179, grad/param norm = 1.4087e-01, time/batch = 15.5495s	
22039/33250 (epoch 33.141), train_loss = 0.91039315, grad/param norm = 2.5539e-01, time/batch = 17.0359s	
22040/33250 (epoch 33.143), train_loss = 0.66164279, grad/param norm = 1.5329e-01, time/batch = 17.1266s	
22041/33250 (epoch 33.144), train_loss = 0.76259000, grad/param norm = 1.5622e-01, time/batch = 16.8489s	
22042/33250 (epoch 33.146), train_loss = 0.77043060, grad/param norm = 1.5917e-01, time/batch = 15.4197s	
22043/33250 (epoch 33.147), train_loss = 0.79033594, grad/param norm = 1.8364e-01, time/batch = 15.8397s	
22044/33250 (epoch 33.149), train_loss = 0.74313509, grad/param norm = 1.6125e-01, time/batch = 17.9863s	
22045/33250 (epoch 33.150), train_loss = 0.70292849, grad/param norm = 1.5382e-01, time/batch = 17.4317s	
22046/33250 (epoch 33.152), train_loss = 0.68579968, grad/param norm = 1.7302e-01, time/batch = 15.3318s	
22047/33250 (epoch 33.153), train_loss = 0.95024461, grad/param norm = 2.0466e-01, time/batch = 18.1150s	
22048/33250 (epoch 33.155), train_loss = 0.76587873, grad/param norm = 1.8075e-01, time/batch = 16.9732s	
22049/33250 (epoch 33.156), train_loss = 0.99295940, grad/param norm = 1.7365e-01, time/batch = 17.8802s	
22050/33250 (epoch 33.158), train_loss = 0.93552937, grad/param norm = 1.9912e-01, time/batch = 17.2745s	
22051/33250 (epoch 33.159), train_loss = 0.75215192, grad/param norm = 1.7361e-01, time/batch = 16.3454s	
22052/33250 (epoch 33.161), train_loss = 0.82821785, grad/param norm = 1.7581e-01, time/batch = 16.0234s	
22053/33250 (epoch 33.162), train_loss = 0.73368098, grad/param norm = 1.4161e-01, time/batch = 18.6238s	
22054/33250 (epoch 33.164), train_loss = 0.79432345, grad/param norm = 1.8039e-01, time/batch = 26.4252s	
22055/33250 (epoch 33.165), train_loss = 0.86634244, grad/param norm = 1.7263e-01, time/batch = 18.1200s	
22056/33250 (epoch 33.167), train_loss = 0.95528149, grad/param norm = 2.0094e-01, time/batch = 15.7569s	
22057/33250 (epoch 33.168), train_loss = 0.69111267, grad/param norm = 1.4249e-01, time/batch = 15.7537s	
22058/33250 (epoch 33.170), train_loss = 0.75814594, grad/param norm = 1.6442e-01, time/batch = 15.5560s	
22059/33250 (epoch 33.171), train_loss = 0.81238296, grad/param norm = 1.6080e-01, time/batch = 14.1378s	
22060/33250 (epoch 33.173), train_loss = 0.78484380, grad/param norm = 1.5684e-01, time/batch = 15.0281s	
22061/33250 (epoch 33.174), train_loss = 0.80743246, grad/param norm = 1.6315e-01, time/batch = 14.5490s	
22062/33250 (epoch 33.176), train_loss = 0.76448687, grad/param norm = 1.9707e-01, time/batch = 14.3716s	
22063/33250 (epoch 33.177), train_loss = 0.76782327, grad/param norm = 1.7029e-01, time/batch = 14.3033s	
22064/33250 (epoch 33.179), train_loss = 0.72930476, grad/param norm = 1.6506e-01, time/batch = 15.0913s	
22065/33250 (epoch 33.180), train_loss = 0.64449229, grad/param norm = 1.5767e-01, time/batch = 14.3089s	
22066/33250 (epoch 33.182), train_loss = 0.74713316, grad/param norm = 1.8518e-01, time/batch = 14.1641s	
22067/33250 (epoch 33.183), train_loss = 0.90774454, grad/param norm = 2.0310e-01, time/batch = 14.4084s	
22068/33250 (epoch 33.185), train_loss = 0.83430094, grad/param norm = 2.1385e-01, time/batch = 14.5661s	
22069/33250 (epoch 33.186), train_loss = 0.84244196, grad/param norm = 1.7991e-01, time/batch = 14.6350s	
22070/33250 (epoch 33.188), train_loss = 0.92093002, grad/param norm = 2.2189e-01, time/batch = 14.3176s	
22071/33250 (epoch 33.189), train_loss = 0.65627622, grad/param norm = 1.7491e-01, time/batch = 14.3034s	
22072/33250 (epoch 33.191), train_loss = 0.74140467, grad/param norm = 1.7012e-01, time/batch = 14.9392s	
22073/33250 (epoch 33.192), train_loss = 0.78320396, grad/param norm = 1.7037e-01, time/batch = 14.7710s	
22074/33250 (epoch 33.194), train_loss = 0.79100287, grad/param norm = 1.6920e-01, time/batch = 14.7800s	
22075/33250 (epoch 33.195), train_loss = 0.98490177, grad/param norm = 1.7487e-01, time/batch = 14.3957s	
22076/33250 (epoch 33.197), train_loss = 0.76153765, grad/param norm = 1.7165e-01, time/batch = 14.4640s	
22077/33250 (epoch 33.198), train_loss = 0.94742836, grad/param norm = 1.7785e-01, time/batch = 14.6981s	
22078/33250 (epoch 33.200), train_loss = 0.80249510, grad/param norm = 1.5986e-01, time/batch = 14.2495s	
22079/33250 (epoch 33.202), train_loss = 0.76195552, grad/param norm = 1.5096e-01, time/batch = 14.7197s	
22080/33250 (epoch 33.203), train_loss = 0.73845388, grad/param norm = 1.9447e-01, time/batch = 14.3261s	
22081/33250 (epoch 33.205), train_loss = 0.83509342, grad/param norm = 1.5511e-01, time/batch = 14.4124s	
22082/33250 (epoch 33.206), train_loss = 0.88547221, grad/param norm = 1.7152e-01, time/batch = 14.7020s	
22083/33250 (epoch 33.208), train_loss = 0.91632617, grad/param norm = 1.9964e-01, time/batch = 14.2980s	
22084/33250 (epoch 33.209), train_loss = 0.75839153, grad/param norm = 1.4909e-01, time/batch = 14.6795s	
22085/33250 (epoch 33.211), train_loss = 0.87884691, grad/param norm = 2.4805e-01, time/batch = 14.1487s	
22086/33250 (epoch 33.212), train_loss = 0.96056500, grad/param norm = 1.8167e-01, time/batch = 13.9716s	
22087/33250 (epoch 33.214), train_loss = 0.83381140, grad/param norm = 1.5821e-01, time/batch = 14.3713s	
22088/33250 (epoch 33.215), train_loss = 0.90861874, grad/param norm = 2.4921e-01, time/batch = 13.9853s	
22089/33250 (epoch 33.217), train_loss = 0.91131896, grad/param norm = 2.1536e-01, time/batch = 14.3823s	
22090/33250 (epoch 33.218), train_loss = 0.88830633, grad/param norm = 1.6325e-01, time/batch = 13.9200s	
22091/33250 (epoch 33.220), train_loss = 0.83247749, grad/param norm = 2.0095e-01, time/batch = 14.0878s	
22092/33250 (epoch 33.221), train_loss = 0.96948032, grad/param norm = 1.9663e-01, time/batch = 14.1641s	
22093/33250 (epoch 33.223), train_loss = 0.82135845, grad/param norm = 1.7844e-01, time/batch = 15.0283s	
22094/33250 (epoch 33.224), train_loss = 0.87152732, grad/param norm = 1.7467e-01, time/batch = 14.4586s	
22095/33250 (epoch 33.226), train_loss = 0.97028730, grad/param norm = 2.0704e-01, time/batch = 14.5437s	
22096/33250 (epoch 33.227), train_loss = 0.86880348, grad/param norm = 2.9459e-01, time/batch = 14.6239s	
22097/33250 (epoch 33.229), train_loss = 0.81247051, grad/param norm = 1.7874e-01, time/batch = 14.9265s	
22098/33250 (epoch 33.230), train_loss = 0.84063522, grad/param norm = 2.0051e-01, time/batch = 14.7861s	
22099/33250 (epoch 33.232), train_loss = 0.77237533, grad/param norm = 1.7610e-01, time/batch = 14.5418s	
22100/33250 (epoch 33.233), train_loss = 0.74436111, grad/param norm = 1.6402e-01, time/batch = 14.5462s	
22101/33250 (epoch 33.235), train_loss = 0.95282338, grad/param norm = 1.7371e-01, time/batch = 14.4085s	
22102/33250 (epoch 33.236), train_loss = 0.77255466, grad/param norm = 1.7524e-01, time/batch = 14.2444s	
22103/33250 (epoch 33.238), train_loss = 0.92851775, grad/param norm = 1.8663e-01, time/batch = 14.2483s	
22104/33250 (epoch 33.239), train_loss = 0.91279225, grad/param norm = 2.1572e-01, time/batch = 14.5506s	
22105/33250 (epoch 33.241), train_loss = 0.93250692, grad/param norm = 1.9455e-01, time/batch = 14.3097s	
22106/33250 (epoch 33.242), train_loss = 0.94787905, grad/param norm = 1.9225e-01, time/batch = 14.4562s	
22107/33250 (epoch 33.244), train_loss = 0.88118083, grad/param norm = 2.2759e-01, time/batch = 14.0660s	
22108/33250 (epoch 33.245), train_loss = 0.85211202, grad/param norm = 1.9003e-01, time/batch = 14.2269s	
22109/33250 (epoch 33.247), train_loss = 0.82096020, grad/param norm = 1.5039e-01, time/batch = 14.5438s	
22110/33250 (epoch 33.248), train_loss = 1.00123308, grad/param norm = 2.3873e-01, time/batch = 14.5461s	
22111/33250 (epoch 33.250), train_loss = 0.93549837, grad/param norm = 1.6484e-01, time/batch = 14.5648s	
22112/33250 (epoch 33.251), train_loss = 0.79607991, grad/param norm = 1.4724e-01, time/batch = 14.7765s	
22113/33250 (epoch 33.253), train_loss = 0.78711577, grad/param norm = 1.5051e-01, time/batch = 14.7203s	
22114/33250 (epoch 33.254), train_loss = 0.77115436, grad/param norm = 1.7236e-01, time/batch = 14.5691s	
22115/33250 (epoch 33.256), train_loss = 0.81785488, grad/param norm = 1.5820e-01, time/batch = 14.4023s	
22116/33250 (epoch 33.257), train_loss = 0.98098703, grad/param norm = 1.8093e-01, time/batch = 14.0778s	
22117/33250 (epoch 33.259), train_loss = 0.88764985, grad/param norm = 1.8006e-01, time/batch = 14.3013s	
22118/33250 (epoch 33.260), train_loss = 0.70460797, grad/param norm = 1.6736e-01, time/batch = 14.6302s	
22119/33250 (epoch 33.262), train_loss = 0.84035504, grad/param norm = 1.6739e-01, time/batch = 14.6249s	
22120/33250 (epoch 33.263), train_loss = 0.71997428, grad/param norm = 1.7845e-01, time/batch = 15.0149s	
22121/33250 (epoch 33.265), train_loss = 0.86200993, grad/param norm = 1.7374e-01, time/batch = 14.5494s	
22122/33250 (epoch 33.266), train_loss = 0.79768472, grad/param norm = 1.7495e-01, time/batch = 14.4637s	
22123/33250 (epoch 33.268), train_loss = 0.73245186, grad/param norm = 1.6034e-01, time/batch = 14.1414s	
22124/33250 (epoch 33.269), train_loss = 0.67958788, grad/param norm = 1.4992e-01, time/batch = 14.5219s	
22125/33250 (epoch 33.271), train_loss = 0.83379095, grad/param norm = 1.7477e-01, time/batch = 14.2267s	
22126/33250 (epoch 33.272), train_loss = 0.74735844, grad/param norm = 1.3774e-01, time/batch = 14.3903s	
22127/33250 (epoch 33.274), train_loss = 0.62404307, grad/param norm = 1.4961e-01, time/batch = 14.1512s	
22128/33250 (epoch 33.275), train_loss = 0.77786809, grad/param norm = 1.4388e-01, time/batch = 14.0768s	
22129/33250 (epoch 33.277), train_loss = 0.63591805, grad/param norm = 1.5873e-01, time/batch = 13.9735s	
22130/33250 (epoch 33.278), train_loss = 0.76712721, grad/param norm = 1.6992e-01, time/batch = 14.5366s	
22131/33250 (epoch 33.280), train_loss = 0.72045892, grad/param norm = 1.5125e-01, time/batch = 14.5574s	
22132/33250 (epoch 33.281), train_loss = 0.83389851, grad/param norm = 1.8558e-01, time/batch = 14.3044s	
22133/33250 (epoch 33.283), train_loss = 0.87358264, grad/param norm = 2.4442e-01, time/batch = 14.2270s	
22134/33250 (epoch 33.284), train_loss = 0.73714124, grad/param norm = 2.5099e-01, time/batch = 14.9450s	
22135/33250 (epoch 33.286), train_loss = 0.86316942, grad/param norm = 1.7604e-01, time/batch = 14.6925s	
22136/33250 (epoch 33.287), train_loss = 0.67395356, grad/param norm = 1.4138e-01, time/batch = 14.4903s	
22137/33250 (epoch 33.289), train_loss = 0.65475188, grad/param norm = 1.6216e-01, time/batch = 14.2555s	
22138/33250 (epoch 33.290), train_loss = 0.81659715, grad/param norm = 1.5433e-01, time/batch = 14.4923s	
22139/33250 (epoch 33.292), train_loss = 0.88145642, grad/param norm = 2.1184e-01, time/batch = 14.5710s	
22140/33250 (epoch 33.293), train_loss = 0.91906005, grad/param norm = 1.7832e-01, time/batch = 14.4694s	
22141/33250 (epoch 33.295), train_loss = 0.90733289, grad/param norm = 1.7333e-01, time/batch = 14.9509s	
22142/33250 (epoch 33.296), train_loss = 0.81069747, grad/param norm = 1.7041e-01, time/batch = 15.0967s	
22143/33250 (epoch 33.298), train_loss = 0.66983518, grad/param norm = 1.6187e-01, time/batch = 17.0298s	
22144/33250 (epoch 33.299), train_loss = 0.65365127, grad/param norm = 1.5758e-01, time/batch = 17.9348s	
22145/33250 (epoch 33.301), train_loss = 0.90551385, grad/param norm = 1.7878e-01, time/batch = 15.9454s	
22146/33250 (epoch 33.302), train_loss = 0.85879992, grad/param norm = 1.7958e-01, time/batch = 16.8541s	
22147/33250 (epoch 33.304), train_loss = 0.75714905, grad/param norm = 1.6602e-01, time/batch = 18.1345s	
22148/33250 (epoch 33.305), train_loss = 0.74266748, grad/param norm = 1.4483e-01, time/batch = 14.8576s	
22149/33250 (epoch 33.307), train_loss = 0.85387889, grad/param norm = 1.8940e-01, time/batch = 17.5323s	
22150/33250 (epoch 33.308), train_loss = 0.92621757, grad/param norm = 2.5936e-01, time/batch = 16.7056s	
22151/33250 (epoch 33.310), train_loss = 0.78349952, grad/param norm = 1.8524e-01, time/batch = 17.0904s	
22152/33250 (epoch 33.311), train_loss = 0.95576489, grad/param norm = 2.1896e-01, time/batch = 16.6909s	
22153/33250 (epoch 33.313), train_loss = 0.68878091, grad/param norm = 1.9966e-01, time/batch = 15.0145s	
22154/33250 (epoch 33.314), train_loss = 0.84715295, grad/param norm = 1.5269e-01, time/batch = 17.0227s	
22155/33250 (epoch 33.316), train_loss = 0.98158577, grad/param norm = 1.9870e-01, time/batch = 15.8553s	
22156/33250 (epoch 33.317), train_loss = 0.72601050, grad/param norm = 1.5109e-01, time/batch = 17.5335s	
22157/33250 (epoch 33.319), train_loss = 0.89297736, grad/param norm = 2.3313e-01, time/batch = 16.5324s	
22158/33250 (epoch 33.320), train_loss = 0.91488138, grad/param norm = 2.3046e-01, time/batch = 18.3821s	
22159/33250 (epoch 33.322), train_loss = 0.96253979, grad/param norm = 2.0028e-01, time/batch = 15.6258s	
22160/33250 (epoch 33.323), train_loss = 0.98244606, grad/param norm = 2.2323e-01, time/batch = 16.6863s	
22161/33250 (epoch 33.325), train_loss = 0.79124171, grad/param norm = 1.7954e-01, time/batch = 15.9529s	
22162/33250 (epoch 33.326), train_loss = 1.01299131, grad/param norm = 2.0584e-01, time/batch = 18.9250s	
22163/33250 (epoch 33.328), train_loss = 0.80746425, grad/param norm = 1.8400e-01, time/batch = 15.0154s	
22164/33250 (epoch 33.329), train_loss = 0.82557949, grad/param norm = 1.9435e-01, time/batch = 15.5820s	
22165/33250 (epoch 33.331), train_loss = 0.82328398, grad/param norm = 1.8922e-01, time/batch = 16.8583s	
22166/33250 (epoch 33.332), train_loss = 0.81692671, grad/param norm = 1.8334e-01, time/batch = 16.8500s	
22167/33250 (epoch 33.334), train_loss = 0.97439958, grad/param norm = 1.7917e-01, time/batch = 17.5339s	
22168/33250 (epoch 33.335), train_loss = 0.62226467, grad/param norm = 1.4756e-01, time/batch = 17.1413s	
22169/33250 (epoch 33.337), train_loss = 0.88492274, grad/param norm = 1.6854e-01, time/batch = 18.9603s	
22170/33250 (epoch 33.338), train_loss = 0.94472461, grad/param norm = 1.8243e-01, time/batch = 15.3625s	
22171/33250 (epoch 33.340), train_loss = 0.79265035, grad/param norm = 1.6039e-01, time/batch = 16.2336s	
22172/33250 (epoch 33.341), train_loss = 0.75985252, grad/param norm = 1.7962e-01, time/batch = 15.4363s	
22173/33250 (epoch 33.343), train_loss = 0.80219264, grad/param norm = 2.0679e-01, time/batch = 15.1844s	
22174/33250 (epoch 33.344), train_loss = 0.81162041, grad/param norm = 1.5845e-01, time/batch = 15.1823s	
22175/33250 (epoch 33.346), train_loss = 0.71288830, grad/param norm = 1.6060e-01, time/batch = 15.4253s	
22176/33250 (epoch 33.347), train_loss = 0.99350047, grad/param norm = 1.8720e-01, time/batch = 15.4953s	
22177/33250 (epoch 33.349), train_loss = 0.77588307, grad/param norm = 1.7201e-01, time/batch = 15.4262s	
22178/33250 (epoch 33.350), train_loss = 0.81113686, grad/param norm = 1.7116e-01, time/batch = 15.1900s	
22179/33250 (epoch 33.352), train_loss = 0.74567446, grad/param norm = 1.7352e-01, time/batch = 15.3488s	
22180/33250 (epoch 33.353), train_loss = 0.78925700, grad/param norm = 1.8303e-01, time/batch = 14.5524s	
22181/33250 (epoch 33.355), train_loss = 0.79620189, grad/param norm = 1.8023e-01, time/batch = 14.7012s	
22182/33250 (epoch 33.356), train_loss = 0.73100701, grad/param norm = 1.8060e-01, time/batch = 14.6070s	
22183/33250 (epoch 33.358), train_loss = 0.78634351, grad/param norm = 1.5176e-01, time/batch = 14.8629s	
22184/33250 (epoch 33.359), train_loss = 0.78648789, grad/param norm = 1.6999e-01, time/batch = 14.3693s	
22185/33250 (epoch 33.361), train_loss = 0.92558699, grad/param norm = 2.0659e-01, time/batch = 14.5319s	
22186/33250 (epoch 33.362), train_loss = 0.86007693, grad/param norm = 1.6237e-01, time/batch = 14.6996s	
22187/33250 (epoch 33.364), train_loss = 0.87078238, grad/param norm = 1.7948e-01, time/batch = 15.0983s	
22188/33250 (epoch 33.365), train_loss = 0.81885208, grad/param norm = 1.5842e-01, time/batch = 14.8635s	
22189/33250 (epoch 33.367), train_loss = 0.83260827, grad/param norm = 1.5212e-01, time/batch = 14.7097s	
22190/33250 (epoch 33.368), train_loss = 0.82106455, grad/param norm = 1.9520e-01, time/batch = 14.3961s	
22191/33250 (epoch 33.370), train_loss = 0.72804556, grad/param norm = 1.4683e-01, time/batch = 15.2599s	
22192/33250 (epoch 33.371), train_loss = 0.92954521, grad/param norm = 1.8942e-01, time/batch = 14.9599s	
22193/33250 (epoch 33.373), train_loss = 0.79028614, grad/param norm = 1.5129e-01, time/batch = 14.8675s	
22194/33250 (epoch 33.374), train_loss = 0.84343372, grad/param norm = 2.8454e-01, time/batch = 14.7925s	
22195/33250 (epoch 33.376), train_loss = 0.80367790, grad/param norm = 1.5676e-01, time/batch = 14.9418s	
22196/33250 (epoch 33.377), train_loss = 0.72596575, grad/param norm = 1.8452e-01, time/batch = 14.6143s	
22197/33250 (epoch 33.379), train_loss = 0.81587789, grad/param norm = 1.8052e-01, time/batch = 15.0824s	
22198/33250 (epoch 33.380), train_loss = 0.81074112, grad/param norm = 1.9731e-01, time/batch = 14.8637s	
22199/33250 (epoch 33.382), train_loss = 0.85063268, grad/param norm = 2.0248e-01, time/batch = 15.1114s	
22200/33250 (epoch 33.383), train_loss = 0.73697165, grad/param norm = 1.7299e-01, time/batch = 14.7126s	
22201/33250 (epoch 33.385), train_loss = 0.70097404, grad/param norm = 1.7152e-01, time/batch = 14.9667s	
22202/33250 (epoch 33.386), train_loss = 0.71503171, grad/param norm = 1.8404e-01, time/batch = 15.1156s	
22203/33250 (epoch 33.388), train_loss = 0.73329760, grad/param norm = 1.5313e-01, time/batch = 14.9571s	
22204/33250 (epoch 33.389), train_loss = 0.78520423, grad/param norm = 1.9048e-01, time/batch = 14.4634s	
22205/33250 (epoch 33.391), train_loss = 0.87156832, grad/param norm = 1.8697e-01, time/batch = 14.9103s	
22206/33250 (epoch 33.392), train_loss = 0.91708543, grad/param norm = 1.8639e-01, time/batch = 14.9939s	
22207/33250 (epoch 33.394), train_loss = 0.90834601, grad/param norm = 2.0386e-01, time/batch = 14.9516s	
22208/33250 (epoch 33.395), train_loss = 0.90379433, grad/param norm = 1.6850e-01, time/batch = 14.9233s	
22209/33250 (epoch 33.397), train_loss = 0.92699193, grad/param norm = 1.8018e-01, time/batch = 15.0168s	
22210/33250 (epoch 33.398), train_loss = 0.74604617, grad/param norm = 1.6686e-01, time/batch = 14.7058s	
22211/33250 (epoch 33.400), train_loss = 0.71571879, grad/param norm = 1.3959e-01, time/batch = 15.4178s	
22212/33250 (epoch 33.402), train_loss = 0.70404587, grad/param norm = 1.9474e-01, time/batch = 14.7361s	
22213/33250 (epoch 33.403), train_loss = 0.78956419, grad/param norm = 1.8907e-01, time/batch = 14.8206s	
22214/33250 (epoch 33.405), train_loss = 0.74388150, grad/param norm = 1.3756e-01, time/batch = 14.8108s	
22215/33250 (epoch 33.406), train_loss = 0.80054632, grad/param norm = 1.8634e-01, time/batch = 15.2080s	
22216/33250 (epoch 33.408), train_loss = 0.96334759, grad/param norm = 1.7588e-01, time/batch = 15.0946s	
22217/33250 (epoch 33.409), train_loss = 0.87339163, grad/param norm = 2.0573e-01, time/batch = 14.9222s	
22218/33250 (epoch 33.411), train_loss = 0.60272080, grad/param norm = 1.3292e-01, time/batch = 14.7787s	
22219/33250 (epoch 33.412), train_loss = 0.67793966, grad/param norm = 1.5304e-01, time/batch = 15.1852s	
22220/33250 (epoch 33.414), train_loss = 0.84491906, grad/param norm = 1.6093e-01, time/batch = 15.0953s	
22221/33250 (epoch 33.415), train_loss = 0.88784716, grad/param norm = 2.0249e-01, time/batch = 15.1136s	
22222/33250 (epoch 33.417), train_loss = 0.92811787, grad/param norm = 1.6610e-01, time/batch = 14.8598s	
22223/33250 (epoch 33.418), train_loss = 1.06838281, grad/param norm = 2.3889e-01, time/batch = 15.3646s	
22224/33250 (epoch 33.420), train_loss = 0.87972589, grad/param norm = 1.7670e-01, time/batch = 15.2536s	
22225/33250 (epoch 33.421), train_loss = 0.76117043, grad/param norm = 1.5304e-01, time/batch = 14.7354s	
22226/33250 (epoch 33.423), train_loss = 0.85671614, grad/param norm = 1.7275e-01, time/batch = 14.6260s	
22227/33250 (epoch 33.424), train_loss = 0.96600718, grad/param norm = 2.5743e-01, time/batch = 15.0266s	
22228/33250 (epoch 33.426), train_loss = 0.77143412, grad/param norm = 1.4932e-01, time/batch = 14.7130s	
22229/33250 (epoch 33.427), train_loss = 0.77508928, grad/param norm = 1.8439e-01, time/batch = 15.0197s	
22230/33250 (epoch 33.429), train_loss = 0.88188977, grad/param norm = 2.4731e-01, time/batch = 14.7088s	
22231/33250 (epoch 33.430), train_loss = 0.75294839, grad/param norm = 1.7515e-01, time/batch = 15.2652s	
22232/33250 (epoch 33.432), train_loss = 0.88379998, grad/param norm = 1.6140e-01, time/batch = 15.0220s	
22233/33250 (epoch 33.433), train_loss = 0.74635742, grad/param norm = 2.7198e-01, time/batch = 14.9442s	
22234/33250 (epoch 33.435), train_loss = 0.92821177, grad/param norm = 2.0986e-01, time/batch = 14.9389s	
22235/33250 (epoch 33.436), train_loss = 0.77450557, grad/param norm = 1.7938e-01, time/batch = 15.2153s	
22236/33250 (epoch 33.438), train_loss = 0.92540940, grad/param norm = 1.7018e-01, time/batch = 14.9501s	
22237/33250 (epoch 33.439), train_loss = 0.83232089, grad/param norm = 1.5913e-01, time/batch = 15.2676s	
22238/33250 (epoch 33.441), train_loss = 0.79567539, grad/param norm = 1.5507e-01, time/batch = 14.7935s	
22239/33250 (epoch 33.442), train_loss = 0.75289023, grad/param norm = 1.7175e-01, time/batch = 14.7059s	
22240/33250 (epoch 33.444), train_loss = 0.77480624, grad/param norm = 1.5501e-01, time/batch = 14.6061s	
22241/33250 (epoch 33.445), train_loss = 0.85180194, grad/param norm = 1.6535e-01, time/batch = 14.7079s	
22242/33250 (epoch 33.447), train_loss = 0.73262936, grad/param norm = 1.5463e-01, time/batch = 15.0783s	
22243/33250 (epoch 33.448), train_loss = 0.83844491, grad/param norm = 1.5025e-01, time/batch = 15.0917s	
22244/33250 (epoch 33.450), train_loss = 0.94671209, grad/param norm = 1.9147e-01, time/batch = 14.7753s	
22245/33250 (epoch 33.451), train_loss = 0.88780194, grad/param norm = 2.0718e-01, time/batch = 14.4561s	
22246/33250 (epoch 33.453), train_loss = 0.73702084, grad/param norm = 1.4012e-01, time/batch = 14.4666s	
22247/33250 (epoch 33.454), train_loss = 0.94565042, grad/param norm = 1.7699e-01, time/batch = 14.8843s	
22248/33250 (epoch 33.456), train_loss = 0.94461887, grad/param norm = 1.5354e-01, time/batch = 14.5556s	
22249/33250 (epoch 33.457), train_loss = 0.74994449, grad/param norm = 1.6196e-01, time/batch = 14.8018s	
22250/33250 (epoch 33.459), train_loss = 0.87258956, grad/param norm = 1.8761e-01, time/batch = 14.9487s	
22251/33250 (epoch 33.460), train_loss = 0.88907500, grad/param norm = 2.0518e-01, time/batch = 15.4959s	
22252/33250 (epoch 33.462), train_loss = 0.80402668, grad/param norm = 1.6945e-01, time/batch = 15.1729s	
22253/33250 (epoch 33.463), train_loss = 0.73762453, grad/param norm = 1.3676e-01, time/batch = 14.4583s	
22254/33250 (epoch 33.465), train_loss = 0.68868658, grad/param norm = 1.5409e-01, time/batch = 14.7671s	
22255/33250 (epoch 33.466), train_loss = 0.66797618, grad/param norm = 1.2825e-01, time/batch = 14.9360s	
22256/33250 (epoch 33.468), train_loss = 0.70525178, grad/param norm = 1.4666e-01, time/batch = 14.7062s	
22257/33250 (epoch 33.469), train_loss = 0.78974119, grad/param norm = 1.5810e-01, time/batch = 14.9566s	
22258/33250 (epoch 33.471), train_loss = 0.88438470, grad/param norm = 1.6128e-01, time/batch = 14.7201s	
22259/33250 (epoch 33.472), train_loss = 0.78780703, grad/param norm = 1.9653e-01, time/batch = 14.8008s	
22260/33250 (epoch 33.474), train_loss = 0.92441390, grad/param norm = 1.9167e-01, time/batch = 14.4816s	
22261/33250 (epoch 33.475), train_loss = 0.84885990, grad/param norm = 1.6649e-01, time/batch = 14.8873s	
22262/33250 (epoch 33.477), train_loss = 0.83192798, grad/param norm = 1.5876e-01, time/batch = 14.6340s	
22263/33250 (epoch 33.478), train_loss = 0.72816416, grad/param norm = 1.7192e-01, time/batch = 15.0239s	
22264/33250 (epoch 33.480), train_loss = 0.92898721, grad/param norm = 1.6802e-01, time/batch = 14.4627s	
22265/33250 (epoch 33.481), train_loss = 0.82807204, grad/param norm = 1.9316e-01, time/batch = 14.4609s	
22266/33250 (epoch 33.483), train_loss = 0.82437728, grad/param norm = 2.0280e-01, time/batch = 14.6949s	
22267/33250 (epoch 33.484), train_loss = 0.73972251, grad/param norm = 1.5934e-01, time/batch = 14.8651s	
22268/33250 (epoch 33.486), train_loss = 0.69135475, grad/param norm = 1.4702e-01, time/batch = 17.6704s	
22269/33250 (epoch 33.487), train_loss = 0.77254601, grad/param norm = 1.5987e-01, time/batch = 15.8642s	
22270/33250 (epoch 33.489), train_loss = 0.90700803, grad/param norm = 2.0446e-01, time/batch = 14.6424s	
22271/33250 (epoch 33.490), train_loss = 0.85472885, grad/param norm = 1.8560e-01, time/batch = 17.2699s	
22272/33250 (epoch 33.492), train_loss = 0.92447400, grad/param norm = 2.0040e-01, time/batch = 18.5322s	
22273/33250 (epoch 33.493), train_loss = 0.82815262, grad/param norm = 1.7659e-01, time/batch = 17.9956s	
22274/33250 (epoch 33.495), train_loss = 0.87951044, grad/param norm = 1.5254e-01, time/batch = 16.1162s	
22275/33250 (epoch 33.496), train_loss = 0.82972052, grad/param norm = 1.6489e-01, time/batch = 15.6121s	
22276/33250 (epoch 33.498), train_loss = 0.90541450, grad/param norm = 1.7883e-01, time/batch = 16.6844s	
22277/33250 (epoch 33.499), train_loss = 0.78020692, grad/param norm = 1.5349e-01, time/batch = 16.6661s	
22278/33250 (epoch 33.501), train_loss = 0.77789481, grad/param norm = 1.7045e-01, time/batch = 15.6922s	
22279/33250 (epoch 33.502), train_loss = 0.77581409, grad/param norm = 1.4889e-01, time/batch = 19.3619s	
22280/33250 (epoch 33.504), train_loss = 0.94950206, grad/param norm = 1.9872e-01, time/batch = 19.2740s	
22281/33250 (epoch 33.505), train_loss = 0.69034802, grad/param norm = 1.2990e-01, time/batch = 17.3514s	
22282/33250 (epoch 33.507), train_loss = 0.73772260, grad/param norm = 1.7901e-01, time/batch = 15.6807s	
22283/33250 (epoch 33.508), train_loss = 0.77263911, grad/param norm = 1.5020e-01, time/batch = 14.9760s	
22284/33250 (epoch 33.510), train_loss = 0.67921532, grad/param norm = 1.3947e-01, time/batch = 14.7616s	
22285/33250 (epoch 33.511), train_loss = 0.81004881, grad/param norm = 1.9140e-01, time/batch = 15.4976s	
22286/33250 (epoch 33.513), train_loss = 0.91795173, grad/param norm = 1.5190e-01, time/batch = 15.6206s	
22287/33250 (epoch 33.514), train_loss = 0.79511725, grad/param norm = 1.6124e-01, time/batch = 15.1380s	
22288/33250 (epoch 33.516), train_loss = 0.76065243, grad/param norm = 1.6492e-01, time/batch = 16.8146s	
22289/33250 (epoch 33.517), train_loss = 0.78889130, grad/param norm = 1.6652e-01, time/batch = 30.2229s	
22290/33250 (epoch 33.519), train_loss = 0.72337460, grad/param norm = 1.2843e-01, time/batch = 17.7634s	
22291/33250 (epoch 33.520), train_loss = 1.00719670, grad/param norm = 1.9852e-01, time/batch = 17.5389s	
22292/33250 (epoch 33.522), train_loss = 0.86788880, grad/param norm = 1.6871e-01, time/batch = 16.6165s	
22293/33250 (epoch 33.523), train_loss = 0.75170786, grad/param norm = 1.6419e-01, time/batch = 16.8582s	
22294/33250 (epoch 33.525), train_loss = 0.70084652, grad/param norm = 1.7536e-01, time/batch = 16.0228s	
22295/33250 (epoch 33.526), train_loss = 0.73303981, grad/param norm = 1.5117e-01, time/batch = 15.2662s	
22296/33250 (epoch 33.528), train_loss = 0.78864036, grad/param norm = 1.8435e-01, time/batch = 15.9271s	
22297/33250 (epoch 33.529), train_loss = 0.76589107, grad/param norm = 1.7676e-01, time/batch = 15.2051s	
22298/33250 (epoch 33.531), train_loss = 0.72714773, grad/param norm = 1.4514e-01, time/batch = 16.1916s	
22299/33250 (epoch 33.532), train_loss = 0.85787218, grad/param norm = 1.5832e-01, time/batch = 17.7763s	
22300/33250 (epoch 33.534), train_loss = 0.73443582, grad/param norm = 1.5163e-01, time/batch = 18.5502s	
22301/33250 (epoch 33.535), train_loss = 0.78132689, grad/param norm = 1.4988e-01, time/batch = 17.2489s	
22302/33250 (epoch 33.537), train_loss = 0.82439487, grad/param norm = 1.6175e-01, time/batch = 15.9663s	
22303/33250 (epoch 33.538), train_loss = 0.86723229, grad/param norm = 1.7147e-01, time/batch = 16.6936s	
22304/33250 (epoch 33.540), train_loss = 0.95235888, grad/param norm = 1.5451e-01, time/batch = 17.3457s	
22305/33250 (epoch 33.541), train_loss = 0.87345472, grad/param norm = 1.7912e-01, time/batch = 16.0043s	
22306/33250 (epoch 33.543), train_loss = 0.85282997, grad/param norm = 1.7191e-01, time/batch = 15.6866s	
22307/33250 (epoch 33.544), train_loss = 0.72719753, grad/param norm = 1.7764e-01, time/batch = 18.0156s	
22308/33250 (epoch 33.546), train_loss = 0.77455312, grad/param norm = 1.9629e-01, time/batch = 15.6984s	
22309/33250 (epoch 33.547), train_loss = 0.78371342, grad/param norm = 1.8639e-01, time/batch = 17.4569s	
22310/33250 (epoch 33.549), train_loss = 0.82917146, grad/param norm = 1.7627e-01, time/batch = 16.9375s	
22311/33250 (epoch 33.550), train_loss = 0.76739939, grad/param norm = 1.4725e-01, time/batch = 18.2024s	
22312/33250 (epoch 33.552), train_loss = 0.85662875, grad/param norm = 1.5906e-01, time/batch = 17.7572s	
22313/33250 (epoch 33.553), train_loss = 0.78436141, grad/param norm = 1.6552e-01, time/batch = 15.1360s	
22314/33250 (epoch 33.555), train_loss = 0.83586405, grad/param norm = 1.6670e-01, time/batch = 15.3367s	
22315/33250 (epoch 33.556), train_loss = 0.82868520, grad/param norm = 1.9435e-01, time/batch = 18.3461s	
22316/33250 (epoch 33.558), train_loss = 0.86743065, grad/param norm = 1.7591e-01, time/batch = 16.9212s	
22317/33250 (epoch 33.559), train_loss = 0.76187965, grad/param norm = 1.6442e-01, time/batch = 15.5174s	
22318/33250 (epoch 33.561), train_loss = 0.71055677, grad/param norm = 1.5464e-01, time/batch = 18.0897s	
22319/33250 (epoch 33.562), train_loss = 0.81645629, grad/param norm = 1.6573e-01, time/batch = 18.8717s	
22320/33250 (epoch 33.564), train_loss = 1.00095586, grad/param norm = 2.0851e-01, time/batch = 16.5858s	
22321/33250 (epoch 33.565), train_loss = 0.93386493, grad/param norm = 2.1233e-01, time/batch = 19.0412s	
22322/33250 (epoch 33.567), train_loss = 0.91686195, grad/param norm = 2.0072e-01, time/batch = 19.0074s	
22323/33250 (epoch 33.568), train_loss = 0.77393607, grad/param norm = 1.8738e-01, time/batch = 16.4028s	
22324/33250 (epoch 33.570), train_loss = 0.90110684, grad/param norm = 2.4248e-01, time/batch = 18.0858s	
22325/33250 (epoch 33.571), train_loss = 0.92947739, grad/param norm = 1.7528e-01, time/batch = 17.0195s	
22326/33250 (epoch 33.573), train_loss = 0.89526031, grad/param norm = 1.8304e-01, time/batch = 16.3412s	
22327/33250 (epoch 33.574), train_loss = 0.76067913, grad/param norm = 1.4887e-01, time/batch = 17.2623s	
22328/33250 (epoch 33.576), train_loss = 0.86426867, grad/param norm = 1.6974e-01, time/batch = 17.8693s	
22329/33250 (epoch 33.577), train_loss = 0.81751283, grad/param norm = 1.6398e-01, time/batch = 17.2794s	
22330/33250 (epoch 33.579), train_loss = 0.70698140, grad/param norm = 1.6351e-01, time/batch = 16.4519s	
22331/33250 (epoch 33.580), train_loss = 0.80961898, grad/param norm = 1.4970e-01, time/batch = 18.9307s	
22332/33250 (epoch 33.582), train_loss = 0.76474981, grad/param norm = 1.5680e-01, time/batch = 15.9539s	
22333/33250 (epoch 33.583), train_loss = 0.89319696, grad/param norm = 1.6516e-01, time/batch = 17.2503s	
22334/33250 (epoch 33.585), train_loss = 0.90722667, grad/param norm = 1.6263e-01, time/batch = 18.1869s	
22335/33250 (epoch 33.586), train_loss = 0.79009312, grad/param norm = 2.0583e-01, time/batch = 18.7598s	
22336/33250 (epoch 33.588), train_loss = 0.83719778, grad/param norm = 1.6564e-01, time/batch = 17.6768s	
22337/33250 (epoch 33.589), train_loss = 0.83380378, grad/param norm = 1.8078e-01, time/batch = 16.8434s	
22338/33250 (epoch 33.591), train_loss = 0.80373670, grad/param norm = 2.5869e-01, time/batch = 17.5365s	
22339/33250 (epoch 33.592), train_loss = 0.78704610, grad/param norm = 1.7080e-01, time/batch = 15.6708s	
22340/33250 (epoch 33.594), train_loss = 0.92355309, grad/param norm = 1.8386e-01, time/batch = 16.6833s	
22341/33250 (epoch 33.595), train_loss = 0.83683654, grad/param norm = 1.8643e-01, time/batch = 17.7408s	
22342/33250 (epoch 33.597), train_loss = 0.69346852, grad/param norm = 1.5741e-01, time/batch = 16.1923s	
22343/33250 (epoch 33.598), train_loss = 0.78960205, grad/param norm = 1.8325e-01, time/batch = 17.0781s	
22344/33250 (epoch 33.600), train_loss = 0.78842510, grad/param norm = 2.0349e-01, time/batch = 16.1926s	
22345/33250 (epoch 33.602), train_loss = 0.85465090, grad/param norm = 2.1209e-01, time/batch = 17.4411s	
22346/33250 (epoch 33.603), train_loss = 0.87035174, grad/param norm = 1.6643e-01, time/batch = 15.5897s	
22347/33250 (epoch 33.605), train_loss = 0.82436595, grad/param norm = 1.8843e-01, time/batch = 15.0945s	
22348/33250 (epoch 33.606), train_loss = 0.87903084, grad/param norm = 1.8723e-01, time/batch = 14.9529s	
22349/33250 (epoch 33.608), train_loss = 0.84774456, grad/param norm = 1.7078e-01, time/batch = 14.8685s	
22350/33250 (epoch 33.609), train_loss = 0.72207922, grad/param norm = 1.7274e-01, time/batch = 18.5536s	
22351/33250 (epoch 33.611), train_loss = 0.81237773, grad/param norm = 1.8771e-01, time/batch = 17.0554s	
22352/33250 (epoch 33.612), train_loss = 0.80057754, grad/param norm = 1.7277e-01, time/batch = 17.9348s	
22353/33250 (epoch 33.614), train_loss = 1.01341373, grad/param norm = 1.9256e-01, time/batch = 15.4311s	
22354/33250 (epoch 33.615), train_loss = 0.93157019, grad/param norm = 1.8183e-01, time/batch = 15.7695s	
22355/33250 (epoch 33.617), train_loss = 1.04103591, grad/param norm = 1.9996e-01, time/batch = 15.8455s	
22356/33250 (epoch 33.618), train_loss = 1.06221714, grad/param norm = 2.7225e-01, time/batch = 16.3592s	
22357/33250 (epoch 33.620), train_loss = 0.92581581, grad/param norm = 1.9194e-01, time/batch = 17.5244s	
22358/33250 (epoch 33.621), train_loss = 0.85977802, grad/param norm = 1.6913e-01, time/batch = 16.7602s	
22359/33250 (epoch 33.623), train_loss = 0.76212376, grad/param norm = 1.7413e-01, time/batch = 17.1881s	
22360/33250 (epoch 33.624), train_loss = 0.80193497, grad/param norm = 1.8054e-01, time/batch = 19.0396s	
22361/33250 (epoch 33.626), train_loss = 0.80330278, grad/param norm = 2.0953e-01, time/batch = 14.6197s	
22362/33250 (epoch 33.627), train_loss = 0.77788198, grad/param norm = 1.7674e-01, time/batch = 14.8337s	
22363/33250 (epoch 33.629), train_loss = 0.86210938, grad/param norm = 2.5218e-01, time/batch = 15.6837s	
22364/33250 (epoch 33.630), train_loss = 0.79301435, grad/param norm = 1.8466e-01, time/batch = 15.6087s	
22365/33250 (epoch 33.632), train_loss = 0.71856142, grad/param norm = 1.5527e-01, time/batch = 16.9112s	
22366/33250 (epoch 33.633), train_loss = 0.83346931, grad/param norm = 1.7571e-01, time/batch = 16.7529s	
22367/33250 (epoch 33.635), train_loss = 0.75969384, grad/param norm = 1.5277e-01, time/batch = 16.6940s	
22368/33250 (epoch 33.636), train_loss = 0.76837221, grad/param norm = 1.6195e-01, time/batch = 16.1789s	
22369/33250 (epoch 33.638), train_loss = 0.74768202, grad/param norm = 1.6533e-01, time/batch = 17.5955s	
22370/33250 (epoch 33.639), train_loss = 0.71711196, grad/param norm = 1.7896e-01, time/batch = 19.0670s	
22371/33250 (epoch 33.641), train_loss = 0.80532862, grad/param norm = 1.7370e-01, time/batch = 19.3482s	
22372/33250 (epoch 33.642), train_loss = 0.61924602, grad/param norm = 1.6821e-01, time/batch = 17.5906s	
22373/33250 (epoch 33.644), train_loss = 0.57005111, grad/param norm = 1.3389e-01, time/batch = 19.0009s	
22374/33250 (epoch 33.645), train_loss = 0.84453032, grad/param norm = 2.0222e-01, time/batch = 16.2767s	
22375/33250 (epoch 33.647), train_loss = 0.72144183, grad/param norm = 1.8837e-01, time/batch = 17.0916s	
22376/33250 (epoch 33.648), train_loss = 0.70521261, grad/param norm = 1.6906e-01, time/batch = 15.2680s	
22377/33250 (epoch 33.650), train_loss = 0.93708911, grad/param norm = 1.9052e-01, time/batch = 17.5168s	
22378/33250 (epoch 33.651), train_loss = 0.84464103, grad/param norm = 1.8259e-01, time/batch = 16.6156s	
22379/33250 (epoch 33.653), train_loss = 0.75644059, grad/param norm = 1.6444e-01, time/batch = 18.7059s	
22380/33250 (epoch 33.654), train_loss = 0.81995597, grad/param norm = 1.5171e-01, time/batch = 16.6845s	
22381/33250 (epoch 33.656), train_loss = 0.85600591, grad/param norm = 1.8053e-01, time/batch = 17.3739s	
22382/33250 (epoch 33.657), train_loss = 0.66748568, grad/param norm = 2.0939e-01, time/batch = 17.6033s	
22383/33250 (epoch 33.659), train_loss = 0.75396388, grad/param norm = 1.5819e-01, time/batch = 15.6641s	
22384/33250 (epoch 33.660), train_loss = 0.82894472, grad/param norm = 1.7930e-01, time/batch = 18.1827s	
22385/33250 (epoch 33.662), train_loss = 0.82563257, grad/param norm = 1.6556e-01, time/batch = 16.2541s	
22386/33250 (epoch 33.663), train_loss = 0.72918754, grad/param norm = 1.5775e-01, time/batch = 15.6198s	
22387/33250 (epoch 33.665), train_loss = 0.83770025, grad/param norm = 1.6845e-01, time/batch = 16.6118s	
22388/33250 (epoch 33.666), train_loss = 0.77626308, grad/param norm = 1.4486e-01, time/batch = 18.0969s	
22389/33250 (epoch 33.668), train_loss = 0.91829204, grad/param norm = 1.8399e-01, time/batch = 19.2853s	
22390/33250 (epoch 33.669), train_loss = 0.81458953, grad/param norm = 1.7063e-01, time/batch = 18.1046s	
22391/33250 (epoch 33.671), train_loss = 0.71154182, grad/param norm = 1.5777e-01, time/batch = 19.3680s	
22392/33250 (epoch 33.672), train_loss = 0.90134176, grad/param norm = 1.7772e-01, time/batch = 15.2748s	
22393/33250 (epoch 33.674), train_loss = 0.71226825, grad/param norm = 1.7546e-01, time/batch = 15.7122s	
22394/33250 (epoch 33.675), train_loss = 0.82878738, grad/param norm = 1.7126e-01, time/batch = 16.3144s	
22395/33250 (epoch 33.677), train_loss = 0.88897130, grad/param norm = 1.7431e-01, time/batch = 14.7135s	
22396/33250 (epoch 33.678), train_loss = 0.76742626, grad/param norm = 1.6932e-01, time/batch = 14.2275s	
22397/33250 (epoch 33.680), train_loss = 0.93162326, grad/param norm = 1.9193e-01, time/batch = 14.6397s	
22398/33250 (epoch 33.681), train_loss = 0.74857623, grad/param norm = 1.8644e-01, time/batch = 14.3847s	
22399/33250 (epoch 33.683), train_loss = 0.75631338, grad/param norm = 1.6800e-01, time/batch = 14.4820s	
22400/33250 (epoch 33.684), train_loss = 0.71108427, grad/param norm = 1.8261e-01, time/batch = 15.1159s	
22401/33250 (epoch 33.686), train_loss = 0.72674036, grad/param norm = 1.7718e-01, time/batch = 14.8041s	
22402/33250 (epoch 33.687), train_loss = 0.82433383, grad/param norm = 1.6484e-01, time/batch = 14.7316s	
22403/33250 (epoch 33.689), train_loss = 0.71549530, grad/param norm = 1.7558e-01, time/batch = 14.9297s	
22404/33250 (epoch 33.690), train_loss = 0.83738783, grad/param norm = 1.6891e-01, time/batch = 14.6156s	
22405/33250 (epoch 33.692), train_loss = 0.78376139, grad/param norm = 2.0415e-01, time/batch = 14.4658s	
22406/33250 (epoch 33.693), train_loss = 0.86423178, grad/param norm = 1.6608e-01, time/batch = 14.7937s	
22407/33250 (epoch 33.695), train_loss = 0.83139265, grad/param norm = 1.5742e-01, time/batch = 14.3091s	
22408/33250 (epoch 33.696), train_loss = 0.86129621, grad/param norm = 1.6742e-01, time/batch = 14.6353s	
22409/33250 (epoch 33.698), train_loss = 0.76678497, grad/param norm = 1.6289e-01, time/batch = 14.5492s	
22410/33250 (epoch 33.699), train_loss = 1.02124028, grad/param norm = 1.7148e-01, time/batch = 14.6224s	
22411/33250 (epoch 33.701), train_loss = 0.80500012, grad/param norm = 1.4419e-01, time/batch = 14.2455s	
22412/33250 (epoch 33.702), train_loss = 0.78134340, grad/param norm = 2.4719e-01, time/batch = 14.7093s	
22413/33250 (epoch 33.704), train_loss = 0.97709284, grad/param norm = 2.1208e-01, time/batch = 14.6433s	
22414/33250 (epoch 33.705), train_loss = 0.76421322, grad/param norm = 1.4883e-01, time/batch = 14.5584s	
22415/33250 (epoch 33.707), train_loss = 0.68435367, grad/param norm = 1.7286e-01, time/batch = 14.4694s	
22416/33250 (epoch 33.708), train_loss = 0.89830469, grad/param norm = 2.0757e-01, time/batch = 14.3859s	
22417/33250 (epoch 33.710), train_loss = 0.85777329, grad/param norm = 1.9076e-01, time/batch = 14.7009s	
22418/33250 (epoch 33.711), train_loss = 0.77060372, grad/param norm = 1.9773e-01, time/batch = 14.3794s	
22419/33250 (epoch 33.713), train_loss = 0.84667945, grad/param norm = 1.5838e-01, time/batch = 14.8029s	
22420/33250 (epoch 33.714), train_loss = 0.80430765, grad/param norm = 1.8951e-01, time/batch = 14.3764s	
22421/33250 (epoch 33.716), train_loss = 0.81777137, grad/param norm = 1.5942e-01, time/batch = 14.7803s	
22422/33250 (epoch 33.717), train_loss = 0.75664009, grad/param norm = 1.4047e-01, time/batch = 15.0957s	
22423/33250 (epoch 33.719), train_loss = 0.74671335, grad/param norm = 1.4740e-01, time/batch = 14.6277s	
22424/33250 (epoch 33.720), train_loss = 1.01656177, grad/param norm = 1.8405e-01, time/batch = 14.4098s	
22425/33250 (epoch 33.722), train_loss = 0.70054725, grad/param norm = 1.6155e-01, time/batch = 14.0835s	
22426/33250 (epoch 33.723), train_loss = 0.63131912, grad/param norm = 1.3249e-01, time/batch = 14.5537s	
22427/33250 (epoch 33.725), train_loss = 0.76133300, grad/param norm = 1.4610e-01, time/batch = 14.5272s	
22428/33250 (epoch 33.726), train_loss = 0.81377856, grad/param norm = 1.6291e-01, time/batch = 14.0674s	
22429/33250 (epoch 33.728), train_loss = 0.84158379, grad/param norm = 1.8360e-01, time/batch = 14.1450s	
22430/33250 (epoch 33.729), train_loss = 0.89787270, grad/param norm = 1.7847e-01, time/batch = 14.6186s	
22431/33250 (epoch 33.731), train_loss = 0.71890134, grad/param norm = 1.6570e-01, time/batch = 14.2238s	
22432/33250 (epoch 33.732), train_loss = 0.72964475, grad/param norm = 1.4332e-01, time/batch = 14.2995s	
22433/33250 (epoch 33.734), train_loss = 0.83578669, grad/param norm = 1.8628e-01, time/batch = 14.0700s	
22434/33250 (epoch 33.735), train_loss = 0.84437261, grad/param norm = 1.8494e-01, time/batch = 14.4587s	
22435/33250 (epoch 33.737), train_loss = 0.78035206, grad/param norm = 1.6544e-01, time/batch = 14.3104s	
22436/33250 (epoch 33.738), train_loss = 0.83378445, grad/param norm = 1.6662e-01, time/batch = 13.9330s	
22437/33250 (epoch 33.740), train_loss = 0.84217359, grad/param norm = 1.7646e-01, time/batch = 14.2387s	
22438/33250 (epoch 33.741), train_loss = 0.85551158, grad/param norm = 1.6147e-01, time/batch = 14.4554s	
22439/33250 (epoch 33.743), train_loss = 0.75750395, grad/param norm = 1.6078e-01, time/batch = 13.9775s	
22440/33250 (epoch 33.744), train_loss = 0.76651604, grad/param norm = 1.8291e-01, time/batch = 13.8253s	
22441/33250 (epoch 33.746), train_loss = 0.72369003, grad/param norm = 1.5301e-01, time/batch = 14.5353s	
22442/33250 (epoch 33.747), train_loss = 0.75523506, grad/param norm = 1.6614e-01, time/batch = 14.2971s	
22443/33250 (epoch 33.749), train_loss = 0.92729205, grad/param norm = 1.9736e-01, time/batch = 14.3788s	
22444/33250 (epoch 33.750), train_loss = 0.92134716, grad/param norm = 1.7633e-01, time/batch = 14.5470s	
22445/33250 (epoch 33.752), train_loss = 0.78422480, grad/param norm = 1.6429e-01, time/batch = 14.7796s	
22446/33250 (epoch 33.753), train_loss = 0.75444663, grad/param norm = 1.6926e-01, time/batch = 13.9713s	
22447/33250 (epoch 33.755), train_loss = 0.72261731, grad/param norm = 1.7455e-01, time/batch = 14.3184s	
22448/33250 (epoch 33.756), train_loss = 0.82209049, grad/param norm = 1.7941e-01, time/batch = 14.4632s	
22449/33250 (epoch 33.758), train_loss = 0.95651522, grad/param norm = 1.6559e-01, time/batch = 14.6329s	
22450/33250 (epoch 33.759), train_loss = 0.76461127, grad/param norm = 1.5863e-01, time/batch = 14.2429s	
22451/33250 (epoch 33.761), train_loss = 0.83493613, grad/param norm = 1.6007e-01, time/batch = 14.6216s	
22452/33250 (epoch 33.762), train_loss = 0.89306484, grad/param norm = 2.0508e-01, time/batch = 14.6250s	
22453/33250 (epoch 33.764), train_loss = 0.73040021, grad/param norm = 2.0543e-01, time/batch = 14.2992s	
22454/33250 (epoch 33.765), train_loss = 0.86041599, grad/param norm = 1.9476e-01, time/batch = 14.3095s	
22455/33250 (epoch 33.767), train_loss = 0.64570577, grad/param norm = 1.6082e-01, time/batch = 15.1759s	
22456/33250 (epoch 33.768), train_loss = 0.68278493, grad/param norm = 1.7203e-01, time/batch = 14.3068s	
22457/33250 (epoch 33.770), train_loss = 0.83657638, grad/param norm = 1.7707e-01, time/batch = 14.3980s	
22458/33250 (epoch 33.771), train_loss = 0.85762898, grad/param norm = 1.8596e-01, time/batch = 14.2557s	
22459/33250 (epoch 33.773), train_loss = 0.79025223, grad/param norm = 1.7706e-01, time/batch = 14.7172s	
22460/33250 (epoch 33.774), train_loss = 0.69602508, grad/param norm = 1.6924e-01, time/batch = 14.3230s	
22461/33250 (epoch 33.776), train_loss = 0.76726343, grad/param norm = 1.6379e-01, time/batch = 14.2419s	
22462/33250 (epoch 33.777), train_loss = 0.90378038, grad/param norm = 1.8400e-01, time/batch = 15.0175s	
22463/33250 (epoch 33.779), train_loss = 0.80425830, grad/param norm = 1.7935e-01, time/batch = 15.0116s	
22464/33250 (epoch 33.780), train_loss = 0.93527840, grad/param norm = 2.1557e-01, time/batch = 14.5495s	
22465/33250 (epoch 33.782), train_loss = 0.80276077, grad/param norm = 1.9438e-01, time/batch = 14.3813s	
22466/33250 (epoch 33.783), train_loss = 0.67702630, grad/param norm = 1.6314e-01, time/batch = 14.4714s	
22467/33250 (epoch 33.785), train_loss = 0.71977339, grad/param norm = 1.9184e-01, time/batch = 14.8540s	
22468/33250 (epoch 33.786), train_loss = 0.91120823, grad/param norm = 1.7839e-01, time/batch = 14.2226s	
22469/33250 (epoch 33.788), train_loss = 0.90226298, grad/param norm = 1.7491e-01, time/batch = 14.0946s	
22470/33250 (epoch 33.789), train_loss = 0.92063574, grad/param norm = 2.3997e-01, time/batch = 14.3298s	
22471/33250 (epoch 33.791), train_loss = 0.93746911, grad/param norm = 1.9769e-01, time/batch = 14.6279s	
22472/33250 (epoch 33.792), train_loss = 0.97465996, grad/param norm = 1.9402e-01, time/batch = 14.6430s	
22473/33250 (epoch 33.794), train_loss = 0.79227159, grad/param norm = 1.6996e-01, time/batch = 14.7940s	
22474/33250 (epoch 33.795), train_loss = 0.80331383, grad/param norm = 1.7774e-01, time/batch = 14.4683s	
22475/33250 (epoch 33.797), train_loss = 0.87990853, grad/param norm = 1.8871e-01, time/batch = 15.2736s	
22476/33250 (epoch 33.798), train_loss = 0.80460422, grad/param norm = 2.0946e-01, time/batch = 14.4655s	
22477/33250 (epoch 33.800), train_loss = 0.86262250, grad/param norm = 1.9211e-01, time/batch = 14.2998s	
22478/33250 (epoch 33.802), train_loss = 0.79854462, grad/param norm = 1.4899e-01, time/batch = 14.4640s	
22479/33250 (epoch 33.803), train_loss = 0.84884184, grad/param norm = 1.5054e-01, time/batch = 14.6944s	
22480/33250 (epoch 33.805), train_loss = 0.84240088, grad/param norm = 1.7269e-01, time/batch = 14.5563s	
22481/33250 (epoch 33.806), train_loss = 0.83096258, grad/param norm = 1.8118e-01, time/batch = 14.2472s	
22482/33250 (epoch 33.808), train_loss = 0.74596358, grad/param norm = 1.8889e-01, time/batch = 14.5366s	
22483/33250 (epoch 33.809), train_loss = 0.73919758, grad/param norm = 1.6460e-01, time/batch = 14.0015s	
22484/33250 (epoch 33.811), train_loss = 0.72821837, grad/param norm = 1.5694e-01, time/batch = 14.8710s	
22485/33250 (epoch 33.812), train_loss = 0.86656990, grad/param norm = 1.9619e-01, time/batch = 14.3952s	
22486/33250 (epoch 33.814), train_loss = 0.80667340, grad/param norm = 2.0413e-01, time/batch = 14.4653s	
22487/33250 (epoch 33.815), train_loss = 0.85913275, grad/param norm = 1.7455e-01, time/batch = 14.3849s	
22488/33250 (epoch 33.817), train_loss = 0.81141434, grad/param norm = 1.7435e-01, time/batch = 14.4776s	
22489/33250 (epoch 33.818), train_loss = 0.74253550, grad/param norm = 1.7341e-01, time/batch = 14.4682s	
22490/33250 (epoch 33.820), train_loss = 0.84510440, grad/param norm = 1.7824e-01, time/batch = 14.4673s	
22491/33250 (epoch 33.821), train_loss = 0.79626110, grad/param norm = 1.6150e-01, time/batch = 14.4570s	
22492/33250 (epoch 33.823), train_loss = 1.10745529, grad/param norm = 1.9370e-01, time/batch = 14.7232s	
22493/33250 (epoch 33.824), train_loss = 0.74464213, grad/param norm = 1.7926e-01, time/batch = 14.6689s	
22494/33250 (epoch 33.826), train_loss = 0.84965374, grad/param norm = 1.6503e-01, time/batch = 16.9625s	
22495/33250 (epoch 33.827), train_loss = 0.71763749, grad/param norm = 1.5932e-01, time/batch = 15.2425s	
22496/33250 (epoch 33.829), train_loss = 0.84370086, grad/param norm = 1.7642e-01, time/batch = 15.2690s	
22497/33250 (epoch 33.830), train_loss = 0.89292631, grad/param norm = 2.7668e-01, time/batch = 17.6012s	
22498/33250 (epoch 33.832), train_loss = 0.83133704, grad/param norm = 1.7475e-01, time/batch = 16.1777s	
22499/33250 (epoch 33.833), train_loss = 0.79799601, grad/param norm = 1.6016e-01, time/batch = 16.9336s	
22500/33250 (epoch 33.835), train_loss = 0.74358939, grad/param norm = 1.8903e-01, time/batch = 16.2634s	
22501/33250 (epoch 33.836), train_loss = 0.80783603, grad/param norm = 1.7753e-01, time/batch = 16.3658s	
22502/33250 (epoch 33.838), train_loss = 0.84872407, grad/param norm = 1.7452e-01, time/batch = 15.3280s	
22503/33250 (epoch 33.839), train_loss = 0.77154233, grad/param norm = 1.6754e-01, time/batch = 16.9648s	
22504/33250 (epoch 33.841), train_loss = 0.75786934, grad/param norm = 1.5971e-01, time/batch = 20.2018s	
22505/33250 (epoch 33.842), train_loss = 0.93735179, grad/param norm = 1.8169e-01, time/batch = 17.2137s	
22506/33250 (epoch 33.844), train_loss = 0.91040878, grad/param norm = 1.9725e-01, time/batch = 16.8606s	
22507/33250 (epoch 33.845), train_loss = 1.00098785, grad/param norm = 2.0157e-01, time/batch = 15.8445s	
22508/33250 (epoch 33.847), train_loss = 0.95828588, grad/param norm = 1.7259e-01, time/batch = 17.1917s	
22509/33250 (epoch 33.848), train_loss = 1.01826322, grad/param norm = 2.2396e-01, time/batch = 17.1884s	
22510/33250 (epoch 33.850), train_loss = 0.89036760, grad/param norm = 1.6883e-01, time/batch = 16.5967s	
22511/33250 (epoch 33.851), train_loss = 0.71361531, grad/param norm = 1.8839e-01, time/batch = 19.1581s	
22512/33250 (epoch 33.853), train_loss = 0.85816805, grad/param norm = 2.0336e-01, time/batch = 15.7964s	
22513/33250 (epoch 33.854), train_loss = 0.77263936, grad/param norm = 1.5715e-01, time/batch = 19.6406s	
22514/33250 (epoch 33.856), train_loss = 0.76351042, grad/param norm = 2.0065e-01, time/batch = 25.8408s	
22515/33250 (epoch 33.857), train_loss = 0.71824587, grad/param norm = 1.7240e-01, time/batch = 15.1167s	
22516/33250 (epoch 33.859), train_loss = 0.77471410, grad/param norm = 1.8650e-01, time/batch = 14.9790s	
22517/33250 (epoch 33.860), train_loss = 0.86238726, grad/param norm = 1.7603e-01, time/batch = 14.7151s	
22518/33250 (epoch 33.862), train_loss = 0.71858403, grad/param norm = 1.5255e-01, time/batch = 16.2824s	
22519/33250 (epoch 33.863), train_loss = 0.75804077, grad/param norm = 1.7994e-01, time/batch = 15.2592s	
22520/33250 (epoch 33.865), train_loss = 0.85843644, grad/param norm = 1.7521e-01, time/batch = 15.5200s	
22521/33250 (epoch 33.866), train_loss = 0.71982576, grad/param norm = 2.0847e-01, time/batch = 15.7366s	
22522/33250 (epoch 33.868), train_loss = 0.81731970, grad/param norm = 1.9949e-01, time/batch = 16.4259s	
22523/33250 (epoch 33.869), train_loss = 0.83707510, grad/param norm = 1.8489e-01, time/batch = 17.7068s	
22524/33250 (epoch 33.871), train_loss = 0.64270884, grad/param norm = 1.4098e-01, time/batch = 16.6953s	
22525/33250 (epoch 33.872), train_loss = 0.88133439, grad/param norm = 1.7743e-01, time/batch = 17.6989s	
22526/33250 (epoch 33.874), train_loss = 0.76353315, grad/param norm = 1.8625e-01, time/batch = 15.8551s	
22527/33250 (epoch 33.875), train_loss = 0.68609162, grad/param norm = 1.6250e-01, time/batch = 17.1760s	
22528/33250 (epoch 33.877), train_loss = 0.91654815, grad/param norm = 1.7497e-01, time/batch = 15.1168s	
22529/33250 (epoch 33.878), train_loss = 0.81634138, grad/param norm = 1.6220e-01, time/batch = 15.6876s	
22530/33250 (epoch 33.880), train_loss = 0.81921985, grad/param norm = 1.9666e-01, time/batch = 17.0971s	
22531/33250 (epoch 33.881), train_loss = 0.92487520, grad/param norm = 1.7947e-01, time/batch = 16.8196s	
22532/33250 (epoch 33.883), train_loss = 0.84707526, grad/param norm = 1.6992e-01, time/batch = 16.6018s	
22533/33250 (epoch 33.884), train_loss = 0.89611353, grad/param norm = 1.9348e-01, time/batch = 18.3571s	
22534/33250 (epoch 33.886), train_loss = 0.75897063, grad/param norm = 1.6966e-01, time/batch = 16.8672s	
22535/33250 (epoch 33.887), train_loss = 0.79111842, grad/param norm = 1.7678e-01, time/batch = 17.9290s	
22536/33250 (epoch 33.889), train_loss = 0.76779742, grad/param norm = 1.4586e-01, time/batch = 16.2727s	
22537/33250 (epoch 33.890), train_loss = 0.63974346, grad/param norm = 1.3058e-01, time/batch = 15.3299s	
22538/33250 (epoch 33.892), train_loss = 0.86131771, grad/param norm = 1.5661e-01, time/batch = 16.6037s	
22539/33250 (epoch 33.893), train_loss = 0.88301235, grad/param norm = 1.8958e-01, time/batch = 16.6156s	
22540/33250 (epoch 33.895), train_loss = 0.75492380, grad/param norm = 1.5930e-01, time/batch = 16.5320s	
22541/33250 (epoch 33.896), train_loss = 0.88468535, grad/param norm = 1.7869e-01, time/batch = 17.0146s	
22542/33250 (epoch 33.898), train_loss = 0.81819750, grad/param norm = 1.6697e-01, time/batch = 15.9548s	
22543/33250 (epoch 33.899), train_loss = 0.74870619, grad/param norm = 1.6092e-01, time/batch = 18.2962s	
22544/33250 (epoch 33.901), train_loss = 0.70910087, grad/param norm = 1.6473e-01, time/batch = 16.6173s	
22545/33250 (epoch 33.902), train_loss = 0.78699044, grad/param norm = 1.7170e-01, time/batch = 16.4494s	
22546/33250 (epoch 33.904), train_loss = 0.74661672, grad/param norm = 1.6274e-01, time/batch = 16.7768s	
22547/33250 (epoch 33.905), train_loss = 0.78091694, grad/param norm = 1.5054e-01, time/batch = 16.4249s	
22548/33250 (epoch 33.907), train_loss = 0.75613030, grad/param norm = 1.8346e-01, time/batch = 18.1718s	
22549/33250 (epoch 33.908), train_loss = 0.80322415, grad/param norm = 1.4730e-01, time/batch = 15.8900s	
22550/33250 (epoch 33.910), train_loss = 0.88291460, grad/param norm = 1.8189e-01, time/batch = 16.5292s	
22551/33250 (epoch 33.911), train_loss = 0.71798344, grad/param norm = 1.5633e-01, time/batch = 17.2685s	
22552/33250 (epoch 33.913), train_loss = 0.78405630, grad/param norm = 1.6595e-01, time/batch = 16.7587s	
22553/33250 (epoch 33.914), train_loss = 0.68486133, grad/param norm = 1.6583e-01, time/batch = 17.7865s	
22554/33250 (epoch 33.916), train_loss = 0.72642436, grad/param norm = 1.6472e-01, time/batch = 19.3720s	
22555/33250 (epoch 33.917), train_loss = 0.80547528, grad/param norm = 1.3898e-01, time/batch = 16.4380s	
22556/33250 (epoch 33.919), train_loss = 0.75106692, grad/param norm = 1.8640e-01, time/batch = 14.9536s	
22557/33250 (epoch 33.920), train_loss = 0.82667859, grad/param norm = 1.9801e-01, time/batch = 17.9291s	
22558/33250 (epoch 33.922), train_loss = 0.83868045, grad/param norm = 1.7550e-01, time/batch = 15.1988s	
22559/33250 (epoch 33.923), train_loss = 0.77751902, grad/param norm = 1.6972e-01, time/batch = 16.0857s	
22560/33250 (epoch 33.925), train_loss = 0.77682840, grad/param norm = 1.6160e-01, time/batch = 16.7749s	
22561/33250 (epoch 33.926), train_loss = 0.75734739, grad/param norm = 1.5400e-01, time/batch = 17.8543s	
22562/33250 (epoch 33.928), train_loss = 0.76700462, grad/param norm = 1.7203e-01, time/batch = 19.5261s	
22563/33250 (epoch 33.929), train_loss = 0.68951784, grad/param norm = 1.3590e-01, time/batch = 16.0392s	
22564/33250 (epoch 33.931), train_loss = 0.90657581, grad/param norm = 1.7658e-01, time/batch = 16.9429s	
22565/33250 (epoch 33.932), train_loss = 0.76975893, grad/param norm = 1.8019e-01, time/batch = 17.1975s	
22566/33250 (epoch 33.934), train_loss = 0.74668234, grad/param norm = 1.4919e-01, time/batch = 17.0899s	
22567/33250 (epoch 33.935), train_loss = 0.75621437, grad/param norm = 1.7586e-01, time/batch = 16.1911s	
22568/33250 (epoch 33.937), train_loss = 0.74823976, grad/param norm = 1.7511e-01, time/batch = 17.3479s	
22569/33250 (epoch 33.938), train_loss = 0.79036634, grad/param norm = 1.8292e-01, time/batch = 16.2608s	
22570/33250 (epoch 33.940), train_loss = 0.76849162, grad/param norm = 1.5398e-01, time/batch = 17.0987s	
22571/33250 (epoch 33.941), train_loss = 0.84477677, grad/param norm = 1.6756e-01, time/batch = 16.1894s	
22572/33250 (epoch 33.943), train_loss = 0.93795045, grad/param norm = 1.7198e-01, time/batch = 17.7070s	
22573/33250 (epoch 33.944), train_loss = 0.77194770, grad/param norm = 1.5570e-01, time/batch = 17.5750s	
22574/33250 (epoch 33.946), train_loss = 0.91809157, grad/param norm = 1.9582e-01, time/batch = 15.8095s	
22575/33250 (epoch 33.947), train_loss = 0.73671949, grad/param norm = 1.7411e-01, time/batch = 17.9512s	
22576/33250 (epoch 33.949), train_loss = 0.86025277, grad/param norm = 1.6600e-01, time/batch = 17.8547s	
22577/33250 (epoch 33.950), train_loss = 0.88112168, grad/param norm = 1.7272e-01, time/batch = 16.1895s	
22578/33250 (epoch 33.952), train_loss = 0.80371615, grad/param norm = 1.8208e-01, time/batch = 18.1721s	
22579/33250 (epoch 33.953), train_loss = 0.83033269, grad/param norm = 1.7529e-01, time/batch = 17.1783s	
22580/33250 (epoch 33.955), train_loss = 0.88683892, grad/param norm = 1.7592e-01, time/batch = 17.5101s	
22581/33250 (epoch 33.956), train_loss = 0.82760354, grad/param norm = 2.0792e-01, time/batch = 17.2763s	
22582/33250 (epoch 33.958), train_loss = 0.76230381, grad/param norm = 1.5220e-01, time/batch = 16.8692s	
22583/33250 (epoch 33.959), train_loss = 0.76278834, grad/param norm = 1.6394e-01, time/batch = 18.6278s	
22584/33250 (epoch 33.961), train_loss = 1.00158068, grad/param norm = 1.8787e-01, time/batch = 16.0208s	
22585/33250 (epoch 33.962), train_loss = 0.79206957, grad/param norm = 1.7625e-01, time/batch = 15.7815s	
22586/33250 (epoch 33.964), train_loss = 0.93318017, grad/param norm = 1.9404e-01, time/batch = 16.2799s	
22587/33250 (epoch 33.965), train_loss = 0.87107792, grad/param norm = 1.9836e-01, time/batch = 17.3426s	
22588/33250 (epoch 33.967), train_loss = 0.82135613, grad/param norm = 1.6787e-01, time/batch = 16.4392s	
22589/33250 (epoch 33.968), train_loss = 0.93758808, grad/param norm = 1.5964e-01, time/batch = 18.1855s	
22590/33250 (epoch 33.970), train_loss = 1.06337056, grad/param norm = 2.8073e-01, time/batch = 16.3247s	
22591/33250 (epoch 33.971), train_loss = 0.98778849, grad/param norm = 1.9536e-01, time/batch = 15.9210s	
22592/33250 (epoch 33.973), train_loss = 0.79963523, grad/param norm = 1.6639e-01, time/batch = 18.2746s	
22593/33250 (epoch 33.974), train_loss = 0.89340160, grad/param norm = 1.8600e-01, time/batch = 19.0273s	
22594/33250 (epoch 33.976), train_loss = 0.79814386, grad/param norm = 1.8388e-01, time/batch = 17.2549s	
22595/33250 (epoch 33.977), train_loss = 0.79323099, grad/param norm = 1.7554e-01, time/batch = 17.9256s	
22596/33250 (epoch 33.979), train_loss = 0.86826672, grad/param norm = 2.0080e-01, time/batch = 19.1666s	
22597/33250 (epoch 33.980), train_loss = 0.85710345, grad/param norm = 1.7680e-01, time/batch = 16.5165s	
22598/33250 (epoch 33.982), train_loss = 0.76159311, grad/param norm = 1.4908e-01, time/batch = 16.6665s	
22599/33250 (epoch 33.983), train_loss = 0.84923275, grad/param norm = 2.0386e-01, time/batch = 16.2735s	
22600/33250 (epoch 33.985), train_loss = 0.78112625, grad/param norm = 2.1700e-01, time/batch = 17.5944s	
22601/33250 (epoch 33.986), train_loss = 0.88610492, grad/param norm = 1.7694e-01, time/batch = 17.0334s	
22602/33250 (epoch 33.988), train_loss = 0.92325932, grad/param norm = 1.7870e-01, time/batch = 19.1966s	
22603/33250 (epoch 33.989), train_loss = 0.91211252, grad/param norm = 1.7485e-01, time/batch = 17.5473s	
22604/33250 (epoch 33.991), train_loss = 0.85324295, grad/param norm = 1.5343e-01, time/batch = 15.6682s	
22605/33250 (epoch 33.992), train_loss = 0.81731554, grad/param norm = 1.7947e-01, time/batch = 15.4342s	
22606/33250 (epoch 33.994), train_loss = 0.77840970, grad/param norm = 1.7250e-01, time/batch = 17.9332s	
22607/33250 (epoch 33.995), train_loss = 0.79490794, grad/param norm = 2.1710e-01, time/batch = 16.0364s	
22608/33250 (epoch 33.997), train_loss = 0.59335164, grad/param norm = 1.4574e-01, time/batch = 15.4467s	
22609/33250 (epoch 33.998), train_loss = 0.86431205, grad/param norm = 1.6754e-01, time/batch = 15.4411s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
22610/33250 (epoch 34.000), train_loss = 0.84227888, grad/param norm = 1.5816e-01, time/batch = 17.5160s	
22611/33250 (epoch 34.002), train_loss = 1.03470108, grad/param norm = 1.8907e-01, time/batch = 16.8643s	
22612/33250 (epoch 34.003), train_loss = 0.89946679, grad/param norm = 2.0160e-01, time/batch = 16.7930s	
22613/33250 (epoch 34.005), train_loss = 0.67921044, grad/param norm = 1.4991e-01, time/batch = 17.1378s	
22614/33250 (epoch 34.006), train_loss = 0.69977701, grad/param norm = 1.5650e-01, time/batch = 17.8623s	
22615/33250 (epoch 34.008), train_loss = 0.90116857, grad/param norm = 1.7748e-01, time/batch = 17.4849s	
22616/33250 (epoch 34.009), train_loss = 0.97278803, grad/param norm = 1.8751e-01, time/batch = 17.6785s	
22617/33250 (epoch 34.011), train_loss = 0.77238031, grad/param norm = 1.6273e-01, time/batch = 18.0921s	
22618/33250 (epoch 34.012), train_loss = 0.81165529, grad/param norm = 2.2539e-01, time/batch = 17.3626s	
22619/33250 (epoch 34.014), train_loss = 0.90204928, grad/param norm = 1.8792e-01, time/batch = 16.0824s	
22620/33250 (epoch 34.015), train_loss = 0.82710121, grad/param norm = 1.6717e-01, time/batch = 16.7761s	
22621/33250 (epoch 34.017), train_loss = 0.85459984, grad/param norm = 2.0038e-01, time/batch = 17.9632s	
22622/33250 (epoch 34.018), train_loss = 0.66539038, grad/param norm = 1.4898e-01, time/batch = 17.6303s	
22623/33250 (epoch 34.020), train_loss = 0.82309292, grad/param norm = 1.4092e-01, time/batch = 17.7926s	
22624/33250 (epoch 34.021), train_loss = 0.85605385, grad/param norm = 1.7381e-01, time/batch = 18.1930s	
22625/33250 (epoch 34.023), train_loss = 0.66747860, grad/param norm = 1.6038e-01, time/batch = 17.4838s	
22626/33250 (epoch 34.024), train_loss = 0.90923834, grad/param norm = 1.9000e-01, time/batch = 17.2243s	
22627/33250 (epoch 34.026), train_loss = 0.84535055, grad/param norm = 1.7207e-01, time/batch = 15.2797s	
22628/33250 (epoch 34.027), train_loss = 0.86327299, grad/param norm = 1.8953e-01, time/batch = 16.1842s	
22629/33250 (epoch 34.029), train_loss = 0.78739084, grad/param norm = 1.6806e-01, time/batch = 16.4386s	
22630/33250 (epoch 34.030), train_loss = 0.82913181, grad/param norm = 1.9992e-01, time/batch = 14.6350s	
22631/33250 (epoch 34.032), train_loss = 1.00745846, grad/param norm = 1.8652e-01, time/batch = 17.6093s	
22632/33250 (epoch 34.033), train_loss = 0.78767439, grad/param norm = 1.8522e-01, time/batch = 16.5885s	
22633/33250 (epoch 34.035), train_loss = 0.85565968, grad/param norm = 2.1716e-01, time/batch = 15.9159s	
22634/33250 (epoch 34.036), train_loss = 0.88448310, grad/param norm = 1.8810e-01, time/batch = 19.8396s	
22635/33250 (epoch 34.038), train_loss = 0.83067978, grad/param norm = 1.4892e-01, time/batch = 18.0207s	
22636/33250 (epoch 34.039), train_loss = 0.76724419, grad/param norm = 1.6076e-01, time/batch = 16.8388s	
22637/33250 (epoch 34.041), train_loss = 0.84501710, grad/param norm = 2.1171e-01, time/batch = 17.1045s	
22638/33250 (epoch 34.042), train_loss = 0.69811477, grad/param norm = 1.5255e-01, time/batch = 16.8558s	
22639/33250 (epoch 34.044), train_loss = 0.91897380, grad/param norm = 1.7203e-01, time/batch = 17.1008s	
22640/33250 (epoch 34.045), train_loss = 0.91827643, grad/param norm = 1.7795e-01, time/batch = 16.2726s	
22641/33250 (epoch 34.047), train_loss = 0.82795876, grad/param norm = 1.6928e-01, time/batch = 17.7959s	
22642/33250 (epoch 34.048), train_loss = 0.90751559, grad/param norm = 2.2332e-01, time/batch = 17.3633s	
22643/33250 (epoch 34.050), train_loss = 0.84832931, grad/param norm = 1.8072e-01, time/batch = 16.9990s	
22644/33250 (epoch 34.051), train_loss = 0.82298749, grad/param norm = 1.7181e-01, time/batch = 16.4401s	
22645/33250 (epoch 34.053), train_loss = 0.87592826, grad/param norm = 2.0417e-01, time/batch = 16.7600s	
22646/33250 (epoch 34.054), train_loss = 0.70050905, grad/param norm = 1.5893e-01, time/batch = 17.3607s	
22647/33250 (epoch 34.056), train_loss = 0.73578966, grad/param norm = 1.5115e-01, time/batch = 15.9293s	
22648/33250 (epoch 34.057), train_loss = 0.92900271, grad/param norm = 1.8687e-01, time/batch = 15.9540s	
22649/33250 (epoch 34.059), train_loss = 0.77858667, grad/param norm = 1.7155e-01, time/batch = 18.7530s	
22650/33250 (epoch 34.060), train_loss = 0.83886998, grad/param norm = 1.8861e-01, time/batch = 18.8405s	
22651/33250 (epoch 34.062), train_loss = 0.91462899, grad/param norm = 1.8040e-01, time/batch = 17.6249s	
22652/33250 (epoch 34.063), train_loss = 0.95423780, grad/param norm = 1.8046e-01, time/batch = 17.2879s	
22653/33250 (epoch 34.065), train_loss = 0.81556852, grad/param norm = 1.7793e-01, time/batch = 17.1790s	
22654/33250 (epoch 34.066), train_loss = 0.87328752, grad/param norm = 1.8596e-01, time/batch = 17.8122s	
22655/33250 (epoch 34.068), train_loss = 0.79095619, grad/param norm = 1.7200e-01, time/batch = 18.1027s	
22656/33250 (epoch 34.069), train_loss = 0.84098477, grad/param norm = 1.6231e-01, time/batch = 16.0152s	
22657/33250 (epoch 34.071), train_loss = 0.76772121, grad/param norm = 1.4750e-01, time/batch = 16.2525s	
22658/33250 (epoch 34.072), train_loss = 0.75189559, grad/param norm = 1.5621e-01, time/batch = 17.5980s	
22659/33250 (epoch 34.074), train_loss = 0.83982263, grad/param norm = 1.5441e-01, time/batch = 17.4237s	
22660/33250 (epoch 34.075), train_loss = 0.78841807, grad/param norm = 1.7532e-01, time/batch = 17.2745s	
22661/33250 (epoch 34.077), train_loss = 0.81054956, grad/param norm = 1.9149e-01, time/batch = 19.2686s	
22662/33250 (epoch 34.078), train_loss = 0.82492784, grad/param norm = 1.6553e-01, time/batch = 17.3736s	
22663/33250 (epoch 34.080), train_loss = 0.82807514, grad/param norm = 1.9893e-01, time/batch = 18.1964s	
22664/33250 (epoch 34.081), train_loss = 0.84506870, grad/param norm = 1.6365e-01, time/batch = 15.6994s	
22665/33250 (epoch 34.083), train_loss = 0.95230906, grad/param norm = 1.7339e-01, time/batch = 17.5109s	
22666/33250 (epoch 34.084), train_loss = 0.87269468, grad/param norm = 2.0262e-01, time/batch = 17.4278s	
22667/33250 (epoch 34.086), train_loss = 0.82684430, grad/param norm = 1.4876e-01, time/batch = 16.4272s	
22668/33250 (epoch 34.087), train_loss = 0.70221600, grad/param norm = 1.4239e-01, time/batch = 17.0306s	
22669/33250 (epoch 34.089), train_loss = 0.80315759, grad/param norm = 1.6820e-01, time/batch = 16.8772s	
22670/33250 (epoch 34.090), train_loss = 0.84964574, grad/param norm = 1.8756e-01, time/batch = 16.4644s	
22671/33250 (epoch 34.092), train_loss = 0.75858028, grad/param norm = 1.5746e-01, time/batch = 15.3454s	
22672/33250 (epoch 34.093), train_loss = 0.80586017, grad/param norm = 1.6351e-01, time/batch = 18.1021s	
22673/33250 (epoch 34.095), train_loss = 0.81950306, grad/param norm = 1.6226e-01, time/batch = 17.0390s	
22674/33250 (epoch 34.096), train_loss = 0.69854318, grad/param norm = 1.6458e-01, time/batch = 17.4265s	
22675/33250 (epoch 34.098), train_loss = 0.70655999, grad/param norm = 1.7403e-01, time/batch = 14.7046s	
22676/33250 (epoch 34.099), train_loss = 0.64178619, grad/param norm = 1.4801e-01, time/batch = 15.4377s	
22677/33250 (epoch 34.101), train_loss = 0.80422754, grad/param norm = 1.9754e-01, time/batch = 15.6078s	
22678/33250 (epoch 34.102), train_loss = 0.75380353, grad/param norm = 1.7033e-01, time/batch = 15.1718s	
22679/33250 (epoch 34.104), train_loss = 0.61111158, grad/param norm = 1.3734e-01, time/batch = 15.5455s	
22680/33250 (epoch 34.105), train_loss = 0.75869215, grad/param norm = 1.8022e-01, time/batch = 16.1051s	
22681/33250 (epoch 34.107), train_loss = 0.68556983, grad/param norm = 1.3144e-01, time/batch = 17.0383s	
22682/33250 (epoch 34.108), train_loss = 0.81800782, grad/param norm = 1.6993e-01, time/batch = 16.7624s	
22683/33250 (epoch 34.110), train_loss = 0.69163302, grad/param norm = 1.5578e-01, time/batch = 17.9494s	
22684/33250 (epoch 34.111), train_loss = 0.80363098, grad/param norm = 1.6046e-01, time/batch = 16.6079s	
22685/33250 (epoch 34.113), train_loss = 0.74283665, grad/param norm = 1.6996e-01, time/batch = 17.5212s	
22686/33250 (epoch 34.114), train_loss = 0.70262124, grad/param norm = 1.7892e-01, time/batch = 16.6769s	
22687/33250 (epoch 34.116), train_loss = 0.74529472, grad/param norm = 1.7113e-01, time/batch = 16.4356s	
22688/33250 (epoch 34.117), train_loss = 0.75571702, grad/param norm = 1.7615e-01, time/batch = 16.3531s	
22689/33250 (epoch 34.119), train_loss = 0.77416954, grad/param norm = 1.6615e-01, time/batch = 16.1830s	
22690/33250 (epoch 34.120), train_loss = 0.63905548, grad/param norm = 1.4747e-01, time/batch = 17.6154s	
22691/33250 (epoch 34.122), train_loss = 0.88798183, grad/param norm = 1.7698e-01, time/batch = 16.7039s	
22692/33250 (epoch 34.123), train_loss = 0.79802133, grad/param norm = 1.9371e-01, time/batch = 18.1304s	
22693/33250 (epoch 34.125), train_loss = 0.64911243, grad/param norm = 1.6379e-01, time/batch = 16.2714s	
22694/33250 (epoch 34.126), train_loss = 0.78278494, grad/param norm = 1.7670e-01, time/batch = 17.1886s	
22695/33250 (epoch 34.128), train_loss = 0.74583817, grad/param norm = 1.5230e-01, time/batch = 15.5965s	
22696/33250 (epoch 34.129), train_loss = 0.78670588, grad/param norm = 1.5445e-01, time/batch = 17.1780s	
22697/33250 (epoch 34.131), train_loss = 0.79365158, grad/param norm = 1.8051e-01, time/batch = 16.6145s	
22698/33250 (epoch 34.132), train_loss = 0.77668142, grad/param norm = 1.8185e-01, time/batch = 16.5083s	
22699/33250 (epoch 34.134), train_loss = 0.75310044, grad/param norm = 1.7636e-01, time/batch = 18.8462s	
22700/33250 (epoch 34.135), train_loss = 0.79130110, grad/param norm = 1.3969e-01, time/batch = 16.5047s	
22701/33250 (epoch 34.137), train_loss = 0.71688996, grad/param norm = 1.6310e-01, time/batch = 17.6970s	
22702/33250 (epoch 34.138), train_loss = 0.72656705, grad/param norm = 1.5639e-01, time/batch = 17.8590s	
22703/33250 (epoch 34.140), train_loss = 0.62560660, grad/param norm = 1.4686e-01, time/batch = 16.3498s	
22704/33250 (epoch 34.141), train_loss = 0.91522382, grad/param norm = 2.6018e-01, time/batch = 18.3339s	
22705/33250 (epoch 34.143), train_loss = 0.65673119, grad/param norm = 2.0285e-01, time/batch = 17.6771s	
22706/33250 (epoch 34.144), train_loss = 0.75020026, grad/param norm = 1.7175e-01, time/batch = 18.2587s	
22707/33250 (epoch 34.146), train_loss = 0.76356134, grad/param norm = 1.5202e-01, time/batch = 15.7678s	
22708/33250 (epoch 34.147), train_loss = 0.78675710, grad/param norm = 1.6819e-01, time/batch = 16.1023s	
22709/33250 (epoch 34.149), train_loss = 0.72632066, grad/param norm = 1.4916e-01, time/batch = 17.8772s	
22710/33250 (epoch 34.150), train_loss = 0.69790708, grad/param norm = 1.5569e-01, time/batch = 17.7096s	
22711/33250 (epoch 34.152), train_loss = 0.68483066, grad/param norm = 1.7389e-01, time/batch = 17.1938s	
22712/33250 (epoch 34.153), train_loss = 0.92824732, grad/param norm = 1.8530e-01, time/batch = 17.0108s	
22713/33250 (epoch 34.155), train_loss = 0.76987739, grad/param norm = 2.2263e-01, time/batch = 17.1600s	
22714/33250 (epoch 34.156), train_loss = 0.98979072, grad/param norm = 1.7433e-01, time/batch = 17.5319s	
22715/33250 (epoch 34.158), train_loss = 0.92315619, grad/param norm = 1.9780e-01, time/batch = 17.5910s	
22716/33250 (epoch 34.159), train_loss = 0.76121823, grad/param norm = 2.2074e-01, time/batch = 18.1022s	
22717/33250 (epoch 34.161), train_loss = 0.82927631, grad/param norm = 1.9431e-01, time/batch = 16.6748s	
22718/33250 (epoch 34.162), train_loss = 0.71991366, grad/param norm = 1.4787e-01, time/batch = 15.9360s	
22719/33250 (epoch 34.164), train_loss = 0.78846144, grad/param norm = 1.9336e-01, time/batch = 18.9368s	
22720/33250 (epoch 34.165), train_loss = 0.85686440, grad/param norm = 1.7932e-01, time/batch = 16.2106s	
22721/33250 (epoch 34.167), train_loss = 0.95252400, grad/param norm = 2.0742e-01, time/batch = 18.2939s	
22722/33250 (epoch 34.168), train_loss = 0.69223791, grad/param norm = 1.6077e-01, time/batch = 18.9336s	
22723/33250 (epoch 34.170), train_loss = 0.74779744, grad/param norm = 1.5463e-01, time/batch = 17.6826s	
22724/33250 (epoch 34.171), train_loss = 0.81974797, grad/param norm = 1.7310e-01, time/batch = 30.9720s	
22725/33250 (epoch 34.173), train_loss = 0.77589862, grad/param norm = 1.5969e-01, time/batch = 16.2672s	
22726/33250 (epoch 34.174), train_loss = 0.80949159, grad/param norm = 1.6328e-01, time/batch = 17.2601s	
22727/33250 (epoch 34.176), train_loss = 0.74362897, grad/param norm = 1.6772e-01, time/batch = 16.9382s	
22728/33250 (epoch 34.177), train_loss = 0.75385236, grad/param norm = 1.6778e-01, time/batch = 17.5256s	
22729/33250 (epoch 34.179), train_loss = 0.73012186, grad/param norm = 1.5097e-01, time/batch = 16.8792s	
22730/33250 (epoch 34.180), train_loss = 0.64206369, grad/param norm = 1.4121e-01, time/batch = 15.4365s	
22731/33250 (epoch 34.182), train_loss = 0.73120669, grad/param norm = 1.8987e-01, time/batch = 18.2369s	
22732/33250 (epoch 34.183), train_loss = 0.90572874, grad/param norm = 2.0049e-01, time/batch = 16.9252s	
22733/33250 (epoch 34.185), train_loss = 0.81549844, grad/param norm = 2.2463e-01, time/batch = 18.0097s	
22734/33250 (epoch 34.186), train_loss = 0.83941865, grad/param norm = 1.9120e-01, time/batch = 15.4232s	
22735/33250 (epoch 34.188), train_loss = 0.88362538, grad/param norm = 2.0254e-01, time/batch = 17.5860s	
22736/33250 (epoch 34.189), train_loss = 0.65390832, grad/param norm = 1.9425e-01, time/batch = 16.5096s	
22737/33250 (epoch 34.191), train_loss = 0.75307880, grad/param norm = 1.8884e-01, time/batch = 16.4995s	
22738/33250 (epoch 34.192), train_loss = 0.76415403, grad/param norm = 1.5527e-01, time/batch = 18.1243s	
22739/33250 (epoch 34.194), train_loss = 0.77876573, grad/param norm = 1.8442e-01, time/batch = 19.0402s	
22740/33250 (epoch 34.195), train_loss = 0.98079666, grad/param norm = 1.8005e-01, time/batch = 17.2883s	
22741/33250 (epoch 34.197), train_loss = 0.74070372, grad/param norm = 1.5069e-01, time/batch = 15.6476s	
22742/33250 (epoch 34.198), train_loss = 0.93831089, grad/param norm = 1.8172e-01, time/batch = 16.5162s	
22743/33250 (epoch 34.200), train_loss = 0.81193036, grad/param norm = 1.8146e-01, time/batch = 18.6918s	
22744/33250 (epoch 34.202), train_loss = 0.75381902, grad/param norm = 1.5255e-01, time/batch = 15.7710s	
22745/33250 (epoch 34.203), train_loss = 0.72752460, grad/param norm = 1.7438e-01, time/batch = 16.6842s	
22746/33250 (epoch 34.205), train_loss = 0.81991810, grad/param norm = 1.7025e-01, time/batch = 15.9528s	
22747/33250 (epoch 34.206), train_loss = 0.87618725, grad/param norm = 1.7324e-01, time/batch = 17.0065s	
22748/33250 (epoch 34.208), train_loss = 0.92614732, grad/param norm = 2.1961e-01, time/batch = 14.6563s	
22749/33250 (epoch 34.209), train_loss = 0.75769873, grad/param norm = 1.6054e-01, time/batch = 17.7992s	
22750/33250 (epoch 34.211), train_loss = 0.86267187, grad/param norm = 1.9953e-01, time/batch = 17.9572s	
22751/33250 (epoch 34.212), train_loss = 0.94724174, grad/param norm = 1.6972e-01, time/batch = 15.4261s	
22752/33250 (epoch 34.214), train_loss = 0.82826365, grad/param norm = 1.6151e-01, time/batch = 15.4575s	
22753/33250 (epoch 34.215), train_loss = 0.87854400, grad/param norm = 2.0790e-01, time/batch = 16.2003s	
22754/33250 (epoch 34.217), train_loss = 0.89910601, grad/param norm = 1.8901e-01, time/batch = 16.7578s	
22755/33250 (epoch 34.218), train_loss = 0.88324464, grad/param norm = 1.6277e-01, time/batch = 15.1712s	
22756/33250 (epoch 34.220), train_loss = 0.81890906, grad/param norm = 1.7494e-01, time/batch = 19.2493s	
22757/33250 (epoch 34.221), train_loss = 0.95161773, grad/param norm = 2.2715e-01, time/batch = 17.6909s	
22758/33250 (epoch 34.223), train_loss = 0.81115875, grad/param norm = 1.6221e-01, time/batch = 18.0336s	
22759/33250 (epoch 34.224), train_loss = 0.87689338, grad/param norm = 1.9100e-01, time/batch = 17.2103s	
22760/33250 (epoch 34.226), train_loss = 0.94458695, grad/param norm = 1.8922e-01, time/batch = 17.7000s	
22761/33250 (epoch 34.227), train_loss = 0.83938803, grad/param norm = 1.7806e-01, time/batch = 17.4429s	
22762/33250 (epoch 34.229), train_loss = 0.81647857, grad/param norm = 1.8903e-01, time/batch = 16.3507s	
22763/33250 (epoch 34.230), train_loss = 0.82847509, grad/param norm = 1.8910e-01, time/batch = 18.3375s	
22764/33250 (epoch 34.232), train_loss = 0.76555609, grad/param norm = 1.5493e-01, time/batch = 16.1847s	
22765/33250 (epoch 34.233), train_loss = 0.71590208, grad/param norm = 1.4764e-01, time/batch = 16.1755s	
22766/33250 (epoch 34.235), train_loss = 0.93660358, grad/param norm = 1.7069e-01, time/batch = 15.6036s	
22767/33250 (epoch 34.236), train_loss = 0.75531081, grad/param norm = 1.6325e-01, time/batch = 18.1922s	
22768/33250 (epoch 34.238), train_loss = 0.91788856, grad/param norm = 1.8877e-01, time/batch = 18.6968s	
22769/33250 (epoch 34.239), train_loss = 0.91660608, grad/param norm = 2.2048e-01, time/batch = 16.7036s	
22770/33250 (epoch 34.241), train_loss = 0.92524125, grad/param norm = 2.0455e-01, time/batch = 18.6226s	
22771/33250 (epoch 34.242), train_loss = 0.92096462, grad/param norm = 2.2827e-01, time/batch = 16.7602s	
22772/33250 (epoch 34.244), train_loss = 0.87059014, grad/param norm = 2.0411e-01, time/batch = 15.8240s	
22773/33250 (epoch 34.245), train_loss = 0.85841880, grad/param norm = 1.7784e-01, time/batch = 16.9403s	
22774/33250 (epoch 34.247), train_loss = 0.81611886, grad/param norm = 2.0401e-01, time/batch = 17.6844s	
22775/33250 (epoch 34.248), train_loss = 0.97661416, grad/param norm = 1.9164e-01, time/batch = 18.1620s	
22776/33250 (epoch 34.250), train_loss = 0.92725851, grad/param norm = 1.6329e-01, time/batch = 16.2729s	
22777/33250 (epoch 34.251), train_loss = 0.79968426, grad/param norm = 1.5786e-01, time/batch = 16.2528s	
22778/33250 (epoch 34.253), train_loss = 0.77843705, grad/param norm = 1.5013e-01, time/batch = 18.2280s	
22779/33250 (epoch 34.254), train_loss = 0.75725187, grad/param norm = 1.7513e-01, time/batch = 17.2920s	
22780/33250 (epoch 34.256), train_loss = 0.80873122, grad/param norm = 1.6189e-01, time/batch = 17.6208s	
22781/33250 (epoch 34.257), train_loss = 0.96148905, grad/param norm = 1.7913e-01, time/batch = 17.6661s	
22782/33250 (epoch 34.259), train_loss = 0.87230070, grad/param norm = 1.8656e-01, time/batch = 17.5758s	
22783/33250 (epoch 34.260), train_loss = 0.68885780, grad/param norm = 1.6526e-01, time/batch = 16.4120s	
22784/33250 (epoch 34.262), train_loss = 0.82267125, grad/param norm = 1.6789e-01, time/batch = 16.6029s	
22785/33250 (epoch 34.263), train_loss = 0.69219540, grad/param norm = 1.5410e-01, time/batch = 15.1875s	
22786/33250 (epoch 34.265), train_loss = 0.85525884, grad/param norm = 1.7377e-01, time/batch = 16.0225s	
22787/33250 (epoch 34.266), train_loss = 0.79612141, grad/param norm = 1.8204e-01, time/batch = 18.9348s	
22788/33250 (epoch 34.268), train_loss = 0.72823580, grad/param norm = 1.6874e-01, time/batch = 18.4563s	
22789/33250 (epoch 34.269), train_loss = 0.67834866, grad/param norm = 1.4381e-01, time/batch = 18.1110s	
22790/33250 (epoch 34.271), train_loss = 0.82133380, grad/param norm = 1.5730e-01, time/batch = 17.3687s	
22791/33250 (epoch 34.272), train_loss = 0.73107516, grad/param norm = 1.4327e-01, time/batch = 17.9288s	
22792/33250 (epoch 34.274), train_loss = 0.61051303, grad/param norm = 1.4569e-01, time/batch = 15.3561s	
22793/33250 (epoch 34.275), train_loss = 0.76885577, grad/param norm = 1.5541e-01, time/batch = 16.1657s	
22794/33250 (epoch 34.277), train_loss = 0.64226806, grad/param norm = 1.7579e-01, time/batch = 16.6943s	
22795/33250 (epoch 34.278), train_loss = 0.75261857, grad/param norm = 1.6608e-01, time/batch = 17.4338s	
22796/33250 (epoch 34.280), train_loss = 0.70825727, grad/param norm = 1.4187e-01, time/batch = 17.4282s	
22797/33250 (epoch 34.281), train_loss = 0.83194972, grad/param norm = 1.8021e-01, time/batch = 18.8708s	
22798/33250 (epoch 34.283), train_loss = 0.86231480, grad/param norm = 2.6463e-01, time/batch = 17.1191s	
22799/33250 (epoch 34.284), train_loss = 0.70514842, grad/param norm = 1.8547e-01, time/batch = 16.4513s	
22800/33250 (epoch 34.286), train_loss = 0.85485379, grad/param norm = 1.7683e-01, time/batch = 16.7509s	
22801/33250 (epoch 34.287), train_loss = 0.67023489, grad/param norm = 1.5462e-01, time/batch = 18.8450s	
22802/33250 (epoch 34.289), train_loss = 0.65723434, grad/param norm = 1.7417e-01, time/batch = 17.5101s	
22803/33250 (epoch 34.290), train_loss = 0.81751670, grad/param norm = 1.5813e-01, time/batch = 15.6688s	
22804/33250 (epoch 34.292), train_loss = 0.87443324, grad/param norm = 2.5394e-01, time/batch = 16.6877s	
22805/33250 (epoch 34.293), train_loss = 0.91218491, grad/param norm = 1.9138e-01, time/batch = 16.9379s	
22806/33250 (epoch 34.295), train_loss = 0.91454591, grad/param norm = 1.7112e-01, time/batch = 17.6801s	
22807/33250 (epoch 34.296), train_loss = 0.81329269, grad/param norm = 1.7350e-01, time/batch = 17.1210s	
22808/33250 (epoch 34.298), train_loss = 0.66197843, grad/param norm = 1.6169e-01, time/batch = 18.1974s	
22809/33250 (epoch 34.299), train_loss = 0.64811123, grad/param norm = 1.4521e-01, time/batch = 16.8802s	
22810/33250 (epoch 34.301), train_loss = 0.90331393, grad/param norm = 1.8285e-01, time/batch = 17.6118s	
22811/33250 (epoch 34.302), train_loss = 0.86266877, grad/param norm = 1.8211e-01, time/batch = 16.6072s	
22812/33250 (epoch 34.304), train_loss = 0.75916252, grad/param norm = 1.6644e-01, time/batch = 15.2905s	
22813/33250 (epoch 34.305), train_loss = 0.74196177, grad/param norm = 1.5328e-01, time/batch = 15.5947s	
22814/33250 (epoch 34.307), train_loss = 0.85621410, grad/param norm = 1.8235e-01, time/batch = 16.6898s	
22815/33250 (epoch 34.308), train_loss = 0.90238599, grad/param norm = 1.9733e-01, time/batch = 17.6078s	
22816/33250 (epoch 34.310), train_loss = 0.76390573, grad/param norm = 1.9363e-01, time/batch = 16.5151s	
22817/33250 (epoch 34.311), train_loss = 0.94869165, grad/param norm = 1.9290e-01, time/batch = 17.6702s	
22818/33250 (epoch 34.313), train_loss = 0.67512183, grad/param norm = 1.7854e-01, time/batch = 17.1297s	
22819/33250 (epoch 34.314), train_loss = 0.83272477, grad/param norm = 1.6649e-01, time/batch = 19.6196s	
22820/33250 (epoch 34.316), train_loss = 0.97226540, grad/param norm = 1.9529e-01, time/batch = 19.3347s	
22821/33250 (epoch 34.317), train_loss = 0.71558643, grad/param norm = 1.5053e-01, time/batch = 17.0302s	
22822/33250 (epoch 34.319), train_loss = 0.86487198, grad/param norm = 1.9823e-01, time/batch = 17.1130s	
22823/33250 (epoch 34.320), train_loss = 0.89500848, grad/param norm = 2.2894e-01, time/batch = 15.7902s	
22824/33250 (epoch 34.322), train_loss = 0.95864120, grad/param norm = 2.0049e-01, time/batch = 15.6561s	
22825/33250 (epoch 34.323), train_loss = 0.95675250, grad/param norm = 2.2352e-01, time/batch = 16.5286s	
22826/33250 (epoch 34.325), train_loss = 0.77690253, grad/param norm = 1.8353e-01, time/batch = 16.8159s	
22827/33250 (epoch 34.326), train_loss = 1.01044176, grad/param norm = 1.9409e-01, time/batch = 18.6671s	
22828/33250 (epoch 34.328), train_loss = 0.80534220, grad/param norm = 1.7905e-01, time/batch = 17.3447s	
22829/33250 (epoch 34.329), train_loss = 0.82597921, grad/param norm = 2.7252e-01, time/batch = 16.7075s	
22830/33250 (epoch 34.331), train_loss = 0.83489203, grad/param norm = 2.4228e-01, time/batch = 14.7984s	
22831/33250 (epoch 34.332), train_loss = 0.81189181, grad/param norm = 1.6795e-01, time/batch = 14.8563s	
22832/33250 (epoch 34.334), train_loss = 0.96680187, grad/param norm = 1.7647e-01, time/batch = 15.3245s	
22833/33250 (epoch 34.335), train_loss = 0.60771040, grad/param norm = 1.5476e-01, time/batch = 16.0274s	
22834/33250 (epoch 34.337), train_loss = 0.87389649, grad/param norm = 1.6379e-01, time/batch = 15.9970s	
22835/33250 (epoch 34.338), train_loss = 0.95457637, grad/param norm = 1.8622e-01, time/batch = 15.1961s	
22836/33250 (epoch 34.340), train_loss = 0.79729087, grad/param norm = 1.9274e-01, time/batch = 16.0882s	
22837/33250 (epoch 34.341), train_loss = 0.76574735, grad/param norm = 2.0048e-01, time/batch = 17.6229s	
22838/33250 (epoch 34.343), train_loss = 0.79045968, grad/param norm = 1.8416e-01, time/batch = 16.4607s	
22839/33250 (epoch 34.344), train_loss = 0.81521948, grad/param norm = 1.7199e-01, time/batch = 15.6123s	
22840/33250 (epoch 34.346), train_loss = 0.69746570, grad/param norm = 1.6025e-01, time/batch = 18.5085s	
22841/33250 (epoch 34.347), train_loss = 0.99388978, grad/param norm = 2.3232e-01, time/batch = 18.4964s	
22842/33250 (epoch 34.349), train_loss = 0.77972062, grad/param norm = 1.7883e-01, time/batch = 16.1781s	
22843/33250 (epoch 34.350), train_loss = 0.80489357, grad/param norm = 1.6122e-01, time/batch = 16.0955s	
22844/33250 (epoch 34.352), train_loss = 0.75401961, grad/param norm = 2.0323e-01, time/batch = 16.0281s	
22845/33250 (epoch 34.353), train_loss = 0.78713638, grad/param norm = 1.5358e-01, time/batch = 17.6141s	
22846/33250 (epoch 34.355), train_loss = 0.75221872, grad/param norm = 1.7880e-01, time/batch = 15.0789s	
22847/33250 (epoch 34.356), train_loss = 0.71810295, grad/param norm = 1.7573e-01, time/batch = 16.3644s	
22848/33250 (epoch 34.358), train_loss = 0.78659113, grad/param norm = 1.5386e-01, time/batch = 16.1447s	
22849/33250 (epoch 34.359), train_loss = 0.77829840, grad/param norm = 1.6018e-01, time/batch = 16.7814s	
22850/33250 (epoch 34.361), train_loss = 0.92376992, grad/param norm = 2.1453e-01, time/batch = 17.4415s	
22851/33250 (epoch 34.362), train_loss = 0.83635235, grad/param norm = 1.5684e-01, time/batch = 16.5245s	
22852/33250 (epoch 34.364), train_loss = 0.86072596, grad/param norm = 1.9115e-01, time/batch = 16.6051s	
22853/33250 (epoch 34.365), train_loss = 0.80516457, grad/param norm = 1.5939e-01, time/batch = 16.7661s	
22854/33250 (epoch 34.367), train_loss = 0.81398865, grad/param norm = 1.4919e-01, time/batch = 16.3393s	
22855/33250 (epoch 34.368), train_loss = 0.80602250, grad/param norm = 1.8334e-01, time/batch = 16.3604s	
22856/33250 (epoch 34.370), train_loss = 0.72762266, grad/param norm = 1.4303e-01, time/batch = 15.5342s	
22857/33250 (epoch 34.371), train_loss = 0.91541642, grad/param norm = 1.8173e-01, time/batch = 16.2765s	
22858/33250 (epoch 34.373), train_loss = 0.77704093, grad/param norm = 1.5110e-01, time/batch = 15.9531s	
22859/33250 (epoch 34.374), train_loss = 0.82784200, grad/param norm = 2.1714e-01, time/batch = 19.1962s	
22860/33250 (epoch 34.376), train_loss = 0.79779999, grad/param norm = 1.6617e-01, time/batch = 17.0527s	
22861/33250 (epoch 34.377), train_loss = 0.72010805, grad/param norm = 2.0590e-01, time/batch = 18.0961s	
22862/33250 (epoch 34.379), train_loss = 0.80857221, grad/param norm = 1.6786e-01, time/batch = 16.0252s	
22863/33250 (epoch 34.380), train_loss = 0.82860763, grad/param norm = 2.0675e-01, time/batch = 18.9250s	
22864/33250 (epoch 34.382), train_loss = 0.83780050, grad/param norm = 2.1443e-01, time/batch = 17.7413s	
22865/33250 (epoch 34.383), train_loss = 0.71964472, grad/param norm = 1.7486e-01, time/batch = 16.0406s	
22866/33250 (epoch 34.385), train_loss = 0.70507181, grad/param norm = 2.0126e-01, time/batch = 17.6788s	
22867/33250 (epoch 34.386), train_loss = 0.72829880, grad/param norm = 1.8450e-01, time/batch = 17.3600s	
22868/33250 (epoch 34.388), train_loss = 0.74266133, grad/param norm = 1.6330e-01, time/batch = 17.8015s	
22869/33250 (epoch 34.389), train_loss = 0.77017604, grad/param norm = 1.9059e-01, time/batch = 16.2298s	
22870/33250 (epoch 34.391), train_loss = 0.85316174, grad/param norm = 2.1161e-01, time/batch = 17.3537s	
22871/33250 (epoch 34.392), train_loss = 0.91251507, grad/param norm = 1.8927e-01, time/batch = 15.6945s	
22872/33250 (epoch 34.394), train_loss = 0.89551522, grad/param norm = 1.9833e-01, time/batch = 17.2673s	
22873/33250 (epoch 34.395), train_loss = 0.89558474, grad/param norm = 1.8415e-01, time/batch = 17.0173s	
22874/33250 (epoch 34.397), train_loss = 0.91279916, grad/param norm = 1.8335e-01, time/batch = 15.7044s	
22875/33250 (epoch 34.398), train_loss = 0.73047883, grad/param norm = 1.5891e-01, time/batch = 16.4517s	
22876/33250 (epoch 34.400), train_loss = 0.71525104, grad/param norm = 1.4932e-01, time/batch = 15.2806s	
22877/33250 (epoch 34.402), train_loss = 0.68975607, grad/param norm = 1.7026e-01, time/batch = 15.6832s	
22878/33250 (epoch 34.403), train_loss = 0.78758000, grad/param norm = 1.9935e-01, time/batch = 15.5911s	
22879/33250 (epoch 34.405), train_loss = 0.74319183, grad/param norm = 1.3752e-01, time/batch = 16.0344s	
22880/33250 (epoch 34.406), train_loss = 0.78460551, grad/param norm = 1.9737e-01, time/batch = 17.7208s	
22881/33250 (epoch 34.408), train_loss = 0.95100563, grad/param norm = 1.7326e-01, time/batch = 17.5184s	
22882/33250 (epoch 34.409), train_loss = 0.86306020, grad/param norm = 2.1613e-01, time/batch = 17.5849s	
22883/33250 (epoch 34.411), train_loss = 0.59034346, grad/param norm = 1.2411e-01, time/batch = 15.6341s	
22884/33250 (epoch 34.412), train_loss = 0.68968281, grad/param norm = 1.8255e-01, time/batch = 16.2691s	
22885/33250 (epoch 34.414), train_loss = 0.83912014, grad/param norm = 1.5829e-01, time/batch = 16.8292s	
22886/33250 (epoch 34.415), train_loss = 0.87275362, grad/param norm = 2.2014e-01, time/batch = 16.9269s	
22887/33250 (epoch 34.417), train_loss = 0.91464563, grad/param norm = 1.7422e-01, time/batch = 17.5271s	
22888/33250 (epoch 34.418), train_loss = 1.06979788, grad/param norm = 2.2041e-01, time/batch = 17.6034s	
22889/33250 (epoch 34.420), train_loss = 0.88635561, grad/param norm = 1.8543e-01, time/batch = 17.1192s	
22890/33250 (epoch 34.421), train_loss = 0.76260791, grad/param norm = 1.5910e-01, time/batch = 17.2891s	
22891/33250 (epoch 34.423), train_loss = 0.84060922, grad/param norm = 1.7413e-01, time/batch = 18.0283s	
22892/33250 (epoch 34.424), train_loss = 0.95747289, grad/param norm = 2.7133e-01, time/batch = 16.6742s	
22893/33250 (epoch 34.426), train_loss = 0.77636506, grad/param norm = 1.6395e-01, time/batch = 17.1034s	
22894/33250 (epoch 34.427), train_loss = 0.76120217, grad/param norm = 1.9843e-01, time/batch = 15.8674s	
22895/33250 (epoch 34.429), train_loss = 0.85089426, grad/param norm = 1.8586e-01, time/batch = 16.0110s	
22896/33250 (epoch 34.430), train_loss = 0.77130818, grad/param norm = 2.0719e-01, time/batch = 15.5873s	
22897/33250 (epoch 34.432), train_loss = 0.87377504, grad/param norm = 1.7138e-01, time/batch = 16.0253s	
22898/33250 (epoch 34.433), train_loss = 0.74974962, grad/param norm = 1.7754e-01, time/batch = 18.1297s	
22899/33250 (epoch 34.435), train_loss = 0.89804540, grad/param norm = 1.6848e-01, time/batch = 17.6025s	
22900/33250 (epoch 34.436), train_loss = 0.76215979, grad/param norm = 1.8370e-01, time/batch = 18.3771s	
22901/33250 (epoch 34.438), train_loss = 0.91046655, grad/param norm = 1.6842e-01, time/batch = 17.1628s	
22902/33250 (epoch 34.439), train_loss = 0.83078163, grad/param norm = 1.6065e-01, time/batch = 15.1755s	
22903/33250 (epoch 34.441), train_loss = 0.78897650, grad/param norm = 1.5393e-01, time/batch = 15.4392s	
22904/33250 (epoch 34.442), train_loss = 0.73990164, grad/param norm = 1.7254e-01, time/batch = 15.5366s	
22905/33250 (epoch 34.444), train_loss = 0.76751285, grad/param norm = 1.5874e-01, time/batch = 14.9473s	
22906/33250 (epoch 34.445), train_loss = 0.82977337, grad/param norm = 1.4380e-01, time/batch = 15.6685s	
22907/33250 (epoch 34.447), train_loss = 0.74296675, grad/param norm = 1.7319e-01, time/batch = 17.0844s	
22908/33250 (epoch 34.448), train_loss = 0.83710925, grad/param norm = 1.5865e-01, time/batch = 18.1832s	
22909/33250 (epoch 34.450), train_loss = 0.93583191, grad/param norm = 1.9622e-01, time/batch = 14.7745s	
22910/33250 (epoch 34.451), train_loss = 0.86217104, grad/param norm = 1.9295e-01, time/batch = 14.9572s	
22911/33250 (epoch 34.453), train_loss = 0.71619232, grad/param norm = 1.4079e-01, time/batch = 14.7801s	
22912/33250 (epoch 34.454), train_loss = 0.95178418, grad/param norm = 1.8143e-01, time/batch = 15.5890s	
22913/33250 (epoch 34.456), train_loss = 0.92426326, grad/param norm = 1.5170e-01, time/batch = 15.4302s	
22914/33250 (epoch 34.457), train_loss = 0.75741883, grad/param norm = 1.8104e-01, time/batch = 16.1852s	
22915/33250 (epoch 34.459), train_loss = 0.86547036, grad/param norm = 1.7932e-01, time/batch = 16.4246s	
22916/33250 (epoch 34.460), train_loss = 0.87813116, grad/param norm = 1.7202e-01, time/batch = 17.6746s	
22917/33250 (epoch 34.462), train_loss = 0.79960432, grad/param norm = 1.6435e-01, time/batch = 17.6767s	
22918/33250 (epoch 34.463), train_loss = 0.73236975, grad/param norm = 1.3413e-01, time/batch = 16.5962s	
22919/33250 (epoch 34.465), train_loss = 0.66667019, grad/param norm = 1.3770e-01, time/batch = 18.4608s	
22920/33250 (epoch 34.466), train_loss = 0.66310960, grad/param norm = 1.3421e-01, time/batch = 18.0494s	
22921/33250 (epoch 34.468), train_loss = 0.70068538, grad/param norm = 1.4783e-01, time/batch = 17.8461s	
22922/33250 (epoch 34.469), train_loss = 0.77968399, grad/param norm = 1.6194e-01, time/batch = 16.8577s	
22923/33250 (epoch 34.471), train_loss = 0.86228719, grad/param norm = 1.5344e-01, time/batch = 18.0069s	
22924/33250 (epoch 34.472), train_loss = 0.76829675, grad/param norm = 2.0460e-01, time/batch = 15.3472s	
22925/33250 (epoch 34.474), train_loss = 0.91918979, grad/param norm = 1.9146e-01, time/batch = 15.5245s	
22926/33250 (epoch 34.475), train_loss = 0.83679185, grad/param norm = 1.6620e-01, time/batch = 17.8497s	
22927/33250 (epoch 34.477), train_loss = 0.83432083, grad/param norm = 1.7517e-01, time/batch = 17.0299s	
22928/33250 (epoch 34.478), train_loss = 0.73732038, grad/param norm = 1.8218e-01, time/batch = 16.6211s	
22929/33250 (epoch 34.480), train_loss = 0.91707242, grad/param norm = 1.6757e-01, time/batch = 14.9007s	
22930/33250 (epoch 34.481), train_loss = 0.80164993, grad/param norm = 1.5784e-01, time/batch = 17.6999s	
22931/33250 (epoch 34.483), train_loss = 0.79376717, grad/param norm = 1.7982e-01, time/batch = 16.2562s	
22932/33250 (epoch 34.484), train_loss = 0.72418025, grad/param norm = 1.4433e-01, time/batch = 16.9347s	
22933/33250 (epoch 34.486), train_loss = 0.69286851, grad/param norm = 1.7804e-01, time/batch = 15.7589s	
22934/33250 (epoch 34.487), train_loss = 0.77131185, grad/param norm = 1.7153e-01, time/batch = 17.9201s	
22935/33250 (epoch 34.489), train_loss = 0.89293505, grad/param norm = 1.8006e-01, time/batch = 22.5128s	
22936/33250 (epoch 34.490), train_loss = 0.85371621, grad/param norm = 2.0151e-01, time/batch = 23.9072s	
22937/33250 (epoch 34.492), train_loss = 0.89783488, grad/param norm = 1.9085e-01, time/batch = 17.5126s	
22938/33250 (epoch 34.493), train_loss = 0.82787051, grad/param norm = 1.7522e-01, time/batch = 18.0257s	
22939/33250 (epoch 34.495), train_loss = 0.86045422, grad/param norm = 1.4327e-01, time/batch = 17.6967s	
22940/33250 (epoch 34.496), train_loss = 0.81417875, grad/param norm = 1.4300e-01, time/batch = 17.4543s	
22941/33250 (epoch 34.498), train_loss = 0.88779803, grad/param norm = 1.8614e-01, time/batch = 17.6047s	
22942/33250 (epoch 34.499), train_loss = 0.76310012, grad/param norm = 1.5182e-01, time/batch = 16.4948s	
22943/33250 (epoch 34.501), train_loss = 0.77161258, grad/param norm = 1.8075e-01, time/batch = 15.9506s	
22944/33250 (epoch 34.502), train_loss = 0.76711158, grad/param norm = 1.4613e-01, time/batch = 16.4263s	
22945/33250 (epoch 34.504), train_loss = 0.94967053, grad/param norm = 1.9677e-01, time/batch = 15.5780s	
22946/33250 (epoch 34.505), train_loss = 0.68778053, grad/param norm = 1.3490e-01, time/batch = 15.5188s	
22947/33250 (epoch 34.507), train_loss = 0.74412800, grad/param norm = 1.7275e-01, time/batch = 16.9398s	
22948/33250 (epoch 34.508), train_loss = 0.75945467, grad/param norm = 1.4587e-01, time/batch = 18.7768s	
22949/33250 (epoch 34.510), train_loss = 0.67027400, grad/param norm = 1.2827e-01, time/batch = 18.0287s	
22950/33250 (epoch 34.511), train_loss = 0.78804052, grad/param norm = 1.9109e-01, time/batch = 19.1201s	
22951/33250 (epoch 34.513), train_loss = 0.91308093, grad/param norm = 1.7404e-01, time/batch = 16.6149s	
22952/33250 (epoch 34.514), train_loss = 0.79009914, grad/param norm = 1.7527e-01, time/batch = 15.3518s	
22953/33250 (epoch 34.516), train_loss = 0.74508572, grad/param norm = 1.6526e-01, time/batch = 17.0043s	
22954/33250 (epoch 34.517), train_loss = 0.78558321, grad/param norm = 1.7257e-01, time/batch = 16.2779s	
22955/33250 (epoch 34.519), train_loss = 0.70816230, grad/param norm = 1.2229e-01, time/batch = 16.7492s	
22956/33250 (epoch 34.520), train_loss = 0.99148496, grad/param norm = 1.9278e-01, time/batch = 15.4096s	
22957/33250 (epoch 34.522), train_loss = 0.85119215, grad/param norm = 1.6799e-01, time/batch = 15.6371s	
22958/33250 (epoch 34.523), train_loss = 0.74211078, grad/param norm = 1.7982e-01, time/batch = 15.2882s	
22959/33250 (epoch 34.525), train_loss = 0.68821844, grad/param norm = 1.6553e-01, time/batch = 15.1976s	
22960/33250 (epoch 34.526), train_loss = 0.71475343, grad/param norm = 1.5006e-01, time/batch = 15.3809s	
22961/33250 (epoch 34.528), train_loss = 0.77530307, grad/param norm = 1.7008e-01, time/batch = 15.2243s	
22962/33250 (epoch 34.529), train_loss = 0.75526305, grad/param norm = 1.6153e-01, time/batch = 15.6669s	
22963/33250 (epoch 34.531), train_loss = 0.72496414, grad/param norm = 1.4859e-01, time/batch = 15.7593s	
22964/33250 (epoch 34.532), train_loss = 0.84511598, grad/param norm = 1.5117e-01, time/batch = 15.6637s	
22965/33250 (epoch 34.534), train_loss = 0.73035001, grad/param norm = 1.5318e-01, time/batch = 15.6180s	
22966/33250 (epoch 34.535), train_loss = 0.77532657, grad/param norm = 1.4752e-01, time/batch = 16.8628s	
22967/33250 (epoch 34.537), train_loss = 0.81053419, grad/param norm = 1.6091e-01, time/batch = 15.8366s	
22968/33250 (epoch 34.538), train_loss = 0.85728181, grad/param norm = 1.8504e-01, time/batch = 15.4492s	
22969/33250 (epoch 34.540), train_loss = 0.94474727, grad/param norm = 1.5131e-01, time/batch = 17.8518s	
22970/33250 (epoch 34.541), train_loss = 0.86714206, grad/param norm = 1.9562e-01, time/batch = 19.2546s	
22971/33250 (epoch 34.543), train_loss = 0.85380781, grad/param norm = 1.6156e-01, time/batch = 17.2782s	
22972/33250 (epoch 34.544), train_loss = 0.70956289, grad/param norm = 1.5740e-01, time/batch = 17.7827s	
22973/33250 (epoch 34.546), train_loss = 0.77669458, grad/param norm = 1.8468e-01, time/batch = 15.1973s	
22974/33250 (epoch 34.547), train_loss = 0.78565806, grad/param norm = 1.8919e-01, time/batch = 16.6833s	
22975/33250 (epoch 34.549), train_loss = 0.80790544, grad/param norm = 1.5819e-01, time/batch = 16.7778s	
22976/33250 (epoch 34.550), train_loss = 0.77840432, grad/param norm = 1.5853e-01, time/batch = 15.9194s	
22977/33250 (epoch 34.552), train_loss = 0.85883712, grad/param norm = 1.7142e-01, time/batch = 16.1934s	
22978/33250 (epoch 34.553), train_loss = 0.76614912, grad/param norm = 1.5496e-01, time/batch = 17.2725s	
22979/33250 (epoch 34.555), train_loss = 0.81583776, grad/param norm = 1.5372e-01, time/batch = 18.5544s	
22980/33250 (epoch 34.556), train_loss = 0.81600380, grad/param norm = 2.1417e-01, time/batch = 15.9604s	
22981/33250 (epoch 34.558), train_loss = 0.84664770, grad/param norm = 1.7268e-01, time/batch = 16.6927s	
22982/33250 (epoch 34.559), train_loss = 0.73287549, grad/param norm = 1.5674e-01, time/batch = 17.4472s	
22983/33250 (epoch 34.561), train_loss = 0.69745445, grad/param norm = 1.4672e-01, time/batch = 16.6103s	
22984/33250 (epoch 34.562), train_loss = 0.81813819, grad/param norm = 1.8603e-01, time/batch = 18.1733s	
22985/33250 (epoch 34.564), train_loss = 0.98256961, grad/param norm = 1.9009e-01, time/batch = 16.1874s	
22986/33250 (epoch 34.565), train_loss = 0.92541442, grad/param norm = 1.9948e-01, time/batch = 16.6177s	
22987/33250 (epoch 34.567), train_loss = 0.89963221, grad/param norm = 1.7661e-01, time/batch = 17.5218s	
22988/33250 (epoch 34.568), train_loss = 0.76933984, grad/param norm = 2.0191e-01, time/batch = 16.9967s	
22989/33250 (epoch 34.570), train_loss = 0.88622600, grad/param norm = 1.9255e-01, time/batch = 19.8458s	
22990/33250 (epoch 34.571), train_loss = 0.91566126, grad/param norm = 1.6784e-01, time/batch = 18.4448s	
22991/33250 (epoch 34.573), train_loss = 0.87572434, grad/param norm = 1.8561e-01, time/batch = 16.1092s	
22992/33250 (epoch 34.574), train_loss = 0.75687187, grad/param norm = 1.4153e-01, time/batch = 15.4713s	
22993/33250 (epoch 34.576), train_loss = 0.85688015, grad/param norm = 1.7363e-01, time/batch = 16.9357s	
22994/33250 (epoch 34.577), train_loss = 0.80964956, grad/param norm = 1.5780e-01, time/batch = 15.6059s	
22995/33250 (epoch 34.579), train_loss = 0.70438706, grad/param norm = 1.6467e-01, time/batch = 15.9989s	
22996/33250 (epoch 34.580), train_loss = 0.78733279, grad/param norm = 1.4869e-01, time/batch = 17.8481s	
22997/33250 (epoch 34.582), train_loss = 0.76854492, grad/param norm = 1.5475e-01, time/batch = 16.0327s	
22998/33250 (epoch 34.583), train_loss = 0.87533371, grad/param norm = 1.6569e-01, time/batch = 16.6796s	
22999/33250 (epoch 34.585), train_loss = 0.89836106, grad/param norm = 1.6880e-01, time/batch = 17.0390s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch34.59_1.6444.t7	
23000/33250 (epoch 34.586), train_loss = 0.78782843, grad/param norm = 2.2126e-01, time/batch = 18.2114s	
23001/33250 (epoch 34.588), train_loss = 1.30160793, grad/param norm = 2.1396e-01, time/batch = 16.9044s	
23002/33250 (epoch 34.589), train_loss = 0.82795203, grad/param norm = 1.7800e-01, time/batch = 17.4677s	
23003/33250 (epoch 34.591), train_loss = 0.80559912, grad/param norm = 2.0042e-01, time/batch = 16.7807s	
23004/33250 (epoch 34.592), train_loss = 0.78550598, grad/param norm = 1.6959e-01, time/batch = 17.3460s	
23005/33250 (epoch 34.594), train_loss = 0.92028293, grad/param norm = 2.0562e-01, time/batch = 18.0005s	
23006/33250 (epoch 34.595), train_loss = 0.82268377, grad/param norm = 1.6486e-01, time/batch = 17.0180s	
23007/33250 (epoch 34.597), train_loss = 0.68260135, grad/param norm = 1.6008e-01, time/batch = 16.6733s	
23008/33250 (epoch 34.598), train_loss = 0.76795184, grad/param norm = 1.6263e-01, time/batch = 14.9364s	
23009/33250 (epoch 34.600), train_loss = 0.78262786, grad/param norm = 1.8719e-01, time/batch = 15.0860s	
23010/33250 (epoch 34.602), train_loss = 0.83722075, grad/param norm = 2.1260e-01, time/batch = 16.8822s	
23011/33250 (epoch 34.603), train_loss = 0.85446211, grad/param norm = 1.6798e-01, time/batch = 18.0261s	
23012/33250 (epoch 34.605), train_loss = 0.81980128, grad/param norm = 1.8218e-01, time/batch = 18.2159s	
23013/33250 (epoch 34.606), train_loss = 0.87736122, grad/param norm = 1.8996e-01, time/batch = 17.3448s	
23014/33250 (epoch 34.608), train_loss = 0.83289486, grad/param norm = 1.6291e-01, time/batch = 18.3467s	
23015/33250 (epoch 34.609), train_loss = 0.70932641, grad/param norm = 1.5609e-01, time/batch = 15.6762s	
23016/33250 (epoch 34.611), train_loss = 0.80875384, grad/param norm = 1.8417e-01, time/batch = 17.3527s	
23017/33250 (epoch 34.612), train_loss = 0.78697279, grad/param norm = 1.6552e-01, time/batch = 16.4433s	
23018/33250 (epoch 34.614), train_loss = 1.00591772, grad/param norm = 2.0459e-01, time/batch = 17.3452s	
23019/33250 (epoch 34.615), train_loss = 0.92119170, grad/param norm = 1.8823e-01, time/batch = 15.1888s	
23020/33250 (epoch 34.617), train_loss = 1.03072203, grad/param norm = 2.1535e-01, time/batch = 18.1934s	
23021/33250 (epoch 34.618), train_loss = 1.05621327, grad/param norm = 2.6783e-01, time/batch = 17.4471s	
23022/33250 (epoch 34.620), train_loss = 0.90810048, grad/param norm = 1.9467e-01, time/batch = 16.1972s	
23023/33250 (epoch 34.621), train_loss = 0.85928016, grad/param norm = 1.7538e-01, time/batch = 17.4271s	
23024/33250 (epoch 34.623), train_loss = 0.76065687, grad/param norm = 1.6800e-01, time/batch = 15.8493s	
23025/33250 (epoch 34.624), train_loss = 0.79592928, grad/param norm = 1.8469e-01, time/batch = 18.3245s	
23026/33250 (epoch 34.626), train_loss = 0.77625932, grad/param norm = 1.8416e-01, time/batch = 16.5944s	
23027/33250 (epoch 34.627), train_loss = 0.78029556, grad/param norm = 1.6130e-01, time/batch = 18.5117s	
23028/33250 (epoch 34.629), train_loss = 0.85215896, grad/param norm = 1.9409e-01, time/batch = 16.2562s	
23029/33250 (epoch 34.630), train_loss = 0.79988445, grad/param norm = 2.0405e-01, time/batch = 15.3558s	
23030/33250 (epoch 34.632), train_loss = 0.71192880, grad/param norm = 1.5518e-01, time/batch = 19.6089s	
23031/33250 (epoch 34.633), train_loss = 0.82602128, grad/param norm = 1.7420e-01, time/batch = 17.8780s	
23032/33250 (epoch 34.635), train_loss = 0.74355599, grad/param norm = 1.6460e-01, time/batch = 17.1997s	
23033/33250 (epoch 34.636), train_loss = 0.75917676, grad/param norm = 1.5764e-01, time/batch = 17.8687s	
23034/33250 (epoch 34.638), train_loss = 0.74220040, grad/param norm = 1.8461e-01, time/batch = 15.7863s	
23035/33250 (epoch 34.639), train_loss = 0.70943081, grad/param norm = 1.7155e-01, time/batch = 16.5312s	
23036/33250 (epoch 34.641), train_loss = 0.80279537, grad/param norm = 1.7888e-01, time/batch = 15.9238s	
23037/33250 (epoch 34.642), train_loss = 0.62617905, grad/param norm = 1.8500e-01, time/batch = 16.6950s	
23038/33250 (epoch 34.644), train_loss = 0.56470724, grad/param norm = 1.4306e-01, time/batch = 16.3557s	
23039/33250 (epoch 34.645), train_loss = 0.84067976, grad/param norm = 1.9854e-01, time/batch = 16.0921s	
23040/33250 (epoch 34.647), train_loss = 0.70313072, grad/param norm = 1.7190e-01, time/batch = 17.5387s	
23041/33250 (epoch 34.648), train_loss = 0.68941948, grad/param norm = 1.5237e-01, time/batch = 17.7121s	
23042/33250 (epoch 34.650), train_loss = 0.92663875, grad/param norm = 2.3727e-01, time/batch = 15.1887s	
23043/33250 (epoch 34.651), train_loss = 0.85070932, grad/param norm = 1.9154e-01, time/batch = 15.1833s	
23044/33250 (epoch 34.653), train_loss = 0.75322307, grad/param norm = 1.7404e-01, time/batch = 16.0899s	
23045/33250 (epoch 34.654), train_loss = 0.80533582, grad/param norm = 1.6388e-01, time/batch = 15.4142s	
23046/33250 (epoch 34.656), train_loss = 0.84944482, grad/param norm = 1.6562e-01, time/batch = 14.6931s	
23047/33250 (epoch 34.657), train_loss = 0.64454722, grad/param norm = 2.0945e-01, time/batch = 15.0584s	
23048/33250 (epoch 34.659), train_loss = 0.77228635, grad/param norm = 1.8416e-01, time/batch = 14.9564s	
23049/33250 (epoch 34.660), train_loss = 0.81344781, grad/param norm = 1.6604e-01, time/batch = 15.8389s	
23050/33250 (epoch 34.662), train_loss = 0.82999546, grad/param norm = 1.7592e-01, time/batch = 18.7782s	
23051/33250 (epoch 34.663), train_loss = 0.75449986, grad/param norm = 1.7963e-01, time/batch = 15.6760s	
23052/33250 (epoch 34.665), train_loss = 0.82160366, grad/param norm = 1.7788e-01, time/batch = 17.2085s	
23053/33250 (epoch 34.666), train_loss = 0.77147749, grad/param norm = 1.7284e-01, time/batch = 17.8676s	
23054/33250 (epoch 34.668), train_loss = 0.91148610, grad/param norm = 1.7034e-01, time/batch = 17.4484s	
23055/33250 (epoch 34.669), train_loss = 0.81008642, grad/param norm = 1.7193e-01, time/batch = 17.7679s	
23056/33250 (epoch 34.671), train_loss = 0.69880754, grad/param norm = 1.6487e-01, time/batch = 16.2686s	
23057/33250 (epoch 34.672), train_loss = 0.90148165, grad/param norm = 1.7963e-01, time/batch = 16.9489s	
23058/33250 (epoch 34.674), train_loss = 0.71509550, grad/param norm = 1.7631e-01, time/batch = 17.6081s	
23059/33250 (epoch 34.675), train_loss = 0.82407318, grad/param norm = 1.5478e-01, time/batch = 16.8682s	
23060/33250 (epoch 34.677), train_loss = 0.87785228, grad/param norm = 1.7416e-01, time/batch = 17.0911s	
23061/33250 (epoch 34.678), train_loss = 0.76140907, grad/param norm = 1.8830e-01, time/batch = 15.9495s	
23062/33250 (epoch 34.680), train_loss = 0.91385536, grad/param norm = 1.8105e-01, time/batch = 17.6814s	
23063/33250 (epoch 34.681), train_loss = 0.72252077, grad/param norm = 1.5256e-01, time/batch = 16.8613s	
23064/33250 (epoch 34.683), train_loss = 0.74488135, grad/param norm = 1.7214e-01, time/batch = 17.1435s	
23065/33250 (epoch 34.684), train_loss = 0.71226360, grad/param norm = 2.0447e-01, time/batch = 18.1830s	
23066/33250 (epoch 34.686), train_loss = 0.72746780, grad/param norm = 1.6449e-01, time/batch = 17.3624s	
23067/33250 (epoch 34.687), train_loss = 0.81845845, grad/param norm = 1.7137e-01, time/batch = 19.4383s	
23068/33250 (epoch 34.689), train_loss = 0.69816897, grad/param norm = 1.6625e-01, time/batch = 16.9390s	
23069/33250 (epoch 34.690), train_loss = 0.82671771, grad/param norm = 1.7287e-01, time/batch = 18.7788s	
23070/33250 (epoch 34.692), train_loss = 0.76922166, grad/param norm = 1.5198e-01, time/batch = 17.1297s	
23071/33250 (epoch 34.693), train_loss = 0.84803518, grad/param norm = 1.6402e-01, time/batch = 17.6168s	
23072/33250 (epoch 34.695), train_loss = 0.82242129, grad/param norm = 1.5653e-01, time/batch = 15.6695s	
23073/33250 (epoch 34.696), train_loss = 0.84945456, grad/param norm = 1.6035e-01, time/batch = 17.6091s	
23074/33250 (epoch 34.698), train_loss = 0.76441474, grad/param norm = 1.8265e-01, time/batch = 16.3593s	
23075/33250 (epoch 34.699), train_loss = 1.01492120, grad/param norm = 1.7362e-01, time/batch = 16.8498s	
23076/33250 (epoch 34.701), train_loss = 0.79872857, grad/param norm = 1.4942e-01, time/batch = 19.4272s	
23077/33250 (epoch 34.702), train_loss = 0.77282616, grad/param norm = 2.5870e-01, time/batch = 17.2729s	
23078/33250 (epoch 34.704), train_loss = 0.98561533, grad/param norm = 2.3659e-01, time/batch = 17.4268s	
23079/33250 (epoch 34.705), train_loss = 0.76364704, grad/param norm = 1.5803e-01, time/batch = 18.5604s	
23080/33250 (epoch 34.707), train_loss = 0.67051104, grad/param norm = 1.5757e-01, time/batch = 17.3556s	
23081/33250 (epoch 34.708), train_loss = 0.87537610, grad/param norm = 1.9243e-01, time/batch = 17.9146s	
23082/33250 (epoch 34.710), train_loss = 0.85231868, grad/param norm = 1.8629e-01, time/batch = 17.7756s	
23083/33250 (epoch 34.711), train_loss = 0.72739291, grad/param norm = 1.8431e-01, time/batch = 18.3637s	
23084/33250 (epoch 34.713), train_loss = 0.84321698, grad/param norm = 1.6411e-01, time/batch = 18.9476s	
23085/33250 (epoch 34.714), train_loss = 0.78975020, grad/param norm = 1.6601e-01, time/batch = 16.0067s	
23086/33250 (epoch 34.716), train_loss = 0.83572559, grad/param norm = 1.8915e-01, time/batch = 17.7799s	
23087/33250 (epoch 34.717), train_loss = 0.74348867, grad/param norm = 1.3704e-01, time/batch = 16.7123s	
23088/33250 (epoch 34.719), train_loss = 0.74688355, grad/param norm = 1.5524e-01, time/batch = 17.3627s	
23089/33250 (epoch 34.720), train_loss = 1.02326115, grad/param norm = 1.8917e-01, time/batch = 17.5334s	
23090/33250 (epoch 34.722), train_loss = 0.69418867, grad/param norm = 1.4741e-01, time/batch = 18.2671s	
23091/33250 (epoch 34.723), train_loss = 0.62771134, grad/param norm = 1.3273e-01, time/batch = 15.9307s	
23092/33250 (epoch 34.725), train_loss = 0.75932114, grad/param norm = 1.4811e-01, time/batch = 15.8194s	
23093/33250 (epoch 34.726), train_loss = 0.80448081, grad/param norm = 1.5316e-01, time/batch = 17.2784s	
23094/33250 (epoch 34.728), train_loss = 0.83519781, grad/param norm = 1.7257e-01, time/batch = 18.8328s	
23095/33250 (epoch 34.729), train_loss = 0.87466591, grad/param norm = 1.5855e-01, time/batch = 17.6825s	
23096/33250 (epoch 34.731), train_loss = 0.72945443, grad/param norm = 1.8182e-01, time/batch = 16.7871s	
23097/33250 (epoch 34.732), train_loss = 0.72416187, grad/param norm = 1.6449e-01, time/batch = 17.7107s	
23098/33250 (epoch 34.734), train_loss = 0.82983498, grad/param norm = 1.8337e-01, time/batch = 17.9649s	
23099/33250 (epoch 34.735), train_loss = 0.83069420, grad/param norm = 1.7148e-01, time/batch = 16.3409s	
23100/33250 (epoch 34.737), train_loss = 0.77124972, grad/param norm = 1.5720e-01, time/batch = 16.1116s	
23101/33250 (epoch 34.738), train_loss = 0.83555555, grad/param norm = 1.7069e-01, time/batch = 16.8525s	
23102/33250 (epoch 34.740), train_loss = 0.83831591, grad/param norm = 1.8080e-01, time/batch = 16.8460s	
23103/33250 (epoch 34.741), train_loss = 0.86081833, grad/param norm = 1.8181e-01, time/batch = 18.1622s	
23104/33250 (epoch 34.743), train_loss = 0.75926469, grad/param norm = 1.7284e-01, time/batch = 17.0221s	
23105/33250 (epoch 34.744), train_loss = 0.75265508, grad/param norm = 1.7169e-01, time/batch = 17.9569s	
23106/33250 (epoch 34.746), train_loss = 0.70717362, grad/param norm = 1.3982e-01, time/batch = 16.6210s	
23107/33250 (epoch 34.747), train_loss = 0.74150148, grad/param norm = 1.7351e-01, time/batch = 18.6219s	
23108/33250 (epoch 34.749), train_loss = 0.90708332, grad/param norm = 1.8047e-01, time/batch = 15.2076s	
23109/33250 (epoch 34.750), train_loss = 0.91385376, grad/param norm = 1.8674e-01, time/batch = 17.0947s	
23110/33250 (epoch 34.752), train_loss = 0.76641450, grad/param norm = 1.5162e-01, time/batch = 15.1611s	
23111/33250 (epoch 34.753), train_loss = 0.74653132, grad/param norm = 1.6238e-01, time/batch = 18.4261s	
23112/33250 (epoch 34.755), train_loss = 0.70998684, grad/param norm = 1.8464e-01, time/batch = 16.1235s	
23113/33250 (epoch 34.756), train_loss = 0.81307434, grad/param norm = 1.7086e-01, time/batch = 15.0942s	
23114/33250 (epoch 34.758), train_loss = 0.95486498, grad/param norm = 1.7162e-01, time/batch = 17.2743s	
23115/33250 (epoch 34.759), train_loss = 0.75976064, grad/param norm = 1.5549e-01, time/batch = 18.0247s	
23116/33250 (epoch 34.761), train_loss = 0.81790970, grad/param norm = 1.7294e-01, time/batch = 17.1148s	
23117/33250 (epoch 34.762), train_loss = 0.87650761, grad/param norm = 1.7995e-01, time/batch = 17.8652s	
23118/33250 (epoch 34.764), train_loss = 0.74372671, grad/param norm = 2.7301e-01, time/batch = 17.4681s	
23119/33250 (epoch 34.765), train_loss = 0.84522962, grad/param norm = 1.8445e-01, time/batch = 18.4259s	
23120/33250 (epoch 34.767), train_loss = 0.63837398, grad/param norm = 1.4996e-01, time/batch = 16.5737s	
23121/33250 (epoch 34.768), train_loss = 0.68512217, grad/param norm = 1.7252e-01, time/batch = 15.6120s	
23122/33250 (epoch 34.770), train_loss = 0.84051148, grad/param norm = 1.7736e-01, time/batch = 16.2893s	
23123/33250 (epoch 34.771), train_loss = 0.85455546, grad/param norm = 1.7804e-01, time/batch = 17.4084s	
23124/33250 (epoch 34.773), train_loss = 0.80033609, grad/param norm = 1.8008e-01, time/batch = 17.6867s	
23125/33250 (epoch 34.774), train_loss = 0.69002328, grad/param norm = 1.6685e-01, time/batch = 18.8609s	
23126/33250 (epoch 34.776), train_loss = 0.75596115, grad/param norm = 1.6416e-01, time/batch = 17.2588s	
23127/33250 (epoch 34.777), train_loss = 0.90243977, grad/param norm = 1.9439e-01, time/batch = 17.6779s	
23128/33250 (epoch 34.779), train_loss = 0.79889445, grad/param norm = 1.9484e-01, time/batch = 18.0171s	
23129/33250 (epoch 34.780), train_loss = 0.93587316, grad/param norm = 2.1195e-01, time/batch = 18.0054s	
23130/33250 (epoch 34.782), train_loss = 0.81766832, grad/param norm = 2.8376e-01, time/batch = 17.4947s	
23131/33250 (epoch 34.783), train_loss = 0.65630616, grad/param norm = 1.5179e-01, time/batch = 17.9214s	
23132/33250 (epoch 34.785), train_loss = 0.70660255, grad/param norm = 1.6102e-01, time/batch = 15.8363s	
23133/33250 (epoch 34.786), train_loss = 0.89669966, grad/param norm = 1.7574e-01, time/batch = 17.5928s	
23134/33250 (epoch 34.788), train_loss = 0.91308549, grad/param norm = 1.8432e-01, time/batch = 15.7963s	
23135/33250 (epoch 34.789), train_loss = 0.92385198, grad/param norm = 2.8956e-01, time/batch = 19.1181s	
23136/33250 (epoch 34.791), train_loss = 0.93554623, grad/param norm = 2.0443e-01, time/batch = 16.1324s	
23137/33250 (epoch 34.792), train_loss = 0.97710951, grad/param norm = 2.2551e-01, time/batch = 26.8611s	
23138/33250 (epoch 34.794), train_loss = 0.79748594, grad/param norm = 1.7122e-01, time/batch = 20.3775s	
23139/33250 (epoch 34.795), train_loss = 0.80175848, grad/param norm = 1.8207e-01, time/batch = 16.2855s	
23140/33250 (epoch 34.797), train_loss = 0.86368367, grad/param norm = 1.9219e-01, time/batch = 16.6040s	
23141/33250 (epoch 34.798), train_loss = 0.80241556, grad/param norm = 2.0480e-01, time/batch = 17.1063s	
23142/33250 (epoch 34.800), train_loss = 0.83564098, grad/param norm = 1.9132e-01, time/batch = 14.9431s	
23143/33250 (epoch 34.802), train_loss = 0.81539469, grad/param norm = 1.8675e-01, time/batch = 16.2585s	
23144/33250 (epoch 34.803), train_loss = 0.84312702, grad/param norm = 1.6563e-01, time/batch = 17.0238s	
23145/33250 (epoch 34.805), train_loss = 0.82835873, grad/param norm = 1.7312e-01, time/batch = 16.5560s	
23146/33250 (epoch 34.806), train_loss = 0.82006306, grad/param norm = 1.6791e-01, time/batch = 15.2142s	
23147/33250 (epoch 34.808), train_loss = 0.72600381, grad/param norm = 1.5549e-01, time/batch = 16.4429s	
23148/33250 (epoch 34.809), train_loss = 0.73488062, grad/param norm = 1.5487e-01, time/batch = 16.3413s	
23149/33250 (epoch 34.811), train_loss = 0.71134647, grad/param norm = 1.6653e-01, time/batch = 17.4271s	
23150/33250 (epoch 34.812), train_loss = 0.85332338, grad/param norm = 1.9273e-01, time/batch = 17.8355s	
23151/33250 (epoch 34.814), train_loss = 0.77693343, grad/param norm = 1.7730e-01, time/batch = 15.8508s	
23152/33250 (epoch 34.815), train_loss = 0.85808605, grad/param norm = 1.6549e-01, time/batch = 17.1837s	
23153/33250 (epoch 34.817), train_loss = 0.81788757, grad/param norm = 2.0066e-01, time/batch = 17.1101s	
23154/33250 (epoch 34.818), train_loss = 0.75110716, grad/param norm = 1.8028e-01, time/batch = 17.0162s	
23155/33250 (epoch 34.820), train_loss = 0.83856300, grad/param norm = 1.7455e-01, time/batch = 15.9487s	
23156/33250 (epoch 34.821), train_loss = 0.79563704, grad/param norm = 1.7577e-01, time/batch = 17.5405s	
23157/33250 (epoch 34.823), train_loss = 1.09292059, grad/param norm = 2.1572e-01, time/batch = 17.1975s	
23158/33250 (epoch 34.824), train_loss = 0.73111712, grad/param norm = 1.8105e-01, time/batch = 17.4338s	
23159/33250 (epoch 34.826), train_loss = 0.84425379, grad/param norm = 1.9203e-01, time/batch = 16.3624s	
23160/33250 (epoch 34.827), train_loss = 0.71524078, grad/param norm = 1.6750e-01, time/batch = 15.6653s	
23161/33250 (epoch 34.829), train_loss = 0.83427882, grad/param norm = 1.6933e-01, time/batch = 16.7663s	
23162/33250 (epoch 34.830), train_loss = 0.91259079, grad/param norm = 2.3187e-01, time/batch = 17.1088s	
23163/33250 (epoch 34.832), train_loss = 0.83214547, grad/param norm = 1.8583e-01, time/batch = 16.4501s	
23164/33250 (epoch 34.833), train_loss = 0.79279618, grad/param norm = 1.5638e-01, time/batch = 17.6343s	
23165/33250 (epoch 34.835), train_loss = 0.72773396, grad/param norm = 2.3044e-01, time/batch = 16.8648s	
23166/33250 (epoch 34.836), train_loss = 0.79063692, grad/param norm = 1.7036e-01, time/batch = 16.2851s	
23167/33250 (epoch 34.838), train_loss = 0.83653843, grad/param norm = 1.6369e-01, time/batch = 18.6650s	
23168/33250 (epoch 34.839), train_loss = 0.77240130, grad/param norm = 1.8243e-01, time/batch = 16.5107s	
23169/33250 (epoch 34.841), train_loss = 0.75440956, grad/param norm = 1.4374e-01, time/batch = 16.1106s	
23170/33250 (epoch 34.842), train_loss = 0.95194653, grad/param norm = 1.7992e-01, time/batch = 17.9369s	
23171/33250 (epoch 34.844), train_loss = 0.87665093, grad/param norm = 1.8477e-01, time/batch = 18.3343s	
23172/33250 (epoch 34.845), train_loss = 0.98109428, grad/param norm = 2.2220e-01, time/batch = 16.8397s	
23173/33250 (epoch 34.847), train_loss = 0.94289310, grad/param norm = 1.8226e-01, time/batch = 17.6860s	
23174/33250 (epoch 34.848), train_loss = 1.01010572, grad/param norm = 2.1285e-01, time/batch = 15.6252s	
23175/33250 (epoch 34.850), train_loss = 0.89922245, grad/param norm = 1.8995e-01, time/batch = 15.9416s	
23176/33250 (epoch 34.851), train_loss = 0.71367226, grad/param norm = 1.9831e-01, time/batch = 17.9564s	
23177/33250 (epoch 34.853), train_loss = 0.85808744, grad/param norm = 2.0099e-01, time/batch = 17.8556s	
23178/33250 (epoch 34.854), train_loss = 0.78041106, grad/param norm = 1.6582e-01, time/batch = 15.1711s	
23179/33250 (epoch 34.856), train_loss = 0.75028673, grad/param norm = 1.8797e-01, time/batch = 15.1811s	
23180/33250 (epoch 34.857), train_loss = 0.71339449, grad/param norm = 1.7254e-01, time/batch = 15.9478s	
23181/33250 (epoch 34.859), train_loss = 0.76847989, grad/param norm = 2.4861e-01, time/batch = 17.6839s	
23182/33250 (epoch 34.860), train_loss = 0.83816277, grad/param norm = 1.5741e-01, time/batch = 16.4199s	
23183/33250 (epoch 34.862), train_loss = 0.72093154, grad/param norm = 1.5853e-01, time/batch = 18.1986s	
23184/33250 (epoch 34.863), train_loss = 0.74518903, grad/param norm = 1.8830e-01, time/batch = 16.8762s	
23185/33250 (epoch 34.865), train_loss = 0.83763297, grad/param norm = 1.7498e-01, time/batch = 18.7890s	
23186/33250 (epoch 34.866), train_loss = 0.72710468, grad/param norm = 1.8501e-01, time/batch = 16.6092s	
23187/33250 (epoch 34.868), train_loss = 0.83113509, grad/param norm = 2.0491e-01, time/batch = 18.0122s	
23188/33250 (epoch 34.869), train_loss = 0.84154263, grad/param norm = 1.8859e-01, time/batch = 17.3328s	
23189/33250 (epoch 34.871), train_loss = 0.62860504, grad/param norm = 1.4239e-01, time/batch = 16.5512s	
23190/33250 (epoch 34.872), train_loss = 0.87588507, grad/param norm = 2.3542e-01, time/batch = 0.6779s	
23191/33250 (epoch 34.874), train_loss = 0.72919475, grad/param norm = 1.7701e-01, time/batch = 0.6622s	
23192/33250 (epoch 34.875), train_loss = 0.70235780, grad/param norm = 2.2983e-01, time/batch = 0.6896s	
23193/33250 (epoch 34.877), train_loss = 0.92114670, grad/param norm = 1.8454e-01, time/batch = 0.6840s	
23194/33250 (epoch 34.878), train_loss = 0.81639245, grad/param norm = 1.7714e-01, time/batch = 0.6745s	
23195/33250 (epoch 34.880), train_loss = 0.79920352, grad/param norm = 1.9883e-01, time/batch = 0.6658s	
23196/33250 (epoch 34.881), train_loss = 0.90864528, grad/param norm = 1.6435e-01, time/batch = 0.6699s	
23197/33250 (epoch 34.883), train_loss = 0.83563714, grad/param norm = 1.7320e-01, time/batch = 0.8682s	
23198/33250 (epoch 34.884), train_loss = 0.88705416, grad/param norm = 1.7904e-01, time/batch = 0.9736s	
23199/33250 (epoch 34.886), train_loss = 0.74318475, grad/param norm = 1.5665e-01, time/batch = 0.9747s	
23200/33250 (epoch 34.887), train_loss = 0.76003756, grad/param norm = 1.8144e-01, time/batch = 0.9699s	
23201/33250 (epoch 34.889), train_loss = 0.76493598, grad/param norm = 1.4719e-01, time/batch = 0.9740s	
23202/33250 (epoch 34.890), train_loss = 0.62454910, grad/param norm = 1.3514e-01, time/batch = 1.4606s	
23203/33250 (epoch 34.892), train_loss = 0.84923919, grad/param norm = 1.5555e-01, time/batch = 1.8722s	
23204/33250 (epoch 34.893), train_loss = 0.86517964, grad/param norm = 1.8013e-01, time/batch = 1.8258s	
23205/33250 (epoch 34.895), train_loss = 0.74778210, grad/param norm = 1.7171e-01, time/batch = 13.3355s	
23206/33250 (epoch 34.896), train_loss = 0.86745109, grad/param norm = 1.5995e-01, time/batch = 16.4437s	
23207/33250 (epoch 34.898), train_loss = 0.81194180, grad/param norm = 1.7439e-01, time/batch = 17.0340s	
23208/33250 (epoch 34.899), train_loss = 0.74061997, grad/param norm = 1.5688e-01, time/batch = 19.2070s	
23209/33250 (epoch 34.901), train_loss = 0.68633488, grad/param norm = 1.4772e-01, time/batch = 17.7892s	
23210/33250 (epoch 34.902), train_loss = 0.77273151, grad/param norm = 1.6740e-01, time/batch = 17.6646s	
23211/33250 (epoch 34.904), train_loss = 0.71861412, grad/param norm = 1.5797e-01, time/batch = 16.7550s	
23212/33250 (epoch 34.905), train_loss = 0.77858758, grad/param norm = 1.5183e-01, time/batch = 17.9219s	
23213/33250 (epoch 34.907), train_loss = 0.73646442, grad/param norm = 1.7003e-01, time/batch = 18.3534s	
23214/33250 (epoch 34.908), train_loss = 0.79323480, grad/param norm = 1.6107e-01, time/batch = 15.9350s	
23215/33250 (epoch 34.910), train_loss = 0.86265896, grad/param norm = 3.8020e-01, time/batch = 16.1804s	
23216/33250 (epoch 34.911), train_loss = 0.72339782, grad/param norm = 1.8517e-01, time/batch = 16.1949s	
23217/33250 (epoch 34.913), train_loss = 0.76565744, grad/param norm = 1.6552e-01, time/batch = 16.6810s	
23218/33250 (epoch 34.914), train_loss = 0.68673918, grad/param norm = 1.6062e-01, time/batch = 17.1781s	
23219/33250 (epoch 34.916), train_loss = 0.71311649, grad/param norm = 1.5466e-01, time/batch = 19.6928s	
23220/33250 (epoch 34.917), train_loss = 0.80623831, grad/param norm = 1.4284e-01, time/batch = 15.7925s	
23221/33250 (epoch 34.919), train_loss = 0.73776835, grad/param norm = 1.9077e-01, time/batch = 15.8503s	
23222/33250 (epoch 34.920), train_loss = 0.81213393, grad/param norm = 1.9839e-01, time/batch = 17.5930s	
23223/33250 (epoch 34.922), train_loss = 0.84486919, grad/param norm = 1.9722e-01, time/batch = 17.9282s	
23224/33250 (epoch 34.923), train_loss = 0.74967183, grad/param norm = 1.5299e-01, time/batch = 16.8453s	
23225/33250 (epoch 34.925), train_loss = 0.79304254, grad/param norm = 1.7956e-01, time/batch = 15.8630s	
23226/33250 (epoch 34.926), train_loss = 0.75994460, grad/param norm = 1.6304e-01, time/batch = 18.9181s	
23227/33250 (epoch 34.928), train_loss = 0.75834876, grad/param norm = 1.5834e-01, time/batch = 15.6075s	
23228/33250 (epoch 34.929), train_loss = 0.67089914, grad/param norm = 1.3236e-01, time/batch = 17.3786s	
23229/33250 (epoch 34.931), train_loss = 0.89496425, grad/param norm = 1.6161e-01, time/batch = 19.1013s	
23230/33250 (epoch 34.932), train_loss = 0.76480743, grad/param norm = 1.8804e-01, time/batch = 19.1038s	
23231/33250 (epoch 34.934), train_loss = 0.74254884, grad/param norm = 1.5511e-01, time/batch = 17.5855s	
23232/33250 (epoch 34.935), train_loss = 0.75601749, grad/param norm = 1.8066e-01, time/batch = 17.3079s	
23233/33250 (epoch 34.937), train_loss = 0.74198594, grad/param norm = 2.0654e-01, time/batch = 15.7854s	
23234/33250 (epoch 34.938), train_loss = 0.77801970, grad/param norm = 1.6609e-01, time/batch = 17.4241s	
23235/33250 (epoch 34.940), train_loss = 0.76919581, grad/param norm = 1.8752e-01, time/batch = 15.5953s	
23236/33250 (epoch 34.941), train_loss = 0.84706899, grad/param norm = 1.9821e-01, time/batch = 18.7661s	
23237/33250 (epoch 34.943), train_loss = 0.95147888, grad/param norm = 1.9434e-01, time/batch = 16.8060s	
23238/33250 (epoch 34.944), train_loss = 0.76253529, grad/param norm = 1.5786e-01, time/batch = 17.6109s	
23239/33250 (epoch 34.946), train_loss = 0.89291608, grad/param norm = 1.9074e-01, time/batch = 17.0254s	
23240/33250 (epoch 34.947), train_loss = 0.72541845, grad/param norm = 1.5967e-01, time/batch = 16.4498s	
23241/33250 (epoch 34.949), train_loss = 0.85766194, grad/param norm = 1.9344e-01, time/batch = 17.0204s	
23242/33250 (epoch 34.950), train_loss = 0.87169310, grad/param norm = 1.8286e-01, time/batch = 17.1773s	
23243/33250 (epoch 34.952), train_loss = 0.80782653, grad/param norm = 2.0239e-01, time/batch = 17.6893s	
23244/33250 (epoch 34.953), train_loss = 0.82790913, grad/param norm = 1.9769e-01, time/batch = 16.8407s	
23245/33250 (epoch 34.955), train_loss = 0.88002081, grad/param norm = 1.7176e-01, time/batch = 16.0759s	
23246/33250 (epoch 34.956), train_loss = 0.81232327, grad/param norm = 2.0514e-01, time/batch = 16.0340s	
23247/33250 (epoch 34.958), train_loss = 0.75579298, grad/param norm = 1.5976e-01, time/batch = 14.8154s	
23248/33250 (epoch 34.959), train_loss = 0.74782440, grad/param norm = 1.5754e-01, time/batch = 16.0245s	
23249/33250 (epoch 34.961), train_loss = 1.00214952, grad/param norm = 1.9281e-01, time/batch = 17.7021s	
23250/33250 (epoch 34.962), train_loss = 0.77492454, grad/param norm = 1.7853e-01, time/batch = 18.1112s	
23251/33250 (epoch 34.964), train_loss = 0.91269719, grad/param norm = 1.7941e-01, time/batch = 14.8596s	
23252/33250 (epoch 34.965), train_loss = 0.86079614, grad/param norm = 1.9716e-01, time/batch = 14.9215s	
23253/33250 (epoch 34.967), train_loss = 0.81608579, grad/param norm = 2.1726e-01, time/batch = 15.2647s	
23254/33250 (epoch 34.968), train_loss = 0.93249933, grad/param norm = 1.7522e-01, time/batch = 14.8559s	
23255/33250 (epoch 34.970), train_loss = 1.03905172, grad/param norm = 2.1694e-01, time/batch = 14.9537s	
23256/33250 (epoch 34.971), train_loss = 0.97255827, grad/param norm = 1.9615e-01, time/batch = 15.0519s	
23257/33250 (epoch 34.973), train_loss = 0.78446237, grad/param norm = 1.5176e-01, time/batch = 17.7551s	
23258/33250 (epoch 34.974), train_loss = 0.88201060, grad/param norm = 1.9360e-01, time/batch = 17.5452s	
23259/33250 (epoch 34.976), train_loss = 0.77967324, grad/param norm = 1.8751e-01, time/batch = 17.7849s	
23260/33250 (epoch 34.977), train_loss = 0.79959901, grad/param norm = 1.6629e-01, time/batch = 16.7206s	
23261/33250 (epoch 34.979), train_loss = 0.84815693, grad/param norm = 1.8846e-01, time/batch = 18.7402s	
23262/33250 (epoch 34.980), train_loss = 0.86985245, grad/param norm = 1.7289e-01, time/batch = 16.4979s	
23263/33250 (epoch 34.982), train_loss = 0.76680352, grad/param norm = 1.5020e-01, time/batch = 17.3285s	
23264/33250 (epoch 34.983), train_loss = 0.84559366, grad/param norm = 2.2516e-01, time/batch = 15.9847s	
23265/33250 (epoch 34.985), train_loss = 0.79867299, grad/param norm = 2.3122e-01, time/batch = 17.3369s	
23266/33250 (epoch 34.986), train_loss = 0.87552324, grad/param norm = 1.7974e-01, time/batch = 17.1055s	
23267/33250 (epoch 34.988), train_loss = 0.91669098, grad/param norm = 1.8958e-01, time/batch = 17.9460s	
23268/33250 (epoch 34.989), train_loss = 0.89087962, grad/param norm = 1.7749e-01, time/batch = 18.6122s	
23269/33250 (epoch 34.991), train_loss = 0.85216223, grad/param norm = 1.6996e-01, time/batch = 18.2890s	
23270/33250 (epoch 34.992), train_loss = 0.79776130, grad/param norm = 1.6409e-01, time/batch = 17.6764s	
23271/33250 (epoch 34.994), train_loss = 0.76205625, grad/param norm = 1.6290e-01, time/batch = 17.9368s	
23272/33250 (epoch 34.995), train_loss = 0.79742859, grad/param norm = 2.3266e-01, time/batch = 17.4930s	
23273/33250 (epoch 34.997), train_loss = 0.61182909, grad/param norm = 1.6980e-01, time/batch = 18.7588s	
23274/33250 (epoch 34.998), train_loss = 0.86665756, grad/param norm = 1.8398e-01, time/batch = 17.5777s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
23275/33250 (epoch 35.000), train_loss = 0.84759201, grad/param norm = 1.8000e-01, time/batch = 17.6814s	
23276/33250 (epoch 35.002), train_loss = 1.01687862, grad/param norm = 1.9054e-01, time/batch = 18.6877s	
23277/33250 (epoch 35.003), train_loss = 0.88891211, grad/param norm = 2.1032e-01, time/batch = 17.0309s	
23278/33250 (epoch 35.005), train_loss = 0.66877290, grad/param norm = 1.4735e-01, time/batch = 19.0192s	
23279/33250 (epoch 35.006), train_loss = 0.68951353, grad/param norm = 1.6040e-01, time/batch = 17.5993s	
23280/33250 (epoch 35.008), train_loss = 0.90183381, grad/param norm = 1.8784e-01, time/batch = 15.9113s	
23281/33250 (epoch 35.009), train_loss = 0.98076943, grad/param norm = 1.8661e-01, time/batch = 18.0924s	
23282/33250 (epoch 35.011), train_loss = 0.76220972, grad/param norm = 1.6340e-01, time/batch = 17.1023s	
23283/33250 (epoch 35.012), train_loss = 0.81392194, grad/param norm = 2.8148e-01, time/batch = 18.2424s	
23284/33250 (epoch 35.014), train_loss = 0.90790268, grad/param norm = 2.0656e-01, time/batch = 16.5079s	
23285/33250 (epoch 35.015), train_loss = 0.82309318, grad/param norm = 1.7695e-01, time/batch = 17.1839s	
23286/33250 (epoch 35.017), train_loss = 0.85725063, grad/param norm = 2.3607e-01, time/batch = 17.6311s	
23287/33250 (epoch 35.018), train_loss = 0.65582242, grad/param norm = 1.6061e-01, time/batch = 17.9571s	
23288/33250 (epoch 35.020), train_loss = 0.82293743, grad/param norm = 1.6416e-01, time/batch = 15.6638s	
23289/33250 (epoch 35.021), train_loss = 0.83840050, grad/param norm = 1.7795e-01, time/batch = 16.1033s	
23290/33250 (epoch 35.023), train_loss = 0.66210879, grad/param norm = 1.7246e-01, time/batch = 15.7454s	
23291/33250 (epoch 35.024), train_loss = 0.92185889, grad/param norm = 2.2389e-01, time/batch = 16.4987s	
23292/33250 (epoch 35.026), train_loss = 0.83219236, grad/param norm = 1.6945e-01, time/batch = 16.2617s	
23293/33250 (epoch 35.027), train_loss = 0.86080401, grad/param norm = 1.7779e-01, time/batch = 15.3721s	
23294/33250 (epoch 35.029), train_loss = 0.80999291, grad/param norm = 1.9496e-01, time/batch = 15.7064s	
23295/33250 (epoch 35.030), train_loss = 0.79736870, grad/param norm = 1.9302e-01, time/batch = 15.6686s	
23296/33250 (epoch 35.032), train_loss = 0.98781019, grad/param norm = 2.0503e-01, time/batch = 15.7039s	
23297/33250 (epoch 35.033), train_loss = 0.77987280, grad/param norm = 2.1375e-01, time/batch = 17.9174s	
23298/33250 (epoch 35.035), train_loss = 0.84222886, grad/param norm = 1.9326e-01, time/batch = 16.3330s	
23299/33250 (epoch 35.036), train_loss = 0.88089293, grad/param norm = 2.1247e-01, time/batch = 16.7201s	
23300/33250 (epoch 35.038), train_loss = 0.82240038, grad/param norm = 1.4286e-01, time/batch = 16.1266s	
23301/33250 (epoch 35.039), train_loss = 0.75757895, grad/param norm = 1.6542e-01, time/batch = 15.7807s	
23302/33250 (epoch 35.041), train_loss = 0.83538594, grad/param norm = 2.0642e-01, time/batch = 15.7577s	
23303/33250 (epoch 35.042), train_loss = 0.69294798, grad/param norm = 1.5232e-01, time/batch = 16.0350s	
23304/33250 (epoch 35.044), train_loss = 0.91757760, grad/param norm = 1.6832e-01, time/batch = 15.7838s	
23305/33250 (epoch 35.045), train_loss = 0.92284393, grad/param norm = 1.7862e-01, time/batch = 16.1933s	
23306/33250 (epoch 35.047), train_loss = 0.83354304, grad/param norm = 1.8049e-01, time/batch = 15.5089s	
23307/33250 (epoch 35.048), train_loss = 0.88421759, grad/param norm = 2.2317e-01, time/batch = 17.8533s	
23308/33250 (epoch 35.050), train_loss = 0.82966333, grad/param norm = 1.6733e-01, time/batch = 18.9344s	
23309/33250 (epoch 35.051), train_loss = 0.82224927, grad/param norm = 1.6048e-01, time/batch = 16.8364s	
23310/33250 (epoch 35.053), train_loss = 0.88171478, grad/param norm = 1.9780e-01, time/batch = 15.8602s	
23311/33250 (epoch 35.054), train_loss = 0.68550730, grad/param norm = 1.4898e-01, time/batch = 15.2658s	
23312/33250 (epoch 35.056), train_loss = 0.71701486, grad/param norm = 1.4294e-01, time/batch = 15.0332s	
23313/33250 (epoch 35.057), train_loss = 0.92261303, grad/param norm = 1.7697e-01, time/batch = 15.8441s	
23314/33250 (epoch 35.059), train_loss = 0.76333048, grad/param norm = 1.7027e-01, time/batch = 15.3565s	
23315/33250 (epoch 35.060), train_loss = 0.83276377, grad/param norm = 1.9300e-01, time/batch = 16.4453s	
23316/33250 (epoch 35.062), train_loss = 0.89947954, grad/param norm = 1.7586e-01, time/batch = 16.2636s	
23317/33250 (epoch 35.063), train_loss = 0.94155841, grad/param norm = 1.6749e-01, time/batch = 15.4897s	
23318/33250 (epoch 35.065), train_loss = 0.81818088, grad/param norm = 1.7352e-01, time/batch = 16.4560s	
23319/33250 (epoch 35.066), train_loss = 0.86890601, grad/param norm = 1.9355e-01, time/batch = 17.4495s	
23320/33250 (epoch 35.068), train_loss = 0.79217990, grad/param norm = 1.7423e-01, time/batch = 16.7788s	
23321/33250 (epoch 35.069), train_loss = 0.82803225, grad/param norm = 1.6273e-01, time/batch = 17.2661s	
23322/33250 (epoch 35.071), train_loss = 0.76920516, grad/param norm = 1.4798e-01, time/batch = 15.5415s	
23323/33250 (epoch 35.072), train_loss = 0.74576679, grad/param norm = 1.5245e-01, time/batch = 16.4452s	
23324/33250 (epoch 35.074), train_loss = 0.83810057, grad/param norm = 1.6778e-01, time/batch = 15.5209s	
23325/33250 (epoch 35.075), train_loss = 0.77619661, grad/param norm = 1.5659e-01, time/batch = 14.9486s	
23326/33250 (epoch 35.077), train_loss = 0.80674020, grad/param norm = 2.2279e-01, time/batch = 16.9382s	
23327/33250 (epoch 35.078), train_loss = 0.81343388, grad/param norm = 1.6431e-01, time/batch = 17.0178s	
23328/33250 (epoch 35.080), train_loss = 0.83985441, grad/param norm = 2.2838e-01, time/batch = 15.7632s	
23329/33250 (epoch 35.081), train_loss = 0.84461650, grad/param norm = 1.6843e-01, time/batch = 16.5937s	
23330/33250 (epoch 35.083), train_loss = 0.92537129, grad/param norm = 1.6165e-01, time/batch = 16.1308s	
23331/33250 (epoch 35.084), train_loss = 0.85751723, grad/param norm = 1.7704e-01, time/batch = 17.4475s	
23332/33250 (epoch 35.086), train_loss = 0.82177921, grad/param norm = 1.4964e-01, time/batch = 18.6891s	
23333/33250 (epoch 35.087), train_loss = 0.70425579, grad/param norm = 1.4693e-01, time/batch = 15.5546s	
23334/33250 (epoch 35.089), train_loss = 0.80714900, grad/param norm = 1.6917e-01, time/batch = 15.3572s	
23335/33250 (epoch 35.090), train_loss = 0.83373716, grad/param norm = 1.8899e-01, time/batch = 16.0246s	
23336/33250 (epoch 35.092), train_loss = 0.75880136, grad/param norm = 1.5993e-01, time/batch = 15.5236s	
23337/33250 (epoch 35.093), train_loss = 0.81075045, grad/param norm = 1.7153e-01, time/batch = 16.1126s	
23338/33250 (epoch 35.095), train_loss = 0.81700390, grad/param norm = 1.7126e-01, time/batch = 15.5380s	
23339/33250 (epoch 35.096), train_loss = 0.68607843, grad/param norm = 1.6631e-01, time/batch = 15.8882s	
23340/33250 (epoch 35.098), train_loss = 0.69112804, grad/param norm = 1.9965e-01, time/batch = 16.0273s	
23341/33250 (epoch 35.099), train_loss = 0.64352327, grad/param norm = 1.5083e-01, time/batch = 15.6950s	
23342/33250 (epoch 35.101), train_loss = 0.79958702, grad/param norm = 1.8359e-01, time/batch = 17.1276s	
23343/33250 (epoch 35.102), train_loss = 0.74984935, grad/param norm = 1.6526e-01, time/batch = 17.1973s	
23344/33250 (epoch 35.104), train_loss = 0.61016104, grad/param norm = 1.3993e-01, time/batch = 17.1747s	
23345/33250 (epoch 35.105), train_loss = 0.77073531, grad/param norm = 1.9262e-01, time/batch = 16.5216s	
23346/33250 (epoch 35.107), train_loss = 0.69513110, grad/param norm = 1.3768e-01, time/batch = 15.5944s	
23347/33250 (epoch 35.108), train_loss = 0.81319449, grad/param norm = 1.7323e-01, time/batch = 15.7039s	
23348/33250 (epoch 35.110), train_loss = 0.68672640, grad/param norm = 1.5629e-01, time/batch = 15.6898s	
23349/33250 (epoch 35.111), train_loss = 0.79705166, grad/param norm = 1.4669e-01, time/batch = 15.5910s	
23350/33250 (epoch 35.113), train_loss = 0.75310327, grad/param norm = 2.1009e-01, time/batch = 16.3478s	
23351/33250 (epoch 35.114), train_loss = 0.71246048, grad/param norm = 1.8693e-01, time/batch = 17.4186s	
23352/33250 (epoch 35.116), train_loss = 0.74321804, grad/param norm = 1.7724e-01, time/batch = 15.6012s	
23353/33250 (epoch 35.117), train_loss = 0.75733315, grad/param norm = 1.7515e-01, time/batch = 17.6030s	
23354/33250 (epoch 35.119), train_loss = 0.76268987, grad/param norm = 1.7325e-01, time/batch = 18.4470s	
23355/33250 (epoch 35.120), train_loss = 0.63556855, grad/param norm = 1.4071e-01, time/batch = 16.6944s	
23356/33250 (epoch 35.122), train_loss = 0.86807452, grad/param norm = 1.7266e-01, time/batch = 15.5123s	
23357/33250 (epoch 35.123), train_loss = 0.78661493, grad/param norm = 2.0730e-01, time/batch = 15.4383s	
23358/33250 (epoch 35.125), train_loss = 0.65792397, grad/param norm = 1.9680e-01, time/batch = 16.2756s	
23359/33250 (epoch 35.126), train_loss = 0.76715084, grad/param norm = 1.6486e-01, time/batch = 15.5239s	
23360/33250 (epoch 35.128), train_loss = 0.73110925, grad/param norm = 1.3055e-01, time/batch = 15.2812s	
23361/33250 (epoch 35.129), train_loss = 0.78737522, grad/param norm = 1.6322e-01, time/batch = 15.5995s	
23362/33250 (epoch 35.131), train_loss = 0.78958308, grad/param norm = 1.8266e-01, time/batch = 17.5201s	
23363/33250 (epoch 35.132), train_loss = 0.76231922, grad/param norm = 1.8731e-01, time/batch = 16.7961s	
23364/33250 (epoch 35.134), train_loss = 0.72626257, grad/param norm = 1.6039e-01, time/batch = 22.7042s	
23365/33250 (epoch 35.135), train_loss = 0.79791970, grad/param norm = 1.4696e-01, time/batch = 24.6678s	
23366/33250 (epoch 35.137), train_loss = 0.70374093, grad/param norm = 1.8207e-01, time/batch = 16.2783s	
23367/33250 (epoch 35.138), train_loss = 0.71700714, grad/param norm = 1.4860e-01, time/batch = 15.3597s	
23368/33250 (epoch 35.140), train_loss = 0.62477234, grad/param norm = 1.4771e-01, time/batch = 15.8104s	
23369/33250 (epoch 35.141), train_loss = 0.87807243, grad/param norm = 2.1182e-01, time/batch = 15.3357s	
23370/33250 (epoch 35.143), train_loss = 0.66010678, grad/param norm = 1.5977e-01, time/batch = 15.5071s	
23371/33250 (epoch 35.144), train_loss = 0.76300328, grad/param norm = 1.7027e-01, time/batch = 15.6061s	
23372/33250 (epoch 35.146), train_loss = 0.75307738, grad/param norm = 1.5383e-01, time/batch = 15.3014s	
23373/33250 (epoch 35.147), train_loss = 0.77336782, grad/param norm = 1.6367e-01, time/batch = 15.3753s	
23374/33250 (epoch 35.149), train_loss = 0.73762085, grad/param norm = 1.7106e-01, time/batch = 15.7444s	
23375/33250 (epoch 35.150), train_loss = 0.69726680, grad/param norm = 1.7496e-01, time/batch = 15.5359s	
23376/33250 (epoch 35.152), train_loss = 0.67130403, grad/param norm = 1.5936e-01, time/batch = 15.3703s	
23377/33250 (epoch 35.153), train_loss = 0.93260272, grad/param norm = 1.9355e-01, time/batch = 15.4380s	
23378/33250 (epoch 35.155), train_loss = 0.74276311, grad/param norm = 1.8205e-01, time/batch = 15.1194s	
23379/33250 (epoch 35.156), train_loss = 0.98275690, grad/param norm = 1.7317e-01, time/batch = 15.6842s	
23380/33250 (epoch 35.158), train_loss = 0.93610259, grad/param norm = 2.3586e-01, time/batch = 15.2156s	
23381/33250 (epoch 35.159), train_loss = 0.75018875, grad/param norm = 1.6753e-01, time/batch = 15.6950s	
23382/33250 (epoch 35.161), train_loss = 0.80401856, grad/param norm = 1.7406e-01, time/batch = 17.0975s	
23383/33250 (epoch 35.162), train_loss = 0.72708365, grad/param norm = 1.5140e-01, time/batch = 17.5304s	
23384/33250 (epoch 35.164), train_loss = 0.77271276, grad/param norm = 1.8078e-01, time/batch = 17.2023s	
23385/33250 (epoch 35.165), train_loss = 0.86753572, grad/param norm = 1.7911e-01, time/batch = 15.7217s	
23386/33250 (epoch 35.167), train_loss = 0.93978060, grad/param norm = 2.1941e-01, time/batch = 15.5099s	
23387/33250 (epoch 35.168), train_loss = 0.68167845, grad/param norm = 1.3812e-01, time/batch = 16.9874s	
23388/33250 (epoch 35.170), train_loss = 0.75142090, grad/param norm = 1.6895e-01, time/batch = 15.2872s	
23389/33250 (epoch 35.171), train_loss = 0.80482803, grad/param norm = 1.5953e-01, time/batch = 16.5200s	
23390/33250 (epoch 35.173), train_loss = 0.76657718, grad/param norm = 1.5800e-01, time/batch = 15.5985s	
23391/33250 (epoch 35.174), train_loss = 0.80069036, grad/param norm = 1.5747e-01, time/batch = 17.9981s	
23392/33250 (epoch 35.176), train_loss = 0.73170515, grad/param norm = 1.5988e-01, time/batch = 15.3694s	
23393/33250 (epoch 35.177), train_loss = 0.75786569, grad/param norm = 1.6600e-01, time/batch = 17.5891s	
23394/33250 (epoch 35.179), train_loss = 0.73654205, grad/param norm = 1.6663e-01, time/batch = 15.3748s	
23395/33250 (epoch 35.180), train_loss = 0.63755604, grad/param norm = 1.5949e-01, time/batch = 15.3754s	
23396/33250 (epoch 35.182), train_loss = 0.72891439, grad/param norm = 1.9749e-01, time/batch = 15.6200s	
23397/33250 (epoch 35.183), train_loss = 0.87956231, grad/param norm = 1.9060e-01, time/batch = 15.4130s	
23398/33250 (epoch 35.185), train_loss = 0.81795583, grad/param norm = 1.9980e-01, time/batch = 15.6023s	
23399/33250 (epoch 35.186), train_loss = 0.82646090, grad/param norm = 1.9046e-01, time/batch = 15.5893s	
23400/33250 (epoch 35.188), train_loss = 0.88669968, grad/param norm = 2.1401e-01, time/batch = 15.7423s	
23401/33250 (epoch 35.189), train_loss = 0.63503768, grad/param norm = 1.6463e-01, time/batch = 15.9161s	
23402/33250 (epoch 35.191), train_loss = 0.74486304, grad/param norm = 1.8322e-01, time/batch = 16.0485s	
23403/33250 (epoch 35.192), train_loss = 0.76651256, grad/param norm = 1.7930e-01, time/batch = 16.6979s	
23404/33250 (epoch 35.194), train_loss = 0.76873098, grad/param norm = 1.8366e-01, time/batch = 19.1065s	
23405/33250 (epoch 35.195), train_loss = 0.97920940, grad/param norm = 1.9091e-01, time/batch = 17.5235s	
23406/33250 (epoch 35.197), train_loss = 0.72845525, grad/param norm = 1.5847e-01, time/batch = 15.5188s	
23407/33250 (epoch 35.198), train_loss = 0.93604042, grad/param norm = 1.8266e-01, time/batch = 16.3475s	
23408/33250 (epoch 35.200), train_loss = 0.80618929, grad/param norm = 2.0677e-01, time/batch = 16.4398s	
23409/33250 (epoch 35.202), train_loss = 0.75727657, grad/param norm = 1.5558e-01, time/batch = 15.5155s	
23410/33250 (epoch 35.203), train_loss = 0.71173489, grad/param norm = 1.6286e-01, time/batch = 15.8649s	
23411/33250 (epoch 35.205), train_loss = 0.81008697, grad/param norm = 1.6045e-01, time/batch = 15.6706s	
23412/33250 (epoch 35.206), train_loss = 0.88058873, grad/param norm = 1.7126e-01, time/batch = 15.4247s	
23413/33250 (epoch 35.208), train_loss = 0.90086488, grad/param norm = 1.8695e-01, time/batch = 16.4172s	
23414/33250 (epoch 35.209), train_loss = 0.75389791, grad/param norm = 1.5609e-01, time/batch = 15.6286s	
23415/33250 (epoch 35.211), train_loss = 0.83337027, grad/param norm = 1.7189e-01, time/batch = 17.4355s	
23416/33250 (epoch 35.212), train_loss = 0.95178054, grad/param norm = 1.8633e-01, time/batch = 16.2984s	
23417/33250 (epoch 35.214), train_loss = 0.81630024, grad/param norm = 1.6149e-01, time/batch = 17.6121s	
23418/33250 (epoch 35.215), train_loss = 0.86142373, grad/param norm = 2.0271e-01, time/batch = 15.6166s	
23419/33250 (epoch 35.217), train_loss = 0.89073049, grad/param norm = 2.0578e-01, time/batch = 16.4263s	
23420/33250 (epoch 35.218), train_loss = 0.86777168, grad/param norm = 1.7069e-01, time/batch = 15.7764s	
23421/33250 (epoch 35.220), train_loss = 0.81614153, grad/param norm = 1.8030e-01, time/batch = 15.6803s	
23422/33250 (epoch 35.221), train_loss = 0.93581516, grad/param norm = 2.0656e-01, time/batch = 15.8666s	
23423/33250 (epoch 35.223), train_loss = 0.81144176, grad/param norm = 1.6497e-01, time/batch = 15.8358s	
23424/33250 (epoch 35.224), train_loss = 0.87153955, grad/param norm = 1.7869e-01, time/batch = 18.7717s	
23425/33250 (epoch 35.226), train_loss = 0.95205047, grad/param norm = 1.8484e-01, time/batch = 17.8583s	
23426/33250 (epoch 35.227), train_loss = 0.83891956, grad/param norm = 1.7266e-01, time/batch = 17.4467s	
23427/33250 (epoch 35.229), train_loss = 0.80371241, grad/param norm = 1.6316e-01, time/batch = 16.2766s	
23428/33250 (epoch 35.230), train_loss = 0.81148157, grad/param norm = 1.8240e-01, time/batch = 16.6218s	
23429/33250 (epoch 35.232), train_loss = 0.75836479, grad/param norm = 1.9452e-01, time/batch = 15.9403s	
23430/33250 (epoch 35.233), train_loss = 0.72431517, grad/param norm = 1.7038e-01, time/batch = 15.6847s	
23431/33250 (epoch 35.235), train_loss = 0.93707417, grad/param norm = 1.7244e-01, time/batch = 15.6627s	
23432/33250 (epoch 35.236), train_loss = 0.74629236, grad/param norm = 1.5740e-01, time/batch = 15.3688s	
23433/33250 (epoch 35.238), train_loss = 0.91250740, grad/param norm = 1.8939e-01, time/batch = 15.6281s	
23434/33250 (epoch 35.239), train_loss = 0.91917723, grad/param norm = 2.4374e-01, time/batch = 15.7516s	
23435/33250 (epoch 35.241), train_loss = 0.91938872, grad/param norm = 2.1617e-01, time/batch = 18.5374s	
23436/33250 (epoch 35.242), train_loss = 0.91908640, grad/param norm = 2.0600e-01, time/batch = 19.0932s	
23437/33250 (epoch 35.244), train_loss = 0.86498849, grad/param norm = 2.1935e-01, time/batch = 15.9506s	
23438/33250 (epoch 35.245), train_loss = 0.86748698, grad/param norm = 2.0844e-01, time/batch = 15.3548s	
23439/33250 (epoch 35.247), train_loss = 0.80242227, grad/param norm = 1.6858e-01, time/batch = 15.3549s	
23440/33250 (epoch 35.248), train_loss = 0.95926976, grad/param norm = 1.9230e-01, time/batch = 15.3686s	
23441/33250 (epoch 35.250), train_loss = 0.92060990, grad/param norm = 1.6431e-01, time/batch = 15.8654s	
23442/33250 (epoch 35.251), train_loss = 0.79488837, grad/param norm = 1.5775e-01, time/batch = 15.5293s	
23443/33250 (epoch 35.253), train_loss = 0.77187590, grad/param norm = 1.5521e-01, time/batch = 15.5226s	
23444/33250 (epoch 35.254), train_loss = 0.76612403, grad/param norm = 1.7015e-01, time/batch = 16.2527s	
23445/33250 (epoch 35.256), train_loss = 0.80403334, grad/param norm = 1.5731e-01, time/batch = 16.8547s	
23446/33250 (epoch 35.257), train_loss = 0.95828629, grad/param norm = 1.7659e-01, time/batch = 17.8532s	
23447/33250 (epoch 35.259), train_loss = 0.86537456, grad/param norm = 1.9015e-01, time/batch = 16.9475s	
23448/33250 (epoch 35.260), train_loss = 0.69015390, grad/param norm = 1.6812e-01, time/batch = 15.7686s	
23449/33250 (epoch 35.262), train_loss = 0.81404717, grad/param norm = 1.6645e-01, time/batch = 15.5177s	
23450/33250 (epoch 35.263), train_loss = 0.69957770, grad/param norm = 1.7126e-01, time/batch = 15.6183s	
23451/33250 (epoch 35.265), train_loss = 0.85882535, grad/param norm = 1.7721e-01, time/batch = 16.1093s	
23452/33250 (epoch 35.266), train_loss = 0.78237827, grad/param norm = 1.7405e-01, time/batch = 16.4263s	
23453/33250 (epoch 35.268), train_loss = 0.71866109, grad/param norm = 1.6990e-01, time/batch = 17.1026s	
23454/33250 (epoch 35.269), train_loss = 0.67793258, grad/param norm = 1.6366e-01, time/batch = 15.4554s	
23455/33250 (epoch 35.271), train_loss = 0.82410916, grad/param norm = 1.4760e-01, time/batch = 19.6823s	
23456/33250 (epoch 35.272), train_loss = 0.72916916, grad/param norm = 1.4515e-01, time/batch = 17.0072s	
23457/33250 (epoch 35.274), train_loss = 0.60772511, grad/param norm = 1.6435e-01, time/batch = 16.2591s	
23458/33250 (epoch 35.275), train_loss = 0.76136661, grad/param norm = 1.5089e-01, time/batch = 15.2852s	
23459/33250 (epoch 35.277), train_loss = 0.64023882, grad/param norm = 1.7091e-01, time/batch = 16.2669s	
23460/33250 (epoch 35.278), train_loss = 0.74028822, grad/param norm = 1.6427e-01, time/batch = 15.4387s	
23461/33250 (epoch 35.280), train_loss = 0.70314819, grad/param norm = 1.5564e-01, time/batch = 16.1166s	
23462/33250 (epoch 35.281), train_loss = 0.82134675, grad/param norm = 2.0249e-01, time/batch = 15.7717s	
23463/33250 (epoch 35.283), train_loss = 0.85942874, grad/param norm = 2.9041e-01, time/batch = 15.8484s	
23464/33250 (epoch 35.284), train_loss = 0.70256964, grad/param norm = 1.8826e-01, time/batch = 15.4557s	
23465/33250 (epoch 35.286), train_loss = 0.85034197, grad/param norm = 1.8454e-01, time/batch = 17.3078s	
23466/33250 (epoch 35.287), train_loss = 0.66875228, grad/param norm = 1.5778e-01, time/batch = 16.6868s	
23467/33250 (epoch 35.289), train_loss = 0.63437610, grad/param norm = 1.7539e-01, time/batch = 17.4451s	
23468/33250 (epoch 35.290), train_loss = 0.80301613, grad/param norm = 1.5831e-01, time/batch = 17.3650s	
23469/33250 (epoch 35.292), train_loss = 0.86284476, grad/param norm = 2.2629e-01, time/batch = 16.3735s	
23470/33250 (epoch 35.293), train_loss = 0.90453108, grad/param norm = 1.8582e-01, time/batch = 15.6898s	
23471/33250 (epoch 35.295), train_loss = 0.88757330, grad/param norm = 1.7229e-01, time/batch = 15.6709s	
23472/33250 (epoch 35.296), train_loss = 0.80585646, grad/param norm = 1.7547e-01, time/batch = 15.7738s	
23473/33250 (epoch 35.298), train_loss = 0.66925011, grad/param norm = 1.8032e-01, time/batch = 15.7662s	
23474/33250 (epoch 35.299), train_loss = 0.65198680, grad/param norm = 1.9317e-01, time/batch = 15.6833s	
23475/33250 (epoch 35.301), train_loss = 0.90349803, grad/param norm = 1.9085e-01, time/batch = 16.8640s	
23476/33250 (epoch 35.302), train_loss = 0.87065253, grad/param norm = 2.1672e-01, time/batch = 17.3771s	
23477/33250 (epoch 35.304), train_loss = 0.75388116, grad/param norm = 1.9110e-01, time/batch = 16.1255s	
23478/33250 (epoch 35.305), train_loss = 0.72025363, grad/param norm = 1.5534e-01, time/batch = 15.8747s	
23479/33250 (epoch 35.307), train_loss = 0.83866845, grad/param norm = 1.7271e-01, time/batch = 15.4500s	
23480/33250 (epoch 35.308), train_loss = 0.89579611, grad/param norm = 2.4031e-01, time/batch = 15.6016s	
23481/33250 (epoch 35.310), train_loss = 0.75586042, grad/param norm = 1.7600e-01, time/batch = 15.7527s	
23482/33250 (epoch 35.311), train_loss = 0.93887915, grad/param norm = 1.9709e-01, time/batch = 15.6774s	
23483/33250 (epoch 35.313), train_loss = 0.64211353, grad/param norm = 1.7453e-01, time/batch = 15.5133s	
23484/33250 (epoch 35.314), train_loss = 0.85174962, grad/param norm = 1.6376e-01, time/batch = 15.6241s	
23485/33250 (epoch 35.316), train_loss = 0.96617785, grad/param norm = 2.0590e-01, time/batch = 15.4355s	
23486/33250 (epoch 35.317), train_loss = 0.70870867, grad/param norm = 1.6152e-01, time/batch = 16.1880s	
23487/33250 (epoch 35.319), train_loss = 0.88324705, grad/param norm = 2.4992e-01, time/batch = 16.2976s	
23488/33250 (epoch 35.320), train_loss = 0.88474038, grad/param norm = 2.6165e-01, time/batch = 16.3841s	
23489/33250 (epoch 35.322), train_loss = 0.94302042, grad/param norm = 1.9324e-01, time/batch = 15.9474s	
23490/33250 (epoch 35.323), train_loss = 0.95158526, grad/param norm = 2.2856e-01, time/batch = 18.4436s	
23491/33250 (epoch 35.325), train_loss = 0.79557501, grad/param norm = 2.2678e-01, time/batch = 15.4403s	
23492/33250 (epoch 35.326), train_loss = 1.00439284, grad/param norm = 2.2612e-01, time/batch = 15.5184s	
23493/33250 (epoch 35.328), train_loss = 0.79654661, grad/param norm = 1.8787e-01, time/batch = 15.4295s	
23494/33250 (epoch 35.329), train_loss = 0.84627818, grad/param norm = 2.8954e-01, time/batch = 14.9479s	
23495/33250 (epoch 35.331), train_loss = 0.83402654, grad/param norm = 1.9969e-01, time/batch = 15.5186s	
23496/33250 (epoch 35.332), train_loss = 0.79969978, grad/param norm = 1.5446e-01, time/batch = 15.2295s	
23497/33250 (epoch 35.334), train_loss = 0.95867367, grad/param norm = 1.7255e-01, time/batch = 15.5975s	
23498/33250 (epoch 35.335), train_loss = 0.62117063, grad/param norm = 1.6134e-01, time/batch = 17.1106s	
23499/33250 (epoch 35.337), train_loss = 0.87811437, grad/param norm = 1.7365e-01, time/batch = 16.8525s	
23500/33250 (epoch 35.338), train_loss = 0.94114446, grad/param norm = 1.7077e-01, time/batch = 15.9355s	
23501/33250 (epoch 35.340), train_loss = 0.78572125, grad/param norm = 1.6448e-01, time/batch = 16.6790s	
23502/33250 (epoch 35.341), train_loss = 0.73896054, grad/param norm = 1.7182e-01, time/batch = 15.7657s	
23503/33250 (epoch 35.343), train_loss = 0.76636334, grad/param norm = 1.6830e-01, time/batch = 15.2009s	
23504/33250 (epoch 35.344), train_loss = 0.80043471, grad/param norm = 1.7542e-01, time/batch = 15.5933s	
23505/33250 (epoch 35.346), train_loss = 0.70406938, grad/param norm = 1.6983e-01, time/batch = 15.2818s	
23506/33250 (epoch 35.347), train_loss = 0.99621919, grad/param norm = 2.4327e-01, time/batch = 14.9452s	
23507/33250 (epoch 35.349), train_loss = 0.79295982, grad/param norm = 2.1158e-01, time/batch = 15.2004s	
23508/33250 (epoch 35.350), train_loss = 0.80411491, grad/param norm = 1.6954e-01, time/batch = 15.9918s	
23509/33250 (epoch 35.352), train_loss = 0.72892576, grad/param norm = 1.8126e-01, time/batch = 16.0129s	
23510/33250 (epoch 35.353), train_loss = 0.77767313, grad/param norm = 1.5407e-01, time/batch = 16.8557s	
23511/33250 (epoch 35.355), train_loss = 0.76509081, grad/param norm = 1.7875e-01, time/batch = 16.7759s	
23512/33250 (epoch 35.356), train_loss = 0.70995023, grad/param norm = 1.8265e-01, time/batch = 15.5340s	
23513/33250 (epoch 35.358), train_loss = 0.78060516, grad/param norm = 1.6759e-01, time/batch = 15.6039s	
23514/33250 (epoch 35.359), train_loss = 0.77342093, grad/param norm = 1.7600e-01, time/batch = 15.4362s	
23515/33250 (epoch 35.361), train_loss = 0.92828821, grad/param norm = 2.2039e-01, time/batch = 15.2571s	
23516/33250 (epoch 35.362), train_loss = 0.84500266, grad/param norm = 1.8213e-01, time/batch = 15.2051s	
23517/33250 (epoch 35.364), train_loss = 0.85405281, grad/param norm = 1.7507e-01, time/batch = 15.0361s	
23518/33250 (epoch 35.365), train_loss = 0.78870170, grad/param norm = 1.4995e-01, time/batch = 15.6557s	
23519/33250 (epoch 35.367), train_loss = 0.82115903, grad/param norm = 1.5481e-01, time/batch = 15.7779s	
23520/33250 (epoch 35.368), train_loss = 0.81379163, grad/param norm = 1.7710e-01, time/batch = 16.5063s	
23521/33250 (epoch 35.370), train_loss = 0.72257681, grad/param norm = 1.5176e-01, time/batch = 15.1887s	
23522/33250 (epoch 35.371), train_loss = 0.90342333, grad/param norm = 2.0095e-01, time/batch = 15.1890s	
23523/33250 (epoch 35.373), train_loss = 0.78572731, grad/param norm = 1.6728e-01, time/batch = 15.2728s	
23524/33250 (epoch 35.374), train_loss = 0.84408453, grad/param norm = 2.4377e-01, time/batch = 15.7011s	
23525/33250 (epoch 35.376), train_loss = 0.79938228, grad/param norm = 1.5604e-01, time/batch = 15.7853s	
23526/33250 (epoch 35.377), train_loss = 0.71063554, grad/param norm = 1.8563e-01, time/batch = 15.5397s	
23527/33250 (epoch 35.379), train_loss = 0.79864774, grad/param norm = 1.7741e-01, time/batch = 15.8239s	
23528/33250 (epoch 35.380), train_loss = 0.79640328, grad/param norm = 1.9195e-01, time/batch = 15.3498s	
23529/33250 (epoch 35.382), train_loss = 0.83769352, grad/param norm = 1.8543e-01, time/batch = 15.6226s	
23530/33250 (epoch 35.383), train_loss = 0.72316365, grad/param norm = 1.7307e-01, time/batch = 17.3402s	
23531/33250 (epoch 35.385), train_loss = 0.67223395, grad/param norm = 1.5718e-01, time/batch = 17.3564s	
23532/33250 (epoch 35.386), train_loss = 0.71098513, grad/param norm = 1.8576e-01, time/batch = 16.2990s	
23533/33250 (epoch 35.388), train_loss = 0.71488753, grad/param norm = 1.5918e-01, time/batch = 16.6942s	
23534/33250 (epoch 35.389), train_loss = 0.76401602, grad/param norm = 2.0247e-01, time/batch = 15.7399s	
23535/33250 (epoch 35.391), train_loss = 0.85502207, grad/param norm = 2.1621e-01, time/batch = 15.7503s	
23536/33250 (epoch 35.392), train_loss = 0.89557961, grad/param norm = 1.9701e-01, time/batch = 15.2622s	
23537/33250 (epoch 35.394), train_loss = 0.88682966, grad/param norm = 1.9869e-01, time/batch = 15.9234s	
23538/33250 (epoch 35.395), train_loss = 0.87543973, grad/param norm = 1.6975e-01, time/batch = 15.5288s	
23539/33250 (epoch 35.397), train_loss = 0.90037526, grad/param norm = 1.6253e-01, time/batch = 15.5091s	
23540/33250 (epoch 35.398), train_loss = 0.72413298, grad/param norm = 1.5329e-01, time/batch = 15.8622s	
23541/33250 (epoch 35.400), train_loss = 0.69681859, grad/param norm = 1.4482e-01, time/batch = 16.7643s	
23542/33250 (epoch 35.402), train_loss = 0.68844096, grad/param norm = 1.9291e-01, time/batch = 16.7698s	
23543/33250 (epoch 35.403), train_loss = 0.76722689, grad/param norm = 1.8078e-01, time/batch = 16.1303s	
23544/33250 (epoch 35.405), train_loss = 0.73658386, grad/param norm = 1.4289e-01, time/batch = 16.0229s	
23545/33250 (epoch 35.406), train_loss = 0.79121091, grad/param norm = 1.9071e-01, time/batch = 15.5218s	
23546/33250 (epoch 35.408), train_loss = 0.95863212, grad/param norm = 1.7664e-01, time/batch = 15.5225s	
23547/33250 (epoch 35.409), train_loss = 0.84427900, grad/param norm = 1.9756e-01, time/batch = 15.5023s	
23548/33250 (epoch 35.411), train_loss = 0.59781892, grad/param norm = 1.4201e-01, time/batch = 15.2788s	
23549/33250 (epoch 35.412), train_loss = 0.69078797, grad/param norm = 1.8677e-01, time/batch = 15.5853s	
23550/33250 (epoch 35.414), train_loss = 0.83652112, grad/param norm = 1.9293e-01, time/batch = 15.4036s	
23551/33250 (epoch 35.415), train_loss = 0.88043270, grad/param norm = 1.9480e-01, time/batch = 15.5184s	
23552/33250 (epoch 35.417), train_loss = 0.90236938, grad/param norm = 1.6232e-01, time/batch = 16.1433s	
23553/33250 (epoch 35.418), train_loss = 1.05992804, grad/param norm = 2.3655e-01, time/batch = 15.9174s	
23554/33250 (epoch 35.420), train_loss = 0.88435340, grad/param norm = 1.8841e-01, time/batch = 16.6249s	
23555/33250 (epoch 35.421), train_loss = 0.75559411, grad/param norm = 1.5344e-01, time/batch = 15.7676s	
23556/33250 (epoch 35.423), train_loss = 0.84588371, grad/param norm = 1.8917e-01, time/batch = 14.9513s	
23557/33250 (epoch 35.424), train_loss = 0.91896835, grad/param norm = 2.4767e-01, time/batch = 15.2560s	
23558/33250 (epoch 35.426), train_loss = 0.78420318, grad/param norm = 1.5679e-01, time/batch = 15.4980s	
23559/33250 (epoch 35.427), train_loss = 0.75323321, grad/param norm = 1.6616e-01, time/batch = 15.5954s	
23560/33250 (epoch 35.429), train_loss = 0.85100019, grad/param norm = 2.0649e-01, time/batch = 15.3626s	
23561/33250 (epoch 35.430), train_loss = 0.75051326, grad/param norm = 1.9048e-01, time/batch = 15.7280s	
23562/33250 (epoch 35.432), train_loss = 0.88188870, grad/param norm = 1.7297e-01, time/batch = 16.4538s	
23563/33250 (epoch 35.433), train_loss = 0.73609849, grad/param norm = 2.1806e-01, time/batch = 18.1941s	
23564/33250 (epoch 35.435), train_loss = 0.88160141, grad/param norm = 1.7360e-01, time/batch = 15.9416s	
23565/33250 (epoch 35.436), train_loss = 0.75554598, grad/param norm = 1.8445e-01, time/batch = 16.7786s	
23566/33250 (epoch 35.438), train_loss = 0.90074848, grad/param norm = 1.7740e-01, time/batch = 15.1088s	
23567/33250 (epoch 35.439), train_loss = 0.81035921, grad/param norm = 1.5938e-01, time/batch = 15.1053s	
23568/33250 (epoch 35.441), train_loss = 0.78235751, grad/param norm = 1.6074e-01, time/batch = 15.5082s	
23569/33250 (epoch 35.442), train_loss = 0.73949465, grad/param norm = 1.6635e-01, time/batch = 15.1799s	
23570/33250 (epoch 35.444), train_loss = 0.77092010, grad/param norm = 1.5684e-01, time/batch = 15.1877s	
23571/33250 (epoch 35.445), train_loss = 0.82232796, grad/param norm = 1.4524e-01, time/batch = 15.4307s	
23572/33250 (epoch 35.447), train_loss = 0.72844161, grad/param norm = 1.6287e-01, time/batch = 15.5283s	
23573/33250 (epoch 35.448), train_loss = 0.83077896, grad/param norm = 1.5620e-01, time/batch = 16.3588s	
23574/33250 (epoch 35.450), train_loss = 0.92062641, grad/param norm = 1.8999e-01, time/batch = 15.1726s	
23575/33250 (epoch 35.451), train_loss = 0.87874528, grad/param norm = 2.4043e-01, time/batch = 15.5301s	
23576/33250 (epoch 35.453), train_loss = 0.71906727, grad/param norm = 1.4790e-01, time/batch = 15.5053s	
23577/33250 (epoch 35.454), train_loss = 0.94242473, grad/param norm = 1.9119e-01, time/batch = 15.6126s	
23578/33250 (epoch 35.456), train_loss = 0.91306146, grad/param norm = 1.4918e-01, time/batch = 15.1996s	
23579/33250 (epoch 35.457), train_loss = 0.74266503, grad/param norm = 1.8090e-01, time/batch = 15.1072s	
23580/33250 (epoch 35.459), train_loss = 0.86773948, grad/param norm = 1.7097e-01, time/batch = 15.4267s	
23581/33250 (epoch 35.460), train_loss = 0.87830343, grad/param norm = 1.8112e-01, time/batch = 15.3572s	
23582/33250 (epoch 35.462), train_loss = 0.79363791, grad/param norm = 1.7624e-01, time/batch = 15.4312s	
23583/33250 (epoch 35.463), train_loss = 0.72587646, grad/param norm = 1.2908e-01, time/batch = 16.1044s	
23584/33250 (epoch 35.465), train_loss = 0.67926142, grad/param norm = 1.4272e-01, time/batch = 15.7770s	
23585/33250 (epoch 35.466), train_loss = 0.65583026, grad/param norm = 1.3196e-01, time/batch = 17.5937s	
23586/33250 (epoch 35.468), train_loss = 0.68890355, grad/param norm = 1.4222e-01, time/batch = 17.5935s	
23587/33250 (epoch 35.469), train_loss = 0.77791225, grad/param norm = 1.9635e-01, time/batch = 28.1497s	
23588/33250 (epoch 35.471), train_loss = 0.85604948, grad/param norm = 1.4556e-01, time/batch = 16.4933s	
23589/33250 (epoch 35.472), train_loss = 0.77517770, grad/param norm = 1.8385e-01, time/batch = 15.5203s	
23590/33250 (epoch 35.474), train_loss = 0.91703357, grad/param norm = 2.0137e-01, time/batch = 15.5900s	
23591/33250 (epoch 35.475), train_loss = 0.82846878, grad/param norm = 1.6774e-01, time/batch = 16.0531s	
23592/33250 (epoch 35.477), train_loss = 0.82260771, grad/param norm = 1.6075e-01, time/batch = 15.9857s	
23593/33250 (epoch 35.478), train_loss = 0.71455515, grad/param norm = 1.7176e-01, time/batch = 15.3667s	
23594/33250 (epoch 35.480), train_loss = 0.89850145, grad/param norm = 1.6657e-01, time/batch = 15.3817s	
23595/33250 (epoch 35.481), train_loss = 0.79406921, grad/param norm = 1.7054e-01, time/batch = 15.6176s	
23596/33250 (epoch 35.483), train_loss = 0.79534306, grad/param norm = 1.7654e-01, time/batch = 15.2185s	
23597/33250 (epoch 35.484), train_loss = 0.73264594, grad/param norm = 1.5776e-01, time/batch = 15.4387s	
23598/33250 (epoch 35.486), train_loss = 0.66556957, grad/param norm = 1.5883e-01, time/batch = 15.6662s	
23599/33250 (epoch 35.487), train_loss = 0.74306586, grad/param norm = 1.5477e-01, time/batch = 15.4909s	
23600/33250 (epoch 35.489), train_loss = 0.89019255, grad/param norm = 2.2760e-01, time/batch = 15.1027s	
23601/33250 (epoch 35.490), train_loss = 0.84242531, grad/param norm = 1.9704e-01, time/batch = 16.2641s	
23602/33250 (epoch 35.492), train_loss = 0.90452840, grad/param norm = 1.8738e-01, time/batch = 15.1919s	
23603/33250 (epoch 35.493), train_loss = 0.81153064, grad/param norm = 1.7278e-01, time/batch = 16.1182s	
23604/33250 (epoch 35.495), train_loss = 0.86596268, grad/param norm = 1.5652e-01, time/batch = 17.1944s	
23605/33250 (epoch 35.496), train_loss = 0.81903197, grad/param norm = 1.4914e-01, time/batch = 15.6959s	
23606/33250 (epoch 35.498), train_loss = 0.89245947, grad/param norm = 1.9498e-01, time/batch = 15.3646s	
23607/33250 (epoch 35.499), train_loss = 0.75732410, grad/param norm = 1.6997e-01, time/batch = 16.3647s	
23608/33250 (epoch 35.501), train_loss = 0.76449001, grad/param norm = 1.7719e-01, time/batch = 15.3683s	
23609/33250 (epoch 35.502), train_loss = 0.76504034, grad/param norm = 1.5485e-01, time/batch = 15.6890s	
23610/33250 (epoch 35.504), train_loss = 0.94329409, grad/param norm = 2.0085e-01, time/batch = 15.2809s	
23611/33250 (epoch 35.505), train_loss = 0.69226223, grad/param norm = 1.4108e-01, time/batch = 15.3561s	
23612/33250 (epoch 35.507), train_loss = 0.74261180, grad/param norm = 1.8137e-01, time/batch = 16.4253s	
23613/33250 (epoch 35.508), train_loss = 0.75899762, grad/param norm = 1.5300e-01, time/batch = 15.4305s	
23614/33250 (epoch 35.510), train_loss = 0.65907337, grad/param norm = 1.3306e-01, time/batch = 16.3512s	
23615/33250 (epoch 35.511), train_loss = 0.76992178, grad/param norm = 1.6421e-01, time/batch = 15.7860s	
23616/33250 (epoch 35.513), train_loss = 0.91976304, grad/param norm = 1.6331e-01, time/batch = 16.6713s	
23617/33250 (epoch 35.514), train_loss = 0.77370919, grad/param norm = 1.6634e-01, time/batch = 15.8520s	
23618/33250 (epoch 35.516), train_loss = 0.74974195, grad/param norm = 3.0465e-01, time/batch = 15.4455s	
23619/33250 (epoch 35.517), train_loss = 0.77285423, grad/param norm = 1.6266e-01, time/batch = 15.6954s	
23620/33250 (epoch 35.519), train_loss = 0.70815010, grad/param norm = 1.2537e-01, time/batch = 15.6664s	
23621/33250 (epoch 35.520), train_loss = 0.98330800, grad/param norm = 2.2003e-01, time/batch = 15.9449s	
23622/33250 (epoch 35.522), train_loss = 0.85336794, grad/param norm = 1.7756e-01, time/batch = 15.4470s	
23623/33250 (epoch 35.523), train_loss = 0.73017986, grad/param norm = 1.6471e-01, time/batch = 15.0330s	
23624/33250 (epoch 35.525), train_loss = 0.67924935, grad/param norm = 1.6298e-01, time/batch = 15.5691s	
23625/33250 (epoch 35.526), train_loss = 0.71845941, grad/param norm = 1.5718e-01, time/batch = 15.6909s	
23626/33250 (epoch 35.528), train_loss = 0.76505554, grad/param norm = 1.6178e-01, time/batch = 15.8503s	
23627/33250 (epoch 35.529), train_loss = 0.75257857, grad/param norm = 1.7622e-01, time/batch = 16.8479s	
23628/33250 (epoch 35.531), train_loss = 0.71636161, grad/param norm = 1.5627e-01, time/batch = 15.5979s	
23629/33250 (epoch 35.532), train_loss = 0.84816224, grad/param norm = 1.6088e-01, time/batch = 15.6855s	
23630/33250 (epoch 35.534), train_loss = 0.72028313, grad/param norm = 1.4210e-01, time/batch = 15.3648s	
23631/33250 (epoch 35.535), train_loss = 0.76924533, grad/param norm = 1.5015e-01, time/batch = 15.7558s	
23632/33250 (epoch 35.537), train_loss = 0.81891964, grad/param norm = 1.6913e-01, time/batch = 15.1868s	
23633/33250 (epoch 35.538), train_loss = 0.84402283, grad/param norm = 1.7923e-01, time/batch = 15.6960s	
23634/33250 (epoch 35.540), train_loss = 0.93280061, grad/param norm = 1.5213e-01, time/batch = 15.5960s	
23635/33250 (epoch 35.541), train_loss = 0.85446192, grad/param norm = 1.8660e-01, time/batch = 15.6689s	
23636/33250 (epoch 35.543), train_loss = 0.83295473, grad/param norm = 1.5593e-01, time/batch = 16.4532s	
23637/33250 (epoch 35.544), train_loss = 0.70252283, grad/param norm = 1.7118e-01, time/batch = 16.0542s	
23638/33250 (epoch 35.546), train_loss = 0.75325326, grad/param norm = 2.0004e-01, time/batch = 15.6231s	
23639/33250 (epoch 35.547), train_loss = 0.76320103, grad/param norm = 1.8810e-01, time/batch = 15.6140s	
23640/33250 (epoch 35.549), train_loss = 0.81030295, grad/param norm = 1.7532e-01, time/batch = 15.4490s	
23641/33250 (epoch 35.550), train_loss = 0.76576448, grad/param norm = 1.6487e-01, time/batch = 15.4522s	
23642/33250 (epoch 35.552), train_loss = 0.83721244, grad/param norm = 1.5836e-01, time/batch = 15.4557s	
23643/33250 (epoch 35.553), train_loss = 0.77515197, grad/param norm = 1.6460e-01, time/batch = 15.5006s	
23644/33250 (epoch 35.555), train_loss = 0.81766297, grad/param norm = 1.6083e-01, time/batch = 15.4315s	
23645/33250 (epoch 35.556), train_loss = 0.80179785, grad/param norm = 2.0070e-01, time/batch = 15.1232s	
23646/33250 (epoch 35.558), train_loss = 0.84477707, grad/param norm = 1.8301e-01, time/batch = 15.7598s	
23647/33250 (epoch 35.559), train_loss = 0.73217129, grad/param norm = 1.6040e-01, time/batch = 15.5940s	
23648/33250 (epoch 35.561), train_loss = 0.70384794, grad/param norm = 1.5413e-01, time/batch = 15.9607s	
23649/33250 (epoch 35.562), train_loss = 0.79279708, grad/param norm = 1.7865e-01, time/batch = 17.1225s	
23650/33250 (epoch 35.564), train_loss = 0.97101093, grad/param norm = 2.1368e-01, time/batch = 15.4445s	
23651/33250 (epoch 35.565), train_loss = 0.92173765, grad/param norm = 2.3804e-01, time/batch = 15.5304s	
23652/33250 (epoch 35.567), train_loss = 0.90947465, grad/param norm = 1.8894e-01, time/batch = 15.4506s	
23653/33250 (epoch 35.568), train_loss = 0.76140525, grad/param norm = 1.6168e-01, time/batch = 16.1801s	
23654/33250 (epoch 35.570), train_loss = 0.88058432, grad/param norm = 2.1796e-01, time/batch = 15.7751s	
23655/33250 (epoch 35.571), train_loss = 0.90833357, grad/param norm = 1.6594e-01, time/batch = 15.2807s	
23656/33250 (epoch 35.573), train_loss = 0.87667668, grad/param norm = 2.0331e-01, time/batch = 15.8430s	
23657/33250 (epoch 35.574), train_loss = 0.74962614, grad/param norm = 1.5133e-01, time/batch = 15.2717s	
23658/33250 (epoch 35.576), train_loss = 0.85589845, grad/param norm = 1.7248e-01, time/batch = 15.2802s	
23659/33250 (epoch 35.577), train_loss = 0.79210950, grad/param norm = 1.5503e-01, time/batch = 17.6011s	
23660/33250 (epoch 35.579), train_loss = 0.68380249, grad/param norm = 1.4571e-01, time/batch = 16.5518s	
23661/33250 (epoch 35.580), train_loss = 0.80344897, grad/param norm = 1.7189e-01, time/batch = 18.8428s	
23662/33250 (epoch 35.582), train_loss = 0.76295672, grad/param norm = 1.7335e-01, time/batch = 15.8481s	
23663/33250 (epoch 35.583), train_loss = 0.86725998, grad/param norm = 1.6294e-01, time/batch = 15.3576s	
23664/33250 (epoch 35.585), train_loss = 0.90275665, grad/param norm = 1.6586e-01, time/batch = 15.4497s	
23665/33250 (epoch 35.586), train_loss = 0.76313085, grad/param norm = 1.8794e-01, time/batch = 15.5778s	
23666/33250 (epoch 35.588), train_loss = 0.84353420, grad/param norm = 1.6865e-01, time/batch = 15.9985s	
23667/33250 (epoch 35.589), train_loss = 0.80220255, grad/param norm = 1.6246e-01, time/batch = 15.7653s	
23668/33250 (epoch 35.591), train_loss = 0.79410409, grad/param norm = 2.0559e-01, time/batch = 15.6848s	
23669/33250 (epoch 35.592), train_loss = 0.76476221, grad/param norm = 1.8577e-01, time/batch = 15.5082s	
23670/33250 (epoch 35.594), train_loss = 0.90515547, grad/param norm = 2.0769e-01, time/batch = 15.7829s	
23671/33250 (epoch 35.595), train_loss = 0.80356368, grad/param norm = 1.6766e-01, time/batch = 16.5186s	
23672/33250 (epoch 35.597), train_loss = 0.67815486, grad/param norm = 1.4497e-01, time/batch = 15.8689s	
23673/33250 (epoch 35.598), train_loss = 0.76767246, grad/param norm = 1.6942e-01, time/batch = 15.7080s	
23674/33250 (epoch 35.600), train_loss = 0.77524236, grad/param norm = 2.1798e-01, time/batch = 15.5359s	
23675/33250 (epoch 35.602), train_loss = 0.82157200, grad/param norm = 1.9962e-01, time/batch = 15.5139s	
23676/33250 (epoch 35.603), train_loss = 0.83749970, grad/param norm = 1.7688e-01, time/batch = 15.5257s	
23677/33250 (epoch 35.605), train_loss = 0.79809634, grad/param norm = 1.6462e-01, time/batch = 15.5324s	
23678/33250 (epoch 35.606), train_loss = 0.86162998, grad/param norm = 1.8305e-01, time/batch = 15.2815s	
23679/33250 (epoch 35.608), train_loss = 0.82619676, grad/param norm = 1.6253e-01, time/batch = 15.7100s	
23680/33250 (epoch 35.609), train_loss = 0.70796813, grad/param norm = 1.7824e-01, time/batch = 15.6097s	
23681/33250 (epoch 35.611), train_loss = 0.77319618, grad/param norm = 1.7650e-01, time/batch = 16.1672s	
23682/33250 (epoch 35.612), train_loss = 0.77740132, grad/param norm = 1.7274e-01, time/batch = 16.0317s	
23683/33250 (epoch 35.614), train_loss = 0.99952754, grad/param norm = 1.9824e-01, time/batch = 15.4354s	
23684/33250 (epoch 35.615), train_loss = 0.91231963, grad/param norm = 1.8403e-01, time/batch = 15.4482s	
23685/33250 (epoch 35.617), train_loss = 1.01134808, grad/param norm = 1.9627e-01, time/batch = 15.7530s	
23686/33250 (epoch 35.618), train_loss = 1.04112735, grad/param norm = 2.4864e-01, time/batch = 15.7110s	
23687/33250 (epoch 35.620), train_loss = 0.88993505, grad/param norm = 1.8553e-01, time/batch = 15.7683s	
23688/33250 (epoch 35.621), train_loss = 0.86468593, grad/param norm = 1.8061e-01, time/batch = 16.0156s	
23689/33250 (epoch 35.623), train_loss = 0.76261692, grad/param norm = 1.7804e-01, time/batch = 15.7814s	
23690/33250 (epoch 35.624), train_loss = 0.78220364, grad/param norm = 2.0089e-01, time/batch = 15.2779s	
23691/33250 (epoch 35.626), train_loss = 0.79800516, grad/param norm = 2.2018e-01, time/batch = 15.5435s	
23692/33250 (epoch 35.627), train_loss = 0.77430801, grad/param norm = 1.6327e-01, time/batch = 15.8453s	
23693/33250 (epoch 35.629), train_loss = 0.84436172, grad/param norm = 1.9033e-01, time/batch = 15.6242s	
23694/33250 (epoch 35.630), train_loss = 0.77445065, grad/param norm = 1.9688e-01, time/batch = 15.5108s	
23695/33250 (epoch 35.632), train_loss = 0.71249851, grad/param norm = 1.5952e-01, time/batch = 15.7038s	
23696/33250 (epoch 35.633), train_loss = 0.80341692, grad/param norm = 1.6656e-01, time/batch = 15.6877s	
23697/33250 (epoch 35.635), train_loss = 0.73679120, grad/param norm = 1.5683e-01, time/batch = 15.6129s	
23698/33250 (epoch 35.636), train_loss = 0.76005877, grad/param norm = 1.5331e-01, time/batch = 15.8669s	
23699/33250 (epoch 35.638), train_loss = 0.72987406, grad/param norm = 1.7423e-01, time/batch = 15.6201s	
23700/33250 (epoch 35.639), train_loss = 0.67785457, grad/param norm = 1.6123e-01, time/batch = 15.6026s	
23701/33250 (epoch 35.641), train_loss = 0.77940607, grad/param norm = 1.7098e-01, time/batch = 15.4557s	
23702/33250 (epoch 35.642), train_loss = 0.61268983, grad/param norm = 1.6579e-01, time/batch = 15.5120s	
23703/33250 (epoch 35.644), train_loss = 0.56279262, grad/param norm = 1.4284e-01, time/batch = 15.9320s	
23704/33250 (epoch 35.645), train_loss = 0.83117995, grad/param norm = 1.9945e-01, time/batch = 15.5588s	
23705/33250 (epoch 35.647), train_loss = 0.70689188, grad/param norm = 1.8885e-01, time/batch = 16.6967s	
23706/33250 (epoch 35.648), train_loss = 0.69025618, grad/param norm = 1.6580e-01, time/batch = 15.7859s	
23707/33250 (epoch 35.650), train_loss = 0.92709985, grad/param norm = 2.6570e-01, time/batch = 15.4398s	
23708/33250 (epoch 35.651), train_loss = 0.83865866, grad/param norm = 1.9849e-01, time/batch = 15.2970s	
23709/33250 (epoch 35.653), train_loss = 0.75099243, grad/param norm = 1.6104e-01, time/batch = 15.5328s	
23710/33250 (epoch 35.654), train_loss = 0.80010320, grad/param norm = 1.8780e-01, time/batch = 15.4593s	
23711/33250 (epoch 35.656), train_loss = 0.83744508, grad/param norm = 1.6006e-01, time/batch = 15.6225s	
23712/33250 (epoch 35.657), train_loss = 0.64123704, grad/param norm = 2.0503e-01, time/batch = 15.6926s	
23713/33250 (epoch 35.659), train_loss = 0.75038647, grad/param norm = 1.6933e-01, time/batch = 15.7794s	
23714/33250 (epoch 35.660), train_loss = 0.82737535, grad/param norm = 1.9694e-01, time/batch = 17.1860s	
23715/33250 (epoch 35.662), train_loss = 0.82027216, grad/param norm = 1.7358e-01, time/batch = 15.9086s	
23716/33250 (epoch 35.663), train_loss = 0.73951435, grad/param norm = 1.7741e-01, time/batch = 15.7885s	
23717/33250 (epoch 35.665), train_loss = 0.82589151, grad/param norm = 1.7073e-01, time/batch = 15.5280s	
23718/33250 (epoch 35.666), train_loss = 0.74674697, grad/param norm = 1.4771e-01, time/batch = 16.2668s	
23719/33250 (epoch 35.668), train_loss = 0.89435277, grad/param norm = 1.7125e-01, time/batch = 15.8527s	
23720/33250 (epoch 35.669), train_loss = 0.80500900, grad/param norm = 1.6191e-01, time/batch = 16.7865s	
23721/33250 (epoch 35.671), train_loss = 0.71205725, grad/param norm = 2.3512e-01, time/batch = 16.6358s	
23722/33250 (epoch 35.672), train_loss = 0.88427316, grad/param norm = 1.7388e-01, time/batch = 16.0236s	
23723/33250 (epoch 35.674), train_loss = 0.70421258, grad/param norm = 1.5608e-01, time/batch = 15.6184s	
23724/33250 (epoch 35.675), train_loss = 0.79879553, grad/param norm = 1.4264e-01, time/batch = 15.6048s	
23725/33250 (epoch 35.677), train_loss = 0.86546951, grad/param norm = 1.7436e-01, time/batch = 15.6829s	
23726/33250 (epoch 35.678), train_loss = 0.74744292, grad/param norm = 1.6777e-01, time/batch = 15.6004s	
23727/33250 (epoch 35.680), train_loss = 0.91663506, grad/param norm = 2.2494e-01, time/batch = 15.6735s	
23728/33250 (epoch 35.681), train_loss = 0.73226432, grad/param norm = 1.6974e-01, time/batch = 15.7834s	
23729/33250 (epoch 35.683), train_loss = 0.73757723, grad/param norm = 1.8048e-01, time/batch = 15.1253s	
23730/33250 (epoch 35.684), train_loss = 0.69507165, grad/param norm = 1.7645e-01, time/batch = 15.5996s	
23731/33250 (epoch 35.686), train_loss = 0.71143036, grad/param norm = 1.6161e-01, time/batch = 16.3665s	
23732/33250 (epoch 35.687), train_loss = 0.82362126, grad/param norm = 1.7679e-01, time/batch = 15.6138s	
23733/33250 (epoch 35.689), train_loss = 0.69652998, grad/param norm = 1.7922e-01, time/batch = 15.8556s	
23734/33250 (epoch 35.690), train_loss = 0.81662659, grad/param norm = 1.8140e-01, time/batch = 16.6821s	
23735/33250 (epoch 35.692), train_loss = 0.75819822, grad/param norm = 1.5393e-01, time/batch = 15.5436s	
23736/33250 (epoch 35.693), train_loss = 0.84658147, grad/param norm = 1.6720e-01, time/batch = 16.1206s	
23737/33250 (epoch 35.695), train_loss = 0.82317020, grad/param norm = 1.8880e-01, time/batch = 15.9197s	
23738/33250 (epoch 35.696), train_loss = 0.84327251, grad/param norm = 1.8087e-01, time/batch = 15.7213s	
23739/33250 (epoch 35.698), train_loss = 0.76216130, grad/param norm = 1.6360e-01, time/batch = 14.9842s	
23740/33250 (epoch 35.699), train_loss = 1.02560679, grad/param norm = 1.8128e-01, time/batch = 15.6029s	
23741/33250 (epoch 35.701), train_loss = 0.80187713, grad/param norm = 1.5060e-01, time/batch = 16.0776s	
23742/33250 (epoch 35.702), train_loss = 0.77762131, grad/param norm = 2.7229e-01, time/batch = 15.7357s	
23743/33250 (epoch 35.704), train_loss = 1.01544540, grad/param norm = 2.8778e-01, time/batch = 15.7402s	
23744/33250 (epoch 35.705), train_loss = 0.76932370, grad/param norm = 1.7076e-01, time/batch = 15.8263s	
23745/33250 (epoch 35.707), train_loss = 0.67304143, grad/param norm = 1.5697e-01, time/batch = 15.7448s	
23746/33250 (epoch 35.708), train_loss = 0.87890853, grad/param norm = 1.8581e-01, time/batch = 15.8464s	
23747/33250 (epoch 35.710), train_loss = 0.82270126, grad/param norm = 1.8989e-01, time/batch = 15.6199s	
23748/33250 (epoch 35.711), train_loss = 0.71718215, grad/param norm = 1.6695e-01, time/batch = 16.1797s	
23749/33250 (epoch 35.713), train_loss = 0.83089531, grad/param norm = 1.6056e-01, time/batch = 15.7812s	
23750/33250 (epoch 35.714), train_loss = 0.79434045, grad/param norm = 1.8469e-01, time/batch = 15.6259s	
23751/33250 (epoch 35.716), train_loss = 0.81907775, grad/param norm = 1.7454e-01, time/batch = 16.0312s	
23752/33250 (epoch 35.717), train_loss = 0.76110787, grad/param norm = 1.5204e-01, time/batch = 15.6889s	
23753/33250 (epoch 35.719), train_loss = 0.72692008, grad/param norm = 1.6387e-01, time/batch = 16.0948s	
23754/33250 (epoch 35.720), train_loss = 1.00622677, grad/param norm = 1.7769e-01, time/batch = 15.5063s	
23755/33250 (epoch 35.722), train_loss = 0.68901115, grad/param norm = 1.4934e-01, time/batch = 15.6202s	
23756/33250 (epoch 35.723), train_loss = 0.61798545, grad/param norm = 1.4048e-01, time/batch = 15.7368s	
23757/33250 (epoch 35.725), train_loss = 0.75757738, grad/param norm = 1.4762e-01, time/batch = 16.7027s	
23758/33250 (epoch 35.726), train_loss = 0.80360887, grad/param norm = 1.6971e-01, time/batch = 16.2994s	
23759/33250 (epoch 35.728), train_loss = 0.82585568, grad/param norm = 1.7697e-01, time/batch = 18.4403s	
23760/33250 (epoch 35.729), train_loss = 0.87845993, grad/param norm = 1.8670e-01, time/batch = 16.5168s	
23761/33250 (epoch 35.731), train_loss = 0.71118918, grad/param norm = 1.6215e-01, time/batch = 15.7789s	
23762/33250 (epoch 35.732), train_loss = 0.71872549, grad/param norm = 1.5196e-01, time/batch = 15.7538s	
23763/33250 (epoch 35.734), train_loss = 0.81796955, grad/param norm = 2.5283e-01, time/batch = 15.8252s	
23764/33250 (epoch 35.735), train_loss = 0.82276483, grad/param norm = 1.8057e-01, time/batch = 16.2712s	
23765/33250 (epoch 35.737), train_loss = 0.76920463, grad/param norm = 1.5276e-01, time/batch = 15.6032s	
23766/33250 (epoch 35.738), train_loss = 0.82565251, grad/param norm = 1.6048e-01, time/batch = 15.5393s	
23767/33250 (epoch 35.740), train_loss = 0.82667683, grad/param norm = 1.7914e-01, time/batch = 15.8430s	
23768/33250 (epoch 35.741), train_loss = 0.84282435, grad/param norm = 1.7167e-01, time/batch = 17.1817s	
23769/33250 (epoch 35.743), train_loss = 0.74779590, grad/param norm = 1.5678e-01, time/batch = 15.2090s	
23770/33250 (epoch 35.744), train_loss = 0.74895809, grad/param norm = 1.7111e-01, time/batch = 15.1271s	
23771/33250 (epoch 35.746), train_loss = 0.71579670, grad/param norm = 1.6115e-01, time/batch = 15.5819s	
23772/33250 (epoch 35.747), train_loss = 0.71962066, grad/param norm = 1.6441e-01, time/batch = 15.6612s	
23773/33250 (epoch 35.749), train_loss = 0.90874762, grad/param norm = 2.8061e-01, time/batch = 15.5789s	
23774/33250 (epoch 35.750), train_loss = 0.90054401, grad/param norm = 1.8499e-01, time/batch = 15.1845s	
23775/33250 (epoch 35.752), train_loss = 0.76119080, grad/param norm = 1.6064e-01, time/batch = 15.5017s	
23776/33250 (epoch 35.753), train_loss = 0.73414112, grad/param norm = 1.6574e-01, time/batch = 14.7767s	
23777/33250 (epoch 35.755), train_loss = 0.69769791, grad/param norm = 1.7902e-01, time/batch = 15.0183s	
23778/33250 (epoch 35.756), train_loss = 0.80355517, grad/param norm = 1.9442e-01, time/batch = 15.4106s	
23779/33250 (epoch 35.758), train_loss = 0.96196845, grad/param norm = 1.7401e-01, time/batch = 15.7375s	
23780/33250 (epoch 35.759), train_loss = 0.74693862, grad/param norm = 1.6375e-01, time/batch = 16.1799s	
23781/33250 (epoch 35.761), train_loss = 0.82988278, grad/param norm = 1.8643e-01, time/batch = 15.8627s	
23782/33250 (epoch 35.762), train_loss = 0.86816686, grad/param norm = 1.7154e-01, time/batch = 15.7693s	
23783/33250 (epoch 35.764), train_loss = 0.71682188, grad/param norm = 2.6542e-01, time/batch = 15.8633s	
23784/33250 (epoch 35.765), train_loss = 0.85891042, grad/param norm = 2.0893e-01, time/batch = 15.1157s	
23785/33250 (epoch 35.767), train_loss = 0.63757700, grad/param norm = 1.5921e-01, time/batch = 15.6025s	
23786/33250 (epoch 35.768), train_loss = 0.68370352, grad/param norm = 1.6811e-01, time/batch = 15.9444s	
23787/33250 (epoch 35.770), train_loss = 0.83827657, grad/param norm = 1.9717e-01, time/batch = 16.5285s	
23788/33250 (epoch 35.771), train_loss = 0.85052611, grad/param norm = 1.7522e-01, time/batch = 15.4491s	
23789/33250 (epoch 35.773), train_loss = 0.78742503, grad/param norm = 1.7534e-01, time/batch = 15.5146s	
23790/33250 (epoch 35.774), train_loss = 0.67805189, grad/param norm = 1.7870e-01, time/batch = 15.4474s	
23791/33250 (epoch 35.776), train_loss = 0.76461804, grad/param norm = 1.7300e-01, time/batch = 15.9504s	
23792/33250 (epoch 35.777), train_loss = 0.90453469, grad/param norm = 2.0259e-01, time/batch = 16.2047s	
23793/33250 (epoch 35.779), train_loss = 0.77358420, grad/param norm = 1.7390e-01, time/batch = 15.6151s	
23794/33250 (epoch 35.780), train_loss = 0.92646500, grad/param norm = 2.0357e-01, time/batch = 16.3558s	
23795/33250 (epoch 35.782), train_loss = 0.79306356, grad/param norm = 1.9012e-01, time/batch = 15.9497s	
23796/33250 (epoch 35.783), train_loss = 0.65144673, grad/param norm = 1.6419e-01, time/batch = 15.8178s	
23797/33250 (epoch 35.785), train_loss = 0.70517374, grad/param norm = 1.9521e-01, time/batch = 15.5328s	
23798/33250 (epoch 35.786), train_loss = 0.89688469, grad/param norm = 1.8305e-01, time/batch = 15.5142s	
23799/33250 (epoch 35.788), train_loss = 0.89804794, grad/param norm = 1.8022e-01, time/batch = 15.6854s	
23800/33250 (epoch 35.789), train_loss = 0.88695779, grad/param norm = 2.1749e-01, time/batch = 15.7499s	
23801/33250 (epoch 35.791), train_loss = 0.92922186, grad/param norm = 2.1086e-01, time/batch = 15.6708s	
23802/33250 (epoch 35.792), train_loss = 0.97093740, grad/param norm = 1.9366e-01, time/batch = 16.3684s	
23803/33250 (epoch 35.794), train_loss = 0.78388094, grad/param norm = 1.9160e-01, time/batch = 15.6435s	
23804/33250 (epoch 35.795), train_loss = 0.80109662, grad/param norm = 1.8200e-01, time/batch = 15.8329s	
23805/33250 (epoch 35.797), train_loss = 0.85964508, grad/param norm = 1.9268e-01, time/batch = 15.6098s	
23806/33250 (epoch 35.798), train_loss = 0.77816547, grad/param norm = 2.0393e-01, time/batch = 15.9274s	
23807/33250 (epoch 35.800), train_loss = 0.82822382, grad/param norm = 1.7839e-01, time/batch = 15.3673s	
23808/33250 (epoch 35.802), train_loss = 0.79719628, grad/param norm = 1.5550e-01, time/batch = 15.3686s	
23809/33250 (epoch 35.803), train_loss = 0.83579065, grad/param norm = 1.6377e-01, time/batch = 15.6764s	
23810/33250 (epoch 35.805), train_loss = 0.82071749, grad/param norm = 1.6568e-01, time/batch = 15.2109s	
23811/33250 (epoch 35.806), train_loss = 0.81121122, grad/param norm = 1.6657e-01, time/batch = 15.9333s	
23812/33250 (epoch 35.808), train_loss = 0.72930710, grad/param norm = 1.8301e-01, time/batch = 15.2918s	
23813/33250 (epoch 35.809), train_loss = 0.71026212, grad/param norm = 1.4835e-01, time/batch = 28.4152s	
23814/33250 (epoch 35.811), train_loss = 0.70879237, grad/param norm = 1.6810e-01, time/batch = 16.4998s	
23815/33250 (epoch 35.812), train_loss = 0.84499047, grad/param norm = 1.9173e-01, time/batch = 15.3836s	
23816/33250 (epoch 35.814), train_loss = 0.76076953, grad/param norm = 1.8477e-01, time/batch = 15.5789s	
23817/33250 (epoch 35.815), train_loss = 0.83959101, grad/param norm = 1.6961e-01, time/batch = 15.2675s	
23818/33250 (epoch 35.817), train_loss = 0.78611149, grad/param norm = 1.6451e-01, time/batch = 15.7398s	
23819/33250 (epoch 35.818), train_loss = 0.74161402, grad/param norm = 1.6665e-01, time/batch = 15.5112s	
23820/33250 (epoch 35.820), train_loss = 0.83239477, grad/param norm = 1.9278e-01, time/batch = 15.4349s	
23821/33250 (epoch 35.821), train_loss = 0.78961523, grad/param norm = 1.6518e-01, time/batch = 15.4325s	
23822/33250 (epoch 35.823), train_loss = 1.07610243, grad/param norm = 2.0539e-01, time/batch = 15.5214s	
23823/33250 (epoch 35.824), train_loss = 0.72656598, grad/param norm = 1.6859e-01, time/batch = 15.6044s	
23824/33250 (epoch 35.826), train_loss = 0.82856460, grad/param norm = 1.7405e-01, time/batch = 15.5114s	
23825/33250 (epoch 35.827), train_loss = 0.72117085, grad/param norm = 1.7648e-01, time/batch = 15.9579s	
23826/33250 (epoch 35.829), train_loss = 0.82232022, grad/param norm = 1.7486e-01, time/batch = 15.4592s	
23827/33250 (epoch 35.830), train_loss = 0.87710935, grad/param norm = 2.5017e-01, time/batch = 15.7417s	
23828/33250 (epoch 35.832), train_loss = 0.83537487, grad/param norm = 1.8990e-01, time/batch = 15.6062s	
23829/33250 (epoch 35.833), train_loss = 0.79608890, grad/param norm = 1.6871e-01, time/batch = 15.5965s	
23830/33250 (epoch 35.835), train_loss = 0.73343100, grad/param norm = 2.2197e-01, time/batch = 15.1123s	
23831/33250 (epoch 35.836), train_loss = 0.78810259, grad/param norm = 1.8292e-01, time/batch = 15.6819s	
23832/33250 (epoch 35.838), train_loss = 0.83778181, grad/param norm = 1.6940e-01, time/batch = 15.7757s	
23833/33250 (epoch 35.839), train_loss = 0.75590216, grad/param norm = 1.5763e-01, time/batch = 15.5074s	
23834/33250 (epoch 35.841), train_loss = 0.76306430, grad/param norm = 1.6330e-01, time/batch = 15.4758s	
23835/33250 (epoch 35.842), train_loss = 0.93243508, grad/param norm = 1.7245e-01, time/batch = 15.8756s	
23836/33250 (epoch 35.844), train_loss = 0.87743307, grad/param norm = 1.9221e-01, time/batch = 15.7112s	
23837/33250 (epoch 35.845), train_loss = 0.96325152, grad/param norm = 1.9767e-01, time/batch = 15.3330s	
23838/33250 (epoch 35.847), train_loss = 0.93489764, grad/param norm = 1.8387e-01, time/batch = 15.9822s	
23839/33250 (epoch 35.848), train_loss = 1.00709180, grad/param norm = 2.3921e-01, time/batch = 15.4370s	
23840/33250 (epoch 35.850), train_loss = 0.89781188, grad/param norm = 1.9016e-01, time/batch = 15.4372s	
23841/33250 (epoch 35.851), train_loss = 0.71029052, grad/param norm = 1.8743e-01, time/batch = 15.7704s	
23842/33250 (epoch 35.853), train_loss = 0.83979331, grad/param norm = 2.0235e-01, time/batch = 15.6749s	
23843/33250 (epoch 35.854), train_loss = 0.78360234, grad/param norm = 1.6606e-01, time/batch = 16.0941s	
23844/33250 (epoch 35.856), train_loss = 0.74691068, grad/param norm = 2.2189e-01, time/batch = 16.7762s	
23845/33250 (epoch 35.857), train_loss = 0.69236346, grad/param norm = 1.8339e-01, time/batch = 16.8690s	
23846/33250 (epoch 35.859), train_loss = 0.76165070, grad/param norm = 1.7566e-01, time/batch = 16.6139s	
23847/33250 (epoch 35.860), train_loss = 0.83453685, grad/param norm = 1.6612e-01, time/batch = 14.6432s	
23848/33250 (epoch 35.862), train_loss = 0.72548010, grad/param norm = 1.6855e-01, time/batch = 17.1978s	
23849/33250 (epoch 35.863), train_loss = 0.76111736, grad/param norm = 2.1158e-01, time/batch = 15.1824s	
23850/33250 (epoch 35.865), train_loss = 0.83632078, grad/param norm = 1.8509e-01, time/batch = 15.1063s	
23851/33250 (epoch 35.866), train_loss = 0.71064411, grad/param norm = 1.6249e-01, time/batch = 15.4050s	
23852/33250 (epoch 35.868), train_loss = 0.80293607, grad/param norm = 2.0887e-01, time/batch = 15.4252s	
23853/33250 (epoch 35.869), train_loss = 0.83148393, grad/param norm = 1.8873e-01, time/batch = 15.1815s	
23854/33250 (epoch 35.871), train_loss = 0.64959857, grad/param norm = 1.6946e-01, time/batch = 15.5969s	
23855/33250 (epoch 35.872), train_loss = 0.86595664, grad/param norm = 1.9532e-01, time/batch = 17.5231s	
23856/33250 (epoch 35.874), train_loss = 0.74383918, grad/param norm = 1.7793e-01, time/batch = 17.2029s	
23857/33250 (epoch 35.875), train_loss = 0.68371741, grad/param norm = 2.6094e-01, time/batch = 15.9084s	
23858/33250 (epoch 35.877), train_loss = 0.89454807, grad/param norm = 1.6531e-01, time/batch = 17.4505s	
23859/33250 (epoch 35.878), train_loss = 0.80667845, grad/param norm = 1.9644e-01, time/batch = 15.1776s	
23860/33250 (epoch 35.880), train_loss = 0.80109124, grad/param norm = 1.9561e-01, time/batch = 15.9345s	
23861/33250 (epoch 35.881), train_loss = 0.90511444, grad/param norm = 1.7079e-01, time/batch = 15.3570s	
23862/33250 (epoch 35.883), train_loss = 0.84069785, grad/param norm = 1.7688e-01, time/batch = 15.3662s	
23863/33250 (epoch 35.884), train_loss = 0.87778682, grad/param norm = 1.8498e-01, time/batch = 16.6840s	
23864/33250 (epoch 35.886), train_loss = 0.74926600, grad/param norm = 1.6019e-01, time/batch = 15.2774s	
23865/33250 (epoch 35.887), train_loss = 0.75905132, grad/param norm = 1.5351e-01, time/batch = 15.9423s	
23866/33250 (epoch 35.889), train_loss = 0.77196372, grad/param norm = 1.5790e-01, time/batch = 19.1823s	
23867/33250 (epoch 35.890), train_loss = 0.61271413, grad/param norm = 1.2945e-01, time/batch = 17.6866s	
23868/33250 (epoch 35.892), train_loss = 0.84070577, grad/param norm = 1.6242e-01, time/batch = 17.0221s	
23869/33250 (epoch 35.893), train_loss = 0.85296512, grad/param norm = 1.8770e-01, time/batch = 15.2799s	
23870/33250 (epoch 35.895), train_loss = 0.75236350, grad/param norm = 1.6792e-01, time/batch = 15.1805s	
23871/33250 (epoch 35.896), train_loss = 0.86754558, grad/param norm = 1.7583e-01, time/batch = 15.9455s	
23872/33250 (epoch 35.898), train_loss = 0.80143718, grad/param norm = 1.7412e-01, time/batch = 15.9230s	
23873/33250 (epoch 35.899), train_loss = 0.73395947, grad/param norm = 1.5496e-01, time/batch = 15.6825s	
23874/33250 (epoch 35.901), train_loss = 0.68187686, grad/param norm = 1.5746e-01, time/batch = 16.0329s	
23875/33250 (epoch 35.902), train_loss = 0.76261435, grad/param norm = 1.5868e-01, time/batch = 16.2591s	
23876/33250 (epoch 35.904), train_loss = 0.71899868, grad/param norm = 1.6987e-01, time/batch = 15.8338s	
23877/33250 (epoch 35.905), train_loss = 0.78495315, grad/param norm = 1.4738e-01, time/batch = 17.6975s	
23878/33250 (epoch 35.907), train_loss = 0.72926324, grad/param norm = 1.8622e-01, time/batch = 19.1010s	
23879/33250 (epoch 35.908), train_loss = 0.78863300, grad/param norm = 1.5007e-01, time/batch = 16.0283s	
23880/33250 (epoch 35.910), train_loss = 0.87096501, grad/param norm = 1.8372e-01, time/batch = 15.0176s	
23881/33250 (epoch 35.911), train_loss = 0.72550058, grad/param norm = 1.5165e-01, time/batch = 15.7838s	
23882/33250 (epoch 35.913), train_loss = 0.76854317, grad/param norm = 1.7020e-01, time/batch = 15.8642s	
23883/33250 (epoch 35.914), train_loss = 0.66791704, grad/param norm = 1.5200e-01, time/batch = 15.8428s	
23884/33250 (epoch 35.916), train_loss = 0.70610423, grad/param norm = 1.5951e-01, time/batch = 16.8445s	
23885/33250 (epoch 35.917), train_loss = 0.79548900, grad/param norm = 1.4466e-01, time/batch = 16.3534s	
23886/33250 (epoch 35.919), train_loss = 0.75090118, grad/param norm = 1.8711e-01, time/batch = 19.0870s	
23887/33250 (epoch 35.920), train_loss = 0.80807383, grad/param norm = 1.7009e-01, time/batch = 16.5908s	
23888/33250 (epoch 35.922), train_loss = 0.81728632, grad/param norm = 1.7528e-01, time/batch = 16.2787s	
23889/33250 (epoch 35.923), train_loss = 0.77885647, grad/param norm = 1.9265e-01, time/batch = 17.2716s	
23890/33250 (epoch 35.925), train_loss = 0.76322483, grad/param norm = 1.6822e-01, time/batch = 16.2584s	
23891/33250 (epoch 35.926), train_loss = 0.75037408, grad/param norm = 1.5734e-01, time/batch = 15.7888s	
23892/33250 (epoch 35.928), train_loss = 0.75600038, grad/param norm = 1.6894e-01, time/batch = 15.5282s	
23893/33250 (epoch 35.929), train_loss = 0.67222314, grad/param norm = 1.3539e-01, time/batch = 15.5913s	
23894/33250 (epoch 35.931), train_loss = 0.88518094, grad/param norm = 1.6376e-01, time/batch = 15.4324s	
23895/33250 (epoch 35.932), train_loss = 0.75356715, grad/param norm = 1.8721e-01, time/batch = 15.7485s	
23896/33250 (epoch 35.934), train_loss = 0.73252603, grad/param norm = 1.4994e-01, time/batch = 17.6970s	
23897/33250 (epoch 35.935), train_loss = 0.74742215, grad/param norm = 1.7333e-01, time/batch = 17.9531s	
23898/33250 (epoch 35.937), train_loss = 0.72691688, grad/param norm = 1.6775e-01, time/batch = 15.5461s	
23899/33250 (epoch 35.938), train_loss = 0.77325401, grad/param norm = 1.8035e-01, time/batch = 16.6866s	
23900/33250 (epoch 35.940), train_loss = 0.75569106, grad/param norm = 1.7475e-01, time/batch = 15.3381s	
23901/33250 (epoch 35.941), train_loss = 0.83892536, grad/param norm = 1.8123e-01, time/batch = 15.3505s	
23902/33250 (epoch 35.943), train_loss = 0.92458078, grad/param norm = 1.9320e-01, time/batch = 15.5251s	
23903/33250 (epoch 35.944), train_loss = 0.77129859, grad/param norm = 1.6115e-01, time/batch = 15.3626s	
23904/33250 (epoch 35.946), train_loss = 0.90051179, grad/param norm = 1.9640e-01, time/batch = 15.0925s	
23905/33250 (epoch 35.947), train_loss = 0.71400303, grad/param norm = 1.9312e-01, time/batch = 15.7180s	
23906/33250 (epoch 35.949), train_loss = 0.84920840, grad/param norm = 1.9145e-01, time/batch = 0.6646s	
23907/33250 (epoch 35.950), train_loss = 0.86707997, grad/param norm = 1.7259e-01, time/batch = 0.6590s	
23908/33250 (epoch 35.952), train_loss = 0.80509896, grad/param norm = 1.9611e-01, time/batch = 0.6534s	
23909/33250 (epoch 35.953), train_loss = 0.80965394, grad/param norm = 1.8953e-01, time/batch = 0.6507s	
23910/33250 (epoch 35.955), train_loss = 0.87519880, grad/param norm = 1.8696e-01, time/batch = 0.6528s	
23911/33250 (epoch 35.956), train_loss = 0.79572886, grad/param norm = 2.0507e-01, time/batch = 0.6591s	
23912/33250 (epoch 35.958), train_loss = 0.74674295, grad/param norm = 1.6143e-01, time/batch = 0.6635s	
23913/33250 (epoch 35.959), train_loss = 0.74910839, grad/param norm = 1.6624e-01, time/batch = 0.8040s	
23914/33250 (epoch 35.961), train_loss = 0.99307423, grad/param norm = 1.9902e-01, time/batch = 0.9486s	
23915/33250 (epoch 35.962), train_loss = 0.77469506, grad/param norm = 1.9651e-01, time/batch = 0.9522s	
23916/33250 (epoch 35.964), train_loss = 0.90005239, grad/param norm = 1.8988e-01, time/batch = 0.9575s	
23917/33250 (epoch 35.965), train_loss = 0.85369692, grad/param norm = 1.8442e-01, time/batch = 0.9582s	
23918/33250 (epoch 35.967), train_loss = 0.80191324, grad/param norm = 1.8078e-01, time/batch = 1.1940s	
23919/33250 (epoch 35.968), train_loss = 0.91138184, grad/param norm = 1.6771e-01, time/batch = 1.8059s	
23920/33250 (epoch 35.970), train_loss = 1.02324893, grad/param norm = 2.7258e-01, time/batch = 1.7791s	
23921/33250 (epoch 35.971), train_loss = 0.96189239, grad/param norm = 1.8340e-01, time/batch = 9.7922s	
23922/33250 (epoch 35.973), train_loss = 0.76838186, grad/param norm = 1.6723e-01, time/batch = 16.3833s	
23923/33250 (epoch 35.974), train_loss = 0.85482915, grad/param norm = 1.7110e-01, time/batch = 15.5144s	
23924/33250 (epoch 35.976), train_loss = 0.77397170, grad/param norm = 2.0065e-01, time/batch = 15.4444s	
23925/33250 (epoch 35.977), train_loss = 0.79166035, grad/param norm = 1.8040e-01, time/batch = 15.4480s	
23926/33250 (epoch 35.979), train_loss = 0.84542929, grad/param norm = 1.8181e-01, time/batch = 15.1696s	
23927/33250 (epoch 35.980), train_loss = 0.85429272, grad/param norm = 1.8708e-01, time/batch = 14.9225s	
23928/33250 (epoch 35.982), train_loss = 0.76177135, grad/param norm = 1.4638e-01, time/batch = 15.1038s	
23929/33250 (epoch 35.983), train_loss = 0.84016104, grad/param norm = 2.3998e-01, time/batch = 16.5159s	
23930/33250 (epoch 35.985), train_loss = 0.77574451, grad/param norm = 1.7808e-01, time/batch = 16.0145s	
23931/33250 (epoch 35.986), train_loss = 0.88025641, grad/param norm = 2.0197e-01, time/batch = 15.3576s	
23932/33250 (epoch 35.988), train_loss = 0.90954044, grad/param norm = 1.8238e-01, time/batch = 15.5362s	
23933/33250 (epoch 35.989), train_loss = 0.88578515, grad/param norm = 1.8389e-01, time/batch = 15.2953s	
23934/33250 (epoch 35.991), train_loss = 0.83845231, grad/param norm = 1.7543e-01, time/batch = 15.4785s	
23935/33250 (epoch 35.992), train_loss = 0.80533460, grad/param norm = 1.6015e-01, time/batch = 15.8678s	
23936/33250 (epoch 35.994), train_loss = 0.76378254, grad/param norm = 1.7017e-01, time/batch = 15.6121s	
23937/33250 (epoch 35.995), train_loss = 0.78126989, grad/param norm = 2.8210e-01, time/batch = 15.8576s	
23938/33250 (epoch 35.997), train_loss = 0.60639806, grad/param norm = 1.6710e-01, time/batch = 15.1990s	
23939/33250 (epoch 35.998), train_loss = 0.83195224, grad/param norm = 1.5476e-01, time/batch = 15.3436s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
23940/33250 (epoch 36.000), train_loss = 0.82595066, grad/param norm = 1.7344e-01, time/batch = 15.2004s	
23941/33250 (epoch 36.002), train_loss = 1.01610013, grad/param norm = 1.9646e-01, time/batch = 16.8539s	
23942/33250 (epoch 36.003), train_loss = 0.87502411, grad/param norm = 1.8762e-01, time/batch = 17.6019s	
23943/33250 (epoch 36.005), train_loss = 0.65337150, grad/param norm = 1.4642e-01, time/batch = 18.0329s	
23944/33250 (epoch 36.006), train_loss = 0.69741839, grad/param norm = 1.6608e-01, time/batch = 16.6791s	
23945/33250 (epoch 36.008), train_loss = 0.89780474, grad/param norm = 1.9160e-01, time/batch = 15.9283s	
23946/33250 (epoch 36.009), train_loss = 0.96480199, grad/param norm = 1.9767e-01, time/batch = 15.7683s	
23947/33250 (epoch 36.011), train_loss = 0.75276489, grad/param norm = 1.6462e-01, time/batch = 15.1768s	
23948/33250 (epoch 36.012), train_loss = 0.79493013, grad/param norm = 2.0680e-01, time/batch = 14.6401s	
23949/33250 (epoch 36.014), train_loss = 0.89536441, grad/param norm = 1.8701e-01, time/batch = 16.0154s	
23950/33250 (epoch 36.015), train_loss = 0.81626542, grad/param norm = 1.7041e-01, time/batch = 15.6926s	
23951/33250 (epoch 36.017), train_loss = 0.83454280, grad/param norm = 2.0072e-01, time/batch = 16.0320s	
23952/33250 (epoch 36.018), train_loss = 0.64850160, grad/param norm = 1.5035e-01, time/batch = 16.3642s	
23953/33250 (epoch 36.020), train_loss = 0.81426433, grad/param norm = 1.6069e-01, time/batch = 17.6266s	
23954/33250 (epoch 36.021), train_loss = 0.82622273, grad/param norm = 1.7101e-01, time/batch = 16.1893s	
23955/33250 (epoch 36.023), train_loss = 0.67465100, grad/param norm = 1.8369e-01, time/batch = 18.7919s	
23956/33250 (epoch 36.024), train_loss = 0.90826336, grad/param norm = 2.0560e-01, time/batch = 16.0397s	
23957/33250 (epoch 36.026), train_loss = 0.83124436, grad/param norm = 1.6935e-01, time/batch = 15.2498s	
23958/33250 (epoch 36.027), train_loss = 0.84939887, grad/param norm = 1.8404e-01, time/batch = 15.5332s	
23959/33250 (epoch 36.029), train_loss = 0.77835675, grad/param norm = 1.6623e-01, time/batch = 16.3523s	
23960/33250 (epoch 36.030), train_loss = 0.77848731, grad/param norm = 1.7654e-01, time/batch = 17.5159s	
23961/33250 (epoch 36.032), train_loss = 0.98525121, grad/param norm = 1.9540e-01, time/batch = 15.2820s	
23962/33250 (epoch 36.033), train_loss = 0.76192282, grad/param norm = 1.6007e-01, time/batch = 17.6960s	
23963/33250 (epoch 36.035), train_loss = 0.82765038, grad/param norm = 1.8665e-01, time/batch = 16.4576s	
23964/33250 (epoch 36.036), train_loss = 0.85170819, grad/param norm = 1.9942e-01, time/batch = 18.0277s	
23965/33250 (epoch 36.038), train_loss = 0.81067042, grad/param norm = 1.4622e-01, time/batch = 15.0128s	
23966/33250 (epoch 36.039), train_loss = 0.74920807, grad/param norm = 1.5925e-01, time/batch = 15.0854s	
23967/33250 (epoch 36.041), train_loss = 0.82423738, grad/param norm = 2.1172e-01, time/batch = 15.0172s	
23968/33250 (epoch 36.042), train_loss = 0.66750219, grad/param norm = 1.4476e-01, time/batch = 15.0515s	
23969/33250 (epoch 36.044), train_loss = 0.92353870, grad/param norm = 1.7931e-01, time/batch = 14.9232s	
23970/33250 (epoch 36.045), train_loss = 0.90989814, grad/param norm = 1.7149e-01, time/batch = 14.6952s	
23971/33250 (epoch 36.047), train_loss = 0.82097246, grad/param norm = 1.7685e-01, time/batch = 15.0047s	
23972/33250 (epoch 36.048), train_loss = 0.87315461, grad/param norm = 2.2425e-01, time/batch = 14.8530s	
23973/33250 (epoch 36.050), train_loss = 0.83339075, grad/param norm = 1.8154e-01, time/batch = 14.9255s	
23974/33250 (epoch 36.051), train_loss = 0.81111727, grad/param norm = 1.7143e-01, time/batch = 14.8701s	
23975/33250 (epoch 36.053), train_loss = 0.86665762, grad/param norm = 2.0082e-01, time/batch = 16.5286s	
23976/33250 (epoch 36.054), train_loss = 0.67927140, grad/param norm = 1.5320e-01, time/batch = 16.8589s	
23977/33250 (epoch 36.056), train_loss = 0.70989122, grad/param norm = 1.5683e-01, time/batch = 15.1959s	
23978/33250 (epoch 36.057), train_loss = 0.91096781, grad/param norm = 1.9004e-01, time/batch = 15.3614s	
23979/33250 (epoch 36.059), train_loss = 0.78396576, grad/param norm = 2.0204e-01, time/batch = 16.0962s	
23980/33250 (epoch 36.060), train_loss = 0.82298786, grad/param norm = 1.9262e-01, time/batch = 15.1018s	
23981/33250 (epoch 36.062), train_loss = 0.90433645, grad/param norm = 1.8865e-01, time/batch = 14.9471s	
23982/33250 (epoch 36.063), train_loss = 0.92970733, grad/param norm = 1.7292e-01, time/batch = 15.3390s	
23983/33250 (epoch 36.065), train_loss = 0.78871946, grad/param norm = 1.6280e-01, time/batch = 15.6123s	
23984/33250 (epoch 36.066), train_loss = 0.85561242, grad/param norm = 1.8051e-01, time/batch = 15.0903s	
23985/33250 (epoch 36.068), train_loss = 0.77512723, grad/param norm = 1.6242e-01, time/batch = 17.4344s	
23986/33250 (epoch 36.069), train_loss = 0.81838729, grad/param norm = 2.0085e-01, time/batch = 16.2890s	
23987/33250 (epoch 36.071), train_loss = 0.76450089, grad/param norm = 1.6231e-01, time/batch = 15.2047s	
23988/33250 (epoch 36.072), train_loss = 0.73610260, grad/param norm = 1.7545e-01, time/batch = 15.5425s	
23989/33250 (epoch 36.074), train_loss = 0.84189881, grad/param norm = 1.7759e-01, time/batch = 14.8597s	
23990/33250 (epoch 36.075), train_loss = 0.76019825, grad/param norm = 1.5703e-01, time/batch = 15.2786s	
23991/33250 (epoch 36.077), train_loss = 0.80161311, grad/param norm = 1.9184e-01, time/batch = 15.7706s	
23992/33250 (epoch 36.078), train_loss = 0.80282384, grad/param norm = 1.6585e-01, time/batch = 15.5765s	
23993/33250 (epoch 36.080), train_loss = 0.80362350, grad/param norm = 3.2210e-01, time/batch = 15.2001s	
23994/33250 (epoch 36.081), train_loss = 0.83936563, grad/param norm = 1.6406e-01, time/batch = 16.0167s	
23995/33250 (epoch 36.083), train_loss = 0.92030723, grad/param norm = 1.7032e-01, time/batch = 17.5006s	
23996/33250 (epoch 36.084), train_loss = 0.86164522, grad/param norm = 1.7829e-01, time/batch = 18.5882s	
23997/33250 (epoch 36.086), train_loss = 0.81176594, grad/param norm = 1.5644e-01, time/batch = 15.1987s	
23998/33250 (epoch 36.087), train_loss = 0.71777955, grad/param norm = 1.5475e-01, time/batch = 16.0562s	
23999/33250 (epoch 36.089), train_loss = 0.78971398, grad/param norm = 1.6216e-01, time/batch = 15.2593s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch36.09_1.6517.t7	
24000/33250 (epoch 36.090), train_loss = 0.82822094, grad/param norm = 1.7322e-01, time/batch = 15.7862s	
24001/33250 (epoch 36.092), train_loss = 1.24128027, grad/param norm = 2.3451e-01, time/batch = 15.4287s	
24002/33250 (epoch 36.093), train_loss = 0.79918068, grad/param norm = 1.6908e-01, time/batch = 15.2023s	
24003/33250 (epoch 36.095), train_loss = 0.82466195, grad/param norm = 1.8096e-01, time/batch = 14.9656s	
24004/33250 (epoch 36.096), train_loss = 0.69106152, grad/param norm = 1.6368e-01, time/batch = 16.0888s	
24005/33250 (epoch 36.098), train_loss = 0.69502195, grad/param norm = 2.3057e-01, time/batch = 15.5098s	
24006/33250 (epoch 36.099), train_loss = 0.64022575, grad/param norm = 1.5471e-01, time/batch = 16.2005s	
24007/33250 (epoch 36.101), train_loss = 0.78620386, grad/param norm = 1.8010e-01, time/batch = 14.7147s	
24008/33250 (epoch 36.102), train_loss = 0.74488596, grad/param norm = 1.5514e-01, time/batch = 16.1195s	
24009/33250 (epoch 36.104), train_loss = 0.60109360, grad/param norm = 1.4465e-01, time/batch = 16.9576s	
24010/33250 (epoch 36.105), train_loss = 0.75500434, grad/param norm = 1.6489e-01, time/batch = 15.4625s	
24011/33250 (epoch 36.107), train_loss = 0.67699312, grad/param norm = 1.3714e-01, time/batch = 15.0371s	
24012/33250 (epoch 36.108), train_loss = 0.80113958, grad/param norm = 1.7456e-01, time/batch = 15.8132s	
24013/33250 (epoch 36.110), train_loss = 0.68312498, grad/param norm = 1.5132e-01, time/batch = 14.7010s	
24014/33250 (epoch 36.111), train_loss = 0.79232068, grad/param norm = 1.5749e-01, time/batch = 14.7751s	
24015/33250 (epoch 36.113), train_loss = 0.73579215, grad/param norm = 1.7352e-01, time/batch = 14.8554s	
24016/33250 (epoch 36.114), train_loss = 0.69076160, grad/param norm = 1.7538e-01, time/batch = 15.8542s	
24017/33250 (epoch 36.116), train_loss = 0.74129167, grad/param norm = 1.7612e-01, time/batch = 15.1796s	
24018/33250 (epoch 36.117), train_loss = 0.72982360, grad/param norm = 1.5484e-01, time/batch = 17.2699s	
24019/33250 (epoch 36.119), train_loss = 0.74026242, grad/param norm = 1.6943e-01, time/batch = 18.8739s	
24020/33250 (epoch 36.120), train_loss = 0.62654502, grad/param norm = 1.4065e-01, time/batch = 17.4332s	
24021/33250 (epoch 36.122), train_loss = 0.85970410, grad/param norm = 1.8131e-01, time/batch = 14.9775s	
24022/33250 (epoch 36.123), train_loss = 0.77950473, grad/param norm = 1.9032e-01, time/batch = 15.1957s	
24023/33250 (epoch 36.125), train_loss = 0.64846902, grad/param norm = 2.0943e-01, time/batch = 17.1072s	
24024/33250 (epoch 36.126), train_loss = 0.76061133, grad/param norm = 1.6809e-01, time/batch = 16.3392s	
24025/33250 (epoch 36.128), train_loss = 0.73526257, grad/param norm = 1.4458e-01, time/batch = 15.4387s	
24026/33250 (epoch 36.129), train_loss = 0.78789683, grad/param norm = 1.7415e-01, time/batch = 14.9097s	
24027/33250 (epoch 36.131), train_loss = 0.77389161, grad/param norm = 1.6484e-01, time/batch = 15.3477s	
24028/33250 (epoch 36.132), train_loss = 0.76757618, grad/param norm = 1.6984e-01, time/batch = 15.0956s	
24029/33250 (epoch 36.134), train_loss = 0.72528211, grad/param norm = 1.6885e-01, time/batch = 16.6735s	
24030/33250 (epoch 36.135), train_loss = 0.78647137, grad/param norm = 1.6178e-01, time/batch = 16.4440s	
24031/33250 (epoch 36.137), train_loss = 0.70029674, grad/param norm = 1.6940e-01, time/batch = 14.9696s	
24032/33250 (epoch 36.138), train_loss = 0.69819794, grad/param norm = 1.4517e-01, time/batch = 15.1729s	
24033/33250 (epoch 36.140), train_loss = 0.62412021, grad/param norm = 1.3600e-01, time/batch = 14.7752s	
24034/33250 (epoch 36.141), train_loss = 0.87524832, grad/param norm = 2.3994e-01, time/batch = 14.7856s	
24035/33250 (epoch 36.143), train_loss = 0.66847062, grad/param norm = 2.2235e-01, time/batch = 14.8579s	
24036/33250 (epoch 36.144), train_loss = 0.74125105, grad/param norm = 1.5861e-01, time/batch = 15.1942s	
24037/33250 (epoch 36.146), train_loss = 0.74080592, grad/param norm = 1.4893e-01, time/batch = 14.9225s	
24038/33250 (epoch 36.147), train_loss = 0.76643654, grad/param norm = 1.6877e-01, time/batch = 14.6168s	
24039/33250 (epoch 36.149), train_loss = 0.72739357, grad/param norm = 1.6104e-01, time/batch = 14.7111s	
24040/33250 (epoch 36.150), train_loss = 0.69595067, grad/param norm = 1.7041e-01, time/batch = 14.7164s	
24041/33250 (epoch 36.152), train_loss = 0.67127506, grad/param norm = 1.7451e-01, time/batch = 14.9444s	
24042/33250 (epoch 36.153), train_loss = 0.93402813, grad/param norm = 1.9359e-01, time/batch = 15.1382s	
24043/33250 (epoch 36.155), train_loss = 0.74085084, grad/param norm = 1.9103e-01, time/batch = 21.4392s	
24044/33250 (epoch 36.156), train_loss = 0.97751230, grad/param norm = 1.7682e-01, time/batch = 23.6116s	
24045/33250 (epoch 36.158), train_loss = 0.90010614, grad/param norm = 1.8693e-01, time/batch = 14.6967s	
24046/33250 (epoch 36.159), train_loss = 0.73949169, grad/param norm = 1.7077e-01, time/batch = 15.0153s	
24047/33250 (epoch 36.161), train_loss = 0.81414330, grad/param norm = 1.8536e-01, time/batch = 14.8482s	
24048/33250 (epoch 36.162), train_loss = 0.71250194, grad/param norm = 1.6182e-01, time/batch = 14.6871s	
24049/33250 (epoch 36.164), train_loss = 0.76955123, grad/param norm = 2.3488e-01, time/batch = 15.0179s	
24050/33250 (epoch 36.165), train_loss = 0.86519166, grad/param norm = 1.8863e-01, time/batch = 16.3442s	
24051/33250 (epoch 36.167), train_loss = 0.92767432, grad/param norm = 1.9697e-01, time/batch = 15.4135s	
24052/33250 (epoch 36.168), train_loss = 0.68514965, grad/param norm = 1.5382e-01, time/batch = 15.1137s	
24053/33250 (epoch 36.170), train_loss = 0.75139735, grad/param norm = 1.9285e-01, time/batch = 15.0239s	
24054/33250 (epoch 36.171), train_loss = 0.79547409, grad/param norm = 1.8056e-01, time/batch = 15.0323s	
24055/33250 (epoch 36.173), train_loss = 0.75615581, grad/param norm = 1.5861e-01, time/batch = 15.0177s	
24056/33250 (epoch 36.174), train_loss = 0.79823982, grad/param norm = 1.5916e-01, time/batch = 15.2834s	
24057/33250 (epoch 36.176), train_loss = 0.72901855, grad/param norm = 1.5943e-01, time/batch = 14.9268s	
24058/33250 (epoch 36.177), train_loss = 0.73702516, grad/param norm = 1.8283e-01, time/batch = 15.2666s	
24059/33250 (epoch 36.179), train_loss = 0.72163782, grad/param norm = 1.5570e-01, time/batch = 14.9391s	
24060/33250 (epoch 36.180), train_loss = 0.62184027, grad/param norm = 1.3991e-01, time/batch = 14.8755s	
24061/33250 (epoch 36.182), train_loss = 0.72120738, grad/param norm = 1.8208e-01, time/batch = 15.2758s	
24062/33250 (epoch 36.183), train_loss = 0.88030402, grad/param norm = 2.0526e-01, time/batch = 15.6487s	
24063/33250 (epoch 36.185), train_loss = 0.80242027, grad/param norm = 1.9206e-01, time/batch = 15.3134s	
24064/33250 (epoch 36.186), train_loss = 0.81978062, grad/param norm = 1.8540e-01, time/batch = 15.3336s	
24065/33250 (epoch 36.188), train_loss = 0.86529413, grad/param norm = 2.0033e-01, time/batch = 15.7543s	
24066/33250 (epoch 36.189), train_loss = 0.63375517, grad/param norm = 1.8490e-01, time/batch = 15.7543s	
24067/33250 (epoch 36.191), train_loss = 0.74541410, grad/param norm = 1.7980e-01, time/batch = 14.8858s	
24068/33250 (epoch 36.192), train_loss = 0.76336325, grad/param norm = 1.7039e-01, time/batch = 15.0712s	
24069/33250 (epoch 36.194), train_loss = 0.76892350, grad/param norm = 1.9550e-01, time/batch = 15.3088s	
24070/33250 (epoch 36.195), train_loss = 0.95917582, grad/param norm = 1.8176e-01, time/batch = 15.4473s	
24071/33250 (epoch 36.197), train_loss = 0.74142770, grad/param norm = 1.7394e-01, time/batch = 16.4028s	
24072/33250 (epoch 36.198), train_loss = 0.92164868, grad/param norm = 1.7352e-01, time/batch = 15.0437s	
24073/33250 (epoch 36.200), train_loss = 0.78664804, grad/param norm = 1.6580e-01, time/batch = 16.5593s	
24074/33250 (epoch 36.202), train_loss = 0.75874515, grad/param norm = 1.6242e-01, time/batch = 15.8096s	
24075/33250 (epoch 36.203), train_loss = 0.71186346, grad/param norm = 1.7681e-01, time/batch = 15.9577s	
24076/33250 (epoch 36.205), train_loss = 0.80946114, grad/param norm = 1.6831e-01, time/batch = 16.0087s	
24077/33250 (epoch 36.206), train_loss = 0.85395054, grad/param norm = 1.7386e-01, time/batch = 15.2269s	
24078/33250 (epoch 36.208), train_loss = 0.88483839, grad/param norm = 2.0466e-01, time/batch = 16.1352s	
24079/33250 (epoch 36.209), train_loss = 0.74672607, grad/param norm = 1.6594e-01, time/batch = 15.4114s	
24080/33250 (epoch 36.211), train_loss = 0.83375717, grad/param norm = 1.7404e-01, time/batch = 15.0610s	
24081/33250 (epoch 36.212), train_loss = 0.93285223, grad/param norm = 1.8074e-01, time/batch = 15.4626s	
24082/33250 (epoch 36.214), train_loss = 0.81353150, grad/param norm = 1.6150e-01, time/batch = 15.9864s	
24083/33250 (epoch 36.215), train_loss = 0.84360671, grad/param norm = 2.0266e-01, time/batch = 15.3746s	
24084/33250 (epoch 36.217), train_loss = 0.87817144, grad/param norm = 1.8961e-01, time/batch = 17.4049s	
24085/33250 (epoch 36.218), train_loss = 0.84816124, grad/param norm = 1.6208e-01, time/batch = 15.6359s	
24086/33250 (epoch 36.220), train_loss = 0.79065654, grad/param norm = 1.6018e-01, time/batch = 15.9874s	
24087/33250 (epoch 36.221), train_loss = 0.92125921, grad/param norm = 2.0210e-01, time/batch = 15.2234s	
24088/33250 (epoch 36.223), train_loss = 0.80448400, grad/param norm = 1.5322e-01, time/batch = 15.2932s	
24089/33250 (epoch 36.224), train_loss = 0.84823552, grad/param norm = 1.8697e-01, time/batch = 15.0959s	
24090/33250 (epoch 36.226), train_loss = 0.92951470, grad/param norm = 1.8044e-01, time/batch = 14.4953s	
24091/33250 (epoch 36.227), train_loss = 0.82565617, grad/param norm = 1.8188e-01, time/batch = 15.2430s	
24092/33250 (epoch 36.229), train_loss = 0.81135101, grad/param norm = 1.7942e-01, time/batch = 15.6637s	
24093/33250 (epoch 36.230), train_loss = 0.81494140, grad/param norm = 1.8676e-01, time/batch = 15.2044s	
24094/33250 (epoch 36.232), train_loss = 0.75937615, grad/param norm = 1.4872e-01, time/batch = 18.4602s	
24095/33250 (epoch 36.233), train_loss = 0.71188758, grad/param norm = 1.5052e-01, time/batch = 16.9673s	
24096/33250 (epoch 36.235), train_loss = 0.93851087, grad/param norm = 1.9010e-01, time/batch = 16.1192s	
24097/33250 (epoch 36.236), train_loss = 0.74039340, grad/param norm = 1.8082e-01, time/batch = 17.5685s	
24098/33250 (epoch 36.238), train_loss = 0.91777869, grad/param norm = 1.9392e-01, time/batch = 15.1376s	
24099/33250 (epoch 36.239), train_loss = 0.90212881, grad/param norm = 2.1346e-01, time/batch = 15.4038s	
24100/33250 (epoch 36.241), train_loss = 0.91807310, grad/param norm = 2.0736e-01, time/batch = 15.1489s	
24101/33250 (epoch 36.242), train_loss = 0.90182305, grad/param norm = 2.0916e-01, time/batch = 15.0514s	
24102/33250 (epoch 36.244), train_loss = 0.86199200, grad/param norm = 2.1169e-01, time/batch = 15.3770s	
24103/33250 (epoch 36.245), train_loss = 0.82976525, grad/param norm = 1.7731e-01, time/batch = 16.0745s	
24104/33250 (epoch 36.247), train_loss = 0.79308711, grad/param norm = 1.7287e-01, time/batch = 15.6462s	
24105/33250 (epoch 36.248), train_loss = 0.93897815, grad/param norm = 1.8801e-01, time/batch = 16.9538s	
24106/33250 (epoch 36.250), train_loss = 0.91472475, grad/param norm = 1.6515e-01, time/batch = 16.1684s	
24107/33250 (epoch 36.251), train_loss = 0.78422467, grad/param norm = 1.6572e-01, time/batch = 15.6245s	
24108/33250 (epoch 36.253), train_loss = 0.76916201, grad/param norm = 1.4921e-01, time/batch = 15.7151s	
24109/33250 (epoch 36.254), train_loss = 0.74509645, grad/param norm = 1.7076e-01, time/batch = 14.7407s	
24110/33250 (epoch 36.256), train_loss = 0.80714866, grad/param norm = 1.6348e-01, time/batch = 14.9358s	
24111/33250 (epoch 36.257), train_loss = 0.95014040, grad/param norm = 1.8007e-01, time/batch = 15.1938s	
24112/33250 (epoch 36.259), train_loss = 0.84385551, grad/param norm = 1.6734e-01, time/batch = 14.7796s	
24113/33250 (epoch 36.260), train_loss = 0.67716879, grad/param norm = 1.8147e-01, time/batch = 14.7812s	
24114/33250 (epoch 36.262), train_loss = 0.81140891, grad/param norm = 1.8497e-01, time/batch = 15.2796s	
24115/33250 (epoch 36.263), train_loss = 0.68378621, grad/param norm = 1.6736e-01, time/batch = 14.9548s	
24116/33250 (epoch 36.265), train_loss = 0.85904394, grad/param norm = 1.8365e-01, time/batch = 15.3640s	
24117/33250 (epoch 36.266), train_loss = 0.78065632, grad/param norm = 1.8315e-01, time/batch = 15.3805s	
24118/33250 (epoch 36.268), train_loss = 0.70840181, grad/param norm = 1.7044e-01, time/batch = 14.9758s	
24119/33250 (epoch 36.269), train_loss = 0.65847708, grad/param norm = 1.4929e-01, time/batch = 15.3951s	
24120/33250 (epoch 36.271), train_loss = 0.82135645, grad/param norm = 1.6010e-01, time/batch = 14.9309s	
24121/33250 (epoch 36.272), train_loss = 0.72911611, grad/param norm = 1.4338e-01, time/batch = 14.9414s	
24122/33250 (epoch 36.274), train_loss = 0.60194097, grad/param norm = 1.5122e-01, time/batch = 14.4522s	
24123/33250 (epoch 36.275), train_loss = 0.75689490, grad/param norm = 1.6296e-01, time/batch = 14.6093s	
24124/33250 (epoch 36.277), train_loss = 0.65418875, grad/param norm = 1.9572e-01, time/batch = 14.9480s	
24125/33250 (epoch 36.278), train_loss = 0.73668288, grad/param norm = 1.7102e-01, time/batch = 14.7789s	
24126/33250 (epoch 36.280), train_loss = 0.69847747, grad/param norm = 1.5601e-01, time/batch = 15.0163s	
24127/33250 (epoch 36.281), train_loss = 0.80524880, grad/param norm = 1.8324e-01, time/batch = 15.1969s	
24128/33250 (epoch 36.283), train_loss = 0.83295651, grad/param norm = 2.4371e-01, time/batch = 14.8797s	
24129/33250 (epoch 36.284), train_loss = 0.68686021, grad/param norm = 2.1321e-01, time/batch = 14.8173s	
24130/33250 (epoch 36.286), train_loss = 0.83047801, grad/param norm = 1.7661e-01, time/batch = 15.9640s	
24131/33250 (epoch 36.287), train_loss = 0.65692782, grad/param norm = 1.5603e-01, time/batch = 14.9470s	
24132/33250 (epoch 36.289), train_loss = 0.64962155, grad/param norm = 1.9958e-01, time/batch = 15.0922s	
24133/33250 (epoch 36.290), train_loss = 0.80101544, grad/param norm = 1.8227e-01, time/batch = 14.8821s	
24134/33250 (epoch 36.292), train_loss = 0.85802304, grad/param norm = 2.0969e-01, time/batch = 15.1563s	
24135/33250 (epoch 36.293), train_loss = 0.89038803, grad/param norm = 1.7295e-01, time/batch = 14.9228s	
24136/33250 (epoch 36.295), train_loss = 0.88326043, grad/param norm = 1.7295e-01, time/batch = 14.8710s	
24137/33250 (epoch 36.296), train_loss = 0.79909845, grad/param norm = 1.7904e-01, time/batch = 14.7834s	
24138/33250 (epoch 36.298), train_loss = 0.64736303, grad/param norm = 1.5221e-01, time/batch = 14.7226s	
24139/33250 (epoch 36.299), train_loss = 0.63403184, grad/param norm = 1.4884e-01, time/batch = 14.8502s	
24140/33250 (epoch 36.301), train_loss = 0.88576563, grad/param norm = 1.8912e-01, time/batch = 14.7176s	
24141/33250 (epoch 36.302), train_loss = 0.85399484, grad/param norm = 1.9000e-01, time/batch = 15.1845s	
24142/33250 (epoch 36.304), train_loss = 0.74981912, grad/param norm = 1.9033e-01, time/batch = 15.5055s	
24143/33250 (epoch 36.305), train_loss = 0.72785534, grad/param norm = 1.7256e-01, time/batch = 15.3451s	
24144/33250 (epoch 36.307), train_loss = 0.84642671, grad/param norm = 1.9235e-01, time/batch = 15.1817s	
24145/33250 (epoch 36.308), train_loss = 0.89876538, grad/param norm = 2.2050e-01, time/batch = 15.3440s	
24146/33250 (epoch 36.310), train_loss = 0.76547217, grad/param norm = 1.9440e-01, time/batch = 15.1873s	
24147/33250 (epoch 36.311), train_loss = 0.93080624, grad/param norm = 1.9872e-01, time/batch = 15.3313s	
24148/33250 (epoch 36.313), train_loss = 0.64419283, grad/param norm = 2.1089e-01, time/batch = 14.7955s	
24149/33250 (epoch 36.314), train_loss = 0.84518957, grad/param norm = 1.6318e-01, time/batch = 15.7258s	
24150/33250 (epoch 36.316), train_loss = 0.95531294, grad/param norm = 2.0101e-01, time/batch = 18.0578s	
24151/33250 (epoch 36.317), train_loss = 0.69957858, grad/param norm = 1.4747e-01, time/batch = 15.4675s	
24152/33250 (epoch 36.319), train_loss = 0.85018035, grad/param norm = 2.1690e-01, time/batch = 16.8841s	
24153/33250 (epoch 36.320), train_loss = 0.87497463, grad/param norm = 2.3066e-01, time/batch = 14.4584s	
24154/33250 (epoch 36.322), train_loss = 0.96879646, grad/param norm = 2.3473e-01, time/batch = 15.4629s	
24155/33250 (epoch 36.323), train_loss = 0.94232745, grad/param norm = 2.4825e-01, time/batch = 14.9431s	
24156/33250 (epoch 36.325), train_loss = 0.78977826, grad/param norm = 2.0282e-01, time/batch = 14.9223s	
24157/33250 (epoch 36.326), train_loss = 0.99426235, grad/param norm = 1.9862e-01, time/batch = 14.7034s	
24158/33250 (epoch 36.328), train_loss = 0.78086785, grad/param norm = 1.7077e-01, time/batch = 14.3844s	
24159/33250 (epoch 36.329), train_loss = 0.81878064, grad/param norm = 2.1313e-01, time/batch = 15.0278s	
24160/33250 (epoch 36.331), train_loss = 0.82626703, grad/param norm = 2.1635e-01, time/batch = 15.2191s	
24161/33250 (epoch 36.332), train_loss = 0.81400184, grad/param norm = 1.8665e-01, time/batch = 15.5936s	
24162/33250 (epoch 36.334), train_loss = 0.93963816, grad/param norm = 1.8145e-01, time/batch = 15.3483s	
24163/33250 (epoch 36.335), train_loss = 0.61052181, grad/param norm = 1.5802e-01, time/batch = 15.1155s	
24164/33250 (epoch 36.337), train_loss = 0.86551064, grad/param norm = 1.6912e-01, time/batch = 15.0185s	
24165/33250 (epoch 36.338), train_loss = 0.95914944, grad/param norm = 1.8880e-01, time/batch = 14.9363s	
24166/33250 (epoch 36.340), train_loss = 0.76972484, grad/param norm = 1.5958e-01, time/batch = 15.2614s	
24167/33250 (epoch 36.341), train_loss = 0.73457752, grad/param norm = 1.7291e-01, time/batch = 15.4426s	
24168/33250 (epoch 36.343), train_loss = 0.77631753, grad/param norm = 2.0160e-01, time/batch = 15.2664s	
24169/33250 (epoch 36.344), train_loss = 0.80160903, grad/param norm = 1.7423e-01, time/batch = 15.4619s	
24170/33250 (epoch 36.346), train_loss = 0.70220696, grad/param norm = 1.7316e-01, time/batch = 15.3509s	
24171/33250 (epoch 36.347), train_loss = 0.98703607, grad/param norm = 2.4652e-01, time/batch = 15.3680s	
24172/33250 (epoch 36.349), train_loss = 0.77990308, grad/param norm = 2.0722e-01, time/batch = 17.2160s	
24173/33250 (epoch 36.350), train_loss = 0.78220199, grad/param norm = 1.6069e-01, time/batch = 17.0500s	
24174/33250 (epoch 36.352), train_loss = 0.70978502, grad/param norm = 1.5101e-01, time/batch = 16.4599s	
24175/33250 (epoch 36.353), train_loss = 0.75388531, grad/param norm = 1.4110e-01, time/batch = 15.1923s	
24176/33250 (epoch 36.355), train_loss = 0.74953704, grad/param norm = 1.7276e-01, time/batch = 15.5290s	
24177/33250 (epoch 36.356), train_loss = 0.69354887, grad/param norm = 1.6775e-01, time/batch = 14.6486s	
24178/33250 (epoch 36.358), train_loss = 0.78863350, grad/param norm = 1.5661e-01, time/batch = 16.1851s	
24179/33250 (epoch 36.359), train_loss = 0.75738963, grad/param norm = 1.7131e-01, time/batch = 14.9498s	
24180/33250 (epoch 36.361), train_loss = 0.91563611, grad/param norm = 2.1230e-01, time/batch = 15.1934s	
24181/33250 (epoch 36.362), train_loss = 0.81640346, grad/param norm = 1.5342e-01, time/batch = 15.1302s	
24182/33250 (epoch 36.364), train_loss = 0.85552300, grad/param norm = 1.9669e-01, time/batch = 15.2815s	
24183/33250 (epoch 36.365), train_loss = 0.79345549, grad/param norm = 1.5899e-01, time/batch = 14.9450s	
24184/33250 (epoch 36.367), train_loss = 0.79863996, grad/param norm = 1.4791e-01, time/batch = 15.3975s	
24185/33250 (epoch 36.368), train_loss = 0.79673805, grad/param norm = 2.0642e-01, time/batch = 14.9614s	
24186/33250 (epoch 36.370), train_loss = 0.72616175, grad/param norm = 1.4829e-01, time/batch = 15.2873s	
24187/33250 (epoch 36.371), train_loss = 0.90024047, grad/param norm = 2.1774e-01, time/batch = 15.3536s	
24188/33250 (epoch 36.373), train_loss = 0.77989671, grad/param norm = 1.6510e-01, time/batch = 15.2202s	
24189/33250 (epoch 36.374), train_loss = 0.82490465, grad/param norm = 2.1844e-01, time/batch = 14.5301s	
24190/33250 (epoch 36.376), train_loss = 0.78777063, grad/param norm = 1.5643e-01, time/batch = 14.7931s	
24191/33250 (epoch 36.377), train_loss = 0.69981345, grad/param norm = 1.8332e-01, time/batch = 14.7198s	
24192/33250 (epoch 36.379), train_loss = 0.80334062, grad/param norm = 1.7328e-01, time/batch = 14.7157s	
24193/33250 (epoch 36.380), train_loss = 0.80008936, grad/param norm = 1.9767e-01, time/batch = 14.4725s	
24194/33250 (epoch 36.382), train_loss = 0.81745608, grad/param norm = 1.9781e-01, time/batch = 15.1152s	
24195/33250 (epoch 36.383), train_loss = 0.72890489, grad/param norm = 2.4678e-01, time/batch = 14.4672s	
24196/33250 (epoch 36.385), train_loss = 0.66000560, grad/param norm = 1.7166e-01, time/batch = 16.0664s	
24197/33250 (epoch 36.386), train_loss = 0.71886837, grad/param norm = 2.8118e-01, time/batch = 15.3756s	
24198/33250 (epoch 36.388), train_loss = 0.72978933, grad/param norm = 1.7971e-01, time/batch = 15.6944s	
24199/33250 (epoch 36.389), train_loss = 0.74432277, grad/param norm = 1.7977e-01, time/batch = 15.5607s	
24200/33250 (epoch 36.391), train_loss = 0.85146338, grad/param norm = 1.8600e-01, time/batch = 14.7244s	
24201/33250 (epoch 36.392), train_loss = 0.91399506, grad/param norm = 2.0571e-01, time/batch = 15.1111s	
24202/33250 (epoch 36.394), train_loss = 0.87569947, grad/param norm = 1.8825e-01, time/batch = 15.5349s	
24203/33250 (epoch 36.395), train_loss = 0.88938377, grad/param norm = 1.8188e-01, time/batch = 15.4678s	
24204/33250 (epoch 36.397), train_loss = 0.91214020, grad/param norm = 1.8381e-01, time/batch = 15.3608s	
24205/33250 (epoch 36.398), train_loss = 0.71452420, grad/param norm = 1.5144e-01, time/batch = 14.9431s	
24206/33250 (epoch 36.400), train_loss = 0.69817141, grad/param norm = 1.4762e-01, time/batch = 14.8594s	
24207/33250 (epoch 36.402), train_loss = 0.67778512, grad/param norm = 2.1379e-01, time/batch = 14.9979s	
24208/33250 (epoch 36.403), train_loss = 0.77345910, grad/param norm = 2.0647e-01, time/batch = 16.0554s	
24209/33250 (epoch 36.405), train_loss = 0.74955150, grad/param norm = 1.5418e-01, time/batch = 15.9728s	
24210/33250 (epoch 36.406), train_loss = 0.78921589, grad/param norm = 1.9886e-01, time/batch = 15.2103s	
24211/33250 (epoch 36.408), train_loss = 0.94350502, grad/param norm = 1.8286e-01, time/batch = 14.8601s	
24212/33250 (epoch 36.409), train_loss = 0.83953069, grad/param norm = 2.0506e-01, time/batch = 14.8745s	
24213/33250 (epoch 36.411), train_loss = 0.58865848, grad/param norm = 1.3992e-01, time/batch = 14.7068s	
24214/33250 (epoch 36.412), train_loss = 0.66993905, grad/param norm = 1.7331e-01, time/batch = 15.0385s	
24215/33250 (epoch 36.414), train_loss = 0.81626273, grad/param norm = 1.8430e-01, time/batch = 14.5586s	
24216/33250 (epoch 36.415), train_loss = 0.85138317, grad/param norm = 1.8492e-01, time/batch = 14.7915s	
24217/33250 (epoch 36.417), train_loss = 0.90506151, grad/param norm = 1.7494e-01, time/batch = 15.7809s	
24218/33250 (epoch 36.418), train_loss = 1.03588268, grad/param norm = 2.3130e-01, time/batch = 15.7725s	
24219/33250 (epoch 36.420), train_loss = 0.85191969, grad/param norm = 1.8212e-01, time/batch = 16.9763s	
24220/33250 (epoch 36.421), train_loss = 0.75375922, grad/param norm = 1.5971e-01, time/batch = 16.2262s	
24221/33250 (epoch 36.423), train_loss = 0.82578799, grad/param norm = 1.8149e-01, time/batch = 15.1944s	
24222/33250 (epoch 36.424), train_loss = 0.91933368, grad/param norm = 2.6545e-01, time/batch = 14.7832s	
24223/33250 (epoch 36.426), train_loss = 0.76710137, grad/param norm = 1.6296e-01, time/batch = 15.0268s	
24224/33250 (epoch 36.427), train_loss = 0.73986389, grad/param norm = 2.1282e-01, time/batch = 15.6873s	
24225/33250 (epoch 36.429), train_loss = 0.83057805, grad/param norm = 1.9409e-01, time/batch = 14.9430s	
24226/33250 (epoch 36.430), train_loss = 0.75458599, grad/param norm = 2.1555e-01, time/batch = 15.2026s	
24227/33250 (epoch 36.432), train_loss = 0.87439148, grad/param norm = 1.7710e-01, time/batch = 15.2885s	
24228/33250 (epoch 36.433), train_loss = 0.72863906, grad/param norm = 2.1850e-01, time/batch = 14.7049s	
24229/33250 (epoch 36.435), train_loss = 0.86774900, grad/param norm = 1.8351e-01, time/batch = 15.1319s	
24230/33250 (epoch 36.436), train_loss = 0.77031247, grad/param norm = 1.9657e-01, time/batch = 17.1951s	
24231/33250 (epoch 36.438), train_loss = 0.90832769, grad/param norm = 1.9204e-01, time/batch = 14.7479s	
24232/33250 (epoch 36.439), train_loss = 0.80984952, grad/param norm = 1.6197e-01, time/batch = 16.3063s	
24233/33250 (epoch 36.441), train_loss = 0.77412546, grad/param norm = 1.4359e-01, time/batch = 15.0847s	
24234/33250 (epoch 36.442), train_loss = 0.71834207, grad/param norm = 1.5777e-01, time/batch = 14.5452s	
24235/33250 (epoch 36.444), train_loss = 0.75225364, grad/param norm = 1.6252e-01, time/batch = 14.6257s	
24236/33250 (epoch 36.445), train_loss = 0.81826701, grad/param norm = 1.5193e-01, time/batch = 14.9662s	
24237/33250 (epoch 36.447), train_loss = 0.73080807, grad/param norm = 1.7929e-01, time/batch = 15.0991s	
24238/33250 (epoch 36.448), train_loss = 0.83340381, grad/param norm = 1.5233e-01, time/batch = 15.0969s	
24239/33250 (epoch 36.450), train_loss = 0.90619047, grad/param norm = 1.9256e-01, time/batch = 14.6247s	
24240/33250 (epoch 36.451), train_loss = 0.86008727, grad/param norm = 2.1902e-01, time/batch = 15.4768s	
24241/33250 (epoch 36.453), train_loss = 0.70679370, grad/param norm = 1.5129e-01, time/batch = 15.4988s	
24242/33250 (epoch 36.454), train_loss = 0.93371895, grad/param norm = 1.9122e-01, time/batch = 19.2760s	
24243/33250 (epoch 36.456), train_loss = 0.91148576, grad/param norm = 1.5318e-01, time/batch = 14.9650s	
24244/33250 (epoch 36.457), train_loss = 0.74438757, grad/param norm = 1.6550e-01, time/batch = 15.0271s	
24245/33250 (epoch 36.459), train_loss = 0.85961208, grad/param norm = 1.7802e-01, time/batch = 14.8721s	
24246/33250 (epoch 36.460), train_loss = 0.87007097, grad/param norm = 1.8711e-01, time/batch = 15.7017s	
24247/33250 (epoch 36.462), train_loss = 0.78360303, grad/param norm = 1.7288e-01, time/batch = 14.6370s	
24248/33250 (epoch 36.463), train_loss = 0.71934939, grad/param norm = 1.4364e-01, time/batch = 15.1786s	
24249/33250 (epoch 36.465), train_loss = 0.67938810, grad/param norm = 1.4422e-01, time/batch = 16.1011s	
24250/33250 (epoch 36.466), train_loss = 0.65172114, grad/param norm = 1.2830e-01, time/batch = 16.9299s	
24251/33250 (epoch 36.468), train_loss = 0.68424917, grad/param norm = 1.3920e-01, time/batch = 17.9569s	
24252/33250 (epoch 36.469), train_loss = 0.77220746, grad/param norm = 1.7573e-01, time/batch = 16.1277s	
24253/33250 (epoch 36.471), train_loss = 0.85738180, grad/param norm = 1.5520e-01, time/batch = 17.3683s	
24254/33250 (epoch 36.472), train_loss = 0.76567143, grad/param norm = 2.0477e-01, time/batch = 16.2867s	
24255/33250 (epoch 36.474), train_loss = 0.89840066, grad/param norm = 1.8343e-01, time/batch = 15.9281s	
24256/33250 (epoch 36.475), train_loss = 0.80305678, grad/param norm = 1.5292e-01, time/batch = 14.9293s	
24257/33250 (epoch 36.477), train_loss = 0.83022151, grad/param norm = 1.6965e-01, time/batch = 15.3746s	
24258/33250 (epoch 36.478), train_loss = 0.71060574, grad/param norm = 1.6862e-01, time/batch = 15.2624s	
24259/33250 (epoch 36.480), train_loss = 0.89419624, grad/param norm = 1.6430e-01, time/batch = 15.4351s	
24260/33250 (epoch 36.481), train_loss = 0.76911226, grad/param norm = 1.5816e-01, time/batch = 15.1847s	
24261/33250 (epoch 36.483), train_loss = 0.78063831, grad/param norm = 1.7392e-01, time/batch = 14.8160s	
24262/33250 (epoch 36.484), train_loss = 0.72653371, grad/param norm = 1.5138e-01, time/batch = 14.8572s	
24263/33250 (epoch 36.486), train_loss = 0.65892195, grad/param norm = 1.5610e-01, time/batch = 15.1135s	
24264/33250 (epoch 36.487), train_loss = 0.73429716, grad/param norm = 1.6700e-01, time/batch = 15.7021s	
24265/33250 (epoch 36.489), train_loss = 0.87455683, grad/param norm = 1.8399e-01, time/batch = 15.1736s	
24266/33250 (epoch 36.490), train_loss = 0.84558672, grad/param norm = 2.0370e-01, time/batch = 15.6265s	
24267/33250 (epoch 36.492), train_loss = 0.89505497, grad/param norm = 2.0704e-01, time/batch = 15.1838s	
24268/33250 (epoch 36.493), train_loss = 0.80051001, grad/param norm = 1.8482e-01, time/batch = 15.1257s	
24269/33250 (epoch 36.495), train_loss = 0.84883338, grad/param norm = 1.5401e-01, time/batch = 16.0322s	
24270/33250 (epoch 36.496), train_loss = 0.80370433, grad/param norm = 1.4346e-01, time/batch = 16.0279s	
24271/33250 (epoch 36.498), train_loss = 0.87956949, grad/param norm = 1.9486e-01, time/batch = 15.5059s	
24272/33250 (epoch 36.499), train_loss = 0.75542242, grad/param norm = 1.5691e-01, time/batch = 16.3008s	
24273/33250 (epoch 36.501), train_loss = 0.76061290, grad/param norm = 1.7768e-01, time/batch = 16.3041s	
24274/33250 (epoch 36.502), train_loss = 0.75120527, grad/param norm = 1.5846e-01, time/batch = 16.4609s	
24275/33250 (epoch 36.504), train_loss = 0.93045320, grad/param norm = 2.0689e-01, time/batch = 27.1955s	
24276/33250 (epoch 36.505), train_loss = 0.68795883, grad/param norm = 1.3978e-01, time/batch = 16.1252s	
24277/33250 (epoch 36.507), train_loss = 0.72343588, grad/param norm = 1.7122e-01, time/batch = 14.6225s	
24278/33250 (epoch 36.508), train_loss = 0.74994962, grad/param norm = 1.5333e-01, time/batch = 15.2034s	
24279/33250 (epoch 36.510), train_loss = 0.65169321, grad/param norm = 1.4000e-01, time/batch = 15.4497s	
24280/33250 (epoch 36.511), train_loss = 0.78286881, grad/param norm = 1.9932e-01, time/batch = 14.9437s	
24281/33250 (epoch 36.513), train_loss = 0.90415373, grad/param norm = 1.7138e-01, time/batch = 15.1087s	
24282/33250 (epoch 36.514), train_loss = 0.76462324, grad/param norm = 1.6529e-01, time/batch = 15.2818s	
24283/33250 (epoch 36.516), train_loss = 0.73384576, grad/param norm = 1.7587e-01, time/batch = 16.8475s	
24284/33250 (epoch 36.517), train_loss = 0.76592832, grad/param norm = 1.6799e-01, time/batch = 16.0117s	
24285/33250 (epoch 36.519), train_loss = 0.69759116, grad/param norm = 1.2642e-01, time/batch = 17.6062s	
24286/33250 (epoch 36.520), train_loss = 0.97806182, grad/param norm = 2.2897e-01, time/batch = 16.1006s	
24287/33250 (epoch 36.522), train_loss = 0.82998788, grad/param norm = 1.8042e-01, time/batch = 15.0402s	
24288/33250 (epoch 36.523), train_loss = 0.72055247, grad/param norm = 1.7347e-01, time/batch = 15.2717s	
24289/33250 (epoch 36.525), train_loss = 0.67542981, grad/param norm = 1.8652e-01, time/batch = 15.7743s	
24290/33250 (epoch 36.526), train_loss = 0.70547198, grad/param norm = 1.5394e-01, time/batch = 15.5651s	
24291/33250 (epoch 36.528), train_loss = 0.75392665, grad/param norm = 1.8080e-01, time/batch = 16.7260s	
24292/33250 (epoch 36.529), train_loss = 0.72680879, grad/param norm = 1.6932e-01, time/batch = 15.0339s	
24293/33250 (epoch 36.531), train_loss = 0.70830148, grad/param norm = 1.5553e-01, time/batch = 14.9487s	
24294/33250 (epoch 36.532), train_loss = 0.82749843, grad/param norm = 1.5981e-01, time/batch = 16.0046s	
24295/33250 (epoch 36.534), train_loss = 0.72286133, grad/param norm = 1.5068e-01, time/batch = 15.0518s	
24296/33250 (epoch 36.535), train_loss = 0.75390905, grad/param norm = 1.4910e-01, time/batch = 14.8500s	
24297/33250 (epoch 36.537), train_loss = 0.80186719, grad/param norm = 1.5562e-01, time/batch = 15.6865s	
24298/33250 (epoch 36.538), train_loss = 0.83754878, grad/param norm = 1.7142e-01, time/batch = 15.9050s	
24299/33250 (epoch 36.540), train_loss = 0.91925548, grad/param norm = 1.5235e-01, time/batch = 16.1041s	
24300/33250 (epoch 36.541), train_loss = 0.84700602, grad/param norm = 1.9879e-01, time/batch = 15.0276s	
24301/33250 (epoch 36.543), train_loss = 0.83852167, grad/param norm = 1.5531e-01, time/batch = 15.3278s	
24302/33250 (epoch 36.544), train_loss = 0.70279785, grad/param norm = 1.7118e-01, time/batch = 15.0444s	
24303/33250 (epoch 36.546), train_loss = 0.74676104, grad/param norm = 2.0833e-01, time/batch = 15.7396s	
24304/33250 (epoch 36.547), train_loss = 0.76259359, grad/param norm = 2.0114e-01, time/batch = 15.8454s	
24305/33250 (epoch 36.549), train_loss = 0.79808268, grad/param norm = 1.6976e-01, time/batch = 15.8089s	
24306/33250 (epoch 36.550), train_loss = 0.75938861, grad/param norm = 1.5138e-01, time/batch = 15.8964s	
24307/33250 (epoch 36.552), train_loss = 0.84560391, grad/param norm = 1.6522e-01, time/batch = 15.5230s	
24308/33250 (epoch 36.553), train_loss = 0.75580221, grad/param norm = 1.6936e-01, time/batch = 14.6286s	
24309/33250 (epoch 36.555), train_loss = 0.79924160, grad/param norm = 1.4744e-01, time/batch = 14.6964s	
24310/33250 (epoch 36.556), train_loss = 0.81314689, grad/param norm = 2.7402e-01, time/batch = 15.0244s	
24311/33250 (epoch 36.558), train_loss = 0.83499383, grad/param norm = 1.8372e-01, time/batch = 14.7897s	
24312/33250 (epoch 36.559), train_loss = 0.73973500, grad/param norm = 1.6632e-01, time/batch = 15.8531s	
24313/33250 (epoch 36.561), train_loss = 0.68978849, grad/param norm = 1.5952e-01, time/batch = 15.6323s	
24314/33250 (epoch 36.562), train_loss = 0.79591814, grad/param norm = 1.9557e-01, time/batch = 17.3627s	
24315/33250 (epoch 36.564), train_loss = 0.97232629, grad/param norm = 2.2570e-01, time/batch = 15.2308s	
24316/33250 (epoch 36.565), train_loss = 0.88369738, grad/param norm = 2.0714e-01, time/batch = 16.9566s	
24317/33250 (epoch 36.567), train_loss = 0.91046857, grad/param norm = 2.0451e-01, time/batch = 14.9471s	
24318/33250 (epoch 36.568), train_loss = 0.76376255, grad/param norm = 1.8391e-01, time/batch = 14.7067s	
24319/33250 (epoch 36.570), train_loss = 0.87096399, grad/param norm = 1.9937e-01, time/batch = 14.9405s	
24320/33250 (epoch 36.571), train_loss = 0.90020268, grad/param norm = 1.9476e-01, time/batch = 14.7942s	
24321/33250 (epoch 36.573), train_loss = 0.85639748, grad/param norm = 1.7497e-01, time/batch = 14.9465s	
24322/33250 (epoch 36.574), train_loss = 0.73321931, grad/param norm = 1.4323e-01, time/batch = 14.7149s	
24323/33250 (epoch 36.576), train_loss = 0.83865495, grad/param norm = 1.8672e-01, time/batch = 16.9523s	
24324/33250 (epoch 36.577), train_loss = 0.78203412, grad/param norm = 1.6890e-01, time/batch = 15.7798s	
24325/33250 (epoch 36.579), train_loss = 0.69361725, grad/param norm = 1.9455e-01, time/batch = 14.3858s	
24326/33250 (epoch 36.580), train_loss = 0.79358325, grad/param norm = 1.5904e-01, time/batch = 14.8432s	
24327/33250 (epoch 36.582), train_loss = 0.74902203, grad/param norm = 1.4940e-01, time/batch = 15.9474s	
24328/33250 (epoch 36.583), train_loss = 0.87790734, grad/param norm = 1.7900e-01, time/batch = 15.3155s	
24329/33250 (epoch 36.585), train_loss = 0.87739137, grad/param norm = 1.5477e-01, time/batch = 14.7620s	
24330/33250 (epoch 36.586), train_loss = 0.77032164, grad/param norm = 2.2787e-01, time/batch = 14.6129s	
24331/33250 (epoch 36.588), train_loss = 0.82399239, grad/param norm = 1.5861e-01, time/batch = 14.6226s	
24332/33250 (epoch 36.589), train_loss = 0.80782887, grad/param norm = 1.7311e-01, time/batch = 15.1843s	
24333/33250 (epoch 36.591), train_loss = 0.78768160, grad/param norm = 1.9990e-01, time/batch = 15.0241s	
24334/33250 (epoch 36.592), train_loss = 0.75253702, grad/param norm = 1.7291e-01, time/batch = 14.6272s	
24335/33250 (epoch 36.594), train_loss = 0.89558282, grad/param norm = 2.0667e-01, time/batch = 14.6206s	
24336/33250 (epoch 36.595), train_loss = 0.79956548, grad/param norm = 1.7423e-01, time/batch = 14.9582s	
24337/33250 (epoch 36.597), train_loss = 0.67953723, grad/param norm = 1.5180e-01, time/batch = 14.7360s	
24338/33250 (epoch 36.598), train_loss = 0.76595766, grad/param norm = 1.8098e-01, time/batch = 15.3758s	
24339/33250 (epoch 36.600), train_loss = 0.77144267, grad/param norm = 2.0073e-01, time/batch = 14.8558s	
24340/33250 (epoch 36.602), train_loss = 0.81199084, grad/param norm = 1.8152e-01, time/batch = 15.3206s	
24341/33250 (epoch 36.603), train_loss = 0.83947626, grad/param norm = 1.7092e-01, time/batch = 14.7812s	
24342/33250 (epoch 36.605), train_loss = 0.79257424, grad/param norm = 1.7422e-01, time/batch = 14.8641s	
24343/33250 (epoch 36.606), train_loss = 0.85588013, grad/param norm = 1.8111e-01, time/batch = 14.6993s	
24344/33250 (epoch 36.608), train_loss = 0.80822029, grad/param norm = 1.5497e-01, time/batch = 14.9468s	
24345/33250 (epoch 36.609), train_loss = 0.70662574, grad/param norm = 1.7219e-01, time/batch = 15.0363s	
24346/33250 (epoch 36.611), train_loss = 0.77311551, grad/param norm = 1.8644e-01, time/batch = 14.7171s	
24347/33250 (epoch 36.612), train_loss = 0.77741454, grad/param norm = 1.8375e-01, time/batch = 14.7143s	
24348/33250 (epoch 36.614), train_loss = 0.99177037, grad/param norm = 2.0217e-01, time/batch = 15.0195s	
24349/33250 (epoch 36.615), train_loss = 0.90132625, grad/param norm = 1.6802e-01, time/batch = 15.6511s	
24350/33250 (epoch 36.617), train_loss = 1.00317804, grad/param norm = 2.1306e-01, time/batch = 14.8550s	
24351/33250 (epoch 36.618), train_loss = 1.02050942, grad/param norm = 2.4189e-01, time/batch = 15.0438s	
24352/33250 (epoch 36.620), train_loss = 0.86877250, grad/param norm = 1.7763e-01, time/batch = 15.1759s	
24353/33250 (epoch 36.621), train_loss = 0.85529821, grad/param norm = 1.7963e-01, time/batch = 14.7259s	
24354/33250 (epoch 36.623), train_loss = 0.74307427, grad/param norm = 1.6602e-01, time/batch = 15.0218s	
24355/33250 (epoch 36.624), train_loss = 0.76489110, grad/param norm = 1.8792e-01, time/batch = 14.8627s	
24356/33250 (epoch 36.626), train_loss = 0.77818625, grad/param norm = 2.1077e-01, time/batch = 15.1751s	
24357/33250 (epoch 36.627), train_loss = 0.76517508, grad/param norm = 1.7269e-01, time/batch = 14.9569s	
24358/33250 (epoch 36.629), train_loss = 0.83451507, grad/param norm = 1.8364e-01, time/batch = 15.1254s	
24359/33250 (epoch 36.630), train_loss = 0.76328652, grad/param norm = 1.9399e-01, time/batch = 15.2981s	
24360/33250 (epoch 36.632), train_loss = 0.69532085, grad/param norm = 1.5431e-01, time/batch = 15.5351s	
24361/33250 (epoch 36.633), train_loss = 0.81852989, grad/param norm = 1.9085e-01, time/batch = 15.2142s	
24362/33250 (epoch 36.635), train_loss = 0.72584446, grad/param norm = 1.6735e-01, time/batch = 15.0309s	
24363/33250 (epoch 36.636), train_loss = 0.74940798, grad/param norm = 1.5526e-01, time/batch = 14.9926s	
24364/33250 (epoch 36.638), train_loss = 0.70453841, grad/param norm = 1.6777e-01, time/batch = 15.0663s	
24365/33250 (epoch 36.639), train_loss = 0.67469062, grad/param norm = 1.7290e-01, time/batch = 14.4492s	
24366/33250 (epoch 36.641), train_loss = 0.77776391, grad/param norm = 1.7567e-01, time/batch = 14.3744s	
24367/33250 (epoch 36.642), train_loss = 0.59442603, grad/param norm = 1.7306e-01, time/batch = 14.5312s	
24368/33250 (epoch 36.644), train_loss = 0.54757426, grad/param norm = 1.3015e-01, time/batch = 14.7883s	
24369/33250 (epoch 36.645), train_loss = 0.82415267, grad/param norm = 2.0902e-01, time/batch = 15.1126s	
24370/33250 (epoch 36.647), train_loss = 0.67965802, grad/param norm = 1.8127e-01, time/batch = 14.8350s	
24371/33250 (epoch 36.648), train_loss = 0.67143395, grad/param norm = 1.6922e-01, time/batch = 14.6574s	
24372/33250 (epoch 36.650), train_loss = 0.91366320, grad/param norm = 1.9928e-01, time/batch = 15.0074s	
24373/33250 (epoch 36.651), train_loss = 0.82530924, grad/param norm = 2.0278e-01, time/batch = 14.6892s	
24374/33250 (epoch 36.653), train_loss = 0.74064299, grad/param norm = 1.7268e-01, time/batch = 14.7088s	
24375/33250 (epoch 36.654), train_loss = 0.79065423, grad/param norm = 1.6019e-01, time/batch = 15.0343s	
24376/33250 (epoch 36.656), train_loss = 0.84246099, grad/param norm = 1.6104e-01, time/batch = 14.9425s	
24377/33250 (epoch 36.657), train_loss = 0.63364735, grad/param norm = 1.9780e-01, time/batch = 14.7096s	
24378/33250 (epoch 36.659), train_loss = 0.75668772, grad/param norm = 1.7081e-01, time/batch = 15.0297s	
24379/33250 (epoch 36.660), train_loss = 0.81476048, grad/param norm = 1.9608e-01, time/batch = 15.0192s	
24380/33250 (epoch 36.662), train_loss = 0.82157878, grad/param norm = 1.8421e-01, time/batch = 15.3855s	
24381/33250 (epoch 36.663), train_loss = 0.75147364, grad/param norm = 1.9366e-01, time/batch = 15.8572s	
24382/33250 (epoch 36.665), train_loss = 0.82153083, grad/param norm = 1.8670e-01, time/batch = 15.2854s	
24383/33250 (epoch 36.666), train_loss = 0.76384991, grad/param norm = 1.5321e-01, time/batch = 14.8923s	
24384/33250 (epoch 36.668), train_loss = 0.89253133, grad/param norm = 1.7294e-01, time/batch = 15.6188s	
24385/33250 (epoch 36.669), train_loss = 0.80957429, grad/param norm = 1.9273e-01, time/batch = 14.9508s	
24386/33250 (epoch 36.671), train_loss = 0.69297312, grad/param norm = 1.6490e-01, time/batch = 14.6205s	
24387/33250 (epoch 36.672), train_loss = 0.86729268, grad/param norm = 1.7810e-01, time/batch = 14.7123s	
24388/33250 (epoch 36.674), train_loss = 0.70804748, grad/param norm = 1.6770e-01, time/batch = 14.9465s	
24389/33250 (epoch 36.675), train_loss = 0.79510982, grad/param norm = 1.4522e-01, time/batch = 14.9582s	
24390/33250 (epoch 36.677), train_loss = 0.85309510, grad/param norm = 1.7317e-01, time/batch = 15.0179s	
24391/33250 (epoch 36.678), train_loss = 0.72623567, grad/param norm = 1.6921e-01, time/batch = 14.9495s	
24392/33250 (epoch 36.680), train_loss = 0.89792558, grad/param norm = 1.9665e-01, time/batch = 15.4997s	
24393/33250 (epoch 36.681), train_loss = 0.72036154, grad/param norm = 1.5875e-01, time/batch = 15.5023s	
24394/33250 (epoch 36.683), train_loss = 0.73236200, grad/param norm = 1.6654e-01, time/batch = 15.0259s	
24395/33250 (epoch 36.684), train_loss = 0.68915685, grad/param norm = 1.9012e-01, time/batch = 14.9268s	
24396/33250 (epoch 36.686), train_loss = 0.69344380, grad/param norm = 1.7412e-01, time/batch = 15.0225s	
24397/33250 (epoch 36.687), train_loss = 0.81245058, grad/param norm = 1.8155e-01, time/batch = 14.3646s	
24398/33250 (epoch 36.689), train_loss = 0.69292327, grad/param norm = 1.7756e-01, time/batch = 14.6202s	
24399/33250 (epoch 36.690), train_loss = 0.81173808, grad/param norm = 1.9401e-01, time/batch = 15.6431s	
24400/33250 (epoch 36.692), train_loss = 0.76341922, grad/param norm = 1.6507e-01, time/batch = 15.1103s	
24401/33250 (epoch 36.693), train_loss = 0.84103662, grad/param norm = 1.7787e-01, time/batch = 15.4208s	
24402/33250 (epoch 36.695), train_loss = 0.80737597, grad/param norm = 1.7438e-01, time/batch = 14.8163s	
24403/33250 (epoch 36.696), train_loss = 0.84574180, grad/param norm = 1.6645e-01, time/batch = 14.9646s	
24404/33250 (epoch 36.698), train_loss = 0.75988960, grad/param norm = 1.8959e-01, time/batch = 15.1981s	
24405/33250 (epoch 36.699), train_loss = 1.00676661, grad/param norm = 1.7750e-01, time/batch = 15.3985s	
24406/33250 (epoch 36.701), train_loss = 0.79361870, grad/param norm = 1.5276e-01, time/batch = 14.7771s	
24407/33250 (epoch 36.702), train_loss = 0.75670883, grad/param norm = 2.0404e-01, time/batch = 14.6859s	
24408/33250 (epoch 36.704), train_loss = 0.97626779, grad/param norm = 2.3175e-01, time/batch = 14.9441s	
24409/33250 (epoch 36.705), train_loss = 0.75453065, grad/param norm = 1.4527e-01, time/batch = 14.7009s	
24410/33250 (epoch 36.707), train_loss = 0.66734698, grad/param norm = 1.6274e-01, time/batch = 14.8686s	
24411/33250 (epoch 36.708), train_loss = 0.87939375, grad/param norm = 2.3511e-01, time/batch = 14.7054s	
24412/33250 (epoch 36.710), train_loss = 0.82570940, grad/param norm = 1.9609e-01, time/batch = 16.0608s	
24413/33250 (epoch 36.711), train_loss = 0.72160916, grad/param norm = 1.9628e-01, time/batch = 14.9613s	
24414/33250 (epoch 36.713), train_loss = 0.81953239, grad/param norm = 1.5908e-01, time/batch = 15.1138s	
24415/33250 (epoch 36.714), train_loss = 0.79499208, grad/param norm = 1.9676e-01, time/batch = 14.8762s	
24416/33250 (epoch 36.716), train_loss = 0.81542400, grad/param norm = 1.7850e-01, time/batch = 15.9567s	
24417/33250 (epoch 36.717), train_loss = 0.74392012, grad/param norm = 1.4426e-01, time/batch = 15.1610s	
24418/33250 (epoch 36.719), train_loss = 0.72375176, grad/param norm = 1.6397e-01, time/batch = 14.7854s	
24419/33250 (epoch 36.720), train_loss = 1.00409180, grad/param norm = 2.0111e-01, time/batch = 15.1098s	
24420/33250 (epoch 36.722), train_loss = 0.68261949, grad/param norm = 1.5470e-01, time/batch = 14.7895s	
24421/33250 (epoch 36.723), train_loss = 0.61959921, grad/param norm = 1.4421e-01, time/batch = 15.4158s	
24422/33250 (epoch 36.725), train_loss = 0.75925694, grad/param norm = 1.5351e-01, time/batch = 15.0326s	
24423/33250 (epoch 36.726), train_loss = 0.79773363, grad/param norm = 1.8178e-01, time/batch = 14.9472s	
24424/33250 (epoch 36.728), train_loss = 0.82530910, grad/param norm = 1.8416e-01, time/batch = 15.0487s	
24425/33250 (epoch 36.729), train_loss = 0.85273088, grad/param norm = 1.7295e-01, time/batch = 15.0346s	
24426/33250 (epoch 36.731), train_loss = 0.71157783, grad/param norm = 1.8558e-01, time/batch = 15.0364s	
24427/33250 (epoch 36.732), train_loss = 0.71413364, grad/param norm = 1.6167e-01, time/batch = 14.8025s	
24428/33250 (epoch 36.734), train_loss = 0.81624490, grad/param norm = 2.1613e-01, time/batch = 14.5378s	
24429/33250 (epoch 36.735), train_loss = 0.80892129, grad/param norm = 1.8094e-01, time/batch = 14.4639s	
24430/33250 (epoch 36.737), train_loss = 0.77985394, grad/param norm = 1.6464e-01, time/batch = 14.7881s	
24431/33250 (epoch 36.738), train_loss = 0.81358900, grad/param norm = 1.6977e-01, time/batch = 14.7808s	
24432/33250 (epoch 36.740), train_loss = 0.81153909, grad/param norm = 1.7201e-01, time/batch = 14.8427s	
24433/33250 (epoch 36.741), train_loss = 0.82821787, grad/param norm = 1.6899e-01, time/batch = 15.5736s	
24434/33250 (epoch 36.743), train_loss = 0.74702294, grad/param norm = 1.7544e-01, time/batch = 15.9822s	
24435/33250 (epoch 36.744), train_loss = 0.74609245, grad/param norm = 1.7988e-01, time/batch = 15.1097s	
24436/33250 (epoch 36.746), train_loss = 0.70080491, grad/param norm = 1.4843e-01, time/batch = 14.7303s	
24437/33250 (epoch 36.747), train_loss = 0.72219476, grad/param norm = 1.8863e-01, time/batch = 15.0349s	
24438/33250 (epoch 36.749), train_loss = 0.90135937, grad/param norm = 1.8574e-01, time/batch = 15.1845s	
24439/33250 (epoch 36.750), train_loss = 0.90049496, grad/param norm = 1.8138e-01, time/batch = 15.4275s	
24440/33250 (epoch 36.752), train_loss = 0.74569077, grad/param norm = 1.5398e-01, time/batch = 15.1932s	
24441/33250 (epoch 36.753), train_loss = 0.74141866, grad/param norm = 1.7939e-01, time/batch = 15.4305s	
24442/33250 (epoch 36.755), train_loss = 0.69732162, grad/param norm = 1.9722e-01, time/batch = 15.4908s	
24443/33250 (epoch 36.756), train_loss = 0.79905182, grad/param norm = 1.8167e-01, time/batch = 15.2575s	
24444/33250 (epoch 36.758), train_loss = 0.96351610, grad/param norm = 1.8627e-01, time/batch = 15.1106s	
24445/33250 (epoch 36.759), train_loss = 0.75177763, grad/param norm = 1.6056e-01, time/batch = 15.3990s	
24446/33250 (epoch 36.761), train_loss = 0.82303941, grad/param norm = 1.8239e-01, time/batch = 14.8696s	
24447/33250 (epoch 36.762), train_loss = 0.86103794, grad/param norm = 1.7529e-01, time/batch = 15.2025s	
24448/33250 (epoch 36.764), train_loss = 0.73503613, grad/param norm = 2.6844e-01, time/batch = 14.9662s	
24449/33250 (epoch 36.765), train_loss = 0.83127899, grad/param norm = 1.9693e-01, time/batch = 14.7282s	
24450/33250 (epoch 36.767), train_loss = 0.63681007, grad/param norm = 1.5651e-01, time/batch = 14.8849s	
24451/33250 (epoch 36.768), train_loss = 0.67738288, grad/param norm = 1.7446e-01, time/batch = 15.0903s	
24452/33250 (epoch 36.770), train_loss = 0.81807950, grad/param norm = 1.7889e-01, time/batch = 15.1879s	
24453/33250 (epoch 36.771), train_loss = 0.84856686, grad/param norm = 1.8132e-01, time/batch = 15.2605s	
24454/33250 (epoch 36.773), train_loss = 0.77590201, grad/param norm = 1.7342e-01, time/batch = 14.8581s	
24455/33250 (epoch 36.774), train_loss = 0.69173690, grad/param norm = 1.7930e-01, time/batch = 15.5024s	
24456/33250 (epoch 36.776), train_loss = 0.75485694, grad/param norm = 1.8416e-01, time/batch = 14.8629s	
24457/33250 (epoch 36.777), train_loss = 0.87005534, grad/param norm = 1.7314e-01, time/batch = 14.9443s	
24458/33250 (epoch 36.779), train_loss = 0.77640666, grad/param norm = 1.8849e-01, time/batch = 15.3568s	
24459/33250 (epoch 36.780), train_loss = 0.92165160, grad/param norm = 2.1519e-01, time/batch = 15.1165s	
24460/33250 (epoch 36.782), train_loss = 0.78152107, grad/param norm = 1.9913e-01, time/batch = 15.1318s	
24461/33250 (epoch 36.783), train_loss = 0.64084346, grad/param norm = 1.5797e-01, time/batch = 15.3530s	
24462/33250 (epoch 36.785), train_loss = 0.68016725, grad/param norm = 1.6380e-01, time/batch = 15.4135s	
24463/33250 (epoch 36.786), train_loss = 0.89229891, grad/param norm = 2.2668e-01, time/batch = 15.7376s	
24464/33250 (epoch 36.788), train_loss = 0.89582215, grad/param norm = 1.8583e-01, time/batch = 15.4249s	
24465/33250 (epoch 36.789), train_loss = 0.89033698, grad/param norm = 2.2823e-01, time/batch = 15.4940s	
24466/33250 (epoch 36.791), train_loss = 0.91746804, grad/param norm = 2.1086e-01, time/batch = 15.1810s	
24467/33250 (epoch 36.792), train_loss = 0.96668595, grad/param norm = 1.9690e-01, time/batch = 15.5740s	
24468/33250 (epoch 36.794), train_loss = 0.76223404, grad/param norm = 1.6446e-01, time/batch = 15.1911s	
24469/33250 (epoch 36.795), train_loss = 0.78168607, grad/param norm = 1.8023e-01, time/batch = 15.2116s	
24470/33250 (epoch 36.797), train_loss = 0.86090970, grad/param norm = 2.3936e-01, time/batch = 15.2188s	
24471/33250 (epoch 36.798), train_loss = 0.78285451, grad/param norm = 2.2633e-01, time/batch = 15.5259s	
24472/33250 (epoch 36.800), train_loss = 0.83406080, grad/param norm = 2.0075e-01, time/batch = 15.5150s	
24473/33250 (epoch 36.802), train_loss = 0.80369905, grad/param norm = 1.7553e-01, time/batch = 15.4298s	
24474/33250 (epoch 36.803), train_loss = 0.83723881, grad/param norm = 1.6858e-01, time/batch = 15.2276s	
24475/33250 (epoch 36.805), train_loss = 0.81820538, grad/param norm = 1.7055e-01, time/batch = 15.5757s	
24476/33250 (epoch 36.806), train_loss = 0.82438675, grad/param norm = 1.8340e-01, time/batch = 15.0837s	
24477/33250 (epoch 36.808), train_loss = 0.72748004, grad/param norm = 1.6283e-01, time/batch = 15.0294s	
24478/33250 (epoch 36.809), train_loss = 0.70724397, grad/param norm = 1.4655e-01, time/batch = 15.1886s	
24479/33250 (epoch 36.811), train_loss = 0.69780207, grad/param norm = 1.6129e-01, time/batch = 15.3514s	
24480/33250 (epoch 36.812), train_loss = 0.82938777, grad/param norm = 1.8285e-01, time/batch = 15.1990s	
24481/33250 (epoch 36.814), train_loss = 0.77420825, grad/param norm = 2.1453e-01, time/batch = 14.8862s	
24482/33250 (epoch 36.815), train_loss = 0.83722018, grad/param norm = 1.7631e-01, time/batch = 15.5958s	
24483/33250 (epoch 36.817), train_loss = 0.78799049, grad/param norm = 1.8251e-01, time/batch = 15.5919s	
24484/33250 (epoch 36.818), train_loss = 0.73559657, grad/param norm = 1.7419e-01, time/batch = 15.3424s	
24485/33250 (epoch 36.820), train_loss = 0.81842038, grad/param norm = 1.6712e-01, time/batch = 15.5759s	
24486/33250 (epoch 36.821), train_loss = 0.77616477, grad/param norm = 1.6283e-01, time/batch = 15.5951s	
24487/33250 (epoch 36.823), train_loss = 1.05765387, grad/param norm = 1.9333e-01, time/batch = 15.2755s	
24488/33250 (epoch 36.824), train_loss = 0.70722018, grad/param norm = 1.8256e-01, time/batch = 15.2681s	
24489/33250 (epoch 36.826), train_loss = 0.81792819, grad/param norm = 1.7943e-01, time/batch = 14.8765s	
24490/33250 (epoch 36.827), train_loss = 0.71095284, grad/param norm = 1.7927e-01, time/batch = 15.3223s	
24491/33250 (epoch 36.829), train_loss = 0.82597242, grad/param norm = 1.7726e-01, time/batch = 14.6473s	
24492/33250 (epoch 36.830), train_loss = 0.86470698, grad/param norm = 2.1493e-01, time/batch = 14.8960s	
24493/33250 (epoch 36.832), train_loss = 0.81495544, grad/param norm = 1.7334e-01, time/batch = 14.8017s	
24494/33250 (epoch 36.833), train_loss = 0.77398433, grad/param norm = 1.7942e-01, time/batch = 15.2069s	
24495/33250 (epoch 36.835), train_loss = 0.72195500, grad/param norm = 2.1113e-01, time/batch = 14.8984s	
24496/33250 (epoch 36.836), train_loss = 0.77774790, grad/param norm = 1.6135e-01, time/batch = 14.8051s	
24497/33250 (epoch 36.838), train_loss = 0.83995822, grad/param norm = 1.9081e-01, time/batch = 15.2740s	
24498/33250 (epoch 36.839), train_loss = 0.74542293, grad/param norm = 1.6337e-01, time/batch = 15.1998s	
24499/33250 (epoch 36.841), train_loss = 0.74158185, grad/param norm = 1.4433e-01, time/batch = 15.3267s	
24500/33250 (epoch 36.842), train_loss = 0.91913432, grad/param norm = 1.7680e-01, time/batch = 14.9498s	
24501/33250 (epoch 36.844), train_loss = 0.87053486, grad/param norm = 1.7513e-01, time/batch = 15.0504s	
24502/33250 (epoch 36.845), train_loss = 0.93975810, grad/param norm = 1.8375e-01, time/batch = 15.2317s	
24503/33250 (epoch 36.847), train_loss = 0.93544274, grad/param norm = 1.8906e-01, time/batch = 15.2242s	
24504/33250 (epoch 36.848), train_loss = 0.99062890, grad/param norm = 2.2375e-01, time/batch = 15.3997s	
24505/33250 (epoch 36.850), train_loss = 0.87275902, grad/param norm = 2.0721e-01, time/batch = 15.4222s	
24506/33250 (epoch 36.851), train_loss = 0.70106562, grad/param norm = 1.9109e-01, time/batch = 15.6618s	
24507/33250 (epoch 36.853), train_loss = 0.82551099, grad/param norm = 1.9000e-01, time/batch = 15.2725s	
24508/33250 (epoch 36.854), train_loss = 0.77014458, grad/param norm = 1.6359e-01, time/batch = 15.0483s	
24509/33250 (epoch 36.856), train_loss = 0.74785258, grad/param norm = 1.9444e-01, time/batch = 15.3326s	
24510/33250 (epoch 36.857), train_loss = 0.69512280, grad/param norm = 1.7973e-01, time/batch = 29.3333s	
24511/33250 (epoch 36.859), train_loss = 0.75565377, grad/param norm = 1.7527e-01, time/batch = 15.5875s	
24512/33250 (epoch 36.860), train_loss = 0.82336083, grad/param norm = 1.5604e-01, time/batch = 15.4986s	
24513/33250 (epoch 36.862), train_loss = 0.70779725, grad/param norm = 1.7454e-01, time/batch = 15.4802s	
24514/33250 (epoch 36.863), train_loss = 0.73732303, grad/param norm = 1.5025e-01, time/batch = 15.3991s	
24515/33250 (epoch 36.865), train_loss = 0.82218103, grad/param norm = 1.7614e-01, time/batch = 15.1037s	
24516/33250 (epoch 36.866), train_loss = 0.69225380, grad/param norm = 1.7569e-01, time/batch = 15.7302s	
24517/33250 (epoch 36.868), train_loss = 0.78789339, grad/param norm = 2.0146e-01, time/batch = 15.5697s	
24518/33250 (epoch 36.869), train_loss = 0.82368926, grad/param norm = 1.9328e-01, time/batch = 15.5701s	
24519/33250 (epoch 36.871), train_loss = 0.62307977, grad/param norm = 1.3924e-01, time/batch = 15.8831s	
24520/33250 (epoch 36.872), train_loss = 0.84411689, grad/param norm = 1.6700e-01, time/batch = 15.6762s	
24521/33250 (epoch 36.874), train_loss = 0.73194852, grad/param norm = 1.7988e-01, time/batch = 15.5211s	
24522/33250 (epoch 36.875), train_loss = 0.68729574, grad/param norm = 2.5335e-01, time/batch = 15.5352s	
24523/33250 (epoch 36.877), train_loss = 0.88629203, grad/param norm = 1.9274e-01, time/batch = 15.4487s	
24524/33250 (epoch 36.878), train_loss = 0.80296512, grad/param norm = 1.5738e-01, time/batch = 15.6039s	
24525/33250 (epoch 36.880), train_loss = 0.80957132, grad/param norm = 2.0572e-01, time/batch = 15.4548s	
24526/33250 (epoch 36.881), train_loss = 0.89579152, grad/param norm = 1.8465e-01, time/batch = 15.0420s	
24527/33250 (epoch 36.883), train_loss = 0.82012045, grad/param norm = 1.7589e-01, time/batch = 15.2811s	
24528/33250 (epoch 36.884), train_loss = 0.87668768, grad/param norm = 1.9759e-01, time/batch = 15.6574s	
24529/33250 (epoch 36.886), train_loss = 0.72299266, grad/param norm = 1.4819e-01, time/batch = 15.2810s	
24530/33250 (epoch 36.887), train_loss = 0.75871585, grad/param norm = 1.8995e-01, time/batch = 15.4405s	
24531/33250 (epoch 36.889), train_loss = 0.75203758, grad/param norm = 1.4857e-01, time/batch = 15.3680s	
24532/33250 (epoch 36.890), train_loss = 0.61327196, grad/param norm = 1.3732e-01, time/batch = 15.5286s	
24533/33250 (epoch 36.892), train_loss = 0.83086778, grad/param norm = 1.5765e-01, time/batch = 15.2224s	
24534/33250 (epoch 36.893), train_loss = 0.85596309, grad/param norm = 1.8169e-01, time/batch = 15.3797s	
24535/33250 (epoch 36.895), train_loss = 0.73881284, grad/param norm = 1.6724e-01, time/batch = 15.6008s	
24536/33250 (epoch 36.896), train_loss = 0.85505420, grad/param norm = 1.7393e-01, time/batch = 15.6877s	
24537/33250 (epoch 36.898), train_loss = 0.79508999, grad/param norm = 1.7645e-01, time/batch = 15.4373s	
24538/33250 (epoch 36.899), train_loss = 0.73355799, grad/param norm = 1.5778e-01, time/batch = 15.0358s	
24539/33250 (epoch 36.901), train_loss = 0.67150061, grad/param norm = 1.5444e-01, time/batch = 15.0236s	
24540/33250 (epoch 36.902), train_loss = 0.77103683, grad/param norm = 1.7758e-01, time/batch = 15.5593s	
24541/33250 (epoch 36.904), train_loss = 0.69335124, grad/param norm = 1.6657e-01, time/batch = 15.3439s	
24542/33250 (epoch 36.905), train_loss = 0.77644558, grad/param norm = 1.5480e-01, time/batch = 15.1071s	
24543/33250 (epoch 36.907), train_loss = 0.73549677, grad/param norm = 1.7438e-01, time/batch = 14.9530s	
24544/33250 (epoch 36.908), train_loss = 0.78830525, grad/param norm = 1.5180e-01, time/batch = 15.4180s	
24545/33250 (epoch 36.910), train_loss = 0.86501005, grad/param norm = 1.8154e-01, time/batch = 15.1342s	
24546/33250 (epoch 36.911), train_loss = 0.71370302, grad/param norm = 1.5731e-01, time/batch = 15.0415s	
24547/33250 (epoch 36.913), train_loss = 0.74206731, grad/param norm = 1.5835e-01, time/batch = 15.1308s	
24548/33250 (epoch 36.914), train_loss = 0.66842229, grad/param norm = 1.6074e-01, time/batch = 15.3305s	
24549/33250 (epoch 36.916), train_loss = 0.70812194, grad/param norm = 1.5835e-01, time/batch = 15.1871s	
24550/33250 (epoch 36.917), train_loss = 0.79481776, grad/param norm = 1.4578e-01, time/batch = 14.8733s	
24551/33250 (epoch 36.919), train_loss = 0.73100598, grad/param norm = 1.6815e-01, time/batch = 14.7747s	
24552/33250 (epoch 36.920), train_loss = 0.79557399, grad/param norm = 1.7608e-01, time/batch = 14.9394s	
24553/33250 (epoch 36.922), train_loss = 0.81011510, grad/param norm = 1.8272e-01, time/batch = 14.8564s	
24554/33250 (epoch 36.923), train_loss = 0.75837451, grad/param norm = 1.8216e-01, time/batch = 15.1910s	
24555/33250 (epoch 36.925), train_loss = 0.76349723, grad/param norm = 1.6737e-01, time/batch = 15.5727s	
24556/33250 (epoch 36.926), train_loss = 0.72789121, grad/param norm = 1.5134e-01, time/batch = 14.7298s	
24557/33250 (epoch 36.928), train_loss = 0.74546531, grad/param norm = 1.5856e-01, time/batch = 14.4770s	
24558/33250 (epoch 36.929), train_loss = 0.66570427, grad/param norm = 1.3212e-01, time/batch = 14.7929s	
24559/33250 (epoch 36.931), train_loss = 0.88615386, grad/param norm = 1.9504e-01, time/batch = 15.0215s	
24560/33250 (epoch 36.932), train_loss = 0.73859309, grad/param norm = 1.8444e-01, time/batch = 14.8580s	
24561/33250 (epoch 36.934), train_loss = 0.72543719, grad/param norm = 1.5630e-01, time/batch = 14.6116s	
24562/33250 (epoch 36.935), train_loss = 0.74484678, grad/param norm = 1.7662e-01, time/batch = 14.6882s	
24563/33250 (epoch 36.937), train_loss = 0.73918773, grad/param norm = 2.0733e-01, time/batch = 14.6922s	
24564/33250 (epoch 36.938), train_loss = 0.76355748, grad/param norm = 2.0221e-01, time/batch = 14.9450s	
24565/33250 (epoch 36.940), train_loss = 0.76535672, grad/param norm = 1.9131e-01, time/batch = 14.9466s	
24566/33250 (epoch 36.941), train_loss = 0.81728870, grad/param norm = 1.6953e-01, time/batch = 14.9451s	
24567/33250 (epoch 36.943), train_loss = 0.91203984, grad/param norm = 1.8577e-01, time/batch = 14.8845s	
24568/33250 (epoch 36.944), train_loss = 0.75150701, grad/param norm = 1.6509e-01, time/batch = 14.9628s	
24569/33250 (epoch 36.946), train_loss = 0.87346202, grad/param norm = 1.9702e-01, time/batch = 14.9663s	
24570/33250 (epoch 36.947), train_loss = 0.72186177, grad/param norm = 2.1643e-01, time/batch = 15.5587s	
24571/33250 (epoch 36.949), train_loss = 0.84652459, grad/param norm = 1.9834e-01, time/batch = 15.4121s	
24572/33250 (epoch 36.950), train_loss = 0.85267860, grad/param norm = 1.8427e-01, time/batch = 14.9477s	
24573/33250 (epoch 36.952), train_loss = 0.79763190, grad/param norm = 2.4130e-01, time/batch = 14.5490s	
24574/33250 (epoch 36.953), train_loss = 0.80225901, grad/param norm = 2.0704e-01, time/batch = 14.5300s	
24575/33250 (epoch 36.955), train_loss = 0.87922548, grad/param norm = 1.9247e-01, time/batch = 15.4109s	
24576/33250 (epoch 36.956), train_loss = 0.80175455, grad/param norm = 2.2247e-01, time/batch = 15.0971s	
24577/33250 (epoch 36.958), train_loss = 0.74086031, grad/param norm = 1.7775e-01, time/batch = 14.8640s	
24578/33250 (epoch 36.959), train_loss = 0.73745850, grad/param norm = 1.6436e-01, time/batch = 14.9561s	
24579/33250 (epoch 36.961), train_loss = 0.98293568, grad/param norm = 1.9862e-01, time/batch = 14.8874s	
24580/33250 (epoch 36.962), train_loss = 0.77221091, grad/param norm = 1.8716e-01, time/batch = 15.1895s	
24581/33250 (epoch 36.964), train_loss = 0.89649505, grad/param norm = 1.8544e-01, time/batch = 15.0303s	
24582/33250 (epoch 36.965), train_loss = 0.84674309, grad/param norm = 1.7910e-01, time/batch = 14.9471s	
24583/33250 (epoch 36.967), train_loss = 0.79823520, grad/param norm = 1.9302e-01, time/batch = 14.9445s	
24584/33250 (epoch 36.968), train_loss = 0.91601143, grad/param norm = 1.7550e-01, time/batch = 14.8576s	
24585/33250 (epoch 36.970), train_loss = 1.01891501, grad/param norm = 2.4389e-01, time/batch = 14.8583s	
24586/33250 (epoch 36.971), train_loss = 0.93942615, grad/param norm = 2.0010e-01, time/batch = 15.1870s	
24587/33250 (epoch 36.973), train_loss = 0.77748990, grad/param norm = 1.5422e-01, time/batch = 15.0873s	
24588/33250 (epoch 36.974), train_loss = 0.86318049, grad/param norm = 1.8878e-01, time/batch = 14.9399s	
24589/33250 (epoch 36.976), train_loss = 0.75938967, grad/param norm = 1.7877e-01, time/batch = 15.1633s	
24590/33250 (epoch 36.977), train_loss = 0.78209712, grad/param norm = 1.8667e-01, time/batch = 14.6490s	
24591/33250 (epoch 36.979), train_loss = 0.84276758, grad/param norm = 1.8121e-01, time/batch = 15.0262s	
24592/33250 (epoch 36.980), train_loss = 0.83958901, grad/param norm = 1.6389e-01, time/batch = 14.7291s	
24593/33250 (epoch 36.982), train_loss = 0.76125050, grad/param norm = 1.6512e-01, time/batch = 14.5764s	
24594/33250 (epoch 36.983), train_loss = 0.83875254, grad/param norm = 2.1216e-01, time/batch = 14.7959s	
24595/33250 (epoch 36.985), train_loss = 0.76130634, grad/param norm = 1.8686e-01, time/batch = 15.1881s	
24596/33250 (epoch 36.986), train_loss = 0.87218317, grad/param norm = 1.8488e-01, time/batch = 14.7087s	
24597/33250 (epoch 36.988), train_loss = 0.90640836, grad/param norm = 1.8792e-01, time/batch = 15.0207s	
24598/33250 (epoch 36.989), train_loss = 0.88088936, grad/param norm = 1.8658e-01, time/batch = 14.6369s	
24599/33250 (epoch 36.991), train_loss = 0.85258058, grad/param norm = 1.9275e-01, time/batch = 14.6155s	
24600/33250 (epoch 36.992), train_loss = 0.78609748, grad/param norm = 2.1148e-01, time/batch = 14.7026s	
24601/33250 (epoch 36.994), train_loss = 0.74299444, grad/param norm = 1.6865e-01, time/batch = 14.8022s	
24602/33250 (epoch 36.995), train_loss = 0.81864228, grad/param norm = 3.2820e-01, time/batch = 14.9458s	
24603/33250 (epoch 36.997), train_loss = 0.59918887, grad/param norm = 1.5789e-01, time/batch = 15.1790s	
24604/33250 (epoch 36.998), train_loss = 0.84751927, grad/param norm = 1.7303e-01, time/batch = 14.4863s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
24605/33250 (epoch 37.000), train_loss = 0.83500672, grad/param norm = 1.6365e-01, time/batch = 14.7063s	
24606/33250 (epoch 37.002), train_loss = 1.01094813, grad/param norm = 1.9241e-01, time/batch = 14.3015s	
24607/33250 (epoch 37.003), train_loss = 0.87099736, grad/param norm = 2.0464e-01, time/batch = 14.6296s	
24608/33250 (epoch 37.005), train_loss = 0.65347254, grad/param norm = 1.4384e-01, time/batch = 14.8623s	
24609/33250 (epoch 37.006), train_loss = 0.69657732, grad/param norm = 1.7572e-01, time/batch = 14.8018s	
24610/33250 (epoch 37.008), train_loss = 0.88787497, grad/param norm = 1.9761e-01, time/batch = 15.1128s	
24611/33250 (epoch 37.009), train_loss = 0.96307012, grad/param norm = 2.0367e-01, time/batch = 15.3319s	
24612/33250 (epoch 37.011), train_loss = 0.75633470, grad/param norm = 1.9438e-01, time/batch = 15.2787s	
24613/33250 (epoch 37.012), train_loss = 0.80372845, grad/param norm = 2.4043e-01, time/batch = 16.3203s	
24614/33250 (epoch 37.014), train_loss = 0.87575940, grad/param norm = 1.9092e-01, time/batch = 15.8978s	
24615/33250 (epoch 37.015), train_loss = 0.80279487, grad/param norm = 1.6345e-01, time/batch = 15.2947s	
24616/33250 (epoch 37.017), train_loss = 0.82834350, grad/param norm = 2.1514e-01, time/batch = 15.6436s	
24617/33250 (epoch 37.018), train_loss = 0.64193434, grad/param norm = 1.5053e-01, time/batch = 14.7048s	
24618/33250 (epoch 37.020), train_loss = 0.80755865, grad/param norm = 1.6692e-01, time/batch = 14.7137s	
24619/33250 (epoch 37.021), train_loss = 0.81586818, grad/param norm = 1.6762e-01, time/batch = 14.7879s	
24620/33250 (epoch 37.023), train_loss = 0.65359735, grad/param norm = 1.8361e-01, time/batch = 15.2953s	
24621/33250 (epoch 37.024), train_loss = 0.88666766, grad/param norm = 2.0102e-01, time/batch = 16.5215s	
24622/33250 (epoch 37.026), train_loss = 0.82590110, grad/param norm = 1.6916e-01, time/batch = 15.2924s	
24623/33250 (epoch 37.027), train_loss = 0.83905260, grad/param norm = 1.8994e-01, time/batch = 15.3530s	
24624/33250 (epoch 37.029), train_loss = 0.78429535, grad/param norm = 1.7965e-01, time/batch = 16.8019s	
24625/33250 (epoch 37.030), train_loss = 0.79169892, grad/param norm = 1.7428e-01, time/batch = 17.3826s	
24626/33250 (epoch 37.032), train_loss = 0.97900460, grad/param norm = 1.9688e-01, time/batch = 15.3870s	
24627/33250 (epoch 37.033), train_loss = 0.76283568, grad/param norm = 1.8646e-01, time/batch = 15.4464s	
24628/33250 (epoch 37.035), train_loss = 0.82163624, grad/param norm = 1.7892e-01, time/batch = 15.0429s	
24629/33250 (epoch 37.036), train_loss = 0.85346399, grad/param norm = 1.9749e-01, time/batch = 14.7231s	
24630/33250 (epoch 37.038), train_loss = 0.80584619, grad/param norm = 1.4441e-01, time/batch = 15.6195s	
24631/33250 (epoch 37.039), train_loss = 0.75148068, grad/param norm = 1.6797e-01, time/batch = 15.5756s	
24632/33250 (epoch 37.041), train_loss = 0.81236018, grad/param norm = 2.1801e-01, time/batch = 15.5612s	
24633/33250 (epoch 37.042), train_loss = 0.68758353, grad/param norm = 1.6162e-01, time/batch = 14.5504s	
24634/33250 (epoch 37.044), train_loss = 0.91767519, grad/param norm = 1.8675e-01, time/batch = 15.0368s	
24635/33250 (epoch 37.045), train_loss = 0.88858327, grad/param norm = 1.6539e-01, time/batch = 14.8766s	
24636/33250 (epoch 37.047), train_loss = 0.81219359, grad/param norm = 1.6327e-01, time/batch = 14.9680s	
24637/33250 (epoch 37.048), train_loss = 0.86108363, grad/param norm = 2.3188e-01, time/batch = 14.7322s	
24638/33250 (epoch 37.050), train_loss = 0.81710970, grad/param norm = 1.8087e-01, time/batch = 15.3374s	
24639/33250 (epoch 37.051), train_loss = 0.80374934, grad/param norm = 1.5289e-01, time/batch = 15.5010s	
24640/33250 (epoch 37.053), train_loss = 0.85705921, grad/param norm = 1.9287e-01, time/batch = 15.0177s	
24641/33250 (epoch 37.054), train_loss = 0.68147474, grad/param norm = 1.5617e-01, time/batch = 14.7724s	
24642/33250 (epoch 37.056), train_loss = 0.70195034, grad/param norm = 1.5735e-01, time/batch = 14.4508s	
24643/33250 (epoch 37.057), train_loss = 0.90834387, grad/param norm = 1.8094e-01, time/batch = 14.7828s	
24644/33250 (epoch 37.059), train_loss = 0.77139246, grad/param norm = 1.7983e-01, time/batch = 14.5465s	
24645/33250 (epoch 37.060), train_loss = 0.81678078, grad/param norm = 2.0525e-01, time/batch = 14.7061s	
24646/33250 (epoch 37.062), train_loss = 0.87618374, grad/param norm = 1.6265e-01, time/batch = 15.1329s	
24647/33250 (epoch 37.063), train_loss = 0.93238960, grad/param norm = 1.8689e-01, time/batch = 4.7859s	
24648/33250 (epoch 37.065), train_loss = 0.78415718, grad/param norm = 1.6198e-01, time/batch = 0.6599s	
24649/33250 (epoch 37.066), train_loss = 0.85569663, grad/param norm = 1.9570e-01, time/batch = 0.6622s	
24650/33250 (epoch 37.068), train_loss = 0.78214932, grad/param norm = 1.8578e-01, time/batch = 0.6624s	
24651/33250 (epoch 37.069), train_loss = 0.82196032, grad/param norm = 1.8083e-01, time/batch = 0.6639s	
24652/33250 (epoch 37.071), train_loss = 0.75830385, grad/param norm = 1.6069e-01, time/batch = 0.6689s	
24653/33250 (epoch 37.072), train_loss = 0.72611534, grad/param norm = 1.6119e-01, time/batch = 0.6625s	
24654/33250 (epoch 37.074), train_loss = 0.83276459, grad/param norm = 1.8645e-01, time/batch = 0.7351s	
24655/33250 (epoch 37.075), train_loss = 0.75677142, grad/param norm = 1.9366e-01, time/batch = 0.9681s	
24656/33250 (epoch 37.077), train_loss = 0.81436402, grad/param norm = 3.5504e-01, time/batch = 0.9565s	
24657/33250 (epoch 37.078), train_loss = 0.79425611, grad/param norm = 1.7107e-01, time/batch = 0.9684s	
24658/33250 (epoch 37.080), train_loss = 0.82041874, grad/param norm = 2.1491e-01, time/batch = 0.9640s	
24659/33250 (epoch 37.081), train_loss = 0.82792903, grad/param norm = 1.6299e-01, time/batch = 1.0355s	
24660/33250 (epoch 37.083), train_loss = 0.90995502, grad/param norm = 1.6973e-01, time/batch = 1.8150s	
24661/33250 (epoch 37.084), train_loss = 0.85722458, grad/param norm = 1.6518e-01, time/batch = 1.8058s	
24662/33250 (epoch 37.086), train_loss = 0.80859958, grad/param norm = 1.4816e-01, time/batch = 7.2511s	
24663/33250 (epoch 37.087), train_loss = 0.69284933, grad/param norm = 1.5013e-01, time/batch = 15.1038s	
24664/33250 (epoch 37.089), train_loss = 0.79285241, grad/param norm = 1.6707e-01, time/batch = 15.3143s	
24665/33250 (epoch 37.090), train_loss = 0.81509519, grad/param norm = 1.8291e-01, time/batch = 15.5667s	
24666/33250 (epoch 37.092), train_loss = 0.76013693, grad/param norm = 1.8247e-01, time/batch = 14.7759s	
24667/33250 (epoch 37.093), train_loss = 0.78671021, grad/param norm = 1.7013e-01, time/batch = 15.3463s	
24668/33250 (epoch 37.095), train_loss = 0.80821688, grad/param norm = 1.6704e-01, time/batch = 15.1669s	
24669/33250 (epoch 37.096), train_loss = 0.68016405, grad/param norm = 1.6844e-01, time/batch = 15.4002s	
24670/33250 (epoch 37.098), train_loss = 0.67974891, grad/param norm = 1.7205e-01, time/batch = 14.7837s	
24671/33250 (epoch 37.099), train_loss = 0.63841540, grad/param norm = 1.7137e-01, time/batch = 14.5530s	
24672/33250 (epoch 37.101), train_loss = 0.79305048, grad/param norm = 1.8696e-01, time/batch = 17.7047s	
24673/33250 (epoch 37.102), train_loss = 0.74559596, grad/param norm = 1.5953e-01, time/batch = 15.5998s	
24674/33250 (epoch 37.104), train_loss = 0.58967099, grad/param norm = 1.3521e-01, time/batch = 16.5470s	
24675/33250 (epoch 37.105), train_loss = 0.74690978, grad/param norm = 1.7846e-01, time/batch = 16.3774s	
24676/33250 (epoch 37.107), train_loss = 0.66875256, grad/param norm = 1.3540e-01, time/batch = 15.2010s	
24677/33250 (epoch 37.108), train_loss = 0.79480201, grad/param norm = 1.8853e-01, time/batch = 15.2598s	
24678/33250 (epoch 37.110), train_loss = 0.66697490, grad/param norm = 1.5984e-01, time/batch = 16.1558s	
24679/33250 (epoch 37.111), train_loss = 0.79449059, grad/param norm = 1.7339e-01, time/batch = 15.0085s	
24680/33250 (epoch 37.113), train_loss = 0.71108834, grad/param norm = 1.6148e-01, time/batch = 15.1018s	
24681/33250 (epoch 37.114), train_loss = 0.68344769, grad/param norm = 1.7978e-01, time/batch = 15.1845s	
24682/33250 (epoch 37.116), train_loss = 0.73194549, grad/param norm = 1.8855e-01, time/batch = 16.3594s	
24683/33250 (epoch 37.117), train_loss = 0.72582907, grad/param norm = 1.8073e-01, time/batch = 15.2392s	
24684/33250 (epoch 37.119), train_loss = 0.74661079, grad/param norm = 2.1262e-01, time/batch = 15.3730s	
24685/33250 (epoch 37.120), train_loss = 0.62385221, grad/param norm = 1.3983e-01, time/batch = 14.7304s	
24686/33250 (epoch 37.122), train_loss = 0.85941978, grad/param norm = 1.8700e-01, time/batch = 14.8661s	
24687/33250 (epoch 37.123), train_loss = 0.76728519, grad/param norm = 1.8582e-01, time/batch = 14.9580s	
24688/33250 (epoch 37.125), train_loss = 0.63950655, grad/param norm = 1.8835e-01, time/batch = 15.1046s	
24689/33250 (epoch 37.126), train_loss = 0.76018978, grad/param norm = 1.7332e-01, time/batch = 14.6245s	
24690/33250 (epoch 37.128), train_loss = 0.72499772, grad/param norm = 1.5376e-01, time/batch = 15.1745s	
24691/33250 (epoch 37.129), train_loss = 0.77699498, grad/param norm = 1.6040e-01, time/batch = 15.4864s	
24692/33250 (epoch 37.131), train_loss = 0.77990785, grad/param norm = 1.9976e-01, time/batch = 14.9447s	
24693/33250 (epoch 37.132), train_loss = 0.75592455, grad/param norm = 1.9963e-01, time/batch = 15.0197s	
24694/33250 (epoch 37.134), train_loss = 0.70428688, grad/param norm = 1.5974e-01, time/batch = 14.8114s	
24695/33250 (epoch 37.135), train_loss = 0.79119727, grad/param norm = 1.5408e-01, time/batch = 14.5756s	
24696/33250 (epoch 37.137), train_loss = 0.70517323, grad/param norm = 1.8052e-01, time/batch = 14.9079s	
24697/33250 (epoch 37.138), train_loss = 0.69308383, grad/param norm = 1.5008e-01, time/batch = 14.9443s	
24698/33250 (epoch 37.140), train_loss = 0.61643772, grad/param norm = 1.5092e-01, time/batch = 15.1914s	
24699/33250 (epoch 37.141), train_loss = 0.86337441, grad/param norm = 2.3948e-01, time/batch = 15.0097s	
24700/33250 (epoch 37.143), train_loss = 0.65601142, grad/param norm = 2.5569e-01, time/batch = 15.1894s	
24701/33250 (epoch 37.144), train_loss = 0.73787104, grad/param norm = 1.7661e-01, time/batch = 15.4136s	
24702/33250 (epoch 37.146), train_loss = 0.73966918, grad/param norm = 1.5816e-01, time/batch = 15.1840s	
24703/33250 (epoch 37.147), train_loss = 0.76623942, grad/param norm = 1.6893e-01, time/batch = 14.8667s	
24704/33250 (epoch 37.149), train_loss = 0.71389680, grad/param norm = 1.5593e-01, time/batch = 14.7888s	
24705/33250 (epoch 37.150), train_loss = 0.69876785, grad/param norm = 1.8994e-01, time/batch = 14.6077s	
24706/33250 (epoch 37.152), train_loss = 0.67187692, grad/param norm = 2.0005e-01, time/batch = 14.3748s	
24707/33250 (epoch 37.153), train_loss = 0.91324856, grad/param norm = 1.9716e-01, time/batch = 14.4778s	
24708/33250 (epoch 37.155), train_loss = 0.73848667, grad/param norm = 1.9934e-01, time/batch = 14.6975s	
24709/33250 (epoch 37.156), train_loss = 0.96992449, grad/param norm = 1.8751e-01, time/batch = 14.9208s	
24710/33250 (epoch 37.158), train_loss = 0.89950038, grad/param norm = 2.2307e-01, time/batch = 14.4627s	
24711/33250 (epoch 37.159), train_loss = 0.72763709, grad/param norm = 1.7489e-01, time/batch = 14.7175s	
24712/33250 (epoch 37.161), train_loss = 0.79188679, grad/param norm = 1.8153e-01, time/batch = 15.0989s	
24713/33250 (epoch 37.162), train_loss = 0.70217568, grad/param norm = 1.7347e-01, time/batch = 14.6363s	
24714/33250 (epoch 37.164), train_loss = 0.76910337, grad/param norm = 2.1252e-01, time/batch = 14.7101s	
24715/33250 (epoch 37.165), train_loss = 0.84813035, grad/param norm = 1.7775e-01, time/batch = 15.0695s	
24716/33250 (epoch 37.167), train_loss = 0.92438282, grad/param norm = 2.0191e-01, time/batch = 16.1229s	
24717/33250 (epoch 37.168), train_loss = 0.67800196, grad/param norm = 1.4388e-01, time/batch = 15.1251s	
24718/33250 (epoch 37.170), train_loss = 0.74343062, grad/param norm = 1.7474e-01, time/batch = 15.2209s	
24719/33250 (epoch 37.171), train_loss = 0.78210139, grad/param norm = 1.7141e-01, time/batch = 14.7812s	
24720/33250 (epoch 37.173), train_loss = 0.76908639, grad/param norm = 1.6352e-01, time/batch = 15.0202s	
24721/33250 (epoch 37.174), train_loss = 0.80084736, grad/param norm = 2.0978e-01, time/batch = 14.8756s	
24722/33250 (epoch 37.176), train_loss = 0.72030816, grad/param norm = 1.5651e-01, time/batch = 15.2916s	
24723/33250 (epoch 37.177), train_loss = 0.72420603, grad/param norm = 1.7256e-01, time/batch = 14.6453s	
24724/33250 (epoch 37.179), train_loss = 0.71134122, grad/param norm = 1.5094e-01, time/batch = 14.9411s	
24725/33250 (epoch 37.180), train_loss = 0.62621230, grad/param norm = 1.5140e-01, time/batch = 14.8690s	
24726/33250 (epoch 37.182), train_loss = 0.69403783, grad/param norm = 1.6633e-01, time/batch = 15.7787s	
24727/33250 (epoch 37.183), train_loss = 0.88413544, grad/param norm = 2.2412e-01, time/batch = 15.8364s	
24728/33250 (epoch 37.185), train_loss = 0.79623162, grad/param norm = 2.0261e-01, time/batch = 16.1100s	
24729/33250 (epoch 37.186), train_loss = 0.81987897, grad/param norm = 1.9219e-01, time/batch = 17.0362s	
24730/33250 (epoch 37.188), train_loss = 0.86973141, grad/param norm = 2.2538e-01, time/batch = 15.1673s	
24731/33250 (epoch 37.189), train_loss = 0.64698481, grad/param norm = 2.2400e-01, time/batch = 15.0395s	
24732/33250 (epoch 37.191), train_loss = 0.72902151, grad/param norm = 1.6959e-01, time/batch = 15.0118s	
24733/33250 (epoch 37.192), train_loss = 0.73105955, grad/param norm = 1.5356e-01, time/batch = 15.1997s	
24734/33250 (epoch 37.194), train_loss = 0.74833652, grad/param norm = 1.7063e-01, time/batch = 14.7097s	
24735/33250 (epoch 37.195), train_loss = 0.94892715, grad/param norm = 1.8388e-01, time/batch = 14.9675s	
24736/33250 (epoch 37.197), train_loss = 0.72726896, grad/param norm = 1.8002e-01, time/batch = 15.0298s	
24737/33250 (epoch 37.198), train_loss = 0.92144099, grad/param norm = 1.8498e-01, time/batch = 17.2834s	
24738/33250 (epoch 37.200), train_loss = 0.78719272, grad/param norm = 1.8926e-01, time/batch = 15.4548s	
24739/33250 (epoch 37.202), train_loss = 0.74766745, grad/param norm = 1.6420e-01, time/batch = 17.1162s	
24740/33250 (epoch 37.203), train_loss = 0.71801915, grad/param norm = 1.9618e-01, time/batch = 14.9646s	
24741/33250 (epoch 37.205), train_loss = 0.79108301, grad/param norm = 1.6445e-01, time/batch = 15.2730s	
24742/33250 (epoch 37.206), train_loss = 0.84458529, grad/param norm = 1.6313e-01, time/batch = 14.7930s	
24743/33250 (epoch 37.208), train_loss = 0.91336989, grad/param norm = 2.2771e-01, time/batch = 14.9593s	
24744/33250 (epoch 37.209), train_loss = 0.74067763, grad/param norm = 1.5941e-01, time/batch = 14.8416s	
24745/33250 (epoch 37.211), train_loss = 0.83188569, grad/param norm = 1.8041e-01, time/batch = 14.6348s	
24746/33250 (epoch 37.212), train_loss = 0.90905696, grad/param norm = 1.7300e-01, time/batch = 14.8927s	
24747/33250 (epoch 37.214), train_loss = 0.82356464, grad/param norm = 1.7114e-01, time/batch = 15.1870s	
24748/33250 (epoch 37.215), train_loss = 0.82958031, grad/param norm = 2.0178e-01, time/batch = 15.1407s	
24749/33250 (epoch 37.217), train_loss = 0.88256154, grad/param norm = 2.4267e-01, time/batch = 15.3807s	
24750/33250 (epoch 37.218), train_loss = 0.84980594, grad/param norm = 1.6922e-01, time/batch = 15.6544s	
24751/33250 (epoch 37.220), train_loss = 0.80429192, grad/param norm = 1.7355e-01, time/batch = 16.5333s	
24752/33250 (epoch 37.221), train_loss = 0.90065559, grad/param norm = 2.4633e-01, time/batch = 15.0273s	
24753/33250 (epoch 37.223), train_loss = 0.79998644, grad/param norm = 1.7387e-01, time/batch = 14.9590s	
24754/33250 (epoch 37.224), train_loss = 0.83677026, grad/param norm = 1.7355e-01, time/batch = 14.7041s	
24755/33250 (epoch 37.226), train_loss = 0.93653379, grad/param norm = 1.9596e-01, time/batch = 15.1622s	
24756/33250 (epoch 37.227), train_loss = 0.84293670, grad/param norm = 2.1329e-01, time/batch = 14.7224s	
24757/33250 (epoch 37.229), train_loss = 0.79509387, grad/param norm = 1.6018e-01, time/batch = 15.0363s	
24758/33250 (epoch 37.230), train_loss = 0.81180231, grad/param norm = 1.9866e-01, time/batch = 14.6362s	
24759/33250 (epoch 37.232), train_loss = 0.76233028, grad/param norm = 1.6676e-01, time/batch = 25.3143s	
24760/33250 (epoch 37.233), train_loss = 0.72164521, grad/param norm = 1.6531e-01, time/batch = 22.6445s	
24761/33250 (epoch 37.235), train_loss = 0.90766194, grad/param norm = 1.6516e-01, time/batch = 15.3913s	
24762/33250 (epoch 37.236), train_loss = 0.73803655, grad/param norm = 1.6652e-01, time/batch = 14.9455s	
24763/33250 (epoch 37.238), train_loss = 0.89419312, grad/param norm = 1.9163e-01, time/batch = 14.9654s	
24764/33250 (epoch 37.239), train_loss = 0.90291527, grad/param norm = 2.5272e-01, time/batch = 15.2492s	
24765/33250 (epoch 37.241), train_loss = 0.89663191, grad/param norm = 2.1162e-01, time/batch = 14.9549s	
24766/33250 (epoch 37.242), train_loss = 0.89648133, grad/param norm = 2.0535e-01, time/batch = 15.0312s	
24767/33250 (epoch 37.244), train_loss = 0.84502268, grad/param norm = 2.0744e-01, time/batch = 14.7700s	
24768/33250 (epoch 37.245), train_loss = 0.82289238, grad/param norm = 1.8305e-01, time/batch = 14.7227s	
24769/33250 (epoch 37.247), train_loss = 0.77927095, grad/param norm = 1.7101e-01, time/batch = 15.4179s	
24770/33250 (epoch 37.248), train_loss = 0.92986405, grad/param norm = 2.0131e-01, time/batch = 15.2653s	
24771/33250 (epoch 37.250), train_loss = 0.90186574, grad/param norm = 1.6593e-01, time/batch = 15.4408s	
24772/33250 (epoch 37.251), train_loss = 0.77360057, grad/param norm = 1.6062e-01, time/batch = 15.3906s	
24773/33250 (epoch 37.253), train_loss = 0.76359828, grad/param norm = 1.5714e-01, time/batch = 15.1450s	
24774/33250 (epoch 37.254), train_loss = 0.73946231, grad/param norm = 1.7043e-01, time/batch = 15.0643s	
24775/33250 (epoch 37.256), train_loss = 0.79012236, grad/param norm = 1.4719e-01, time/batch = 14.9453s	
24776/33250 (epoch 37.257), train_loss = 0.94681403, grad/param norm = 1.8585e-01, time/batch = 14.7795s	
24777/33250 (epoch 37.259), train_loss = 0.84572523, grad/param norm = 1.8537e-01, time/batch = 14.9668s	
24778/33250 (epoch 37.260), train_loss = 0.66487752, grad/param norm = 1.7679e-01, time/batch = 17.3031s	
24779/33250 (epoch 37.262), train_loss = 0.81885642, grad/param norm = 1.9964e-01, time/batch = 32.6478s	
24780/33250 (epoch 37.263), train_loss = 0.68453262, grad/param norm = 1.8072e-01, time/batch = 30.7680s	
24781/33250 (epoch 37.265), train_loss = 0.85067276, grad/param norm = 1.9330e-01, time/batch = 31.0716s	
24782/33250 (epoch 37.266), train_loss = 0.77656050, grad/param norm = 1.8203e-01, time/batch = 30.8817s	
24783/33250 (epoch 37.268), train_loss = 0.72137314, grad/param norm = 1.8699e-01, time/batch = 28.4297s	
24784/33250 (epoch 37.269), train_loss = 0.66084269, grad/param norm = 1.4811e-01, time/batch = 31.1379s	
24785/33250 (epoch 37.271), train_loss = 0.82854274, grad/param norm = 1.6705e-01, time/batch = 31.7882s	
24786/33250 (epoch 37.272), train_loss = 0.72901401, grad/param norm = 1.4884e-01, time/batch = 31.2970s	
24787/33250 (epoch 37.274), train_loss = 0.58885102, grad/param norm = 1.4610e-01, time/batch = 31.6512s	
24788/33250 (epoch 37.275), train_loss = 0.75715404, grad/param norm = 1.6273e-01, time/batch = 32.0026s	
24789/33250 (epoch 37.277), train_loss = 0.62960998, grad/param norm = 1.7739e-01, time/batch = 27.7091s	
24790/33250 (epoch 37.278), train_loss = 0.73637055, grad/param norm = 1.5396e-01, time/batch = 15.4592s	
24791/33250 (epoch 37.280), train_loss = 0.69694571, grad/param norm = 1.4723e-01, time/batch = 16.4460s	
24792/33250 (epoch 37.281), train_loss = 0.79612316, grad/param norm = 1.9353e-01, time/batch = 15.6429s	
24793/33250 (epoch 37.283), train_loss = 0.83622286, grad/param norm = 2.5751e-01, time/batch = 15.4427s	
24794/33250 (epoch 37.284), train_loss = 0.70347203, grad/param norm = 2.0508e-01, time/batch = 15.3678s	
24795/33250 (epoch 37.286), train_loss = 0.82968991, grad/param norm = 1.9927e-01, time/batch = 14.6985s	
24796/33250 (epoch 37.287), train_loss = 0.65175893, grad/param norm = 1.4825e-01, time/batch = 14.4565s	
24797/33250 (epoch 37.289), train_loss = 0.63361592, grad/param norm = 1.9471e-01, time/batch = 14.4595s	
24798/33250 (epoch 37.290), train_loss = 0.78803042, grad/param norm = 1.6146e-01, time/batch = 14.9415s	
24799/33250 (epoch 37.292), train_loss = 0.85300480, grad/param norm = 2.2806e-01, time/batch = 14.4628s	
24800/33250 (epoch 37.293), train_loss = 0.89336731, grad/param norm = 1.8510e-01, time/batch = 14.7114s	
24801/33250 (epoch 37.295), train_loss = 0.87919762, grad/param norm = 1.7735e-01, time/batch = 14.7214s	
24802/33250 (epoch 37.296), train_loss = 0.79154144, grad/param norm = 1.6032e-01, time/batch = 14.8883s	
24803/33250 (epoch 37.298), train_loss = 0.64251168, grad/param norm = 1.4859e-01, time/batch = 14.8090s	
24804/33250 (epoch 37.299), train_loss = 0.63144489, grad/param norm = 2.1203e-01, time/batch = 15.4648s	
24805/33250 (epoch 37.301), train_loss = 0.88019500, grad/param norm = 1.8786e-01, time/batch = 14.7626s	
24806/33250 (epoch 37.302), train_loss = 0.84762823, grad/param norm = 1.9499e-01, time/batch = 14.9394s	
24807/33250 (epoch 37.304), train_loss = 0.74309667, grad/param norm = 1.6280e-01, time/batch = 14.6822s	
24808/33250 (epoch 37.305), train_loss = 0.71373225, grad/param norm = 1.6084e-01, time/batch = 14.6274s	
24809/33250 (epoch 37.307), train_loss = 0.83393671, grad/param norm = 1.7033e-01, time/batch = 14.4734s	
24810/33250 (epoch 37.308), train_loss = 0.88300866, grad/param norm = 2.2477e-01, time/batch = 15.0219s	
24811/33250 (epoch 37.310), train_loss = 0.76102906, grad/param norm = 1.9419e-01, time/batch = 14.7127s	
24812/33250 (epoch 37.311), train_loss = 0.92754222, grad/param norm = 2.1899e-01, time/batch = 15.2930s	
24813/33250 (epoch 37.313), train_loss = 0.64612195, grad/param norm = 1.8121e-01, time/batch = 15.7827s	
24814/33250 (epoch 37.314), train_loss = 0.84448958, grad/param norm = 1.8436e-01, time/batch = 15.5530s	
24815/33250 (epoch 37.316), train_loss = 0.94915670, grad/param norm = 2.4185e-01, time/batch = 15.0389s	
24816/33250 (epoch 37.317), train_loss = 0.70427328, grad/param norm = 1.6370e-01, time/batch = 15.6465s	
24817/33250 (epoch 37.319), train_loss = 0.84987760, grad/param norm = 2.6831e-01, time/batch = 15.5387s	
24818/33250 (epoch 37.320), train_loss = 0.87316389, grad/param norm = 2.2446e-01, time/batch = 14.5550s	
24819/33250 (epoch 37.322), train_loss = 0.95311565, grad/param norm = 2.0622e-01, time/batch = 14.9420s	
24820/33250 (epoch 37.323), train_loss = 0.93210475, grad/param norm = 2.2232e-01, time/batch = 14.7990s	
24821/33250 (epoch 37.325), train_loss = 0.76625145, grad/param norm = 1.9185e-01, time/batch = 14.9544s	
24822/33250 (epoch 37.326), train_loss = 0.98997242, grad/param norm = 2.0871e-01, time/batch = 15.2702s	
24823/33250 (epoch 37.328), train_loss = 0.79130375, grad/param norm = 2.1086e-01, time/batch = 14.8884s	
24824/33250 (epoch 37.329), train_loss = 0.81167780, grad/param norm = 2.1203e-01, time/batch = 16.0471s	
24825/33250 (epoch 37.331), train_loss = 0.81097614, grad/param norm = 1.9770e-01, time/batch = 17.5226s	
24826/33250 (epoch 37.332), train_loss = 0.79302186, grad/param norm = 1.7584e-01, time/batch = 16.2936s	
24827/33250 (epoch 37.334), train_loss = 0.93013643, grad/param norm = 1.6345e-01, time/batch = 15.8156s	
24828/33250 (epoch 37.335), train_loss = 0.61535631, grad/param norm = 1.8790e-01, time/batch = 14.7726s	
24829/33250 (epoch 37.337), train_loss = 0.85149239, grad/param norm = 1.8433e-01, time/batch = 14.7006s	
24830/33250 (epoch 37.338), train_loss = 0.93836625, grad/param norm = 1.8059e-01, time/batch = 14.8070s	
24831/33250 (epoch 37.340), train_loss = 0.76470502, grad/param norm = 1.7606e-01, time/batch = 16.2873s	
24832/33250 (epoch 37.341), train_loss = 0.72185881, grad/param norm = 1.6517e-01, time/batch = 14.9526s	
24833/33250 (epoch 37.343), train_loss = 0.77675398, grad/param norm = 1.8437e-01, time/batch = 15.0973s	
24834/33250 (epoch 37.344), train_loss = 0.78422835, grad/param norm = 1.6066e-01, time/batch = 16.2812s	
24835/33250 (epoch 37.346), train_loss = 0.69702548, grad/param norm = 1.6485e-01, time/batch = 15.0176s	
24836/33250 (epoch 37.347), train_loss = 0.98823404, grad/param norm = 2.9054e-01, time/batch = 16.7183s	
24837/33250 (epoch 37.349), train_loss = 0.77950507, grad/param norm = 1.9713e-01, time/batch = 15.6950s	
24838/33250 (epoch 37.350), train_loss = 0.79535979, grad/param norm = 2.0759e-01, time/batch = 15.2146s	
24839/33250 (epoch 37.352), train_loss = 0.72157563, grad/param norm = 1.7271e-01, time/batch = 14.6322s	
24840/33250 (epoch 37.353), train_loss = 0.76314021, grad/param norm = 1.6935e-01, time/batch = 15.0938s	
24841/33250 (epoch 37.355), train_loss = 0.74520264, grad/param norm = 1.8596e-01, time/batch = 15.2693s	
24842/33250 (epoch 37.356), train_loss = 0.69392586, grad/param norm = 1.7352e-01, time/batch = 15.0324s	
24843/33250 (epoch 37.358), train_loss = 0.76764060, grad/param norm = 1.5214e-01, time/batch = 14.7137s	
24844/33250 (epoch 37.359), train_loss = 0.76552423, grad/param norm = 1.8328e-01, time/batch = 14.7897s	
24845/33250 (epoch 37.361), train_loss = 0.89464352, grad/param norm = 1.8824e-01, time/batch = 15.7601s	
24846/33250 (epoch 37.362), train_loss = 0.81976672, grad/param norm = 1.6323e-01, time/batch = 16.5500s	
24847/33250 (epoch 37.364), train_loss = 0.85018892, grad/param norm = 1.9711e-01, time/batch = 15.8712s	
24848/33250 (epoch 37.365), train_loss = 0.79809457, grad/param norm = 1.7402e-01, time/batch = 15.6390s	
24849/33250 (epoch 37.367), train_loss = 0.80553327, grad/param norm = 1.4604e-01, time/batch = 15.2739s	
24850/33250 (epoch 37.368), train_loss = 0.78955393, grad/param norm = 1.9918e-01, time/batch = 14.7004s	
24851/33250 (epoch 37.370), train_loss = 0.72006965, grad/param norm = 1.4722e-01, time/batch = 14.8820s	
24852/33250 (epoch 37.371), train_loss = 0.88368066, grad/param norm = 1.8243e-01, time/batch = 15.1587s	
24853/33250 (epoch 37.373), train_loss = 0.76764910, grad/param norm = 1.4791e-01, time/batch = 14.9583s	
24854/33250 (epoch 37.374), train_loss = 0.81102300, grad/param norm = 2.5030e-01, time/batch = 14.5548s	
24855/33250 (epoch 37.376), train_loss = 0.78738923, grad/param norm = 1.6242e-01, time/batch = 14.8025s	
24856/33250 (epoch 37.377), train_loss = 0.68896715, grad/param norm = 1.8690e-01, time/batch = 15.2118s	
24857/33250 (epoch 37.379), train_loss = 0.79462392, grad/param norm = 1.8384e-01, time/batch = 15.7240s	
24858/33250 (epoch 37.380), train_loss = 0.78140766, grad/param norm = 1.9899e-01, time/batch = 15.3200s	
24859/33250 (epoch 37.382), train_loss = 0.81796532, grad/param norm = 2.2720e-01, time/batch = 16.1210s	
24860/33250 (epoch 37.383), train_loss = 0.70832029, grad/param norm = 1.7227e-01, time/batch = 15.4709s	
24861/33250 (epoch 37.385), train_loss = 0.66051360, grad/param norm = 1.7144e-01, time/batch = 14.7173s	
24862/33250 (epoch 37.386), train_loss = 0.71198805, grad/param norm = 2.0062e-01, time/batch = 15.2793s	
24863/33250 (epoch 37.388), train_loss = 0.72485845, grad/param norm = 1.8754e-01, time/batch = 15.1958s	
24864/33250 (epoch 37.389), train_loss = 0.75853567, grad/param norm = 2.1107e-01, time/batch = 15.1800s	
24865/33250 (epoch 37.391), train_loss = 0.85147882, grad/param norm = 2.0079e-01, time/batch = 15.0406s	
24866/33250 (epoch 37.392), train_loss = 0.88328585, grad/param norm = 1.8494e-01, time/batch = 14.9495s	
24867/33250 (epoch 37.394), train_loss = 0.88986252, grad/param norm = 1.9742e-01, time/batch = 15.7986s	
24868/33250 (epoch 37.395), train_loss = 0.87272442, grad/param norm = 1.6882e-01, time/batch = 15.4784s	
24869/33250 (epoch 37.397), train_loss = 0.89541864, grad/param norm = 1.6392e-01, time/batch = 16.2080s	
24870/33250 (epoch 37.398), train_loss = 0.71003773, grad/param norm = 1.6602e-01, time/batch = 17.7207s	
24871/33250 (epoch 37.400), train_loss = 0.69209948, grad/param norm = 1.4916e-01, time/batch = 15.8798s	
24872/33250 (epoch 37.402), train_loss = 0.67149079, grad/param norm = 1.7671e-01, time/batch = 15.1938s	
24873/33250 (epoch 37.403), train_loss = 0.76951235, grad/param norm = 2.0732e-01, time/batch = 15.2421s	
24874/33250 (epoch 37.405), train_loss = 0.72738449, grad/param norm = 1.4763e-01, time/batch = 15.0710s	
24875/33250 (epoch 37.406), train_loss = 0.77887033, grad/param norm = 2.0705e-01, time/batch = 14.7135s	
24876/33250 (epoch 37.408), train_loss = 0.94454146, grad/param norm = 1.8354e-01, time/batch = 14.9340s	
24877/33250 (epoch 37.409), train_loss = 0.82929722, grad/param norm = 2.2140e-01, time/batch = 14.4522s	
24878/33250 (epoch 37.411), train_loss = 0.58213436, grad/param norm = 1.3771e-01, time/batch = 14.5407s	
24879/33250 (epoch 37.412), train_loss = 0.66812989, grad/param norm = 1.7877e-01, time/batch = 14.3628s	
24880/33250 (epoch 37.414), train_loss = 0.81128581, grad/param norm = 1.6947e-01, time/batch = 15.3256s	
24881/33250 (epoch 37.415), train_loss = 0.85777770, grad/param norm = 1.8612e-01, time/batch = 15.4610s	
24882/33250 (epoch 37.417), train_loss = 0.89199822, grad/param norm = 1.7777e-01, time/batch = 14.9673s	
24883/33250 (epoch 37.418), train_loss = 1.02677127, grad/param norm = 2.4139e-01, time/batch = 14.8010s	
24884/33250 (epoch 37.420), train_loss = 0.87555281, grad/param norm = 1.7651e-01, time/batch = 14.9380s	
24885/33250 (epoch 37.421), train_loss = 0.75462481, grad/param norm = 1.5722e-01, time/batch = 14.6299s	
24886/33250 (epoch 37.423), train_loss = 0.83284122, grad/param norm = 2.1621e-01, time/batch = 14.7119s	
24887/33250 (epoch 37.424), train_loss = 0.91968183, grad/param norm = 3.2224e-01, time/batch = 14.4598s	
24888/33250 (epoch 37.426), train_loss = 0.76348631, grad/param norm = 1.5118e-01, time/batch = 14.9524s	
24889/33250 (epoch 37.427), train_loss = 0.73647398, grad/param norm = 2.0341e-01, time/batch = 15.3889s	
24890/33250 (epoch 37.429), train_loss = 0.81856961, grad/param norm = 2.1766e-01, time/batch = 15.3834s	
24891/33250 (epoch 37.430), train_loss = 0.75096502, grad/param norm = 1.8115e-01, time/batch = 15.1092s	
24892/33250 (epoch 37.432), train_loss = 0.89512000, grad/param norm = 2.0652e-01, time/batch = 15.5921s	
24893/33250 (epoch 37.433), train_loss = 0.72078864, grad/param norm = 2.2634e-01, time/batch = 15.5539s	
24894/33250 (epoch 37.435), train_loss = 0.87536213, grad/param norm = 1.7269e-01, time/batch = 14.7092s	
24895/33250 (epoch 37.436), train_loss = 0.74745454, grad/param norm = 1.9006e-01, time/batch = 14.6936s	
24896/33250 (epoch 37.438), train_loss = 0.89347883, grad/param norm = 1.7646e-01, time/batch = 15.0307s	
24897/33250 (epoch 37.439), train_loss = 0.80114347, grad/param norm = 1.5602e-01, time/batch = 15.1199s	
24898/33250 (epoch 37.441), train_loss = 0.77320413, grad/param norm = 1.7231e-01, time/batch = 14.5480s	
24899/33250 (epoch 37.442), train_loss = 0.72637618, grad/param norm = 1.7623e-01, time/batch = 14.6979s	
24900/33250 (epoch 37.444), train_loss = 0.75422267, grad/param norm = 1.5793e-01, time/batch = 15.0338s	
24901/33250 (epoch 37.445), train_loss = 0.81372075, grad/param norm = 1.5788e-01, time/batch = 16.0530s	
24902/33250 (epoch 37.447), train_loss = 0.71729598, grad/param norm = 1.6504e-01, time/batch = 15.8862s	
24903/33250 (epoch 37.448), train_loss = 0.82876902, grad/param norm = 1.5955e-01, time/batch = 16.0299s	
24904/33250 (epoch 37.450), train_loss = 0.91668457, grad/param norm = 1.9570e-01, time/batch = 14.9525s	
24905/33250 (epoch 37.451), train_loss = 0.85941751, grad/param norm = 2.0148e-01, time/batch = 14.6288s	
24906/33250 (epoch 37.453), train_loss = 0.69961019, grad/param norm = 1.5254e-01, time/batch = 14.7780s	
24907/33250 (epoch 37.454), train_loss = 0.92769921, grad/param norm = 1.8354e-01, time/batch = 15.1008s	
24908/33250 (epoch 37.456), train_loss = 0.90596231, grad/param norm = 1.5372e-01, time/batch = 15.0318s	
24909/33250 (epoch 37.457), train_loss = 0.73231335, grad/param norm = 1.6045e-01, time/batch = 15.2751s	
24910/33250 (epoch 37.459), train_loss = 0.86142848, grad/param norm = 1.9719e-01, time/batch = 16.1822s	
24911/33250 (epoch 37.460), train_loss = 0.87430333, grad/param norm = 1.8572e-01, time/batch = 15.9243s	
24912/33250 (epoch 37.462), train_loss = 0.78285879, grad/param norm = 2.0259e-01, time/batch = 16.8330s	
24913/33250 (epoch 37.463), train_loss = 0.70686123, grad/param norm = 1.2697e-01, time/batch = 15.2022s	
24914/33250 (epoch 37.465), train_loss = 0.66233520, grad/param norm = 1.5955e-01, time/batch = 14.8825s	
24915/33250 (epoch 37.466), train_loss = 0.64527279, grad/param norm = 1.3334e-01, time/batch = 14.8660s	
24916/33250 (epoch 37.468), train_loss = 0.68453533, grad/param norm = 1.4440e-01, time/batch = 14.7634s	
24917/33250 (epoch 37.469), train_loss = 0.77832806, grad/param norm = 2.0076e-01, time/batch = 14.5936s	
24918/33250 (epoch 37.471), train_loss = 0.85388730, grad/param norm = 1.7525e-01, time/batch = 14.8433s	
24919/33250 (epoch 37.472), train_loss = 0.75949958, grad/param norm = 1.9054e-01, time/batch = 15.1788s	
24920/33250 (epoch 37.474), train_loss = 0.88505529, grad/param norm = 2.0195e-01, time/batch = 14.9673s	
24921/33250 (epoch 37.475), train_loss = 0.80256718, grad/param norm = 1.5017e-01, time/batch = 14.8716s	
24922/33250 (epoch 37.477), train_loss = 0.81356093, grad/param norm = 1.4705e-01, time/batch = 15.1228s	
24923/33250 (epoch 37.478), train_loss = 0.70292788, grad/param norm = 1.6150e-01, time/batch = 16.1735s	
24924/33250 (epoch 37.480), train_loss = 0.88452702, grad/param norm = 1.7224e-01, time/batch = 16.1423s	
24925/33250 (epoch 37.481), train_loss = 0.77466250, grad/param norm = 1.7674e-01, time/batch = 15.0685s	
24926/33250 (epoch 37.483), train_loss = 0.77747989, grad/param norm = 1.7925e-01, time/batch = 16.8713s	
24927/33250 (epoch 37.484), train_loss = 0.72067229, grad/param norm = 1.6094e-01, time/batch = 15.0976s	
24928/33250 (epoch 37.486), train_loss = 0.65274772, grad/param norm = 1.6057e-01, time/batch = 14.7890s	
24929/33250 (epoch 37.487), train_loss = 0.72434404, grad/param norm = 1.5742e-01, time/batch = 14.6349s	
24930/33250 (epoch 37.489), train_loss = 0.85480244, grad/param norm = 1.9687e-01, time/batch = 14.9508s	
24931/33250 (epoch 37.490), train_loss = 0.81634247, grad/param norm = 1.8369e-01, time/batch = 15.1997s	
24932/33250 (epoch 37.492), train_loss = 0.88499894, grad/param norm = 1.9116e-01, time/batch = 15.6143s	
24933/33250 (epoch 37.493), train_loss = 0.79095044, grad/param norm = 1.7348e-01, time/batch = 16.8660s	
24934/33250 (epoch 37.495), train_loss = 0.85348265, grad/param norm = 1.5900e-01, time/batch = 16.4658s	
24935/33250 (epoch 37.496), train_loss = 0.80897220, grad/param norm = 1.4911e-01, time/batch = 15.2319s	
24936/33250 (epoch 37.498), train_loss = 0.86225648, grad/param norm = 1.7687e-01, time/batch = 15.4790s	
24937/33250 (epoch 37.499), train_loss = 0.75411565, grad/param norm = 1.7435e-01, time/batch = 14.7704s	
24938/33250 (epoch 37.501), train_loss = 0.75638936, grad/param norm = 2.0998e-01, time/batch = 15.2976s	
24939/33250 (epoch 37.502), train_loss = 0.75688909, grad/param norm = 1.5541e-01, time/batch = 15.6369s	
24940/33250 (epoch 37.504), train_loss = 0.91914314, grad/param norm = 1.9870e-01, time/batch = 14.9562s	
24941/33250 (epoch 37.505), train_loss = 0.68775916, grad/param norm = 1.3615e-01, time/batch = 14.8622s	
24942/33250 (epoch 37.507), train_loss = 0.72674499, grad/param norm = 1.8232e-01, time/batch = 14.8604s	
24943/33250 (epoch 37.508), train_loss = 0.75169573, grad/param norm = 1.6211e-01, time/batch = 14.7785s	
24944/33250 (epoch 37.510), train_loss = 0.65497180, grad/param norm = 1.4503e-01, time/batch = 17.0447s	
24945/33250 (epoch 37.511), train_loss = 0.77724623, grad/param norm = 1.8002e-01, time/batch = 15.4432s	
24946/33250 (epoch 37.513), train_loss = 0.90502795, grad/param norm = 1.7279e-01, time/batch = 15.4554s	
24947/33250 (epoch 37.514), train_loss = 0.76524501, grad/param norm = 1.8529e-01, time/batch = 17.4375s	
24948/33250 (epoch 37.516), train_loss = 0.72742424, grad/param norm = 1.9743e-01, time/batch = 14.7141s	
24949/33250 (epoch 37.517), train_loss = 0.76226297, grad/param norm = 1.6769e-01, time/batch = 15.0326s	
24950/33250 (epoch 37.519), train_loss = 0.69584723, grad/param norm = 1.3186e-01, time/batch = 15.0061s	
24951/33250 (epoch 37.520), train_loss = 0.97113756, grad/param norm = 2.5443e-01, time/batch = 14.8034s	
24952/33250 (epoch 37.522), train_loss = 0.83196261, grad/param norm = 1.7697e-01, time/batch = 14.9513s	
24953/33250 (epoch 37.523), train_loss = 0.71669372, grad/param norm = 1.9099e-01, time/batch = 14.9516s	
24954/33250 (epoch 37.525), train_loss = 0.67112921, grad/param norm = 1.8005e-01, time/batch = 15.1867s	
24955/33250 (epoch 37.526), train_loss = 0.70587721, grad/param norm = 1.6080e-01, time/batch = 15.4885s	
24956/33250 (epoch 37.528), train_loss = 0.75149548, grad/param norm = 1.6599e-01, time/batch = 15.3346s	
24957/33250 (epoch 37.529), train_loss = 0.72869232, grad/param norm = 1.6395e-01, time/batch = 14.9086s	
24958/33250 (epoch 37.531), train_loss = 0.70928441, grad/param norm = 1.5716e-01, time/batch = 15.1874s	
24959/33250 (epoch 37.532), train_loss = 0.82832299, grad/param norm = 1.5253e-01, time/batch = 14.8470s	
24960/33250 (epoch 37.534), train_loss = 0.70229965, grad/param norm = 1.4551e-01, time/batch = 14.7965s	
24961/33250 (epoch 37.535), train_loss = 0.77468413, grad/param norm = 1.7055e-01, time/batch = 14.7699s	
24962/33250 (epoch 37.537), train_loss = 0.78774070, grad/param norm = 1.5903e-01, time/batch = 15.2615s	
24963/33250 (epoch 37.538), train_loss = 0.82682161, grad/param norm = 1.7262e-01, time/batch = 14.5480s	
24964/33250 (epoch 37.540), train_loss = 0.94026664, grad/param norm = 1.6007e-01, time/batch = 14.7164s	
24965/33250 (epoch 37.541), train_loss = 0.83279588, grad/param norm = 1.8184e-01, time/batch = 14.5307s	
24966/33250 (epoch 37.543), train_loss = 0.83068100, grad/param norm = 1.6288e-01, time/batch = 15.3917s	
24967/33250 (epoch 37.544), train_loss = 0.69121269, grad/param norm = 1.6449e-01, time/batch = 15.5506s	
24968/33250 (epoch 37.546), train_loss = 0.74173155, grad/param norm = 1.9872e-01, time/batch = 15.0328s	
24969/33250 (epoch 37.547), train_loss = 0.76105674, grad/param norm = 1.8569e-01, time/batch = 15.3842s	
24970/33250 (epoch 37.549), train_loss = 0.79903496, grad/param norm = 1.7057e-01, time/batch = 15.1920s	
24971/33250 (epoch 37.550), train_loss = 0.76020909, grad/param norm = 1.5681e-01, time/batch = 14.3853s	
24972/33250 (epoch 37.552), train_loss = 0.83145127, grad/param norm = 1.6632e-01, time/batch = 14.4638s	
24973/33250 (epoch 37.553), train_loss = 0.77186763, grad/param norm = 1.6867e-01, time/batch = 14.7957s	
24974/33250 (epoch 37.555), train_loss = 0.80955407, grad/param norm = 1.5672e-01, time/batch = 15.0448s	
24975/33250 (epoch 37.556), train_loss = 0.80559996, grad/param norm = 2.1875e-01, time/batch = 14.7130s	
24976/33250 (epoch 37.558), train_loss = 0.83401923, grad/param norm = 1.7934e-01, time/batch = 14.7905s	
24977/33250 (epoch 37.559), train_loss = 0.72506561, grad/param norm = 1.6283e-01, time/batch = 17.3927s	
24978/33250 (epoch 37.561), train_loss = 0.68436946, grad/param norm = 1.6686e-01, time/batch = 15.4431s	
24979/33250 (epoch 37.562), train_loss = 0.78600352, grad/param norm = 1.8515e-01, time/batch = 15.7274s	
24980/33250 (epoch 37.564), train_loss = 0.95662695, grad/param norm = 2.2535e-01, time/batch = 16.8920s	
24981/33250 (epoch 37.565), train_loss = 0.88867488, grad/param norm = 2.0897e-01, time/batch = 14.7121s	
24982/33250 (epoch 37.567), train_loss = 0.90328090, grad/param norm = 1.9552e-01, time/batch = 23.0735s	
24983/33250 (epoch 37.568), train_loss = 0.75910349, grad/param norm = 1.8519e-01, time/batch = 22.1859s	
24984/33250 (epoch 37.570), train_loss = 0.86242409, grad/param norm = 1.8979e-01, time/batch = 15.0313s	
24985/33250 (epoch 37.571), train_loss = 0.88648222, grad/param norm = 1.7953e-01, time/batch = 15.2559s	
24986/33250 (epoch 37.573), train_loss = 0.83850448, grad/param norm = 1.7757e-01, time/batch = 15.2383s	
24987/33250 (epoch 37.574), train_loss = 0.73111842, grad/param norm = 1.5048e-01, time/batch = 14.7927s	
24988/33250 (epoch 37.576), train_loss = 0.81877890, grad/param norm = 1.7147e-01, time/batch = 15.1822s	
24989/33250 (epoch 37.577), train_loss = 0.77245677, grad/param norm = 1.5897e-01, time/batch = 15.5270s	
24990/33250 (epoch 37.579), train_loss = 0.67980268, grad/param norm = 1.8119e-01, time/batch = 16.7841s	
24991/33250 (epoch 37.580), train_loss = 0.79460408, grad/param norm = 1.9373e-01, time/batch = 15.4587s	
24992/33250 (epoch 37.582), train_loss = 0.75322925, grad/param norm = 1.7959e-01, time/batch = 15.1235s	
24993/33250 (epoch 37.583), train_loss = 0.85467556, grad/param norm = 1.9330e-01, time/batch = 15.2541s	
24994/33250 (epoch 37.585), train_loss = 0.88049330, grad/param norm = 1.8238e-01, time/batch = 15.1725s	
24995/33250 (epoch 37.586), train_loss = 0.75791349, grad/param norm = 1.9560e-01, time/batch = 14.6392s	
24996/33250 (epoch 37.588), train_loss = 0.81659951, grad/param norm = 1.7353e-01, time/batch = 15.1905s	
24997/33250 (epoch 37.589), train_loss = 0.78949527, grad/param norm = 1.9025e-01, time/batch = 14.9622s	
24998/33250 (epoch 37.591), train_loss = 0.78251424, grad/param norm = 1.9129e-01, time/batch = 16.7135s	
24999/33250 (epoch 37.592), train_loss = 0.75481934, grad/param norm = 1.8706e-01, time/batch = 16.1403s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch37.59_1.6687.t7	
25000/33250 (epoch 37.594), train_loss = 0.89288135, grad/param norm = 1.9151e-01, time/batch = 15.3660s	
25001/33250 (epoch 37.595), train_loss = 1.30524060, grad/param norm = 2.2377e-01, time/batch = 16.5512s	
25002/33250 (epoch 37.597), train_loss = 0.66094479, grad/param norm = 1.5483e-01, time/batch = 16.9502s	
25003/33250 (epoch 37.598), train_loss = 0.75926301, grad/param norm = 2.1862e-01, time/batch = 14.9566s	
25004/33250 (epoch 37.600), train_loss = 0.76268518, grad/param norm = 1.9377e-01, time/batch = 14.6393s	
25005/33250 (epoch 37.602), train_loss = 0.80006482, grad/param norm = 1.8361e-01, time/batch = 15.0132s	
25006/33250 (epoch 37.603), train_loss = 0.83072324, grad/param norm = 1.8812e-01, time/batch = 14.7925s	
25007/33250 (epoch 37.605), train_loss = 0.78011278, grad/param norm = 1.7032e-01, time/batch = 14.8030s	
25008/33250 (epoch 37.606), train_loss = 0.83703180, grad/param norm = 1.8149e-01, time/batch = 14.8812s	
25009/33250 (epoch 37.608), train_loss = 0.80570490, grad/param norm = 1.6138e-01, time/batch = 15.3665s	
25010/33250 (epoch 37.609), train_loss = 0.69200939, grad/param norm = 1.5611e-01, time/batch = 15.1027s	
25011/33250 (epoch 37.611), train_loss = 0.76612772, grad/param norm = 1.9829e-01, time/batch = 15.9722s	
25012/33250 (epoch 37.612), train_loss = 0.76514840, grad/param norm = 1.7001e-01, time/batch = 16.7257s	
25013/33250 (epoch 37.614), train_loss = 0.97324972, grad/param norm = 1.9084e-01, time/batch = 15.4912s	
25014/33250 (epoch 37.615), train_loss = 0.90114845, grad/param norm = 2.2392e-01, time/batch = 15.0899s	
25015/33250 (epoch 37.617), train_loss = 0.98797774, grad/param norm = 1.9056e-01, time/batch = 14.7967s	
25016/33250 (epoch 37.618), train_loss = 1.01593952, grad/param norm = 2.4699e-01, time/batch = 14.8761s	
25017/33250 (epoch 37.620), train_loss = 0.86769451, grad/param norm = 1.8801e-01, time/batch = 14.5508s	
25018/33250 (epoch 37.621), train_loss = 0.84283482, grad/param norm = 1.8066e-01, time/batch = 15.0973s	
25019/33250 (epoch 37.623), train_loss = 0.74752688, grad/param norm = 1.6831e-01, time/batch = 15.2143s	
25020/33250 (epoch 37.624), train_loss = 0.77151134, grad/param norm = 2.2587e-01, time/batch = 15.4539s	
25021/33250 (epoch 37.626), train_loss = 0.76113085, grad/param norm = 1.9175e-01, time/batch = 14.9743s	
25022/33250 (epoch 37.627), train_loss = 0.74306623, grad/param norm = 1.5365e-01, time/batch = 15.6091s	
25023/33250 (epoch 37.629), train_loss = 0.84783092, grad/param norm = 2.3909e-01, time/batch = 17.2147s	
25024/33250 (epoch 37.630), train_loss = 0.76374371, grad/param norm = 1.9919e-01, time/batch = 15.2409s	
25025/33250 (epoch 37.632), train_loss = 0.69102847, grad/param norm = 1.7262e-01, time/batch = 16.3772s	
25026/33250 (epoch 37.633), train_loss = 0.80639167, grad/param norm = 1.7951e-01, time/batch = 14.8613s	
25027/33250 (epoch 37.635), train_loss = 0.73171421, grad/param norm = 1.8131e-01, time/batch = 14.7831s	
25028/33250 (epoch 37.636), train_loss = 0.74512293, grad/param norm = 1.4723e-01, time/batch = 15.4561s	
25029/33250 (epoch 37.638), train_loss = 0.71144070, grad/param norm = 1.8225e-01, time/batch = 15.0411s	
25030/33250 (epoch 37.639), train_loss = 0.69268418, grad/param norm = 1.7746e-01, time/batch = 15.0962s	
25031/33250 (epoch 37.641), train_loss = 0.76328988, grad/param norm = 1.7692e-01, time/batch = 14.9693s	
25032/33250 (epoch 37.642), train_loss = 0.60439531, grad/param norm = 1.8697e-01, time/batch = 14.7945s	
25033/33250 (epoch 37.644), train_loss = 0.56580231, grad/param norm = 1.6373e-01, time/batch = 16.8804s	
25034/33250 (epoch 37.645), train_loss = 0.81791309, grad/param norm = 2.1061e-01, time/batch = 15.2011s	
25035/33250 (epoch 37.647), train_loss = 0.67592778, grad/param norm = 1.7410e-01, time/batch = 14.9582s	
25036/33250 (epoch 37.648), train_loss = 0.67548505, grad/param norm = 1.7929e-01, time/batch = 15.6297s	
25037/33250 (epoch 37.650), train_loss = 0.91560482, grad/param norm = 2.0888e-01, time/batch = 16.1688s	
25038/33250 (epoch 37.651), train_loss = 0.82746276, grad/param norm = 2.0078e-01, time/batch = 15.1134s	
25039/33250 (epoch 37.653), train_loss = 0.74245832, grad/param norm = 1.5756e-01, time/batch = 14.7920s	
25040/33250 (epoch 37.654), train_loss = 0.77949466, grad/param norm = 1.5742e-01, time/batch = 14.9359s	
25041/33250 (epoch 37.656), train_loss = 0.82832229, grad/param norm = 1.6394e-01, time/batch = 15.1940s	
25042/33250 (epoch 37.657), train_loss = 0.61441580, grad/param norm = 1.5500e-01, time/batch = 15.2189s	
25043/33250 (epoch 37.659), train_loss = 0.75464733, grad/param norm = 1.8933e-01, time/batch = 14.5543s	
25044/33250 (epoch 37.660), train_loss = 0.80155212, grad/param norm = 1.9351e-01, time/batch = 15.7069s	
25045/33250 (epoch 37.662), train_loss = 0.81211869, grad/param norm = 1.6909e-01, time/batch = 16.0463s	
25046/33250 (epoch 37.663), train_loss = 0.72568232, grad/param norm = 1.7814e-01, time/batch = 14.7125s	
25047/33250 (epoch 37.665), train_loss = 0.79588560, grad/param norm = 1.6579e-01, time/batch = 15.4192s	
25048/33250 (epoch 37.666), train_loss = 0.74275880, grad/param norm = 1.4996e-01, time/batch = 14.7921s	
25049/33250 (epoch 37.668), train_loss = 0.87755097, grad/param norm = 1.7478e-01, time/batch = 15.3426s	
25050/33250 (epoch 37.669), train_loss = 0.80054869, grad/param norm = 1.7322e-01, time/batch = 14.8514s	
25051/33250 (epoch 37.671), train_loss = 0.67234319, grad/param norm = 1.5628e-01, time/batch = 14.9325s	
25052/33250 (epoch 37.672), train_loss = 0.87766568, grad/param norm = 2.0190e-01, time/batch = 15.3961s	
25053/33250 (epoch 37.674), train_loss = 0.70703696, grad/param norm = 1.8943e-01, time/batch = 15.2538s	
25054/33250 (epoch 37.675), train_loss = 0.78116401, grad/param norm = 1.4778e-01, time/batch = 14.6270s	
25055/33250 (epoch 37.677), train_loss = 0.84904073, grad/param norm = 1.7055e-01, time/batch = 15.2181s	
25056/33250 (epoch 37.678), train_loss = 0.73894260, grad/param norm = 1.8034e-01, time/batch = 15.8096s	
25057/33250 (epoch 37.680), train_loss = 0.88347898, grad/param norm = 1.8161e-01, time/batch = 15.4378s	
25058/33250 (epoch 37.681), train_loss = 0.70944984, grad/param norm = 1.6051e-01, time/batch = 15.9731s	
25059/33250 (epoch 37.683), train_loss = 0.72341819, grad/param norm = 1.7211e-01, time/batch = 14.7123s	
25060/33250 (epoch 37.684), train_loss = 0.67598801, grad/param norm = 1.7406e-01, time/batch = 14.3927s	
25061/33250 (epoch 37.686), train_loss = 0.68307453, grad/param norm = 1.5998e-01, time/batch = 15.2895s	
25062/33250 (epoch 37.687), train_loss = 0.79786465, grad/param norm = 1.7480e-01, time/batch = 14.8368s	
25063/33250 (epoch 37.689), train_loss = 0.67498758, grad/param norm = 1.7306e-01, time/batch = 14.5466s	
25064/33250 (epoch 37.690), train_loss = 0.80913340, grad/param norm = 2.0681e-01, time/batch = 14.2986s	
25065/33250 (epoch 37.692), train_loss = 0.75711635, grad/param norm = 1.6710e-01, time/batch = 14.7109s	
25066/33250 (epoch 37.693), train_loss = 0.81894350, grad/param norm = 1.6899e-01, time/batch = 18.7850s	
25067/33250 (epoch 37.695), train_loss = 0.80507150, grad/param norm = 1.7426e-01, time/batch = 15.8906s	
25068/33250 (epoch 37.696), train_loss = 0.83299876, grad/param norm = 1.7376e-01, time/batch = 14.3433s	
25069/33250 (epoch 37.698), train_loss = 0.75154653, grad/param norm = 1.8072e-01, time/batch = 16.2500s	
25070/33250 (epoch 37.699), train_loss = 0.99270966, grad/param norm = 1.7065e-01, time/batch = 14.9648s	
25071/33250 (epoch 37.701), train_loss = 0.77646764, grad/param norm = 1.4384e-01, time/batch = 14.7105s	
25072/33250 (epoch 37.702), train_loss = 0.74759221, grad/param norm = 3.1592e-01, time/batch = 14.5521s	
25073/33250 (epoch 37.704), train_loss = 0.97885995, grad/param norm = 2.9608e-01, time/batch = 15.0158s	
25074/33250 (epoch 37.705), train_loss = 0.73457659, grad/param norm = 1.5291e-01, time/batch = 14.3054s	
25075/33250 (epoch 37.707), train_loss = 0.66609666, grad/param norm = 1.7285e-01, time/batch = 14.7835s	
25076/33250 (epoch 37.708), train_loss = 0.86984866, grad/param norm = 1.8206e-01, time/batch = 15.0081s	
25077/33250 (epoch 37.710), train_loss = 0.81017285, grad/param norm = 1.9196e-01, time/batch = 14.8577s	
25078/33250 (epoch 37.711), train_loss = 0.70210314, grad/param norm = 1.7731e-01, time/batch = 15.8947s	
25079/33250 (epoch 37.713), train_loss = 0.81464157, grad/param norm = 1.7200e-01, time/batch = 14.9426s	
25080/33250 (epoch 37.714), train_loss = 0.78614499, grad/param norm = 1.9421e-01, time/batch = 14.7827s	
25081/33250 (epoch 37.716), train_loss = 0.79848924, grad/param norm = 1.6396e-01, time/batch = 15.4202s	
25082/33250 (epoch 37.717), train_loss = 0.74884547, grad/param norm = 1.4104e-01, time/batch = 14.7106s	
25083/33250 (epoch 37.719), train_loss = 0.72104640, grad/param norm = 1.6240e-01, time/batch = 14.9516s	
25084/33250 (epoch 37.720), train_loss = 1.01120397, grad/param norm = 1.8243e-01, time/batch = 14.7178s	
25085/33250 (epoch 37.722), train_loss = 0.68840248, grad/param norm = 1.7452e-01, time/batch = 14.8592s	
25086/33250 (epoch 37.723), train_loss = 0.61164612, grad/param norm = 1.3755e-01, time/batch = 14.6339s	
25087/33250 (epoch 37.725), train_loss = 0.74614514, grad/param norm = 1.4570e-01, time/batch = 14.5509s	
25088/33250 (epoch 37.726), train_loss = 0.79885631, grad/param norm = 1.7316e-01, time/batch = 17.0365s	
25089/33250 (epoch 37.728), train_loss = 0.82158751, grad/param norm = 1.8543e-01, time/batch = 16.1153s	
25090/33250 (epoch 37.729), train_loss = 0.85723084, grad/param norm = 1.7693e-01, time/batch = 15.9659s	
25091/33250 (epoch 37.731), train_loss = 0.69706765, grad/param norm = 1.9022e-01, time/batch = 16.0601s	
25092/33250 (epoch 37.732), train_loss = 0.71408798, grad/param norm = 1.6536e-01, time/batch = 14.7917s	
25093/33250 (epoch 37.734), train_loss = 0.81557658, grad/param norm = 1.8478e-01, time/batch = 14.7814s	
25094/33250 (epoch 37.735), train_loss = 0.81125358, grad/param norm = 1.8152e-01, time/batch = 14.6370s	
25095/33250 (epoch 37.737), train_loss = 0.75783490, grad/param norm = 1.4867e-01, time/batch = 14.7915s	
25096/33250 (epoch 37.738), train_loss = 0.80707214, grad/param norm = 1.7376e-01, time/batch = 15.1840s	
25097/33250 (epoch 37.740), train_loss = 0.80878657, grad/param norm = 1.8273e-01, time/batch = 15.2601s	
25098/33250 (epoch 37.741), train_loss = 0.81235681, grad/param norm = 1.6018e-01, time/batch = 15.3865s	
25099/33250 (epoch 37.743), train_loss = 0.73525226, grad/param norm = 1.6506e-01, time/batch = 15.6167s	
25100/33250 (epoch 37.744), train_loss = 0.73332167, grad/param norm = 1.7958e-01, time/batch = 15.6694s	
25101/33250 (epoch 37.746), train_loss = 0.69302813, grad/param norm = 1.5542e-01, time/batch = 16.0397s	
25102/33250 (epoch 37.747), train_loss = 0.70729259, grad/param norm = 1.5031e-01, time/batch = 15.5389s	
25103/33250 (epoch 37.749), train_loss = 0.87493456, grad/param norm = 1.7545e-01, time/batch = 15.7900s	
25104/33250 (epoch 37.750), train_loss = 0.88433235, grad/param norm = 1.7783e-01, time/batch = 15.2009s	
25105/33250 (epoch 37.752), train_loss = 0.74530262, grad/param norm = 1.6072e-01, time/batch = 15.5989s	
25106/33250 (epoch 37.753), train_loss = 0.72594258, grad/param norm = 1.8358e-01, time/batch = 15.2736s	
25107/33250 (epoch 37.755), train_loss = 0.67393393, grad/param norm = 1.7380e-01, time/batch = 15.3759s	
25108/33250 (epoch 37.756), train_loss = 0.79088636, grad/param norm = 1.9253e-01, time/batch = 15.1866s	
25109/33250 (epoch 37.758), train_loss = 0.93703785, grad/param norm = 1.7275e-01, time/batch = 16.7053s	
25110/33250 (epoch 37.759), train_loss = 0.74320156, grad/param norm = 1.6874e-01, time/batch = 15.9618s	
25111/33250 (epoch 37.761), train_loss = 0.83439045, grad/param norm = 2.0637e-01, time/batch = 16.3025s	
25112/33250 (epoch 37.762), train_loss = 0.84842308, grad/param norm = 2.0867e-01, time/batch = 17.9429s	
25113/33250 (epoch 37.764), train_loss = 0.70714742, grad/param norm = 2.1222e-01, time/batch = 15.6827s	
25114/33250 (epoch 37.765), train_loss = 0.81828787, grad/param norm = 1.9018e-01, time/batch = 15.0368s	
25115/33250 (epoch 37.767), train_loss = 0.62154708, grad/param norm = 1.6258e-01, time/batch = 15.1900s	
25116/33250 (epoch 37.768), train_loss = 0.66700400, grad/param norm = 1.7409e-01, time/batch = 14.8548s	
25117/33250 (epoch 37.770), train_loss = 0.80376746, grad/param norm = 1.8841e-01, time/batch = 14.9506s	
25118/33250 (epoch 37.771), train_loss = 0.83132400, grad/param norm = 1.8938e-01, time/batch = 16.2747s	
25119/33250 (epoch 37.773), train_loss = 0.75401910, grad/param norm = 1.7866e-01, time/batch = 14.8759s	
25120/33250 (epoch 37.774), train_loss = 0.66123603, grad/param norm = 1.7077e-01, time/batch = 16.2053s	
25121/33250 (epoch 37.776), train_loss = 0.74449110, grad/param norm = 1.7008e-01, time/batch = 17.3813s	
25122/33250 (epoch 37.777), train_loss = 0.87082702, grad/param norm = 1.7767e-01, time/batch = 18.2135s	
25123/33250 (epoch 37.779), train_loss = 0.76739399, grad/param norm = 2.0477e-01, time/batch = 15.2645s	
25124/33250 (epoch 37.780), train_loss = 0.89882669, grad/param norm = 2.0718e-01, time/batch = 15.6387s	
25125/33250 (epoch 37.782), train_loss = 0.78529887, grad/param norm = 2.0094e-01, time/batch = 16.0344s	
25126/33250 (epoch 37.783), train_loss = 0.63913170, grad/param norm = 1.7656e-01, time/batch = 15.7840s	
25127/33250 (epoch 37.785), train_loss = 0.66623882, grad/param norm = 1.5501e-01, time/batch = 15.0231s	
25128/33250 (epoch 37.786), train_loss = 0.88459696, grad/param norm = 1.9349e-01, time/batch = 14.3961s	
25129/33250 (epoch 37.788), train_loss = 0.87936167, grad/param norm = 1.8403e-01, time/batch = 14.3646s	
25130/33250 (epoch 37.789), train_loss = 0.88711110, grad/param norm = 2.1800e-01, time/batch = 14.5523s	
25131/33250 (epoch 37.791), train_loss = 0.90910390, grad/param norm = 2.2738e-01, time/batch = 16.3024s	
25132/33250 (epoch 37.792), train_loss = 0.95647236, grad/param norm = 1.9675e-01, time/batch = 15.8179s	
25133/33250 (epoch 37.794), train_loss = 0.75960627, grad/param norm = 1.8592e-01, time/batch = 16.6464s	
25134/33250 (epoch 37.795), train_loss = 0.76801920, grad/param norm = 1.9474e-01, time/batch = 14.8723s	
25135/33250 (epoch 37.797), train_loss = 0.83970412, grad/param norm = 1.9850e-01, time/batch = 14.3856s	
25136/33250 (epoch 37.798), train_loss = 0.75598872, grad/param norm = 1.8765e-01, time/batch = 14.6141s	
25137/33250 (epoch 37.800), train_loss = 0.82769974, grad/param norm = 2.0145e-01, time/batch = 14.8656s	
25138/33250 (epoch 37.802), train_loss = 0.79428055, grad/param norm = 1.8303e-01, time/batch = 14.4648s	
25139/33250 (epoch 37.803), train_loss = 0.82311548, grad/param norm = 1.7270e-01, time/batch = 14.8639s	
25140/33250 (epoch 37.805), train_loss = 0.82379815, grad/param norm = 1.8342e-01, time/batch = 14.8781s	
25141/33250 (epoch 37.806), train_loss = 0.78816826, grad/param norm = 1.6262e-01, time/batch = 15.5443s	
25142/33250 (epoch 37.808), train_loss = 0.72298660, grad/param norm = 1.9063e-01, time/batch = 15.9734s	
25143/33250 (epoch 37.809), train_loss = 0.70645622, grad/param norm = 1.5638e-01, time/batch = 16.2950s	
25144/33250 (epoch 37.811), train_loss = 0.70520350, grad/param norm = 1.6818e-01, time/batch = 15.4821s	
25145/33250 (epoch 37.812), train_loss = 0.83049644, grad/param norm = 2.0179e-01, time/batch = 15.2091s	
25146/33250 (epoch 37.814), train_loss = 0.75305671, grad/param norm = 1.9807e-01, time/batch = 15.1700s	
25147/33250 (epoch 37.815), train_loss = 0.83030955, grad/param norm = 1.8422e-01, time/batch = 15.5333s	
25148/33250 (epoch 37.817), train_loss = 0.77346072, grad/param norm = 1.7719e-01, time/batch = 15.0445s	
25149/33250 (epoch 37.818), train_loss = 0.72304738, grad/param norm = 1.6941e-01, time/batch = 14.5505s	
25150/33250 (epoch 37.820), train_loss = 0.82173715, grad/param norm = 1.8543e-01, time/batch = 14.9354s	
25151/33250 (epoch 37.821), train_loss = 0.78183369, grad/param norm = 1.7998e-01, time/batch = 15.6957s	
25152/33250 (epoch 37.823), train_loss = 1.05017826, grad/param norm = 2.0150e-01, time/batch = 15.6423s	
25153/33250 (epoch 37.824), train_loss = 0.72154835, grad/param norm = 1.9299e-01, time/batch = 17.3746s	
25154/33250 (epoch 37.826), train_loss = 0.83523572, grad/param norm = 1.9320e-01, time/batch = 15.2024s	
25155/33250 (epoch 37.827), train_loss = 0.69976534, grad/param norm = 1.6468e-01, time/batch = 14.9122s	
25156/33250 (epoch 37.829), train_loss = 0.80784942, grad/param norm = 1.6008e-01, time/batch = 14.7191s	
25157/33250 (epoch 37.830), train_loss = 0.85187714, grad/param norm = 2.2150e-01, time/batch = 14.9331s	
25158/33250 (epoch 37.832), train_loss = 0.80914166, grad/param norm = 1.9109e-01, time/batch = 14.6952s	
25159/33250 (epoch 37.833), train_loss = 0.77553848, grad/param norm = 1.9586e-01, time/batch = 14.8700s	
25160/33250 (epoch 37.835), train_loss = 0.70724716, grad/param norm = 2.0187e-01, time/batch = 15.0423s	
25161/33250 (epoch 37.836), train_loss = 0.77816636, grad/param norm = 1.7346e-01, time/batch = 14.5516s	
25162/33250 (epoch 37.838), train_loss = 0.82234092, grad/param norm = 1.7947e-01, time/batch = 15.1749s	
25163/33250 (epoch 37.839), train_loss = 0.75031679, grad/param norm = 1.7294e-01, time/batch = 14.9728s	
25164/33250 (epoch 37.841), train_loss = 0.75537742, grad/param norm = 1.8086e-01, time/batch = 15.6367s	
25165/33250 (epoch 37.842), train_loss = 0.91547973, grad/param norm = 1.9124e-01, time/batch = 17.8658s	
25166/33250 (epoch 37.844), train_loss = 0.86402526, grad/param norm = 1.8621e-01, time/batch = 15.9435s	
25167/33250 (epoch 37.845), train_loss = 0.93463165, grad/param norm = 1.8404e-01, time/batch = 14.8113s	
25168/33250 (epoch 37.847), train_loss = 0.91699190, grad/param norm = 1.7682e-01, time/batch = 14.7905s	
25169/33250 (epoch 37.848), train_loss = 0.96323265, grad/param norm = 2.0516e-01, time/batch = 14.8004s	
25170/33250 (epoch 37.850), train_loss = 0.88138113, grad/param norm = 1.8334e-01, time/batch = 14.9441s	
25171/33250 (epoch 37.851), train_loss = 0.69463364, grad/param norm = 1.8136e-01, time/batch = 14.9446s	
25172/33250 (epoch 37.853), train_loss = 0.83704347, grad/param norm = 2.2232e-01, time/batch = 14.6285s	
25173/33250 (epoch 37.854), train_loss = 0.76282751, grad/param norm = 1.7585e-01, time/batch = 14.7905s	
25174/33250 (epoch 37.856), train_loss = 0.76718715, grad/param norm = 2.7738e-01, time/batch = 15.1284s	
25175/33250 (epoch 37.857), train_loss = 0.69142920, grad/param norm = 2.1636e-01, time/batch = 16.4311s	
25176/33250 (epoch 37.859), train_loss = 0.75428192, grad/param norm = 2.0442e-01, time/batch = 17.8811s	
25177/33250 (epoch 37.860), train_loss = 0.81888478, grad/param norm = 1.7337e-01, time/batch = 15.8696s	
25178/33250 (epoch 37.862), train_loss = 0.70327040, grad/param norm = 1.6214e-01, time/batch = 15.1809s	
25179/33250 (epoch 37.863), train_loss = 0.74816282, grad/param norm = 1.7467e-01, time/batch = 15.2110s	
25180/33250 (epoch 37.865), train_loss = 0.80572816, grad/param norm = 1.6408e-01, time/batch = 14.8669s	
25181/33250 (epoch 37.866), train_loss = 0.70494670, grad/param norm = 2.0656e-01, time/batch = 15.2034s	
25182/33250 (epoch 37.868), train_loss = 0.78548611, grad/param norm = 1.9208e-01, time/batch = 15.3805s	
25183/33250 (epoch 37.869), train_loss = 0.82945918, grad/param norm = 1.8974e-01, time/batch = 14.7089s	
25184/33250 (epoch 37.871), train_loss = 0.63984274, grad/param norm = 1.5847e-01, time/batch = 16.6242s	
25185/33250 (epoch 37.872), train_loss = 0.84024930, grad/param norm = 2.2044e-01, time/batch = 16.1350s	
25186/33250 (epoch 37.874), train_loss = 0.72098348, grad/param norm = 1.6770e-01, time/batch = 18.2864s	
25187/33250 (epoch 37.875), train_loss = 0.66498571, grad/param norm = 1.9846e-01, time/batch = 16.8895s	
25188/33250 (epoch 37.877), train_loss = 0.88384832, grad/param norm = 1.7795e-01, time/batch = 15.1106s	
25189/33250 (epoch 37.878), train_loss = 0.78107396, grad/param norm = 1.5585e-01, time/batch = 15.0436s	
25190/33250 (epoch 37.880), train_loss = 0.78828005, grad/param norm = 1.9894e-01, time/batch = 15.0413s	
25191/33250 (epoch 37.881), train_loss = 0.90131253, grad/param norm = 1.8126e-01, time/batch = 15.1151s	
25192/33250 (epoch 37.883), train_loss = 0.81541163, grad/param norm = 1.6791e-01, time/batch = 14.8462s	
25193/33250 (epoch 37.884), train_loss = 0.88899357, grad/param norm = 2.2035e-01, time/batch = 15.0187s	
25194/33250 (epoch 37.886), train_loss = 0.72803338, grad/param norm = 1.5492e-01, time/batch = 14.8764s	
25195/33250 (epoch 37.887), train_loss = 0.74585921, grad/param norm = 1.7158e-01, time/batch = 17.6275s	
25196/33250 (epoch 37.889), train_loss = 0.73615569, grad/param norm = 1.4840e-01, time/batch = 16.3762s	
25197/33250 (epoch 37.890), train_loss = 0.60824732, grad/param norm = 1.3449e-01, time/batch = 14.5689s	
25198/33250 (epoch 37.892), train_loss = 0.82079713, grad/param norm = 1.6416e-01, time/batch = 15.5157s	
25199/33250 (epoch 37.893), train_loss = 0.84872766, grad/param norm = 1.9788e-01, time/batch = 15.4640s	
25200/33250 (epoch 37.895), train_loss = 0.72849307, grad/param norm = 1.6480e-01, time/batch = 15.0275s	
25201/33250 (epoch 37.896), train_loss = 0.85407690, grad/param norm = 1.8842e-01, time/batch = 16.0936s	
25202/33250 (epoch 37.898), train_loss = 0.78647416, grad/param norm = 1.6816e-01, time/batch = 15.1256s	
25203/33250 (epoch 37.899), train_loss = 0.73091513, grad/param norm = 1.7093e-01, time/batch = 14.8807s	
25204/33250 (epoch 37.901), train_loss = 0.65664836, grad/param norm = 1.4904e-01, time/batch = 17.5594s	
25205/33250 (epoch 37.902), train_loss = 0.76130033, grad/param norm = 2.1004e-01, time/batch = 27.8125s	
25206/33250 (epoch 37.904), train_loss = 0.70698270, grad/param norm = 1.6416e-01, time/batch = 15.2238s	
25207/33250 (epoch 37.905), train_loss = 0.76628476, grad/param norm = 1.5048e-01, time/batch = 15.6248s	
25208/33250 (epoch 37.907), train_loss = 0.72068010, grad/param norm = 1.9679e-01, time/batch = 14.8122s	
25209/33250 (epoch 37.908), train_loss = 0.77269267, grad/param norm = 1.5149e-01, time/batch = 14.7955s	
25210/33250 (epoch 37.910), train_loss = 0.85494882, grad/param norm = 1.9361e-01, time/batch = 14.7899s	
25211/33250 (epoch 37.911), train_loss = 0.71174048, grad/param norm = 1.6595e-01, time/batch = 15.1854s	
25212/33250 (epoch 37.913), train_loss = 0.74672479, grad/param norm = 1.7506e-01, time/batch = 15.1632s	
25213/33250 (epoch 37.914), train_loss = 0.66970674, grad/param norm = 1.6246e-01, time/batch = 14.8724s	
25214/33250 (epoch 37.916), train_loss = 0.69567286, grad/param norm = 1.5831e-01, time/batch = 14.6307s	
25215/33250 (epoch 37.917), train_loss = 0.78616555, grad/param norm = 1.4783e-01, time/batch = 15.0997s	
25216/33250 (epoch 37.919), train_loss = 0.71616446, grad/param norm = 1.7194e-01, time/batch = 15.1549s	
25217/33250 (epoch 37.920), train_loss = 0.79131943, grad/param norm = 1.7689e-01, time/batch = 15.0560s	
25218/33250 (epoch 37.922), train_loss = 0.77671976, grad/param norm = 1.7592e-01, time/batch = 16.0111s	
25219/33250 (epoch 37.923), train_loss = 0.74804959, grad/param norm = 1.7471e-01, time/batch = 15.0190s	
25220/33250 (epoch 37.925), train_loss = 0.75338156, grad/param norm = 1.6414e-01, time/batch = 14.9441s	
25221/33250 (epoch 37.926), train_loss = 0.72573622, grad/param norm = 1.4721e-01, time/batch = 15.1241s	
25222/33250 (epoch 37.928), train_loss = 0.73672243, grad/param norm = 1.6446e-01, time/batch = 14.6920s	
25223/33250 (epoch 37.929), train_loss = 0.66275527, grad/param norm = 1.4058e-01, time/batch = 15.1108s	
25224/33250 (epoch 37.931), train_loss = 0.87044521, grad/param norm = 1.7442e-01, time/batch = 14.8710s	
25225/33250 (epoch 37.932), train_loss = 0.72784862, grad/param norm = 1.8087e-01, time/batch = 14.7911s	
25226/33250 (epoch 37.934), train_loss = 0.70961479, grad/param norm = 1.4625e-01, time/batch = 14.8841s	
25227/33250 (epoch 37.935), train_loss = 0.74538414, grad/param norm = 1.8047e-01, time/batch = 15.2062s	
25228/33250 (epoch 37.937), train_loss = 0.72929105, grad/param norm = 1.8930e-01, time/batch = 14.8974s	
25229/33250 (epoch 37.938), train_loss = 0.74664108, grad/param norm = 1.9394e-01, time/batch = 16.2933s	
25230/33250 (epoch 37.940), train_loss = 0.75234808, grad/param norm = 1.7803e-01, time/batch = 17.1100s	
25231/33250 (epoch 37.941), train_loss = 0.81415268, grad/param norm = 1.8628e-01, time/batch = 15.2611s	
25232/33250 (epoch 37.943), train_loss = 0.91789800, grad/param norm = 1.8541e-01, time/batch = 15.1370s	
25233/33250 (epoch 37.944), train_loss = 0.74635238, grad/param norm = 1.6905e-01, time/batch = 15.1094s	
25234/33250 (epoch 37.946), train_loss = 0.85669216, grad/param norm = 2.1438e-01, time/batch = 15.3776s	
25235/33250 (epoch 37.947), train_loss = 0.71257953, grad/param norm = 1.9736e-01, time/batch = 15.4378s	
25236/33250 (epoch 37.949), train_loss = 0.82892092, grad/param norm = 1.8099e-01, time/batch = 14.8882s	
25237/33250 (epoch 37.950), train_loss = 0.85591512, grad/param norm = 1.8422e-01, time/batch = 15.2048s	
25238/33250 (epoch 37.952), train_loss = 0.80054141, grad/param norm = 2.2225e-01, time/batch = 17.1266s	
25239/33250 (epoch 37.953), train_loss = 0.78825570, grad/param norm = 1.9295e-01, time/batch = 17.8601s	
25240/33250 (epoch 37.955), train_loss = 0.87044125, grad/param norm = 2.1949e-01, time/batch = 16.7243s	
25241/33250 (epoch 37.956), train_loss = 0.79880564, grad/param norm = 2.3095e-01, time/batch = 16.2229s	
25242/33250 (epoch 37.958), train_loss = 0.73774763, grad/param norm = 1.6776e-01, time/batch = 15.0106s	
25243/33250 (epoch 37.959), train_loss = 0.74669296, grad/param norm = 1.8148e-01, time/batch = 14.9530s	
25244/33250 (epoch 37.961), train_loss = 0.95941484, grad/param norm = 1.9274e-01, time/batch = 15.1763s	
25245/33250 (epoch 37.962), train_loss = 0.76604202, grad/param norm = 2.1766e-01, time/batch = 15.0333s	
25246/33250 (epoch 37.964), train_loss = 0.89021314, grad/param norm = 1.9798e-01, time/batch = 14.9557s	
25247/33250 (epoch 37.965), train_loss = 0.83030458, grad/param norm = 2.0190e-01, time/batch = 14.9639s	
25248/33250 (epoch 37.967), train_loss = 0.79368393, grad/param norm = 1.8173e-01, time/batch = 15.8571s	
25249/33250 (epoch 37.968), train_loss = 0.88920926, grad/param norm = 1.7328e-01, time/batch = 15.3900s	
25250/33250 (epoch 37.970), train_loss = 1.01518378, grad/param norm = 2.3263e-01, time/batch = 15.4451s	
25251/33250 (epoch 37.971), train_loss = 0.94870073, grad/param norm = 2.1521e-01, time/batch = 18.4486s	
25252/33250 (epoch 37.973), train_loss = 0.76332391, grad/param norm = 1.6456e-01, time/batch = 14.7986s	
25253/33250 (epoch 37.974), train_loss = 0.85621363, grad/param norm = 1.9689e-01, time/batch = 14.9548s	
25254/33250 (epoch 37.976), train_loss = 0.76709828, grad/param norm = 2.0794e-01, time/batch = 14.9491s	
25255/33250 (epoch 37.977), train_loss = 0.76999184, grad/param norm = 1.6337e-01, time/batch = 15.8733s	
25256/33250 (epoch 37.979), train_loss = 0.84754631, grad/param norm = 1.8980e-01, time/batch = 14.8012s	
25257/33250 (epoch 37.980), train_loss = 0.83384403, grad/param norm = 1.7655e-01, time/batch = 14.7118s	
25258/33250 (epoch 37.982), train_loss = 0.76265861, grad/param norm = 1.5454e-01, time/batch = 15.4423s	
25259/33250 (epoch 37.983), train_loss = 0.83566796, grad/param norm = 2.1125e-01, time/batch = 15.7758s	
25260/33250 (epoch 37.985), train_loss = 0.74978323, grad/param norm = 1.9520e-01, time/batch = 17.0531s	
25261/33250 (epoch 37.986), train_loss = 0.85521146, grad/param norm = 1.7574e-01, time/batch = 15.4359s	
25262/33250 (epoch 37.988), train_loss = 0.88362437, grad/param norm = 1.7260e-01, time/batch = 16.3005s	
25263/33250 (epoch 37.989), train_loss = 0.87809307, grad/param norm = 1.9203e-01, time/batch = 15.1412s	
25264/33250 (epoch 37.991), train_loss = 0.83462902, grad/param norm = 1.6608e-01, time/batch = 14.9575s	
25265/33250 (epoch 37.992), train_loss = 0.78640060, grad/param norm = 1.7426e-01, time/batch = 14.5272s	
25266/33250 (epoch 37.994), train_loss = 0.75405872, grad/param norm = 1.7920e-01, time/batch = 15.3780s	
25267/33250 (epoch 37.995), train_loss = 0.77665747, grad/param norm = 1.9722e-01, time/batch = 14.7139s	
25268/33250 (epoch 37.997), train_loss = 0.58915710, grad/param norm = 1.5474e-01, time/batch = 15.5420s	
25269/33250 (epoch 37.998), train_loss = 0.82422490, grad/param norm = 1.7457e-01, time/batch = 15.1798s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
25270/33250 (epoch 38.000), train_loss = 0.83638614, grad/param norm = 1.8501e-01, time/batch = 16.3716s	
25271/33250 (epoch 38.002), train_loss = 1.00628124, grad/param norm = 1.8367e-01, time/batch = 16.3073s	
25272/33250 (epoch 38.003), train_loss = 0.85821683, grad/param norm = 2.0030e-01, time/batch = 18.9590s	
25273/33250 (epoch 38.005), train_loss = 0.64182719, grad/param norm = 1.4199e-01, time/batch = 16.2884s	
25274/33250 (epoch 38.006), train_loss = 0.67198022, grad/param norm = 1.6670e-01, time/batch = 15.1759s	
25275/33250 (epoch 38.008), train_loss = 0.87799258, grad/param norm = 1.7993e-01, time/batch = 14.8659s	
25276/33250 (epoch 38.009), train_loss = 0.94976348, grad/param norm = 1.8051e-01, time/batch = 14.8467s	
25277/33250 (epoch 38.011), train_loss = 0.75191576, grad/param norm = 1.8050e-01, time/batch = 14.5226s	
25278/33250 (epoch 38.012), train_loss = 0.77271904, grad/param norm = 2.0905e-01, time/batch = 14.4706s	
25279/33250 (epoch 38.014), train_loss = 0.87095076, grad/param norm = 2.1015e-01, time/batch = 14.7067s	
25280/33250 (epoch 38.015), train_loss = 0.80854245, grad/param norm = 1.7276e-01, time/batch = 14.8770s	
25281/33250 (epoch 38.017), train_loss = 0.83451331, grad/param norm = 2.0347e-01, time/batch = 17.1809s	
25282/33250 (epoch 38.018), train_loss = 0.64024462, grad/param norm = 1.6744e-01, time/batch = 16.8766s	
25283/33250 (epoch 38.020), train_loss = 0.80380691, grad/param norm = 1.6761e-01, time/batch = 15.7285s	
25284/33250 (epoch 38.021), train_loss = 0.81259863, grad/param norm = 1.7638e-01, time/batch = 16.7134s	
25285/33250 (epoch 38.023), train_loss = 0.66040394, grad/param norm = 2.1642e-01, time/batch = 15.2629s	
25286/33250 (epoch 38.024), train_loss = 0.87478658, grad/param norm = 1.8686e-01, time/batch = 14.8741s	
25287/33250 (epoch 38.026), train_loss = 0.82888052, grad/param norm = 1.6520e-01, time/batch = 15.1128s	
25288/33250 (epoch 38.027), train_loss = 0.83938580, grad/param norm = 1.7453e-01, time/batch = 15.2718s	
25289/33250 (epoch 38.029), train_loss = 0.76329187, grad/param norm = 1.7476e-01, time/batch = 14.9429s	
25290/33250 (epoch 38.030), train_loss = 0.77629330, grad/param norm = 1.8174e-01, time/batch = 14.6313s	
25291/33250 (epoch 38.032), train_loss = 0.98315177, grad/param norm = 2.0289e-01, time/batch = 14.8791s	
25292/33250 (epoch 38.033), train_loss = 0.75580433, grad/param norm = 1.8318e-01, time/batch = 16.2108s	
25293/33250 (epoch 38.035), train_loss = 0.81483054, grad/param norm = 1.7452e-01, time/batch = 15.6413s	
25294/33250 (epoch 38.036), train_loss = 0.85687130, grad/param norm = 2.0835e-01, time/batch = 15.7218s	
25295/33250 (epoch 38.038), train_loss = 0.79853712, grad/param norm = 1.4458e-01, time/batch = 14.8725s	
25296/33250 (epoch 38.039), train_loss = 0.73789409, grad/param norm = 1.6517e-01, time/batch = 14.9504s	
25297/33250 (epoch 38.041), train_loss = 0.83273521, grad/param norm = 2.6869e-01, time/batch = 14.9606s	
25298/33250 (epoch 38.042), train_loss = 0.67485445, grad/param norm = 1.5782e-01, time/batch = 15.1334s	
25299/33250 (epoch 38.044), train_loss = 0.90191739, grad/param norm = 1.7821e-01, time/batch = 14.9639s	
25300/33250 (epoch 38.045), train_loss = 0.90072110, grad/param norm = 1.7201e-01, time/batch = 15.0350s	
25301/33250 (epoch 38.047), train_loss = 0.82532531, grad/param norm = 2.0971e-01, time/batch = 15.1782s	
25302/33250 (epoch 38.048), train_loss = 0.84417103, grad/param norm = 2.0402e-01, time/batch = 14.8710s	
25303/33250 (epoch 38.050), train_loss = 0.81073511, grad/param norm = 2.0274e-01, time/batch = 17.8588s	
25304/33250 (epoch 38.051), train_loss = 0.79974223, grad/param norm = 1.8353e-01, time/batch = 15.2285s	
25305/33250 (epoch 38.053), train_loss = 0.85478132, grad/param norm = 1.8483e-01, time/batch = 15.4792s	
25306/33250 (epoch 38.054), train_loss = 0.66995004, grad/param norm = 1.5827e-01, time/batch = 15.5615s	
25307/33250 (epoch 38.056), train_loss = 0.68951276, grad/param norm = 1.5363e-01, time/batch = 15.7928s	
25308/33250 (epoch 38.057), train_loss = 0.89128347, grad/param norm = 1.8001e-01, time/batch = 15.7279s	
25309/33250 (epoch 38.059), train_loss = 0.76538131, grad/param norm = 1.9244e-01, time/batch = 15.7233s	
25310/33250 (epoch 38.060), train_loss = 0.82945767, grad/param norm = 1.9789e-01, time/batch = 15.0743s	
25311/33250 (epoch 38.062), train_loss = 0.87679519, grad/param norm = 1.8462e-01, time/batch = 15.7632s	
25312/33250 (epoch 38.063), train_loss = 0.91881998, grad/param norm = 1.8536e-01, time/batch = 14.9259s	
25313/33250 (epoch 38.065), train_loss = 0.76841999, grad/param norm = 1.6309e-01, time/batch = 14.7602s	
25314/33250 (epoch 38.066), train_loss = 0.84787782, grad/param norm = 2.3896e-01, time/batch = 14.8304s	
25315/33250 (epoch 38.068), train_loss = 0.78435264, grad/param norm = 2.1353e-01, time/batch = 14.8507s	
25316/33250 (epoch 38.069), train_loss = 0.81056292, grad/param norm = 1.7411e-01, time/batch = 15.5954s	
25317/33250 (epoch 38.071), train_loss = 0.74975857, grad/param norm = 1.5691e-01, time/batch = 17.7890s	
25318/33250 (epoch 38.072), train_loss = 0.72488182, grad/param norm = 1.5316e-01, time/batch = 15.5468s	
25319/33250 (epoch 38.074), train_loss = 0.82631793, grad/param norm = 1.7047e-01, time/batch = 15.1814s	
25320/33250 (epoch 38.075), train_loss = 0.74517550, grad/param norm = 1.6630e-01, time/batch = 14.6339s	
25321/33250 (epoch 38.077), train_loss = 0.80694325, grad/param norm = 2.8879e-01, time/batch = 15.2737s	
25322/33250 (epoch 38.078), train_loss = 0.79641197, grad/param norm = 1.6943e-01, time/batch = 15.1005s	
25323/33250 (epoch 38.080), train_loss = 0.79066250, grad/param norm = 2.0644e-01, time/batch = 14.7081s	
25324/33250 (epoch 38.081), train_loss = 0.82703061, grad/param norm = 1.7429e-01, time/batch = 14.9373s	
25325/33250 (epoch 38.083), train_loss = 0.91939490, grad/param norm = 1.9023e-01, time/batch = 17.8027s	
25326/33250 (epoch 38.084), train_loss = 0.85062242, grad/param norm = 1.9656e-01, time/batch = 16.3032s	
25327/33250 (epoch 38.086), train_loss = 0.79824069, grad/param norm = 1.5447e-01, time/batch = 15.7902s	
25328/33250 (epoch 38.087), train_loss = 0.69578261, grad/param norm = 1.6534e-01, time/batch = 14.6890s	
25329/33250 (epoch 38.089), train_loss = 0.78177333, grad/param norm = 1.8090e-01, time/batch = 14.2918s	
25330/33250 (epoch 38.090), train_loss = 0.81825233, grad/param norm = 1.7821e-01, time/batch = 14.2135s	
25331/33250 (epoch 38.092), train_loss = 0.75007447, grad/param norm = 1.5457e-01, time/batch = 15.0280s	
25332/33250 (epoch 38.093), train_loss = 0.78639191, grad/param norm = 1.7040e-01, time/batch = 14.7843s	
25333/33250 (epoch 38.095), train_loss = 0.79843880, grad/param norm = 1.7032e-01, time/batch = 14.5409s	
25334/33250 (epoch 38.096), train_loss = 0.68717380, grad/param norm = 1.8693e-01, time/batch = 14.5342s	
25335/33250 (epoch 38.098), train_loss = 0.67738951, grad/param norm = 1.8482e-01, time/batch = 14.8560s	
25336/33250 (epoch 38.099), train_loss = 0.63344901, grad/param norm = 1.5806e-01, time/batch = 16.2027s	
25337/33250 (epoch 38.101), train_loss = 0.77445738, grad/param norm = 1.9382e-01, time/batch = 16.6437s	
25338/33250 (epoch 38.102), train_loss = 0.73696771, grad/param norm = 1.6241e-01, time/batch = 17.0367s	
25339/33250 (epoch 38.104), train_loss = 0.58930388, grad/param norm = 1.4097e-01, time/batch = 15.7800s	
25340/33250 (epoch 38.105), train_loss = 0.73357907, grad/param norm = 1.7915e-01, time/batch = 15.0556s	
25341/33250 (epoch 38.107), train_loss = 0.67297178, grad/param norm = 1.3955e-01, time/batch = 14.8783s	
25342/33250 (epoch 38.108), train_loss = 0.78931502, grad/param norm = 1.9097e-01, time/batch = 14.9535s	
25343/33250 (epoch 38.110), train_loss = 0.67364593, grad/param norm = 1.6078e-01, time/batch = 15.0229s	
25344/33250 (epoch 38.111), train_loss = 0.76563509, grad/param norm = 1.5123e-01, time/batch = 14.9340s	
25345/33250 (epoch 38.113), train_loss = 0.71826298, grad/param norm = 1.7151e-01, time/batch = 14.7109s	
25346/33250 (epoch 38.114), train_loss = 0.67375482, grad/param norm = 1.7972e-01, time/batch = 14.8578s	
25347/33250 (epoch 38.116), train_loss = 0.71025126, grad/param norm = 1.7079e-01, time/batch = 15.4656s	
25348/33250 (epoch 38.117), train_loss = 0.70569558, grad/param norm = 1.6193e-01, time/batch = 17.7988s	
25349/33250 (epoch 38.119), train_loss = 0.74380213, grad/param norm = 1.8160e-01, time/batch = 16.3816s	
25350/33250 (epoch 38.120), train_loss = 0.63050155, grad/param norm = 1.3922e-01, time/batch = 16.8007s	
25351/33250 (epoch 38.122), train_loss = 0.84247593, grad/param norm = 1.7116e-01, time/batch = 14.7958s	
25352/33250 (epoch 38.123), train_loss = 0.74492067, grad/param norm = 1.7674e-01, time/batch = 14.9544s	
25353/33250 (epoch 38.125), train_loss = 0.62742730, grad/param norm = 1.7240e-01, time/batch = 14.7863s	
25354/33250 (epoch 38.126), train_loss = 0.74880781, grad/param norm = 1.9865e-01, time/batch = 14.8642s	
25355/33250 (epoch 38.128), train_loss = 0.72017702, grad/param norm = 1.5206e-01, time/batch = 14.4442s	
25356/33250 (epoch 38.129), train_loss = 0.76648972, grad/param norm = 1.6683e-01, time/batch = 14.4753s	
25357/33250 (epoch 38.131), train_loss = 0.76545103, grad/param norm = 1.7823e-01, time/batch = 15.2149s	
25358/33250 (epoch 38.132), train_loss = 0.73763312, grad/param norm = 1.7400e-01, time/batch = 16.1080s	
25359/33250 (epoch 38.134), train_loss = 0.70320166, grad/param norm = 1.6660e-01, time/batch = 14.8894s	
25360/33250 (epoch 38.135), train_loss = 0.79102027, grad/param norm = 1.6576e-01, time/batch = 14.4873s	
25361/33250 (epoch 38.137), train_loss = 0.69797575, grad/param norm = 1.8787e-01, time/batch = 16.4028s	
25362/33250 (epoch 38.138), train_loss = 0.68427898, grad/param norm = 1.4925e-01, time/batch = 14.5293s	
25363/33250 (epoch 38.140), train_loss = 0.61150399, grad/param norm = 1.4770e-01, time/batch = 15.4460s	
25364/33250 (epoch 38.141), train_loss = 0.85418975, grad/param norm = 2.1552e-01, time/batch = 14.3739s	
25365/33250 (epoch 38.143), train_loss = 0.64386977, grad/param norm = 1.8656e-01, time/batch = 14.6362s	
25366/33250 (epoch 38.144), train_loss = 0.72406673, grad/param norm = 1.6947e-01, time/batch = 14.7533s	
25367/33250 (epoch 38.146), train_loss = 0.71865103, grad/param norm = 1.5226e-01, time/batch = 14.5377s	
25368/33250 (epoch 38.147), train_loss = 0.76166465, grad/param norm = 1.7407e-01, time/batch = 14.6386s	
25369/33250 (epoch 38.149), train_loss = 0.70787716, grad/param norm = 1.5150e-01, time/batch = 14.9470s	
25370/33250 (epoch 38.150), train_loss = 0.68760393, grad/param norm = 1.6355e-01, time/batch = 15.3459s	
25371/33250 (epoch 38.152), train_loss = 0.66101320, grad/param norm = 1.6156e-01, time/batch = 16.2991s	
25372/33250 (epoch 38.153), train_loss = 0.90518757, grad/param norm = 1.8159e-01, time/batch = 15.8956s	
25373/33250 (epoch 38.155), train_loss = 0.73273372, grad/param norm = 1.9659e-01, time/batch = 14.6406s	
25374/33250 (epoch 38.156), train_loss = 0.95346972, grad/param norm = 1.7133e-01, time/batch = 14.9404s	
25375/33250 (epoch 38.158), train_loss = 0.89225882, grad/param norm = 2.0995e-01, time/batch = 14.7181s	
25376/33250 (epoch 38.159), train_loss = 0.73464289, grad/param norm = 1.6689e-01, time/batch = 14.7866s	
25377/33250 (epoch 38.161), train_loss = 0.79661312, grad/param norm = 1.9286e-01, time/batch = 15.4589s	
25378/33250 (epoch 38.162), train_loss = 0.69494385, grad/param norm = 1.5077e-01, time/batch = 14.8538s	
25379/33250 (epoch 38.164), train_loss = 0.76411242, grad/param norm = 2.0098e-01, time/batch = 14.7961s	
25380/33250 (epoch 38.165), train_loss = 0.85325070, grad/param norm = 1.9169e-01, time/batch = 16.2653s	
25381/33250 (epoch 38.167), train_loss = 0.91443680, grad/param norm = 2.0481e-01, time/batch = 14.7439s	
25382/33250 (epoch 38.168), train_loss = 0.68415664, grad/param norm = 1.4380e-01, time/batch = 15.0412s	
25383/33250 (epoch 38.170), train_loss = 0.74638215, grad/param norm = 2.2606e-01, time/batch = 14.9738s	
25384/33250 (epoch 38.171), train_loss = 0.77619905, grad/param norm = 1.5405e-01, time/batch = 14.7029s	
25385/33250 (epoch 38.173), train_loss = 0.75876848, grad/param norm = 1.9401e-01, time/batch = 14.6318s	
25386/33250 (epoch 38.174), train_loss = 0.77955825, grad/param norm = 1.4386e-01, time/batch = 14.9205s	
25387/33250 (epoch 38.176), train_loss = 0.71636515, grad/param norm = 1.5975e-01, time/batch = 14.7191s	
25388/33250 (epoch 38.177), train_loss = 0.70180973, grad/param norm = 1.5212e-01, time/batch = 14.6363s	
25389/33250 (epoch 38.179), train_loss = 0.69894194, grad/param norm = 1.5642e-01, time/batch = 14.6654s	
25390/33250 (epoch 38.180), train_loss = 0.62181633, grad/param norm = 1.5719e-01, time/batch = 14.9610s	
25391/33250 (epoch 38.182), train_loss = 0.69594890, grad/param norm = 1.8119e-01, time/batch = 16.2164s	
25392/33250 (epoch 38.183), train_loss = 0.86892312, grad/param norm = 2.3375e-01, time/batch = 16.5546s	
25393/33250 (epoch 38.185), train_loss = 0.78923345, grad/param norm = 2.0957e-01, time/batch = 16.7135s	
25394/33250 (epoch 38.186), train_loss = 0.81038544, grad/param norm = 2.0745e-01, time/batch = 15.4526s	
25395/33250 (epoch 38.188), train_loss = 0.85804272, grad/param norm = 2.1087e-01, time/batch = 16.1151s	
25396/33250 (epoch 38.189), train_loss = 0.62355116, grad/param norm = 1.7915e-01, time/batch = 14.7812s	
25397/33250 (epoch 38.191), train_loss = 0.73227407, grad/param norm = 1.9157e-01, time/batch = 14.7705s	
25398/33250 (epoch 38.192), train_loss = 0.75587746, grad/param norm = 1.7753e-01, time/batch = 14.6940s	
25399/33250 (epoch 38.194), train_loss = 0.74579405, grad/param norm = 2.0484e-01, time/batch = 14.5491s	
25400/33250 (epoch 38.195), train_loss = 0.93691272, grad/param norm = 1.8931e-01, time/batch = 14.4674s	
25401/33250 (epoch 38.197), train_loss = 0.72934664, grad/param norm = 1.6317e-01, time/batch = 15.4626s	
25402/33250 (epoch 38.198), train_loss = 0.92363085, grad/param norm = 1.8491e-01, time/batch = 16.3888s	
25403/33250 (epoch 38.200), train_loss = 0.77696720, grad/param norm = 1.7974e-01, time/batch = 16.1843s	
25404/33250 (epoch 38.202), train_loss = 0.74542181, grad/param norm = 1.7572e-01, time/batch = 15.3847s	
25405/33250 (epoch 38.203), train_loss = 0.69481509, grad/param norm = 1.8154e-01, time/batch = 15.0225s	
25406/33250 (epoch 38.205), train_loss = 0.78968481, grad/param norm = 1.6518e-01, time/batch = 15.4051s	
25407/33250 (epoch 38.206), train_loss = 0.83178911, grad/param norm = 1.7320e-01, time/batch = 14.7887s	
25408/33250 (epoch 38.208), train_loss = 0.89044457, grad/param norm = 2.1625e-01, time/batch = 14.9706s	
25409/33250 (epoch 38.209), train_loss = 0.74417514, grad/param norm = 1.6986e-01, time/batch = 14.7945s	
25410/33250 (epoch 38.211), train_loss = 0.81772399, grad/param norm = 1.7870e-01, time/batch = 14.7950s	
25411/33250 (epoch 38.212), train_loss = 0.90423986, grad/param norm = 1.7401e-01, time/batch = 15.0255s	
25412/33250 (epoch 38.214), train_loss = 0.80853152, grad/param norm = 1.6301e-01, time/batch = 17.8539s	
25413/33250 (epoch 38.215), train_loss = 0.82696896, grad/param norm = 2.2286e-01, time/batch = 15.5456s	
25414/33250 (epoch 38.217), train_loss = 0.87064145, grad/param norm = 2.1355e-01, time/batch = 15.6484s	
25415/33250 (epoch 38.218), train_loss = 0.82636200, grad/param norm = 1.7122e-01, time/batch = 16.1462s	
25416/33250 (epoch 38.220), train_loss = 0.78866311, grad/param norm = 1.6572e-01, time/batch = 14.6380s	
25417/33250 (epoch 38.221), train_loss = 0.90428936, grad/param norm = 2.1153e-01, time/batch = 15.1067s	
25418/33250 (epoch 38.223), train_loss = 0.78798932, grad/param norm = 1.6936e-01, time/batch = 14.9482s	
25419/33250 (epoch 38.224), train_loss = 0.83788005, grad/param norm = 1.8693e-01, time/batch = 14.9473s	
25420/33250 (epoch 38.226), train_loss = 0.89951106, grad/param norm = 1.7335e-01, time/batch = 14.7086s	
25421/33250 (epoch 38.227), train_loss = 0.80469416, grad/param norm = 1.7924e-01, time/batch = 15.1103s	
25422/33250 (epoch 38.229), train_loss = 0.79327275, grad/param norm = 1.5787e-01, time/batch = 14.8761s	
25423/33250 (epoch 38.230), train_loss = 0.80053401, grad/param norm = 1.9521e-01, time/batch = 14.9752s	
25424/33250 (epoch 38.232), train_loss = 0.72884961, grad/param norm = 1.4403e-01, time/batch = 15.3020s	
25425/33250 (epoch 38.233), train_loss = 0.71220059, grad/param norm = 1.5914e-01, time/batch = 15.1313s	
25426/33250 (epoch 38.235), train_loss = 0.89941959, grad/param norm = 1.7424e-01, time/batch = 17.9432s	
25427/33250 (epoch 38.236), train_loss = 0.72831424, grad/param norm = 1.6244e-01, time/batch = 15.0951s	
25428/33250 (epoch 38.238), train_loss = 0.87554005, grad/param norm = 1.9849e-01, time/batch = 14.8826s	
25429/33250 (epoch 38.239), train_loss = 0.87799803, grad/param norm = 2.3693e-01, time/batch = 15.0349s	
25430/33250 (epoch 38.241), train_loss = 0.89431382, grad/param norm = 2.3055e-01, time/batch = 14.7175s	
25431/33250 (epoch 38.242), train_loss = 0.89687209, grad/param norm = 2.2168e-01, time/batch = 15.2070s	
25432/33250 (epoch 38.244), train_loss = 0.82058769, grad/param norm = 1.9454e-01, time/batch = 14.9577s	
25433/33250 (epoch 38.245), train_loss = 0.83738657, grad/param norm = 2.1004e-01, time/batch = 15.7545s	
25434/33250 (epoch 38.247), train_loss = 0.77568050, grad/param norm = 1.7670e-01, time/batch = 17.1217s	
25435/33250 (epoch 38.248), train_loss = 0.90823495, grad/param norm = 2.0158e-01, time/batch = 17.1289s	
25436/33250 (epoch 38.250), train_loss = 0.89786254, grad/param norm = 1.6150e-01, time/batch = 20.3818s	
25437/33250 (epoch 38.251), train_loss = 0.77570310, grad/param norm = 1.6970e-01, time/batch = 24.1878s	
25438/33250 (epoch 38.253), train_loss = 0.76550370, grad/param norm = 1.5481e-01, time/batch = 15.5353s	
25439/33250 (epoch 38.254), train_loss = 0.73458633, grad/param norm = 1.7594e-01, time/batch = 15.0221s	
25440/33250 (epoch 38.256), train_loss = 0.79604888, grad/param norm = 1.6027e-01, time/batch = 14.7895s	
25441/33250 (epoch 38.257), train_loss = 0.94179436, grad/param norm = 1.9184e-01, time/batch = 14.9697s	
25442/33250 (epoch 38.259), train_loss = 0.81453952, grad/param norm = 1.8400e-01, time/batch = 15.1126s	
25443/33250 (epoch 38.260), train_loss = 0.64982794, grad/param norm = 1.6363e-01, time/batch = 15.2620s	
25444/33250 (epoch 38.262), train_loss = 0.80437131, grad/param norm = 1.7507e-01, time/batch = 16.8053s	
25445/33250 (epoch 38.263), train_loss = 0.66872936, grad/param norm = 1.8046e-01, time/batch = 15.8772s	
25446/33250 (epoch 38.265), train_loss = 0.83365052, grad/param norm = 1.8827e-01, time/batch = 15.6172s	
25447/33250 (epoch 38.266), train_loss = 0.75900078, grad/param norm = 1.8380e-01, time/batch = 15.4389s	
25448/33250 (epoch 38.268), train_loss = 0.69211525, grad/param norm = 1.6588e-01, time/batch = 16.1063s	
25449/33250 (epoch 38.269), train_loss = 0.64115428, grad/param norm = 1.5446e-01, time/batch = 14.6222s	
25450/33250 (epoch 38.271), train_loss = 0.81797702, grad/param norm = 1.6199e-01, time/batch = 14.5556s	
25451/33250 (epoch 38.272), train_loss = 0.72283528, grad/param norm = 1.5335e-01, time/batch = 15.1027s	
25452/33250 (epoch 38.274), train_loss = 0.58927702, grad/param norm = 1.5568e-01, time/batch = 15.1052s	
25453/33250 (epoch 38.275), train_loss = 0.74914566, grad/param norm = 1.5811e-01, time/batch = 14.7719s	
25454/33250 (epoch 38.277), train_loss = 0.63090970, grad/param norm = 1.8078e-01, time/batch = 14.5647s	
25455/33250 (epoch 38.278), train_loss = 0.72340321, grad/param norm = 1.5545e-01, time/batch = 15.3567s	
25456/33250 (epoch 38.280), train_loss = 0.69605871, grad/param norm = 1.5512e-01, time/batch = 15.9739s	
25457/33250 (epoch 38.281), train_loss = 0.78585185, grad/param norm = 1.7545e-01, time/batch = 16.3766s	
25458/33250 (epoch 38.283), train_loss = 0.81890782, grad/param norm = 2.4371e-01, time/batch = 16.2206s	
25459/33250 (epoch 38.284), train_loss = 0.68787230, grad/param norm = 2.2165e-01, time/batch = 14.9541s	
25460/33250 (epoch 38.286), train_loss = 0.81775109, grad/param norm = 1.8688e-01, time/batch = 14.8843s	
25461/33250 (epoch 38.287), train_loss = 0.64418522, grad/param norm = 1.4758e-01, time/batch = 15.2853s	
25462/33250 (epoch 38.289), train_loss = 0.61298371, grad/param norm = 1.5626e-01, time/batch = 15.0226s	
25463/33250 (epoch 38.290), train_loss = 0.78255669, grad/param norm = 1.9715e-01, time/batch = 14.9190s	
25464/33250 (epoch 38.292), train_loss = 0.82480804, grad/param norm = 2.0978e-01, time/batch = 14.7161s	
25465/33250 (epoch 38.293), train_loss = 0.89043593, grad/param norm = 1.9093e-01, time/batch = 14.9606s	
25466/33250 (epoch 38.295), train_loss = 0.87221191, grad/param norm = 1.7936e-01, time/batch = 16.5528s	
25467/33250 (epoch 38.296), train_loss = 0.77877703, grad/param norm = 1.7245e-01, time/batch = 15.4857s	
25468/33250 (epoch 38.298), train_loss = 0.64790807, grad/param norm = 1.6863e-01, time/batch = 15.2318s	
25469/33250 (epoch 38.299), train_loss = 0.62182394, grad/param norm = 1.5129e-01, time/batch = 17.0447s	
25470/33250 (epoch 38.301), train_loss = 0.86861165, grad/param norm = 1.8250e-01, time/batch = 15.0221s	
25471/33250 (epoch 38.302), train_loss = 0.85544722, grad/param norm = 2.3986e-01, time/batch = 14.7826s	
25472/33250 (epoch 38.304), train_loss = 0.74845576, grad/param norm = 1.9320e-01, time/batch = 14.6910s	
25473/33250 (epoch 38.305), train_loss = 0.71381916, grad/param norm = 1.6865e-01, time/batch = 16.6944s	
25474/33250 (epoch 38.307), train_loss = 0.82060709, grad/param norm = 1.9261e-01, time/batch = 15.3533s	
25475/33250 (epoch 38.308), train_loss = 0.87530691, grad/param norm = 2.3449e-01, time/batch = 15.1128s	
25476/33250 (epoch 38.310), train_loss = 0.74325517, grad/param norm = 1.8857e-01, time/batch = 14.6075s	
25477/33250 (epoch 38.311), train_loss = 0.92383776, grad/param norm = 2.0753e-01, time/batch = 16.4592s	
25478/33250 (epoch 38.313), train_loss = 0.61928344, grad/param norm = 1.8711e-01, time/batch = 16.5534s	
25479/33250 (epoch 38.314), train_loss = 0.86212369, grad/param norm = 1.6993e-01, time/batch = 16.3673s	
25480/33250 (epoch 38.316), train_loss = 0.94683634, grad/param norm = 2.3819e-01, time/batch = 15.5877s	
25481/33250 (epoch 38.317), train_loss = 0.68892685, grad/param norm = 1.6981e-01, time/batch = 15.0407s	
25482/33250 (epoch 38.319), train_loss = 0.85447491, grad/param norm = 2.3116e-01, time/batch = 15.1882s	
25483/33250 (epoch 38.320), train_loss = 0.84896848, grad/param norm = 2.4333e-01, time/batch = 15.6102s	
25484/33250 (epoch 38.322), train_loss = 0.94319020, grad/param norm = 2.3461e-01, time/batch = 15.4587s	
25485/33250 (epoch 38.323), train_loss = 0.92637975, grad/param norm = 2.5689e-01, time/batch = 14.5558s	
25486/33250 (epoch 38.325), train_loss = 0.74884580, grad/param norm = 2.1109e-01, time/batch = 14.7034s	
25487/33250 (epoch 38.326), train_loss = 0.98322889, grad/param norm = 2.0151e-01, time/batch = 14.7137s	
25488/33250 (epoch 38.328), train_loss = 0.77420327, grad/param norm = 1.7958e-01, time/batch = 16.8853s	
25489/33250 (epoch 38.329), train_loss = 0.80950775, grad/param norm = 2.3411e-01, time/batch = 15.9462s	
25490/33250 (epoch 38.331), train_loss = 0.80655988, grad/param norm = 2.0985e-01, time/batch = 15.8889s	
25491/33250 (epoch 38.332), train_loss = 0.78862626, grad/param norm = 1.7065e-01, time/batch = 15.4710s	
25492/33250 (epoch 38.334), train_loss = 0.91782735, grad/param norm = 1.7335e-01, time/batch = 14.5544s	
25493/33250 (epoch 38.335), train_loss = 0.60362681, grad/param norm = 1.6137e-01, time/batch = 15.1830s	
25494/33250 (epoch 38.337), train_loss = 0.86006023, grad/param norm = 1.7449e-01, time/batch = 14.8593s	
25495/33250 (epoch 38.338), train_loss = 0.94890912, grad/param norm = 1.8422e-01, time/batch = 14.7097s	
25496/33250 (epoch 38.340), train_loss = 0.75963453, grad/param norm = 1.7222e-01, time/batch = 14.6364s	
25497/33250 (epoch 38.341), train_loss = 0.72154661, grad/param norm = 1.7236e-01, time/batch = 16.3564s	
25498/33250 (epoch 38.343), train_loss = 0.75938689, grad/param norm = 1.8558e-01, time/batch = 15.0287s	
25499/33250 (epoch 38.344), train_loss = 0.78584887, grad/param norm = 1.7968e-01, time/batch = 17.5202s	
25500/33250 (epoch 38.346), train_loss = 0.68239536, grad/param norm = 1.6548e-01, time/batch = 16.3067s	
25501/33250 (epoch 38.347), train_loss = 0.96916241, grad/param norm = 2.7939e-01, time/batch = 15.4978s	
25502/33250 (epoch 38.349), train_loss = 0.77410437, grad/param norm = 1.9518e-01, time/batch = 14.9788s	
25503/33250 (epoch 38.350), train_loss = 0.76533922, grad/param norm = 1.6559e-01, time/batch = 14.3896s	
25504/33250 (epoch 38.352), train_loss = 0.70866825, grad/param norm = 1.6568e-01, time/batch = 14.8124s	
25505/33250 (epoch 38.353), train_loss = 0.74484771, grad/param norm = 1.5259e-01, time/batch = 15.1179s	
25506/33250 (epoch 38.355), train_loss = 0.73498903, grad/param norm = 1.7984e-01, time/batch = 14.5469s	
25507/33250 (epoch 38.356), train_loss = 0.70107282, grad/param norm = 1.9188e-01, time/batch = 14.2994s	
25508/33250 (epoch 38.358), train_loss = 0.75903425, grad/param norm = 1.5870e-01, time/batch = 15.2046s	
25509/33250 (epoch 38.359), train_loss = 0.76219813, grad/param norm = 1.8126e-01, time/batch = 15.6079s	
25510/33250 (epoch 38.361), train_loss = 0.87895104, grad/param norm = 1.9603e-01, time/batch = 16.3892s	
25511/33250 (epoch 38.362), train_loss = 0.80955298, grad/param norm = 1.6159e-01, time/batch = 18.7002s	
25512/33250 (epoch 38.364), train_loss = 0.84246794, grad/param norm = 1.9425e-01, time/batch = 16.6358s	
25513/33250 (epoch 38.365), train_loss = 0.78366700, grad/param norm = 1.4982e-01, time/batch = 15.4303s	
25514/33250 (epoch 38.367), train_loss = 0.79177231, grad/param norm = 1.5609e-01, time/batch = 14.6325s	
25515/33250 (epoch 38.368), train_loss = 0.78950660, grad/param norm = 1.9514e-01, time/batch = 15.1189s	
25516/33250 (epoch 38.370), train_loss = 0.71445717, grad/param norm = 1.5669e-01, time/batch = 15.1817s	
25517/33250 (epoch 38.371), train_loss = 0.88029129, grad/param norm = 1.8371e-01, time/batch = 15.4546s	
25518/33250 (epoch 38.373), train_loss = 0.76470245, grad/param norm = 1.5639e-01, time/batch = 14.9435s	
25519/33250 (epoch 38.374), train_loss = 0.79361827, grad/param norm = 2.3152e-01, time/batch = 15.7944s	
25520/33250 (epoch 38.376), train_loss = 0.78900507, grad/param norm = 1.7457e-01, time/batch = 15.7881s	
25521/33250 (epoch 38.377), train_loss = 0.69845000, grad/param norm = 2.2216e-01, time/batch = 16.1873s	
25522/33250 (epoch 38.379), train_loss = 0.78969618, grad/param norm = 1.7139e-01, time/batch = 16.9639s	
25523/33250 (epoch 38.380), train_loss = 0.79860484, grad/param norm = 2.3559e-01, time/batch = 16.4500s	
25524/33250 (epoch 38.382), train_loss = 0.82203433, grad/param norm = 2.3840e-01, time/batch = 14.8765s	
25525/33250 (epoch 38.383), train_loss = 0.69926958, grad/param norm = 2.3628e-01, time/batch = 15.0374s	
25526/33250 (epoch 38.385), train_loss = 0.66371859, grad/param norm = 1.7298e-01, time/batch = 14.8807s	
25527/33250 (epoch 38.386), train_loss = 0.70050741, grad/param norm = 2.1676e-01, time/batch = 15.1344s	
25528/33250 (epoch 38.388), train_loss = 0.71725113, grad/param norm = 1.8741e-01, time/batch = 15.3568s	
25529/33250 (epoch 38.389), train_loss = 0.74271105, grad/param norm = 2.0231e-01, time/batch = 14.5545s	
25530/33250 (epoch 38.391), train_loss = 0.82469410, grad/param norm = 1.7529e-01, time/batch = 14.5552s	
25531/33250 (epoch 38.392), train_loss = 0.88956260, grad/param norm = 2.1193e-01, time/batch = 17.2281s	
25532/33250 (epoch 38.394), train_loss = 0.87921679, grad/param norm = 2.0313e-01, time/batch = 15.2025s	
25533/33250 (epoch 38.395), train_loss = 0.88567066, grad/param norm = 1.9549e-01, time/batch = 14.8872s	
25534/33250 (epoch 38.397), train_loss = 0.89363276, grad/param norm = 1.9238e-01, time/batch = 14.8158s	
25535/33250 (epoch 38.398), train_loss = 0.70337717, grad/param norm = 1.6089e-01, time/batch = 15.0166s	
25536/33250 (epoch 38.400), train_loss = 0.69029323, grad/param norm = 1.5452e-01, time/batch = 14.8777s	
25537/33250 (epoch 38.402), train_loss = 0.66477562, grad/param norm = 1.7840e-01, time/batch = 14.7752s	
25538/33250 (epoch 38.403), train_loss = 0.76902827, grad/param norm = 2.1113e-01, time/batch = 14.6374s	
25539/33250 (epoch 38.405), train_loss = 0.72718238, grad/param norm = 1.5803e-01, time/batch = 15.5335s	
25540/33250 (epoch 38.406), train_loss = 0.77453048, grad/param norm = 1.8654e-01, time/batch = 14.9425s	
25541/33250 (epoch 38.408), train_loss = 0.93009920, grad/param norm = 1.9001e-01, time/batch = 14.7931s	
25542/33250 (epoch 38.409), train_loss = 0.83294625, grad/param norm = 2.1891e-01, time/batch = 14.8204s	
25543/33250 (epoch 38.411), train_loss = 0.57209778, grad/param norm = 1.3140e-01, time/batch = 18.7828s	
25544/33250 (epoch 38.412), train_loss = 0.65519065, grad/param norm = 1.5760e-01, time/batch = 15.4363s	
25545/33250 (epoch 38.414), train_loss = 0.80801819, grad/param norm = 1.7215e-01, time/batch = 16.9655s	
25546/33250 (epoch 38.415), train_loss = 0.83730206, grad/param norm = 1.9289e-01, time/batch = 14.5639s	
25547/33250 (epoch 38.417), train_loss = 0.88683840, grad/param norm = 1.8274e-01, time/batch = 14.6319s	
25548/33250 (epoch 38.418), train_loss = 1.02438880, grad/param norm = 2.1073e-01, time/batch = 15.2851s	
25549/33250 (epoch 38.420), train_loss = 0.84762554, grad/param norm = 1.7214e-01, time/batch = 14.8845s	
25550/33250 (epoch 38.421), train_loss = 0.74947322, grad/param norm = 1.5771e-01, time/batch = 14.8781s	
25551/33250 (epoch 38.423), train_loss = 0.83247403, grad/param norm = 2.1823e-01, time/batch = 15.1969s	
25552/33250 (epoch 38.424), train_loss = 0.91776493, grad/param norm = 3.1319e-01, time/batch = 14.9353s	
25553/33250 (epoch 38.426), train_loss = 0.76533148, grad/param norm = 1.4778e-01, time/batch = 18.2865s	
25554/33250 (epoch 38.427), train_loss = 0.72710581, grad/param norm = 1.7744e-01, time/batch = 15.3529s	
25555/33250 (epoch 38.429), train_loss = 0.81193333, grad/param norm = 2.2380e-01, time/batch = 15.2799s	
25556/33250 (epoch 38.430), train_loss = 0.73405967, grad/param norm = 2.1655e-01, time/batch = 15.8120s	
25557/33250 (epoch 38.432), train_loss = 0.87324827, grad/param norm = 1.8753e-01, time/batch = 15.0441s	
25558/33250 (epoch 38.433), train_loss = 0.74617460, grad/param norm = 2.6054e-01, time/batch = 14.4753s	
25559/33250 (epoch 38.435), train_loss = 0.86784795, grad/param norm = 2.0153e-01, time/batch = 15.1060s	
25560/33250 (epoch 38.436), train_loss = 0.74480512, grad/param norm = 1.9140e-01, time/batch = 15.0411s	
25561/33250 (epoch 38.438), train_loss = 0.89280225, grad/param norm = 1.8433e-01, time/batch = 14.7167s	
25562/33250 (epoch 38.439), train_loss = 0.79819172, grad/param norm = 1.5883e-01, time/batch = 14.9537s	
25563/33250 (epoch 38.441), train_loss = 0.76685874, grad/param norm = 1.6823e-01, time/batch = 14.7834s	
25564/33250 (epoch 38.442), train_loss = 0.71741748, grad/param norm = 1.7822e-01, time/batch = 15.1286s	
25565/33250 (epoch 38.444), train_loss = 0.74504544, grad/param norm = 1.5905e-01, time/batch = 15.0443s	
25566/33250 (epoch 38.445), train_loss = 0.81314088, grad/param norm = 1.5746e-01, time/batch = 14.6555s	
25567/33250 (epoch 38.447), train_loss = 0.73250111, grad/param norm = 1.7242e-01, time/batch = 15.7035s	
25568/33250 (epoch 38.448), train_loss = 0.82116669, grad/param norm = 1.6589e-01, time/batch = 14.7794s	
25569/33250 (epoch 38.450), train_loss = 0.90631017, grad/param norm = 1.9578e-01, time/batch = 14.4682s	
25570/33250 (epoch 38.451), train_loss = 0.85328438, grad/param norm = 2.0742e-01, time/batch = 14.8026s	
25571/33250 (epoch 38.453), train_loss = 0.68865877, grad/param norm = 1.4310e-01, time/batch = 15.4056s	
25572/33250 (epoch 38.454), train_loss = 0.91417331, grad/param norm = 1.8954e-01, time/batch = 14.3905s	
25573/33250 (epoch 38.456), train_loss = 0.88964940, grad/param norm = 1.5075e-01, time/batch = 15.1739s	
25574/33250 (epoch 38.457), train_loss = 0.73096719, grad/param norm = 1.6661e-01, time/batch = 14.7789s	
25575/33250 (epoch 38.459), train_loss = 0.84524831, grad/param norm = 1.7313e-01, time/batch = 14.7865s	
25576/33250 (epoch 38.460), train_loss = 0.84925218, grad/param norm = 1.8156e-01, time/batch = 16.1332s	
25577/33250 (epoch 38.462), train_loss = 0.77508880, grad/param norm = 1.7870e-01, time/batch = 14.9862s	
25578/33250 (epoch 38.463), train_loss = 0.70477138, grad/param norm = 1.3678e-01, time/batch = 14.9564s	
25579/33250 (epoch 38.465), train_loss = 0.65833879, grad/param norm = 1.4139e-01, time/batch = 14.6296s	
25580/33250 (epoch 38.466), train_loss = 0.64107890, grad/param norm = 1.3725e-01, time/batch = 14.4620s	
25581/33250 (epoch 38.468), train_loss = 0.67461274, grad/param norm = 1.4142e-01, time/batch = 14.7162s	
25582/33250 (epoch 38.469), train_loss = 0.76699378, grad/param norm = 1.6365e-01, time/batch = 14.7988s	
25583/33250 (epoch 38.471), train_loss = 0.85193799, grad/param norm = 1.6314e-01, time/batch = 15.3489s	
25584/33250 (epoch 38.472), train_loss = 0.75715128, grad/param norm = 2.0695e-01, time/batch = 14.7922s	
25585/33250 (epoch 38.474), train_loss = 0.86560129, grad/param norm = 1.7962e-01, time/batch = 14.6262s	
25586/33250 (epoch 38.475), train_loss = 0.80042835, grad/param norm = 1.7210e-01, time/batch = 14.7958s	
25587/33250 (epoch 38.477), train_loss = 0.81369735, grad/param norm = 1.6391e-01, time/batch = 15.0905s	
25588/33250 (epoch 38.478), train_loss = 0.70356747, grad/param norm = 1.9564e-01, time/batch = 14.9116s	
25589/33250 (epoch 38.480), train_loss = 0.88441402, grad/param norm = 1.7141e-01, time/batch = 14.3303s	
25590/33250 (epoch 38.481), train_loss = 0.76011095, grad/param norm = 1.7043e-01, time/batch = 14.9823s	
25591/33250 (epoch 38.483), train_loss = 0.76841264, grad/param norm = 1.7114e-01, time/batch = 14.7880s	
25592/33250 (epoch 38.484), train_loss = 0.71808180, grad/param norm = 1.5989e-01, time/batch = 15.2753s	
25593/33250 (epoch 38.486), train_loss = 0.65003696, grad/param norm = 1.6723e-01, time/batch = 14.7986s	
25594/33250 (epoch 38.487), train_loss = 0.72938151, grad/param norm = 1.8965e-01, time/batch = 14.5561s	
25595/33250 (epoch 38.489), train_loss = 0.85361179, grad/param norm = 1.8657e-01, time/batch = 15.4426s	
25596/33250 (epoch 38.490), train_loss = 0.80916136, grad/param norm = 1.8854e-01, time/batch = 16.1993s	
25597/33250 (epoch 38.492), train_loss = 0.86838883, grad/param norm = 1.9434e-01, time/batch = 15.3738s	
25598/33250 (epoch 38.493), train_loss = 0.78508112, grad/param norm = 1.7282e-01, time/batch = 14.6511s	
25599/33250 (epoch 38.495), train_loss = 0.83651148, grad/param norm = 1.5301e-01, time/batch = 15.7099s	
25600/33250 (epoch 38.496), train_loss = 0.80598598, grad/param norm = 1.4994e-01, time/batch = 19.1865s	
25601/33250 (epoch 38.498), train_loss = 0.85524157, grad/param norm = 1.7068e-01, time/batch = 16.4427s	
25602/33250 (epoch 38.499), train_loss = 0.74217986, grad/param norm = 1.7888e-01, time/batch = 15.6211s	
25603/33250 (epoch 38.501), train_loss = 0.75272596, grad/param norm = 1.9685e-01, time/batch = 15.3553s	
25604/33250 (epoch 38.502), train_loss = 0.73790921, grad/param norm = 1.5682e-01, time/batch = 14.7922s	
25605/33250 (epoch 38.504), train_loss = 0.92221529, grad/param norm = 2.1995e-01, time/batch = 15.0252s	
25606/33250 (epoch 38.505), train_loss = 0.67558267, grad/param norm = 1.3784e-01, time/batch = 15.5416s	
25607/33250 (epoch 38.507), train_loss = 0.70831746, grad/param norm = 1.7047e-01, time/batch = 14.8759s	
25608/33250 (epoch 38.508), train_loss = 0.74643002, grad/param norm = 1.8592e-01, time/batch = 15.2854s	
25609/33250 (epoch 38.510), train_loss = 0.64901733, grad/param norm = 1.3224e-01, time/batch = 15.8814s	
25610/33250 (epoch 38.511), train_loss = 0.76847079, grad/param norm = 1.8552e-01, time/batch = 17.3488s	
25611/33250 (epoch 38.513), train_loss = 0.89742532, grad/param norm = 1.8754e-01, time/batch = 18.1108s	
25612/33250 (epoch 38.514), train_loss = 0.75436294, grad/param norm = 1.8113e-01, time/batch = 16.7163s	
25613/33250 (epoch 38.516), train_loss = 0.72347594, grad/param norm = 1.8202e-01, time/batch = 15.1412s	
25614/33250 (epoch 38.517), train_loss = 0.74714699, grad/param norm = 1.5724e-01, time/batch = 15.1085s	
25615/33250 (epoch 38.519), train_loss = 0.68908565, grad/param norm = 1.2347e-01, time/batch = 15.2512s	
25616/33250 (epoch 38.520), train_loss = 0.96567192, grad/param norm = 2.8983e-01, time/batch = 14.5509s	
25617/33250 (epoch 38.522), train_loss = 0.82245709, grad/param norm = 1.8588e-01, time/batch = 14.5535s	
25618/33250 (epoch 38.523), train_loss = 0.70649781, grad/param norm = 1.6999e-01, time/batch = 15.1072s	
25619/33250 (epoch 38.525), train_loss = 0.66805202, grad/param norm = 1.9424e-01, time/batch = 15.2554s	
25620/33250 (epoch 38.526), train_loss = 0.69009771, grad/param norm = 1.6264e-01, time/batch = 17.2042s	
25621/33250 (epoch 38.528), train_loss = 0.74077097, grad/param norm = 1.6460e-01, time/batch = 18.2894s	
25622/33250 (epoch 38.529), train_loss = 0.72068716, grad/param norm = 1.8204e-01, time/batch = 15.7316s	
25623/33250 (epoch 38.531), train_loss = 0.69187224, grad/param norm = 1.5481e-01, time/batch = 14.4661s	
25624/33250 (epoch 38.532), train_loss = 0.82121534, grad/param norm = 1.5789e-01, time/batch = 14.2063s	
25625/33250 (epoch 38.534), train_loss = 0.70828780, grad/param norm = 1.5159e-01, time/batch = 14.5552s	
25626/33250 (epoch 38.535), train_loss = 0.74934450, grad/param norm = 1.5258e-01, time/batch = 14.9244s	
25627/33250 (epoch 38.537), train_loss = 0.78773490, grad/param norm = 1.5606e-01, time/batch = 14.3859s	
25628/33250 (epoch 38.538), train_loss = 0.83109872, grad/param norm = 1.9017e-01, time/batch = 14.4778s	
25629/33250 (epoch 38.540), train_loss = 0.91661531, grad/param norm = 1.5015e-01, time/batch = 14.4532s	
25630/33250 (epoch 38.541), train_loss = 0.82861443, grad/param norm = 1.9192e-01, time/batch = 14.4588s	
25631/33250 (epoch 38.543), train_loss = 0.82068655, grad/param norm = 1.5464e-01, time/batch = 14.9863s	
25632/33250 (epoch 38.544), train_loss = 0.68766248, grad/param norm = 1.7964e-01, time/batch = 15.8110s	
25633/33250 (epoch 38.546), train_loss = 0.73972233, grad/param norm = 2.1390e-01, time/batch = 17.1985s	
25634/33250 (epoch 38.547), train_loss = 0.75644097, grad/param norm = 1.9105e-01, time/batch = 14.8680s	
25635/33250 (epoch 38.549), train_loss = 0.80006674, grad/param norm = 2.0608e-01, time/batch = 15.3800s	
25636/33250 (epoch 38.550), train_loss = 0.77187126, grad/param norm = 2.0263e-01, time/batch = 14.9572s	
25637/33250 (epoch 38.552), train_loss = 0.82556731, grad/param norm = 1.6120e-01, time/batch = 15.3192s	
25638/33250 (epoch 38.553), train_loss = 0.75510756, grad/param norm = 1.6028e-01, time/batch = 14.9636s	
25639/33250 (epoch 38.555), train_loss = 0.77813771, grad/param norm = 1.5193e-01, time/batch = 14.8710s	
25640/33250 (epoch 38.556), train_loss = 0.78112777, grad/param norm = 2.0654e-01, time/batch = 15.3591s	
25641/33250 (epoch 38.558), train_loss = 0.81320518, grad/param norm = 1.7569e-01, time/batch = 15.8969s	
25642/33250 (epoch 38.559), train_loss = 0.72158577, grad/param norm = 1.6147e-01, time/batch = 15.9552s	
25643/33250 (epoch 38.561), train_loss = 0.68442513, grad/param norm = 1.6828e-01, time/batch = 16.4506s	
25644/33250 (epoch 38.562), train_loss = 0.78144129, grad/param norm = 1.8136e-01, time/batch = 16.2257s	
25645/33250 (epoch 38.564), train_loss = 0.93247544, grad/param norm = 2.1137e-01, time/batch = 15.0280s	
25646/33250 (epoch 38.565), train_loss = 0.87581485, grad/param norm = 2.0738e-01, time/batch = 15.1851s	
25647/33250 (epoch 38.567), train_loss = 0.88805227, grad/param norm = 1.8552e-01, time/batch = 15.0314s	
25648/33250 (epoch 38.568), train_loss = 0.74746056, grad/param norm = 1.8177e-01, time/batch = 15.0588s	
25649/33250 (epoch 38.570), train_loss = 0.83895272, grad/param norm = 1.7640e-01, time/batch = 15.1825s	
25650/33250 (epoch 38.571), train_loss = 0.87565535, grad/param norm = 1.7485e-01, time/batch = 15.0413s	
25651/33250 (epoch 38.573), train_loss = 0.84626264, grad/param norm = 1.9826e-01, time/batch = 14.9431s	
25652/33250 (epoch 38.574), train_loss = 0.71860349, grad/param norm = 1.6362e-01, time/batch = 18.2054s	
25653/33250 (epoch 38.576), train_loss = 0.82050672, grad/param norm = 1.7557e-01, time/batch = 16.3703s	
25654/33250 (epoch 38.577), train_loss = 0.77416920, grad/param norm = 1.6718e-01, time/batch = 17.7740s	
25655/33250 (epoch 38.579), train_loss = 0.66903130, grad/param norm = 1.6102e-01, time/batch = 14.8802s	
25656/33250 (epoch 38.580), train_loss = 0.78234913, grad/param norm = 1.6168e-01, time/batch = 15.0342s	
25657/33250 (epoch 38.582), train_loss = 0.73264377, grad/param norm = 1.5942e-01, time/batch = 14.7949s	
25658/33250 (epoch 38.583), train_loss = 0.83198396, grad/param norm = 1.6893e-01, time/batch = 14.8557s	
25659/33250 (epoch 38.585), train_loss = 0.86138172, grad/param norm = 1.5915e-01, time/batch = 15.0431s	
25660/33250 (epoch 38.586), train_loss = 0.75112414, grad/param norm = 1.7823e-01, time/batch = 15.6922s	
25661/33250 (epoch 38.588), train_loss = 0.81490775, grad/param norm = 1.7038e-01, time/batch = 15.0421s	
25662/33250 (epoch 38.589), train_loss = 0.77318543, grad/param norm = 1.7186e-01, time/batch = 15.5405s	
25663/33250 (epoch 38.591), train_loss = 0.76453796, grad/param norm = 1.8966e-01, time/batch = 16.9663s	
25664/33250 (epoch 38.592), train_loss = 0.74341677, grad/param norm = 1.7789e-01, time/batch = 16.6259s	
25665/33250 (epoch 38.594), train_loss = 0.89895475, grad/param norm = 2.9618e-01, time/batch = 14.9629s	
25666/33250 (epoch 38.595), train_loss = 0.79287251, grad/param norm = 1.6453e-01, time/batch = 14.5613s	
25667/33250 (epoch 38.597), train_loss = 0.66871971, grad/param norm = 1.4272e-01, time/batch = 14.7192s	
25668/33250 (epoch 38.598), train_loss = 0.75268048, grad/param norm = 2.0372e-01, time/batch = 21.2632s	
25669/33250 (epoch 38.600), train_loss = 0.75090684, grad/param norm = 2.3357e-01, time/batch = 21.8145s	
25670/33250 (epoch 38.602), train_loss = 0.79996460, grad/param norm = 1.8400e-01, time/batch = 15.1383s	
25671/33250 (epoch 38.603), train_loss = 0.81848673, grad/param norm = 1.8090e-01, time/batch = 15.1512s	
25672/33250 (epoch 38.605), train_loss = 0.78200844, grad/param norm = 1.9353e-01, time/batch = 17.2855s	
25673/33250 (epoch 38.606), train_loss = 0.85450254, grad/param norm = 1.8913e-01, time/batch = 15.4820s	
25674/33250 (epoch 38.608), train_loss = 0.79550621, grad/param norm = 1.5582e-01, time/batch = 16.1395s	
25675/33250 (epoch 38.609), train_loss = 0.68747304, grad/param norm = 1.6340e-01, time/batch = 16.0322s	
25676/33250 (epoch 38.611), train_loss = 0.76881586, grad/param norm = 2.0413e-01, time/batch = 15.2820s	
25677/33250 (epoch 38.612), train_loss = 0.76313874, grad/param norm = 1.7069e-01, time/batch = 15.1197s	
25678/33250 (epoch 38.614), train_loss = 0.96860792, grad/param norm = 2.0118e-01, time/batch = 15.9619s	
25679/33250 (epoch 38.615), train_loss = 0.89862455, grad/param norm = 1.7990e-01, time/batch = 14.7841s	
25680/33250 (epoch 38.617), train_loss = 0.97935885, grad/param norm = 2.5064e-01, time/batch = 15.2438s	
25681/33250 (epoch 38.618), train_loss = 0.99519572, grad/param norm = 2.5085e-01, time/batch = 15.2064s	
25682/33250 (epoch 38.620), train_loss = 0.87331916, grad/param norm = 2.2318e-01, time/batch = 16.9576s	
25683/33250 (epoch 38.621), train_loss = 0.83057660, grad/param norm = 1.7418e-01, time/batch = 15.7875s	
25684/33250 (epoch 38.623), train_loss = 0.76740145, grad/param norm = 1.8634e-01, time/batch = 18.2957s	
25685/33250 (epoch 38.624), train_loss = 0.75484371, grad/param norm = 1.9450e-01, time/batch = 15.4804s	
25686/33250 (epoch 38.626), train_loss = 0.75216986, grad/param norm = 1.8414e-01, time/batch = 14.9580s	
25687/33250 (epoch 38.627), train_loss = 0.73699363, grad/param norm = 1.6846e-01, time/batch = 15.2510s	
25688/33250 (epoch 38.629), train_loss = 0.84227447, grad/param norm = 2.4886e-01, time/batch = 15.0271s	
25689/33250 (epoch 38.630), train_loss = 0.74835499, grad/param norm = 1.8796e-01, time/batch = 14.6992s	
25690/33250 (epoch 38.632), train_loss = 0.69574559, grad/param norm = 1.6955e-01, time/batch = 14.7861s	
25691/33250 (epoch 38.633), train_loss = 0.80892082, grad/param norm = 1.9851e-01, time/batch = 15.1700s	
25692/33250 (epoch 38.635), train_loss = 0.71865366, grad/param norm = 1.6879e-01, time/batch = 14.7150s	
25693/33250 (epoch 38.636), train_loss = 0.73294759, grad/param norm = 1.5426e-01, time/batch = 16.3909s	
25694/33250 (epoch 38.638), train_loss = 0.70064076, grad/param norm = 1.7509e-01, time/batch = 15.1290s	
25695/33250 (epoch 38.639), train_loss = 0.67185178, grad/param norm = 1.6798e-01, time/batch = 17.1326s	
25696/33250 (epoch 38.641), train_loss = 0.77636659, grad/param norm = 1.7545e-01, time/batch = 17.6213s	
25697/33250 (epoch 38.642), train_loss = 0.58649847, grad/param norm = 1.7732e-01, time/batch = 14.5634s	
25698/33250 (epoch 38.644), train_loss = 0.54280885, grad/param norm = 1.4778e-01, time/batch = 14.7858s	
25699/33250 (epoch 38.645), train_loss = 0.80523651, grad/param norm = 1.9980e-01, time/batch = 14.7187s	
25700/33250 (epoch 38.647), train_loss = 0.66059906, grad/param norm = 1.7641e-01, time/batch = 14.3061s	
25701/33250 (epoch 38.648), train_loss = 0.65363878, grad/param norm = 1.6839e-01, time/batch = 14.8818s	
25702/33250 (epoch 38.650), train_loss = 0.90367777, grad/param norm = 2.1256e-01, time/batch = 15.1029s	
25703/33250 (epoch 38.651), train_loss = 0.81165139, grad/param norm = 1.9195e-01, time/batch = 14.7105s	
25704/33250 (epoch 38.653), train_loss = 0.73999655, grad/param norm = 1.7875e-01, time/batch = 17.1356s	
25705/33250 (epoch 38.654), train_loss = 0.77551809, grad/param norm = 1.8137e-01, time/batch = 15.8724s	
25706/33250 (epoch 38.656), train_loss = 0.83678373, grad/param norm = 1.6192e-01, time/batch = 15.6537s	
25707/33250 (epoch 38.657), train_loss = 0.61334602, grad/param norm = 2.2020e-01, time/batch = 15.9653s	
25708/33250 (epoch 38.659), train_loss = 0.74090655, grad/param norm = 1.9543e-01, time/batch = 14.7983s	
25709/33250 (epoch 38.660), train_loss = 0.79792009, grad/param norm = 1.9928e-01, time/batch = 14.7806s	
25710/33250 (epoch 38.662), train_loss = 0.79936218, grad/param norm = 1.7299e-01, time/batch = 14.7824s	
25711/33250 (epoch 38.663), train_loss = 0.72656258, grad/param norm = 1.8509e-01, time/batch = 15.0460s	
25712/33250 (epoch 38.665), train_loss = 0.80538242, grad/param norm = 1.8445e-01, time/batch = 14.8877s	
25713/33250 (epoch 38.666), train_loss = 0.75706125, grad/param norm = 1.7323e-01, time/batch = 14.9586s	
25714/33250 (epoch 38.668), train_loss = 0.86979859, grad/param norm = 1.7424e-01, time/batch = 15.7811s	
25715/33250 (epoch 38.669), train_loss = 0.80104234, grad/param norm = 1.8980e-01, time/batch = 17.5493s	
25716/33250 (epoch 38.671), train_loss = 0.65792340, grad/param norm = 1.5975e-01, time/batch = 17.3543s	
25717/33250 (epoch 38.672), train_loss = 0.85600307, grad/param norm = 1.8172e-01, time/batch = 16.1358s	
25718/33250 (epoch 38.674), train_loss = 0.71379406, grad/param norm = 2.2962e-01, time/batch = 15.0536s	
25719/33250 (epoch 38.675), train_loss = 0.77412705, grad/param norm = 1.4558e-01, time/batch = 14.5645s	
25720/33250 (epoch 38.677), train_loss = 0.84806417, grad/param norm = 1.9366e-01, time/batch = 14.7910s	
25721/33250 (epoch 38.678), train_loss = 0.71969238, grad/param norm = 2.1108e-01, time/batch = 15.5283s	
25722/33250 (epoch 38.680), train_loss = 0.87899168, grad/param norm = 1.8474e-01, time/batch = 15.2947s	
25723/33250 (epoch 38.681), train_loss = 0.71020049, grad/param norm = 1.7253e-01, time/batch = 14.7982s	
25724/33250 (epoch 38.683), train_loss = 0.71457577, grad/param norm = 1.7889e-01, time/batch = 15.3015s	
25725/33250 (epoch 38.684), train_loss = 0.67209931, grad/param norm = 1.8631e-01, time/batch = 16.2702s	
25726/33250 (epoch 38.686), train_loss = 0.67954409, grad/param norm = 1.5964e-01, time/batch = 15.2456s	
25727/33250 (epoch 38.687), train_loss = 0.80385640, grad/param norm = 1.7678e-01, time/batch = 15.9797s	
25728/33250 (epoch 38.689), train_loss = 0.67878733, grad/param norm = 1.8601e-01, time/batch = 16.4722s	
25729/33250 (epoch 38.690), train_loss = 0.81828691, grad/param norm = 2.1685e-01, time/batch = 14.7073s	
25730/33250 (epoch 38.692), train_loss = 0.76333894, grad/param norm = 1.9033e-01, time/batch = 15.0417s	
25731/33250 (epoch 38.693), train_loss = 0.82046196, grad/param norm = 1.6460e-01, time/batch = 14.4702s	
25732/33250 (epoch 38.695), train_loss = 0.79649188, grad/param norm = 1.8110e-01, time/batch = 14.2823s	
25733/33250 (epoch 38.696), train_loss = 0.82018983, grad/param norm = 1.7729e-01, time/batch = 15.2557s	
25734/33250 (epoch 38.698), train_loss = 0.73997466, grad/param norm = 1.8115e-01, time/batch = 14.6305s	
25735/33250 (epoch 38.699), train_loss = 0.98292503, grad/param norm = 1.8149e-01, time/batch = 14.5408s	
25736/33250 (epoch 38.701), train_loss = 0.77912518, grad/param norm = 1.5589e-01, time/batch = 14.4753s	
25737/33250 (epoch 38.702), train_loss = 0.74018798, grad/param norm = 2.2488e-01, time/batch = 16.0446s	
25738/33250 (epoch 38.704), train_loss = 0.94956174, grad/param norm = 2.8445e-01, time/batch = 15.6039s	
25739/33250 (epoch 38.705), train_loss = 0.73891338, grad/param norm = 1.6278e-01, time/batch = 15.3829s	
25740/33250 (epoch 38.707), train_loss = 0.67502088, grad/param norm = 1.6584e-01, time/batch = 14.4631s	
25741/33250 (epoch 38.708), train_loss = 0.87351400, grad/param norm = 2.0432e-01, time/batch = 15.2548s	
25742/33250 (epoch 38.710), train_loss = 0.80199074, grad/param norm = 2.0446e-01, time/batch = 14.6983s	
25743/33250 (epoch 38.711), train_loss = 0.70447132, grad/param norm = 2.0240e-01, time/batch = 14.7042s	
25744/33250 (epoch 38.713), train_loss = 0.82445495, grad/param norm = 1.7961e-01, time/batch = 14.5484s	
25745/33250 (epoch 38.714), train_loss = 0.77142661, grad/param norm = 1.9201e-01, time/batch = 8.1733s	
25746/33250 (epoch 38.716), train_loss = 0.80175232, grad/param norm = 1.7418e-01, time/batch = 0.6688s	
25747/33250 (epoch 38.717), train_loss = 0.73824878, grad/param norm = 1.4206e-01, time/batch = 0.6839s	
25748/33250 (epoch 38.719), train_loss = 0.72760356, grad/param norm = 1.8961e-01, time/batch = 0.6724s	
25749/33250 (epoch 38.720), train_loss = 1.00167676, grad/param norm = 2.0587e-01, time/batch = 0.6672s	
25750/33250 (epoch 38.722), train_loss = 0.67508284, grad/param norm = 1.5504e-01, time/batch = 0.6696s	
25751/33250 (epoch 38.723), train_loss = 0.60783842, grad/param norm = 1.4158e-01, time/batch = 0.6680s	
25752/33250 (epoch 38.725), train_loss = 0.75445619, grad/param norm = 1.4861e-01, time/batch = 0.6957s	
25753/33250 (epoch 38.726), train_loss = 0.80397446, grad/param norm = 1.8235e-01, time/batch = 0.9720s	
25754/33250 (epoch 38.728), train_loss = 0.81337087, grad/param norm = 1.9119e-01, time/batch = 0.9698s	
25755/33250 (epoch 38.729), train_loss = 0.85409628, grad/param norm = 2.0676e-01, time/batch = 0.9641s	
25756/33250 (epoch 38.731), train_loss = 0.70219195, grad/param norm = 1.8925e-01, time/batch = 0.9593s	
25757/33250 (epoch 38.732), train_loss = 0.70267082, grad/param norm = 1.5839e-01, time/batch = 0.9659s	
25758/33250 (epoch 38.734), train_loss = 0.79063996, grad/param norm = 1.8096e-01, time/batch = 1.7418s	
25759/33250 (epoch 38.735), train_loss = 0.81314253, grad/param norm = 1.8270e-01, time/batch = 1.8002s	
25760/33250 (epoch 38.737), train_loss = 0.75678099, grad/param norm = 1.5304e-01, time/batch = 3.8137s	
25761/33250 (epoch 38.738), train_loss = 0.81379477, grad/param norm = 1.6703e-01, time/batch = 14.6366s	
25762/33250 (epoch 38.740), train_loss = 0.79046824, grad/param norm = 1.7071e-01, time/batch = 15.6145s	
25763/33250 (epoch 38.741), train_loss = 0.81671646, grad/param norm = 1.8056e-01, time/batch = 16.7872s	
25764/33250 (epoch 38.743), train_loss = 0.74458080, grad/param norm = 1.7757e-01, time/batch = 16.7250s	
25765/33250 (epoch 38.744), train_loss = 0.72534185, grad/param norm = 1.9242e-01, time/batch = 16.0564s	
25766/33250 (epoch 38.746), train_loss = 0.68988462, grad/param norm = 1.8521e-01, time/batch = 14.8818s	
25767/33250 (epoch 38.747), train_loss = 0.70255587, grad/param norm = 1.5536e-01, time/batch = 15.0736s	
25768/33250 (epoch 38.749), train_loss = 0.88903428, grad/param norm = 1.8641e-01, time/batch = 14.4503s	
25769/33250 (epoch 38.750), train_loss = 0.88906564, grad/param norm = 1.6925e-01, time/batch = 15.1957s	
25770/33250 (epoch 38.752), train_loss = 0.73236920, grad/param norm = 1.5233e-01, time/batch = 14.4712s	
25771/33250 (epoch 38.753), train_loss = 0.73413215, grad/param norm = 2.3611e-01, time/batch = 15.1963s	
25772/33250 (epoch 38.755), train_loss = 0.67813517, grad/param norm = 2.0475e-01, time/batch = 15.2913s	
25773/33250 (epoch 38.756), train_loss = 0.76990229, grad/param norm = 1.8127e-01, time/batch = 17.7084s	
25774/33250 (epoch 38.758), train_loss = 0.91960770, grad/param norm = 1.6267e-01, time/batch = 16.6367s	
25775/33250 (epoch 38.759), train_loss = 0.74815522, grad/param norm = 1.7513e-01, time/batch = 15.4551s	
25776/33250 (epoch 38.761), train_loss = 0.82244757, grad/param norm = 1.9806e-01, time/batch = 14.3866s	
25777/33250 (epoch 38.762), train_loss = 0.84332621, grad/param norm = 1.8733e-01, time/batch = 14.7208s	
25778/33250 (epoch 38.764), train_loss = 0.69717310, grad/param norm = 2.2613e-01, time/batch = 15.2823s	
25779/33250 (epoch 38.765), train_loss = 0.82297181, grad/param norm = 1.9926e-01, time/batch = 14.9492s	
25780/33250 (epoch 38.767), train_loss = 0.61442689, grad/param norm = 1.5164e-01, time/batch = 14.9643s	
25781/33250 (epoch 38.768), train_loss = 0.67089712, grad/param norm = 1.8805e-01, time/batch = 15.2637s	
25782/33250 (epoch 38.770), train_loss = 0.79809350, grad/param norm = 1.8141e-01, time/batch = 14.7885s	
25783/33250 (epoch 38.771), train_loss = 0.84310623, grad/param norm = 1.9898e-01, time/batch = 16.8551s	
25784/33250 (epoch 38.773), train_loss = 0.75944866, grad/param norm = 1.6406e-01, time/batch = 15.0161s	
25785/33250 (epoch 38.774), train_loss = 0.65907876, grad/param norm = 1.7023e-01, time/batch = 15.9761s	
25786/33250 (epoch 38.776), train_loss = 0.72972564, grad/param norm = 1.6166e-01, time/batch = 15.1167s	
25787/33250 (epoch 38.777), train_loss = 0.86695193, grad/param norm = 1.9414e-01, time/batch = 15.0400s	
25788/33250 (epoch 38.779), train_loss = 0.74361583, grad/param norm = 1.7304e-01, time/batch = 14.7975s	
25789/33250 (epoch 38.780), train_loss = 0.89999793, grad/param norm = 2.2063e-01, time/batch = 14.6348s	
25790/33250 (epoch 38.782), train_loss = 0.79240206, grad/param norm = 2.7436e-01, time/batch = 14.8719s	
25791/33250 (epoch 38.783), train_loss = 0.63560764, grad/param norm = 1.7016e-01, time/batch = 14.9540s	
25792/33250 (epoch 38.785), train_loss = 0.68089737, grad/param norm = 1.6924e-01, time/batch = 14.7019s	
25793/33250 (epoch 38.786), train_loss = 0.85961221, grad/param norm = 1.9504e-01, time/batch = 14.3857s	
25794/33250 (epoch 38.788), train_loss = 0.87214029, grad/param norm = 1.7852e-01, time/batch = 14.7033s	
25795/33250 (epoch 38.789), train_loss = 0.86718987, grad/param norm = 2.0452e-01, time/batch = 18.4469s	
25796/33250 (epoch 38.791), train_loss = 0.89771761, grad/param norm = 2.0220e-01, time/batch = 15.9742s	
25797/33250 (epoch 38.792), train_loss = 0.95893833, grad/param norm = 2.0207e-01, time/batch = 16.1065s	
25798/33250 (epoch 38.794), train_loss = 0.74920101, grad/param norm = 1.6734e-01, time/batch = 15.1895s	
25799/33250 (epoch 38.795), train_loss = 0.76542804, grad/param norm = 1.7755e-01, time/batch = 14.6304s	
25800/33250 (epoch 38.797), train_loss = 0.85750911, grad/param norm = 2.0827e-01, time/batch = 14.7802s	
25801/33250 (epoch 38.798), train_loss = 0.76625723, grad/param norm = 2.1599e-01, time/batch = 15.1895s	
25802/33250 (epoch 38.800), train_loss = 0.80020188, grad/param norm = 1.9329e-01, time/batch = 15.0183s	
25803/33250 (epoch 38.802), train_loss = 0.77524055, grad/param norm = 1.6281e-01, time/batch = 15.0515s	
25804/33250 (epoch 38.803), train_loss = 0.83026585, grad/param norm = 1.6499e-01, time/batch = 14.3899s	
25805/33250 (epoch 38.805), train_loss = 0.81435604, grad/param norm = 1.6344e-01, time/batch = 17.2215s	
25806/33250 (epoch 38.806), train_loss = 0.77974521, grad/param norm = 1.8479e-01, time/batch = 15.6080s	
25807/33250 (epoch 38.808), train_loss = 0.70978696, grad/param norm = 1.6325e-01, time/batch = 15.8861s	
25808/33250 (epoch 38.809), train_loss = 0.69474148, grad/param norm = 1.4993e-01, time/batch = 15.5375s	
25809/33250 (epoch 38.811), train_loss = 0.68091440, grad/param norm = 1.6743e-01, time/batch = 14.8852s	
25810/33250 (epoch 38.812), train_loss = 0.81137059, grad/param norm = 2.0391e-01, time/batch = 15.1962s	
25811/33250 (epoch 38.814), train_loss = 0.73847201, grad/param norm = 2.0475e-01, time/batch = 14.8679s	
25812/33250 (epoch 38.815), train_loss = 0.82635700, grad/param norm = 1.9115e-01, time/batch = 15.3727s	
25813/33250 (epoch 38.817), train_loss = 0.76686868, grad/param norm = 1.8908e-01, time/batch = 15.0993s	
25814/33250 (epoch 38.818), train_loss = 0.72410709, grad/param norm = 1.7671e-01, time/batch = 15.2758s	
25815/33250 (epoch 38.820), train_loss = 0.81205168, grad/param norm = 1.7422e-01, time/batch = 17.5361s	
25816/33250 (epoch 38.821), train_loss = 0.76562463, grad/param norm = 1.4626e-01, time/batch = 17.9446s	
25817/33250 (epoch 38.823), train_loss = 1.03246692, grad/param norm = 2.1041e-01, time/batch = 15.7002s	
25818/33250 (epoch 38.824), train_loss = 0.71233240, grad/param norm = 1.8201e-01, time/batch = 16.5257s	
25819/33250 (epoch 38.826), train_loss = 0.80914261, grad/param norm = 1.8091e-01, time/batch = 14.7000s	
25820/33250 (epoch 38.827), train_loss = 0.70178588, grad/param norm = 1.7906e-01, time/batch = 14.2207s	
25821/33250 (epoch 38.829), train_loss = 0.80621468, grad/param norm = 1.8542e-01, time/batch = 14.7061s	
25822/33250 (epoch 38.830), train_loss = 0.84342969, grad/param norm = 2.3860e-01, time/batch = 15.3653s	
25823/33250 (epoch 38.832), train_loss = 0.81110940, grad/param norm = 1.7805e-01, time/batch = 14.6308s	
25824/33250 (epoch 38.833), train_loss = 0.77949924, grad/param norm = 1.9775e-01, time/batch = 14.8619s	
25825/33250 (epoch 38.835), train_loss = 0.68957809, grad/param norm = 1.7080e-01, time/batch = 15.1579s	
25826/33250 (epoch 38.836), train_loss = 0.77011563, grad/param norm = 1.6417e-01, time/batch = 16.3838s	
25827/33250 (epoch 38.838), train_loss = 0.81484199, grad/param norm = 1.8829e-01, time/batch = 15.5730s	
25828/33250 (epoch 38.839), train_loss = 0.74781174, grad/param norm = 1.7894e-01, time/batch = 16.9824s	
25829/33250 (epoch 38.841), train_loss = 0.72858804, grad/param norm = 1.8472e-01, time/batch = 16.5228s	
25830/33250 (epoch 38.842), train_loss = 0.90707045, grad/param norm = 2.0452e-01, time/batch = 15.2106s	
25831/33250 (epoch 38.844), train_loss = 0.84971581, grad/param norm = 1.9813e-01, time/batch = 14.7713s	
25832/33250 (epoch 38.845), train_loss = 0.93661900, grad/param norm = 2.1008e-01, time/batch = 16.2771s	
25833/33250 (epoch 38.847), train_loss = 0.91053633, grad/param norm = 1.9113e-01, time/batch = 15.1231s	
25834/33250 (epoch 38.848), train_loss = 0.96184841, grad/param norm = 2.0530e-01, time/batch = 14.8028s	
25835/33250 (epoch 38.850), train_loss = 0.84951565, grad/param norm = 1.7847e-01, time/batch = 14.6906s	
25836/33250 (epoch 38.851), train_loss = 0.69109232, grad/param norm = 1.9704e-01, time/batch = 15.0405s	
25837/33250 (epoch 38.853), train_loss = 0.82610221, grad/param norm = 2.1561e-01, time/batch = 15.1355s	
25838/33250 (epoch 38.854), train_loss = 0.75448133, grad/param norm = 1.6497e-01, time/batch = 17.0583s	
25839/33250 (epoch 38.856), train_loss = 0.73199624, grad/param norm = 1.9788e-01, time/batch = 14.8876s	
25840/33250 (epoch 38.857), train_loss = 0.68351668, grad/param norm = 1.8794e-01, time/batch = 14.9753s	
25841/33250 (epoch 38.859), train_loss = 0.75398603, grad/param norm = 2.0614e-01, time/batch = 14.9403s	
25842/33250 (epoch 38.860), train_loss = 0.82338655, grad/param norm = 1.7880e-01, time/batch = 14.5565s	
25843/33250 (epoch 38.862), train_loss = 0.70597123, grad/param norm = 1.5803e-01, time/batch = 15.0298s	
25844/33250 (epoch 38.863), train_loss = 0.73711665, grad/param norm = 1.8057e-01, time/batch = 15.1076s	
25845/33250 (epoch 38.865), train_loss = 0.80566498, grad/param norm = 1.9068e-01, time/batch = 15.2997s	
25846/33250 (epoch 38.866), train_loss = 0.69468900, grad/param norm = 1.7741e-01, time/batch = 14.6308s	
25847/33250 (epoch 38.868), train_loss = 0.77792361, grad/param norm = 2.0181e-01, time/batch = 14.3000s	
25848/33250 (epoch 38.869), train_loss = 0.81730753, grad/param norm = 1.8780e-01, time/batch = 15.3022s	
25849/33250 (epoch 38.871), train_loss = 0.63181427, grad/param norm = 1.5036e-01, time/batch = 15.4076s	
25850/33250 (epoch 38.872), train_loss = 0.83441678, grad/param norm = 2.1102e-01, time/batch = 15.7874s	
25851/33250 (epoch 38.874), train_loss = 0.73857675, grad/param norm = 2.0171e-01, time/batch = 16.7228s	
25852/33250 (epoch 38.875), train_loss = 0.67677212, grad/param norm = 2.3859e-01, time/batch = 15.1071s	
25853/33250 (epoch 38.877), train_loss = 0.86369366, grad/param norm = 1.7891e-01, time/batch = 16.6179s	
25854/33250 (epoch 38.878), train_loss = 0.79620459, grad/param norm = 1.8022e-01, time/batch = 15.8635s	
25855/33250 (epoch 38.880), train_loss = 0.79306675, grad/param norm = 2.0837e-01, time/batch = 16.3698s	
25856/33250 (epoch 38.881), train_loss = 0.88963400, grad/param norm = 1.8619e-01, time/batch = 15.1147s	
25857/33250 (epoch 38.883), train_loss = 0.82868512, grad/param norm = 1.7837e-01, time/batch = 14.8014s	
25858/33250 (epoch 38.884), train_loss = 0.87361635, grad/param norm = 2.0704e-01, time/batch = 14.9668s	
25859/33250 (epoch 38.886), train_loss = 0.71523507, grad/param norm = 1.5013e-01, time/batch = 15.9757s	
25860/33250 (epoch 38.887), train_loss = 0.75385709, grad/param norm = 2.1122e-01, time/batch = 15.2124s	
25861/33250 (epoch 38.889), train_loss = 0.73893377, grad/param norm = 1.5963e-01, time/batch = 17.1313s	
25862/33250 (epoch 38.890), train_loss = 0.59376176, grad/param norm = 1.2958e-01, time/batch = 16.5565s	
25863/33250 (epoch 38.892), train_loss = 0.80534322, grad/param norm = 1.5815e-01, time/batch = 15.0749s	
25864/33250 (epoch 38.893), train_loss = 0.84540182, grad/param norm = 2.0437e-01, time/batch = 14.5372s	
25865/33250 (epoch 38.895), train_loss = 0.73039964, grad/param norm = 1.6574e-01, time/batch = 14.5458s	
25866/33250 (epoch 38.896), train_loss = 0.83657643, grad/param norm = 1.8250e-01, time/batch = 15.0522s	
25867/33250 (epoch 38.898), train_loss = 0.78902568, grad/param norm = 1.7094e-01, time/batch = 14.9605s	
25868/33250 (epoch 38.899), train_loss = 0.73372959, grad/param norm = 1.7445e-01, time/batch = 14.7789s	
25869/33250 (epoch 38.901), train_loss = 0.65564761, grad/param norm = 1.6034e-01, time/batch = 15.2023s	
25870/33250 (epoch 38.902), train_loss = 0.75204105, grad/param norm = 1.9698e-01, time/batch = 15.7708s	
25871/33250 (epoch 38.904), train_loss = 0.69368815, grad/param norm = 1.7397e-01, time/batch = 17.1130s	
25872/33250 (epoch 38.905), train_loss = 0.76169956, grad/param norm = 1.4706e-01, time/batch = 16.2228s	
25873/33250 (epoch 38.907), train_loss = 0.71825194, grad/param norm = 1.7230e-01, time/batch = 17.8860s	
25874/33250 (epoch 38.908), train_loss = 0.76417647, grad/param norm = 1.4663e-01, time/batch = 15.7066s	
25875/33250 (epoch 38.910), train_loss = 0.85118751, grad/param norm = 2.5521e-01, time/batch = 15.2668s	
25876/33250 (epoch 38.911), train_loss = 0.70138444, grad/param norm = 1.7300e-01, time/batch = 14.8683s	
25877/33250 (epoch 38.913), train_loss = 0.72509401, grad/param norm = 1.5050e-01, time/batch = 14.4576s	
25878/33250 (epoch 38.914), train_loss = 0.64410306, grad/param norm = 1.5192e-01, time/batch = 15.2151s	
25879/33250 (epoch 38.916), train_loss = 0.68650886, grad/param norm = 1.7616e-01, time/batch = 15.0256s	
25880/33250 (epoch 38.917), train_loss = 0.76921361, grad/param norm = 1.4005e-01, time/batch = 14.7838s	
25881/33250 (epoch 38.919), train_loss = 0.72186878, grad/param norm = 1.8266e-01, time/batch = 14.8013s	
25882/33250 (epoch 38.920), train_loss = 0.79277907, grad/param norm = 2.3950e-01, time/batch = 17.0548s	
25883/33250 (epoch 38.922), train_loss = 0.80547027, grad/param norm = 1.9680e-01, time/batch = 15.6043s	
25884/33250 (epoch 38.923), train_loss = 0.75627038, grad/param norm = 1.7790e-01, time/batch = 16.5953s	
25885/33250 (epoch 38.925), train_loss = 0.73467868, grad/param norm = 1.7739e-01, time/batch = 15.6282s	
25886/33250 (epoch 38.926), train_loss = 0.72566961, grad/param norm = 1.5864e-01, time/batch = 14.7195s	
25887/33250 (epoch 38.928), train_loss = 0.74789048, grad/param norm = 1.7535e-01, time/batch = 14.7899s	
25888/33250 (epoch 38.929), train_loss = 0.66601318, grad/param norm = 1.3718e-01, time/batch = 14.8682s	
25889/33250 (epoch 38.931), train_loss = 0.85869276, grad/param norm = 1.8208e-01, time/batch = 14.7112s	
25890/33250 (epoch 38.932), train_loss = 0.72066834, grad/param norm = 1.8841e-01, time/batch = 14.8718s	
25891/33250 (epoch 38.934), train_loss = 0.70376624, grad/param norm = 1.6969e-01, time/batch = 15.2612s	
25892/33250 (epoch 38.935), train_loss = 0.74249429, grad/param norm = 1.7563e-01, time/batch = 15.2931s	
25893/33250 (epoch 38.937), train_loss = 0.71249214, grad/param norm = 1.7575e-01, time/batch = 16.6439s	
25894/33250 (epoch 38.938), train_loss = 0.74797271, grad/param norm = 2.2992e-01, time/batch = 16.9322s	
25895/33250 (epoch 38.940), train_loss = 0.74610934, grad/param norm = 1.8760e-01, time/batch = 16.0495s	
25896/33250 (epoch 38.941), train_loss = 0.81670010, grad/param norm = 1.7527e-01, time/batch = 16.1246s	
25897/33250 (epoch 38.943), train_loss = 0.90925226, grad/param norm = 1.9331e-01, time/batch = 14.6102s	
25898/33250 (epoch 38.944), train_loss = 0.73444432, grad/param norm = 1.5827e-01, time/batch = 15.0333s	
25899/33250 (epoch 38.946), train_loss = 0.85549713, grad/param norm = 1.9860e-01, time/batch = 15.3620s	
25900/33250 (epoch 38.947), train_loss = 0.69636957, grad/param norm = 2.0866e-01, time/batch = 15.4506s	
25901/33250 (epoch 38.949), train_loss = 0.81954817, grad/param norm = 1.7591e-01, time/batch = 14.7822s	
25902/33250 (epoch 38.950), train_loss = 0.84744566, grad/param norm = 1.8479e-01, time/batch = 15.1797s	
25903/33250 (epoch 38.952), train_loss = 0.77462500, grad/param norm = 1.8046e-01, time/batch = 15.5446s	
25904/33250 (epoch 38.953), train_loss = 0.79179631, grad/param norm = 2.3404e-01, time/batch = 16.8930s	
25905/33250 (epoch 38.955), train_loss = 0.87023468, grad/param norm = 1.9221e-01, time/batch = 14.4037s	
25906/33250 (epoch 38.956), train_loss = 0.78705649, grad/param norm = 2.2454e-01, time/batch = 15.1165s	
25907/33250 (epoch 38.958), train_loss = 0.72904233, grad/param norm = 1.7848e-01, time/batch = 15.1524s	
25908/33250 (epoch 38.959), train_loss = 0.72582409, grad/param norm = 1.7266e-01, time/batch = 14.4684s	
25909/33250 (epoch 38.961), train_loss = 0.95811402, grad/param norm = 2.0237e-01, time/batch = 14.7213s	
25910/33250 (epoch 38.962), train_loss = 0.75546411, grad/param norm = 1.8260e-01, time/batch = 14.6320s	
25911/33250 (epoch 38.964), train_loss = 0.88345218, grad/param norm = 1.9820e-01, time/batch = 14.7691s	
25912/33250 (epoch 38.965), train_loss = 0.85322919, grad/param norm = 2.2876e-01, time/batch = 14.7940s	
25913/33250 (epoch 38.967), train_loss = 0.77525596, grad/param norm = 2.0442e-01, time/batch = 15.2957s	
25914/33250 (epoch 38.968), train_loss = 0.90527288, grad/param norm = 1.8799e-01, time/batch = 24.2458s	
25915/33250 (epoch 38.970), train_loss = 1.00590200, grad/param norm = 2.2823e-01, time/batch = 21.1738s	
25916/33250 (epoch 38.971), train_loss = 0.93264460, grad/param norm = 2.1116e-01, time/batch = 15.2328s	
25917/33250 (epoch 38.973), train_loss = 0.75916825, grad/param norm = 1.6661e-01, time/batch = 14.9702s	
25918/33250 (epoch 38.974), train_loss = 0.85094952, grad/param norm = 1.9142e-01, time/batch = 14.7145s	
25919/33250 (epoch 38.976), train_loss = 0.74105753, grad/param norm = 1.6636e-01, time/batch = 14.9338s	
25920/33250 (epoch 38.977), train_loss = 0.77313263, grad/param norm = 1.8045e-01, time/batch = 14.7060s	
25921/33250 (epoch 38.979), train_loss = 0.83535478, grad/param norm = 1.8138e-01, time/batch = 15.1730s	
25922/33250 (epoch 38.980), train_loss = 0.82060932, grad/param norm = 1.6599e-01, time/batch = 15.0982s	
25923/33250 (epoch 38.982), train_loss = 0.75859001, grad/param norm = 1.6450e-01, time/batch = 14.5394s	
25924/33250 (epoch 38.983), train_loss = 0.82893723, grad/param norm = 1.9930e-01, time/batch = 14.6974s	
25925/33250 (epoch 38.985), train_loss = 0.75083229, grad/param norm = 1.8196e-01, time/batch = 14.8012s	
25926/33250 (epoch 38.986), train_loss = 0.85430017, grad/param norm = 1.8235e-01, time/batch = 15.4613s	
25927/33250 (epoch 38.988), train_loss = 0.89032244, grad/param norm = 1.8778e-01, time/batch = 15.0006s	
25928/33250 (epoch 38.989), train_loss = 0.87679549, grad/param norm = 1.9482e-01, time/batch = 16.8832s	
25929/33250 (epoch 38.991), train_loss = 0.85193967, grad/param norm = 2.0980e-01, time/batch = 15.0252s	
25930/33250 (epoch 38.992), train_loss = 0.78657560, grad/param norm = 1.8204e-01, time/batch = 14.9663s	
25931/33250 (epoch 38.994), train_loss = 0.73269989, grad/param norm = 1.6387e-01, time/batch = 14.8803s	
25932/33250 (epoch 38.995), train_loss = 0.79502459, grad/param norm = 2.4840e-01, time/batch = 15.5339s	
25933/33250 (epoch 38.997), train_loss = 0.57823809, grad/param norm = 1.4892e-01, time/batch = 15.1730s	
25934/33250 (epoch 38.998), train_loss = 0.83002287, grad/param norm = 1.6817e-01, time/batch = 14.8838s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
25935/33250 (epoch 39.000), train_loss = 0.82868624, grad/param norm = 1.7526e-01, time/batch = 15.4978s	
25936/33250 (epoch 39.002), train_loss = 0.99456575, grad/param norm = 1.8383e-01, time/batch = 16.9447s	
25937/33250 (epoch 39.003), train_loss = 0.86514050, grad/param norm = 2.0372e-01, time/batch = 15.1259s	
25938/33250 (epoch 39.005), train_loss = 0.63933046, grad/param norm = 1.4997e-01, time/batch = 17.9663s	
25939/33250 (epoch 39.006), train_loss = 0.67617496, grad/param norm = 1.6360e-01, time/batch = 15.3058s	
25940/33250 (epoch 39.008), train_loss = 0.88359983, grad/param norm = 1.9357e-01, time/batch = 15.0174s	
25941/33250 (epoch 39.009), train_loss = 0.95068071, grad/param norm = 1.8594e-01, time/batch = 16.3573s	
25942/33250 (epoch 39.011), train_loss = 0.73692524, grad/param norm = 1.7667e-01, time/batch = 14.8805s	
25943/33250 (epoch 39.012), train_loss = 0.76576594, grad/param norm = 2.6218e-01, time/batch = 14.7804s	
25944/33250 (epoch 39.014), train_loss = 0.87180193, grad/param norm = 2.1318e-01, time/batch = 14.9499s	
25945/33250 (epoch 39.015), train_loss = 0.81287578, grad/param norm = 1.9008e-01, time/batch = 14.8666s	
25946/33250 (epoch 39.017), train_loss = 0.83250282, grad/param norm = 2.3478e-01, time/batch = 15.4669s	
25947/33250 (epoch 39.018), train_loss = 0.62889519, grad/param norm = 1.5520e-01, time/batch = 16.9609s	
25948/33250 (epoch 39.020), train_loss = 0.78844827, grad/param norm = 1.6276e-01, time/batch = 15.1118s	
25949/33250 (epoch 39.021), train_loss = 0.79792607, grad/param norm = 1.6820e-01, time/batch = 16.3158s	
25950/33250 (epoch 39.023), train_loss = 0.63474810, grad/param norm = 1.6102e-01, time/batch = 15.7084s	
25951/33250 (epoch 39.024), train_loss = 0.88086317, grad/param norm = 1.9915e-01, time/batch = 15.3841s	
25952/33250 (epoch 39.026), train_loss = 0.83230343, grad/param norm = 1.7907e-01, time/batch = 15.0214s	
25953/33250 (epoch 39.027), train_loss = 0.83010146, grad/param norm = 1.7725e-01, time/batch = 14.2596s	
25954/33250 (epoch 39.029), train_loss = 0.75856555, grad/param norm = 1.6580e-01, time/batch = 14.5526s	
25955/33250 (epoch 39.030), train_loss = 0.77212763, grad/param norm = 1.8841e-01, time/batch = 14.5866s	
25956/33250 (epoch 39.032), train_loss = 0.96357648, grad/param norm = 2.0357e-01, time/batch = 14.8566s	
25957/33250 (epoch 39.033), train_loss = 0.75984112, grad/param norm = 1.9612e-01, time/batch = 14.7898s	
25958/33250 (epoch 39.035), train_loss = 0.80948635, grad/param norm = 1.7928e-01, time/batch = 14.8051s	
25959/33250 (epoch 39.036), train_loss = 0.83387573, grad/param norm = 1.9619e-01, time/batch = 15.4777s	
25960/33250 (epoch 39.038), train_loss = 0.79702057, grad/param norm = 1.4864e-01, time/batch = 15.3115s	
25961/33250 (epoch 39.039), train_loss = 0.74201851, grad/param norm = 1.7954e-01, time/batch = 16.3971s	
25962/33250 (epoch 39.041), train_loss = 0.80268368, grad/param norm = 2.2750e-01, time/batch = 14.5480s	
25963/33250 (epoch 39.042), train_loss = 0.66229541, grad/param norm = 1.6197e-01, time/batch = 14.7964s	
25964/33250 (epoch 39.044), train_loss = 0.90264545, grad/param norm = 1.9192e-01, time/batch = 14.7032s	
25965/33250 (epoch 39.045), train_loss = 0.89067091, grad/param norm = 1.7812e-01, time/batch = 14.6373s	
25966/33250 (epoch 39.047), train_loss = 0.81858271, grad/param norm = 1.7560e-01, time/batch = 14.5520s	
25967/33250 (epoch 39.048), train_loss = 0.83376789, grad/param norm = 2.1924e-01, time/batch = 14.2890s	
25968/33250 (epoch 39.050), train_loss = 0.79405562, grad/param norm = 1.8855e-01, time/batch = 14.9393s	
25969/33250 (epoch 39.051), train_loss = 0.79637079, grad/param norm = 1.5819e-01, time/batch = 16.9576s	
25970/33250 (epoch 39.053), train_loss = 0.84936828, grad/param norm = 2.0621e-01, time/batch = 15.8891s	
25971/33250 (epoch 39.054), train_loss = 0.67264063, grad/param norm = 1.5450e-01, time/batch = 16.4650s	
25972/33250 (epoch 39.056), train_loss = 0.68323295, grad/param norm = 1.5812e-01, time/batch = 16.8615s	
25973/33250 (epoch 39.057), train_loss = 0.87648395, grad/param norm = 1.7819e-01, time/batch = 14.7832s	
25974/33250 (epoch 39.059), train_loss = 0.77058419, grad/param norm = 1.9579e-01, time/batch = 14.7930s	
25975/33250 (epoch 39.060), train_loss = 0.81588507, grad/param norm = 1.9376e-01, time/batch = 15.2063s	
25976/33250 (epoch 39.062), train_loss = 0.87158043, grad/param norm = 1.7620e-01, time/batch = 17.1825s	
25977/33250 (epoch 39.063), train_loss = 0.90866288, grad/param norm = 1.7264e-01, time/batch = 15.2095s	
25978/33250 (epoch 39.065), train_loss = 0.77187226, grad/param norm = 1.8108e-01, time/batch = 15.1784s	
25979/33250 (epoch 39.066), train_loss = 0.83452315, grad/param norm = 1.9496e-01, time/batch = 15.0987s	
25980/33250 (epoch 39.068), train_loss = 0.75751240, grad/param norm = 1.6791e-01, time/batch = 18.0052s	
25981/33250 (epoch 39.069), train_loss = 0.81690264, grad/param norm = 1.7963e-01, time/batch = 17.2811s	
25982/33250 (epoch 39.071), train_loss = 0.74939316, grad/param norm = 1.6623e-01, time/batch = 19.4529s	
25983/33250 (epoch 39.072), train_loss = 0.70867035, grad/param norm = 1.5874e-01, time/batch = 14.8678s	
25984/33250 (epoch 39.074), train_loss = 0.81300491, grad/param norm = 1.6717e-01, time/batch = 14.7141s	
25985/33250 (epoch 39.075), train_loss = 0.74355020, grad/param norm = 1.6806e-01, time/batch = 14.8726s	
25986/33250 (epoch 39.077), train_loss = 0.78522179, grad/param norm = 2.3769e-01, time/batch = 14.4775s	
25987/33250 (epoch 39.078), train_loss = 0.78614831, grad/param norm = 1.7442e-01, time/batch = 14.8618s	
25988/33250 (epoch 39.080), train_loss = 0.82193942, grad/param norm = 2.4810e-01, time/batch = 14.7895s	
25989/33250 (epoch 39.081), train_loss = 0.80822799, grad/param norm = 1.6140e-01, time/batch = 14.9602s	
25990/33250 (epoch 39.083), train_loss = 0.91100474, grad/param norm = 1.8317e-01, time/batch = 17.6894s	
25991/33250 (epoch 39.084), train_loss = 0.83829135, grad/param norm = 1.8799e-01, time/batch = 15.2716s	
25992/33250 (epoch 39.086), train_loss = 0.79082161, grad/param norm = 1.5005e-01, time/batch = 17.2897s	
25993/33250 (epoch 39.087), train_loss = 0.68748247, grad/param norm = 1.5675e-01, time/batch = 15.0598s	
25994/33250 (epoch 39.089), train_loss = 0.77250103, grad/param norm = 1.7711e-01, time/batch = 15.2122s	
25995/33250 (epoch 39.090), train_loss = 0.80468085, grad/param norm = 1.6965e-01, time/batch = 14.5317s	
25996/33250 (epoch 39.092), train_loss = 0.73720919, grad/param norm = 1.5097e-01, time/batch = 14.8739s	
25997/33250 (epoch 39.093), train_loss = 0.77703456, grad/param norm = 1.6466e-01, time/batch = 14.1380s	
25998/33250 (epoch 39.095), train_loss = 0.79925627, grad/param norm = 1.8558e-01, time/batch = 14.5298s	
25999/33250 (epoch 39.096), train_loss = 0.67402794, grad/param norm = 1.6234e-01, time/batch = 15.3761s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch39.10_1.6771.t7	
26000/33250 (epoch 39.098), train_loss = 0.66549727, grad/param norm = 1.8746e-01, time/batch = 14.9696s	
26001/33250 (epoch 39.099), train_loss = 1.18937048, grad/param norm = 2.4062e-01, time/batch = 20.1678s	
26002/33250 (epoch 39.101), train_loss = 0.78160546, grad/param norm = 2.0556e-01, time/batch = 17.9708s	
26003/33250 (epoch 39.102), train_loss = 0.74171224, grad/param norm = 1.8797e-01, time/batch = 18.2114s	
26004/33250 (epoch 39.104), train_loss = 0.59654735, grad/param norm = 1.4772e-01, time/batch = 18.4595s	
26005/33250 (epoch 39.105), train_loss = 0.74494618, grad/param norm = 1.7874e-01, time/batch = 18.7656s	
26006/33250 (epoch 39.107), train_loss = 0.65400961, grad/param norm = 1.4479e-01, time/batch = 18.6871s	
26007/33250 (epoch 39.108), train_loss = 0.77020086, grad/param norm = 1.8337e-01, time/batch = 17.8652s	
26008/33250 (epoch 39.110), train_loss = 0.67209891, grad/param norm = 1.7231e-01, time/batch = 17.7861s	
26009/33250 (epoch 39.111), train_loss = 0.76954532, grad/param norm = 1.7775e-01, time/batch = 18.5354s	
26010/33250 (epoch 39.113), train_loss = 0.71378899, grad/param norm = 1.7151e-01, time/batch = 19.1172s	
26011/33250 (epoch 39.114), train_loss = 0.67317510, grad/param norm = 1.8265e-01, time/batch = 20.7656s	
26012/33250 (epoch 39.116), train_loss = 0.71898395, grad/param norm = 1.9745e-01, time/batch = 18.7050s	
26013/33250 (epoch 39.117), train_loss = 0.69199527, grad/param norm = 1.6449e-01, time/batch = 19.8736s	
26014/33250 (epoch 39.119), train_loss = 0.74510403, grad/param norm = 1.8271e-01, time/batch = 17.8123s	
26015/33250 (epoch 39.120), train_loss = 0.62608940, grad/param norm = 1.4649e-01, time/batch = 18.1907s	
26016/33250 (epoch 39.122), train_loss = 0.84065341, grad/param norm = 1.8656e-01, time/batch = 18.3833s	
26017/33250 (epoch 39.123), train_loss = 0.75406008, grad/param norm = 1.9394e-01, time/batch = 17.7007s	
26018/33250 (epoch 39.125), train_loss = 0.61494134, grad/param norm = 1.8273e-01, time/batch = 17.7069s	
26019/33250 (epoch 39.126), train_loss = 0.73689508, grad/param norm = 1.7161e-01, time/batch = 18.2894s	
26020/33250 (epoch 39.128), train_loss = 0.71234128, grad/param norm = 1.5651e-01, time/batch = 18.2031s	
26021/33250 (epoch 39.129), train_loss = 0.77573810, grad/param norm = 1.8278e-01, time/batch = 21.5799s	
26022/33250 (epoch 39.131), train_loss = 0.74350786, grad/param norm = 1.6866e-01, time/batch = 25.9897s	
26023/33250 (epoch 39.132), train_loss = 0.71403391, grad/param norm = 1.6413e-01, time/batch = 15.4302s	
26024/33250 (epoch 39.134), train_loss = 0.70312848, grad/param norm = 1.8112e-01, time/batch = 15.0347s	
26025/33250 (epoch 39.135), train_loss = 0.77948494, grad/param norm = 1.5950e-01, time/batch = 14.7228s	
26026/33250 (epoch 39.137), train_loss = 0.69103585, grad/param norm = 1.7752e-01, time/batch = 14.5608s	
26027/33250 (epoch 39.138), train_loss = 0.67908485, grad/param norm = 1.4740e-01, time/batch = 15.1724s	
26028/33250 (epoch 39.140), train_loss = 0.60837141, grad/param norm = 1.6138e-01, time/batch = 15.1956s	
26029/33250 (epoch 39.141), train_loss = 0.87328085, grad/param norm = 2.8203e-01, time/batch = 14.7031s	
26030/33250 (epoch 39.143), train_loss = 0.64894158, grad/param norm = 1.8374e-01, time/batch = 15.6252s	
26031/33250 (epoch 39.144), train_loss = 0.73525206, grad/param norm = 1.5517e-01, time/batch = 15.6276s	
26032/33250 (epoch 39.146), train_loss = 0.70555627, grad/param norm = 1.4962e-01, time/batch = 15.0670s	
26033/33250 (epoch 39.147), train_loss = 0.74324711, grad/param norm = 1.7029e-01, time/batch = 14.9061s	
26034/33250 (epoch 39.149), train_loss = 0.69470422, grad/param norm = 1.4525e-01, time/batch = 14.8124s	
26035/33250 (epoch 39.150), train_loss = 0.69193883, grad/param norm = 1.7512e-01, time/batch = 14.9385s	
26036/33250 (epoch 39.152), train_loss = 0.64620795, grad/param norm = 1.5373e-01, time/batch = 15.3483s	
26037/33250 (epoch 39.153), train_loss = 0.88665377, grad/param norm = 1.7661e-01, time/batch = 14.8027s	
26038/33250 (epoch 39.155), train_loss = 0.72578164, grad/param norm = 1.9090e-01, time/batch = 14.8858s	
26039/33250 (epoch 39.156), train_loss = 0.94538671, grad/param norm = 1.7706e-01, time/batch = 14.7864s	
26040/33250 (epoch 39.158), train_loss = 0.90877956, grad/param norm = 2.7573e-01, time/batch = 15.0270s	
26041/33250 (epoch 39.159), train_loss = 0.72665690, grad/param norm = 2.5216e-01, time/batch = 15.2789s	
26042/33250 (epoch 39.161), train_loss = 0.79338489, grad/param norm = 1.9457e-01, time/batch = 15.2092s	
26043/33250 (epoch 39.162), train_loss = 0.68541700, grad/param norm = 1.6064e-01, time/batch = 14.9574s	
26044/33250 (epoch 39.164), train_loss = 0.76528531, grad/param norm = 2.0578e-01, time/batch = 14.5358s	
26045/33250 (epoch 39.165), train_loss = 0.84989742, grad/param norm = 1.9667e-01, time/batch = 14.6964s	
26046/33250 (epoch 39.167), train_loss = 0.90528400, grad/param norm = 1.9726e-01, time/batch = 14.6970s	
26047/33250 (epoch 39.168), train_loss = 0.68062518, grad/param norm = 1.4808e-01, time/batch = 15.0111s	
26048/33250 (epoch 39.170), train_loss = 0.73431031, grad/param norm = 1.7886e-01, time/batch = 15.3158s	
26049/33250 (epoch 39.171), train_loss = 0.77531744, grad/param norm = 1.7015e-01, time/batch = 14.8264s	
26050/33250 (epoch 39.173), train_loss = 0.75297619, grad/param norm = 1.7618e-01, time/batch = 14.8485s	
26051/33250 (epoch 39.174), train_loss = 0.78720659, grad/param norm = 1.5911e-01, time/batch = 15.4139s	
26052/33250 (epoch 39.176), train_loss = 0.71593623, grad/param norm = 1.6061e-01, time/batch = 14.8484s	
26053/33250 (epoch 39.177), train_loss = 0.69940227, grad/param norm = 1.5906e-01, time/batch = 14.8034s	
26054/33250 (epoch 39.179), train_loss = 0.68711196, grad/param norm = 1.4910e-01, time/batch = 14.6246s	
26055/33250 (epoch 39.180), train_loss = 0.61793573, grad/param norm = 1.5196e-01, time/batch = 15.1890s	
26056/33250 (epoch 39.182), train_loss = 0.69052047, grad/param norm = 1.7860e-01, time/batch = 14.6298s	
26057/33250 (epoch 39.183), train_loss = 0.86771101, grad/param norm = 2.0321e-01, time/batch = 14.9278s	
26058/33250 (epoch 39.185), train_loss = 0.77226115, grad/param norm = 1.8556e-01, time/batch = 14.7000s	
26059/33250 (epoch 39.186), train_loss = 0.80119976, grad/param norm = 1.8558e-01, time/batch = 15.2405s	
26060/33250 (epoch 39.188), train_loss = 0.87161264, grad/param norm = 2.1665e-01, time/batch = 14.9190s	
26061/33250 (epoch 39.189), train_loss = 0.62046088, grad/param norm = 1.8904e-01, time/batch = 15.2476s	
26062/33250 (epoch 39.191), train_loss = 0.72782824, grad/param norm = 1.8406e-01, time/batch = 15.0133s	
26063/33250 (epoch 39.192), train_loss = 0.73390633, grad/param norm = 1.7455e-01, time/batch = 15.2790s	
26064/33250 (epoch 39.194), train_loss = 0.73942091, grad/param norm = 1.8869e-01, time/batch = 15.0277s	
26065/33250 (epoch 39.195), train_loss = 0.91950719, grad/param norm = 1.7577e-01, time/batch = 14.8816s	
26066/33250 (epoch 39.197), train_loss = 0.71456359, grad/param norm = 1.9044e-01, time/batch = 14.9655s	
26067/33250 (epoch 39.198), train_loss = 0.90243617, grad/param norm = 1.9102e-01, time/batch = 15.4625s	
26068/33250 (epoch 39.200), train_loss = 0.75766120, grad/param norm = 1.8753e-01, time/batch = 14.6949s	
26069/33250 (epoch 39.202), train_loss = 0.73408210, grad/param norm = 1.5934e-01, time/batch = 14.6337s	
26070/33250 (epoch 39.203), train_loss = 0.69660930, grad/param norm = 1.9575e-01, time/batch = 15.7091s	
26071/33250 (epoch 39.205), train_loss = 0.78380470, grad/param norm = 1.7502e-01, time/batch = 15.1229s	
26072/33250 (epoch 39.206), train_loss = 0.82904523, grad/param norm = 1.7588e-01, time/batch = 15.0426s	
26073/33250 (epoch 39.208), train_loss = 0.87609656, grad/param norm = 2.0183e-01, time/batch = 14.9594s	
26074/33250 (epoch 39.209), train_loss = 0.72936487, grad/param norm = 1.5717e-01, time/batch = 15.9365s	
26075/33250 (epoch 39.211), train_loss = 0.80763974, grad/param norm = 1.9027e-01, time/batch = 15.2028s	
26076/33250 (epoch 39.212), train_loss = 0.89461303, grad/param norm = 1.7992e-01, time/batch = 16.8858s	
26077/33250 (epoch 39.214), train_loss = 0.79944723, grad/param norm = 1.6023e-01, time/batch = 15.0214s	
26078/33250 (epoch 39.215), train_loss = 0.81898028, grad/param norm = 2.0097e-01, time/batch = 15.0227s	
26079/33250 (epoch 39.217), train_loss = 0.84922368, grad/param norm = 2.0538e-01, time/batch = 14.5508s	
26080/33250 (epoch 39.218), train_loss = 0.81852006, grad/param norm = 1.6414e-01, time/batch = 14.7224s	
26081/33250 (epoch 39.220), train_loss = 0.78608262, grad/param norm = 1.6960e-01, time/batch = 15.2013s	
26082/33250 (epoch 39.221), train_loss = 0.89162313, grad/param norm = 2.1393e-01, time/batch = 15.0258s	
26083/33250 (epoch 39.223), train_loss = 0.78409303, grad/param norm = 1.8177e-01, time/batch = 14.6188s	
26084/33250 (epoch 39.224), train_loss = 0.82580279, grad/param norm = 1.9039e-01, time/batch = 14.7930s	
26085/33250 (epoch 39.226), train_loss = 0.91545862, grad/param norm = 1.9302e-01, time/batch = 15.4645s	
26086/33250 (epoch 39.227), train_loss = 0.82143354, grad/param norm = 1.9246e-01, time/batch = 16.6256s	
26087/33250 (epoch 39.229), train_loss = 0.78565712, grad/param norm = 1.7800e-01, time/batch = 15.0465s	
26088/33250 (epoch 39.230), train_loss = 0.78815628, grad/param norm = 1.7246e-01, time/batch = 16.0325s	
26089/33250 (epoch 39.232), train_loss = 0.75773249, grad/param norm = 1.6770e-01, time/batch = 14.8761s	
26090/33250 (epoch 39.233), train_loss = 0.71045304, grad/param norm = 1.5884e-01, time/batch = 15.1716s	
26091/33250 (epoch 39.235), train_loss = 0.89568963, grad/param norm = 1.7490e-01, time/batch = 17.1911s	
26092/33250 (epoch 39.236), train_loss = 0.73189929, grad/param norm = 1.8499e-01, time/batch = 14.8748s	
26093/33250 (epoch 39.238), train_loss = 0.89380792, grad/param norm = 2.2360e-01, time/batch = 14.7207s	
26094/33250 (epoch 39.239), train_loss = 0.88125576, grad/param norm = 2.3029e-01, time/batch = 15.0201s	
26095/33250 (epoch 39.241), train_loss = 0.87898973, grad/param norm = 2.2170e-01, time/batch = 14.8053s	
26096/33250 (epoch 39.242), train_loss = 0.89021418, grad/param norm = 2.5160e-01, time/batch = 14.7129s	
26097/33250 (epoch 39.244), train_loss = 0.82497619, grad/param norm = 2.1632e-01, time/batch = 16.2126s	
26098/33250 (epoch 39.245), train_loss = 0.81944675, grad/param norm = 1.9037e-01, time/batch = 16.4609s	
26099/33250 (epoch 39.247), train_loss = 0.76348305, grad/param norm = 1.9796e-01, time/batch = 16.1233s	
26100/33250 (epoch 39.248), train_loss = 0.90689850, grad/param norm = 2.0223e-01, time/batch = 16.1188s	
26101/33250 (epoch 39.250), train_loss = 0.89386112, grad/param norm = 1.6580e-01, time/batch = 15.4141s	
26102/33250 (epoch 39.251), train_loss = 0.76698204, grad/param norm = 1.6266e-01, time/batch = 15.3452s	
26103/33250 (epoch 39.253), train_loss = 0.76059411, grad/param norm = 1.5892e-01, time/batch = 16.1977s	
26104/33250 (epoch 39.254), train_loss = 0.71381864, grad/param norm = 1.7614e-01, time/batch = 15.0553s	
26105/33250 (epoch 39.256), train_loss = 0.77770894, grad/param norm = 1.5711e-01, time/batch = 14.8756s	
26106/33250 (epoch 39.257), train_loss = 0.93009051, grad/param norm = 1.8277e-01, time/batch = 14.9495s	
26107/33250 (epoch 39.259), train_loss = 0.83416970, grad/param norm = 2.0187e-01, time/batch = 14.7709s	
26108/33250 (epoch 39.260), train_loss = 0.65793683, grad/param norm = 1.9157e-01, time/batch = 16.6295s	
26109/33250 (epoch 39.262), train_loss = 0.80806467, grad/param norm = 1.8513e-01, time/batch = 16.9601s	
26110/33250 (epoch 39.263), train_loss = 0.66345049, grad/param norm = 1.8532e-01, time/batch = 15.2299s	
26111/33250 (epoch 39.265), train_loss = 0.83707436, grad/param norm = 2.1923e-01, time/batch = 15.8108s	
26112/33250 (epoch 39.266), train_loss = 0.77798740, grad/param norm = 1.7404e-01, time/batch = 14.6302s	
26113/33250 (epoch 39.268), train_loss = 0.69096068, grad/param norm = 1.7567e-01, time/batch = 15.0218s	
26114/33250 (epoch 39.269), train_loss = 0.64044070, grad/param norm = 1.6821e-01, time/batch = 15.0193s	
26115/33250 (epoch 39.271), train_loss = 0.81848738, grad/param norm = 1.7013e-01, time/batch = 15.6690s	
26116/33250 (epoch 39.272), train_loss = 0.71456889, grad/param norm = 1.4083e-01, time/batch = 14.8841s	
26117/33250 (epoch 39.274), train_loss = 0.58831108, grad/param norm = 1.5948e-01, time/batch = 15.0231s	
26118/33250 (epoch 39.275), train_loss = 0.74751149, grad/param norm = 1.7206e-01, time/batch = 18.0222s	
26119/33250 (epoch 39.277), train_loss = 0.63949559, grad/param norm = 1.7342e-01, time/batch = 15.5594s	
26120/33250 (epoch 39.278), train_loss = 0.73385677, grad/param norm = 1.6947e-01, time/batch = 16.7079s	
26121/33250 (epoch 39.280), train_loss = 0.68663907, grad/param norm = 1.5477e-01, time/batch = 15.5470s	
26122/33250 (epoch 39.281), train_loss = 0.79053850, grad/param norm = 2.1092e-01, time/batch = 14.9709s	
26123/33250 (epoch 39.283), train_loss = 0.81842188, grad/param norm = 2.6198e-01, time/batch = 15.0258s	
26124/33250 (epoch 39.284), train_loss = 0.66206763, grad/param norm = 1.8405e-01, time/batch = 15.6089s	
26125/33250 (epoch 39.286), train_loss = 0.80865722, grad/param norm = 1.7708e-01, time/batch = 14.9462s	
26126/33250 (epoch 39.287), train_loss = 0.64639119, grad/param norm = 1.5992e-01, time/batch = 14.4674s	
26127/33250 (epoch 39.289), train_loss = 0.62569694, grad/param norm = 1.7300e-01, time/batch = 15.0054s	
26128/33250 (epoch 39.290), train_loss = 0.77158047, grad/param norm = 1.6679e-01, time/batch = 15.6916s	
26129/33250 (epoch 39.292), train_loss = 0.82554295, grad/param norm = 2.4268e-01, time/batch = 16.9529s	
26130/33250 (epoch 39.293), train_loss = 0.86597442, grad/param norm = 1.7015e-01, time/batch = 18.7087s	
26131/33250 (epoch 39.295), train_loss = 0.86975980, grad/param norm = 1.7952e-01, time/batch = 17.9555s	
26132/33250 (epoch 39.296), train_loss = 0.79942368, grad/param norm = 1.9266e-01, time/batch = 21.4313s	
26133/33250 (epoch 39.298), train_loss = 0.63184316, grad/param norm = 1.4546e-01, time/batch = 25.2263s	
26134/33250 (epoch 39.299), train_loss = 0.61270633, grad/param norm = 1.6144e-01, time/batch = 15.8691s	
26135/33250 (epoch 39.301), train_loss = 0.85831181, grad/param norm = 1.7875e-01, time/batch = 15.0222s	
26136/33250 (epoch 39.302), train_loss = 0.83841590, grad/param norm = 2.2751e-01, time/batch = 14.9426s	
26137/33250 (epoch 39.304), train_loss = 0.72785181, grad/param norm = 1.7643e-01, time/batch = 14.7993s	
26138/33250 (epoch 39.305), train_loss = 0.69487746, grad/param norm = 1.4985e-01, time/batch = 14.9650s	
26139/33250 (epoch 39.307), train_loss = 0.82015141, grad/param norm = 1.8094e-01, time/batch = 15.8594s	
26140/33250 (epoch 39.308), train_loss = 0.88862392, grad/param norm = 3.6062e-01, time/batch = 14.8705s	
26141/33250 (epoch 39.310), train_loss = 0.73215132, grad/param norm = 1.9089e-01, time/batch = 16.0496s	
26142/33250 (epoch 39.311), train_loss = 0.93453967, grad/param norm = 2.2893e-01, time/batch = 16.8072s	
26143/33250 (epoch 39.313), train_loss = 0.62949485, grad/param norm = 1.9989e-01, time/batch = 14.9612s	
26144/33250 (epoch 39.314), train_loss = 0.83840030, grad/param norm = 1.6395e-01, time/batch = 16.1930s	
26145/33250 (epoch 39.316), train_loss = 0.93341191, grad/param norm = 2.3803e-01, time/batch = 14.9648s	
26146/33250 (epoch 39.317), train_loss = 0.69218056, grad/param norm = 1.8110e-01, time/batch = 14.9235s	
26147/33250 (epoch 39.319), train_loss = 0.83077699, grad/param norm = 2.2225e-01, time/batch = 14.7742s	
26148/33250 (epoch 39.320), train_loss = 0.84884081, grad/param norm = 2.5701e-01, time/batch = 14.1399s	
26149/33250 (epoch 39.322), train_loss = 0.94131004, grad/param norm = 2.0388e-01, time/batch = 14.4611s	
26150/33250 (epoch 39.323), train_loss = 0.92393804, grad/param norm = 2.4803e-01, time/batch = 16.7674s	
26151/33250 (epoch 39.325), train_loss = 0.77463068, grad/param norm = 2.4624e-01, time/batch = 15.1197s	
26152/33250 (epoch 39.326), train_loss = 1.00314923, grad/param norm = 2.1677e-01, time/batch = 18.4583s	
26153/33250 (epoch 39.328), train_loss = 0.77608089, grad/param norm = 1.8207e-01, time/batch = 15.9754s	
26154/33250 (epoch 39.329), train_loss = 0.81134574, grad/param norm = 2.0929e-01, time/batch = 14.5438s	
26155/33250 (epoch 39.331), train_loss = 0.79394706, grad/param norm = 2.0632e-01, time/batch = 14.8086s	
26156/33250 (epoch 39.332), train_loss = 0.78965854, grad/param norm = 1.7018e-01, time/batch = 14.7978s	
26157/33250 (epoch 39.334), train_loss = 0.93776406, grad/param norm = 1.9363e-01, time/batch = 14.6875s	
26158/33250 (epoch 39.335), train_loss = 0.59946261, grad/param norm = 1.6323e-01, time/batch = 15.0871s	
26159/33250 (epoch 39.337), train_loss = 0.83883170, grad/param norm = 1.7421e-01, time/batch = 14.8087s	
26160/33250 (epoch 39.338), train_loss = 0.94683094, grad/param norm = 2.1836e-01, time/batch = 15.9611s	
26161/33250 (epoch 39.340), train_loss = 0.76135401, grad/param norm = 1.6386e-01, time/batch = 16.6345s	
26162/33250 (epoch 39.341), train_loss = 0.73087543, grad/param norm = 2.0304e-01, time/batch = 16.5410s	
26163/33250 (epoch 39.343), train_loss = 0.75243636, grad/param norm = 1.8731e-01, time/batch = 15.1497s	
26164/33250 (epoch 39.344), train_loss = 0.77059088, grad/param norm = 1.5918e-01, time/batch = 17.2948s	
26165/33250 (epoch 39.346), train_loss = 0.66583824, grad/param norm = 1.5448e-01, time/batch = 14.8076s	
26166/33250 (epoch 39.347), train_loss = 0.97199153, grad/param norm = 2.1885e-01, time/batch = 14.9040s	
26167/33250 (epoch 39.349), train_loss = 0.76520740, grad/param norm = 2.0307e-01, time/batch = 14.9577s	
26168/33250 (epoch 39.350), train_loss = 0.79762209, grad/param norm = 2.5989e-01, time/batch = 15.7141s	
26169/33250 (epoch 39.352), train_loss = 0.70054508, grad/param norm = 2.0834e-01, time/batch = 15.2004s	
26170/33250 (epoch 39.353), train_loss = 0.74682972, grad/param norm = 1.6862e-01, time/batch = 14.8695s	
26171/33250 (epoch 39.355), train_loss = 0.73928302, grad/param norm = 1.9722e-01, time/batch = 15.5353s	
26172/33250 (epoch 39.356), train_loss = 0.71380120, grad/param norm = 2.1537e-01, time/batch = 16.0621s	
26173/33250 (epoch 39.358), train_loss = 0.76386124, grad/param norm = 1.6694e-01, time/batch = 15.7810s	
26174/33250 (epoch 39.359), train_loss = 0.74456928, grad/param norm = 1.9893e-01, time/batch = 18.2885s	
26175/33250 (epoch 39.361), train_loss = 0.89505793, grad/param norm = 2.2519e-01, time/batch = 14.7380s	
26176/33250 (epoch 39.362), train_loss = 0.81701595, grad/param norm = 1.7134e-01, time/batch = 14.5530s	
26177/33250 (epoch 39.364), train_loss = 0.81898737, grad/param norm = 1.8797e-01, time/batch = 15.6804s	
26178/33250 (epoch 39.365), train_loss = 0.77563653, grad/param norm = 1.5848e-01, time/batch = 15.2216s	
26179/33250 (epoch 39.367), train_loss = 0.80595492, grad/param norm = 1.5876e-01, time/batch = 14.7182s	
26180/33250 (epoch 39.368), train_loss = 0.76716204, grad/param norm = 1.8331e-01, time/batch = 14.6357s	
26181/33250 (epoch 39.370), train_loss = 0.71823401, grad/param norm = 1.6607e-01, time/batch = 15.0473s	
26182/33250 (epoch 39.371), train_loss = 0.88357237, grad/param norm = 1.9472e-01, time/batch = 16.3562s	
26183/33250 (epoch 39.373), train_loss = 0.75784418, grad/param norm = 1.6160e-01, time/batch = 15.5403s	
26184/33250 (epoch 39.374), train_loss = 0.79440573, grad/param norm = 2.3434e-01, time/batch = 15.5969s	
26185/33250 (epoch 39.376), train_loss = 0.79031433, grad/param norm = 1.7943e-01, time/batch = 15.0512s	
26186/33250 (epoch 39.377), train_loss = 0.68370556, grad/param norm = 2.2113e-01, time/batch = 16.4688s	
26187/33250 (epoch 39.379), train_loss = 0.78049246, grad/param norm = 1.8404e-01, time/batch = 14.6332s	
26188/33250 (epoch 39.380), train_loss = 0.77518038, grad/param norm = 1.9145e-01, time/batch = 14.6365s	
26189/33250 (epoch 39.382), train_loss = 0.80673375, grad/param norm = 2.0942e-01, time/batch = 15.1027s	
26190/33250 (epoch 39.383), train_loss = 0.69386097, grad/param norm = 1.7146e-01, time/batch = 15.7915s	
26191/33250 (epoch 39.385), train_loss = 0.64031847, grad/param norm = 1.7512e-01, time/batch = 15.1841s	
26192/33250 (epoch 39.386), train_loss = 0.69520349, grad/param norm = 2.2737e-01, time/batch = 14.8767s	
26193/33250 (epoch 39.388), train_loss = 0.72416105, grad/param norm = 1.7224e-01, time/batch = 15.5186s	
26194/33250 (epoch 39.389), train_loss = 0.72975950, grad/param norm = 2.1305e-01, time/batch = 16.1920s	
26195/33250 (epoch 39.391), train_loss = 0.81327422, grad/param norm = 1.6802e-01, time/batch = 16.0391s	
26196/33250 (epoch 39.392), train_loss = 0.88216442, grad/param norm = 2.0361e-01, time/batch = 15.5516s	
26197/33250 (epoch 39.394), train_loss = 0.86403285, grad/param norm = 2.1065e-01, time/batch = 15.1289s	
26198/33250 (epoch 39.395), train_loss = 0.86366562, grad/param norm = 1.6960e-01, time/batch = 15.0429s	
26199/33250 (epoch 39.397), train_loss = 0.89001326, grad/param norm = 1.7731e-01, time/batch = 15.3799s	
26200/33250 (epoch 39.398), train_loss = 0.69695117, grad/param norm = 1.6742e-01, time/batch = 15.3630s	
26201/33250 (epoch 39.400), train_loss = 0.69072969, grad/param norm = 1.5184e-01, time/batch = 16.0888s	
26202/33250 (epoch 39.402), train_loss = 0.66092449, grad/param norm = 1.7947e-01, time/batch = 15.2840s	
26203/33250 (epoch 39.403), train_loss = 0.74603509, grad/param norm = 1.7785e-01, time/batch = 15.6945s	
26204/33250 (epoch 39.405), train_loss = 0.71420639, grad/param norm = 1.4574e-01, time/batch = 16.4498s	
26205/33250 (epoch 39.406), train_loss = 0.75859020, grad/param norm = 2.1764e-01, time/batch = 17.2092s	
26206/33250 (epoch 39.408), train_loss = 0.92274321, grad/param norm = 1.8911e-01, time/batch = 18.4475s	
26207/33250 (epoch 39.409), train_loss = 0.82494296, grad/param norm = 2.2084e-01, time/batch = 18.1609s	
26208/33250 (epoch 39.411), train_loss = 0.56653459, grad/param norm = 1.2843e-01, time/batch = 15.1870s	
26209/33250 (epoch 39.412), train_loss = 0.67169833, grad/param norm = 1.9070e-01, time/batch = 15.4640s	
26210/33250 (epoch 39.414), train_loss = 0.79941161, grad/param norm = 1.7776e-01, time/batch = 14.7957s	
26211/33250 (epoch 39.415), train_loss = 0.83581716, grad/param norm = 1.8806e-01, time/batch = 16.1104s	
26212/33250 (epoch 39.417), train_loss = 0.87112011, grad/param norm = 1.8368e-01, time/batch = 15.1037s	
26213/33250 (epoch 39.418), train_loss = 1.00948414, grad/param norm = 2.2647e-01, time/batch = 16.3751s	
26214/33250 (epoch 39.420), train_loss = 0.87152260, grad/param norm = 1.8100e-01, time/batch = 15.5408s	
26215/33250 (epoch 39.421), train_loss = 0.76538844, grad/param norm = 1.8048e-01, time/batch = 16.0279s	
26216/33250 (epoch 39.423), train_loss = 0.81447372, grad/param norm = 1.8854e-01, time/batch = 16.7686s	
26217/33250 (epoch 39.424), train_loss = 0.88741369, grad/param norm = 2.4585e-01, time/batch = 16.9760s	
26218/33250 (epoch 39.426), train_loss = 0.74942781, grad/param norm = 1.5980e-01, time/batch = 14.8136s	
26219/33250 (epoch 39.427), train_loss = 0.73095646, grad/param norm = 1.7309e-01, time/batch = 15.3339s	
26220/33250 (epoch 39.429), train_loss = 0.79486215, grad/param norm = 2.0978e-01, time/batch = 15.5540s	
26221/33250 (epoch 39.430), train_loss = 0.74298043, grad/param norm = 1.8657e-01, time/batch = 15.5190s	
26222/33250 (epoch 39.432), train_loss = 0.85803795, grad/param norm = 1.7138e-01, time/batch = 15.0166s	
26223/33250 (epoch 39.433), train_loss = 0.71414141, grad/param norm = 1.7116e-01, time/batch = 15.1664s	
26224/33250 (epoch 39.435), train_loss = 0.84733657, grad/param norm = 1.7657e-01, time/batch = 14.6946s	
26225/33250 (epoch 39.436), train_loss = 0.73761867, grad/param norm = 1.8924e-01, time/batch = 15.0306s	
26226/33250 (epoch 39.438), train_loss = 0.89588583, grad/param norm = 1.9473e-01, time/batch = 16.9731s	
26227/33250 (epoch 39.439), train_loss = 0.79262173, grad/param norm = 1.7371e-01, time/batch = 15.2916s	
26228/33250 (epoch 39.441), train_loss = 0.76550324, grad/param norm = 1.7489e-01, time/batch = 14.9044s	
26229/33250 (epoch 39.442), train_loss = 0.70785756, grad/param norm = 1.6383e-01, time/batch = 14.9054s	
26230/33250 (epoch 39.444), train_loss = 0.73873932, grad/param norm = 1.6079e-01, time/batch = 15.0453s	
26231/33250 (epoch 39.445), train_loss = 0.80172162, grad/param norm = 1.6185e-01, time/batch = 15.6120s	
26232/33250 (epoch 39.447), train_loss = 0.69902847, grad/param norm = 1.6704e-01, time/batch = 15.0286s	
26233/33250 (epoch 39.448), train_loss = 0.80832194, grad/param norm = 1.5349e-01, time/batch = 14.7186s	
26234/33250 (epoch 39.450), train_loss = 0.89333622, grad/param norm = 2.1319e-01, time/batch = 15.0139s	
26235/33250 (epoch 39.451), train_loss = 0.84464294, grad/param norm = 1.9418e-01, time/batch = 15.0907s	
26236/33250 (epoch 39.453), train_loss = 0.68510060, grad/param norm = 1.5212e-01, time/batch = 15.3519s	
26237/33250 (epoch 39.454), train_loss = 0.90654345, grad/param norm = 1.8782e-01, time/batch = 16.6355s	
26238/33250 (epoch 39.456), train_loss = 0.89407248, grad/param norm = 1.6110e-01, time/batch = 15.9822s	
26239/33250 (epoch 39.457), train_loss = 0.72295225, grad/param norm = 1.9639e-01, time/batch = 17.2001s	
26240/33250 (epoch 39.459), train_loss = 0.83330567, grad/param norm = 1.9549e-01, time/batch = 15.2942s	
26241/33250 (epoch 39.460), train_loss = 0.84913108, grad/param norm = 1.9883e-01, time/batch = 14.7969s	
26242/33250 (epoch 39.462), train_loss = 0.78844409, grad/param norm = 2.0729e-01, time/batch = 15.9451s	
26243/33250 (epoch 39.463), train_loss = 0.69489711, grad/param norm = 1.3849e-01, time/batch = 15.2103s	
26244/33250 (epoch 39.465), train_loss = 0.65044408, grad/param norm = 1.5225e-01, time/batch = 15.2166s	
26245/33250 (epoch 39.466), train_loss = 0.63383031, grad/param norm = 1.2803e-01, time/batch = 15.9352s	
26246/33250 (epoch 39.468), train_loss = 0.67707326, grad/param norm = 1.4955e-01, time/batch = 15.1011s	
26247/33250 (epoch 39.469), train_loss = 0.77698284, grad/param norm = 1.7891e-01, time/batch = 15.2840s	
26248/33250 (epoch 39.471), train_loss = 0.84681168, grad/param norm = 1.6252e-01, time/batch = 15.1775s	
26249/33250 (epoch 39.472), train_loss = 0.74657317, grad/param norm = 2.0596e-01, time/batch = 15.0284s	
26250/33250 (epoch 39.474), train_loss = 0.85943538, grad/param norm = 1.8312e-01, time/batch = 15.3551s	
26251/33250 (epoch 39.475), train_loss = 0.78028377, grad/param norm = 1.5037e-01, time/batch = 15.7447s	
26252/33250 (epoch 39.477), train_loss = 0.79995554, grad/param norm = 1.5612e-01, time/batch = 14.9160s	
26253/33250 (epoch 39.478), train_loss = 0.70230354, grad/param norm = 1.7940e-01, time/batch = 15.0258s	
26254/33250 (epoch 39.480), train_loss = 0.87707222, grad/param norm = 1.7326e-01, time/batch = 15.7085s	
26255/33250 (epoch 39.481), train_loss = 0.76082668, grad/param norm = 1.9434e-01, time/batch = 15.2374s	
26256/33250 (epoch 39.483), train_loss = 0.75772383, grad/param norm = 1.7785e-01, time/batch = 15.3220s	
26257/33250 (epoch 39.484), train_loss = 0.69851204, grad/param norm = 1.5217e-01, time/batch = 15.0290s	
26258/33250 (epoch 39.486), train_loss = 0.64279703, grad/param norm = 1.7647e-01, time/batch = 15.1241s	
26259/33250 (epoch 39.487), train_loss = 0.70586397, grad/param norm = 1.6873e-01, time/batch = 16.1429s	
26260/33250 (epoch 39.489), train_loss = 0.85954802, grad/param norm = 1.8754e-01, time/batch = 15.7218s	
26261/33250 (epoch 39.490), train_loss = 0.81870490, grad/param norm = 2.1865e-01, time/batch = 16.0424s	
26262/33250 (epoch 39.492), train_loss = 0.85905939, grad/param norm = 2.0455e-01, time/batch = 14.8572s	
26263/33250 (epoch 39.493), train_loss = 0.77483757, grad/param norm = 1.8616e-01, time/batch = 14.6979s	
26264/33250 (epoch 39.495), train_loss = 0.84456247, grad/param norm = 1.5844e-01, time/batch = 14.5398s	
26265/33250 (epoch 39.496), train_loss = 0.79425481, grad/param norm = 1.5991e-01, time/batch = 14.9561s	
26266/33250 (epoch 39.498), train_loss = 0.85277011, grad/param norm = 2.0578e-01, time/batch = 14.7830s	
26267/33250 (epoch 39.499), train_loss = 0.73459145, grad/param norm = 1.6521e-01, time/batch = 14.7226s	
26268/33250 (epoch 39.501), train_loss = 0.74793409, grad/param norm = 1.9565e-01, time/batch = 14.7815s	
26269/33250 (epoch 39.502), train_loss = 0.74345968, grad/param norm = 1.5914e-01, time/batch = 15.8771s	
26270/33250 (epoch 39.504), train_loss = 0.91864748, grad/param norm = 2.2480e-01, time/batch = 15.7115s	
26271/33250 (epoch 39.505), train_loss = 0.66113623, grad/param norm = 1.3415e-01, time/batch = 17.8710s	
26272/33250 (epoch 39.507), train_loss = 0.70567361, grad/param norm = 1.8532e-01, time/batch = 15.4520s	
26273/33250 (epoch 39.508), train_loss = 0.75006118, grad/param norm = 1.6865e-01, time/batch = 15.1931s	
26274/33250 (epoch 39.510), train_loss = 0.64344046, grad/param norm = 1.4605e-01, time/batch = 15.0115s	
26275/33250 (epoch 39.511), train_loss = 0.76237999, grad/param norm = 1.9849e-01, time/batch = 15.3865s	
26276/33250 (epoch 39.513), train_loss = 0.88533172, grad/param norm = 1.7708e-01, time/batch = 14.7061s	
26277/33250 (epoch 39.514), train_loss = 0.74611096, grad/param norm = 1.7309e-01, time/batch = 15.1890s	
26278/33250 (epoch 39.516), train_loss = 0.71120352, grad/param norm = 1.8107e-01, time/batch = 14.6234s	
26279/33250 (epoch 39.517), train_loss = 0.74319776, grad/param norm = 1.5630e-01, time/batch = 14.7055s	
26280/33250 (epoch 39.519), train_loss = 0.69364637, grad/param norm = 1.3134e-01, time/batch = 15.3150s	
26281/33250 (epoch 39.520), train_loss = 0.95498654, grad/param norm = 2.2684e-01, time/batch = 16.5482s	
26282/33250 (epoch 39.522), train_loss = 0.80524743, grad/param norm = 1.7979e-01, time/batch = 15.7215s	
26283/33250 (epoch 39.523), train_loss = 0.70763495, grad/param norm = 1.7591e-01, time/batch = 15.4428s	
26284/33250 (epoch 39.525), train_loss = 0.65510142, grad/param norm = 1.7169e-01, time/batch = 15.1756s	
26285/33250 (epoch 39.526), train_loss = 0.68461361, grad/param norm = 1.6494e-01, time/batch = 14.8551s	
26286/33250 (epoch 39.528), train_loss = 0.72258315, grad/param norm = 1.6658e-01, time/batch = 15.0959s	
26287/33250 (epoch 39.529), train_loss = 0.71696677, grad/param norm = 1.6963e-01, time/batch = 15.2119s	
26288/33250 (epoch 39.531), train_loss = 0.68509807, grad/param norm = 1.5840e-01, time/batch = 15.6182s	
26289/33250 (epoch 39.532), train_loss = 0.80280099, grad/param norm = 1.5455e-01, time/batch = 15.0336s	
26290/33250 (epoch 39.534), train_loss = 0.69859576, grad/param norm = 1.4992e-01, time/batch = 14.7709s	
26291/33250 (epoch 39.535), train_loss = 0.76166932, grad/param norm = 1.7580e-01, time/batch = 15.5490s	
26292/33250 (epoch 39.537), train_loss = 0.77598617, grad/param norm = 1.5956e-01, time/batch = 15.7022s	
26293/33250 (epoch 39.538), train_loss = 0.82082023, grad/param norm = 1.7746e-01, time/batch = 15.9395s	
26294/33250 (epoch 39.540), train_loss = 0.90745467, grad/param norm = 1.5325e-01, time/batch = 16.4531s	
26295/33250 (epoch 39.541), train_loss = 0.83218909, grad/param norm = 1.9818e-01, time/batch = 15.6608s	
26296/33250 (epoch 39.543), train_loss = 0.81216561, grad/param norm = 1.4911e-01, time/batch = 15.2914s	
26297/33250 (epoch 39.544), train_loss = 0.68491895, grad/param norm = 1.7725e-01, time/batch = 14.7903s	
26298/33250 (epoch 39.546), train_loss = 0.71678091, grad/param norm = 1.9501e-01, time/batch = 14.7942s	
26299/33250 (epoch 39.547), train_loss = 0.74374940, grad/param norm = 1.8959e-01, time/batch = 14.4658s	
26300/33250 (epoch 39.549), train_loss = 0.78098850, grad/param norm = 2.0093e-01, time/batch = 14.7083s	
26301/33250 (epoch 39.550), train_loss = 0.73825396, grad/param norm = 1.5663e-01, time/batch = 14.9550s	
26302/33250 (epoch 39.552), train_loss = 0.81742364, grad/param norm = 1.6906e-01, time/batch = 18.0266s	
26303/33250 (epoch 39.553), train_loss = 0.75498846, grad/param norm = 1.6299e-01, time/batch = 16.3873s	
26304/33250 (epoch 39.555), train_loss = 0.76753029, grad/param norm = 1.5365e-01, time/batch = 16.3626s	
26305/33250 (epoch 39.556), train_loss = 0.78678978, grad/param norm = 2.1093e-01, time/batch = 15.6334s	
26306/33250 (epoch 39.558), train_loss = 0.81514313, grad/param norm = 1.7895e-01, time/batch = 14.8555s	
26307/33250 (epoch 39.559), train_loss = 0.71008006, grad/param norm = 1.6412e-01, time/batch = 14.7099s	
26308/33250 (epoch 39.561), train_loss = 0.65245071, grad/param norm = 1.5406e-01, time/batch = 14.8691s	
26309/33250 (epoch 39.562), train_loss = 0.76763075, grad/param norm = 1.9283e-01, time/batch = 14.9656s	
26310/33250 (epoch 39.564), train_loss = 0.93956874, grad/param norm = 2.1046e-01, time/batch = 15.2990s	
26311/33250 (epoch 39.565), train_loss = 0.87377886, grad/param norm = 2.1263e-01, time/batch = 14.7954s	
26312/33250 (epoch 39.567), train_loss = 0.89104282, grad/param norm = 1.9870e-01, time/batch = 15.5552s	
26313/33250 (epoch 39.568), train_loss = 0.73972214, grad/param norm = 2.0046e-01, time/batch = 16.3964s	
26314/33250 (epoch 39.570), train_loss = 0.84530572, grad/param norm = 1.8025e-01, time/batch = 15.0282s	
26315/33250 (epoch 39.571), train_loss = 0.86557337, grad/param norm = 1.7082e-01, time/batch = 15.6114s	
26316/33250 (epoch 39.573), train_loss = 0.84361893, grad/param norm = 1.9136e-01, time/batch = 15.1141s	
26317/33250 (epoch 39.574), train_loss = 0.70961087, grad/param norm = 1.4366e-01, time/batch = 15.0478s	
26318/33250 (epoch 39.576), train_loss = 0.79907836, grad/param norm = 1.6635e-01, time/batch = 14.7798s	
26319/33250 (epoch 39.577), train_loss = 0.76422947, grad/param norm = 1.6111e-01, time/batch = 14.7190s	
26320/33250 (epoch 39.579), train_loss = 0.66599925, grad/param norm = 1.7225e-01, time/batch = 14.7838s	
26321/33250 (epoch 39.580), train_loss = 0.77061748, grad/param norm = 1.5711e-01, time/batch = 15.3661s	
26322/33250 (epoch 39.582), train_loss = 0.72272098, grad/param norm = 1.6034e-01, time/batch = 14.2356s	
26323/33250 (epoch 39.583), train_loss = 0.84261771, grad/param norm = 1.8649e-01, time/batch = 14.3767s	
26324/33250 (epoch 39.585), train_loss = 0.86129949, grad/param norm = 1.6968e-01, time/batch = 15.2041s	
26325/33250 (epoch 39.586), train_loss = 0.74192109, grad/param norm = 1.9373e-01, time/batch = 17.2101s	
26326/33250 (epoch 39.588), train_loss = 0.81667573, grad/param norm = 1.5960e-01, time/batch = 15.9697s	
26327/33250 (epoch 39.589), train_loss = 0.77121816, grad/param norm = 1.7268e-01, time/batch = 16.4786s	
26328/33250 (epoch 39.591), train_loss = 0.76727657, grad/param norm = 2.1153e-01, time/batch = 15.0941s	
26329/33250 (epoch 39.592), train_loss = 0.74586342, grad/param norm = 1.8231e-01, time/batch = 15.6738s	
26330/33250 (epoch 39.594), train_loss = 0.87874879, grad/param norm = 1.9675e-01, time/batch = 14.7210s	
26331/33250 (epoch 39.595), train_loss = 0.77503084, grad/param norm = 1.5949e-01, time/batch = 15.0424s	
26332/33250 (epoch 39.597), train_loss = 0.64690438, grad/param norm = 1.5305e-01, time/batch = 15.2673s	
26333/33250 (epoch 39.598), train_loss = 0.74265790, grad/param norm = 1.9381e-01, time/batch = 15.1243s	
26334/33250 (epoch 39.600), train_loss = 0.74219628, grad/param norm = 2.1393e-01, time/batch = 16.1979s	
26335/33250 (epoch 39.602), train_loss = 0.81222685, grad/param norm = 2.1808e-01, time/batch = 17.5466s	
26336/33250 (epoch 39.603), train_loss = 0.81566874, grad/param norm = 1.7601e-01, time/batch = 16.4703s	
26337/33250 (epoch 39.605), train_loss = 0.76730732, grad/param norm = 1.6681e-01, time/batch = 15.7334s	
26338/33250 (epoch 39.606), train_loss = 0.82883631, grad/param norm = 1.7609e-01, time/batch = 15.3043s	
26339/33250 (epoch 39.608), train_loss = 0.78125863, grad/param norm = 1.7071e-01, time/batch = 14.9538s	
26340/33250 (epoch 39.609), train_loss = 0.66862656, grad/param norm = 1.7233e-01, time/batch = 15.1119s	
26341/33250 (epoch 39.611), train_loss = 0.74704208, grad/param norm = 1.9496e-01, time/batch = 15.0525s	
26342/33250 (epoch 39.612), train_loss = 0.76102483, grad/param norm = 1.8742e-01, time/batch = 14.8076s	
26343/33250 (epoch 39.614), train_loss = 0.95706203, grad/param norm = 2.0667e-01, time/batch = 14.9459s	
26344/33250 (epoch 39.615), train_loss = 0.88888032, grad/param norm = 1.9029e-01, time/batch = 15.1002s	
26345/33250 (epoch 39.617), train_loss = 0.97026092, grad/param norm = 2.1750e-01, time/batch = 15.4141s	
26346/33250 (epoch 39.618), train_loss = 0.98500617, grad/param norm = 2.5411e-01, time/batch = 15.5323s	
26347/33250 (epoch 39.620), train_loss = 0.84346937, grad/param norm = 1.9357e-01, time/batch = 14.8868s	
26348/33250 (epoch 39.621), train_loss = 0.83484950, grad/param norm = 1.7263e-01, time/batch = 15.6224s	
26349/33250 (epoch 39.623), train_loss = 0.74098016, grad/param norm = 2.1034e-01, time/batch = 14.9766s	
26350/33250 (epoch 39.624), train_loss = 0.76051167, grad/param norm = 1.8947e-01, time/batch = 15.1312s	
26351/33250 (epoch 39.626), train_loss = 0.75687925, grad/param norm = 2.3140e-01, time/batch = 15.5632s	
26352/33250 (epoch 39.627), train_loss = 0.74285503, grad/param norm = 1.7591e-01, time/batch = 15.0374s	
26353/33250 (epoch 39.629), train_loss = 0.82318319, grad/param norm = 2.1287e-01, time/batch = 14.7811s	
26354/33250 (epoch 39.630), train_loss = 0.74996335, grad/param norm = 2.0280e-01, time/batch = 14.7987s	
26355/33250 (epoch 39.632), train_loss = 0.68128954, grad/param norm = 1.7257e-01, time/batch = 15.1057s	
26356/33250 (epoch 39.633), train_loss = 0.79595067, grad/param norm = 1.7557e-01, time/batch = 14.8836s	
26357/33250 (epoch 39.635), train_loss = 0.71151142, grad/param norm = 1.6954e-01, time/batch = 15.9842s	
26358/33250 (epoch 39.636), train_loss = 0.72526651, grad/param norm = 1.5608e-01, time/batch = 15.1005s	
26359/33250 (epoch 39.638), train_loss = 0.69524640, grad/param norm = 2.0034e-01, time/batch = 16.6121s	
26360/33250 (epoch 39.639), train_loss = 0.66556663, grad/param norm = 1.8348e-01, time/batch = 15.4436s	
26361/33250 (epoch 39.641), train_loss = 0.76200673, grad/param norm = 1.6916e-01, time/batch = 15.1328s	
26362/33250 (epoch 39.642), train_loss = 0.57909770, grad/param norm = 1.9160e-01, time/batch = 15.0561s	
26363/33250 (epoch 39.644), train_loss = 0.54100887, grad/param norm = 1.4246e-01, time/batch = 29.0152s	
26364/33250 (epoch 39.645), train_loss = 0.80962548, grad/param norm = 2.1849e-01, time/batch = 14.7942s	
26365/33250 (epoch 39.647), train_loss = 0.65679791, grad/param norm = 2.1225e-01, time/batch = 15.3644s	
26366/33250 (epoch 39.648), train_loss = 0.65455657, grad/param norm = 1.7030e-01, time/batch = 15.1186s	
26367/33250 (epoch 39.650), train_loss = 0.90146190, grad/param norm = 2.0413e-01, time/batch = 18.2147s	
26368/33250 (epoch 39.651), train_loss = 0.79587207, grad/param norm = 1.7408e-01, time/batch = 17.3029s	
26369/33250 (epoch 39.653), train_loss = 0.74331773, grad/param norm = 1.7623e-01, time/batch = 16.8359s	
26370/33250 (epoch 39.654), train_loss = 0.76610851, grad/param norm = 1.6133e-01, time/batch = 15.9140s	
26371/33250 (epoch 39.656), train_loss = 0.81998660, grad/param norm = 1.6298e-01, time/batch = 15.0295s	
26372/33250 (epoch 39.657), train_loss = 0.63660102, grad/param norm = 2.7092e-01, time/batch = 15.1988s	
26373/33250 (epoch 39.659), train_loss = 0.74170789, grad/param norm = 1.8038e-01, time/batch = 15.1659s	
26374/33250 (epoch 39.660), train_loss = 0.79222234, grad/param norm = 1.8781e-01, time/batch = 14.7738s	
26375/33250 (epoch 39.662), train_loss = 0.78402233, grad/param norm = 1.6214e-01, time/batch = 15.4905s	
26376/33250 (epoch 39.663), train_loss = 0.70739843, grad/param norm = 1.7816e-01, time/batch = 14.9538s	
26377/33250 (epoch 39.665), train_loss = 0.81503274, grad/param norm = 1.8948e-01, time/batch = 15.2814s	
26378/33250 (epoch 39.666), train_loss = 0.74814118, grad/param norm = 1.6729e-01, time/batch = 15.0456s	
26379/33250 (epoch 39.668), train_loss = 0.86619347, grad/param norm = 1.9385e-01, time/batch = 15.0427s	
26380/33250 (epoch 39.669), train_loss = 0.79380305, grad/param norm = 1.9021e-01, time/batch = 15.3689s	
26381/33250 (epoch 39.671), train_loss = 0.66840689, grad/param norm = 1.6413e-01, time/batch = 15.5133s	
26382/33250 (epoch 39.672), train_loss = 0.85197711, grad/param norm = 1.8522e-01, time/batch = 15.7156s	
26383/33250 (epoch 39.674), train_loss = 0.70603025, grad/param norm = 1.7611e-01, time/batch = 14.6188s	
26384/33250 (epoch 39.675), train_loss = 0.78033112, grad/param norm = 1.5376e-01, time/batch = 14.6253s	
26385/33250 (epoch 39.677), train_loss = 0.83354991, grad/param norm = 1.8451e-01, time/batch = 15.2522s	
26386/33250 (epoch 39.678), train_loss = 0.71848778, grad/param norm = 1.9107e-01, time/batch = 14.5082s	
26387/33250 (epoch 39.680), train_loss = 0.88086783, grad/param norm = 2.1132e-01, time/batch = 14.7729s	
26388/33250 (epoch 39.681), train_loss = 0.71122936, grad/param norm = 1.6852e-01, time/batch = 14.7144s	
26389/33250 (epoch 39.683), train_loss = 0.71336396, grad/param norm = 1.7319e-01, time/batch = 15.3496s	
26390/33250 (epoch 39.684), train_loss = 0.66651328, grad/param norm = 1.8112e-01, time/batch = 15.0987s	
26391/33250 (epoch 39.686), train_loss = 0.67921830, grad/param norm = 1.6551e-01, time/batch = 15.0300s	
26392/33250 (epoch 39.687), train_loss = 0.79013526, grad/param norm = 1.8276e-01, time/batch = 14.9438s	
26393/33250 (epoch 39.689), train_loss = 0.67441337, grad/param norm = 2.0905e-01, time/batch = 15.1658s	
26394/33250 (epoch 39.690), train_loss = 0.80367790, grad/param norm = 2.0024e-01, time/batch = 15.0163s	
26395/33250 (epoch 39.692), train_loss = 0.74763070, grad/param norm = 1.6214e-01, time/batch = 14.5067s	
26396/33250 (epoch 39.693), train_loss = 0.83153174, grad/param norm = 2.0248e-01, time/batch = 14.3777s	
26397/33250 (epoch 39.695), train_loss = 0.80633384, grad/param norm = 1.9287e-01, time/batch = 15.0810s	
26398/33250 (epoch 39.696), train_loss = 0.82184113, grad/param norm = 1.8051e-01, time/batch = 14.7819s	
26399/33250 (epoch 39.698), train_loss = 0.74300295, grad/param norm = 1.8375e-01, time/batch = 14.6321s	
26400/33250 (epoch 39.699), train_loss = 0.97155460, grad/param norm = 1.8211e-01, time/batch = 14.7341s	
26401/33250 (epoch 39.701), train_loss = 0.77653986, grad/param norm = 1.5164e-01, time/batch = 14.9585s	
26402/33250 (epoch 39.702), train_loss = 0.73818763, grad/param norm = 2.0450e-01, time/batch = 14.2426s	
26403/33250 (epoch 39.704), train_loss = 0.95206906, grad/param norm = 2.3437e-01, time/batch = 14.7992s	
26404/33250 (epoch 39.705), train_loss = 0.72121446, grad/param norm = 1.6528e-01, time/batch = 14.6341s	
26405/33250 (epoch 39.707), train_loss = 0.64987942, grad/param norm = 1.5657e-01, time/batch = 15.2695s	
26406/33250 (epoch 39.708), train_loss = 0.85581605, grad/param norm = 2.0363e-01, time/batch = 14.7042s	
26407/33250 (epoch 39.710), train_loss = 0.78834653, grad/param norm = 1.9000e-01, time/batch = 14.4449s	
26408/33250 (epoch 39.711), train_loss = 0.67399277, grad/param norm = 1.6264e-01, time/batch = 14.4671s	
26409/33250 (epoch 39.713), train_loss = 0.79215298, grad/param norm = 1.6971e-01, time/batch = 15.5577s	
26410/33250 (epoch 39.714), train_loss = 0.74990079, grad/param norm = 1.7173e-01, time/batch = 14.8618s	
26411/33250 (epoch 39.716), train_loss = 0.79617745, grad/param norm = 1.7519e-01, time/batch = 15.1225s	
26412/33250 (epoch 39.717), train_loss = 0.72429638, grad/param norm = 1.3724e-01, time/batch = 14.5558s	
26413/33250 (epoch 39.719), train_loss = 0.70643073, grad/param norm = 1.6909e-01, time/batch = 14.9569s	
26414/33250 (epoch 39.720), train_loss = 0.98550380, grad/param norm = 1.7817e-01, time/batch = 14.6465s	
26415/33250 (epoch 39.722), train_loss = 0.66957705, grad/param norm = 1.6095e-01, time/batch = 14.7909s	
26416/33250 (epoch 39.723), train_loss = 0.59675839, grad/param norm = 1.2374e-01, time/batch = 14.8687s	
26417/33250 (epoch 39.725), train_loss = 0.74048404, grad/param norm = 1.4373e-01, time/batch = 14.9506s	
26418/33250 (epoch 39.726), train_loss = 0.77869008, grad/param norm = 1.7191e-01, time/batch = 15.1819s	
26419/33250 (epoch 39.728), train_loss = 0.81294026, grad/param norm = 1.9318e-01, time/batch = 14.7101s	
26420/33250 (epoch 39.729), train_loss = 0.84856410, grad/param norm = 1.8427e-01, time/batch = 15.0216s	
26421/33250 (epoch 39.731), train_loss = 0.69144749, grad/param norm = 1.8899e-01, time/batch = 16.2094s	
26422/33250 (epoch 39.732), train_loss = 0.71455837, grad/param norm = 1.6905e-01, time/batch = 15.4226s	
26423/33250 (epoch 39.734), train_loss = 0.81553139, grad/param norm = 2.1157e-01, time/batch = 15.1312s	
26424/33250 (epoch 39.735), train_loss = 0.79495562, grad/param norm = 1.9418e-01, time/batch = 15.1305s	
26425/33250 (epoch 39.737), train_loss = 0.75000399, grad/param norm = 1.5441e-01, time/batch = 15.1721s	
26426/33250 (epoch 39.738), train_loss = 0.80736663, grad/param norm = 1.7354e-01, time/batch = 15.1762s	
26427/33250 (epoch 39.740), train_loss = 0.79030684, grad/param norm = 1.9350e-01, time/batch = 14.9319s	
26428/33250 (epoch 39.741), train_loss = 0.81201250, grad/param norm = 1.5789e-01, time/batch = 14.8460s	
26429/33250 (epoch 39.743), train_loss = 0.73594893, grad/param norm = 1.8181e-01, time/batch = 15.8927s	
26430/33250 (epoch 39.744), train_loss = 0.72395318, grad/param norm = 1.7841e-01, time/batch = 15.1015s	
26431/33250 (epoch 39.746), train_loss = 0.67891622, grad/param norm = 1.3554e-01, time/batch = 15.1988s	
26432/33250 (epoch 39.747), train_loss = 0.69796862, grad/param norm = 1.6468e-01, time/batch = 15.0350s	
26433/33250 (epoch 39.749), train_loss = 0.86381825, grad/param norm = 1.7807e-01, time/batch = 15.4141s	
26434/33250 (epoch 39.750), train_loss = 0.87154343, grad/param norm = 1.8475e-01, time/batch = 15.0439s	
26435/33250 (epoch 39.752), train_loss = 0.72397594, grad/param norm = 1.5826e-01, time/batch = 14.7165s	
26436/33250 (epoch 39.753), train_loss = 0.72195469, grad/param norm = 1.7914e-01, time/batch = 14.7809s	
26437/33250 (epoch 39.755), train_loss = 0.67190820, grad/param norm = 1.8201e-01, time/batch = 15.1965s	
26438/33250 (epoch 39.756), train_loss = 0.77419912, grad/param norm = 1.8622e-01, time/batch = 15.0124s	
26439/33250 (epoch 39.758), train_loss = 0.92583756, grad/param norm = 1.7753e-01, time/batch = 14.7809s	
26440/33250 (epoch 39.759), train_loss = 0.73429280, grad/param norm = 1.6471e-01, time/batch = 14.6997s	
26441/33250 (epoch 39.761), train_loss = 0.82827216, grad/param norm = 2.2586e-01, time/batch = 15.6588s	
26442/33250 (epoch 39.762), train_loss = 0.82908035, grad/param norm = 1.7722e-01, time/batch = 14.7791s	
26443/33250 (epoch 39.764), train_loss = 0.66470030, grad/param norm = 2.3471e-01, time/batch = 15.0997s	
26444/33250 (epoch 39.765), train_loss = 0.81123448, grad/param norm = 1.8730e-01, time/batch = 14.7782s	
26445/33250 (epoch 39.767), train_loss = 0.62577003, grad/param norm = 1.7951e-01, time/batch = 14.9415s	
26446/33250 (epoch 39.768), train_loss = 0.67037865, grad/param norm = 1.8416e-01, time/batch = 14.9426s	
26447/33250 (epoch 39.770), train_loss = 0.79473973, grad/param norm = 1.8879e-01, time/batch = 14.7940s	
26448/33250 (epoch 39.771), train_loss = 0.84347524, grad/param norm = 2.1656e-01, time/batch = 14.7076s	
26449/33250 (epoch 39.773), train_loss = 0.77041798, grad/param norm = 1.9743e-01, time/batch = 15.4662s	
26450/33250 (epoch 39.774), train_loss = 0.66712853, grad/param norm = 1.8726e-01, time/batch = 14.8180s	
26451/33250 (epoch 39.776), train_loss = 0.73476429, grad/param norm = 1.7859e-01, time/batch = 15.0832s	
26452/33250 (epoch 39.777), train_loss = 0.87035465, grad/param norm = 2.0430e-01, time/batch = 14.6103s	
26453/33250 (epoch 39.779), train_loss = 0.75639711, grad/param norm = 2.0177e-01, time/batch = 15.0294s	
26454/33250 (epoch 39.780), train_loss = 0.87479495, grad/param norm = 1.9793e-01, time/batch = 15.1086s	
26455/33250 (epoch 39.782), train_loss = 0.78858831, grad/param norm = 2.5171e-01, time/batch = 15.2498s	
26456/33250 (epoch 39.783), train_loss = 0.63466425, grad/param norm = 1.7990e-01, time/batch = 15.2722s	
26457/33250 (epoch 39.785), train_loss = 0.68514011, grad/param norm = 1.7566e-01, time/batch = 15.5853s	
26458/33250 (epoch 39.786), train_loss = 0.86066360, grad/param norm = 2.2817e-01, time/batch = 15.1340s	
26459/33250 (epoch 39.788), train_loss = 0.87260932, grad/param norm = 1.9158e-01, time/batch = 14.8921s	
26460/33250 (epoch 39.789), train_loss = 0.87929610, grad/param norm = 2.3241e-01, time/batch = 15.3472s	
26461/33250 (epoch 39.791), train_loss = 0.89238086, grad/param norm = 1.9363e-01, time/batch = 15.1023s	
26462/33250 (epoch 39.792), train_loss = 0.95262835, grad/param norm = 1.8597e-01, time/batch = 15.1159s	
26463/33250 (epoch 39.794), train_loss = 0.75311870, grad/param norm = 1.7628e-01, time/batch = 15.0275s	
26464/33250 (epoch 39.795), train_loss = 0.75697865, grad/param norm = 1.9111e-01, time/batch = 15.0359s	
26465/33250 (epoch 39.797), train_loss = 0.82610915, grad/param norm = 1.7537e-01, time/batch = 14.7094s	
26466/33250 (epoch 39.798), train_loss = 0.75155165, grad/param norm = 2.0319e-01, time/batch = 14.7950s	
26467/33250 (epoch 39.800), train_loss = 0.80555655, grad/param norm = 2.0285e-01, time/batch = 14.9709s	
26468/33250 (epoch 39.802), train_loss = 0.77905808, grad/param norm = 1.7054e-01, time/batch = 15.3871s	
26469/33250 (epoch 39.803), train_loss = 0.81983723, grad/param norm = 1.6586e-01, time/batch = 15.2872s	
26470/33250 (epoch 39.805), train_loss = 0.81110492, grad/param norm = 1.7727e-01, time/batch = 15.3377s	
26471/33250 (epoch 39.806), train_loss = 0.78632015, grad/param norm = 1.7316e-01, time/batch = 14.5748s	
26472/33250 (epoch 39.808), train_loss = 0.72182093, grad/param norm = 1.7777e-01, time/batch = 15.1871s	
26473/33250 (epoch 39.809), train_loss = 0.69090000, grad/param norm = 1.4310e-01, time/batch = 15.1872s	
26474/33250 (epoch 39.811), train_loss = 0.68486323, grad/param norm = 1.6667e-01, time/batch = 15.0325s	
26475/33250 (epoch 39.812), train_loss = 0.80679211, grad/param norm = 2.0060e-01, time/batch = 14.8002s	
26476/33250 (epoch 39.814), train_loss = 0.74663446, grad/param norm = 2.0713e-01, time/batch = 15.4214s	
26477/33250 (epoch 39.815), train_loss = 0.81336502, grad/param norm = 1.7535e-01, time/batch = 15.5643s	
26478/33250 (epoch 39.817), train_loss = 0.75968226, grad/param norm = 1.7784e-01, time/batch = 15.4216s	
26479/33250 (epoch 39.818), train_loss = 0.70550502, grad/param norm = 1.5727e-01, time/batch = 15.3753s	
26480/33250 (epoch 39.820), train_loss = 0.80711796, grad/param norm = 1.8773e-01, time/batch = 15.1907s	
26481/33250 (epoch 39.821), train_loss = 0.77065174, grad/param norm = 1.6009e-01, time/batch = 16.3818s	
26482/33250 (epoch 39.823), train_loss = 1.03822445, grad/param norm = 2.1331e-01, time/batch = 15.1855s	
26483/33250 (epoch 39.824), train_loss = 0.72621769, grad/param norm = 2.2910e-01, time/batch = 14.8704s	
26484/33250 (epoch 39.826), train_loss = 0.80723865, grad/param norm = 2.0264e-01, time/batch = 15.1582s	
26485/33250 (epoch 39.827), train_loss = 0.70096435, grad/param norm = 1.7615e-01, time/batch = 15.2646s	
26486/33250 (epoch 39.829), train_loss = 0.79776379, grad/param norm = 1.7537e-01, time/batch = 15.4907s	
26487/33250 (epoch 39.830), train_loss = 0.83650236, grad/param norm = 2.8695e-01, time/batch = 15.4318s	
26488/33250 (epoch 39.832), train_loss = 0.80168860, grad/param norm = 1.8439e-01, time/batch = 15.4997s	
26489/33250 (epoch 39.833), train_loss = 0.77180209, grad/param norm = 1.9265e-01, time/batch = 15.4801s	
26490/33250 (epoch 39.835), train_loss = 0.69978964, grad/param norm = 2.2634e-01, time/batch = 15.5785s	
26491/33250 (epoch 39.836), train_loss = 0.76777006, grad/param norm = 1.8509e-01, time/batch = 17.8686s	
26492/33250 (epoch 39.838), train_loss = 0.81307687, grad/param norm = 1.9012e-01, time/batch = 16.2209s	
26493/33250 (epoch 39.839), train_loss = 0.72018878, grad/param norm = 1.5618e-01, time/batch = 15.9426s	
26494/33250 (epoch 39.841), train_loss = 0.74012907, grad/param norm = 1.7151e-01, time/batch = 16.1159s	
26495/33250 (epoch 39.842), train_loss = 0.89923845, grad/param norm = 1.9708e-01, time/batch = 15.3463s	
26496/33250 (epoch 39.844), train_loss = 0.85366766, grad/param norm = 1.9523e-01, time/batch = 15.6545s	
26497/33250 (epoch 39.845), train_loss = 0.94747080, grad/param norm = 2.2691e-01, time/batch = 15.8864s	
26498/33250 (epoch 39.847), train_loss = 0.89133491, grad/param norm = 1.7687e-01, time/batch = 15.4155s	
26499/33250 (epoch 39.848), train_loss = 0.94433175, grad/param norm = 1.9766e-01, time/batch = 15.4871s	
26500/33250 (epoch 39.850), train_loss = 0.86327421, grad/param norm = 1.9191e-01, time/batch = 15.3414s	
26501/33250 (epoch 39.851), train_loss = 0.66834896, grad/param norm = 1.7772e-01, time/batch = 15.4931s	
26502/33250 (epoch 39.853), train_loss = 0.78782605, grad/param norm = 1.9667e-01, time/batch = 15.5335s	
26503/33250 (epoch 39.854), train_loss = 0.74312698, grad/param norm = 1.6045e-01, time/batch = 15.7439s	
26504/33250 (epoch 39.856), train_loss = 0.75547337, grad/param norm = 2.2048e-01, time/batch = 15.6522s	
26505/33250 (epoch 39.857), train_loss = 0.68724807, grad/param norm = 1.9367e-01, time/batch = 15.0437s	
26506/33250 (epoch 39.859), train_loss = 0.75213624, grad/param norm = 2.1019e-01, time/batch = 15.6918s	
26507/33250 (epoch 39.860), train_loss = 0.81323347, grad/param norm = 1.8643e-01, time/batch = 15.6700s	
26508/33250 (epoch 39.862), train_loss = 0.70091898, grad/param norm = 1.6949e-01, time/batch = 15.5810s	
26509/33250 (epoch 39.863), train_loss = 0.75758894, grad/param norm = 2.1045e-01, time/batch = 14.9343s	
26510/33250 (epoch 39.865), train_loss = 0.78986042, grad/param norm = 1.9104e-01, time/batch = 15.3582s	
26511/33250 (epoch 39.866), train_loss = 0.68335074, grad/param norm = 1.6803e-01, time/batch = 15.3284s	
26512/33250 (epoch 39.868), train_loss = 0.77181200, grad/param norm = 2.1416e-01, time/batch = 14.8853s	
26513/33250 (epoch 39.869), train_loss = 0.80209617, grad/param norm = 1.7970e-01, time/batch = 15.2935s	
26514/33250 (epoch 39.871), train_loss = 0.63087294, grad/param norm = 1.5134e-01, time/batch = 15.2946s	
26515/33250 (epoch 39.872), train_loss = 0.81858353, grad/param norm = 2.4635e-01, time/batch = 15.7658s	
26516/33250 (epoch 39.874), train_loss = 0.71606209, grad/param norm = 1.7026e-01, time/batch = 22.3357s	
26517/33250 (epoch 39.875), train_loss = 0.67223271, grad/param norm = 2.1030e-01, time/batch = 15.0859s	
26518/33250 (epoch 39.877), train_loss = 0.87278910, grad/param norm = 1.9334e-01, time/batch = 15.3279s	
26519/33250 (epoch 39.878), train_loss = 0.79317100, grad/param norm = 1.6379e-01, time/batch = 15.6387s	
26520/33250 (epoch 39.880), train_loss = 0.77538968, grad/param norm = 1.9856e-01, time/batch = 14.6973s	
26521/33250 (epoch 39.881), train_loss = 0.89081771, grad/param norm = 1.7298e-01, time/batch = 15.2985s	
26522/33250 (epoch 39.883), train_loss = 0.81619684, grad/param norm = 1.8257e-01, time/batch = 15.5177s	
26523/33250 (epoch 39.884), train_loss = 0.88389990, grad/param norm = 2.1540e-01, time/batch = 19.3327s	
26524/33250 (epoch 39.886), train_loss = 0.71835238, grad/param norm = 1.6133e-01, time/batch = 14.8518s	
26525/33250 (epoch 39.887), train_loss = 0.73280251, grad/param norm = 1.9231e-01, time/batch = 14.7729s	
26526/33250 (epoch 39.889), train_loss = 0.73934756, grad/param norm = 1.6165e-01, time/batch = 15.4064s	
26527/33250 (epoch 39.890), train_loss = 0.59421648, grad/param norm = 1.3135e-01, time/batch = 14.8461s	
26528/33250 (epoch 39.892), train_loss = 0.80628101, grad/param norm = 1.7301e-01, time/batch = 14.9414s	
26529/33250 (epoch 39.893), train_loss = 0.84022741, grad/param norm = 1.9356e-01, time/batch = 14.7722s	
26530/33250 (epoch 39.895), train_loss = 0.72293589, grad/param norm = 1.7464e-01, time/batch = 15.1830s	
26531/33250 (epoch 39.896), train_loss = 0.81879530, grad/param norm = 1.7913e-01, time/batch = 15.7758s	
26532/33250 (epoch 39.898), train_loss = 0.76443283, grad/param norm = 1.5669e-01, time/batch = 16.3368s	
26533/33250 (epoch 39.899), train_loss = 0.72745250, grad/param norm = 1.5628e-01, time/batch = 17.0587s	
26534/33250 (epoch 39.901), train_loss = 0.63856742, grad/param norm = 1.5154e-01, time/batch = 17.2546s	
26535/33250 (epoch 39.902), train_loss = 0.73406134, grad/param norm = 1.9035e-01, time/batch = 14.5198s	
26536/33250 (epoch 39.904), train_loss = 0.68078336, grad/param norm = 1.6944e-01, time/batch = 14.5980s	
26537/33250 (epoch 39.905), train_loss = 0.74968874, grad/param norm = 1.4717e-01, time/batch = 14.9311s	
26538/33250 (epoch 39.907), train_loss = 0.71632522, grad/param norm = 1.9822e-01, time/batch = 15.1520s	
26539/33250 (epoch 39.908), train_loss = 0.76178025, grad/param norm = 1.7477e-01, time/batch = 14.9385s	
26540/33250 (epoch 39.910), train_loss = 0.84508964, grad/param norm = 2.0363e-01, time/batch = 15.0292s	
26541/33250 (epoch 39.911), train_loss = 0.70268356, grad/param norm = 1.7555e-01, time/batch = 15.4130s	
26542/33250 (epoch 39.913), train_loss = 0.73442853, grad/param norm = 1.6346e-01, time/batch = 14.8517s	
26543/33250 (epoch 39.914), train_loss = 0.65243788, grad/param norm = 1.7882e-01, time/batch = 14.6782s	
26544/33250 (epoch 39.916), train_loss = 0.68803060, grad/param norm = 1.7378e-01, time/batch = 15.3680s	
26545/33250 (epoch 39.917), train_loss = 0.77732291, grad/param norm = 1.4753e-01, time/batch = 15.7570s	
26546/33250 (epoch 39.919), train_loss = 0.70541985, grad/param norm = 1.9085e-01, time/batch = 16.1716s	
26547/33250 (epoch 39.920), train_loss = 0.77553396, grad/param norm = 2.0322e-01, time/batch = 14.6862s	
26548/33250 (epoch 39.922), train_loss = 0.78218983, grad/param norm = 2.2201e-01, time/batch = 14.6076s	
26549/33250 (epoch 39.923), train_loss = 0.75285255, grad/param norm = 1.8608e-01, time/batch = 15.0103s	
26550/33250 (epoch 39.925), train_loss = 0.73592468, grad/param norm = 1.6807e-01, time/batch = 15.9222s	
26551/33250 (epoch 39.926), train_loss = 0.72301778, grad/param norm = 1.5409e-01, time/batch = 15.0038s	
26552/33250 (epoch 39.928), train_loss = 0.73784811, grad/param norm = 1.6853e-01, time/batch = 14.6090s	
26553/33250 (epoch 39.929), train_loss = 0.66022238, grad/param norm = 1.4683e-01, time/batch = 15.4784s	
26554/33250 (epoch 39.931), train_loss = 0.87266426, grad/param norm = 2.0096e-01, time/batch = 15.2988s	
26555/33250 (epoch 39.932), train_loss = 0.70271839, grad/param norm = 1.7704e-01, time/batch = 14.8607s	
26556/33250 (epoch 39.934), train_loss = 0.70372490, grad/param norm = 1.5158e-01, time/batch = 14.7035s	
26557/33250 (epoch 39.935), train_loss = 0.73427503, grad/param norm = 1.7104e-01, time/batch = 15.2571s	
26558/33250 (epoch 39.937), train_loss = 0.70085821, grad/param norm = 1.8020e-01, time/batch = 15.0931s	
26559/33250 (epoch 39.938), train_loss = 0.74167003, grad/param norm = 1.9999e-01, time/batch = 14.6225s	
26560/33250 (epoch 39.940), train_loss = 0.74420045, grad/param norm = 1.7555e-01, time/batch = 14.9885s	
26561/33250 (epoch 39.941), train_loss = 0.79722022, grad/param norm = 1.6497e-01, time/batch = 14.6975s	
26562/33250 (epoch 39.943), train_loss = 0.88552047, grad/param norm = 1.7671e-01, time/batch = 14.3128s	
26563/33250 (epoch 39.944), train_loss = 0.72987166, grad/param norm = 1.5721e-01, time/batch = 14.5445s	
26564/33250 (epoch 39.946), train_loss = 0.83199301, grad/param norm = 1.6875e-01, time/batch = 15.3060s	
26565/33250 (epoch 39.947), train_loss = 0.69701073, grad/param norm = 2.0077e-01, time/batch = 15.4205s	
26566/33250 (epoch 39.949), train_loss = 0.82791382, grad/param norm = 2.1743e-01, time/batch = 15.1465s	
26567/33250 (epoch 39.950), train_loss = 0.83454151, grad/param norm = 1.8030e-01, time/batch = 14.7422s	
26568/33250 (epoch 39.952), train_loss = 0.76883365, grad/param norm = 2.0450e-01, time/batch = 15.0687s	
26569/33250 (epoch 39.953), train_loss = 0.78041134, grad/param norm = 1.8801e-01, time/batch = 14.9521s	
26570/33250 (epoch 39.955), train_loss = 0.85254131, grad/param norm = 2.0211e-01, time/batch = 14.8774s	
26571/33250 (epoch 39.956), train_loss = 0.78108475, grad/param norm = 2.0863e-01, time/batch = 14.8651s	
26572/33250 (epoch 39.958), train_loss = 0.73433001, grad/param norm = 1.7622e-01, time/batch = 14.8581s	
26573/33250 (epoch 39.959), train_loss = 0.72627869, grad/param norm = 1.6777e-01, time/batch = 15.0269s	
26574/33250 (epoch 39.961), train_loss = 0.94206447, grad/param norm = 1.9500e-01, time/batch = 15.9385s	
26575/33250 (epoch 39.962), train_loss = 0.74205884, grad/param norm = 1.8527e-01, time/batch = 15.1450s	
26576/33250 (epoch 39.964), train_loss = 0.87257256, grad/param norm = 1.8369e-01, time/batch = 17.2839s	
26577/33250 (epoch 39.965), train_loss = 0.83139187, grad/param norm = 1.9534e-01, time/batch = 15.8058s	
26578/33250 (epoch 39.967), train_loss = 0.76817151, grad/param norm = 2.0149e-01, time/batch = 15.1219s	
26579/33250 (epoch 39.968), train_loss = 0.89105462, grad/param norm = 1.8150e-01, time/batch = 15.1902s	
26580/33250 (epoch 39.970), train_loss = 0.99114180, grad/param norm = 2.6600e-01, time/batch = 15.0349s	
26581/33250 (epoch 39.971), train_loss = 0.92627202, grad/param norm = 2.1071e-01, time/batch = 15.3558s	
26582/33250 (epoch 39.973), train_loss = 0.75386380, grad/param norm = 1.6784e-01, time/batch = 14.8673s	
26583/33250 (epoch 39.974), train_loss = 0.83181148, grad/param norm = 1.8251e-01, time/batch = 15.0755s	
26584/33250 (epoch 39.976), train_loss = 0.74258850, grad/param norm = 1.7525e-01, time/batch = 14.7085s	
26585/33250 (epoch 39.977), train_loss = 0.75048704, grad/param norm = 1.7519e-01, time/batch = 15.0408s	
26586/33250 (epoch 39.979), train_loss = 0.83801952, grad/param norm = 1.9837e-01, time/batch = 15.3516s	
26587/33250 (epoch 39.980), train_loss = 0.81022958, grad/param norm = 1.7394e-01, time/batch = 16.7302s	
26588/33250 (epoch 39.982), train_loss = 0.74126808, grad/param norm = 1.4997e-01, time/batch = 15.4736s	
26589/33250 (epoch 39.983), train_loss = 0.82449497, grad/param norm = 2.2326e-01, time/batch = 15.2914s	
26590/33250 (epoch 39.985), train_loss = 0.73627948, grad/param norm = 1.9917e-01, time/batch = 14.8702s	
26591/33250 (epoch 39.986), train_loss = 0.83491148, grad/param norm = 1.7233e-01, time/batch = 14.8775s	
26592/33250 (epoch 39.988), train_loss = 0.88237767, grad/param norm = 1.9449e-01, time/batch = 15.5309s	
26593/33250 (epoch 39.989), train_loss = 0.84915198, grad/param norm = 1.7819e-01, time/batch = 14.7072s	
26594/33250 (epoch 39.991), train_loss = 0.84955121, grad/param norm = 1.9477e-01, time/batch = 14.7054s	
26595/33250 (epoch 39.992), train_loss = 0.77932006, grad/param norm = 1.8403e-01, time/batch = 15.1273s	
26596/33250 (epoch 39.994), train_loss = 0.71813740, grad/param norm = 1.5932e-01, time/batch = 19.2842s	
26597/33250 (epoch 39.995), train_loss = 0.77814763, grad/param norm = 2.2792e-01, time/batch = 25.4762s	
26598/33250 (epoch 39.997), train_loss = 0.57688858, grad/param norm = 1.5257e-01, time/batch = 16.4800s	
26599/33250 (epoch 39.998), train_loss = 0.82299688, grad/param norm = 1.7954e-01, time/batch = 16.3697s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
26600/33250 (epoch 40.000), train_loss = 0.82332634, grad/param norm = 1.8551e-01, time/batch = 15.2011s	
26601/33250 (epoch 40.002), train_loss = 0.98704610, grad/param norm = 1.9411e-01, time/batch = 15.7940s	
26602/33250 (epoch 40.003), train_loss = 0.84811589, grad/param norm = 2.2029e-01, time/batch = 15.5812s	
26603/33250 (epoch 40.005), train_loss = 0.64149925, grad/param norm = 1.5424e-01, time/batch = 16.0690s	
26604/33250 (epoch 40.006), train_loss = 0.67233017, grad/param norm = 1.6960e-01, time/batch = 15.6457s	
26605/33250 (epoch 40.008), train_loss = 0.86650729, grad/param norm = 1.9457e-01, time/batch = 15.6006s	
26606/33250 (epoch 40.009), train_loss = 0.94396640, grad/param norm = 1.7726e-01, time/batch = 15.5981s	
26607/33250 (epoch 40.011), train_loss = 0.74692001, grad/param norm = 1.7521e-01, time/batch = 15.1231s	
26608/33250 (epoch 40.012), train_loss = 0.76762960, grad/param norm = 2.1295e-01, time/batch = 15.3665s	
26609/33250 (epoch 40.014), train_loss = 0.85825247, grad/param norm = 2.1527e-01, time/batch = 15.1918s	
26610/33250 (epoch 40.015), train_loss = 0.80078052, grad/param norm = 1.8547e-01, time/batch = 15.2121s	
26611/33250 (epoch 40.017), train_loss = 0.79747268, grad/param norm = 1.9265e-01, time/batch = 15.8518s	
26612/33250 (epoch 40.018), train_loss = 0.63347954, grad/param norm = 1.6510e-01, time/batch = 15.4527s	
26613/33250 (epoch 40.020), train_loss = 0.79763555, grad/param norm = 1.7715e-01, time/batch = 15.0238s	
26614/33250 (epoch 40.021), train_loss = 0.79894155, grad/param norm = 1.7297e-01, time/batch = 15.6175s	
26615/33250 (epoch 40.023), train_loss = 0.64871862, grad/param norm = 1.8060e-01, time/batch = 15.1881s	
26616/33250 (epoch 40.024), train_loss = 0.87512583, grad/param norm = 2.4614e-01, time/batch = 15.1083s	
26617/33250 (epoch 40.026), train_loss = 0.82015491, grad/param norm = 1.7512e-01, time/batch = 15.4419s	
26618/33250 (epoch 40.027), train_loss = 0.81805987, grad/param norm = 1.7124e-01, time/batch = 15.3895s	
26619/33250 (epoch 40.029), train_loss = 0.75492753, grad/param norm = 1.9133e-01, time/batch = 16.0476s	
26620/33250 (epoch 40.030), train_loss = 0.75244633, grad/param norm = 1.6806e-01, time/batch = 15.2035s	
26621/33250 (epoch 40.032), train_loss = 0.95861433, grad/param norm = 1.8789e-01, time/batch = 14.7736s	
26622/33250 (epoch 40.033), train_loss = 0.75084141, grad/param norm = 2.0267e-01, time/batch = 14.6998s	
26623/33250 (epoch 40.035), train_loss = 0.80227687, grad/param norm = 1.9456e-01, time/batch = 14.9344s	
26624/33250 (epoch 40.036), train_loss = 0.82671632, grad/param norm = 1.9976e-01, time/batch = 14.8728s	
26625/33250 (epoch 40.038), train_loss = 0.78152605, grad/param norm = 1.5670e-01, time/batch = 15.1137s	
26626/33250 (epoch 40.039), train_loss = 0.72878801, grad/param norm = 1.7372e-01, time/batch = 14.9545s	
26627/33250 (epoch 40.041), train_loss = 0.78990732, grad/param norm = 2.2429e-01, time/batch = 14.7704s	
26628/33250 (epoch 40.042), train_loss = 0.66555322, grad/param norm = 1.5585e-01, time/batch = 15.3967s	
26629/33250 (epoch 40.044), train_loss = 0.89416109, grad/param norm = 1.8570e-01, time/batch = 16.3688s	
26630/33250 (epoch 40.045), train_loss = 0.87475389, grad/param norm = 1.8330e-01, time/batch = 15.3695s	
26631/33250 (epoch 40.047), train_loss = 0.79772449, grad/param norm = 1.7211e-01, time/batch = 15.6165s	
26632/33250 (epoch 40.048), train_loss = 0.82026572, grad/param norm = 2.1125e-01, time/batch = 14.6327s	
26633/33250 (epoch 40.050), train_loss = 0.77957953, grad/param norm = 1.8530e-01, time/batch = 14.8535s	
26634/33250 (epoch 40.051), train_loss = 0.80053549, grad/param norm = 2.1220e-01, time/batch = 13.8984s	
26635/33250 (epoch 40.053), train_loss = 0.85606602, grad/param norm = 2.0137e-01, time/batch = 0.6914s	
26636/33250 (epoch 40.054), train_loss = 0.67176161, grad/param norm = 1.6323e-01, time/batch = 0.6962s	
26637/33250 (epoch 40.056), train_loss = 0.67932808, grad/param norm = 1.6414e-01, time/batch = 0.6884s	
26638/33250 (epoch 40.057), train_loss = 0.87476865, grad/param norm = 1.7358e-01, time/batch = 0.6772s	
26639/33250 (epoch 40.059), train_loss = 0.74663826, grad/param norm = 1.7065e-01, time/batch = 0.6643s	
26640/33250 (epoch 40.060), train_loss = 0.79521375, grad/param norm = 2.0514e-01, time/batch = 0.6676s	
26641/33250 (epoch 40.062), train_loss = 0.87859492, grad/param norm = 1.7768e-01, time/batch = 0.6679s	
26642/33250 (epoch 40.063), train_loss = 0.90451764, grad/param norm = 1.8413e-01, time/batch = 0.9089s	
26643/33250 (epoch 40.065), train_loss = 0.76391107, grad/param norm = 1.7938e-01, time/batch = 0.9775s	
26644/33250 (epoch 40.066), train_loss = 0.84066921, grad/param norm = 2.1114e-01, time/batch = 0.9899s	
26645/33250 (epoch 40.068), train_loss = 0.74963069, grad/param norm = 1.6940e-01, time/batch = 0.9737s	
26646/33250 (epoch 40.069), train_loss = 0.81250734, grad/param norm = 1.9380e-01, time/batch = 0.9591s	
26647/33250 (epoch 40.071), train_loss = 0.74572974, grad/param norm = 1.7640e-01, time/batch = 1.5118s	
26648/33250 (epoch 40.072), train_loss = 0.70893365, grad/param norm = 1.5913e-01, time/batch = 1.8046s	
26649/33250 (epoch 40.074), train_loss = 0.80545419, grad/param norm = 1.6946e-01, time/batch = 1.8179s	
26650/33250 (epoch 40.075), train_loss = 0.75011649, grad/param norm = 2.0013e-01, time/batch = 13.2143s	
26651/33250 (epoch 40.077), train_loss = 0.76867944, grad/param norm = 1.8713e-01, time/batch = 14.8657s	
26652/33250 (epoch 40.078), train_loss = 0.78815758, grad/param norm = 1.7437e-01, time/batch = 14.8727s	
26653/33250 (epoch 40.080), train_loss = 0.78089069, grad/param norm = 2.0001e-01, time/batch = 15.1443s	
26654/33250 (epoch 40.081), train_loss = 0.79517513, grad/param norm = 1.6761e-01, time/batch = 15.7142s	
26655/33250 (epoch 40.083), train_loss = 0.90052200, grad/param norm = 1.7761e-01, time/batch = 15.6241s	
26656/33250 (epoch 40.084), train_loss = 0.83686832, grad/param norm = 1.8263e-01, time/batch = 15.7160s	
26657/33250 (epoch 40.086), train_loss = 0.77068152, grad/param norm = 1.5213e-01, time/batch = 15.3529s	
26658/33250 (epoch 40.087), train_loss = 0.68385570, grad/param norm = 1.7172e-01, time/batch = 15.0394s	
26659/33250 (epoch 40.089), train_loss = 0.76237625, grad/param norm = 1.7705e-01, time/batch = 15.3324s	
26660/33250 (epoch 40.090), train_loss = 0.80045414, grad/param norm = 1.8847e-01, time/batch = 15.1027s	
26661/33250 (epoch 40.092), train_loss = 0.73453190, grad/param norm = 1.5208e-01, time/batch = 14.9695s	
26662/33250 (epoch 40.093), train_loss = 0.77387969, grad/param norm = 1.7712e-01, time/batch = 14.7853s	
26663/33250 (epoch 40.095), train_loss = 0.78877384, grad/param norm = 1.8428e-01, time/batch = 14.6982s	
26664/33250 (epoch 40.096), train_loss = 0.67687720, grad/param norm = 1.8757e-01, time/batch = 15.3491s	
26665/33250 (epoch 40.098), train_loss = 0.65522593, grad/param norm = 1.7772e-01, time/batch = 15.3769s	
26666/33250 (epoch 40.099), train_loss = 0.61730475, grad/param norm = 1.4903e-01, time/batch = 15.7975s	
26667/33250 (epoch 40.101), train_loss = 0.77553005, grad/param norm = 2.0887e-01, time/batch = 17.9552s	
26668/33250 (epoch 40.102), train_loss = 0.71506087, grad/param norm = 1.6191e-01, time/batch = 15.5141s	
26669/33250 (epoch 40.104), train_loss = 0.59679473, grad/param norm = 1.5551e-01, time/batch = 15.1986s	
26670/33250 (epoch 40.105), train_loss = 0.74230153, grad/param norm = 1.7127e-01, time/batch = 14.9561s	
26671/33250 (epoch 40.107), train_loss = 0.65810955, grad/param norm = 1.4566e-01, time/batch = 14.3778s	
26672/33250 (epoch 40.108), train_loss = 0.76738808, grad/param norm = 1.7995e-01, time/batch = 14.7919s	
26673/33250 (epoch 40.110), train_loss = 0.66889999, grad/param norm = 1.8225e-01, time/batch = 14.4748s	
26674/33250 (epoch 40.111), train_loss = 0.75739530, grad/param norm = 1.5334e-01, time/batch = 14.9322s	
26675/33250 (epoch 40.113), train_loss = 0.71339149, grad/param norm = 2.0358e-01, time/batch = 16.7037s	
26676/33250 (epoch 40.114), train_loss = 0.67701677, grad/param norm = 1.9807e-01, time/batch = 15.1826s	
26677/33250 (epoch 40.116), train_loss = 0.71728597, grad/param norm = 1.9500e-01, time/batch = 15.6444s	
26678/33250 (epoch 40.117), train_loss = 0.68762868, grad/param norm = 1.7661e-01, time/batch = 16.4813s	
26679/33250 (epoch 40.119), train_loss = 0.72979392, grad/param norm = 1.8223e-01, time/batch = 14.6312s	
26680/33250 (epoch 40.120), train_loss = 0.62200036, grad/param norm = 1.4805e-01, time/batch = 14.6313s	
26681/33250 (epoch 40.122), train_loss = 0.82538545, grad/param norm = 1.8357e-01, time/batch = 14.9262s	
26682/33250 (epoch 40.123), train_loss = 0.74952010, grad/param norm = 2.1196e-01, time/batch = 14.5300s	
26683/33250 (epoch 40.125), train_loss = 0.61885379, grad/param norm = 1.8771e-01, time/batch = 14.7738s	
26684/33250 (epoch 40.126), train_loss = 0.73386781, grad/param norm = 1.9029e-01, time/batch = 14.8721s	
26685/33250 (epoch 40.128), train_loss = 0.70555746, grad/param norm = 1.5364e-01, time/batch = 14.8673s	
26686/33250 (epoch 40.129), train_loss = 0.75582306, grad/param norm = 1.6644e-01, time/batch = 16.7056s	
26687/33250 (epoch 40.131), train_loss = 0.74106752, grad/param norm = 1.7364e-01, time/batch = 16.5323s	
26688/33250 (epoch 40.132), train_loss = 0.72269763, grad/param norm = 1.8423e-01, time/batch = 15.1096s	
26689/33250 (epoch 40.134), train_loss = 0.70081478, grad/param norm = 1.7601e-01, time/batch = 15.3669s	
26690/33250 (epoch 40.135), train_loss = 0.79703367, grad/param norm = 1.6117e-01, time/batch = 15.0413s	
26691/33250 (epoch 40.137), train_loss = 0.68716848, grad/param norm = 1.8819e-01, time/batch = 15.0240s	
26692/33250 (epoch 40.138), train_loss = 0.66892980, grad/param norm = 1.4927e-01, time/batch = 14.8723s	
26693/33250 (epoch 40.140), train_loss = 0.59683165, grad/param norm = 1.4438e-01, time/batch = 15.0159s	
26694/33250 (epoch 40.141), train_loss = 0.82787231, grad/param norm = 2.1449e-01, time/batch = 14.9446s	
26695/33250 (epoch 40.143), train_loss = 0.64838685, grad/param norm = 2.3626e-01, time/batch = 14.7799s	
26696/33250 (epoch 40.144), train_loss = 0.72393889, grad/param norm = 1.7141e-01, time/batch = 15.3607s	
26697/33250 (epoch 40.146), train_loss = 0.70910445, grad/param norm = 1.7173e-01, time/batch = 16.5614s	
26698/33250 (epoch 40.147), train_loss = 0.73340734, grad/param norm = 1.7213e-01, time/batch = 17.2852s	
26699/33250 (epoch 40.149), train_loss = 0.69124737, grad/param norm = 1.5582e-01, time/batch = 15.3719s	
26700/33250 (epoch 40.150), train_loss = 0.68757635, grad/param norm = 1.9186e-01, time/batch = 15.2632s	
26701/33250 (epoch 40.152), train_loss = 0.63476786, grad/param norm = 1.8319e-01, time/batch = 15.1146s	
26702/33250 (epoch 40.153), train_loss = 0.89505044, grad/param norm = 1.9069e-01, time/batch = 14.7291s	
26703/33250 (epoch 40.155), train_loss = 0.71244167, grad/param norm = 2.0213e-01, time/batch = 15.0323s	
26704/33250 (epoch 40.156), train_loss = 0.94518961, grad/param norm = 1.7975e-01, time/batch = 15.3733s	
26705/33250 (epoch 40.158), train_loss = 0.89209875, grad/param norm = 2.1092e-01, time/batch = 14.7789s	
26706/33250 (epoch 40.159), train_loss = 0.73197489, grad/param norm = 1.8119e-01, time/batch = 15.7095s	
26707/33250 (epoch 40.161), train_loss = 0.78993304, grad/param norm = 2.1401e-01, time/batch = 16.0017s	
26708/33250 (epoch 40.162), train_loss = 0.68289714, grad/param norm = 1.6629e-01, time/batch = 17.3774s	
26709/33250 (epoch 40.164), train_loss = 0.75295410, grad/param norm = 1.8593e-01, time/batch = 16.0433s	
26710/33250 (epoch 40.165), train_loss = 0.83866983, grad/param norm = 1.9023e-01, time/batch = 17.6934s	
26711/33250 (epoch 40.167), train_loss = 0.89509092, grad/param norm = 1.9901e-01, time/batch = 15.8596s	
26712/33250 (epoch 40.168), train_loss = 0.67357551, grad/param norm = 1.6326e-01, time/batch = 15.7814s	
26713/33250 (epoch 40.170), train_loss = 0.73606070, grad/param norm = 1.9975e-01, time/batch = 15.4565s	
26714/33250 (epoch 40.171), train_loss = 0.76129844, grad/param norm = 1.4898e-01, time/batch = 14.7794s	
26715/33250 (epoch 40.173), train_loss = 0.75815719, grad/param norm = 1.6673e-01, time/batch = 14.9616s	
26716/33250 (epoch 40.174), train_loss = 0.78502302, grad/param norm = 2.0086e-01, time/batch = 15.1931s	
26717/33250 (epoch 40.176), train_loss = 0.70384899, grad/param norm = 1.8647e-01, time/batch = 15.5057s	
26718/33250 (epoch 40.177), train_loss = 0.69171790, grad/param norm = 1.6053e-01, time/batch = 15.6977s	
26719/33250 (epoch 40.179), train_loss = 0.68797094, grad/param norm = 1.5467e-01, time/batch = 16.5209s	
26720/33250 (epoch 40.180), train_loss = 0.61221998, grad/param norm = 1.5371e-01, time/batch = 15.8737s	
26721/33250 (epoch 40.182), train_loss = 0.68172821, grad/param norm = 2.7326e-01, time/batch = 14.5262s	
26722/33250 (epoch 40.183), train_loss = 0.85096884, grad/param norm = 1.8773e-01, time/batch = 14.9514s	
26723/33250 (epoch 40.185), train_loss = 0.77288137, grad/param norm = 2.2129e-01, time/batch = 14.6280s	
26724/33250 (epoch 40.186), train_loss = 0.79779778, grad/param norm = 2.0679e-01, time/batch = 14.5438s	
26725/33250 (epoch 40.188), train_loss = 0.85697343, grad/param norm = 2.3479e-01, time/batch = 15.1735s	
26726/33250 (epoch 40.189), train_loss = 0.62535418, grad/param norm = 2.0020e-01, time/batch = 15.4123s	
26727/33250 (epoch 40.191), train_loss = 0.70752780, grad/param norm = 1.7002e-01, time/batch = 15.7450s	
26728/33250 (epoch 40.192), train_loss = 0.71314288, grad/param norm = 1.6387e-01, time/batch = 15.5287s	
26729/33250 (epoch 40.194), train_loss = 0.73707081, grad/param norm = 1.9013e-01, time/batch = 15.1377s	
26730/33250 (epoch 40.195), train_loss = 0.90407534, grad/param norm = 1.8686e-01, time/batch = 15.6106s	
26731/33250 (epoch 40.197), train_loss = 0.69954829, grad/param norm = 1.5546e-01, time/batch = 15.1396s	
26732/33250 (epoch 40.198), train_loss = 0.87935218, grad/param norm = 1.6961e-01, time/batch = 15.3700s	
26733/33250 (epoch 40.200), train_loss = 0.75142780, grad/param norm = 1.7319e-01, time/batch = 15.4372s	
26734/33250 (epoch 40.202), train_loss = 0.72080464, grad/param norm = 1.6044e-01, time/batch = 15.7286s	
26735/33250 (epoch 40.203), train_loss = 0.67869851, grad/param norm = 1.6336e-01, time/batch = 15.1744s	
26736/33250 (epoch 40.205), train_loss = 0.77675836, grad/param norm = 1.6966e-01, time/batch = 15.1260s	
26737/33250 (epoch 40.206), train_loss = 0.80975803, grad/param norm = 1.7006e-01, time/batch = 14.7994s	
26738/33250 (epoch 40.208), train_loss = 0.86933435, grad/param norm = 2.3402e-01, time/batch = 14.6078s	
26739/33250 (epoch 40.209), train_loss = 0.72374672, grad/param norm = 1.6739e-01, time/batch = 15.2230s	
26740/33250 (epoch 40.211), train_loss = 0.78569397, grad/param norm = 1.6354e-01, time/batch = 16.8796s	
26741/33250 (epoch 40.212), train_loss = 0.87756278, grad/param norm = 1.8238e-01, time/batch = 14.9768s	
26742/33250 (epoch 40.214), train_loss = 0.79076137, grad/param norm = 1.6220e-01, time/batch = 15.3901s	
26743/33250 (epoch 40.215), train_loss = 0.80403282, grad/param norm = 2.0645e-01, time/batch = 15.5618s	
26744/33250 (epoch 40.217), train_loss = 0.85549338, grad/param norm = 2.0621e-01, time/batch = 14.9644s	
26745/33250 (epoch 40.218), train_loss = 0.81296333, grad/param norm = 1.7400e-01, time/batch = 15.2515s	
26746/33250 (epoch 40.220), train_loss = 0.78425874, grad/param norm = 2.0013e-01, time/batch = 15.1134s	
26747/33250 (epoch 40.221), train_loss = 0.88536038, grad/param norm = 1.9608e-01, time/batch = 14.6906s	
26748/33250 (epoch 40.223), train_loss = 0.77723985, grad/param norm = 1.6907e-01, time/batch = 14.6932s	
26749/33250 (epoch 40.224), train_loss = 0.81388533, grad/param norm = 1.9205e-01, time/batch = 15.0363s	
26750/33250 (epoch 40.226), train_loss = 0.89203545, grad/param norm = 1.8436e-01, time/batch = 15.5159s	
26751/33250 (epoch 40.227), train_loss = 0.79675682, grad/param norm = 1.6467e-01, time/batch = 19.3628s	
26752/33250 (epoch 40.229), train_loss = 0.79464477, grad/param norm = 1.6948e-01, time/batch = 16.8874s	
26753/33250 (epoch 40.230), train_loss = 0.78790518, grad/param norm = 1.8891e-01, time/batch = 15.2812s	
26754/33250 (epoch 40.232), train_loss = 0.73754522, grad/param norm = 1.7655e-01, time/batch = 15.3464s	
26755/33250 (epoch 40.233), train_loss = 0.70374405, grad/param norm = 1.6118e-01, time/batch = 15.0848s	
26756/33250 (epoch 40.235), train_loss = 0.87255738, grad/param norm = 1.6810e-01, time/batch = 15.1690s	
26757/33250 (epoch 40.236), train_loss = 0.72302851, grad/param norm = 1.9019e-01, time/batch = 15.3502s	
26758/33250 (epoch 40.238), train_loss = 0.86643531, grad/param norm = 1.9345e-01, time/batch = 15.1120s	
26759/33250 (epoch 40.239), train_loss = 0.86263596, grad/param norm = 2.1754e-01, time/batch = 15.1911s	
26760/33250 (epoch 40.241), train_loss = 0.85874381, grad/param norm = 2.0825e-01, time/batch = 15.1050s	
26761/33250 (epoch 40.242), train_loss = 0.87375892, grad/param norm = 2.1172e-01, time/batch = 16.8654s	
26762/33250 (epoch 40.244), train_loss = 0.81278696, grad/param norm = 2.1022e-01, time/batch = 14.9653s	
26763/33250 (epoch 40.245), train_loss = 0.80488144, grad/param norm = 1.9951e-01, time/batch = 15.3778s	
26764/33250 (epoch 40.247), train_loss = 0.76621008, grad/param norm = 1.8583e-01, time/batch = 15.5459s	
26765/33250 (epoch 40.248), train_loss = 0.90165019, grad/param norm = 2.1216e-01, time/batch = 15.0252s	
26766/33250 (epoch 40.250), train_loss = 0.89547137, grad/param norm = 1.7185e-01, time/batch = 14.9696s	
26767/33250 (epoch 40.251), train_loss = 0.76155619, grad/param norm = 1.7236e-01, time/batch = 15.2781s	
26768/33250 (epoch 40.253), train_loss = 0.75311869, grad/param norm = 1.6919e-01, time/batch = 15.2686s	
26769/33250 (epoch 40.254), train_loss = 0.71382823, grad/param norm = 1.7893e-01, time/batch = 14.7941s	
26770/33250 (epoch 40.256), train_loss = 0.78679816, grad/param norm = 1.6568e-01, time/batch = 14.7192s	
26771/33250 (epoch 40.257), train_loss = 0.92917466, grad/param norm = 1.7710e-01, time/batch = 14.9660s	
26772/33250 (epoch 40.259), train_loss = 0.81588914, grad/param norm = 1.9670e-01, time/batch = 16.2664s	
26773/33250 (epoch 40.260), train_loss = 0.65403175, grad/param norm = 1.9772e-01, time/batch = 17.0049s	
26774/33250 (epoch 40.262), train_loss = 0.78742925, grad/param norm = 1.8117e-01, time/batch = 15.6205s	
26775/33250 (epoch 40.263), train_loss = 0.66677653, grad/param norm = 1.9428e-01, time/batch = 15.6616s	
26776/33250 (epoch 40.265), train_loss = 0.82855137, grad/param norm = 1.8361e-01, time/batch = 15.1807s	
26777/33250 (epoch 40.266), train_loss = 0.77704013, grad/param norm = 1.9907e-01, time/batch = 14.8749s	
26778/33250 (epoch 40.268), train_loss = 0.68684155, grad/param norm = 1.8257e-01, time/batch = 14.7786s	
26779/33250 (epoch 40.269), train_loss = 0.64189940, grad/param norm = 1.5394e-01, time/batch = 14.7192s	
26780/33250 (epoch 40.271), train_loss = 0.81312558, grad/param norm = 1.6579e-01, time/batch = 14.9332s	
26781/33250 (epoch 40.272), train_loss = 0.71642165, grad/param norm = 1.6169e-01, time/batch = 14.9678s	
26782/33250 (epoch 40.274), train_loss = 0.57507394, grad/param norm = 1.5033e-01, time/batch = 14.7106s	
26783/33250 (epoch 40.275), train_loss = 0.73723678, grad/param norm = 1.5222e-01, time/batch = 16.3005s	
26784/33250 (epoch 40.277), train_loss = 0.63188620, grad/param norm = 1.7007e-01, time/batch = 15.7608s	
26785/33250 (epoch 40.278), train_loss = 0.72520633, grad/param norm = 1.7675e-01, time/batch = 17.9474s	
26786/33250 (epoch 40.280), train_loss = 0.68084600, grad/param norm = 1.6443e-01, time/batch = 14.8874s	
26787/33250 (epoch 40.281), train_loss = 0.78908967, grad/param norm = 1.7881e-01, time/batch = 14.9724s	
26788/33250 (epoch 40.283), train_loss = 0.79658819, grad/param norm = 2.3875e-01, time/batch = 15.2605s	
26789/33250 (epoch 40.284), train_loss = 0.67477799, grad/param norm = 2.0418e-01, time/batch = 14.7931s	
26790/33250 (epoch 40.286), train_loss = 0.80269311, grad/param norm = 1.8087e-01, time/batch = 15.1715s	
26791/33250 (epoch 40.287), train_loss = 0.63536951, grad/param norm = 1.6705e-01, time/batch = 15.0914s	
26792/33250 (epoch 40.289), train_loss = 0.61043071, grad/param norm = 1.5551e-01, time/batch = 15.2385s	
26793/33250 (epoch 40.290), train_loss = 0.76395313, grad/param norm = 1.5964e-01, time/batch = 16.3465s	
26794/33250 (epoch 40.292), train_loss = 0.79957608, grad/param norm = 2.1849e-01, time/batch = 16.2862s	
26795/33250 (epoch 40.293), train_loss = 0.87043854, grad/param norm = 1.9701e-01, time/batch = 14.1423s	
26796/33250 (epoch 40.295), train_loss = 0.87849012, grad/param norm = 2.1420e-01, time/batch = 15.2101s	
26797/33250 (epoch 40.296), train_loss = 0.76960630, grad/param norm = 1.7247e-01, time/batch = 15.3772s	
26798/33250 (epoch 40.298), train_loss = 0.62065048, grad/param norm = 1.4518e-01, time/batch = 14.7836s	
26799/33250 (epoch 40.299), train_loss = 0.61721426, grad/param norm = 2.0680e-01, time/batch = 15.1302s	
26800/33250 (epoch 40.301), train_loss = 0.85529233, grad/param norm = 2.1339e-01, time/batch = 14.6948s	
26801/33250 (epoch 40.302), train_loss = 0.82981683, grad/param norm = 2.0270e-01, time/batch = 15.8027s	
26802/33250 (epoch 40.304), train_loss = 0.73044289, grad/param norm = 1.8323e-01, time/batch = 15.1833s	
26803/33250 (epoch 40.305), train_loss = 0.69860917, grad/param norm = 1.7046e-01, time/batch = 15.3473s	
26804/33250 (epoch 40.307), train_loss = 0.80888464, grad/param norm = 1.6705e-01, time/batch = 15.5302s	
26805/33250 (epoch 40.308), train_loss = 0.89981219, grad/param norm = 3.1459e-01, time/batch = 15.3388s	
26806/33250 (epoch 40.310), train_loss = 0.72536065, grad/param norm = 1.9984e-01, time/batch = 15.0309s	
26807/33250 (epoch 40.311), train_loss = 0.91692767, grad/param norm = 2.1940e-01, time/batch = 15.3599s	
26808/33250 (epoch 40.313), train_loss = 0.63121159, grad/param norm = 1.7866e-01, time/batch = 14.6413s	
26809/33250 (epoch 40.314), train_loss = 0.85023818, grad/param norm = 1.7782e-01, time/batch = 14.6132s	
26810/33250 (epoch 40.316), train_loss = 0.95255183, grad/param norm = 2.2035e-01, time/batch = 14.8884s	
26811/33250 (epoch 40.317), train_loss = 0.68405196, grad/param norm = 1.6480e-01, time/batch = 15.5964s	
26812/33250 (epoch 40.319), train_loss = 0.83481497, grad/param norm = 2.5096e-01, time/batch = 15.5237s	
26813/33250 (epoch 40.320), train_loss = 0.85238852, grad/param norm = 2.7614e-01, time/batch = 15.0410s	
26814/33250 (epoch 40.322), train_loss = 0.93418702, grad/param norm = 2.2233e-01, time/batch = 14.8943s	
26815/33250 (epoch 40.323), train_loss = 0.94214982, grad/param norm = 2.7544e-01, time/batch = 14.8925s	
26816/33250 (epoch 40.325), train_loss = 0.75023351, grad/param norm = 2.0624e-01, time/batch = 16.9568s	
26817/33250 (epoch 40.326), train_loss = 0.98901858, grad/param norm = 2.0514e-01, time/batch = 15.5518s	
26818/33250 (epoch 40.328), train_loss = 0.75998970, grad/param norm = 1.6901e-01, time/batch = 14.9855s	
26819/33250 (epoch 40.329), train_loss = 0.80994452, grad/param norm = 2.4704e-01, time/batch = 14.9344s	
26820/33250 (epoch 40.331), train_loss = 0.78010432, grad/param norm = 2.1686e-01, time/batch = 15.1292s	
26821/33250 (epoch 40.332), train_loss = 0.78583797, grad/param norm = 1.7185e-01, time/batch = 15.1219s	
26822/33250 (epoch 40.334), train_loss = 0.92184064, grad/param norm = 2.0742e-01, time/batch = 14.7908s	
26823/33250 (epoch 40.335), train_loss = 0.59988681, grad/param norm = 1.7613e-01, time/batch = 15.2662s	
26824/33250 (epoch 40.337), train_loss = 0.84993309, grad/param norm = 1.9425e-01, time/batch = 15.3289s	
26825/33250 (epoch 40.338), train_loss = 0.94642360, grad/param norm = 1.9346e-01, time/batch = 15.7270s	
26826/33250 (epoch 40.340), train_loss = 0.74184987, grad/param norm = 1.5591e-01, time/batch = 15.5609s	
26827/33250 (epoch 40.341), train_loss = 0.71529783, grad/param norm = 1.7082e-01, time/batch = 15.5211s	
26828/33250 (epoch 40.343), train_loss = 0.75418183, grad/param norm = 2.0106e-01, time/batch = 17.0393s	
26829/33250 (epoch 40.344), train_loss = 0.76748219, grad/param norm = 1.5711e-01, time/batch = 15.3027s	
26830/33250 (epoch 40.346), train_loss = 0.67708833, grad/param norm = 1.4857e-01, time/batch = 15.0970s	
26831/33250 (epoch 40.347), train_loss = 0.95522681, grad/param norm = 2.5100e-01, time/batch = 15.4898s	
26832/33250 (epoch 40.349), train_loss = 0.76950405, grad/param norm = 2.0787e-01, time/batch = 15.8598s	
26833/33250 (epoch 40.350), train_loss = 0.78089966, grad/param norm = 1.8909e-01, time/batch = 15.6163s	
26834/33250 (epoch 40.352), train_loss = 0.70230521, grad/param norm = 1.8329e-01, time/batch = 15.1315s	
26835/33250 (epoch 40.353), train_loss = 0.74002067, grad/param norm = 1.7772e-01, time/batch = 15.6824s	
26836/33250 (epoch 40.355), train_loss = 0.72970167, grad/param norm = 1.7731e-01, time/batch = 16.4807s	
26837/33250 (epoch 40.356), train_loss = 0.69881645, grad/param norm = 1.7962e-01, time/batch = 16.8958s	
26838/33250 (epoch 40.358), train_loss = 0.75886847, grad/param norm = 1.6542e-01, time/batch = 16.3022s	
26839/33250 (epoch 40.359), train_loss = 0.75006969, grad/param norm = 1.7749e-01, time/batch = 15.3360s	
26840/33250 (epoch 40.361), train_loss = 0.88356585, grad/param norm = 2.4461e-01, time/batch = 15.1810s	
26841/33250 (epoch 40.362), train_loss = 0.81156473, grad/param norm = 1.7011e-01, time/batch = 15.6556s	
26842/33250 (epoch 40.364), train_loss = 0.83052113, grad/param norm = 1.9850e-01, time/batch = 13.9063s	
26843/33250 (epoch 40.365), train_loss = 0.78743625, grad/param norm = 1.8900e-01, time/batch = 0.9174s	
26844/33250 (epoch 40.367), train_loss = 0.79994401, grad/param norm = 1.7247e-01, time/batch = 0.6852s	
26845/33250 (epoch 40.368), train_loss = 0.77188030, grad/param norm = 2.0192e-01, time/batch = 0.6740s	
26846/33250 (epoch 40.370), train_loss = 0.70588866, grad/param norm = 1.6011e-01, time/batch = 0.6734s	
26847/33250 (epoch 40.371), train_loss = 0.87492353, grad/param norm = 2.0964e-01, time/batch = 0.6777s	
26848/33250 (epoch 40.373), train_loss = 0.75164506, grad/param norm = 1.5799e-01, time/batch = 0.6849s	
26849/33250 (epoch 40.374), train_loss = 0.77419088, grad/param norm = 2.2204e-01, time/batch = 0.9298s	
26850/33250 (epoch 40.376), train_loss = 0.76703981, grad/param norm = 1.7485e-01, time/batch = 1.0181s	
26851/33250 (epoch 40.377), train_loss = 0.67698244, grad/param norm = 1.7517e-01, time/batch = 1.0030s	
26852/33250 (epoch 40.379), train_loss = 0.79311589, grad/param norm = 2.2011e-01, time/batch = 1.0188s	
26853/33250 (epoch 40.380), train_loss = 0.78575716, grad/param norm = 2.2009e-01, time/batch = 1.0396s	
26854/33250 (epoch 40.382), train_loss = 0.79929693, grad/param norm = 2.2749e-01, time/batch = 1.8629s	
26855/33250 (epoch 40.383), train_loss = 0.68704744, grad/param norm = 1.8067e-01, time/batch = 1.9761s	
26856/33250 (epoch 40.385), train_loss = 0.65132821, grad/param norm = 1.8075e-01, time/batch = 6.0391s	
26857/33250 (epoch 40.386), train_loss = 0.69063072, grad/param norm = 1.8775e-01, time/batch = 15.4079s	
26858/33250 (epoch 40.388), train_loss = 0.70823972, grad/param norm = 1.6316e-01, time/batch = 15.4810s	
26859/33250 (epoch 40.389), train_loss = 0.73130397, grad/param norm = 2.1723e-01, time/batch = 15.7153s	
26860/33250 (epoch 40.391), train_loss = 0.81132952, grad/param norm = 2.0662e-01, time/batch = 15.4409s	
26861/33250 (epoch 40.392), train_loss = 0.87169833, grad/param norm = 2.2075e-01, time/batch = 15.6977s	
26862/33250 (epoch 40.394), train_loss = 0.86332848, grad/param norm = 1.9132e-01, time/batch = 15.2834s	
26863/33250 (epoch 40.395), train_loss = 0.86668217, grad/param norm = 1.8320e-01, time/batch = 15.5130s	
26864/33250 (epoch 40.397), train_loss = 0.89477182, grad/param norm = 2.1109e-01, time/batch = 15.1137s	
26865/33250 (epoch 40.398), train_loss = 0.69951242, grad/param norm = 1.7349e-01, time/batch = 15.1846s	
26866/33250 (epoch 40.400), train_loss = 0.67779369, grad/param norm = 1.5965e-01, time/batch = 14.9456s	
26867/33250 (epoch 40.402), train_loss = 0.65422183, grad/param norm = 2.0468e-01, time/batch = 15.2618s	
26868/33250 (epoch 40.403), train_loss = 0.75766857, grad/param norm = 2.1423e-01, time/batch = 14.7688s	
26869/33250 (epoch 40.405), train_loss = 0.71124392, grad/param norm = 1.4821e-01, time/batch = 14.8599s	
26870/33250 (epoch 40.406), train_loss = 0.76406667, grad/param norm = 2.1401e-01, time/batch = 14.7805s	
26871/33250 (epoch 40.408), train_loss = 0.91492656, grad/param norm = 1.8630e-01, time/batch = 15.2605s	
26872/33250 (epoch 40.409), train_loss = 0.81740658, grad/param norm = 1.9069e-01, time/batch = 14.6426s	
26873/33250 (epoch 40.411), train_loss = 0.56438570, grad/param norm = 1.3409e-01, time/batch = 15.2741s	
26874/33250 (epoch 40.412), train_loss = 0.65662958, grad/param norm = 1.8348e-01, time/batch = 14.8908s	
26875/33250 (epoch 40.414), train_loss = 0.78300457, grad/param norm = 1.6988e-01, time/batch = 15.5681s	
26876/33250 (epoch 40.415), train_loss = 0.83760665, grad/param norm = 1.8553e-01, time/batch = 14.9453s	
26877/33250 (epoch 40.417), train_loss = 0.87357595, grad/param norm = 1.8118e-01, time/batch = 14.8410s	
26878/33250 (epoch 40.418), train_loss = 1.02048762, grad/param norm = 2.1668e-01, time/batch = 14.9465s	
26879/33250 (epoch 40.420), train_loss = 0.85179022, grad/param norm = 1.8911e-01, time/batch = 15.0253s	
26880/33250 (epoch 40.421), train_loss = 0.73859924, grad/param norm = 1.5995e-01, time/batch = 15.2493s	
26881/33250 (epoch 40.423), train_loss = 0.81503122, grad/param norm = 1.7895e-01, time/batch = 15.1154s	
26882/33250 (epoch 40.424), train_loss = 0.87538265, grad/param norm = 2.1969e-01, time/batch = 14.9420s	
26883/33250 (epoch 40.426), train_loss = 0.77277618, grad/param norm = 1.5711e-01, time/batch = 15.5289s	
26884/33250 (epoch 40.427), train_loss = 0.72602234, grad/param norm = 1.9974e-01, time/batch = 15.5893s	
26885/33250 (epoch 40.429), train_loss = 0.77444209, grad/param norm = 1.8592e-01, time/batch = 16.0792s	
26886/33250 (epoch 40.430), train_loss = 0.73922690, grad/param norm = 2.1765e-01, time/batch = 15.3726s	
26887/33250 (epoch 40.432), train_loss = 0.86040418, grad/param norm = 1.7793e-01, time/batch = 15.1909s	
26888/33250 (epoch 40.433), train_loss = 0.71568945, grad/param norm = 1.9070e-01, time/batch = 15.0294s	
26889/33250 (epoch 40.435), train_loss = 0.85247201, grad/param norm = 2.1074e-01, time/batch = 15.3957s	
26890/33250 (epoch 40.436), train_loss = 0.72619061, grad/param norm = 1.9297e-01, time/batch = 15.0851s	
26891/33250 (epoch 40.438), train_loss = 0.88788096, grad/param norm = 1.8492e-01, time/batch = 15.1065s	
26892/33250 (epoch 40.439), train_loss = 0.78167976, grad/param norm = 1.6923e-01, time/batch = 14.8706s	
26893/33250 (epoch 40.441), train_loss = 0.75911605, grad/param norm = 1.6236e-01, time/batch = 14.7140s	
26894/33250 (epoch 40.442), train_loss = 0.69681341, grad/param norm = 1.6764e-01, time/batch = 15.1128s	
26895/33250 (epoch 40.444), train_loss = 0.74489196, grad/param norm = 1.6957e-01, time/batch = 14.9703s	
26896/33250 (epoch 40.445), train_loss = 0.80033442, grad/param norm = 1.6477e-01, time/batch = 15.1066s	
26897/33250 (epoch 40.447), train_loss = 0.69103308, grad/param norm = 1.6647e-01, time/batch = 14.9394s	
26898/33250 (epoch 40.448), train_loss = 0.80216509, grad/param norm = 1.5755e-01, time/batch = 15.4960s	
26899/33250 (epoch 40.450), train_loss = 0.88052019, grad/param norm = 1.9113e-01, time/batch = 14.7653s	
26900/33250 (epoch 40.451), train_loss = 0.84706665, grad/param norm = 2.4964e-01, time/batch = 14.8624s	
26901/33250 (epoch 40.453), train_loss = 0.68470277, grad/param norm = 1.6333e-01, time/batch = 15.1844s	
26902/33250 (epoch 40.454), train_loss = 0.90018951, grad/param norm = 2.0057e-01, time/batch = 15.4197s	
26903/33250 (epoch 40.456), train_loss = 0.88763830, grad/param norm = 1.6145e-01, time/batch = 14.9407s	
26904/33250 (epoch 40.457), train_loss = 0.71842998, grad/param norm = 1.6527e-01, time/batch = 14.8668s	
26905/33250 (epoch 40.459), train_loss = 0.84146960, grad/param norm = 1.7282e-01, time/batch = 14.7166s	
26906/33250 (epoch 40.460), train_loss = 0.84369708, grad/param norm = 1.9476e-01, time/batch = 15.1086s	
26907/33250 (epoch 40.462), train_loss = 0.78624930, grad/param norm = 2.0292e-01, time/batch = 15.6429s	
26908/33250 (epoch 40.463), train_loss = 0.68411954, grad/param norm = 1.3490e-01, time/batch = 15.5776s	
26909/33250 (epoch 40.465), train_loss = 0.64814285, grad/param norm = 1.4601e-01, time/batch = 15.2875s	
26910/33250 (epoch 40.466), train_loss = 0.63378493, grad/param norm = 1.3014e-01, time/batch = 15.3504s	
26911/33250 (epoch 40.468), train_loss = 0.67282776, grad/param norm = 1.4851e-01, time/batch = 15.2677s	
26912/33250 (epoch 40.469), train_loss = 0.76761563, grad/param norm = 2.2240e-01, time/batch = 15.2711s	
26913/33250 (epoch 40.471), train_loss = 0.83841828, grad/param norm = 1.5138e-01, time/batch = 15.1054s	
26914/33250 (epoch 40.472), train_loss = 0.78275545, grad/param norm = 3.2256e-01, time/batch = 15.5772s	
26915/33250 (epoch 40.474), train_loss = 0.85452422, grad/param norm = 1.8030e-01, time/batch = 15.2564s	
26916/33250 (epoch 40.475), train_loss = 0.78832124, grad/param norm = 1.5909e-01, time/batch = 15.4467s	
26917/33250 (epoch 40.477), train_loss = 0.79771501, grad/param norm = 1.7838e-01, time/batch = 15.8970s	
26918/33250 (epoch 40.478), train_loss = 0.68203756, grad/param norm = 1.7111e-01, time/batch = 15.5301s	
26919/33250 (epoch 40.480), train_loss = 0.86407807, grad/param norm = 1.7598e-01, time/batch = 15.0522s	
26920/33250 (epoch 40.481), train_loss = 0.74065249, grad/param norm = 1.9843e-01, time/batch = 15.0310s	
26921/33250 (epoch 40.483), train_loss = 0.73957290, grad/param norm = 1.6839e-01, time/batch = 14.9489s	
26922/33250 (epoch 40.484), train_loss = 0.70885614, grad/param norm = 1.7027e-01, time/batch = 15.6560s	
26923/33250 (epoch 40.486), train_loss = 0.64523838, grad/param norm = 1.7864e-01, time/batch = 15.0149s	
26924/33250 (epoch 40.487), train_loss = 0.70801507, grad/param norm = 1.7262e-01, time/batch = 14.9481s	
26925/33250 (epoch 40.489), train_loss = 0.84735495, grad/param norm = 1.9551e-01, time/batch = 15.4159s	
26926/33250 (epoch 40.490), train_loss = 0.79515158, grad/param norm = 2.2134e-01, time/batch = 15.1113s	
26927/33250 (epoch 40.492), train_loss = 0.84472886, grad/param norm = 1.8428e-01, time/batch = 15.3484s	
26928/33250 (epoch 40.493), train_loss = 0.78062702, grad/param norm = 1.7716e-01, time/batch = 15.4768s	
26929/33250 (epoch 40.495), train_loss = 0.83403075, grad/param norm = 1.5397e-01, time/batch = 14.8796s	
26930/33250 (epoch 40.496), train_loss = 0.77983711, grad/param norm = 1.5185e-01, time/batch = 15.5207s	
26931/33250 (epoch 40.498), train_loss = 0.84679415, grad/param norm = 1.7950e-01, time/batch = 14.7959s	
26932/33250 (epoch 40.499), train_loss = 0.72800242, grad/param norm = 1.6339e-01, time/batch = 14.7839s	
26933/33250 (epoch 40.501), train_loss = 0.74206137, grad/param norm = 2.0859e-01, time/batch = 15.0246s	
26934/33250 (epoch 40.502), train_loss = 0.72197136, grad/param norm = 1.5204e-01, time/batch = 15.4846s	
26935/33250 (epoch 40.504), train_loss = 0.89880050, grad/param norm = 2.0936e-01, time/batch = 15.3372s	
26936/33250 (epoch 40.505), train_loss = 0.67236449, grad/param norm = 1.4703e-01, time/batch = 15.0335s	
26937/33250 (epoch 40.507), train_loss = 0.71008563, grad/param norm = 1.6659e-01, time/batch = 14.9440s	
26938/33250 (epoch 40.508), train_loss = 0.75892603, grad/param norm = 1.7441e-01, time/batch = 15.4437s	
26939/33250 (epoch 40.510), train_loss = 0.64209935, grad/param norm = 1.4834e-01, time/batch = 14.9650s	
26940/33250 (epoch 40.511), train_loss = 0.75155498, grad/param norm = 1.8476e-01, time/batch = 15.2064s	
26941/33250 (epoch 40.513), train_loss = 0.87390267, grad/param norm = 1.9564e-01, time/batch = 15.2872s	
26942/33250 (epoch 40.514), train_loss = 0.72117651, grad/param norm = 1.6572e-01, time/batch = 15.4887s	
26943/33250 (epoch 40.516), train_loss = 0.69279413, grad/param norm = 1.7040e-01, time/batch = 15.0305s	
26944/33250 (epoch 40.517), train_loss = 0.75004975, grad/param norm = 1.7197e-01, time/batch = 15.1035s	
26945/33250 (epoch 40.519), train_loss = 0.68026850, grad/param norm = 1.2669e-01, time/batch = 14.6956s	
26946/33250 (epoch 40.520), train_loss = 0.93086558, grad/param norm = 2.0909e-01, time/batch = 14.7917s	
26947/33250 (epoch 40.522), train_loss = 0.79241584, grad/param norm = 1.8707e-01, time/batch = 15.3277s	
26948/33250 (epoch 40.523), train_loss = 0.68674912, grad/param norm = 1.6620e-01, time/batch = 15.5207s	
26949/33250 (epoch 40.525), train_loss = 0.65731852, grad/param norm = 1.8656e-01, time/batch = 15.3887s	
26950/33250 (epoch 40.526), train_loss = 0.67949084, grad/param norm = 1.6153e-01, time/batch = 15.6471s	
26951/33250 (epoch 40.528), train_loss = 0.72825940, grad/param norm = 1.7273e-01, time/batch = 15.4376s	
26952/33250 (epoch 40.529), train_loss = 0.70774897, grad/param norm = 1.8226e-01, time/batch = 15.3005s	
26953/33250 (epoch 40.531), train_loss = 0.67438473, grad/param norm = 1.5758e-01, time/batch = 15.5825s	
26954/33250 (epoch 40.532), train_loss = 0.79709005, grad/param norm = 1.5520e-01, time/batch = 15.4254s	
26955/33250 (epoch 40.534), train_loss = 0.69916764, grad/param norm = 1.5580e-01, time/batch = 15.4387s	
26956/33250 (epoch 40.535), train_loss = 0.73235378, grad/param norm = 1.6632e-01, time/batch = 15.4447s	
26957/33250 (epoch 40.537), train_loss = 0.77486701, grad/param norm = 1.6215e-01, time/batch = 15.3438s	
26958/33250 (epoch 40.538), train_loss = 0.82203336, grad/param norm = 1.9010e-01, time/batch = 15.0110s	
26959/33250 (epoch 40.540), train_loss = 0.90627691, grad/param norm = 1.6062e-01, time/batch = 14.9560s	
26960/33250 (epoch 40.541), train_loss = 0.81528517, grad/param norm = 1.8530e-01, time/batch = 15.4265s	
26961/33250 (epoch 40.543), train_loss = 0.81523015, grad/param norm = 1.5514e-01, time/batch = 15.7292s	
26962/33250 (epoch 40.544), train_loss = 0.68935394, grad/param norm = 1.8747e-01, time/batch = 15.4889s	
26963/33250 (epoch 40.546), train_loss = 0.71629290, grad/param norm = 1.9426e-01, time/batch = 15.0479s	
26964/33250 (epoch 40.547), train_loss = 0.73694296, grad/param norm = 1.9231e-01, time/batch = 14.7091s	
26965/33250 (epoch 40.549), train_loss = 0.78550260, grad/param norm = 1.9187e-01, time/batch = 15.5031s	
26966/33250 (epoch 40.550), train_loss = 0.74915046, grad/param norm = 1.7029e-01, time/batch = 15.4143s	
26967/33250 (epoch 40.552), train_loss = 0.80901161, grad/param norm = 1.6624e-01, time/batch = 15.8652s	
26968/33250 (epoch 40.553), train_loss = 0.75323277, grad/param norm = 1.6926e-01, time/batch = 15.7759s	
26969/33250 (epoch 40.555), train_loss = 0.76195412, grad/param norm = 1.5143e-01, time/batch = 15.2819s	
26970/33250 (epoch 40.556), train_loss = 0.77558178, grad/param norm = 2.1507e-01, time/batch = 15.2685s	
26971/33250 (epoch 40.558), train_loss = 0.80099295, grad/param norm = 1.8287e-01, time/batch = 15.8611s	
26972/33250 (epoch 40.559), train_loss = 0.71173959, grad/param norm = 1.8712e-01, time/batch = 15.2627s	
26973/33250 (epoch 40.561), train_loss = 0.65880756, grad/param norm = 1.6597e-01, time/batch = 15.2755s	
26974/33250 (epoch 40.562), train_loss = 0.76680333, grad/param norm = 1.7861e-01, time/batch = 15.3492s	
26975/33250 (epoch 40.564), train_loss = 0.92277681, grad/param norm = 2.2447e-01, time/batch = 14.8853s	
26976/33250 (epoch 40.565), train_loss = 0.85868504, grad/param norm = 2.2207e-01, time/batch = 15.1806s	
26977/33250 (epoch 40.567), train_loss = 0.87911393, grad/param norm = 1.9356e-01, time/batch = 15.2702s	
26978/33250 (epoch 40.568), train_loss = 0.73283991, grad/param norm = 1.9003e-01, time/batch = 15.4714s	
26979/33250 (epoch 40.570), train_loss = 0.83846634, grad/param norm = 2.1801e-01, time/batch = 15.4806s	
26980/33250 (epoch 40.571), train_loss = 0.85718097, grad/param norm = 1.7409e-01, time/batch = 15.3185s	
26981/33250 (epoch 40.573), train_loss = 0.82503533, grad/param norm = 2.1951e-01, time/batch = 15.3386s	
26982/33250 (epoch 40.574), train_loss = 0.70666023, grad/param norm = 1.4859e-01, time/batch = 14.7213s	
26983/33250 (epoch 40.576), train_loss = 0.79291754, grad/param norm = 1.8060e-01, time/batch = 14.9499s	
26984/33250 (epoch 40.577), train_loss = 0.75065692, grad/param norm = 1.6096e-01, time/batch = 15.1259s	
26985/33250 (epoch 40.579), train_loss = 0.65457221, grad/param norm = 1.6962e-01, time/batch = 15.0213s	
26986/33250 (epoch 40.580), train_loss = 0.77294258, grad/param norm = 1.7775e-01, time/batch = 15.1731s	
26987/33250 (epoch 40.582), train_loss = 0.74058561, grad/param norm = 1.9132e-01, time/batch = 15.0251s	
26988/33250 (epoch 40.583), train_loss = 0.82306666, grad/param norm = 1.8193e-01, time/batch = 15.3436s	
26989/33250 (epoch 40.585), train_loss = 0.84944886, grad/param norm = 1.5736e-01, time/batch = 14.7543s	
26990/33250 (epoch 40.586), train_loss = 0.73136208, grad/param norm = 1.9035e-01, time/batch = 14.7034s	
26991/33250 (epoch 40.588), train_loss = 0.81043620, grad/param norm = 1.5256e-01, time/batch = 14.0682s	
26992/33250 (epoch 40.589), train_loss = 0.75574884, grad/param norm = 1.7847e-01, time/batch = 14.6157s	
26993/33250 (epoch 40.591), train_loss = 0.75260959, grad/param norm = 1.8537e-01, time/batch = 14.6222s	
26994/33250 (epoch 40.592), train_loss = 0.74100987, grad/param norm = 1.8780e-01, time/batch = 14.0025s	
26995/33250 (epoch 40.594), train_loss = 0.88244719, grad/param norm = 2.1290e-01, time/batch = 14.3948s	
26996/33250 (epoch 40.595), train_loss = 0.75942872, grad/param norm = 1.6211e-01, time/batch = 14.3844s	
26997/33250 (epoch 40.597), train_loss = 0.63949943, grad/param norm = 1.4345e-01, time/batch = 14.4613s	
26998/33250 (epoch 40.598), train_loss = 0.73500540, grad/param norm = 2.6086e-01, time/batch = 14.2943s	
26999/33250 (epoch 40.600), train_loss = 0.73876925, grad/param norm = 1.9053e-01, time/batch = 15.2350s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch40.60_1.6866.t7	
27000/33250 (epoch 40.602), train_loss = 0.78763711, grad/param norm = 2.0380e-01, time/batch = 15.0289s	
27001/33250 (epoch 40.603), train_loss = 1.28406075, grad/param norm = 2.8121e-01, time/batch = 14.9530s	
27002/33250 (epoch 40.605), train_loss = 0.76739545, grad/param norm = 1.8825e-01, time/batch = 14.6425s	
27003/33250 (epoch 40.606), train_loss = 0.82470572, grad/param norm = 1.8950e-01, time/batch = 14.7720s	
27004/33250 (epoch 40.608), train_loss = 0.76940536, grad/param norm = 1.6318e-01, time/batch = 14.3013s	
27005/33250 (epoch 40.609), train_loss = 0.67278969, grad/param norm = 1.6796e-01, time/batch = 14.1301s	
27006/33250 (epoch 40.611), train_loss = 0.75127894, grad/param norm = 1.9212e-01, time/batch = 14.6365s	
27007/33250 (epoch 40.612), train_loss = 0.76197340, grad/param norm = 1.9810e-01, time/batch = 14.6408s	
27008/33250 (epoch 40.614), train_loss = 0.95680503, grad/param norm = 2.1495e-01, time/batch = 14.5661s	
27009/33250 (epoch 40.615), train_loss = 0.87895229, grad/param norm = 2.0140e-01, time/batch = 14.1536s	
27010/33250 (epoch 40.617), train_loss = 0.96696996, grad/param norm = 2.2270e-01, time/batch = 14.4796s	
27011/33250 (epoch 40.618), train_loss = 0.98171831, grad/param norm = 2.8492e-01, time/batch = 14.8525s	
27012/33250 (epoch 40.620), train_loss = 0.83545228, grad/param norm = 1.8068e-01, time/batch = 15.0835s	
27013/33250 (epoch 40.621), train_loss = 0.82093391, grad/param norm = 1.8693e-01, time/batch = 15.0100s	
27014/33250 (epoch 40.623), train_loss = 0.74220510, grad/param norm = 1.9236e-01, time/batch = 15.0454s	
27015/33250 (epoch 40.624), train_loss = 0.74729510, grad/param norm = 2.1590e-01, time/batch = 15.2318s	
27016/33250 (epoch 40.626), train_loss = 0.74433761, grad/param norm = 2.0994e-01, time/batch = 14.9240s	
27017/33250 (epoch 40.627), train_loss = 0.71614905, grad/param norm = 1.6404e-01, time/batch = 14.8562s	
27018/33250 (epoch 40.629), train_loss = 0.82264904, grad/param norm = 2.0468e-01, time/batch = 14.7145s	
27019/33250 (epoch 40.630), train_loss = 0.72269831, grad/param norm = 1.7675e-01, time/batch = 14.7225s	
27020/33250 (epoch 40.632), train_loss = 0.67077749, grad/param norm = 1.6477e-01, time/batch = 15.3106s	
27021/33250 (epoch 40.633), train_loss = 0.77970386, grad/param norm = 2.0227e-01, time/batch = 15.2999s	
27022/33250 (epoch 40.635), train_loss = 0.70719662, grad/param norm = 1.6406e-01, time/batch = 15.0242s	
27023/33250 (epoch 40.636), train_loss = 0.73103510, grad/param norm = 1.6156e-01, time/batch = 15.5111s	
27024/33250 (epoch 40.638), train_loss = 0.68122344, grad/param norm = 1.7596e-01, time/batch = 15.2592s	
27025/33250 (epoch 40.639), train_loss = 0.66625474, grad/param norm = 2.0425e-01, time/batch = 15.5772s	
27026/33250 (epoch 40.641), train_loss = 0.75795548, grad/param norm = 1.7774e-01, time/batch = 15.4234s	
27027/33250 (epoch 40.642), train_loss = 0.57953029, grad/param norm = 2.1732e-01, time/batch = 15.0357s	
27028/33250 (epoch 40.644), train_loss = 0.53764797, grad/param norm = 1.5257e-01, time/batch = 14.9645s	
27029/33250 (epoch 40.645), train_loss = 0.80603663, grad/param norm = 1.9811e-01, time/batch = 14.5782s	
27030/33250 (epoch 40.647), train_loss = 0.64533629, grad/param norm = 1.8837e-01, time/batch = 14.5738s	
27031/33250 (epoch 40.648), train_loss = 0.65403175, grad/param norm = 1.7189e-01, time/batch = 15.0384s	
27032/33250 (epoch 40.650), train_loss = 0.90508447, grad/param norm = 2.1718e-01, time/batch = 14.6195s	
27033/33250 (epoch 40.651), train_loss = 0.80809474, grad/param norm = 1.9766e-01, time/batch = 15.2400s	
27034/33250 (epoch 40.653), train_loss = 0.74289021, grad/param norm = 1.7552e-01, time/batch = 14.8625s	
27035/33250 (epoch 40.654), train_loss = 0.76421748, grad/param norm = 1.6866e-01, time/batch = 14.7638s	
27036/33250 (epoch 40.656), train_loss = 0.82655002, grad/param norm = 1.6601e-01, time/batch = 14.5518s	
27037/33250 (epoch 40.657), train_loss = 0.60315102, grad/param norm = 1.7662e-01, time/batch = 14.7674s	
27038/33250 (epoch 40.659), train_loss = 0.72771080, grad/param norm = 1.9030e-01, time/batch = 15.0246s	
27039/33250 (epoch 40.660), train_loss = 0.79303289, grad/param norm = 1.8923e-01, time/batch = 15.1106s	
27040/33250 (epoch 40.662), train_loss = 0.78554779, grad/param norm = 1.6854e-01, time/batch = 14.9600s	
27041/33250 (epoch 40.663), train_loss = 0.69850152, grad/param norm = 1.8242e-01, time/batch = 14.8092s	
27042/33250 (epoch 40.665), train_loss = 0.77947085, grad/param norm = 1.7470e-01, time/batch = 15.1322s	
27043/33250 (epoch 40.666), train_loss = 0.74269518, grad/param norm = 1.7217e-01, time/batch = 15.2756s	
27044/33250 (epoch 40.668), train_loss = 0.85704858, grad/param norm = 1.9055e-01, time/batch = 14.7812s	
27045/33250 (epoch 40.669), train_loss = 0.79281187, grad/param norm = 1.9273e-01, time/batch = 14.9522s	
27046/33250 (epoch 40.671), train_loss = 0.66704148, grad/param norm = 1.7816e-01, time/batch = 14.6398s	
27047/33250 (epoch 40.672), train_loss = 0.84309230, grad/param norm = 1.9554e-01, time/batch = 14.9396s	
27048/33250 (epoch 40.674), train_loss = 0.69730484, grad/param norm = 1.6618e-01, time/batch = 14.5376s	
27049/33250 (epoch 40.675), train_loss = 0.76828145, grad/param norm = 1.5430e-01, time/batch = 14.3834s	
27050/33250 (epoch 40.677), train_loss = 0.83392236, grad/param norm = 1.9764e-01, time/batch = 14.7756s	
27051/33250 (epoch 40.678), train_loss = 0.71147347, grad/param norm = 1.9061e-01, time/batch = 15.0024s	
27052/33250 (epoch 40.680), train_loss = 0.87628315, grad/param norm = 2.0930e-01, time/batch = 15.5655s	
27053/33250 (epoch 40.681), train_loss = 0.70772451, grad/param norm = 1.6334e-01, time/batch = 15.0123s	
27054/33250 (epoch 40.683), train_loss = 0.69495574, grad/param norm = 1.7865e-01, time/batch = 14.6634s	
27055/33250 (epoch 40.684), train_loss = 0.65361778, grad/param norm = 1.8161e-01, time/batch = 15.0975s	
27056/33250 (epoch 40.686), train_loss = 0.67421200, grad/param norm = 1.6719e-01, time/batch = 14.7814s	
27057/33250 (epoch 40.687), train_loss = 0.78596672, grad/param norm = 1.7881e-01, time/batch = 15.0985s	
27058/33250 (epoch 40.689), train_loss = 0.66269963, grad/param norm = 1.9463e-01, time/batch = 15.4059s	
27059/33250 (epoch 40.690), train_loss = 0.79977313, grad/param norm = 1.9134e-01, time/batch = 14.9260s	
27060/33250 (epoch 40.692), train_loss = 0.74741050, grad/param norm = 1.6870e-01, time/batch = 14.9306s	
27061/33250 (epoch 40.693), train_loss = 0.80281588, grad/param norm = 1.5474e-01, time/batch = 15.3985s	
27062/33250 (epoch 40.695), train_loss = 0.78642454, grad/param norm = 1.8265e-01, time/batch = 14.4790s	
27063/33250 (epoch 40.696), train_loss = 0.80817353, grad/param norm = 1.7761e-01, time/batch = 15.0312s	
27064/33250 (epoch 40.698), train_loss = 0.73953423, grad/param norm = 1.9580e-01, time/batch = 14.7976s	
27065/33250 (epoch 40.699), train_loss = 0.97279454, grad/param norm = 1.8456e-01, time/batch = 15.0490s	
27066/33250 (epoch 40.701), train_loss = 0.78078773, grad/param norm = 1.6070e-01, time/batch = 15.2676s	
27067/33250 (epoch 40.702), train_loss = 0.72227921, grad/param norm = 2.0082e-01, time/batch = 15.1919s	
27068/33250 (epoch 40.704), train_loss = 0.96537495, grad/param norm = 3.8978e-01, time/batch = 15.1621s	
27069/33250 (epoch 40.705), train_loss = 0.73670379, grad/param norm = 1.6380e-01, time/batch = 15.0253s	
27070/33250 (epoch 40.707), train_loss = 0.65900145, grad/param norm = 1.7089e-01, time/batch = 15.3163s	
27071/33250 (epoch 40.708), train_loss = 0.84477336, grad/param norm = 1.8874e-01, time/batch = 15.3257s	
27072/33250 (epoch 40.710), train_loss = 0.78791457, grad/param norm = 1.8421e-01, time/batch = 15.0238s	
27073/33250 (epoch 40.711), train_loss = 0.68364795, grad/param norm = 2.0314e-01, time/batch = 15.1200s	
27074/33250 (epoch 40.713), train_loss = 0.78624609, grad/param norm = 1.7901e-01, time/batch = 15.0998s	
27075/33250 (epoch 40.714), train_loss = 0.76557415, grad/param norm = 2.0393e-01, time/batch = 16.0466s	
27076/33250 (epoch 40.716), train_loss = 0.79028250, grad/param norm = 1.6947e-01, time/batch = 15.2306s	
27077/33250 (epoch 40.717), train_loss = 0.72256384, grad/param norm = 1.4508e-01, time/batch = 14.7930s	
27078/33250 (epoch 40.719), train_loss = 0.69637452, grad/param norm = 1.5878e-01, time/batch = 14.7867s	
27079/33250 (epoch 40.720), train_loss = 0.97861310, grad/param norm = 1.7164e-01, time/batch = 14.7111s	
27080/33250 (epoch 40.722), train_loss = 0.65751716, grad/param norm = 1.5235e-01, time/batch = 14.6310s	
27081/33250 (epoch 40.723), train_loss = 0.60297184, grad/param norm = 1.4183e-01, time/batch = 14.7061s	
27082/33250 (epoch 40.725), train_loss = 0.74720921, grad/param norm = 1.6455e-01, time/batch = 15.0210s	
27083/33250 (epoch 40.726), train_loss = 0.78636613, grad/param norm = 1.8241e-01, time/batch = 29.9811s	
27084/33250 (epoch 40.728), train_loss = 0.81390748, grad/param norm = 1.9880e-01, time/batch = 15.7317s	
27085/33250 (epoch 40.729), train_loss = 0.82848802, grad/param norm = 1.6770e-01, time/batch = 15.4596s	
27086/33250 (epoch 40.731), train_loss = 0.68715072, grad/param norm = 1.9320e-01, time/batch = 15.2722s	
27087/33250 (epoch 40.732), train_loss = 0.69564494, grad/param norm = 1.7427e-01, time/batch = 14.8659s	
27088/33250 (epoch 40.734), train_loss = 0.78365596, grad/param norm = 2.2226e-01, time/batch = 14.8636s	
27089/33250 (epoch 40.735), train_loss = 0.78403734, grad/param norm = 1.6672e-01, time/batch = 14.8718s	
27090/33250 (epoch 40.737), train_loss = 0.74621996, grad/param norm = 1.5091e-01, time/batch = 15.1800s	
27091/33250 (epoch 40.738), train_loss = 0.80504275, grad/param norm = 1.7203e-01, time/batch = 15.4389s	
27092/33250 (epoch 40.740), train_loss = 0.78883083, grad/param norm = 1.9293e-01, time/batch = 15.1964s	
27093/33250 (epoch 40.741), train_loss = 0.81381037, grad/param norm = 1.7178e-01, time/batch = 14.9580s	
27094/33250 (epoch 40.743), train_loss = 0.71900053, grad/param norm = 1.7205e-01, time/batch = 15.5147s	
27095/33250 (epoch 40.744), train_loss = 0.71962315, grad/param norm = 1.8688e-01, time/batch = 15.9472s	
27096/33250 (epoch 40.746), train_loss = 0.67619571, grad/param norm = 1.5162e-01, time/batch = 15.4228s	
27097/33250 (epoch 40.747), train_loss = 0.68156760, grad/param norm = 1.5445e-01, time/batch = 15.4336s	
27098/33250 (epoch 40.749), train_loss = 0.86878727, grad/param norm = 2.0392e-01, time/batch = 15.0709s	
27099/33250 (epoch 40.750), train_loss = 0.85940977, grad/param norm = 1.7236e-01, time/batch = 14.9160s	
27100/33250 (epoch 40.752), train_loss = 0.72459067, grad/param norm = 1.6622e-01, time/batch = 14.9305s	
27101/33250 (epoch 40.753), train_loss = 0.71438318, grad/param norm = 1.8140e-01, time/batch = 15.1866s	
27102/33250 (epoch 40.755), train_loss = 0.64537408, grad/param norm = 1.7399e-01, time/batch = 14.8673s	
27103/33250 (epoch 40.756), train_loss = 0.77599858, grad/param norm = 1.9611e-01, time/batch = 15.9979s	
27104/33250 (epoch 40.758), train_loss = 0.91331565, grad/param norm = 1.8947e-01, time/batch = 14.6275s	
27105/33250 (epoch 40.759), train_loss = 0.73012266, grad/param norm = 1.7165e-01, time/batch = 15.8042s	
27106/33250 (epoch 40.761), train_loss = 0.80407387, grad/param norm = 1.9133e-01, time/batch = 15.3787s	
27107/33250 (epoch 40.762), train_loss = 0.83252956, grad/param norm = 1.8403e-01, time/batch = 15.5680s	
27108/33250 (epoch 40.764), train_loss = 0.66912303, grad/param norm = 2.1631e-01, time/batch = 14.8644s	
27109/33250 (epoch 40.765), train_loss = 0.79350677, grad/param norm = 1.8942e-01, time/batch = 15.4072s	
27110/33250 (epoch 40.767), train_loss = 0.61644419, grad/param norm = 1.7635e-01, time/batch = 14.8600s	
27111/33250 (epoch 40.768), train_loss = 0.66148190, grad/param norm = 1.8331e-01, time/batch = 14.6227s	
27112/33250 (epoch 40.770), train_loss = 0.79013084, grad/param norm = 2.0139e-01, time/batch = 14.8464s	
27113/33250 (epoch 40.771), train_loss = 0.82119360, grad/param norm = 2.0268e-01, time/batch = 15.4243s	
27114/33250 (epoch 40.773), train_loss = 0.74167574, grad/param norm = 1.5617e-01, time/batch = 15.0396s	
27115/33250 (epoch 40.774), train_loss = 0.66120785, grad/param norm = 1.7969e-01, time/batch = 15.1194s	
27116/33250 (epoch 40.776), train_loss = 0.73297674, grad/param norm = 1.7678e-01, time/batch = 15.5486s	
27117/33250 (epoch 40.777), train_loss = 0.84797733, grad/param norm = 1.7515e-01, time/batch = 15.3822s	
27118/33250 (epoch 40.779), train_loss = 0.73697113, grad/param norm = 1.7694e-01, time/batch = 15.5448s	
27119/33250 (epoch 40.780), train_loss = 0.88143488, grad/param norm = 2.1898e-01, time/batch = 15.2595s	
27120/33250 (epoch 40.782), train_loss = 0.77187600, grad/param norm = 2.1157e-01, time/batch = 14.4597s	
27121/33250 (epoch 40.783), train_loss = 0.61744826, grad/param norm = 1.7524e-01, time/batch = 15.1061s	
27122/33250 (epoch 40.785), train_loss = 0.67661739, grad/param norm = 1.9003e-01, time/batch = 14.4313s	
27123/33250 (epoch 40.786), train_loss = 0.84066540, grad/param norm = 1.9212e-01, time/batch = 14.5469s	
27124/33250 (epoch 40.788), train_loss = 0.85462193, grad/param norm = 1.7213e-01, time/batch = 14.3601s	
27125/33250 (epoch 40.789), train_loss = 0.87064337, grad/param norm = 2.2622e-01, time/batch = 14.7868s	
27126/33250 (epoch 40.791), train_loss = 0.86633720, grad/param norm = 1.8860e-01, time/batch = 14.5433s	
27127/33250 (epoch 40.792), train_loss = 0.94234231, grad/param norm = 2.1399e-01, time/batch = 15.6238s	
27128/33250 (epoch 40.794), train_loss = 0.74863399, grad/param norm = 1.6745e-01, time/batch = 15.3877s	
27129/33250 (epoch 40.795), train_loss = 0.74594414, grad/param norm = 1.7196e-01, time/batch = 15.6788s	
27130/33250 (epoch 40.797), train_loss = 0.82550434, grad/param norm = 2.1213e-01, time/batch = 17.5393s	
27131/33250 (epoch 40.798), train_loss = 0.74776333, grad/param norm = 2.6117e-01, time/batch = 14.7154s	
27132/33250 (epoch 40.800), train_loss = 0.79912259, grad/param norm = 2.0573e-01, time/batch = 15.4202s	
27133/33250 (epoch 40.802), train_loss = 0.77180280, grad/param norm = 1.6769e-01, time/batch = 15.3446s	
27134/33250 (epoch 40.803), train_loss = 0.81045108, grad/param norm = 1.6845e-01, time/batch = 15.1083s	
27135/33250 (epoch 40.805), train_loss = 0.80811824, grad/param norm = 1.8369e-01, time/batch = 15.1712s	
27136/33250 (epoch 40.806), train_loss = 0.78038972, grad/param norm = 1.6190e-01, time/batch = 15.4874s	
27137/33250 (epoch 40.808), train_loss = 0.70256585, grad/param norm = 1.6635e-01, time/batch = 15.6109s	
27138/33250 (epoch 40.809), train_loss = 0.68199305, grad/param norm = 1.4792e-01, time/batch = 15.2811s	
27139/33250 (epoch 40.811), train_loss = 0.67747684, grad/param norm = 1.7293e-01, time/batch = 15.7360s	
27140/33250 (epoch 40.812), train_loss = 0.78786567, grad/param norm = 1.8245e-01, time/batch = 15.7803s	
27141/33250 (epoch 40.814), train_loss = 0.73044776, grad/param norm = 2.2272e-01, time/batch = 15.6731s	
27142/33250 (epoch 40.815), train_loss = 0.79101241, grad/param norm = 1.8752e-01, time/batch = 15.6625s	
27143/33250 (epoch 40.817), train_loss = 0.74091152, grad/param norm = 1.7256e-01, time/batch = 15.0097s	
27144/33250 (epoch 40.818), train_loss = 0.69514435, grad/param norm = 1.6605e-01, time/batch = 14.7862s	
27145/33250 (epoch 40.820), train_loss = 0.80090734, grad/param norm = 2.0928e-01, time/batch = 14.8529s	
27146/33250 (epoch 40.821), train_loss = 0.75952588, grad/param norm = 1.7228e-01, time/batch = 14.9594s	
27147/33250 (epoch 40.823), train_loss = 1.02513823, grad/param norm = 1.9993e-01, time/batch = 14.5560s	
27148/33250 (epoch 40.824), train_loss = 0.70358576, grad/param norm = 1.7965e-01, time/batch = 14.7866s	
27149/33250 (epoch 40.826), train_loss = 0.80117161, grad/param norm = 1.8187e-01, time/batch = 15.5094s	
27150/33250 (epoch 40.827), train_loss = 0.69476624, grad/param norm = 1.7379e-01, time/batch = 15.6212s	
27151/33250 (epoch 40.829), train_loss = 0.78934321, grad/param norm = 1.8330e-01, time/batch = 15.2236s	
27152/33250 (epoch 40.830), train_loss = 0.85274421, grad/param norm = 2.6427e-01, time/batch = 15.5725s	
27153/33250 (epoch 40.832), train_loss = 0.80526975, grad/param norm = 1.8265e-01, time/batch = 15.8700s	
27154/33250 (epoch 40.833), train_loss = 0.75077745, grad/param norm = 1.6255e-01, time/batch = 14.7779s	
27155/33250 (epoch 40.835), train_loss = 0.68183328, grad/param norm = 2.1788e-01, time/batch = 14.7820s	
27156/33250 (epoch 40.836), train_loss = 0.75312372, grad/param norm = 1.7121e-01, time/batch = 15.3315s	
27157/33250 (epoch 40.838), train_loss = 0.80220759, grad/param norm = 1.8474e-01, time/batch = 15.3570s	
27158/33250 (epoch 40.839), train_loss = 0.74351806, grad/param norm = 1.8685e-01, time/batch = 16.6005s	
27159/33250 (epoch 40.841), train_loss = 0.72170301, grad/param norm = 1.6175e-01, time/batch = 16.9376s	
27160/33250 (epoch 40.842), train_loss = 0.90270554, grad/param norm = 2.0158e-01, time/batch = 14.7809s	
27161/33250 (epoch 40.844), train_loss = 0.84551976, grad/param norm = 1.9128e-01, time/batch = 14.9829s	
27162/33250 (epoch 40.845), train_loss = 0.92697532, grad/param norm = 1.9706e-01, time/batch = 14.9050s	
27163/33250 (epoch 40.847), train_loss = 0.87980784, grad/param norm = 1.7752e-01, time/batch = 14.2462s	
27164/33250 (epoch 40.848), train_loss = 0.94671620, grad/param norm = 2.1747e-01, time/batch = 14.7234s	
27165/33250 (epoch 40.850), train_loss = 0.83961397, grad/param norm = 1.7705e-01, time/batch = 14.7939s	
27166/33250 (epoch 40.851), train_loss = 0.66274298, grad/param norm = 1.8156e-01, time/batch = 14.7893s	
27167/33250 (epoch 40.853), train_loss = 0.81002982, grad/param norm = 2.5602e-01, time/batch = 15.0167s	
27168/33250 (epoch 40.854), train_loss = 0.74616017, grad/param norm = 1.6806e-01, time/batch = 15.4073s	
27169/33250 (epoch 40.856), train_loss = 0.73588961, grad/param norm = 2.0388e-01, time/batch = 16.4308s	
27170/33250 (epoch 40.857), train_loss = 0.67154478, grad/param norm = 2.1007e-01, time/batch = 15.0744s	
27171/33250 (epoch 40.859), train_loss = 0.72856669, grad/param norm = 1.9980e-01, time/batch = 15.9491s	
27172/33250 (epoch 40.860), train_loss = 0.80676622, grad/param norm = 1.7489e-01, time/batch = 15.4430s	
27173/33250 (epoch 40.862), train_loss = 0.69317197, grad/param norm = 1.6519e-01, time/batch = 16.2992s	
27174/33250 (epoch 40.863), train_loss = 0.73437051, grad/param norm = 1.8515e-01, time/batch = 15.0525s	
27175/33250 (epoch 40.865), train_loss = 0.80221934, grad/param norm = 2.2001e-01, time/batch = 15.7885s	
27176/33250 (epoch 40.866), train_loss = 0.67670059, grad/param norm = 1.7814e-01, time/batch = 14.9389s	
27177/33250 (epoch 40.868), train_loss = 0.74910345, grad/param norm = 2.0108e-01, time/batch = 14.4653s	
27178/33250 (epoch 40.869), train_loss = 0.79557251, grad/param norm = 1.7906e-01, time/batch = 14.6057s	
27179/33250 (epoch 40.871), train_loss = 0.63456296, grad/param norm = 1.5496e-01, time/batch = 14.6291s	
27180/33250 (epoch 40.872), train_loss = 0.81652999, grad/param norm = 2.6224e-01, time/batch = 15.4841s	
27181/33250 (epoch 40.874), train_loss = 0.72173848, grad/param norm = 1.8663e-01, time/batch = 14.7200s	
27182/33250 (epoch 40.875), train_loss = 0.66648299, grad/param norm = 2.1794e-01, time/batch = 15.3216s	
27183/33250 (epoch 40.877), train_loss = 0.88022953, grad/param norm = 2.0866e-01, time/batch = 15.4838s	
27184/33250 (epoch 40.878), train_loss = 0.77944326, grad/param norm = 1.6193e-01, time/batch = 15.4708s	
27185/33250 (epoch 40.880), train_loss = 0.78084841, grad/param norm = 1.9297e-01, time/batch = 15.5444s	
27186/33250 (epoch 40.881), train_loss = 0.86439049, grad/param norm = 1.9309e-01, time/batch = 14.6423s	
27187/33250 (epoch 40.883), train_loss = 0.79523020, grad/param norm = 1.7263e-01, time/batch = 14.7852s	
27188/33250 (epoch 40.884), train_loss = 0.86008897, grad/param norm = 1.9442e-01, time/batch = 15.6316s	
27189/33250 (epoch 40.886), train_loss = 0.71353763, grad/param norm = 1.7217e-01, time/batch = 14.8007s	
27190/33250 (epoch 40.887), train_loss = 0.75578202, grad/param norm = 2.5890e-01, time/batch = 14.7028s	
27191/33250 (epoch 40.889), train_loss = 0.72599360, grad/param norm = 1.5008e-01, time/batch = 15.5741s	
27192/33250 (epoch 40.890), train_loss = 0.58490441, grad/param norm = 1.3742e-01, time/batch = 15.2056s	
27193/33250 (epoch 40.892), train_loss = 0.80818049, grad/param norm = 1.7318e-01, time/batch = 14.7932s	
27194/33250 (epoch 40.893), train_loss = 0.83525190, grad/param norm = 2.0680e-01, time/batch = 15.2929s	
27195/33250 (epoch 40.895), train_loss = 0.72013594, grad/param norm = 1.9598e-01, time/batch = 16.7749s	
27196/33250 (epoch 40.896), train_loss = 0.84199423, grad/param norm = 2.1163e-01, time/batch = 16.6191s	
27197/33250 (epoch 40.898), train_loss = 0.77350195, grad/param norm = 1.7569e-01, time/batch = 16.7770s	
27198/33250 (epoch 40.899), train_loss = 0.70859333, grad/param norm = 1.6333e-01, time/batch = 15.2776s	
27199/33250 (epoch 40.901), train_loss = 0.63107519, grad/param norm = 1.5619e-01, time/batch = 15.1983s	
27200/33250 (epoch 40.902), train_loss = 0.72237120, grad/param norm = 1.7246e-01, time/batch = 15.6074s	
27201/33250 (epoch 40.904), train_loss = 0.67898092, grad/param norm = 1.8539e-01, time/batch = 15.0494s	
27202/33250 (epoch 40.905), train_loss = 0.75260839, grad/param norm = 1.5335e-01, time/batch = 15.2056s	
27203/33250 (epoch 40.907), train_loss = 0.70100379, grad/param norm = 1.8889e-01, time/batch = 15.1737s	
27204/33250 (epoch 40.908), train_loss = 0.75657459, grad/param norm = 1.5318e-01, time/batch = 15.2641s	
27205/33250 (epoch 40.910), train_loss = 0.82158867, grad/param norm = 1.7978e-01, time/batch = 15.9609s	
27206/33250 (epoch 40.911), train_loss = 0.69656712, grad/param norm = 1.7731e-01, time/batch = 15.2242s	
27207/33250 (epoch 40.913), train_loss = 0.71856058, grad/param norm = 1.6568e-01, time/batch = 15.1139s	
27208/33250 (epoch 40.914), train_loss = 0.63760163, grad/param norm = 1.7033e-01, time/batch = 15.7480s	
27209/33250 (epoch 40.916), train_loss = 0.68045610, grad/param norm = 1.9518e-01, time/batch = 15.1288s	
27210/33250 (epoch 40.917), train_loss = 0.76754950, grad/param norm = 1.5092e-01, time/batch = 15.8696s	
27211/33250 (epoch 40.919), train_loss = 0.70492039, grad/param norm = 1.8400e-01, time/batch = 15.3562s	
27212/33250 (epoch 40.920), train_loss = 0.77391567, grad/param norm = 1.7847e-01, time/batch = 15.3795s	
27213/33250 (epoch 40.922), train_loss = 0.79099304, grad/param norm = 2.0751e-01, time/batch = 14.8678s	
27214/33250 (epoch 40.923), train_loss = 0.75921626, grad/param norm = 1.9925e-01, time/batch = 14.7686s	
27215/33250 (epoch 40.925), train_loss = 0.73717844, grad/param norm = 1.7917e-01, time/batch = 15.8892s	
27216/33250 (epoch 40.926), train_loss = 0.70729084, grad/param norm = 1.5707e-01, time/batch = 15.0204s	
27217/33250 (epoch 40.928), train_loss = 0.72655925, grad/param norm = 1.7202e-01, time/batch = 15.2051s	
27218/33250 (epoch 40.929), train_loss = 0.65620329, grad/param norm = 1.3554e-01, time/batch = 17.4048s	
27219/33250 (epoch 40.931), train_loss = 0.84530470, grad/param norm = 1.9125e-01, time/batch = 16.6935s	
27220/33250 (epoch 40.932), train_loss = 0.71898108, grad/param norm = 1.8540e-01, time/batch = 15.5397s	
27221/33250 (epoch 40.934), train_loss = 0.69469254, grad/param norm = 1.5517e-01, time/batch = 15.1927s	
27222/33250 (epoch 40.935), train_loss = 0.73542974, grad/param norm = 1.9411e-01, time/batch = 15.6968s	
27223/33250 (epoch 40.937), train_loss = 0.69577527, grad/param norm = 1.7505e-01, time/batch = 16.2853s	
27224/33250 (epoch 40.938), train_loss = 0.71997109, grad/param norm = 1.7081e-01, time/batch = 14.8848s	
27225/33250 (epoch 40.940), train_loss = 0.72306338, grad/param norm = 1.8021e-01, time/batch = 15.3955s	
27226/33250 (epoch 40.941), train_loss = 0.80530464, grad/param norm = 2.2547e-01, time/batch = 15.4608s	
27227/33250 (epoch 40.943), train_loss = 0.87859684, grad/param norm = 1.8159e-01, time/batch = 19.7458s	
27228/33250 (epoch 40.944), train_loss = 0.72399161, grad/param norm = 1.6132e-01, time/batch = 16.1274s	
27229/33250 (epoch 40.946), train_loss = 0.81947220, grad/param norm = 1.6951e-01, time/batch = 17.7817s	
27230/33250 (epoch 40.947), train_loss = 0.67673965, grad/param norm = 1.6489e-01, time/batch = 14.7970s	
27231/33250 (epoch 40.949), train_loss = 0.81612363, grad/param norm = 1.9800e-01, time/batch = 14.7928s	
27232/33250 (epoch 40.950), train_loss = 0.83426574, grad/param norm = 1.9308e-01, time/batch = 14.8067s	
27233/33250 (epoch 40.952), train_loss = 0.75694356, grad/param norm = 2.1374e-01, time/batch = 15.6125s	
27234/33250 (epoch 40.953), train_loss = 0.77204190, grad/param norm = 1.9556e-01, time/batch = 14.7826s	
27235/33250 (epoch 40.955), train_loss = 0.83303946, grad/param norm = 1.8492e-01, time/batch = 15.5436s	
27236/33250 (epoch 40.956), train_loss = 0.77263803, grad/param norm = 2.2318e-01, time/batch = 14.9335s	
27237/33250 (epoch 40.958), train_loss = 0.72595140, grad/param norm = 1.7544e-01, time/batch = 15.3535s	
27238/33250 (epoch 40.959), train_loss = 0.73637258, grad/param norm = 1.7294e-01, time/batch = 15.5175s	
27239/33250 (epoch 40.961), train_loss = 0.93865936, grad/param norm = 1.9578e-01, time/batch = 15.8328s	
27240/33250 (epoch 40.962), train_loss = 0.73449330, grad/param norm = 1.9189e-01, time/batch = 16.1046s	
27241/33250 (epoch 40.964), train_loss = 0.88346588, grad/param norm = 1.9860e-01, time/batch = 15.5994s	
27242/33250 (epoch 40.965), train_loss = 0.82827213, grad/param norm = 2.0448e-01, time/batch = 15.9302s	
27243/33250 (epoch 40.967), train_loss = 0.75255590, grad/param norm = 2.0570e-01, time/batch = 15.0296s	
27244/33250 (epoch 40.968), train_loss = 0.88510118, grad/param norm = 1.9337e-01, time/batch = 14.9490s	
27245/33250 (epoch 40.970), train_loss = 0.99367370, grad/param norm = 2.6564e-01, time/batch = 15.2586s	
27246/33250 (epoch 40.971), train_loss = 0.91676322, grad/param norm = 2.3847e-01, time/batch = 15.1705s	
27247/33250 (epoch 40.973), train_loss = 0.74277861, grad/param norm = 1.7091e-01, time/batch = 15.4526s	
27248/33250 (epoch 40.974), train_loss = 0.82557772, grad/param norm = 2.1212e-01, time/batch = 17.0475s	
27249/33250 (epoch 40.976), train_loss = 0.75797709, grad/param norm = 2.6959e-01, time/batch = 16.4604s	
27250/33250 (epoch 40.977), train_loss = 0.75408928, grad/param norm = 1.7955e-01, time/batch = 18.0296s	
27251/33250 (epoch 40.979), train_loss = 0.83027510, grad/param norm = 2.0053e-01, time/batch = 15.3504s	
27252/33250 (epoch 40.980), train_loss = 0.80234202, grad/param norm = 1.7100e-01, time/batch = 15.2893s	
27253/33250 (epoch 40.982), train_loss = 0.74980492, grad/param norm = 1.5936e-01, time/batch = 15.1279s	
27254/33250 (epoch 40.983), train_loss = 0.80849931, grad/param norm = 2.2209e-01, time/batch = 15.5966s	
27255/33250 (epoch 40.985), train_loss = 0.74010076, grad/param norm = 1.8993e-01, time/batch = 14.9525s	
27256/33250 (epoch 40.986), train_loss = 0.84386787, grad/param norm = 1.8425e-01, time/batch = 15.1048s	
27257/33250 (epoch 40.988), train_loss = 0.86961715, grad/param norm = 1.9260e-01, time/batch = 15.7026s	
27258/33250 (epoch 40.989), train_loss = 0.84831043, grad/param norm = 1.8741e-01, time/batch = 16.3612s	
27259/33250 (epoch 40.991), train_loss = 0.82720938, grad/param norm = 1.9431e-01, time/batch = 15.8770s	
27260/33250 (epoch 40.992), train_loss = 0.76537073, grad/param norm = 1.8113e-01, time/batch = 16.9566s	
27261/33250 (epoch 40.994), train_loss = 0.72079677, grad/param norm = 1.7122e-01, time/batch = 17.6745s	
27262/33250 (epoch 40.995), train_loss = 0.77485277, grad/param norm = 2.7306e-01, time/batch = 15.2324s	
27263/33250 (epoch 40.997), train_loss = 0.58410369, grad/param norm = 1.7602e-01, time/batch = 14.7141s	
27264/33250 (epoch 40.998), train_loss = 0.81239868, grad/param norm = 1.6935e-01, time/batch = 15.5619s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
27265/33250 (epoch 41.000), train_loss = 0.82617971, grad/param norm = 1.8726e-01, time/batch = 15.1692s	
27266/33250 (epoch 41.002), train_loss = 0.98236511, grad/param norm = 1.9037e-01, time/batch = 15.2476s	
27267/33250 (epoch 41.003), train_loss = 0.83391233, grad/param norm = 1.9122e-01, time/batch = 14.7679s	
27268/33250 (epoch 41.005), train_loss = 0.62295412, grad/param norm = 1.3664e-01, time/batch = 14.7152s	
27269/33250 (epoch 41.006), train_loss = 0.65695985, grad/param norm = 1.8172e-01, time/batch = 15.9774s	
27270/33250 (epoch 41.008), train_loss = 0.86023043, grad/param norm = 1.8003e-01, time/batch = 14.9036s	
27271/33250 (epoch 41.009), train_loss = 0.94770130, grad/param norm = 2.1451e-01, time/batch = 15.3762s	
27272/33250 (epoch 41.011), train_loss = 0.72946991, grad/param norm = 1.7852e-01, time/batch = 14.7827s	
27273/33250 (epoch 41.012), train_loss = 0.75787163, grad/param norm = 2.3133e-01, time/batch = 14.2223s	
27274/33250 (epoch 41.014), train_loss = 0.85165743, grad/param norm = 1.9780e-01, time/batch = 14.6922s	
27275/33250 (epoch 41.015), train_loss = 0.79042342, grad/param norm = 1.8180e-01, time/batch = 14.3854s	
27276/33250 (epoch 41.017), train_loss = 0.79246996, grad/param norm = 1.9631e-01, time/batch = 14.7759s	
27277/33250 (epoch 41.018), train_loss = 0.62735222, grad/param norm = 1.5352e-01, time/batch = 14.3079s	
27278/33250 (epoch 41.020), train_loss = 0.78537156, grad/param norm = 1.7716e-01, time/batch = 14.2913s	
27279/33250 (epoch 41.021), train_loss = 0.78667918, grad/param norm = 1.7157e-01, time/batch = 14.5489s	
27280/33250 (epoch 41.023), train_loss = 0.64518802, grad/param norm = 1.9265e-01, time/batch = 15.0938s	
27281/33250 (epoch 41.024), train_loss = 0.86474654, grad/param norm = 1.8484e-01, time/batch = 16.6909s	
27282/33250 (epoch 41.026), train_loss = 0.80365515, grad/param norm = 1.7076e-01, time/batch = 16.3815s	
27283/33250 (epoch 41.027), train_loss = 0.80570684, grad/param norm = 1.6657e-01, time/batch = 15.2090s	
27284/33250 (epoch 41.029), train_loss = 0.74761409, grad/param norm = 1.8474e-01, time/batch = 15.1878s	
27285/33250 (epoch 41.030), train_loss = 0.75532979, grad/param norm = 1.8887e-01, time/batch = 15.8553s	
27286/33250 (epoch 41.032), train_loss = 0.94308211, grad/param norm = 1.8569e-01, time/batch = 14.7885s	
27287/33250 (epoch 41.033), train_loss = 0.74488269, grad/param norm = 1.9805e-01, time/batch = 15.1901s	
27288/33250 (epoch 41.035), train_loss = 0.77299910, grad/param norm = 1.7407e-01, time/batch = 14.8705s	
27289/33250 (epoch 41.036), train_loss = 0.83091692, grad/param norm = 2.4903e-01, time/batch = 14.6281s	
27290/33250 (epoch 41.038), train_loss = 0.78231981, grad/param norm = 1.4777e-01, time/batch = 15.2868s	
27291/33250 (epoch 41.039), train_loss = 0.73795411, grad/param norm = 2.0068e-01, time/batch = 16.8461s	
27292/33250 (epoch 41.041), train_loss = 0.77933957, grad/param norm = 2.2835e-01, time/batch = 17.2068s	
27293/33250 (epoch 41.042), train_loss = 0.66961299, grad/param norm = 1.7248e-01, time/batch = 15.7340s	
27294/33250 (epoch 41.044), train_loss = 0.89194432, grad/param norm = 1.9921e-01, time/batch = 17.4616s	
27295/33250 (epoch 41.045), train_loss = 0.86865468, grad/param norm = 1.7431e-01, time/batch = 15.2574s	
27296/33250 (epoch 41.047), train_loss = 0.80616710, grad/param norm = 1.8960e-01, time/batch = 14.5508s	
27297/33250 (epoch 41.048), train_loss = 0.80784745, grad/param norm = 2.0690e-01, time/batch = 14.6320s	
27298/33250 (epoch 41.050), train_loss = 0.77766531, grad/param norm = 1.8804e-01, time/batch = 15.3922s	
27299/33250 (epoch 41.051), train_loss = 0.77845652, grad/param norm = 1.5372e-01, time/batch = 15.0155s	
27300/33250 (epoch 41.053), train_loss = 0.82945452, grad/param norm = 1.9022e-01, time/batch = 15.5665s	
27301/33250 (epoch 41.054), train_loss = 0.66737766, grad/param norm = 1.4827e-01, time/batch = 15.5660s	
27302/33250 (epoch 41.056), train_loss = 0.66267212, grad/param norm = 1.5374e-01, time/batch = 15.2848s	
27303/33250 (epoch 41.057), train_loss = 0.84692859, grad/param norm = 1.6746e-01, time/batch = 15.2622s	
27304/33250 (epoch 41.059), train_loss = 0.75264415, grad/param norm = 1.7803e-01, time/batch = 15.6314s	
27305/33250 (epoch 41.060), train_loss = 0.79360306, grad/param norm = 2.1943e-01, time/batch = 16.6184s	
27306/33250 (epoch 41.062), train_loss = 0.88216211, grad/param norm = 1.8855e-01, time/batch = 15.4379s	
27307/33250 (epoch 41.063), train_loss = 0.89500631, grad/param norm = 1.6459e-01, time/batch = 15.1973s	
27308/33250 (epoch 41.065), train_loss = 0.75378781, grad/param norm = 1.7663e-01, time/batch = 14.7938s	
27309/33250 (epoch 41.066), train_loss = 0.83201060, grad/param norm = 1.9794e-01, time/batch = 14.5506s	
27310/33250 (epoch 41.068), train_loss = 0.74313531, grad/param norm = 1.8218e-01, time/batch = 14.6322s	
27311/33250 (epoch 41.069), train_loss = 0.80830432, grad/param norm = 2.0606e-01, time/batch = 14.8721s	
27312/33250 (epoch 41.071), train_loss = 0.74155935, grad/param norm = 2.3491e-01, time/batch = 15.2840s	
27313/33250 (epoch 41.072), train_loss = 0.70277392, grad/param norm = 1.5966e-01, time/batch = 15.7208s	
27314/33250 (epoch 41.074), train_loss = 0.79634177, grad/param norm = 1.7213e-01, time/batch = 17.9861s	
27315/33250 (epoch 41.075), train_loss = 0.73084721, grad/param norm = 1.6749e-01, time/batch = 36.3143s	
27316/33250 (epoch 41.077), train_loss = 0.76731704, grad/param norm = 2.2288e-01, time/batch = 15.2602s	
27317/33250 (epoch 41.078), train_loss = 0.78007518, grad/param norm = 1.7867e-01, time/batch = 14.7857s	
27318/33250 (epoch 41.080), train_loss = 0.78494454, grad/param norm = 2.0585e-01, time/batch = 14.7059s	
27319/33250 (epoch 41.081), train_loss = 0.79877787, grad/param norm = 1.7077e-01, time/batch = 14.7897s	
27320/33250 (epoch 41.083), train_loss = 0.89242555, grad/param norm = 1.8354e-01, time/batch = 14.7970s	
27321/33250 (epoch 41.084), train_loss = 0.81969178, grad/param norm = 1.8816e-01, time/batch = 15.6280s	
27322/33250 (epoch 41.086), train_loss = 0.77435515, grad/param norm = 1.5957e-01, time/batch = 15.6632s	
27323/33250 (epoch 41.087), train_loss = 0.68170028, grad/param norm = 1.5024e-01, time/batch = 15.6589s	
27324/33250 (epoch 41.089), train_loss = 0.75237662, grad/param norm = 1.8404e-01, time/batch = 15.1280s	
27325/33250 (epoch 41.090), train_loss = 0.79625907, grad/param norm = 1.7845e-01, time/batch = 15.5839s	
27326/33250 (epoch 41.092), train_loss = 0.72981556, grad/param norm = 1.8495e-01, time/batch = 15.3976s	
27327/33250 (epoch 41.093), train_loss = 0.75621532, grad/param norm = 1.6735e-01, time/batch = 14.8625s	
27328/33250 (epoch 41.095), train_loss = 0.78004194, grad/param norm = 2.0088e-01, time/batch = 14.7913s	
27329/33250 (epoch 41.096), train_loss = 0.65881294, grad/param norm = 1.6833e-01, time/batch = 15.1060s	
27330/33250 (epoch 41.098), train_loss = 0.65602312, grad/param norm = 1.7993e-01, time/batch = 15.1204s	
27331/33250 (epoch 41.099), train_loss = 0.61801119, grad/param norm = 1.7556e-01, time/batch = 14.6917s	
27332/33250 (epoch 41.101), train_loss = 0.76878505, grad/param norm = 1.9474e-01, time/batch = 14.4792s	
27333/33250 (epoch 41.102), train_loss = 0.72031728, grad/param norm = 1.6885e-01, time/batch = 15.0038s	
27334/33250 (epoch 41.104), train_loss = 0.59273590, grad/param norm = 1.5884e-01, time/batch = 14.9689s	
27335/33250 (epoch 41.105), train_loss = 0.71889772, grad/param norm = 1.6538e-01, time/batch = 15.1343s	
27336/33250 (epoch 41.107), train_loss = 0.64775875, grad/param norm = 1.4618e-01, time/batch = 16.7890s	
27337/33250 (epoch 41.108), train_loss = 0.76802268, grad/param norm = 1.8029e-01, time/batch = 15.5311s	
27338/33250 (epoch 41.110), train_loss = 0.66175529, grad/param norm = 1.8270e-01, time/batch = 15.1360s	
27339/33250 (epoch 41.111), train_loss = 0.75338325, grad/param norm = 1.6499e-01, time/batch = 14.7065s	
27340/33250 (epoch 41.113), train_loss = 0.71766817, grad/param norm = 2.1198e-01, time/batch = 14.7979s	
27341/33250 (epoch 41.114), train_loss = 0.66479004, grad/param norm = 1.8288e-01, time/batch = 15.3373s	
27342/33250 (epoch 41.116), train_loss = 0.70176900, grad/param norm = 1.8818e-01, time/batch = 15.0081s	
27343/33250 (epoch 41.117), train_loss = 0.67861317, grad/param norm = 1.5975e-01, time/batch = 14.8697s	
27344/33250 (epoch 41.119), train_loss = 0.71355900, grad/param norm = 1.6562e-01, time/batch = 14.8692s	
27345/33250 (epoch 41.120), train_loss = 0.61590100, grad/param norm = 1.4024e-01, time/batch = 15.0502s	
27346/33250 (epoch 41.122), train_loss = 0.81509244, grad/param norm = 1.9832e-01, time/batch = 15.2923s	
27347/33250 (epoch 41.123), train_loss = 0.74444833, grad/param norm = 2.1312e-01, time/batch = 14.8200s	
27348/33250 (epoch 41.125), train_loss = 0.62511601, grad/param norm = 1.9905e-01, time/batch = 15.9377s	
27349/33250 (epoch 41.126), train_loss = 0.70367390, grad/param norm = 1.6164e-01, time/batch = 14.8737s	
27350/33250 (epoch 41.128), train_loss = 0.70566955, grad/param norm = 1.5208e-01, time/batch = 14.5455s	
27351/33250 (epoch 41.129), train_loss = 0.76420282, grad/param norm = 1.8826e-01, time/batch = 15.1775s	
27352/33250 (epoch 41.131), train_loss = 0.73660374, grad/param norm = 1.8430e-01, time/batch = 15.8680s	
27353/33250 (epoch 41.132), train_loss = 0.70668197, grad/param norm = 1.7499e-01, time/batch = 16.0816s	
27354/33250 (epoch 41.134), train_loss = 0.68196716, grad/param norm = 1.6063e-01, time/batch = 15.2783s	
27355/33250 (epoch 41.135), train_loss = 0.76979045, grad/param norm = 1.4960e-01, time/batch = 15.4792s	
27356/33250 (epoch 41.137), train_loss = 0.68489394, grad/param norm = 1.7822e-01, time/batch = 15.6934s	
27357/33250 (epoch 41.138), train_loss = 0.66308257, grad/param norm = 1.4964e-01, time/batch = 15.7841s	
27358/33250 (epoch 41.140), train_loss = 0.59917458, grad/param norm = 1.4811e-01, time/batch = 15.8377s	
27359/33250 (epoch 41.141), train_loss = 0.82088971, grad/param norm = 2.2470e-01, time/batch = 15.4925s	
27360/33250 (epoch 41.143), train_loss = 0.62957517, grad/param norm = 1.7620e-01, time/batch = 14.9328s	
27361/33250 (epoch 41.144), train_loss = 0.72857551, grad/param norm = 1.7451e-01, time/batch = 14.9957s	
27362/33250 (epoch 41.146), train_loss = 0.70229939, grad/param norm = 1.5761e-01, time/batch = 14.6260s	
27363/33250 (epoch 41.147), train_loss = 0.73055836, grad/param norm = 1.9617e-01, time/batch = 15.1006s	
27364/33250 (epoch 41.149), train_loss = 0.69768047, grad/param norm = 1.7010e-01, time/batch = 15.2671s	
27365/33250 (epoch 41.150), train_loss = 0.68081777, grad/param norm = 1.8415e-01, time/batch = 15.0319s	
27366/33250 (epoch 41.152), train_loss = 0.64627759, grad/param norm = 1.9860e-01, time/batch = 15.4687s	
27367/33250 (epoch 41.153), train_loss = 0.88171486, grad/param norm = 1.8681e-01, time/batch = 15.5443s	
27368/33250 (epoch 41.155), train_loss = 0.70539911, grad/param norm = 1.7301e-01, time/batch = 15.9572s	
27369/33250 (epoch 41.156), train_loss = 0.92734812, grad/param norm = 1.8662e-01, time/batch = 16.8584s	
27370/33250 (epoch 41.158), train_loss = 0.89414595, grad/param norm = 2.6385e-01, time/batch = 16.0545s	
27371/33250 (epoch 41.159), train_loss = 0.71257061, grad/param norm = 1.7928e-01, time/batch = 15.1091s	
27372/33250 (epoch 41.161), train_loss = 0.76394776, grad/param norm = 1.9044e-01, time/batch = 15.0975s	
27373/33250 (epoch 41.162), train_loss = 0.67482951, grad/param norm = 1.5976e-01, time/batch = 14.8605s	
27374/33250 (epoch 41.164), train_loss = 0.74588963, grad/param norm = 1.8664e-01, time/batch = 14.6348s	
27375/33250 (epoch 41.165), train_loss = 0.82691540, grad/param norm = 1.9910e-01, time/batch = 14.6920s	
27376/33250 (epoch 41.167), train_loss = 0.89464571, grad/param norm = 2.0916e-01, time/batch = 15.1117s	
27377/33250 (epoch 41.168), train_loss = 0.66530383, grad/param norm = 1.5963e-01, time/batch = 15.3871s	
27378/33250 (epoch 41.170), train_loss = 0.71267325, grad/param norm = 1.6231e-01, time/batch = 14.5330s	
27379/33250 (epoch 41.171), train_loss = 0.75671356, grad/param norm = 1.6967e-01, time/batch = 14.4102s	
27380/33250 (epoch 41.173), train_loss = 0.74215004, grad/param norm = 1.6898e-01, time/batch = 15.4031s	
27381/33250 (epoch 41.174), train_loss = 0.77783992, grad/param norm = 1.5401e-01, time/batch = 14.6897s	
27382/33250 (epoch 41.176), train_loss = 0.69050985, grad/param norm = 1.4604e-01, time/batch = 14.5172s	
27383/33250 (epoch 41.177), train_loss = 0.69019541, grad/param norm = 1.5358e-01, time/batch = 14.7738s	
27384/33250 (epoch 41.179), train_loss = 0.68586237, grad/param norm = 1.5583e-01, time/batch = 15.1532s	
27385/33250 (epoch 41.180), train_loss = 0.61823006, grad/param norm = 1.7414e-01, time/batch = 14.7068s	
27386/33250 (epoch 41.182), train_loss = 0.67215259, grad/param norm = 1.7876e-01, time/batch = 14.5445s	
27387/33250 (epoch 41.183), train_loss = 0.84810750, grad/param norm = 1.9743e-01, time/batch = 14.9579s	
27388/33250 (epoch 41.185), train_loss = 0.76738689, grad/param norm = 2.1195e-01, time/batch = 14.7862s	
27389/33250 (epoch 41.186), train_loss = 0.78549897, grad/param norm = 1.9637e-01, time/batch = 14.9721s	
27390/33250 (epoch 41.188), train_loss = 0.85040423, grad/param norm = 2.2107e-01, time/batch = 15.7049s	
27391/33250 (epoch 41.189), train_loss = 0.60482405, grad/param norm = 1.7429e-01, time/batch = 16.9587s	
27392/33250 (epoch 41.191), train_loss = 0.71725663, grad/param norm = 2.0852e-01, time/batch = 15.3783s	
27393/33250 (epoch 41.192), train_loss = 0.70207504, grad/param norm = 1.5806e-01, time/batch = 14.8674s	
27394/33250 (epoch 41.194), train_loss = 0.73203098, grad/param norm = 2.0080e-01, time/batch = 15.1805s	
27395/33250 (epoch 41.195), train_loss = 0.89924067, grad/param norm = 1.9994e-01, time/batch = 14.8692s	
27396/33250 (epoch 41.197), train_loss = 0.69682748, grad/param norm = 1.7404e-01, time/batch = 14.8733s	
27397/33250 (epoch 41.198), train_loss = 0.88530560, grad/param norm = 1.9475e-01, time/batch = 15.2391s	
27398/33250 (epoch 41.200), train_loss = 0.75176852, grad/param norm = 1.7853e-01, time/batch = 15.0209s	
27399/33250 (epoch 41.202), train_loss = 0.73331027, grad/param norm = 1.6923e-01, time/batch = 14.8494s	
27400/33250 (epoch 41.203), train_loss = 0.68106582, grad/param norm = 1.9719e-01, time/batch = 15.4245s	
27401/33250 (epoch 41.205), train_loss = 0.75676566, grad/param norm = 1.6122e-01, time/batch = 14.8995s	
27402/33250 (epoch 41.206), train_loss = 0.80617149, grad/param norm = 1.7217e-01, time/batch = 15.8060s	
27403/33250 (epoch 41.208), train_loss = 0.86831015, grad/param norm = 2.3379e-01, time/batch = 16.3688s	
27404/33250 (epoch 41.209), train_loss = 0.72454879, grad/param norm = 1.8803e-01, time/batch = 15.0235s	
27405/33250 (epoch 41.211), train_loss = 0.78471061, grad/param norm = 1.9474e-01, time/batch = 14.7172s	
27406/33250 (epoch 41.212), train_loss = 0.88066802, grad/param norm = 1.8962e-01, time/batch = 15.0807s	
27407/33250 (epoch 41.214), train_loss = 0.78427548, grad/param norm = 1.6777e-01, time/batch = 14.7195s	
27408/33250 (epoch 41.215), train_loss = 0.79861930, grad/param norm = 2.1932e-01, time/batch = 14.8872s	
27409/33250 (epoch 41.217), train_loss = 0.84256574, grad/param norm = 2.1804e-01, time/batch = 15.2854s	
27410/33250 (epoch 41.218), train_loss = 0.80818535, grad/param norm = 1.7011e-01, time/batch = 14.6929s	
27411/33250 (epoch 41.220), train_loss = 0.76942986, grad/param norm = 1.7827e-01, time/batch = 15.7737s	
27412/33250 (epoch 41.221), train_loss = 0.88094462, grad/param norm = 2.1548e-01, time/batch = 16.8802s	
27413/33250 (epoch 41.223), train_loss = 0.75946034, grad/param norm = 1.6855e-01, time/batch = 16.6050s	
27414/33250 (epoch 41.224), train_loss = 0.79830915, grad/param norm = 1.9205e-01, time/batch = 15.4792s	
27415/33250 (epoch 41.226), train_loss = 0.87961597, grad/param norm = 1.7420e-01, time/batch = 14.9387s	
27416/33250 (epoch 41.227), train_loss = 0.79737043, grad/param norm = 1.8215e-01, time/batch = 14.9500s	
27417/33250 (epoch 41.229), train_loss = 0.79009624, grad/param norm = 1.7499e-01, time/batch = 15.3792s	
27418/33250 (epoch 41.230), train_loss = 0.78687740, grad/param norm = 1.9099e-01, time/batch = 14.7146s	
27419/33250 (epoch 41.232), train_loss = 0.72415811, grad/param norm = 1.8194e-01, time/batch = 15.5207s	
27420/33250 (epoch 41.233), train_loss = 0.70189760, grad/param norm = 1.6506e-01, time/batch = 15.5081s	
27421/33250 (epoch 41.235), train_loss = 0.87585943, grad/param norm = 1.8076e-01, time/batch = 15.5541s	
27422/33250 (epoch 41.236), train_loss = 0.70193584, grad/param norm = 1.7820e-01, time/batch = 14.9742s	
27423/33250 (epoch 41.238), train_loss = 0.86813965, grad/param norm = 2.1736e-01, time/batch = 14.8806s	
27424/33250 (epoch 41.239), train_loss = 0.86405272, grad/param norm = 2.2467e-01, time/batch = 18.1245s	
27425/33250 (epoch 41.241), train_loss = 0.86913964, grad/param norm = 2.3498e-01, time/batch = 16.8740s	
27426/33250 (epoch 41.242), train_loss = 0.85839316, grad/param norm = 1.9732e-01, time/batch = 14.6324s	
27427/33250 (epoch 41.244), train_loss = 0.81215332, grad/param norm = 2.0917e-01, time/batch = 15.1214s	
27428/33250 (epoch 41.245), train_loss = 0.80111061, grad/param norm = 2.0157e-01, time/batch = 14.4697s	
27429/33250 (epoch 41.247), train_loss = 0.74797744, grad/param norm = 1.6832e-01, time/batch = 14.6344s	
27430/33250 (epoch 41.248), train_loss = 0.88320308, grad/param norm = 1.9756e-01, time/batch = 14.7750s	
27431/33250 (epoch 41.250), train_loss = 0.88911203, grad/param norm = 1.7294e-01, time/batch = 15.0212s	
27432/33250 (epoch 41.251), train_loss = 0.75499153, grad/param norm = 1.8724e-01, time/batch = 15.0353s	
27433/33250 (epoch 41.253), train_loss = 0.74947823, grad/param norm = 1.6153e-01, time/batch = 15.8652s	
27434/33250 (epoch 41.254), train_loss = 0.71203924, grad/param norm = 1.7312e-01, time/batch = 16.7886s	
27435/33250 (epoch 41.256), train_loss = 0.77688677, grad/param norm = 1.6278e-01, time/batch = 16.4590s	
27436/33250 (epoch 41.257), train_loss = 0.92324658, grad/param norm = 1.7928e-01, time/batch = 16.2950s	
27437/33250 (epoch 41.259), train_loss = 0.80703534, grad/param norm = 2.0472e-01, time/batch = 14.4729s	
27438/33250 (epoch 41.260), train_loss = 0.63165246, grad/param norm = 1.8779e-01, time/batch = 15.2832s	
27439/33250 (epoch 41.262), train_loss = 0.78579128, grad/param norm = 1.8901e-01, time/batch = 15.3400s	
27440/33250 (epoch 41.263), train_loss = 0.65781312, grad/param norm = 1.9420e-01, time/batch = 14.7960s	
27441/33250 (epoch 41.265), train_loss = 0.81164408, grad/param norm = 1.8226e-01, time/batch = 14.8030s	
27442/33250 (epoch 41.266), train_loss = 0.76555809, grad/param norm = 1.7660e-01, time/batch = 14.9458s	
27443/33250 (epoch 41.268), train_loss = 0.68181114, grad/param norm = 1.9033e-01, time/batch = 16.0423s	
27444/33250 (epoch 41.269), train_loss = 0.63359487, grad/param norm = 1.7152e-01, time/batch = 16.8057s	
27445/33250 (epoch 41.271), train_loss = 0.80941103, grad/param norm = 1.7232e-01, time/batch = 14.7309s	
27446/33250 (epoch 41.272), train_loss = 0.71033162, grad/param norm = 1.4663e-01, time/batch = 15.7906s	
27447/33250 (epoch 41.274), train_loss = 0.56344182, grad/param norm = 1.3919e-01, time/batch = 15.3076s	
27448/33250 (epoch 41.275), train_loss = 0.72280227, grad/param norm = 1.4700e-01, time/batch = 14.7868s	
27449/33250 (epoch 41.277), train_loss = 0.64625154, grad/param norm = 1.9510e-01, time/batch = 14.4653s	
27450/33250 (epoch 41.278), train_loss = 0.71286226, grad/param norm = 1.7049e-01, time/batch = 15.0068s	
27451/33250 (epoch 41.280), train_loss = 0.68038110, grad/param norm = 1.7878e-01, time/batch = 14.4670s	
27452/33250 (epoch 41.281), train_loss = 0.79614315, grad/param norm = 2.1098e-01, time/batch = 15.3538s	
27453/33250 (epoch 41.283), train_loss = 0.78724201, grad/param norm = 2.5074e-01, time/batch = 14.8523s	
27454/33250 (epoch 41.284), train_loss = 0.64904430, grad/param norm = 1.9465e-01, time/batch = 15.0430s	
27455/33250 (epoch 41.286), train_loss = 0.79153920, grad/param norm = 1.7129e-01, time/batch = 14.7989s	
27456/33250 (epoch 41.287), train_loss = 0.63152478, grad/param norm = 1.5328e-01, time/batch = 14.5692s	
27457/33250 (epoch 41.289), train_loss = 0.61588892, grad/param norm = 1.9284e-01, time/batch = 17.6234s	
27458/33250 (epoch 41.290), train_loss = 0.75554334, grad/param norm = 1.6383e-01, time/batch = 15.1031s	
27459/33250 (epoch 41.292), train_loss = 0.79370219, grad/param norm = 2.4281e-01, time/batch = 14.7247s	
27460/33250 (epoch 41.293), train_loss = 0.85018724, grad/param norm = 1.7343e-01, time/batch = 14.7193s	
27461/33250 (epoch 41.295), train_loss = 0.86675982, grad/param norm = 2.0322e-01, time/batch = 15.3552s	
27462/33250 (epoch 41.296), train_loss = 0.75722941, grad/param norm = 1.6887e-01, time/batch = 15.1142s	
27463/33250 (epoch 41.298), train_loss = 0.62604604, grad/param norm = 1.4464e-01, time/batch = 15.2295s	
27464/33250 (epoch 41.299), train_loss = 0.61407587, grad/param norm = 2.6916e-01, time/batch = 15.2032s	
27465/33250 (epoch 41.301), train_loss = 0.85254739, grad/param norm = 1.9322e-01, time/batch = 17.0367s	
27466/33250 (epoch 41.302), train_loss = 0.82776674, grad/param norm = 1.9848e-01, time/batch = 15.4045s	
27467/33250 (epoch 41.304), train_loss = 0.73537197, grad/param norm = 1.9614e-01, time/batch = 15.7878s	
27468/33250 (epoch 41.305), train_loss = 0.69444339, grad/param norm = 1.7123e-01, time/batch = 15.0488s	
27469/33250 (epoch 41.307), train_loss = 0.81889618, grad/param norm = 1.8450e-01, time/batch = 14.9416s	
27470/33250 (epoch 41.308), train_loss = 0.89190780, grad/param norm = 2.3169e-01, time/batch = 15.2107s	
27471/33250 (epoch 41.310), train_loss = 0.72499420, grad/param norm = 1.9195e-01, time/batch = 15.1095s	
27472/33250 (epoch 41.311), train_loss = 0.91445115, grad/param norm = 1.9851e-01, time/batch = 15.2667s	
27473/33250 (epoch 41.313), train_loss = 0.61815606, grad/param norm = 1.8798e-01, time/batch = 14.9631s	
27474/33250 (epoch 41.314), train_loss = 0.82611118, grad/param norm = 1.6661e-01, time/batch = 14.8733s	
27475/33250 (epoch 41.316), train_loss = 0.92550918, grad/param norm = 2.0794e-01, time/batch = 15.4573s	
27476/33250 (epoch 41.317), train_loss = 0.68783413, grad/param norm = 1.8079e-01, time/batch = 16.9638s	
27477/33250 (epoch 41.319), train_loss = 0.80798866, grad/param norm = 2.0806e-01, time/batch = 16.6008s	
27478/33250 (epoch 41.320), train_loss = 0.84189914, grad/param norm = 2.5276e-01, time/batch = 15.4548s	
27479/33250 (epoch 41.322), train_loss = 0.93741744, grad/param norm = 2.2724e-01, time/batch = 16.7861s	
27480/33250 (epoch 41.323), train_loss = 0.92209909, grad/param norm = 2.4632e-01, time/batch = 14.7956s	
27481/33250 (epoch 41.325), train_loss = 0.73533324, grad/param norm = 2.0310e-01, time/batch = 15.2576s	
27482/33250 (epoch 41.326), train_loss = 0.98200610, grad/param norm = 2.0520e-01, time/batch = 14.3038s	
27483/33250 (epoch 41.328), train_loss = 0.76536336, grad/param norm = 1.7297e-01, time/batch = 14.6077s	
27484/33250 (epoch 41.329), train_loss = 0.79445530, grad/param norm = 2.2254e-01, time/batch = 14.4678s	
27485/33250 (epoch 41.331), train_loss = 0.78921983, grad/param norm = 1.9931e-01, time/batch = 15.1013s	
27486/33250 (epoch 41.332), train_loss = 0.77890975, grad/param norm = 1.7229e-01, time/batch = 15.4827s	
27487/33250 (epoch 41.334), train_loss = 0.89894298, grad/param norm = 1.6742e-01, time/batch = 14.4770s	
27488/33250 (epoch 41.335), train_loss = 0.59765093, grad/param norm = 1.7762e-01, time/batch = 14.3290s	
27489/33250 (epoch 41.337), train_loss = 0.83506987, grad/param norm = 1.7930e-01, time/batch = 15.0128s	
27490/33250 (epoch 41.338), train_loss = 0.93074787, grad/param norm = 1.9102e-01, time/batch = 14.4550s	
27491/33250 (epoch 41.340), train_loss = 0.74421693, grad/param norm = 1.6508e-01, time/batch = 14.7721s	
27492/33250 (epoch 41.341), train_loss = 0.71176134, grad/param norm = 1.7454e-01, time/batch = 15.0180s	
27493/33250 (epoch 41.343), train_loss = 0.76141150, grad/param norm = 2.2830e-01, time/batch = 14.9504s	
27494/33250 (epoch 41.344), train_loss = 0.76023734, grad/param norm = 1.6920e-01, time/batch = 14.7184s	
27495/33250 (epoch 41.346), train_loss = 0.66325836, grad/param norm = 1.6902e-01, time/batch = 14.9574s	
27496/33250 (epoch 41.347), train_loss = 0.92723699, grad/param norm = 2.0255e-01, time/batch = 15.1215s	
27497/33250 (epoch 41.349), train_loss = 0.76713983, grad/param norm = 2.0040e-01, time/batch = 15.1800s	
27498/33250 (epoch 41.350), train_loss = 0.75175583, grad/param norm = 1.8515e-01, time/batch = 15.1589s	
27499/33250 (epoch 41.352), train_loss = 0.69268014, grad/param norm = 1.7702e-01, time/batch = 15.2517s	
27500/33250 (epoch 41.353), train_loss = 0.72611110, grad/param norm = 1.5553e-01, time/batch = 14.4756s	
27501/33250 (epoch 41.355), train_loss = 0.72115980, grad/param norm = 2.2285e-01, time/batch = 15.2122s	
27502/33250 (epoch 41.356), train_loss = 0.68929042, grad/param norm = 1.8467e-01, time/batch = 15.1700s	
27503/33250 (epoch 41.358), train_loss = 0.76119793, grad/param norm = 1.7716e-01, time/batch = 14.7019s	
27504/33250 (epoch 41.359), train_loss = 0.73035100, grad/param norm = 1.9784e-01, time/batch = 14.8615s	
27505/33250 (epoch 41.361), train_loss = 0.85996712, grad/param norm = 2.2860e-01, time/batch = 15.5488s	
27506/33250 (epoch 41.362), train_loss = 0.79495940, grad/param norm = 1.6551e-01, time/batch = 15.2407s	
27507/33250 (epoch 41.364), train_loss = 0.81794470, grad/param norm = 2.0249e-01, time/batch = 14.7652s	
27508/33250 (epoch 41.365), train_loss = 0.76629741, grad/param norm = 1.7010e-01, time/batch = 14.6979s	
27509/33250 (epoch 41.367), train_loss = 0.78950284, grad/param norm = 1.5991e-01, time/batch = 10.9832s	
27510/33250 (epoch 41.368), train_loss = 0.77231257, grad/param norm = 1.8858e-01, time/batch = 0.6870s	
27511/33250 (epoch 41.370), train_loss = 0.69383264, grad/param norm = 1.5718e-01, time/batch = 0.6888s	
27512/33250 (epoch 41.371), train_loss = 0.87421203, grad/param norm = 2.1290e-01, time/batch = 0.6825s	
27513/33250 (epoch 41.373), train_loss = 0.74094193, grad/param norm = 1.5004e-01, time/batch = 0.6649s	
27514/33250 (epoch 41.374), train_loss = 0.77599769, grad/param norm = 2.3180e-01, time/batch = 0.6882s	
27515/33250 (epoch 41.376), train_loss = 0.78539200, grad/param norm = 1.7035e-01, time/batch = 0.6872s	
27516/33250 (epoch 41.377), train_loss = 0.66922794, grad/param norm = 2.1212e-01, time/batch = 0.6724s	
27517/33250 (epoch 41.379), train_loss = 0.78342086, grad/param norm = 1.9211e-01, time/batch = 0.6626s	
27518/33250 (epoch 41.380), train_loss = 0.75791492, grad/param norm = 1.9216e-01, time/batch = 0.6569s	
27519/33250 (epoch 41.382), train_loss = 0.79633694, grad/param norm = 2.0548e-01, time/batch = 0.6533s	
27520/33250 (epoch 41.383), train_loss = 0.67315293, grad/param norm = 1.8446e-01, time/batch = 0.6608s	
27521/33250 (epoch 41.385), train_loss = 0.65863079, grad/param norm = 2.1301e-01, time/batch = 0.6635s	
27522/33250 (epoch 41.386), train_loss = 0.66906460, grad/param norm = 1.9107e-01, time/batch = 0.6565s	
27523/33250 (epoch 41.388), train_loss = 0.69997045, grad/param norm = 2.3235e-01, time/batch = 0.6659s	
27524/33250 (epoch 41.389), train_loss = 0.71087154, grad/param norm = 2.0730e-01, time/batch = 0.8451s	
27525/33250 (epoch 41.391), train_loss = 0.81429176, grad/param norm = 2.0709e-01, time/batch = 0.9961s	
27526/33250 (epoch 41.392), train_loss = 0.89056809, grad/param norm = 2.1311e-01, time/batch = 0.9827s	
27527/33250 (epoch 41.394), train_loss = 0.84764680, grad/param norm = 2.0234e-01, time/batch = 0.9958s	
27528/33250 (epoch 41.395), train_loss = 0.86436497, grad/param norm = 1.7938e-01, time/batch = 0.9893s	
27529/33250 (epoch 41.397), train_loss = 0.88563740, grad/param norm = 1.9635e-01, time/batch = 1.3637s	
27530/33250 (epoch 41.398), train_loss = 0.68507948, grad/param norm = 1.5486e-01, time/batch = 1.8240s	
27531/33250 (epoch 41.400), train_loss = 0.68488415, grad/param norm = 1.7034e-01, time/batch = 1.8134s	
27532/33250 (epoch 41.402), train_loss = 0.64676352, grad/param norm = 1.9493e-01, time/batch = 11.8965s	
27533/33250 (epoch 41.403), train_loss = 0.74997145, grad/param norm = 1.9538e-01, time/batch = 15.2544s	
27534/33250 (epoch 41.405), train_loss = 0.71225838, grad/param norm = 1.5802e-01, time/batch = 15.3454s	
27535/33250 (epoch 41.406), train_loss = 0.74423292, grad/param norm = 2.1259e-01, time/batch = 14.7019s	
27536/33250 (epoch 41.408), train_loss = 0.90869810, grad/param norm = 1.8349e-01, time/batch = 14.6355s	
27537/33250 (epoch 41.409), train_loss = 0.80887417, grad/param norm = 2.1616e-01, time/batch = 14.7872s	
27538/33250 (epoch 41.411), train_loss = 0.56192101, grad/param norm = 1.2724e-01, time/batch = 15.0239s	
27539/33250 (epoch 41.412), train_loss = 0.63459487, grad/param norm = 1.6420e-01, time/batch = 15.5143s	
27540/33250 (epoch 41.414), train_loss = 0.78733807, grad/param norm = 1.9614e-01, time/batch = 14.7019s	
27541/33250 (epoch 41.415), train_loss = 0.83555448, grad/param norm = 2.2325e-01, time/batch = 14.7127s	
27542/33250 (epoch 41.417), train_loss = 0.87441088, grad/param norm = 2.1954e-01, time/batch = 14.9999s	
27543/33250 (epoch 41.418), train_loss = 1.01179116, grad/param norm = 2.2917e-01, time/batch = 16.4680s	
27544/33250 (epoch 41.420), train_loss = 0.85971074, grad/param norm = 2.1444e-01, time/batch = 16.2038s	
27545/33250 (epoch 41.421), train_loss = 0.73500519, grad/param norm = 1.5928e-01, time/batch = 16.2916s	
27546/33250 (epoch 41.423), train_loss = 0.81234072, grad/param norm = 1.9564e-01, time/batch = 15.1156s	
27547/33250 (epoch 41.424), train_loss = 0.87341568, grad/param norm = 2.4370e-01, time/batch = 15.5533s	
27548/33250 (epoch 41.426), train_loss = 0.75293016, grad/param norm = 1.5321e-01, time/batch = 14.9553s	
27549/33250 (epoch 41.427), train_loss = 0.70802232, grad/param norm = 1.8119e-01, time/batch = 15.1157s	
27550/33250 (epoch 41.429), train_loss = 0.76871089, grad/param norm = 1.9654e-01, time/batch = 15.2691s	
27551/33250 (epoch 41.430), train_loss = 0.73223255, grad/param norm = 2.0692e-01, time/batch = 15.0453s	
27552/33250 (epoch 41.432), train_loss = 0.85527100, grad/param norm = 1.8476e-01, time/batch = 15.1011s	
27553/33250 (epoch 41.433), train_loss = 0.72570330, grad/param norm = 3.1506e-01, time/batch = 15.6983s	
27554/33250 (epoch 41.435), train_loss = 0.82943220, grad/param norm = 1.8613e-01, time/batch = 15.2732s	
27555/33250 (epoch 41.436), train_loss = 0.73386676, grad/param norm = 2.1068e-01, time/batch = 15.9313s	
27556/33250 (epoch 41.438), train_loss = 0.87759124, grad/param norm = 1.9922e-01, time/batch = 15.2549s	
27557/33250 (epoch 41.439), train_loss = 0.77800765, grad/param norm = 1.6868e-01, time/batch = 14.9293s	
27558/33250 (epoch 41.441), train_loss = 0.75840784, grad/param norm = 1.7394e-01, time/batch = 15.3141s	
27559/33250 (epoch 41.442), train_loss = 0.69219750, grad/param norm = 2.0569e-01, time/batch = 14.7902s	
27560/33250 (epoch 41.444), train_loss = 0.73143507, grad/param norm = 1.6456e-01, time/batch = 14.8874s	
27561/33250 (epoch 41.445), train_loss = 0.78674750, grad/param norm = 1.4571e-01, time/batch = 15.0338s	
27562/33250 (epoch 41.447), train_loss = 0.69331050, grad/param norm = 1.6858e-01, time/batch = 15.3439s	
27563/33250 (epoch 41.448), train_loss = 0.80546137, grad/param norm = 1.5805e-01, time/batch = 15.4188s	
27564/33250 (epoch 41.450), train_loss = 0.87284087, grad/param norm = 2.1429e-01, time/batch = 15.6343s	
27565/33250 (epoch 41.451), train_loss = 0.85016709, grad/param norm = 3.1061e-01, time/batch = 15.4261s	
27566/33250 (epoch 41.453), train_loss = 0.67076784, grad/param norm = 1.4519e-01, time/batch = 15.1339s	
27567/33250 (epoch 41.454), train_loss = 0.90753635, grad/param norm = 2.0810e-01, time/batch = 15.5482s	
27568/33250 (epoch 41.456), train_loss = 0.88867372, grad/param norm = 1.5831e-01, time/batch = 16.0138s	
27569/33250 (epoch 41.457), train_loss = 0.72478050, grad/param norm = 1.7786e-01, time/batch = 21.1527s	
27570/33250 (epoch 41.459), train_loss = 0.84939665, grad/param norm = 1.6788e-01, time/batch = 22.5099s	
27571/33250 (epoch 41.460), train_loss = 0.84242061, grad/param norm = 2.0617e-01, time/batch = 15.1257s	
27572/33250 (epoch 41.462), train_loss = 0.77914696, grad/param norm = 1.9086e-01, time/batch = 15.6448s	
27573/33250 (epoch 41.463), train_loss = 0.68721500, grad/param norm = 1.3846e-01, time/batch = 15.5836s	
27574/33250 (epoch 41.465), train_loss = 0.64696314, grad/param norm = 1.5599e-01, time/batch = 15.3708s	
27575/33250 (epoch 41.466), train_loss = 0.62779146, grad/param norm = 1.3383e-01, time/batch = 14.8834s	
27576/33250 (epoch 41.468), train_loss = 0.66680599, grad/param norm = 1.5182e-01, time/batch = 15.1925s	
27577/33250 (epoch 41.469), train_loss = 0.75703563, grad/param norm = 1.7731e-01, time/batch = 15.2808s	
27578/33250 (epoch 41.471), train_loss = 0.83231482, grad/param norm = 1.5181e-01, time/batch = 14.7907s	
27579/33250 (epoch 41.472), train_loss = 0.74904656, grad/param norm = 2.0553e-01, time/batch = 15.0921s	
27580/33250 (epoch 41.474), train_loss = 0.84191981, grad/param norm = 1.8001e-01, time/batch = 15.3403s	
27581/33250 (epoch 41.475), train_loss = 0.78736610, grad/param norm = 1.6336e-01, time/batch = 15.3588s	
27582/33250 (epoch 41.477), train_loss = 0.78696812, grad/param norm = 1.7775e-01, time/batch = 14.5391s	
27583/33250 (epoch 41.478), train_loss = 0.68493616, grad/param norm = 1.8381e-01, time/batch = 14.9498s	
27584/33250 (epoch 41.480), train_loss = 0.86812965, grad/param norm = 1.7162e-01, time/batch = 15.1849s	
27585/33250 (epoch 41.481), train_loss = 0.73066261, grad/param norm = 1.5781e-01, time/batch = 14.8533s	
27586/33250 (epoch 41.483), train_loss = 0.74553875, grad/param norm = 2.3036e-01, time/batch = 14.5537s	
27587/33250 (epoch 41.484), train_loss = 0.70131971, grad/param norm = 1.5482e-01, time/batch = 14.8716s	
27588/33250 (epoch 41.486), train_loss = 0.63701734, grad/param norm = 1.7944e-01, time/batch = 15.1077s	
27589/33250 (epoch 41.487), train_loss = 0.70048152, grad/param norm = 1.7708e-01, time/batch = 15.2708s	
27590/33250 (epoch 41.489), train_loss = 0.83278400, grad/param norm = 2.1040e-01, time/batch = 14.7845s	
27591/33250 (epoch 41.490), train_loss = 0.79046103, grad/param norm = 2.1773e-01, time/batch = 14.7944s	
27592/33250 (epoch 41.492), train_loss = 0.83284204, grad/param norm = 1.7678e-01, time/batch = 15.2690s	
27593/33250 (epoch 41.493), train_loss = 0.76209945, grad/param norm = 1.8376e-01, time/batch = 14.9476s	
27594/33250 (epoch 41.495), train_loss = 0.83085762, grad/param norm = 1.5530e-01, time/batch = 15.1788s	
27595/33250 (epoch 41.496), train_loss = 0.77723951, grad/param norm = 1.5368e-01, time/batch = 15.2549s	
27596/33250 (epoch 41.498), train_loss = 0.83727409, grad/param norm = 1.9636e-01, time/batch = 15.4999s	
27597/33250 (epoch 41.499), train_loss = 0.71881286, grad/param norm = 1.8421e-01, time/batch = 15.6460s	
27598/33250 (epoch 41.501), train_loss = 0.73726335, grad/param norm = 1.9664e-01, time/batch = 15.7220s	
27599/33250 (epoch 41.502), train_loss = 0.72526429, grad/param norm = 1.5825e-01, time/batch = 15.3526s	
27600/33250 (epoch 41.504), train_loss = 0.90622383, grad/param norm = 2.2703e-01, time/batch = 15.3544s	
27601/33250 (epoch 41.505), train_loss = 0.65986104, grad/param norm = 1.3375e-01, time/batch = 15.0218s	
27602/33250 (epoch 41.507), train_loss = 0.70449710, grad/param norm = 1.7136e-01, time/batch = 14.6223s	
27603/33250 (epoch 41.508), train_loss = 0.74147893, grad/param norm = 1.6545e-01, time/batch = 14.6961s	
27604/33250 (epoch 41.510), train_loss = 0.64358957, grad/param norm = 1.6307e-01, time/batch = 14.8541s	
27605/33250 (epoch 41.511), train_loss = 0.74282548, grad/param norm = 1.9524e-01, time/batch = 14.8568s	
27606/33250 (epoch 41.513), train_loss = 0.87309186, grad/param norm = 1.8716e-01, time/batch = 14.7089s	
27607/33250 (epoch 41.514), train_loss = 0.72183561, grad/param norm = 1.6710e-01, time/batch = 14.9376s	
27608/33250 (epoch 41.516), train_loss = 0.69049966, grad/param norm = 1.8428e-01, time/batch = 15.3579s	
27609/33250 (epoch 41.517), train_loss = 0.73790527, grad/param norm = 1.6531e-01, time/batch = 14.8793s	
27610/33250 (epoch 41.519), train_loss = 0.68369682, grad/param norm = 1.3063e-01, time/batch = 14.4592s	
27611/33250 (epoch 41.520), train_loss = 0.93193787, grad/param norm = 1.9664e-01, time/batch = 14.5619s	
27612/33250 (epoch 41.522), train_loss = 0.78874645, grad/param norm = 1.7857e-01, time/batch = 15.1181s	
27613/33250 (epoch 41.523), train_loss = 0.69726963, grad/param norm = 1.8373e-01, time/batch = 14.7053s	
27614/33250 (epoch 41.525), train_loss = 0.65338669, grad/param norm = 1.9841e-01, time/batch = 14.9383s	
27615/33250 (epoch 41.526), train_loss = 0.66874104, grad/param norm = 1.7290e-01, time/batch = 14.4603s	
27616/33250 (epoch 41.528), train_loss = 0.71899515, grad/param norm = 1.9101e-01, time/batch = 15.1758s	
27617/33250 (epoch 41.529), train_loss = 0.70968935, grad/param norm = 1.8234e-01, time/batch = 15.1794s	
27618/33250 (epoch 41.531), train_loss = 0.67344484, grad/param norm = 1.5192e-01, time/batch = 15.9556s	
27619/33250 (epoch 41.532), train_loss = 0.79212557, grad/param norm = 1.6583e-01, time/batch = 15.1765s	
27620/33250 (epoch 41.534), train_loss = 0.69448745, grad/param norm = 1.6331e-01, time/batch = 15.4352s	
27621/33250 (epoch 41.535), train_loss = 0.73302545, grad/param norm = 1.6834e-01, time/batch = 14.9752s	
27622/33250 (epoch 41.537), train_loss = 0.77149290, grad/param norm = 1.6250e-01, time/batch = 15.2821s	
27623/33250 (epoch 41.538), train_loss = 0.82298560, grad/param norm = 1.8826e-01, time/batch = 14.5533s	
27624/33250 (epoch 41.540), train_loss = 0.89424950, grad/param norm = 1.5454e-01, time/batch = 14.9352s	
27625/33250 (epoch 41.541), train_loss = 0.81209154, grad/param norm = 1.9340e-01, time/batch = 14.5385s	
27626/33250 (epoch 41.543), train_loss = 0.80107064, grad/param norm = 1.5308e-01, time/batch = 14.4613s	
27627/33250 (epoch 41.544), train_loss = 0.68058065, grad/param norm = 1.8188e-01, time/batch = 14.7744s	
27628/33250 (epoch 41.546), train_loss = 0.71286814, grad/param norm = 1.9886e-01, time/batch = 15.1744s	
27629/33250 (epoch 41.547), train_loss = 0.73432909, grad/param norm = 1.9488e-01, time/batch = 14.7753s	
27630/33250 (epoch 41.549), train_loss = 0.77801613, grad/param norm = 1.8857e-01, time/batch = 15.0084s	
27631/33250 (epoch 41.550), train_loss = 0.73297050, grad/param norm = 1.6460e-01, time/batch = 14.8928s	
27632/33250 (epoch 41.552), train_loss = 0.79993665, grad/param norm = 1.6482e-01, time/batch = 15.6549s	
27633/33250 (epoch 41.553), train_loss = 0.74039516, grad/param norm = 1.6900e-01, time/batch = 15.5139s	
27634/33250 (epoch 41.555), train_loss = 0.75783844, grad/param norm = 1.6651e-01, time/batch = 14.8728s	
27635/33250 (epoch 41.556), train_loss = 0.78299312, grad/param norm = 2.1775e-01, time/batch = 14.7972s	
27636/33250 (epoch 41.558), train_loss = 0.79218572, grad/param norm = 1.8051e-01, time/batch = 15.3359s	
27637/33250 (epoch 41.559), train_loss = 0.70229620, grad/param norm = 1.7042e-01, time/batch = 14.5354s	
27638/33250 (epoch 41.561), train_loss = 0.64762934, grad/param norm = 1.5960e-01, time/batch = 14.7072s	
27639/33250 (epoch 41.562), train_loss = 0.75333726, grad/param norm = 1.8022e-01, time/batch = 14.8457s	
27640/33250 (epoch 41.564), train_loss = 0.93113700, grad/param norm = 2.2527e-01, time/batch = 15.3963s	
27641/33250 (epoch 41.565), train_loss = 0.86045491, grad/param norm = 2.3361e-01, time/batch = 14.9378s	
27642/33250 (epoch 41.567), train_loss = 0.85866937, grad/param norm = 1.8230e-01, time/batch = 15.1853s	
27643/33250 (epoch 41.568), train_loss = 0.73026615, grad/param norm = 1.6782e-01, time/batch = 15.1939s	
27644/33250 (epoch 41.570), train_loss = 0.82905000, grad/param norm = 1.8713e-01, time/batch = 15.2162s	
27645/33250 (epoch 41.571), train_loss = 0.86751099, grad/param norm = 2.0219e-01, time/batch = 15.2109s	
27646/33250 (epoch 41.573), train_loss = 0.80790997, grad/param norm = 1.8402e-01, time/batch = 14.9429s	
27647/33250 (epoch 41.574), train_loss = 0.69799117, grad/param norm = 1.5959e-01, time/batch = 15.1701s	
27648/33250 (epoch 41.576), train_loss = 0.78460172, grad/param norm = 1.7871e-01, time/batch = 15.4225s	
27649/33250 (epoch 41.577), train_loss = 0.74578712, grad/param norm = 1.7046e-01, time/batch = 15.4156s	
27650/33250 (epoch 41.579), train_loss = 0.65410129, grad/param norm = 1.8756e-01, time/batch = 15.2757s	
27651/33250 (epoch 41.580), train_loss = 0.76410439, grad/param norm = 1.7973e-01, time/batch = 15.1101s	
27652/33250 (epoch 41.582), train_loss = 0.73083296, grad/param norm = 1.7991e-01, time/batch = 15.2026s	
27653/33250 (epoch 41.583), train_loss = 0.82376137, grad/param norm = 1.8572e-01, time/batch = 15.6370s	
27654/33250 (epoch 41.585), train_loss = 0.84624363, grad/param norm = 1.6479e-01, time/batch = 14.6581s	
27655/33250 (epoch 41.586), train_loss = 0.72272461, grad/param norm = 2.1346e-01, time/batch = 16.2202s	
27656/33250 (epoch 41.588), train_loss = 0.80593067, grad/param norm = 1.7349e-01, time/batch = 16.8418s	
27657/33250 (epoch 41.589), train_loss = 0.76464862, grad/param norm = 2.0990e-01, time/batch = 15.7092s	
27658/33250 (epoch 41.591), train_loss = 0.76421449, grad/param norm = 2.0700e-01, time/batch = 15.0293s	
27659/33250 (epoch 41.592), train_loss = 0.75179856, grad/param norm = 2.0072e-01, time/batch = 15.1106s	
27660/33250 (epoch 41.594), train_loss = 0.86351893, grad/param norm = 2.1723e-01, time/batch = 15.4122s	
27661/33250 (epoch 41.595), train_loss = 0.76720997, grad/param norm = 1.8648e-01, time/batch = 15.3564s	
27662/33250 (epoch 41.597), train_loss = 0.64223550, grad/param norm = 1.5916e-01, time/batch = 15.4324s	
27663/33250 (epoch 41.598), train_loss = 0.73197551, grad/param norm = 1.9501e-01, time/batch = 15.1887s	
27664/33250 (epoch 41.600), train_loss = 0.72244680, grad/param norm = 1.8614e-01, time/batch = 14.8818s	
27665/33250 (epoch 41.602), train_loss = 0.77583022, grad/param norm = 1.9984e-01, time/batch = 15.0463s	
27666/33250 (epoch 41.603), train_loss = 0.81553257, grad/param norm = 2.0457e-01, time/batch = 15.0638s	
27667/33250 (epoch 41.605), train_loss = 0.76569006, grad/param norm = 1.8939e-01, time/batch = 15.2160s	
27668/33250 (epoch 41.606), train_loss = 0.80563097, grad/param norm = 1.8877e-01, time/batch = 15.2688s	
27669/33250 (epoch 41.608), train_loss = 0.76318260, grad/param norm = 1.6221e-01, time/batch = 15.0293s	
27670/33250 (epoch 41.609), train_loss = 0.66725582, grad/param norm = 1.6997e-01, time/batch = 14.9632s	
27671/33250 (epoch 41.611), train_loss = 0.73338942, grad/param norm = 1.8038e-01, time/batch = 15.2666s	
27672/33250 (epoch 41.612), train_loss = 0.74813285, grad/param norm = 1.7742e-01, time/batch = 14.8810s	
27673/33250 (epoch 41.614), train_loss = 0.93587910, grad/param norm = 2.0189e-01, time/batch = 15.1067s	
27674/33250 (epoch 41.615), train_loss = 0.86419841, grad/param norm = 1.7426e-01, time/batch = 15.4098s	
27675/33250 (epoch 41.617), train_loss = 0.96333197, grad/param norm = 2.1497e-01, time/batch = 15.5540s	
27676/33250 (epoch 41.618), train_loss = 0.97178351, grad/param norm = 2.4920e-01, time/batch = 15.4978s	
27677/33250 (epoch 41.620), train_loss = 0.82334421, grad/param norm = 1.7313e-01, time/batch = 15.8068s	
27678/33250 (epoch 41.621), train_loss = 0.83184802, grad/param norm = 1.7091e-01, time/batch = 16.2042s	
27679/33250 (epoch 41.623), train_loss = 0.73924797, grad/param norm = 1.8059e-01, time/batch = 15.2887s	
27680/33250 (epoch 41.624), train_loss = 0.74432520, grad/param norm = 1.9611e-01, time/batch = 15.7175s	
27681/33250 (epoch 41.626), train_loss = 0.75052904, grad/param norm = 2.0302e-01, time/batch = 15.4026s	
27682/33250 (epoch 41.627), train_loss = 0.72184013, grad/param norm = 1.6686e-01, time/batch = 15.0191s	
27683/33250 (epoch 41.629), train_loss = 0.82210046, grad/param norm = 2.0503e-01, time/batch = 15.1242s	
27684/33250 (epoch 41.630), train_loss = 0.71014370, grad/param norm = 1.9708e-01, time/batch = 15.0998s	
27685/33250 (epoch 41.632), train_loss = 0.66419775, grad/param norm = 1.7140e-01, time/batch = 15.3417s	
27686/33250 (epoch 41.633), train_loss = 0.79204650, grad/param norm = 2.0034e-01, time/batch = 15.3663s	
27687/33250 (epoch 41.635), train_loss = 0.69488417, grad/param norm = 1.5945e-01, time/batch = 15.2756s	
27688/33250 (epoch 41.636), train_loss = 0.71281376, grad/param norm = 1.5580e-01, time/batch = 15.3275s	
27689/33250 (epoch 41.638), train_loss = 0.68381731, grad/param norm = 2.1028e-01, time/batch = 15.5573s	
27690/33250 (epoch 41.639), train_loss = 0.65248075, grad/param norm = 1.8074e-01, time/batch = 15.2939s	
27691/33250 (epoch 41.641), train_loss = 0.74471372, grad/param norm = 1.6371e-01, time/batch = 15.5635s	
27692/33250 (epoch 41.642), train_loss = 0.57710304, grad/param norm = 1.8434e-01, time/batch = 15.0179s	
27693/33250 (epoch 41.644), train_loss = 0.51732296, grad/param norm = 1.4895e-01, time/batch = 14.7812s	
27694/33250 (epoch 41.645), train_loss = 0.79439237, grad/param norm = 2.1730e-01, time/batch = 14.9439s	
27695/33250 (epoch 41.647), train_loss = 0.63811762, grad/param norm = 1.8760e-01, time/batch = 15.6377s	
27696/33250 (epoch 41.648), train_loss = 0.63016810, grad/param norm = 1.7793e-01, time/batch = 14.8615s	
27697/33250 (epoch 41.650), train_loss = 0.87071865, grad/param norm = 2.1203e-01, time/batch = 15.5424s	
27698/33250 (epoch 41.651), train_loss = 0.79042185, grad/param norm = 2.2032e-01, time/batch = 14.8748s	
27699/33250 (epoch 41.653), train_loss = 0.73056096, grad/param norm = 1.8046e-01, time/batch = 15.1278s	
27700/33250 (epoch 41.654), train_loss = 0.75600929, grad/param norm = 1.6836e-01, time/batch = 15.0373s	
27701/33250 (epoch 41.656), train_loss = 0.81498529, grad/param norm = 1.5293e-01, time/batch = 15.3201s	
27702/33250 (epoch 41.657), train_loss = 0.59762786, grad/param norm = 1.7639e-01, time/batch = 15.0997s	
27703/33250 (epoch 41.659), train_loss = 0.73242143, grad/param norm = 1.8727e-01, time/batch = 14.9387s	
27704/33250 (epoch 41.660), train_loss = 0.77743858, grad/param norm = 1.9626e-01, time/batch = 14.6942s	
27705/33250 (epoch 41.662), train_loss = 0.77133286, grad/param norm = 1.7341e-01, time/batch = 14.4757s	
27706/33250 (epoch 41.663), train_loss = 0.68109793, grad/param norm = 1.9192e-01, time/batch = 15.1000s	
27707/33250 (epoch 41.665), train_loss = 0.79134812, grad/param norm = 1.9589e-01, time/batch = 14.9360s	
27708/33250 (epoch 41.666), train_loss = 0.73397151, grad/param norm = 1.5763e-01, time/batch = 14.8104s	
27709/33250 (epoch 41.668), train_loss = 0.84285152, grad/param norm = 2.0099e-01, time/batch = 14.6378s	
27710/33250 (epoch 41.669), train_loss = 0.78656719, grad/param norm = 1.9709e-01, time/batch = 14.7989s	
27711/33250 (epoch 41.671), train_loss = 0.66579242, grad/param norm = 1.8113e-01, time/batch = 16.3030s	
27712/33250 (epoch 41.672), train_loss = 0.83542467, grad/param norm = 1.9188e-01, time/batch = 14.7982s	
27713/33250 (epoch 41.674), train_loss = 0.69004046, grad/param norm = 1.7537e-01, time/batch = 14.5571s	
27714/33250 (epoch 41.675), train_loss = 0.76402873, grad/param norm = 1.4469e-01, time/batch = 14.8709s	
27715/33250 (epoch 41.677), train_loss = 0.80881651, grad/param norm = 1.8777e-01, time/batch = 15.1706s	
27716/33250 (epoch 41.678), train_loss = 0.69550080, grad/param norm = 1.9178e-01, time/batch = 14.9420s	
27717/33250 (epoch 41.680), train_loss = 0.87236130, grad/param norm = 2.3686e-01, time/batch = 14.8029s	
27718/33250 (epoch 41.681), train_loss = 0.68112239, grad/param norm = 1.5930e-01, time/batch = 14.7087s	
27719/33250 (epoch 41.683), train_loss = 0.71057634, grad/param norm = 1.8893e-01, time/batch = 16.0454s	
27720/33250 (epoch 41.684), train_loss = 0.64996342, grad/param norm = 1.8589e-01, time/batch = 15.9750s	
27721/33250 (epoch 41.686), train_loss = 0.66782839, grad/param norm = 2.1736e-01, time/batch = 18.0199s	
27722/33250 (epoch 41.687), train_loss = 0.77171908, grad/param norm = 1.8056e-01, time/batch = 16.4337s	
27723/33250 (epoch 41.689), train_loss = 0.65429519, grad/param norm = 1.7193e-01, time/batch = 14.9643s	
27724/33250 (epoch 41.690), train_loss = 0.79070886, grad/param norm = 1.9456e-01, time/batch = 15.1846s	
27725/33250 (epoch 41.692), train_loss = 0.71832288, grad/param norm = 1.5519e-01, time/batch = 15.0895s	
27726/33250 (epoch 41.693), train_loss = 0.80933247, grad/param norm = 1.7424e-01, time/batch = 15.5373s	
27727/33250 (epoch 41.695), train_loss = 0.77312547, grad/param norm = 1.7590e-01, time/batch = 14.5406s	
27728/33250 (epoch 41.696), train_loss = 0.79200599, grad/param norm = 1.7269e-01, time/batch = 14.5298s	
27729/33250 (epoch 41.698), train_loss = 0.71437985, grad/param norm = 1.7334e-01, time/batch = 14.9473s	
27730/33250 (epoch 41.699), train_loss = 0.94619138, grad/param norm = 1.7209e-01, time/batch = 15.3173s	
27731/33250 (epoch 41.701), train_loss = 0.76984770, grad/param norm = 1.5824e-01, time/batch = 14.4794s	
27732/33250 (epoch 41.702), train_loss = 0.71424059, grad/param norm = 1.9856e-01, time/batch = 15.0605s	
27733/33250 (epoch 41.704), train_loss = 0.93619598, grad/param norm = 3.0321e-01, time/batch = 15.6521s	
27734/33250 (epoch 41.705), train_loss = 0.73136293, grad/param norm = 2.1406e-01, time/batch = 15.5698s	
27735/33250 (epoch 41.707), train_loss = 0.65599107, grad/param norm = 1.5784e-01, time/batch = 15.2708s	
27736/33250 (epoch 41.708), train_loss = 0.85619700, grad/param norm = 2.3165e-01, time/batch = 15.2026s	
27737/33250 (epoch 41.710), train_loss = 0.77835541, grad/param norm = 1.8746e-01, time/batch = 15.0216s	
27738/33250 (epoch 41.711), train_loss = 0.67638078, grad/param norm = 1.7688e-01, time/batch = 15.0218s	
27739/33250 (epoch 41.713), train_loss = 0.79305944, grad/param norm = 1.7140e-01, time/batch = 14.9309s	
27740/33250 (epoch 41.714), train_loss = 0.74864912, grad/param norm = 1.9237e-01, time/batch = 15.0248s	
27741/33250 (epoch 41.716), train_loss = 0.78195856, grad/param norm = 1.7614e-01, time/batch = 17.1979s	
27742/33250 (epoch 41.717), train_loss = 0.72116352, grad/param norm = 1.4433e-01, time/batch = 15.2249s	
27743/33250 (epoch 41.719), train_loss = 0.69674263, grad/param norm = 1.6645e-01, time/batch = 15.0372s	
27744/33250 (epoch 41.720), train_loss = 0.98029833, grad/param norm = 1.8319e-01, time/batch = 15.0538s	
27745/33250 (epoch 41.722), train_loss = 0.65458561, grad/param norm = 1.6891e-01, time/batch = 15.5171s	
27746/33250 (epoch 41.723), train_loss = 0.60124310, grad/param norm = 1.4232e-01, time/batch = 14.5446s	
27747/33250 (epoch 41.725), train_loss = 0.74871985, grad/param norm = 1.4794e-01, time/batch = 14.6290s	
27748/33250 (epoch 41.726), train_loss = 0.77476950, grad/param norm = 1.7149e-01, time/batch = 15.1814s	
27749/33250 (epoch 41.728), train_loss = 0.79544393, grad/param norm = 1.8074e-01, time/batch = 15.0683s	
27750/33250 (epoch 41.729), train_loss = 0.81871083, grad/param norm = 1.7437e-01, time/batch = 15.5417s	
27751/33250 (epoch 41.731), train_loss = 0.66935150, grad/param norm = 1.8513e-01, time/batch = 14.8584s	
27752/33250 (epoch 41.732), train_loss = 0.68909629, grad/param norm = 1.5941e-01, time/batch = 15.1049s	
27753/33250 (epoch 41.734), train_loss = 0.77843038, grad/param norm = 2.0249e-01, time/batch = 15.3767s	
27754/33250 (epoch 41.735), train_loss = 0.77544499, grad/param norm = 1.8534e-01, time/batch = 15.0801s	
27755/33250 (epoch 41.737), train_loss = 0.73864434, grad/param norm = 1.5199e-01, time/batch = 14.8423s	
27756/33250 (epoch 41.738), train_loss = 0.78273647, grad/param norm = 1.7271e-01, time/batch = 15.0861s	
27757/33250 (epoch 41.740), train_loss = 0.76961472, grad/param norm = 1.7560e-01, time/batch = 14.9335s	
27758/33250 (epoch 41.741), train_loss = 0.79969596, grad/param norm = 1.6123e-01, time/batch = 15.0145s	
27759/33250 (epoch 41.743), train_loss = 0.71049727, grad/param norm = 1.6038e-01, time/batch = 14.7718s	
27760/33250 (epoch 41.744), train_loss = 0.70758818, grad/param norm = 1.7137e-01, time/batch = 14.9375s	
27761/33250 (epoch 41.746), train_loss = 0.67460290, grad/param norm = 1.6772e-01, time/batch = 15.1008s	
27762/33250 (epoch 41.747), train_loss = 0.67245411, grad/param norm = 1.5857e-01, time/batch = 15.8746s	
27763/33250 (epoch 41.749), train_loss = 0.86773155, grad/param norm = 1.8917e-01, time/batch = 15.2557s	
27764/33250 (epoch 41.750), train_loss = 0.86628303, grad/param norm = 1.8120e-01, time/batch = 17.6153s	
27765/33250 (epoch 41.752), train_loss = 0.72722116, grad/param norm = 1.7247e-01, time/batch = 15.1184s	
27766/33250 (epoch 41.753), train_loss = 0.72004526, grad/param norm = 2.2195e-01, time/batch = 15.3045s	
27767/33250 (epoch 41.755), train_loss = 0.64186164, grad/param norm = 1.9611e-01, time/batch = 14.9471s	
27768/33250 (epoch 41.756), train_loss = 0.75865600, grad/param norm = 1.6528e-01, time/batch = 14.7861s	
27769/33250 (epoch 41.758), train_loss = 0.89461168, grad/param norm = 1.6518e-01, time/batch = 15.2536s	
27770/33250 (epoch 41.759), train_loss = 0.71848076, grad/param norm = 1.6760e-01, time/batch = 15.0946s	
27771/33250 (epoch 41.761), train_loss = 0.79532815, grad/param norm = 2.0029e-01, time/batch = 15.3335s	
27772/33250 (epoch 41.762), train_loss = 0.83219996, grad/param norm = 1.8792e-01, time/batch = 15.2376s	
27773/33250 (epoch 41.764), train_loss = 0.65610641, grad/param norm = 1.7632e-01, time/batch = 15.4306s	
27774/33250 (epoch 41.765), train_loss = 0.78518747, grad/param norm = 2.0077e-01, time/batch = 15.4708s	
27775/33250 (epoch 41.767), train_loss = 0.60506239, grad/param norm = 1.6758e-01, time/batch = 15.6539s	
27776/33250 (epoch 41.768), train_loss = 0.64204582, grad/param norm = 1.7810e-01, time/batch = 14.8835s	
27777/33250 (epoch 41.770), train_loss = 0.78902810, grad/param norm = 1.9599e-01, time/batch = 15.2822s	
27778/33250 (epoch 41.771), train_loss = 0.82888320, grad/param norm = 2.1392e-01, time/batch = 14.7921s	
27779/33250 (epoch 41.773), train_loss = 0.74313147, grad/param norm = 1.8574e-01, time/batch = 14.6203s	
27780/33250 (epoch 41.774), train_loss = 0.64523861, grad/param norm = 2.3462e-01, time/batch = 14.9062s	
27781/33250 (epoch 41.776), train_loss = 0.72508781, grad/param norm = 1.7540e-01, time/batch = 14.9459s	
27782/33250 (epoch 41.777), train_loss = 0.86081487, grad/param norm = 1.8597e-01, time/batch = 14.3926s	
27783/33250 (epoch 41.779), train_loss = 0.74815315, grad/param norm = 2.1455e-01, time/batch = 14.2743s	
27784/33250 (epoch 41.780), train_loss = 0.86437760, grad/param norm = 2.0198e-01, time/batch = 14.2600s	
27785/33250 (epoch 41.782), train_loss = 0.76585211, grad/param norm = 2.0704e-01, time/batch = 15.6283s	
27786/33250 (epoch 41.783), train_loss = 0.60096128, grad/param norm = 1.5987e-01, time/batch = 15.8621s	
27787/33250 (epoch 41.785), train_loss = 0.67410364, grad/param norm = 1.7835e-01, time/batch = 14.6882s	
27788/33250 (epoch 41.786), train_loss = 0.83397771, grad/param norm = 1.9488e-01, time/batch = 14.9814s	
27789/33250 (epoch 41.788), train_loss = 0.86339924, grad/param norm = 1.8525e-01, time/batch = 15.2625s	
27790/33250 (epoch 41.789), train_loss = 0.86232223, grad/param norm = 2.0749e-01, time/batch = 15.0696s	
27791/33250 (epoch 41.791), train_loss = 0.88047760, grad/param norm = 2.2446e-01, time/batch = 14.5440s	
27792/33250 (epoch 41.792), train_loss = 0.94581205, grad/param norm = 2.0196e-01, time/batch = 14.8718s	
27793/33250 (epoch 41.794), train_loss = 0.73308172, grad/param norm = 1.7184e-01, time/batch = 15.0782s	
27794/33250 (epoch 41.795), train_loss = 0.72947254, grad/param norm = 1.6979e-01, time/batch = 14.6248s	
27795/33250 (epoch 41.797), train_loss = 0.81514340, grad/param norm = 1.9044e-01, time/batch = 14.9650s	
27796/33250 (epoch 41.798), train_loss = 0.74902814, grad/param norm = 2.2023e-01, time/batch = 15.9425s	
27797/33250 (epoch 41.800), train_loss = 0.78659770, grad/param norm = 1.9136e-01, time/batch = 15.7417s	
27798/33250 (epoch 41.802), train_loss = 0.77182364, grad/param norm = 1.7276e-01, time/batch = 15.5606s	
27799/33250 (epoch 41.803), train_loss = 0.81635387, grad/param norm = 1.7212e-01, time/batch = 15.2873s	
27800/33250 (epoch 41.805), train_loss = 0.80384200, grad/param norm = 1.6807e-01, time/batch = 15.6176s	
27801/33250 (epoch 41.806), train_loss = 0.78239521, grad/param norm = 1.8691e-01, time/batch = 15.3689s	
27802/33250 (epoch 41.808), train_loss = 0.70132665, grad/param norm = 1.7457e-01, time/batch = 15.0354s	
27803/33250 (epoch 41.809), train_loss = 0.67341841, grad/param norm = 1.4324e-01, time/batch = 14.7885s	
27804/33250 (epoch 41.811), train_loss = 0.66954602, grad/param norm = 1.8441e-01, time/batch = 19.5217s	
27805/33250 (epoch 41.812), train_loss = 0.79398701, grad/param norm = 2.2158e-01, time/batch = 24.4748s	
27806/33250 (epoch 41.814), train_loss = 0.70804799, grad/param norm = 1.8481e-01, time/batch = 15.3173s	
27807/33250 (epoch 41.815), train_loss = 0.79414065, grad/param norm = 1.7224e-01, time/batch = 14.7134s	
27808/33250 (epoch 41.817), train_loss = 0.74202659, grad/param norm = 1.6935e-01, time/batch = 15.2491s	
27809/33250 (epoch 41.818), train_loss = 0.69178689, grad/param norm = 1.8379e-01, time/batch = 14.9515s	
27810/33250 (epoch 41.820), train_loss = 0.79506852, grad/param norm = 1.8771e-01, time/batch = 14.8955s	
27811/33250 (epoch 41.821), train_loss = 0.75529666, grad/param norm = 1.5075e-01, time/batch = 15.0342s	
27812/33250 (epoch 41.823), train_loss = 1.00151850, grad/param norm = 1.9240e-01, time/batch = 15.2637s	
27813/33250 (epoch 41.824), train_loss = 0.69427661, grad/param norm = 1.6565e-01, time/batch = 14.9504s	
27814/33250 (epoch 41.826), train_loss = 0.78260763, grad/param norm = 1.9221e-01, time/batch = 14.7964s	
27815/33250 (epoch 41.827), train_loss = 0.69876390, grad/param norm = 1.8253e-01, time/batch = 14.9577s	
27816/33250 (epoch 41.829), train_loss = 0.78029639, grad/param norm = 1.7449e-01, time/batch = 15.2462s	
27817/33250 (epoch 41.830), train_loss = 0.81219876, grad/param norm = 2.0514e-01, time/batch = 14.6324s	
27818/33250 (epoch 41.832), train_loss = 0.78905247, grad/param norm = 1.8433e-01, time/batch = 15.1479s	
27819/33250 (epoch 41.833), train_loss = 0.75032485, grad/param norm = 1.7198e-01, time/batch = 15.2679s	
27820/33250 (epoch 41.835), train_loss = 0.68370535, grad/param norm = 2.1921e-01, time/batch = 15.3807s	
27821/33250 (epoch 41.836), train_loss = 0.74364581, grad/param norm = 1.6125e-01, time/batch = 15.3775s	
27822/33250 (epoch 41.838), train_loss = 0.79322584, grad/param norm = 1.8017e-01, time/batch = 15.0484s	
27823/33250 (epoch 41.839), train_loss = 0.74221070, grad/param norm = 1.9107e-01, time/batch = 15.0344s	
27824/33250 (epoch 41.841), train_loss = 0.71693952, grad/param norm = 1.6256e-01, time/batch = 14.9290s	
27825/33250 (epoch 41.842), train_loss = 0.88200321, grad/param norm = 2.0273e-01, time/batch = 14.5463s	
27826/33250 (epoch 41.844), train_loss = 0.82110457, grad/param norm = 1.8642e-01, time/batch = 14.8791s	
27827/33250 (epoch 41.845), train_loss = 0.91767600, grad/param norm = 2.2299e-01, time/batch = 15.0894s	
27828/33250 (epoch 41.847), train_loss = 0.87049803, grad/param norm = 1.8603e-01, time/batch = 15.1820s	
27829/33250 (epoch 41.848), train_loss = 0.93630757, grad/param norm = 2.0856e-01, time/batch = 15.6291s	
27830/33250 (epoch 41.850), train_loss = 0.84895529, grad/param norm = 2.0872e-01, time/batch = 15.4037s	
27831/33250 (epoch 41.851), train_loss = 0.66916968, grad/param norm = 2.0714e-01, time/batch = 15.2817s	
27832/33250 (epoch 41.853), train_loss = 0.78117961, grad/param norm = 2.3727e-01, time/batch = 15.4820s	
27833/33250 (epoch 41.854), train_loss = 0.73244180, grad/param norm = 1.6396e-01, time/batch = 15.1588s	
27834/33250 (epoch 41.856), train_loss = 0.73572606, grad/param norm = 2.1508e-01, time/batch = 14.9476s	
27835/33250 (epoch 41.857), train_loss = 0.65346852, grad/param norm = 1.9015e-01, time/batch = 15.1021s	
27836/33250 (epoch 41.859), train_loss = 0.72707911, grad/param norm = 1.9883e-01, time/batch = 14.6124s	
27837/33250 (epoch 41.860), train_loss = 0.79655629, grad/param norm = 1.8556e-01, time/batch = 14.7860s	
27838/33250 (epoch 41.862), train_loss = 0.69838927, grad/param norm = 1.8859e-01, time/batch = 14.9236s	
27839/33250 (epoch 41.863), train_loss = 0.71992190, grad/param norm = 1.9192e-01, time/batch = 15.0809s	
27840/33250 (epoch 41.865), train_loss = 0.76755604, grad/param norm = 1.7960e-01, time/batch = 14.7712s	
27841/33250 (epoch 41.866), train_loss = 0.70051095, grad/param norm = 3.2410e-01, time/batch = 14.9980s	
27842/33250 (epoch 41.868), train_loss = 0.75340867, grad/param norm = 2.1877e-01, time/batch = 15.3254s	
27843/33250 (epoch 41.869), train_loss = 0.78724102, grad/param norm = 1.7835e-01, time/batch = 15.4884s	
27844/33250 (epoch 41.871), train_loss = 0.61916431, grad/param norm = 1.4156e-01, time/batch = 15.0121s	
27845/33250 (epoch 41.872), train_loss = 0.79701453, grad/param norm = 1.7132e-01, time/batch = 15.1578s	
27846/33250 (epoch 41.874), train_loss = 0.70138259, grad/param norm = 1.7427e-01, time/batch = 15.5622s	
27847/33250 (epoch 41.875), train_loss = 0.66311130, grad/param norm = 2.5206e-01, time/batch = 15.4206s	
27848/33250 (epoch 41.877), train_loss = 0.85462619, grad/param norm = 1.7788e-01, time/batch = 14.6981s	
27849/33250 (epoch 41.878), train_loss = 0.76622916, grad/param norm = 1.5844e-01, time/batch = 14.9511s	
27850/33250 (epoch 41.880), train_loss = 0.76225029, grad/param norm = 1.9785e-01, time/batch = 15.3412s	
27851/33250 (epoch 41.881), train_loss = 0.88102953, grad/param norm = 2.0605e-01, time/batch = 15.3509s	
27852/33250 (epoch 41.883), train_loss = 0.78968423, grad/param norm = 1.7562e-01, time/batch = 19.2604s	
27853/33250 (epoch 41.884), train_loss = 0.85926916, grad/param norm = 2.0010e-01, time/batch = 16.2303s	
27854/33250 (epoch 41.886), train_loss = 0.69771578, grad/param norm = 1.6201e-01, time/batch = 15.7981s	
27855/33250 (epoch 41.887), train_loss = 0.71864032, grad/param norm = 1.7321e-01, time/batch = 14.4013s	
27856/33250 (epoch 41.889), train_loss = 0.73317788, grad/param norm = 1.5982e-01, time/batch = 14.7046s	
27857/33250 (epoch 41.890), train_loss = 0.58673823, grad/param norm = 1.4388e-01, time/batch = 14.9334s	
27858/33250 (epoch 41.892), train_loss = 0.79358070, grad/param norm = 1.7125e-01, time/batch = 15.1988s	
27859/33250 (epoch 41.893), train_loss = 0.80533979, grad/param norm = 1.8275e-01, time/batch = 14.7852s	
27860/33250 (epoch 41.895), train_loss = 0.69532447, grad/param norm = 1.6022e-01, time/batch = 14.7807s	
27861/33250 (epoch 41.896), train_loss = 0.81832624, grad/param norm = 1.7541e-01, time/batch = 15.2950s	
27862/33250 (epoch 41.898), train_loss = 0.76394996, grad/param norm = 1.6891e-01, time/batch = 15.4904s	
27863/33250 (epoch 41.899), train_loss = 0.71238201, grad/param norm = 1.6343e-01, time/batch = 15.4552s	
27864/33250 (epoch 41.901), train_loss = 0.62410334, grad/param norm = 1.4174e-01, time/batch = 14.7909s	
27865/33250 (epoch 41.902), train_loss = 0.70659661, grad/param norm = 1.8403e-01, time/batch = 15.0422s	
27866/33250 (epoch 41.904), train_loss = 0.66540239, grad/param norm = 1.5175e-01, time/batch = 14.9446s	
27867/33250 (epoch 41.905), train_loss = 0.74253395, grad/param norm = 1.5303e-01, time/batch = 15.3944s	
27868/33250 (epoch 41.907), train_loss = 0.69242620, grad/param norm = 1.9441e-01, time/batch = 14.6001s	
27869/33250 (epoch 41.908), train_loss = 0.74617562, grad/param norm = 1.4558e-01, time/batch = 15.3331s	
27870/33250 (epoch 41.910), train_loss = 0.81600247, grad/param norm = 1.9691e-01, time/batch = 15.2301s	
27871/33250 (epoch 41.911), train_loss = 0.67146104, grad/param norm = 1.7677e-01, time/batch = 15.4839s	
27872/33250 (epoch 41.913), train_loss = 0.71267018, grad/param norm = 1.5774e-01, time/batch = 14.9376s	
27873/33250 (epoch 41.914), train_loss = 0.62870036, grad/param norm = 1.5558e-01, time/batch = 14.7169s	
27874/33250 (epoch 41.916), train_loss = 0.66201822, grad/param norm = 1.6170e-01, time/batch = 14.8830s	
27875/33250 (epoch 41.917), train_loss = 0.76812088, grad/param norm = 1.4230e-01, time/batch = 15.0377s	
27876/33250 (epoch 41.919), train_loss = 0.69518989, grad/param norm = 2.1851e-01, time/batch = 14.6996s	
27877/33250 (epoch 41.920), train_loss = 0.75433030, grad/param norm = 1.8422e-01, time/batch = 14.5764s	
27878/33250 (epoch 41.922), train_loss = 0.76013280, grad/param norm = 1.8669e-01, time/batch = 15.0346s	
27879/33250 (epoch 41.923), train_loss = 0.74151205, grad/param norm = 1.9919e-01, time/batch = 15.2576s	
27880/33250 (epoch 41.925), train_loss = 0.73966491, grad/param norm = 1.9818e-01, time/batch = 14.7090s	
27881/33250 (epoch 41.926), train_loss = 0.70774047, grad/param norm = 1.6204e-01, time/batch = 14.8685s	
27882/33250 (epoch 41.928), train_loss = 0.73317751, grad/param norm = 1.9790e-01, time/batch = 14.9394s	
27883/33250 (epoch 41.929), train_loss = 0.65198931, grad/param norm = 1.3523e-01, time/batch = 14.9469s	
27884/33250 (epoch 41.931), train_loss = 0.83296508, grad/param norm = 1.7392e-01, time/batch = 15.4022s	
27885/33250 (epoch 41.932), train_loss = 0.68711296, grad/param norm = 1.8227e-01, time/batch = 15.0991s	
27886/33250 (epoch 41.934), train_loss = 0.68423532, grad/param norm = 1.4968e-01, time/batch = 15.9581s	
27887/33250 (epoch 41.935), train_loss = 0.72176077, grad/param norm = 1.9710e-01, time/batch = 17.4629s	
27888/33250 (epoch 41.937), train_loss = 0.68204810, grad/param norm = 1.7821e-01, time/batch = 15.6386s	
27889/33250 (epoch 41.938), train_loss = 0.71130809, grad/param norm = 2.0266e-01, time/batch = 16.2732s	
27890/33250 (epoch 41.940), train_loss = 0.72280658, grad/param norm = 1.8739e-01, time/batch = 15.2603s	
27891/33250 (epoch 41.941), train_loss = 0.78912797, grad/param norm = 1.7644e-01, time/batch = 15.2530s	
27892/33250 (epoch 41.943), train_loss = 0.87971286, grad/param norm = 1.9801e-01, time/batch = 15.2655s	
27893/33250 (epoch 41.944), train_loss = 0.72051739, grad/param norm = 1.7518e-01, time/batch = 14.4668s	
27894/33250 (epoch 41.946), train_loss = 0.83328803, grad/param norm = 2.2017e-01, time/batch = 15.1762s	
27895/33250 (epoch 41.947), train_loss = 0.67737447, grad/param norm = 2.0457e-01, time/batch = 14.6177s	
27896/33250 (epoch 41.949), train_loss = 0.80269383, grad/param norm = 1.8495e-01, time/batch = 15.3831s	
27897/33250 (epoch 41.950), train_loss = 0.81363777, grad/param norm = 1.7681e-01, time/batch = 16.2250s	
27898/33250 (epoch 41.952), train_loss = 0.76139616, grad/param norm = 1.9438e-01, time/batch = 15.5440s	
27899/33250 (epoch 41.953), train_loss = 0.78061710, grad/param norm = 2.1484e-01, time/batch = 15.3253s	
27900/33250 (epoch 41.955), train_loss = 0.81672135, grad/param norm = 1.7070e-01, time/batch = 14.8087s	
27901/33250 (epoch 41.956), train_loss = 0.75256535, grad/param norm = 2.1795e-01, time/batch = 15.6364s	
27902/33250 (epoch 41.958), train_loss = 0.71194379, grad/param norm = 1.5900e-01, time/batch = 15.5746s	
27903/33250 (epoch 41.959), train_loss = 0.71788015, grad/param norm = 1.6825e-01, time/batch = 14.9458s	
27904/33250 (epoch 41.961), train_loss = 0.93020351, grad/param norm = 1.9834e-01, time/batch = 15.1665s	
27905/33250 (epoch 41.962), train_loss = 0.72539210, grad/param norm = 1.8397e-01, time/batch = 15.1959s	
27906/33250 (epoch 41.964), train_loss = 0.85111094, grad/param norm = 1.8958e-01, time/batch = 14.8022s	
27907/33250 (epoch 41.965), train_loss = 0.81469348, grad/param norm = 1.9076e-01, time/batch = 15.2222s	
27908/33250 (epoch 41.967), train_loss = 0.73694929, grad/param norm = 1.9177e-01, time/batch = 16.5484s	
27909/33250 (epoch 41.968), train_loss = 0.86958144, grad/param norm = 1.6901e-01, time/batch = 16.7037s	
27910/33250 (epoch 41.970), train_loss = 0.97807024, grad/param norm = 2.5399e-01, time/batch = 15.2515s	
27911/33250 (epoch 41.971), train_loss = 0.92637493, grad/param norm = 2.5401e-01, time/batch = 15.5336s	
27912/33250 (epoch 41.973), train_loss = 0.74577544, grad/param norm = 1.6581e-01, time/batch = 15.1242s	
27913/33250 (epoch 41.974), train_loss = 0.82399986, grad/param norm = 1.9295e-01, time/batch = 14.6982s	
27914/33250 (epoch 41.976), train_loss = 0.72194138, grad/param norm = 1.8183e-01, time/batch = 14.5600s	
27915/33250 (epoch 41.977), train_loss = 0.75368486, grad/param norm = 1.7358e-01, time/batch = 14.7791s	
27916/33250 (epoch 41.979), train_loss = 0.82716577, grad/param norm = 1.9715e-01, time/batch = 14.5443s	
27917/33250 (epoch 41.980), train_loss = 0.80127598, grad/param norm = 1.7365e-01, time/batch = 14.7992s	
27918/33250 (epoch 41.982), train_loss = 0.73259446, grad/param norm = 1.5488e-01, time/batch = 15.5686s	
27919/33250 (epoch 41.983), train_loss = 0.80790072, grad/param norm = 2.2186e-01, time/batch = 15.1443s	
27920/33250 (epoch 41.985), train_loss = 0.72760170, grad/param norm = 1.9045e-01, time/batch = 16.0482s	
27921/33250 (epoch 41.986), train_loss = 0.83230329, grad/param norm = 2.7509e-01, time/batch = 15.6036s	
27922/33250 (epoch 41.988), train_loss = 0.87162085, grad/param norm = 2.0889e-01, time/batch = 15.2801s	
27923/33250 (epoch 41.989), train_loss = 0.83488024, grad/param norm = 1.9346e-01, time/batch = 14.6994s	
27924/33250 (epoch 41.991), train_loss = 0.84185934, grad/param norm = 2.0351e-01, time/batch = 14.6178s	
27925/33250 (epoch 41.992), train_loss = 0.75266846, grad/param norm = 1.9262e-01, time/batch = 15.1634s	
27926/33250 (epoch 41.994), train_loss = 0.71813431, grad/param norm = 1.7244e-01, time/batch = 14.8624s	
27927/33250 (epoch 41.995), train_loss = 0.77998554, grad/param norm = 3.0861e-01, time/batch = 14.6100s	
27928/33250 (epoch 41.997), train_loss = 0.58102146, grad/param norm = 1.5088e-01, time/batch = 14.5454s	
27929/33250 (epoch 41.998), train_loss = 0.80372562, grad/param norm = 1.7649e-01, time/batch = 15.3416s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
27930/33250 (epoch 42.000), train_loss = 0.82271930, grad/param norm = 1.8656e-01, time/batch = 15.3409s	
27931/33250 (epoch 42.002), train_loss = 0.98048917, grad/param norm = 1.8293e-01, time/batch = 15.5773s	
27932/33250 (epoch 42.003), train_loss = 0.82864970, grad/param norm = 2.0835e-01, time/batch = 15.2035s	
27933/33250 (epoch 42.005), train_loss = 0.63124383, grad/param norm = 1.5322e-01, time/batch = 15.4104s	
27934/33250 (epoch 42.006), train_loss = 0.66181914, grad/param norm = 2.0353e-01, time/batch = 14.4442s	
27935/33250 (epoch 42.008), train_loss = 0.84449977, grad/param norm = 1.9002e-01, time/batch = 14.7890s	
27936/33250 (epoch 42.009), train_loss = 0.92653815, grad/param norm = 1.8176e-01, time/batch = 15.1866s	
27937/33250 (epoch 42.011), train_loss = 0.72600665, grad/param norm = 1.6658e-01, time/batch = 15.0941s	
27938/33250 (epoch 42.012), train_loss = 0.74572759, grad/param norm = 1.9452e-01, time/batch = 15.0281s	
27939/33250 (epoch 42.014), train_loss = 0.85850861, grad/param norm = 2.2952e-01, time/batch = 15.0323s	
27940/33250 (epoch 42.015), train_loss = 0.79098988, grad/param norm = 1.7839e-01, time/batch = 15.4569s	
27941/33250 (epoch 42.017), train_loss = 0.78832628, grad/param norm = 1.9731e-01, time/batch = 15.4346s	
27942/33250 (epoch 42.018), train_loss = 0.61576783, grad/param norm = 1.6826e-01, time/batch = 17.0345s	
27943/33250 (epoch 42.020), train_loss = 0.77905425, grad/param norm = 1.6063e-01, time/batch = 16.3711s	
27944/33250 (epoch 42.021), train_loss = 0.77642816, grad/param norm = 1.6884e-01, time/batch = 14.3851s	
27945/33250 (epoch 42.023), train_loss = 0.64194457, grad/param norm = 2.0648e-01, time/batch = 15.1187s	
27946/33250 (epoch 42.024), train_loss = 0.85706231, grad/param norm = 2.1154e-01, time/batch = 14.8728s	
27947/33250 (epoch 42.026), train_loss = 0.80660729, grad/param norm = 1.8208e-01, time/batch = 14.9534s	
27948/33250 (epoch 42.027), train_loss = 0.80489083, grad/param norm = 2.0372e-01, time/batch = 15.5299s	
27949/33250 (epoch 42.029), train_loss = 0.73971005, grad/param norm = 1.6398e-01, time/batch = 15.0078s	
27950/33250 (epoch 42.030), train_loss = 0.75313729, grad/param norm = 1.8032e-01, time/batch = 14.8753s	
27951/33250 (epoch 42.032), train_loss = 0.93679016, grad/param norm = 2.5097e-01, time/batch = 16.7171s	
27952/33250 (epoch 42.033), train_loss = 0.74346082, grad/param norm = 2.0028e-01, time/batch = 15.5960s	
27953/33250 (epoch 42.035), train_loss = 0.78907841, grad/param norm = 1.9690e-01, time/batch = 14.9658s	
27954/33250 (epoch 42.036), train_loss = 0.80894702, grad/param norm = 2.0605e-01, time/batch = 14.8877s	
27955/33250 (epoch 42.038), train_loss = 0.78333266, grad/param norm = 1.6431e-01, time/batch = 15.2858s	
27956/33250 (epoch 42.039), train_loss = 0.71152781, grad/param norm = 1.6965e-01, time/batch = 14.8159s	
27957/33250 (epoch 42.041), train_loss = 0.79791256, grad/param norm = 2.5561e-01, time/batch = 14.9194s	
27958/33250 (epoch 42.042), train_loss = 0.67608404, grad/param norm = 1.6976e-01, time/batch = 14.9977s	
27959/33250 (epoch 42.044), train_loss = 0.87834589, grad/param norm = 1.9734e-01, time/batch = 15.3174s	
27960/33250 (epoch 42.045), train_loss = 0.87722644, grad/param norm = 2.0884e-01, time/batch = 14.9903s	
27961/33250 (epoch 42.047), train_loss = 0.80161675, grad/param norm = 1.7467e-01, time/batch = 15.2402s	
27962/33250 (epoch 42.048), train_loss = 0.80995620, grad/param norm = 2.1596e-01, time/batch = 15.3236s	
27963/33250 (epoch 42.050), train_loss = 0.76477491, grad/param norm = 1.8684e-01, time/batch = 15.6968s	
27964/33250 (epoch 42.051), train_loss = 0.76701207, grad/param norm = 1.8900e-01, time/batch = 15.7199s	
27965/33250 (epoch 42.053), train_loss = 0.82488651, grad/param norm = 1.9802e-01, time/batch = 16.8550s	
27966/33250 (epoch 42.054), train_loss = 0.66703878, grad/param norm = 1.7076e-01, time/batch = 14.9351s	
27967/33250 (epoch 42.056), train_loss = 0.65979739, grad/param norm = 1.6909e-01, time/batch = 14.6158s	
27968/33250 (epoch 42.057), train_loss = 0.84998160, grad/param norm = 1.7164e-01, time/batch = 15.2466s	
27969/33250 (epoch 42.059), train_loss = 0.73816701, grad/param norm = 1.6956e-01, time/batch = 15.3487s	
27970/33250 (epoch 42.060), train_loss = 0.79302770, grad/param norm = 2.0030e-01, time/batch = 15.2814s	
27971/33250 (epoch 42.062), train_loss = 0.85990280, grad/param norm = 1.8469e-01, time/batch = 14.7110s	
27972/33250 (epoch 42.063), train_loss = 0.88120823, grad/param norm = 1.7620e-01, time/batch = 15.0317s	
27973/33250 (epoch 42.065), train_loss = 0.76263509, grad/param norm = 1.9860e-01, time/batch = 15.6412s	
27974/33250 (epoch 42.066), train_loss = 0.83401034, grad/param norm = 1.9644e-01, time/batch = 17.0424s	
27975/33250 (epoch 42.068), train_loss = 0.74388183, grad/param norm = 1.9661e-01, time/batch = 15.9646s	
27976/33250 (epoch 42.069), train_loss = 0.79883763, grad/param norm = 2.0314e-01, time/batch = 15.3961s	
27977/33250 (epoch 42.071), train_loss = 0.73479826, grad/param norm = 1.5917e-01, time/batch = 14.6305s	
27978/33250 (epoch 42.072), train_loss = 0.69983107, grad/param norm = 1.8089e-01, time/batch = 14.8547s	
27979/33250 (epoch 42.074), train_loss = 0.78843748, grad/param norm = 1.7544e-01, time/batch = 14.2254s	
27980/33250 (epoch 42.075), train_loss = 0.73475654, grad/param norm = 1.9619e-01, time/batch = 15.4084s	
27981/33250 (epoch 42.077), train_loss = 0.76337474, grad/param norm = 2.1831e-01, time/batch = 14.9741s	
27982/33250 (epoch 42.078), train_loss = 0.77306894, grad/param norm = 1.8649e-01, time/batch = 14.8028s	
27983/33250 (epoch 42.080), train_loss = 0.76535778, grad/param norm = 1.9988e-01, time/batch = 14.5384s	
27984/33250 (epoch 42.081), train_loss = 0.79869093, grad/param norm = 1.9379e-01, time/batch = 15.7954s	
27985/33250 (epoch 42.083), train_loss = 0.88913243, grad/param norm = 1.9695e-01, time/batch = 16.0306s	
27986/33250 (epoch 42.084), train_loss = 0.80004231, grad/param norm = 1.8036e-01, time/batch = 14.9013s	
27987/33250 (epoch 42.086), train_loss = 0.77759976, grad/param norm = 1.6730e-01, time/batch = 15.2904s	
27988/33250 (epoch 42.087), train_loss = 0.67677882, grad/param norm = 1.7293e-01, time/batch = 14.9369s	
27989/33250 (epoch 42.089), train_loss = 0.74173682, grad/param norm = 1.8559e-01, time/batch = 14.8008s	
27990/33250 (epoch 42.090), train_loss = 0.79365371, grad/param norm = 1.8137e-01, time/batch = 15.4079s	
27991/33250 (epoch 42.092), train_loss = 0.73425454, grad/param norm = 1.6551e-01, time/batch = 14.9249s	
27992/33250 (epoch 42.093), train_loss = 0.75699041, grad/param norm = 1.6826e-01, time/batch = 14.8853s	
27993/33250 (epoch 42.095), train_loss = 0.77198875, grad/param norm = 1.9096e-01, time/batch = 15.0111s	
27994/33250 (epoch 42.096), train_loss = 0.65252081, grad/param norm = 1.9629e-01, time/batch = 14.9691s	
27995/33250 (epoch 42.098), train_loss = 0.66081653, grad/param norm = 2.0618e-01, time/batch = 14.9452s	
27996/33250 (epoch 42.099), train_loss = 0.60750938, grad/param norm = 2.0927e-01, time/batch = 14.8865s	
27997/33250 (epoch 42.101), train_loss = 0.76467803, grad/param norm = 2.1478e-01, time/batch = 15.8782s	
27998/33250 (epoch 42.102), train_loss = 0.70960988, grad/param norm = 1.6651e-01, time/batch = 16.1428s	
27999/33250 (epoch 42.104), train_loss = 0.59287554, grad/param norm = 1.6409e-01, time/batch = 15.1199s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch42.11_1.7087.t7	
28000/33250 (epoch 42.105), train_loss = 0.73286028, grad/param norm = 1.8402e-01, time/batch = 14.7848s	
28001/33250 (epoch 42.107), train_loss = 1.16984439, grad/param norm = 2.1567e-01, time/batch = 15.7908s	
28002/33250 (epoch 42.108), train_loss = 0.76146095, grad/param norm = 1.9566e-01, time/batch = 15.3587s	
28003/33250 (epoch 42.110), train_loss = 0.65263359, grad/param norm = 1.6381e-01, time/batch = 15.0272s	
28004/33250 (epoch 42.111), train_loss = 0.75667824, grad/param norm = 1.6858e-01, time/batch = 14.7966s	
28005/33250 (epoch 42.113), train_loss = 0.70587615, grad/param norm = 1.9676e-01, time/batch = 14.8673s	
28006/33250 (epoch 42.114), train_loss = 0.66600052, grad/param norm = 1.7873e-01, time/batch = 15.0994s	
28007/33250 (epoch 42.116), train_loss = 0.70027114, grad/param norm = 1.7954e-01, time/batch = 15.0421s	
28008/33250 (epoch 42.117), train_loss = 0.68062200, grad/param norm = 1.7334e-01, time/batch = 16.2981s	
28009/33250 (epoch 42.119), train_loss = 0.72014781, grad/param norm = 1.7249e-01, time/batch = 16.2328s	
28010/33250 (epoch 42.120), train_loss = 0.62585748, grad/param norm = 1.5290e-01, time/batch = 16.2435s	
28011/33250 (epoch 42.122), train_loss = 0.81685233, grad/param norm = 1.9783e-01, time/batch = 15.5694s	
28012/33250 (epoch 42.123), train_loss = 0.74468080, grad/param norm = 2.1322e-01, time/batch = 15.6568s	
28013/33250 (epoch 42.125), train_loss = 0.61997385, grad/param norm = 2.3067e-01, time/batch = 15.0409s	
28014/33250 (epoch 42.126), train_loss = 0.72213102, grad/param norm = 1.7778e-01, time/batch = 15.3471s	
28015/33250 (epoch 42.128), train_loss = 0.69198858, grad/param norm = 1.5446e-01, time/batch = 15.1648s	
28016/33250 (epoch 42.129), train_loss = 0.75483216, grad/param norm = 1.9654e-01, time/batch = 15.0726s	
28017/33250 (epoch 42.131), train_loss = 0.73325879, grad/param norm = 1.7103e-01, time/batch = 15.0142s	
28018/33250 (epoch 42.132), train_loss = 0.71212792, grad/param norm = 1.7376e-01, time/batch = 15.3919s	
28019/33250 (epoch 42.134), train_loss = 0.68172354, grad/param norm = 1.8225e-01, time/batch = 15.2250s	
28020/33250 (epoch 42.135), train_loss = 0.76743292, grad/param norm = 1.5412e-01, time/batch = 15.0897s	
28021/33250 (epoch 42.137), train_loss = 0.66428594, grad/param norm = 1.8401e-01, time/batch = 14.8778s	
28022/33250 (epoch 42.138), train_loss = 0.66175382, grad/param norm = 1.6940e-01, time/batch = 14.6420s	
28023/33250 (epoch 42.140), train_loss = 0.58901595, grad/param norm = 1.6218e-01, time/batch = 14.5407s	
28024/33250 (epoch 42.141), train_loss = 0.81830333, grad/param norm = 2.4253e-01, time/batch = 14.6463s	
28025/33250 (epoch 42.143), train_loss = 0.64473396, grad/param norm = 2.2533e-01, time/batch = 14.7121s	
28026/33250 (epoch 42.144), train_loss = 0.72100546, grad/param norm = 1.7906e-01, time/batch = 14.6327s	
28027/33250 (epoch 42.146), train_loss = 0.70471143, grad/param norm = 1.6784e-01, time/batch = 14.5517s	
28028/33250 (epoch 42.147), train_loss = 0.73123785, grad/param norm = 1.7148e-01, time/batch = 14.9289s	
28029/33250 (epoch 42.149), train_loss = 0.69224076, grad/param norm = 1.7885e-01, time/batch = 16.5004s	
28030/33250 (epoch 42.150), train_loss = 0.69000048, grad/param norm = 2.0098e-01, time/batch = 26.7192s	
28031/33250 (epoch 42.152), train_loss = 0.63146852, grad/param norm = 1.7785e-01, time/batch = 15.2234s	
28032/33250 (epoch 42.153), train_loss = 0.87307927, grad/param norm = 1.8394e-01, time/batch = 15.6288s	
28033/33250 (epoch 42.155), train_loss = 0.72643505, grad/param norm = 2.1769e-01, time/batch = 15.3058s	
28034/33250 (epoch 42.156), train_loss = 0.92863687, grad/param norm = 1.8809e-01, time/batch = 14.7731s	
28035/33250 (epoch 42.158), train_loss = 0.88893854, grad/param norm = 2.3695e-01, time/batch = 15.6302s	
28036/33250 (epoch 42.159), train_loss = 0.72060478, grad/param norm = 1.7647e-01, time/batch = 15.3101s	
28037/33250 (epoch 42.161), train_loss = 0.76153180, grad/param norm = 1.9659e-01, time/batch = 15.6434s	
28038/33250 (epoch 42.162), train_loss = 0.68100188, grad/param norm = 1.6497e-01, time/batch = 15.2446s	
28039/33250 (epoch 42.164), train_loss = 0.74917431, grad/param norm = 1.9567e-01, time/batch = 15.2749s	
28040/33250 (epoch 42.165), train_loss = 0.81830059, grad/param norm = 1.8535e-01, time/batch = 14.7786s	
28041/33250 (epoch 42.167), train_loss = 0.88614139, grad/param norm = 2.2116e-01, time/batch = 15.8225s	
28042/33250 (epoch 42.168), train_loss = 0.67462323, grad/param norm = 1.6142e-01, time/batch = 15.4687s	
28043/33250 (epoch 42.170), train_loss = 0.72378548, grad/param norm = 2.0459e-01, time/batch = 16.1332s	
28044/33250 (epoch 42.171), train_loss = 0.75178477, grad/param norm = 1.6354e-01, time/batch = 16.0210s	
28045/33250 (epoch 42.173), train_loss = 0.75199296, grad/param norm = 1.9218e-01, time/batch = 15.1181s	
28046/33250 (epoch 42.174), train_loss = 0.77428501, grad/param norm = 1.6103e-01, time/batch = 14.9588s	
28047/33250 (epoch 42.176), train_loss = 0.67750061, grad/param norm = 1.4693e-01, time/batch = 14.6333s	
28048/33250 (epoch 42.177), train_loss = 0.68867089, grad/param norm = 1.6671e-01, time/batch = 15.0961s	
28049/33250 (epoch 42.179), train_loss = 0.67191952, grad/param norm = 1.5645e-01, time/batch = 15.6321s	
28050/33250 (epoch 42.180), train_loss = 0.60754973, grad/param norm = 1.5325e-01, time/batch = 15.0733s	
28051/33250 (epoch 42.182), train_loss = 0.66715833, grad/param norm = 1.7585e-01, time/batch = 14.9457s	
28052/33250 (epoch 42.183), train_loss = 0.84320246, grad/param norm = 1.8935e-01, time/batch = 15.2961s	
28053/33250 (epoch 42.185), train_loss = 0.75571488, grad/param norm = 2.0239e-01, time/batch = 16.7920s	
28054/33250 (epoch 42.186), train_loss = 0.78416060, grad/param norm = 2.0206e-01, time/batch = 16.3029s	
28055/33250 (epoch 42.188), train_loss = 0.83381726, grad/param norm = 2.0711e-01, time/batch = 15.1474s	
28056/33250 (epoch 42.189), train_loss = 0.61073769, grad/param norm = 2.0465e-01, time/batch = 15.2664s	
28057/33250 (epoch 42.191), train_loss = 0.70846896, grad/param norm = 1.9601e-01, time/batch = 14.7878s	
28058/33250 (epoch 42.192), train_loss = 0.70320043, grad/param norm = 1.6230e-01, time/batch = 14.7909s	
28059/33250 (epoch 42.194), train_loss = 0.72087644, grad/param norm = 1.8410e-01, time/batch = 14.9373s	
28060/33250 (epoch 42.195), train_loss = 0.88764209, grad/param norm = 1.8661e-01, time/batch = 15.1080s	
28061/33250 (epoch 42.197), train_loss = 0.68952113, grad/param norm = 1.6500e-01, time/batch = 14.9591s	
28062/33250 (epoch 42.198), train_loss = 0.87797612, grad/param norm = 1.8370e-01, time/batch = 15.3258s	
28063/33250 (epoch 42.200), train_loss = 0.74549445, grad/param norm = 1.6752e-01, time/batch = 15.5836s	
28064/33250 (epoch 42.202), train_loss = 0.72908155, grad/param norm = 1.6645e-01, time/batch = 15.4640s	
28065/33250 (epoch 42.203), train_loss = 0.66708330, grad/param norm = 1.6452e-01, time/batch = 15.5798s	
28066/33250 (epoch 42.205), train_loss = 0.75788908, grad/param norm = 1.7371e-01, time/batch = 15.3924s	
28067/33250 (epoch 42.206), train_loss = 0.79857682, grad/param norm = 1.8459e-01, time/batch = 15.1799s	
28068/33250 (epoch 42.208), train_loss = 0.83021676, grad/param norm = 2.0296e-01, time/batch = 15.6343s	
28069/33250 (epoch 42.209), train_loss = 0.71415350, grad/param norm = 1.7396e-01, time/batch = 15.1011s	
28070/33250 (epoch 42.211), train_loss = 0.78222188, grad/param norm = 1.9341e-01, time/batch = 14.8883s	
28071/33250 (epoch 42.212), train_loss = 0.89024538, grad/param norm = 2.3224e-01, time/batch = 15.1882s	
28072/33250 (epoch 42.214), train_loss = 0.76846032, grad/param norm = 1.6242e-01, time/batch = 15.2540s	
28073/33250 (epoch 42.215), train_loss = 0.79340648, grad/param norm = 2.1168e-01, time/batch = 15.1909s	
28074/33250 (epoch 42.217), train_loss = 0.82095719, grad/param norm = 2.1936e-01, time/batch = 15.2032s	
28075/33250 (epoch 42.218), train_loss = 0.78693969, grad/param norm = 1.6238e-01, time/batch = 15.7896s	
28076/33250 (epoch 42.220), train_loss = 0.76891637, grad/param norm = 1.8040e-01, time/batch = 15.1859s	
28077/33250 (epoch 42.221), train_loss = 0.85816958, grad/param norm = 1.8708e-01, time/batch = 16.7134s	
28078/33250 (epoch 42.223), train_loss = 0.75641972, grad/param norm = 1.6065e-01, time/batch = 14.6385s	
28079/33250 (epoch 42.224), train_loss = 0.78875921, grad/param norm = 1.8300e-01, time/batch = 14.4593s	
28080/33250 (epoch 42.226), train_loss = 0.88872269, grad/param norm = 1.9595e-01, time/batch = 14.3046s	
28081/33250 (epoch 42.227), train_loss = 0.79128861, grad/param norm = 1.7638e-01, time/batch = 14.9505s	
28082/33250 (epoch 42.229), train_loss = 0.78648013, grad/param norm = 1.8406e-01, time/batch = 15.0256s	
28083/33250 (epoch 42.230), train_loss = 0.77384431, grad/param norm = 1.8092e-01, time/batch = 14.8454s	
28084/33250 (epoch 42.232), train_loss = 0.72716754, grad/param norm = 1.7255e-01, time/batch = 15.1852s	
28085/33250 (epoch 42.233), train_loss = 0.69299512, grad/param norm = 1.7351e-01, time/batch = 16.3050s	
28086/33250 (epoch 42.235), train_loss = 0.87091134, grad/param norm = 1.8119e-01, time/batch = 18.0381s	
28087/33250 (epoch 42.236), train_loss = 0.69339029, grad/param norm = 1.7502e-01, time/batch = 15.6018s	
28088/33250 (epoch 42.238), train_loss = 0.84950667, grad/param norm = 1.9553e-01, time/batch = 15.3503s	
28089/33250 (epoch 42.239), train_loss = 0.85082971, grad/param norm = 2.2096e-01, time/batch = 15.2429s	
28090/33250 (epoch 42.241), train_loss = 0.84977744, grad/param norm = 2.1427e-01, time/batch = 15.3948s	
28091/33250 (epoch 42.242), train_loss = 0.86478395, grad/param norm = 2.1406e-01, time/batch = 15.4157s	
28092/33250 (epoch 42.244), train_loss = 0.80688536, grad/param norm = 2.7373e-01, time/batch = 15.2771s	
28093/33250 (epoch 42.245), train_loss = 0.78550683, grad/param norm = 1.7701e-01, time/batch = 15.5101s	
28094/33250 (epoch 42.247), train_loss = 0.74796403, grad/param norm = 1.7155e-01, time/batch = 15.1290s	
28095/33250 (epoch 42.248), train_loss = 0.89514064, grad/param norm = 2.3176e-01, time/batch = 15.8061s	
28096/33250 (epoch 42.250), train_loss = 0.87223869, grad/param norm = 1.7626e-01, time/batch = 15.1849s	
28097/33250 (epoch 42.251), train_loss = 0.75664000, grad/param norm = 1.8202e-01, time/batch = 15.2971s	
28098/33250 (epoch 42.253), train_loss = 0.76386256, grad/param norm = 1.7335e-01, time/batch = 15.2101s	
28099/33250 (epoch 42.254), train_loss = 0.70481105, grad/param norm = 1.6765e-01, time/batch = 15.1137s	
28100/33250 (epoch 42.256), train_loss = 0.79556450, grad/param norm = 1.7990e-01, time/batch = 14.7859s	
28101/33250 (epoch 42.257), train_loss = 0.92031229, grad/param norm = 1.8342e-01, time/batch = 15.1176s	
28102/33250 (epoch 42.259), train_loss = 0.81029423, grad/param norm = 2.0034e-01, time/batch = 14.9477s	
28103/33250 (epoch 42.260), train_loss = 0.62059347, grad/param norm = 1.7310e-01, time/batch = 15.1596s	
28104/33250 (epoch 42.262), train_loss = 0.78308426, grad/param norm = 1.8843e-01, time/batch = 14.9179s	
28105/33250 (epoch 42.263), train_loss = 0.63997307, grad/param norm = 1.9934e-01, time/batch = 14.3006s	
28106/33250 (epoch 42.265), train_loss = 0.80432058, grad/param norm = 1.8325e-01, time/batch = 14.5300s	
28107/33250 (epoch 42.266), train_loss = 0.76219674, grad/param norm = 1.9414e-01, time/batch = 15.1022s	
28108/33250 (epoch 42.268), train_loss = 0.67456405, grad/param norm = 1.8427e-01, time/batch = 14.3906s	
28109/33250 (epoch 42.269), train_loss = 0.62864867, grad/param norm = 1.6264e-01, time/batch = 14.3215s	
28110/33250 (epoch 42.271), train_loss = 0.80354834, grad/param norm = 1.7146e-01, time/batch = 14.7767s	
28111/33250 (epoch 42.272), train_loss = 0.70989126, grad/param norm = 1.4739e-01, time/batch = 15.7167s	
28112/33250 (epoch 42.274), train_loss = 0.56975674, grad/param norm = 1.5120e-01, time/batch = 15.4877s	
28113/33250 (epoch 42.275), train_loss = 0.73268417, grad/param norm = 1.5383e-01, time/batch = 14.9395s	
28114/33250 (epoch 42.277), train_loss = 0.63550212, grad/param norm = 2.1442e-01, time/batch = 15.1785s	
28115/33250 (epoch 42.278), train_loss = 0.73077933, grad/param norm = 1.8816e-01, time/batch = 15.5060s	
28116/33250 (epoch 42.280), train_loss = 0.68402346, grad/param norm = 1.6996e-01, time/batch = 15.3424s	
28117/33250 (epoch 42.281), train_loss = 0.78955364, grad/param norm = 2.0214e-01, time/batch = 15.4063s	
28118/33250 (epoch 42.283), train_loss = 0.80158014, grad/param norm = 3.3531e-01, time/batch = 15.3394s	
28119/33250 (epoch 42.284), train_loss = 0.65522796, grad/param norm = 2.2387e-01, time/batch = 15.4626s	
28120/33250 (epoch 42.286), train_loss = 0.79786730, grad/param norm = 1.8021e-01, time/batch = 15.4260s	
28121/33250 (epoch 42.287), train_loss = 0.62960304, grad/param norm = 1.8489e-01, time/batch = 15.4347s	
28122/33250 (epoch 42.289), train_loss = 0.59405019, grad/param norm = 1.8102e-01, time/batch = 15.5541s	
28123/33250 (epoch 42.290), train_loss = 0.74800282, grad/param norm = 2.3332e-01, time/batch = 15.4275s	
28124/33250 (epoch 42.292), train_loss = 0.78265062, grad/param norm = 2.1314e-01, time/batch = 15.4905s	
28125/33250 (epoch 42.293), train_loss = 0.85526227, grad/param norm = 1.8683e-01, time/batch = 15.8122s	
28126/33250 (epoch 42.295), train_loss = 0.85973619, grad/param norm = 1.8708e-01, time/batch = 15.5837s	
28127/33250 (epoch 42.296), train_loss = 0.76723528, grad/param norm = 1.7994e-01, time/batch = 15.1732s	
28128/33250 (epoch 42.298), train_loss = 0.62677727, grad/param norm = 1.8965e-01, time/batch = 15.2945s	
28129/33250 (epoch 42.299), train_loss = 0.60659577, grad/param norm = 1.6364e-01, time/batch = 14.8192s	
28130/33250 (epoch 42.301), train_loss = 0.83775545, grad/param norm = 1.9168e-01, time/batch = 15.4919s	
28131/33250 (epoch 42.302), train_loss = 0.82125034, grad/param norm = 2.4028e-01, time/batch = 15.7436s	
28132/33250 (epoch 42.304), train_loss = 0.72198086, grad/param norm = 1.6777e-01, time/batch = 15.7408s	
28133/33250 (epoch 42.305), train_loss = 0.68879364, grad/param norm = 1.8891e-01, time/batch = 15.1824s	
28134/33250 (epoch 42.307), train_loss = 0.81617996, grad/param norm = 1.9790e-01, time/batch = 15.8047s	
28135/33250 (epoch 42.308), train_loss = 0.86048524, grad/param norm = 2.3009e-01, time/batch = 15.1005s	
28136/33250 (epoch 42.310), train_loss = 0.70440888, grad/param norm = 1.8932e-01, time/batch = 15.1136s	
28137/33250 (epoch 42.311), train_loss = 0.89978187, grad/param norm = 2.1229e-01, time/batch = 15.1288s	
28138/33250 (epoch 42.313), train_loss = 0.60568772, grad/param norm = 1.7989e-01, time/batch = 15.4401s	
28139/33250 (epoch 42.314), train_loss = 0.82695465, grad/param norm = 1.8145e-01, time/batch = 15.7155s	
28140/33250 (epoch 42.316), train_loss = 0.93054566, grad/param norm = 2.0763e-01, time/batch = 15.3814s	
28141/33250 (epoch 42.317), train_loss = 0.67517233, grad/param norm = 1.7653e-01, time/batch = 16.4615s	
28142/33250 (epoch 42.319), train_loss = 0.81216920, grad/param norm = 2.9115e-01, time/batch = 15.5321s	
28143/33250 (epoch 42.320), train_loss = 0.82345026, grad/param norm = 2.1514e-01, time/batch = 15.3737s	
28144/33250 (epoch 42.322), train_loss = 0.94504641, grad/param norm = 2.1825e-01, time/batch = 15.0490s	
28145/33250 (epoch 42.323), train_loss = 0.90450056, grad/param norm = 2.6800e-01, time/batch = 15.1065s	
28146/33250 (epoch 42.325), train_loss = 0.74376790, grad/param norm = 2.1795e-01, time/batch = 14.9604s	
28147/33250 (epoch 42.326), train_loss = 0.98851785, grad/param norm = 2.0487e-01, time/batch = 14.7908s	
28148/33250 (epoch 42.328), train_loss = 0.75261473, grad/param norm = 1.8728e-01, time/batch = 14.9457s	
28149/33250 (epoch 42.329), train_loss = 0.79444094, grad/param norm = 2.3661e-01, time/batch = 15.1904s	
28150/33250 (epoch 42.331), train_loss = 0.79000103, grad/param norm = 2.2184e-01, time/batch = 15.2764s	
28151/33250 (epoch 42.332), train_loss = 0.78650336, grad/param norm = 1.8596e-01, time/batch = 15.4360s	
28152/33250 (epoch 42.334), train_loss = 0.90554281, grad/param norm = 2.0238e-01, time/batch = 15.7408s	
28153/33250 (epoch 42.335), train_loss = 0.59104349, grad/param norm = 1.6365e-01, time/batch = 15.6259s	
28154/33250 (epoch 42.337), train_loss = 0.83664092, grad/param norm = 1.8411e-01, time/batch = 15.5776s	
28155/33250 (epoch 42.338), train_loss = 0.92948723, grad/param norm = 1.9915e-01, time/batch = 15.4860s	
28156/33250 (epoch 42.340), train_loss = 0.74664864, grad/param norm = 2.0057e-01, time/batch = 15.3168s	
28157/33250 (epoch 42.341), train_loss = 0.69474083, grad/param norm = 1.8140e-01, time/batch = 15.3065s	
28158/33250 (epoch 42.343), train_loss = 0.75770720, grad/param norm = 2.1098e-01, time/batch = 14.9977s	
28159/33250 (epoch 42.344), train_loss = 0.74038291, grad/param norm = 1.6854e-01, time/batch = 15.3080s	
28160/33250 (epoch 42.346), train_loss = 0.67121731, grad/param norm = 1.6793e-01, time/batch = 15.2451s	
28161/33250 (epoch 42.347), train_loss = 0.92200249, grad/param norm = 1.8478e-01, time/batch = 15.6607s	
28162/33250 (epoch 42.349), train_loss = 0.76447343, grad/param norm = 1.9401e-01, time/batch = 15.3464s	
28163/33250 (epoch 42.350), train_loss = 0.76020091, grad/param norm = 1.8228e-01, time/batch = 15.4791s	
28164/33250 (epoch 42.352), train_loss = 0.69443951, grad/param norm = 1.9027e-01, time/batch = 15.0680s	
28165/33250 (epoch 42.353), train_loss = 0.72940563, grad/param norm = 1.7127e-01, time/batch = 15.6651s	
28166/33250 (epoch 42.355), train_loss = 0.71473544, grad/param norm = 1.7340e-01, time/batch = 15.1098s	
28167/33250 (epoch 42.356), train_loss = 0.70072753, grad/param norm = 1.8590e-01, time/batch = 15.7261s	
28168/33250 (epoch 42.358), train_loss = 0.76343051, grad/param norm = 1.6613e-01, time/batch = 15.4217s	
28169/33250 (epoch 42.359), train_loss = 0.73231771, grad/param norm = 1.8988e-01, time/batch = 15.4914s	
28170/33250 (epoch 42.361), train_loss = 0.84561394, grad/param norm = 2.1522e-01, time/batch = 15.4860s	
28171/33250 (epoch 42.362), train_loss = 0.80711522, grad/param norm = 1.8079e-01, time/batch = 15.6801s	
28172/33250 (epoch 42.364), train_loss = 0.80838427, grad/param norm = 1.8842e-01, time/batch = 15.4094s	
28173/33250 (epoch 42.365), train_loss = 0.76217491, grad/param norm = 1.5604e-01, time/batch = 16.2803s	
28174/33250 (epoch 42.367), train_loss = 0.78680976, grad/param norm = 1.7316e-01, time/batch = 17.0356s	
28175/33250 (epoch 42.368), train_loss = 0.75349552, grad/param norm = 1.7451e-01, time/batch = 16.2832s	
28176/33250 (epoch 42.370), train_loss = 0.68526803, grad/param norm = 1.5627e-01, time/batch = 14.7071s	
28177/33250 (epoch 42.371), train_loss = 0.85770445, grad/param norm = 2.4069e-01, time/batch = 15.1131s	
28178/33250 (epoch 42.373), train_loss = 0.74256698, grad/param norm = 1.5239e-01, time/batch = 15.1914s	
28179/33250 (epoch 42.374), train_loss = 0.75264757, grad/param norm = 2.3533e-01, time/batch = 15.4632s	
28180/33250 (epoch 42.376), train_loss = 0.78545650, grad/param norm = 1.8501e-01, time/batch = 15.2806s	
28181/33250 (epoch 42.377), train_loss = 0.68302422, grad/param norm = 2.4809e-01, time/batch = 15.1223s	
28182/33250 (epoch 42.379), train_loss = 0.75311254, grad/param norm = 1.8855e-01, time/batch = 14.7262s	
28183/33250 (epoch 42.380), train_loss = 0.76141571, grad/param norm = 2.0695e-01, time/batch = 15.0391s	
28184/33250 (epoch 42.382), train_loss = 0.77817057, grad/param norm = 2.2851e-01, time/batch = 16.0181s	
28185/33250 (epoch 42.383), train_loss = 0.67470199, grad/param norm = 1.8158e-01, time/batch = 15.7452s	
28186/33250 (epoch 42.385), train_loss = 0.64871863, grad/param norm = 1.8839e-01, time/batch = 15.4470s	
28187/33250 (epoch 42.386), train_loss = 0.66920857, grad/param norm = 2.0620e-01, time/batch = 14.9554s	
28188/33250 (epoch 42.388), train_loss = 0.70259599, grad/param norm = 1.7790e-01, time/batch = 14.9521s	
28189/33250 (epoch 42.389), train_loss = 0.70484981, grad/param norm = 2.2647e-01, time/batch = 15.4525s	
28190/33250 (epoch 42.391), train_loss = 0.79611833, grad/param norm = 1.8149e-01, time/batch = 14.8884s	
28191/33250 (epoch 42.392), train_loss = 0.85419256, grad/param norm = 2.0646e-01, time/batch = 15.1062s	
28192/33250 (epoch 42.394), train_loss = 0.86684963, grad/param norm = 2.0899e-01, time/batch = 15.3403s	
28193/33250 (epoch 42.395), train_loss = 0.86112446, grad/param norm = 1.8271e-01, time/batch = 15.9732s	
28194/33250 (epoch 42.397), train_loss = 0.88324723, grad/param norm = 2.1848e-01, time/batch = 14.9771s	
28195/33250 (epoch 42.398), train_loss = 0.67508383, grad/param norm = 1.5353e-01, time/batch = 15.4463s	
28196/33250 (epoch 42.400), train_loss = 0.66887124, grad/param norm = 1.5803e-01, time/batch = 15.1881s	
28197/33250 (epoch 42.402), train_loss = 0.63012362, grad/param norm = 1.5946e-01, time/batch = 15.0431s	
28198/33250 (epoch 42.403), train_loss = 0.74070135, grad/param norm = 2.1123e-01, time/batch = 14.8595s	
28199/33250 (epoch 42.405), train_loss = 0.70664683, grad/param norm = 1.6647e-01, time/batch = 14.8832s	
28200/33250 (epoch 42.406), train_loss = 0.76052049, grad/param norm = 2.2008e-01, time/batch = 15.1856s	
28201/33250 (epoch 42.408), train_loss = 0.90846007, grad/param norm = 2.0242e-01, time/batch = 15.0352s	
28202/33250 (epoch 42.409), train_loss = 0.79789793, grad/param norm = 2.1527e-01, time/batch = 14.8650s	
28203/33250 (epoch 42.411), train_loss = 0.56019229, grad/param norm = 1.3726e-01, time/batch = 14.9478s	
28204/33250 (epoch 42.412), train_loss = 0.65145153, grad/param norm = 2.1756e-01, time/batch = 15.3408s	
28205/33250 (epoch 42.414), train_loss = 0.77357182, grad/param norm = 1.6924e-01, time/batch = 17.7541s	
28206/33250 (epoch 42.415), train_loss = 0.84840030, grad/param norm = 2.6401e-01, time/batch = 16.1246s	
28207/33250 (epoch 42.417), train_loss = 0.86171997, grad/param norm = 1.9785e-01, time/batch = 16.2030s	
28208/33250 (epoch 42.418), train_loss = 1.00569267, grad/param norm = 2.4562e-01, time/batch = 15.5062s	
28209/33250 (epoch 42.420), train_loss = 0.84798913, grad/param norm = 1.9585e-01, time/batch = 14.9511s	
28210/33250 (epoch 42.421), train_loss = 0.73730229, grad/param norm = 1.7615e-01, time/batch = 14.9573s	
28211/33250 (epoch 42.423), train_loss = 0.80516218, grad/param norm = 2.0547e-01, time/batch = 15.1087s	
28212/33250 (epoch 42.424), train_loss = 0.88764388, grad/param norm = 2.9800e-01, time/batch = 16.0436s	
28213/33250 (epoch 42.426), train_loss = 0.75079268, grad/param norm = 1.6228e-01, time/batch = 15.4871s	
28214/33250 (epoch 42.427), train_loss = 0.72707883, grad/param norm = 1.8928e-01, time/batch = 15.1208s	
28215/33250 (epoch 42.429), train_loss = 0.75385426, grad/param norm = 1.9457e-01, time/batch = 15.2747s	
28216/33250 (epoch 42.430), train_loss = 0.71804045, grad/param norm = 1.9946e-01, time/batch = 15.3650s	
28217/33250 (epoch 42.432), train_loss = 0.84462902, grad/param norm = 1.8238e-01, time/batch = 14.9761s	
28218/33250 (epoch 42.433), train_loss = 0.74779653, grad/param norm = 2.2449e-01, time/batch = 15.0253s	
28219/33250 (epoch 42.435), train_loss = 0.82147661, grad/param norm = 1.9056e-01, time/batch = 15.5166s	
28220/33250 (epoch 42.436), train_loss = 0.72915801, grad/param norm = 1.9015e-01, time/batch = 15.0475s	
28221/33250 (epoch 42.438), train_loss = 0.87882724, grad/param norm = 1.9706e-01, time/batch = 15.3655s	
28222/33250 (epoch 42.439), train_loss = 0.77317961, grad/param norm = 1.8393e-01, time/batch = 15.3626s	
28223/33250 (epoch 42.441), train_loss = 0.76339554, grad/param norm = 1.7975e-01, time/batch = 15.5919s	
28224/33250 (epoch 42.442), train_loss = 0.68728027, grad/param norm = 1.6717e-01, time/batch = 15.2782s	
28225/33250 (epoch 42.444), train_loss = 0.71488571, grad/param norm = 1.5879e-01, time/batch = 14.8654s	
28226/33250 (epoch 42.445), train_loss = 0.78252084, grad/param norm = 1.4827e-01, time/batch = 14.8948s	
28227/33250 (epoch 42.447), train_loss = 0.68479267, grad/param norm = 1.6643e-01, time/batch = 15.1071s	
28228/33250 (epoch 42.448), train_loss = 0.80217691, grad/param norm = 1.6383e-01, time/batch = 15.9446s	
28229/33250 (epoch 42.450), train_loss = 0.87067672, grad/param norm = 1.9006e-01, time/batch = 15.3889s	
28230/33250 (epoch 42.451), train_loss = 0.82372463, grad/param norm = 2.0843e-01, time/batch = 15.7923s	
28231/33250 (epoch 42.453), train_loss = 0.66940862, grad/param norm = 1.6030e-01, time/batch = 15.6671s	
28232/33250 (epoch 42.454), train_loss = 0.88895812, grad/param norm = 1.9647e-01, time/batch = 15.0126s	
28233/33250 (epoch 42.456), train_loss = 0.86707724, grad/param norm = 1.5640e-01, time/batch = 14.7831s	
28234/33250 (epoch 42.457), train_loss = 0.71493197, grad/param norm = 1.6801e-01, time/batch = 15.2677s	
28235/33250 (epoch 42.459), train_loss = 0.83510892, grad/param norm = 1.7902e-01, time/batch = 15.7491s	
28236/33250 (epoch 42.460), train_loss = 0.82954916, grad/param norm = 1.7845e-01, time/batch = 15.0145s	
28237/33250 (epoch 42.462), train_loss = 0.76481208, grad/param norm = 1.7494e-01, time/batch = 15.8090s	
28238/33250 (epoch 42.463), train_loss = 0.67877160, grad/param norm = 1.3785e-01, time/batch = 15.0987s	
28239/33250 (epoch 42.465), train_loss = 0.63390375, grad/param norm = 1.5068e-01, time/batch = 15.4149s	
28240/33250 (epoch 42.466), train_loss = 0.63746287, grad/param norm = 1.4259e-01, time/batch = 15.8839s	
28241/33250 (epoch 42.468), train_loss = 0.66917116, grad/param norm = 1.5207e-01, time/batch = 15.2040s	
28242/33250 (epoch 42.469), train_loss = 0.75853482, grad/param norm = 1.9158e-01, time/batch = 15.1900s	
28243/33250 (epoch 42.471), train_loss = 0.83243393, grad/param norm = 1.6030e-01, time/batch = 15.2767s	
28244/33250 (epoch 42.472), train_loss = 0.73697459, grad/param norm = 2.0416e-01, time/batch = 15.0429s	
28245/33250 (epoch 42.474), train_loss = 0.84627998, grad/param norm = 1.9271e-01, time/batch = 15.6430s	
28246/33250 (epoch 42.475), train_loss = 0.78148420, grad/param norm = 1.6049e-01, time/batch = 15.3447s	
28247/33250 (epoch 42.477), train_loss = 0.79139719, grad/param norm = 1.6017e-01, time/batch = 15.5088s	
28248/33250 (epoch 42.478), train_loss = 0.67024230, grad/param norm = 1.7533e-01, time/batch = 16.0577s	
28249/33250 (epoch 42.480), train_loss = 0.85636096, grad/param norm = 1.7177e-01, time/batch = 15.7090s	
28250/33250 (epoch 42.481), train_loss = 0.72513857, grad/param norm = 1.9365e-01, time/batch = 15.3499s	
28251/33250 (epoch 42.483), train_loss = 0.74535479, grad/param norm = 1.9085e-01, time/batch = 15.7851s	
28252/33250 (epoch 42.484), train_loss = 0.70361695, grad/param norm = 1.7999e-01, time/batch = 14.6265s	
28253/33250 (epoch 42.486), train_loss = 0.62168765, grad/param norm = 1.9781e-01, time/batch = 15.4094s	
28254/33250 (epoch 42.487), train_loss = 0.68884352, grad/param norm = 1.8897e-01, time/batch = 14.9540s	
28255/33250 (epoch 42.489), train_loss = 0.82431222, grad/param norm = 1.7433e-01, time/batch = 15.5057s	
28256/33250 (epoch 42.490), train_loss = 0.76643196, grad/param norm = 1.8177e-01, time/batch = 15.2815s	
28257/33250 (epoch 42.492), train_loss = 0.83305670, grad/param norm = 1.8702e-01, time/batch = 15.0370s	
28258/33250 (epoch 42.493), train_loss = 0.75608481, grad/param norm = 1.7583e-01, time/batch = 15.1845s	
28259/33250 (epoch 42.495), train_loss = 0.81928049, grad/param norm = 1.6006e-01, time/batch = 15.4414s	
28260/33250 (epoch 42.496), train_loss = 0.76309514, grad/param norm = 1.4730e-01, time/batch = 17.7121s	
28261/33250 (epoch 42.498), train_loss = 0.83004848, grad/param norm = 1.8878e-01, time/batch = 15.2416s	
28262/33250 (epoch 42.499), train_loss = 0.71806808, grad/param norm = 1.7871e-01, time/batch = 29.3361s	
28263/33250 (epoch 42.501), train_loss = 0.73522195, grad/param norm = 2.0205e-01, time/batch = 15.2064s	
28264/33250 (epoch 42.502), train_loss = 0.71624219, grad/param norm = 1.6506e-01, time/batch = 15.5661s	
28265/33250 (epoch 42.504), train_loss = 0.90033694, grad/param norm = 2.3459e-01, time/batch = 15.9601s	
28266/33250 (epoch 42.505), train_loss = 0.65860660, grad/param norm = 1.4346e-01, time/batch = 15.5967s	
28267/33250 (epoch 42.507), train_loss = 0.69446265, grad/param norm = 1.6903e-01, time/batch = 15.4096s	
28268/33250 (epoch 42.508), train_loss = 0.73129194, grad/param norm = 1.6464e-01, time/batch = 15.1873s	
28269/33250 (epoch 42.510), train_loss = 0.62978928, grad/param norm = 1.3794e-01, time/batch = 15.5242s	
28270/33250 (epoch 42.511), train_loss = 0.72690233, grad/param norm = 1.7353e-01, time/batch = 15.9937s	
28271/33250 (epoch 42.513), train_loss = 0.86414133, grad/param norm = 1.9922e-01, time/batch = 15.7089s	
28272/33250 (epoch 42.514), train_loss = 0.71589740, grad/param norm = 1.8878e-01, time/batch = 15.4418s	
28273/33250 (epoch 42.516), train_loss = 0.68588447, grad/param norm = 1.8022e-01, time/batch = 15.5801s	
28274/33250 (epoch 42.517), train_loss = 0.72380565, grad/param norm = 1.6039e-01, time/batch = 14.8699s	
28275/33250 (epoch 42.519), train_loss = 0.67394412, grad/param norm = 1.3002e-01, time/batch = 14.7841s	
28276/33250 (epoch 42.520), train_loss = 0.92370722, grad/param norm = 1.8770e-01, time/batch = 15.0991s	
28277/33250 (epoch 42.522), train_loss = 0.78370320, grad/param norm = 1.7593e-01, time/batch = 15.6116s	
28278/33250 (epoch 42.523), train_loss = 0.70035853, grad/param norm = 1.9685e-01, time/batch = 15.0264s	
28279/33250 (epoch 42.525), train_loss = 0.64082967, grad/param norm = 1.7396e-01, time/batch = 15.1883s	
28280/33250 (epoch 42.526), train_loss = 0.66775673, grad/param norm = 1.6982e-01, time/batch = 15.3541s	
28281/33250 (epoch 42.528), train_loss = 0.70841615, grad/param norm = 1.6586e-01, time/batch = 15.5205s	
28282/33250 (epoch 42.529), train_loss = 0.70008789, grad/param norm = 1.7703e-01, time/batch = 15.2795s	
28283/33250 (epoch 42.531), train_loss = 0.66595113, grad/param norm = 1.5270e-01, time/batch = 15.4514s	
28284/33250 (epoch 42.532), train_loss = 0.77727194, grad/param norm = 1.5553e-01, time/batch = 15.5089s	
28285/33250 (epoch 42.534), train_loss = 0.68157397, grad/param norm = 1.5207e-01, time/batch = 15.4209s	
28286/33250 (epoch 42.535), train_loss = 0.71729266, grad/param norm = 1.5250e-01, time/batch = 15.3332s	
28287/33250 (epoch 42.537), train_loss = 0.76449284, grad/param norm = 1.6224e-01, time/batch = 15.1925s	
28288/33250 (epoch 42.538), train_loss = 0.80013566, grad/param norm = 1.8692e-01, time/batch = 14.9318s	
28289/33250 (epoch 42.540), train_loss = 0.88166914, grad/param norm = 1.6107e-01, time/batch = 15.0290s	
28290/33250 (epoch 42.541), train_loss = 0.80128827, grad/param norm = 1.9615e-01, time/batch = 15.6519s	
28291/33250 (epoch 42.543), train_loss = 0.79999833, grad/param norm = 1.4820e-01, time/batch = 15.7611s	
28292/33250 (epoch 42.544), train_loss = 0.67719274, grad/param norm = 1.8834e-01, time/batch = 15.2825s	
28293/33250 (epoch 42.546), train_loss = 0.70463997, grad/param norm = 1.8883e-01, time/batch = 15.3613s	
28294/33250 (epoch 42.547), train_loss = 0.72720603, grad/param norm = 1.8505e-01, time/batch = 15.6156s	
28295/33250 (epoch 42.549), train_loss = 0.76068942, grad/param norm = 1.8339e-01, time/batch = 15.1488s	
28296/33250 (epoch 42.550), train_loss = 0.74075543, grad/param norm = 1.8639e-01, time/batch = 15.5128s	
28297/33250 (epoch 42.552), train_loss = 0.80005460, grad/param norm = 1.8585e-01, time/batch = 15.3516s	
28298/33250 (epoch 42.553), train_loss = 0.73305509, grad/param norm = 1.5032e-01, time/batch = 15.8025s	
28299/33250 (epoch 42.555), train_loss = 0.73943203, grad/param norm = 1.6221e-01, time/batch = 15.4994s	
28300/33250 (epoch 42.556), train_loss = 0.77644341, grad/param norm = 2.0679e-01, time/batch = 15.5765s	
28301/33250 (epoch 42.558), train_loss = 0.78822548, grad/param norm = 1.8472e-01, time/batch = 15.4217s	
28302/33250 (epoch 42.559), train_loss = 0.69767625, grad/param norm = 1.7045e-01, time/batch = 15.2748s	
28303/33250 (epoch 42.561), train_loss = 0.64730935, grad/param norm = 1.8885e-01, time/batch = 15.2753s	
28304/33250 (epoch 42.562), train_loss = 0.74939662, grad/param norm = 1.8177e-01, time/batch = 15.6561s	
28305/33250 (epoch 42.564), train_loss = 0.91362898, grad/param norm = 2.3809e-01, time/batch = 15.0604s	
28306/33250 (epoch 42.565), train_loss = 0.85559846, grad/param norm = 2.2580e-01, time/batch = 15.0769s	
28307/33250 (epoch 42.567), train_loss = 0.86138440, grad/param norm = 1.9398e-01, time/batch = 15.3742s	
28308/33250 (epoch 42.568), train_loss = 0.73254615, grad/param norm = 2.3302e-01, time/batch = 15.7417s	
28309/33250 (epoch 42.570), train_loss = 0.82032131, grad/param norm = 2.0357e-01, time/batch = 15.6052s	
28310/33250 (epoch 42.571), train_loss = 0.85424139, grad/param norm = 1.9247e-01, time/batch = 15.8240s	
28311/33250 (epoch 42.573), train_loss = 0.80789047, grad/param norm = 1.9226e-01, time/batch = 15.8044s	
28312/33250 (epoch 42.574), train_loss = 0.69228199, grad/param norm = 1.4428e-01, time/batch = 15.5140s	
28313/33250 (epoch 42.576), train_loss = 0.76527641, grad/param norm = 1.5928e-01, time/batch = 15.5192s	
28314/33250 (epoch 42.577), train_loss = 0.74071067, grad/param norm = 1.6909e-01, time/batch = 15.4321s	
28315/33250 (epoch 42.579), train_loss = 0.64171369, grad/param norm = 1.6202e-01, time/batch = 15.7628s	
28316/33250 (epoch 42.580), train_loss = 0.76602824, grad/param norm = 1.7836e-01, time/batch = 15.2919s	
28317/33250 (epoch 42.582), train_loss = 0.71439869, grad/param norm = 1.8346e-01, time/batch = 15.5345s	
28318/33250 (epoch 42.583), train_loss = 0.81649147, grad/param norm = 1.9012e-01, time/batch = 15.7514s	
28319/33250 (epoch 42.585), train_loss = 0.84467625, grad/param norm = 1.6045e-01, time/batch = 15.6752s	
28320/33250 (epoch 42.586), train_loss = 0.71660028, grad/param norm = 2.2225e-01, time/batch = 15.7257s	
28321/33250 (epoch 42.588), train_loss = 0.79487523, grad/param norm = 1.6131e-01, time/batch = 16.0490s	
28322/33250 (epoch 42.589), train_loss = 0.75649220, grad/param norm = 1.9256e-01, time/batch = 15.4239s	
28323/33250 (epoch 42.591), train_loss = 0.73410273, grad/param norm = 2.0433e-01, time/batch = 15.5905s	
28324/33250 (epoch 42.592), train_loss = 0.72647147, grad/param norm = 1.8225e-01, time/batch = 15.3621s	
28325/33250 (epoch 42.594), train_loss = 0.85667987, grad/param norm = 2.3216e-01, time/batch = 15.5939s	
28326/33250 (epoch 42.595), train_loss = 0.76162593, grad/param norm = 1.7047e-01, time/batch = 15.2923s	
28327/33250 (epoch 42.597), train_loss = 0.63879071, grad/param norm = 1.4005e-01, time/batch = 15.7716s	
28328/33250 (epoch 42.598), train_loss = 0.71925760, grad/param norm = 1.8343e-01, time/batch = 15.3851s	
28329/33250 (epoch 42.600), train_loss = 0.71944232, grad/param norm = 1.7806e-01, time/batch = 15.4560s	
28330/33250 (epoch 42.602), train_loss = 0.76384899, grad/param norm = 1.8889e-01, time/batch = 15.3598s	
28331/33250 (epoch 42.603), train_loss = 0.80918822, grad/param norm = 2.0307e-01, time/batch = 15.5358s	
28332/33250 (epoch 42.605), train_loss = 0.75383067, grad/param norm = 1.8938e-01, time/batch = 15.5875s	
28333/33250 (epoch 42.606), train_loss = 0.79858580, grad/param norm = 1.7655e-01, time/batch = 15.5888s	
28334/33250 (epoch 42.608), train_loss = 0.76005896, grad/param norm = 1.6488e-01, time/batch = 15.6759s	
28335/33250 (epoch 42.609), train_loss = 0.65814507, grad/param norm = 1.6346e-01, time/batch = 15.5893s	
28336/33250 (epoch 42.611), train_loss = 0.73582207, grad/param norm = 1.9388e-01, time/batch = 15.3769s	
28337/33250 (epoch 42.612), train_loss = 0.74568889, grad/param norm = 1.8979e-01, time/batch = 15.0599s	
28338/33250 (epoch 42.614), train_loss = 0.94253727, grad/param norm = 2.5805e-01, time/batch = 15.5077s	
28339/33250 (epoch 42.615), train_loss = 0.85524406, grad/param norm = 1.9728e-01, time/batch = 15.2292s	
28340/33250 (epoch 42.617), train_loss = 0.94774082, grad/param norm = 2.2115e-01, time/batch = 15.3781s	
28341/33250 (epoch 42.618), train_loss = 0.96371442, grad/param norm = 2.5497e-01, time/batch = 15.8201s	
28342/33250 (epoch 42.620), train_loss = 0.81015051, grad/param norm = 1.8023e-01, time/batch = 15.3323s	
28343/33250 (epoch 42.621), train_loss = 0.82531154, grad/param norm = 2.1013e-01, time/batch = 15.8359s	
28344/33250 (epoch 42.623), train_loss = 0.73105349, grad/param norm = 1.9987e-01, time/batch = 15.9975s	
28345/33250 (epoch 42.624), train_loss = 0.73370330, grad/param norm = 2.2206e-01, time/batch = 15.6084s	
28346/33250 (epoch 42.626), train_loss = 0.75755765, grad/param norm = 2.4961e-01, time/batch = 15.9964s	
28347/33250 (epoch 42.627), train_loss = 0.71541048, grad/param norm = 1.7339e-01, time/batch = 15.7058s	
28348/33250 (epoch 42.629), train_loss = 0.80642653, grad/param norm = 2.2606e-01, time/batch = 15.5257s	
28349/33250 (epoch 42.630), train_loss = 0.73252751, grad/param norm = 2.1420e-01, time/batch = 15.2938s	
28350/33250 (epoch 42.632), train_loss = 0.65862139, grad/param norm = 1.5807e-01, time/batch = 15.2230s	
28351/33250 (epoch 42.633), train_loss = 0.78535033, grad/param norm = 1.9577e-01, time/batch = 15.4484s	
28352/33250 (epoch 42.635), train_loss = 0.69262134, grad/param norm = 1.7548e-01, time/batch = 15.4429s	
28353/33250 (epoch 42.636), train_loss = 0.70901458, grad/param norm = 1.5713e-01, time/batch = 15.3480s	
28354/33250 (epoch 42.638), train_loss = 0.65932908, grad/param norm = 1.6737e-01, time/batch = 15.6020s	
28355/33250 (epoch 42.639), train_loss = 0.64407024, grad/param norm = 1.7644e-01, time/batch = 15.8233s	
28356/33250 (epoch 42.641), train_loss = 0.73618418, grad/param norm = 1.7844e-01, time/batch = 16.1284s	
28357/33250 (epoch 42.642), train_loss = 0.56526572, grad/param norm = 1.8906e-01, time/batch = 15.6317s	
28358/33250 (epoch 42.644), train_loss = 0.52356897, grad/param norm = 1.5502e-01, time/batch = 14.7553s	
28359/33250 (epoch 42.645), train_loss = 0.78440381, grad/param norm = 2.0082e-01, time/batch = 15.2129s	
28360/33250 (epoch 42.647), train_loss = 0.63382992, grad/param norm = 1.7789e-01, time/batch = 15.0539s	
28361/33250 (epoch 42.648), train_loss = 0.64137690, grad/param norm = 1.6990e-01, time/batch = 15.6003s	
28362/33250 (epoch 42.650), train_loss = 0.87244809, grad/param norm = 2.1060e-01, time/batch = 15.8977s	
28363/33250 (epoch 42.651), train_loss = 0.78575840, grad/param norm = 1.9469e-01, time/batch = 15.5107s	
28364/33250 (epoch 42.653), train_loss = 0.72257340, grad/param norm = 1.6826e-01, time/batch = 15.5121s	
28365/33250 (epoch 42.654), train_loss = 0.75426378, grad/param norm = 1.7989e-01, time/batch = 15.8180s	
28366/33250 (epoch 42.656), train_loss = 0.81881803, grad/param norm = 1.6676e-01, time/batch = 15.6003s	
28367/33250 (epoch 42.657), train_loss = 0.58861097, grad/param norm = 1.8509e-01, time/batch = 15.2936s	
28368/33250 (epoch 42.659), train_loss = 0.72545874, grad/param norm = 1.8397e-01, time/batch = 15.3038s	
28369/33250 (epoch 42.660), train_loss = 0.76729199, grad/param norm = 1.8149e-01, time/batch = 15.6665s	
28370/33250 (epoch 42.662), train_loss = 0.77607916, grad/param norm = 1.7354e-01, time/batch = 15.7061s	
28371/33250 (epoch 42.663), train_loss = 0.66873559, grad/param norm = 1.5727e-01, time/batch = 15.9625s	
28372/33250 (epoch 42.665), train_loss = 0.77473889, grad/param norm = 1.7889e-01, time/batch = 16.1866s	
28373/33250 (epoch 42.666), train_loss = 0.73419452, grad/param norm = 1.6830e-01, time/batch = 15.9992s	
28374/33250 (epoch 42.668), train_loss = 0.84432238, grad/param norm = 2.1692e-01, time/batch = 15.9243s	
28375/33250 (epoch 42.669), train_loss = 0.77093374, grad/param norm = 1.7671e-01, time/batch = 15.7506s	
28376/33250 (epoch 42.671), train_loss = 0.65143944, grad/param norm = 1.5348e-01, time/batch = 15.7977s	
28377/33250 (epoch 42.672), train_loss = 0.83015254, grad/param norm = 1.9208e-01, time/batch = 15.8253s	
28378/33250 (epoch 42.674), train_loss = 0.69559962, grad/param norm = 1.8061e-01, time/batch = 15.6384s	
28379/33250 (epoch 42.675), train_loss = 0.76236445, grad/param norm = 1.6206e-01, time/batch = 15.4403s	
28380/33250 (epoch 42.677), train_loss = 0.80527806, grad/param norm = 1.8765e-01, time/batch = 15.6379s	
28381/33250 (epoch 42.678), train_loss = 0.72156874, grad/param norm = 2.2899e-01, time/batch = 15.4400s	
28382/33250 (epoch 42.680), train_loss = 0.86612789, grad/param norm = 2.1001e-01, time/batch = 15.2777s	
28383/33250 (epoch 42.681), train_loss = 0.67003243, grad/param norm = 1.5972e-01, time/batch = 15.4176s	
28384/33250 (epoch 42.683), train_loss = 0.68565764, grad/param norm = 1.7463e-01, time/batch = 15.2699s	
28385/33250 (epoch 42.684), train_loss = 0.64187627, grad/param norm = 1.9060e-01, time/batch = 15.6446s	
28386/33250 (epoch 42.686), train_loss = 0.65591279, grad/param norm = 2.1512e-01, time/batch = 15.7401s	
28387/33250 (epoch 42.687), train_loss = 0.76379153, grad/param norm = 1.8378e-01, time/batch = 16.1128s	
28388/33250 (epoch 42.689), train_loss = 0.64774136, grad/param norm = 1.8606e-01, time/batch = 16.0606s	
28389/33250 (epoch 42.690), train_loss = 0.76958117, grad/param norm = 1.7378e-01, time/batch = 15.4390s	
28390/33250 (epoch 42.692), train_loss = 0.73749813, grad/param norm = 1.7021e-01, time/batch = 15.8252s	
28391/33250 (epoch 42.693), train_loss = 0.78542148, grad/param norm = 1.7124e-01, time/batch = 15.5296s	
28392/33250 (epoch 42.695), train_loss = 0.76458238, grad/param norm = 1.9170e-01, time/batch = 15.3696s	
28393/33250 (epoch 42.696), train_loss = 0.80122033, grad/param norm = 1.6808e-01, time/batch = 15.3508s	
28394/33250 (epoch 42.698), train_loss = 0.71786251, grad/param norm = 1.9437e-01, time/batch = 15.5282s	
28395/33250 (epoch 42.699), train_loss = 0.94383832, grad/param norm = 1.8438e-01, time/batch = 15.8812s	
28396/33250 (epoch 42.701), train_loss = 0.76536592, grad/param norm = 1.6050e-01, time/batch = 15.8303s	
28397/33250 (epoch 42.702), train_loss = 0.72386922, grad/param norm = 2.2160e-01, time/batch = 15.4240s	
28398/33250 (epoch 42.704), train_loss = 0.94874402, grad/param norm = 2.8678e-01, time/batch = 15.1999s	
28399/33250 (epoch 42.705), train_loss = 0.71408211, grad/param norm = 1.5413e-01, time/batch = 15.2771s	
28400/33250 (epoch 42.707), train_loss = 0.65196041, grad/param norm = 1.7108e-01, time/batch = 15.6113s	
28401/33250 (epoch 42.708), train_loss = 0.83840981, grad/param norm = 1.9248e-01, time/batch = 15.3959s	
28402/33250 (epoch 42.710), train_loss = 0.78382912, grad/param norm = 2.0144e-01, time/batch = 15.2860s	
28403/33250 (epoch 42.711), train_loss = 0.66341470, grad/param norm = 1.8376e-01, time/batch = 15.3717s	
28404/33250 (epoch 42.713), train_loss = 0.78096794, grad/param norm = 1.6904e-01, time/batch = 15.9605s	
28405/33250 (epoch 42.714), train_loss = 0.73309680, grad/param norm = 1.9675e-01, time/batch = 15.4907s	
28406/33250 (epoch 42.716), train_loss = 0.78102132, grad/param norm = 1.8459e-01, time/batch = 15.2611s	
28407/33250 (epoch 42.717), train_loss = 0.71397863, grad/param norm = 1.4051e-01, time/batch = 15.5806s	
28408/33250 (epoch 42.719), train_loss = 0.68414119, grad/param norm = 1.5361e-01, time/batch = 15.7388s	
28409/33250 (epoch 42.720), train_loss = 0.96894895, grad/param norm = 1.8210e-01, time/batch = 15.5098s	
28410/33250 (epoch 42.722), train_loss = 0.64370034, grad/param norm = 1.4357e-01, time/batch = 15.5654s	
28411/33250 (epoch 42.723), train_loss = 0.58420641, grad/param norm = 1.3366e-01, time/batch = 15.5403s	
28412/33250 (epoch 42.725), train_loss = 0.72008581, grad/param norm = 1.3666e-01, time/batch = 15.3067s	
28413/33250 (epoch 42.726), train_loss = 0.76862646, grad/param norm = 1.8353e-01, time/batch = 15.2096s	
28414/33250 (epoch 42.728), train_loss = 0.77439495, grad/param norm = 1.7307e-01, time/batch = 15.0984s	
28415/33250 (epoch 42.729), train_loss = 0.81604274, grad/param norm = 1.7232e-01, time/batch = 15.6650s	
28416/33250 (epoch 42.731), train_loss = 0.67913867, grad/param norm = 1.9616e-01, time/batch = 15.4034s	
28417/33250 (epoch 42.732), train_loss = 0.69055879, grad/param norm = 1.5714e-01, time/batch = 15.6542s	
28418/33250 (epoch 42.734), train_loss = 0.76113715, grad/param norm = 1.7797e-01, time/batch = 15.4200s	
28419/33250 (epoch 42.735), train_loss = 0.76299845, grad/param norm = 1.6895e-01, time/batch = 15.6521s	
28420/33250 (epoch 42.737), train_loss = 0.73000083, grad/param norm = 1.5723e-01, time/batch = 15.6516s	
28421/33250 (epoch 42.738), train_loss = 0.77515619, grad/param norm = 1.6116e-01, time/batch = 15.4210s	
28422/33250 (epoch 42.740), train_loss = 0.76898030, grad/param norm = 1.9853e-01, time/batch = 15.4295s	
28423/33250 (epoch 42.741), train_loss = 0.80000404, grad/param norm = 1.7697e-01, time/batch = 15.8248s	
28424/33250 (epoch 42.743), train_loss = 0.71235771, grad/param norm = 1.5984e-01, time/batch = 15.1128s	
28425/33250 (epoch 42.744), train_loss = 0.69725265, grad/param norm = 1.8658e-01, time/batch = 15.3525s	
28426/33250 (epoch 42.746), train_loss = 0.68304594, grad/param norm = 2.1702e-01, time/batch = 15.0900s	
28427/33250 (epoch 42.747), train_loss = 0.67480791, grad/param norm = 1.6271e-01, time/batch = 15.4098s	
28428/33250 (epoch 42.749), train_loss = 0.85286441, grad/param norm = 1.8425e-01, time/batch = 15.2454s	
28429/33250 (epoch 42.750), train_loss = 0.85768310, grad/param norm = 1.8177e-01, time/batch = 14.9329s	
28430/33250 (epoch 42.752), train_loss = 0.71249785, grad/param norm = 1.6349e-01, time/batch = 15.3303s	
28431/33250 (epoch 42.753), train_loss = 0.70810337, grad/param norm = 1.8015e-01, time/batch = 15.0371s	
28432/33250 (epoch 42.755), train_loss = 0.63892397, grad/param norm = 1.7948e-01, time/batch = 15.1776s	
28433/33250 (epoch 42.756), train_loss = 0.74837576, grad/param norm = 1.7440e-01, time/batch = 15.0223s	
28434/33250 (epoch 42.758), train_loss = 0.89196583, grad/param norm = 1.6302e-01, time/batch = 15.3374s	
28435/33250 (epoch 42.759), train_loss = 0.71706952, grad/param norm = 1.6029e-01, time/batch = 15.1180s	
28436/33250 (epoch 42.761), train_loss = 0.80873685, grad/param norm = 2.0849e-01, time/batch = 14.9650s	
28437/33250 (epoch 42.762), train_loss = 0.81024501, grad/param norm = 1.7653e-01, time/batch = 15.3421s	
28438/33250 (epoch 42.764), train_loss = 0.63863284, grad/param norm = 2.0655e-01, time/batch = 15.1673s	
28439/33250 (epoch 42.765), train_loss = 0.77987188, grad/param norm = 2.0540e-01, time/batch = 14.9940s	
28440/33250 (epoch 42.767), train_loss = 0.60204712, grad/param norm = 1.6759e-01, time/batch = 14.9960s	
28441/33250 (epoch 42.768), train_loss = 0.63456101, grad/param norm = 1.7742e-01, time/batch = 15.2611s	
28442/33250 (epoch 42.770), train_loss = 0.77258860, grad/param norm = 1.9846e-01, time/batch = 15.5651s	
28443/33250 (epoch 42.771), train_loss = 0.81940741, grad/param norm = 2.0678e-01, time/batch = 15.5518s	
28444/33250 (epoch 42.773), train_loss = 0.74625896, grad/param norm = 1.8177e-01, time/batch = 15.1518s	
28445/33250 (epoch 42.774), train_loss = 0.63837877, grad/param norm = 1.8127e-01, time/batch = 15.1639s	
28446/33250 (epoch 42.776), train_loss = 0.70947025, grad/param norm = 1.6740e-01, time/batch = 15.3139s	
28447/33250 (epoch 42.777), train_loss = 0.85501696, grad/param norm = 1.9147e-01, time/batch = 15.0322s	
28448/33250 (epoch 42.779), train_loss = 0.72667039, grad/param norm = 1.9357e-01, time/batch = 14.8585s	
28449/33250 (epoch 42.780), train_loss = 0.87740079, grad/param norm = 2.1796e-01, time/batch = 15.0954s	
28450/33250 (epoch 42.782), train_loss = 0.77259865, grad/param norm = 2.6000e-01, time/batch = 15.4733s	
28451/33250 (epoch 42.783), train_loss = 0.60124024, grad/param norm = 1.7315e-01, time/batch = 15.7287s	
28452/33250 (epoch 42.785), train_loss = 0.67925166, grad/param norm = 1.9161e-01, time/batch = 15.5652s	
28453/33250 (epoch 42.786), train_loss = 0.81937763, grad/param norm = 1.7820e-01, time/batch = 15.4134s	
28454/33250 (epoch 42.788), train_loss = 0.85420414, grad/param norm = 1.7406e-01, time/batch = 15.9713s	
28455/33250 (epoch 42.789), train_loss = 0.86017369, grad/param norm = 2.0517e-01, time/batch = 15.3937s	
28456/33250 (epoch 42.791), train_loss = 0.85414298, grad/param norm = 2.0606e-01, time/batch = 15.0776s	
28457/33250 (epoch 42.792), train_loss = 0.93236819, grad/param norm = 2.0975e-01, time/batch = 15.3378s	
28458/33250 (epoch 42.794), train_loss = 0.73356534, grad/param norm = 1.7355e-01, time/batch = 15.2669s	
28459/33250 (epoch 42.795), train_loss = 0.73719677, grad/param norm = 2.0444e-01, time/batch = 14.6495s	
28460/33250 (epoch 42.797), train_loss = 0.80389746, grad/param norm = 1.9745e-01, time/batch = 14.8874s	
28461/33250 (epoch 42.798), train_loss = 0.72227684, grad/param norm = 2.1570e-01, time/batch = 15.1774s	
28462/33250 (epoch 42.800), train_loss = 0.79308405, grad/param norm = 1.9358e-01, time/batch = 15.5692s	
28463/33250 (epoch 42.802), train_loss = 0.76819733, grad/param norm = 1.6766e-01, time/batch = 15.3356s	
28464/33250 (epoch 42.803), train_loss = 0.79000866, grad/param norm = 1.5790e-01, time/batch = 14.9388s	
28465/33250 (epoch 42.805), train_loss = 0.79533333, grad/param norm = 1.9705e-01, time/batch = 15.4884s	
28466/33250 (epoch 42.806), train_loss = 0.76605129, grad/param norm = 1.7203e-01, time/batch = 15.3309s	
28467/33250 (epoch 42.808), train_loss = 0.68944338, grad/param norm = 2.0189e-01, time/batch = 15.1299s	
28468/33250 (epoch 42.809), train_loss = 0.67484854, grad/param norm = 1.4555e-01, time/batch = 15.6133s	
28469/33250 (epoch 42.811), train_loss = 0.66601907, grad/param norm = 1.8161e-01, time/batch = 15.4490s	
28470/33250 (epoch 42.812), train_loss = 0.78430822, grad/param norm = 2.0533e-01, time/batch = 15.2300s	
28471/33250 (epoch 42.814), train_loss = 0.70901314, grad/param norm = 2.1165e-01, time/batch = 15.2490s	
28472/33250 (epoch 42.815), train_loss = 0.77986629, grad/param norm = 1.8621e-01, time/batch = 15.1831s	
28473/33250 (epoch 42.817), train_loss = 0.72682293, grad/param norm = 1.7602e-01, time/batch = 15.5781s	
28474/33250 (epoch 42.818), train_loss = 0.68569270, grad/param norm = 1.6978e-01, time/batch = 15.5678s	
28475/33250 (epoch 42.820), train_loss = 0.79079197, grad/param norm = 1.8410e-01, time/batch = 15.3607s	
28476/33250 (epoch 42.821), train_loss = 0.74825030, grad/param norm = 1.6296e-01, time/batch = 14.9646s	
28477/33250 (epoch 42.823), train_loss = 1.00156844, grad/param norm = 2.0335e-01, time/batch = 15.5047s	
28478/33250 (epoch 42.824), train_loss = 0.70775445, grad/param norm = 1.9800e-01, time/batch = 14.8581s	
28479/33250 (epoch 42.826), train_loss = 0.77993143, grad/param norm = 2.2457e-01, time/batch = 15.4799s	
28480/33250 (epoch 42.827), train_loss = 0.67881447, grad/param norm = 1.6786e-01, time/batch = 15.3842s	
28481/33250 (epoch 42.829), train_loss = 0.77099351, grad/param norm = 1.7514e-01, time/batch = 15.7014s	
28482/33250 (epoch 42.830), train_loss = 0.83115973, grad/param norm = 2.8711e-01, time/batch = 15.7476s	
28483/33250 (epoch 42.832), train_loss = 0.78302341, grad/param norm = 1.9393e-01, time/batch = 15.1166s	
28484/33250 (epoch 42.833), train_loss = 0.76040569, grad/param norm = 1.7798e-01, time/batch = 15.1315s	
28485/33250 (epoch 42.835), train_loss = 0.67520015, grad/param norm = 1.9880e-01, time/batch = 15.1908s	
28486/33250 (epoch 42.836), train_loss = 0.75095428, grad/param norm = 1.6848e-01, time/batch = 15.0260s	
28487/33250 (epoch 42.838), train_loss = 0.78507318, grad/param norm = 1.8191e-01, time/batch = 15.1104s	
28488/33250 (epoch 42.839), train_loss = 0.73848411, grad/param norm = 1.8751e-01, time/batch = 15.3440s	
28489/33250 (epoch 42.841), train_loss = 0.73152274, grad/param norm = 1.8527e-01, time/batch = 15.6103s	
28490/33250 (epoch 42.842), train_loss = 0.88795258, grad/param norm = 1.9941e-01, time/batch = 15.7101s	
28491/33250 (epoch 42.844), train_loss = 0.83596447, grad/param norm = 1.9428e-01, time/batch = 16.2755s	
28492/33250 (epoch 42.845), train_loss = 0.92137724, grad/param norm = 2.1064e-01, time/batch = 18.0022s	
28493/33250 (epoch 42.847), train_loss = 0.86828681, grad/param norm = 1.7956e-01, time/batch = 27.3863s	
28494/33250 (epoch 42.848), train_loss = 0.94344532, grad/param norm = 2.2276e-01, time/batch = 15.1048s	
28495/33250 (epoch 42.850), train_loss = 0.82978372, grad/param norm = 1.7992e-01, time/batch = 15.1778s	
28496/33250 (epoch 42.851), train_loss = 0.65927140, grad/param norm = 2.0637e-01, time/batch = 15.3283s	
28497/33250 (epoch 42.853), train_loss = 0.77773017, grad/param norm = 2.3658e-01, time/batch = 15.1000s	
28498/33250 (epoch 42.854), train_loss = 0.71912618, grad/param norm = 1.6649e-01, time/batch = 15.0655s	
28499/33250 (epoch 42.856), train_loss = 0.72734954, grad/param norm = 1.9909e-01, time/batch = 15.5212s	
28500/33250 (epoch 42.857), train_loss = 0.64171264, grad/param norm = 1.7393e-01, time/batch = 15.7501s	
28501/33250 (epoch 42.859), train_loss = 0.72815540, grad/param norm = 1.9122e-01, time/batch = 15.3015s	
28502/33250 (epoch 42.860), train_loss = 0.79855553, grad/param norm = 1.8554e-01, time/batch = 15.6130s	
28503/33250 (epoch 42.862), train_loss = 0.69905486, grad/param norm = 1.9463e-01, time/batch = 15.5163s	
28504/33250 (epoch 42.863), train_loss = 0.74082327, grad/param norm = 2.6765e-01, time/batch = 15.0303s	
28505/33250 (epoch 42.865), train_loss = 0.75477891, grad/param norm = 1.7738e-01, time/batch = 15.3322s	
28506/33250 (epoch 42.866), train_loss = 0.68622451, grad/param norm = 2.0510e-01, time/batch = 15.1693s	
28507/33250 (epoch 42.868), train_loss = 0.75548109, grad/param norm = 2.3849e-01, time/batch = 15.4976s	
28508/33250 (epoch 42.869), train_loss = 0.77942583, grad/param norm = 1.8057e-01, time/batch = 14.8780s	
28509/33250 (epoch 42.871), train_loss = 0.62781234, grad/param norm = 1.8565e-01, time/batch = 15.1940s	
28510/33250 (epoch 42.872), train_loss = 0.82537190, grad/param norm = 2.2407e-01, time/batch = 15.3790s	
28511/33250 (epoch 42.874), train_loss = 0.73246395, grad/param norm = 2.1958e-01, time/batch = 15.9855s	
28512/33250 (epoch 42.875), train_loss = 0.66272681, grad/param norm = 2.1634e-01, time/batch = 14.8239s	
28513/33250 (epoch 42.877), train_loss = 0.84977422, grad/param norm = 2.1757e-01, time/batch = 16.2337s	
28514/33250 (epoch 42.878), train_loss = 0.77762197, grad/param norm = 1.7368e-01, time/batch = 15.3982s	
28515/33250 (epoch 42.880), train_loss = 0.76873723, grad/param norm = 2.0987e-01, time/batch = 15.4190s	
28516/33250 (epoch 42.881), train_loss = 0.85420595, grad/param norm = 1.9653e-01, time/batch = 14.8706s	
28517/33250 (epoch 42.883), train_loss = 0.80415165, grad/param norm = 1.9148e-01, time/batch = 14.9413s	
28518/33250 (epoch 42.884), train_loss = 0.85961421, grad/param norm = 2.0243e-01, time/batch = 15.1859s	
28519/33250 (epoch 42.886), train_loss = 0.69433763, grad/param norm = 1.7137e-01, time/batch = 15.1114s	
28520/33250 (epoch 42.887), train_loss = 0.72962863, grad/param norm = 1.8026e-01, time/batch = 15.1128s	
28521/33250 (epoch 42.889), train_loss = 0.71788644, grad/param norm = 1.5486e-01, time/batch = 17.6145s	
28522/33250 (epoch 42.890), train_loss = 0.57978219, grad/param norm = 1.3376e-01, time/batch = 16.7911s	
28523/33250 (epoch 42.892), train_loss = 0.78933836, grad/param norm = 1.8508e-01, time/batch = 15.9405s	
28524/33250 (epoch 42.893), train_loss = 0.80897578, grad/param norm = 1.9853e-01, time/batch = 15.4577s	
28525/33250 (epoch 42.895), train_loss = 0.71350988, grad/param norm = 1.8340e-01, time/batch = 15.0433s	
28526/33250 (epoch 42.896), train_loss = 0.82038169, grad/param norm = 1.8706e-01, time/batch = 15.0336s	
28527/33250 (epoch 42.898), train_loss = 0.75580671, grad/param norm = 1.6285e-01, time/batch = 15.6776s	
28528/33250 (epoch 42.899), train_loss = 0.71492320, grad/param norm = 1.6708e-01, time/batch = 16.1169s	
28529/33250 (epoch 42.901), train_loss = 0.62113619, grad/param norm = 1.5047e-01, time/batch = 15.3705s	
28530/33250 (epoch 42.902), train_loss = 0.72021044, grad/param norm = 2.3945e-01, time/batch = 15.1969s	
28531/33250 (epoch 42.904), train_loss = 0.66910956, grad/param norm = 1.8209e-01, time/batch = 14.7676s	
28532/33250 (epoch 42.905), train_loss = 0.74388704, grad/param norm = 1.6410e-01, time/batch = 14.7134s	
28533/33250 (epoch 42.907), train_loss = 0.69206176, grad/param norm = 1.7956e-01, time/batch = 15.1250s	
28534/33250 (epoch 42.908), train_loss = 0.73881757, grad/param norm = 1.5581e-01, time/batch = 15.1391s	
28535/33250 (epoch 42.910), train_loss = 0.82382494, grad/param norm = 2.8908e-01, time/batch = 14.6634s	
28536/33250 (epoch 42.911), train_loss = 0.67476476, grad/param norm = 1.9545e-01, time/batch = 16.7142s	
28537/33250 (epoch 42.913), train_loss = 0.69876920, grad/param norm = 1.5111e-01, time/batch = 14.7149s	
28538/33250 (epoch 42.914), train_loss = 0.61934597, grad/param norm = 1.7101e-01, time/batch = 15.5076s	
28539/33250 (epoch 42.916), train_loss = 0.68671881, grad/param norm = 2.7768e-01, time/batch = 15.0020s	
28540/33250 (epoch 42.917), train_loss = 0.75494243, grad/param norm = 1.4522e-01, time/batch = 14.6863s	
28541/33250 (epoch 42.919), train_loss = 0.70153681, grad/param norm = 2.4392e-01, time/batch = 14.7105s	
28542/33250 (epoch 42.920), train_loss = 0.76024159, grad/param norm = 1.8674e-01, time/batch = 14.9501s	
28543/33250 (epoch 42.922), train_loss = 0.78340691, grad/param norm = 2.4509e-01, time/batch = 14.9567s	
28544/33250 (epoch 42.923), train_loss = 0.73273889, grad/param norm = 1.8782e-01, time/batch = 15.9018s	
28545/33250 (epoch 42.925), train_loss = 0.72786134, grad/param norm = 1.8310e-01, time/batch = 15.6254s	
28546/33250 (epoch 42.926), train_loss = 0.70228707, grad/param norm = 1.6556e-01, time/batch = 15.7979s	
28547/33250 (epoch 42.928), train_loss = 0.71253552, grad/param norm = 1.7769e-01, time/batch = 15.6295s	
28548/33250 (epoch 42.929), train_loss = 0.65038546, grad/param norm = 1.3155e-01, time/batch = 15.2030s	
28549/33250 (epoch 42.931), train_loss = 0.82675983, grad/param norm = 2.0820e-01, time/batch = 14.7955s	
28550/33250 (epoch 42.932), train_loss = 0.69566006, grad/param norm = 1.8733e-01, time/batch = 15.5023s	
28551/33250 (epoch 42.934), train_loss = 0.67848600, grad/param norm = 1.5499e-01, time/batch = 15.0238s	
28552/33250 (epoch 42.935), train_loss = 0.72215511, grad/param norm = 1.8394e-01, time/batch = 15.2731s	
28553/33250 (epoch 42.937), train_loss = 0.67496907, grad/param norm = 1.7543e-01, time/batch = 14.9370s	
28554/33250 (epoch 42.938), train_loss = 0.70874007, grad/param norm = 1.9913e-01, time/batch = 15.9290s	
28555/33250 (epoch 42.940), train_loss = 0.73777044, grad/param norm = 2.1889e-01, time/batch = 16.9546s	
28556/33250 (epoch 42.941), train_loss = 0.79801315, grad/param norm = 1.9661e-01, time/batch = 15.7051s	
28557/33250 (epoch 42.943), train_loss = 0.87879204, grad/param norm = 1.9811e-01, time/batch = 15.2117s	
28558/33250 (epoch 42.944), train_loss = 0.71649974, grad/param norm = 1.6772e-01, time/batch = 14.9571s	
28559/33250 (epoch 42.946), train_loss = 0.81992600, grad/param norm = 2.0021e-01, time/batch = 14.6896s	
28560/33250 (epoch 42.947), train_loss = 0.66482316, grad/param norm = 1.6601e-01, time/batch = 15.2736s	
28561/33250 (epoch 42.949), train_loss = 0.81182403, grad/param norm = 2.1365e-01, time/batch = 15.0348s	
28562/33250 (epoch 42.950), train_loss = 0.82341636, grad/param norm = 1.9395e-01, time/batch = 14.8661s	
28563/33250 (epoch 42.952), train_loss = 0.76577053, grad/param norm = 2.1342e-01, time/batch = 14.4704s	
28564/33250 (epoch 42.953), train_loss = 0.76173441, grad/param norm = 2.0518e-01, time/batch = 14.8677s	
28565/33250 (epoch 42.955), train_loss = 0.80398906, grad/param norm = 1.9145e-01, time/batch = 15.0302s	
28566/33250 (epoch 42.956), train_loss = 0.75857986, grad/param norm = 2.3666e-01, time/batch = 15.3880s	
28567/33250 (epoch 42.958), train_loss = 0.72195294, grad/param norm = 1.8992e-01, time/batch = 16.5637s	
28568/33250 (epoch 42.959), train_loss = 0.71334894, grad/param norm = 1.7201e-01, time/batch = 16.2375s	
28569/33250 (epoch 42.961), train_loss = 0.93416763, grad/param norm = 2.2049e-01, time/batch = 15.1052s	
28570/33250 (epoch 42.962), train_loss = 0.73390426, grad/param norm = 1.8914e-01, time/batch = 15.1872s	
28571/33250 (epoch 42.964), train_loss = 0.86301215, grad/param norm = 2.0208e-01, time/batch = 15.1260s	
28572/33250 (epoch 42.965), train_loss = 0.80936496, grad/param norm = 1.9838e-01, time/batch = 14.6216s	
28573/33250 (epoch 42.967), train_loss = 0.73931491, grad/param norm = 1.9276e-01, time/batch = 15.0350s	
28574/33250 (epoch 42.968), train_loss = 0.86189565, grad/param norm = 1.8115e-01, time/batch = 15.3503s	
28575/33250 (epoch 42.970), train_loss = 0.96063366, grad/param norm = 2.2758e-01, time/batch = 15.2600s	
28576/33250 (epoch 42.971), train_loss = 0.91056515, grad/param norm = 2.2402e-01, time/batch = 15.2203s	
28577/33250 (epoch 42.973), train_loss = 0.72899438, grad/param norm = 1.6046e-01, time/batch = 15.7859s	
28578/33250 (epoch 42.974), train_loss = 0.81291093, grad/param norm = 1.9764e-01, time/batch = 16.1131s	
28579/33250 (epoch 42.976), train_loss = 0.73628797, grad/param norm = 1.9728e-01, time/batch = 16.3039s	
28580/33250 (epoch 42.977), train_loss = 0.75115483, grad/param norm = 1.7095e-01, time/batch = 14.9743s	
28581/33250 (epoch 42.979), train_loss = 0.81860998, grad/param norm = 2.0043e-01, time/batch = 14.8678s	
28582/33250 (epoch 42.980), train_loss = 0.79946569, grad/param norm = 1.7481e-01, time/batch = 14.8853s	
28583/33250 (epoch 42.982), train_loss = 0.72995161, grad/param norm = 1.5868e-01, time/batch = 15.0950s	
28584/33250 (epoch 42.983), train_loss = 0.80285574, grad/param norm = 2.0954e-01, time/batch = 14.8676s	
28585/33250 (epoch 42.985), train_loss = 0.72909872, grad/param norm = 1.8691e-01, time/batch = 15.4965s	
28586/33250 (epoch 42.986), train_loss = 0.82057912, grad/param norm = 1.8587e-01, time/batch = 15.1244s	
28587/33250 (epoch 42.988), train_loss = 0.87713053, grad/param norm = 2.0479e-01, time/batch = 16.0439s	
28588/33250 (epoch 42.989), train_loss = 0.84259390, grad/param norm = 2.0086e-01, time/batch = 14.7374s	
28589/33250 (epoch 42.991), train_loss = 0.82099438, grad/param norm = 1.7715e-01, time/batch = 15.4506s	
28590/33250 (epoch 42.992), train_loss = 0.74301470, grad/param norm = 1.7464e-01, time/batch = 16.1362s	
28591/33250 (epoch 42.994), train_loss = 0.71566251, grad/param norm = 1.8788e-01, time/batch = 15.0383s	
28592/33250 (epoch 42.995), train_loss = 0.75633708, grad/param norm = 2.4194e-01, time/batch = 14.7695s	
28593/33250 (epoch 42.997), train_loss = 0.58129318, grad/param norm = 1.6019e-01, time/batch = 14.7839s	
28594/33250 (epoch 42.998), train_loss = 0.78861951, grad/param norm = 1.8138e-01, time/batch = 14.7167s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
28595/33250 (epoch 43.000), train_loss = 0.82449292, grad/param norm = 2.2408e-01, time/batch = 15.1927s	
28596/33250 (epoch 43.002), train_loss = 0.97303377, grad/param norm = 1.9590e-01, time/batch = 14.8780s	
28597/33250 (epoch 43.003), train_loss = 0.82254535, grad/param norm = 2.1446e-01, time/batch = 15.6444s	
28598/33250 (epoch 43.005), train_loss = 0.63743958, grad/param norm = 1.6675e-01, time/batch = 15.4520s	
28599/33250 (epoch 43.006), train_loss = 0.65349723, grad/param norm = 1.8880e-01, time/batch = 17.6332s	
28600/33250 (epoch 43.008), train_loss = 0.85000968, grad/param norm = 2.0255e-01, time/batch = 14.8912s	
28601/33250 (epoch 43.009), train_loss = 0.92540621, grad/param norm = 2.0365e-01, time/batch = 15.3094s	
28602/33250 (epoch 43.011), train_loss = 0.72740011, grad/param norm = 2.0562e-01, time/batch = 14.7998s	
28603/33250 (epoch 43.012), train_loss = 0.75771447, grad/param norm = 2.4785e-01, time/batch = 14.4560s	
28604/33250 (epoch 43.014), train_loss = 0.86078001, grad/param norm = 2.2224e-01, time/batch = 14.8559s	
28605/33250 (epoch 43.015), train_loss = 0.78266269, grad/param norm = 1.8821e-01, time/batch = 14.8667s	
28606/33250 (epoch 43.017), train_loss = 0.79528305, grad/param norm = 2.1981e-01, time/batch = 14.4618s	
28607/33250 (epoch 43.018), train_loss = 0.60403991, grad/param norm = 1.8411e-01, time/batch = 14.6296s	
28608/33250 (epoch 43.020), train_loss = 0.78299634, grad/param norm = 1.6751e-01, time/batch = 14.9254s	
28609/33250 (epoch 43.021), train_loss = 0.78786732, grad/param norm = 1.7557e-01, time/batch = 15.0337s	
28610/33250 (epoch 43.023), train_loss = 0.64106159, grad/param norm = 1.8940e-01, time/batch = 14.8017s	
28611/33250 (epoch 43.024), train_loss = 0.84685854, grad/param norm = 2.2785e-01, time/batch = 14.9043s	
28612/33250 (epoch 43.026), train_loss = 0.80879106, grad/param norm = 1.8366e-01, time/batch = 15.1923s	
28613/33250 (epoch 43.027), train_loss = 0.80881226, grad/param norm = 1.9125e-01, time/batch = 15.4162s	
28614/33250 (epoch 43.029), train_loss = 0.75060055, grad/param norm = 1.9650e-01, time/batch = 15.2615s	
28615/33250 (epoch 43.030), train_loss = 0.74483538, grad/param norm = 1.8525e-01, time/batch = 15.6301s	
28616/33250 (epoch 43.032), train_loss = 0.93709363, grad/param norm = 2.2035e-01, time/batch = 15.3426s	
28617/33250 (epoch 43.033), train_loss = 0.75337683, grad/param norm = 2.2140e-01, time/batch = 15.6819s	
28618/33250 (epoch 43.035), train_loss = 0.78888288, grad/param norm = 2.1412e-01, time/batch = 15.2393s	
28619/33250 (epoch 43.036), train_loss = 0.81199247, grad/param norm = 1.8854e-01, time/batch = 14.9544s	
28620/33250 (epoch 43.038), train_loss = 0.76692413, grad/param norm = 1.5491e-01, time/batch = 15.3485s	
28621/33250 (epoch 43.039), train_loss = 0.71974488, grad/param norm = 1.8300e-01, time/batch = 15.4008s	
28622/33250 (epoch 43.041), train_loss = 0.78840718, grad/param norm = 2.7322e-01, time/batch = 15.0679s	
28623/33250 (epoch 43.042), train_loss = 0.65287853, grad/param norm = 1.5659e-01, time/batch = 15.7310s	
28624/33250 (epoch 43.044), train_loss = 0.87011172, grad/param norm = 2.0460e-01, time/batch = 15.4257s	
28625/33250 (epoch 43.045), train_loss = 0.86518470, grad/param norm = 1.9094e-01, time/batch = 14.9584s	
28626/33250 (epoch 43.047), train_loss = 0.79782716, grad/param norm = 1.8756e-01, time/batch = 14.9526s	
28627/33250 (epoch 43.048), train_loss = 0.79522440, grad/param norm = 1.9500e-01, time/batch = 14.7193s	
28628/33250 (epoch 43.050), train_loss = 0.76534285, grad/param norm = 1.9328e-01, time/batch = 15.2688s	
28629/33250 (epoch 43.051), train_loss = 0.76553906, grad/param norm = 1.7223e-01, time/batch = 15.0190s	
28630/33250 (epoch 43.053), train_loss = 0.81866166, grad/param norm = 1.9460e-01, time/batch = 14.7996s	
28631/33250 (epoch 43.054), train_loss = 0.66748433, grad/param norm = 1.5882e-01, time/batch = 16.0528s	
28632/33250 (epoch 43.056), train_loss = 0.64708838, grad/param norm = 1.5998e-01, time/batch = 15.9341s	
28633/33250 (epoch 43.057), train_loss = 0.84252022, grad/param norm = 1.8484e-01, time/batch = 15.0553s	
28634/33250 (epoch 43.059), train_loss = 0.75322471, grad/param norm = 1.8889e-01, time/batch = 15.6201s	
28635/33250 (epoch 43.060), train_loss = 0.77621569, grad/param norm = 1.9179e-01, time/batch = 14.8932s	
28636/33250 (epoch 43.062), train_loss = 0.85009414, grad/param norm = 1.8367e-01, time/batch = 15.1223s	
28637/33250 (epoch 43.063), train_loss = 0.87970770, grad/param norm = 1.7381e-01, time/batch = 15.1156s	
28638/33250 (epoch 43.065), train_loss = 0.73361518, grad/param norm = 1.7142e-01, time/batch = 15.7146s	
28639/33250 (epoch 43.066), train_loss = 0.81086989, grad/param norm = 1.9380e-01, time/batch = 16.0334s	
28640/33250 (epoch 43.068), train_loss = 0.73263789, grad/param norm = 1.8276e-01, time/batch = 15.7813s	
28641/33250 (epoch 43.069), train_loss = 0.79043437, grad/param norm = 1.8168e-01, time/batch = 15.2653s	
28642/33250 (epoch 43.071), train_loss = 0.74386059, grad/param norm = 1.9441e-01, time/batch = 15.0423s	
28643/33250 (epoch 43.072), train_loss = 0.69204605, grad/param norm = 1.6727e-01, time/batch = 15.0467s	
28644/33250 (epoch 43.074), train_loss = 0.79022743, grad/param norm = 1.9731e-01, time/batch = 15.2025s	
28645/33250 (epoch 43.075), train_loss = 0.72531204, grad/param norm = 1.7876e-01, time/batch = 15.4633s	
28646/33250 (epoch 43.077), train_loss = 0.76482893, grad/param norm = 2.3019e-01, time/batch = 15.0540s	
28647/33250 (epoch 43.078), train_loss = 0.77316775, grad/param norm = 1.7812e-01, time/batch = 15.1226s	
28648/33250 (epoch 43.080), train_loss = 0.78249494, grad/param norm = 2.1828e-01, time/batch = 15.9590s	
28649/33250 (epoch 43.081), train_loss = 0.79643054, grad/param norm = 1.6936e-01, time/batch = 15.7124s	
28650/33250 (epoch 43.083), train_loss = 0.87503182, grad/param norm = 1.8552e-01, time/batch = 15.9711s	
28651/33250 (epoch 43.084), train_loss = 0.81414537, grad/param norm = 1.9672e-01, time/batch = 15.4200s	
28652/33250 (epoch 43.086), train_loss = 0.76477268, grad/param norm = 1.6416e-01, time/batch = 15.6954s	
28653/33250 (epoch 43.087), train_loss = 0.67028388, grad/param norm = 1.5527e-01, time/batch = 16.1104s	
28654/33250 (epoch 43.089), train_loss = 0.75101217, grad/param norm = 1.9732e-01, time/batch = 15.7562s	
28655/33250 (epoch 43.090), train_loss = 0.78458601, grad/param norm = 1.7900e-01, time/batch = 14.9552s	
28656/33250 (epoch 43.092), train_loss = 0.71521769, grad/param norm = 1.6289e-01, time/batch = 15.1044s	
28657/33250 (epoch 43.093), train_loss = 0.74832647, grad/param norm = 1.7096e-01, time/batch = 15.6119s	
28658/33250 (epoch 43.095), train_loss = 0.77640770, grad/param norm = 2.0852e-01, time/batch = 14.9717s	
28659/33250 (epoch 43.096), train_loss = 0.65527916, grad/param norm = 1.8326e-01, time/batch = 15.2808s	
28660/33250 (epoch 43.098), train_loss = 0.64769247, grad/param norm = 1.8420e-01, time/batch = 16.3872s	
28661/33250 (epoch 43.099), train_loss = 0.60505294, grad/param norm = 1.4750e-01, time/batch = 15.5902s	
28662/33250 (epoch 43.101), train_loss = 0.75189590, grad/param norm = 2.0866e-01, time/batch = 14.7074s	
28663/33250 (epoch 43.102), train_loss = 0.70817238, grad/param norm = 1.5781e-01, time/batch = 15.2033s	
28664/33250 (epoch 43.104), train_loss = 0.59472918, grad/param norm = 1.7501e-01, time/batch = 14.8859s	
28665/33250 (epoch 43.105), train_loss = 0.72330645, grad/param norm = 1.8588e-01, time/batch = 15.0902s	
28666/33250 (epoch 43.107), train_loss = 0.64351408, grad/param norm = 1.4336e-01, time/batch = 15.5431s	
28667/33250 (epoch 43.108), train_loss = 0.76341580, grad/param norm = 2.2377e-01, time/batch = 15.3234s	
28668/33250 (epoch 43.110), train_loss = 0.65173272, grad/param norm = 1.9285e-01, time/batch = 15.8598s	
28669/33250 (epoch 43.111), train_loss = 0.76494946, grad/param norm = 1.7763e-01, time/batch = 15.8445s	
28670/33250 (epoch 43.113), train_loss = 0.69802818, grad/param norm = 1.7142e-01, time/batch = 15.2323s	
28671/33250 (epoch 43.114), train_loss = 0.65643869, grad/param norm = 1.7636e-01, time/batch = 15.5591s	
28672/33250 (epoch 43.116), train_loss = 0.69780797, grad/param norm = 1.7600e-01, time/batch = 16.0414s	
28673/33250 (epoch 43.117), train_loss = 0.67155696, grad/param norm = 1.7441e-01, time/batch = 15.1963s	
28674/33250 (epoch 43.119), train_loss = 0.70275485, grad/param norm = 1.6008e-01, time/batch = 15.3319s	
28675/33250 (epoch 43.120), train_loss = 0.62570521, grad/param norm = 1.5240e-01, time/batch = 15.3613s	
28676/33250 (epoch 43.122), train_loss = 0.80570530, grad/param norm = 1.8891e-01, time/batch = 15.1623s	
28677/33250 (epoch 43.123), train_loss = 0.73441927, grad/param norm = 2.0207e-01, time/batch = 15.3857s	
28678/33250 (epoch 43.125), train_loss = 0.60032031, grad/param norm = 1.8248e-01, time/batch = 14.5378s	
28679/33250 (epoch 43.126), train_loss = 0.71863801, grad/param norm = 1.7959e-01, time/batch = 14.5517s	
28680/33250 (epoch 43.128), train_loss = 0.69407651, grad/param norm = 1.5837e-01, time/batch = 16.5500s	
28681/33250 (epoch 43.129), train_loss = 0.74779382, grad/param norm = 1.8440e-01, time/batch = 14.6440s	
28682/33250 (epoch 43.131), train_loss = 0.72732713, grad/param norm = 1.7722e-01, time/batch = 14.8004s	
28683/33250 (epoch 43.132), train_loss = 0.69868034, grad/param norm = 1.7091e-01, time/batch = 14.4887s	
28684/33250 (epoch 43.134), train_loss = 0.66939137, grad/param norm = 1.6907e-01, time/batch = 14.3706s	
28685/33250 (epoch 43.135), train_loss = 0.76362703, grad/param norm = 1.5364e-01, time/batch = 14.5303s	
28686/33250 (epoch 43.137), train_loss = 0.67319229, grad/param norm = 2.0272e-01, time/batch = 15.1098s	
28687/33250 (epoch 43.138), train_loss = 0.65661428, grad/param norm = 1.5542e-01, time/batch = 15.1029s	
28688/33250 (epoch 43.140), train_loss = 0.58838397, grad/param norm = 1.5558e-01, time/batch = 14.8860s	
28689/33250 (epoch 43.141), train_loss = 0.81203949, grad/param norm = 2.6712e-01, time/batch = 14.5456s	
28690/33250 (epoch 43.143), train_loss = 0.63814768, grad/param norm = 1.7503e-01, time/batch = 14.4648s	
28691/33250 (epoch 43.144), train_loss = 0.71735979, grad/param norm = 1.8283e-01, time/batch = 14.8594s	
28692/33250 (epoch 43.146), train_loss = 0.69293679, grad/param norm = 1.6254e-01, time/batch = 18.5408s	
28693/33250 (epoch 43.147), train_loss = 0.72437713, grad/param norm = 1.8976e-01, time/batch = 15.5751s	
28694/33250 (epoch 43.149), train_loss = 0.68995169, grad/param norm = 1.6951e-01, time/batch = 15.8062s	
28695/33250 (epoch 43.150), train_loss = 0.66898097, grad/param norm = 1.6233e-01, time/batch = 16.1878s	
28696/33250 (epoch 43.152), train_loss = 0.62089052, grad/param norm = 1.5636e-01, time/batch = 15.3611s	
28697/33250 (epoch 43.153), train_loss = 0.86596706, grad/param norm = 1.8469e-01, time/batch = 15.1747s	
28698/33250 (epoch 43.155), train_loss = 0.70581830, grad/param norm = 2.0876e-01, time/batch = 14.9547s	
28699/33250 (epoch 43.156), train_loss = 0.91885041, grad/param norm = 1.8384e-01, time/batch = 14.5329s	
28700/33250 (epoch 43.158), train_loss = 0.87160590, grad/param norm = 2.2807e-01, time/batch = 14.9510s	
28701/33250 (epoch 43.159), train_loss = 0.71129884, grad/param norm = 2.2041e-01, time/batch = 14.8760s	
28702/33250 (epoch 43.161), train_loss = 0.75703760, grad/param norm = 1.9923e-01, time/batch = 15.4346s	
28703/33250 (epoch 43.162), train_loss = 0.66546187, grad/param norm = 1.7186e-01, time/batch = 14.6651s	
28704/33250 (epoch 43.164), train_loss = 0.75446430, grad/param norm = 2.5903e-01, time/batch = 15.8117s	
28705/33250 (epoch 43.165), train_loss = 0.81618850, grad/param norm = 1.9609e-01, time/batch = 14.8918s	
28706/33250 (epoch 43.167), train_loss = 0.87009370, grad/param norm = 2.0522e-01, time/batch = 15.5961s	
28707/33250 (epoch 43.168), train_loss = 0.66799468, grad/param norm = 1.8034e-01, time/batch = 14.8670s	
28708/33250 (epoch 43.170), train_loss = 0.71966704, grad/param norm = 1.9423e-01, time/batch = 14.7138s	
28709/33250 (epoch 43.171), train_loss = 0.73574857, grad/param norm = 1.7457e-01, time/batch = 14.8027s	
28710/33250 (epoch 43.173), train_loss = 0.75316019, grad/param norm = 1.7985e-01, time/batch = 14.6169s	
28711/33250 (epoch 43.174), train_loss = 0.76243900, grad/param norm = 1.6148e-01, time/batch = 15.1042s	
28712/33250 (epoch 43.176), train_loss = 0.68467240, grad/param norm = 1.6872e-01, time/batch = 14.9387s	
28713/33250 (epoch 43.177), train_loss = 0.67387315, grad/param norm = 1.5189e-01, time/batch = 14.6337s	
28714/33250 (epoch 43.179), train_loss = 0.67363124, grad/param norm = 1.4470e-01, time/batch = 14.8961s	
28715/33250 (epoch 43.180), train_loss = 0.61711603, grad/param norm = 1.7879e-01, time/batch = 15.5145s	
28716/33250 (epoch 43.182), train_loss = 0.66492944, grad/param norm = 1.9323e-01, time/batch = 15.5627s	
28717/33250 (epoch 43.183), train_loss = 0.82594497, grad/param norm = 2.0448e-01, time/batch = 15.6173s	
28718/33250 (epoch 43.185), train_loss = 0.75873464, grad/param norm = 2.5261e-01, time/batch = 15.2038s	
28719/33250 (epoch 43.186), train_loss = 0.77020901, grad/param norm = 2.0989e-01, time/batch = 15.0267s	
28720/33250 (epoch 43.188), train_loss = 0.82621470, grad/param norm = 2.0084e-01, time/batch = 14.7723s	
28721/33250 (epoch 43.189), train_loss = 0.60059226, grad/param norm = 2.0656e-01, time/batch = 14.6343s	
28722/33250 (epoch 43.191), train_loss = 0.69461542, grad/param norm = 1.8337e-01, time/batch = 15.1651s	
28723/33250 (epoch 43.192), train_loss = 0.70821065, grad/param norm = 1.9739e-01, time/batch = 14.6364s	
28724/33250 (epoch 43.194), train_loss = 0.72225012, grad/param norm = 1.9780e-01, time/batch = 14.7199s	
28725/33250 (epoch 43.195), train_loss = 0.88170890, grad/param norm = 1.8146e-01, time/batch = 17.7177s	
28726/33250 (epoch 43.197), train_loss = 0.68963298, grad/param norm = 1.6406e-01, time/batch = 31.5858s	
28727/33250 (epoch 43.198), train_loss = 0.86526170, grad/param norm = 1.8525e-01, time/batch = 15.2134s	
28728/33250 (epoch 43.200), train_loss = 0.74458061, grad/param norm = 1.9110e-01, time/batch = 14.9499s	
28729/33250 (epoch 43.202), train_loss = 0.71587106, grad/param norm = 1.7031e-01, time/batch = 14.9405s	
28730/33250 (epoch 43.203), train_loss = 0.65867910, grad/param norm = 1.7379e-01, time/batch = 14.8614s	
28731/33250 (epoch 43.205), train_loss = 0.75433630, grad/param norm = 1.7162e-01, time/batch = 14.8626s	
28732/33250 (epoch 43.206), train_loss = 0.79534740, grad/param norm = 1.7197e-01, time/batch = 14.7020s	
28733/33250 (epoch 43.208), train_loss = 0.83260333, grad/param norm = 2.1194e-01, time/batch = 15.4810s	
28734/33250 (epoch 43.209), train_loss = 0.70484999, grad/param norm = 1.6851e-01, time/batch = 16.2699s	
28735/33250 (epoch 43.211), train_loss = 0.76403941, grad/param norm = 1.8781e-01, time/batch = 16.2753s	
28736/33250 (epoch 43.212), train_loss = 0.85682988, grad/param norm = 1.7961e-01, time/batch = 15.3689s	
28737/33250 (epoch 43.214), train_loss = 0.76535597, grad/param norm = 1.5726e-01, time/batch = 17.7843s	
28738/33250 (epoch 43.215), train_loss = 0.77697732, grad/param norm = 1.8906e-01, time/batch = 15.7049s	
28739/33250 (epoch 43.217), train_loss = 0.82808189, grad/param norm = 2.5238e-01, time/batch = 14.7942s	
28740/33250 (epoch 43.218), train_loss = 0.78938351, grad/param norm = 1.7514e-01, time/batch = 15.0274s	
28741/33250 (epoch 43.220), train_loss = 0.75719420, grad/param norm = 1.9481e-01, time/batch = 14.9593s	
28742/33250 (epoch 43.221), train_loss = 0.84759278, grad/param norm = 2.0249e-01, time/batch = 14.6339s	
28743/33250 (epoch 43.223), train_loss = 0.74742184, grad/param norm = 1.5908e-01, time/batch = 14.7031s	
28744/33250 (epoch 43.224), train_loss = 0.78349822, grad/param norm = 1.9331e-01, time/batch = 15.4128s	
28745/33250 (epoch 43.226), train_loss = 0.86618394, grad/param norm = 1.9731e-01, time/batch = 15.4137s	
28746/33250 (epoch 43.227), train_loss = 0.79307976, grad/param norm = 1.8184e-01, time/batch = 14.7296s	
28747/33250 (epoch 43.229), train_loss = 0.76957629, grad/param norm = 1.6799e-01, time/batch = 15.3294s	
28748/33250 (epoch 43.230), train_loss = 0.76759024, grad/param norm = 1.8465e-01, time/batch = 15.1131s	
28749/33250 (epoch 43.232), train_loss = 0.71122446, grad/param norm = 1.7302e-01, time/batch = 15.5385s	
28750/33250 (epoch 43.233), train_loss = 0.68275492, grad/param norm = 1.6790e-01, time/batch = 14.3923s	
28751/33250 (epoch 43.235), train_loss = 0.85910208, grad/param norm = 1.8714e-01, time/batch = 14.5535s	
28752/33250 (epoch 43.236), train_loss = 0.69109926, grad/param norm = 1.9764e-01, time/batch = 14.9300s	
28753/33250 (epoch 43.238), train_loss = 0.85128026, grad/param norm = 2.1051e-01, time/batch = 15.1652s	
28754/33250 (epoch 43.239), train_loss = 0.85673852, grad/param norm = 2.4558e-01, time/batch = 14.9608s	
28755/33250 (epoch 43.241), train_loss = 0.84702767, grad/param norm = 2.4372e-01, time/batch = 15.0871s	
28756/33250 (epoch 43.242), train_loss = 0.83485237, grad/param norm = 2.0756e-01, time/batch = 15.1810s	
28757/33250 (epoch 43.244), train_loss = 0.80306841, grad/param norm = 2.1684e-01, time/batch = 15.7113s	
28758/33250 (epoch 43.245), train_loss = 0.78495414, grad/param norm = 2.0235e-01, time/batch = 15.1345s	
28759/33250 (epoch 43.247), train_loss = 0.75183069, grad/param norm = 1.8813e-01, time/batch = 15.4383s	
28760/33250 (epoch 43.248), train_loss = 0.88081741, grad/param norm = 2.2516e-01, time/batch = 16.6078s	
28761/33250 (epoch 43.250), train_loss = 0.87984995, grad/param norm = 1.7646e-01, time/batch = 14.8848s	
28762/33250 (epoch 43.251), train_loss = 0.74328188, grad/param norm = 1.6332e-01, time/batch = 14.7090s	
28763/33250 (epoch 43.253), train_loss = 0.74171600, grad/param norm = 1.8034e-01, time/batch = 14.9519s	
28764/33250 (epoch 43.254), train_loss = 0.70459008, grad/param norm = 1.7373e-01, time/batch = 15.1024s	
28765/33250 (epoch 43.256), train_loss = 0.76782650, grad/param norm = 1.6266e-01, time/batch = 14.4711s	
28766/33250 (epoch 43.257), train_loss = 0.90855900, grad/param norm = 1.8373e-01, time/batch = 14.6973s	
28767/33250 (epoch 43.259), train_loss = 0.79456369, grad/param norm = 2.1309e-01, time/batch = 15.2523s	
28768/33250 (epoch 43.260), train_loss = 0.62980511, grad/param norm = 2.0838e-01, time/batch = 15.0161s	
28769/33250 (epoch 43.262), train_loss = 0.77247252, grad/param norm = 1.8150e-01, time/batch = 15.2395s	
28770/33250 (epoch 43.263), train_loss = 0.63186539, grad/param norm = 1.7617e-01, time/batch = 15.5560s	
28771/33250 (epoch 43.265), train_loss = 0.79211091, grad/param norm = 2.0392e-01, time/batch = 15.6286s	
28772/33250 (epoch 43.266), train_loss = 0.77042546, grad/param norm = 2.0375e-01, time/batch = 15.0237s	
28773/33250 (epoch 43.268), train_loss = 0.66108221, grad/param norm = 1.7079e-01, time/batch = 15.3486s	
28774/33250 (epoch 43.269), train_loss = 0.63215363, grad/param norm = 1.8056e-01, time/batch = 15.1890s	
28775/33250 (epoch 43.271), train_loss = 0.80726304, grad/param norm = 1.7497e-01, time/batch = 14.7834s	
28776/33250 (epoch 43.272), train_loss = 0.69461153, grad/param norm = 1.5537e-01, time/batch = 15.2773s	
28777/33250 (epoch 43.274), train_loss = 0.56434335, grad/param norm = 1.5725e-01, time/batch = 14.7829s	
28778/33250 (epoch 43.275), train_loss = 0.71292273, grad/param norm = 1.4327e-01, time/batch = 14.6916s	
28779/33250 (epoch 43.277), train_loss = 0.63935584, grad/param norm = 2.0817e-01, time/batch = 15.7925s	
28780/33250 (epoch 43.278), train_loss = 0.70446964, grad/param norm = 1.5986e-01, time/batch = 14.5585s	
28781/33250 (epoch 43.280), train_loss = 0.67771703, grad/param norm = 1.9340e-01, time/batch = 15.6349s	
28782/33250 (epoch 43.281), train_loss = 0.76364930, grad/param norm = 1.8154e-01, time/batch = 15.2993s	
28783/33250 (epoch 43.283), train_loss = 0.76889624, grad/param norm = 2.9216e-01, time/batch = 15.1841s	
28784/33250 (epoch 43.284), train_loss = 0.64960591, grad/param norm = 2.1463e-01, time/batch = 14.7902s	
28785/33250 (epoch 43.286), train_loss = 0.77114122, grad/param norm = 1.8627e-01, time/batch = 14.5510s	
28786/33250 (epoch 43.287), train_loss = 0.63621961, grad/param norm = 1.6801e-01, time/batch = 15.0317s	
28787/33250 (epoch 43.289), train_loss = 0.59820500, grad/param norm = 1.6557e-01, time/batch = 14.8567s	
28788/33250 (epoch 43.290), train_loss = 0.74685800, grad/param norm = 1.7281e-01, time/batch = 15.0084s	
28789/33250 (epoch 43.292), train_loss = 0.79102021, grad/param norm = 2.6384e-01, time/batch = 14.8759s	
28790/33250 (epoch 43.293), train_loss = 0.85130483, grad/param norm = 1.8781e-01, time/batch = 14.8060s	
28791/33250 (epoch 43.295), train_loss = 0.84912154, grad/param norm = 1.8561e-01, time/batch = 16.9523s	
28792/33250 (epoch 43.296), train_loss = 0.74672463, grad/param norm = 1.6931e-01, time/batch = 15.7039s	
28793/33250 (epoch 43.298), train_loss = 0.61641065, grad/param norm = 1.6998e-01, time/batch = 15.1232s	
28794/33250 (epoch 43.299), train_loss = 0.60936159, grad/param norm = 1.8868e-01, time/batch = 14.9461s	
28795/33250 (epoch 43.301), train_loss = 0.79824332, grad/param norm = 1.6838e-01, time/batch = 14.9414s	
28796/33250 (epoch 43.302), train_loss = 0.80990436, grad/param norm = 2.2771e-01, time/batch = 14.9379s	
28797/33250 (epoch 43.304), train_loss = 0.73468457, grad/param norm = 2.4274e-01, time/batch = 14.7169s	
28798/33250 (epoch 43.305), train_loss = 0.69993224, grad/param norm = 1.8470e-01, time/batch = 14.8658s	
28799/33250 (epoch 43.307), train_loss = 0.79766648, grad/param norm = 1.9049e-01, time/batch = 14.9441s	
28800/33250 (epoch 43.308), train_loss = 0.86767963, grad/param norm = 2.2165e-01, time/batch = 14.9418s	
28801/33250 (epoch 43.310), train_loss = 0.71201697, grad/param norm = 2.0043e-01, time/batch = 16.3829s	
28802/33250 (epoch 43.311), train_loss = 0.89274813, grad/param norm = 2.1765e-01, time/batch = 15.4528s	
28803/33250 (epoch 43.313), train_loss = 0.62333267, grad/param norm = 1.8657e-01, time/batch = 15.1212s	
28804/33250 (epoch 43.314), train_loss = 0.81659833, grad/param norm = 1.6584e-01, time/batch = 14.8825s	
28805/33250 (epoch 43.316), train_loss = 0.91126458, grad/param norm = 2.0283e-01, time/batch = 14.8751s	
28806/33250 (epoch 43.317), train_loss = 0.67084243, grad/param norm = 1.5820e-01, time/batch = 15.0260s	
28807/33250 (epoch 43.319), train_loss = 0.80547040, grad/param norm = 2.3412e-01, time/batch = 14.7901s	
28808/33250 (epoch 43.320), train_loss = 0.85080119, grad/param norm = 2.7626e-01, time/batch = 14.8675s	
28809/33250 (epoch 43.322), train_loss = 0.92260992, grad/param norm = 2.1091e-01, time/batch = 14.9137s	
28810/33250 (epoch 43.323), train_loss = 0.89761125, grad/param norm = 2.5087e-01, time/batch = 14.7104s	
28811/33250 (epoch 43.325), train_loss = 0.73916054, grad/param norm = 2.2194e-01, time/batch = 15.1086s	
28812/33250 (epoch 43.326), train_loss = 0.98052239, grad/param norm = 2.1906e-01, time/batch = 15.2503s	
28813/33250 (epoch 43.328), train_loss = 0.76262869, grad/param norm = 1.9614e-01, time/batch = 14.8872s	
28814/33250 (epoch 43.329), train_loss = 0.80934336, grad/param norm = 2.8741e-01, time/batch = 14.6335s	
28815/33250 (epoch 43.331), train_loss = 0.76628241, grad/param norm = 2.0188e-01, time/batch = 14.8774s	
28816/33250 (epoch 43.332), train_loss = 0.77962374, grad/param norm = 1.8328e-01, time/batch = 14.8030s	
28817/33250 (epoch 43.334), train_loss = 0.87855960, grad/param norm = 1.6827e-01, time/batch = 14.7078s	
28818/33250 (epoch 43.335), train_loss = 0.59911687, grad/param norm = 1.9865e-01, time/batch = 14.7993s	
28819/33250 (epoch 43.337), train_loss = 0.83823665, grad/param norm = 1.8202e-01, time/batch = 15.5927s	
28820/33250 (epoch 43.338), train_loss = 0.93215435, grad/param norm = 1.8755e-01, time/batch = 14.6527s	
28821/33250 (epoch 43.340), train_loss = 0.73863317, grad/param norm = 1.6511e-01, time/batch = 14.8911s	
28822/33250 (epoch 43.341), train_loss = 0.68924321, grad/param norm = 1.7893e-01, time/batch = 15.1866s	
28823/33250 (epoch 43.343), train_loss = 0.73968709, grad/param norm = 2.0059e-01, time/batch = 15.3417s	
28824/33250 (epoch 43.344), train_loss = 0.75351500, grad/param norm = 1.8091e-01, time/batch = 14.8727s	
28825/33250 (epoch 43.346), train_loss = 0.66784590, grad/param norm = 1.7606e-01, time/batch = 15.5277s	
28826/33250 (epoch 43.347), train_loss = 0.93608831, grad/param norm = 2.4177e-01, time/batch = 15.1348s	
28827/33250 (epoch 43.349), train_loss = 0.76194461, grad/param norm = 2.0114e-01, time/batch = 15.2794s	
28828/33250 (epoch 43.350), train_loss = 0.76442551, grad/param norm = 1.9996e-01, time/batch = 14.7988s	
28829/33250 (epoch 43.352), train_loss = 0.68670754, grad/param norm = 1.7287e-01, time/batch = 14.5569s	
28830/33250 (epoch 43.353), train_loss = 0.72820698, grad/param norm = 1.7523e-01, time/batch = 14.5366s	
28831/33250 (epoch 43.355), train_loss = 0.71760954, grad/param norm = 1.6404e-01, time/batch = 15.0176s	
28832/33250 (epoch 43.356), train_loss = 0.68751021, grad/param norm = 1.8519e-01, time/batch = 15.3482s	
28833/33250 (epoch 43.358), train_loss = 0.73104955, grad/param norm = 1.6263e-01, time/batch = 14.6442s	
28834/33250 (epoch 43.359), train_loss = 0.71298972, grad/param norm = 1.7457e-01, time/batch = 15.0400s	
28835/33250 (epoch 43.361), train_loss = 0.83051799, grad/param norm = 2.0871e-01, time/batch = 15.2483s	
28836/33250 (epoch 43.362), train_loss = 0.77916738, grad/param norm = 1.5910e-01, time/batch = 15.8741s	
28837/33250 (epoch 43.364), train_loss = 0.81022239, grad/param norm = 1.9440e-01, time/batch = 14.9772s	
28838/33250 (epoch 43.365), train_loss = 0.74955494, grad/param norm = 1.6292e-01, time/batch = 16.5543s	
28839/33250 (epoch 43.367), train_loss = 0.77530260, grad/param norm = 1.6214e-01, time/batch = 15.1829s	
28840/33250 (epoch 43.368), train_loss = 0.74596159, grad/param norm = 1.7374e-01, time/batch = 14.8523s	
28841/33250 (epoch 43.370), train_loss = 0.66449992, grad/param norm = 1.6171e-01, time/batch = 15.0517s	
28842/33250 (epoch 43.371), train_loss = 0.85158512, grad/param norm = 1.9282e-01, time/batch = 14.8737s	
28843/33250 (epoch 43.373), train_loss = 0.74900028, grad/param norm = 1.7083e-01, time/batch = 15.2493s	
28844/33250 (epoch 43.374), train_loss = 0.75858738, grad/param norm = 2.7558e-01, time/batch = 14.8496s	
28845/33250 (epoch 43.376), train_loss = 0.78207483, grad/param norm = 1.9188e-01, time/batch = 14.7139s	
28846/33250 (epoch 43.377), train_loss = 0.66528233, grad/param norm = 2.1765e-01, time/batch = 15.7859s	
28847/33250 (epoch 43.379), train_loss = 0.76554802, grad/param norm = 1.9320e-01, time/batch = 15.6091s	
28848/33250 (epoch 43.380), train_loss = 0.75366308, grad/param norm = 2.0807e-01, time/batch = 16.6452s	
28849/33250 (epoch 43.382), train_loss = 0.77961757, grad/param norm = 2.2175e-01, time/batch = 15.1525s	
28850/33250 (epoch 43.383), train_loss = 0.66342949, grad/param norm = 1.8223e-01, time/batch = 16.1912s	
28851/33250 (epoch 43.385), train_loss = 0.63770029, grad/param norm = 1.8542e-01, time/batch = 15.3609s	
28852/33250 (epoch 43.386), train_loss = 0.67307073, grad/param norm = 2.3935e-01, time/batch = 15.4315s	
28853/33250 (epoch 43.388), train_loss = 0.69811972, grad/param norm = 1.7476e-01, time/batch = 14.9465s	
28854/33250 (epoch 43.389), train_loss = 0.68364585, grad/param norm = 1.9050e-01, time/batch = 15.4015s	
28855/33250 (epoch 43.391), train_loss = 0.79689316, grad/param norm = 2.0281e-01, time/batch = 15.0492s	
28856/33250 (epoch 43.392), train_loss = 0.86803959, grad/param norm = 1.9975e-01, time/batch = 15.0247s	
28857/33250 (epoch 43.394), train_loss = 0.83352784, grad/param norm = 1.8799e-01, time/batch = 15.5476s	
28858/33250 (epoch 43.395), train_loss = 0.84737810, grad/param norm = 1.6895e-01, time/batch = 15.7777s	
28859/33250 (epoch 43.397), train_loss = 0.87903190, grad/param norm = 1.8271e-01, time/batch = 16.5345s	
28860/33250 (epoch 43.398), train_loss = 0.68358308, grad/param norm = 1.6373e-01, time/batch = 17.5488s	
28861/33250 (epoch 43.400), train_loss = 0.67000535, grad/param norm = 1.5920e-01, time/batch = 14.7955s	
28862/33250 (epoch 43.402), train_loss = 0.62927578, grad/param norm = 1.7201e-01, time/batch = 15.2631s	
28863/33250 (epoch 43.403), train_loss = 0.74575760, grad/param norm = 2.4448e-01, time/batch = 14.4497s	
28864/33250 (epoch 43.405), train_loss = 0.69317525, grad/param norm = 1.5935e-01, time/batch = 14.3915s	
28865/33250 (epoch 43.406), train_loss = 0.75262911, grad/param norm = 2.1341e-01, time/batch = 14.3805s	
28866/33250 (epoch 43.408), train_loss = 0.90069906, grad/param norm = 1.8787e-01, time/batch = 14.9489s	
28867/33250 (epoch 43.409), train_loss = 0.80226173, grad/param norm = 2.3363e-01, time/batch = 15.1875s	
28868/33250 (epoch 43.411), train_loss = 0.55705012, grad/param norm = 1.3429e-01, time/batch = 14.9611s	
28869/33250 (epoch 43.412), train_loss = 0.63567120, grad/param norm = 1.9698e-01, time/batch = 17.5365s	
28870/33250 (epoch 43.414), train_loss = 0.77042339, grad/param norm = 2.1207e-01, time/batch = 15.2115s	
28871/33250 (epoch 43.415), train_loss = 0.81544175, grad/param norm = 1.8340e-01, time/batch = 15.3731s	
28872/33250 (epoch 43.417), train_loss = 0.86255558, grad/param norm = 1.9300e-01, time/batch = 15.3809s	
28873/33250 (epoch 43.418), train_loss = 0.99550833, grad/param norm = 2.1528e-01, time/batch = 14.7031s	
28874/33250 (epoch 43.420), train_loss = 0.82542938, grad/param norm = 1.7736e-01, time/batch = 15.5425s	
28875/33250 (epoch 43.421), train_loss = 0.71914848, grad/param norm = 1.6699e-01, time/batch = 14.6242s	
28876/33250 (epoch 43.423), train_loss = 0.79577113, grad/param norm = 1.9612e-01, time/batch = 14.6171s	
28877/33250 (epoch 43.424), train_loss = 0.86136755, grad/param norm = 2.3622e-01, time/batch = 15.0542s	
28878/33250 (epoch 43.426), train_loss = 0.74978002, grad/param norm = 1.6053e-01, time/batch = 14.8721s	
28879/33250 (epoch 43.427), train_loss = 0.70202090, grad/param norm = 2.1211e-01, time/batch = 15.4600s	
28880/33250 (epoch 43.429), train_loss = 0.74464229, grad/param norm = 1.8819e-01, time/batch = 16.0652s	
28881/33250 (epoch 43.430), train_loss = 0.71518591, grad/param norm = 2.0293e-01, time/batch = 16.5468s	
28882/33250 (epoch 43.432), train_loss = 0.82540543, grad/param norm = 1.7423e-01, time/batch = 15.4580s	
28883/33250 (epoch 43.433), train_loss = 0.71544695, grad/param norm = 2.0170e-01, time/batch = 14.8115s	
28884/33250 (epoch 43.435), train_loss = 0.82305911, grad/param norm = 1.9736e-01, time/batch = 14.8686s	
28885/33250 (epoch 43.436), train_loss = 0.72852447, grad/param norm = 2.0789e-01, time/batch = 14.8685s	
28886/33250 (epoch 43.438), train_loss = 0.87730829, grad/param norm = 2.1230e-01, time/batch = 15.0999s	
28887/33250 (epoch 43.439), train_loss = 0.74782716, grad/param norm = 1.6269e-01, time/batch = 14.7900s	
28888/33250 (epoch 43.441), train_loss = 0.75696378, grad/param norm = 2.8606e-01, time/batch = 14.9501s	
28889/33250 (epoch 43.442), train_loss = 0.68753789, grad/param norm = 1.8615e-01, time/batch = 14.7052s	
28890/33250 (epoch 43.444), train_loss = 0.72117314, grad/param norm = 1.7386e-01, time/batch = 15.1999s	
28891/33250 (epoch 43.445), train_loss = 0.78367547, grad/param norm = 1.5366e-01, time/batch = 15.0362s	
28892/33250 (epoch 43.447), train_loss = 0.68849727, grad/param norm = 1.9971e-01, time/batch = 17.0271s	
28893/33250 (epoch 43.448), train_loss = 0.78207709, grad/param norm = 1.5686e-01, time/batch = 15.3780s	
28894/33250 (epoch 43.450), train_loss = 0.86013551, grad/param norm = 2.0520e-01, time/batch = 16.2728s	
28895/33250 (epoch 43.451), train_loss = 0.82330631, grad/param norm = 2.1974e-01, time/batch = 14.9320s	
28896/33250 (epoch 43.453), train_loss = 0.64757917, grad/param norm = 1.4333e-01, time/batch = 14.7175s	
28897/33250 (epoch 43.454), train_loss = 0.85939632, grad/param norm = 1.9425e-01, time/batch = 15.2473s	
28898/33250 (epoch 43.456), train_loss = 0.87270104, grad/param norm = 1.5878e-01, time/batch = 15.0132s	
28899/33250 (epoch 43.457), train_loss = 0.71528444, grad/param norm = 1.7499e-01, time/batch = 15.0299s	
28900/33250 (epoch 43.459), train_loss = 0.83245985, grad/param norm = 1.8588e-01, time/batch = 15.3454s	
28901/33250 (epoch 43.460), train_loss = 0.81760678, grad/param norm = 1.8827e-01, time/batch = 15.4162s	
28902/33250 (epoch 43.462), train_loss = 0.76300886, grad/param norm = 2.0151e-01, time/batch = 14.9825s	
28903/33250 (epoch 43.463), train_loss = 0.67883815, grad/param norm = 1.4409e-01, time/batch = 14.8945s	
28904/33250 (epoch 43.465), train_loss = 0.64220844, grad/param norm = 1.5660e-01, time/batch = 14.9646s	
28905/33250 (epoch 43.466), train_loss = 0.63220103, grad/param norm = 1.4247e-01, time/batch = 14.7876s	
28906/33250 (epoch 43.468), train_loss = 0.65749770, grad/param norm = 1.5273e-01, time/batch = 15.0961s	
28907/33250 (epoch 43.469), train_loss = 0.74703381, grad/param norm = 2.0274e-01, time/batch = 14.7942s	
28908/33250 (epoch 43.471), train_loss = 0.82620570, grad/param norm = 1.6137e-01, time/batch = 14.6249s	
28909/33250 (epoch 43.472), train_loss = 0.71829445, grad/param norm = 2.2896e-01, time/batch = 15.0266s	
28910/33250 (epoch 43.474), train_loss = 0.83038890, grad/param norm = 1.9437e-01, time/batch = 14.7747s	
28911/33250 (epoch 43.475), train_loss = 0.78217948, grad/param norm = 1.5409e-01, time/batch = 15.0286s	
28912/33250 (epoch 43.477), train_loss = 0.77450357, grad/param norm = 2.1533e-01, time/batch = 14.7937s	
28913/33250 (epoch 43.478), train_loss = 0.66548958, grad/param norm = 1.9799e-01, time/batch = 15.0467s	
28914/33250 (epoch 43.480), train_loss = 0.85860336, grad/param norm = 1.7686e-01, time/batch = 15.1432s	
28915/33250 (epoch 43.481), train_loss = 0.73242427, grad/param norm = 1.5754e-01, time/batch = 14.6338s	
28916/33250 (epoch 43.483), train_loss = 0.73287242, grad/param norm = 1.8991e-01, time/batch = 15.5543s	
28917/33250 (epoch 43.484), train_loss = 0.69951840, grad/param norm = 1.7312e-01, time/batch = 14.9256s	
28918/33250 (epoch 43.486), train_loss = 0.63070536, grad/param norm = 1.8634e-01, time/batch = 15.0359s	
28919/33250 (epoch 43.487), train_loss = 0.68528501, grad/param norm = 1.7261e-01, time/batch = 14.9514s	
28920/33250 (epoch 43.489), train_loss = 0.83106662, grad/param norm = 2.0724e-01, time/batch = 14.7829s	
28921/33250 (epoch 43.490), train_loss = 0.77566693, grad/param norm = 2.1385e-01, time/batch = 15.0969s	
28922/33250 (epoch 43.492), train_loss = 0.83315668, grad/param norm = 2.4225e-01, time/batch = 14.7893s	
28923/33250 (epoch 43.493), train_loss = 0.75282743, grad/param norm = 1.7880e-01, time/batch = 14.9591s	
28924/33250 (epoch 43.495), train_loss = 0.81914983, grad/param norm = 1.4806e-01, time/batch = 15.8106s	
28925/33250 (epoch 43.496), train_loss = 0.76434173, grad/param norm = 1.5585e-01, time/batch = 14.8180s	
28926/33250 (epoch 43.498), train_loss = 0.82271307, grad/param norm = 2.0982e-01, time/batch = 16.5490s	
28927/33250 (epoch 43.499), train_loss = 0.71936341, grad/param norm = 1.7033e-01, time/batch = 15.7782s	
28928/33250 (epoch 43.501), train_loss = 0.71792656, grad/param norm = 2.0587e-01, time/batch = 14.9612s	
28929/33250 (epoch 43.502), train_loss = 0.71671086, grad/param norm = 1.5685e-01, time/batch = 15.0272s	
28930/33250 (epoch 43.504), train_loss = 0.88320548, grad/param norm = 2.4243e-01, time/batch = 15.0976s	
28931/33250 (epoch 43.505), train_loss = 0.65282603, grad/param norm = 1.4070e-01, time/batch = 14.8007s	
28932/33250 (epoch 43.507), train_loss = 0.68059761, grad/param norm = 1.7000e-01, time/batch = 14.7215s	
28933/33250 (epoch 43.508), train_loss = 0.73367591, grad/param norm = 1.7676e-01, time/batch = 14.9381s	
28934/33250 (epoch 43.510), train_loss = 0.62939379, grad/param norm = 1.5522e-01, time/batch = 14.7823s	
28935/33250 (epoch 43.511), train_loss = 0.73912673, grad/param norm = 2.0753e-01, time/batch = 14.5528s	
28936/33250 (epoch 43.513), train_loss = 0.85624868, grad/param norm = 1.8042e-01, time/batch = 15.9680s	
28937/33250 (epoch 43.514), train_loss = 0.71466310, grad/param norm = 1.7292e-01, time/batch = 16.6961s	
28938/33250 (epoch 43.516), train_loss = 0.68044146, grad/param norm = 1.7567e-01, time/batch = 15.9696s	
28939/33250 (epoch 43.517), train_loss = 0.72985553, grad/param norm = 1.8789e-01, time/batch = 16.2074s	
28940/33250 (epoch 43.519), train_loss = 0.68074254, grad/param norm = 1.3519e-01, time/batch = 15.6963s	
28941/33250 (epoch 43.520), train_loss = 0.90113833, grad/param norm = 1.8366e-01, time/batch = 15.9280s	
28942/33250 (epoch 43.522), train_loss = 0.76032328, grad/param norm = 1.8995e-01, time/batch = 15.4347s	
28943/33250 (epoch 43.523), train_loss = 0.68526768, grad/param norm = 1.7199e-01, time/batch = 14.9554s	
28944/33250 (epoch 43.525), train_loss = 0.63912111, grad/param norm = 1.8322e-01, time/batch = 15.0895s	
28945/33250 (epoch 43.526), train_loss = 0.64979090, grad/param norm = 1.6437e-01, time/batch = 14.8625s	
28946/33250 (epoch 43.528), train_loss = 0.69242334, grad/param norm = 1.7475e-01, time/batch = 14.9493s	
28947/33250 (epoch 43.529), train_loss = 0.69951379, grad/param norm = 1.7777e-01, time/batch = 17.0448s	
28948/33250 (epoch 43.531), train_loss = 0.65773548, grad/param norm = 1.6238e-01, time/batch = 15.5460s	
28949/33250 (epoch 43.532), train_loss = 0.77996098, grad/param norm = 1.6701e-01, time/batch = 17.5225s	
28950/33250 (epoch 43.534), train_loss = 0.67664912, grad/param norm = 1.5875e-01, time/batch = 15.0533s	
28951/33250 (epoch 43.535), train_loss = 0.71588995, grad/param norm = 1.7035e-01, time/batch = 15.5086s	
28952/33250 (epoch 43.537), train_loss = 0.75644143, grad/param norm = 1.5788e-01, time/batch = 15.4135s	
28953/33250 (epoch 43.538), train_loss = 0.79387027, grad/param norm = 1.9127e-01, time/batch = 14.9583s	
28954/33250 (epoch 43.540), train_loss = 0.89055936, grad/param norm = 1.6436e-01, time/batch = 14.8850s	
28955/33250 (epoch 43.541), train_loss = 0.80227085, grad/param norm = 1.8978e-01, time/batch = 14.6215s	
28956/33250 (epoch 43.543), train_loss = 0.79093425, grad/param norm = 1.4982e-01, time/batch = 15.0265s	
28957/33250 (epoch 43.544), train_loss = 0.66520007, grad/param norm = 2.0745e-01, time/batch = 14.7103s	
28958/33250 (epoch 43.546), train_loss = 0.70142290, grad/param norm = 2.0338e-01, time/batch = 14.5697s	
28959/33250 (epoch 43.547), train_loss = 0.72195838, grad/param norm = 2.1177e-01, time/batch = 14.7056s	
28960/33250 (epoch 43.549), train_loss = 0.77213976, grad/param norm = 1.9260e-01, time/batch = 23.4032s	
28961/33250 (epoch 43.550), train_loss = 0.73272367, grad/param norm = 1.7654e-01, time/batch = 19.0861s	
28962/33250 (epoch 43.552), train_loss = 0.80173124, grad/param norm = 1.8218e-01, time/batch = 14.7105s	
28963/33250 (epoch 43.553), train_loss = 0.74162539, grad/param norm = 1.6363e-01, time/batch = 15.2620s	
28964/33250 (epoch 43.555), train_loss = 0.73569212, grad/param norm = 1.6054e-01, time/batch = 14.6262s	
28965/33250 (epoch 43.556), train_loss = 0.76382472, grad/param norm = 2.1675e-01, time/batch = 14.7900s	
28966/33250 (epoch 43.558), train_loss = 0.79455347, grad/param norm = 2.1464e-01, time/batch = 14.7934s	
28967/33250 (epoch 43.559), train_loss = 0.69062173, grad/param norm = 1.7187e-01, time/batch = 15.1645s	
28968/33250 (epoch 43.561), train_loss = 0.64531669, grad/param norm = 1.6993e-01, time/batch = 16.0910s	
28969/33250 (epoch 43.562), train_loss = 0.72944726, grad/param norm = 1.7116e-01, time/batch = 14.9802s	
28970/33250 (epoch 43.564), train_loss = 0.89167597, grad/param norm = 2.0662e-01, time/batch = 16.0493s	
28971/33250 (epoch 43.565), train_loss = 0.84547018, grad/param norm = 2.2127e-01, time/batch = 14.9618s	
28972/33250 (epoch 43.567), train_loss = 0.85199004, grad/param norm = 1.8918e-01, time/batch = 14.7087s	
28973/33250 (epoch 43.568), train_loss = 0.70834441, grad/param norm = 2.1119e-01, time/batch = 14.9533s	
28974/33250 (epoch 43.570), train_loss = 0.81590140, grad/param norm = 2.1646e-01, time/batch = 14.8624s	
28975/33250 (epoch 43.571), train_loss = 0.85065840, grad/param norm = 1.7715e-01, time/batch = 15.1059s	
28976/33250 (epoch 43.573), train_loss = 0.79394268, grad/param norm = 1.7622e-01, time/batch = 14.8761s	
28977/33250 (epoch 43.574), train_loss = 0.67466794, grad/param norm = 1.5112e-01, time/batch = 14.7912s	
28978/33250 (epoch 43.576), train_loss = 0.78634067, grad/param norm = 1.8884e-01, time/batch = 14.7236s	
28979/33250 (epoch 43.577), train_loss = 0.72644851, grad/param norm = 1.6997e-01, time/batch = 15.2700s	
28980/33250 (epoch 43.579), train_loss = 0.64869085, grad/param norm = 1.8190e-01, time/batch = 15.3451s	
28981/33250 (epoch 43.580), train_loss = 0.75380971, grad/param norm = 1.7588e-01, time/batch = 15.6943s	
28982/33250 (epoch 43.582), train_loss = 0.72254104, grad/param norm = 1.8416e-01, time/batch = 15.9597s	
28983/33250 (epoch 43.583), train_loss = 0.82807048, grad/param norm = 1.9920e-01, time/batch = 14.9455s	
28984/33250 (epoch 43.585), train_loss = 0.84548135, grad/param norm = 1.7039e-01, time/batch = 14.7094s	
28985/33250 (epoch 43.586), train_loss = 0.69151306, grad/param norm = 1.8542e-01, time/batch = 14.7085s	
28986/33250 (epoch 43.588), train_loss = 0.79487909, grad/param norm = 1.6750e-01, time/batch = 14.8046s	
28987/33250 (epoch 43.589), train_loss = 0.74514997, grad/param norm = 1.8840e-01, time/batch = 15.0300s	
28988/33250 (epoch 43.591), train_loss = 0.73130716, grad/param norm = 1.9558e-01, time/batch = 15.0212s	
28989/33250 (epoch 43.592), train_loss = 0.72917619, grad/param norm = 1.7577e-01, time/batch = 15.6295s	
28990/33250 (epoch 43.594), train_loss = 0.84826359, grad/param norm = 1.9531e-01, time/batch = 15.3164s	
28991/33250 (epoch 43.595), train_loss = 0.75593236, grad/param norm = 1.8709e-01, time/batch = 15.2073s	
28992/33250 (epoch 43.597), train_loss = 0.62232173, grad/param norm = 1.4027e-01, time/batch = 15.7015s	
28993/33250 (epoch 43.598), train_loss = 0.72058459, grad/param norm = 2.1513e-01, time/batch = 14.8906s	
28994/33250 (epoch 43.600), train_loss = 0.71580430, grad/param norm = 2.3741e-01, time/batch = 14.8762s	
28995/33250 (epoch 43.602), train_loss = 0.75328833, grad/param norm = 2.0974e-01, time/batch = 15.1163s	
28996/33250 (epoch 43.603), train_loss = 0.80825064, grad/param norm = 2.0493e-01, time/batch = 14.8658s	
28997/33250 (epoch 43.605), train_loss = 0.74966086, grad/param norm = 1.7308e-01, time/batch = 14.7959s	
28998/33250 (epoch 43.606), train_loss = 0.79064811, grad/param norm = 1.8286e-01, time/batch = 14.7022s	
28999/33250 (epoch 43.608), train_loss = 0.76305072, grad/param norm = 1.8129e-01, time/batch = 15.1009s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch43.61_1.7157.t7	
29000/33250 (epoch 43.609), train_loss = 0.65723155, grad/param norm = 1.8563e-01, time/batch = 14.7845s	
29001/33250 (epoch 43.611), train_loss = 1.30923177, grad/param norm = 2.6726e-01, time/batch = 15.1892s	
29002/33250 (epoch 43.612), train_loss = 0.74151190, grad/param norm = 1.7804e-01, time/batch = 15.7138s	
29003/33250 (epoch 43.614), train_loss = 0.93779952, grad/param norm = 2.1939e-01, time/batch = 15.4976s	
29004/33250 (epoch 43.615), train_loss = 0.85430509, grad/param norm = 1.9647e-01, time/batch = 17.6348s	
29005/33250 (epoch 43.617), train_loss = 0.96273543, grad/param norm = 2.4291e-01, time/batch = 15.2094s	
29006/33250 (epoch 43.618), train_loss = 0.95580258, grad/param norm = 3.5919e-01, time/batch = 16.2875s	
29007/33250 (epoch 43.620), train_loss = 0.81880778, grad/param norm = 2.1852e-01, time/batch = 15.1208s	
29008/33250 (epoch 43.621), train_loss = 0.82440196, grad/param norm = 1.9606e-01, time/batch = 15.3766s	
29009/33250 (epoch 43.623), train_loss = 0.74415870, grad/param norm = 1.9307e-01, time/batch = 15.6757s	
29010/33250 (epoch 43.624), train_loss = 0.73660880, grad/param norm = 2.1826e-01, time/batch = 15.0383s	
29011/33250 (epoch 43.626), train_loss = 0.74956068, grad/param norm = 2.1270e-01, time/batch = 15.0421s	
29012/33250 (epoch 43.627), train_loss = 0.71246365, grad/param norm = 1.7030e-01, time/batch = 14.8571s	
29013/33250 (epoch 43.629), train_loss = 0.80877397, grad/param norm = 2.1257e-01, time/batch = 15.9500s	
29014/33250 (epoch 43.630), train_loss = 0.72713638, grad/param norm = 2.1160e-01, time/batch = 15.3344s	
29015/33250 (epoch 43.632), train_loss = 0.65783457, grad/param norm = 1.6686e-01, time/batch = 17.8006s	
29016/33250 (epoch 43.633), train_loss = 0.77155570, grad/param norm = 1.8623e-01, time/batch = 16.2919s	
29017/33250 (epoch 43.635), train_loss = 0.67570542, grad/param norm = 1.5921e-01, time/batch = 15.1924s	
29018/33250 (epoch 43.636), train_loss = 0.70320676, grad/param norm = 1.7690e-01, time/batch = 15.2479s	
29019/33250 (epoch 43.638), train_loss = 0.66382721, grad/param norm = 1.9031e-01, time/batch = 15.4533s	
29020/33250 (epoch 43.639), train_loss = 0.64543749, grad/param norm = 1.8662e-01, time/batch = 15.3590s	
29021/33250 (epoch 43.641), train_loss = 0.72189872, grad/param norm = 1.7083e-01, time/batch = 14.9506s	
29022/33250 (epoch 43.642), train_loss = 0.55384336, grad/param norm = 1.7513e-01, time/batch = 14.9286s	
29023/33250 (epoch 43.644), train_loss = 0.53298975, grad/param norm = 1.8412e-01, time/batch = 15.1784s	
29024/33250 (epoch 43.645), train_loss = 0.77314538, grad/param norm = 2.1482e-01, time/batch = 15.3207s	
29025/33250 (epoch 43.647), train_loss = 0.63227268, grad/param norm = 2.0384e-01, time/batch = 15.2170s	
29026/33250 (epoch 43.648), train_loss = 0.64101887, grad/param norm = 1.8814e-01, time/batch = 14.7914s	
29027/33250 (epoch 43.650), train_loss = 0.85967177, grad/param norm = 2.0857e-01, time/batch = 14.9012s	
29028/33250 (epoch 43.651), train_loss = 0.77972403, grad/param norm = 2.2638e-01, time/batch = 15.1976s	
29029/33250 (epoch 43.653), train_loss = 0.70930883, grad/param norm = 1.6400e-01, time/batch = 15.3382s	
29030/33250 (epoch 43.654), train_loss = 0.73705464, grad/param norm = 1.5830e-01, time/batch = 14.7039s	
29031/33250 (epoch 43.656), train_loss = 0.80508277, grad/param norm = 1.5662e-01, time/batch = 14.7903s	
29032/33250 (epoch 43.657), train_loss = 0.58516975, grad/param norm = 2.0214e-01, time/batch = 15.1750s	
29033/33250 (epoch 43.659), train_loss = 0.72711523, grad/param norm = 1.9802e-01, time/batch = 14.8637s	
29034/33250 (epoch 43.660), train_loss = 0.77115817, grad/param norm = 1.9903e-01, time/batch = 15.1001s	
29035/33250 (epoch 43.662), train_loss = 0.76151779, grad/param norm = 1.7455e-01, time/batch = 14.4669s	
29036/33250 (epoch 43.663), train_loss = 0.66923111, grad/param norm = 1.9227e-01, time/batch = 14.7960s	
29037/33250 (epoch 43.665), train_loss = 0.78102563, grad/param norm = 1.9798e-01, time/batch = 15.0438s	
29038/33250 (epoch 43.666), train_loss = 0.72954983, grad/param norm = 1.6004e-01, time/batch = 14.4776s	
29039/33250 (epoch 43.668), train_loss = 0.81924383, grad/param norm = 1.7523e-01, time/batch = 14.3256s	
29040/33250 (epoch 43.669), train_loss = 0.77227843, grad/param norm = 2.0303e-01, time/batch = 14.6318s	
29041/33250 (epoch 43.671), train_loss = 0.64351433, grad/param norm = 1.6903e-01, time/batch = 14.9655s	
29042/33250 (epoch 43.672), train_loss = 0.82757468, grad/param norm = 1.8592e-01, time/batch = 14.8714s	
29043/33250 (epoch 43.674), train_loss = 0.68821941, grad/param norm = 1.9002e-01, time/batch = 14.6948s	
29044/33250 (epoch 43.675), train_loss = 0.76151262, grad/param norm = 1.6141e-01, time/batch = 14.8670s	
29045/33250 (epoch 43.677), train_loss = 0.78922377, grad/param norm = 1.9254e-01, time/batch = 14.9496s	
29046/33250 (epoch 43.678), train_loss = 0.68761711, grad/param norm = 2.0013e-01, time/batch = 14.7050s	
29047/33250 (epoch 43.680), train_loss = 0.83884694, grad/param norm = 1.9162e-01, time/batch = 16.3017s	
29048/33250 (epoch 43.681), train_loss = 0.68530557, grad/param norm = 1.7206e-01, time/batch = 15.5915s	
29049/33250 (epoch 43.683), train_loss = 0.67719803, grad/param norm = 1.8208e-01, time/batch = 16.1209s	
29050/33250 (epoch 43.684), train_loss = 0.63192752, grad/param norm = 1.8645e-01, time/batch = 15.9038s	
29051/33250 (epoch 43.686), train_loss = 0.66033871, grad/param norm = 1.8359e-01, time/batch = 14.8835s	
29052/33250 (epoch 43.687), train_loss = 0.77342999, grad/param norm = 1.7912e-01, time/batch = 15.1163s	
29053/33250 (epoch 43.689), train_loss = 0.64823856, grad/param norm = 2.0290e-01, time/batch = 14.8750s	
29054/33250 (epoch 43.690), train_loss = 0.78489859, grad/param norm = 1.9929e-01, time/batch = 15.0333s	
29055/33250 (epoch 43.692), train_loss = 0.70978049, grad/param norm = 1.6269e-01, time/batch = 15.0368s	
29056/33250 (epoch 43.693), train_loss = 0.79070979, grad/param norm = 1.6785e-01, time/batch = 15.3545s	
29057/33250 (epoch 43.695), train_loss = 0.77551002, grad/param norm = 2.3447e-01, time/batch = 15.1825s	
29058/33250 (epoch 43.696), train_loss = 0.78375666, grad/param norm = 1.6963e-01, time/batch = 17.1183s	
29059/33250 (epoch 43.698), train_loss = 0.71840486, grad/param norm = 2.0972e-01, time/batch = 15.6914s	
29060/33250 (epoch 43.699), train_loss = 0.93800661, grad/param norm = 1.8966e-01, time/batch = 15.9110s	
29061/33250 (epoch 43.701), train_loss = 0.77066461, grad/param norm = 1.5115e-01, time/batch = 15.3992s	
29062/33250 (epoch 43.702), train_loss = 0.71570894, grad/param norm = 2.5703e-01, time/batch = 15.2866s	
29063/33250 (epoch 43.704), train_loss = 0.93767114, grad/param norm = 2.4988e-01, time/batch = 14.7075s	
29064/33250 (epoch 43.705), train_loss = 0.70858033, grad/param norm = 1.6259e-01, time/batch = 15.2064s	
29065/33250 (epoch 43.707), train_loss = 0.64606633, grad/param norm = 1.6699e-01, time/batch = 14.7015s	
29066/33250 (epoch 43.708), train_loss = 0.84316816, grad/param norm = 1.9861e-01, time/batch = 14.6901s	
29067/33250 (epoch 43.710), train_loss = 0.78368433, grad/param norm = 2.2252e-01, time/batch = 14.6215s	
29068/33250 (epoch 43.711), train_loss = 0.66247119, grad/param norm = 1.7845e-01, time/batch = 14.7678s	
29069/33250 (epoch 43.713), train_loss = 0.77853379, grad/param norm = 1.8530e-01, time/batch = 14.6263s	
29070/33250 (epoch 43.714), train_loss = 0.72311072, grad/param norm = 1.9079e-01, time/batch = 14.2318s	
29071/33250 (epoch 43.716), train_loss = 0.77136085, grad/param norm = 1.7816e-01, time/batch = 15.2168s	
29072/33250 (epoch 43.717), train_loss = 0.71606272, grad/param norm = 1.4024e-01, time/batch = 15.1168s	
29073/33250 (epoch 43.719), train_loss = 0.69269453, grad/param norm = 1.7069e-01, time/batch = 14.6196s	
29074/33250 (epoch 43.720), train_loss = 0.96425466, grad/param norm = 1.8266e-01, time/batch = 14.5282s	
29075/33250 (epoch 43.722), train_loss = 0.65158856, grad/param norm = 1.8386e-01, time/batch = 14.4598s	
29076/33250 (epoch 43.723), train_loss = 0.59148227, grad/param norm = 1.4223e-01, time/batch = 15.1030s	
29077/33250 (epoch 43.725), train_loss = 0.73760601, grad/param norm = 1.5466e-01, time/batch = 15.3388s	
29078/33250 (epoch 43.726), train_loss = 0.76604854, grad/param norm = 1.7005e-01, time/batch = 14.6192s	
29079/33250 (epoch 43.728), train_loss = 0.79623065, grad/param norm = 2.2097e-01, time/batch = 14.7687s	
29080/33250 (epoch 43.729), train_loss = 0.80831940, grad/param norm = 1.8300e-01, time/batch = 14.8647s	
29081/33250 (epoch 43.731), train_loss = 0.69065489, grad/param norm = 2.4162e-01, time/batch = 15.2918s	
29082/33250 (epoch 43.732), train_loss = 0.67816005, grad/param norm = 1.5913e-01, time/batch = 14.8025s	
29083/33250 (epoch 43.734), train_loss = 0.77265948, grad/param norm = 2.0965e-01, time/batch = 14.5651s	
29084/33250 (epoch 43.735), train_loss = 0.76358343, grad/param norm = 1.8463e-01, time/batch = 15.1042s	
29085/33250 (epoch 43.737), train_loss = 0.72560360, grad/param norm = 1.5689e-01, time/batch = 14.6281s	
29086/33250 (epoch 43.738), train_loss = 0.77885219, grad/param norm = 1.7774e-01, time/batch = 14.2916s	
29087/33250 (epoch 43.740), train_loss = 0.75786132, grad/param norm = 1.9860e-01, time/batch = 14.2974s	
29088/33250 (epoch 43.741), train_loss = 0.81054346, grad/param norm = 1.9981e-01, time/batch = 15.0867s	
29089/33250 (epoch 43.743), train_loss = 0.70021479, grad/param norm = 1.6401e-01, time/batch = 14.3778s	
29090/33250 (epoch 43.744), train_loss = 0.71167403, grad/param norm = 1.9282e-01, time/batch = 14.7109s	
29091/33250 (epoch 43.746), train_loss = 0.67535407, grad/param norm = 1.5891e-01, time/batch = 14.9527s	
29092/33250 (epoch 43.747), train_loss = 0.66182911, grad/param norm = 1.5789e-01, time/batch = 15.1877s	
29093/33250 (epoch 43.749), train_loss = 0.84375651, grad/param norm = 2.0356e-01, time/batch = 15.1446s	
29094/33250 (epoch 43.750), train_loss = 0.85338294, grad/param norm = 1.8257e-01, time/batch = 15.1334s	
29095/33250 (epoch 43.752), train_loss = 0.72447877, grad/param norm = 1.9644e-01, time/batch = 17.1916s	
29096/33250 (epoch 43.753), train_loss = 0.71154973, grad/param norm = 1.7925e-01, time/batch = 14.9450s	
29097/33250 (epoch 43.755), train_loss = 0.62988058, grad/param norm = 2.0113e-01, time/batch = 15.0074s	
29098/33250 (epoch 43.756), train_loss = 0.75104016, grad/param norm = 2.1133e-01, time/batch = 14.8625s	
29099/33250 (epoch 43.758), train_loss = 0.89405671, grad/param norm = 1.8580e-01, time/batch = 14.6193s	
29100/33250 (epoch 43.759), train_loss = 0.71473320, grad/param norm = 1.7009e-01, time/batch = 14.9260s	
29101/33250 (epoch 43.761), train_loss = 0.78377283, grad/param norm = 2.0990e-01, time/batch = 15.5054s	
29102/33250 (epoch 43.762), train_loss = 0.80253757, grad/param norm = 1.7186e-01, time/batch = 15.1795s	
29103/33250 (epoch 43.764), train_loss = 0.63902900, grad/param norm = 2.0028e-01, time/batch = 16.2826s	
29104/33250 (epoch 43.765), train_loss = 0.77582265, grad/param norm = 2.0249e-01, time/batch = 14.9807s	
29105/33250 (epoch 43.767), train_loss = 0.59403019, grad/param norm = 1.6042e-01, time/batch = 15.3963s	
29106/33250 (epoch 43.768), train_loss = 0.63318027, grad/param norm = 1.8961e-01, time/batch = 14.8900s	
29107/33250 (epoch 43.770), train_loss = 0.78446031, grad/param norm = 2.3160e-01, time/batch = 14.7825s	
29108/33250 (epoch 43.771), train_loss = 0.81792352, grad/param norm = 2.1260e-01, time/batch = 14.9473s	
29109/33250 (epoch 43.773), train_loss = 0.74216013, grad/param norm = 1.8565e-01, time/batch = 14.7114s	
29110/33250 (epoch 43.774), train_loss = 0.61849735, grad/param norm = 1.8102e-01, time/batch = 15.0195s	
29111/33250 (epoch 43.776), train_loss = 0.71120338, grad/param norm = 1.7064e-01, time/batch = 14.7069s	
29112/33250 (epoch 43.777), train_loss = 0.84977254, grad/param norm = 2.0475e-01, time/batch = 14.9535s	
29113/33250 (epoch 43.779), train_loss = 0.72337266, grad/param norm = 1.9317e-01, time/batch = 14.8480s	
29114/33250 (epoch 43.780), train_loss = 0.86548573, grad/param norm = 2.3018e-01, time/batch = 15.3445s	
29115/33250 (epoch 43.782), train_loss = 0.76168270, grad/param norm = 2.1656e-01, time/batch = 15.1305s	
29116/33250 (epoch 43.783), train_loss = 0.60000004, grad/param norm = 1.7521e-01, time/batch = 14.7972s	
29117/33250 (epoch 43.785), train_loss = 0.66575330, grad/param norm = 1.7968e-01, time/batch = 15.0056s	
29118/33250 (epoch 43.786), train_loss = 0.82657854, grad/param norm = 1.9441e-01, time/batch = 14.6271s	
29119/33250 (epoch 43.788), train_loss = 0.86107562, grad/param norm = 1.9261e-01, time/batch = 14.9939s	
29120/33250 (epoch 43.789), train_loss = 0.85730238, grad/param norm = 2.1925e-01, time/batch = 14.6968s	
29121/33250 (epoch 43.791), train_loss = 0.86414233, grad/param norm = 2.1625e-01, time/batch = 14.6300s	
29122/33250 (epoch 43.792), train_loss = 0.92252660, grad/param norm = 1.8679e-01, time/batch = 14.8502s	
29123/33250 (epoch 43.794), train_loss = 0.72616813, grad/param norm = 1.7365e-01, time/batch = 14.7024s	
29124/33250 (epoch 43.795), train_loss = 0.71537274, grad/param norm = 1.7691e-01, time/batch = 15.1791s	
29125/33250 (epoch 43.797), train_loss = 0.78921784, grad/param norm = 1.8250e-01, time/batch = 14.7051s	
29126/33250 (epoch 43.798), train_loss = 0.71574201, grad/param norm = 2.0154e-01, time/batch = 14.8691s	
29127/33250 (epoch 43.800), train_loss = 0.78379073, grad/param norm = 1.9874e-01, time/batch = 14.6439s	
29128/33250 (epoch 43.802), train_loss = 0.76408762, grad/param norm = 1.7587e-01, time/batch = 15.1922s	
29129/33250 (epoch 43.803), train_loss = 0.78047071, grad/param norm = 1.5615e-01, time/batch = 14.6375s	
29130/33250 (epoch 43.805), train_loss = 0.78886547, grad/param norm = 1.7822e-01, time/batch = 14.9327s	
29131/33250 (epoch 43.806), train_loss = 0.76589005, grad/param norm = 1.7543e-01, time/batch = 14.7777s	
29132/33250 (epoch 43.808), train_loss = 0.68109083, grad/param norm = 1.7948e-01, time/batch = 15.0187s	
29133/33250 (epoch 43.809), train_loss = 0.67907348, grad/param norm = 1.6550e-01, time/batch = 15.1004s	
29134/33250 (epoch 43.811), train_loss = 0.64627839, grad/param norm = 1.6814e-01, time/batch = 14.6262s	
29135/33250 (epoch 43.812), train_loss = 0.77834451, grad/param norm = 2.0397e-01, time/batch = 14.6993s	
29136/33250 (epoch 43.814), train_loss = 0.70022423, grad/param norm = 2.1003e-01, time/batch = 15.0951s	
29137/33250 (epoch 43.815), train_loss = 0.77610791, grad/param norm = 1.7207e-01, time/batch = 15.2443s	
29138/33250 (epoch 43.817), train_loss = 0.72798282, grad/param norm = 1.8326e-01, time/batch = 16.2181s	
29139/33250 (epoch 43.818), train_loss = 0.68087823, grad/param norm = 1.7510e-01, time/batch = 15.7073s	
29140/33250 (epoch 43.820), train_loss = 0.78862593, grad/param norm = 1.9857e-01, time/batch = 15.3606s	
29141/33250 (epoch 43.821), train_loss = 0.74690665, grad/param norm = 1.5476e-01, time/batch = 15.0461s	
29142/33250 (epoch 43.823), train_loss = 0.99937510, grad/param norm = 2.1298e-01, time/batch = 14.8742s	
29143/33250 (epoch 43.824), train_loss = 0.69732334, grad/param norm = 1.8126e-01, time/batch = 14.8477s	
29144/33250 (epoch 43.826), train_loss = 0.78378974, grad/param norm = 2.1593e-01, time/batch = 14.8388s	
29145/33250 (epoch 43.827), train_loss = 0.68391775, grad/param norm = 1.6497e-01, time/batch = 14.2054s	
29146/33250 (epoch 43.829), train_loss = 0.76769813, grad/param norm = 2.2074e-01, time/batch = 14.9467s	
29147/33250 (epoch 43.830), train_loss = 0.80209320, grad/param norm = 2.5362e-01, time/batch = 14.6829s	
29148/33250 (epoch 43.832), train_loss = 0.77547655, grad/param norm = 1.9051e-01, time/batch = 5.9516s	
29149/33250 (epoch 43.833), train_loss = 0.73959596, grad/param norm = 1.7672e-01, time/batch = 0.6742s	
29150/33250 (epoch 43.835), train_loss = 0.67130276, grad/param norm = 1.9652e-01, time/batch = 0.6781s	
29151/33250 (epoch 43.836), train_loss = 0.73143990, grad/param norm = 1.8769e-01, time/batch = 0.6782s	
29152/33250 (epoch 43.838), train_loss = 0.77321109, grad/param norm = 1.8927e-01, time/batch = 0.6689s	
29153/33250 (epoch 43.839), train_loss = 0.73568742, grad/param norm = 2.0722e-01, time/batch = 0.6571s	
29154/33250 (epoch 43.841), train_loss = 0.71300391, grad/param norm = 1.7547e-01, time/batch = 0.6633s	
29155/33250 (epoch 43.842), train_loss = 0.87275534, grad/param norm = 1.9891e-01, time/batch = 0.7130s	
29156/33250 (epoch 43.844), train_loss = 0.81614284, grad/param norm = 1.8363e-01, time/batch = 0.9583s	
29157/33250 (epoch 43.845), train_loss = 0.91369341, grad/param norm = 2.3885e-01, time/batch = 0.9645s	
29158/33250 (epoch 43.847), train_loss = 0.85381656, grad/param norm = 1.8478e-01, time/batch = 0.9857s	
29159/33250 (epoch 43.848), train_loss = 0.93517183, grad/param norm = 2.2964e-01, time/batch = 0.9806s	
29160/33250 (epoch 43.850), train_loss = 0.84482612, grad/param norm = 2.0096e-01, time/batch = 1.0022s	
29161/33250 (epoch 43.851), train_loss = 0.65737082, grad/param norm = 1.8678e-01, time/batch = 1.8272s	
29162/33250 (epoch 43.853), train_loss = 0.76439729, grad/param norm = 2.1332e-01, time/batch = 1.8573s	
29163/33250 (epoch 43.854), train_loss = 0.71387626, grad/param norm = 1.6288e-01, time/batch = 6.8473s	
29164/33250 (epoch 43.856), train_loss = 0.70947664, grad/param norm = 1.9426e-01, time/batch = 14.8096s	
29165/33250 (epoch 43.857), train_loss = 0.63929041, grad/param norm = 1.7968e-01, time/batch = 15.2175s	
29166/33250 (epoch 43.859), train_loss = 0.72056928, grad/param norm = 1.8083e-01, time/batch = 14.8625s	
29167/33250 (epoch 43.860), train_loss = 0.78620470, grad/param norm = 1.7287e-01, time/batch = 14.6326s	
29168/33250 (epoch 43.862), train_loss = 0.68576014, grad/param norm = 1.7334e-01, time/batch = 14.6899s	
29169/33250 (epoch 43.863), train_loss = 0.72998949, grad/param norm = 2.3212e-01, time/batch = 14.4595s	
29170/33250 (epoch 43.865), train_loss = 0.75759666, grad/param norm = 2.0313e-01, time/batch = 15.2603s	
29171/33250 (epoch 43.866), train_loss = 0.67389600, grad/param norm = 1.7783e-01, time/batch = 15.0998s	
29172/33250 (epoch 43.868), train_loss = 0.74226907, grad/param norm = 2.0848e-01, time/batch = 14.7767s	
29173/33250 (epoch 43.869), train_loss = 0.77354402, grad/param norm = 1.9444e-01, time/batch = 14.6764s	
29174/33250 (epoch 43.871), train_loss = 0.61614427, grad/param norm = 1.5558e-01, time/batch = 14.7941s	
29175/33250 (epoch 43.872), train_loss = 0.79177810, grad/param norm = 1.8461e-01, time/batch = 14.4893s	
29176/33250 (epoch 43.874), train_loss = 0.70394497, grad/param norm = 1.8712e-01, time/batch = 14.5515s	
29177/33250 (epoch 43.875), train_loss = 0.65773523, grad/param norm = 2.3803e-01, time/batch = 14.6228s	
29178/33250 (epoch 43.877), train_loss = 0.84947190, grad/param norm = 1.8869e-01, time/batch = 15.4972s	
29179/33250 (epoch 43.878), train_loss = 0.75708409, grad/param norm = 1.6350e-01, time/batch = 14.9364s	
29180/33250 (epoch 43.880), train_loss = 0.75220658, grad/param norm = 1.9243e-01, time/batch = 14.6227s	
29181/33250 (epoch 43.881), train_loss = 0.84163428, grad/param norm = 1.8977e-01, time/batch = 14.5428s	
29182/33250 (epoch 43.883), train_loss = 0.79572699, grad/param norm = 1.9449e-01, time/batch = 15.1694s	
29183/33250 (epoch 43.884), train_loss = 0.85471773, grad/param norm = 2.0826e-01, time/batch = 14.7016s	
29184/33250 (epoch 43.886), train_loss = 0.68366199, grad/param norm = 1.6168e-01, time/batch = 14.7714s	
29185/33250 (epoch 43.887), train_loss = 0.71938886, grad/param norm = 2.3166e-01, time/batch = 14.7052s	
29186/33250 (epoch 43.889), train_loss = 0.71196309, grad/param norm = 1.5085e-01, time/batch = 14.7075s	
29187/33250 (epoch 43.890), train_loss = 0.57964606, grad/param norm = 1.3815e-01, time/batch = 14.3966s	
29188/33250 (epoch 43.892), train_loss = 0.78602618, grad/param norm = 1.7401e-01, time/batch = 14.6348s	
29189/33250 (epoch 43.893), train_loss = 0.80546180, grad/param norm = 1.9136e-01, time/batch = 14.5343s	
29190/33250 (epoch 43.895), train_loss = 0.69414167, grad/param norm = 1.8290e-01, time/batch = 14.9306s	
29191/33250 (epoch 43.896), train_loss = 0.82408290, grad/param norm = 1.9268e-01, time/batch = 15.0913s	
29192/33250 (epoch 43.898), train_loss = 0.75234317, grad/param norm = 1.6491e-01, time/batch = 14.6192s	
29193/33250 (epoch 43.899), train_loss = 0.70322186, grad/param norm = 1.6565e-01, time/batch = 14.5347s	
29194/33250 (epoch 43.901), train_loss = 0.61811760, grad/param norm = 1.5285e-01, time/batch = 14.8747s	
29195/33250 (epoch 43.902), train_loss = 0.69865815, grad/param norm = 2.0622e-01, time/batch = 15.1145s	
29196/33250 (epoch 43.904), train_loss = 0.68001312, grad/param norm = 2.0997e-01, time/batch = 15.2499s	
29197/33250 (epoch 43.905), train_loss = 0.73792160, grad/param norm = 1.7881e-01, time/batch = 15.9343s	
29198/33250 (epoch 43.907), train_loss = 0.69711473, grad/param norm = 1.9996e-01, time/batch = 15.3889s	
29199/33250 (epoch 43.908), train_loss = 0.73890094, grad/param norm = 1.5932e-01, time/batch = 15.3164s	
29200/33250 (epoch 43.910), train_loss = 0.81524252, grad/param norm = 1.9243e-01, time/batch = 15.9672s	
29201/33250 (epoch 43.911), train_loss = 0.66625740, grad/param norm = 1.8836e-01, time/batch = 14.7199s	
29202/33250 (epoch 43.913), train_loss = 0.70352593, grad/param norm = 1.6633e-01, time/batch = 27.4899s	
29203/33250 (epoch 43.914), train_loss = 0.62054986, grad/param norm = 1.7330e-01, time/batch = 15.7673s	
29204/33250 (epoch 43.916), train_loss = 0.65182084, grad/param norm = 1.8936e-01, time/batch = 14.9558s	
29205/33250 (epoch 43.917), train_loss = 0.75606309, grad/param norm = 1.4643e-01, time/batch = 14.9335s	
29206/33250 (epoch 43.919), train_loss = 0.68068783, grad/param norm = 1.9628e-01, time/batch = 14.6297s	
29207/33250 (epoch 43.920), train_loss = 0.76365073, grad/param norm = 1.9693e-01, time/batch = 14.8834s	
29208/33250 (epoch 43.922), train_loss = 0.76029977, grad/param norm = 2.0564e-01, time/batch = 15.3099s	
29209/33250 (epoch 43.923), train_loss = 0.74551372, grad/param norm = 2.0114e-01, time/batch = 15.1815s	
29210/33250 (epoch 43.925), train_loss = 0.71622859, grad/param norm = 1.8110e-01, time/batch = 15.3341s	
29211/33250 (epoch 43.926), train_loss = 0.68565665, grad/param norm = 1.6112e-01, time/batch = 15.5543s	
29212/33250 (epoch 43.928), train_loss = 0.71901603, grad/param norm = 1.8767e-01, time/batch = 15.1937s	
29213/33250 (epoch 43.929), train_loss = 0.64357058, grad/param norm = 1.3902e-01, time/batch = 15.1077s	
29214/33250 (epoch 43.931), train_loss = 0.83350841, grad/param norm = 1.7825e-01, time/batch = 14.8545s	
29215/33250 (epoch 43.932), train_loss = 0.67664801, grad/param norm = 1.7303e-01, time/batch = 14.6218s	
29216/33250 (epoch 43.934), train_loss = 0.67417556, grad/param norm = 1.5880e-01, time/batch = 15.1668s	
29217/33250 (epoch 43.935), train_loss = 0.72665638, grad/param norm = 1.7497e-01, time/batch = 15.0978s	
29218/33250 (epoch 43.937), train_loss = 0.68582323, grad/param norm = 2.3536e-01, time/batch = 14.9601s	
29219/33250 (epoch 43.938), train_loss = 0.70439990, grad/param norm = 2.2385e-01, time/batch = 16.3737s	
29220/33250 (epoch 43.940), train_loss = 0.71064395, grad/param norm = 1.7773e-01, time/batch = 16.3745s	
29221/33250 (epoch 43.941), train_loss = 0.78473802, grad/param norm = 1.9938e-01, time/batch = 15.0365s	
29222/33250 (epoch 43.943), train_loss = 0.87231755, grad/param norm = 1.9266e-01, time/batch = 15.2091s	
29223/33250 (epoch 43.944), train_loss = 0.70201165, grad/param norm = 1.8700e-01, time/batch = 14.6065s	
29224/33250 (epoch 43.946), train_loss = 0.81398916, grad/param norm = 1.9600e-01, time/batch = 14.8760s	
29225/33250 (epoch 43.947), train_loss = 0.66011213, grad/param norm = 1.6262e-01, time/batch = 15.3532s	
29226/33250 (epoch 43.949), train_loss = 0.80213374, grad/param norm = 1.9862e-01, time/batch = 14.8677s	
29227/33250 (epoch 43.950), train_loss = 0.81272709, grad/param norm = 1.9827e-01, time/batch = 14.4563s	
29228/33250 (epoch 43.952), train_loss = 0.74177214, grad/param norm = 1.9441e-01, time/batch = 15.1564s	
29229/33250 (epoch 43.953), train_loss = 0.75798667, grad/param norm = 2.4568e-01, time/batch = 15.3218s	
29230/33250 (epoch 43.955), train_loss = 0.81777830, grad/param norm = 1.9057e-01, time/batch = 15.1626s	
29231/33250 (epoch 43.956), train_loss = 0.73506115, grad/param norm = 1.9965e-01, time/batch = 14.5661s	
29232/33250 (epoch 43.958), train_loss = 0.71044472, grad/param norm = 1.7436e-01, time/batch = 15.6382s	
29233/33250 (epoch 43.959), train_loss = 0.69682724, grad/param norm = 1.7956e-01, time/batch = 14.5543s	
29234/33250 (epoch 43.961), train_loss = 0.91974777, grad/param norm = 2.1636e-01, time/batch = 14.4552s	
29235/33250 (epoch 43.962), train_loss = 0.72901614, grad/param norm = 1.9288e-01, time/batch = 14.7000s	
29236/33250 (epoch 43.964), train_loss = 0.86413856, grad/param norm = 2.0338e-01, time/batch = 14.5305s	
29237/33250 (epoch 43.965), train_loss = 0.79145635, grad/param norm = 1.9326e-01, time/batch = 15.3708s	
29238/33250 (epoch 43.967), train_loss = 0.74108671, grad/param norm = 1.8938e-01, time/batch = 15.1154s	
29239/33250 (epoch 43.968), train_loss = 0.86502291, grad/param norm = 1.8256e-01, time/batch = 14.6333s	
29240/33250 (epoch 43.970), train_loss = 0.95579571, grad/param norm = 2.5218e-01, time/batch = 15.2437s	
29241/33250 (epoch 43.971), train_loss = 0.90441757, grad/param norm = 2.3574e-01, time/batch = 15.0408s	
29242/33250 (epoch 43.973), train_loss = 0.71727713, grad/param norm = 1.6841e-01, time/batch = 15.5691s	
29243/33250 (epoch 43.974), train_loss = 0.80634439, grad/param norm = 2.1285e-01, time/batch = 15.3761s	
29244/33250 (epoch 43.976), train_loss = 0.71794171, grad/param norm = 1.8365e-01, time/batch = 14.8762s	
29245/33250 (epoch 43.977), train_loss = 0.74561609, grad/param norm = 1.7203e-01, time/batch = 14.8739s	
29246/33250 (epoch 43.979), train_loss = 0.81115474, grad/param norm = 2.1862e-01, time/batch = 15.0887s	
29247/33250 (epoch 43.980), train_loss = 0.79790378, grad/param norm = 1.7900e-01, time/batch = 14.7030s	
29248/33250 (epoch 43.982), train_loss = 0.73290190, grad/param norm = 1.5668e-01, time/batch = 15.1076s	
29249/33250 (epoch 43.983), train_loss = 0.79080333, grad/param norm = 1.9615e-01, time/batch = 15.0972s	
29250/33250 (epoch 43.985), train_loss = 0.72242467, grad/param norm = 1.9928e-01, time/batch = 14.9419s	
29251/33250 (epoch 43.986), train_loss = 0.81350697, grad/param norm = 1.8433e-01, time/batch = 14.8113s	
29252/33250 (epoch 43.988), train_loss = 0.85577640, grad/param norm = 1.9659e-01, time/batch = 15.0249s	
29253/33250 (epoch 43.989), train_loss = 0.82621496, grad/param norm = 1.7348e-01, time/batch = 16.6291s	
29254/33250 (epoch 43.991), train_loss = 0.82345516, grad/param norm = 1.8937e-01, time/batch = 15.5981s	
29255/33250 (epoch 43.992), train_loss = 0.74648565, grad/param norm = 2.0328e-01, time/batch = 15.0595s	
29256/33250 (epoch 43.994), train_loss = 0.71685161, grad/param norm = 1.7559e-01, time/batch = 14.8566s	
29257/33250 (epoch 43.995), train_loss = 0.73356160, grad/param norm = 2.2821e-01, time/batch = 15.0540s	
29258/33250 (epoch 43.997), train_loss = 0.58213420, grad/param norm = 1.6710e-01, time/batch = 14.7182s	
29259/33250 (epoch 43.998), train_loss = 0.79029696, grad/param norm = 1.8181e-01, time/batch = 14.9541s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
29260/33250 (epoch 44.000), train_loss = 0.79353284, grad/param norm = 1.8370e-01, time/batch = 16.8500s	
29261/33250 (epoch 44.002), train_loss = 0.96675818, grad/param norm = 1.9139e-01, time/batch = 14.7878s	
29262/33250 (epoch 44.003), train_loss = 0.81362100, grad/param norm = 2.1961e-01, time/batch = 14.8529s	
29263/33250 (epoch 44.005), train_loss = 0.63223088, grad/param norm = 1.6088e-01, time/batch = 14.7235s	
29264/33250 (epoch 44.006), train_loss = 0.65027445, grad/param norm = 1.8690e-01, time/batch = 15.2077s	
29265/33250 (epoch 44.008), train_loss = 0.82945508, grad/param norm = 1.8521e-01, time/batch = 14.9659s	
29266/33250 (epoch 44.009), train_loss = 0.92026460, grad/param norm = 1.9670e-01, time/batch = 15.1422s	
29267/33250 (epoch 44.011), train_loss = 0.70211192, grad/param norm = 1.7821e-01, time/batch = 14.6118s	
29268/33250 (epoch 44.012), train_loss = 0.73438106, grad/param norm = 2.3950e-01, time/batch = 14.9426s	
29269/33250 (epoch 44.014), train_loss = 0.85245060, grad/param norm = 2.3555e-01, time/batch = 14.9495s	
29270/33250 (epoch 44.015), train_loss = 0.77061127, grad/param norm = 1.7990e-01, time/batch = 14.9251s	
29271/33250 (epoch 44.017), train_loss = 0.77429653, grad/param norm = 2.0238e-01, time/batch = 14.7682s	
29272/33250 (epoch 44.018), train_loss = 0.61489931, grad/param norm = 1.7891e-01, time/batch = 14.8702s	
29273/33250 (epoch 44.020), train_loss = 0.78038260, grad/param norm = 1.7849e-01, time/batch = 14.7022s	
29274/33250 (epoch 44.021), train_loss = 0.78177349, grad/param norm = 1.7692e-01, time/batch = 14.9474s	
29275/33250 (epoch 44.023), train_loss = 0.61685416, grad/param norm = 1.7876e-01, time/batch = 14.7940s	
29276/33250 (epoch 44.024), train_loss = 0.84254861, grad/param norm = 2.4189e-01, time/batch = 14.8014s	
29277/33250 (epoch 44.026), train_loss = 0.79497423, grad/param norm = 1.8567e-01, time/batch = 14.9771s	
29278/33250 (epoch 44.027), train_loss = 0.78911956, grad/param norm = 1.8442e-01, time/batch = 15.0499s	
29279/33250 (epoch 44.029), train_loss = 0.73024334, grad/param norm = 1.6810e-01, time/batch = 15.0446s	
29280/33250 (epoch 44.030), train_loss = 0.74543249, grad/param norm = 1.9627e-01, time/batch = 14.9978s	
29281/33250 (epoch 44.032), train_loss = 0.91830410, grad/param norm = 2.0098e-01, time/batch = 15.1940s	
29282/33250 (epoch 44.033), train_loss = 0.73559264, grad/param norm = 2.1831e-01, time/batch = 15.0828s	
29283/33250 (epoch 44.035), train_loss = 0.76064396, grad/param norm = 1.7741e-01, time/batch = 15.3240s	
29284/33250 (epoch 44.036), train_loss = 0.80757550, grad/param norm = 2.1695e-01, time/batch = 14.7836s	
29285/33250 (epoch 44.038), train_loss = 0.76745453, grad/param norm = 1.4935e-01, time/batch = 14.4667s	
29286/33250 (epoch 44.039), train_loss = 0.70684507, grad/param norm = 1.6592e-01, time/batch = 14.7861s	
29287/33250 (epoch 44.041), train_loss = 0.79266948, grad/param norm = 2.4755e-01, time/batch = 15.1244s	
29288/33250 (epoch 44.042), train_loss = 0.65423433, grad/param norm = 1.6473e-01, time/batch = 14.7939s	
29289/33250 (epoch 44.044), train_loss = 0.87055118, grad/param norm = 1.9879e-01, time/batch = 14.9480s	
29290/33250 (epoch 44.045), train_loss = 0.85200731, grad/param norm = 1.7795e-01, time/batch = 14.3059s	
29291/33250 (epoch 44.047), train_loss = 0.78118068, grad/param norm = 1.6986e-01, time/batch = 14.6945s	
29292/33250 (epoch 44.048), train_loss = 0.80002005, grad/param norm = 2.6113e-01, time/batch = 14.8606s	
29293/33250 (epoch 44.050), train_loss = 0.76572334, grad/param norm = 1.9733e-01, time/batch = 14.6229s	
29294/33250 (epoch 44.051), train_loss = 0.75546001, grad/param norm = 1.7825e-01, time/batch = 14.6084s	
29295/33250 (epoch 44.053), train_loss = 0.81766851, grad/param norm = 1.9499e-01, time/batch = 14.4585s	
29296/33250 (epoch 44.054), train_loss = 0.65380852, grad/param norm = 1.5642e-01, time/batch = 14.6910s	
29297/33250 (epoch 44.056), train_loss = 0.63634114, grad/param norm = 1.7682e-01, time/batch = 15.6350s	
29298/33250 (epoch 44.057), train_loss = 0.83706970, grad/param norm = 1.8421e-01, time/batch = 14.4915s	
29299/33250 (epoch 44.059), train_loss = 0.75407627, grad/param norm = 1.7846e-01, time/batch = 15.2293s	
29300/33250 (epoch 44.060), train_loss = 0.77634570, grad/param norm = 2.2519e-01, time/batch = 15.6832s	
29301/33250 (epoch 44.062), train_loss = 0.86303724, grad/param norm = 2.0217e-01, time/batch = 14.7814s	
29302/33250 (epoch 44.063), train_loss = 0.87750806, grad/param norm = 1.9015e-01, time/batch = 14.7100s	
29303/33250 (epoch 44.065), train_loss = 0.74153120, grad/param norm = 1.7210e-01, time/batch = 14.6901s	
29304/33250 (epoch 44.066), train_loss = 0.79807192, grad/param norm = 1.8730e-01, time/batch = 14.5395s	
29305/33250 (epoch 44.068), train_loss = 0.72343740, grad/param norm = 1.8120e-01, time/batch = 14.8496s	
29306/33250 (epoch 44.069), train_loss = 0.79448168, grad/param norm = 2.0380e-01, time/batch = 14.4652s	
29307/33250 (epoch 44.071), train_loss = 0.72691019, grad/param norm = 1.7377e-01, time/batch = 14.2988s	
29308/33250 (epoch 44.072), train_loss = 0.68535077, grad/param norm = 1.5542e-01, time/batch = 14.6210s	
29309/33250 (epoch 44.074), train_loss = 0.77534766, grad/param norm = 1.7176e-01, time/batch = 14.6514s	
29310/33250 (epoch 44.075), train_loss = 0.72075246, grad/param norm = 1.9492e-01, time/batch = 15.2955s	
29311/33250 (epoch 44.077), train_loss = 0.74115981, grad/param norm = 1.9871e-01, time/batch = 14.6437s	
29312/33250 (epoch 44.078), train_loss = 0.77300633, grad/param norm = 1.9912e-01, time/batch = 15.0186s	
29313/33250 (epoch 44.080), train_loss = 0.77207649, grad/param norm = 3.2177e-01, time/batch = 14.8624s	
29314/33250 (epoch 44.081), train_loss = 0.78300955, grad/param norm = 1.7859e-01, time/batch = 14.5451s	
29315/33250 (epoch 44.083), train_loss = 0.87527440, grad/param norm = 1.8787e-01, time/batch = 14.4611s	
29316/33250 (epoch 44.084), train_loss = 0.80011323, grad/param norm = 1.8677e-01, time/batch = 14.8576s	
29317/33250 (epoch 44.086), train_loss = 0.76772529, grad/param norm = 1.5963e-01, time/batch = 14.7697s	
29318/33250 (epoch 44.087), train_loss = 0.68124665, grad/param norm = 1.7861e-01, time/batch = 14.4716s	
29319/33250 (epoch 44.089), train_loss = 0.72583868, grad/param norm = 1.7904e-01, time/batch = 14.5500s	
29320/33250 (epoch 44.090), train_loss = 0.76796037, grad/param norm = 1.7691e-01, time/batch = 17.5978s	
29321/33250 (epoch 44.092), train_loss = 0.71131417, grad/param norm = 1.6091e-01, time/batch = 15.7834s	
29322/33250 (epoch 44.093), train_loss = 0.73609480, grad/param norm = 1.6621e-01, time/batch = 17.7141s	
29323/33250 (epoch 44.095), train_loss = 0.75647714, grad/param norm = 1.9206e-01, time/batch = 14.8979s	
29324/33250 (epoch 44.096), train_loss = 0.65366037, grad/param norm = 2.4393e-01, time/batch = 15.0243s	
29325/33250 (epoch 44.098), train_loss = 0.64920595, grad/param norm = 1.9790e-01, time/batch = 15.2134s	
29326/33250 (epoch 44.099), train_loss = 0.59950181, grad/param norm = 1.4870e-01, time/batch = 15.2818s	
29327/33250 (epoch 44.101), train_loss = 0.73637407, grad/param norm = 2.0081e-01, time/batch = 14.8010s	
29328/33250 (epoch 44.102), train_loss = 0.70724830, grad/param norm = 1.6991e-01, time/batch = 14.9216s	
29329/33250 (epoch 44.104), train_loss = 0.57772936, grad/param norm = 1.5076e-01, time/batch = 15.4253s	
29330/33250 (epoch 44.105), train_loss = 0.70698415, grad/param norm = 2.0106e-01, time/batch = 14.6275s	
29331/33250 (epoch 44.107), train_loss = 0.63772612, grad/param norm = 1.4074e-01, time/batch = 15.3868s	
29332/33250 (epoch 44.108), train_loss = 0.74010018, grad/param norm = 1.8732e-01, time/batch = 14.8072s	
29333/33250 (epoch 44.110), train_loss = 0.64568776, grad/param norm = 1.8082e-01, time/batch = 14.9374s	
29334/33250 (epoch 44.111), train_loss = 0.74165056, grad/param norm = 1.6049e-01, time/batch = 16.9684s	
29335/33250 (epoch 44.113), train_loss = 0.70068230, grad/param norm = 2.0457e-01, time/batch = 15.5656s	
29336/33250 (epoch 44.114), train_loss = 0.64726367, grad/param norm = 1.7560e-01, time/batch = 15.0904s	
29337/33250 (epoch 44.116), train_loss = 0.68218145, grad/param norm = 1.9015e-01, time/batch = 14.5547s	
29338/33250 (epoch 44.117), train_loss = 0.66119529, grad/param norm = 1.6785e-01, time/batch = 14.2285s	
29339/33250 (epoch 44.119), train_loss = 0.69586559, grad/param norm = 2.1625e-01, time/batch = 14.6213s	
29340/33250 (epoch 44.120), train_loss = 0.61586049, grad/param norm = 1.6044e-01, time/batch = 14.7769s	
29341/33250 (epoch 44.122), train_loss = 0.79913288, grad/param norm = 1.9038e-01, time/batch = 14.8544s	
29342/33250 (epoch 44.123), train_loss = 0.74089494, grad/param norm = 2.2382e-01, time/batch = 14.5472s	
29343/33250 (epoch 44.125), train_loss = 0.60822813, grad/param norm = 2.0343e-01, time/batch = 15.0674s	
29344/33250 (epoch 44.126), train_loss = 0.71538810, grad/param norm = 2.1333e-01, time/batch = 15.2926s	
29345/33250 (epoch 44.128), train_loss = 0.69086139, grad/param norm = 1.6206e-01, time/batch = 16.6418s	
29346/33250 (epoch 44.129), train_loss = 0.73382631, grad/param norm = 1.9923e-01, time/batch = 15.9748s	
29347/33250 (epoch 44.131), train_loss = 0.71780166, grad/param norm = 1.7606e-01, time/batch = 15.3772s	
29348/33250 (epoch 44.132), train_loss = 0.69944665, grad/param norm = 1.7480e-01, time/batch = 14.7833s	
29349/33250 (epoch 44.134), train_loss = 0.67007396, grad/param norm = 1.9267e-01, time/batch = 14.6052s	
29350/33250 (epoch 44.135), train_loss = 0.74857463, grad/param norm = 1.5003e-01, time/batch = 14.8443s	
29351/33250 (epoch 44.137), train_loss = 0.66236665, grad/param norm = 2.1293e-01, time/batch = 14.1396s	
29352/33250 (epoch 44.138), train_loss = 0.65291904, grad/param norm = 1.5824e-01, time/batch = 14.7791s	
29353/33250 (epoch 44.140), train_loss = 0.58596925, grad/param norm = 1.7980e-01, time/batch = 14.3142s	
29354/33250 (epoch 44.141), train_loss = 0.79874434, grad/param norm = 2.3412e-01, time/batch = 15.4783s	
29355/33250 (epoch 44.143), train_loss = 0.62248549, grad/param norm = 1.7004e-01, time/batch = 16.4756s	
29356/33250 (epoch 44.144), train_loss = 0.69977743, grad/param norm = 1.6216e-01, time/batch = 16.3464s	
29357/33250 (epoch 44.146), train_loss = 0.69165409, grad/param norm = 1.6639e-01, time/batch = 16.5643s	
29358/33250 (epoch 44.147), train_loss = 0.71719864, grad/param norm = 1.8438e-01, time/batch = 15.7165s	
29359/33250 (epoch 44.149), train_loss = 0.68270190, grad/param norm = 1.6782e-01, time/batch = 15.5981s	
29360/33250 (epoch 44.150), train_loss = 0.67584209, grad/param norm = 2.2087e-01, time/batch = 14.5307s	
29361/33250 (epoch 44.152), train_loss = 0.62188619, grad/param norm = 2.0406e-01, time/batch = 15.7039s	
29362/33250 (epoch 44.153), train_loss = 0.86483805, grad/param norm = 1.9905e-01, time/batch = 14.4720s	
29363/33250 (epoch 44.155), train_loss = 0.69649082, grad/param norm = 2.2738e-01, time/batch = 14.3758s	
29364/33250 (epoch 44.156), train_loss = 0.92141137, grad/param norm = 2.0778e-01, time/batch = 15.2828s	
29365/33250 (epoch 44.158), train_loss = 0.86843719, grad/param norm = 2.6582e-01, time/batch = 15.4623s	
29366/33250 (epoch 44.159), train_loss = 0.70558139, grad/param norm = 1.8084e-01, time/batch = 15.4610s	
29367/33250 (epoch 44.161), train_loss = 0.74738640, grad/param norm = 2.1144e-01, time/batch = 14.7139s	
29368/33250 (epoch 44.162), train_loss = 0.67360294, grad/param norm = 1.7282e-01, time/batch = 15.8818s	
29369/33250 (epoch 44.164), train_loss = 0.74031251, grad/param norm = 2.1330e-01, time/batch = 14.8286s	
29370/33250 (epoch 44.165), train_loss = 0.82464868, grad/param norm = 2.0253e-01, time/batch = 14.2976s	
29371/33250 (epoch 44.167), train_loss = 0.84229242, grad/param norm = 1.8427e-01, time/batch = 14.7052s	
29372/33250 (epoch 44.168), train_loss = 0.66916636, grad/param norm = 1.6557e-01, time/batch = 14.8479s	
29373/33250 (epoch 44.170), train_loss = 0.73685044, grad/param norm = 2.4250e-01, time/batch = 14.6358s	
29374/33250 (epoch 44.171), train_loss = 0.74791109, grad/param norm = 1.7727e-01, time/batch = 14.1395s	
29375/33250 (epoch 44.173), train_loss = 0.75485741, grad/param norm = 1.8866e-01, time/batch = 14.9461s	
29376/33250 (epoch 44.174), train_loss = 0.76798941, grad/param norm = 1.7890e-01, time/batch = 15.8532s	
29377/33250 (epoch 44.176), train_loss = 0.68499333, grad/param norm = 1.8157e-01, time/batch = 14.6236s	
29378/33250 (epoch 44.177), train_loss = 0.67327074, grad/param norm = 1.9193e-01, time/batch = 15.0577s	
29379/33250 (epoch 44.179), train_loss = 0.67065641, grad/param norm = 1.5175e-01, time/batch = 15.2161s	
29380/33250 (epoch 44.180), train_loss = 0.59650001, grad/param norm = 1.7221e-01, time/batch = 15.6405s	
29381/33250 (epoch 44.182), train_loss = 0.68585649, grad/param norm = 2.7377e-01, time/batch = 15.8684s	
29382/33250 (epoch 44.183), train_loss = 0.81581309, grad/param norm = 2.2673e-01, time/batch = 15.5340s	
29383/33250 (epoch 44.185), train_loss = 0.76158712, grad/param norm = 2.2517e-01, time/batch = 14.5404s	
29384/33250 (epoch 44.186), train_loss = 0.75736410, grad/param norm = 2.0520e-01, time/batch = 14.6853s	
29385/33250 (epoch 44.188), train_loss = 0.81800061, grad/param norm = 2.0611e-01, time/batch = 14.2868s	
29386/33250 (epoch 44.189), train_loss = 0.60457901, grad/param norm = 2.0193e-01, time/batch = 14.0616s	
29387/33250 (epoch 44.191), train_loss = 0.69112868, grad/param norm = 1.8802e-01, time/batch = 14.2099s	
29388/33250 (epoch 44.192), train_loss = 0.69096021, grad/param norm = 1.6848e-01, time/batch = 14.1556s	
29389/33250 (epoch 44.194), train_loss = 0.70784614, grad/param norm = 1.9901e-01, time/batch = 15.0426s	
29390/33250 (epoch 44.195), train_loss = 0.86144564, grad/param norm = 1.8340e-01, time/batch = 16.1368s	
29391/33250 (epoch 44.197), train_loss = 0.69026972, grad/param norm = 1.8578e-01, time/batch = 14.8053s	
29392/33250 (epoch 44.198), train_loss = 0.85315710, grad/param norm = 1.8465e-01, time/batch = 14.6157s	
29393/33250 (epoch 44.200), train_loss = 0.75083522, grad/param norm = 2.0700e-01, time/batch = 14.6007s	
29394/33250 (epoch 44.202), train_loss = 0.70557654, grad/param norm = 1.5236e-01, time/batch = 14.4645s	
29395/33250 (epoch 44.203), train_loss = 0.64927266, grad/param norm = 1.9455e-01, time/batch = 14.4619s	
29396/33250 (epoch 44.205), train_loss = 0.74447762, grad/param norm = 1.6206e-01, time/batch = 14.5500s	
29397/33250 (epoch 44.206), train_loss = 0.78971341, grad/param norm = 1.8948e-01, time/batch = 14.2230s	
29398/33250 (epoch 44.208), train_loss = 0.83041511, grad/param norm = 2.1524e-01, time/batch = 14.2101s	
29399/33250 (epoch 44.209), train_loss = 0.71977501, grad/param norm = 2.0105e-01, time/batch = 14.4755s	
29400/33250 (epoch 44.211), train_loss = 0.75483012, grad/param norm = 1.7538e-01, time/batch = 14.4560s	
29401/33250 (epoch 44.212), train_loss = 0.86019276, grad/param norm = 1.8845e-01, time/batch = 14.7061s	
29402/33250 (epoch 44.214), train_loss = 0.77011315, grad/param norm = 1.6287e-01, time/batch = 14.9559s	
29403/33250 (epoch 44.215), train_loss = 0.77083461, grad/param norm = 2.1424e-01, time/batch = 14.3196s	
29404/33250 (epoch 44.217), train_loss = 0.81597788, grad/param norm = 2.1742e-01, time/batch = 14.3842s	
29405/33250 (epoch 44.218), train_loss = 0.76982352, grad/param norm = 1.6246e-01, time/batch = 14.8044s	
29406/33250 (epoch 44.220), train_loss = 0.74248798, grad/param norm = 1.7456e-01, time/batch = 14.6253s	
29407/33250 (epoch 44.221), train_loss = 0.84649240, grad/param norm = 2.1214e-01, time/batch = 14.6940s	
29408/33250 (epoch 44.223), train_loss = 0.74920909, grad/param norm = 1.7090e-01, time/batch = 14.7756s	
29409/33250 (epoch 44.224), train_loss = 0.77770392, grad/param norm = 1.9117e-01, time/batch = 15.0233s	
29410/33250 (epoch 44.226), train_loss = 0.86404011, grad/param norm = 1.7888e-01, time/batch = 14.2358s	
29411/33250 (epoch 44.227), train_loss = 0.78660177, grad/param norm = 1.9076e-01, time/batch = 14.1508s	
29412/33250 (epoch 44.229), train_loss = 0.78900355, grad/param norm = 1.7824e-01, time/batch = 14.9357s	
29413/33250 (epoch 44.230), train_loss = 0.76190943, grad/param norm = 1.7903e-01, time/batch = 14.4774s	
29414/33250 (epoch 44.232), train_loss = 0.70566294, grad/param norm = 1.7231e-01, time/batch = 14.6286s	
29415/33250 (epoch 44.233), train_loss = 0.68344656, grad/param norm = 1.8063e-01, time/batch = 14.3968s	
29416/33250 (epoch 44.235), train_loss = 0.84166438, grad/param norm = 1.6687e-01, time/batch = 15.0286s	
29417/33250 (epoch 44.236), train_loss = 0.68376320, grad/param norm = 1.9603e-01, time/batch = 14.4870s	
29418/33250 (epoch 44.238), train_loss = 0.84653336, grad/param norm = 2.2556e-01, time/batch = 14.6222s	
29419/33250 (epoch 44.239), train_loss = 0.84914223, grad/param norm = 2.2162e-01, time/batch = 14.4030s	
29420/33250 (epoch 44.241), train_loss = 0.82690007, grad/param norm = 2.1910e-01, time/batch = 14.8587s	
29421/33250 (epoch 44.242), train_loss = 0.83778415, grad/param norm = 2.0101e-01, time/batch = 14.3748s	
29422/33250 (epoch 44.244), train_loss = 0.78376984, grad/param norm = 2.2008e-01, time/batch = 14.5371s	
29423/33250 (epoch 44.245), train_loss = 0.78676231, grad/param norm = 1.9957e-01, time/batch = 14.3756s	
29424/33250 (epoch 44.247), train_loss = 0.74371444, grad/param norm = 1.7722e-01, time/batch = 14.6968s	
29425/33250 (epoch 44.248), train_loss = 0.86716861, grad/param norm = 2.0650e-01, time/batch = 14.2994s	
29426/33250 (epoch 44.250), train_loss = 0.87325337, grad/param norm = 1.8010e-01, time/batch = 14.4605s	
29427/33250 (epoch 44.251), train_loss = 0.73599814, grad/param norm = 1.6650e-01, time/batch = 14.8620s	
29428/33250 (epoch 44.253), train_loss = 0.74378459, grad/param norm = 1.7037e-01, time/batch = 15.0364s	
29429/33250 (epoch 44.254), train_loss = 0.69951790, grad/param norm = 1.7521e-01, time/batch = 15.0470s	
29430/33250 (epoch 44.256), train_loss = 0.75622016, grad/param norm = 1.8147e-01, time/batch = 15.2966s	
29431/33250 (epoch 44.257), train_loss = 0.90651103, grad/param norm = 1.9137e-01, time/batch = 14.8143s	
29432/33250 (epoch 44.259), train_loss = 0.76649031, grad/param norm = 1.8534e-01, time/batch = 14.7787s	
29433/33250 (epoch 44.260), train_loss = 0.62555562, grad/param norm = 1.8610e-01, time/batch = 14.5352s	
29434/33250 (epoch 44.262), train_loss = 0.75950596, grad/param norm = 1.7250e-01, time/batch = 14.3721s	
29435/33250 (epoch 44.263), train_loss = 0.61905448, grad/param norm = 1.7795e-01, time/batch = 14.2132s	
29436/33250 (epoch 44.265), train_loss = 0.78300781, grad/param norm = 1.9461e-01, time/batch = 14.4458s	
29437/33250 (epoch 44.266), train_loss = 0.76464636, grad/param norm = 1.8201e-01, time/batch = 14.0530s	
29438/33250 (epoch 44.268), train_loss = 0.68398646, grad/param norm = 1.8445e-01, time/batch = 14.3622s	
29439/33250 (epoch 44.269), train_loss = 0.62802265, grad/param norm = 1.8122e-01, time/batch = 14.5640s	
29440/33250 (epoch 44.271), train_loss = 0.79771861, grad/param norm = 1.8096e-01, time/batch = 21.6170s	
29441/33250 (epoch 44.272), train_loss = 0.68814003, grad/param norm = 1.7398e-01, time/batch = 22.5262s	
29442/33250 (epoch 44.274), train_loss = 0.55451299, grad/param norm = 1.5870e-01, time/batch = 14.7765s	
29443/33250 (epoch 44.275), train_loss = 0.72048481, grad/param norm = 1.6946e-01, time/batch = 14.7034s	
29444/33250 (epoch 44.277), train_loss = 0.63211873, grad/param norm = 1.6823e-01, time/batch = 14.6209s	
29445/33250 (epoch 44.278), train_loss = 0.71536301, grad/param norm = 1.7783e-01, time/batch = 14.7844s	
29446/33250 (epoch 44.280), train_loss = 0.65630675, grad/param norm = 1.6109e-01, time/batch = 15.0910s	
29447/33250 (epoch 44.281), train_loss = 0.78497933, grad/param norm = 2.3585e-01, time/batch = 14.7945s	
29448/33250 (epoch 44.283), train_loss = 0.77879044, grad/param norm = 3.4541e-01, time/batch = 14.7927s	
29449/33250 (epoch 44.284), train_loss = 0.65112078, grad/param norm = 2.3234e-01, time/batch = 15.1649s	
29450/33250 (epoch 44.286), train_loss = 0.77870719, grad/param norm = 1.8695e-01, time/batch = 15.1222s	
29451/33250 (epoch 44.287), train_loss = 0.63316685, grad/param norm = 1.6590e-01, time/batch = 14.8080s	
29452/33250 (epoch 44.289), train_loss = 0.59537261, grad/param norm = 1.6947e-01, time/batch = 14.9724s	
29453/33250 (epoch 44.290), train_loss = 0.73928793, grad/param norm = 1.6563e-01, time/batch = 14.7820s	
29454/33250 (epoch 44.292), train_loss = 0.77279673, grad/param norm = 2.2872e-01, time/batch = 14.5493s	
29455/33250 (epoch 44.293), train_loss = 0.85218873, grad/param norm = 2.0362e-01, time/batch = 14.7800s	
29456/33250 (epoch 44.295), train_loss = 0.85232204, grad/param norm = 2.1049e-01, time/batch = 15.1194s	
29457/33250 (epoch 44.296), train_loss = 0.75869375, grad/param norm = 1.8124e-01, time/batch = 14.7095s	
29458/33250 (epoch 44.298), train_loss = 0.61500170, grad/param norm = 1.5744e-01, time/batch = 14.3779s	
29459/33250 (epoch 44.299), train_loss = 0.59856995, grad/param norm = 1.7676e-01, time/batch = 14.5327s	
29460/33250 (epoch 44.301), train_loss = 0.81963926, grad/param norm = 2.1176e-01, time/batch = 14.6852s	
29461/33250 (epoch 44.302), train_loss = 0.82209015, grad/param norm = 2.2757e-01, time/batch = 14.3980s	
29462/33250 (epoch 44.304), train_loss = 0.71181977, grad/param norm = 1.9385e-01, time/batch = 14.3915s	
29463/33250 (epoch 44.305), train_loss = 0.69630327, grad/param norm = 1.9400e-01, time/batch = 14.2314s	
29464/33250 (epoch 44.307), train_loss = 0.80671526, grad/param norm = 2.7184e-01, time/batch = 14.9396s	
29465/33250 (epoch 44.308), train_loss = 0.85852690, grad/param norm = 2.1714e-01, time/batch = 14.5514s	
29466/33250 (epoch 44.310), train_loss = 0.70452314, grad/param norm = 2.1926e-01, time/batch = 14.6929s	
29467/33250 (epoch 44.311), train_loss = 0.89040204, grad/param norm = 2.1292e-01, time/batch = 14.4535s	
29468/33250 (epoch 44.313), train_loss = 0.62324046, grad/param norm = 2.0391e-01, time/batch = 14.9458s	
29469/33250 (epoch 44.314), train_loss = 0.82410959, grad/param norm = 1.9557e-01, time/batch = 15.0314s	
29470/33250 (epoch 44.316), train_loss = 0.93019698, grad/param norm = 2.4810e-01, time/batch = 14.7851s	
29471/33250 (epoch 44.317), train_loss = 0.65974408, grad/param norm = 1.6717e-01, time/batch = 14.7825s	
29472/33250 (epoch 44.319), train_loss = 0.78441902, grad/param norm = 2.7455e-01, time/batch = 14.9303s	
29473/33250 (epoch 44.320), train_loss = 0.83077533, grad/param norm = 2.3224e-01, time/batch = 14.9400s	
29474/33250 (epoch 44.322), train_loss = 0.93016551, grad/param norm = 2.4709e-01, time/batch = 14.7906s	
29475/33250 (epoch 44.323), train_loss = 0.89861020, grad/param norm = 3.1794e-01, time/batch = 14.8267s	
29476/33250 (epoch 44.325), train_loss = 0.72629452, grad/param norm = 2.0639e-01, time/batch = 14.9533s	
29477/33250 (epoch 44.326), train_loss = 0.96911002, grad/param norm = 2.2219e-01, time/batch = 14.5416s	
29478/33250 (epoch 44.328), train_loss = 0.73733823, grad/param norm = 1.7958e-01, time/batch = 14.4673s	
29479/33250 (epoch 44.329), train_loss = 0.78472109, grad/param norm = 2.1669e-01, time/batch = 14.7076s	
29480/33250 (epoch 44.331), train_loss = 0.78774876, grad/param norm = 2.2323e-01, time/batch = 15.0828s	
29481/33250 (epoch 44.332), train_loss = 0.78951537, grad/param norm = 2.0489e-01, time/batch = 14.7784s	
29482/33250 (epoch 44.334), train_loss = 0.89409653, grad/param norm = 1.9333e-01, time/batch = 14.7852s	
29483/33250 (epoch 44.335), train_loss = 0.57625661, grad/param norm = 1.6148e-01, time/batch = 14.5464s	
29484/33250 (epoch 44.337), train_loss = 0.82083814, grad/param norm = 1.7374e-01, time/batch = 14.9475s	
29485/33250 (epoch 44.338), train_loss = 0.93350191, grad/param norm = 1.9234e-01, time/batch = 15.0555s	
29486/33250 (epoch 44.340), train_loss = 0.72878809, grad/param norm = 1.7196e-01, time/batch = 14.7119s	
29487/33250 (epoch 44.341), train_loss = 0.69370672, grad/param norm = 1.9683e-01, time/batch = 15.1915s	
29488/33250 (epoch 44.343), train_loss = 0.74333695, grad/param norm = 1.8726e-01, time/batch = 14.8014s	
29489/33250 (epoch 44.344), train_loss = 0.72985475, grad/param norm = 1.7891e-01, time/batch = 14.9356s	
29490/33250 (epoch 44.346), train_loss = 0.66965237, grad/param norm = 2.1523e-01, time/batch = 14.4614s	
29491/33250 (epoch 44.347), train_loss = 0.91085227, grad/param norm = 1.9224e-01, time/batch = 14.9367s	
29492/33250 (epoch 44.349), train_loss = 0.75202375, grad/param norm = 1.9598e-01, time/batch = 15.0133s	
29493/33250 (epoch 44.350), train_loss = 0.75312904, grad/param norm = 2.0040e-01, time/batch = 14.4565s	
29494/33250 (epoch 44.352), train_loss = 0.68341226, grad/param norm = 1.8103e-01, time/batch = 14.8611s	
29495/33250 (epoch 44.353), train_loss = 0.72624079, grad/param norm = 1.8788e-01, time/batch = 14.6724s	
29496/33250 (epoch 44.355), train_loss = 0.72363475, grad/param norm = 1.7227e-01, time/batch = 14.8664s	
29497/33250 (epoch 44.356), train_loss = 0.68501454, grad/param norm = 1.7142e-01, time/batch = 14.3778s	
29498/33250 (epoch 44.358), train_loss = 0.74384119, grad/param norm = 1.6790e-01, time/batch = 14.3950s	
29499/33250 (epoch 44.359), train_loss = 0.72144467, grad/param norm = 1.8622e-01, time/batch = 16.3028s	
29500/33250 (epoch 44.361), train_loss = 0.83987692, grad/param norm = 2.4815e-01, time/batch = 15.0141s	
29501/33250 (epoch 44.362), train_loss = 0.78898926, grad/param norm = 1.7911e-01, time/batch = 14.2963s	
29502/33250 (epoch 44.364), train_loss = 0.81421713, grad/param norm = 2.1042e-01, time/batch = 14.6976s	
29503/33250 (epoch 44.365), train_loss = 0.74924057, grad/param norm = 1.6847e-01, time/batch = 14.4686s	
29504/33250 (epoch 44.367), train_loss = 0.77049360, grad/param norm = 1.6090e-01, time/batch = 14.6969s	
29505/33250 (epoch 44.368), train_loss = 0.74021992, grad/param norm = 1.7856e-01, time/batch = 14.3815s	
29506/33250 (epoch 44.370), train_loss = 0.66182608, grad/param norm = 1.5866e-01, time/batch = 14.3852s	
29507/33250 (epoch 44.371), train_loss = 0.83473232, grad/param norm = 1.9931e-01, time/batch = 14.3787s	
29508/33250 (epoch 44.373), train_loss = 0.72483462, grad/param norm = 1.4429e-01, time/batch = 15.0978s	
29509/33250 (epoch 44.374), train_loss = 0.75491778, grad/param norm = 2.8834e-01, time/batch = 14.6354s	
29510/33250 (epoch 44.376), train_loss = 0.76033842, grad/param norm = 1.7492e-01, time/batch = 14.3866s	
29511/33250 (epoch 44.377), train_loss = 0.65926422, grad/param norm = 2.1678e-01, time/batch = 14.4950s	
29512/33250 (epoch 44.379), train_loss = 0.76253796, grad/param norm = 2.0575e-01, time/batch = 14.6998s	
29513/33250 (epoch 44.380), train_loss = 0.74738455, grad/param norm = 2.0113e-01, time/batch = 14.7594s	
29514/33250 (epoch 44.382), train_loss = 0.77516715, grad/param norm = 2.3837e-01, time/batch = 14.1299s	
29515/33250 (epoch 44.383), train_loss = 0.66610379, grad/param norm = 1.9829e-01, time/batch = 14.3736s	
29516/33250 (epoch 44.385), train_loss = 0.63262716, grad/param norm = 1.7386e-01, time/batch = 14.2899s	
29517/33250 (epoch 44.386), train_loss = 0.64778033, grad/param norm = 1.9526e-01, time/batch = 14.3719s	
29518/33250 (epoch 44.388), train_loss = 0.70224356, grad/param norm = 1.8080e-01, time/batch = 14.6201s	
29519/33250 (epoch 44.389), train_loss = 0.67834870, grad/param norm = 1.8650e-01, time/batch = 14.2337s	
29520/33250 (epoch 44.391), train_loss = 0.77832987, grad/param norm = 1.8329e-01, time/batch = 14.7968s	
29521/33250 (epoch 44.392), train_loss = 0.84449874, grad/param norm = 2.1272e-01, time/batch = 14.5700s	
29522/33250 (epoch 44.394), train_loss = 0.82796357, grad/param norm = 1.9229e-01, time/batch = 14.8007s	
29523/33250 (epoch 44.395), train_loss = 0.85453402, grad/param norm = 1.7919e-01, time/batch = 14.7896s	
29524/33250 (epoch 44.397), train_loss = 0.86982994, grad/param norm = 2.0423e-01, time/batch = 14.5415s	
29525/33250 (epoch 44.398), train_loss = 0.67207182, grad/param norm = 1.6151e-01, time/batch = 14.6145s	
29526/33250 (epoch 44.400), train_loss = 0.66830152, grad/param norm = 1.7282e-01, time/batch = 14.8442s	
29527/33250 (epoch 44.402), train_loss = 0.63572173, grad/param norm = 1.7367e-01, time/batch = 14.7748s	
29528/33250 (epoch 44.403), train_loss = 0.73981413, grad/param norm = 2.1603e-01, time/batch = 14.6272s	
29529/33250 (epoch 44.405), train_loss = 0.69672243, grad/param norm = 1.6659e-01, time/batch = 15.0243s	
29530/33250 (epoch 44.406), train_loss = 0.74555908, grad/param norm = 1.9885e-01, time/batch = 15.0240s	
29531/33250 (epoch 44.408), train_loss = 0.89188465, grad/param norm = 1.8908e-01, time/batch = 15.5373s	
29532/33250 (epoch 44.409), train_loss = 0.78940510, grad/param norm = 2.3227e-01, time/batch = 15.3856s	
29533/33250 (epoch 44.411), train_loss = 0.55570263, grad/param norm = 1.4944e-01, time/batch = 14.9848s	
29534/33250 (epoch 44.412), train_loss = 0.65102062, grad/param norm = 1.9927e-01, time/batch = 14.8122s	
29535/33250 (epoch 44.414), train_loss = 0.75619744, grad/param norm = 1.9440e-01, time/batch = 14.6201s	
29536/33250 (epoch 44.415), train_loss = 0.82042452, grad/param norm = 1.9359e-01, time/batch = 14.6895s	
29537/33250 (epoch 44.417), train_loss = 0.84302892, grad/param norm = 1.9725e-01, time/batch = 15.0133s	
29538/33250 (epoch 44.418), train_loss = 0.98920974, grad/param norm = 2.1480e-01, time/batch = 14.4762s	
29539/33250 (epoch 44.420), train_loss = 0.82013897, grad/param norm = 1.9955e-01, time/batch = 14.5361s	
29540/33250 (epoch 44.421), train_loss = 0.71505215, grad/param norm = 1.6743e-01, time/batch = 14.5379s	
29541/33250 (epoch 44.423), train_loss = 0.80301032, grad/param norm = 1.9888e-01, time/batch = 14.6999s	
29542/33250 (epoch 44.424), train_loss = 0.87258074, grad/param norm = 2.5220e-01, time/batch = 14.5568s	
29543/33250 (epoch 44.426), train_loss = 0.73398660, grad/param norm = 1.5843e-01, time/batch = 14.8034s	
29544/33250 (epoch 44.427), train_loss = 0.69626261, grad/param norm = 1.7774e-01, time/batch = 14.5559s	
29545/33250 (epoch 44.429), train_loss = 0.74427408, grad/param norm = 2.0726e-01, time/batch = 14.9450s	
29546/33250 (epoch 44.430), train_loss = 0.70352839, grad/param norm = 1.9865e-01, time/batch = 14.6052s	
29547/33250 (epoch 44.432), train_loss = 0.81974323, grad/param norm = 1.7869e-01, time/batch = 14.5459s	
29548/33250 (epoch 44.433), train_loss = 0.71792682, grad/param norm = 2.0239e-01, time/batch = 14.6134s	
29549/33250 (epoch 44.435), train_loss = 0.80429829, grad/param norm = 1.7475e-01, time/batch = 15.1797s	
29550/33250 (epoch 44.436), train_loss = 0.72132163, grad/param norm = 1.8814e-01, time/batch = 15.0668s	
29551/33250 (epoch 44.438), train_loss = 0.85585601, grad/param norm = 1.8854e-01, time/batch = 15.0118s	
29552/33250 (epoch 44.439), train_loss = 0.77297293, grad/param norm = 1.8767e-01, time/batch = 14.5254s	
29553/33250 (epoch 44.441), train_loss = 0.74565744, grad/param norm = 1.7800e-01, time/batch = 14.6142s	
29554/33250 (epoch 44.442), train_loss = 0.67098350, grad/param norm = 1.6950e-01, time/batch = 14.8057s	
29555/33250 (epoch 44.444), train_loss = 0.71256620, grad/param norm = 1.7279e-01, time/batch = 14.6422s	
29556/33250 (epoch 44.445), train_loss = 0.77909816, grad/param norm = 1.6355e-01, time/batch = 14.5746s	
29557/33250 (epoch 44.447), train_loss = 0.67094846, grad/param norm = 1.9564e-01, time/batch = 14.9449s	
29558/33250 (epoch 44.448), train_loss = 0.78089054, grad/param norm = 1.6024e-01, time/batch = 14.9337s	
29559/33250 (epoch 44.450), train_loss = 0.85286357, grad/param norm = 2.1657e-01, time/batch = 14.5484s	
29560/33250 (epoch 44.451), train_loss = 0.81873272, grad/param norm = 2.4212e-01, time/batch = 14.3010s	
29561/33250 (epoch 44.453), train_loss = 0.64391301, grad/param norm = 1.3794e-01, time/batch = 15.0956s	
29562/33250 (epoch 44.454), train_loss = 0.86227075, grad/param norm = 1.8875e-01, time/batch = 14.4626s	
29563/33250 (epoch 44.456), train_loss = 0.87744666, grad/param norm = 1.6332e-01, time/batch = 14.5413s	
29564/33250 (epoch 44.457), train_loss = 0.68788827, grad/param norm = 1.7347e-01, time/batch = 14.8578s	
29565/33250 (epoch 44.459), train_loss = 0.82583488, grad/param norm = 1.6994e-01, time/batch = 15.1029s	
29566/33250 (epoch 44.460), train_loss = 0.81665351, grad/param norm = 2.0132e-01, time/batch = 14.4892s	
29567/33250 (epoch 44.462), train_loss = 0.75575238, grad/param norm = 1.7918e-01, time/batch = 14.4867s	
29568/33250 (epoch 44.463), train_loss = 0.66139187, grad/param norm = 1.4811e-01, time/batch = 15.2294s	
29569/33250 (epoch 44.465), train_loss = 0.64002418, grad/param norm = 1.6063e-01, time/batch = 14.9527s	
29570/33250 (epoch 44.466), train_loss = 0.62284856, grad/param norm = 1.4538e-01, time/batch = 15.1492s	
29571/33250 (epoch 44.468), train_loss = 0.64618907, grad/param norm = 1.5168e-01, time/batch = 14.7138s	
29572/33250 (epoch 44.469), train_loss = 0.74652676, grad/param norm = 1.9583e-01, time/batch = 14.7840s	
29573/33250 (epoch 44.471), train_loss = 0.82838738, grad/param norm = 1.5832e-01, time/batch = 15.2405s	
29574/33250 (epoch 44.472), train_loss = 0.72171821, grad/param norm = 1.9447e-01, time/batch = 14.8525s	
29575/33250 (epoch 44.474), train_loss = 0.83033871, grad/param norm = 1.9112e-01, time/batch = 14.3004s	
29576/33250 (epoch 44.475), train_loss = 0.78273446, grad/param norm = 1.6230e-01, time/batch = 14.4484s	
29577/33250 (epoch 44.477), train_loss = 0.77285072, grad/param norm = 1.6772e-01, time/batch = 14.7800s	
29578/33250 (epoch 44.478), train_loss = 0.66720422, grad/param norm = 2.0898e-01, time/batch = 14.3819s	
29579/33250 (epoch 44.480), train_loss = 0.85161041, grad/param norm = 1.8364e-01, time/batch = 14.5529s	
29580/33250 (epoch 44.481), train_loss = 0.72537791, grad/param norm = 1.8099e-01, time/batch = 15.2378s	
29581/33250 (epoch 44.483), train_loss = 0.73412505, grad/param norm = 1.7473e-01, time/batch = 15.3205s	
29582/33250 (epoch 44.484), train_loss = 0.68802986, grad/param norm = 1.6711e-01, time/batch = 14.4587s	
29583/33250 (epoch 44.486), train_loss = 0.60090787, grad/param norm = 1.6090e-01, time/batch = 14.7800s	
29584/33250 (epoch 44.487), train_loss = 0.67396924, grad/param norm = 1.7484e-01, time/batch = 14.8505s	
29585/33250 (epoch 44.489), train_loss = 0.81514689, grad/param norm = 2.1048e-01, time/batch = 14.7786s	
29586/33250 (epoch 44.490), train_loss = 0.74898758, grad/param norm = 1.8377e-01, time/batch = 14.6242s	
29587/33250 (epoch 44.492), train_loss = 0.81791502, grad/param norm = 1.8543e-01, time/batch = 14.3765s	
29588/33250 (epoch 44.493), train_loss = 0.74018937, grad/param norm = 1.9682e-01, time/batch = 14.3602s	
29589/33250 (epoch 44.495), train_loss = 0.81238820, grad/param norm = 1.6772e-01, time/batch = 14.6306s	
29590/33250 (epoch 44.496), train_loss = 0.76294140, grad/param norm = 1.6398e-01, time/batch = 15.0208s	
29591/33250 (epoch 44.498), train_loss = 0.80626475, grad/param norm = 1.8986e-01, time/batch = 14.5550s	
29592/33250 (epoch 44.499), train_loss = 0.71106968, grad/param norm = 1.8383e-01, time/batch = 14.5552s	
29593/33250 (epoch 44.501), train_loss = 0.70742113, grad/param norm = 2.0409e-01, time/batch = 14.5279s	
29594/33250 (epoch 44.502), train_loss = 0.70621732, grad/param norm = 1.6040e-01, time/batch = 14.3707s	
29595/33250 (epoch 44.504), train_loss = 0.85948175, grad/param norm = 2.2105e-01, time/batch = 14.5298s	
29596/33250 (epoch 44.505), train_loss = 0.65085209, grad/param norm = 1.4559e-01, time/batch = 14.2931s	
29597/33250 (epoch 44.507), train_loss = 0.68026582, grad/param norm = 1.7778e-01, time/batch = 14.5358s	
29598/33250 (epoch 44.508), train_loss = 0.72849327, grad/param norm = 1.8139e-01, time/batch = 14.3674s	
29599/33250 (epoch 44.510), train_loss = 0.62705327, grad/param norm = 1.5031e-01, time/batch = 14.3645s	
29600/33250 (epoch 44.511), train_loss = 0.72009883, grad/param norm = 1.8299e-01, time/batch = 14.7350s	
29601/33250 (epoch 44.513), train_loss = 0.85113916, grad/param norm = 1.9118e-01, time/batch = 14.9558s	
29602/33250 (epoch 44.514), train_loss = 0.71868514, grad/param norm = 1.9788e-01, time/batch = 14.9457s	
29603/33250 (epoch 44.516), train_loss = 0.68097406, grad/param norm = 1.8152e-01, time/batch = 14.9604s	
29604/33250 (epoch 44.517), train_loss = 0.71235431, grad/param norm = 1.6543e-01, time/batch = 15.1728s	
29605/33250 (epoch 44.519), train_loss = 0.66952128, grad/param norm = 1.3472e-01, time/batch = 14.8558s	
29606/33250 (epoch 44.520), train_loss = 0.89439109, grad/param norm = 2.1496e-01, time/batch = 14.8473s	
29607/33250 (epoch 44.522), train_loss = 0.75290742, grad/param norm = 1.7035e-01, time/batch = 14.6170s	
29608/33250 (epoch 44.523), train_loss = 0.67367415, grad/param norm = 1.8710e-01, time/batch = 14.6167s	
29609/33250 (epoch 44.525), train_loss = 0.63675060, grad/param norm = 1.9623e-01, time/batch = 14.9094s	
29610/33250 (epoch 44.526), train_loss = 0.64898482, grad/param norm = 1.5682e-01, time/batch = 14.6988s	
29611/33250 (epoch 44.528), train_loss = 0.71515239, grad/param norm = 1.9107e-01, time/batch = 14.4619s	
29612/33250 (epoch 44.529), train_loss = 0.69399151, grad/param norm = 2.3910e-01, time/batch = 14.6439s	
29613/33250 (epoch 44.531), train_loss = 0.65404921, grad/param norm = 1.5668e-01, time/batch = 14.6325s	
29614/33250 (epoch 44.532), train_loss = 0.77889074, grad/param norm = 1.7753e-01, time/batch = 14.4794s	
29615/33250 (epoch 44.534), train_loss = 0.67743447, grad/param norm = 1.6016e-01, time/batch = 14.6890s	
29616/33250 (epoch 44.535), train_loss = 0.71698673, grad/param norm = 1.6398e-01, time/batch = 14.7730s	
29617/33250 (epoch 44.537), train_loss = 0.75336074, grad/param norm = 1.6298e-01, time/batch = 14.5345s	
29618/33250 (epoch 44.538), train_loss = 0.78453325, grad/param norm = 1.8405e-01, time/batch = 15.1561s	
29619/33250 (epoch 44.540), train_loss = 0.86799703, grad/param norm = 1.7022e-01, time/batch = 14.3818s	
29620/33250 (epoch 44.541), train_loss = 0.79285916, grad/param norm = 2.0169e-01, time/batch = 14.4602s	
29621/33250 (epoch 44.543), train_loss = 0.79035932, grad/param norm = 1.5938e-01, time/batch = 14.6143s	
29622/33250 (epoch 44.544), train_loss = 0.66267386, grad/param norm = 1.8778e-01, time/batch = 15.0149s	
29623/33250 (epoch 44.546), train_loss = 0.67751173, grad/param norm = 1.8509e-01, time/batch = 14.9948s	
29624/33250 (epoch 44.547), train_loss = 0.71740123, grad/param norm = 2.0421e-01, time/batch = 14.9905s	
29625/33250 (epoch 44.549), train_loss = 0.75952458, grad/param norm = 1.9494e-01, time/batch = 14.5720s	
29626/33250 (epoch 44.550), train_loss = 0.71213645, grad/param norm = 1.7600e-01, time/batch = 14.8766s	
29627/33250 (epoch 44.552), train_loss = 0.78559741, grad/param norm = 1.7218e-01, time/batch = 14.6178s	
29628/33250 (epoch 44.553), train_loss = 0.74037412, grad/param norm = 1.6461e-01, time/batch = 14.4653s	
29629/33250 (epoch 44.555), train_loss = 0.72473164, grad/param norm = 1.6265e-01, time/batch = 14.5414s	
29630/33250 (epoch 44.556), train_loss = 0.76664195, grad/param norm = 2.0996e-01, time/batch = 15.0009s	
29631/33250 (epoch 44.558), train_loss = 0.78697101, grad/param norm = 1.9333e-01, time/batch = 15.1688s	
29632/33250 (epoch 44.559), train_loss = 0.69025379, grad/param norm = 1.8174e-01, time/batch = 14.5451s	
29633/33250 (epoch 44.561), train_loss = 0.63965186, grad/param norm = 2.0114e-01, time/batch = 14.5331s	
29634/33250 (epoch 44.562), train_loss = 0.73716290, grad/param norm = 2.0103e-01, time/batch = 15.0299s	
29635/33250 (epoch 44.564), train_loss = 0.88329357, grad/param norm = 2.0549e-01, time/batch = 14.6248s	
29636/33250 (epoch 44.565), train_loss = 0.84291207, grad/param norm = 2.1535e-01, time/batch = 14.7144s	
29637/33250 (epoch 44.567), train_loss = 0.85105023, grad/param norm = 2.0902e-01, time/batch = 14.4085s	
29638/33250 (epoch 44.568), train_loss = 0.70609049, grad/param norm = 1.9474e-01, time/batch = 15.0146s	
29639/33250 (epoch 44.570), train_loss = 0.80263495, grad/param norm = 1.8979e-01, time/batch = 14.4561s	
29640/33250 (epoch 44.571), train_loss = 0.84162527, grad/param norm = 1.8724e-01, time/batch = 14.7596s	
29641/33250 (epoch 44.573), train_loss = 0.79450605, grad/param norm = 1.8644e-01, time/batch = 14.3881s	
29642/33250 (epoch 44.574), train_loss = 0.66062882, grad/param norm = 1.4060e-01, time/batch = 14.8511s	
29643/33250 (epoch 44.576), train_loss = 0.75019470, grad/param norm = 1.5981e-01, time/batch = 14.4588s	
29644/33250 (epoch 44.577), train_loss = 0.72990060, grad/param norm = 1.6083e-01, time/batch = 14.3822s	
29645/33250 (epoch 44.579), train_loss = 0.63702144, grad/param norm = 1.5826e-01, time/batch = 14.3006s	
29646/33250 (epoch 44.580), train_loss = 0.74319770, grad/param norm = 1.8092e-01, time/batch = 14.4673s	
29647/33250 (epoch 44.582), train_loss = 0.69560638, grad/param norm = 1.6649e-01, time/batch = 15.0134s	
29648/33250 (epoch 44.583), train_loss = 0.81904021, grad/param norm = 1.7679e-01, time/batch = 14.3216s	
29649/33250 (epoch 44.585), train_loss = 0.83975921, grad/param norm = 1.7745e-01, time/batch = 14.3076s	
29650/33250 (epoch 44.586), train_loss = 0.68847481, grad/param norm = 2.0832e-01, time/batch = 14.4560s	
29651/33250 (epoch 44.588), train_loss = 0.78404550, grad/param norm = 1.7252e-01, time/batch = 14.6034s	
29652/33250 (epoch 44.589), train_loss = 0.75394248, grad/param norm = 2.7351e-01, time/batch = 14.3614s	
29653/33250 (epoch 44.591), train_loss = 0.73425124, grad/param norm = 2.6770e-01, time/batch = 14.2875s	
29654/33250 (epoch 44.592), train_loss = 0.72888037, grad/param norm = 1.8026e-01, time/batch = 15.0005s	
29655/33250 (epoch 44.594), train_loss = 0.84980785, grad/param norm = 2.3163e-01, time/batch = 14.6323s	
29656/33250 (epoch 44.595), train_loss = 0.74781375, grad/param norm = 1.9583e-01, time/batch = 14.6230s	
29657/33250 (epoch 44.597), train_loss = 0.62561607, grad/param norm = 1.4323e-01, time/batch = 14.6967s	
29658/33250 (epoch 44.598), train_loss = 0.70751081, grad/param norm = 1.8910e-01, time/batch = 14.7283s	
29659/33250 (epoch 44.600), train_loss = 0.71448353, grad/param norm = 1.9664e-01, time/batch = 14.7769s	
29660/33250 (epoch 44.602), train_loss = 0.74505871, grad/param norm = 1.9106e-01, time/batch = 15.7270s	
29661/33250 (epoch 44.603), train_loss = 0.79129929, grad/param norm = 2.2734e-01, time/batch = 15.3712s	
29662/33250 (epoch 44.605), train_loss = 0.75502348, grad/param norm = 1.8954e-01, time/batch = 15.0263s	
29663/33250 (epoch 44.606), train_loss = 0.79351886, grad/param norm = 1.8644e-01, time/batch = 14.9459s	
29664/33250 (epoch 44.608), train_loss = 0.75014207, grad/param norm = 1.6701e-01, time/batch = 14.6267s	
29665/33250 (epoch 44.609), train_loss = 0.65387492, grad/param norm = 1.7184e-01, time/batch = 14.3798s	
29666/33250 (epoch 44.611), train_loss = 0.73094208, grad/param norm = 1.9785e-01, time/batch = 14.8544s	
29667/33250 (epoch 44.612), train_loss = 0.74536130, grad/param norm = 2.1453e-01, time/batch = 14.5439s	
29668/33250 (epoch 44.614), train_loss = 0.93983678, grad/param norm = 2.1894e-01, time/batch = 14.7123s	
29669/33250 (epoch 44.615), train_loss = 0.84555464, grad/param norm = 1.6963e-01, time/batch = 14.7380s	
29670/33250 (epoch 44.617), train_loss = 0.93834750, grad/param norm = 2.1971e-01, time/batch = 14.6338s	
29671/33250 (epoch 44.618), train_loss = 0.94646640, grad/param norm = 2.7853e-01, time/batch = 14.7852s	
29672/33250 (epoch 44.620), train_loss = 0.80535769, grad/param norm = 2.2887e-01, time/batch = 15.1624s	
29673/33250 (epoch 44.621), train_loss = 0.82985004, grad/param norm = 2.0152e-01, time/batch = 14.9384s	
29674/33250 (epoch 44.623), train_loss = 0.73003979, grad/param norm = 1.9212e-01, time/batch = 14.6072s	
29675/33250 (epoch 44.624), train_loss = 0.72501902, grad/param norm = 2.2788e-01, time/batch = 15.0955s	
29676/33250 (epoch 44.626), train_loss = 0.76361941, grad/param norm = 2.3575e-01, time/batch = 14.7015s	
29677/33250 (epoch 44.627), train_loss = 0.70494222, grad/param norm = 1.7099e-01, time/batch = 14.7032s	
29678/33250 (epoch 44.629), train_loss = 0.80139042, grad/param norm = 2.1421e-01, time/batch = 14.7663s	
29679/33250 (epoch 44.630), train_loss = 0.71980926, grad/param norm = 2.0837e-01, time/batch = 14.6349s	
29680/33250 (epoch 44.632), train_loss = 0.66371972, grad/param norm = 1.8173e-01, time/batch = 14.4686s	
29681/33250 (epoch 44.633), train_loss = 0.77417069, grad/param norm = 1.9458e-01, time/batch = 15.0521s	
29682/33250 (epoch 44.635), train_loss = 0.67349917, grad/param norm = 1.7121e-01, time/batch = 18.7886s	
29683/33250 (epoch 44.636), train_loss = 0.71153240, grad/param norm = 1.7336e-01, time/batch = 24.1561s	
29684/33250 (epoch 44.638), train_loss = 0.66778087, grad/param norm = 1.9021e-01, time/batch = 14.7707s	
29685/33250 (epoch 44.639), train_loss = 0.65150859, grad/param norm = 2.1126e-01, time/batch = 14.9283s	
29686/33250 (epoch 44.641), train_loss = 0.73835697, grad/param norm = 1.9322e-01, time/batch = 14.6142s	
29687/33250 (epoch 44.642), train_loss = 0.58226160, grad/param norm = 2.3591e-01, time/batch = 14.5461s	
29688/33250 (epoch 44.644), train_loss = 0.51893459, grad/param norm = 1.4622e-01, time/batch = 14.6225s	
29689/33250 (epoch 44.645), train_loss = 0.76797846, grad/param norm = 2.1067e-01, time/batch = 14.7814s	
29690/33250 (epoch 44.647), train_loss = 0.63386646, grad/param norm = 1.9640e-01, time/batch = 14.8775s	
29691/33250 (epoch 44.648), train_loss = 0.61471545, grad/param norm = 1.7125e-01, time/batch = 15.2491s	
29692/33250 (epoch 44.650), train_loss = 0.86061496, grad/param norm = 2.5911e-01, time/batch = 14.4080s	
29693/33250 (epoch 44.651), train_loss = 0.77575673, grad/param norm = 1.9343e-01, time/batch = 14.4022s	
29694/33250 (epoch 44.653), train_loss = 0.70146062, grad/param norm = 1.7112e-01, time/batch = 14.7089s	
29695/33250 (epoch 44.654), train_loss = 0.74760232, grad/param norm = 1.7065e-01, time/batch = 14.7840s	
29696/33250 (epoch 44.656), train_loss = 0.81222762, grad/param norm = 1.7323e-01, time/batch = 14.5448s	
29697/33250 (epoch 44.657), train_loss = 0.57646003, grad/param norm = 2.0874e-01, time/batch = 14.7788s	
29698/33250 (epoch 44.659), train_loss = 0.70817505, grad/param norm = 2.0557e-01, time/batch = 15.0134s	
29699/33250 (epoch 44.660), train_loss = 0.76039107, grad/param norm = 1.9269e-01, time/batch = 14.0725s	
29700/33250 (epoch 44.662), train_loss = 0.73792667, grad/param norm = 1.6464e-01, time/batch = 14.1316s	
29701/33250 (epoch 44.663), train_loss = 0.66247404, grad/param norm = 1.6806e-01, time/batch = 14.8868s	
29702/33250 (epoch 44.665), train_loss = 0.79024685, grad/param norm = 2.1892e-01, time/batch = 15.0117s	
29703/33250 (epoch 44.666), train_loss = 0.71400262, grad/param norm = 1.6033e-01, time/batch = 14.4052s	
29704/33250 (epoch 44.668), train_loss = 0.82840217, grad/param norm = 2.0186e-01, time/batch = 14.7830s	
29705/33250 (epoch 44.669), train_loss = 0.77007965, grad/param norm = 2.1423e-01, time/batch = 14.6563s	
29706/33250 (epoch 44.671), train_loss = 0.64710518, grad/param norm = 1.8570e-01, time/batch = 15.0813s	
29707/33250 (epoch 44.672), train_loss = 0.81352288, grad/param norm = 1.8581e-01, time/batch = 14.9238s	
29708/33250 (epoch 44.674), train_loss = 0.68864851, grad/param norm = 1.7538e-01, time/batch = 14.6758s	
29709/33250 (epoch 44.675), train_loss = 0.75450690, grad/param norm = 1.5375e-01, time/batch = 14.6199s	
29710/33250 (epoch 44.677), train_loss = 0.79594999, grad/param norm = 1.9308e-01, time/batch = 14.7719s	
29711/33250 (epoch 44.678), train_loss = 0.67751092, grad/param norm = 2.0654e-01, time/batch = 14.6292s	
29712/33250 (epoch 44.680), train_loss = 0.85079741, grad/param norm = 2.0799e-01, time/batch = 14.9698s	
29713/33250 (epoch 44.681), train_loss = 0.67542467, grad/param norm = 1.6081e-01, time/batch = 14.9751s	
29714/33250 (epoch 44.683), train_loss = 0.67878018, grad/param norm = 2.0204e-01, time/batch = 15.0414s	
29715/33250 (epoch 44.684), train_loss = 0.63387895, grad/param norm = 1.9254e-01, time/batch = 17.2063s	
29716/33250 (epoch 44.686), train_loss = 0.64461908, grad/param norm = 1.7151e-01, time/batch = 14.8901s	
29717/33250 (epoch 44.687), train_loss = 0.74403572, grad/param norm = 1.7382e-01, time/batch = 14.6181s	
29718/33250 (epoch 44.689), train_loss = 0.63067108, grad/param norm = 1.7646e-01, time/batch = 14.8484s	
29719/33250 (epoch 44.690), train_loss = 0.76401200, grad/param norm = 1.8530e-01, time/batch = 14.3753s	
29720/33250 (epoch 44.692), train_loss = 0.72100052, grad/param norm = 1.8143e-01, time/batch = 14.5449s	
29721/33250 (epoch 44.693), train_loss = 0.78343287, grad/param norm = 1.9310e-01, time/batch = 14.3841s	
29722/33250 (epoch 44.695), train_loss = 0.75954432, grad/param norm = 1.9161e-01, time/batch = 14.9478s	
29723/33250 (epoch 44.696), train_loss = 0.77848405, grad/param norm = 1.7963e-01, time/batch = 14.8838s	
29724/33250 (epoch 44.698), train_loss = 0.70152227, grad/param norm = 1.7508e-01, time/batch = 14.9814s	
29725/33250 (epoch 44.699), train_loss = 0.94486304, grad/param norm = 1.9006e-01, time/batch = 15.5677s	
29726/33250 (epoch 44.701), train_loss = 0.75101885, grad/param norm = 1.6605e-01, time/batch = 15.5971s	
29727/33250 (epoch 44.702), train_loss = 0.72027562, grad/param norm = 2.8751e-01, time/batch = 14.6570s	
29728/33250 (epoch 44.704), train_loss = 0.91308547, grad/param norm = 2.5742e-01, time/batch = 14.3670s	
29729/33250 (epoch 44.705), train_loss = 0.68872541, grad/param norm = 1.5532e-01, time/batch = 14.6818s	
29730/33250 (epoch 44.707), train_loss = 0.63385783, grad/param norm = 1.6016e-01, time/batch = 14.7124s	
29731/33250 (epoch 44.708), train_loss = 0.83250142, grad/param norm = 2.0051e-01, time/batch = 14.6148s	
29732/33250 (epoch 44.710), train_loss = 0.78008210, grad/param norm = 2.6238e-01, time/batch = 14.3051s	
29733/33250 (epoch 44.711), train_loss = 0.65108456, grad/param norm = 1.7648e-01, time/batch = 14.6891s	
29734/33250 (epoch 44.713), train_loss = 0.77048874, grad/param norm = 1.7368e-01, time/batch = 14.3600s	
29735/33250 (epoch 44.714), train_loss = 0.71800988, grad/param norm = 1.8456e-01, time/batch = 14.6561s	
29736/33250 (epoch 44.716), train_loss = 0.75641115, grad/param norm = 1.6597e-01, time/batch = 14.2398s	
29737/33250 (epoch 44.717), train_loss = 0.72625765, grad/param norm = 1.6671e-01, time/batch = 14.9731s	
29738/33250 (epoch 44.719), train_loss = 0.66782369, grad/param norm = 1.6724e-01, time/batch = 14.5658s	
29739/33250 (epoch 44.720), train_loss = 0.96202062, grad/param norm = 1.8314e-01, time/batch = 14.3003s	
29740/33250 (epoch 44.722), train_loss = 0.65022936, grad/param norm = 1.5373e-01, time/batch = 14.2230s	
29741/33250 (epoch 44.723), train_loss = 0.58005698, grad/param norm = 1.3527e-01, time/batch = 14.5454s	
29742/33250 (epoch 44.725), train_loss = 0.73580260, grad/param norm = 1.6133e-01, time/batch = 14.6904s	
29743/33250 (epoch 44.726), train_loss = 0.75747014, grad/param norm = 1.7662e-01, time/batch = 14.5426s	
29744/33250 (epoch 44.728), train_loss = 0.77090531, grad/param norm = 1.7765e-01, time/batch = 15.1232s	
29745/33250 (epoch 44.729), train_loss = 0.79649053, grad/param norm = 1.9449e-01, time/batch = 14.6182s	
29746/33250 (epoch 44.731), train_loss = 0.67512213, grad/param norm = 2.2644e-01, time/batch = 14.7914s	
29747/33250 (epoch 44.732), train_loss = 0.67722302, grad/param norm = 1.7634e-01, time/batch = 15.8912s	
29748/33250 (epoch 44.734), train_loss = 0.77328436, grad/param norm = 2.7281e-01, time/batch = 14.9123s	
29749/33250 (epoch 44.735), train_loss = 0.75856168, grad/param norm = 1.9604e-01, time/batch = 14.6156s	
29750/33250 (epoch 44.737), train_loss = 0.72110713, grad/param norm = 1.6013e-01, time/batch = 14.8718s	
29751/33250 (epoch 44.738), train_loss = 0.78906106, grad/param norm = 1.7762e-01, time/batch = 14.8550s	
29752/33250 (epoch 44.740), train_loss = 0.74734079, grad/param norm = 1.7448e-01, time/batch = 14.5418s	
29753/33250 (epoch 44.741), train_loss = 0.79778783, grad/param norm = 1.6631e-01, time/batch = 14.9252s	
29754/33250 (epoch 44.743), train_loss = 0.70578239, grad/param norm = 1.7295e-01, time/batch = 14.8645s	
29755/33250 (epoch 44.744), train_loss = 0.69124236, grad/param norm = 1.8023e-01, time/batch = 14.3863s	
29756/33250 (epoch 44.746), train_loss = 0.68329566, grad/param norm = 2.0086e-01, time/batch = 14.4617s	
29757/33250 (epoch 44.747), train_loss = 0.66224777, grad/param norm = 1.6538e-01, time/batch = 14.6878s	
29758/33250 (epoch 44.749), train_loss = 0.85083132, grad/param norm = 1.9913e-01, time/batch = 14.5377s	
29759/33250 (epoch 44.750), train_loss = 0.84941683, grad/param norm = 1.8626e-01, time/batch = 14.9669s	
29760/33250 (epoch 44.752), train_loss = 0.71116542, grad/param norm = 1.7840e-01, time/batch = 14.2448s	
29761/33250 (epoch 44.753), train_loss = 0.70406794, grad/param norm = 1.9141e-01, time/batch = 16.0658s	
29762/33250 (epoch 44.755), train_loss = 0.61683541, grad/param norm = 1.8502e-01, time/batch = 15.1990s	
29763/33250 (epoch 44.756), train_loss = 0.75656746, grad/param norm = 1.9198e-01, time/batch = 14.7894s	
29764/33250 (epoch 44.758), train_loss = 0.87477000, grad/param norm = 1.7110e-01, time/batch = 14.4653s	
29765/33250 (epoch 44.759), train_loss = 0.70769467, grad/param norm = 1.7000e-01, time/batch = 14.4570s	
29766/33250 (epoch 44.761), train_loss = 0.77927428, grad/param norm = 2.1043e-01, time/batch = 14.5333s	
29767/33250 (epoch 44.762), train_loss = 0.80232034, grad/param norm = 1.8031e-01, time/batch = 14.6961s	
29768/33250 (epoch 44.764), train_loss = 0.65044050, grad/param norm = 2.1647e-01, time/batch = 14.3861s	
29769/33250 (epoch 44.765), train_loss = 0.75845242, grad/param norm = 1.9510e-01, time/batch = 14.6197s	
29770/33250 (epoch 44.767), train_loss = 0.59313007, grad/param norm = 1.7134e-01, time/batch = 14.7112s	
29771/33250 (epoch 44.768), train_loss = 0.62429851, grad/param norm = 1.7023e-01, time/batch = 14.5649s	
29772/33250 (epoch 44.770), train_loss = 0.77567543, grad/param norm = 2.0946e-01, time/batch = 14.7970s	
29773/33250 (epoch 44.771), train_loss = 0.80981419, grad/param norm = 1.9898e-01, time/batch = 15.4022s	
29774/33250 (epoch 44.773), train_loss = 0.73493655, grad/param norm = 1.8989e-01, time/batch = 14.6128s	
29775/33250 (epoch 44.774), train_loss = 0.60474159, grad/param norm = 1.8182e-01, time/batch = 14.5466s	
29776/33250 (epoch 44.776), train_loss = 0.70567423, grad/param norm = 1.6577e-01, time/batch = 14.3105s	
29777/33250 (epoch 44.777), train_loss = 0.83047340, grad/param norm = 1.9995e-01, time/batch = 14.5942s	
29778/33250 (epoch 44.779), train_loss = 0.71687187, grad/param norm = 2.1117e-01, time/batch = 14.2921s	
29779/33250 (epoch 44.780), train_loss = 0.86294893, grad/param norm = 2.2667e-01, time/batch = 14.8356s	
29780/33250 (epoch 44.782), train_loss = 0.74187130, grad/param norm = 2.1159e-01, time/batch = 14.2977s	
29781/33250 (epoch 44.783), train_loss = 0.59903352, grad/param norm = 1.6622e-01, time/batch = 14.4848s	
29782/33250 (epoch 44.785), train_loss = 0.65750379, grad/param norm = 1.6688e-01, time/batch = 14.4112s	
29783/33250 (epoch 44.786), train_loss = 0.81216613, grad/param norm = 1.8120e-01, time/batch = 14.8723s	
29784/33250 (epoch 44.788), train_loss = 0.84957577, grad/param norm = 1.7711e-01, time/batch = 14.9824s	
29785/33250 (epoch 44.789), train_loss = 0.86027035, grad/param norm = 2.3584e-01, time/batch = 15.3027s	
29786/33250 (epoch 44.791), train_loss = 0.84469017, grad/param norm = 1.8388e-01, time/batch = 14.7994s	
29787/33250 (epoch 44.792), train_loss = 0.93079933, grad/param norm = 1.9215e-01, time/batch = 14.7820s	
29788/33250 (epoch 44.794), train_loss = 0.71221388, grad/param norm = 1.6702e-01, time/batch = 15.2716s	
29789/33250 (epoch 44.795), train_loss = 0.72669677, grad/param norm = 1.8821e-01, time/batch = 15.0902s	
29790/33250 (epoch 44.797), train_loss = 0.78871020, grad/param norm = 1.8262e-01, time/batch = 14.3024s	
29791/33250 (epoch 44.798), train_loss = 0.70557708, grad/param norm = 1.9380e-01, time/batch = 14.7911s	
29792/33250 (epoch 44.800), train_loss = 0.76903537, grad/param norm = 1.8964e-01, time/batch = 15.1677s	
29793/33250 (epoch 44.802), train_loss = 0.75267904, grad/param norm = 1.7539e-01, time/batch = 15.3114s	
29794/33250 (epoch 44.803), train_loss = 0.78846436, grad/param norm = 1.6285e-01, time/batch = 14.5673s	
29795/33250 (epoch 44.805), train_loss = 0.78694272, grad/param norm = 1.9252e-01, time/batch = 15.1202s	
29796/33250 (epoch 44.806), train_loss = 0.75095235, grad/param norm = 1.7243e-01, time/batch = 14.6198s	
29797/33250 (epoch 44.808), train_loss = 0.67348183, grad/param norm = 1.7074e-01, time/batch = 14.2308s	
29798/33250 (epoch 44.809), train_loss = 0.66157917, grad/param norm = 1.4716e-01, time/batch = 14.0541s	
29799/33250 (epoch 44.811), train_loss = 0.65112252, grad/param norm = 1.8067e-01, time/batch = 14.9244s	
29800/33250 (epoch 44.812), train_loss = 0.76041598, grad/param norm = 1.8949e-01, time/batch = 14.4378s	
29801/33250 (epoch 44.814), train_loss = 0.70856764, grad/param norm = 2.4185e-01, time/batch = 14.4682s	
29802/33250 (epoch 44.815), train_loss = 0.77472461, grad/param norm = 1.8904e-01, time/batch = 14.3065s	
29803/33250 (epoch 44.817), train_loss = 0.71935985, grad/param norm = 1.9373e-01, time/batch = 15.0788s	
29804/33250 (epoch 44.818), train_loss = 0.67766881, grad/param norm = 1.6582e-01, time/batch = 14.4702s	
29805/33250 (epoch 44.820), train_loss = 0.78760288, grad/param norm = 1.9187e-01, time/batch = 14.7268s	
29806/33250 (epoch 44.821), train_loss = 0.74924871, grad/param norm = 1.9285e-01, time/batch = 14.8622s	
29807/33250 (epoch 44.823), train_loss = 0.99206051, grad/param norm = 2.1140e-01, time/batch = 14.7303s	
29808/33250 (epoch 44.824), train_loss = 0.68456991, grad/param norm = 1.7664e-01, time/batch = 14.3104s	
29809/33250 (epoch 44.826), train_loss = 0.76212675, grad/param norm = 2.0030e-01, time/batch = 14.3821s	
29810/33250 (epoch 44.827), train_loss = 0.69016440, grad/param norm = 1.7847e-01, time/batch = 14.3778s	
29811/33250 (epoch 44.829), train_loss = 0.76875289, grad/param norm = 2.0365e-01, time/batch = 14.7891s	
29812/33250 (epoch 44.830), train_loss = 0.79717136, grad/param norm = 2.2682e-01, time/batch = 14.6288s	
29813/33250 (epoch 44.832), train_loss = 0.76623525, grad/param norm = 1.8968e-01, time/batch = 14.8327s	
29814/33250 (epoch 44.833), train_loss = 0.73868628, grad/param norm = 1.6936e-01, time/batch = 14.5338s	
29815/33250 (epoch 44.835), train_loss = 0.65756515, grad/param norm = 2.2331e-01, time/batch = 14.5420s	
29816/33250 (epoch 44.836), train_loss = 0.74079066, grad/param norm = 2.3656e-01, time/batch = 14.8002s	
29817/33250 (epoch 44.838), train_loss = 0.76203700, grad/param norm = 1.7865e-01, time/batch = 14.3933s	
29818/33250 (epoch 44.839), train_loss = 0.72868901, grad/param norm = 1.8007e-01, time/batch = 14.2369s	
29819/33250 (epoch 44.841), train_loss = 0.71608681, grad/param norm = 1.7612e-01, time/batch = 14.8632s	
29820/33250 (epoch 44.842), train_loss = 0.87589922, grad/param norm = 1.9804e-01, time/batch = 14.4731s	
29821/33250 (epoch 44.844), train_loss = 0.81192956, grad/param norm = 2.0207e-01, time/batch = 14.2147s	
29822/33250 (epoch 44.845), train_loss = 0.89747450, grad/param norm = 2.0443e-01, time/batch = 14.1428s	
29823/33250 (epoch 44.847), train_loss = 0.84627226, grad/param norm = 1.8098e-01, time/batch = 14.5290s	
29824/33250 (epoch 44.848), train_loss = 0.93416684, grad/param norm = 2.3752e-01, time/batch = 14.4550s	
29825/33250 (epoch 44.850), train_loss = 0.83597090, grad/param norm = 1.7915e-01, time/batch = 14.5273s	
29826/33250 (epoch 44.851), train_loss = 0.63598470, grad/param norm = 1.8266e-01, time/batch = 14.5239s	
29827/33250 (epoch 44.853), train_loss = 0.75877303, grad/param norm = 2.1256e-01, time/batch = 14.4688s	
29828/33250 (epoch 44.854), train_loss = 0.68984209, grad/param norm = 1.4999e-01, time/batch = 14.5540s	
29829/33250 (epoch 44.856), train_loss = 0.69427639, grad/param norm = 2.3773e-01, time/batch = 14.3869s	
29830/33250 (epoch 44.857), train_loss = 0.63598955, grad/param norm = 1.8495e-01, time/batch = 14.6383s	
29831/33250 (epoch 44.859), train_loss = 0.71901198, grad/param norm = 2.3128e-01, time/batch = 14.6299s	
29832/33250 (epoch 44.860), train_loss = 0.78326943, grad/param norm = 1.7684e-01, time/batch = 15.4094s	
29833/33250 (epoch 44.862), train_loss = 0.69677070, grad/param norm = 1.8295e-01, time/batch = 15.2341s	
29834/33250 (epoch 44.863), train_loss = 0.70821107, grad/param norm = 1.9948e-01, time/batch = 15.2479s	
29835/33250 (epoch 44.865), train_loss = 0.74172852, grad/param norm = 1.7838e-01, time/batch = 15.2590s	
29836/33250 (epoch 44.866), train_loss = 0.67128234, grad/param norm = 1.7838e-01, time/batch = 15.0871s	
29837/33250 (epoch 44.868), train_loss = 0.74387978, grad/param norm = 2.2845e-01, time/batch = 14.5158s	
29838/33250 (epoch 44.869), train_loss = 0.75754465, grad/param norm = 1.8243e-01, time/batch = 14.4357s	
29839/33250 (epoch 44.871), train_loss = 0.61425182, grad/param norm = 1.4972e-01, time/batch = 14.4719s	
29840/33250 (epoch 44.872), train_loss = 0.78928866, grad/param norm = 1.9887e-01, time/batch = 14.9592s	
29841/33250 (epoch 44.874), train_loss = 0.70518403, grad/param norm = 1.9263e-01, time/batch = 15.2373s	
29842/33250 (epoch 44.875), train_loss = 0.64644504, grad/param norm = 2.2629e-01, time/batch = 14.7782s	
29843/33250 (epoch 44.877), train_loss = 0.83356163, grad/param norm = 1.8566e-01, time/batch = 14.8578s	
29844/33250 (epoch 44.878), train_loss = 0.75948202, grad/param norm = 1.7308e-01, time/batch = 14.9361s	
29845/33250 (epoch 44.880), train_loss = 0.74302045, grad/param norm = 1.9612e-01, time/batch = 14.7933s	
29846/33250 (epoch 44.881), train_loss = 0.85689110, grad/param norm = 2.1714e-01, time/batch = 14.7879s	
29847/33250 (epoch 44.883), train_loss = 0.79809030, grad/param norm = 1.9909e-01, time/batch = 14.8616s	
29848/33250 (epoch 44.884), train_loss = 0.84661033, grad/param norm = 1.9069e-01, time/batch = 15.0909s	
29849/33250 (epoch 44.886), train_loss = 0.67712136, grad/param norm = 1.6241e-01, time/batch = 16.1325s	
29850/33250 (epoch 44.887), train_loss = 0.71906138, grad/param norm = 1.8008e-01, time/batch = 15.5632s	
29851/33250 (epoch 44.889), train_loss = 0.69662316, grad/param norm = 1.4938e-01, time/batch = 15.9659s	
29852/33250 (epoch 44.890), train_loss = 0.56658285, grad/param norm = 1.3224e-01, time/batch = 15.1746s	
29853/33250 (epoch 44.892), train_loss = 0.78536345, grad/param norm = 1.8009e-01, time/batch = 14.8661s	
29854/33250 (epoch 44.893), train_loss = 0.79902046, grad/param norm = 1.9537e-01, time/batch = 14.8690s	
29855/33250 (epoch 44.895), train_loss = 0.69362779, grad/param norm = 2.3162e-01, time/batch = 14.8544s	
29856/33250 (epoch 44.896), train_loss = 0.80878450, grad/param norm = 1.9147e-01, time/batch = 14.5462s	
29857/33250 (epoch 44.898), train_loss = 0.74537797, grad/param norm = 1.7818e-01, time/batch = 14.5483s	
29858/33250 (epoch 44.899), train_loss = 0.69934400, grad/param norm = 1.5788e-01, time/batch = 14.8014s	
29859/33250 (epoch 44.901), train_loss = 0.61350808, grad/param norm = 1.4341e-01, time/batch = 14.5423s	
29860/33250 (epoch 44.902), train_loss = 0.69817493, grad/param norm = 2.0474e-01, time/batch = 15.1965s	
29861/33250 (epoch 44.904), train_loss = 0.66752739, grad/param norm = 1.6184e-01, time/batch = 17.9524s	
29862/33250 (epoch 44.905), train_loss = 0.72637721, grad/param norm = 1.5989e-01, time/batch = 16.9658s	
29863/33250 (epoch 44.907), train_loss = 0.67693608, grad/param norm = 1.8180e-01, time/batch = 15.3610s	
29864/33250 (epoch 44.908), train_loss = 0.72950298, grad/param norm = 1.5686e-01, time/batch = 14.7030s	
29865/33250 (epoch 44.910), train_loss = 0.81670725, grad/param norm = 1.9299e-01, time/batch = 14.5523s	
29866/33250 (epoch 44.911), train_loss = 0.66163395, grad/param norm = 1.8043e-01, time/batch = 14.7879s	
29867/33250 (epoch 44.913), train_loss = 0.68639221, grad/param norm = 1.5307e-01, time/batch = 14.8787s	
29868/33250 (epoch 44.914), train_loss = 0.60734571, grad/param norm = 1.5422e-01, time/batch = 14.7936s	
29869/33250 (epoch 44.916), train_loss = 0.64585455, grad/param norm = 1.8574e-01, time/batch = 15.0311s	
29870/33250 (epoch 44.917), train_loss = 0.74749279, grad/param norm = 1.4221e-01, time/batch = 14.9710s	
29871/33250 (epoch 44.919), train_loss = 0.67128524, grad/param norm = 2.0883e-01, time/batch = 16.4547s	
29872/33250 (epoch 44.920), train_loss = 0.75331442, grad/param norm = 1.9794e-01, time/batch = 14.7304s	
29873/33250 (epoch 44.922), train_loss = 0.75050490, grad/param norm = 1.9362e-01, time/batch = 15.1013s	
29874/33250 (epoch 44.923), train_loss = 0.73243756, grad/param norm = 2.1269e-01, time/batch = 15.5664s	
29875/33250 (epoch 44.925), train_loss = 0.70458284, grad/param norm = 1.7076e-01, time/batch = 14.8770s	
29876/33250 (epoch 44.926), train_loss = 0.68830270, grad/param norm = 1.7222e-01, time/batch = 14.7161s	
29877/33250 (epoch 44.928), train_loss = 0.71482715, grad/param norm = 1.9844e-01, time/batch = 14.6272s	
29878/33250 (epoch 44.929), train_loss = 0.64343989, grad/param norm = 1.3251e-01, time/batch = 15.1124s	
29879/33250 (epoch 44.931), train_loss = 0.82752061, grad/param norm = 2.0365e-01, time/batch = 15.0178s	
29880/33250 (epoch 44.932), train_loss = 0.68055579, grad/param norm = 1.8733e-01, time/batch = 14.6265s	
29881/33250 (epoch 44.934), train_loss = 0.68427740, grad/param norm = 1.7915e-01, time/batch = 14.7143s	
29882/33250 (epoch 44.935), train_loss = 0.71055139, grad/param norm = 2.0495e-01, time/batch = 15.3053s	
29883/33250 (epoch 44.937), train_loss = 0.68505470, grad/param norm = 1.9416e-01, time/batch = 15.1307s	
29884/33250 (epoch 44.938), train_loss = 0.69690784, grad/param norm = 2.1557e-01, time/batch = 15.2781s	
29885/33250 (epoch 44.940), train_loss = 0.71503126, grad/param norm = 1.9723e-01, time/batch = 14.8784s	
29886/33250 (epoch 44.941), train_loss = 0.77607299, grad/param norm = 1.7480e-01, time/batch = 14.7937s	
29887/33250 (epoch 44.943), train_loss = 0.85305171, grad/param norm = 2.1146e-01, time/batch = 14.4597s	
29888/33250 (epoch 44.944), train_loss = 0.71210506, grad/param norm = 1.7396e-01, time/batch = 15.1291s	
29889/33250 (epoch 44.946), train_loss = 0.80342494, grad/param norm = 1.8570e-01, time/batch = 14.8739s	
29890/33250 (epoch 44.947), train_loss = 0.66554356, grad/param norm = 2.0998e-01, time/batch = 14.8726s	
29891/33250 (epoch 44.949), train_loss = 0.81470762, grad/param norm = 2.4063e-01, time/batch = 15.0240s	
29892/33250 (epoch 44.950), train_loss = 0.81667816, grad/param norm = 1.9537e-01, time/batch = 14.4650s	
29893/33250 (epoch 44.952), train_loss = 0.72836345, grad/param norm = 2.0585e-01, time/batch = 15.4517s	
29894/33250 (epoch 44.953), train_loss = 0.75938770, grad/param norm = 2.3583e-01, time/batch = 15.9807s	
29895/33250 (epoch 44.955), train_loss = 0.79692810, grad/param norm = 1.7928e-01, time/batch = 14.7963s	
29896/33250 (epoch 44.956), train_loss = 0.74666015, grad/param norm = 2.4245e-01, time/batch = 14.8897s	
29897/33250 (epoch 44.958), train_loss = 0.71428559, grad/param norm = 1.6967e-01, time/batch = 15.8038s	
29898/33250 (epoch 44.959), train_loss = 0.70843162, grad/param norm = 1.7378e-01, time/batch = 14.5541s	
29899/33250 (epoch 44.961), train_loss = 0.91614770, grad/param norm = 1.9369e-01, time/batch = 14.7652s	
29900/33250 (epoch 44.962), train_loss = 0.73795860, grad/param norm = 2.0902e-01, time/batch = 14.2313s	
29901/33250 (epoch 44.964), train_loss = 0.85599086, grad/param norm = 1.9591e-01, time/batch = 14.6265s	
29902/33250 (epoch 44.965), train_loss = 0.79263831, grad/param norm = 1.8094e-01, time/batch = 14.3866s	
29903/33250 (epoch 44.967), train_loss = 0.73240947, grad/param norm = 2.2959e-01, time/batch = 14.9337s	
29904/33250 (epoch 44.968), train_loss = 0.84828922, grad/param norm = 1.8383e-01, time/batch = 15.1082s	
29905/33250 (epoch 44.970), train_loss = 0.95014966, grad/param norm = 2.4412e-01, time/batch = 15.2365s	
29906/33250 (epoch 44.971), train_loss = 0.91412999, grad/param norm = 3.0769e-01, time/batch = 15.7927s	
29907/33250 (epoch 44.973), train_loss = 0.72237477, grad/param norm = 1.7765e-01, time/batch = 14.5557s	
29908/33250 (epoch 44.974), train_loss = 0.81230187, grad/param norm = 2.0378e-01, time/batch = 14.5763s	
29909/33250 (epoch 44.976), train_loss = 0.72894227, grad/param norm = 1.8632e-01, time/batch = 14.3065s	
29910/33250 (epoch 44.977), train_loss = 0.74652751, grad/param norm = 1.8472e-01, time/batch = 14.1418s	
29911/33250 (epoch 44.979), train_loss = 0.81116656, grad/param norm = 1.9966e-01, time/batch = 14.4667s	
29912/33250 (epoch 44.980), train_loss = 0.79471863, grad/param norm = 1.8773e-01, time/batch = 14.2135s	
29913/33250 (epoch 44.982), train_loss = 0.73287211, grad/param norm = 1.7586e-01, time/batch = 14.9229s	
29914/33250 (epoch 44.983), train_loss = 0.79273916, grad/param norm = 2.3449e-01, time/batch = 15.1726s	
29915/33250 (epoch 44.985), train_loss = 0.71674928, grad/param norm = 1.9692e-01, time/batch = 15.0222s	
29916/33250 (epoch 44.986), train_loss = 0.82845660, grad/param norm = 1.8976e-01, time/batch = 16.3963s	
29917/33250 (epoch 44.988), train_loss = 0.84141407, grad/param norm = 1.8605e-01, time/batch = 15.8130s	
29918/33250 (epoch 44.989), train_loss = 0.83067722, grad/param norm = 1.9338e-01, time/batch = 17.3922s	
29919/33250 (epoch 44.991), train_loss = 0.82106061, grad/param norm = 1.9931e-01, time/batch = 14.7241s	
29920/33250 (epoch 44.992), train_loss = 0.73065438, grad/param norm = 1.7539e-01, time/batch = 14.7723s	
29921/33250 (epoch 44.994), train_loss = 0.69065005, grad/param norm = 1.7201e-01, time/batch = 14.6279s	
29922/33250 (epoch 44.995), train_loss = 0.73859281, grad/param norm = 3.0552e-01, time/batch = 14.5572s	
29923/33250 (epoch 44.997), train_loss = 0.58687413, grad/param norm = 1.5670e-01, time/batch = 11.7712s	
29924/33250 (epoch 44.998), train_loss = 0.78553125, grad/param norm = 1.8819e-01, time/batch = 0.6970s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
29925/33250 (epoch 45.000), train_loss = 0.80060593, grad/param norm = 1.9696e-01, time/batch = 0.6671s	
29926/33250 (epoch 45.002), train_loss = 0.98147464, grad/param norm = 2.1276e-01, time/batch = 0.6739s	
29927/33250 (epoch 45.003), train_loss = 0.80349423, grad/param norm = 2.0585e-01, time/batch = 0.6727s	
29928/33250 (epoch 45.005), train_loss = 0.63183042, grad/param norm = 1.6136e-01, time/batch = 0.6694s	
29929/33250 (epoch 45.006), train_loss = 0.63772519, grad/param norm = 1.8416e-01, time/batch = 0.6633s	
29930/33250 (epoch 45.008), train_loss = 0.83979719, grad/param norm = 2.3854e-01, time/batch = 0.8801s	
29931/33250 (epoch 45.009), train_loss = 0.91663279, grad/param norm = 2.0411e-01, time/batch = 0.9811s	
29932/33250 (epoch 45.011), train_loss = 0.70289706, grad/param norm = 1.8941e-01, time/batch = 0.9951s	
29933/33250 (epoch 45.012), train_loss = 0.73916800, grad/param norm = 2.3867e-01, time/batch = 1.0260s	
29934/33250 (epoch 45.014), train_loss = 0.83037195, grad/param norm = 2.0970e-01, time/batch = 0.9922s	
29935/33250 (epoch 45.015), train_loss = 0.76894206, grad/param norm = 1.7644e-01, time/batch = 1.6080s	
29936/33250 (epoch 45.017), train_loss = 0.75829583, grad/param norm = 2.3488e-01, time/batch = 1.8320s	
29937/33250 (epoch 45.018), train_loss = 0.61487537, grad/param norm = 1.8604e-01, time/batch = 1.8138s	
29938/33250 (epoch 45.020), train_loss = 0.76989179, grad/param norm = 1.7871e-01, time/batch = 14.3964s	
29939/33250 (epoch 45.021), train_loss = 0.77465007, grad/param norm = 1.7428e-01, time/batch = 14.3004s	
29940/33250 (epoch 45.023), train_loss = 0.62737385, grad/param norm = 1.9669e-01, time/batch = 15.0438s	
29941/33250 (epoch 45.024), train_loss = 0.82893898, grad/param norm = 1.9653e-01, time/batch = 18.4684s	
29942/33250 (epoch 45.026), train_loss = 0.80260533, grad/param norm = 2.0296e-01, time/batch = 18.1998s	
29943/33250 (epoch 45.027), train_loss = 0.78348873, grad/param norm = 1.7293e-01, time/batch = 16.7006s	
29944/33250 (epoch 45.029), train_loss = 0.73070275, grad/param norm = 1.8588e-01, time/batch = 14.7893s	
29945/33250 (epoch 45.030), train_loss = 0.75942837, grad/param norm = 2.1012e-01, time/batch = 15.0796s	
29946/33250 (epoch 45.032), train_loss = 0.91292276, grad/param norm = 2.1110e-01, time/batch = 14.7899s	
29947/33250 (epoch 45.033), train_loss = 0.72966280, grad/param norm = 2.0908e-01, time/batch = 15.0109s	
29948/33250 (epoch 45.035), train_loss = 0.76483976, grad/param norm = 1.8052e-01, time/batch = 14.7129s	
29949/33250 (epoch 45.036), train_loss = 0.79234031, grad/param norm = 1.9731e-01, time/batch = 14.6150s	
29950/33250 (epoch 45.038), train_loss = 0.76948060, grad/param norm = 1.5701e-01, time/batch = 14.8008s	
29951/33250 (epoch 45.039), train_loss = 0.70140181, grad/param norm = 1.7715e-01, time/batch = 14.7798s	
29952/33250 (epoch 45.041), train_loss = 0.77808650, grad/param norm = 2.6842e-01, time/batch = 15.0168s	
29953/33250 (epoch 45.042), train_loss = 0.64541528, grad/param norm = 1.8011e-01, time/batch = 15.0374s	
29954/33250 (epoch 45.044), train_loss = 0.86308174, grad/param norm = 1.9142e-01, time/batch = 14.9921s	
29955/33250 (epoch 45.045), train_loss = 0.86010520, grad/param norm = 1.8855e-01, time/batch = 15.6455s	
29956/33250 (epoch 45.047), train_loss = 0.78877637, grad/param norm = 1.9635e-01, time/batch = 15.0959s	
29957/33250 (epoch 45.048), train_loss = 0.79693598, grad/param norm = 2.4705e-01, time/batch = 14.6380s	
29958/33250 (epoch 45.050), train_loss = 0.75756406, grad/param norm = 1.8584e-01, time/batch = 14.5479s	
29959/33250 (epoch 45.051), train_loss = 0.75057322, grad/param norm = 1.9330e-01, time/batch = 14.7946s	
29960/33250 (epoch 45.053), train_loss = 0.80440886, grad/param norm = 2.0037e-01, time/batch = 15.2824s	
29961/33250 (epoch 45.054), train_loss = 0.64891853, grad/param norm = 1.6923e-01, time/batch = 14.5459s	
29962/33250 (epoch 45.056), train_loss = 0.64313855, grad/param norm = 1.7235e-01, time/batch = 15.1187s	
29963/33250 (epoch 45.057), train_loss = 0.83057524, grad/param norm = 1.9136e-01, time/batch = 15.3040s	
29964/33250 (epoch 45.059), train_loss = 0.74849532, grad/param norm = 1.7716e-01, time/batch = 16.1365s	
29965/33250 (epoch 45.060), train_loss = 0.76874505, grad/param norm = 2.0841e-01, time/batch = 15.2431s	
29966/33250 (epoch 45.062), train_loss = 0.83968874, grad/param norm = 1.9516e-01, time/batch = 18.2922s	
29967/33250 (epoch 45.063), train_loss = 0.87305868, grad/param norm = 1.9134e-01, time/batch = 15.2076s	
29968/33250 (epoch 45.065), train_loss = 0.72647267, grad/param norm = 2.0802e-01, time/batch = 15.3328s	
29969/33250 (epoch 45.066), train_loss = 0.80165741, grad/param norm = 2.0426e-01, time/batch = 14.7018s	
29970/33250 (epoch 45.068), train_loss = 0.72302564, grad/param norm = 2.0374e-01, time/batch = 14.7801s	
29971/33250 (epoch 45.069), train_loss = 0.77387917, grad/param norm = 2.0730e-01, time/batch = 14.7093s	
29972/33250 (epoch 45.071), train_loss = 0.71519503, grad/param norm = 1.6941e-01, time/batch = 15.1252s	
29973/33250 (epoch 45.072), train_loss = 0.67343243, grad/param norm = 1.5751e-01, time/batch = 14.2241s	
29974/33250 (epoch 45.074), train_loss = 0.76706601, grad/param norm = 1.7753e-01, time/batch = 15.3727s	
29975/33250 (epoch 45.075), train_loss = 0.72799278, grad/param norm = 1.8325e-01, time/batch = 16.2768s	
29976/33250 (epoch 45.077), train_loss = 0.74784599, grad/param norm = 2.0767e-01, time/batch = 14.6372s	
29977/33250 (epoch 45.078), train_loss = 0.76422496, grad/param norm = 1.8016e-01, time/batch = 15.3121s	
29978/33250 (epoch 45.080), train_loss = 0.78011562, grad/param norm = 3.0429e-01, time/batch = 14.9015s	
29979/33250 (epoch 45.081), train_loss = 0.77898631, grad/param norm = 1.7678e-01, time/batch = 14.7820s	
29980/33250 (epoch 45.083), train_loss = 0.86534571, grad/param norm = 1.8723e-01, time/batch = 14.7099s	
29981/33250 (epoch 45.084), train_loss = 0.80009003, grad/param norm = 2.0673e-01, time/batch = 14.4730s	
29982/33250 (epoch 45.086), train_loss = 0.77296483, grad/param norm = 1.7908e-01, time/batch = 14.7919s	
29983/33250 (epoch 45.087), train_loss = 0.65341017, grad/param norm = 1.4854e-01, time/batch = 14.4720s	
29984/33250 (epoch 45.089), train_loss = 0.74241799, grad/param norm = 2.0518e-01, time/batch = 14.7313s	
29985/33250 (epoch 45.090), train_loss = 0.76713406, grad/param norm = 1.8082e-01, time/batch = 15.0281s	
29986/33250 (epoch 45.092), train_loss = 0.70782253, grad/param norm = 2.0817e-01, time/batch = 16.9764s	
29987/33250 (epoch 45.093), train_loss = 0.72457040, grad/param norm = 1.6566e-01, time/batch = 14.6584s	
29988/33250 (epoch 45.095), train_loss = 0.74698855, grad/param norm = 1.8862e-01, time/batch = 14.4797s	
29989/33250 (epoch 45.096), train_loss = 0.63100594, grad/param norm = 1.6703e-01, time/batch = 14.3607s	
29990/33250 (epoch 45.098), train_loss = 0.63006259, grad/param norm = 1.8399e-01, time/batch = 15.2077s	
29991/33250 (epoch 45.099), train_loss = 0.59219492, grad/param norm = 1.5367e-01, time/batch = 14.7069s	
29992/33250 (epoch 45.101), train_loss = 0.73126736, grad/param norm = 2.1534e-01, time/batch = 14.6962s	
29993/33250 (epoch 45.102), train_loss = 0.68655731, grad/param norm = 1.6076e-01, time/batch = 14.7055s	
29994/33250 (epoch 45.104), train_loss = 0.58709525, grad/param norm = 1.6652e-01, time/batch = 14.7862s	
29995/33250 (epoch 45.105), train_loss = 0.70108762, grad/param norm = 1.8508e-01, time/batch = 14.7864s	
29996/33250 (epoch 45.107), train_loss = 0.62694214, grad/param norm = 1.4608e-01, time/batch = 14.6910s	
29997/33250 (epoch 45.108), train_loss = 0.73917475, grad/param norm = 1.9049e-01, time/batch = 15.0581s	
29998/33250 (epoch 45.110), train_loss = 0.64296091, grad/param norm = 1.9323e-01, time/batch = 14.6396s	
29999/33250 (epoch 45.111), train_loss = 0.73698153, grad/param norm = 1.6421e-01, time/batch = 15.1082s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch45.11_1.7371.t7	
30000/33250 (epoch 45.113), train_loss = 0.68890024, grad/param norm = 1.8185e-01, time/batch = 14.8085s	
30001/33250 (epoch 45.114), train_loss = 1.35679485, grad/param norm = 2.7051e-01, time/batch = 15.7603s	
30002/33250 (epoch 45.116), train_loss = 0.70152559, grad/param norm = 2.4452e-01, time/batch = 16.5291s	
30003/33250 (epoch 45.117), train_loss = 0.67205397, grad/param norm = 1.9026e-01, time/batch = 14.3709s	
30004/33250 (epoch 45.119), train_loss = 0.71086386, grad/param norm = 1.8503e-01, time/batch = 14.4645s	
30005/33250 (epoch 45.120), train_loss = 0.62265328, grad/param norm = 1.6088e-01, time/batch = 14.3050s	
30006/33250 (epoch 45.122), train_loss = 0.78380644, grad/param norm = 3.1089e-01, time/batch = 14.8441s	
30007/33250 (epoch 45.123), train_loss = 0.73807403, grad/param norm = 2.3911e-01, time/batch = 14.6353s	
30008/33250 (epoch 45.125), train_loss = 0.60314219, grad/param norm = 2.4379e-01, time/batch = 14.4553s	
30009/33250 (epoch 45.126), train_loss = 0.70725528, grad/param norm = 1.7528e-01, time/batch = 14.3713s	
30010/33250 (epoch 45.128), train_loss = 0.68604276, grad/param norm = 1.6380e-01, time/batch = 14.5482s	
30011/33250 (epoch 45.129), train_loss = 0.74724770, grad/param norm = 1.9091e-01, time/batch = 15.0684s	
30012/33250 (epoch 45.131), train_loss = 0.72543293, grad/param norm = 1.7876e-01, time/batch = 15.8077s	
30013/33250 (epoch 45.132), train_loss = 0.69694488, grad/param norm = 1.7386e-01, time/batch = 15.2399s	
30014/33250 (epoch 45.134), train_loss = 0.67262249, grad/param norm = 2.2296e-01, time/batch = 14.6979s	
30015/33250 (epoch 45.135), train_loss = 0.75497527, grad/param norm = 1.5044e-01, time/batch = 14.4522s	
30016/33250 (epoch 45.137), train_loss = 0.66915909, grad/param norm = 1.9528e-01, time/batch = 14.4463s	
30017/33250 (epoch 45.138), train_loss = 0.65737547, grad/param norm = 1.5334e-01, time/batch = 14.3861s	
30018/33250 (epoch 45.140), train_loss = 0.57510989, grad/param norm = 1.8196e-01, time/batch = 14.9467s	
30019/33250 (epoch 45.141), train_loss = 0.81279534, grad/param norm = 2.4519e-01, time/batch = 14.9128s	
30020/33250 (epoch 45.143), train_loss = 0.62105452, grad/param norm = 1.8814e-01, time/batch = 14.9650s	
30021/33250 (epoch 45.144), train_loss = 0.70287002, grad/param norm = 1.7972e-01, time/batch = 14.7249s	
30022/33250 (epoch 45.146), train_loss = 0.69580460, grad/param norm = 1.6955e-01, time/batch = 14.5546s	
30023/33250 (epoch 45.147), train_loss = 0.71228521, grad/param norm = 1.8218e-01, time/batch = 15.4797s	
30024/33250 (epoch 45.149), train_loss = 0.67448192, grad/param norm = 1.6105e-01, time/batch = 15.2724s	
30025/33250 (epoch 45.150), train_loss = 0.67017176, grad/param norm = 1.8788e-01, time/batch = 15.5618s	
30026/33250 (epoch 45.152), train_loss = 0.60868043, grad/param norm = 1.6301e-01, time/batch = 15.1770s	
30027/33250 (epoch 45.153), train_loss = 0.89391450, grad/param norm = 2.1850e-01, time/batch = 14.3838s	
30028/33250 (epoch 45.155), train_loss = 0.70827970, grad/param norm = 1.9274e-01, time/batch = 14.3073s	
30029/33250 (epoch 45.156), train_loss = 0.90522115, grad/param norm = 1.8303e-01, time/batch = 14.4387s	
30030/33250 (epoch 45.158), train_loss = 0.87016513, grad/param norm = 2.0815e-01, time/batch = 14.6050s	
30031/33250 (epoch 45.159), train_loss = 0.69321629, grad/param norm = 1.7375e-01, time/batch = 14.1437s	
30032/33250 (epoch 45.161), train_loss = 0.74756848, grad/param norm = 1.9356e-01, time/batch = 14.4506s	
30033/33250 (epoch 45.162), train_loss = 0.66232310, grad/param norm = 1.9084e-01, time/batch = 14.9089s	
30034/33250 (epoch 45.164), train_loss = 0.73815014, grad/param norm = 2.5631e-01, time/batch = 14.9681s	
30035/33250 (epoch 45.165), train_loss = 0.82048031, grad/param norm = 2.0056e-01, time/batch = 16.3960s	
30036/33250 (epoch 45.167), train_loss = 0.85499091, grad/param norm = 2.4752e-01, time/batch = 15.9524s	
30037/33250 (epoch 45.168), train_loss = 0.66563170, grad/param norm = 1.7268e-01, time/batch = 14.6370s	
30038/33250 (epoch 45.170), train_loss = 0.73798987, grad/param norm = 2.6543e-01, time/batch = 14.7021s	
30039/33250 (epoch 45.171), train_loss = 0.74006709, grad/param norm = 1.7338e-01, time/batch = 14.6977s	
30040/33250 (epoch 45.173), train_loss = 0.74288021, grad/param norm = 1.9269e-01, time/batch = 14.2190s	
30041/33250 (epoch 45.174), train_loss = 0.77634088, grad/param norm = 2.2159e-01, time/batch = 14.5532s	
30042/33250 (epoch 45.176), train_loss = 0.66560127, grad/param norm = 1.7985e-01, time/batch = 14.3796s	
30043/33250 (epoch 45.177), train_loss = 0.66866455, grad/param norm = 1.5719e-01, time/batch = 14.6365s	
30044/33250 (epoch 45.179), train_loss = 0.66731288, grad/param norm = 1.6060e-01, time/batch = 15.7213s	
30045/33250 (epoch 45.180), train_loss = 0.61596522, grad/param norm = 1.6303e-01, time/batch = 17.1405s	
30046/33250 (epoch 45.182), train_loss = 0.65597662, grad/param norm = 1.9203e-01, time/batch = 15.0315s	
30047/33250 (epoch 45.183), train_loss = 0.82001931, grad/param norm = 2.2971e-01, time/batch = 14.9117s	
30048/33250 (epoch 45.185), train_loss = 0.74626361, grad/param norm = 2.2608e-01, time/batch = 14.9465s	
30049/33250 (epoch 45.186), train_loss = 0.76253078, grad/param norm = 2.1813e-01, time/batch = 14.4524s	
30050/33250 (epoch 45.188), train_loss = 0.79853889, grad/param norm = 1.8912e-01, time/batch = 14.8566s	
30051/33250 (epoch 45.189), train_loss = 0.59044077, grad/param norm = 1.7876e-01, time/batch = 15.0101s	
30052/33250 (epoch 45.191), train_loss = 0.67862062, grad/param norm = 1.8912e-01, time/batch = 14.6912s	
30053/33250 (epoch 45.192), train_loss = 0.68729734, grad/param norm = 1.6487e-01, time/batch = 14.5327s	
30054/33250 (epoch 45.194), train_loss = 0.71201743, grad/param norm = 1.9967e-01, time/batch = 15.0115s	
30055/33250 (epoch 45.195), train_loss = 0.86206715, grad/param norm = 1.8791e-01, time/batch = 14.6450s	
30056/33250 (epoch 45.197), train_loss = 0.68748165, grad/param norm = 1.6660e-01, time/batch = 14.6493s	
30057/33250 (epoch 45.198), train_loss = 0.84832559, grad/param norm = 1.8732e-01, time/batch = 14.4695s	
30058/33250 (epoch 45.200), train_loss = 0.74776765, grad/param norm = 2.0603e-01, time/batch = 14.4744s	
30059/33250 (epoch 45.202), train_loss = 0.70987827, grad/param norm = 1.7348e-01, time/batch = 15.2156s	
30060/33250 (epoch 45.203), train_loss = 0.65930088, grad/param norm = 1.8056e-01, time/batch = 14.7166s	
30061/33250 (epoch 45.205), train_loss = 0.74713020, grad/param norm = 1.7910e-01, time/batch = 14.5674s	
30062/33250 (epoch 45.206), train_loss = 0.78780107, grad/param norm = 1.8992e-01, time/batch = 15.0846s	
30063/33250 (epoch 45.208), train_loss = 0.82345301, grad/param norm = 2.2997e-01, time/batch = 14.3862s	
30064/33250 (epoch 45.209), train_loss = 0.69686297, grad/param norm = 1.9303e-01, time/batch = 14.4697s	
30065/33250 (epoch 45.211), train_loss = 0.74271070, grad/param norm = 1.8976e-01, time/batch = 14.5398s	
30066/33250 (epoch 45.212), train_loss = 0.85012713, grad/param norm = 1.9347e-01, time/batch = 14.7992s	
30067/33250 (epoch 45.214), train_loss = 0.75854623, grad/param norm = 1.6611e-01, time/batch = 14.4240s	
30068/33250 (epoch 45.215), train_loss = 0.77806956, grad/param norm = 2.4915e-01, time/batch = 15.3995s	
30069/33250 (epoch 45.217), train_loss = 0.83118164, grad/param norm = 2.2311e-01, time/batch = 14.5920s	
30070/33250 (epoch 45.218), train_loss = 0.78559793, grad/param norm = 1.7829e-01, time/batch = 14.6429s	
30071/33250 (epoch 45.220), train_loss = 0.75025847, grad/param norm = 1.8131e-01, time/batch = 14.4746s	
30072/33250 (epoch 45.221), train_loss = 0.84987105, grad/param norm = 2.2707e-01, time/batch = 14.5373s	
30073/33250 (epoch 45.223), train_loss = 0.73366629, grad/param norm = 1.7520e-01, time/batch = 14.2239s	
30074/33250 (epoch 45.224), train_loss = 0.77252554, grad/param norm = 1.9874e-01, time/batch = 14.7877s	
30075/33250 (epoch 45.226), train_loss = 0.86451416, grad/param norm = 1.8995e-01, time/batch = 14.5475s	
30076/33250 (epoch 45.227), train_loss = 0.77150874, grad/param norm = 1.8173e-01, time/batch = 14.7926s	
30077/33250 (epoch 45.229), train_loss = 0.77193533, grad/param norm = 1.7652e-01, time/batch = 15.2912s	
30078/33250 (epoch 45.230), train_loss = 0.75748806, grad/param norm = 1.7511e-01, time/batch = 15.1652s	
30079/33250 (epoch 45.232), train_loss = 0.70383495, grad/param norm = 1.7541e-01, time/batch = 15.8049s	
30080/33250 (epoch 45.233), train_loss = 0.67265028, grad/param norm = 1.6837e-01, time/batch = 17.6195s	
30081/33250 (epoch 45.235), train_loss = 0.84931526, grad/param norm = 1.7729e-01, time/batch = 17.5451s	
30082/33250 (epoch 45.236), train_loss = 0.67056710, grad/param norm = 1.8134e-01, time/batch = 14.7941s	
30083/33250 (epoch 45.238), train_loss = 0.82437986, grad/param norm = 2.0499e-01, time/batch = 14.5582s	
30084/33250 (epoch 45.239), train_loss = 0.85136800, grad/param norm = 2.5119e-01, time/batch = 15.3343s	
30085/33250 (epoch 45.241), train_loss = 0.83537244, grad/param norm = 2.5168e-01, time/batch = 15.4497s	
30086/33250 (epoch 45.242), train_loss = 0.82050489, grad/param norm = 2.0892e-01, time/batch = 15.0940s	
30087/33250 (epoch 45.244), train_loss = 0.78306115, grad/param norm = 2.0509e-01, time/batch = 14.7180s	
30088/33250 (epoch 45.245), train_loss = 0.79487717, grad/param norm = 2.0941e-01, time/batch = 15.2972s	
30089/33250 (epoch 45.247), train_loss = 0.74512764, grad/param norm = 1.7995e-01, time/batch = 15.1331s	
30090/33250 (epoch 45.248), train_loss = 0.87990537, grad/param norm = 2.2355e-01, time/batch = 14.9557s	
30091/33250 (epoch 45.250), train_loss = 0.86293710, grad/param norm = 1.7154e-01, time/batch = 14.1462s	
30092/33250 (epoch 45.251), train_loss = 0.73340431, grad/param norm = 1.7034e-01, time/batch = 17.1362s	
30093/33250 (epoch 45.253), train_loss = 0.74210934, grad/param norm = 1.7016e-01, time/batch = 14.4520s	
30094/33250 (epoch 45.254), train_loss = 0.69202280, grad/param norm = 1.7218e-01, time/batch = 14.5278s	
30095/33250 (epoch 45.256), train_loss = 0.76718776, grad/param norm = 1.8014e-01, time/batch = 14.3689s	
30096/33250 (epoch 45.257), train_loss = 0.88155108, grad/param norm = 1.8605e-01, time/batch = 14.6313s	
30097/33250 (epoch 45.259), train_loss = 0.78181386, grad/param norm = 2.0312e-01, time/batch = 14.7663s	
30098/33250 (epoch 45.260), train_loss = 0.62708721, grad/param norm = 2.1060e-01, time/batch = 14.8768s	
30099/33250 (epoch 45.262), train_loss = 0.75388533, grad/param norm = 1.7375e-01, time/batch = 14.7197s	
30100/33250 (epoch 45.263), train_loss = 0.62094066, grad/param norm = 1.6899e-01, time/batch = 15.4856s	
30101/33250 (epoch 45.265), train_loss = 0.78760143, grad/param norm = 1.9908e-01, time/batch = 17.0497s	
30102/33250 (epoch 45.266), train_loss = 0.76341117, grad/param norm = 1.9363e-01, time/batch = 15.6512s	
30103/33250 (epoch 45.268), train_loss = 0.65299473, grad/param norm = 1.7138e-01, time/batch = 14.7122s	
30104/33250 (epoch 45.269), train_loss = 0.61642713, grad/param norm = 1.8512e-01, time/batch = 14.7916s	
30105/33250 (epoch 45.271), train_loss = 0.78867526, grad/param norm = 1.7245e-01, time/batch = 14.8836s	
30106/33250 (epoch 45.272), train_loss = 0.68224756, grad/param norm = 1.4406e-01, time/batch = 14.7091s	
30107/33250 (epoch 45.274), train_loss = 0.56045521, grad/param norm = 1.6123e-01, time/batch = 14.4022s	
30108/33250 (epoch 45.275), train_loss = 0.71315052, grad/param norm = 1.5172e-01, time/batch = 14.5604s	
30109/33250 (epoch 45.277), train_loss = 0.63526136, grad/param norm = 1.8363e-01, time/batch = 14.8511s	
30110/33250 (epoch 45.278), train_loss = 0.71345424, grad/param norm = 1.8472e-01, time/batch = 14.7764s	
30111/33250 (epoch 45.280), train_loss = 0.65988301, grad/param norm = 1.6834e-01, time/batch = 14.4015s	
30112/33250 (epoch 45.281), train_loss = 0.76376169, grad/param norm = 2.0170e-01, time/batch = 14.7022s	
30113/33250 (epoch 45.283), train_loss = 0.78314183, grad/param norm = 2.7773e-01, time/batch = 14.5545s	
30114/33250 (epoch 45.284), train_loss = 0.64508003, grad/param norm = 2.4188e-01, time/batch = 14.7980s	
30115/33250 (epoch 45.286), train_loss = 0.76858274, grad/param norm = 1.6712e-01, time/batch = 14.6280s	
30116/33250 (epoch 45.287), train_loss = 0.61710877, grad/param norm = 1.5470e-01, time/batch = 14.2961s	
30117/33250 (epoch 45.289), train_loss = 0.60071635, grad/param norm = 1.9431e-01, time/batch = 14.8573s	
30118/33250 (epoch 45.290), train_loss = 0.72237221, grad/param norm = 1.7469e-01, time/batch = 15.1660s	
30119/33250 (epoch 45.292), train_loss = 0.77040592, grad/param norm = 2.2159e-01, time/batch = 14.8102s	
30120/33250 (epoch 45.293), train_loss = 0.84081644, grad/param norm = 2.1190e-01, time/batch = 15.0414s	
30121/33250 (epoch 45.295), train_loss = 0.83506427, grad/param norm = 2.0280e-01, time/batch = 14.7169s	
30122/33250 (epoch 45.296), train_loss = 0.74071947, grad/param norm = 1.8156e-01, time/batch = 15.2712s	
30123/33250 (epoch 45.298), train_loss = 0.60244661, grad/param norm = 1.6794e-01, time/batch = 14.8698s	
30124/33250 (epoch 45.299), train_loss = 0.59499950, grad/param norm = 2.3158e-01, time/batch = 14.7197s	
30125/33250 (epoch 45.301), train_loss = 0.81056467, grad/param norm = 1.7875e-01, time/batch = 14.5795s	
30126/33250 (epoch 45.302), train_loss = 0.80186862, grad/param norm = 1.9464e-01, time/batch = 14.7056s	
30127/33250 (epoch 45.304), train_loss = 0.70252189, grad/param norm = 2.2218e-01, time/batch = 15.1540s	
30128/33250 (epoch 45.305), train_loss = 0.68605844, grad/param norm = 1.7638e-01, time/batch = 14.8789s	
30129/33250 (epoch 45.307), train_loss = 0.81595933, grad/param norm = 2.0515e-01, time/batch = 14.3915s	
30130/33250 (epoch 45.308), train_loss = 0.84984029, grad/param norm = 2.3247e-01, time/batch = 14.7671s	
30131/33250 (epoch 45.310), train_loss = 0.70452071, grad/param norm = 2.1538e-01, time/batch = 14.3967s	
30132/33250 (epoch 45.311), train_loss = 0.88166104, grad/param norm = 1.9687e-01, time/batch = 14.5349s	
30133/33250 (epoch 45.313), train_loss = 0.60043885, grad/param norm = 1.9742e-01, time/batch = 14.3811s	
30134/33250 (epoch 45.314), train_loss = 0.82365022, grad/param norm = 1.8004e-01, time/batch = 14.8526s	
30135/33250 (epoch 45.316), train_loss = 0.89762973, grad/param norm = 2.0034e-01, time/batch = 14.3221s	
30136/33250 (epoch 45.317), train_loss = 0.66078388, grad/param norm = 1.7455e-01, time/batch = 14.4817s	
30137/33250 (epoch 45.319), train_loss = 0.77978201, grad/param norm = 2.2244e-01, time/batch = 14.7201s	
30138/33250 (epoch 45.320), train_loss = 0.80137167, grad/param norm = 2.0553e-01, time/batch = 14.5722s	
30139/33250 (epoch 45.322), train_loss = 0.89806119, grad/param norm = 2.0558e-01, time/batch = 14.6509s	
30140/33250 (epoch 45.323), train_loss = 0.91149792, grad/param norm = 2.8273e-01, time/batch = 14.8429s	
30141/33250 (epoch 45.325), train_loss = 0.73407420, grad/param norm = 2.2915e-01, time/batch = 14.3857s	
30142/33250 (epoch 45.326), train_loss = 0.97801291, grad/param norm = 2.0970e-01, time/batch = 14.7034s	
30143/33250 (epoch 45.328), train_loss = 0.73638944, grad/param norm = 2.0401e-01, time/batch = 14.5560s	
30144/33250 (epoch 45.329), train_loss = 0.79360114, grad/param norm = 2.2500e-01, time/batch = 14.3040s	
30145/33250 (epoch 45.331), train_loss = 0.76199659, grad/param norm = 2.8709e-01, time/batch = 14.4607s	
30146/33250 (epoch 45.332), train_loss = 0.77321429, grad/param norm = 1.8255e-01, time/batch = 14.7869s	
30147/33250 (epoch 45.334), train_loss = 0.88044238, grad/param norm = 1.9090e-01, time/batch = 14.6597s	
30148/33250 (epoch 45.335), train_loss = 0.57003757, grad/param norm = 1.7888e-01, time/batch = 14.4789s	
30149/33250 (epoch 45.337), train_loss = 0.83265748, grad/param norm = 1.8241e-01, time/batch = 14.2319s	
30150/33250 (epoch 45.338), train_loss = 0.90525769, grad/param norm = 1.8999e-01, time/batch = 14.2290s	
30151/33250 (epoch 45.340), train_loss = 0.72064120, grad/param norm = 1.7062e-01, time/batch = 14.2320s	
30152/33250 (epoch 45.341), train_loss = 0.68180643, grad/param norm = 1.8535e-01, time/batch = 14.4622s	
30153/33250 (epoch 45.343), train_loss = 0.73128929, grad/param norm = 2.1661e-01, time/batch = 13.9867s	
30154/33250 (epoch 45.344), train_loss = 0.73957332, grad/param norm = 1.6072e-01, time/batch = 14.2100s	
30155/33250 (epoch 45.346), train_loss = 0.66272030, grad/param norm = 1.6858e-01, time/batch = 14.3731s	
30156/33250 (epoch 45.347), train_loss = 0.91575335, grad/param norm = 2.3989e-01, time/batch = 14.3672s	
30157/33250 (epoch 45.349), train_loss = 0.75803985, grad/param norm = 2.1031e-01, time/batch = 14.2164s	
30158/33250 (epoch 45.350), train_loss = 0.75464847, grad/param norm = 2.0245e-01, time/batch = 13.8963s	
30159/33250 (epoch 45.352), train_loss = 0.68700821, grad/param norm = 1.9414e-01, time/batch = 15.0141s	
30160/33250 (epoch 45.353), train_loss = 0.72095634, grad/param norm = 1.7131e-01, time/batch = 14.4832s	
30161/33250 (epoch 45.355), train_loss = 0.71195411, grad/param norm = 1.5353e-01, time/batch = 14.6466s	
30162/33250 (epoch 45.356), train_loss = 0.69450125, grad/param norm = 2.1613e-01, time/batch = 14.1623s	
30163/33250 (epoch 45.358), train_loss = 0.74260220, grad/param norm = 1.7257e-01, time/batch = 15.0161s	
30164/33250 (epoch 45.359), train_loss = 0.71998949, grad/param norm = 1.8408e-01, time/batch = 14.3973s	
30165/33250 (epoch 45.361), train_loss = 0.83113077, grad/param norm = 2.2295e-01, time/batch = 14.3921s	
30166/33250 (epoch 45.362), train_loss = 0.77172430, grad/param norm = 1.6986e-01, time/batch = 14.3087s	
30167/33250 (epoch 45.364), train_loss = 0.78939325, grad/param norm = 1.9862e-01, time/batch = 27.6235s	
30168/33250 (epoch 45.365), train_loss = 0.74489876, grad/param norm = 1.6286e-01, time/batch = 16.3251s	
30169/33250 (epoch 45.367), train_loss = 0.77184081, grad/param norm = 1.6565e-01, time/batch = 14.8471s	
30170/33250 (epoch 45.368), train_loss = 0.73803543, grad/param norm = 2.0784e-01, time/batch = 14.9350s	
30171/33250 (epoch 45.370), train_loss = 0.65981198, grad/param norm = 1.5272e-01, time/batch = 14.5470s	
30172/33250 (epoch 45.371), train_loss = 0.84333104, grad/param norm = 2.1509e-01, time/batch = 14.3773s	
30173/33250 (epoch 45.373), train_loss = 0.73245632, grad/param norm = 1.6006e-01, time/batch = 14.8562s	
30174/33250 (epoch 45.374), train_loss = 0.74162300, grad/param norm = 2.3700e-01, time/batch = 14.7716s	
30175/33250 (epoch 45.376), train_loss = 0.77214268, grad/param norm = 1.8561e-01, time/batch = 14.8564s	
30176/33250 (epoch 45.377), train_loss = 0.66514554, grad/param norm = 2.2779e-01, time/batch = 14.9323s	
30177/33250 (epoch 45.379), train_loss = 0.74691187, grad/param norm = 1.9050e-01, time/batch = 14.6950s	
30178/33250 (epoch 45.380), train_loss = 0.73748409, grad/param norm = 2.3630e-01, time/batch = 15.0056s	
30179/33250 (epoch 45.382), train_loss = 0.78411950, grad/param norm = 2.1985e-01, time/batch = 15.0774s	
30180/33250 (epoch 45.383), train_loss = 0.65956590, grad/param norm = 1.8108e-01, time/batch = 15.1637s	
30181/33250 (epoch 45.385), train_loss = 0.63843388, grad/param norm = 1.8494e-01, time/batch = 15.1150s	
30182/33250 (epoch 45.386), train_loss = 0.63028079, grad/param norm = 2.1534e-01, time/batch = 15.0292s	
30183/33250 (epoch 45.388), train_loss = 0.69387857, grad/param norm = 1.8190e-01, time/batch = 15.0302s	
30184/33250 (epoch 45.389), train_loss = 0.66640676, grad/param norm = 1.9331e-01, time/batch = 14.7685s	
30185/33250 (epoch 45.391), train_loss = 0.78352939, grad/param norm = 1.9134e-01, time/batch = 14.8512s	
30186/33250 (epoch 45.392), train_loss = 0.86445063, grad/param norm = 2.0837e-01, time/batch = 15.6482s	
30187/33250 (epoch 45.394), train_loss = 0.81558523, grad/param norm = 1.8815e-01, time/batch = 14.9300s	
30188/33250 (epoch 45.395), train_loss = 0.84336561, grad/param norm = 1.8067e-01, time/batch = 14.4624s	
30189/33250 (epoch 45.397), train_loss = 0.86048345, grad/param norm = 1.7871e-01, time/batch = 14.4626s	
30190/33250 (epoch 45.398), train_loss = 0.66110837, grad/param norm = 1.7044e-01, time/batch = 14.8682s	
30191/33250 (epoch 45.400), train_loss = 0.66026264, grad/param norm = 1.7182e-01, time/batch = 14.4624s	
30192/33250 (epoch 45.402), train_loss = 0.61704031, grad/param norm = 1.7263e-01, time/batch = 14.5325s	
30193/33250 (epoch 45.403), train_loss = 0.72290824, grad/param norm = 2.0166e-01, time/batch = 14.5463s	
30194/33250 (epoch 45.405), train_loss = 0.69590283, grad/param norm = 1.6104e-01, time/batch = 14.7035s	
30195/33250 (epoch 45.406), train_loss = 0.71894656, grad/param norm = 1.9745e-01, time/batch = 14.6227s	
30196/33250 (epoch 45.408), train_loss = 0.87282251, grad/param norm = 1.8358e-01, time/batch = 14.7807s	
30197/33250 (epoch 45.409), train_loss = 0.77697725, grad/param norm = 2.2614e-01, time/batch = 14.7062s	
30198/33250 (epoch 45.411), train_loss = 0.56120879, grad/param norm = 1.5415e-01, time/batch = 14.9527s	
30199/33250 (epoch 45.412), train_loss = 0.63978006, grad/param norm = 1.9454e-01, time/batch = 14.7872s	
30200/33250 (epoch 45.414), train_loss = 0.74400523, grad/param norm = 1.7917e-01, time/batch = 14.3789s	
30201/33250 (epoch 45.415), train_loss = 0.82396233, grad/param norm = 2.3207e-01, time/batch = 14.7022s	
30202/33250 (epoch 45.417), train_loss = 0.83973211, grad/param norm = 1.9705e-01, time/batch = 14.7040s	
30203/33250 (epoch 45.418), train_loss = 0.96978671, grad/param norm = 2.2672e-01, time/batch = 15.0334s	
30204/33250 (epoch 45.420), train_loss = 0.82264005, grad/param norm = 1.8794e-01, time/batch = 14.6227s	
30205/33250 (epoch 45.421), train_loss = 0.71256851, grad/param norm = 1.6332e-01, time/batch = 14.5461s	
30206/33250 (epoch 45.423), train_loss = 0.78070096, grad/param norm = 1.9753e-01, time/batch = 14.8736s	
30207/33250 (epoch 45.424), train_loss = 0.87409138, grad/param norm = 2.8916e-01, time/batch = 21.8148s	
30208/33250 (epoch 45.426), train_loss = 0.71254240, grad/param norm = 1.3935e-01, time/batch = 32.3589s	
30209/33250 (epoch 45.427), train_loss = 0.69741391, grad/param norm = 2.1525e-01, time/batch = 27.5192s	
30210/33250 (epoch 45.429), train_loss = 0.72254347, grad/param norm = 2.0079e-01, time/batch = 26.4575s	
30211/33250 (epoch 45.430), train_loss = 0.71203527, grad/param norm = 2.2206e-01, time/batch = 32.9663s	
30212/33250 (epoch 45.432), train_loss = 0.81867265, grad/param norm = 1.8174e-01, time/batch = 32.9063s	
30213/33250 (epoch 45.433), train_loss = 0.70686707, grad/param norm = 2.3953e-01, time/batch = 30.0525s	
30214/33250 (epoch 45.435), train_loss = 0.78745350, grad/param norm = 1.6465e-01, time/batch = 30.5184s	
30215/33250 (epoch 45.436), train_loss = 0.72041128, grad/param norm = 1.8836e-01, time/batch = 30.7438s	
30216/33250 (epoch 45.438), train_loss = 0.86140596, grad/param norm = 2.0774e-01, time/batch = 31.2401s	
30217/33250 (epoch 45.439), train_loss = 0.76811124, grad/param norm = 1.7722e-01, time/batch = 33.1510s	
30218/33250 (epoch 45.441), train_loss = 0.75171319, grad/param norm = 2.4494e-01, time/batch = 32.9671s	
30219/33250 (epoch 45.442), train_loss = 0.67659253, grad/param norm = 1.7569e-01, time/batch = 29.4254s	
30220/33250 (epoch 45.444), train_loss = 0.70223683, grad/param norm = 1.6320e-01, time/batch = 29.4988s	
30221/33250 (epoch 45.445), train_loss = 0.77018710, grad/param norm = 1.6388e-01, time/batch = 22.8103s	
30222/33250 (epoch 45.447), train_loss = 0.67391545, grad/param norm = 1.9285e-01, time/batch = 28.6929s	
30223/33250 (epoch 45.448), train_loss = 0.76570933, grad/param norm = 1.5712e-01, time/batch = 25.6885s	
30224/33250 (epoch 45.450), train_loss = 0.82613788, grad/param norm = 1.9328e-01, time/batch = 29.3018s	
30225/33250 (epoch 45.451), train_loss = 0.80655119, grad/param norm = 2.0314e-01, time/batch = 28.0867s	
30226/33250 (epoch 45.453), train_loss = 0.64918155, grad/param norm = 1.6139e-01, time/batch = 31.2940s	
30227/33250 (epoch 45.454), train_loss = 0.85067470, grad/param norm = 1.9087e-01, time/batch = 31.3755s	
30228/33250 (epoch 45.456), train_loss = 0.85640972, grad/param norm = 1.5931e-01, time/batch = 33.1426s	
30229/33250 (epoch 45.457), train_loss = 0.69146525, grad/param norm = 1.6846e-01, time/batch = 18.0183s	
30230/33250 (epoch 45.459), train_loss = 0.80607218, grad/param norm = 1.7263e-01, time/batch = 17.6819s	
30231/33250 (epoch 45.460), train_loss = 0.80983450, grad/param norm = 2.0082e-01, time/batch = 15.0600s	
30232/33250 (epoch 45.462), train_loss = 0.76160849, grad/param norm = 2.0807e-01, time/batch = 14.7832s	
30233/33250 (epoch 45.463), train_loss = 0.67308595, grad/param norm = 1.6211e-01, time/batch = 14.6251s	
30234/33250 (epoch 45.465), train_loss = 0.63462464, grad/param norm = 1.5191e-01, time/batch = 14.9412s	
30235/33250 (epoch 45.466), train_loss = 0.62425663, grad/param norm = 1.3906e-01, time/batch = 14.6441s	
30236/33250 (epoch 45.468), train_loss = 0.63899622, grad/param norm = 1.5398e-01, time/batch = 14.5282s	
30237/33250 (epoch 45.469), train_loss = 0.74313816, grad/param norm = 2.1093e-01, time/batch = 14.5511s	
30238/33250 (epoch 45.471), train_loss = 0.81832180, grad/param norm = 1.5759e-01, time/batch = 17.2187s	
30239/33250 (epoch 45.472), train_loss = 0.70993721, grad/param norm = 2.1197e-01, time/batch = 15.2955s	
30240/33250 (epoch 45.474), train_loss = 0.80951566, grad/param norm = 1.6592e-01, time/batch = 16.1284s	
30241/33250 (epoch 45.475), train_loss = 0.78201676, grad/param norm = 1.6153e-01, time/batch = 16.2157s	
30242/33250 (epoch 45.477), train_loss = 0.77490468, grad/param norm = 1.9472e-01, time/batch = 15.0139s	
30243/33250 (epoch 45.478), train_loss = 0.65937394, grad/param norm = 1.7953e-01, time/batch = 14.3916s	
30244/33250 (epoch 45.480), train_loss = 0.84898254, grad/param norm = 1.9805e-01, time/batch = 15.1574s	
30245/33250 (epoch 45.481), train_loss = 0.72362303, grad/param norm = 1.7715e-01, time/batch = 14.4546s	
30246/33250 (epoch 45.483), train_loss = 0.72036651, grad/param norm = 1.9117e-01, time/batch = 14.8011s	
30247/33250 (epoch 45.484), train_loss = 0.68695827, grad/param norm = 2.1341e-01, time/batch = 14.7916s	
30248/33250 (epoch 45.486), train_loss = 0.61478747, grad/param norm = 1.9069e-01, time/batch = 14.6249s	
30249/33250 (epoch 45.487), train_loss = 0.66717147, grad/param norm = 1.8090e-01, time/batch = 17.2136s	
30250/33250 (epoch 45.489), train_loss = 0.83223339, grad/param norm = 2.3742e-01, time/batch = 15.2349s	
30251/33250 (epoch 45.490), train_loss = 0.74212356, grad/param norm = 2.1231e-01, time/batch = 17.7796s	
30252/33250 (epoch 45.492), train_loss = 0.83205912, grad/param norm = 1.9551e-01, time/batch = 15.0323s	
30253/33250 (epoch 45.493), train_loss = 0.72568149, grad/param norm = 1.5504e-01, time/batch = 14.5212s	
30254/33250 (epoch 45.495), train_loss = 0.82851428, grad/param norm = 1.6856e-01, time/batch = 14.4614s	
30255/33250 (epoch 45.496), train_loss = 0.74978391, grad/param norm = 1.5897e-01, time/batch = 14.4799s	
30256/33250 (epoch 45.498), train_loss = 0.79585184, grad/param norm = 1.8393e-01, time/batch = 15.1941s	
30257/33250 (epoch 45.499), train_loss = 0.70715149, grad/param norm = 1.8284e-01, time/batch = 14.3746s	
30258/33250 (epoch 45.501), train_loss = 0.70388278, grad/param norm = 1.9996e-01, time/batch = 14.5392s	
30259/33250 (epoch 45.502), train_loss = 0.70144537, grad/param norm = 1.6612e-01, time/batch = 14.5378s	
30260/33250 (epoch 45.504), train_loss = 0.86544025, grad/param norm = 2.3971e-01, time/batch = 15.6166s	
30261/33250 (epoch 45.505), train_loss = 0.64690699, grad/param norm = 1.4440e-01, time/batch = 16.5676s	
30262/33250 (epoch 45.507), train_loss = 0.67254949, grad/param norm = 1.6799e-01, time/batch = 14.6572s	
30263/33250 (epoch 45.508), train_loss = 0.72336851, grad/param norm = 1.7301e-01, time/batch = 16.7950s	
30264/33250 (epoch 45.510), train_loss = 0.62200153, grad/param norm = 1.5760e-01, time/batch = 14.7819s	
30265/33250 (epoch 45.511), train_loss = 0.72846139, grad/param norm = 2.0398e-01, time/batch = 14.7720s	
30266/33250 (epoch 45.513), train_loss = 0.84483803, grad/param norm = 1.8857e-01, time/batch = 14.6338s	
30267/33250 (epoch 45.514), train_loss = 0.70535357, grad/param norm = 1.7689e-01, time/batch = 14.5465s	
30268/33250 (epoch 45.516), train_loss = 0.67591772, grad/param norm = 1.7198e-01, time/batch = 14.7758s	
30269/33250 (epoch 45.517), train_loss = 0.70370366, grad/param norm = 1.5999e-01, time/batch = 14.8018s	
30270/33250 (epoch 45.519), train_loss = 0.67448782, grad/param norm = 1.4195e-01, time/batch = 15.0343s	
30271/33250 (epoch 45.520), train_loss = 0.88458421, grad/param norm = 2.0101e-01, time/batch = 16.6219s	
30272/33250 (epoch 45.522), train_loss = 0.76026543, grad/param norm = 1.9673e-01, time/batch = 17.3758s	
30273/33250 (epoch 45.523), train_loss = 0.67552012, grad/param norm = 1.8472e-01, time/batch = 15.0248s	
30274/33250 (epoch 45.525), train_loss = 0.62988265, grad/param norm = 1.6787e-01, time/batch = 17.5497s	
30275/33250 (epoch 45.526), train_loss = 0.64870356, grad/param norm = 1.6552e-01, time/batch = 14.5524s	
30276/33250 (epoch 45.528), train_loss = 0.68938112, grad/param norm = 1.5737e-01, time/batch = 14.3848s	
30277/33250 (epoch 45.529), train_loss = 0.67822233, grad/param norm = 1.6272e-01, time/batch = 14.6120s	
30278/33250 (epoch 45.531), train_loss = 0.64904740, grad/param norm = 1.5801e-01, time/batch = 14.2904s	
30279/33250 (epoch 45.532), train_loss = 0.76472504, grad/param norm = 1.6906e-01, time/batch = 14.8677s	
30280/33250 (epoch 45.534), train_loss = 0.66178096, grad/param norm = 1.5670e-01, time/batch = 15.0012s	
30281/33250 (epoch 45.535), train_loss = 0.71384981, grad/param norm = 1.8815e-01, time/batch = 15.2341s	
30282/33250 (epoch 45.537), train_loss = 0.73599223, grad/param norm = 1.6756e-01, time/batch = 15.1150s	
30283/33250 (epoch 45.538), train_loss = 0.78880247, grad/param norm = 1.7960e-01, time/batch = 16.2906s	
30284/33250 (epoch 45.540), train_loss = 0.86014389, grad/param norm = 1.7235e-01, time/batch = 14.9533s	
30285/33250 (epoch 45.541), train_loss = 0.77914731, grad/param norm = 1.9194e-01, time/batch = 15.3161s	
30286/33250 (epoch 45.543), train_loss = 0.79421050, grad/param norm = 1.5204e-01, time/batch = 14.3833s	
30287/33250 (epoch 45.544), train_loss = 0.65192468, grad/param norm = 1.9227e-01, time/batch = 14.8628s	
30288/33250 (epoch 45.546), train_loss = 0.68989357, grad/param norm = 2.0990e-01, time/batch = 14.5415s	
30289/33250 (epoch 45.547), train_loss = 0.69267683, grad/param norm = 1.8988e-01, time/batch = 14.6348s	
30290/33250 (epoch 45.549), train_loss = 0.74751852, grad/param norm = 1.7899e-01, time/batch = 14.2982s	
30291/33250 (epoch 45.550), train_loss = 0.71763156, grad/param norm = 1.8926e-01, time/batch = 14.4566s	
30292/33250 (epoch 45.552), train_loss = 0.77493489, grad/param norm = 1.6750e-01, time/batch = 14.4608s	
30293/33250 (epoch 45.553), train_loss = 0.73744924, grad/param norm = 1.6080e-01, time/batch = 14.6138s	
30294/33250 (epoch 45.555), train_loss = 0.73123274, grad/param norm = 1.7249e-01, time/batch = 14.4837s	
30295/33250 (epoch 45.556), train_loss = 0.76448046, grad/param norm = 2.5907e-01, time/batch = 14.6443s	
30296/33250 (epoch 45.558), train_loss = 0.78046730, grad/param norm = 1.8562e-01, time/batch = 14.8915s	
30297/33250 (epoch 45.559), train_loss = 0.69457295, grad/param norm = 1.8117e-01, time/batch = 14.3968s	
30298/33250 (epoch 45.561), train_loss = 0.63618747, grad/param norm = 1.8393e-01, time/batch = 14.6267s	
30299/33250 (epoch 45.562), train_loss = 0.74526205, grad/param norm = 1.9341e-01, time/batch = 14.6305s	
30300/33250 (epoch 45.564), train_loss = 0.87237154, grad/param norm = 2.2778e-01, time/batch = 14.6179s	
30301/33250 (epoch 45.565), train_loss = 0.82987530, grad/param norm = 2.5072e-01, time/batch = 14.4780s	
30302/33250 (epoch 45.567), train_loss = 0.85277036, grad/param norm = 2.0910e-01, time/batch = 14.6380s	
30303/33250 (epoch 45.568), train_loss = 0.70718760, grad/param norm = 1.9352e-01, time/batch = 14.7047s	
30304/33250 (epoch 45.570), train_loss = 0.79201061, grad/param norm = 2.1041e-01, time/batch = 14.6975s	
30305/33250 (epoch 45.571), train_loss = 0.84018143, grad/param norm = 1.9449e-01, time/batch = 14.4913s	
30306/33250 (epoch 45.573), train_loss = 0.78596032, grad/param norm = 1.9323e-01, time/batch = 14.4095s	
30307/33250 (epoch 45.574), train_loss = 0.67293242, grad/param norm = 1.5148e-01, time/batch = 14.3221s	
30308/33250 (epoch 45.576), train_loss = 0.75240855, grad/param norm = 1.6862e-01, time/batch = 15.3865s	
30309/33250 (epoch 45.577), train_loss = 0.72710270, grad/param norm = 1.7444e-01, time/batch = 14.5522s	
30310/33250 (epoch 45.579), train_loss = 0.63536889, grad/param norm = 1.6162e-01, time/batch = 15.0977s	
30311/33250 (epoch 45.580), train_loss = 0.74372447, grad/param norm = 1.7830e-01, time/batch = 14.6249s	
30312/33250 (epoch 45.582), train_loss = 0.69384610, grad/param norm = 1.7881e-01, time/batch = 14.5573s	
30313/33250 (epoch 45.583), train_loss = 0.79293323, grad/param norm = 1.7787e-01, time/batch = 14.3921s	
30314/33250 (epoch 45.585), train_loss = 0.83354661, grad/param norm = 1.6037e-01, time/batch = 14.6982s	
30315/33250 (epoch 45.586), train_loss = 0.69039983, grad/param norm = 1.7929e-01, time/batch = 14.3077s	
30316/33250 (epoch 45.588), train_loss = 0.77583854, grad/param norm = 1.7156e-01, time/batch = 14.7267s	
30317/33250 (epoch 45.589), train_loss = 0.73590899, grad/param norm = 2.0233e-01, time/batch = 16.5712s	
30318/33250 (epoch 45.591), train_loss = 0.71860039, grad/param norm = 1.9285e-01, time/batch = 14.5783s	
30319/33250 (epoch 45.592), train_loss = 0.73263675, grad/param norm = 1.8544e-01, time/batch = 14.7122s	
30320/33250 (epoch 45.594), train_loss = 0.84128155, grad/param norm = 2.1947e-01, time/batch = 14.6328s	
30321/33250 (epoch 45.595), train_loss = 0.74023033, grad/param norm = 1.7025e-01, time/batch = 14.3865s	
30322/33250 (epoch 45.597), train_loss = 0.61642905, grad/param norm = 1.3732e-01, time/batch = 14.4746s	
30323/33250 (epoch 45.598), train_loss = 0.70000207, grad/param norm = 1.9627e-01, time/batch = 14.3113s	
30324/33250 (epoch 45.600), train_loss = 0.70738164, grad/param norm = 1.8866e-01, time/batch = 15.0316s	
30325/33250 (epoch 45.602), train_loss = 0.74693780, grad/param norm = 2.2005e-01, time/batch = 14.3909s	
30326/33250 (epoch 45.603), train_loss = 0.79267760, grad/param norm = 2.2206e-01, time/batch = 14.6298s	
30327/33250 (epoch 45.605), train_loss = 0.74120590, grad/param norm = 1.9237e-01, time/batch = 14.7731s	
30328/33250 (epoch 45.606), train_loss = 0.79493114, grad/param norm = 1.8958e-01, time/batch = 14.9527s	
30329/33250 (epoch 45.608), train_loss = 0.74964344, grad/param norm = 1.8425e-01, time/batch = 14.4143s	
30330/33250 (epoch 45.609), train_loss = 0.64696769, grad/param norm = 1.7694e-01, time/batch = 14.6447s	
30331/33250 (epoch 45.611), train_loss = 0.71663498, grad/param norm = 1.9762e-01, time/batch = 14.4145s	
30332/33250 (epoch 45.612), train_loss = 0.73234875, grad/param norm = 1.8971e-01, time/batch = 14.7043s	
30333/33250 (epoch 45.614), train_loss = 0.93381866, grad/param norm = 2.1850e-01, time/batch = 14.3896s	
30334/33250 (epoch 45.615), train_loss = 0.83202511, grad/param norm = 2.0204e-01, time/batch = 14.6905s	
30335/33250 (epoch 45.617), train_loss = 0.92998912, grad/param norm = 2.1020e-01, time/batch = 14.8317s	
30336/33250 (epoch 45.618), train_loss = 0.92701831, grad/param norm = 2.4302e-01, time/batch = 15.1509s	
30337/33250 (epoch 45.620), train_loss = 0.79753139, grad/param norm = 2.0304e-01, time/batch = 15.1221s	
30338/33250 (epoch 45.621), train_loss = 0.80068858, grad/param norm = 1.8073e-01, time/batch = 14.9344s	
30339/33250 (epoch 45.623), train_loss = 0.71764445, grad/param norm = 1.8948e-01, time/batch = 14.4683s	
30340/33250 (epoch 45.624), train_loss = 0.73494674, grad/param norm = 2.1987e-01, time/batch = 15.0504s	
30341/33250 (epoch 45.626), train_loss = 0.75442918, grad/param norm = 2.4933e-01, time/batch = 14.6522s	
30342/33250 (epoch 45.627), train_loss = 0.71293414, grad/param norm = 1.9932e-01, time/batch = 14.8804s	
30343/33250 (epoch 45.629), train_loss = 0.81581195, grad/param norm = 3.0120e-01, time/batch = 14.7035s	
30344/33250 (epoch 45.630), train_loss = 0.71111956, grad/param norm = 2.2000e-01, time/batch = 14.7774s	
30345/33250 (epoch 45.632), train_loss = 0.66591533, grad/param norm = 2.0350e-01, time/batch = 14.5277s	
30346/33250 (epoch 45.633), train_loss = 0.77011987, grad/param norm = 2.1253e-01, time/batch = 14.1391s	
30347/33250 (epoch 45.635), train_loss = 0.66617056, grad/param norm = 1.5939e-01, time/batch = 14.2221s	
30348/33250 (epoch 45.636), train_loss = 0.69036811, grad/param norm = 1.6373e-01, time/batch = 14.4648s	
30349/33250 (epoch 45.638), train_loss = 0.65078474, grad/param norm = 1.7706e-01, time/batch = 14.6221s	
30350/33250 (epoch 45.639), train_loss = 0.64147736, grad/param norm = 1.7892e-01, time/batch = 14.4694s	
30351/33250 (epoch 45.641), train_loss = 0.73376129, grad/param norm = 1.9029e-01, time/batch = 14.6466s	
30352/33250 (epoch 45.642), train_loss = 0.56364553, grad/param norm = 1.8041e-01, time/batch = 15.0487s	
30353/33250 (epoch 45.644), train_loss = 0.53211722, grad/param norm = 1.6221e-01, time/batch = 14.4974s	
30354/33250 (epoch 45.645), train_loss = 0.75129833, grad/param norm = 2.0171e-01, time/batch = 14.3038s	
30355/33250 (epoch 45.647), train_loss = 0.61729090, grad/param norm = 1.7930e-01, time/batch = 14.2158s	
30356/33250 (epoch 45.648), train_loss = 0.61684120, grad/param norm = 1.8994e-01, time/batch = 14.3748s	
30357/33250 (epoch 45.650), train_loss = 0.85191412, grad/param norm = 2.4384e-01, time/batch = 14.4565s	
30358/33250 (epoch 45.651), train_loss = 0.76732661, grad/param norm = 1.9381e-01, time/batch = 14.8457s	
30359/33250 (epoch 45.653), train_loss = 0.70200424, grad/param norm = 1.7139e-01, time/batch = 14.5432s	
30360/33250 (epoch 45.654), train_loss = 0.74239837, grad/param norm = 1.9782e-01, time/batch = 14.6091s	
30361/33250 (epoch 45.656), train_loss = 0.80308607, grad/param norm = 1.6230e-01, time/batch = 15.1735s	
30362/33250 (epoch 45.657), train_loss = 0.57584214, grad/param norm = 2.1508e-01, time/batch = 14.5509s	
30363/33250 (epoch 45.659), train_loss = 0.70936575, grad/param norm = 1.8785e-01, time/batch = 14.5039s	
30364/33250 (epoch 45.660), train_loss = 0.75640788, grad/param norm = 1.8532e-01, time/batch = 15.9577s	
30365/33250 (epoch 45.662), train_loss = 0.75849677, grad/param norm = 1.8692e-01, time/batch = 14.6291s	
30366/33250 (epoch 45.663), train_loss = 0.65011759, grad/param norm = 1.7141e-01, time/batch = 14.2996s	
30367/33250 (epoch 45.665), train_loss = 0.75876807, grad/param norm = 2.5728e-01, time/batch = 14.8864s	
30368/33250 (epoch 45.666), train_loss = 0.73179339, grad/param norm = 1.7614e-01, time/batch = 14.3854s	
30369/33250 (epoch 45.668), train_loss = 0.80942471, grad/param norm = 1.9625e-01, time/batch = 14.7807s	
30370/33250 (epoch 45.669), train_loss = 0.75298638, grad/param norm = 2.2188e-01, time/batch = 14.3790s	
30371/33250 (epoch 45.671), train_loss = 0.64759935, grad/param norm = 2.0882e-01, time/batch = 14.3091s	
30372/33250 (epoch 45.672), train_loss = 0.79933117, grad/param norm = 1.7374e-01, time/batch = 14.7806s	
30373/33250 (epoch 45.674), train_loss = 0.70075444, grad/param norm = 1.8740e-01, time/batch = 14.6180s	
30374/33250 (epoch 45.675), train_loss = 0.76268840, grad/param norm = 1.6800e-01, time/batch = 14.6486s	
30375/33250 (epoch 45.677), train_loss = 0.77586916, grad/param norm = 1.9656e-01, time/batch = 14.7702s	
30376/33250 (epoch 45.678), train_loss = 0.66936445, grad/param norm = 1.9890e-01, time/batch = 14.6429s	
30377/33250 (epoch 45.680), train_loss = 0.83261798, grad/param norm = 2.3748e-01, time/batch = 14.7940s	
30378/33250 (epoch 45.681), train_loss = 0.66164440, grad/param norm = 1.6001e-01, time/batch = 14.3568s	
30379/33250 (epoch 45.683), train_loss = 0.66162926, grad/param norm = 1.5835e-01, time/batch = 14.3957s	
30380/33250 (epoch 45.684), train_loss = 0.62911772, grad/param norm = 2.0250e-01, time/batch = 14.3907s	
30381/33250 (epoch 45.686), train_loss = 0.64353663, grad/param norm = 1.7680e-01, time/batch = 15.0929s	
30382/33250 (epoch 45.687), train_loss = 0.74093589, grad/param norm = 1.7312e-01, time/batch = 14.3922s	
30383/33250 (epoch 45.689), train_loss = 0.63917923, grad/param norm = 2.0467e-01, time/batch = 14.3977s	
30384/33250 (epoch 45.690), train_loss = 0.75795506, grad/param norm = 1.9166e-01, time/batch = 15.5432s	
30385/33250 (epoch 45.692), train_loss = 0.71310920, grad/param norm = 1.6804e-01, time/batch = 22.5248s	
30386/33250 (epoch 45.693), train_loss = 0.78770426, grad/param norm = 1.8860e-01, time/batch = 24.7041s	
30387/33250 (epoch 45.695), train_loss = 0.73761881, grad/param norm = 1.9511e-01, time/batch = 15.2861s	
30388/33250 (epoch 45.696), train_loss = 0.78343945, grad/param norm = 2.2250e-01, time/batch = 14.8613s	
30389/33250 (epoch 45.698), train_loss = 0.69894353, grad/param norm = 2.0574e-01, time/batch = 14.2230s	
30390/33250 (epoch 45.699), train_loss = 0.91759882, grad/param norm = 1.9573e-01, time/batch = 15.0026s	
30391/33250 (epoch 45.701), train_loss = 0.75224963, grad/param norm = 1.6977e-01, time/batch = 14.7137s	
30392/33250 (epoch 45.702), train_loss = 0.72859136, grad/param norm = 3.5069e-01, time/batch = 15.1925s	
30393/33250 (epoch 45.704), train_loss = 0.91090285, grad/param norm = 2.3296e-01, time/batch = 14.8451s	
30394/33250 (epoch 45.705), train_loss = 0.69239876, grad/param norm = 1.7920e-01, time/batch = 15.3529s	
30395/33250 (epoch 45.707), train_loss = 0.63029791, grad/param norm = 1.7578e-01, time/batch = 15.7221s	
30396/33250 (epoch 45.708), train_loss = 0.81693584, grad/param norm = 2.0060e-01, time/batch = 16.7174s	
30397/33250 (epoch 45.710), train_loss = 0.75496820, grad/param norm = 1.9319e-01, time/batch = 16.3183s	
30398/33250 (epoch 45.711), train_loss = 0.65986222, grad/param norm = 1.8622e-01, time/batch = 15.2905s	
30399/33250 (epoch 45.713), train_loss = 0.75474672, grad/param norm = 1.6018e-01, time/batch = 14.7990s	
30400/33250 (epoch 45.714), train_loss = 0.72856041, grad/param norm = 1.8585e-01, time/batch = 15.2729s	
30401/33250 (epoch 45.716), train_loss = 0.76605884, grad/param norm = 1.8056e-01, time/batch = 14.6358s	
30402/33250 (epoch 45.717), train_loss = 0.71301460, grad/param norm = 1.4774e-01, time/batch = 14.7585s	
30403/33250 (epoch 45.719), train_loss = 0.67334392, grad/param norm = 1.8645e-01, time/batch = 15.1923s	
30404/33250 (epoch 45.720), train_loss = 0.96461216, grad/param norm = 1.9629e-01, time/batch = 14.8510s	
30405/33250 (epoch 45.722), train_loss = 0.64394889, grad/param norm = 1.7105e-01, time/batch = 15.7920s	
30406/33250 (epoch 45.723), train_loss = 0.57442284, grad/param norm = 1.2889e-01, time/batch = 15.9093s	
30407/33250 (epoch 45.725), train_loss = 0.73104936, grad/param norm = 1.6083e-01, time/batch = 16.0317s	
30408/33250 (epoch 45.726), train_loss = 0.76101867, grad/param norm = 1.8663e-01, time/batch = 16.5504s	
30409/33250 (epoch 45.728), train_loss = 0.76911125, grad/param norm = 1.8761e-01, time/batch = 14.7928s	
30410/33250 (epoch 45.729), train_loss = 0.79511729, grad/param norm = 1.8163e-01, time/batch = 14.5494s	
30411/33250 (epoch 45.731), train_loss = 0.65534178, grad/param norm = 2.0340e-01, time/batch = 14.7830s	
30412/33250 (epoch 45.732), train_loss = 0.67072617, grad/param norm = 1.7488e-01, time/batch = 14.4628s	
30413/33250 (epoch 45.734), train_loss = 0.75844917, grad/param norm = 1.8720e-01, time/batch = 14.7015s	
30414/33250 (epoch 45.735), train_loss = 0.75070946, grad/param norm = 1.7658e-01, time/batch = 14.9242s	
30415/33250 (epoch 45.737), train_loss = 0.70666266, grad/param norm = 1.5964e-01, time/batch = 14.8597s	
30416/33250 (epoch 45.738), train_loss = 0.76205150, grad/param norm = 1.8028e-01, time/batch = 16.3818s	
30417/33250 (epoch 45.740), train_loss = 0.73979666, grad/param norm = 1.7895e-01, time/batch = 17.3050s	
30418/33250 (epoch 45.741), train_loss = 0.78260373, grad/param norm = 1.5890e-01, time/batch = 14.7450s	
30419/33250 (epoch 45.743), train_loss = 0.69746397, grad/param norm = 1.6967e-01, time/batch = 15.0327s	
30420/33250 (epoch 45.744), train_loss = 0.68495209, grad/param norm = 1.8728e-01, time/batch = 14.4619s	
30421/33250 (epoch 45.746), train_loss = 0.67872879, grad/param norm = 2.0915e-01, time/batch = 15.4520s	
30422/33250 (epoch 45.747), train_loss = 0.65089039, grad/param norm = 1.7204e-01, time/batch = 14.5477s	
30423/33250 (epoch 45.749), train_loss = 0.86456244, grad/param norm = 2.5608e-01, time/batch = 15.0167s	
30424/33250 (epoch 45.750), train_loss = 0.85640676, grad/param norm = 1.8199e-01, time/batch = 14.4476s	
30425/33250 (epoch 45.752), train_loss = 0.70352708, grad/param norm = 1.8115e-01, time/batch = 14.3059s	
30426/33250 (epoch 45.753), train_loss = 0.72415467, grad/param norm = 2.4948e-01, time/batch = 14.5420s	
30427/33250 (epoch 45.755), train_loss = 0.62779415, grad/param norm = 2.0837e-01, time/batch = 14.7169s	
30428/33250 (epoch 45.756), train_loss = 0.73475204, grad/param norm = 1.7010e-01, time/batch = 15.0324s	
30429/33250 (epoch 45.758), train_loss = 0.88593266, grad/param norm = 1.7740e-01, time/batch = 14.7136s	
30430/33250 (epoch 45.759), train_loss = 0.70039553, grad/param norm = 1.6423e-01, time/batch = 17.3799s	
30431/33250 (epoch 45.761), train_loss = 0.76947397, grad/param norm = 1.9554e-01, time/batch = 15.1193s	
30432/33250 (epoch 45.762), train_loss = 0.80591064, grad/param norm = 1.8856e-01, time/batch = 14.7269s	
30433/33250 (epoch 45.764), train_loss = 0.63092802, grad/param norm = 1.8356e-01, time/batch = 14.6174s	
30434/33250 (epoch 45.765), train_loss = 0.75659947, grad/param norm = 1.9541e-01, time/batch = 14.7706s	
30435/33250 (epoch 45.767), train_loss = 0.58236253, grad/param norm = 1.5643e-01, time/batch = 14.8175s	
30436/33250 (epoch 45.768), train_loss = 0.63091169, grad/param norm = 2.0766e-01, time/batch = 14.5036s	
30437/33250 (epoch 45.770), train_loss = 0.77098052, grad/param norm = 1.9568e-01, time/batch = 14.9744s	
30438/33250 (epoch 45.771), train_loss = 0.79494020, grad/param norm = 1.9346e-01, time/batch = 15.0914s	
30439/33250 (epoch 45.773), train_loss = 0.72091512, grad/param norm = 1.8771e-01, time/batch = 15.1180s	
30440/33250 (epoch 45.774), train_loss = 0.61418085, grad/param norm = 1.8502e-01, time/batch = 16.8088s	
30441/33250 (epoch 45.776), train_loss = 0.70462312, grad/param norm = 1.8158e-01, time/batch = 18.4518s	
30442/33250 (epoch 45.777), train_loss = 0.81895889, grad/param norm = 2.0112e-01, time/batch = 16.0233s	
30443/33250 (epoch 45.779), train_loss = 0.70346536, grad/param norm = 2.0298e-01, time/batch = 14.7867s	
30444/33250 (epoch 45.780), train_loss = 0.84250685, grad/param norm = 2.2390e-01, time/batch = 15.8603s	
30445/33250 (epoch 45.782), train_loss = 0.75170897, grad/param norm = 2.2709e-01, time/batch = 14.8568s	
30446/33250 (epoch 45.783), train_loss = 0.59403459, grad/param norm = 1.8005e-01, time/batch = 15.0185s	
30447/33250 (epoch 45.785), train_loss = 0.66012126, grad/param norm = 1.9236e-01, time/batch = 14.6362s	
30448/33250 (epoch 45.786), train_loss = 0.81715217, grad/param norm = 1.9928e-01, time/batch = 14.8738s	
30449/33250 (epoch 45.788), train_loss = 0.85002495, grad/param norm = 1.9518e-01, time/batch = 15.4577s	
30450/33250 (epoch 45.789), train_loss = 0.85440860, grad/param norm = 2.4376e-01, time/batch = 14.7173s	
30451/33250 (epoch 45.791), train_loss = 0.84575950, grad/param norm = 2.2031e-01, time/batch = 15.7120s	
30452/33250 (epoch 45.792), train_loss = 0.91259884, grad/param norm = 2.1161e-01, time/batch = 14.7092s	
30453/33250 (epoch 45.794), train_loss = 0.71601226, grad/param norm = 1.8228e-01, time/batch = 14.1306s	
30454/33250 (epoch 45.795), train_loss = 0.71790586, grad/param norm = 2.0142e-01, time/batch = 14.4570s	
30455/33250 (epoch 45.797), train_loss = 0.78711871, grad/param norm = 1.9924e-01, time/batch = 15.3400s	
30456/33250 (epoch 45.798), train_loss = 0.70684448, grad/param norm = 1.9948e-01, time/batch = 14.8815s	
30457/33250 (epoch 45.800), train_loss = 0.76673368, grad/param norm = 1.9707e-01, time/batch = 14.6231s	
30458/33250 (epoch 45.802), train_loss = 0.74998964, grad/param norm = 1.6922e-01, time/batch = 14.7682s	
30459/33250 (epoch 45.803), train_loss = 0.78862008, grad/param norm = 1.7502e-01, time/batch = 14.6257s	
30460/33250 (epoch 45.805), train_loss = 0.77358341, grad/param norm = 1.9694e-01, time/batch = 14.7891s	
30461/33250 (epoch 45.806), train_loss = 0.75492433, grad/param norm = 1.8376e-01, time/batch = 14.9703s	
30462/33250 (epoch 45.808), train_loss = 0.67507920, grad/param norm = 1.8471e-01, time/batch = 15.5864s	
30463/33250 (epoch 45.809), train_loss = 0.66033167, grad/param norm = 1.5780e-01, time/batch = 15.3159s	
30464/33250 (epoch 45.811), train_loss = 0.65113355, grad/param norm = 1.9752e-01, time/batch = 14.8623s	
30465/33250 (epoch 45.812), train_loss = 0.76744211, grad/param norm = 2.2734e-01, time/batch = 14.3027s	
30466/33250 (epoch 45.814), train_loss = 0.69454471, grad/param norm = 1.8800e-01, time/batch = 14.5511s	
30467/33250 (epoch 45.815), train_loss = 0.75833743, grad/param norm = 1.9768e-01, time/batch = 14.4594s	
30468/33250 (epoch 45.817), train_loss = 0.71596638, grad/param norm = 1.7905e-01, time/batch = 14.4776s	
30469/33250 (epoch 45.818), train_loss = 0.66388461, grad/param norm = 1.6822e-01, time/batch = 14.6260s	
30470/33250 (epoch 45.820), train_loss = 0.76302146, grad/param norm = 1.8726e-01, time/batch = 14.6317s	
30471/33250 (epoch 45.821), train_loss = 0.72936206, grad/param norm = 1.5308e-01, time/batch = 15.4633s	
30472/33250 (epoch 45.823), train_loss = 0.98177215, grad/param norm = 2.1912e-01, time/batch = 15.0521s	
30473/33250 (epoch 45.824), train_loss = 0.67284421, grad/param norm = 1.6933e-01, time/batch = 15.7903s	
30474/33250 (epoch 45.826), train_loss = 0.75932485, grad/param norm = 2.2714e-01, time/batch = 15.7211s	
30475/33250 (epoch 45.827), train_loss = 0.67511030, grad/param norm = 1.6708e-01, time/batch = 14.6577s	
30476/33250 (epoch 45.829), train_loss = 0.75596593, grad/param norm = 1.8603e-01, time/batch = 14.5332s	
30477/33250 (epoch 45.830), train_loss = 0.78486380, grad/param norm = 2.1578e-01, time/batch = 14.6230s	
30478/33250 (epoch 45.832), train_loss = 0.76577200, grad/param norm = 1.9935e-01, time/batch = 14.6183s	
30479/33250 (epoch 45.833), train_loss = 0.73437968, grad/param norm = 1.8037e-01, time/batch = 14.7850s	
30480/33250 (epoch 45.835), train_loss = 0.66389058, grad/param norm = 2.3104e-01, time/batch = 14.7136s	
30481/33250 (epoch 45.836), train_loss = 0.73091866, grad/param norm = 1.8474e-01, time/batch = 14.7117s	
30482/33250 (epoch 45.838), train_loss = 0.77755213, grad/param norm = 1.9862e-01, time/batch = 16.1735s	
30483/33250 (epoch 45.839), train_loss = 0.74124199, grad/param norm = 2.3062e-01, time/batch = 16.7163s	
30484/33250 (epoch 45.841), train_loss = 0.70339436, grad/param norm = 1.9236e-01, time/batch = 16.8907s	
30485/33250 (epoch 45.842), train_loss = 0.87775221, grad/param norm = 2.3970e-01, time/batch = 16.3867s	
30486/33250 (epoch 45.844), train_loss = 0.82362657, grad/param norm = 1.9891e-01, time/batch = 15.4561s	
30487/33250 (epoch 45.845), train_loss = 0.91072131, grad/param norm = 2.2452e-01, time/batch = 15.6843s	
30488/33250 (epoch 45.847), train_loss = 0.83808297, grad/param norm = 2.3579e-01, time/batch = 14.8824s	
30489/33250 (epoch 45.848), train_loss = 0.93067789, grad/param norm = 2.2360e-01, time/batch = 15.0490s	
30490/33250 (epoch 45.850), train_loss = 0.82321981, grad/param norm = 1.7027e-01, time/batch = 15.1030s	
30491/33250 (epoch 45.851), train_loss = 0.63704156, grad/param norm = 1.9367e-01, time/batch = 14.7707s	
30492/33250 (epoch 45.853), train_loss = 0.74054176, grad/param norm = 2.0067e-01, time/batch = 14.9374s	
30493/33250 (epoch 45.854), train_loss = 0.69285019, grad/param norm = 1.6214e-01, time/batch = 15.4670s	
30494/33250 (epoch 45.856), train_loss = 0.69027831, grad/param norm = 1.9329e-01, time/batch = 14.9868s	
30495/33250 (epoch 45.857), train_loss = 0.62723644, grad/param norm = 1.7162e-01, time/batch = 14.9649s	
30496/33250 (epoch 45.859), train_loss = 0.71664029, grad/param norm = 2.3202e-01, time/batch = 15.5695s	
30497/33250 (epoch 45.860), train_loss = 0.79274247, grad/param norm = 2.0669e-01, time/batch = 14.8908s	
30498/33250 (epoch 45.862), train_loss = 0.69714794, grad/param norm = 1.9563e-01, time/batch = 14.7021s	
30499/33250 (epoch 45.863), train_loss = 0.69124273, grad/param norm = 1.7922e-01, time/batch = 14.7206s	
30500/33250 (epoch 45.865), train_loss = 0.73773949, grad/param norm = 1.8761e-01, time/batch = 14.5492s	
30501/33250 (epoch 45.866), train_loss = 0.67691991, grad/param norm = 2.1048e-01, time/batch = 14.5636s	
30502/33250 (epoch 45.868), train_loss = 0.74405327, grad/param norm = 2.3550e-01, time/batch = 15.0201s	
30503/33250 (epoch 45.869), train_loss = 0.76521192, grad/param norm = 1.9082e-01, time/batch = 14.6908s	
30504/33250 (epoch 45.871), train_loss = 0.60593107, grad/param norm = 1.5980e-01, time/batch = 14.7737s	
30505/33250 (epoch 45.872), train_loss = 0.80605103, grad/param norm = 2.3766e-01, time/batch = 14.3000s	
30506/33250 (epoch 45.874), train_loss = 0.69477674, grad/param norm = 1.9493e-01, time/batch = 14.8564s	
30507/33250 (epoch 45.875), train_loss = 0.64157813, grad/param norm = 2.5537e-01, time/batch = 14.8056s	
30508/33250 (epoch 45.877), train_loss = 0.83022895, grad/param norm = 1.9419e-01, time/batch = 15.7204s	
30509/33250 (epoch 45.878), train_loss = 0.75244394, grad/param norm = 1.8281e-01, time/batch = 14.8810s	
30510/33250 (epoch 45.880), train_loss = 0.74626533, grad/param norm = 2.1862e-01, time/batch = 14.7775s	
30511/33250 (epoch 45.881), train_loss = 0.81407137, grad/param norm = 1.8400e-01, time/batch = 14.8540s	
30512/33250 (epoch 45.883), train_loss = 0.78227569, grad/param norm = 1.9830e-01, time/batch = 14.8514s	
30513/33250 (epoch 45.884), train_loss = 0.84876764, grad/param norm = 2.3190e-01, time/batch = 14.4768s	
30514/33250 (epoch 45.886), train_loss = 0.67039132, grad/param norm = 1.5539e-01, time/batch = 14.8635s	
30515/33250 (epoch 45.887), train_loss = 0.69622496, grad/param norm = 1.7949e-01, time/batch = 14.6940s	
30516/33250 (epoch 45.889), train_loss = 0.69925564, grad/param norm = 1.5566e-01, time/batch = 14.8059s	
30517/33250 (epoch 45.890), train_loss = 0.56806259, grad/param norm = 1.5601e-01, time/batch = 15.5339s	
30518/33250 (epoch 45.892), train_loss = 0.78288653, grad/param norm = 2.1160e-01, time/batch = 15.5195s	
30519/33250 (epoch 45.893), train_loss = 0.78871079, grad/param norm = 2.0994e-01, time/batch = 14.7354s	
30520/33250 (epoch 45.895), train_loss = 0.69307875, grad/param norm = 1.8635e-01, time/batch = 14.2253s	
30521/33250 (epoch 45.896), train_loss = 0.80713010, grad/param norm = 1.7825e-01, time/batch = 14.4731s	
30522/33250 (epoch 45.898), train_loss = 0.74004128, grad/param norm = 1.9930e-01, time/batch = 15.2456s	
30523/33250 (epoch 45.899), train_loss = 0.70687248, grad/param norm = 1.8513e-01, time/batch = 14.6091s	
30524/33250 (epoch 45.901), train_loss = 0.61056031, grad/param norm = 1.5338e-01, time/batch = 14.6383s	
30525/33250 (epoch 45.902), train_loss = 0.68197887, grad/param norm = 1.8718e-01, time/batch = 14.8876s	
30526/33250 (epoch 45.904), train_loss = 0.67504580, grad/param norm = 2.0394e-01, time/batch = 15.0094s	
30527/33250 (epoch 45.905), train_loss = 0.71377777, grad/param norm = 1.4822e-01, time/batch = 15.2567s	
30528/33250 (epoch 45.907), train_loss = 0.68785171, grad/param norm = 2.0576e-01, time/batch = 14.6528s	
30529/33250 (epoch 45.908), train_loss = 0.71298553, grad/param norm = 1.5480e-01, time/batch = 16.6482s	
30530/33250 (epoch 45.910), train_loss = 0.80554763, grad/param norm = 2.2369e-01, time/batch = 14.8834s	
30531/33250 (epoch 45.911), train_loss = 0.65719413, grad/param norm = 1.9619e-01, time/batch = 14.4739s	
30532/33250 (epoch 45.913), train_loss = 0.67589951, grad/param norm = 1.5572e-01, time/batch = 14.6777s	
30533/33250 (epoch 45.914), train_loss = 0.61177353, grad/param norm = 1.6713e-01, time/batch = 14.5617s	
30534/33250 (epoch 45.916), train_loss = 0.65043812, grad/param norm = 2.2708e-01, time/batch = 15.1100s	
30535/33250 (epoch 45.917), train_loss = 0.74880860, grad/param norm = 1.4182e-01, time/batch = 14.3014s	
30536/33250 (epoch 45.919), train_loss = 0.67907154, grad/param norm = 2.8256e-01, time/batch = 14.3917s	
30537/33250 (epoch 45.920), train_loss = 0.74707575, grad/param norm = 1.8859e-01, time/batch = 14.6240s	
30538/33250 (epoch 45.922), train_loss = 0.74202750, grad/param norm = 1.8100e-01, time/batch = 14.7133s	
30539/33250 (epoch 45.923), train_loss = 0.71889907, grad/param norm = 1.9250e-01, time/batch = 15.2263s	
30540/33250 (epoch 45.925), train_loss = 0.72127217, grad/param norm = 1.8839e-01, time/batch = 15.0460s	
30541/33250 (epoch 45.926), train_loss = 0.68345434, grad/param norm = 1.7508e-01, time/batch = 16.9674s	
30542/33250 (epoch 45.928), train_loss = 0.71397188, grad/param norm = 1.8542e-01, time/batch = 15.4080s	
30543/33250 (epoch 45.929), train_loss = 0.64088238, grad/param norm = 1.4451e-01, time/batch = 14.3734s	
30544/33250 (epoch 45.931), train_loss = 0.80637167, grad/param norm = 1.8064e-01, time/batch = 14.1440s	
30545/33250 (epoch 45.932), train_loss = 0.65985829, grad/param norm = 1.7284e-01, time/batch = 14.1371s	
30546/33250 (epoch 45.934), train_loss = 0.67520968, grad/param norm = 1.6642e-01, time/batch = 14.3895s	
30547/33250 (epoch 45.935), train_loss = 0.71502946, grad/param norm = 2.1005e-01, time/batch = 14.8731s	
30548/33250 (epoch 45.937), train_loss = 0.67505636, grad/param norm = 1.9188e-01, time/batch = 14.7103s	
30549/33250 (epoch 45.938), train_loss = 0.69029617, grad/param norm = 1.7853e-01, time/batch = 14.6391s	
30550/33250 (epoch 45.940), train_loss = 0.69380421, grad/param norm = 1.8463e-01, time/batch = 14.9682s	
30551/33250 (epoch 45.941), train_loss = 0.76606767, grad/param norm = 1.9772e-01, time/batch = 15.9820s	
30552/33250 (epoch 45.943), train_loss = 0.86101663, grad/param norm = 2.0253e-01, time/batch = 15.7886s	
30553/33250 (epoch 45.944), train_loss = 0.69293986, grad/param norm = 1.7614e-01, time/batch = 17.2121s	
30554/33250 (epoch 45.946), train_loss = 0.79279560, grad/param norm = 2.0021e-01, time/batch = 15.1684s	
30555/33250 (epoch 45.947), train_loss = 0.65533003, grad/param norm = 2.1168e-01, time/batch = 14.3882s	
30556/33250 (epoch 45.949), train_loss = 0.80801548, grad/param norm = 2.0648e-01, time/batch = 14.5498s	
30557/33250 (epoch 45.950), train_loss = 0.80738486, grad/param norm = 1.9641e-01, time/batch = 14.3901s	
30558/33250 (epoch 45.952), train_loss = 0.73290059, grad/param norm = 2.0343e-01, time/batch = 15.1941s	
30559/33250 (epoch 45.953), train_loss = 0.74529143, grad/param norm = 2.2396e-01, time/batch = 14.7145s	
30560/33250 (epoch 45.955), train_loss = 0.79716404, grad/param norm = 1.8236e-01, time/batch = 16.6150s	
30561/33250 (epoch 45.956), train_loss = 0.71338175, grad/param norm = 1.9971e-01, time/batch = 15.5331s	
30562/33250 (epoch 45.958), train_loss = 0.70526156, grad/param norm = 1.8150e-01, time/batch = 15.1219s	
30563/33250 (epoch 45.959), train_loss = 0.68623561, grad/param norm = 1.6948e-01, time/batch = 17.1335s	
30564/33250 (epoch 45.961), train_loss = 0.91881303, grad/param norm = 2.2127e-01, time/batch = 14.6257s	
30565/33250 (epoch 45.962), train_loss = 0.73801281, grad/param norm = 2.2795e-01, time/batch = 14.9337s	
30566/33250 (epoch 45.964), train_loss = 0.85302148, grad/param norm = 2.1098e-01, time/batch = 16.6060s	
30567/33250 (epoch 45.965), train_loss = 0.78225817, grad/param norm = 1.9324e-01, time/batch = 14.8728s	
30568/33250 (epoch 45.967), train_loss = 0.71941458, grad/param norm = 1.9699e-01, time/batch = 15.3838s	
30569/33250 (epoch 45.968), train_loss = 0.83599648, grad/param norm = 1.6337e-01, time/batch = 14.9361s	
30570/33250 (epoch 45.970), train_loss = 0.94464074, grad/param norm = 2.5704e-01, time/batch = 14.8831s	
30571/33250 (epoch 45.971), train_loss = 0.89171782, grad/param norm = 2.1874e-01, time/batch = 14.7633s	
30572/33250 (epoch 45.973), train_loss = 0.70603890, grad/param norm = 1.6770e-01, time/batch = 16.4780s	
30573/33250 (epoch 45.974), train_loss = 0.79711828, grad/param norm = 1.9694e-01, time/batch = 15.8819s	
30574/33250 (epoch 45.976), train_loss = 0.70050631, grad/param norm = 1.7445e-01, time/batch = 15.8729s	
30575/33250 (epoch 45.977), train_loss = 0.74155452, grad/param norm = 2.0760e-01, time/batch = 14.8785s	
30576/33250 (epoch 45.979), train_loss = 0.79994107, grad/param norm = 2.0360e-01, time/batch = 14.3073s	
30577/33250 (epoch 45.980), train_loss = 0.77564609, grad/param norm = 1.7049e-01, time/batch = 14.6033s	
30578/33250 (epoch 45.982), train_loss = 0.72532572, grad/param norm = 1.6953e-01, time/batch = 14.3830s	
30579/33250 (epoch 45.983), train_loss = 0.78877083, grad/param norm = 2.0985e-01, time/batch = 14.6343s	
30580/33250 (epoch 45.985), train_loss = 0.71345671, grad/param norm = 2.1547e-01, time/batch = 14.6288s	
30581/33250 (epoch 45.986), train_loss = 0.80126552, grad/param norm = 1.9703e-01, time/batch = 15.1901s	
30582/33250 (epoch 45.988), train_loss = 0.85329211, grad/param norm = 2.1278e-01, time/batch = 15.2213s	
30583/33250 (epoch 45.989), train_loss = 0.81956756, grad/param norm = 1.8150e-01, time/batch = 16.6375s	
30584/33250 (epoch 45.991), train_loss = 0.80405428, grad/param norm = 1.9274e-01, time/batch = 14.5655s	
30585/33250 (epoch 45.992), train_loss = 0.72780252, grad/param norm = 2.1763e-01, time/batch = 14.7301s	
30586/33250 (epoch 45.994), train_loss = 0.70593712, grad/param norm = 1.8421e-01, time/batch = 15.3858s	
30587/33250 (epoch 45.995), train_loss = 0.71629559, grad/param norm = 2.0797e-01, time/batch = 15.0592s	
30588/33250 (epoch 45.997), train_loss = 0.58377843, grad/param norm = 1.5538e-01, time/batch = 14.6154s	
30589/33250 (epoch 45.998), train_loss = 0.78018696, grad/param norm = 1.8234e-01, time/batch = 14.8624s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
30590/33250 (epoch 46.000), train_loss = 0.79830212, grad/param norm = 2.0133e-01, time/batch = 14.6370s	
30591/33250 (epoch 46.002), train_loss = 0.97017338, grad/param norm = 2.0022e-01, time/batch = 14.9428s	
30592/33250 (epoch 46.003), train_loss = 0.80414232, grad/param norm = 1.9827e-01, time/batch = 14.7964s	
30593/33250 (epoch 46.005), train_loss = 0.62059193, grad/param norm = 1.5264e-01, time/batch = 14.7232s	
30594/33250 (epoch 46.006), train_loss = 0.63496236, grad/param norm = 1.9569e-01, time/batch = 15.0507s	
30595/33250 (epoch 46.008), train_loss = 0.83302083, grad/param norm = 2.1868e-01, time/batch = 14.6496s	
30596/33250 (epoch 46.009), train_loss = 0.91088720, grad/param norm = 1.9594e-01, time/batch = 14.3105s	
30597/33250 (epoch 46.011), train_loss = 0.70052672, grad/param norm = 1.8603e-01, time/batch = 14.4739s	
30598/33250 (epoch 46.012), train_loss = 0.72789970, grad/param norm = 2.3196e-01, time/batch = 14.4624s	
30599/33250 (epoch 46.014), train_loss = 0.85051703, grad/param norm = 2.7885e-01, time/batch = 14.7132s	
30600/33250 (epoch 46.015), train_loss = 0.75629464, grad/param norm = 1.6644e-01, time/batch = 14.6231s	
30601/33250 (epoch 46.017), train_loss = 0.75776846, grad/param norm = 1.9872e-01, time/batch = 14.9430s	
30602/33250 (epoch 46.018), train_loss = 0.59338279, grad/param norm = 1.8910e-01, time/batch = 14.6048s	
30603/33250 (epoch 46.020), train_loss = 0.78575771, grad/param norm = 1.8388e-01, time/batch = 14.7412s	
30604/33250 (epoch 46.021), train_loss = 0.77075299, grad/param norm = 1.9090e-01, time/batch = 16.2103s	
30605/33250 (epoch 46.023), train_loss = 0.61269528, grad/param norm = 1.9678e-01, time/batch = 16.1408s	
30606/33250 (epoch 46.024), train_loss = 0.82570056, grad/param norm = 2.6132e-01, time/batch = 15.6468s	
30607/33250 (epoch 46.026), train_loss = 0.80088573, grad/param norm = 1.8385e-01, time/batch = 16.3082s	
30608/33250 (epoch 46.027), train_loss = 0.78762955, grad/param norm = 1.8259e-01, time/batch = 15.5420s	
30609/33250 (epoch 46.029), train_loss = 0.71741628, grad/param norm = 1.7038e-01, time/batch = 14.8645s	
30610/33250 (epoch 46.030), train_loss = 0.74824080, grad/param norm = 1.9920e-01, time/batch = 14.3006s	
30611/33250 (epoch 46.032), train_loss = 0.91654489, grad/param norm = 2.1802e-01, time/batch = 14.4564s	
30612/33250 (epoch 46.033), train_loss = 0.72382404, grad/param norm = 2.1280e-01, time/batch = 14.9642s	
30613/33250 (epoch 46.035), train_loss = 0.74794907, grad/param norm = 1.8742e-01, time/batch = 14.6945s	
30614/33250 (epoch 46.036), train_loss = 0.77502895, grad/param norm = 1.9929e-01, time/batch = 15.0156s	
30615/33250 (epoch 46.038), train_loss = 0.75541698, grad/param norm = 1.5951e-01, time/batch = 15.8160s	
30616/33250 (epoch 46.039), train_loss = 0.70211042, grad/param norm = 1.6668e-01, time/batch = 16.8032s	
30617/33250 (epoch 46.041), train_loss = 0.77177039, grad/param norm = 2.9985e-01, time/batch = 14.8745s	
30618/33250 (epoch 46.042), train_loss = 0.65261837, grad/param norm = 1.8722e-01, time/batch = 17.7014s	
30619/33250 (epoch 46.044), train_loss = 0.84612627, grad/param norm = 1.9856e-01, time/batch = 14.2993s	
30620/33250 (epoch 46.045), train_loss = 0.86636397, grad/param norm = 2.1159e-01, time/batch = 15.1333s	
30621/33250 (epoch 46.047), train_loss = 0.77797451, grad/param norm = 1.8080e-01, time/batch = 27.7125s	
30622/33250 (epoch 46.048), train_loss = 0.78655469, grad/param norm = 2.0957e-01, time/batch = 15.2975s	
30623/33250 (epoch 46.050), train_loss = 0.76025634, grad/param norm = 1.9707e-01, time/batch = 14.3022s	
30624/33250 (epoch 46.051), train_loss = 0.74807441, grad/param norm = 2.0748e-01, time/batch = 14.7811s	
30625/33250 (epoch 46.053), train_loss = 0.80464457, grad/param norm = 2.3051e-01, time/batch = 16.1490s	
30626/33250 (epoch 46.054), train_loss = 0.64607119, grad/param norm = 1.5372e-01, time/batch = 15.1508s	
30627/33250 (epoch 46.056), train_loss = 0.63932923, grad/param norm = 1.8522e-01, time/batch = 15.8917s	
30628/33250 (epoch 46.057), train_loss = 0.82402190, grad/param norm = 1.8430e-01, time/batch = 14.7236s	
30629/33250 (epoch 46.059), train_loss = 0.75141870, grad/param norm = 1.8946e-01, time/batch = 14.5974s	
30630/33250 (epoch 46.060), train_loss = 0.75905109, grad/param norm = 2.0797e-01, time/batch = 15.0762s	
30631/33250 (epoch 46.062), train_loss = 0.82049560, grad/param norm = 1.7816e-01, time/batch = 14.3759s	
30632/33250 (epoch 46.063), train_loss = 0.86904436, grad/param norm = 1.9126e-01, time/batch = 14.9515s	
30633/33250 (epoch 46.065), train_loss = 0.71912357, grad/param norm = 1.9469e-01, time/batch = 14.5615s	
30634/33250 (epoch 46.066), train_loss = 0.79063157, grad/param norm = 1.8932e-01, time/batch = 14.3856s	
30635/33250 (epoch 46.068), train_loss = 0.71059440, grad/param norm = 1.7982e-01, time/batch = 14.3968s	
30636/33250 (epoch 46.069), train_loss = 0.78744962, grad/param norm = 1.7970e-01, time/batch = 15.1214s	
30637/33250 (epoch 46.071), train_loss = 0.73831404, grad/param norm = 1.7246e-01, time/batch = 15.4874s	
30638/33250 (epoch 46.072), train_loss = 0.67766067, grad/param norm = 1.5914e-01, time/batch = 15.6231s	
30639/33250 (epoch 46.074), train_loss = 0.76123189, grad/param norm = 1.8109e-01, time/batch = 15.3124s	
30640/33250 (epoch 46.075), train_loss = 0.71277895, grad/param norm = 1.7228e-01, time/batch = 15.0791s	
30641/33250 (epoch 46.077), train_loss = 0.74101673, grad/param norm = 2.4762e-01, time/batch = 14.8666s	
30642/33250 (epoch 46.078), train_loss = 0.76377077, grad/param norm = 2.0932e-01, time/batch = 14.2831s	
30643/33250 (epoch 46.080), train_loss = 0.76192158, grad/param norm = 1.9694e-01, time/batch = 14.5979s	
30644/33250 (epoch 46.081), train_loss = 0.77137026, grad/param norm = 1.6911e-01, time/batch = 14.4554s	
30645/33250 (epoch 46.083), train_loss = 0.85774155, grad/param norm = 1.8000e-01, time/batch = 14.3906s	
30646/33250 (epoch 46.084), train_loss = 0.80105016, grad/param norm = 2.1049e-01, time/batch = 14.6370s	
30647/33250 (epoch 46.086), train_loss = 0.77442588, grad/param norm = 1.7578e-01, time/batch = 15.4796s	
30648/33250 (epoch 46.087), train_loss = 0.66131837, grad/param norm = 1.6548e-01, time/batch = 15.0449s	
30649/33250 (epoch 46.089), train_loss = 0.73243523, grad/param norm = 2.0726e-01, time/batch = 16.7786s	
30650/33250 (epoch 46.090), train_loss = 0.77466779, grad/param norm = 2.0140e-01, time/batch = 16.5376s	
30651/33250 (epoch 46.092), train_loss = 0.70112025, grad/param norm = 1.4924e-01, time/batch = 16.1128s	
30652/33250 (epoch 46.093), train_loss = 0.73438007, grad/param norm = 1.8456e-01, time/batch = 14.9492s	
30653/33250 (epoch 46.095), train_loss = 0.74787533, grad/param norm = 1.9735e-01, time/batch = 15.0374s	
30654/33250 (epoch 46.096), train_loss = 0.63230202, grad/param norm = 1.9673e-01, time/batch = 14.7958s	
30655/33250 (epoch 46.098), train_loss = 0.64305101, grad/param norm = 2.2970e-01, time/batch = 14.3915s	
30656/33250 (epoch 46.099), train_loss = 0.60054038, grad/param norm = 1.6154e-01, time/batch = 15.3485s	
30657/33250 (epoch 46.101), train_loss = 0.71804027, grad/param norm = 1.9609e-01, time/batch = 14.7727s	
30658/33250 (epoch 46.102), train_loss = 0.68721289, grad/param norm = 1.6384e-01, time/batch = 14.8932s	
30659/33250 (epoch 46.104), train_loss = 0.59069453, grad/param norm = 1.6860e-01, time/batch = 16.5571s	
30660/33250 (epoch 46.105), train_loss = 0.69540458, grad/param norm = 1.7541e-01, time/batch = 14.8823s	
30661/33250 (epoch 46.107), train_loss = 0.61118527, grad/param norm = 1.4235e-01, time/batch = 15.1347s	
30662/33250 (epoch 46.108), train_loss = 0.73410109, grad/param norm = 2.1500e-01, time/batch = 14.2987s	
30663/33250 (epoch 46.110), train_loss = 0.63193890, grad/param norm = 1.7916e-01, time/batch = 14.1351s	
30664/33250 (epoch 46.111), train_loss = 0.74636902, grad/param norm = 1.8175e-01, time/batch = 14.8540s	
30665/33250 (epoch 46.113), train_loss = 0.68988190, grad/param norm = 1.9735e-01, time/batch = 14.3079s	
30666/33250 (epoch 46.114), train_loss = 0.65415331, grad/param norm = 1.9881e-01, time/batch = 14.7027s	
30667/33250 (epoch 46.116), train_loss = 0.68110105, grad/param norm = 1.8099e-01, time/batch = 14.3063s	
30668/33250 (epoch 46.117), train_loss = 0.65294848, grad/param norm = 1.7052e-01, time/batch = 14.6976s	
30669/33250 (epoch 46.119), train_loss = 0.68221172, grad/param norm = 1.6813e-01, time/batch = 14.6145s	
30670/33250 (epoch 46.120), train_loss = 0.61880738, grad/param norm = 1.5374e-01, time/batch = 15.0977s	
30671/33250 (epoch 46.122), train_loss = 0.77269590, grad/param norm = 1.7825e-01, time/batch = 16.3703s	
30672/33250 (epoch 46.123), train_loss = 0.72977219, grad/param norm = 2.0674e-01, time/batch = 16.4495s	
30673/33250 (epoch 46.125), train_loss = 0.59338702, grad/param norm = 1.9445e-01, time/batch = 15.5601s	
30674/33250 (epoch 46.126), train_loss = 0.71134503, grad/param norm = 1.9025e-01, time/batch = 15.1391s	
30675/33250 (epoch 46.128), train_loss = 0.68560960, grad/param norm = 1.5876e-01, time/batch = 15.0427s	
30676/33250 (epoch 46.129), train_loss = 0.73307631, grad/param norm = 2.0515e-01, time/batch = 15.4200s	
30677/33250 (epoch 46.131), train_loss = 0.71132026, grad/param norm = 1.7879e-01, time/batch = 14.7214s	
30678/33250 (epoch 46.132), train_loss = 0.67391755, grad/param norm = 1.7135e-01, time/batch = 14.8858s	
30679/33250 (epoch 46.134), train_loss = 0.65923764, grad/param norm = 1.8598e-01, time/batch = 14.2155s	
30680/33250 (epoch 46.135), train_loss = 0.75077581, grad/param norm = 1.6322e-01, time/batch = 14.9405s	
30681/33250 (epoch 46.137), train_loss = 0.65246928, grad/param norm = 1.9206e-01, time/batch = 14.3172s	
30682/33250 (epoch 46.138), train_loss = 0.65381067, grad/param norm = 1.6381e-01, time/batch = 14.5828s	
30683/33250 (epoch 46.140), train_loss = 0.58262668, grad/param norm = 1.9596e-01, time/batch = 15.4184s	
30684/33250 (epoch 46.141), train_loss = 0.80655795, grad/param norm = 3.3354e-01, time/batch = 15.6382s	
30685/33250 (epoch 46.143), train_loss = 0.61514031, grad/param norm = 2.0068e-01, time/batch = 15.8082s	
30686/33250 (epoch 46.144), train_loss = 0.70382886, grad/param norm = 1.6430e-01, time/batch = 14.6989s	
30687/33250 (epoch 46.146), train_loss = 0.68494817, grad/param norm = 1.6942e-01, time/batch = 14.8629s	
30688/33250 (epoch 46.147), train_loss = 0.71389926, grad/param norm = 1.8742e-01, time/batch = 14.5409s	
30689/33250 (epoch 46.149), train_loss = 0.68074664, grad/param norm = 1.6632e-01, time/batch = 14.7845s	
30690/33250 (epoch 46.150), train_loss = 0.66796052, grad/param norm = 2.1518e-01, time/batch = 14.7832s	
30691/33250 (epoch 46.152), train_loss = 0.60809645, grad/param norm = 1.5653e-01, time/batch = 16.1926s	
30692/33250 (epoch 46.153), train_loss = 0.86842204, grad/param norm = 2.0517e-01, time/batch = 14.8865s	
30693/33250 (epoch 46.155), train_loss = 0.70323446, grad/param norm = 2.4201e-01, time/batch = 17.8790s	
30694/33250 (epoch 46.156), train_loss = 0.90649315, grad/param norm = 1.9523e-01, time/batch = 15.5593s	
30695/33250 (epoch 46.158), train_loss = 0.86621719, grad/param norm = 2.3668e-01, time/batch = 14.9991s	
30696/33250 (epoch 46.159), train_loss = 0.70176936, grad/param norm = 2.1246e-01, time/batch = 15.6254s	
30697/33250 (epoch 46.161), train_loss = 0.73797223, grad/param norm = 2.3711e-01, time/batch = 14.8718s	
30698/33250 (epoch 46.162), train_loss = 0.66867154, grad/param norm = 2.1178e-01, time/batch = 15.0291s	
30699/33250 (epoch 46.164), train_loss = 0.75028790, grad/param norm = 2.2423e-01, time/batch = 14.8646s	
30700/33250 (epoch 46.165), train_loss = 0.79296377, grad/param norm = 1.8481e-01, time/batch = 15.5734s	
30701/33250 (epoch 46.167), train_loss = 0.84418760, grad/param norm = 2.0684e-01, time/batch = 15.0935s	
30702/33250 (epoch 46.168), train_loss = 0.65036327, grad/param norm = 1.4495e-01, time/batch = 14.4603s	
30703/33250 (epoch 46.170), train_loss = 0.72305430, grad/param norm = 2.0441e-01, time/batch = 15.3771s	
30704/33250 (epoch 46.171), train_loss = 0.74633414, grad/param norm = 1.7113e-01, time/batch = 16.7971s	
30705/33250 (epoch 46.173), train_loss = 0.74465191, grad/param norm = 2.0553e-01, time/batch = 15.5397s	
30706/33250 (epoch 46.174), train_loss = 0.76017134, grad/param norm = 1.6848e-01, time/batch = 17.1283s	
30707/33250 (epoch 46.176), train_loss = 0.66788524, grad/param norm = 1.7451e-01, time/batch = 14.9403s	
30708/33250 (epoch 46.177), train_loss = 0.66034976, grad/param norm = 1.6632e-01, time/batch = 14.4719s	
30709/33250 (epoch 46.179), train_loss = 0.66579236, grad/param norm = 1.6877e-01, time/batch = 14.6274s	
30710/33250 (epoch 46.180), train_loss = 0.59379660, grad/param norm = 1.7028e-01, time/batch = 14.3869s	
30711/33250 (epoch 46.182), train_loss = 0.66310541, grad/param norm = 2.4959e-01, time/batch = 14.7071s	
30712/33250 (epoch 46.183), train_loss = 0.80969417, grad/param norm = 2.0414e-01, time/batch = 14.6189s	
30713/33250 (epoch 46.185), train_loss = 0.74408572, grad/param norm = 2.3071e-01, time/batch = 14.3656s	
30714/33250 (epoch 46.186), train_loss = 0.76471580, grad/param norm = 2.2084e-01, time/batch = 15.2960s	
30715/33250 (epoch 46.188), train_loss = 0.81649541, grad/param norm = 2.8275e-01, time/batch = 15.2464s	
30716/33250 (epoch 46.189), train_loss = 0.59506288, grad/param norm = 1.9139e-01, time/batch = 15.2289s	
30717/33250 (epoch 46.191), train_loss = 0.68066256, grad/param norm = 1.9843e-01, time/batch = 16.2812s	
30718/33250 (epoch 46.192), train_loss = 0.68854157, grad/param norm = 1.7872e-01, time/batch = 15.7228s	
30719/33250 (epoch 46.194), train_loss = 0.71024658, grad/param norm = 2.0106e-01, time/batch = 15.2673s	
30720/33250 (epoch 46.195), train_loss = 0.86011126, grad/param norm = 1.9100e-01, time/batch = 14.6313s	
30721/33250 (epoch 46.197), train_loss = 0.68715765, grad/param norm = 1.8777e-01, time/batch = 14.7908s	
30722/33250 (epoch 46.198), train_loss = 0.84454824, grad/param norm = 1.9215e-01, time/batch = 14.3831s	
30723/33250 (epoch 46.200), train_loss = 0.73129165, grad/param norm = 1.7401e-01, time/batch = 14.7011s	
30724/33250 (epoch 46.202), train_loss = 0.69322730, grad/param norm = 1.5929e-01, time/batch = 14.4649s	
30725/33250 (epoch 46.203), train_loss = 0.65044994, grad/param norm = 1.8038e-01, time/batch = 14.6116s	
30726/33250 (epoch 46.205), train_loss = 0.74682557, grad/param norm = 1.7050e-01, time/batch = 16.6358s	
30727/33250 (epoch 46.206), train_loss = 0.78086201, grad/param norm = 1.8548e-01, time/batch = 15.2298s	
30728/33250 (epoch 46.208), train_loss = 0.82218266, grad/param norm = 2.2226e-01, time/batch = 16.1381s	
30729/33250 (epoch 46.209), train_loss = 0.69053470, grad/param norm = 1.5326e-01, time/batch = 15.5035s	
30730/33250 (epoch 46.211), train_loss = 0.74704176, grad/param norm = 1.7514e-01, time/batch = 14.7948s	
30731/33250 (epoch 46.212), train_loss = 0.83573673, grad/param norm = 1.8243e-01, time/batch = 14.7945s	
30732/33250 (epoch 46.214), train_loss = 0.75158129, grad/param norm = 1.7322e-01, time/batch = 14.4706s	
30733/33250 (epoch 46.215), train_loss = 0.76016323, grad/param norm = 2.3091e-01, time/batch = 14.4503s	
30734/33250 (epoch 46.217), train_loss = 0.79801650, grad/param norm = 2.0509e-01, time/batch = 15.8687s	
30735/33250 (epoch 46.218), train_loss = 0.76464322, grad/param norm = 1.6680e-01, time/batch = 15.0303s	
30736/33250 (epoch 46.220), train_loss = 0.73188334, grad/param norm = 1.6458e-01, time/batch = 14.8002s	
30737/33250 (epoch 46.221), train_loss = 0.85064927, grad/param norm = 2.2440e-01, time/batch = 15.8949s	
30738/33250 (epoch 46.223), train_loss = 0.72911403, grad/param norm = 1.6116e-01, time/batch = 16.5363s	
30739/33250 (epoch 46.224), train_loss = 0.75836656, grad/param norm = 1.8862e-01, time/batch = 16.1181s	
30740/33250 (epoch 46.226), train_loss = 0.86747639, grad/param norm = 2.0969e-01, time/batch = 15.6259s	
30741/33250 (epoch 46.227), train_loss = 0.76954666, grad/param norm = 1.8412e-01, time/batch = 14.5672s	
30742/33250 (epoch 46.229), train_loss = 0.76835575, grad/param norm = 1.7395e-01, time/batch = 14.7951s	
30743/33250 (epoch 46.230), train_loss = 0.74991488, grad/param norm = 1.9227e-01, time/batch = 14.6273s	
30744/33250 (epoch 46.232), train_loss = 0.71787298, grad/param norm = 2.0280e-01, time/batch = 14.3809s	
30745/33250 (epoch 46.233), train_loss = 0.68492760, grad/param norm = 1.7572e-01, time/batch = 14.5302s	
30746/33250 (epoch 46.235), train_loss = 0.84112367, grad/param norm = 2.0192e-01, time/batch = 14.8582s	
30747/33250 (epoch 46.236), train_loss = 0.66271230, grad/param norm = 1.8360e-01, time/batch = 14.3167s	
30748/33250 (epoch 46.238), train_loss = 0.82499206, grad/param norm = 1.9837e-01, time/batch = 14.7672s	
30749/33250 (epoch 46.239), train_loss = 0.84812566, grad/param norm = 2.6610e-01, time/batch = 16.9576s	
30750/33250 (epoch 46.241), train_loss = 0.83050662, grad/param norm = 2.2813e-01, time/batch = 15.3025s	
30751/33250 (epoch 46.242), train_loss = 0.83475429, grad/param norm = 2.3490e-01, time/batch = 15.3133s	
30752/33250 (epoch 46.244), train_loss = 0.78474517, grad/param norm = 2.6495e-01, time/batch = 14.5520s	
30753/33250 (epoch 46.245), train_loss = 0.79118774, grad/param norm = 2.3317e-01, time/batch = 14.6166s	
30754/33250 (epoch 46.247), train_loss = 0.75040454, grad/param norm = 1.8382e-01, time/batch = 14.5311s	
30755/33250 (epoch 46.248), train_loss = 0.85086320, grad/param norm = 2.4015e-01, time/batch = 14.0616s	
30756/33250 (epoch 46.250), train_loss = 0.85657507, grad/param norm = 1.7992e-01, time/batch = 14.0585s	
30757/33250 (epoch 46.251), train_loss = 0.72603831, grad/param norm = 1.7269e-01, time/batch = 14.3828s	
30758/33250 (epoch 46.253), train_loss = 0.73745538, grad/param norm = 1.7434e-01, time/batch = 14.6204s	
30759/33250 (epoch 46.254), train_loss = 0.68900031, grad/param norm = 1.5773e-01, time/batch = 15.1055s	
30760/33250 (epoch 46.256), train_loss = 0.74299248, grad/param norm = 1.7806e-01, time/batch = 15.1129s	
30761/33250 (epoch 46.257), train_loss = 0.89071194, grad/param norm = 1.9089e-01, time/batch = 14.5721s	
30762/33250 (epoch 46.259), train_loss = 0.75392484, grad/param norm = 1.9270e-01, time/batch = 16.5927s	
30763/33250 (epoch 46.260), train_loss = 0.60557070, grad/param norm = 1.6427e-01, time/batch = 14.8704s	
30764/33250 (epoch 46.262), train_loss = 0.74394097, grad/param norm = 1.7895e-01, time/batch = 14.1546s	
30765/33250 (epoch 46.263), train_loss = 0.60281032, grad/param norm = 1.6829e-01, time/batch = 14.7895s	
30766/33250 (epoch 46.265), train_loss = 0.78978986, grad/param norm = 2.3854e-01, time/batch = 14.5393s	
30767/33250 (epoch 46.266), train_loss = 0.76661103, grad/param norm = 1.9713e-01, time/batch = 14.7823s	
30768/33250 (epoch 46.268), train_loss = 0.64635203, grad/param norm = 1.7032e-01, time/batch = 14.6198s	
30769/33250 (epoch 46.269), train_loss = 0.59956172, grad/param norm = 1.6963e-01, time/batch = 14.6185s	
30770/33250 (epoch 46.271), train_loss = 0.79352838, grad/param norm = 1.8190e-01, time/batch = 15.1252s	
30771/33250 (epoch 46.272), train_loss = 0.68131497, grad/param norm = 1.5275e-01, time/batch = 15.4661s	
30772/33250 (epoch 46.274), train_loss = 0.55007460, grad/param norm = 1.5486e-01, time/batch = 17.0440s	
30773/33250 (epoch 46.275), train_loss = 0.69843747, grad/param norm = 1.4741e-01, time/batch = 15.4668s	
30774/33250 (epoch 46.277), train_loss = 0.63114082, grad/param norm = 1.9302e-01, time/batch = 16.2072s	
30775/33250 (epoch 46.278), train_loss = 0.70344612, grad/param norm = 1.7457e-01, time/batch = 15.1862s	
30776/33250 (epoch 46.280), train_loss = 0.64908418, grad/param norm = 1.6841e-01, time/batch = 14.7773s	
30777/33250 (epoch 46.281), train_loss = 0.75575327, grad/param norm = 2.0481e-01, time/batch = 14.6257s	
30778/33250 (epoch 46.283), train_loss = 0.76236629, grad/param norm = 2.7482e-01, time/batch = 15.1145s	
30779/33250 (epoch 46.284), train_loss = 0.63001248, grad/param norm = 2.2114e-01, time/batch = 14.9517s	
30780/33250 (epoch 46.286), train_loss = 0.77000495, grad/param norm = 1.9424e-01, time/batch = 15.0106s	
30781/33250 (epoch 46.287), train_loss = 0.62144420, grad/param norm = 1.6106e-01, time/batch = 15.2796s	
30782/33250 (epoch 46.289), train_loss = 0.59106644, grad/param norm = 1.9392e-01, time/batch = 16.7748s	
30783/33250 (epoch 46.290), train_loss = 0.73661289, grad/param norm = 1.7511e-01, time/batch = 16.7241s	
30784/33250 (epoch 46.292), train_loss = 0.78066291, grad/param norm = 2.5284e-01, time/batch = 16.7260s	
30785/33250 (epoch 46.293), train_loss = 0.84076952, grad/param norm = 1.9764e-01, time/batch = 16.3907s	
30786/33250 (epoch 46.295), train_loss = 0.83638549, grad/param norm = 1.9478e-01, time/batch = 15.2855s	
30787/33250 (epoch 46.296), train_loss = 0.75132622, grad/param norm = 1.7581e-01, time/batch = 15.0468s	
30788/33250 (epoch 46.298), train_loss = 0.59809113, grad/param norm = 1.5089e-01, time/batch = 14.5352s	
30789/33250 (epoch 46.299), train_loss = 0.58100261, grad/param norm = 1.7903e-01, time/batch = 14.5346s	
30790/33250 (epoch 46.301), train_loss = 0.80158058, grad/param norm = 2.0105e-01, time/batch = 14.7102s	
30791/33250 (epoch 46.302), train_loss = 0.79200861, grad/param norm = 2.0738e-01, time/batch = 15.7093s	
30792/33250 (epoch 46.304), train_loss = 0.71226829, grad/param norm = 2.0946e-01, time/batch = 15.4650s	
30793/33250 (epoch 46.305), train_loss = 0.68277769, grad/param norm = 1.8575e-01, time/batch = 14.6489s	
30794/33250 (epoch 46.307), train_loss = 0.79707633, grad/param norm = 1.9131e-01, time/batch = 15.3827s	
30795/33250 (epoch 46.308), train_loss = 0.82925211, grad/param norm = 2.1031e-01, time/batch = 16.3869s	
30796/33250 (epoch 46.310), train_loss = 0.70610588, grad/param norm = 2.1872e-01, time/batch = 16.7984s	
30797/33250 (epoch 46.311), train_loss = 0.86800130, grad/param norm = 2.1393e-01, time/batch = 14.9496s	
30798/33250 (epoch 46.313), train_loss = 0.61636268, grad/param norm = 2.0505e-01, time/batch = 15.0520s	
30799/33250 (epoch 46.314), train_loss = 0.82419492, grad/param norm = 1.8357e-01, time/batch = 14.7147s	
30800/33250 (epoch 46.316), train_loss = 0.88989221, grad/param norm = 2.1198e-01, time/batch = 14.5545s	
30801/33250 (epoch 46.317), train_loss = 0.64991486, grad/param norm = 1.5260e-01, time/batch = 14.5404s	
30802/33250 (epoch 46.319), train_loss = 0.78748834, grad/param norm = 2.5315e-01, time/batch = 14.8036s	
30803/33250 (epoch 46.320), train_loss = 0.82055451, grad/param norm = 2.5125e-01, time/batch = 14.8450s	
30804/33250 (epoch 46.322), train_loss = 0.89866408, grad/param norm = 2.2093e-01, time/batch = 14.4177s	
30805/33250 (epoch 46.323), train_loss = 0.88280155, grad/param norm = 2.3574e-01, time/batch = 15.5584s	
30806/33250 (epoch 46.325), train_loss = 0.72126689, grad/param norm = 2.1601e-01, time/batch = 14.1595s	
30807/33250 (epoch 46.326), train_loss = 0.95592053, grad/param norm = 2.0429e-01, time/batch = 14.2293s	
30808/33250 (epoch 46.328), train_loss = 0.72886477, grad/param norm = 1.8023e-01, time/batch = 14.5354s	
30809/33250 (epoch 46.329), train_loss = 0.78760601, grad/param norm = 2.3103e-01, time/batch = 14.5321s	
30810/33250 (epoch 46.331), train_loss = 0.77052376, grad/param norm = 2.4549e-01, time/batch = 14.6195s	
30811/33250 (epoch 46.332), train_loss = 0.78006166, grad/param norm = 2.2674e-01, time/batch = 14.8614s	
30812/33250 (epoch 46.334), train_loss = 0.87405723, grad/param norm = 1.9173e-01, time/batch = 14.4738s	
30813/33250 (epoch 46.335), train_loss = 0.57115332, grad/param norm = 1.8356e-01, time/batch = 14.4658s	
30814/33250 (epoch 46.337), train_loss = 0.81428973, grad/param norm = 1.9351e-01, time/batch = 14.8544s	
30815/33250 (epoch 46.338), train_loss = 0.92081392, grad/param norm = 2.1011e-01, time/batch = 15.0483s	
30816/33250 (epoch 46.340), train_loss = 0.71369225, grad/param norm = 1.5656e-01, time/batch = 17.4716s	
30817/33250 (epoch 46.341), train_loss = 0.68636008, grad/param norm = 2.1328e-01, time/batch = 17.6852s	
30818/33250 (epoch 46.343), train_loss = 0.73734354, grad/param norm = 2.3407e-01, time/batch = 15.0550s	
30819/33250 (epoch 46.344), train_loss = 0.72779960, grad/param norm = 1.8098e-01, time/batch = 14.6262s	
30820/33250 (epoch 46.346), train_loss = 0.66120954, grad/param norm = 1.9971e-01, time/batch = 14.5597s	
30821/33250 (epoch 46.347), train_loss = 0.91279678, grad/param norm = 2.5710e-01, time/batch = 15.5407s	
30822/33250 (epoch 46.349), train_loss = 0.75902881, grad/param norm = 2.2055e-01, time/batch = 14.4709s	
30823/33250 (epoch 46.350), train_loss = 0.75413761, grad/param norm = 2.0041e-01, time/batch = 14.2193s	
30824/33250 (epoch 46.352), train_loss = 0.68712104, grad/param norm = 2.0091e-01, time/batch = 14.5452s	
30825/33250 (epoch 46.353), train_loss = 0.71565501, grad/param norm = 1.7109e-01, time/batch = 15.1063s	
30826/33250 (epoch 46.355), train_loss = 0.70834337, grad/param norm = 1.8863e-01, time/batch = 15.7950s	
30827/33250 (epoch 46.356), train_loss = 0.68134704, grad/param norm = 1.9800e-01, time/batch = 15.4613s	
30828/33250 (epoch 46.358), train_loss = 0.72983209, grad/param norm = 1.6601e-01, time/batch = 16.1426s	
30829/33250 (epoch 46.359), train_loss = 0.69434564, grad/param norm = 1.8477e-01, time/batch = 15.0538s	
30830/33250 (epoch 46.361), train_loss = 0.82390241, grad/param norm = 2.0861e-01, time/batch = 15.3787s	
30831/33250 (epoch 46.362), train_loss = 0.76115925, grad/param norm = 1.7594e-01, time/batch = 14.6282s	
30832/33250 (epoch 46.364), train_loss = 0.79183240, grad/param norm = 2.0007e-01, time/batch = 14.6314s	
30833/33250 (epoch 46.365), train_loss = 0.73448684, grad/param norm = 1.6696e-01, time/batch = 14.9846s	
30834/33250 (epoch 46.367), train_loss = 0.76554813, grad/param norm = 1.6472e-01, time/batch = 14.8119s	
30835/33250 (epoch 46.368), train_loss = 0.73642597, grad/param norm = 2.0488e-01, time/batch = 14.6906s	
30836/33250 (epoch 46.370), train_loss = 0.66270812, grad/param norm = 1.7329e-01, time/batch = 14.4702s	
30837/33250 (epoch 46.371), train_loss = 0.82959148, grad/param norm = 2.2593e-01, time/batch = 14.8654s	
30838/33250 (epoch 46.373), train_loss = 0.73075197, grad/param norm = 1.6250e-01, time/batch = 14.6501s	
30839/33250 (epoch 46.374), train_loss = 0.72495932, grad/param norm = 2.3455e-01, time/batch = 17.2928s	
30840/33250 (epoch 46.376), train_loss = 0.75418680, grad/param norm = 1.8781e-01, time/batch = 16.3805s	
30841/33250 (epoch 46.377), train_loss = 0.65492174, grad/param norm = 1.9672e-01, time/batch = 15.6372s	
30842/33250 (epoch 46.379), train_loss = 0.75730840, grad/param norm = 1.9888e-01, time/batch = 14.7810s	
30843/33250 (epoch 46.380), train_loss = 0.72533864, grad/param norm = 2.3097e-01, time/batch = 14.7232s	
30844/33250 (epoch 46.382), train_loss = 0.76321516, grad/param norm = 2.0501e-01, time/batch = 14.5513s	
30845/33250 (epoch 46.383), train_loss = 0.65024299, grad/param norm = 1.7935e-01, time/batch = 14.6262s	
30846/33250 (epoch 46.385), train_loss = 0.63164594, grad/param norm = 1.7776e-01, time/batch = 14.7231s	
30847/33250 (epoch 46.386), train_loss = 0.64203009, grad/param norm = 3.2410e-01, time/batch = 14.7757s	
30848/33250 (epoch 46.388), train_loss = 0.69825268, grad/param norm = 1.9769e-01, time/batch = 14.4684s	
30849/33250 (epoch 46.389), train_loss = 0.64900844, grad/param norm = 1.9214e-01, time/batch = 15.1096s	
30850/33250 (epoch 46.391), train_loss = 0.77338810, grad/param norm = 2.3460e-01, time/batch = 16.0626s	
30851/33250 (epoch 46.392), train_loss = 0.84297657, grad/param norm = 2.2082e-01, time/batch = 17.3750s	
30852/33250 (epoch 46.394), train_loss = 0.83053121, grad/param norm = 1.9983e-01, time/batch = 16.3884s	
30853/33250 (epoch 46.395), train_loss = 0.84756706, grad/param norm = 1.7754e-01, time/batch = 14.7060s	
30854/33250 (epoch 46.397), train_loss = 0.86598704, grad/param norm = 1.9608e-01, time/batch = 15.0421s	
30855/33250 (epoch 46.398), train_loss = 0.66317467, grad/param norm = 1.6255e-01, time/batch = 15.7004s	
30856/33250 (epoch 46.400), train_loss = 0.65950871, grad/param norm = 1.7624e-01, time/batch = 14.9675s	
30857/33250 (epoch 46.402), train_loss = 0.62186468, grad/param norm = 1.8091e-01, time/batch = 28.3200s	
30858/33250 (epoch 46.403), train_loss = 0.73083855, grad/param norm = 2.1218e-01, time/batch = 14.4615s	
30859/33250 (epoch 46.405), train_loss = 0.69102044, grad/param norm = 1.5824e-01, time/batch = 17.0536s	
30860/33250 (epoch 46.406), train_loss = 0.72367881, grad/param norm = 1.9569e-01, time/batch = 16.2767s	
30861/33250 (epoch 46.408), train_loss = 0.86766186, grad/param norm = 2.0533e-01, time/batch = 15.8104s	
30862/33250 (epoch 46.409), train_loss = 0.77680509, grad/param norm = 2.4843e-01, time/batch = 15.3884s	
30863/33250 (epoch 46.411), train_loss = 0.54717706, grad/param norm = 1.5075e-01, time/batch = 14.3762s	
30864/33250 (epoch 46.412), train_loss = 0.62590212, grad/param norm = 1.7236e-01, time/batch = 14.5532s	
30865/33250 (epoch 46.414), train_loss = 0.75174646, grad/param norm = 1.9814e-01, time/batch = 14.8498s	
30866/33250 (epoch 46.415), train_loss = 0.81682662, grad/param norm = 2.2866e-01, time/batch = 14.6199s	
30867/33250 (epoch 46.417), train_loss = 0.84084517, grad/param norm = 1.9683e-01, time/batch = 14.5576s	
30868/33250 (epoch 46.418), train_loss = 0.95935312, grad/param norm = 2.1132e-01, time/batch = 14.7954s	
30869/33250 (epoch 46.420), train_loss = 0.81580363, grad/param norm = 1.9265e-01, time/batch = 14.5432s	
30870/33250 (epoch 46.421), train_loss = 0.70527663, grad/param norm = 1.7286e-01, time/batch = 14.6367s	
30871/33250 (epoch 46.423), train_loss = 0.79779015, grad/param norm = 2.0430e-01, time/batch = 14.7145s	
30872/33250 (epoch 46.424), train_loss = 0.84502569, grad/param norm = 2.5816e-01, time/batch = 15.9318s	
30873/33250 (epoch 46.426), train_loss = 0.72939200, grad/param norm = 1.5907e-01, time/batch = 15.3072s	
30874/33250 (epoch 46.427), train_loss = 0.70222784, grad/param norm = 1.9944e-01, time/batch = 15.7070s	
30875/33250 (epoch 46.429), train_loss = 0.71329965, grad/param norm = 1.8494e-01, time/batch = 15.2733s	
30876/33250 (epoch 46.430), train_loss = 0.69968447, grad/param norm = 1.9714e-01, time/batch = 14.8580s	
30877/33250 (epoch 46.432), train_loss = 0.80947084, grad/param norm = 1.6914e-01, time/batch = 14.4692s	
30878/33250 (epoch 46.433), train_loss = 0.71219800, grad/param norm = 4.9230e-01, time/batch = 14.9391s	
30879/33250 (epoch 46.435), train_loss = 0.79583120, grad/param norm = 2.0969e-01, time/batch = 14.4525s	
30880/33250 (epoch 46.436), train_loss = 0.72178731, grad/param norm = 2.0715e-01, time/batch = 14.7858s	
30881/33250 (epoch 46.438), train_loss = 0.84177585, grad/param norm = 2.0242e-01, time/batch = 14.7166s	
30882/33250 (epoch 46.439), train_loss = 0.76291062, grad/param norm = 1.9182e-01, time/batch = 14.9479s	
30883/33250 (epoch 46.441), train_loss = 0.74550762, grad/param norm = 1.8384e-01, time/batch = 14.9863s	
30884/33250 (epoch 46.442), train_loss = 0.66409060, grad/param norm = 1.7413e-01, time/batch = 15.4883s	
30885/33250 (epoch 46.444), train_loss = 0.69292689, grad/param norm = 1.5637e-01, time/batch = 15.7191s	
30886/33250 (epoch 46.445), train_loss = 0.76658934, grad/param norm = 1.6453e-01, time/batch = 14.7878s	
30887/33250 (epoch 46.447), train_loss = 0.66436025, grad/param norm = 1.9996e-01, time/batch = 14.8629s	
30888/33250 (epoch 46.448), train_loss = 0.78343097, grad/param norm = 1.8557e-01, time/batch = 15.1045s	
30889/33250 (epoch 46.450), train_loss = 0.83086436, grad/param norm = 2.1171e-01, time/batch = 14.7164s	
30890/33250 (epoch 46.451), train_loss = 0.79397633, grad/param norm = 2.1718e-01, time/batch = 14.7977s	
30891/33250 (epoch 46.453), train_loss = 0.63784983, grad/param norm = 1.4904e-01, time/batch = 14.7882s	
30892/33250 (epoch 46.454), train_loss = 0.85458878, grad/param norm = 1.8877e-01, time/batch = 14.9514s	
30893/33250 (epoch 46.456), train_loss = 0.85562661, grad/param norm = 1.6562e-01, time/batch = 16.7822s	
30894/33250 (epoch 46.457), train_loss = 0.69742102, grad/param norm = 2.1372e-01, time/batch = 17.0525s	
30895/33250 (epoch 46.459), train_loss = 0.82192192, grad/param norm = 2.3205e-01, time/batch = 16.5363s	
30896/33250 (epoch 46.460), train_loss = 0.78965482, grad/param norm = 1.9490e-01, time/batch = 15.6416s	
30897/33250 (epoch 46.462), train_loss = 0.75978759, grad/param norm = 1.9156e-01, time/batch = 14.4615s	
30898/33250 (epoch 46.463), train_loss = 0.65882562, grad/param norm = 1.4145e-01, time/batch = 14.9678s	
30899/33250 (epoch 46.465), train_loss = 0.64150584, grad/param norm = 1.5910e-01, time/batch = 14.5443s	
30900/33250 (epoch 46.466), train_loss = 0.62945589, grad/param norm = 1.7652e-01, time/batch = 14.9639s	
30901/33250 (epoch 46.468), train_loss = 0.65498347, grad/param norm = 1.5536e-01, time/batch = 14.9559s	
30902/33250 (epoch 46.469), train_loss = 0.74899408, grad/param norm = 2.0644e-01, time/batch = 15.0465s	
30903/33250 (epoch 46.471), train_loss = 0.82468828, grad/param norm = 1.8560e-01, time/batch = 14.5431s	
30904/33250 (epoch 46.472), train_loss = 0.70691009, grad/param norm = 2.1077e-01, time/batch = 17.5470s	
30905/33250 (epoch 46.474), train_loss = 0.80936150, grad/param norm = 1.8480e-01, time/batch = 15.3462s	
30906/33250 (epoch 46.475), train_loss = 0.76855431, grad/param norm = 1.6319e-01, time/batch = 16.1431s	
30907/33250 (epoch 46.477), train_loss = 0.77020485, grad/param norm = 1.7414e-01, time/batch = 15.0486s	
30908/33250 (epoch 46.478), train_loss = 0.64575011, grad/param norm = 1.8717e-01, time/batch = 14.6316s	
30909/33250 (epoch 46.480), train_loss = 0.83456362, grad/param norm = 1.7545e-01, time/batch = 14.7920s	
30910/33250 (epoch 46.481), train_loss = 0.71409900, grad/param norm = 1.6573e-01, time/batch = 14.4605s	
30911/33250 (epoch 46.483), train_loss = 0.70175861, grad/param norm = 1.8009e-01, time/batch = 14.7020s	
30912/33250 (epoch 46.484), train_loss = 0.68634140, grad/param norm = 1.7231e-01, time/batch = 14.4736s	
30913/33250 (epoch 46.486), train_loss = 0.60045954, grad/param norm = 1.7070e-01, time/batch = 14.2947s	
30914/33250 (epoch 46.487), train_loss = 0.66502366, grad/param norm = 1.9921e-01, time/batch = 14.3095s	
30915/33250 (epoch 46.489), train_loss = 0.80142530, grad/param norm = 1.8474e-01, time/batch = 15.0282s	
30916/33250 (epoch 46.490), train_loss = 0.73353032, grad/param norm = 1.9580e-01, time/batch = 15.1097s	
30917/33250 (epoch 46.492), train_loss = 0.81825920, grad/param norm = 1.8139e-01, time/batch = 14.7551s	
30918/33250 (epoch 46.493), train_loss = 0.73509009, grad/param norm = 1.8955e-01, time/batch = 15.8196s	
30919/33250 (epoch 46.495), train_loss = 0.80989492, grad/param norm = 1.5264e-01, time/batch = 14.7709s	
30920/33250 (epoch 46.496), train_loss = 0.75277331, grad/param norm = 1.6486e-01, time/batch = 14.2256s	
30921/33250 (epoch 46.498), train_loss = 0.78904602, grad/param norm = 2.0970e-01, time/batch = 14.4699s	
30922/33250 (epoch 46.499), train_loss = 0.70732977, grad/param norm = 1.8207e-01, time/batch = 14.5267s	
30923/33250 (epoch 46.501), train_loss = 0.70167301, grad/param norm = 1.9294e-01, time/batch = 14.9458s	
30924/33250 (epoch 46.502), train_loss = 0.70236145, grad/param norm = 1.7627e-01, time/batch = 14.3927s	
30925/33250 (epoch 46.504), train_loss = 0.84474283, grad/param norm = 2.1646e-01, time/batch = 14.7849s	
30926/33250 (epoch 46.505), train_loss = 0.64465993, grad/param norm = 1.5241e-01, time/batch = 15.0505s	
30927/33250 (epoch 46.507), train_loss = 0.67877551, grad/param norm = 1.7947e-01, time/batch = 15.7306s	
30928/33250 (epoch 46.508), train_loss = 0.71507424, grad/param norm = 1.6709e-01, time/batch = 16.0625s	
30929/33250 (epoch 46.510), train_loss = 0.61234547, grad/param norm = 1.4856e-01, time/batch = 14.8885s	
30930/33250 (epoch 46.511), train_loss = 0.71969768, grad/param norm = 1.9882e-01, time/batch = 14.9002s	
30931/33250 (epoch 46.513), train_loss = 0.82453510, grad/param norm = 1.7649e-01, time/batch = 15.0221s	
30932/33250 (epoch 46.514), train_loss = 0.69956390, grad/param norm = 1.6935e-01, time/batch = 14.4784s	
30933/33250 (epoch 46.516), train_loss = 0.66892681, grad/param norm = 1.8414e-01, time/batch = 14.8640s	
30934/33250 (epoch 46.517), train_loss = 0.70158368, grad/param norm = 1.6322e-01, time/batch = 14.6329s	
30935/33250 (epoch 46.519), train_loss = 0.66576921, grad/param norm = 1.4057e-01, time/batch = 14.8591s	
30936/33250 (epoch 46.520), train_loss = 0.88510121, grad/param norm = 2.0407e-01, time/batch = 14.7130s	
30937/33250 (epoch 46.522), train_loss = 0.74081569, grad/param norm = 1.7746e-01, time/batch = 14.7203s	
30938/33250 (epoch 46.523), train_loss = 0.67600250, grad/param norm = 1.8861e-01, time/batch = 15.7013s	
30939/33250 (epoch 46.525), train_loss = 0.61720348, grad/param norm = 1.7704e-01, time/batch = 14.9880s	
30940/33250 (epoch 46.526), train_loss = 0.64497039, grad/param norm = 1.6239e-01, time/batch = 14.8242s	
30941/33250 (epoch 46.528), train_loss = 0.68354320, grad/param norm = 1.8307e-01, time/batch = 16.5512s	
30942/33250 (epoch 46.529), train_loss = 0.67755048, grad/param norm = 1.9391e-01, time/batch = 14.8035s	
30943/33250 (epoch 46.531), train_loss = 0.64375540, grad/param norm = 1.6143e-01, time/batch = 15.1598s	
30944/33250 (epoch 46.532), train_loss = 0.75663413, grad/param norm = 1.7541e-01, time/batch = 14.7651s	
30945/33250 (epoch 46.534), train_loss = 0.66163503, grad/param norm = 1.5602e-01, time/batch = 14.4585s	
30946/33250 (epoch 46.535), train_loss = 0.70424654, grad/param norm = 1.6024e-01, time/batch = 14.3941s	
30947/33250 (epoch 46.537), train_loss = 0.74273006, grad/param norm = 1.7419e-01, time/batch = 14.7797s	
30948/33250 (epoch 46.538), train_loss = 0.77878647, grad/param norm = 1.7697e-01, time/batch = 14.5483s	
30949/33250 (epoch 46.540), train_loss = 0.86051628, grad/param norm = 1.7368e-01, time/batch = 16.6463s	
30950/33250 (epoch 46.541), train_loss = 0.79002975, grad/param norm = 2.0290e-01, time/batch = 15.0718s	
30951/33250 (epoch 46.543), train_loss = 0.78467994, grad/param norm = 1.6015e-01, time/batch = 14.7165s	
30952/33250 (epoch 46.544), train_loss = 0.63356498, grad/param norm = 1.7313e-01, time/batch = 16.4058s	
30953/33250 (epoch 46.546), train_loss = 0.67935912, grad/param norm = 2.0913e-01, time/batch = 14.2291s	
30954/33250 (epoch 46.547), train_loss = 0.69475819, grad/param norm = 2.0017e-01, time/batch = 14.7018s	
30955/33250 (epoch 46.549), train_loss = 0.74977911, grad/param norm = 2.0065e-01, time/batch = 15.3296s	
30956/33250 (epoch 46.550), train_loss = 0.70605902, grad/param norm = 1.7914e-01, time/batch = 14.7805s	
30957/33250 (epoch 46.552), train_loss = 0.77447345, grad/param norm = 1.7130e-01, time/batch = 14.6284s	
30958/33250 (epoch 46.553), train_loss = 0.73358702, grad/param norm = 1.5698e-01, time/batch = 15.1137s	
30959/33250 (epoch 46.555), train_loss = 0.73734771, grad/param norm = 1.8152e-01, time/batch = 14.7852s	
30960/33250 (epoch 46.556), train_loss = 0.76598397, grad/param norm = 2.4682e-01, time/batch = 15.8907s	
30961/33250 (epoch 46.558), train_loss = 0.77488381, grad/param norm = 1.9464e-01, time/batch = 15.7195s	
30962/33250 (epoch 46.559), train_loss = 0.68202558, grad/param norm = 1.5673e-01, time/batch = 14.6607s	
30963/33250 (epoch 46.561), train_loss = 0.61901463, grad/param norm = 1.5878e-01, time/batch = 16.5292s	
30964/33250 (epoch 46.562), train_loss = 0.72562281, grad/param norm = 1.8765e-01, time/batch = 14.9272s	
30965/33250 (epoch 46.564), train_loss = 0.87544808, grad/param norm = 2.1568e-01, time/batch = 14.9465s	
30966/33250 (epoch 46.565), train_loss = 0.83467904, grad/param norm = 2.0998e-01, time/batch = 14.7929s	
30967/33250 (epoch 46.567), train_loss = 0.83581907, grad/param norm = 1.8256e-01, time/batch = 14.5455s	
30968/33250 (epoch 46.568), train_loss = 0.71105428, grad/param norm = 2.4687e-01, time/batch = 14.7054s	
30969/33250 (epoch 46.570), train_loss = 0.80277708, grad/param norm = 2.1169e-01, time/batch = 14.9631s	
30970/33250 (epoch 46.571), train_loss = 0.83960660, grad/param norm = 2.1161e-01, time/batch = 14.4703s	
30971/33250 (epoch 46.573), train_loss = 0.77145869, grad/param norm = 1.8213e-01, time/batch = 14.8747s	
30972/33250 (epoch 46.574), train_loss = 0.65643571, grad/param norm = 1.4112e-01, time/batch = 17.4699s	
30973/33250 (epoch 46.576), train_loss = 0.74454764, grad/param norm = 1.8130e-01, time/batch = 16.2283s	
30974/33250 (epoch 46.577), train_loss = 0.71809346, grad/param norm = 1.6552e-01, time/batch = 16.2082s	
30975/33250 (epoch 46.579), train_loss = 0.63786717, grad/param norm = 1.7449e-01, time/batch = 14.9526s	
30976/33250 (epoch 46.580), train_loss = 0.73983420, grad/param norm = 1.8695e-01, time/batch = 14.8921s	
30977/33250 (epoch 46.582), train_loss = 0.67363533, grad/param norm = 1.9056e-01, time/batch = 14.3096s	
30978/33250 (epoch 46.583), train_loss = 0.80648526, grad/param norm = 1.8425e-01, time/batch = 14.4494s	
30979/33250 (epoch 46.585), train_loss = 0.82598770, grad/param norm = 1.7004e-01, time/batch = 14.8465s	
30980/33250 (epoch 46.586), train_loss = 0.67719869, grad/param norm = 1.9329e-01, time/batch = 15.4520s	
30981/33250 (epoch 46.588), train_loss = 0.76494675, grad/param norm = 1.7762e-01, time/batch = 15.1319s	
30982/33250 (epoch 46.589), train_loss = 0.72869231, grad/param norm = 1.8322e-01, time/batch = 15.6335s	
30983/33250 (epoch 46.591), train_loss = 0.70951636, grad/param norm = 1.8321e-01, time/batch = 16.6253s	
30984/33250 (epoch 46.592), train_loss = 0.70402650, grad/param norm = 1.6960e-01, time/batch = 15.3469s	
30985/33250 (epoch 46.594), train_loss = 0.82890921, grad/param norm = 2.0677e-01, time/batch = 16.6390s	
30986/33250 (epoch 46.595), train_loss = 0.73221209, grad/param norm = 1.8627e-01, time/batch = 15.2994s	
30987/33250 (epoch 46.597), train_loss = 0.62252216, grad/param norm = 1.5249e-01, time/batch = 14.4633s	
30988/33250 (epoch 46.598), train_loss = 0.70831994, grad/param norm = 2.2718e-01, time/batch = 15.5369s	
30989/33250 (epoch 46.600), train_loss = 0.70719761, grad/param norm = 1.9063e-01, time/batch = 14.8675s	
30990/33250 (epoch 46.602), train_loss = 0.73339786, grad/param norm = 2.0627e-01, time/batch = 14.8513s	
30991/33250 (epoch 46.603), train_loss = 0.77571261, grad/param norm = 2.0064e-01, time/batch = 15.0539s	
30992/33250 (epoch 46.605), train_loss = 0.72998555, grad/param norm = 1.9234e-01, time/batch = 14.6327s	
30993/33250 (epoch 46.606), train_loss = 0.77038454, grad/param norm = 1.7461e-01, time/batch = 17.4553s	
30994/33250 (epoch 46.608), train_loss = 0.72912348, grad/param norm = 2.0058e-01, time/batch = 15.1174s	
30995/33250 (epoch 46.609), train_loss = 0.63772050, grad/param norm = 1.7784e-01, time/batch = 15.0572s	
30996/33250 (epoch 46.611), train_loss = 0.71754484, grad/param norm = 2.1419e-01, time/batch = 16.1322s	
30997/33250 (epoch 46.612), train_loss = 0.74547338, grad/param norm = 1.9308e-01, time/batch = 16.1188s	
30998/33250 (epoch 46.614), train_loss = 0.92510209, grad/param norm = 2.4230e-01, time/batch = 15.1946s	
30999/33250 (epoch 46.615), train_loss = 0.82792223, grad/param norm = 1.8892e-01, time/batch = 14.7655s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch46.62_1.7377.t7	
31000/33250 (epoch 46.617), train_loss = 0.92766727, grad/param norm = 2.2671e-01, time/batch = 14.8502s	
31001/33250 (epoch 46.618), train_loss = 1.58104580, grad/param norm = 2.8791e-01, time/batch = 14.6929s	
31002/33250 (epoch 46.620), train_loss = 0.80648221, grad/param norm = 2.1504e-01, time/batch = 14.4534s	
31003/33250 (epoch 46.621), train_loss = 0.80831201, grad/param norm = 2.0006e-01, time/batch = 14.4410s	
31004/33250 (epoch 46.623), train_loss = 0.72551496, grad/param norm = 1.9379e-01, time/batch = 14.5436s	
31005/33250 (epoch 46.624), train_loss = 0.71967147, grad/param norm = 2.1712e-01, time/batch = 14.6320s	
31006/33250 (epoch 46.626), train_loss = 0.76552356, grad/param norm = 2.1448e-01, time/batch = 16.3977s	
31007/33250 (epoch 46.627), train_loss = 0.69664246, grad/param norm = 1.9056e-01, time/batch = 15.7190s	
31008/33250 (epoch 46.629), train_loss = 0.80363174, grad/param norm = 2.1921e-01, time/batch = 15.8533s	
31009/33250 (epoch 46.630), train_loss = 0.71167556, grad/param norm = 2.0767e-01, time/batch = 15.1437s	
31010/33250 (epoch 46.632), train_loss = 0.66371144, grad/param norm = 1.8076e-01, time/batch = 15.1401s	
31011/33250 (epoch 46.633), train_loss = 0.76150751, grad/param norm = 1.9408e-01, time/batch = 15.3965s	
31012/33250 (epoch 46.635), train_loss = 0.67096624, grad/param norm = 1.9129e-01, time/batch = 15.6373s	
31013/33250 (epoch 46.636), train_loss = 0.69690173, grad/param norm = 1.5924e-01, time/batch = 15.8010s	
31014/33250 (epoch 46.638), train_loss = 0.65826473, grad/param norm = 2.3182e-01, time/batch = 15.4841s	
31015/33250 (epoch 46.639), train_loss = 0.63770767, grad/param norm = 1.9243e-01, time/batch = 14.7332s	
31016/33250 (epoch 46.641), train_loss = 0.70586535, grad/param norm = 1.6515e-01, time/batch = 14.7968s	
31017/33250 (epoch 46.642), train_loss = 0.57423598, grad/param norm = 2.1138e-01, time/batch = 15.8724s	
31018/33250 (epoch 46.644), train_loss = 0.52997512, grad/param norm = 1.7523e-01, time/batch = 14.9478s	
31019/33250 (epoch 46.645), train_loss = 0.74986987, grad/param norm = 1.9514e-01, time/batch = 14.2554s	
31020/33250 (epoch 46.647), train_loss = 0.59786388, grad/param norm = 1.7780e-01, time/batch = 14.8236s	
31021/33250 (epoch 46.648), train_loss = 0.60308460, grad/param norm = 1.8072e-01, time/batch = 14.3011s	
31022/33250 (epoch 46.650), train_loss = 0.82115387, grad/param norm = 1.9043e-01, time/batch = 14.1318s	
31023/33250 (epoch 46.651), train_loss = 0.76031027, grad/param norm = 2.3087e-01, time/batch = 14.5606s	
31024/33250 (epoch 46.653), train_loss = 0.69390780, grad/param norm = 1.6408e-01, time/batch = 14.8730s	
31025/33250 (epoch 46.654), train_loss = 0.73282533, grad/param norm = 1.6736e-01, time/batch = 1.5586s	
31026/33250 (epoch 46.656), train_loss = 0.79631451, grad/param norm = 1.6247e-01, time/batch = 0.6638s	
31027/33250 (epoch 46.657), train_loss = 0.57231454, grad/param norm = 1.9057e-01, time/batch = 0.6628s	
31028/33250 (epoch 46.659), train_loss = 0.71137142, grad/param norm = 2.0145e-01, time/batch = 0.6638s	
31029/33250 (epoch 46.660), train_loss = 0.75430597, grad/param norm = 2.1760e-01, time/batch = 0.6793s	
31030/33250 (epoch 46.662), train_loss = 0.74088467, grad/param norm = 1.8051e-01, time/batch = 0.6775s	
31031/33250 (epoch 46.663), train_loss = 0.64768516, grad/param norm = 1.7157e-01, time/batch = 0.6634s	
31032/33250 (epoch 46.665), train_loss = 0.75958102, grad/param norm = 1.8511e-01, time/batch = 0.8107s	
31033/33250 (epoch 46.666), train_loss = 0.71407628, grad/param norm = 1.7379e-01, time/batch = 0.9662s	
31034/33250 (epoch 46.668), train_loss = 0.80507412, grad/param norm = 1.8127e-01, time/batch = 0.9699s	
31035/33250 (epoch 46.669), train_loss = 0.75469034, grad/param norm = 2.1515e-01, time/batch = 1.0220s	
31036/33250 (epoch 46.671), train_loss = 0.63694867, grad/param norm = 1.8755e-01, time/batch = 0.9850s	
31037/33250 (epoch 46.672), train_loss = 0.80440106, grad/param norm = 1.8369e-01, time/batch = 1.3226s	
31038/33250 (epoch 46.674), train_loss = 0.68392975, grad/param norm = 1.6671e-01, time/batch = 1.8516s	
31039/33250 (epoch 46.675), train_loss = 0.75162753, grad/param norm = 1.5946e-01, time/batch = 1.8274s	
31040/33250 (epoch 46.677), train_loss = 0.78319981, grad/param norm = 1.9535e-01, time/batch = 10.3388s	
31041/33250 (epoch 46.678), train_loss = 0.66858684, grad/param norm = 1.9230e-01, time/batch = 14.4749s	
31042/33250 (epoch 46.680), train_loss = 0.84700392, grad/param norm = 2.3044e-01, time/batch = 15.0290s	
31043/33250 (epoch 46.681), train_loss = 0.66522317, grad/param norm = 1.6772e-01, time/batch = 14.5588s	
31044/33250 (epoch 46.683), train_loss = 0.66230296, grad/param norm = 1.8254e-01, time/batch = 16.3764s	
31045/33250 (epoch 46.684), train_loss = 0.61861617, grad/param norm = 1.8453e-01, time/batch = 17.5621s	
31046/33250 (epoch 46.686), train_loss = 0.64068132, grad/param norm = 1.9903e-01, time/batch = 15.5152s	
31047/33250 (epoch 46.687), train_loss = 0.74945761, grad/param norm = 1.8511e-01, time/batch = 14.8833s	
31048/33250 (epoch 46.689), train_loss = 0.63586922, grad/param norm = 2.0429e-01, time/batch = 15.0073s	
31049/33250 (epoch 46.690), train_loss = 0.75502930, grad/param norm = 1.9829e-01, time/batch = 14.4732s	
31050/33250 (epoch 46.692), train_loss = 0.70292395, grad/param norm = 1.8181e-01, time/batch = 14.5451s	
31051/33250 (epoch 46.693), train_loss = 0.76356930, grad/param norm = 1.8905e-01, time/batch = 14.5506s	
31052/33250 (epoch 46.695), train_loss = 0.74185821, grad/param norm = 1.8923e-01, time/batch = 14.5459s	
31053/33250 (epoch 46.696), train_loss = 0.77510010, grad/param norm = 2.0920e-01, time/batch = 15.4679s	
31054/33250 (epoch 46.698), train_loss = 0.70543607, grad/param norm = 2.5150e-01, time/batch = 15.0635s	
31055/33250 (epoch 46.699), train_loss = 0.91507502, grad/param norm = 2.1033e-01, time/batch = 15.0764s	
31056/33250 (epoch 46.701), train_loss = 0.75405711, grad/param norm = 1.7612e-01, time/batch = 16.3121s	
31057/33250 (epoch 46.702), train_loss = 0.71706521, grad/param norm = 2.6579e-01, time/batch = 14.9498s	
31058/33250 (epoch 46.704), train_loss = 0.89890730, grad/param norm = 2.6998e-01, time/batch = 15.3301s	
31059/33250 (epoch 46.705), train_loss = 0.68541774, grad/param norm = 1.6212e-01, time/batch = 14.4491s	
31060/33250 (epoch 46.707), train_loss = 0.63104938, grad/param norm = 1.7058e-01, time/batch = 14.7125s	
31061/33250 (epoch 46.708), train_loss = 0.82039492, grad/param norm = 1.9830e-01, time/batch = 14.8705s	
31062/33250 (epoch 46.710), train_loss = 0.76564046, grad/param norm = 2.2243e-01, time/batch = 14.8618s	
31063/33250 (epoch 46.711), train_loss = 0.66472861, grad/param norm = 1.9508e-01, time/batch = 14.7151s	
31064/33250 (epoch 46.713), train_loss = 0.75065963, grad/param norm = 1.6909e-01, time/batch = 15.0559s	
31065/33250 (epoch 46.714), train_loss = 0.69676036, grad/param norm = 1.7513e-01, time/batch = 16.1437s	
31066/33250 (epoch 46.716), train_loss = 0.75056477, grad/param norm = 1.8208e-01, time/batch = 16.5433s	
31067/33250 (epoch 46.717), train_loss = 0.70756432, grad/param norm = 1.5333e-01, time/batch = 15.2000s	
31068/33250 (epoch 46.719), train_loss = 0.66741885, grad/param norm = 1.7157e-01, time/batch = 14.7953s	
31069/33250 (epoch 46.720), train_loss = 0.94681217, grad/param norm = 1.8045e-01, time/batch = 15.0415s	
31070/33250 (epoch 46.722), train_loss = 0.64707266, grad/param norm = 1.6649e-01, time/batch = 14.9473s	
31071/33250 (epoch 46.723), train_loss = 0.58523858, grad/param norm = 1.7169e-01, time/batch = 15.0376s	
31072/33250 (epoch 46.725), train_loss = 0.71683134, grad/param norm = 1.6136e-01, time/batch = 14.6946s	
31073/33250 (epoch 46.726), train_loss = 0.76008710, grad/param norm = 1.7737e-01, time/batch = 14.8714s	
31074/33250 (epoch 46.728), train_loss = 0.76688939, grad/param norm = 1.9150e-01, time/batch = 14.7889s	
31075/33250 (epoch 46.729), train_loss = 0.79074529, grad/param norm = 1.8450e-01, time/batch = 14.6410s	
31076/33250 (epoch 46.731), train_loss = 0.64468817, grad/param norm = 1.8647e-01, time/batch = 15.8049s	
31077/33250 (epoch 46.732), train_loss = 0.65773376, grad/param norm = 1.5750e-01, time/batch = 15.0260s	
31078/33250 (epoch 46.734), train_loss = 0.75369584, grad/param norm = 2.1450e-01, time/batch = 14.9641s	
31079/33250 (epoch 46.735), train_loss = 0.74931002, grad/param norm = 1.9520e-01, time/batch = 16.0562s	
31080/33250 (epoch 46.737), train_loss = 0.71618261, grad/param norm = 1.7358e-01, time/batch = 14.7129s	
31081/33250 (epoch 46.738), train_loss = 0.76767349, grad/param norm = 2.2623e-01, time/batch = 14.6243s	
31082/33250 (epoch 46.740), train_loss = 0.73600056, grad/param norm = 1.7398e-01, time/batch = 15.0849s	
31083/33250 (epoch 46.741), train_loss = 0.78864437, grad/param norm = 1.8323e-01, time/batch = 14.7761s	
31084/33250 (epoch 46.743), train_loss = 0.69616853, grad/param norm = 1.7265e-01, time/batch = 14.4729s	
31085/33250 (epoch 46.744), train_loss = 0.68087636, grad/param norm = 1.7740e-01, time/batch = 14.4794s	
31086/33250 (epoch 46.746), train_loss = 0.66409991, grad/param norm = 1.5427e-01, time/batch = 14.8576s	
31087/33250 (epoch 46.747), train_loss = 0.64776141, grad/param norm = 1.8419e-01, time/batch = 15.7900s	
31088/33250 (epoch 46.749), train_loss = 0.81716048, grad/param norm = 1.9360e-01, time/batch = 15.1070s	
31089/33250 (epoch 46.750), train_loss = 0.83981978, grad/param norm = 1.8478e-01, time/batch = 17.4445s	
31090/33250 (epoch 46.752), train_loss = 0.70493354, grad/param norm = 1.8293e-01, time/batch = 15.3048s	
31091/33250 (epoch 46.753), train_loss = 0.70504348, grad/param norm = 1.9727e-01, time/batch = 14.6309s	
31092/33250 (epoch 46.755), train_loss = 0.61619287, grad/param norm = 2.2474e-01, time/batch = 14.7100s	
31093/33250 (epoch 46.756), train_loss = 0.73781041, grad/param norm = 1.8185e-01, time/batch = 14.3099s	
31094/33250 (epoch 46.758), train_loss = 0.88261986, grad/param norm = 1.7710e-01, time/batch = 14.4413s	
31095/33250 (epoch 46.759), train_loss = 0.69626873, grad/param norm = 1.6344e-01, time/batch = 14.5512s	
31096/33250 (epoch 46.761), train_loss = 0.77009407, grad/param norm = 2.0966e-01, time/batch = 14.6318s	
31097/33250 (epoch 46.762), train_loss = 0.80027757, grad/param norm = 2.0475e-01, time/batch = 15.4739s	
31098/33250 (epoch 46.764), train_loss = 0.64801028, grad/param norm = 2.1984e-01, time/batch = 29.9970s	
31099/33250 (epoch 46.765), train_loss = 0.76387359, grad/param norm = 2.1347e-01, time/batch = 15.7953s	
31100/33250 (epoch 46.767), train_loss = 0.58942214, grad/param norm = 1.7960e-01, time/batch = 16.3618s	
31101/33250 (epoch 46.768), train_loss = 0.62196070, grad/param norm = 1.8578e-01, time/batch = 15.1151s	
31102/33250 (epoch 46.770), train_loss = 0.76567220, grad/param norm = 1.9752e-01, time/batch = 15.1349s	
31103/33250 (epoch 46.771), train_loss = 0.79970931, grad/param norm = 2.0997e-01, time/batch = 14.7120s	
31104/33250 (epoch 46.773), train_loss = 0.72288845, grad/param norm = 2.3619e-01, time/batch = 15.0190s	
31105/33250 (epoch 46.774), train_loss = 0.60845815, grad/param norm = 1.8725e-01, time/batch = 14.9539s	
31106/33250 (epoch 46.776), train_loss = 0.70981003, grad/param norm = 1.9008e-01, time/batch = 14.7576s	
31107/33250 (epoch 46.777), train_loss = 0.82408556, grad/param norm = 2.0432e-01, time/batch = 15.4444s	
31108/33250 (epoch 46.779), train_loss = 0.69509401, grad/param norm = 1.8593e-01, time/batch = 17.1998s	
31109/33250 (epoch 46.780), train_loss = 0.85540094, grad/param norm = 2.3810e-01, time/batch = 16.7217s	
31110/33250 (epoch 46.782), train_loss = 0.75105460, grad/param norm = 2.7686e-01, time/batch = 15.2345s	
31111/33250 (epoch 46.783), train_loss = 0.59693898, grad/param norm = 1.6488e-01, time/batch = 15.6304s	
31112/33250 (epoch 46.785), train_loss = 0.64732749, grad/param norm = 1.6583e-01, time/batch = 14.7652s	
31113/33250 (epoch 46.786), train_loss = 0.81737147, grad/param norm = 2.2008e-01, time/batch = 14.8763s	
31114/33250 (epoch 46.788), train_loss = 0.85141445, grad/param norm = 1.9159e-01, time/batch = 14.6302s	
31115/33250 (epoch 46.789), train_loss = 0.83705111, grad/param norm = 2.0921e-01, time/batch = 15.1108s	
31116/33250 (epoch 46.791), train_loss = 0.84136399, grad/param norm = 2.0703e-01, time/batch = 15.2776s	
31117/33250 (epoch 46.792), train_loss = 0.91659649, grad/param norm = 2.0744e-01, time/batch = 14.6698s	
31118/33250 (epoch 46.794), train_loss = 0.70016997, grad/param norm = 1.8508e-01, time/batch = 16.8807s	
31119/33250 (epoch 46.795), train_loss = 0.71686090, grad/param norm = 1.8614e-01, time/batch = 15.9849s	
31120/33250 (epoch 46.797), train_loss = 0.78527711, grad/param norm = 1.9877e-01, time/batch = 15.0537s	
31121/33250 (epoch 46.798), train_loss = 0.69450337, grad/param norm = 1.8605e-01, time/batch = 18.0356s	
31122/33250 (epoch 46.800), train_loss = 0.74562279, grad/param norm = 1.8790e-01, time/batch = 14.7152s	
31123/33250 (epoch 46.802), train_loss = 0.74651304, grad/param norm = 1.6530e-01, time/batch = 15.4601s	
31124/33250 (epoch 46.803), train_loss = 0.77902432, grad/param norm = 1.6608e-01, time/batch = 14.9596s	
31125/33250 (epoch 46.805), train_loss = 0.77211608, grad/param norm = 1.8391e-01, time/batch = 15.8710s	
31126/33250 (epoch 46.806), train_loss = 0.73370719, grad/param norm = 1.7995e-01, time/batch = 14.7922s	
31127/33250 (epoch 46.808), train_loss = 0.66920785, grad/param norm = 1.7278e-01, time/batch = 14.3544s	
31128/33250 (epoch 46.809), train_loss = 0.65405427, grad/param norm = 1.5168e-01, time/batch = 14.7854s	
31129/33250 (epoch 46.811), train_loss = 0.63895602, grad/param norm = 1.9856e-01, time/batch = 17.2044s	
31130/33250 (epoch 46.812), train_loss = 0.75135742, grad/param norm = 1.9799e-01, time/batch = 15.2807s	
31131/33250 (epoch 46.814), train_loss = 0.69915200, grad/param norm = 2.2722e-01, time/batch = 16.0506s	
31132/33250 (epoch 46.815), train_loss = 0.76022460, grad/param norm = 1.7734e-01, time/batch = 17.2183s	
31133/33250 (epoch 46.817), train_loss = 0.69827352, grad/param norm = 1.7710e-01, time/batch = 14.3900s	
31134/33250 (epoch 46.818), train_loss = 0.65961252, grad/param norm = 1.7511e-01, time/batch = 14.4653s	
31135/33250 (epoch 46.820), train_loss = 0.76154865, grad/param norm = 1.7501e-01, time/batch = 14.9377s	
31136/33250 (epoch 46.821), train_loss = 0.72503309, grad/param norm = 1.5318e-01, time/batch = 14.6199s	
31137/33250 (epoch 46.823), train_loss = 0.96752860, grad/param norm = 2.3485e-01, time/batch = 14.6339s	
31138/33250 (epoch 46.824), train_loss = 0.68142124, grad/param norm = 2.3911e-01, time/batch = 14.7980s	
31139/33250 (epoch 46.826), train_loss = 0.74668847, grad/param norm = 1.8067e-01, time/batch = 14.8748s	
31140/33250 (epoch 46.827), train_loss = 0.68428514, grad/param norm = 1.7263e-01, time/batch = 15.9571s	
31141/33250 (epoch 46.829), train_loss = 0.75361705, grad/param norm = 1.8536e-01, time/batch = 16.2094s	
31142/33250 (epoch 46.830), train_loss = 0.80519589, grad/param norm = 3.0257e-01, time/batch = 17.6935s	
31143/33250 (epoch 46.832), train_loss = 0.76314098, grad/param norm = 1.9568e-01, time/batch = 15.4655s	
31144/33250 (epoch 46.833), train_loss = 0.72363127, grad/param norm = 1.9072e-01, time/batch = 16.4520s	
31145/33250 (epoch 46.835), train_loss = 0.65662521, grad/param norm = 2.0753e-01, time/batch = 14.8605s	
31146/33250 (epoch 46.836), train_loss = 0.72665042, grad/param norm = 1.9182e-01, time/batch = 15.8818s	
31147/33250 (epoch 46.838), train_loss = 0.76359172, grad/param norm = 1.8553e-01, time/batch = 14.4570s	
31148/33250 (epoch 46.839), train_loss = 0.71847344, grad/param norm = 1.9430e-01, time/batch = 14.6129s	
31149/33250 (epoch 46.841), train_loss = 0.70054361, grad/param norm = 1.8220e-01, time/batch = 14.2898s	
31150/33250 (epoch 46.842), train_loss = 0.87246066, grad/param norm = 2.8754e-01, time/batch = 14.3815s	
31151/33250 (epoch 46.844), train_loss = 0.80788029, grad/param norm = 1.9215e-01, time/batch = 14.5598s	
31152/33250 (epoch 46.845), train_loss = 0.89375274, grad/param norm = 2.3307e-01, time/batch = 15.4012s	
31153/33250 (epoch 46.847), train_loss = 0.80979509, grad/param norm = 1.7663e-01, time/batch = 15.6339s	
31154/33250 (epoch 46.848), train_loss = 0.91317270, grad/param norm = 2.3646e-01, time/batch = 15.6460s	
31155/33250 (epoch 46.850), train_loss = 0.82818613, grad/param norm = 1.9525e-01, time/batch = 14.6920s	
31156/33250 (epoch 46.851), train_loss = 0.64001473, grad/param norm = 1.9367e-01, time/batch = 14.2173s	
31157/33250 (epoch 46.853), train_loss = 0.74387091, grad/param norm = 2.2445e-01, time/batch = 14.2292s	
31158/33250 (epoch 46.854), train_loss = 0.68455241, grad/param norm = 1.6135e-01, time/batch = 14.6367s	
31159/33250 (epoch 46.856), train_loss = 0.67454068, grad/param norm = 1.7083e-01, time/batch = 14.5402s	
31160/33250 (epoch 46.857), train_loss = 0.62759913, grad/param norm = 1.9016e-01, time/batch = 14.4702s	
31161/33250 (epoch 46.859), train_loss = 0.70577870, grad/param norm = 1.9594e-01, time/batch = 14.5537s	
31162/33250 (epoch 46.860), train_loss = 0.79350542, grad/param norm = 1.9593e-01, time/batch = 14.6264s	
31163/33250 (epoch 46.862), train_loss = 0.66993152, grad/param norm = 1.8331e-01, time/batch = 15.2827s	
31164/33250 (epoch 46.863), train_loss = 0.70379569, grad/param norm = 2.1497e-01, time/batch = 15.8036s	
31165/33250 (epoch 46.865), train_loss = 0.74468113, grad/param norm = 2.1012e-01, time/batch = 15.8436s	
31166/33250 (epoch 46.866), train_loss = 0.66093150, grad/param norm = 2.0218e-01, time/batch = 16.9596s	
31167/33250 (epoch 46.868), train_loss = 0.73799826, grad/param norm = 2.5450e-01, time/batch = 14.7952s	
31168/33250 (epoch 46.869), train_loss = 0.75222410, grad/param norm = 1.8159e-01, time/batch = 15.4566s	
31169/33250 (epoch 46.871), train_loss = 0.60294371, grad/param norm = 1.4025e-01, time/batch = 14.7205s	
31170/33250 (epoch 46.872), train_loss = 0.79185991, grad/param norm = 2.0222e-01, time/batch = 14.7431s	
31171/33250 (epoch 46.874), train_loss = 0.69373082, grad/param norm = 1.9084e-01, time/batch = 15.0402s	
31172/33250 (epoch 46.875), train_loss = 0.63226672, grad/param norm = 2.4107e-01, time/batch = 14.3852s	
31173/33250 (epoch 46.877), train_loss = 0.84017821, grad/param norm = 1.9344e-01, time/batch = 14.3877s	
31174/33250 (epoch 46.878), train_loss = 0.75641336, grad/param norm = 1.9058e-01, time/batch = 16.0545s	
31175/33250 (epoch 46.880), train_loss = 0.72514873, grad/param norm = 1.8587e-01, time/batch = 14.6209s	
31176/33250 (epoch 46.881), train_loss = 0.83872447, grad/param norm = 3.0890e-01, time/batch = 14.5719s	
31177/33250 (epoch 46.883), train_loss = 0.79363339, grad/param norm = 2.0589e-01, time/batch = 14.6193s	
31178/33250 (epoch 46.884), train_loss = 0.85219944, grad/param norm = 2.2790e-01, time/batch = 14.1437s	
31179/33250 (epoch 46.886), train_loss = 0.67527189, grad/param norm = 1.7304e-01, time/batch = 15.0066s	
31180/33250 (epoch 46.887), train_loss = 0.70192694, grad/param norm = 2.1697e-01, time/batch = 14.3877s	
31181/33250 (epoch 46.889), train_loss = 0.70048637, grad/param norm = 1.5655e-01, time/batch = 14.3929s	
31182/33250 (epoch 46.890), train_loss = 0.56294254, grad/param norm = 1.4147e-01, time/batch = 15.2127s	
31183/33250 (epoch 46.892), train_loss = 0.77612641, grad/param norm = 1.9118e-01, time/batch = 14.8599s	
31184/33250 (epoch 46.893), train_loss = 0.77446944, grad/param norm = 1.8693e-01, time/batch = 15.8690s	
31185/33250 (epoch 46.895), train_loss = 0.70282947, grad/param norm = 2.1781e-01, time/batch = 15.7771s	
31186/33250 (epoch 46.896), train_loss = 0.80312770, grad/param norm = 1.8968e-01, time/batch = 17.4647s	
31187/33250 (epoch 46.898), train_loss = 0.73269619, grad/param norm = 1.7702e-01, time/batch = 16.0326s	
31188/33250 (epoch 46.899), train_loss = 0.68904885, grad/param norm = 1.6377e-01, time/batch = 16.4558s	
31189/33250 (epoch 46.901), train_loss = 0.60865495, grad/param norm = 1.6389e-01, time/batch = 15.5276s	
31190/33250 (epoch 46.902), train_loss = 0.68821747, grad/param norm = 2.0886e-01, time/batch = 14.3794s	
31191/33250 (epoch 46.904), train_loss = 0.67416804, grad/param norm = 1.8061e-01, time/batch = 16.8646s	
31192/33250 (epoch 46.905), train_loss = 0.71121300, grad/param norm = 1.5853e-01, time/batch = 15.1093s	
31193/33250 (epoch 46.907), train_loss = 0.67524165, grad/param norm = 1.7164e-01, time/batch = 15.3324s	
31194/33250 (epoch 46.908), train_loss = 0.72145189, grad/param norm = 1.6034e-01, time/batch = 15.2397s	
31195/33250 (epoch 46.910), train_loss = 0.80892817, grad/param norm = 2.3241e-01, time/batch = 15.2035s	
31196/33250 (epoch 46.911), train_loss = 0.65443014, grad/param norm = 1.8933e-01, time/batch = 16.2691s	
31197/33250 (epoch 46.913), train_loss = 0.66765547, grad/param norm = 1.6203e-01, time/batch = 16.8195s	
31198/33250 (epoch 46.914), train_loss = 0.60398802, grad/param norm = 2.0415e-01, time/batch = 15.5591s	
31199/33250 (epoch 46.916), train_loss = 0.64118553, grad/param norm = 1.6865e-01, time/batch = 18.3778s	
31200/33250 (epoch 46.917), train_loss = 0.73846971, grad/param norm = 1.4653e-01, time/batch = 14.4819s	
31201/33250 (epoch 46.919), train_loss = 0.64922252, grad/param norm = 2.3457e-01, time/batch = 15.2176s	
31202/33250 (epoch 46.920), train_loss = 0.74914814, grad/param norm = 2.0457e-01, time/batch = 15.0921s	
31203/33250 (epoch 46.922), train_loss = 0.74400265, grad/param norm = 1.9380e-01, time/batch = 14.6289s	
31204/33250 (epoch 46.923), train_loss = 0.70609273, grad/param norm = 1.9645e-01, time/batch = 14.9274s	
31205/33250 (epoch 46.925), train_loss = 0.70752036, grad/param norm = 1.7948e-01, time/batch = 14.3850s	
31206/33250 (epoch 46.926), train_loss = 0.67262178, grad/param norm = 1.6331e-01, time/batch = 14.7067s	
31207/33250 (epoch 46.928), train_loss = 0.71325579, grad/param norm = 1.8805e-01, time/batch = 16.7280s	
31208/33250 (epoch 46.929), train_loss = 0.63538851, grad/param norm = 1.4358e-01, time/batch = 15.4856s	
31209/33250 (epoch 46.931), train_loss = 0.81856815, grad/param norm = 2.1807e-01, time/batch = 17.8616s	
31210/33250 (epoch 46.932), train_loss = 0.65517542, grad/param norm = 1.8162e-01, time/batch = 15.7212s	
31211/33250 (epoch 46.934), train_loss = 0.65083686, grad/param norm = 1.5721e-01, time/batch = 16.4515s	
31212/33250 (epoch 46.935), train_loss = 0.70722654, grad/param norm = 1.8466e-01, time/batch = 14.6272s	
31213/33250 (epoch 46.937), train_loss = 0.66598503, grad/param norm = 1.8899e-01, time/batch = 14.7066s	
31214/33250 (epoch 46.938), train_loss = 0.68472758, grad/param norm = 1.9448e-01, time/batch = 14.7797s	
31215/33250 (epoch 46.940), train_loss = 0.69597099, grad/param norm = 1.8016e-01, time/batch = 14.5399s	
31216/33250 (epoch 46.941), train_loss = 0.77248024, grad/param norm = 1.8943e-01, time/batch = 15.1776s	
31217/33250 (epoch 46.943), train_loss = 0.84784854, grad/param norm = 1.9806e-01, time/batch = 15.0240s	
31218/33250 (epoch 46.944), train_loss = 0.68988174, grad/param norm = 1.9058e-01, time/batch = 15.3097s	
31219/33250 (epoch 46.946), train_loss = 0.79001868, grad/param norm = 2.4402e-01, time/batch = 15.1469s	
31220/33250 (epoch 46.947), train_loss = 0.66213959, grad/param norm = 2.0418e-01, time/batch = 15.2454s	
31221/33250 (epoch 46.949), train_loss = 0.79183406, grad/param norm = 2.1397e-01, time/batch = 14.7924s	
31222/33250 (epoch 46.950), train_loss = 0.80190181, grad/param norm = 2.0247e-01, time/batch = 14.6397s	
31223/33250 (epoch 46.952), train_loss = 0.72355176, grad/param norm = 1.9303e-01, time/batch = 14.9222s	
31224/33250 (epoch 46.953), train_loss = 0.73783702, grad/param norm = 2.2062e-01, time/batch = 14.4658s	
31225/33250 (epoch 46.955), train_loss = 0.79172425, grad/param norm = 1.8167e-01, time/batch = 14.7089s	
31226/33250 (epoch 46.956), train_loss = 0.71469429, grad/param norm = 2.2300e-01, time/batch = 14.7965s	
31227/33250 (epoch 46.958), train_loss = 0.69334571, grad/param norm = 1.7493e-01, time/batch = 15.2154s	
31228/33250 (epoch 46.959), train_loss = 0.69179055, grad/param norm = 1.8754e-01, time/batch = 14.8592s	
31229/33250 (epoch 46.961), train_loss = 0.90658931, grad/param norm = 2.0463e-01, time/batch = 16.1121s	
31230/33250 (epoch 46.962), train_loss = 0.71834790, grad/param norm = 1.9076e-01, time/batch = 15.2323s	
31231/33250 (epoch 46.964), train_loss = 0.85418798, grad/param norm = 2.1032e-01, time/batch = 16.6408s	
31232/33250 (epoch 46.965), train_loss = 0.78817649, grad/param norm = 1.9800e-01, time/batch = 16.1317s	
31233/33250 (epoch 46.967), train_loss = 0.73167935, grad/param norm = 2.0395e-01, time/batch = 14.6866s	
31234/33250 (epoch 46.968), train_loss = 0.83542772, grad/param norm = 1.6227e-01, time/batch = 14.7810s	
31235/33250 (epoch 46.970), train_loss = 0.92509242, grad/param norm = 2.2810e-01, time/batch = 15.3757s	
31236/33250 (epoch 46.971), train_loss = 0.88341144, grad/param norm = 3.3099e-01, time/batch = 14.6422s	
31237/33250 (epoch 46.973), train_loss = 0.71235904, grad/param norm = 1.7520e-01, time/batch = 14.7058s	
31238/33250 (epoch 46.974), train_loss = 0.80355553, grad/param norm = 1.9656e-01, time/batch = 14.5532s	
31239/33250 (epoch 46.976), train_loss = 0.70937014, grad/param norm = 1.8199e-01, time/batch = 15.5446s	
31240/33250 (epoch 46.977), train_loss = 0.74553750, grad/param norm = 1.8368e-01, time/batch = 15.9913s	
31241/33250 (epoch 46.979), train_loss = 0.79515913, grad/param norm = 1.8560e-01, time/batch = 15.9663s	
31242/33250 (epoch 46.980), train_loss = 0.77497372, grad/param norm = 1.8508e-01, time/batch = 15.0238s	
31243/33250 (epoch 46.982), train_loss = 0.71628217, grad/param norm = 1.6948e-01, time/batch = 14.9535s	
31244/33250 (epoch 46.983), train_loss = 0.76085591, grad/param norm = 1.8326e-01, time/batch = 14.4710s	
31245/33250 (epoch 46.985), train_loss = 0.70357334, grad/param norm = 2.0969e-01, time/batch = 15.2378s	
31246/33250 (epoch 46.986), train_loss = 0.80345530, grad/param norm = 1.9719e-01, time/batch = 14.5585s	
31247/33250 (epoch 46.988), train_loss = 0.83309082, grad/param norm = 2.1881e-01, time/batch = 14.7119s	
31248/33250 (epoch 46.989), train_loss = 0.81703813, grad/param norm = 1.9348e-01, time/batch = 14.5559s	
31249/33250 (epoch 46.991), train_loss = 0.80200315, grad/param norm = 2.0523e-01, time/batch = 14.8629s	
31250/33250 (epoch 46.992), train_loss = 0.72909294, grad/param norm = 1.8596e-01, time/batch = 15.2168s	
31251/33250 (epoch 46.994), train_loss = 0.69311546, grad/param norm = 1.7759e-01, time/batch = 14.7022s	
31252/33250 (epoch 46.995), train_loss = 0.71591925, grad/param norm = 2.7758e-01, time/batch = 17.4473s	
31253/33250 (epoch 46.997), train_loss = 0.58210973, grad/param norm = 1.6894e-01, time/batch = 15.1784s	
31254/33250 (epoch 46.998), train_loss = 0.76215961, grad/param norm = 1.8969e-01, time/batch = 16.5536s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
31255/33250 (epoch 47.000), train_loss = 0.77716394, grad/param norm = 2.0151e-01, time/batch = 14.9942s	
31256/33250 (epoch 47.002), train_loss = 0.95404555, grad/param norm = 2.2266e-01, time/batch = 14.4505s	
31257/33250 (epoch 47.003), train_loss = 0.80583220, grad/param norm = 2.1234e-01, time/batch = 14.9382s	
31258/33250 (epoch 47.005), train_loss = 0.61675636, grad/param norm = 1.6099e-01, time/batch = 14.3571s	
31259/33250 (epoch 47.006), train_loss = 0.62977408, grad/param norm = 1.7958e-01, time/batch = 14.2119s	
31260/33250 (epoch 47.008), train_loss = 0.84047419, grad/param norm = 2.2517e-01, time/batch = 14.2197s	
31261/33250 (epoch 47.009), train_loss = 0.91737253, grad/param norm = 2.0569e-01, time/batch = 15.4537s	
31262/33250 (epoch 47.011), train_loss = 0.70804046, grad/param norm = 1.8377e-01, time/batch = 15.1322s	
31263/33250 (epoch 47.012), train_loss = 0.72444947, grad/param norm = 2.3874e-01, time/batch = 16.2017s	
31264/33250 (epoch 47.014), train_loss = 0.83847225, grad/param norm = 2.1635e-01, time/batch = 16.6326s	
31265/33250 (epoch 47.015), train_loss = 0.75677892, grad/param norm = 1.8263e-01, time/batch = 16.4496s	
31266/33250 (epoch 47.017), train_loss = 0.75407943, grad/param norm = 2.0890e-01, time/batch = 14.9540s	
31267/33250 (epoch 47.018), train_loss = 0.60205406, grad/param norm = 1.8738e-01, time/batch = 15.1941s	
31268/33250 (epoch 47.020), train_loss = 0.77714912, grad/param norm = 2.0205e-01, time/batch = 16.1904s	
31269/33250 (epoch 47.021), train_loss = 0.76908449, grad/param norm = 1.7901e-01, time/batch = 14.5524s	
31270/33250 (epoch 47.023), train_loss = 0.60703343, grad/param norm = 2.1228e-01, time/batch = 14.4692s	
31271/33250 (epoch 47.024), train_loss = 0.82481477, grad/param norm = 2.2669e-01, time/batch = 14.8742s	
31272/33250 (epoch 47.026), train_loss = 0.79372361, grad/param norm = 2.0092e-01, time/batch = 15.9255s	
31273/33250 (epoch 47.027), train_loss = 0.76582085, grad/param norm = 1.8224e-01, time/batch = 14.9490s	
31274/33250 (epoch 47.029), train_loss = 0.72179051, grad/param norm = 1.9493e-01, time/batch = 16.2517s	
31275/33250 (epoch 47.030), train_loss = 0.71861697, grad/param norm = 1.8421e-01, time/batch = 14.8084s	
31276/33250 (epoch 47.032), train_loss = 0.90009095, grad/param norm = 2.1583e-01, time/batch = 17.0137s	
31277/33250 (epoch 47.033), train_loss = 0.71373009, grad/param norm = 1.9917e-01, time/batch = 15.5464s	
31278/33250 (epoch 47.035), train_loss = 0.75266164, grad/param norm = 1.7607e-01, time/batch = 14.4719s	
31279/33250 (epoch 47.036), train_loss = 0.77508166, grad/param norm = 1.9405e-01, time/batch = 14.8149s	
31280/33250 (epoch 47.038), train_loss = 0.75446811, grad/param norm = 1.6653e-01, time/batch = 14.8710s	
31281/33250 (epoch 47.039), train_loss = 0.68358913, grad/param norm = 1.8219e-01, time/batch = 14.8799s	
31282/33250 (epoch 47.041), train_loss = 0.75359761, grad/param norm = 2.2327e-01, time/batch = 14.6288s	
31283/33250 (epoch 47.042), train_loss = 0.63707434, grad/param norm = 1.6234e-01, time/batch = 14.9598s	
31284/33250 (epoch 47.044), train_loss = 0.84566639, grad/param norm = 2.0206e-01, time/batch = 14.6333s	
31285/33250 (epoch 47.045), train_loss = 0.84054660, grad/param norm = 1.9480e-01, time/batch = 15.7201s	
31286/33250 (epoch 47.047), train_loss = 0.76912357, grad/param norm = 1.7663e-01, time/batch = 16.0689s	
31287/33250 (epoch 47.048), train_loss = 0.77988895, grad/param norm = 1.9459e-01, time/batch = 15.6470s	
31288/33250 (epoch 47.050), train_loss = 0.75232767, grad/param norm = 2.1383e-01, time/batch = 15.4076s	
31289/33250 (epoch 47.051), train_loss = 0.73267028, grad/param norm = 1.9514e-01, time/batch = 14.9640s	
31290/33250 (epoch 47.053), train_loss = 0.78666311, grad/param norm = 2.2965e-01, time/batch = 14.8040s	
31291/33250 (epoch 47.054), train_loss = 0.63455406, grad/param norm = 1.5722e-01, time/batch = 15.0573s	
31292/33250 (epoch 47.056), train_loss = 0.62483004, grad/param norm = 1.7728e-01, time/batch = 14.9412s	
31293/33250 (epoch 47.057), train_loss = 0.81694132, grad/param norm = 1.9168e-01, time/batch = 14.6225s	
31294/33250 (epoch 47.059), train_loss = 0.72409202, grad/param norm = 1.7069e-01, time/batch = 14.5481s	
31295/33250 (epoch 47.060), train_loss = 0.76816431, grad/param norm = 2.4737e-01, time/batch = 15.0252s	
31296/33250 (epoch 47.062), train_loss = 0.84552238, grad/param norm = 2.1487e-01, time/batch = 14.9646s	
31297/33250 (epoch 47.063), train_loss = 0.86677103, grad/param norm = 2.1592e-01, time/batch = 16.6127s	
31298/33250 (epoch 47.065), train_loss = 0.70701119, grad/param norm = 1.9806e-01, time/batch = 17.9639s	
31299/33250 (epoch 47.066), train_loss = 0.78829210, grad/param norm = 1.8883e-01, time/batch = 15.3903s	
31300/33250 (epoch 47.068), train_loss = 0.71247040, grad/param norm = 2.2152e-01, time/batch = 14.9311s	
31301/33250 (epoch 47.069), train_loss = 0.76279185, grad/param norm = 2.2401e-01, time/batch = 14.7150s	
31302/33250 (epoch 47.071), train_loss = 0.71391055, grad/param norm = 1.6588e-01, time/batch = 14.6068s	
31303/33250 (epoch 47.072), train_loss = 0.66447744, grad/param norm = 1.5170e-01, time/batch = 14.2181s	
31304/33250 (epoch 47.074), train_loss = 0.75852037, grad/param norm = 1.8382e-01, time/batch = 14.5342s	
31305/33250 (epoch 47.075), train_loss = 0.69730211, grad/param norm = 1.6820e-01, time/batch = 15.2994s	
31306/33250 (epoch 47.077), train_loss = 0.75066287, grad/param norm = 3.2172e-01, time/batch = 15.0497s	
31307/33250 (epoch 47.078), train_loss = 0.74493770, grad/param norm = 1.8473e-01, time/batch = 16.1362s	
31308/33250 (epoch 47.080), train_loss = 0.76719739, grad/param norm = 2.2675e-01, time/batch = 14.8832s	
31309/33250 (epoch 47.081), train_loss = 0.76631197, grad/param norm = 1.8554e-01, time/batch = 14.6797s	
31310/33250 (epoch 47.083), train_loss = 0.85340244, grad/param norm = 2.0322e-01, time/batch = 16.8084s	
31311/33250 (epoch 47.084), train_loss = 0.78186219, grad/param norm = 1.8569e-01, time/batch = 14.9604s	
31312/33250 (epoch 47.086), train_loss = 0.74913104, grad/param norm = 1.5710e-01, time/batch = 15.0300s	
31313/33250 (epoch 47.087), train_loss = 0.65997904, grad/param norm = 1.6722e-01, time/batch = 15.7910s	
31314/33250 (epoch 47.089), train_loss = 0.72112208, grad/param norm = 1.9236e-01, time/batch = 14.7136s	
31315/33250 (epoch 47.090), train_loss = 0.77269218, grad/param norm = 1.9311e-01, time/batch = 14.5391s	
31316/33250 (epoch 47.092), train_loss = 0.70888860, grad/param norm = 1.6797e-01, time/batch = 15.1702s	
31317/33250 (epoch 47.093), train_loss = 0.72204324, grad/param norm = 1.6464e-01, time/batch = 14.9629s	
31318/33250 (epoch 47.095), train_loss = 0.73653018, grad/param norm = 1.8028e-01, time/batch = 15.0123s	
31319/33250 (epoch 47.096), train_loss = 0.62453595, grad/param norm = 1.7094e-01, time/batch = 16.7891s	
31320/33250 (epoch 47.098), train_loss = 0.62708780, grad/param norm = 2.1536e-01, time/batch = 16.9536s	
31321/33250 (epoch 47.099), train_loss = 0.57926838, grad/param norm = 1.6302e-01, time/batch = 15.7137s	
31322/33250 (epoch 47.101), train_loss = 0.71411424, grad/param norm = 2.0835e-01, time/batch = 16.5526s	
31323/33250 (epoch 47.102), train_loss = 0.68672182, grad/param norm = 1.7089e-01, time/batch = 15.1259s	
31324/33250 (epoch 47.104), train_loss = 0.57289084, grad/param norm = 1.4811e-01, time/batch = 15.4574s	
31325/33250 (epoch 47.105), train_loss = 0.68417267, grad/param norm = 1.6942e-01, time/batch = 14.6322s	
31326/33250 (epoch 47.107), train_loss = 0.61181507, grad/param norm = 1.4726e-01, time/batch = 15.0390s	
31327/33250 (epoch 47.108), train_loss = 0.73438020, grad/param norm = 1.9284e-01, time/batch = 15.4482s	
31328/33250 (epoch 47.110), train_loss = 0.63795113, grad/param norm = 1.9339e-01, time/batch = 15.2773s	
31329/33250 (epoch 47.111), train_loss = 0.72071651, grad/param norm = 1.7104e-01, time/batch = 15.0572s	
31330/33250 (epoch 47.113), train_loss = 0.68035964, grad/param norm = 1.7622e-01, time/batch = 16.7831s	
31331/33250 (epoch 47.114), train_loss = 0.64753441, grad/param norm = 1.8975e-01, time/batch = 30.8259s	
31332/33250 (epoch 47.116), train_loss = 0.66389661, grad/param norm = 1.8768e-01, time/batch = 15.9595s	
31333/33250 (epoch 47.117), train_loss = 0.65035460, grad/param norm = 1.8712e-01, time/batch = 15.2085s	
31334/33250 (epoch 47.119), train_loss = 0.68165707, grad/param norm = 1.8691e-01, time/batch = 14.8701s	
31335/33250 (epoch 47.120), train_loss = 0.61627806, grad/param norm = 1.7486e-01, time/batch = 16.3499s	
31336/33250 (epoch 47.122), train_loss = 0.76807828, grad/param norm = 1.9613e-01, time/batch = 14.5434s	
31337/33250 (epoch 47.123), train_loss = 0.72737438, grad/param norm = 1.9993e-01, time/batch = 14.6213s	
31338/33250 (epoch 47.125), train_loss = 0.57924894, grad/param norm = 1.9020e-01, time/batch = 14.7911s	
31339/33250 (epoch 47.126), train_loss = 0.71786639, grad/param norm = 2.0863e-01, time/batch = 14.6946s	
31340/33250 (epoch 47.128), train_loss = 0.68256771, grad/param norm = 1.6373e-01, time/batch = 14.8723s	
31341/33250 (epoch 47.129), train_loss = 0.71359080, grad/param norm = 1.7156e-01, time/batch = 14.8294s	
31342/33250 (epoch 47.131), train_loss = 0.70206556, grad/param norm = 1.6927e-01, time/batch = 15.4454s	
31343/33250 (epoch 47.132), train_loss = 0.67131385, grad/param norm = 1.7564e-01, time/batch = 16.3926s	
31344/33250 (epoch 47.134), train_loss = 0.65142365, grad/param norm = 1.8696e-01, time/batch = 14.4737s	
31345/33250 (epoch 47.135), train_loss = 0.73099157, grad/param norm = 1.4632e-01, time/batch = 14.5517s	
31346/33250 (epoch 47.137), train_loss = 0.66157553, grad/param norm = 1.8910e-01, time/batch = 14.8598s	
31347/33250 (epoch 47.138), train_loss = 0.65112912, grad/param norm = 1.5333e-01, time/batch = 14.2928s	
31348/33250 (epoch 47.140), train_loss = 0.56492236, grad/param norm = 2.0474e-01, time/batch = 14.5509s	
31349/33250 (epoch 47.141), train_loss = 0.80068876, grad/param norm = 3.5533e-01, time/batch = 14.4747s	
31350/33250 (epoch 47.143), train_loss = 0.62393515, grad/param norm = 1.9007e-01, time/batch = 15.0124s	
31351/33250 (epoch 47.144), train_loss = 0.67631982, grad/param norm = 1.6382e-01, time/batch = 16.2288s	
31352/33250 (epoch 47.146), train_loss = 0.68956868, grad/param norm = 1.7298e-01, time/batch = 16.4807s	
31353/33250 (epoch 47.147), train_loss = 0.69210641, grad/param norm = 1.7619e-01, time/batch = 16.9637s	
31354/33250 (epoch 47.149), train_loss = 0.67403058, grad/param norm = 1.6945e-01, time/batch = 15.1325s	
31355/33250 (epoch 47.150), train_loss = 0.65701938, grad/param norm = 1.8047e-01, time/batch = 14.9608s	
31356/33250 (epoch 47.152), train_loss = 0.61543452, grad/param norm = 1.9795e-01, time/batch = 15.6929s	
31357/33250 (epoch 47.153), train_loss = 0.83621886, grad/param norm = 2.0408e-01, time/batch = 15.4526s	
31358/33250 (epoch 47.155), train_loss = 0.69964943, grad/param norm = 1.9177e-01, time/batch = 14.7903s	
31359/33250 (epoch 47.156), train_loss = 0.90625020, grad/param norm = 2.0636e-01, time/batch = 15.0198s	
31360/33250 (epoch 47.158), train_loss = 0.84712979, grad/param norm = 2.2510e-01, time/batch = 14.5948s	
31361/33250 (epoch 47.159), train_loss = 0.70467671, grad/param norm = 2.2097e-01, time/batch = 14.7102s	
31362/33250 (epoch 47.161), train_loss = 0.74698343, grad/param norm = 2.0705e-01, time/batch = 16.2258s	
31363/33250 (epoch 47.162), train_loss = 0.64834632, grad/param norm = 1.7465e-01, time/batch = 16.5592s	
31364/33250 (epoch 47.164), train_loss = 0.73255189, grad/param norm = 2.1533e-01, time/batch = 15.3234s	
31365/33250 (epoch 47.165), train_loss = 0.80994518, grad/param norm = 2.0303e-01, time/batch = 16.1371s	
31366/33250 (epoch 47.167), train_loss = 0.85523355, grad/param norm = 2.3688e-01, time/batch = 14.9738s	
31367/33250 (epoch 47.168), train_loss = 0.65320930, grad/param norm = 1.6802e-01, time/batch = 15.2318s	
31368/33250 (epoch 47.170), train_loss = 0.72349654, grad/param norm = 2.2194e-01, time/batch = 14.3751s	
31369/33250 (epoch 47.171), train_loss = 0.73514583, grad/param norm = 1.7963e-01, time/batch = 15.0302s	
31370/33250 (epoch 47.173), train_loss = 0.73574031, grad/param norm = 1.8958e-01, time/batch = 14.3887s	
31371/33250 (epoch 47.174), train_loss = 0.75638430, grad/param norm = 1.8212e-01, time/batch = 14.7119s	
31372/33250 (epoch 47.176), train_loss = 0.66573915, grad/param norm = 2.2500e-01, time/batch = 14.3051s	
31373/33250 (epoch 47.177), train_loss = 0.65520554, grad/param norm = 1.5716e-01, time/batch = 15.0387s	
31374/33250 (epoch 47.179), train_loss = 0.65939810, grad/param norm = 1.7425e-01, time/batch = 15.7100s	
31375/33250 (epoch 47.180), train_loss = 0.60127930, grad/param norm = 1.6181e-01, time/batch = 15.4558s	
31376/33250 (epoch 47.182), train_loss = 0.66004000, grad/param norm = 2.3281e-01, time/batch = 16.7978s	
31377/33250 (epoch 47.183), train_loss = 0.79998303, grad/param norm = 2.3571e-01, time/batch = 14.7946s	
31378/33250 (epoch 47.185), train_loss = 0.74496959, grad/param norm = 2.2519e-01, time/batch = 14.7714s	
31379/33250 (epoch 47.186), train_loss = 0.74297940, grad/param norm = 2.0303e-01, time/batch = 14.8612s	
31380/33250 (epoch 47.188), train_loss = 0.80522885, grad/param norm = 2.2572e-01, time/batch = 14.6316s	
31381/33250 (epoch 47.189), train_loss = 0.59266723, grad/param norm = 2.0640e-01, time/batch = 15.0270s	
31382/33250 (epoch 47.191), train_loss = 0.67584848, grad/param norm = 2.0736e-01, time/batch = 14.7038s	
31383/33250 (epoch 47.192), train_loss = 0.66967768, grad/param norm = 1.5992e-01, time/batch = 14.7135s	
31384/33250 (epoch 47.194), train_loss = 0.68916043, grad/param norm = 2.1922e-01, time/batch = 14.5580s	
31385/33250 (epoch 47.195), train_loss = 0.84342628, grad/param norm = 1.9082e-01, time/batch = 16.3756s	
31386/33250 (epoch 47.197), train_loss = 0.67428776, grad/param norm = 1.6382e-01, time/batch = 16.1364s	
31387/33250 (epoch 47.198), train_loss = 0.84824758, grad/param norm = 2.0609e-01, time/batch = 15.4516s	
31388/33250 (epoch 47.200), train_loss = 0.72921834, grad/param norm = 2.1568e-01, time/batch = 15.9678s	
31389/33250 (epoch 47.202), train_loss = 0.69044797, grad/param norm = 1.5965e-01, time/batch = 15.1945s	
31390/33250 (epoch 47.203), train_loss = 0.64845482, grad/param norm = 2.4364e-01, time/batch = 14.7034s	
31391/33250 (epoch 47.205), train_loss = 0.73667289, grad/param norm = 1.7461e-01, time/batch = 14.9670s	
31392/33250 (epoch 47.206), train_loss = 0.78595611, grad/param norm = 2.1693e-01, time/batch = 14.2902s	
31393/33250 (epoch 47.208), train_loss = 0.80641547, grad/param norm = 2.0752e-01, time/batch = 14.7710s	
31394/33250 (epoch 47.209), train_loss = 0.68137101, grad/param norm = 1.7841e-01, time/batch = 14.6207s	
31395/33250 (epoch 47.211), train_loss = 0.73725142, grad/param norm = 1.8525e-01, time/batch = 16.4636s	
31396/33250 (epoch 47.212), train_loss = 0.84073709, grad/param norm = 1.9081e-01, time/batch = 17.6246s	
31397/33250 (epoch 47.214), train_loss = 0.76052194, grad/param norm = 1.6954e-01, time/batch = 16.3033s	
31398/33250 (epoch 47.215), train_loss = 0.75028983, grad/param norm = 2.3857e-01, time/batch = 15.5439s	
31399/33250 (epoch 47.217), train_loss = 0.78937308, grad/param norm = 1.9689e-01, time/batch = 15.0733s	
31400/33250 (epoch 47.218), train_loss = 0.74968388, grad/param norm = 1.8199e-01, time/batch = 15.0173s	
31401/33250 (epoch 47.220), train_loss = 0.71743951, grad/param norm = 1.5971e-01, time/batch = 15.2042s	
31402/33250 (epoch 47.221), train_loss = 0.82841600, grad/param norm = 2.5014e-01, time/batch = 14.2943s	
31403/33250 (epoch 47.223), train_loss = 0.71871971, grad/param norm = 1.6650e-01, time/batch = 14.1273s	
31404/33250 (epoch 47.224), train_loss = 0.76174823, grad/param norm = 2.0307e-01, time/batch = 14.6218s	
31405/33250 (epoch 47.226), train_loss = 0.86015160, grad/param norm = 2.0784e-01, time/batch = 14.6209s	
31406/33250 (epoch 47.227), train_loss = 0.75466342, grad/param norm = 1.8493e-01, time/batch = 14.7285s	
31407/33250 (epoch 47.229), train_loss = 0.75832989, grad/param norm = 1.7280e-01, time/batch = 15.3823s	
31408/33250 (epoch 47.230), train_loss = 0.76046215, grad/param norm = 2.0739e-01, time/batch = 16.1974s	
31409/33250 (epoch 47.232), train_loss = 0.69605646, grad/param norm = 1.7608e-01, time/batch = 15.9539s	
31410/33250 (epoch 47.233), train_loss = 0.66956893, grad/param norm = 1.7136e-01, time/batch = 14.7607s	
31411/33250 (epoch 47.235), train_loss = 0.83570597, grad/param norm = 1.7306e-01, time/batch = 14.8600s	
31412/33250 (epoch 47.236), train_loss = 0.67156640, grad/param norm = 1.9183e-01, time/batch = 14.6933s	
31413/33250 (epoch 47.238), train_loss = 0.81252888, grad/param norm = 2.2931e-01, time/batch = 14.5472s	
31414/33250 (epoch 47.239), train_loss = 0.84272489, grad/param norm = 3.1649e-01, time/batch = 14.4622s	
31415/33250 (epoch 47.241), train_loss = 0.82868510, grad/param norm = 2.6043e-01, time/batch = 14.0542s	
31416/33250 (epoch 47.242), train_loss = 0.81627921, grad/param norm = 2.4322e-01, time/batch = 14.2101s	
31417/33250 (epoch 47.244), train_loss = 0.77741141, grad/param norm = 2.2390e-01, time/batch = 15.3979s	
31418/33250 (epoch 47.245), train_loss = 0.77550104, grad/param norm = 2.0094e-01, time/batch = 14.5616s	
31419/33250 (epoch 47.247), train_loss = 0.74985462, grad/param norm = 1.9487e-01, time/batch = 15.4459s	
31420/33250 (epoch 47.248), train_loss = 0.86962070, grad/param norm = 2.5689e-01, time/batch = 14.9708s	
31421/33250 (epoch 47.250), train_loss = 0.85452370, grad/param norm = 1.7404e-01, time/batch = 14.6244s	
31422/33250 (epoch 47.251), train_loss = 0.74375920, grad/param norm = 1.8567e-01, time/batch = 14.5606s	
31423/33250 (epoch 47.253), train_loss = 0.73591461, grad/param norm = 1.9294e-01, time/batch = 14.5471s	
31424/33250 (epoch 47.254), train_loss = 0.67630109, grad/param norm = 1.7315e-01, time/batch = 14.7078s	
31425/33250 (epoch 47.256), train_loss = 0.74992003, grad/param norm = 1.8356e-01, time/batch = 14.8720s	
31426/33250 (epoch 47.257), train_loss = 0.88992903, grad/param norm = 1.9347e-01, time/batch = 14.5598s	
31427/33250 (epoch 47.259), train_loss = 0.75217977, grad/param norm = 1.9170e-01, time/batch = 14.5606s	
31428/33250 (epoch 47.260), train_loss = 0.60933814, grad/param norm = 1.7102e-01, time/batch = 15.1702s	
31429/33250 (epoch 47.262), train_loss = 0.73687297, grad/param norm = 1.7245e-01, time/batch = 15.9178s	
31430/33250 (epoch 47.263), train_loss = 0.61551399, grad/param norm = 2.0616e-01, time/batch = 16.7200s	
31431/33250 (epoch 47.265), train_loss = 0.77023991, grad/param norm = 2.0027e-01, time/batch = 14.4875s	
31432/33250 (epoch 47.266), train_loss = 0.76157132, grad/param norm = 2.0887e-01, time/batch = 15.1274s	
31433/33250 (epoch 47.268), train_loss = 0.63813005, grad/param norm = 1.7566e-01, time/batch = 14.5453s	
31434/33250 (epoch 47.269), train_loss = 0.59978131, grad/param norm = 1.6622e-01, time/batch = 14.6326s	
31435/33250 (epoch 47.271), train_loss = 0.79404398, grad/param norm = 1.7840e-01, time/batch = 14.4697s	
31436/33250 (epoch 47.272), train_loss = 0.67452310, grad/param norm = 1.5194e-01, time/batch = 14.6920s	
31437/33250 (epoch 47.274), train_loss = 0.54951917, grad/param norm = 1.6381e-01, time/batch = 14.7072s	
31438/33250 (epoch 47.275), train_loss = 0.69322339, grad/param norm = 1.5442e-01, time/batch = 14.7992s	
31439/33250 (epoch 47.277), train_loss = 0.62796707, grad/param norm = 2.0357e-01, time/batch = 14.6983s	
31440/33250 (epoch 47.278), train_loss = 0.69311438, grad/param norm = 1.8561e-01, time/batch = 16.3722s	
31441/33250 (epoch 47.280), train_loss = 0.64974154, grad/param norm = 1.7373e-01, time/batch = 15.0286s	
31442/33250 (epoch 47.281), train_loss = 0.75748314, grad/param norm = 1.9684e-01, time/batch = 16.8034s	
31443/33250 (epoch 47.283), train_loss = 0.78376813, grad/param norm = 3.1275e-01, time/batch = 15.8889s	
31444/33250 (epoch 47.284), train_loss = 0.63055132, grad/param norm = 1.9447e-01, time/batch = 14.7144s	
31445/33250 (epoch 47.286), train_loss = 0.76263651, grad/param norm = 1.8233e-01, time/batch = 15.0755s	
31446/33250 (epoch 47.287), train_loss = 0.61223708, grad/param norm = 1.5907e-01, time/batch = 14.6356s	
31447/33250 (epoch 47.289), train_loss = 0.57807731, grad/param norm = 1.7393e-01, time/batch = 14.9720s	
31448/33250 (epoch 47.290), train_loss = 0.72696301, grad/param norm = 1.8149e-01, time/batch = 15.0261s	
31449/33250 (epoch 47.292), train_loss = 0.77280127, grad/param norm = 2.5498e-01, time/batch = 14.4440s	
31450/33250 (epoch 47.293), train_loss = 0.83204956, grad/param norm = 2.0118e-01, time/batch = 14.5212s	
31451/33250 (epoch 47.295), train_loss = 0.83339112, grad/param norm = 2.1617e-01, time/batch = 14.7940s	
31452/33250 (epoch 47.296), train_loss = 0.75257383, grad/param norm = 1.9513e-01, time/batch = 15.2197s	
31453/33250 (epoch 47.298), train_loss = 0.59523512, grad/param norm = 1.5633e-01, time/batch = 16.5361s	
31454/33250 (epoch 47.299), train_loss = 0.59080501, grad/param norm = 1.8371e-01, time/batch = 14.8166s	
31455/33250 (epoch 47.301), train_loss = 0.79357682, grad/param norm = 2.0553e-01, time/batch = 14.7187s	
31456/33250 (epoch 47.302), train_loss = 0.78922260, grad/param norm = 2.0755e-01, time/batch = 14.6993s	
31457/33250 (epoch 47.304), train_loss = 0.70184445, grad/param norm = 2.1103e-01, time/batch = 14.5496s	
31458/33250 (epoch 47.305), train_loss = 0.67454083, grad/param norm = 1.6352e-01, time/batch = 15.0742s	
31459/33250 (epoch 47.307), train_loss = 0.82186619, grad/param norm = 2.3016e-01, time/batch = 14.6267s	
31460/33250 (epoch 47.308), train_loss = 0.84813028, grad/param norm = 2.9020e-01, time/batch = 14.7781s	
31461/33250 (epoch 47.310), train_loss = 0.69519027, grad/param norm = 2.1196e-01, time/batch = 14.3637s	
31462/33250 (epoch 47.311), train_loss = 0.87481574, grad/param norm = 2.3114e-01, time/batch = 14.4718s	
31463/33250 (epoch 47.313), train_loss = 0.61269193, grad/param norm = 2.2219e-01, time/batch = 17.3808s	
31464/33250 (epoch 47.314), train_loss = 0.83224872, grad/param norm = 2.0949e-01, time/batch = 15.4400s	
31465/33250 (epoch 47.316), train_loss = 0.88707780, grad/param norm = 2.0527e-01, time/batch = 19.1116s	
31466/33250 (epoch 47.317), train_loss = 0.65005050, grad/param norm = 1.6835e-01, time/batch = 14.6413s	
31467/33250 (epoch 47.319), train_loss = 0.76841653, grad/param norm = 2.5051e-01, time/batch = 15.5275s	
31468/33250 (epoch 47.320), train_loss = 0.79402071, grad/param norm = 2.5533e-01, time/batch = 15.0927s	
31469/33250 (epoch 47.322), train_loss = 0.88430284, grad/param norm = 2.1446e-01, time/batch = 14.9464s	
31470/33250 (epoch 47.323), train_loss = 0.87009819, grad/param norm = 2.6882e-01, time/batch = 15.0277s	
31471/33250 (epoch 47.325), train_loss = 0.70170616, grad/param norm = 2.1996e-01, time/batch = 15.6229s	
31472/33250 (epoch 47.326), train_loss = 0.94021970, grad/param norm = 2.1286e-01, time/batch = 14.8643s	
31473/33250 (epoch 47.328), train_loss = 0.73582259, grad/param norm = 1.9140e-01, time/batch = 14.7022s	
31474/33250 (epoch 47.329), train_loss = 0.77630815, grad/param norm = 2.2082e-01, time/batch = 15.7045s	
31475/33250 (epoch 47.331), train_loss = 0.74933842, grad/param norm = 2.1569e-01, time/batch = 15.8051s	
31476/33250 (epoch 47.332), train_loss = 0.77051982, grad/param norm = 1.9558e-01, time/batch = 15.0658s	
31477/33250 (epoch 47.334), train_loss = 0.87641892, grad/param norm = 1.8714e-01, time/batch = 15.3948s	
31478/33250 (epoch 47.335), train_loss = 0.57429839, grad/param norm = 1.9816e-01, time/batch = 14.4588s	
31479/33250 (epoch 47.337), train_loss = 0.80720609, grad/param norm = 1.7133e-01, time/batch = 14.7152s	
31480/33250 (epoch 47.338), train_loss = 0.89725093, grad/param norm = 1.9285e-01, time/batch = 15.4626s	
31481/33250 (epoch 47.340), train_loss = 0.71196223, grad/param norm = 1.8106e-01, time/batch = 16.1129s	
31482/33250 (epoch 47.341), train_loss = 0.66896131, grad/param norm = 1.7952e-01, time/batch = 14.6298s	
31483/33250 (epoch 47.343), train_loss = 0.70964907, grad/param norm = 1.8459e-01, time/batch = 14.9816s	
31484/33250 (epoch 47.344), train_loss = 0.72294993, grad/param norm = 1.7604e-01, time/batch = 14.7034s	
31485/33250 (epoch 47.346), train_loss = 0.65013973, grad/param norm = 1.7197e-01, time/batch = 15.7011s	
31486/33250 (epoch 47.347), train_loss = 0.91942859, grad/param norm = 2.6618e-01, time/batch = 16.1440s	
31487/33250 (epoch 47.349), train_loss = 0.73780432, grad/param norm = 1.9860e-01, time/batch = 16.3881s	
31488/33250 (epoch 47.350), train_loss = 0.73831718, grad/param norm = 2.0706e-01, time/batch = 15.3022s	
31489/33250 (epoch 47.352), train_loss = 0.68158100, grad/param norm = 1.9808e-01, time/batch = 14.3854s	
31490/33250 (epoch 47.353), train_loss = 0.72416975, grad/param norm = 2.1067e-01, time/batch = 14.5372s	
31491/33250 (epoch 47.355), train_loss = 0.72533461, grad/param norm = 1.9945e-01, time/batch = 15.5317s	
31492/33250 (epoch 47.356), train_loss = 0.68430635, grad/param norm = 1.9295e-01, time/batch = 14.3036s	
31493/33250 (epoch 47.358), train_loss = 0.72690408, grad/param norm = 1.7412e-01, time/batch = 14.6943s	
31494/33250 (epoch 47.359), train_loss = 0.69247510, grad/param norm = 1.7070e-01, time/batch = 14.8042s	
31495/33250 (epoch 47.361), train_loss = 0.80433656, grad/param norm = 2.0139e-01, time/batch = 14.6145s	
31496/33250 (epoch 47.362), train_loss = 0.76559964, grad/param norm = 1.8353e-01, time/batch = 16.5525s	
31497/33250 (epoch 47.364), train_loss = 0.78005780, grad/param norm = 1.8190e-01, time/batch = 15.5594s	
31498/33250 (epoch 47.365), train_loss = 0.72520772, grad/param norm = 1.5452e-01, time/batch = 15.9373s	
31499/33250 (epoch 47.367), train_loss = 0.77900665, grad/param norm = 1.8809e-01, time/batch = 15.0538s	
31500/33250 (epoch 47.368), train_loss = 0.73475165, grad/param norm = 1.8759e-01, time/batch = 14.9270s	
31501/33250 (epoch 47.370), train_loss = 0.64992620, grad/param norm = 1.5810e-01, time/batch = 14.7817s	
31502/33250 (epoch 47.371), train_loss = 0.83508239, grad/param norm = 2.2233e-01, time/batch = 14.4715s	
31503/33250 (epoch 47.373), train_loss = 0.72533441, grad/param norm = 1.5817e-01, time/batch = 15.4607s	
31504/33250 (epoch 47.374), train_loss = 0.70891119, grad/param norm = 2.1757e-01, time/batch = 14.9504s	
31505/33250 (epoch 47.376), train_loss = 0.75750573, grad/param norm = 1.8427e-01, time/batch = 14.1973s	
31506/33250 (epoch 47.377), train_loss = 0.65037973, grad/param norm = 2.3286e-01, time/batch = 14.3873s	
31507/33250 (epoch 47.379), train_loss = 0.75065656, grad/param norm = 2.2747e-01, time/batch = 15.2554s	
31508/33250 (epoch 47.380), train_loss = 0.74718988, grad/param norm = 2.6711e-01, time/batch = 15.2812s	
31509/33250 (epoch 47.382), train_loss = 0.76292788, grad/param norm = 2.5242e-01, time/batch = 16.2220s	
31510/33250 (epoch 47.383), train_loss = 0.66363633, grad/param norm = 2.1764e-01, time/batch = 16.3869s	
31511/33250 (epoch 47.385), train_loss = 0.64347080, grad/param norm = 2.0686e-01, time/batch = 14.8785s	
31512/33250 (epoch 47.386), train_loss = 0.66368640, grad/param norm = 2.7038e-01, time/batch = 15.2810s	
31513/33250 (epoch 47.388), train_loss = 0.69419603, grad/param norm = 1.8501e-01, time/batch = 14.5301s	
31514/33250 (epoch 47.389), train_loss = 0.65444574, grad/param norm = 1.9557e-01, time/batch = 14.8079s	
31515/33250 (epoch 47.391), train_loss = 0.77096471, grad/param norm = 1.7333e-01, time/batch = 15.1780s	
31516/33250 (epoch 47.392), train_loss = 0.84153708, grad/param norm = 2.0148e-01, time/batch = 14.4536s	
31517/33250 (epoch 47.394), train_loss = 0.80214061, grad/param norm = 1.7498e-01, time/batch = 14.8523s	
31518/33250 (epoch 47.395), train_loss = 0.84558079, grad/param norm = 2.0024e-01, time/batch = 15.8864s	
31519/33250 (epoch 47.397), train_loss = 0.85729742, grad/param norm = 2.1430e-01, time/batch = 15.8657s	
31520/33250 (epoch 47.398), train_loss = 0.64586230, grad/param norm = 1.5375e-01, time/batch = 18.2135s	
31521/33250 (epoch 47.400), train_loss = 0.66246259, grad/param norm = 1.7379e-01, time/batch = 16.3817s	
31522/33250 (epoch 47.402), train_loss = 0.61886323, grad/param norm = 1.7377e-01, time/batch = 14.6303s	
31523/33250 (epoch 47.403), train_loss = 0.72732891, grad/param norm = 2.0983e-01, time/batch = 14.7759s	
31524/33250 (epoch 47.405), train_loss = 0.68855760, grad/param norm = 1.7029e-01, time/batch = 15.3005s	
31525/33250 (epoch 47.406), train_loss = 0.73553885, grad/param norm = 2.3944e-01, time/batch = 15.2853s	
31526/33250 (epoch 47.408), train_loss = 0.85165033, grad/param norm = 1.7165e-01, time/batch = 15.6985s	
31527/33250 (epoch 47.409), train_loss = 0.76385954, grad/param norm = 2.1366e-01, time/batch = 14.8522s	
31528/33250 (epoch 47.411), train_loss = 0.54858875, grad/param norm = 1.6515e-01, time/batch = 14.7916s	
31529/33250 (epoch 47.412), train_loss = 0.62527504, grad/param norm = 2.0758e-01, time/batch = 15.7039s	
31530/33250 (epoch 47.414), train_loss = 0.73559073, grad/param norm = 1.9907e-01, time/batch = 16.4318s	
31531/33250 (epoch 47.415), train_loss = 0.79668200, grad/param norm = 1.9601e-01, time/batch = 18.1129s	
31532/33250 (epoch 47.417), train_loss = 0.83433208, grad/param norm = 2.0553e-01, time/batch = 15.3056s	
31533/33250 (epoch 47.418), train_loss = 0.98788134, grad/param norm = 2.7647e-01, time/batch = 14.5336s	
31534/33250 (epoch 47.420), train_loss = 0.82654821, grad/param norm = 1.9238e-01, time/batch = 14.7850s	
31535/33250 (epoch 47.421), train_loss = 0.70372475, grad/param norm = 1.7246e-01, time/batch = 14.4614s	
31536/33250 (epoch 47.423), train_loss = 0.78272699, grad/param norm = 1.8754e-01, time/batch = 14.1319s	
31537/33250 (epoch 47.424), train_loss = 0.85185847, grad/param norm = 3.3321e-01, time/batch = 15.6188s	
31538/33250 (epoch 47.426), train_loss = 0.72272931, grad/param norm = 1.5194e-01, time/batch = 14.5491s	
31539/33250 (epoch 47.427), train_loss = 0.68720018, grad/param norm = 1.9133e-01, time/batch = 14.8655s	
31540/33250 (epoch 47.429), train_loss = 0.73020766, grad/param norm = 2.4128e-01, time/batch = 15.0430s	
31541/33250 (epoch 47.430), train_loss = 0.70460513, grad/param norm = 2.2565e-01, time/batch = 15.0721s	
31542/33250 (epoch 47.432), train_loss = 0.80449609, grad/param norm = 1.7189e-01, time/batch = 15.7174s	
31543/33250 (epoch 47.433), train_loss = 0.72256857, grad/param norm = 3.5576e-01, time/batch = 16.5498s	
31544/33250 (epoch 47.435), train_loss = 0.78913478, grad/param norm = 1.9389e-01, time/batch = 14.5367s	
31545/33250 (epoch 47.436), train_loss = 0.72013482, grad/param norm = 2.2535e-01, time/batch = 14.5446s	
31546/33250 (epoch 47.438), train_loss = 0.84994284, grad/param norm = 2.0274e-01, time/batch = 15.4978s	
31547/33250 (epoch 47.439), train_loss = 0.76378054, grad/param norm = 1.8058e-01, time/batch = 14.3921s	
31548/33250 (epoch 47.441), train_loss = 0.74035498, grad/param norm = 1.7524e-01, time/batch = 14.7022s	
31549/33250 (epoch 47.442), train_loss = 0.65553370, grad/param norm = 1.7262e-01, time/batch = 14.3971s	
31550/33250 (epoch 47.444), train_loss = 0.70018079, grad/param norm = 1.6036e-01, time/batch = 15.1135s	
31551/33250 (epoch 47.445), train_loss = 0.75228615, grad/param norm = 1.5619e-01, time/batch = 15.6296s	
31552/33250 (epoch 47.447), train_loss = 0.65332674, grad/param norm = 2.0529e-01, time/batch = 16.6300s	
31553/33250 (epoch 47.448), train_loss = 0.76531200, grad/param norm = 1.7378e-01, time/batch = 17.1369s	
31554/33250 (epoch 47.450), train_loss = 0.82980883, grad/param norm = 1.9506e-01, time/batch = 14.7317s	
31555/33250 (epoch 47.451), train_loss = 0.79535202, grad/param norm = 2.1330e-01, time/batch = 14.7147s	
31556/33250 (epoch 47.453), train_loss = 0.63497819, grad/param norm = 1.4393e-01, time/batch = 14.5318s	
31557/33250 (epoch 47.454), train_loss = 0.84198267, grad/param norm = 1.9387e-01, time/batch = 14.7072s	
31558/33250 (epoch 47.456), train_loss = 0.85810869, grad/param norm = 1.6706e-01, time/batch = 15.0838s	
31559/33250 (epoch 47.457), train_loss = 0.68167254, grad/param norm = 1.7711e-01, time/batch = 14.6376s	
31560/33250 (epoch 47.459), train_loss = 0.82482961, grad/param norm = 1.7784e-01, time/batch = 14.4593s	
31561/33250 (epoch 47.460), train_loss = 0.79787079, grad/param norm = 2.1360e-01, time/batch = 14.7107s	
31562/33250 (epoch 47.462), train_loss = 0.76303150, grad/param norm = 1.9756e-01, time/batch = 14.8612s	
31563/33250 (epoch 47.463), train_loss = 0.66334771, grad/param norm = 1.6661e-01, time/batch = 16.7114s	
31564/33250 (epoch 47.465), train_loss = 0.63323359, grad/param norm = 1.5465e-01, time/batch = 16.2333s	
31565/33250 (epoch 47.466), train_loss = 0.62450527, grad/param norm = 1.5226e-01, time/batch = 15.9856s	
31566/33250 (epoch 47.468), train_loss = 0.63611857, grad/param norm = 1.6073e-01, time/batch = 28.0058s	
31567/33250 (epoch 47.469), train_loss = 0.73261661, grad/param norm = 2.3909e-01, time/batch = 14.1442s	
31568/33250 (epoch 47.471), train_loss = 0.81974978, grad/param norm = 1.6339e-01, time/batch = 14.7939s	
31569/33250 (epoch 47.472), train_loss = 0.69415778, grad/param norm = 2.2017e-01, time/batch = 14.5989s	
31570/33250 (epoch 47.474), train_loss = 0.81429422, grad/param norm = 1.7997e-01, time/batch = 14.5531s	
31571/33250 (epoch 47.475), train_loss = 0.77357809, grad/param norm = 1.6648e-01, time/batch = 14.2265s	
31572/33250 (epoch 47.477), train_loss = 0.76543999, grad/param norm = 1.6590e-01, time/batch = 14.2962s	
31573/33250 (epoch 47.478), train_loss = 0.64198129, grad/param norm = 2.0567e-01, time/batch = 15.2122s	
31574/33250 (epoch 47.480), train_loss = 0.83863761, grad/param norm = 2.0307e-01, time/batch = 15.7665s	
31575/33250 (epoch 47.481), train_loss = 0.71489470, grad/param norm = 2.2305e-01, time/batch = 14.8530s	
31576/33250 (epoch 47.483), train_loss = 0.70633009, grad/param norm = 1.9801e-01, time/batch = 16.4898s	
31577/33250 (epoch 47.484), train_loss = 0.67755999, grad/param norm = 1.7073e-01, time/batch = 14.7780s	
31578/33250 (epoch 47.486), train_loss = 0.59133925, grad/param norm = 1.7079e-01, time/batch = 14.3029s	
31579/33250 (epoch 47.487), train_loss = 0.65319067, grad/param norm = 1.8913e-01, time/batch = 14.5509s	
31580/33250 (epoch 47.489), train_loss = 0.81622804, grad/param norm = 2.2702e-01, time/batch = 14.3080s	
31581/33250 (epoch 47.490), train_loss = 0.73359180, grad/param norm = 2.0959e-01, time/batch = 14.9405s	
31582/33250 (epoch 47.492), train_loss = 0.81433398, grad/param norm = 2.4717e-01, time/batch = 14.8716s	
31583/33250 (epoch 47.493), train_loss = 0.72369101, grad/param norm = 1.8599e-01, time/batch = 14.6831s	
31584/33250 (epoch 47.495), train_loss = 0.81127098, grad/param norm = 1.5231e-01, time/batch = 14.9721s	
31585/33250 (epoch 47.496), train_loss = 0.74707649, grad/param norm = 1.5615e-01, time/batch = 15.1259s	
31586/33250 (epoch 47.498), train_loss = 0.78712398, grad/param norm = 2.1305e-01, time/batch = 16.0434s	
31587/33250 (epoch 47.499), train_loss = 0.70078072, grad/param norm = 2.6111e-01, time/batch = 15.8914s	
31588/33250 (epoch 47.501), train_loss = 0.68704136, grad/param norm = 1.8708e-01, time/batch = 14.9777s	
31589/33250 (epoch 47.502), train_loss = 0.70354456, grad/param norm = 1.8016e-01, time/batch = 14.8741s	
31590/33250 (epoch 47.504), train_loss = 0.84559966, grad/param norm = 2.7117e-01, time/batch = 15.5324s	
31591/33250 (epoch 47.505), train_loss = 0.63859368, grad/param norm = 1.5238e-01, time/batch = 14.3056s	
31592/33250 (epoch 47.507), train_loss = 0.66221677, grad/param norm = 1.6940e-01, time/batch = 14.9186s	
31593/33250 (epoch 47.508), train_loss = 0.70966006, grad/param norm = 1.6415e-01, time/batch = 14.6941s	
31594/33250 (epoch 47.510), train_loss = 0.60827926, grad/param norm = 1.5074e-01, time/batch = 15.0214s	
31595/33250 (epoch 47.511), train_loss = 0.71055693, grad/param norm = 2.1245e-01, time/batch = 15.0456s	
31596/33250 (epoch 47.513), train_loss = 0.83513156, grad/param norm = 2.0254e-01, time/batch = 17.7779s	
31597/33250 (epoch 47.514), train_loss = 0.70068524, grad/param norm = 1.7442e-01, time/batch = 15.1528s	
31598/33250 (epoch 47.516), train_loss = 0.66277408, grad/param norm = 1.7778e-01, time/batch = 16.9671s	
31599/33250 (epoch 47.517), train_loss = 0.69998378, grad/param norm = 1.6904e-01, time/batch = 14.3648s	
31600/33250 (epoch 47.519), train_loss = 0.66269211, grad/param norm = 1.3864e-01, time/batch = 14.2882s	
31601/33250 (epoch 47.520), train_loss = 0.89027298, grad/param norm = 2.2994e-01, time/batch = 14.8039s	
31602/33250 (epoch 47.522), train_loss = 0.73941115, grad/param norm = 1.9050e-01, time/batch = 14.7150s	
31603/33250 (epoch 47.523), train_loss = 0.67819420, grad/param norm = 2.0261e-01, time/batch = 14.7906s	
31604/33250 (epoch 47.525), train_loss = 0.61903129, grad/param norm = 1.8198e-01, time/batch = 15.1251s	
31605/33250 (epoch 47.526), train_loss = 0.63715623, grad/param norm = 1.5531e-01, time/batch = 14.9448s	
31606/33250 (epoch 47.528), train_loss = 0.69288688, grad/param norm = 1.8383e-01, time/batch = 17.8706s	
31607/33250 (epoch 47.529), train_loss = 0.67274809, grad/param norm = 1.9533e-01, time/batch = 15.7180s	
31608/33250 (epoch 47.531), train_loss = 0.64361523, grad/param norm = 1.7110e-01, time/batch = 16.6034s	
31609/33250 (epoch 47.532), train_loss = 0.74957793, grad/param norm = 1.6409e-01, time/batch = 16.2847s	
31610/33250 (epoch 47.534), train_loss = 0.65276190, grad/param norm = 1.5520e-01, time/batch = 15.2177s	
31611/33250 (epoch 47.535), train_loss = 0.70149100, grad/param norm = 1.8734e-01, time/batch = 14.8058s	
31612/33250 (epoch 47.537), train_loss = 0.73005672, grad/param norm = 1.6011e-01, time/batch = 14.7015s	
31613/33250 (epoch 47.538), train_loss = 0.76818555, grad/param norm = 1.9694e-01, time/batch = 14.7080s	
31614/33250 (epoch 47.540), train_loss = 0.85931130, grad/param norm = 1.6231e-01, time/batch = 15.0889s	
31615/33250 (epoch 47.541), train_loss = 0.78987129, grad/param norm = 2.0004e-01, time/batch = 14.3922s	
31616/33250 (epoch 47.543), train_loss = 0.77873014, grad/param norm = 1.5961e-01, time/batch = 14.6197s	
31617/33250 (epoch 47.544), train_loss = 0.62459872, grad/param norm = 1.7588e-01, time/batch = 15.8086s	
31618/33250 (epoch 47.546), train_loss = 0.67346172, grad/param norm = 1.8940e-01, time/batch = 16.1127s	
31619/33250 (epoch 47.547), train_loss = 0.67943578, grad/param norm = 1.7540e-01, time/batch = 14.9748s	
31620/33250 (epoch 47.549), train_loss = 0.74161195, grad/param norm = 2.0122e-01, time/batch = 15.2173s	
31621/33250 (epoch 47.550), train_loss = 0.70118686, grad/param norm = 1.7978e-01, time/batch = 14.6281s	
31622/33250 (epoch 47.552), train_loss = 0.77357823, grad/param norm = 1.8836e-01, time/batch = 14.6359s	
31623/33250 (epoch 47.553), train_loss = 0.73168105, grad/param norm = 1.6319e-01, time/batch = 14.3055s	
31624/33250 (epoch 47.555), train_loss = 0.71782455, grad/param norm = 1.6230e-01, time/batch = 14.8661s	
31625/33250 (epoch 47.556), train_loss = 0.74817709, grad/param norm = 2.4879e-01, time/batch = 14.5330s	
31626/33250 (epoch 47.558), train_loss = 0.75675904, grad/param norm = 1.8221e-01, time/batch = 14.4699s	
31627/33250 (epoch 47.559), train_loss = 0.68269119, grad/param norm = 1.6958e-01, time/batch = 14.3862s	
31628/33250 (epoch 47.561), train_loss = 0.60662381, grad/param norm = 1.5942e-01, time/batch = 15.7095s	
31629/33250 (epoch 47.562), train_loss = 0.73062734, grad/param norm = 1.8987e-01, time/batch = 15.4712s	
31630/33250 (epoch 47.564), train_loss = 0.86220750, grad/param norm = 2.3028e-01, time/batch = 15.9728s	
31631/33250 (epoch 47.565), train_loss = 0.83450576, grad/param norm = 2.4709e-01, time/batch = 15.6949s	
31632/33250 (epoch 47.567), train_loss = 0.83966847, grad/param norm = 2.0645e-01, time/batch = 14.7209s	
31633/33250 (epoch 47.568), train_loss = 0.69329334, grad/param norm = 1.8689e-01, time/batch = 14.8544s	
31634/33250 (epoch 47.570), train_loss = 0.79444028, grad/param norm = 2.0545e-01, time/batch = 14.8697s	
31635/33250 (epoch 47.571), train_loss = 0.82915810, grad/param norm = 2.0672e-01, time/batch = 14.6192s	
31636/33250 (epoch 47.573), train_loss = 0.78011863, grad/param norm = 2.7583e-01, time/batch = 14.7139s	
31637/33250 (epoch 47.574), train_loss = 0.65741708, grad/param norm = 1.4993e-01, time/batch = 14.6126s	
31638/33250 (epoch 47.576), train_loss = 0.74057186, grad/param norm = 1.7834e-01, time/batch = 14.4676s	
31639/33250 (epoch 47.577), train_loss = 0.70968036, grad/param norm = 1.7673e-01, time/batch = 15.4827s	
31640/33250 (epoch 47.579), train_loss = 0.62832728, grad/param norm = 1.7128e-01, time/batch = 15.9692s	
31641/33250 (epoch 47.580), train_loss = 0.73207189, grad/param norm = 1.8453e-01, time/batch = 15.5406s	
31642/33250 (epoch 47.582), train_loss = 0.67367673, grad/param norm = 1.8032e-01, time/batch = 16.9838s	
31643/33250 (epoch 47.583), train_loss = 0.79087835, grad/param norm = 1.9760e-01, time/batch = 14.8926s	
31644/33250 (epoch 47.585), train_loss = 0.81910471, grad/param norm = 1.6955e-01, time/batch = 14.9257s	
31645/33250 (epoch 47.586), train_loss = 0.68093152, grad/param norm = 1.9661e-01, time/batch = 14.8679s	
31646/33250 (epoch 47.588), train_loss = 0.76032116, grad/param norm = 1.6298e-01, time/batch = 14.6333s	
31647/33250 (epoch 47.589), train_loss = 0.71515213, grad/param norm = 1.9023e-01, time/batch = 14.6488s	
31648/33250 (epoch 47.591), train_loss = 0.72455556, grad/param norm = 3.1267e-01, time/batch = 15.0226s	
31649/33250 (epoch 47.592), train_loss = 0.70709523, grad/param norm = 1.9834e-01, time/batch = 14.8786s	
31650/33250 (epoch 47.594), train_loss = 0.82179374, grad/param norm = 2.0686e-01, time/batch = 15.9394s	
31651/33250 (epoch 47.595), train_loss = 0.72611256, grad/param norm = 1.8614e-01, time/batch = 15.8762s	
31652/33250 (epoch 47.597), train_loss = 0.60694672, grad/param norm = 1.5153e-01, time/batch = 15.3751s	
31653/33250 (epoch 47.598), train_loss = 0.69961510, grad/param norm = 1.9971e-01, time/batch = 15.0260s	
31654/33250 (epoch 47.600), train_loss = 0.69918038, grad/param norm = 1.9870e-01, time/batch = 15.3299s	
31655/33250 (epoch 47.602), train_loss = 0.73729543, grad/param norm = 2.0030e-01, time/batch = 15.0723s	
31656/33250 (epoch 47.603), train_loss = 0.76340301, grad/param norm = 2.1721e-01, time/batch = 15.0158s	
31657/33250 (epoch 47.605), train_loss = 0.72962723, grad/param norm = 1.8827e-01, time/batch = 15.1436s	
31658/33250 (epoch 47.606), train_loss = 0.76269483, grad/param norm = 1.7868e-01, time/batch = 14.8496s	
31659/33250 (epoch 47.608), train_loss = 0.72911057, grad/param norm = 1.7751e-01, time/batch = 14.6071s	
31660/33250 (epoch 47.609), train_loss = 0.63452089, grad/param norm = 1.7881e-01, time/batch = 15.0813s	
31661/33250 (epoch 47.611), train_loss = 0.69688757, grad/param norm = 1.9263e-01, time/batch = 14.4796s	
31662/33250 (epoch 47.612), train_loss = 0.73020394, grad/param norm = 1.8944e-01, time/batch = 14.4662s	
31663/33250 (epoch 47.614), train_loss = 0.93395316, grad/param norm = 2.7646e-01, time/batch = 15.1310s	
31664/33250 (epoch 47.615), train_loss = 0.83050002, grad/param norm = 1.9102e-01, time/batch = 20.7141s	
31665/33250 (epoch 47.617), train_loss = 0.93162612, grad/param norm = 2.7243e-01, time/batch = 16.9985s	
31666/33250 (epoch 47.618), train_loss = 0.93831302, grad/param norm = 2.8538e-01, time/batch = 17.1741s	
31667/33250 (epoch 47.620), train_loss = 0.80036344, grad/param norm = 2.0761e-01, time/batch = 17.6594s	
31668/33250 (epoch 47.621), train_loss = 0.80158343, grad/param norm = 2.0925e-01, time/batch = 17.7488s	
31669/33250 (epoch 47.623), train_loss = 0.72634496, grad/param norm = 2.0362e-01, time/batch = 17.5948s	
31670/33250 (epoch 47.624), train_loss = 0.71854207, grad/param norm = 2.0490e-01, time/batch = 17.4177s	
31671/33250 (epoch 47.626), train_loss = 0.74533199, grad/param norm = 2.1594e-01, time/batch = 19.9151s	
31672/33250 (epoch 47.627), train_loss = 0.69143189, grad/param norm = 1.7777e-01, time/batch = 18.3114s	
31673/33250 (epoch 47.629), train_loss = 0.78966132, grad/param norm = 2.0281e-01, time/batch = 18.7387s	
31674/33250 (epoch 47.630), train_loss = 0.70544780, grad/param norm = 2.0853e-01, time/batch = 17.3495s	
31675/33250 (epoch 47.632), train_loss = 0.64485032, grad/param norm = 1.6092e-01, time/batch = 17.5939s	
31676/33250 (epoch 47.633), train_loss = 0.75098421, grad/param norm = 1.8231e-01, time/batch = 17.7337s	
31677/33250 (epoch 47.635), train_loss = 0.66524036, grad/param norm = 1.6540e-01, time/batch = 17.3201s	
31678/33250 (epoch 47.636), train_loss = 0.69619314, grad/param norm = 1.8153e-01, time/batch = 17.3423s	
31679/33250 (epoch 47.638), train_loss = 0.65823945, grad/param norm = 2.0485e-01, time/batch = 17.9164s	
31680/33250 (epoch 47.639), train_loss = 0.63330842, grad/param norm = 1.8975e-01, time/batch = 19.1348s	
31681/33250 (epoch 47.641), train_loss = 0.70586882, grad/param norm = 1.8406e-01, time/batch = 21.1614s	
31682/33250 (epoch 47.642), train_loss = 0.55920618, grad/param norm = 1.8516e-01, time/batch = 18.4349s	
31683/33250 (epoch 47.644), train_loss = 0.52053070, grad/param norm = 1.6777e-01, time/batch = 17.1695s	
31684/33250 (epoch 47.645), train_loss = 0.73508046, grad/param norm = 2.0849e-01, time/batch = 24.4942s	
31685/33250 (epoch 47.647), train_loss = 0.60633379, grad/param norm = 2.0102e-01, time/batch = 16.4100s	
31686/33250 (epoch 47.648), train_loss = 0.59584850, grad/param norm = 1.6304e-01, time/batch = 14.7013s	
31687/33250 (epoch 47.650), train_loss = 0.83303558, grad/param norm = 2.1785e-01, time/batch = 15.5415s	
31688/33250 (epoch 47.651), train_loss = 0.74551711, grad/param norm = 1.7601e-01, time/batch = 14.8521s	
31689/33250 (epoch 47.653), train_loss = 0.69220555, grad/param norm = 1.7386e-01, time/batch = 14.6015s	
31690/33250 (epoch 47.654), train_loss = 0.72223804, grad/param norm = 1.6465e-01, time/batch = 15.1163s	
31691/33250 (epoch 47.656), train_loss = 0.78309347, grad/param norm = 1.5861e-01, time/batch = 15.2557s	
31692/33250 (epoch 47.657), train_loss = 0.55422583, grad/param norm = 1.8343e-01, time/batch = 14.5484s	
31693/33250 (epoch 47.659), train_loss = 0.69265115, grad/param norm = 1.7619e-01, time/batch = 14.5431s	
31694/33250 (epoch 47.660), train_loss = 0.74110971, grad/param norm = 1.8135e-01, time/batch = 14.6816s	
31695/33250 (epoch 47.662), train_loss = 0.73362630, grad/param norm = 1.7259e-01, time/batch = 14.8494s	
31696/33250 (epoch 47.663), train_loss = 0.65525555, grad/param norm = 2.0042e-01, time/batch = 15.1779s	
31697/33250 (epoch 47.665), train_loss = 0.76853951, grad/param norm = 1.9214e-01, time/batch = 14.7529s	
31698/33250 (epoch 47.666), train_loss = 0.69915578, grad/param norm = 1.6681e-01, time/batch = 14.8246s	
31699/33250 (epoch 47.668), train_loss = 0.81141342, grad/param norm = 2.0224e-01, time/batch = 14.6740s	
31700/33250 (epoch 47.669), train_loss = 0.73200185, grad/param norm = 1.8947e-01, time/batch = 14.5177s	
31701/33250 (epoch 47.671), train_loss = 0.62693901, grad/param norm = 1.8359e-01, time/batch = 14.9309s	
31702/33250 (epoch 47.672), train_loss = 0.78754177, grad/param norm = 1.8038e-01, time/batch = 14.6912s	
31703/33250 (epoch 47.674), train_loss = 0.67960649, grad/param norm = 2.0552e-01, time/batch = 14.7942s	
31704/33250 (epoch 47.675), train_loss = 0.74505750, grad/param norm = 1.6525e-01, time/batch = 14.7813s	
31705/33250 (epoch 47.677), train_loss = 0.76639640, grad/param norm = 1.9015e-01, time/batch = 14.6138s	
31706/33250 (epoch 47.678), train_loss = 0.66657240, grad/param norm = 2.0514e-01, time/batch = 14.7562s	
31707/33250 (epoch 47.680), train_loss = 0.82523735, grad/param norm = 2.3714e-01, time/batch = 14.9061s	
31708/33250 (epoch 47.681), train_loss = 0.65392789, grad/param norm = 1.6197e-01, time/batch = 14.5384s	
31709/33250 (epoch 47.683), train_loss = 0.65693939, grad/param norm = 1.8766e-01, time/batch = 15.5571s	
31710/33250 (epoch 47.684), train_loss = 0.61137045, grad/param norm = 1.9702e-01, time/batch = 14.5699s	
31711/33250 (epoch 47.686), train_loss = 0.63762714, grad/param norm = 2.4729e-01, time/batch = 14.8373s	
31712/33250 (epoch 47.687), train_loss = 0.73194363, grad/param norm = 1.7084e-01, time/batch = 14.6764s	
31713/33250 (epoch 47.689), train_loss = 0.65170029, grad/param norm = 2.3916e-01, time/batch = 14.3779s	
31714/33250 (epoch 47.690), train_loss = 0.75143136, grad/param norm = 2.1367e-01, time/batch = 14.5399s	
31715/33250 (epoch 47.692), train_loss = 0.71138180, grad/param norm = 1.8772e-01, time/batch = 15.1803s	
31716/33250 (epoch 47.693), train_loss = 0.75216733, grad/param norm = 1.7254e-01, time/batch = 14.4453s	
31717/33250 (epoch 47.695), train_loss = 0.73587395, grad/param norm = 2.0428e-01, time/batch = 14.5220s	
31718/33250 (epoch 47.696), train_loss = 0.76659248, grad/param norm = 1.7747e-01, time/batch = 14.4470s	
31719/33250 (epoch 47.698), train_loss = 0.70002488, grad/param norm = 2.1006e-01, time/batch = 15.0689s	
31720/33250 (epoch 47.699), train_loss = 0.90626888, grad/param norm = 2.0484e-01, time/batch = 14.4480s	
31721/33250 (epoch 47.701), train_loss = 0.75108191, grad/param norm = 1.8065e-01, time/batch = 14.6751s	
31722/33250 (epoch 47.702), train_loss = 0.71164986, grad/param norm = 2.5668e-01, time/batch = 14.6829s	
31723/33250 (epoch 47.704), train_loss = 0.89104598, grad/param norm = 2.9038e-01, time/batch = 14.7468s	
31724/33250 (epoch 47.705), train_loss = 0.68960886, grad/param norm = 1.9700e-01, time/batch = 16.3676s	
31725/33250 (epoch 47.707), train_loss = 0.62370656, grad/param norm = 1.7734e-01, time/batch = 16.8721s	
31726/33250 (epoch 47.708), train_loss = 0.82056657, grad/param norm = 1.9695e-01, time/batch = 16.2978s	
31727/33250 (epoch 47.710), train_loss = 0.74302047, grad/param norm = 2.0983e-01, time/batch = 14.7330s	
31728/33250 (epoch 47.711), train_loss = 0.63198544, grad/param norm = 1.7523e-01, time/batch = 14.5479s	
31729/33250 (epoch 47.713), train_loss = 0.75852085, grad/param norm = 1.8251e-01, time/batch = 14.5287s	
31730/33250 (epoch 47.714), train_loss = 0.70160768, grad/param norm = 1.8201e-01, time/batch = 14.6163s	
31731/33250 (epoch 47.716), train_loss = 0.74291708, grad/param norm = 1.7888e-01, time/batch = 14.4624s	
31732/33250 (epoch 47.717), train_loss = 0.70906184, grad/param norm = 1.5524e-01, time/batch = 14.8501s	
31733/33250 (epoch 47.719), train_loss = 0.66894057, grad/param norm = 1.7479e-01, time/batch = 14.3723s	
31734/33250 (epoch 47.720), train_loss = 0.94305240, grad/param norm = 1.7948e-01, time/batch = 14.1566s	
31735/33250 (epoch 47.722), train_loss = 0.63183645, grad/param norm = 1.6482e-01, time/batch = 15.5658s	
31736/33250 (epoch 47.723), train_loss = 0.57695593, grad/param norm = 1.5167e-01, time/batch = 17.0552s	
31737/33250 (epoch 47.725), train_loss = 0.71843316, grad/param norm = 1.6425e-01, time/batch = 15.8771s	
31738/33250 (epoch 47.726), train_loss = 0.75405929, grad/param norm = 1.7339e-01, time/batch = 15.6115s	
31739/33250 (epoch 47.728), train_loss = 0.75919188, grad/param norm = 1.8214e-01, time/batch = 14.9506s	
31740/33250 (epoch 47.729), train_loss = 0.77989153, grad/param norm = 1.8540e-01, time/batch = 14.8025s	
31741/33250 (epoch 47.731), train_loss = 0.63332713, grad/param norm = 1.9103e-01, time/batch = 14.9442s	
31742/33250 (epoch 47.732), train_loss = 0.65725887, grad/param norm = 1.6981e-01, time/batch = 15.1123s	
31743/33250 (epoch 47.734), train_loss = 0.74834172, grad/param norm = 1.9907e-01, time/batch = 14.1362s	
31744/33250 (epoch 47.735), train_loss = 0.74959110, grad/param norm = 2.0107e-01, time/batch = 14.2202s	
31745/33250 (epoch 47.737), train_loss = 0.70462024, grad/param norm = 1.6265e-01, time/batch = 14.3736s	
31746/33250 (epoch 47.738), train_loss = 0.76615093, grad/param norm = 1.9399e-01, time/batch = 14.1457s	
31747/33250 (epoch 47.740), train_loss = 0.72779419, grad/param norm = 1.7605e-01, time/batch = 14.6142s	
31748/33250 (epoch 47.741), train_loss = 0.77439203, grad/param norm = 1.7180e-01, time/batch = 14.0735s	
31749/33250 (epoch 47.743), train_loss = 0.68021933, grad/param norm = 1.6151e-01, time/batch = 14.9473s	
31750/33250 (epoch 47.744), train_loss = 0.68079121, grad/param norm = 1.9510e-01, time/batch = 14.6437s	
31751/33250 (epoch 47.746), train_loss = 0.66781074, grad/param norm = 1.6480e-01, time/batch = 15.1689s	
31752/33250 (epoch 47.747), train_loss = 0.63378609, grad/param norm = 1.9542e-01, time/batch = 14.3776s	
31753/33250 (epoch 47.749), train_loss = 0.83093259, grad/param norm = 1.9414e-01, time/batch = 14.1200s	
31754/33250 (epoch 47.750), train_loss = 0.83507124, grad/param norm = 1.8367e-01, time/batch = 14.2116s	
31755/33250 (epoch 47.752), train_loss = 0.69951226, grad/param norm = 1.8284e-01, time/batch = 14.4466s	
31756/33250 (epoch 47.753), train_loss = 0.69874285, grad/param norm = 1.9080e-01, time/batch = 14.0572s	
31757/33250 (epoch 47.755), train_loss = 0.60158551, grad/param norm = 2.0025e-01, time/batch = 14.7177s	
31758/33250 (epoch 47.756), train_loss = 0.72884391, grad/param norm = 1.7752e-01, time/batch = 14.9621s	
31759/33250 (epoch 47.758), train_loss = 0.88389896, grad/param norm = 1.9292e-01, time/batch = 15.1054s	
31760/33250 (epoch 47.759), train_loss = 0.69598905, grad/param norm = 1.7956e-01, time/batch = 16.0286s	
31761/33250 (epoch 47.761), train_loss = 0.76007806, grad/param norm = 2.0797e-01, time/batch = 14.9688s	
31762/33250 (epoch 47.762), train_loss = 0.78140553, grad/param norm = 1.8481e-01, time/batch = 14.6964s	
31763/33250 (epoch 47.764), train_loss = 0.64657678, grad/param norm = 2.0364e-01, time/batch = 14.8547s	
31764/33250 (epoch 47.765), train_loss = 0.74859535, grad/param norm = 1.9000e-01, time/batch = 14.7722s	
31765/33250 (epoch 47.767), train_loss = 0.57732695, grad/param norm = 1.6528e-01, time/batch = 14.8010s	
31766/33250 (epoch 47.768), train_loss = 0.61917854, grad/param norm = 2.0101e-01, time/batch = 14.6249s	
31767/33250 (epoch 47.770), train_loss = 0.76964775, grad/param norm = 2.2045e-01, time/batch = 15.4181s	
31768/33250 (epoch 47.771), train_loss = 0.77580377, grad/param norm = 2.0077e-01, time/batch = 14.7976s	
31769/33250 (epoch 47.773), train_loss = 0.71300507, grad/param norm = 1.9046e-01, time/batch = 14.8187s	
31770/33250 (epoch 47.774), train_loss = 0.60470877, grad/param norm = 1.8096e-01, time/batch = 15.3211s	
31771/33250 (epoch 47.776), train_loss = 0.69133399, grad/param norm = 1.7534e-01, time/batch = 14.9561s	
31772/33250 (epoch 47.777), train_loss = 0.81385855, grad/param norm = 2.0553e-01, time/batch = 15.2827s	
31773/33250 (epoch 47.779), train_loss = 0.70431417, grad/param norm = 2.0694e-01, time/batch = 14.1377s	
31774/33250 (epoch 47.780), train_loss = 0.84642333, grad/param norm = 2.3093e-01, time/batch = 14.3063s	
31775/33250 (epoch 47.782), train_loss = 0.73711618, grad/param norm = 2.7095e-01, time/batch = 14.4538s	
31776/33250 (epoch 47.783), train_loss = 0.58143951, grad/param norm = 1.8014e-01, time/batch = 14.4647s	
31777/33250 (epoch 47.785), train_loss = 0.64679328, grad/param norm = 1.7497e-01, time/batch = 14.7200s	
31778/33250 (epoch 47.786), train_loss = 0.79593829, grad/param norm = 2.2345e-01, time/batch = 14.4652s	
31779/33250 (epoch 47.788), train_loss = 0.83450146, grad/param norm = 1.8946e-01, time/batch = 14.8642s	
31780/33250 (epoch 47.789), train_loss = 0.83073581, grad/param norm = 2.2738e-01, time/batch = 15.1370s	
31781/33250 (epoch 47.791), train_loss = 0.82986102, grad/param norm = 2.0496e-01, time/batch = 15.3072s	
31782/33250 (epoch 47.792), train_loss = 0.90408621, grad/param norm = 2.0759e-01, time/batch = 15.3009s	
31783/33250 (epoch 47.794), train_loss = 0.69561013, grad/param norm = 1.7720e-01, time/batch = 15.0549s	
31784/33250 (epoch 47.795), train_loss = 0.71925576, grad/param norm = 1.9034e-01, time/batch = 14.8034s	
31785/33250 (epoch 47.797), train_loss = 0.79055195, grad/param norm = 1.8738e-01, time/batch = 14.5480s	
31786/33250 (epoch 47.798), train_loss = 0.70250633, grad/param norm = 2.2195e-01, time/batch = 14.6282s	
31787/33250 (epoch 47.800), train_loss = 0.76701369, grad/param norm = 2.0757e-01, time/batch = 14.6202s	
31788/33250 (epoch 47.802), train_loss = 0.73920112, grad/param norm = 1.7895e-01, time/batch = 14.6086s	
31789/33250 (epoch 47.803), train_loss = 0.77602774, grad/param norm = 1.6558e-01, time/batch = 14.2087s	
31790/33250 (epoch 47.805), train_loss = 0.75336996, grad/param norm = 1.8030e-01, time/batch = 14.3582s	
31791/33250 (epoch 47.806), train_loss = 0.72990660, grad/param norm = 2.1479e-01, time/batch = 14.7653s	
31792/33250 (epoch 47.808), train_loss = 0.66956119, grad/param norm = 1.7624e-01, time/batch = 16.7024s	
31793/33250 (epoch 47.809), train_loss = 0.65435179, grad/param norm = 1.5562e-01, time/batch = 15.2427s	
31794/33250 (epoch 47.811), train_loss = 0.63386782, grad/param norm = 1.7438e-01, time/batch = 16.0986s	
31795/33250 (epoch 47.812), train_loss = 0.74477035, grad/param norm = 1.8989e-01, time/batch = 14.7821s	
31796/33250 (epoch 47.814), train_loss = 0.68688816, grad/param norm = 2.0410e-01, time/batch = 14.5973s	
31797/33250 (epoch 47.815), train_loss = 0.73513637, grad/param norm = 1.7056e-01, time/batch = 14.7973s	
31798/33250 (epoch 47.817), train_loss = 0.69711146, grad/param norm = 1.6963e-01, time/batch = 14.4622s	
31799/33250 (epoch 47.818), train_loss = 0.65629050, grad/param norm = 1.8338e-01, time/batch = 20.1750s	
31800/33250 (epoch 47.820), train_loss = 0.75455293, grad/param norm = 1.9539e-01, time/batch = 23.5075s	
31801/33250 (epoch 47.821), train_loss = 0.72320664, grad/param norm = 1.4911e-01, time/batch = 18.3619s	
31802/33250 (epoch 47.823), train_loss = 0.96096295, grad/param norm = 2.1784e-01, time/batch = 15.7916s	
31803/33250 (epoch 47.824), train_loss = 0.66672151, grad/param norm = 1.8608e-01, time/batch = 17.5533s	
31804/33250 (epoch 47.826), train_loss = 0.74787943, grad/param norm = 1.9386e-01, time/batch = 16.4633s	
31805/33250 (epoch 47.827), train_loss = 0.68465354, grad/param norm = 1.9375e-01, time/batch = 14.7698s	
31806/33250 (epoch 47.829), train_loss = 0.75030513, grad/param norm = 2.0881e-01, time/batch = 14.9303s	
31807/33250 (epoch 47.830), train_loss = 0.77254845, grad/param norm = 2.2058e-01, time/batch = 15.1009s	
31808/33250 (epoch 47.832), train_loss = 0.76094305, grad/param norm = 1.7644e-01, time/batch = 14.6923s	
31809/33250 (epoch 47.833), train_loss = 0.73167648, grad/param norm = 1.8820e-01, time/batch = 15.2699s	
31810/33250 (epoch 47.835), train_loss = 0.65215219, grad/param norm = 2.3285e-01, time/batch = 15.2107s	
31811/33250 (epoch 47.836), train_loss = 0.72114028, grad/param norm = 1.6844e-01, time/batch = 15.6308s	
31812/33250 (epoch 47.838), train_loss = 0.74762746, grad/param norm = 1.7133e-01, time/batch = 15.9610s	
31813/33250 (epoch 47.839), train_loss = 0.69775504, grad/param norm = 1.8081e-01, time/batch = 15.2755s	
31814/33250 (epoch 47.841), train_loss = 0.67846924, grad/param norm = 1.7606e-01, time/batch = 17.3703s	
31815/33250 (epoch 47.842), train_loss = 0.86722059, grad/param norm = 2.0986e-01, time/batch = 16.1393s	
31816/33250 (epoch 47.844), train_loss = 0.79725016, grad/param norm = 2.0562e-01, time/batch = 14.7113s	
31817/33250 (epoch 47.845), train_loss = 0.88977997, grad/param norm = 2.5190e-01, time/batch = 15.0933s	
31818/33250 (epoch 47.847), train_loss = 0.80675619, grad/param norm = 1.6914e-01, time/batch = 14.9578s	
31819/33250 (epoch 47.848), train_loss = 0.90122771, grad/param norm = 2.2977e-01, time/batch = 14.7898s	
31820/33250 (epoch 47.850), train_loss = 0.81134185, grad/param norm = 1.8799e-01, time/batch = 14.7965s	
31821/33250 (epoch 47.851), train_loss = 0.63619673, grad/param norm = 2.1708e-01, time/batch = 14.7784s	
31822/33250 (epoch 47.853), train_loss = 0.73257162, grad/param norm = 2.4882e-01, time/batch = 14.8046s	
31823/33250 (epoch 47.854), train_loss = 0.67717814, grad/param norm = 1.8201e-01, time/batch = 15.2229s	
31824/33250 (epoch 47.856), train_loss = 0.67669855, grad/param norm = 2.0290e-01, time/batch = 16.6381s	
31825/33250 (epoch 47.857), train_loss = 0.62326194, grad/param norm = 1.8027e-01, time/batch = 15.0446s	
31826/33250 (epoch 47.859), train_loss = 0.69776768, grad/param norm = 2.1514e-01, time/batch = 15.9510s	
31827/33250 (epoch 47.860), train_loss = 0.77874483, grad/param norm = 1.7996e-01, time/batch = 14.8465s	
31828/33250 (epoch 47.862), train_loss = 0.67566563, grad/param norm = 1.8715e-01, time/batch = 14.7609s	
31829/33250 (epoch 47.863), train_loss = 0.67538563, grad/param norm = 2.0753e-01, time/batch = 15.0198s	
31830/33250 (epoch 47.865), train_loss = 0.74062847, grad/param norm = 2.0811e-01, time/batch = 14.6285s	
31831/33250 (epoch 47.866), train_loss = 0.66392368, grad/param norm = 2.1003e-01, time/batch = 14.6313s	
31832/33250 (epoch 47.868), train_loss = 0.72399857, grad/param norm = 2.3136e-01, time/batch = 14.6933s	
31833/33250 (epoch 47.869), train_loss = 0.74402733, grad/param norm = 2.0338e-01, time/batch = 14.9289s	
31834/33250 (epoch 47.871), train_loss = 0.60738871, grad/param norm = 1.6634e-01, time/batch = 16.2247s	
31835/33250 (epoch 47.872), train_loss = 0.79582423, grad/param norm = 2.3839e-01, time/batch = 16.5551s	
31836/33250 (epoch 47.874), train_loss = 0.70637074, grad/param norm = 2.5377e-01, time/batch = 16.8846s	
31837/33250 (epoch 47.875), train_loss = 0.62738918, grad/param norm = 2.1240e-01, time/batch = 15.9287s	
31838/33250 (epoch 47.877), train_loss = 0.82899380, grad/param norm = 2.0285e-01, time/batch = 14.3068s	
31839/33250 (epoch 47.878), train_loss = 0.74049302, grad/param norm = 1.8836e-01, time/batch = 14.8470s	
31840/33250 (epoch 47.880), train_loss = 0.74016816, grad/param norm = 2.2810e-01, time/batch = 14.5515s	
31841/33250 (epoch 47.881), train_loss = 0.86138873, grad/param norm = 3.2544e-01, time/batch = 14.5402s	
31842/33250 (epoch 47.883), train_loss = 0.78334343, grad/param norm = 1.9910e-01, time/batch = 14.4523s	
31843/33250 (epoch 47.884), train_loss = 0.83079984, grad/param norm = 2.5315e-01, time/batch = 14.9604s	
31844/33250 (epoch 47.886), train_loss = 0.68431518, grad/param norm = 1.7373e-01, time/batch = 15.2249s	
31845/33250 (epoch 47.887), train_loss = 0.71928029, grad/param norm = 2.8651e-01, time/batch = 14.9770s	
31846/33250 (epoch 47.889), train_loss = 0.69372022, grad/param norm = 1.5602e-01, time/batch = 15.9763s	
31847/33250 (epoch 47.890), train_loss = 0.56008958, grad/param norm = 1.3306e-01, time/batch = 14.8726s	
31848/33250 (epoch 47.892), train_loss = 0.76226876, grad/param norm = 1.7288e-01, time/batch = 14.6452s	
31849/33250 (epoch 47.893), train_loss = 0.77155380, grad/param norm = 2.0614e-01, time/batch = 14.8589s	
31850/33250 (epoch 47.895), train_loss = 0.70501604, grad/param norm = 2.0405e-01, time/batch = 14.7076s	
31851/33250 (epoch 47.896), train_loss = 0.79330770, grad/param norm = 2.0427e-01, time/batch = 14.9390s	
31852/33250 (epoch 47.898), train_loss = 0.73042730, grad/param norm = 1.8505e-01, time/batch = 14.6973s	
31853/33250 (epoch 47.899), train_loss = 0.69074760, grad/param norm = 1.7225e-01, time/batch = 14.7806s	
31854/33250 (epoch 47.901), train_loss = 0.61269594, grad/param norm = 1.5671e-01, time/batch = 14.6267s	
31855/33250 (epoch 47.902), train_loss = 0.67605659, grad/param norm = 1.8334e-01, time/batch = 15.1279s	
31856/33250 (epoch 47.904), train_loss = 0.66358711, grad/param norm = 1.9326e-01, time/batch = 17.9336s	
31857/33250 (epoch 47.905), train_loss = 0.70093322, grad/param norm = 1.6657e-01, time/batch = 14.6391s	
31858/33250 (epoch 47.907), train_loss = 0.67364685, grad/param norm = 2.3346e-01, time/batch = 14.9651s	
31859/33250 (epoch 47.908), train_loss = 0.71291428, grad/param norm = 1.6403e-01, time/batch = 14.7201s	
31860/33250 (epoch 47.910), train_loss = 0.81342334, grad/param norm = 2.7433e-01, time/batch = 14.5225s	
31861/33250 (epoch 47.911), train_loss = 0.63654218, grad/param norm = 1.8842e-01, time/batch = 15.2101s	
31862/33250 (epoch 47.913), train_loss = 0.66496155, grad/param norm = 1.6506e-01, time/batch = 14.6163s	
31863/33250 (epoch 47.914), train_loss = 0.60079240, grad/param norm = 1.6919e-01, time/batch = 14.4692s	
31864/33250 (epoch 47.916), train_loss = 0.61891249, grad/param norm = 1.5916e-01, time/batch = 14.7955s	
31865/33250 (epoch 47.917), train_loss = 0.73423277, grad/param norm = 1.4291e-01, time/batch = 14.7123s	
31866/33250 (epoch 47.919), train_loss = 0.66023588, grad/param norm = 2.0476e-01, time/batch = 14.5534s	
31867/33250 (epoch 47.920), train_loss = 0.73854107, grad/param norm = 1.8804e-01, time/batch = 15.8371s	
31868/33250 (epoch 47.922), train_loss = 0.73909288, grad/param norm = 2.0241e-01, time/batch = 16.5410s	
31869/33250 (epoch 47.923), train_loss = 0.69553287, grad/param norm = 1.7952e-01, time/batch = 15.6736s	
31870/33250 (epoch 47.925), train_loss = 0.70950002, grad/param norm = 1.8121e-01, time/batch = 15.2360s	
31871/33250 (epoch 47.926), train_loss = 0.66360676, grad/param norm = 1.5865e-01, time/batch = 14.6336s	
31872/33250 (epoch 47.928), train_loss = 0.69517482, grad/param norm = 1.7887e-01, time/batch = 14.7008s	
31873/33250 (epoch 47.929), train_loss = 0.64437809, grad/param norm = 1.4892e-01, time/batch = 14.7789s	
31874/33250 (epoch 47.931), train_loss = 0.80194561, grad/param norm = 1.8648e-01, time/batch = 14.5180s	
31875/33250 (epoch 47.932), train_loss = 0.65553243, grad/param norm = 1.9417e-01, time/batch = 14.6248s	
31876/33250 (epoch 47.934), train_loss = 0.65647541, grad/param norm = 1.7220e-01, time/batch = 14.9488s	
31877/33250 (epoch 47.935), train_loss = 0.68709642, grad/param norm = 1.7336e-01, time/batch = 14.6409s	
31878/33250 (epoch 47.937), train_loss = 0.66536905, grad/param norm = 1.9940e-01, time/batch = 15.5058s	
31879/33250 (epoch 47.938), train_loss = 0.67749302, grad/param norm = 2.2434e-01, time/batch = 14.8099s	
31880/33250 (epoch 47.940), train_loss = 0.68834855, grad/param norm = 2.0127e-01, time/batch = 14.8383s	
31881/33250 (epoch 47.941), train_loss = 0.75724461, grad/param norm = 1.9146e-01, time/batch = 15.7090s	
31882/33250 (epoch 47.943), train_loss = 0.84606356, grad/param norm = 2.0405e-01, time/batch = 14.6159s	
31883/33250 (epoch 47.944), train_loss = 0.68377213, grad/param norm = 1.8210e-01, time/batch = 14.7971s	
31884/33250 (epoch 47.946), train_loss = 0.77704695, grad/param norm = 2.1061e-01, time/batch = 14.6995s	
31885/33250 (epoch 47.947), train_loss = 0.63592635, grad/param norm = 1.6605e-01, time/batch = 14.4606s	
31886/33250 (epoch 47.949), train_loss = 0.79625903, grad/param norm = 2.5106e-01, time/batch = 15.1060s	
31887/33250 (epoch 47.950), train_loss = 0.78008039, grad/param norm = 1.6810e-01, time/batch = 14.8632s	
31888/33250 (epoch 47.952), train_loss = 0.74752669, grad/param norm = 2.1985e-01, time/batch = 15.1290s	
31889/33250 (epoch 47.953), train_loss = 0.73542233, grad/param norm = 2.1464e-01, time/batch = 16.3853s	
31890/33250 (epoch 47.955), train_loss = 0.79620476, grad/param norm = 2.0899e-01, time/batch = 18.8718s	
31891/33250 (epoch 47.956), train_loss = 0.72016686, grad/param norm = 2.3676e-01, time/batch = 15.7991s	
31892/33250 (epoch 47.958), train_loss = 0.69369683, grad/param norm = 1.8877e-01, time/batch = 16.1960s	
31893/33250 (epoch 47.959), train_loss = 0.70092501, grad/param norm = 2.1467e-01, time/batch = 17.9302s	
31894/33250 (epoch 47.961), train_loss = 0.89627181, grad/param norm = 2.0047e-01, time/batch = 14.7083s	
31895/33250 (epoch 47.962), train_loss = 0.71696992, grad/param norm = 2.1768e-01, time/batch = 14.8837s	
31896/33250 (epoch 47.964), train_loss = 0.83762721, grad/param norm = 2.3003e-01, time/batch = 15.0139s	
31897/33250 (epoch 47.965), train_loss = 0.77284254, grad/param norm = 1.9117e-01, time/batch = 14.7742s	
31898/33250 (epoch 47.967), train_loss = 0.73321936, grad/param norm = 2.2713e-01, time/batch = 14.8646s	
31899/33250 (epoch 47.968), train_loss = 0.82414022, grad/param norm = 1.6612e-01, time/batch = 16.7061s	
31900/33250 (epoch 47.970), train_loss = 0.91322709, grad/param norm = 2.3149e-01, time/batch = 15.0657s	
31901/33250 (epoch 47.971), train_loss = 0.88689810, grad/param norm = 2.2637e-01, time/batch = 15.7217s	
31902/33250 (epoch 47.973), train_loss = 0.69033988, grad/param norm = 1.7283e-01, time/batch = 16.5571s	
31903/33250 (epoch 47.974), train_loss = 0.78717919, grad/param norm = 2.0973e-01, time/batch = 15.2897s	
31904/33250 (epoch 47.976), train_loss = 0.71108781, grad/param norm = 2.1754e-01, time/batch = 15.0239s	
31905/33250 (epoch 47.977), train_loss = 0.72670719, grad/param norm = 1.8571e-01, time/batch = 15.1307s	
31906/33250 (epoch 47.979), train_loss = 0.79385198, grad/param norm = 2.0939e-01, time/batch = 14.8719s	
31907/33250 (epoch 47.980), train_loss = 0.78526270, grad/param norm = 1.9534e-01, time/batch = 15.2106s	
31908/33250 (epoch 47.982), train_loss = 0.71665196, grad/param norm = 1.6902e-01, time/batch = 14.7938s	
31909/33250 (epoch 47.983), train_loss = 0.78419034, grad/param norm = 2.3509e-01, time/batch = 14.9187s	
31910/33250 (epoch 47.985), train_loss = 0.69753052, grad/param norm = 1.9253e-01, time/batch = 14.8927s	
31911/33250 (epoch 47.986), train_loss = 0.79758348, grad/param norm = 2.1646e-01, time/batch = 15.1462s	
31912/33250 (epoch 47.988), train_loss = 0.85046557, grad/param norm = 2.2103e-01, time/batch = 16.0573s	
31913/33250 (epoch 47.989), train_loss = 0.81257320, grad/param norm = 1.8103e-01, time/batch = 16.8822s	
31914/33250 (epoch 47.991), train_loss = 0.80482894, grad/param norm = 1.8566e-01, time/batch = 14.6387s	
31915/33250 (epoch 47.992), train_loss = 0.71836451, grad/param norm = 2.8893e-01, time/batch = 14.7074s	
31916/33250 (epoch 47.994), train_loss = 0.68742030, grad/param norm = 1.8421e-01, time/batch = 0.8785s	
31917/33250 (epoch 47.995), train_loss = 0.73136652, grad/param norm = 2.8155e-01, time/batch = 0.6685s	
31918/33250 (epoch 47.997), train_loss = 0.57486485, grad/param norm = 1.6455e-01, time/batch = 0.6673s	
31919/33250 (epoch 47.998), train_loss = 0.74921559, grad/param norm = 1.9364e-01, time/batch = 0.6661s	
decayed learning rate by a factor 0.97 to 0.00060971605649306	
31920/33250 (epoch 48.000), train_loss = 0.79866494, grad/param norm = 2.1434e-01, time/batch = 0.6596s	
31921/33250 (epoch 48.002), train_loss = 0.96224655, grad/param norm = 2.0293e-01, time/batch = 0.6697s	
31922/33250 (epoch 48.003), train_loss = 0.80173163, grad/param norm = 2.2648e-01, time/batch = 0.6844s	
31923/33250 (epoch 48.005), train_loss = 0.62816196, grad/param norm = 1.7096e-01, time/batch = 0.8475s	
31924/33250 (epoch 48.006), train_loss = 0.62632781, grad/param norm = 1.7407e-01, time/batch = 0.9697s	
31925/33250 (epoch 48.008), train_loss = 0.82181313, grad/param norm = 2.0462e-01, time/batch = 0.9659s	
31926/33250 (epoch 48.009), train_loss = 0.90867399, grad/param norm = 2.0923e-01, time/batch = 0.9674s	
31927/33250 (epoch 48.011), train_loss = 0.69226938, grad/param norm = 1.9148e-01, time/batch = 0.9769s	
31928/33250 (epoch 48.012), train_loss = 0.71273871, grad/param norm = 2.4211e-01, time/batch = 1.3482s	
31929/33250 (epoch 48.014), train_loss = 0.82068176, grad/param norm = 2.3104e-01, time/batch = 1.8307s	
31930/33250 (epoch 48.015), train_loss = 0.77373915, grad/param norm = 2.2215e-01, time/batch = 1.8383s	
31931/33250 (epoch 48.017), train_loss = 0.74583048, grad/param norm = 2.1056e-01, time/batch = 11.3242s	
31932/33250 (epoch 48.018), train_loss = 0.59832347, grad/param norm = 2.1755e-01, time/batch = 14.5571s	
31933/33250 (epoch 48.020), train_loss = 0.76104216, grad/param norm = 1.6621e-01, time/batch = 14.5494s	
31934/33250 (epoch 48.021), train_loss = 0.76236310, grad/param norm = 1.8253e-01, time/batch = 14.7913s	
31935/33250 (epoch 48.023), train_loss = 0.61591732, grad/param norm = 2.6727e-01, time/batch = 14.4705s	
31936/33250 (epoch 48.024), train_loss = 0.82284745, grad/param norm = 2.0672e-01, time/batch = 14.2276s	
31937/33250 (epoch 48.026), train_loss = 0.80093168, grad/param norm = 2.0238e-01, time/batch = 14.4819s	
31938/33250 (epoch 48.027), train_loss = 0.77431977, grad/param norm = 1.9286e-01, time/batch = 14.6397s	
31939/33250 (epoch 48.029), train_loss = 0.70718420, grad/param norm = 1.8494e-01, time/batch = 14.6959s	
31940/33250 (epoch 48.030), train_loss = 0.72514303, grad/param norm = 1.7874e-01, time/batch = 15.0222s	
31941/33250 (epoch 48.032), train_loss = 0.90229169, grad/param norm = 3.0996e-01, time/batch = 14.4754s	
31942/33250 (epoch 48.033), train_loss = 0.72707800, grad/param norm = 2.2338e-01, time/batch = 14.9396s	
31943/33250 (epoch 48.035), train_loss = 0.74998562, grad/param norm = 2.1783e-01, time/batch = 14.8771s	
31944/33250 (epoch 48.036), train_loss = 0.76937701, grad/param norm = 2.0171e-01, time/batch = 14.6389s	
31945/33250 (epoch 48.038), train_loss = 0.75626627, grad/param norm = 1.7669e-01, time/batch = 14.8921s	
31946/33250 (epoch 48.039), train_loss = 0.68795000, grad/param norm = 1.6480e-01, time/batch = 14.6040s	
31947/33250 (epoch 48.041), train_loss = 0.76737280, grad/param norm = 2.4629e-01, time/batch = 14.7282s	
31948/33250 (epoch 48.042), train_loss = 0.63416407, grad/param norm = 1.5896e-01, time/batch = 15.0580s	
31949/33250 (epoch 48.044), train_loss = 0.83824396, grad/param norm = 2.0429e-01, time/batch = 16.4751s	
31950/33250 (epoch 48.045), train_loss = 0.84958337, grad/param norm = 1.9070e-01, time/batch = 16.5985s	
31951/33250 (epoch 48.047), train_loss = 0.76850824, grad/param norm = 1.8079e-01, time/batch = 17.9570s	
31952/33250 (epoch 48.048), train_loss = 0.80021644, grad/param norm = 2.3622e-01, time/batch = 14.6261s	
31953/33250 (epoch 48.050), train_loss = 0.75106998, grad/param norm = 1.9322e-01, time/batch = 15.0115s	
31954/33250 (epoch 48.051), train_loss = 0.73095192, grad/param norm = 1.7317e-01, time/batch = 14.2814s	
31955/33250 (epoch 48.053), train_loss = 0.78690626, grad/param norm = 2.2611e-01, time/batch = 14.0649s	
31956/33250 (epoch 48.054), train_loss = 0.63019417, grad/param norm = 1.7213e-01, time/batch = 14.1531s	
31957/33250 (epoch 48.056), train_loss = 0.62441236, grad/param norm = 1.7846e-01, time/batch = 14.3770s	
31958/33250 (epoch 48.057), train_loss = 0.80464744, grad/param norm = 1.8686e-01, time/batch = 14.5538s	
31959/33250 (epoch 48.059), train_loss = 0.73114734, grad/param norm = 1.7841e-01, time/batch = 15.8836s	
31960/33250 (epoch 48.060), train_loss = 0.75137212, grad/param norm = 1.9072e-01, time/batch = 14.8590s	
31961/33250 (epoch 48.062), train_loss = 0.82132554, grad/param norm = 2.0546e-01, time/batch = 15.8869s	
31962/33250 (epoch 48.063), train_loss = 0.85017344, grad/param norm = 2.0446e-01, time/batch = 15.0511s	
31963/33250 (epoch 48.065), train_loss = 0.70895929, grad/param norm = 2.1033e-01, time/batch = 14.6204s	
31964/33250 (epoch 48.066), train_loss = 0.78216730, grad/param norm = 1.9063e-01, time/batch = 14.9633s	
31965/33250 (epoch 48.068), train_loss = 0.70218023, grad/param norm = 1.9884e-01, time/batch = 14.6277s	
31966/33250 (epoch 48.069), train_loss = 0.75932270, grad/param norm = 2.0277e-01, time/batch = 14.7988s	
31967/33250 (epoch 48.071), train_loss = 0.71175588, grad/param norm = 1.6766e-01, time/batch = 14.3917s	
31968/33250 (epoch 48.072), train_loss = 0.66545844, grad/param norm = 1.5800e-01, time/batch = 14.6350s	
31969/33250 (epoch 48.074), train_loss = 0.74033362, grad/param norm = 1.7445e-01, time/batch = 15.2752s	
31970/33250 (epoch 48.075), train_loss = 0.69873959, grad/param norm = 1.8773e-01, time/batch = 15.0236s	
31971/33250 (epoch 48.077), train_loss = 0.72564413, grad/param norm = 2.4620e-01, time/batch = 16.8020s	
31972/33250 (epoch 48.078), train_loss = 0.73869024, grad/param norm = 1.8641e-01, time/batch = 14.7937s	
31973/33250 (epoch 48.080), train_loss = 0.76584804, grad/param norm = 3.2996e-01, time/batch = 16.1280s	
31974/33250 (epoch 48.081), train_loss = 0.78191963, grad/param norm = 1.9330e-01, time/batch = 15.2669s	
31975/33250 (epoch 48.083), train_loss = 0.84669156, grad/param norm = 1.9388e-01, time/batch = 14.5507s	
31976/33250 (epoch 48.084), train_loss = 0.78127971, grad/param norm = 2.1631e-01, time/batch = 14.7195s	
31977/33250 (epoch 48.086), train_loss = 0.76529844, grad/param norm = 1.7268e-01, time/batch = 14.7073s	
31978/33250 (epoch 48.087), train_loss = 0.66073072, grad/param norm = 1.6791e-01, time/batch = 15.2677s	
31979/33250 (epoch 48.089), train_loss = 0.72465281, grad/param norm = 1.9510e-01, time/batch = 14.7145s	
31980/33250 (epoch 48.090), train_loss = 0.76953505, grad/param norm = 1.8134e-01, time/batch = 14.5395s	
31981/33250 (epoch 48.092), train_loss = 0.69371853, grad/param norm = 1.6235e-01, time/batch = 15.4704s	
31982/33250 (epoch 48.093), train_loss = 0.72649543, grad/param norm = 1.8184e-01, time/batch = 16.0630s	
31983/33250 (epoch 48.095), train_loss = 0.73776308, grad/param norm = 2.2819e-01, time/batch = 17.0354s	
31984/33250 (epoch 48.096), train_loss = 0.61783096, grad/param norm = 1.8002e-01, time/batch = 16.3958s	
31985/33250 (epoch 48.098), train_loss = 0.62244298, grad/param norm = 2.0633e-01, time/batch = 14.8851s	
31986/33250 (epoch 48.099), train_loss = 0.57293263, grad/param norm = 1.6390e-01, time/batch = 16.1191s	
31987/33250 (epoch 48.101), train_loss = 0.71647962, grad/param norm = 1.9867e-01, time/batch = 15.1200s	
31988/33250 (epoch 48.102), train_loss = 0.68543555, grad/param norm = 1.7101e-01, time/batch = 14.9402s	
31989/33250 (epoch 48.104), train_loss = 0.58017498, grad/param norm = 1.7082e-01, time/batch = 15.2541s	
31990/33250 (epoch 48.105), train_loss = 0.68169926, grad/param norm = 1.7984e-01, time/batch = 15.3482s	
31991/33250 (epoch 48.107), train_loss = 0.60645288, grad/param norm = 1.4781e-01, time/batch = 15.7991s	
31992/33250 (epoch 48.108), train_loss = 0.72473759, grad/param norm = 2.1124e-01, time/batch = 16.5370s	
31993/33250 (epoch 48.110), train_loss = 0.62924427, grad/param norm = 1.8117e-01, time/batch = 15.2834s	
31994/33250 (epoch 48.111), train_loss = 0.72309147, grad/param norm = 1.7740e-01, time/batch = 15.8813s	
31995/33250 (epoch 48.113), train_loss = 0.68827743, grad/param norm = 1.7751e-01, time/batch = 14.9022s	
31996/33250 (epoch 48.114), train_loss = 0.63602366, grad/param norm = 1.7837e-01, time/batch = 14.2940s	
31997/33250 (epoch 48.116), train_loss = 0.66945028, grad/param norm = 1.9811e-01, time/batch = 14.2146s	
31998/33250 (epoch 48.117), train_loss = 0.64329068, grad/param norm = 1.8622e-01, time/batch = 14.1482s	
31999/33250 (epoch 48.119), train_loss = 0.68687404, grad/param norm = 2.2011e-01, time/batch = 14.8610s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch48.12_1.7557.t7	
32000/33250 (epoch 48.120), train_loss = 0.61484025, grad/param norm = 1.7411e-01, time/batch = 14.3070s	
32001/33250 (epoch 48.122), train_loss = 1.29041075, grad/param norm = 2.8486e-01, time/batch = 15.2061s	
32002/33250 (epoch 48.123), train_loss = 0.73040044, grad/param norm = 2.4163e-01, time/batch = 14.6355s	
32003/33250 (epoch 48.125), train_loss = 0.59371421, grad/param norm = 1.9808e-01, time/batch = 15.1995s	
32004/33250 (epoch 48.126), train_loss = 0.69663171, grad/param norm = 1.9692e-01, time/batch = 15.3735s	
32005/33250 (epoch 48.128), train_loss = 0.67311549, grad/param norm = 1.5997e-01, time/batch = 15.0585s	
32006/33250 (epoch 48.129), train_loss = 0.71058224, grad/param norm = 1.7869e-01, time/batch = 16.7126s	
32007/33250 (epoch 48.131), train_loss = 0.70174623, grad/param norm = 1.8049e-01, time/batch = 15.4570s	
32008/33250 (epoch 48.132), train_loss = 0.68667673, grad/param norm = 1.7451e-01, time/batch = 15.1438s	
32009/33250 (epoch 48.134), train_loss = 0.65147121, grad/param norm = 2.0670e-01, time/batch = 14.6225s	
32010/33250 (epoch 48.135), train_loss = 0.73536095, grad/param norm = 1.5763e-01, time/batch = 14.7833s	
32011/33250 (epoch 48.137), train_loss = 0.65724268, grad/param norm = 2.2955e-01, time/batch = 14.7845s	
32012/33250 (epoch 48.138), train_loss = 0.65050879, grad/param norm = 1.6244e-01, time/batch = 14.7112s	
32013/33250 (epoch 48.140), train_loss = 0.56785232, grad/param norm = 1.6991e-01, time/batch = 15.0479s	
32014/33250 (epoch 48.141), train_loss = 0.79971232, grad/param norm = 3.4615e-01, time/batch = 14.6267s	
32015/33250 (epoch 48.143), train_loss = 0.61642919, grad/param norm = 2.1835e-01, time/batch = 15.4381s	
32016/33250 (epoch 48.144), train_loss = 0.69239632, grad/param norm = 1.7992e-01, time/batch = 15.2855s	
32017/33250 (epoch 48.146), train_loss = 0.68470433, grad/param norm = 1.8173e-01, time/batch = 16.8004s	
32018/33250 (epoch 48.147), train_loss = 0.69765558, grad/param norm = 1.9244e-01, time/batch = 16.8861s	
32019/33250 (epoch 48.149), train_loss = 0.67820577, grad/param norm = 1.7900e-01, time/batch = 14.9444s	
32020/33250 (epoch 48.150), train_loss = 0.66106513, grad/param norm = 2.0830e-01, time/batch = 15.5477s	
32021/33250 (epoch 48.152), train_loss = 0.60020853, grad/param norm = 1.8281e-01, time/batch = 14.5540s	
32022/33250 (epoch 48.153), train_loss = 0.85169944, grad/param norm = 1.9240e-01, time/batch = 15.1292s	
32023/33250 (epoch 48.155), train_loss = 0.68583116, grad/param norm = 1.9527e-01, time/batch = 14.5864s	
32024/33250 (epoch 48.156), train_loss = 0.90544957, grad/param norm = 1.9328e-01, time/batch = 16.1244s	
32025/33250 (epoch 48.158), train_loss = 0.85294315, grad/param norm = 2.2287e-01, time/batch = 14.8660s	
32026/33250 (epoch 48.159), train_loss = 0.70295360, grad/param norm = 2.3030e-01, time/batch = 15.0603s	
32027/33250 (epoch 48.161), train_loss = 0.72181317, grad/param norm = 1.9528e-01, time/batch = 15.7179s	
32028/33250 (epoch 48.162), train_loss = 0.63547276, grad/param norm = 1.6992e-01, time/batch = 15.6072s	
32029/33250 (epoch 48.164), train_loss = 0.72274268, grad/param norm = 2.4509e-01, time/batch = 14.7200s	
32030/33250 (epoch 48.165), train_loss = 0.80657517, grad/param norm = 2.3071e-01, time/batch = 15.4018s	
32031/33250 (epoch 48.167), train_loss = 0.84339200, grad/param norm = 2.0972e-01, time/batch = 14.3698s	
32032/33250 (epoch 48.168), train_loss = 0.64680814, grad/param norm = 1.5331e-01, time/batch = 14.5208s	
32033/33250 (epoch 48.170), train_loss = 0.72458123, grad/param norm = 2.2743e-01, time/batch = 14.3870s	
32034/33250 (epoch 48.171), train_loss = 0.73856699, grad/param norm = 2.0276e-01, time/batch = 14.1402s	
32035/33250 (epoch 48.173), train_loss = 0.73949395, grad/param norm = 1.9341e-01, time/batch = 14.5480s	
32036/33250 (epoch 48.174), train_loss = 0.76182228, grad/param norm = 1.8813e-01, time/batch = 14.5342s	
32037/33250 (epoch 48.176), train_loss = 0.67096059, grad/param norm = 2.2809e-01, time/batch = 14.7819s	
32038/33250 (epoch 48.177), train_loss = 0.65701351, grad/param norm = 1.7227e-01, time/batch = 16.7129s	
32039/33250 (epoch 48.179), train_loss = 0.65686510, grad/param norm = 1.7404e-01, time/batch = 28.3516s	
32040/33250 (epoch 48.180), train_loss = 0.59314350, grad/param norm = 1.7806e-01, time/batch = 15.2958s	
32041/33250 (epoch 48.182), train_loss = 0.65305606, grad/param norm = 2.3096e-01, time/batch = 14.3866s	
32042/33250 (epoch 48.183), train_loss = 0.79504614, grad/param norm = 1.7521e-01, time/batch = 14.5322s	
32043/33250 (epoch 48.185), train_loss = 0.73478748, grad/param norm = 2.5252e-01, time/batch = 14.6795s	
32044/33250 (epoch 48.186), train_loss = 0.72917704, grad/param norm = 2.0588e-01, time/batch = 14.4765s	
32045/33250 (epoch 48.188), train_loss = 0.78480621, grad/param norm = 2.2319e-01, time/batch = 14.9715s	
32046/33250 (epoch 48.189), train_loss = 0.58350577, grad/param norm = 2.1513e-01, time/batch = 14.7660s	
32047/33250 (epoch 48.191), train_loss = 0.66894615, grad/param norm = 1.8305e-01, time/batch = 14.5240s	
32048/33250 (epoch 48.192), train_loss = 0.67076573, grad/param norm = 1.7266e-01, time/batch = 14.7058s	
32049/33250 (epoch 48.194), train_loss = 0.70403484, grad/param norm = 2.3293e-01, time/batch = 15.9829s	
32050/33250 (epoch 48.195), train_loss = 0.83969739, grad/param norm = 1.8442e-01, time/batch = 15.3652s	
32051/33250 (epoch 48.197), train_loss = 0.67579300, grad/param norm = 1.8564e-01, time/batch = 18.3727s	
32052/33250 (epoch 48.198), train_loss = 0.84469841, grad/param norm = 2.2380e-01, time/batch = 15.2871s	
32053/33250 (epoch 48.200), train_loss = 0.72073694, grad/param norm = 1.9509e-01, time/batch = 14.5522s	
32054/33250 (epoch 48.202), train_loss = 0.69845273, grad/param norm = 1.7354e-01, time/batch = 14.4517s	
32055/33250 (epoch 48.203), train_loss = 0.65108123, grad/param norm = 1.8597e-01, time/batch = 15.2158s	
32056/33250 (epoch 48.205), train_loss = 0.73197119, grad/param norm = 1.6727e-01, time/batch = 14.5472s	
32057/33250 (epoch 48.206), train_loss = 0.77930044, grad/param norm = 1.9632e-01, time/batch = 14.6247s	
32058/33250 (epoch 48.208), train_loss = 0.81509671, grad/param norm = 2.4275e-01, time/batch = 14.9327s	
32059/33250 (epoch 48.209), train_loss = 0.68158940, grad/param norm = 1.7007e-01, time/batch = 15.1244s	
32060/33250 (epoch 48.211), train_loss = 0.74782447, grad/param norm = 1.8379e-01, time/batch = 15.9522s	
32061/33250 (epoch 48.212), train_loss = 0.82354369, grad/param norm = 1.9280e-01, time/batch = 15.9608s	
32062/33250 (epoch 48.214), train_loss = 0.74291718, grad/param norm = 1.5760e-01, time/batch = 16.7082s	
32063/33250 (epoch 48.215), train_loss = 0.73583891, grad/param norm = 1.9722e-01, time/batch = 15.3051s	
32064/33250 (epoch 48.217), train_loss = 0.78693475, grad/param norm = 2.1021e-01, time/batch = 14.8335s	
32065/33250 (epoch 48.218), train_loss = 0.75427689, grad/param norm = 1.8569e-01, time/batch = 14.6203s	
32066/33250 (epoch 48.220), train_loss = 0.70482920, grad/param norm = 1.5665e-01, time/batch = 14.6243s	
32067/33250 (epoch 48.221), train_loss = 0.84771047, grad/param norm = 2.4894e-01, time/batch = 14.6228s	
32068/33250 (epoch 48.223), train_loss = 0.72410172, grad/param norm = 1.6729e-01, time/batch = 14.7594s	
32069/33250 (epoch 48.224), train_loss = 0.74813235, grad/param norm = 1.8406e-01, time/batch = 14.6129s	
32070/33250 (epoch 48.226), train_loss = 0.85168177, grad/param norm = 2.0011e-01, time/batch = 14.3840s	
32071/33250 (epoch 48.227), train_loss = 0.75041840, grad/param norm = 1.8614e-01, time/batch = 15.6346s	
32072/33250 (epoch 48.229), train_loss = 0.75529608, grad/param norm = 1.8141e-01, time/batch = 15.5402s	
32073/33250 (epoch 48.230), train_loss = 0.74604670, grad/param norm = 2.0916e-01, time/batch = 14.7226s	
32074/33250 (epoch 48.232), train_loss = 0.69764449, grad/param norm = 2.1899e-01, time/batch = 16.6393s	
32075/33250 (epoch 48.233), train_loss = 0.66944274, grad/param norm = 1.8552e-01, time/batch = 15.1203s	
32076/33250 (epoch 48.235), train_loss = 0.82896902, grad/param norm = 1.8004e-01, time/batch = 15.0544s	
32077/33250 (epoch 48.236), train_loss = 0.66542854, grad/param norm = 2.0520e-01, time/batch = 15.6188s	
32078/33250 (epoch 48.238), train_loss = 0.82901135, grad/param norm = 2.2881e-01, time/batch = 14.3055s	
32079/33250 (epoch 48.239), train_loss = 0.84875428, grad/param norm = 3.0915e-01, time/batch = 14.3893s	
32080/33250 (epoch 48.241), train_loss = 0.81256650, grad/param norm = 2.2686e-01, time/batch = 14.4569s	
32081/33250 (epoch 48.242), train_loss = 0.81734696, grad/param norm = 2.5530e-01, time/batch = 14.5241s	
32082/33250 (epoch 48.244), train_loss = 0.77868013, grad/param norm = 2.6485e-01, time/batch = 14.9767s	
32083/33250 (epoch 48.245), train_loss = 0.77464310, grad/param norm = 2.1199e-01, time/batch = 17.2820s	
32084/33250 (epoch 48.247), train_loss = 0.74162790, grad/param norm = 2.0515e-01, time/batch = 16.8051s	
32085/33250 (epoch 48.248), train_loss = 0.86631969, grad/param norm = 2.4682e-01, time/batch = 14.8157s	
32086/33250 (epoch 48.250), train_loss = 0.85161858, grad/param norm = 1.7747e-01, time/batch = 14.3779s	
32087/33250 (epoch 48.251), train_loss = 0.72837719, grad/param norm = 1.9177e-01, time/batch = 15.1714s	
32088/33250 (epoch 48.253), train_loss = 0.73480294, grad/param norm = 1.7786e-01, time/batch = 14.3735s	
32089/33250 (epoch 48.254), train_loss = 0.69173253, grad/param norm = 1.9028e-01, time/batch = 14.8507s	
32090/33250 (epoch 48.256), train_loss = 0.74494838, grad/param norm = 1.9041e-01, time/batch = 14.9565s	
32091/33250 (epoch 48.257), train_loss = 0.89171218, grad/param norm = 2.1154e-01, time/batch = 15.0486s	
32092/33250 (epoch 48.259), train_loss = 0.75373498, grad/param norm = 2.2175e-01, time/batch = 14.6040s	
32093/33250 (epoch 48.260), train_loss = 0.59840639, grad/param norm = 1.6823e-01, time/batch = 14.7290s	
32094/33250 (epoch 48.262), train_loss = 0.73744273, grad/param norm = 1.9025e-01, time/batch = 15.4694s	
32095/33250 (epoch 48.263), train_loss = 0.59880991, grad/param norm = 2.0183e-01, time/batch = 16.0603s	
32096/33250 (epoch 48.265), train_loss = 0.76087783, grad/param norm = 2.0242e-01, time/batch = 17.3847s	
32097/33250 (epoch 48.266), train_loss = 0.75362394, grad/param norm = 1.8690e-01, time/batch = 14.6207s	
32098/33250 (epoch 48.268), train_loss = 0.64439951, grad/param norm = 1.8118e-01, time/batch = 14.4580s	
32099/33250 (epoch 48.269), train_loss = 0.58711049, grad/param norm = 1.7654e-01, time/batch = 14.8591s	
32100/33250 (epoch 48.271), train_loss = 0.79080495, grad/param norm = 1.7661e-01, time/batch = 14.2954s	
32101/33250 (epoch 48.272), train_loss = 0.67893301, grad/param norm = 1.4326e-01, time/batch = 15.0260s	
32102/33250 (epoch 48.274), train_loss = 0.54064727, grad/param norm = 1.5890e-01, time/batch = 16.3652s	
32103/33250 (epoch 48.275), train_loss = 0.68932152, grad/param norm = 1.5092e-01, time/batch = 14.2119s	
32104/33250 (epoch 48.277), train_loss = 0.62264229, grad/param norm = 1.9295e-01, time/batch = 14.1400s	
32105/33250 (epoch 48.278), train_loss = 0.68694972, grad/param norm = 1.7050e-01, time/batch = 16.5503s	
32106/33250 (epoch 48.280), train_loss = 0.63999399, grad/param norm = 1.7631e-01, time/batch = 14.2368s	
32107/33250 (epoch 48.281), train_loss = 0.74497483, grad/param norm = 2.0028e-01, time/batch = 15.0492s	
32108/33250 (epoch 48.283), train_loss = 0.75735758, grad/param norm = 2.9940e-01, time/batch = 14.4583s	
32109/33250 (epoch 48.284), train_loss = 0.62837230, grad/param norm = 2.0405e-01, time/batch = 14.7019s	
32110/33250 (epoch 48.286), train_loss = 0.76456376, grad/param norm = 1.9912e-01, time/batch = 15.3839s	
32111/33250 (epoch 48.287), train_loss = 0.61226532, grad/param norm = 1.5867e-01, time/batch = 14.8058s	
32112/33250 (epoch 48.289), train_loss = 0.58003369, grad/param norm = 2.0434e-01, time/batch = 14.5514s	
32113/33250 (epoch 48.290), train_loss = 0.72684937, grad/param norm = 1.8695e-01, time/batch = 14.6887s	
32114/33250 (epoch 48.292), train_loss = 0.75866918, grad/param norm = 2.5161e-01, time/batch = 15.0129s	
32115/33250 (epoch 48.293), train_loss = 0.83178713, grad/param norm = 1.9375e-01, time/batch = 15.2025s	
32116/33250 (epoch 48.295), train_loss = 0.82901635, grad/param norm = 2.0344e-01, time/batch = 14.4842s	
32117/33250 (epoch 48.296), train_loss = 0.76688177, grad/param norm = 2.0696e-01, time/batch = 14.8663s	
32118/33250 (epoch 48.298), train_loss = 0.58536489, grad/param norm = 1.5191e-01, time/batch = 17.0540s	
32119/33250 (epoch 48.299), train_loss = 0.57271352, grad/param norm = 1.7130e-01, time/batch = 16.2273s	
32120/33250 (epoch 48.301), train_loss = 0.77350992, grad/param norm = 1.7784e-01, time/batch = 15.5557s	
32121/33250 (epoch 48.302), train_loss = 0.78794727, grad/param norm = 1.9828e-01, time/batch = 14.6998s	
32122/33250 (epoch 48.304), train_loss = 0.71294608, grad/param norm = 2.3839e-01, time/batch = 14.3126s	
32123/33250 (epoch 48.305), train_loss = 0.66279570, grad/param norm = 1.7072e-01, time/batch = 14.6376s	
32124/33250 (epoch 48.307), train_loss = 0.80560472, grad/param norm = 1.9335e-01, time/batch = 14.6166s	
32125/33250 (epoch 48.308), train_loss = 0.81324681, grad/param norm = 2.0982e-01, time/batch = 14.7001s	
32126/33250 (epoch 48.310), train_loss = 0.68586444, grad/param norm = 2.1655e-01, time/batch = 14.3890s	
32127/33250 (epoch 48.311), train_loss = 0.85251127, grad/param norm = 2.0605e-01, time/batch = 14.7140s	
32128/33250 (epoch 48.313), train_loss = 0.59755736, grad/param norm = 1.9873e-01, time/batch = 14.9461s	
32129/33250 (epoch 48.314), train_loss = 0.81303741, grad/param norm = 1.9175e-01, time/batch = 15.0281s	
32130/33250 (epoch 48.316), train_loss = 0.87870937, grad/param norm = 2.0427e-01, time/batch = 15.7233s	
32131/33250 (epoch 48.317), train_loss = 0.64458754, grad/param norm = 1.7708e-01, time/batch = 14.3008s	
32132/33250 (epoch 48.319), train_loss = 0.78748023, grad/param norm = 3.1075e-01, time/batch = 14.5590s	
32133/33250 (epoch 48.320), train_loss = 0.80329198, grad/param norm = 2.3299e-01, time/batch = 14.6972s	
32134/33250 (epoch 48.322), train_loss = 0.89344893, grad/param norm = 2.5406e-01, time/batch = 14.4079s	
32135/33250 (epoch 48.323), train_loss = 0.88972565, grad/param norm = 2.9741e-01, time/batch = 14.4716s	
32136/33250 (epoch 48.325), train_loss = 0.70992716, grad/param norm = 2.3403e-01, time/batch = 14.7807s	
32137/33250 (epoch 48.326), train_loss = 0.95612236, grad/param norm = 2.2824e-01, time/batch = 14.8496s	
32138/33250 (epoch 48.328), train_loss = 0.72239845, grad/param norm = 2.1037e-01, time/batch = 14.4622s	
32139/33250 (epoch 48.329), train_loss = 0.79093555, grad/param norm = 2.9713e-01, time/batch = 15.4827s	
32140/33250 (epoch 48.331), train_loss = 0.75911954, grad/param norm = 2.2658e-01, time/batch = 15.1512s	
32141/33250 (epoch 48.332), train_loss = 0.77009667, grad/param norm = 1.9041e-01, time/batch = 14.9814s	
32142/33250 (epoch 48.334), train_loss = 0.86462891, grad/param norm = 1.7277e-01, time/batch = 16.3974s	
32143/33250 (epoch 48.335), train_loss = 0.57310137, grad/param norm = 1.9845e-01, time/batch = 14.2276s	
32144/33250 (epoch 48.337), train_loss = 0.78784811, grad/param norm = 1.6319e-01, time/batch = 14.7952s	
32145/33250 (epoch 48.338), train_loss = 0.90653838, grad/param norm = 2.0530e-01, time/batch = 14.7703s	
32146/33250 (epoch 48.340), train_loss = 0.71789609, grad/param norm = 1.8275e-01, time/batch = 14.9692s	
32147/33250 (epoch 48.341), train_loss = 0.67443458, grad/param norm = 2.1752e-01, time/batch = 14.7027s	
32148/33250 (epoch 48.343), train_loss = 0.73342893, grad/param norm = 2.3721e-01, time/batch = 14.5665s	
32149/33250 (epoch 48.344), train_loss = 0.72024271, grad/param norm = 1.7655e-01, time/batch = 15.0779s	
32150/33250 (epoch 48.346), train_loss = 0.64016303, grad/param norm = 1.6704e-01, time/batch = 15.0353s	
32151/33250 (epoch 48.347), train_loss = 0.90855248, grad/param norm = 2.3856e-01, time/batch = 14.7427s	
32152/33250 (epoch 48.349), train_loss = 0.75073495, grad/param norm = 2.1899e-01, time/batch = 16.1469s	
32153/33250 (epoch 48.350), train_loss = 0.74530743, grad/param norm = 2.2383e-01, time/batch = 14.9059s	
32154/33250 (epoch 48.352), train_loss = 0.67777076, grad/param norm = 1.8954e-01, time/batch = 16.3862s	
32155/33250 (epoch 48.353), train_loss = 0.71115914, grad/param norm = 1.5935e-01, time/batch = 14.6266s	
32156/33250 (epoch 48.355), train_loss = 0.71349594, grad/param norm = 1.8873e-01, time/batch = 14.8654s	
32157/33250 (epoch 48.356), train_loss = 0.67247053, grad/param norm = 1.8065e-01, time/batch = 14.9346s	
32158/33250 (epoch 48.358), train_loss = 0.71559738, grad/param norm = 1.5499e-01, time/batch = 14.3931s	
32159/33250 (epoch 48.359), train_loss = 0.69025170, grad/param norm = 1.9711e-01, time/batch = 14.4660s	
32160/33250 (epoch 48.361), train_loss = 0.80174378, grad/param norm = 2.0034e-01, time/batch = 14.0662s	
32161/33250 (epoch 48.362), train_loss = 0.75625343, grad/param norm = 1.9143e-01, time/batch = 14.8772s	
32162/33250 (epoch 48.364), train_loss = 0.77850880, grad/param norm = 1.9146e-01, time/batch = 16.2860s	
32163/33250 (epoch 48.365), train_loss = 0.71717981, grad/param norm = 1.6874e-01, time/batch = 14.5243s	
32164/33250 (epoch 48.367), train_loss = 0.77195361, grad/param norm = 1.7737e-01, time/batch = 15.1552s	
32165/33250 (epoch 48.368), train_loss = 0.73591347, grad/param norm = 2.4797e-01, time/batch = 14.8848s	
32166/33250 (epoch 48.370), train_loss = 0.64687477, grad/param norm = 1.5908e-01, time/batch = 15.1921s	
32167/33250 (epoch 48.371), train_loss = 0.81128111, grad/param norm = 2.1141e-01, time/batch = 14.5425s	
32168/33250 (epoch 48.373), train_loss = 0.72889375, grad/param norm = 1.8215e-01, time/batch = 15.2245s	
32169/33250 (epoch 48.374), train_loss = 0.72041092, grad/param norm = 2.6995e-01, time/batch = 15.3380s	
32170/33250 (epoch 48.376), train_loss = 0.75799783, grad/param norm = 1.9360e-01, time/batch = 15.4403s	
32171/33250 (epoch 48.377), train_loss = 0.64514822, grad/param norm = 2.1281e-01, time/batch = 14.7860s	
32172/33250 (epoch 48.379), train_loss = 0.75591237, grad/param norm = 2.3372e-01, time/batch = 14.3032s	
32173/33250 (epoch 48.380), train_loss = 0.73696493, grad/param norm = 2.8397e-01, time/batch = 15.2734s	
32174/33250 (epoch 48.382), train_loss = 0.76796775, grad/param norm = 2.5309e-01, time/batch = 15.5368s	
32175/33250 (epoch 48.383), train_loss = 0.64608501, grad/param norm = 2.0890e-01, time/batch = 15.8152s	
32176/33250 (epoch 48.385), train_loss = 0.64231135, grad/param norm = 2.3843e-01, time/batch = 16.1343s	
32177/33250 (epoch 48.386), train_loss = 0.65673500, grad/param norm = 2.4421e-01, time/batch = 15.0145s	
32178/33250 (epoch 48.388), train_loss = 0.68581066, grad/param norm = 1.9197e-01, time/batch = 15.0091s	
32179/33250 (epoch 48.389), train_loss = 0.66267522, grad/param norm = 1.9314e-01, time/batch = 14.2838s	
32180/33250 (epoch 48.391), train_loss = 0.77778568, grad/param norm = 2.0226e-01, time/batch = 14.7060s	
32181/33250 (epoch 48.392), train_loss = 0.85747949, grad/param norm = 2.8244e-01, time/batch = 14.4664s	
32182/33250 (epoch 48.394), train_loss = 0.80182857, grad/param norm = 1.8547e-01, time/batch = 15.0396s	
32183/33250 (epoch 48.395), train_loss = 0.83495814, grad/param norm = 1.7808e-01, time/batch = 14.4421s	
32184/33250 (epoch 48.397), train_loss = 0.85836163, grad/param norm = 1.9329e-01, time/batch = 15.1347s	
32185/33250 (epoch 48.398), train_loss = 0.65384601, grad/param norm = 1.6785e-01, time/batch = 15.4855s	
32186/33250 (epoch 48.400), train_loss = 0.66527263, grad/param norm = 1.6777e-01, time/batch = 17.1164s	
32187/33250 (epoch 48.402), train_loss = 0.60887834, grad/param norm = 1.6582e-01, time/batch = 16.2145s	
32188/33250 (epoch 48.403), train_loss = 0.72433596, grad/param norm = 2.2932e-01, time/batch = 16.0285s	
32189/33250 (epoch 48.405), train_loss = 0.68145082, grad/param norm = 1.6301e-01, time/batch = 14.9294s	
32190/33250 (epoch 48.406), train_loss = 0.73843632, grad/param norm = 2.5203e-01, time/batch = 14.5627s	
32191/33250 (epoch 48.408), train_loss = 0.85660291, grad/param norm = 2.1058e-01, time/batch = 14.5619s	
32192/33250 (epoch 48.409), train_loss = 0.75651063, grad/param norm = 2.2143e-01, time/batch = 14.7026s	
32193/33250 (epoch 48.411), train_loss = 0.55726306, grad/param norm = 1.6633e-01, time/batch = 14.3118s	
32194/33250 (epoch 48.412), train_loss = 0.61992055, grad/param norm = 1.7049e-01, time/batch = 14.5618s	
32195/33250 (epoch 48.414), train_loss = 0.72400962, grad/param norm = 1.8585e-01, time/batch = 15.0606s	
32196/33250 (epoch 48.415), train_loss = 0.79515654, grad/param norm = 2.2035e-01, time/batch = 16.0122s	
32197/33250 (epoch 48.417), train_loss = 0.82393463, grad/param norm = 1.9321e-01, time/batch = 15.8803s	
32198/33250 (epoch 48.418), train_loss = 0.96464297, grad/param norm = 2.1088e-01, time/batch = 16.4753s	
32199/33250 (epoch 48.420), train_loss = 0.81231260, grad/param norm = 1.9615e-01, time/batch = 14.7401s	
32200/33250 (epoch 48.421), train_loss = 0.69932103, grad/param norm = 1.8393e-01, time/batch = 14.8651s	
32201/33250 (epoch 48.423), train_loss = 0.78744922, grad/param norm = 2.1888e-01, time/batch = 14.6465s	
32202/33250 (epoch 48.424), train_loss = 0.83881441, grad/param norm = 2.4620e-01, time/batch = 14.8828s	
32203/33250 (epoch 48.426), train_loss = 0.73520190, grad/param norm = 1.6331e-01, time/batch = 14.7245s	
32204/33250 (epoch 48.427), train_loss = 0.69139943, grad/param norm = 2.1591e-01, time/batch = 14.7790s	
32205/33250 (epoch 48.429), train_loss = 0.70038977, grad/param norm = 1.9720e-01, time/batch = 14.9539s	
32206/33250 (epoch 48.430), train_loss = 0.68665607, grad/param norm = 2.0096e-01, time/batch = 14.6791s	
32207/33250 (epoch 48.432), train_loss = 0.79412161, grad/param norm = 1.6983e-01, time/batch = 14.3181s	
32208/33250 (epoch 48.433), train_loss = 0.70736021, grad/param norm = 2.2330e-01, time/batch = 14.4851s	
32209/33250 (epoch 48.435), train_loss = 0.77823589, grad/param norm = 1.8594e-01, time/batch = 16.0632s	
32210/33250 (epoch 48.436), train_loss = 0.70998089, grad/param norm = 2.0378e-01, time/batch = 17.2297s	
32211/33250 (epoch 48.438), train_loss = 0.83611796, grad/param norm = 2.0691e-01, time/batch = 14.5634s	
32212/33250 (epoch 48.439), train_loss = 0.74523853, grad/param norm = 1.6963e-01, time/batch = 15.0150s	
32213/33250 (epoch 48.441), train_loss = 0.73683048, grad/param norm = 1.9920e-01, time/batch = 15.0413s	
32214/33250 (epoch 48.442), train_loss = 0.64928126, grad/param norm = 1.6679e-01, time/batch = 15.5107s	
32215/33250 (epoch 48.444), train_loss = 0.69820755, grad/param norm = 1.5420e-01, time/batch = 15.1369s	
32216/33250 (epoch 48.445), train_loss = 0.74912319, grad/param norm = 1.5779e-01, time/batch = 15.1784s	
32217/33250 (epoch 48.447), train_loss = 0.66460002, grad/param norm = 2.1840e-01, time/batch = 15.1146s	
32218/33250 (epoch 48.448), train_loss = 0.75290249, grad/param norm = 1.6540e-01, time/batch = 15.1920s	
32219/33250 (epoch 48.450), train_loss = 0.81070267, grad/param norm = 1.8973e-01, time/batch = 15.7685s	
32220/33250 (epoch 48.451), train_loss = 0.77408979, grad/param norm = 1.9590e-01, time/batch = 15.4334s	
32221/33250 (epoch 48.453), train_loss = 0.63596125, grad/param norm = 1.4166e-01, time/batch = 19.1115s	
32222/33250 (epoch 48.454), train_loss = 0.83443630, grad/param norm = 2.0322e-01, time/batch = 14.8145s	
32223/33250 (epoch 48.456), train_loss = 0.85562806, grad/param norm = 1.6323e-01, time/batch = 15.1105s	
32224/33250 (epoch 48.457), train_loss = 0.67669329, grad/param norm = 1.6517e-01, time/batch = 14.8737s	
32225/33250 (epoch 48.459), train_loss = 0.81704150, grad/param norm = 1.7980e-01, time/batch = 14.6437s	
32226/33250 (epoch 48.460), train_loss = 0.79502276, grad/param norm = 2.2140e-01, time/batch = 14.9405s	
32227/33250 (epoch 48.462), train_loss = 0.74713271, grad/param norm = 1.7604e-01, time/batch = 14.4708s	
32228/33250 (epoch 48.463), train_loss = 0.64750022, grad/param norm = 1.4048e-01, time/batch = 14.9562s	
32229/33250 (epoch 48.465), train_loss = 0.62493832, grad/param norm = 1.5220e-01, time/batch = 17.3691s	
32230/33250 (epoch 48.466), train_loss = 0.61511138, grad/param norm = 1.4509e-01, time/batch = 15.8579s	
32231/33250 (epoch 48.468), train_loss = 0.63128939, grad/param norm = 1.6127e-01, time/batch = 16.5068s	
32232/33250 (epoch 48.469), train_loss = 0.72323805, grad/param norm = 1.8482e-01, time/batch = 17.1992s	
32233/33250 (epoch 48.471), train_loss = 0.80298305, grad/param norm = 1.5527e-01, time/batch = 15.2932s	
32234/33250 (epoch 48.472), train_loss = 0.70937875, grad/param norm = 2.5698e-01, time/batch = 15.1331s	
32235/33250 (epoch 48.474), train_loss = 0.80093691, grad/param norm = 1.8135e-01, time/batch = 15.1048s	
32236/33250 (epoch 48.475), train_loss = 0.77358409, grad/param norm = 1.6991e-01, time/batch = 14.7736s	
32237/33250 (epoch 48.477), train_loss = 0.75598374, grad/param norm = 1.6632e-01, time/batch = 14.9503s	
32238/33250 (epoch 48.478), train_loss = 0.62430411, grad/param norm = 1.7581e-01, time/batch = 14.7187s	
32239/33250 (epoch 48.480), train_loss = 0.82264645, grad/param norm = 1.8891e-01, time/batch = 14.8693s	
32240/33250 (epoch 48.481), train_loss = 0.72099012, grad/param norm = 1.8412e-01, time/batch = 15.7728s	
32241/33250 (epoch 48.483), train_loss = 0.71078092, grad/param norm = 2.5716e-01, time/batch = 15.5463s	
32242/33250 (epoch 48.484), train_loss = 0.67363667, grad/param norm = 1.8267e-01, time/batch = 16.7314s	
32243/33250 (epoch 48.486), train_loss = 0.58955030, grad/param norm = 1.7770e-01, time/batch = 15.2978s	
32244/33250 (epoch 48.487), train_loss = 0.66274628, grad/param norm = 1.8471e-01, time/batch = 15.1300s	
32245/33250 (epoch 48.489), train_loss = 0.78629395, grad/param norm = 1.8181e-01, time/batch = 14.7729s	
32246/33250 (epoch 48.490), train_loss = 0.73299874, grad/param norm = 2.1698e-01, time/batch = 14.1503s	
32247/33250 (epoch 48.492), train_loss = 0.81710219, grad/param norm = 2.1965e-01, time/batch = 14.5362s	
32248/33250 (epoch 48.493), train_loss = 0.71558836, grad/param norm = 1.9029e-01, time/batch = 14.3052s	
32249/33250 (epoch 48.495), train_loss = 0.80310757, grad/param norm = 1.6196e-01, time/batch = 14.2219s	
32250/33250 (epoch 48.496), train_loss = 0.74202678, grad/param norm = 1.6360e-01, time/batch = 14.1331s	
32251/33250 (epoch 48.498), train_loss = 0.77478619, grad/param norm = 1.9642e-01, time/batch = 15.0319s	
32252/33250 (epoch 48.499), train_loss = 0.69188759, grad/param norm = 1.8609e-01, time/batch = 16.7967s	
32253/33250 (epoch 48.501), train_loss = 0.68492706, grad/param norm = 2.3037e-01, time/batch = 14.6486s	
32254/33250 (epoch 48.502), train_loss = 0.71262267, grad/param norm = 1.9143e-01, time/batch = 16.2214s	
32255/33250 (epoch 48.504), train_loss = 0.83959139, grad/param norm = 2.3926e-01, time/batch = 14.8696s	
32256/33250 (epoch 48.505), train_loss = 0.63263378, grad/param norm = 1.5261e-01, time/batch = 14.5481s	
32257/33250 (epoch 48.507), train_loss = 0.67083388, grad/param norm = 1.9062e-01, time/batch = 14.8491s	
32258/33250 (epoch 48.508), train_loss = 0.70648674, grad/param norm = 1.7266e-01, time/batch = 14.5378s	
32259/33250 (epoch 48.510), train_loss = 0.60308371, grad/param norm = 1.7290e-01, time/batch = 15.1662s	
32260/33250 (epoch 48.511), train_loss = 0.70956345, grad/param norm = 1.8814e-01, time/batch = 14.5505s	
32261/33250 (epoch 48.513), train_loss = 0.82680571, grad/param norm = 1.9283e-01, time/batch = 14.8859s	
32262/33250 (epoch 48.514), train_loss = 0.69139916, grad/param norm = 1.9099e-01, time/batch = 14.7215s	
32263/33250 (epoch 48.516), train_loss = 0.67641903, grad/param norm = 2.0273e-01, time/batch = 14.7974s	
32264/33250 (epoch 48.517), train_loss = 0.69143738, grad/param norm = 1.6497e-01, time/batch = 17.3035s	
32265/33250 (epoch 48.519), train_loss = 0.65626035, grad/param norm = 1.4317e-01, time/batch = 15.2164s	
32266/33250 (epoch 48.520), train_loss = 0.86811250, grad/param norm = 2.0768e-01, time/batch = 14.9711s	
32267/33250 (epoch 48.522), train_loss = 0.73119214, grad/param norm = 1.7655e-01, time/batch = 14.2028s	
32268/33250 (epoch 48.523), train_loss = 0.65241394, grad/param norm = 1.8254e-01, time/batch = 14.7205s	
32269/33250 (epoch 48.525), train_loss = 0.62289514, grad/param norm = 2.1767e-01, time/batch = 14.7060s	
32270/33250 (epoch 48.526), train_loss = 0.62935114, grad/param norm = 1.6319e-01, time/batch = 14.8775s	
32271/33250 (epoch 48.528), train_loss = 0.67734996, grad/param norm = 1.7474e-01, time/batch = 14.9375s	
32272/33250 (epoch 48.529), train_loss = 0.66040467, grad/param norm = 1.9691e-01, time/batch = 14.8742s	
32273/33250 (epoch 48.531), train_loss = 0.62958642, grad/param norm = 1.5938e-01, time/batch = 14.3901s	
32274/33250 (epoch 48.532), train_loss = 0.75016248, grad/param norm = 1.7471e-01, time/batch = 16.1198s	
32275/33250 (epoch 48.534), train_loss = 0.66218450, grad/param norm = 1.7745e-01, time/batch = 30.0231s	
32276/33250 (epoch 48.535), train_loss = 0.68927502, grad/param norm = 1.7358e-01, time/batch = 15.5370s	
32277/33250 (epoch 48.537), train_loss = 0.72790065, grad/param norm = 1.7766e-01, time/batch = 14.4695s	
32278/33250 (epoch 48.538), train_loss = 0.75653429, grad/param norm = 1.7112e-01, time/batch = 15.2532s	
32279/33250 (epoch 48.540), train_loss = 0.85543508, grad/param norm = 1.6912e-01, time/batch = 14.7066s	
32280/33250 (epoch 48.541), train_loss = 0.77928213, grad/param norm = 2.0041e-01, time/batch = 14.5353s	
32281/33250 (epoch 48.543), train_loss = 0.78577273, grad/param norm = 1.7040e-01, time/batch = 14.7842s	
32282/33250 (epoch 48.544), train_loss = 0.63504678, grad/param norm = 2.8316e-01, time/batch = 15.0175s	
32283/33250 (epoch 48.546), train_loss = 0.68555165, grad/param norm = 2.1645e-01, time/batch = 14.6857s	
32284/33250 (epoch 48.547), train_loss = 0.68891568, grad/param norm = 2.0682e-01, time/batch = 15.2559s	
32285/33250 (epoch 48.549), train_loss = 0.74959972, grad/param norm = 1.9508e-01, time/batch = 14.4718s	
32286/33250 (epoch 48.550), train_loss = 0.70835177, grad/param norm = 2.1299e-01, time/batch = 14.6420s	
32287/33250 (epoch 48.552), train_loss = 0.76938788, grad/param norm = 1.8289e-01, time/batch = 15.8910s	
32288/33250 (epoch 48.553), train_loss = 0.73262187, grad/param norm = 1.6766e-01, time/batch = 14.7687s	
32289/33250 (epoch 48.555), train_loss = 0.72646150, grad/param norm = 1.9129e-01, time/batch = 14.6306s	
32290/33250 (epoch 48.556), train_loss = 0.74471446, grad/param norm = 1.9583e-01, time/batch = 14.7007s	
32291/33250 (epoch 48.558), train_loss = 0.76496487, grad/param norm = 2.0351e-01, time/batch = 15.1387s	
32292/33250 (epoch 48.559), train_loss = 0.67107654, grad/param norm = 1.5265e-01, time/batch = 15.0966s	
32293/33250 (epoch 48.561), train_loss = 0.61956583, grad/param norm = 1.7464e-01, time/batch = 14.4711s	
32294/33250 (epoch 48.562), train_loss = 0.72960900, grad/param norm = 1.9340e-01, time/batch = 15.1112s	
32295/33250 (epoch 48.564), train_loss = 0.86620493, grad/param norm = 2.0611e-01, time/batch = 16.0428s	
32296/33250 (epoch 48.565), train_loss = 0.82298409, grad/param norm = 2.5477e-01, time/batch = 15.4890s	
32297/33250 (epoch 48.567), train_loss = 0.83586571, grad/param norm = 1.8776e-01, time/batch = 16.1304s	
32298/33250 (epoch 48.568), train_loss = 0.69450485, grad/param norm = 2.0909e-01, time/batch = 15.1459s	
32299/33250 (epoch 48.570), train_loss = 0.76985393, grad/param norm = 1.9348e-01, time/batch = 14.6470s	
32300/33250 (epoch 48.571), train_loss = 0.83630752, grad/param norm = 2.2238e-01, time/batch = 14.6285s	
32301/33250 (epoch 48.573), train_loss = 0.77302956, grad/param norm = 2.2650e-01, time/batch = 14.8521s	
32302/33250 (epoch 48.574), train_loss = 0.64852286, grad/param norm = 1.4782e-01, time/batch = 14.8685s	
32303/33250 (epoch 48.576), train_loss = 0.73565895, grad/param norm = 1.7927e-01, time/batch = 14.9841s	
32304/33250 (epoch 48.577), train_loss = 0.70641401, grad/param norm = 1.7375e-01, time/batch = 14.8458s	
32305/33250 (epoch 48.579), train_loss = 0.63588275, grad/param norm = 1.8567e-01, time/batch = 15.0427s	
32306/33250 (epoch 48.580), train_loss = 0.73357730, grad/param norm = 2.1647e-01, time/batch = 15.5423s	
32307/33250 (epoch 48.582), train_loss = 0.67063403, grad/param norm = 1.7951e-01, time/batch = 16.4727s	
32308/33250 (epoch 48.583), train_loss = 0.77236496, grad/param norm = 1.9347e-01, time/batch = 16.3077s	
32309/33250 (epoch 48.585), train_loss = 0.81278420, grad/param norm = 1.7086e-01, time/batch = 15.5261s	
32310/33250 (epoch 48.586), train_loss = 0.65716147, grad/param norm = 1.8216e-01, time/batch = 15.6115s	
32311/33250 (epoch 48.588), train_loss = 0.75858873, grad/param norm = 1.7191e-01, time/batch = 15.2909s	
32312/33250 (epoch 48.589), train_loss = 0.72342932, grad/param norm = 1.9993e-01, time/batch = 14.4476s	
32313/33250 (epoch 48.591), train_loss = 0.69911755, grad/param norm = 2.1112e-01, time/batch = 14.7733s	
32314/33250 (epoch 48.592), train_loss = 0.68522804, grad/param norm = 1.7891e-01, time/batch = 14.6256s	
32315/33250 (epoch 48.594), train_loss = 0.82315761, grad/param norm = 1.9474e-01, time/batch = 14.7211s	
32316/33250 (epoch 48.595), train_loss = 0.72503288, grad/param norm = 1.9082e-01, time/batch = 14.6211s	
32317/33250 (epoch 48.597), train_loss = 0.61506178, grad/param norm = 1.4162e-01, time/batch = 16.7086s	
32318/33250 (epoch 48.598), train_loss = 0.69723505, grad/param norm = 2.6715e-01, time/batch = 17.2947s	
32319/33250 (epoch 48.600), train_loss = 0.69650128, grad/param norm = 2.1472e-01, time/batch = 15.9773s	
32320/33250 (epoch 48.602), train_loss = 0.72660075, grad/param norm = 2.2552e-01, time/batch = 15.4760s	
32321/33250 (epoch 48.603), train_loss = 0.77144226, grad/param norm = 2.1552e-01, time/batch = 15.3254s	
32322/33250 (epoch 48.605), train_loss = 0.72133876, grad/param norm = 1.7506e-01, time/batch = 14.7287s	
32323/33250 (epoch 48.606), train_loss = 0.76808073, grad/param norm = 2.0177e-01, time/batch = 15.2767s	
32324/33250 (epoch 48.608), train_loss = 0.72088572, grad/param norm = 1.6792e-01, time/batch = 14.4761s	
32325/33250 (epoch 48.609), train_loss = 0.63198597, grad/param norm = 1.7351e-01, time/batch = 14.7033s	
32326/33250 (epoch 48.611), train_loss = 0.69284691, grad/param norm = 2.1434e-01, time/batch = 14.6938s	
32327/33250 (epoch 48.612), train_loss = 0.72624011, grad/param norm = 1.9211e-01, time/batch = 15.2008s	
32328/33250 (epoch 48.614), train_loss = 0.93770148, grad/param norm = 2.5128e-01, time/batch = 15.4810s	
32329/33250 (epoch 48.615), train_loss = 0.82272827, grad/param norm = 1.8762e-01, time/batch = 15.1302s	
32330/33250 (epoch 48.617), train_loss = 0.91950791, grad/param norm = 2.4979e-01, time/batch = 17.0307s	
32331/33250 (epoch 48.618), train_loss = 0.91830577, grad/param norm = 2.7121e-01, time/batch = 14.9610s	
32332/33250 (epoch 48.620), train_loss = 0.79133355, grad/param norm = 2.0324e-01, time/batch = 14.3922s	
32333/33250 (epoch 48.621), train_loss = 0.79067128, grad/param norm = 2.1764e-01, time/batch = 14.9343s	
32334/33250 (epoch 48.623), train_loss = 0.70747942, grad/param norm = 1.9407e-01, time/batch = 14.8832s	
32335/33250 (epoch 48.624), train_loss = 0.70881905, grad/param norm = 2.2976e-01, time/batch = 14.6134s	
32336/33250 (epoch 48.626), train_loss = 0.73886968, grad/param norm = 2.1362e-01, time/batch = 14.7954s	
32337/33250 (epoch 48.627), train_loss = 0.69357634, grad/param norm = 1.8466e-01, time/batch = 15.4835s	
32338/33250 (epoch 48.629), train_loss = 0.78866442, grad/param norm = 2.2271e-01, time/batch = 15.5548s	
32339/33250 (epoch 48.630), train_loss = 0.69607818, grad/param norm = 2.3140e-01, time/batch = 15.3091s	
32340/33250 (epoch 48.632), train_loss = 0.66054134, grad/param norm = 1.8220e-01, time/batch = 14.9743s	
32341/33250 (epoch 48.633), train_loss = 0.74539147, grad/param norm = 1.9328e-01, time/batch = 15.7908s	
32342/33250 (epoch 48.635), train_loss = 0.65942976, grad/param norm = 2.0346e-01, time/batch = 15.3020s	
32343/33250 (epoch 48.636), train_loss = 0.68901702, grad/param norm = 1.6508e-01, time/batch = 14.6992s	
32344/33250 (epoch 48.638), train_loss = 0.65012121, grad/param norm = 1.9379e-01, time/batch = 14.7763s	
32345/33250 (epoch 48.639), train_loss = 0.61695482, grad/param norm = 1.8802e-01, time/batch = 15.6984s	
32346/33250 (epoch 48.641), train_loss = 0.69874895, grad/param norm = 1.7343e-01, time/batch = 15.5243s	
32347/33250 (epoch 48.642), train_loss = 0.55341868, grad/param norm = 1.8105e-01, time/batch = 14.4692s	
32348/33250 (epoch 48.644), train_loss = 0.51979544, grad/param norm = 1.6379e-01, time/batch = 14.7905s	
32349/33250 (epoch 48.645), train_loss = 0.73815080, grad/param norm = 2.5336e-01, time/batch = 15.7252s	
32350/33250 (epoch 48.647), train_loss = 0.59206399, grad/param norm = 2.1015e-01, time/batch = 15.0634s	
32351/33250 (epoch 48.648), train_loss = 0.58999579, grad/param norm = 1.7142e-01, time/batch = 18.1169s	
32352/33250 (epoch 48.650), train_loss = 0.80149929, grad/param norm = 2.0882e-01, time/batch = 16.0495s	
32353/33250 (epoch 48.651), train_loss = 0.77046298, grad/param norm = 3.2558e-01, time/batch = 14.6233s	
32354/33250 (epoch 48.653), train_loss = 0.69093629, grad/param norm = 1.6211e-01, time/batch = 14.8110s	
32355/33250 (epoch 48.654), train_loss = 0.72993632, grad/param norm = 2.2052e-01, time/batch = 14.1378s	
32356/33250 (epoch 48.656), train_loss = 0.77963584, grad/param norm = 1.5695e-01, time/batch = 14.2983s	
32357/33250 (epoch 48.657), train_loss = 0.57156528, grad/param norm = 2.3484e-01, time/batch = 14.8499s	
32358/33250 (epoch 48.659), train_loss = 0.69882244, grad/param norm = 1.8726e-01, time/batch = 14.5242s	
32359/33250 (epoch 48.660), train_loss = 0.74124074, grad/param norm = 1.9098e-01, time/batch = 14.1239s	
32360/33250 (epoch 48.662), train_loss = 0.72887355, grad/param norm = 1.9032e-01, time/batch = 14.1452s	
32361/33250 (epoch 48.663), train_loss = 0.63598680, grad/param norm = 1.7939e-01, time/batch = 17.0461s	
32362/33250 (epoch 48.665), train_loss = 0.74760722, grad/param norm = 1.8484e-01, time/batch = 17.2918s	
32363/33250 (epoch 48.666), train_loss = 0.69824539, grad/param norm = 1.6658e-01, time/batch = 15.2206s	
32364/33250 (epoch 48.668), train_loss = 0.80278845, grad/param norm = 1.7545e-01, time/batch = 14.7847s	
32365/33250 (epoch 48.669), train_loss = 0.73676026, grad/param norm = 1.8947e-01, time/batch = 14.3912s	
32366/33250 (epoch 48.671), train_loss = 0.63209741, grad/param norm = 3.0003e-01, time/batch = 14.4598s	
32367/33250 (epoch 48.672), train_loss = 0.78726394, grad/param norm = 2.0384e-01, time/batch = 14.3901s	
32368/33250 (epoch 48.674), train_loss = 0.69246799, grad/param norm = 1.9668e-01, time/batch = 14.6229s	
32369/33250 (epoch 48.675), train_loss = 0.74434815, grad/param norm = 1.5375e-01, time/batch = 14.6963s	
32370/33250 (epoch 48.677), train_loss = 0.77297428, grad/param norm = 2.1652e-01, time/batch = 14.8795s	
32371/33250 (epoch 48.678), train_loss = 0.67864290, grad/param norm = 2.2245e-01, time/batch = 14.7252s	
32372/33250 (epoch 48.680), train_loss = 0.82964836, grad/param norm = 1.9983e-01, time/batch = 16.5157s	
32373/33250 (epoch 48.681), train_loss = 0.65540882, grad/param norm = 1.6264e-01, time/batch = 15.5285s	
32374/33250 (epoch 48.683), train_loss = 0.66238779, grad/param norm = 1.7087e-01, time/batch = 16.1464s	
32375/33250 (epoch 48.684), train_loss = 0.61423855, grad/param norm = 2.0262e-01, time/batch = 14.4688s	
32376/33250 (epoch 48.686), train_loss = 0.62759932, grad/param norm = 1.6961e-01, time/batch = 14.6197s	
32377/33250 (epoch 48.687), train_loss = 0.73239235, grad/param norm = 1.7348e-01, time/batch = 14.5497s	
32378/33250 (epoch 48.689), train_loss = 0.63533337, grad/param norm = 2.0902e-01, time/batch = 14.5606s	
32379/33250 (epoch 48.690), train_loss = 0.75233529, grad/param norm = 2.3119e-01, time/batch = 14.3076s	
32380/33250 (epoch 48.692), train_loss = 0.71225315, grad/param norm = 1.9980e-01, time/batch = 14.6212s	
32381/33250 (epoch 48.693), train_loss = 0.75602541, grad/param norm = 1.7097e-01, time/batch = 14.8887s	
32382/33250 (epoch 48.695), train_loss = 0.72387308, grad/param norm = 1.9580e-01, time/batch = 15.0881s	
32383/33250 (epoch 48.696), train_loss = 0.77138263, grad/param norm = 2.0699e-01, time/batch = 15.9705s	
32384/33250 (epoch 48.698), train_loss = 0.69556463, grad/param norm = 2.0859e-01, time/batch = 15.5591s	
32385/33250 (epoch 48.699), train_loss = 0.90734930, grad/param norm = 2.3379e-01, time/batch = 15.8085s	
32386/33250 (epoch 48.701), train_loss = 0.73347304, grad/param norm = 1.7143e-01, time/batch = 17.3853s	
32387/33250 (epoch 48.702), train_loss = 0.70189001, grad/param norm = 2.0567e-01, time/batch = 14.4685s	
32388/33250 (epoch 48.704), train_loss = 0.89371546, grad/param norm = 3.1626e-01, time/batch = 14.5512s	
32389/33250 (epoch 48.705), train_loss = 0.69068732, grad/param norm = 1.7097e-01, time/batch = 14.4500s	
32390/33250 (epoch 48.707), train_loss = 0.60554014, grad/param norm = 1.7824e-01, time/batch = 14.2212s	
32391/33250 (epoch 48.708), train_loss = 0.81271703, grad/param norm = 2.1617e-01, time/batch = 15.2293s	
32392/33250 (epoch 48.710), train_loss = 0.75833968, grad/param norm = 2.5005e-01, time/batch = 14.9184s	
32393/33250 (epoch 48.711), train_loss = 0.64339660, grad/param norm = 1.9299e-01, time/batch = 16.4498s	
32394/33250 (epoch 48.713), train_loss = 0.73672826, grad/param norm = 1.6535e-01, time/batch = 16.1375s	
32395/33250 (epoch 48.714), train_loss = 0.69975901, grad/param norm = 2.0933e-01, time/batch = 16.1374s	
32396/33250 (epoch 48.716), train_loss = 0.75330047, grad/param norm = 1.8925e-01, time/batch = 15.5564s	
32397/33250 (epoch 48.717), train_loss = 0.70318682, grad/param norm = 1.5367e-01, time/batch = 17.1905s	
32398/33250 (epoch 48.719), train_loss = 0.65541877, grad/param norm = 1.7711e-01, time/batch = 15.6234s	
32399/33250 (epoch 48.720), train_loss = 0.93569133, grad/param norm = 2.0577e-01, time/batch = 14.7803s	
32400/33250 (epoch 48.722), train_loss = 0.63085218, grad/param norm = 1.7700e-01, time/batch = 15.1448s	
32401/33250 (epoch 48.723), train_loss = 0.57063107, grad/param norm = 1.4539e-01, time/batch = 15.4945s	
32402/33250 (epoch 48.725), train_loss = 0.71806795, grad/param norm = 1.6234e-01, time/batch = 16.0175s	
32403/33250 (epoch 48.726), train_loss = 0.74815680, grad/param norm = 1.9611e-01, time/batch = 15.3747s	
32404/33250 (epoch 48.728), train_loss = 0.75162176, grad/param norm = 1.9028e-01, time/batch = 15.2167s	
32405/33250 (epoch 48.729), train_loss = 0.79053575, grad/param norm = 1.9908e-01, time/batch = 17.1354s	
32406/33250 (epoch 48.731), train_loss = 0.63574442, grad/param norm = 1.9527e-01, time/batch = 16.2161s	
32407/33250 (epoch 48.732), train_loss = 0.65982446, grad/param norm = 1.7631e-01, time/batch = 15.3779s	
32408/33250 (epoch 48.734), train_loss = 0.74366905, grad/param norm = 2.0777e-01, time/batch = 14.4672s	
32409/33250 (epoch 48.735), train_loss = 0.74500973, grad/param norm = 1.8457e-01, time/batch = 14.8083s	
32410/33250 (epoch 48.737), train_loss = 0.69666081, grad/param norm = 1.6445e-01, time/batch = 14.5488s	
32411/33250 (epoch 48.738), train_loss = 0.76440007, grad/param norm = 2.0204e-01, time/batch = 15.3275s	
32412/33250 (epoch 48.740), train_loss = 0.72916477, grad/param norm = 1.8433e-01, time/batch = 15.0491s	
32413/33250 (epoch 48.741), train_loss = 0.77258474, grad/param norm = 1.7698e-01, time/batch = 14.4784s	
32414/33250 (epoch 48.743), train_loss = 0.67972248, grad/param norm = 1.6957e-01, time/batch = 14.6905s	
32415/33250 (epoch 48.744), train_loss = 0.66965532, grad/param norm = 1.8368e-01, time/batch = 14.9657s	
32416/33250 (epoch 48.746), train_loss = 0.66893116, grad/param norm = 1.9962e-01, time/batch = 17.7091s	
32417/33250 (epoch 48.747), train_loss = 0.62775317, grad/param norm = 1.8332e-01, time/batch = 16.5657s	
32418/33250 (epoch 48.749), train_loss = 0.80899911, grad/param norm = 2.0919e-01, time/batch = 16.7211s	
32419/33250 (epoch 48.750), train_loss = 0.81197058, grad/param norm = 1.7857e-01, time/batch = 15.0397s	
32420/33250 (epoch 48.752), train_loss = 0.70452929, grad/param norm = 1.8202e-01, time/batch = 14.6537s	
32421/33250 (epoch 48.753), train_loss = 0.69866021, grad/param norm = 2.0748e-01, time/batch = 14.9386s	
32422/33250 (epoch 48.755), train_loss = 0.61057875, grad/param norm = 2.2484e-01, time/batch = 15.0861s	
32423/33250 (epoch 48.756), train_loss = 0.72205393, grad/param norm = 1.9619e-01, time/batch = 15.1802s	
32424/33250 (epoch 48.758), train_loss = 0.87128685, grad/param norm = 1.7628e-01, time/batch = 15.1578s	
32425/33250 (epoch 48.759), train_loss = 0.69080136, grad/param norm = 1.6218e-01, time/batch = 14.9388s	
32426/33250 (epoch 48.761), train_loss = 0.78059231, grad/param norm = 2.3734e-01, time/batch = 15.2507s	
32427/33250 (epoch 48.762), train_loss = 0.78028002, grad/param norm = 1.9127e-01, time/batch = 14.9295s	
32428/33250 (epoch 48.764), train_loss = 0.63957459, grad/param norm = 2.1964e-01, time/batch = 14.4773s	
32429/33250 (epoch 48.765), train_loss = 0.73917328, grad/param norm = 1.9786e-01, time/batch = 14.9590s	
32430/33250 (epoch 48.767), train_loss = 0.58156847, grad/param norm = 1.7806e-01, time/batch = 15.8676s	
32431/33250 (epoch 48.768), train_loss = 0.61005268, grad/param norm = 1.9500e-01, time/batch = 14.7775s	
32432/33250 (epoch 48.770), train_loss = 0.75354948, grad/param norm = 1.9031e-01, time/batch = 14.7006s	
32433/33250 (epoch 48.771), train_loss = 0.77948657, grad/param norm = 2.0600e-01, time/batch = 14.5548s	
32434/33250 (epoch 48.773), train_loss = 0.70724536, grad/param norm = 2.0365e-01, time/batch = 14.5308s	
32435/33250 (epoch 48.774), train_loss = 0.58708804, grad/param norm = 1.8607e-01, time/batch = 14.8011s	
32436/33250 (epoch 48.776), train_loss = 0.68963921, grad/param norm = 1.8240e-01, time/batch = 15.3726s	
32437/33250 (epoch 48.777), train_loss = 0.80858313, grad/param norm = 2.3875e-01, time/batch = 15.9790s	
32438/33250 (epoch 48.779), train_loss = 0.69151696, grad/param norm = 1.9377e-01, time/batch = 16.4433s	
32439/33250 (epoch 48.780), train_loss = 0.83006971, grad/param norm = 2.3655e-01, time/batch = 15.7902s	
32440/33250 (epoch 48.782), train_loss = 0.72665792, grad/param norm = 3.0185e-01, time/batch = 17.9576s	
32441/33250 (epoch 48.783), train_loss = 0.57830883, grad/param norm = 1.6856e-01, time/batch = 15.1238s	
32442/33250 (epoch 48.785), train_loss = 0.64799170, grad/param norm = 1.8927e-01, time/batch = 15.0331s	
32443/33250 (epoch 48.786), train_loss = 0.79380352, grad/param norm = 1.9516e-01, time/batch = 15.1184s	
32444/33250 (epoch 48.788), train_loss = 0.83219582, grad/param norm = 1.9152e-01, time/batch = 14.8955s	
32445/33250 (epoch 48.789), train_loss = 0.82044170, grad/param norm = 2.2624e-01, time/batch = 14.7780s	
32446/33250 (epoch 48.791), train_loss = 0.83438960, grad/param norm = 2.1168e-01, time/batch = 15.2761s	
32447/33250 (epoch 48.792), train_loss = 0.91390840, grad/param norm = 2.1942e-01, time/batch = 15.6244s	
32448/33250 (epoch 48.794), train_loss = 0.69791366, grad/param norm = 1.8678e-01, time/batch = 17.2172s	
32449/33250 (epoch 48.795), train_loss = 0.70458435, grad/param norm = 1.7247e-01, time/batch = 17.4694s	
32450/33250 (epoch 48.797), train_loss = 0.79090957, grad/param norm = 2.1146e-01, time/batch = 15.3491s	
32451/33250 (epoch 48.798), train_loss = 0.67741664, grad/param norm = 2.0078e-01, time/batch = 16.8921s	
32452/33250 (epoch 48.800), train_loss = 0.74618431, grad/param norm = 2.0369e-01, time/batch = 14.6294s	
32453/33250 (epoch 48.802), train_loss = 0.74265576, grad/param norm = 1.7181e-01, time/batch = 14.7536s	
32454/33250 (epoch 48.803), train_loss = 0.78326051, grad/param norm = 1.7899e-01, time/batch = 15.0705s	
32455/33250 (epoch 48.805), train_loss = 0.75194231, grad/param norm = 1.9246e-01, time/batch = 14.7105s	
32456/33250 (epoch 48.806), train_loss = 0.71413084, grad/param norm = 1.8230e-01, time/batch = 14.4734s	
32457/33250 (epoch 48.808), train_loss = 0.66586168, grad/param norm = 1.8844e-01, time/batch = 14.4741s	
32458/33250 (epoch 48.809), train_loss = 0.64816004, grad/param norm = 1.6189e-01, time/batch = 14.8519s	
32459/33250 (epoch 48.811), train_loss = 0.63367953, grad/param norm = 1.8759e-01, time/batch = 14.8050s	
32460/33250 (epoch 48.812), train_loss = 0.74115931, grad/param norm = 2.6922e-01, time/batch = 15.1319s	
32461/33250 (epoch 48.814), train_loss = 0.66963212, grad/param norm = 1.9494e-01, time/batch = 16.2159s	
32462/33250 (epoch 48.815), train_loss = 0.74380960, grad/param norm = 1.9792e-01, time/batch = 15.0497s	
32463/33250 (epoch 48.817), train_loss = 0.68657650, grad/param norm = 1.7815e-01, time/batch = 14.3930s	
32464/33250 (epoch 48.818), train_loss = 0.64683120, grad/param norm = 1.6960e-01, time/batch = 14.4609s	
32465/33250 (epoch 48.820), train_loss = 0.75116399, grad/param norm = 1.8715e-01, time/batch = 14.3800s	
32466/33250 (epoch 48.821), train_loss = 0.71506312, grad/param norm = 1.5324e-01, time/batch = 14.6948s	
32467/33250 (epoch 48.823), train_loss = 0.94281605, grad/param norm = 1.9981e-01, time/batch = 14.8788s	
32468/33250 (epoch 48.824), train_loss = 0.67309608, grad/param norm = 2.0008e-01, time/batch = 14.4784s	
32469/33250 (epoch 48.826), train_loss = 0.74171177, grad/param norm = 1.8360e-01, time/batch = 14.5547s	
32470/33250 (epoch 48.827), train_loss = 0.67105441, grad/param norm = 1.7625e-01, time/batch = 15.0332s	
32471/33250 (epoch 48.829), train_loss = 0.74749297, grad/param norm = 2.1853e-01, time/batch = 17.2992s	
32472/33250 (epoch 48.830), train_loss = 0.76835354, grad/param norm = 2.2339e-01, time/batch = 15.3769s	
32473/33250 (epoch 48.832), train_loss = 0.75570129, grad/param norm = 1.8434e-01, time/batch = 16.4506s	
32474/33250 (epoch 48.833), train_loss = 0.72292186, grad/param norm = 1.8939e-01, time/batch = 15.1296s	
32475/33250 (epoch 48.835), train_loss = 0.65190664, grad/param norm = 2.0222e-01, time/batch = 14.9396s	
32476/33250 (epoch 48.836), train_loss = 0.71537918, grad/param norm = 1.6540e-01, time/batch = 14.8100s	
32477/33250 (epoch 48.838), train_loss = 0.74797145, grad/param norm = 1.8189e-01, time/batch = 15.1898s	
32478/33250 (epoch 48.839), train_loss = 0.70850538, grad/param norm = 2.1194e-01, time/batch = 14.6820s	
32479/33250 (epoch 48.841), train_loss = 0.67463403, grad/param norm = 1.7935e-01, time/batch = 15.5458s	
32480/33250 (epoch 48.842), train_loss = 0.85348903, grad/param norm = 2.2127e-01, time/batch = 14.7916s	
32481/33250 (epoch 48.844), train_loss = 0.79481444, grad/param norm = 2.1468e-01, time/batch = 15.2027s	
32482/33250 (epoch 48.845), train_loss = 0.88151932, grad/param norm = 2.3677e-01, time/batch = 16.2255s	
32483/33250 (epoch 48.847), train_loss = 0.81857277, grad/param norm = 1.9591e-01, time/batch = 15.7170s	
32484/33250 (epoch 48.848), train_loss = 0.89454761, grad/param norm = 1.9945e-01, time/batch = 15.7996s	
32485/33250 (epoch 48.850), train_loss = 0.81353720, grad/param norm = 1.8461e-01, time/batch = 14.8698s	
32486/33250 (epoch 48.851), train_loss = 0.63137510, grad/param norm = 2.3461e-01, time/batch = 14.7729s	
32487/33250 (epoch 48.853), train_loss = 0.72706733, grad/param norm = 2.2120e-01, time/batch = 14.3102s	
32488/33250 (epoch 48.854), train_loss = 0.67297333, grad/param norm = 1.5696e-01, time/batch = 14.7903s	
32489/33250 (epoch 48.856), train_loss = 0.66193808, grad/param norm = 1.6826e-01, time/batch = 14.8677s	
32490/33250 (epoch 48.857), train_loss = 0.62061176, grad/param norm = 1.9590e-01, time/batch = 14.7765s	
32491/33250 (epoch 48.859), train_loss = 0.69108111, grad/param norm = 1.9503e-01, time/batch = 14.4675s	
32492/33250 (epoch 48.860), train_loss = 0.78443461, grad/param norm = 1.7706e-01, time/batch = 14.9699s	
32493/33250 (epoch 48.862), train_loss = 0.67816729, grad/param norm = 2.1763e-01, time/batch = 15.7901s	
32494/33250 (epoch 48.863), train_loss = 0.68071793, grad/param norm = 2.1845e-01, time/batch = 15.3168s	
32495/33250 (epoch 48.865), train_loss = 0.72851653, grad/param norm = 1.8972e-01, time/batch = 15.7994s	
32496/33250 (epoch 48.866), train_loss = 0.65644211, grad/param norm = 1.7873e-01, time/batch = 14.4852s	
32497/33250 (epoch 48.868), train_loss = 0.73675345, grad/param norm = 3.1172e-01, time/batch = 14.6240s	
32498/33250 (epoch 48.869), train_loss = 0.74677237, grad/param norm = 1.9513e-01, time/batch = 14.8734s	
32499/33250 (epoch 48.871), train_loss = 0.59599145, grad/param norm = 1.5505e-01, time/batch = 14.6239s	
32500/33250 (epoch 48.872), train_loss = 0.79714811, grad/param norm = 2.1116e-01, time/batch = 15.0957s	
32501/33250 (epoch 48.874), train_loss = 0.66953237, grad/param norm = 1.9946e-01, time/batch = 14.7003s	
32502/33250 (epoch 48.875), train_loss = 0.62207857, grad/param norm = 2.1373e-01, time/batch = 15.0913s	
32503/33250 (epoch 48.877), train_loss = 0.79993299, grad/param norm = 1.8250e-01, time/batch = 15.0672s	
32504/33250 (epoch 48.878), train_loss = 0.74996511, grad/param norm = 2.0519e-01, time/batch = 15.8697s	
32505/33250 (epoch 48.880), train_loss = 0.72397874, grad/param norm = 1.9905e-01, time/batch = 15.3166s	
32506/33250 (epoch 48.881), train_loss = 0.82295212, grad/param norm = 1.9635e-01, time/batch = 16.3953s	
32507/33250 (epoch 48.883), train_loss = 0.77470980, grad/param norm = 2.0689e-01, time/batch = 15.2978s	
32508/33250 (epoch 48.884), train_loss = 0.83510853, grad/param norm = 2.3068e-01, time/batch = 14.6951s	
32509/33250 (epoch 48.886), train_loss = 0.66938910, grad/param norm = 1.6761e-01, time/batch = 12.9354s	
32510/33250 (epoch 48.887), train_loss = 0.68778031, grad/param norm = 1.9396e-01, time/batch = 0.9453s	
32511/33250 (epoch 48.889), train_loss = 0.68789567, grad/param norm = 1.6484e-01, time/batch = 0.6795s	
32512/33250 (epoch 48.890), train_loss = 0.56504252, grad/param norm = 1.5004e-01, time/batch = 0.6623s	
32513/33250 (epoch 48.892), train_loss = 0.75783730, grad/param norm = 1.8706e-01, time/batch = 0.6616s	
32514/33250 (epoch 48.893), train_loss = 0.75171201, grad/param norm = 1.9011e-01, time/batch = 0.6672s	
32515/33250 (epoch 48.895), train_loss = 0.68679587, grad/param norm = 2.0514e-01, time/batch = 0.6689s	
32516/33250 (epoch 48.896), train_loss = 0.77866631, grad/param norm = 1.8799e-01, time/batch = 0.8664s	
32517/33250 (epoch 48.898), train_loss = 0.72282457, grad/param norm = 2.1700e-01, time/batch = 0.9752s	
32518/33250 (epoch 48.899), train_loss = 0.70131271, grad/param norm = 1.8269e-01, time/batch = 0.9697s	
32519/33250 (epoch 48.901), train_loss = 0.60764679, grad/param norm = 1.6331e-01, time/batch = 0.9685s	
32520/33250 (epoch 48.902), train_loss = 0.66713271, grad/param norm = 2.0173e-01, time/batch = 0.9712s	
32521/33250 (epoch 48.904), train_loss = 0.65484772, grad/param norm = 1.7968e-01, time/batch = 1.4449s	
32522/33250 (epoch 48.905), train_loss = 0.69343527, grad/param norm = 1.5495e-01, time/batch = 1.8210s	
32523/33250 (epoch 48.907), train_loss = 0.67401901, grad/param norm = 2.0046e-01, time/batch = 1.8141s	
32524/33250 (epoch 48.908), train_loss = 0.69729396, grad/param norm = 1.5605e-01, time/batch = 12.2479s	
32525/33250 (epoch 48.910), train_loss = 0.80684460, grad/param norm = 2.3859e-01, time/batch = 14.2980s	
32526/33250 (epoch 48.911), train_loss = 0.62954178, grad/param norm = 1.7644e-01, time/batch = 15.2963s	
32527/33250 (epoch 48.913), train_loss = 0.64708499, grad/param norm = 1.4916e-01, time/batch = 15.5415s	
32528/33250 (epoch 48.914), train_loss = 0.58742710, grad/param norm = 1.7630e-01, time/batch = 18.6962s	
32529/33250 (epoch 48.916), train_loss = 0.63509104, grad/param norm = 2.2475e-01, time/batch = 15.7902s	
32530/33250 (epoch 48.917), train_loss = 0.73048266, grad/param norm = 1.5504e-01, time/batch = 17.2022s	
32531/33250 (epoch 48.919), train_loss = 0.64449645, grad/param norm = 2.3231e-01, time/batch = 15.0224s	
32532/33250 (epoch 48.920), train_loss = 0.72332882, grad/param norm = 1.7950e-01, time/batch = 15.1148s	
32533/33250 (epoch 48.922), train_loss = 0.73787000, grad/param norm = 2.2315e-01, time/batch = 15.0264s	
32534/33250 (epoch 48.923), train_loss = 0.69390194, grad/param norm = 1.9520e-01, time/batch = 14.7863s	
32535/33250 (epoch 48.925), train_loss = 0.70221207, grad/param norm = 1.9003e-01, time/batch = 15.1252s	
32536/33250 (epoch 48.926), train_loss = 0.67046816, grad/param norm = 1.6867e-01, time/batch = 14.7939s	
32537/33250 (epoch 48.928), train_loss = 0.71737707, grad/param norm = 2.1690e-01, time/batch = 14.9234s	
32538/33250 (epoch 48.929), train_loss = 0.63870112, grad/param norm = 1.4826e-01, time/batch = 14.5478s	
32539/33250 (epoch 48.931), train_loss = 0.81199470, grad/param norm = 1.9952e-01, time/batch = 16.9754s	
32540/33250 (epoch 48.932), train_loss = 0.64211717, grad/param norm = 1.7154e-01, time/batch = 16.7049s	
32541/33250 (epoch 48.934), train_loss = 0.64877610, grad/param norm = 1.6797e-01, time/batch = 16.0392s	
32542/33250 (epoch 48.935), train_loss = 0.68185667, grad/param norm = 1.8590e-01, time/batch = 16.3654s	
32543/33250 (epoch 48.937), train_loss = 0.65383673, grad/param norm = 1.7700e-01, time/batch = 15.0420s	
32544/33250 (epoch 48.938), train_loss = 0.68250939, grad/param norm = 2.0462e-01, time/batch = 14.7776s	
32545/33250 (epoch 48.940), train_loss = 0.69119373, grad/param norm = 2.1250e-01, time/batch = 15.0332s	
32546/33250 (epoch 48.941), train_loss = 0.74475070, grad/param norm = 2.1199e-01, time/batch = 14.7734s	
32547/33250 (epoch 48.943), train_loss = 0.82855639, grad/param norm = 1.9752e-01, time/batch = 14.2278s	
32548/33250 (epoch 48.944), train_loss = 0.69261371, grad/param norm = 1.8202e-01, time/batch = 14.2223s	
32549/33250 (epoch 48.946), train_loss = 0.77706922, grad/param norm = 2.0936e-01, time/batch = 14.5291s	
32550/33250 (epoch 48.947), train_loss = 0.63683989, grad/param norm = 1.6860e-01, time/batch = 15.2909s	
32551/33250 (epoch 48.949), train_loss = 0.77863074, grad/param norm = 2.2856e-01, time/batch = 16.2291s	
32552/33250 (epoch 48.950), train_loss = 0.78880684, grad/param norm = 2.0322e-01, time/batch = 16.5295s	
32553/33250 (epoch 48.952), train_loss = 0.72119742, grad/param norm = 2.1366e-01, time/batch = 16.4670s	
32554/33250 (epoch 48.953), train_loss = 0.74870902, grad/param norm = 2.4206e-01, time/batch = 14.7040s	
32555/33250 (epoch 48.955), train_loss = 0.77368450, grad/param norm = 1.8040e-01, time/batch = 16.0398s	
32556/33250 (epoch 48.956), train_loss = 0.69829454, grad/param norm = 2.4465e-01, time/batch = 14.8883s	
32557/33250 (epoch 48.958), train_loss = 0.68800024, grad/param norm = 1.7652e-01, time/batch = 14.7023s	
32558/33250 (epoch 48.959), train_loss = 0.69085005, grad/param norm = 1.8669e-01, time/batch = 14.4727s	
32559/33250 (epoch 48.961), train_loss = 0.90661172, grad/param norm = 2.2166e-01, time/batch = 15.1182s	
32560/33250 (epoch 48.962), train_loss = 0.73407407, grad/param norm = 1.9969e-01, time/batch = 14.3069s	
32561/33250 (epoch 48.964), train_loss = 0.83654797, grad/param norm = 2.1153e-01, time/batch = 15.3679s	
32562/33250 (epoch 48.965), train_loss = 0.77172389, grad/param norm = 2.0170e-01, time/batch = 15.5553s	
32563/33250 (epoch 48.967), train_loss = 0.70772539, grad/param norm = 2.4231e-01, time/batch = 15.7334s	
32564/33250 (epoch 48.968), train_loss = 0.81539972, grad/param norm = 1.6169e-01, time/batch = 14.4997s	
32565/33250 (epoch 48.970), train_loss = 0.90308235, grad/param norm = 2.5231e-01, time/batch = 14.9516s	
32566/33250 (epoch 48.971), train_loss = 0.86225096, grad/param norm = 2.2201e-01, time/batch = 14.8637s	
32567/33250 (epoch 48.973), train_loss = 0.68677210, grad/param norm = 1.6695e-01, time/batch = 14.7112s	
32568/33250 (epoch 48.974), train_loss = 0.78851272, grad/param norm = 2.0123e-01, time/batch = 14.7206s	
32569/33250 (epoch 48.976), train_loss = 0.71618992, grad/param norm = 2.1053e-01, time/batch = 15.1989s	
32570/33250 (epoch 48.977), train_loss = 0.72245830, grad/param norm = 1.8520e-01, time/batch = 15.6215s	
32571/33250 (epoch 48.979), train_loss = 0.78390392, grad/param norm = 1.9543e-01, time/batch = 15.6088s	
32572/33250 (epoch 48.980), train_loss = 0.77525100, grad/param norm = 1.8149e-01, time/batch = 17.7831s	
32573/33250 (epoch 48.982), train_loss = 0.70954556, grad/param norm = 1.7035e-01, time/batch = 16.2188s	
32574/33250 (epoch 48.983), train_loss = 0.75987201, grad/param norm = 2.3959e-01, time/batch = 14.4671s	
32575/33250 (epoch 48.985), train_loss = 0.69426651, grad/param norm = 1.8767e-01, time/batch = 15.1002s	
32576/33250 (epoch 48.986), train_loss = 0.78030747, grad/param norm = 1.8348e-01, time/batch = 15.1341s	
32577/33250 (epoch 48.988), train_loss = 0.83728736, grad/param norm = 2.1339e-01, time/batch = 15.0093s	
32578/33250 (epoch 48.989), train_loss = 0.81565867, grad/param norm = 1.8463e-01, time/batch = 14.9479s	
32579/33250 (epoch 48.991), train_loss = 0.80314112, grad/param norm = 2.0171e-01, time/batch = 14.9594s	
32580/33250 (epoch 48.992), train_loss = 0.72362950, grad/param norm = 1.7932e-01, time/batch = 14.3037s	
32581/33250 (epoch 48.994), train_loss = 0.68135483, grad/param norm = 1.8506e-01, time/batch = 15.2664s	
32582/33250 (epoch 48.995), train_loss = 0.70056360, grad/param norm = 2.3572e-01, time/batch = 14.7991s	
32583/33250 (epoch 48.997), train_loss = 0.58658642, grad/param norm = 1.9173e-01, time/batch = 14.5336s	
32584/33250 (epoch 48.998), train_loss = 0.74961855, grad/param norm = 1.8661e-01, time/batch = 16.3048s	
decayed learning rate by a factor 0.97 to 0.00059142457479826	
32585/33250 (epoch 49.000), train_loss = 0.77426684, grad/param norm = 1.9519e-01, time/batch = 15.7953s	
32586/33250 (epoch 49.002), train_loss = 0.96803402, grad/param norm = 1.9795e-01, time/batch = 16.9679s	
32587/33250 (epoch 49.003), train_loss = 0.78896036, grad/param norm = 2.0047e-01, time/batch = 15.1023s	
32588/33250 (epoch 49.005), train_loss = 0.61874438, grad/param norm = 1.6393e-01, time/batch = 14.1356s	
32589/33250 (epoch 49.006), train_loss = 0.62013986, grad/param norm = 1.7809e-01, time/batch = 14.3911s	
32590/33250 (epoch 49.008), train_loss = 0.81860544, grad/param norm = 2.0865e-01, time/batch = 14.2928s	
32591/33250 (epoch 49.009), train_loss = 0.90897996, grad/param norm = 2.2268e-01, time/batch = 14.4691s	
32592/33250 (epoch 49.011), train_loss = 0.69743994, grad/param norm = 1.9693e-01, time/batch = 14.5363s	
32593/33250 (epoch 49.012), train_loss = 0.71543681, grad/param norm = 2.3900e-01, time/batch = 14.6194s	
32594/33250 (epoch 49.014), train_loss = 0.80756993, grad/param norm = 2.2884e-01, time/batch = 16.2978s	
32595/33250 (epoch 49.015), train_loss = 0.73596115, grad/param norm = 1.7651e-01, time/batch = 16.9519s	
32596/33250 (epoch 49.017), train_loss = 0.73820536, grad/param norm = 2.1668e-01, time/batch = 15.8929s	
32597/33250 (epoch 49.018), train_loss = 0.59645465, grad/param norm = 1.8406e-01, time/batch = 16.3074s	
32598/33250 (epoch 49.020), train_loss = 0.77040298, grad/param norm = 2.0274e-01, time/batch = 15.7011s	
32599/33250 (epoch 49.021), train_loss = 0.76293028, grad/param norm = 1.8299e-01, time/batch = 14.4726s	
32600/33250 (epoch 49.023), train_loss = 0.60255988, grad/param norm = 1.9535e-01, time/batch = 14.3671s	
32601/33250 (epoch 49.024), train_loss = 0.80909149, grad/param norm = 2.1028e-01, time/batch = 14.7830s	
32602/33250 (epoch 49.026), train_loss = 0.79158923, grad/param norm = 1.9923e-01, time/batch = 14.9559s	
32603/33250 (epoch 49.027), train_loss = 0.77240103, grad/param norm = 2.0207e-01, time/batch = 14.9585s	
32604/33250 (epoch 49.029), train_loss = 0.72748195, grad/param norm = 1.8958e-01, time/batch = 14.9427s	
32605/33250 (epoch 49.030), train_loss = 0.73111093, grad/param norm = 1.9327e-01, time/batch = 17.7154s	
32606/33250 (epoch 49.032), train_loss = 0.89726707, grad/param norm = 2.2484e-01, time/batch = 16.8809s	
32607/33250 (epoch 49.033), train_loss = 0.72100956, grad/param norm = 2.4299e-01, time/batch = 17.7118s	
32608/33250 (epoch 49.035), train_loss = 0.75102726, grad/param norm = 2.0690e-01, time/batch = 14.8775s	
32609/33250 (epoch 49.036), train_loss = 0.77069295, grad/param norm = 2.1512e-01, time/batch = 15.2918s	
32610/33250 (epoch 49.038), train_loss = 0.75695053, grad/param norm = 1.8254e-01, time/batch = 14.7056s	
32611/33250 (epoch 49.039), train_loss = 0.67345109, grad/param norm = 1.7074e-01, time/batch = 15.2220s	
32612/33250 (epoch 49.041), train_loss = 0.73352982, grad/param norm = 2.5400e-01, time/batch = 15.0285s	
32613/33250 (epoch 49.042), train_loss = 0.63003914, grad/param norm = 1.6036e-01, time/batch = 15.1359s	
32614/33250 (epoch 49.044), train_loss = 0.83013434, grad/param norm = 1.8936e-01, time/batch = 15.5625s	
32615/33250 (epoch 49.045), train_loss = 0.85199291, grad/param norm = 2.2218e-01, time/batch = 14.4052s	
32616/33250 (epoch 49.047), train_loss = 0.75974238, grad/param norm = 1.8077e-01, time/batch = 15.5259s	
32617/33250 (epoch 49.048), train_loss = 0.79155934, grad/param norm = 2.3247e-01, time/batch = 16.0587s	
32618/33250 (epoch 49.050), train_loss = 0.73827795, grad/param norm = 1.9508e-01, time/batch = 17.2994s	
32619/33250 (epoch 49.051), train_loss = 0.72710383, grad/param norm = 1.8279e-01, time/batch = 14.8729s	
32620/33250 (epoch 49.053), train_loss = 0.78575744, grad/param norm = 2.2977e-01, time/batch = 14.9292s	
32621/33250 (epoch 49.054), train_loss = 0.62673019, grad/param norm = 1.7123e-01, time/batch = 14.9623s	
32622/33250 (epoch 49.056), train_loss = 0.62850304, grad/param norm = 1.8194e-01, time/batch = 15.5455s	
32623/33250 (epoch 49.057), train_loss = 0.80852026, grad/param norm = 1.9208e-01, time/batch = 14.6413s	
32624/33250 (epoch 49.059), train_loss = 0.72343018, grad/param norm = 1.7533e-01, time/batch = 14.8597s	
32625/33250 (epoch 49.060), train_loss = 0.75839072, grad/param norm = 2.0499e-01, time/batch = 14.4707s	
32626/33250 (epoch 49.062), train_loss = 0.82182123, grad/param norm = 1.9169e-01, time/batch = 15.7255s	
32627/33250 (epoch 49.063), train_loss = 0.84278964, grad/param norm = 2.1612e-01, time/batch = 16.1985s	
32628/33250 (epoch 49.065), train_loss = 0.69036282, grad/param norm = 1.8341e-01, time/batch = 17.8035s	
32629/33250 (epoch 49.066), train_loss = 0.77151004, grad/param norm = 1.9208e-01, time/batch = 15.5334s	
32630/33250 (epoch 49.068), train_loss = 0.70552697, grad/param norm = 2.4369e-01, time/batch = 14.6878s	
32631/33250 (epoch 49.069), train_loss = 0.75447427, grad/param norm = 1.9798e-01, time/batch = 15.0369s	
32632/33250 (epoch 49.071), train_loss = 0.69794293, grad/param norm = 1.8142e-01, time/batch = 14.8002s	
32633/33250 (epoch 49.072), train_loss = 0.66665247, grad/param norm = 1.7540e-01, time/batch = 14.3039s	
32634/33250 (epoch 49.074), train_loss = 0.74269578, grad/param norm = 1.9998e-01, time/batch = 14.3835s	
32635/33250 (epoch 49.075), train_loss = 0.70035511, grad/param norm = 2.1411e-01, time/batch = 14.3809s	
32636/33250 (epoch 49.077), train_loss = 0.72705537, grad/param norm = 2.0039e-01, time/batch = 14.4475s	
32637/33250 (epoch 49.078), train_loss = 0.73398426, grad/param norm = 1.9730e-01, time/batch = 16.5516s	
32638/33250 (epoch 49.080), train_loss = 0.75416968, grad/param norm = 2.2158e-01, time/batch = 16.8039s	
32639/33250 (epoch 49.081), train_loss = 0.75393758, grad/param norm = 1.7244e-01, time/batch = 15.2095s	
32640/33250 (epoch 49.083), train_loss = 0.85548367, grad/param norm = 2.1558e-01, time/batch = 15.3916s	
32641/33250 (epoch 49.084), train_loss = 0.76431300, grad/param norm = 2.1309e-01, time/batch = 14.3990s	
32642/33250 (epoch 49.086), train_loss = 0.75631110, grad/param norm = 1.6045e-01, time/batch = 14.5920s	
32643/33250 (epoch 49.087), train_loss = 0.66202049, grad/param norm = 1.7352e-01, time/batch = 14.5266s	
32644/33250 (epoch 49.089), train_loss = 0.70907680, grad/param norm = 1.9570e-01, time/batch = 14.7677s	
32645/33250 (epoch 49.090), train_loss = 0.77016424, grad/param norm = 1.8360e-01, time/batch = 14.2943s	
32646/33250 (epoch 49.092), train_loss = 0.69091555, grad/param norm = 1.7675e-01, time/batch = 14.2266s	
32647/33250 (epoch 49.093), train_loss = 0.71456508, grad/param norm = 1.7026e-01, time/batch = 14.8526s	
32648/33250 (epoch 49.095), train_loss = 0.73879081, grad/param norm = 2.2173e-01, time/batch = 14.3945s	
32649/33250 (epoch 49.096), train_loss = 0.61200762, grad/param norm = 1.8995e-01, time/batch = 14.5306s	
32650/33250 (epoch 49.098), train_loss = 0.62516797, grad/param norm = 2.2121e-01, time/batch = 14.9403s	
32651/33250 (epoch 49.099), train_loss = 0.57380247, grad/param norm = 1.6425e-01, time/batch = 14.7140s	
32652/33250 (epoch 49.101), train_loss = 0.71121311, grad/param norm = 2.5599e-01, time/batch = 14.4729s	
32653/33250 (epoch 49.102), train_loss = 0.68535710, grad/param norm = 1.6894e-01, time/batch = 14.3680s	
32654/33250 (epoch 49.104), train_loss = 0.57722658, grad/param norm = 1.8104e-01, time/batch = 14.8556s	
32655/33250 (epoch 49.105), train_loss = 0.67977093, grad/param norm = 1.8710e-01, time/batch = 14.6175s	
32656/33250 (epoch 49.107), train_loss = 0.60264202, grad/param norm = 1.4798e-01, time/batch = 14.3764s	
32657/33250 (epoch 49.108), train_loss = 0.71412601, grad/param norm = 2.0421e-01, time/batch = 14.2148s	
32658/33250 (epoch 49.110), train_loss = 0.61481961, grad/param norm = 1.8902e-01, time/batch = 14.6232s	
32659/33250 (epoch 49.111), train_loss = 0.71701092, grad/param norm = 1.7586e-01, time/batch = 16.8654s	
32660/33250 (epoch 49.113), train_loss = 0.66332607, grad/param norm = 1.6393e-01, time/batch = 15.3011s	
32661/33250 (epoch 49.114), train_loss = 0.62463105, grad/param norm = 1.7363e-01, time/batch = 15.1094s	
32662/33250 (epoch 49.116), train_loss = 0.65668813, grad/param norm = 1.8850e-01, time/batch = 15.5533s	
32663/33250 (epoch 49.117), train_loss = 0.64748551, grad/param norm = 1.9076e-01, time/batch = 14.7824s	
32664/33250 (epoch 49.119), train_loss = 0.67918806, grad/param norm = 1.9508e-01, time/batch = 15.1858s	
32665/33250 (epoch 49.120), train_loss = 0.59381954, grad/param norm = 1.5819e-01, time/batch = 14.5607s	
32666/33250 (epoch 49.122), train_loss = 0.75884993, grad/param norm = 1.8559e-01, time/batch = 14.5522s	
32667/33250 (epoch 49.123), train_loss = 0.72537342, grad/param norm = 2.3709e-01, time/batch = 14.7806s	
32668/33250 (epoch 49.125), train_loss = 0.57908397, grad/param norm = 1.7435e-01, time/batch = 14.7951s	
32669/33250 (epoch 49.126), train_loss = 0.68963773, grad/param norm = 1.9879e-01, time/batch = 15.6204s	
32670/33250 (epoch 49.128), train_loss = 0.67068342, grad/param norm = 1.6535e-01, time/batch = 15.8726s	
32671/33250 (epoch 49.129), train_loss = 0.70523976, grad/param norm = 1.7985e-01, time/batch = 16.3737s	
32672/33250 (epoch 49.131), train_loss = 0.69860569, grad/param norm = 1.8960e-01, time/batch = 15.9539s	
32673/33250 (epoch 49.132), train_loss = 0.67439702, grad/param norm = 1.7533e-01, time/batch = 15.9716s	
32674/33250 (epoch 49.134), train_loss = 0.63764027, grad/param norm = 1.8365e-01, time/batch = 15.1656s	
32675/33250 (epoch 49.135), train_loss = 0.72991115, grad/param norm = 1.6652e-01, time/batch = 14.7810s	
32676/33250 (epoch 49.137), train_loss = 0.64157229, grad/param norm = 2.0544e-01, time/batch = 14.3893s	
32677/33250 (epoch 49.138), train_loss = 0.64325362, grad/param norm = 1.6135e-01, time/batch = 14.7095s	
32678/33250 (epoch 49.140), train_loss = 0.55983618, grad/param norm = 1.8363e-01, time/batch = 14.6363s	
32679/33250 (epoch 49.141), train_loss = 0.78182990, grad/param norm = 2.6643e-01, time/batch = 14.7853s	
32680/33250 (epoch 49.143), train_loss = 0.61480060, grad/param norm = 2.0213e-01, time/batch = 15.4519s	
32681/33250 (epoch 49.144), train_loss = 0.68921811, grad/param norm = 1.9697e-01, time/batch = 15.3145s	
32682/33250 (epoch 49.146), train_loss = 0.68298707, grad/param norm = 1.8415e-01, time/batch = 15.1516s	
32683/33250 (epoch 49.147), train_loss = 0.68549970, grad/param norm = 1.9533e-01, time/batch = 14.8923s	
32684/33250 (epoch 49.149), train_loss = 0.65834397, grad/param norm = 1.6989e-01, time/batch = 16.6754s	
32685/33250 (epoch 49.150), train_loss = 0.65006200, grad/param norm = 1.7787e-01, time/batch = 14.4498s	
32686/33250 (epoch 49.152), train_loss = 0.60345362, grad/param norm = 1.7238e-01, time/batch = 14.8051s	
32687/33250 (epoch 49.153), train_loss = 0.84230563, grad/param norm = 1.9758e-01, time/batch = 14.7855s	
32688/33250 (epoch 49.155), train_loss = 0.70338677, grad/param norm = 2.1149e-01, time/batch = 14.3123s	
32689/33250 (epoch 49.156), train_loss = 0.89843516, grad/param norm = 1.9607e-01, time/batch = 14.3665s	
32690/33250 (epoch 49.158), train_loss = 0.85036586, grad/param norm = 2.2894e-01, time/batch = 14.2177s	
32691/33250 (epoch 49.159), train_loss = 0.69627412, grad/param norm = 1.8497e-01, time/batch = 14.6323s	
32692/33250 (epoch 49.161), train_loss = 0.71299558, grad/param norm = 2.1432e-01, time/batch = 16.3022s	
32693/33250 (epoch 49.162), train_loss = 0.62766788, grad/param norm = 1.8358e-01, time/batch = 15.4570s	
32694/33250 (epoch 49.164), train_loss = 0.73461778, grad/param norm = 2.0617e-01, time/batch = 16.9256s	
32695/33250 (epoch 49.165), train_loss = 0.80372541, grad/param norm = 2.0065e-01, time/batch = 14.8892s	
32696/33250 (epoch 49.167), train_loss = 0.82791542, grad/param norm = 2.2416e-01, time/batch = 15.0454s	
32697/33250 (epoch 49.168), train_loss = 0.64810900, grad/param norm = 1.5400e-01, time/batch = 16.1893s	
32698/33250 (epoch 49.170), train_loss = 0.72771418, grad/param norm = 2.2423e-01, time/batch = 14.8003s	
32699/33250 (epoch 49.171), train_loss = 0.72438920, grad/param norm = 1.7935e-01, time/batch = 15.2682s	
32700/33250 (epoch 49.173), train_loss = 0.71920353, grad/param norm = 1.6890e-01, time/batch = 14.7210s	
32701/33250 (epoch 49.174), train_loss = 0.75496864, grad/param norm = 1.6502e-01, time/batch = 15.1713s	
32702/33250 (epoch 49.176), train_loss = 0.65539256, grad/param norm = 1.9759e-01, time/batch = 14.9273s	
32703/33250 (epoch 49.177), train_loss = 0.64270248, grad/param norm = 1.6119e-01, time/batch = 15.6292s	
32704/33250 (epoch 49.179), train_loss = 0.64717554, grad/param norm = 1.6542e-01, time/batch = 16.6371s	
32705/33250 (epoch 49.180), train_loss = 0.59412596, grad/param norm = 1.6109e-01, time/batch = 15.8071s	
32706/33250 (epoch 49.182), train_loss = 0.65175223, grad/param norm = 2.1310e-01, time/batch = 17.2839s	
32707/33250 (epoch 49.183), train_loss = 0.79802898, grad/param norm = 2.1619e-01, time/batch = 14.4628s	
32708/33250 (epoch 49.185), train_loss = 0.74881883, grad/param norm = 2.5728e-01, time/batch = 14.3069s	
32709/33250 (epoch 49.186), train_loss = 0.74434067, grad/param norm = 2.1096e-01, time/batch = 14.7664s	
32710/33250 (epoch 49.188), train_loss = 0.78269882, grad/param norm = 2.2258e-01, time/batch = 14.5403s	
32711/33250 (epoch 49.189), train_loss = 0.57212192, grad/param norm = 1.8805e-01, time/batch = 14.5523s	
32712/33250 (epoch 49.191), train_loss = 0.65337425, grad/param norm = 1.8587e-01, time/batch = 14.7952s	
32713/33250 (epoch 49.192), train_loss = 0.67486258, grad/param norm = 1.8444e-01, time/batch = 14.3845s	
32714/33250 (epoch 49.194), train_loss = 0.69558530, grad/param norm = 2.7987e-01, time/batch = 15.2767s	
32715/33250 (epoch 49.195), train_loss = 0.83296841, grad/param norm = 2.0861e-01, time/batch = 16.2102s	
32716/33250 (epoch 49.197), train_loss = 0.66741154, grad/param norm = 1.5534e-01, time/batch = 17.5454s	
32717/33250 (epoch 49.198), train_loss = 0.82233117, grad/param norm = 2.0180e-01, time/batch = 15.3112s	
32718/33250 (epoch 49.200), train_loss = 0.72145005, grad/param norm = 1.9614e-01, time/batch = 15.9307s	
32719/33250 (epoch 49.202), train_loss = 0.67307079, grad/param norm = 1.6108e-01, time/batch = 15.0194s	
32720/33250 (epoch 49.203), train_loss = 0.64724409, grad/param norm = 1.7817e-01, time/batch = 15.4379s	
32721/33250 (epoch 49.205), train_loss = 0.71891178, grad/param norm = 1.9387e-01, time/batch = 14.9559s	
32722/33250 (epoch 49.206), train_loss = 0.77567236, grad/param norm = 1.8206e-01, time/batch = 14.8772s	
32723/33250 (epoch 49.208), train_loss = 0.79690874, grad/param norm = 2.0053e-01, time/batch = 14.5531s	
32724/33250 (epoch 49.209), train_loss = 0.67561864, grad/param norm = 1.8336e-01, time/batch = 14.9509s	
32725/33250 (epoch 49.211), train_loss = 0.74655074, grad/param norm = 2.8578e-01, time/batch = 16.3931s	
32726/33250 (epoch 49.212), train_loss = 0.83699197, grad/param norm = 2.1110e-01, time/batch = 15.2635s	
32727/33250 (epoch 49.214), train_loss = 0.75369526, grad/param norm = 1.7179e-01, time/batch = 17.5344s	
32728/33250 (epoch 49.215), train_loss = 0.75545652, grad/param norm = 2.5356e-01, time/batch = 15.0351s	
32729/33250 (epoch 49.217), train_loss = 0.79569942, grad/param norm = 2.2745e-01, time/batch = 15.1282s	
32730/33250 (epoch 49.218), train_loss = 0.73021696, grad/param norm = 1.7876e-01, time/batch = 15.0130s	
32731/33250 (epoch 49.220), train_loss = 0.70716294, grad/param norm = 1.7779e-01, time/batch = 14.7914s	
32732/33250 (epoch 49.221), train_loss = 0.82426849, grad/param norm = 2.7115e-01, time/batch = 14.8851s	
32733/33250 (epoch 49.223), train_loss = 0.70952532, grad/param norm = 1.7143e-01, time/batch = 14.9586s	
32734/33250 (epoch 49.224), train_loss = 0.75038087, grad/param norm = 1.9444e-01, time/batch = 14.8553s	
32735/33250 (epoch 49.226), train_loss = 0.84899725, grad/param norm = 2.0310e-01, time/batch = 16.6989s	
32736/33250 (epoch 49.227), train_loss = 0.75538692, grad/param norm = 2.1031e-01, time/batch = 17.8718s	
32737/33250 (epoch 49.229), train_loss = 0.74989748, grad/param norm = 1.8056e-01, time/batch = 17.1060s	
32738/33250 (epoch 49.230), train_loss = 0.74448147, grad/param norm = 1.7665e-01, time/batch = 18.2850s	
32739/33250 (epoch 49.232), train_loss = 0.70168838, grad/param norm = 2.2130e-01, time/batch = 15.0427s	
32740/33250 (epoch 49.233), train_loss = 0.66971225, grad/param norm = 1.8264e-01, time/batch = 15.0599s	
32741/33250 (epoch 49.235), train_loss = 0.81913014, grad/param norm = 1.7601e-01, time/batch = 14.8696s	
32742/33250 (epoch 49.236), train_loss = 0.65357239, grad/param norm = 1.7821e-01, time/batch = 16.1819s	
32743/33250 (epoch 49.238), train_loss = 0.80878026, grad/param norm = 2.1295e-01, time/batch = 14.7854s	
32744/33250 (epoch 49.239), train_loss = 0.83239906, grad/param norm = 2.4068e-01, time/batch = 14.6304s	
32745/33250 (epoch 49.241), train_loss = 0.79426807, grad/param norm = 2.3010e-01, time/batch = 15.3394s	
32746/33250 (epoch 49.242), train_loss = 0.81226406, grad/param norm = 2.4192e-01, time/batch = 16.1961s	
32747/33250 (epoch 49.244), train_loss = 0.77391514, grad/param norm = 3.0096e-01, time/batch = 15.0577s	
32748/33250 (epoch 49.245), train_loss = 0.77880994, grad/param norm = 2.1200e-01, time/batch = 17.2899s	
32749/33250 (epoch 49.247), train_loss = 0.74064192, grad/param norm = 2.0202e-01, time/batch = 15.0195s	
32750/33250 (epoch 49.248), train_loss = 0.85452790, grad/param norm = 2.1772e-01, time/batch = 14.3120s	
32751/33250 (epoch 49.250), train_loss = 0.84391937, grad/param norm = 1.7164e-01, time/batch = 14.5542s	
32752/33250 (epoch 49.251), train_loss = 0.71961690, grad/param norm = 1.8230e-01, time/batch = 14.3873s	
32753/33250 (epoch 49.253), train_loss = 0.73145499, grad/param norm = 1.8484e-01, time/batch = 14.7794s	
32754/33250 (epoch 49.254), train_loss = 0.67304219, grad/param norm = 1.7254e-01, time/batch = 14.7163s	
32755/33250 (epoch 49.256), train_loss = 0.72901199, grad/param norm = 1.7485e-01, time/batch = 15.0409s	
32756/33250 (epoch 49.257), train_loss = 0.87652662, grad/param norm = 1.8970e-01, time/batch = 14.5529s	
32757/33250 (epoch 49.259), train_loss = 0.75108381, grad/param norm = 2.0297e-01, time/batch = 29.7485s	
32758/33250 (epoch 49.260), train_loss = 0.60950978, grad/param norm = 1.9401e-01, time/batch = 16.5626s	
32759/33250 (epoch 49.262), train_loss = 0.72623915, grad/param norm = 1.8232e-01, time/batch = 16.7249s	
32760/33250 (epoch 49.263), train_loss = 0.58203068, grad/param norm = 1.6983e-01, time/batch = 15.0952s	
32761/33250 (epoch 49.265), train_loss = 0.76280464, grad/param norm = 1.9620e-01, time/batch = 14.9504s	
32762/33250 (epoch 49.266), train_loss = 0.75452049, grad/param norm = 2.1398e-01, time/batch = 14.5478s	
32763/33250 (epoch 49.268), train_loss = 0.63346349, grad/param norm = 1.8109e-01, time/batch = 14.5171s	
32764/33250 (epoch 49.269), train_loss = 0.59528666, grad/param norm = 1.8961e-01, time/batch = 15.0239s	
32765/33250 (epoch 49.271), train_loss = 0.78115161, grad/param norm = 1.8520e-01, time/batch = 14.9305s	
32766/33250 (epoch 49.272), train_loss = 0.67559327, grad/param norm = 1.8074e-01, time/batch = 14.8442s	
32767/33250 (epoch 49.274), train_loss = 0.54935627, grad/param norm = 1.7326e-01, time/batch = 15.4757s	
32768/33250 (epoch 49.275), train_loss = 0.68091622, grad/param norm = 1.4987e-01, time/batch = 14.5640s	
32769/33250 (epoch 49.277), train_loss = 0.61373991, grad/param norm = 2.0071e-01, time/batch = 16.5358s	
32770/33250 (epoch 49.278), train_loss = 0.67931518, grad/param norm = 1.7847e-01, time/batch = 16.4636s	
32771/33250 (epoch 49.280), train_loss = 0.63637403, grad/param norm = 1.7688e-01, time/batch = 15.4606s	
32772/33250 (epoch 49.281), train_loss = 0.75170350, grad/param norm = 2.0878e-01, time/batch = 15.2811s	
32773/33250 (epoch 49.283), train_loss = 0.76450980, grad/param norm = 3.5171e-01, time/batch = 15.0560s	
32774/33250 (epoch 49.284), train_loss = 0.63982593, grad/param norm = 2.2607e-01, time/batch = 14.6176s	
32775/33250 (epoch 49.286), train_loss = 0.75794268, grad/param norm = 1.7909e-01, time/batch = 14.6253s	
32776/33250 (epoch 49.287), train_loss = 0.60822909, grad/param norm = 1.8221e-01, time/batch = 14.7819s	
32777/33250 (epoch 49.289), train_loss = 0.56059026, grad/param norm = 1.7007e-01, time/batch = 15.7009s	
32778/33250 (epoch 49.290), train_loss = 0.72076124, grad/param norm = 2.1199e-01, time/batch = 14.8248s	
32779/33250 (epoch 49.292), train_loss = 0.76418794, grad/param norm = 2.8088e-01, time/batch = 15.2917s	
32780/33250 (epoch 49.293), train_loss = 0.83231830, grad/param norm = 2.0241e-01, time/batch = 17.1154s	
32781/33250 (epoch 49.295), train_loss = 0.82032097, grad/param norm = 2.0080e-01, time/batch = 16.8747s	
32782/33250 (epoch 49.296), train_loss = 0.73756984, grad/param norm = 1.8087e-01, time/batch = 14.7181s	
32783/33250 (epoch 49.298), train_loss = 0.59330179, grad/param norm = 2.0198e-01, time/batch = 14.5486s	
32784/33250 (epoch 49.299), train_loss = 0.58090874, grad/param norm = 2.0378e-01, time/batch = 15.0388s	
32785/33250 (epoch 49.301), train_loss = 0.78472043, grad/param norm = 1.9116e-01, time/batch = 14.7788s	
32786/33250 (epoch 49.302), train_loss = 0.77284213, grad/param norm = 2.1132e-01, time/batch = 14.4612s	
32787/33250 (epoch 49.304), train_loss = 0.70912227, grad/param norm = 2.3712e-01, time/batch = 14.8640s	
32788/33250 (epoch 49.305), train_loss = 0.67335419, grad/param norm = 2.0361e-01, time/batch = 14.9343s	
32789/33250 (epoch 49.307), train_loss = 0.81800862, grad/param norm = 1.8725e-01, time/batch = 15.6450s	
32790/33250 (epoch 49.308), train_loss = 0.80852489, grad/param norm = 2.1192e-01, time/batch = 16.3946s	
32791/33250 (epoch 49.310), train_loss = 0.68262385, grad/param norm = 2.2936e-01, time/batch = 15.1043s	
32792/33250 (epoch 49.311), train_loss = 0.85230338, grad/param norm = 2.4251e-01, time/batch = 14.7977s	
32793/33250 (epoch 49.313), train_loss = 0.60457295, grad/param norm = 2.4771e-01, time/batch = 14.8659s	
32794/33250 (epoch 49.314), train_loss = 0.82279430, grad/param norm = 2.0686e-01, time/batch = 14.0620s	
32795/33250 (epoch 49.316), train_loss = 0.87708289, grad/param norm = 2.1384e-01, time/batch = 14.6083s	
32796/33250 (epoch 49.317), train_loss = 0.63516542, grad/param norm = 1.5668e-01, time/batch = 14.5504s	
32797/33250 (epoch 49.319), train_loss = 0.75300595, grad/param norm = 2.2321e-01, time/batch = 14.2276s	
32798/33250 (epoch 49.320), train_loss = 0.78313671, grad/param norm = 2.1303e-01, time/batch = 14.3879s	
32799/33250 (epoch 49.322), train_loss = 0.88652600, grad/param norm = 2.3879e-01, time/batch = 14.5439s	
32800/33250 (epoch 49.323), train_loss = 0.86047533, grad/param norm = 3.0888e-01, time/batch = 15.6331s	
32801/33250 (epoch 49.325), train_loss = 0.71905645, grad/param norm = 2.7230e-01, time/batch = 14.8733s	
32802/33250 (epoch 49.326), train_loss = 0.93844764, grad/param norm = 2.2553e-01, time/batch = 16.0561s	
32803/33250 (epoch 49.328), train_loss = 0.72788137, grad/param norm = 2.0654e-01, time/batch = 14.8955s	
32804/33250 (epoch 49.329), train_loss = 0.78022745, grad/param norm = 3.0344e-01, time/batch = 15.3806s	
32805/33250 (epoch 49.331), train_loss = 0.73488946, grad/param norm = 2.2806e-01, time/batch = 14.7854s	
32806/33250 (epoch 49.332), train_loss = 0.77065863, grad/param norm = 2.0198e-01, time/batch = 14.5478s	
32807/33250 (epoch 49.334), train_loss = 0.86482785, grad/param norm = 2.0864e-01, time/batch = 15.0826s	
32808/33250 (epoch 49.335), train_loss = 0.56416826, grad/param norm = 1.7579e-01, time/batch = 14.7986s	
32809/33250 (epoch 49.337), train_loss = 0.79610076, grad/param norm = 1.8032e-01, time/batch = 14.6901s	
32810/33250 (epoch 49.338), train_loss = 0.89372204, grad/param norm = 2.2232e-01, time/batch = 14.3915s	
32811/33250 (epoch 49.340), train_loss = 0.71025745, grad/param norm = 1.6901e-01, time/batch = 15.6271s	
32812/33250 (epoch 49.341), train_loss = 0.65840543, grad/param norm = 1.7937e-01, time/batch = 18.5314s	
32813/33250 (epoch 49.343), train_loss = 0.71239051, grad/param norm = 1.9385e-01, time/batch = 16.4557s	
32814/33250 (epoch 49.344), train_loss = 0.69990751, grad/param norm = 1.5272e-01, time/batch = 16.1402s	
32815/33250 (epoch 49.346), train_loss = 0.64482026, grad/param norm = 1.7876e-01, time/batch = 14.8506s	
32816/33250 (epoch 49.347), train_loss = 0.90224985, grad/param norm = 2.1451e-01, time/batch = 16.1247s	
32817/33250 (epoch 49.349), train_loss = 0.74043813, grad/param norm = 2.3829e-01, time/batch = 15.2987s	
32818/33250 (epoch 49.350), train_loss = 0.72983001, grad/param norm = 2.0003e-01, time/batch = 15.5275s	
32819/33250 (epoch 49.352), train_loss = 0.66115941, grad/param norm = 1.7175e-01, time/batch = 14.7185s	
32820/33250 (epoch 49.353), train_loss = 0.69568772, grad/param norm = 1.6419e-01, time/batch = 14.8899s	
32821/33250 (epoch 49.355), train_loss = 0.69343988, grad/param norm = 1.7188e-01, time/batch = 14.7908s	
32822/33250 (epoch 49.356), train_loss = 0.68401443, grad/param norm = 2.5282e-01, time/batch = 16.1944s	
32823/33250 (epoch 49.358), train_loss = 0.72298737, grad/param norm = 1.8045e-01, time/batch = 15.0296s	
32824/33250 (epoch 49.359), train_loss = 0.69241628, grad/param norm = 2.0118e-01, time/batch = 18.8648s	
32825/33250 (epoch 49.361), train_loss = 0.80292198, grad/param norm = 2.1968e-01, time/batch = 14.8660s	
32826/33250 (epoch 49.362), train_loss = 0.75475515, grad/param norm = 1.8287e-01, time/batch = 15.1994s	
32827/33250 (epoch 49.364), train_loss = 0.78031817, grad/param norm = 2.0974e-01, time/batch = 14.8578s	
32828/33250 (epoch 49.365), train_loss = 0.72257729, grad/param norm = 1.7614e-01, time/batch = 14.6753s	
32829/33250 (epoch 49.367), train_loss = 0.76467090, grad/param norm = 1.9444e-01, time/batch = 14.6429s	
32830/33250 (epoch 49.368), train_loss = 0.72436633, grad/param norm = 1.8196e-01, time/batch = 15.8408s	
32831/33250 (epoch 49.370), train_loss = 0.66108248, grad/param norm = 2.4383e-01, time/batch = 14.3806s	
32832/33250 (epoch 49.371), train_loss = 0.81197927, grad/param norm = 2.4181e-01, time/batch = 16.0560s	
32833/33250 (epoch 49.373), train_loss = 0.71709958, grad/param norm = 1.6540e-01, time/batch = 15.6433s	
32834/33250 (epoch 49.374), train_loss = 0.70445890, grad/param norm = 2.7952e-01, time/batch = 15.2938s	
32835/33250 (epoch 49.376), train_loss = 0.73917310, grad/param norm = 2.0481e-01, time/batch = 16.3560s	
32836/33250 (epoch 49.377), train_loss = 0.63613315, grad/param norm = 2.3709e-01, time/batch = 14.7759s	
32837/33250 (epoch 49.379), train_loss = 0.73598114, grad/param norm = 2.1535e-01, time/batch = 14.4656s	
32838/33250 (epoch 49.380), train_loss = 0.73959650, grad/param norm = 2.1341e-01, time/batch = 14.6334s	
32839/33250 (epoch 49.382), train_loss = 0.74937309, grad/param norm = 2.3515e-01, time/batch = 14.3808s	
32840/33250 (epoch 49.383), train_loss = 0.65482447, grad/param norm = 1.9390e-01, time/batch = 14.4571s	
32841/33250 (epoch 49.385), train_loss = 0.62716934, grad/param norm = 1.9979e-01, time/batch = 14.2995s	
32842/33250 (epoch 49.386), train_loss = 0.64238934, grad/param norm = 2.8731e-01, time/batch = 14.4481s	
32843/33250 (epoch 49.388), train_loss = 0.69957111, grad/param norm = 2.0067e-01, time/batch = 16.6286s	
32844/33250 (epoch 49.389), train_loss = 0.64894497, grad/param norm = 2.1922e-01, time/batch = 15.0622s	
32845/33250 (epoch 49.391), train_loss = 0.75558132, grad/param norm = 2.0623e-01, time/batch = 14.7004s	
32846/33250 (epoch 49.392), train_loss = 0.83522608, grad/param norm = 2.3690e-01, time/batch = 14.9726s	
32847/33250 (epoch 49.394), train_loss = 0.80545565, grad/param norm = 2.0574e-01, time/batch = 14.4684s	
32848/33250 (epoch 49.395), train_loss = 0.84816800, grad/param norm = 1.9549e-01, time/batch = 14.3005s	
32849/33250 (epoch 49.397), train_loss = 0.83960865, grad/param norm = 1.9435e-01, time/batch = 14.2243s	
32850/33250 (epoch 49.398), train_loss = 0.64766953, grad/param norm = 1.8341e-01, time/batch = 14.7839s	
32851/33250 (epoch 49.400), train_loss = 0.65918076, grad/param norm = 1.8660e-01, time/batch = 15.0343s	
32852/33250 (epoch 49.402), train_loss = 0.61248847, grad/param norm = 2.3961e-01, time/batch = 14.3837s	
32853/33250 (epoch 49.403), train_loss = 0.74306107, grad/param norm = 2.7183e-01, time/batch = 14.7077s	
32854/33250 (epoch 49.405), train_loss = 0.66102977, grad/param norm = 1.6309e-01, time/batch = 14.6219s	
32855/33250 (epoch 49.406), train_loss = 0.71302025, grad/param norm = 2.1801e-01, time/batch = 15.9680s	
32856/33250 (epoch 49.408), train_loss = 0.83648435, grad/param norm = 1.8808e-01, time/batch = 16.8197s	
32857/33250 (epoch 49.409), train_loss = 0.75649222, grad/param norm = 1.9305e-01, time/batch = 14.4877s	
32858/33250 (epoch 49.411), train_loss = 0.56234484, grad/param norm = 1.7301e-01, time/batch = 14.6395s	
32859/33250 (epoch 49.412), train_loss = 0.61646890, grad/param norm = 1.7489e-01, time/batch = 14.0572s	
32860/33250 (epoch 49.414), train_loss = 0.72839406, grad/param norm = 1.8900e-01, time/batch = 14.5908s	
32861/33250 (epoch 49.415), train_loss = 0.80092380, grad/param norm = 2.1380e-01, time/batch = 14.3862s	
32862/33250 (epoch 49.417), train_loss = 0.82662353, grad/param norm = 2.3311e-01, time/batch = 14.3699s	
32863/33250 (epoch 49.418), train_loss = 0.95998905, grad/param norm = 2.2385e-01, time/batch = 14.6841s	
32864/33250 (epoch 49.420), train_loss = 0.80742616, grad/param norm = 1.9348e-01, time/batch = 14.4549s	
32865/33250 (epoch 49.421), train_loss = 0.69756346, grad/param norm = 1.9433e-01, time/batch = 14.9630s	
32866/33250 (epoch 49.423), train_loss = 0.76741211, grad/param norm = 1.8800e-01, time/batch = 15.0567s	
32867/33250 (epoch 49.424), train_loss = 0.84415332, grad/param norm = 2.9126e-01, time/batch = 14.6982s	
32868/33250 (epoch 49.426), train_loss = 0.72217046, grad/param norm = 1.5341e-01, time/batch = 15.8190s	
32869/33250 (epoch 49.427), train_loss = 0.67213172, grad/param norm = 1.8098e-01, time/batch = 15.3165s	
32870/33250 (epoch 49.429), train_loss = 0.70852697, grad/param norm = 2.2015e-01, time/batch = 14.6293s	
32871/33250 (epoch 49.430), train_loss = 0.68472393, grad/param norm = 2.1366e-01, time/batch = 14.6255s	
32872/33250 (epoch 49.432), train_loss = 0.80457934, grad/param norm = 2.1182e-01, time/batch = 14.7135s	
32873/33250 (epoch 49.433), train_loss = 0.69529220, grad/param norm = 1.7928e-01, time/batch = 14.4635s	
32874/33250 (epoch 49.435), train_loss = 0.76033227, grad/param norm = 1.8606e-01, time/batch = 14.8667s	
32875/33250 (epoch 49.436), train_loss = 0.69109145, grad/param norm = 1.9768e-01, time/batch = 15.5333s	
32876/33250 (epoch 49.438), train_loss = 0.83457613, grad/param norm = 1.8234e-01, time/batch = 15.0214s	
32877/33250 (epoch 49.439), train_loss = 0.74124394, grad/param norm = 1.6858e-01, time/batch = 15.5370s	
32878/33250 (epoch 49.441), train_loss = 0.72409239, grad/param norm = 1.7505e-01, time/batch = 15.4752s	
32879/33250 (epoch 49.442), train_loss = 0.65098061, grad/param norm = 1.6880e-01, time/batch = 15.6479s	
32880/33250 (epoch 49.444), train_loss = 0.69339934, grad/param norm = 1.6086e-01, time/batch = 14.9779s	
32881/33250 (epoch 49.445), train_loss = 0.74465721, grad/param norm = 1.5699e-01, time/batch = 15.1861s	
32882/33250 (epoch 49.447), train_loss = 0.65180632, grad/param norm = 1.8565e-01, time/batch = 14.5403s	
32883/33250 (epoch 49.448), train_loss = 0.74738787, grad/param norm = 1.6248e-01, time/batch = 14.3927s	
32884/33250 (epoch 49.450), train_loss = 0.80635750, grad/param norm = 2.0558e-01, time/batch = 14.4395s	
32885/33250 (epoch 49.451), train_loss = 0.77156320, grad/param norm = 1.9880e-01, time/batch = 14.2891s	
32886/33250 (epoch 49.453), train_loss = 0.63511125, grad/param norm = 1.5804e-01, time/batch = 14.4617s	
32887/33250 (epoch 49.454), train_loss = 0.82069204, grad/param norm = 1.9141e-01, time/batch = 14.4715s	
32888/33250 (epoch 49.456), train_loss = 0.84715655, grad/param norm = 1.6920e-01, time/batch = 14.7221s	
32889/33250 (epoch 49.457), train_loss = 0.67706242, grad/param norm = 1.8204e-01, time/batch = 16.9664s	
32890/33250 (epoch 49.459), train_loss = 0.81051556, grad/param norm = 2.0978e-01, time/batch = 14.9801s	
32891/33250 (epoch 49.460), train_loss = 0.77460058, grad/param norm = 2.1034e-01, time/batch = 15.4010s	
32892/33250 (epoch 49.462), train_loss = 0.74216913, grad/param norm = 1.7831e-01, time/batch = 14.5667s	
32893/33250 (epoch 49.463), train_loss = 0.65276956, grad/param norm = 1.6330e-01, time/batch = 15.0409s	
32894/33250 (epoch 49.465), train_loss = 0.62730361, grad/param norm = 1.5774e-01, time/batch = 15.0332s	
32895/33250 (epoch 49.466), train_loss = 0.61199163, grad/param norm = 1.5092e-01, time/batch = 15.9480s	
32896/33250 (epoch 49.468), train_loss = 0.62098430, grad/param norm = 1.6726e-01, time/batch = 14.5580s	
32897/33250 (epoch 49.469), train_loss = 0.73201573, grad/param norm = 2.2531e-01, time/batch = 14.7958s	
32898/33250 (epoch 49.471), train_loss = 0.80444405, grad/param norm = 1.6707e-01, time/batch = 14.8436s	
32899/33250 (epoch 49.472), train_loss = 0.68774064, grad/param norm = 2.0512e-01, time/batch = 16.4558s	
32900/33250 (epoch 49.474), train_loss = 0.79851515, grad/param norm = 1.8105e-01, time/batch = 17.2987s	
32901/33250 (epoch 49.475), train_loss = 0.77747785, grad/param norm = 2.0787e-01, time/batch = 18.1102s	
32902/33250 (epoch 49.477), train_loss = 0.75897230, grad/param norm = 2.3179e-01, time/batch = 15.7323s	
32903/33250 (epoch 49.478), train_loss = 0.62792421, grad/param norm = 1.8788e-01, time/batch = 15.8849s	
32904/33250 (epoch 49.480), train_loss = 0.82418319, grad/param norm = 2.0122e-01, time/batch = 14.7968s	
32905/33250 (epoch 49.481), train_loss = 0.71962868, grad/param norm = 1.7770e-01, time/batch = 16.8421s	
32906/33250 (epoch 49.483), train_loss = 0.69205169, grad/param norm = 2.1541e-01, time/batch = 14.2245s	
32907/33250 (epoch 49.484), train_loss = 0.68005476, grad/param norm = 1.8756e-01, time/batch = 14.4593s	
32908/33250 (epoch 49.486), train_loss = 0.59028373, grad/param norm = 1.8097e-01, time/batch = 14.1476s	
32909/33250 (epoch 49.487), train_loss = 0.65433659, grad/param norm = 2.0269e-01, time/batch = 14.3012s	
32910/33250 (epoch 49.489), train_loss = 0.80352812, grad/param norm = 2.1031e-01, time/batch = 15.2020s	
32911/33250 (epoch 49.490), train_loss = 0.71525633, grad/param norm = 2.2712e-01, time/batch = 15.5633s	
32912/33250 (epoch 49.492), train_loss = 0.80485256, grad/param norm = 2.1773e-01, time/batch = 17.0484s	
32913/33250 (epoch 49.493), train_loss = 0.71320719, grad/param norm = 1.7662e-01, time/batch = 15.5258s	
32914/33250 (epoch 49.495), train_loss = 0.80502491, grad/param norm = 1.7430e-01, time/batch = 14.5550s	
32915/33250 (epoch 49.496), train_loss = 0.74250840, grad/param norm = 1.6796e-01, time/batch = 14.3923s	
32916/33250 (epoch 49.498), train_loss = 0.78160890, grad/param norm = 2.1810e-01, time/batch = 14.7007s	
32917/33250 (epoch 49.499), train_loss = 0.67890618, grad/param norm = 1.8311e-01, time/batch = 14.5375s	
32918/33250 (epoch 49.501), train_loss = 0.67952369, grad/param norm = 2.0377e-01, time/batch = 14.9150s	
32919/33250 (epoch 49.502), train_loss = 0.70265109, grad/param norm = 1.9417e-01, time/batch = 14.4583s	
32920/33250 (epoch 49.504), train_loss = 0.82205930, grad/param norm = 2.3389e-01, time/batch = 14.5647s	
32921/33250 (epoch 49.505), train_loss = 0.63619827, grad/param norm = 1.5278e-01, time/batch = 16.0285s	
32922/33250 (epoch 49.507), train_loss = 0.65802305, grad/param norm = 1.8126e-01, time/batch = 15.0182s	
32923/33250 (epoch 49.508), train_loss = 0.69591781, grad/param norm = 1.7084e-01, time/batch = 15.3110s	
32924/33250 (epoch 49.510), train_loss = 0.59481994, grad/param norm = 1.4797e-01, time/batch = 15.5515s	
32925/33250 (epoch 49.511), train_loss = 0.70105894, grad/param norm = 1.9747e-01, time/batch = 15.7973s	
32926/33250 (epoch 49.513), train_loss = 0.81923579, grad/param norm = 1.8819e-01, time/batch = 14.7152s	
32927/33250 (epoch 49.514), train_loss = 0.67747450, grad/param norm = 1.8120e-01, time/batch = 14.8861s	
32928/33250 (epoch 49.516), train_loss = 0.66371562, grad/param norm = 2.3607e-01, time/batch = 14.6372s	
32929/33250 (epoch 49.517), train_loss = 0.69929135, grad/param norm = 1.7270e-01, time/batch = 14.7880s	
32930/33250 (epoch 49.519), train_loss = 0.66187966, grad/param norm = 1.4795e-01, time/batch = 14.7073s	
32931/33250 (epoch 49.520), train_loss = 0.87016747, grad/param norm = 2.1911e-01, time/batch = 14.7793s	
32932/33250 (epoch 49.522), train_loss = 0.71867263, grad/param norm = 1.9196e-01, time/batch = 15.5646s	
32933/33250 (epoch 49.523), train_loss = 0.65030840, grad/param norm = 1.8810e-01, time/batch = 16.0298s	
32934/33250 (epoch 49.525), train_loss = 0.61372431, grad/param norm = 1.9127e-01, time/batch = 15.6417s	
32935/33250 (epoch 49.526), train_loss = 0.62683313, grad/param norm = 1.6590e-01, time/batch = 16.8831s	
32936/33250 (epoch 49.528), train_loss = 0.65943633, grad/param norm = 1.7177e-01, time/batch = 14.6329s	
32937/33250 (epoch 49.529), train_loss = 0.66888444, grad/param norm = 2.2070e-01, time/batch = 15.5173s	
32938/33250 (epoch 49.531), train_loss = 0.63018484, grad/param norm = 1.6852e-01, time/batch = 14.9155s	
32939/33250 (epoch 49.532), train_loss = 0.73712321, grad/param norm = 1.7731e-01, time/batch = 15.0186s	
32940/33250 (epoch 49.534), train_loss = 0.65632507, grad/param norm = 1.5663e-01, time/batch = 14.9585s	
32941/33250 (epoch 49.535), train_loss = 0.68618065, grad/param norm = 1.7034e-01, time/batch = 14.3834s	
32942/33250 (epoch 49.537), train_loss = 0.72815199, grad/param norm = 1.5733e-01, time/batch = 15.6150s	
32943/33250 (epoch 49.538), train_loss = 0.75879139, grad/param norm = 1.7817e-01, time/batch = 16.7076s	
32944/33250 (epoch 49.540), train_loss = 0.84879482, grad/param norm = 1.6799e-01, time/batch = 16.3063s	
32945/33250 (epoch 49.541), train_loss = 0.77648672, grad/param norm = 1.9904e-01, time/batch = 16.0302s	
32946/33250 (epoch 49.543), train_loss = 0.77167511, grad/param norm = 1.6177e-01, time/batch = 16.4357s	
32947/33250 (epoch 49.544), train_loss = 0.62982259, grad/param norm = 2.0156e-01, time/batch = 15.3881s	
32948/33250 (epoch 49.546), train_loss = 0.65684493, grad/param norm = 1.8524e-01, time/batch = 15.2896s	
32949/33250 (epoch 49.547), train_loss = 0.67772500, grad/param norm = 1.9297e-01, time/batch = 15.1988s	
32950/33250 (epoch 49.549), train_loss = 0.74207566, grad/param norm = 1.9038e-01, time/batch = 14.7810s	
32951/33250 (epoch 49.550), train_loss = 0.70012414, grad/param norm = 1.9544e-01, time/batch = 14.7187s	
32952/33250 (epoch 49.552), train_loss = 0.77255989, grad/param norm = 1.7726e-01, time/batch = 15.2023s	
32953/33250 (epoch 49.553), train_loss = 0.72596739, grad/param norm = 1.7622e-01, time/batch = 15.1914s	
32954/33250 (epoch 49.555), train_loss = 0.71412845, grad/param norm = 1.8043e-01, time/batch = 16.3171s	
32955/33250 (epoch 49.556), train_loss = 0.74015290, grad/param norm = 2.0881e-01, time/batch = 15.3280s	
32956/33250 (epoch 49.558), train_loss = 0.75220106, grad/param norm = 1.9352e-01, time/batch = 16.5503s	
32957/33250 (epoch 49.559), train_loss = 0.66378105, grad/param norm = 1.7161e-01, time/batch = 14.8741s	
32958/33250 (epoch 49.561), train_loss = 0.59938259, grad/param norm = 1.7625e-01, time/batch = 14.3887s	
32959/33250 (epoch 49.562), train_loss = 0.72103009, grad/param norm = 2.2004e-01, time/batch = 15.2985s	
32960/33250 (epoch 49.564), train_loss = 0.86158376, grad/param norm = 2.2043e-01, time/batch = 15.0136s	
32961/33250 (epoch 49.565), train_loss = 0.79710906, grad/param norm = 2.1380e-01, time/batch = 14.3884s	
32962/33250 (epoch 49.567), train_loss = 0.81943105, grad/param norm = 1.9978e-01, time/batch = 14.6138s	
32963/33250 (epoch 49.568), train_loss = 0.68387100, grad/param norm = 1.9465e-01, time/batch = 14.7002s	
32964/33250 (epoch 49.570), train_loss = 0.76817937, grad/param norm = 1.9218e-01, time/batch = 14.7105s	
32965/33250 (epoch 49.571), train_loss = 0.82494677, grad/param norm = 1.9348e-01, time/batch = 14.9736s	
32966/33250 (epoch 49.573), train_loss = 0.75659348, grad/param norm = 1.9729e-01, time/batch = 16.2297s	
32967/33250 (epoch 49.574), train_loss = 0.65808468, grad/param norm = 1.6706e-01, time/batch = 14.9692s	
32968/33250 (epoch 49.576), train_loss = 0.74462220, grad/param norm = 1.9339e-01, time/batch = 14.2389s	
32969/33250 (epoch 49.577), train_loss = 0.71710969, grad/param norm = 1.9330e-01, time/batch = 14.8616s	
32970/33250 (epoch 49.579), train_loss = 0.62911994, grad/param norm = 1.7388e-01, time/batch = 14.0633s	
32971/33250 (epoch 49.580), train_loss = 0.72124316, grad/param norm = 1.6778e-01, time/batch = 14.6264s	
32972/33250 (epoch 49.582), train_loss = 0.66716582, grad/param norm = 2.0116e-01, time/batch = 15.0194s	
32973/33250 (epoch 49.583), train_loss = 0.77992275, grad/param norm = 2.1101e-01, time/batch = 14.7178s	
32974/33250 (epoch 49.585), train_loss = 0.79783073, grad/param norm = 1.7017e-01, time/batch = 14.9600s	
32975/33250 (epoch 49.586), train_loss = 0.66902972, grad/param norm = 2.1308e-01, time/batch = 14.5433s	
32976/33250 (epoch 49.588), train_loss = 0.75198879, grad/param norm = 1.8184e-01, time/batch = 14.7142s	
32977/33250 (epoch 49.589), train_loss = 0.71420220, grad/param norm = 1.8887e-01, time/batch = 17.8645s	
32978/33250 (epoch 49.591), train_loss = 0.69035550, grad/param norm = 1.8820e-01, time/batch = 15.9782s	
32979/33250 (epoch 49.592), train_loss = 0.68882611, grad/param norm = 1.6913e-01, time/batch = 15.7339s	
32980/33250 (epoch 49.594), train_loss = 0.80766060, grad/param norm = 2.2657e-01, time/batch = 14.9505s	
32981/33250 (epoch 49.595), train_loss = 0.71173593, grad/param norm = 1.7380e-01, time/batch = 15.7844s	
32982/33250 (epoch 49.597), train_loss = 0.59791175, grad/param norm = 1.6029e-01, time/batch = 15.7022s	
32983/33250 (epoch 49.598), train_loss = 0.69489145, grad/param norm = 2.2060e-01, time/batch = 15.0215s	
32984/33250 (epoch 49.600), train_loss = 0.69204919, grad/param norm = 2.0748e-01, time/batch = 14.7784s	
32985/33250 (epoch 49.602), train_loss = 0.72093011, grad/param norm = 2.1628e-01, time/batch = 15.2845s	
32986/33250 (epoch 49.603), train_loss = 0.74759452, grad/param norm = 2.0391e-01, time/batch = 15.3039s	
32987/33250 (epoch 49.605), train_loss = 0.71706532, grad/param norm = 1.7560e-01, time/batch = 15.8540s	
32988/33250 (epoch 49.606), train_loss = 0.74760339, grad/param norm = 1.7220e-01, time/batch = 15.2141s	
32989/33250 (epoch 49.608), train_loss = 0.71671974, grad/param norm = 1.8521e-01, time/batch = 17.1425s	
32990/33250 (epoch 49.609), train_loss = 0.63064626, grad/param norm = 1.8757e-01, time/batch = 16.4518s	
32991/33250 (epoch 49.611), train_loss = 0.67494225, grad/param norm = 1.8910e-01, time/batch = 14.4693s	
32992/33250 (epoch 49.612), train_loss = 0.72300262, grad/param norm = 1.9338e-01, time/batch = 36.6385s	
32993/33250 (epoch 49.614), train_loss = 0.91654249, grad/param norm = 2.2259e-01, time/batch = 14.6119s	
32994/33250 (epoch 49.615), train_loss = 0.81037404, grad/param norm = 1.7799e-01, time/batch = 14.5934s	
32995/33250 (epoch 49.617), train_loss = 0.90530963, grad/param norm = 2.3082e-01, time/batch = 14.3816s	
32996/33250 (epoch 49.618), train_loss = 0.91038241, grad/param norm = 2.6646e-01, time/batch = 14.5325s	
32997/33250 (epoch 49.620), train_loss = 0.78297023, grad/param norm = 2.0091e-01, time/batch = 15.8504s	
32998/33250 (epoch 49.621), train_loss = 0.78145658, grad/param norm = 1.8648e-01, time/batch = 14.8936s	
32999/33250 (epoch 49.623), train_loss = 0.71108358, grad/param norm = 2.0567e-01, time/batch = 14.8968s	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch49.62_1.7674.t7	
33000/33250 (epoch 49.624), train_loss = 0.71331574, grad/param norm = 2.2724e-01, time/batch = 15.1925s	
33001/33250 (epoch 49.626), train_loss = 1.36263149, grad/param norm = 2.8462e-01, time/batch = 15.5116s	
33002/33250 (epoch 49.627), train_loss = 0.67726847, grad/param norm = 1.7533e-01, time/batch = 15.6226s	
33003/33250 (epoch 49.629), train_loss = 0.78954163, grad/param norm = 2.6461e-01, time/batch = 15.0528s	
33004/33250 (epoch 49.630), train_loss = 0.69158911, grad/param norm = 2.1084e-01, time/batch = 14.4687s	
33005/33250 (epoch 49.632), train_loss = 0.64910712, grad/param norm = 1.7857e-01, time/batch = 15.1000s	
33006/33250 (epoch 49.633), train_loss = 0.75754979, grad/param norm = 2.1139e-01, time/batch = 14.6223s	
33007/33250 (epoch 49.635), train_loss = 0.65470464, grad/param norm = 2.0459e-01, time/batch = 14.7180s	
33008/33250 (epoch 49.636), train_loss = 0.69579129, grad/param norm = 1.9251e-01, time/batch = 14.8680s	
33009/33250 (epoch 49.638), train_loss = 0.65736589, grad/param norm = 2.0744e-01, time/batch = 14.8642s	
33010/33250 (epoch 49.639), train_loss = 0.61725857, grad/param norm = 1.8651e-01, time/batch = 15.2733s	
33011/33250 (epoch 49.641), train_loss = 0.71080979, grad/param norm = 1.7814e-01, time/batch = 15.6215s	
33012/33250 (epoch 49.642), train_loss = 0.55161217, grad/param norm = 1.9209e-01, time/batch = 16.3703s	
33013/33250 (epoch 49.644), train_loss = 0.51452486, grad/param norm = 1.6275e-01, time/batch = 15.8813s	
33014/33250 (epoch 49.645), train_loss = 0.73343633, grad/param norm = 2.0978e-01, time/batch = 14.7976s	
33015/33250 (epoch 49.647), train_loss = 0.58546315, grad/param norm = 1.9350e-01, time/batch = 15.1067s	
33016/33250 (epoch 49.648), train_loss = 0.59385537, grad/param norm = 1.7178e-01, time/batch = 14.8631s	
33017/33250 (epoch 49.650), train_loss = 0.81080401, grad/param norm = 2.1672e-01, time/batch = 16.0164s	
33018/33250 (epoch 49.651), train_loss = 0.74963082, grad/param norm = 1.9249e-01, time/batch = 14.7061s	
33019/33250 (epoch 49.653), train_loss = 0.67425550, grad/param norm = 1.6618e-01, time/batch = 14.7889s	
33020/33250 (epoch 49.654), train_loss = 0.71589593, grad/param norm = 1.8182e-01, time/batch = 15.4418s	
33021/33250 (epoch 49.656), train_loss = 0.78108098, grad/param norm = 1.7368e-01, time/batch = 16.7566s	
33022/33250 (epoch 49.657), train_loss = 0.54022049, grad/param norm = 1.7321e-01, time/batch = 16.8015s	
33023/33250 (epoch 49.659), train_loss = 0.68768038, grad/param norm = 2.0491e-01, time/batch = 16.5530s	
33024/33250 (epoch 49.660), train_loss = 0.74014628, grad/param norm = 2.0141e-01, time/batch = 15.8027s	
33025/33250 (epoch 49.662), train_loss = 0.72702352, grad/param norm = 1.8571e-01, time/batch = 14.8667s	
33026/33250 (epoch 49.663), train_loss = 0.63717938, grad/param norm = 1.6987e-01, time/batch = 14.4700s	
33027/33250 (epoch 49.665), train_loss = 0.75349595, grad/param norm = 1.9682e-01, time/batch = 14.8812s	
33028/33250 (epoch 49.666), train_loss = 0.69047887, grad/param norm = 1.8993e-01, time/batch = 14.6203s	
33029/33250 (epoch 49.668), train_loss = 0.78594348, grad/param norm = 1.7668e-01, time/batch = 15.4543s	
33030/33250 (epoch 49.669), train_loss = 0.73602666, grad/param norm = 1.9034e-01, time/batch = 15.1199s	
33031/33250 (epoch 49.671), train_loss = 0.63333159, grad/param norm = 1.9540e-01, time/batch = 15.0359s	
33032/33250 (epoch 49.672), train_loss = 0.78334726, grad/param norm = 1.7981e-01, time/batch = 14.3929s	
33033/33250 (epoch 49.674), train_loss = 0.67512659, grad/param norm = 2.3224e-01, time/batch = 15.3946s	
33034/33250 (epoch 49.675), train_loss = 0.74160847, grad/param norm = 1.6652e-01, time/batch = 16.6472s	
33035/33250 (epoch 49.677), train_loss = 0.76337351, grad/param norm = 2.0262e-01, time/batch = 14.6054s	
33036/33250 (epoch 49.678), train_loss = 0.65525991, grad/param norm = 1.9126e-01, time/batch = 14.5493s	
33037/33250 (epoch 49.680), train_loss = 0.82392164, grad/param norm = 1.9285e-01, time/batch = 14.5502s	
33038/33250 (epoch 49.681), train_loss = 0.64110859, grad/param norm = 1.6348e-01, time/batch = 15.0473s	
33039/33250 (epoch 49.683), train_loss = 0.66422168, grad/param norm = 1.9578e-01, time/batch = 14.5393s	
33040/33250 (epoch 49.684), train_loss = 0.61001395, grad/param norm = 1.9176e-01, time/batch = 14.8460s	
33041/33250 (epoch 49.686), train_loss = 0.61768545, grad/param norm = 1.9352e-01, time/batch = 14.5306s	
33042/33250 (epoch 49.687), train_loss = 0.73658727, grad/param norm = 1.7929e-01, time/batch = 14.0385s	
33043/33250 (epoch 49.689), train_loss = 0.63376229, grad/param norm = 2.1112e-01, time/batch = 14.3950s	
33044/33250 (epoch 49.690), train_loss = 0.74279794, grad/param norm = 2.2585e-01, time/batch = 14.4873s	
33045/33250 (epoch 49.692), train_loss = 0.69228233, grad/param norm = 1.6941e-01, time/batch = 15.2120s	
33046/33250 (epoch 49.693), train_loss = 0.76339341, grad/param norm = 2.2400e-01, time/batch = 15.8727s	
33047/33250 (epoch 49.695), train_loss = 0.72515539, grad/param norm = 2.1984e-01, time/batch = 14.8087s	
33048/33250 (epoch 49.696), train_loss = 0.75577756, grad/param norm = 1.7952e-01, time/batch = 14.7044s	
33049/33250 (epoch 49.698), train_loss = 0.69754140, grad/param norm = 2.7126e-01, time/batch = 14.8563s	
33050/33250 (epoch 49.699), train_loss = 0.89684197, grad/param norm = 2.0428e-01, time/batch = 14.8817s	
33051/33250 (epoch 49.701), train_loss = 0.73498981, grad/param norm = 1.7987e-01, time/batch = 14.7866s	
33052/33250 (epoch 49.702), train_loss = 0.71200072, grad/param norm = 2.7838e-01, time/batch = 15.3039s	
33053/33250 (epoch 49.704), train_loss = 0.86631407, grad/param norm = 2.5629e-01, time/batch = 14.9645s	
33054/33250 (epoch 49.705), train_loss = 0.68988116, grad/param norm = 2.0879e-01, time/batch = 15.7681s	
33055/33250 (epoch 49.707), train_loss = 0.60195133, grad/param norm = 1.7244e-01, time/batch = 16.7927s	
33056/33250 (epoch 49.708), train_loss = 0.79371201, grad/param norm = 2.0981e-01, time/batch = 15.2834s	
33057/33250 (epoch 49.710), train_loss = 0.74702975, grad/param norm = 2.2556e-01, time/batch = 17.9645s	
33058/33250 (epoch 49.711), train_loss = 0.62993160, grad/param norm = 1.8532e-01, time/batch = 15.3055s	
33059/33250 (epoch 49.713), train_loss = 0.74270705, grad/param norm = 1.6906e-01, time/batch = 15.1241s	
33060/33250 (epoch 49.714), train_loss = 0.68220847, grad/param norm = 1.6515e-01, time/batch = 15.1086s	
33061/33250 (epoch 49.716), train_loss = 0.74527677, grad/param norm = 1.8971e-01, time/batch = 14.5500s	
33062/33250 (epoch 49.717), train_loss = 0.69945461, grad/param norm = 1.5843e-01, time/batch = 14.7711s	
33063/33250 (epoch 49.719), train_loss = 0.65228338, grad/param norm = 1.8225e-01, time/batch = 14.3790s	
33064/33250 (epoch 49.720), train_loss = 0.92646393, grad/param norm = 1.9091e-01, time/batch = 14.4643s	
33065/33250 (epoch 49.722), train_loss = 0.64268169, grad/param norm = 2.0983e-01, time/batch = 15.0551s	
33066/33250 (epoch 49.723), train_loss = 0.56948432, grad/param norm = 1.6253e-01, time/batch = 14.4737s	
33067/33250 (epoch 49.725), train_loss = 0.70940479, grad/param norm = 1.6670e-01, time/batch = 14.4937s	
33068/33250 (epoch 49.726), train_loss = 0.74029466, grad/param norm = 1.9611e-01, time/batch = 14.6470s	
33069/33250 (epoch 49.728), train_loss = 0.75529396, grad/param norm = 1.7902e-01, time/batch = 15.6300s	
33070/33250 (epoch 49.729), train_loss = 0.77219181, grad/param norm = 2.1271e-01, time/batch = 14.4401s	
33071/33250 (epoch 49.731), train_loss = 0.61657025, grad/param norm = 1.9247e-01, time/batch = 14.8796s	
33072/33250 (epoch 49.732), train_loss = 0.65052706, grad/param norm = 1.6680e-01, time/batch = 15.0202s	
33073/33250 (epoch 49.734), train_loss = 0.73699240, grad/param norm = 1.8124e-01, time/batch = 14.7666s	
33074/33250 (epoch 49.735), train_loss = 0.74701948, grad/param norm = 2.0965e-01, time/batch = 14.3072s	
33075/33250 (epoch 49.737), train_loss = 0.68509871, grad/param norm = 1.6094e-01, time/batch = 14.3085s	
33076/33250 (epoch 49.738), train_loss = 0.74477665, grad/param norm = 1.8159e-01, time/batch = 14.5358s	
33077/33250 (epoch 49.740), train_loss = 0.71919841, grad/param norm = 1.8037e-01, time/batch = 15.9684s	
33078/33250 (epoch 49.741), train_loss = 0.75968423, grad/param norm = 1.7326e-01, time/batch = 15.9660s	
33079/33250 (epoch 49.743), train_loss = 0.67274056, grad/param norm = 1.6932e-01, time/batch = 16.3071s	
33080/33250 (epoch 49.744), train_loss = 0.66684056, grad/param norm = 1.8912e-01, time/batch = 15.3693s	
33081/33250 (epoch 49.746), train_loss = 0.66507803, grad/param norm = 1.6964e-01, time/batch = 14.9462s	
33082/33250 (epoch 49.747), train_loss = 0.62694237, grad/param norm = 1.7768e-01, time/batch = 14.6924s	
33083/33250 (epoch 49.749), train_loss = 0.79758013, grad/param norm = 1.9495e-01, time/batch = 14.3823s	
33084/33250 (epoch 49.750), train_loss = 0.82362791, grad/param norm = 1.8465e-01, time/batch = 14.2994s	
33085/33250 (epoch 49.752), train_loss = 0.67817906, grad/param norm = 1.8028e-01, time/batch = 14.4592s	
33086/33250 (epoch 49.753), train_loss = 0.69972542, grad/param norm = 2.0253e-01, time/batch = 13.9751s	
33087/33250 (epoch 49.755), train_loss = 0.60993186, grad/param norm = 2.4925e-01, time/batch = 14.5449s	
33088/33250 (epoch 49.756), train_loss = 0.71566763, grad/param norm = 1.9113e-01, time/batch = 14.5681s	
33089/33250 (epoch 49.758), train_loss = 0.86226976, grad/param norm = 1.8776e-01, time/batch = 16.7265s	
33090/33250 (epoch 49.759), train_loss = 0.68876112, grad/param norm = 1.5984e-01, time/batch = 15.3049s	
33091/33250 (epoch 49.761), train_loss = 0.75983595, grad/param norm = 2.4268e-01, time/batch = 16.2214s	
33092/33250 (epoch 49.762), train_loss = 0.77833137, grad/param norm = 1.9537e-01, time/batch = 15.1231s	
33093/33250 (epoch 49.764), train_loss = 0.64857412, grad/param norm = 3.1776e-01, time/batch = 14.4373s	
33094/33250 (epoch 49.765), train_loss = 0.75886015, grad/param norm = 2.6805e-01, time/batch = 14.6410s	
33095/33250 (epoch 49.767), train_loss = 0.56798490, grad/param norm = 1.8722e-01, time/batch = 15.0427s	
33096/33250 (epoch 49.768), train_loss = 0.60668466, grad/param norm = 2.0278e-01, time/batch = 14.7743s	
33097/33250 (epoch 49.770), train_loss = 0.75440770, grad/param norm = 2.0808e-01, time/batch = 15.3577s	
33098/33250 (epoch 49.771), train_loss = 0.76983200, grad/param norm = 2.1208e-01, time/batch = 14.8926s	
33099/33250 (epoch 49.773), train_loss = 0.70242076, grad/param norm = 2.0237e-01, time/batch = 17.5328s	
33100/33250 (epoch 49.774), train_loss = 0.60563915, grad/param norm = 1.9574e-01, time/batch = 16.2608s	
33101/33250 (epoch 49.776), train_loss = 0.70146267, grad/param norm = 1.7953e-01, time/batch = 17.1138s	
33102/33250 (epoch 49.777), train_loss = 0.80021354, grad/param norm = 2.0039e-01, time/batch = 16.0494s	
33103/33250 (epoch 49.779), train_loss = 0.69751633, grad/param norm = 2.2011e-01, time/batch = 15.1071s	
33104/33250 (epoch 49.780), train_loss = 0.83379025, grad/param norm = 2.2880e-01, time/batch = 15.1192s	
33105/33250 (epoch 49.782), train_loss = 0.74162717, grad/param norm = 2.7645e-01, time/batch = 15.6350s	
33106/33250 (epoch 49.783), train_loss = 0.59475672, grad/param norm = 1.7802e-01, time/batch = 15.3657s	
33107/33250 (epoch 49.785), train_loss = 0.64150156, grad/param norm = 1.7738e-01, time/batch = 14.8625s	
33108/33250 (epoch 49.786), train_loss = 0.79500555, grad/param norm = 2.1161e-01, time/batch = 14.7146s	
33109/33250 (epoch 49.788), train_loss = 0.82975498, grad/param norm = 2.5259e-01, time/batch = 15.7690s	
33110/33250 (epoch 49.789), train_loss = 0.84034012, grad/param norm = 2.4695e-01, time/batch = 15.8606s	
33111/33250 (epoch 49.791), train_loss = 0.86174320, grad/param norm = 2.6381e-01, time/batch = 15.7053s	
33112/33250 (epoch 49.792), train_loss = 0.88893920, grad/param norm = 1.8590e-01, time/batch = 17.8802s	
33113/33250 (epoch 49.794), train_loss = 0.68017701, grad/param norm = 1.7208e-01, time/batch = 15.1477s	
33114/33250 (epoch 49.795), train_loss = 0.71567965, grad/param norm = 1.9820e-01, time/batch = 14.8905s	
33115/33250 (epoch 49.797), train_loss = 0.79099757, grad/param norm = 1.9631e-01, time/batch = 15.2454s	
33116/33250 (epoch 49.798), train_loss = 0.68486313, grad/param norm = 2.3064e-01, time/batch = 14.7964s	
33117/33250 (epoch 49.800), train_loss = 0.74901864, grad/param norm = 2.1400e-01, time/batch = 14.8904s	
33118/33250 (epoch 49.802), train_loss = 0.73665368, grad/param norm = 1.9236e-01, time/batch = 14.7907s	
33119/33250 (epoch 49.803), train_loss = 0.76696403, grad/param norm = 1.6430e-01, time/batch = 15.0176s	
33120/33250 (epoch 49.805), train_loss = 0.75478122, grad/param norm = 2.0685e-01, time/batch = 14.7808s	
33121/33250 (epoch 49.806), train_loss = 0.70714689, grad/param norm = 1.9434e-01, time/batch = 17.7137s	
33122/33250 (epoch 49.808), train_loss = 0.66447563, grad/param norm = 1.8789e-01, time/batch = 16.5388s	
33123/33250 (epoch 49.809), train_loss = 0.64209759, grad/param norm = 1.6844e-01, time/batch = 14.9040s	
33124/33250 (epoch 49.811), train_loss = 0.62211403, grad/param norm = 1.8822e-01, time/batch = 15.7226s	
33125/33250 (epoch 49.812), train_loss = 0.75074648, grad/param norm = 2.3858e-01, time/batch = 14.8054s	
33126/33250 (epoch 49.814), train_loss = 0.66692775, grad/param norm = 2.0232e-01, time/batch = 15.4514s	
33127/33250 (epoch 49.815), train_loss = 0.73087106, grad/param norm = 1.8922e-01, time/batch = 14.8023s	
33128/33250 (epoch 49.817), train_loss = 0.69029925, grad/param norm = 1.6664e-01, time/batch = 17.0193s	
33129/33250 (epoch 49.818), train_loss = 0.63728450, grad/param norm = 1.7454e-01, time/batch = 15.5192s	
33130/33250 (epoch 49.820), train_loss = 0.75481891, grad/param norm = 2.1254e-01, time/batch = 15.2344s	
33131/33250 (epoch 49.821), train_loss = 0.71807373, grad/param norm = 1.6047e-01, time/batch = 14.6411s	
33132/33250 (epoch 49.823), train_loss = 0.95666299, grad/param norm = 2.3509e-01, time/batch = 18.7017s	
33133/33250 (epoch 49.824), train_loss = 0.66791057, grad/param norm = 1.8892e-01, time/batch = 15.8170s	
33134/33250 (epoch 49.826), train_loss = 0.73566898, grad/param norm = 1.9700e-01, time/batch = 15.1417s	
33135/33250 (epoch 49.827), train_loss = 0.67786384, grad/param norm = 1.8704e-01, time/batch = 14.8676s	
33136/33250 (epoch 49.829), train_loss = 0.73008823, grad/param norm = 1.7688e-01, time/batch = 14.8900s	
33137/33250 (epoch 49.830), train_loss = 0.76068698, grad/param norm = 2.5761e-01, time/batch = 15.5337s	
33138/33250 (epoch 49.832), train_loss = 0.75328899, grad/param norm = 1.8683e-01, time/batch = 15.0848s	
33139/33250 (epoch 49.833), train_loss = 0.71334759, grad/param norm = 1.8054e-01, time/batch = 15.3481s	
33140/33250 (epoch 49.835), train_loss = 0.66216230, grad/param norm = 2.3591e-01, time/batch = 15.7573s	
33141/33250 (epoch 49.836), train_loss = 0.70172842, grad/param norm = 1.6718e-01, time/batch = 14.8754s	
33142/33250 (epoch 49.838), train_loss = 0.72817006, grad/param norm = 1.6362e-01, time/batch = 17.2889s	
33143/33250 (epoch 49.839), train_loss = 0.69625075, grad/param norm = 1.8330e-01, time/batch = 16.2263s	
33144/33250 (epoch 49.841), train_loss = 0.66752668, grad/param norm = 1.6521e-01, time/batch = 18.1271s	
33145/33250 (epoch 49.842), train_loss = 0.84444125, grad/param norm = 1.9869e-01, time/batch = 16.2961s	
33146/33250 (epoch 49.844), train_loss = 0.79511954, grad/param norm = 2.1748e-01, time/batch = 14.3104s	
33147/33250 (epoch 49.845), train_loss = 0.87510152, grad/param norm = 2.2195e-01, time/batch = 14.7212s	
33148/33250 (epoch 49.847), train_loss = 0.79476812, grad/param norm = 1.7166e-01, time/batch = 15.0066s	
33149/33250 (epoch 49.848), train_loss = 0.89099067, grad/param norm = 2.1893e-01, time/batch = 14.6293s	
33150/33250 (epoch 49.850), train_loss = 0.79785906, grad/param norm = 1.7772e-01, time/batch = 14.6276s	
33151/33250 (epoch 49.851), train_loss = 0.63147580, grad/param norm = 2.0690e-01, time/batch = 14.4626s	
33152/33250 (epoch 49.853), train_loss = 0.70964668, grad/param norm = 2.1633e-01, time/batch = 14.4715s	
33153/33250 (epoch 49.854), train_loss = 0.66865974, grad/param norm = 1.9883e-01, time/batch = 16.2182s	
33154/33250 (epoch 49.856), train_loss = 0.66109526, grad/param norm = 1.9054e-01, time/batch = 18.3729s	
33155/33250 (epoch 49.857), train_loss = 0.58635479, grad/param norm = 1.6029e-01, time/batch = 15.2914s	
33156/33250 (epoch 49.859), train_loss = 0.69058756, grad/param norm = 2.0473e-01, time/batch = 15.8871s	
33157/33250 (epoch 49.860), train_loss = 0.77002032, grad/param norm = 1.8455e-01, time/batch = 10.5748s	
33158/33250 (epoch 49.862), train_loss = 0.66836837, grad/param norm = 1.9589e-01, time/batch = 0.6771s	
33159/33250 (epoch 49.863), train_loss = 0.67224297, grad/param norm = 2.1725e-01, time/batch = 0.6726s	
33160/33250 (epoch 49.865), train_loss = 0.73360884, grad/param norm = 2.1637e-01, time/batch = 0.6696s	
33161/33250 (epoch 49.866), train_loss = 0.65709966, grad/param norm = 1.8375e-01, time/batch = 0.6706s	
33162/33250 (epoch 49.868), train_loss = 0.73266456, grad/param norm = 2.2890e-01, time/batch = 0.6582s	
33163/33250 (epoch 49.869), train_loss = 0.73393006, grad/param norm = 1.8774e-01, time/batch = 0.6613s	
33164/33250 (epoch 49.871), train_loss = 0.59336929, grad/param norm = 1.5604e-01, time/batch = 0.6614s	
33165/33250 (epoch 49.872), train_loss = 0.77322639, grad/param norm = 2.2484e-01, time/batch = 0.9260s	
33166/33250 (epoch 49.874), train_loss = 0.66984031, grad/param norm = 1.9451e-01, time/batch = 0.9689s	
33167/33250 (epoch 49.875), train_loss = 0.61699331, grad/param norm = 2.5696e-01, time/batch = 0.9939s	
33168/33250 (epoch 49.877), train_loss = 0.81534338, grad/param norm = 2.1758e-01, time/batch = 0.9713s	
33169/33250 (epoch 49.878), train_loss = 0.73257393, grad/param norm = 1.8249e-01, time/batch = 0.9568s	
33170/33250 (epoch 49.880), train_loss = 0.71285866, grad/param norm = 2.1350e-01, time/batch = 1.5838s	
33171/33250 (epoch 49.881), train_loss = 0.80502447, grad/param norm = 2.0293e-01, time/batch = 1.8092s	
33172/33250 (epoch 49.883), train_loss = 0.76319784, grad/param norm = 1.9841e-01, time/batch = 2.7071s	
33173/33250 (epoch 49.884), train_loss = 0.79657608, grad/param norm = 1.8850e-01, time/batch = 14.5501s	
33174/33250 (epoch 49.886), train_loss = 0.67199927, grad/param norm = 1.7576e-01, time/batch = 14.6251s	
33175/33250 (epoch 49.887), train_loss = 0.68209782, grad/param norm = 1.8494e-01, time/batch = 14.6262s	
33176/33250 (epoch 49.889), train_loss = 0.68477329, grad/param norm = 1.4951e-01, time/batch = 14.4726s	
33177/33250 (epoch 49.890), train_loss = 0.55089984, grad/param norm = 1.4577e-01, time/batch = 14.3872s	
33178/33250 (epoch 49.892), train_loss = 0.76364951, grad/param norm = 1.8110e-01, time/batch = 15.2948s	
33179/33250 (epoch 49.893), train_loss = 0.75493060, grad/param norm = 2.0225e-01, time/batch = 14.6999s	
33180/33250 (epoch 49.895), train_loss = 0.67664968, grad/param norm = 2.0612e-01, time/batch = 14.8106s	
33181/33250 (epoch 49.896), train_loss = 0.77503241, grad/param norm = 1.7959e-01, time/batch = 15.4796s	
33182/33250 (epoch 49.898), train_loss = 0.71528377, grad/param norm = 2.0510e-01, time/batch = 14.6218s	
33183/33250 (epoch 49.899), train_loss = 0.68727325, grad/param norm = 1.8682e-01, time/batch = 14.6956s	
33184/33250 (epoch 49.901), train_loss = 0.59678084, grad/param norm = 1.5686e-01, time/batch = 14.3589s	
33185/33250 (epoch 49.902), train_loss = 0.68216796, grad/param norm = 2.5137e-01, time/batch = 14.3036s	
33186/33250 (epoch 49.904), train_loss = 0.66834587, grad/param norm = 2.7412e-01, time/batch = 15.4677s	
33187/33250 (epoch 49.905), train_loss = 0.68639832, grad/param norm = 1.7006e-01, time/batch = 14.6946s	
33188/33250 (epoch 49.907), train_loss = 0.67041494, grad/param norm = 1.9848e-01, time/batch = 14.7740s	
33189/33250 (epoch 49.908), train_loss = 0.70609183, grad/param norm = 1.6001e-01, time/batch = 15.4720s	
33190/33250 (epoch 49.910), train_loss = 0.80254516, grad/param norm = 2.6001e-01, time/batch = 17.4696s	
33191/33250 (epoch 49.911), train_loss = 0.63414448, grad/param norm = 1.8930e-01, time/batch = 15.6198s	
33192/33250 (epoch 49.913), train_loss = 0.65526505, grad/param norm = 1.5840e-01, time/batch = 14.8122s	
33193/33250 (epoch 49.914), train_loss = 0.59385094, grad/param norm = 1.7391e-01, time/batch = 14.9472s	
33194/33250 (epoch 49.916), train_loss = 0.61378381, grad/param norm = 1.6913e-01, time/batch = 14.6346s	
33195/33250 (epoch 49.917), train_loss = 0.72381858, grad/param norm = 1.4370e-01, time/batch = 14.8706s	
33196/33250 (epoch 49.919), train_loss = 0.64124004, grad/param norm = 2.1948e-01, time/batch = 14.5518s	
33197/33250 (epoch 49.920), train_loss = 0.73120105, grad/param norm = 2.0874e-01, time/batch = 14.3921s	
33198/33250 (epoch 49.922), train_loss = 0.73129351, grad/param norm = 2.0177e-01, time/batch = 14.7116s	
33199/33250 (epoch 49.923), train_loss = 0.70243542, grad/param norm = 1.8747e-01, time/batch = 14.7040s	
33200/33250 (epoch 49.925), train_loss = 0.70121642, grad/param norm = 1.9350e-01, time/batch = 14.8600s	
33201/33250 (epoch 49.926), train_loss = 0.66601087, grad/param norm = 1.6912e-01, time/batch = 16.4660s	
33202/33250 (epoch 49.928), train_loss = 0.69805130, grad/param norm = 1.7966e-01, time/batch = 14.7789s	
33203/33250 (epoch 49.929), train_loss = 0.63473573, grad/param norm = 1.4571e-01, time/batch = 14.8896s	
33204/33250 (epoch 49.931), train_loss = 0.78954082, grad/param norm = 2.1718e-01, time/batch = 14.7239s	
33205/33250 (epoch 49.932), train_loss = 0.63042420, grad/param norm = 1.7083e-01, time/batch = 14.4654s	
33206/33250 (epoch 49.934), train_loss = 0.63266112, grad/param norm = 1.4793e-01, time/batch = 14.3840s	
33207/33250 (epoch 49.935), train_loss = 0.68844127, grad/param norm = 2.0140e-01, time/batch = 14.6936s	
33208/33250 (epoch 49.937), train_loss = 0.65681533, grad/param norm = 1.9455e-01, time/batch = 14.9567s	
33209/33250 (epoch 49.938), train_loss = 0.68887144, grad/param norm = 2.3534e-01, time/batch = 14.6370s	
33210/33250 (epoch 49.940), train_loss = 0.68054194, grad/param norm = 1.8909e-01, time/batch = 14.6267s	
33211/33250 (epoch 49.941), train_loss = 0.73896982, grad/param norm = 1.8710e-01, time/batch = 15.6135s	
33212/33250 (epoch 49.943), train_loss = 0.82918632, grad/param norm = 1.9899e-01, time/batch = 15.5508s	
33213/33250 (epoch 49.944), train_loss = 0.68558186, grad/param norm = 1.8193e-01, time/batch = 15.2265s	
33214/33250 (epoch 49.946), train_loss = 0.76514518, grad/param norm = 2.0847e-01, time/batch = 14.5751s	
33215/33250 (epoch 49.947), train_loss = 0.62157260, grad/param norm = 1.7101e-01, time/batch = 15.1312s	
33216/33250 (epoch 49.949), train_loss = 0.77879930, grad/param norm = 2.2525e-01, time/batch = 14.4524s	
33217/33250 (epoch 49.950), train_loss = 0.78417227, grad/param norm = 1.8535e-01, time/batch = 14.3844s	
33218/33250 (epoch 49.952), train_loss = 0.73565749, grad/param norm = 2.0851e-01, time/batch = 14.3025s	
33219/33250 (epoch 49.953), train_loss = 0.74168236, grad/param norm = 2.0717e-01, time/batch = 14.6212s	
33220/33250 (epoch 49.955), train_loss = 0.78059898, grad/param norm = 1.8605e-01, time/batch = 14.6060s	
33221/33250 (epoch 49.956), train_loss = 0.70144721, grad/param norm = 2.3921e-01, time/batch = 14.5510s	
33222/33250 (epoch 49.958), train_loss = 0.67896429, grad/param norm = 1.7112e-01, time/batch = 15.5301s	
33223/33250 (epoch 49.959), train_loss = 0.69108118, grad/param norm = 1.8122e-01, time/batch = 15.0596s	
33224/33250 (epoch 49.961), train_loss = 0.90630628, grad/param norm = 2.5429e-01, time/batch = 15.4690s	
33225/33250 (epoch 49.962), train_loss = 0.70979620, grad/param norm = 1.9617e-01, time/batch = 15.2059s	
33226/33250 (epoch 49.964), train_loss = 0.81760807, grad/param norm = 1.9254e-01, time/batch = 15.6349s	
33227/33250 (epoch 49.965), train_loss = 0.77383390, grad/param norm = 1.9523e-01, time/batch = 14.6261s	
33228/33250 (epoch 49.967), train_loss = 0.71028712, grad/param norm = 2.3556e-01, time/batch = 14.4651s	
33229/33250 (epoch 49.968), train_loss = 0.80996116, grad/param norm = 1.6824e-01, time/batch = 14.9615s	
33230/33250 (epoch 49.970), train_loss = 0.88361401, grad/param norm = 2.3266e-01, time/batch = 14.7151s	
33231/33250 (epoch 49.971), train_loss = 0.86313572, grad/param norm = 2.1328e-01, time/batch = 23.4726s	
33232/33250 (epoch 49.973), train_loss = 0.69017697, grad/param norm = 1.8067e-01, time/batch = 19.8948s	
33233/33250 (epoch 49.974), train_loss = 0.80305886, grad/param norm = 2.3500e-01, time/batch = 16.2179s	
33234/33250 (epoch 49.976), train_loss = 0.69224557, grad/param norm = 1.7890e-01, time/batch = 15.0375s	
33235/33250 (epoch 49.977), train_loss = 0.72420641, grad/param norm = 1.7818e-01, time/batch = 15.3845s	
33236/33250 (epoch 49.979), train_loss = 0.79031421, grad/param norm = 2.2666e-01, time/batch = 15.8067s	
33237/33250 (epoch 49.980), train_loss = 0.78214774, grad/param norm = 1.9852e-01, time/batch = 14.8042s	
33238/33250 (epoch 49.982), train_loss = 0.71019844, grad/param norm = 1.6961e-01, time/batch = 15.1220s	
33239/33250 (epoch 49.983), train_loss = 0.77448095, grad/param norm = 2.2938e-01, time/batch = 15.7500s	
33240/33250 (epoch 49.985), train_loss = 0.68821317, grad/param norm = 1.8052e-01, time/batch = 14.5325s	
33241/33250 (epoch 49.986), train_loss = 0.77450376, grad/param norm = 1.8079e-01, time/batch = 15.3644s	
33242/33250 (epoch 49.988), train_loss = 0.81997933, grad/param norm = 1.8736e-01, time/batch = 14.7052s	
33243/33250 (epoch 49.989), train_loss = 0.80866377, grad/param norm = 1.9316e-01, time/batch = 15.1115s	
33244/33250 (epoch 49.991), train_loss = 0.79668517, grad/param norm = 2.0095e-01, time/batch = 16.3978s	
33245/33250 (epoch 49.992), train_loss = 0.71088155, grad/param norm = 1.7876e-01, time/batch = 16.3852s	
33246/33250 (epoch 49.994), train_loss = 0.67847531, grad/param norm = 1.8233e-01, time/batch = 15.2921s	
33247/33250 (epoch 49.995), train_loss = 0.69669780, grad/param norm = 3.2528e-01, time/batch = 17.2162s	
33248/33250 (epoch 49.997), train_loss = 0.57212239, grad/param norm = 1.6505e-01, time/batch = 14.7223s	
33249/33250 (epoch 49.998), train_loss = 0.73866679, grad/param norm = 1.7930e-01, time/batch = 15.0265s	
decayed learning rate by a factor 0.97 to 0.00057368183755432	
evaluating loss over split index 2	
1/36...	
2/36...	
3/36...	
4/36...	
5/36...	
6/36...	
7/36...	
8/36...	
9/36...	
10/36...	
11/36...	
12/36...	
13/36...	
14/36...	
15/36...	
16/36...	
17/36...	
18/36...	
19/36...	
20/36...	
21/36...	
22/36...	
23/36...	
24/36...	
25/36...	
26/36...	
27/36...	
28/36...	
29/36...	
30/36...	
31/36...	
32/36...	
33/36...	
34/36...	
35/36...	
36/36...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasakennedy_epoch50.00_1.7783.t7	
33250/33250 (epoch 50.000), train_loss = 0.76287780, grad/param norm = 2.1976e-01, time/batch = 15.0190s	

real	7297m29.076s
user	7235m58.608s
sys	6m38.464s
