tput: No value for $TERM and no -T specified
vocab.t7 or data.t7 detected as stale. Re-running preprocessing...	
one-time setup: preprocessing input text file /home/ubuntu/scimirrorbot/dat/training/input.txt...	
loading text file...	
creating vocabulary mapping...	
putting data into tensor...	
saving /home/ubuntu/scimirrorbot/dat/training/vocab.t7	
saving /home/ubuntu/scimirrorbot/dat/training/data.t7	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 521, val: 28, test: 0	
vocab size: 136	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 285832	
cloning rnn	
cloning criterion	
1/26050 (epoch 0.002), train_loss = 4.92163106, grad/param norm = 5.6071e-01, time/batch = 0.7101s	
2/26050 (epoch 0.004), train_loss = 4.59126397, grad/param norm = 1.6650e+00, time/batch = 0.6440s	
3/26050 (epoch 0.006), train_loss = 3.79198034, grad/param norm = 1.1353e+00, time/batch = 0.6751s	
4/26050 (epoch 0.008), train_loss = 3.50360345, grad/param norm = 7.6045e-01, time/batch = 0.6804s	
5/26050 (epoch 0.010), train_loss = 3.69571659, grad/param norm = 9.5982e-01, time/batch = 0.6393s	
6/26050 (epoch 0.012), train_loss = 3.62391407, grad/param norm = 5.7481e-01, time/batch = 0.6400s	
7/26050 (epoch 0.013), train_loss = 3.67711362, grad/param norm = 8.3643e-01, time/batch = 0.6379s	
8/26050 (epoch 0.015), train_loss = 3.46286064, grad/param norm = 8.0972e-01, time/batch = 0.6400s	
9/26050 (epoch 0.017), train_loss = 3.50489147, grad/param norm = 8.8169e-01, time/batch = 0.6378s	
10/26050 (epoch 0.019), train_loss = 3.49390191, grad/param norm = 5.1986e-01, time/batch = 0.6426s	
11/26050 (epoch 0.021), train_loss = 3.40492143, grad/param norm = 6.8335e-01, time/batch = 0.6377s	
12/26050 (epoch 0.023), train_loss = 3.49554823, grad/param norm = 8.5484e-01, time/batch = 0.6387s	
13/26050 (epoch 0.025), train_loss = 3.39006821, grad/param norm = 7.7387e-01, time/batch = 0.6422s	
14/26050 (epoch 0.027), train_loss = 3.54607690, grad/param norm = 8.9881e-01, time/batch = 0.6374s	
15/26050 (epoch 0.029), train_loss = 3.39956436, grad/param norm = 8.4834e-01, time/batch = 0.6400s	
16/26050 (epoch 0.031), train_loss = 3.42923414, grad/param norm = 6.7008e-01, time/batch = 0.6384s	
17/26050 (epoch 0.033), train_loss = 3.40206496, grad/param norm = 5.0876e-01, time/batch = 0.6402s	
18/26050 (epoch 0.035), train_loss = 3.60172930, grad/param norm = 7.3693e-01, time/batch = 0.6443s	
19/26050 (epoch 0.036), train_loss = 3.52850047, grad/param norm = 7.3864e-01, time/batch = 0.6816s	
20/26050 (epoch 0.038), train_loss = 3.42953049, grad/param norm = 6.2132e-01, time/batch = 0.6578s	
21/26050 (epoch 0.040), train_loss = 3.42214345, grad/param norm = 5.7267e-01, time/batch = 0.6425s	
22/26050 (epoch 0.042), train_loss = 3.49207636, grad/param norm = 5.5788e-01, time/batch = 0.6376s	
23/26050 (epoch 0.044), train_loss = 3.46997238, grad/param norm = 5.8632e-01, time/batch = 0.6364s	
24/26050 (epoch 0.046), train_loss = 3.62522699, grad/param norm = 7.5255e-01, time/batch = 0.6387s	
25/26050 (epoch 0.048), train_loss = 3.37992367, grad/param norm = 7.1668e-01, time/batch = 0.6388s	
26/26050 (epoch 0.050), train_loss = 3.30069825, grad/param norm = 6.8889e-01, time/batch = 0.6388s	
27/26050 (epoch 0.052), train_loss = 3.58785652, grad/param norm = 7.2630e-01, time/batch = 0.6370s	
28/26050 (epoch 0.054), train_loss = 3.41622591, grad/param norm = 7.0446e-01, time/batch = 0.6370s	
29/26050 (epoch 0.056), train_loss = 3.46914531, grad/param norm = 7.0462e-01, time/batch = 0.6383s	
30/26050 (epoch 0.058), train_loss = 3.47767374, grad/param norm = 6.0513e-01, time/batch = 0.6380s	
31/26050 (epoch 0.060), train_loss = 3.39864310, grad/param norm = 5.6617e-01, time/batch = 0.6385s	
32/26050 (epoch 0.061), train_loss = 3.60421356, grad/param norm = 8.0735e-01, time/batch = 0.6384s	
33/26050 (epoch 0.063), train_loss = 3.47419142, grad/param norm = 5.2138e-01, time/batch = 0.6428s	
34/26050 (epoch 0.065), train_loss = 3.53837030, grad/param norm = 5.9773e-01, time/batch = 0.6421s	
35/26050 (epoch 0.067), train_loss = 3.43084214, grad/param norm = 6.1525e-01, time/batch = 0.6381s	
36/26050 (epoch 0.069), train_loss = 3.49259581, grad/param norm = 5.6059e-01, time/batch = 0.6381s	
37/26050 (epoch 0.071), train_loss = 3.51750057, grad/param norm = 5.6578e-01, time/batch = 0.6388s	
38/26050 (epoch 0.073), train_loss = 3.62099008, grad/param norm = 6.5942e-01, time/batch = 0.6375s	
39/26050 (epoch 0.075), train_loss = 3.53999933, grad/param norm = 6.0516e-01, time/batch = 0.6395s	
40/26050 (epoch 0.077), train_loss = 3.47727117, grad/param norm = 6.5047e-01, time/batch = 0.6545s	
41/26050 (epoch 0.079), train_loss = 3.62318795, grad/param norm = 7.2697e-01, time/batch = 0.6438s	
42/26050 (epoch 0.081), train_loss = 3.47745657, grad/param norm = 7.8877e-01, time/batch = 0.6392s	
43/26050 (epoch 0.083), train_loss = 3.46162560, grad/param norm = 6.1824e-01, time/batch = 0.6373s	
44/26050 (epoch 0.084), train_loss = 3.51741803, grad/param norm = 6.2304e-01, time/batch = 0.6369s	
45/26050 (epoch 0.086), train_loss = 3.52911602, grad/param norm = 5.8381e-01, time/batch = 0.6374s	
46/26050 (epoch 0.088), train_loss = 3.46228013, grad/param norm = 6.1317e-01, time/batch = 0.6362s	
47/26050 (epoch 0.090), train_loss = 3.46168945, grad/param norm = 6.3015e-01, time/batch = 0.6386s	
48/26050 (epoch 0.092), train_loss = 3.45602105, grad/param norm = 6.6627e-01, time/batch = 0.6371s	
49/26050 (epoch 0.094), train_loss = 3.48894115, grad/param norm = 6.2498e-01, time/batch = 0.6390s	
50/26050 (epoch 0.096), train_loss = 3.36251985, grad/param norm = 6.9575e-01, time/batch = 0.6402s	
51/26050 (epoch 0.098), train_loss = 3.47112302, grad/param norm = 5.6802e-01, time/batch = 0.6379s	
52/26050 (epoch 0.100), train_loss = 3.55160514, grad/param norm = 7.3681e-01, time/batch = 0.6364s	
53/26050 (epoch 0.102), train_loss = 3.59340439, grad/param norm = 5.1555e-01, time/batch = 0.6400s	
54/26050 (epoch 0.104), train_loss = 3.49118541, grad/param norm = 6.7687e-01, time/batch = 0.6530s	
55/26050 (epoch 0.106), train_loss = 3.43381660, grad/param norm = 7.6563e-01, time/batch = 0.6811s	
56/26050 (epoch 0.107), train_loss = 3.42805596, grad/param norm = 4.8328e-01, time/batch = 0.6487s	
57/26050 (epoch 0.109), train_loss = 3.49533909, grad/param norm = 6.4143e-01, time/batch = 0.6388s	
58/26050 (epoch 0.111), train_loss = 3.59287329, grad/param norm = 6.3598e-01, time/batch = 0.6374s	
59/26050 (epoch 0.113), train_loss = 3.34472756, grad/param norm = 7.5812e-01, time/batch = 0.6386s	
60/26050 (epoch 0.115), train_loss = 3.56205549, grad/param norm = 6.4092e-01, time/batch = 0.6379s	
61/26050 (epoch 0.117), train_loss = 3.65056121, grad/param norm = 7.4935e-01, time/batch = 0.6375s	
62/26050 (epoch 0.119), train_loss = 3.52502894, grad/param norm = 6.3947e-01, time/batch = 0.6377s	
63/26050 (epoch 0.121), train_loss = 3.51054062, grad/param norm = 5.5005e-01, time/batch = 0.6368s	
64/26050 (epoch 0.123), train_loss = 3.45658377, grad/param norm = 5.1487e-01, time/batch = 0.6435s	
65/26050 (epoch 0.125), train_loss = 3.47215758, grad/param norm = 7.2652e-01, time/batch = 0.6389s	
66/26050 (epoch 0.127), train_loss = 3.46610215, grad/param norm = 5.2019e-01, time/batch = 0.6377s	
67/26050 (epoch 0.129), train_loss = 3.58459649, grad/param norm = 6.3838e-01, time/batch = 0.6374s	
68/26050 (epoch 0.131), train_loss = 3.48555012, grad/param norm = 5.7784e-01, time/batch = 0.6364s	
69/26050 (epoch 0.132), train_loss = 3.48433494, grad/param norm = 6.5934e-01, time/batch = 0.6365s	
70/26050 (epoch 0.134), train_loss = 3.62201226, grad/param norm = 6.9942e-01, time/batch = 0.6723s	
71/26050 (epoch 0.136), train_loss = 3.50696305, grad/param norm = 6.0453e-01, time/batch = 0.6707s	
72/26050 (epoch 0.138), train_loss = 3.45682655, grad/param norm = 5.4977e-01, time/batch = 0.6424s	
73/26050 (epoch 0.140), train_loss = 3.50547495, grad/param norm = 4.6156e-01, time/batch = 0.6378s	
74/26050 (epoch 0.142), train_loss = 3.46365599, grad/param norm = 5.4735e-01, time/batch = 0.6371s	
75/26050 (epoch 0.144), train_loss = 3.50480263, grad/param norm = 4.7344e-01, time/batch = 0.6387s	
76/26050 (epoch 0.146), train_loss = 3.41739550, grad/param norm = 4.3496e-01, time/batch = 0.6384s	
77/26050 (epoch 0.148), train_loss = 3.59538184, grad/param norm = 5.3148e-01, time/batch = 0.6375s	
78/26050 (epoch 0.150), train_loss = 3.48510698, grad/param norm = 7.8245e-01, time/batch = 0.6392s	
79/26050 (epoch 0.152), train_loss = 3.60745203, grad/param norm = 9.4964e-01, time/batch = 0.6464s	
80/26050 (epoch 0.154), train_loss = 3.58400125, grad/param norm = 5.9642e-01, time/batch = 0.6521s	
81/26050 (epoch 0.155), train_loss = 3.48099427, grad/param norm = 4.6997e-01, time/batch = 0.6561s	
82/26050 (epoch 0.157), train_loss = 3.55430711, grad/param norm = 4.8448e-01, time/batch = 0.6426s	
83/26050 (epoch 0.159), train_loss = 3.45880004, grad/param norm = 4.4668e-01, time/batch = 0.6454s	
84/26050 (epoch 0.161), train_loss = 3.43312988, grad/param norm = 5.4970e-01, time/batch = 0.6379s	
85/26050 (epoch 0.163), train_loss = 3.43473276, grad/param norm = 5.9213e-01, time/batch = 0.6463s	
86/26050 (epoch 0.165), train_loss = 3.49204101, grad/param norm = 7.4425e-01, time/batch = 0.6393s	
87/26050 (epoch 0.167), train_loss = 3.41067114, grad/param norm = 7.4167e-01, time/batch = 0.6399s	
88/26050 (epoch 0.169), train_loss = 3.61490753, grad/param norm = 7.0220e-01, time/batch = 0.6397s	
89/26050 (epoch 0.171), train_loss = 3.50292357, grad/param norm = 4.4009e-01, time/batch = 0.6400s	
90/26050 (epoch 0.173), train_loss = 3.43354607, grad/param norm = 4.4231e-01, time/batch = 0.6372s	
91/26050 (epoch 0.175), train_loss = 3.56390885, grad/param norm = 6.8486e-01, time/batch = 0.6499s	
92/26050 (epoch 0.177), train_loss = 3.39883693, grad/param norm = 6.0457e-01, time/batch = 0.6404s	
93/26050 (epoch 0.179), train_loss = 3.50067375, grad/param norm = 7.3225e-01, time/batch = 0.6382s	
94/26050 (epoch 0.180), train_loss = 3.48403944, grad/param norm = 9.0968e-01, time/batch = 0.6397s	
95/26050 (epoch 0.182), train_loss = 3.55947537, grad/param norm = 8.8935e-01, time/batch = 0.6435s	
96/26050 (epoch 0.184), train_loss = 3.52462685, grad/param norm = 5.6140e-01, time/batch = 0.6396s	
97/26050 (epoch 0.186), train_loss = 3.50859287, grad/param norm = 4.6637e-01, time/batch = 0.6400s	
98/26050 (epoch 0.188), train_loss = 3.52274351, grad/param norm = 5.8470e-01, time/batch = 0.6405s	
99/26050 (epoch 0.190), train_loss = 3.45468963, grad/param norm = 4.4528e-01, time/batch = 0.6379s	
100/26050 (epoch 0.192), train_loss = 3.52578559, grad/param norm = 5.1139e-01, time/batch = 0.6374s	
101/26050 (epoch 0.194), train_loss = 3.35001356, grad/param norm = 5.3103e-01, time/batch = 0.6394s	
102/26050 (epoch 0.196), train_loss = 3.39975077, grad/param norm = 5.9756e-01, time/batch = 0.6391s	
103/26050 (epoch 0.198), train_loss = 3.32101589, grad/param norm = 6.3451e-01, time/batch = 0.6400s	
104/26050 (epoch 0.200), train_loss = 3.35700080, grad/param norm = 5.1327e-01, time/batch = 0.6397s	
105/26050 (epoch 0.202), train_loss = 3.48101606, grad/param norm = 1.1128e+00, time/batch = 0.6470s	
106/26050 (epoch 0.203), train_loss = 3.43605382, grad/param norm = 1.3463e+00, time/batch = 0.6783s	
107/26050 (epoch 0.205), train_loss = 3.32946759, grad/param norm = 5.9178e-01, time/batch = 0.6496s	
108/26050 (epoch 0.207), train_loss = 3.49500332, grad/param norm = 8.0887e-01, time/batch = 0.6419s	
109/26050 (epoch 0.209), train_loss = 3.41449291, grad/param norm = 1.0083e+00, time/batch = 0.6429s	
110/26050 (epoch 0.211), train_loss = 3.34858196, grad/param norm = 6.0239e-01, time/batch = 0.6393s	
111/26050 (epoch 0.213), train_loss = 3.43214502, grad/param norm = 5.4317e-01, time/batch = 0.6444s	
112/26050 (epoch 0.215), train_loss = 3.41926732, grad/param norm = 4.3457e-01, time/batch = 0.6388s	
113/26050 (epoch 0.217), train_loss = 3.31827781, grad/param norm = 5.0650e-01, time/batch = 0.6380s	
114/26050 (epoch 0.219), train_loss = 3.22072676, grad/param norm = 3.8303e-01, time/batch = 0.6377s	
115/26050 (epoch 0.221), train_loss = 3.31886892, grad/param norm = 6.5673e-01, time/batch = 0.6382s	
116/26050 (epoch 0.223), train_loss = 3.42712466, grad/param norm = 5.3991e-01, time/batch = 0.6383s	
117/26050 (epoch 0.225), train_loss = 3.49494375, grad/param norm = 2.0519e+00, time/batch = 0.6382s	
118/26050 (epoch 0.226), train_loss = 3.60872114, grad/param norm = 1.2554e+00, time/batch = 0.6400s	
119/26050 (epoch 0.228), train_loss = 3.36292880, grad/param norm = 5.3763e-01, time/batch = 0.6393s	
120/26050 (epoch 0.230), train_loss = 3.19304811, grad/param norm = 3.5395e-01, time/batch = 0.6385s	
121/26050 (epoch 0.232), train_loss = 3.31632955, grad/param norm = 5.2047e-01, time/batch = 0.6735s	
122/26050 (epoch 0.234), train_loss = 3.30221553, grad/param norm = 5.1925e-01, time/batch = 0.6707s	
123/26050 (epoch 0.236), train_loss = 3.21616735, grad/param norm = 7.6009e-01, time/batch = 0.6391s	
124/26050 (epoch 0.238), train_loss = 3.38106679, grad/param norm = 1.0044e+00, time/batch = 0.6392s	
125/26050 (epoch 0.240), train_loss = 3.22685131, grad/param norm = 1.0547e+00, time/batch = 0.6399s	
126/26050 (epoch 0.242), train_loss = 3.36956165, grad/param norm = 8.3303e-01, time/batch = 0.6405s	
127/26050 (epoch 0.244), train_loss = 3.30376597, grad/param norm = 6.8121e-01, time/batch = 0.6443s	
128/26050 (epoch 0.246), train_loss = 3.31525917, grad/param norm = 5.3503e-01, time/batch = 0.6402s	
129/26050 (epoch 0.248), train_loss = 3.34138828, grad/param norm = 4.7597e-01, time/batch = 0.6417s	
130/26050 (epoch 0.250), train_loss = 3.24437774, grad/param norm = 4.7683e-01, time/batch = 0.6398s	
131/26050 (epoch 0.251), train_loss = 3.22356130, grad/param norm = 9.7513e-01, time/batch = 0.6405s	
132/26050 (epoch 0.253), train_loss = 3.23532364, grad/param norm = 1.5648e+00, time/batch = 0.6412s	
133/26050 (epoch 0.255), train_loss = 3.51246965, grad/param norm = 1.1608e+00, time/batch = 0.6410s	
134/26050 (epoch 0.257), train_loss = 3.11243331, grad/param norm = 4.3539e-01, time/batch = 0.6412s	
135/26050 (epoch 0.259), train_loss = 3.15821033, grad/param norm = 7.5427e-01, time/batch = 0.6399s	
136/26050 (epoch 0.261), train_loss = 3.31451462, grad/param norm = 7.6239e-01, time/batch = 0.6522s	
137/26050 (epoch 0.263), train_loss = 3.20784334, grad/param norm = 5.4965e-01, time/batch = 0.6823s	
138/26050 (epoch 0.265), train_loss = 3.36380695, grad/param norm = 4.9146e-01, time/batch = 0.6477s	
139/26050 (epoch 0.267), train_loss = 3.17511370, grad/param norm = 4.9044e-01, time/batch = 0.6487s	
140/26050 (epoch 0.269), train_loss = 3.24389971, grad/param norm = 5.3222e-01, time/batch = 0.6465s	
141/26050 (epoch 0.271), train_loss = 3.17164189, grad/param norm = 7.3027e-01, time/batch = 0.6466s	
142/26050 (epoch 0.273), train_loss = 3.31625121, grad/param norm = 9.0370e-01, time/batch = 0.6395s	
143/26050 (epoch 0.274), train_loss = 3.33252814, grad/param norm = 1.1776e+00, time/batch = 0.6394s	
144/26050 (epoch 0.276), train_loss = 3.26536383, grad/param norm = 8.3611e-01, time/batch = 0.6448s	
145/26050 (epoch 0.278), train_loss = 3.16347882, grad/param norm = 7.1405e-01, time/batch = 0.6462s	
146/26050 (epoch 0.280), train_loss = 3.17600069, grad/param norm = 6.5237e-01, time/batch = 0.6541s	
147/26050 (epoch 0.282), train_loss = 3.15694490, grad/param norm = 7.0525e-01, time/batch = 0.6569s	
148/26050 (epoch 0.284), train_loss = 3.16610220, grad/param norm = 1.1950e+00, time/batch = 0.6471s	
149/26050 (epoch 0.286), train_loss = 3.25066744, grad/param norm = 1.7483e+00, time/batch = 0.6437s	
150/26050 (epoch 0.288), train_loss = 3.13055659, grad/param norm = 1.2582e+00, time/batch = 0.6432s	
151/26050 (epoch 0.290), train_loss = 3.15720153, grad/param norm = 5.3621e-01, time/batch = 0.6405s	
152/26050 (epoch 0.292), train_loss = 3.20665318, grad/param norm = 5.2153e-01, time/batch = 0.6820s	
153/26050 (epoch 0.294), train_loss = 3.14926888, grad/param norm = 4.6037e-01, time/batch = 0.6625s	
154/26050 (epoch 0.296), train_loss = 3.13970502, grad/param norm = 5.0370e-01, time/batch = 0.6418s	
155/26050 (epoch 0.298), train_loss = 3.10762289, grad/param norm = 7.2023e-01, time/batch = 0.6431s	
156/26050 (epoch 0.299), train_loss = 3.12653222, grad/param norm = 9.7413e-01, time/batch = 0.6494s	
157/26050 (epoch 0.301), train_loss = 3.20403946, grad/param norm = 1.2151e+00, time/batch = 0.6551s	
158/26050 (epoch 0.303), train_loss = 3.10452034, grad/param norm = 6.6860e-01, time/batch = 0.6404s	
159/26050 (epoch 0.305), train_loss = 3.14868709, grad/param norm = 3.8552e-01, time/batch = 0.6450s	
160/26050 (epoch 0.307), train_loss = 3.03483340, grad/param norm = 5.1423e-01, time/batch = 0.6401s	
161/26050 (epoch 0.309), train_loss = 3.03663431, grad/param norm = 5.3376e-01, time/batch = 0.6387s	
162/26050 (epoch 0.311), train_loss = 3.28814417, grad/param norm = 4.7858e-01, time/batch = 0.6397s	
163/26050 (epoch 0.313), train_loss = 3.09400554, grad/param norm = 5.4861e-01, time/batch = 0.6414s	
164/26050 (epoch 0.315), train_loss = 3.15372414, grad/param norm = 7.4693e-01, time/batch = 0.6413s	
165/26050 (epoch 0.317), train_loss = 3.10290838, grad/param norm = 9.7970e-01, time/batch = 0.6534s	
166/26050 (epoch 0.319), train_loss = 3.21369963, grad/param norm = 8.3736e-01, time/batch = 0.6574s	
167/26050 (epoch 0.321), train_loss = 3.12706054, grad/param norm = 5.6222e-01, time/batch = 0.6582s	
168/26050 (epoch 0.322), train_loss = 3.01119393, grad/param norm = 5.1117e-01, time/batch = 0.6581s	
169/26050 (epoch 0.324), train_loss = 3.03388584, grad/param norm = 6.1814e-01, time/batch = 0.6562s	
170/26050 (epoch 0.326), train_loss = 3.13198653, grad/param norm = 8.6841e-01, time/batch = 0.6573s	
171/26050 (epoch 0.328), train_loss = 3.12714087, grad/param norm = 1.1459e+00, time/batch = 0.6466s	
172/26050 (epoch 0.330), train_loss = 3.18736040, grad/param norm = 1.8419e+00, time/batch = 0.6712s	
173/26050 (epoch 0.332), train_loss = 3.21811685, grad/param norm = 1.5795e+00, time/batch = 0.6709s	
174/26050 (epoch 0.334), train_loss = 3.11046495, grad/param norm = 9.5013e-01, time/batch = 0.6664s	
175/26050 (epoch 0.336), train_loss = 3.07470693, grad/param norm = 8.1357e-01, time/batch = 0.6585s	
176/26050 (epoch 0.338), train_loss = 3.01120285, grad/param norm = 5.9321e-01, time/batch = 0.6452s	
177/26050 (epoch 0.340), train_loss = 3.03952152, grad/param norm = 4.4606e-01, time/batch = 0.6414s	
178/26050 (epoch 0.342), train_loss = 3.02484161, grad/param norm = 3.7567e-01, time/batch = 0.6390s	
179/26050 (epoch 0.344), train_loss = 3.06640261, grad/param norm = 4.7726e-01, time/batch = 0.6410s	
180/26050 (epoch 0.345), train_loss = 3.01997641, grad/param norm = 5.3563e-01, time/batch = 0.6420s	
181/26050 (epoch 0.347), train_loss = 3.05751598, grad/param norm = 4.3744e-01, time/batch = 0.6411s	
182/26050 (epoch 0.349), train_loss = 2.92639301, grad/param norm = 4.6176e-01, time/batch = 0.6484s	
183/26050 (epoch 0.351), train_loss = 2.98741136, grad/param norm = 6.2251e-01, time/batch = 0.6762s	
184/26050 (epoch 0.353), train_loss = 2.93848863, grad/param norm = 7.1039e-01, time/batch = 0.6659s	
185/26050 (epoch 0.355), train_loss = 2.94626095, grad/param norm = 8.0522e-01, time/batch = 0.6753s	
186/26050 (epoch 0.357), train_loss = 2.96854295, grad/param norm = 7.6767e-01, time/batch = 0.6760s	
187/26050 (epoch 0.359), train_loss = 2.93298055, grad/param norm = 1.2248e+00, time/batch = 0.6723s	
188/26050 (epoch 0.361), train_loss = 3.04169238, grad/param norm = 1.9102e+00, time/batch = 0.6723s	
189/26050 (epoch 0.363), train_loss = 3.10385937, grad/param norm = 1.5688e+00, time/batch = 0.6420s	
190/26050 (epoch 0.365), train_loss = 2.86501225, grad/param norm = 7.4792e-01, time/batch = 0.6412s	
191/26050 (epoch 0.367), train_loss = 2.92016415, grad/param norm = 5.2656e-01, time/batch = 0.6403s	
192/26050 (epoch 0.369), train_loss = 3.08089675, grad/param norm = 7.4061e-01, time/batch = 0.6394s	
193/26050 (epoch 0.370), train_loss = 3.02333457, grad/param norm = 8.0204e-01, time/batch = 0.6386s	
194/26050 (epoch 0.372), train_loss = 3.15321644, grad/param norm = 7.4031e-01, time/batch = 0.6398s	
195/26050 (epoch 0.374), train_loss = 3.02687264, grad/param norm = 7.4700e-01, time/batch = 0.6402s	
196/26050 (epoch 0.376), train_loss = 3.07983895, grad/param norm = 5.8120e-01, time/batch = 0.6538s	
197/26050 (epoch 0.378), train_loss = 2.91286306, grad/param norm = 4.4354e-01, time/batch = 0.6452s	
198/26050 (epoch 0.380), train_loss = 3.06775787, grad/param norm = 7.6445e-01, time/batch = 0.6432s	
199/26050 (epoch 0.382), train_loss = 3.12868435, grad/param norm = 6.6069e-01, time/batch = 0.6397s	
200/26050 (epoch 0.384), train_loss = 2.95044935, grad/param norm = 6.2731e-01, time/batch = 0.6391s	
201/26050 (epoch 0.386), train_loss = 3.03121998, grad/param norm = 6.5536e-01, time/batch = 0.6467s	
202/26050 (epoch 0.388), train_loss = 2.86358696, grad/param norm = 7.1552e-01, time/batch = 0.6425s	
203/26050 (epoch 0.390), train_loss = 3.03116047, grad/param norm = 6.0345e-01, time/batch = 0.6492s	
204/26050 (epoch 0.392), train_loss = 2.82119138, grad/param norm = 5.4237e-01, time/batch = 0.6411s	
205/26050 (epoch 0.393), train_loss = 2.92199337, grad/param norm = 4.6462e-01, time/batch = 0.6400s	
206/26050 (epoch 0.395), train_loss = 2.92146177, grad/param norm = 6.1416e-01, time/batch = 0.6386s	
207/26050 (epoch 0.397), train_loss = 3.04292749, grad/param norm = 7.7945e-01, time/batch = 0.6406s	
208/26050 (epoch 0.399), train_loss = 2.81627600, grad/param norm = 7.8096e-01, time/batch = 0.6562s	
209/26050 (epoch 0.401), train_loss = 2.90043145, grad/param norm = 8.0805e-01, time/batch = 0.6824s	
210/26050 (epoch 0.403), train_loss = 2.88822241, grad/param norm = 1.1951e+00, time/batch = 0.6475s	
211/26050 (epoch 0.405), train_loss = 2.87831948, grad/param norm = 6.9379e-01, time/batch = 0.6415s	
212/26050 (epoch 0.407), train_loss = 2.91183685, grad/param norm = 8.2136e-01, time/batch = 0.6399s	
213/26050 (epoch 0.409), train_loss = 2.96860199, grad/param norm = 7.7521e-01, time/batch = 0.6395s	
214/26050 (epoch 0.411), train_loss = 2.93473907, grad/param norm = 6.6443e-01, time/batch = 0.6443s	
215/26050 (epoch 0.413), train_loss = 2.86958671, grad/param norm = 3.3940e-01, time/batch = 0.6586s	
216/26050 (epoch 0.415), train_loss = 2.88156046, grad/param norm = 5.0399e-01, time/batch = 0.6444s	
217/26050 (epoch 0.417), train_loss = 2.86197590, grad/param norm = 8.6940e-01, time/batch = 0.6447s	
218/26050 (epoch 0.418), train_loss = 3.05955939, grad/param norm = 1.2679e+00, time/batch = 0.6393s	
219/26050 (epoch 0.420), train_loss = 2.70080580, grad/param norm = 1.3011e+00, time/batch = 0.6434s	
220/26050 (epoch 0.422), train_loss = 2.87337453, grad/param norm = 9.3949e-01, time/batch = 0.6428s	
221/26050 (epoch 0.424), train_loss = 2.92609369, grad/param norm = 6.2240e-01, time/batch = 0.6425s	
222/26050 (epoch 0.426), train_loss = 2.93689487, grad/param norm = 8.1262e-01, time/batch = 0.6437s	
223/26050 (epoch 0.428), train_loss = 2.86551283, grad/param norm = 9.5576e-01, time/batch = 0.6409s	
224/26050 (epoch 0.430), train_loss = 2.81730471, grad/param norm = 7.8324e-01, time/batch = 0.6798s	
225/26050 (epoch 0.432), train_loss = 2.89306460, grad/param norm = 4.9645e-01, time/batch = 0.6726s	
226/26050 (epoch 0.434), train_loss = 3.05914269, grad/param norm = 5.1183e-01, time/batch = 0.6555s	
227/26050 (epoch 0.436), train_loss = 2.85394783, grad/param norm = 6.6563e-01, time/batch = 0.6408s	
228/26050 (epoch 0.438), train_loss = 2.79998895, grad/param norm = 6.6153e-01, time/batch = 0.6409s	
229/26050 (epoch 0.440), train_loss = 2.91708828, grad/param norm = 5.4793e-01, time/batch = 0.6392s	
230/26050 (epoch 0.441), train_loss = 2.85342384, grad/param norm = 5.3941e-01, time/batch = 0.6533s	
231/26050 (epoch 0.443), train_loss = 2.77053804, grad/param norm = 4.1225e-01, time/batch = 0.6530s	
232/26050 (epoch 0.445), train_loss = 2.74620429, grad/param norm = 4.1720e-01, time/batch = 0.6518s	
233/26050 (epoch 0.447), train_loss = 2.89436277, grad/param norm = 6.4505e-01, time/batch = 0.6629s	
234/26050 (epoch 0.449), train_loss = 2.84957337, grad/param norm = 9.7618e-01, time/batch = 0.6500s	
235/26050 (epoch 0.451), train_loss = 2.89519215, grad/param norm = 8.4515e-01, time/batch = 0.6537s	
236/26050 (epoch 0.453), train_loss = 2.68344827, grad/param norm = 6.4541e-01, time/batch = 0.6538s	
237/26050 (epoch 0.455), train_loss = 2.77496656, grad/param norm = 6.9624e-01, time/batch = 0.6470s	
238/26050 (epoch 0.457), train_loss = 2.72461036, grad/param norm = 6.4481e-01, time/batch = 0.6469s	
239/26050 (epoch 0.459), train_loss = 2.86947567, grad/param norm = 6.9184e-01, time/batch = 0.6502s	
240/26050 (epoch 0.461), train_loss = 2.69259752, grad/param norm = 7.5010e-01, time/batch = 0.6509s	
241/26050 (epoch 0.463), train_loss = 2.77942319, grad/param norm = 8.4871e-01, time/batch = 0.6545s	
242/26050 (epoch 0.464), train_loss = 2.84948535, grad/param norm = 1.2234e+00, time/batch = 0.6577s	
243/26050 (epoch 0.466), train_loss = 2.86945764, grad/param norm = 1.0739e+00, time/batch = 0.6542s	
244/26050 (epoch 0.468), train_loss = 2.84600083, grad/param norm = 8.0466e-01, time/batch = 0.6535s	
245/26050 (epoch 0.470), train_loss = 2.83619016, grad/param norm = 6.4891e-01, time/batch = 0.6565s	
246/26050 (epoch 0.472), train_loss = 2.95416253, grad/param norm = 5.2820e-01, time/batch = 0.6536s	
247/26050 (epoch 0.474), train_loss = 2.97418630, grad/param norm = 5.9307e-01, time/batch = 0.6498s	
248/26050 (epoch 0.476), train_loss = 2.90771608, grad/param norm = 5.5400e-01, time/batch = 0.6552s	
249/26050 (epoch 0.478), train_loss = 2.74073471, grad/param norm = 4.4921e-01, time/batch = 0.6492s	
250/26050 (epoch 0.480), train_loss = 2.78916640, grad/param norm = 5.6059e-01, time/batch = 0.6417s	
251/26050 (epoch 0.482), train_loss = 2.67601830, grad/param norm = 4.7996e-01, time/batch = 0.6416s	
252/26050 (epoch 0.484), train_loss = 2.75144546, grad/param norm = 4.5612e-01, time/batch = 0.6419s	
253/26050 (epoch 0.486), train_loss = 2.81706527, grad/param norm = 6.1509e-01, time/batch = 0.6416s	
254/26050 (epoch 0.488), train_loss = 2.99436320, grad/param norm = 7.4126e-01, time/batch = 0.6443s	
255/26050 (epoch 0.489), train_loss = 2.92951446, grad/param norm = 1.1255e+00, time/batch = 0.6402s	
256/26050 (epoch 0.491), train_loss = 2.74885994, grad/param norm = 8.3499e-01, time/batch = 0.6437s	
257/26050 (epoch 0.493), train_loss = 2.67087596, grad/param norm = 5.0135e-01, time/batch = 0.6418s	
258/26050 (epoch 0.495), train_loss = 2.73852356, grad/param norm = 5.7254e-01, time/batch = 0.6402s	
259/26050 (epoch 0.497), train_loss = 2.78770478, grad/param norm = 8.0414e-01, time/batch = 0.6699s	
260/26050 (epoch 0.499), train_loss = 2.58171617, grad/param norm = 9.4339e-01, time/batch = 0.6731s	
261/26050 (epoch 0.501), train_loss = 2.65236829, grad/param norm = 7.7017e-01, time/batch = 0.6432s	
262/26050 (epoch 0.503), train_loss = 2.83107698, grad/param norm = 6.0870e-01, time/batch = 0.6427s	
263/26050 (epoch 0.505), train_loss = 2.76031748, grad/param norm = 4.3230e-01, time/batch = 0.6470s	
264/26050 (epoch 0.507), train_loss = 2.74677274, grad/param norm = 3.8788e-01, time/batch = 0.6611s	
265/26050 (epoch 0.509), train_loss = 2.91387069, grad/param norm = 4.4742e-01, time/batch = 0.6527s	
266/26050 (epoch 0.511), train_loss = 2.64051941, grad/param norm = 3.3127e-01, time/batch = 0.6546s	
267/26050 (epoch 0.512), train_loss = 2.80131335, grad/param norm = 4.3697e-01, time/batch = 0.6424s	
268/26050 (epoch 0.514), train_loss = 2.79318010, grad/param norm = 5.4446e-01, time/batch = 0.6458s	
269/26050 (epoch 0.516), train_loss = 2.74449314, grad/param norm = 6.7031e-01, time/batch = 0.6410s	
270/26050 (epoch 0.518), train_loss = 2.70947518, grad/param norm = 6.6154e-01, time/batch = 0.6447s	
271/26050 (epoch 0.520), train_loss = 2.65551171, grad/param norm = 6.5906e-01, time/batch = 0.6485s	
272/26050 (epoch 0.522), train_loss = 2.77982682, grad/param norm = 7.3096e-01, time/batch = 0.6429s	
273/26050 (epoch 0.524), train_loss = 2.94468079, grad/param norm = 5.6949e-01, time/batch = 0.6415s	
274/26050 (epoch 0.526), train_loss = 2.75043361, grad/param norm = 4.2778e-01, time/batch = 0.6449s	
275/26050 (epoch 0.528), train_loss = 2.77698332, grad/param norm = 5.7253e-01, time/batch = 0.6443s	
276/26050 (epoch 0.530), train_loss = 2.79909778, grad/param norm = 7.1856e-01, time/batch = 0.6445s	
277/26050 (epoch 0.532), train_loss = 2.73143875, grad/param norm = 6.7576e-01, time/batch = 0.6418s	
278/26050 (epoch 0.534), train_loss = 2.81993384, grad/param norm = 6.1042e-01, time/batch = 0.6480s	
279/26050 (epoch 0.536), train_loss = 2.66372204, grad/param norm = 4.9545e-01, time/batch = 0.6482s	
280/26050 (epoch 0.537), train_loss = 2.71945118, grad/param norm = 4.8155e-01, time/batch = 0.6472s	
281/26050 (epoch 0.539), train_loss = 2.55112994, grad/param norm = 6.3601e-01, time/batch = 0.6412s	
282/26050 (epoch 0.541), train_loss = 2.76110089, grad/param norm = 7.1295e-01, time/batch = 0.6440s	
283/26050 (epoch 0.543), train_loss = 2.73095704, grad/param norm = 7.2071e-01, time/batch = 0.6420s	
284/26050 (epoch 0.545), train_loss = 2.73856704, grad/param norm = 8.7984e-01, time/batch = 0.6395s	
285/26050 (epoch 0.547), train_loss = 2.91266908, grad/param norm = 6.5094e-01, time/batch = 0.6400s	
286/26050 (epoch 0.549), train_loss = 2.70492841, grad/param norm = 3.9922e-01, time/batch = 0.6398s	
287/26050 (epoch 0.551), train_loss = 2.66173379, grad/param norm = 5.3296e-01, time/batch = 0.6419s	
288/26050 (epoch 0.553), train_loss = 2.68514488, grad/param norm = 5.4081e-01, time/batch = 0.6412s	
289/26050 (epoch 0.555), train_loss = 2.62888015, grad/param norm = 6.0248e-01, time/batch = 0.6386s	
290/26050 (epoch 0.557), train_loss = 2.77633667, grad/param norm = 5.0107e-01, time/batch = 0.6786s	
291/26050 (epoch 0.559), train_loss = 2.72340477, grad/param norm = 4.5701e-01, time/batch = 0.6640s	
292/26050 (epoch 0.560), train_loss = 2.70450215, grad/param norm = 5.3016e-01, time/batch = 0.6407s	
293/26050 (epoch 0.562), train_loss = 2.65794627, grad/param norm = 5.7989e-01, time/batch = 0.6448s	
294/26050 (epoch 0.564), train_loss = 2.80695494, grad/param norm = 3.9826e-01, time/batch = 0.6404s	
295/26050 (epoch 0.566), train_loss = 2.70462552, grad/param norm = 3.6291e-01, time/batch = 0.6432s	
296/26050 (epoch 0.568), train_loss = 2.66810115, grad/param norm = 3.2092e-01, time/batch = 0.6462s	
297/26050 (epoch 0.570), train_loss = 2.78293241, grad/param norm = 4.6541e-01, time/batch = 0.6396s	
298/26050 (epoch 0.572), train_loss = 2.82163552, grad/param norm = 5.1162e-01, time/batch = 0.6389s	
299/26050 (epoch 0.574), train_loss = 2.74778487, grad/param norm = 6.1663e-01, time/batch = 0.6401s	
300/26050 (epoch 0.576), train_loss = 2.72139386, grad/param norm = 9.3833e-01, time/batch = 0.6404s	
301/26050 (epoch 0.578), train_loss = 2.84297683, grad/param norm = 8.0449e-01, time/batch = 0.6503s	
302/26050 (epoch 0.580), train_loss = 2.63814996, grad/param norm = 4.8184e-01, time/batch = 0.6635s	
303/26050 (epoch 0.582), train_loss = 2.80367697, grad/param norm = 5.6421e-01, time/batch = 0.6606s	
304/26050 (epoch 0.583), train_loss = 2.78017555, grad/param norm = 7.2126e-01, time/batch = 0.6603s	
305/26050 (epoch 0.585), train_loss = 2.83225591, grad/param norm = 7.4359e-01, time/batch = 0.6755s	
306/26050 (epoch 0.587), train_loss = 2.69496600, grad/param norm = 5.4731e-01, time/batch = 0.6792s	
307/26050 (epoch 0.589), train_loss = 2.59024480, grad/param norm = 5.0988e-01, time/batch = 0.6465s	
308/26050 (epoch 0.591), train_loss = 2.75063835, grad/param norm = 6.3470e-01, time/batch = 0.6515s	
309/26050 (epoch 0.593), train_loss = 2.76319926, grad/param norm = 7.8986e-01, time/batch = 0.6591s	
310/26050 (epoch 0.595), train_loss = 2.69559576, grad/param norm = 6.9478e-01, time/batch = 0.6641s	
311/26050 (epoch 0.597), train_loss = 2.57849496, grad/param norm = 4.7792e-01, time/batch = 0.6593s	
312/26050 (epoch 0.599), train_loss = 2.50302945, grad/param norm = 5.1087e-01, time/batch = 0.6628s	
313/26050 (epoch 0.601), train_loss = 2.91395008, grad/param norm = 6.2842e-01, time/batch = 0.6539s	
314/26050 (epoch 0.603), train_loss = 2.70829399, grad/param norm = 5.8084e-01, time/batch = 0.6452s	
315/26050 (epoch 0.605), train_loss = 2.72919376, grad/param norm = 5.0135e-01, time/batch = 0.6394s	
316/26050 (epoch 0.607), train_loss = 2.66593916, grad/param norm = 4.8291e-01, time/batch = 0.6397s	
317/26050 (epoch 0.608), train_loss = 2.73005833, grad/param norm = 3.5898e-01, time/batch = 0.6492s	
318/26050 (epoch 0.610), train_loss = 2.61964562, grad/param norm = 3.7540e-01, time/batch = 0.6572s	
319/26050 (epoch 0.612), train_loss = 2.69598972, grad/param norm = 3.6016e-01, time/batch = 0.6519s	
320/26050 (epoch 0.614), train_loss = 2.58458929, grad/param norm = 5.9507e-01, time/batch = 0.6397s	
321/26050 (epoch 0.616), train_loss = 2.89334658, grad/param norm = 9.8901e-01, time/batch = 0.6413s	
322/26050 (epoch 0.618), train_loss = 2.66632208, grad/param norm = 9.9545e-01, time/batch = 0.6408s	
323/26050 (epoch 0.620), train_loss = 2.73400330, grad/param norm = 6.9777e-01, time/batch = 0.6403s	
324/26050 (epoch 0.622), train_loss = 2.48285319, grad/param norm = 3.7300e-01, time/batch = 0.6401s	
325/26050 (epoch 0.624), train_loss = 2.56555688, grad/param norm = 3.6166e-01, time/batch = 0.6398s	
326/26050 (epoch 0.626), train_loss = 2.67923540, grad/param norm = 5.6599e-01, time/batch = 0.6466s	
327/26050 (epoch 0.628), train_loss = 2.73997786, grad/param norm = 7.2367e-01, time/batch = 0.6394s	
328/26050 (epoch 0.630), train_loss = 2.72646685, grad/param norm = 7.4680e-01, time/batch = 0.6400s	
329/26050 (epoch 0.631), train_loss = 2.66596980, grad/param norm = 3.9027e-01, time/batch = 0.6391s	
330/26050 (epoch 0.633), train_loss = 2.52868287, grad/param norm = 4.4012e-01, time/batch = 0.6406s	
331/26050 (epoch 0.635), train_loss = 2.53354847, grad/param norm = 3.5674e-01, time/batch = 0.6413s	
332/26050 (epoch 0.637), train_loss = 2.54878961, grad/param norm = 3.4232e-01, time/batch = 0.6397s	
333/26050 (epoch 0.639), train_loss = 2.69350857, grad/param norm = 3.2911e-01, time/batch = 0.6419s	
334/26050 (epoch 0.641), train_loss = 2.47778658, grad/param norm = 4.8379e-01, time/batch = 0.6409s	
335/26050 (epoch 0.643), train_loss = 2.64666537, grad/param norm = 6.9330e-01, time/batch = 0.6412s	
336/26050 (epoch 0.645), train_loss = 2.77617288, grad/param norm = 7.4464e-01, time/batch = 0.6405s	
337/26050 (epoch 0.647), train_loss = 2.55913606, grad/param norm = 5.9611e-01, time/batch = 0.6398s	
338/26050 (epoch 0.649), train_loss = 2.70560484, grad/param norm = 6.4445e-01, time/batch = 0.6402s	
339/26050 (epoch 0.651), train_loss = 2.64561992, grad/param norm = 3.9997e-01, time/batch = 0.6398s	
340/26050 (epoch 0.653), train_loss = 2.54648930, grad/param norm = 3.8549e-01, time/batch = 0.6401s	
341/26050 (epoch 0.655), train_loss = 2.62200761, grad/param norm = 4.0961e-01, time/batch = 0.6403s	
342/26050 (epoch 0.656), train_loss = 2.62196726, grad/param norm = 4.9102e-01, time/batch = 0.6463s	
343/26050 (epoch 0.658), train_loss = 2.58235427, grad/param norm = 4.3871e-01, time/batch = 0.6398s	
344/26050 (epoch 0.660), train_loss = 2.53671746, grad/param norm = 4.2471e-01, time/batch = 0.6398s	
345/26050 (epoch 0.662), train_loss = 2.51704837, grad/param norm = 5.2805e-01, time/batch = 0.6407s	
346/26050 (epoch 0.664), train_loss = 2.42621813, grad/param norm = 4.3491e-01, time/batch = 0.6410s	
347/26050 (epoch 0.666), train_loss = 2.62631471, grad/param norm = 3.1738e-01, time/batch = 0.6412s	
348/26050 (epoch 0.668), train_loss = 2.33183076, grad/param norm = 4.0347e-01, time/batch = 0.6437s	
349/26050 (epoch 0.670), train_loss = 2.75022340, grad/param norm = 5.8331e-01, time/batch = 0.6424s	
350/26050 (epoch 0.672), train_loss = 2.55202369, grad/param norm = 7.5170e-01, time/batch = 0.6428s	
351/26050 (epoch 0.674), train_loss = 2.57682021, grad/param norm = 9.2931e-01, time/batch = 0.6431s	
352/26050 (epoch 0.676), train_loss = 2.64964374, grad/param norm = 7.9578e-01, time/batch = 0.6412s	
353/26050 (epoch 0.678), train_loss = 2.65845311, grad/param norm = 4.6467e-01, time/batch = 0.6429s	
354/26050 (epoch 0.679), train_loss = 2.58465020, grad/param norm = 4.5014e-01, time/batch = 0.6415s	
355/26050 (epoch 0.681), train_loss = 2.63224582, grad/param norm = 4.3064e-01, time/batch = 0.6433s	
356/26050 (epoch 0.683), train_loss = 2.50073488, grad/param norm = 4.7714e-01, time/batch = 0.6616s	
357/26050 (epoch 0.685), train_loss = 2.49714904, grad/param norm = 5.7761e-01, time/batch = 0.6540s	
358/26050 (epoch 0.687), train_loss = 2.42029278, grad/param norm = 4.5574e-01, time/batch = 0.6595s	
359/26050 (epoch 0.689), train_loss = 2.50720642, grad/param norm = 3.3033e-01, time/batch = 0.6644s	
360/26050 (epoch 0.691), train_loss = 2.48303583, grad/param norm = 4.0599e-01, time/batch = 0.6631s	
361/26050 (epoch 0.693), train_loss = 2.58826959, grad/param norm = 6.0532e-01, time/batch = 0.6422s	
362/26050 (epoch 0.695), train_loss = 2.55148889, grad/param norm = 6.3064e-01, time/batch = 0.6420s	
363/26050 (epoch 0.697), train_loss = 2.53908162, grad/param norm = 5.5111e-01, time/batch = 0.6526s	
364/26050 (epoch 0.699), train_loss = 2.58822941, grad/param norm = 6.0169e-01, time/batch = 0.6460s	
365/26050 (epoch 0.701), train_loss = 2.58746985, grad/param norm = 5.7405e-01, time/batch = 0.6434s	
366/26050 (epoch 0.702), train_loss = 2.69794785, grad/param norm = 5.5916e-01, time/batch = 0.6408s	
367/26050 (epoch 0.704), train_loss = 2.60993667, grad/param norm = 5.2384e-01, time/batch = 0.6824s	
368/26050 (epoch 0.706), train_loss = 2.50746505, grad/param norm = 3.8595e-01, time/batch = 0.6600s	
369/26050 (epoch 0.708), train_loss = 2.48680453, grad/param norm = 3.1783e-01, time/batch = 0.6487s	
370/26050 (epoch 0.710), train_loss = 2.71595090, grad/param norm = 3.9140e-01, time/batch = 0.6413s	
371/26050 (epoch 0.712), train_loss = 2.67399547, grad/param norm = 4.9297e-01, time/batch = 0.6438s	
372/26050 (epoch 0.714), train_loss = 2.54969726, grad/param norm = 6.1858e-01, time/batch = 0.6568s	
373/26050 (epoch 0.716), train_loss = 2.77504168, grad/param norm = 6.0725e-01, time/batch = 0.6423s	
374/26050 (epoch 0.718), train_loss = 2.54677009, grad/param norm = 6.1309e-01, time/batch = 0.6446s	
375/26050 (epoch 0.720), train_loss = 2.37173139, grad/param norm = 3.9533e-01, time/batch = 0.6525s	
376/26050 (epoch 0.722), train_loss = 2.60686862, grad/param norm = 3.8779e-01, time/batch = 0.6464s	
377/26050 (epoch 0.724), train_loss = 2.44487638, grad/param norm = 7.9707e-01, time/batch = 0.6394s	
378/26050 (epoch 0.726), train_loss = 2.67567469, grad/param norm = 7.6196e-01, time/batch = 0.6395s	
379/26050 (epoch 0.727), train_loss = 2.60137583, grad/param norm = 4.6330e-01, time/batch = 0.6418s	
380/26050 (epoch 0.729), train_loss = 2.58494971, grad/param norm = 3.7902e-01, time/batch = 0.6417s	
381/26050 (epoch 0.731), train_loss = 2.47257356, grad/param norm = 3.6608e-01, time/batch = 0.6537s	
382/26050 (epoch 0.733), train_loss = 2.51467729, grad/param norm = 3.6847e-01, time/batch = 0.6750s	
383/26050 (epoch 0.735), train_loss = 2.71994481, grad/param norm = 4.1541e-01, time/batch = 0.6773s	
384/26050 (epoch 0.737), train_loss = 2.55213936, grad/param norm = 3.9722e-01, time/batch = 0.6435s	
385/26050 (epoch 0.739), train_loss = 2.52314552, grad/param norm = 3.9560e-01, time/batch = 0.6418s	
386/26050 (epoch 0.741), train_loss = 2.41444522, grad/param norm = 3.3261e-01, time/batch = 0.6510s	
387/26050 (epoch 0.743), train_loss = 2.70961599, grad/param norm = 4.4593e-01, time/batch = 0.6507s	
388/26050 (epoch 0.745), train_loss = 2.51743999, grad/param norm = 9.1747e-01, time/batch = 0.6410s	
389/26050 (epoch 0.747), train_loss = 2.52471904, grad/param norm = 6.6967e-01, time/batch = 0.6444s	
390/26050 (epoch 0.749), train_loss = 2.62731150, grad/param norm = 6.9566e-01, time/batch = 0.6400s	
391/26050 (epoch 0.750), train_loss = 2.55101156, grad/param norm = 5.9784e-01, time/batch = 0.6416s	
392/26050 (epoch 0.752), train_loss = 2.55220522, grad/param norm = 5.1421e-01, time/batch = 0.6399s	
393/26050 (epoch 0.754), train_loss = 2.36810712, grad/param norm = 4.0619e-01, time/batch = 0.6419s	
394/26050 (epoch 0.756), train_loss = 2.60513427, grad/param norm = 3.3616e-01, time/batch = 0.6407s	
395/26050 (epoch 0.758), train_loss = 2.59338106, grad/param norm = 3.7057e-01, time/batch = 0.6405s	
396/26050 (epoch 0.760), train_loss = 2.42510453, grad/param norm = 4.0393e-01, time/batch = 0.6404s	
397/26050 (epoch 0.762), train_loss = 2.51173708, grad/param norm = 5.2439e-01, time/batch = 0.6519s	
398/26050 (epoch 0.764), train_loss = 2.57162735, grad/param norm = 4.4905e-01, time/batch = 0.6827s	
399/26050 (epoch 0.766), train_loss = 2.55391627, grad/param norm = 3.7713e-01, time/batch = 0.6477s	
400/26050 (epoch 0.768), train_loss = 2.48079917, grad/param norm = 3.8676e-01, time/batch = 0.6420s	
401/26050 (epoch 0.770), train_loss = 2.46218399, grad/param norm = 4.7204e-01, time/batch = 0.6410s	
402/26050 (epoch 0.772), train_loss = 2.52557147, grad/param norm = 3.9674e-01, time/batch = 0.6430s	
403/26050 (epoch 0.774), train_loss = 2.47054168, grad/param norm = 4.5966e-01, time/batch = 0.6443s	
404/26050 (epoch 0.775), train_loss = 2.46709431, grad/param norm = 5.2111e-01, time/batch = 0.6403s	
405/26050 (epoch 0.777), train_loss = 2.43425781, grad/param norm = 7.1570e-01, time/batch = 0.6411s	
406/26050 (epoch 0.779), train_loss = 2.57522979, grad/param norm = 9.1019e-01, time/batch = 0.6388s	
407/26050 (epoch 0.781), train_loss = 2.55475721, grad/param norm = 6.8676e-01, time/batch = 0.6411s	
408/26050 (epoch 0.783), train_loss = 2.42615254, grad/param norm = 3.4491e-01, time/batch = 0.6419s	
409/26050 (epoch 0.785), train_loss = 2.46151172, grad/param norm = 2.9864e-01, time/batch = 0.6420s	
410/26050 (epoch 0.787), train_loss = 2.44207540, grad/param norm = 4.1278e-01, time/batch = 0.6422s	
411/26050 (epoch 0.789), train_loss = 2.62576695, grad/param norm = 6.2308e-01, time/batch = 0.6512s	
412/26050 (epoch 0.791), train_loss = 2.53138858, grad/param norm = 5.7278e-01, time/batch = 0.6450s	
413/26050 (epoch 0.793), train_loss = 2.39178222, grad/param norm = 3.5578e-01, time/batch = 0.6795s	
414/26050 (epoch 0.795), train_loss = 2.48829146, grad/param norm = 3.5725e-01, time/batch = 0.6648s	
415/26050 (epoch 0.797), train_loss = 2.29685445, grad/param norm = 3.7124e-01, time/batch = 0.6386s	
416/26050 (epoch 0.798), train_loss = 2.35615489, grad/param norm = 3.4488e-01, time/batch = 0.6394s	
417/26050 (epoch 0.800), train_loss = 2.38851681, grad/param norm = 3.3534e-01, time/batch = 0.6395s	
418/26050 (epoch 0.802), train_loss = 2.50972211, grad/param norm = 3.4174e-01, time/batch = 0.6433s	
419/26050 (epoch 0.804), train_loss = 2.51464246, grad/param norm = 2.8824e-01, time/batch = 0.6482s	
420/26050 (epoch 0.806), train_loss = 2.53222496, grad/param norm = 3.0814e-01, time/batch = 0.6391s	
421/26050 (epoch 0.808), train_loss = 2.31831090, grad/param norm = 4.1660e-01, time/batch = 0.6405s	
422/26050 (epoch 0.810), train_loss = 2.47355865, grad/param norm = 6.4719e-01, time/batch = 0.6471s	
423/26050 (epoch 0.812), train_loss = 2.42136741, grad/param norm = 6.8493e-01, time/batch = 0.6409s	
424/26050 (epoch 0.814), train_loss = 2.39733219, grad/param norm = 4.4713e-01, time/batch = 0.6398s	
425/26050 (epoch 0.816), train_loss = 2.44089200, grad/param norm = 3.6678e-01, time/batch = 0.6424s	
426/26050 (epoch 0.818), train_loss = 2.55441823, grad/param norm = 3.6608e-01, time/batch = 0.6412s	
427/26050 (epoch 0.820), train_loss = 2.50255623, grad/param norm = 3.7249e-01, time/batch = 0.6403s	
428/26050 (epoch 0.821), train_loss = 2.52754785, grad/param norm = 3.5824e-01, time/batch = 0.6588s	
429/26050 (epoch 0.823), train_loss = 2.61913599, grad/param norm = 5.2894e-01, time/batch = 0.6821s	
430/26050 (epoch 0.825), train_loss = 2.50750186, grad/param norm = 5.5641e-01, time/batch = 0.6402s	
431/26050 (epoch 0.827), train_loss = 2.61302836, grad/param norm = 4.8995e-01, time/batch = 0.6402s	
432/26050 (epoch 0.829), train_loss = 2.52785333, grad/param norm = 4.6660e-01, time/batch = 0.6434s	
433/26050 (epoch 0.831), train_loss = 2.55891376, grad/param norm = 4.2476e-01, time/batch = 0.6492s	
434/26050 (epoch 0.833), train_loss = 2.57024096, grad/param norm = 3.8499e-01, time/batch = 0.6402s	
435/26050 (epoch 0.835), train_loss = 2.65303016, grad/param norm = 4.6314e-01, time/batch = 0.6395s	
436/26050 (epoch 0.837), train_loss = 2.39826433, grad/param norm = 6.2463e-01, time/batch = 0.6396s	
437/26050 (epoch 0.839), train_loss = 2.67972548, grad/param norm = 5.7444e-01, time/batch = 0.6506s	
438/26050 (epoch 0.841), train_loss = 2.54292729, grad/param norm = 4.2551e-01, time/batch = 0.6553s	
439/26050 (epoch 0.843), train_loss = 2.50564836, grad/param norm = 3.7783e-01, time/batch = 0.6554s	
440/26050 (epoch 0.845), train_loss = 2.35850251, grad/param norm = 3.6106e-01, time/batch = 0.6543s	
441/26050 (epoch 0.846), train_loss = 2.49338605, grad/param norm = 4.3874e-01, time/batch = 0.6602s	
442/26050 (epoch 0.848), train_loss = 2.42127527, grad/param norm = 4.3783e-01, time/batch = 0.6569s	
443/26050 (epoch 0.850), train_loss = 2.34262181, grad/param norm = 4.7420e-01, time/batch = 0.6495s	
444/26050 (epoch 0.852), train_loss = 2.52362495, grad/param norm = 5.8563e-01, time/batch = 0.6830s	
445/26050 (epoch 0.854), train_loss = 2.51714127, grad/param norm = 4.0655e-01, time/batch = 0.6640s	
446/26050 (epoch 0.856), train_loss = 2.49508311, grad/param norm = 3.5591e-01, time/batch = 0.6544s	
447/26050 (epoch 0.858), train_loss = 2.33515174, grad/param norm = 4.0364e-01, time/batch = 0.6550s	
448/26050 (epoch 0.860), train_loss = 2.50962227, grad/param norm = 3.5713e-01, time/batch = 0.6685s	
449/26050 (epoch 0.862), train_loss = 2.50419090, grad/param norm = 4.2332e-01, time/batch = 0.6727s	
450/26050 (epoch 0.864), train_loss = 2.36951488, grad/param norm = 5.9922e-01, time/batch = 0.6402s	
451/26050 (epoch 0.866), train_loss = 2.41613938, grad/param norm = 5.9125e-01, time/batch = 0.6727s	
452/26050 (epoch 0.868), train_loss = 2.58616466, grad/param norm = 5.3943e-01, time/batch = 0.6593s	
453/26050 (epoch 0.869), train_loss = 2.33369401, grad/param norm = 4.3849e-01, time/batch = 0.6429s	
454/26050 (epoch 0.871), train_loss = 2.24247080, grad/param norm = 4.0876e-01, time/batch = 0.6417s	
455/26050 (epoch 0.873), train_loss = 2.31126171, grad/param norm = 6.0450e-01, time/batch = 0.6385s	
456/26050 (epoch 0.875), train_loss = 2.42917649, grad/param norm = 6.3824e-01, time/batch = 0.6404s	
457/26050 (epoch 0.877), train_loss = 2.32907314, grad/param norm = 5.2625e-01, time/batch = 0.6410s	
458/26050 (epoch 0.879), train_loss = 2.49616380, grad/param norm = 3.9845e-01, time/batch = 0.6393s	
459/26050 (epoch 0.881), train_loss = 2.51848571, grad/param norm = 3.6424e-01, time/batch = 0.6380s	
460/26050 (epoch 0.883), train_loss = 2.49194312, grad/param norm = 4.3794e-01, time/batch = 0.6446s	
461/26050 (epoch 0.885), train_loss = 2.32165265, grad/param norm = 4.8602e-01, time/batch = 0.6389s	
462/26050 (epoch 0.887), train_loss = 2.37908636, grad/param norm = 4.1828e-01, time/batch = 0.6465s	
463/26050 (epoch 0.889), train_loss = 2.33110901, grad/param norm = 4.0030e-01, time/batch = 0.6512s	
464/26050 (epoch 0.891), train_loss = 2.21691539, grad/param norm = 4.0835e-01, time/batch = 0.6465s	
465/26050 (epoch 0.893), train_loss = 2.27133017, grad/param norm = 3.2853e-01, time/batch = 0.6501s	
466/26050 (epoch 0.894), train_loss = 2.32993346, grad/param norm = 3.9583e-01, time/batch = 0.6633s	
467/26050 (epoch 0.896), train_loss = 2.37814537, grad/param norm = 3.4875e-01, time/batch = 0.6451s	
468/26050 (epoch 0.898), train_loss = 2.41073546, grad/param norm = 3.9374e-01, time/batch = 0.6483s	
469/26050 (epoch 0.900), train_loss = 2.72501084, grad/param norm = 4.1919e-01, time/batch = 0.6470s	
470/26050 (epoch 0.902), train_loss = 2.55399549, grad/param norm = 4.8249e-01, time/batch = 0.6828s	
471/26050 (epoch 0.904), train_loss = 2.52734907, grad/param norm = 3.3000e-01, time/batch = 0.6534s	
472/26050 (epoch 0.906), train_loss = 2.41811893, grad/param norm = 3.1415e-01, time/batch = 0.6469s	
473/26050 (epoch 0.908), train_loss = 2.36639485, grad/param norm = 3.5560e-01, time/batch = 0.6468s	
474/26050 (epoch 0.910), train_loss = 2.42330643, grad/param norm = 3.5356e-01, time/batch = 0.6434s	
475/26050 (epoch 0.912), train_loss = 2.68353252, grad/param norm = 4.2309e-01, time/batch = 0.6403s	
476/26050 (epoch 0.914), train_loss = 2.55079804, grad/param norm = 4.3291e-01, time/batch = 0.6448s	
477/26050 (epoch 0.916), train_loss = 2.36832533, grad/param norm = 4.5658e-01, time/batch = 0.6413s	
478/26050 (epoch 0.917), train_loss = 2.30624111, grad/param norm = 4.0551e-01, time/batch = 0.6388s	
479/26050 (epoch 0.919), train_loss = 2.43490029, grad/param norm = 3.7050e-01, time/batch = 0.6449s	
480/26050 (epoch 0.921), train_loss = 2.21877460, grad/param norm = 5.0859e-01, time/batch = 0.6423s	
481/26050 (epoch 0.923), train_loss = 2.35886130, grad/param norm = 5.5484e-01, time/batch = 0.6390s	
482/26050 (epoch 0.925), train_loss = 2.29604065, grad/param norm = 6.3670e-01, time/batch = 0.6417s	
483/26050 (epoch 0.927), train_loss = 2.36469749, grad/param norm = 5.6026e-01, time/batch = 0.6393s	
484/26050 (epoch 0.929), train_loss = 2.35621917, grad/param norm = 4.3115e-01, time/batch = 0.6385s	
485/26050 (epoch 0.931), train_loss = 2.60471978, grad/param norm = 3.4323e-01, time/batch = 0.6732s	
486/26050 (epoch 0.933), train_loss = 2.40675615, grad/param norm = 3.6735e-01, time/batch = 0.6693s	
487/26050 (epoch 0.935), train_loss = 2.19808369, grad/param norm = 3.8288e-01, time/batch = 0.6398s	
488/26050 (epoch 0.937), train_loss = 2.38864110, grad/param norm = 3.6720e-01, time/batch = 0.6400s	
489/26050 (epoch 0.939), train_loss = 2.27729238, grad/param norm = 3.3661e-01, time/batch = 0.6397s	
490/26050 (epoch 0.940), train_loss = 2.40667159, grad/param norm = 3.9087e-01, time/batch = 0.6400s	
491/26050 (epoch 0.942), train_loss = 2.45036690, grad/param norm = 3.2856e-01, time/batch = 0.6456s	
492/26050 (epoch 0.944), train_loss = 2.33936982, grad/param norm = 3.8557e-01, time/batch = 0.6412s	
493/26050 (epoch 0.946), train_loss = 2.43867175, grad/param norm = 3.8069e-01, time/batch = 0.6395s	
494/26050 (epoch 0.948), train_loss = 2.13235339, grad/param norm = 5.2574e-01, time/batch = 0.6407s	
495/26050 (epoch 0.950), train_loss = 2.38831450, grad/param norm = 6.0955e-01, time/batch = 0.6476s	
496/26050 (epoch 0.952), train_loss = 2.51636525, grad/param norm = 5.1430e-01, time/batch = 0.6414s	
497/26050 (epoch 0.954), train_loss = 2.51553380, grad/param norm = 3.3750e-01, time/batch = 0.6401s	
498/26050 (epoch 0.956), train_loss = 2.51000011, grad/param norm = 3.9084e-01, time/batch = 0.6384s	
499/26050 (epoch 0.958), train_loss = 2.50526698, grad/param norm = 3.9008e-01, time/batch = 0.6389s	
500/26050 (epoch 0.960), train_loss = 2.44068188, grad/param norm = 3.9463e-01, time/batch = 0.6540s	
501/26050 (epoch 0.962), train_loss = 2.37924688, grad/param norm = 3.7749e-01, time/batch = 0.6833s	
502/26050 (epoch 0.964), train_loss = 2.60538133, grad/param norm = 4.3047e-01, time/batch = 0.6457s	
503/26050 (epoch 0.965), train_loss = 2.26399636, grad/param norm = 3.9996e-01, time/batch = 0.6410s	
504/26050 (epoch 0.967), train_loss = 2.65409911, grad/param norm = 3.9619e-01, time/batch = 0.6436s	
505/26050 (epoch 0.969), train_loss = 2.38013669, grad/param norm = 3.5971e-01, time/batch = 0.6502s	
506/26050 (epoch 0.971), train_loss = 2.23634482, grad/param norm = 3.9090e-01, time/batch = 0.6439s	
507/26050 (epoch 0.973), train_loss = 2.27607843, grad/param norm = 4.6262e-01, time/batch = 0.6426s	
508/26050 (epoch 0.975), train_loss = 2.39049277, grad/param norm = 3.8259e-01, time/batch = 0.6418s	
509/26050 (epoch 0.977), train_loss = 2.43827486, grad/param norm = 3.6023e-01, time/batch = 0.6417s	
510/26050 (epoch 0.979), train_loss = 2.21170193, grad/param norm = 3.5970e-01, time/batch = 0.6492s	
511/26050 (epoch 0.981), train_loss = 2.38961775, grad/param norm = 3.1527e-01, time/batch = 0.6412s	
512/26050 (epoch 0.983), train_loss = 2.37425080, grad/param norm = 3.3393e-01, time/batch = 0.6387s	
513/26050 (epoch 0.985), train_loss = 2.32470865, grad/param norm = 3.6835e-01, time/batch = 0.6395s	
514/26050 (epoch 0.987), train_loss = 2.48494325, grad/param norm = 4.0800e-01, time/batch = 0.6395s	
515/26050 (epoch 0.988), train_loss = 2.58636605, grad/param norm = 5.1502e-01, time/batch = 0.6394s	
516/26050 (epoch 0.990), train_loss = 2.46128306, grad/param norm = 4.9634e-01, time/batch = 0.6808s	
517/26050 (epoch 0.992), train_loss = 2.53640406, grad/param norm = 5.3898e-01, time/batch = 0.6643s	
518/26050 (epoch 0.994), train_loss = 2.48556337, grad/param norm = 5.1439e-01, time/batch = 0.6440s	
519/26050 (epoch 0.996), train_loss = 2.51543005, grad/param norm = 3.6094e-01, time/batch = 0.6392s	
520/26050 (epoch 0.998), train_loss = 2.38092969, grad/param norm = 4.4028e-01, time/batch = 0.6382s	
521/26050 (epoch 1.000), train_loss = 2.33866769, grad/param norm = 3.9460e-01, time/batch = 0.6399s	
522/26050 (epoch 1.002), train_loss = 2.25035843, grad/param norm = 3.7718e-01, time/batch = 0.6401s	
523/26050 (epoch 1.004), train_loss = 2.30740292, grad/param norm = 4.5265e-01, time/batch = 0.6382s	
524/26050 (epoch 1.006), train_loss = 2.24580820, grad/param norm = 4.8956e-01, time/batch = 0.6379s	
525/26050 (epoch 1.008), train_loss = 2.31739893, grad/param norm = 5.2113e-01, time/batch = 0.6399s	
526/26050 (epoch 1.010), train_loss = 2.39534992, grad/param norm = 3.9526e-01, time/batch = 0.6409s	
527/26050 (epoch 1.012), train_loss = 2.42098798, grad/param norm = 2.8253e-01, time/batch = 0.6378s	
528/26050 (epoch 1.013), train_loss = 2.75496636, grad/param norm = 3.1932e-01, time/batch = 0.6378s	
529/26050 (epoch 1.015), train_loss = 2.32253103, grad/param norm = 3.5660e-01, time/batch = 0.6389s	
530/26050 (epoch 1.017), train_loss = 2.27847869, grad/param norm = 3.1391e-01, time/batch = 0.6377s	
531/26050 (epoch 1.019), train_loss = 2.36686206, grad/param norm = 2.7202e-01, time/batch = 0.6619s	
532/26050 (epoch 1.021), train_loss = 2.40662821, grad/param norm = 3.2275e-01, time/batch = 0.6816s	
533/26050 (epoch 1.023), train_loss = 2.28033824, grad/param norm = 3.2573e-01, time/batch = 0.6408s	
534/26050 (epoch 1.025), train_loss = 2.32873663, grad/param norm = 3.5302e-01, time/batch = 0.6402s	
535/26050 (epoch 1.027), train_loss = 2.25169811, grad/param norm = 4.3547e-01, time/batch = 0.6384s	
536/26050 (epoch 1.029), train_loss = 2.36724408, grad/param norm = 5.3920e-01, time/batch = 0.6394s	
537/26050 (epoch 1.031), train_loss = 2.38052672, grad/param norm = 4.9729e-01, time/batch = 0.6409s	
538/26050 (epoch 1.033), train_loss = 2.34299183, grad/param norm = 4.2406e-01, time/batch = 0.6399s	
539/26050 (epoch 1.035), train_loss = 2.50516094, grad/param norm = 3.6777e-01, time/batch = 0.6400s	
540/26050 (epoch 1.036), train_loss = 2.30844967, grad/param norm = 3.3804e-01, time/batch = 0.6431s	
541/26050 (epoch 1.038), train_loss = 2.31754817, grad/param norm = 3.1983e-01, time/batch = 0.6578s	
542/26050 (epoch 1.040), train_loss = 2.32938963, grad/param norm = 3.7920e-01, time/batch = 0.6475s	
543/26050 (epoch 1.042), train_loss = 2.23074499, grad/param norm = 4.2031e-01, time/batch = 0.6510s	
544/26050 (epoch 1.044), train_loss = 2.32166853, grad/param norm = 3.7187e-01, time/batch = 0.6451s	
545/26050 (epoch 1.046), train_loss = 2.19415549, grad/param norm = 3.2238e-01, time/batch = 0.6477s	
546/26050 (epoch 1.048), train_loss = 2.35853210, grad/param norm = 4.0707e-01, time/batch = 0.6462s	
547/26050 (epoch 1.050), train_loss = 2.16217081, grad/param norm = 4.3042e-01, time/batch = 0.6827s	
548/26050 (epoch 1.052), train_loss = 2.33311421, grad/param norm = 4.9235e-01, time/batch = 0.6576s	
549/26050 (epoch 1.054), train_loss = 2.30609877, grad/param norm = 6.3433e-01, time/batch = 0.6463s	
550/26050 (epoch 1.056), train_loss = 2.03204851, grad/param norm = 4.5064e-01, time/batch = 0.6512s	
551/26050 (epoch 1.058), train_loss = 2.27082736, grad/param norm = 4.0089e-01, time/batch = 0.6425s	
552/26050 (epoch 1.060), train_loss = 2.31014908, grad/param norm = 3.4497e-01, time/batch = 0.6416s	
553/26050 (epoch 1.061), train_loss = 2.24309386, grad/param norm = 3.2747e-01, time/batch = 0.6466s	
554/26050 (epoch 1.063), train_loss = 2.16872819, grad/param norm = 2.4357e-01, time/batch = 0.6511s	
555/26050 (epoch 1.065), train_loss = 2.31821801, grad/param norm = 3.3697e-01, time/batch = 0.6479s	
556/26050 (epoch 1.067), train_loss = 2.28967531, grad/param norm = 4.6447e-01, time/batch = 0.6433s	
557/26050 (epoch 1.069), train_loss = 2.37383712, grad/param norm = 3.2640e-01, time/batch = 0.6526s	
558/26050 (epoch 1.071), train_loss = 2.37593960, grad/param norm = 3.2271e-01, time/batch = 0.6752s	
559/26050 (epoch 1.073), train_loss = 2.47202432, grad/param norm = 3.6565e-01, time/batch = 0.6774s	
560/26050 (epoch 1.075), train_loss = 2.32203117, grad/param norm = 3.9648e-01, time/batch = 0.6744s	
561/26050 (epoch 1.077), train_loss = 2.18133961, grad/param norm = 3.2438e-01, time/batch = 0.6716s	
562/26050 (epoch 1.079), train_loss = 2.46015690, grad/param norm = 3.4988e-01, time/batch = 0.6609s	
563/26050 (epoch 1.081), train_loss = 2.25714724, grad/param norm = 2.9519e-01, time/batch = 0.6454s	
564/26050 (epoch 1.083), train_loss = 2.35374333, grad/param norm = 3.2798e-01, time/batch = 0.6395s	
565/26050 (epoch 1.084), train_loss = 2.54000759, grad/param norm = 3.0665e-01, time/batch = 0.6395s	
566/26050 (epoch 1.086), train_loss = 2.49416268, grad/param norm = 3.2226e-01, time/batch = 0.6455s	
567/26050 (epoch 1.088), train_loss = 2.25641474, grad/param norm = 3.1300e-01, time/batch = 0.6560s	
568/26050 (epoch 1.090), train_loss = 2.44308543, grad/param norm = 3.0079e-01, time/batch = 0.6427s	
569/26050 (epoch 1.092), train_loss = 2.18127903, grad/param norm = 3.1612e-01, time/batch = 0.6444s	
570/26050 (epoch 1.094), train_loss = 2.40200948, grad/param norm = 2.9970e-01, time/batch = 0.6397s	
571/26050 (epoch 1.096), train_loss = 2.11049346, grad/param norm = 3.2221e-01, time/batch = 0.6414s	
572/26050 (epoch 1.098), train_loss = 2.20630811, grad/param norm = 3.3064e-01, time/batch = 0.6527s	
573/26050 (epoch 1.100), train_loss = 2.21757543, grad/param norm = 3.7649e-01, time/batch = 0.6827s	
574/26050 (epoch 1.102), train_loss = 2.36338058, grad/param norm = 3.7357e-01, time/batch = 0.6517s	
575/26050 (epoch 1.104), train_loss = 2.42622152, grad/param norm = 3.3984e-01, time/batch = 0.6391s	
576/26050 (epoch 1.106), train_loss = 2.18676896, grad/param norm = 4.4267e-01, time/batch = 0.6395s	
577/26050 (epoch 1.107), train_loss = 2.09516207, grad/param norm = 5.1996e-01, time/batch = 0.6441s	
578/26050 (epoch 1.109), train_loss = 2.26159512, grad/param norm = 5.5613e-01, time/batch = 0.6383s	
579/26050 (epoch 1.111), train_loss = 2.53329786, grad/param norm = 4.7466e-01, time/batch = 0.6396s	
580/26050 (epoch 1.113), train_loss = 2.28441279, grad/param norm = 4.4892e-01, time/batch = 0.6398s	
581/26050 (epoch 1.115), train_loss = 2.41528990, grad/param norm = 3.8940e-01, time/batch = 0.6394s	
582/26050 (epoch 1.117), train_loss = 2.40037021, grad/param norm = 3.9118e-01, time/batch = 0.6383s	
583/26050 (epoch 1.119), train_loss = 2.31865951, grad/param norm = 3.8859e-01, time/batch = 0.6409s	
584/26050 (epoch 1.121), train_loss = 2.29733506, grad/param norm = 4.1384e-01, time/batch = 0.6392s	
585/26050 (epoch 1.123), train_loss = 2.17677019, grad/param norm = 3.6929e-01, time/batch = 0.6408s	
586/26050 (epoch 1.125), train_loss = 1.96710921, grad/param norm = 2.9627e-01, time/batch = 0.6390s	
587/26050 (epoch 1.127), train_loss = 2.19610706, grad/param norm = 2.5974e-01, time/batch = 0.6396s	
588/26050 (epoch 1.129), train_loss = 2.10225338, grad/param norm = 3.4294e-01, time/batch = 0.6729s	
589/26050 (epoch 1.131), train_loss = 2.19654565, grad/param norm = 2.8544e-01, time/batch = 0.6712s	
590/26050 (epoch 1.132), train_loss = 2.17098917, grad/param norm = 2.2778e-01, time/batch = 0.6433s	
591/26050 (epoch 1.134), train_loss = 2.18273726, grad/param norm = 2.9417e-01, time/batch = 0.6411s	
592/26050 (epoch 1.136), train_loss = 2.25134569, grad/param norm = 2.9502e-01, time/batch = 0.6413s	
593/26050 (epoch 1.138), train_loss = 2.26096973, grad/param norm = 2.7922e-01, time/batch = 0.6565s	
594/26050 (epoch 1.140), train_loss = 2.28353716, grad/param norm = 3.2420e-01, time/batch = 0.6477s	
595/26050 (epoch 1.142), train_loss = 2.24249710, grad/param norm = 3.7573e-01, time/batch = 0.6408s	
596/26050 (epoch 1.144), train_loss = 2.14572640, grad/param norm = 3.9631e-01, time/batch = 0.6390s	
597/26050 (epoch 1.146), train_loss = 2.10954105, grad/param norm = 3.6728e-01, time/batch = 0.6393s	
598/26050 (epoch 1.148), train_loss = 2.24483809, grad/param norm = 3.4593e-01, time/batch = 0.6386s	
599/26050 (epoch 1.150), train_loss = 2.25636289, grad/param norm = 3.1552e-01, time/batch = 0.6399s	
600/26050 (epoch 1.152), train_loss = 2.49533086, grad/param norm = 4.8004e-01, time/batch = 0.6408s	
601/26050 (epoch 1.154), train_loss = 2.17602018, grad/param norm = 4.5416e-01, time/batch = 0.6401s	
602/26050 (epoch 1.155), train_loss = 2.22885727, grad/param norm = 3.5456e-01, time/batch = 0.6447s	
603/26050 (epoch 1.157), train_loss = 2.23481922, grad/param norm = 2.7914e-01, time/batch = 0.6549s	
604/26050 (epoch 1.159), train_loss = 2.33270152, grad/param norm = 2.5636e-01, time/batch = 0.6826s	
605/26050 (epoch 1.161), train_loss = 2.43132350, grad/param norm = 3.0759e-01, time/batch = 0.6593s	
606/26050 (epoch 1.163), train_loss = 2.22589628, grad/param norm = 3.5607e-01, time/batch = 0.6498s	
607/26050 (epoch 1.165), train_loss = 1.96117937, grad/param norm = 4.5855e-01, time/batch = 0.6442s	
608/26050 (epoch 1.167), train_loss = 2.45271154, grad/param norm = 5.6796e-01, time/batch = 0.6402s	
609/26050 (epoch 1.169), train_loss = 2.43405262, grad/param norm = 4.3723e-01, time/batch = 0.6394s	
610/26050 (epoch 1.171), train_loss = 2.18181121, grad/param norm = 3.2751e-01, time/batch = 0.6407s	
611/26050 (epoch 1.173), train_loss = 2.24059944, grad/param norm = 3.4884e-01, time/batch = 0.6421s	
612/26050 (epoch 1.175), train_loss = 2.32907844, grad/param norm = 4.0594e-01, time/batch = 0.6463s	
613/26050 (epoch 1.177), train_loss = 2.36850041, grad/param norm = 3.5245e-01, time/batch = 0.6503s	
614/26050 (epoch 1.179), train_loss = 1.97042694, grad/param norm = 3.4069e-01, time/batch = 0.6492s	
615/26050 (epoch 1.180), train_loss = 2.38228885, grad/param norm = 3.5686e-01, time/batch = 0.6569s	
616/26050 (epoch 1.182), train_loss = 2.60751091, grad/param norm = 3.1933e-01, time/batch = 0.6619s	
617/26050 (epoch 1.184), train_loss = 2.32286969, grad/param norm = 2.9388e-01, time/batch = 0.6568s	
618/26050 (epoch 1.186), train_loss = 2.08127169, grad/param norm = 3.0864e-01, time/batch = 0.6475s	
619/26050 (epoch 1.188), train_loss = 2.17511505, grad/param norm = 3.2805e-01, time/batch = 0.6558s	
620/26050 (epoch 1.190), train_loss = 2.28360508, grad/param norm = 3.8290e-01, time/batch = 0.6471s	
621/26050 (epoch 1.192), train_loss = 2.24773512, grad/param norm = 4.1578e-01, time/batch = 0.6401s	
622/26050 (epoch 1.194), train_loss = 2.20427676, grad/param norm = 4.3589e-01, time/batch = 0.6395s	
623/26050 (epoch 1.196), train_loss = 2.39015797, grad/param norm = 4.1730e-01, time/batch = 0.6394s	
624/26050 (epoch 1.198), train_loss = 2.10906498, grad/param norm = 3.9846e-01, time/batch = 0.6384s	
625/26050 (epoch 1.200), train_loss = 2.19572027, grad/param norm = 4.7788e-01, time/batch = 0.6438s	
626/26050 (epoch 1.202), train_loss = 2.12834732, grad/param norm = 3.2794e-01, time/batch = 0.6421s	
627/26050 (epoch 1.203), train_loss = 2.23547825, grad/param norm = 3.6685e-01, time/batch = 0.6399s	
628/26050 (epoch 1.205), train_loss = 2.17745643, grad/param norm = 3.6803e-01, time/batch = 0.6410s	
629/26050 (epoch 1.207), train_loss = 2.24448639, grad/param norm = 4.0319e-01, time/batch = 0.6398s	
630/26050 (epoch 1.209), train_loss = 2.16831719, grad/param norm = 2.9287e-01, time/batch = 0.6429s	
631/26050 (epoch 1.211), train_loss = 2.19980468, grad/param norm = 2.8391e-01, time/batch = 0.6412s	
632/26050 (epoch 1.213), train_loss = 2.31046613, grad/param norm = 3.9477e-01, time/batch = 0.6441s	
633/26050 (epoch 1.215), train_loss = 2.29944254, grad/param norm = 3.7316e-01, time/batch = 0.6561s	
634/26050 (epoch 1.217), train_loss = 2.26520367, grad/param norm = 3.7182e-01, time/batch = 0.6685s	
635/26050 (epoch 1.219), train_loss = 2.16638767, grad/param norm = 3.1485e-01, time/batch = 0.6792s	
636/26050 (epoch 1.221), train_loss = 2.15366752, grad/param norm = 3.1928e-01, time/batch = 0.6452s	
637/26050 (epoch 1.223), train_loss = 2.37737327, grad/param norm = 3.3606e-01, time/batch = 0.6390s	
638/26050 (epoch 1.225), train_loss = 2.24495438, grad/param norm = 3.2017e-01, time/batch = 0.6402s	
639/26050 (epoch 1.226), train_loss = 2.32740094, grad/param norm = 3.7523e-01, time/batch = 0.6375s	
640/26050 (epoch 1.228), train_loss = 2.31172656, grad/param norm = 2.9290e-01, time/batch = 0.6460s	
641/26050 (epoch 1.230), train_loss = 2.19994695, grad/param norm = 3.1800e-01, time/batch = 0.6510s	
642/26050 (epoch 1.232), train_loss = 2.28906330, grad/param norm = 3.1445e-01, time/batch = 0.6394s	
643/26050 (epoch 1.234), train_loss = 2.05745422, grad/param norm = 2.9302e-01, time/batch = 0.6368s	
644/26050 (epoch 1.236), train_loss = 2.30019865, grad/param norm = 3.2052e-01, time/batch = 0.6367s	
645/26050 (epoch 1.238), train_loss = 2.07695857, grad/param norm = 3.4871e-01, time/batch = 0.6398s	
646/26050 (epoch 1.240), train_loss = 2.19885970, grad/param norm = 3.4703e-01, time/batch = 0.6468s	
647/26050 (epoch 1.242), train_loss = 2.25933763, grad/param norm = 2.7990e-01, time/batch = 0.6375s	
648/26050 (epoch 1.244), train_loss = 2.29077037, grad/param norm = 3.2893e-01, time/batch = 0.6378s	
649/26050 (epoch 1.246), train_loss = 2.13870377, grad/param norm = 2.9390e-01, time/batch = 0.6527s	
650/26050 (epoch 1.248), train_loss = 2.33543782, grad/param norm = 3.3333e-01, time/batch = 0.6827s	
651/26050 (epoch 1.250), train_loss = 2.27613790, grad/param norm = 3.1155e-01, time/batch = 0.6545s	
652/26050 (epoch 1.251), train_loss = 2.11764038, grad/param norm = 3.0475e-01, time/batch = 0.6381s	
653/26050 (epoch 1.253), train_loss = 2.13093851, grad/param norm = 3.3540e-01, time/batch = 0.6368s	
654/26050 (epoch 1.255), train_loss = 2.38485800, grad/param norm = 4.6231e-01, time/batch = 0.6389s	
655/26050 (epoch 1.257), train_loss = 2.24507861, grad/param norm = 5.6770e-01, time/batch = 0.6385s	
656/26050 (epoch 1.259), train_loss = 2.25864225, grad/param norm = 6.0457e-01, time/batch = 0.6402s	
657/26050 (epoch 1.261), train_loss = 2.19806014, grad/param norm = 4.4242e-01, time/batch = 0.6390s	
658/26050 (epoch 1.263), train_loss = 2.28846316, grad/param norm = 3.9545e-01, time/batch = 0.6395s	
659/26050 (epoch 1.265), train_loss = 2.38682017, grad/param norm = 3.2883e-01, time/batch = 0.6499s	
660/26050 (epoch 1.267), train_loss = 2.28016755, grad/param norm = 2.5049e-01, time/batch = 0.6426s	
661/26050 (epoch 1.269), train_loss = 2.46138679, grad/param norm = 2.7680e-01, time/batch = 0.6460s	
662/26050 (epoch 1.271), train_loss = 2.14648310, grad/param norm = 2.9827e-01, time/batch = 0.6421s	
663/26050 (epoch 1.273), train_loss = 2.41151143, grad/param norm = 3.4933e-01, time/batch = 0.6383s	
664/26050 (epoch 1.274), train_loss = 2.26042047, grad/param norm = 3.0037e-01, time/batch = 0.6387s	
665/26050 (epoch 1.276), train_loss = 2.15358291, grad/param norm = 3.4236e-01, time/batch = 0.6727s	
666/26050 (epoch 1.278), train_loss = 2.28471168, grad/param norm = 3.6789e-01, time/batch = 0.6753s	
667/26050 (epoch 1.280), train_loss = 2.10623855, grad/param norm = 3.2951e-01, time/batch = 0.6425s	
668/26050 (epoch 1.282), train_loss = 2.20590027, grad/param norm = 3.0940e-01, time/batch = 0.6385s	
669/26050 (epoch 1.284), train_loss = 2.03220603, grad/param norm = 3.0931e-01, time/batch = 0.6382s	
670/26050 (epoch 1.286), train_loss = 2.13883848, grad/param norm = 3.2562e-01, time/batch = 0.6400s	
671/26050 (epoch 1.288), train_loss = 2.14097302, grad/param norm = 3.7979e-01, time/batch = 0.6417s	
672/26050 (epoch 1.290), train_loss = 2.08051885, grad/param norm = 3.4232e-01, time/batch = 0.6399s	
673/26050 (epoch 1.292), train_loss = 2.11817535, grad/param norm = 3.7165e-01, time/batch = 0.6396s	
674/26050 (epoch 1.294), train_loss = 2.27699997, grad/param norm = 4.3855e-01, time/batch = 0.6403s	
675/26050 (epoch 1.296), train_loss = 2.31530557, grad/param norm = 3.5705e-01, time/batch = 0.6378s	
676/26050 (epoch 1.298), train_loss = 2.16496621, grad/param norm = 3.7027e-01, time/batch = 0.6423s	
677/26050 (epoch 1.299), train_loss = 1.97659219, grad/param norm = 3.4634e-01, time/batch = 0.6399s	
678/26050 (epoch 1.301), train_loss = 2.10869717, grad/param norm = 3.0050e-01, time/batch = 0.6380s	
679/26050 (epoch 1.303), train_loss = 2.25910606, grad/param norm = 3.6089e-01, time/batch = 0.6447s	
680/26050 (epoch 1.305), train_loss = 2.21132616, grad/param norm = 3.6063e-01, time/batch = 0.6420s	
681/26050 (epoch 1.307), train_loss = 1.98809460, grad/param norm = 3.1563e-01, time/batch = 0.6547s	
682/26050 (epoch 1.309), train_loss = 2.08132325, grad/param norm = 2.9504e-01, time/batch = 0.6539s	
683/26050 (epoch 1.311), train_loss = 2.40592271, grad/param norm = 2.9751e-01, time/batch = 0.6471s	
684/26050 (epoch 1.313), train_loss = 2.25640359, grad/param norm = 3.4413e-01, time/batch = 0.6402s	
685/26050 (epoch 1.315), train_loss = 2.42835461, grad/param norm = 4.6409e-01, time/batch = 0.6397s	
686/26050 (epoch 1.317), train_loss = 2.06647611, grad/param norm = 3.8418e-01, time/batch = 0.6449s	
687/26050 (epoch 1.319), train_loss = 2.16382150, grad/param norm = 3.6021e-01, time/batch = 0.6493s	
688/26050 (epoch 1.321), train_loss = 2.23505864, grad/param norm = 3.1140e-01, time/batch = 0.6510s	
689/26050 (epoch 1.322), train_loss = 2.14414327, grad/param norm = 3.2965e-01, time/batch = 0.6386s	
690/26050 (epoch 1.324), train_loss = 2.05946279, grad/param norm = 4.1098e-01, time/batch = 0.6380s	
691/26050 (epoch 1.326), train_loss = 2.38474748, grad/param norm = 5.2544e-01, time/batch = 0.6402s	
692/26050 (epoch 1.328), train_loss = 2.21540362, grad/param norm = 4.4253e-01, time/batch = 0.6383s	
693/26050 (epoch 1.330), train_loss = 2.17344701, grad/param norm = 3.7276e-01, time/batch = 0.6388s	
694/26050 (epoch 1.332), train_loss = 2.32010813, grad/param norm = 2.6325e-01, time/batch = 0.6392s	
695/26050 (epoch 1.334), train_loss = 2.16707489, grad/param norm = 2.6374e-01, time/batch = 0.6458s	
696/26050 (epoch 1.336), train_loss = 2.04404917, grad/param norm = 2.7073e-01, time/batch = 0.6759s	
697/26050 (epoch 1.338), train_loss = 2.03208005, grad/param norm = 2.7156e-01, time/batch = 0.6666s	
698/26050 (epoch 1.340), train_loss = 2.23363307, grad/param norm = 3.3502e-01, time/batch = 0.6384s	
699/26050 (epoch 1.342), train_loss = 2.19043657, grad/param norm = 3.3279e-01, time/batch = 0.6394s	
700/26050 (epoch 1.344), train_loss = 2.16842464, grad/param norm = 3.2187e-01, time/batch = 0.6400s	
701/26050 (epoch 1.345), train_loss = 2.12931315, grad/param norm = 3.3217e-01, time/batch = 0.6394s	
702/26050 (epoch 1.347), train_loss = 2.20905865, grad/param norm = 3.4892e-01, time/batch = 0.6395s	
703/26050 (epoch 1.349), train_loss = 2.15082918, grad/param norm = 3.2806e-01, time/batch = 0.6371s	
704/26050 (epoch 1.351), train_loss = 2.09177344, grad/param norm = 2.7480e-01, time/batch = 0.6370s	
705/26050 (epoch 1.353), train_loss = 2.06762987, grad/param norm = 3.2800e-01, time/batch = 0.6366s	
706/26050 (epoch 1.355), train_loss = 2.19478426, grad/param norm = 3.5649e-01, time/batch = 0.6365s	
707/26050 (epoch 1.357), train_loss = 1.99527557, grad/param norm = 3.1156e-01, time/batch = 0.6450s	
708/26050 (epoch 1.359), train_loss = 2.07214822, grad/param norm = 3.0180e-01, time/batch = 0.6410s	
709/26050 (epoch 1.361), train_loss = 1.94363523, grad/param norm = 2.9097e-01, time/batch = 0.6399s	
710/26050 (epoch 1.363), train_loss = 2.15962232, grad/param norm = 3.6998e-01, time/batch = 0.6375s	
711/26050 (epoch 1.365), train_loss = 1.95043368, grad/param norm = 3.3076e-01, time/batch = 0.6579s	
712/26050 (epoch 1.367), train_loss = 2.09740008, grad/param norm = 3.7921e-01, time/batch = 0.6832s	
713/26050 (epoch 1.369), train_loss = 2.19165065, grad/param norm = 3.6996e-01, time/batch = 0.6425s	
714/26050 (epoch 1.370), train_loss = 2.14143040, grad/param norm = 3.4022e-01, time/batch = 0.6373s	
715/26050 (epoch 1.372), train_loss = 2.36069949, grad/param norm = 3.0108e-01, time/batch = 0.6367s	
716/26050 (epoch 1.374), train_loss = 2.34581749, grad/param norm = 3.9178e-01, time/batch = 0.6427s	
717/26050 (epoch 1.376), train_loss = 2.32090124, grad/param norm = 3.3344e-01, time/batch = 0.6386s	
718/26050 (epoch 1.378), train_loss = 2.20214610, grad/param norm = 3.3716e-01, time/batch = 0.6381s	
719/26050 (epoch 1.380), train_loss = 2.26768278, grad/param norm = 4.0220e-01, time/batch = 0.6486s	
720/26050 (epoch 1.382), train_loss = 2.43318683, grad/param norm = 2.9718e-01, time/batch = 0.6530s	
721/26050 (epoch 1.384), train_loss = 2.16556824, grad/param norm = 2.7726e-01, time/batch = 0.6522s	
722/26050 (epoch 1.386), train_loss = 2.28705585, grad/param norm = 3.3092e-01, time/batch = 0.6444s	
723/26050 (epoch 1.388), train_loss = 2.07040515, grad/param norm = 2.5995e-01, time/batch = 0.6383s	
724/26050 (epoch 1.390), train_loss = 2.07878962, grad/param norm = 2.5340e-01, time/batch = 0.6383s	
725/26050 (epoch 1.392), train_loss = 2.11570736, grad/param norm = 2.9267e-01, time/batch = 0.6521s	
726/26050 (epoch 1.393), train_loss = 2.23467379, grad/param norm = 3.0826e-01, time/batch = 0.6539s	
727/26050 (epoch 1.395), train_loss = 2.18280088, grad/param norm = 2.9891e-01, time/batch = 0.6834s	
728/26050 (epoch 1.397), train_loss = 2.26893296, grad/param norm = 2.8337e-01, time/batch = 0.6603s	
729/26050 (epoch 1.399), train_loss = 2.06575329, grad/param norm = 3.3039e-01, time/batch = 0.6453s	
730/26050 (epoch 1.401), train_loss = 2.08229000, grad/param norm = 2.9341e-01, time/batch = 0.6376s	
731/26050 (epoch 1.403), train_loss = 2.10494880, grad/param norm = 3.2579e-01, time/batch = 0.6419s	
732/26050 (epoch 1.405), train_loss = 2.15686907, grad/param norm = 3.0481e-01, time/batch = 0.6407s	
733/26050 (epoch 1.407), train_loss = 2.27065618, grad/param norm = 3.3257e-01, time/batch = 0.6400s	
734/26050 (epoch 1.409), train_loss = 2.27400122, grad/param norm = 3.2171e-01, time/batch = 0.6396s	
735/26050 (epoch 1.411), train_loss = 2.17308417, grad/param norm = 2.7835e-01, time/batch = 0.6388s	
736/26050 (epoch 1.413), train_loss = 2.20772886, grad/param norm = 2.8959e-01, time/batch = 0.6374s	
737/26050 (epoch 1.415), train_loss = 2.29582553, grad/param norm = 2.8435e-01, time/batch = 0.6436s	
738/26050 (epoch 1.417), train_loss = 2.22826265, grad/param norm = 3.0949e-01, time/batch = 0.6466s	
739/26050 (epoch 1.418), train_loss = 2.23547254, grad/param norm = 2.9022e-01, time/batch = 0.6417s	
740/26050 (epoch 1.420), train_loss = 1.92302915, grad/param norm = 2.8732e-01, time/batch = 0.6539s	
741/26050 (epoch 1.422), train_loss = 2.04456337, grad/param norm = 2.6168e-01, time/batch = 0.6428s	
742/26050 (epoch 1.424), train_loss = 2.35915282, grad/param norm = 3.0439e-01, time/batch = 0.6693s	
743/26050 (epoch 1.426), train_loss = 2.30962213, grad/param norm = 3.8959e-01, time/batch = 0.6806s	
744/26050 (epoch 1.428), train_loss = 2.08124813, grad/param norm = 2.9096e-01, time/batch = 0.6644s	
745/26050 (epoch 1.430), train_loss = 2.13238861, grad/param norm = 2.8577e-01, time/batch = 0.6457s	
746/26050 (epoch 1.432), train_loss = 2.13991446, grad/param norm = 2.7300e-01, time/batch = 0.6404s	
747/26050 (epoch 1.434), train_loss = 2.37584908, grad/param norm = 3.3355e-01, time/batch = 0.6391s	
748/26050 (epoch 1.436), train_loss = 2.32771229, grad/param norm = 3.3556e-01, time/batch = 0.6450s	
749/26050 (epoch 1.438), train_loss = 2.11395268, grad/param norm = 4.0182e-01, time/batch = 0.6571s	
750/26050 (epoch 1.440), train_loss = 2.27218674, grad/param norm = 3.6794e-01, time/batch = 0.6402s	
751/26050 (epoch 1.441), train_loss = 2.12855753, grad/param norm = 4.0139e-01, time/batch = 0.6389s	
752/26050 (epoch 1.443), train_loss = 2.07527605, grad/param norm = 4.1609e-01, time/batch = 0.6375s	
753/26050 (epoch 1.445), train_loss = 2.09987163, grad/param norm = 3.6463e-01, time/batch = 0.6787s	
754/26050 (epoch 1.447), train_loss = 2.35728725, grad/param norm = 2.9834e-01, time/batch = 0.6682s	
755/26050 (epoch 1.449), train_loss = 2.02346391, grad/param norm = 2.8547e-01, time/batch = 0.6371s	
756/26050 (epoch 1.451), train_loss = 2.21445254, grad/param norm = 3.0309e-01, time/batch = 0.6475s	
757/26050 (epoch 1.453), train_loss = 1.92228479, grad/param norm = 3.0158e-01, time/batch = 0.6395s	
758/26050 (epoch 1.455), train_loss = 2.09178633, grad/param norm = 2.8418e-01, time/batch = 0.6378s	
759/26050 (epoch 1.457), train_loss = 2.12096153, grad/param norm = 3.0885e-01, time/batch = 0.6391s	
760/26050 (epoch 1.459), train_loss = 2.31097793, grad/param norm = 3.7601e-01, time/batch = 0.6388s	
761/26050 (epoch 1.461), train_loss = 2.13700962, grad/param norm = 3.2267e-01, time/batch = 0.6399s	
762/26050 (epoch 1.463), train_loss = 2.09084484, grad/param norm = 2.8260e-01, time/batch = 0.6376s	
763/26050 (epoch 1.464), train_loss = 2.22775748, grad/param norm = 3.5315e-01, time/batch = 0.6379s	
764/26050 (epoch 1.466), train_loss = 2.20528158, grad/param norm = 2.6635e-01, time/batch = 0.6379s	
765/26050 (epoch 1.468), train_loss = 2.23785826, grad/param norm = 2.9997e-01, time/batch = 0.6488s	
766/26050 (epoch 1.470), train_loss = 2.27474957, grad/param norm = 3.4615e-01, time/batch = 0.6524s	
767/26050 (epoch 1.472), train_loss = 2.41881337, grad/param norm = 3.7787e-01, time/batch = 0.6384s	
768/26050 (epoch 1.474), train_loss = 2.39439875, grad/param norm = 3.3148e-01, time/batch = 0.6364s	
769/26050 (epoch 1.476), train_loss = 2.29969420, grad/param norm = 2.9854e-01, time/batch = 0.6389s	
770/26050 (epoch 1.478), train_loss = 2.13652559, grad/param norm = 2.7478e-01, time/batch = 0.6379s	
771/26050 (epoch 1.480), train_loss = 2.19816138, grad/param norm = 2.7907e-01, time/batch = 0.6376s	
772/26050 (epoch 1.482), train_loss = 2.05421787, grad/param norm = 3.4434e-01, time/batch = 0.6444s	
773/26050 (epoch 1.484), train_loss = 2.05721029, grad/param norm = 3.0343e-01, time/batch = 0.6393s	
774/26050 (epoch 1.486), train_loss = 2.23471277, grad/param norm = 2.7193e-01, time/batch = 0.6380s	
775/26050 (epoch 1.488), train_loss = 2.44604346, grad/param norm = 2.6920e-01, time/batch = 0.6398s	
776/26050 (epoch 1.489), train_loss = 2.32440821, grad/param norm = 3.0191e-01, time/batch = 0.6383s	
777/26050 (epoch 1.491), train_loss = 2.04969906, grad/param norm = 3.3089e-01, time/batch = 0.6382s	
778/26050 (epoch 1.493), train_loss = 2.04373036, grad/param norm = 3.6772e-01, time/batch = 0.6387s	
779/26050 (epoch 1.495), train_loss = 2.19566217, grad/param norm = 3.2065e-01, time/batch = 0.6400s	
780/26050 (epoch 1.497), train_loss = 2.12473037, grad/param norm = 3.0646e-01, time/batch = 0.6399s	
781/26050 (epoch 1.499), train_loss = 2.00767691, grad/param norm = 2.6898e-01, time/batch = 0.6410s	
782/26050 (epoch 1.501), train_loss = 2.03788253, grad/param norm = 2.8335e-01, time/batch = 0.6412s	
783/26050 (epoch 1.503), train_loss = 2.23786894, grad/param norm = 4.3642e-01, time/batch = 0.6387s	
784/26050 (epoch 1.505), train_loss = 2.21403994, grad/param norm = 4.6152e-01, time/batch = 0.6779s	
785/26050 (epoch 1.507), train_loss = 2.20532288, grad/param norm = 3.0371e-01, time/batch = 0.6581s	
786/26050 (epoch 1.509), train_loss = 2.38237823, grad/param norm = 3.0241e-01, time/batch = 0.6390s	
787/26050 (epoch 1.511), train_loss = 2.03465899, grad/param norm = 2.6506e-01, time/batch = 0.6414s	
788/26050 (epoch 1.512), train_loss = 2.19045310, grad/param norm = 2.7015e-01, time/batch = 0.6508s	
789/26050 (epoch 1.514), train_loss = 2.19557877, grad/param norm = 2.8693e-01, time/batch = 0.6429s	
790/26050 (epoch 1.516), train_loss = 2.16780129, grad/param norm = 3.0964e-01, time/batch = 0.6400s	
791/26050 (epoch 1.518), train_loss = 2.15082093, grad/param norm = 2.7404e-01, time/batch = 0.6449s	
792/26050 (epoch 1.520), train_loss = 2.12980305, grad/param norm = 3.4050e-01, time/batch = 0.6536s	
793/26050 (epoch 1.522), train_loss = 2.19697946, grad/param norm = 3.3808e-01, time/batch = 0.6517s	
794/26050 (epoch 1.524), train_loss = 2.45988635, grad/param norm = 2.7739e-01, time/batch = 0.6583s	
795/26050 (epoch 1.526), train_loss = 2.23810227, grad/param norm = 3.2567e-01, time/batch = 0.6568s	
796/26050 (epoch 1.528), train_loss = 2.22578359, grad/param norm = 3.5748e-01, time/batch = 0.6500s	
797/26050 (epoch 1.530), train_loss = 2.20533093, grad/param norm = 3.0443e-01, time/batch = 0.6512s	
798/26050 (epoch 1.532), train_loss = 2.20431754, grad/param norm = 2.9982e-01, time/batch = 0.6530s	
799/26050 (epoch 1.534), train_loss = 2.21604881, grad/param norm = 3.0324e-01, time/batch = 0.6703s	
800/26050 (epoch 1.536), train_loss = 2.10533678, grad/param norm = 3.1228e-01, time/batch = 0.6800s	
801/26050 (epoch 1.537), train_loss = 2.20309339, grad/param norm = 2.6385e-01, time/batch = 0.6591s	
802/26050 (epoch 1.539), train_loss = 2.06863114, grad/param norm = 2.4601e-01, time/batch = 0.6599s	
803/26050 (epoch 1.541), train_loss = 2.21599737, grad/param norm = 2.5574e-01, time/batch = 0.6521s	
804/26050 (epoch 1.543), train_loss = 2.01844024, grad/param norm = 2.9160e-01, time/batch = 0.6507s	
805/26050 (epoch 1.545), train_loss = 2.17540182, grad/param norm = 3.6146e-01, time/batch = 0.6511s	
806/26050 (epoch 1.547), train_loss = 2.32201449, grad/param norm = 3.8186e-01, time/batch = 0.6525s	
807/26050 (epoch 1.549), train_loss = 2.09358156, grad/param norm = 3.0345e-01, time/batch = 0.6554s	
808/26050 (epoch 1.551), train_loss = 2.18977884, grad/param norm = 3.0365e-01, time/batch = 0.6491s	
809/26050 (epoch 1.553), train_loss = 2.12482251, grad/param norm = 3.4610e-01, time/batch = 0.6438s	
810/26050 (epoch 1.555), train_loss = 2.09582986, grad/param norm = 3.1053e-01, time/batch = 0.6548s	
811/26050 (epoch 1.557), train_loss = 2.20127436, grad/param norm = 2.9332e-01, time/batch = 0.6446s	
812/26050 (epoch 1.559), train_loss = 2.16433396, grad/param norm = 2.7572e-01, time/batch = 0.6404s	
813/26050 (epoch 1.560), train_loss = 2.12456856, grad/param norm = 2.9065e-01, time/batch = 0.6408s	
814/26050 (epoch 1.562), train_loss = 2.18298625, grad/param norm = 3.0767e-01, time/batch = 0.6418s	
815/26050 (epoch 1.564), train_loss = 2.32374990, grad/param norm = 2.7717e-01, time/batch = 0.6473s	
816/26050 (epoch 1.566), train_loss = 2.12592359, grad/param norm = 2.7968e-01, time/batch = 0.6431s	
817/26050 (epoch 1.568), train_loss = 2.16818561, grad/param norm = 2.9259e-01, time/batch = 0.6450s	
818/26050 (epoch 1.570), train_loss = 2.24819052, grad/param norm = 3.3611e-01, time/batch = 0.6604s	
819/26050 (epoch 1.572), train_loss = 2.28188526, grad/param norm = 2.7035e-01, time/batch = 0.6423s	
820/26050 (epoch 1.574), train_loss = 2.27068501, grad/param norm = 3.5006e-01, time/batch = 0.6532s	
821/26050 (epoch 1.576), train_loss = 2.14064849, grad/param norm = 2.9202e-01, time/batch = 0.6490s	
822/26050 (epoch 1.578), train_loss = 2.23414328, grad/param norm = 2.5736e-01, time/batch = 0.6486s	
823/26050 (epoch 1.580), train_loss = 2.04949991, grad/param norm = 2.3797e-01, time/batch = 0.6411s	
824/26050 (epoch 1.582), train_loss = 2.24461625, grad/param norm = 3.0829e-01, time/batch = 0.6398s	
825/26050 (epoch 1.583), train_loss = 2.21961668, grad/param norm = 3.0872e-01, time/batch = 0.6465s	
826/26050 (epoch 1.585), train_loss = 2.13720797, grad/param norm = 3.5323e-01, time/batch = 0.6415s	
827/26050 (epoch 1.587), train_loss = 2.21178233, grad/param norm = 3.5074e-01, time/batch = 0.6406s	
828/26050 (epoch 1.589), train_loss = 2.13440095, grad/param norm = 3.6600e-01, time/batch = 0.6422s	
829/26050 (epoch 1.591), train_loss = 2.20848369, grad/param norm = 3.3126e-01, time/batch = 0.6438s	
830/26050 (epoch 1.593), train_loss = 2.09439641, grad/param norm = 3.0907e-01, time/batch = 0.6421s	
831/26050 (epoch 1.595), train_loss = 2.24140184, grad/param norm = 3.1357e-01, time/batch = 0.6407s	
832/26050 (epoch 1.597), train_loss = 2.08264514, grad/param norm = 2.3755e-01, time/batch = 0.6410s	
833/26050 (epoch 1.599), train_loss = 1.97161870, grad/param norm = 2.3884e-01, time/batch = 0.6415s	
834/26050 (epoch 1.601), train_loss = 2.37603152, grad/param norm = 3.1579e-01, time/batch = 0.6466s	
835/26050 (epoch 1.603), train_loss = 2.24303199, grad/param norm = 4.0651e-01, time/batch = 0.6422s	
836/26050 (epoch 1.605), train_loss = 2.11155802, grad/param norm = 3.3918e-01, time/batch = 0.6418s	
837/26050 (epoch 1.607), train_loss = 2.18803674, grad/param norm = 2.8127e-01, time/batch = 0.6397s	
838/26050 (epoch 1.608), train_loss = 2.18797521, grad/param norm = 2.6739e-01, time/batch = 0.6383s	
839/26050 (epoch 1.610), train_loss = 2.10116197, grad/param norm = 2.9385e-01, time/batch = 0.6407s	
840/26050 (epoch 1.612), train_loss = 2.17710343, grad/param norm = 3.1255e-01, time/batch = 0.6406s	
841/26050 (epoch 1.614), train_loss = 2.14459120, grad/param norm = 3.3603e-01, time/batch = 0.6429s	
842/26050 (epoch 1.616), train_loss = 2.47191936, grad/param norm = 3.4808e-01, time/batch = 0.6440s	
843/26050 (epoch 1.618), train_loss = 2.02841450, grad/param norm = 3.0662e-01, time/batch = 0.6545s	
844/26050 (epoch 1.620), train_loss = 2.28417529, grad/param norm = 3.0458e-01, time/batch = 0.6516s	
845/26050 (epoch 1.622), train_loss = 1.86924974, grad/param norm = 2.6090e-01, time/batch = 0.6484s	
846/26050 (epoch 1.624), train_loss = 2.04628651, grad/param norm = 2.8609e-01, time/batch = 0.6407s	
847/26050 (epoch 1.626), train_loss = 2.15805809, grad/param norm = 3.9116e-01, time/batch = 0.6513s	
848/26050 (epoch 1.628), train_loss = 2.20175358, grad/param norm = 3.9370e-01, time/batch = 0.6589s	
849/26050 (epoch 1.630), train_loss = 2.24397348, grad/param norm = 3.3450e-01, time/batch = 0.6606s	
850/26050 (epoch 1.631), train_loss = 2.22853755, grad/param norm = 2.9915e-01, time/batch = 0.6608s	
851/26050 (epoch 1.633), train_loss = 1.98657121, grad/param norm = 2.9466e-01, time/batch = 0.6568s	
852/26050 (epoch 1.635), train_loss = 2.04035820, grad/param norm = 2.5344e-01, time/batch = 0.6581s	
853/26050 (epoch 1.637), train_loss = 2.04011580, grad/param norm = 2.9073e-01, time/batch = 0.6514s	
854/26050 (epoch 1.639), train_loss = 2.18363664, grad/param norm = 2.6885e-01, time/batch = 0.6447s	
855/26050 (epoch 1.641), train_loss = 2.02733931, grad/param norm = 2.5803e-01, time/batch = 0.6635s	
856/26050 (epoch 1.643), train_loss = 2.07754585, grad/param norm = 2.4735e-01, time/batch = 0.6613s	
857/26050 (epoch 1.645), train_loss = 2.28615849, grad/param norm = 2.8442e-01, time/batch = 0.6549s	
858/26050 (epoch 1.647), train_loss = 2.02074758, grad/param norm = 3.0626e-01, time/batch = 0.6551s	
859/26050 (epoch 1.649), train_loss = 2.22050457, grad/param norm = 3.4350e-01, time/batch = 0.6721s	
860/26050 (epoch 1.651), train_loss = 2.18694110, grad/param norm = 3.4894e-01, time/batch = 0.6577s	
861/26050 (epoch 1.653), train_loss = 2.07702829, grad/param norm = 3.5356e-01, time/batch = 0.6536s	
862/26050 (epoch 1.655), train_loss = 2.10384501, grad/param norm = 2.9082e-01, time/batch = 0.6399s	
863/26050 (epoch 1.656), train_loss = 2.11475386, grad/param norm = 2.9384e-01, time/batch = 0.6390s	
864/26050 (epoch 1.658), train_loss = 2.21664815, grad/param norm = 2.8517e-01, time/batch = 0.6432s	
865/26050 (epoch 1.660), train_loss = 2.00948011, grad/param norm = 2.7121e-01, time/batch = 0.6436s	
866/26050 (epoch 1.662), train_loss = 1.98326029, grad/param norm = 2.8024e-01, time/batch = 0.6419s	
867/26050 (epoch 1.664), train_loss = 1.93046641, grad/param norm = 3.0694e-01, time/batch = 0.6450s	
868/26050 (epoch 1.666), train_loss = 2.14062021, grad/param norm = 2.7515e-01, time/batch = 0.6427s	
869/26050 (epoch 1.668), train_loss = 1.82654992, grad/param norm = 2.7757e-01, time/batch = 0.6377s	
870/26050 (epoch 1.670), train_loss = 2.25998175, grad/param norm = 3.1735e-01, time/batch = 0.6381s	
871/26050 (epoch 1.672), train_loss = 2.07436554, grad/param norm = 2.7371e-01, time/batch = 0.6404s	
872/26050 (epoch 1.674), train_loss = 1.96924749, grad/param norm = 2.8931e-01, time/batch = 0.6400s	
873/26050 (epoch 1.676), train_loss = 2.01172000, grad/param norm = 2.7347e-01, time/batch = 0.6465s	
874/26050 (epoch 1.678), train_loss = 2.21684711, grad/param norm = 2.9871e-01, time/batch = 0.6389s	
875/26050 (epoch 1.679), train_loss = 2.14578569, grad/param norm = 3.7184e-01, time/batch = 0.6367s	
876/26050 (epoch 1.681), train_loss = 2.18654549, grad/param norm = 3.4284e-01, time/batch = 0.6694s	
877/26050 (epoch 1.683), train_loss = 1.99571553, grad/param norm = 3.4950e-01, time/batch = 0.6654s	
878/26050 (epoch 1.685), train_loss = 2.04653656, grad/param norm = 3.7057e-01, time/batch = 0.6367s	
879/26050 (epoch 1.687), train_loss = 1.91360591, grad/param norm = 3.5725e-01, time/batch = 0.6373s	
880/26050 (epoch 1.689), train_loss = 2.04137659, grad/param norm = 3.1320e-01, time/batch = 0.6433s	
881/26050 (epoch 1.691), train_loss = 1.91853581, grad/param norm = 2.6160e-01, time/batch = 0.6385s	
882/26050 (epoch 1.693), train_loss = 2.06301263, grad/param norm = 2.7857e-01, time/batch = 0.6377s	
883/26050 (epoch 1.695), train_loss = 2.10751421, grad/param norm = 2.7638e-01, time/batch = 0.6370s	
884/26050 (epoch 1.697), train_loss = 1.97013050, grad/param norm = 3.1538e-01, time/batch = 0.6386s	
885/26050 (epoch 1.699), train_loss = 2.09761650, grad/param norm = 2.7527e-01, time/batch = 0.6373s	
886/26050 (epoch 1.701), train_loss = 1.93480091, grad/param norm = 2.7303e-01, time/batch = 0.6377s	
887/26050 (epoch 1.702), train_loss = 2.29409094, grad/param norm = 3.1920e-01, time/batch = 0.6394s	
888/26050 (epoch 1.704), train_loss = 2.10616415, grad/param norm = 2.6770e-01, time/batch = 0.6383s	
889/26050 (epoch 1.706), train_loss = 2.14053959, grad/param norm = 2.6064e-01, time/batch = 0.6390s	
890/26050 (epoch 1.708), train_loss = 2.05831945, grad/param norm = 2.1358e-01, time/batch = 0.6380s	
891/26050 (epoch 1.710), train_loss = 2.25063355, grad/param norm = 2.6804e-01, time/batch = 0.6507s	
892/26050 (epoch 1.712), train_loss = 2.26959817, grad/param norm = 2.4444e-01, time/batch = 0.6781s	
893/26050 (epoch 1.714), train_loss = 2.01314770, grad/param norm = 2.8988e-01, time/batch = 0.6446s	
894/26050 (epoch 1.716), train_loss = 2.33618205, grad/param norm = 3.3205e-01, time/batch = 0.6386s	
895/26050 (epoch 1.718), train_loss = 2.11578701, grad/param norm = 3.2880e-01, time/batch = 0.6470s	
896/26050 (epoch 1.720), train_loss = 1.89699377, grad/param norm = 2.6542e-01, time/batch = 0.6394s	
897/26050 (epoch 1.722), train_loss = 2.07508566, grad/param norm = 2.9298e-01, time/batch = 0.6386s	
898/26050 (epoch 1.724), train_loss = 1.95849693, grad/param norm = 3.3460e-01, time/batch = 0.6386s	
899/26050 (epoch 1.726), train_loss = 2.18416409, grad/param norm = 3.2226e-01, time/batch = 0.6374s	
900/26050 (epoch 1.727), train_loss = 2.15567917, grad/param norm = 2.9129e-01, time/batch = 0.6382s	
901/26050 (epoch 1.729), train_loss = 2.16824104, grad/param norm = 2.5986e-01, time/batch = 0.6403s	
902/26050 (epoch 1.731), train_loss = 2.01587435, grad/param norm = 2.5495e-01, time/batch = 0.6401s	
903/26050 (epoch 1.733), train_loss = 2.08205257, grad/param norm = 2.7974e-01, time/batch = 0.6389s	
904/26050 (epoch 1.735), train_loss = 2.26354599, grad/param norm = 2.7111e-01, time/batch = 0.6386s	
905/26050 (epoch 1.737), train_loss = 2.16852070, grad/param norm = 2.4148e-01, time/batch = 0.6378s	
906/26050 (epoch 1.739), train_loss = 2.12763029, grad/param norm = 2.5261e-01, time/batch = 0.6380s	
907/26050 (epoch 1.741), train_loss = 1.94305938, grad/param norm = 2.5461e-01, time/batch = 0.6741s	
908/26050 (epoch 1.743), train_loss = 2.26952361, grad/param norm = 3.3760e-01, time/batch = 0.6612s	
909/26050 (epoch 1.745), train_loss = 1.95560272, grad/param norm = 2.8396e-01, time/batch = 0.6454s	
910/26050 (epoch 1.747), train_loss = 2.02860549, grad/param norm = 3.2095e-01, time/batch = 0.6592s	
911/26050 (epoch 1.749), train_loss = 2.12758275, grad/param norm = 4.2131e-01, time/batch = 0.6535s	
912/26050 (epoch 1.750), train_loss = 1.99508024, grad/param norm = 2.9522e-01, time/batch = 0.6717s	
913/26050 (epoch 1.752), train_loss = 2.15160097, grad/param norm = 2.5005e-01, time/batch = 0.6802s	
914/26050 (epoch 1.754), train_loss = 1.89507628, grad/param norm = 2.5065e-01, time/batch = 0.6757s	
915/26050 (epoch 1.756), train_loss = 2.20260417, grad/param norm = 2.3766e-01, time/batch = 0.6461s	
916/26050 (epoch 1.758), train_loss = 2.16030799, grad/param norm = 3.4877e-01, time/batch = 0.6405s	
917/26050 (epoch 1.760), train_loss = 2.01912961, grad/param norm = 3.1093e-01, time/batch = 0.6406s	
918/26050 (epoch 1.762), train_loss = 2.11115939, grad/param norm = 2.8093e-01, time/batch = 0.6428s	
919/26050 (epoch 1.764), train_loss = 2.16652307, grad/param norm = 2.6607e-01, time/batch = 0.6409s	
920/26050 (epoch 1.766), train_loss = 2.08886877, grad/param norm = 2.6036e-01, time/batch = 0.6470s	
921/26050 (epoch 1.768), train_loss = 2.01691718, grad/param norm = 2.5969e-01, time/batch = 0.6404s	
922/26050 (epoch 1.770), train_loss = 2.07476091, grad/param norm = 2.8921e-01, time/batch = 0.6416s	
923/26050 (epoch 1.772), train_loss = 2.08968238, grad/param norm = 2.5344e-01, time/batch = 0.6415s	
924/26050 (epoch 1.774), train_loss = 2.01011361, grad/param norm = 2.7335e-01, time/batch = 0.6408s	
925/26050 (epoch 1.775), train_loss = 1.90322923, grad/param norm = 2.6654e-01, time/batch = 0.6418s	
926/26050 (epoch 1.777), train_loss = 1.95739232, grad/param norm = 3.1260e-01, time/batch = 0.6555s	
927/26050 (epoch 1.779), train_loss = 2.14394639, grad/param norm = 3.1965e-01, time/batch = 0.6610s	
928/26050 (epoch 1.781), train_loss = 2.03408069, grad/param norm = 3.3075e-01, time/batch = 0.6589s	
929/26050 (epoch 1.783), train_loss = 2.00255463, grad/param norm = 2.7768e-01, time/batch = 0.6642s	
930/26050 (epoch 1.785), train_loss = 2.01973482, grad/param norm = 3.0602e-01, time/batch = 0.6682s	
931/26050 (epoch 1.787), train_loss = 2.02806862, grad/param norm = 3.3855e-01, time/batch = 0.6564s	
932/26050 (epoch 1.789), train_loss = 2.16631173, grad/param norm = 3.5646e-01, time/batch = 0.6529s	
933/26050 (epoch 1.791), train_loss = 2.10148869, grad/param norm = 2.8392e-01, time/batch = 0.6824s	
934/26050 (epoch 1.793), train_loss = 1.99397580, grad/param norm = 2.6645e-01, time/batch = 0.6704s	
935/26050 (epoch 1.795), train_loss = 2.00639828, grad/param norm = 3.2098e-01, time/batch = 0.6567s	
936/26050 (epoch 1.797), train_loss = 1.90199634, grad/param norm = 2.8410e-01, time/batch = 0.6547s	
937/26050 (epoch 1.798), train_loss = 1.88506205, grad/param norm = 2.3178e-01, time/batch = 0.6555s	
938/26050 (epoch 1.800), train_loss = 1.93432069, grad/param norm = 2.5186e-01, time/batch = 0.6571s	
939/26050 (epoch 1.802), train_loss = 2.09127492, grad/param norm = 2.6879e-01, time/batch = 0.6488s	
940/26050 (epoch 1.804), train_loss = 2.13530170, grad/param norm = 2.7523e-01, time/batch = 0.6408s	
941/26050 (epoch 1.806), train_loss = 2.17518973, grad/param norm = 3.0338e-01, time/batch = 0.6482s	
942/26050 (epoch 1.808), train_loss = 1.92720856, grad/param norm = 2.9696e-01, time/batch = 0.6414s	
943/26050 (epoch 1.810), train_loss = 2.02799609, grad/param norm = 3.4249e-01, time/batch = 0.6417s	
944/26050 (epoch 1.812), train_loss = 1.90404010, grad/param norm = 3.0707e-01, time/batch = 0.6397s	
945/26050 (epoch 1.814), train_loss = 1.98374747, grad/param norm = 2.9705e-01, time/batch = 0.6392s	
946/26050 (epoch 1.816), train_loss = 2.07524216, grad/param norm = 2.6162e-01, time/batch = 0.6401s	
947/26050 (epoch 1.818), train_loss = 2.15134384, grad/param norm = 3.0909e-01, time/batch = 0.6418s	
948/26050 (epoch 1.820), train_loss = 2.07670946, grad/param norm = 2.6210e-01, time/batch = 0.6670s	
949/26050 (epoch 1.821), train_loss = 2.17262606, grad/param norm = 2.8526e-01, time/batch = 0.6753s	
950/26050 (epoch 1.823), train_loss = 2.22853642, grad/param norm = 3.2529e-01, time/batch = 0.6411s	
951/26050 (epoch 1.825), train_loss = 2.05747269, grad/param norm = 2.8458e-01, time/batch = 0.6403s	
952/26050 (epoch 1.827), train_loss = 2.14565993, grad/param norm = 3.2197e-01, time/batch = 0.6412s	
953/26050 (epoch 1.829), train_loss = 2.09580532, grad/param norm = 2.6858e-01, time/batch = 0.6407s	
954/26050 (epoch 1.831), train_loss = 2.17159001, grad/param norm = 2.5736e-01, time/batch = 0.6410s	
955/26050 (epoch 1.833), train_loss = 2.20356474, grad/param norm = 2.8251e-01, time/batch = 0.6395s	
956/26050 (epoch 1.835), train_loss = 2.29094386, grad/param norm = 2.5776e-01, time/batch = 0.6411s	
957/26050 (epoch 1.837), train_loss = 1.96900184, grad/param norm = 2.9834e-01, time/batch = 0.6452s	
958/26050 (epoch 1.839), train_loss = 2.25520213, grad/param norm = 3.3050e-01, time/batch = 0.6384s	
959/26050 (epoch 1.841), train_loss = 2.17911708, grad/param norm = 3.2967e-01, time/batch = 0.6388s	
960/26050 (epoch 1.843), train_loss = 2.12049620, grad/param norm = 2.8325e-01, time/batch = 0.6406s	
961/26050 (epoch 1.845), train_loss = 1.98356162, grad/param norm = 2.8085e-01, time/batch = 0.6409s	
962/26050 (epoch 1.846), train_loss = 2.14028311, grad/param norm = 2.9994e-01, time/batch = 0.6409s	
963/26050 (epoch 1.848), train_loss = 1.99587272, grad/param norm = 2.6331e-01, time/batch = 0.6499s	
964/26050 (epoch 1.850), train_loss = 1.98048979, grad/param norm = 2.5781e-01, time/batch = 0.6838s	
965/26050 (epoch 1.852), train_loss = 2.06091968, grad/param norm = 3.0678e-01, time/batch = 0.6507s	
966/26050 (epoch 1.854), train_loss = 2.06226978, grad/param norm = 2.8008e-01, time/batch = 0.6387s	
967/26050 (epoch 1.856), train_loss = 2.05538672, grad/param norm = 2.6537e-01, time/batch = 0.6383s	
968/26050 (epoch 1.858), train_loss = 1.84984200, grad/param norm = 2.7167e-01, time/batch = 0.6389s	
969/26050 (epoch 1.860), train_loss = 2.09382186, grad/param norm = 2.8021e-01, time/batch = 0.6394s	
970/26050 (epoch 1.862), train_loss = 2.10348948, grad/param norm = 2.9895e-01, time/batch = 0.6386s	
971/26050 (epoch 1.864), train_loss = 1.96075220, grad/param norm = 2.8590e-01, time/batch = 0.6434s	
972/26050 (epoch 1.866), train_loss = 1.94981597, grad/param norm = 2.9426e-01, time/batch = 0.6428s	
973/26050 (epoch 1.868), train_loss = 2.22564943, grad/param norm = 3.3131e-01, time/batch = 0.6389s	
974/26050 (epoch 1.869), train_loss = 1.89590956, grad/param norm = 3.0562e-01, time/batch = 0.6387s	
975/26050 (epoch 1.871), train_loss = 1.81113240, grad/param norm = 3.1669e-01, time/batch = 0.6388s	
976/26050 (epoch 1.873), train_loss = 1.92097090, grad/param norm = 3.1767e-01, time/batch = 0.6394s	
977/26050 (epoch 1.875), train_loss = 2.01817119, grad/param norm = 3.4599e-01, time/batch = 0.6407s	
978/26050 (epoch 1.877), train_loss = 1.86094828, grad/param norm = 3.3194e-01, time/batch = 0.6402s	
979/26050 (epoch 1.879), train_loss = 2.01308444, grad/param norm = 2.9228e-01, time/batch = 0.6718s	
980/26050 (epoch 1.881), train_loss = 2.18470841, grad/param norm = 2.8316e-01, time/batch = 0.6716s	
981/26050 (epoch 1.883), train_loss = 2.06261188, grad/param norm = 2.7577e-01, time/batch = 0.6398s	
982/26050 (epoch 1.885), train_loss = 1.85909150, grad/param norm = 2.8929e-01, time/batch = 0.6404s	
983/26050 (epoch 1.887), train_loss = 2.02625563, grad/param norm = 2.4670e-01, time/batch = 0.6398s	
984/26050 (epoch 1.889), train_loss = 1.89067690, grad/param norm = 2.4916e-01, time/batch = 0.6399s	
985/26050 (epoch 1.891), train_loss = 1.79884097, grad/param norm = 2.7853e-01, time/batch = 0.6413s	
986/26050 (epoch 1.893), train_loss = 1.80557887, grad/param norm = 2.2570e-01, time/batch = 0.6492s	
987/26050 (epoch 1.894), train_loss = 1.87390360, grad/param norm = 2.5170e-01, time/batch = 0.6431s	
988/26050 (epoch 1.896), train_loss = 2.06317367, grad/param norm = 2.8452e-01, time/batch = 0.6418s	
989/26050 (epoch 1.898), train_loss = 1.98180410, grad/param norm = 3.0015e-01, time/batch = 0.6397s	
990/26050 (epoch 1.900), train_loss = 2.31955268, grad/param norm = 3.0100e-01, time/batch = 0.6406s	
991/26050 (epoch 1.902), train_loss = 2.10609692, grad/param norm = 2.5110e-01, time/batch = 0.6412s	
992/26050 (epoch 1.904), train_loss = 2.07583652, grad/param norm = 2.6438e-01, time/batch = 0.6397s	
993/26050 (epoch 1.906), train_loss = 2.04442058, grad/param norm = 2.6588e-01, time/batch = 0.6404s	
994/26050 (epoch 1.908), train_loss = 2.00115874, grad/param norm = 2.8665e-01, time/batch = 0.6426s	
995/26050 (epoch 1.910), train_loss = 1.98117342, grad/param norm = 2.5116e-01, time/batch = 0.6424s	
996/26050 (epoch 1.912), train_loss = 2.33909460, grad/param norm = 2.9603e-01, time/batch = 0.6410s	
997/26050 (epoch 1.914), train_loss = 2.28728132, grad/param norm = 2.4879e-01, time/batch = 0.6392s	
998/26050 (epoch 1.916), train_loss = 2.06481126, grad/param norm = 2.3045e-01, time/batch = 0.6389s	
999/26050 (epoch 1.917), train_loss = 1.95064536, grad/param norm = 2.4634e-01, time/batch = 0.6395s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch1.92_2.0736.t7	
1000/26050 (epoch 1.919), train_loss = 2.06385295, grad/param norm = 2.6302e-01, time/batch = 0.6432s	
1001/26050 (epoch 1.921), train_loss = 1.90019157, grad/param norm = 2.6848e-01, time/batch = 0.6487s	
1002/26050 (epoch 1.923), train_loss = 1.94138740, grad/param norm = 2.9850e-01, time/batch = 0.6446s	
1003/26050 (epoch 1.925), train_loss = 1.86903585, grad/param norm = 2.9899e-01, time/batch = 0.6430s	
1004/26050 (epoch 1.927), train_loss = 1.92331892, grad/param norm = 2.6684e-01, time/batch = 0.6420s	
1005/26050 (epoch 1.929), train_loss = 1.95146777, grad/param norm = 2.5754e-01, time/batch = 0.6493s	
1006/26050 (epoch 1.931), train_loss = 2.27888274, grad/param norm = 2.8986e-01, time/batch = 0.6500s	
1007/26050 (epoch 1.933), train_loss = 2.01990177, grad/param norm = 2.9838e-01, time/batch = 0.6491s	
1008/26050 (epoch 1.935), train_loss = 1.81264368, grad/param norm = 2.8615e-01, time/batch = 0.6515s	
1009/26050 (epoch 1.937), train_loss = 1.94343475, grad/param norm = 2.7150e-01, time/batch = 0.6459s	
1010/26050 (epoch 1.939), train_loss = 1.88525382, grad/param norm = 2.7564e-01, time/batch = 0.6509s	
1011/26050 (epoch 1.940), train_loss = 2.07585518, grad/param norm = 2.8079e-01, time/batch = 0.6436s	
1012/26050 (epoch 1.942), train_loss = 2.05272457, grad/param norm = 2.6779e-01, time/batch = 0.6417s	
1013/26050 (epoch 1.944), train_loss = 1.95598182, grad/param norm = 3.0365e-01, time/batch = 0.6440s	
1014/26050 (epoch 1.946), train_loss = 2.11346670, grad/param norm = 2.9459e-01, time/batch = 0.6424s	
1015/26050 (epoch 1.948), train_loss = 1.76610882, grad/param norm = 3.2253e-01, time/batch = 0.6411s	
1016/26050 (epoch 1.950), train_loss = 1.96680731, grad/param norm = 3.4827e-01, time/batch = 0.6416s	
1017/26050 (epoch 1.952), train_loss = 2.16661191, grad/param norm = 3.1260e-01, time/batch = 0.6481s	
1018/26050 (epoch 1.954), train_loss = 2.17331350, grad/param norm = 2.5520e-01, time/batch = 0.6823s	
1019/26050 (epoch 1.956), train_loss = 2.13477751, grad/param norm = 2.3335e-01, time/batch = 0.6555s	
1020/26050 (epoch 1.958), train_loss = 2.08777987, grad/param norm = 2.8127e-01, time/batch = 0.6402s	
1021/26050 (epoch 1.960), train_loss = 2.00161774, grad/param norm = 3.0942e-01, time/batch = 0.6415s	
1022/26050 (epoch 1.962), train_loss = 1.98679798, grad/param norm = 2.8179e-01, time/batch = 0.6407s	
1023/26050 (epoch 1.964), train_loss = 2.13806527, grad/param norm = 3.4880e-01, time/batch = 0.6409s	
1024/26050 (epoch 1.965), train_loss = 1.88270577, grad/param norm = 2.7878e-01, time/batch = 0.6465s	
1025/26050 (epoch 1.967), train_loss = 2.36833072, grad/param norm = 2.8678e-01, time/batch = 0.6491s	
1026/26050 (epoch 1.969), train_loss = 1.96919282, grad/param norm = 2.7864e-01, time/batch = 0.6519s	
1027/26050 (epoch 1.971), train_loss = 1.83360504, grad/param norm = 2.7422e-01, time/batch = 0.6415s	
1028/26050 (epoch 1.973), train_loss = 1.92259859, grad/param norm = 2.4201e-01, time/batch = 0.6556s	
1029/26050 (epoch 1.975), train_loss = 2.09163103, grad/param norm = 2.6182e-01, time/batch = 0.6824s	
1030/26050 (epoch 1.977), train_loss = 2.04967815, grad/param norm = 2.2420e-01, time/batch = 0.6444s	
1031/26050 (epoch 1.979), train_loss = 1.79720210, grad/param norm = 2.4434e-01, time/batch = 0.6403s	
1032/26050 (epoch 1.981), train_loss = 2.06438817, grad/param norm = 2.6207e-01, time/batch = 0.6422s	
1033/26050 (epoch 1.983), train_loss = 2.06354557, grad/param norm = 3.3542e-01, time/batch = 0.6416s	
1034/26050 (epoch 1.985), train_loss = 2.04710455, grad/param norm = 3.0819e-01, time/batch = 0.6407s	
1035/26050 (epoch 1.987), train_loss = 2.16502001, grad/param norm = 3.0876e-01, time/batch = 0.6394s	
1036/26050 (epoch 1.988), train_loss = 2.21007527, grad/param norm = 3.3973e-01, time/batch = 0.6401s	
1037/26050 (epoch 1.990), train_loss = 2.03162313, grad/param norm = 3.3952e-01, time/batch = 0.6423s	
1038/26050 (epoch 1.992), train_loss = 2.25539326, grad/param norm = 2.9119e-01, time/batch = 0.6406s	
1039/26050 (epoch 1.994), train_loss = 2.02646734, grad/param norm = 2.8628e-01, time/batch = 0.6411s	
1040/26050 (epoch 1.996), train_loss = 2.17330033, grad/param norm = 3.0628e-01, time/batch = 0.6389s	
1041/26050 (epoch 1.998), train_loss = 2.07188357, grad/param norm = 2.6972e-01, time/batch = 0.6450s	
1042/26050 (epoch 2.000), train_loss = 1.94571338, grad/param norm = 2.4139e-01, time/batch = 0.6470s	
1043/26050 (epoch 2.002), train_loss = 1.90822396, grad/param norm = 2.1756e-01, time/batch = 0.6416s	
1044/26050 (epoch 2.004), train_loss = 1.94086211, grad/param norm = 2.4659e-01, time/batch = 0.6814s	
1045/26050 (epoch 2.006), train_loss = 1.82863620, grad/param norm = 2.2794e-01, time/batch = 0.6619s	
1046/26050 (epoch 2.008), train_loss = 1.88340693, grad/param norm = 2.4654e-01, time/batch = 0.6410s	
1047/26050 (epoch 2.010), train_loss = 1.97896139, grad/param norm = 2.2858e-01, time/batch = 0.6411s	
1048/26050 (epoch 2.012), train_loss = 2.08801525, grad/param norm = 2.8948e-01, time/batch = 0.6423s	
1049/26050 (epoch 2.013), train_loss = 2.48977647, grad/param norm = 2.8737e-01, time/batch = 0.6424s	
1050/26050 (epoch 2.015), train_loss = 1.93071955, grad/param norm = 2.6337e-01, time/batch = 0.6415s	
1051/26050 (epoch 2.017), train_loss = 1.93974190, grad/param norm = 2.5039e-01, time/batch = 0.6423s	
1052/26050 (epoch 2.019), train_loss = 1.95170660, grad/param norm = 2.3640e-01, time/batch = 0.6397s	
1053/26050 (epoch 2.021), train_loss = 2.09705461, grad/param norm = 2.9721e-01, time/batch = 0.6401s	
1054/26050 (epoch 2.023), train_loss = 1.90682080, grad/param norm = 2.6522e-01, time/batch = 0.6450s	
1055/26050 (epoch 2.025), train_loss = 1.97288183, grad/param norm = 2.9411e-01, time/batch = 0.6394s	
1056/26050 (epoch 2.027), train_loss = 1.86659444, grad/param norm = 3.2417e-01, time/batch = 0.6525s	
1057/26050 (epoch 2.029), train_loss = 1.98299364, grad/param norm = 3.4879e-01, time/batch = 0.6443s	
1058/26050 (epoch 2.031), train_loss = 2.15001926, grad/param norm = 3.2719e-01, time/batch = 0.6421s	
1059/26050 (epoch 2.033), train_loss = 2.04595737, grad/param norm = 3.0478e-01, time/batch = 0.6620s	
1060/26050 (epoch 2.035), train_loss = 2.21061794, grad/param norm = 2.9419e-01, time/batch = 0.6790s	
1061/26050 (epoch 2.036), train_loss = 1.99071515, grad/param norm = 2.7204e-01, time/batch = 0.6421s	
1062/26050 (epoch 2.038), train_loss = 1.85187547, grad/param norm = 2.7781e-01, time/batch = 0.6415s	
1063/26050 (epoch 2.040), train_loss = 2.04431070, grad/param norm = 2.3821e-01, time/batch = 0.6406s	
1064/26050 (epoch 2.042), train_loss = 1.79878227, grad/param norm = 2.4841e-01, time/batch = 0.6408s	
1065/26050 (epoch 2.044), train_loss = 2.04796976, grad/param norm = 2.5282e-01, time/batch = 0.6405s	
1066/26050 (epoch 2.046), train_loss = 1.81052328, grad/param norm = 2.7369e-01, time/batch = 0.6495s	
1067/26050 (epoch 2.048), train_loss = 1.99449321, grad/param norm = 2.7898e-01, time/batch = 0.6515s	
1068/26050 (epoch 2.050), train_loss = 1.80701832, grad/param norm = 2.5693e-01, time/batch = 0.6402s	
1069/26050 (epoch 2.052), train_loss = 1.98593801, grad/param norm = 2.8975e-01, time/batch = 0.6395s	
1070/26050 (epoch 2.054), train_loss = 1.89619486, grad/param norm = 3.5689e-01, time/batch = 0.6419s	
1071/26050 (epoch 2.056), train_loss = 1.62631819, grad/param norm = 2.8386e-01, time/batch = 0.6413s	
1072/26050 (epoch 2.058), train_loss = 1.91701981, grad/param norm = 2.8970e-01, time/batch = 0.6466s	
1073/26050 (epoch 2.060), train_loss = 1.95595572, grad/param norm = 2.5040e-01, time/batch = 0.6414s	
1074/26050 (epoch 2.061), train_loss = 1.83112257, grad/param norm = 2.6129e-01, time/batch = 0.6407s	
1075/26050 (epoch 2.063), train_loss = 1.81546431, grad/param norm = 2.1132e-01, time/batch = 0.6394s	
1076/26050 (epoch 2.065), train_loss = 1.94520520, grad/param norm = 2.4915e-01, time/batch = 0.6395s	
1077/26050 (epoch 2.067), train_loss = 2.00191016, grad/param norm = 2.8189e-01, time/batch = 0.6408s	
1078/26050 (epoch 2.069), train_loss = 2.05518241, grad/param norm = 2.5583e-01, time/batch = 0.6393s	
1079/26050 (epoch 2.071), train_loss = 2.03848397, grad/param norm = 2.6836e-01, time/batch = 0.6422s	
1080/26050 (epoch 2.073), train_loss = 2.14860217, grad/param norm = 2.8866e-01, time/batch = 0.6399s	
1081/26050 (epoch 2.075), train_loss = 1.89974311, grad/param norm = 2.6195e-01, time/batch = 0.6444s	
1082/26050 (epoch 2.077), train_loss = 1.84068640, grad/param norm = 2.6110e-01, time/batch = 0.6494s	
1083/26050 (epoch 2.079), train_loss = 2.11017376, grad/param norm = 2.8943e-01, time/batch = 0.6444s	
1084/26050 (epoch 2.081), train_loss = 1.92090949, grad/param norm = 2.5186e-01, time/batch = 0.6407s	
1085/26050 (epoch 2.083), train_loss = 2.05353382, grad/param norm = 2.7164e-01, time/batch = 0.6554s	
1086/26050 (epoch 2.084), train_loss = 2.23519250, grad/param norm = 2.7995e-01, time/batch = 0.6828s	
1087/26050 (epoch 2.086), train_loss = 2.18689306, grad/param norm = 2.7269e-01, time/batch = 0.6635s	
1088/26050 (epoch 2.088), train_loss = 1.86140415, grad/param norm = 2.6396e-01, time/batch = 0.6487s	
1089/26050 (epoch 2.090), train_loss = 2.20136132, grad/param norm = 2.7953e-01, time/batch = 0.6517s	
1090/26050 (epoch 2.092), train_loss = 1.88345646, grad/param norm = 2.8110e-01, time/batch = 0.6500s	
1091/26050 (epoch 2.094), train_loss = 2.06170576, grad/param norm = 2.4936e-01, time/batch = 0.6521s	
1092/26050 (epoch 2.096), train_loss = 1.74670774, grad/param norm = 2.4489e-01, time/batch = 0.6417s	
1093/26050 (epoch 2.098), train_loss = 1.85175654, grad/param norm = 2.3471e-01, time/batch = 0.6567s	
1094/26050 (epoch 2.100), train_loss = 1.89055926, grad/param norm = 2.7665e-01, time/batch = 0.6480s	
1095/26050 (epoch 2.102), train_loss = 2.00707418, grad/param norm = 2.4830e-01, time/batch = 0.6432s	
1096/26050 (epoch 2.104), train_loss = 2.07585897, grad/param norm = 2.5209e-01, time/batch = 0.6412s	
1097/26050 (epoch 2.106), train_loss = 1.87469010, grad/param norm = 2.8745e-01, time/batch = 0.6397s	
1098/26050 (epoch 2.107), train_loss = 1.69351515, grad/param norm = 2.9660e-01, time/batch = 0.6387s	
1099/26050 (epoch 2.109), train_loss = 1.85491286, grad/param norm = 2.7303e-01, time/batch = 0.6436s	
1100/26050 (epoch 2.111), train_loss = 2.26799734, grad/param norm = 2.6082e-01, time/batch = 0.6422s	
1101/26050 (epoch 2.113), train_loss = 1.94268171, grad/param norm = 3.0412e-01, time/batch = 0.6450s	
1102/26050 (epoch 2.115), train_loss = 2.13336099, grad/param norm = 2.5829e-01, time/batch = 0.6448s	
1103/26050 (epoch 2.117), train_loss = 2.02507390, grad/param norm = 2.8689e-01, time/batch = 0.6485s	
1104/26050 (epoch 2.119), train_loss = 1.90490742, grad/param norm = 2.7397e-01, time/batch = 0.6446s	
1105/26050 (epoch 2.121), train_loss = 1.99190049, grad/param norm = 2.9301e-01, time/batch = 0.6403s	
1106/26050 (epoch 2.123), train_loss = 1.85533611, grad/param norm = 2.5744e-01, time/batch = 0.6490s	
1107/26050 (epoch 2.125), train_loss = 1.59932279, grad/param norm = 2.2326e-01, time/batch = 0.6450s	
1108/26050 (epoch 2.127), train_loss = 1.83146301, grad/param norm = 2.3120e-01, time/batch = 0.6434s	
1109/26050 (epoch 2.129), train_loss = 1.76386251, grad/param norm = 2.5112e-01, time/batch = 0.6464s	
1110/26050 (epoch 2.131), train_loss = 1.88603525, grad/param norm = 2.3760e-01, time/batch = 0.6453s	
1111/26050 (epoch 2.132), train_loss = 1.84287659, grad/param norm = 2.2860e-01, time/batch = 0.6458s	
1112/26050 (epoch 2.134), train_loss = 1.90974943, grad/param norm = 2.3996e-01, time/batch = 0.6420s	
1113/26050 (epoch 2.136), train_loss = 1.89671973, grad/param norm = 2.2872e-01, time/batch = 0.6413s	
1114/26050 (epoch 2.138), train_loss = 1.90473761, grad/param norm = 2.6136e-01, time/batch = 0.6415s	
1115/26050 (epoch 2.140), train_loss = 1.97052413, grad/param norm = 2.8790e-01, time/batch = 0.6442s	
1116/26050 (epoch 2.142), train_loss = 1.94347331, grad/param norm = 3.1248e-01, time/batch = 0.6412s	
1117/26050 (epoch 2.144), train_loss = 1.82689853, grad/param norm = 2.8492e-01, time/batch = 0.6406s	
1118/26050 (epoch 2.146), train_loss = 1.74043721, grad/param norm = 2.6456e-01, time/batch = 0.6419s	
1119/26050 (epoch 2.148), train_loss = 1.81521979, grad/param norm = 2.3291e-01, time/batch = 0.6473s	
1120/26050 (epoch 2.150), train_loss = 2.01007076, grad/param norm = 2.6367e-01, time/batch = 0.6412s	
1121/26050 (epoch 2.152), train_loss = 2.19464082, grad/param norm = 2.7539e-01, time/batch = 0.6451s	
1122/26050 (epoch 2.154), train_loss = 1.78792336, grad/param norm = 2.4170e-01, time/batch = 0.6433s	
1123/26050 (epoch 2.155), train_loss = 1.88839070, grad/param norm = 2.4871e-01, time/batch = 0.6414s	
1124/26050 (epoch 2.157), train_loss = 1.92632850, grad/param norm = 2.5174e-01, time/batch = 0.6679s	
1125/26050 (epoch 2.159), train_loss = 2.06247722, grad/param norm = 2.6941e-01, time/batch = 0.6636s	
1126/26050 (epoch 2.161), train_loss = 2.18503231, grad/param norm = 3.0765e-01, time/batch = 0.6705s	
1127/26050 (epoch 2.163), train_loss = 1.91762241, grad/param norm = 3.5882e-01, time/batch = 0.6714s	
1128/26050 (epoch 2.165), train_loss = 1.61211287, grad/param norm = 3.0754e-01, time/batch = 0.6765s	
1129/26050 (epoch 2.167), train_loss = 2.14681812, grad/param norm = 3.3585e-01, time/batch = 0.6767s	
1130/26050 (epoch 2.169), train_loss = 2.05276297, grad/param norm = 2.6061e-01, time/batch = 0.6749s	
1131/26050 (epoch 2.171), train_loss = 1.81958658, grad/param norm = 2.5989e-01, time/batch = 0.6692s	
1132/26050 (epoch 2.173), train_loss = 1.93774722, grad/param norm = 2.9992e-01, time/batch = 0.6536s	
1133/26050 (epoch 2.175), train_loss = 2.00235807, grad/param norm = 2.9699e-01, time/batch = 0.6430s	
1134/26050 (epoch 2.177), train_loss = 2.02530711, grad/param norm = 2.5863e-01, time/batch = 0.6513s	
1135/26050 (epoch 2.179), train_loss = 1.60678931, grad/param norm = 2.5504e-01, time/batch = 0.6460s	
1136/26050 (epoch 2.180), train_loss = 2.10650957, grad/param norm = 2.6279e-01, time/batch = 0.6378s	
1137/26050 (epoch 2.182), train_loss = 2.32156461, grad/param norm = 2.8773e-01, time/batch = 0.6406s	
1138/26050 (epoch 2.184), train_loss = 2.01331062, grad/param norm = 2.7127e-01, time/batch = 0.6372s	
1139/26050 (epoch 2.186), train_loss = 1.71672964, grad/param norm = 2.2905e-01, time/batch = 0.6373s	
1140/26050 (epoch 2.188), train_loss = 1.85502379, grad/param norm = 2.3182e-01, time/batch = 0.6394s	
1141/26050 (epoch 2.190), train_loss = 1.98339638, grad/param norm = 2.2728e-01, time/batch = 0.6428s	
1142/26050 (epoch 2.192), train_loss = 1.92516742, grad/param norm = 2.3728e-01, time/batch = 0.6393s	
1143/26050 (epoch 2.194), train_loss = 1.88148083, grad/param norm = 2.5351e-01, time/batch = 0.6397s	
1144/26050 (epoch 2.196), train_loss = 2.06592214, grad/param norm = 3.0891e-01, time/batch = 0.6408s	
1145/26050 (epoch 2.198), train_loss = 1.81384718, grad/param norm = 2.5610e-01, time/batch = 0.6395s	
1146/26050 (epoch 2.200), train_loss = 1.85382121, grad/param norm = 2.4258e-01, time/batch = 0.6388s	
1147/26050 (epoch 2.202), train_loss = 1.82358586, grad/param norm = 2.6772e-01, time/batch = 0.6400s	
1148/26050 (epoch 2.203), train_loss = 1.99337669, grad/param norm = 2.6288e-01, time/batch = 0.6400s	
1149/26050 (epoch 2.205), train_loss = 1.83437828, grad/param norm = 2.5728e-01, time/batch = 0.6437s	
1150/26050 (epoch 2.207), train_loss = 1.88572059, grad/param norm = 2.5636e-01, time/batch = 0.6422s	
1151/26050 (epoch 2.209), train_loss = 1.85016557, grad/param norm = 2.4625e-01, time/batch = 0.6562s	
1152/26050 (epoch 2.211), train_loss = 1.86194898, grad/param norm = 3.3458e-01, time/batch = 0.6854s	
1153/26050 (epoch 2.213), train_loss = 2.00780376, grad/param norm = 3.4764e-01, time/batch = 0.6524s	
1154/26050 (epoch 2.215), train_loss = 1.99016988, grad/param norm = 2.9728e-01, time/batch = 0.6598s	
1155/26050 (epoch 2.217), train_loss = 1.94042766, grad/param norm = 3.3693e-01, time/batch = 0.6613s	
1156/26050 (epoch 2.219), train_loss = 1.82504641, grad/param norm = 2.4732e-01, time/batch = 0.6604s	
1157/26050 (epoch 2.221), train_loss = 1.81070936, grad/param norm = 2.5300e-01, time/batch = 0.6506s	
1158/26050 (epoch 2.223), train_loss = 2.07102090, grad/param norm = 2.7417e-01, time/batch = 0.6509s	
1159/26050 (epoch 2.225), train_loss = 1.86253836, grad/param norm = 2.6675e-01, time/batch = 0.6485s	
1160/26050 (epoch 2.226), train_loss = 2.04569393, grad/param norm = 2.7899e-01, time/batch = 0.6504s	
1161/26050 (epoch 2.228), train_loss = 2.00039672, grad/param norm = 2.8495e-01, time/batch = 0.6513s	
1162/26050 (epoch 2.230), train_loss = 1.88122056, grad/param norm = 2.6482e-01, time/batch = 0.6544s	
1163/26050 (epoch 2.232), train_loss = 2.03671640, grad/param norm = 2.7096e-01, time/batch = 0.6697s	
1164/26050 (epoch 2.234), train_loss = 1.70743011, grad/param norm = 2.2175e-01, time/batch = 0.6594s	
1165/26050 (epoch 2.236), train_loss = 1.96011564, grad/param norm = 2.7084e-01, time/batch = 0.6579s	
1166/26050 (epoch 2.238), train_loss = 1.73914611, grad/param norm = 2.8472e-01, time/batch = 0.6567s	
1167/26050 (epoch 2.240), train_loss = 1.83792171, grad/param norm = 2.3419e-01, time/batch = 0.6838s	
1168/26050 (epoch 2.242), train_loss = 1.96921317, grad/param norm = 2.5548e-01, time/batch = 0.6682s	
1169/26050 (epoch 2.244), train_loss = 1.94253910, grad/param norm = 2.5536e-01, time/batch = 0.6478s	
1170/26050 (epoch 2.246), train_loss = 1.81065718, grad/param norm = 2.3493e-01, time/batch = 0.6459s	
1171/26050 (epoch 2.248), train_loss = 2.01121643, grad/param norm = 2.5767e-01, time/batch = 0.6433s	
1172/26050 (epoch 2.250), train_loss = 1.98554409, grad/param norm = 2.8582e-01, time/batch = 0.6408s	
1173/26050 (epoch 2.251), train_loss = 1.79658826, grad/param norm = 2.6148e-01, time/batch = 0.6384s	
1174/26050 (epoch 2.253), train_loss = 1.81097913, grad/param norm = 3.0233e-01, time/batch = 0.6379s	
1175/26050 (epoch 2.255), train_loss = 2.12292026, grad/param norm = 2.8448e-01, time/batch = 0.6369s	
1176/26050 (epoch 2.257), train_loss = 1.95258241, grad/param norm = 2.7872e-01, time/batch = 0.6382s	
1177/26050 (epoch 2.259), train_loss = 1.98393978, grad/param norm = 3.2861e-01, time/batch = 0.6401s	
1178/26050 (epoch 2.261), train_loss = 1.87614320, grad/param norm = 2.6612e-01, time/batch = 0.6367s	
1179/26050 (epoch 2.263), train_loss = 1.97098870, grad/param norm = 2.7467e-01, time/batch = 0.6515s	
1180/26050 (epoch 2.265), train_loss = 2.12239587, grad/param norm = 2.3905e-01, time/batch = 0.6573s	
1181/26050 (epoch 2.267), train_loss = 1.98299260, grad/param norm = 2.3105e-01, time/batch = 0.6550s	
1182/26050 (epoch 2.269), train_loss = 2.14710530, grad/param norm = 2.6302e-01, time/batch = 0.6752s	
1183/26050 (epoch 2.271), train_loss = 1.85898193, grad/param norm = 2.1688e-01, time/batch = 0.6687s	
1184/26050 (epoch 2.273), train_loss = 2.00192759, grad/param norm = 2.6865e-01, time/batch = 0.6414s	
1185/26050 (epoch 2.274), train_loss = 1.90593513, grad/param norm = 2.1770e-01, time/batch = 0.6428s	
1186/26050 (epoch 2.276), train_loss = 1.79588845, grad/param norm = 2.2603e-01, time/batch = 0.6406s	
1187/26050 (epoch 2.278), train_loss = 1.96891453, grad/param norm = 2.4465e-01, time/batch = 0.6452s	
1188/26050 (epoch 2.280), train_loss = 1.82585145, grad/param norm = 2.1831e-01, time/batch = 0.6398s	
1189/26050 (epoch 2.282), train_loss = 1.91678426, grad/param norm = 2.2892e-01, time/batch = 0.6395s	
1190/26050 (epoch 2.284), train_loss = 1.74854669, grad/param norm = 2.6096e-01, time/batch = 0.6389s	
1191/26050 (epoch 2.286), train_loss = 1.83177319, grad/param norm = 2.8127e-01, time/batch = 0.6413s	
1192/26050 (epoch 2.288), train_loss = 1.80486089, grad/param norm = 3.1853e-01, time/batch = 0.6402s	
1193/26050 (epoch 2.290), train_loss = 1.77860874, grad/param norm = 2.6196e-01, time/batch = 0.6415s	
1194/26050 (epoch 2.292), train_loss = 1.78845856, grad/param norm = 2.6920e-01, time/batch = 0.6416s	
1195/26050 (epoch 2.294), train_loss = 1.95536304, grad/param norm = 2.9034e-01, time/batch = 0.6482s	
1196/26050 (epoch 2.296), train_loss = 1.96014237, grad/param norm = 2.4271e-01, time/batch = 0.6447s	
1197/26050 (epoch 2.298), train_loss = 1.85102714, grad/param norm = 2.5506e-01, time/batch = 0.6562s	
1198/26050 (epoch 2.299), train_loss = 1.60858654, grad/param norm = 2.5659e-01, time/batch = 0.6821s	
1199/26050 (epoch 2.301), train_loss = 1.76209428, grad/param norm = 2.5032e-01, time/batch = 0.6434s	
1200/26050 (epoch 2.303), train_loss = 1.95251467, grad/param norm = 3.2584e-01, time/batch = 0.6383s	
1201/26050 (epoch 2.305), train_loss = 1.86115262, grad/param norm = 2.9336e-01, time/batch = 0.6385s	
1202/26050 (epoch 2.307), train_loss = 1.67876773, grad/param norm = 2.4076e-01, time/batch = 0.6426s	
1203/26050 (epoch 2.309), train_loss = 1.77698394, grad/param norm = 2.5784e-01, time/batch = 0.6501s	
1204/26050 (epoch 2.311), train_loss = 2.10723970, grad/param norm = 2.7642e-01, time/batch = 0.6550s	
1205/26050 (epoch 2.313), train_loss = 1.95625638, grad/param norm = 2.4932e-01, time/batch = 0.6495s	
1206/26050 (epoch 2.315), train_loss = 2.10359971, grad/param norm = 2.7900e-01, time/batch = 0.6415s	
1207/26050 (epoch 2.317), train_loss = 1.74202845, grad/param norm = 2.7906e-01, time/batch = 0.6448s	
1208/26050 (epoch 2.319), train_loss = 1.85072329, grad/param norm = 2.7158e-01, time/batch = 0.6683s	
1209/26050 (epoch 2.321), train_loss = 1.91359899, grad/param norm = 2.4595e-01, time/batch = 0.6757s	
1210/26050 (epoch 2.322), train_loss = 1.89241002, grad/param norm = 2.8678e-01, time/batch = 0.6434s	
1211/26050 (epoch 2.324), train_loss = 1.73938787, grad/param norm = 3.0470e-01, time/batch = 0.6416s	
1212/26050 (epoch 2.326), train_loss = 2.05596093, grad/param norm = 3.2945e-01, time/batch = 0.6394s	
1213/26050 (epoch 2.328), train_loss = 1.93542377, grad/param norm = 3.0337e-01, time/batch = 0.6380s	
1214/26050 (epoch 2.330), train_loss = 1.81822658, grad/param norm = 2.7183e-01, time/batch = 0.6388s	
1215/26050 (epoch 2.332), train_loss = 2.01839439, grad/param norm = 2.3885e-01, time/batch = 0.6380s	
1216/26050 (epoch 2.334), train_loss = 1.86029984, grad/param norm = 2.3416e-01, time/batch = 0.6424s	
1217/26050 (epoch 2.336), train_loss = 1.70123044, grad/param norm = 2.2934e-01, time/batch = 0.6420s	
1218/26050 (epoch 2.338), train_loss = 1.69210831, grad/param norm = 2.2020e-01, time/batch = 0.6407s	
1219/26050 (epoch 2.340), train_loss = 1.97488270, grad/param norm = 2.4441e-01, time/batch = 0.6399s	
1220/26050 (epoch 2.342), train_loss = 1.94464126, grad/param norm = 2.8571e-01, time/batch = 0.6508s	
1221/26050 (epoch 2.344), train_loss = 1.84280621, grad/param norm = 2.7090e-01, time/batch = 0.6571s	
1222/26050 (epoch 2.345), train_loss = 1.83829110, grad/param norm = 2.5758e-01, time/batch = 0.6587s	
1223/26050 (epoch 2.347), train_loss = 1.92895728, grad/param norm = 2.6236e-01, time/batch = 0.6664s	
1224/26050 (epoch 2.349), train_loss = 1.83396107, grad/param norm = 2.5918e-01, time/batch = 0.6839s	
1225/26050 (epoch 2.351), train_loss = 1.83255731, grad/param norm = 2.3951e-01, time/batch = 0.6644s	
1226/26050 (epoch 2.353), train_loss = 1.78602848, grad/param norm = 2.6681e-01, time/batch = 0.6543s	
1227/26050 (epoch 2.355), train_loss = 1.92395948, grad/param norm = 2.8449e-01, time/batch = 0.6559s	
1228/26050 (epoch 2.357), train_loss = 1.67321454, grad/param norm = 2.4500e-01, time/batch = 0.6580s	
1229/26050 (epoch 2.359), train_loss = 1.85012239, grad/param norm = 2.4118e-01, time/batch = 0.6576s	
1230/26050 (epoch 2.361), train_loss = 1.62213492, grad/param norm = 2.2648e-01, time/batch = 0.6563s	
1231/26050 (epoch 2.363), train_loss = 1.85994642, grad/param norm = 2.4803e-01, time/batch = 0.6609s	
1232/26050 (epoch 2.365), train_loss = 1.67601688, grad/param norm = 2.5295e-01, time/batch = 0.6533s	
1233/26050 (epoch 2.367), train_loss = 1.82575004, grad/param norm = 2.9195e-01, time/batch = 0.6425s	
1234/26050 (epoch 2.369), train_loss = 1.87132814, grad/param norm = 2.4938e-01, time/batch = 0.6415s	
1235/26050 (epoch 2.370), train_loss = 1.80572332, grad/param norm = 2.7019e-01, time/batch = 0.6405s	
1236/26050 (epoch 2.372), train_loss = 2.07820617, grad/param norm = 2.7599e-01, time/batch = 0.6411s	
1237/26050 (epoch 2.374), train_loss = 2.06886455, grad/param norm = 2.9132e-01, time/batch = 0.6396s	
1238/26050 (epoch 2.376), train_loss = 2.05988245, grad/param norm = 2.5037e-01, time/batch = 0.6425s	
1239/26050 (epoch 2.378), train_loss = 1.90648249, grad/param norm = 2.7811e-01, time/batch = 0.6825s	
1240/26050 (epoch 2.380), train_loss = 1.98683879, grad/param norm = 2.8802e-01, time/batch = 0.6572s	
1241/26050 (epoch 2.382), train_loss = 2.23010984, grad/param norm = 2.6769e-01, time/batch = 0.6453s	
1242/26050 (epoch 2.384), train_loss = 1.86016204, grad/param norm = 2.5434e-01, time/batch = 0.6409s	
1243/26050 (epoch 2.386), train_loss = 1.98100301, grad/param norm = 2.5436e-01, time/batch = 0.6409s	
1244/26050 (epoch 2.388), train_loss = 1.84124755, grad/param norm = 2.1032e-01, time/batch = 0.6415s	
1245/26050 (epoch 2.390), train_loss = 1.77391308, grad/param norm = 1.9895e-01, time/batch = 0.6403s	
1246/26050 (epoch 2.392), train_loss = 1.81936264, grad/param norm = 2.3748e-01, time/batch = 0.6395s	
1247/26050 (epoch 2.393), train_loss = 1.92510979, grad/param norm = 2.4445e-01, time/batch = 0.6388s	
1248/26050 (epoch 2.395), train_loss = 1.90515162, grad/param norm = 2.4760e-01, time/batch = 0.6417s	
1249/26050 (epoch 2.397), train_loss = 1.94111597, grad/param norm = 2.4039e-01, time/batch = 0.6408s	
1250/26050 (epoch 2.399), train_loss = 1.76234191, grad/param norm = 2.9688e-01, time/batch = 0.6383s	
1251/26050 (epoch 2.401), train_loss = 1.79189243, grad/param norm = 2.4675e-01, time/batch = 0.6412s	
1252/26050 (epoch 2.403), train_loss = 1.85722225, grad/param norm = 2.7106e-01, time/batch = 0.6392s	
1253/26050 (epoch 2.405), train_loss = 1.91944848, grad/param norm = 2.7950e-01, time/batch = 0.6399s	
1254/26050 (epoch 2.407), train_loss = 2.01321215, grad/param norm = 2.5890e-01, time/batch = 0.6691s	
1255/26050 (epoch 2.409), train_loss = 2.03117471, grad/param norm = 2.7810e-01, time/batch = 0.6756s	
1256/26050 (epoch 2.411), train_loss = 1.89004787, grad/param norm = 2.3436e-01, time/batch = 0.6565s	
1257/26050 (epoch 2.413), train_loss = 1.97484577, grad/param norm = 2.4793e-01, time/batch = 0.6508s	
1258/26050 (epoch 2.415), train_loss = 2.04469748, grad/param norm = 2.5747e-01, time/batch = 0.6383s	
1259/26050 (epoch 2.417), train_loss = 2.01796664, grad/param norm = 2.4332e-01, time/batch = 0.6379s	
1260/26050 (epoch 2.418), train_loss = 1.97181601, grad/param norm = 2.5744e-01, time/batch = 0.6385s	
1261/26050 (epoch 2.420), train_loss = 1.63981266, grad/param norm = 2.2297e-01, time/batch = 0.6394s	
1262/26050 (epoch 2.422), train_loss = 1.77852166, grad/param norm = 2.5642e-01, time/batch = 0.6388s	
1263/26050 (epoch 2.424), train_loss = 2.15753332, grad/param norm = 3.1153e-01, time/batch = 0.6408s	
1264/26050 (epoch 2.426), train_loss = 2.09737467, grad/param norm = 3.5771e-01, time/batch = 0.6391s	
1265/26050 (epoch 2.428), train_loss = 1.77446862, grad/param norm = 2.2828e-01, time/batch = 0.6381s	
1266/26050 (epoch 2.430), train_loss = 1.87125920, grad/param norm = 2.4726e-01, time/batch = 0.6393s	
1267/26050 (epoch 2.432), train_loss = 1.85456684, grad/param norm = 2.5725e-01, time/batch = 0.6378s	
1268/26050 (epoch 2.434), train_loss = 2.02672122, grad/param norm = 2.6713e-01, time/batch = 0.6381s	
1269/26050 (epoch 2.436), train_loss = 2.07060009, grad/param norm = 2.3085e-01, time/batch = 0.6471s	
1270/26050 (epoch 2.438), train_loss = 1.77343877, grad/param norm = 2.4987e-01, time/batch = 0.6826s	
1271/26050 (epoch 2.440), train_loss = 1.92727725, grad/param norm = 2.6340e-01, time/batch = 0.6689s	
1272/26050 (epoch 2.441), train_loss = 1.82521892, grad/param norm = 2.8723e-01, time/batch = 0.6479s	
1273/26050 (epoch 2.443), train_loss = 1.71479850, grad/param norm = 2.3463e-01, time/batch = 0.6500s	
1274/26050 (epoch 2.445), train_loss = 1.79801445, grad/param norm = 2.6910e-01, time/batch = 0.6445s	
1275/26050 (epoch 2.447), train_loss = 2.10583709, grad/param norm = 2.3341e-01, time/batch = 0.6460s	
1276/26050 (epoch 2.449), train_loss = 1.75712086, grad/param norm = 2.4675e-01, time/batch = 0.6422s	
1277/26050 (epoch 2.451), train_loss = 1.89685899, grad/param norm = 2.7178e-01, time/batch = 0.6395s	
1278/26050 (epoch 2.453), train_loss = 1.66577069, grad/param norm = 2.4165e-01, time/batch = 0.6405s	
1279/26050 (epoch 2.455), train_loss = 1.82667139, grad/param norm = 2.2830e-01, time/batch = 0.6429s	
1280/26050 (epoch 2.457), train_loss = 1.91174375, grad/param norm = 2.7801e-01, time/batch = 0.6410s	
1281/26050 (epoch 2.459), train_loss = 2.06651925, grad/param norm = 3.2126e-01, time/batch = 0.6398s	
1282/26050 (epoch 2.461), train_loss = 1.88270895, grad/param norm = 2.6163e-01, time/batch = 0.6416s	
1283/26050 (epoch 2.463), train_loss = 1.79722841, grad/param norm = 2.3139e-01, time/batch = 0.6420s	
1284/26050 (epoch 2.464), train_loss = 1.98546581, grad/param norm = 2.6601e-01, time/batch = 0.6450s	
1285/26050 (epoch 2.466), train_loss = 1.99054832, grad/param norm = 2.1957e-01, time/batch = 0.6677s	
1286/26050 (epoch 2.468), train_loss = 1.96871644, grad/param norm = 2.2360e-01, time/batch = 0.6552s	
1287/26050 (epoch 2.470), train_loss = 2.03157520, grad/param norm = 2.5008e-01, time/batch = 0.6410s	
1288/26050 (epoch 2.472), train_loss = 2.18088993, grad/param norm = 3.0963e-01, time/batch = 0.6483s	
1289/26050 (epoch 2.474), train_loss = 2.15858660, grad/param norm = 2.6627e-01, time/batch = 0.6411s	
1290/26050 (epoch 2.476), train_loss = 2.02603486, grad/param norm = 2.2980e-01, time/batch = 0.6413s	
1291/26050 (epoch 2.478), train_loss = 1.82482340, grad/param norm = 2.2294e-01, time/batch = 0.6402s	
1292/26050 (epoch 2.480), train_loss = 1.94228536, grad/param norm = 2.3633e-01, time/batch = 0.6385s	
1293/26050 (epoch 2.482), train_loss = 1.82598108, grad/param norm = 2.3676e-01, time/batch = 0.6372s	
1294/26050 (epoch 2.484), train_loss = 1.70317571, grad/param norm = 2.4064e-01, time/batch = 0.6411s	
1295/26050 (epoch 2.486), train_loss = 2.01913945, grad/param norm = 2.5087e-01, time/batch = 0.6411s	
1296/26050 (epoch 2.488), train_loss = 2.19936882, grad/param norm = 2.3773e-01, time/batch = 0.6550s	
1297/26050 (epoch 2.489), train_loss = 2.09855757, grad/param norm = 2.6585e-01, time/batch = 0.6504s	
1298/26050 (epoch 2.491), train_loss = 1.80970461, grad/param norm = 2.7671e-01, time/batch = 0.6487s	
1299/26050 (epoch 2.493), train_loss = 1.79726908, grad/param norm = 2.4823e-01, time/batch = 0.6375s	
1300/26050 (epoch 2.495), train_loss = 1.93149725, grad/param norm = 2.6796e-01, time/batch = 0.6636s	
1301/26050 (epoch 2.497), train_loss = 1.81874170, grad/param norm = 2.4347e-01, time/batch = 0.6838s	
1302/26050 (epoch 2.499), train_loss = 1.77404179, grad/param norm = 2.3160e-01, time/batch = 0.6492s	
1303/26050 (epoch 2.501), train_loss = 1.80209253, grad/param norm = 2.2442e-01, time/batch = 0.6446s	
1304/26050 (epoch 2.503), train_loss = 1.90314665, grad/param norm = 2.5870e-01, time/batch = 0.6420s	
1305/26050 (epoch 2.505), train_loss = 1.95414171, grad/param norm = 2.5346e-01, time/batch = 0.6381s	
1306/26050 (epoch 2.507), train_loss = 1.98829934, grad/param norm = 2.7717e-01, time/batch = 0.6382s	
1307/26050 (epoch 2.509), train_loss = 2.13980275, grad/param norm = 3.0277e-01, time/batch = 0.6372s	
1308/26050 (epoch 2.511), train_loss = 1.76088808, grad/param norm = 2.2770e-01, time/batch = 0.6373s	
1309/26050 (epoch 2.512), train_loss = 1.93686475, grad/param norm = 2.3938e-01, time/batch = 0.6380s	
1310/26050 (epoch 2.514), train_loss = 1.93323513, grad/param norm = 2.4400e-01, time/batch = 0.6385s	
1311/26050 (epoch 2.516), train_loss = 1.94176906, grad/param norm = 2.3664e-01, time/batch = 0.6397s	
1312/26050 (epoch 2.518), train_loss = 1.90545157, grad/param norm = 2.3435e-01, time/batch = 0.6382s	
1313/26050 (epoch 2.520), train_loss = 1.90319856, grad/param norm = 2.5156e-01, time/batch = 0.6373s	
1314/26050 (epoch 2.522), train_loss = 1.86828891, grad/param norm = 2.4484e-01, time/batch = 0.6372s	
1315/26050 (epoch 2.524), train_loss = 2.19073599, grad/param norm = 2.6187e-01, time/batch = 0.6393s	
1316/26050 (epoch 2.526), train_loss = 1.99527292, grad/param norm = 3.0718e-01, time/batch = 0.6405s	
1317/26050 (epoch 2.528), train_loss = 2.00787457, grad/param norm = 3.0894e-01, time/batch = 0.6413s	
1318/26050 (epoch 2.530), train_loss = 1.89228124, grad/param norm = 2.6062e-01, time/batch = 0.6452s	
1319/26050 (epoch 2.532), train_loss = 1.95618850, grad/param norm = 2.5163e-01, time/batch = 0.6427s	
1320/26050 (epoch 2.534), train_loss = 1.94822281, grad/param norm = 2.5086e-01, time/batch = 0.6407s	
1321/26050 (epoch 2.536), train_loss = 1.85143603, grad/param norm = 3.0130e-01, time/batch = 0.6458s	
1322/26050 (epoch 2.537), train_loss = 1.97159457, grad/param norm = 2.4187e-01, time/batch = 0.6480s	
1323/26050 (epoch 2.539), train_loss = 1.83482177, grad/param norm = 2.3963e-01, time/batch = 0.6474s	
1324/26050 (epoch 2.541), train_loss = 2.01610877, grad/param norm = 2.4541e-01, time/batch = 0.6447s	
1325/26050 (epoch 2.543), train_loss = 1.72396828, grad/param norm = 2.5782e-01, time/batch = 0.6437s	
1326/26050 (epoch 2.545), train_loss = 1.89077660, grad/param norm = 2.3947e-01, time/batch = 0.6428s	
1327/26050 (epoch 2.547), train_loss = 2.00532122, grad/param norm = 2.7247e-01, time/batch = 0.6397s	
1328/26050 (epoch 2.549), train_loss = 1.80306623, grad/param norm = 2.3789e-01, time/batch = 0.6408s	
1329/26050 (epoch 2.551), train_loss = 1.93650976, grad/param norm = 2.4711e-01, time/batch = 0.6409s	
1330/26050 (epoch 2.553), train_loss = 1.85565003, grad/param norm = 2.5868e-01, time/batch = 0.6403s	
1331/26050 (epoch 2.555), train_loss = 1.83436952, grad/param norm = 2.4890e-01, time/batch = 0.6424s	
1332/26050 (epoch 2.557), train_loss = 1.96082512, grad/param norm = 2.5214e-01, time/batch = 0.6436s	
1333/26050 (epoch 2.559), train_loss = 1.91797226, grad/param norm = 2.7975e-01, time/batch = 0.6418s	
1334/26050 (epoch 2.560), train_loss = 1.85897557, grad/param norm = 2.2686e-01, time/batch = 0.6563s	
1335/26050 (epoch 2.562), train_loss = 1.94340718, grad/param norm = 2.5867e-01, time/batch = 0.6456s	
1336/26050 (epoch 2.564), train_loss = 2.08399124, grad/param norm = 2.4695e-01, time/batch = 0.6784s	
1337/26050 (epoch 2.566), train_loss = 1.81573543, grad/param norm = 2.3447e-01, time/batch = 0.6656s	
1338/26050 (epoch 2.568), train_loss = 1.94105647, grad/param norm = 2.3312e-01, time/batch = 0.6406s	
1339/26050 (epoch 2.570), train_loss = 1.96941089, grad/param norm = 2.6523e-01, time/batch = 0.6389s	
1340/26050 (epoch 2.572), train_loss = 1.95744998, grad/param norm = 2.5462e-01, time/batch = 0.6387s	
1341/26050 (epoch 2.574), train_loss = 2.04108843, grad/param norm = 2.9018e-01, time/batch = 0.6410s	
1342/26050 (epoch 2.576), train_loss = 1.92619963, grad/param norm = 2.6306e-01, time/batch = 0.6412s	
1343/26050 (epoch 2.578), train_loss = 1.95155542, grad/param norm = 2.2601e-01, time/batch = 0.6401s	
1344/26050 (epoch 2.580), train_loss = 1.79470210, grad/param norm = 2.3616e-01, time/batch = 0.6390s	
1345/26050 (epoch 2.582), train_loss = 1.99202039, grad/param norm = 2.5161e-01, time/batch = 0.6387s	
1346/26050 (epoch 2.583), train_loss = 1.94962592, grad/param norm = 2.5042e-01, time/batch = 0.6414s	
1347/26050 (epoch 2.585), train_loss = 1.80643963, grad/param norm = 2.6407e-01, time/batch = 0.6827s	
1348/26050 (epoch 2.587), train_loss = 1.95052251, grad/param norm = 2.5734e-01, time/batch = 0.6607s	
1349/26050 (epoch 2.589), train_loss = 1.92204015, grad/param norm = 2.5971e-01, time/batch = 0.6419s	
1350/26050 (epoch 2.591), train_loss = 1.94231316, grad/param norm = 2.4433e-01, time/batch = 0.6388s	
1351/26050 (epoch 2.593), train_loss = 1.80513088, grad/param norm = 2.6163e-01, time/batch = 0.6405s	
1352/26050 (epoch 2.595), train_loss = 2.00665777, grad/param norm = 2.6472e-01, time/batch = 0.6400s	
1353/26050 (epoch 2.597), train_loss = 1.89917283, grad/param norm = 2.3368e-01, time/batch = 0.6463s	
1354/26050 (epoch 2.599), train_loss = 1.73079571, grad/param norm = 2.1640e-01, time/batch = 0.6419s	
1355/26050 (epoch 2.601), train_loss = 2.09144267, grad/param norm = 2.4558e-01, time/batch = 0.6392s	
1356/26050 (epoch 2.603), train_loss = 1.97265082, grad/param norm = 2.6114e-01, time/batch = 0.6438s	
1357/26050 (epoch 2.605), train_loss = 1.82856727, grad/param norm = 2.1437e-01, time/batch = 0.6564s	
1358/26050 (epoch 2.607), train_loss = 1.96608948, grad/param norm = 2.5424e-01, time/batch = 0.6432s	
1359/26050 (epoch 2.608), train_loss = 1.88373171, grad/param norm = 2.3300e-01, time/batch = 0.6433s	
1360/26050 (epoch 2.610), train_loss = 1.86215399, grad/param norm = 2.4686e-01, time/batch = 0.6408s	
1361/26050 (epoch 2.612), train_loss = 1.87239741, grad/param norm = 2.4824e-01, time/batch = 0.6402s	
1362/26050 (epoch 2.614), train_loss = 1.92747171, grad/param norm = 2.9536e-01, time/batch = 0.6712s	
1363/26050 (epoch 2.616), train_loss = 2.24767909, grad/param norm = 2.7332e-01, time/batch = 0.6785s	
1364/26050 (epoch 2.618), train_loss = 1.75872636, grad/param norm = 2.6884e-01, time/batch = 0.6612s	
1365/26050 (epoch 2.620), train_loss = 2.01736312, grad/param norm = 2.7412e-01, time/batch = 0.6539s	
1366/26050 (epoch 2.622), train_loss = 1.59784153, grad/param norm = 2.3000e-01, time/batch = 0.6809s	
1367/26050 (epoch 2.624), train_loss = 1.79056591, grad/param norm = 2.2612e-01, time/batch = 0.6542s	
1368/26050 (epoch 2.626), train_loss = 1.90377273, grad/param norm = 2.9857e-01, time/batch = 0.6426s	
1369/26050 (epoch 2.628), train_loss = 1.89581976, grad/param norm = 2.7117e-01, time/batch = 0.6401s	
1370/26050 (epoch 2.630), train_loss = 2.01427656, grad/param norm = 2.3321e-01, time/batch = 0.6368s	
1371/26050 (epoch 2.631), train_loss = 1.95210853, grad/param norm = 2.1856e-01, time/batch = 0.6539s	
1372/26050 (epoch 2.633), train_loss = 1.70960063, grad/param norm = 2.1356e-01, time/batch = 0.6418s	
1373/26050 (epoch 2.635), train_loss = 1.77420121, grad/param norm = 2.2229e-01, time/batch = 0.6404s	
1374/26050 (epoch 2.637), train_loss = 1.76469685, grad/param norm = 2.4564e-01, time/batch = 0.6390s	
1375/26050 (epoch 2.639), train_loss = 1.93461567, grad/param norm = 2.2738e-01, time/batch = 0.6381s	
1376/26050 (epoch 2.641), train_loss = 1.78642762, grad/param norm = 2.2057e-01, time/batch = 0.6386s	
1377/26050 (epoch 2.643), train_loss = 1.79467888, grad/param norm = 2.1209e-01, time/batch = 0.6555s	
1378/26050 (epoch 2.645), train_loss = 2.04207531, grad/param norm = 2.4780e-01, time/batch = 0.6829s	
1379/26050 (epoch 2.647), train_loss = 1.75701120, grad/param norm = 2.4171e-01, time/batch = 0.6488s	
1380/26050 (epoch 2.649), train_loss = 1.93216555, grad/param norm = 2.6253e-01, time/batch = 0.6403s	
1381/26050 (epoch 2.651), train_loss = 1.93406927, grad/param norm = 2.6149e-01, time/batch = 0.6644s	
1382/26050 (epoch 2.653), train_loss = 1.81072961, grad/param norm = 2.6329e-01, time/batch = 0.6701s	
1383/26050 (epoch 2.655), train_loss = 1.82634957, grad/param norm = 2.4499e-01, time/batch = 0.6539s	
1384/26050 (epoch 2.656), train_loss = 1.81764305, grad/param norm = 2.4379e-01, time/batch = 0.6394s	
1385/26050 (epoch 2.658), train_loss = 2.00999296, grad/param norm = 2.4222e-01, time/batch = 0.6389s	
1386/26050 (epoch 2.660), train_loss = 1.73461691, grad/param norm = 2.8115e-01, time/batch = 0.6397s	
1387/26050 (epoch 2.662), train_loss = 1.72815374, grad/param norm = 2.4588e-01, time/batch = 0.6379s	
1388/26050 (epoch 2.664), train_loss = 1.74790153, grad/param norm = 2.5656e-01, time/batch = 0.6383s	
1389/26050 (epoch 2.666), train_loss = 1.91181765, grad/param norm = 2.6185e-01, time/batch = 0.6389s	
1390/26050 (epoch 2.668), train_loss = 1.61386515, grad/param norm = 2.3383e-01, time/batch = 0.6377s	
1391/26050 (epoch 2.670), train_loss = 2.02339390, grad/param norm = 2.7675e-01, time/batch = 0.6388s	
1392/26050 (epoch 2.672), train_loss = 1.79549645, grad/param norm = 2.5220e-01, time/batch = 0.6439s	
1393/26050 (epoch 2.674), train_loss = 1.72256219, grad/param norm = 2.3795e-01, time/batch = 0.6831s	
1394/26050 (epoch 2.676), train_loss = 1.82051599, grad/param norm = 2.3815e-01, time/batch = 0.6583s	
1395/26050 (epoch 2.678), train_loss = 2.03632176, grad/param norm = 2.4766e-01, time/batch = 0.6418s	
1396/26050 (epoch 2.679), train_loss = 1.92235400, grad/param norm = 2.5851e-01, time/batch = 0.6375s	
1397/26050 (epoch 2.681), train_loss = 1.92101325, grad/param norm = 2.5596e-01, time/batch = 0.6374s	
1398/26050 (epoch 2.683), train_loss = 1.79764806, grad/param norm = 3.1576e-01, time/batch = 0.6376s	
1399/26050 (epoch 2.685), train_loss = 1.79495061, grad/param norm = 2.5825e-01, time/batch = 0.6382s	
1400/26050 (epoch 2.687), train_loss = 1.62287437, grad/param norm = 2.2797e-01, time/batch = 0.6372s	
1401/26050 (epoch 2.689), train_loss = 1.83674168, grad/param norm = 2.2106e-01, time/batch = 0.6405s	
1402/26050 (epoch 2.691), train_loss = 1.61474315, grad/param norm = 2.2681e-01, time/batch = 0.6401s	
1403/26050 (epoch 2.693), train_loss = 1.78003698, grad/param norm = 2.5194e-01, time/batch = 0.6419s	
1404/26050 (epoch 2.695), train_loss = 1.90302854, grad/param norm = 2.6144e-01, time/batch = 0.6376s	
1405/26050 (epoch 2.697), train_loss = 1.71241300, grad/param norm = 2.5320e-01, time/batch = 0.6414s	
1406/26050 (epoch 2.699), train_loss = 1.88548357, grad/param norm = 2.6449e-01, time/batch = 0.6405s	
1407/26050 (epoch 2.701), train_loss = 1.67704045, grad/param norm = 2.3052e-01, time/batch = 0.6380s	
1408/26050 (epoch 2.702), train_loss = 2.08227226, grad/param norm = 2.5301e-01, time/batch = 0.6634s	
1409/26050 (epoch 2.704), train_loss = 1.84223596, grad/param norm = 2.2749e-01, time/batch = 0.6789s	
1410/26050 (epoch 2.706), train_loss = 1.97021373, grad/param norm = 2.3955e-01, time/batch = 0.6403s	
1411/26050 (epoch 2.708), train_loss = 1.84411892, grad/param norm = 2.0520e-01, time/batch = 0.6466s	
1412/26050 (epoch 2.710), train_loss = 1.99090129, grad/param norm = 2.2629e-01, time/batch = 0.6410s	
1413/26050 (epoch 2.712), train_loss = 2.02650263, grad/param norm = 2.2744e-01, time/batch = 0.6446s	
1414/26050 (epoch 2.714), train_loss = 1.73505025, grad/param norm = 2.4548e-01, time/batch = 0.6421s	
1415/26050 (epoch 2.716), train_loss = 2.10746314, grad/param norm = 2.6436e-01, time/batch = 0.6391s	
1416/26050 (epoch 2.718), train_loss = 1.91033452, grad/param norm = 2.7465e-01, time/batch = 0.6397s	
1417/26050 (epoch 2.720), train_loss = 1.69666479, grad/param norm = 2.3338e-01, time/batch = 0.6406s	
1418/26050 (epoch 2.722), train_loss = 1.79906306, grad/param norm = 2.8539e-01, time/batch = 0.6401s	
1419/26050 (epoch 2.724), train_loss = 1.73192374, grad/param norm = 2.7482e-01, time/batch = 0.6384s	
1420/26050 (epoch 2.726), train_loss = 1.98067924, grad/param norm = 2.4692e-01, time/batch = 0.6390s	
1421/26050 (epoch 2.727), train_loss = 1.88914249, grad/param norm = 2.3546e-01, time/batch = 0.6397s	
1422/26050 (epoch 2.729), train_loss = 1.96066645, grad/param norm = 2.3211e-01, time/batch = 0.6402s	
1423/26050 (epoch 2.731), train_loss = 1.80691211, grad/param norm = 2.2458e-01, time/batch = 0.6439s	
1424/26050 (epoch 2.733), train_loss = 1.90328488, grad/param norm = 2.6994e-01, time/batch = 0.6828s	
1425/26050 (epoch 2.735), train_loss = 2.04777530, grad/param norm = 2.4899e-01, time/batch = 0.6638s	
1426/26050 (epoch 2.737), train_loss = 1.94341147, grad/param norm = 2.3849e-01, time/batch = 0.6485s	
1427/26050 (epoch 2.739), train_loss = 1.94454226, grad/param norm = 2.5541e-01, time/batch = 0.6463s	
1428/26050 (epoch 2.741), train_loss = 1.72606111, grad/param norm = 2.4220e-01, time/batch = 0.6412s	
1429/26050 (epoch 2.743), train_loss = 2.01366265, grad/param norm = 2.9179e-01, time/batch = 0.6432s	
1430/26050 (epoch 2.745), train_loss = 1.71086504, grad/param norm = 2.1191e-01, time/batch = 0.6409s	
1431/26050 (epoch 2.747), train_loss = 1.80941482, grad/param norm = 2.1543e-01, time/batch = 0.6422s	
1432/26050 (epoch 2.749), train_loss = 1.88104612, grad/param norm = 2.7152e-01, time/batch = 0.6394s	
1433/26050 (epoch 2.750), train_loss = 1.77053475, grad/param norm = 2.2386e-01, time/batch = 0.6400s	
1434/26050 (epoch 2.752), train_loss = 1.96563992, grad/param norm = 2.5160e-01, time/batch = 0.6391s	
1435/26050 (epoch 2.754), train_loss = 1.71170844, grad/param norm = 2.1415e-01, time/batch = 0.6500s	
1436/26050 (epoch 2.756), train_loss = 1.99580016, grad/param norm = 2.2451e-01, time/batch = 0.6455s	
1437/26050 (epoch 2.758), train_loss = 1.91392438, grad/param norm = 2.7348e-01, time/batch = 0.6383s	
1438/26050 (epoch 2.760), train_loss = 1.83911455, grad/param norm = 2.2906e-01, time/batch = 0.6375s	
1439/26050 (epoch 2.762), train_loss = 1.85763468, grad/param norm = 2.3976e-01, time/batch = 0.6696s	
1440/26050 (epoch 2.764), train_loss = 1.94480611, grad/param norm = 2.3593e-01, time/batch = 0.6726s	
1441/26050 (epoch 2.766), train_loss = 1.90121156, grad/param norm = 2.2266e-01, time/batch = 0.6489s	
1442/26050 (epoch 2.768), train_loss = 1.80234036, grad/param norm = 2.1952e-01, time/batch = 0.6405s	
1443/26050 (epoch 2.770), train_loss = 1.85321925, grad/param norm = 2.5178e-01, time/batch = 0.6393s	
1444/26050 (epoch 2.772), train_loss = 1.86792059, grad/param norm = 2.6374e-01, time/batch = 0.6387s	
1445/26050 (epoch 2.774), train_loss = 1.78130371, grad/param norm = 2.6490e-01, time/batch = 0.6389s	
1446/26050 (epoch 2.775), train_loss = 1.63331554, grad/param norm = 2.4929e-01, time/batch = 0.6383s	
1447/26050 (epoch 2.777), train_loss = 1.72245193, grad/param norm = 2.3227e-01, time/batch = 0.6388s	
1448/26050 (epoch 2.779), train_loss = 1.87743142, grad/param norm = 2.5950e-01, time/batch = 0.6400s	
1449/26050 (epoch 2.781), train_loss = 1.79583451, grad/param norm = 2.5633e-01, time/batch = 0.6398s	
1450/26050 (epoch 2.783), train_loss = 1.77504641, grad/param norm = 2.0520e-01, time/batch = 0.6389s	
1451/26050 (epoch 2.785), train_loss = 1.79827407, grad/param norm = 2.7745e-01, time/batch = 0.6396s	
1452/26050 (epoch 2.787), train_loss = 1.79814612, grad/param norm = 2.8835e-01, time/batch = 0.6411s	
1453/26050 (epoch 2.789), train_loss = 1.93760640, grad/param norm = 2.8153e-01, time/batch = 0.6425s	
1454/26050 (epoch 2.791), train_loss = 1.88130096, grad/param norm = 2.2808e-01, time/batch = 0.6624s	
1455/26050 (epoch 2.793), train_loss = 1.80558225, grad/param norm = 2.5140e-01, time/batch = 0.6832s	
1456/26050 (epoch 2.795), train_loss = 1.78665173, grad/param norm = 2.6542e-01, time/batch = 0.6603s	
1457/26050 (epoch 2.797), train_loss = 1.72445514, grad/param norm = 2.2940e-01, time/batch = 0.6576s	
1458/26050 (epoch 2.798), train_loss = 1.68443000, grad/param norm = 2.1402e-01, time/batch = 0.6570s	
1459/26050 (epoch 2.800), train_loss = 1.71637355, grad/param norm = 2.2487e-01, time/batch = 0.6484s	
1460/26050 (epoch 2.802), train_loss = 1.87152627, grad/param norm = 2.2180e-01, time/batch = 0.6459s	
1461/26050 (epoch 2.804), train_loss = 1.89799184, grad/param norm = 2.5463e-01, time/batch = 0.6431s	
1462/26050 (epoch 2.806), train_loss = 1.98785103, grad/param norm = 2.7293e-01, time/batch = 0.6443s	
1463/26050 (epoch 2.808), train_loss = 1.73723436, grad/param norm = 2.3036e-01, time/batch = 0.6429s	
1464/26050 (epoch 2.810), train_loss = 1.77613622, grad/param norm = 2.5709e-01, time/batch = 0.6436s	
1465/26050 (epoch 2.812), train_loss = 1.68223038, grad/param norm = 2.3976e-01, time/batch = 0.6399s	
1466/26050 (epoch 2.814), train_loss = 1.77919473, grad/param norm = 2.5728e-01, time/batch = 0.6396s	
1467/26050 (epoch 2.816), train_loss = 1.88038576, grad/param norm = 2.2422e-01, time/batch = 0.6387s	
1468/26050 (epoch 2.818), train_loss = 1.97119377, grad/param norm = 2.8273e-01, time/batch = 0.6556s	
1469/26050 (epoch 2.820), train_loss = 1.86016358, grad/param norm = 2.2820e-01, time/batch = 0.6414s	
1470/26050 (epoch 2.821), train_loss = 1.97190108, grad/param norm = 2.4885e-01, time/batch = 0.6843s	
1471/26050 (epoch 2.823), train_loss = 2.05818724, grad/param norm = 2.7155e-01, time/batch = 0.6708s	
1472/26050 (epoch 2.825), train_loss = 1.82863573, grad/param norm = 2.4567e-01, time/batch = 0.6511s	
1473/26050 (epoch 2.827), train_loss = 1.92396550, grad/param norm = 3.0720e-01, time/batch = 0.6429s	
1474/26050 (epoch 2.829), train_loss = 1.88355229, grad/param norm = 2.2825e-01, time/batch = 0.6432s	
1475/26050 (epoch 2.831), train_loss = 1.96586778, grad/param norm = 2.1589e-01, time/batch = 0.6475s	
1476/26050 (epoch 2.833), train_loss = 2.02654525, grad/param norm = 2.5759e-01, time/batch = 0.6409s	
1477/26050 (epoch 2.835), train_loss = 2.08348348, grad/param norm = 2.3021e-01, time/batch = 0.6406s	
1478/26050 (epoch 2.837), train_loss = 1.75271486, grad/param norm = 2.3804e-01, time/batch = 0.6395s	
1479/26050 (epoch 2.839), train_loss = 2.01507965, grad/param norm = 2.5371e-01, time/batch = 0.6429s	
1480/26050 (epoch 2.841), train_loss = 1.96003252, grad/param norm = 2.7523e-01, time/batch = 0.6421s	
1481/26050 (epoch 2.843), train_loss = 1.90133219, grad/param norm = 2.4397e-01, time/batch = 0.6399s	
1482/26050 (epoch 2.845), train_loss = 1.77020592, grad/param norm = 2.3503e-01, time/batch = 0.6444s	
1483/26050 (epoch 2.846), train_loss = 1.94993922, grad/param norm = 2.5214e-01, time/batch = 0.6544s	
1484/26050 (epoch 2.848), train_loss = 1.77901356, grad/param norm = 2.2338e-01, time/batch = 0.6538s	
1485/26050 (epoch 2.850), train_loss = 1.79773518, grad/param norm = 2.2717e-01, time/batch = 0.6683s	
1486/26050 (epoch 2.852), train_loss = 1.82517646, grad/param norm = 2.4749e-01, time/batch = 0.6756s	
1487/26050 (epoch 2.854), train_loss = 1.85088359, grad/param norm = 2.3197e-01, time/batch = 0.6438s	
1488/26050 (epoch 2.856), train_loss = 1.77768379, grad/param norm = 2.3316e-01, time/batch = 0.6434s	
1489/26050 (epoch 2.858), train_loss = 1.64821319, grad/param norm = 2.6060e-01, time/batch = 0.6395s	
1490/26050 (epoch 2.860), train_loss = 1.89097226, grad/param norm = 2.8223e-01, time/batch = 0.6391s	
1491/26050 (epoch 2.862), train_loss = 1.84817243, grad/param norm = 2.6769e-01, time/batch = 0.6412s	
1492/26050 (epoch 2.864), train_loss = 1.75195211, grad/param norm = 2.5973e-01, time/batch = 0.6408s	
1493/26050 (epoch 2.866), train_loss = 1.73253729, grad/param norm = 2.5557e-01, time/batch = 0.6413s	
1494/26050 (epoch 2.868), train_loss = 2.01933546, grad/param norm = 2.8328e-01, time/batch = 0.6414s	
1495/26050 (epoch 2.869), train_loss = 1.66091862, grad/param norm = 2.4865e-01, time/batch = 0.6405s	
1496/26050 (epoch 2.871), train_loss = 1.59470158, grad/param norm = 2.3824e-01, time/batch = 0.6408s	
1497/26050 (epoch 2.873), train_loss = 1.76177277, grad/param norm = 2.6431e-01, time/batch = 0.6398s	
1498/26050 (epoch 2.875), train_loss = 1.81919730, grad/param norm = 2.8067e-01, time/batch = 0.6400s	
1499/26050 (epoch 2.877), train_loss = 1.63018904, grad/param norm = 2.4685e-01, time/batch = 0.6398s	
1500/26050 (epoch 2.879), train_loss = 1.78359808, grad/param norm = 2.2580e-01, time/batch = 0.6497s	
1501/26050 (epoch 2.881), train_loss = 2.00525557, grad/param norm = 2.3155e-01, time/batch = 0.6835s	
1502/26050 (epoch 2.883), train_loss = 1.87944994, grad/param norm = 2.4855e-01, time/batch = 0.6637s	
1503/26050 (epoch 2.885), train_loss = 1.60194280, grad/param norm = 2.2519e-01, time/batch = 0.6438s	
1504/26050 (epoch 2.887), train_loss = 1.83028330, grad/param norm = 2.2408e-01, time/batch = 0.6409s	
1505/26050 (epoch 2.889), train_loss = 1.71942725, grad/param norm = 2.3889e-01, time/batch = 0.6402s	
1506/26050 (epoch 2.891), train_loss = 1.58653757, grad/param norm = 2.5213e-01, time/batch = 0.6388s	
1507/26050 (epoch 2.893), train_loss = 1.57650692, grad/param norm = 1.9147e-01, time/batch = 0.6447s	
1508/26050 (epoch 2.894), train_loss = 1.66408442, grad/param norm = 2.0139e-01, time/batch = 0.6420s	
1509/26050 (epoch 2.896), train_loss = 1.88858440, grad/param norm = 2.2689e-01, time/batch = 0.6391s	
1510/26050 (epoch 2.898), train_loss = 1.77485658, grad/param norm = 2.3873e-01, time/batch = 0.6422s	
1511/26050 (epoch 2.900), train_loss = 2.08145300, grad/param norm = 2.4935e-01, time/batch = 0.6418s	
1512/26050 (epoch 2.902), train_loss = 1.86935743, grad/param norm = 2.2215e-01, time/batch = 0.6394s	
1513/26050 (epoch 2.904), train_loss = 1.84983455, grad/param norm = 2.4174e-01, time/batch = 0.6426s	
1514/26050 (epoch 2.906), train_loss = 1.83786568, grad/param norm = 2.3009e-01, time/batch = 0.6400s	
1515/26050 (epoch 2.908), train_loss = 1.80126251, grad/param norm = 2.5062e-01, time/batch = 0.6405s	
1516/26050 (epoch 2.910), train_loss = 1.75213529, grad/param norm = 2.2015e-01, time/batch = 0.6750s	
1517/26050 (epoch 2.912), train_loss = 2.12071658, grad/param norm = 2.6074e-01, time/batch = 0.6758s	
1518/26050 (epoch 2.914), train_loss = 2.15745608, grad/param norm = 2.3137e-01, time/batch = 0.6457s	
1519/26050 (epoch 2.916), train_loss = 1.94902833, grad/param norm = 2.1840e-01, time/batch = 0.6412s	
1520/26050 (epoch 2.917), train_loss = 1.77587542, grad/param norm = 2.2607e-01, time/batch = 0.6404s	
1521/26050 (epoch 2.919), train_loss = 1.88976022, grad/param norm = 2.3119e-01, time/batch = 0.6412s	
1522/26050 (epoch 2.921), train_loss = 1.64149592, grad/param norm = 2.2546e-01, time/batch = 0.6419s	
1523/26050 (epoch 2.923), train_loss = 1.75953170, grad/param norm = 2.6646e-01, time/batch = 0.6503s	
1524/26050 (epoch 2.925), train_loss = 1.68757809, grad/param norm = 2.6310e-01, time/batch = 0.6590s	
1525/26050 (epoch 2.927), train_loss = 1.70623925, grad/param norm = 2.1365e-01, time/batch = 0.6635s	
1526/26050 (epoch 2.929), train_loss = 1.73881993, grad/param norm = 2.2752e-01, time/batch = 0.6700s	
1527/26050 (epoch 2.931), train_loss = 2.11357622, grad/param norm = 2.7162e-01, time/batch = 0.6632s	
1528/26050 (epoch 2.933), train_loss = 1.82025247, grad/param norm = 2.5590e-01, time/batch = 0.6586s	
1529/26050 (epoch 2.935), train_loss = 1.62946233, grad/param norm = 2.1943e-01, time/batch = 0.6542s	
1530/26050 (epoch 2.937), train_loss = 1.75043816, grad/param norm = 2.2942e-01, time/batch = 0.6557s	
1531/26050 (epoch 2.939), train_loss = 1.68568699, grad/param norm = 2.4206e-01, time/batch = 0.6768s	
1532/26050 (epoch 2.940), train_loss = 1.88701464, grad/param norm = 2.4342e-01, time/batch = 0.6780s	
1533/26050 (epoch 2.942), train_loss = 1.86600499, grad/param norm = 2.4163e-01, time/batch = 0.6560s	
1534/26050 (epoch 2.944), train_loss = 1.76478916, grad/param norm = 2.4519e-01, time/batch = 0.6567s	
1535/26050 (epoch 2.946), train_loss = 1.95115098, grad/param norm = 2.4375e-01, time/batch = 0.6511s	
1536/26050 (epoch 2.948), train_loss = 1.57001978, grad/param norm = 2.6225e-01, time/batch = 0.6382s	
1537/26050 (epoch 2.950), train_loss = 1.74590220, grad/param norm = 2.3741e-01, time/batch = 0.6388s	
1538/26050 (epoch 2.952), train_loss = 1.98709854, grad/param norm = 2.4417e-01, time/batch = 0.6378s	
1539/26050 (epoch 2.954), train_loss = 1.96190418, grad/param norm = 2.1854e-01, time/batch = 0.6466s	
1540/26050 (epoch 2.956), train_loss = 1.94894307, grad/param norm = 2.2603e-01, time/batch = 0.6465s	
1541/26050 (epoch 2.958), train_loss = 1.85645437, grad/param norm = 2.3088e-01, time/batch = 0.6395s	
1542/26050 (epoch 2.960), train_loss = 1.77007876, grad/param norm = 2.3273e-01, time/batch = 0.6409s	
1543/26050 (epoch 2.962), train_loss = 1.77661896, grad/param norm = 2.2493e-01, time/batch = 0.6371s	
1544/26050 (epoch 2.964), train_loss = 1.87435626, grad/param norm = 2.7135e-01, time/batch = 0.6377s	
1545/26050 (epoch 2.965), train_loss = 1.66327533, grad/param norm = 2.1976e-01, time/batch = 0.6386s	
1546/26050 (epoch 2.967), train_loss = 2.19444114, grad/param norm = 2.4908e-01, time/batch = 0.6485s	
1547/26050 (epoch 2.969), train_loss = 1.77930883, grad/param norm = 2.6927e-01, time/batch = 0.6827s	
1548/26050 (epoch 2.971), train_loss = 1.62289272, grad/param norm = 2.4345e-01, time/batch = 0.6701s	
1549/26050 (epoch 2.973), train_loss = 1.74882280, grad/param norm = 2.3429e-01, time/batch = 0.6493s	
1550/26050 (epoch 2.975), train_loss = 1.89732177, grad/param norm = 2.3168e-01, time/batch = 0.6384s	
1551/26050 (epoch 2.977), train_loss = 1.85179002, grad/param norm = 2.1264e-01, time/batch = 0.6537s	
1552/26050 (epoch 2.979), train_loss = 1.61842033, grad/param norm = 2.2851e-01, time/batch = 0.6415s	
1553/26050 (epoch 2.981), train_loss = 1.85806206, grad/param norm = 2.2314e-01, time/batch = 0.6426s	
1554/26050 (epoch 2.983), train_loss = 1.86821722, grad/param norm = 2.5444e-01, time/batch = 0.6533s	
1555/26050 (epoch 2.985), train_loss = 1.87427700, grad/param norm = 2.5208e-01, time/batch = 0.6564s	
1556/26050 (epoch 2.987), train_loss = 1.98120061, grad/param norm = 2.4433e-01, time/batch = 0.6779s	
1557/26050 (epoch 2.988), train_loss = 2.00388150, grad/param norm = 2.6854e-01, time/batch = 0.6600s	
1558/26050 (epoch 2.990), train_loss = 1.81924180, grad/param norm = 2.9614e-01, time/batch = 0.6545s	
1559/26050 (epoch 2.992), train_loss = 2.06880237, grad/param norm = 2.6430e-01, time/batch = 0.6418s	
1560/26050 (epoch 2.994), train_loss = 1.80677106, grad/param norm = 2.3681e-01, time/batch = 0.6471s	
1561/26050 (epoch 2.996), train_loss = 1.94997864, grad/param norm = 2.8091e-01, time/batch = 0.6446s	
1562/26050 (epoch 2.998), train_loss = 1.88815494, grad/param norm = 2.1725e-01, time/batch = 0.6394s	
1563/26050 (epoch 3.000), train_loss = 1.74199764, grad/param norm = 2.1489e-01, time/batch = 0.6392s	
1564/26050 (epoch 3.002), train_loss = 1.79501403, grad/param norm = 2.1503e-01, time/batch = 0.6420s	
1565/26050 (epoch 3.004), train_loss = 1.78421249, grad/param norm = 2.3350e-01, time/batch = 0.6392s	
1566/26050 (epoch 3.006), train_loss = 1.65949153, grad/param norm = 2.2026e-01, time/batch = 0.6411s	
1567/26050 (epoch 3.008), train_loss = 1.70231342, grad/param norm = 2.2882e-01, time/batch = 0.6414s	
1568/26050 (epoch 3.010), train_loss = 1.79512796, grad/param norm = 2.1077e-01, time/batch = 0.6395s	
1569/26050 (epoch 3.012), train_loss = 1.89723186, grad/param norm = 2.7322e-01, time/batch = 0.6401s	
1570/26050 (epoch 3.013), train_loss = 2.29976158, grad/param norm = 2.5835e-01, time/batch = 0.6375s	
1571/26050 (epoch 3.015), train_loss = 1.72307844, grad/param norm = 2.4972e-01, time/batch = 0.6427s	
1572/26050 (epoch 3.017), train_loss = 1.77844006, grad/param norm = 2.2055e-01, time/batch = 0.6408s	
1573/26050 (epoch 3.019), train_loss = 1.71333048, grad/param norm = 2.2255e-01, time/batch = 0.6384s	
1574/26050 (epoch 3.021), train_loss = 1.95637829, grad/param norm = 2.5094e-01, time/batch = 0.6396s	
1575/26050 (epoch 3.023), train_loss = 1.71038333, grad/param norm = 2.2664e-01, time/batch = 0.6391s	
1576/26050 (epoch 3.025), train_loss = 1.75635331, grad/param norm = 2.5946e-01, time/batch = 0.6407s	
1577/26050 (epoch 3.027), train_loss = 1.63314014, grad/param norm = 2.6828e-01, time/batch = 0.6647s	
1578/26050 (epoch 3.029), train_loss = 1.74752270, grad/param norm = 2.5503e-01, time/batch = 0.6818s	
1579/26050 (epoch 3.031), train_loss = 1.99610128, grad/param norm = 2.7133e-01, time/batch = 0.6444s	
1580/26050 (epoch 3.033), train_loss = 1.85868048, grad/param norm = 2.6126e-01, time/batch = 0.6391s	
1581/26050 (epoch 3.035), train_loss = 2.01144694, grad/param norm = 2.5192e-01, time/batch = 0.6394s	
1582/26050 (epoch 3.036), train_loss = 1.80826826, grad/param norm = 2.5805e-01, time/batch = 0.6394s	
1583/26050 (epoch 3.038), train_loss = 1.62069162, grad/param norm = 2.5072e-01, time/batch = 0.6387s	
1584/26050 (epoch 3.040), train_loss = 1.87383914, grad/param norm = 2.2877e-01, time/batch = 0.6470s	
1585/26050 (epoch 3.042), train_loss = 1.63092638, grad/param norm = 2.2030e-01, time/batch = 0.6411s	
1586/26050 (epoch 3.044), train_loss = 1.85905266, grad/param norm = 2.1406e-01, time/batch = 0.6410s	
1587/26050 (epoch 3.046), train_loss = 1.59994606, grad/param norm = 2.3133e-01, time/batch = 0.6396s	
1588/26050 (epoch 3.048), train_loss = 1.78278940, grad/param norm = 2.1448e-01, time/batch = 0.6394s	
1589/26050 (epoch 3.050), train_loss = 1.65317633, grad/param norm = 2.4969e-01, time/batch = 0.6384s	
1590/26050 (epoch 3.052), train_loss = 1.76993623, grad/param norm = 2.3663e-01, time/batch = 0.6385s	
1591/26050 (epoch 3.054), train_loss = 1.69280034, grad/param norm = 2.9043e-01, time/batch = 0.6410s	
1592/26050 (epoch 3.056), train_loss = 1.45056377, grad/param norm = 2.2591e-01, time/batch = 0.6416s	
1593/26050 (epoch 3.058), train_loss = 1.69562565, grad/param norm = 2.2801e-01, time/batch = 0.6829s	
1594/26050 (epoch 3.060), train_loss = 1.75176698, grad/param norm = 1.9942e-01, time/batch = 0.6584s	
1595/26050 (epoch 3.061), train_loss = 1.64949728, grad/param norm = 2.2852e-01, time/batch = 0.6412s	
1596/26050 (epoch 3.063), train_loss = 1.64553215, grad/param norm = 2.1469e-01, time/batch = 0.6393s	
1597/26050 (epoch 3.065), train_loss = 1.70448015, grad/param norm = 2.2252e-01, time/batch = 0.6380s	
1598/26050 (epoch 3.067), train_loss = 1.85929854, grad/param norm = 2.7598e-01, time/batch = 0.6385s	
1599/26050 (epoch 3.069), train_loss = 1.86780554, grad/param norm = 2.4175e-01, time/batch = 0.6408s	
1600/26050 (epoch 3.071), train_loss = 1.83749571, grad/param norm = 2.4390e-01, time/batch = 0.6394s	
1601/26050 (epoch 3.073), train_loss = 1.98084154, grad/param norm = 2.3334e-01, time/batch = 0.6443s	
1602/26050 (epoch 3.075), train_loss = 1.65813879, grad/param norm = 2.2760e-01, time/batch = 0.6569s	
1603/26050 (epoch 3.077), train_loss = 1.66355841, grad/param norm = 2.3907e-01, time/batch = 0.6485s	
1604/26050 (epoch 3.079), train_loss = 1.93076145, grad/param norm = 2.4504e-01, time/batch = 0.6389s	
1605/26050 (epoch 3.081), train_loss = 1.70147001, grad/param norm = 2.0768e-01, time/batch = 0.6403s	
1606/26050 (epoch 3.083), train_loss = 1.88357796, grad/param norm = 2.5191e-01, time/batch = 0.6397s	
1607/26050 (epoch 3.084), train_loss = 2.05549194, grad/param norm = 2.7554e-01, time/batch = 0.6394s	
1608/26050 (epoch 3.086), train_loss = 1.98411027, grad/param norm = 2.5125e-01, time/batch = 0.6424s	
1609/26050 (epoch 3.088), train_loss = 1.64621645, grad/param norm = 2.1127e-01, time/batch = 0.6411s	
1610/26050 (epoch 3.090), train_loss = 2.03017887, grad/param norm = 2.3882e-01, time/batch = 0.6425s	
1611/26050 (epoch 3.092), train_loss = 1.68968611, grad/param norm = 2.3985e-01, time/batch = 0.6433s	
1612/26050 (epoch 3.094), train_loss = 1.87768526, grad/param norm = 2.3175e-01, time/batch = 0.6415s	
1613/26050 (epoch 3.096), train_loss = 1.56692533, grad/param norm = 2.2513e-01, time/batch = 0.6828s	
1614/26050 (epoch 3.098), train_loss = 1.67212677, grad/param norm = 2.0629e-01, time/batch = 0.6501s	
1615/26050 (epoch 3.100), train_loss = 1.69486375, grad/param norm = 2.4874e-01, time/batch = 0.6395s	
1616/26050 (epoch 3.102), train_loss = 1.81994254, grad/param norm = 2.2977e-01, time/batch = 0.6481s	
1617/26050 (epoch 3.104), train_loss = 1.86997482, grad/param norm = 2.4369e-01, time/batch = 0.6451s	
1618/26050 (epoch 3.106), train_loss = 1.69542255, grad/param norm = 2.3840e-01, time/batch = 0.6414s	
1619/26050 (epoch 3.107), train_loss = 1.48475529, grad/param norm = 2.4126e-01, time/batch = 0.6422s	
1620/26050 (epoch 3.109), train_loss = 1.65821772, grad/param norm = 2.4631e-01, time/batch = 0.6396s	
1621/26050 (epoch 3.111), train_loss = 2.09256937, grad/param norm = 2.4635e-01, time/batch = 0.6401s	
1622/26050 (epoch 3.113), train_loss = 1.73235215, grad/param norm = 2.5963e-01, time/batch = 0.6404s	
1623/26050 (epoch 3.115), train_loss = 1.94458505, grad/param norm = 2.2016e-01, time/batch = 0.6388s	
1624/26050 (epoch 3.117), train_loss = 1.84923659, grad/param norm = 2.4515e-01, time/batch = 0.6392s	
1625/26050 (epoch 3.119), train_loss = 1.64975846, grad/param norm = 2.2346e-01, time/batch = 0.6408s	
1626/26050 (epoch 3.121), train_loss = 1.81818529, grad/param norm = 2.5109e-01, time/batch = 0.6427s	
1627/26050 (epoch 3.123), train_loss = 1.68778248, grad/param norm = 2.4300e-01, time/batch = 0.6422s	
1628/26050 (epoch 3.125), train_loss = 1.44672117, grad/param norm = 1.8989e-01, time/batch = 0.6627s	
1629/26050 (epoch 3.127), train_loss = 1.61713532, grad/param norm = 2.1485e-01, time/batch = 0.6790s	
1630/26050 (epoch 3.129), train_loss = 1.56112307, grad/param norm = 2.1154e-01, time/batch = 0.6395s	
1631/26050 (epoch 3.131), train_loss = 1.72657146, grad/param norm = 2.0627e-01, time/batch = 0.6410s	
1632/26050 (epoch 3.132), train_loss = 1.65683779, grad/param norm = 2.0493e-01, time/batch = 0.6399s	
1633/26050 (epoch 3.134), train_loss = 1.74085064, grad/param norm = 2.4455e-01, time/batch = 0.6398s	
1634/26050 (epoch 3.136), train_loss = 1.69620123, grad/param norm = 1.9291e-01, time/batch = 0.6394s	
1635/26050 (epoch 3.138), train_loss = 1.69080476, grad/param norm = 2.3157e-01, time/batch = 0.6383s	
1636/26050 (epoch 3.140), train_loss = 1.76936933, grad/param norm = 2.3295e-01, time/batch = 0.6399s	
1637/26050 (epoch 3.142), train_loss = 1.76278710, grad/param norm = 2.5885e-01, time/batch = 0.6402s	
1638/26050 (epoch 3.144), train_loss = 1.64009711, grad/param norm = 2.4268e-01, time/batch = 0.6499s	
1639/26050 (epoch 3.146), train_loss = 1.52816648, grad/param norm = 2.4259e-01, time/batch = 0.6704s	
1640/26050 (epoch 3.148), train_loss = 1.57914393, grad/param norm = 2.0082e-01, time/batch = 0.6767s	
1641/26050 (epoch 3.150), train_loss = 1.81516314, grad/param norm = 2.4340e-01, time/batch = 0.6786s	
1642/26050 (epoch 3.152), train_loss = 2.04238412, grad/param norm = 2.5081e-01, time/batch = 0.6780s	
1643/26050 (epoch 3.154), train_loss = 1.60976073, grad/param norm = 2.3689e-01, time/batch = 0.6786s	
1644/26050 (epoch 3.155), train_loss = 1.65043113, grad/param norm = 2.1730e-01, time/batch = 0.6845s	
1645/26050 (epoch 3.157), train_loss = 1.78068087, grad/param norm = 2.3453e-01, time/batch = 0.6511s	
1646/26050 (epoch 3.159), train_loss = 1.84995626, grad/param norm = 2.4586e-01, time/batch = 0.6414s	
1647/26050 (epoch 3.161), train_loss = 1.99884661, grad/param norm = 2.4807e-01, time/batch = 0.6479s	
1648/26050 (epoch 3.163), train_loss = 1.70363006, grad/param norm = 2.3700e-01, time/batch = 0.6427s	
1649/26050 (epoch 3.165), train_loss = 1.40935498, grad/param norm = 2.0354e-01, time/batch = 0.6409s	
1650/26050 (epoch 3.167), train_loss = 1.95690401, grad/param norm = 3.0102e-01, time/batch = 0.6420s	
1651/26050 (epoch 3.169), train_loss = 1.85189107, grad/param norm = 2.5029e-01, time/batch = 0.6497s	
1652/26050 (epoch 3.171), train_loss = 1.58489662, grad/param norm = 2.0892e-01, time/batch = 0.6413s	
1653/26050 (epoch 3.173), train_loss = 1.74135737, grad/param norm = 2.5368e-01, time/batch = 0.6415s	
1654/26050 (epoch 3.175), train_loss = 1.79690992, grad/param norm = 2.6006e-01, time/batch = 0.6679s	
1655/26050 (epoch 3.177), train_loss = 1.84265925, grad/param norm = 2.2385e-01, time/batch = 0.6793s	
1656/26050 (epoch 3.179), train_loss = 1.42641022, grad/param norm = 2.0379e-01, time/batch = 0.6576s	
1657/26050 (epoch 3.180), train_loss = 1.95053911, grad/param norm = 2.2570e-01, time/batch = 0.6526s	
1658/26050 (epoch 3.182), train_loss = 2.10841760, grad/param norm = 2.4242e-01, time/batch = 0.6404s	
1659/26050 (epoch 3.184), train_loss = 1.81187707, grad/param norm = 2.2488e-01, time/batch = 0.6416s	
1660/26050 (epoch 3.186), train_loss = 1.50588009, grad/param norm = 2.0536e-01, time/batch = 0.6396s	
1661/26050 (epoch 3.188), train_loss = 1.69856716, grad/param norm = 2.2094e-01, time/batch = 0.6406s	
1662/26050 (epoch 3.190), train_loss = 1.82407973, grad/param norm = 2.2410e-01, time/batch = 0.6460s	
1663/26050 (epoch 3.192), train_loss = 1.75123877, grad/param norm = 2.1881e-01, time/batch = 0.6424s	
1664/26050 (epoch 3.194), train_loss = 1.73666240, grad/param norm = 2.2729e-01, time/batch = 0.6406s	
1665/26050 (epoch 3.196), train_loss = 1.90323640, grad/param norm = 2.9030e-01, time/batch = 0.6397s	
1666/26050 (epoch 3.198), train_loss = 1.65520490, grad/param norm = 2.1967e-01, time/batch = 0.6385s	
1667/26050 (epoch 3.200), train_loss = 1.67351571, grad/param norm = 2.4142e-01, time/batch = 0.6377s	
1668/26050 (epoch 3.202), train_loss = 1.64395271, grad/param norm = 2.3740e-01, time/batch = 0.6410s	
1669/26050 (epoch 3.203), train_loss = 1.83603643, grad/param norm = 2.5263e-01, time/batch = 0.6541s	
1670/26050 (epoch 3.205), train_loss = 1.62407332, grad/param norm = 2.3496e-01, time/batch = 0.6827s	
1671/26050 (epoch 3.207), train_loss = 1.68846478, grad/param norm = 2.0192e-01, time/batch = 0.6543s	
1672/26050 (epoch 3.209), train_loss = 1.68908358, grad/param norm = 2.1532e-01, time/batch = 0.6419s	
1673/26050 (epoch 3.211), train_loss = 1.64423211, grad/param norm = 2.5547e-01, time/batch = 0.6377s	
1674/26050 (epoch 3.213), train_loss = 1.80432834, grad/param norm = 2.5181e-01, time/batch = 0.6427s	
1675/26050 (epoch 3.215), train_loss = 1.81869390, grad/param norm = 2.3729e-01, time/batch = 0.6404s	
1676/26050 (epoch 3.217), train_loss = 1.72854388, grad/param norm = 2.6041e-01, time/batch = 0.6398s	
1677/26050 (epoch 3.219), train_loss = 1.63974386, grad/param norm = 2.2885e-01, time/batch = 0.6407s	
1678/26050 (epoch 3.221), train_loss = 1.64118737, grad/param norm = 2.2703e-01, time/batch = 0.6374s	
1679/26050 (epoch 3.223), train_loss = 1.88337388, grad/param norm = 2.4209e-01, time/batch = 0.6393s	
1680/26050 (epoch 3.225), train_loss = 1.64674143, grad/param norm = 2.3966e-01, time/batch = 0.6390s	
1681/26050 (epoch 3.226), train_loss = 1.89768297, grad/param norm = 2.7420e-01, time/batch = 0.6384s	
1682/26050 (epoch 3.228), train_loss = 1.85381033, grad/param norm = 2.6254e-01, time/batch = 0.6384s	
1683/26050 (epoch 3.230), train_loss = 1.70607588, grad/param norm = 2.1636e-01, time/batch = 0.6374s	
1684/26050 (epoch 3.232), train_loss = 1.90256522, grad/param norm = 2.4746e-01, time/batch = 0.6374s	
1685/26050 (epoch 3.234), train_loss = 1.52804507, grad/param norm = 2.1103e-01, time/batch = 0.6738s	
1686/26050 (epoch 3.236), train_loss = 1.77255688, grad/param norm = 2.5714e-01, time/batch = 0.6698s	
1687/26050 (epoch 3.238), train_loss = 1.52182322, grad/param norm = 2.4124e-01, time/batch = 0.6490s	
1688/26050 (epoch 3.240), train_loss = 1.63938747, grad/param norm = 1.9920e-01, time/batch = 0.6424s	
1689/26050 (epoch 3.242), train_loss = 1.77403310, grad/param norm = 2.5368e-01, time/batch = 0.6395s	
1690/26050 (epoch 3.244), train_loss = 1.76445571, grad/param norm = 2.4767e-01, time/batch = 0.6374s	
1691/26050 (epoch 3.246), train_loss = 1.62589985, grad/param norm = 2.2849e-01, time/batch = 0.6396s	
1692/26050 (epoch 3.248), train_loss = 1.84396854, grad/param norm = 2.4644e-01, time/batch = 0.6386s	
1693/26050 (epoch 3.250), train_loss = 1.82107566, grad/param norm = 2.5977e-01, time/batch = 0.6403s	
1694/26050 (epoch 3.251), train_loss = 1.61130141, grad/param norm = 2.4331e-01, time/batch = 0.6411s	
1695/26050 (epoch 3.253), train_loss = 1.57376155, grad/param norm = 2.4059e-01, time/batch = 0.6405s	
1696/26050 (epoch 3.255), train_loss = 1.96817874, grad/param norm = 2.4933e-01, time/batch = 0.6381s	
1697/26050 (epoch 3.257), train_loss = 1.76375170, grad/param norm = 2.3414e-01, time/batch = 0.6375s	
1698/26050 (epoch 3.259), train_loss = 1.82539663, grad/param norm = 2.4741e-01, time/batch = 0.6382s	
1699/26050 (epoch 3.261), train_loss = 1.69237807, grad/param norm = 2.2431e-01, time/batch = 0.6476s	
1700/26050 (epoch 3.263), train_loss = 1.75789422, grad/param norm = 2.4282e-01, time/batch = 0.6604s	
1701/26050 (epoch 3.265), train_loss = 1.94529072, grad/param norm = 2.1192e-01, time/batch = 0.6851s	
1702/26050 (epoch 3.267), train_loss = 1.80422152, grad/param norm = 2.3740e-01, time/batch = 0.6457s	
1703/26050 (epoch 3.269), train_loss = 1.97491974, grad/param norm = 2.5667e-01, time/batch = 0.6395s	
1704/26050 (epoch 3.271), train_loss = 1.71388394, grad/param norm = 2.1817e-01, time/batch = 0.6447s	
1705/26050 (epoch 3.273), train_loss = 1.77399395, grad/param norm = 2.4445e-01, time/batch = 0.6420s	
1706/26050 (epoch 3.274), train_loss = 1.68952101, grad/param norm = 2.1573e-01, time/batch = 0.6376s	
1707/26050 (epoch 3.276), train_loss = 1.60888691, grad/param norm = 2.1262e-01, time/batch = 0.6393s	
1708/26050 (epoch 3.278), train_loss = 1.80524436, grad/param norm = 2.1667e-01, time/batch = 0.6399s	
1709/26050 (epoch 3.280), train_loss = 1.69387466, grad/param norm = 2.0834e-01, time/batch = 0.6423s	
1710/26050 (epoch 3.282), train_loss = 1.75254293, grad/param norm = 2.1550e-01, time/batch = 0.6406s	
1711/26050 (epoch 3.284), train_loss = 1.57420426, grad/param norm = 2.3807e-01, time/batch = 0.6679s	
1712/26050 (epoch 3.286), train_loss = 1.66941467, grad/param norm = 2.5892e-01, time/batch = 0.6654s	
1713/26050 (epoch 3.288), train_loss = 1.58225408, grad/param norm = 2.2960e-01, time/batch = 0.6413s	
1714/26050 (epoch 3.290), train_loss = 1.61868160, grad/param norm = 2.2667e-01, time/batch = 0.6406s	
1715/26050 (epoch 3.292), train_loss = 1.62633954, grad/param norm = 2.1467e-01, time/batch = 0.6422s	
1716/26050 (epoch 3.294), train_loss = 1.75182294, grad/param norm = 2.3921e-01, time/batch = 0.6573s	
1717/26050 (epoch 3.296), train_loss = 1.80672944, grad/param norm = 2.1999e-01, time/batch = 0.6522s	
1718/26050 (epoch 3.298), train_loss = 1.68932193, grad/param norm = 2.3502e-01, time/batch = 0.6578s	
1719/26050 (epoch 3.299), train_loss = 1.42906637, grad/param norm = 2.1272e-01, time/batch = 0.6580s	
1720/26050 (epoch 3.301), train_loss = 1.59962411, grad/param norm = 2.2456e-01, time/batch = 0.6553s	
1721/26050 (epoch 3.303), train_loss = 1.76100351, grad/param norm = 2.6598e-01, time/batch = 0.6568s	
1722/26050 (epoch 3.305), train_loss = 1.65744282, grad/param norm = 2.2489e-01, time/batch = 0.6543s	
1723/26050 (epoch 3.307), train_loss = 1.53173323, grad/param norm = 2.2625e-01, time/batch = 0.6515s	
1724/26050 (epoch 3.309), train_loss = 1.62230003, grad/param norm = 2.2747e-01, time/batch = 0.6527s	
1725/26050 (epoch 3.311), train_loss = 1.95843821, grad/param norm = 2.6247e-01, time/batch = 0.6588s	
1726/26050 (epoch 3.313), train_loss = 1.79140037, grad/param norm = 2.4431e-01, time/batch = 0.6648s	
1727/26050 (epoch 3.315), train_loss = 1.92897872, grad/param norm = 2.6215e-01, time/batch = 0.6844s	
1728/26050 (epoch 3.317), train_loss = 1.57991583, grad/param norm = 2.2492e-01, time/batch = 0.6570s	
1729/26050 (epoch 3.319), train_loss = 1.64880114, grad/param norm = 2.1405e-01, time/batch = 0.6516s	
1730/26050 (epoch 3.321), train_loss = 1.74795781, grad/param norm = 2.4426e-01, time/batch = 0.6547s	
1731/26050 (epoch 3.322), train_loss = 1.71693495, grad/param norm = 2.5302e-01, time/batch = 0.6552s	
1732/26050 (epoch 3.324), train_loss = 1.56549253, grad/param norm = 2.4371e-01, time/batch = 0.6652s	
1733/26050 (epoch 3.326), train_loss = 1.86199923, grad/param norm = 2.4386e-01, time/batch = 0.6644s	
1734/26050 (epoch 3.328), train_loss = 1.75541770, grad/param norm = 2.1524e-01, time/batch = 0.6653s	
1735/26050 (epoch 3.330), train_loss = 1.62836978, grad/param norm = 2.3659e-01, time/batch = 0.6635s	
1736/26050 (epoch 3.332), train_loss = 1.83882928, grad/param norm = 2.2404e-01, time/batch = 0.6549s	
1737/26050 (epoch 3.334), train_loss = 1.68635216, grad/param norm = 2.2509e-01, time/batch = 0.6419s	
1738/26050 (epoch 3.336), train_loss = 1.52718085, grad/param norm = 1.9513e-01, time/batch = 0.6410s	
1739/26050 (epoch 3.338), train_loss = 1.50853871, grad/param norm = 2.0136e-01, time/batch = 0.6382s	
1740/26050 (epoch 3.340), train_loss = 1.83021669, grad/param norm = 2.4402e-01, time/batch = 0.6406s	
1741/26050 (epoch 3.342), train_loss = 1.80454605, grad/param norm = 2.4898e-01, time/batch = 0.6550s	
1742/26050 (epoch 3.344), train_loss = 1.69003137, grad/param norm = 2.3104e-01, time/batch = 0.6833s	
1743/26050 (epoch 3.345), train_loss = 1.69783666, grad/param norm = 2.2700e-01, time/batch = 0.6526s	
1744/26050 (epoch 3.347), train_loss = 1.76576087, grad/param norm = 2.4549e-01, time/batch = 0.6529s	
1745/26050 (epoch 3.349), train_loss = 1.68440620, grad/param norm = 2.2517e-01, time/batch = 0.6423s	
1746/26050 (epoch 3.351), train_loss = 1.70592717, grad/param norm = 2.2188e-01, time/batch = 0.6399s	
1747/26050 (epoch 3.353), train_loss = 1.63691701, grad/param norm = 2.3459e-01, time/batch = 0.6395s	
1748/26050 (epoch 3.355), train_loss = 1.76819778, grad/param norm = 2.4301e-01, time/batch = 0.6465s	
1749/26050 (epoch 3.357), train_loss = 1.52045278, grad/param norm = 2.2166e-01, time/batch = 0.6409s	
1750/26050 (epoch 3.359), train_loss = 1.72130259, grad/param norm = 2.0256e-01, time/batch = 0.6476s	
1751/26050 (epoch 3.361), train_loss = 1.48879635, grad/param norm = 2.0040e-01, time/batch = 0.6458s	
1752/26050 (epoch 3.363), train_loss = 1.68077437, grad/param norm = 2.1517e-01, time/batch = 0.6422s	
1753/26050 (epoch 3.365), train_loss = 1.54377602, grad/param norm = 2.2141e-01, time/batch = 0.6484s	
1754/26050 (epoch 3.367), train_loss = 1.67696834, grad/param norm = 2.4218e-01, time/batch = 0.6496s	
1755/26050 (epoch 3.369), train_loss = 1.68376990, grad/param norm = 2.1476e-01, time/batch = 0.6507s	
1756/26050 (epoch 3.370), train_loss = 1.60392962, grad/param norm = 2.3750e-01, time/batch = 0.6448s	
1757/26050 (epoch 3.372), train_loss = 1.87840649, grad/param norm = 2.3083e-01, time/batch = 0.6392s	
1758/26050 (epoch 3.374), train_loss = 1.90531942, grad/param norm = 2.5278e-01, time/batch = 0.6456s	
1759/26050 (epoch 3.376), train_loss = 1.92617628, grad/param norm = 2.1634e-01, time/batch = 0.6527s	
1760/26050 (epoch 3.378), train_loss = 1.72000543, grad/param norm = 2.3875e-01, time/batch = 0.6511s	
1761/26050 (epoch 3.380), train_loss = 1.86034031, grad/param norm = 2.3658e-01, time/batch = 0.6574s	
1762/26050 (epoch 3.382), train_loss = 2.10101619, grad/param norm = 2.4584e-01, time/batch = 0.6431s	
1763/26050 (epoch 3.384), train_loss = 1.66682023, grad/param norm = 2.2357e-01, time/batch = 0.6406s	
1764/26050 (epoch 3.386), train_loss = 1.80743929, grad/param norm = 2.3232e-01, time/batch = 0.6486s	
1765/26050 (epoch 3.388), train_loss = 1.70767610, grad/param norm = 2.0041e-01, time/batch = 0.6396s	
1766/26050 (epoch 3.390), train_loss = 1.59492103, grad/param norm = 1.9856e-01, time/batch = 0.6391s	
1767/26050 (epoch 3.392), train_loss = 1.62710336, grad/param norm = 2.1950e-01, time/batch = 0.6414s	
1768/26050 (epoch 3.393), train_loss = 1.76533165, grad/param norm = 2.2836e-01, time/batch = 0.6803s	
1769/26050 (epoch 3.395), train_loss = 1.74333319, grad/param norm = 2.2468e-01, time/batch = 0.6569s	
1770/26050 (epoch 3.397), train_loss = 1.75569309, grad/param norm = 2.1543e-01, time/batch = 0.6391s	
1771/26050 (epoch 3.399), train_loss = 1.57156027, grad/param norm = 2.0261e-01, time/batch = 0.6415s	
1772/26050 (epoch 3.401), train_loss = 1.64340652, grad/param norm = 2.2993e-01, time/batch = 0.6413s	
1773/26050 (epoch 3.403), train_loss = 1.69401964, grad/param norm = 2.5944e-01, time/batch = 0.6392s	
1774/26050 (epoch 3.405), train_loss = 1.74697030, grad/param norm = 2.5549e-01, time/batch = 0.6439s	
1775/26050 (epoch 3.407), train_loss = 1.85870147, grad/param norm = 2.3302e-01, time/batch = 0.6501s	
1776/26050 (epoch 3.409), train_loss = 1.86667737, grad/param norm = 2.4430e-01, time/batch = 0.6405s	
1777/26050 (epoch 3.411), train_loss = 1.71827083, grad/param norm = 2.2150e-01, time/batch = 0.6405s	
1778/26050 (epoch 3.413), train_loss = 1.83489017, grad/param norm = 2.1949e-01, time/batch = 0.6464s	
1779/26050 (epoch 3.415), train_loss = 1.87348081, grad/param norm = 2.3463e-01, time/batch = 0.6543s	
1780/26050 (epoch 3.417), train_loss = 1.88913182, grad/param norm = 2.3518e-01, time/batch = 0.6616s	
1781/26050 (epoch 3.418), train_loss = 1.80793261, grad/param norm = 2.1648e-01, time/batch = 0.6614s	
1782/26050 (epoch 3.420), train_loss = 1.45691922, grad/param norm = 2.0469e-01, time/batch = 0.6551s	
1783/26050 (epoch 3.422), train_loss = 1.59408731, grad/param norm = 2.2544e-01, time/batch = 0.6562s	
1784/26050 (epoch 3.424), train_loss = 2.01004872, grad/param norm = 2.6832e-01, time/batch = 0.6591s	
1785/26050 (epoch 3.426), train_loss = 1.94523149, grad/param norm = 3.0519e-01, time/batch = 0.6498s	
1786/26050 (epoch 3.428), train_loss = 1.60293526, grad/param norm = 1.9352e-01, time/batch = 0.6593s	
1787/26050 (epoch 3.430), train_loss = 1.71325497, grad/param norm = 2.3265e-01, time/batch = 0.6587s	
1788/26050 (epoch 3.432), train_loss = 1.70068894, grad/param norm = 2.3363e-01, time/batch = 0.6575s	
1789/26050 (epoch 3.434), train_loss = 1.81000811, grad/param norm = 2.2648e-01, time/batch = 0.6578s	
1790/26050 (epoch 3.436), train_loss = 1.90520215, grad/param norm = 2.1978e-01, time/batch = 0.6580s	
1791/26050 (epoch 3.438), train_loss = 1.61615878, grad/param norm = 2.2871e-01, time/batch = 0.6496s	
1792/26050 (epoch 3.440), train_loss = 1.75542226, grad/param norm = 2.2496e-01, time/batch = 0.6427s	
1793/26050 (epoch 3.441), train_loss = 1.66951031, grad/param norm = 2.5046e-01, time/batch = 0.6419s	
1794/26050 (epoch 3.443), train_loss = 1.52205163, grad/param norm = 1.8444e-01, time/batch = 0.6494s	
1795/26050 (epoch 3.445), train_loss = 1.58882425, grad/param norm = 2.2062e-01, time/batch = 0.6470s	
1796/26050 (epoch 3.447), train_loss = 1.94552357, grad/param norm = 2.1315e-01, time/batch = 0.6423s	
1797/26050 (epoch 3.449), train_loss = 1.60692101, grad/param norm = 2.2616e-01, time/batch = 0.6421s	
1798/26050 (epoch 3.451), train_loss = 1.71512073, grad/param norm = 2.2778e-01, time/batch = 0.6427s	
1799/26050 (epoch 3.453), train_loss = 1.52721935, grad/param norm = 2.0340e-01, time/batch = 0.6453s	
1800/26050 (epoch 3.455), train_loss = 1.68014593, grad/param norm = 2.0652e-01, time/batch = 0.6409s	
1801/26050 (epoch 3.457), train_loss = 1.77532622, grad/param norm = 2.5032e-01, time/batch = 0.6419s	
1802/26050 (epoch 3.459), train_loss = 1.87911636, grad/param norm = 2.8821e-01, time/batch = 0.6430s	
1803/26050 (epoch 3.461), train_loss = 1.75683707, grad/param norm = 2.3650e-01, time/batch = 0.6799s	
1804/26050 (epoch 3.463), train_loss = 1.61768125, grad/param norm = 2.0276e-01, time/batch = 0.6664s	
1805/26050 (epoch 3.464), train_loss = 1.81992541, grad/param norm = 2.3108e-01, time/batch = 0.6391s	
1806/26050 (epoch 3.466), train_loss = 1.83063373, grad/param norm = 2.0777e-01, time/batch = 0.6402s	
1807/26050 (epoch 3.468), train_loss = 1.82236542, grad/param norm = 2.1117e-01, time/batch = 0.6397s	
1808/26050 (epoch 3.470), train_loss = 1.91925368, grad/param norm = 2.3395e-01, time/batch = 0.6451s	
1809/26050 (epoch 3.472), train_loss = 2.00909254, grad/param norm = 2.5426e-01, time/batch = 0.6412s	
1810/26050 (epoch 3.474), train_loss = 2.01795617, grad/param norm = 2.4116e-01, time/batch = 0.6559s	
1811/26050 (epoch 3.476), train_loss = 1.85539237, grad/param norm = 2.1603e-01, time/batch = 0.6501s	
1812/26050 (epoch 3.478), train_loss = 1.64459365, grad/param norm = 2.0064e-01, time/batch = 0.6419s	
1813/26050 (epoch 3.480), train_loss = 1.76467839, grad/param norm = 2.0707e-01, time/batch = 0.6411s	
1814/26050 (epoch 3.482), train_loss = 1.68359196, grad/param norm = 2.2196e-01, time/batch = 0.6469s	
1815/26050 (epoch 3.484), train_loss = 1.54622834, grad/param norm = 2.1239e-01, time/batch = 0.6409s	
1816/26050 (epoch 3.486), train_loss = 1.88845440, grad/param norm = 2.3038e-01, time/batch = 0.6452s	
1817/26050 (epoch 3.488), train_loss = 2.06735786, grad/param norm = 2.3426e-01, time/batch = 0.6407s	
1818/26050 (epoch 3.489), train_loss = 1.95512440, grad/param norm = 2.3673e-01, time/batch = 0.6598s	
1819/26050 (epoch 3.491), train_loss = 1.65665401, grad/param norm = 2.2533e-01, time/batch = 0.6825s	
1820/26050 (epoch 3.493), train_loss = 1.62682152, grad/param norm = 2.0326e-01, time/batch = 0.6390s	
1821/26050 (epoch 3.495), train_loss = 1.74520031, grad/param norm = 2.3939e-01, time/batch = 0.6401s	
1822/26050 (epoch 3.497), train_loss = 1.63223220, grad/param norm = 2.1650e-01, time/batch = 0.6390s	
1823/26050 (epoch 3.499), train_loss = 1.64049637, grad/param norm = 2.2117e-01, time/batch = 0.6437s	
1824/26050 (epoch 3.501), train_loss = 1.67389723, grad/param norm = 2.1424e-01, time/batch = 0.6507s	
1825/26050 (epoch 3.503), train_loss = 1.69301473, grad/param norm = 2.1526e-01, time/batch = 0.6451s	
1826/26050 (epoch 3.505), train_loss = 1.80350840, grad/param norm = 2.1586e-01, time/batch = 0.6547s	
1827/26050 (epoch 3.507), train_loss = 1.84626731, grad/param norm = 2.3785e-01, time/batch = 0.6565s	
1828/26050 (epoch 3.509), train_loss = 1.98755212, grad/param norm = 2.9492e-01, time/batch = 0.6571s	
1829/26050 (epoch 3.511), train_loss = 1.62601766, grad/param norm = 2.1576e-01, time/batch = 0.6407s	
1830/26050 (epoch 3.512), train_loss = 1.79368998, grad/param norm = 2.3213e-01, time/batch = 0.6510s	
1831/26050 (epoch 3.514), train_loss = 1.78876051, grad/param norm = 2.2343e-01, time/batch = 0.6476s	
1832/26050 (epoch 3.516), train_loss = 1.81909995, grad/param norm = 2.1764e-01, time/batch = 0.6424s	
1833/26050 (epoch 3.518), train_loss = 1.78731060, grad/param norm = 2.3409e-01, time/batch = 0.6483s	
1834/26050 (epoch 3.520), train_loss = 1.75935596, grad/param norm = 2.2326e-01, time/batch = 0.6830s	
1835/26050 (epoch 3.522), train_loss = 1.67274791, grad/param norm = 2.2560e-01, time/batch = 0.6394s	
1836/26050 (epoch 3.524), train_loss = 2.02376945, grad/param norm = 2.3921e-01, time/batch = 0.6465s	
1837/26050 (epoch 3.526), train_loss = 1.82920654, grad/param norm = 2.5007e-01, time/batch = 0.6406s	
1838/26050 (epoch 3.528), train_loss = 1.84472231, grad/param norm = 2.5502e-01, time/batch = 0.6380s	
1839/26050 (epoch 3.530), train_loss = 1.72101227, grad/param norm = 2.1663e-01, time/batch = 0.6401s	
1840/26050 (epoch 3.532), train_loss = 1.78314209, grad/param norm = 2.1832e-01, time/batch = 0.6390s	
1841/26050 (epoch 3.534), train_loss = 1.80013239, grad/param norm = 2.2811e-01, time/batch = 0.6431s	
1842/26050 (epoch 3.536), train_loss = 1.66633286, grad/param norm = 2.4883e-01, time/batch = 0.6425s	
1843/26050 (epoch 3.537), train_loss = 1.82493529, grad/param norm = 2.0756e-01, time/batch = 0.6417s	
1844/26050 (epoch 3.539), train_loss = 1.69375272, grad/param norm = 2.2275e-01, time/batch = 0.6384s	
1845/26050 (epoch 3.541), train_loss = 1.89621197, grad/param norm = 2.4228e-01, time/batch = 0.6372s	
1846/26050 (epoch 3.543), train_loss = 1.54968935, grad/param norm = 2.1800e-01, time/batch = 0.6381s	
1847/26050 (epoch 3.545), train_loss = 1.76621217, grad/param norm = 2.3072e-01, time/batch = 0.6384s	
1848/26050 (epoch 3.547), train_loss = 1.80930219, grad/param norm = 2.3592e-01, time/batch = 0.6385s	
1849/26050 (epoch 3.549), train_loss = 1.61372506, grad/param norm = 2.1448e-01, time/batch = 0.6431s	
1850/26050 (epoch 3.551), train_loss = 1.79467775, grad/param norm = 2.3948e-01, time/batch = 0.6372s	
1851/26050 (epoch 3.553), train_loss = 1.69145611, grad/param norm = 2.3141e-01, time/batch = 0.6378s	
1852/26050 (epoch 3.555), train_loss = 1.68169918, grad/param norm = 2.2098e-01, time/batch = 0.6393s	
1853/26050 (epoch 3.557), train_loss = 1.81311088, grad/param norm = 2.2161e-01, time/batch = 0.6379s	
1854/26050 (epoch 3.559), train_loss = 1.75335414, grad/param norm = 2.5179e-01, time/batch = 0.6833s	
1855/26050 (epoch 3.560), train_loss = 1.71907663, grad/param norm = 2.0846e-01, time/batch = 0.6587s	
1856/26050 (epoch 3.562), train_loss = 1.75947393, grad/param norm = 2.2392e-01, time/batch = 0.6401s	
1857/26050 (epoch 3.564), train_loss = 1.92671950, grad/param norm = 2.5234e-01, time/batch = 0.6531s	
1858/26050 (epoch 3.566), train_loss = 1.64543172, grad/param norm = 2.2827e-01, time/batch = 0.6428s	
1859/26050 (epoch 3.568), train_loss = 1.76717537, grad/param norm = 2.0221e-01, time/batch = 0.6386s	
1860/26050 (epoch 3.570), train_loss = 1.82990395, grad/param norm = 2.3876e-01, time/batch = 0.6422s	
1861/26050 (epoch 3.572), train_loss = 1.79643333, grad/param norm = 2.2514e-01, time/batch = 0.6419s	
1862/26050 (epoch 3.574), train_loss = 1.87983401, grad/param norm = 2.5332e-01, time/batch = 0.6493s	
1863/26050 (epoch 3.576), train_loss = 1.81590032, grad/param norm = 2.3006e-01, time/batch = 0.6429s	
1864/26050 (epoch 3.578), train_loss = 1.78929873, grad/param norm = 2.2123e-01, time/batch = 0.6439s	
1865/26050 (epoch 3.580), train_loss = 1.62866559, grad/param norm = 2.1288e-01, time/batch = 0.6391s	
1866/26050 (epoch 3.582), train_loss = 1.83138398, grad/param norm = 2.2775e-01, time/batch = 0.6410s	
1867/26050 (epoch 3.583), train_loss = 1.79102850, grad/param norm = 2.2140e-01, time/batch = 0.6417s	
1868/26050 (epoch 3.585), train_loss = 1.61515814, grad/param norm = 2.2181e-01, time/batch = 0.6407s	
1869/26050 (epoch 3.587), train_loss = 1.81194959, grad/param norm = 2.3633e-01, time/batch = 0.6400s	
1870/26050 (epoch 3.589), train_loss = 1.78442592, grad/param norm = 2.4044e-01, time/batch = 0.6409s	
1871/26050 (epoch 3.591), train_loss = 1.79689319, grad/param norm = 2.2004e-01, time/batch = 0.6460s	
1872/26050 (epoch 3.593), train_loss = 1.63109468, grad/param norm = 2.2599e-01, time/batch = 0.6411s	
1873/26050 (epoch 3.595), train_loss = 1.87782241, grad/param norm = 2.6337e-01, time/batch = 0.6442s	
1874/26050 (epoch 3.597), train_loss = 1.76949759, grad/param norm = 2.4401e-01, time/batch = 0.6432s	
1875/26050 (epoch 3.599), train_loss = 1.58265740, grad/param norm = 2.0239e-01, time/batch = 0.6461s	
1876/26050 (epoch 3.601), train_loss = 1.92776113, grad/param norm = 2.3173e-01, time/batch = 0.6467s	
1877/26050 (epoch 3.603), train_loss = 1.82944761, grad/param norm = 2.2188e-01, time/batch = 0.6483s	
1878/26050 (epoch 3.605), train_loss = 1.64851840, grad/param norm = 1.8997e-01, time/batch = 0.6497s	
1879/26050 (epoch 3.607), train_loss = 1.83547609, grad/param norm = 2.3067e-01, time/batch = 0.6448s	
1880/26050 (epoch 3.608), train_loss = 1.71072585, grad/param norm = 2.0495e-01, time/batch = 0.6409s	
1881/26050 (epoch 3.610), train_loss = 1.71729716, grad/param norm = 2.4464e-01, time/batch = 0.6411s	
1882/26050 (epoch 3.612), train_loss = 1.69487606, grad/param norm = 2.3209e-01, time/batch = 0.6409s	
1883/26050 (epoch 3.614), train_loss = 1.77350046, grad/param norm = 2.4184e-01, time/batch = 0.6411s	
1884/26050 (epoch 3.616), train_loss = 2.07387410, grad/param norm = 2.3708e-01, time/batch = 0.6568s	
1885/26050 (epoch 3.618), train_loss = 1.62755656, grad/param norm = 2.3116e-01, time/batch = 0.6411s	
1886/26050 (epoch 3.620), train_loss = 1.81640086, grad/param norm = 2.4301e-01, time/batch = 0.6408s	
1887/26050 (epoch 3.622), train_loss = 1.44956159, grad/param norm = 2.0135e-01, time/batch = 0.6444s	
1888/26050 (epoch 3.624), train_loss = 1.63238510, grad/param norm = 2.1190e-01, time/batch = 0.6412s	
1889/26050 (epoch 3.626), train_loss = 1.73816535, grad/param norm = 2.5213e-01, time/batch = 0.6409s	
1890/26050 (epoch 3.628), train_loss = 1.75148674, grad/param norm = 2.3966e-01, time/batch = 0.6399s	
1891/26050 (epoch 3.630), train_loss = 1.86004940, grad/param norm = 2.1164e-01, time/batch = 0.6437s	
1892/26050 (epoch 3.631), train_loss = 1.81459580, grad/param norm = 2.1914e-01, time/batch = 0.6417s	
1893/26050 (epoch 3.633), train_loss = 1.56831328, grad/param norm = 1.9778e-01, time/batch = 0.6407s	
1894/26050 (epoch 3.635), train_loss = 1.60436044, grad/param norm = 2.1270e-01, time/batch = 0.6453s	
1895/26050 (epoch 3.637), train_loss = 1.62178233, grad/param norm = 2.1878e-01, time/batch = 0.6424s	
1896/26050 (epoch 3.639), train_loss = 1.78827161, grad/param norm = 2.1075e-01, time/batch = 0.6390s	
1897/26050 (epoch 3.641), train_loss = 1.63738496, grad/param norm = 1.9253e-01, time/batch = 0.6404s	
1898/26050 (epoch 3.643), train_loss = 1.63051840, grad/param norm = 1.9906e-01, time/batch = 0.6406s	
1899/26050 (epoch 3.645), train_loss = 1.85013630, grad/param norm = 2.2843e-01, time/batch = 0.6447s	
1900/26050 (epoch 3.647), train_loss = 1.61048466, grad/param norm = 2.1742e-01, time/batch = 0.6676s	
1901/26050 (epoch 3.649), train_loss = 1.75871677, grad/param norm = 2.2890e-01, time/batch = 0.6758s	
1902/26050 (epoch 3.651), train_loss = 1.75367456, grad/param norm = 2.2705e-01, time/batch = 0.6416s	
1903/26050 (epoch 3.653), train_loss = 1.65121060, grad/param norm = 2.2215e-01, time/batch = 0.6460s	
1904/26050 (epoch 3.655), train_loss = 1.64286154, grad/param norm = 2.2441e-01, time/batch = 0.6415s	
1905/26050 (epoch 3.656), train_loss = 1.63766711, grad/param norm = 2.1006e-01, time/batch = 0.6395s	
1906/26050 (epoch 3.658), train_loss = 1.87633918, grad/param norm = 2.3337e-01, time/batch = 0.6401s	
1907/26050 (epoch 3.660), train_loss = 1.58139817, grad/param norm = 2.5003e-01, time/batch = 0.6393s	
1908/26050 (epoch 3.662), train_loss = 1.57664083, grad/param norm = 2.1940e-01, time/batch = 0.6395s	
1909/26050 (epoch 3.664), train_loss = 1.63984619, grad/param norm = 2.2882e-01, time/batch = 0.6423s	
1910/26050 (epoch 3.666), train_loss = 1.76394148, grad/param norm = 2.3935e-01, time/batch = 0.6412s	
1911/26050 (epoch 3.668), train_loss = 1.46306159, grad/param norm = 1.9963e-01, time/batch = 0.6462s	
1912/26050 (epoch 3.670), train_loss = 1.89515111, grad/param norm = 2.6003e-01, time/batch = 0.6535s	
1913/26050 (epoch 3.672), train_loss = 1.62058509, grad/param norm = 2.1728e-01, time/batch = 0.6475s	
1914/26050 (epoch 3.674), train_loss = 1.57314132, grad/param norm = 2.0426e-01, time/batch = 0.6435s	
1915/26050 (epoch 3.676), train_loss = 1.71509690, grad/param norm = 2.2262e-01, time/batch = 0.6746s	
1916/26050 (epoch 3.678), train_loss = 1.90404336, grad/param norm = 2.3786e-01, time/batch = 0.6858s	
1917/26050 (epoch 3.679), train_loss = 1.80720463, grad/param norm = 2.4515e-01, time/batch = 0.6784s	
1918/26050 (epoch 3.681), train_loss = 1.73961131, grad/param norm = 2.2264e-01, time/batch = 0.6761s	
1919/26050 (epoch 3.683), train_loss = 1.63844617, grad/param norm = 2.5440e-01, time/batch = 0.6755s	
1920/26050 (epoch 3.685), train_loss = 1.63946120, grad/param norm = 2.2040e-01, time/batch = 0.6754s	
1921/26050 (epoch 3.687), train_loss = 1.48575835, grad/param norm = 2.0117e-01, time/batch = 0.6707s	
1922/26050 (epoch 3.689), train_loss = 1.69324977, grad/param norm = 2.0044e-01, time/batch = 0.6549s	
1923/26050 (epoch 3.691), train_loss = 1.44567981, grad/param norm = 2.1518e-01, time/batch = 0.6517s	
1924/26050 (epoch 3.693), train_loss = 1.61434202, grad/param norm = 2.3574e-01, time/batch = 0.6598s	
1925/26050 (epoch 3.695), train_loss = 1.75441219, grad/param norm = 2.2523e-01, time/batch = 0.6718s	
1926/26050 (epoch 3.697), train_loss = 1.55359129, grad/param norm = 2.2672e-01, time/batch = 0.6615s	
1927/26050 (epoch 3.699), train_loss = 1.74999739, grad/param norm = 2.3555e-01, time/batch = 0.6575s	
1928/26050 (epoch 3.701), train_loss = 1.53155617, grad/param norm = 1.9705e-01, time/batch = 0.6550s	
1929/26050 (epoch 3.702), train_loss = 1.95639506, grad/param norm = 2.2075e-01, time/batch = 0.6597s	
1930/26050 (epoch 3.704), train_loss = 1.69373318, grad/param norm = 2.1675e-01, time/batch = 0.6538s	
1931/26050 (epoch 3.706), train_loss = 1.83483114, grad/param norm = 2.3580e-01, time/batch = 0.6826s	
1932/26050 (epoch 3.708), train_loss = 1.73896713, grad/param norm = 2.1579e-01, time/batch = 0.6474s	
1933/26050 (epoch 3.710), train_loss = 1.81499767, grad/param norm = 2.0674e-01, time/batch = 0.6403s	
1934/26050 (epoch 3.712), train_loss = 1.89337861, grad/param norm = 2.2021e-01, time/batch = 0.6396s	
1935/26050 (epoch 3.714), train_loss = 1.59218270, grad/param norm = 2.2673e-01, time/batch = 0.6418s	
1936/26050 (epoch 3.716), train_loss = 1.95486943, grad/param norm = 2.5949e-01, time/batch = 0.6435s	
1937/26050 (epoch 3.718), train_loss = 1.79281248, grad/param norm = 2.3740e-01, time/batch = 0.6393s	
1938/26050 (epoch 3.720), train_loss = 1.60008025, grad/param norm = 2.2938e-01, time/batch = 0.6399s	
1939/26050 (epoch 3.722), train_loss = 1.61839742, grad/param norm = 2.5741e-01, time/batch = 0.6396s	
1940/26050 (epoch 3.724), train_loss = 1.56856401, grad/param norm = 2.2839e-01, time/batch = 0.6399s	
1941/26050 (epoch 3.726), train_loss = 1.81539457, grad/param norm = 2.2501e-01, time/batch = 0.6403s	
1942/26050 (epoch 3.727), train_loss = 1.73956987, grad/param norm = 2.1421e-01, time/batch = 0.6419s	
1943/26050 (epoch 3.729), train_loss = 1.83174135, grad/param norm = 2.4456e-01, time/batch = 0.6396s	
1944/26050 (epoch 3.731), train_loss = 1.67262230, grad/param norm = 2.0324e-01, time/batch = 0.6409s	
1945/26050 (epoch 3.733), train_loss = 1.76962985, grad/param norm = 2.6603e-01, time/batch = 0.6393s	
1946/26050 (epoch 3.735), train_loss = 1.90437511, grad/param norm = 2.2769e-01, time/batch = 0.6455s	
1947/26050 (epoch 3.737), train_loss = 1.77601806, grad/param norm = 2.2979e-01, time/batch = 0.6414s	
1948/26050 (epoch 3.739), train_loss = 1.80519568, grad/param norm = 2.3531e-01, time/batch = 0.6456s	
1949/26050 (epoch 3.741), train_loss = 1.58979218, grad/param norm = 2.0622e-01, time/batch = 0.6401s	
1950/26050 (epoch 3.743), train_loss = 1.84436927, grad/param norm = 2.5349e-01, time/batch = 0.6398s	
1951/26050 (epoch 3.745), train_loss = 1.56862295, grad/param norm = 2.0312e-01, time/batch = 0.6396s	
1952/26050 (epoch 3.747), train_loss = 1.65863227, grad/param norm = 2.0801e-01, time/batch = 0.6409s	
1953/26050 (epoch 3.749), train_loss = 1.77221993, grad/param norm = 2.5427e-01, time/batch = 0.6420s	
1954/26050 (epoch 3.750), train_loss = 1.64297449, grad/param norm = 2.0308e-01, time/batch = 0.6391s	
1955/26050 (epoch 3.752), train_loss = 1.81999613, grad/param norm = 2.3227e-01, time/batch = 0.6395s	
1956/26050 (epoch 3.754), train_loss = 1.58927924, grad/param norm = 2.0352e-01, time/batch = 0.6385s	
1957/26050 (epoch 3.756), train_loss = 1.83443288, grad/param norm = 2.2437e-01, time/batch = 0.6373s	
1958/26050 (epoch 3.758), train_loss = 1.75699353, grad/param norm = 2.3904e-01, time/batch = 0.6375s	
1959/26050 (epoch 3.760), train_loss = 1.72360164, grad/param norm = 2.1313e-01, time/batch = 0.6388s	
1960/26050 (epoch 3.762), train_loss = 1.67647757, grad/param norm = 2.3159e-01, time/batch = 0.6386s	
1961/26050 (epoch 3.764), train_loss = 1.80554420, grad/param norm = 2.2641e-01, time/batch = 0.6532s	
1962/26050 (epoch 3.766), train_loss = 1.78777518, grad/param norm = 2.2219e-01, time/batch = 0.6794s	
1963/26050 (epoch 3.768), train_loss = 1.65810387, grad/param norm = 2.0484e-01, time/batch = 0.6438s	
1964/26050 (epoch 3.770), train_loss = 1.70936562, grad/param norm = 2.2309e-01, time/batch = 0.6410s	
1965/26050 (epoch 3.772), train_loss = 1.72628516, grad/param norm = 2.4511e-01, time/batch = 0.6381s	
1966/26050 (epoch 3.774), train_loss = 1.64042395, grad/param norm = 2.2355e-01, time/batch = 0.6392s	
1967/26050 (epoch 3.775), train_loss = 1.47181845, grad/param norm = 2.1035e-01, time/batch = 0.6381s	
1968/26050 (epoch 3.777), train_loss = 1.60112177, grad/param norm = 2.1505e-01, time/batch = 0.6388s	
1969/26050 (epoch 3.779), train_loss = 1.71843341, grad/param norm = 2.4551e-01, time/batch = 0.6401s	
1970/26050 (epoch 3.781), train_loss = 1.64594823, grad/param norm = 2.3191e-01, time/batch = 0.6393s	
1971/26050 (epoch 3.783), train_loss = 1.63132293, grad/param norm = 1.9072e-01, time/batch = 0.6394s	
1972/26050 (epoch 3.785), train_loss = 1.66871653, grad/param norm = 2.4599e-01, time/batch = 0.6479s	
1973/26050 (epoch 3.787), train_loss = 1.66040662, grad/param norm = 2.2696e-01, time/batch = 0.6462s	
1974/26050 (epoch 3.789), train_loss = 1.77141218, grad/param norm = 2.4003e-01, time/batch = 0.6381s	
1975/26050 (epoch 3.791), train_loss = 1.74354158, grad/param norm = 2.1289e-01, time/batch = 0.6386s	
1976/26050 (epoch 3.793), train_loss = 1.67951181, grad/param norm = 2.3720e-01, time/batch = 0.6429s	
1977/26050 (epoch 3.795), train_loss = 1.62771786, grad/param norm = 2.2949e-01, time/batch = 0.6755s	
1978/26050 (epoch 3.797), train_loss = 1.59925629, grad/param norm = 2.0540e-01, time/batch = 0.6641s	
1979/26050 (epoch 3.798), train_loss = 1.56677553, grad/param norm = 2.1193e-01, time/batch = 0.6380s	
1980/26050 (epoch 3.800), train_loss = 1.55552419, grad/param norm = 2.0533e-01, time/batch = 0.6389s	
1981/26050 (epoch 3.802), train_loss = 1.73267958, grad/param norm = 2.1813e-01, time/batch = 0.6415s	
1982/26050 (epoch 3.804), train_loss = 1.72661099, grad/param norm = 2.1790e-01, time/batch = 0.6393s	
1983/26050 (epoch 3.806), train_loss = 1.87390951, grad/param norm = 2.4112e-01, time/batch = 0.6411s	
1984/26050 (epoch 3.808), train_loss = 1.61558392, grad/param norm = 2.1627e-01, time/batch = 0.6405s	
1985/26050 (epoch 3.810), train_loss = 1.60637635, grad/param norm = 2.3377e-01, time/batch = 0.6457s	
1986/26050 (epoch 3.812), train_loss = 1.54698380, grad/param norm = 2.2061e-01, time/batch = 0.6413s	
1987/26050 (epoch 3.814), train_loss = 1.62581407, grad/param norm = 2.3647e-01, time/batch = 0.6398s	
1988/26050 (epoch 3.816), train_loss = 1.74738985, grad/param norm = 2.2262e-01, time/batch = 0.6379s	
1989/26050 (epoch 3.818), train_loss = 1.84764602, grad/param norm = 2.6018e-01, time/batch = 0.6386s	
1990/26050 (epoch 3.820), train_loss = 1.75041844, grad/param norm = 2.3173e-01, time/batch = 0.6373s	
1991/26050 (epoch 3.821), train_loss = 1.85649173, grad/param norm = 2.5266e-01, time/batch = 0.6391s	
1992/26050 (epoch 3.823), train_loss = 1.92941342, grad/param norm = 2.4428e-01, time/batch = 0.6585s	
1993/26050 (epoch 3.825), train_loss = 1.67107885, grad/param norm = 2.3238e-01, time/batch = 0.6811s	
1994/26050 (epoch 3.827), train_loss = 1.78368260, grad/param norm = 2.8432e-01, time/batch = 0.6445s	
1995/26050 (epoch 3.829), train_loss = 1.75106660, grad/param norm = 2.0900e-01, time/batch = 0.6384s	
1996/26050 (epoch 3.831), train_loss = 1.82327300, grad/param norm = 2.0714e-01, time/batch = 0.6395s	
1997/26050 (epoch 3.833), train_loss = 1.91150438, grad/param norm = 2.6337e-01, time/batch = 0.6382s	
1998/26050 (epoch 3.835), train_loss = 1.95237547, grad/param norm = 2.1077e-01, time/batch = 0.6403s	
1999/26050 (epoch 3.837), train_loss = 1.62917487, grad/param norm = 2.1643e-01, time/batch = 0.6372s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch3.84_1.8126.t7	
2000/26050 (epoch 3.839), train_loss = 1.84457445, grad/param norm = 2.0585e-01, time/batch = 0.6406s	
2001/26050 (epoch 3.841), train_loss = 1.87652673, grad/param norm = 2.2730e-01, time/batch = 0.6857s	
2002/26050 (epoch 3.843), train_loss = 1.77121074, grad/param norm = 2.1191e-01, time/batch = 0.6506s	
2003/26050 (epoch 3.845), train_loss = 1.62776236, grad/param norm = 2.1735e-01, time/batch = 0.6587s	
2004/26050 (epoch 3.846), train_loss = 1.83412644, grad/param norm = 2.3097e-01, time/batch = 0.6448s	
2005/26050 (epoch 3.848), train_loss = 1.64255940, grad/param norm = 1.9963e-01, time/batch = 0.6434s	
2006/26050 (epoch 3.850), train_loss = 1.65750117, grad/param norm = 2.0123e-01, time/batch = 0.6479s	
2007/26050 (epoch 3.852), train_loss = 1.68327703, grad/param norm = 2.2367e-01, time/batch = 0.6430s	
2008/26050 (epoch 3.854), train_loss = 1.72330863, grad/param norm = 2.1463e-01, time/batch = 0.6469s	
2009/26050 (epoch 3.856), train_loss = 1.60929199, grad/param norm = 2.0650e-01, time/batch = 0.6477s	
2010/26050 (epoch 3.858), train_loss = 1.53025540, grad/param norm = 2.3139e-01, time/batch = 0.6460s	
2011/26050 (epoch 3.860), train_loss = 1.73950752, grad/param norm = 2.5391e-01, time/batch = 0.6787s	
2012/26050 (epoch 3.862), train_loss = 1.70768370, grad/param norm = 2.4348e-01, time/batch = 0.6629s	
2013/26050 (epoch 3.864), train_loss = 1.61195551, grad/param norm = 2.2971e-01, time/batch = 0.6386s	
2014/26050 (epoch 3.866), train_loss = 1.58326289, grad/param norm = 2.1200e-01, time/batch = 0.6418s	
2015/26050 (epoch 3.868), train_loss = 1.85997725, grad/param norm = 2.3853e-01, time/batch = 0.6398s	
2016/26050 (epoch 3.869), train_loss = 1.52293895, grad/param norm = 2.1060e-01, time/batch = 0.6383s	
2017/26050 (epoch 3.871), train_loss = 1.46713050, grad/param norm = 2.0488e-01, time/batch = 0.6448s	
2018/26050 (epoch 3.873), train_loss = 1.64017328, grad/param norm = 2.1386e-01, time/batch = 0.6440s	
2019/26050 (epoch 3.875), train_loss = 1.68528167, grad/param norm = 2.3868e-01, time/batch = 0.6418s	
2020/26050 (epoch 3.877), train_loss = 1.49666778, grad/param norm = 2.1650e-01, time/batch = 0.6406s	
2021/26050 (epoch 3.879), train_loss = 1.63287242, grad/param norm = 2.0465e-01, time/batch = 0.6448s	
2022/26050 (epoch 3.881), train_loss = 1.90530918, grad/param norm = 2.1851e-01, time/batch = 0.6468s	
2023/26050 (epoch 3.883), train_loss = 1.74027230, grad/param norm = 2.0956e-01, time/batch = 0.6572s	
2024/26050 (epoch 3.885), train_loss = 1.44970140, grad/param norm = 1.9859e-01, time/batch = 0.6450s	
2025/26050 (epoch 3.887), train_loss = 1.70849494, grad/param norm = 2.1612e-01, time/batch = 0.6401s	
2026/26050 (epoch 3.889), train_loss = 1.59164222, grad/param norm = 1.9769e-01, time/batch = 0.6388s	
2027/26050 (epoch 3.891), train_loss = 1.43816473, grad/param norm = 2.1682e-01, time/batch = 0.6380s	
2028/26050 (epoch 3.893), train_loss = 1.42705381, grad/param norm = 1.8447e-01, time/batch = 0.6384s	
2029/26050 (epoch 3.894), train_loss = 1.54359529, grad/param norm = 1.8859e-01, time/batch = 0.6393s	
2030/26050 (epoch 3.896), train_loss = 1.76490372, grad/param norm = 2.0880e-01, time/batch = 0.6378s	
2031/26050 (epoch 3.898), train_loss = 1.63014517, grad/param norm = 2.1408e-01, time/batch = 0.6759s	
2032/26050 (epoch 3.900), train_loss = 1.94051277, grad/param norm = 2.5286e-01, time/batch = 0.6658s	
2033/26050 (epoch 3.902), train_loss = 1.71750106, grad/param norm = 2.0988e-01, time/batch = 0.6424s	
2034/26050 (epoch 3.904), train_loss = 1.67665071, grad/param norm = 2.2094e-01, time/batch = 0.6397s	
2035/26050 (epoch 3.906), train_loss = 1.68234289, grad/param norm = 2.1208e-01, time/batch = 0.6429s	
2036/26050 (epoch 3.908), train_loss = 1.67254215, grad/param norm = 2.2108e-01, time/batch = 0.6411s	
2037/26050 (epoch 3.910), train_loss = 1.59849489, grad/param norm = 2.0805e-01, time/batch = 0.6410s	
2038/26050 (epoch 3.912), train_loss = 1.97289407, grad/param norm = 2.4268e-01, time/batch = 0.6391s	
2039/26050 (epoch 3.914), train_loss = 2.07870128, grad/param norm = 2.2872e-01, time/batch = 0.6420s	
2040/26050 (epoch 3.916), train_loss = 1.86118321, grad/param norm = 2.3084e-01, time/batch = 0.6435s	
2041/26050 (epoch 3.917), train_loss = 1.67980300, grad/param norm = 2.1307e-01, time/batch = 0.6408s	
2042/26050 (epoch 3.919), train_loss = 1.77577158, grad/param norm = 2.1591e-01, time/batch = 0.6396s	
2043/26050 (epoch 3.921), train_loss = 1.53957194, grad/param norm = 2.1253e-01, time/batch = 0.6393s	
2044/26050 (epoch 3.923), train_loss = 1.62482001, grad/param norm = 2.4187e-01, time/batch = 0.6386s	
2045/26050 (epoch 3.925), train_loss = 1.56436353, grad/param norm = 2.1096e-01, time/batch = 0.6388s	
2046/26050 (epoch 3.927), train_loss = 1.56084851, grad/param norm = 1.8593e-01, time/batch = 0.6553s	
2047/26050 (epoch 3.929), train_loss = 1.59147930, grad/param norm = 2.2169e-01, time/batch = 0.6811s	
2048/26050 (epoch 3.931), train_loss = 2.00195536, grad/param norm = 2.7087e-01, time/batch = 0.6432s	
2049/26050 (epoch 3.933), train_loss = 1.68978636, grad/param norm = 2.3289e-01, time/batch = 0.6473s	
2050/26050 (epoch 3.935), train_loss = 1.52062807, grad/param norm = 2.0683e-01, time/batch = 0.6383s	
2051/26050 (epoch 3.937), train_loss = 1.63348188, grad/param norm = 2.2169e-01, time/batch = 0.6427s	
2052/26050 (epoch 3.939), train_loss = 1.56096239, grad/param norm = 2.2214e-01, time/batch = 0.6381s	
2053/26050 (epoch 3.940), train_loss = 1.74237845, grad/param norm = 2.1280e-01, time/batch = 0.6385s	
2054/26050 (epoch 3.942), train_loss = 1.73897083, grad/param norm = 2.3521e-01, time/batch = 0.6395s	
2055/26050 (epoch 3.944), train_loss = 1.62843303, grad/param norm = 2.3132e-01, time/batch = 0.6419s	
2056/26050 (epoch 3.946), train_loss = 1.84808102, grad/param norm = 2.2425e-01, time/batch = 0.6400s	
2057/26050 (epoch 3.948), train_loss = 1.45652667, grad/param norm = 2.5407e-01, time/batch = 0.6385s	
2058/26050 (epoch 3.950), train_loss = 1.61238502, grad/param norm = 2.2837e-01, time/batch = 0.6374s	
2059/26050 (epoch 3.952), train_loss = 1.86210415, grad/param norm = 2.3269e-01, time/batch = 0.6376s	
2060/26050 (epoch 3.954), train_loss = 1.81071384, grad/param norm = 2.0560e-01, time/batch = 0.6391s	
2061/26050 (epoch 3.956), train_loss = 1.82885732, grad/param norm = 2.2479e-01, time/batch = 0.6387s	
2062/26050 (epoch 3.958), train_loss = 1.70539225, grad/param norm = 2.0874e-01, time/batch = 0.6792s	
2063/26050 (epoch 3.960), train_loss = 1.61490220, grad/param norm = 2.0630e-01, time/batch = 0.6822s	
2064/26050 (epoch 3.962), train_loss = 1.61456666, grad/param norm = 2.0578e-01, time/batch = 0.6827s	
2065/26050 (epoch 3.964), train_loss = 1.68157676, grad/param norm = 2.2213e-01, time/batch = 0.6409s	
2066/26050 (epoch 3.965), train_loss = 1.52210644, grad/param norm = 1.9540e-01, time/batch = 0.6451s	
2067/26050 (epoch 3.967), train_loss = 2.04571973, grad/param norm = 2.3989e-01, time/batch = 0.6393s	
2068/26050 (epoch 3.969), train_loss = 1.63773892, grad/param norm = 2.3560e-01, time/batch = 0.6407s	
2069/26050 (epoch 3.971), train_loss = 1.47938282, grad/param norm = 2.0020e-01, time/batch = 0.6469s	
2070/26050 (epoch 3.973), train_loss = 1.62289312, grad/param norm = 2.4137e-01, time/batch = 0.6455s	
2071/26050 (epoch 3.975), train_loss = 1.76616254, grad/param norm = 2.1097e-01, time/batch = 0.6428s	
2072/26050 (epoch 3.977), train_loss = 1.70885411, grad/param norm = 2.0053e-01, time/batch = 0.6452s	
2073/26050 (epoch 3.979), train_loss = 1.50248075, grad/param norm = 2.0674e-01, time/batch = 0.6465s	
2074/26050 (epoch 3.981), train_loss = 1.72880949, grad/param norm = 1.9769e-01, time/batch = 0.6430s	
2075/26050 (epoch 3.983), train_loss = 1.74753778, grad/param norm = 2.2735e-01, time/batch = 0.6423s	
2076/26050 (epoch 3.985), train_loss = 1.74796293, grad/param norm = 2.3004e-01, time/batch = 0.6434s	
2077/26050 (epoch 3.987), train_loss = 1.85601667, grad/param norm = 2.2613e-01, time/batch = 0.6392s	
2078/26050 (epoch 3.988), train_loss = 1.85408024, grad/param norm = 2.3906e-01, time/batch = 0.6391s	
2079/26050 (epoch 3.990), train_loss = 1.65794319, grad/param norm = 2.5027e-01, time/batch = 0.6426s	
2080/26050 (epoch 3.992), train_loss = 1.91739439, grad/param norm = 2.5136e-01, time/batch = 0.6394s	
2081/26050 (epoch 3.994), train_loss = 1.65799495, grad/param norm = 2.2421e-01, time/batch = 0.6411s	
2082/26050 (epoch 3.996), train_loss = 1.78673653, grad/param norm = 2.8186e-01, time/batch = 0.6821s	
2083/26050 (epoch 3.998), train_loss = 1.75785988, grad/param norm = 2.1105e-01, time/batch = 0.6605s	
2084/26050 (epoch 4.000), train_loss = 1.63497556, grad/param norm = 2.0239e-01, time/batch = 0.6390s	
2085/26050 (epoch 4.002), train_loss = 1.69543461, grad/param norm = 2.0132e-01, time/batch = 0.6407s	
2086/26050 (epoch 4.004), train_loss = 1.65328839, grad/param norm = 2.2250e-01, time/batch = 0.6405s	
2087/26050 (epoch 4.006), train_loss = 1.55693340, grad/param norm = 2.0580e-01, time/batch = 0.6405s	
2088/26050 (epoch 4.008), train_loss = 1.59627721, grad/param norm = 2.0409e-01, time/batch = 0.6397s	
2089/26050 (epoch 4.010), train_loss = 1.65058504, grad/param norm = 1.8897e-01, time/batch = 0.6401s	
2090/26050 (epoch 4.012), train_loss = 1.75053271, grad/param norm = 2.3434e-01, time/batch = 0.6433s	
2091/26050 (epoch 4.013), train_loss = 2.16007068, grad/param norm = 2.2644e-01, time/batch = 0.6420s	
2092/26050 (epoch 4.015), train_loss = 1.55938490, grad/param norm = 2.1957e-01, time/batch = 0.6405s	
2093/26050 (epoch 4.017), train_loss = 1.66211812, grad/param norm = 2.1226e-01, time/batch = 0.6409s	
2094/26050 (epoch 4.019), train_loss = 1.54138389, grad/param norm = 1.9947e-01, time/batch = 0.6598s	
2095/26050 (epoch 4.021), train_loss = 1.84757533, grad/param norm = 2.4324e-01, time/batch = 0.6492s	
2096/26050 (epoch 4.023), train_loss = 1.57718037, grad/param norm = 2.1561e-01, time/batch = 0.6596s	
2097/26050 (epoch 4.025), train_loss = 1.61345472, grad/param norm = 2.3428e-01, time/batch = 0.6693s	
2098/26050 (epoch 4.027), train_loss = 1.44655886, grad/param norm = 1.9926e-01, time/batch = 0.6651s	
2099/26050 (epoch 4.029), train_loss = 1.59361981, grad/param norm = 2.0004e-01, time/batch = 0.6409s	
2100/26050 (epoch 4.031), train_loss = 1.87011594, grad/param norm = 2.4172e-01, time/batch = 0.6411s	
2101/26050 (epoch 4.033), train_loss = 1.71825580, grad/param norm = 2.4623e-01, time/batch = 0.6419s	
2102/26050 (epoch 4.035), train_loss = 1.87252104, grad/param norm = 2.2205e-01, time/batch = 0.6419s	
2103/26050 (epoch 4.036), train_loss = 1.66327866, grad/param norm = 2.3023e-01, time/batch = 0.6416s	
2104/26050 (epoch 4.038), train_loss = 1.47706237, grad/param norm = 2.3015e-01, time/batch = 0.6402s	
2105/26050 (epoch 4.040), train_loss = 1.74448561, grad/param norm = 2.3257e-01, time/batch = 0.6398s	
2106/26050 (epoch 4.042), train_loss = 1.50821540, grad/param norm = 2.0015e-01, time/batch = 0.6412s	
2107/26050 (epoch 4.044), train_loss = 1.72921007, grad/param norm = 2.0155e-01, time/batch = 0.6396s	
2108/26050 (epoch 4.046), train_loss = 1.47172062, grad/param norm = 2.0902e-01, time/batch = 0.6399s	
2109/26050 (epoch 4.048), train_loss = 1.66911049, grad/param norm = 2.0550e-01, time/batch = 0.6397s	
2110/26050 (epoch 4.050), train_loss = 1.54065737, grad/param norm = 2.2387e-01, time/batch = 0.6484s	
2111/26050 (epoch 4.052), train_loss = 1.65632523, grad/param norm = 2.2126e-01, time/batch = 0.6440s	
2112/26050 (epoch 4.054), train_loss = 1.55313896, grad/param norm = 2.5475e-01, time/batch = 0.6481s	
2113/26050 (epoch 4.056), train_loss = 1.32056379, grad/param norm = 2.0030e-01, time/batch = 0.6825s	
2114/26050 (epoch 4.058), train_loss = 1.55229415, grad/param norm = 2.0266e-01, time/batch = 0.6539s	
2115/26050 (epoch 4.060), train_loss = 1.62207578, grad/param norm = 1.8861e-01, time/batch = 0.6396s	
2116/26050 (epoch 4.061), train_loss = 1.51937027, grad/param norm = 2.0539e-01, time/batch = 0.6399s	
2117/26050 (epoch 4.063), train_loss = 1.52851470, grad/param norm = 1.9102e-01, time/batch = 0.6423s	
2118/26050 (epoch 4.065), train_loss = 1.52123641, grad/param norm = 2.0728e-01, time/batch = 0.6420s	
2119/26050 (epoch 4.067), train_loss = 1.74674317, grad/param norm = 2.5153e-01, time/batch = 0.6410s	
2120/26050 (epoch 4.069), train_loss = 1.73810107, grad/param norm = 2.2235e-01, time/batch = 0.6419s	
2121/26050 (epoch 4.071), train_loss = 1.72074437, grad/param norm = 2.3163e-01, time/batch = 0.6415s	
2122/26050 (epoch 4.073), train_loss = 1.87449647, grad/param norm = 2.1599e-01, time/batch = 0.6475s	
2123/26050 (epoch 4.075), train_loss = 1.52340399, grad/param norm = 2.0384e-01, time/batch = 0.6429s	
2124/26050 (epoch 4.077), train_loss = 1.54640628, grad/param norm = 2.2649e-01, time/batch = 0.6398s	
2125/26050 (epoch 4.079), train_loss = 1.79659534, grad/param norm = 2.1610e-01, time/batch = 0.6391s	
2126/26050 (epoch 4.081), train_loss = 1.56748768, grad/param norm = 1.9597e-01, time/batch = 0.6420s	
2127/26050 (epoch 4.083), train_loss = 1.75096802, grad/param norm = 2.3117e-01, time/batch = 0.6390s	
2128/26050 (epoch 4.084), train_loss = 1.91984935, grad/param norm = 2.5236e-01, time/batch = 0.6391s	
2129/26050 (epoch 4.086), train_loss = 1.83511477, grad/param norm = 2.4315e-01, time/batch = 0.6443s	
2130/26050 (epoch 4.088), train_loss = 1.50274512, grad/param norm = 1.8735e-01, time/batch = 0.6570s	
2131/26050 (epoch 4.090), train_loss = 1.88726439, grad/param norm = 2.2475e-01, time/batch = 0.6473s	
2132/26050 (epoch 4.092), train_loss = 1.55947194, grad/param norm = 2.2028e-01, time/batch = 0.6451s	
2133/26050 (epoch 4.094), train_loss = 1.73182292, grad/param norm = 2.1184e-01, time/batch = 0.6603s	
2134/26050 (epoch 4.096), train_loss = 1.46192712, grad/param norm = 2.0160e-01, time/batch = 0.6556s	
2135/26050 (epoch 4.098), train_loss = 1.55846664, grad/param norm = 1.9780e-01, time/batch = 0.6390s	
2136/26050 (epoch 4.100), train_loss = 1.57691796, grad/param norm = 2.4181e-01, time/batch = 0.6383s	
2137/26050 (epoch 4.102), train_loss = 1.70769496, grad/param norm = 2.0997e-01, time/batch = 0.6383s	
2138/26050 (epoch 4.104), train_loss = 1.75072063, grad/param norm = 2.2622e-01, time/batch = 0.6389s	
2139/26050 (epoch 4.106), train_loss = 1.56945774, grad/param norm = 2.0731e-01, time/batch = 0.6545s	
2140/26050 (epoch 4.107), train_loss = 1.35539462, grad/param norm = 2.0891e-01, time/batch = 0.6639s	
2141/26050 (epoch 4.109), train_loss = 1.53563621, grad/param norm = 2.0575e-01, time/batch = 0.6593s	
2142/26050 (epoch 4.111), train_loss = 1.94730348, grad/param norm = 2.4683e-01, time/batch = 0.6582s	
2143/26050 (epoch 4.113), train_loss = 1.56946551, grad/param norm = 2.3002e-01, time/batch = 0.6564s	
2144/26050 (epoch 4.115), train_loss = 1.80731505, grad/param norm = 2.1173e-01, time/batch = 0.6572s	
2145/26050 (epoch 4.117), train_loss = 1.71388048, grad/param norm = 2.2796e-01, time/batch = 0.6522s	
2146/26050 (epoch 4.119), train_loss = 1.48248137, grad/param norm = 2.0615e-01, time/batch = 0.6605s	
2147/26050 (epoch 4.121), train_loss = 1.68064159, grad/param norm = 2.2481e-01, time/batch = 0.6523s	
2148/26050 (epoch 4.123), train_loss = 1.57645723, grad/param norm = 2.2260e-01, time/batch = 0.6584s	
2149/26050 (epoch 4.125), train_loss = 1.36284025, grad/param norm = 1.8090e-01, time/batch = 0.6564s	
2150/26050 (epoch 4.127), train_loss = 1.45883714, grad/param norm = 2.0599e-01, time/batch = 0.6579s	
2151/26050 (epoch 4.129), train_loss = 1.42994978, grad/param norm = 1.9476e-01, time/batch = 0.6447s	
2152/26050 (epoch 4.131), train_loss = 1.62698938, grad/param norm = 2.1026e-01, time/batch = 0.6405s	
2153/26050 (epoch 4.132), train_loss = 1.54822029, grad/param norm = 1.9186e-01, time/batch = 0.6388s	
2154/26050 (epoch 4.134), train_loss = 1.60500097, grad/param norm = 2.2255e-01, time/batch = 0.6410s	
2155/26050 (epoch 4.136), train_loss = 1.58371198, grad/param norm = 1.9275e-01, time/batch = 0.6382s	
2156/26050 (epoch 4.138), train_loss = 1.55618482, grad/param norm = 2.2510e-01, time/batch = 0.6451s	
2157/26050 (epoch 4.140), train_loss = 1.62413841, grad/param norm = 2.1204e-01, time/batch = 0.6383s	
2158/26050 (epoch 4.142), train_loss = 1.63692684, grad/param norm = 2.1657e-01, time/batch = 0.6380s	
2159/26050 (epoch 4.144), train_loss = 1.49782548, grad/param norm = 2.1759e-01, time/batch = 0.6386s	
2160/26050 (epoch 4.146), train_loss = 1.37940908, grad/param norm = 2.0098e-01, time/batch = 0.6385s	
2161/26050 (epoch 4.148), train_loss = 1.42644120, grad/param norm = 1.8229e-01, time/batch = 0.6389s	
2162/26050 (epoch 4.150), train_loss = 1.65385327, grad/param norm = 2.1869e-01, time/batch = 0.6437s	
2163/26050 (epoch 4.152), train_loss = 1.93576854, grad/param norm = 2.3901e-01, time/batch = 0.6399s	
2164/26050 (epoch 4.154), train_loss = 1.47987419, grad/param norm = 2.1532e-01, time/batch = 0.6384s	
2165/26050 (epoch 4.155), train_loss = 1.49671017, grad/param norm = 1.9700e-01, time/batch = 0.6383s	
2166/26050 (epoch 4.157), train_loss = 1.65265218, grad/param norm = 2.2239e-01, time/batch = 0.6381s	
2167/26050 (epoch 4.159), train_loss = 1.68238698, grad/param norm = 2.2946e-01, time/batch = 0.6391s	
2168/26050 (epoch 4.161), train_loss = 1.86711473, grad/param norm = 2.3167e-01, time/batch = 0.6384s	
2169/26050 (epoch 4.163), train_loss = 1.52999439, grad/param norm = 1.9604e-01, time/batch = 0.6420s	
2170/26050 (epoch 4.165), train_loss = 1.29133431, grad/param norm = 1.8277e-01, time/batch = 0.6525s	
2171/26050 (epoch 4.167), train_loss = 1.80460771, grad/param norm = 2.6851e-01, time/batch = 0.6435s	
2172/26050 (epoch 4.169), train_loss = 1.70902372, grad/param norm = 2.3323e-01, time/batch = 0.6463s	
2173/26050 (epoch 4.171), train_loss = 1.42456960, grad/param norm = 1.8281e-01, time/batch = 0.6374s	
2174/26050 (epoch 4.173), train_loss = 1.60048460, grad/param norm = 2.2591e-01, time/batch = 0.6621s	
2175/26050 (epoch 4.175), train_loss = 1.64618395, grad/param norm = 2.3294e-01, time/batch = 0.6774s	
2176/26050 (epoch 4.177), train_loss = 1.71326662, grad/param norm = 2.1368e-01, time/batch = 0.6425s	
2177/26050 (epoch 4.179), train_loss = 1.30915255, grad/param norm = 1.8874e-01, time/batch = 0.6422s	
2178/26050 (epoch 4.180), train_loss = 1.84854017, grad/param norm = 2.0739e-01, time/batch = 0.6407s	
2179/26050 (epoch 4.182), train_loss = 1.96281066, grad/param norm = 2.2127e-01, time/batch = 0.6389s	
2180/26050 (epoch 4.184), train_loss = 1.68707023, grad/param norm = 2.1496e-01, time/batch = 0.6389s	
2181/26050 (epoch 4.186), train_loss = 1.37171608, grad/param norm = 1.9530e-01, time/batch = 0.6396s	
2182/26050 (epoch 4.188), train_loss = 1.60103579, grad/param norm = 2.0092e-01, time/batch = 0.6394s	
2183/26050 (epoch 4.190), train_loss = 1.70771525, grad/param norm = 2.0937e-01, time/batch = 0.6379s	
2184/26050 (epoch 4.192), train_loss = 1.62887125, grad/param norm = 2.1640e-01, time/batch = 0.6370s	
2185/26050 (epoch 4.194), train_loss = 1.63735948, grad/param norm = 2.1244e-01, time/batch = 0.6377s	
2186/26050 (epoch 4.196), train_loss = 1.75500903, grad/param norm = 2.3601e-01, time/batch = 0.6517s	
2187/26050 (epoch 4.198), train_loss = 1.53147109, grad/param norm = 2.0600e-01, time/batch = 0.6561s	
2188/26050 (epoch 4.200), train_loss = 1.55409960, grad/param norm = 2.2284e-01, time/batch = 0.6389s	
2189/26050 (epoch 4.202), train_loss = 1.52561644, grad/param norm = 2.1366e-01, time/batch = 0.6570s	
2190/26050 (epoch 4.203), train_loss = 1.69955551, grad/param norm = 2.2396e-01, time/batch = 0.6824s	
2191/26050 (epoch 4.205), train_loss = 1.49240627, grad/param norm = 2.0835e-01, time/batch = 0.6567s	
2192/26050 (epoch 4.207), train_loss = 1.56868455, grad/param norm = 1.8520e-01, time/batch = 0.6450s	
2193/26050 (epoch 4.209), train_loss = 1.56749342, grad/param norm = 2.0195e-01, time/batch = 0.6406s	
2194/26050 (epoch 4.211), train_loss = 1.49409634, grad/param norm = 2.2885e-01, time/batch = 0.6586s	
2195/26050 (epoch 4.213), train_loss = 1.67083102, grad/param norm = 2.2127e-01, time/batch = 0.6693s	
2196/26050 (epoch 4.215), train_loss = 1.69493323, grad/param norm = 2.3050e-01, time/batch = 0.6558s	
2197/26050 (epoch 4.217), train_loss = 1.58040440, grad/param norm = 2.2597e-01, time/batch = 0.6419s	
2198/26050 (epoch 4.219), train_loss = 1.53268502, grad/param norm = 2.1707e-01, time/batch = 0.6413s	
2199/26050 (epoch 4.221), train_loss = 1.50871727, grad/param norm = 2.1169e-01, time/batch = 0.6421s	
2200/26050 (epoch 4.223), train_loss = 1.75872172, grad/param norm = 2.3586e-01, time/batch = 0.6400s	
2201/26050 (epoch 4.225), train_loss = 1.52091881, grad/param norm = 2.2329e-01, time/batch = 0.6403s	
2202/26050 (epoch 4.226), train_loss = 1.79699994, grad/param norm = 2.5841e-01, time/batch = 0.6423s	
2203/26050 (epoch 4.228), train_loss = 1.74877817, grad/param norm = 2.4349e-01, time/batch = 0.6449s	
2204/26050 (epoch 4.230), train_loss = 1.60959288, grad/param norm = 2.0596e-01, time/batch = 0.6417s	
2205/26050 (epoch 4.232), train_loss = 1.79559947, grad/param norm = 2.3330e-01, time/batch = 0.6747s	
2206/26050 (epoch 4.234), train_loss = 1.40131523, grad/param norm = 1.9630e-01, time/batch = 0.6692s	
2207/26050 (epoch 4.236), train_loss = 1.64156842, grad/param norm = 2.1889e-01, time/batch = 0.6381s	
2208/26050 (epoch 4.238), train_loss = 1.38402454, grad/param norm = 1.9949e-01, time/batch = 0.6398s	
2209/26050 (epoch 4.240), train_loss = 1.53233919, grad/param norm = 1.9168e-01, time/batch = 0.6400s	
2210/26050 (epoch 4.242), train_loss = 1.61737020, grad/param norm = 2.1906e-01, time/batch = 0.6391s	
2211/26050 (epoch 4.244), train_loss = 1.65595757, grad/param norm = 2.3071e-01, time/batch = 0.6410s	
2212/26050 (epoch 4.246), train_loss = 1.51743011, grad/param norm = 2.0657e-01, time/batch = 0.6476s	
2213/26050 (epoch 4.248), train_loss = 1.72405185, grad/param norm = 2.3435e-01, time/batch = 0.6522s	
2214/26050 (epoch 4.250), train_loss = 1.70594401, grad/param norm = 2.2492e-01, time/batch = 0.6526s	
2215/26050 (epoch 4.251), train_loss = 1.49763933, grad/param norm = 2.2414e-01, time/batch = 0.6513s	
2216/26050 (epoch 4.253), train_loss = 1.42404319, grad/param norm = 2.1074e-01, time/batch = 0.6389s	
2217/26050 (epoch 4.255), train_loss = 1.85482386, grad/param norm = 2.2201e-01, time/batch = 0.6472s	
2218/26050 (epoch 4.257), train_loss = 1.62999435, grad/param norm = 2.0493e-01, time/batch = 0.6404s	
2219/26050 (epoch 4.259), train_loss = 1.72541081, grad/param norm = 2.2508e-01, time/batch = 0.6384s	
2220/26050 (epoch 4.261), train_loss = 1.55302045, grad/param norm = 2.1135e-01, time/batch = 0.6558s	
2221/26050 (epoch 4.263), train_loss = 1.61930887, grad/param norm = 2.1413e-01, time/batch = 0.6687s	
2222/26050 (epoch 4.265), train_loss = 1.82110397, grad/param norm = 2.0139e-01, time/batch = 0.6395s	
2223/26050 (epoch 4.267), train_loss = 1.67307136, grad/param norm = 2.2568e-01, time/batch = 0.6460s	
2224/26050 (epoch 4.269), train_loss = 1.83277341, grad/param norm = 2.4088e-01, time/batch = 0.6413s	
2225/26050 (epoch 4.271), train_loss = 1.59860566, grad/param norm = 2.0237e-01, time/batch = 0.6380s	
2226/26050 (epoch 4.273), train_loss = 1.62050715, grad/param norm = 2.2708e-01, time/batch = 0.6401s	
2227/26050 (epoch 4.274), train_loss = 1.55220645, grad/param norm = 2.0097e-01, time/batch = 0.6384s	
2228/26050 (epoch 4.276), train_loss = 1.49087624, grad/param norm = 1.9512e-01, time/batch = 0.6384s	
2229/26050 (epoch 4.278), train_loss = 1.69602459, grad/param norm = 2.0533e-01, time/batch = 0.6474s	
2230/26050 (epoch 4.280), train_loss = 1.59987583, grad/param norm = 2.0131e-01, time/batch = 0.6437s	
2231/26050 (epoch 4.282), train_loss = 1.63802694, grad/param norm = 2.0851e-01, time/batch = 0.6420s	
2232/26050 (epoch 4.284), train_loss = 1.44860972, grad/param norm = 2.1089e-01, time/batch = 0.6410s	
2233/26050 (epoch 4.286), train_loss = 1.56710108, grad/param norm = 2.3307e-01, time/batch = 0.6488s	
2234/26050 (epoch 4.288), train_loss = 1.45633217, grad/param norm = 2.0412e-01, time/batch = 0.6403s	
2235/26050 (epoch 4.290), train_loss = 1.52529519, grad/param norm = 2.0868e-01, time/batch = 0.6410s	
2236/26050 (epoch 4.292), train_loss = 1.50942673, grad/param norm = 1.9384e-01, time/batch = 0.6415s	
2237/26050 (epoch 4.294), train_loss = 1.64096566, grad/param norm = 2.3291e-01, time/batch = 0.6392s	
2238/26050 (epoch 4.296), train_loss = 1.70070697, grad/param norm = 2.1098e-01, time/batch = 0.6389s	
2239/26050 (epoch 4.298), train_loss = 1.57400854, grad/param norm = 2.0443e-01, time/batch = 0.6471s	
2240/26050 (epoch 4.299), train_loss = 1.32403041, grad/param norm = 1.8084e-01, time/batch = 0.6408s	
2241/26050 (epoch 4.301), train_loss = 1.49419083, grad/param norm = 2.0740e-01, time/batch = 0.6406s	
2242/26050 (epoch 4.303), train_loss = 1.63848714, grad/param norm = 2.3660e-01, time/batch = 0.6407s	
2243/26050 (epoch 4.305), train_loss = 1.51387687, grad/param norm = 2.0953e-01, time/batch = 0.6398s	
2244/26050 (epoch 4.307), train_loss = 1.42234848, grad/param norm = 2.0533e-01, time/batch = 0.6387s	
2245/26050 (epoch 4.309), train_loss = 1.50863349, grad/param norm = 2.1410e-01, time/batch = 0.6402s	
2246/26050 (epoch 4.311), train_loss = 1.83395470, grad/param norm = 2.3804e-01, time/batch = 0.6417s	
2247/26050 (epoch 4.313), train_loss = 1.66676271, grad/param norm = 2.3104e-01, time/batch = 0.6446s	
2248/26050 (epoch 4.315), train_loss = 1.79833546, grad/param norm = 2.4134e-01, time/batch = 0.6425s	
2249/26050 (epoch 4.317), train_loss = 1.47977824, grad/param norm = 2.0134e-01, time/batch = 0.6564s	
2250/26050 (epoch 4.319), train_loss = 1.52995308, grad/param norm = 1.9563e-01, time/batch = 0.6407s	
2251/26050 (epoch 4.321), train_loss = 1.62223674, grad/param norm = 2.1434e-01, time/batch = 0.6681s	
2252/26050 (epoch 4.322), train_loss = 1.60917173, grad/param norm = 2.1063e-01, time/batch = 0.6806s	
2253/26050 (epoch 4.324), train_loss = 1.43037910, grad/param norm = 2.0823e-01, time/batch = 0.6382s	
2254/26050 (epoch 4.326), train_loss = 1.74750040, grad/param norm = 2.2886e-01, time/batch = 0.6399s	
2255/26050 (epoch 4.328), train_loss = 1.63149313, grad/param norm = 2.0420e-01, time/batch = 0.6396s	
2256/26050 (epoch 4.330), train_loss = 1.51094986, grad/param norm = 2.2388e-01, time/batch = 0.6390s	
2257/26050 (epoch 4.332), train_loss = 1.69663861, grad/param norm = 2.0981e-01, time/batch = 0.6398s	
2258/26050 (epoch 4.334), train_loss = 1.57031974, grad/param norm = 2.2135e-01, time/batch = 0.6380s	
2259/26050 (epoch 4.336), train_loss = 1.41652492, grad/param norm = 1.7576e-01, time/batch = 0.6387s	
2260/26050 (epoch 4.338), train_loss = 1.40210086, grad/param norm = 1.9466e-01, time/batch = 0.6380s	
2261/26050 (epoch 4.340), train_loss = 1.70544874, grad/param norm = 2.2840e-01, time/batch = 0.6417s	
2262/26050 (epoch 4.342), train_loss = 1.71732011, grad/param norm = 2.2209e-01, time/batch = 0.6548s	
2263/26050 (epoch 4.344), train_loss = 1.57578674, grad/param norm = 2.1537e-01, time/batch = 0.6629s	
2264/26050 (epoch 4.345), train_loss = 1.59728284, grad/param norm = 2.3556e-01, time/batch = 0.6459s	
2265/26050 (epoch 4.347), train_loss = 1.67570277, grad/param norm = 2.5058e-01, time/batch = 0.6556s	
2266/26050 (epoch 4.349), train_loss = 1.58977936, grad/param norm = 2.1006e-01, time/batch = 0.6547s	
2267/26050 (epoch 4.351), train_loss = 1.62167496, grad/param norm = 2.1766e-01, time/batch = 0.6505s	
2268/26050 (epoch 4.353), train_loss = 1.50979735, grad/param norm = 2.2328e-01, time/batch = 0.6482s	
2269/26050 (epoch 4.355), train_loss = 1.67490204, grad/param norm = 2.2512e-01, time/batch = 0.6516s	
2270/26050 (epoch 4.357), train_loss = 1.41674635, grad/param norm = 1.9278e-01, time/batch = 0.6492s	
2271/26050 (epoch 4.359), train_loss = 1.63842725, grad/param norm = 1.9227e-01, time/batch = 0.6571s	
2272/26050 (epoch 4.361), train_loss = 1.41087874, grad/param norm = 1.9015e-01, time/batch = 0.6496s	
2273/26050 (epoch 4.363), train_loss = 1.55996106, grad/param norm = 1.9717e-01, time/batch = 0.6509s	
2274/26050 (epoch 4.365), train_loss = 1.45275096, grad/param norm = 1.9811e-01, time/batch = 0.6508s	
2275/26050 (epoch 4.367), train_loss = 1.57323150, grad/param norm = 2.1808e-01, time/batch = 0.6577s	
2276/26050 (epoch 4.369), train_loss = 1.56224159, grad/param norm = 1.9852e-01, time/batch = 0.6476s	
2277/26050 (epoch 4.370), train_loss = 1.47772748, grad/param norm = 2.0884e-01, time/batch = 0.6564s	
2278/26050 (epoch 4.372), train_loss = 1.76165159, grad/param norm = 2.2203e-01, time/batch = 0.6557s	
2279/26050 (epoch 4.374), train_loss = 1.79821369, grad/param norm = 2.3185e-01, time/batch = 0.6681s	
2280/26050 (epoch 4.376), train_loss = 1.82620607, grad/param norm = 1.9661e-01, time/batch = 0.6753s	
2281/26050 (epoch 4.378), train_loss = 1.57892315, grad/param norm = 2.0393e-01, time/batch = 0.6745s	
2282/26050 (epoch 4.380), train_loss = 1.76866719, grad/param norm = 2.1509e-01, time/batch = 0.6887s	
2283/26050 (epoch 4.382), train_loss = 1.98367187, grad/param norm = 2.2912e-01, time/batch = 0.6680s	
2284/26050 (epoch 4.384), train_loss = 1.55180343, grad/param norm = 2.1039e-01, time/batch = 0.6412s	
2285/26050 (epoch 4.386), train_loss = 1.68130076, grad/param norm = 2.0831e-01, time/batch = 0.6492s	
2286/26050 (epoch 4.388), train_loss = 1.63271372, grad/param norm = 2.0180e-01, time/batch = 0.6418s	
2287/26050 (epoch 4.390), train_loss = 1.46933656, grad/param norm = 1.8449e-01, time/batch = 0.6438s	
2288/26050 (epoch 4.392), train_loss = 1.49720031, grad/param norm = 2.0346e-01, time/batch = 0.6442s	
2289/26050 (epoch 4.393), train_loss = 1.65432671, grad/param norm = 2.1290e-01, time/batch = 0.6389s	
2290/26050 (epoch 4.395), train_loss = 1.64852389, grad/param norm = 2.1917e-01, time/batch = 0.6373s	
2291/26050 (epoch 4.397), train_loss = 1.65128907, grad/param norm = 2.0535e-01, time/batch = 0.6414s	
2292/26050 (epoch 4.399), train_loss = 1.45584449, grad/param norm = 1.8842e-01, time/batch = 0.6400s	
2293/26050 (epoch 4.401), train_loss = 1.53590278, grad/param norm = 2.1540e-01, time/batch = 0.6396s	
2294/26050 (epoch 4.403), train_loss = 1.57960567, grad/param norm = 2.2300e-01, time/batch = 0.6539s	
2295/26050 (epoch 4.405), train_loss = 1.61401040, grad/param norm = 2.2337e-01, time/batch = 0.6489s	
2296/26050 (epoch 4.407), train_loss = 1.75065979, grad/param norm = 2.1110e-01, time/batch = 0.6368s	
2297/26050 (epoch 4.409), train_loss = 1.76947108, grad/param norm = 2.2617e-01, time/batch = 0.6614s	
2298/26050 (epoch 4.411), train_loss = 1.60321627, grad/param norm = 2.0303e-01, time/batch = 0.6780s	
2299/26050 (epoch 4.413), train_loss = 1.73951974, grad/param norm = 2.0322e-01, time/batch = 0.6486s	
2300/26050 (epoch 4.415), train_loss = 1.75124924, grad/param norm = 2.2254e-01, time/batch = 0.6412s	
2301/26050 (epoch 4.417), train_loss = 1.77675954, grad/param norm = 2.2033e-01, time/batch = 0.6421s	
2302/26050 (epoch 4.418), train_loss = 1.68550023, grad/param norm = 2.0964e-01, time/batch = 0.6403s	
2303/26050 (epoch 4.420), train_loss = 1.35186207, grad/param norm = 1.8846e-01, time/batch = 0.6424s	
2304/26050 (epoch 4.422), train_loss = 1.46262952, grad/param norm = 2.2028e-01, time/batch = 0.6387s	
2305/26050 (epoch 4.424), train_loss = 1.90056002, grad/param norm = 2.5412e-01, time/batch = 0.6448s	
2306/26050 (epoch 4.426), train_loss = 1.82861437, grad/param norm = 2.6546e-01, time/batch = 0.6496s	
2307/26050 (epoch 4.428), train_loss = 1.49158057, grad/param norm = 1.9015e-01, time/batch = 0.6395s	
2308/26050 (epoch 4.430), train_loss = 1.61642383, grad/param norm = 2.1535e-01, time/batch = 0.6459s	
2309/26050 (epoch 4.432), train_loss = 1.59030433, grad/param norm = 2.1843e-01, time/batch = 0.6428s	
2310/26050 (epoch 4.434), train_loss = 1.66142716, grad/param norm = 1.9386e-01, time/batch = 0.6508s	
2311/26050 (epoch 4.436), train_loss = 1.78011215, grad/param norm = 2.0395e-01, time/batch = 0.6400s	
2312/26050 (epoch 4.438), train_loss = 1.50507815, grad/param norm = 2.0640e-01, time/batch = 0.6401s	
2313/26050 (epoch 4.440), train_loss = 1.62795340, grad/param norm = 2.0967e-01, time/batch = 0.6394s	
2314/26050 (epoch 4.441), train_loss = 1.57481278, grad/param norm = 2.2240e-01, time/batch = 0.6390s	
2315/26050 (epoch 4.443), train_loss = 1.40383346, grad/param norm = 1.7278e-01, time/batch = 0.6383s	
2316/26050 (epoch 4.445), train_loss = 1.47039806, grad/param norm = 2.0318e-01, time/batch = 0.6399s	
2317/26050 (epoch 4.447), train_loss = 1.83693268, grad/param norm = 2.0934e-01, time/batch = 0.6613s	
2318/26050 (epoch 4.449), train_loss = 1.48772145, grad/param norm = 2.0987e-01, time/batch = 0.6786s	
2319/26050 (epoch 4.451), train_loss = 1.61506412, grad/param norm = 1.9627e-01, time/batch = 0.6412s	
2320/26050 (epoch 4.453), train_loss = 1.42565471, grad/param norm = 1.8065e-01, time/batch = 0.6590s	
2321/26050 (epoch 4.455), train_loss = 1.59182339, grad/param norm = 2.0780e-01, time/batch = 0.6749s	
2322/26050 (epoch 4.457), train_loss = 1.66624791, grad/param norm = 2.2974e-01, time/batch = 0.6769s	
2323/26050 (epoch 4.459), train_loss = 1.74934230, grad/param norm = 2.4197e-01, time/batch = 0.6736s	
2324/26050 (epoch 4.461), train_loss = 1.67209656, grad/param norm = 2.1729e-01, time/batch = 0.6637s	
2325/26050 (epoch 4.463), train_loss = 1.51121818, grad/param norm = 1.9175e-01, time/batch = 0.6512s	
2326/26050 (epoch 4.464), train_loss = 1.69814660, grad/param norm = 2.1898e-01, time/batch = 0.6417s	
2327/26050 (epoch 4.466), train_loss = 1.71439781, grad/param norm = 1.9543e-01, time/batch = 0.6395s	
2328/26050 (epoch 4.468), train_loss = 1.70845364, grad/param norm = 2.0152e-01, time/batch = 0.6831s	
2329/26050 (epoch 4.470), train_loss = 1.83953932, grad/param norm = 2.2692e-01, time/batch = 0.6596s	
2330/26050 (epoch 4.472), train_loss = 1.88995975, grad/param norm = 2.3033e-01, time/batch = 0.6387s	
2331/26050 (epoch 4.474), train_loss = 1.91006060, grad/param norm = 2.2388e-01, time/batch = 0.6424s	
2332/26050 (epoch 4.476), train_loss = 1.72481091, grad/param norm = 1.9916e-01, time/batch = 0.6424s	
2333/26050 (epoch 4.478), train_loss = 1.52162564, grad/param norm = 1.9256e-01, time/batch = 0.6408s	
2334/26050 (epoch 4.480), train_loss = 1.64226962, grad/param norm = 1.9830e-01, time/batch = 0.6494s	
2335/26050 (epoch 4.482), train_loss = 1.58197331, grad/param norm = 2.1377e-01, time/batch = 0.6492s	
2336/26050 (epoch 4.484), train_loss = 1.44677246, grad/param norm = 2.0865e-01, time/batch = 0.6402s	
2337/26050 (epoch 4.486), train_loss = 1.80036928, grad/param norm = 2.2831e-01, time/batch = 0.6397s	
2338/26050 (epoch 4.488), train_loss = 1.98177722, grad/param norm = 2.2452e-01, time/batch = 0.6455s	
2339/26050 (epoch 4.489), train_loss = 1.85293342, grad/param norm = 2.1639e-01, time/batch = 0.6395s	
2340/26050 (epoch 4.491), train_loss = 1.54267393, grad/param norm = 2.0626e-01, time/batch = 0.6474s	
2341/26050 (epoch 4.493), train_loss = 1.52101083, grad/param norm = 1.9065e-01, time/batch = 0.6425s	
2342/26050 (epoch 4.495), train_loss = 1.60903621, grad/param norm = 2.1843e-01, time/batch = 0.6389s	
2343/26050 (epoch 4.497), train_loss = 1.53365338, grad/param norm = 2.0520e-01, time/batch = 0.6418s	
2344/26050 (epoch 4.499), train_loss = 1.55041435, grad/param norm = 2.1845e-01, time/batch = 0.6401s	
2345/26050 (epoch 4.501), train_loss = 1.57460140, grad/param norm = 2.0158e-01, time/batch = 0.6392s	
2346/26050 (epoch 4.503), train_loss = 1.55614581, grad/param norm = 2.0341e-01, time/batch = 0.6391s	
2347/26050 (epoch 4.505), train_loss = 1.70700549, grad/param norm = 2.0077e-01, time/batch = 0.6393s	
2348/26050 (epoch 4.507), train_loss = 1.73379824, grad/param norm = 2.2176e-01, time/batch = 0.6794s	
2349/26050 (epoch 4.509), train_loss = 1.87493148, grad/param norm = 2.2741e-01, time/batch = 0.6621s	
2350/26050 (epoch 4.511), train_loss = 1.51416306, grad/param norm = 1.9702e-01, time/batch = 0.6392s	
2351/26050 (epoch 4.512), train_loss = 1.69549207, grad/param norm = 2.3073e-01, time/batch = 0.6399s	
2352/26050 (epoch 4.514), train_loss = 1.68677683, grad/param norm = 2.0227e-01, time/batch = 0.6579s	
2353/26050 (epoch 4.516), train_loss = 1.72684119, grad/param norm = 2.0804e-01, time/batch = 0.6590s	
2354/26050 (epoch 4.518), train_loss = 1.69738002, grad/param norm = 2.3264e-01, time/batch = 0.6588s	
2355/26050 (epoch 4.520), train_loss = 1.65289139, grad/param norm = 2.0848e-01, time/batch = 0.6591s	
2356/26050 (epoch 4.522), train_loss = 1.54044329, grad/param norm = 2.0764e-01, time/batch = 0.6591s	
2357/26050 (epoch 4.524), train_loss = 1.89705123, grad/param norm = 2.1755e-01, time/batch = 0.6534s	
2358/26050 (epoch 4.526), train_loss = 1.70963181, grad/param norm = 2.2444e-01, time/batch = 0.6527s	
2359/26050 (epoch 4.528), train_loss = 1.72090690, grad/param norm = 2.2635e-01, time/batch = 0.6560s	
2360/26050 (epoch 4.530), train_loss = 1.60952907, grad/param norm = 2.0337e-01, time/batch = 0.6564s	
2361/26050 (epoch 4.532), train_loss = 1.65981187, grad/param norm = 2.0365e-01, time/batch = 0.6587s	
2362/26050 (epoch 4.534), train_loss = 1.70822167, grad/param norm = 2.1450e-01, time/batch = 0.6583s	
2363/26050 (epoch 4.536), train_loss = 1.54165533, grad/param norm = 2.1259e-01, time/batch = 0.6590s	
2364/26050 (epoch 4.537), train_loss = 1.73120481, grad/param norm = 1.9158e-01, time/batch = 0.6573s	
2365/26050 (epoch 4.539), train_loss = 1.58797942, grad/param norm = 2.0626e-01, time/batch = 0.6425s	
2366/26050 (epoch 4.541), train_loss = 1.79890683, grad/param norm = 2.2948e-01, time/batch = 0.6387s	
2367/26050 (epoch 4.543), train_loss = 1.43408537, grad/param norm = 2.0399e-01, time/batch = 0.6386s	
2368/26050 (epoch 4.545), train_loss = 1.67495936, grad/param norm = 2.2172e-01, time/batch = 0.6394s	
2369/26050 (epoch 4.547), train_loss = 1.67676748, grad/param norm = 2.2542e-01, time/batch = 0.6390s	
2370/26050 (epoch 4.549), train_loss = 1.49205712, grad/param norm = 2.0785e-01, time/batch = 0.6473s	
2371/26050 (epoch 4.551), train_loss = 1.68310594, grad/param norm = 2.3289e-01, time/batch = 0.6597s	
2372/26050 (epoch 4.553), train_loss = 1.57166557, grad/param norm = 2.1692e-01, time/batch = 0.6528s	
2373/26050 (epoch 4.555), train_loss = 1.56186268, grad/param norm = 2.0395e-01, time/batch = 0.6489s	
2374/26050 (epoch 4.557), train_loss = 1.71555260, grad/param norm = 2.0657e-01, time/batch = 0.6518s	
2375/26050 (epoch 4.559), train_loss = 1.64293363, grad/param norm = 2.2674e-01, time/batch = 0.6429s	
2376/26050 (epoch 4.560), train_loss = 1.62807550, grad/param norm = 2.0721e-01, time/batch = 0.6544s	
2377/26050 (epoch 4.562), train_loss = 1.62615172, grad/param norm = 2.0521e-01, time/batch = 0.6629s	
2378/26050 (epoch 4.564), train_loss = 1.82021080, grad/param norm = 2.4256e-01, time/batch = 0.6749s	
2379/26050 (epoch 4.566), train_loss = 1.52650933, grad/param norm = 2.1529e-01, time/batch = 0.6841s	
2380/26050 (epoch 4.568), train_loss = 1.65865594, grad/param norm = 1.9304e-01, time/batch = 0.6567s	
2381/26050 (epoch 4.570), train_loss = 1.74124459, grad/param norm = 2.2202e-01, time/batch = 0.6537s	
2382/26050 (epoch 4.572), train_loss = 1.68951087, grad/param norm = 2.0182e-01, time/batch = 0.6524s	
2383/26050 (epoch 4.574), train_loss = 1.76918226, grad/param norm = 2.4606e-01, time/batch = 0.6610s	
2384/26050 (epoch 4.576), train_loss = 1.72687207, grad/param norm = 2.1516e-01, time/batch = 0.6606s	
2385/26050 (epoch 4.578), train_loss = 1.66497811, grad/param norm = 2.1393e-01, time/batch = 0.6604s	
2386/26050 (epoch 4.580), train_loss = 1.50796945, grad/param norm = 1.9374e-01, time/batch = 0.6647s	
2387/26050 (epoch 4.582), train_loss = 1.70168259, grad/param norm = 2.0728e-01, time/batch = 0.6642s	
2388/26050 (epoch 4.583), train_loss = 1.69119049, grad/param norm = 2.0625e-01, time/batch = 0.6441s	
2389/26050 (epoch 4.585), train_loss = 1.49963162, grad/param norm = 2.0563e-01, time/batch = 0.6401s	
2390/26050 (epoch 4.587), train_loss = 1.70918102, grad/param norm = 2.1387e-01, time/batch = 0.6416s	
2391/26050 (epoch 4.589), train_loss = 1.69668919, grad/param norm = 2.3099e-01, time/batch = 0.6442s	
2392/26050 (epoch 4.591), train_loss = 1.69004486, grad/param norm = 1.9921e-01, time/batch = 0.6396s	
2393/26050 (epoch 4.593), train_loss = 1.52107276, grad/param norm = 2.0995e-01, time/batch = 0.6533s	
2394/26050 (epoch 4.595), train_loss = 1.79218939, grad/param norm = 2.5854e-01, time/batch = 0.6826s	
2395/26050 (epoch 4.597), train_loss = 1.66839026, grad/param norm = 2.3106e-01, time/batch = 0.6482s	
2396/26050 (epoch 4.599), train_loss = 1.47422299, grad/param norm = 1.8335e-01, time/batch = 0.6406s	
2397/26050 (epoch 4.601), train_loss = 1.82914593, grad/param norm = 2.0899e-01, time/batch = 0.6383s	
2398/26050 (epoch 4.603), train_loss = 1.71535055, grad/param norm = 2.0790e-01, time/batch = 0.6402s	
2399/26050 (epoch 4.605), train_loss = 1.53788335, grad/param norm = 1.7986e-01, time/batch = 0.6449s	
2400/26050 (epoch 4.607), train_loss = 1.73475343, grad/param norm = 2.1186e-01, time/batch = 0.6529s	
2401/26050 (epoch 4.608), train_loss = 1.58805821, grad/param norm = 1.9852e-01, time/batch = 0.6449s	
2402/26050 (epoch 4.610), train_loss = 1.62065463, grad/param norm = 2.3385e-01, time/batch = 0.6510s	
2403/26050 (epoch 4.612), train_loss = 1.57054505, grad/param norm = 2.1811e-01, time/batch = 0.6388s	
2404/26050 (epoch 4.614), train_loss = 1.66632437, grad/param norm = 2.1926e-01, time/batch = 0.6409s	
2405/26050 (epoch 4.616), train_loss = 1.93751148, grad/param norm = 2.1749e-01, time/batch = 0.6414s	
2406/26050 (epoch 4.618), train_loss = 1.54383465, grad/param norm = 2.1304e-01, time/batch = 0.6409s	
2407/26050 (epoch 4.620), train_loss = 1.68483992, grad/param norm = 2.3120e-01, time/batch = 0.6395s	
2408/26050 (epoch 4.622), train_loss = 1.35714252, grad/param norm = 1.9049e-01, time/batch = 0.6441s	
2409/26050 (epoch 4.624), train_loss = 1.51122307, grad/param norm = 1.8950e-01, time/batch = 0.6763s	
2410/26050 (epoch 4.626), train_loss = 1.62498413, grad/param norm = 2.2343e-01, time/batch = 0.6658s	
2411/26050 (epoch 4.628), train_loss = 1.64175715, grad/param norm = 2.2196e-01, time/batch = 0.6424s	
2412/26050 (epoch 4.630), train_loss = 1.75410401, grad/param norm = 2.0576e-01, time/batch = 0.6419s	
2413/26050 (epoch 4.631), train_loss = 1.73194546, grad/param norm = 2.1413e-01, time/batch = 0.6420s	
2414/26050 (epoch 4.633), train_loss = 1.47095084, grad/param norm = 1.8635e-01, time/batch = 0.6431s	
2415/26050 (epoch 4.635), train_loss = 1.48579735, grad/param norm = 1.9241e-01, time/batch = 0.6408s	
2416/26050 (epoch 4.637), train_loss = 1.51352620, grad/param norm = 1.9999e-01, time/batch = 0.6416s	
2417/26050 (epoch 4.639), train_loss = 1.70726355, grad/param norm = 2.1478e-01, time/batch = 0.6439s	
2418/26050 (epoch 4.641), train_loss = 1.53642372, grad/param norm = 1.8143e-01, time/batch = 0.6454s	
2419/26050 (epoch 4.643), train_loss = 1.51861621, grad/param norm = 1.9083e-01, time/batch = 0.6406s	
2420/26050 (epoch 4.645), train_loss = 1.70612007, grad/param norm = 2.1433e-01, time/batch = 0.6434s	
2421/26050 (epoch 4.647), train_loss = 1.52596315, grad/param norm = 2.0122e-01, time/batch = 0.6439s	
2422/26050 (epoch 4.649), train_loss = 1.65811340, grad/param norm = 2.1779e-01, time/batch = 0.6426s	
2423/26050 (epoch 4.651), train_loss = 1.61168506, grad/param norm = 2.0492e-01, time/batch = 0.6435s	
2424/26050 (epoch 4.653), train_loss = 1.55681927, grad/param norm = 2.0390e-01, time/batch = 0.6556s	
2425/26050 (epoch 4.655), train_loss = 1.51945191, grad/param norm = 2.0603e-01, time/batch = 0.6741s	
2426/26050 (epoch 4.656), train_loss = 1.50817902, grad/param norm = 1.9608e-01, time/batch = 0.6468s	
2427/26050 (epoch 4.658), train_loss = 1.78215282, grad/param norm = 2.2556e-01, time/batch = 0.6423s	
2428/26050 (epoch 4.660), train_loss = 1.49720587, grad/param norm = 2.3009e-01, time/batch = 0.6390s	
2429/26050 (epoch 4.662), train_loss = 1.46406855, grad/param norm = 2.0402e-01, time/batch = 0.6410s	
2430/26050 (epoch 4.664), train_loss = 1.56340583, grad/param norm = 2.1777e-01, time/batch = 0.6403s	
2431/26050 (epoch 4.666), train_loss = 1.65452880, grad/param norm = 2.2389e-01, time/batch = 0.6411s	
2432/26050 (epoch 4.668), train_loss = 1.34882562, grad/param norm = 1.7792e-01, time/batch = 0.6511s	
2433/26050 (epoch 4.670), train_loss = 1.78752589, grad/param norm = 2.3211e-01, time/batch = 0.6422s	
2434/26050 (epoch 4.672), train_loss = 1.49843606, grad/param norm = 1.9452e-01, time/batch = 0.6394s	
2435/26050 (epoch 4.674), train_loss = 1.47160132, grad/param norm = 1.8937e-01, time/batch = 0.6420s	
2436/26050 (epoch 4.676), train_loss = 1.61927024, grad/param norm = 2.1364e-01, time/batch = 0.6422s	
2437/26050 (epoch 4.678), train_loss = 1.79925961, grad/param norm = 2.1928e-01, time/batch = 0.6468s	
2438/26050 (epoch 4.679), train_loss = 1.72785236, grad/param norm = 2.2185e-01, time/batch = 0.6413s	
2439/26050 (epoch 4.681), train_loss = 1.62580580, grad/param norm = 2.2210e-01, time/batch = 0.6424s	
2440/26050 (epoch 4.683), train_loss = 1.53882275, grad/param norm = 2.1638e-01, time/batch = 0.6825s	
2441/26050 (epoch 4.685), train_loss = 1.54061688, grad/param norm = 1.9933e-01, time/batch = 0.6593s	
2442/26050 (epoch 4.687), train_loss = 1.39337738, grad/param norm = 1.9106e-01, time/batch = 0.6409s	
2443/26050 (epoch 4.689), train_loss = 1.59946584, grad/param norm = 2.0308e-01, time/batch = 0.6404s	
2444/26050 (epoch 4.691), train_loss = 1.31804970, grad/param norm = 1.9910e-01, time/batch = 0.6399s	
2445/26050 (epoch 4.693), train_loss = 1.50416954, grad/param norm = 2.1709e-01, time/batch = 0.6426s	
2446/26050 (epoch 4.695), train_loss = 1.64975133, grad/param norm = 2.0593e-01, time/batch = 0.6405s	
2447/26050 (epoch 4.697), train_loss = 1.44848036, grad/param norm = 2.0946e-01, time/batch = 0.6406s	
2448/26050 (epoch 4.699), train_loss = 1.65478295, grad/param norm = 2.1830e-01, time/batch = 0.6465s	
2449/26050 (epoch 4.701), train_loss = 1.42553707, grad/param norm = 1.8916e-01, time/batch = 0.6426s	
2450/26050 (epoch 4.702), train_loss = 1.85385794, grad/param norm = 2.0451e-01, time/batch = 0.6414s	
2451/26050 (epoch 4.704), train_loss = 1.59050678, grad/param norm = 2.0005e-01, time/batch = 0.6423s	
2452/26050 (epoch 4.706), train_loss = 1.72028387, grad/param norm = 2.2056e-01, time/batch = 0.6419s	
2453/26050 (epoch 4.708), train_loss = 1.66520890, grad/param norm = 2.0481e-01, time/batch = 0.6416s	
2454/26050 (epoch 4.710), train_loss = 1.69725812, grad/param norm = 2.0911e-01, time/batch = 0.6416s	
2455/26050 (epoch 4.712), train_loss = 1.79746032, grad/param norm = 2.2026e-01, time/batch = 0.6698s	
2456/26050 (epoch 4.714), train_loss = 1.49116119, grad/param norm = 2.1863e-01, time/batch = 0.6761s	
2457/26050 (epoch 4.716), train_loss = 1.85449538, grad/param norm = 2.5467e-01, time/batch = 0.6428s	
2458/26050 (epoch 4.718), train_loss = 1.70663361, grad/param norm = 2.3621e-01, time/batch = 0.6405s	
2459/26050 (epoch 4.720), train_loss = 1.51929822, grad/param norm = 2.1248e-01, time/batch = 0.6413s	
2460/26050 (epoch 4.722), train_loss = 1.49235292, grad/param norm = 2.1878e-01, time/batch = 0.6413s	
2461/26050 (epoch 4.724), train_loss = 1.45880369, grad/param norm = 1.9758e-01, time/batch = 0.6429s	
2462/26050 (epoch 4.726), train_loss = 1.70651923, grad/param norm = 2.0979e-01, time/batch = 0.6505s	
2463/26050 (epoch 4.727), train_loss = 1.65167017, grad/param norm = 2.0355e-01, time/batch = 0.6546s	
2464/26050 (epoch 4.729), train_loss = 1.71532284, grad/param norm = 2.3652e-01, time/batch = 0.6697s	
2465/26050 (epoch 4.731), train_loss = 1.57366935, grad/param norm = 1.9203e-01, time/batch = 0.6457s	
2466/26050 (epoch 4.733), train_loss = 1.65375009, grad/param norm = 2.4966e-01, time/batch = 0.6440s	
2467/26050 (epoch 4.735), train_loss = 1.80534015, grad/param norm = 2.1279e-01, time/batch = 0.6571s	
2468/26050 (epoch 4.737), train_loss = 1.65994344, grad/param norm = 2.1413e-01, time/batch = 0.6432s	
2469/26050 (epoch 4.739), train_loss = 1.67063878, grad/param norm = 2.1546e-01, time/batch = 0.6416s	
2470/26050 (epoch 4.741), train_loss = 1.48729054, grad/param norm = 1.8938e-01, time/batch = 0.6588s	
2471/26050 (epoch 4.743), train_loss = 1.73679977, grad/param norm = 2.6491e-01, time/batch = 0.6865s	
2472/26050 (epoch 4.745), train_loss = 1.46651882, grad/param norm = 1.9829e-01, time/batch = 0.6493s	
2473/26050 (epoch 4.747), train_loss = 1.54482324, grad/param norm = 2.0615e-01, time/batch = 0.6418s	
2474/26050 (epoch 4.749), train_loss = 1.67631254, grad/param norm = 2.3068e-01, time/batch = 0.6413s	
2475/26050 (epoch 4.750), train_loss = 1.54981825, grad/param norm = 1.8957e-01, time/batch = 0.6415s	
2476/26050 (epoch 4.752), train_loss = 1.70415867, grad/param norm = 2.1973e-01, time/batch = 0.6455s	
2477/26050 (epoch 4.754), train_loss = 1.50263474, grad/param norm = 1.9999e-01, time/batch = 0.6408s	
2478/26050 (epoch 4.756), train_loss = 1.72766334, grad/param norm = 2.5595e-01, time/batch = 0.6443s	
2479/26050 (epoch 4.758), train_loss = 1.65250299, grad/param norm = 2.3259e-01, time/batch = 0.6496s	
2480/26050 (epoch 4.760), train_loss = 1.64328473, grad/param norm = 2.0823e-01, time/batch = 0.6406s	
2481/26050 (epoch 4.762), train_loss = 1.55555519, grad/param norm = 2.1753e-01, time/batch = 0.6441s	
2482/26050 (epoch 4.764), train_loss = 1.71665984, grad/param norm = 2.1814e-01, time/batch = 0.6441s	
2483/26050 (epoch 4.766), train_loss = 1.70388716, grad/param norm = 2.2010e-01, time/batch = 0.6403s	
2484/26050 (epoch 4.768), train_loss = 1.53823710, grad/param norm = 1.8674e-01, time/batch = 0.6403s	
2485/26050 (epoch 4.770), train_loss = 1.61177520, grad/param norm = 2.0787e-01, time/batch = 0.6410s	
2486/26050 (epoch 4.772), train_loss = 1.61707942, grad/param norm = 2.2011e-01, time/batch = 0.6453s	
2487/26050 (epoch 4.774), train_loss = 1.53732997, grad/param norm = 1.9943e-01, time/batch = 0.6420s	
2488/26050 (epoch 4.775), train_loss = 1.36110460, grad/param norm = 2.0275e-01, time/batch = 0.6394s	
2489/26050 (epoch 4.777), train_loss = 1.51661359, grad/param norm = 2.0539e-01, time/batch = 0.6404s	
2490/26050 (epoch 4.779), train_loss = 1.59265133, grad/param norm = 2.2276e-01, time/batch = 0.6410s	
2491/26050 (epoch 4.781), train_loss = 1.54002760, grad/param norm = 2.0577e-01, time/batch = 0.6497s	
2492/26050 (epoch 4.783), train_loss = 1.52989681, grad/param norm = 1.8071e-01, time/batch = 0.6419s	
2493/26050 (epoch 4.785), train_loss = 1.58161625, grad/param norm = 2.3359e-01, time/batch = 0.6417s	
2494/26050 (epoch 4.787), train_loss = 1.55537629, grad/param norm = 2.0211e-01, time/batch = 0.6434s	
2495/26050 (epoch 4.789), train_loss = 1.63924593, grad/param norm = 2.2030e-01, time/batch = 0.6518s	
2496/26050 (epoch 4.791), train_loss = 1.62679633, grad/param norm = 1.9719e-01, time/batch = 0.6397s	
2497/26050 (epoch 4.793), train_loss = 1.58669500, grad/param norm = 2.2062e-01, time/batch = 0.6405s	
2498/26050 (epoch 4.795), train_loss = 1.49022021, grad/param norm = 1.9783e-01, time/batch = 0.6397s	
2499/26050 (epoch 4.797), train_loss = 1.49486861, grad/param norm = 1.9129e-01, time/batch = 0.6386s	
2500/26050 (epoch 4.798), train_loss = 1.47390148, grad/param norm = 2.1392e-01, time/batch = 0.6399s	
2501/26050 (epoch 4.800), train_loss = 1.44881885, grad/param norm = 1.9824e-01, time/batch = 0.6620s	
2502/26050 (epoch 4.802), train_loss = 1.62660050, grad/param norm = 2.1088e-01, time/batch = 0.6827s	
2503/26050 (epoch 4.804), train_loss = 1.59771777, grad/param norm = 2.0053e-01, time/batch = 0.6410s	
2504/26050 (epoch 4.806), train_loss = 1.78034504, grad/param norm = 2.2355e-01, time/batch = 0.6408s	
2505/26050 (epoch 4.808), train_loss = 1.53497177, grad/param norm = 2.0352e-01, time/batch = 0.6396s	
2506/26050 (epoch 4.810), train_loss = 1.50695806, grad/param norm = 2.2055e-01, time/batch = 0.6415s	
2507/26050 (epoch 4.812), train_loss = 1.45016245, grad/param norm = 1.9920e-01, time/batch = 0.6395s	
2508/26050 (epoch 4.814), train_loss = 1.51588251, grad/param norm = 2.2848e-01, time/batch = 0.6390s	
2509/26050 (epoch 4.816), train_loss = 1.64969584, grad/param norm = 2.1500e-01, time/batch = 0.6509s	
2510/26050 (epoch 4.818), train_loss = 1.75552207, grad/param norm = 2.3976e-01, time/batch = 0.6414s	
2511/26050 (epoch 4.820), train_loss = 1.65509878, grad/param norm = 2.2679e-01, time/batch = 0.6420s	
2512/26050 (epoch 4.821), train_loss = 1.77969070, grad/param norm = 2.4274e-01, time/batch = 0.6421s	
2513/26050 (epoch 4.823), train_loss = 1.82673399, grad/param norm = 2.2035e-01, time/batch = 0.6544s	
2514/26050 (epoch 4.825), train_loss = 1.53428036, grad/param norm = 2.1581e-01, time/batch = 0.6418s	
2515/26050 (epoch 4.827), train_loss = 1.67597457, grad/param norm = 2.5027e-01, time/batch = 0.6403s	
2516/26050 (epoch 4.829), train_loss = 1.67365396, grad/param norm = 2.0193e-01, time/batch = 0.6514s	
2517/26050 (epoch 4.831), train_loss = 1.73723928, grad/param norm = 2.0614e-01, time/batch = 0.6840s	
2518/26050 (epoch 4.833), train_loss = 1.80459418, grad/param norm = 2.4192e-01, time/batch = 0.6643s	
2519/26050 (epoch 4.835), train_loss = 1.86216635, grad/param norm = 2.1098e-01, time/batch = 0.6426s	
2520/26050 (epoch 4.837), train_loss = 1.53471218, grad/param norm = 2.0365e-01, time/batch = 0.6404s	
2521/26050 (epoch 4.839), train_loss = 1.72858984, grad/param norm = 1.9724e-01, time/batch = 0.6424s	
2522/26050 (epoch 4.841), train_loss = 1.69619586, grad/param norm = 2.0006e-01, time/batch = 0.6425s	
2523/26050 (epoch 4.843), train_loss = 1.67211381, grad/param norm = 2.0729e-01, time/batch = 0.6413s	
2524/26050 (epoch 4.845), train_loss = 1.53025176, grad/param norm = 2.1018e-01, time/batch = 0.6422s	
2525/26050 (epoch 4.846), train_loss = 1.74121897, grad/param norm = 2.1266e-01, time/batch = 0.6454s	
2526/26050 (epoch 4.848), train_loss = 1.54121016, grad/param norm = 1.9099e-01, time/batch = 0.6424s	
2527/26050 (epoch 4.850), train_loss = 1.55158291, grad/param norm = 1.8867e-01, time/batch = 0.6416s	
2528/26050 (epoch 4.852), train_loss = 1.58596941, grad/param norm = 2.2168e-01, time/batch = 0.6437s	
2529/26050 (epoch 4.854), train_loss = 1.62045661, grad/param norm = 2.0307e-01, time/batch = 0.6440s	
2530/26050 (epoch 4.856), train_loss = 1.49976117, grad/param norm = 2.0012e-01, time/batch = 0.6412s	
2531/26050 (epoch 4.858), train_loss = 1.44215271, grad/param norm = 2.1413e-01, time/batch = 0.6437s	
2532/26050 (epoch 4.860), train_loss = 1.62767611, grad/param norm = 2.2711e-01, time/batch = 0.6458s	
2533/26050 (epoch 4.862), train_loss = 1.61287119, grad/param norm = 2.2825e-01, time/batch = 0.6439s	
2534/26050 (epoch 4.864), train_loss = 1.51466163, grad/param norm = 2.0384e-01, time/batch = 0.6413s	
2535/26050 (epoch 4.866), train_loss = 1.47588739, grad/param norm = 1.8862e-01, time/batch = 0.6422s	
2536/26050 (epoch 4.868), train_loss = 1.73845327, grad/param norm = 2.1505e-01, time/batch = 0.6460s	
2537/26050 (epoch 4.869), train_loss = 1.43547897, grad/param norm = 1.8343e-01, time/batch = 0.6413s	
2538/26050 (epoch 4.871), train_loss = 1.37373888, grad/param norm = 1.8946e-01, time/batch = 0.6418s	
2539/26050 (epoch 4.873), train_loss = 1.56953457, grad/param norm = 2.0537e-01, time/batch = 0.6476s	
2540/26050 (epoch 4.875), train_loss = 1.58104571, grad/param norm = 2.2022e-01, time/batch = 0.6454s	
2541/26050 (epoch 4.877), train_loss = 1.39852669, grad/param norm = 2.0593e-01, time/batch = 0.6480s	
2542/26050 (epoch 4.879), train_loss = 1.52835512, grad/param norm = 1.8961e-01, time/batch = 0.6468s	
2543/26050 (epoch 4.881), train_loss = 1.81608297, grad/param norm = 2.1171e-01, time/batch = 0.6473s	
2544/26050 (epoch 4.883), train_loss = 1.62879929, grad/param norm = 1.9195e-01, time/batch = 0.6436s	
2545/26050 (epoch 4.885), train_loss = 1.33249918, grad/param norm = 1.8093e-01, time/batch = 0.6425s	
2546/26050 (epoch 4.887), train_loss = 1.61807047, grad/param norm = 2.0911e-01, time/batch = 0.6434s	
2547/26050 (epoch 4.889), train_loss = 1.49917575, grad/param norm = 1.9054e-01, time/batch = 0.6453s	
2548/26050 (epoch 4.891), train_loss = 1.33985868, grad/param norm = 1.9541e-01, time/batch = 0.6427s	
2549/26050 (epoch 4.893), train_loss = 1.31466442, grad/param norm = 1.7388e-01, time/batch = 0.6402s	
2550/26050 (epoch 4.894), train_loss = 1.43879598, grad/param norm = 1.7756e-01, time/batch = 0.6397s	
2551/26050 (epoch 4.896), train_loss = 1.67438342, grad/param norm = 1.9872e-01, time/batch = 0.6417s	
2552/26050 (epoch 4.898), train_loss = 1.51671354, grad/param norm = 1.9540e-01, time/batch = 0.6664s	
2553/26050 (epoch 4.900), train_loss = 1.83669397, grad/param norm = 2.2956e-01, time/batch = 0.6772s	
2554/26050 (epoch 4.902), train_loss = 1.61678037, grad/param norm = 2.0551e-01, time/batch = 0.6389s	
2555/26050 (epoch 4.904), train_loss = 1.56032934, grad/param norm = 2.0941e-01, time/batch = 0.6626s	
2556/26050 (epoch 4.906), train_loss = 1.58609921, grad/param norm = 2.0375e-01, time/batch = 0.6449s	
2557/26050 (epoch 4.908), train_loss = 1.57321174, grad/param norm = 2.0726e-01, time/batch = 0.6505s	
2558/26050 (epoch 4.910), train_loss = 1.50372955, grad/param norm = 1.8793e-01, time/batch = 0.6432s	
2559/26050 (epoch 4.912), train_loss = 1.86435977, grad/param norm = 2.2295e-01, time/batch = 0.6465s	
2560/26050 (epoch 4.914), train_loss = 2.02277139, grad/param norm = 2.2575e-01, time/batch = 0.6388s	
2561/26050 (epoch 4.916), train_loss = 1.78457228, grad/param norm = 2.2356e-01, time/batch = 0.6405s	
2562/26050 (epoch 4.917), train_loss = 1.59540857, grad/param norm = 1.9575e-01, time/batch = 0.6414s	
2563/26050 (epoch 4.919), train_loss = 1.68525379, grad/param norm = 2.0310e-01, time/batch = 0.6406s	
2564/26050 (epoch 4.921), train_loss = 1.46890002, grad/param norm = 2.0844e-01, time/batch = 0.6410s	
2565/26050 (epoch 4.923), train_loss = 1.52396004, grad/param norm = 2.1557e-01, time/batch = 0.6394s	
2566/26050 (epoch 4.925), train_loss = 1.48503558, grad/param norm = 1.8948e-01, time/batch = 0.6404s	
2567/26050 (epoch 4.927), train_loss = 1.46627949, grad/param norm = 1.7784e-01, time/batch = 0.6537s	
2568/26050 (epoch 4.929), train_loss = 1.49204648, grad/param norm = 2.1475e-01, time/batch = 0.6822s	
2569/26050 (epoch 4.931), train_loss = 1.90233741, grad/param norm = 2.5954e-01, time/batch = 0.6542s	
2570/26050 (epoch 4.933), train_loss = 1.57357267, grad/param norm = 2.1738e-01, time/batch = 0.6432s	
2571/26050 (epoch 4.935), train_loss = 1.46137766, grad/param norm = 2.0694e-01, time/batch = 0.6475s	
2572/26050 (epoch 4.937), train_loss = 1.54550992, grad/param norm = 1.9887e-01, time/batch = 0.6453s	
2573/26050 (epoch 4.939), train_loss = 1.44853307, grad/param norm = 2.0191e-01, time/batch = 0.6398s	
2574/26050 (epoch 4.940), train_loss = 1.63178488, grad/param norm = 1.9666e-01, time/batch = 0.6429s	
2575/26050 (epoch 4.942), train_loss = 1.64285337, grad/param norm = 2.2765e-01, time/batch = 0.6451s	
2576/26050 (epoch 4.944), train_loss = 1.53840940, grad/param norm = 2.2733e-01, time/batch = 0.6448s	
2577/26050 (epoch 4.946), train_loss = 1.74142235, grad/param norm = 1.9420e-01, time/batch = 0.6402s	
2578/26050 (epoch 4.948), train_loss = 1.37581996, grad/param norm = 2.3640e-01, time/batch = 0.6428s	
2579/26050 (epoch 4.950), train_loss = 1.52201338, grad/param norm = 2.1185e-01, time/batch = 0.6439s	
2580/26050 (epoch 4.952), train_loss = 1.76386246, grad/param norm = 2.1972e-01, time/batch = 0.6503s	
2581/26050 (epoch 4.954), train_loss = 1.69390129, grad/param norm = 1.9588e-01, time/batch = 0.6530s	
2582/26050 (epoch 4.956), train_loss = 1.72598298, grad/param norm = 2.1873e-01, time/batch = 0.6414s	
2583/26050 (epoch 4.958), train_loss = 1.59038788, grad/param norm = 1.9254e-01, time/batch = 0.6441s	
2584/26050 (epoch 4.960), train_loss = 1.50660617, grad/param norm = 1.9129e-01, time/batch = 0.6614s	
2585/26050 (epoch 4.962), train_loss = 1.49860334, grad/param norm = 1.9670e-01, time/batch = 0.6596s	
2586/26050 (epoch 4.964), train_loss = 1.55642370, grad/param norm = 2.0223e-01, time/batch = 0.6678s	
2587/26050 (epoch 4.965), train_loss = 1.43493782, grad/param norm = 1.9582e-01, time/batch = 0.6553s	
2588/26050 (epoch 4.967), train_loss = 1.93301019, grad/param norm = 2.2547e-01, time/batch = 0.6554s	
2589/26050 (epoch 4.969), train_loss = 1.53327724, grad/param norm = 2.0571e-01, time/batch = 0.6476s	
2590/26050 (epoch 4.971), train_loss = 1.38223342, grad/param norm = 1.8036e-01, time/batch = 0.6465s	
2591/26050 (epoch 4.973), train_loss = 1.53946780, grad/param norm = 2.2461e-01, time/batch = 0.6540s	
2592/26050 (epoch 4.975), train_loss = 1.65796318, grad/param norm = 1.9393e-01, time/batch = 0.6567s	
2593/26050 (epoch 4.977), train_loss = 1.60004342, grad/param norm = 1.8130e-01, time/batch = 0.6575s	
2594/26050 (epoch 4.979), train_loss = 1.41456075, grad/param norm = 1.9086e-01, time/batch = 0.6560s	
2595/26050 (epoch 4.981), train_loss = 1.64312680, grad/param norm = 1.8378e-01, time/batch = 0.6598s	
2596/26050 (epoch 4.983), train_loss = 1.66113905, grad/param norm = 2.0955e-01, time/batch = 0.6425s	
2597/26050 (epoch 4.985), train_loss = 1.64187533, grad/param norm = 2.1201e-01, time/batch = 0.6467s	
2598/26050 (epoch 4.987), train_loss = 1.75992822, grad/param norm = 2.2148e-01, time/batch = 0.6541s	
2599/26050 (epoch 4.988), train_loss = 1.74157886, grad/param norm = 2.2530e-01, time/batch = 0.6529s	
2600/26050 (epoch 4.990), train_loss = 1.54539127, grad/param norm = 2.2117e-01, time/batch = 0.6379s	
2601/26050 (epoch 4.992), train_loss = 1.79898256, grad/param norm = 2.3769e-01, time/batch = 0.6442s	
2602/26050 (epoch 4.994), train_loss = 1.55167541, grad/param norm = 2.0835e-01, time/batch = 0.6459s	
2603/26050 (epoch 4.996), train_loss = 1.64330750, grad/param norm = 2.5833e-01, time/batch = 0.6428s	
2604/26050 (epoch 4.998), train_loss = 1.66283299, grad/param norm = 2.0899e-01, time/batch = 0.6583s	
2605/26050 (epoch 5.000), train_loss = 1.55924217, grad/param norm = 2.0072e-01, time/batch = 0.6610s	
2606/26050 (epoch 5.002), train_loss = 1.61255647, grad/param norm = 1.9299e-01, time/batch = 0.6405s	
2607/26050 (epoch 5.004), train_loss = 1.54503514, grad/param norm = 2.1002e-01, time/batch = 0.6395s	
2608/26050 (epoch 5.006), train_loss = 1.47512258, grad/param norm = 1.8708e-01, time/batch = 0.6405s	
2609/26050 (epoch 5.008), train_loss = 1.50427844, grad/param norm = 1.9387e-01, time/batch = 0.6409s	
2610/26050 (epoch 5.010), train_loss = 1.55219086, grad/param norm = 1.8694e-01, time/batch = 0.6416s	
2611/26050 (epoch 5.012), train_loss = 1.64224253, grad/param norm = 2.1983e-01, time/batch = 0.6401s	
2612/26050 (epoch 5.013), train_loss = 2.05193255, grad/param norm = 2.1625e-01, time/batch = 0.6400s	
2613/26050 (epoch 5.015), train_loss = 1.44576714, grad/param norm = 1.9345e-01, time/batch = 0.6489s	
2614/26050 (epoch 5.017), train_loss = 1.58379090, grad/param norm = 2.0644e-01, time/batch = 0.6760s	
2615/26050 (epoch 5.019), train_loss = 1.41533724, grad/param norm = 1.7045e-01, time/batch = 0.6393s	
2616/26050 (epoch 5.021), train_loss = 1.74498317, grad/param norm = 2.3448e-01, time/batch = 0.6397s	
2617/26050 (epoch 5.023), train_loss = 1.46969111, grad/param norm = 2.0711e-01, time/batch = 0.6543s	
2618/26050 (epoch 5.025), train_loss = 1.51876598, grad/param norm = 2.1375e-01, time/batch = 0.6486s	
2619/26050 (epoch 5.027), train_loss = 1.33667689, grad/param norm = 1.8549e-01, time/batch = 0.6410s	
2620/26050 (epoch 5.029), train_loss = 1.50922348, grad/param norm = 1.9143e-01, time/batch = 0.6387s	
2621/26050 (epoch 5.031), train_loss = 1.77314695, grad/param norm = 2.2934e-01, time/batch = 0.6434s	
2622/26050 (epoch 5.033), train_loss = 1.61403587, grad/param norm = 2.1467e-01, time/batch = 0.6415s	
2623/26050 (epoch 5.035), train_loss = 1.74905869, grad/param norm = 1.9748e-01, time/batch = 0.6410s	
2624/26050 (epoch 5.036), train_loss = 1.55790228, grad/param norm = 2.1480e-01, time/batch = 0.6411s	
2625/26050 (epoch 5.038), train_loss = 1.36836812, grad/param norm = 2.0341e-01, time/batch = 0.6395s	
2626/26050 (epoch 5.040), train_loss = 1.64365337, grad/param norm = 2.2226e-01, time/batch = 0.6393s	
2627/26050 (epoch 5.042), train_loss = 1.42430446, grad/param norm = 1.9552e-01, time/batch = 0.6390s	
2628/26050 (epoch 5.044), train_loss = 1.62050140, grad/param norm = 1.9317e-01, time/batch = 0.6388s	
2629/26050 (epoch 5.046), train_loss = 1.38080903, grad/param norm = 2.0651e-01, time/batch = 0.6706s	
2630/26050 (epoch 5.048), train_loss = 1.58678919, grad/param norm = 1.9251e-01, time/batch = 0.6700s	
2631/26050 (epoch 5.050), train_loss = 1.45770408, grad/param norm = 2.1267e-01, time/batch = 0.6402s	
2632/26050 (epoch 5.052), train_loss = 1.57961168, grad/param norm = 2.0575e-01, time/batch = 0.6462s	
2633/26050 (epoch 5.054), train_loss = 1.43455279, grad/param norm = 2.2119e-01, time/batch = 0.6411s	
2634/26050 (epoch 5.056), train_loss = 1.23396378, grad/param norm = 1.7607e-01, time/batch = 0.6406s	
2635/26050 (epoch 5.058), train_loss = 1.46033717, grad/param norm = 1.9174e-01, time/batch = 0.6438s	
2636/26050 (epoch 5.060), train_loss = 1.53273406, grad/param norm = 1.8541e-01, time/batch = 0.6481s	
2637/26050 (epoch 5.061), train_loss = 1.43481136, grad/param norm = 1.9388e-01, time/batch = 0.6396s	
2638/26050 (epoch 5.063), train_loss = 1.45231769, grad/param norm = 1.7437e-01, time/batch = 0.6399s	
2639/26050 (epoch 5.065), train_loss = 1.39371521, grad/param norm = 1.9318e-01, time/batch = 0.6425s	
2640/26050 (epoch 5.067), train_loss = 1.65314135, grad/param norm = 2.2401e-01, time/batch = 0.6420s	
2641/26050 (epoch 5.069), train_loss = 1.64303966, grad/param norm = 2.0567e-01, time/batch = 0.6416s	
2642/26050 (epoch 5.071), train_loss = 1.62614696, grad/param norm = 2.1409e-01, time/batch = 0.6410s	
2643/26050 (epoch 5.073), train_loss = 1.78522968, grad/param norm = 1.9831e-01, time/batch = 0.6411s	
2644/26050 (epoch 5.075), train_loss = 1.43077644, grad/param norm = 1.8533e-01, time/batch = 0.6545s	
2645/26050 (epoch 5.077), train_loss = 1.44892636, grad/param norm = 2.0372e-01, time/batch = 0.6825s	
2646/26050 (epoch 5.079), train_loss = 1.68359106, grad/param norm = 2.0824e-01, time/batch = 0.6474s	
2647/26050 (epoch 5.081), train_loss = 1.46936327, grad/param norm = 1.8478e-01, time/batch = 0.6552s	
2648/26050 (epoch 5.083), train_loss = 1.64288973, grad/param norm = 2.1362e-01, time/batch = 0.6574s	
2649/26050 (epoch 5.084), train_loss = 1.81231287, grad/param norm = 2.3563e-01, time/batch = 0.6398s	
2650/26050 (epoch 5.086), train_loss = 1.73374929, grad/param norm = 2.2809e-01, time/batch = 0.6501s	
2651/26050 (epoch 5.088), train_loss = 1.40999269, grad/param norm = 1.7462e-01, time/batch = 0.6479s	
2652/26050 (epoch 5.090), train_loss = 1.75762652, grad/param norm = 2.0281e-01, time/batch = 0.6426s	
2653/26050 (epoch 5.092), train_loss = 1.48324324, grad/param norm = 2.1311e-01, time/batch = 0.6463s	
2654/26050 (epoch 5.094), train_loss = 1.62181450, grad/param norm = 2.0098e-01, time/batch = 0.6444s	
2655/26050 (epoch 5.096), train_loss = 1.40405256, grad/param norm = 1.8261e-01, time/batch = 0.6429s	
2656/26050 (epoch 5.098), train_loss = 1.46941156, grad/param norm = 1.9282e-01, time/batch = 0.6518s	
2657/26050 (epoch 5.100), train_loss = 1.47579623, grad/param norm = 2.2302e-01, time/batch = 0.6452s	
2658/26050 (epoch 5.102), train_loss = 1.60357156, grad/param norm = 1.9430e-01, time/batch = 0.6421s	
2659/26050 (epoch 5.104), train_loss = 1.64492596, grad/param norm = 2.0822e-01, time/batch = 0.6406s	
2660/26050 (epoch 5.106), train_loss = 1.49129630, grad/param norm = 1.9711e-01, time/batch = 0.6824s	
2661/26050 (epoch 5.107), train_loss = 1.26722923, grad/param norm = 1.8558e-01, time/batch = 0.6597s	
2662/26050 (epoch 5.109), train_loss = 1.44395886, grad/param norm = 1.8448e-01, time/batch = 0.6473s	
2663/26050 (epoch 5.111), train_loss = 1.82924395, grad/param norm = 2.3331e-01, time/batch = 0.6480s	
2664/26050 (epoch 5.113), train_loss = 1.46741481, grad/param norm = 2.0888e-01, time/batch = 0.6492s	
2665/26050 (epoch 5.115), train_loss = 1.70155280, grad/param norm = 2.0063e-01, time/batch = 0.6412s	
2666/26050 (epoch 5.117), train_loss = 1.62056086, grad/param norm = 2.1467e-01, time/batch = 0.6427s	
2667/26050 (epoch 5.119), train_loss = 1.36567407, grad/param norm = 1.9625e-01, time/batch = 0.6457s	
2668/26050 (epoch 5.121), train_loss = 1.58707983, grad/param norm = 2.1214e-01, time/batch = 0.6425s	
2669/26050 (epoch 5.123), train_loss = 1.48906174, grad/param norm = 2.1654e-01, time/batch = 0.6416s	
2670/26050 (epoch 5.125), train_loss = 1.29520097, grad/param norm = 1.7248e-01, time/batch = 0.6441s	
2671/26050 (epoch 5.127), train_loss = 1.34064070, grad/param norm = 1.8947e-01, time/batch = 0.6441s	
2672/26050 (epoch 5.129), train_loss = 1.32571000, grad/param norm = 1.8146e-01, time/batch = 0.6529s	
2673/26050 (epoch 5.131), train_loss = 1.55498775, grad/param norm = 2.1035e-01, time/batch = 0.6624s	
2674/26050 (epoch 5.132), train_loss = 1.47350993, grad/param norm = 1.8777e-01, time/batch = 0.6548s	
2675/26050 (epoch 5.134), train_loss = 1.50810379, grad/param norm = 2.1209e-01, time/batch = 0.6772s	
2676/26050 (epoch 5.136), train_loss = 1.50201811, grad/param norm = 1.8592e-01, time/batch = 0.6728s	
2677/26050 (epoch 5.138), train_loss = 1.45553108, grad/param norm = 2.3792e-01, time/batch = 0.6421s	
2678/26050 (epoch 5.140), train_loss = 1.49812409, grad/param norm = 1.9564e-01, time/batch = 0.6447s	
2679/26050 (epoch 5.142), train_loss = 1.53561684, grad/param norm = 1.9733e-01, time/batch = 0.6462s	
2680/26050 (epoch 5.144), train_loss = 1.38208449, grad/param norm = 1.9807e-01, time/batch = 0.6416s	
2681/26050 (epoch 5.146), train_loss = 1.28621734, grad/param norm = 1.8136e-01, time/batch = 0.6425s	
2682/26050 (epoch 5.148), train_loss = 1.31983194, grad/param norm = 1.7102e-01, time/batch = 0.6462s	
2683/26050 (epoch 5.150), train_loss = 1.55436073, grad/param norm = 2.0574e-01, time/batch = 0.6433s	
2684/26050 (epoch 5.152), train_loss = 1.84055698, grad/param norm = 2.2561e-01, time/batch = 0.6615s	
2685/26050 (epoch 5.154), train_loss = 1.37494948, grad/param norm = 1.9739e-01, time/batch = 0.6517s	
2686/26050 (epoch 5.155), train_loss = 1.37883847, grad/param norm = 1.8498e-01, time/batch = 0.6412s	
2687/26050 (epoch 5.157), train_loss = 1.54416488, grad/param norm = 2.0788e-01, time/batch = 0.6394s	
2688/26050 (epoch 5.159), train_loss = 1.55763575, grad/param norm = 2.1758e-01, time/batch = 0.6413s	
2689/26050 (epoch 5.161), train_loss = 1.77011405, grad/param norm = 2.2052e-01, time/batch = 0.6395s	
2690/26050 (epoch 5.163), train_loss = 1.41788901, grad/param norm = 1.8737e-01, time/batch = 0.6540s	
2691/26050 (epoch 5.165), train_loss = 1.21589242, grad/param norm = 1.7734e-01, time/batch = 0.6835s	
2692/26050 (epoch 5.167), train_loss = 1.68481636, grad/param norm = 2.4508e-01, time/batch = 0.6434s	
2693/26050 (epoch 5.169), train_loss = 1.61314061, grad/param norm = 2.1022e-01, time/batch = 0.6392s	
2694/26050 (epoch 5.171), train_loss = 1.32017536, grad/param norm = 1.6994e-01, time/batch = 0.6466s	
2695/26050 (epoch 5.173), train_loss = 1.50174386, grad/param norm = 2.0955e-01, time/batch = 0.6398s	
2696/26050 (epoch 5.175), train_loss = 1.53923976, grad/param norm = 2.2225e-01, time/batch = 0.6392s	
2697/26050 (epoch 5.177), train_loss = 1.61069279, grad/param norm = 2.0262e-01, time/batch = 0.6391s	
2698/26050 (epoch 5.179), train_loss = 1.21852819, grad/param norm = 1.7755e-01, time/batch = 0.6413s	
2699/26050 (epoch 5.180), train_loss = 1.78139915, grad/param norm = 2.0015e-01, time/batch = 0.6385s	
2700/26050 (epoch 5.182), train_loss = 1.85812745, grad/param norm = 2.1344e-01, time/batch = 0.6396s	
2701/26050 (epoch 5.184), train_loss = 1.58703432, grad/param norm = 1.9812e-01, time/batch = 0.6431s	
2702/26050 (epoch 5.186), train_loss = 1.27757032, grad/param norm = 1.7722e-01, time/batch = 0.6410s	
2703/26050 (epoch 5.188), train_loss = 1.52494184, grad/param norm = 1.8565e-01, time/batch = 0.6399s	
2704/26050 (epoch 5.190), train_loss = 1.61480927, grad/param norm = 2.0972e-01, time/batch = 0.6387s	
2705/26050 (epoch 5.192), train_loss = 1.55261682, grad/param norm = 2.0891e-01, time/batch = 0.6381s	
2706/26050 (epoch 5.194), train_loss = 1.56203236, grad/param norm = 2.0105e-01, time/batch = 0.6385s	
2707/26050 (epoch 5.196), train_loss = 1.64354400, grad/param norm = 2.2302e-01, time/batch = 0.6386s	
2708/26050 (epoch 5.198), train_loss = 1.44235745, grad/param norm = 1.9140e-01, time/batch = 0.6395s	
2709/26050 (epoch 5.200), train_loss = 1.45388222, grad/param norm = 1.9813e-01, time/batch = 0.6414s	
2710/26050 (epoch 5.202), train_loss = 1.45127774, grad/param norm = 1.9995e-01, time/batch = 0.6391s	
2711/26050 (epoch 5.203), train_loss = 1.61780753, grad/param norm = 2.0920e-01, time/batch = 0.6388s	
2712/26050 (epoch 5.205), train_loss = 1.40853360, grad/param norm = 1.9195e-01, time/batch = 0.6384s	
2713/26050 (epoch 5.207), train_loss = 1.48826893, grad/param norm = 1.7661e-01, time/batch = 0.6401s	
2714/26050 (epoch 5.209), train_loss = 1.47415553, grad/param norm = 1.9383e-01, time/batch = 0.6387s	
2715/26050 (epoch 5.211), train_loss = 1.39082078, grad/param norm = 2.0712e-01, time/batch = 0.6377s	
2716/26050 (epoch 5.213), train_loss = 1.57502974, grad/param norm = 1.9252e-01, time/batch = 0.6388s	
2717/26050 (epoch 5.215), train_loss = 1.59138070, grad/param norm = 2.1692e-01, time/batch = 0.6393s	
2718/26050 (epoch 5.217), train_loss = 1.46783878, grad/param norm = 1.9887e-01, time/batch = 0.6391s	
2719/26050 (epoch 5.219), train_loss = 1.45395107, grad/param norm = 2.0454e-01, time/batch = 0.6389s	
2720/26050 (epoch 5.221), train_loss = 1.41022963, grad/param norm = 2.0549e-01, time/batch = 0.6390s	
2721/26050 (epoch 5.223), train_loss = 1.65382207, grad/param norm = 2.2435e-01, time/batch = 0.6403s	
2722/26050 (epoch 5.225), train_loss = 1.42559977, grad/param norm = 2.1312e-01, time/batch = 0.6397s	
2723/26050 (epoch 5.226), train_loss = 1.69707086, grad/param norm = 2.3125e-01, time/batch = 0.6407s	
2724/26050 (epoch 5.228), train_loss = 1.67858675, grad/param norm = 2.2759e-01, time/batch = 0.6401s	
2725/26050 (epoch 5.230), train_loss = 1.53988251, grad/param norm = 2.0187e-01, time/batch = 0.6487s	
2726/26050 (epoch 5.232), train_loss = 1.69827628, grad/param norm = 2.1614e-01, time/batch = 0.6720s	
2727/26050 (epoch 5.234), train_loss = 1.31297226, grad/param norm = 1.8828e-01, time/batch = 0.6728s	
2728/26050 (epoch 5.236), train_loss = 1.55880296, grad/param norm = 2.1094e-01, time/batch = 0.6384s	
2729/26050 (epoch 5.238), train_loss = 1.29258257, grad/param norm = 1.8068e-01, time/batch = 0.6383s	
2730/26050 (epoch 5.240), train_loss = 1.45953349, grad/param norm = 1.8280e-01, time/batch = 0.6387s	
2731/26050 (epoch 5.242), train_loss = 1.49533432, grad/param norm = 1.9329e-01, time/batch = 0.6394s	
2732/26050 (epoch 5.244), train_loss = 1.58735114, grad/param norm = 2.2316e-01, time/batch = 0.6403s	
2733/26050 (epoch 5.246), train_loss = 1.43697292, grad/param norm = 1.8795e-01, time/batch = 0.6396s	
2734/26050 (epoch 5.248), train_loss = 1.62010046, grad/param norm = 2.1726e-01, time/batch = 0.6380s	
2735/26050 (epoch 5.250), train_loss = 1.60893148, grad/param norm = 2.1211e-01, time/batch = 0.6492s	
2736/26050 (epoch 5.251), train_loss = 1.40137356, grad/param norm = 2.0180e-01, time/batch = 0.6406s	
2737/26050 (epoch 5.253), train_loss = 1.32727350, grad/param norm = 1.9365e-01, time/batch = 0.6786s	
2738/26050 (epoch 5.255), train_loss = 1.75768392, grad/param norm = 2.0659e-01, time/batch = 0.6454s	
2739/26050 (epoch 5.257), train_loss = 1.52673367, grad/param norm = 1.9465e-01, time/batch = 0.6412s	
2740/26050 (epoch 5.259), train_loss = 1.64962829, grad/param norm = 2.0822e-01, time/batch = 0.6564s	
2741/26050 (epoch 5.261), train_loss = 1.45232098, grad/param norm = 1.9987e-01, time/batch = 0.9120s	
2742/26050 (epoch 5.263), train_loss = 1.52130403, grad/param norm = 1.9923e-01, time/batch = 1.2405s	
2743/26050 (epoch 5.265), train_loss = 1.72349396, grad/param norm = 1.8865e-01, time/batch = 0.6842s	
2744/26050 (epoch 5.267), train_loss = 1.56873858, grad/param norm = 2.0927e-01, time/batch = 0.6486s	
2745/26050 (epoch 5.269), train_loss = 1.74007829, grad/param norm = 2.2955e-01, time/batch = 0.6436s	
2746/26050 (epoch 5.271), train_loss = 1.51381115, grad/param norm = 1.8625e-01, time/batch = 0.6403s	
2747/26050 (epoch 5.273), train_loss = 1.50649009, grad/param norm = 2.0592e-01, time/batch = 0.6427s	
2748/26050 (epoch 5.274), train_loss = 1.45090968, grad/param norm = 1.9162e-01, time/batch = 0.6388s	
2749/26050 (epoch 5.276), train_loss = 1.41765775, grad/param norm = 1.8545e-01, time/batch = 0.6395s	
2750/26050 (epoch 5.278), train_loss = 1.61550240, grad/param norm = 2.0417e-01, time/batch = 0.6414s	
2751/26050 (epoch 5.280), train_loss = 1.50949198, grad/param norm = 1.8857e-01, time/batch = 0.6859s	
2752/26050 (epoch 5.282), train_loss = 1.55643554, grad/param norm = 2.0175e-01, time/batch = 0.6723s	
2753/26050 (epoch 5.284), train_loss = 1.37017731, grad/param norm = 2.0484e-01, time/batch = 0.6468s	
2754/26050 (epoch 5.286), train_loss = 1.49276519, grad/param norm = 2.1925e-01, time/batch = 0.6471s	
2755/26050 (epoch 5.288), train_loss = 1.36651064, grad/param norm = 1.9165e-01, time/batch = 0.6459s	
2756/26050 (epoch 5.290), train_loss = 1.45430875, grad/param norm = 1.9762e-01, time/batch = 0.6423s	
2757/26050 (epoch 5.292), train_loss = 1.42229593, grad/param norm = 1.8431e-01, time/batch = 0.6412s	
2758/26050 (epoch 5.294), train_loss = 1.55779517, grad/param norm = 2.3114e-01, time/batch = 0.6460s	
2759/26050 (epoch 5.296), train_loss = 1.61857913, grad/param norm = 1.9571e-01, time/batch = 0.6397s	
2760/26050 (epoch 5.298), train_loss = 1.47934684, grad/param norm = 1.8445e-01, time/batch = 0.6406s	
2761/26050 (epoch 5.299), train_loss = 1.24948257, grad/param norm = 1.7011e-01, time/batch = 0.6443s	
2762/26050 (epoch 5.301), train_loss = 1.42484948, grad/param norm = 1.9486e-01, time/batch = 0.6423s	
2763/26050 (epoch 5.303), train_loss = 1.54638751, grad/param norm = 2.0971e-01, time/batch = 0.6407s	
2764/26050 (epoch 5.305), train_loss = 1.40127907, grad/param norm = 1.9434e-01, time/batch = 0.6491s	
2765/26050 (epoch 5.307), train_loss = 1.35291599, grad/param norm = 1.9690e-01, time/batch = 0.6440s	
2766/26050 (epoch 5.309), train_loss = 1.44197361, grad/param norm = 2.0697e-01, time/batch = 0.6653s	
2767/26050 (epoch 5.311), train_loss = 1.73761339, grad/param norm = 2.2029e-01, time/batch = 0.6788s	
2768/26050 (epoch 5.313), train_loss = 1.55659232, grad/param norm = 2.2225e-01, time/batch = 0.6386s	
2769/26050 (epoch 5.315), train_loss = 1.68960250, grad/param norm = 2.2654e-01, time/batch = 0.6399s	
2770/26050 (epoch 5.317), train_loss = 1.40766552, grad/param norm = 1.8928e-01, time/batch = 0.6451s	
2771/26050 (epoch 5.319), train_loss = 1.46563425, grad/param norm = 1.8176e-01, time/batch = 0.6413s	
2772/26050 (epoch 5.321), train_loss = 1.51229194, grad/param norm = 1.8286e-01, time/batch = 0.6398s	
2773/26050 (epoch 5.322), train_loss = 1.52390189, grad/param norm = 1.8680e-01, time/batch = 0.6402s	
2774/26050 (epoch 5.324), train_loss = 1.33051880, grad/param norm = 1.7877e-01, time/batch = 0.6397s	
2775/26050 (epoch 5.326), train_loss = 1.66337241, grad/param norm = 2.1802e-01, time/batch = 0.6388s	
2776/26050 (epoch 5.328), train_loss = 1.54369906, grad/param norm = 1.9098e-01, time/batch = 0.6393s	
2777/26050 (epoch 5.330), train_loss = 1.42818975, grad/param norm = 2.0711e-01, time/batch = 0.6400s	
2778/26050 (epoch 5.332), train_loss = 1.60034769, grad/param norm = 2.0121e-01, time/batch = 0.6394s	
2779/26050 (epoch 5.334), train_loss = 1.47834358, grad/param norm = 2.1139e-01, time/batch = 0.6376s	
2780/26050 (epoch 5.336), train_loss = 1.34517087, grad/param norm = 1.7039e-01, time/batch = 0.6381s	
2781/26050 (epoch 5.338), train_loss = 1.31771963, grad/param norm = 1.8196e-01, time/batch = 0.6463s	
2782/26050 (epoch 5.340), train_loss = 1.61514352, grad/param norm = 2.1404e-01, time/batch = 0.6830s	
2783/26050 (epoch 5.342), train_loss = 1.64486705, grad/param norm = 2.0235e-01, time/batch = 0.6554s	
2784/26050 (epoch 5.344), train_loss = 1.49220854, grad/param norm = 2.0426e-01, time/batch = 0.6385s	
2785/26050 (epoch 5.345), train_loss = 1.51356694, grad/param norm = 2.2239e-01, time/batch = 0.6417s	
2786/26050 (epoch 5.347), train_loss = 1.58822009, grad/param norm = 2.2027e-01, time/batch = 0.6438s	
2787/26050 (epoch 5.349), train_loss = 1.51665541, grad/param norm = 2.0201e-01, time/batch = 0.6382s	
2788/26050 (epoch 5.351), train_loss = 1.55110471, grad/param norm = 2.0862e-01, time/batch = 0.6373s	
2789/26050 (epoch 5.353), train_loss = 1.42321057, grad/param norm = 2.1408e-01, time/batch = 0.6414s	
2790/26050 (epoch 5.355), train_loss = 1.60357592, grad/param norm = 2.1126e-01, time/batch = 0.6424s	
2791/26050 (epoch 5.357), train_loss = 1.34189915, grad/param norm = 1.7337e-01, time/batch = 0.6406s	
2792/26050 (epoch 5.359), train_loss = 1.57747272, grad/param norm = 1.9122e-01, time/batch = 0.6425s	
2793/26050 (epoch 5.361), train_loss = 1.35263985, grad/param norm = 1.8649e-01, time/batch = 0.6391s	
2794/26050 (epoch 5.363), train_loss = 1.48174005, grad/param norm = 1.9025e-01, time/batch = 0.6398s	
2795/26050 (epoch 5.365), train_loss = 1.38081873, grad/param norm = 1.8062e-01, time/batch = 0.6391s	
2796/26050 (epoch 5.367), train_loss = 1.50243000, grad/param norm = 1.9977e-01, time/batch = 0.6381s	
2797/26050 (epoch 5.369), train_loss = 1.47519070, grad/param norm = 1.8491e-01, time/batch = 0.6686s	
2798/26050 (epoch 5.370), train_loss = 1.38846574, grad/param norm = 1.9044e-01, time/batch = 0.6735s	
2799/26050 (epoch 5.372), train_loss = 1.67309037, grad/param norm = 2.1854e-01, time/batch = 0.6380s	
2800/26050 (epoch 5.374), train_loss = 1.71472093, grad/param norm = 2.1812e-01, time/batch = 0.6426s	
2801/26050 (epoch 5.376), train_loss = 1.74619026, grad/param norm = 1.9100e-01, time/batch = 0.6467s	
2802/26050 (epoch 5.378), train_loss = 1.49197447, grad/param norm = 2.0078e-01, time/batch = 0.6426s	
2803/26050 (epoch 5.380), train_loss = 1.70534898, grad/param norm = 2.0935e-01, time/batch = 0.6426s	
2804/26050 (epoch 5.382), train_loss = 1.90077296, grad/param norm = 2.2348e-01, time/batch = 0.6440s	
2805/26050 (epoch 5.384), train_loss = 1.46367839, grad/param norm = 1.9630e-01, time/batch = 0.6427s	
2806/26050 (epoch 5.386), train_loss = 1.60135632, grad/param norm = 1.9490e-01, time/batch = 0.6421s	
2807/26050 (epoch 5.388), train_loss = 1.55852792, grad/param norm = 1.8535e-01, time/batch = 0.6427s	
2808/26050 (epoch 5.390), train_loss = 1.37707011, grad/param norm = 1.7341e-01, time/batch = 0.6431s	
2809/26050 (epoch 5.392), train_loss = 1.40575308, grad/param norm = 1.9298e-01, time/batch = 0.6465s	
2810/26050 (epoch 5.393), train_loss = 1.56838173, grad/param norm = 1.9263e-01, time/batch = 0.6525s	
2811/26050 (epoch 5.395), train_loss = 1.57687144, grad/param norm = 2.0451e-01, time/batch = 0.6510s	
2812/26050 (epoch 5.397), train_loss = 1.57186114, grad/param norm = 1.9640e-01, time/batch = 0.6668s	
2813/26050 (epoch 5.399), train_loss = 1.37663370, grad/param norm = 1.7769e-01, time/batch = 0.6838s	
2814/26050 (epoch 5.401), train_loss = 1.45042813, grad/param norm = 1.9116e-01, time/batch = 0.6614s	
2815/26050 (epoch 5.403), train_loss = 1.50988493, grad/param norm = 2.0196e-01, time/batch = 0.6531s	
2816/26050 (epoch 5.405), train_loss = 1.51608501, grad/param norm = 2.0769e-01, time/batch = 0.6558s	
2817/26050 (epoch 5.407), train_loss = 1.67214215, grad/param norm = 2.0213e-01, time/batch = 0.6507s	
2818/26050 (epoch 5.409), train_loss = 1.69867995, grad/param norm = 2.1138e-01, time/batch = 0.6513s	
2819/26050 (epoch 5.411), train_loss = 1.53591980, grad/param norm = 1.9984e-01, time/batch = 0.6518s	
2820/26050 (epoch 5.413), train_loss = 1.65825644, grad/param norm = 1.9071e-01, time/batch = 0.6553s	
2821/26050 (epoch 5.415), train_loss = 1.66174239, grad/param norm = 2.1153e-01, time/batch = 0.6523s	
2822/26050 (epoch 5.417), train_loss = 1.70133737, grad/param norm = 2.0908e-01, time/batch = 0.6557s	
2823/26050 (epoch 5.418), train_loss = 1.59572708, grad/param norm = 1.9937e-01, time/batch = 0.6493s	
2824/26050 (epoch 5.420), train_loss = 1.27675629, grad/param norm = 1.7268e-01, time/batch = 0.6495s	
2825/26050 (epoch 5.422), train_loss = 1.37352481, grad/param norm = 2.0577e-01, time/batch = 0.6564s	
2826/26050 (epoch 5.424), train_loss = 1.79503878, grad/param norm = 2.3821e-01, time/batch = 0.6474s	
2827/26050 (epoch 5.426), train_loss = 1.73334756, grad/param norm = 2.4396e-01, time/batch = 0.6462s	
2828/26050 (epoch 5.428), train_loss = 1.41470168, grad/param norm = 1.7805e-01, time/batch = 0.6830s	
2829/26050 (epoch 5.430), train_loss = 1.54745913, grad/param norm = 2.0609e-01, time/batch = 0.6539s	
2830/26050 (epoch 5.432), train_loss = 1.49840211, grad/param norm = 2.0011e-01, time/batch = 0.6502s	
2831/26050 (epoch 5.434), train_loss = 1.56377041, grad/param norm = 1.8555e-01, time/batch = 0.6524s	
2832/26050 (epoch 5.436), train_loss = 1.68420778, grad/param norm = 1.9548e-01, time/batch = 0.6495s	
2833/26050 (epoch 5.438), train_loss = 1.41560773, grad/param norm = 1.8625e-01, time/batch = 0.6557s	
2834/26050 (epoch 5.440), train_loss = 1.53771516, grad/param norm = 2.0076e-01, time/batch = 0.6445s	
2835/26050 (epoch 5.441), train_loss = 1.50480869, grad/param norm = 2.0599e-01, time/batch = 0.6523s	
2836/26050 (epoch 5.443), train_loss = 1.31338248, grad/param norm = 1.6938e-01, time/batch = 0.6466s	
2837/26050 (epoch 5.445), train_loss = 1.38121464, grad/param norm = 1.9342e-01, time/batch = 0.6408s	
2838/26050 (epoch 5.447), train_loss = 1.75946919, grad/param norm = 2.0377e-01, time/batch = 0.6444s	
2839/26050 (epoch 5.449), train_loss = 1.40544256, grad/param norm = 1.9416e-01, time/batch = 0.6410s	
2840/26050 (epoch 5.451), train_loss = 1.56250419, grad/param norm = 1.7928e-01, time/batch = 0.6394s	
2841/26050 (epoch 5.453), train_loss = 1.35754325, grad/param norm = 1.7304e-01, time/batch = 0.6412s	
2842/26050 (epoch 5.455), train_loss = 1.53067618, grad/param norm = 1.9664e-01, time/batch = 0.6423s	
2843/26050 (epoch 5.457), train_loss = 1.58016291, grad/param norm = 2.1869e-01, time/batch = 0.6796s	
2844/26050 (epoch 5.459), train_loss = 1.65236816, grad/param norm = 2.1454e-01, time/batch = 0.6702s	
2845/26050 (epoch 5.461), train_loss = 1.59590534, grad/param norm = 2.0454e-01, time/batch = 0.6410s	
2846/26050 (epoch 5.463), train_loss = 1.43825150, grad/param norm = 1.8031e-01, time/batch = 0.6454s	
2847/26050 (epoch 5.464), train_loss = 1.60529632, grad/param norm = 2.1320e-01, time/batch = 0.6447s	
2848/26050 (epoch 5.466), train_loss = 1.62540049, grad/param norm = 1.8874e-01, time/batch = 0.6409s	
2849/26050 (epoch 5.468), train_loss = 1.62150190, grad/param norm = 1.8976e-01, time/batch = 0.6398s	
2850/26050 (epoch 5.470), train_loss = 1.75862951, grad/param norm = 2.1902e-01, time/batch = 0.6446s	
2851/26050 (epoch 5.472), train_loss = 1.79486677, grad/param norm = 2.1253e-01, time/batch = 0.6426s	
2852/26050 (epoch 5.474), train_loss = 1.82346192, grad/param norm = 2.0112e-01, time/batch = 0.6436s	
2853/26050 (epoch 5.476), train_loss = 1.62729213, grad/param norm = 1.8421e-01, time/batch = 0.6429s	
2854/26050 (epoch 5.478), train_loss = 1.43617319, grad/param norm = 1.8074e-01, time/batch = 0.6407s	
2855/26050 (epoch 5.480), train_loss = 1.55092862, grad/param norm = 1.8303e-01, time/batch = 0.6400s	
2856/26050 (epoch 5.482), train_loss = 1.49710460, grad/param norm = 1.9703e-01, time/batch = 0.6389s	
2857/26050 (epoch 5.484), train_loss = 1.37431342, grad/param norm = 1.9604e-01, time/batch = 0.6398s	
2858/26050 (epoch 5.486), train_loss = 1.70671457, grad/param norm = 2.1572e-01, time/batch = 0.6563s	
2859/26050 (epoch 5.488), train_loss = 1.90605824, grad/param norm = 2.1491e-01, time/batch = 0.6670s	
2860/26050 (epoch 5.489), train_loss = 1.78281816, grad/param norm = 2.0821e-01, time/batch = 0.6503s	
2861/26050 (epoch 5.491), train_loss = 1.46116443, grad/param norm = 1.9884e-01, time/batch = 0.6428s	
2862/26050 (epoch 5.493), train_loss = 1.44459763, grad/param norm = 1.8528e-01, time/batch = 0.6437s	
2863/26050 (epoch 5.495), train_loss = 1.52867717, grad/param norm = 2.1263e-01, time/batch = 0.6451s	
2864/26050 (epoch 5.497), train_loss = 1.45637733, grad/param norm = 1.9524e-01, time/batch = 0.6566s	
2865/26050 (epoch 5.499), train_loss = 1.47104509, grad/param norm = 2.1290e-01, time/batch = 0.6515s	
2866/26050 (epoch 5.501), train_loss = 1.50901293, grad/param norm = 2.0198e-01, time/batch = 0.6684s	
2867/26050 (epoch 5.503), train_loss = 1.45728292, grad/param norm = 1.9553e-01, time/batch = 0.6763s	
2868/26050 (epoch 5.505), train_loss = 1.64048144, grad/param norm = 1.9618e-01, time/batch = 0.6760s	
2869/26050 (epoch 5.507), train_loss = 1.65475853, grad/param norm = 2.1273e-01, time/batch = 0.6716s	
2870/26050 (epoch 5.509), train_loss = 1.78678595, grad/param norm = 2.1607e-01, time/batch = 0.6652s	
2871/26050 (epoch 5.511), train_loss = 1.43502090, grad/param norm = 1.9653e-01, time/batch = 0.6495s	
2872/26050 (epoch 5.512), train_loss = 1.59967913, grad/param norm = 2.1887e-01, time/batch = 0.6429s	
2873/26050 (epoch 5.514), train_loss = 1.61081611, grad/param norm = 1.9221e-01, time/batch = 0.6471s	
2874/26050 (epoch 5.516), train_loss = 1.64862557, grad/param norm = 2.0566e-01, time/batch = 0.6643s	
2875/26050 (epoch 5.518), train_loss = 1.60999673, grad/param norm = 2.1502e-01, time/batch = 0.6458s	
2876/26050 (epoch 5.520), train_loss = 1.56021327, grad/param norm = 2.0155e-01, time/batch = 0.6432s	
2877/26050 (epoch 5.522), train_loss = 1.43536466, grad/param norm = 1.9225e-01, time/batch = 0.6445s	
2878/26050 (epoch 5.524), train_loss = 1.79748146, grad/param norm = 2.1634e-01, time/batch = 0.6472s	
2879/26050 (epoch 5.526), train_loss = 1.61513027, grad/param norm = 2.0442e-01, time/batch = 0.6400s	
2880/26050 (epoch 5.528), train_loss = 1.61839788, grad/param norm = 2.0782e-01, time/batch = 0.6405s	
2881/26050 (epoch 5.530), train_loss = 1.52535615, grad/param norm = 1.9546e-01, time/batch = 0.6443s	
2882/26050 (epoch 5.532), train_loss = 1.56564691, grad/param norm = 1.9131e-01, time/batch = 0.6482s	
2883/26050 (epoch 5.534), train_loss = 1.63812739, grad/param norm = 2.0277e-01, time/batch = 0.6390s	
2884/26050 (epoch 5.536), train_loss = 1.46693500, grad/param norm = 2.0464e-01, time/batch = 0.6421s	
2885/26050 (epoch 5.537), train_loss = 1.65945386, grad/param norm = 1.8847e-01, time/batch = 0.6393s	
2886/26050 (epoch 5.539), train_loss = 1.50841630, grad/param norm = 1.9019e-01, time/batch = 0.6392s	
2887/26050 (epoch 5.541), train_loss = 1.73590889, grad/param norm = 2.2864e-01, time/batch = 0.6568s	
2888/26050 (epoch 5.543), train_loss = 1.35369754, grad/param norm = 1.9471e-01, time/batch = 0.6662s	
2889/26050 (epoch 5.545), train_loss = 1.60827641, grad/param norm = 2.1011e-01, time/batch = 0.6822s	
2890/26050 (epoch 5.547), train_loss = 1.57838290, grad/param norm = 2.0632e-01, time/batch = 0.6724s	
2891/26050 (epoch 5.549), train_loss = 1.39495198, grad/param norm = 1.9337e-01, time/batch = 0.6613s	
2892/26050 (epoch 5.551), train_loss = 1.60123686, grad/param norm = 2.2120e-01, time/batch = 0.6571s	
2893/26050 (epoch 5.553), train_loss = 1.47542168, grad/param norm = 2.0366e-01, time/batch = 0.6416s	
2894/26050 (epoch 5.555), train_loss = 1.48072030, grad/param norm = 1.9480e-01, time/batch = 0.6508s	
2895/26050 (epoch 5.557), train_loss = 1.63244569, grad/param norm = 1.9737e-01, time/batch = 0.6571s	
2896/26050 (epoch 5.559), train_loss = 1.56215216, grad/param norm = 2.1048e-01, time/batch = 0.6581s	
2897/26050 (epoch 5.560), train_loss = 1.54480826, grad/param norm = 2.0377e-01, time/batch = 0.6559s	
2898/26050 (epoch 5.562), train_loss = 1.52809990, grad/param norm = 2.0396e-01, time/batch = 0.6576s	
2899/26050 (epoch 5.564), train_loss = 1.74149909, grad/param norm = 2.2974e-01, time/batch = 0.6530s	
2900/26050 (epoch 5.566), train_loss = 1.43089500, grad/param norm = 1.9585e-01, time/batch = 0.6400s	
2901/26050 (epoch 5.568), train_loss = 1.57673113, grad/param norm = 1.9006e-01, time/batch = 0.6432s	
2902/26050 (epoch 5.570), train_loss = 1.67011930, grad/param norm = 2.0830e-01, time/batch = 0.6399s	
2903/26050 (epoch 5.572), train_loss = 1.58314991, grad/param norm = 1.9425e-01, time/batch = 0.6394s	
2904/26050 (epoch 5.574), train_loss = 1.67808680, grad/param norm = 2.3846e-01, time/batch = 0.6471s	
2905/26050 (epoch 5.576), train_loss = 1.64995246, grad/param norm = 2.0897e-01, time/batch = 0.6517s	
2906/26050 (epoch 5.578), train_loss = 1.56488622, grad/param norm = 2.0921e-01, time/batch = 0.6615s	
2907/26050 (epoch 5.580), train_loss = 1.42327312, grad/param norm = 1.8386e-01, time/batch = 0.6482s	
2908/26050 (epoch 5.582), train_loss = 1.61026933, grad/param norm = 1.9613e-01, time/batch = 0.6462s	
2909/26050 (epoch 5.583), train_loss = 1.61596079, grad/param norm = 1.9709e-01, time/batch = 0.6425s	
2910/26050 (epoch 5.585), train_loss = 1.42079139, grad/param norm = 1.9170e-01, time/batch = 0.6401s	
2911/26050 (epoch 5.587), train_loss = 1.61918147, grad/param norm = 1.9483e-01, time/batch = 0.6401s	
2912/26050 (epoch 5.589), train_loss = 1.63121079, grad/param norm = 2.2304e-01, time/batch = 0.6408s	
2913/26050 (epoch 5.591), train_loss = 1.60838596, grad/param norm = 1.9273e-01, time/batch = 0.6402s	
2914/26050 (epoch 5.593), train_loss = 1.44075467, grad/param norm = 2.1141e-01, time/batch = 0.6414s	
2915/26050 (epoch 5.595), train_loss = 1.72412994, grad/param norm = 2.4526e-01, time/batch = 0.6425s	
2916/26050 (epoch 5.597), train_loss = 1.58647904, grad/param norm = 2.1313e-01, time/batch = 0.6408s	
2917/26050 (epoch 5.599), train_loss = 1.40250049, grad/param norm = 1.7683e-01, time/batch = 0.6392s	
2918/26050 (epoch 5.601), train_loss = 1.75222550, grad/param norm = 2.0308e-01, time/batch = 0.6398s	
2919/26050 (epoch 5.603), train_loss = 1.63011790, grad/param norm = 2.0014e-01, time/batch = 0.6392s	
2920/26050 (epoch 5.605), train_loss = 1.46583407, grad/param norm = 1.7384e-01, time/batch = 0.6385s	
2921/26050 (epoch 5.607), train_loss = 1.65711063, grad/param norm = 2.0197e-01, time/batch = 0.6408s	
2922/26050 (epoch 5.608), train_loss = 1.49274197, grad/param norm = 1.8297e-01, time/batch = 0.6556s	
2923/26050 (epoch 5.610), train_loss = 1.53620945, grad/param norm = 2.1470e-01, time/batch = 0.6555s	
2924/26050 (epoch 5.612), train_loss = 1.49205339, grad/param norm = 2.0616e-01, time/batch = 0.6537s	
2925/26050 (epoch 5.614), train_loss = 1.58420182, grad/param norm = 1.9957e-01, time/batch = 0.6430s	
2926/26050 (epoch 5.616), train_loss = 1.84290876, grad/param norm = 2.0563e-01, time/batch = 0.6421s	
2927/26050 (epoch 5.618), train_loss = 1.47057859, grad/param norm = 2.0069e-01, time/batch = 0.6394s	
2928/26050 (epoch 5.620), train_loss = 1.58300185, grad/param norm = 2.2365e-01, time/batch = 0.6422s	
2929/26050 (epoch 5.622), train_loss = 1.28649338, grad/param norm = 1.7655e-01, time/batch = 0.6401s	
2930/26050 (epoch 5.624), train_loss = 1.41570997, grad/param norm = 1.7942e-01, time/batch = 0.6604s	
2931/26050 (epoch 5.626), train_loss = 1.55070140, grad/param norm = 2.0625e-01, time/batch = 0.6840s	
2932/26050 (epoch 5.628), train_loss = 1.55972340, grad/param norm = 2.1518e-01, time/batch = 0.6632s	
2933/26050 (epoch 5.630), train_loss = 1.67020748, grad/param norm = 1.9628e-01, time/batch = 0.6441s	
2934/26050 (epoch 5.631), train_loss = 1.66101343, grad/param norm = 2.0862e-01, time/batch = 0.6403s	
2935/26050 (epoch 5.633), train_loss = 1.39774643, grad/param norm = 1.7650e-01, time/batch = 0.6416s	
2936/26050 (epoch 5.635), train_loss = 1.40798180, grad/param norm = 1.8361e-01, time/batch = 0.6400s	
2937/26050 (epoch 5.637), train_loss = 1.42990300, grad/param norm = 1.8847e-01, time/batch = 0.6415s	
2938/26050 (epoch 5.639), train_loss = 1.64225182, grad/param norm = 2.0320e-01, time/batch = 0.6421s	
2939/26050 (epoch 5.641), train_loss = 1.45302629, grad/param norm = 1.7010e-01, time/batch = 0.6446s	
2940/26050 (epoch 5.643), train_loss = 1.42979139, grad/param norm = 1.8051e-01, time/batch = 0.6399s	
2941/26050 (epoch 5.645), train_loss = 1.60212828, grad/param norm = 2.0435e-01, time/batch = 0.6425s	
2942/26050 (epoch 5.647), train_loss = 1.46378236, grad/param norm = 1.9065e-01, time/batch = 0.6485s	
2943/26050 (epoch 5.649), train_loss = 1.58000441, grad/param norm = 2.0843e-01, time/batch = 0.6412s	
2944/26050 (epoch 5.651), train_loss = 1.50426825, grad/param norm = 1.9256e-01, time/batch = 0.6436s	
2945/26050 (epoch 5.653), train_loss = 1.50234137, grad/param norm = 1.9888e-01, time/batch = 0.6423s	
2946/26050 (epoch 5.655), train_loss = 1.43354942, grad/param norm = 1.9856e-01, time/batch = 0.6414s	
2947/26050 (epoch 5.656), train_loss = 1.42087042, grad/param norm = 1.8828e-01, time/batch = 0.6482s	
2948/26050 (epoch 5.658), train_loss = 1.71495323, grad/param norm = 2.1360e-01, time/batch = 0.6455s	
2949/26050 (epoch 5.660), train_loss = 1.42403529, grad/param norm = 2.1770e-01, time/batch = 0.6424s	
2950/26050 (epoch 5.662), train_loss = 1.38169941, grad/param norm = 1.8906e-01, time/batch = 0.6386s	
2951/26050 (epoch 5.664), train_loss = 1.50057666, grad/param norm = 2.1057e-01, time/batch = 0.6387s	
2952/26050 (epoch 5.666), train_loss = 1.57042052, grad/param norm = 2.1660e-01, time/batch = 0.6442s	
2953/26050 (epoch 5.668), train_loss = 1.27883166, grad/param norm = 1.7017e-01, time/batch = 0.6437s	
2954/26050 (epoch 5.670), train_loss = 1.71165668, grad/param norm = 2.2523e-01, time/batch = 0.6389s	
2955/26050 (epoch 5.672), train_loss = 1.42357450, grad/param norm = 1.8778e-01, time/batch = 0.6418s	
2956/26050 (epoch 5.674), train_loss = 1.39634968, grad/param norm = 1.8046e-01, time/batch = 0.6380s	
2957/26050 (epoch 5.676), train_loss = 1.54619203, grad/param norm = 1.9985e-01, time/batch = 0.6375s	
2958/26050 (epoch 5.678), train_loss = 1.70899153, grad/param norm = 2.0747e-01, time/batch = 0.6383s	
2959/26050 (epoch 5.679), train_loss = 1.67776398, grad/param norm = 2.1779e-01, time/batch = 0.6404s	
2960/26050 (epoch 5.681), train_loss = 1.54506730, grad/param norm = 2.1221e-01, time/batch = 0.6397s	
2961/26050 (epoch 5.683), train_loss = 1.46648508, grad/param norm = 2.0160e-01, time/batch = 0.6452s	
2962/26050 (epoch 5.685), train_loss = 1.46382763, grad/param norm = 1.8500e-01, time/batch = 0.6416s	
2963/26050 (epoch 5.687), train_loss = 1.31043713, grad/param norm = 1.7618e-01, time/batch = 0.6393s	
2964/26050 (epoch 5.689), train_loss = 1.51625781, grad/param norm = 1.9481e-01, time/batch = 0.6396s	
2965/26050 (epoch 5.691), train_loss = 1.24036294, grad/param norm = 1.8543e-01, time/batch = 0.6383s	
2966/26050 (epoch 5.693), train_loss = 1.42956015, grad/param norm = 2.0150e-01, time/batch = 0.6756s	
2967/26050 (epoch 5.695), train_loss = 1.55925567, grad/param norm = 1.9940e-01, time/batch = 0.6673s	
2968/26050 (epoch 5.697), train_loss = 1.37466453, grad/param norm = 1.9887e-01, time/batch = 0.6390s	
2969/26050 (epoch 5.699), train_loss = 1.57981313, grad/param norm = 2.0676e-01, time/batch = 0.6509s	
2970/26050 (epoch 5.701), train_loss = 1.34181456, grad/param norm = 1.8143e-01, time/batch = 0.6420s	
2971/26050 (epoch 5.702), train_loss = 1.77101105, grad/param norm = 1.9281e-01, time/batch = 0.6402s	
2972/26050 (epoch 5.704), train_loss = 1.51519221, grad/param norm = 1.9204e-01, time/batch = 0.6428s	
2973/26050 (epoch 5.706), train_loss = 1.62982700, grad/param norm = 2.1896e-01, time/batch = 0.6410s	
2974/26050 (epoch 5.708), train_loss = 1.60006531, grad/param norm = 1.9523e-01, time/batch = 0.6414s	
2975/26050 (epoch 5.710), train_loss = 1.61681546, grad/param norm = 2.0392e-01, time/batch = 0.6409s	
2976/26050 (epoch 5.712), train_loss = 1.71718982, grad/param norm = 2.1140e-01, time/batch = 0.6474s	
2977/26050 (epoch 5.714), train_loss = 1.41508751, grad/param norm = 2.0914e-01, time/batch = 0.6584s	
2978/26050 (epoch 5.716), train_loss = 1.77050359, grad/param norm = 2.4074e-01, time/batch = 0.6451s	
2979/26050 (epoch 5.718), train_loss = 1.63395446, grad/param norm = 2.2271e-01, time/batch = 0.6395s	
2980/26050 (epoch 5.720), train_loss = 1.44812767, grad/param norm = 1.9871e-01, time/batch = 0.6403s	
2981/26050 (epoch 5.722), train_loss = 1.40210310, grad/param norm = 2.0214e-01, time/batch = 0.6617s	
2982/26050 (epoch 5.724), train_loss = 1.38094543, grad/param norm = 1.9079e-01, time/batch = 0.6645s	
2983/26050 (epoch 5.726), train_loss = 1.62703345, grad/param norm = 1.9674e-01, time/batch = 0.6419s	
2984/26050 (epoch 5.727), train_loss = 1.59277946, grad/param norm = 1.9865e-01, time/batch = 0.6418s	
2985/26050 (epoch 5.729), train_loss = 1.62383925, grad/param norm = 2.2312e-01, time/batch = 0.6468s	
2986/26050 (epoch 5.731), train_loss = 1.50287604, grad/param norm = 1.8220e-01, time/batch = 0.6417s	
2987/26050 (epoch 5.733), train_loss = 1.55209362, grad/param norm = 2.3272e-01, time/batch = 0.6499s	
2988/26050 (epoch 5.735), train_loss = 1.73883455, grad/param norm = 2.1051e-01, time/batch = 0.6464s	
2989/26050 (epoch 5.737), train_loss = 1.57025540, grad/param norm = 2.0324e-01, time/batch = 0.6494s	
2990/26050 (epoch 5.739), train_loss = 1.56884471, grad/param norm = 1.9346e-01, time/batch = 0.6569s	
2991/26050 (epoch 5.741), train_loss = 1.41878563, grad/param norm = 1.8111e-01, time/batch = 0.6477s	
2992/26050 (epoch 5.743), train_loss = 1.64461262, grad/param norm = 2.2683e-01, time/batch = 0.6422s	
2993/26050 (epoch 5.745), train_loss = 1.39528608, grad/param norm = 1.9659e-01, time/batch = 0.6399s	
2994/26050 (epoch 5.747), train_loss = 1.45203964, grad/param norm = 1.9734e-01, time/batch = 0.6388s	
2995/26050 (epoch 5.749), train_loss = 1.60401265, grad/param norm = 2.1108e-01, time/batch = 0.6406s	
2996/26050 (epoch 5.750), train_loss = 1.47857264, grad/param norm = 1.8312e-01, time/batch = 0.6444s	
2997/26050 (epoch 5.752), train_loss = 1.60096229, grad/param norm = 2.1810e-01, time/batch = 0.6826s	
2998/26050 (epoch 5.754), train_loss = 1.44806699, grad/param norm = 1.9758e-01, time/batch = 0.6566s	
2999/26050 (epoch 5.756), train_loss = 1.62779090, grad/param norm = 2.3275e-01, time/batch = 0.6442s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch5.76_1.6913.t7	
3000/26050 (epoch 5.758), train_loss = 1.56593005, grad/param norm = 2.1170e-01, time/batch = 0.6411s	
3001/26050 (epoch 5.760), train_loss = 1.71657079, grad/param norm = 2.1707e-01, time/batch = 0.6478s	
3002/26050 (epoch 5.762), train_loss = 1.45526302, grad/param norm = 1.9644e-01, time/batch = 0.6398s	
3003/26050 (epoch 5.764), train_loss = 1.64192462, grad/param norm = 2.0619e-01, time/batch = 0.6404s	
3004/26050 (epoch 5.766), train_loss = 1.63161855, grad/param norm = 2.1349e-01, time/batch = 0.6517s	
3005/26050 (epoch 5.768), train_loss = 1.45256317, grad/param norm = 1.7592e-01, time/batch = 0.6837s	
3006/26050 (epoch 5.770), train_loss = 1.53490738, grad/param norm = 2.0147e-01, time/batch = 0.6590s	
3007/26050 (epoch 5.772), train_loss = 1.53526662, grad/param norm = 2.0194e-01, time/batch = 0.6620s	
3008/26050 (epoch 5.774), train_loss = 1.44464789, grad/param norm = 1.8892e-01, time/batch = 0.6573s	
3009/26050 (epoch 5.775), train_loss = 1.26241356, grad/param norm = 1.9799e-01, time/batch = 0.6576s	
3010/26050 (epoch 5.777), train_loss = 1.44432022, grad/param norm = 1.9518e-01, time/batch = 0.6466s	
3011/26050 (epoch 5.779), train_loss = 1.50609956, grad/param norm = 2.0851e-01, time/batch = 0.6440s	
3012/26050 (epoch 5.781), train_loss = 1.46690429, grad/param norm = 1.8748e-01, time/batch = 0.6383s	
3013/26050 (epoch 5.783), train_loss = 1.44480485, grad/param norm = 1.7144e-01, time/batch = 0.6410s	
3014/26050 (epoch 5.785), train_loss = 1.49842679, grad/param norm = 2.1809e-01, time/batch = 0.6375s	
3015/26050 (epoch 5.787), train_loss = 1.46563608, grad/param norm = 1.8899e-01, time/batch = 0.6451s	
3016/26050 (epoch 5.789), train_loss = 1.53667288, grad/param norm = 2.0936e-01, time/batch = 0.6413s	
3017/26050 (epoch 5.791), train_loss = 1.54346768, grad/param norm = 1.8737e-01, time/batch = 0.6373s	
3018/26050 (epoch 5.793), train_loss = 1.50904711, grad/param norm = 2.0185e-01, time/batch = 0.6427s	
3019/26050 (epoch 5.795), train_loss = 1.38278881, grad/param norm = 1.8416e-01, time/batch = 0.6529s	
3020/26050 (epoch 5.797), train_loss = 1.40699886, grad/param norm = 1.8007e-01, time/batch = 0.6803s	
3021/26050 (epoch 5.798), train_loss = 1.38973921, grad/param norm = 2.0018e-01, time/batch = 0.6629s	
3022/26050 (epoch 5.800), train_loss = 1.37174307, grad/param norm = 1.8975e-01, time/batch = 0.6403s	
3023/26050 (epoch 5.802), train_loss = 1.53391310, grad/param norm = 1.9730e-01, time/batch = 0.6443s	
3024/26050 (epoch 5.804), train_loss = 1.50318116, grad/param norm = 1.9491e-01, time/batch = 0.6511s	
3025/26050 (epoch 5.806), train_loss = 1.70535196, grad/param norm = 2.2169e-01, time/batch = 0.6398s	
3026/26050 (epoch 5.808), train_loss = 1.46842861, grad/param norm = 1.9005e-01, time/batch = 0.6504s	
3027/26050 (epoch 5.810), train_loss = 1.42133651, grad/param norm = 2.1260e-01, time/batch = 0.6527s	
3028/26050 (epoch 5.812), train_loss = 1.38076137, grad/param norm = 1.9104e-01, time/batch = 0.6422s	
3029/26050 (epoch 5.814), train_loss = 1.41707879, grad/param norm = 2.1300e-01, time/batch = 0.6405s	
3030/26050 (epoch 5.816), train_loss = 1.57317463, grad/param norm = 2.0182e-01, time/batch = 0.6411s	
3031/26050 (epoch 5.818), train_loss = 1.69074159, grad/param norm = 2.2979e-01, time/batch = 0.6421s	
3032/26050 (epoch 5.820), train_loss = 1.56322223, grad/param norm = 2.0655e-01, time/batch = 0.6401s	
3033/26050 (epoch 5.821), train_loss = 1.70535422, grad/param norm = 2.1832e-01, time/batch = 0.6399s	
3034/26050 (epoch 5.823), train_loss = 1.74570205, grad/param norm = 2.0924e-01, time/batch = 0.6402s	
3035/26050 (epoch 5.825), train_loss = 1.44376368, grad/param norm = 2.0293e-01, time/batch = 0.6408s	
3036/26050 (epoch 5.827), train_loss = 1.59911826, grad/param norm = 2.2100e-01, time/batch = 0.6397s	
3037/26050 (epoch 5.829), train_loss = 1.60693731, grad/param norm = 1.9318e-01, time/batch = 0.6455s	
3038/26050 (epoch 5.831), train_loss = 1.67235151, grad/param norm = 2.0006e-01, time/batch = 0.6448s	
3039/26050 (epoch 5.833), train_loss = 1.72210158, grad/param norm = 2.0814e-01, time/batch = 0.6463s	
3040/26050 (epoch 5.835), train_loss = 1.79423439, grad/param norm = 2.0950e-01, time/batch = 0.6413s	
3041/26050 (epoch 5.837), train_loss = 1.45711425, grad/param norm = 1.9192e-01, time/batch = 0.6415s	
3042/26050 (epoch 5.839), train_loss = 1.63416232, grad/param norm = 1.8965e-01, time/batch = 0.6410s	
3043/26050 (epoch 5.841), train_loss = 1.62474003, grad/param norm = 1.9216e-01, time/batch = 0.6415s	
3044/26050 (epoch 5.843), train_loss = 1.58995686, grad/param norm = 1.9505e-01, time/batch = 0.6422s	
3045/26050 (epoch 5.845), train_loss = 1.45321105, grad/param norm = 1.9644e-01, time/batch = 0.6412s	
3046/26050 (epoch 5.846), train_loss = 1.65361940, grad/param norm = 2.0089e-01, time/batch = 0.6417s	
3047/26050 (epoch 5.848), train_loss = 1.46803967, grad/param norm = 1.9183e-01, time/batch = 0.6433s	
3048/26050 (epoch 5.850), train_loss = 1.46651378, grad/param norm = 1.8202e-01, time/batch = 0.6439s	
3049/26050 (epoch 5.852), train_loss = 1.51525008, grad/param norm = 2.1721e-01, time/batch = 0.6567s	
3050/26050 (epoch 5.854), train_loss = 1.55525864, grad/param norm = 2.0359e-01, time/batch = 0.6429s	
3051/26050 (epoch 5.856), train_loss = 1.41938109, grad/param norm = 1.8713e-01, time/batch = 0.6834s	
3052/26050 (epoch 5.858), train_loss = 1.38780270, grad/param norm = 1.9997e-01, time/batch = 0.6553s	
3053/26050 (epoch 5.860), train_loss = 1.54420407, grad/param norm = 2.1110e-01, time/batch = 0.6421s	
3054/26050 (epoch 5.862), train_loss = 1.53538998, grad/param norm = 2.0589e-01, time/batch = 0.6648s	
3055/26050 (epoch 5.864), train_loss = 1.45717831, grad/param norm = 1.9633e-01, time/batch = 0.6611s	
3056/26050 (epoch 5.866), train_loss = 1.40228537, grad/param norm = 1.8545e-01, time/batch = 0.6605s	
3057/26050 (epoch 5.868), train_loss = 1.65310932, grad/param norm = 2.1000e-01, time/batch = 0.6581s	
3058/26050 (epoch 5.869), train_loss = 1.36128293, grad/param norm = 1.7625e-01, time/batch = 0.6598s	
3059/26050 (epoch 5.871), train_loss = 1.30493207, grad/param norm = 1.7607e-01, time/batch = 0.6517s	
3060/26050 (epoch 5.873), train_loss = 1.50707986, grad/param norm = 1.9358e-01, time/batch = 0.6497s	
3061/26050 (epoch 5.875), train_loss = 1.50329694, grad/param norm = 2.0483e-01, time/batch = 0.6603s	
3062/26050 (epoch 5.877), train_loss = 1.33206432, grad/param norm = 1.9938e-01, time/batch = 0.6614s	
3063/26050 (epoch 5.879), train_loss = 1.45713683, grad/param norm = 1.7690e-01, time/batch = 0.6568s	
3064/26050 (epoch 5.881), train_loss = 1.72900047, grad/param norm = 2.0955e-01, time/batch = 0.6583s	
3065/26050 (epoch 5.883), train_loss = 1.53928099, grad/param norm = 1.8253e-01, time/batch = 0.6605s	
3066/26050 (epoch 5.885), train_loss = 1.24109328, grad/param norm = 1.7245e-01, time/batch = 0.6783s	
3067/26050 (epoch 5.887), train_loss = 1.55715117, grad/param norm = 1.9884e-01, time/batch = 0.6397s	
3068/26050 (epoch 5.889), train_loss = 1.42488678, grad/param norm = 1.8584e-01, time/batch = 0.6438s	
3069/26050 (epoch 5.891), train_loss = 1.26813453, grad/param norm = 1.8029e-01, time/batch = 0.6419s	
3070/26050 (epoch 5.893), train_loss = 1.22722451, grad/param norm = 1.6198e-01, time/batch = 0.6468s	
3071/26050 (epoch 5.894), train_loss = 1.37209712, grad/param norm = 1.6739e-01, time/batch = 0.6397s	
3072/26050 (epoch 5.896), train_loss = 1.60452180, grad/param norm = 1.9229e-01, time/batch = 0.6385s	
3073/26050 (epoch 5.898), train_loss = 1.43990656, grad/param norm = 1.8831e-01, time/batch = 0.6438s	
3074/26050 (epoch 5.900), train_loss = 1.74942326, grad/param norm = 2.1125e-01, time/batch = 0.6408s	
3075/26050 (epoch 5.902), train_loss = 1.52692893, grad/param norm = 1.9190e-01, time/batch = 0.6601s	
3076/26050 (epoch 5.904), train_loss = 1.46945720, grad/param norm = 1.9246e-01, time/batch = 0.6631s	
3077/26050 (epoch 5.906), train_loss = 1.49848617, grad/param norm = 1.9303e-01, time/batch = 0.6624s	
3078/26050 (epoch 5.908), train_loss = 1.48391580, grad/param norm = 1.9752e-01, time/batch = 0.6457s	
3079/26050 (epoch 5.910), train_loss = 1.43529886, grad/param norm = 1.8038e-01, time/batch = 0.6452s	
3080/26050 (epoch 5.912), train_loss = 1.79340686, grad/param norm = 2.1240e-01, time/batch = 0.6488s	
3081/26050 (epoch 5.914), train_loss = 1.96519795, grad/param norm = 2.1425e-01, time/batch = 0.6718s	
3082/26050 (epoch 5.916), train_loss = 1.70641020, grad/param norm = 2.1653e-01, time/batch = 0.6762s	
3083/26050 (epoch 5.917), train_loss = 1.54567732, grad/param norm = 1.9784e-01, time/batch = 0.6585s	
3084/26050 (epoch 5.919), train_loss = 1.61623406, grad/param norm = 1.9590e-01, time/batch = 0.6483s	
3085/26050 (epoch 5.921), train_loss = 1.40721127, grad/param norm = 2.1019e-01, time/batch = 0.6401s	
3086/26050 (epoch 5.923), train_loss = 1.45538924, grad/param norm = 2.0252e-01, time/batch = 0.6393s	
3087/26050 (epoch 5.925), train_loss = 1.43027662, grad/param norm = 1.8202e-01, time/batch = 0.6387s	
3088/26050 (epoch 5.927), train_loss = 1.38588645, grad/param norm = 1.7103e-01, time/batch = 0.6406s	
3089/26050 (epoch 5.929), train_loss = 1.42269039, grad/param norm = 1.9739e-01, time/batch = 0.6400s	
3090/26050 (epoch 5.931), train_loss = 1.80693528, grad/param norm = 2.4355e-01, time/batch = 0.6397s	
3091/26050 (epoch 5.933), train_loss = 1.48706105, grad/param norm = 2.1160e-01, time/batch = 0.6419s	
3092/26050 (epoch 5.935), train_loss = 1.40441721, grad/param norm = 1.9924e-01, time/batch = 0.6425s	
3093/26050 (epoch 5.937), train_loss = 1.47916538, grad/param norm = 1.8435e-01, time/batch = 0.6395s	
3094/26050 (epoch 5.939), train_loss = 1.36678464, grad/param norm = 1.8739e-01, time/batch = 0.6380s	
3095/26050 (epoch 5.940), train_loss = 1.54937077, grad/param norm = 1.9173e-01, time/batch = 0.6385s	
3096/26050 (epoch 5.942), train_loss = 1.56303714, grad/param norm = 2.1439e-01, time/batch = 0.6501s	
3097/26050 (epoch 5.944), train_loss = 1.45795116, grad/param norm = 2.0432e-01, time/batch = 0.6716s	
3098/26050 (epoch 5.946), train_loss = 1.65576962, grad/param norm = 1.8080e-01, time/batch = 0.6412s	
3099/26050 (epoch 5.948), train_loss = 1.30312007, grad/param norm = 2.2299e-01, time/batch = 0.6527s	
3100/26050 (epoch 5.950), train_loss = 1.45466208, grad/param norm = 1.9201e-01, time/batch = 0.6551s	
3101/26050 (epoch 5.952), train_loss = 1.68685820, grad/param norm = 2.1229e-01, time/batch = 0.6527s	
3102/26050 (epoch 5.954), train_loss = 1.61778172, grad/param norm = 1.9101e-01, time/batch = 0.6630s	
3103/26050 (epoch 5.956), train_loss = 1.62985832, grad/param norm = 2.0978e-01, time/batch = 0.6799s	
3104/26050 (epoch 5.958), train_loss = 1.50754336, grad/param norm = 1.9039e-01, time/batch = 0.6482s	
3105/26050 (epoch 5.960), train_loss = 1.43596076, grad/param norm = 1.8471e-01, time/batch = 0.6438s	
3106/26050 (epoch 5.962), train_loss = 1.41532001, grad/param norm = 1.8512e-01, time/batch = 0.6493s	
3107/26050 (epoch 5.964), train_loss = 1.47429116, grad/param norm = 1.9315e-01, time/batch = 0.6510s	
3108/26050 (epoch 5.965), train_loss = 1.36585766, grad/param norm = 1.8999e-01, time/batch = 0.6472s	
3109/26050 (epoch 5.967), train_loss = 1.84371505, grad/param norm = 2.1312e-01, time/batch = 0.6424s	
3110/26050 (epoch 5.969), train_loss = 1.46109770, grad/param norm = 1.9305e-01, time/batch = 0.6423s	
3111/26050 (epoch 5.971), train_loss = 1.32833600, grad/param norm = 1.7140e-01, time/batch = 0.6427s	
3112/26050 (epoch 5.973), train_loss = 1.47449799, grad/param norm = 2.1821e-01, time/batch = 0.6415s	
3113/26050 (epoch 5.975), train_loss = 1.57541795, grad/param norm = 1.8140e-01, time/batch = 0.6418s	
3114/26050 (epoch 5.977), train_loss = 1.51286749, grad/param norm = 1.6719e-01, time/batch = 0.6448s	
3115/26050 (epoch 5.979), train_loss = 1.34982145, grad/param norm = 1.8291e-01, time/batch = 0.6483s	
3116/26050 (epoch 5.981), train_loss = 1.58135767, grad/param norm = 1.7896e-01, time/batch = 0.6421s	
3117/26050 (epoch 5.983), train_loss = 1.59534332, grad/param norm = 2.0418e-01, time/batch = 0.6415s	
3118/26050 (epoch 5.985), train_loss = 1.54613135, grad/param norm = 1.9659e-01, time/batch = 0.6420s	
3119/26050 (epoch 5.987), train_loss = 1.68508032, grad/param norm = 2.1211e-01, time/batch = 0.6451s	
3120/26050 (epoch 5.988), train_loss = 1.65172390, grad/param norm = 2.1166e-01, time/batch = 0.6420s	
3121/26050 (epoch 5.990), train_loss = 1.46016528, grad/param norm = 2.0676e-01, time/batch = 0.6427s	
3122/26050 (epoch 5.992), train_loss = 1.71198008, grad/param norm = 2.2804e-01, time/batch = 0.6485s	
3123/26050 (epoch 5.994), train_loss = 1.48338177, grad/param norm = 2.0944e-01, time/batch = 0.6427s	
3124/26050 (epoch 5.996), train_loss = 1.53463320, grad/param norm = 2.4470e-01, time/batch = 0.6399s	
3125/26050 (epoch 5.998), train_loss = 1.56859481, grad/param norm = 1.9939e-01, time/batch = 0.6469s	
3126/26050 (epoch 6.000), train_loss = 1.50325822, grad/param norm = 2.0330e-01, time/batch = 0.6523s	
3127/26050 (epoch 6.002), train_loss = 1.53641444, grad/param norm = 1.9087e-01, time/batch = 0.6504s	
3128/26050 (epoch 6.004), train_loss = 1.46031564, grad/param norm = 1.9956e-01, time/batch = 0.6702s	
3129/26050 (epoch 6.006), train_loss = 1.41399336, grad/param norm = 1.7999e-01, time/batch = 0.6530s	
3130/26050 (epoch 6.008), train_loss = 1.42090533, grad/param norm = 1.8638e-01, time/batch = 0.6535s	
3131/26050 (epoch 6.010), train_loss = 1.47192774, grad/param norm = 1.8232e-01, time/batch = 0.6647s	
3132/26050 (epoch 6.012), train_loss = 1.55984221, grad/param norm = 2.0932e-01, time/batch = 0.6834s	
3133/26050 (epoch 6.013), train_loss = 1.96866998, grad/param norm = 2.1508e-01, time/batch = 0.6612s	
3134/26050 (epoch 6.015), train_loss = 1.36969269, grad/param norm = 1.7860e-01, time/batch = 0.6476s	
3135/26050 (epoch 6.017), train_loss = 1.52102200, grad/param norm = 2.0240e-01, time/batch = 0.6440s	
3136/26050 (epoch 6.019), train_loss = 1.32838629, grad/param norm = 1.6085e-01, time/batch = 0.6410s	
3137/26050 (epoch 6.021), train_loss = 1.65815154, grad/param norm = 2.1796e-01, time/batch = 0.6498s	
3138/26050 (epoch 6.023), train_loss = 1.38300638, grad/param norm = 1.9605e-01, time/batch = 0.6414s	
3139/26050 (epoch 6.025), train_loss = 1.43666859, grad/param norm = 1.9194e-01, time/batch = 0.6405s	
3140/26050 (epoch 6.027), train_loss = 1.26255844, grad/param norm = 1.7523e-01, time/batch = 0.6388s	
3141/26050 (epoch 6.029), train_loss = 1.44485625, grad/param norm = 1.8526e-01, time/batch = 0.6406s	
3142/26050 (epoch 6.031), train_loss = 1.69122015, grad/param norm = 2.1872e-01, time/batch = 0.6393s	
3143/26050 (epoch 6.033), train_loss = 1.54639899, grad/param norm = 1.9894e-01, time/batch = 0.6394s	
3144/26050 (epoch 6.035), train_loss = 1.65660962, grad/param norm = 1.9218e-01, time/batch = 0.6396s	
3145/26050 (epoch 6.036), train_loss = 1.47201144, grad/param norm = 2.0801e-01, time/batch = 0.6395s	
3146/26050 (epoch 6.038), train_loss = 1.28931318, grad/param norm = 1.8117e-01, time/batch = 0.6463s	
3147/26050 (epoch 6.040), train_loss = 1.57158340, grad/param norm = 2.0313e-01, time/batch = 0.6685s	
3148/26050 (epoch 6.042), train_loss = 1.35203717, grad/param norm = 1.7584e-01, time/batch = 0.6764s	
3149/26050 (epoch 6.044), train_loss = 1.53427494, grad/param norm = 1.8657e-01, time/batch = 0.6387s	
3150/26050 (epoch 6.046), train_loss = 1.29778365, grad/param norm = 1.9444e-01, time/batch = 0.6412s	
3151/26050 (epoch 6.048), train_loss = 1.52041936, grad/param norm = 1.8881e-01, time/batch = 0.6445s	
3152/26050 (epoch 6.050), train_loss = 1.38681728, grad/param norm = 2.0854e-01, time/batch = 0.6411s	
3153/26050 (epoch 6.052), train_loss = 1.51370457, grad/param norm = 1.9778e-01, time/batch = 0.6430s	
3154/26050 (epoch 6.054), train_loss = 1.34463482, grad/param norm = 1.9932e-01, time/batch = 0.6405s	
3155/26050 (epoch 6.056), train_loss = 1.16982204, grad/param norm = 1.5942e-01, time/batch = 0.6434s	
3156/26050 (epoch 6.058), train_loss = 1.39324905, grad/param norm = 1.7820e-01, time/batch = 0.6590s	
3157/26050 (epoch 6.060), train_loss = 1.46361323, grad/param norm = 1.7866e-01, time/batch = 0.6551s	
3158/26050 (epoch 6.061), train_loss = 1.36995950, grad/param norm = 1.8335e-01, time/batch = 0.6558s	
3159/26050 (epoch 6.063), train_loss = 1.40073320, grad/param norm = 1.6616e-01, time/batch = 0.6563s	
3160/26050 (epoch 6.065), train_loss = 1.30520828, grad/param norm = 1.8048e-01, time/batch = 0.6556s	
3161/26050 (epoch 6.067), train_loss = 1.57272534, grad/param norm = 2.0532e-01, time/batch = 0.6524s	
3162/26050 (epoch 6.069), train_loss = 1.57105007, grad/param norm = 1.9690e-01, time/batch = 0.6598s	
3163/26050 (epoch 6.071), train_loss = 1.55880594, grad/param norm = 2.0658e-01, time/batch = 0.6842s	
3164/26050 (epoch 6.073), train_loss = 1.70796042, grad/param norm = 1.8966e-01, time/batch = 0.6558s	
3165/26050 (epoch 6.075), train_loss = 1.37116096, grad/param norm = 1.7729e-01, time/batch = 0.6545s	
3166/26050 (epoch 6.077), train_loss = 1.37321031, grad/param norm = 1.8583e-01, time/batch = 0.6629s	
3167/26050 (epoch 6.079), train_loss = 1.59398157, grad/param norm = 1.9997e-01, time/batch = 0.6553s	
3168/26050 (epoch 6.081), train_loss = 1.40963393, grad/param norm = 1.8501e-01, time/batch = 0.6430s	
3169/26050 (epoch 6.083), train_loss = 1.56165629, grad/param norm = 2.0252e-01, time/batch = 0.6403s	
3170/26050 (epoch 6.084), train_loss = 1.70772275, grad/param norm = 2.2641e-01, time/batch = 0.6396s	
3171/26050 (epoch 6.086), train_loss = 1.64648600, grad/param norm = 2.0528e-01, time/batch = 0.6432s	
3172/26050 (epoch 6.088), train_loss = 1.33898006, grad/param norm = 1.6702e-01, time/batch = 0.6495s	
3173/26050 (epoch 6.090), train_loss = 1.64623530, grad/param norm = 1.9355e-01, time/batch = 0.6413s	
3174/26050 (epoch 6.092), train_loss = 1.42525879, grad/param norm = 1.9884e-01, time/batch = 0.6414s	
3175/26050 (epoch 6.094), train_loss = 1.52732944, grad/param norm = 1.9572e-01, time/batch = 0.6435s	
3176/26050 (epoch 6.096), train_loss = 1.36752378, grad/param norm = 1.7070e-01, time/batch = 0.6444s	
3177/26050 (epoch 6.098), train_loss = 1.40379329, grad/param norm = 1.9024e-01, time/batch = 0.6452s	
3178/26050 (epoch 6.100), train_loss = 1.39074882, grad/param norm = 2.0593e-01, time/batch = 0.6825s	
3179/26050 (epoch 6.102), train_loss = 1.52176503, grad/param norm = 1.9045e-01, time/batch = 0.6607s	
3180/26050 (epoch 6.104), train_loss = 1.55939057, grad/param norm = 1.9751e-01, time/batch = 0.6397s	
3181/26050 (epoch 6.106), train_loss = 1.43543530, grad/param norm = 1.9343e-01, time/batch = 0.6396s	
3182/26050 (epoch 6.107), train_loss = 1.20367906, grad/param norm = 1.7706e-01, time/batch = 0.6433s	
3183/26050 (epoch 6.109), train_loss = 1.37699212, grad/param norm = 1.7369e-01, time/batch = 0.6497s	
3184/26050 (epoch 6.111), train_loss = 1.73762706, grad/param norm = 2.1946e-01, time/batch = 0.6415s	
3185/26050 (epoch 6.113), train_loss = 1.39606924, grad/param norm = 1.9810e-01, time/batch = 0.6406s	
3186/26050 (epoch 6.115), train_loss = 1.61400643, grad/param norm = 1.9077e-01, time/batch = 0.6397s	
3187/26050 (epoch 6.117), train_loss = 1.54889946, grad/param norm = 2.0403e-01, time/batch = 0.6392s	
3188/26050 (epoch 6.119), train_loss = 1.27379777, grad/param norm = 1.7997e-01, time/batch = 0.6404s	
3189/26050 (epoch 6.121), train_loss = 1.52357611, grad/param norm = 1.9709e-01, time/batch = 0.6393s	
3190/26050 (epoch 6.123), train_loss = 1.42334130, grad/param norm = 2.1795e-01, time/batch = 0.6409s	
3191/26050 (epoch 6.125), train_loss = 1.24476012, grad/param norm = 1.6752e-01, time/batch = 0.6548s	
3192/26050 (epoch 6.127), train_loss = 1.26043471, grad/param norm = 1.8104e-01, time/batch = 0.6634s	
3193/26050 (epoch 6.129), train_loss = 1.25082258, grad/param norm = 1.6971e-01, time/batch = 0.6963s	
3194/26050 (epoch 6.131), train_loss = 1.48590810, grad/param norm = 1.9795e-01, time/batch = 0.6790s	
3195/26050 (epoch 6.132), train_loss = 1.40290258, grad/param norm = 1.7687e-01, time/batch = 0.6542s	
3196/26050 (epoch 6.134), train_loss = 1.43515349, grad/param norm = 2.0265e-01, time/batch = 0.6708s	
3197/26050 (epoch 6.136), train_loss = 1.44098748, grad/param norm = 1.8043e-01, time/batch = 0.6566s	
3198/26050 (epoch 6.138), train_loss = 1.35684804, grad/param norm = 2.2475e-01, time/batch = 0.6557s	
3199/26050 (epoch 6.140), train_loss = 1.39717108, grad/param norm = 1.8944e-01, time/batch = 0.6539s	
3200/26050 (epoch 6.142), train_loss = 1.44683383, grad/param norm = 1.8915e-01, time/batch = 0.6531s	
3201/26050 (epoch 6.144), train_loss = 1.28789480, grad/param norm = 1.8947e-01, time/batch = 0.6542s	
3202/26050 (epoch 6.146), train_loss = 1.21690650, grad/param norm = 1.7665e-01, time/batch = 0.6513s	
3203/26050 (epoch 6.148), train_loss = 1.23544545, grad/param norm = 1.5427e-01, time/batch = 0.6514s	
3204/26050 (epoch 6.150), train_loss = 1.47109922, grad/param norm = 1.9350e-01, time/batch = 0.6500s	
3205/26050 (epoch 6.152), train_loss = 1.75963708, grad/param norm = 2.1486e-01, time/batch = 0.6523s	
3206/26050 (epoch 6.154), train_loss = 1.28911928, grad/param norm = 1.8527e-01, time/batch = 0.6559s	
3207/26050 (epoch 6.155), train_loss = 1.29154598, grad/param norm = 1.7608e-01, time/batch = 0.6659s	
3208/26050 (epoch 6.157), train_loss = 1.47007890, grad/param norm = 2.0198e-01, time/batch = 0.6762s	
3209/26050 (epoch 6.159), train_loss = 1.46616026, grad/param norm = 2.0830e-01, time/batch = 0.6804s	
3210/26050 (epoch 6.161), train_loss = 1.68424574, grad/param norm = 2.1542e-01, time/batch = 0.6473s	
3211/26050 (epoch 6.163), train_loss = 1.32763295, grad/param norm = 1.7650e-01, time/batch = 0.6608s	
3212/26050 (epoch 6.165), train_loss = 1.15034354, grad/param norm = 1.6922e-01, time/batch = 0.6607s	
3213/26050 (epoch 6.167), train_loss = 1.60256247, grad/param norm = 2.3171e-01, time/batch = 0.6613s	
3214/26050 (epoch 6.169), train_loss = 1.54466067, grad/param norm = 2.0499e-01, time/batch = 0.6560s	
3215/26050 (epoch 6.171), train_loss = 1.24519973, grad/param norm = 1.6228e-01, time/batch = 0.6495s	
3216/26050 (epoch 6.173), train_loss = 1.43106051, grad/param norm = 1.9891e-01, time/batch = 0.6471s	
3217/26050 (epoch 6.175), train_loss = 1.46410947, grad/param norm = 2.0573e-01, time/batch = 0.6558s	
3218/26050 (epoch 6.177), train_loss = 1.53523100, grad/param norm = 1.9389e-01, time/batch = 0.6568s	
3219/26050 (epoch 6.179), train_loss = 1.15057900, grad/param norm = 1.7219e-01, time/batch = 0.6602s	
3220/26050 (epoch 6.180), train_loss = 1.71535238, grad/param norm = 1.9341e-01, time/batch = 0.6565s	
3221/26050 (epoch 6.182), train_loss = 1.77043331, grad/param norm = 2.0313e-01, time/batch = 0.6584s	
3222/26050 (epoch 6.184), train_loss = 1.50387855, grad/param norm = 1.8439e-01, time/batch = 0.6571s	
3223/26050 (epoch 6.186), train_loss = 1.20828394, grad/param norm = 1.6438e-01, time/batch = 0.6588s	
3224/26050 (epoch 6.188), train_loss = 1.44945460, grad/param norm = 1.7702e-01, time/batch = 0.6533s	
3225/26050 (epoch 6.190), train_loss = 1.53041182, grad/param norm = 2.0356e-01, time/batch = 0.6533s	
3226/26050 (epoch 6.192), train_loss = 1.49773964, grad/param norm = 2.0108e-01, time/batch = 0.6573s	
3227/26050 (epoch 6.194), train_loss = 1.49463001, grad/param norm = 1.9246e-01, time/batch = 0.6516s	
3228/26050 (epoch 6.196), train_loss = 1.56021685, grad/param norm = 2.0942e-01, time/batch = 0.6575s	
3229/26050 (epoch 6.198), train_loss = 1.37679895, grad/param norm = 1.8627e-01, time/batch = 0.6444s	
3230/26050 (epoch 6.200), train_loss = 1.38167443, grad/param norm = 1.9079e-01, time/batch = 0.6591s	
3231/26050 (epoch 6.202), train_loss = 1.38783491, grad/param norm = 1.9775e-01, time/batch = 0.6505s	
3232/26050 (epoch 6.203), train_loss = 1.55579631, grad/param norm = 2.0924e-01, time/batch = 0.6658s	
3233/26050 (epoch 6.205), train_loss = 1.34376910, grad/param norm = 1.8261e-01, time/batch = 0.6450s	
3234/26050 (epoch 6.207), train_loss = 1.43156260, grad/param norm = 1.7262e-01, time/batch = 0.6845s	
3235/26050 (epoch 6.209), train_loss = 1.40589765, grad/param norm = 1.8383e-01, time/batch = 0.6802s	
3236/26050 (epoch 6.211), train_loss = 1.31358542, grad/param norm = 1.9290e-01, time/batch = 0.6585s	
3237/26050 (epoch 6.213), train_loss = 1.49659923, grad/param norm = 1.7634e-01, time/batch = 0.6545s	
3238/26050 (epoch 6.215), train_loss = 1.51827337, grad/param norm = 2.1321e-01, time/batch = 0.6572s	
3239/26050 (epoch 6.217), train_loss = 1.39100580, grad/param norm = 1.8496e-01, time/batch = 0.6480s	
3240/26050 (epoch 6.219), train_loss = 1.39047863, grad/param norm = 1.9812e-01, time/batch = 0.6509s	
3241/26050 (epoch 6.221), train_loss = 1.32591647, grad/param norm = 1.8758e-01, time/batch = 0.6534s	
3242/26050 (epoch 6.223), train_loss = 1.56785617, grad/param norm = 2.1685e-01, time/batch = 0.6442s	
3243/26050 (epoch 6.225), train_loss = 1.35229651, grad/param norm = 2.0068e-01, time/batch = 0.6459s	
3244/26050 (epoch 6.226), train_loss = 1.62005243, grad/param norm = 2.1028e-01, time/batch = 0.6448s	
3245/26050 (epoch 6.228), train_loss = 1.62040774, grad/param norm = 2.1190e-01, time/batch = 0.6427s	
3246/26050 (epoch 6.230), train_loss = 1.48215816, grad/param norm = 1.9576e-01, time/batch = 0.6440s	
3247/26050 (epoch 6.232), train_loss = 1.61012414, grad/param norm = 2.1072e-01, time/batch = 0.6457s	
3248/26050 (epoch 6.234), train_loss = 1.25389252, grad/param norm = 1.8776e-01, time/batch = 0.6435s	
3249/26050 (epoch 6.236), train_loss = 1.50541955, grad/param norm = 2.1219e-01, time/batch = 0.6664s	
3250/26050 (epoch 6.238), train_loss = 1.22426879, grad/param norm = 1.7947e-01, time/batch = 0.6815s	
3251/26050 (epoch 6.240), train_loss = 1.39516608, grad/param norm = 1.7893e-01, time/batch = 0.6542s	
3252/26050 (epoch 6.242), train_loss = 1.41153363, grad/param norm = 1.8236e-01, time/batch = 0.6661s	
3253/26050 (epoch 6.244), train_loss = 1.52412262, grad/param norm = 2.1635e-01, time/batch = 0.6609s	
3254/26050 (epoch 6.246), train_loss = 1.37666017, grad/param norm = 1.7766e-01, time/batch = 0.6554s	
3255/26050 (epoch 6.248), train_loss = 1.53242737, grad/param norm = 2.0277e-01, time/batch = 0.6474s	
3256/26050 (epoch 6.250), train_loss = 1.51966969, grad/param norm = 2.0811e-01, time/batch = 0.6578s	
3257/26050 (epoch 6.251), train_loss = 1.33806445, grad/param norm = 1.8771e-01, time/batch = 0.6490s	
3258/26050 (epoch 6.253), train_loss = 1.25755561, grad/param norm = 1.8553e-01, time/batch = 0.6501s	
3259/26050 (epoch 6.255), train_loss = 1.67642365, grad/param norm = 1.9653e-01, time/batch = 0.6489s	
3260/26050 (epoch 6.257), train_loss = 1.45124547, grad/param norm = 1.9346e-01, time/batch = 0.6840s	
3261/26050 (epoch 6.259), train_loss = 1.59027234, grad/param norm = 1.9752e-01, time/batch = 0.6669s	
3262/26050 (epoch 6.261), train_loss = 1.38619750, grad/param norm = 1.9201e-01, time/batch = 0.6664s	
3263/26050 (epoch 6.263), train_loss = 1.44714557, grad/param norm = 1.9473e-01, time/batch = 0.6662s	
3264/26050 (epoch 6.265), train_loss = 1.64500456, grad/param norm = 1.8081e-01, time/batch = 0.6692s	
3265/26050 (epoch 6.267), train_loss = 1.49697526, grad/param norm = 1.9810e-01, time/batch = 0.6675s	
3266/26050 (epoch 6.269), train_loss = 1.67211265, grad/param norm = 2.1678e-01, time/batch = 0.6667s	
3267/26050 (epoch 6.271), train_loss = 1.44473080, grad/param norm = 1.7538e-01, time/batch = 0.6608s	
3268/26050 (epoch 6.273), train_loss = 1.41415842, grad/param norm = 1.9003e-01, time/batch = 0.6550s	
3269/26050 (epoch 6.274), train_loss = 1.38238053, grad/param norm = 1.8869e-01, time/batch = 0.6535s	
3270/26050 (epoch 6.276), train_loss = 1.36149857, grad/param norm = 1.8370e-01, time/batch = 0.6484s	
3271/26050 (epoch 6.278), train_loss = 1.56109462, grad/param norm = 2.0216e-01, time/batch = 0.6505s	
3272/26050 (epoch 6.280), train_loss = 1.43269191, grad/param norm = 1.7916e-01, time/batch = 0.6497s	
3273/26050 (epoch 6.282), train_loss = 1.49382039, grad/param norm = 1.9997e-01, time/batch = 0.6489s	
3274/26050 (epoch 6.284), train_loss = 1.31774675, grad/param norm = 1.9120e-01, time/batch = 0.6446s	
3275/26050 (epoch 6.286), train_loss = 1.42819524, grad/param norm = 2.0364e-01, time/batch = 0.6821s	
3276/26050 (epoch 6.288), train_loss = 1.28953316, grad/param norm = 1.8035e-01, time/batch = 0.6636s	
3277/26050 (epoch 6.290), train_loss = 1.40070015, grad/param norm = 1.9051e-01, time/batch = 0.6402s	
3278/26050 (epoch 6.292), train_loss = 1.35916595, grad/param norm = 1.7818e-01, time/batch = 0.6404s	
3279/26050 (epoch 6.294), train_loss = 1.48984718, grad/param norm = 2.1799e-01, time/batch = 0.6507s	
3280/26050 (epoch 6.296), train_loss = 1.56236856, grad/param norm = 1.8878e-01, time/batch = 0.6571s	
3281/26050 (epoch 6.298), train_loss = 1.41106866, grad/param norm = 1.7441e-01, time/batch = 0.6534s	
3282/26050 (epoch 6.299), train_loss = 1.19230354, grad/param norm = 1.6142e-01, time/batch = 0.6718s	
3283/26050 (epoch 6.301), train_loss = 1.37421596, grad/param norm = 1.9294e-01, time/batch = 0.6633s	
3284/26050 (epoch 6.303), train_loss = 1.48089343, grad/param norm = 1.9436e-01, time/batch = 0.6672s	
3285/26050 (epoch 6.305), train_loss = 1.31143215, grad/param norm = 1.8324e-01, time/batch = 0.6534s	
3286/26050 (epoch 6.307), train_loss = 1.30761022, grad/param norm = 1.8682e-01, time/batch = 0.6480s	
3287/26050 (epoch 6.309), train_loss = 1.39027011, grad/param norm = 1.9967e-01, time/batch = 0.6495s	
3288/26050 (epoch 6.311), train_loss = 1.66599091, grad/param norm = 2.1396e-01, time/batch = 0.6481s	
3289/26050 (epoch 6.313), train_loss = 1.46527972, grad/param norm = 2.0769e-01, time/batch = 0.6539s	
3290/26050 (epoch 6.315), train_loss = 1.60437352, grad/param norm = 2.1150e-01, time/batch = 0.6736s	
3291/26050 (epoch 6.317), train_loss = 1.35595726, grad/param norm = 1.8177e-01, time/batch = 0.6774s	
3292/26050 (epoch 6.319), train_loss = 1.42252719, grad/param norm = 1.7092e-01, time/batch = 0.6548s	
3293/26050 (epoch 6.321), train_loss = 1.42733046, grad/param norm = 1.7676e-01, time/batch = 0.6529s	
3294/26050 (epoch 6.322), train_loss = 1.46106939, grad/param norm = 1.8116e-01, time/batch = 0.6582s	
3295/26050 (epoch 6.324), train_loss = 1.25940584, grad/param norm = 1.7098e-01, time/batch = 0.6577s	
3296/26050 (epoch 6.326), train_loss = 1.60381199, grad/param norm = 2.0827e-01, time/batch = 0.6449s	
3297/26050 (epoch 6.328), train_loss = 1.48228532, grad/param norm = 1.8693e-01, time/batch = 0.6425s	
3298/26050 (epoch 6.330), train_loss = 1.34736596, grad/param norm = 1.9366e-01, time/batch = 0.6533s	
3299/26050 (epoch 6.332), train_loss = 1.53180395, grad/param norm = 1.9390e-01, time/batch = 0.6499s	
3300/26050 (epoch 6.334), train_loss = 1.40471982, grad/param norm = 1.9260e-01, time/batch = 0.6446s	
3301/26050 (epoch 6.336), train_loss = 1.29442179, grad/param norm = 1.6413e-01, time/batch = 0.6566s	
3302/26050 (epoch 6.338), train_loss = 1.25866225, grad/param norm = 1.7264e-01, time/batch = 0.6543s	
3303/26050 (epoch 6.340), train_loss = 1.54769393, grad/param norm = 2.0558e-01, time/batch = 0.6431s	
3304/26050 (epoch 6.342), train_loss = 1.58508698, grad/param norm = 1.8894e-01, time/batch = 0.6535s	
3305/26050 (epoch 6.344), train_loss = 1.43218401, grad/param norm = 1.9897e-01, time/batch = 0.6723s	
3306/26050 (epoch 6.345), train_loss = 1.44330918, grad/param norm = 2.0797e-01, time/batch = 0.6823s	
3307/26050 (epoch 6.347), train_loss = 1.51285625, grad/param norm = 2.0159e-01, time/batch = 0.6568s	
3308/26050 (epoch 6.349), train_loss = 1.45369045, grad/param norm = 1.8839e-01, time/batch = 0.6566s	
3309/26050 (epoch 6.351), train_loss = 1.49451874, grad/param norm = 2.0737e-01, time/batch = 0.6510s	
3310/26050 (epoch 6.353), train_loss = 1.36796958, grad/param norm = 2.0165e-01, time/batch = 0.6519s	
3311/26050 (epoch 6.355), train_loss = 1.54397086, grad/param norm = 2.0801e-01, time/batch = 0.6605s	
3312/26050 (epoch 6.357), train_loss = 1.28262449, grad/param norm = 1.6386e-01, time/batch = 0.6534s	
3313/26050 (epoch 6.359), train_loss = 1.53369119, grad/param norm = 1.9317e-01, time/batch = 0.6504s	
3314/26050 (epoch 6.361), train_loss = 1.31194980, grad/param norm = 1.8123e-01, time/batch = 0.6574s	
3315/26050 (epoch 6.363), train_loss = 1.43021705, grad/param norm = 1.8534e-01, time/batch = 0.6487s	
3316/26050 (epoch 6.365), train_loss = 1.32889458, grad/param norm = 1.7288e-01, time/batch = 0.6488s	
3317/26050 (epoch 6.367), train_loss = 1.43789223, grad/param norm = 1.9047e-01, time/batch = 0.6437s	
3318/26050 (epoch 6.369), train_loss = 1.40241609, grad/param norm = 1.7320e-01, time/batch = 0.6535s	
3319/26050 (epoch 6.370), train_loss = 1.32388859, grad/param norm = 1.7938e-01, time/batch = 0.6562s	
3320/26050 (epoch 6.372), train_loss = 1.58231091, grad/param norm = 2.1023e-01, time/batch = 0.6511s	
3321/26050 (epoch 6.374), train_loss = 1.66191812, grad/param norm = 2.1788e-01, time/batch = 0.6538s	
3322/26050 (epoch 6.376), train_loss = 1.67940947, grad/param norm = 1.8445e-01, time/batch = 0.6431s	
3323/26050 (epoch 6.378), train_loss = 1.43135836, grad/param norm = 1.9281e-01, time/batch = 0.6386s	
3324/26050 (epoch 6.380), train_loss = 1.65881405, grad/param norm = 2.0595e-01, time/batch = 0.6379s	
3325/26050 (epoch 6.382), train_loss = 1.84194503, grad/param norm = 2.2330e-01, time/batch = 0.6385s	
3326/26050 (epoch 6.384), train_loss = 1.40107528, grad/param norm = 1.8473e-01, time/batch = 0.6605s	
3327/26050 (epoch 6.386), train_loss = 1.54260202, grad/param norm = 1.8448e-01, time/batch = 0.6447s	
3328/26050 (epoch 6.388), train_loss = 1.49229766, grad/param norm = 1.7880e-01, time/batch = 0.6437s	
3329/26050 (epoch 6.390), train_loss = 1.30769475, grad/param norm = 1.6784e-01, time/batch = 0.6498s	
3330/26050 (epoch 6.392), train_loss = 1.32694833, grad/param norm = 1.8205e-01, time/batch = 0.6642s	
3331/26050 (epoch 6.393), train_loss = 1.50516766, grad/param norm = 1.8267e-01, time/batch = 0.6783s	
3332/26050 (epoch 6.395), train_loss = 1.51664024, grad/param norm = 1.9118e-01, time/batch = 0.6768s	
3333/26050 (epoch 6.397), train_loss = 1.50486951, grad/param norm = 1.9150e-01, time/batch = 0.6736s	
3334/26050 (epoch 6.399), train_loss = 1.31603432, grad/param norm = 1.7462e-01, time/batch = 0.6666s	
3335/26050 (epoch 6.401), train_loss = 1.38369745, grad/param norm = 1.7743e-01, time/batch = 0.6587s	
3336/26050 (epoch 6.403), train_loss = 1.45891663, grad/param norm = 1.9245e-01, time/batch = 0.6410s	
3337/26050 (epoch 6.405), train_loss = 1.44104528, grad/param norm = 1.9660e-01, time/batch = 0.6404s	
3338/26050 (epoch 6.407), train_loss = 1.61767561, grad/param norm = 1.9692e-01, time/batch = 0.6394s	
3339/26050 (epoch 6.409), train_loss = 1.64386728, grad/param norm = 2.0767e-01, time/batch = 0.6416s	
3340/26050 (epoch 6.411), train_loss = 1.49350426, grad/param norm = 1.9017e-01, time/batch = 0.6402s	
3341/26050 (epoch 6.413), train_loss = 1.58862503, grad/param norm = 1.8350e-01, time/batch = 0.6617s	
3342/26050 (epoch 6.415), train_loss = 1.59285271, grad/param norm = 2.0592e-01, time/batch = 0.6519s	
3343/26050 (epoch 6.417), train_loss = 1.64643852, grad/param norm = 2.0462e-01, time/batch = 0.6397s	
3344/26050 (epoch 6.418), train_loss = 1.53890738, grad/param norm = 1.9754e-01, time/batch = 0.6439s	
3345/26050 (epoch 6.420), train_loss = 1.22710218, grad/param norm = 1.6531e-01, time/batch = 0.6403s	
3346/26050 (epoch 6.422), train_loss = 1.31626739, grad/param norm = 1.9487e-01, time/batch = 0.6407s	
3347/26050 (epoch 6.424), train_loss = 1.70851242, grad/param norm = 2.2695e-01, time/batch = 0.6397s	
3348/26050 (epoch 6.426), train_loss = 1.65353572, grad/param norm = 2.2777e-01, time/batch = 0.6406s	
3349/26050 (epoch 6.428), train_loss = 1.35770648, grad/param norm = 1.7604e-01, time/batch = 0.6409s	
3350/26050 (epoch 6.430), train_loss = 1.49477160, grad/param norm = 2.0360e-01, time/batch = 0.6406s	
3351/26050 (epoch 6.432), train_loss = 1.42060978, grad/param norm = 1.9186e-01, time/batch = 0.6430s	
3352/26050 (epoch 6.434), train_loss = 1.48595515, grad/param norm = 1.8794e-01, time/batch = 0.6426s	
3353/26050 (epoch 6.436), train_loss = 1.60493767, grad/param norm = 1.8928e-01, time/batch = 0.6406s	
3354/26050 (epoch 6.438), train_loss = 1.33691942, grad/param norm = 1.7198e-01, time/batch = 0.6405s	
3355/26050 (epoch 6.440), train_loss = 1.47668528, grad/param norm = 1.9203e-01, time/batch = 0.6407s	
3356/26050 (epoch 6.441), train_loss = 1.44760514, grad/param norm = 1.8931e-01, time/batch = 0.6399s	
3357/26050 (epoch 6.443), train_loss = 1.24209182, grad/param norm = 1.6268e-01, time/batch = 0.6410s	
3358/26050 (epoch 6.445), train_loss = 1.31348648, grad/param norm = 1.8259e-01, time/batch = 0.6436s	
3359/26050 (epoch 6.447), train_loss = 1.69627556, grad/param norm = 1.9928e-01, time/batch = 0.6423s	
3360/26050 (epoch 6.449), train_loss = 1.34319424, grad/param norm = 1.7905e-01, time/batch = 0.6415s	
3361/26050 (epoch 6.451), train_loss = 1.52477336, grad/param norm = 1.7140e-01, time/batch = 0.6424s	
3362/26050 (epoch 6.453), train_loss = 1.30378213, grad/param norm = 1.6840e-01, time/batch = 0.6415s	
3363/26050 (epoch 6.455), train_loss = 1.47965675, grad/param norm = 1.9156e-01, time/batch = 0.6415s	
3364/26050 (epoch 6.457), train_loss = 1.49876403, grad/param norm = 1.9615e-01, time/batch = 0.6418s	
3365/26050 (epoch 6.459), train_loss = 1.58051453, grad/param norm = 1.9359e-01, time/batch = 0.6461s	
3366/26050 (epoch 6.461), train_loss = 1.53788082, grad/param norm = 1.9463e-01, time/batch = 0.6462s	
3367/26050 (epoch 6.463), train_loss = 1.38060658, grad/param norm = 1.7283e-01, time/batch = 0.6418s	
3368/26050 (epoch 6.464), train_loss = 1.53347879, grad/param norm = 2.0807e-01, time/batch = 0.6456s	
3369/26050 (epoch 6.466), train_loss = 1.56345281, grad/param norm = 1.8714e-01, time/batch = 0.6416s	
3370/26050 (epoch 6.468), train_loss = 1.55357985, grad/param norm = 1.7977e-01, time/batch = 0.6399s	
3371/26050 (epoch 6.470), train_loss = 1.68886835, grad/param norm = 2.0868e-01, time/batch = 0.6424s	
3372/26050 (epoch 6.472), train_loss = 1.71201251, grad/param norm = 1.9875e-01, time/batch = 0.6421s	
3373/26050 (epoch 6.474), train_loss = 1.74883491, grad/param norm = 1.9243e-01, time/batch = 0.6410s	
3374/26050 (epoch 6.476), train_loss = 1.55186532, grad/param norm = 1.7802e-01, time/batch = 0.6605s	
3375/26050 (epoch 6.478), train_loss = 1.36637314, grad/param norm = 1.7104e-01, time/batch = 0.6661s	
3376/26050 (epoch 6.480), train_loss = 1.47766555, grad/param norm = 1.6826e-01, time/batch = 0.6680s	
3377/26050 (epoch 6.482), train_loss = 1.42904033, grad/param norm = 1.8457e-01, time/batch = 0.6731s	
3378/26050 (epoch 6.484), train_loss = 1.31419000, grad/param norm = 1.8894e-01, time/batch = 0.6835s	
3379/26050 (epoch 6.486), train_loss = 1.63714728, grad/param norm = 2.0276e-01, time/batch = 0.6615s	
3380/26050 (epoch 6.488), train_loss = 1.83618609, grad/param norm = 2.0432e-01, time/batch = 0.6551s	
3381/26050 (epoch 6.489), train_loss = 1.72549964, grad/param norm = 1.9917e-01, time/batch = 0.6507s	
3382/26050 (epoch 6.491), train_loss = 1.38977646, grad/param norm = 1.8566e-01, time/batch = 0.6715s	
3383/26050 (epoch 6.493), train_loss = 1.39425543, grad/param norm = 1.8118e-01, time/batch = 0.6582s	
3384/26050 (epoch 6.495), train_loss = 1.45517125, grad/param norm = 1.9772e-01, time/batch = 0.6572s	
3385/26050 (epoch 6.497), train_loss = 1.39061598, grad/param norm = 1.8302e-01, time/batch = 0.6592s	
3386/26050 (epoch 6.499), train_loss = 1.40193281, grad/param norm = 1.9829e-01, time/batch = 0.6630s	
3387/26050 (epoch 6.501), train_loss = 1.46392768, grad/param norm = 2.0155e-01, time/batch = 0.6462s	
3388/26050 (epoch 6.503), train_loss = 1.38740218, grad/param norm = 1.9081e-01, time/batch = 0.6437s	
3389/26050 (epoch 6.505), train_loss = 1.58824215, grad/param norm = 1.8992e-01, time/batch = 0.6509s	
3390/26050 (epoch 6.507), train_loss = 1.59673498, grad/param norm = 2.0291e-01, time/batch = 0.6424s	
3391/26050 (epoch 6.509), train_loss = 1.72323760, grad/param norm = 2.1591e-01, time/batch = 0.6420s	
3392/26050 (epoch 6.511), train_loss = 1.36837603, grad/param norm = 1.8760e-01, time/batch = 0.6561s	
3393/26050 (epoch 6.512), train_loss = 1.52074143, grad/param norm = 2.1072e-01, time/batch = 0.6833s	
3394/26050 (epoch 6.514), train_loss = 1.54338833, grad/param norm = 1.9129e-01, time/batch = 0.6501s	
3395/26050 (epoch 6.516), train_loss = 1.58960900, grad/param norm = 2.0489e-01, time/batch = 0.6428s	
3396/26050 (epoch 6.518), train_loss = 1.54597859, grad/param norm = 1.9617e-01, time/batch = 0.6419s	
3397/26050 (epoch 6.520), train_loss = 1.49038295, grad/param norm = 1.9183e-01, time/batch = 0.6447s	
3398/26050 (epoch 6.522), train_loss = 1.34134897, grad/param norm = 1.8114e-01, time/batch = 0.6416s	
3399/26050 (epoch 6.524), train_loss = 1.70374624, grad/param norm = 2.0456e-01, time/batch = 0.6395s	
3400/26050 (epoch 6.526), train_loss = 1.54187219, grad/param norm = 1.8930e-01, time/batch = 0.6402s	
3401/26050 (epoch 6.528), train_loss = 1.55055781, grad/param norm = 2.0350e-01, time/batch = 0.6415s	
3402/26050 (epoch 6.530), train_loss = 1.45798766, grad/param norm = 1.8385e-01, time/batch = 0.6421s	
3403/26050 (epoch 6.532), train_loss = 1.48540358, grad/param norm = 1.8577e-01, time/batch = 0.6480s	
3404/26050 (epoch 6.534), train_loss = 1.56938013, grad/param norm = 1.9152e-01, time/batch = 0.6420s	
3405/26050 (epoch 6.536), train_loss = 1.40601658, grad/param norm = 1.9425e-01, time/batch = 0.6463s	
3406/26050 (epoch 6.537), train_loss = 1.59919041, grad/param norm = 1.8969e-01, time/batch = 0.6415s	
3407/26050 (epoch 6.539), train_loss = 1.44513102, grad/param norm = 1.7991e-01, time/batch = 0.6414s	
3408/26050 (epoch 6.541), train_loss = 1.69163123, grad/param norm = 2.2916e-01, time/batch = 0.6792s	
3409/26050 (epoch 6.543), train_loss = 1.29566394, grad/param norm = 1.8236e-01, time/batch = 0.6649s	
3410/26050 (epoch 6.545), train_loss = 1.54499855, grad/param norm = 1.9804e-01, time/batch = 0.6525s	
3411/26050 (epoch 6.547), train_loss = 1.50170390, grad/param norm = 1.9406e-01, time/batch = 0.6426s	
3412/26050 (epoch 6.549), train_loss = 1.31884949, grad/param norm = 1.8413e-01, time/batch = 0.6442s	
3413/26050 (epoch 6.551), train_loss = 1.53572164, grad/param norm = 2.0262e-01, time/batch = 0.6422s	
3414/26050 (epoch 6.553), train_loss = 1.39650904, grad/param norm = 1.9185e-01, time/batch = 0.6418s	
3415/26050 (epoch 6.555), train_loss = 1.41128702, grad/param norm = 1.8133e-01, time/batch = 0.6426s	
3416/26050 (epoch 6.557), train_loss = 1.55639372, grad/param norm = 1.8799e-01, time/batch = 0.6399s	
3417/26050 (epoch 6.559), train_loss = 1.49309927, grad/param norm = 1.9802e-01, time/batch = 0.6501s	
3418/26050 (epoch 6.560), train_loss = 1.46862607, grad/param norm = 1.9623e-01, time/batch = 0.6542s	
3419/26050 (epoch 6.562), train_loss = 1.45071654, grad/param norm = 1.9453e-01, time/batch = 0.6455s	
3420/26050 (epoch 6.564), train_loss = 1.67074133, grad/param norm = 2.1478e-01, time/batch = 0.6434s	
3421/26050 (epoch 6.566), train_loss = 1.35152700, grad/param norm = 1.7721e-01, time/batch = 0.6495s	
3422/26050 (epoch 6.568), train_loss = 1.50086897, grad/param norm = 1.8048e-01, time/batch = 0.6405s	
3423/26050 (epoch 6.570), train_loss = 1.61884666, grad/param norm = 2.0288e-01, time/batch = 0.6652s	
3424/26050 (epoch 6.572), train_loss = 1.49701773, grad/param norm = 1.8276e-01, time/batch = 0.6776s	
3425/26050 (epoch 6.574), train_loss = 1.59961050, grad/param norm = 2.2386e-01, time/batch = 0.6398s	
3426/26050 (epoch 6.576), train_loss = 1.57374349, grad/param norm = 1.9939e-01, time/batch = 0.6402s	
3427/26050 (epoch 6.578), train_loss = 1.48942391, grad/param norm = 1.9656e-01, time/batch = 0.6475s	
3428/26050 (epoch 6.580), train_loss = 1.35114448, grad/param norm = 1.8094e-01, time/batch = 0.6512s	
3429/26050 (epoch 6.582), train_loss = 1.54186460, grad/param norm = 1.9210e-01, time/batch = 0.6407s	
3430/26050 (epoch 6.583), train_loss = 1.54770796, grad/param norm = 1.8929e-01, time/batch = 0.6409s	
3431/26050 (epoch 6.585), train_loss = 1.35978446, grad/param norm = 1.8101e-01, time/batch = 0.6421s	
3432/26050 (epoch 6.587), train_loss = 1.54991115, grad/param norm = 1.9220e-01, time/batch = 0.6415s	
3433/26050 (epoch 6.589), train_loss = 1.56934953, grad/param norm = 2.1088e-01, time/batch = 0.6449s	
3434/26050 (epoch 6.591), train_loss = 1.53730126, grad/param norm = 1.9071e-01, time/batch = 0.6434s	
3435/26050 (epoch 6.593), train_loss = 1.37516454, grad/param norm = 2.0412e-01, time/batch = 0.6462s	
3436/26050 (epoch 6.595), train_loss = 1.66313627, grad/param norm = 2.3441e-01, time/batch = 0.6405s	
3437/26050 (epoch 6.597), train_loss = 1.52898177, grad/param norm = 2.0224e-01, time/batch = 0.6399s	
3438/26050 (epoch 6.599), train_loss = 1.36157561, grad/param norm = 1.7890e-01, time/batch = 0.6472s	
3439/26050 (epoch 6.601), train_loss = 1.68784427, grad/param norm = 1.9469e-01, time/batch = 0.6730s	
3440/26050 (epoch 6.603), train_loss = 1.55191861, grad/param norm = 1.9298e-01, time/batch = 0.6405s	
3441/26050 (epoch 6.605), train_loss = 1.40426708, grad/param norm = 1.7120e-01, time/batch = 0.6434s	
3442/26050 (epoch 6.607), train_loss = 1.59413971, grad/param norm = 2.0048e-01, time/batch = 0.6416s	
3443/26050 (epoch 6.608), train_loss = 1.42064750, grad/param norm = 1.7306e-01, time/batch = 0.6426s	
3444/26050 (epoch 6.610), train_loss = 1.45643115, grad/param norm = 1.9471e-01, time/batch = 0.6413s	
3445/26050 (epoch 6.612), train_loss = 1.42743632, grad/param norm = 1.9586e-01, time/batch = 0.6397s	
3446/26050 (epoch 6.614), train_loss = 1.52508347, grad/param norm = 1.8972e-01, time/batch = 0.6414s	
3447/26050 (epoch 6.616), train_loss = 1.77040568, grad/param norm = 1.9767e-01, time/batch = 0.6409s	
3448/26050 (epoch 6.618), train_loss = 1.40422712, grad/param norm = 1.8694e-01, time/batch = 0.6406s	
3449/26050 (epoch 6.620), train_loss = 1.49847647, grad/param norm = 2.0054e-01, time/batch = 0.6400s	
3450/26050 (epoch 6.622), train_loss = 1.22569900, grad/param norm = 1.6706e-01, time/batch = 0.6403s	
3451/26050 (epoch 6.624), train_loss = 1.34725099, grad/param norm = 1.7098e-01, time/batch = 0.6483s	
3452/26050 (epoch 6.626), train_loss = 1.49908111, grad/param norm = 1.9460e-01, time/batch = 0.6438s	
3453/26050 (epoch 6.628), train_loss = 1.48205185, grad/param norm = 2.0044e-01, time/batch = 0.6403s	
3454/26050 (epoch 6.630), train_loss = 1.60225941, grad/param norm = 1.8482e-01, time/batch = 0.6419s	
3455/26050 (epoch 6.631), train_loss = 1.60670537, grad/param norm = 2.0441e-01, time/batch = 0.6405s	
3456/26050 (epoch 6.633), train_loss = 1.34280669, grad/param norm = 1.7267e-01, time/batch = 0.6405s	
3457/26050 (epoch 6.635), train_loss = 1.34844095, grad/param norm = 1.7319e-01, time/batch = 0.6412s	
3458/26050 (epoch 6.637), train_loss = 1.36792279, grad/param norm = 1.8297e-01, time/batch = 0.6432s	
3459/26050 (epoch 6.639), train_loss = 1.57537867, grad/param norm = 1.9073e-01, time/batch = 0.6413s	
3460/26050 (epoch 6.641), train_loss = 1.38220881, grad/param norm = 1.5936e-01, time/batch = 0.6407s	
3461/26050 (epoch 6.643), train_loss = 1.36035472, grad/param norm = 1.7448e-01, time/batch = 0.6416s	
3462/26050 (epoch 6.645), train_loss = 1.51954703, grad/param norm = 1.9736e-01, time/batch = 0.6416s	
3463/26050 (epoch 6.647), train_loss = 1.41249759, grad/param norm = 1.8559e-01, time/batch = 0.6422s	
3464/26050 (epoch 6.649), train_loss = 1.52493193, grad/param norm = 2.0517e-01, time/batch = 0.6466s	
3465/26050 (epoch 6.651), train_loss = 1.42359285, grad/param norm = 1.8667e-01, time/batch = 0.6412s	
3466/26050 (epoch 6.653), train_loss = 1.46308699, grad/param norm = 1.9475e-01, time/batch = 0.6620s	
3467/26050 (epoch 6.655), train_loss = 1.36590986, grad/param norm = 1.8908e-01, time/batch = 0.6591s	
3468/26050 (epoch 6.656), train_loss = 1.34997309, grad/param norm = 1.8144e-01, time/batch = 0.6593s	
3469/26050 (epoch 6.658), train_loss = 1.65781669, grad/param norm = 1.9913e-01, time/batch = 0.6564s	
3470/26050 (epoch 6.660), train_loss = 1.36187082, grad/param norm = 2.0918e-01, time/batch = 0.6534s	
3471/26050 (epoch 6.662), train_loss = 1.31870733, grad/param norm = 1.7322e-01, time/batch = 0.6469s	
3472/26050 (epoch 6.664), train_loss = 1.45010499, grad/param norm = 2.0063e-01, time/batch = 0.6433s	
3473/26050 (epoch 6.666), train_loss = 1.50808982, grad/param norm = 2.0690e-01, time/batch = 0.6534s	
3474/26050 (epoch 6.668), train_loss = 1.22714103, grad/param norm = 1.6289e-01, time/batch = 0.6548s	
3475/26050 (epoch 6.670), train_loss = 1.64954877, grad/param norm = 2.1812e-01, time/batch = 0.6613s	
3476/26050 (epoch 6.672), train_loss = 1.36815810, grad/param norm = 1.8048e-01, time/batch = 0.6468s	
3477/26050 (epoch 6.674), train_loss = 1.33065269, grad/param norm = 1.6801e-01, time/batch = 0.6438s	
3478/26050 (epoch 6.676), train_loss = 1.49111376, grad/param norm = 1.8721e-01, time/batch = 0.6446s	
3479/26050 (epoch 6.678), train_loss = 1.62622369, grad/param norm = 2.0136e-01, time/batch = 0.6429s	
3480/26050 (epoch 6.679), train_loss = 1.63364215, grad/param norm = 2.1237e-01, time/batch = 0.6416s	
3481/26050 (epoch 6.681), train_loss = 1.48588311, grad/param norm = 2.0383e-01, time/batch = 0.6431s	
3482/26050 (epoch 6.683), train_loss = 1.41133810, grad/param norm = 2.0083e-01, time/batch = 0.6480s	
3483/26050 (epoch 6.685), train_loss = 1.40167573, grad/param norm = 1.7507e-01, time/batch = 0.6400s	
3484/26050 (epoch 6.687), train_loss = 1.25376840, grad/param norm = 1.7168e-01, time/batch = 0.6405s	
3485/26050 (epoch 6.689), train_loss = 1.44745902, grad/param norm = 1.9210e-01, time/batch = 0.6393s	
3486/26050 (epoch 6.691), train_loss = 1.18012165, grad/param norm = 1.7312e-01, time/batch = 0.6404s	
3487/26050 (epoch 6.693), train_loss = 1.37591564, grad/param norm = 1.9421e-01, time/batch = 0.6383s	
3488/26050 (epoch 6.695), train_loss = 1.48869756, grad/param norm = 1.9547e-01, time/batch = 0.6386s	
3489/26050 (epoch 6.697), train_loss = 1.31519827, grad/param norm = 1.8926e-01, time/batch = 0.6529s	
3490/26050 (epoch 6.699), train_loss = 1.52298331, grad/param norm = 1.9863e-01, time/batch = 0.6827s	
3491/26050 (epoch 6.701), train_loss = 1.28298582, grad/param norm = 1.7542e-01, time/batch = 0.6463s	
3492/26050 (epoch 6.702), train_loss = 1.69854854, grad/param norm = 1.8649e-01, time/batch = 0.6384s	
3493/26050 (epoch 6.704), train_loss = 1.45738896, grad/param norm = 1.8444e-01, time/batch = 0.6379s	
3494/26050 (epoch 6.706), train_loss = 1.55553293, grad/param norm = 2.1878e-01, time/batch = 0.6384s	
3495/26050 (epoch 6.708), train_loss = 1.53339544, grad/param norm = 1.8982e-01, time/batch = 0.6405s	
3496/26050 (epoch 6.710), train_loss = 1.54648718, grad/param norm = 1.9157e-01, time/batch = 0.6385s	
3497/26050 (epoch 6.712), train_loss = 1.64927890, grad/param norm = 1.9907e-01, time/batch = 0.6403s	
3498/26050 (epoch 6.714), train_loss = 1.34944130, grad/param norm = 1.9653e-01, time/batch = 0.6401s	
3499/26050 (epoch 6.716), train_loss = 1.70874775, grad/param norm = 2.2944e-01, time/batch = 0.6420s	
3500/26050 (epoch 6.718), train_loss = 1.57147516, grad/param norm = 2.0774e-01, time/batch = 0.6441s	
3501/26050 (epoch 6.720), train_loss = 1.39207193, grad/param norm = 1.9155e-01, time/batch = 0.6412s	
3502/26050 (epoch 6.722), train_loss = 1.32664859, grad/param norm = 1.8389e-01, time/batch = 0.6385s	
3503/26050 (epoch 6.724), train_loss = 1.32223169, grad/param norm = 1.8729e-01, time/batch = 0.6381s	
3504/26050 (epoch 6.726), train_loss = 1.56804353, grad/param norm = 1.8983e-01, time/batch = 0.6384s	
3505/26050 (epoch 6.727), train_loss = 1.54371945, grad/param norm = 1.9166e-01, time/batch = 0.6748s	
3506/26050 (epoch 6.729), train_loss = 1.55658899, grad/param norm = 2.1185e-01, time/batch = 0.6680s	
3507/26050 (epoch 6.731), train_loss = 1.45040129, grad/param norm = 1.7460e-01, time/batch = 0.6375s	
3508/26050 (epoch 6.733), train_loss = 1.45918674, grad/param norm = 2.2197e-01, time/batch = 0.6380s	
3509/26050 (epoch 6.735), train_loss = 1.68359356, grad/param norm = 2.0996e-01, time/batch = 0.6374s	
3510/26050 (epoch 6.737), train_loss = 1.50407837, grad/param norm = 1.9730e-01, time/batch = 0.6375s	
3511/26050 (epoch 6.739), train_loss = 1.49497337, grad/param norm = 1.8171e-01, time/batch = 0.6394s	
3512/26050 (epoch 6.741), train_loss = 1.36529600, grad/param norm = 1.7597e-01, time/batch = 0.6386s	
3513/26050 (epoch 6.743), train_loss = 1.57130678, grad/param norm = 2.4320e-01, time/batch = 0.6420s	
3514/26050 (epoch 6.745), train_loss = 1.33037518, grad/param norm = 1.8307e-01, time/batch = 0.6444s	
3515/26050 (epoch 6.747), train_loss = 1.37644473, grad/param norm = 1.8852e-01, time/batch = 0.6377s	
3516/26050 (epoch 6.749), train_loss = 1.55359147, grad/param norm = 1.9990e-01, time/batch = 0.6374s	
3517/26050 (epoch 6.750), train_loss = 1.42223210, grad/param norm = 1.7957e-01, time/batch = 0.6387s	
3518/26050 (epoch 6.752), train_loss = 1.51097012, grad/param norm = 2.0850e-01, time/batch = 0.6377s	
3519/26050 (epoch 6.754), train_loss = 1.40703021, grad/param norm = 1.9298e-01, time/batch = 0.6382s	
3520/26050 (epoch 6.756), train_loss = 1.55733019, grad/param norm = 2.2798e-01, time/batch = 0.6539s	
3521/26050 (epoch 6.758), train_loss = 1.49170280, grad/param norm = 1.9900e-01, time/batch = 0.6841s	
3522/26050 (epoch 6.760), train_loss = 1.55791330, grad/param norm = 2.0824e-01, time/batch = 0.6431s	
3523/26050 (epoch 6.762), train_loss = 1.37336915, grad/param norm = 1.7861e-01, time/batch = 0.6381s	
3524/26050 (epoch 6.764), train_loss = 1.57814866, grad/param norm = 1.9977e-01, time/batch = 0.6384s	
3525/26050 (epoch 6.766), train_loss = 1.57034040, grad/param norm = 2.0470e-01, time/batch = 0.6398s	
3526/26050 (epoch 6.768), train_loss = 1.37501834, grad/param norm = 1.7052e-01, time/batch = 0.6394s	
3527/26050 (epoch 6.770), train_loss = 1.46195543, grad/param norm = 1.9311e-01, time/batch = 0.6410s	
3528/26050 (epoch 6.772), train_loss = 1.46261488, grad/param norm = 1.9225e-01, time/batch = 0.6438s	
3529/26050 (epoch 6.774), train_loss = 1.36671724, grad/param norm = 1.8888e-01, time/batch = 0.6411s	
3530/26050 (epoch 6.775), train_loss = 1.17521783, grad/param norm = 1.8261e-01, time/batch = 0.6384s	
3531/26050 (epoch 6.777), train_loss = 1.38383441, grad/param norm = 1.8819e-01, time/batch = 0.6411s	
3532/26050 (epoch 6.779), train_loss = 1.44176098, grad/param norm = 2.0554e-01, time/batch = 0.6393s	
3533/26050 (epoch 6.781), train_loss = 1.41078043, grad/param norm = 1.8292e-01, time/batch = 0.6396s	
3534/26050 (epoch 6.783), train_loss = 1.37418449, grad/param norm = 1.6624e-01, time/batch = 0.6413s	
3535/26050 (epoch 6.785), train_loss = 1.42995576, grad/param norm = 2.0805e-01, time/batch = 0.6392s	
3536/26050 (epoch 6.787), train_loss = 1.39228144, grad/param norm = 1.8392e-01, time/batch = 0.6407s	
3537/26050 (epoch 6.789), train_loss = 1.46878784, grad/param norm = 2.0611e-01, time/batch = 0.6394s	
3538/26050 (epoch 6.791), train_loss = 1.47784042, grad/param norm = 1.8643e-01, time/batch = 0.6381s	
3539/26050 (epoch 6.793), train_loss = 1.45634489, grad/param norm = 1.9723e-01, time/batch = 0.6392s	
3540/26050 (epoch 6.795), train_loss = 1.30003889, grad/param norm = 1.7997e-01, time/batch = 0.6399s	
3541/26050 (epoch 6.797), train_loss = 1.33432807, grad/param norm = 1.7157e-01, time/batch = 0.6402s	
3542/26050 (epoch 6.798), train_loss = 1.32650155, grad/param norm = 1.9093e-01, time/batch = 0.6415s	
3543/26050 (epoch 6.800), train_loss = 1.30161619, grad/param norm = 1.7647e-01, time/batch = 0.6406s	
3544/26050 (epoch 6.802), train_loss = 1.46258535, grad/param norm = 1.9146e-01, time/batch = 0.6467s	
3545/26050 (epoch 6.804), train_loss = 1.42935827, grad/param norm = 1.8175e-01, time/batch = 0.6448s	
3546/26050 (epoch 6.806), train_loss = 1.63242488, grad/param norm = 2.1901e-01, time/batch = 0.6400s	
3547/26050 (epoch 6.808), train_loss = 1.41252509, grad/param norm = 1.8087e-01, time/batch = 0.6390s	
3548/26050 (epoch 6.810), train_loss = 1.36058097, grad/param norm = 1.9022e-01, time/batch = 0.6393s	
3549/26050 (epoch 6.812), train_loss = 1.31572936, grad/param norm = 1.8180e-01, time/batch = 0.6427s	
3550/26050 (epoch 6.814), train_loss = 1.33358404, grad/param norm = 2.0498e-01, time/batch = 0.6421s	
3551/26050 (epoch 6.816), train_loss = 1.52802708, grad/param norm = 1.9643e-01, time/batch = 0.6561s	
3552/26050 (epoch 6.818), train_loss = 1.62664134, grad/param norm = 2.0983e-01, time/batch = 0.6534s	
3553/26050 (epoch 6.820), train_loss = 1.48709464, grad/param norm = 1.8973e-01, time/batch = 0.6529s	
3554/26050 (epoch 6.821), train_loss = 1.63945268, grad/param norm = 2.0945e-01, time/batch = 0.6557s	
3555/26050 (epoch 6.823), train_loss = 1.68703573, grad/param norm = 2.0366e-01, time/batch = 0.6506s	
3556/26050 (epoch 6.825), train_loss = 1.38973519, grad/param norm = 1.9541e-01, time/batch = 0.6767s	
3557/26050 (epoch 6.827), train_loss = 1.53104855, grad/param norm = 2.0593e-01, time/batch = 0.6725s	
3558/26050 (epoch 6.829), train_loss = 1.54174040, grad/param norm = 1.9312e-01, time/batch = 0.6634s	
3559/26050 (epoch 6.831), train_loss = 1.60854708, grad/param norm = 1.9699e-01, time/batch = 0.6652s	
3560/26050 (epoch 6.833), train_loss = 1.66146906, grad/param norm = 1.9547e-01, time/batch = 0.6651s	
3561/26050 (epoch 6.835), train_loss = 1.73268497, grad/param norm = 2.0349e-01, time/batch = 0.6654s	
3562/26050 (epoch 6.837), train_loss = 1.39678529, grad/param norm = 1.8345e-01, time/batch = 0.6577s	
3563/26050 (epoch 6.839), train_loss = 1.55809505, grad/param norm = 1.8390e-01, time/batch = 0.6562s	
3564/26050 (epoch 6.841), train_loss = 1.56282373, grad/param norm = 1.8332e-01, time/batch = 0.6549s	
3565/26050 (epoch 6.843), train_loss = 1.52708476, grad/param norm = 1.8544e-01, time/batch = 0.6520s	
3566/26050 (epoch 6.845), train_loss = 1.38310915, grad/param norm = 1.8708e-01, time/batch = 0.6670s	
3567/26050 (epoch 6.846), train_loss = 1.58621290, grad/param norm = 1.9065e-01, time/batch = 0.6839s	
3568/26050 (epoch 6.848), train_loss = 1.41190454, grad/param norm = 1.8577e-01, time/batch = 0.6700s	
3569/26050 (epoch 6.850), train_loss = 1.39851344, grad/param norm = 1.7717e-01, time/batch = 0.6587s	
3570/26050 (epoch 6.852), train_loss = 1.44678057, grad/param norm = 2.0298e-01, time/batch = 0.6433s	
3571/26050 (epoch 6.854), train_loss = 1.48740819, grad/param norm = 1.9507e-01, time/batch = 0.6426s	
3572/26050 (epoch 6.856), train_loss = 1.37125359, grad/param norm = 1.8474e-01, time/batch = 0.6407s	
3573/26050 (epoch 6.858), train_loss = 1.34014784, grad/param norm = 1.9303e-01, time/batch = 0.6450s	
3574/26050 (epoch 6.860), train_loss = 1.49316212, grad/param norm = 2.0294e-01, time/batch = 0.6542s	
3575/26050 (epoch 6.862), train_loss = 1.47649216, grad/param norm = 1.9617e-01, time/batch = 0.6417s	
3576/26050 (epoch 6.864), train_loss = 1.40865670, grad/param norm = 1.9345e-01, time/batch = 0.6387s	
3577/26050 (epoch 6.866), train_loss = 1.33942283, grad/param norm = 1.7525e-01, time/batch = 0.6403s	
3578/26050 (epoch 6.868), train_loss = 1.58992328, grad/param norm = 2.0766e-01, time/batch = 0.6410s	
3579/26050 (epoch 6.869), train_loss = 1.29758702, grad/param norm = 1.7083e-01, time/batch = 0.6422s	
3580/26050 (epoch 6.871), train_loss = 1.25390850, grad/param norm = 1.6680e-01, time/batch = 0.6398s	
3581/26050 (epoch 6.873), train_loss = 1.46363064, grad/param norm = 1.7948e-01, time/batch = 0.6415s	
3582/26050 (epoch 6.875), train_loss = 1.43620326, grad/param norm = 1.8789e-01, time/batch = 0.6825s	
3583/26050 (epoch 6.877), train_loss = 1.28544987, grad/param norm = 1.8850e-01, time/batch = 0.6617s	
3584/26050 (epoch 6.879), train_loss = 1.40719313, grad/param norm = 1.7030e-01, time/batch = 0.6474s	
3585/26050 (epoch 6.881), train_loss = 1.64921243, grad/param norm = 2.0498e-01, time/batch = 0.6542s	
3586/26050 (epoch 6.883), train_loss = 1.46943728, grad/param norm = 1.7748e-01, time/batch = 0.6536s	
3587/26050 (epoch 6.885), train_loss = 1.16814604, grad/param norm = 1.6309e-01, time/batch = 0.6425s	
3588/26050 (epoch 6.887), train_loss = 1.50734798, grad/param norm = 1.9187e-01, time/batch = 0.6487s	
3589/26050 (epoch 6.889), train_loss = 1.35697283, grad/param norm = 1.7684e-01, time/batch = 0.6387s	
3590/26050 (epoch 6.891), train_loss = 1.21018004, grad/param norm = 1.6740e-01, time/batch = 0.6427s	
3591/26050 (epoch 6.893), train_loss = 1.16578080, grad/param norm = 1.5537e-01, time/batch = 0.6441s	
3592/26050 (epoch 6.894), train_loss = 1.32590777, grad/param norm = 1.6319e-01, time/batch = 0.6412s	
3593/26050 (epoch 6.896), train_loss = 1.55261170, grad/param norm = 1.8965e-01, time/batch = 0.6389s	
3594/26050 (epoch 6.898), train_loss = 1.38050919, grad/param norm = 1.8979e-01, time/batch = 0.6404s	
3595/26050 (epoch 6.900), train_loss = 1.67555347, grad/param norm = 2.0328e-01, time/batch = 0.6403s	
3596/26050 (epoch 6.902), train_loss = 1.45652878, grad/param norm = 1.8042e-01, time/batch = 0.6395s	
3597/26050 (epoch 6.904), train_loss = 1.39739471, grad/param norm = 1.7957e-01, time/batch = 0.6658s	
3598/26050 (epoch 6.906), train_loss = 1.42487550, grad/param norm = 1.8578e-01, time/batch = 0.6776s	
3599/26050 (epoch 6.908), train_loss = 1.41352305, grad/param norm = 1.8835e-01, time/batch = 0.6388s	
3600/26050 (epoch 6.910), train_loss = 1.36594036, grad/param norm = 1.7468e-01, time/batch = 0.6396s	
3601/26050 (epoch 6.912), train_loss = 1.72773265, grad/param norm = 2.0186e-01, time/batch = 0.6402s	
3602/26050 (epoch 6.914), train_loss = 1.90889032, grad/param norm = 2.0529e-01, time/batch = 0.6389s	
3603/26050 (epoch 6.916), train_loss = 1.64004542, grad/param norm = 2.1621e-01, time/batch = 0.6399s	
3604/26050 (epoch 6.917), train_loss = 1.49796501, grad/param norm = 1.9781e-01, time/batch = 0.6581s	
3605/26050 (epoch 6.919), train_loss = 1.56120804, grad/param norm = 2.0010e-01, time/batch = 0.6455s	
3606/26050 (epoch 6.921), train_loss = 1.35999001, grad/param norm = 2.1002e-01, time/batch = 0.6414s	
3607/26050 (epoch 6.923), train_loss = 1.41573385, grad/param norm = 2.0043e-01, time/batch = 0.6387s	
3608/26050 (epoch 6.925), train_loss = 1.38472181, grad/param norm = 1.7858e-01, time/batch = 0.6393s	
3609/26050 (epoch 6.927), train_loss = 1.31758370, grad/param norm = 1.6417e-01, time/batch = 0.6389s	
3610/26050 (epoch 6.929), train_loss = 1.36370652, grad/param norm = 1.8722e-01, time/batch = 0.6385s	
3611/26050 (epoch 6.931), train_loss = 1.73401826, grad/param norm = 2.3975e-01, time/batch = 0.6409s	
3612/26050 (epoch 6.933), train_loss = 1.42834172, grad/param norm = 2.1249e-01, time/batch = 0.6493s	
3613/26050 (epoch 6.935), train_loss = 1.35991496, grad/param norm = 1.9166e-01, time/batch = 0.6832s	
3614/26050 (epoch 6.937), train_loss = 1.42524966, grad/param norm = 1.7201e-01, time/batch = 0.6520s	
3615/26050 (epoch 6.939), train_loss = 1.31691506, grad/param norm = 1.7615e-01, time/batch = 0.6388s	
3616/26050 (epoch 6.940), train_loss = 1.47576807, grad/param norm = 1.8223e-01, time/batch = 0.6442s	
3617/26050 (epoch 6.942), train_loss = 1.49381052, grad/param norm = 2.0450e-01, time/batch = 0.6390s	
3618/26050 (epoch 6.944), train_loss = 1.39801213, grad/param norm = 1.9215e-01, time/batch = 0.6390s	
3619/26050 (epoch 6.946), train_loss = 1.59800904, grad/param norm = 1.8189e-01, time/batch = 0.6389s	
3620/26050 (epoch 6.948), train_loss = 1.24689235, grad/param norm = 2.0697e-01, time/batch = 0.6425s	
3621/26050 (epoch 6.950), train_loss = 1.40098570, grad/param norm = 1.8169e-01, time/batch = 0.6419s	
3622/26050 (epoch 6.952), train_loss = 1.62089629, grad/param norm = 1.9984e-01, time/batch = 0.6377s	
3623/26050 (epoch 6.954), train_loss = 1.54595736, grad/param norm = 1.8129e-01, time/batch = 0.6383s	
3624/26050 (epoch 6.956), train_loss = 1.55507028, grad/param norm = 2.0186e-01, time/batch = 0.6385s	
3625/26050 (epoch 6.958), train_loss = 1.44361802, grad/param norm = 1.8800e-01, time/batch = 0.6379s	
3626/26050 (epoch 6.960), train_loss = 1.38862083, grad/param norm = 1.8116e-01, time/batch = 0.6385s	
3627/26050 (epoch 6.962), train_loss = 1.35289465, grad/param norm = 1.7918e-01, time/batch = 0.6428s	
3628/26050 (epoch 6.964), train_loss = 1.41218900, grad/param norm = 1.8274e-01, time/batch = 0.6565s	
3629/26050 (epoch 6.965), train_loss = 1.30635929, grad/param norm = 1.8213e-01, time/batch = 0.6419s	
3630/26050 (epoch 6.967), train_loss = 1.77352982, grad/param norm = 1.9378e-01, time/batch = 0.6507s	
3631/26050 (epoch 6.969), train_loss = 1.39728001, grad/param norm = 1.7533e-01, time/batch = 0.6522s	
3632/26050 (epoch 6.971), train_loss = 1.28888942, grad/param norm = 1.6725e-01, time/batch = 0.6546s	
3633/26050 (epoch 6.973), train_loss = 1.41264250, grad/param norm = 2.0379e-01, time/batch = 0.6543s	
3634/26050 (epoch 6.975), train_loss = 1.51279227, grad/param norm = 1.7169e-01, time/batch = 0.6541s	
3635/26050 (epoch 6.977), train_loss = 1.45398053, grad/param norm = 1.6230e-01, time/batch = 0.6508s	
3636/26050 (epoch 6.979), train_loss = 1.28753705, grad/param norm = 1.7883e-01, time/batch = 0.6548s	
3637/26050 (epoch 6.981), train_loss = 1.53214031, grad/param norm = 1.7785e-01, time/batch = 0.6585s	
3638/26050 (epoch 6.983), train_loss = 1.53731989, grad/param norm = 1.9208e-01, time/batch = 0.6555s	
3639/26050 (epoch 6.985), train_loss = 1.47684334, grad/param norm = 1.8501e-01, time/batch = 0.6570s	
3640/26050 (epoch 6.987), train_loss = 1.61961154, grad/param norm = 1.9963e-01, time/batch = 0.6574s	
3641/26050 (epoch 6.988), train_loss = 1.57594423, grad/param norm = 2.0336e-01, time/batch = 0.6606s	
3642/26050 (epoch 6.990), train_loss = 1.38566116, grad/param norm = 1.8805e-01, time/batch = 0.6482s	
3643/26050 (epoch 6.992), train_loss = 1.64351751, grad/param norm = 2.1302e-01, time/batch = 0.6631s	
3644/26050 (epoch 6.994), train_loss = 1.43654905, grad/param norm = 1.9643e-01, time/batch = 0.6824s	
3645/26050 (epoch 6.996), train_loss = 1.45515056, grad/param norm = 2.2519e-01, time/batch = 0.6399s	
3646/26050 (epoch 6.998), train_loss = 1.48606433, grad/param norm = 1.9274e-01, time/batch = 0.6438s	
3647/26050 (epoch 7.000), train_loss = 1.43979580, grad/param norm = 1.9306e-01, time/batch = 0.6403s	
3648/26050 (epoch 7.002), train_loss = 1.47718505, grad/param norm = 1.8805e-01, time/batch = 0.6404s	
3649/26050 (epoch 7.004), train_loss = 1.39059287, grad/param norm = 1.9337e-01, time/batch = 0.6399s	
3650/26050 (epoch 7.006), train_loss = 1.36133085, grad/param norm = 1.7162e-01, time/batch = 0.6469s	
3651/26050 (epoch 7.008), train_loss = 1.35228925, grad/param norm = 1.8230e-01, time/batch = 0.6642s	
3652/26050 (epoch 7.010), train_loss = 1.40591306, grad/param norm = 1.7707e-01, time/batch = 0.6408s	
3653/26050 (epoch 7.012), train_loss = 1.49673558, grad/param norm = 1.9741e-01, time/batch = 0.6666s	
3654/26050 (epoch 7.013), train_loss = 1.90112277, grad/param norm = 2.1073e-01, time/batch = 0.6510s	
3655/26050 (epoch 7.015), train_loss = 1.31776192, grad/param norm = 1.7392e-01, time/batch = 0.6404s	
3656/26050 (epoch 7.017), train_loss = 1.47344625, grad/param norm = 1.9499e-01, time/batch = 0.6420s	
3657/26050 (epoch 7.019), train_loss = 1.25610783, grad/param norm = 1.5668e-01, time/batch = 0.6423s	
3658/26050 (epoch 7.021), train_loss = 1.58413312, grad/param norm = 2.0324e-01, time/batch = 0.6426s	
3659/26050 (epoch 7.023), train_loss = 1.31003886, grad/param norm = 1.7548e-01, time/batch = 0.6620s	
3660/26050 (epoch 7.025), train_loss = 1.37750396, grad/param norm = 1.7825e-01, time/batch = 0.6467s	
3661/26050 (epoch 7.027), train_loss = 1.20571475, grad/param norm = 1.6769e-01, time/batch = 0.6421s	
3662/26050 (epoch 7.029), train_loss = 1.38848765, grad/param norm = 1.7599e-01, time/batch = 0.6404s	
3663/26050 (epoch 7.031), train_loss = 1.63762235, grad/param norm = 2.0992e-01, time/batch = 0.6422s	
3664/26050 (epoch 7.033), train_loss = 1.49249418, grad/param norm = 1.9069e-01, time/batch = 0.6411s	
3665/26050 (epoch 7.035), train_loss = 1.59321307, grad/param norm = 1.8950e-01, time/batch = 0.6409s	
3666/26050 (epoch 7.036), train_loss = 1.40547883, grad/param norm = 2.0260e-01, time/batch = 0.6513s	
3667/26050 (epoch 7.038), train_loss = 1.23337107, grad/param norm = 1.7104e-01, time/batch = 0.6572s	
3668/26050 (epoch 7.040), train_loss = 1.50777626, grad/param norm = 1.8465e-01, time/batch = 0.6454s	
3669/26050 (epoch 7.042), train_loss = 1.29592711, grad/param norm = 1.9810e-01, time/batch = 0.6415s	
3670/26050 (epoch 7.044), train_loss = 1.48137085, grad/param norm = 1.8076e-01, time/batch = 0.6425s	
3671/26050 (epoch 7.046), train_loss = 1.23253274, grad/param norm = 1.8926e-01, time/batch = 0.6450s	
3672/26050 (epoch 7.048), train_loss = 1.46255631, grad/param norm = 1.8910e-01, time/batch = 0.6428s	
3673/26050 (epoch 7.050), train_loss = 1.32648727, grad/param norm = 1.9688e-01, time/batch = 0.6435s	
3674/26050 (epoch 7.052), train_loss = 1.44267147, grad/param norm = 1.9885e-01, time/batch = 0.6734s	
3675/26050 (epoch 7.054), train_loss = 1.26430460, grad/param norm = 1.7793e-01, time/batch = 0.6751s	
3676/26050 (epoch 7.056), train_loss = 1.12334386, grad/param norm = 1.5094e-01, time/batch = 0.6456s	
3677/26050 (epoch 7.058), train_loss = 1.33726487, grad/param norm = 1.7290e-01, time/batch = 0.6428s	
3678/26050 (epoch 7.060), train_loss = 1.40591090, grad/param norm = 1.6748e-01, time/batch = 0.6425s	
3679/26050 (epoch 7.061), train_loss = 1.31668396, grad/param norm = 1.7617e-01, time/batch = 0.6449s	
3680/26050 (epoch 7.063), train_loss = 1.36155877, grad/param norm = 1.6517e-01, time/batch = 0.6419s	
3681/26050 (epoch 7.065), train_loss = 1.24565343, grad/param norm = 1.8272e-01, time/batch = 0.6474s	
3682/26050 (epoch 7.067), train_loss = 1.51227211, grad/param norm = 1.9615e-01, time/batch = 0.6461s	
3683/26050 (epoch 7.069), train_loss = 1.49900873, grad/param norm = 1.8393e-01, time/batch = 0.6502s	
3684/26050 (epoch 7.071), train_loss = 1.49752202, grad/param norm = 1.9920e-01, time/batch = 0.6466s	
3685/26050 (epoch 7.073), train_loss = 1.65313634, grad/param norm = 1.8152e-01, time/batch = 0.6773s	
3686/26050 (epoch 7.075), train_loss = 1.31536130, grad/param norm = 1.7065e-01, time/batch = 0.6417s	
3687/26050 (epoch 7.077), train_loss = 1.31816975, grad/param norm = 1.8000e-01, time/batch = 0.6412s	
3688/26050 (epoch 7.079), train_loss = 1.52156023, grad/param norm = 1.9719e-01, time/batch = 0.6400s	
3689/26050 (epoch 7.081), train_loss = 1.36617992, grad/param norm = 1.8937e-01, time/batch = 0.6432s	
3690/26050 (epoch 7.083), train_loss = 1.50309733, grad/param norm = 1.9238e-01, time/batch = 0.6451s	
3691/26050 (epoch 7.084), train_loss = 1.61580631, grad/param norm = 2.2233e-01, time/batch = 0.6424s	
3692/26050 (epoch 7.086), train_loss = 1.57277146, grad/param norm = 1.9257e-01, time/batch = 0.6431s	
3693/26050 (epoch 7.088), train_loss = 1.28437052, grad/param norm = 1.6402e-01, time/batch = 0.6425s	
3694/26050 (epoch 7.090), train_loss = 1.55193344, grad/param norm = 1.8813e-01, time/batch = 0.6422s	
3695/26050 (epoch 7.092), train_loss = 1.39421898, grad/param norm = 1.9373e-01, time/batch = 0.6547s	
3696/26050 (epoch 7.094), train_loss = 1.44870686, grad/param norm = 1.8688e-01, time/batch = 0.6602s	
3697/26050 (epoch 7.096), train_loss = 1.33445299, grad/param norm = 1.7485e-01, time/batch = 0.6661s	
3698/26050 (epoch 7.098), train_loss = 1.35163170, grad/param norm = 1.8225e-01, time/batch = 0.6582s	
3699/26050 (epoch 7.100), train_loss = 1.32962159, grad/param norm = 1.9592e-01, time/batch = 0.6589s	
3700/26050 (epoch 7.102), train_loss = 1.45993131, grad/param norm = 1.8725e-01, time/batch = 0.6760s	
3701/26050 (epoch 7.104), train_loss = 1.48436473, grad/param norm = 1.8848e-01, time/batch = 0.6767s	
3702/26050 (epoch 7.106), train_loss = 1.38457090, grad/param norm = 1.8563e-01, time/batch = 0.6600s	
3703/26050 (epoch 7.107), train_loss = 1.15624763, grad/param norm = 1.7890e-01, time/batch = 0.6600s	
3704/26050 (epoch 7.109), train_loss = 1.32641033, grad/param norm = 1.7317e-01, time/batch = 0.6570s	
3705/26050 (epoch 7.111), train_loss = 1.67006008, grad/param norm = 2.1283e-01, time/batch = 0.6608s	
3706/26050 (epoch 7.113), train_loss = 1.34652659, grad/param norm = 1.9025e-01, time/batch = 0.6599s	
3707/26050 (epoch 7.115), train_loss = 1.54529178, grad/param norm = 1.8433e-01, time/batch = 0.6444s	
3708/26050 (epoch 7.117), train_loss = 1.48980527, grad/param norm = 1.9526e-01, time/batch = 0.6389s	
3709/26050 (epoch 7.119), train_loss = 1.20425083, grad/param norm = 1.7134e-01, time/batch = 0.6402s	
3710/26050 (epoch 7.121), train_loss = 1.47679554, grad/param norm = 1.8813e-01, time/batch = 0.6415s	
3711/26050 (epoch 7.123), train_loss = 1.37142079, grad/param norm = 2.1879e-01, time/batch = 0.6403s	
3712/26050 (epoch 7.125), train_loss = 1.19859092, grad/param norm = 1.5939e-01, time/batch = 0.6420s	
3713/26050 (epoch 7.127), train_loss = 1.19684473, grad/param norm = 1.7609e-01, time/batch = 0.6524s	
3714/26050 (epoch 7.129), train_loss = 1.19374554, grad/param norm = 1.6326e-01, time/batch = 0.6402s	
3715/26050 (epoch 7.131), train_loss = 1.42182511, grad/param norm = 1.8289e-01, time/batch = 0.6649s	
3716/26050 (epoch 7.132), train_loss = 1.34822853, grad/param norm = 1.7201e-01, time/batch = 0.6821s	
3717/26050 (epoch 7.134), train_loss = 1.37343973, grad/param norm = 1.8656e-01, time/batch = 0.6402s	
3718/26050 (epoch 7.136), train_loss = 1.39296235, grad/param norm = 1.7876e-01, time/batch = 0.6472s	
3719/26050 (epoch 7.138), train_loss = 1.26732223, grad/param norm = 2.1190e-01, time/batch = 0.6504s	
3720/26050 (epoch 7.140), train_loss = 1.31289920, grad/param norm = 1.8258e-01, time/batch = 0.6470s	
3721/26050 (epoch 7.142), train_loss = 1.36516382, grad/param norm = 1.8092e-01, time/batch = 0.6430s	
3722/26050 (epoch 7.144), train_loss = 1.21691758, grad/param norm = 1.7346e-01, time/batch = 0.6417s	
3723/26050 (epoch 7.146), train_loss = 1.15302394, grad/param norm = 1.6735e-01, time/batch = 0.6415s	
3724/26050 (epoch 7.148), train_loss = 1.16797039, grad/param norm = 1.4498e-01, time/batch = 0.6420s	
3725/26050 (epoch 7.150), train_loss = 1.39469968, grad/param norm = 1.8307e-01, time/batch = 0.6402s	
3726/26050 (epoch 7.152), train_loss = 1.69087809, grad/param norm = 2.0771e-01, time/batch = 0.6452s	
3727/26050 (epoch 7.154), train_loss = 1.22015691, grad/param norm = 1.7876e-01, time/batch = 0.6471s	
3728/26050 (epoch 7.155), train_loss = 1.22452463, grad/param norm = 1.6630e-01, time/batch = 0.6417s	
3729/26050 (epoch 7.157), train_loss = 1.40710296, grad/param norm = 1.9936e-01, time/batch = 0.6416s	
3730/26050 (epoch 7.159), train_loss = 1.39948321, grad/param norm = 1.9425e-01, time/batch = 0.6415s	
3731/26050 (epoch 7.161), train_loss = 1.60716755, grad/param norm = 2.1452e-01, time/batch = 0.6500s	
3732/26050 (epoch 7.163), train_loss = 1.26155722, grad/param norm = 1.7042e-01, time/batch = 0.6475s	
3733/26050 (epoch 7.165), train_loss = 1.09906765, grad/param norm = 1.6076e-01, time/batch = 0.6437s	
3734/26050 (epoch 7.167), train_loss = 1.54296010, grad/param norm = 2.2051e-01, time/batch = 0.6424s	
3735/26050 (epoch 7.169), train_loss = 1.47655275, grad/param norm = 1.9610e-01, time/batch = 0.6435s	
3736/26050 (epoch 7.171), train_loss = 1.18633393, grad/param norm = 1.5706e-01, time/batch = 0.6430s	
3737/26050 (epoch 7.173), train_loss = 1.36890268, grad/param norm = 1.9187e-01, time/batch = 0.6416s	
3738/26050 (epoch 7.175), train_loss = 1.41026899, grad/param norm = 1.9677e-01, time/batch = 0.6421s	
3739/26050 (epoch 7.177), train_loss = 1.47864292, grad/param norm = 1.8629e-01, time/batch = 0.6408s	
3740/26050 (epoch 7.179), train_loss = 1.09929146, grad/param norm = 1.6743e-01, time/batch = 0.6402s	
3741/26050 (epoch 7.180), train_loss = 1.66120956, grad/param norm = 1.8518e-01, time/batch = 0.6423s	
3742/26050 (epoch 7.182), train_loss = 1.69417409, grad/param norm = 1.9067e-01, time/batch = 0.6455s	
3743/26050 (epoch 7.184), train_loss = 1.43413408, grad/param norm = 1.7632e-01, time/batch = 0.6683s	
3744/26050 (epoch 7.186), train_loss = 1.15848606, grad/param norm = 1.5878e-01, time/batch = 0.6475s	
3745/26050 (epoch 7.188), train_loss = 1.38312144, grad/param norm = 1.7000e-01, time/batch = 0.6521s	
3746/26050 (epoch 7.190), train_loss = 1.45803964, grad/param norm = 1.9519e-01, time/batch = 0.6449s	
3747/26050 (epoch 7.192), train_loss = 1.45084606, grad/param norm = 1.9043e-01, time/batch = 0.6475s	
3748/26050 (epoch 7.194), train_loss = 1.42982364, grad/param norm = 1.8305e-01, time/batch = 0.6398s	
3749/26050 (epoch 7.196), train_loss = 1.49707322, grad/param norm = 1.9793e-01, time/batch = 0.6412s	
3750/26050 (epoch 7.198), train_loss = 1.33257918, grad/param norm = 1.9010e-01, time/batch = 0.6445s	
3751/26050 (epoch 7.200), train_loss = 1.32558680, grad/param norm = 1.8815e-01, time/batch = 0.6841s	
3752/26050 (epoch 7.202), train_loss = 1.33226584, grad/param norm = 1.9425e-01, time/batch = 0.6637s	
3753/26050 (epoch 7.203), train_loss = 1.49120836, grad/param norm = 2.0311e-01, time/batch = 0.6460s	
3754/26050 (epoch 7.205), train_loss = 1.29197462, grad/param norm = 1.7891e-01, time/batch = 0.6438s	
3755/26050 (epoch 7.207), train_loss = 1.37894115, grad/param norm = 1.6555e-01, time/batch = 0.6431s	
3756/26050 (epoch 7.209), train_loss = 1.35959651, grad/param norm = 1.8263e-01, time/batch = 0.6398s	
3757/26050 (epoch 7.211), train_loss = 1.24610446, grad/param norm = 1.8009e-01, time/batch = 0.6396s	
3758/26050 (epoch 7.213), train_loss = 1.44055371, grad/param norm = 1.6959e-01, time/batch = 0.6465s	
3759/26050 (epoch 7.215), train_loss = 1.45792678, grad/param norm = 2.0896e-01, time/batch = 0.6477s	
3760/26050 (epoch 7.217), train_loss = 1.33446960, grad/param norm = 1.7475e-01, time/batch = 0.6565s	
3761/26050 (epoch 7.219), train_loss = 1.32482763, grad/param norm = 1.8836e-01, time/batch = 0.6428s	
3762/26050 (epoch 7.221), train_loss = 1.25916979, grad/param norm = 1.7805e-01, time/batch = 0.6412s	
3763/26050 (epoch 7.223), train_loss = 1.48977958, grad/param norm = 1.9750e-01, time/batch = 0.6423s	
3764/26050 (epoch 7.225), train_loss = 1.30005342, grad/param norm = 1.9703e-01, time/batch = 0.6420s	
3765/26050 (epoch 7.226), train_loss = 1.55523193, grad/param norm = 1.9613e-01, time/batch = 0.6449s	
3766/26050 (epoch 7.228), train_loss = 1.57175731, grad/param norm = 2.0739e-01, time/batch = 0.6707s	
3767/26050 (epoch 7.230), train_loss = 1.44290285, grad/param norm = 1.9422e-01, time/batch = 0.6733s	
3768/26050 (epoch 7.232), train_loss = 1.54497624, grad/param norm = 2.0586e-01, time/batch = 0.6392s	
3769/26050 (epoch 7.234), train_loss = 1.20964218, grad/param norm = 1.8108e-01, time/batch = 0.6395s	
3770/26050 (epoch 7.236), train_loss = 1.45819873, grad/param norm = 2.0902e-01, time/batch = 0.6400s	
3771/26050 (epoch 7.238), train_loss = 1.18215957, grad/param norm = 1.8302e-01, time/batch = 0.6456s	
3772/26050 (epoch 7.240), train_loss = 1.33145958, grad/param norm = 1.6715e-01, time/batch = 0.6417s	
3773/26050 (epoch 7.242), train_loss = 1.35071479, grad/param norm = 1.7544e-01, time/batch = 0.6410s	
3774/26050 (epoch 7.244), train_loss = 1.46417391, grad/param norm = 2.1118e-01, time/batch = 0.6473s	
3775/26050 (epoch 7.246), train_loss = 1.32055472, grad/param norm = 1.6875e-01, time/batch = 0.6412s	
3776/26050 (epoch 7.248), train_loss = 1.45135951, grad/param norm = 1.8960e-01, time/batch = 0.6399s	
3777/26050 (epoch 7.250), train_loss = 1.44353629, grad/param norm = 2.0322e-01, time/batch = 0.6406s	
3778/26050 (epoch 7.251), train_loss = 1.29001832, grad/param norm = 1.7994e-01, time/batch = 0.6404s	
3779/26050 (epoch 7.253), train_loss = 1.20228960, grad/param norm = 1.8067e-01, time/batch = 0.6400s	
3780/26050 (epoch 7.255), train_loss = 1.62027041, grad/param norm = 1.9334e-01, time/batch = 0.6400s	
3781/26050 (epoch 7.257), train_loss = 1.39828927, grad/param norm = 1.9793e-01, time/batch = 0.6540s	
3782/26050 (epoch 7.259), train_loss = 1.54098256, grad/param norm = 1.8910e-01, time/batch = 0.6838s	
3783/26050 (epoch 7.261), train_loss = 1.33491251, grad/param norm = 1.9440e-01, time/batch = 0.6548s	
3784/26050 (epoch 7.263), train_loss = 1.38890584, grad/param norm = 1.8966e-01, time/batch = 0.6497s	
3785/26050 (epoch 7.265), train_loss = 1.58668232, grad/param norm = 1.7926e-01, time/batch = 0.6407s	
3786/26050 (epoch 7.267), train_loss = 1.45160754, grad/param norm = 1.8696e-01, time/batch = 0.6395s	
3787/26050 (epoch 7.269), train_loss = 1.59956209, grad/param norm = 2.0109e-01, time/batch = 0.6423s	
3788/26050 (epoch 7.271), train_loss = 1.39640207, grad/param norm = 1.7581e-01, time/batch = 0.6396s	
3789/26050 (epoch 7.273), train_loss = 1.34248811, grad/param norm = 1.8077e-01, time/batch = 0.6457s	
3790/26050 (epoch 7.274), train_loss = 1.32902304, grad/param norm = 1.8161e-01, time/batch = 0.6431s	
3791/26050 (epoch 7.276), train_loss = 1.31377485, grad/param norm = 1.8349e-01, time/batch = 0.6428s	
3792/26050 (epoch 7.278), train_loss = 1.50593678, grad/param norm = 1.9327e-01, time/batch = 0.6412s	
3793/26050 (epoch 7.280), train_loss = 1.37572301, grad/param norm = 1.7155e-01, time/batch = 0.6398s	
3794/26050 (epoch 7.282), train_loss = 1.44715193, grad/param norm = 1.9921e-01, time/batch = 0.6404s	
3795/26050 (epoch 7.284), train_loss = 1.27267506, grad/param norm = 1.8104e-01, time/batch = 0.6403s	
3796/26050 (epoch 7.286), train_loss = 1.37350056, grad/param norm = 1.9515e-01, time/batch = 0.6431s	
3797/26050 (epoch 7.288), train_loss = 1.22814277, grad/param norm = 1.7049e-01, time/batch = 0.6770s	
3798/26050 (epoch 7.290), train_loss = 1.35779646, grad/param norm = 1.8615e-01, time/batch = 0.6660s	
3799/26050 (epoch 7.292), train_loss = 1.31306644, grad/param norm = 1.7586e-01, time/batch = 0.6420s	
3800/26050 (epoch 7.294), train_loss = 1.43280717, grad/param norm = 2.0854e-01, time/batch = 0.6405s	
3801/26050 (epoch 7.296), train_loss = 1.50999792, grad/param norm = 1.8786e-01, time/batch = 0.6405s	
3802/26050 (epoch 7.298), train_loss = 1.36257759, grad/param norm = 1.7149e-01, time/batch = 0.6411s	
3803/26050 (epoch 7.299), train_loss = 1.13974726, grad/param norm = 1.5245e-01, time/batch = 0.6415s	
3804/26050 (epoch 7.301), train_loss = 1.32737253, grad/param norm = 1.8994e-01, time/batch = 0.6445s	
3805/26050 (epoch 7.303), train_loss = 1.43620130, grad/param norm = 1.8842e-01, time/batch = 0.6405s	
3806/26050 (epoch 7.305), train_loss = 1.24151277, grad/param norm = 1.7715e-01, time/batch = 0.6398s	
3807/26050 (epoch 7.307), train_loss = 1.26824840, grad/param norm = 1.8188e-01, time/batch = 0.6424s	
3808/26050 (epoch 7.309), train_loss = 1.34552474, grad/param norm = 1.9120e-01, time/batch = 0.6405s	
3809/26050 (epoch 7.311), train_loss = 1.60044394, grad/param norm = 2.0872e-01, time/batch = 0.6400s	
3810/26050 (epoch 7.313), train_loss = 1.39918823, grad/param norm = 1.9549e-01, time/batch = 0.6394s	
3811/26050 (epoch 7.315), train_loss = 1.54345120, grad/param norm = 2.0039e-01, time/batch = 0.6411s	
3812/26050 (epoch 7.317), train_loss = 1.31343935, grad/param norm = 1.8004e-01, time/batch = 0.6604s	
3813/26050 (epoch 7.319), train_loss = 1.37101597, grad/param norm = 1.6517e-01, time/batch = 0.6833s	
3814/26050 (epoch 7.321), train_loss = 1.36319913, grad/param norm = 1.8124e-01, time/batch = 0.6451s	
3815/26050 (epoch 7.322), train_loss = 1.40519159, grad/param norm = 1.8272e-01, time/batch = 0.6392s	
3816/26050 (epoch 7.324), train_loss = 1.20257250, grad/param norm = 1.7134e-01, time/batch = 0.6379s	
3817/26050 (epoch 7.326), train_loss = 1.54773189, grad/param norm = 2.0810e-01, time/batch = 0.6381s	
3818/26050 (epoch 7.328), train_loss = 1.43492398, grad/param norm = 1.8780e-01, time/batch = 0.6382s	
3819/26050 (epoch 7.330), train_loss = 1.28334810, grad/param norm = 1.8369e-01, time/batch = 0.6381s	
3820/26050 (epoch 7.332), train_loss = 1.48091984, grad/param norm = 1.9000e-01, time/batch = 0.6467s	
3821/26050 (epoch 7.334), train_loss = 1.35016455, grad/param norm = 1.7892e-01, time/batch = 0.6419s	
3822/26050 (epoch 7.336), train_loss = 1.25420104, grad/param norm = 1.6070e-01, time/batch = 0.6381s	
3823/26050 (epoch 7.338), train_loss = 1.21825082, grad/param norm = 1.6644e-01, time/batch = 0.6393s	
3824/26050 (epoch 7.340), train_loss = 1.48905978, grad/param norm = 2.0364e-01, time/batch = 0.6392s	
3825/26050 (epoch 7.342), train_loss = 1.53617829, grad/param norm = 1.8780e-01, time/batch = 0.6497s	
3826/26050 (epoch 7.344), train_loss = 1.38046136, grad/param norm = 1.9631e-01, time/batch = 0.6709s	
3827/26050 (epoch 7.345), train_loss = 1.38920982, grad/param norm = 2.0264e-01, time/batch = 0.6784s	
3828/26050 (epoch 7.347), train_loss = 1.45890322, grad/param norm = 1.9468e-01, time/batch = 0.6853s	
3829/26050 (epoch 7.349), train_loss = 1.40711344, grad/param norm = 1.8415e-01, time/batch = 0.6760s	
3830/26050 (epoch 7.351), train_loss = 1.44160459, grad/param norm = 2.0747e-01, time/batch = 0.6595s	
3831/26050 (epoch 7.353), train_loss = 1.32361717, grad/param norm = 1.9255e-01, time/batch = 0.6472s	
3832/26050 (epoch 7.355), train_loss = 1.48924169, grad/param norm = 1.9800e-01, time/batch = 0.6415s	
3833/26050 (epoch 7.357), train_loss = 1.23418450, grad/param norm = 1.5876e-01, time/batch = 0.6556s	
3834/26050 (epoch 7.359), train_loss = 1.49128465, grad/param norm = 1.9323e-01, time/batch = 0.6546s	
3835/26050 (epoch 7.361), train_loss = 1.27507814, grad/param norm = 1.7352e-01, time/batch = 0.6588s	
3836/26050 (epoch 7.363), train_loss = 1.39548356, grad/param norm = 1.7888e-01, time/batch = 0.6484s	
3837/26050 (epoch 7.365), train_loss = 1.28680652, grad/param norm = 1.6875e-01, time/batch = 0.6507s	
3838/26050 (epoch 7.367), train_loss = 1.38619349, grad/param norm = 1.8656e-01, time/batch = 0.6476s	
3839/26050 (epoch 7.369), train_loss = 1.34407514, grad/param norm = 1.6569e-01, time/batch = 0.6389s	
3840/26050 (epoch 7.370), train_loss = 1.26775929, grad/param norm = 1.6893e-01, time/batch = 0.6458s	
3841/26050 (epoch 7.372), train_loss = 1.51156052, grad/param norm = 2.0334e-01, time/batch = 0.6488s	
3842/26050 (epoch 7.374), train_loss = 1.60478233, grad/param norm = 2.1596e-01, time/batch = 0.6458s	
3843/26050 (epoch 7.376), train_loss = 1.63224443, grad/param norm = 1.8538e-01, time/batch = 0.6780s	
3844/26050 (epoch 7.378), train_loss = 1.37623462, grad/param norm = 1.8704e-01, time/batch = 0.6673s	
3845/26050 (epoch 7.380), train_loss = 1.60835127, grad/param norm = 2.0020e-01, time/batch = 0.6406s	
3846/26050 (epoch 7.382), train_loss = 1.76595723, grad/param norm = 2.1640e-01, time/batch = 0.6385s	
3847/26050 (epoch 7.384), train_loss = 1.34915944, grad/param norm = 1.7802e-01, time/batch = 0.6400s	
3848/26050 (epoch 7.386), train_loss = 1.49545017, grad/param norm = 1.8468e-01, time/batch = 0.6392s	
3849/26050 (epoch 7.388), train_loss = 1.42774791, grad/param norm = 1.6824e-01, time/batch = 0.6520s	
3850/26050 (epoch 7.390), train_loss = 1.25412570, grad/param norm = 1.6548e-01, time/batch = 0.6611s	
3851/26050 (epoch 7.392), train_loss = 1.26699526, grad/param norm = 1.7434e-01, time/batch = 0.6622s	
3852/26050 (epoch 7.393), train_loss = 1.45218728, grad/param norm = 1.7554e-01, time/batch = 0.6600s	
3853/26050 (epoch 7.395), train_loss = 1.46580019, grad/param norm = 1.8499e-01, time/batch = 0.6693s	
3854/26050 (epoch 7.397), train_loss = 1.44869487, grad/param norm = 1.8658e-01, time/batch = 0.6838s	
3855/26050 (epoch 7.399), train_loss = 1.26584505, grad/param norm = 1.6748e-01, time/batch = 0.6637s	
3856/26050 (epoch 7.401), train_loss = 1.32841661, grad/param norm = 1.7150e-01, time/batch = 0.6601s	
3857/26050 (epoch 7.403), train_loss = 1.41427133, grad/param norm = 1.8491e-01, time/batch = 0.6604s	
3858/26050 (epoch 7.405), train_loss = 1.38536321, grad/param norm = 1.8527e-01, time/batch = 0.6617s	
3859/26050 (epoch 7.407), train_loss = 1.56838633, grad/param norm = 1.9290e-01, time/batch = 0.6570s	
3860/26050 (epoch 7.409), train_loss = 1.59061278, grad/param norm = 2.0367e-01, time/batch = 0.6595s	
3861/26050 (epoch 7.411), train_loss = 1.44586135, grad/param norm = 1.8700e-01, time/batch = 0.6485s	
3862/26050 (epoch 7.413), train_loss = 1.53588657, grad/param norm = 1.7959e-01, time/batch = 0.6399s	
3863/26050 (epoch 7.415), train_loss = 1.53618776, grad/param norm = 1.9236e-01, time/batch = 0.6461s	
3864/26050 (epoch 7.417), train_loss = 1.60951540, grad/param norm = 1.9971e-01, time/batch = 0.6432s	
3865/26050 (epoch 7.418), train_loss = 1.49633212, grad/param norm = 1.9930e-01, time/batch = 0.6389s	
3866/26050 (epoch 7.420), train_loss = 1.18135800, grad/param norm = 1.6226e-01, time/batch = 0.6465s	
3867/26050 (epoch 7.422), train_loss = 1.26109868, grad/param norm = 1.8433e-01, time/batch = 0.6443s	
3868/26050 (epoch 7.424), train_loss = 1.63600224, grad/param norm = 2.1726e-01, time/batch = 0.6526s	
3869/26050 (epoch 7.426), train_loss = 1.57659455, grad/param norm = 2.0894e-01, time/batch = 0.6834s	
3870/26050 (epoch 7.428), train_loss = 1.30384459, grad/param norm = 1.7036e-01, time/batch = 0.6587s	
3871/26050 (epoch 7.430), train_loss = 1.44977673, grad/param norm = 2.0130e-01, time/batch = 0.6415s	
3872/26050 (epoch 7.432), train_loss = 1.35330463, grad/param norm = 1.8533e-01, time/batch = 0.6404s	
3873/26050 (epoch 7.434), train_loss = 1.42281504, grad/param norm = 1.8569e-01, time/batch = 0.6445s	
3874/26050 (epoch 7.436), train_loss = 1.54164722, grad/param norm = 1.8113e-01, time/batch = 0.6434s	
3875/26050 (epoch 7.438), train_loss = 1.28112149, grad/param norm = 1.6913e-01, time/batch = 0.6393s	
3876/26050 (epoch 7.440), train_loss = 1.42858717, grad/param norm = 1.8371e-01, time/batch = 0.6396s	
3877/26050 (epoch 7.441), train_loss = 1.39709000, grad/param norm = 1.8170e-01, time/batch = 0.6398s	
3878/26050 (epoch 7.443), train_loss = 1.18687313, grad/param norm = 1.5646e-01, time/batch = 0.6538s	
3879/26050 (epoch 7.445), train_loss = 1.26132554, grad/param norm = 1.7718e-01, time/batch = 0.6408s	
3880/26050 (epoch 7.447), train_loss = 1.63455168, grad/param norm = 1.9352e-01, time/batch = 0.6394s	
3881/26050 (epoch 7.449), train_loss = 1.29140047, grad/param norm = 1.7265e-01, time/batch = 0.6417s	
3882/26050 (epoch 7.451), train_loss = 1.49385016, grad/param norm = 1.6825e-01, time/batch = 0.6515s	
3883/26050 (epoch 7.453), train_loss = 1.25588172, grad/param norm = 1.6408e-01, time/batch = 0.6431s	
3884/26050 (epoch 7.455), train_loss = 1.42871615, grad/param norm = 1.8453e-01, time/batch = 0.6395s	
3885/26050 (epoch 7.457), train_loss = 1.43916076, grad/param norm = 1.8932e-01, time/batch = 0.6406s	
3886/26050 (epoch 7.459), train_loss = 1.53131296, grad/param norm = 1.9243e-01, time/batch = 0.6390s	
3887/26050 (epoch 7.461), train_loss = 1.48183708, grad/param norm = 1.9328e-01, time/batch = 0.6399s	
3888/26050 (epoch 7.463), train_loss = 1.32496324, grad/param norm = 1.6740e-01, time/batch = 0.6446s	
3889/26050 (epoch 7.464), train_loss = 1.48076044, grad/param norm = 1.9609e-01, time/batch = 0.6559s	
3890/26050 (epoch 7.466), train_loss = 1.50667242, grad/param norm = 1.8748e-01, time/batch = 0.6437s	
3891/26050 (epoch 7.468), train_loss = 1.50384881, grad/param norm = 1.7475e-01, time/batch = 0.6394s	
3892/26050 (epoch 7.470), train_loss = 1.63196491, grad/param norm = 2.0371e-01, time/batch = 0.6389s	
3893/26050 (epoch 7.472), train_loss = 1.63540217, grad/param norm = 1.9355e-01, time/batch = 0.6383s	
3894/26050 (epoch 7.474), train_loss = 1.68180414, grad/param norm = 1.8796e-01, time/batch = 0.6389s	
3895/26050 (epoch 7.476), train_loss = 1.49386287, grad/param norm = 1.7487e-01, time/batch = 0.6378s	
3896/26050 (epoch 7.478), train_loss = 1.30945686, grad/param norm = 1.6288e-01, time/batch = 0.6424s	
3897/26050 (epoch 7.480), train_loss = 1.42353617, grad/param norm = 1.6187e-01, time/batch = 0.6411s	
3898/26050 (epoch 7.482), train_loss = 1.38042346, grad/param norm = 1.7975e-01, time/batch = 0.6409s	
3899/26050 (epoch 7.484), train_loss = 1.27159347, grad/param norm = 1.8008e-01, time/batch = 0.6425s	
3900/26050 (epoch 7.486), train_loss = 1.58070930, grad/param norm = 1.9022e-01, time/batch = 0.6826s	
3901/26050 (epoch 7.488), train_loss = 1.77414279, grad/param norm = 1.9911e-01, time/batch = 0.6546s	
3902/26050 (epoch 7.489), train_loss = 1.68190988, grad/param norm = 2.0092e-01, time/batch = 0.6386s	
3903/26050 (epoch 7.491), train_loss = 1.33144701, grad/param norm = 1.7534e-01, time/batch = 0.6415s	
3904/26050 (epoch 7.493), train_loss = 1.34992935, grad/param norm = 1.7590e-01, time/batch = 0.6396s	
3905/26050 (epoch 7.495), train_loss = 1.38459962, grad/param norm = 1.7899e-01, time/batch = 0.6401s	
3906/26050 (epoch 7.497), train_loss = 1.34634341, grad/param norm = 1.7670e-01, time/batch = 0.6471s	
3907/26050 (epoch 7.499), train_loss = 1.35059328, grad/param norm = 1.8347e-01, time/batch = 0.6430s	
3908/26050 (epoch 7.501), train_loss = 1.43054092, grad/param norm = 1.9811e-01, time/batch = 0.6405s	
3909/26050 (epoch 7.503), train_loss = 1.33526790, grad/param norm = 1.8561e-01, time/batch = 0.6428s	
3910/26050 (epoch 7.505), train_loss = 1.54277077, grad/param norm = 1.8287e-01, time/batch = 0.6445s	
3911/26050 (epoch 7.507), train_loss = 1.54880707, grad/param norm = 1.9232e-01, time/batch = 0.6478s	
3912/26050 (epoch 7.509), train_loss = 1.66327086, grad/param norm = 2.1826e-01, time/batch = 0.6459s	
3913/26050 (epoch 7.511), train_loss = 1.31303899, grad/param norm = 1.7956e-01, time/batch = 0.6495s	
3914/26050 (epoch 7.512), train_loss = 1.44948425, grad/param norm = 2.0283e-01, time/batch = 0.6558s	
3915/26050 (epoch 7.514), train_loss = 1.48757967, grad/param norm = 1.8774e-01, time/batch = 0.6779s	
3916/26050 (epoch 7.516), train_loss = 1.53083194, grad/param norm = 1.9558e-01, time/batch = 0.6722s	
3917/26050 (epoch 7.518), train_loss = 1.48346250, grad/param norm = 1.8706e-01, time/batch = 0.6431s	
3918/26050 (epoch 7.520), train_loss = 1.44455216, grad/param norm = 1.8900e-01, time/batch = 0.6426s	
3919/26050 (epoch 7.522), train_loss = 1.26610134, grad/param norm = 1.7632e-01, time/batch = 0.6446s	
3920/26050 (epoch 7.524), train_loss = 1.62135056, grad/param norm = 1.9921e-01, time/batch = 0.6420s	
3921/26050 (epoch 7.526), train_loss = 1.49489134, grad/param norm = 1.8547e-01, time/batch = 0.6428s	
3922/26050 (epoch 7.528), train_loss = 1.49108194, grad/param norm = 1.9998e-01, time/batch = 0.6442s	
3923/26050 (epoch 7.530), train_loss = 1.40406039, grad/param norm = 1.7619e-01, time/batch = 0.6400s	
3924/26050 (epoch 7.532), train_loss = 1.42743843, grad/param norm = 1.8857e-01, time/batch = 0.6404s	
3925/26050 (epoch 7.534), train_loss = 1.51400825, grad/param norm = 1.8275e-01, time/batch = 0.6433s	
3926/26050 (epoch 7.536), train_loss = 1.35602125, grad/param norm = 1.7874e-01, time/batch = 0.6405s	
3927/26050 (epoch 7.537), train_loss = 1.54735959, grad/param norm = 1.8995e-01, time/batch = 0.6574s	
3928/26050 (epoch 7.539), train_loss = 1.39059680, grad/param norm = 1.7330e-01, time/batch = 0.6510s	
3929/26050 (epoch 7.541), train_loss = 1.63879681, grad/param norm = 2.2319e-01, time/batch = 0.6649s	
3930/26050 (epoch 7.543), train_loss = 1.24970067, grad/param norm = 1.7557e-01, time/batch = 0.6490s	
3931/26050 (epoch 7.545), train_loss = 1.49203582, grad/param norm = 1.8775e-01, time/batch = 0.6540s	
3932/26050 (epoch 7.547), train_loss = 1.44716978, grad/param norm = 1.8988e-01, time/batch = 0.6560s	
3933/26050 (epoch 7.549), train_loss = 1.25221881, grad/param norm = 1.8058e-01, time/batch = 0.6556s	
3934/26050 (epoch 7.551), train_loss = 1.48545368, grad/param norm = 1.9343e-01, time/batch = 0.6499s	
3935/26050 (epoch 7.553), train_loss = 1.32955633, grad/param norm = 1.7982e-01, time/batch = 0.6585s	
3936/26050 (epoch 7.555), train_loss = 1.36163002, grad/param norm = 1.7451e-01, time/batch = 0.6559s	
3937/26050 (epoch 7.557), train_loss = 1.48925856, grad/param norm = 1.7864e-01, time/batch = 0.6535s	
3938/26050 (epoch 7.559), train_loss = 1.43150938, grad/param norm = 1.8788e-01, time/batch = 0.6549s	
3939/26050 (epoch 7.560), train_loss = 1.41304295, grad/param norm = 1.8842e-01, time/batch = 0.6531s	
3940/26050 (epoch 7.562), train_loss = 1.39761962, grad/param norm = 1.9654e-01, time/batch = 0.6505s	
3941/26050 (epoch 7.564), train_loss = 1.61678273, grad/param norm = 2.0288e-01, time/batch = 0.6509s	
3942/26050 (epoch 7.566), train_loss = 1.29727695, grad/param norm = 1.7116e-01, time/batch = 0.6564s	
3943/26050 (epoch 7.568), train_loss = 1.44056296, grad/param norm = 1.7736e-01, time/batch = 0.6728s	
3944/26050 (epoch 7.570), train_loss = 1.56620609, grad/param norm = 1.9909e-01, time/batch = 0.6607s	
3945/26050 (epoch 7.572), train_loss = 1.42721795, grad/param norm = 1.7771e-01, time/batch = 0.6524s	
3946/26050 (epoch 7.574), train_loss = 1.52987260, grad/param norm = 2.1182e-01, time/batch = 0.6519s	
3947/26050 (epoch 7.576), train_loss = 1.50883024, grad/param norm = 1.9314e-01, time/batch = 0.6598s	
3948/26050 (epoch 7.578), train_loss = 1.42419944, grad/param norm = 1.8874e-01, time/batch = 0.6493s	
3949/26050 (epoch 7.580), train_loss = 1.29522381, grad/param norm = 1.7441e-01, time/batch = 0.6607s	
3950/26050 (epoch 7.582), train_loss = 1.48013435, grad/param norm = 1.8533e-01, time/batch = 0.6557s	
3951/26050 (epoch 7.583), train_loss = 1.49584654, grad/param norm = 1.8774e-01, time/batch = 0.6458s	
3952/26050 (epoch 7.585), train_loss = 1.30672553, grad/param norm = 1.7205e-01, time/batch = 0.6394s	
3953/26050 (epoch 7.587), train_loss = 1.48958453, grad/param norm = 1.8922e-01, time/batch = 0.6406s	
3954/26050 (epoch 7.589), train_loss = 1.51469885, grad/param norm = 2.0626e-01, time/batch = 0.6426s	
3955/26050 (epoch 7.591), train_loss = 1.46762852, grad/param norm = 1.8684e-01, time/batch = 0.6511s	
3956/26050 (epoch 7.593), train_loss = 1.31339214, grad/param norm = 1.9574e-01, time/batch = 0.6475s	
3957/26050 (epoch 7.595), train_loss = 1.60568868, grad/param norm = 2.1944e-01, time/batch = 0.6457s	
3958/26050 (epoch 7.597), train_loss = 1.47367450, grad/param norm = 1.8906e-01, time/batch = 0.6443s	
3959/26050 (epoch 7.599), train_loss = 1.33074660, grad/param norm = 1.7650e-01, time/batch = 0.6440s	
3960/26050 (epoch 7.601), train_loss = 1.62922888, grad/param norm = 1.9033e-01, time/batch = 0.6421s	
3961/26050 (epoch 7.603), train_loss = 1.48960740, grad/param norm = 1.8740e-01, time/batch = 0.6426s	
3962/26050 (epoch 7.605), train_loss = 1.35086819, grad/param norm = 1.7284e-01, time/batch = 0.6453s	
3963/26050 (epoch 7.607), train_loss = 1.54957700, grad/param norm = 1.9865e-01, time/batch = 0.6419s	
3964/26050 (epoch 7.608), train_loss = 1.36308863, grad/param norm = 1.6677e-01, time/batch = 0.6429s	
3965/26050 (epoch 7.610), train_loss = 1.40312953, grad/param norm = 1.8769e-01, time/batch = 0.6419s	
3966/26050 (epoch 7.612), train_loss = 1.38403636, grad/param norm = 1.9400e-01, time/batch = 0.6413s	
3967/26050 (epoch 7.614), train_loss = 1.47910580, grad/param norm = 1.8419e-01, time/batch = 0.6706s	
3968/26050 (epoch 7.616), train_loss = 1.71270268, grad/param norm = 1.9488e-01, time/batch = 0.6740s	
3969/26050 (epoch 7.618), train_loss = 1.34791344, grad/param norm = 1.8126e-01, time/batch = 0.6431s	
3970/26050 (epoch 7.620), train_loss = 1.43654566, grad/param norm = 1.8707e-01, time/batch = 0.6426s	
3971/26050 (epoch 7.622), train_loss = 1.17781559, grad/param norm = 1.6095e-01, time/batch = 0.6456s	
3972/26050 (epoch 7.624), train_loss = 1.29559481, grad/param norm = 1.6700e-01, time/batch = 0.6535s	
3973/26050 (epoch 7.626), train_loss = 1.46535061, grad/param norm = 1.9091e-01, time/batch = 0.6596s	
3974/26050 (epoch 7.628), train_loss = 1.41109379, grad/param norm = 1.9265e-01, time/batch = 0.6450s	
3975/26050 (epoch 7.630), train_loss = 1.55035079, grad/param norm = 1.8021e-01, time/batch = 0.6401s	
3976/26050 (epoch 7.631), train_loss = 1.55445548, grad/param norm = 1.9906e-01, time/batch = 0.6382s	
3977/26050 (epoch 7.633), train_loss = 1.29754587, grad/param norm = 1.7168e-01, time/batch = 0.6388s	
3978/26050 (epoch 7.635), train_loss = 1.30323191, grad/param norm = 1.6684e-01, time/batch = 0.6377s	
3979/26050 (epoch 7.637), train_loss = 1.31657401, grad/param norm = 1.8250e-01, time/batch = 0.6392s	
3980/26050 (epoch 7.639), train_loss = 1.52056422, grad/param norm = 1.8353e-01, time/batch = 0.6399s	
3981/26050 (epoch 7.641), train_loss = 1.33182329, grad/param norm = 1.5623e-01, time/batch = 0.6392s	
3982/26050 (epoch 7.643), train_loss = 1.30199781, grad/param norm = 1.6927e-01, time/batch = 0.6547s	
3983/26050 (epoch 7.645), train_loss = 1.46051952, grad/param norm = 1.9062e-01, time/batch = 0.6831s	
3984/26050 (epoch 7.647), train_loss = 1.36586678, grad/param norm = 1.7790e-01, time/batch = 0.6633s	
3985/26050 (epoch 7.649), train_loss = 1.47316113, grad/param norm = 2.0476e-01, time/batch = 0.6437s	
3986/26050 (epoch 7.651), train_loss = 1.36190392, grad/param norm = 1.8599e-01, time/batch = 0.6395s	
3987/26050 (epoch 7.653), train_loss = 1.42161874, grad/param norm = 1.9355e-01, time/batch = 0.6391s	
3988/26050 (epoch 7.655), train_loss = 1.31512153, grad/param norm = 1.8161e-01, time/batch = 0.6426s	
3989/26050 (epoch 7.656), train_loss = 1.28632308, grad/param norm = 1.7673e-01, time/batch = 0.6451s	
3990/26050 (epoch 7.658), train_loss = 1.60418617, grad/param norm = 1.8854e-01, time/batch = 0.6392s	
3991/26050 (epoch 7.660), train_loss = 1.30928184, grad/param norm = 1.9708e-01, time/batch = 0.6408s	
3992/26050 (epoch 7.662), train_loss = 1.27271737, grad/param norm = 1.6750e-01, time/batch = 0.6517s	
3993/26050 (epoch 7.664), train_loss = 1.39560787, grad/param norm = 1.8966e-01, time/batch = 0.6476s	
3994/26050 (epoch 7.666), train_loss = 1.45795666, grad/param norm = 1.9966e-01, time/batch = 0.6446s	
3995/26050 (epoch 7.668), train_loss = 1.17973825, grad/param norm = 1.5652e-01, time/batch = 0.6412s	
3996/26050 (epoch 7.670), train_loss = 1.59952986, grad/param norm = 2.1413e-01, time/batch = 0.6438s	
3997/26050 (epoch 7.672), train_loss = 1.32937163, grad/param norm = 1.8276e-01, time/batch = 0.6417s	
3998/26050 (epoch 7.674), train_loss = 1.28346967, grad/param norm = 1.6150e-01, time/batch = 0.6802s	
3999/26050 (epoch 7.676), train_loss = 1.44413306, grad/param norm = 1.7976e-01, time/batch = 0.6626s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch7.68_1.6465.t7	
4000/26050 (epoch 7.678), train_loss = 1.55998664, grad/param norm = 1.9365e-01, time/batch = 0.6392s	
4001/26050 (epoch 7.679), train_loss = 1.82664307, grad/param norm = 2.2239e-01, time/batch = 0.6463s	
4002/26050 (epoch 7.681), train_loss = 1.43530742, grad/param norm = 1.9304e-01, time/batch = 0.6412s	
4003/26050 (epoch 7.683), train_loss = 1.35806210, grad/param norm = 1.9515e-01, time/batch = 0.6415s	
4004/26050 (epoch 7.685), train_loss = 1.35020643, grad/param norm = 1.6729e-01, time/batch = 0.6449s	
4005/26050 (epoch 7.687), train_loss = 1.20121708, grad/param norm = 1.6738e-01, time/batch = 0.6477s	
4006/26050 (epoch 7.689), train_loss = 1.38744665, grad/param norm = 1.8393e-01, time/batch = 0.6652s	
4007/26050 (epoch 7.691), train_loss = 1.12825556, grad/param norm = 1.6815e-01, time/batch = 0.6490s	
4008/26050 (epoch 7.693), train_loss = 1.32302616, grad/param norm = 1.8545e-01, time/batch = 0.6465s	
4009/26050 (epoch 7.695), train_loss = 1.43071138, grad/param norm = 1.8772e-01, time/batch = 0.6444s	
4010/26050 (epoch 7.697), train_loss = 1.26854969, grad/param norm = 1.8199e-01, time/batch = 0.6453s	
4011/26050 (epoch 7.699), train_loss = 1.47356773, grad/param norm = 1.8842e-01, time/batch = 0.6589s	
4012/26050 (epoch 7.701), train_loss = 1.23653015, grad/param norm = 1.7076e-01, time/batch = 0.6512s	
4013/26050 (epoch 7.702), train_loss = 1.64311523, grad/param norm = 1.8658e-01, time/batch = 0.6425s	
4014/26050 (epoch 7.704), train_loss = 1.40863120, grad/param norm = 1.7704e-01, time/batch = 0.6741s	
4015/26050 (epoch 7.706), train_loss = 1.49852002, grad/param norm = 2.1309e-01, time/batch = 0.6523s	
4016/26050 (epoch 7.708), train_loss = 1.47365718, grad/param norm = 1.7911e-01, time/batch = 0.6500s	
4017/26050 (epoch 7.710), train_loss = 1.48750025, grad/param norm = 1.8500e-01, time/batch = 0.6421s	
4018/26050 (epoch 7.712), train_loss = 1.59298350, grad/param norm = 1.9036e-01, time/batch = 0.6416s	
4019/26050 (epoch 7.714), train_loss = 1.27942317, grad/param norm = 1.8316e-01, time/batch = 0.6435s	
4020/26050 (epoch 7.716), train_loss = 1.66246840, grad/param norm = 2.1298e-01, time/batch = 0.6406s	
4021/26050 (epoch 7.718), train_loss = 1.51973442, grad/param norm = 1.9339e-01, time/batch = 0.6430s	
4022/26050 (epoch 7.720), train_loss = 1.33447783, grad/param norm = 1.8076e-01, time/batch = 0.6411s	
4023/26050 (epoch 7.722), train_loss = 1.27210840, grad/param norm = 1.7035e-01, time/batch = 0.6399s	
4024/26050 (epoch 7.724), train_loss = 1.27859305, grad/param norm = 1.8306e-01, time/batch = 0.6451s	
4025/26050 (epoch 7.726), train_loss = 1.51403298, grad/param norm = 1.8526e-01, time/batch = 0.6472s	
4026/26050 (epoch 7.727), train_loss = 1.48604663, grad/param norm = 1.8446e-01, time/batch = 0.6420s	
4027/26050 (epoch 7.729), train_loss = 1.49890820, grad/param norm = 1.9982e-01, time/batch = 0.6425s	
4028/26050 (epoch 7.731), train_loss = 1.40892435, grad/param norm = 1.6762e-01, time/batch = 0.6515s	
4029/26050 (epoch 7.733), train_loss = 1.38463661, grad/param norm = 2.0926e-01, time/batch = 0.6456s	
4030/26050 (epoch 7.735), train_loss = 1.62413027, grad/param norm = 2.0070e-01, time/batch = 0.6392s	
4031/26050 (epoch 7.737), train_loss = 1.44119946, grad/param norm = 1.9327e-01, time/batch = 0.6398s	
4032/26050 (epoch 7.739), train_loss = 1.44308158, grad/param norm = 1.8273e-01, time/batch = 0.6408s	
4033/26050 (epoch 7.741), train_loss = 1.31461522, grad/param norm = 1.7635e-01, time/batch = 0.6394s	
4034/26050 (epoch 7.743), train_loss = 1.50719797, grad/param norm = 2.2235e-01, time/batch = 0.6418s	
4035/26050 (epoch 7.745), train_loss = 1.27553314, grad/param norm = 1.7646e-01, time/batch = 0.6406s	
4036/26050 (epoch 7.747), train_loss = 1.31221791, grad/param norm = 1.8275e-01, time/batch = 0.6428s	
4037/26050 (epoch 7.749), train_loss = 1.51823324, grad/param norm = 1.9602e-01, time/batch = 0.6536s	
4038/26050 (epoch 7.750), train_loss = 1.37108883, grad/param norm = 1.7464e-01, time/batch = 0.6516s	
4039/26050 (epoch 7.752), train_loss = 1.44369392, grad/param norm = 2.0235e-01, time/batch = 0.6545s	
4040/26050 (epoch 7.754), train_loss = 1.37411101, grad/param norm = 1.8445e-01, time/batch = 0.6420s	
4041/26050 (epoch 7.756), train_loss = 1.49141633, grad/param norm = 1.9727e-01, time/batch = 0.6480s	
4042/26050 (epoch 7.758), train_loss = 1.43988523, grad/param norm = 1.9075e-01, time/batch = 0.6467s	
4043/26050 (epoch 7.760), train_loss = 1.51074448, grad/param norm = 2.0032e-01, time/batch = 0.6419s	
4044/26050 (epoch 7.762), train_loss = 1.30770693, grad/param norm = 1.7223e-01, time/batch = 0.6446s	
4045/26050 (epoch 7.764), train_loss = 1.52179396, grad/param norm = 1.9250e-01, time/batch = 0.6450s	
4046/26050 (epoch 7.766), train_loss = 1.51765233, grad/param norm = 1.9734e-01, time/batch = 0.6474s	
4047/26050 (epoch 7.768), train_loss = 1.30120433, grad/param norm = 1.6442e-01, time/batch = 0.6462s	
4048/26050 (epoch 7.770), train_loss = 1.40869504, grad/param norm = 1.8562e-01, time/batch = 0.6401s	
4049/26050 (epoch 7.772), train_loss = 1.40261151, grad/param norm = 1.8507e-01, time/batch = 0.6399s	
4050/26050 (epoch 7.774), train_loss = 1.30035105, grad/param norm = 1.9146e-01, time/batch = 0.6406s	
4051/26050 (epoch 7.775), train_loss = 1.11580482, grad/param norm = 1.7934e-01, time/batch = 0.6421s	
4052/26050 (epoch 7.777), train_loss = 1.33197216, grad/param norm = 1.8108e-01, time/batch = 0.6419s	
4053/26050 (epoch 7.779), train_loss = 1.37974299, grad/param norm = 1.8548e-01, time/batch = 0.6401s	
4054/26050 (epoch 7.781), train_loss = 1.36211668, grad/param norm = 1.8138e-01, time/batch = 0.6431s	
4055/26050 (epoch 7.783), train_loss = 1.31995871, grad/param norm = 1.6700e-01, time/batch = 0.6394s	
4056/26050 (epoch 7.785), train_loss = 1.36803159, grad/param norm = 1.9752e-01, time/batch = 0.6530s	
4057/26050 (epoch 7.787), train_loss = 1.33942617, grad/param norm = 1.7458e-01, time/batch = 0.6445s	
4058/26050 (epoch 7.789), train_loss = 1.40493222, grad/param norm = 1.9718e-01, time/batch = 0.6479s	
4059/26050 (epoch 7.791), train_loss = 1.41911447, grad/param norm = 1.8736e-01, time/batch = 0.6403s	
4060/26050 (epoch 7.793), train_loss = 1.39971796, grad/param norm = 1.9056e-01, time/batch = 0.6401s	
4061/26050 (epoch 7.795), train_loss = 1.23070523, grad/param norm = 1.7305e-01, time/batch = 0.6413s	
4062/26050 (epoch 7.797), train_loss = 1.27881693, grad/param norm = 1.6520e-01, time/batch = 0.6399s	
4063/26050 (epoch 7.798), train_loss = 1.27472702, grad/param norm = 1.8275e-01, time/batch = 0.6415s	
4064/26050 (epoch 7.800), train_loss = 1.25156454, grad/param norm = 1.6694e-01, time/batch = 0.6429s	
4065/26050 (epoch 7.802), train_loss = 1.40394026, grad/param norm = 1.8697e-01, time/batch = 0.6490s	
4066/26050 (epoch 7.804), train_loss = 1.37038287, grad/param norm = 1.7797e-01, time/batch = 0.6404s	
4067/26050 (epoch 7.806), train_loss = 1.55536562, grad/param norm = 2.0662e-01, time/batch = 0.6410s	
4068/26050 (epoch 7.808), train_loss = 1.35902198, grad/param norm = 1.7328e-01, time/batch = 0.6408s	
4069/26050 (epoch 7.810), train_loss = 1.32399022, grad/param norm = 1.8983e-01, time/batch = 0.6393s	
4070/26050 (epoch 7.812), train_loss = 1.27083793, grad/param norm = 1.8066e-01, time/batch = 0.6402s	
4071/26050 (epoch 7.814), train_loss = 1.26977348, grad/param norm = 1.9113e-01, time/batch = 0.6407s	
4072/26050 (epoch 7.816), train_loss = 1.47720212, grad/param norm = 1.9113e-01, time/batch = 0.6408s	
4073/26050 (epoch 7.818), train_loss = 1.57224311, grad/param norm = 2.1038e-01, time/batch = 0.6397s	
4074/26050 (epoch 7.820), train_loss = 1.43038903, grad/param norm = 1.8728e-01, time/batch = 0.6433s	
4075/26050 (epoch 7.821), train_loss = 1.57803428, grad/param norm = 2.1065e-01, time/batch = 0.6407s	
4076/26050 (epoch 7.823), train_loss = 1.62873600, grad/param norm = 1.9804e-01, time/batch = 0.6414s	
4077/26050 (epoch 7.825), train_loss = 1.34519537, grad/param norm = 1.9089e-01, time/batch = 0.6480s	
4078/26050 (epoch 7.827), train_loss = 1.47567643, grad/param norm = 2.0105e-01, time/batch = 0.6474s	
4079/26050 (epoch 7.829), train_loss = 1.47892532, grad/param norm = 1.9669e-01, time/batch = 0.6409s	
4080/26050 (epoch 7.831), train_loss = 1.55569684, grad/param norm = 1.9470e-01, time/batch = 0.6438s	
4081/26050 (epoch 7.833), train_loss = 1.61329104, grad/param norm = 1.8539e-01, time/batch = 0.6433s	
4082/26050 (epoch 7.835), train_loss = 1.66716633, grad/param norm = 1.9973e-01, time/batch = 0.6424s	
4083/26050 (epoch 7.837), train_loss = 1.35101060, grad/param norm = 1.7904e-01, time/batch = 0.6412s	
4084/26050 (epoch 7.839), train_loss = 1.49617169, grad/param norm = 1.8202e-01, time/batch = 0.6413s	
4085/26050 (epoch 7.841), train_loss = 1.51453259, grad/param norm = 1.7889e-01, time/batch = 0.6403s	
4086/26050 (epoch 7.843), train_loss = 1.47618732, grad/param norm = 1.8424e-01, time/batch = 0.6421s	
4087/26050 (epoch 7.845), train_loss = 1.32762591, grad/param norm = 1.7950e-01, time/batch = 0.6455s	
4088/26050 (epoch 7.846), train_loss = 1.54254743, grad/param norm = 1.8739e-01, time/batch = 0.6413s	
4089/26050 (epoch 7.848), train_loss = 1.36387428, grad/param norm = 1.8232e-01, time/batch = 0.6410s	
4090/26050 (epoch 7.850), train_loss = 1.35148510, grad/param norm = 1.7534e-01, time/batch = 0.6460s	
4091/26050 (epoch 7.852), train_loss = 1.39208452, grad/param norm = 1.9452e-01, time/batch = 0.6410s	
4092/26050 (epoch 7.854), train_loss = 1.42722631, grad/param norm = 1.8937e-01, time/batch = 0.6410s	
4093/26050 (epoch 7.856), train_loss = 1.32375297, grad/param norm = 1.8210e-01, time/batch = 0.6405s	
4094/26050 (epoch 7.858), train_loss = 1.29543857, grad/param norm = 1.8747e-01, time/batch = 0.6395s	
4095/26050 (epoch 7.860), train_loss = 1.45039783, grad/param norm = 2.0078e-01, time/batch = 0.6408s	
4096/26050 (epoch 7.862), train_loss = 1.42586020, grad/param norm = 1.8853e-01, time/batch = 0.6417s	
4097/26050 (epoch 7.864), train_loss = 1.36337251, grad/param norm = 1.9040e-01, time/batch = 0.6424s	
4098/26050 (epoch 7.866), train_loss = 1.29748431, grad/param norm = 1.6814e-01, time/batch = 0.6412s	
4099/26050 (epoch 7.868), train_loss = 1.53578238, grad/param norm = 2.0792e-01, time/batch = 0.6402s	
4100/26050 (epoch 7.869), train_loss = 1.24401439, grad/param norm = 1.6282e-01, time/batch = 0.6395s	
4101/26050 (epoch 7.871), train_loss = 1.21159877, grad/param norm = 1.6147e-01, time/batch = 0.6422s	
4102/26050 (epoch 7.873), train_loss = 1.43290067, grad/param norm = 1.7325e-01, time/batch = 0.6416s	
4103/26050 (epoch 7.875), train_loss = 1.38089425, grad/param norm = 1.7941e-01, time/batch = 0.6571s	
4104/26050 (epoch 7.877), train_loss = 1.24037394, grad/param norm = 1.7832e-01, time/batch = 0.6786s	
4105/26050 (epoch 7.879), train_loss = 1.37147953, grad/param norm = 1.6989e-01, time/batch = 0.6561s	
4106/26050 (epoch 7.881), train_loss = 1.58571821, grad/param norm = 1.9728e-01, time/batch = 0.6418s	
4107/26050 (epoch 7.883), train_loss = 1.41740460, grad/param norm = 1.7408e-01, time/batch = 0.6785s	
4108/26050 (epoch 7.885), train_loss = 1.11440518, grad/param norm = 1.5946e-01, time/batch = 0.6551s	
4109/26050 (epoch 7.887), train_loss = 1.45392834, grad/param norm = 1.7911e-01, time/batch = 0.6394s	
4110/26050 (epoch 7.889), train_loss = 1.30805588, grad/param norm = 1.6566e-01, time/batch = 0.6415s	
4111/26050 (epoch 7.891), train_loss = 1.15779970, grad/param norm = 1.5995e-01, time/batch = 0.6404s	
4112/26050 (epoch 7.893), train_loss = 1.12089116, grad/param norm = 1.5232e-01, time/batch = 0.6460s	
4113/26050 (epoch 7.894), train_loss = 1.28984233, grad/param norm = 1.6449e-01, time/batch = 0.6421s	
4114/26050 (epoch 7.896), train_loss = 1.50825502, grad/param norm = 1.8826e-01, time/batch = 0.6421s	
4115/26050 (epoch 7.898), train_loss = 1.33206766, grad/param norm = 1.9032e-01, time/batch = 0.6400s	
4116/26050 (epoch 7.900), train_loss = 1.61336031, grad/param norm = 1.9699e-01, time/batch = 0.6394s	
4117/26050 (epoch 7.902), train_loss = 1.40001823, grad/param norm = 1.7401e-01, time/batch = 0.6388s	
4118/26050 (epoch 7.904), train_loss = 1.33815451, grad/param norm = 1.7105e-01, time/batch = 0.6406s	
4119/26050 (epoch 7.906), train_loss = 1.36738873, grad/param norm = 1.7903e-01, time/batch = 0.6416s	
4120/26050 (epoch 7.908), train_loss = 1.36663177, grad/param norm = 1.8369e-01, time/batch = 0.6432s	
4121/26050 (epoch 7.910), train_loss = 1.30416160, grad/param norm = 1.6948e-01, time/batch = 0.6588s	
4122/26050 (epoch 7.912), train_loss = 1.67025114, grad/param norm = 1.9408e-01, time/batch = 0.6494s	
4123/26050 (epoch 7.914), train_loss = 1.85003089, grad/param norm = 1.9655e-01, time/batch = 0.6399s	
4124/26050 (epoch 7.916), train_loss = 1.57337930, grad/param norm = 2.0654e-01, time/batch = 0.6449s	
4125/26050 (epoch 7.917), train_loss = 1.45236520, grad/param norm = 1.9791e-01, time/batch = 0.6487s	
4126/26050 (epoch 7.919), train_loss = 1.51421777, grad/param norm = 1.9900e-01, time/batch = 0.6483s	
4127/26050 (epoch 7.921), train_loss = 1.31693583, grad/param norm = 2.1041e-01, time/batch = 0.6460s	
4128/26050 (epoch 7.923), train_loss = 1.38311610, grad/param norm = 1.9885e-01, time/batch = 0.6429s	
4129/26050 (epoch 7.925), train_loss = 1.34667253, grad/param norm = 1.7391e-01, time/batch = 0.6502s	
4130/26050 (epoch 7.927), train_loss = 1.26139374, grad/param norm = 1.5959e-01, time/batch = 0.6425s	
4131/26050 (epoch 7.929), train_loss = 1.31499944, grad/param norm = 1.8148e-01, time/batch = 0.6475s	
4132/26050 (epoch 7.931), train_loss = 1.66936677, grad/param norm = 2.2069e-01, time/batch = 0.6418s	
4133/26050 (epoch 7.933), train_loss = 1.36790121, grad/param norm = 1.9410e-01, time/batch = 0.6451s	
4134/26050 (epoch 7.935), train_loss = 1.31503124, grad/param norm = 1.7972e-01, time/batch = 0.6413s	
4135/26050 (epoch 7.937), train_loss = 1.39160484, grad/param norm = 1.6702e-01, time/batch = 0.6447s	
4136/26050 (epoch 7.939), train_loss = 1.27399482, grad/param norm = 1.6817e-01, time/batch = 0.6417s	
4137/26050 (epoch 7.940), train_loss = 1.41137840, grad/param norm = 1.7641e-01, time/batch = 0.6403s	
4138/26050 (epoch 7.942), train_loss = 1.43583923, grad/param norm = 1.9943e-01, time/batch = 0.6426s	
4139/26050 (epoch 7.944), train_loss = 1.35282327, grad/param norm = 1.8626e-01, time/batch = 0.6406s	
4140/26050 (epoch 7.946), train_loss = 1.54577292, grad/param norm = 1.8288e-01, time/batch = 0.6453s	
4141/26050 (epoch 7.948), train_loss = 1.20496249, grad/param norm = 2.0012e-01, time/batch = 0.6436s	
4142/26050 (epoch 7.950), train_loss = 1.36196334, grad/param norm = 1.7606e-01, time/batch = 0.6430s	
4143/26050 (epoch 7.952), train_loss = 1.55840215, grad/param norm = 1.9405e-01, time/batch = 0.6424s	
4144/26050 (epoch 7.954), train_loss = 1.49346056, grad/param norm = 1.8379e-01, time/batch = 0.6485s	
4145/26050 (epoch 7.956), train_loss = 1.49343068, grad/param norm = 1.9635e-01, time/batch = 0.6552s	
4146/26050 (epoch 7.958), train_loss = 1.39108303, grad/param norm = 1.8427e-01, time/batch = 0.6452s	
4147/26050 (epoch 7.960), train_loss = 1.35620438, grad/param norm = 1.7829e-01, time/batch = 0.6432s	
4148/26050 (epoch 7.962), train_loss = 1.30313856, grad/param norm = 1.7682e-01, time/batch = 0.6402s	
4149/26050 (epoch 7.964), train_loss = 1.36014444, grad/param norm = 1.7539e-01, time/batch = 0.6417s	
4150/26050 (epoch 7.965), train_loss = 1.25878569, grad/param norm = 1.7839e-01, time/batch = 0.6405s	
4151/26050 (epoch 7.967), train_loss = 1.72266544, grad/param norm = 1.8765e-01, time/batch = 0.6469s	
4152/26050 (epoch 7.969), train_loss = 1.34861372, grad/param norm = 1.6693e-01, time/batch = 0.6414s	
4153/26050 (epoch 7.971), train_loss = 1.25544341, grad/param norm = 1.6512e-01, time/batch = 0.6417s	
4154/26050 (epoch 7.973), train_loss = 1.36267307, grad/param norm = 1.9718e-01, time/batch = 0.6443s	
4155/26050 (epoch 7.975), train_loss = 1.46156732, grad/param norm = 1.6839e-01, time/batch = 0.6413s	
4156/26050 (epoch 7.977), train_loss = 1.40405358, grad/param norm = 1.6006e-01, time/batch = 0.6405s	
4157/26050 (epoch 7.979), train_loss = 1.22818811, grad/param norm = 1.7336e-01, time/batch = 0.6396s	
4158/26050 (epoch 7.981), train_loss = 1.49027924, grad/param norm = 1.8009e-01, time/batch = 0.6443s	
4159/26050 (epoch 7.983), train_loss = 1.49243161, grad/param norm = 1.8591e-01, time/batch = 0.6415s	
4160/26050 (epoch 7.985), train_loss = 1.42435078, grad/param norm = 1.8308e-01, time/batch = 0.6420s	
4161/26050 (epoch 7.987), train_loss = 1.56791016, grad/param norm = 1.9750e-01, time/batch = 0.6414s	
4162/26050 (epoch 7.988), train_loss = 1.52172267, grad/param norm = 2.2999e-01, time/batch = 0.6432s	
4163/26050 (epoch 7.990), train_loss = 1.32612944, grad/param norm = 1.7692e-01, time/batch = 0.6403s	
4164/26050 (epoch 7.992), train_loss = 1.58753384, grad/param norm = 2.0501e-01, time/batch = 0.6416s	
4165/26050 (epoch 7.994), train_loss = 1.40114353, grad/param norm = 1.9003e-01, time/batch = 0.6400s	
4166/26050 (epoch 7.996), train_loss = 1.39182469, grad/param norm = 2.1600e-01, time/batch = 0.6394s	
4167/26050 (epoch 7.998), train_loss = 1.41667145, grad/param norm = 1.9000e-01, time/batch = 0.6460s	
4168/26050 (epoch 8.000), train_loss = 1.37236451, grad/param norm = 1.8814e-01, time/batch = 0.6393s	
4169/26050 (epoch 8.002), train_loss = 1.43268816, grad/param norm = 1.8444e-01, time/batch = 0.6416s	
4170/26050 (epoch 8.004), train_loss = 1.32703969, grad/param norm = 1.9456e-01, time/batch = 0.6390s	
4171/26050 (epoch 8.006), train_loss = 1.31654206, grad/param norm = 1.6755e-01, time/batch = 0.6422s	
4172/26050 (epoch 8.008), train_loss = 1.29224328, grad/param norm = 1.7246e-01, time/batch = 0.6528s	
4173/26050 (epoch 8.010), train_loss = 1.35573679, grad/param norm = 1.7031e-01, time/batch = 0.6561s	
4174/26050 (epoch 8.012), train_loss = 1.44344130, grad/param norm = 1.8922e-01, time/batch = 0.6508s	
4175/26050 (epoch 8.013), train_loss = 1.83473126, grad/param norm = 2.0293e-01, time/batch = 0.6616s	
4176/26050 (epoch 8.015), train_loss = 1.26969666, grad/param norm = 1.6819e-01, time/batch = 0.6585s	
4177/26050 (epoch 8.017), train_loss = 1.42737209, grad/param norm = 1.8680e-01, time/batch = 0.6538s	
4178/26050 (epoch 8.019), train_loss = 1.19882478, grad/param norm = 1.5168e-01, time/batch = 0.6613s	
4179/26050 (epoch 8.021), train_loss = 1.52255120, grad/param norm = 1.9668e-01, time/batch = 0.6734s	
4180/26050 (epoch 8.023), train_loss = 1.24738076, grad/param norm = 1.7155e-01, time/batch = 0.6663s	
4181/26050 (epoch 8.025), train_loss = 1.32965155, grad/param norm = 1.7591e-01, time/batch = 0.6737s	
4182/26050 (epoch 8.027), train_loss = 1.15359752, grad/param norm = 1.6656e-01, time/batch = 0.6708s	
4183/26050 (epoch 8.029), train_loss = 1.34174991, grad/param norm = 1.6533e-01, time/batch = 0.6694s	
4184/26050 (epoch 8.031), train_loss = 1.58638958, grad/param norm = 2.0775e-01, time/batch = 0.6706s	
4185/26050 (epoch 8.033), train_loss = 1.43719820, grad/param norm = 1.8627e-01, time/batch = 0.6828s	
4186/26050 (epoch 8.035), train_loss = 1.53590233, grad/param norm = 1.8384e-01, time/batch = 0.6652s	
4187/26050 (epoch 8.036), train_loss = 1.34238294, grad/param norm = 2.0097e-01, time/batch = 0.6695s	
4188/26050 (epoch 8.038), train_loss = 1.19221702, grad/param norm = 1.6679e-01, time/batch = 0.6699s	
4189/26050 (epoch 8.040), train_loss = 1.45128343, grad/param norm = 1.7631e-01, time/batch = 0.6676s	
4190/26050 (epoch 8.042), train_loss = 1.25548427, grad/param norm = 1.7780e-01, time/batch = 0.6702s	
4191/26050 (epoch 8.044), train_loss = 1.43682097, grad/param norm = 1.8424e-01, time/batch = 0.6524s	
4192/26050 (epoch 8.046), train_loss = 1.18314484, grad/param norm = 1.8726e-01, time/batch = 0.6425s	
4193/26050 (epoch 8.048), train_loss = 1.41008656, grad/param norm = 1.8384e-01, time/batch = 0.6405s	
4194/26050 (epoch 8.050), train_loss = 1.27193179, grad/param norm = 1.9037e-01, time/batch = 0.6410s	
4195/26050 (epoch 8.052), train_loss = 1.37949793, grad/param norm = 1.8558e-01, time/batch = 0.6385s	
4196/26050 (epoch 8.054), train_loss = 1.20801245, grad/param norm = 1.6824e-01, time/batch = 0.6572s	
4197/26050 (epoch 8.056), train_loss = 1.08518074, grad/param norm = 1.4678e-01, time/batch = 0.6629s	
4198/26050 (epoch 8.058), train_loss = 1.28777137, grad/param norm = 1.6752e-01, time/batch = 0.6422s	
4199/26050 (epoch 8.060), train_loss = 1.36645189, grad/param norm = 1.6345e-01, time/batch = 0.6492s	
4200/26050 (epoch 8.061), train_loss = 1.26750086, grad/param norm = 1.7148e-01, time/batch = 0.6413s	
4201/26050 (epoch 8.063), train_loss = 1.33086912, grad/param norm = 1.6426e-01, time/batch = 0.6423s	
4202/26050 (epoch 8.065), train_loss = 1.19149689, grad/param norm = 1.7318e-01, time/batch = 0.6452s	
4203/26050 (epoch 8.067), train_loss = 1.45839199, grad/param norm = 1.9244e-01, time/batch = 0.6447s	
4204/26050 (epoch 8.069), train_loss = 1.44459202, grad/param norm = 1.7339e-01, time/batch = 0.6641s	
4205/26050 (epoch 8.071), train_loss = 1.45705451, grad/param norm = 1.9859e-01, time/batch = 0.6505s	
4206/26050 (epoch 8.073), train_loss = 1.60808852, grad/param norm = 1.7515e-01, time/batch = 0.6418s	
4207/26050 (epoch 8.075), train_loss = 1.26822945, grad/param norm = 1.7264e-01, time/batch = 0.6404s	
4208/26050 (epoch 8.077), train_loss = 1.27299472, grad/param norm = 1.7211e-01, time/batch = 0.6405s	
4209/26050 (epoch 8.079), train_loss = 1.46278407, grad/param norm = 1.9782e-01, time/batch = 0.6404s	
4210/26050 (epoch 8.081), train_loss = 1.33052970, grad/param norm = 1.9226e-01, time/batch = 0.6422s	
4211/26050 (epoch 8.083), train_loss = 1.45988363, grad/param norm = 1.8633e-01, time/batch = 0.6437s	
4212/26050 (epoch 8.084), train_loss = 1.53638623, grad/param norm = 2.1520e-01, time/batch = 0.6438s	
4213/26050 (epoch 8.086), train_loss = 1.51585657, grad/param norm = 1.8430e-01, time/batch = 0.6402s	
4214/26050 (epoch 8.088), train_loss = 1.24106084, grad/param norm = 1.6307e-01, time/batch = 0.6410s	
4215/26050 (epoch 8.090), train_loss = 1.47630303, grad/param norm = 1.8253e-01, time/batch = 0.6542s	
4216/26050 (epoch 8.092), train_loss = 1.37060019, grad/param norm = 1.8866e-01, time/batch = 0.6562s	
4217/26050 (epoch 8.094), train_loss = 1.37761624, grad/param norm = 1.7775e-01, time/batch = 0.6421s	
4218/26050 (epoch 8.096), train_loss = 1.30683954, grad/param norm = 1.7627e-01, time/batch = 0.6397s	
4219/26050 (epoch 8.098), train_loss = 1.30770829, grad/param norm = 1.7429e-01, time/batch = 0.6410s	
4220/26050 (epoch 8.100), train_loss = 1.27506982, grad/param norm = 1.8520e-01, time/batch = 0.6391s	
4221/26050 (epoch 8.102), train_loss = 1.40983696, grad/param norm = 1.8521e-01, time/batch = 0.6413s	
4222/26050 (epoch 8.104), train_loss = 1.42608912, grad/param norm = 1.8218e-01, time/batch = 0.6412s	
4223/26050 (epoch 8.106), train_loss = 1.33476212, grad/param norm = 1.7727e-01, time/batch = 0.6396s	
4224/26050 (epoch 8.107), train_loss = 1.11466166, grad/param norm = 1.7372e-01, time/batch = 0.6404s	
4225/26050 (epoch 8.109), train_loss = 1.28819559, grad/param norm = 1.7556e-01, time/batch = 0.6393s	
4226/26050 (epoch 8.111), train_loss = 1.61326786, grad/param norm = 2.0842e-01, time/batch = 0.6660s	
4227/26050 (epoch 8.113), train_loss = 1.31085420, grad/param norm = 1.8704e-01, time/batch = 0.6548s	
4228/26050 (epoch 8.115), train_loss = 1.49489942, grad/param norm = 1.7958e-01, time/batch = 0.6422s	
4229/26050 (epoch 8.117), train_loss = 1.44032285, grad/param norm = 1.8986e-01, time/batch = 0.6400s	
4230/26050 (epoch 8.119), train_loss = 1.15341931, grad/param norm = 1.6903e-01, time/batch = 0.6390s	
4231/26050 (epoch 8.121), train_loss = 1.43521503, grad/param norm = 1.8124e-01, time/batch = 0.6391s	
4232/26050 (epoch 8.123), train_loss = 1.31626380, grad/param norm = 2.0539e-01, time/batch = 0.6392s	
4233/26050 (epoch 8.125), train_loss = 1.15934892, grad/param norm = 1.5314e-01, time/batch = 0.6404s	
4234/26050 (epoch 8.127), train_loss = 1.14476072, grad/param norm = 1.7080e-01, time/batch = 0.6463s	
4235/26050 (epoch 8.129), train_loss = 1.14490407, grad/param norm = 1.6133e-01, time/batch = 0.6534s	
4236/26050 (epoch 8.131), train_loss = 1.36464423, grad/param norm = 1.8204e-01, time/batch = 0.6551s	
4237/26050 (epoch 8.132), train_loss = 1.30338245, grad/param norm = 1.7410e-01, time/batch = 0.6390s	
4238/26050 (epoch 8.134), train_loss = 1.32578454, grad/param norm = 1.8155e-01, time/batch = 0.6393s	
4239/26050 (epoch 8.136), train_loss = 1.34566790, grad/param norm = 1.7516e-01, time/batch = 0.6378s	
4240/26050 (epoch 8.138), train_loss = 1.19907446, grad/param norm = 1.9343e-01, time/batch = 0.6385s	
4241/26050 (epoch 8.140), train_loss = 1.24125905, grad/param norm = 1.7372e-01, time/batch = 0.6415s	
4242/26050 (epoch 8.142), train_loss = 1.29669117, grad/param norm = 1.7644e-01, time/batch = 0.6437s	
4243/26050 (epoch 8.144), train_loss = 1.16814540, grad/param norm = 1.6468e-01, time/batch = 0.6432s	
4244/26050 (epoch 8.146), train_loss = 1.09292355, grad/param norm = 1.5754e-01, time/batch = 0.6445s	
4245/26050 (epoch 8.148), train_loss = 1.11408680, grad/param norm = 1.4229e-01, time/batch = 0.6486s	
4246/26050 (epoch 8.150), train_loss = 1.34066603, grad/param norm = 1.9404e-01, time/batch = 0.6556s	
4247/26050 (epoch 8.152), train_loss = 1.63279887, grad/param norm = 2.0162e-01, time/batch = 0.6569s	
4248/26050 (epoch 8.154), train_loss = 1.16516863, grad/param norm = 1.8318e-01, time/batch = 0.6547s	
4249/26050 (epoch 8.155), train_loss = 1.17231012, grad/param norm = 1.6207e-01, time/batch = 0.6567s	
4250/26050 (epoch 8.157), train_loss = 1.34879723, grad/param norm = 1.9048e-01, time/batch = 0.6559s	
4251/26050 (epoch 8.159), train_loss = 1.34914864, grad/param norm = 1.8524e-01, time/batch = 0.6499s	
4252/26050 (epoch 8.161), train_loss = 1.54134496, grad/param norm = 2.1486e-01, time/batch = 0.6502s	
4253/26050 (epoch 8.163), train_loss = 1.20341446, grad/param norm = 1.6985e-01, time/batch = 0.6588s	
4254/26050 (epoch 8.165), train_loss = 1.05791081, grad/param norm = 1.5777e-01, time/batch = 0.6574s	
4255/26050 (epoch 8.167), train_loss = 1.48600616, grad/param norm = 2.1134e-01, time/batch = 0.6554s	
4256/26050 (epoch 8.169), train_loss = 1.42015517, grad/param norm = 1.8106e-01, time/batch = 0.6571s	
4257/26050 (epoch 8.171), train_loss = 1.13330483, grad/param norm = 1.5066e-01, time/batch = 0.6548s	
4258/26050 (epoch 8.173), train_loss = 1.31015815, grad/param norm = 1.8708e-01, time/batch = 0.6426s	
4259/26050 (epoch 8.175), train_loss = 1.35655671, grad/param norm = 1.8331e-01, time/batch = 0.6436s	
4260/26050 (epoch 8.177), train_loss = 1.43529692, grad/param norm = 1.8038e-01, time/batch = 0.6404s	
4261/26050 (epoch 8.179), train_loss = 1.05785330, grad/param norm = 1.6075e-01, time/batch = 0.6488s	
4262/26050 (epoch 8.180), train_loss = 1.61495112, grad/param norm = 1.8023e-01, time/batch = 0.6556s	
4263/26050 (epoch 8.182), train_loss = 1.64013231, grad/param norm = 1.9092e-01, time/batch = 0.6388s	
4264/26050 (epoch 8.184), train_loss = 1.37870310, grad/param norm = 1.7517e-01, time/batch = 0.6477s	
4265/26050 (epoch 8.186), train_loss = 1.11773647, grad/param norm = 1.5674e-01, time/batch = 0.6435s	
4266/26050 (epoch 8.188), train_loss = 1.33580288, grad/param norm = 1.6647e-01, time/batch = 0.6458s	
4267/26050 (epoch 8.190), train_loss = 1.40159521, grad/param norm = 1.8505e-01, time/batch = 0.6453s	
4268/26050 (epoch 8.192), train_loss = 1.39382672, grad/param norm = 1.7864e-01, time/batch = 0.6387s	
4269/26050 (epoch 8.194), train_loss = 1.38792438, grad/param norm = 1.7963e-01, time/batch = 0.6373s	
4270/26050 (epoch 8.196), train_loss = 1.45235801, grad/param norm = 1.8952e-01, time/batch = 0.6379s	
4271/26050 (epoch 8.198), train_loss = 1.28640247, grad/param norm = 1.8719e-01, time/batch = 0.6395s	
4272/26050 (epoch 8.200), train_loss = 1.27295683, grad/param norm = 1.8486e-01, time/batch = 0.6399s	
4273/26050 (epoch 8.202), train_loss = 1.28027682, grad/param norm = 1.8588e-01, time/batch = 0.6400s	
4274/26050 (epoch 8.203), train_loss = 1.44036110, grad/param norm = 2.0403e-01, time/batch = 0.6409s	
4275/26050 (epoch 8.205), train_loss = 1.24923703, grad/param norm = 1.7488e-01, time/batch = 0.6423s	
4276/26050 (epoch 8.207), train_loss = 1.33189911, grad/param norm = 1.6158e-01, time/batch = 0.6593s	
4277/26050 (epoch 8.209), train_loss = 1.32957390, grad/param norm = 1.7917e-01, time/batch = 0.6717s	
4278/26050 (epoch 8.211), train_loss = 1.19026993, grad/param norm = 1.6866e-01, time/batch = 0.6557s	
4279/26050 (epoch 8.213), train_loss = 1.39478763, grad/param norm = 1.7051e-01, time/batch = 0.6427s	
4280/26050 (epoch 8.215), train_loss = 1.39893367, grad/param norm = 2.0154e-01, time/batch = 0.6513s	
4281/26050 (epoch 8.217), train_loss = 1.29458060, grad/param norm = 1.7031e-01, time/batch = 0.6426s	
4282/26050 (epoch 8.219), train_loss = 1.27324332, grad/param norm = 1.8553e-01, time/batch = 0.6404s	
4283/26050 (epoch 8.221), train_loss = 1.19593355, grad/param norm = 1.6704e-01, time/batch = 0.6383s	
4284/26050 (epoch 8.223), train_loss = 1.42558583, grad/param norm = 1.9041e-01, time/batch = 0.6391s	
4285/26050 (epoch 8.225), train_loss = 1.25523340, grad/param norm = 1.9658e-01, time/batch = 0.6379s	
4286/26050 (epoch 8.226), train_loss = 1.50320974, grad/param norm = 1.8835e-01, time/batch = 0.6393s	
4287/26050 (epoch 8.228), train_loss = 1.51273216, grad/param norm = 1.9627e-01, time/batch = 0.6406s	
4288/26050 (epoch 8.230), train_loss = 1.39424640, grad/param norm = 1.8431e-01, time/batch = 0.6469s	
4289/26050 (epoch 8.232), train_loss = 1.48837895, grad/param norm = 2.0083e-01, time/batch = 0.6565s	
4290/26050 (epoch 8.234), train_loss = 1.17624375, grad/param norm = 1.7828e-01, time/batch = 0.6628s	
4291/26050 (epoch 8.236), train_loss = 1.41901033, grad/param norm = 2.0084e-01, time/batch = 0.6445s	
4292/26050 (epoch 8.238), train_loss = 1.15309506, grad/param norm = 1.7749e-01, time/batch = 0.6554s	
4293/26050 (epoch 8.240), train_loss = 1.28969760, grad/param norm = 1.7155e-01, time/batch = 0.6452s	
4294/26050 (epoch 8.242), train_loss = 1.30744591, grad/param norm = 1.6903e-01, time/batch = 0.6455s	
4295/26050 (epoch 8.244), train_loss = 1.40735025, grad/param norm = 2.0379e-01, time/batch = 0.6423s	
4296/26050 (epoch 8.246), train_loss = 1.26875209, grad/param norm = 1.6202e-01, time/batch = 0.6442s	
4297/26050 (epoch 8.248), train_loss = 1.39195277, grad/param norm = 1.8147e-01, time/batch = 0.6481s	
4298/26050 (epoch 8.250), train_loss = 1.38006071, grad/param norm = 1.9710e-01, time/batch = 0.6448s	
4299/26050 (epoch 8.251), train_loss = 1.24434842, grad/param norm = 1.7332e-01, time/batch = 0.6424s	
4300/26050 (epoch 8.253), train_loss = 1.15948361, grad/param norm = 1.7895e-01, time/batch = 0.6412s	
4301/26050 (epoch 8.255), train_loss = 1.58029275, grad/param norm = 1.9234e-01, time/batch = 0.6440s	
4302/26050 (epoch 8.257), train_loss = 1.35550967, grad/param norm = 1.9898e-01, time/batch = 0.6420s	
4303/26050 (epoch 8.259), train_loss = 1.49506449, grad/param norm = 1.8326e-01, time/batch = 0.6434s	
4304/26050 (epoch 8.261), train_loss = 1.29073080, grad/param norm = 1.9008e-01, time/batch = 0.6468s	
4305/26050 (epoch 8.263), train_loss = 1.34099578, grad/param norm = 1.8312e-01, time/batch = 0.6456s	
4306/26050 (epoch 8.265), train_loss = 1.53776758, grad/param norm = 1.8076e-01, time/batch = 0.6410s	
4307/26050 (epoch 8.267), train_loss = 1.41616301, grad/param norm = 1.8530e-01, time/batch = 0.6409s	
4308/26050 (epoch 8.269), train_loss = 1.54577508, grad/param norm = 1.9349e-01, time/batch = 0.6418s	
4309/26050 (epoch 8.271), train_loss = 1.37321272, grad/param norm = 1.7981e-01, time/batch = 0.6479s	
4310/26050 (epoch 8.273), train_loss = 1.29934634, grad/param norm = 1.7819e-01, time/batch = 0.6423s	
4311/26050 (epoch 8.274), train_loss = 1.28791429, grad/param norm = 1.7594e-01, time/batch = 0.6471s	
4312/26050 (epoch 8.276), train_loss = 1.26832839, grad/param norm = 1.8348e-01, time/batch = 0.6603s	
4313/26050 (epoch 8.278), train_loss = 1.45930440, grad/param norm = 1.8578e-01, time/batch = 0.6608s	
4314/26050 (epoch 8.280), train_loss = 1.32521871, grad/param norm = 1.6673e-01, time/batch = 0.6434s	
4315/26050 (epoch 8.282), train_loss = 1.39981111, grad/param norm = 1.9423e-01, time/batch = 0.6410s	
4316/26050 (epoch 8.284), train_loss = 1.23424662, grad/param norm = 1.7921e-01, time/batch = 0.6416s	
4317/26050 (epoch 8.286), train_loss = 1.33014154, grad/param norm = 1.9090e-01, time/batch = 0.6598s	
4318/26050 (epoch 8.288), train_loss = 1.16923163, grad/param norm = 1.5990e-01, time/batch = 0.6554s	
4319/26050 (epoch 8.290), train_loss = 1.32220564, grad/param norm = 1.7893e-01, time/batch = 0.6427s	
4320/26050 (epoch 8.292), train_loss = 1.27604261, grad/param norm = 1.7095e-01, time/batch = 0.6510s	
4321/26050 (epoch 8.294), train_loss = 1.36672373, grad/param norm = 1.9575e-01, time/batch = 0.6403s	
4322/26050 (epoch 8.296), train_loss = 1.46101476, grad/param norm = 1.8625e-01, time/batch = 0.6402s	
4323/26050 (epoch 8.298), train_loss = 1.32899795, grad/param norm = 1.7310e-01, time/batch = 0.6396s	
4324/26050 (epoch 8.299), train_loss = 1.09569726, grad/param norm = 1.4884e-01, time/batch = 0.6394s	
4325/26050 (epoch 8.301), train_loss = 1.28248417, grad/param norm = 1.8479e-01, time/batch = 0.6392s	
4326/26050 (epoch 8.303), train_loss = 1.39543007, grad/param norm = 1.8021e-01, time/batch = 0.6391s	
4327/26050 (epoch 8.305), train_loss = 1.18391655, grad/param norm = 1.7111e-01, time/batch = 0.6403s	
4328/26050 (epoch 8.307), train_loss = 1.22752557, grad/param norm = 1.7906e-01, time/batch = 0.6409s	
4329/26050 (epoch 8.309), train_loss = 1.30686015, grad/param norm = 1.8701e-01, time/batch = 0.6384s	
4330/26050 (epoch 8.311), train_loss = 1.54263759, grad/param norm = 2.0611e-01, time/batch = 0.6411s	
4331/26050 (epoch 8.313), train_loss = 1.34688239, grad/param norm = 1.9361e-01, time/batch = 0.6403s	
4332/26050 (epoch 8.315), train_loss = 1.49393158, grad/param norm = 1.9319e-01, time/batch = 0.6401s	
4333/26050 (epoch 8.317), train_loss = 1.27285341, grad/param norm = 1.7481e-01, time/batch = 0.6430s	
4334/26050 (epoch 8.319), train_loss = 1.31710431, grad/param norm = 1.6269e-01, time/batch = 0.6577s	
4335/26050 (epoch 8.321), train_loss = 1.31711217, grad/param norm = 1.8623e-01, time/batch = 0.6603s	
4336/26050 (epoch 8.322), train_loss = 1.35680258, grad/param norm = 1.7647e-01, time/batch = 0.6625s	
4337/26050 (epoch 8.324), train_loss = 1.14867426, grad/param norm = 1.7175e-01, time/batch = 0.6392s	
4338/26050 (epoch 8.326), train_loss = 1.49277146, grad/param norm = 1.9725e-01, time/batch = 0.6435s	
4339/26050 (epoch 8.328), train_loss = 1.38502785, grad/param norm = 1.7933e-01, time/batch = 0.6412s	
4340/26050 (epoch 8.330), train_loss = 1.23378957, grad/param norm = 1.7670e-01, time/batch = 0.6398s	
4341/26050 (epoch 8.332), train_loss = 1.43778722, grad/param norm = 1.8476e-01, time/batch = 0.6461s	
4342/26050 (epoch 8.334), train_loss = 1.31386244, grad/param norm = 1.7526e-01, time/batch = 0.6492s	
4343/26050 (epoch 8.336), train_loss = 1.21783957, grad/param norm = 1.6123e-01, time/batch = 0.6796s	
4344/26050 (epoch 8.338), train_loss = 1.18581659, grad/param norm = 1.5926e-01, time/batch = 0.6683s	
4345/26050 (epoch 8.340), train_loss = 1.44244435, grad/param norm = 1.9991e-01, time/batch = 0.6417s	
4346/26050 (epoch 8.342), train_loss = 1.49719876, grad/param norm = 1.8975e-01, time/batch = 0.6383s	
4347/26050 (epoch 8.344), train_loss = 1.33558395, grad/param norm = 1.9861e-01, time/batch = 0.6380s	
4348/26050 (epoch 8.345), train_loss = 1.34620243, grad/param norm = 2.0086e-01, time/batch = 0.6382s	
4349/26050 (epoch 8.347), train_loss = 1.41693660, grad/param norm = 1.8817e-01, time/batch = 0.6408s	
4350/26050 (epoch 8.349), train_loss = 1.36861669, grad/param norm = 1.8430e-01, time/batch = 0.6417s	
4351/26050 (epoch 8.351), train_loss = 1.38736480, grad/param norm = 1.9596e-01, time/batch = 0.6425s	
4352/26050 (epoch 8.353), train_loss = 1.28346412, grad/param norm = 1.8914e-01, time/batch = 0.6414s	
4353/26050 (epoch 8.355), train_loss = 1.44435228, grad/param norm = 1.9032e-01, time/batch = 0.6418s	
4354/26050 (epoch 8.357), train_loss = 1.19710946, grad/param norm = 1.6000e-01, time/batch = 0.6558s	
4355/26050 (epoch 8.359), train_loss = 1.44614522, grad/param norm = 1.9175e-01, time/batch = 0.6562s	
4356/26050 (epoch 8.361), train_loss = 1.24875864, grad/param norm = 1.7396e-01, time/batch = 0.6569s	
4357/26050 (epoch 8.363), train_loss = 1.36280303, grad/param norm = 1.7471e-01, time/batch = 0.6559s	
4358/26050 (epoch 8.365), train_loss = 1.25710894, grad/param norm = 1.6370e-01, time/batch = 0.6496s	
4359/26050 (epoch 8.367), train_loss = 1.33984882, grad/param norm = 1.7837e-01, time/batch = 0.6410s	
4360/26050 (epoch 8.369), train_loss = 1.30150325, grad/param norm = 1.6248e-01, time/batch = 0.6376s	
4361/26050 (epoch 8.370), train_loss = 1.22323073, grad/param norm = 1.6182e-01, time/batch = 0.6415s	
4362/26050 (epoch 8.372), train_loss = 1.45185454, grad/param norm = 1.9599e-01, time/batch = 0.6392s	
4363/26050 (epoch 8.374), train_loss = 1.55819353, grad/param norm = 2.0673e-01, time/batch = 0.6376s	
4364/26050 (epoch 8.376), train_loss = 1.58830281, grad/param norm = 1.8696e-01, time/batch = 0.6381s	
4365/26050 (epoch 8.378), train_loss = 1.32759760, grad/param norm = 1.8413e-01, time/batch = 0.6387s	
4366/26050 (epoch 8.380), train_loss = 1.55942206, grad/param norm = 1.9415e-01, time/batch = 0.6467s	
4367/26050 (epoch 8.382), train_loss = 1.69974339, grad/param norm = 2.1210e-01, time/batch = 0.6389s	
4368/26050 (epoch 8.384), train_loss = 1.31677017, grad/param norm = 1.7484e-01, time/batch = 0.6382s	
4369/26050 (epoch 8.386), train_loss = 1.45960143, grad/param norm = 1.8443e-01, time/batch = 0.6373s	
4370/26050 (epoch 8.388), train_loss = 1.38006543, grad/param norm = 1.6994e-01, time/batch = 0.6383s	
4371/26050 (epoch 8.390), train_loss = 1.21351580, grad/param norm = 1.6362e-01, time/batch = 0.6399s	
4372/26050 (epoch 8.392), train_loss = 1.22947251, grad/param norm = 1.6623e-01, time/batch = 0.6389s	
4373/26050 (epoch 8.393), train_loss = 1.40961285, grad/param norm = 1.7382e-01, time/batch = 0.6395s	
4374/26050 (epoch 8.395), train_loss = 1.41972513, grad/param norm = 1.7729e-01, time/batch = 0.6385s	
4375/26050 (epoch 8.397), train_loss = 1.40572589, grad/param norm = 1.9117e-01, time/batch = 0.6376s	
4376/26050 (epoch 8.399), train_loss = 1.21737584, grad/param norm = 1.6076e-01, time/batch = 0.6463s	
4377/26050 (epoch 8.401), train_loss = 1.28570886, grad/param norm = 1.6412e-01, time/batch = 0.6424s	
4378/26050 (epoch 8.403), train_loss = 1.36625667, grad/param norm = 1.7677e-01, time/batch = 0.6436s	
4379/26050 (epoch 8.405), train_loss = 1.34569600, grad/param norm = 1.8059e-01, time/batch = 0.6391s	
4380/26050 (epoch 8.407), train_loss = 1.51777194, grad/param norm = 1.9083e-01, time/batch = 0.6413s	
4381/26050 (epoch 8.409), train_loss = 1.54330096, grad/param norm = 1.9976e-01, time/batch = 0.6616s	
4382/26050 (epoch 8.411), train_loss = 1.40334389, grad/param norm = 1.8464e-01, time/batch = 0.6502s	
4383/26050 (epoch 8.413), train_loss = 1.48793828, grad/param norm = 1.7705e-01, time/batch = 0.6552s	
4384/26050 (epoch 8.415), train_loss = 1.48711223, grad/param norm = 1.9383e-01, time/batch = 0.6482s	
4385/26050 (epoch 8.417), train_loss = 1.57697269, grad/param norm = 1.9492e-01, time/batch = 0.6424s	
4386/26050 (epoch 8.418), train_loss = 1.45610826, grad/param norm = 2.0095e-01, time/batch = 0.6433s	
4387/26050 (epoch 8.420), train_loss = 1.14615466, grad/param norm = 1.5957e-01, time/batch = 0.6398s	
4388/26050 (epoch 8.422), train_loss = 1.21709281, grad/param norm = 1.7937e-01, time/batch = 0.6552s	
4389/26050 (epoch 8.424), train_loss = 1.57672392, grad/param norm = 2.1371e-01, time/batch = 0.6436s	
4390/26050 (epoch 8.426), train_loss = 1.52048331, grad/param norm = 1.9903e-01, time/batch = 0.6411s	
4391/26050 (epoch 8.428), train_loss = 1.25480486, grad/param norm = 1.6124e-01, time/batch = 0.6423s	
4392/26050 (epoch 8.430), train_loss = 1.40881480, grad/param norm = 1.9707e-01, time/batch = 0.6398s	
4393/26050 (epoch 8.432), train_loss = 1.30041672, grad/param norm = 1.8027e-01, time/batch = 0.6389s	
4394/26050 (epoch 8.434), train_loss = 1.36705272, grad/param norm = 1.8481e-01, time/batch = 0.6374s	
4395/26050 (epoch 8.436), train_loss = 1.49083238, grad/param norm = 1.7474e-01, time/batch = 0.6383s	
4396/26050 (epoch 8.438), train_loss = 1.23396796, grad/param norm = 1.6672e-01, time/batch = 0.6388s	
4397/26050 (epoch 8.440), train_loss = 1.39146584, grad/param norm = 1.7822e-01, time/batch = 0.6429s	
4398/26050 (epoch 8.441), train_loss = 1.35434524, grad/param norm = 1.7520e-01, time/batch = 0.6402s	
4399/26050 (epoch 8.443), train_loss = 1.14560404, grad/param norm = 1.5066e-01, time/batch = 0.6381s	
4400/26050 (epoch 8.445), train_loss = 1.22045255, grad/param norm = 1.7207e-01, time/batch = 0.6384s	
4401/26050 (epoch 8.447), train_loss = 1.57961718, grad/param norm = 1.9097e-01, time/batch = 0.6492s	
4402/26050 (epoch 8.449), train_loss = 1.25107550, grad/param norm = 1.7367e-01, time/batch = 0.6478s	
4403/26050 (epoch 8.451), train_loss = 1.45640177, grad/param norm = 1.6736e-01, time/batch = 0.6416s	
4404/26050 (epoch 8.453), train_loss = 1.21606493, grad/param norm = 1.6316e-01, time/batch = 0.6433s	
4405/26050 (epoch 8.455), train_loss = 1.37847759, grad/param norm = 1.7571e-01, time/batch = 0.6425s	
4406/26050 (epoch 8.457), train_loss = 1.38193959, grad/param norm = 1.7786e-01, time/batch = 0.6401s	
4407/26050 (epoch 8.459), train_loss = 1.48420373, grad/param norm = 1.8720e-01, time/batch = 0.6420s	
4408/26050 (epoch 8.461), train_loss = 1.42438079, grad/param norm = 1.8969e-01, time/batch = 0.6420s	
4409/26050 (epoch 8.463), train_loss = 1.27821846, grad/param norm = 1.6193e-01, time/batch = 0.6414s	
4410/26050 (epoch 8.464), train_loss = 1.43038510, grad/param norm = 1.8577e-01, time/batch = 0.6490s	
4411/26050 (epoch 8.466), train_loss = 1.45740488, grad/param norm = 1.8749e-01, time/batch = 0.6464s	
4412/26050 (epoch 8.468), train_loss = 1.45909910, grad/param norm = 1.7089e-01, time/batch = 0.6484s	
4413/26050 (epoch 8.470), train_loss = 1.57439462, grad/param norm = 1.9903e-01, time/batch = 0.6445s	
4414/26050 (epoch 8.472), train_loss = 1.56370901, grad/param norm = 1.9023e-01, time/batch = 0.6409s	
4415/26050 (epoch 8.474), train_loss = 1.63168519, grad/param norm = 1.8591e-01, time/batch = 0.6404s	
4416/26050 (epoch 8.476), train_loss = 1.44592406, grad/param norm = 1.6979e-01, time/batch = 0.6465s	
4417/26050 (epoch 8.478), train_loss = 1.26455652, grad/param norm = 1.5924e-01, time/batch = 0.6637s	
4418/26050 (epoch 8.480), train_loss = 1.37866554, grad/param norm = 1.6033e-01, time/batch = 0.6734s	
4419/26050 (epoch 8.482), train_loss = 1.33626573, grad/param norm = 1.7707e-01, time/batch = 0.6764s	
4420/26050 (epoch 8.484), train_loss = 1.23911897, grad/param norm = 1.8041e-01, time/batch = 0.6747s	
4421/26050 (epoch 8.486), train_loss = 1.53185457, grad/param norm = 1.8074e-01, time/batch = 0.6758s	
4422/26050 (epoch 8.488), train_loss = 1.72034099, grad/param norm = 1.9683e-01, time/batch = 0.6632s	
4423/26050 (epoch 8.489), train_loss = 1.63999215, grad/param norm = 2.0184e-01, time/batch = 0.6412s	
4424/26050 (epoch 8.491), train_loss = 1.27921915, grad/param norm = 1.6782e-01, time/batch = 0.6390s	
4425/26050 (epoch 8.493), train_loss = 1.31867068, grad/param norm = 1.7302e-01, time/batch = 0.6390s	
4426/26050 (epoch 8.495), train_loss = 1.32827537, grad/param norm = 1.6755e-01, time/batch = 0.6396s	
4427/26050 (epoch 8.497), train_loss = 1.31477584, grad/param norm = 1.7532e-01, time/batch = 0.6501s	
4428/26050 (epoch 8.499), train_loss = 1.31724523, grad/param norm = 1.7866e-01, time/batch = 0.6494s	
4429/26050 (epoch 8.501), train_loss = 1.40283750, grad/param norm = 1.9173e-01, time/batch = 0.6407s	
4430/26050 (epoch 8.503), train_loss = 1.29632898, grad/param norm = 1.8451e-01, time/batch = 0.6399s	
4431/26050 (epoch 8.505), train_loss = 1.50082033, grad/param norm = 1.7890e-01, time/batch = 0.6418s	
4432/26050 (epoch 8.507), train_loss = 1.50067177, grad/param norm = 1.8296e-01, time/batch = 0.6422s	
4433/26050 (epoch 8.509), train_loss = 1.60621112, grad/param norm = 2.1317e-01, time/batch = 0.6446s	
4434/26050 (epoch 8.511), train_loss = 1.27470561, grad/param norm = 1.7745e-01, time/batch = 0.6551s	
4435/26050 (epoch 8.512), train_loss = 1.37935903, grad/param norm = 1.9180e-01, time/batch = 0.6496s	
4436/26050 (epoch 8.514), train_loss = 1.43799636, grad/param norm = 1.8291e-01, time/batch = 0.6581s	
4437/26050 (epoch 8.516), train_loss = 1.48558639, grad/param norm = 1.8796e-01, time/batch = 0.6661s	
4438/26050 (epoch 8.518), train_loss = 1.43147855, grad/param norm = 1.8324e-01, time/batch = 0.6509s	
4439/26050 (epoch 8.520), train_loss = 1.39948591, grad/param norm = 1.8660e-01, time/batch = 0.6490s	
4440/26050 (epoch 8.522), train_loss = 1.20577021, grad/param norm = 1.6921e-01, time/batch = 0.6497s	
4441/26050 (epoch 8.524), train_loss = 1.55396577, grad/param norm = 1.9300e-01, time/batch = 0.6542s	
4442/26050 (epoch 8.526), train_loss = 1.45877597, grad/param norm = 1.8888e-01, time/batch = 0.6507s	
4443/26050 (epoch 8.528), train_loss = 1.43899762, grad/param norm = 1.9117e-01, time/batch = 0.6511s	
4444/26050 (epoch 8.530), train_loss = 1.35355189, grad/param norm = 1.7064e-01, time/batch = 0.6595s	
4445/26050 (epoch 8.532), train_loss = 1.38046746, grad/param norm = 1.8492e-01, time/batch = 0.6516s	
4446/26050 (epoch 8.534), train_loss = 1.46856252, grad/param norm = 2.0135e-01, time/batch = 0.6513s	
4447/26050 (epoch 8.536), train_loss = 1.31452826, grad/param norm = 1.6853e-01, time/batch = 0.6535s	
4448/26050 (epoch 8.537), train_loss = 1.49951697, grad/param norm = 1.9348e-01, time/batch = 0.6588s	
4449/26050 (epoch 8.539), train_loss = 1.35431923, grad/param norm = 1.7087e-01, time/batch = 0.6579s	
4450/26050 (epoch 8.541), train_loss = 1.59287733, grad/param norm = 2.1959e-01, time/batch = 0.6489s	
4451/26050 (epoch 8.543), train_loss = 1.19818828, grad/param norm = 1.6602e-01, time/batch = 0.6466s	
4452/26050 (epoch 8.545), train_loss = 1.44860622, grad/param norm = 1.8418e-01, time/batch = 0.6568s	
4453/26050 (epoch 8.547), train_loss = 1.39832867, grad/param norm = 1.8409e-01, time/batch = 0.6428s	
4454/26050 (epoch 8.549), train_loss = 1.19906427, grad/param norm = 1.8331e-01, time/batch = 0.6424s	
4455/26050 (epoch 8.551), train_loss = 1.43541236, grad/param norm = 1.8582e-01, time/batch = 0.6407s	
4456/26050 (epoch 8.553), train_loss = 1.27637746, grad/param norm = 1.7598e-01, time/batch = 0.6410s	
4457/26050 (epoch 8.555), train_loss = 1.31667575, grad/param norm = 1.7012e-01, time/batch = 0.6406s	
4458/26050 (epoch 8.557), train_loss = 1.43921874, grad/param norm = 1.7349e-01, time/batch = 0.6467s	
4459/26050 (epoch 8.559), train_loss = 1.38380784, grad/param norm = 1.8251e-01, time/batch = 0.6412s	
4460/26050 (epoch 8.560), train_loss = 1.36519471, grad/param norm = 1.8575e-01, time/batch = 0.6401s	
4461/26050 (epoch 8.562), train_loss = 1.34827903, grad/param norm = 1.7819e-01, time/batch = 0.6531s	
4462/26050 (epoch 8.564), train_loss = 1.58086048, grad/param norm = 1.9935e-01, time/batch = 0.6817s	
4463/26050 (epoch 8.566), train_loss = 1.25207956, grad/param norm = 1.6554e-01, time/batch = 0.6629s	
4464/26050 (epoch 8.568), train_loss = 1.39139814, grad/param norm = 1.7704e-01, time/batch = 0.6548s	
4465/26050 (epoch 8.570), train_loss = 1.51532091, grad/param norm = 1.9329e-01, time/batch = 0.6410s	
4466/26050 (epoch 8.572), train_loss = 1.36847340, grad/param norm = 1.7193e-01, time/batch = 0.6546s	
4467/26050 (epoch 8.574), train_loss = 1.47763701, grad/param norm = 2.0631e-01, time/batch = 0.6537s	
4468/26050 (epoch 8.576), train_loss = 1.46622042, grad/param norm = 1.9266e-01, time/batch = 0.6391s	
4469/26050 (epoch 8.578), train_loss = 1.37035786, grad/param norm = 1.8315e-01, time/batch = 0.6397s	
4470/26050 (epoch 8.580), train_loss = 1.25511194, grad/param norm = 1.7369e-01, time/batch = 0.6430s	
4471/26050 (epoch 8.582), train_loss = 1.43598843, grad/param norm = 1.8863e-01, time/batch = 0.6432s	
4472/26050 (epoch 8.583), train_loss = 1.45591202, grad/param norm = 1.8479e-01, time/batch = 0.6450s	
4473/26050 (epoch 8.585), train_loss = 1.26058199, grad/param norm = 1.7254e-01, time/batch = 0.6588s	
4474/26050 (epoch 8.587), train_loss = 1.44028947, grad/param norm = 1.8511e-01, time/batch = 0.6527s	
4475/26050 (epoch 8.589), train_loss = 1.47017083, grad/param norm = 2.0532e-01, time/batch = 0.6640s	
4476/26050 (epoch 8.591), train_loss = 1.41605839, grad/param norm = 1.8733e-01, time/batch = 0.6640s	
4477/26050 (epoch 8.593), train_loss = 1.25788337, grad/param norm = 1.9239e-01, time/batch = 0.6839s	
4478/26050 (epoch 8.595), train_loss = 1.55389298, grad/param norm = 2.1277e-01, time/batch = 0.6602s	
4479/26050 (epoch 8.597), train_loss = 1.42047268, grad/param norm = 1.8315e-01, time/batch = 0.6434s	
4480/26050 (epoch 8.599), train_loss = 1.30289769, grad/param norm = 1.7586e-01, time/batch = 0.6442s	
4481/26050 (epoch 8.601), train_loss = 1.59031080, grad/param norm = 1.8893e-01, time/batch = 0.6474s	
4482/26050 (epoch 8.603), train_loss = 1.44216693, grad/param norm = 1.8427e-01, time/batch = 0.6512s	
4483/26050 (epoch 8.605), train_loss = 1.30583397, grad/param norm = 1.7153e-01, time/batch = 0.6420s	
4484/26050 (epoch 8.607), train_loss = 1.51515081, grad/param norm = 1.9119e-01, time/batch = 0.6421s	
4485/26050 (epoch 8.608), train_loss = 1.31428032, grad/param norm = 1.6227e-01, time/batch = 0.6437s	
4486/26050 (epoch 8.610), train_loss = 1.35453396, grad/param norm = 1.8255e-01, time/batch = 0.6416s	
4487/26050 (epoch 8.612), train_loss = 1.34263001, grad/param norm = 1.8430e-01, time/batch = 0.6417s	
4488/26050 (epoch 8.614), train_loss = 1.44089854, grad/param norm = 1.8052e-01, time/batch = 0.6460s	
4489/26050 (epoch 8.616), train_loss = 1.65395608, grad/param norm = 1.9340e-01, time/batch = 0.6481s	
4490/26050 (epoch 8.618), train_loss = 1.29655923, grad/param norm = 1.7946e-01, time/batch = 0.6425s	
4491/26050 (epoch 8.620), train_loss = 1.39556984, grad/param norm = 1.8434e-01, time/batch = 0.6429s	
4492/26050 (epoch 8.622), train_loss = 1.14288759, grad/param norm = 1.6015e-01, time/batch = 0.6744s	
4493/26050 (epoch 8.624), train_loss = 1.25279636, grad/param norm = 1.6632e-01, time/batch = 0.6629s	
4494/26050 (epoch 8.626), train_loss = 1.43720150, grad/param norm = 1.9015e-01, time/batch = 0.6446s	
4495/26050 (epoch 8.628), train_loss = 1.35612407, grad/param norm = 1.9033e-01, time/batch = 0.6443s	
4496/26050 (epoch 8.630), train_loss = 1.50578880, grad/param norm = 1.7728e-01, time/batch = 0.6433s	
4497/26050 (epoch 8.631), train_loss = 1.51543024, grad/param norm = 1.9537e-01, time/batch = 0.6417s	
4498/26050 (epoch 8.633), train_loss = 1.26983339, grad/param norm = 1.7437e-01, time/batch = 0.6429s	
4499/26050 (epoch 8.635), train_loss = 1.26518268, grad/param norm = 1.6565e-01, time/batch = 0.6529s	
4500/26050 (epoch 8.637), train_loss = 1.27420561, grad/param norm = 1.8211e-01, time/batch = 0.6544s	
4501/26050 (epoch 8.639), train_loss = 1.47728956, grad/param norm = 1.8088e-01, time/batch = 0.6563s	
4502/26050 (epoch 8.641), train_loss = 1.29647100, grad/param norm = 1.5747e-01, time/batch = 0.6728s	
4503/26050 (epoch 8.643), train_loss = 1.24811089, grad/param norm = 1.5864e-01, time/batch = 0.6589s	
4504/26050 (epoch 8.645), train_loss = 1.40984543, grad/param norm = 1.8733e-01, time/batch = 0.6621s	
4505/26050 (epoch 8.647), train_loss = 1.32659071, grad/param norm = 1.7339e-01, time/batch = 0.6600s	
4506/26050 (epoch 8.649), train_loss = 1.42214295, grad/param norm = 1.9929e-01, time/batch = 0.6539s	
4507/26050 (epoch 8.651), train_loss = 1.31298646, grad/param norm = 1.8664e-01, time/batch = 0.6479s	
4508/26050 (epoch 8.653), train_loss = 1.37043743, grad/param norm = 1.8524e-01, time/batch = 0.6506s	
4509/26050 (epoch 8.655), train_loss = 1.27053106, grad/param norm = 1.7572e-01, time/batch = 0.6761s	
4510/26050 (epoch 8.656), train_loss = 1.24087932, grad/param norm = 1.7602e-01, time/batch = 0.6804s	
4511/26050 (epoch 8.658), train_loss = 1.57057084, grad/param norm = 1.8470e-01, time/batch = 0.6792s	
4512/26050 (epoch 8.660), train_loss = 1.26232991, grad/param norm = 1.9656e-01, time/batch = 0.6601s	
4513/26050 (epoch 8.662), train_loss = 1.23096768, grad/param norm = 1.6314e-01, time/batch = 0.6534s	
4514/26050 (epoch 8.664), train_loss = 1.34607519, grad/param norm = 1.8244e-01, time/batch = 0.6419s	
4515/26050 (epoch 8.666), train_loss = 1.41279236, grad/param norm = 1.9498e-01, time/batch = 0.6407s	
4516/26050 (epoch 8.668), train_loss = 1.14135665, grad/param norm = 1.5615e-01, time/batch = 0.6401s	
4517/26050 (epoch 8.670), train_loss = 1.55329758, grad/param norm = 2.0396e-01, time/batch = 0.6433s	
4518/26050 (epoch 8.672), train_loss = 1.29032776, grad/param norm = 1.8089e-01, time/batch = 0.6436s	
4519/26050 (epoch 8.674), train_loss = 1.24654263, grad/param norm = 1.5819e-01, time/batch = 0.6409s	
4520/26050 (epoch 8.676), train_loss = 1.40503789, grad/param norm = 1.7498e-01, time/batch = 0.6501s	
4521/26050 (epoch 8.678), train_loss = 1.51436792, grad/param norm = 1.8672e-01, time/batch = 0.6416s	
4522/26050 (epoch 8.679), train_loss = 1.56633433, grad/param norm = 2.0145e-01, time/batch = 0.6418s	
4523/26050 (epoch 8.681), train_loss = 1.39006002, grad/param norm = 1.8906e-01, time/batch = 0.6432s	
4524/26050 (epoch 8.683), train_loss = 1.30184637, grad/param norm = 1.9739e-01, time/batch = 0.6422s	
4525/26050 (epoch 8.685), train_loss = 1.30079364, grad/param norm = 1.6356e-01, time/batch = 0.6418s	
4526/26050 (epoch 8.687), train_loss = 1.16250164, grad/param norm = 1.6576e-01, time/batch = 0.6413s	
4527/26050 (epoch 8.689), train_loss = 1.34201999, grad/param norm = 1.7688e-01, time/batch = 0.6446s	
4528/26050 (epoch 8.691), train_loss = 1.08904760, grad/param norm = 1.6891e-01, time/batch = 0.6422s	
4529/26050 (epoch 8.693), train_loss = 1.28032485, grad/param norm = 1.7932e-01, time/batch = 0.6399s	
4530/26050 (epoch 8.695), train_loss = 1.38756801, grad/param norm = 1.8360e-01, time/batch = 0.6403s	
4531/26050 (epoch 8.697), train_loss = 1.23177770, grad/param norm = 1.7706e-01, time/batch = 0.6402s	
4532/26050 (epoch 8.699), train_loss = 1.42965297, grad/param norm = 1.8284e-01, time/batch = 0.6392s	
4533/26050 (epoch 8.701), train_loss = 1.19223602, grad/param norm = 1.6665e-01, time/batch = 0.6406s	
4534/26050 (epoch 8.702), train_loss = 1.59286491, grad/param norm = 1.9046e-01, time/batch = 0.6459s	
4535/26050 (epoch 8.704), train_loss = 1.37509351, grad/param norm = 1.7392e-01, time/batch = 0.6440s	
4536/26050 (epoch 8.706), train_loss = 1.44428713, grad/param norm = 2.0451e-01, time/batch = 0.6402s	
4537/26050 (epoch 8.708), train_loss = 1.42664882, grad/param norm = 1.7515e-01, time/batch = 0.6394s	
4538/26050 (epoch 8.710), train_loss = 1.43817940, grad/param norm = 1.8261e-01, time/batch = 0.6514s	
4539/26050 (epoch 8.712), train_loss = 1.54495391, grad/param norm = 1.8491e-01, time/batch = 0.6418s	
4540/26050 (epoch 8.714), train_loss = 1.22189894, grad/param norm = 1.7754e-01, time/batch = 0.6384s	
4541/26050 (epoch 8.716), train_loss = 1.62178395, grad/param norm = 2.0937e-01, time/batch = 0.6423s	
4542/26050 (epoch 8.718), train_loss = 1.48043578, grad/param norm = 1.8886e-01, time/batch = 0.6425s	
4543/26050 (epoch 8.720), train_loss = 1.28738140, grad/param norm = 1.7521e-01, time/batch = 0.6414s	
4544/26050 (epoch 8.722), train_loss = 1.22620649, grad/param norm = 1.6571e-01, time/batch = 0.6394s	
4545/26050 (epoch 8.724), train_loss = 1.23282587, grad/param norm = 1.7558e-01, time/batch = 0.6395s	
4546/26050 (epoch 8.726), train_loss = 1.47186778, grad/param norm = 1.8109e-01, time/batch = 0.6407s	
4547/26050 (epoch 8.727), train_loss = 1.43263490, grad/param norm = 1.7562e-01, time/batch = 0.6392s	
4548/26050 (epoch 8.729), train_loss = 1.43763112, grad/param norm = 1.8730e-01, time/batch = 0.6401s	
4549/26050 (epoch 8.731), train_loss = 1.37011126, grad/param norm = 1.6326e-01, time/batch = 0.6398s	
4550/26050 (epoch 8.733), train_loss = 1.33369658, grad/param norm = 2.0765e-01, time/batch = 0.6444s	
4551/26050 (epoch 8.735), train_loss = 1.56961736, grad/param norm = 1.8864e-01, time/batch = 0.6482s	
4552/26050 (epoch 8.737), train_loss = 1.38175936, grad/param norm = 1.8646e-01, time/batch = 0.6408s	
4553/26050 (epoch 8.739), train_loss = 1.39800506, grad/param norm = 1.7548e-01, time/batch = 0.6490s	
4554/26050 (epoch 8.741), train_loss = 1.26473457, grad/param norm = 1.6918e-01, time/batch = 0.6831s	
4555/26050 (epoch 8.743), train_loss = 1.44409708, grad/param norm = 2.1861e-01, time/batch = 0.6532s	
4556/26050 (epoch 8.745), train_loss = 1.24534403, grad/param norm = 1.8768e-01, time/batch = 0.6411s	
4557/26050 (epoch 8.747), train_loss = 1.26758069, grad/param norm = 1.8025e-01, time/batch = 0.6404s	
4558/26050 (epoch 8.749), train_loss = 1.50214775, grad/param norm = 1.9600e-01, time/batch = 0.6400s	
4559/26050 (epoch 8.750), train_loss = 1.31991826, grad/param norm = 1.6802e-01, time/batch = 0.6398s	
4560/26050 (epoch 8.752), train_loss = 1.40019224, grad/param norm = 2.0942e-01, time/batch = 0.6396s	
4561/26050 (epoch 8.754), train_loss = 1.35614258, grad/param norm = 1.7926e-01, time/batch = 0.6424s	
4562/26050 (epoch 8.756), train_loss = 1.43757134, grad/param norm = 1.9394e-01, time/batch = 0.6404s	
4563/26050 (epoch 8.758), train_loss = 1.38432301, grad/param norm = 1.8126e-01, time/batch = 0.6399s	
4564/26050 (epoch 8.760), train_loss = 1.46692391, grad/param norm = 1.8937e-01, time/batch = 0.6410s	
4565/26050 (epoch 8.762), train_loss = 1.26150453, grad/param norm = 1.6575e-01, time/batch = 0.6492s	
4566/26050 (epoch 8.764), train_loss = 1.46778374, grad/param norm = 1.8386e-01, time/batch = 0.6489s	
4567/26050 (epoch 8.766), train_loss = 1.46545138, grad/param norm = 1.9130e-01, time/batch = 0.6768s	
4568/26050 (epoch 8.768), train_loss = 1.23196706, grad/param norm = 1.5580e-01, time/batch = 0.6534s	
4569/26050 (epoch 8.770), train_loss = 1.37227441, grad/param norm = 1.8249e-01, time/batch = 0.6649s	
4570/26050 (epoch 8.772), train_loss = 1.35199045, grad/param norm = 1.6998e-01, time/batch = 0.6579s	
4571/26050 (epoch 8.774), train_loss = 1.24547850, grad/param norm = 1.8470e-01, time/batch = 0.6585s	
4572/26050 (epoch 8.775), train_loss = 1.06439588, grad/param norm = 1.7262e-01, time/batch = 0.6449s	
4573/26050 (epoch 8.777), train_loss = 1.28804337, grad/param norm = 1.8089e-01, time/batch = 0.6442s	
4574/26050 (epoch 8.779), train_loss = 1.32588162, grad/param norm = 1.7359e-01, time/batch = 0.6553s	
4575/26050 (epoch 8.781), train_loss = 1.31025278, grad/param norm = 1.7407e-01, time/batch = 0.6425s	
4576/26050 (epoch 8.783), train_loss = 1.27819161, grad/param norm = 1.6530e-01, time/batch = 0.6415s	
4577/26050 (epoch 8.785), train_loss = 1.31623925, grad/param norm = 1.9176e-01, time/batch = 0.6415s	
4578/26050 (epoch 8.787), train_loss = 1.28968945, grad/param norm = 1.7143e-01, time/batch = 0.6395s	
4579/26050 (epoch 8.789), train_loss = 1.35335552, grad/param norm = 1.9624e-01, time/batch = 0.6425s	
4580/26050 (epoch 8.791), train_loss = 1.36900343, grad/param norm = 1.8226e-01, time/batch = 0.6409s	
4581/26050 (epoch 8.793), train_loss = 1.35236071, grad/param norm = 1.8507e-01, time/batch = 0.6458s	
4582/26050 (epoch 8.795), train_loss = 1.17731550, grad/param norm = 1.6416e-01, time/batch = 0.6444s	
4583/26050 (epoch 8.797), train_loss = 1.23969476, grad/param norm = 1.6306e-01, time/batch = 0.6405s	
4584/26050 (epoch 8.798), train_loss = 1.22950368, grad/param norm = 1.7605e-01, time/batch = 0.6649s	
4585/26050 (epoch 8.800), train_loss = 1.20833107, grad/param norm = 1.6084e-01, time/batch = 0.6848s	
4586/26050 (epoch 8.802), train_loss = 1.34140144, grad/param norm = 1.8061e-01, time/batch = 0.6466s	
4587/26050 (epoch 8.804), train_loss = 1.32440009, grad/param norm = 1.6850e-01, time/batch = 0.6460s	
4588/26050 (epoch 8.806), train_loss = 1.48966706, grad/param norm = 1.9263e-01, time/batch = 0.6508s	
4589/26050 (epoch 8.808), train_loss = 1.31890752, grad/param norm = 1.7251e-01, time/batch = 0.6431s	
4590/26050 (epoch 8.810), train_loss = 1.29183731, grad/param norm = 1.8830e-01, time/batch = 0.6513s	
4591/26050 (epoch 8.812), train_loss = 1.22903471, grad/param norm = 1.7812e-01, time/batch = 0.6483s	
4592/26050 (epoch 8.814), train_loss = 1.22620872, grad/param norm = 1.8480e-01, time/batch = 0.6426s	
4593/26050 (epoch 8.816), train_loss = 1.42731128, grad/param norm = 1.8912e-01, time/batch = 0.6411s	
4594/26050 (epoch 8.818), train_loss = 1.52854481, grad/param norm = 2.1092e-01, time/batch = 0.6438s	
4595/26050 (epoch 8.820), train_loss = 1.37505183, grad/param norm = 1.8513e-01, time/batch = 0.6394s	
4596/26050 (epoch 8.821), train_loss = 1.53060271, grad/param norm = 2.1291e-01, time/batch = 0.6400s	
4597/26050 (epoch 8.823), train_loss = 1.57054993, grad/param norm = 1.9101e-01, time/batch = 0.6430s	
4598/26050 (epoch 8.825), train_loss = 1.30991968, grad/param norm = 1.9043e-01, time/batch = 0.6414s	
4599/26050 (epoch 8.827), train_loss = 1.41501936, grad/param norm = 1.9589e-01, time/batch = 0.6408s	
4600/26050 (epoch 8.829), train_loss = 1.42453199, grad/param norm = 1.9148e-01, time/batch = 0.6403s	
4601/26050 (epoch 8.831), train_loss = 1.51204117, grad/param norm = 1.9345e-01, time/batch = 0.6445s	
4602/26050 (epoch 8.833), train_loss = 1.56975992, grad/param norm = 1.7950e-01, time/batch = 0.6433s	
4603/26050 (epoch 8.835), train_loss = 1.60290026, grad/param norm = 1.9288e-01, time/batch = 0.6426s	
4604/26050 (epoch 8.837), train_loss = 1.31026996, grad/param norm = 1.7763e-01, time/batch = 0.6425s	
4605/26050 (epoch 8.839), train_loss = 1.45002556, grad/param norm = 1.8988e-01, time/batch = 0.6421s	
4606/26050 (epoch 8.841), train_loss = 1.47334200, grad/param norm = 1.7274e-01, time/batch = 0.6396s	
4607/26050 (epoch 8.843), train_loss = 1.43067223, grad/param norm = 1.8524e-01, time/batch = 0.6402s	
4608/26050 (epoch 8.845), train_loss = 1.28284733, grad/param norm = 1.7843e-01, time/batch = 0.6417s	
4609/26050 (epoch 8.846), train_loss = 1.50804881, grad/param norm = 1.8486e-01, time/batch = 0.6389s	
4610/26050 (epoch 8.848), train_loss = 1.32182359, grad/param norm = 1.7678e-01, time/batch = 0.6410s	
4611/26050 (epoch 8.850), train_loss = 1.31207513, grad/param norm = 1.7419e-01, time/batch = 0.6440s	
4612/26050 (epoch 8.852), train_loss = 1.34234274, grad/param norm = 1.8559e-01, time/batch = 0.6481s	
4613/26050 (epoch 8.854), train_loss = 1.37424444, grad/param norm = 1.8251e-01, time/batch = 0.6416s	
4614/26050 (epoch 8.856), train_loss = 1.28924932, grad/param norm = 1.8316e-01, time/batch = 0.6404s	
4615/26050 (epoch 8.858), train_loss = 1.24518374, grad/param norm = 1.8403e-01, time/batch = 0.6412s	
4616/26050 (epoch 8.860), train_loss = 1.40947852, grad/param norm = 1.9627e-01, time/batch = 0.6390s	
4617/26050 (epoch 8.862), train_loss = 1.37896594, grad/param norm = 1.8354e-01, time/batch = 0.6443s	
4618/26050 (epoch 8.864), train_loss = 1.33136209, grad/param norm = 1.8631e-01, time/batch = 0.6426s	
4619/26050 (epoch 8.866), train_loss = 1.26132357, grad/param norm = 1.6668e-01, time/batch = 0.6399s	
4620/26050 (epoch 8.868), train_loss = 1.47681981, grad/param norm = 2.0048e-01, time/batch = 0.6420s	
4621/26050 (epoch 8.869), train_loss = 1.20682597, grad/param norm = 1.6088e-01, time/batch = 0.6410s	
4622/26050 (epoch 8.871), train_loss = 1.17422943, grad/param norm = 1.5674e-01, time/batch = 0.6397s	
4623/26050 (epoch 8.873), train_loss = 1.40153405, grad/param norm = 1.7413e-01, time/batch = 0.6405s	
4624/26050 (epoch 8.875), train_loss = 1.33164235, grad/param norm = 1.7826e-01, time/batch = 0.6403s	
4625/26050 (epoch 8.877), train_loss = 1.19877925, grad/param norm = 1.7342e-01, time/batch = 0.6395s	
4626/26050 (epoch 8.879), train_loss = 1.33822267, grad/param norm = 1.6905e-01, time/batch = 0.6392s	
4627/26050 (epoch 8.881), train_loss = 1.52656657, grad/param norm = 1.9011e-01, time/batch = 0.6424s	
4628/26050 (epoch 8.883), train_loss = 1.38006304, grad/param norm = 1.7424e-01, time/batch = 0.6473s	
4629/26050 (epoch 8.885), train_loss = 1.07228990, grad/param norm = 1.5691e-01, time/batch = 0.6401s	
4630/26050 (epoch 8.887), train_loss = 1.40731486, grad/param norm = 1.7482e-01, time/batch = 0.6447s	
4631/26050 (epoch 8.889), train_loss = 1.27622723, grad/param norm = 1.6341e-01, time/batch = 0.6838s	
4632/26050 (epoch 8.891), train_loss = 1.11392760, grad/param norm = 1.5723e-01, time/batch = 0.6552s	
4633/26050 (epoch 8.893), train_loss = 1.08677231, grad/param norm = 1.5287e-01, time/batch = 0.6410s	
4634/26050 (epoch 8.894), train_loss = 1.26150562, grad/param norm = 1.6649e-01, time/batch = 0.6407s	
4635/26050 (epoch 8.896), train_loss = 1.46930761, grad/param norm = 1.8654e-01, time/batch = 0.6423s	
4636/26050 (epoch 8.898), train_loss = 1.28760784, grad/param norm = 1.8773e-01, time/batch = 0.6426s	
4637/26050 (epoch 8.900), train_loss = 1.55251489, grad/param norm = 1.9052e-01, time/batch = 0.6401s	
4638/26050 (epoch 8.902), train_loss = 1.35237548, grad/param norm = 1.7404e-01, time/batch = 0.6406s	
4639/26050 (epoch 8.904), train_loss = 1.29165226, grad/param norm = 1.6354e-01, time/batch = 0.6401s	
4640/26050 (epoch 8.906), train_loss = 1.32571046, grad/param norm = 1.7957e-01, time/batch = 0.6400s	
4641/26050 (epoch 8.908), train_loss = 1.32169998, grad/param norm = 1.7701e-01, time/batch = 0.6433s	
4642/26050 (epoch 8.910), train_loss = 1.24966559, grad/param norm = 1.6128e-01, time/batch = 0.6430s	
4643/26050 (epoch 8.912), train_loss = 1.62357596, grad/param norm = 1.9571e-01, time/batch = 0.6441s	
4644/26050 (epoch 8.914), train_loss = 1.79472648, grad/param norm = 1.9502e-01, time/batch = 0.6477s	
4645/26050 (epoch 8.916), train_loss = 1.50875926, grad/param norm = 1.9764e-01, time/batch = 0.6398s	
4646/26050 (epoch 8.917), train_loss = 1.41107328, grad/param norm = 1.9890e-01, time/batch = 0.6547s	
4647/26050 (epoch 8.919), train_loss = 1.47403432, grad/param norm = 1.9451e-01, time/batch = 0.6581s	
4648/26050 (epoch 8.921), train_loss = 1.28042913, grad/param norm = 2.0756e-01, time/batch = 0.6396s	
4649/26050 (epoch 8.923), train_loss = 1.35107462, grad/param norm = 1.9753e-01, time/batch = 0.6399s	
4650/26050 (epoch 8.925), train_loss = 1.31301152, grad/param norm = 1.7027e-01, time/batch = 0.6449s	
4651/26050 (epoch 8.927), train_loss = 1.21526262, grad/param norm = 1.5527e-01, time/batch = 0.6453s	
4652/26050 (epoch 8.929), train_loss = 1.27210520, grad/param norm = 1.7901e-01, time/batch = 0.6431s	
4653/26050 (epoch 8.931), train_loss = 1.61697227, grad/param norm = 2.1648e-01, time/batch = 0.6420s	
4654/26050 (epoch 8.933), train_loss = 1.30543344, grad/param norm = 1.8408e-01, time/batch = 0.6436s	
4655/26050 (epoch 8.935), train_loss = 1.27602593, grad/param norm = 1.7220e-01, time/batch = 0.6422s	
4656/26050 (epoch 8.937), train_loss = 1.36551558, grad/param norm = 1.6692e-01, time/batch = 0.6425s	
4657/26050 (epoch 8.939), train_loss = 1.23231095, grad/param norm = 1.6492e-01, time/batch = 0.6445s	
4658/26050 (epoch 8.940), train_loss = 1.36122876, grad/param norm = 1.7255e-01, time/batch = 0.6673s	
4659/26050 (epoch 8.942), train_loss = 1.38662770, grad/param norm = 2.0002e-01, time/batch = 0.6542s	
4660/26050 (epoch 8.944), train_loss = 1.31641521, grad/param norm = 1.9661e-01, time/batch = 0.6426s	
4661/26050 (epoch 8.946), train_loss = 1.50313712, grad/param norm = 1.8122e-01, time/batch = 0.6546s	
4662/26050 (epoch 8.948), train_loss = 1.17373772, grad/param norm = 1.9545e-01, time/batch = 0.6412s	
4663/26050 (epoch 8.950), train_loss = 1.31699935, grad/param norm = 1.6891e-01, time/batch = 0.6562s	
4664/26050 (epoch 8.952), train_loss = 1.50666894, grad/param norm = 1.9355e-01, time/batch = 0.6587s	
4665/26050 (epoch 8.954), train_loss = 1.44801476, grad/param norm = 1.8011e-01, time/batch = 0.6556s	
4666/26050 (epoch 8.956), train_loss = 1.42857639, grad/param norm = 1.9388e-01, time/batch = 0.6478s	
4667/26050 (epoch 8.958), train_loss = 1.33673947, grad/param norm = 1.8032e-01, time/batch = 0.6437s	
4668/26050 (epoch 8.960), train_loss = 1.32565291, grad/param norm = 1.7201e-01, time/batch = 0.6412s	
4669/26050 (epoch 8.962), train_loss = 1.26099033, grad/param norm = 1.7423e-01, time/batch = 0.6401s	
4670/26050 (epoch 8.964), train_loss = 1.32165699, grad/param norm = 1.6991e-01, time/batch = 0.6425s	
4671/26050 (epoch 8.965), train_loss = 1.22217318, grad/param norm = 1.7645e-01, time/batch = 0.6431s	
4672/26050 (epoch 8.967), train_loss = 1.67998688, grad/param norm = 1.8393e-01, time/batch = 0.6414s	
4673/26050 (epoch 8.969), train_loss = 1.30507617, grad/param norm = 1.6304e-01, time/batch = 0.6403s	
4674/26050 (epoch 8.971), train_loss = 1.22717950, grad/param norm = 1.6535e-01, time/batch = 0.6468s	
4675/26050 (epoch 8.973), train_loss = 1.31216413, grad/param norm = 1.9012e-01, time/batch = 0.6499s	
4676/26050 (epoch 8.975), train_loss = 1.41183831, grad/param norm = 1.6813e-01, time/batch = 0.6440s	
4677/26050 (epoch 8.977), train_loss = 1.36279914, grad/param norm = 1.5860e-01, time/batch = 0.6609s	
4678/26050 (epoch 8.979), train_loss = 1.18332611, grad/param norm = 1.7021e-01, time/batch = 0.6540s	
4679/26050 (epoch 8.981), train_loss = 1.45026407, grad/param norm = 1.7884e-01, time/batch = 0.6442s	
4680/26050 (epoch 8.983), train_loss = 1.45774844, grad/param norm = 1.8122e-01, time/batch = 0.6402s	
4681/26050 (epoch 8.985), train_loss = 1.38214439, grad/param norm = 1.8357e-01, time/batch = 0.6457s	
4682/26050 (epoch 8.987), train_loss = 1.52609482, grad/param norm = 1.9865e-01, time/batch = 0.6513s	
4683/26050 (epoch 8.988), train_loss = 1.46198754, grad/param norm = 1.8735e-01, time/batch = 0.6614s	
4684/26050 (epoch 8.990), train_loss = 1.27189021, grad/param norm = 1.6839e-01, time/batch = 0.6645s	
4685/26050 (epoch 8.992), train_loss = 1.52122030, grad/param norm = 1.9657e-01, time/batch = 0.6754s	
4686/26050 (epoch 8.994), train_loss = 1.36493946, grad/param norm = 1.8016e-01, time/batch = 0.6522s	
4687/26050 (epoch 8.996), train_loss = 1.32923338, grad/param norm = 2.0293e-01, time/batch = 0.6507s	
4688/26050 (epoch 8.998), train_loss = 1.37273494, grad/param norm = 1.8802e-01, time/batch = 0.6426s	
4689/26050 (epoch 9.000), train_loss = 1.31864029, grad/param norm = 1.8186e-01, time/batch = 0.6437s	
4690/26050 (epoch 9.002), train_loss = 1.39242484, grad/param norm = 1.8068e-01, time/batch = 0.6423s	
4691/26050 (epoch 9.004), train_loss = 1.26834903, grad/param norm = 1.8822e-01, time/batch = 0.6419s	
4692/26050 (epoch 9.006), train_loss = 1.27677647, grad/param norm = 1.6754e-01, time/batch = 0.6576s	
4693/26050 (epoch 9.008), train_loss = 1.24821038, grad/param norm = 1.7796e-01, time/batch = 0.6617s	
4694/26050 (epoch 9.010), train_loss = 1.30323541, grad/param norm = 1.6827e-01, time/batch = 0.6407s	
4695/26050 (epoch 9.012), train_loss = 1.38573324, grad/param norm = 1.8298e-01, time/batch = 0.6408s	
4696/26050 (epoch 9.013), train_loss = 1.77782131, grad/param norm = 2.0529e-01, time/batch = 0.6421s	
4697/26050 (epoch 9.015), train_loss = 1.23464024, grad/param norm = 1.6484e-01, time/batch = 0.6409s	
4698/26050 (epoch 9.017), train_loss = 1.38485708, grad/param norm = 1.8186e-01, time/batch = 0.6408s	
4699/26050 (epoch 9.019), train_loss = 1.15158041, grad/param norm = 1.4946e-01, time/batch = 0.6407s	
4700/26050 (epoch 9.021), train_loss = 1.47060834, grad/param norm = 1.9354e-01, time/batch = 0.6466s	
4701/26050 (epoch 9.023), train_loss = 1.18588374, grad/param norm = 1.6690e-01, time/batch = 0.6419s	
4702/26050 (epoch 9.025), train_loss = 1.29953897, grad/param norm = 1.7684e-01, time/batch = 0.6392s	
4703/26050 (epoch 9.027), train_loss = 1.10786793, grad/param norm = 1.6362e-01, time/batch = 0.6398s	
4704/26050 (epoch 9.029), train_loss = 1.29551259, grad/param norm = 1.6004e-01, time/batch = 0.6428s	
4705/26050 (epoch 9.031), train_loss = 1.53425963, grad/param norm = 2.0259e-01, time/batch = 0.6436s	
4706/26050 (epoch 9.033), train_loss = 1.39400798, grad/param norm = 1.8554e-01, time/batch = 0.6412s	
4707/26050 (epoch 9.035), train_loss = 1.47571301, grad/param norm = 1.7730e-01, time/batch = 0.6413s	
4708/26050 (epoch 9.036), train_loss = 1.27994025, grad/param norm = 1.9884e-01, time/batch = 0.6413s	
4709/26050 (epoch 9.038), train_loss = 1.15582037, grad/param norm = 1.7002e-01, time/batch = 0.6400s	
4710/26050 (epoch 9.040), train_loss = 1.40435992, grad/param norm = 1.7854e-01, time/batch = 0.6403s	
4711/26050 (epoch 9.042), train_loss = 1.21357348, grad/param norm = 1.7673e-01, time/batch = 0.6441s	
4712/26050 (epoch 9.044), train_loss = 1.41025130, grad/param norm = 1.8840e-01, time/batch = 0.6456s	
4713/26050 (epoch 9.046), train_loss = 1.14220193, grad/param norm = 1.8362e-01, time/batch = 0.6434s	
4714/26050 (epoch 9.048), train_loss = 1.37418821, grad/param norm = 1.8163e-01, time/batch = 0.6396s	
4715/26050 (epoch 9.050), train_loss = 1.23052883, grad/param norm = 1.8945e-01, time/batch = 0.6416s	
4716/26050 (epoch 9.052), train_loss = 1.32521850, grad/param norm = 1.7574e-01, time/batch = 0.6425s	
4717/26050 (epoch 9.054), train_loss = 1.16436197, grad/param norm = 1.6426e-01, time/batch = 0.6401s	
4718/26050 (epoch 9.056), train_loss = 1.05314936, grad/param norm = 1.4381e-01, time/batch = 0.6451s	
4719/26050 (epoch 9.058), train_loss = 1.24917555, grad/param norm = 1.6532e-01, time/batch = 0.6740s	
4720/26050 (epoch 9.060), train_loss = 1.32877688, grad/param norm = 1.6539e-01, time/batch = 0.6657s	
4721/26050 (epoch 9.061), train_loss = 1.22131521, grad/param norm = 1.7016e-01, time/batch = 0.6625s	
4722/26050 (epoch 9.063), train_loss = 1.30877739, grad/param norm = 1.6576e-01, time/batch = 0.6567s	
4723/26050 (epoch 9.065), train_loss = 1.14655499, grad/param norm = 1.6472e-01, time/batch = 0.6796s	
4724/26050 (epoch 9.067), train_loss = 1.41249790, grad/param norm = 1.9340e-01, time/batch = 0.6731s	
4725/26050 (epoch 9.069), train_loss = 1.39393050, grad/param norm = 1.6918e-01, time/batch = 0.6614s	
4726/26050 (epoch 9.071), train_loss = 1.41091668, grad/param norm = 1.9089e-01, time/batch = 0.6673s	
4727/26050 (epoch 9.073), train_loss = 1.55788714, grad/param norm = 1.7497e-01, time/batch = 0.6719s	
4728/26050 (epoch 9.075), train_loss = 1.23040389, grad/param norm = 1.7192e-01, time/batch = 0.6688s	
4729/26050 (epoch 9.077), train_loss = 1.23537837, grad/param norm = 1.7019e-01, time/batch = 0.6656s	
4730/26050 (epoch 9.079), train_loss = 1.40294392, grad/param norm = 1.9436e-01, time/batch = 0.6666s	
4731/26050 (epoch 9.081), train_loss = 1.28992370, grad/param norm = 1.8448e-01, time/batch = 0.6554s	
4732/26050 (epoch 9.083), train_loss = 1.42592720, grad/param norm = 1.8404e-01, time/batch = 0.6568s	
4733/26050 (epoch 9.084), train_loss = 1.46881135, grad/param norm = 2.1010e-01, time/batch = 0.6579s	
4734/26050 (epoch 9.086), train_loss = 1.47406611, grad/param norm = 1.8532e-01, time/batch = 0.6572s	
4735/26050 (epoch 9.088), train_loss = 1.20132698, grad/param norm = 1.6070e-01, time/batch = 0.6530s	
4736/26050 (epoch 9.090), train_loss = 1.42168502, grad/param norm = 1.8262e-01, time/batch = 0.6561s	
4737/26050 (epoch 9.092), train_loss = 1.35088165, grad/param norm = 1.8661e-01, time/batch = 0.6519s	
4738/26050 (epoch 9.094), train_loss = 1.32264257, grad/param norm = 1.7480e-01, time/batch = 0.6543s	
4739/26050 (epoch 9.096), train_loss = 1.27743224, grad/param norm = 1.7174e-01, time/batch = 0.6665s	
4740/26050 (epoch 9.098), train_loss = 1.27609470, grad/param norm = 1.7571e-01, time/batch = 0.6743s	
4741/26050 (epoch 9.100), train_loss = 1.22710357, grad/param norm = 1.8129e-01, time/batch = 0.6544s	
4742/26050 (epoch 9.102), train_loss = 1.36929321, grad/param norm = 1.8204e-01, time/batch = 0.6504s	
4743/26050 (epoch 9.104), train_loss = 1.37381663, grad/param norm = 1.7741e-01, time/batch = 0.6501s	
4744/26050 (epoch 9.106), train_loss = 1.29568550, grad/param norm = 1.7225e-01, time/batch = 0.6403s	
4745/26050 (epoch 9.107), train_loss = 1.08310189, grad/param norm = 1.7113e-01, time/batch = 0.6410s	
4746/26050 (epoch 9.109), train_loss = 1.25031819, grad/param norm = 1.7498e-01, time/batch = 0.6412s	
4747/26050 (epoch 9.111), train_loss = 1.55589608, grad/param norm = 2.0396e-01, time/batch = 0.6427s	
4748/26050 (epoch 9.113), train_loss = 1.26265056, grad/param norm = 1.8216e-01, time/batch = 0.6400s	
4749/26050 (epoch 9.115), train_loss = 1.44774847, grad/param norm = 1.8134e-01, time/batch = 0.6499s	
4750/26050 (epoch 9.117), train_loss = 1.39207127, grad/param norm = 1.8397e-01, time/batch = 0.6601s	
4751/26050 (epoch 9.119), train_loss = 1.10831603, grad/param norm = 1.6226e-01, time/batch = 0.6529s	
4752/26050 (epoch 9.121), train_loss = 1.39899796, grad/param norm = 1.7858e-01, time/batch = 0.6537s	
4753/26050 (epoch 9.123), train_loss = 1.25522784, grad/param norm = 1.9245e-01, time/batch = 0.6493s	
4754/26050 (epoch 9.125), train_loss = 1.12671138, grad/param norm = 1.5183e-01, time/batch = 0.6384s	
4755/26050 (epoch 9.127), train_loss = 1.09686837, grad/param norm = 1.6454e-01, time/batch = 0.6436s	
4756/26050 (epoch 9.129), train_loss = 1.10842362, grad/param norm = 1.5636e-01, time/batch = 0.6427s	
4757/26050 (epoch 9.131), train_loss = 1.31051170, grad/param norm = 1.8256e-01, time/batch = 0.6439s	
4758/26050 (epoch 9.132), train_loss = 1.26344506, grad/param norm = 1.7242e-01, time/batch = 0.6461s	
4759/26050 (epoch 9.134), train_loss = 1.28435387, grad/param norm = 1.7982e-01, time/batch = 0.6628s	
4760/26050 (epoch 9.136), train_loss = 1.30226166, grad/param norm = 1.7389e-01, time/batch = 0.6462s	
4761/26050 (epoch 9.138), train_loss = 1.14559665, grad/param norm = 1.8634e-01, time/batch = 0.6402s	
4762/26050 (epoch 9.140), train_loss = 1.19030248, grad/param norm = 1.6661e-01, time/batch = 0.6417s	
4763/26050 (epoch 9.142), train_loss = 1.24085176, grad/param norm = 1.7842e-01, time/batch = 0.6387s	
4764/26050 (epoch 9.144), train_loss = 1.12602476, grad/param norm = 1.6172e-01, time/batch = 0.6420s	
4765/26050 (epoch 9.146), train_loss = 1.03923158, grad/param norm = 1.5467e-01, time/batch = 0.6439s	
4766/26050 (epoch 9.148), train_loss = 1.06628135, grad/param norm = 1.4170e-01, time/batch = 0.6397s	
4767/26050 (epoch 9.150), train_loss = 1.29997085, grad/param norm = 2.1014e-01, time/batch = 0.6399s	
4768/26050 (epoch 9.152), train_loss = 1.57581137, grad/param norm = 1.9745e-01, time/batch = 0.6409s	
4769/26050 (epoch 9.154), train_loss = 1.11914342, grad/param norm = 1.8874e-01, time/batch = 0.6570s	
4770/26050 (epoch 9.155), train_loss = 1.12476851, grad/param norm = 1.6064e-01, time/batch = 0.6479s	
4771/26050 (epoch 9.157), train_loss = 1.29597087, grad/param norm = 1.9651e-01, time/batch = 0.6458s	
4772/26050 (epoch 9.159), train_loss = 1.29952229, grad/param norm = 1.7975e-01, time/batch = 0.6402s	
4773/26050 (epoch 9.161), train_loss = 1.48664485, grad/param norm = 2.0899e-01, time/batch = 0.6424s	
4774/26050 (epoch 9.163), train_loss = 1.15614292, grad/param norm = 1.6894e-01, time/batch = 0.6403s	
4775/26050 (epoch 9.165), train_loss = 1.01398167, grad/param norm = 1.5040e-01, time/batch = 0.6439s	
4776/26050 (epoch 9.167), train_loss = 1.42697095, grad/param norm = 2.0641e-01, time/batch = 0.6483s	
4777/26050 (epoch 9.169), train_loss = 1.38211711, grad/param norm = 1.7481e-01, time/batch = 0.6400s	
4778/26050 (epoch 9.171), train_loss = 1.08935026, grad/param norm = 1.4648e-01, time/batch = 0.6374s	
4779/26050 (epoch 9.173), train_loss = 1.25622047, grad/param norm = 1.8104e-01, time/batch = 0.6412s	
4780/26050 (epoch 9.175), train_loss = 1.31665321, grad/param norm = 1.8115e-01, time/batch = 0.6378s	
4781/26050 (epoch 9.177), train_loss = 1.39684693, grad/param norm = 1.7341e-01, time/batch = 0.6478s	
4782/26050 (epoch 9.179), train_loss = 1.01986782, grad/param norm = 1.5389e-01, time/batch = 0.6405s	
4783/26050 (epoch 9.180), train_loss = 1.57165973, grad/param norm = 1.7668e-01, time/batch = 0.6386s	
4784/26050 (epoch 9.182), train_loss = 1.58837213, grad/param norm = 1.9144e-01, time/batch = 0.6407s	
4785/26050 (epoch 9.184), train_loss = 1.32584559, grad/param norm = 1.6970e-01, time/batch = 0.6407s	
4786/26050 (epoch 9.186), train_loss = 1.08308557, grad/param norm = 1.5356e-01, time/batch = 0.6381s	
4787/26050 (epoch 9.188), train_loss = 1.29473972, grad/param norm = 1.6292e-01, time/batch = 0.6397s	
4788/26050 (epoch 9.190), train_loss = 1.35895152, grad/param norm = 1.8100e-01, time/batch = 0.6402s	
4789/26050 (epoch 9.192), train_loss = 1.34823766, grad/param norm = 1.7159e-01, time/batch = 0.6395s	
4790/26050 (epoch 9.194), train_loss = 1.34616285, grad/param norm = 1.7794e-01, time/batch = 0.6388s	
4791/26050 (epoch 9.196), train_loss = 1.41442587, grad/param norm = 1.8950e-01, time/batch = 0.6394s	
4792/26050 (epoch 9.198), train_loss = 1.24336532, grad/param norm = 1.7816e-01, time/batch = 0.6392s	
4793/26050 (epoch 9.200), train_loss = 1.22928656, grad/param norm = 1.8350e-01, time/batch = 0.6395s	
4794/26050 (epoch 9.202), train_loss = 1.23582185, grad/param norm = 1.7805e-01, time/batch = 0.6381s	
4795/26050 (epoch 9.203), train_loss = 1.39164651, grad/param norm = 1.8853e-01, time/batch = 0.6388s	
4796/26050 (epoch 9.205), train_loss = 1.20318544, grad/param norm = 1.6454e-01, time/batch = 0.6386s	
4797/26050 (epoch 9.207), train_loss = 1.29573272, grad/param norm = 1.6861e-01, time/batch = 0.6471s	
4798/26050 (epoch 9.209), train_loss = 1.29657966, grad/param norm = 1.7505e-01, time/batch = 0.6410s	
4799/26050 (epoch 9.211), train_loss = 1.14544253, grad/param norm = 1.6299e-01, time/batch = 0.6443s	
4800/26050 (epoch 9.213), train_loss = 1.34737681, grad/param norm = 1.6873e-01, time/batch = 0.6402s	
4801/26050 (epoch 9.215), train_loss = 1.35157736, grad/param norm = 1.9695e-01, time/batch = 0.6408s	
4802/26050 (epoch 9.217), train_loss = 1.26257418, grad/param norm = 1.7066e-01, time/batch = 0.6418s	
4803/26050 (epoch 9.219), train_loss = 1.23441474, grad/param norm = 1.8418e-01, time/batch = 0.6558s	
4804/26050 (epoch 9.221), train_loss = 1.16140317, grad/param norm = 1.6825e-01, time/batch = 0.6481s	
4805/26050 (epoch 9.223), train_loss = 1.36338452, grad/param norm = 1.8522e-01, time/batch = 0.6430s	
4806/26050 (epoch 9.225), train_loss = 1.20488237, grad/param norm = 1.8562e-01, time/batch = 0.6398s	
4807/26050 (epoch 9.226), train_loss = 1.44996514, grad/param norm = 1.8545e-01, time/batch = 0.6416s	
4808/26050 (epoch 9.228), train_loss = 1.45784012, grad/param norm = 1.8598e-01, time/batch = 0.6396s	
4809/26050 (epoch 9.230), train_loss = 1.35193101, grad/param norm = 1.8001e-01, time/batch = 0.6412s	
4810/26050 (epoch 9.232), train_loss = 1.43953888, grad/param norm = 1.9420e-01, time/batch = 0.6399s	
4811/26050 (epoch 9.234), train_loss = 1.14145600, grad/param norm = 1.7885e-01, time/batch = 0.6474s	
4812/26050 (epoch 9.236), train_loss = 1.38401807, grad/param norm = 1.9544e-01, time/batch = 0.6418s	
4813/26050 (epoch 9.238), train_loss = 1.12340535, grad/param norm = 1.7517e-01, time/batch = 0.6404s	
4814/26050 (epoch 9.240), train_loss = 1.26048786, grad/param norm = 1.8471e-01, time/batch = 0.6391s	
4815/26050 (epoch 9.242), train_loss = 1.27538898, grad/param norm = 1.6249e-01, time/batch = 0.6398s	
4816/26050 (epoch 9.244), train_loss = 1.35914777, grad/param norm = 1.9224e-01, time/batch = 0.6458s	
4817/26050 (epoch 9.246), train_loss = 1.22964035, grad/param norm = 1.6507e-01, time/batch = 0.6379s	
4818/26050 (epoch 9.248), train_loss = 1.34614365, grad/param norm = 1.8089e-01, time/batch = 0.6397s	
4819/26050 (epoch 9.250), train_loss = 1.33942513, grad/param norm = 1.9300e-01, time/batch = 0.6397s	
4820/26050 (epoch 9.251), train_loss = 1.20510466, grad/param norm = 1.6716e-01, time/batch = 0.6400s	
4821/26050 (epoch 9.253), train_loss = 1.11953863, grad/param norm = 1.7371e-01, time/batch = 0.6415s	
4822/26050 (epoch 9.255), train_loss = 1.54096766, grad/param norm = 1.8824e-01, time/batch = 0.6397s	
4823/26050 (epoch 9.257), train_loss = 1.31134951, grad/param norm = 1.9767e-01, time/batch = 0.6386s	
4824/26050 (epoch 9.259), train_loss = 1.45634041, grad/param norm = 1.7951e-01, time/batch = 0.6400s	
4825/26050 (epoch 9.261), train_loss = 1.24219207, grad/param norm = 1.8624e-01, time/batch = 0.6401s	
4826/26050 (epoch 9.263), train_loss = 1.30610641, grad/param norm = 1.7594e-01, time/batch = 0.6388s	
4827/26050 (epoch 9.265), train_loss = 1.49127980, grad/param norm = 1.7567e-01, time/batch = 0.6406s	
4828/26050 (epoch 9.267), train_loss = 1.38628383, grad/param norm = 1.8716e-01, time/batch = 0.6407s	
4829/26050 (epoch 9.269), train_loss = 1.50875509, grad/param norm = 1.9743e-01, time/batch = 0.6392s	
4830/26050 (epoch 9.271), train_loss = 1.34761478, grad/param norm = 1.8177e-01, time/batch = 0.6389s	
4831/26050 (epoch 9.273), train_loss = 1.26145319, grad/param norm = 1.7153e-01, time/batch = 0.6838s	
4832/26050 (epoch 9.274), train_loss = 1.25825634, grad/param norm = 1.7736e-01, time/batch = 0.6624s	
4833/26050 (epoch 9.276), train_loss = 1.23025736, grad/param norm = 1.8079e-01, time/batch = 0.6457s	
4834/26050 (epoch 9.278), train_loss = 1.42064182, grad/param norm = 1.8007e-01, time/batch = 0.6428s	
4835/26050 (epoch 9.280), train_loss = 1.28291402, grad/param norm = 1.6710e-01, time/batch = 0.6408s	
4836/26050 (epoch 9.282), train_loss = 1.36536153, grad/param norm = 1.9366e-01, time/batch = 0.6405s	
4837/26050 (epoch 9.284), train_loss = 1.19837911, grad/param norm = 1.7339e-01, time/batch = 0.6391s	
4838/26050 (epoch 9.286), train_loss = 1.29368914, grad/param norm = 1.8577e-01, time/batch = 0.6398s	
4839/26050 (epoch 9.288), train_loss = 1.12311507, grad/param norm = 1.5226e-01, time/batch = 0.6389s	
4840/26050 (epoch 9.290), train_loss = 1.28240378, grad/param norm = 1.8223e-01, time/batch = 0.6395s	
4841/26050 (epoch 9.292), train_loss = 1.23265847, grad/param norm = 1.6981e-01, time/batch = 0.6409s	
4842/26050 (epoch 9.294), train_loss = 1.32226569, grad/param norm = 1.8925e-01, time/batch = 0.6493s	
4843/26050 (epoch 9.296), train_loss = 1.42952996, grad/param norm = 1.8359e-01, time/batch = 0.6556s	
4844/26050 (epoch 9.298), train_loss = 1.29395124, grad/param norm = 1.6932e-01, time/batch = 0.6481s	
4845/26050 (epoch 9.299), train_loss = 1.05187788, grad/param norm = 1.4692e-01, time/batch = 0.6492s	
4846/26050 (epoch 9.301), train_loss = 1.23851928, grad/param norm = 1.8105e-01, time/batch = 0.6535s	
4847/26050 (epoch 9.303), train_loss = 1.35256028, grad/param norm = 1.7648e-01, time/batch = 0.6582s	
4848/26050 (epoch 9.305), train_loss = 1.13518111, grad/param norm = 1.6397e-01, time/batch = 0.6395s	
4849/26050 (epoch 9.307), train_loss = 1.19555544, grad/param norm = 1.7655e-01, time/batch = 0.6412s	
4850/26050 (epoch 9.309), train_loss = 1.27358821, grad/param norm = 1.8202e-01, time/batch = 0.6451s	
4851/26050 (epoch 9.311), train_loss = 1.49115028, grad/param norm = 2.0572e-01, time/batch = 0.6443s	
4852/26050 (epoch 9.313), train_loss = 1.30440593, grad/param norm = 1.8868e-01, time/batch = 0.6422s	
4853/26050 (epoch 9.315), train_loss = 1.44590977, grad/param norm = 1.8902e-01, time/batch = 0.6411s	
4854/26050 (epoch 9.317), train_loss = 1.24005021, grad/param norm = 1.7161e-01, time/batch = 0.6390s	
4855/26050 (epoch 9.319), train_loss = 1.26278000, grad/param norm = 1.6012e-01, time/batch = 0.6414s	
4856/26050 (epoch 9.321), train_loss = 1.26777993, grad/param norm = 1.7849e-01, time/batch = 0.6395s	
4857/26050 (epoch 9.322), train_loss = 1.32514779, grad/param norm = 1.7038e-01, time/batch = 0.6411s	
4858/26050 (epoch 9.324), train_loss = 1.11147139, grad/param norm = 1.7307e-01, time/batch = 0.6651s	
4859/26050 (epoch 9.326), train_loss = 1.45454381, grad/param norm = 1.8908e-01, time/batch = 0.6561s	
4860/26050 (epoch 9.328), train_loss = 1.34505872, grad/param norm = 1.7386e-01, time/batch = 0.6437s	
4861/26050 (epoch 9.330), train_loss = 1.19148911, grad/param norm = 1.7273e-01, time/batch = 0.6512s	
4862/26050 (epoch 9.332), train_loss = 1.40021035, grad/param norm = 1.8125e-01, time/batch = 0.6834s	
4863/26050 (epoch 9.334), train_loss = 1.28165280, grad/param norm = 1.7553e-01, time/batch = 0.6510s	
4864/26050 (epoch 9.336), train_loss = 1.18805201, grad/param norm = 1.5688e-01, time/batch = 0.6421s	
4865/26050 (epoch 9.338), train_loss = 1.15868098, grad/param norm = 1.5812e-01, time/batch = 0.6421s	
4866/26050 (epoch 9.340), train_loss = 1.40236212, grad/param norm = 1.9476e-01, time/batch = 0.6429s	
4867/26050 (epoch 9.342), train_loss = 1.45222185, grad/param norm = 1.8264e-01, time/batch = 0.6416s	
4868/26050 (epoch 9.344), train_loss = 1.29284354, grad/param norm = 1.8626e-01, time/batch = 0.6393s	
4869/26050 (epoch 9.345), train_loss = 1.30957676, grad/param norm = 1.9682e-01, time/batch = 0.6409s	
4870/26050 (epoch 9.347), train_loss = 1.38118035, grad/param norm = 1.8753e-01, time/batch = 0.6402s	
4871/26050 (epoch 9.349), train_loss = 1.33539559, grad/param norm = 1.8921e-01, time/batch = 0.6406s	
4872/26050 (epoch 9.351), train_loss = 1.34760038, grad/param norm = 1.9591e-01, time/batch = 0.6463s	
4873/26050 (epoch 9.353), train_loss = 1.24366268, grad/param norm = 1.8130e-01, time/batch = 0.6403s	
4874/26050 (epoch 9.355), train_loss = 1.40060642, grad/param norm = 1.9109e-01, time/batch = 0.6451s	
4875/26050 (epoch 9.357), train_loss = 1.16524040, grad/param norm = 1.6446e-01, time/batch = 0.6403s	
4876/26050 (epoch 9.359), train_loss = 1.40135890, grad/param norm = 1.8516e-01, time/batch = 0.6412s	
4877/26050 (epoch 9.361), train_loss = 1.22526806, grad/param norm = 1.7441e-01, time/batch = 0.6753s	
4878/26050 (epoch 9.363), train_loss = 1.34372974, grad/param norm = 1.7571e-01, time/batch = 0.6730s	
4879/26050 (epoch 9.365), train_loss = 1.23339637, grad/param norm = 1.6015e-01, time/batch = 0.6448s	
4880/26050 (epoch 9.367), train_loss = 1.29866546, grad/param norm = 1.7126e-01, time/batch = 0.6462s	
4881/26050 (epoch 9.369), train_loss = 1.26460089, grad/param norm = 1.6119e-01, time/batch = 0.6414s	
4882/26050 (epoch 9.370), train_loss = 1.18338537, grad/param norm = 1.5808e-01, time/batch = 0.6416s	
4883/26050 (epoch 9.372), train_loss = 1.40928370, grad/param norm = 1.9115e-01, time/batch = 0.6409s	
4884/26050 (epoch 9.374), train_loss = 1.51175128, grad/param norm = 1.8929e-01, time/batch = 0.6490s	
4885/26050 (epoch 9.376), train_loss = 1.54525419, grad/param norm = 1.8605e-01, time/batch = 0.6442s	
4886/26050 (epoch 9.378), train_loss = 1.28347383, grad/param norm = 1.8039e-01, time/batch = 0.6401s	
4887/26050 (epoch 9.380), train_loss = 1.51421061, grad/param norm = 1.9093e-01, time/batch = 0.6464s	
4888/26050 (epoch 9.382), train_loss = 1.65027398, grad/param norm = 2.1643e-01, time/batch = 0.6477s	
4889/26050 (epoch 9.384), train_loss = 1.27840765, grad/param norm = 1.7127e-01, time/batch = 0.6425s	
4890/26050 (epoch 9.386), train_loss = 1.42954765, grad/param norm = 1.8846e-01, time/batch = 0.6479s	
4891/26050 (epoch 9.388), train_loss = 1.34475807, grad/param norm = 1.7617e-01, time/batch = 0.6408s	
4892/26050 (epoch 9.390), train_loss = 1.17146459, grad/param norm = 1.5446e-01, time/batch = 0.6604s	
4893/26050 (epoch 9.392), train_loss = 1.19234136, grad/param norm = 1.6405e-01, time/batch = 0.6828s	
4894/26050 (epoch 9.393), train_loss = 1.37357014, grad/param norm = 1.7671e-01, time/batch = 0.6389s	
4895/26050 (epoch 9.395), train_loss = 1.38031348, grad/param norm = 1.7638e-01, time/batch = 0.6408s	
4896/26050 (epoch 9.397), train_loss = 1.37164129, grad/param norm = 1.9524e-01, time/batch = 0.6418s	
4897/26050 (epoch 9.399), train_loss = 1.17294556, grad/param norm = 1.5422e-01, time/batch = 0.6415s	
4898/26050 (epoch 9.401), train_loss = 1.25300363, grad/param norm = 1.6155e-01, time/batch = 0.6435s	
4899/26050 (epoch 9.403), train_loss = 1.31801743, grad/param norm = 1.7072e-01, time/batch = 0.6472s	
4900/26050 (epoch 9.405), train_loss = 1.31386314, grad/param norm = 1.8102e-01, time/batch = 0.6417s	
4901/26050 (epoch 9.407), train_loss = 1.46628061, grad/param norm = 1.8930e-01, time/batch = 0.6424s	
4902/26050 (epoch 9.409), train_loss = 1.50110885, grad/param norm = 1.9569e-01, time/batch = 0.6396s	
4903/26050 (epoch 9.411), train_loss = 1.36232163, grad/param norm = 1.7923e-01, time/batch = 0.6395s	
4904/26050 (epoch 9.413), train_loss = 1.44605605, grad/param norm = 1.7361e-01, time/batch = 0.6467s	
4905/26050 (epoch 9.415), train_loss = 1.44563757, grad/param norm = 1.9407e-01, time/batch = 0.6409s	
4906/26050 (epoch 9.417), train_loss = 1.55093971, grad/param norm = 1.9116e-01, time/batch = 0.6393s	
4907/26050 (epoch 9.418), train_loss = 1.42437377, grad/param norm = 1.9854e-01, time/batch = 0.6404s	
4908/26050 (epoch 9.420), train_loss = 1.11718842, grad/param norm = 1.5746e-01, time/batch = 0.6707s	
4909/26050 (epoch 9.422), train_loss = 1.17498240, grad/param norm = 1.7271e-01, time/batch = 0.6423s	
4910/26050 (epoch 9.424), train_loss = 1.52820441, grad/param norm = 2.1462e-01, time/batch = 0.6392s	
4911/26050 (epoch 9.426), train_loss = 1.47924289, grad/param norm = 1.9480e-01, time/batch = 0.6406s	
4912/26050 (epoch 9.428), train_loss = 1.21871689, grad/param norm = 1.5658e-01, time/batch = 0.6428s	
4913/26050 (epoch 9.430), train_loss = 1.36616234, grad/param norm = 1.8681e-01, time/batch = 0.6430s	
4914/26050 (epoch 9.432), train_loss = 1.25574564, grad/param norm = 1.7498e-01, time/batch = 0.6406s	
4915/26050 (epoch 9.434), train_loss = 1.32421179, grad/param norm = 1.8531e-01, time/batch = 0.6412s	
4916/26050 (epoch 9.436), train_loss = 1.44434022, grad/param norm = 1.6671e-01, time/batch = 0.6388s	
4917/26050 (epoch 9.438), train_loss = 1.19747441, grad/param norm = 1.6541e-01, time/batch = 0.6404s	
4918/26050 (epoch 9.440), train_loss = 1.35519904, grad/param norm = 1.7291e-01, time/batch = 0.6403s	
4919/26050 (epoch 9.441), train_loss = 1.31684925, grad/param norm = 1.6678e-01, time/batch = 0.6393s	
4920/26050 (epoch 9.443), train_loss = 1.11417912, grad/param norm = 1.5034e-01, time/batch = 0.6461s	
4921/26050 (epoch 9.445), train_loss = 1.18416002, grad/param norm = 1.6689e-01, time/batch = 0.6420s	
4922/26050 (epoch 9.447), train_loss = 1.53382586, grad/param norm = 1.9493e-01, time/batch = 0.6410s	
4923/26050 (epoch 9.449), train_loss = 1.21837319, grad/param norm = 1.7046e-01, time/batch = 0.6415s	
4924/26050 (epoch 9.451), train_loss = 1.42137085, grad/param norm = 1.6565e-01, time/batch = 0.6396s	
4925/26050 (epoch 9.453), train_loss = 1.19166265, grad/param norm = 1.6314e-01, time/batch = 0.6405s	
4926/26050 (epoch 9.455), train_loss = 1.34041118, grad/param norm = 1.7515e-01, time/batch = 0.6521s	
4927/26050 (epoch 9.457), train_loss = 1.33465356, grad/param norm = 1.7394e-01, time/batch = 0.6613s	
4928/26050 (epoch 9.459), train_loss = 1.44233475, grad/param norm = 1.8281e-01, time/batch = 0.6726s	
4929/26050 (epoch 9.461), train_loss = 1.38471703, grad/param norm = 1.8704e-01, time/batch = 0.6703s	
4930/26050 (epoch 9.463), train_loss = 1.24255989, grad/param norm = 1.5945e-01, time/batch = 0.6741s	
4931/26050 (epoch 9.464), train_loss = 1.39711588, grad/param norm = 1.8230e-01, time/batch = 0.6771s	
4932/26050 (epoch 9.466), train_loss = 1.41296647, grad/param norm = 1.8908e-01, time/batch = 0.6773s	
4933/26050 (epoch 9.468), train_loss = 1.41483564, grad/param norm = 1.6495e-01, time/batch = 0.6766s	
4934/26050 (epoch 9.470), train_loss = 1.53470138, grad/param norm = 2.0046e-01, time/batch = 0.6812s	
4935/26050 (epoch 9.472), train_loss = 1.50555753, grad/param norm = 1.8856e-01, time/batch = 0.6676s	
4936/26050 (epoch 9.474), train_loss = 1.58299917, grad/param norm = 1.8562e-01, time/batch = 0.6754s	
4937/26050 (epoch 9.476), train_loss = 1.40719302, grad/param norm = 1.6702e-01, time/batch = 0.6576s	
4938/26050 (epoch 9.478), train_loss = 1.22833172, grad/param norm = 1.5818e-01, time/batch = 0.6657s	
4939/26050 (epoch 9.480), train_loss = 1.33915453, grad/param norm = 1.5954e-01, time/batch = 0.6778s	
4940/26050 (epoch 9.482), train_loss = 1.29400121, grad/param norm = 1.7324e-01, time/batch = 0.6420s	
4941/26050 (epoch 9.484), train_loss = 1.21512583, grad/param norm = 1.7624e-01, time/batch = 0.6504s	
4942/26050 (epoch 9.486), train_loss = 1.49589724, grad/param norm = 1.7566e-01, time/batch = 0.6451s	
4943/26050 (epoch 9.488), train_loss = 1.66939141, grad/param norm = 1.9211e-01, time/batch = 0.6396s	
4944/26050 (epoch 9.489), train_loss = 1.60134796, grad/param norm = 1.9980e-01, time/batch = 0.6406s	
4945/26050 (epoch 9.491), train_loss = 1.23258598, grad/param norm = 1.6934e-01, time/batch = 0.6394s	
4946/26050 (epoch 9.493), train_loss = 1.29034676, grad/param norm = 1.6768e-01, time/batch = 0.6384s	
4947/26050 (epoch 9.495), train_loss = 1.28898071, grad/param norm = 1.6506e-01, time/batch = 0.6431s	
4948/26050 (epoch 9.497), train_loss = 1.27697788, grad/param norm = 1.6966e-01, time/batch = 0.6465s	
4949/26050 (epoch 9.499), train_loss = 1.28686009, grad/param norm = 1.7802e-01, time/batch = 0.6419s	
4950/26050 (epoch 9.501), train_loss = 1.37771619, grad/param norm = 1.8206e-01, time/batch = 0.6448s	
4951/26050 (epoch 9.503), train_loss = 1.26292956, grad/param norm = 1.8572e-01, time/batch = 0.6408s	
4952/26050 (epoch 9.505), train_loss = 1.45900359, grad/param norm = 1.7849e-01, time/batch = 0.6400s	
4953/26050 (epoch 9.507), train_loss = 1.46686990, grad/param norm = 1.8988e-01, time/batch = 0.6445s	
4954/26050 (epoch 9.509), train_loss = 1.56153733, grad/param norm = 1.9694e-01, time/batch = 0.6618s	
4955/26050 (epoch 9.511), train_loss = 1.23976153, grad/param norm = 1.7598e-01, time/batch = 0.6465s	
4956/26050 (epoch 9.512), train_loss = 1.32057920, grad/param norm = 1.8493e-01, time/batch = 0.6417s	
4957/26050 (epoch 9.514), train_loss = 1.39653052, grad/param norm = 1.7971e-01, time/batch = 0.6417s	
4958/26050 (epoch 9.516), train_loss = 1.44026688, grad/param norm = 1.8151e-01, time/batch = 0.6412s	
4959/26050 (epoch 9.518), train_loss = 1.38899921, grad/param norm = 1.8285e-01, time/batch = 0.6400s	
4960/26050 (epoch 9.520), train_loss = 1.35044516, grad/param norm = 1.7481e-01, time/batch = 0.6546s	
4961/26050 (epoch 9.522), train_loss = 1.15729400, grad/param norm = 1.6528e-01, time/batch = 0.6619s	
4962/26050 (epoch 9.524), train_loss = 1.49891218, grad/param norm = 1.8780e-01, time/batch = 0.6611s	
4963/26050 (epoch 9.526), train_loss = 1.41882394, grad/param norm = 1.8021e-01, time/batch = 0.6558s	
4964/26050 (epoch 9.528), train_loss = 1.39404348, grad/param norm = 1.8139e-01, time/batch = 0.6423s	
4965/26050 (epoch 9.530), train_loss = 1.31256574, grad/param norm = 1.6347e-01, time/batch = 0.6434s	
4966/26050 (epoch 9.532), train_loss = 1.33222599, grad/param norm = 1.7565e-01, time/batch = 0.6480s	
4967/26050 (epoch 9.534), train_loss = 1.42688576, grad/param norm = 1.8367e-01, time/batch = 0.6418s	
4968/26050 (epoch 9.536), train_loss = 1.28399921, grad/param norm = 1.5878e-01, time/batch = 0.6413s	
4969/26050 (epoch 9.537), train_loss = 1.45265456, grad/param norm = 1.8800e-01, time/batch = 0.6749s	
4970/26050 (epoch 9.539), train_loss = 1.32436949, grad/param norm = 1.7020e-01, time/batch = 0.6687s	
4971/26050 (epoch 9.541), train_loss = 1.54502976, grad/param norm = 2.0842e-01, time/batch = 0.6428s	
4972/26050 (epoch 9.543), train_loss = 1.15741600, grad/param norm = 1.6275e-01, time/batch = 0.6428s	
4973/26050 (epoch 9.545), train_loss = 1.40245935, grad/param norm = 1.7908e-01, time/batch = 0.6431s	
4974/26050 (epoch 9.547), train_loss = 1.36210010, grad/param norm = 1.8126e-01, time/batch = 0.6424s	
4975/26050 (epoch 9.549), train_loss = 1.15393608, grad/param norm = 1.7495e-01, time/batch = 0.6414s	
4976/26050 (epoch 9.551), train_loss = 1.38525271, grad/param norm = 1.8618e-01, time/batch = 0.6438s	
4977/26050 (epoch 9.553), train_loss = 1.23017280, grad/param norm = 1.6668e-01, time/batch = 0.6427s	
4978/26050 (epoch 9.555), train_loss = 1.27941305, grad/param norm = 1.6737e-01, time/batch = 0.6420s	
4979/26050 (epoch 9.557), train_loss = 1.39422058, grad/param norm = 1.6870e-01, time/batch = 0.6514s	
4980/26050 (epoch 9.559), train_loss = 1.34222192, grad/param norm = 1.7869e-01, time/batch = 0.6560s	
4981/26050 (epoch 9.560), train_loss = 1.32379108, grad/param norm = 1.8129e-01, time/batch = 0.6620s	
4982/26050 (epoch 9.562), train_loss = 1.30843970, grad/param norm = 1.7659e-01, time/batch = 0.6607s	
4983/26050 (epoch 9.564), train_loss = 1.54239633, grad/param norm = 1.8743e-01, time/batch = 0.6579s	
4984/26050 (epoch 9.566), train_loss = 1.21140052, grad/param norm = 1.6801e-01, time/batch = 0.6722s	
4985/26050 (epoch 9.568), train_loss = 1.34901177, grad/param norm = 1.7544e-01, time/batch = 0.6788s	
4986/26050 (epoch 9.570), train_loss = 1.46330781, grad/param norm = 1.8957e-01, time/batch = 0.6544s	
4987/26050 (epoch 9.572), train_loss = 1.31418724, grad/param norm = 1.6564e-01, time/batch = 0.6555s	
4988/26050 (epoch 9.574), train_loss = 1.42943208, grad/param norm = 2.0424e-01, time/batch = 0.6565s	
4989/26050 (epoch 9.576), train_loss = 1.42143567, grad/param norm = 1.9494e-01, time/batch = 0.6523s	
4990/26050 (epoch 9.578), train_loss = 1.33117923, grad/param norm = 1.8148e-01, time/batch = 0.6558s	
4991/26050 (epoch 9.580), train_loss = 1.21966075, grad/param norm = 1.7254e-01, time/batch = 0.6508s	
4992/26050 (epoch 9.582), train_loss = 1.38782904, grad/param norm = 1.8565e-01, time/batch = 0.6391s	
4993/26050 (epoch 9.583), train_loss = 1.42380298, grad/param norm = 1.8281e-01, time/batch = 0.6392s	
4994/26050 (epoch 9.585), train_loss = 1.22347645, grad/param norm = 1.7854e-01, time/batch = 0.6403s	
4995/26050 (epoch 9.587), train_loss = 1.39806871, grad/param norm = 1.7904e-01, time/batch = 0.6429s	
4996/26050 (epoch 9.589), train_loss = 1.43239371, grad/param norm = 1.9564e-01, time/batch = 0.6410s	
4997/26050 (epoch 9.591), train_loss = 1.37044974, grad/param norm = 1.8775e-01, time/batch = 0.6413s	
4998/26050 (epoch 9.593), train_loss = 1.21125678, grad/param norm = 1.8981e-01, time/batch = 0.6402s	
4999/26050 (epoch 9.595), train_loss = 1.50660304, grad/param norm = 2.1032e-01, time/batch = 0.6492s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch9.60_1.6043.t7	
5000/26050 (epoch 9.597), train_loss = 1.37654598, grad/param norm = 1.8793e-01, time/batch = 0.6793s	
5001/26050 (epoch 9.599), train_loss = 1.49157123, grad/param norm = 1.9802e-01, time/batch = 0.6471s	
5002/26050 (epoch 9.601), train_loss = 1.54874047, grad/param norm = 1.8568e-01, time/batch = 0.6409s	
5003/26050 (epoch 9.603), train_loss = 1.40410242, grad/param norm = 1.8130e-01, time/batch = 0.6414s	
5004/26050 (epoch 9.605), train_loss = 1.26703876, grad/param norm = 1.6926e-01, time/batch = 0.6457s	
5005/26050 (epoch 9.607), train_loss = 1.47695800, grad/param norm = 1.8907e-01, time/batch = 0.6413s	
5006/26050 (epoch 9.608), train_loss = 1.27127001, grad/param norm = 1.6080e-01, time/batch = 0.6457s	
5007/26050 (epoch 9.610), train_loss = 1.30999482, grad/param norm = 1.8017e-01, time/batch = 0.6428s	
5008/26050 (epoch 9.612), train_loss = 1.30209831, grad/param norm = 1.7536e-01, time/batch = 0.6434s	
5009/26050 (epoch 9.614), train_loss = 1.40495085, grad/param norm = 1.7940e-01, time/batch = 0.6450s	
5010/26050 (epoch 9.616), train_loss = 1.60335657, grad/param norm = 1.9181e-01, time/batch = 0.6430s	
5011/26050 (epoch 9.618), train_loss = 1.26260749, grad/param norm = 1.8358e-01, time/batch = 0.6412s	
5012/26050 (epoch 9.620), train_loss = 1.35929746, grad/param norm = 1.8701e-01, time/batch = 0.6415s	
5013/26050 (epoch 9.622), train_loss = 1.11756028, grad/param norm = 1.5887e-01, time/batch = 0.6407s	
5014/26050 (epoch 9.624), train_loss = 1.20779996, grad/param norm = 1.6471e-01, time/batch = 0.6399s	
5015/26050 (epoch 9.626), train_loss = 1.40391988, grad/param norm = 1.8654e-01, time/batch = 0.6391s	
5016/26050 (epoch 9.628), train_loss = 1.30973416, grad/param norm = 1.8989e-01, time/batch = 0.6396s	
5017/26050 (epoch 9.630), train_loss = 1.46438899, grad/param norm = 1.7477e-01, time/batch = 0.6408s	
5018/26050 (epoch 9.631), train_loss = 1.48255797, grad/param norm = 1.8753e-01, time/batch = 0.6408s	
5019/26050 (epoch 9.633), train_loss = 1.24411280, grad/param norm = 1.7466e-01, time/batch = 0.6552s	
5020/26050 (epoch 9.635), train_loss = 1.23033887, grad/param norm = 1.6128e-01, time/batch = 0.6547s	
5021/26050 (epoch 9.637), train_loss = 1.23872174, grad/param norm = 1.7945e-01, time/batch = 0.6697s	
5022/26050 (epoch 9.639), train_loss = 1.43534759, grad/param norm = 1.7372e-01, time/batch = 0.6584s	
5023/26050 (epoch 9.641), train_loss = 1.27046134, grad/param norm = 1.5801e-01, time/batch = 0.6597s	
5024/26050 (epoch 9.643), train_loss = 1.20189051, grad/param norm = 1.5132e-01, time/batch = 0.6590s	
5025/26050 (epoch 9.645), train_loss = 1.37234490, grad/param norm = 2.0174e-01, time/batch = 0.6562s	
5026/26050 (epoch 9.647), train_loss = 1.29083194, grad/param norm = 1.7191e-01, time/batch = 0.6408s	
5027/26050 (epoch 9.649), train_loss = 1.37960659, grad/param norm = 1.9443e-01, time/batch = 0.6409s	
5028/26050 (epoch 9.651), train_loss = 1.26796013, grad/param norm = 1.8160e-01, time/batch = 0.6405s	
5029/26050 (epoch 9.653), train_loss = 1.32712191, grad/param norm = 1.7787e-01, time/batch = 0.6505s	
5030/26050 (epoch 9.655), train_loss = 1.23635769, grad/param norm = 1.7212e-01, time/batch = 0.6600s	
5031/26050 (epoch 9.656), train_loss = 1.19966859, grad/param norm = 1.7382e-01, time/batch = 0.6556s	
5032/26050 (epoch 9.658), train_loss = 1.54059977, grad/param norm = 1.8257e-01, time/batch = 0.6438s	
5033/26050 (epoch 9.660), train_loss = 1.21823832, grad/param norm = 1.9195e-01, time/batch = 0.6577s	
5034/26050 (epoch 9.662), train_loss = 1.19918142, grad/param norm = 1.6183e-01, time/batch = 0.6723s	
5035/26050 (epoch 9.664), train_loss = 1.30336451, grad/param norm = 1.7677e-01, time/batch = 0.6766s	
5036/26050 (epoch 9.666), train_loss = 1.36518569, grad/param norm = 1.9020e-01, time/batch = 0.6616s	
5037/26050 (epoch 9.668), train_loss = 1.10991458, grad/param norm = 1.5800e-01, time/batch = 0.6505s	
5038/26050 (epoch 9.670), train_loss = 1.50825881, grad/param norm = 1.9557e-01, time/batch = 0.6764s	
5039/26050 (epoch 9.672), train_loss = 1.25689758, grad/param norm = 1.7876e-01, time/batch = 0.6767s	
5040/26050 (epoch 9.674), train_loss = 1.21561681, grad/param norm = 1.6087e-01, time/batch = 0.6554s	
5041/26050 (epoch 9.676), train_loss = 1.36650668, grad/param norm = 1.6850e-01, time/batch = 0.6546s	
5042/26050 (epoch 9.678), train_loss = 1.48277086, grad/param norm = 1.8282e-01, time/batch = 0.6424s	
5043/26050 (epoch 9.679), train_loss = 1.54246635, grad/param norm = 1.9727e-01, time/batch = 0.6428s	
5044/26050 (epoch 9.681), train_loss = 1.35413533, grad/param norm = 1.8224e-01, time/batch = 0.6407s	
5045/26050 (epoch 9.683), train_loss = 1.25367488, grad/param norm = 2.0085e-01, time/batch = 0.6424s	
5046/26050 (epoch 9.685), train_loss = 1.26404559, grad/param norm = 1.6209e-01, time/batch = 0.6427s	
5047/26050 (epoch 9.687), train_loss = 1.12659760, grad/param norm = 1.5856e-01, time/batch = 0.6461s	
5048/26050 (epoch 9.689), train_loss = 1.30087639, grad/param norm = 1.7110e-01, time/batch = 0.6449s	
5049/26050 (epoch 9.691), train_loss = 1.05012165, grad/param norm = 1.6549e-01, time/batch = 0.6420s	
5050/26050 (epoch 9.693), train_loss = 1.24485130, grad/param norm = 1.7532e-01, time/batch = 0.6438s	
5051/26050 (epoch 9.695), train_loss = 1.34181212, grad/param norm = 1.7811e-01, time/batch = 0.6463s	
5052/26050 (epoch 9.697), train_loss = 1.20022522, grad/param norm = 1.7214e-01, time/batch = 0.6420s	
5053/26050 (epoch 9.699), train_loss = 1.38755088, grad/param norm = 1.8189e-01, time/batch = 0.6640s	
5054/26050 (epoch 9.701), train_loss = 1.15236917, grad/param norm = 1.5873e-01, time/batch = 0.6801s	
5055/26050 (epoch 9.702), train_loss = 1.54435049, grad/param norm = 1.9289e-01, time/batch = 0.6423s	
5056/26050 (epoch 9.704), train_loss = 1.34668062, grad/param norm = 1.7086e-01, time/batch = 0.6457s	
5057/26050 (epoch 9.706), train_loss = 1.39576890, grad/param norm = 2.0009e-01, time/batch = 0.6442s	
5058/26050 (epoch 9.708), train_loss = 1.39448188, grad/param norm = 1.7494e-01, time/batch = 0.6434s	
5059/26050 (epoch 9.710), train_loss = 1.39291526, grad/param norm = 1.7775e-01, time/batch = 0.6408s	
5060/26050 (epoch 9.712), train_loss = 1.49824382, grad/param norm = 1.8413e-01, time/batch = 0.6409s	
5061/26050 (epoch 9.714), train_loss = 1.18139594, grad/param norm = 1.7812e-01, time/batch = 0.6424s	
5062/26050 (epoch 9.716), train_loss = 1.58875435, grad/param norm = 2.0684e-01, time/batch = 0.6417s	
5063/26050 (epoch 9.718), train_loss = 1.44202566, grad/param norm = 1.8750e-01, time/batch = 0.6411s	
5064/26050 (epoch 9.720), train_loss = 1.25262789, grad/param norm = 1.7148e-01, time/batch = 0.6395s	
5065/26050 (epoch 9.722), train_loss = 1.19825740, grad/param norm = 1.6719e-01, time/batch = 0.6432s	
5066/26050 (epoch 9.724), train_loss = 1.20267672, grad/param norm = 1.7268e-01, time/batch = 0.6401s	
5067/26050 (epoch 9.726), train_loss = 1.43644963, grad/param norm = 1.7701e-01, time/batch = 0.6390s	
5068/26050 (epoch 9.727), train_loss = 1.38942218, grad/param norm = 1.7239e-01, time/batch = 0.6443s	
5069/26050 (epoch 9.729), train_loss = 1.38660593, grad/param norm = 1.8073e-01, time/batch = 0.6826s	
5070/26050 (epoch 9.731), train_loss = 1.33777586, grad/param norm = 1.5981e-01, time/batch = 0.6562s	
5071/26050 (epoch 9.733), train_loss = 1.29843056, grad/param norm = 2.1491e-01, time/batch = 0.6438s	
5072/26050 (epoch 9.735), train_loss = 1.52372065, grad/param norm = 1.8302e-01, time/batch = 0.6472s	
5073/26050 (epoch 9.737), train_loss = 1.33382986, grad/param norm = 1.8184e-01, time/batch = 0.6438s	
5074/26050 (epoch 9.739), train_loss = 1.36185388, grad/param norm = 1.6671e-01, time/batch = 0.6406s	
5075/26050 (epoch 9.741), train_loss = 1.22742583, grad/param norm = 1.6579e-01, time/batch = 0.6440s	
5076/26050 (epoch 9.743), train_loss = 1.40939898, grad/param norm = 2.3930e-01, time/batch = 0.6428s	
5077/26050 (epoch 9.745), train_loss = 1.20186419, grad/param norm = 1.7382e-01, time/batch = 0.6415s	
5078/26050 (epoch 9.747), train_loss = 1.22286317, grad/param norm = 1.7440e-01, time/batch = 0.6422s	
5079/26050 (epoch 9.749), train_loss = 1.45621088, grad/param norm = 1.8859e-01, time/batch = 0.6432s	
5080/26050 (epoch 9.750), train_loss = 1.30108471, grad/param norm = 1.6339e-01, time/batch = 0.6408s	
5081/26050 (epoch 9.752), train_loss = 1.34559928, grad/param norm = 1.8942e-01, time/batch = 0.6521s	
5082/26050 (epoch 9.754), train_loss = 1.32254808, grad/param norm = 1.6799e-01, time/batch = 0.6436s	
5083/26050 (epoch 9.756), train_loss = 1.38032513, grad/param norm = 2.0127e-01, time/batch = 0.6413s	
5084/26050 (epoch 9.758), train_loss = 1.34426180, grad/param norm = 1.7664e-01, time/batch = 0.6710s	
5085/26050 (epoch 9.760), train_loss = 1.42987336, grad/param norm = 1.8473e-01, time/batch = 0.6747s	
5086/26050 (epoch 9.762), train_loss = 1.21953186, grad/param norm = 1.6098e-01, time/batch = 0.6457s	
5087/26050 (epoch 9.764), train_loss = 1.43210872, grad/param norm = 1.9935e-01, time/batch = 0.6429s	
5088/26050 (epoch 9.766), train_loss = 1.42318261, grad/param norm = 1.9309e-01, time/batch = 0.6419s	
5089/26050 (epoch 9.768), train_loss = 1.17980958, grad/param norm = 1.5379e-01, time/batch = 0.6449s	
5090/26050 (epoch 9.770), train_loss = 1.33545519, grad/param norm = 1.8038e-01, time/batch = 0.6438s	
5091/26050 (epoch 9.772), train_loss = 1.31253818, grad/param norm = 1.6704e-01, time/batch = 0.6441s	
5092/26050 (epoch 9.774), train_loss = 1.18288563, grad/param norm = 1.7505e-01, time/batch = 0.6417s	
5093/26050 (epoch 9.775), train_loss = 1.02191967, grad/param norm = 1.5980e-01, time/batch = 0.6427s	
5094/26050 (epoch 9.777), train_loss = 1.24471919, grad/param norm = 1.7512e-01, time/batch = 0.6428s	
5095/26050 (epoch 9.779), train_loss = 1.28776622, grad/param norm = 1.7277e-01, time/batch = 0.6404s	
5096/26050 (epoch 9.781), train_loss = 1.26888403, grad/param norm = 1.6838e-01, time/batch = 0.6441s	
5097/26050 (epoch 9.783), train_loss = 1.23723945, grad/param norm = 1.6764e-01, time/batch = 0.6491s	
5098/26050 (epoch 9.785), train_loss = 1.26871146, grad/param norm = 1.8429e-01, time/batch = 0.6441s	
5099/26050 (epoch 9.787), train_loss = 1.24875734, grad/param norm = 1.7237e-01, time/batch = 0.6577s	
5100/26050 (epoch 9.789), train_loss = 1.30163297, grad/param norm = 1.9350e-01, time/batch = 0.6827s	
5101/26050 (epoch 9.791), train_loss = 1.31956724, grad/param norm = 1.7309e-01, time/batch = 0.6469s	
5102/26050 (epoch 9.793), train_loss = 1.30036377, grad/param norm = 1.7899e-01, time/batch = 0.6444s	
5103/26050 (epoch 9.795), train_loss = 1.12998619, grad/param norm = 1.5621e-01, time/batch = 0.6446s	
5104/26050 (epoch 9.797), train_loss = 1.21698548, grad/param norm = 1.6745e-01, time/batch = 0.6449s	
5105/26050 (epoch 9.798), train_loss = 1.18244816, grad/param norm = 1.7309e-01, time/batch = 0.6439s	
5106/26050 (epoch 9.800), train_loss = 1.16305213, grad/param norm = 1.5134e-01, time/batch = 0.6436s	
5107/26050 (epoch 9.802), train_loss = 1.29178309, grad/param norm = 1.7695e-01, time/batch = 0.6584s	
5108/26050 (epoch 9.804), train_loss = 1.28485268, grad/param norm = 1.6523e-01, time/batch = 0.6586s	
5109/26050 (epoch 9.806), train_loss = 1.43973532, grad/param norm = 1.8971e-01, time/batch = 0.6519s	
5110/26050 (epoch 9.808), train_loss = 1.28361545, grad/param norm = 1.7624e-01, time/batch = 0.6589s	
5111/26050 (epoch 9.810), train_loss = 1.25839856, grad/param norm = 1.7374e-01, time/batch = 0.6771s	
5112/26050 (epoch 9.812), train_loss = 1.18673046, grad/param norm = 1.7810e-01, time/batch = 0.6604s	
5113/26050 (epoch 9.814), train_loss = 1.19778918, grad/param norm = 1.9265e-01, time/batch = 0.6659s	
5114/26050 (epoch 9.816), train_loss = 1.38623304, grad/param norm = 1.8343e-01, time/batch = 0.6658s	
5115/26050 (epoch 9.818), train_loss = 1.49232088, grad/param norm = 2.1266e-01, time/batch = 0.6850s	
5116/26050 (epoch 9.820), train_loss = 1.33186365, grad/param norm = 1.8163e-01, time/batch = 0.6629s	
5117/26050 (epoch 9.821), train_loss = 1.48910248, grad/param norm = 2.1503e-01, time/batch = 0.6496s	
5118/26050 (epoch 9.823), train_loss = 1.52363781, grad/param norm = 1.8827e-01, time/batch = 0.6567s	
5119/26050 (epoch 9.825), train_loss = 1.27286429, grad/param norm = 1.8875e-01, time/batch = 0.6572s	
5120/26050 (epoch 9.827), train_loss = 1.36501518, grad/param norm = 1.8950e-01, time/batch = 0.6651s	
5121/26050 (epoch 9.829), train_loss = 1.37410444, grad/param norm = 1.8036e-01, time/batch = 0.6641s	
5122/26050 (epoch 9.831), train_loss = 1.45830604, grad/param norm = 1.8219e-01, time/batch = 0.6630s	
5123/26050 (epoch 9.833), train_loss = 1.53261401, grad/param norm = 1.8364e-01, time/batch = 0.6635s	
5124/26050 (epoch 9.835), train_loss = 1.55857215, grad/param norm = 1.9010e-01, time/batch = 0.6684s	
5125/26050 (epoch 9.837), train_loss = 1.27452419, grad/param norm = 1.6919e-01, time/batch = 0.6682s	
5126/26050 (epoch 9.839), train_loss = 1.40674024, grad/param norm = 1.9842e-01, time/batch = 0.6569s	
5127/26050 (epoch 9.841), train_loss = 1.44306459, grad/param norm = 1.7771e-01, time/batch = 0.6568s	
5128/26050 (epoch 9.843), train_loss = 1.38253409, grad/param norm = 1.8603e-01, time/batch = 0.6520s	
5129/26050 (epoch 9.845), train_loss = 1.24292580, grad/param norm = 1.6838e-01, time/batch = 0.6476s	
5130/26050 (epoch 9.846), train_loss = 1.47266741, grad/param norm = 1.8580e-01, time/batch = 0.6412s	
5131/26050 (epoch 9.848), train_loss = 1.27595509, grad/param norm = 1.7310e-01, time/batch = 0.6549s	
5132/26050 (epoch 9.850), train_loss = 1.26894763, grad/param norm = 1.7091e-01, time/batch = 0.6588s	
5133/26050 (epoch 9.852), train_loss = 1.29653828, grad/param norm = 1.7892e-01, time/batch = 0.6581s	
5134/26050 (epoch 9.854), train_loss = 1.32803070, grad/param norm = 1.7540e-01, time/batch = 0.6572s	
5135/26050 (epoch 9.856), train_loss = 1.25651474, grad/param norm = 1.8159e-01, time/batch = 0.6633s	
5136/26050 (epoch 9.858), train_loss = 1.19993165, grad/param norm = 1.7969e-01, time/batch = 0.6435s	
5137/26050 (epoch 9.860), train_loss = 1.36765888, grad/param norm = 1.9381e-01, time/batch = 0.6385s	
5138/26050 (epoch 9.862), train_loss = 1.33369076, grad/param norm = 1.8108e-01, time/batch = 0.6428s	
5139/26050 (epoch 9.864), train_loss = 1.30803476, grad/param norm = 1.8284e-01, time/batch = 0.6428s	
5140/26050 (epoch 9.866), train_loss = 1.22995461, grad/param norm = 1.6219e-01, time/batch = 0.6587s	
5141/26050 (epoch 9.868), train_loss = 1.42931134, grad/param norm = 1.9631e-01, time/batch = 0.6842s	
5142/26050 (epoch 9.869), train_loss = 1.18166380, grad/param norm = 1.6135e-01, time/batch = 0.6417s	
5143/26050 (epoch 9.871), train_loss = 1.13742669, grad/param norm = 1.5477e-01, time/batch = 0.6421s	
5144/26050 (epoch 9.873), train_loss = 1.36949775, grad/param norm = 1.7697e-01, time/batch = 0.6388s	
5145/26050 (epoch 9.875), train_loss = 1.29628740, grad/param norm = 1.7702e-01, time/batch = 0.6446s	
5146/26050 (epoch 9.877), train_loss = 1.17514443, grad/param norm = 1.7248e-01, time/batch = 0.6677s	
5147/26050 (epoch 9.879), train_loss = 1.30462936, grad/param norm = 1.6449e-01, time/batch = 0.6400s	
5148/26050 (epoch 9.881), train_loss = 1.47865460, grad/param norm = 1.8748e-01, time/batch = 0.6405s	
5149/26050 (epoch 9.883), train_loss = 1.34732267, grad/param norm = 1.7411e-01, time/batch = 0.6413s	
5150/26050 (epoch 9.885), train_loss = 1.03785717, grad/param norm = 1.5276e-01, time/batch = 0.6409s	
5151/26050 (epoch 9.887), train_loss = 1.36593855, grad/param norm = 1.7777e-01, time/batch = 0.6405s	
5152/26050 (epoch 9.889), train_loss = 1.24791798, grad/param norm = 1.6377e-01, time/batch = 0.6409s	
5153/26050 (epoch 9.891), train_loss = 1.08000313, grad/param norm = 1.5506e-01, time/batch = 0.6406s	
5154/26050 (epoch 9.893), train_loss = 1.05948593, grad/param norm = 1.5298e-01, time/batch = 0.6402s	
5155/26050 (epoch 9.894), train_loss = 1.23798626, grad/param norm = 1.6485e-01, time/batch = 0.6455s	
5156/26050 (epoch 9.896), train_loss = 1.42811842, grad/param norm = 1.7906e-01, time/batch = 0.6830s	
5157/26050 (epoch 9.898), train_loss = 1.25350602, grad/param norm = 1.8911e-01, time/batch = 0.6604s	
5158/26050 (epoch 9.900), train_loss = 1.49642771, grad/param norm = 1.8645e-01, time/batch = 0.6396s	
5159/26050 (epoch 9.902), train_loss = 1.31759775, grad/param norm = 1.7679e-01, time/batch = 0.6386s	
5160/26050 (epoch 9.904), train_loss = 1.26153985, grad/param norm = 1.6129e-01, time/batch = 0.6407s	
5161/26050 (epoch 9.906), train_loss = 1.29090651, grad/param norm = 1.7446e-01, time/batch = 0.6412s	
5162/26050 (epoch 9.908), train_loss = 1.28018937, grad/param norm = 1.7230e-01, time/batch = 0.6417s	
5163/26050 (epoch 9.910), train_loss = 1.20489637, grad/param norm = 1.5503e-01, time/batch = 0.6413s	
5164/26050 (epoch 9.912), train_loss = 1.57723278, grad/param norm = 1.9688e-01, time/batch = 0.6436s	
5165/26050 (epoch 9.914), train_loss = 1.74291556, grad/param norm = 1.9752e-01, time/batch = 0.6416s	
5166/26050 (epoch 9.916), train_loss = 1.46062538, grad/param norm = 1.9676e-01, time/batch = 0.6410s	
5167/26050 (epoch 9.917), train_loss = 1.37650910, grad/param norm = 2.1315e-01, time/batch = 0.6449s	
5168/26050 (epoch 9.919), train_loss = 1.43581500, grad/param norm = 1.8612e-01, time/batch = 0.6401s	
5169/26050 (epoch 9.921), train_loss = 1.25007963, grad/param norm = 2.0509e-01, time/batch = 0.6417s	
5170/26050 (epoch 9.923), train_loss = 1.31986694, grad/param norm = 1.9257e-01, time/batch = 0.6537s	
5171/26050 (epoch 9.925), train_loss = 1.28324134, grad/param norm = 1.7000e-01, time/batch = 0.6462s	
5172/26050 (epoch 9.927), train_loss = 1.17977657, grad/param norm = 1.5225e-01, time/batch = 0.6416s	
5173/26050 (epoch 9.929), train_loss = 1.23398181, grad/param norm = 1.7646e-01, time/batch = 0.6549s	
5174/26050 (epoch 9.931), train_loss = 1.57276846, grad/param norm = 2.1397e-01, time/batch = 0.6391s	
5175/26050 (epoch 9.933), train_loss = 1.26293754, grad/param norm = 1.8182e-01, time/batch = 0.6387s	
5176/26050 (epoch 9.935), train_loss = 1.22829745, grad/param norm = 1.6382e-01, time/batch = 0.6389s	
5177/26050 (epoch 9.937), train_loss = 1.34503900, grad/param norm = 1.6797e-01, time/batch = 0.6479s	
5178/26050 (epoch 9.939), train_loss = 1.19423326, grad/param norm = 1.6279e-01, time/batch = 0.6383s	
5179/26050 (epoch 9.940), train_loss = 1.32227665, grad/param norm = 1.6591e-01, time/batch = 0.6436s	
5180/26050 (epoch 9.942), train_loss = 1.34495566, grad/param norm = 1.9536e-01, time/batch = 0.6394s	
5181/26050 (epoch 9.944), train_loss = 1.27186034, grad/param norm = 1.7361e-01, time/batch = 0.6407s	
5182/26050 (epoch 9.946), train_loss = 1.46372477, grad/param norm = 1.7824e-01, time/batch = 0.6395s	
5183/26050 (epoch 9.948), train_loss = 1.13724775, grad/param norm = 1.9133e-01, time/batch = 0.6395s	
5184/26050 (epoch 9.950), train_loss = 1.28427549, grad/param norm = 1.6942e-01, time/batch = 0.6384s	
5185/26050 (epoch 9.952), train_loss = 1.45894886, grad/param norm = 1.9225e-01, time/batch = 0.6378s	
5186/26050 (epoch 9.954), train_loss = 1.40623053, grad/param norm = 1.7650e-01, time/batch = 0.6409s	
5187/26050 (epoch 9.956), train_loss = 1.36137280, grad/param norm = 1.8178e-01, time/batch = 0.6486s	
5188/26050 (epoch 9.958), train_loss = 1.28271883, grad/param norm = 1.7374e-01, time/batch = 0.6419s	
5189/26050 (epoch 9.960), train_loss = 1.29977916, grad/param norm = 1.7353e-01, time/batch = 0.6426s	
5190/26050 (epoch 9.962), train_loss = 1.22184329, grad/param norm = 1.7103e-01, time/batch = 0.6393s	
5191/26050 (epoch 9.964), train_loss = 1.29636124, grad/param norm = 1.7229e-01, time/batch = 0.6515s	
5192/26050 (epoch 9.965), train_loss = 1.18897230, grad/param norm = 1.7125e-01, time/batch = 0.6606s	
5193/26050 (epoch 9.967), train_loss = 1.64522706, grad/param norm = 1.8444e-01, time/batch = 0.6498s	
5194/26050 (epoch 9.969), train_loss = 1.27251392, grad/param norm = 1.6246e-01, time/batch = 0.6541s	
5195/26050 (epoch 9.971), train_loss = 1.19729144, grad/param norm = 1.6121e-01, time/batch = 0.6425s	
5196/26050 (epoch 9.973), train_loss = 1.27878231, grad/param norm = 1.8717e-01, time/batch = 0.6409s	
5197/26050 (epoch 9.975), train_loss = 1.37099755, grad/param norm = 1.6525e-01, time/batch = 0.6400s	
5198/26050 (epoch 9.977), train_loss = 1.32613387, grad/param norm = 1.5720e-01, time/batch = 0.6399s	
5199/26050 (epoch 9.979), train_loss = 1.14011345, grad/param norm = 1.6762e-01, time/batch = 0.6409s	
5200/26050 (epoch 9.981), train_loss = 1.42014307, grad/param norm = 1.7359e-01, time/batch = 0.6435s	
5201/26050 (epoch 9.983), train_loss = 1.42479040, grad/param norm = 1.8248e-01, time/batch = 0.6424s	
5202/26050 (epoch 9.985), train_loss = 1.34486550, grad/param norm = 1.8590e-01, time/batch = 0.6500s	
5203/26050 (epoch 9.987), train_loss = 1.48016330, grad/param norm = 1.9589e-01, time/batch = 0.6665s	
5204/26050 (epoch 9.988), train_loss = 1.42530025, grad/param norm = 1.8439e-01, time/batch = 0.6484s	
5205/26050 (epoch 9.990), train_loss = 1.22662780, grad/param norm = 1.6377e-01, time/batch = 0.6475s	
5206/26050 (epoch 9.992), train_loss = 1.46476510, grad/param norm = 1.8742e-01, time/batch = 0.6510s	
5207/26050 (epoch 9.994), train_loss = 1.32817488, grad/param norm = 1.7766e-01, time/batch = 0.6830s	
5208/26050 (epoch 9.996), train_loss = 1.28360167, grad/param norm = 1.9971e-01, time/batch = 0.6634s	
5209/26050 (epoch 9.998), train_loss = 1.33009710, grad/param norm = 1.8202e-01, time/batch = 0.6422s	
decayed learning rate by a factor 0.97 to 0.00194	
5210/26050 (epoch 10.000), train_loss = 1.27821630, grad/param norm = 1.7778e-01, time/batch = 0.6489s	
5211/26050 (epoch 10.002), train_loss = 1.36309541, grad/param norm = 1.8583e-01, time/batch = 0.6496s	
5212/26050 (epoch 10.004), train_loss = 1.21566972, grad/param norm = 1.7837e-01, time/batch = 0.6450s	
5213/26050 (epoch 10.006), train_loss = 1.23830254, grad/param norm = 1.6964e-01, time/batch = 0.6415s	
5214/26050 (epoch 10.008), train_loss = 1.21178714, grad/param norm = 1.8321e-01, time/batch = 0.6400s	
5215/26050 (epoch 10.010), train_loss = 1.25341520, grad/param norm = 1.6356e-01, time/batch = 0.6383s	
5216/26050 (epoch 10.012), train_loss = 1.33418054, grad/param norm = 1.7941e-01, time/batch = 0.6390s	
5217/26050 (epoch 10.013), train_loss = 1.73406266, grad/param norm = 2.0769e-01, time/batch = 0.6416s	
5218/26050 (epoch 10.015), train_loss = 1.20373717, grad/param norm = 1.6280e-01, time/batch = 0.6407s	
5219/26050 (epoch 10.017), train_loss = 1.34859634, grad/param norm = 1.7715e-01, time/batch = 0.6430s	
5220/26050 (epoch 10.019), train_loss = 1.11241358, grad/param norm = 1.4737e-01, time/batch = 0.6482s	
5221/26050 (epoch 10.021), train_loss = 1.41887988, grad/param norm = 1.8491e-01, time/batch = 0.6782s	
5222/26050 (epoch 10.023), train_loss = 1.13723467, grad/param norm = 1.6558e-01, time/batch = 0.6676s	
5223/26050 (epoch 10.025), train_loss = 1.26975623, grad/param norm = 1.7563e-01, time/batch = 0.6550s	
5224/26050 (epoch 10.027), train_loss = 1.06477311, grad/param norm = 1.5734e-01, time/batch = 0.6517s	
5225/26050 (epoch 10.029), train_loss = 1.26460894, grad/param norm = 1.5975e-01, time/batch = 0.6487s	
5226/26050 (epoch 10.031), train_loss = 1.47859717, grad/param norm = 1.9892e-01, time/batch = 0.6491s	
5227/26050 (epoch 10.033), train_loss = 1.35625324, grad/param norm = 1.7885e-01, time/batch = 0.6416s	
5228/26050 (epoch 10.035), train_loss = 1.41761951, grad/param norm = 1.7011e-01, time/batch = 0.6413s	
5229/26050 (epoch 10.036), train_loss = 1.22586635, grad/param norm = 1.8842e-01, time/batch = 0.6410s	
5230/26050 (epoch 10.038), train_loss = 1.12282171, grad/param norm = 1.6732e-01, time/batch = 0.6418s	
5231/26050 (epoch 10.040), train_loss = 1.36426943, grad/param norm = 1.8246e-01, time/batch = 0.6417s	
5232/26050 (epoch 10.042), train_loss = 1.17366439, grad/param norm = 1.7862e-01, time/batch = 0.6503s	
5233/26050 (epoch 10.044), train_loss = 1.38119595, grad/param norm = 1.8510e-01, time/batch = 0.6428s	
5234/26050 (epoch 10.046), train_loss = 1.10162313, grad/param norm = 1.7626e-01, time/batch = 0.6500s	
5235/26050 (epoch 10.048), train_loss = 1.34055092, grad/param norm = 1.8372e-01, time/batch = 0.6404s	
5236/26050 (epoch 10.050), train_loss = 1.19659264, grad/param norm = 1.8730e-01, time/batch = 0.6397s	
5237/26050 (epoch 10.052), train_loss = 1.28063673, grad/param norm = 1.7498e-01, time/batch = 0.6611s	
5238/26050 (epoch 10.054), train_loss = 1.12773795, grad/param norm = 1.5953e-01, time/batch = 0.6833s	
5239/26050 (epoch 10.056), train_loss = 1.02200396, grad/param norm = 1.4105e-01, time/batch = 0.6426s	
5240/26050 (epoch 10.058), train_loss = 1.21743741, grad/param norm = 1.6471e-01, time/batch = 0.6445s	
5241/26050 (epoch 10.060), train_loss = 1.29435520, grad/param norm = 1.6203e-01, time/batch = 0.6439s	
5242/26050 (epoch 10.061), train_loss = 1.18176346, grad/param norm = 1.6602e-01, time/batch = 0.6504s	
5243/26050 (epoch 10.063), train_loss = 1.28364649, grad/param norm = 1.6588e-01, time/batch = 0.6430s	
5244/26050 (epoch 10.065), train_loss = 1.10975363, grad/param norm = 1.6501e-01, time/batch = 0.6427s	
5245/26050 (epoch 10.067), train_loss = 1.36655972, grad/param norm = 1.9441e-01, time/batch = 0.6409s	
5246/26050 (epoch 10.069), train_loss = 1.35120802, grad/param norm = 1.6913e-01, time/batch = 0.6422s	
5247/26050 (epoch 10.071), train_loss = 1.36723859, grad/param norm = 1.8480e-01, time/batch = 0.6427s	
5248/26050 (epoch 10.073), train_loss = 1.51052508, grad/param norm = 1.7330e-01, time/batch = 0.6414s	
5249/26050 (epoch 10.075), train_loss = 1.18944944, grad/param norm = 1.5973e-01, time/batch = 0.6464s	
5250/26050 (epoch 10.077), train_loss = 1.18786020, grad/param norm = 1.6560e-01, time/batch = 0.6465s	
5251/26050 (epoch 10.079), train_loss = 1.35964130, grad/param norm = 1.8945e-01, time/batch = 0.6406s	
5252/26050 (epoch 10.081), train_loss = 1.24759222, grad/param norm = 1.7175e-01, time/batch = 0.6409s	
5253/26050 (epoch 10.083), train_loss = 1.38269648, grad/param norm = 1.7730e-01, time/batch = 0.6405s	
5254/26050 (epoch 10.084), train_loss = 1.41115629, grad/param norm = 1.9698e-01, time/batch = 0.6447s	
5255/26050 (epoch 10.086), train_loss = 1.43485538, grad/param norm = 1.8442e-01, time/batch = 0.6401s	
5256/26050 (epoch 10.088), train_loss = 1.17352186, grad/param norm = 1.5882e-01, time/batch = 0.6509s	
5257/26050 (epoch 10.090), train_loss = 1.37660646, grad/param norm = 1.8629e-01, time/batch = 0.6673s	
5258/26050 (epoch 10.092), train_loss = 1.31516896, grad/param norm = 1.7711e-01, time/batch = 0.6836s	
5259/26050 (epoch 10.094), train_loss = 1.28076826, grad/param norm = 1.7521e-01, time/batch = 0.6433s	
5260/26050 (epoch 10.096), train_loss = 1.24804041, grad/param norm = 1.6710e-01, time/batch = 0.6407s	
5261/26050 (epoch 10.098), train_loss = 1.24708190, grad/param norm = 1.7334e-01, time/batch = 0.6481s	
5262/26050 (epoch 10.100), train_loss = 1.18561169, grad/param norm = 1.8095e-01, time/batch = 0.6414s	
5263/26050 (epoch 10.102), train_loss = 1.32967101, grad/param norm = 1.7974e-01, time/batch = 0.6409s	
5264/26050 (epoch 10.104), train_loss = 1.32292074, grad/param norm = 1.7693e-01, time/batch = 0.6408s	
5265/26050 (epoch 10.106), train_loss = 1.26297818, grad/param norm = 1.7185e-01, time/batch = 0.6441s	
5266/26050 (epoch 10.107), train_loss = 1.05193572, grad/param norm = 1.6686e-01, time/batch = 0.6445s	
5267/26050 (epoch 10.109), train_loss = 1.21207219, grad/param norm = 1.7125e-01, time/batch = 0.6413s	
5268/26050 (epoch 10.111), train_loss = 1.50416839, grad/param norm = 2.0031e-01, time/batch = 0.6409s	
5269/26050 (epoch 10.113), train_loss = 1.21486042, grad/param norm = 1.7382e-01, time/batch = 0.6436s	
5270/26050 (epoch 10.115), train_loss = 1.39815021, grad/param norm = 1.8142e-01, time/batch = 0.6422s	
5271/26050 (epoch 10.117), train_loss = 1.35080362, grad/param norm = 1.7956e-01, time/batch = 0.6429s	
5272/26050 (epoch 10.119), train_loss = 1.07247296, grad/param norm = 1.5541e-01, time/batch = 0.6442s	
5273/26050 (epoch 10.121), train_loss = 1.35392515, grad/param norm = 1.7437e-01, time/batch = 0.6829s	
5274/26050 (epoch 10.123), train_loss = 1.20027122, grad/param norm = 1.8226e-01, time/batch = 0.6692s	
5275/26050 (epoch 10.125), train_loss = 1.09450017, grad/param norm = 1.5225e-01, time/batch = 0.6469s	
5276/26050 (epoch 10.127), train_loss = 1.05624917, grad/param norm = 1.6477e-01, time/batch = 0.6433s	
5277/26050 (epoch 10.129), train_loss = 1.07729781, grad/param norm = 1.4966e-01, time/batch = 0.6399s	
5278/26050 (epoch 10.131), train_loss = 1.26261364, grad/param norm = 1.7496e-01, time/batch = 0.6409s	
5279/26050 (epoch 10.132), train_loss = 1.23232499, grad/param norm = 1.6543e-01, time/batch = 0.6441s	
5280/26050 (epoch 10.134), train_loss = 1.24715383, grad/param norm = 1.6897e-01, time/batch = 0.6468s	
5281/26050 (epoch 10.136), train_loss = 1.26822273, grad/param norm = 1.7015e-01, time/batch = 0.6461s	
5282/26050 (epoch 10.138), train_loss = 1.08726093, grad/param norm = 1.7821e-01, time/batch = 0.6439s	
5283/26050 (epoch 10.140), train_loss = 1.14420610, grad/param norm = 1.6455e-01, time/batch = 0.6434s	
5284/26050 (epoch 10.142), train_loss = 1.19494571, grad/param norm = 1.7407e-01, time/batch = 0.6431s	
5285/26050 (epoch 10.144), train_loss = 1.09313769, grad/param norm = 1.5925e-01, time/batch = 0.6509s	
5286/26050 (epoch 10.146), train_loss = 0.99818496, grad/param norm = 1.5388e-01, time/batch = 0.6505s	
5287/26050 (epoch 10.148), train_loss = 1.02569032, grad/param norm = 1.3622e-01, time/batch = 0.6476s	
5288/26050 (epoch 10.150), train_loss = 1.25495111, grad/param norm = 1.9308e-01, time/batch = 0.6748s	
5289/26050 (epoch 10.152), train_loss = 1.52142618, grad/param norm = 1.9708e-01, time/batch = 0.6733s	
5290/26050 (epoch 10.154), train_loss = 1.07866319, grad/param norm = 1.7517e-01, time/batch = 0.6403s	
5291/26050 (epoch 10.155), train_loss = 1.09075245, grad/param norm = 1.5897e-01, time/batch = 0.6417s	
5292/26050 (epoch 10.157), train_loss = 1.24451151, grad/param norm = 1.8942e-01, time/batch = 0.6424s	
5293/26050 (epoch 10.159), train_loss = 1.25125619, grad/param norm = 1.8067e-01, time/batch = 0.6406s	
5294/26050 (epoch 10.161), train_loss = 1.42492376, grad/param norm = 1.9523e-01, time/batch = 0.6417s	
5295/26050 (epoch 10.163), train_loss = 1.11731869, grad/param norm = 1.7647e-01, time/batch = 0.6585s	
5296/26050 (epoch 10.165), train_loss = 0.97336329, grad/param norm = 1.4851e-01, time/batch = 0.6487s	
5297/26050 (epoch 10.167), train_loss = 1.38028501, grad/param norm = 1.9651e-01, time/batch = 0.6508s	
5298/26050 (epoch 10.169), train_loss = 1.34522611, grad/param norm = 1.7656e-01, time/batch = 0.6427s	
5299/26050 (epoch 10.171), train_loss = 1.04821808, grad/param norm = 1.4451e-01, time/batch = 0.6831s	
5300/26050 (epoch 10.173), train_loss = 1.20697065, grad/param norm = 1.7540e-01, time/batch = 0.6681s	
5301/26050 (epoch 10.175), train_loss = 1.28401538, grad/param norm = 1.7957e-01, time/batch = 0.6565s	
5302/26050 (epoch 10.177), train_loss = 1.35630532, grad/param norm = 1.7073e-01, time/batch = 0.6419s	
5303/26050 (epoch 10.179), train_loss = 0.99835700, grad/param norm = 1.5666e-01, time/batch = 0.6543s	
5304/26050 (epoch 10.180), train_loss = 1.53898949, grad/param norm = 1.7985e-01, time/batch = 0.6817s	
5305/26050 (epoch 10.182), train_loss = 1.54364074, grad/param norm = 1.9027e-01, time/batch = 0.6406s	
5306/26050 (epoch 10.184), train_loss = 1.28616267, grad/param norm = 1.6751e-01, time/batch = 0.6382s	
5307/26050 (epoch 10.186), train_loss = 1.05424200, grad/param norm = 1.5434e-01, time/batch = 0.6415s	
5308/26050 (epoch 10.188), train_loss = 1.26716374, grad/param norm = 1.6267e-01, time/batch = 0.6371s	
5309/26050 (epoch 10.190), train_loss = 1.31956250, grad/param norm = 1.7650e-01, time/batch = 0.6396s	
5310/26050 (epoch 10.192), train_loss = 1.31248540, grad/param norm = 1.7188e-01, time/batch = 0.6440s	
5311/26050 (epoch 10.194), train_loss = 1.30637874, grad/param norm = 1.7297e-01, time/batch = 0.6454s	
5312/26050 (epoch 10.196), train_loss = 1.37185234, grad/param norm = 1.9129e-01, time/batch = 0.6577s	
5313/26050 (epoch 10.198), train_loss = 1.20146945, grad/param norm = 1.6829e-01, time/batch = 0.6393s	
5314/26050 (epoch 10.200), train_loss = 1.18702868, grad/param norm = 1.7368e-01, time/batch = 0.6703s	
5315/26050 (epoch 10.202), train_loss = 1.20540881, grad/param norm = 1.7379e-01, time/batch = 0.6724s	
5316/26050 (epoch 10.203), train_loss = 1.35661905, grad/param norm = 1.8341e-01, time/batch = 0.6414s	
5317/26050 (epoch 10.205), train_loss = 1.16996086, grad/param norm = 1.6389e-01, time/batch = 0.6386s	
5318/26050 (epoch 10.207), train_loss = 1.25128247, grad/param norm = 1.6783e-01, time/batch = 0.6408s	
5319/26050 (epoch 10.209), train_loss = 1.26382577, grad/param norm = 1.6979e-01, time/batch = 0.6425s	
5320/26050 (epoch 10.211), train_loss = 1.10798419, grad/param norm = 1.7021e-01, time/batch = 0.6406s	
5321/26050 (epoch 10.213), train_loss = 1.31391260, grad/param norm = 1.7275e-01, time/batch = 0.6411s	
5322/26050 (epoch 10.215), train_loss = 1.30270474, grad/param norm = 1.9669e-01, time/batch = 0.6398s	
5323/26050 (epoch 10.217), train_loss = 1.23359624, grad/param norm = 1.6959e-01, time/batch = 0.6462s	
5324/26050 (epoch 10.219), train_loss = 1.19991711, grad/param norm = 1.8300e-01, time/batch = 0.6507s	
5325/26050 (epoch 10.221), train_loss = 1.13621427, grad/param norm = 1.6102e-01, time/batch = 0.6419s	
5326/26050 (epoch 10.223), train_loss = 1.30307260, grad/param norm = 1.7439e-01, time/batch = 0.6458s	
5327/26050 (epoch 10.225), train_loss = 1.16560141, grad/param norm = 1.8301e-01, time/batch = 0.6404s	
5328/26050 (epoch 10.226), train_loss = 1.39515338, grad/param norm = 1.8024e-01, time/batch = 0.6387s	
5329/26050 (epoch 10.228), train_loss = 1.40747720, grad/param norm = 1.8049e-01, time/batch = 0.6387s	
5330/26050 (epoch 10.230), train_loss = 1.31744319, grad/param norm = 1.7783e-01, time/batch = 0.6385s	
5331/26050 (epoch 10.232), train_loss = 1.39200071, grad/param norm = 1.8526e-01, time/batch = 0.6409s	
5332/26050 (epoch 10.234), train_loss = 1.10589089, grad/param norm = 1.6968e-01, time/batch = 0.6426s	
5333/26050 (epoch 10.236), train_loss = 1.35198382, grad/param norm = 1.9053e-01, time/batch = 0.6409s	
5334/26050 (epoch 10.238), train_loss = 1.08801643, grad/param norm = 1.6744e-01, time/batch = 0.6407s	
5335/26050 (epoch 10.240), train_loss = 1.22087723, grad/param norm = 1.6763e-01, time/batch = 0.6526s	
5336/26050 (epoch 10.242), train_loss = 1.24696324, grad/param norm = 1.5958e-01, time/batch = 0.6479s	
5337/26050 (epoch 10.244), train_loss = 1.32278818, grad/param norm = 1.9446e-01, time/batch = 0.6435s	
5338/26050 (epoch 10.246), train_loss = 1.19198657, grad/param norm = 1.6489e-01, time/batch = 0.6382s	
5339/26050 (epoch 10.248), train_loss = 1.29676466, grad/param norm = 1.7202e-01, time/batch = 0.6384s	
5340/26050 (epoch 10.250), train_loss = 1.28951160, grad/param norm = 1.9104e-01, time/batch = 0.6409s	
5341/26050 (epoch 10.251), train_loss = 1.17426179, grad/param norm = 1.6709e-01, time/batch = 0.6412s	
5342/26050 (epoch 10.253), train_loss = 1.08798183, grad/param norm = 1.6634e-01, time/batch = 0.6457s	
5343/26050 (epoch 10.255), train_loss = 1.49833209, grad/param norm = 1.8068e-01, time/batch = 0.6406s	
5344/26050 (epoch 10.257), train_loss = 1.27050428, grad/param norm = 1.9289e-01, time/batch = 0.6407s	
5345/26050 (epoch 10.259), train_loss = 1.41521836, grad/param norm = 1.7388e-01, time/batch = 0.6386s	
5346/26050 (epoch 10.261), train_loss = 1.19360500, grad/param norm = 1.8942e-01, time/batch = 0.6410s	
5347/26050 (epoch 10.263), train_loss = 1.27791636, grad/param norm = 1.7663e-01, time/batch = 0.6548s	
5348/26050 (epoch 10.265), train_loss = 1.45399375, grad/param norm = 1.7825e-01, time/batch = 0.6487s	
5349/26050 (epoch 10.267), train_loss = 1.35569890, grad/param norm = 1.8233e-01, time/batch = 0.6482s	
5350/26050 (epoch 10.269), train_loss = 1.46874335, grad/param norm = 1.9695e-01, time/batch = 0.6826s	
5351/26050 (epoch 10.271), train_loss = 1.32529764, grad/param norm = 1.7633e-01, time/batch = 0.6534s	
5352/26050 (epoch 10.273), train_loss = 1.22267740, grad/param norm = 1.8212e-01, time/batch = 0.6412s	
5353/26050 (epoch 10.274), train_loss = 1.22360492, grad/param norm = 1.7141e-01, time/batch = 0.6416s	
5354/26050 (epoch 10.276), train_loss = 1.19324450, grad/param norm = 1.7813e-01, time/batch = 0.6402s	
5355/26050 (epoch 10.278), train_loss = 1.38538757, grad/param norm = 1.7746e-01, time/batch = 0.6398s	
5356/26050 (epoch 10.280), train_loss = 1.25402049, grad/param norm = 1.6988e-01, time/batch = 0.6432s	
5357/26050 (epoch 10.282), train_loss = 1.32674321, grad/param norm = 1.8954e-01, time/batch = 0.6427s	
5358/26050 (epoch 10.284), train_loss = 1.16379138, grad/param norm = 1.6744e-01, time/batch = 0.6412s	
5359/26050 (epoch 10.286), train_loss = 1.25885923, grad/param norm = 1.7964e-01, time/batch = 0.6396s	
5360/26050 (epoch 10.288), train_loss = 1.08576235, grad/param norm = 1.4781e-01, time/batch = 0.6398s	
5361/26050 (epoch 10.290), train_loss = 1.23871869, grad/param norm = 1.7480e-01, time/batch = 0.6432s	
5362/26050 (epoch 10.292), train_loss = 1.19389707, grad/param norm = 1.7391e-01, time/batch = 0.6411s	
5363/26050 (epoch 10.294), train_loss = 1.29232385, grad/param norm = 1.9615e-01, time/batch = 0.6412s	
5364/26050 (epoch 10.296), train_loss = 1.39718459, grad/param norm = 1.8247e-01, time/batch = 0.6420s	
5365/26050 (epoch 10.298), train_loss = 1.25946794, grad/param norm = 1.6751e-01, time/batch = 0.6715s	
5366/26050 (epoch 10.299), train_loss = 1.01533120, grad/param norm = 1.4438e-01, time/batch = 0.6730s	
5367/26050 (epoch 10.301), train_loss = 1.19690848, grad/param norm = 1.7807e-01, time/batch = 0.6406s	
5368/26050 (epoch 10.303), train_loss = 1.30790838, grad/param norm = 1.7207e-01, time/batch = 0.6402s	
5369/26050 (epoch 10.305), train_loss = 1.09744927, grad/param norm = 1.6302e-01, time/batch = 0.6400s	
5370/26050 (epoch 10.307), train_loss = 1.15464100, grad/param norm = 1.6795e-01, time/batch = 0.6394s	
5371/26050 (epoch 10.309), train_loss = 1.24117262, grad/param norm = 1.8083e-01, time/batch = 0.6573s	
5372/26050 (epoch 10.311), train_loss = 1.43576548, grad/param norm = 2.0019e-01, time/batch = 0.6550s	
5373/26050 (epoch 10.313), train_loss = 1.27132169, grad/param norm = 1.8818e-01, time/batch = 0.6415s	
5374/26050 (epoch 10.315), train_loss = 1.40740036, grad/param norm = 1.8590e-01, time/batch = 0.6390s	
5375/26050 (epoch 10.317), train_loss = 1.21200273, grad/param norm = 1.6772e-01, time/batch = 0.6390s	
5376/26050 (epoch 10.319), train_loss = 1.21572224, grad/param norm = 1.6070e-01, time/batch = 0.6392s	
5377/26050 (epoch 10.321), train_loss = 1.22875833, grad/param norm = 1.7984e-01, time/batch = 0.6393s	
5378/26050 (epoch 10.322), train_loss = 1.29761613, grad/param norm = 1.7321e-01, time/batch = 0.6390s	
5379/26050 (epoch 10.324), train_loss = 1.07960064, grad/param norm = 1.7181e-01, time/batch = 0.6399s	
5380/26050 (epoch 10.326), train_loss = 1.42240705, grad/param norm = 1.8672e-01, time/batch = 0.6527s	
5381/26050 (epoch 10.328), train_loss = 1.31833630, grad/param norm = 1.7376e-01, time/batch = 0.6843s	
5382/26050 (epoch 10.330), train_loss = 1.16063316, grad/param norm = 1.7493e-01, time/batch = 0.6450s	
5383/26050 (epoch 10.332), train_loss = 1.36270082, grad/param norm = 1.8085e-01, time/batch = 0.6413s	
5384/26050 (epoch 10.334), train_loss = 1.23723234, grad/param norm = 1.7355e-01, time/batch = 0.6476s	
5385/26050 (epoch 10.336), train_loss = 1.16297802, grad/param norm = 1.5841e-01, time/batch = 0.6400s	
5386/26050 (epoch 10.338), train_loss = 1.13241206, grad/param norm = 1.5924e-01, time/batch = 0.6405s	
5387/26050 (epoch 10.340), train_loss = 1.36615538, grad/param norm = 1.8867e-01, time/batch = 0.6545s	
5388/26050 (epoch 10.342), train_loss = 1.40966358, grad/param norm = 1.7829e-01, time/batch = 0.6517s	
5389/26050 (epoch 10.344), train_loss = 1.26221390, grad/param norm = 1.8385e-01, time/batch = 0.6435s	
5390/26050 (epoch 10.345), train_loss = 1.25927931, grad/param norm = 1.7974e-01, time/batch = 0.6484s	
5391/26050 (epoch 10.347), train_loss = 1.34897239, grad/param norm = 1.8530e-01, time/batch = 0.6452s	
5392/26050 (epoch 10.349), train_loss = 1.29966411, grad/param norm = 1.8361e-01, time/batch = 0.6409s	
5393/26050 (epoch 10.351), train_loss = 1.30264275, grad/param norm = 1.9166e-01, time/batch = 0.6430s	
5394/26050 (epoch 10.353), train_loss = 1.21494799, grad/param norm = 1.7827e-01, time/batch = 0.6451s	
5395/26050 (epoch 10.355), train_loss = 1.35559808, grad/param norm = 1.8998e-01, time/batch = 0.6411s	
5396/26050 (epoch 10.357), train_loss = 1.12909728, grad/param norm = 1.6436e-01, time/batch = 0.6813s	
5397/26050 (epoch 10.359), train_loss = 1.35642547, grad/param norm = 1.7854e-01, time/batch = 0.6607s	
5398/26050 (epoch 10.361), train_loss = 1.19728668, grad/param norm = 1.7349e-01, time/batch = 0.6389s	
5399/26050 (epoch 10.363), train_loss = 1.31569895, grad/param norm = 1.7082e-01, time/batch = 0.6381s	
5400/26050 (epoch 10.365), train_loss = 1.20742163, grad/param norm = 1.5542e-01, time/batch = 0.6386s	
5401/26050 (epoch 10.367), train_loss = 1.26186331, grad/param norm = 1.7008e-01, time/batch = 0.6416s	
5402/26050 (epoch 10.369), train_loss = 1.23041415, grad/param norm = 1.5838e-01, time/batch = 0.6418s	
5403/26050 (epoch 10.370), train_loss = 1.15238243, grad/param norm = 1.5721e-01, time/batch = 0.6425s	
5404/26050 (epoch 10.372), train_loss = 1.36086797, grad/param norm = 1.8907e-01, time/batch = 0.6387s	
5405/26050 (epoch 10.374), train_loss = 1.46693402, grad/param norm = 1.8508e-01, time/batch = 0.6384s	
5406/26050 (epoch 10.376), train_loss = 1.50133258, grad/param norm = 1.8812e-01, time/batch = 0.6380s	
5407/26050 (epoch 10.378), train_loss = 1.24727885, grad/param norm = 1.7681e-01, time/batch = 0.6405s	
5408/26050 (epoch 10.380), train_loss = 1.48203052, grad/param norm = 1.9697e-01, time/batch = 0.6387s	
5409/26050 (epoch 10.382), train_loss = 1.61254468, grad/param norm = 2.1293e-01, time/batch = 0.6509s	
5410/26050 (epoch 10.384), train_loss = 1.23636352, grad/param norm = 1.6651e-01, time/batch = 0.6469s	
5411/26050 (epoch 10.386), train_loss = 1.38885292, grad/param norm = 1.9390e-01, time/batch = 0.6448s	
5412/26050 (epoch 10.388), train_loss = 1.31232238, grad/param norm = 1.7903e-01, time/batch = 0.6408s	
5413/26050 (epoch 10.390), train_loss = 1.13720780, grad/param norm = 1.5037e-01, time/batch = 0.6513s	
5414/26050 (epoch 10.392), train_loss = 1.15980678, grad/param norm = 1.6052e-01, time/batch = 0.6605s	
5415/26050 (epoch 10.393), train_loss = 1.33458905, grad/param norm = 1.6860e-01, time/batch = 0.6524s	
5416/26050 (epoch 10.395), train_loss = 1.34390753, grad/param norm = 1.7673e-01, time/batch = 0.6383s	
5417/26050 (epoch 10.397), train_loss = 1.33974635, grad/param norm = 1.9872e-01, time/batch = 0.6489s	
5418/26050 (epoch 10.399), train_loss = 1.13690235, grad/param norm = 1.4905e-01, time/batch = 0.6378s	
5419/26050 (epoch 10.401), train_loss = 1.22162374, grad/param norm = 1.5634e-01, time/batch = 0.6425s	
5420/26050 (epoch 10.403), train_loss = 1.27654493, grad/param norm = 1.6133e-01, time/batch = 0.6420s	
5421/26050 (epoch 10.405), train_loss = 1.27186165, grad/param norm = 1.7828e-01, time/batch = 0.6388s	
5422/26050 (epoch 10.407), train_loss = 1.42189851, grad/param norm = 1.8258e-01, time/batch = 0.6449s	
5423/26050 (epoch 10.409), train_loss = 1.46263464, grad/param norm = 1.9546e-01, time/batch = 0.6446s	
5424/26050 (epoch 10.411), train_loss = 1.32222615, grad/param norm = 1.7940e-01, time/batch = 0.6413s	
5425/26050 (epoch 10.413), train_loss = 1.41258560, grad/param norm = 1.6795e-01, time/batch = 0.6399s	
5426/26050 (epoch 10.415), train_loss = 1.40405674, grad/param norm = 1.9024e-01, time/batch = 0.6400s	
5427/26050 (epoch 10.417), train_loss = 1.52228187, grad/param norm = 1.9256e-01, time/batch = 0.6387s	
5428/26050 (epoch 10.418), train_loss = 1.38600630, grad/param norm = 1.9353e-01, time/batch = 0.6380s	
5429/26050 (epoch 10.420), train_loss = 1.09155393, grad/param norm = 1.5285e-01, time/batch = 0.6384s	
5430/26050 (epoch 10.422), train_loss = 1.14079330, grad/param norm = 1.6849e-01, time/batch = 0.6383s	
5431/26050 (epoch 10.424), train_loss = 1.48219995, grad/param norm = 2.1108e-01, time/batch = 0.6578s	
5432/26050 (epoch 10.426), train_loss = 1.44199931, grad/param norm = 1.8958e-01, time/batch = 0.6821s	
5433/26050 (epoch 10.428), train_loss = 1.18485685, grad/param norm = 1.5682e-01, time/batch = 0.6412s	
5434/26050 (epoch 10.430), train_loss = 1.33056535, grad/param norm = 1.7998e-01, time/batch = 0.6428s	
5435/26050 (epoch 10.432), train_loss = 1.22156479, grad/param norm = 1.7375e-01, time/batch = 0.6461s	
5436/26050 (epoch 10.434), train_loss = 1.29141755, grad/param norm = 1.8418e-01, time/batch = 0.6390s	
5437/26050 (epoch 10.436), train_loss = 1.39977855, grad/param norm = 1.6318e-01, time/batch = 0.6452s	
5438/26050 (epoch 10.438), train_loss = 1.17168237, grad/param norm = 1.6728e-01, time/batch = 0.6399s	
5439/26050 (epoch 10.440), train_loss = 1.31530966, grad/param norm = 1.6860e-01, time/batch = 0.6397s	
5440/26050 (epoch 10.441), train_loss = 1.28327871, grad/param norm = 1.6006e-01, time/batch = 0.6404s	
5441/26050 (epoch 10.443), train_loss = 1.07976204, grad/param norm = 1.5044e-01, time/batch = 0.6620s	
5442/26050 (epoch 10.445), train_loss = 1.14904788, grad/param norm = 1.7070e-01, time/batch = 0.6536s	
5443/26050 (epoch 10.447), train_loss = 1.48836712, grad/param norm = 1.9354e-01, time/batch = 0.6416s	
5444/26050 (epoch 10.449), train_loss = 1.17988191, grad/param norm = 1.6906e-01, time/batch = 0.6420s	
5445/26050 (epoch 10.451), train_loss = 1.39075241, grad/param norm = 1.6799e-01, time/batch = 0.6403s	
5446/26050 (epoch 10.453), train_loss = 1.17528410, grad/param norm = 1.6404e-01, time/batch = 0.6405s	
5447/26050 (epoch 10.455), train_loss = 1.30928572, grad/param norm = 1.7430e-01, time/batch = 0.6411s	
5448/26050 (epoch 10.457), train_loss = 1.29112896, grad/param norm = 1.7065e-01, time/batch = 0.6397s	
5449/26050 (epoch 10.459), train_loss = 1.41113867, grad/param norm = 1.8334e-01, time/batch = 0.6498s	
5450/26050 (epoch 10.461), train_loss = 1.34858408, grad/param norm = 1.8470e-01, time/batch = 0.6390s	
5451/26050 (epoch 10.463), train_loss = 1.20620928, grad/param norm = 1.5618e-01, time/batch = 0.6431s	
5452/26050 (epoch 10.464), train_loss = 1.36763953, grad/param norm = 1.8563e-01, time/batch = 0.6609s	
5453/26050 (epoch 10.466), train_loss = 1.36599074, grad/param norm = 1.8504e-01, time/batch = 0.6588s	
5454/26050 (epoch 10.468), train_loss = 1.37328280, grad/param norm = 1.6373e-01, time/batch = 0.6596s	
5455/26050 (epoch 10.470), train_loss = 1.50238766, grad/param norm = 2.0114e-01, time/batch = 0.6580s	
5456/26050 (epoch 10.472), train_loss = 1.45741055, grad/param norm = 1.8771e-01, time/batch = 0.6564s	
5457/26050 (epoch 10.474), train_loss = 1.53156678, grad/param norm = 1.8262e-01, time/batch = 0.6513s	
5458/26050 (epoch 10.476), train_loss = 1.37788244, grad/param norm = 1.6590e-01, time/batch = 0.6510s	
5459/26050 (epoch 10.478), train_loss = 1.19231605, grad/param norm = 1.5316e-01, time/batch = 0.6553s	
5460/26050 (epoch 10.480), train_loss = 1.31007091, grad/param norm = 1.5980e-01, time/batch = 0.6574s	
5461/26050 (epoch 10.482), train_loss = 1.25364928, grad/param norm = 1.6834e-01, time/batch = 0.6575s	
5462/26050 (epoch 10.484), train_loss = 1.18949070, grad/param norm = 1.6799e-01, time/batch = 0.6590s	
5463/26050 (epoch 10.486), train_loss = 1.46539013, grad/param norm = 1.7387e-01, time/batch = 0.6551s	
5464/26050 (epoch 10.488), train_loss = 1.62224286, grad/param norm = 1.8870e-01, time/batch = 0.6409s	
5465/26050 (epoch 10.489), train_loss = 1.55739484, grad/param norm = 1.9988e-01, time/batch = 0.6456s	
5466/26050 (epoch 10.491), train_loss = 1.19254902, grad/param norm = 1.7231e-01, time/batch = 0.6403s	
5467/26050 (epoch 10.493), train_loss = 1.27092442, grad/param norm = 1.6952e-01, time/batch = 0.6385s	
5468/26050 (epoch 10.495), train_loss = 1.25216348, grad/param norm = 1.6672e-01, time/batch = 0.6386s	
5469/26050 (epoch 10.497), train_loss = 1.23581239, grad/param norm = 1.7014e-01, time/batch = 0.6383s	
5470/26050 (epoch 10.499), train_loss = 1.25227264, grad/param norm = 1.7861e-01, time/batch = 0.6373s	
5471/26050 (epoch 10.501), train_loss = 1.35597071, grad/param norm = 1.7782e-01, time/batch = 0.6402s	
5472/26050 (epoch 10.503), train_loss = 1.22233944, grad/param norm = 1.8628e-01, time/batch = 0.6408s	
5473/26050 (epoch 10.505), train_loss = 1.41972122, grad/param norm = 1.7786e-01, time/batch = 0.6806s	
5474/26050 (epoch 10.507), train_loss = 1.42364682, grad/param norm = 1.9474e-01, time/batch = 0.6617s	
5475/26050 (epoch 10.509), train_loss = 1.52393780, grad/param norm = 1.9164e-01, time/batch = 0.6374s	
5476/26050 (epoch 10.511), train_loss = 1.19560731, grad/param norm = 1.6825e-01, time/batch = 0.6380s	
5477/26050 (epoch 10.512), train_loss = 1.27058555, grad/param norm = 1.8211e-01, time/batch = 0.6395s	
5478/26050 (epoch 10.514), train_loss = 1.36286588, grad/param norm = 1.7931e-01, time/batch = 0.6379s	
5479/26050 (epoch 10.516), train_loss = 1.40169368, grad/param norm = 1.8124e-01, time/batch = 0.6432s	
5480/26050 (epoch 10.518), train_loss = 1.35779694, grad/param norm = 1.8480e-01, time/batch = 0.6559s	
5481/26050 (epoch 10.520), train_loss = 1.29732352, grad/param norm = 1.6726e-01, time/batch = 0.6527s	
5482/26050 (epoch 10.522), train_loss = 1.11334350, grad/param norm = 1.6640e-01, time/batch = 0.6743s	
5483/26050 (epoch 10.524), train_loss = 1.44724036, grad/param norm = 1.8656e-01, time/batch = 0.6628s	
5484/26050 (epoch 10.526), train_loss = 1.38665572, grad/param norm = 1.7817e-01, time/batch = 0.6444s	
5485/26050 (epoch 10.528), train_loss = 1.35118704, grad/param norm = 1.7430e-01, time/batch = 0.6407s	
5486/26050 (epoch 10.530), train_loss = 1.27336148, grad/param norm = 1.5874e-01, time/batch = 0.6451s	
5487/26050 (epoch 10.532), train_loss = 1.28258861, grad/param norm = 1.6159e-01, time/batch = 0.6422s	
5488/26050 (epoch 10.534), train_loss = 1.38494088, grad/param norm = 1.8290e-01, time/batch = 0.6386s	
5489/26050 (epoch 10.536), train_loss = 1.26052449, grad/param norm = 1.5666e-01, time/batch = 0.6395s	
5490/26050 (epoch 10.537), train_loss = 1.40917846, grad/param norm = 1.9350e-01, time/batch = 0.6392s	
5491/26050 (epoch 10.539), train_loss = 1.29176891, grad/param norm = 1.7039e-01, time/batch = 0.6400s	
5492/26050 (epoch 10.541), train_loss = 1.49789708, grad/param norm = 2.0130e-01, time/batch = 0.6421s	
5493/26050 (epoch 10.543), train_loss = 1.12390890, grad/param norm = 1.7034e-01, time/batch = 0.6401s	
5494/26050 (epoch 10.545), train_loss = 1.34933241, grad/param norm = 1.7315e-01, time/batch = 0.6403s	
5495/26050 (epoch 10.547), train_loss = 1.32962621, grad/param norm = 1.7567e-01, time/batch = 0.6510s	
5496/26050 (epoch 10.549), train_loss = 1.11162525, grad/param norm = 1.6942e-01, time/batch = 0.6466s	
5497/26050 (epoch 10.551), train_loss = 1.33722021, grad/param norm = 1.8162e-01, time/batch = 0.6417s	
5498/26050 (epoch 10.553), train_loss = 1.18782808, grad/param norm = 1.6183e-01, time/batch = 0.6394s	
5499/26050 (epoch 10.555), train_loss = 1.24332099, grad/param norm = 1.6586e-01, time/batch = 0.6421s	
5500/26050 (epoch 10.557), train_loss = 1.35358469, grad/param norm = 1.6228e-01, time/batch = 0.6393s	
5501/26050 (epoch 10.559), train_loss = 1.29856572, grad/param norm = 1.7234e-01, time/batch = 0.6417s	
5502/26050 (epoch 10.560), train_loss = 1.28339531, grad/param norm = 1.7876e-01, time/batch = 0.6412s	
5503/26050 (epoch 10.562), train_loss = 1.27585911, grad/param norm = 1.7477e-01, time/batch = 0.6519s	
5504/26050 (epoch 10.564), train_loss = 1.50600351, grad/param norm = 1.8059e-01, time/batch = 0.6468s	
5505/26050 (epoch 10.566), train_loss = 1.17218099, grad/param norm = 1.6642e-01, time/batch = 0.6392s	
5506/26050 (epoch 10.568), train_loss = 1.31010110, grad/param norm = 1.7168e-01, time/batch = 0.6384s	
5507/26050 (epoch 10.570), train_loss = 1.41820938, grad/param norm = 1.8548e-01, time/batch = 0.6397s	
5508/26050 (epoch 10.572), train_loss = 1.27582005, grad/param norm = 1.6528e-01, time/batch = 0.6588s	
5509/26050 (epoch 10.574), train_loss = 1.38092896, grad/param norm = 2.0185e-01, time/batch = 0.6830s	
5510/26050 (epoch 10.576), train_loss = 1.38005323, grad/param norm = 1.9361e-01, time/batch = 0.6446s	
5511/26050 (epoch 10.578), train_loss = 1.30105360, grad/param norm = 1.8671e-01, time/batch = 0.6457s	
5512/26050 (epoch 10.580), train_loss = 1.18575123, grad/param norm = 1.7451e-01, time/batch = 0.6468s	
5513/26050 (epoch 10.582), train_loss = 1.34559628, grad/param norm = 1.8286e-01, time/batch = 0.6388s	
5514/26050 (epoch 10.583), train_loss = 1.38614203, grad/param norm = 1.8083e-01, time/batch = 0.6388s	
5515/26050 (epoch 10.585), train_loss = 1.18978988, grad/param norm = 1.7569e-01, time/batch = 0.6412s	
5516/26050 (epoch 10.587), train_loss = 1.35338843, grad/param norm = 1.7416e-01, time/batch = 0.6382s	
5517/26050 (epoch 10.589), train_loss = 1.39425938, grad/param norm = 1.9090e-01, time/batch = 0.6398s	
5518/26050 (epoch 10.591), train_loss = 1.32662995, grad/param norm = 1.8211e-01, time/batch = 0.6400s	
5519/26050 (epoch 10.593), train_loss = 1.17057452, grad/param norm = 1.7981e-01, time/batch = 0.6391s	
5520/26050 (epoch 10.595), train_loss = 1.45737612, grad/param norm = 2.0848e-01, time/batch = 0.6412s	
5521/26050 (epoch 10.597), train_loss = 1.32796033, grad/param norm = 1.7942e-01, time/batch = 0.6399s	
5522/26050 (epoch 10.599), train_loss = 1.26318665, grad/param norm = 1.7530e-01, time/batch = 0.6394s	
5523/26050 (epoch 10.601), train_loss = 1.51026389, grad/param norm = 1.8571e-01, time/batch = 0.6432s	
5524/26050 (epoch 10.603), train_loss = 1.35690697, grad/param norm = 1.7686e-01, time/batch = 0.6830s	
5525/26050 (epoch 10.605), train_loss = 1.22597721, grad/param norm = 1.6623e-01, time/batch = 0.6587s	
5526/26050 (epoch 10.607), train_loss = 1.44529599, grad/param norm = 1.8769e-01, time/batch = 0.6451s	
5527/26050 (epoch 10.608), train_loss = 1.22629084, grad/param norm = 1.6045e-01, time/batch = 0.6407s	
5528/26050 (epoch 10.610), train_loss = 1.28163983, grad/param norm = 1.8241e-01, time/batch = 0.6392s	
5529/26050 (epoch 10.612), train_loss = 1.26891485, grad/param norm = 1.7221e-01, time/batch = 0.6416s	
5530/26050 (epoch 10.614), train_loss = 1.37215302, grad/param norm = 1.7792e-01, time/batch = 0.6389s	
5531/26050 (epoch 10.616), train_loss = 1.55574585, grad/param norm = 1.9429e-01, time/batch = 0.6415s	
5532/26050 (epoch 10.618), train_loss = 1.22961486, grad/param norm = 1.7643e-01, time/batch = 0.6401s	
5533/26050 (epoch 10.620), train_loss = 1.32158013, grad/param norm = 1.7893e-01, time/batch = 0.6452s	
5534/26050 (epoch 10.622), train_loss = 1.09342368, grad/param norm = 1.5225e-01, time/batch = 0.6427s	
5535/26050 (epoch 10.624), train_loss = 1.16762997, grad/param norm = 1.6339e-01, time/batch = 0.6421s	
5536/26050 (epoch 10.626), train_loss = 1.36620951, grad/param norm = 1.8235e-01, time/batch = 0.6472s	
5537/26050 (epoch 10.628), train_loss = 1.26317429, grad/param norm = 1.8708e-01, time/batch = 0.6427s	
5538/26050 (epoch 10.630), train_loss = 1.42665154, grad/param norm = 1.7280e-01, time/batch = 0.6417s	
5539/26050 (epoch 10.631), train_loss = 1.45199537, grad/param norm = 1.8613e-01, time/batch = 0.6660s	
5540/26050 (epoch 10.633), train_loss = 1.21353158, grad/param norm = 1.7580e-01, time/batch = 0.6442s	
5541/26050 (epoch 10.635), train_loss = 1.19660408, grad/param norm = 1.5824e-01, time/batch = 0.6465s	
5542/26050 (epoch 10.637), train_loss = 1.19944166, grad/param norm = 1.7958e-01, time/batch = 0.6535s	
5543/26050 (epoch 10.639), train_loss = 1.39681917, grad/param norm = 1.7076e-01, time/batch = 0.6478s	
5544/26050 (epoch 10.641), train_loss = 1.24038979, grad/param norm = 1.5948e-01, time/batch = 0.6420s	
5545/26050 (epoch 10.643), train_loss = 1.15818983, grad/param norm = 1.5090e-01, time/batch = 0.6441s	
5546/26050 (epoch 10.645), train_loss = 1.33535948, grad/param norm = 1.8866e-01, time/batch = 0.6410s	
5547/26050 (epoch 10.647), train_loss = 1.25629862, grad/param norm = 1.7664e-01, time/batch = 0.6412s	
5548/26050 (epoch 10.649), train_loss = 1.33206920, grad/param norm = 1.9227e-01, time/batch = 0.6394s	
5549/26050 (epoch 10.651), train_loss = 1.23873318, grad/param norm = 1.8228e-01, time/batch = 0.6401s	
5550/26050 (epoch 10.653), train_loss = 1.29492207, grad/param norm = 1.7435e-01, time/batch = 0.6403s	
5551/26050 (epoch 10.655), train_loss = 1.20974025, grad/param norm = 1.7012e-01, time/batch = 0.6412s	
5552/26050 (epoch 10.656), train_loss = 1.15940511, grad/param norm = 1.6713e-01, time/batch = 0.6412s	
5553/26050 (epoch 10.658), train_loss = 1.50430466, grad/param norm = 1.8264e-01, time/batch = 0.6409s	
5554/26050 (epoch 10.660), train_loss = 1.17807104, grad/param norm = 1.8142e-01, time/batch = 0.6480s	
5555/26050 (epoch 10.662), train_loss = 1.16497285, grad/param norm = 1.5569e-01, time/batch = 0.6829s	
5556/26050 (epoch 10.664), train_loss = 1.26090434, grad/param norm = 1.7352e-01, time/batch = 0.6539s	
5557/26050 (epoch 10.666), train_loss = 1.30986057, grad/param norm = 1.8261e-01, time/batch = 0.6418s	
5558/26050 (epoch 10.668), train_loss = 1.07565043, grad/param norm = 1.6455e-01, time/batch = 0.6485s	
5559/26050 (epoch 10.670), train_loss = 1.45845179, grad/param norm = 1.9299e-01, time/batch = 0.6384s	
5560/26050 (epoch 10.672), train_loss = 1.22053830, grad/param norm = 1.7066e-01, time/batch = 0.6392s	
5561/26050 (epoch 10.674), train_loss = 1.17983175, grad/param norm = 1.6689e-01, time/batch = 0.6394s	
5562/26050 (epoch 10.676), train_loss = 1.33097284, grad/param norm = 1.6946e-01, time/batch = 0.6392s	
5563/26050 (epoch 10.678), train_loss = 1.42925580, grad/param norm = 1.7411e-01, time/batch = 0.6384s	
5564/26050 (epoch 10.679), train_loss = 1.51654784, grad/param norm = 1.9637e-01, time/batch = 0.6404s	
5565/26050 (epoch 10.681), train_loss = 1.31481033, grad/param norm = 1.7624e-01, time/batch = 0.6400s	
5566/26050 (epoch 10.683), train_loss = 1.20856268, grad/param norm = 2.0362e-01, time/batch = 0.6384s	
5567/26050 (epoch 10.685), train_loss = 1.22890111, grad/param norm = 1.5727e-01, time/batch = 0.6381s	
5568/26050 (epoch 10.687), train_loss = 1.09630488, grad/param norm = 1.5798e-01, time/batch = 0.6380s	
5569/26050 (epoch 10.689), train_loss = 1.26429784, grad/param norm = 1.7298e-01, time/batch = 0.6385s	
5570/26050 (epoch 10.691), train_loss = 1.01330504, grad/param norm = 1.5435e-01, time/batch = 0.6688s	
5571/26050 (epoch 10.693), train_loss = 1.20555914, grad/param norm = 1.7497e-01, time/batch = 0.6714s	
5572/26050 (epoch 10.695), train_loss = 1.29743765, grad/param norm = 1.7107e-01, time/batch = 0.6584s	
5573/26050 (epoch 10.697), train_loss = 1.16931002, grad/param norm = 1.6826e-01, time/batch = 0.6581s	
5574/26050 (epoch 10.699), train_loss = 1.35773976, grad/param norm = 1.8528e-01, time/batch = 0.6404s	
5575/26050 (epoch 10.701), train_loss = 1.12112342, grad/param norm = 1.5674e-01, time/batch = 0.6572s	
5576/26050 (epoch 10.702), train_loss = 1.49570619, grad/param norm = 1.9006e-01, time/batch = 0.6436s	
5577/26050 (epoch 10.704), train_loss = 1.32542805, grad/param norm = 1.7184e-01, time/batch = 0.6403s	
5578/26050 (epoch 10.706), train_loss = 1.34677242, grad/param norm = 2.0068e-01, time/batch = 0.6414s	
5579/26050 (epoch 10.708), train_loss = 1.35939092, grad/param norm = 1.7496e-01, time/batch = 0.6387s	
5580/26050 (epoch 10.710), train_loss = 1.34972978, grad/param norm = 1.7632e-01, time/batch = 0.6425s	
5581/26050 (epoch 10.712), train_loss = 1.44314716, grad/param norm = 1.8017e-01, time/batch = 0.6444s	
5582/26050 (epoch 10.714), train_loss = 1.14288226, grad/param norm = 1.7861e-01, time/batch = 0.6417s	
5583/26050 (epoch 10.716), train_loss = 1.55927881, grad/param norm = 2.0826e-01, time/batch = 0.6488s	
5584/26050 (epoch 10.718), train_loss = 1.40496666, grad/param norm = 1.9156e-01, time/batch = 0.6496s	
5585/26050 (epoch 10.720), train_loss = 1.21400192, grad/param norm = 1.7062e-01, time/batch = 0.6604s	
5586/26050 (epoch 10.722), train_loss = 1.16155681, grad/param norm = 1.6932e-01, time/batch = 0.6838s	
5587/26050 (epoch 10.724), train_loss = 1.16980710, grad/param norm = 1.6686e-01, time/batch = 0.6580s	
5588/26050 (epoch 10.726), train_loss = 1.40530539, grad/param norm = 1.7523e-01, time/batch = 0.6605s	
5589/26050 (epoch 10.727), train_loss = 1.34663113, grad/param norm = 1.7343e-01, time/batch = 0.6466s	
5590/26050 (epoch 10.729), train_loss = 1.34720164, grad/param norm = 1.7351e-01, time/batch = 0.6402s	
5591/26050 (epoch 10.731), train_loss = 1.31257393, grad/param norm = 1.5948e-01, time/batch = 0.6439s	
5592/26050 (epoch 10.733), train_loss = 1.25055387, grad/param norm = 1.9627e-01, time/batch = 0.6407s	
5593/26050 (epoch 10.735), train_loss = 1.48647865, grad/param norm = 1.8513e-01, time/batch = 0.6409s	
5594/26050 (epoch 10.737), train_loss = 1.28438009, grad/param norm = 1.7576e-01, time/batch = 0.6454s	
5595/26050 (epoch 10.739), train_loss = 1.32986486, grad/param norm = 1.6529e-01, time/batch = 0.6427s	
5596/26050 (epoch 10.741), train_loss = 1.19641365, grad/param norm = 1.6567e-01, time/batch = 0.6424s	
5597/26050 (epoch 10.743), train_loss = 1.36279167, grad/param norm = 2.4128e-01, time/batch = 0.6416s	
5598/26050 (epoch 10.745), train_loss = 1.17733097, grad/param norm = 1.7337e-01, time/batch = 0.6414s	
5599/26050 (epoch 10.747), train_loss = 1.18930928, grad/param norm = 1.7105e-01, time/batch = 0.6424s	
5600/26050 (epoch 10.749), train_loss = 1.44142141, grad/param norm = 1.9193e-01, time/batch = 0.6429s	
5601/26050 (epoch 10.750), train_loss = 1.26636247, grad/param norm = 1.5921e-01, time/batch = 0.6843s	
5602/26050 (epoch 10.752), train_loss = 1.30504219, grad/param norm = 1.9955e-01, time/batch = 0.6651s	
5603/26050 (epoch 10.754), train_loss = 1.31190244, grad/param norm = 1.7341e-01, time/batch = 0.6427s	
5604/26050 (epoch 10.756), train_loss = 1.32823475, grad/param norm = 1.8430e-01, time/batch = 0.6467s	
5605/26050 (epoch 10.758), train_loss = 1.31328754, grad/param norm = 1.7411e-01, time/batch = 0.6432s	
5606/26050 (epoch 10.760), train_loss = 1.39963102, grad/param norm = 1.8099e-01, time/batch = 0.6401s	
5607/26050 (epoch 10.762), train_loss = 1.19240678, grad/param norm = 1.5875e-01, time/batch = 0.6392s	
5608/26050 (epoch 10.764), train_loss = 1.39324632, grad/param norm = 1.9446e-01, time/batch = 0.6398s	
5609/26050 (epoch 10.766), train_loss = 1.38386719, grad/param norm = 1.8904e-01, time/batch = 0.6397s	
5610/26050 (epoch 10.768), train_loss = 1.14359487, grad/param norm = 1.5180e-01, time/batch = 0.6413s	
5611/26050 (epoch 10.770), train_loss = 1.28727057, grad/param norm = 1.7825e-01, time/batch = 0.6427s	
5612/26050 (epoch 10.772), train_loss = 1.27085167, grad/param norm = 1.6216e-01, time/batch = 0.6452s	
5613/26050 (epoch 10.774), train_loss = 1.14874068, grad/param norm = 1.7373e-01, time/batch = 0.6424s	
5614/26050 (epoch 10.775), train_loss = 0.98636214, grad/param norm = 1.5639e-01, time/batch = 0.6422s	
5615/26050 (epoch 10.777), train_loss = 1.20183064, grad/param norm = 1.6826e-01, time/batch = 0.6549s	
5616/26050 (epoch 10.779), train_loss = 1.25659786, grad/param norm = 1.7666e-01, time/batch = 0.6757s	
5617/26050 (epoch 10.781), train_loss = 1.23148619, grad/param norm = 1.6430e-01, time/batch = 0.6785s	
5618/26050 (epoch 10.783), train_loss = 1.18715752, grad/param norm = 1.6424e-01, time/batch = 0.6606s	
5619/26050 (epoch 10.785), train_loss = 1.23952067, grad/param norm = 1.8168e-01, time/batch = 0.6595s	
5620/26050 (epoch 10.787), train_loss = 1.20645589, grad/param norm = 1.6791e-01, time/batch = 0.6542s	
5621/26050 (epoch 10.789), train_loss = 1.24456349, grad/param norm = 1.8555e-01, time/batch = 0.6517s	
5622/26050 (epoch 10.791), train_loss = 1.28200571, grad/param norm = 1.8298e-01, time/batch = 0.6536s	
5623/26050 (epoch 10.793), train_loss = 1.26133019, grad/param norm = 1.8232e-01, time/batch = 0.6534s	
5624/26050 (epoch 10.795), train_loss = 1.09796191, grad/param norm = 1.5158e-01, time/batch = 0.6558s	
5625/26050 (epoch 10.797), train_loss = 1.19339923, grad/param norm = 1.7534e-01, time/batch = 0.6531s	
5626/26050 (epoch 10.798), train_loss = 1.15019063, grad/param norm = 1.7278e-01, time/batch = 0.6605s	
5627/26050 (epoch 10.800), train_loss = 1.12244813, grad/param norm = 1.4693e-01, time/batch = 0.6620s	
5628/26050 (epoch 10.802), train_loss = 1.25024159, grad/param norm = 1.7502e-01, time/batch = 0.6516s	
5629/26050 (epoch 10.804), train_loss = 1.24887578, grad/param norm = 1.6758e-01, time/batch = 0.6400s	
5630/26050 (epoch 10.806), train_loss = 1.38906363, grad/param norm = 1.8709e-01, time/batch = 0.6403s	
5631/26050 (epoch 10.808), train_loss = 1.24629272, grad/param norm = 1.6970e-01, time/batch = 0.6502s	
5632/26050 (epoch 10.810), train_loss = 1.21963667, grad/param norm = 1.7411e-01, time/batch = 0.6583s	
5633/26050 (epoch 10.812), train_loss = 1.14833670, grad/param norm = 1.7558e-01, time/batch = 0.6418s	
5634/26050 (epoch 10.814), train_loss = 1.15856753, grad/param norm = 2.0539e-01, time/batch = 0.6435s	
5635/26050 (epoch 10.816), train_loss = 1.35538179, grad/param norm = 1.8277e-01, time/batch = 0.6508s	
5636/26050 (epoch 10.818), train_loss = 1.44083586, grad/param norm = 2.0501e-01, time/batch = 0.6408s	
5637/26050 (epoch 10.820), train_loss = 1.29162532, grad/param norm = 1.7840e-01, time/batch = 0.6403s	
5638/26050 (epoch 10.821), train_loss = 1.44851852, grad/param norm = 2.1660e-01, time/batch = 0.6397s	
5639/26050 (epoch 10.823), train_loss = 1.47044216, grad/param norm = 1.8395e-01, time/batch = 0.6405s	
5640/26050 (epoch 10.825), train_loss = 1.24536439, grad/param norm = 1.9993e-01, time/batch = 0.6388s	
5641/26050 (epoch 10.827), train_loss = 1.31848756, grad/param norm = 1.8542e-01, time/batch = 0.6415s	
5642/26050 (epoch 10.829), train_loss = 1.33168245, grad/param norm = 1.8404e-01, time/batch = 0.6417s	
5643/26050 (epoch 10.831), train_loss = 1.41400036, grad/param norm = 1.7423e-01, time/batch = 0.6411s	
5644/26050 (epoch 10.833), train_loss = 1.49520361, grad/param norm = 1.8085e-01, time/batch = 0.6406s	
5645/26050 (epoch 10.835), train_loss = 1.51552106, grad/param norm = 1.9513e-01, time/batch = 0.6415s	
5646/26050 (epoch 10.837), train_loss = 1.24523394, grad/param norm = 1.7117e-01, time/batch = 0.6422s	
5647/26050 (epoch 10.839), train_loss = 1.36030519, grad/param norm = 1.9585e-01, time/batch = 0.6825s	
5648/26050 (epoch 10.841), train_loss = 1.41276347, grad/param norm = 1.7870e-01, time/batch = 0.6580s	
5649/26050 (epoch 10.843), train_loss = 1.33452608, grad/param norm = 1.8083e-01, time/batch = 0.6398s	
5650/26050 (epoch 10.845), train_loss = 1.21312687, grad/param norm = 1.6562e-01, time/batch = 0.6432s	
5651/26050 (epoch 10.846), train_loss = 1.42481955, grad/param norm = 1.8029e-01, time/batch = 0.6417s	
5652/26050 (epoch 10.848), train_loss = 1.24253090, grad/param norm = 1.7111e-01, time/batch = 0.6394s	
5653/26050 (epoch 10.850), train_loss = 1.22684123, grad/param norm = 1.6722e-01, time/batch = 0.6390s	
5654/26050 (epoch 10.852), train_loss = 1.25545587, grad/param norm = 1.7584e-01, time/batch = 0.6389s	
5655/26050 (epoch 10.854), train_loss = 1.27712785, grad/param norm = 1.7121e-01, time/batch = 0.6385s	
5656/26050 (epoch 10.856), train_loss = 1.22000664, grad/param norm = 1.8187e-01, time/batch = 0.6433s	
5657/26050 (epoch 10.858), train_loss = 1.15821734, grad/param norm = 1.7418e-01, time/batch = 0.6456s	
5658/26050 (epoch 10.860), train_loss = 1.32745461, grad/param norm = 1.9353e-01, time/batch = 0.6590s	
5659/26050 (epoch 10.862), train_loss = 1.29326256, grad/param norm = 1.7707e-01, time/batch = 0.6469s	
5660/26050 (epoch 10.864), train_loss = 1.28318170, grad/param norm = 1.8629e-01, time/batch = 0.6406s	
5661/26050 (epoch 10.866), train_loss = 1.20622246, grad/param norm = 1.6142e-01, time/batch = 0.6472s	
5662/26050 (epoch 10.868), train_loss = 1.38681016, grad/param norm = 1.9759e-01, time/batch = 0.6428s	
5663/26050 (epoch 10.869), train_loss = 1.15790312, grad/param norm = 1.6201e-01, time/batch = 0.6402s	
5664/26050 (epoch 10.871), train_loss = 1.11002234, grad/param norm = 1.5482e-01, time/batch = 0.6507s	
5665/26050 (epoch 10.873), train_loss = 1.33826004, grad/param norm = 1.7465e-01, time/batch = 0.6589s	
5666/26050 (epoch 10.875), train_loss = 1.26561429, grad/param norm = 1.7549e-01, time/batch = 0.6626s	
5667/26050 (epoch 10.877), train_loss = 1.14620746, grad/param norm = 1.7087e-01, time/batch = 0.6733s	
5668/26050 (epoch 10.879), train_loss = 1.27252176, grad/param norm = 1.6125e-01, time/batch = 0.6425s	
5669/26050 (epoch 10.881), train_loss = 1.42579250, grad/param norm = 1.8088e-01, time/batch = 0.6444s	
5670/26050 (epoch 10.883), train_loss = 1.31237649, grad/param norm = 1.7448e-01, time/batch = 0.6409s	
5671/26050 (epoch 10.885), train_loss = 1.00462449, grad/param norm = 1.5209e-01, time/batch = 0.6414s	
5672/26050 (epoch 10.887), train_loss = 1.32576722, grad/param norm = 1.7841e-01, time/batch = 0.6435s	
5673/26050 (epoch 10.889), train_loss = 1.21668846, grad/param norm = 1.6161e-01, time/batch = 0.6433s	
5674/26050 (epoch 10.891), train_loss = 1.04026400, grad/param norm = 1.5408e-01, time/batch = 0.6403s	
5675/26050 (epoch 10.893), train_loss = 1.02702129, grad/param norm = 1.5246e-01, time/batch = 0.6402s	
5676/26050 (epoch 10.894), train_loss = 1.21032041, grad/param norm = 1.6288e-01, time/batch = 0.6420s	
5677/26050 (epoch 10.896), train_loss = 1.39278002, grad/param norm = 1.7742e-01, time/batch = 0.6539s	
5678/26050 (epoch 10.898), train_loss = 1.21745822, grad/param norm = 1.8528e-01, time/batch = 0.6827s	
5679/26050 (epoch 10.900), train_loss = 1.43214139, grad/param norm = 1.7805e-01, time/batch = 0.6497s	
5680/26050 (epoch 10.902), train_loss = 1.27671718, grad/param norm = 1.7873e-01, time/batch = 0.6584s	
5681/26050 (epoch 10.904), train_loss = 1.23146372, grad/param norm = 1.6098e-01, time/batch = 0.6640s	
5682/26050 (epoch 10.906), train_loss = 1.25321109, grad/param norm = 1.7191e-01, time/batch = 0.6570s	
5683/26050 (epoch 10.908), train_loss = 1.24017569, grad/param norm = 1.7008e-01, time/batch = 0.6562s	
5684/26050 (epoch 10.910), train_loss = 1.16674382, grad/param norm = 1.5250e-01, time/batch = 0.6568s	
5685/26050 (epoch 10.912), train_loss = 1.53169199, grad/param norm = 1.9180e-01, time/batch = 0.6603s	
5686/26050 (epoch 10.914), train_loss = 1.68875074, grad/param norm = 1.9840e-01, time/batch = 0.6562s	
5687/26050 (epoch 10.916), train_loss = 1.41287993, grad/param norm = 1.9443e-01, time/batch = 0.6615s	
5688/26050 (epoch 10.917), train_loss = 1.32602086, grad/param norm = 2.0204e-01, time/batch = 0.6594s	
5689/26050 (epoch 10.919), train_loss = 1.39046594, grad/param norm = 1.8429e-01, time/batch = 0.6604s	
5690/26050 (epoch 10.921), train_loss = 1.21926931, grad/param norm = 1.9766e-01, time/batch = 0.6577s	
5691/26050 (epoch 10.923), train_loss = 1.28576408, grad/param norm = 1.9072e-01, time/batch = 0.6619s	
5692/26050 (epoch 10.925), train_loss = 1.25294542, grad/param norm = 1.6741e-01, time/batch = 0.6532s	
5693/26050 (epoch 10.927), train_loss = 1.14393974, grad/param norm = 1.4938e-01, time/batch = 0.6837s	
5694/26050 (epoch 10.929), train_loss = 1.18934656, grad/param norm = 1.7494e-01, time/batch = 0.6520s	
5695/26050 (epoch 10.931), train_loss = 1.52479950, grad/param norm = 2.1375e-01, time/batch = 0.6477s	
5696/26050 (epoch 10.933), train_loss = 1.23299141, grad/param norm = 1.7940e-01, time/batch = 0.6425s	
5697/26050 (epoch 10.935), train_loss = 1.19717385, grad/param norm = 1.5948e-01, time/batch = 0.6397s	
5698/26050 (epoch 10.937), train_loss = 1.32078105, grad/param norm = 1.6969e-01, time/batch = 0.6392s	
5699/26050 (epoch 10.939), train_loss = 1.15509599, grad/param norm = 1.5463e-01, time/batch = 0.6398s	
5700/26050 (epoch 10.940), train_loss = 1.28491747, grad/param norm = 1.6246e-01, time/batch = 0.6402s	
5701/26050 (epoch 10.942), train_loss = 1.31296009, grad/param norm = 1.9509e-01, time/batch = 0.6417s	
5702/26050 (epoch 10.944), train_loss = 1.24229004, grad/param norm = 1.9153e-01, time/batch = 0.6411s	
5703/26050 (epoch 10.946), train_loss = 1.43717936, grad/param norm = 1.7894e-01, time/batch = 0.6487s	
5704/26050 (epoch 10.948), train_loss = 1.10257715, grad/param norm = 1.8582e-01, time/batch = 0.6570s	
5705/26050 (epoch 10.950), train_loss = 1.24890563, grad/param norm = 1.7773e-01, time/batch = 0.6507s	
5706/26050 (epoch 10.952), train_loss = 1.41452747, grad/param norm = 1.9454e-01, time/batch = 0.6542s	
5707/26050 (epoch 10.954), train_loss = 1.38309400, grad/param norm = 1.7927e-01, time/batch = 0.6561s	
5708/26050 (epoch 10.956), train_loss = 1.31126121, grad/param norm = 1.8947e-01, time/batch = 0.6496s	
5709/26050 (epoch 10.958), train_loss = 1.24437280, grad/param norm = 1.7159e-01, time/batch = 0.6502s	
5710/26050 (epoch 10.960), train_loss = 1.26069863, grad/param norm = 1.7096e-01, time/batch = 0.6521s	
5711/26050 (epoch 10.962), train_loss = 1.18617510, grad/param norm = 1.6676e-01, time/batch = 0.6562s	
5712/26050 (epoch 10.964), train_loss = 1.26320287, grad/param norm = 1.7280e-01, time/batch = 0.6488s	
5713/26050 (epoch 10.965), train_loss = 1.16532848, grad/param norm = 1.6691e-01, time/batch = 0.6474s	
5714/26050 (epoch 10.967), train_loss = 1.60101470, grad/param norm = 1.7999e-01, time/batch = 0.6490s	
5715/26050 (epoch 10.969), train_loss = 1.24299269, grad/param norm = 1.6055e-01, time/batch = 0.6522s	
5716/26050 (epoch 10.971), train_loss = 1.16888982, grad/param norm = 1.5588e-01, time/batch = 0.6598s	
5717/26050 (epoch 10.973), train_loss = 1.23597401, grad/param norm = 1.8215e-01, time/batch = 0.6511s	
5718/26050 (epoch 10.975), train_loss = 1.33312559, grad/param norm = 1.6530e-01, time/batch = 0.6687s	
5719/26050 (epoch 10.977), train_loss = 1.29123676, grad/param norm = 1.5722e-01, time/batch = 0.6606s	
5720/26050 (epoch 10.979), train_loss = 1.10044527, grad/param norm = 1.6768e-01, time/batch = 0.6490s	
5721/26050 (epoch 10.981), train_loss = 1.39181945, grad/param norm = 1.7008e-01, time/batch = 0.6458s	
5722/26050 (epoch 10.983), train_loss = 1.39206657, grad/param norm = 1.7575e-01, time/batch = 0.6546s	
5723/26050 (epoch 10.985), train_loss = 1.30327703, grad/param norm = 1.7534e-01, time/batch = 0.6420s	
5724/26050 (epoch 10.987), train_loss = 1.43464309, grad/param norm = 1.9109e-01, time/batch = 0.6434s	
5725/26050 (epoch 10.988), train_loss = 1.38015995, grad/param norm = 1.7299e-01, time/batch = 0.6416s	
5726/26050 (epoch 10.990), train_loss = 1.18190565, grad/param norm = 1.5744e-01, time/batch = 0.6439s	
5727/26050 (epoch 10.992), train_loss = 1.43373333, grad/param norm = 1.8652e-01, time/batch = 0.6457s	
5728/26050 (epoch 10.994), train_loss = 1.29988386, grad/param norm = 1.7876e-01, time/batch = 0.6436s	
5729/26050 (epoch 10.996), train_loss = 1.23865737, grad/param norm = 1.9175e-01, time/batch = 0.6429s	
5730/26050 (epoch 10.998), train_loss = 1.29436516, grad/param norm = 1.7416e-01, time/batch = 0.6430s	
decayed learning rate by a factor 0.97 to 0.0018818	
5731/26050 (epoch 11.000), train_loss = 1.24085240, grad/param norm = 1.7555e-01, time/batch = 0.6446s	
5732/26050 (epoch 11.002), train_loss = 1.34149392, grad/param norm = 1.8864e-01, time/batch = 0.6508s	
5733/26050 (epoch 11.004), train_loss = 1.17590722, grad/param norm = 1.7192e-01, time/batch = 0.6469s	
5734/26050 (epoch 11.006), train_loss = 1.20177689, grad/param norm = 1.7052e-01, time/batch = 0.6487s	
5735/26050 (epoch 11.008), train_loss = 1.18040089, grad/param norm = 1.7512e-01, time/batch = 0.6406s	
5736/26050 (epoch 11.010), train_loss = 1.20981546, grad/param norm = 1.6566e-01, time/batch = 0.6658s	
5737/26050 (epoch 11.012), train_loss = 1.29499277, grad/param norm = 1.7710e-01, time/batch = 0.6508s	
5738/26050 (epoch 11.013), train_loss = 1.69420986, grad/param norm = 2.0352e-01, time/batch = 0.6482s	
5739/26050 (epoch 11.015), train_loss = 1.17591815, grad/param norm = 1.6696e-01, time/batch = 0.6830s	
5740/26050 (epoch 11.017), train_loss = 1.30287774, grad/param norm = 1.7071e-01, time/batch = 0.6605s	
5741/26050 (epoch 11.019), train_loss = 1.06715429, grad/param norm = 1.4191e-01, time/batch = 0.6461s	
5742/26050 (epoch 11.021), train_loss = 1.37088080, grad/param norm = 1.7676e-01, time/batch = 0.6425s	
5743/26050 (epoch 11.023), train_loss = 1.10243594, grad/param norm = 1.6259e-01, time/batch = 0.6398s	
5744/26050 (epoch 11.025), train_loss = 1.23167041, grad/param norm = 1.6747e-01, time/batch = 0.6401s	
5745/26050 (epoch 11.027), train_loss = 1.03498936, grad/param norm = 1.5876e-01, time/batch = 0.6398s	
5746/26050 (epoch 11.029), train_loss = 1.24164897, grad/param norm = 1.6640e-01, time/batch = 0.6399s	
5747/26050 (epoch 11.031), train_loss = 1.42216539, grad/param norm = 1.9372e-01, time/batch = 0.6394s	
5748/26050 (epoch 11.033), train_loss = 1.32231486, grad/param norm = 1.7717e-01, time/batch = 0.6409s	
5749/26050 (epoch 11.035), train_loss = 1.36295713, grad/param norm = 1.6470e-01, time/batch = 0.6421s	
5750/26050 (epoch 11.036), train_loss = 1.18181527, grad/param norm = 2.0239e-01, time/batch = 0.6419s	
5751/26050 (epoch 11.038), train_loss = 1.09701132, grad/param norm = 1.6687e-01, time/batch = 0.6405s	
5752/26050 (epoch 11.040), train_loss = 1.32103907, grad/param norm = 1.8559e-01, time/batch = 0.6405s	
5753/26050 (epoch 11.042), train_loss = 1.13386273, grad/param norm = 1.7982e-01, time/batch = 0.6406s	
5754/26050 (epoch 11.044), train_loss = 1.35042372, grad/param norm = 1.7725e-01, time/batch = 0.6736s	
5755/26050 (epoch 11.046), train_loss = 1.06099967, grad/param norm = 1.7210e-01, time/batch = 0.6693s	
5756/26050 (epoch 11.048), train_loss = 1.30312219, grad/param norm = 1.8057e-01, time/batch = 0.6532s	
5757/26050 (epoch 11.050), train_loss = 1.15835176, grad/param norm = 1.8504e-01, time/batch = 0.6544s	
5758/26050 (epoch 11.052), train_loss = 1.23251887, grad/param norm = 1.7014e-01, time/batch = 0.6514s	
5759/26050 (epoch 11.054), train_loss = 1.08877004, grad/param norm = 1.5687e-01, time/batch = 0.6484s	
5760/26050 (epoch 11.056), train_loss = 0.99965468, grad/param norm = 1.4174e-01, time/batch = 0.6422s	
5761/26050 (epoch 11.058), train_loss = 1.18031955, grad/param norm = 1.6412e-01, time/batch = 0.6456s	
5762/26050 (epoch 11.060), train_loss = 1.27085571, grad/param norm = 1.6198e-01, time/batch = 0.6435s	
5763/26050 (epoch 11.061), train_loss = 1.15053969, grad/param norm = 1.6456e-01, time/batch = 0.6402s	
5764/26050 (epoch 11.063), train_loss = 1.25842822, grad/param norm = 1.6534e-01, time/batch = 0.6446s	
5765/26050 (epoch 11.065), train_loss = 1.07535288, grad/param norm = 1.7296e-01, time/batch = 0.6446s	
5766/26050 (epoch 11.067), train_loss = 1.32128873, grad/param norm = 1.8811e-01, time/batch = 0.6522s	
5767/26050 (epoch 11.069), train_loss = 1.31019646, grad/param norm = 1.6290e-01, time/batch = 0.6467s	
5768/26050 (epoch 11.071), train_loss = 1.32803276, grad/param norm = 1.8078e-01, time/batch = 0.6441s	
5769/26050 (epoch 11.073), train_loss = 1.47211216, grad/param norm = 1.7465e-01, time/batch = 0.6627s	
5770/26050 (epoch 11.075), train_loss = 1.16147904, grad/param norm = 1.5741e-01, time/batch = 0.6846s	
5771/26050 (epoch 11.077), train_loss = 1.15407391, grad/param norm = 1.6275e-01, time/batch = 0.6605s	
5772/26050 (epoch 11.079), train_loss = 1.31319940, grad/param norm = 1.8597e-01, time/batch = 0.6473s	
5773/26050 (epoch 11.081), train_loss = 1.21108996, grad/param norm = 1.6406e-01, time/batch = 0.6430s	
5774/26050 (epoch 11.083), train_loss = 1.34711775, grad/param norm = 1.7504e-01, time/batch = 0.6403s	
5775/26050 (epoch 11.084), train_loss = 1.36211008, grad/param norm = 1.8323e-01, time/batch = 0.6400s	
5776/26050 (epoch 11.086), train_loss = 1.40194093, grad/param norm = 1.8508e-01, time/batch = 0.6400s	
5777/26050 (epoch 11.088), train_loss = 1.14473160, grad/param norm = 1.5775e-01, time/batch = 0.6392s	
5778/26050 (epoch 11.090), train_loss = 1.33513970, grad/param norm = 1.8323e-01, time/batch = 0.6443s	
5779/26050 (epoch 11.092), train_loss = 1.28704146, grad/param norm = 1.7333e-01, time/batch = 0.6408s	
5780/26050 (epoch 11.094), train_loss = 1.23857263, grad/param norm = 1.7377e-01, time/batch = 0.6417s	
5781/26050 (epoch 11.096), train_loss = 1.21811690, grad/param norm = 1.6603e-01, time/batch = 0.6430s	
5782/26050 (epoch 11.098), train_loss = 1.22256152, grad/param norm = 1.7253e-01, time/batch = 0.6407s	
5783/26050 (epoch 11.100), train_loss = 1.14686046, grad/param norm = 1.7574e-01, time/batch = 0.6577s	
5784/26050 (epoch 11.102), train_loss = 1.27996801, grad/param norm = 1.7608e-01, time/batch = 0.6730s	
5785/26050 (epoch 11.104), train_loss = 1.27146068, grad/param norm = 1.7477e-01, time/batch = 0.6798s	
5786/26050 (epoch 11.106), train_loss = 1.23607162, grad/param norm = 1.7763e-01, time/batch = 0.6763s	
5787/26050 (epoch 11.107), train_loss = 1.02741566, grad/param norm = 1.6344e-01, time/batch = 0.6788s	
5788/26050 (epoch 11.109), train_loss = 1.18182585, grad/param norm = 1.7277e-01, time/batch = 0.6613s	
5789/26050 (epoch 11.111), train_loss = 1.45847327, grad/param norm = 1.9739e-01, time/batch = 0.6538s	
5790/26050 (epoch 11.113), train_loss = 1.18489989, grad/param norm = 1.6686e-01, time/batch = 0.6384s	
5791/26050 (epoch 11.115), train_loss = 1.35034976, grad/param norm = 1.7996e-01, time/batch = 0.6388s	
5792/26050 (epoch 11.117), train_loss = 1.31084182, grad/param norm = 1.8124e-01, time/batch = 0.6398s	
5793/26050 (epoch 11.119), train_loss = 1.03689424, grad/param norm = 1.5386e-01, time/batch = 0.6479s	
5794/26050 (epoch 11.121), train_loss = 1.30724915, grad/param norm = 1.7006e-01, time/batch = 0.6465s	
5795/26050 (epoch 11.123), train_loss = 1.15515719, grad/param norm = 1.8130e-01, time/batch = 0.6640s	
5796/26050 (epoch 11.125), train_loss = 1.06296584, grad/param norm = 1.5233e-01, time/batch = 0.6795s	
5797/26050 (epoch 11.127), train_loss = 1.01623613, grad/param norm = 1.5917e-01, time/batch = 0.6421s	
5798/26050 (epoch 11.129), train_loss = 1.05217106, grad/param norm = 1.5005e-01, time/batch = 0.6396s	
5799/26050 (epoch 11.131), train_loss = 1.22902086, grad/param norm = 1.7313e-01, time/batch = 0.6395s	
5800/26050 (epoch 11.132), train_loss = 1.20653205, grad/param norm = 1.6420e-01, time/batch = 0.6384s	
5801/26050 (epoch 11.134), train_loss = 1.21541852, grad/param norm = 1.6725e-01, time/batch = 0.6395s	
5802/26050 (epoch 11.136), train_loss = 1.24204951, grad/param norm = 1.7123e-01, time/batch = 0.6400s	
5803/26050 (epoch 11.138), train_loss = 1.04658843, grad/param norm = 1.7073e-01, time/batch = 0.6432s	
5804/26050 (epoch 11.140), train_loss = 1.10736907, grad/param norm = 1.6733e-01, time/batch = 0.6395s	
5805/26050 (epoch 11.142), train_loss = 1.15844439, grad/param norm = 1.7056e-01, time/batch = 0.6401s	
5806/26050 (epoch 11.144), train_loss = 1.06276149, grad/param norm = 1.5347e-01, time/batch = 0.6389s	
5807/26050 (epoch 11.146), train_loss = 0.97566008, grad/param norm = 1.6062e-01, time/batch = 0.6391s	
5808/26050 (epoch 11.148), train_loss = 0.99086233, grad/param norm = 1.3391e-01, time/batch = 0.6397s	
5809/26050 (epoch 11.150), train_loss = 1.21880540, grad/param norm = 1.8298e-01, time/batch = 0.6390s	
5810/26050 (epoch 11.152), train_loss = 1.47063235, grad/param norm = 1.9590e-01, time/batch = 0.6424s	
5811/26050 (epoch 11.154), train_loss = 1.03187019, grad/param norm = 1.7318e-01, time/batch = 0.6413s	
5812/26050 (epoch 11.155), train_loss = 1.05240857, grad/param norm = 1.5908e-01, time/batch = 0.6390s	
5813/26050 (epoch 11.157), train_loss = 1.20323906, grad/param norm = 1.8620e-01, time/batch = 0.6389s	
5814/26050 (epoch 11.159), train_loss = 1.21313805, grad/param norm = 1.8301e-01, time/batch = 0.6406s	
5815/26050 (epoch 11.161), train_loss = 1.36789764, grad/param norm = 1.9136e-01, time/batch = 0.6473s	
5816/26050 (epoch 11.163), train_loss = 1.06903873, grad/param norm = 1.6604e-01, time/batch = 0.6560s	
5817/26050 (epoch 11.165), train_loss = 0.94498883, grad/param norm = 1.5002e-01, time/batch = 0.6434s	
5818/26050 (epoch 11.167), train_loss = 1.34137938, grad/param norm = 1.9064e-01, time/batch = 0.6456s	
5819/26050 (epoch 11.169), train_loss = 1.30247879, grad/param norm = 1.7201e-01, time/batch = 0.6392s	
5820/26050 (epoch 11.171), train_loss = 1.01647922, grad/param norm = 1.4350e-01, time/batch = 0.6404s	
5821/26050 (epoch 11.173), train_loss = 1.16740859, grad/param norm = 1.7727e-01, time/batch = 0.6406s	
5822/26050 (epoch 11.175), train_loss = 1.25366072, grad/param norm = 1.7599e-01, time/batch = 0.6407s	
5823/26050 (epoch 11.177), train_loss = 1.32907852, grad/param norm = 1.6753e-01, time/batch = 0.6386s	
5824/26050 (epoch 11.179), train_loss = 0.97360726, grad/param norm = 1.5394e-01, time/batch = 0.6392s	
5825/26050 (epoch 11.180), train_loss = 1.49850610, grad/param norm = 1.7788e-01, time/batch = 0.6394s	
5826/26050 (epoch 11.182), train_loss = 1.50587718, grad/param norm = 1.9580e-01, time/batch = 0.6398s	
5827/26050 (epoch 11.184), train_loss = 1.25248130, grad/param norm = 1.6490e-01, time/batch = 0.6404s	
5828/26050 (epoch 11.186), train_loss = 1.02444691, grad/param norm = 1.5221e-01, time/batch = 0.6379s	
5829/26050 (epoch 11.188), train_loss = 1.23181184, grad/param norm = 1.6429e-01, time/batch = 0.6377s	
5830/26050 (epoch 11.190), train_loss = 1.28743701, grad/param norm = 1.7856e-01, time/batch = 0.6398s	
5831/26050 (epoch 11.192), train_loss = 1.27981087, grad/param norm = 1.7249e-01, time/batch = 0.6383s	
5832/26050 (epoch 11.194), train_loss = 1.26799238, grad/param norm = 1.7049e-01, time/batch = 0.6411s	
5833/26050 (epoch 11.196), train_loss = 1.33299704, grad/param norm = 1.8761e-01, time/batch = 0.6462s	
5834/26050 (epoch 11.198), train_loss = 1.15794455, grad/param norm = 1.6095e-01, time/batch = 0.6472s	
5835/26050 (epoch 11.200), train_loss = 1.15283064, grad/param norm = 1.7154e-01, time/batch = 0.6390s	
5836/26050 (epoch 11.202), train_loss = 1.18279442, grad/param norm = 1.7064e-01, time/batch = 0.6388s	
5837/26050 (epoch 11.203), train_loss = 1.33194728, grad/param norm = 1.8254e-01, time/batch = 0.6380s	
5838/26050 (epoch 11.205), train_loss = 1.13984332, grad/param norm = 1.6225e-01, time/batch = 0.6388s	
5839/26050 (epoch 11.207), train_loss = 1.20924422, grad/param norm = 1.6716e-01, time/batch = 0.6424s	
5840/26050 (epoch 11.209), train_loss = 1.23110308, grad/param norm = 1.6766e-01, time/batch = 0.6385s	
5841/26050 (epoch 11.211), train_loss = 1.07387895, grad/param norm = 1.7209e-01, time/batch = 0.6417s	
5842/26050 (epoch 11.213), train_loss = 1.27820793, grad/param norm = 1.7247e-01, time/batch = 0.6414s	
5843/26050 (epoch 11.215), train_loss = 1.25246186, grad/param norm = 1.8615e-01, time/batch = 0.6382s	
5844/26050 (epoch 11.217), train_loss = 1.20890603, grad/param norm = 1.6483e-01, time/batch = 0.6393s	
5845/26050 (epoch 11.219), train_loss = 1.17071515, grad/param norm = 1.7925e-01, time/batch = 0.6384s	
5846/26050 (epoch 11.221), train_loss = 1.10130317, grad/param norm = 1.5948e-01, time/batch = 0.6547s	
5847/26050 (epoch 11.223), train_loss = 1.26113040, grad/param norm = 1.7032e-01, time/batch = 0.6828s	
5848/26050 (epoch 11.225), train_loss = 1.13299113, grad/param norm = 1.8498e-01, time/batch = 0.6484s	
5849/26050 (epoch 11.226), train_loss = 1.34230638, grad/param norm = 1.7846e-01, time/batch = 0.6576s	
5850/26050 (epoch 11.228), train_loss = 1.37289381, grad/param norm = 1.7717e-01, time/batch = 0.6679s	
5851/26050 (epoch 11.230), train_loss = 1.28115553, grad/param norm = 1.7313e-01, time/batch = 0.6616s	
5852/26050 (epoch 11.232), train_loss = 1.35272321, grad/param norm = 1.8210e-01, time/batch = 0.6588s	
5853/26050 (epoch 11.234), train_loss = 1.07567996, grad/param norm = 1.6635e-01, time/batch = 0.6540s	
5854/26050 (epoch 11.236), train_loss = 1.32749260, grad/param norm = 1.8842e-01, time/batch = 0.6581s	
5855/26050 (epoch 11.238), train_loss = 1.05477937, grad/param norm = 1.6520e-01, time/batch = 0.6615s	
5856/26050 (epoch 11.240), train_loss = 1.19520714, grad/param norm = 1.7747e-01, time/batch = 0.6749s	
5857/26050 (epoch 11.242), train_loss = 1.22690146, grad/param norm = 1.6002e-01, time/batch = 0.6591s	
5858/26050 (epoch 11.244), train_loss = 1.27897612, grad/param norm = 1.9844e-01, time/batch = 0.6545s	
5859/26050 (epoch 11.246), train_loss = 1.15284557, grad/param norm = 1.6042e-01, time/batch = 0.6590s	
5860/26050 (epoch 11.248), train_loss = 1.25221881, grad/param norm = 1.6838e-01, time/batch = 0.6592s	
5861/26050 (epoch 11.250), train_loss = 1.24137807, grad/param norm = 1.8756e-01, time/batch = 0.6612s	
5862/26050 (epoch 11.251), train_loss = 1.14741230, grad/param norm = 1.6765e-01, time/batch = 0.6603s	
5863/26050 (epoch 11.253), train_loss = 1.06133830, grad/param norm = 1.6546e-01, time/batch = 0.6614s	
5864/26050 (epoch 11.255), train_loss = 1.45417506, grad/param norm = 1.7744e-01, time/batch = 0.6570s	
5865/26050 (epoch 11.257), train_loss = 1.23581953, grad/param norm = 1.8972e-01, time/batch = 0.6531s	
5866/26050 (epoch 11.259), train_loss = 1.37694907, grad/param norm = 1.7344e-01, time/batch = 0.6402s	
5867/26050 (epoch 11.261), train_loss = 1.14893845, grad/param norm = 1.8688e-01, time/batch = 0.6435s	
5868/26050 (epoch 11.263), train_loss = 1.24838296, grad/param norm = 1.7683e-01, time/batch = 0.6401s	
5869/26050 (epoch 11.265), train_loss = 1.41304207, grad/param norm = 1.7790e-01, time/batch = 0.6396s	
5870/26050 (epoch 11.267), train_loss = 1.32252862, grad/param norm = 1.7409e-01, time/batch = 0.6470s	
5871/26050 (epoch 11.269), train_loss = 1.42830174, grad/param norm = 1.9750e-01, time/batch = 0.6461s	
5872/26050 (epoch 11.271), train_loss = 1.29969877, grad/param norm = 1.8515e-01, time/batch = 0.6671s	
5873/26050 (epoch 11.273), train_loss = 1.20457780, grad/param norm = 1.9953e-01, time/batch = 0.6772s	
5874/26050 (epoch 11.274), train_loss = 1.19206866, grad/param norm = 1.7195e-01, time/batch = 0.6547s	
5875/26050 (epoch 11.276), train_loss = 1.16030728, grad/param norm = 1.7653e-01, time/batch = 0.6537s	
5876/26050 (epoch 11.278), train_loss = 1.35173993, grad/param norm = 1.7467e-01, time/batch = 0.6510s	
5877/26050 (epoch 11.280), train_loss = 1.22193070, grad/param norm = 1.6826e-01, time/batch = 0.6530s	
5878/26050 (epoch 11.282), train_loss = 1.28060393, grad/param norm = 1.7937e-01, time/batch = 0.6420s	
5879/26050 (epoch 11.284), train_loss = 1.14115538, grad/param norm = 1.7013e-01, time/batch = 0.6418s	
5880/26050 (epoch 11.286), train_loss = 1.23252981, grad/param norm = 1.7365e-01, time/batch = 0.6530s	
5881/26050 (epoch 11.288), train_loss = 1.05182794, grad/param norm = 1.4475e-01, time/batch = 0.6442s	
5882/26050 (epoch 11.290), train_loss = 1.20657280, grad/param norm = 1.7257e-01, time/batch = 0.6421s	
5883/26050 (epoch 11.292), train_loss = 1.14869743, grad/param norm = 1.6755e-01, time/batch = 0.6424s	
5884/26050 (epoch 11.294), train_loss = 1.26783375, grad/param norm = 1.9482e-01, time/batch = 0.6423s	
5885/26050 (epoch 11.296), train_loss = 1.36311172, grad/param norm = 1.7557e-01, time/batch = 0.6436s	
5886/26050 (epoch 11.298), train_loss = 1.22954399, grad/param norm = 1.6575e-01, time/batch = 0.6413s	
5887/26050 (epoch 11.299), train_loss = 0.98746492, grad/param norm = 1.4629e-01, time/batch = 0.6418s	
5888/26050 (epoch 11.301), train_loss = 1.15500085, grad/param norm = 1.7535e-01, time/batch = 0.6420s	
5889/26050 (epoch 11.303), train_loss = 1.27135676, grad/param norm = 1.7710e-01, time/batch = 0.6485s	
5890/26050 (epoch 11.305), train_loss = 1.06991982, grad/param norm = 1.6608e-01, time/batch = 0.6397s	
5891/26050 (epoch 11.307), train_loss = 1.13326482, grad/param norm = 1.7164e-01, time/batch = 0.6401s	
5892/26050 (epoch 11.309), train_loss = 1.20270963, grad/param norm = 1.7498e-01, time/batch = 0.6395s	
5893/26050 (epoch 11.311), train_loss = 1.38737597, grad/param norm = 1.9241e-01, time/batch = 0.6402s	
5894/26050 (epoch 11.313), train_loss = 1.23409009, grad/param norm = 1.8935e-01, time/batch = 0.6446s	
5895/26050 (epoch 11.315), train_loss = 1.35956798, grad/param norm = 1.8383e-01, time/batch = 0.6421s	
5896/26050 (epoch 11.317), train_loss = 1.18318568, grad/param norm = 1.6592e-01, time/batch = 0.6421s	
5897/26050 (epoch 11.319), train_loss = 1.17780689, grad/param norm = 1.6373e-01, time/batch = 0.6406s	
5898/26050 (epoch 11.321), train_loss = 1.19339463, grad/param norm = 1.7961e-01, time/batch = 0.6391s	
5899/26050 (epoch 11.322), train_loss = 1.25836555, grad/param norm = 1.7254e-01, time/batch = 0.6387s	
5900/26050 (epoch 11.324), train_loss = 1.05272728, grad/param norm = 1.7219e-01, time/batch = 0.6382s	
5901/26050 (epoch 11.326), train_loss = 1.39371264, grad/param norm = 1.8350e-01, time/batch = 0.6412s	
5902/26050 (epoch 11.328), train_loss = 1.27865400, grad/param norm = 1.7291e-01, time/batch = 0.6401s	
5903/26050 (epoch 11.330), train_loss = 1.12901861, grad/param norm = 1.7062e-01, time/batch = 0.6715s	
5904/26050 (epoch 11.332), train_loss = 1.32802618, grad/param norm = 1.7631e-01, time/batch = 0.6697s	
5905/26050 (epoch 11.334), train_loss = 1.20182821, grad/param norm = 1.7303e-01, time/batch = 0.6375s	
5906/26050 (epoch 11.336), train_loss = 1.12897771, grad/param norm = 1.5580e-01, time/batch = 0.6493s	
5907/26050 (epoch 11.338), train_loss = 1.10393981, grad/param norm = 1.5970e-01, time/batch = 0.6443s	
5908/26050 (epoch 11.340), train_loss = 1.33383171, grad/param norm = 1.8523e-01, time/batch = 0.6434s	
5909/26050 (epoch 11.342), train_loss = 1.38441702, grad/param norm = 1.8128e-01, time/batch = 0.6383s	
5910/26050 (epoch 11.344), train_loss = 1.23225468, grad/param norm = 1.8455e-01, time/batch = 0.6443s	
5911/26050 (epoch 11.345), train_loss = 1.21593703, grad/param norm = 1.7893e-01, time/batch = 0.6429s	
5912/26050 (epoch 11.347), train_loss = 1.32145158, grad/param norm = 1.8513e-01, time/batch = 0.6472s	
5913/26050 (epoch 11.349), train_loss = 1.27153916, grad/param norm = 1.7812e-01, time/batch = 0.6445s	
5914/26050 (epoch 11.351), train_loss = 1.25655335, grad/param norm = 1.8036e-01, time/batch = 0.6424s	
5915/26050 (epoch 11.353), train_loss = 1.18550000, grad/param norm = 1.8510e-01, time/batch = 0.6396s	
5916/26050 (epoch 11.355), train_loss = 1.31134929, grad/param norm = 1.8555e-01, time/batch = 0.6387s	
5917/26050 (epoch 11.357), train_loss = 1.10174345, grad/param norm = 1.5844e-01, time/batch = 0.6382s	
5918/26050 (epoch 11.359), train_loss = 1.31919468, grad/param norm = 1.7318e-01, time/batch = 0.6407s	
5919/26050 (epoch 11.361), train_loss = 1.16531613, grad/param norm = 1.7004e-01, time/batch = 0.6403s	
5920/26050 (epoch 11.363), train_loss = 1.28199198, grad/param norm = 1.6355e-01, time/batch = 0.6384s	
5921/26050 (epoch 11.365), train_loss = 1.18122440, grad/param norm = 1.5432e-01, time/batch = 0.6409s	
5922/26050 (epoch 11.367), train_loss = 1.23277878, grad/param norm = 1.7424e-01, time/batch = 0.6411s	
5923/26050 (epoch 11.369), train_loss = 1.20672070, grad/param norm = 1.5783e-01, time/batch = 0.6384s	
5924/26050 (epoch 11.370), train_loss = 1.12053324, grad/param norm = 1.5411e-01, time/batch = 0.6391s	
5925/26050 (epoch 11.372), train_loss = 1.31518614, grad/param norm = 1.8785e-01, time/batch = 0.6405s	
5926/26050 (epoch 11.374), train_loss = 1.42736967, grad/param norm = 1.8382e-01, time/batch = 0.6464s	
5927/26050 (epoch 11.376), train_loss = 1.44636041, grad/param norm = 1.8060e-01, time/batch = 0.6437s	
5928/26050 (epoch 11.378), train_loss = 1.21017007, grad/param norm = 1.7419e-01, time/batch = 0.6392s	
5929/26050 (epoch 11.380), train_loss = 1.45383115, grad/param norm = 2.0190e-01, time/batch = 0.6402s	
5930/26050 (epoch 11.382), train_loss = 1.59446226, grad/param norm = 2.1945e-01, time/batch = 0.6379s	
5931/26050 (epoch 11.384), train_loss = 1.19810799, grad/param norm = 1.6358e-01, time/batch = 0.6391s	
5932/26050 (epoch 11.386), train_loss = 1.35403532, grad/param norm = 1.8534e-01, time/batch = 0.6399s	
5933/26050 (epoch 11.388), train_loss = 1.28508027, grad/param norm = 1.7934e-01, time/batch = 0.6471s	
5934/26050 (epoch 11.390), train_loss = 1.11621294, grad/param norm = 1.4983e-01, time/batch = 0.6404s	
5935/26050 (epoch 11.392), train_loss = 1.12955256, grad/param norm = 1.5868e-01, time/batch = 0.6397s	
5936/26050 (epoch 11.393), train_loss = 1.30247256, grad/param norm = 1.6822e-01, time/batch = 0.6396s	
5937/26050 (epoch 11.395), train_loss = 1.30964881, grad/param norm = 1.7081e-01, time/batch = 0.6381s	
5938/26050 (epoch 11.397), train_loss = 1.30369549, grad/param norm = 1.9057e-01, time/batch = 0.6453s	
5939/26050 (epoch 11.399), train_loss = 1.11104362, grad/param norm = 1.5576e-01, time/batch = 0.6827s	
5940/26050 (epoch 11.401), train_loss = 1.19830467, grad/param norm = 1.5195e-01, time/batch = 0.6549s	
5941/26050 (epoch 11.403), train_loss = 1.24668893, grad/param norm = 1.5788e-01, time/batch = 0.6668s	
5942/26050 (epoch 11.405), train_loss = 1.22759593, grad/param norm = 1.7618e-01, time/batch = 0.6514s	
5943/26050 (epoch 11.407), train_loss = 1.38686315, grad/param norm = 1.8143e-01, time/batch = 0.6657s	
5944/26050 (epoch 11.409), train_loss = 1.42862443, grad/param norm = 1.9264e-01, time/batch = 0.6576s	
5945/26050 (epoch 11.411), train_loss = 1.28489807, grad/param norm = 1.8077e-01, time/batch = 0.6451s	
5946/26050 (epoch 11.413), train_loss = 1.38395239, grad/param norm = 1.6238e-01, time/batch = 0.6409s	
5947/26050 (epoch 11.415), train_loss = 1.36910323, grad/param norm = 1.8639e-01, time/batch = 0.6405s	
5948/26050 (epoch 11.417), train_loss = 1.48359480, grad/param norm = 1.9073e-01, time/batch = 0.6398s	
5949/26050 (epoch 11.418), train_loss = 1.34830008, grad/param norm = 1.9001e-01, time/batch = 0.6487s	
5950/26050 (epoch 11.420), train_loss = 1.06177206, grad/param norm = 1.4978e-01, time/batch = 0.6527s	
5951/26050 (epoch 11.422), train_loss = 1.10894118, grad/param norm = 1.6945e-01, time/batch = 0.6407s	
5952/26050 (epoch 11.424), train_loss = 1.44030900, grad/param norm = 2.0757e-01, time/batch = 0.6542s	
5953/26050 (epoch 11.426), train_loss = 1.39781822, grad/param norm = 1.8381e-01, time/batch = 0.6564s	
5954/26050 (epoch 11.428), train_loss = 1.14850963, grad/param norm = 1.5054e-01, time/batch = 0.6798s	
5955/26050 (epoch 11.430), train_loss = 1.30133543, grad/param norm = 1.7437e-01, time/batch = 0.6641s	
5956/26050 (epoch 11.432), train_loss = 1.18560893, grad/param norm = 1.6826e-01, time/batch = 0.6413s	
5957/26050 (epoch 11.434), train_loss = 1.26383888, grad/param norm = 1.8490e-01, time/batch = 0.6512s	
5958/26050 (epoch 11.436), train_loss = 1.36776491, grad/param norm = 1.6362e-01, time/batch = 0.6414s	
5959/26050 (epoch 11.438), train_loss = 1.14680755, grad/param norm = 1.6720e-01, time/batch = 0.6411s	
5960/26050 (epoch 11.440), train_loss = 1.28609946, grad/param norm = 1.7353e-01, time/batch = 0.6404s	
5961/26050 (epoch 11.441), train_loss = 1.25201102, grad/param norm = 1.5687e-01, time/batch = 0.6423s	
5962/26050 (epoch 11.443), train_loss = 1.05412427, grad/param norm = 1.4960e-01, time/batch = 0.6481s	
5963/26050 (epoch 11.445), train_loss = 1.11794600, grad/param norm = 1.7330e-01, time/batch = 0.6497s	
5964/26050 (epoch 11.447), train_loss = 1.44002869, grad/param norm = 1.8663e-01, time/batch = 0.6491s	
5965/26050 (epoch 11.449), train_loss = 1.14412491, grad/param norm = 1.7260e-01, time/batch = 0.6429s	
5966/26050 (epoch 11.451), train_loss = 1.36870028, grad/param norm = 1.7386e-01, time/batch = 0.6419s	
5967/26050 (epoch 11.453), train_loss = 1.15477267, grad/param norm = 1.6153e-01, time/batch = 0.6419s	
5968/26050 (epoch 11.455), train_loss = 1.28150972, grad/param norm = 1.6892e-01, time/batch = 0.6421s	
5969/26050 (epoch 11.457), train_loss = 1.26027120, grad/param norm = 1.6993e-01, time/batch = 0.6638s	
5970/26050 (epoch 11.459), train_loss = 1.36875752, grad/param norm = 1.7935e-01, time/batch = 0.6807s	
5971/26050 (epoch 11.461), train_loss = 1.31779617, grad/param norm = 1.8740e-01, time/batch = 0.6457s	
5972/26050 (epoch 11.463), train_loss = 1.17723598, grad/param norm = 1.5152e-01, time/batch = 0.6425s	
5973/26050 (epoch 11.464), train_loss = 1.32718566, grad/param norm = 1.8321e-01, time/batch = 0.6428s	
5974/26050 (epoch 11.466), train_loss = 1.32581039, grad/param norm = 1.8065e-01, time/batch = 0.6428s	
5975/26050 (epoch 11.468), train_loss = 1.33985057, grad/param norm = 1.6213e-01, time/batch = 0.6442s	
5976/26050 (epoch 11.470), train_loss = 1.46290064, grad/param norm = 1.9636e-01, time/batch = 0.6436s	
5977/26050 (epoch 11.472), train_loss = 1.41903871, grad/param norm = 1.8271e-01, time/batch = 0.6408s	
5978/26050 (epoch 11.474), train_loss = 1.48645046, grad/param norm = 1.7852e-01, time/batch = 0.6428s	
5979/26050 (epoch 11.476), train_loss = 1.35189040, grad/param norm = 1.7100e-01, time/batch = 0.6420s	
5980/26050 (epoch 11.478), train_loss = 1.16192762, grad/param norm = 1.4944e-01, time/batch = 0.6512s	
5981/26050 (epoch 11.480), train_loss = 1.28059842, grad/param norm = 1.6291e-01, time/batch = 0.6529s	
5982/26050 (epoch 11.482), train_loss = 1.21408537, grad/param norm = 1.6503e-01, time/batch = 0.6483s	
5983/26050 (epoch 11.484), train_loss = 1.16350259, grad/param norm = 1.6203e-01, time/batch = 0.6421s	
5984/26050 (epoch 11.486), train_loss = 1.42703727, grad/param norm = 1.7476e-01, time/batch = 0.6496s	
5985/26050 (epoch 11.488), train_loss = 1.59601612, grad/param norm = 1.9447e-01, time/batch = 0.6828s	
5986/26050 (epoch 11.489), train_loss = 1.51499616, grad/param norm = 2.0424e-01, time/batch = 0.6528s	
5987/26050 (epoch 11.491), train_loss = 1.15248642, grad/param norm = 1.6234e-01, time/batch = 0.6450s	
5988/26050 (epoch 11.493), train_loss = 1.24729509, grad/param norm = 1.7198e-01, time/batch = 0.6419s	
5989/26050 (epoch 11.495), train_loss = 1.21905736, grad/param norm = 1.6499e-01, time/batch = 0.6421s	
5990/26050 (epoch 11.497), train_loss = 1.19849629, grad/param norm = 1.6694e-01, time/batch = 0.6417s	
5991/26050 (epoch 11.499), train_loss = 1.21965495, grad/param norm = 1.7359e-01, time/batch = 0.6415s	
5992/26050 (epoch 11.501), train_loss = 1.33345856, grad/param norm = 1.7814e-01, time/batch = 0.6428s	
5993/26050 (epoch 11.503), train_loss = 1.18380059, grad/param norm = 1.8704e-01, time/batch = 0.6435s	
5994/26050 (epoch 11.505), train_loss = 1.38263278, grad/param norm = 1.7479e-01, time/batch = 0.6430s	
5995/26050 (epoch 11.507), train_loss = 1.36953181, grad/param norm = 1.9450e-01, time/batch = 0.6482s	
5996/26050 (epoch 11.509), train_loss = 1.48953250, grad/param norm = 1.9310e-01, time/batch = 0.6418s	
5997/26050 (epoch 11.511), train_loss = 1.15339630, grad/param norm = 1.6408e-01, time/batch = 0.6408s	
5998/26050 (epoch 11.512), train_loss = 1.22385996, grad/param norm = 1.8241e-01, time/batch = 0.6417s	
5999/26050 (epoch 11.514), train_loss = 1.33261382, grad/param norm = 1.7945e-01, time/batch = 0.6426s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch11.52_1.5958.t7	
6000/26050 (epoch 11.516), train_loss = 1.36918974, grad/param norm = 1.8523e-01, time/batch = 0.6401s	
6001/26050 (epoch 11.518), train_loss = 1.50431425, grad/param norm = 1.9651e-01, time/batch = 0.6479s	
6002/26050 (epoch 11.520), train_loss = 1.24858289, grad/param norm = 1.5987e-01, time/batch = 0.6417s	
6003/26050 (epoch 11.522), train_loss = 1.07205470, grad/param norm = 1.6285e-01, time/batch = 0.6435s	
6004/26050 (epoch 11.524), train_loss = 1.39269145, grad/param norm = 1.8442e-01, time/batch = 0.6441s	
6005/26050 (epoch 11.526), train_loss = 1.36474806, grad/param norm = 1.7905e-01, time/batch = 0.6427s	
6006/26050 (epoch 11.528), train_loss = 1.33059192, grad/param norm = 1.8121e-01, time/batch = 0.6491s	
6007/26050 (epoch 11.530), train_loss = 1.24214167, grad/param norm = 1.5864e-01, time/batch = 0.6467s	
6008/26050 (epoch 11.532), train_loss = 1.24584289, grad/param norm = 1.5472e-01, time/batch = 0.6475s	
6009/26050 (epoch 11.534), train_loss = 1.34865680, grad/param norm = 2.2425e-01, time/batch = 0.6484s	
6010/26050 (epoch 11.536), train_loss = 1.24132384, grad/param norm = 1.6420e-01, time/batch = 0.6465s	
6011/26050 (epoch 11.537), train_loss = 1.37171123, grad/param norm = 1.9005e-01, time/batch = 0.6479s	
6012/26050 (epoch 11.539), train_loss = 1.25952879, grad/param norm = 1.7107e-01, time/batch = 0.6608s	
6013/26050 (epoch 11.541), train_loss = 1.45339205, grad/param norm = 1.9461e-01, time/batch = 0.6833s	
6014/26050 (epoch 11.543), train_loss = 1.08546764, grad/param norm = 1.6674e-01, time/batch = 0.6431s	
6015/26050 (epoch 11.545), train_loss = 1.30698192, grad/param norm = 1.6956e-01, time/batch = 0.6409s	
6016/26050 (epoch 11.547), train_loss = 1.29968619, grad/param norm = 1.7747e-01, time/batch = 0.6407s	
6017/26050 (epoch 11.549), train_loss = 1.07448460, grad/param norm = 1.6355e-01, time/batch = 0.6422s	
6018/26050 (epoch 11.551), train_loss = 1.29841060, grad/param norm = 1.7435e-01, time/batch = 0.6408s	
6019/26050 (epoch 11.553), train_loss = 1.15965918, grad/param norm = 1.5968e-01, time/batch = 0.6421s	
6020/26050 (epoch 11.555), train_loss = 1.20443418, grad/param norm = 1.6618e-01, time/batch = 0.6403s	
6021/26050 (epoch 11.557), train_loss = 1.31711682, grad/param norm = 1.6031e-01, time/batch = 0.6444s	
6022/26050 (epoch 11.559), train_loss = 1.26166048, grad/param norm = 1.6867e-01, time/batch = 0.6414s	
6023/26050 (epoch 11.560), train_loss = 1.24666576, grad/param norm = 1.7439e-01, time/batch = 0.6653s	
6024/26050 (epoch 11.562), train_loss = 1.23739566, grad/param norm = 1.7126e-01, time/batch = 0.6433s	
6025/26050 (epoch 11.564), train_loss = 1.46963312, grad/param norm = 1.7710e-01, time/batch = 0.6539s	
6026/26050 (epoch 11.566), train_loss = 1.14039658, grad/param norm = 1.6577e-01, time/batch = 0.6544s	
6027/26050 (epoch 11.568), train_loss = 1.28337562, grad/param norm = 1.7005e-01, time/batch = 0.6505s	
6028/26050 (epoch 11.570), train_loss = 1.37524837, grad/param norm = 1.8011e-01, time/batch = 0.6597s	
6029/26050 (epoch 11.572), train_loss = 1.23595266, grad/param norm = 1.6367e-01, time/batch = 0.6553s	
6030/26050 (epoch 11.574), train_loss = 1.34219228, grad/param norm = 2.0375e-01, time/batch = 0.6411s	
6031/26050 (epoch 11.576), train_loss = 1.34071884, grad/param norm = 1.8893e-01, time/batch = 0.6446s	
6032/26050 (epoch 11.578), train_loss = 1.27341033, grad/param norm = 1.8510e-01, time/batch = 0.6408s	
6033/26050 (epoch 11.580), train_loss = 1.15423417, grad/param norm = 1.7514e-01, time/batch = 0.6404s	
6034/26050 (epoch 11.582), train_loss = 1.30721571, grad/param norm = 1.7779e-01, time/batch = 0.6405s	
6035/26050 (epoch 11.583), train_loss = 1.34731392, grad/param norm = 1.7441e-01, time/batch = 0.6386s	
6036/26050 (epoch 11.585), train_loss = 1.15896179, grad/param norm = 1.7380e-01, time/batch = 0.6386s	
6037/26050 (epoch 11.587), train_loss = 1.30956509, grad/param norm = 1.7448e-01, time/batch = 0.6423s	
6038/26050 (epoch 11.589), train_loss = 1.36048828, grad/param norm = 1.9079e-01, time/batch = 0.6445s	
6039/26050 (epoch 11.591), train_loss = 1.27815118, grad/param norm = 1.7562e-01, time/batch = 0.6380s	
6040/26050 (epoch 11.593), train_loss = 1.13974080, grad/param norm = 1.7476e-01, time/batch = 0.6431s	
6041/26050 (epoch 11.595), train_loss = 1.40400545, grad/param norm = 2.0147e-01, time/batch = 0.6432s	
6042/26050 (epoch 11.597), train_loss = 1.29476018, grad/param norm = 1.7391e-01, time/batch = 0.6452s	
6043/26050 (epoch 11.599), train_loss = 1.23590134, grad/param norm = 1.7335e-01, time/batch = 0.6379s	
6044/26050 (epoch 11.601), train_loss = 1.47452520, grad/param norm = 1.8379e-01, time/batch = 0.6389s	
6045/26050 (epoch 11.603), train_loss = 1.32153326, grad/param norm = 1.7284e-01, time/batch = 0.6397s	
6046/26050 (epoch 11.605), train_loss = 1.19147571, grad/param norm = 1.6399e-01, time/batch = 0.6411s	
6047/26050 (epoch 11.607), train_loss = 1.41729902, grad/param norm = 1.8879e-01, time/batch = 0.6410s	
6048/26050 (epoch 11.608), train_loss = 1.17420313, grad/param norm = 1.5613e-01, time/batch = 0.6416s	
6049/26050 (epoch 11.610), train_loss = 1.24698822, grad/param norm = 1.8036e-01, time/batch = 0.6403s	
6050/26050 (epoch 11.612), train_loss = 1.25152276, grad/param norm = 1.7443e-01, time/batch = 0.6385s	
6051/26050 (epoch 11.614), train_loss = 1.34614504, grad/param norm = 1.7466e-01, time/batch = 0.6388s	
6052/26050 (epoch 11.616), train_loss = 1.51230542, grad/param norm = 1.9870e-01, time/batch = 0.6401s	
6053/26050 (epoch 11.618), train_loss = 1.20342274, grad/param norm = 1.7232e-01, time/batch = 0.6404s	
6054/26050 (epoch 11.620), train_loss = 1.28942707, grad/param norm = 1.7960e-01, time/batch = 0.6710s	
6055/26050 (epoch 11.622), train_loss = 1.07747359, grad/param norm = 1.5083e-01, time/batch = 0.6713s	
6056/26050 (epoch 11.624), train_loss = 1.12922501, grad/param norm = 1.6402e-01, time/batch = 0.6416s	
6057/26050 (epoch 11.626), train_loss = 1.33098234, grad/param norm = 1.7860e-01, time/batch = 0.6426s	
6058/26050 (epoch 11.628), train_loss = 1.22034008, grad/param norm = 1.8832e-01, time/batch = 0.6402s	
6059/26050 (epoch 11.630), train_loss = 1.40129769, grad/param norm = 1.7377e-01, time/batch = 0.6385s	
6060/26050 (epoch 11.631), train_loss = 1.42524795, grad/param norm = 1.8660e-01, time/batch = 0.6381s	
6061/26050 (epoch 11.633), train_loss = 1.17927868, grad/param norm = 1.7457e-01, time/batch = 0.6419s	
6062/26050 (epoch 11.635), train_loss = 1.16748901, grad/param norm = 1.5461e-01, time/batch = 0.6499s	
6063/26050 (epoch 11.637), train_loss = 1.15520644, grad/param norm = 1.7557e-01, time/batch = 0.6397s	
6064/26050 (epoch 11.639), train_loss = 1.36648652, grad/param norm = 1.6853e-01, time/batch = 0.6404s	
6065/26050 (epoch 11.641), train_loss = 1.20613161, grad/param norm = 1.5597e-01, time/batch = 0.6395s	
6066/26050 (epoch 11.643), train_loss = 1.12044178, grad/param norm = 1.5239e-01, time/batch = 0.6394s	
6067/26050 (epoch 11.645), train_loss = 1.30084484, grad/param norm = 1.8459e-01, time/batch = 0.6378s	
6068/26050 (epoch 11.647), train_loss = 1.22511459, grad/param norm = 1.7351e-01, time/batch = 0.6453s	
6069/26050 (epoch 11.649), train_loss = 1.29326423, grad/param norm = 1.9429e-01, time/batch = 0.6539s	
6070/26050 (epoch 11.651), train_loss = 1.19962582, grad/param norm = 1.7788e-01, time/batch = 0.6831s	
6071/26050 (epoch 11.653), train_loss = 1.26124260, grad/param norm = 1.7216e-01, time/batch = 0.6453s	
6072/26050 (epoch 11.655), train_loss = 1.17681269, grad/param norm = 1.6591e-01, time/batch = 0.6482s	
6073/26050 (epoch 11.656), train_loss = 1.12352762, grad/param norm = 1.6446e-01, time/batch = 0.6397s	
6074/26050 (epoch 11.658), train_loss = 1.47072204, grad/param norm = 1.8135e-01, time/batch = 0.6423s	
6075/26050 (epoch 11.660), train_loss = 1.14099083, grad/param norm = 1.7187e-01, time/batch = 0.6384s	
6076/26050 (epoch 11.662), train_loss = 1.14127616, grad/param norm = 1.5731e-01, time/batch = 0.6368s	
6077/26050 (epoch 11.664), train_loss = 1.23028736, grad/param norm = 1.7483e-01, time/batch = 0.6382s	
6078/26050 (epoch 11.666), train_loss = 1.26660383, grad/param norm = 1.8222e-01, time/batch = 0.6404s	
6079/26050 (epoch 11.668), train_loss = 1.05055485, grad/param norm = 1.6087e-01, time/batch = 0.6402s	
6080/26050 (epoch 11.670), train_loss = 1.41037692, grad/param norm = 1.8437e-01, time/batch = 0.6420s	
6081/26050 (epoch 11.672), train_loss = 1.19029199, grad/param norm = 1.6539e-01, time/batch = 0.6396s	
6082/26050 (epoch 11.674), train_loss = 1.14419914, grad/param norm = 1.7139e-01, time/batch = 0.6401s	
6083/26050 (epoch 11.676), train_loss = 1.28936962, grad/param norm = 1.6980e-01, time/batch = 0.6401s	
6084/26050 (epoch 11.678), train_loss = 1.39665313, grad/param norm = 1.7734e-01, time/batch = 0.6414s	
6085/26050 (epoch 11.679), train_loss = 1.48049736, grad/param norm = 1.9814e-01, time/batch = 0.6795s	
6086/26050 (epoch 11.681), train_loss = 1.27588885, grad/param norm = 1.7099e-01, time/batch = 0.6726s	
6087/26050 (epoch 11.683), train_loss = 1.16145637, grad/param norm = 2.0809e-01, time/batch = 0.6557s	
6088/26050 (epoch 11.685), train_loss = 1.19758723, grad/param norm = 1.5352e-01, time/batch = 0.6584s	
6089/26050 (epoch 11.687), train_loss = 1.06641138, grad/param norm = 1.5950e-01, time/batch = 0.6546s	
6090/26050 (epoch 11.689), train_loss = 1.23108203, grad/param norm = 1.7307e-01, time/batch = 0.6503s	
6091/26050 (epoch 11.691), train_loss = 0.98728654, grad/param norm = 1.5499e-01, time/batch = 0.6450s	
6092/26050 (epoch 11.693), train_loss = 1.16517505, grad/param norm = 1.7082e-01, time/batch = 0.6574s	
6093/26050 (epoch 11.695), train_loss = 1.26507884, grad/param norm = 1.7403e-01, time/batch = 0.6564s	
6094/26050 (epoch 11.697), train_loss = 1.14766463, grad/param norm = 1.7060e-01, time/batch = 0.6548s	
6095/26050 (epoch 11.699), train_loss = 1.32656269, grad/param norm = 1.8466e-01, time/batch = 0.6577s	
6096/26050 (epoch 11.701), train_loss = 1.09083969, grad/param norm = 1.5241e-01, time/batch = 0.6616s	
6097/26050 (epoch 11.702), train_loss = 1.45429331, grad/param norm = 1.8852e-01, time/batch = 0.6407s	
6098/26050 (epoch 11.704), train_loss = 1.29568212, grad/param norm = 1.7236e-01, time/batch = 0.6398s	
6099/26050 (epoch 11.706), train_loss = 1.30341217, grad/param norm = 1.9871e-01, time/batch = 0.6394s	
6100/26050 (epoch 11.708), train_loss = 1.33129741, grad/param norm = 1.7926e-01, time/batch = 0.6405s	
6101/26050 (epoch 11.710), train_loss = 1.31056028, grad/param norm = 1.7462e-01, time/batch = 0.6419s	
6102/26050 (epoch 11.712), train_loss = 1.38700079, grad/param norm = 1.7760e-01, time/batch = 0.6461s	
6103/26050 (epoch 11.714), train_loss = 1.10682773, grad/param norm = 1.7263e-01, time/batch = 0.6438s	
6104/26050 (epoch 11.716), train_loss = 1.53533618, grad/param norm = 2.1187e-01, time/batch = 0.6411s	
6105/26050 (epoch 11.718), train_loss = 1.37104726, grad/param norm = 1.8706e-01, time/batch = 0.6405s	
6106/26050 (epoch 11.720), train_loss = 1.18240368, grad/param norm = 1.6839e-01, time/batch = 0.6404s	
6107/26050 (epoch 11.722), train_loss = 1.13175586, grad/param norm = 1.7121e-01, time/batch = 0.6406s	
6108/26050 (epoch 11.724), train_loss = 1.13597664, grad/param norm = 1.7105e-01, time/batch = 0.6409s	
6109/26050 (epoch 11.726), train_loss = 1.37276663, grad/param norm = 1.7439e-01, time/batch = 0.6403s	
6110/26050 (epoch 11.727), train_loss = 1.31299304, grad/param norm = 1.7453e-01, time/batch = 0.6448s	
6111/26050 (epoch 11.729), train_loss = 1.31391785, grad/param norm = 1.7170e-01, time/batch = 0.6417s	
6112/26050 (epoch 11.731), train_loss = 1.28639591, grad/param norm = 1.5853e-01, time/batch = 0.6406s	
6113/26050 (epoch 11.733), train_loss = 1.21493362, grad/param norm = 1.9711e-01, time/batch = 0.6396s	
6114/26050 (epoch 11.735), train_loss = 1.44753466, grad/param norm = 1.8542e-01, time/batch = 0.6405s	
6115/26050 (epoch 11.737), train_loss = 1.24775633, grad/param norm = 1.7326e-01, time/batch = 0.6422s	
6116/26050 (epoch 11.739), train_loss = 1.30986693, grad/param norm = 1.6500e-01, time/batch = 0.6408s	
6117/26050 (epoch 11.741), train_loss = 1.16174643, grad/param norm = 1.6547e-01, time/batch = 0.6403s	
6118/26050 (epoch 11.743), train_loss = 1.33660151, grad/param norm = 2.2604e-01, time/batch = 0.6616s	
6119/26050 (epoch 11.745), train_loss = 1.13399317, grad/param norm = 1.6639e-01, time/batch = 0.6502s	
6120/26050 (epoch 11.747), train_loss = 1.14807831, grad/param norm = 1.6234e-01, time/batch = 0.6528s	
6121/26050 (epoch 11.749), train_loss = 1.39803902, grad/param norm = 1.8784e-01, time/batch = 0.6492s	
6122/26050 (epoch 11.750), train_loss = 1.25310864, grad/param norm = 1.5876e-01, time/batch = 0.6443s	
6123/26050 (epoch 11.752), train_loss = 1.24748477, grad/param norm = 1.8171e-01, time/batch = 0.6594s	
6124/26050 (epoch 11.754), train_loss = 1.27543688, grad/param norm = 1.7489e-01, time/batch = 0.6619s	
6125/26050 (epoch 11.756), train_loss = 1.28187451, grad/param norm = 1.8761e-01, time/batch = 0.6466s	
6126/26050 (epoch 11.758), train_loss = 1.27586479, grad/param norm = 1.7891e-01, time/batch = 0.6476s	
6127/26050 (epoch 11.760), train_loss = 1.37698203, grad/param norm = 1.7670e-01, time/batch = 0.6498s	
6128/26050 (epoch 11.762), train_loss = 1.16699028, grad/param norm = 1.5962e-01, time/batch = 0.6454s	
6129/26050 (epoch 11.764), train_loss = 1.34684229, grad/param norm = 1.9545e-01, time/batch = 0.6416s	
6130/26050 (epoch 11.766), train_loss = 1.35216582, grad/param norm = 1.9401e-01, time/batch = 0.6400s	
6131/26050 (epoch 11.768), train_loss = 1.12039673, grad/param norm = 1.5611e-01, time/batch = 0.6405s	
6132/26050 (epoch 11.770), train_loss = 1.24564856, grad/param norm = 1.8352e-01, time/batch = 0.6407s	
6133/26050 (epoch 11.772), train_loss = 1.23259356, grad/param norm = 1.6553e-01, time/batch = 0.6469s	
6134/26050 (epoch 11.774), train_loss = 1.11072762, grad/param norm = 1.7608e-01, time/batch = 0.6411s	
6135/26050 (epoch 11.775), train_loss = 0.95490100, grad/param norm = 1.5727e-01, time/batch = 0.6411s	
6136/26050 (epoch 11.777), train_loss = 1.15583758, grad/param norm = 1.6285e-01, time/batch = 0.6392s	
6137/26050 (epoch 11.779), train_loss = 1.23260217, grad/param norm = 1.8307e-01, time/batch = 0.6416s	
6138/26050 (epoch 11.781), train_loss = 1.19764583, grad/param norm = 1.6541e-01, time/batch = 0.6424s	
6139/26050 (epoch 11.783), train_loss = 1.15379438, grad/param norm = 1.5913e-01, time/batch = 0.6407s	
6140/26050 (epoch 11.785), train_loss = 1.20562642, grad/param norm = 1.7732e-01, time/batch = 0.6430s	
6141/26050 (epoch 11.787), train_loss = 1.17744448, grad/param norm = 1.6683e-01, time/batch = 0.6477s	
6142/26050 (epoch 11.789), train_loss = 1.20416299, grad/param norm = 1.8821e-01, time/batch = 0.6839s	
6143/26050 (epoch 11.791), train_loss = 1.23595086, grad/param norm = 1.6915e-01, time/batch = 0.6616s	
6144/26050 (epoch 11.793), train_loss = 1.22487171, grad/param norm = 1.8358e-01, time/batch = 0.6519s	
6145/26050 (epoch 11.795), train_loss = 1.06128119, grad/param norm = 1.4977e-01, time/batch = 0.6546s	
6146/26050 (epoch 11.797), train_loss = 1.17058652, grad/param norm = 1.7209e-01, time/batch = 0.6546s	
6147/26050 (epoch 11.798), train_loss = 1.11113381, grad/param norm = 1.6887e-01, time/batch = 0.6551s	
6148/26050 (epoch 11.800), train_loss = 1.08734025, grad/param norm = 1.4548e-01, time/batch = 0.6516s	
6149/26050 (epoch 11.802), train_loss = 1.21723102, grad/param norm = 1.8003e-01, time/batch = 0.6569s	
6150/26050 (epoch 11.804), train_loss = 1.20273953, grad/param norm = 1.6454e-01, time/batch = 0.6537s	
6151/26050 (epoch 11.806), train_loss = 1.33799791, grad/param norm = 1.8020e-01, time/batch = 0.6735s	
6152/26050 (epoch 11.808), train_loss = 1.20615830, grad/param norm = 1.6641e-01, time/batch = 0.6760s	
6153/26050 (epoch 11.810), train_loss = 1.17906486, grad/param norm = 1.6517e-01, time/batch = 0.6476s	
6154/26050 (epoch 11.812), train_loss = 1.12329116, grad/param norm = 1.8654e-01, time/batch = 0.6506s	
6155/26050 (epoch 11.814), train_loss = 1.10805284, grad/param norm = 1.7021e-01, time/batch = 0.6561s	
6156/26050 (epoch 11.816), train_loss = 1.33080309, grad/param norm = 1.8321e-01, time/batch = 0.6553s	
6157/26050 (epoch 11.818), train_loss = 1.39768007, grad/param norm = 2.1126e-01, time/batch = 0.6694s	
6158/26050 (epoch 11.820), train_loss = 1.26316951, grad/param norm = 1.8055e-01, time/batch = 0.6704s	
6159/26050 (epoch 11.821), train_loss = 1.40746209, grad/param norm = 2.0367e-01, time/batch = 0.6812s	
6160/26050 (epoch 11.823), train_loss = 1.43200709, grad/param norm = 1.8458e-01, time/batch = 0.6524s	
6161/26050 (epoch 11.825), train_loss = 1.22782781, grad/param norm = 2.0056e-01, time/batch = 0.6416s	
6162/26050 (epoch 11.827), train_loss = 1.27554353, grad/param norm = 1.8542e-01, time/batch = 0.6414s	
6163/26050 (epoch 11.829), train_loss = 1.30049648, grad/param norm = 1.8366e-01, time/batch = 0.6432s	
6164/26050 (epoch 11.831), train_loss = 1.37984717, grad/param norm = 1.7493e-01, time/batch = 0.6438s	
6165/26050 (epoch 11.833), train_loss = 1.45158613, grad/param norm = 1.7628e-01, time/batch = 0.6461s	
6166/26050 (epoch 11.835), train_loss = 1.47606697, grad/param norm = 1.9082e-01, time/batch = 0.6420s	
6167/26050 (epoch 11.837), train_loss = 1.21548567, grad/param norm = 1.7457e-01, time/batch = 0.6408s	
6168/26050 (epoch 11.839), train_loss = 1.31624009, grad/param norm = 1.9785e-01, time/batch = 0.6407s	
6169/26050 (epoch 11.841), train_loss = 1.37775816, grad/param norm = 1.7801e-01, time/batch = 0.6395s	
6170/26050 (epoch 11.843), train_loss = 1.28703779, grad/param norm = 1.8185e-01, time/batch = 0.6410s	
6171/26050 (epoch 11.845), train_loss = 1.17751525, grad/param norm = 1.6065e-01, time/batch = 0.6593s	
6172/26050 (epoch 11.846), train_loss = 1.38026090, grad/param norm = 1.7875e-01, time/batch = 0.6741s	
6173/26050 (epoch 11.848), train_loss = 1.20385561, grad/param norm = 1.6163e-01, time/batch = 0.6801s	
6174/26050 (epoch 11.850), train_loss = 1.19061333, grad/param norm = 1.7436e-01, time/batch = 0.6416s	
6175/26050 (epoch 11.852), train_loss = 1.22202077, grad/param norm = 1.7321e-01, time/batch = 0.6414s	
6176/26050 (epoch 11.854), train_loss = 1.24158591, grad/param norm = 1.6725e-01, time/batch = 0.6461s	
6177/26050 (epoch 11.856), train_loss = 1.19074269, grad/param norm = 1.9074e-01, time/batch = 0.6437s	
6178/26050 (epoch 11.858), train_loss = 1.12242299, grad/param norm = 1.7145e-01, time/batch = 0.6393s	
6179/26050 (epoch 11.860), train_loss = 1.29888239, grad/param norm = 1.8786e-01, time/batch = 0.6445s	
6180/26050 (epoch 11.862), train_loss = 1.26308289, grad/param norm = 1.7505e-01, time/batch = 0.6555s	
6181/26050 (epoch 11.864), train_loss = 1.25866989, grad/param norm = 1.8670e-01, time/batch = 0.6412s	
6182/26050 (epoch 11.866), train_loss = 1.17884386, grad/param norm = 1.5856e-01, time/batch = 0.6402s	
6183/26050 (epoch 11.868), train_loss = 1.34995582, grad/param norm = 1.9030e-01, time/batch = 0.6407s	
6184/26050 (epoch 11.869), train_loss = 1.13184598, grad/param norm = 1.5986e-01, time/batch = 0.6414s	
6185/26050 (epoch 11.871), train_loss = 1.08028017, grad/param norm = 1.6020e-01, time/batch = 0.6401s	
6186/26050 (epoch 11.873), train_loss = 1.30336575, grad/param norm = 1.7167e-01, time/batch = 0.6394s	
6187/26050 (epoch 11.875), train_loss = 1.24466569, grad/param norm = 1.8043e-01, time/batch = 0.6466s	
6188/26050 (epoch 11.877), train_loss = 1.12157707, grad/param norm = 1.7209e-01, time/batch = 0.6829s	
6189/26050 (epoch 11.879), train_loss = 1.24857012, grad/param norm = 1.6157e-01, time/batch = 0.6541s	
6190/26050 (epoch 11.881), train_loss = 1.38128072, grad/param norm = 1.7529e-01, time/batch = 0.6387s	
6191/26050 (epoch 11.883), train_loss = 1.28114851, grad/param norm = 1.7606e-01, time/batch = 0.6409s	
6192/26050 (epoch 11.885), train_loss = 0.97597470, grad/param norm = 1.5028e-01, time/batch = 0.6411s	
6193/26050 (epoch 11.887), train_loss = 1.28388301, grad/param norm = 1.7784e-01, time/batch = 0.6389s	
6194/26050 (epoch 11.889), train_loss = 1.18555047, grad/param norm = 1.6096e-01, time/batch = 0.6399s	
6195/26050 (epoch 11.891), train_loss = 1.00100145, grad/param norm = 1.5197e-01, time/batch = 0.6441s	
6196/26050 (epoch 11.893), train_loss = 1.00244818, grad/param norm = 1.5579e-01, time/batch = 0.6405s	
6197/26050 (epoch 11.894), train_loss = 1.19294799, grad/param norm = 1.6337e-01, time/batch = 0.6398s	
6198/26050 (epoch 11.896), train_loss = 1.36442521, grad/param norm = 1.8113e-01, time/batch = 0.6392s	
6199/26050 (epoch 11.898), train_loss = 1.18411904, grad/param norm = 1.8818e-01, time/batch = 0.6396s	
6200/26050 (epoch 11.900), train_loss = 1.37241285, grad/param norm = 1.7966e-01, time/batch = 0.6394s	
6201/26050 (epoch 11.902), train_loss = 1.23522901, grad/param norm = 1.7731e-01, time/batch = 0.6419s	
6202/26050 (epoch 11.904), train_loss = 1.19767789, grad/param norm = 1.6070e-01, time/batch = 0.6413s	
6203/26050 (epoch 11.906), train_loss = 1.22050300, grad/param norm = 1.7182e-01, time/batch = 0.6698s	
6204/26050 (epoch 11.908), train_loss = 1.20695257, grad/param norm = 1.7036e-01, time/batch = 0.6725s	
6205/26050 (epoch 11.910), train_loss = 1.13679100, grad/param norm = 1.4977e-01, time/batch = 0.6393s	
6206/26050 (epoch 11.912), train_loss = 1.48917937, grad/param norm = 1.9083e-01, time/batch = 0.6392s	
6207/26050 (epoch 11.914), train_loss = 1.64330275, grad/param norm = 2.0328e-01, time/batch = 0.6451s	
6208/26050 (epoch 11.916), train_loss = 1.37454131, grad/param norm = 1.9174e-01, time/batch = 0.6450s	
6209/26050 (epoch 11.917), train_loss = 1.28021211, grad/param norm = 2.0048e-01, time/batch = 0.6437s	
6210/26050 (epoch 11.919), train_loss = 1.35189972, grad/param norm = 1.9362e-01, time/batch = 0.6590s	
6211/26050 (epoch 11.921), train_loss = 1.18673992, grad/param norm = 1.8791e-01, time/batch = 0.6597s	
6212/26050 (epoch 11.923), train_loss = 1.25250812, grad/param norm = 1.8712e-01, time/batch = 0.6543s	
6213/26050 (epoch 11.925), train_loss = 1.22985920, grad/param norm = 1.6929e-01, time/batch = 0.6447s	
6214/26050 (epoch 11.927), train_loss = 1.11578060, grad/param norm = 1.5309e-01, time/batch = 0.6551s	
6215/26050 (epoch 11.929), train_loss = 1.15327473, grad/param norm = 1.7197e-01, time/batch = 0.6436s	
6216/26050 (epoch 11.931), train_loss = 1.47695128, grad/param norm = 2.0842e-01, time/batch = 0.6446s	
6217/26050 (epoch 11.933), train_loss = 1.21046364, grad/param norm = 1.8547e-01, time/batch = 0.6462s	
6218/26050 (epoch 11.935), train_loss = 1.16637947, grad/param norm = 1.5697e-01, time/batch = 0.6597s	
6219/26050 (epoch 11.937), train_loss = 1.29651298, grad/param norm = 1.7099e-01, time/batch = 0.6836s	
6220/26050 (epoch 11.939), train_loss = 1.12348672, grad/param norm = 1.4798e-01, time/batch = 0.6448s	
6221/26050 (epoch 11.940), train_loss = 1.25322132, grad/param norm = 1.6823e-01, time/batch = 0.6421s	
6222/26050 (epoch 11.942), train_loss = 1.28293256, grad/param norm = 1.9151e-01, time/batch = 0.6561s	
6223/26050 (epoch 11.944), train_loss = 1.21001596, grad/param norm = 1.7403e-01, time/batch = 0.6516s	
6224/26050 (epoch 11.946), train_loss = 1.40333239, grad/param norm = 1.8338e-01, time/batch = 0.6414s	
6225/26050 (epoch 11.948), train_loss = 1.08134406, grad/param norm = 2.9760e-01, time/batch = 0.6454s	
6226/26050 (epoch 11.950), train_loss = 1.22923183, grad/param norm = 1.7896e-01, time/batch = 0.6533s	
6227/26050 (epoch 11.952), train_loss = 1.38159146, grad/param norm = 1.9412e-01, time/batch = 0.6408s	
6228/26050 (epoch 11.954), train_loss = 1.35636237, grad/param norm = 1.8121e-01, time/batch = 0.6397s	
6229/26050 (epoch 11.956), train_loss = 1.26607042, grad/param norm = 1.8714e-01, time/batch = 0.6404s	
6230/26050 (epoch 11.958), train_loss = 1.20491869, grad/param norm = 1.7139e-01, time/batch = 0.6405s	
6231/26050 (epoch 11.960), train_loss = 1.23624698, grad/param norm = 1.7464e-01, time/batch = 0.6405s	
6232/26050 (epoch 11.962), train_loss = 1.16726682, grad/param norm = 1.6980e-01, time/batch = 0.6430s	
6233/26050 (epoch 11.964), train_loss = 1.23493322, grad/param norm = 1.7740e-01, time/batch = 0.6432s	
6234/26050 (epoch 11.965), train_loss = 1.13741580, grad/param norm = 1.7572e-01, time/batch = 0.6832s	
6235/26050 (epoch 11.967), train_loss = 1.55986635, grad/param norm = 1.7812e-01, time/batch = 0.6590s	
6236/26050 (epoch 11.969), train_loss = 1.21786858, grad/param norm = 1.6835e-01, time/batch = 0.6403s	
6237/26050 (epoch 11.971), train_loss = 1.14670102, grad/param norm = 1.5462e-01, time/batch = 0.6408s	
6238/26050 (epoch 11.973), train_loss = 1.21014201, grad/param norm = 1.8913e-01, time/batch = 0.6400s	
6239/26050 (epoch 11.975), train_loss = 1.30446191, grad/param norm = 1.6188e-01, time/batch = 0.6433s	
6240/26050 (epoch 11.977), train_loss = 1.27039282, grad/param norm = 1.6461e-01, time/batch = 0.6440s	
6241/26050 (epoch 11.979), train_loss = 1.06398331, grad/param norm = 1.6590e-01, time/batch = 0.6463s	
6242/26050 (epoch 11.981), train_loss = 1.36554711, grad/param norm = 1.6772e-01, time/batch = 0.6428s	
6243/26050 (epoch 11.983), train_loss = 1.36057272, grad/param norm = 1.7535e-01, time/batch = 0.6407s	
6244/26050 (epoch 11.985), train_loss = 1.27069887, grad/param norm = 1.7749e-01, time/batch = 0.6418s	
6245/26050 (epoch 11.987), train_loss = 1.40227303, grad/param norm = 1.9578e-01, time/batch = 0.6411s	
6246/26050 (epoch 11.988), train_loss = 1.34759144, grad/param norm = 1.7338e-01, time/batch = 0.6401s	
6247/26050 (epoch 11.990), train_loss = 1.14527137, grad/param norm = 1.5533e-01, time/batch = 0.6428s	
6248/26050 (epoch 11.992), train_loss = 1.39420757, grad/param norm = 1.8208e-01, time/batch = 0.6449s	
6249/26050 (epoch 11.994), train_loss = 1.26813084, grad/param norm = 1.7853e-01, time/batch = 0.6760s	
6250/26050 (epoch 11.996), train_loss = 1.20206881, grad/param norm = 1.8205e-01, time/batch = 0.6837s	
6251/26050 (epoch 11.998), train_loss = 1.25831019, grad/param norm = 1.7499e-01, time/batch = 0.6788s	
decayed learning rate by a factor 0.97 to 0.001825346	
6252/26050 (epoch 12.000), train_loss = 1.20335774, grad/param norm = 1.7803e-01, time/batch = 0.6717s	
6253/26050 (epoch 12.002), train_loss = 1.32127998, grad/param norm = 1.9152e-01, time/batch = 0.6644s	
6254/26050 (epoch 12.004), train_loss = 1.13779341, grad/param norm = 1.7291e-01, time/batch = 0.6720s	
6255/26050 (epoch 12.006), train_loss = 1.16079606, grad/param norm = 1.6566e-01, time/batch = 0.6646s	
6256/26050 (epoch 12.008), train_loss = 1.14072047, grad/param norm = 1.7015e-01, time/batch = 0.6735s	
6257/26050 (epoch 12.010), train_loss = 1.17360092, grad/param norm = 1.6016e-01, time/batch = 0.6722s	
6258/26050 (epoch 12.012), train_loss = 1.26282289, grad/param norm = 1.7442e-01, time/batch = 0.6633s	
6259/26050 (epoch 12.013), train_loss = 1.65098977, grad/param norm = 1.9903e-01, time/batch = 0.6627s	
6260/26050 (epoch 12.015), train_loss = 1.15018682, grad/param norm = 1.6100e-01, time/batch = 0.6830s	
6261/26050 (epoch 12.017), train_loss = 1.26301058, grad/param norm = 1.6454e-01, time/batch = 0.6640s	
6262/26050 (epoch 12.019), train_loss = 1.03733405, grad/param norm = 1.4023e-01, time/batch = 0.6615s	
6263/26050 (epoch 12.021), train_loss = 1.32298322, grad/param norm = 1.7540e-01, time/batch = 0.6600s	
6264/26050 (epoch 12.023), train_loss = 1.07996595, grad/param norm = 1.6674e-01, time/batch = 0.6592s	
6265/26050 (epoch 12.025), train_loss = 1.20392812, grad/param norm = 1.6151e-01, time/batch = 0.6597s	
6266/26050 (epoch 12.027), train_loss = 1.00573890, grad/param norm = 1.6343e-01, time/batch = 0.6419s	
6267/26050 (epoch 12.029), train_loss = 1.21810077, grad/param norm = 1.6567e-01, time/batch = 0.6395s	
6268/26050 (epoch 12.031), train_loss = 1.37959901, grad/param norm = 1.9616e-01, time/batch = 0.6423s	
6269/26050 (epoch 12.033), train_loss = 1.27749694, grad/param norm = 1.7119e-01, time/batch = 0.6422s	
6270/26050 (epoch 12.035), train_loss = 1.31735658, grad/param norm = 1.6139e-01, time/batch = 0.6396s	
6271/26050 (epoch 12.036), train_loss = 1.13232065, grad/param norm = 1.8396e-01, time/batch = 0.6445s	
6272/26050 (epoch 12.038), train_loss = 1.06252314, grad/param norm = 1.6501e-01, time/batch = 0.6489s	
6273/26050 (epoch 12.040), train_loss = 1.27704265, grad/param norm = 1.7955e-01, time/batch = 0.6394s	
6274/26050 (epoch 12.042), train_loss = 1.08943113, grad/param norm = 1.7915e-01, time/batch = 0.6407s	
6275/26050 (epoch 12.044), train_loss = 1.32460023, grad/param norm = 1.7310e-01, time/batch = 0.6827s	
6276/26050 (epoch 12.046), train_loss = 1.02967209, grad/param norm = 1.6816e-01, time/batch = 0.6612s	
6277/26050 (epoch 12.048), train_loss = 1.26949721, grad/param norm = 1.7583e-01, time/batch = 0.6407s	
6278/26050 (epoch 12.050), train_loss = 1.12675035, grad/param norm = 1.7955e-01, time/batch = 0.6413s	
6279/26050 (epoch 12.052), train_loss = 1.20479637, grad/param norm = 1.6994e-01, time/batch = 0.6425s	
6280/26050 (epoch 12.054), train_loss = 1.06512431, grad/param norm = 1.5717e-01, time/batch = 0.6409s	
6281/26050 (epoch 12.056), train_loss = 0.98307173, grad/param norm = 1.4233e-01, time/batch = 0.6421s	
6282/26050 (epoch 12.058), train_loss = 1.15268166, grad/param norm = 1.6048e-01, time/batch = 0.6409s	
6283/26050 (epoch 12.060), train_loss = 1.25381867, grad/param norm = 1.6434e-01, time/batch = 0.6457s	
6284/26050 (epoch 12.061), train_loss = 1.12751950, grad/param norm = 1.6687e-01, time/batch = 0.6515s	
6285/26050 (epoch 12.063), train_loss = 1.23643645, grad/param norm = 1.6842e-01, time/batch = 0.6462s	
6286/26050 (epoch 12.065), train_loss = 1.03720158, grad/param norm = 1.6066e-01, time/batch = 0.6422s	
6287/26050 (epoch 12.067), train_loss = 1.27738192, grad/param norm = 1.7890e-01, time/batch = 0.6436s	
6288/26050 (epoch 12.069), train_loss = 1.27467672, grad/param norm = 1.6087e-01, time/batch = 0.6409s	
6289/26050 (epoch 12.071), train_loss = 1.28365227, grad/param norm = 1.7139e-01, time/batch = 0.6408s	
6290/26050 (epoch 12.073), train_loss = 1.44358789, grad/param norm = 1.7798e-01, time/batch = 0.6646s	
6291/26050 (epoch 12.075), train_loss = 1.12925217, grad/param norm = 1.5763e-01, time/batch = 0.6777s	
6292/26050 (epoch 12.077), train_loss = 1.12348139, grad/param norm = 1.6245e-01, time/batch = 0.6393s	
6293/26050 (epoch 12.079), train_loss = 1.27287686, grad/param norm = 1.8322e-01, time/batch = 0.6397s	
6294/26050 (epoch 12.081), train_loss = 1.17309793, grad/param norm = 1.6495e-01, time/batch = 0.6413s	
6295/26050 (epoch 12.083), train_loss = 1.31054767, grad/param norm = 1.7371e-01, time/batch = 0.6412s	
6296/26050 (epoch 12.084), train_loss = 1.32055789, grad/param norm = 1.8540e-01, time/batch = 0.6405s	
6297/26050 (epoch 12.086), train_loss = 1.37106633, grad/param norm = 1.8636e-01, time/batch = 0.6401s	
6298/26050 (epoch 12.088), train_loss = 1.11670357, grad/param norm = 1.5840e-01, time/batch = 0.6408s	
6299/26050 (epoch 12.090), train_loss = 1.29607444, grad/param norm = 1.8254e-01, time/batch = 0.6411s	
6300/26050 (epoch 12.092), train_loss = 1.25818208, grad/param norm = 1.7403e-01, time/batch = 0.6409s	
6301/26050 (epoch 12.094), train_loss = 1.19468195, grad/param norm = 1.7475e-01, time/batch = 0.6447s	
6302/26050 (epoch 12.096), train_loss = 1.18106091, grad/param norm = 1.6507e-01, time/batch = 0.6667s	
6303/26050 (epoch 12.098), train_loss = 1.19870727, grad/param norm = 1.7085e-01, time/batch = 0.6426s	
6304/26050 (epoch 12.100), train_loss = 1.11647865, grad/param norm = 1.7671e-01, time/batch = 0.6535s	
6305/26050 (epoch 12.102), train_loss = 1.23593995, grad/param norm = 1.6730e-01, time/batch = 0.6660s	
6306/26050 (epoch 12.104), train_loss = 1.23205617, grad/param norm = 1.7367e-01, time/batch = 0.6833s	
6307/26050 (epoch 12.106), train_loss = 1.20727573, grad/param norm = 1.8207e-01, time/batch = 0.6507s	
6308/26050 (epoch 12.107), train_loss = 1.00720851, grad/param norm = 1.6413e-01, time/batch = 0.6593s	
6309/26050 (epoch 12.109), train_loss = 1.15014412, grad/param norm = 1.7423e-01, time/batch = 0.6836s	
6310/26050 (epoch 12.111), train_loss = 1.41847323, grad/param norm = 1.8992e-01, time/batch = 0.6827s	
6311/26050 (epoch 12.113), train_loss = 1.16206637, grad/param norm = 1.6601e-01, time/batch = 0.6699s	
6312/26050 (epoch 12.115), train_loss = 1.30509848, grad/param norm = 1.7713e-01, time/batch = 0.6405s	
6313/26050 (epoch 12.117), train_loss = 1.27079731, grad/param norm = 1.7473e-01, time/batch = 0.6396s	
6314/26050 (epoch 12.119), train_loss = 1.00107654, grad/param norm = 1.5106e-01, time/batch = 0.6473s	
6315/26050 (epoch 12.121), train_loss = 1.26957717, grad/param norm = 1.6830e-01, time/batch = 0.6406s	
6316/26050 (epoch 12.123), train_loss = 1.11977091, grad/param norm = 1.7563e-01, time/batch = 0.6393s	
6317/26050 (epoch 12.125), train_loss = 1.03799921, grad/param norm = 1.5406e-01, time/batch = 0.6404s	
6318/26050 (epoch 12.127), train_loss = 0.98017663, grad/param norm = 1.5549e-01, time/batch = 0.6660s	
6319/26050 (epoch 12.129), train_loss = 1.02700252, grad/param norm = 1.4987e-01, time/batch = 0.6551s	
6320/26050 (epoch 12.131), train_loss = 1.19386324, grad/param norm = 1.6892e-01, time/batch = 0.6443s	
6321/26050 (epoch 12.132), train_loss = 1.17816191, grad/param norm = 1.6678e-01, time/batch = 0.6846s	
6322/26050 (epoch 12.134), train_loss = 1.18522065, grad/param norm = 1.7555e-01, time/batch = 0.6559s	
6323/26050 (epoch 12.136), train_loss = 1.21367540, grad/param norm = 1.7148e-01, time/batch = 0.6449s	
6324/26050 (epoch 12.138), train_loss = 1.01954231, grad/param norm = 1.7192e-01, time/batch = 0.6451s	
6325/26050 (epoch 12.140), train_loss = 1.07161389, grad/param norm = 1.6768e-01, time/batch = 0.6417s	
6326/26050 (epoch 12.142), train_loss = 1.12104877, grad/param norm = 1.6866e-01, time/batch = 0.6549s	
6327/26050 (epoch 12.144), train_loss = 1.02950226, grad/param norm = 1.5770e-01, time/batch = 0.6549s	
6328/26050 (epoch 12.146), train_loss = 0.95088762, grad/param norm = 1.6316e-01, time/batch = 0.6575s	
6329/26050 (epoch 12.148), train_loss = 0.96344967, grad/param norm = 1.3833e-01, time/batch = 0.6442s	
6330/26050 (epoch 12.150), train_loss = 1.19140072, grad/param norm = 1.8636e-01, time/batch = 0.6427s	
6331/26050 (epoch 12.152), train_loss = 1.43795400, grad/param norm = 2.0974e-01, time/batch = 0.6546s	
6332/26050 (epoch 12.154), train_loss = 0.99188185, grad/param norm = 1.6129e-01, time/batch = 0.6548s	
6333/26050 (epoch 12.155), train_loss = 1.02616234, grad/param norm = 1.5845e-01, time/batch = 0.6423s	
6334/26050 (epoch 12.157), train_loss = 1.16358974, grad/param norm = 1.8544e-01, time/batch = 0.6515s	
6335/26050 (epoch 12.159), train_loss = 1.17514339, grad/param norm = 1.7419e-01, time/batch = 0.6419s	
6336/26050 (epoch 12.161), train_loss = 1.32204636, grad/param norm = 1.8902e-01, time/batch = 0.6750s	
6337/26050 (epoch 12.163), train_loss = 1.02979108, grad/param norm = 1.6289e-01, time/batch = 0.6697s	
6338/26050 (epoch 12.165), train_loss = 0.91934738, grad/param norm = 1.4977e-01, time/batch = 0.6427s	
6339/26050 (epoch 12.167), train_loss = 1.30508833, grad/param norm = 1.8726e-01, time/batch = 0.6431s	
6340/26050 (epoch 12.169), train_loss = 1.25920503, grad/param norm = 1.6788e-01, time/batch = 0.6418s	
6341/26050 (epoch 12.171), train_loss = 0.98936722, grad/param norm = 1.4391e-01, time/batch = 0.6429s	
6342/26050 (epoch 12.173), train_loss = 1.14123731, grad/param norm = 1.8230e-01, time/batch = 0.6405s	
6343/26050 (epoch 12.175), train_loss = 1.20988988, grad/param norm = 1.7071e-01, time/batch = 0.6416s	
6344/26050 (epoch 12.177), train_loss = 1.30861198, grad/param norm = 1.6982e-01, time/batch = 0.6428s	
6345/26050 (epoch 12.179), train_loss = 0.94425880, grad/param norm = 1.5066e-01, time/batch = 0.6411s	
6346/26050 (epoch 12.180), train_loss = 1.45499292, grad/param norm = 1.7458e-01, time/batch = 0.6421s	
6347/26050 (epoch 12.182), train_loss = 1.46424023, grad/param norm = 1.9888e-01, time/batch = 0.6413s	
6348/26050 (epoch 12.184), train_loss = 1.21698838, grad/param norm = 1.6311e-01, time/batch = 0.6484s	
6349/26050 (epoch 12.186), train_loss = 0.99609354, grad/param norm = 1.4921e-01, time/batch = 0.6539s	
6350/26050 (epoch 12.188), train_loss = 1.20119498, grad/param norm = 1.6311e-01, time/batch = 0.6487s	
6351/26050 (epoch 12.190), train_loss = 1.25292584, grad/param norm = 1.7439e-01, time/batch = 0.6650s	
6352/26050 (epoch 12.192), train_loss = 1.24646993, grad/param norm = 1.7249e-01, time/batch = 0.6834s	
6353/26050 (epoch 12.194), train_loss = 1.23600702, grad/param norm = 1.6824e-01, time/batch = 0.6414s	
6354/26050 (epoch 12.196), train_loss = 1.30302815, grad/param norm = 1.8834e-01, time/batch = 0.6432s	
6355/26050 (epoch 12.198), train_loss = 1.12563566, grad/param norm = 1.6190e-01, time/batch = 0.6577s	
6356/26050 (epoch 12.200), train_loss = 1.10882767, grad/param norm = 1.6704e-01, time/batch = 0.6442s	
6357/26050 (epoch 12.202), train_loss = 1.15205708, grad/param norm = 1.7458e-01, time/batch = 0.6392s	
6358/26050 (epoch 12.203), train_loss = 1.30048231, grad/param norm = 1.7885e-01, time/batch = 0.6393s	
6359/26050 (epoch 12.205), train_loss = 1.11451496, grad/param norm = 1.6486e-01, time/batch = 0.6397s	
6360/26050 (epoch 12.207), train_loss = 1.16735031, grad/param norm = 1.6249e-01, time/batch = 0.6428s	
6361/26050 (epoch 12.209), train_loss = 1.19502172, grad/param norm = 1.6612e-01, time/batch = 0.6420s	
6362/26050 (epoch 12.211), train_loss = 1.03767340, grad/param norm = 1.6722e-01, time/batch = 0.6407s	
6363/26050 (epoch 12.213), train_loss = 1.25463791, grad/param norm = 1.7842e-01, time/batch = 0.6432s	
6364/26050 (epoch 12.215), train_loss = 1.20215155, grad/param norm = 1.8085e-01, time/batch = 0.6463s	
6365/26050 (epoch 12.217), train_loss = 1.17937216, grad/param norm = 1.6554e-01, time/batch = 0.6392s	
6366/26050 (epoch 12.219), train_loss = 1.14335229, grad/param norm = 1.7930e-01, time/batch = 0.6447s	
6367/26050 (epoch 12.221), train_loss = 1.06857509, grad/param norm = 1.5181e-01, time/batch = 0.6611s	
6368/26050 (epoch 12.223), train_loss = 1.22278348, grad/param norm = 1.6645e-01, time/batch = 0.6404s	
6369/26050 (epoch 12.225), train_loss = 1.10178431, grad/param norm = 1.7859e-01, time/batch = 0.6403s	
6370/26050 (epoch 12.226), train_loss = 1.29788460, grad/param norm = 1.8036e-01, time/batch = 0.6433s	
6371/26050 (epoch 12.228), train_loss = 1.34543136, grad/param norm = 1.8112e-01, time/batch = 0.6492s	
6372/26050 (epoch 12.230), train_loss = 1.24193965, grad/param norm = 1.6715e-01, time/batch = 0.6438s	
6373/26050 (epoch 12.232), train_loss = 1.31648721, grad/param norm = 1.8348e-01, time/batch = 0.6410s	
6374/26050 (epoch 12.234), train_loss = 1.04609901, grad/param norm = 1.6342e-01, time/batch = 0.6402s	
6375/26050 (epoch 12.236), train_loss = 1.29761276, grad/param norm = 1.8209e-01, time/batch = 0.6413s	
6376/26050 (epoch 12.238), train_loss = 1.02557240, grad/param norm = 1.6532e-01, time/batch = 0.6436s	
6377/26050 (epoch 12.240), train_loss = 1.17356724, grad/param norm = 1.7842e-01, time/batch = 0.6414s	
6378/26050 (epoch 12.242), train_loss = 1.20194844, grad/param norm = 1.5681e-01, time/batch = 0.6404s	
6379/26050 (epoch 12.244), train_loss = 1.23362965, grad/param norm = 1.9033e-01, time/batch = 0.6440s	
6380/26050 (epoch 12.246), train_loss = 1.11739889, grad/param norm = 1.5798e-01, time/batch = 0.6451s	
6381/26050 (epoch 12.248), train_loss = 1.21774855, grad/param norm = 1.6594e-01, time/batch = 0.6398s	
6382/26050 (epoch 12.250), train_loss = 1.19874554, grad/param norm = 1.8633e-01, time/batch = 0.6658s	
6383/26050 (epoch 12.251), train_loss = 1.12258709, grad/param norm = 1.6413e-01, time/batch = 0.6766s	
6384/26050 (epoch 12.253), train_loss = 1.04472576, grad/param norm = 1.6525e-01, time/batch = 0.6409s	
6385/26050 (epoch 12.255), train_loss = 1.41193386, grad/param norm = 1.7640e-01, time/batch = 0.6397s	
6386/26050 (epoch 12.257), train_loss = 1.20817317, grad/param norm = 1.9115e-01, time/batch = 0.6403s	
6387/26050 (epoch 12.259), train_loss = 1.34339868, grad/param norm = 1.7048e-01, time/batch = 0.6427s	
6388/26050 (epoch 12.261), train_loss = 1.10261174, grad/param norm = 1.8165e-01, time/batch = 0.6396s	
6389/26050 (epoch 12.263), train_loss = 1.22284438, grad/param norm = 1.7318e-01, time/batch = 0.6424s	
6390/26050 (epoch 12.265), train_loss = 1.38471827, grad/param norm = 1.8054e-01, time/batch = 0.6389s	
6391/26050 (epoch 12.267), train_loss = 1.29577046, grad/param norm = 1.7117e-01, time/batch = 0.6401s	
6392/26050 (epoch 12.269), train_loss = 1.39800148, grad/param norm = 1.9862e-01, time/batch = 0.6410s	
6393/26050 (epoch 12.271), train_loss = 1.26508302, grad/param norm = 1.8172e-01, time/batch = 0.6466s	
6394/26050 (epoch 12.273), train_loss = 1.17083346, grad/param norm = 1.8476e-01, time/batch = 0.6629s	
6395/26050 (epoch 12.274), train_loss = 1.16883858, grad/param norm = 1.7562e-01, time/batch = 0.6416s	
6396/26050 (epoch 12.276), train_loss = 1.13433468, grad/param norm = 1.7884e-01, time/batch = 0.6617s	
6397/26050 (epoch 12.278), train_loss = 1.33372443, grad/param norm = 1.8103e-01, time/batch = 0.6553s	
6398/26050 (epoch 12.280), train_loss = 1.19266706, grad/param norm = 1.6746e-01, time/batch = 0.6840s	
6399/26050 (epoch 12.282), train_loss = 1.25012629, grad/param norm = 1.8247e-01, time/batch = 0.6548s	
6400/26050 (epoch 12.284), train_loss = 1.12907205, grad/param norm = 1.7605e-01, time/batch = 0.6497s	
6401/26050 (epoch 12.286), train_loss = 1.21015414, grad/param norm = 1.7396e-01, time/batch = 0.6495s	
6402/26050 (epoch 12.288), train_loss = 1.03580013, grad/param norm = 1.5966e-01, time/batch = 0.6405s	
6403/26050 (epoch 12.290), train_loss = 1.18259084, grad/param norm = 1.7454e-01, time/batch = 0.6404s	
6404/26050 (epoch 12.292), train_loss = 1.11071213, grad/param norm = 1.6465e-01, time/batch = 0.6392s	
6405/26050 (epoch 12.294), train_loss = 1.23808496, grad/param norm = 1.8576e-01, time/batch = 0.6382s	
6406/26050 (epoch 12.296), train_loss = 1.33295436, grad/param norm = 1.7393e-01, time/batch = 0.6416s	
6407/26050 (epoch 12.298), train_loss = 1.20426648, grad/param norm = 1.6849e-01, time/batch = 0.6392s	
6408/26050 (epoch 12.299), train_loss = 0.95734714, grad/param norm = 1.4550e-01, time/batch = 0.6387s	
6409/26050 (epoch 12.301), train_loss = 1.12055789, grad/param norm = 1.7548e-01, time/batch = 0.6383s	
6410/26050 (epoch 12.303), train_loss = 1.23874376, grad/param norm = 1.7893e-01, time/batch = 0.6448s	
6411/26050 (epoch 12.305), train_loss = 1.04287548, grad/param norm = 1.6668e-01, time/batch = 0.6393s	
6412/26050 (epoch 12.307), train_loss = 1.11159491, grad/param norm = 1.7127e-01, time/batch = 0.6385s	
6413/26050 (epoch 12.309), train_loss = 1.17135159, grad/param norm = 1.7577e-01, time/batch = 0.6758s	
6414/26050 (epoch 12.311), train_loss = 1.34301628, grad/param norm = 1.8249e-01, time/batch = 0.6663s	
6415/26050 (epoch 12.313), train_loss = 1.20121632, grad/param norm = 1.9616e-01, time/batch = 0.6374s	
6416/26050 (epoch 12.315), train_loss = 1.31436256, grad/param norm = 1.8359e-01, time/batch = 0.6422s	
6417/26050 (epoch 12.317), train_loss = 1.15997896, grad/param norm = 1.6373e-01, time/batch = 0.6400s	
6418/26050 (epoch 12.319), train_loss = 1.15188368, grad/param norm = 1.8340e-01, time/batch = 0.6397s	
6419/26050 (epoch 12.321), train_loss = 1.15821455, grad/param norm = 1.7931e-01, time/batch = 0.6392s	
6420/26050 (epoch 12.322), train_loss = 1.22474853, grad/param norm = 1.6915e-01, time/batch = 0.6399s	
6421/26050 (epoch 12.324), train_loss = 1.02724000, grad/param norm = 1.7597e-01, time/batch = 0.6405s	
6422/26050 (epoch 12.326), train_loss = 1.35785479, grad/param norm = 1.8252e-01, time/batch = 0.6389s	
6423/26050 (epoch 12.328), train_loss = 1.25687722, grad/param norm = 1.6839e-01, time/batch = 0.6432s	
6424/26050 (epoch 12.330), train_loss = 1.09542692, grad/param norm = 1.6801e-01, time/batch = 0.6428s	
6425/26050 (epoch 12.332), train_loss = 1.28939641, grad/param norm = 1.8529e-01, time/batch = 0.6452s	
6426/26050 (epoch 12.334), train_loss = 1.17057768, grad/param norm = 1.7655e-01, time/batch = 0.6387s	
6427/26050 (epoch 12.336), train_loss = 1.11034599, grad/param norm = 1.6113e-01, time/batch = 0.6381s	
6428/26050 (epoch 12.338), train_loss = 1.07329603, grad/param norm = 1.5790e-01, time/batch = 0.6546s	
6429/26050 (epoch 12.340), train_loss = 1.31148486, grad/param norm = 1.8413e-01, time/batch = 0.6827s	
6430/26050 (epoch 12.342), train_loss = 1.35771702, grad/param norm = 1.8468e-01, time/batch = 0.6439s	
6431/26050 (epoch 12.344), train_loss = 1.19359321, grad/param norm = 1.7810e-01, time/batch = 0.6409s	
6432/26050 (epoch 12.345), train_loss = 1.17551761, grad/param norm = 1.7559e-01, time/batch = 0.6416s	
6433/26050 (epoch 12.347), train_loss = 1.29304400, grad/param norm = 1.8696e-01, time/batch = 0.6415s	
6434/26050 (epoch 12.349), train_loss = 1.24681457, grad/param norm = 1.7188e-01, time/batch = 0.6399s	
6435/26050 (epoch 12.351), train_loss = 1.22270853, grad/param norm = 1.8118e-01, time/batch = 0.6405s	
6436/26050 (epoch 12.353), train_loss = 1.16841497, grad/param norm = 1.8212e-01, time/batch = 0.6398s	
6437/26050 (epoch 12.355), train_loss = 1.27583074, grad/param norm = 1.8464e-01, time/batch = 0.6404s	
6438/26050 (epoch 12.357), train_loss = 1.06082261, grad/param norm = 1.5310e-01, time/batch = 0.6392s	
6439/26050 (epoch 12.359), train_loss = 1.28254920, grad/param norm = 1.6970e-01, time/batch = 0.6392s	
6440/26050 (epoch 12.361), train_loss = 1.13481358, grad/param norm = 1.6720e-01, time/batch = 0.6432s	
6441/26050 (epoch 12.363), train_loss = 1.25041154, grad/param norm = 1.5986e-01, time/batch = 0.6422s	
6442/26050 (epoch 12.365), train_loss = 1.15865035, grad/param norm = 1.5261e-01, time/batch = 0.6385s	
6443/26050 (epoch 12.367), train_loss = 1.20542986, grad/param norm = 1.6748e-01, time/batch = 0.6397s	
6444/26050 (epoch 12.369), train_loss = 1.17926458, grad/param norm = 1.5575e-01, time/batch = 0.6385s	
6445/26050 (epoch 12.370), train_loss = 1.08857953, grad/param norm = 1.5142e-01, time/batch = 0.6389s	
6446/26050 (epoch 12.372), train_loss = 1.28280744, grad/param norm = 1.9178e-01, time/batch = 0.6389s	
6447/26050 (epoch 12.374), train_loss = 1.38338547, grad/param norm = 1.7931e-01, time/batch = 0.6402s	
6448/26050 (epoch 12.376), train_loss = 1.41207497, grad/param norm = 1.7910e-01, time/batch = 0.6408s	
6449/26050 (epoch 12.378), train_loss = 1.17996212, grad/param norm = 1.7437e-01, time/batch = 0.6398s	
6450/26050 (epoch 12.380), train_loss = 1.41371810, grad/param norm = 2.0036e-01, time/batch = 0.6380s	
6451/26050 (epoch 12.382), train_loss = 1.55589336, grad/param norm = 2.1466e-01, time/batch = 0.6410s	
6452/26050 (epoch 12.384), train_loss = 1.16173829, grad/param norm = 1.6048e-01, time/batch = 0.6381s	
6453/26050 (epoch 12.386), train_loss = 1.32917394, grad/param norm = 1.9420e-01, time/batch = 0.6409s	
6454/26050 (epoch 12.388), train_loss = 1.24704356, grad/param norm = 1.7590e-01, time/batch = 0.6394s	
6455/26050 (epoch 12.390), train_loss = 1.09388158, grad/param norm = 1.5327e-01, time/batch = 0.6380s	
6456/26050 (epoch 12.392), train_loss = 1.09952088, grad/param norm = 1.5484e-01, time/batch = 0.6412s	
6457/26050 (epoch 12.393), train_loss = 1.25640954, grad/param norm = 1.6487e-01, time/batch = 0.6420s	
6458/26050 (epoch 12.395), train_loss = 1.27671218, grad/param norm = 1.6718e-01, time/batch = 0.6392s	
6459/26050 (epoch 12.397), train_loss = 1.26061491, grad/param norm = 1.8642e-01, time/batch = 0.6418s	
6460/26050 (epoch 12.399), train_loss = 1.08415694, grad/param norm = 1.6045e-01, time/batch = 0.6412s	
6461/26050 (epoch 12.401), train_loss = 1.17481185, grad/param norm = 1.5281e-01, time/batch = 0.6397s	
6462/26050 (epoch 12.403), train_loss = 1.22697033, grad/param norm = 1.6018e-01, time/batch = 0.6407s	
6463/26050 (epoch 12.405), train_loss = 1.19644256, grad/param norm = 1.7757e-01, time/batch = 0.6408s	
6464/26050 (epoch 12.407), train_loss = 1.35539431, grad/param norm = 1.7785e-01, time/batch = 0.6687s	
6465/26050 (epoch 12.409), train_loss = 1.39675321, grad/param norm = 1.9059e-01, time/batch = 0.6792s	
6466/26050 (epoch 12.411), train_loss = 1.25263213, grad/param norm = 1.8203e-01, time/batch = 0.6454s	
6467/26050 (epoch 12.413), train_loss = 1.36017206, grad/param norm = 1.5988e-01, time/batch = 0.6389s	
6468/26050 (epoch 12.415), train_loss = 1.33490396, grad/param norm = 1.8883e-01, time/batch = 0.6384s	
6469/26050 (epoch 12.417), train_loss = 1.44856116, grad/param norm = 1.9193e-01, time/batch = 0.6396s	
6470/26050 (epoch 12.418), train_loss = 1.32215457, grad/param norm = 1.9474e-01, time/batch = 0.6480s	
6471/26050 (epoch 12.420), train_loss = 1.03092576, grad/param norm = 1.4838e-01, time/batch = 0.6504s	
6472/26050 (epoch 12.422), train_loss = 1.07489618, grad/param norm = 1.6896e-01, time/batch = 0.6407s	
6473/26050 (epoch 12.424), train_loss = 1.39351791, grad/param norm = 2.0604e-01, time/batch = 0.6416s	
6474/26050 (epoch 12.426), train_loss = 1.35885784, grad/param norm = 1.7913e-01, time/batch = 0.6461s	
6475/26050 (epoch 12.428), train_loss = 1.12187212, grad/param norm = 1.4729e-01, time/batch = 0.6430s	
6476/26050 (epoch 12.430), train_loss = 1.27918416, grad/param norm = 1.7482e-01, time/batch = 0.6402s	
6477/26050 (epoch 12.432), train_loss = 1.15633909, grad/param norm = 1.6753e-01, time/batch = 0.6384s	
6478/26050 (epoch 12.434), train_loss = 1.23339210, grad/param norm = 1.8827e-01, time/batch = 0.6398s	
6479/26050 (epoch 12.436), train_loss = 1.34004757, grad/param norm = 1.6396e-01, time/batch = 0.6522s	
6480/26050 (epoch 12.438), train_loss = 1.12875163, grad/param norm = 1.6917e-01, time/batch = 0.6828s	
6481/26050 (epoch 12.440), train_loss = 1.25366944, grad/param norm = 1.7014e-01, time/batch = 0.6473s	
6482/26050 (epoch 12.441), train_loss = 1.22947426, grad/param norm = 1.5807e-01, time/batch = 0.6407s	
6483/26050 (epoch 12.443), train_loss = 1.02894229, grad/param norm = 1.5301e-01, time/batch = 0.6431s	
6484/26050 (epoch 12.445), train_loss = 1.09237773, grad/param norm = 1.6015e-01, time/batch = 0.6403s	
6485/26050 (epoch 12.447), train_loss = 1.40959578, grad/param norm = 1.8735e-01, time/batch = 0.6435s	
6486/26050 (epoch 12.449), train_loss = 1.11806604, grad/param norm = 1.7691e-01, time/batch = 0.6563s	
6487/26050 (epoch 12.451), train_loss = 1.35047891, grad/param norm = 1.7688e-01, time/batch = 0.6581s	
6488/26050 (epoch 12.453), train_loss = 1.12577669, grad/param norm = 1.6256e-01, time/batch = 0.6463s	
6489/26050 (epoch 12.455), train_loss = 1.25648316, grad/param norm = 1.6268e-01, time/batch = 0.6502s	
6490/26050 (epoch 12.457), train_loss = 1.24006896, grad/param norm = 1.7424e-01, time/batch = 0.6394s	
6491/26050 (epoch 12.459), train_loss = 1.33159010, grad/param norm = 1.7417e-01, time/batch = 0.6428s	
6492/26050 (epoch 12.461), train_loss = 1.29831385, grad/param norm = 1.9539e-01, time/batch = 0.6397s	
6493/26050 (epoch 12.463), train_loss = 1.15400296, grad/param norm = 1.5329e-01, time/batch = 0.6404s	
6494/26050 (epoch 12.464), train_loss = 1.28661859, grad/param norm = 1.7755e-01, time/batch = 0.6449s	
6495/26050 (epoch 12.466), train_loss = 1.30410429, grad/param norm = 1.7612e-01, time/batch = 0.6830s	
6496/26050 (epoch 12.468), train_loss = 1.31284448, grad/param norm = 1.6057e-01, time/batch = 0.6618s	
6497/26050 (epoch 12.470), train_loss = 1.43085665, grad/param norm = 2.0139e-01, time/batch = 0.6399s	
6498/26050 (epoch 12.472), train_loss = 1.38574780, grad/param norm = 1.9133e-01, time/batch = 0.6396s	
6499/26050 (epoch 12.474), train_loss = 1.44971106, grad/param norm = 1.8200e-01, time/batch = 0.6428s	
6500/26050 (epoch 12.476), train_loss = 1.32431800, grad/param norm = 1.7321e-01, time/batch = 0.6404s	
6501/26050 (epoch 12.478), train_loss = 1.14263640, grad/param norm = 1.5357e-01, time/batch = 0.6434s	
6502/26050 (epoch 12.480), train_loss = 1.25247195, grad/param norm = 1.6542e-01, time/batch = 0.6427s	
6503/26050 (epoch 12.482), train_loss = 1.18316779, grad/param norm = 1.6316e-01, time/batch = 0.6415s	
6504/26050 (epoch 12.484), train_loss = 1.14730340, grad/param norm = 1.5907e-01, time/batch = 0.6400s	
6505/26050 (epoch 12.486), train_loss = 1.38954516, grad/param norm = 1.7580e-01, time/batch = 0.6395s	
6506/26050 (epoch 12.488), train_loss = 1.55750709, grad/param norm = 1.9772e-01, time/batch = 0.6407s	
6507/26050 (epoch 12.489), train_loss = 1.47024097, grad/param norm = 2.0284e-01, time/batch = 0.6384s	
6508/26050 (epoch 12.491), train_loss = 1.11842748, grad/param norm = 1.6075e-01, time/batch = 0.6403s	
6509/26050 (epoch 12.493), train_loss = 1.21995210, grad/param norm = 1.7084e-01, time/batch = 0.6432s	
6510/26050 (epoch 12.495), train_loss = 1.19500818, grad/param norm = 1.6593e-01, time/batch = 0.6618s	
6511/26050 (epoch 12.497), train_loss = 1.16069903, grad/param norm = 1.6432e-01, time/batch = 0.6802s	
6512/26050 (epoch 12.499), train_loss = 1.18540646, grad/param norm = 1.6824e-01, time/batch = 0.6493s	
6513/26050 (epoch 12.501), train_loss = 1.30451260, grad/param norm = 1.7494e-01, time/batch = 0.6446s	
6514/26050 (epoch 12.503), train_loss = 1.15520711, grad/param norm = 1.8475e-01, time/batch = 0.6406s	
6515/26050 (epoch 12.505), train_loss = 1.35376438, grad/param norm = 1.7581e-01, time/batch = 0.6410s	
6516/26050 (epoch 12.507), train_loss = 1.32496981, grad/param norm = 1.9406e-01, time/batch = 0.6457s	
6517/26050 (epoch 12.509), train_loss = 1.45646388, grad/param norm = 1.8416e-01, time/batch = 0.6443s	
6518/26050 (epoch 12.511), train_loss = 1.12159858, grad/param norm = 1.5990e-01, time/batch = 0.6438s	
6519/26050 (epoch 12.512), train_loss = 1.18365895, grad/param norm = 1.8403e-01, time/batch = 0.6406s	
6520/26050 (epoch 12.514), train_loss = 1.30836700, grad/param norm = 1.7816e-01, time/batch = 0.6442s	
6521/26050 (epoch 12.516), train_loss = 1.32880353, grad/param norm = 1.7815e-01, time/batch = 0.6430s	
6522/26050 (epoch 12.518), train_loss = 1.30551913, grad/param norm = 1.8828e-01, time/batch = 0.6420s	
6523/26050 (epoch 12.520), train_loss = 1.22084651, grad/param norm = 1.6248e-01, time/batch = 0.6402s	
6524/26050 (epoch 12.522), train_loss = 1.03516771, grad/param norm = 1.6253e-01, time/batch = 0.6433s	
6525/26050 (epoch 12.524), train_loss = 1.35457230, grad/param norm = 1.8548e-01, time/batch = 0.6487s	
6526/26050 (epoch 12.526), train_loss = 1.33969979, grad/param norm = 1.8308e-01, time/batch = 0.6828s	
6527/26050 (epoch 12.528), train_loss = 1.29034745, grad/param norm = 1.7597e-01, time/batch = 0.6530s	
6528/26050 (epoch 12.530), train_loss = 1.22031643, grad/param norm = 1.6162e-01, time/batch = 0.6406s	
6529/26050 (epoch 12.532), train_loss = 1.21790306, grad/param norm = 1.5292e-01, time/batch = 0.6401s	
6530/26050 (epoch 12.534), train_loss = 1.32095511, grad/param norm = 1.8498e-01, time/batch = 0.6396s	
6531/26050 (epoch 12.536), train_loss = 1.21690431, grad/param norm = 1.6246e-01, time/batch = 0.6583s	
6532/26050 (epoch 12.537), train_loss = 1.35313221, grad/param norm = 1.9074e-01, time/batch = 0.6571s	
6533/26050 (epoch 12.539), train_loss = 1.23882937, grad/param norm = 1.7076e-01, time/batch = 0.6623s	
6534/26050 (epoch 12.541), train_loss = 1.42537808, grad/param norm = 1.9305e-01, time/batch = 0.6565s	
6535/26050 (epoch 12.543), train_loss = 1.06073630, grad/param norm = 1.6391e-01, time/batch = 0.6556s	
6536/26050 (epoch 12.545), train_loss = 1.27778816, grad/param norm = 1.7146e-01, time/batch = 0.6546s	
6537/26050 (epoch 12.547), train_loss = 1.25883268, grad/param norm = 1.7273e-01, time/batch = 0.6578s	
6538/26050 (epoch 12.549), train_loss = 1.03471934, grad/param norm = 1.5029e-01, time/batch = 0.6589s	
6539/26050 (epoch 12.551), train_loss = 1.26147169, grad/param norm = 1.6781e-01, time/batch = 0.6587s	
6540/26050 (epoch 12.553), train_loss = 1.12975264, grad/param norm = 1.5578e-01, time/batch = 0.6594s	
6541/26050 (epoch 12.555), train_loss = 1.17476019, grad/param norm = 1.6668e-01, time/batch = 0.6852s	
6542/26050 (epoch 12.557), train_loss = 1.28145692, grad/param norm = 1.5749e-01, time/batch = 0.6822s	
6543/26050 (epoch 12.559), train_loss = 1.22819972, grad/param norm = 1.6661e-01, time/batch = 0.6617s	
6544/26050 (epoch 12.560), train_loss = 1.20894116, grad/param norm = 1.7273e-01, time/batch = 0.6413s	
6545/26050 (epoch 12.562), train_loss = 1.20282423, grad/param norm = 1.7294e-01, time/batch = 0.6405s	
6546/26050 (epoch 12.564), train_loss = 1.43419591, grad/param norm = 1.7578e-01, time/batch = 0.6400s	
6547/26050 (epoch 12.566), train_loss = 1.11076676, grad/param norm = 1.7191e-01, time/batch = 0.6410s	
6548/26050 (epoch 12.568), train_loss = 1.25413348, grad/param norm = 1.6422e-01, time/batch = 0.6420s	
6549/26050 (epoch 12.570), train_loss = 1.34072320, grad/param norm = 1.8758e-01, time/batch = 0.6410s	
6550/26050 (epoch 12.572), train_loss = 1.20303705, grad/param norm = 1.6670e-01, time/batch = 0.6395s	
6551/26050 (epoch 12.574), train_loss = 1.30520950, grad/param norm = 2.0080e-01, time/batch = 0.6419s	
6552/26050 (epoch 12.576), train_loss = 1.29505221, grad/param norm = 1.8661e-01, time/batch = 0.6419s	
6553/26050 (epoch 12.578), train_loss = 1.23988567, grad/param norm = 1.8263e-01, time/batch = 0.6408s	
6554/26050 (epoch 12.580), train_loss = 1.12479265, grad/param norm = 1.7438e-01, time/batch = 0.6405s	
6555/26050 (epoch 12.582), train_loss = 1.27044393, grad/param norm = 1.7698e-01, time/batch = 0.6420s	
6556/26050 (epoch 12.583), train_loss = 1.31412688, grad/param norm = 1.7158e-01, time/batch = 0.6521s	
6557/26050 (epoch 12.585), train_loss = 1.12674441, grad/param norm = 1.7323e-01, time/batch = 0.6573s	
6558/26050 (epoch 12.587), train_loss = 1.26903354, grad/param norm = 1.7467e-01, time/batch = 0.6405s	
6559/26050 (epoch 12.589), train_loss = 1.33830708, grad/param norm = 1.9719e-01, time/batch = 0.6387s	
6560/26050 (epoch 12.591), train_loss = 1.23960432, grad/param norm = 1.7892e-01, time/batch = 0.6489s	
6561/26050 (epoch 12.593), train_loss = 1.11402587, grad/param norm = 1.8932e-01, time/batch = 0.6446s	
6562/26050 (epoch 12.595), train_loss = 1.37080444, grad/param norm = 2.0312e-01, time/batch = 0.6402s	
6563/26050 (epoch 12.597), train_loss = 1.26588141, grad/param norm = 1.7660e-01, time/batch = 0.6466s	
6564/26050 (epoch 12.599), train_loss = 1.20358935, grad/param norm = 1.7139e-01, time/batch = 0.6435s	
6565/26050 (epoch 12.601), train_loss = 1.43766198, grad/param norm = 1.8143e-01, time/batch = 0.6405s	
6566/26050 (epoch 12.603), train_loss = 1.29754007, grad/param norm = 1.7764e-01, time/batch = 0.6403s	
6567/26050 (epoch 12.605), train_loss = 1.17121733, grad/param norm = 1.6325e-01, time/batch = 0.6405s	
6568/26050 (epoch 12.607), train_loss = 1.38666113, grad/param norm = 1.9418e-01, time/batch = 0.6401s	
6569/26050 (epoch 12.608), train_loss = 1.12750990, grad/param norm = 1.5660e-01, time/batch = 0.6416s	
6570/26050 (epoch 12.610), train_loss = 1.21028441, grad/param norm = 1.7353e-01, time/batch = 0.6454s	
6571/26050 (epoch 12.612), train_loss = 1.22214058, grad/param norm = 1.7633e-01, time/batch = 0.6503s	
6572/26050 (epoch 12.614), train_loss = 1.32210685, grad/param norm = 1.7967e-01, time/batch = 0.6835s	
6573/26050 (epoch 12.616), train_loss = 1.46737966, grad/param norm = 1.9629e-01, time/batch = 0.6527s	
6574/26050 (epoch 12.618), train_loss = 1.17940372, grad/param norm = 1.7758e-01, time/batch = 0.6393s	
6575/26050 (epoch 12.620), train_loss = 1.25704826, grad/param norm = 1.7666e-01, time/batch = 0.6396s	
6576/26050 (epoch 12.622), train_loss = 1.06015795, grad/param norm = 1.5889e-01, time/batch = 0.6396s	
6577/26050 (epoch 12.624), train_loss = 1.09604587, grad/param norm = 1.6437e-01, time/batch = 0.6405s	
6578/26050 (epoch 12.626), train_loss = 1.29843255, grad/param norm = 1.7656e-01, time/batch = 0.6692s	
6579/26050 (epoch 12.628), train_loss = 1.18705511, grad/param norm = 1.8934e-01, time/batch = 0.6503s	
6580/26050 (epoch 12.630), train_loss = 1.37402412, grad/param norm = 1.7306e-01, time/batch = 0.6597s	
6581/26050 (epoch 12.631), train_loss = 1.39838040, grad/param norm = 1.8690e-01, time/batch = 0.6450s	
6582/26050 (epoch 12.633), train_loss = 1.14994305, grad/param norm = 1.7593e-01, time/batch = 0.6596s	
6583/26050 (epoch 12.635), train_loss = 1.13909213, grad/param norm = 1.5211e-01, time/batch = 0.6496s	
6584/26050 (epoch 12.637), train_loss = 1.12366380, grad/param norm = 1.7436e-01, time/batch = 0.6587s	
6585/26050 (epoch 12.639), train_loss = 1.33875888, grad/param norm = 1.6867e-01, time/batch = 0.6704s	
6586/26050 (epoch 12.641), train_loss = 1.17832629, grad/param norm = 1.5725e-01, time/batch = 0.6773s	
6587/26050 (epoch 12.643), train_loss = 1.08392221, grad/param norm = 1.4957e-01, time/batch = 0.6751s	
6588/26050 (epoch 12.645), train_loss = 1.27019840, grad/param norm = 1.8769e-01, time/batch = 0.6669s	
6589/26050 (epoch 12.647), train_loss = 1.18649266, grad/param norm = 1.7040e-01, time/batch = 0.6624s	
6590/26050 (epoch 12.649), train_loss = 1.25422791, grad/param norm = 1.8646e-01, time/batch = 0.6410s	
6591/26050 (epoch 12.651), train_loss = 1.16485649, grad/param norm = 1.7761e-01, time/batch = 0.6423s	
6592/26050 (epoch 12.653), train_loss = 1.23185102, grad/param norm = 1.7109e-01, time/batch = 0.6429s	
6593/26050 (epoch 12.655), train_loss = 1.14365478, grad/param norm = 1.6210e-01, time/batch = 0.6473s	
6594/26050 (epoch 12.656), train_loss = 1.08289076, grad/param norm = 1.7262e-01, time/batch = 0.6560s	
6595/26050 (epoch 12.658), train_loss = 1.42899521, grad/param norm = 1.7964e-01, time/batch = 0.6444s	
6596/26050 (epoch 12.660), train_loss = 1.11315940, grad/param norm = 1.6811e-01, time/batch = 0.6404s	
6597/26050 (epoch 12.662), train_loss = 1.11577941, grad/param norm = 1.5590e-01, time/batch = 0.6421s	
6598/26050 (epoch 12.664), train_loss = 1.20112507, grad/param norm = 1.7675e-01, time/batch = 0.6417s	
6599/26050 (epoch 12.666), train_loss = 1.22654948, grad/param norm = 1.8664e-01, time/batch = 0.6407s	
6600/26050 (epoch 12.668), train_loss = 1.02930395, grad/param norm = 1.7787e-01, time/batch = 0.6430s	
6601/26050 (epoch 12.670), train_loss = 1.38268428, grad/param norm = 1.8813e-01, time/batch = 0.6448s	
6602/26050 (epoch 12.672), train_loss = 1.16684389, grad/param norm = 1.6928e-01, time/batch = 0.6684s	
6603/26050 (epoch 12.674), train_loss = 1.11222746, grad/param norm = 1.7195e-01, time/batch = 0.6744s	
6604/26050 (epoch 12.676), train_loss = 1.25043371, grad/param norm = 1.7496e-01, time/batch = 0.6387s	
6605/26050 (epoch 12.678), train_loss = 1.36003163, grad/param norm = 1.8281e-01, time/batch = 0.6394s	
6606/26050 (epoch 12.679), train_loss = 1.44711766, grad/param norm = 1.9576e-01, time/batch = 0.6411s	
6607/26050 (epoch 12.681), train_loss = 1.24425169, grad/param norm = 1.8025e-01, time/batch = 0.6456s	
6608/26050 (epoch 12.683), train_loss = 1.12321830, grad/param norm = 2.0450e-01, time/batch = 0.6384s	
6609/26050 (epoch 12.685), train_loss = 1.18030816, grad/param norm = 1.6137e-01, time/batch = 0.6428s	
6610/26050 (epoch 12.687), train_loss = 1.03360340, grad/param norm = 1.6257e-01, time/batch = 0.6395s	
6611/26050 (epoch 12.689), train_loss = 1.19213645, grad/param norm = 1.7174e-01, time/batch = 0.6389s	
6612/26050 (epoch 12.691), train_loss = 0.95934106, grad/param norm = 1.5568e-01, time/batch = 0.6404s	
6613/26050 (epoch 12.693), train_loss = 1.12463095, grad/param norm = 1.6860e-01, time/batch = 0.6404s	
6614/26050 (epoch 12.695), train_loss = 1.23568584, grad/param norm = 1.7629e-01, time/batch = 0.6480s	
6615/26050 (epoch 12.697), train_loss = 1.12221302, grad/param norm = 1.7421e-01, time/batch = 0.6439s	
6616/26050 (epoch 12.699), train_loss = 1.28365787, grad/param norm = 1.8241e-01, time/batch = 0.6413s	
6617/26050 (epoch 12.701), train_loss = 1.07028622, grad/param norm = 1.5270e-01, time/batch = 0.6555s	
6618/26050 (epoch 12.702), train_loss = 1.41968656, grad/param norm = 1.8966e-01, time/batch = 0.6832s	
6619/26050 (epoch 12.704), train_loss = 1.26965014, grad/param norm = 1.7080e-01, time/batch = 0.6527s	
6620/26050 (epoch 12.706), train_loss = 1.27154315, grad/param norm = 1.9689e-01, time/batch = 0.6388s	
6621/26050 (epoch 12.708), train_loss = 1.30873157, grad/param norm = 1.8205e-01, time/batch = 0.6392s	
6622/26050 (epoch 12.710), train_loss = 1.27907249, grad/param norm = 1.7702e-01, time/batch = 0.6401s	
6623/26050 (epoch 12.712), train_loss = 1.35019486, grad/param norm = 1.7922e-01, time/batch = 0.6385s	
6624/26050 (epoch 12.714), train_loss = 1.06516374, grad/param norm = 1.6971e-01, time/batch = 0.6391s	
6625/26050 (epoch 12.716), train_loss = 1.49406462, grad/param norm = 2.0560e-01, time/batch = 0.6411s	
6626/26050 (epoch 12.718), train_loss = 1.33868226, grad/param norm = 1.8597e-01, time/batch = 0.6382s	
6627/26050 (epoch 12.720), train_loss = 1.15219568, grad/param norm = 1.6772e-01, time/batch = 0.6379s	
6628/26050 (epoch 12.722), train_loss = 1.09859314, grad/param norm = 1.6887e-01, time/batch = 0.6393s	
6629/26050 (epoch 12.724), train_loss = 1.10542761, grad/param norm = 1.7384e-01, time/batch = 0.6405s	
6630/26050 (epoch 12.726), train_loss = 1.34655672, grad/param norm = 1.8060e-01, time/batch = 0.6394s	
6631/26050 (epoch 12.727), train_loss = 1.27810333, grad/param norm = 1.7227e-01, time/batch = 0.6399s	
6632/26050 (epoch 12.729), train_loss = 1.28072568, grad/param norm = 1.7260e-01, time/batch = 0.6467s	
6633/26050 (epoch 12.731), train_loss = 1.26097399, grad/param norm = 1.6216e-01, time/batch = 0.6743s	
6634/26050 (epoch 12.733), train_loss = 1.18668020, grad/param norm = 1.9308e-01, time/batch = 0.6698s	
6635/26050 (epoch 12.735), train_loss = 1.41477694, grad/param norm = 1.8855e-01, time/batch = 0.6391s	
6636/26050 (epoch 12.737), train_loss = 1.21834819, grad/param norm = 1.7166e-01, time/batch = 0.6395s	
6637/26050 (epoch 12.739), train_loss = 1.28695561, grad/param norm = 1.6806e-01, time/batch = 0.6396s	
6638/26050 (epoch 12.741), train_loss = 1.14457904, grad/param norm = 1.7428e-01, time/batch = 0.6420s	
6639/26050 (epoch 12.743), train_loss = 1.28761125, grad/param norm = 1.8820e-01, time/batch = 0.6404s	
6640/26050 (epoch 12.745), train_loss = 1.11316243, grad/param norm = 1.7156e-01, time/batch = 0.6434s	
6641/26050 (epoch 12.747), train_loss = 1.11889892, grad/param norm = 1.5306e-01, time/batch = 0.6486s	
6642/26050 (epoch 12.749), train_loss = 1.37485017, grad/param norm = 1.8696e-01, time/batch = 0.6399s	
6643/26050 (epoch 12.750), train_loss = 1.22375276, grad/param norm = 1.6029e-01, time/batch = 0.6547s	
6644/26050 (epoch 12.752), train_loss = 1.21482641, grad/param norm = 1.9660e-01, time/batch = 0.6570s	
6645/26050 (epoch 12.754), train_loss = 1.24442767, grad/param norm = 1.7621e-01, time/batch = 0.6518s	
6646/26050 (epoch 12.756), train_loss = 1.23814052, grad/param norm = 1.7833e-01, time/batch = 0.6493s	
6647/26050 (epoch 12.758), train_loss = 1.24285810, grad/param norm = 1.8032e-01, time/batch = 0.6497s	
6648/26050 (epoch 12.760), train_loss = 1.34567643, grad/param norm = 1.6935e-01, time/batch = 0.6678s	
6649/26050 (epoch 12.762), train_loss = 1.14223892, grad/param norm = 1.6153e-01, time/batch = 0.6834s	
6650/26050 (epoch 12.764), train_loss = 1.30298035, grad/param norm = 1.7945e-01, time/batch = 0.6500s	
6651/26050 (epoch 12.766), train_loss = 1.31442984, grad/param norm = 1.9020e-01, time/batch = 0.6509s	
6652/26050 (epoch 12.768), train_loss = 1.09998676, grad/param norm = 1.5192e-01, time/batch = 0.6466s	
6653/26050 (epoch 12.770), train_loss = 1.20475806, grad/param norm = 1.8839e-01, time/batch = 0.6446s	
6654/26050 (epoch 12.772), train_loss = 1.20369175, grad/param norm = 1.7162e-01, time/batch = 0.6537s	
6655/26050 (epoch 12.774), train_loss = 1.08277076, grad/param norm = 1.7074e-01, time/batch = 0.6609s	
6656/26050 (epoch 12.775), train_loss = 0.92395205, grad/param norm = 1.5747e-01, time/batch = 0.6524s	
6657/26050 (epoch 12.777), train_loss = 1.12520100, grad/param norm = 1.6084e-01, time/batch = 0.6507s	
6658/26050 (epoch 12.779), train_loss = 1.19589711, grad/param norm = 1.7469e-01, time/batch = 0.6482s	
6659/26050 (epoch 12.781), train_loss = 1.16697354, grad/param norm = 1.6740e-01, time/batch = 0.6430s	
6660/26050 (epoch 12.783), train_loss = 1.12923564, grad/param norm = 1.6066e-01, time/batch = 0.6420s	
6661/26050 (epoch 12.785), train_loss = 1.18472966, grad/param norm = 1.7453e-01, time/batch = 0.6440s	
6662/26050 (epoch 12.787), train_loss = 1.15151500, grad/param norm = 1.6697e-01, time/batch = 0.6438s	
6663/26050 (epoch 12.789), train_loss = 1.15586010, grad/param norm = 1.8764e-01, time/batch = 0.6435s	
6664/26050 (epoch 12.791), train_loss = 1.20115391, grad/param norm = 1.6791e-01, time/batch = 0.6425s	
6665/26050 (epoch 12.793), train_loss = 1.18930916, grad/param norm = 1.8291e-01, time/batch = 0.6403s	
6666/26050 (epoch 12.795), train_loss = 1.04061918, grad/param norm = 1.5084e-01, time/batch = 0.6392s	
6667/26050 (epoch 12.797), train_loss = 1.14153435, grad/param norm = 1.7225e-01, time/batch = 0.6380s	
6668/26050 (epoch 12.798), train_loss = 1.07465562, grad/param norm = 1.6457e-01, time/batch = 0.6409s	
6669/26050 (epoch 12.800), train_loss = 1.05892111, grad/param norm = 1.4476e-01, time/batch = 0.6409s	
6670/26050 (epoch 12.802), train_loss = 1.18425013, grad/param norm = 1.7776e-01, time/batch = 0.6475s	
6671/26050 (epoch 12.804), train_loss = 1.17163429, grad/param norm = 1.6718e-01, time/batch = 0.6583s	
6672/26050 (epoch 12.806), train_loss = 1.30459720, grad/param norm = 1.8922e-01, time/batch = 0.6515s	
6673/26050 (epoch 12.808), train_loss = 1.17830008, grad/param norm = 1.6849e-01, time/batch = 0.6414s	
6674/26050 (epoch 12.810), train_loss = 1.14345008, grad/param norm = 1.6473e-01, time/batch = 0.6483s	
6675/26050 (epoch 12.812), train_loss = 1.09102890, grad/param norm = 1.8517e-01, time/batch = 0.6421s	
6676/26050 (epoch 12.814), train_loss = 1.07819298, grad/param norm = 1.7838e-01, time/batch = 0.6398s	
6677/26050 (epoch 12.816), train_loss = 1.30563208, grad/param norm = 1.7977e-01, time/batch = 0.6530s	
6678/26050 (epoch 12.818), train_loss = 1.35827240, grad/param norm = 1.9760e-01, time/batch = 0.6622s	
6679/26050 (epoch 12.820), train_loss = 1.23117409, grad/param norm = 1.7724e-01, time/batch = 0.6804s	
6680/26050 (epoch 12.821), train_loss = 1.37111361, grad/param norm = 1.9779e-01, time/batch = 0.6767s	
6681/26050 (epoch 12.823), train_loss = 1.39349922, grad/param norm = 1.8646e-01, time/batch = 0.6613s	
6682/26050 (epoch 12.825), train_loss = 1.20086557, grad/param norm = 1.8571e-01, time/batch = 0.6536s	
6683/26050 (epoch 12.827), train_loss = 1.24379094, grad/param norm = 1.9209e-01, time/batch = 0.6541s	
6684/26050 (epoch 12.829), train_loss = 1.27007640, grad/param norm = 1.8729e-01, time/batch = 0.6594s	
6685/26050 (epoch 12.831), train_loss = 1.34683328, grad/param norm = 1.7777e-01, time/batch = 0.6631s	
6686/26050 (epoch 12.833), train_loss = 1.41830729, grad/param norm = 1.8467e-01, time/batch = 0.6690s	
6687/26050 (epoch 12.835), train_loss = 1.44034729, grad/param norm = 1.9036e-01, time/batch = 0.6662s	
6688/26050 (epoch 12.837), train_loss = 1.19992864, grad/param norm = 1.8388e-01, time/batch = 0.6556s	
6689/26050 (epoch 12.839), train_loss = 1.27244131, grad/param norm = 1.9356e-01, time/batch = 0.6515s	
6690/26050 (epoch 12.841), train_loss = 1.33732856, grad/param norm = 1.7482e-01, time/batch = 0.6392s	
6691/26050 (epoch 12.843), train_loss = 1.24358713, grad/param norm = 1.8017e-01, time/batch = 0.6399s	
6692/26050 (epoch 12.845), train_loss = 1.14489549, grad/param norm = 1.5607e-01, time/batch = 0.6440s	
6693/26050 (epoch 12.846), train_loss = 1.33921300, grad/param norm = 1.7748e-01, time/batch = 0.6443s	
6694/26050 (epoch 12.848), train_loss = 1.17883088, grad/param norm = 1.8065e-01, time/batch = 0.6719s	
6695/26050 (epoch 12.850), train_loss = 1.15366225, grad/param norm = 1.7707e-01, time/batch = 0.6787s	
6696/26050 (epoch 12.852), train_loss = 1.18550691, grad/param norm = 1.7234e-01, time/batch = 0.6418s	
6697/26050 (epoch 12.854), train_loss = 1.21219616, grad/param norm = 1.8633e-01, time/batch = 0.6400s	
6698/26050 (epoch 12.856), train_loss = 1.15992296, grad/param norm = 1.7947e-01, time/batch = 0.6537s	
6699/26050 (epoch 12.858), train_loss = 1.09540859, grad/param norm = 1.6745e-01, time/batch = 0.6592s	
6700/26050 (epoch 12.860), train_loss = 1.26043958, grad/param norm = 1.8449e-01, time/batch = 0.6420s	
6701/26050 (epoch 12.862), train_loss = 1.24091414, grad/param norm = 1.6959e-01, time/batch = 0.6461s	
6702/26050 (epoch 12.864), train_loss = 1.24391797, grad/param norm = 1.9403e-01, time/batch = 0.6403s	
6703/26050 (epoch 12.866), train_loss = 1.15409069, grad/param norm = 1.5884e-01, time/batch = 0.6393s	
6704/26050 (epoch 12.868), train_loss = 1.30760064, grad/param norm = 1.8169e-01, time/batch = 0.6405s	
6705/26050 (epoch 12.869), train_loss = 1.10552661, grad/param norm = 1.5935e-01, time/batch = 0.6412s	
6706/26050 (epoch 12.871), train_loss = 1.05154875, grad/param norm = 1.6117e-01, time/batch = 0.6392s	
6707/26050 (epoch 12.873), train_loss = 1.27025378, grad/param norm = 1.6850e-01, time/batch = 0.6387s	
6708/26050 (epoch 12.875), train_loss = 1.20544463, grad/param norm = 1.7372e-01, time/batch = 0.6424s	
6709/26050 (epoch 12.877), train_loss = 1.09408454, grad/param norm = 1.7290e-01, time/batch = 0.6490s	
6710/26050 (epoch 12.879), train_loss = 1.21596020, grad/param norm = 1.5750e-01, time/batch = 0.6832s	
6711/26050 (epoch 12.881), train_loss = 1.34667418, grad/param norm = 1.7492e-01, time/batch = 0.6513s	
6712/26050 (epoch 12.883), train_loss = 1.25605903, grad/param norm = 1.7564e-01, time/batch = 0.6394s	
6713/26050 (epoch 12.885), train_loss = 0.95320442, grad/param norm = 1.5173e-01, time/batch = 0.6394s	
6714/26050 (epoch 12.887), train_loss = 1.24386563, grad/param norm = 1.7690e-01, time/batch = 0.6388s	
6715/26050 (epoch 12.889), train_loss = 1.15785511, grad/param norm = 1.6048e-01, time/batch = 0.6421s	
6716/26050 (epoch 12.891), train_loss = 0.96936065, grad/param norm = 1.4941e-01, time/batch = 0.6383s	
6717/26050 (epoch 12.893), train_loss = 0.98396946, grad/param norm = 1.5566e-01, time/batch = 0.6440s	
6718/26050 (epoch 12.894), train_loss = 1.17682413, grad/param norm = 1.6827e-01, time/batch = 0.6454s	
6719/26050 (epoch 12.896), train_loss = 1.33003669, grad/param norm = 1.7966e-01, time/batch = 0.6394s	
6720/26050 (epoch 12.898), train_loss = 1.14935678, grad/param norm = 1.8062e-01, time/batch = 0.6401s	
6721/26050 (epoch 12.900), train_loss = 1.32175776, grad/param norm = 1.8032e-01, time/batch = 0.6412s	
6722/26050 (epoch 12.902), train_loss = 1.20365784, grad/param norm = 1.7991e-01, time/batch = 0.6405s	
6723/26050 (epoch 12.904), train_loss = 1.17452689, grad/param norm = 1.6543e-01, time/batch = 0.6398s	
6724/26050 (epoch 12.906), train_loss = 1.19743025, grad/param norm = 1.7782e-01, time/batch = 0.6458s	
6725/26050 (epoch 12.908), train_loss = 1.17702324, grad/param norm = 1.6817e-01, time/batch = 0.6749s	
6726/26050 (epoch 12.910), train_loss = 1.10793461, grad/param norm = 1.5065e-01, time/batch = 0.6685s	
6727/26050 (epoch 12.912), train_loss = 1.45220373, grad/param norm = 1.9056e-01, time/batch = 0.6409s	
6728/26050 (epoch 12.914), train_loss = 1.59577130, grad/param norm = 1.9726e-01, time/batch = 0.6401s	
6729/26050 (epoch 12.916), train_loss = 1.33077578, grad/param norm = 1.9529e-01, time/batch = 0.6401s	
6730/26050 (epoch 12.917), train_loss = 1.23711483, grad/param norm = 2.0202e-01, time/batch = 0.6419s	
6731/26050 (epoch 12.919), train_loss = 1.31034541, grad/param norm = 1.8877e-01, time/batch = 0.6400s	
6732/26050 (epoch 12.921), train_loss = 1.15583309, grad/param norm = 1.8089e-01, time/batch = 0.6409s	
6733/26050 (epoch 12.923), train_loss = 1.22601791, grad/param norm = 1.8439e-01, time/batch = 0.6447s	
6734/26050 (epoch 12.925), train_loss = 1.20571243, grad/param norm = 1.6994e-01, time/batch = 0.6402s	
6735/26050 (epoch 12.927), train_loss = 1.08677488, grad/param norm = 1.5539e-01, time/batch = 0.6449s	
6736/26050 (epoch 12.929), train_loss = 1.11876742, grad/param norm = 1.6720e-01, time/batch = 0.6484s	
6737/26050 (epoch 12.931), train_loss = 1.42962457, grad/param norm = 2.0738e-01, time/batch = 0.6438s	
6738/26050 (epoch 12.933), train_loss = 1.18346610, grad/param norm = 1.8352e-01, time/batch = 0.6402s	
6739/26050 (epoch 12.935), train_loss = 1.14548225, grad/param norm = 1.5618e-01, time/batch = 0.6420s	
6740/26050 (epoch 12.937), train_loss = 1.27840236, grad/param norm = 1.7870e-01, time/batch = 0.6427s	
6741/26050 (epoch 12.939), train_loss = 1.09900194, grad/param norm = 1.4321e-01, time/batch = 0.6415s	
6742/26050 (epoch 12.940), train_loss = 1.22481286, grad/param norm = 1.6707e-01, time/batch = 0.6408s	
6743/26050 (epoch 12.942), train_loss = 1.25441525, grad/param norm = 1.9036e-01, time/batch = 0.6397s	
6744/26050 (epoch 12.944), train_loss = 1.17285003, grad/param norm = 1.7028e-01, time/batch = 0.6404s	
6745/26050 (epoch 12.946), train_loss = 1.38089211, grad/param norm = 1.8286e-01, time/batch = 0.6404s	
6746/26050 (epoch 12.948), train_loss = 1.04622164, grad/param norm = 1.8794e-01, time/batch = 0.6413s	
6747/26050 (epoch 12.950), train_loss = 1.20676111, grad/param norm = 1.8063e-01, time/batch = 0.6429s	
6748/26050 (epoch 12.952), train_loss = 1.34602387, grad/param norm = 1.9529e-01, time/batch = 0.6441s	
6749/26050 (epoch 12.954), train_loss = 1.32177717, grad/param norm = 1.8434e-01, time/batch = 0.6405s	
6750/26050 (epoch 12.956), train_loss = 1.22847639, grad/param norm = 1.8342e-01, time/batch = 0.6390s	
6751/26050 (epoch 12.958), train_loss = 1.17579197, grad/param norm = 1.7489e-01, time/batch = 0.6411s	
6752/26050 (epoch 12.960), train_loss = 1.21254888, grad/param norm = 1.8085e-01, time/batch = 0.6417s	
6753/26050 (epoch 12.962), train_loss = 1.14042269, grad/param norm = 1.6518e-01, time/batch = 0.6405s	
6754/26050 (epoch 12.964), train_loss = 1.20904223, grad/param norm = 1.7220e-01, time/batch = 0.6407s	
6755/26050 (epoch 12.965), train_loss = 1.11229062, grad/param norm = 1.7362e-01, time/batch = 0.6462s	
6756/26050 (epoch 12.967), train_loss = 1.52067248, grad/param norm = 1.7640e-01, time/batch = 0.6780s	
6757/26050 (epoch 12.969), train_loss = 1.19952506, grad/param norm = 1.6606e-01, time/batch = 0.6662s	
6758/26050 (epoch 12.971), train_loss = 1.12005250, grad/param norm = 1.5185e-01, time/batch = 0.6420s	
6759/26050 (epoch 12.973), train_loss = 1.18377496, grad/param norm = 1.9161e-01, time/batch = 0.6405s	
6760/26050 (epoch 12.975), train_loss = 1.27451671, grad/param norm = 1.6333e-01, time/batch = 0.6387s	
6761/26050 (epoch 12.977), train_loss = 1.24651662, grad/param norm = 1.6574e-01, time/batch = 0.6421s	
6762/26050 (epoch 12.979), train_loss = 1.04772078, grad/param norm = 1.6706e-01, time/batch = 0.6493s	
6763/26050 (epoch 12.981), train_loss = 1.33950215, grad/param norm = 1.6496e-01, time/batch = 0.6581s	
6764/26050 (epoch 12.983), train_loss = 1.32482461, grad/param norm = 1.7597e-01, time/batch = 0.6488s	
6765/26050 (epoch 12.985), train_loss = 1.24599904, grad/param norm = 1.7433e-01, time/batch = 0.6495s	
6766/26050 (epoch 12.987), train_loss = 1.35804492, grad/param norm = 1.8833e-01, time/batch = 0.6438s	
6767/26050 (epoch 12.988), train_loss = 1.31475117, grad/param norm = 1.7081e-01, time/batch = 0.6488s	
6768/26050 (epoch 12.990), train_loss = 1.10478833, grad/param norm = 1.5001e-01, time/batch = 0.6436s	
6769/26050 (epoch 12.992), train_loss = 1.35877395, grad/param norm = 1.8109e-01, time/batch = 0.6386s	
6770/26050 (epoch 12.994), train_loss = 1.24095042, grad/param norm = 1.8114e-01, time/batch = 0.6491s	
6771/26050 (epoch 12.996), train_loss = 1.17819538, grad/param norm = 1.8083e-01, time/batch = 0.6526s	
6772/26050 (epoch 12.998), train_loss = 1.22389789, grad/param norm = 1.7884e-01, time/batch = 0.6415s	
decayed learning rate by a factor 0.97 to 0.00177058562	
6773/26050 (epoch 13.000), train_loss = 1.17451227, grad/param norm = 1.7925e-01, time/batch = 0.6399s	
6774/26050 (epoch 13.002), train_loss = 1.29098093, grad/param norm = 1.9083e-01, time/batch = 0.6401s	
6775/26050 (epoch 13.004), train_loss = 1.10574946, grad/param norm = 1.7118e-01, time/batch = 0.6395s	
6776/26050 (epoch 13.006), train_loss = 1.12176668, grad/param norm = 1.6514e-01, time/batch = 0.6427s	
6777/26050 (epoch 13.008), train_loss = 1.10815042, grad/param norm = 1.7272e-01, time/batch = 0.6404s	
6778/26050 (epoch 13.010), train_loss = 1.15010834, grad/param norm = 1.7122e-01, time/batch = 0.6485s	
6779/26050 (epoch 13.012), train_loss = 1.23962632, grad/param norm = 1.7438e-01, time/batch = 0.6412s	
6780/26050 (epoch 13.013), train_loss = 1.60048606, grad/param norm = 1.9696e-01, time/batch = 0.6405s	
6781/26050 (epoch 13.015), train_loss = 1.12237708, grad/param norm = 1.5425e-01, time/batch = 0.6398s	
6782/26050 (epoch 13.017), train_loss = 1.22617420, grad/param norm = 1.6903e-01, time/batch = 0.6790s	
6783/26050 (epoch 13.019), train_loss = 1.01861643, grad/param norm = 1.4181e-01, time/batch = 0.6731s	
6784/26050 (epoch 13.021), train_loss = 1.28750723, grad/param norm = 1.7573e-01, time/batch = 0.6406s	
6785/26050 (epoch 13.023), train_loss = 1.05713521, grad/param norm = 1.6774e-01, time/batch = 0.6433s	
6786/26050 (epoch 13.025), train_loss = 1.19214958, grad/param norm = 1.6653e-01, time/batch = 0.6470s	
6787/26050 (epoch 13.027), train_loss = 0.98135311, grad/param norm = 1.6796e-01, time/batch = 0.6508s	
6788/26050 (epoch 13.029), train_loss = 1.19366558, grad/param norm = 1.6390e-01, time/batch = 0.6519s	
6789/26050 (epoch 13.031), train_loss = 1.33719050, grad/param norm = 1.8867e-01, time/batch = 0.6510s	
6790/26050 (epoch 13.033), train_loss = 1.24758754, grad/param norm = 1.7156e-01, time/batch = 0.6489s	
6791/26050 (epoch 13.035), train_loss = 1.28118751, grad/param norm = 1.6080e-01, time/batch = 0.6474s	
6792/26050 (epoch 13.036), train_loss = 1.09322846, grad/param norm = 1.8566e-01, time/batch = 0.6457s	
6793/26050 (epoch 13.038), train_loss = 1.04135309, grad/param norm = 1.6461e-01, time/batch = 0.6394s	
6794/26050 (epoch 13.040), train_loss = 1.23852493, grad/param norm = 1.8138e-01, time/batch = 0.6535s	
6795/26050 (epoch 13.042), train_loss = 1.05226207, grad/param norm = 1.8734e-01, time/batch = 0.6488s	
6796/26050 (epoch 13.044), train_loss = 1.29023222, grad/param norm = 1.6891e-01, time/batch = 0.6416s	
6797/26050 (epoch 13.046), train_loss = 1.00134527, grad/param norm = 1.6423e-01, time/batch = 0.6563s	
6798/26050 (epoch 13.048), train_loss = 1.24226520, grad/param norm = 1.7577e-01, time/batch = 0.6831s	
6799/26050 (epoch 13.050), train_loss = 1.10066032, grad/param norm = 1.7657e-01, time/batch = 0.6425s	
6800/26050 (epoch 13.052), train_loss = 1.17598987, grad/param norm = 1.7390e-01, time/batch = 0.6388s	
6801/26050 (epoch 13.054), train_loss = 1.03761745, grad/param norm = 1.5588e-01, time/batch = 0.6419s	
6802/26050 (epoch 13.056), train_loss = 0.96109284, grad/param norm = 1.3905e-01, time/batch = 0.6406s	
6803/26050 (epoch 13.058), train_loss = 1.12623534, grad/param norm = 1.5723e-01, time/batch = 0.6401s	
6804/26050 (epoch 13.060), train_loss = 1.22569656, grad/param norm = 1.6396e-01, time/batch = 0.6398s	
6805/26050 (epoch 13.061), train_loss = 1.10669850, grad/param norm = 1.6837e-01, time/batch = 0.6383s	
6806/26050 (epoch 13.063), train_loss = 1.20381860, grad/param norm = 1.6816e-01, time/batch = 0.6392s	
6807/26050 (epoch 13.065), train_loss = 1.01103700, grad/param norm = 1.5734e-01, time/batch = 0.6383s	
6808/26050 (epoch 13.067), train_loss = 1.23208359, grad/param norm = 1.7369e-01, time/batch = 0.6393s	
6809/26050 (epoch 13.069), train_loss = 1.24468473, grad/param norm = 1.6270e-01, time/batch = 0.6398s	
6810/26050 (epoch 13.071), train_loss = 1.25239065, grad/param norm = 1.6718e-01, time/batch = 0.6431s	
6811/26050 (epoch 13.073), train_loss = 1.41389813, grad/param norm = 1.8605e-01, time/batch = 0.6392s	
6812/26050 (epoch 13.075), train_loss = 1.10544095, grad/param norm = 1.6066e-01, time/batch = 0.6383s	
6813/26050 (epoch 13.077), train_loss = 1.10160941, grad/param norm = 1.6351e-01, time/batch = 0.6389s	
6814/26050 (epoch 13.079), train_loss = 1.22876410, grad/param norm = 1.7458e-01, time/batch = 0.6386s	
6815/26050 (epoch 13.081), train_loss = 1.14490228, grad/param norm = 1.9424e-01, time/batch = 0.6392s	
6816/26050 (epoch 13.083), train_loss = 1.27377096, grad/param norm = 1.7063e-01, time/batch = 0.6403s	
6817/26050 (epoch 13.084), train_loss = 1.27242826, grad/param norm = 1.8350e-01, time/batch = 0.6470s	
6818/26050 (epoch 13.086), train_loss = 1.34391657, grad/param norm = 1.8391e-01, time/batch = 0.6393s	
6819/26050 (epoch 13.088), train_loss = 1.08895362, grad/param norm = 1.6065e-01, time/batch = 0.6388s	
6820/26050 (epoch 13.090), train_loss = 1.25199814, grad/param norm = 1.7954e-01, time/batch = 0.6410s	
6821/26050 (epoch 13.092), train_loss = 1.22891194, grad/param norm = 1.7515e-01, time/batch = 0.6565s	
6822/26050 (epoch 13.094), train_loss = 1.16402887, grad/param norm = 1.8034e-01, time/batch = 0.6473s	
6823/26050 (epoch 13.096), train_loss = 1.15736561, grad/param norm = 1.6160e-01, time/batch = 0.6518s	
6824/26050 (epoch 13.098), train_loss = 1.17161395, grad/param norm = 1.7272e-01, time/batch = 0.6603s	
6825/26050 (epoch 13.100), train_loss = 1.08603276, grad/param norm = 1.7585e-01, time/batch = 0.6547s	
6826/26050 (epoch 13.102), train_loss = 1.19550142, grad/param norm = 1.6327e-01, time/batch = 0.6547s	
6827/26050 (epoch 13.104), train_loss = 1.19846322, grad/param norm = 1.7550e-01, time/batch = 0.6524s	
6828/26050 (epoch 13.106), train_loss = 1.18544684, grad/param norm = 1.8478e-01, time/batch = 0.6556s	
6829/26050 (epoch 13.107), train_loss = 0.98153224, grad/param norm = 1.6179e-01, time/batch = 0.6571s	
6830/26050 (epoch 13.109), train_loss = 1.12108274, grad/param norm = 1.7123e-01, time/batch = 0.6570s	
6831/26050 (epoch 13.111), train_loss = 1.37542771, grad/param norm = 1.8487e-01, time/batch = 0.6625s	
6832/26050 (epoch 13.113), train_loss = 1.14232837, grad/param norm = 1.6603e-01, time/batch = 0.6633s	
6833/26050 (epoch 13.115), train_loss = 1.28124190, grad/param norm = 1.7776e-01, time/batch = 0.6684s	
6834/26050 (epoch 13.117), train_loss = 1.24033258, grad/param norm = 1.7131e-01, time/batch = 0.6632s	
6835/26050 (epoch 13.119), train_loss = 0.97762660, grad/param norm = 1.5256e-01, time/batch = 0.6649s	
6836/26050 (epoch 13.121), train_loss = 1.23604188, grad/param norm = 1.6684e-01, time/batch = 0.6522s	
6837/26050 (epoch 13.123), train_loss = 1.08642665, grad/param norm = 1.7353e-01, time/batch = 0.6508s	
6838/26050 (epoch 13.125), train_loss = 1.01934071, grad/param norm = 1.5670e-01, time/batch = 0.6571s	
6839/26050 (epoch 13.127), train_loss = 0.95162288, grad/param norm = 1.5211e-01, time/batch = 0.6542s	
6840/26050 (epoch 13.129), train_loss = 1.00176483, grad/param norm = 1.5183e-01, time/batch = 0.6439s	
6841/26050 (epoch 13.131), train_loss = 1.16269794, grad/param norm = 1.6744e-01, time/batch = 0.6406s	
6842/26050 (epoch 13.132), train_loss = 1.14914115, grad/param norm = 1.6875e-01, time/batch = 0.6397s	
6843/26050 (epoch 13.134), train_loss = 1.14489554, grad/param norm = 1.7267e-01, time/batch = 0.6400s	
6844/26050 (epoch 13.136), train_loss = 1.18738377, grad/param norm = 1.6829e-01, time/batch = 0.6403s	
6845/26050 (epoch 13.138), train_loss = 0.98434214, grad/param norm = 1.6675e-01, time/batch = 0.6390s	
6846/26050 (epoch 13.140), train_loss = 1.03341211, grad/param norm = 1.6783e-01, time/batch = 0.6404s	
6847/26050 (epoch 13.142), train_loss = 1.08981091, grad/param norm = 1.6955e-01, time/batch = 0.6415s	
6848/26050 (epoch 13.144), train_loss = 1.00004572, grad/param norm = 1.6405e-01, time/batch = 0.6405s	
6849/26050 (epoch 13.146), train_loss = 0.92878555, grad/param norm = 1.6356e-01, time/batch = 0.6401s	
6850/26050 (epoch 13.148), train_loss = 0.94172586, grad/param norm = 1.3731e-01, time/batch = 0.6392s	
6851/26050 (epoch 13.150), train_loss = 1.16679654, grad/param norm = 1.9339e-01, time/batch = 0.6442s	
6852/26050 (epoch 13.152), train_loss = 1.39820800, grad/param norm = 2.1172e-01, time/batch = 0.6421s	
6853/26050 (epoch 13.154), train_loss = 0.95064026, grad/param norm = 1.5805e-01, time/batch = 0.6427s	
6854/26050 (epoch 13.155), train_loss = 1.00118637, grad/param norm = 1.5999e-01, time/batch = 0.6420s	
6855/26050 (epoch 13.157), train_loss = 1.12137227, grad/param norm = 1.9132e-01, time/batch = 0.6583s	
6856/26050 (epoch 13.159), train_loss = 1.14285680, grad/param norm = 1.8334e-01, time/batch = 0.6609s	
6857/26050 (epoch 13.161), train_loss = 1.27891813, grad/param norm = 1.9090e-01, time/batch = 0.6543s	
6858/26050 (epoch 13.163), train_loss = 0.99836805, grad/param norm = 1.6225e-01, time/batch = 0.6617s	
6859/26050 (epoch 13.165), train_loss = 0.90156355, grad/param norm = 1.4893e-01, time/batch = 0.6572s	
6860/26050 (epoch 13.167), train_loss = 1.27917170, grad/param norm = 1.8865e-01, time/batch = 0.6410s	
6861/26050 (epoch 13.169), train_loss = 1.22619769, grad/param norm = 1.6770e-01, time/batch = 0.6403s	
6862/26050 (epoch 13.171), train_loss = 0.96915271, grad/param norm = 1.4580e-01, time/batch = 0.6600s	
6863/26050 (epoch 13.173), train_loss = 1.11620583, grad/param norm = 1.8811e-01, time/batch = 0.6651s	
6864/26050 (epoch 13.175), train_loss = 1.16742128, grad/param norm = 1.6553e-01, time/batch = 0.6848s	
6865/26050 (epoch 13.177), train_loss = 1.28676546, grad/param norm = 1.7362e-01, time/batch = 0.6513s	
6866/26050 (epoch 13.179), train_loss = 0.92224485, grad/param norm = 1.5094e-01, time/batch = 0.6419s	
6867/26050 (epoch 13.180), train_loss = 1.41310011, grad/param norm = 1.7625e-01, time/batch = 0.6651s	
6868/26050 (epoch 13.182), train_loss = 1.42496292, grad/param norm = 1.9554e-01, time/batch = 0.6633s	
6869/26050 (epoch 13.184), train_loss = 1.18444759, grad/param norm = 1.6476e-01, time/batch = 0.6611s	
6870/26050 (epoch 13.186), train_loss = 0.97288117, grad/param norm = 1.4753e-01, time/batch = 0.6613s	
6871/26050 (epoch 13.188), train_loss = 1.17286572, grad/param norm = 1.6663e-01, time/batch = 0.6642s	
6872/26050 (epoch 13.190), train_loss = 1.22861750, grad/param norm = 1.7568e-01, time/batch = 0.6548s	
6873/26050 (epoch 13.192), train_loss = 1.21092880, grad/param norm = 1.5915e-01, time/batch = 0.6555s	
6874/26050 (epoch 13.194), train_loss = 1.20189507, grad/param norm = 1.6612e-01, time/batch = 0.6608s	
6875/26050 (epoch 13.196), train_loss = 1.27136524, grad/param norm = 1.8300e-01, time/batch = 0.6600s	
6876/26050 (epoch 13.198), train_loss = 1.09938360, grad/param norm = 1.6448e-01, time/batch = 0.6594s	
6877/26050 (epoch 13.200), train_loss = 1.07471096, grad/param norm = 1.6943e-01, time/batch = 0.6673s	
6878/26050 (epoch 13.202), train_loss = 1.12806193, grad/param norm = 1.7702e-01, time/batch = 0.6696s	
6879/26050 (epoch 13.203), train_loss = 1.27967995, grad/param norm = 1.8366e-01, time/batch = 0.6466s	
6880/26050 (epoch 13.205), train_loss = 1.10074935, grad/param norm = 1.6680e-01, time/batch = 0.6392s	
6881/26050 (epoch 13.207), train_loss = 1.12876631, grad/param norm = 1.6084e-01, time/batch = 0.6396s	
6882/26050 (epoch 13.209), train_loss = 1.16893449, grad/param norm = 1.6160e-01, time/batch = 0.6389s	
6883/26050 (epoch 13.211), train_loss = 1.00406762, grad/param norm = 1.6119e-01, time/batch = 0.6390s	
6884/26050 (epoch 13.213), train_loss = 1.23274263, grad/param norm = 1.8262e-01, time/batch = 0.6439s	
6885/26050 (epoch 13.215), train_loss = 1.16517961, grad/param norm = 1.8285e-01, time/batch = 0.6385s	
6886/26050 (epoch 13.217), train_loss = 1.14963195, grad/param norm = 1.6413e-01, time/batch = 0.6522s	
6887/26050 (epoch 13.219), train_loss = 1.11447801, grad/param norm = 1.7525e-01, time/batch = 0.6498s	
6888/26050 (epoch 13.221), train_loss = 1.04113194, grad/param norm = 1.5719e-01, time/batch = 0.6394s	
6889/26050 (epoch 13.223), train_loss = 1.18843127, grad/param norm = 1.6724e-01, time/batch = 0.6581s	
6890/26050 (epoch 13.225), train_loss = 1.07399526, grad/param norm = 1.7602e-01, time/batch = 0.6830s	
6891/26050 (epoch 13.226), train_loss = 1.26422510, grad/param norm = 1.8001e-01, time/batch = 0.6434s	
6892/26050 (epoch 13.228), train_loss = 1.30749750, grad/param norm = 1.8085e-01, time/batch = 0.6413s	
6893/26050 (epoch 13.230), train_loss = 1.21276948, grad/param norm = 1.6620e-01, time/batch = 0.6413s	
6894/26050 (epoch 13.232), train_loss = 1.29217527, grad/param norm = 1.8275e-01, time/batch = 0.6430s	
6895/26050 (epoch 13.234), train_loss = 1.02979098, grad/param norm = 1.6445e-01, time/batch = 0.6396s	
6896/26050 (epoch 13.236), train_loss = 1.26389543, grad/param norm = 1.7705e-01, time/batch = 0.6414s	
6897/26050 (epoch 13.238), train_loss = 1.00533952, grad/param norm = 1.6112e-01, time/batch = 0.6416s	
6898/26050 (epoch 13.240), train_loss = 1.14699463, grad/param norm = 1.6955e-01, time/batch = 0.6396s	
6899/26050 (epoch 13.242), train_loss = 1.17169232, grad/param norm = 1.5544e-01, time/batch = 0.6397s	
6900/26050 (epoch 13.244), train_loss = 1.18648307, grad/param norm = 1.8385e-01, time/batch = 0.6408s	
6901/26050 (epoch 13.246), train_loss = 1.09894531, grad/param norm = 1.6200e-01, time/batch = 0.6443s	
6902/26050 (epoch 13.248), train_loss = 1.19190261, grad/param norm = 1.6840e-01, time/batch = 0.6456s	
6903/26050 (epoch 13.250), train_loss = 1.17029509, grad/param norm = 1.8053e-01, time/batch = 0.6410s	
6904/26050 (epoch 13.251), train_loss = 1.10137587, grad/param norm = 1.6324e-01, time/batch = 0.6400s	
6905/26050 (epoch 13.253), train_loss = 1.02724761, grad/param norm = 1.6322e-01, time/batch = 0.6400s	
6906/26050 (epoch 13.255), train_loss = 1.37720018, grad/param norm = 1.7192e-01, time/batch = 0.6413s	
6907/26050 (epoch 13.257), train_loss = 1.18212720, grad/param norm = 1.8790e-01, time/batch = 0.6397s	
6908/26050 (epoch 13.259), train_loss = 1.32439757, grad/param norm = 1.7591e-01, time/batch = 0.6438s	
6909/26050 (epoch 13.261), train_loss = 1.07362741, grad/param norm = 1.8574e-01, time/batch = 0.6425s	
6910/26050 (epoch 13.263), train_loss = 1.20324199, grad/param norm = 1.7274e-01, time/batch = 0.6396s	
6911/26050 (epoch 13.265), train_loss = 1.35121955, grad/param norm = 1.8215e-01, time/batch = 0.6426s	
6912/26050 (epoch 13.267), train_loss = 1.26892188, grad/param norm = 1.6877e-01, time/batch = 0.6413s	
6913/26050 (epoch 13.269), train_loss = 1.36076528, grad/param norm = 1.9535e-01, time/batch = 0.6528s	
6914/26050 (epoch 13.271), train_loss = 1.23676278, grad/param norm = 1.8354e-01, time/batch = 0.6524s	
6915/26050 (epoch 13.273), train_loss = 1.13992214, grad/param norm = 1.8495e-01, time/batch = 0.6458s	
6916/26050 (epoch 13.274), train_loss = 1.13585940, grad/param norm = 1.6939e-01, time/batch = 0.6500s	
6917/26050 (epoch 13.276), train_loss = 1.10711923, grad/param norm = 1.7786e-01, time/batch = 0.8048s	
6918/26050 (epoch 13.278), train_loss = 1.30731048, grad/param norm = 1.8222e-01, time/batch = 0.9418s	
6919/26050 (epoch 13.280), train_loss = 1.15901651, grad/param norm = 1.6058e-01, time/batch = 0.9401s	
6920/26050 (epoch 13.282), train_loss = 1.21729862, grad/param norm = 1.8221e-01, time/batch = 0.9410s	
6921/26050 (epoch 13.284), train_loss = 1.11089447, grad/param norm = 1.7320e-01, time/batch = 0.9427s	
6922/26050 (epoch 13.286), train_loss = 1.18678028, grad/param norm = 1.7405e-01, time/batch = 1.1638s	
6923/26050 (epoch 13.288), train_loss = 1.01741606, grad/param norm = 1.6508e-01, time/batch = 1.7524s	
6924/26050 (epoch 13.290), train_loss = 1.15321575, grad/param norm = 1.6395e-01, time/batch = 1.7423s	
6925/26050 (epoch 13.292), train_loss = 1.07723206, grad/param norm = 1.5625e-01, time/batch = 9.4238s	
6926/26050 (epoch 13.294), train_loss = 1.20806933, grad/param norm = 1.8596e-01, time/batch = 16.4801s	
6927/26050 (epoch 13.296), train_loss = 1.30624138, grad/param norm = 1.7485e-01, time/batch = 18.0727s	
6928/26050 (epoch 13.298), train_loss = 1.17954473, grad/param norm = 1.6906e-01, time/batch = 17.7386s	
6929/26050 (epoch 13.299), train_loss = 0.93492611, grad/param norm = 1.4709e-01, time/batch = 16.7471s	
6930/26050 (epoch 13.301), train_loss = 1.08583871, grad/param norm = 1.8070e-01, time/batch = 18.1530s	
6931/26050 (epoch 13.303), train_loss = 1.21101603, grad/param norm = 1.7998e-01, time/batch = 17.5677s	
6932/26050 (epoch 13.305), train_loss = 1.02385560, grad/param norm = 1.8167e-01, time/batch = 16.8351s	
6933/26050 (epoch 13.307), train_loss = 1.09050140, grad/param norm = 1.7389e-01, time/batch = 16.1291s	
6934/26050 (epoch 13.309), train_loss = 1.14815092, grad/param norm = 1.7871e-01, time/batch = 16.2976s	
6935/26050 (epoch 13.311), train_loss = 1.30842520, grad/param norm = 1.8685e-01, time/batch = 18.6505s	
6936/26050 (epoch 13.313), train_loss = 1.16615666, grad/param norm = 1.9260e-01, time/batch = 17.8218s	
6937/26050 (epoch 13.315), train_loss = 1.28305048, grad/param norm = 1.7527e-01, time/batch = 17.3944s	
6938/26050 (epoch 13.317), train_loss = 1.14299787, grad/param norm = 1.6614e-01, time/batch = 18.4910s	
6939/26050 (epoch 13.319), train_loss = 1.12320238, grad/param norm = 1.6709e-01, time/batch = 17.4784s	
6940/26050 (epoch 13.321), train_loss = 1.12679984, grad/param norm = 1.7333e-01, time/batch = 18.0705s	
6941/26050 (epoch 13.322), train_loss = 1.20168635, grad/param norm = 1.7516e-01, time/batch = 18.2322s	
6942/26050 (epoch 13.324), train_loss = 1.00110131, grad/param norm = 1.7375e-01, time/batch = 18.4773s	
6943/26050 (epoch 13.326), train_loss = 1.33798877, grad/param norm = 1.8129e-01, time/batch = 16.7984s	
6944/26050 (epoch 13.328), train_loss = 1.22500086, grad/param norm = 1.6555e-01, time/batch = 16.3905s	
6945/26050 (epoch 13.330), train_loss = 1.07343632, grad/param norm = 1.6992e-01, time/batch = 15.4677s	
6946/26050 (epoch 13.332), train_loss = 1.24764218, grad/param norm = 1.7530e-01, time/batch = 17.3238s	
6947/26050 (epoch 13.334), train_loss = 1.13701228, grad/param norm = 1.7675e-01, time/batch = 18.0742s	
6948/26050 (epoch 13.336), train_loss = 1.08353308, grad/param norm = 1.6077e-01, time/batch = 18.1666s	
6949/26050 (epoch 13.338), train_loss = 1.04566885, grad/param norm = 1.5834e-01, time/batch = 18.4685s	
6950/26050 (epoch 13.340), train_loss = 1.28450339, grad/param norm = 1.8378e-01, time/batch = 18.2940s	
6951/26050 (epoch 13.342), train_loss = 1.33153590, grad/param norm = 1.8912e-01, time/batch = 18.9826s	
6952/26050 (epoch 13.344), train_loss = 1.16082463, grad/param norm = 1.7608e-01, time/batch = 17.1274s	
6953/26050 (epoch 13.345), train_loss = 1.13865003, grad/param norm = 1.6842e-01, time/batch = 17.1440s	
6954/26050 (epoch 13.347), train_loss = 1.26682342, grad/param norm = 1.8977e-01, time/batch = 17.5633s	
6955/26050 (epoch 13.349), train_loss = 1.21776131, grad/param norm = 1.6777e-01, time/batch = 18.8176s	
6956/26050 (epoch 13.351), train_loss = 1.18751927, grad/param norm = 1.7468e-01, time/batch = 16.9814s	
6957/26050 (epoch 13.353), train_loss = 1.14881473, grad/param norm = 1.8142e-01, time/batch = 17.6439s	
6958/26050 (epoch 13.355), train_loss = 1.25308401, grad/param norm = 1.9401e-01, time/batch = 15.4530s	
6959/26050 (epoch 13.357), train_loss = 1.03723682, grad/param norm = 1.5304e-01, time/batch = 18.4968s	
6960/26050 (epoch 13.359), train_loss = 1.24018131, grad/param norm = 1.6844e-01, time/batch = 17.1955s	
6961/26050 (epoch 13.361), train_loss = 1.10831184, grad/param norm = 1.6801e-01, time/batch = 18.3279s	
6962/26050 (epoch 13.363), train_loss = 1.23000416, grad/param norm = 1.6234e-01, time/batch = 15.7279s	
6963/26050 (epoch 13.365), train_loss = 1.13929740, grad/param norm = 1.4940e-01, time/batch = 17.6349s	
6964/26050 (epoch 13.367), train_loss = 1.18491857, grad/param norm = 1.7149e-01, time/batch = 18.4901s	
6965/26050 (epoch 13.369), train_loss = 1.15212860, grad/param norm = 1.5843e-01, time/batch = 17.7413s	
6966/26050 (epoch 13.370), train_loss = 1.06117596, grad/param norm = 1.4928e-01, time/batch = 18.1521s	
6967/26050 (epoch 13.372), train_loss = 1.25351367, grad/param norm = 1.9531e-01, time/batch = 18.5609s	
6968/26050 (epoch 13.374), train_loss = 1.34656127, grad/param norm = 1.8401e-01, time/batch = 18.2379s	
6969/26050 (epoch 13.376), train_loss = 1.38202654, grad/param norm = 1.8243e-01, time/batch = 18.6618s	
6970/26050 (epoch 13.378), train_loss = 1.15018218, grad/param norm = 1.7245e-01, time/batch = 17.6424s	
6971/26050 (epoch 13.380), train_loss = 1.38265996, grad/param norm = 1.9814e-01, time/batch = 15.9701s	
6972/26050 (epoch 13.382), train_loss = 1.51611409, grad/param norm = 2.1029e-01, time/batch = 17.0461s	
6973/26050 (epoch 13.384), train_loss = 1.13404974, grad/param norm = 1.6006e-01, time/batch = 15.6097s	
6974/26050 (epoch 13.386), train_loss = 1.29535627, grad/param norm = 1.9876e-01, time/batch = 33.2572s	
6975/26050 (epoch 13.388), train_loss = 1.21158259, grad/param norm = 1.7039e-01, time/batch = 22.5280s	
6976/26050 (epoch 13.390), train_loss = 1.07457628, grad/param norm = 1.5502e-01, time/batch = 18.0541s	
6977/26050 (epoch 13.392), train_loss = 1.06702162, grad/param norm = 1.5778e-01, time/batch = 18.1237s	
6978/26050 (epoch 13.393), train_loss = 1.21983211, grad/param norm = 1.6482e-01, time/batch = 14.8920s	
6979/26050 (epoch 13.395), train_loss = 1.24345784, grad/param norm = 1.6663e-01, time/batch = 17.3203s	
6980/26050 (epoch 13.397), train_loss = 1.22903037, grad/param norm = 1.8810e-01, time/batch = 18.8865s	
6981/26050 (epoch 13.399), train_loss = 1.06166209, grad/param norm = 1.6018e-01, time/batch = 17.9830s	
6982/26050 (epoch 13.401), train_loss = 1.14906544, grad/param norm = 1.5602e-01, time/batch = 17.4978s	
6983/26050 (epoch 13.403), train_loss = 1.20713189, grad/param norm = 1.5938e-01, time/batch = 18.8177s	
6984/26050 (epoch 13.405), train_loss = 1.16650450, grad/param norm = 1.7349e-01, time/batch = 18.1614s	
6985/26050 (epoch 13.407), train_loss = 1.32212991, grad/param norm = 1.7527e-01, time/batch = 17.7380s	
6986/26050 (epoch 13.409), train_loss = 1.36928306, grad/param norm = 1.8659e-01, time/batch = 17.7290s	
6987/26050 (epoch 13.411), train_loss = 1.22169172, grad/param norm = 1.8465e-01, time/batch = 18.5573s	
6988/26050 (epoch 13.413), train_loss = 1.33823948, grad/param norm = 1.5962e-01, time/batch = 18.5730s	
6989/26050 (epoch 13.415), train_loss = 1.30692049, grad/param norm = 1.9312e-01, time/batch = 17.7232s	
6990/26050 (epoch 13.417), train_loss = 1.41774544, grad/param norm = 1.9328e-01, time/batch = 17.6486s	
6991/26050 (epoch 13.418), train_loss = 1.29810214, grad/param norm = 1.9926e-01, time/batch = 18.9864s	
6992/26050 (epoch 13.420), train_loss = 1.00965281, grad/param norm = 1.5026e-01, time/batch = 17.6568s	
6993/26050 (epoch 13.422), train_loss = 1.04619253, grad/param norm = 1.6505e-01, time/batch = 18.3971s	
6994/26050 (epoch 13.424), train_loss = 1.36473153, grad/param norm = 2.0846e-01, time/batch = 18.1587s	
6995/26050 (epoch 13.426), train_loss = 1.32850109, grad/param norm = 1.8019e-01, time/batch = 14.4881s	
6996/26050 (epoch 13.428), train_loss = 1.10257866, grad/param norm = 1.4973e-01, time/batch = 16.8779s	
6997/26050 (epoch 13.430), train_loss = 1.25766103, grad/param norm = 1.7309e-01, time/batch = 16.9641s	
6998/26050 (epoch 13.432), train_loss = 1.13493388, grad/param norm = 1.6883e-01, time/batch = 15.6572s	
6999/26050 (epoch 13.434), train_loss = 1.20142523, grad/param norm = 1.9278e-01, time/batch = 17.8091s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch13.44_1.6270.t7	
7000/26050 (epoch 13.436), train_loss = 1.30479774, grad/param norm = 1.6336e-01, time/batch = 17.6479s	
7001/26050 (epoch 13.438), train_loss = 1.37651749, grad/param norm = 2.0389e-01, time/batch = 18.2423s	
7002/26050 (epoch 13.440), train_loss = 1.22053689, grad/param norm = 1.6740e-01, time/batch = 18.8269s	
7003/26050 (epoch 13.441), train_loss = 1.20194598, grad/param norm = 1.6058e-01, time/batch = 17.7183s	
7004/26050 (epoch 13.443), train_loss = 1.00498561, grad/param norm = 1.5177e-01, time/batch = 18.5682s	
7005/26050 (epoch 13.445), train_loss = 1.07169210, grad/param norm = 1.5718e-01, time/batch = 18.1544s	
7006/26050 (epoch 13.447), train_loss = 1.37319589, grad/param norm = 1.8869e-01, time/batch = 16.7947s	
7007/26050 (epoch 13.449), train_loss = 1.09571532, grad/param norm = 1.6715e-01, time/batch = 18.0695s	
7008/26050 (epoch 13.451), train_loss = 1.32395058, grad/param norm = 1.7388e-01, time/batch = 17.9910s	
7009/26050 (epoch 13.453), train_loss = 1.10646980, grad/param norm = 1.6388e-01, time/batch = 15.3834s	
7010/26050 (epoch 13.455), train_loss = 1.23927796, grad/param norm = 1.6764e-01, time/batch = 17.3830s	
7011/26050 (epoch 13.457), train_loss = 1.21895007, grad/param norm = 1.7220e-01, time/batch = 16.9542s	
7012/26050 (epoch 13.459), train_loss = 1.30132754, grad/param norm = 1.7118e-01, time/batch = 17.7467s	
7013/26050 (epoch 13.461), train_loss = 1.27687595, grad/param norm = 2.1991e-01, time/batch = 17.9080s	
7014/26050 (epoch 13.463), train_loss = 1.13882806, grad/param norm = 1.6049e-01, time/batch = 17.1541s	
7015/26050 (epoch 13.464), train_loss = 1.25224218, grad/param norm = 1.7471e-01, time/batch = 18.7473s	
7016/26050 (epoch 13.466), train_loss = 1.28611431, grad/param norm = 1.8477e-01, time/batch = 14.5729s	
7017/26050 (epoch 13.468), train_loss = 1.29014535, grad/param norm = 1.6033e-01, time/batch = 17.4791s	
7018/26050 (epoch 13.470), train_loss = 1.40900105, grad/param norm = 2.0323e-01, time/batch = 17.6526s	
7019/26050 (epoch 13.472), train_loss = 1.35612290, grad/param norm = 1.9532e-01, time/batch = 18.3062s	
7020/26050 (epoch 13.474), train_loss = 1.41343340, grad/param norm = 1.8002e-01, time/batch = 17.6500s	
7021/26050 (epoch 13.476), train_loss = 1.30465549, grad/param norm = 1.7436e-01, time/batch = 18.3079s	
7022/26050 (epoch 13.478), train_loss = 1.12881375, grad/param norm = 1.5987e-01, time/batch = 18.7264s	
7023/26050 (epoch 13.480), train_loss = 1.22326536, grad/param norm = 1.6674e-01, time/batch = 17.8984s	
7024/26050 (epoch 13.482), train_loss = 1.15371018, grad/param norm = 1.6565e-01, time/batch = 18.0529s	
7025/26050 (epoch 13.484), train_loss = 1.13334202, grad/param norm = 1.6309e-01, time/batch = 15.8877s	
7026/26050 (epoch 13.486), train_loss = 1.36388206, grad/param norm = 1.7626e-01, time/batch = 18.8196s	
7027/26050 (epoch 13.488), train_loss = 1.51895403, grad/param norm = 1.9695e-01, time/batch = 17.4847s	
7028/26050 (epoch 13.489), train_loss = 1.43007419, grad/param norm = 1.9799e-01, time/batch = 18.2434s	
7029/26050 (epoch 13.491), train_loss = 1.09105918, grad/param norm = 1.5854e-01, time/batch = 16.6234s	
7030/26050 (epoch 13.493), train_loss = 1.19861203, grad/param norm = 1.7227e-01, time/batch = 17.7399s	
7031/26050 (epoch 13.495), train_loss = 1.17334584, grad/param norm = 1.6487e-01, time/batch = 16.5771s	
7032/26050 (epoch 13.497), train_loss = 1.12884093, grad/param norm = 1.6675e-01, time/batch = 18.8445s	
7033/26050 (epoch 13.499), train_loss = 1.15726108, grad/param norm = 1.6679e-01, time/batch = 15.7204s	
7034/26050 (epoch 13.501), train_loss = 1.26978118, grad/param norm = 1.7208e-01, time/batch = 14.5449s	
7035/26050 (epoch 13.503), train_loss = 1.13422095, grad/param norm = 1.8468e-01, time/batch = 17.7258s	
7036/26050 (epoch 13.505), train_loss = 1.32898263, grad/param norm = 1.7668e-01, time/batch = 18.3837s	
7037/26050 (epoch 13.507), train_loss = 1.28667458, grad/param norm = 1.8867e-01, time/batch = 18.0508s	
7038/26050 (epoch 13.509), train_loss = 1.41654458, grad/param norm = 1.8377e-01, time/batch = 17.4697s	
7039/26050 (epoch 13.511), train_loss = 1.09420387, grad/param norm = 1.5186e-01, time/batch = 17.5203s	
7040/26050 (epoch 13.512), train_loss = 1.15565266, grad/param norm = 1.8625e-01, time/batch = 18.9050s	
7041/26050 (epoch 13.514), train_loss = 1.27274757, grad/param norm = 1.7856e-01, time/batch = 18.0465s	
7042/26050 (epoch 13.516), train_loss = 1.29715220, grad/param norm = 1.7616e-01, time/batch = 18.1331s	
7043/26050 (epoch 13.518), train_loss = 1.26769439, grad/param norm = 1.8678e-01, time/batch = 15.7226s	
7044/26050 (epoch 13.520), train_loss = 1.18952186, grad/param norm = 1.6359e-01, time/batch = 16.6405s	
7045/26050 (epoch 13.522), train_loss = 1.00263254, grad/param norm = 1.5928e-01, time/batch = 15.3921s	
7046/26050 (epoch 13.524), train_loss = 1.32803265, grad/param norm = 1.8771e-01, time/batch = 17.8127s	
7047/26050 (epoch 13.526), train_loss = 1.31569853, grad/param norm = 1.8320e-01, time/batch = 18.4904s	
7048/26050 (epoch 13.528), train_loss = 1.25725051, grad/param norm = 1.7311e-01, time/batch = 18.1496s	
7049/26050 (epoch 13.530), train_loss = 1.19735954, grad/param norm = 1.6631e-01, time/batch = 18.3980s	
7050/26050 (epoch 13.532), train_loss = 1.18717882, grad/param norm = 1.5179e-01, time/batch = 18.1473s	
7051/26050 (epoch 13.534), train_loss = 1.28023385, grad/param norm = 1.8927e-01, time/batch = 17.3889s	
7052/26050 (epoch 13.536), train_loss = 1.18653706, grad/param norm = 1.6263e-01, time/batch = 17.8257s	
7053/26050 (epoch 13.537), train_loss = 1.31951907, grad/param norm = 1.9865e-01, time/batch = 18.1584s	
7054/26050 (epoch 13.539), train_loss = 1.20151294, grad/param norm = 1.7303e-01, time/batch = 17.3177s	
7055/26050 (epoch 13.541), train_loss = 1.39882498, grad/param norm = 1.9144e-01, time/batch = 18.5536s	
7056/26050 (epoch 13.543), train_loss = 1.03224076, grad/param norm = 1.6773e-01, time/batch = 18.8122s	
7057/26050 (epoch 13.545), train_loss = 1.24737804, grad/param norm = 1.7131e-01, time/batch = 18.3208s	
7058/26050 (epoch 13.547), train_loss = 1.21724577, grad/param norm = 1.6950e-01, time/batch = 16.5425s	
7059/26050 (epoch 13.549), train_loss = 0.99630601, grad/param norm = 1.4924e-01, time/batch = 18.4129s	
7060/26050 (epoch 13.551), train_loss = 1.23240874, grad/param norm = 1.7542e-01, time/batch = 18.3223s	
7061/26050 (epoch 13.553), train_loss = 1.10824761, grad/param norm = 1.5656e-01, time/batch = 17.6542s	
7062/26050 (epoch 13.555), train_loss = 1.14574132, grad/param norm = 1.7042e-01, time/batch = 16.9637s	
7063/26050 (epoch 13.557), train_loss = 1.25445823, grad/param norm = 1.5751e-01, time/batch = 17.6481s	
7064/26050 (epoch 13.559), train_loss = 1.19784546, grad/param norm = 1.6652e-01, time/batch = 15.3053s	
7065/26050 (epoch 13.560), train_loss = 1.18535510, grad/param norm = 1.7728e-01, time/batch = 15.0525s	
7066/26050 (epoch 13.562), train_loss = 1.18363265, grad/param norm = 1.7859e-01, time/batch = 18.7355s	
7067/26050 (epoch 13.564), train_loss = 1.39966865, grad/param norm = 1.7585e-01, time/batch = 18.5641s	
7068/26050 (epoch 13.566), train_loss = 1.08230045, grad/param norm = 1.6275e-01, time/batch = 16.8006s	
7069/26050 (epoch 13.568), train_loss = 1.22590185, grad/param norm = 1.6194e-01, time/batch = 18.2474s	
7070/26050 (epoch 13.570), train_loss = 1.30654481, grad/param norm = 1.7909e-01, time/batch = 18.4920s	
7071/26050 (epoch 13.572), train_loss = 1.17778116, grad/param norm = 1.8285e-01, time/batch = 17.7220s	
7072/26050 (epoch 13.574), train_loss = 1.27347773, grad/param norm = 1.9691e-01, time/batch = 18.5603s	
7073/26050 (epoch 13.576), train_loss = 1.25596406, grad/param norm = 1.8358e-01, time/batch = 16.9806s	
7074/26050 (epoch 13.578), train_loss = 1.20337318, grad/param norm = 1.7600e-01, time/batch = 17.9704s	
7075/26050 (epoch 13.580), train_loss = 1.10514428, grad/param norm = 1.7835e-01, time/batch = 17.4909s	
7076/26050 (epoch 13.582), train_loss = 1.24725416, grad/param norm = 1.7556e-01, time/batch = 16.2278s	
7077/26050 (epoch 13.583), train_loss = 1.28876551, grad/param norm = 1.7156e-01, time/batch = 18.7421s	
7078/26050 (epoch 13.585), train_loss = 1.10213545, grad/param norm = 1.7277e-01, time/batch = 14.9045s	
7079/26050 (epoch 13.587), train_loss = 1.23960314, grad/param norm = 1.8051e-01, time/batch = 18.1461s	
7080/26050 (epoch 13.589), train_loss = 1.33222125, grad/param norm = 2.0668e-01, time/batch = 17.4877s	
7081/26050 (epoch 13.591), train_loss = 1.20311185, grad/param norm = 1.7023e-01, time/batch = 16.9720s	
7082/26050 (epoch 13.593), train_loss = 1.08021886, grad/param norm = 1.7636e-01, time/batch = 18.1433s	
7083/26050 (epoch 13.595), train_loss = 1.33149854, grad/param norm = 2.0218e-01, time/batch = 17.7380s	
7084/26050 (epoch 13.597), train_loss = 1.23327266, grad/param norm = 1.7342e-01, time/batch = 18.8271s	
7085/26050 (epoch 13.599), train_loss = 1.17624837, grad/param norm = 1.6731e-01, time/batch = 17.5639s	
7086/26050 (epoch 13.601), train_loss = 1.40477333, grad/param norm = 1.8133e-01, time/batch = 18.1529s	
7087/26050 (epoch 13.603), train_loss = 1.26748458, grad/param norm = 1.7872e-01, time/batch = 17.1592s	
7088/26050 (epoch 13.605), train_loss = 1.13830608, grad/param norm = 1.5728e-01, time/batch = 16.9538s	
7089/26050 (epoch 13.607), train_loss = 1.34599308, grad/param norm = 1.9010e-01, time/batch = 18.0858s	
7090/26050 (epoch 13.608), train_loss = 1.08793026, grad/param norm = 1.5453e-01, time/batch = 17.6500s	
7091/26050 (epoch 13.610), train_loss = 1.18347185, grad/param norm = 1.7553e-01, time/batch = 18.3927s	
7092/26050 (epoch 13.612), train_loss = 1.20508897, grad/param norm = 1.7827e-01, time/batch = 17.3290s	
7093/26050 (epoch 13.614), train_loss = 1.28713547, grad/param norm = 1.7993e-01, time/batch = 17.7353s	
7094/26050 (epoch 13.616), train_loss = 1.41686342, grad/param norm = 1.9482e-01, time/batch = 15.9734s	
7095/26050 (epoch 13.618), train_loss = 1.14678507, grad/param norm = 1.7595e-01, time/batch = 15.5500s	
7096/26050 (epoch 13.620), train_loss = 1.23103811, grad/param norm = 1.7501e-01, time/batch = 17.6506s	
7097/26050 (epoch 13.622), train_loss = 1.04277925, grad/param norm = 1.5278e-01, time/batch = 18.6349s	
7098/26050 (epoch 13.624), train_loss = 1.06919414, grad/param norm = 1.6417e-01, time/batch = 16.0511s	
7099/26050 (epoch 13.626), train_loss = 1.26203429, grad/param norm = 1.6754e-01, time/batch = 17.6528s	
7100/26050 (epoch 13.628), train_loss = 1.15076377, grad/param norm = 1.7792e-01, time/batch = 18.3253s	
7101/26050 (epoch 13.630), train_loss = 1.34692684, grad/param norm = 1.7376e-01, time/batch = 18.3167s	
7102/26050 (epoch 13.631), train_loss = 1.37205024, grad/param norm = 1.8741e-01, time/batch = 16.1298s	
7103/26050 (epoch 13.633), train_loss = 1.12427729, grad/param norm = 1.7510e-01, time/batch = 17.7435s	
7104/26050 (epoch 13.635), train_loss = 1.11811032, grad/param norm = 1.5367e-01, time/batch = 17.8010s	
7105/26050 (epoch 13.637), train_loss = 1.09349239, grad/param norm = 1.7284e-01, time/batch = 17.4787s	
7106/26050 (epoch 13.639), train_loss = 1.32191096, grad/param norm = 1.7320e-01, time/batch = 17.5739s	
7107/26050 (epoch 13.641), train_loss = 1.15439872, grad/param norm = 1.6282e-01, time/batch = 18.2410s	
7108/26050 (epoch 13.643), train_loss = 1.05789621, grad/param norm = 1.5136e-01, time/batch = 18.0618s	
7109/26050 (epoch 13.645), train_loss = 1.23592503, grad/param norm = 1.8108e-01, time/batch = 17.8082s	
7110/26050 (epoch 13.647), train_loss = 1.15739221, grad/param norm = 1.6899e-01, time/batch = 17.8119s	
7111/26050 (epoch 13.649), train_loss = 1.21917588, grad/param norm = 1.9421e-01, time/batch = 18.3175s	
7112/26050 (epoch 13.651), train_loss = 1.13282708, grad/param norm = 1.7733e-01, time/batch = 15.6281s	
7113/26050 (epoch 13.653), train_loss = 1.20730506, grad/param norm = 1.6959e-01, time/batch = 17.3781s	
7114/26050 (epoch 13.655), train_loss = 1.12371619, grad/param norm = 1.6166e-01, time/batch = 15.8201s	
7115/26050 (epoch 13.656), train_loss = 1.05488871, grad/param norm = 1.7629e-01, time/batch = 18.4798s	
7116/26050 (epoch 13.658), train_loss = 1.39134020, grad/param norm = 1.8372e-01, time/batch = 17.3103s	
7117/26050 (epoch 13.660), train_loss = 1.07769637, grad/param norm = 1.6157e-01, time/batch = 15.6480s	
7118/26050 (epoch 13.662), train_loss = 1.08374780, grad/param norm = 1.5314e-01, time/batch = 18.2339s	
7119/26050 (epoch 13.664), train_loss = 1.17486183, grad/param norm = 1.7623e-01, time/batch = 14.9639s	
7120/26050 (epoch 13.666), train_loss = 1.18596365, grad/param norm = 1.7898e-01, time/batch = 16.2110s	
7121/26050 (epoch 13.668), train_loss = 1.00087316, grad/param norm = 1.5821e-01, time/batch = 17.9843s	
7122/26050 (epoch 13.670), train_loss = 1.37248163, grad/param norm = 1.9452e-01, time/batch = 17.9824s	
7123/26050 (epoch 13.672), train_loss = 1.15147322, grad/param norm = 1.7132e-01, time/batch = 15.7410s	
7124/26050 (epoch 13.674), train_loss = 1.08108054, grad/param norm = 1.6662e-01, time/batch = 18.0615s	
7125/26050 (epoch 13.676), train_loss = 1.20881983, grad/param norm = 1.7427e-01, time/batch = 18.3971s	
7126/26050 (epoch 13.678), train_loss = 1.32946704, grad/param norm = 1.7820e-01, time/batch = 17.0672s	
7127/26050 (epoch 13.679), train_loss = 1.41067459, grad/param norm = 1.9343e-01, time/batch = 16.1247s	
7128/26050 (epoch 13.681), train_loss = 1.21053297, grad/param norm = 1.7134e-01, time/batch = 18.2324s	
7129/26050 (epoch 13.683), train_loss = 1.09910363, grad/param norm = 2.0439e-01, time/batch = 18.2365s	
7130/26050 (epoch 13.685), train_loss = 1.15827761, grad/param norm = 1.6622e-01, time/batch = 18.5470s	
7131/26050 (epoch 13.687), train_loss = 1.01074855, grad/param norm = 1.6394e-01, time/batch = 17.6675s	
7132/26050 (epoch 13.689), train_loss = 1.16257154, grad/param norm = 1.7267e-01, time/batch = 18.7472s	
7133/26050 (epoch 13.691), train_loss = 0.93371282, grad/param norm = 1.5377e-01, time/batch = 17.4040s	
7134/26050 (epoch 13.693), train_loss = 1.09621526, grad/param norm = 1.6926e-01, time/batch = 15.2205s	
7135/26050 (epoch 13.695), train_loss = 1.20334007, grad/param norm = 1.7385e-01, time/batch = 18.2371s	
7136/26050 (epoch 13.697), train_loss = 1.08924646, grad/param norm = 1.6933e-01, time/batch = 17.2302s	
7137/26050 (epoch 13.699), train_loss = 1.25681873, grad/param norm = 1.8502e-01, time/batch = 14.6118s	
7138/26050 (epoch 13.701), train_loss = 1.05469627, grad/param norm = 1.5542e-01, time/batch = 18.7233s	
7139/26050 (epoch 13.702), train_loss = 1.37707523, grad/param norm = 1.9371e-01, time/batch = 18.4674s	
7140/26050 (epoch 13.704), train_loss = 1.23845734, grad/param norm = 1.6539e-01, time/batch = 16.3860s	
7141/26050 (epoch 13.706), train_loss = 1.23472536, grad/param norm = 2.0165e-01, time/batch = 18.1321s	
7142/26050 (epoch 13.708), train_loss = 1.28450160, grad/param norm = 1.7981e-01, time/batch = 18.3119s	
7143/26050 (epoch 13.710), train_loss = 1.25990404, grad/param norm = 1.7802e-01, time/batch = 17.5499s	
7144/26050 (epoch 13.712), train_loss = 1.31309806, grad/param norm = 1.8425e-01, time/batch = 17.5710s	
7145/26050 (epoch 13.714), train_loss = 1.03323051, grad/param norm = 1.7071e-01, time/batch = 18.4780s	
7146/26050 (epoch 13.716), train_loss = 1.46215772, grad/param norm = 2.0376e-01, time/batch = 17.1527s	
7147/26050 (epoch 13.718), train_loss = 1.31138261, grad/param norm = 1.8526e-01, time/batch = 17.9017s	
7148/26050 (epoch 13.720), train_loss = 1.13592314, grad/param norm = 1.7201e-01, time/batch = 15.2396s	
7149/26050 (epoch 13.722), train_loss = 1.06943184, grad/param norm = 1.6721e-01, time/batch = 18.9052s	
7150/26050 (epoch 13.724), train_loss = 1.08848330, grad/param norm = 1.7743e-01, time/batch = 17.2332s	
7151/26050 (epoch 13.726), train_loss = 1.31869031, grad/param norm = 1.8401e-01, time/batch = 15.8092s	
7152/26050 (epoch 13.727), train_loss = 1.25468160, grad/param norm = 1.7090e-01, time/batch = 18.4871s	
7153/26050 (epoch 13.729), train_loss = 1.25099333, grad/param norm = 1.7513e-01, time/batch = 17.4869s	
7154/26050 (epoch 13.731), train_loss = 1.22659454, grad/param norm = 1.6202e-01, time/batch = 16.9877s	
7155/26050 (epoch 13.733), train_loss = 1.16494699, grad/param norm = 2.0261e-01, time/batch = 17.3267s	
7156/26050 (epoch 13.735), train_loss = 1.38936391, grad/param norm = 1.9134e-01, time/batch = 18.4267s	
7157/26050 (epoch 13.737), train_loss = 1.18816247, grad/param norm = 1.6871e-01, time/batch = 15.0523s	
7158/26050 (epoch 13.739), train_loss = 1.25761471, grad/param norm = 1.6791e-01, time/batch = 14.9508s	
7159/26050 (epoch 13.741), train_loss = 1.12258719, grad/param norm = 1.7629e-01, time/batch = 18.3273s	
7160/26050 (epoch 13.743), train_loss = 1.24494618, grad/param norm = 1.9410e-01, time/batch = 17.8342s	
7161/26050 (epoch 13.745), train_loss = 1.08526499, grad/param norm = 1.7367e-01, time/batch = 17.7456s	
7162/26050 (epoch 13.747), train_loss = 1.09326762, grad/param norm = 1.5586e-01, time/batch = 18.4948s	
7163/26050 (epoch 13.749), train_loss = 1.34864364, grad/param norm = 1.8559e-01, time/batch = 18.8246s	
7164/26050 (epoch 13.750), train_loss = 1.19365582, grad/param norm = 1.5702e-01, time/batch = 17.7336s	
7165/26050 (epoch 13.752), train_loss = 1.17795738, grad/param norm = 2.0640e-01, time/batch = 17.1502s	
7166/26050 (epoch 13.754), train_loss = 1.21672903, grad/param norm = 1.7339e-01, time/batch = 16.3045s	
7167/26050 (epoch 13.756), train_loss = 1.19966592, grad/param norm = 1.8052e-01, time/batch = 15.7224s	
7168/26050 (epoch 13.758), train_loss = 1.21012266, grad/param norm = 1.7763e-01, time/batch = 18.1503s	
7169/26050 (epoch 13.760), train_loss = 1.33427256, grad/param norm = 1.7442e-01, time/batch = 17.4125s	
7170/26050 (epoch 13.762), train_loss = 1.12081866, grad/param norm = 1.6358e-01, time/batch = 15.5622s	
7171/26050 (epoch 13.764), train_loss = 1.25661941, grad/param norm = 1.7557e-01, time/batch = 28.5946s	
7172/26050 (epoch 13.766), train_loss = 1.28669682, grad/param norm = 1.9203e-01, time/batch = 28.0236s	
7173/26050 (epoch 13.768), train_loss = 1.07989405, grad/param norm = 1.5245e-01, time/batch = 17.0539s	
7174/26050 (epoch 13.770), train_loss = 1.17496733, grad/param norm = 1.8566e-01, time/batch = 15.7171s	
7175/26050 (epoch 13.772), train_loss = 1.17411195, grad/param norm = 1.6246e-01, time/batch = 17.8014s	
7176/26050 (epoch 13.774), train_loss = 1.05012225, grad/param norm = 1.7129e-01, time/batch = 17.8158s	
7177/26050 (epoch 13.775), train_loss = 0.89875669, grad/param norm = 1.6083e-01, time/batch = 17.7437s	
7178/26050 (epoch 13.777), train_loss = 1.10479208, grad/param norm = 1.6255e-01, time/batch = 15.3699s	
7179/26050 (epoch 13.779), train_loss = 1.16492508, grad/param norm = 1.7533e-01, time/batch = 16.1494s	
7180/26050 (epoch 13.781), train_loss = 1.13756519, grad/param norm = 1.7288e-01, time/batch = 17.9843s	
7181/26050 (epoch 13.783), train_loss = 1.09886173, grad/param norm = 1.6697e-01, time/batch = 18.7340s	
7182/26050 (epoch 13.785), train_loss = 1.15818488, grad/param norm = 1.7204e-01, time/batch = 18.4922s	
7183/26050 (epoch 13.787), train_loss = 1.12477235, grad/param norm = 1.6990e-01, time/batch = 17.5709s	
7184/26050 (epoch 13.789), train_loss = 1.12533024, grad/param norm = 1.9590e-01, time/batch = 17.9870s	
7185/26050 (epoch 13.791), train_loss = 1.15880475, grad/param norm = 1.6655e-01, time/batch = 17.6588s	
7186/26050 (epoch 13.793), train_loss = 1.17052977, grad/param norm = 1.8971e-01, time/batch = 18.6609s	
7187/26050 (epoch 13.795), train_loss = 1.01364442, grad/param norm = 1.5547e-01, time/batch = 16.9609s	
7188/26050 (epoch 13.797), train_loss = 1.10452751, grad/param norm = 1.6538e-01, time/batch = 17.0517s	
7189/26050 (epoch 13.798), train_loss = 1.04582368, grad/param norm = 1.6590e-01, time/batch = 18.2416s	
7190/26050 (epoch 13.800), train_loss = 1.03347142, grad/param norm = 1.4786e-01, time/batch = 16.5682s	
7191/26050 (epoch 13.802), train_loss = 1.15558712, grad/param norm = 1.8170e-01, time/batch = 17.8337s	
7192/26050 (epoch 13.804), train_loss = 1.14575934, grad/param norm = 1.6907e-01, time/batch = 18.3354s	
7193/26050 (epoch 13.806), train_loss = 1.26777471, grad/param norm = 1.7603e-01, time/batch = 17.9088s	
7194/26050 (epoch 13.808), train_loss = 1.15102680, grad/param norm = 1.6434e-01, time/batch = 17.8947s	
7195/26050 (epoch 13.810), train_loss = 1.11638812, grad/param norm = 1.7781e-01, time/batch = 14.6510s	
7196/26050 (epoch 13.812), train_loss = 1.05589067, grad/param norm = 1.7851e-01, time/batch = 18.5758s	
7197/26050 (epoch 13.814), train_loss = 1.06475556, grad/param norm = 1.9387e-01, time/batch = 17.0760s	
7198/26050 (epoch 13.816), train_loss = 1.28484977, grad/param norm = 1.8260e-01, time/batch = 16.9832s	
7199/26050 (epoch 13.818), train_loss = 1.33718780, grad/param norm = 2.0754e-01, time/batch = 18.7388s	
7200/26050 (epoch 13.820), train_loss = 1.19609425, grad/param norm = 1.7592e-01, time/batch = 17.6571s	
7201/26050 (epoch 13.821), train_loss = 1.33678690, grad/param norm = 1.9402e-01, time/batch = 16.8664s	
7202/26050 (epoch 13.823), train_loss = 1.36394598, grad/param norm = 1.9082e-01, time/batch = 18.1453s	
7203/26050 (epoch 13.825), train_loss = 1.17170372, grad/param norm = 1.7826e-01, time/batch = 18.7347s	
7204/26050 (epoch 13.827), train_loss = 1.22243408, grad/param norm = 1.9709e-01, time/batch = 18.6378s	
7205/26050 (epoch 13.829), train_loss = 1.23680028, grad/param norm = 1.7518e-01, time/batch = 18.0782s	
7206/26050 (epoch 13.831), train_loss = 1.31231016, grad/param norm = 1.7453e-01, time/batch = 18.5777s	
7207/26050 (epoch 13.833), train_loss = 1.38341025, grad/param norm = 1.8352e-01, time/batch = 16.6625s	
7208/26050 (epoch 13.835), train_loss = 1.40849973, grad/param norm = 1.8825e-01, time/batch = 18.4010s	
7209/26050 (epoch 13.837), train_loss = 1.17261763, grad/param norm = 1.8573e-01, time/batch = 16.1394s	
7210/26050 (epoch 13.839), train_loss = 1.23086940, grad/param norm = 2.0662e-01, time/batch = 17.4860s	
7211/26050 (epoch 13.841), train_loss = 1.29903888, grad/param norm = 1.7679e-01, time/batch = 17.3112s	
7212/26050 (epoch 13.843), train_loss = 1.20116211, grad/param norm = 1.8083e-01, time/batch = 15.1353s	
7213/26050 (epoch 13.845), train_loss = 1.10698002, grad/param norm = 1.5480e-01, time/batch = 15.7960s	
7214/26050 (epoch 13.846), train_loss = 1.29850103, grad/param norm = 1.7201e-01, time/batch = 14.9604s	
7215/26050 (epoch 13.848), train_loss = 1.15271277, grad/param norm = 1.6041e-01, time/batch = 18.0578s	
7216/26050 (epoch 13.850), train_loss = 1.11525638, grad/param norm = 1.7111e-01, time/batch = 18.8223s	
7217/26050 (epoch 13.852), train_loss = 1.15775106, grad/param norm = 1.6744e-01, time/batch = 17.3244s	
7218/26050 (epoch 13.854), train_loss = 1.16478412, grad/param norm = 1.6443e-01, time/batch = 18.0527s	
7219/26050 (epoch 13.856), train_loss = 1.14045153, grad/param norm = 1.8564e-01, time/batch = 18.8092s	
7220/26050 (epoch 13.858), train_loss = 1.07624324, grad/param norm = 1.6702e-01, time/batch = 18.4980s	
7221/26050 (epoch 13.860), train_loss = 1.23910750, grad/param norm = 1.7997e-01, time/batch = 15.2124s	
7222/26050 (epoch 13.862), train_loss = 1.22323338, grad/param norm = 1.7528e-01, time/batch = 18.0697s	
7223/26050 (epoch 13.864), train_loss = 1.21780527, grad/param norm = 1.9705e-01, time/batch = 18.6465s	
7224/26050 (epoch 13.866), train_loss = 1.12227575, grad/param norm = 1.5975e-01, time/batch = 17.3288s	
7225/26050 (epoch 13.868), train_loss = 1.27128338, grad/param norm = 1.9131e-01, time/batch = 18.3265s	
7226/26050 (epoch 13.869), train_loss = 1.07651128, grad/param norm = 1.5468e-01, time/batch = 16.9187s	
7227/26050 (epoch 13.871), train_loss = 1.02476635, grad/param norm = 1.6402e-01, time/batch = 17.3891s	
7228/26050 (epoch 13.873), train_loss = 1.24526568, grad/param norm = 1.7412e-01, time/batch = 17.4908s	
7229/26050 (epoch 13.875), train_loss = 1.17687024, grad/param norm = 1.7543e-01, time/batch = 18.2425s	
7230/26050 (epoch 13.877), train_loss = 1.06466732, grad/param norm = 1.6448e-01, time/batch = 18.6666s	
7231/26050 (epoch 13.879), train_loss = 1.18554095, grad/param norm = 1.5761e-01, time/batch = 17.5650s	
7232/26050 (epoch 13.881), train_loss = 1.32632486, grad/param norm = 1.8168e-01, time/batch = 17.8158s	
7233/26050 (epoch 13.883), train_loss = 1.23300616, grad/param norm = 1.8276e-01, time/batch = 16.6457s	
7234/26050 (epoch 13.885), train_loss = 0.93080185, grad/param norm = 1.5380e-01, time/batch = 17.3094s	
7235/26050 (epoch 13.887), train_loss = 1.22060307, grad/param norm = 1.7590e-01, time/batch = 15.7878s	
7236/26050 (epoch 13.889), train_loss = 1.13394235, grad/param norm = 1.6171e-01, time/batch = 16.3829s	
7237/26050 (epoch 13.891), train_loss = 0.94179782, grad/param norm = 1.4976e-01, time/batch = 17.3988s	
7238/26050 (epoch 13.893), train_loss = 0.96598952, grad/param norm = 1.5804e-01, time/batch = 17.3072s	
7239/26050 (epoch 13.894), train_loss = 1.14733999, grad/param norm = 1.6932e-01, time/batch = 17.9743s	
7240/26050 (epoch 13.896), train_loss = 1.29721590, grad/param norm = 1.7305e-01, time/batch = 18.3210s	
7241/26050 (epoch 13.898), train_loss = 1.11733121, grad/param norm = 1.7814e-01, time/batch = 17.9981s	
7242/26050 (epoch 13.900), train_loss = 1.27422756, grad/param norm = 1.7722e-01, time/batch = 17.9901s	
7243/26050 (epoch 13.902), train_loss = 1.17961018, grad/param norm = 1.8156e-01, time/batch = 16.2296s	
7244/26050 (epoch 13.904), train_loss = 1.15086100, grad/param norm = 1.6581e-01, time/batch = 17.3976s	
7245/26050 (epoch 13.906), train_loss = 1.16734819, grad/param norm = 1.8463e-01, time/batch = 18.2247s	
7246/26050 (epoch 13.908), train_loss = 1.15132787, grad/param norm = 1.6820e-01, time/batch = 18.3982s	
7247/26050 (epoch 13.910), train_loss = 1.08359006, grad/param norm = 1.5266e-01, time/batch = 17.8258s	
7248/26050 (epoch 13.912), train_loss = 1.42673900, grad/param norm = 1.9492e-01, time/batch = 16.4073s	
7249/26050 (epoch 13.914), train_loss = 1.55487559, grad/param norm = 2.0263e-01, time/batch = 17.8847s	
7250/26050 (epoch 13.916), train_loss = 1.29264790, grad/param norm = 1.8881e-01, time/batch = 18.5678s	
7251/26050 (epoch 13.917), train_loss = 1.20279598, grad/param norm = 2.0367e-01, time/batch = 17.9708s	
7252/26050 (epoch 13.919), train_loss = 1.27595040, grad/param norm = 1.8755e-01, time/batch = 17.7981s	
7253/26050 (epoch 13.921), train_loss = 1.13072709, grad/param norm = 1.7966e-01, time/batch = 18.4064s	
7254/26050 (epoch 13.923), train_loss = 1.20098675, grad/param norm = 1.8112e-01, time/batch = 17.8137s	
7255/26050 (epoch 13.925), train_loss = 1.18775875, grad/param norm = 1.7421e-01, time/batch = 15.9511s	
7256/26050 (epoch 13.927), train_loss = 1.06001080, grad/param norm = 1.5406e-01, time/batch = 16.3008s	
7257/26050 (epoch 13.929), train_loss = 1.08984729, grad/param norm = 1.6663e-01, time/batch = 18.4088s	
7258/26050 (epoch 13.931), train_loss = 1.38480212, grad/param norm = 1.9693e-01, time/batch = 16.9784s	
7259/26050 (epoch 13.933), train_loss = 1.15526414, grad/param norm = 1.8592e-01, time/batch = 15.1323s	
7260/26050 (epoch 13.935), train_loss = 1.13124544, grad/param norm = 1.6376e-01, time/batch = 18.5655s	
7261/26050 (epoch 13.937), train_loss = 1.25745607, grad/param norm = 1.7556e-01, time/batch = 15.9616s	
7262/26050 (epoch 13.939), train_loss = 1.06905628, grad/param norm = 1.4171e-01, time/batch = 17.0635s	
7263/26050 (epoch 13.940), train_loss = 1.18919977, grad/param norm = 1.6196e-01, time/batch = 18.5859s	
7264/26050 (epoch 13.942), train_loss = 1.21640345, grad/param norm = 1.8526e-01, time/batch = 16.2432s	
7265/26050 (epoch 13.944), train_loss = 1.13927692, grad/param norm = 1.6867e-01, time/batch = 17.0652s	
7266/26050 (epoch 13.946), train_loss = 1.35534256, grad/param norm = 1.8787e-01, time/batch = 18.7373s	
7267/26050 (epoch 13.948), train_loss = 1.01523783, grad/param norm = 1.8698e-01, time/batch = 14.9836s	
7268/26050 (epoch 13.950), train_loss = 1.18001958, grad/param norm = 1.8490e-01, time/batch = 18.7323s	
7269/26050 (epoch 13.952), train_loss = 1.31117156, grad/param norm = 1.9116e-01, time/batch = 17.3947s	
7270/26050 (epoch 13.954), train_loss = 1.28202422, grad/param norm = 1.8245e-01, time/batch = 18.1487s	
7271/26050 (epoch 13.956), train_loss = 1.18661589, grad/param norm = 1.7884e-01, time/batch = 18.0849s	
7272/26050 (epoch 13.958), train_loss = 1.14465782, grad/param norm = 1.7309e-01, time/batch = 14.4758s	
7273/26050 (epoch 13.960), train_loss = 1.17754212, grad/param norm = 1.7516e-01, time/batch = 13.9708s	
7274/26050 (epoch 13.962), train_loss = 1.11913972, grad/param norm = 1.6504e-01, time/batch = 13.9274s	
7275/26050 (epoch 13.964), train_loss = 1.17858926, grad/param norm = 1.7393e-01, time/batch = 14.1495s	
7276/26050 (epoch 13.965), train_loss = 1.09294966, grad/param norm = 1.7928e-01, time/batch = 16.6371s	
7277/26050 (epoch 13.967), train_loss = 1.48158452, grad/param norm = 1.7978e-01, time/batch = 17.7951s	
7278/26050 (epoch 13.969), train_loss = 1.17827528, grad/param norm = 1.6649e-01, time/batch = 18.7206s	
7279/26050 (epoch 13.971), train_loss = 1.10370447, grad/param norm = 1.5239e-01, time/batch = 18.4015s	
7280/26050 (epoch 13.973), train_loss = 1.15368433, grad/param norm = 1.9353e-01, time/batch = 17.5810s	
7281/26050 (epoch 13.975), train_loss = 1.24670468, grad/param norm = 1.6295e-01, time/batch = 17.7403s	
7282/26050 (epoch 13.977), train_loss = 1.22047416, grad/param norm = 1.6373e-01, time/batch = 18.8963s	
7283/26050 (epoch 13.979), train_loss = 1.02358097, grad/param norm = 1.6759e-01, time/batch = 17.3933s	
7284/26050 (epoch 13.981), train_loss = 1.31540021, grad/param norm = 1.6699e-01, time/batch = 15.3954s	
7285/26050 (epoch 13.983), train_loss = 1.29408273, grad/param norm = 1.7330e-01, time/batch = 18.4013s	
7286/26050 (epoch 13.985), train_loss = 1.22606302, grad/param norm = 1.8068e-01, time/batch = 18.0636s	
7287/26050 (epoch 13.987), train_loss = 1.32529391, grad/param norm = 1.9157e-01, time/batch = 17.1445s	
7288/26050 (epoch 13.988), train_loss = 1.28444223, grad/param norm = 1.6988e-01, time/batch = 15.4026s	
7289/26050 (epoch 13.990), train_loss = 1.07867831, grad/param norm = 1.5114e-01, time/batch = 18.4626s	
7290/26050 (epoch 13.992), train_loss = 1.33224918, grad/param norm = 1.8588e-01, time/batch = 16.8123s	
7291/26050 (epoch 13.994), train_loss = 1.20434981, grad/param norm = 1.8787e-01, time/batch = 18.4062s	
7292/26050 (epoch 13.996), train_loss = 1.14163780, grad/param norm = 1.7650e-01, time/batch = 16.3811s	
7293/26050 (epoch 13.998), train_loss = 1.19094885, grad/param norm = 1.7350e-01, time/batch = 17.6538s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
7294/26050 (epoch 14.000), train_loss = 1.14041669, grad/param norm = 1.7879e-01, time/batch = 17.9083s	
7295/26050 (epoch 14.002), train_loss = 1.27624814, grad/param norm = 1.9577e-01, time/batch = 18.1686s	
7296/26050 (epoch 14.004), train_loss = 1.08238057, grad/param norm = 1.7264e-01, time/batch = 17.9847s	
7297/26050 (epoch 14.006), train_loss = 1.09896481, grad/param norm = 1.6568e-01, time/batch = 18.0794s	
7298/26050 (epoch 14.008), train_loss = 1.08314148, grad/param norm = 1.7475e-01, time/batch = 15.2320s	
7299/26050 (epoch 14.010), train_loss = 1.11693785, grad/param norm = 1.6400e-01, time/batch = 17.9118s	
7300/26050 (epoch 14.012), train_loss = 1.20254531, grad/param norm = 1.7157e-01, time/batch = 16.6132s	
7301/26050 (epoch 14.013), train_loss = 1.56358082, grad/param norm = 2.0088e-01, time/batch = 16.2280s	
7302/26050 (epoch 14.015), train_loss = 1.09829705, grad/param norm = 1.5010e-01, time/batch = 17.3855s	
7303/26050 (epoch 14.017), train_loss = 1.19766233, grad/param norm = 1.8376e-01, time/batch = 17.8367s	
7304/26050 (epoch 14.019), train_loss = 1.00325029, grad/param norm = 1.4550e-01, time/batch = 18.0774s	
7305/26050 (epoch 14.021), train_loss = 1.26336641, grad/param norm = 1.8169e-01, time/batch = 15.9879s	
7306/26050 (epoch 14.023), train_loss = 1.03589862, grad/param norm = 1.6858e-01, time/batch = 18.4741s	
7307/26050 (epoch 14.025), train_loss = 1.16835170, grad/param norm = 1.6717e-01, time/batch = 16.7519s	
7308/26050 (epoch 14.027), train_loss = 0.95858593, grad/param norm = 1.7457e-01, time/batch = 18.4000s	
7309/26050 (epoch 14.029), train_loss = 1.17404237, grad/param norm = 1.6237e-01, time/batch = 18.0651s	
7310/26050 (epoch 14.031), train_loss = 1.31763991, grad/param norm = 1.9811e-01, time/batch = 18.0630s	
7311/26050 (epoch 14.033), train_loss = 1.21973607, grad/param norm = 1.7311e-01, time/batch = 17.2454s	
7312/26050 (epoch 14.035), train_loss = 1.24952997, grad/param norm = 1.6170e-01, time/batch = 16.1428s	
7313/26050 (epoch 14.036), train_loss = 1.06460837, grad/param norm = 1.9284e-01, time/batch = 18.5660s	
7314/26050 (epoch 14.038), train_loss = 1.00536013, grad/param norm = 1.5992e-01, time/batch = 17.8045s	
7315/26050 (epoch 14.040), train_loss = 1.20058248, grad/param norm = 1.8102e-01, time/batch = 17.2893s	
7316/26050 (epoch 14.042), train_loss = 1.01976716, grad/param norm = 1.7466e-01, time/batch = 15.7289s	
7317/26050 (epoch 14.044), train_loss = 1.26758492, grad/param norm = 1.6936e-01, time/batch = 17.9702s	
7318/26050 (epoch 14.046), train_loss = 0.96894261, grad/param norm = 1.5503e-01, time/batch = 17.9681s	
7319/26050 (epoch 14.048), train_loss = 1.20658611, grad/param norm = 1.7142e-01, time/batch = 16.9041s	
7320/26050 (epoch 14.050), train_loss = 1.07838393, grad/param norm = 1.7312e-01, time/batch = 18.2263s	
7321/26050 (epoch 14.052), train_loss = 1.13322928, grad/param norm = 1.6505e-01, time/batch = 18.3942s	
7322/26050 (epoch 14.054), train_loss = 1.00443144, grad/param norm = 1.5716e-01, time/batch = 18.0650s	
7323/26050 (epoch 14.056), train_loss = 0.94385806, grad/param norm = 1.3958e-01, time/batch = 18.5690s	
7324/26050 (epoch 14.058), train_loss = 1.10542512, grad/param norm = 1.5871e-01, time/batch = 14.6183s	
7325/26050 (epoch 14.060), train_loss = 1.19698456, grad/param norm = 1.6189e-01, time/batch = 15.9776s	
7326/26050 (epoch 14.061), train_loss = 1.08563261, grad/param norm = 1.6543e-01, time/batch = 18.6473s	
7327/26050 (epoch 14.063), train_loss = 1.18369510, grad/param norm = 1.6889e-01, time/batch = 17.8098s	
7328/26050 (epoch 14.065), train_loss = 0.98267831, grad/param norm = 1.5047e-01, time/batch = 16.5596s	
7329/26050 (epoch 14.067), train_loss = 1.19451231, grad/param norm = 1.7768e-01, time/batch = 18.8222s	
7330/26050 (epoch 14.069), train_loss = 1.21875365, grad/param norm = 1.6220e-01, time/batch = 16.2252s	
7331/26050 (epoch 14.071), train_loss = 1.22612909, grad/param norm = 1.6930e-01, time/batch = 17.5637s	
7332/26050 (epoch 14.073), train_loss = 1.37426565, grad/param norm = 1.8192e-01, time/batch = 17.3224s	
7333/26050 (epoch 14.075), train_loss = 1.08160257, grad/param norm = 1.5655e-01, time/batch = 15.1572s	
7334/26050 (epoch 14.077), train_loss = 1.08081959, grad/param norm = 1.6694e-01, time/batch = 16.9763s	
7335/26050 (epoch 14.079), train_loss = 1.19589177, grad/param norm = 1.7131e-01, time/batch = 18.4766s	
7336/26050 (epoch 14.081), train_loss = 1.12181094, grad/param norm = 1.8924e-01, time/batch = 18.6491s	
7337/26050 (epoch 14.083), train_loss = 1.24016331, grad/param norm = 1.6619e-01, time/batch = 17.8127s	
7338/26050 (epoch 14.084), train_loss = 1.23820637, grad/param norm = 1.8158e-01, time/batch = 17.3807s	
7339/26050 (epoch 14.086), train_loss = 1.31702246, grad/param norm = 1.7937e-01, time/batch = 14.8841s	
7340/26050 (epoch 14.088), train_loss = 1.06106053, grad/param norm = 1.6129e-01, time/batch = 15.1542s	
7341/26050 (epoch 14.090), train_loss = 1.21168796, grad/param norm = 1.7967e-01, time/batch = 17.2382s	
7342/26050 (epoch 14.092), train_loss = 1.20801004, grad/param norm = 1.7552e-01, time/batch = 17.6491s	
7343/26050 (epoch 14.094), train_loss = 1.13491545, grad/param norm = 1.7653e-01, time/batch = 18.7308s	
7344/26050 (epoch 14.096), train_loss = 1.13804495, grad/param norm = 1.6252e-01, time/batch = 17.0492s	
7345/26050 (epoch 14.098), train_loss = 1.14106298, grad/param norm = 1.7181e-01, time/batch = 14.4806s	
7346/26050 (epoch 14.100), train_loss = 1.05998978, grad/param norm = 1.7579e-01, time/batch = 18.4789s	
7347/26050 (epoch 14.102), train_loss = 1.16971121, grad/param norm = 1.6920e-01, time/batch = 18.8963s	
7348/26050 (epoch 14.104), train_loss = 1.18038898, grad/param norm = 1.7958e-01, time/batch = 17.6445s	
7349/26050 (epoch 14.106), train_loss = 1.16584161, grad/param norm = 1.8325e-01, time/batch = 18.2391s	
7350/26050 (epoch 14.107), train_loss = 0.95597490, grad/param norm = 1.5591e-01, time/batch = 18.3236s	
7351/26050 (epoch 14.109), train_loss = 1.09566164, grad/param norm = 1.7138e-01, time/batch = 18.5584s	
7352/26050 (epoch 14.111), train_loss = 1.34792723, grad/param norm = 1.9075e-01, time/batch = 15.3010s	
7353/26050 (epoch 14.113), train_loss = 1.12262611, grad/param norm = 1.6999e-01, time/batch = 18.7318s	
7354/26050 (epoch 14.115), train_loss = 1.25568517, grad/param norm = 1.7347e-01, time/batch = 18.4892s	
7355/26050 (epoch 14.117), train_loss = 1.20608012, grad/param norm = 1.6546e-01, time/batch = 15.4756s	
7356/26050 (epoch 14.119), train_loss = 0.95784605, grad/param norm = 1.5238e-01, time/batch = 15.3924s	
7357/26050 (epoch 14.121), train_loss = 1.20486708, grad/param norm = 1.6737e-01, time/batch = 18.3054s	
7358/26050 (epoch 14.123), train_loss = 1.05421015, grad/param norm = 1.7273e-01, time/batch = 18.2304s	
7359/26050 (epoch 14.125), train_loss = 1.00536400, grad/param norm = 1.6160e-01, time/batch = 4.0845s	
7360/26050 (epoch 14.127), train_loss = 0.92995703, grad/param norm = 1.4896e-01, time/batch = 0.6469s	
7361/26050 (epoch 14.129), train_loss = 0.97902704, grad/param norm = 1.5483e-01, time/batch = 0.6424s	
7362/26050 (epoch 14.131), train_loss = 1.12738197, grad/param norm = 1.6618e-01, time/batch = 0.6521s	
7363/26050 (epoch 14.132), train_loss = 1.12749919, grad/param norm = 1.6508e-01, time/batch = 0.6413s	
7364/26050 (epoch 14.134), train_loss = 1.12213135, grad/param norm = 1.7250e-01, time/batch = 0.6406s	
7365/26050 (epoch 14.136), train_loss = 1.15950583, grad/param norm = 1.6369e-01, time/batch = 0.6516s	
7366/26050 (epoch 14.138), train_loss = 0.95258635, grad/param norm = 1.6150e-01, time/batch = 0.6585s	
7367/26050 (epoch 14.140), train_loss = 0.99832589, grad/param norm = 1.6840e-01, time/batch = 0.9331s	
7368/26050 (epoch 14.142), train_loss = 1.05635267, grad/param norm = 1.7320e-01, time/batch = 0.9388s	
7369/26050 (epoch 14.144), train_loss = 0.96555433, grad/param norm = 1.7284e-01, time/batch = 0.9487s	
7370/26050 (epoch 14.146), train_loss = 0.90385341, grad/param norm = 1.5901e-01, time/batch = 0.9444s	
7371/26050 (epoch 14.148), train_loss = 0.92730685, grad/param norm = 1.4037e-01, time/batch = 0.9430s	
7372/26050 (epoch 14.150), train_loss = 1.13461120, grad/param norm = 1.7678e-01, time/batch = 1.6228s	
7373/26050 (epoch 14.152), train_loss = 1.36403137, grad/param norm = 2.0819e-01, time/batch = 1.8837s	
7374/26050 (epoch 14.154), train_loss = 0.92466159, grad/param norm = 1.6209e-01, time/batch = 2.4056s	
7375/26050 (epoch 14.155), train_loss = 0.97794007, grad/param norm = 1.6466e-01, time/batch = 16.3290s	
7376/26050 (epoch 14.157), train_loss = 1.08802924, grad/param norm = 1.8888e-01, time/batch = 17.8811s	
7377/26050 (epoch 14.159), train_loss = 1.11455262, grad/param norm = 1.8481e-01, time/batch = 17.0685s	
7378/26050 (epoch 14.161), train_loss = 1.23791072, grad/param norm = 1.9024e-01, time/batch = 18.0655s	
7379/26050 (epoch 14.163), train_loss = 0.97174120, grad/param norm = 1.6737e-01, time/batch = 18.7277s	
7380/26050 (epoch 14.165), train_loss = 0.87213256, grad/param norm = 1.4868e-01, time/batch = 14.7993s	
7381/26050 (epoch 14.167), train_loss = 1.25324458, grad/param norm = 1.9005e-01, time/batch = 18.4839s	
7382/26050 (epoch 14.169), train_loss = 1.20095014, grad/param norm = 1.6828e-01, time/batch = 17.9860s	
7383/26050 (epoch 14.171), train_loss = 0.94484057, grad/param norm = 1.4698e-01, time/batch = 18.3083s	
7384/26050 (epoch 14.173), train_loss = 1.08826457, grad/param norm = 1.8249e-01, time/batch = 18.6308s	
7385/26050 (epoch 14.175), train_loss = 1.13186965, grad/param norm = 1.6287e-01, time/batch = 16.1351s	
7386/26050 (epoch 14.177), train_loss = 1.26748483, grad/param norm = 1.7056e-01, time/batch = 18.2400s	
7387/26050 (epoch 14.179), train_loss = 0.89787790, grad/param norm = 1.4904e-01, time/batch = 15.5770s	
7388/26050 (epoch 14.180), train_loss = 1.37734935, grad/param norm = 1.7667e-01, time/batch = 17.3744s	
7389/26050 (epoch 14.182), train_loss = 1.38574860, grad/param norm = 1.9130e-01, time/batch = 16.9013s	
7390/26050 (epoch 14.184), train_loss = 1.15907120, grad/param norm = 1.6476e-01, time/batch = 16.6458s	
7391/26050 (epoch 14.186), train_loss = 0.95103320, grad/param norm = 1.4905e-01, time/batch = 31.2450s	
7392/26050 (epoch 14.188), train_loss = 1.14771777, grad/param norm = 1.6899e-01, time/batch = 22.9081s	
7393/26050 (epoch 14.190), train_loss = 1.19995236, grad/param norm = 1.7750e-01, time/batch = 17.0669s	
7394/26050 (epoch 14.192), train_loss = 1.18684458, grad/param norm = 1.6010e-01, time/batch = 17.5610s	
7395/26050 (epoch 14.194), train_loss = 1.17490925, grad/param norm = 1.6832e-01, time/batch = 18.8882s	
7396/26050 (epoch 14.196), train_loss = 1.24461102, grad/param norm = 1.8034e-01, time/batch = 17.9660s	
7397/26050 (epoch 14.198), train_loss = 1.07072057, grad/param norm = 1.6180e-01, time/batch = 17.1270s	
7398/26050 (epoch 14.200), train_loss = 1.04810202, grad/param norm = 1.7016e-01, time/batch = 17.2289s	
7399/26050 (epoch 14.202), train_loss = 1.10705696, grad/param norm = 1.7761e-01, time/batch = 18.2380s	
7400/26050 (epoch 14.203), train_loss = 1.25202437, grad/param norm = 1.8792e-01, time/batch = 18.3894s	
7401/26050 (epoch 14.205), train_loss = 1.08243958, grad/param norm = 1.6683e-01, time/batch = 16.7270s	
7402/26050 (epoch 14.207), train_loss = 1.09363537, grad/param norm = 1.6536e-01, time/batch = 18.5643s	
7403/26050 (epoch 14.209), train_loss = 1.14610472, grad/param norm = 1.5890e-01, time/batch = 17.0715s	
7404/26050 (epoch 14.211), train_loss = 0.98271728, grad/param norm = 1.6158e-01, time/batch = 17.3849s	
7405/26050 (epoch 14.213), train_loss = 1.20363411, grad/param norm = 1.8079e-01, time/batch = 19.1630s	
7406/26050 (epoch 14.215), train_loss = 1.14317981, grad/param norm = 1.8968e-01, time/batch = 17.8199s	
7407/26050 (epoch 14.217), train_loss = 1.12270927, grad/param norm = 1.6264e-01, time/batch = 17.3940s	
7408/26050 (epoch 14.219), train_loss = 1.10250635, grad/param norm = 1.8085e-01, time/batch = 17.9102s	
7409/26050 (epoch 14.221), train_loss = 1.01500036, grad/param norm = 1.5983e-01, time/batch = 16.7120s	
7410/26050 (epoch 14.223), train_loss = 1.16087780, grad/param norm = 1.6660e-01, time/batch = 17.6532s	
7411/26050 (epoch 14.225), train_loss = 1.04542649, grad/param norm = 1.6818e-01, time/batch = 16.1365s	
7412/26050 (epoch 14.226), train_loss = 1.23257124, grad/param norm = 1.8095e-01, time/batch = 18.7379s	
7413/26050 (epoch 14.228), train_loss = 1.27739639, grad/param norm = 1.7768e-01, time/batch = 14.7183s	
7414/26050 (epoch 14.230), train_loss = 1.19282978, grad/param norm = 1.7618e-01, time/batch = 18.2301s	
7415/26050 (epoch 14.232), train_loss = 1.26451361, grad/param norm = 1.7994e-01, time/batch = 17.4134s	
7416/26050 (epoch 14.234), train_loss = 1.00690595, grad/param norm = 1.6459e-01, time/batch = 18.9910s	
7417/26050 (epoch 14.236), train_loss = 1.23925304, grad/param norm = 1.7661e-01, time/batch = 17.6523s	
7418/26050 (epoch 14.238), train_loss = 0.98157770, grad/param norm = 1.5397e-01, time/batch = 18.5674s	
7419/26050 (epoch 14.240), train_loss = 1.12903002, grad/param norm = 1.7437e-01, time/batch = 17.6811s	
7420/26050 (epoch 14.242), train_loss = 1.14277454, grad/param norm = 1.5529e-01, time/batch = 17.9833s	
7421/26050 (epoch 14.244), train_loss = 1.14675430, grad/param norm = 1.8533e-01, time/batch = 15.6362s	
7422/26050 (epoch 14.246), train_loss = 1.07405286, grad/param norm = 1.5585e-01, time/batch = 18.6593s	
7423/26050 (epoch 14.248), train_loss = 1.15538589, grad/param norm = 1.6568e-01, time/batch = 17.5482s	
7424/26050 (epoch 14.250), train_loss = 1.14586685, grad/param norm = 1.8782e-01, time/batch = 18.0686s	
7425/26050 (epoch 14.251), train_loss = 1.08644416, grad/param norm = 1.6472e-01, time/batch = 18.6349s	
7426/26050 (epoch 14.253), train_loss = 1.00863249, grad/param norm = 1.6457e-01, time/batch = 18.1509s	
7427/26050 (epoch 14.255), train_loss = 1.34463977, grad/param norm = 1.7446e-01, time/batch = 17.7244s	
7428/26050 (epoch 14.257), train_loss = 1.15554428, grad/param norm = 1.8991e-01, time/batch = 18.3907s	
7429/26050 (epoch 14.259), train_loss = 1.30070882, grad/param norm = 1.7798e-01, time/batch = 18.8920s	
7430/26050 (epoch 14.261), train_loss = 1.04246522, grad/param norm = 1.7804e-01, time/batch = 17.2345s	
7431/26050 (epoch 14.263), train_loss = 1.17678393, grad/param norm = 1.6785e-01, time/batch = 15.3929s	
7432/26050 (epoch 14.265), train_loss = 1.33009047, grad/param norm = 1.9165e-01, time/batch = 17.7325s	
7433/26050 (epoch 14.267), train_loss = 1.24736041, grad/param norm = 1.7038e-01, time/batch = 16.7918s	
7434/26050 (epoch 14.269), train_loss = 1.33215709, grad/param norm = 1.9303e-01, time/batch = 16.9805s	
7435/26050 (epoch 14.271), train_loss = 1.20569239, grad/param norm = 1.7703e-01, time/batch = 18.1564s	
7436/26050 (epoch 14.273), train_loss = 1.11450868, grad/param norm = 1.8752e-01, time/batch = 18.3771s	
7437/26050 (epoch 14.274), train_loss = 1.11021946, grad/param norm = 1.6523e-01, time/batch = 15.5296s	
7438/26050 (epoch 14.276), train_loss = 1.08514867, grad/param norm = 1.7153e-01, time/batch = 17.6478s	
7439/26050 (epoch 14.278), train_loss = 1.28308296, grad/param norm = 1.8231e-01, time/batch = 18.3182s	
7440/26050 (epoch 14.280), train_loss = 1.13318237, grad/param norm = 1.5949e-01, time/batch = 17.6342s	
7441/26050 (epoch 14.282), train_loss = 1.18569848, grad/param norm = 1.7909e-01, time/batch = 17.2393s	
7442/26050 (epoch 14.284), train_loss = 1.08697176, grad/param norm = 1.7538e-01, time/batch = 15.9930s	
7443/26050 (epoch 14.286), train_loss = 1.16341043, grad/param norm = 1.7256e-01, time/batch = 18.1328s	
7444/26050 (epoch 14.288), train_loss = 0.99742447, grad/param norm = 1.6196e-01, time/batch = 15.5783s	
7445/26050 (epoch 14.290), train_loss = 1.13314639, grad/param norm = 1.6545e-01, time/batch = 18.1507s	
7446/26050 (epoch 14.292), train_loss = 1.05458490, grad/param norm = 1.6085e-01, time/batch = 18.3297s	
7447/26050 (epoch 14.294), train_loss = 1.17948568, grad/param norm = 1.8991e-01, time/batch = 16.8918s	
7448/26050 (epoch 14.296), train_loss = 1.28292820, grad/param norm = 1.7721e-01, time/batch = 17.7163s	
7449/26050 (epoch 14.298), train_loss = 1.14272954, grad/param norm = 1.6299e-01, time/batch = 16.5808s	
7450/26050 (epoch 14.299), train_loss = 0.91053995, grad/param norm = 1.5017e-01, time/batch = 18.8130s	
7451/26050 (epoch 14.301), train_loss = 1.04378845, grad/param norm = 1.7420e-01, time/batch = 18.6461s	
7452/26050 (epoch 14.303), train_loss = 1.17620323, grad/param norm = 1.7965e-01, time/batch = 16.0581s	
7453/26050 (epoch 14.305), train_loss = 0.99101068, grad/param norm = 1.7449e-01, time/batch = 16.4595s	
7454/26050 (epoch 14.307), train_loss = 1.05801629, grad/param norm = 1.7306e-01, time/batch = 17.3189s	
7455/26050 (epoch 14.309), train_loss = 1.11927807, grad/param norm = 1.7545e-01, time/batch = 17.1431s	
7456/26050 (epoch 14.311), train_loss = 1.27037876, grad/param norm = 2.0189e-01, time/batch = 18.1629s	
7457/26050 (epoch 14.313), train_loss = 1.14633442, grad/param norm = 2.0493e-01, time/batch = 17.7383s	
7458/26050 (epoch 14.315), train_loss = 1.24891365, grad/param norm = 1.7948e-01, time/batch = 17.4055s	
7459/26050 (epoch 14.317), train_loss = 1.12067277, grad/param norm = 1.6488e-01, time/batch = 16.6433s	
7460/26050 (epoch 14.319), train_loss = 1.09473108, grad/param norm = 1.6245e-01, time/batch = 18.0926s	
7461/26050 (epoch 14.321), train_loss = 1.10466192, grad/param norm = 1.7302e-01, time/batch = 16.2390s	
7462/26050 (epoch 14.322), train_loss = 1.17703078, grad/param norm = 1.7869e-01, time/batch = 18.6446s	
7463/26050 (epoch 14.324), train_loss = 0.97032404, grad/param norm = 1.7517e-01, time/batch = 15.1464s	
7464/26050 (epoch 14.326), train_loss = 1.30729229, grad/param norm = 1.7958e-01, time/batch = 18.2452s	
7465/26050 (epoch 14.328), train_loss = 1.19419173, grad/param norm = 1.6450e-01, time/batch = 18.2330s	
7466/26050 (epoch 14.330), train_loss = 1.04346792, grad/param norm = 1.7095e-01, time/batch = 17.9038s	
7467/26050 (epoch 14.332), train_loss = 1.21062787, grad/param norm = 1.7315e-01, time/batch = 18.0828s	
7468/26050 (epoch 14.334), train_loss = 1.11886066, grad/param norm = 1.8051e-01, time/batch = 17.0710s	
7469/26050 (epoch 14.336), train_loss = 1.05842953, grad/param norm = 1.6228e-01, time/batch = 18.1566s	
7470/26050 (epoch 14.338), train_loss = 1.01891187, grad/param norm = 1.5810e-01, time/batch = 18.8186s	
7471/26050 (epoch 14.340), train_loss = 1.25822160, grad/param norm = 1.8559e-01, time/batch = 15.8875s	
7472/26050 (epoch 14.342), train_loss = 1.29616284, grad/param norm = 1.8559e-01, time/batch = 17.3131s	
7473/26050 (epoch 14.344), train_loss = 1.12369918, grad/param norm = 1.7045e-01, time/batch = 18.1473s	
7474/26050 (epoch 14.345), train_loss = 1.11193454, grad/param norm = 1.6858e-01, time/batch = 18.0634s	
7475/26050 (epoch 14.347), train_loss = 1.23752359, grad/param norm = 1.8320e-01, time/batch = 14.4682s	
7476/26050 (epoch 14.349), train_loss = 1.19300926, grad/param norm = 1.7012e-01, time/batch = 17.9057s	
7477/26050 (epoch 14.351), train_loss = 1.16211049, grad/param norm = 1.7565e-01, time/batch = 18.2398s	
7478/26050 (epoch 14.353), train_loss = 1.13166203, grad/param norm = 1.7771e-01, time/batch = 15.1381s	
7479/26050 (epoch 14.355), train_loss = 1.22334642, grad/param norm = 1.9953e-01, time/batch = 18.8873s	
7480/26050 (epoch 14.357), train_loss = 1.02193135, grad/param norm = 1.5156e-01, time/batch = 17.7395s	
7481/26050 (epoch 14.359), train_loss = 1.20755817, grad/param norm = 1.6621e-01, time/batch = 18.1501s	
7482/26050 (epoch 14.361), train_loss = 1.08369498, grad/param norm = 1.6611e-01, time/batch = 17.2354s	
7483/26050 (epoch 14.363), train_loss = 1.20005108, grad/param norm = 1.6133e-01, time/batch = 15.9575s	
7484/26050 (epoch 14.365), train_loss = 1.11951915, grad/param norm = 1.4639e-01, time/batch = 18.7401s	
7485/26050 (epoch 14.367), train_loss = 1.16100274, grad/param norm = 1.6815e-01, time/batch = 16.3125s	
7486/26050 (epoch 14.369), train_loss = 1.12693929, grad/param norm = 1.6108e-01, time/batch = 15.3718s	
7487/26050 (epoch 14.370), train_loss = 1.03939221, grad/param norm = 1.5054e-01, time/batch = 18.3188s	
7488/26050 (epoch 14.372), train_loss = 1.22134190, grad/param norm = 1.9148e-01, time/batch = 16.7964s	
7489/26050 (epoch 14.374), train_loss = 1.31716280, grad/param norm = 1.8326e-01, time/batch = 17.1307s	
7490/26050 (epoch 14.376), train_loss = 1.35748216, grad/param norm = 1.8569e-01, time/batch = 17.8888s	
7491/26050 (epoch 14.378), train_loss = 1.12676349, grad/param norm = 1.7288e-01, time/batch = 18.5567s	
7492/26050 (epoch 14.380), train_loss = 1.35601476, grad/param norm = 2.0019e-01, time/batch = 16.9760s	
7493/26050 (epoch 14.382), train_loss = 1.47198278, grad/param norm = 1.9992e-01, time/batch = 18.3018s	
7494/26050 (epoch 14.384), train_loss = 1.12196964, grad/param norm = 1.6358e-01, time/batch = 18.3989s	
7495/26050 (epoch 14.386), train_loss = 1.26035755, grad/param norm = 1.8741e-01, time/batch = 17.4715s	
7496/26050 (epoch 14.388), train_loss = 1.18108595, grad/param norm = 1.7028e-01, time/batch = 17.9701s	
7497/26050 (epoch 14.390), train_loss = 1.05793570, grad/param norm = 1.6494e-01, time/batch = 17.9805s	
7498/26050 (epoch 14.392), train_loss = 1.04023869, grad/param norm = 1.5786e-01, time/batch = 18.3147s	
7499/26050 (epoch 14.393), train_loss = 1.19402206, grad/param norm = 1.7005e-01, time/batch = 18.4725s	
7500/26050 (epoch 14.395), train_loss = 1.21861412, grad/param norm = 1.6954e-01, time/batch = 17.4019s	
7501/26050 (epoch 14.397), train_loss = 1.19723218, grad/param norm = 1.9161e-01, time/batch = 16.7257s	
7502/26050 (epoch 14.399), train_loss = 1.05256234, grad/param norm = 1.6529e-01, time/batch = 14.6824s	
7503/26050 (epoch 14.401), train_loss = 1.12193178, grad/param norm = 1.5623e-01, time/batch = 18.8943s	
7504/26050 (epoch 14.403), train_loss = 1.18392986, grad/param norm = 1.6237e-01, time/batch = 18.4896s	
7505/26050 (epoch 14.405), train_loss = 1.14511929, grad/param norm = 1.7258e-01, time/batch = 17.4027s	
7506/26050 (epoch 14.407), train_loss = 1.30503004, grad/param norm = 1.8053e-01, time/batch = 16.3938s	
7507/26050 (epoch 14.409), train_loss = 1.34238025, grad/param norm = 1.8089e-01, time/batch = 18.1337s	
7508/26050 (epoch 14.411), train_loss = 1.20070748, grad/param norm = 1.9107e-01, time/batch = 18.4845s	
7509/26050 (epoch 14.413), train_loss = 1.30693087, grad/param norm = 1.6186e-01, time/batch = 17.0676s	
7510/26050 (epoch 14.415), train_loss = 1.28018686, grad/param norm = 1.9206e-01, time/batch = 17.5657s	
7511/26050 (epoch 14.417), train_loss = 1.38758600, grad/param norm = 1.8953e-01, time/batch = 18.7375s	
7512/26050 (epoch 14.418), train_loss = 1.28471452, grad/param norm = 2.0161e-01, time/batch = 17.3154s	
7513/26050 (epoch 14.420), train_loss = 0.98098338, grad/param norm = 1.5126e-01, time/batch = 18.9814s	
7514/26050 (epoch 14.422), train_loss = 1.01885971, grad/param norm = 1.6225e-01, time/batch = 15.6434s	
7515/26050 (epoch 14.424), train_loss = 1.32539681, grad/param norm = 2.0582e-01, time/batch = 18.0023s	
7516/26050 (epoch 14.426), train_loss = 1.29027278, grad/param norm = 1.8054e-01, time/batch = 17.6416s	
7517/26050 (epoch 14.428), train_loss = 1.08046400, grad/param norm = 1.5149e-01, time/batch = 17.9951s	
7518/26050 (epoch 14.430), train_loss = 1.23394627, grad/param norm = 1.7266e-01, time/batch = 18.4030s	
7519/26050 (epoch 14.432), train_loss = 1.10978498, grad/param norm = 1.7119e-01, time/batch = 16.4654s	
7520/26050 (epoch 14.434), train_loss = 1.17630742, grad/param norm = 2.0078e-01, time/batch = 14.3544s	
7521/26050 (epoch 14.436), train_loss = 1.28197133, grad/param norm = 1.6863e-01, time/batch = 18.2384s	
7522/26050 (epoch 14.438), train_loss = 1.12278279, grad/param norm = 1.8113e-01, time/batch = 18.0566s	
7523/26050 (epoch 14.440), train_loss = 1.19151094, grad/param norm = 1.6999e-01, time/batch = 17.5661s	
7524/26050 (epoch 14.441), train_loss = 1.17802647, grad/param norm = 1.6322e-01, time/batch = 18.5686s	
7525/26050 (epoch 14.443), train_loss = 0.97897755, grad/param norm = 1.5437e-01, time/batch = 18.9863s	
7526/26050 (epoch 14.445), train_loss = 1.04971939, grad/param norm = 1.6094e-01, time/batch = 17.9728s	
7527/26050 (epoch 14.447), train_loss = 1.34342693, grad/param norm = 1.9268e-01, time/batch = 17.6545s	
7528/26050 (epoch 14.449), train_loss = 1.07929056, grad/param norm = 1.7364e-01, time/batch = 18.5749s	
7529/26050 (epoch 14.451), train_loss = 1.30956552, grad/param norm = 1.7995e-01, time/batch = 16.9844s	
7530/26050 (epoch 14.453), train_loss = 1.07555214, grad/param norm = 1.5874e-01, time/batch = 18.9783s	
7531/26050 (epoch 14.455), train_loss = 1.20809119, grad/param norm = 1.6983e-01, time/batch = 15.3930s	
7532/26050 (epoch 14.457), train_loss = 1.19204359, grad/param norm = 1.7286e-01, time/batch = 17.7312s	
7533/26050 (epoch 14.459), train_loss = 1.28256661, grad/param norm = 1.7761e-01, time/batch = 18.1485s	
7534/26050 (epoch 14.461), train_loss = 1.24620641, grad/param norm = 1.9640e-01, time/batch = 17.8373s	
7535/26050 (epoch 14.463), train_loss = 1.11305510, grad/param norm = 1.6535e-01, time/batch = 16.1333s	
7536/26050 (epoch 14.464), train_loss = 1.21761634, grad/param norm = 1.6970e-01, time/batch = 16.1322s	
7537/26050 (epoch 14.466), train_loss = 1.26006721, grad/param norm = 1.8789e-01, time/batch = 16.9633s	
7538/26050 (epoch 14.468), train_loss = 1.27023229, grad/param norm = 1.6143e-01, time/batch = 17.5743s	
7539/26050 (epoch 14.470), train_loss = 1.37430960, grad/param norm = 2.0147e-01, time/batch = 16.4013s	
7540/26050 (epoch 14.472), train_loss = 1.31927522, grad/param norm = 1.9582e-01, time/batch = 18.4021s	
7541/26050 (epoch 14.474), train_loss = 1.38519207, grad/param norm = 1.7749e-01, time/batch = 18.1443s	
7542/26050 (epoch 14.476), train_loss = 1.29245306, grad/param norm = 1.7844e-01, time/batch = 18.2287s	
7543/26050 (epoch 14.478), train_loss = 1.10928494, grad/param norm = 1.6463e-01, time/batch = 17.7172s	
7544/26050 (epoch 14.480), train_loss = 1.20116722, grad/param norm = 1.7333e-01, time/batch = 15.1457s	
7545/26050 (epoch 14.482), train_loss = 1.12085862, grad/param norm = 1.6624e-01, time/batch = 18.4774s	
7546/26050 (epoch 14.484), train_loss = 1.12205695, grad/param norm = 1.7320e-01, time/batch = 17.4004s	
7547/26050 (epoch 14.486), train_loss = 1.34191349, grad/param norm = 1.7712e-01, time/batch = 16.8188s	
7548/26050 (epoch 14.488), train_loss = 1.48559668, grad/param norm = 1.9501e-01, time/batch = 18.3234s	
7549/26050 (epoch 14.489), train_loss = 1.39778532, grad/param norm = 1.9802e-01, time/batch = 17.0529s	
7550/26050 (epoch 14.491), train_loss = 1.06798592, grad/param norm = 1.6181e-01, time/batch = 17.7221s	
7551/26050 (epoch 14.493), train_loss = 1.17758751, grad/param norm = 1.7652e-01, time/batch = 17.7360s	
7552/26050 (epoch 14.495), train_loss = 1.15642045, grad/param norm = 1.7492e-01, time/batch = 15.2409s	
7553/26050 (epoch 14.497), train_loss = 1.09247676, grad/param norm = 1.6663e-01, time/batch = 17.4771s	
7554/26050 (epoch 14.499), train_loss = 1.12995250, grad/param norm = 1.6579e-01, time/batch = 15.5527s	
7555/26050 (epoch 14.501), train_loss = 1.24032628, grad/param norm = 1.7014e-01, time/batch = 18.2495s	
7556/26050 (epoch 14.503), train_loss = 1.11213746, grad/param norm = 1.8438e-01, time/batch = 18.2442s	
7557/26050 (epoch 14.505), train_loss = 1.30102099, grad/param norm = 1.7728e-01, time/batch = 17.9002s	
7558/26050 (epoch 14.507), train_loss = 1.26142205, grad/param norm = 1.8986e-01, time/batch = 17.4790s	
7559/26050 (epoch 14.509), train_loss = 1.38071209, grad/param norm = 1.8205e-01, time/batch = 18.7339s	
7560/26050 (epoch 14.511), train_loss = 1.07304666, grad/param norm = 1.5186e-01, time/batch = 17.1408s	
7561/26050 (epoch 14.512), train_loss = 1.12528051, grad/param norm = 1.8841e-01, time/batch = 17.4792s	
7562/26050 (epoch 14.514), train_loss = 1.25340343, grad/param norm = 1.8230e-01, time/batch = 17.8810s	
7563/26050 (epoch 14.516), train_loss = 1.27439012, grad/param norm = 1.8406e-01, time/batch = 18.0651s	
7564/26050 (epoch 14.518), train_loss = 1.23452642, grad/param norm = 1.8371e-01, time/batch = 18.1507s	
7565/26050 (epoch 14.520), train_loss = 1.15637723, grad/param norm = 1.6025e-01, time/batch = 17.4899s	
7566/26050 (epoch 14.522), train_loss = 0.97660227, grad/param norm = 1.6311e-01, time/batch = 18.6554s	
7567/26050 (epoch 14.524), train_loss = 1.29489620, grad/param norm = 1.8629e-01, time/batch = 18.3902s	
7568/26050 (epoch 14.526), train_loss = 1.28786860, grad/param norm = 1.8324e-01, time/batch = 17.9843s	
7569/26050 (epoch 14.528), train_loss = 1.22597597, grad/param norm = 1.7326e-01, time/batch = 16.3976s	
7570/26050 (epoch 14.530), train_loss = 1.17557367, grad/param norm = 1.7188e-01, time/batch = 17.3780s	
7571/26050 (epoch 14.532), train_loss = 1.16814572, grad/param norm = 1.5787e-01, time/batch = 16.9857s	
7572/26050 (epoch 14.534), train_loss = 1.24503960, grad/param norm = 1.8877e-01, time/batch = 18.2427s	
7573/26050 (epoch 14.536), train_loss = 1.16733374, grad/param norm = 1.5833e-01, time/batch = 15.9678s	
7574/26050 (epoch 14.537), train_loss = 1.30792841, grad/param norm = 2.0065e-01, time/batch = 17.9003s	
7575/26050 (epoch 14.539), train_loss = 1.18320918, grad/param norm = 1.8105e-01, time/batch = 16.4741s	
7576/26050 (epoch 14.541), train_loss = 1.36895802, grad/param norm = 1.9242e-01, time/batch = 17.8059s	
7577/26050 (epoch 14.543), train_loss = 1.00803067, grad/param norm = 1.6891e-01, time/batch = 14.7091s	
7578/26050 (epoch 14.545), train_loss = 1.22754901, grad/param norm = 1.7427e-01, time/batch = 17.8208s	
7579/26050 (epoch 14.547), train_loss = 1.18341001, grad/param norm = 1.6620e-01, time/batch = 19.0590s	
7580/26050 (epoch 14.549), train_loss = 0.97331865, grad/param norm = 1.5423e-01, time/batch = 17.4872s	
7581/26050 (epoch 14.551), train_loss = 1.20928309, grad/param norm = 1.7823e-01, time/batch = 17.8229s	
7582/26050 (epoch 14.553), train_loss = 1.09312828, grad/param norm = 1.6249e-01, time/batch = 18.4808s	
7583/26050 (epoch 14.555), train_loss = 1.11919742, grad/param norm = 1.7743e-01, time/batch = 18.2341s	
7584/26050 (epoch 14.557), train_loss = 1.22788747, grad/param norm = 1.5849e-01, time/batch = 18.4779s	
7585/26050 (epoch 14.559), train_loss = 1.17194763, grad/param norm = 1.6496e-01, time/batch = 17.9848s	
7586/26050 (epoch 14.560), train_loss = 1.16052990, grad/param norm = 1.7742e-01, time/batch = 18.5550s	
7587/26050 (epoch 14.562), train_loss = 1.15916079, grad/param norm = 1.7655e-01, time/batch = 15.9067s	
7588/26050 (epoch 14.564), train_loss = 1.36674027, grad/param norm = 1.7489e-01, time/batch = 18.5764s	
7589/26050 (epoch 14.566), train_loss = 1.06760464, grad/param norm = 1.6382e-01, time/batch = 17.7280s	
7590/26050 (epoch 14.568), train_loss = 1.20378411, grad/param norm = 1.6311e-01, time/batch = 17.6597s	
7591/26050 (epoch 14.570), train_loss = 1.27966274, grad/param norm = 1.7801e-01, time/batch = 17.5615s	
7592/26050 (epoch 14.572), train_loss = 1.15436009, grad/param norm = 1.7551e-01, time/batch = 18.6506s	
7593/26050 (epoch 14.574), train_loss = 1.24857199, grad/param norm = 2.0217e-01, time/batch = 17.6599s	
7594/26050 (epoch 14.576), train_loss = 1.21479496, grad/param norm = 1.8210e-01, time/batch = 23.9994s	
7595/26050 (epoch 14.578), train_loss = 1.17165595, grad/param norm = 1.7862e-01, time/batch = 26.5761s	
7596/26050 (epoch 14.580), train_loss = 1.08076882, grad/param norm = 1.7756e-01, time/batch = 17.2951s	
7597/26050 (epoch 14.582), train_loss = 1.22281712, grad/param norm = 1.7411e-01, time/batch = 18.2310s	
7598/26050 (epoch 14.583), train_loss = 1.26456878, grad/param norm = 1.6866e-01, time/batch = 17.9998s	
7599/26050 (epoch 14.585), train_loss = 1.06614776, grad/param norm = 1.6808e-01, time/batch = 18.1630s	
7600/26050 (epoch 14.587), train_loss = 1.21054420, grad/param norm = 1.7705e-01, time/batch = 18.8000s	
7601/26050 (epoch 14.589), train_loss = 1.32236628, grad/param norm = 2.0816e-01, time/batch = 16.9957s	
7602/26050 (epoch 14.591), train_loss = 1.17565503, grad/param norm = 1.6996e-01, time/batch = 17.1509s	
7603/26050 (epoch 14.593), train_loss = 1.05444108, grad/param norm = 1.8028e-01, time/batch = 16.5542s	
7604/26050 (epoch 14.595), train_loss = 1.29313281, grad/param norm = 2.0452e-01, time/batch = 17.8039s	
7605/26050 (epoch 14.597), train_loss = 1.20544014, grad/param norm = 1.7074e-01, time/batch = 18.4043s	
7606/26050 (epoch 14.599), train_loss = 1.14409790, grad/param norm = 1.6467e-01, time/batch = 15.3127s	
7607/26050 (epoch 14.601), train_loss = 1.37118679, grad/param norm = 1.7887e-01, time/batch = 18.1474s	
7608/26050 (epoch 14.603), train_loss = 1.23233048, grad/param norm = 1.7647e-01, time/batch = 16.7266s	
7609/26050 (epoch 14.605), train_loss = 1.11603408, grad/param norm = 1.6220e-01, time/batch = 18.2313s	
7610/26050 (epoch 14.607), train_loss = 1.32041363, grad/param norm = 1.9931e-01, time/batch = 14.8829s	
7611/26050 (epoch 14.608), train_loss = 1.05272416, grad/param norm = 1.5079e-01, time/batch = 17.8974s	
7612/26050 (epoch 14.610), train_loss = 1.15675908, grad/param norm = 1.7483e-01, time/batch = 18.2448s	
7613/26050 (epoch 14.612), train_loss = 1.18545519, grad/param norm = 1.8189e-01, time/batch = 18.1465s	
7614/26050 (epoch 14.614), train_loss = 1.25390161, grad/param norm = 1.8157e-01, time/batch = 18.4050s	
7615/26050 (epoch 14.616), train_loss = 1.37912848, grad/param norm = 1.8951e-01, time/batch = 14.8221s	
7616/26050 (epoch 14.618), train_loss = 1.11926144, grad/param norm = 1.7514e-01, time/batch = 17.9211s	
7617/26050 (epoch 14.620), train_loss = 1.20264791, grad/param norm = 1.7081e-01, time/batch = 17.9837s	
7618/26050 (epoch 14.622), train_loss = 1.03236118, grad/param norm = 1.6448e-01, time/batch = 18.2401s	
7619/26050 (epoch 14.624), train_loss = 1.04584626, grad/param norm = 1.6129e-01, time/batch = 18.4793s	
7620/26050 (epoch 14.626), train_loss = 1.23601836, grad/param norm = 1.6973e-01, time/batch = 18.0712s	
7621/26050 (epoch 14.628), train_loss = 1.12327629, grad/param norm = 1.7576e-01, time/batch = 18.9909s	
7622/26050 (epoch 14.630), train_loss = 1.30934997, grad/param norm = 1.7069e-01, time/batch = 18.5715s	
7623/26050 (epoch 14.631), train_loss = 1.33755880, grad/param norm = 1.8044e-01, time/batch = 15.3039s	
7624/26050 (epoch 14.633), train_loss = 1.09705447, grad/param norm = 1.7017e-01, time/batch = 18.1436s	
7625/26050 (epoch 14.635), train_loss = 1.09404989, grad/param norm = 1.5133e-01, time/batch = 18.5628s	
7626/26050 (epoch 14.637), train_loss = 1.06758708, grad/param norm = 1.7458e-01, time/batch = 15.3813s	
7627/26050 (epoch 14.639), train_loss = 1.29673314, grad/param norm = 1.7797e-01, time/batch = 14.7973s	
7628/26050 (epoch 14.641), train_loss = 1.12990100, grad/param norm = 1.5928e-01, time/batch = 18.0747s	
7629/26050 (epoch 14.643), train_loss = 1.03073665, grad/param norm = 1.4959e-01, time/batch = 18.6426s	
7630/26050 (epoch 14.645), train_loss = 1.19846198, grad/param norm = 1.7058e-01, time/batch = 17.6603s	
7631/26050 (epoch 14.647), train_loss = 1.12750871, grad/param norm = 1.6530e-01, time/batch = 17.2182s	
7632/26050 (epoch 14.649), train_loss = 1.19168359, grad/param norm = 1.8646e-01, time/batch = 18.4932s	
7633/26050 (epoch 14.651), train_loss = 1.09944543, grad/param norm = 1.8065e-01, time/batch = 18.6432s	
7634/26050 (epoch 14.653), train_loss = 1.19553456, grad/param norm = 1.7674e-01, time/batch = 17.4011s	
7635/26050 (epoch 14.655), train_loss = 1.10207791, grad/param norm = 1.6304e-01, time/batch = 16.3107s	
7636/26050 (epoch 14.656), train_loss = 1.01600007, grad/param norm = 1.6803e-01, time/batch = 18.0566s	
7637/26050 (epoch 14.658), train_loss = 1.35990819, grad/param norm = 1.8594e-01, time/batch = 18.1351s	
7638/26050 (epoch 14.660), train_loss = 1.04496576, grad/param norm = 1.6521e-01, time/batch = 17.8160s	
7639/26050 (epoch 14.662), train_loss = 1.05856437, grad/param norm = 1.5315e-01, time/batch = 18.3964s	
7640/26050 (epoch 14.664), train_loss = 1.14659592, grad/param norm = 1.7575e-01, time/batch = 17.9029s	
7641/26050 (epoch 14.666), train_loss = 1.16229810, grad/param norm = 1.8391e-01, time/batch = 17.7302s	
7642/26050 (epoch 14.668), train_loss = 0.97933084, grad/param norm = 1.8518e-01, time/batch = 18.6476s	
7643/26050 (epoch 14.670), train_loss = 1.34590765, grad/param norm = 1.8947e-01, time/batch = 18.4101s	
7644/26050 (epoch 14.672), train_loss = 1.12352040, grad/param norm = 1.7419e-01, time/batch = 15.6138s	
7645/26050 (epoch 14.674), train_loss = 1.05905941, grad/param norm = 1.6734e-01, time/batch = 16.5754s	
7646/26050 (epoch 14.676), train_loss = 1.17694271, grad/param norm = 1.7243e-01, time/batch = 18.3411s	
7647/26050 (epoch 14.678), train_loss = 1.29876976, grad/param norm = 1.8214e-01, time/batch = 15.8104s	
7648/26050 (epoch 14.679), train_loss = 1.37776288, grad/param norm = 1.9035e-01, time/batch = 17.5431s	
7649/26050 (epoch 14.681), train_loss = 1.18801996, grad/param norm = 1.7287e-01, time/batch = 17.9763s	
7650/26050 (epoch 14.683), train_loss = 1.06139123, grad/param norm = 2.0074e-01, time/batch = 17.7477s	
7651/26050 (epoch 14.685), train_loss = 1.12777080, grad/param norm = 1.6953e-01, time/batch = 16.7189s	
7652/26050 (epoch 14.687), train_loss = 0.98755370, grad/param norm = 1.6497e-01, time/batch = 17.5704s	
7653/26050 (epoch 14.689), train_loss = 1.13988853, grad/param norm = 1.8559e-01, time/batch = 18.2288s	
7654/26050 (epoch 14.691), train_loss = 0.91399670, grad/param norm = 1.5124e-01, time/batch = 15.9600s	
7655/26050 (epoch 14.693), train_loss = 1.06236747, grad/param norm = 1.6660e-01, time/batch = 18.7231s	
7656/26050 (epoch 14.695), train_loss = 1.17276667, grad/param norm = 1.7399e-01, time/batch = 18.1458s	
7657/26050 (epoch 14.697), train_loss = 1.06254888, grad/param norm = 1.6905e-01, time/batch = 17.8881s	
7658/26050 (epoch 14.699), train_loss = 1.23021179, grad/param norm = 1.8374e-01, time/batch = 17.8989s	
7659/26050 (epoch 14.701), train_loss = 1.03703155, grad/param norm = 1.6225e-01, time/batch = 18.1393s	
7660/26050 (epoch 14.702), train_loss = 1.33268013, grad/param norm = 1.9333e-01, time/batch = 15.3867s	
7661/26050 (epoch 14.704), train_loss = 1.21300735, grad/param norm = 1.6102e-01, time/batch = 16.8941s	
7662/26050 (epoch 14.706), train_loss = 1.19321169, grad/param norm = 1.9900e-01, time/batch = 14.2101s	
7663/26050 (epoch 14.708), train_loss = 1.26417865, grad/param norm = 1.8172e-01, time/batch = 18.1352s	
7664/26050 (epoch 14.710), train_loss = 1.23424361, grad/param norm = 1.7971e-01, time/batch = 17.5569s	
7665/26050 (epoch 14.712), train_loss = 1.28903793, grad/param norm = 1.9229e-01, time/batch = 17.8966s	
7666/26050 (epoch 14.714), train_loss = 1.00862333, grad/param norm = 1.7019e-01, time/batch = 18.6396s	
7667/26050 (epoch 14.716), train_loss = 1.43301812, grad/param norm = 1.9753e-01, time/batch = 18.7399s	
7668/26050 (epoch 14.718), train_loss = 1.27796915, grad/param norm = 1.8448e-01, time/batch = 17.8965s	
7669/26050 (epoch 14.720), train_loss = 1.11651775, grad/param norm = 1.7053e-01, time/batch = 18.4868s	
7670/26050 (epoch 14.722), train_loss = 1.04976839, grad/param norm = 1.6588e-01, time/batch = 16.1468s	
7671/26050 (epoch 14.724), train_loss = 1.07186727, grad/param norm = 1.8081e-01, time/batch = 16.5445s	
7672/26050 (epoch 14.726), train_loss = 1.28359610, grad/param norm = 1.8484e-01, time/batch = 14.9030s	
7673/26050 (epoch 14.727), train_loss = 1.23232871, grad/param norm = 1.7231e-01, time/batch = 16.5466s	
7674/26050 (epoch 14.729), train_loss = 1.22186943, grad/param norm = 1.7355e-01, time/batch = 18.2414s	
7675/26050 (epoch 14.731), train_loss = 1.20620671, grad/param norm = 1.6934e-01, time/batch = 17.5683s	
7676/26050 (epoch 14.733), train_loss = 1.14172032, grad/param norm = 2.0102e-01, time/batch = 16.9121s	
7677/26050 (epoch 14.735), train_loss = 1.37776964, grad/param norm = 1.9723e-01, time/batch = 17.4102s	
7678/26050 (epoch 14.737), train_loss = 1.15201785, grad/param norm = 1.6686e-01, time/batch = 15.1387s	
7679/26050 (epoch 14.739), train_loss = 1.23737730, grad/param norm = 1.8048e-01, time/batch = 18.4852s	
7680/26050 (epoch 14.741), train_loss = 1.09773774, grad/param norm = 1.7706e-01, time/batch = 17.4030s	
7681/26050 (epoch 14.743), train_loss = 1.21199132, grad/param norm = 1.8705e-01, time/batch = 18.4760s	
7682/26050 (epoch 14.745), train_loss = 1.06199234, grad/param norm = 1.7936e-01, time/batch = 17.9943s	
7683/26050 (epoch 14.747), train_loss = 1.06608004, grad/param norm = 1.5369e-01, time/batch = 18.0802s	
7684/26050 (epoch 14.749), train_loss = 1.32343044, grad/param norm = 1.8394e-01, time/batch = 18.5768s	
7685/26050 (epoch 14.750), train_loss = 1.16737035, grad/param norm = 1.5841e-01, time/batch = 16.2129s	
7686/26050 (epoch 14.752), train_loss = 1.14163302, grad/param norm = 2.0199e-01, time/batch = 15.1401s	
7687/26050 (epoch 14.754), train_loss = 1.18749078, grad/param norm = 1.7045e-01, time/batch = 17.4987s	
7688/26050 (epoch 14.756), train_loss = 1.17655020, grad/param norm = 1.7814e-01, time/batch = 18.0654s	
7689/26050 (epoch 14.758), train_loss = 1.18627881, grad/param norm = 1.7614e-01, time/batch = 18.4867s	
7690/26050 (epoch 14.760), train_loss = 1.31414226, grad/param norm = 1.7868e-01, time/batch = 15.3988s	
7691/26050 (epoch 14.762), train_loss = 1.09396526, grad/param norm = 1.6109e-01, time/batch = 18.8093s	
7692/26050 (epoch 14.764), train_loss = 1.21675293, grad/param norm = 1.8197e-01, time/batch = 17.4762s	
7693/26050 (epoch 14.766), train_loss = 1.26933677, grad/param norm = 2.0716e-01, time/batch = 17.0741s	
7694/26050 (epoch 14.768), train_loss = 1.05338917, grad/param norm = 1.5735e-01, time/batch = 17.1588s	
7695/26050 (epoch 14.770), train_loss = 1.14358653, grad/param norm = 1.7912e-01, time/batch = 15.8895s	
7696/26050 (epoch 14.772), train_loss = 1.15774157, grad/param norm = 1.6452e-01, time/batch = 17.3115s	
7697/26050 (epoch 14.774), train_loss = 1.02656666, grad/param norm = 1.6823e-01, time/batch = 18.8247s	
7698/26050 (epoch 14.775), train_loss = 0.87228229, grad/param norm = 1.6428e-01, time/batch = 18.2367s	
7699/26050 (epoch 14.777), train_loss = 1.08655488, grad/param norm = 1.6025e-01, time/batch = 15.7077s	
7700/26050 (epoch 14.779), train_loss = 1.13514101, grad/param norm = 1.8232e-01, time/batch = 18.1402s	
7701/26050 (epoch 14.781), train_loss = 1.09174417, grad/param norm = 1.6502e-01, time/batch = 18.0826s	
7702/26050 (epoch 14.783), train_loss = 1.06577712, grad/param norm = 1.6527e-01, time/batch = 17.9026s	
7703/26050 (epoch 14.785), train_loss = 1.13649109, grad/param norm = 1.7422e-01, time/batch = 16.4071s	
7704/26050 (epoch 14.787), train_loss = 1.09455134, grad/param norm = 1.7009e-01, time/batch = 16.2960s	
7705/26050 (epoch 14.789), train_loss = 1.08862078, grad/param norm = 1.9090e-01, time/batch = 18.2365s	
7706/26050 (epoch 14.791), train_loss = 1.13848241, grad/param norm = 1.7366e-01, time/batch = 16.7891s	
7707/26050 (epoch 14.793), train_loss = 1.14232219, grad/param norm = 1.9313e-01, time/batch = 18.7348s	
7708/26050 (epoch 14.795), train_loss = 0.98739493, grad/param norm = 1.5601e-01, time/batch = 17.5817s	
7709/26050 (epoch 14.797), train_loss = 1.07379805, grad/param norm = 1.6647e-01, time/batch = 17.2301s	
7710/26050 (epoch 14.798), train_loss = 1.01891534, grad/param norm = 1.7207e-01, time/batch = 15.4008s	
7711/26050 (epoch 14.800), train_loss = 1.00684312, grad/param norm = 1.4866e-01, time/batch = 18.0639s	
7712/26050 (epoch 14.802), train_loss = 1.11405480, grad/param norm = 1.7584e-01, time/batch = 17.6482s	
7713/26050 (epoch 14.804), train_loss = 1.12344598, grad/param norm = 1.7038e-01, time/batch = 18.1407s	
7714/26050 (epoch 14.806), train_loss = 1.24025011, grad/param norm = 1.7787e-01, time/batch = 17.9019s	
7715/26050 (epoch 14.808), train_loss = 1.13190148, grad/param norm = 1.6783e-01, time/batch = 18.0918s	
7716/26050 (epoch 14.810), train_loss = 1.07900606, grad/param norm = 1.7052e-01, time/batch = 17.5689s	
7717/26050 (epoch 14.812), train_loss = 1.02910705, grad/param norm = 1.7625e-01, time/batch = 17.7387s	
7718/26050 (epoch 14.814), train_loss = 1.02608972, grad/param norm = 1.9103e-01, time/batch = 15.9619s	
7719/26050 (epoch 14.816), train_loss = 1.27617037, grad/param norm = 1.9024e-01, time/batch = 14.5340s	
7720/26050 (epoch 14.818), train_loss = 1.30432429, grad/param norm = 2.2098e-01, time/batch = 18.0641s	
7721/26050 (epoch 14.820), train_loss = 1.16718937, grad/param norm = 1.7462e-01, time/batch = 17.9778s	
7722/26050 (epoch 14.821), train_loss = 1.30391449, grad/param norm = 1.9118e-01, time/batch = 18.7338s	
7723/26050 (epoch 14.823), train_loss = 1.33776335, grad/param norm = 1.9872e-01, time/batch = 17.4010s	
7724/26050 (epoch 14.825), train_loss = 1.13972576, grad/param norm = 1.7882e-01, time/batch = 17.9729s	
7725/26050 (epoch 14.827), train_loss = 1.17531459, grad/param norm = 1.9444e-01, time/batch = 17.9936s	
7726/26050 (epoch 14.829), train_loss = 1.20523263, grad/param norm = 1.7507e-01, time/batch = 17.3190s	
7727/26050 (epoch 14.831), train_loss = 1.28211350, grad/param norm = 1.7589e-01, time/batch = 17.0623s	
7728/26050 (epoch 14.833), train_loss = 1.36807900, grad/param norm = 1.9680e-01, time/batch = 17.4906s	
7729/26050 (epoch 14.835), train_loss = 1.37826214, grad/param norm = 1.8702e-01, time/batch = 18.1704s	
7730/26050 (epoch 14.837), train_loss = 1.14998506, grad/param norm = 1.7919e-01, time/batch = 17.8991s	
7731/26050 (epoch 14.839), train_loss = 1.18784196, grad/param norm = 1.9015e-01, time/batch = 18.5700s	
7732/26050 (epoch 14.841), train_loss = 1.26683418, grad/param norm = 1.8375e-01, time/batch = 18.0652s	
7733/26050 (epoch 14.843), train_loss = 1.17070429, grad/param norm = 1.7340e-01, time/batch = 17.3169s	
7734/26050 (epoch 14.845), train_loss = 1.08339438, grad/param norm = 1.5704e-01, time/batch = 15.8126s	
7735/26050 (epoch 14.846), train_loss = 1.26942296, grad/param norm = 1.6951e-01, time/batch = 18.2973s	
7736/26050 (epoch 14.848), train_loss = 1.14078440, grad/param norm = 1.6562e-01, time/batch = 17.2277s	
7737/26050 (epoch 14.850), train_loss = 1.07535294, grad/param norm = 1.6587e-01, time/batch = 18.0657s	
7738/26050 (epoch 14.852), train_loss = 1.13352594, grad/param norm = 1.7046e-01, time/batch = 15.4441s	
7739/26050 (epoch 14.854), train_loss = 1.13150925, grad/param norm = 1.6724e-01, time/batch = 17.7730s	
7740/26050 (epoch 14.856), train_loss = 1.11280131, grad/param norm = 1.9095e-01, time/batch = 17.4852s	
7741/26050 (epoch 14.858), train_loss = 1.05241706, grad/param norm = 1.7067e-01, time/batch = 18.6497s	
7742/26050 (epoch 14.860), train_loss = 1.21018014, grad/param norm = 1.7646e-01, time/batch = 18.3931s	
7743/26050 (epoch 14.862), train_loss = 1.20029546, grad/param norm = 1.7761e-01, time/batch = 18.0662s	
7744/26050 (epoch 14.864), train_loss = 1.19478311, grad/param norm = 1.9438e-01, time/batch = 17.8183s	
7745/26050 (epoch 14.866), train_loss = 1.09783539, grad/param norm = 1.6198e-01, time/batch = 18.1530s	
7746/26050 (epoch 14.868), train_loss = 1.23837916, grad/param norm = 1.9655e-01, time/batch = 17.5538s	
7747/26050 (epoch 14.869), train_loss = 1.05266087, grad/param norm = 1.6018e-01, time/batch = 17.2316s	
7748/26050 (epoch 14.871), train_loss = 0.99789365, grad/param norm = 1.6379e-01, time/batch = 17.8072s	
7749/26050 (epoch 14.873), train_loss = 1.22154629, grad/param norm = 1.7614e-01, time/batch = 17.0605s	
7750/26050 (epoch 14.875), train_loss = 1.15027350, grad/param norm = 1.7944e-01, time/batch = 16.8867s	
7751/26050 (epoch 14.877), train_loss = 1.03714222, grad/param norm = 1.6119e-01, time/batch = 15.3864s	
7752/26050 (epoch 14.879), train_loss = 1.16746501, grad/param norm = 1.6192e-01, time/batch = 18.6381s	
7753/26050 (epoch 14.881), train_loss = 1.30489116, grad/param norm = 1.7810e-01, time/batch = 16.4775s	
7754/26050 (epoch 14.883), train_loss = 1.20116644, grad/param norm = 1.8273e-01, time/batch = 16.9786s	
7755/26050 (epoch 14.885), train_loss = 0.90640812, grad/param norm = 1.5829e-01, time/batch = 18.0708s	
7756/26050 (epoch 14.887), train_loss = 1.20156654, grad/param norm = 1.7859e-01, time/batch = 16.7074s	
7757/26050 (epoch 14.889), train_loss = 1.11590115, grad/param norm = 1.6484e-01, time/batch = 17.3956s	
7758/26050 (epoch 14.891), train_loss = 0.91967358, grad/param norm = 1.4820e-01, time/batch = 17.9833s	
7759/26050 (epoch 14.893), train_loss = 0.95652729, grad/param norm = 1.5669e-01, time/batch = 18.6586s	
7760/26050 (epoch 14.894), train_loss = 1.12337946, grad/param norm = 1.7352e-01, time/batch = 16.1364s	
7761/26050 (epoch 14.896), train_loss = 1.26442903, grad/param norm = 1.6825e-01, time/batch = 17.6407s	
7762/26050 (epoch 14.898), train_loss = 1.08608891, grad/param norm = 1.7948e-01, time/batch = 18.1411s	
7763/26050 (epoch 14.900), train_loss = 1.23586609, grad/param norm = 1.8592e-01, time/batch = 18.4876s	
7764/26050 (epoch 14.902), train_loss = 1.15753525, grad/param norm = 1.7921e-01, time/batch = 17.7372s	
7765/26050 (epoch 14.904), train_loss = 1.13657512, grad/param norm = 1.7559e-01, time/batch = 18.5712s	
7766/26050 (epoch 14.906), train_loss = 1.13681790, grad/param norm = 1.7957e-01, time/batch = 17.9947s	
7767/26050 (epoch 14.908), train_loss = 1.13237842, grad/param norm = 1.7426e-01, time/batch = 17.1496s	
7768/26050 (epoch 14.910), train_loss = 1.06104676, grad/param norm = 1.5541e-01, time/batch = 15.3171s	
7769/26050 (epoch 14.912), train_loss = 1.39453774, grad/param norm = 1.9958e-01, time/batch = 15.2226s	
7770/26050 (epoch 14.914), train_loss = 1.52556693, grad/param norm = 2.1046e-01, time/batch = 17.9557s	
7771/26050 (epoch 14.916), train_loss = 1.27016638, grad/param norm = 1.9120e-01, time/batch = 18.4838s	
7772/26050 (epoch 14.917), train_loss = 1.16862284, grad/param norm = 2.0012e-01, time/batch = 18.0753s	
7773/26050 (epoch 14.919), train_loss = 1.25373216, grad/param norm = 1.9416e-01, time/batch = 17.2213s	
7774/26050 (epoch 14.921), train_loss = 1.10667301, grad/param norm = 1.8303e-01, time/batch = 17.1488s	
7775/26050 (epoch 14.923), train_loss = 1.18405592, grad/param norm = 1.8449e-01, time/batch = 18.9901s	
7776/26050 (epoch 14.925), train_loss = 1.17017389, grad/param norm = 1.7329e-01, time/batch = 18.9789s	
7777/26050 (epoch 14.927), train_loss = 1.03155998, grad/param norm = 1.4971e-01, time/batch = 14.8114s	
7778/26050 (epoch 14.929), train_loss = 1.06052125, grad/param norm = 1.7216e-01, time/batch = 17.8102s	
7779/26050 (epoch 14.931), train_loss = 1.35758449, grad/param norm = 2.0303e-01, time/batch = 18.3027s	
7780/26050 (epoch 14.933), train_loss = 1.12610625, grad/param norm = 1.7477e-01, time/batch = 18.5668s	
7781/26050 (epoch 14.935), train_loss = 1.11800877, grad/param norm = 1.6816e-01, time/batch = 17.8010s	
7782/26050 (epoch 14.937), train_loss = 1.23866487, grad/param norm = 1.7552e-01, time/batch = 18.0653s	
7783/26050 (epoch 14.939), train_loss = 1.04596766, grad/param norm = 1.4639e-01, time/batch = 17.1395s	
7784/26050 (epoch 14.940), train_loss = 1.15946636, grad/param norm = 1.6062e-01, time/batch = 16.9684s	
7785/26050 (epoch 14.942), train_loss = 1.18149450, grad/param norm = 1.8322e-01, time/batch = 18.8101s	
7786/26050 (epoch 14.944), train_loss = 1.10946081, grad/param norm = 1.8076e-01, time/batch = 14.7996s	
7787/26050 (epoch 14.946), train_loss = 1.31477861, grad/param norm = 1.8727e-01, time/batch = 18.1395s	
7788/26050 (epoch 14.948), train_loss = 1.00894536, grad/param norm = 1.9020e-01, time/batch = 15.4448s	
7789/26050 (epoch 14.950), train_loss = 1.14734618, grad/param norm = 1.8517e-01, time/batch = 18.3051s	
7790/26050 (epoch 14.952), train_loss = 1.28337641, grad/param norm = 1.9428e-01, time/batch = 18.2219s	
7791/26050 (epoch 14.954), train_loss = 1.25207732, grad/param norm = 1.8233e-01, time/batch = 18.1416s	
7792/26050 (epoch 14.956), train_loss = 1.15298795, grad/param norm = 1.8093e-01, time/batch = 17.9922s	
7793/26050 (epoch 14.958), train_loss = 1.10960677, grad/param norm = 1.7241e-01, time/batch = 18.6468s	
7794/26050 (epoch 14.960), train_loss = 1.15109999, grad/param norm = 1.6912e-01, time/batch = 17.4006s	
7795/26050 (epoch 14.962), train_loss = 1.08813989, grad/param norm = 1.6173e-01, time/batch = 17.8160s	
7796/26050 (epoch 14.964), train_loss = 1.14975629, grad/param norm = 1.7376e-01, time/batch = 18.1568s	
7797/26050 (epoch 14.965), train_loss = 1.06358265, grad/param norm = 1.7219e-01, time/batch = 15.8278s	
7798/26050 (epoch 14.967), train_loss = 1.46057110, grad/param norm = 1.8335e-01, time/batch = 28.5011s	
7799/26050 (epoch 14.969), train_loss = 1.15063325, grad/param norm = 1.6158e-01, time/batch = 28.6593s	
7800/26050 (epoch 14.971), train_loss = 1.08295393, grad/param norm = 1.5283e-01, time/batch = 16.1014s	
7801/26050 (epoch 14.973), train_loss = 1.12844242, grad/param norm = 1.8643e-01, time/batch = 17.9913s	
7802/26050 (epoch 14.975), train_loss = 1.22490017, grad/param norm = 1.6952e-01, time/batch = 18.8904s	
7803/26050 (epoch 14.977), train_loss = 1.19091824, grad/param norm = 1.5841e-01, time/batch = 16.3063s	
7804/26050 (epoch 14.979), train_loss = 0.99117947, grad/param norm = 1.6623e-01, time/batch = 17.6514s	
7805/26050 (epoch 14.981), train_loss = 1.28865202, grad/param norm = 1.7116e-01, time/batch = 17.2385s	
7806/26050 (epoch 14.983), train_loss = 1.25979708, grad/param norm = 1.6909e-01, time/batch = 17.8206s	
7807/26050 (epoch 14.985), train_loss = 1.20790064, grad/param norm = 1.8673e-01, time/batch = 16.5548s	
7808/26050 (epoch 14.987), train_loss = 1.28850195, grad/param norm = 1.8494e-01, time/batch = 18.1219s	
7809/26050 (epoch 14.988), train_loss = 1.24824231, grad/param norm = 1.7048e-01, time/batch = 17.7382s	
7810/26050 (epoch 14.990), train_loss = 1.04178879, grad/param norm = 1.4999e-01, time/batch = 18.0616s	
7811/26050 (epoch 14.992), train_loss = 1.30286891, grad/param norm = 1.8512e-01, time/batch = 18.0605s	
7812/26050 (epoch 14.994), train_loss = 1.16633462, grad/param norm = 1.9094e-01, time/batch = 18.4149s	
7813/26050 (epoch 14.996), train_loss = 1.12046714, grad/param norm = 1.8121e-01, time/batch = 17.1553s	
7814/26050 (epoch 14.998), train_loss = 1.16378121, grad/param norm = 1.7196e-01, time/batch = 18.6354s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
7815/26050 (epoch 15.000), train_loss = 1.11372157, grad/param norm = 1.8103e-01, time/batch = 16.5399s	
7816/26050 (epoch 15.002), train_loss = 1.25788085, grad/param norm = 1.9997e-01, time/batch = 16.2182s	
7817/26050 (epoch 15.004), train_loss = 1.06379973, grad/param norm = 1.7742e-01, time/batch = 17.3205s	
7818/26050 (epoch 15.006), train_loss = 1.08052568, grad/param norm = 1.7039e-01, time/batch = 18.0640s	
7819/26050 (epoch 15.008), train_loss = 1.06290608, grad/param norm = 1.8011e-01, time/batch = 14.3145s	
7820/26050 (epoch 15.010), train_loss = 1.08996350, grad/param norm = 1.6827e-01, time/batch = 17.3223s	
7821/26050 (epoch 15.012), train_loss = 1.18103250, grad/param norm = 1.7502e-01, time/batch = 18.6596s	
7822/26050 (epoch 15.013), train_loss = 1.53514811, grad/param norm = 2.0162e-01, time/batch = 17.8279s	
7823/26050 (epoch 15.015), train_loss = 1.08992841, grad/param norm = 1.5896e-01, time/batch = 17.1541s	
7824/26050 (epoch 15.017), train_loss = 1.16733892, grad/param norm = 1.7273e-01, time/batch = 17.0494s	
7825/26050 (epoch 15.019), train_loss = 0.98085501, grad/param norm = 1.4493e-01, time/batch = 15.9096s	
7826/26050 (epoch 15.021), train_loss = 1.23356898, grad/param norm = 1.7917e-01, time/batch = 18.3154s	
7827/26050 (epoch 15.023), train_loss = 1.02908222, grad/param norm = 2.0070e-01, time/batch = 17.4046s	
7828/26050 (epoch 15.025), train_loss = 1.14738022, grad/param norm = 1.7362e-01, time/batch = 17.7378s	
7829/26050 (epoch 15.027), train_loss = 0.93804406, grad/param norm = 1.8055e-01, time/batch = 14.5456s	
7830/26050 (epoch 15.029), train_loss = 1.16258799, grad/param norm = 1.6507e-01, time/batch = 18.6478s	
7831/26050 (epoch 15.031), train_loss = 1.28280213, grad/param norm = 1.9749e-01, time/batch = 16.6442s	
7832/26050 (epoch 15.033), train_loss = 1.20015419, grad/param norm = 1.7350e-01, time/batch = 18.6504s	
7833/26050 (epoch 15.035), train_loss = 1.21912680, grad/param norm = 1.6821e-01, time/batch = 18.5845s	
7834/26050 (epoch 15.036), train_loss = 1.04707282, grad/param norm = 2.0757e-01, time/batch = 15.3889s	
7835/26050 (epoch 15.038), train_loss = 0.97319333, grad/param norm = 1.6075e-01, time/batch = 17.7062s	
7836/26050 (epoch 15.040), train_loss = 1.16658074, grad/param norm = 1.8537e-01, time/batch = 18.8943s	
7837/26050 (epoch 15.042), train_loss = 0.99212073, grad/param norm = 1.5900e-01, time/batch = 17.8283s	
7838/26050 (epoch 15.044), train_loss = 1.24588814, grad/param norm = 1.6879e-01, time/batch = 17.4719s	
7839/26050 (epoch 15.046), train_loss = 0.93922480, grad/param norm = 1.4708e-01, time/batch = 15.4700s	
7840/26050 (epoch 15.048), train_loss = 1.16383869, grad/param norm = 1.6571e-01, time/batch = 16.6282s	
7841/26050 (epoch 15.050), train_loss = 1.06471817, grad/param norm = 1.7827e-01, time/batch = 18.1387s	
7842/26050 (epoch 15.052), train_loss = 1.10224208, grad/param norm = 1.6425e-01, time/batch = 17.9751s	
7843/26050 (epoch 15.054), train_loss = 0.97958343, grad/param norm = 1.5726e-01, time/batch = 18.7350s	
7844/26050 (epoch 15.056), train_loss = 0.92592184, grad/param norm = 1.3834e-01, time/batch = 17.4847s	
7845/26050 (epoch 15.058), train_loss = 1.08704726, grad/param norm = 1.6091e-01, time/batch = 18.3260s	
7846/26050 (epoch 15.060), train_loss = 1.17080018, grad/param norm = 1.6479e-01, time/batch = 18.3876s	
7847/26050 (epoch 15.061), train_loss = 1.06587257, grad/param norm = 1.6691e-01, time/batch = 17.8305s	
7848/26050 (epoch 15.063), train_loss = 1.16619438, grad/param norm = 1.7429e-01, time/batch = 15.7117s	
7849/26050 (epoch 15.065), train_loss = 0.96420225, grad/param norm = 1.5620e-01, time/batch = 16.9945s	
7850/26050 (epoch 15.067), train_loss = 1.16776837, grad/param norm = 1.7965e-01, time/batch = 18.4908s	
7851/26050 (epoch 15.069), train_loss = 1.19464046, grad/param norm = 1.6152e-01, time/batch = 17.2140s	
7852/26050 (epoch 15.071), train_loss = 1.20208235, grad/param norm = 1.6783e-01, time/batch = 15.0558s	
7853/26050 (epoch 15.073), train_loss = 1.34884060, grad/param norm = 1.8463e-01, time/batch = 16.5490s	
7854/26050 (epoch 15.075), train_loss = 1.05692293, grad/param norm = 1.5998e-01, time/batch = 18.4904s	
7855/26050 (epoch 15.077), train_loss = 1.05684281, grad/param norm = 1.5936e-01, time/batch = 17.8874s	
7856/26050 (epoch 15.079), train_loss = 1.17162702, grad/param norm = 1.6903e-01, time/batch = 18.2402s	
7857/26050 (epoch 15.081), train_loss = 1.10477957, grad/param norm = 1.8812e-01, time/batch = 16.9814s	
7858/26050 (epoch 15.083), train_loss = 1.21577031, grad/param norm = 1.6194e-01, time/batch = 17.1385s	
7859/26050 (epoch 15.084), train_loss = 1.21432128, grad/param norm = 2.0034e-01, time/batch = 15.0598s	
7860/26050 (epoch 15.086), train_loss = 1.28678847, grad/param norm = 1.8291e-01, time/batch = 18.8202s	
7861/26050 (epoch 15.088), train_loss = 1.03390580, grad/param norm = 1.6065e-01, time/batch = 18.1495s	
7862/26050 (epoch 15.090), train_loss = 1.18810203, grad/param norm = 1.9163e-01, time/batch = 15.4582s	
7863/26050 (epoch 15.092), train_loss = 1.19017363, grad/param norm = 1.7501e-01, time/batch = 17.3105s	
7864/26050 (epoch 15.094), train_loss = 1.10814734, grad/param norm = 1.7633e-01, time/batch = 18.6137s	
7865/26050 (epoch 15.096), train_loss = 1.12182011, grad/param norm = 1.6411e-01, time/batch = 17.2255s	
7866/26050 (epoch 15.098), train_loss = 1.10512536, grad/param norm = 1.7118e-01, time/batch = 17.9127s	
7867/26050 (epoch 15.100), train_loss = 1.03438227, grad/param norm = 1.7803e-01, time/batch = 18.3999s	
7868/26050 (epoch 15.102), train_loss = 1.14851145, grad/param norm = 1.7300e-01, time/batch = 14.8891s	
7869/26050 (epoch 15.104), train_loss = 1.15012619, grad/param norm = 1.8154e-01, time/batch = 18.1441s	
7870/26050 (epoch 15.106), train_loss = 1.14960920, grad/param norm = 1.8941e-01, time/batch = 18.4026s	
7871/26050 (epoch 15.107), train_loss = 0.92635764, grad/param norm = 1.4678e-01, time/batch = 18.2304s	
7872/26050 (epoch 15.109), train_loss = 1.07089074, grad/param norm = 1.7570e-01, time/batch = 16.4693s	
7873/26050 (epoch 15.111), train_loss = 1.32313652, grad/param norm = 1.9272e-01, time/batch = 17.9885s	
7874/26050 (epoch 15.113), train_loss = 1.09438179, grad/param norm = 1.6991e-01, time/batch = 18.4932s	
7875/26050 (epoch 15.115), train_loss = 1.23807123, grad/param norm = 1.7582e-01, time/batch = 17.4007s	
7876/26050 (epoch 15.117), train_loss = 1.17768718, grad/param norm = 1.6506e-01, time/batch = 18.8986s	
7877/26050 (epoch 15.119), train_loss = 0.94907382, grad/param norm = 1.5918e-01, time/batch = 17.8151s	
7878/26050 (epoch 15.121), train_loss = 1.17382509, grad/param norm = 1.6655e-01, time/batch = 17.9017s	
7879/26050 (epoch 15.123), train_loss = 1.03151574, grad/param norm = 1.7608e-01, time/batch = 14.7383s	
7880/26050 (epoch 15.125), train_loss = 0.99326866, grad/param norm = 1.6386e-01, time/batch = 17.9041s	
7881/26050 (epoch 15.127), train_loss = 0.90834580, grad/param norm = 1.5076e-01, time/batch = 17.9773s	
7882/26050 (epoch 15.129), train_loss = 0.96335112, grad/param norm = 1.6092e-01, time/batch = 17.4834s	
7883/26050 (epoch 15.131), train_loss = 1.10280888, grad/param norm = 1.6994e-01, time/batch = 18.2991s	
7884/26050 (epoch 15.132), train_loss = 1.10985254, grad/param norm = 1.6538e-01, time/batch = 17.8904s	
7885/26050 (epoch 15.134), train_loss = 1.10850639, grad/param norm = 1.8930e-01, time/batch = 16.3787s	
7886/26050 (epoch 15.136), train_loss = 1.13593172, grad/param norm = 1.6715e-01, time/batch = 17.0607s	
7887/26050 (epoch 15.138), train_loss = 0.92756127, grad/param norm = 1.6496e-01, time/batch = 18.1526s	
7888/26050 (epoch 15.140), train_loss = 0.97192017, grad/param norm = 1.6999e-01, time/batch = 17.3805s	
7889/26050 (epoch 15.142), train_loss = 1.02351371, grad/param norm = 1.6602e-01, time/batch = 17.1324s	
7890/26050 (epoch 15.144), train_loss = 0.93969752, grad/param norm = 1.6760e-01, time/batch = 18.6398s	
7891/26050 (epoch 15.146), train_loss = 0.87307586, grad/param norm = 1.5833e-01, time/batch = 17.1382s	
7892/26050 (epoch 15.148), train_loss = 0.90788371, grad/param norm = 1.4128e-01, time/batch = 17.2111s	
7893/26050 (epoch 15.150), train_loss = 1.10349468, grad/param norm = 1.7431e-01, time/batch = 18.8086s	
7894/26050 (epoch 15.152), train_loss = 1.32663434, grad/param norm = 2.0809e-01, time/batch = 16.2205s	
7895/26050 (epoch 15.154), train_loss = 0.89916263, grad/param norm = 1.6460e-01, time/batch = 18.1574s	
7896/26050 (epoch 15.155), train_loss = 0.95044498, grad/param norm = 1.6946e-01, time/batch = 17.4917s	
7897/26050 (epoch 15.157), train_loss = 1.05522330, grad/param norm = 1.9313e-01, time/batch = 17.3057s	
7898/26050 (epoch 15.159), train_loss = 1.09906570, grad/param norm = 1.9919e-01, time/batch = 18.9979s	
7899/26050 (epoch 15.161), train_loss = 1.20363526, grad/param norm = 1.8779e-01, time/batch = 16.9755s	
7900/26050 (epoch 15.163), train_loss = 0.95543288, grad/param norm = 1.6874e-01, time/batch = 18.6589s	
7901/26050 (epoch 15.165), train_loss = 0.85896945, grad/param norm = 1.4802e-01, time/batch = 18.6617s	
7902/26050 (epoch 15.167), train_loss = 1.22355226, grad/param norm = 1.9308e-01, time/batch = 17.5658s	
7903/26050 (epoch 15.169), train_loss = 1.18658374, grad/param norm = 1.8313e-01, time/batch = 17.9864s	
7904/26050 (epoch 15.171), train_loss = 0.91853958, grad/param norm = 1.4595e-01, time/batch = 15.4056s	
7905/26050 (epoch 15.173), train_loss = 1.05661776, grad/param norm = 1.7955e-01, time/batch = 18.4759s	
7906/26050 (epoch 15.175), train_loss = 1.10323267, grad/param norm = 1.6796e-01, time/batch = 15.4834s	
7907/26050 (epoch 15.177), train_loss = 1.24507970, grad/param norm = 1.7345e-01, time/batch = 17.6363s	
7908/26050 (epoch 15.179), train_loss = 0.87966920, grad/param norm = 1.5134e-01, time/batch = 16.6284s	
7909/26050 (epoch 15.180), train_loss = 1.33819605, grad/param norm = 1.7436e-01, time/batch = 17.4887s	
7910/26050 (epoch 15.182), train_loss = 1.35427619, grad/param norm = 1.8255e-01, time/batch = 16.5598s	
7911/26050 (epoch 15.184), train_loss = 1.13908407, grad/param norm = 1.6665e-01, time/batch = 17.0579s	
7912/26050 (epoch 15.186), train_loss = 0.92411321, grad/param norm = 1.4861e-01, time/batch = 18.6606s	
7913/26050 (epoch 15.188), train_loss = 1.11779738, grad/param norm = 1.6553e-01, time/batch = 16.8172s	
7914/26050 (epoch 15.190), train_loss = 1.17376523, grad/param norm = 1.8239e-01, time/batch = 17.6456s	
7915/26050 (epoch 15.192), train_loss = 1.17266269, grad/param norm = 1.6389e-01, time/batch = 18.3200s	
7916/26050 (epoch 15.194), train_loss = 1.15396545, grad/param norm = 1.6862e-01, time/batch = 17.5642s	
7917/26050 (epoch 15.196), train_loss = 1.21968472, grad/param norm = 1.7765e-01, time/batch = 18.4002s	
7918/26050 (epoch 15.198), train_loss = 1.04404528, grad/param norm = 1.5721e-01, time/batch = 17.8060s	
7919/26050 (epoch 15.200), train_loss = 1.02814581, grad/param norm = 1.6910e-01, time/batch = 18.1518s	
7920/26050 (epoch 15.202), train_loss = 1.08507114, grad/param norm = 1.7630e-01, time/batch = 15.2274s	
7921/26050 (epoch 15.203), train_loss = 1.23437958, grad/param norm = 1.9099e-01, time/batch = 18.3146s	
7922/26050 (epoch 15.205), train_loss = 1.06526773, grad/param norm = 1.7275e-01, time/batch = 18.4773s	
7923/26050 (epoch 15.207), train_loss = 1.05761109, grad/param norm = 1.6358e-01, time/batch = 17.5684s	
7924/26050 (epoch 15.209), train_loss = 1.12845004, grad/param norm = 1.5904e-01, time/batch = 15.4792s	
7925/26050 (epoch 15.211), train_loss = 0.95603623, grad/param norm = 1.6117e-01, time/batch = 16.1323s	
7926/26050 (epoch 15.213), train_loss = 1.17785668, grad/param norm = 1.8529e-01, time/batch = 17.4127s	
7927/26050 (epoch 15.215), train_loss = 1.12271143, grad/param norm = 1.9271e-01, time/batch = 18.7288s	
7928/26050 (epoch 15.217), train_loss = 1.10886568, grad/param norm = 1.6977e-01, time/batch = 17.7281s	
7929/26050 (epoch 15.219), train_loss = 1.08812299, grad/param norm = 1.8661e-01, time/batch = 17.9658s	
7930/26050 (epoch 15.221), train_loss = 1.00345369, grad/param norm = 1.7073e-01, time/batch = 17.0653s	
7931/26050 (epoch 15.223), train_loss = 1.13472556, grad/param norm = 1.6663e-01, time/batch = 17.7357s	
7932/26050 (epoch 15.225), train_loss = 1.01943039, grad/param norm = 1.6545e-01, time/batch = 18.1549s	
7933/26050 (epoch 15.226), train_loss = 1.21033492, grad/param norm = 1.9178e-01, time/batch = 16.4743s	
7934/26050 (epoch 15.228), train_loss = 1.25272201, grad/param norm = 1.7415e-01, time/batch = 18.1517s	
7935/26050 (epoch 15.230), train_loss = 1.16317131, grad/param norm = 1.6750e-01, time/batch = 16.9997s	
7936/26050 (epoch 15.232), train_loss = 1.24706455, grad/param norm = 1.9160e-01, time/batch = 18.0788s	
7937/26050 (epoch 15.234), train_loss = 0.98629380, grad/param norm = 1.6493e-01, time/batch = 16.1554s	
7938/26050 (epoch 15.236), train_loss = 1.20967148, grad/param norm = 1.7812e-01, time/batch = 17.8808s	
7939/26050 (epoch 15.238), train_loss = 0.96668695, grad/param norm = 1.5755e-01, time/batch = 17.3093s	
7940/26050 (epoch 15.240), train_loss = 1.10966475, grad/param norm = 1.7395e-01, time/batch = 15.7267s	
7941/26050 (epoch 15.242), train_loss = 1.11736724, grad/param norm = 1.5703e-01, time/batch = 17.2330s	
7942/26050 (epoch 15.244), train_loss = 1.11315272, grad/param norm = 1.9059e-01, time/batch = 17.9909s	
7943/26050 (epoch 15.246), train_loss = 1.05762781, grad/param norm = 1.5780e-01, time/batch = 17.1979s	
7944/26050 (epoch 15.248), train_loss = 1.13130202, grad/param norm = 1.7247e-01, time/batch = 18.4179s	
7945/26050 (epoch 15.250), train_loss = 1.12342058, grad/param norm = 1.9927e-01, time/batch = 17.9088s	
7946/26050 (epoch 15.251), train_loss = 1.07531041, grad/param norm = 1.6760e-01, time/batch = 16.3048s	
7947/26050 (epoch 15.253), train_loss = 0.99155560, grad/param norm = 1.6028e-01, time/batch = 17.4103s	
7948/26050 (epoch 15.255), train_loss = 1.31380354, grad/param norm = 1.7238e-01, time/batch = 17.1578s	
7949/26050 (epoch 15.257), train_loss = 1.12894572, grad/param norm = 1.8542e-01, time/batch = 18.4971s	
7950/26050 (epoch 15.259), train_loss = 1.27268381, grad/param norm = 1.7880e-01, time/batch = 17.8171s	
7951/26050 (epoch 15.261), train_loss = 1.01202186, grad/param norm = 1.7483e-01, time/batch = 18.4062s	
7952/26050 (epoch 15.263), train_loss = 1.15067743, grad/param norm = 1.7129e-01, time/batch = 17.8121s	
7953/26050 (epoch 15.265), train_loss = 1.29723065, grad/param norm = 1.8618e-01, time/batch = 18.3987s	
7954/26050 (epoch 15.267), train_loss = 1.22274396, grad/param norm = 1.7258e-01, time/batch = 15.8000s	
7955/26050 (epoch 15.269), train_loss = 1.31046581, grad/param norm = 1.9508e-01, time/batch = 15.2294s	
7956/26050 (epoch 15.271), train_loss = 1.18018266, grad/param norm = 1.7781e-01, time/batch = 16.6297s	
7957/26050 (epoch 15.273), train_loss = 1.08716198, grad/param norm = 1.8559e-01, time/batch = 18.1445s	
7958/26050 (epoch 15.274), train_loss = 1.08769336, grad/param norm = 1.6946e-01, time/batch = 15.1460s	
7959/26050 (epoch 15.276), train_loss = 1.05593399, grad/param norm = 1.7444e-01, time/batch = 17.8201s	
7960/26050 (epoch 15.278), train_loss = 1.25461606, grad/param norm = 1.7950e-01, time/batch = 17.4840s	
7961/26050 (epoch 15.280), train_loss = 1.10685082, grad/param norm = 1.6188e-01, time/batch = 17.6522s	
7962/26050 (epoch 15.282), train_loss = 1.15380257, grad/param norm = 1.7376e-01, time/batch = 18.1536s	
7963/26050 (epoch 15.284), train_loss = 1.06564146, grad/param norm = 1.7287e-01, time/batch = 16.7124s	
7964/26050 (epoch 15.286), train_loss = 1.14377949, grad/param norm = 1.6946e-01, time/batch = 17.7228s	
7965/26050 (epoch 15.288), train_loss = 0.97394328, grad/param norm = 1.5721e-01, time/batch = 17.7361s	
7966/26050 (epoch 15.290), train_loss = 1.11158025, grad/param norm = 1.7185e-01, time/batch = 17.9949s	
7967/26050 (epoch 15.292), train_loss = 1.03008486, grad/param norm = 1.5648e-01, time/batch = 18.0714s	
7968/26050 (epoch 15.294), train_loss = 1.15697271, grad/param norm = 1.8947e-01, time/batch = 17.4703s	
7969/26050 (epoch 15.296), train_loss = 1.25390093, grad/param norm = 1.8114e-01, time/batch = 18.7118s	
7970/26050 (epoch 15.298), train_loss = 1.12489766, grad/param norm = 1.6836e-01, time/batch = 18.7316s	
7971/26050 (epoch 15.299), train_loss = 0.89033902, grad/param norm = 1.5307e-01, time/batch = 16.6317s	
7972/26050 (epoch 15.301), train_loss = 1.01474079, grad/param norm = 1.7810e-01, time/batch = 18.8215s	
7973/26050 (epoch 15.303), train_loss = 1.15261132, grad/param norm = 1.7964e-01, time/batch = 15.3065s	
7974/26050 (epoch 15.305), train_loss = 0.95942064, grad/param norm = 1.7388e-01, time/batch = 16.1114s	
7975/26050 (epoch 15.307), train_loss = 1.04545898, grad/param norm = 1.7848e-01, time/batch = 17.4848s	
7976/26050 (epoch 15.309), train_loss = 1.09418456, grad/param norm = 1.7427e-01, time/batch = 17.7358s	
7977/26050 (epoch 15.311), train_loss = 1.23802956, grad/param norm = 1.9532e-01, time/batch = 18.4077s	
7978/26050 (epoch 15.313), train_loss = 1.10652695, grad/param norm = 2.0589e-01, time/batch = 18.0711s	
7979/26050 (epoch 15.315), train_loss = 1.21661673, grad/param norm = 1.9104e-01, time/batch = 17.3373s	
7980/26050 (epoch 15.317), train_loss = 1.09973705, grad/param norm = 1.6626e-01, time/batch = 17.9134s	
7981/26050 (epoch 15.319), train_loss = 1.06612592, grad/param norm = 1.7000e-01, time/batch = 17.8983s	
7982/26050 (epoch 15.321), train_loss = 1.08316668, grad/param norm = 1.8036e-01, time/batch = 17.2337s	
7983/26050 (epoch 15.322), train_loss = 1.14893750, grad/param norm = 1.7362e-01, time/batch = 18.4152s	
7984/26050 (epoch 15.324), train_loss = 0.94689294, grad/param norm = 1.7562e-01, time/batch = 17.3272s	
7985/26050 (epoch 15.326), train_loss = 1.27870538, grad/param norm = 1.7750e-01, time/batch = 18.6562s	
7986/26050 (epoch 15.328), train_loss = 1.16823096, grad/param norm = 1.5998e-01, time/batch = 17.3208s	
7987/26050 (epoch 15.330), train_loss = 1.01352473, grad/param norm = 1.7146e-01, time/batch = 16.6926s	
7988/26050 (epoch 15.332), train_loss = 1.18613490, grad/param norm = 1.7164e-01, time/batch = 16.5391s	
7989/26050 (epoch 15.334), train_loss = 1.08934406, grad/param norm = 1.7933e-01, time/batch = 17.9941s	
7990/26050 (epoch 15.336), train_loss = 1.04103988, grad/param norm = 1.6273e-01, time/batch = 18.1716s	
7991/26050 (epoch 15.338), train_loss = 0.99551708, grad/param norm = 1.5733e-01, time/batch = 16.4832s	
7992/26050 (epoch 15.340), train_loss = 1.23306912, grad/param norm = 1.8836e-01, time/batch = 17.9534s	
7993/26050 (epoch 15.342), train_loss = 1.26992092, grad/param norm = 1.8467e-01, time/batch = 16.2133s	
7994/26050 (epoch 15.344), train_loss = 1.10029124, grad/param norm = 1.7539e-01, time/batch = 18.2190s	
7995/26050 (epoch 15.345), train_loss = 1.08395165, grad/param norm = 1.7155e-01, time/batch = 17.3934s	
7996/26050 (epoch 15.347), train_loss = 1.22181049, grad/param norm = 1.8860e-01, time/batch = 17.9129s	
7997/26050 (epoch 15.349), train_loss = 1.17202370, grad/param norm = 1.7291e-01, time/batch = 16.9905s	
7998/26050 (epoch 15.351), train_loss = 1.13353154, grad/param norm = 1.7869e-01, time/batch = 16.0644s	
7999/26050 (epoch 15.353), train_loss = 1.10630240, grad/param norm = 1.8017e-01, time/batch = 17.9855s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch15.36_1.6379.t7	
8000/26050 (epoch 15.355), train_loss = 1.19525494, grad/param norm = 2.0205e-01, time/batch = 18.4023s	
8001/26050 (epoch 15.357), train_loss = 1.35416730, grad/param norm = 2.0429e-01, time/batch = 0.9207s	
8002/26050 (epoch 15.359), train_loss = 1.18582078, grad/param norm = 1.6639e-01, time/batch = 0.9455s	
8003/26050 (epoch 15.361), train_loss = 1.05998237, grad/param norm = 1.6320e-01, time/batch = 0.9389s	
8004/26050 (epoch 15.363), train_loss = 1.18612009, grad/param norm = 1.6556e-01, time/batch = 0.9334s	
8005/26050 (epoch 15.365), train_loss = 1.09872519, grad/param norm = 1.4794e-01, time/batch = 0.9422s	
8006/26050 (epoch 15.367), train_loss = 1.15050179, grad/param norm = 1.7512e-01, time/batch = 1.4292s	
8007/26050 (epoch 15.369), train_loss = 1.10777855, grad/param norm = 1.6511e-01, time/batch = 1.8013s	
8008/26050 (epoch 15.370), train_loss = 1.01476988, grad/param norm = 1.5246e-01, time/batch = 1.8207s	
8009/26050 (epoch 15.372), train_loss = 1.19838166, grad/param norm = 1.9310e-01, time/batch = 16.2014s	
8010/26050 (epoch 15.374), train_loss = 1.28254771, grad/param norm = 1.8042e-01, time/batch = 18.8927s	
8011/26050 (epoch 15.376), train_loss = 1.34012111, grad/param norm = 1.8785e-01, time/batch = 15.6324s	
8012/26050 (epoch 15.378), train_loss = 1.10792935, grad/param norm = 1.7105e-01, time/batch = 18.3791s	
8013/26050 (epoch 15.380), train_loss = 1.33041569, grad/param norm = 1.9691e-01, time/batch = 18.3038s	
8014/26050 (epoch 15.382), train_loss = 1.44602991, grad/param norm = 2.0747e-01, time/batch = 17.6523s	
8015/26050 (epoch 15.384), train_loss = 1.11012822, grad/param norm = 1.6980e-01, time/batch = 17.5557s	
8016/26050 (epoch 15.386), train_loss = 1.23068879, grad/param norm = 1.9417e-01, time/batch = 15.0701s	
8017/26050 (epoch 15.388), train_loss = 1.15003687, grad/param norm = 1.6659e-01, time/batch = 17.8952s	
8018/26050 (epoch 15.390), train_loss = 1.04587839, grad/param norm = 1.6235e-01, time/batch = 16.3660s	
8019/26050 (epoch 15.392), train_loss = 1.01421535, grad/param norm = 1.6128e-01, time/batch = 17.9752s	
8020/26050 (epoch 15.393), train_loss = 1.16727912, grad/param norm = 1.6371e-01, time/batch = 16.6541s	
8021/26050 (epoch 15.395), train_loss = 1.19130372, grad/param norm = 1.6174e-01, time/batch = 17.4039s	
8022/26050 (epoch 15.397), train_loss = 1.16443497, grad/param norm = 1.8889e-01, time/batch = 18.5645s	
8023/26050 (epoch 15.399), train_loss = 1.04023781, grad/param norm = 1.6977e-01, time/batch = 16.4777s	
8024/26050 (epoch 15.401), train_loss = 1.11367700, grad/param norm = 1.6360e-01, time/batch = 18.3876s	
8025/26050 (epoch 15.403), train_loss = 1.16218013, grad/param norm = 1.6274e-01, time/batch = 18.6224s	
8026/26050 (epoch 15.405), train_loss = 1.12582176, grad/param norm = 1.7846e-01, time/batch = 17.2158s	
8027/26050 (epoch 15.407), train_loss = 1.27424268, grad/param norm = 1.8322e-01, time/batch = 18.6351s	
8028/26050 (epoch 15.409), train_loss = 1.31941910, grad/param norm = 1.8087e-01, time/batch = 17.0705s	
8029/26050 (epoch 15.411), train_loss = 1.17833998, grad/param norm = 1.8842e-01, time/batch = 18.6356s	
8030/26050 (epoch 15.413), train_loss = 1.28094113, grad/param norm = 1.6330e-01, time/batch = 16.8196s	
8031/26050 (epoch 15.415), train_loss = 1.24725862, grad/param norm = 1.9882e-01, time/batch = 17.3806s	
8032/26050 (epoch 15.417), train_loss = 1.37519262, grad/param norm = 2.0038e-01, time/batch = 18.3086s	
8033/26050 (epoch 15.418), train_loss = 1.26330539, grad/param norm = 2.1214e-01, time/batch = 17.3404s	
8034/26050 (epoch 15.420), train_loss = 0.95821809, grad/param norm = 1.5207e-01, time/batch = 18.4909s	
8035/26050 (epoch 15.422), train_loss = 0.99121347, grad/param norm = 1.6079e-01, time/batch = 18.0712s	
8036/26050 (epoch 15.424), train_loss = 1.30271743, grad/param norm = 2.0964e-01, time/batch = 18.4834s	
8037/26050 (epoch 15.426), train_loss = 1.26650278, grad/param norm = 1.8367e-01, time/batch = 18.0647s	
8038/26050 (epoch 15.428), train_loss = 1.05772155, grad/param norm = 1.5141e-01, time/batch = 17.3198s	
8039/26050 (epoch 15.430), train_loss = 1.21734097, grad/param norm = 1.7576e-01, time/batch = 17.4133s	
8040/26050 (epoch 15.432), train_loss = 1.10248757, grad/param norm = 1.7810e-01, time/batch = 15.0712s	
8041/26050 (epoch 15.434), train_loss = 1.13069386, grad/param norm = 1.8745e-01, time/batch = 17.5609s	
8042/26050 (epoch 15.436), train_loss = 1.26218781, grad/param norm = 1.7480e-01, time/batch = 14.7845s	
8043/26050 (epoch 15.438), train_loss = 1.10561086, grad/param norm = 1.7919e-01, time/batch = 18.7250s	
8044/26050 (epoch 15.440), train_loss = 1.17044779, grad/param norm = 1.6983e-01, time/batch = 18.6520s	
8045/26050 (epoch 15.441), train_loss = 1.15409339, grad/param norm = 1.6876e-01, time/batch = 16.8113s	
8046/26050 (epoch 15.443), train_loss = 0.95716050, grad/param norm = 1.5110e-01, time/batch = 18.7358s	
8047/26050 (epoch 15.445), train_loss = 1.02296436, grad/param norm = 1.5955e-01, time/batch = 18.7335s	
8048/26050 (epoch 15.447), train_loss = 1.31262468, grad/param norm = 1.9644e-01, time/batch = 17.6632s	
8049/26050 (epoch 15.449), train_loss = 1.04825993, grad/param norm = 1.6831e-01, time/batch = 17.8201s	
8050/26050 (epoch 15.451), train_loss = 1.28933530, grad/param norm = 1.8444e-01, time/batch = 17.2440s	
8051/26050 (epoch 15.453), train_loss = 1.06222935, grad/param norm = 1.6318e-01, time/batch = 14.8073s	
8052/26050 (epoch 15.455), train_loss = 1.17758579, grad/param norm = 1.7158e-01, time/batch = 17.4593s	
8053/26050 (epoch 15.457), train_loss = 1.16330209, grad/param norm = 1.7301e-01, time/batch = 18.3981s	
8054/26050 (epoch 15.459), train_loss = 1.26266527, grad/param norm = 1.8123e-01, time/batch = 18.6597s	
8055/26050 (epoch 15.461), train_loss = 1.21622762, grad/param norm = 1.9129e-01, time/batch = 15.9648s	
8056/26050 (epoch 15.463), train_loss = 1.08357437, grad/param norm = 1.6225e-01, time/batch = 17.7329s	
8057/26050 (epoch 15.464), train_loss = 1.18579470, grad/param norm = 1.7028e-01, time/batch = 18.3102s	
8058/26050 (epoch 15.466), train_loss = 1.23226189, grad/param norm = 1.8906e-01, time/batch = 18.2149s	
8059/26050 (epoch 15.468), train_loss = 1.24620473, grad/param norm = 1.5951e-01, time/batch = 17.6503s	
8060/26050 (epoch 15.470), train_loss = 1.33960911, grad/param norm = 2.0075e-01, time/batch = 18.0558s	
8061/26050 (epoch 15.472), train_loss = 1.29018027, grad/param norm = 1.9614e-01, time/batch = 18.0603s	
8062/26050 (epoch 15.474), train_loss = 1.36166071, grad/param norm = 1.7557e-01, time/batch = 17.3298s	
8063/26050 (epoch 15.476), train_loss = 1.27398957, grad/param norm = 1.8456e-01, time/batch = 17.7473s	
8064/26050 (epoch 15.478), train_loss = 1.09232228, grad/param norm = 1.6479e-01, time/batch = 18.8200s	
8065/26050 (epoch 15.480), train_loss = 1.17749382, grad/param norm = 1.7485e-01, time/batch = 17.0637s	
8066/26050 (epoch 15.482), train_loss = 1.09729378, grad/param norm = 1.6832e-01, time/batch = 16.0259s	
8067/26050 (epoch 15.484), train_loss = 1.10019043, grad/param norm = 1.7536e-01, time/batch = 16.7630s	
8068/26050 (epoch 15.486), train_loss = 1.31188565, grad/param norm = 1.7689e-01, time/batch = 18.4974s	
8069/26050 (epoch 15.488), train_loss = 1.44962904, grad/param norm = 1.9869e-01, time/batch = 15.3769s	
8070/26050 (epoch 15.489), train_loss = 1.36872103, grad/param norm = 2.0039e-01, time/batch = 16.2205s	
8071/26050 (epoch 15.491), train_loss = 1.04859201, grad/param norm = 1.6678e-01, time/batch = 19.1554s	
8072/26050 (epoch 15.493), train_loss = 1.15214799, grad/param norm = 1.7081e-01, time/batch = 17.4867s	
8073/26050 (epoch 15.495), train_loss = 1.13533570, grad/param norm = 1.7178e-01, time/batch = 17.5611s	
8074/26050 (epoch 15.497), train_loss = 1.06381825, grad/param norm = 1.6941e-01, time/batch = 17.9118s	
8075/26050 (epoch 15.499), train_loss = 1.09917901, grad/param norm = 1.6734e-01, time/batch = 17.9042s	
8076/26050 (epoch 15.501), train_loss = 1.21619786, grad/param norm = 1.7593e-01, time/batch = 17.8867s	
8077/26050 (epoch 15.503), train_loss = 1.08796415, grad/param norm = 1.7891e-01, time/batch = 18.2412s	
8078/26050 (epoch 15.505), train_loss = 1.27164046, grad/param norm = 1.7361e-01, time/batch = 18.4840s	
8079/26050 (epoch 15.507), train_loss = 1.23581147, grad/param norm = 1.8306e-01, time/batch = 17.4818s	
8080/26050 (epoch 15.509), train_loss = 1.35376104, grad/param norm = 1.8478e-01, time/batch = 17.9804s	
8081/26050 (epoch 15.511), train_loss = 1.05616937, grad/param norm = 1.5112e-01, time/batch = 15.4633s	
8082/26050 (epoch 15.512), train_loss = 1.10337212, grad/param norm = 1.8364e-01, time/batch = 14.4537s	
8083/26050 (epoch 15.514), train_loss = 1.23386422, grad/param norm = 1.8048e-01, time/batch = 18.4736s	
8084/26050 (epoch 15.516), train_loss = 1.25615907, grad/param norm = 1.8552e-01, time/batch = 17.7367s	
8085/26050 (epoch 15.518), train_loss = 1.19670447, grad/param norm = 1.8134e-01, time/batch = 18.3999s	
8086/26050 (epoch 15.520), train_loss = 1.12682529, grad/param norm = 1.6197e-01, time/batch = 16.2958s	
8087/26050 (epoch 15.522), train_loss = 0.94370032, grad/param norm = 1.6120e-01, time/batch = 18.3261s	
8088/26050 (epoch 15.524), train_loss = 1.26928579, grad/param norm = 1.9334e-01, time/batch = 18.6594s	
8089/26050 (epoch 15.526), train_loss = 1.25882762, grad/param norm = 1.8380e-01, time/batch = 17.3966s	
8090/26050 (epoch 15.528), train_loss = 1.19868871, grad/param norm = 1.8239e-01, time/batch = 17.7322s	
8091/26050 (epoch 15.530), train_loss = 1.15251487, grad/param norm = 1.8382e-01, time/batch = 18.0379s	
8092/26050 (epoch 15.532), train_loss = 1.14846970, grad/param norm = 1.6438e-01, time/batch = 18.1389s	
8093/26050 (epoch 15.534), train_loss = 1.21107372, grad/param norm = 1.8377e-01, time/batch = 17.9703s	
8094/26050 (epoch 15.536), train_loss = 1.14051167, grad/param norm = 1.5597e-01, time/batch = 17.6476s	
8095/26050 (epoch 15.537), train_loss = 1.27307973, grad/param norm = 2.0520e-01, time/batch = 18.8976s	
8096/26050 (epoch 15.539), train_loss = 1.15795337, grad/param norm = 1.7602e-01, time/batch = 16.7365s	
8097/26050 (epoch 15.541), train_loss = 1.34937253, grad/param norm = 2.0056e-01, time/batch = 14.4735s	
8098/26050 (epoch 15.543), train_loss = 0.98093242, grad/param norm = 1.6820e-01, time/batch = 15.3022s	
8099/26050 (epoch 15.545), train_loss = 1.20603852, grad/param norm = 1.7495e-01, time/batch = 18.4012s	
8100/26050 (epoch 15.547), train_loss = 1.15875108, grad/param norm = 1.7272e-01, time/batch = 18.3228s	
8101/26050 (epoch 15.549), train_loss = 0.95497692, grad/param norm = 1.5384e-01, time/batch = 17.8169s	
8102/26050 (epoch 15.551), train_loss = 1.18793966, grad/param norm = 1.7494e-01, time/batch = 18.9012s	
8103/26050 (epoch 15.553), train_loss = 1.06903703, grad/param norm = 1.6157e-01, time/batch = 14.3721s	
8104/26050 (epoch 15.555), train_loss = 1.09225748, grad/param norm = 1.7890e-01, time/batch = 17.3258s	
8105/26050 (epoch 15.557), train_loss = 1.20389086, grad/param norm = 1.5770e-01, time/batch = 17.9828s	
8106/26050 (epoch 15.559), train_loss = 1.14690612, grad/param norm = 1.6417e-01, time/batch = 17.7186s	
8107/26050 (epoch 15.560), train_loss = 1.13136724, grad/param norm = 1.7590e-01, time/batch = 17.8339s	
8108/26050 (epoch 15.562), train_loss = 1.13440980, grad/param norm = 1.7710e-01, time/batch = 17.5649s	
8109/26050 (epoch 15.564), train_loss = 1.33523972, grad/param norm = 1.6741e-01, time/batch = 18.0720s	
8110/26050 (epoch 15.566), train_loss = 1.05269264, grad/param norm = 1.7080e-01, time/batch = 17.0663s	
8111/26050 (epoch 15.568), train_loss = 1.18009441, grad/param norm = 1.6075e-01, time/batch = 17.4891s	
8112/26050 (epoch 15.570), train_loss = 1.25379503, grad/param norm = 1.7983e-01, time/batch = 17.4029s	
8113/26050 (epoch 15.572), train_loss = 1.12712976, grad/param norm = 1.7657e-01, time/batch = 14.0067s	
8114/26050 (epoch 15.574), train_loss = 1.22318092, grad/param norm = 1.9927e-01, time/batch = 13.9147s	
8115/26050 (epoch 15.576), train_loss = 1.18621247, grad/param norm = 1.7808e-01, time/batch = 13.7685s	
8116/26050 (epoch 15.578), train_loss = 1.13475107, grad/param norm = 1.7182e-01, time/batch = 14.0716s	
8117/26050 (epoch 15.580), train_loss = 1.05758290, grad/param norm = 1.7481e-01, time/batch = 14.6307s	
8118/26050 (epoch 15.582), train_loss = 1.19767398, grad/param norm = 1.6993e-01, time/batch = 18.3949s	
8119/26050 (epoch 15.583), train_loss = 1.24251697, grad/param norm = 1.6950e-01, time/batch = 16.8817s	
8120/26050 (epoch 15.585), train_loss = 1.03876721, grad/param norm = 1.6994e-01, time/batch = 18.3201s	
8121/26050 (epoch 15.587), train_loss = 1.18367155, grad/param norm = 1.8790e-01, time/batch = 14.7784s	
8122/26050 (epoch 15.589), train_loss = 1.30080174, grad/param norm = 2.0148e-01, time/batch = 18.4826s	
8123/26050 (epoch 15.591), train_loss = 1.14563566, grad/param norm = 1.6906e-01, time/batch = 18.8985s	
8124/26050 (epoch 15.593), train_loss = 1.03380602, grad/param norm = 1.7830e-01, time/batch = 17.3934s	
8125/26050 (epoch 15.595), train_loss = 1.25929861, grad/param norm = 2.0679e-01, time/batch = 18.2421s	
8126/26050 (epoch 15.597), train_loss = 1.18214095, grad/param norm = 1.6784e-01, time/batch = 17.5701s	
8127/26050 (epoch 15.599), train_loss = 1.11601946, grad/param norm = 1.6669e-01, time/batch = 18.6643s	
8128/26050 (epoch 15.601), train_loss = 1.34827385, grad/param norm = 1.8258e-01, time/batch = 18.4729s	
8129/26050 (epoch 15.603), train_loss = 1.20261120, grad/param norm = 1.7374e-01, time/batch = 17.1424s	
8130/26050 (epoch 15.605), train_loss = 1.08698536, grad/param norm = 1.6025e-01, time/batch = 16.8667s	
8131/26050 (epoch 15.607), train_loss = 1.28844718, grad/param norm = 1.9815e-01, time/batch = 17.4782s	
8132/26050 (epoch 15.608), train_loss = 1.02122417, grad/param norm = 1.5112e-01, time/batch = 18.2457s	
8133/26050 (epoch 15.610), train_loss = 1.13459103, grad/param norm = 1.8104e-01, time/batch = 18.8921s	
8134/26050 (epoch 15.612), train_loss = 1.16814811, grad/param norm = 1.8257e-01, time/batch = 18.0722s	
8135/26050 (epoch 15.614), train_loss = 1.22483727, grad/param norm = 1.8278e-01, time/batch = 18.4918s	
8136/26050 (epoch 15.616), train_loss = 1.33806179, grad/param norm = 1.9027e-01, time/batch = 17.0757s	
8137/26050 (epoch 15.618), train_loss = 1.10221819, grad/param norm = 1.8911e-01, time/batch = 14.8024s	
8138/26050 (epoch 15.620), train_loss = 1.17823942, grad/param norm = 1.7474e-01, time/batch = 16.8847s	
8139/26050 (epoch 15.622), train_loss = 1.01683403, grad/param norm = 1.6556e-01, time/batch = 17.4149s	
8140/26050 (epoch 15.624), train_loss = 1.02253472, grad/param norm = 1.5873e-01, time/batch = 18.2322s	
8141/26050 (epoch 15.626), train_loss = 1.20790645, grad/param norm = 1.7076e-01, time/batch = 16.2083s	
8142/26050 (epoch 15.628), train_loss = 1.09358672, grad/param norm = 1.7857e-01, time/batch = 18.0718s	
8143/26050 (epoch 15.630), train_loss = 1.27233522, grad/param norm = 1.6942e-01, time/batch = 18.0674s	
8144/26050 (epoch 15.631), train_loss = 1.30860583, grad/param norm = 1.7823e-01, time/batch = 18.4958s	
8145/26050 (epoch 15.633), train_loss = 1.06935850, grad/param norm = 1.6852e-01, time/batch = 18.0627s	
8146/26050 (epoch 15.635), train_loss = 1.07310489, grad/param norm = 1.5207e-01, time/batch = 17.6459s	
8147/26050 (epoch 15.637), train_loss = 1.04794288, grad/param norm = 1.7222e-01, time/batch = 18.9177s	
8148/26050 (epoch 15.639), train_loss = 1.26741430, grad/param norm = 1.7941e-01, time/batch = 16.6516s	
8149/26050 (epoch 15.641), train_loss = 1.11008728, grad/param norm = 1.6080e-01, time/batch = 16.6433s	
8150/26050 (epoch 15.643), train_loss = 1.00575432, grad/param norm = 1.4657e-01, time/batch = 17.7965s	
8151/26050 (epoch 15.645), train_loss = 1.18002434, grad/param norm = 1.7488e-01, time/batch = 17.8165s	
8152/26050 (epoch 15.647), train_loss = 1.10120770, grad/param norm = 1.6773e-01, time/batch = 16.9664s	
8153/26050 (epoch 15.649), train_loss = 1.17009607, grad/param norm = 1.8840e-01, time/batch = 17.6457s	
8154/26050 (epoch 15.651), train_loss = 1.06647314, grad/param norm = 1.7548e-01, time/batch = 16.7119s	
8155/26050 (epoch 15.653), train_loss = 1.17739115, grad/param norm = 1.7721e-01, time/batch = 17.9000s	
8156/26050 (epoch 15.655), train_loss = 1.07776831, grad/param norm = 1.6608e-01, time/batch = 18.3074s	
8157/26050 (epoch 15.656), train_loss = 0.98342480, grad/param norm = 1.6556e-01, time/batch = 17.8231s	
8158/26050 (epoch 15.658), train_loss = 1.34609626, grad/param norm = 1.9287e-01, time/batch = 17.5649s	
8159/26050 (epoch 15.660), train_loss = 1.01550811, grad/param norm = 1.5894e-01, time/batch = 15.3093s	
8160/26050 (epoch 15.662), train_loss = 1.03901579, grad/param norm = 1.5389e-01, time/batch = 14.3969s	
8161/26050 (epoch 15.664), train_loss = 1.12704570, grad/param norm = 1.7885e-01, time/batch = 18.4713s	
8162/26050 (epoch 15.666), train_loss = 1.14151083, grad/param norm = 1.9363e-01, time/batch = 17.7859s	
8163/26050 (epoch 15.668), train_loss = 0.95728431, grad/param norm = 1.7821e-01, time/batch = 18.1498s	
8164/26050 (epoch 15.670), train_loss = 1.32410209, grad/param norm = 1.9527e-01, time/batch = 18.3229s	
8165/26050 (epoch 15.672), train_loss = 1.10610292, grad/param norm = 1.7349e-01, time/batch = 16.7378s	
8166/26050 (epoch 15.674), train_loss = 1.04639024, grad/param norm = 1.7885e-01, time/batch = 16.7168s	
8167/26050 (epoch 15.676), train_loss = 1.14897748, grad/param norm = 1.7223e-01, time/batch = 17.0451s	
8168/26050 (epoch 15.678), train_loss = 1.26839931, grad/param norm = 1.8206e-01, time/batch = 18.1550s	
8169/26050 (epoch 15.679), train_loss = 1.35148355, grad/param norm = 1.9540e-01, time/batch = 16.1151s	
8170/26050 (epoch 15.681), train_loss = 1.16787623, grad/param norm = 1.7471e-01, time/batch = 18.4785s	
8171/26050 (epoch 15.683), train_loss = 1.03797732, grad/param norm = 1.9471e-01, time/batch = 18.3002s	
8172/26050 (epoch 15.685), train_loss = 1.09694956, grad/param norm = 1.6134e-01, time/batch = 16.4855s	
8173/26050 (epoch 15.687), train_loss = 0.97647263, grad/param norm = 1.7794e-01, time/batch = 17.8121s	
8174/26050 (epoch 15.689), train_loss = 1.12261697, grad/param norm = 1.8768e-01, time/batch = 15.3916s	
8175/26050 (epoch 15.691), train_loss = 0.88836325, grad/param norm = 1.4731e-01, time/batch = 18.3154s	
8176/26050 (epoch 15.693), train_loss = 1.03545998, grad/param norm = 1.5941e-01, time/batch = 17.5594s	
8177/26050 (epoch 15.695), train_loss = 1.13437665, grad/param norm = 1.7113e-01, time/batch = 18.0583s	
8178/26050 (epoch 15.697), train_loss = 1.03102562, grad/param norm = 1.6625e-01, time/batch = 18.3185s	
8179/26050 (epoch 15.699), train_loss = 1.19714358, grad/param norm = 1.8477e-01, time/batch = 16.2331s	
8180/26050 (epoch 15.701), train_loss = 1.01453763, grad/param norm = 1.6343e-01, time/batch = 17.7387s	
8181/26050 (epoch 15.702), train_loss = 1.29549926, grad/param norm = 1.9204e-01, time/batch = 14.2985s	
8182/26050 (epoch 15.704), train_loss = 1.19509207, grad/param norm = 1.6179e-01, time/batch = 17.5612s	
8183/26050 (epoch 15.706), train_loss = 1.15236756, grad/param norm = 1.9074e-01, time/batch = 18.2293s	
8184/26050 (epoch 15.708), train_loss = 1.23621800, grad/param norm = 1.8410e-01, time/batch = 17.6503s	
8185/26050 (epoch 15.710), train_loss = 1.20986611, grad/param norm = 1.7200e-01, time/batch = 18.7310s	
8186/26050 (epoch 15.712), train_loss = 1.25686700, grad/param norm = 1.9175e-01, time/batch = 17.7370s	
8187/26050 (epoch 15.714), train_loss = 0.98854635, grad/param norm = 1.7934e-01, time/batch = 17.3765s	
8188/26050 (epoch 15.716), train_loss = 1.41539740, grad/param norm = 1.9929e-01, time/batch = 17.9012s	
8189/26050 (epoch 15.718), train_loss = 1.24771880, grad/param norm = 1.7810e-01, time/batch = 16.1463s	
8190/26050 (epoch 15.720), train_loss = 1.11006303, grad/param norm = 1.7302e-01, time/batch = 17.7214s	
8191/26050 (epoch 15.722), train_loss = 1.03232950, grad/param norm = 1.6785e-01, time/batch = 18.1566s	
8192/26050 (epoch 15.724), train_loss = 1.05626178, grad/param norm = 1.8155e-01, time/batch = 17.9849s	
8193/26050 (epoch 15.726), train_loss = 1.25433466, grad/param norm = 1.8059e-01, time/batch = 18.1634s	
8194/26050 (epoch 15.727), train_loss = 1.22574685, grad/param norm = 1.8410e-01, time/batch = 17.9747s	
8195/26050 (epoch 15.729), train_loss = 1.19323582, grad/param norm = 1.7532e-01, time/batch = 15.5538s	
8196/26050 (epoch 15.731), train_loss = 1.17816521, grad/param norm = 1.7129e-01, time/batch = 16.3899s	
8197/26050 (epoch 15.733), train_loss = 1.12007472, grad/param norm = 2.1673e-01, time/batch = 18.5652s	
8198/26050 (epoch 15.735), train_loss = 1.35733724, grad/param norm = 1.9866e-01, time/batch = 16.0575s	
8199/26050 (epoch 15.737), train_loss = 1.11716047, grad/param norm = 1.7176e-01, time/batch = 17.3000s	
8200/26050 (epoch 15.739), train_loss = 1.21000870, grad/param norm = 1.8486e-01, time/batch = 17.8191s	
8201/26050 (epoch 15.741), train_loss = 1.06819419, grad/param norm = 1.7332e-01, time/batch = 18.3142s	
8202/26050 (epoch 15.743), train_loss = 1.19408188, grad/param norm = 2.2726e-01, time/batch = 18.4138s	
8203/26050 (epoch 15.745), train_loss = 1.03039528, grad/param norm = 1.7826e-01, time/batch = 17.7925s	
8204/26050 (epoch 15.747), train_loss = 1.03983580, grad/param norm = 1.5368e-01, time/batch = 18.2481s	
8205/26050 (epoch 15.749), train_loss = 1.28669523, grad/param norm = 1.8322e-01, time/batch = 15.8312s	
8206/26050 (epoch 15.750), train_loss = 1.14211627, grad/param norm = 1.6186e-01, time/batch = 18.0489s	
8207/26050 (epoch 15.752), train_loss = 1.09940148, grad/param norm = 1.9589e-01, time/batch = 18.4104s	
8208/26050 (epoch 15.754), train_loss = 1.17221555, grad/param norm = 1.7525e-01, time/batch = 14.9714s	
8209/26050 (epoch 15.756), train_loss = 1.14999205, grad/param norm = 1.8271e-01, time/batch = 17.4794s	
8210/26050 (epoch 15.758), train_loss = 1.15567713, grad/param norm = 1.7690e-01, time/batch = 16.8001s	
8211/26050 (epoch 15.760), train_loss = 1.29118778, grad/param norm = 1.8027e-01, time/batch = 17.4005s	
8212/26050 (epoch 15.762), train_loss = 1.07627299, grad/param norm = 1.6811e-01, time/batch = 18.5642s	
8213/26050 (epoch 15.764), train_loss = 1.19198733, grad/param norm = 1.8420e-01, time/batch = 20.9191s	
8214/26050 (epoch 15.766), train_loss = 1.23948412, grad/param norm = 1.9002e-01, time/batch = 32.6935s	
8215/26050 (epoch 15.768), train_loss = 1.04401521, grad/param norm = 1.6286e-01, time/batch = 18.6036s	
8216/26050 (epoch 15.770), train_loss = 1.12282386, grad/param norm = 1.7487e-01, time/batch = 18.3684s	
8217/26050 (epoch 15.772), train_loss = 1.13689336, grad/param norm = 1.6791e-01, time/batch = 18.0533s	
8218/26050 (epoch 15.774), train_loss = 1.01618677, grad/param norm = 1.7854e-01, time/batch = 14.9832s	
8219/26050 (epoch 15.775), train_loss = 0.83891388, grad/param norm = 1.5709e-01, time/batch = 16.7240s	
8220/26050 (epoch 15.777), train_loss = 1.07525069, grad/param norm = 1.6502e-01, time/batch = 18.3155s	
8221/26050 (epoch 15.779), train_loss = 1.11823774, grad/param norm = 1.8967e-01, time/batch = 18.8215s	
8222/26050 (epoch 15.781), train_loss = 1.06345770, grad/param norm = 1.6492e-01, time/batch = 17.2255s	
8223/26050 (epoch 15.783), train_loss = 1.03209448, grad/param norm = 1.6291e-01, time/batch = 15.5332s	
8224/26050 (epoch 15.785), train_loss = 1.11601393, grad/param norm = 1.6928e-01, time/batch = 18.3232s	
8225/26050 (epoch 15.787), train_loss = 1.06061015, grad/param norm = 1.6045e-01, time/batch = 18.3340s	
8226/26050 (epoch 15.789), train_loss = 1.06926529, grad/param norm = 1.9829e-01, time/batch = 18.0620s	
8227/26050 (epoch 15.791), train_loss = 1.11806220, grad/param norm = 1.7507e-01, time/batch = 17.4021s	
8228/26050 (epoch 15.793), train_loss = 1.10830999, grad/param norm = 1.8855e-01, time/batch = 17.9163s	
8229/26050 (epoch 15.795), train_loss = 0.95683141, grad/param norm = 1.5485e-01, time/batch = 17.7233s	
8230/26050 (epoch 15.797), train_loss = 1.03984209, grad/param norm = 1.5927e-01, time/batch = 18.8079s	
8231/26050 (epoch 15.798), train_loss = 0.98611023, grad/param norm = 1.7078e-01, time/batch = 16.5579s	
8232/26050 (epoch 15.800), train_loss = 0.98701474, grad/param norm = 1.5346e-01, time/batch = 17.4557s	
8233/26050 (epoch 15.802), train_loss = 1.08518407, grad/param norm = 1.7244e-01, time/batch = 18.3164s	
8234/26050 (epoch 15.804), train_loss = 1.10756077, grad/param norm = 1.7501e-01, time/batch = 18.3291s	
8235/26050 (epoch 15.806), train_loss = 1.21499579, grad/param norm = 1.8283e-01, time/batch = 15.3998s	
8236/26050 (epoch 15.808), train_loss = 1.11425587, grad/param norm = 1.7366e-01, time/batch = 17.6408s	
8237/26050 (epoch 15.810), train_loss = 1.05341980, grad/param norm = 1.6844e-01, time/batch = 18.6390s	
8238/26050 (epoch 15.812), train_loss = 1.00834366, grad/param norm = 1.7537e-01, time/batch = 18.4774s	
8239/26050 (epoch 15.814), train_loss = 1.00107176, grad/param norm = 1.9332e-01, time/batch = 17.5537s	
8240/26050 (epoch 15.816), train_loss = 1.25002812, grad/param norm = 1.8786e-01, time/batch = 16.5544s	
8241/26050 (epoch 15.818), train_loss = 1.26967808, grad/param norm = 2.1800e-01, time/batch = 17.2248s	
8242/26050 (epoch 15.820), train_loss = 1.14066523, grad/param norm = 1.7954e-01, time/batch = 18.3240s	
8243/26050 (epoch 15.821), train_loss = 1.29188110, grad/param norm = 2.0177e-01, time/batch = 17.7268s	
8244/26050 (epoch 15.823), train_loss = 1.31112008, grad/param norm = 1.9918e-01, time/batch = 18.1551s	
8245/26050 (epoch 15.825), train_loss = 1.11642474, grad/param norm = 1.7772e-01, time/batch = 17.8158s	
8246/26050 (epoch 15.827), train_loss = 1.15775367, grad/param norm = 2.1787e-01, time/batch = 16.6264s	
8247/26050 (epoch 15.829), train_loss = 1.18832718, grad/param norm = 1.7577e-01, time/batch = 18.1460s	
8248/26050 (epoch 15.831), train_loss = 1.25581761, grad/param norm = 1.7598e-01, time/batch = 18.2347s	
8249/26050 (epoch 15.833), train_loss = 1.33806662, grad/param norm = 1.9022e-01, time/batch = 18.3267s	
8250/26050 (epoch 15.835), train_loss = 1.35837989, grad/param norm = 1.9707e-01, time/batch = 17.4973s	
8251/26050 (epoch 15.837), train_loss = 1.12935891, grad/param norm = 1.7830e-01, time/batch = 18.6564s	
8252/26050 (epoch 15.839), train_loss = 1.16492372, grad/param norm = 2.1432e-01, time/batch = 18.3078s	
8253/26050 (epoch 15.841), train_loss = 1.23916872, grad/param norm = 1.7579e-01, time/batch = 18.3978s	
8254/26050 (epoch 15.843), train_loss = 1.14642805, grad/param norm = 1.7311e-01, time/batch = 17.8361s	
8255/26050 (epoch 15.845), train_loss = 1.05659601, grad/param norm = 1.5509e-01, time/batch = 18.9809s	
8256/26050 (epoch 15.846), train_loss = 1.24490539, grad/param norm = 1.7228e-01, time/batch = 18.3023s	
8257/26050 (epoch 15.848), train_loss = 1.11620703, grad/param norm = 1.6722e-01, time/batch = 16.3247s	
8258/26050 (epoch 15.850), train_loss = 1.04281141, grad/param norm = 1.6383e-01, time/batch = 14.8499s	
8259/26050 (epoch 15.852), train_loss = 1.10169680, grad/param norm = 1.6901e-01, time/batch = 17.9085s	
8260/26050 (epoch 15.854), train_loss = 1.11238597, grad/param norm = 1.6677e-01, time/batch = 17.6669s	
8261/26050 (epoch 15.856), train_loss = 1.08612105, grad/param norm = 1.8698e-01, time/batch = 17.8271s	
8262/26050 (epoch 15.858), train_loss = 1.03388295, grad/param norm = 1.6866e-01, time/batch = 17.9005s	
8263/26050 (epoch 15.860), train_loss = 1.17780028, grad/param norm = 1.7869e-01, time/batch = 18.8036s	
8264/26050 (epoch 15.862), train_loss = 1.18303427, grad/param norm = 1.7993e-01, time/batch = 17.3155s	
8265/26050 (epoch 15.864), train_loss = 1.16856352, grad/param norm = 1.9514e-01, time/batch = 16.1280s	
8266/26050 (epoch 15.866), train_loss = 1.08262712, grad/param norm = 1.6543e-01, time/batch = 17.7278s	
8267/26050 (epoch 15.868), train_loss = 1.19849045, grad/param norm = 1.7992e-01, time/batch = 18.0661s	
8268/26050 (epoch 15.869), train_loss = 1.02676697, grad/param norm = 1.6774e-01, time/batch = 17.1662s	
8269/26050 (epoch 15.871), train_loss = 0.96830320, grad/param norm = 1.6598e-01, time/batch = 17.6713s	
8270/26050 (epoch 15.873), train_loss = 1.20043336, grad/param norm = 1.7920e-01, time/batch = 18.5454s	
8271/26050 (epoch 15.875), train_loss = 1.12064314, grad/param norm = 1.7872e-01, time/batch = 15.7049s	
8272/26050 (epoch 15.877), train_loss = 1.02107056, grad/param norm = 1.6486e-01, time/batch = 18.8151s	
8273/26050 (epoch 15.879), train_loss = 1.15512838, grad/param norm = 1.6470e-01, time/batch = 16.8202s	
8274/26050 (epoch 15.881), train_loss = 1.26304464, grad/param norm = 1.7369e-01, time/batch = 15.0733s	
8275/26050 (epoch 15.883), train_loss = 1.17300584, grad/param norm = 1.8980e-01, time/batch = 16.5528s	
8276/26050 (epoch 15.885), train_loss = 0.87741137, grad/param norm = 1.6390e-01, time/batch = 17.2420s	
8277/26050 (epoch 15.887), train_loss = 1.17273201, grad/param norm = 1.7906e-01, time/batch = 18.0544s	
8278/26050 (epoch 15.889), train_loss = 1.09220259, grad/param norm = 1.6502e-01, time/batch = 17.9894s	
8279/26050 (epoch 15.891), train_loss = 0.91090828, grad/param norm = 1.5740e-01, time/batch = 18.0661s	
8280/26050 (epoch 15.893), train_loss = 0.95719199, grad/param norm = 1.6006e-01, time/batch = 14.6229s	
8281/26050 (epoch 15.894), train_loss = 1.09706353, grad/param norm = 1.7261e-01, time/batch = 17.4448s	
8282/26050 (epoch 15.896), train_loss = 1.23604070, grad/param norm = 1.7231e-01, time/batch = 18.6395s	
8283/26050 (epoch 15.898), train_loss = 1.06255183, grad/param norm = 1.8174e-01, time/batch = 17.7332s	
8284/26050 (epoch 15.900), train_loss = 1.19764661, grad/param norm = 1.7822e-01, time/batch = 18.0634s	
8285/26050 (epoch 15.902), train_loss = 1.12386860, grad/param norm = 1.7294e-01, time/batch = 18.3979s	
8286/26050 (epoch 15.904), train_loss = 1.11766132, grad/param norm = 1.7777e-01, time/batch = 18.6466s	
8287/26050 (epoch 15.906), train_loss = 1.11631580, grad/param norm = 1.8540e-01, time/batch = 18.1409s	
8288/26050 (epoch 15.908), train_loss = 1.11985120, grad/param norm = 1.7821e-01, time/batch = 15.4667s	
8289/26050 (epoch 15.910), train_loss = 1.04086349, grad/param norm = 1.5503e-01, time/batch = 18.2369s	
8290/26050 (epoch 15.912), train_loss = 1.36424778, grad/param norm = 1.9691e-01, time/batch = 17.7422s	
8291/26050 (epoch 15.914), train_loss = 1.50527746, grad/param norm = 2.1101e-01, time/batch = 17.9019s	
8292/26050 (epoch 15.916), train_loss = 1.23906586, grad/param norm = 1.8665e-01, time/batch = 18.7262s	
8293/26050 (epoch 15.917), train_loss = 1.14724355, grad/param norm = 1.9701e-01, time/batch = 18.0652s	
8294/26050 (epoch 15.919), train_loss = 1.22664411, grad/param norm = 1.9302e-01, time/batch = 17.3126s	
8295/26050 (epoch 15.921), train_loss = 1.09023517, grad/param norm = 1.7953e-01, time/batch = 17.5628s	
8296/26050 (epoch 15.923), train_loss = 1.16185215, grad/param norm = 1.9039e-01, time/batch = 15.4042s	
8297/26050 (epoch 15.925), train_loss = 1.14320763, grad/param norm = 1.6981e-01, time/batch = 16.4493s	
8298/26050 (epoch 15.927), train_loss = 1.00476767, grad/param norm = 1.4765e-01, time/batch = 18.6522s	
8299/26050 (epoch 15.929), train_loss = 1.02674910, grad/param norm = 1.7139e-01, time/batch = 18.2354s	
8300/26050 (epoch 15.931), train_loss = 1.32817330, grad/param norm = 1.9319e-01, time/batch = 17.8168s	
8301/26050 (epoch 15.933), train_loss = 1.09612421, grad/param norm = 1.7232e-01, time/batch = 15.3949s	
8302/26050 (epoch 15.935), train_loss = 1.10275546, grad/param norm = 1.7359e-01, time/batch = 18.1588s	
8303/26050 (epoch 15.937), train_loss = 1.21371562, grad/param norm = 1.7263e-01, time/batch = 15.7182s	
8304/26050 (epoch 15.939), train_loss = 1.02758063, grad/param norm = 1.4923e-01, time/batch = 17.7367s	
8305/26050 (epoch 15.940), train_loss = 1.12261276, grad/param norm = 1.5323e-01, time/batch = 18.0584s	
8306/26050 (epoch 15.942), train_loss = 1.16023075, grad/param norm = 1.8427e-01, time/batch = 18.6522s	
8307/26050 (epoch 15.944), train_loss = 1.08045883, grad/param norm = 1.7205e-01, time/batch = 17.3893s	
8308/26050 (epoch 15.946), train_loss = 1.28183976, grad/param norm = 1.8319e-01, time/batch = 18.0609s	
8309/26050 (epoch 15.948), train_loss = 1.00008355, grad/param norm = 1.9310e-01, time/batch = 18.6358s	
8310/26050 (epoch 15.950), train_loss = 1.11619927, grad/param norm = 1.8826e-01, time/batch = 17.3976s	
8311/26050 (epoch 15.952), train_loss = 1.25889720, grad/param norm = 1.9848e-01, time/batch = 18.2317s	
8312/26050 (epoch 15.954), train_loss = 1.22089170, grad/param norm = 1.8220e-01, time/batch = 17.5568s	
8313/26050 (epoch 15.956), train_loss = 1.12286816, grad/param norm = 1.7605e-01, time/batch = 17.1332s	
8314/26050 (epoch 15.958), train_loss = 1.08595843, grad/param norm = 1.7508e-01, time/batch = 16.0445s	
8315/26050 (epoch 15.960), train_loss = 1.12704542, grad/param norm = 1.7324e-01, time/batch = 16.9816s	
8316/26050 (epoch 15.962), train_loss = 1.05731892, grad/param norm = 1.5943e-01, time/batch = 17.6420s	
8317/26050 (epoch 15.964), train_loss = 1.11921681, grad/param norm = 1.7471e-01, time/batch = 14.8065s	
8318/26050 (epoch 15.965), train_loss = 1.04470854, grad/param norm = 1.7110e-01, time/batch = 17.8193s	
8319/26050 (epoch 15.967), train_loss = 1.43949205, grad/param norm = 1.8122e-01, time/batch = 18.5658s	
8320/26050 (epoch 15.969), train_loss = 1.11879074, grad/param norm = 1.6059e-01, time/batch = 18.3252s	
8321/26050 (epoch 15.971), train_loss = 1.06416488, grad/param norm = 1.5056e-01, time/batch = 18.0501s	
8322/26050 (epoch 15.973), train_loss = 1.09656228, grad/param norm = 1.8570e-01, time/batch = 17.9861s	
8323/26050 (epoch 15.975), train_loss = 1.19586267, grad/param norm = 1.6867e-01, time/batch = 18.6490s	
8324/26050 (epoch 15.977), train_loss = 1.16403131, grad/param norm = 1.6446e-01, time/batch = 17.3998s	
8325/26050 (epoch 15.979), train_loss = 0.96221053, grad/param norm = 1.6708e-01, time/batch = 14.4676s	
8326/26050 (epoch 15.981), train_loss = 1.26279188, grad/param norm = 1.7006e-01, time/batch = 14.0596s	
8327/26050 (epoch 15.983), train_loss = 1.22377083, grad/param norm = 1.7296e-01, time/batch = 15.4693s	
8328/26050 (epoch 15.985), train_loss = 1.18737583, grad/param norm = 1.9839e-01, time/batch = 14.3635s	
8329/26050 (epoch 15.987), train_loss = 1.25642031, grad/param norm = 1.8480e-01, time/batch = 15.0425s	
8330/26050 (epoch 15.988), train_loss = 1.21640091, grad/param norm = 1.7022e-01, time/batch = 16.8834s	
8331/26050 (epoch 15.990), train_loss = 1.01854667, grad/param norm = 1.5497e-01, time/batch = 18.8979s	
8332/26050 (epoch 15.992), train_loss = 1.28138105, grad/param norm = 1.8517e-01, time/batch = 18.1474s	
8333/26050 (epoch 15.994), train_loss = 1.12961559, grad/param norm = 1.9210e-01, time/batch = 17.4838s	
8334/26050 (epoch 15.996), train_loss = 1.09461278, grad/param norm = 1.8237e-01, time/batch = 18.7243s	
8335/26050 (epoch 15.998), train_loss = 1.13606651, grad/param norm = 1.6805e-01, time/batch = 15.2189s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
8336/26050 (epoch 16.000), train_loss = 1.09482685, grad/param norm = 1.8304e-01, time/batch = 18.2223s	
8337/26050 (epoch 16.002), train_loss = 1.22591440, grad/param norm = 1.9877e-01, time/batch = 17.9848s	
8338/26050 (epoch 16.004), train_loss = 1.04813826, grad/param norm = 1.7791e-01, time/batch = 17.2476s	
8339/26050 (epoch 16.006), train_loss = 1.06101844, grad/param norm = 1.7673e-01, time/batch = 18.5777s	
8340/26050 (epoch 16.008), train_loss = 1.05325785, grad/param norm = 1.8890e-01, time/batch = 16.1343s	
8341/26050 (epoch 16.010), train_loss = 1.06900076, grad/param norm = 1.6619e-01, time/batch = 18.6488s	
8342/26050 (epoch 16.012), train_loss = 1.15214538, grad/param norm = 1.7220e-01, time/batch = 18.3101s	
8343/26050 (epoch 16.013), train_loss = 1.50785745, grad/param norm = 2.3590e-01, time/batch = 17.4889s	
8344/26050 (epoch 16.015), train_loss = 1.07120670, grad/param norm = 1.5378e-01, time/batch = 18.1605s	
8345/26050 (epoch 16.017), train_loss = 1.14840781, grad/param norm = 1.7296e-01, time/batch = 17.4068s	
8346/26050 (epoch 16.019), train_loss = 0.95658155, grad/param norm = 1.4560e-01, time/batch = 15.8086s	
8347/26050 (epoch 16.021), train_loss = 1.20380269, grad/param norm = 1.7775e-01, time/batch = 17.1359s	
8348/26050 (epoch 16.023), train_loss = 1.00866838, grad/param norm = 1.9790e-01, time/batch = 18.7390s	
8349/26050 (epoch 16.025), train_loss = 1.12692281, grad/param norm = 1.7185e-01, time/batch = 17.6418s	
8350/26050 (epoch 16.027), train_loss = 0.91636218, grad/param norm = 1.7693e-01, time/batch = 16.3738s	
8351/26050 (epoch 16.029), train_loss = 1.15153313, grad/param norm = 1.6635e-01, time/batch = 18.6451s	
8352/26050 (epoch 16.031), train_loss = 1.26095308, grad/param norm = 2.0112e-01, time/batch = 17.5630s	
8353/26050 (epoch 16.033), train_loss = 1.17774791, grad/param norm = 1.7813e-01, time/batch = 18.2416s	
8354/26050 (epoch 16.035), train_loss = 1.19247305, grad/param norm = 1.6963e-01, time/batch = 18.4175s	
8355/26050 (epoch 16.036), train_loss = 1.03044132, grad/param norm = 1.9270e-01, time/batch = 17.8205s	
8356/26050 (epoch 16.038), train_loss = 0.94396147, grad/param norm = 1.5702e-01, time/batch = 15.9592s	
8357/26050 (epoch 16.040), train_loss = 1.14196877, grad/param norm = 1.8398e-01, time/batch = 16.8043s	
8358/26050 (epoch 16.042), train_loss = 0.97675599, grad/param norm = 1.7064e-01, time/batch = 16.9635s	
8359/26050 (epoch 16.044), train_loss = 1.21996056, grad/param norm = 1.6841e-01, time/batch = 16.6321s	
8360/26050 (epoch 16.046), train_loss = 0.90843648, grad/param norm = 1.4837e-01, time/batch = 17.5638s	
8361/26050 (epoch 16.048), train_loss = 1.14765560, grad/param norm = 1.6687e-01, time/batch = 18.7390s	
8362/26050 (epoch 16.050), train_loss = 1.03888689, grad/param norm = 1.7234e-01, time/batch = 16.8978s	
8363/26050 (epoch 16.052), train_loss = 1.08790988, grad/param norm = 1.8531e-01, time/batch = 18.4819s	
8364/26050 (epoch 16.054), train_loss = 0.95497852, grad/param norm = 1.5822e-01, time/batch = 17.9733s	
8365/26050 (epoch 16.056), train_loss = 0.90658659, grad/param norm = 1.4061e-01, time/batch = 18.7390s	
8366/26050 (epoch 16.058), train_loss = 1.07224984, grad/param norm = 1.6253e-01, time/batch = 18.3271s	
8367/26050 (epoch 16.060), train_loss = 1.15787922, grad/param norm = 1.6855e-01, time/batch = 14.8125s	
8368/26050 (epoch 16.061), train_loss = 1.04031799, grad/param norm = 1.6662e-01, time/batch = 18.7291s	
8369/26050 (epoch 16.063), train_loss = 1.15318972, grad/param norm = 1.7231e-01, time/batch = 17.1485s	
8370/26050 (epoch 16.065), train_loss = 0.93594425, grad/param norm = 1.5679e-01, time/batch = 14.3084s	
8371/26050 (epoch 16.067), train_loss = 1.14596132, grad/param norm = 1.8663e-01, time/batch = 17.0522s	
8372/26050 (epoch 16.069), train_loss = 1.17875053, grad/param norm = 1.6711e-01, time/batch = 18.4674s	
8373/26050 (epoch 16.071), train_loss = 1.18479245, grad/param norm = 1.6938e-01, time/batch = 18.3922s	
8374/26050 (epoch 16.073), train_loss = 1.31783121, grad/param norm = 1.8846e-01, time/batch = 17.9922s	
8375/26050 (epoch 16.075), train_loss = 1.03080118, grad/param norm = 1.5818e-01, time/batch = 18.4093s	
8376/26050 (epoch 16.077), train_loss = 1.03387921, grad/param norm = 1.5838e-01, time/batch = 17.3282s	
8377/26050 (epoch 16.079), train_loss = 1.15535729, grad/param norm = 1.7444e-01, time/batch = 17.8168s	
8378/26050 (epoch 16.081), train_loss = 1.08882454, grad/param norm = 1.8935e-01, time/batch = 17.0562s	
8379/26050 (epoch 16.083), train_loss = 1.19103433, grad/param norm = 1.6118e-01, time/batch = 17.7144s	
8380/26050 (epoch 16.084), train_loss = 1.17539647, grad/param norm = 1.9675e-01, time/batch = 17.5687s	
8381/26050 (epoch 16.086), train_loss = 1.26626381, grad/param norm = 1.8664e-01, time/batch = 15.8945s	
8382/26050 (epoch 16.088), train_loss = 1.01316549, grad/param norm = 1.6368e-01, time/batch = 15.8032s	
8383/26050 (epoch 16.090), train_loss = 1.15565824, grad/param norm = 1.8179e-01, time/batch = 16.9852s	
8384/26050 (epoch 16.092), train_loss = 1.16484331, grad/param norm = 1.6848e-01, time/batch = 18.5659s	
8385/26050 (epoch 16.094), train_loss = 1.06563427, grad/param norm = 1.7002e-01, time/batch = 17.7280s	
8386/26050 (epoch 16.096), train_loss = 1.10270584, grad/param norm = 1.6664e-01, time/batch = 17.1374s	
8387/26050 (epoch 16.098), train_loss = 1.08293402, grad/param norm = 1.7931e-01, time/batch = 18.2406s	
8388/26050 (epoch 16.100), train_loss = 1.01046691, grad/param norm = 1.8023e-01, time/batch = 15.4781s	
8389/26050 (epoch 16.102), train_loss = 1.12898955, grad/param norm = 1.7259e-01, time/batch = 19.0750s	
8390/26050 (epoch 16.104), train_loss = 1.13341293, grad/param norm = 1.9217e-01, time/batch = 18.1390s	
8391/26050 (epoch 16.106), train_loss = 1.12918731, grad/param norm = 1.9381e-01, time/batch = 18.1540s	
8392/26050 (epoch 16.107), train_loss = 0.90661589, grad/param norm = 1.4727e-01, time/batch = 18.3933s	
8393/26050 (epoch 16.109), train_loss = 1.04797835, grad/param norm = 1.7317e-01, time/batch = 17.2393s	
8394/26050 (epoch 16.111), train_loss = 1.29413299, grad/param norm = 1.9532e-01, time/batch = 17.0048s	
8395/26050 (epoch 16.113), train_loss = 1.06153532, grad/param norm = 1.6875e-01, time/batch = 17.6656s	
8396/26050 (epoch 16.115), train_loss = 1.21959986, grad/param norm = 1.7539e-01, time/batch = 18.0687s	
8397/26050 (epoch 16.117), train_loss = 1.15212090, grad/param norm = 1.6417e-01, time/batch = 14.4548s	
8398/26050 (epoch 16.119), train_loss = 0.93942741, grad/param norm = 1.6805e-01, time/batch = 17.8788s	
8399/26050 (epoch 16.121), train_loss = 1.15002141, grad/param norm = 1.6805e-01, time/batch = 17.8195s	
8400/26050 (epoch 16.123), train_loss = 1.01311487, grad/param norm = 1.7022e-01, time/batch = 16.7353s	
8401/26050 (epoch 16.125), train_loss = 0.97976875, grad/param norm = 1.6926e-01, time/batch = 18.1266s	
8402/26050 (epoch 16.127), train_loss = 0.89045416, grad/param norm = 1.5156e-01, time/batch = 17.7399s	
8403/26050 (epoch 16.129), train_loss = 0.95131960, grad/param norm = 1.6850e-01, time/batch = 17.5821s	
8404/26050 (epoch 16.131), train_loss = 1.08495832, grad/param norm = 1.7047e-01, time/batch = 17.9050s	
8405/26050 (epoch 16.132), train_loss = 1.08908270, grad/param norm = 1.6859e-01, time/batch = 17.9974s	
8406/26050 (epoch 16.134), train_loss = 1.09340845, grad/param norm = 1.8551e-01, time/batch = 14.3985s	
8407/26050 (epoch 16.136), train_loss = 1.10888653, grad/param norm = 1.6130e-01, time/batch = 14.5521s	
8408/26050 (epoch 16.138), train_loss = 0.90264004, grad/param norm = 1.7046e-01, time/batch = 18.9019s	
8409/26050 (epoch 16.140), train_loss = 0.94499345, grad/param norm = 1.6366e-01, time/batch = 17.5669s	
8410/26050 (epoch 16.142), train_loss = 0.99952849, grad/param norm = 1.6497e-01, time/batch = 18.2237s	
8411/26050 (epoch 16.144), train_loss = 0.91703892, grad/param norm = 1.6590e-01, time/batch = 17.6559s	
8412/26050 (epoch 16.146), train_loss = 0.84928785, grad/param norm = 1.6132e-01, time/batch = 17.9977s	
8413/26050 (epoch 16.148), train_loss = 0.88627380, grad/param norm = 1.3913e-01, time/batch = 18.3174s	
8414/26050 (epoch 16.150), train_loss = 1.08329172, grad/param norm = 1.7049e-01, time/batch = 15.2283s	
8415/26050 (epoch 16.152), train_loss = 1.28976705, grad/param norm = 2.0793e-01, time/batch = 17.3210s	
8416/26050 (epoch 16.154), train_loss = 0.87842927, grad/param norm = 1.5859e-01, time/batch = 17.9917s	
8417/26050 (epoch 16.155), train_loss = 0.92111756, grad/param norm = 1.5945e-01, time/batch = 19.7686s	
8418/26050 (epoch 16.157), train_loss = 1.03767643, grad/param norm = 2.0831e-01, time/batch = 36.0806s	
8419/26050 (epoch 16.159), train_loss = 1.08934709, grad/param norm = 1.9590e-01, time/batch = 17.8987s	
8420/26050 (epoch 16.161), train_loss = 1.17766593, grad/param norm = 1.9386e-01, time/batch = 15.1980s	
8421/26050 (epoch 16.163), train_loss = 0.92415417, grad/param norm = 1.6484e-01, time/batch = 18.2406s	
8422/26050 (epoch 16.165), train_loss = 0.83603095, grad/param norm = 1.4933e-01, time/batch = 18.9806s	
8423/26050 (epoch 16.167), train_loss = 1.20313093, grad/param norm = 1.9010e-01, time/batch = 16.4615s	
8424/26050 (epoch 16.169), train_loss = 1.15624659, grad/param norm = 1.8748e-01, time/batch = 16.3676s	
8425/26050 (epoch 16.171), train_loss = 0.89883366, grad/param norm = 1.4630e-01, time/batch = 17.3290s	
8426/26050 (epoch 16.173), train_loss = 1.02117307, grad/param norm = 1.7316e-01, time/batch = 18.3122s	
8427/26050 (epoch 16.175), train_loss = 1.07965806, grad/param norm = 1.6357e-01, time/batch = 17.2306s	
8428/26050 (epoch 16.177), train_loss = 1.21757708, grad/param norm = 1.7644e-01, time/batch = 14.8718s	
8429/26050 (epoch 16.179), train_loss = 0.86552731, grad/param norm = 1.5327e-01, time/batch = 18.7362s	
8430/26050 (epoch 16.180), train_loss = 1.31496460, grad/param norm = 1.7813e-01, time/batch = 17.3077s	
8431/26050 (epoch 16.182), train_loss = 1.33279785, grad/param norm = 1.9838e-01, time/batch = 16.9928s	
8432/26050 (epoch 16.184), train_loss = 1.11596978, grad/param norm = 1.6376e-01, time/batch = 18.1565s	
8433/26050 (epoch 16.186), train_loss = 0.90362323, grad/param norm = 1.4944e-01, time/batch = 18.0525s	
8434/26050 (epoch 16.188), train_loss = 1.08243806, grad/param norm = 1.6493e-01, time/batch = 18.3196s	
8435/26050 (epoch 16.190), train_loss = 1.15017171, grad/param norm = 1.8058e-01, time/batch = 17.3989s	
8436/26050 (epoch 16.192), train_loss = 1.15410610, grad/param norm = 1.6610e-01, time/batch = 14.9900s	
8437/26050 (epoch 16.194), train_loss = 1.13169564, grad/param norm = 1.6950e-01, time/batch = 18.2353s	
8438/26050 (epoch 16.196), train_loss = 1.19865206, grad/param norm = 1.7689e-01, time/batch = 17.9920s	
8439/26050 (epoch 16.198), train_loss = 1.01955218, grad/param norm = 1.6063e-01, time/batch = 18.5710s	
8440/26050 (epoch 16.200), train_loss = 1.00465614, grad/param norm = 1.6582e-01, time/batch = 17.0509s	
8441/26050 (epoch 16.202), train_loss = 1.07178220, grad/param norm = 1.7647e-01, time/batch = 15.8010s	
8442/26050 (epoch 16.203), train_loss = 1.21102120, grad/param norm = 1.8892e-01, time/batch = 17.5695s	
8443/26050 (epoch 16.205), train_loss = 1.03504851, grad/param norm = 1.6852e-01, time/batch = 18.3155s	
8444/26050 (epoch 16.207), train_loss = 1.03989581, grad/param norm = 1.6753e-01, time/batch = 18.0685s	
8445/26050 (epoch 16.209), train_loss = 1.11851339, grad/param norm = 1.6408e-01, time/batch = 15.5224s	
8446/26050 (epoch 16.211), train_loss = 0.93640580, grad/param norm = 1.5693e-01, time/batch = 17.9042s	
8447/26050 (epoch 16.213), train_loss = 1.15429406, grad/param norm = 1.7929e-01, time/batch = 17.0702s	
8448/26050 (epoch 16.215), train_loss = 1.09331244, grad/param norm = 1.8688e-01, time/batch = 17.7356s	
8449/26050 (epoch 16.217), train_loss = 1.08881722, grad/param norm = 1.6435e-01, time/batch = 17.9900s	
8450/26050 (epoch 16.219), train_loss = 1.07193858, grad/param norm = 1.8754e-01, time/batch = 17.8994s	
8451/26050 (epoch 16.221), train_loss = 0.98775954, grad/param norm = 1.7316e-01, time/batch = 18.8068s	
8452/26050 (epoch 16.223), train_loss = 1.11871388, grad/param norm = 1.6856e-01, time/batch = 18.0743s	
8453/26050 (epoch 16.225), train_loss = 0.99314702, grad/param norm = 1.6439e-01, time/batch = 18.0683s	
8454/26050 (epoch 16.226), train_loss = 1.16936349, grad/param norm = 1.8594e-01, time/batch = 18.4753s	
8455/26050 (epoch 16.228), train_loss = 1.23129265, grad/param norm = 1.7618e-01, time/batch = 15.0557s	
8456/26050 (epoch 16.230), train_loss = 1.13313932, grad/param norm = 1.6811e-01, time/batch = 16.7159s	
8457/26050 (epoch 16.232), train_loss = 1.22239009, grad/param norm = 1.8988e-01, time/batch = 14.6442s	
8458/26050 (epoch 16.234), train_loss = 0.96415566, grad/param norm = 1.7035e-01, time/batch = 18.3170s	
8459/26050 (epoch 16.236), train_loss = 1.18874816, grad/param norm = 1.8212e-01, time/batch = 17.8966s	
8460/26050 (epoch 16.238), train_loss = 0.94635917, grad/param norm = 1.5683e-01, time/batch = 17.5543s	
8461/26050 (epoch 16.240), train_loss = 1.09251453, grad/param norm = 1.7132e-01, time/batch = 17.4790s	
8462/26050 (epoch 16.242), train_loss = 1.09981876, grad/param norm = 1.6169e-01, time/batch = 18.3238s	
8463/26050 (epoch 16.244), train_loss = 1.09611862, grad/param norm = 2.0099e-01, time/batch = 18.3950s	
8464/26050 (epoch 16.246), train_loss = 1.03317379, grad/param norm = 1.5670e-01, time/batch = 17.9044s	
8465/26050 (epoch 16.248), train_loss = 1.10373625, grad/param norm = 1.7046e-01, time/batch = 17.3168s	
8466/26050 (epoch 16.250), train_loss = 1.10857728, grad/param norm = 1.9770e-01, time/batch = 18.2423s	
8467/26050 (epoch 16.251), train_loss = 1.06187555, grad/param norm = 1.7323e-01, time/batch = 17.8810s	
8468/26050 (epoch 16.253), train_loss = 0.96484918, grad/param norm = 1.6034e-01, time/batch = 14.8117s	
8469/26050 (epoch 16.255), train_loss = 1.28475110, grad/param norm = 1.7370e-01, time/batch = 17.6548s	
8470/26050 (epoch 16.257), train_loss = 1.10011152, grad/param norm = 1.8194e-01, time/batch = 18.9008s	
8471/26050 (epoch 16.259), train_loss = 1.24817890, grad/param norm = 1.8263e-01, time/batch = 17.4074s	
8472/26050 (epoch 16.261), train_loss = 0.98716885, grad/param norm = 1.7817e-01, time/batch = 18.3221s	
8473/26050 (epoch 16.263), train_loss = 1.14019426, grad/param norm = 1.7312e-01, time/batch = 17.8309s	
8474/26050 (epoch 16.265), train_loss = 1.26232087, grad/param norm = 1.8772e-01, time/batch = 17.4790s	
8475/26050 (epoch 16.267), train_loss = 1.19922937, grad/param norm = 1.6800e-01, time/batch = 17.9832s	
8476/26050 (epoch 16.269), train_loss = 1.28304969, grad/param norm = 1.9704e-01, time/batch = 15.9438s	
8477/26050 (epoch 16.271), train_loss = 1.15905484, grad/param norm = 1.8349e-01, time/batch = 18.2313s	
8478/26050 (epoch 16.273), train_loss = 1.05416658, grad/param norm = 1.8557e-01, time/batch = 18.2330s	
8479/26050 (epoch 16.274), train_loss = 1.06433074, grad/param norm = 1.6930e-01, time/batch = 18.1392s	
8480/26050 (epoch 16.276), train_loss = 1.03266542, grad/param norm = 1.7181e-01, time/batch = 18.1429s	
8481/26050 (epoch 16.278), train_loss = 1.23270695, grad/param norm = 1.7705e-01, time/batch = 17.8077s	
8482/26050 (epoch 16.280), train_loss = 1.08687852, grad/param norm = 1.6271e-01, time/batch = 17.4064s	
8483/26050 (epoch 16.282), train_loss = 1.12854774, grad/param norm = 1.7021e-01, time/batch = 14.9834s	
8484/26050 (epoch 16.284), train_loss = 1.04142976, grad/param norm = 1.7245e-01, time/batch = 18.1412s	
8485/26050 (epoch 16.286), train_loss = 1.12336266, grad/param norm = 1.7248e-01, time/batch = 17.2330s	
8486/26050 (epoch 16.288), train_loss = 0.95414389, grad/param norm = 1.5366e-01, time/batch = 17.9017s	
8487/26050 (epoch 16.290), train_loss = 1.09121326, grad/param norm = 1.8096e-01, time/batch = 17.5672s	
8488/26050 (epoch 16.292), train_loss = 1.01066793, grad/param norm = 1.5996e-01, time/batch = 17.8979s	
8489/26050 (epoch 16.294), train_loss = 1.13834067, grad/param norm = 1.9375e-01, time/batch = 17.8242s	
8490/26050 (epoch 16.296), train_loss = 1.21909578, grad/param norm = 1.8457e-01, time/batch = 14.5590s	
8491/26050 (epoch 16.298), train_loss = 1.10090271, grad/param norm = 1.6804e-01, time/batch = 15.3797s	
8492/26050 (epoch 16.299), train_loss = 0.87585180, grad/param norm = 1.5001e-01, time/batch = 17.4874s	
8493/26050 (epoch 16.301), train_loss = 0.99646827, grad/param norm = 1.8139e-01, time/batch = 17.3013s	
8494/26050 (epoch 16.303), train_loss = 1.12250753, grad/param norm = 1.7977e-01, time/batch = 18.9144s	
8495/26050 (epoch 16.305), train_loss = 0.93064977, grad/param norm = 1.7290e-01, time/batch = 18.3081s	
8496/26050 (epoch 16.307), train_loss = 1.02458996, grad/param norm = 1.7509e-01, time/batch = 16.5591s	
8497/26050 (epoch 16.309), train_loss = 1.07776347, grad/param norm = 1.8049e-01, time/batch = 18.0449s	
8498/26050 (epoch 16.311), train_loss = 1.20907519, grad/param norm = 2.1634e-01, time/batch = 17.3134s	
8499/26050 (epoch 16.313), train_loss = 1.08331047, grad/param norm = 1.8882e-01, time/batch = 18.7129s	
8500/26050 (epoch 16.315), train_loss = 1.18655069, grad/param norm = 1.7500e-01, time/batch = 18.9757s	
8501/26050 (epoch 16.317), train_loss = 1.07999041, grad/param norm = 1.6763e-01, time/batch = 17.8833s	
8502/26050 (epoch 16.319), train_loss = 1.04883339, grad/param norm = 1.7007e-01, time/batch = 17.8910s	
8503/26050 (epoch 16.321), train_loss = 1.06885556, grad/param norm = 1.7980e-01, time/batch = 15.3903s	
8504/26050 (epoch 16.322), train_loss = 1.12425109, grad/param norm = 1.7310e-01, time/batch = 18.6482s	
8505/26050 (epoch 16.324), train_loss = 0.92646809, grad/param norm = 1.8064e-01, time/batch = 17.8928s	
8506/26050 (epoch 16.326), train_loss = 1.25320746, grad/param norm = 1.8036e-01, time/batch = 18.5697s	
8507/26050 (epoch 16.328), train_loss = 1.14187522, grad/param norm = 1.6035e-01, time/batch = 18.3909s	
8508/26050 (epoch 16.330), train_loss = 0.98899256, grad/param norm = 1.7031e-01, time/batch = 17.1174s	
8509/26050 (epoch 16.332), train_loss = 1.15800759, grad/param norm = 1.7031e-01, time/batch = 14.7154s	
8510/26050 (epoch 16.334), train_loss = 1.06527058, grad/param norm = 1.8404e-01, time/batch = 15.9621s	
8511/26050 (epoch 16.336), train_loss = 1.03555213, grad/param norm = 1.7133e-01, time/batch = 18.8158s	
8512/26050 (epoch 16.338), train_loss = 0.96850864, grad/param norm = 1.5366e-01, time/batch = 18.5603s	
8513/26050 (epoch 16.340), train_loss = 1.21572122, grad/param norm = 1.9919e-01, time/batch = 18.5575s	
8514/26050 (epoch 16.342), train_loss = 1.23647126, grad/param norm = 1.8454e-01, time/batch = 17.8103s	
8515/26050 (epoch 16.344), train_loss = 1.07162693, grad/param norm = 1.7728e-01, time/batch = 16.6408s	
8516/26050 (epoch 16.345), train_loss = 1.06291208, grad/param norm = 1.6553e-01, time/batch = 17.2879s	
8517/26050 (epoch 16.347), train_loss = 1.20507841, grad/param norm = 1.8215e-01, time/batch = 18.4741s	
8518/26050 (epoch 16.349), train_loss = 1.15044097, grad/param norm = 1.7734e-01, time/batch = 17.6490s	
8519/26050 (epoch 16.351), train_loss = 1.11031343, grad/param norm = 1.7357e-01, time/batch = 17.2218s	
8520/26050 (epoch 16.353), train_loss = 1.09136312, grad/param norm = 1.7948e-01, time/batch = 18.1342s	
8521/26050 (epoch 16.355), train_loss = 1.16282967, grad/param norm = 1.9166e-01, time/batch = 18.6460s	
8522/26050 (epoch 16.357), train_loss = 1.01890985, grad/param norm = 1.6172e-01, time/batch = 17.8886s	
8523/26050 (epoch 16.359), train_loss = 1.17137697, grad/param norm = 1.6607e-01, time/batch = 18.8952s	
8524/26050 (epoch 16.361), train_loss = 1.03781673, grad/param norm = 1.7065e-01, time/batch = 18.4049s	
8525/26050 (epoch 16.363), train_loss = 1.15736816, grad/param norm = 1.6270e-01, time/batch = 17.2303s	
8526/26050 (epoch 16.365), train_loss = 1.07689200, grad/param norm = 1.4859e-01, time/batch = 18.6532s	
8527/26050 (epoch 16.367), train_loss = 1.13199275, grad/param norm = 1.7148e-01, time/batch = 14.6426s	
8528/26050 (epoch 16.369), train_loss = 1.07387606, grad/param norm = 1.6264e-01, time/batch = 17.9053s	
8529/26050 (epoch 16.370), train_loss = 0.99133931, grad/param norm = 1.5449e-01, time/batch = 18.2448s	
8530/26050 (epoch 16.372), train_loss = 1.16980431, grad/param norm = 1.8432e-01, time/batch = 17.8305s	
8531/26050 (epoch 16.374), train_loss = 1.26050738, grad/param norm = 1.8891e-01, time/batch = 17.6482s	
8532/26050 (epoch 16.376), train_loss = 1.31341762, grad/param norm = 1.8388e-01, time/batch = 18.0650s	
8533/26050 (epoch 16.378), train_loss = 1.09572252, grad/param norm = 1.7784e-01, time/batch = 16.4751s	
8534/26050 (epoch 16.380), train_loss = 1.30264783, grad/param norm = 2.0260e-01, time/batch = 14.5568s	
8535/26050 (epoch 16.382), train_loss = 1.41796934, grad/param norm = 2.2458e-01, time/batch = 17.5393s	
8536/26050 (epoch 16.384), train_loss = 1.09525758, grad/param norm = 1.6781e-01, time/batch = 17.3865s	
8537/26050 (epoch 16.386), train_loss = 1.20590843, grad/param norm = 1.9489e-01, time/batch = 17.6382s	
8538/26050 (epoch 16.388), train_loss = 1.12568034, grad/param norm = 1.7690e-01, time/batch = 15.1932s	
8539/26050 (epoch 16.390), train_loss = 1.03156591, grad/param norm = 1.7492e-01, time/batch = 17.2322s	
8540/26050 (epoch 16.392), train_loss = 0.98927951, grad/param norm = 1.5782e-01, time/batch = 18.7260s	
8541/26050 (epoch 16.393), train_loss = 1.14941471, grad/param norm = 1.7537e-01, time/batch = 18.2429s	
8542/26050 (epoch 16.395), train_loss = 1.16752809, grad/param norm = 1.7587e-01, time/batch = 17.8133s	
8543/26050 (epoch 16.397), train_loss = 1.15399081, grad/param norm = 1.9336e-01, time/batch = 18.3931s	
8544/26050 (epoch 16.399), train_loss = 1.02683019, grad/param norm = 1.6495e-01, time/batch = 17.6607s	
8545/26050 (epoch 16.401), train_loss = 1.09737279, grad/param norm = 1.6688e-01, time/batch = 18.3176s	
8546/26050 (epoch 16.403), train_loss = 1.14285604, grad/param norm = 1.6863e-01, time/batch = 15.9013s	
8547/26050 (epoch 16.405), train_loss = 1.10351094, grad/param norm = 1.7524e-01, time/batch = 18.4753s	
8548/26050 (epoch 16.407), train_loss = 1.25316381, grad/param norm = 1.8372e-01, time/batch = 17.7332s	
8549/26050 (epoch 16.409), train_loss = 1.29747386, grad/param norm = 1.8764e-01, time/batch = 17.8213s	
8550/26050 (epoch 16.411), train_loss = 1.16729988, grad/param norm = 2.0732e-01, time/batch = 17.7368s	
8551/26050 (epoch 16.413), train_loss = 1.25794523, grad/param norm = 1.6613e-01, time/batch = 18.2438s	
8552/26050 (epoch 16.415), train_loss = 1.25805499, grad/param norm = 2.1945e-01, time/batch = 17.3181s	
8553/26050 (epoch 16.417), train_loss = 1.34514346, grad/param norm = 2.0095e-01, time/batch = 17.7331s	
8554/26050 (epoch 16.418), train_loss = 1.23021450, grad/param norm = 2.0034e-01, time/batch = 15.4837s	
8555/26050 (epoch 16.420), train_loss = 0.93813915, grad/param norm = 1.5659e-01, time/batch = 16.0775s	
8556/26050 (epoch 16.422), train_loss = 0.96518478, grad/param norm = 1.6144e-01, time/batch = 16.8012s	
8557/26050 (epoch 16.424), train_loss = 1.28092716, grad/param norm = 2.0941e-01, time/batch = 18.3206s	
8558/26050 (epoch 16.426), train_loss = 1.23909852, grad/param norm = 1.8694e-01, time/batch = 18.8858s	
8559/26050 (epoch 16.428), train_loss = 1.03357941, grad/param norm = 1.5317e-01, time/batch = 17.3873s	
8560/26050 (epoch 16.430), train_loss = 1.19937944, grad/param norm = 1.7761e-01, time/batch = 18.8991s	
8561/26050 (epoch 16.432), train_loss = 1.07736098, grad/param norm = 1.7348e-01, time/batch = 16.7387s	
8562/26050 (epoch 16.434), train_loss = 1.10336285, grad/param norm = 1.9754e-01, time/batch = 17.3725s	
8563/26050 (epoch 16.436), train_loss = 1.23987295, grad/param norm = 1.7601e-01, time/batch = 17.1257s	
8564/26050 (epoch 16.438), train_loss = 1.09454595, grad/param norm = 1.8133e-01, time/batch = 18.4053s	
8565/26050 (epoch 16.440), train_loss = 1.14008503, grad/param norm = 1.7093e-01, time/batch = 18.6540s	
8566/26050 (epoch 16.441), train_loss = 1.12415002, grad/param norm = 1.7000e-01, time/batch = 17.5697s	
8567/26050 (epoch 16.443), train_loss = 0.93322759, grad/param norm = 1.4939e-01, time/batch = 17.8951s	
8568/26050 (epoch 16.445), train_loss = 1.01101595, grad/param norm = 1.6441e-01, time/batch = 18.9924s	
8569/26050 (epoch 16.447), train_loss = 1.26908591, grad/param norm = 1.9802e-01, time/batch = 16.7228s	
8570/26050 (epoch 16.449), train_loss = 1.01967574, grad/param norm = 1.6674e-01, time/batch = 17.1542s	
8571/26050 (epoch 16.451), train_loss = 1.27374263, grad/param norm = 1.8617e-01, time/batch = 15.2172s	
8572/26050 (epoch 16.453), train_loss = 1.03795407, grad/param norm = 1.6272e-01, time/batch = 15.4805s	
8573/26050 (epoch 16.455), train_loss = 1.15503626, grad/param norm = 1.6918e-01, time/batch = 16.4892s	
8574/26050 (epoch 16.457), train_loss = 1.13302942, grad/param norm = 1.7169e-01, time/batch = 17.7319s	
8575/26050 (epoch 16.459), train_loss = 1.23035812, grad/param norm = 1.8574e-01, time/batch = 18.2248s	
8576/26050 (epoch 16.461), train_loss = 1.19885616, grad/param norm = 2.0862e-01, time/batch = 17.3994s	
8577/26050 (epoch 16.463), train_loss = 1.06462275, grad/param norm = 1.6364e-01, time/batch = 15.7952s	
8578/26050 (epoch 16.464), train_loss = 1.16480297, grad/param norm = 1.6941e-01, time/batch = 18.2328s	
8579/26050 (epoch 16.466), train_loss = 1.21342572, grad/param norm = 1.9590e-01, time/batch = 18.8113s	
8580/26050 (epoch 16.468), train_loss = 1.20789879, grad/param norm = 1.5661e-01, time/batch = 14.7096s	
8581/26050 (epoch 16.470), train_loss = 1.32013177, grad/param norm = 2.0531e-01, time/batch = 17.6426s	
8582/26050 (epoch 16.472), train_loss = 1.26298922, grad/param norm = 2.0321e-01, time/batch = 16.3122s	
8583/26050 (epoch 16.474), train_loss = 1.32331245, grad/param norm = 1.7169e-01, time/batch = 17.1527s	
8584/26050 (epoch 16.476), train_loss = 1.25820997, grad/param norm = 1.8776e-01, time/batch = 17.1710s	
8585/26050 (epoch 16.478), train_loss = 1.07904104, grad/param norm = 1.6959e-01, time/batch = 15.4780s	
8586/26050 (epoch 16.480), train_loss = 1.16026876, grad/param norm = 1.8314e-01, time/batch = 18.2613s	
8587/26050 (epoch 16.482), train_loss = 1.08246869, grad/param norm = 1.8234e-01, time/batch = 17.3977s	
8588/26050 (epoch 16.484), train_loss = 1.07397263, grad/param norm = 1.7077e-01, time/batch = 18.2157s	
8589/26050 (epoch 16.486), train_loss = 1.29080339, grad/param norm = 1.8271e-01, time/batch = 16.7955s	
8590/26050 (epoch 16.488), train_loss = 1.41613864, grad/param norm = 1.9412e-01, time/batch = 18.2313s	
8591/26050 (epoch 16.489), train_loss = 1.34625305, grad/param norm = 1.9792e-01, time/batch = 18.8022s	
8592/26050 (epoch 16.491), train_loss = 1.03071369, grad/param norm = 1.6976e-01, time/batch = 17.9750s	
8593/26050 (epoch 16.493), train_loss = 1.13611584, grad/param norm = 1.7443e-01, time/batch = 17.9867s	
8594/26050 (epoch 16.495), train_loss = 1.11148702, grad/param norm = 1.6597e-01, time/batch = 16.5509s	
8595/26050 (epoch 16.497), train_loss = 1.03771643, grad/param norm = 1.6828e-01, time/batch = 16.4750s	
8596/26050 (epoch 16.499), train_loss = 1.07960538, grad/param norm = 1.6817e-01, time/batch = 15.2244s	
8597/26050 (epoch 16.501), train_loss = 1.19237242, grad/param norm = 1.7882e-01, time/batch = 16.0490s	
8598/26050 (epoch 16.503), train_loss = 1.06746388, grad/param norm = 1.7558e-01, time/batch = 18.0631s	
8599/26050 (epoch 16.505), train_loss = 1.25410634, grad/param norm = 1.7132e-01, time/batch = 18.1523s	
8600/26050 (epoch 16.507), train_loss = 1.21851691, grad/param norm = 1.8778e-01, time/batch = 18.4973s	
8601/26050 (epoch 16.509), train_loss = 1.32954164, grad/param norm = 1.8333e-01, time/batch = 18.4635s	
8602/26050 (epoch 16.511), train_loss = 1.03193971, grad/param norm = 1.5500e-01, time/batch = 17.9062s	
8603/26050 (epoch 16.512), train_loss = 1.08547816, grad/param norm = 1.8557e-01, time/batch = 16.4771s	
8604/26050 (epoch 16.514), train_loss = 1.20805087, grad/param norm = 1.8304e-01, time/batch = 16.5225s	
8605/26050 (epoch 16.516), train_loss = 1.23895203, grad/param norm = 1.8585e-01, time/batch = 18.8183s	
8606/26050 (epoch 16.518), train_loss = 1.15976089, grad/param norm = 1.7947e-01, time/batch = 17.9189s	
8607/26050 (epoch 16.520), train_loss = 1.11007254, grad/param norm = 1.6728e-01, time/batch = 17.1494s	
8608/26050 (epoch 16.522), train_loss = 0.91926512, grad/param norm = 1.6030e-01, time/batch = 16.8115s	
8609/26050 (epoch 16.524), train_loss = 1.23629484, grad/param norm = 1.9832e-01, time/batch = 18.8331s	
8610/26050 (epoch 16.526), train_loss = 1.23479869, grad/param norm = 1.8916e-01, time/batch = 17.9808s	
8611/26050 (epoch 16.528), train_loss = 1.17476939, grad/param norm = 1.8171e-01, time/batch = 18.2285s	
8612/26050 (epoch 16.530), train_loss = 1.12769545, grad/param norm = 1.8125e-01, time/batch = 18.0641s	
8613/26050 (epoch 16.532), train_loss = 1.12200628, grad/param norm = 1.6500e-01, time/batch = 15.2176s	
8614/26050 (epoch 16.534), train_loss = 1.18569706, grad/param norm = 1.9737e-01, time/batch = 17.3163s	
8615/26050 (epoch 16.536), train_loss = 1.12254463, grad/param norm = 1.6234e-01, time/batch = 18.4817s	
8616/26050 (epoch 16.537), train_loss = 1.24693437, grad/param norm = 1.8497e-01, time/batch = 18.4042s	
8617/26050 (epoch 16.539), train_loss = 1.13195397, grad/param norm = 1.8376e-01, time/batch = 15.7343s	
8618/26050 (epoch 16.541), train_loss = 1.34304957, grad/param norm = 2.1358e-01, time/batch = 17.9013s	
8619/26050 (epoch 16.543), train_loss = 0.95788929, grad/param norm = 1.7799e-01, time/batch = 16.1458s	
8620/26050 (epoch 16.545), train_loss = 1.18583196, grad/param norm = 1.7391e-01, time/batch = 16.3954s	
8621/26050 (epoch 16.547), train_loss = 1.13030033, grad/param norm = 1.7429e-01, time/batch = 22.0667s	
8622/26050 (epoch 16.549), train_loss = 0.93391853, grad/param norm = 1.6528e-01, time/batch = 29.6013s	
8623/26050 (epoch 16.551), train_loss = 1.17433617, grad/param norm = 1.7555e-01, time/batch = 20.5412s	
8624/26050 (epoch 16.553), train_loss = 1.05489963, grad/param norm = 1.6887e-01, time/batch = 18.8964s	
8625/26050 (epoch 16.555), train_loss = 1.06802015, grad/param norm = 1.7570e-01, time/batch = 17.8990s	
8626/26050 (epoch 16.557), train_loss = 1.18397207, grad/param norm = 1.6560e-01, time/batch = 17.2171s	
8627/26050 (epoch 16.559), train_loss = 1.12240542, grad/param norm = 1.6362e-01, time/batch = 17.3165s	
8628/26050 (epoch 16.560), train_loss = 1.09707419, grad/param norm = 1.7212e-01, time/batch = 14.8148s	
8629/26050 (epoch 16.562), train_loss = 1.11094198, grad/param norm = 1.7473e-01, time/batch = 18.4652s	
8630/26050 (epoch 16.564), train_loss = 1.31534966, grad/param norm = 1.7429e-01, time/batch = 18.0668s	
8631/26050 (epoch 16.566), train_loss = 1.03390954, grad/param norm = 1.7262e-01, time/batch = 16.3803s	
8632/26050 (epoch 16.568), train_loss = 1.15478811, grad/param norm = 1.6676e-01, time/batch = 16.6504s	
8633/26050 (epoch 16.570), train_loss = 1.23440650, grad/param norm = 1.8224e-01, time/batch = 18.6548s	
8634/26050 (epoch 16.572), train_loss = 1.10210624, grad/param norm = 1.8188e-01, time/batch = 18.3859s	
8635/26050 (epoch 16.574), train_loss = 1.20019134, grad/param norm = 2.0360e-01, time/batch = 16.9788s	
8636/26050 (epoch 16.576), train_loss = 1.16194712, grad/param norm = 1.7955e-01, time/batch = 18.2443s	
8637/26050 (epoch 16.578), train_loss = 1.10031511, grad/param norm = 1.7155e-01, time/batch = 13.4732s	
8638/26050 (epoch 16.580), train_loss = 1.04085110, grad/param norm = 1.7580e-01, time/batch = 0.6489s	
8639/26050 (epoch 16.582), train_loss = 1.16980203, grad/param norm = 1.6729e-01, time/batch = 0.6520s	
8640/26050 (epoch 16.583), train_loss = 1.23280382, grad/param norm = 1.7153e-01, time/batch = 0.6411s	
8641/26050 (epoch 16.585), train_loss = 1.01120089, grad/param norm = 1.7297e-01, time/batch = 0.6398s	
8642/26050 (epoch 16.587), train_loss = 1.16143231, grad/param norm = 1.8246e-01, time/batch = 0.6648s	
8643/26050 (epoch 16.589), train_loss = 1.28219524, grad/param norm = 2.0418e-01, time/batch = 0.6563s	
8644/26050 (epoch 16.591), train_loss = 1.11805814, grad/param norm = 1.7144e-01, time/batch = 0.6514s	
8645/26050 (epoch 16.593), train_loss = 1.01186020, grad/param norm = 1.7063e-01, time/batch = 0.8110s	
8646/26050 (epoch 16.595), train_loss = 1.22676428, grad/param norm = 2.0633e-01, time/batch = 0.9427s	
8647/26050 (epoch 16.597), train_loss = 1.15938131, grad/param norm = 1.6580e-01, time/batch = 0.9412s	
8648/26050 (epoch 16.599), train_loss = 1.10959877, grad/param norm = 1.7725e-01, time/batch = 0.9422s	
8649/26050 (epoch 16.601), train_loss = 1.31487008, grad/param norm = 1.7757e-01, time/batch = 0.9442s	
8650/26050 (epoch 16.603), train_loss = 1.17505750, grad/param norm = 1.7322e-01, time/batch = 1.1556s	
8651/26050 (epoch 16.605), train_loss = 1.06863949, grad/param norm = 1.6459e-01, time/batch = 1.7657s	
8652/26050 (epoch 16.607), train_loss = 1.25103499, grad/param norm = 1.9349e-01, time/batch = 1.8185s	
8653/26050 (epoch 16.608), train_loss = 0.99435306, grad/param norm = 1.4966e-01, time/batch = 10.6269s	
8654/26050 (epoch 16.610), train_loss = 1.11329442, grad/param norm = 1.8912e-01, time/batch = 17.6433s	
8655/26050 (epoch 16.612), train_loss = 1.14441990, grad/param norm = 1.8745e-01, time/batch = 17.0768s	
8656/26050 (epoch 16.614), train_loss = 1.19893226, grad/param norm = 1.8206e-01, time/batch = 16.1235s	
8657/26050 (epoch 16.616), train_loss = 1.30415746, grad/param norm = 1.9111e-01, time/batch = 16.8907s	
8658/26050 (epoch 16.618), train_loss = 1.08403151, grad/param norm = 1.9295e-01, time/batch = 15.8067s	
8659/26050 (epoch 16.620), train_loss = 1.16145991, grad/param norm = 1.8247e-01, time/batch = 17.3279s	
8660/26050 (epoch 16.622), train_loss = 0.99900475, grad/param norm = 1.6482e-01, time/batch = 18.3159s	
8661/26050 (epoch 16.624), train_loss = 1.00095097, grad/param norm = 1.6307e-01, time/batch = 18.0752s	
8662/26050 (epoch 16.626), train_loss = 1.17905994, grad/param norm = 1.7192e-01, time/batch = 17.2291s	
8663/26050 (epoch 16.628), train_loss = 1.06919701, grad/param norm = 1.8436e-01, time/batch = 18.5696s	
8664/26050 (epoch 16.630), train_loss = 1.24100089, grad/param norm = 1.6895e-01, time/batch = 18.3993s	
8665/26050 (epoch 16.631), train_loss = 1.28609818, grad/param norm = 1.8000e-01, time/batch = 15.7212s	
8666/26050 (epoch 16.633), train_loss = 1.04540903, grad/param norm = 1.7020e-01, time/batch = 17.8247s	
8667/26050 (epoch 16.635), train_loss = 1.04750762, grad/param norm = 1.5176e-01, time/batch = 18.1427s	
8668/26050 (epoch 16.637), train_loss = 1.01943891, grad/param norm = 1.7315e-01, time/batch = 17.8997s	
8669/26050 (epoch 16.639), train_loss = 1.23530004, grad/param norm = 1.8058e-01, time/batch = 15.3849s	
8670/26050 (epoch 16.641), train_loss = 1.09188574, grad/param norm = 1.6195e-01, time/batch = 17.5586s	
8671/26050 (epoch 16.643), train_loss = 0.98902013, grad/param norm = 1.5025e-01, time/batch = 18.3886s	
8672/26050 (epoch 16.645), train_loss = 1.15165021, grad/param norm = 1.7761e-01, time/batch = 17.8277s	
8673/26050 (epoch 16.647), train_loss = 1.07580394, grad/param norm = 1.7041e-01, time/batch = 17.9902s	
8674/26050 (epoch 16.649), train_loss = 1.15338698, grad/param norm = 2.2515e-01, time/batch = 15.5697s	
8675/26050 (epoch 16.651), train_loss = 1.04614847, grad/param norm = 1.8112e-01, time/batch = 18.4894s	
8676/26050 (epoch 16.653), train_loss = 1.14841055, grad/param norm = 1.7337e-01, time/batch = 16.6242s	
8677/26050 (epoch 16.655), train_loss = 1.05170381, grad/param norm = 1.6293e-01, time/batch = 18.1394s	
8678/26050 (epoch 16.656), train_loss = 0.96539464, grad/param norm = 1.6828e-01, time/batch = 18.0674s	
8679/26050 (epoch 16.658), train_loss = 1.31001443, grad/param norm = 1.9109e-01, time/batch = 16.6167s	
8680/26050 (epoch 16.660), train_loss = 0.99863173, grad/param norm = 1.6522e-01, time/batch = 18.1369s	
8681/26050 (epoch 16.662), train_loss = 1.01905573, grad/param norm = 1.6115e-01, time/batch = 18.2988s	
8682/26050 (epoch 16.664), train_loss = 1.10947008, grad/param norm = 1.7988e-01, time/batch = 18.2417s	
8683/26050 (epoch 16.666), train_loss = 1.11655226, grad/param norm = 1.9898e-01, time/batch = 18.0698s	
8684/26050 (epoch 16.668), train_loss = 0.94508323, grad/param norm = 1.8030e-01, time/batch = 17.0582s	
8685/26050 (epoch 16.670), train_loss = 1.28672100, grad/param norm = 1.9820e-01, time/batch = 18.4792s	
8686/26050 (epoch 16.672), train_loss = 1.08356867, grad/param norm = 1.7748e-01, time/batch = 16.5709s	
8687/26050 (epoch 16.674), train_loss = 1.02988512, grad/param norm = 1.7789e-01, time/batch = 18.2405s	
8688/26050 (epoch 16.676), train_loss = 1.13723178, grad/param norm = 1.7854e-01, time/batch = 14.8791s	
8689/26050 (epoch 16.678), train_loss = 1.23453257, grad/param norm = 1.8258e-01, time/batch = 15.6399s	
8690/26050 (epoch 16.679), train_loss = 1.32571352, grad/param norm = 1.9933e-01, time/batch = 18.4694s	
8691/26050 (epoch 16.681), train_loss = 1.14539341, grad/param norm = 1.7810e-01, time/batch = 17.8190s	
8692/26050 (epoch 16.683), train_loss = 1.00820421, grad/param norm = 1.9016e-01, time/batch = 15.1564s	
8693/26050 (epoch 16.685), train_loss = 1.06964584, grad/param norm = 1.5855e-01, time/batch = 17.4725s	
8694/26050 (epoch 16.687), train_loss = 0.95243164, grad/param norm = 1.7102e-01, time/batch = 18.7324s	
8695/26050 (epoch 16.689), train_loss = 1.09362461, grad/param norm = 1.8832e-01, time/batch = 18.3120s	
8696/26050 (epoch 16.691), train_loss = 0.87497492, grad/param norm = 1.4933e-01, time/batch = 15.5586s	
8697/26050 (epoch 16.693), train_loss = 1.01391759, grad/param norm = 1.6303e-01, time/batch = 16.3849s	
8698/26050 (epoch 16.695), train_loss = 1.11524690, grad/param norm = 1.7072e-01, time/batch = 17.2362s	
8699/26050 (epoch 16.697), train_loss = 1.01481987, grad/param norm = 1.7068e-01, time/batch = 18.2519s	
8700/26050 (epoch 16.699), train_loss = 1.16986044, grad/param norm = 1.9082e-01, time/batch = 16.9903s	
8701/26050 (epoch 16.701), train_loss = 0.98817936, grad/param norm = 1.6108e-01, time/batch = 17.9042s	
8702/26050 (epoch 16.702), train_loss = 1.26118944, grad/param norm = 1.9245e-01, time/batch = 18.1543s	
8703/26050 (epoch 16.704), train_loss = 1.18300383, grad/param norm = 1.6374e-01, time/batch = 17.2333s	
8704/26050 (epoch 16.706), train_loss = 1.12402148, grad/param norm = 1.9379e-01, time/batch = 17.8086s	
8705/26050 (epoch 16.708), train_loss = 1.21875988, grad/param norm = 1.8777e-01, time/batch = 18.3931s	
8706/26050 (epoch 16.710), train_loss = 1.19281877, grad/param norm = 1.7964e-01, time/batch = 16.2302s	
8707/26050 (epoch 16.712), train_loss = 1.21577112, grad/param norm = 1.8680e-01, time/batch = 16.6265s	
8708/26050 (epoch 16.714), train_loss = 0.95718989, grad/param norm = 1.6656e-01, time/batch = 16.7132s	
8709/26050 (epoch 16.716), train_loss = 1.37137322, grad/param norm = 1.9893e-01, time/batch = 18.7360s	
8710/26050 (epoch 16.718), train_loss = 1.22603813, grad/param norm = 1.8269e-01, time/batch = 17.5667s	
8711/26050 (epoch 16.720), train_loss = 1.09621457, grad/param norm = 1.7996e-01, time/batch = 18.3072s	
8712/26050 (epoch 16.722), train_loss = 1.01167208, grad/param norm = 1.7231e-01, time/batch = 16.2253s	
8713/26050 (epoch 16.724), train_loss = 1.04120794, grad/param norm = 1.8214e-01, time/batch = 18.3179s	
8714/26050 (epoch 16.726), train_loss = 1.22622922, grad/param norm = 1.7882e-01, time/batch = 17.8190s	
8715/26050 (epoch 16.727), train_loss = 1.21702566, grad/param norm = 1.8866e-01, time/batch = 17.2291s	
8716/26050 (epoch 16.729), train_loss = 1.16046559, grad/param norm = 1.7597e-01, time/batch = 17.6375s	
8717/26050 (epoch 16.731), train_loss = 1.15717211, grad/param norm = 1.7454e-01, time/batch = 17.4061s	
8718/26050 (epoch 16.733), train_loss = 1.08992368, grad/param norm = 2.1407e-01, time/batch = 14.9753s	
8719/26050 (epoch 16.735), train_loss = 1.32645449, grad/param norm = 1.9585e-01, time/batch = 17.6416s	
8720/26050 (epoch 16.737), train_loss = 1.09059167, grad/param norm = 1.7364e-01, time/batch = 17.8887s	
8721/26050 (epoch 16.739), train_loss = 1.17723681, grad/param norm = 1.7720e-01, time/batch = 15.5521s	
8722/26050 (epoch 16.741), train_loss = 1.05019559, grad/param norm = 1.8033e-01, time/batch = 18.3937s	
8723/26050 (epoch 16.743), train_loss = 1.15752285, grad/param norm = 1.8696e-01, time/batch = 18.5609s	
8724/26050 (epoch 16.745), train_loss = 0.99597928, grad/param norm = 1.7007e-01, time/batch = 17.2305s	
8725/26050 (epoch 16.747), train_loss = 1.01569681, grad/param norm = 1.5359e-01, time/batch = 18.9016s	
8726/26050 (epoch 16.749), train_loss = 1.25502258, grad/param norm = 1.8824e-01, time/batch = 17.9827s	
8727/26050 (epoch 16.750), train_loss = 1.10867108, grad/param norm = 1.6481e-01, time/batch = 17.8979s	
8728/26050 (epoch 16.752), train_loss = 1.08670156, grad/param norm = 2.0099e-01, time/batch = 16.3882s	
8729/26050 (epoch 16.754), train_loss = 1.14834403, grad/param norm = 1.7739e-01, time/batch = 17.8793s	
8730/26050 (epoch 16.756), train_loss = 1.13913733, grad/param norm = 2.0381e-01, time/batch = 18.1291s	
8731/26050 (epoch 16.758), train_loss = 1.13244093, grad/param norm = 1.8018e-01, time/batch = 18.1502s	
8732/26050 (epoch 16.760), train_loss = 1.28302412, grad/param norm = 1.8405e-01, time/batch = 17.8138s	
8733/26050 (epoch 16.762), train_loss = 1.06048759, grad/param norm = 1.7064e-01, time/batch = 16.1790s	
8734/26050 (epoch 16.764), train_loss = 1.16784243, grad/param norm = 1.9640e-01, time/batch = 15.9691s	
8735/26050 (epoch 16.766), train_loss = 1.21472915, grad/param norm = 1.9586e-01, time/batch = 18.0695s	
8736/26050 (epoch 16.768), train_loss = 1.02344556, grad/param norm = 1.6316e-01, time/batch = 18.7285s	
8737/26050 (epoch 16.770), train_loss = 1.10000628, grad/param norm = 1.7856e-01, time/batch = 17.3085s	
8738/26050 (epoch 16.772), train_loss = 1.10915875, grad/param norm = 1.6351e-01, time/batch = 18.3243s	
8739/26050 (epoch 16.774), train_loss = 0.99424707, grad/param norm = 1.7937e-01, time/batch = 18.2323s	
8740/26050 (epoch 16.775), train_loss = 0.81644736, grad/param norm = 1.5773e-01, time/batch = 17.0545s	
8741/26050 (epoch 16.777), train_loss = 1.05258123, grad/param norm = 1.6491e-01, time/batch = 18.1399s	
8742/26050 (epoch 16.779), train_loss = 1.09611501, grad/param norm = 1.8267e-01, time/batch = 18.0732s	
8743/26050 (epoch 16.781), train_loss = 1.02696855, grad/param norm = 1.6623e-01, time/batch = 18.0846s	
8744/26050 (epoch 16.783), train_loss = 1.01061035, grad/param norm = 1.7617e-01, time/batch = 17.6491s	
8745/26050 (epoch 16.785), train_loss = 1.09476911, grad/param norm = 1.7179e-01, time/batch = 18.3205s	
8746/26050 (epoch 16.787), train_loss = 1.03983251, grad/param norm = 1.6226e-01, time/batch = 17.3330s	
8747/26050 (epoch 16.789), train_loss = 1.04380462, grad/param norm = 1.9817e-01, time/batch = 16.9739s	
8748/26050 (epoch 16.791), train_loss = 1.08745130, grad/param norm = 1.7696e-01, time/batch = 16.5634s	
8749/26050 (epoch 16.793), train_loss = 1.08708249, grad/param norm = 1.9666e-01, time/batch = 18.1508s	
8750/26050 (epoch 16.795), train_loss = 0.92764918, grad/param norm = 1.5667e-01, time/batch = 17.6460s	
8751/26050 (epoch 16.797), train_loss = 1.01990915, grad/param norm = 1.5806e-01, time/batch = 17.2278s	
8752/26050 (epoch 16.798), train_loss = 0.95700020, grad/param norm = 1.6996e-01, time/batch = 17.5772s	
8753/26050 (epoch 16.800), train_loss = 0.95903599, grad/param norm = 1.5322e-01, time/batch = 17.9835s	
8754/26050 (epoch 16.802), train_loss = 1.05685280, grad/param norm = 1.7580e-01, time/batch = 17.9058s	
8755/26050 (epoch 16.804), train_loss = 1.07936976, grad/param norm = 1.7314e-01, time/batch = 17.6461s	
8756/26050 (epoch 16.806), train_loss = 1.19530810, grad/param norm = 1.8293e-01, time/batch = 15.0379s	
8757/26050 (epoch 16.808), train_loss = 1.09274167, grad/param norm = 1.7891e-01, time/batch = 18.3976s	
8758/26050 (epoch 16.810), train_loss = 1.03296726, grad/param norm = 1.7040e-01, time/batch = 17.4891s	
8759/26050 (epoch 16.812), train_loss = 0.99305071, grad/param norm = 1.8060e-01, time/batch = 17.2350s	
8760/26050 (epoch 16.814), train_loss = 0.98585920, grad/param norm = 1.9191e-01, time/batch = 17.8961s	
8761/26050 (epoch 16.816), train_loss = 1.23192295, grad/param norm = 1.9263e-01, time/batch = 15.3842s	
8762/26050 (epoch 16.818), train_loss = 1.23083770, grad/param norm = 1.9776e-01, time/batch = 18.4689s	
8763/26050 (epoch 16.820), train_loss = 1.12044708, grad/param norm = 1.7579e-01, time/batch = 16.7549s	
8764/26050 (epoch 16.821), train_loss = 1.25783498, grad/param norm = 1.9092e-01, time/batch = 18.7349s	
8765/26050 (epoch 16.823), train_loss = 1.28150465, grad/param norm = 1.9503e-01, time/batch = 16.8758s	
8766/26050 (epoch 16.825), train_loss = 1.10002697, grad/param norm = 1.8109e-01, time/batch = 18.2953s	
8767/26050 (epoch 16.827), train_loss = 1.12683621, grad/param norm = 2.0511e-01, time/batch = 18.0757s	
8768/26050 (epoch 16.829), train_loss = 1.17233394, grad/param norm = 1.7986e-01, time/batch = 17.8928s	
8769/26050 (epoch 16.831), train_loss = 1.22740003, grad/param norm = 1.7809e-01, time/batch = 17.8970s	
8770/26050 (epoch 16.833), train_loss = 1.32531003, grad/param norm = 1.9278e-01, time/batch = 18.4886s	
8771/26050 (epoch 16.835), train_loss = 1.32899550, grad/param norm = 1.9804e-01, time/batch = 17.1479s	
8772/26050 (epoch 16.837), train_loss = 1.10527425, grad/param norm = 1.7687e-01, time/batch = 18.7147s	
8773/26050 (epoch 16.839), train_loss = 1.12787794, grad/param norm = 1.8403e-01, time/batch = 18.2330s	
8774/26050 (epoch 16.841), train_loss = 1.22224467, grad/param norm = 1.8179e-01, time/batch = 14.5580s	
8775/26050 (epoch 16.843), train_loss = 1.13215292, grad/param norm = 1.7818e-01, time/batch = 17.6433s	
8776/26050 (epoch 16.845), train_loss = 1.04201200, grad/param norm = 1.5868e-01, time/batch = 17.1451s	
8777/26050 (epoch 16.846), train_loss = 1.21632010, grad/param norm = 1.6933e-01, time/batch = 18.3086s	
8778/26050 (epoch 16.848), train_loss = 1.11433065, grad/param norm = 1.7428e-01, time/batch = 17.4029s	
8779/26050 (epoch 16.850), train_loss = 1.02467914, grad/param norm = 1.6232e-01, time/batch = 18.7421s	
8780/26050 (epoch 16.852), train_loss = 1.08746235, grad/param norm = 1.7290e-01, time/batch = 17.8388s	
8781/26050 (epoch 16.854), train_loss = 1.09408187, grad/param norm = 1.7037e-01, time/batch = 16.3056s	
8782/26050 (epoch 16.856), train_loss = 1.07062423, grad/param norm = 1.8509e-01, time/batch = 18.4833s	
8783/26050 (epoch 16.858), train_loss = 1.01283326, grad/param norm = 1.6837e-01, time/batch = 17.1223s	
8784/26050 (epoch 16.860), train_loss = 1.14843189, grad/param norm = 1.8834e-01, time/batch = 14.3133s	
8785/26050 (epoch 16.862), train_loss = 1.16031818, grad/param norm = 1.7308e-01, time/batch = 17.0873s	
8786/26050 (epoch 16.864), train_loss = 1.15063515, grad/param norm = 2.0634e-01, time/batch = 18.0719s	
8787/26050 (epoch 16.866), train_loss = 1.05893680, grad/param norm = 1.7181e-01, time/batch = 17.6520s	
8788/26050 (epoch 16.868), train_loss = 1.17045239, grad/param norm = 1.8244e-01, time/batch = 17.7357s	
8789/26050 (epoch 16.869), train_loss = 1.00669935, grad/param norm = 1.6712e-01, time/batch = 16.8193s	
8790/26050 (epoch 16.871), train_loss = 0.94216392, grad/param norm = 1.6871e-01, time/batch = 15.3939s	
8791/26050 (epoch 16.873), train_loss = 1.16555051, grad/param norm = 1.8156e-01, time/batch = 18.1469s	
8792/26050 (epoch 16.875), train_loss = 1.10167323, grad/param norm = 1.8117e-01, time/batch = 17.2306s	
8793/26050 (epoch 16.877), train_loss = 1.00363871, grad/param norm = 1.6830e-01, time/batch = 17.1566s	
8794/26050 (epoch 16.879), train_loss = 1.13119795, grad/param norm = 1.6642e-01, time/batch = 18.8288s	
8795/26050 (epoch 16.881), train_loss = 1.24223913, grad/param norm = 1.7905e-01, time/batch = 17.3977s	
8796/26050 (epoch 16.883), train_loss = 1.16003975, grad/param norm = 1.8358e-01, time/batch = 18.3987s	
8797/26050 (epoch 16.885), train_loss = 0.85337066, grad/param norm = 1.6102e-01, time/batch = 15.2136s	
8798/26050 (epoch 16.887), train_loss = 1.15179372, grad/param norm = 1.8069e-01, time/batch = 18.6581s	
8799/26050 (epoch 16.889), train_loss = 1.07096670, grad/param norm = 1.6506e-01, time/batch = 14.5482s	
8800/26050 (epoch 16.891), train_loss = 0.89772789, grad/param norm = 1.5502e-01, time/batch = 17.7049s	
8801/26050 (epoch 16.893), train_loss = 0.94783053, grad/param norm = 1.6144e-01, time/batch = 15.8766s	
8802/26050 (epoch 16.894), train_loss = 1.06738504, grad/param norm = 1.7002e-01, time/batch = 17.2168s	
8803/26050 (epoch 16.896), train_loss = 1.21605458, grad/param norm = 1.7197e-01, time/batch = 17.6523s	
8804/26050 (epoch 16.898), train_loss = 1.03763280, grad/param norm = 1.7853e-01, time/batch = 17.7367s	
8805/26050 (epoch 16.900), train_loss = 1.16274331, grad/param norm = 1.7917e-01, time/batch = 18.6518s	
8806/26050 (epoch 16.902), train_loss = 1.09953630, grad/param norm = 1.7756e-01, time/batch = 16.4090s	
8807/26050 (epoch 16.904), train_loss = 1.09135893, grad/param norm = 1.7740e-01, time/batch = 18.6661s	
8808/26050 (epoch 16.906), train_loss = 1.08631024, grad/param norm = 1.8318e-01, time/batch = 15.5639s	
8809/26050 (epoch 16.908), train_loss = 1.09686416, grad/param norm = 1.7836e-01, time/batch = 15.7118s	
8810/26050 (epoch 16.910), train_loss = 1.02951614, grad/param norm = 1.5772e-01, time/batch = 18.1378s	
8811/26050 (epoch 16.912), train_loss = 1.34774452, grad/param norm = 2.0992e-01, time/batch = 18.2291s	
8812/26050 (epoch 16.914), train_loss = 1.46106700, grad/param norm = 2.0277e-01, time/batch = 18.0827s	
8813/26050 (epoch 16.916), train_loss = 1.21486472, grad/param norm = 1.9283e-01, time/batch = 17.5638s	
8814/26050 (epoch 16.917), train_loss = 1.13550717, grad/param norm = 1.9913e-01, time/batch = 18.3871s	
8815/26050 (epoch 16.919), train_loss = 1.19865575, grad/param norm = 1.9638e-01, time/batch = 14.9792s	
8816/26050 (epoch 16.921), train_loss = 1.06485544, grad/param norm = 1.8117e-01, time/batch = 17.5712s	
8817/26050 (epoch 16.923), train_loss = 1.14344770, grad/param norm = 1.8990e-01, time/batch = 17.7125s	
8818/26050 (epoch 16.925), train_loss = 1.12779506, grad/param norm = 1.7651e-01, time/batch = 17.8297s	
8819/26050 (epoch 16.927), train_loss = 0.98300871, grad/param norm = 1.4837e-01, time/batch = 18.3213s	
8820/26050 (epoch 16.929), train_loss = 0.99852843, grad/param norm = 1.6817e-01, time/batch = 16.3889s	
8821/26050 (epoch 16.931), train_loss = 1.30615789, grad/param norm = 2.0583e-01, time/batch = 17.9730s	
8822/26050 (epoch 16.933), train_loss = 1.07081752, grad/param norm = 1.7407e-01, time/batch = 18.2340s	
8823/26050 (epoch 16.935), train_loss = 1.08534857, grad/param norm = 1.8273e-01, time/batch = 17.4729s	
8824/26050 (epoch 16.937), train_loss = 1.19939056, grad/param norm = 1.7956e-01, time/batch = 16.9674s	
8825/26050 (epoch 16.939), train_loss = 1.00510528, grad/param norm = 1.4858e-01, time/batch = 17.9839s	
8826/26050 (epoch 16.940), train_loss = 1.09727867, grad/param norm = 1.5817e-01, time/batch = 16.6467s	
8827/26050 (epoch 16.942), train_loss = 1.13212458, grad/param norm = 1.8219e-01, time/batch = 17.8151s	
8828/26050 (epoch 16.944), train_loss = 1.05381871, grad/param norm = 1.6433e-01, time/batch = 18.2417s	
8829/26050 (epoch 16.946), train_loss = 1.24445792, grad/param norm = 1.9372e-01, time/batch = 18.1637s	
8830/26050 (epoch 16.948), train_loss = 0.99359047, grad/param norm = 2.0654e-01, time/batch = 17.1534s	
8831/26050 (epoch 16.950), train_loss = 1.08545106, grad/param norm = 1.8216e-01, time/batch = 18.2433s	
8832/26050 (epoch 16.952), train_loss = 1.23426002, grad/param norm = 1.9861e-01, time/batch = 18.4889s	
8833/26050 (epoch 16.954), train_loss = 1.21039608, grad/param norm = 1.8236e-01, time/batch = 17.3884s	
8834/26050 (epoch 16.956), train_loss = 1.10415090, grad/param norm = 1.7638e-01, time/batch = 16.1597s	
8835/26050 (epoch 16.958), train_loss = 1.05880797, grad/param norm = 1.7410e-01, time/batch = 17.3989s	
8836/26050 (epoch 16.960), train_loss = 1.10653864, grad/param norm = 1.7286e-01, time/batch = 18.2299s	
8837/26050 (epoch 16.962), train_loss = 1.02985737, grad/param norm = 1.5832e-01, time/batch = 17.9799s	
8838/26050 (epoch 16.964), train_loss = 1.09126998, grad/param norm = 1.7749e-01, time/batch = 16.9818s	
8839/26050 (epoch 16.965), train_loss = 1.02676703, grad/param norm = 1.7092e-01, time/batch = 17.2414s	
8840/26050 (epoch 16.967), train_loss = 1.42720440, grad/param norm = 1.8336e-01, time/batch = 21.7204s	
8841/26050 (epoch 16.969), train_loss = 1.09048934, grad/param norm = 1.6368e-01, time/batch = 34.3556s	
8842/26050 (epoch 16.971), train_loss = 1.05103011, grad/param norm = 1.5067e-01, time/batch = 17.2148s	
8843/26050 (epoch 16.973), train_loss = 1.07569156, grad/param norm = 1.8843e-01, time/batch = 18.7374s	
8844/26050 (epoch 16.975), train_loss = 1.17106812, grad/param norm = 1.7236e-01, time/batch = 17.2079s	
8845/26050 (epoch 16.977), train_loss = 1.15127037, grad/param norm = 1.6795e-01, time/batch = 15.1561s	
8846/26050 (epoch 16.979), train_loss = 0.93504056, grad/param norm = 1.6549e-01, time/batch = 18.4766s	
8847/26050 (epoch 16.981), train_loss = 1.23977602, grad/param norm = 1.7058e-01, time/batch = 17.8276s	
8848/26050 (epoch 16.983), train_loss = 1.19955307, grad/param norm = 1.7847e-01, time/batch = 18.4795s	
8849/26050 (epoch 16.985), train_loss = 1.16144236, grad/param norm = 1.7784e-01, time/batch = 17.2233s	
8850/26050 (epoch 16.987), train_loss = 1.22709897, grad/param norm = 1.7502e-01, time/batch = 14.6476s	
8851/26050 (epoch 16.988), train_loss = 1.20041897, grad/param norm = 1.7243e-01, time/batch = 14.9661s	
8852/26050 (epoch 16.990), train_loss = 0.98266778, grad/param norm = 1.4955e-01, time/batch = 18.8858s	
8853/26050 (epoch 16.992), train_loss = 1.26918110, grad/param norm = 1.9071e-01, time/batch = 18.3024s	
8854/26050 (epoch 16.994), train_loss = 1.09719746, grad/param norm = 1.8557e-01, time/batch = 18.0759s	
8855/26050 (epoch 16.996), train_loss = 1.07463423, grad/param norm = 1.8735e-01, time/batch = 17.5733s	
8856/26050 (epoch 16.998), train_loss = 1.12178523, grad/param norm = 1.7194e-01, time/batch = 17.2363s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
8857/26050 (epoch 17.000), train_loss = 1.06415345, grad/param norm = 1.8486e-01, time/batch = 18.5689s	
8858/26050 (epoch 17.002), train_loss = 1.19640016, grad/param norm = 1.9569e-01, time/batch = 17.8206s	
8859/26050 (epoch 17.004), train_loss = 1.01730572, grad/param norm = 1.7361e-01, time/batch = 17.7265s	
8860/26050 (epoch 17.006), train_loss = 1.03795119, grad/param norm = 1.7553e-01, time/batch = 19.3839s	
8861/26050 (epoch 17.008), train_loss = 1.02479075, grad/param norm = 1.8276e-01, time/batch = 18.3180s	
8862/26050 (epoch 17.010), train_loss = 1.04061637, grad/param norm = 1.7426e-01, time/batch = 18.0756s	
8863/26050 (epoch 17.012), train_loss = 1.12617166, grad/param norm = 1.7212e-01, time/batch = 17.4459s	
8864/26050 (epoch 17.013), train_loss = 1.45773454, grad/param norm = 2.0420e-01, time/batch = 17.9925s	
8865/26050 (epoch 17.015), train_loss = 1.05646776, grad/param norm = 1.7187e-01, time/batch = 17.8111s	
8866/26050 (epoch 17.017), train_loss = 1.12228349, grad/param norm = 1.7417e-01, time/batch = 16.3011s	
8867/26050 (epoch 17.019), train_loss = 0.94805283, grad/param norm = 1.4896e-01, time/batch = 16.7074s	
8868/26050 (epoch 17.021), train_loss = 1.17839828, grad/param norm = 1.7751e-01, time/batch = 17.8846s	
8869/26050 (epoch 17.023), train_loss = 0.96170471, grad/param norm = 1.7218e-01, time/batch = 15.7144s	
8870/26050 (epoch 17.025), train_loss = 1.10878950, grad/param norm = 1.7071e-01, time/batch = 17.4865s	
8871/26050 (epoch 17.027), train_loss = 0.89489276, grad/param norm = 1.6386e-01, time/batch = 17.8243s	
8872/26050 (epoch 17.029), train_loss = 1.13549807, grad/param norm = 1.7115e-01, time/batch = 18.9123s	
8873/26050 (epoch 17.031), train_loss = 1.24332105, grad/param norm = 2.0407e-01, time/batch = 17.0613s	
8874/26050 (epoch 17.033), train_loss = 1.15541402, grad/param norm = 1.8520e-01, time/batch = 17.7443s	
8875/26050 (epoch 17.035), train_loss = 1.16761416, grad/param norm = 1.8193e-01, time/batch = 18.7334s	
8876/26050 (epoch 17.036), train_loss = 1.01102834, grad/param norm = 1.8881e-01, time/batch = 18.0502s	
8877/26050 (epoch 17.038), train_loss = 0.92746356, grad/param norm = 1.6306e-01, time/batch = 15.3067s	
8878/26050 (epoch 17.040), train_loss = 1.11781864, grad/param norm = 1.8858e-01, time/batch = 17.9022s	
8879/26050 (epoch 17.042), train_loss = 0.94849165, grad/param norm = 1.6725e-01, time/batch = 18.5512s	
8880/26050 (epoch 17.044), train_loss = 1.19219448, grad/param norm = 1.6771e-01, time/batch = 18.2952s	
8881/26050 (epoch 17.046), train_loss = 0.88687074, grad/param norm = 1.4913e-01, time/batch = 17.9640s	
8882/26050 (epoch 17.048), train_loss = 1.12737904, grad/param norm = 1.6904e-01, time/batch = 18.7344s	
8883/26050 (epoch 17.050), train_loss = 1.01853669, grad/param norm = 1.7194e-01, time/batch = 17.5470s	
8884/26050 (epoch 17.052), train_loss = 1.05969905, grad/param norm = 1.8034e-01, time/batch = 16.2320s	
8885/26050 (epoch 17.054), train_loss = 0.93955118, grad/param norm = 1.5745e-01, time/batch = 18.3150s	
8886/26050 (epoch 17.056), train_loss = 0.88753550, grad/param norm = 1.3988e-01, time/batch = 16.9792s	
8887/26050 (epoch 17.058), train_loss = 1.05683677, grad/param norm = 1.6354e-01, time/batch = 18.4723s	
8888/26050 (epoch 17.060), train_loss = 1.13480746, grad/param norm = 1.7111e-01, time/batch = 17.4769s	
8889/26050 (epoch 17.061), train_loss = 1.01697016, grad/param norm = 1.7193e-01, time/batch = 15.7143s	
8890/26050 (epoch 17.063), train_loss = 1.14602508, grad/param norm = 1.7992e-01, time/batch = 17.4660s	
8891/26050 (epoch 17.065), train_loss = 0.91074113, grad/param norm = 1.5623e-01, time/batch = 17.9090s	
8892/26050 (epoch 17.067), train_loss = 1.12066144, grad/param norm = 1.8153e-01, time/batch = 17.8080s	
8893/26050 (epoch 17.069), train_loss = 1.15144204, grad/param norm = 1.6980e-01, time/batch = 15.5429s	
8894/26050 (epoch 17.071), train_loss = 1.17375630, grad/param norm = 1.7567e-01, time/batch = 18.0663s	
8895/26050 (epoch 17.073), train_loss = 1.29218385, grad/param norm = 1.9365e-01, time/batch = 18.2996s	
8896/26050 (epoch 17.075), train_loss = 1.01563090, grad/param norm = 1.6276e-01, time/batch = 17.2205s	
8897/26050 (epoch 17.077), train_loss = 1.01711258, grad/param norm = 1.6434e-01, time/batch = 18.1348s	
8898/26050 (epoch 17.079), train_loss = 1.12887930, grad/param norm = 1.7815e-01, time/batch = 18.1531s	
8899/26050 (epoch 17.081), train_loss = 1.06077676, grad/param norm = 1.7022e-01, time/batch = 18.7316s	
8900/26050 (epoch 17.083), train_loss = 1.16795875, grad/param norm = 1.6344e-01, time/batch = 16.8960s	
8901/26050 (epoch 17.084), train_loss = 1.14273204, grad/param norm = 2.0575e-01, time/batch = 18.4698s	
8902/26050 (epoch 17.086), train_loss = 1.24697936, grad/param norm = 1.8493e-01, time/batch = 15.8899s	
8903/26050 (epoch 17.088), train_loss = 0.99775104, grad/param norm = 1.6948e-01, time/batch = 17.3812s	
8904/26050 (epoch 17.090), train_loss = 1.13320193, grad/param norm = 1.8594e-01, time/batch = 18.3069s	
8905/26050 (epoch 17.092), train_loss = 1.15243128, grad/param norm = 1.7597e-01, time/batch = 17.4982s	
8906/26050 (epoch 17.094), train_loss = 1.04898777, grad/param norm = 1.7174e-01, time/batch = 18.9058s	
8907/26050 (epoch 17.096), train_loss = 1.08527546, grad/param norm = 1.6911e-01, time/batch = 15.5340s	
8908/26050 (epoch 17.098), train_loss = 1.05383983, grad/param norm = 1.8092e-01, time/batch = 18.1627s	
8909/26050 (epoch 17.100), train_loss = 0.99330377, grad/param norm = 1.7705e-01, time/batch = 17.3876s	
8910/26050 (epoch 17.102), train_loss = 1.11466200, grad/param norm = 1.6947e-01, time/batch = 14.8715s	
8911/26050 (epoch 17.104), train_loss = 1.10570403, grad/param norm = 1.9216e-01, time/batch = 17.8148s	
8912/26050 (epoch 17.106), train_loss = 1.11251807, grad/param norm = 1.9445e-01, time/batch = 18.2331s	
8913/26050 (epoch 17.107), train_loss = 0.88870390, grad/param norm = 1.5134e-01, time/batch = 18.2351s	
8914/26050 (epoch 17.109), train_loss = 1.02444064, grad/param norm = 1.7824e-01, time/batch = 17.9786s	
8915/26050 (epoch 17.111), train_loss = 1.27168253, grad/param norm = 1.9169e-01, time/batch = 17.7248s	
8916/26050 (epoch 17.113), train_loss = 1.03632396, grad/param norm = 1.6908e-01, time/batch = 16.0474s	
8917/26050 (epoch 17.115), train_loss = 1.20112899, grad/param norm = 1.7529e-01, time/batch = 17.3958s	
8918/26050 (epoch 17.117), train_loss = 1.12576551, grad/param norm = 1.6342e-01, time/batch = 18.8812s	
8919/26050 (epoch 17.119), train_loss = 0.92439949, grad/param norm = 1.6935e-01, time/batch = 17.8264s	
8920/26050 (epoch 17.121), train_loss = 1.12891956, grad/param norm = 1.8295e-01, time/batch = 17.9752s	
8921/26050 (epoch 17.123), train_loss = 0.99226434, grad/param norm = 1.6478e-01, time/batch = 17.7299s	
8922/26050 (epoch 17.125), train_loss = 0.96658446, grad/param norm = 1.7035e-01, time/batch = 14.6225s	
8923/26050 (epoch 17.127), train_loss = 0.87294838, grad/param norm = 1.5145e-01, time/batch = 17.7367s	
8924/26050 (epoch 17.129), train_loss = 0.93049406, grad/param norm = 1.7151e-01, time/batch = 16.8232s	
8925/26050 (epoch 17.131), train_loss = 1.06217671, grad/param norm = 1.7243e-01, time/batch = 18.8159s	
8926/26050 (epoch 17.132), train_loss = 1.06390770, grad/param norm = 1.6644e-01, time/batch = 17.4153s	
8927/26050 (epoch 17.134), train_loss = 1.07837785, grad/param norm = 1.9668e-01, time/batch = 17.8194s	
8928/26050 (epoch 17.136), train_loss = 1.08973647, grad/param norm = 1.6683e-01, time/batch = 14.9862s	
8929/26050 (epoch 17.138), train_loss = 0.87049994, grad/param norm = 1.6405e-01, time/batch = 17.9921s	
8930/26050 (epoch 17.140), train_loss = 0.92478839, grad/param norm = 1.7035e-01, time/batch = 17.8939s	
8931/26050 (epoch 17.142), train_loss = 0.96657500, grad/param norm = 1.6469e-01, time/batch = 18.0528s	
8932/26050 (epoch 17.144), train_loss = 0.89837685, grad/param norm = 1.6324e-01, time/batch = 17.7308s	
8933/26050 (epoch 17.146), train_loss = 0.82553321, grad/param norm = 1.6172e-01, time/batch = 18.3850s	
8934/26050 (epoch 17.148), train_loss = 0.86315645, grad/param norm = 1.4976e-01, time/batch = 17.3197s	
8935/26050 (epoch 17.150), train_loss = 1.06444929, grad/param norm = 1.8177e-01, time/batch = 17.9888s	
8936/26050 (epoch 17.152), train_loss = 1.25697460, grad/param norm = 2.0153e-01, time/batch = 18.7995s	
8937/26050 (epoch 17.154), train_loss = 0.85467329, grad/param norm = 1.6315e-01, time/batch = 17.6489s	
8938/26050 (epoch 17.155), train_loss = 0.89957554, grad/param norm = 1.5850e-01, time/batch = 18.3836s	
8939/26050 (epoch 17.157), train_loss = 1.01177530, grad/param norm = 2.0149e-01, time/batch = 15.2221s	
8940/26050 (epoch 17.159), train_loss = 1.07068180, grad/param norm = 1.8974e-01, time/batch = 18.8125s	
8941/26050 (epoch 17.161), train_loss = 1.14439042, grad/param norm = 1.8673e-01, time/batch = 16.7364s	
8942/26050 (epoch 17.163), train_loss = 0.89811707, grad/param norm = 1.6362e-01, time/batch = 17.4951s	
8943/26050 (epoch 17.165), train_loss = 0.81807709, grad/param norm = 1.4812e-01, time/batch = 18.0649s	
8944/26050 (epoch 17.167), train_loss = 1.17170476, grad/param norm = 1.8385e-01, time/batch = 14.8821s	
8945/26050 (epoch 17.169), train_loss = 1.12881935, grad/param norm = 1.8128e-01, time/batch = 15.9848s	
8946/26050 (epoch 17.171), train_loss = 0.87569802, grad/param norm = 1.5149e-01, time/batch = 16.4778s	
8947/26050 (epoch 17.173), train_loss = 1.00525070, grad/param norm = 1.7574e-01, time/batch = 15.0992s	
8948/26050 (epoch 17.175), train_loss = 1.05684262, grad/param norm = 1.6616e-01, time/batch = 14.2478s	
8949/26050 (epoch 17.177), train_loss = 1.19288652, grad/param norm = 1.7847e-01, time/batch = 13.9188s	
8950/26050 (epoch 17.179), train_loss = 0.85034465, grad/param norm = 1.5649e-01, time/batch = 13.9362s	
8951/26050 (epoch 17.180), train_loss = 1.29281872, grad/param norm = 1.8260e-01, time/batch = 17.7317s	
8952/26050 (epoch 17.182), train_loss = 1.30533680, grad/param norm = 1.8971e-01, time/batch = 17.9011s	
8953/26050 (epoch 17.184), train_loss = 1.10047691, grad/param norm = 1.7018e-01, time/batch = 16.3857s	
8954/26050 (epoch 17.186), train_loss = 0.89027679, grad/param norm = 1.5684e-01, time/batch = 18.4630s	
8955/26050 (epoch 17.188), train_loss = 1.07201291, grad/param norm = 1.7500e-01, time/batch = 14.4666s	
8956/26050 (epoch 17.190), train_loss = 1.12946523, grad/param norm = 1.7931e-01, time/batch = 18.2234s	
8957/26050 (epoch 17.192), train_loss = 1.13447838, grad/param norm = 1.6582e-01, time/batch = 17.0589s	
8958/26050 (epoch 17.194), train_loss = 1.11537416, grad/param norm = 1.6948e-01, time/batch = 18.3976s	
8959/26050 (epoch 17.196), train_loss = 1.17133057, grad/param norm = 1.8059e-01, time/batch = 17.0598s	
8960/26050 (epoch 17.198), train_loss = 0.99815453, grad/param norm = 1.6135e-01, time/batch = 18.4832s	
8961/26050 (epoch 17.200), train_loss = 0.97926680, grad/param norm = 1.7364e-01, time/batch = 17.5858s	
8962/26050 (epoch 17.202), train_loss = 1.06200871, grad/param norm = 1.7607e-01, time/batch = 15.6333s	
8963/26050 (epoch 17.203), train_loss = 1.19058601, grad/param norm = 1.9348e-01, time/batch = 18.0706s	
8964/26050 (epoch 17.205), train_loss = 1.01117566, grad/param norm = 1.6474e-01, time/batch = 18.8058s	
8965/26050 (epoch 17.207), train_loss = 1.01467894, grad/param norm = 1.7004e-01, time/batch = 18.8948s	
8966/26050 (epoch 17.209), train_loss = 1.10195475, grad/param norm = 1.6754e-01, time/batch = 17.6397s	
8967/26050 (epoch 17.211), train_loss = 0.91968503, grad/param norm = 1.5925e-01, time/batch = 17.9689s	
8968/26050 (epoch 17.213), train_loss = 1.13806900, grad/param norm = 1.7698e-01, time/batch = 18.1604s	
8969/26050 (epoch 17.215), train_loss = 1.06457516, grad/param norm = 1.8771e-01, time/batch = 17.0003s	
8970/26050 (epoch 17.217), train_loss = 1.07385797, grad/param norm = 1.7033e-01, time/batch = 15.9059s	
8971/26050 (epoch 17.219), train_loss = 1.05515234, grad/param norm = 1.9783e-01, time/batch = 14.5384s	
8972/26050 (epoch 17.221), train_loss = 0.97819308, grad/param norm = 1.8071e-01, time/batch = 18.6409s	
8973/26050 (epoch 17.223), train_loss = 1.09381067, grad/param norm = 1.7257e-01, time/batch = 18.6357s	
8974/26050 (epoch 17.225), train_loss = 0.97391962, grad/param norm = 1.6754e-01, time/batch = 18.1539s	
8975/26050 (epoch 17.226), train_loss = 1.15456176, grad/param norm = 1.9561e-01, time/batch = 18.4874s	
8976/26050 (epoch 17.228), train_loss = 1.21166992, grad/param norm = 1.8249e-01, time/batch = 16.3879s	
8977/26050 (epoch 17.230), train_loss = 1.10861974, grad/param norm = 1.6984e-01, time/batch = 18.2370s	
8978/26050 (epoch 17.232), train_loss = 1.19726897, grad/param norm = 1.9383e-01, time/batch = 18.0585s	
8979/26050 (epoch 17.234), train_loss = 0.94764797, grad/param norm = 1.7494e-01, time/batch = 18.3171s	
8980/26050 (epoch 17.236), train_loss = 1.16700576, grad/param norm = 1.8780e-01, time/batch = 17.5849s	
8981/26050 (epoch 17.238), train_loss = 0.92878548, grad/param norm = 1.6221e-01, time/batch = 17.3190s	
8982/26050 (epoch 17.240), train_loss = 1.07325589, grad/param norm = 1.7420e-01, time/batch = 18.4851s	
8983/26050 (epoch 17.242), train_loss = 1.07885419, grad/param norm = 1.6606e-01, time/batch = 17.8059s	
8984/26050 (epoch 17.244), train_loss = 1.06859782, grad/param norm = 2.0014e-01, time/batch = 15.0632s	
8985/26050 (epoch 17.246), train_loss = 1.02104826, grad/param norm = 1.6937e-01, time/batch = 17.9774s	
8986/26050 (epoch 17.248), train_loss = 1.07765251, grad/param norm = 1.6833e-01, time/batch = 16.3857s	
8987/26050 (epoch 17.250), train_loss = 1.09018717, grad/param norm = 2.0198e-01, time/batch = 17.4114s	
8988/26050 (epoch 17.251), train_loss = 1.04598098, grad/param norm = 1.8154e-01, time/batch = 18.3250s	
8989/26050 (epoch 17.253), train_loss = 0.94225355, grad/param norm = 1.6316e-01, time/batch = 18.3737s	
8990/26050 (epoch 17.255), train_loss = 1.25594050, grad/param norm = 1.7485e-01, time/batch = 18.1587s	
8991/26050 (epoch 17.257), train_loss = 1.07195360, grad/param norm = 1.7961e-01, time/batch = 16.8163s	
8992/26050 (epoch 17.259), train_loss = 1.22171808, grad/param norm = 1.7971e-01, time/batch = 14.9784s	
8993/26050 (epoch 17.261), train_loss = 0.96494349, grad/param norm = 1.7717e-01, time/batch = 16.1460s	
8994/26050 (epoch 17.263), train_loss = 1.13031098, grad/param norm = 1.7722e-01, time/batch = 18.5895s	
8995/26050 (epoch 17.265), train_loss = 1.24622684, grad/param norm = 1.8458e-01, time/batch = 16.8307s	
8996/26050 (epoch 17.267), train_loss = 1.18125071, grad/param norm = 1.6737e-01, time/batch = 18.1414s	
8997/26050 (epoch 17.269), train_loss = 1.24907346, grad/param norm = 2.0022e-01, time/batch = 15.8408s	
8998/26050 (epoch 17.271), train_loss = 1.13583010, grad/param norm = 1.7921e-01, time/batch = 18.3010s	
8999/26050 (epoch 17.273), train_loss = 1.04161629, grad/param norm = 1.8466e-01, time/batch = 18.1296s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch17.27_1.6478.t7	
9000/26050 (epoch 17.274), train_loss = 1.04781501, grad/param norm = 1.7025e-01, time/batch = 16.9047s	
9001/26050 (epoch 17.276), train_loss = 1.28684870, grad/param norm = 2.0510e-01, time/batch = 15.6282s	
9002/26050 (epoch 17.278), train_loss = 1.22011665, grad/param norm = 1.7963e-01, time/batch = 17.7339s	
9003/26050 (epoch 17.280), train_loss = 1.06880908, grad/param norm = 1.6606e-01, time/batch = 18.4017s	
9004/26050 (epoch 17.282), train_loss = 1.10347808, grad/param norm = 1.6653e-01, time/batch = 15.7111s	
9005/26050 (epoch 17.284), train_loss = 1.02420606, grad/param norm = 1.7546e-01, time/batch = 18.7374s	
9006/26050 (epoch 17.286), train_loss = 1.10182272, grad/param norm = 1.7625e-01, time/batch = 15.5547s	
9007/26050 (epoch 17.288), train_loss = 0.93049304, grad/param norm = 1.5520e-01, time/batch = 18.0522s	
9008/26050 (epoch 17.290), train_loss = 1.08006704, grad/param norm = 1.8505e-01, time/batch = 18.2365s	
9009/26050 (epoch 17.292), train_loss = 0.99734680, grad/param norm = 1.6904e-01, time/batch = 18.9819s	
9010/26050 (epoch 17.294), train_loss = 1.12224076, grad/param norm = 1.9862e-01, time/batch = 17.2964s	
9011/26050 (epoch 17.296), train_loss = 1.18129284, grad/param norm = 1.8026e-01, time/batch = 17.7216s	
9012/26050 (epoch 17.298), train_loss = 1.08500027, grad/param norm = 1.7101e-01, time/batch = 17.6559s	
9013/26050 (epoch 17.299), train_loss = 0.86747145, grad/param norm = 1.5460e-01, time/batch = 17.6367s	
9014/26050 (epoch 17.301), train_loss = 0.96657668, grad/param norm = 1.8332e-01, time/batch = 16.6387s	
9015/26050 (epoch 17.303), train_loss = 1.10474765, grad/param norm = 1.9846e-01, time/batch = 17.4017s	
9016/26050 (epoch 17.305), train_loss = 0.90603313, grad/param norm = 1.7397e-01, time/batch = 16.4777s	
9017/26050 (epoch 17.307), train_loss = 0.99991913, grad/param norm = 1.7255e-01, time/batch = 17.0467s	
9018/26050 (epoch 17.309), train_loss = 1.05980257, grad/param norm = 1.7885e-01, time/batch = 18.3039s	
9019/26050 (epoch 17.311), train_loss = 1.18419370, grad/param norm = 2.1114e-01, time/batch = 17.6483s	
9020/26050 (epoch 17.313), train_loss = 1.06208795, grad/param norm = 1.9671e-01, time/batch = 18.4814s	
9021/26050 (epoch 17.315), train_loss = 1.18090514, grad/param norm = 2.3148e-01, time/batch = 17.0571s	
9022/26050 (epoch 17.317), train_loss = 1.06787826, grad/param norm = 1.7009e-01, time/batch = 15.8898s	
9023/26050 (epoch 17.319), train_loss = 1.02719741, grad/param norm = 1.8311e-01, time/batch = 17.5631s	
9024/26050 (epoch 17.321), train_loss = 1.05574495, grad/param norm = 1.8343e-01, time/batch = 17.9737s	
9025/26050 (epoch 17.322), train_loss = 1.10277632, grad/param norm = 1.6758e-01, time/batch = 18.2056s	
9026/26050 (epoch 17.324), train_loss = 0.90651198, grad/param norm = 1.7277e-01, time/batch = 18.4574s	
9027/26050 (epoch 17.326), train_loss = 1.22409027, grad/param norm = 1.7421e-01, time/batch = 17.2378s	
9028/26050 (epoch 17.328), train_loss = 1.12728361, grad/param norm = 1.6843e-01, time/batch = 18.0581s	
9029/26050 (epoch 17.330), train_loss = 0.96557013, grad/param norm = 1.6774e-01, time/batch = 16.9055s	
9030/26050 (epoch 17.332), train_loss = 1.13178363, grad/param norm = 1.7482e-01, time/batch = 17.6258s	
9031/26050 (epoch 17.334), train_loss = 1.05227142, grad/param norm = 2.0152e-01, time/batch = 18.3049s	
9032/26050 (epoch 17.336), train_loss = 1.01573913, grad/param norm = 1.6615e-01, time/batch = 18.7292s	
9033/26050 (epoch 17.338), train_loss = 0.96117635, grad/param norm = 1.5771e-01, time/batch = 17.9748s	
9034/26050 (epoch 17.340), train_loss = 1.19678995, grad/param norm = 1.9433e-01, time/batch = 14.9846s	
9035/26050 (epoch 17.342), train_loss = 1.21103617, grad/param norm = 1.8267e-01, time/batch = 18.2310s	
9036/26050 (epoch 17.344), train_loss = 1.03912880, grad/param norm = 1.7841e-01, time/batch = 17.7252s	
9037/26050 (epoch 17.345), train_loss = 1.04991737, grad/param norm = 1.7808e-01, time/batch = 17.8211s	
9038/26050 (epoch 17.347), train_loss = 1.18949388, grad/param norm = 1.8177e-01, time/batch = 19.8850s	
9039/26050 (epoch 17.349), train_loss = 1.13061821, grad/param norm = 1.8182e-01, time/batch = 35.0064s	
9040/26050 (epoch 17.351), train_loss = 1.09578395, grad/param norm = 1.8061e-01, time/batch = 17.4489s	
9041/26050 (epoch 17.353), train_loss = 1.07643931, grad/param norm = 1.8336e-01, time/batch = 17.6483s	
9042/26050 (epoch 17.355), train_loss = 1.14033398, grad/param norm = 1.9636e-01, time/batch = 17.2805s	
9043/26050 (epoch 17.357), train_loss = 1.00304605, grad/param norm = 1.6139e-01, time/batch = 18.1679s	
9044/26050 (epoch 17.359), train_loss = 1.16115026, grad/param norm = 1.7482e-01, time/batch = 17.5540s	
9045/26050 (epoch 17.361), train_loss = 1.01035359, grad/param norm = 1.6857e-01, time/batch = 17.9724s	
9046/26050 (epoch 17.363), train_loss = 1.14242292, grad/param norm = 1.7368e-01, time/batch = 18.6399s	
9047/26050 (epoch 17.365), train_loss = 1.05932864, grad/param norm = 1.5293e-01, time/batch = 17.3108s	
9048/26050 (epoch 17.367), train_loss = 1.11669714, grad/param norm = 1.7245e-01, time/batch = 18.2139s	
9049/26050 (epoch 17.369), train_loss = 1.05228221, grad/param norm = 1.6756e-01, time/batch = 19.0566s	
9050/26050 (epoch 17.370), train_loss = 0.97036128, grad/param norm = 1.5759e-01, time/batch = 15.9733s	
9051/26050 (epoch 17.372), train_loss = 1.14843277, grad/param norm = 1.8504e-01, time/batch = 14.5363s	
9052/26050 (epoch 17.374), train_loss = 1.23304616, grad/param norm = 1.9373e-01, time/batch = 17.7447s	
9053/26050 (epoch 17.376), train_loss = 1.29376228, grad/param norm = 1.8578e-01, time/batch = 18.5662s	
9054/26050 (epoch 17.378), train_loss = 1.06445242, grad/param norm = 1.7311e-01, time/batch = 17.9666s	
9055/26050 (epoch 17.380), train_loss = 1.27473848, grad/param norm = 2.0056e-01, time/batch = 17.2419s	
9056/26050 (epoch 17.382), train_loss = 1.38526202, grad/param norm = 2.2497e-01, time/batch = 17.5567s	
9057/26050 (epoch 17.384), train_loss = 1.08136997, grad/param norm = 1.8466e-01, time/batch = 17.8937s	
9058/26050 (epoch 17.386), train_loss = 1.18088089, grad/param norm = 2.0668e-01, time/batch = 17.8293s	
9059/26050 (epoch 17.388), train_loss = 1.09671212, grad/param norm = 1.7336e-01, time/batch = 16.8846s	
9060/26050 (epoch 17.390), train_loss = 1.01573943, grad/param norm = 1.7389e-01, time/batch = 18.1622s	
9061/26050 (epoch 17.392), train_loss = 0.96467083, grad/param norm = 1.5885e-01, time/batch = 18.8153s	
9062/26050 (epoch 17.393), train_loss = 1.12540625, grad/param norm = 1.7434e-01, time/batch = 18.0600s	
9063/26050 (epoch 17.395), train_loss = 1.14183331, grad/param norm = 1.6201e-01, time/batch = 15.2188s	
9064/26050 (epoch 17.397), train_loss = 1.13818868, grad/param norm = 2.0218e-01, time/batch = 17.2367s	
9065/26050 (epoch 17.399), train_loss = 1.01035772, grad/param norm = 1.6798e-01, time/batch = 17.8171s	
9066/26050 (epoch 17.401), train_loss = 1.09238691, grad/param norm = 1.8537e-01, time/batch = 18.4760s	
9067/26050 (epoch 17.403), train_loss = 1.12577783, grad/param norm = 1.7219e-01, time/batch = 16.0655s	
9068/26050 (epoch 17.405), train_loss = 1.09047941, grad/param norm = 1.7362e-01, time/batch = 17.5489s	
9069/26050 (epoch 17.407), train_loss = 1.23435031, grad/param norm = 1.8974e-01, time/batch = 17.6579s	
9070/26050 (epoch 17.409), train_loss = 1.27049325, grad/param norm = 1.9048e-01, time/batch = 18.3183s	
9071/26050 (epoch 17.411), train_loss = 1.14257966, grad/param norm = 2.0073e-01, time/batch = 16.5647s	
9072/26050 (epoch 17.413), train_loss = 1.23629279, grad/param norm = 1.6559e-01, time/batch = 17.6351s	
9073/26050 (epoch 17.415), train_loss = 1.21730285, grad/param norm = 2.1547e-01, time/batch = 18.4052s	
9074/26050 (epoch 17.417), train_loss = 1.30924904, grad/param norm = 1.9980e-01, time/batch = 17.6449s	
9075/26050 (epoch 17.418), train_loss = 1.20104997, grad/param norm = 1.9710e-01, time/batch = 18.8293s	
9076/26050 (epoch 17.420), train_loss = 0.92017186, grad/param norm = 1.5982e-01, time/batch = 18.5640s	
9077/26050 (epoch 17.422), train_loss = 0.94832459, grad/param norm = 1.6239e-01, time/batch = 17.4909s	
9078/26050 (epoch 17.424), train_loss = 1.25778076, grad/param norm = 2.1407e-01, time/batch = 18.8192s	
9079/26050 (epoch 17.426), train_loss = 1.21615414, grad/param norm = 1.8664e-01, time/batch = 14.8748s	
9080/26050 (epoch 17.428), train_loss = 1.01684376, grad/param norm = 1.5860e-01, time/batch = 16.9827s	
9081/26050 (epoch 17.430), train_loss = 1.18950758, grad/param norm = 1.7667e-01, time/batch = 16.9748s	
9082/26050 (epoch 17.432), train_loss = 1.06316905, grad/param norm = 1.7373e-01, time/batch = 18.1533s	
9083/26050 (epoch 17.434), train_loss = 1.08071111, grad/param norm = 1.9853e-01, time/batch = 14.1381s	
9084/26050 (epoch 17.436), train_loss = 1.22138400, grad/param norm = 1.8418e-01, time/batch = 14.1374s	
9085/26050 (epoch 17.438), train_loss = 1.09047574, grad/param norm = 1.8347e-01, time/batch = 15.2171s	
9086/26050 (epoch 17.440), train_loss = 1.11015426, grad/param norm = 1.7006e-01, time/batch = 15.2940s	
9087/26050 (epoch 17.441), train_loss = 1.09963596, grad/param norm = 1.7590e-01, time/batch = 17.8857s	
9088/26050 (epoch 17.443), train_loss = 0.92127860, grad/param norm = 1.5229e-01, time/batch = 17.8180s	
9089/26050 (epoch 17.445), train_loss = 1.00156716, grad/param norm = 1.6633e-01, time/batch = 17.3898s	
9090/26050 (epoch 17.447), train_loss = 1.24468146, grad/param norm = 1.9956e-01, time/batch = 18.6587s	
9091/26050 (epoch 17.449), train_loss = 0.99825274, grad/param norm = 1.6943e-01, time/batch = 18.8830s	
9092/26050 (epoch 17.451), train_loss = 1.24857339, grad/param norm = 1.8781e-01, time/batch = 17.0418s	
9093/26050 (epoch 17.453), train_loss = 1.01753953, grad/param norm = 1.6281e-01, time/batch = 18.3282s	
9094/26050 (epoch 17.455), train_loss = 1.13103932, grad/param norm = 1.6775e-01, time/batch = 18.4773s	
9095/26050 (epoch 17.457), train_loss = 1.10828141, grad/param norm = 1.7220e-01, time/batch = 17.9759s	
9096/26050 (epoch 17.459), train_loss = 1.20806854, grad/param norm = 1.9051e-01, time/batch = 14.4574s	
9097/26050 (epoch 17.461), train_loss = 1.17916202, grad/param norm = 2.0739e-01, time/batch = 17.1433s	
9098/26050 (epoch 17.463), train_loss = 1.06057245, grad/param norm = 1.7357e-01, time/batch = 18.3893s	
9099/26050 (epoch 17.464), train_loss = 1.14469472, grad/param norm = 1.7825e-01, time/batch = 15.2944s	
9100/26050 (epoch 17.466), train_loss = 1.17263212, grad/param norm = 1.7223e-01, time/batch = 17.5582s	
9101/26050 (epoch 17.468), train_loss = 1.18711743, grad/param norm = 1.5951e-01, time/batch = 17.1226s	
9102/26050 (epoch 17.470), train_loss = 1.28391725, grad/param norm = 2.0625e-01, time/batch = 16.5754s	
9103/26050 (epoch 17.472), train_loss = 1.23747687, grad/param norm = 1.9801e-01, time/batch = 18.5749s	
9104/26050 (epoch 17.474), train_loss = 1.29258576, grad/param norm = 1.8034e-01, time/batch = 17.8795s	
9105/26050 (epoch 17.476), train_loss = 1.23437491, grad/param norm = 1.8958e-01, time/batch = 17.7273s	
9106/26050 (epoch 17.478), train_loss = 1.06110406, grad/param norm = 1.6860e-01, time/batch = 18.0555s	
9107/26050 (epoch 17.480), train_loss = 1.12986474, grad/param norm = 1.7317e-01, time/batch = 17.5673s	
9108/26050 (epoch 17.482), train_loss = 1.06500829, grad/param norm = 1.7950e-01, time/batch = 18.7365s	
9109/26050 (epoch 17.484), train_loss = 1.05513214, grad/param norm = 1.7934e-01, time/batch = 16.5720s	
9110/26050 (epoch 17.486), train_loss = 1.26938849, grad/param norm = 1.8749e-01, time/batch = 14.8005s	
9111/26050 (epoch 17.488), train_loss = 1.38206203, grad/param norm = 1.9517e-01, time/batch = 14.4527s	
9112/26050 (epoch 17.489), train_loss = 1.32497368, grad/param norm = 2.1132e-01, time/batch = 15.2735s	
9113/26050 (epoch 17.491), train_loss = 1.01672632, grad/param norm = 1.7646e-01, time/batch = 15.3503s	
9114/26050 (epoch 17.493), train_loss = 1.12155014, grad/param norm = 1.7898e-01, time/batch = 14.2816s	
9115/26050 (epoch 17.495), train_loss = 1.09317566, grad/param norm = 1.6490e-01, time/batch = 15.4535s	
9116/26050 (epoch 17.497), train_loss = 1.00976475, grad/param norm = 1.6679e-01, time/batch = 17.5528s	
9117/26050 (epoch 17.499), train_loss = 1.06129451, grad/param norm = 1.7439e-01, time/batch = 18.4058s	
9118/26050 (epoch 17.501), train_loss = 1.17632969, grad/param norm = 1.8390e-01, time/batch = 18.0726s	
9119/26050 (epoch 17.503), train_loss = 1.05250967, grad/param norm = 1.7875e-01, time/batch = 17.9979s	
9120/26050 (epoch 17.505), train_loss = 1.23366011, grad/param norm = 1.6901e-01, time/batch = 16.7228s	
9121/26050 (epoch 17.507), train_loss = 1.18563243, grad/param norm = 1.8329e-01, time/batch = 18.4125s	
9122/26050 (epoch 17.509), train_loss = 1.30812542, grad/param norm = 1.8850e-01, time/batch = 16.9055s	
9123/26050 (epoch 17.511), train_loss = 1.02293611, grad/param norm = 1.5330e-01, time/batch = 14.6140s	
9124/26050 (epoch 17.512), train_loss = 1.05674699, grad/param norm = 2.0213e-01, time/batch = 18.3863s	
9125/26050 (epoch 17.514), train_loss = 1.18015130, grad/param norm = 1.8661e-01, time/batch = 18.3916s	
9126/26050 (epoch 17.516), train_loss = 1.21743302, grad/param norm = 1.8645e-01, time/batch = 18.4742s	
9127/26050 (epoch 17.518), train_loss = 1.12247339, grad/param norm = 1.7091e-01, time/batch = 17.8125s	
9128/26050 (epoch 17.520), train_loss = 1.09360908, grad/param norm = 1.6919e-01, time/batch = 16.6485s	
9129/26050 (epoch 17.522), train_loss = 0.89647155, grad/param norm = 1.6213e-01, time/batch = 18.1187s	
9130/26050 (epoch 17.524), train_loss = 1.20270360, grad/param norm = 1.9187e-01, time/batch = 18.2330s	
9131/26050 (epoch 17.526), train_loss = 1.21226346, grad/param norm = 1.8979e-01, time/batch = 18.4260s	
9132/26050 (epoch 17.528), train_loss = 1.15463002, grad/param norm = 1.8559e-01, time/batch = 17.9746s	
9133/26050 (epoch 17.530), train_loss = 1.09140869, grad/param norm = 1.8509e-01, time/batch = 17.8853s	
9134/26050 (epoch 17.532), train_loss = 1.10312907, grad/param norm = 1.6841e-01, time/batch = 17.6160s	
9135/26050 (epoch 17.534), train_loss = 1.16815519, grad/param norm = 2.4583e-01, time/batch = 18.3967s	
9136/26050 (epoch 17.536), train_loss = 1.09837587, grad/param norm = 1.7025e-01, time/batch = 18.4749s	
9137/26050 (epoch 17.537), train_loss = 1.20463070, grad/param norm = 1.8772e-01, time/batch = 17.8161s	
9138/26050 (epoch 17.539), train_loss = 1.11276923, grad/param norm = 1.8802e-01, time/batch = 16.1490s	
9139/26050 (epoch 17.541), train_loss = 1.31608459, grad/param norm = 2.0440e-01, time/batch = 17.8163s	
9140/26050 (epoch 17.543), train_loss = 0.94129157, grad/param norm = 1.7534e-01, time/batch = 15.2187s	
9141/26050 (epoch 17.545), train_loss = 1.17605120, grad/param norm = 1.8389e-01, time/batch = 17.9756s	
9142/26050 (epoch 17.547), train_loss = 1.10584415, grad/param norm = 1.7210e-01, time/batch = 18.0693s	
9143/26050 (epoch 17.549), train_loss = 0.91219950, grad/param norm = 1.6315e-01, time/batch = 18.3094s	
9144/26050 (epoch 17.551), train_loss = 1.16731477, grad/param norm = 1.7779e-01, time/batch = 16.7916s	
9145/26050 (epoch 17.553), train_loss = 1.03338195, grad/param norm = 1.6846e-01, time/batch = 16.8853s	
9146/26050 (epoch 17.555), train_loss = 1.04512681, grad/param norm = 1.7223e-01, time/batch = 17.8866s	
9147/26050 (epoch 17.557), train_loss = 1.16675232, grad/param norm = 1.7372e-01, time/batch = 17.8044s	
9148/26050 (epoch 17.559), train_loss = 1.09893361, grad/param norm = 1.6466e-01, time/batch = 19.0660s	
9149/26050 (epoch 17.560), train_loss = 1.07434053, grad/param norm = 1.7016e-01, time/batch = 17.7510s	
9150/26050 (epoch 17.562), train_loss = 1.08347830, grad/param norm = 1.7022e-01, time/batch = 18.1598s	
9151/26050 (epoch 17.564), train_loss = 1.29248086, grad/param norm = 1.7567e-01, time/batch = 18.5707s	
9152/26050 (epoch 17.566), train_loss = 1.01849267, grad/param norm = 1.7412e-01, time/batch = 18.2349s	
9153/26050 (epoch 17.568), train_loss = 1.13643946, grad/param norm = 1.6738e-01, time/batch = 14.8950s	
9154/26050 (epoch 17.570), train_loss = 1.20490263, grad/param norm = 1.8160e-01, time/batch = 17.7087s	
9155/26050 (epoch 17.572), train_loss = 1.08237446, grad/param norm = 1.8302e-01, time/batch = 18.3073s	
9156/26050 (epoch 17.574), train_loss = 1.17601703, grad/param norm = 1.9878e-01, time/batch = 18.5674s	
9157/26050 (epoch 17.576), train_loss = 1.13974350, grad/param norm = 1.9042e-01, time/batch = 15.6342s	
9158/26050 (epoch 17.578), train_loss = 1.07870076, grad/param norm = 1.7922e-01, time/batch = 17.3125s	
9159/26050 (epoch 17.580), train_loss = 1.02759383, grad/param norm = 1.8531e-01, time/batch = 17.0861s	
9160/26050 (epoch 17.582), train_loss = 1.14540883, grad/param norm = 1.6889e-01, time/batch = 18.3948s	
9161/26050 (epoch 17.583), train_loss = 1.21585460, grad/param norm = 1.7549e-01, time/batch = 16.3033s	
9162/26050 (epoch 17.585), train_loss = 0.98787577, grad/param norm = 1.8022e-01, time/batch = 18.1574s	
9163/26050 (epoch 17.587), train_loss = 1.14610740, grad/param norm = 1.8745e-01, time/batch = 18.0728s	
9164/26050 (epoch 17.589), train_loss = 1.26215841, grad/param norm = 2.0150e-01, time/batch = 16.4849s	
9165/26050 (epoch 17.591), train_loss = 1.09358766, grad/param norm = 1.6203e-01, time/batch = 18.7322s	
9166/26050 (epoch 17.593), train_loss = 0.98638837, grad/param norm = 1.7268e-01, time/batch = 18.3274s	
9167/26050 (epoch 17.595), train_loss = 1.19999732, grad/param norm = 2.0073e-01, time/batch = 18.3098s	
9168/26050 (epoch 17.597), train_loss = 1.14115018, grad/param norm = 1.6913e-01, time/batch = 18.0769s	
9169/26050 (epoch 17.599), train_loss = 1.10541817, grad/param norm = 1.8312e-01, time/batch = 16.3840s	
9170/26050 (epoch 17.601), train_loss = 1.29832505, grad/param norm = 1.8257e-01, time/batch = 18.6603s	
9171/26050 (epoch 17.603), train_loss = 1.15204978, grad/param norm = 1.8034e-01, time/batch = 15.5531s	
9172/26050 (epoch 17.605), train_loss = 1.04910397, grad/param norm = 1.6869e-01, time/batch = 17.8876s	
9173/26050 (epoch 17.607), train_loss = 1.22120507, grad/param norm = 1.9144e-01, time/batch = 15.1397s	
9174/26050 (epoch 17.608), train_loss = 0.97561427, grad/param norm = 1.5129e-01, time/batch = 17.8138s	
9175/26050 (epoch 17.610), train_loss = 1.09107980, grad/param norm = 1.9434e-01, time/batch = 17.9850s	
9176/26050 (epoch 17.612), train_loss = 1.12385183, grad/param norm = 1.8221e-01, time/batch = 18.3085s	
9177/26050 (epoch 17.614), train_loss = 1.16782840, grad/param norm = 1.8635e-01, time/batch = 18.2239s	
9178/26050 (epoch 17.616), train_loss = 1.28251162, grad/param norm = 1.9404e-01, time/batch = 14.7172s	
9179/26050 (epoch 17.618), train_loss = 1.07344967, grad/param norm = 1.9382e-01, time/batch = 16.4716s	
9180/26050 (epoch 17.620), train_loss = 1.13638769, grad/param norm = 1.7957e-01, time/batch = 18.6561s	
9181/26050 (epoch 17.622), train_loss = 0.97377641, grad/param norm = 1.5807e-01, time/batch = 16.8835s	
9182/26050 (epoch 17.624), train_loss = 0.98250921, grad/param norm = 1.6433e-01, time/batch = 13.9312s	
9183/26050 (epoch 17.626), train_loss = 1.16084750, grad/param norm = 1.7810e-01, time/batch = 13.9276s	
9184/26050 (epoch 17.628), train_loss = 1.03779661, grad/param norm = 1.8476e-01, time/batch = 18.0621s	
9185/26050 (epoch 17.630), train_loss = 1.22192865, grad/param norm = 2.0078e-01, time/batch = 17.5831s	
9186/26050 (epoch 17.631), train_loss = 1.27120693, grad/param norm = 1.8747e-01, time/batch = 18.5665s	
9187/26050 (epoch 17.633), train_loss = 1.02170335, grad/param norm = 1.6998e-01, time/batch = 17.8110s	
9188/26050 (epoch 17.635), train_loss = 1.03088166, grad/param norm = 1.5278e-01, time/batch = 15.6244s	
9189/26050 (epoch 17.637), train_loss = 0.99644450, grad/param norm = 1.7612e-01, time/batch = 18.1462s	
9190/26050 (epoch 17.639), train_loss = 1.21490910, grad/param norm = 1.7662e-01, time/batch = 17.6356s	
9191/26050 (epoch 17.641), train_loss = 1.06886419, grad/param norm = 1.6104e-01, time/batch = 18.3155s	
9192/26050 (epoch 17.643), train_loss = 0.98176296, grad/param norm = 1.5463e-01, time/batch = 17.4558s	
9193/26050 (epoch 17.645), train_loss = 1.12674111, grad/param norm = 1.8664e-01, time/batch = 15.1139s	
9194/26050 (epoch 17.647), train_loss = 1.05622507, grad/param norm = 1.7123e-01, time/batch = 17.8165s	
9195/26050 (epoch 17.649), train_loss = 1.13446570, grad/param norm = 2.3494e-01, time/batch = 17.9646s	
9196/26050 (epoch 17.651), train_loss = 1.04197105, grad/param norm = 2.0466e-01, time/batch = 15.3960s	
9197/26050 (epoch 17.653), train_loss = 1.13259222, grad/param norm = 1.8485e-01, time/batch = 18.3927s	
9198/26050 (epoch 17.655), train_loss = 1.03133213, grad/param norm = 1.6866e-01, time/batch = 18.4189s	
9199/26050 (epoch 17.656), train_loss = 0.94840081, grad/param norm = 1.7384e-01, time/batch = 18.0515s	
9200/26050 (epoch 17.658), train_loss = 1.28239986, grad/param norm = 1.8161e-01, time/batch = 17.4844s	
9201/26050 (epoch 17.660), train_loss = 0.97864454, grad/param norm = 1.7247e-01, time/batch = 18.8101s	
9202/26050 (epoch 17.662), train_loss = 1.00676071, grad/param norm = 1.6646e-01, time/batch = 17.3092s	
9203/26050 (epoch 17.664), train_loss = 1.08924031, grad/param norm = 1.8001e-01, time/batch = 18.2376s	
9204/26050 (epoch 17.666), train_loss = 1.08774939, grad/param norm = 1.9311e-01, time/batch = 18.3196s	
9205/26050 (epoch 17.668), train_loss = 0.92356776, grad/param norm = 1.7802e-01, time/batch = 16.8928s	
9206/26050 (epoch 17.670), train_loss = 1.25472031, grad/param norm = 1.9400e-01, time/batch = 16.3959s	
9207/26050 (epoch 17.672), train_loss = 1.05435447, grad/param norm = 1.8355e-01, time/batch = 16.0637s	
9208/26050 (epoch 17.674), train_loss = 1.00702385, grad/param norm = 1.7391e-01, time/batch = 18.3911s	
9209/26050 (epoch 17.676), train_loss = 1.14152138, grad/param norm = 1.8695e-01, time/batch = 17.3052s	
9210/26050 (epoch 17.678), train_loss = 1.21359433, grad/param norm = 1.9207e-01, time/batch = 16.9857s	
9211/26050 (epoch 17.679), train_loss = 1.30760870, grad/param norm = 2.0658e-01, time/batch = 15.3834s	
9212/26050 (epoch 17.681), train_loss = 1.12100211, grad/param norm = 1.7820e-01, time/batch = 16.9581s	
9213/26050 (epoch 17.683), train_loss = 0.99534430, grad/param norm = 2.0082e-01, time/batch = 18.5725s	
9214/26050 (epoch 17.685), train_loss = 1.04758357, grad/param norm = 1.6307e-01, time/batch = 17.6572s	
9215/26050 (epoch 17.687), train_loss = 0.92878616, grad/param norm = 1.6821e-01, time/batch = 18.1562s	
9216/26050 (epoch 17.689), train_loss = 1.07959884, grad/param norm = 1.8678e-01, time/batch = 17.3978s	
9217/26050 (epoch 17.691), train_loss = 0.85471344, grad/param norm = 1.4880e-01, time/batch = 16.9731s	
9218/26050 (epoch 17.693), train_loss = 0.99947290, grad/param norm = 1.7273e-01, time/batch = 18.1455s	
9219/26050 (epoch 17.695), train_loss = 1.08763273, grad/param norm = 1.6980e-01, time/batch = 16.2947s	
9220/26050 (epoch 17.697), train_loss = 0.99904966, grad/param norm = 1.6956e-01, time/batch = 17.9079s	
9221/26050 (epoch 17.699), train_loss = 1.16031626, grad/param norm = 1.9106e-01, time/batch = 17.4960s	
9222/26050 (epoch 17.701), train_loss = 0.98603728, grad/param norm = 1.7234e-01, time/batch = 16.5046s	
9223/26050 (epoch 17.702), train_loss = 1.22581111, grad/param norm = 1.8209e-01, time/batch = 18.1594s	
9224/26050 (epoch 17.704), train_loss = 1.16973969, grad/param norm = 1.6471e-01, time/batch = 17.4955s	
9225/26050 (epoch 17.706), train_loss = 1.09876853, grad/param norm = 2.0354e-01, time/batch = 15.5701s	
9226/26050 (epoch 17.708), train_loss = 1.21002161, grad/param norm = 1.9773e-01, time/batch = 17.5640s	
9227/26050 (epoch 17.710), train_loss = 1.16892742, grad/param norm = 1.8347e-01, time/batch = 18.3115s	
9228/26050 (epoch 17.712), train_loss = 1.18931181, grad/param norm = 1.9686e-01, time/batch = 14.4723s	
9229/26050 (epoch 17.714), train_loss = 0.93924411, grad/param norm = 1.6474e-01, time/batch = 17.8203s	
9230/26050 (epoch 17.716), train_loss = 1.33992861, grad/param norm = 1.9439e-01, time/batch = 17.1271s	
9231/26050 (epoch 17.718), train_loss = 1.20592389, grad/param norm = 1.9051e-01, time/batch = 18.6559s	
9232/26050 (epoch 17.720), train_loss = 1.07947403, grad/param norm = 1.8003e-01, time/batch = 17.9798s	
9233/26050 (epoch 17.722), train_loss = 0.97732028, grad/param norm = 1.6988e-01, time/batch = 17.4934s	
9234/26050 (epoch 17.724), train_loss = 1.02441665, grad/param norm = 1.8657e-01, time/batch = 17.3126s	
9235/26050 (epoch 17.726), train_loss = 1.20194058, grad/param norm = 1.8518e-01, time/batch = 16.8062s	
9236/26050 (epoch 17.727), train_loss = 1.20729644, grad/param norm = 1.8871e-01, time/batch = 18.0547s	
9237/26050 (epoch 17.729), train_loss = 1.14244610, grad/param norm = 1.8092e-01, time/batch = 18.0596s	
9238/26050 (epoch 17.731), train_loss = 1.13860679, grad/param norm = 1.7963e-01, time/batch = 15.4841s	
9239/26050 (epoch 17.733), train_loss = 1.06874607, grad/param norm = 2.1739e-01, time/batch = 18.7320s	
9240/26050 (epoch 17.735), train_loss = 1.28856405, grad/param norm = 1.8438e-01, time/batch = 17.3276s	
9241/26050 (epoch 17.737), train_loss = 1.06403222, grad/param norm = 1.8114e-01, time/batch = 18.1628s	
9242/26050 (epoch 17.739), train_loss = 1.15229267, grad/param norm = 1.8296e-01, time/batch = 17.8123s	
9243/26050 (epoch 17.741), train_loss = 1.02856071, grad/param norm = 1.8426e-01, time/batch = 19.2599s	
9244/26050 (epoch 17.743), train_loss = 1.14121465, grad/param norm = 2.5046e-01, time/batch = 30.2444s	
9245/26050 (epoch 17.745), train_loss = 0.97100466, grad/param norm = 1.6817e-01, time/batch = 21.0874s	
9246/26050 (epoch 17.747), train_loss = 1.00010206, grad/param norm = 1.5937e-01, time/batch = 16.8145s	
9247/26050 (epoch 17.749), train_loss = 1.23911595, grad/param norm = 1.9193e-01, time/batch = 18.4826s	
9248/26050 (epoch 17.750), train_loss = 1.08259068, grad/param norm = 1.6390e-01, time/batch = 18.1543s	
9249/26050 (epoch 17.752), train_loss = 1.06735666, grad/param norm = 1.9457e-01, time/batch = 15.3893s	
9250/26050 (epoch 17.754), train_loss = 1.12048716, grad/param norm = 1.8429e-01, time/batch = 17.8901s	
9251/26050 (epoch 17.756), train_loss = 1.10846737, grad/param norm = 1.9095e-01, time/batch = 16.1459s	
9252/26050 (epoch 17.758), train_loss = 1.10002430, grad/param norm = 1.8226e-01, time/batch = 17.9928s	
9253/26050 (epoch 17.760), train_loss = 1.26312077, grad/param norm = 1.8728e-01, time/batch = 18.1519s	
9254/26050 (epoch 17.762), train_loss = 1.04018692, grad/param norm = 1.8003e-01, time/batch = 18.7280s	
9255/26050 (epoch 17.764), train_loss = 1.13582714, grad/param norm = 1.8594e-01, time/batch = 18.8237s	
9256/26050 (epoch 17.766), train_loss = 1.19117751, grad/param norm = 1.9919e-01, time/batch = 17.6221s	
9257/26050 (epoch 17.768), train_loss = 1.00522367, grad/param norm = 1.6378e-01, time/batch = 17.5468s	
9258/26050 (epoch 17.770), train_loss = 1.07796202, grad/param norm = 1.7623e-01, time/batch = 18.4122s	
9259/26050 (epoch 17.772), train_loss = 1.09007748, grad/param norm = 1.6690e-01, time/batch = 14.9752s	
9260/26050 (epoch 17.774), train_loss = 0.95928779, grad/param norm = 1.6953e-01, time/batch = 18.3753s	
9261/26050 (epoch 17.775), train_loss = 0.79063095, grad/param norm = 1.5190e-01, time/batch = 17.9726s	
9262/26050 (epoch 17.777), train_loss = 1.02813272, grad/param norm = 1.6652e-01, time/batch = 14.8009s	
9263/26050 (epoch 17.779), train_loss = 1.06995570, grad/param norm = 1.8565e-01, time/batch = 18.1496s	
9264/26050 (epoch 17.781), train_loss = 1.00417524, grad/param norm = 1.6800e-01, time/batch = 18.5665s	
9265/26050 (epoch 17.783), train_loss = 0.98941693, grad/param norm = 1.7304e-01, time/batch = 18.6614s	
9266/26050 (epoch 17.785), train_loss = 1.07609995, grad/param norm = 1.6845e-01, time/batch = 17.1717s	
9267/26050 (epoch 17.787), train_loss = 1.02783625, grad/param norm = 1.8162e-01, time/batch = 16.2974s	
9268/26050 (epoch 17.789), train_loss = 1.03115194, grad/param norm = 2.0340e-01, time/batch = 18.0703s	
9269/26050 (epoch 17.791), train_loss = 1.06253101, grad/param norm = 1.7956e-01, time/batch = 17.7319s	
9270/26050 (epoch 17.793), train_loss = 1.06312265, grad/param norm = 1.9290e-01, time/batch = 17.4720s	
9271/26050 (epoch 17.795), train_loss = 0.90928659, grad/param norm = 1.5427e-01, time/batch = 16.7972s	
9272/26050 (epoch 17.797), train_loss = 0.99766792, grad/param norm = 1.5603e-01, time/batch = 18.6569s	
9273/26050 (epoch 17.798), train_loss = 0.92822735, grad/param norm = 1.6712e-01, time/batch = 17.0620s	
9274/26050 (epoch 17.800), train_loss = 0.93144089, grad/param norm = 1.4482e-01, time/batch = 15.6299s	
9275/26050 (epoch 17.802), train_loss = 1.02934642, grad/param norm = 1.8241e-01, time/batch = 15.5463s	
9276/26050 (epoch 17.804), train_loss = 1.06056179, grad/param norm = 1.7170e-01, time/batch = 17.1648s	
9277/26050 (epoch 17.806), train_loss = 1.18138500, grad/param norm = 1.8650e-01, time/batch = 3.7498s	
9278/26050 (epoch 17.808), train_loss = 1.08745424, grad/param norm = 1.7975e-01, time/batch = 0.6407s	
9279/26050 (epoch 17.810), train_loss = 1.01504894, grad/param norm = 1.7986e-01, time/batch = 0.6415s	
9280/26050 (epoch 17.812), train_loss = 0.98643659, grad/param norm = 1.8563e-01, time/batch = 0.6517s	
9281/26050 (epoch 17.814), train_loss = 0.97190228, grad/param norm = 1.9250e-01, time/batch = 0.6450s	
9282/26050 (epoch 17.816), train_loss = 1.19867376, grad/param norm = 1.9055e-01, time/batch = 0.6459s	
9283/26050 (epoch 17.818), train_loss = 1.21483079, grad/param norm = 2.1772e-01, time/batch = 0.6440s	
9284/26050 (epoch 17.820), train_loss = 1.10642119, grad/param norm = 1.8142e-01, time/batch = 0.6776s	
9285/26050 (epoch 17.821), train_loss = 1.24251718, grad/param norm = 2.0070e-01, time/batch = 0.9399s	
9286/26050 (epoch 17.823), train_loss = 1.25704183, grad/param norm = 1.9873e-01, time/batch = 0.9403s	
9287/26050 (epoch 17.825), train_loss = 1.08248755, grad/param norm = 1.8784e-01, time/batch = 0.9303s	
9288/26050 (epoch 17.827), train_loss = 1.10075327, grad/param norm = 2.0716e-01, time/batch = 0.9397s	
9289/26050 (epoch 17.829), train_loss = 1.16054240, grad/param norm = 1.8758e-01, time/batch = 0.9421s	
9290/26050 (epoch 17.831), train_loss = 1.21454020, grad/param norm = 1.8446e-01, time/batch = 1.5920s	
9291/26050 (epoch 17.833), train_loss = 1.29937667, grad/param norm = 1.8936e-01, time/batch = 1.7902s	
9292/26050 (epoch 17.835), train_loss = 1.28994578, grad/param norm = 1.9410e-01, time/batch = 2.6732s	
9293/26050 (epoch 17.837), train_loss = 1.08988036, grad/param norm = 1.7587e-01, time/batch = 17.9084s	
9294/26050 (epoch 17.839), train_loss = 1.12544714, grad/param norm = 2.0831e-01, time/batch = 14.6556s	
9295/26050 (epoch 17.841), train_loss = 1.20715266, grad/param norm = 1.8354e-01, time/batch = 15.9645s	
9296/26050 (epoch 17.843), train_loss = 1.10082164, grad/param norm = 1.7410e-01, time/batch = 18.8924s	
9297/26050 (epoch 17.845), train_loss = 1.02113079, grad/param norm = 1.5658e-01, time/batch = 17.9069s	
9298/26050 (epoch 17.846), train_loss = 1.19569760, grad/param norm = 1.7318e-01, time/batch = 17.2353s	
9299/26050 (epoch 17.848), train_loss = 1.09411836, grad/param norm = 1.7844e-01, time/batch = 17.8185s	
9300/26050 (epoch 17.850), train_loss = 0.99732882, grad/param norm = 1.6342e-01, time/batch = 17.7499s	
9301/26050 (epoch 17.852), train_loss = 1.07283388, grad/param norm = 1.7870e-01, time/batch = 18.2320s	
9302/26050 (epoch 17.854), train_loss = 1.07443419, grad/param norm = 1.7224e-01, time/batch = 15.7992s	
9303/26050 (epoch 17.856), train_loss = 1.05241284, grad/param norm = 1.8305e-01, time/batch = 18.2348s	
9304/26050 (epoch 17.858), train_loss = 0.99322194, grad/param norm = 1.7354e-01, time/batch = 18.7505s	
9305/26050 (epoch 17.860), train_loss = 1.12391827, grad/param norm = 1.8902e-01, time/batch = 17.8002s	
9306/26050 (epoch 17.862), train_loss = 1.13529139, grad/param norm = 1.7396e-01, time/batch = 18.2193s	
9307/26050 (epoch 17.864), train_loss = 1.13564213, grad/param norm = 2.1303e-01, time/batch = 18.1397s	
9308/26050 (epoch 17.866), train_loss = 1.03697260, grad/param norm = 1.6976e-01, time/batch = 16.8848s	
9309/26050 (epoch 17.868), train_loss = 1.15171197, grad/param norm = 1.8980e-01, time/batch = 17.5638s	
9310/26050 (epoch 17.869), train_loss = 0.98237187, grad/param norm = 1.6071e-01, time/batch = 18.0945s	
9311/26050 (epoch 17.871), train_loss = 0.92164737, grad/param norm = 1.6636e-01, time/batch = 17.1554s	
9312/26050 (epoch 17.873), train_loss = 1.14406742, grad/param norm = 1.8769e-01, time/batch = 14.4748s	
9313/26050 (epoch 17.875), train_loss = 1.08200304, grad/param norm = 1.8301e-01, time/batch = 17.9865s	
9314/26050 (epoch 17.877), train_loss = 0.98309463, grad/param norm = 1.6873e-01, time/batch = 17.9899s	
9315/26050 (epoch 17.879), train_loss = 1.12743703, grad/param norm = 1.7117e-01, time/batch = 15.7798s	
9316/26050 (epoch 17.881), train_loss = 1.22067890, grad/param norm = 1.8673e-01, time/batch = 16.8054s	
9317/26050 (epoch 17.883), train_loss = 1.14197732, grad/param norm = 1.8506e-01, time/batch = 17.4719s	
9318/26050 (epoch 17.885), train_loss = 0.83290951, grad/param norm = 1.5982e-01, time/batch = 18.6487s	
9319/26050 (epoch 17.887), train_loss = 1.12902437, grad/param norm = 1.7659e-01, time/batch = 18.0624s	
9320/26050 (epoch 17.889), train_loss = 1.04301756, grad/param norm = 1.6182e-01, time/batch = 18.1425s	
9321/26050 (epoch 17.891), train_loss = 0.87981135, grad/param norm = 1.5463e-01, time/batch = 17.7396s	
9322/26050 (epoch 17.893), train_loss = 0.94383935, grad/param norm = 1.6843e-01, time/batch = 17.3301s	
9323/26050 (epoch 17.894), train_loss = 1.05135623, grad/param norm = 1.7806e-01, time/batch = 18.6451s	
9324/26050 (epoch 17.896), train_loss = 1.18359484, grad/param norm = 1.7038e-01, time/batch = 16.8973s	
9325/26050 (epoch 17.898), train_loss = 1.02380019, grad/param norm = 1.8292e-01, time/batch = 15.3673s	
9326/26050 (epoch 17.900), train_loss = 1.13427317, grad/param norm = 1.7570e-01, time/batch = 16.3620s	
9327/26050 (epoch 17.902), train_loss = 1.07776102, grad/param norm = 1.7567e-01, time/batch = 17.3881s	
9328/26050 (epoch 17.904), train_loss = 1.07737792, grad/param norm = 1.7365e-01, time/batch = 17.0482s	
9329/26050 (epoch 17.906), train_loss = 1.07568193, grad/param norm = 1.8743e-01, time/batch = 17.3916s	
9330/26050 (epoch 17.908), train_loss = 1.06631443, grad/param norm = 1.6741e-01, time/batch = 18.4864s	
9331/26050 (epoch 17.910), train_loss = 1.01242174, grad/param norm = 1.6190e-01, time/batch = 18.3847s	
9332/26050 (epoch 17.912), train_loss = 1.31349466, grad/param norm = 2.0499e-01, time/batch = 17.4129s	
9333/26050 (epoch 17.914), train_loss = 1.44916251, grad/param norm = 2.1028e-01, time/batch = 17.2812s	
9334/26050 (epoch 17.916), train_loss = 1.18145256, grad/param norm = 1.8610e-01, time/batch = 17.7427s	
9335/26050 (epoch 17.917), train_loss = 1.12105080, grad/param norm = 2.0797e-01, time/batch = 16.8747s	
9336/26050 (epoch 17.919), train_loss = 1.17939655, grad/param norm = 2.0306e-01, time/batch = 16.3848s	
9337/26050 (epoch 17.921), train_loss = 1.03776618, grad/param norm = 1.8107e-01, time/batch = 16.5577s	
9338/26050 (epoch 17.923), train_loss = 1.11714198, grad/param norm = 1.8967e-01, time/batch = 18.8032s	
9339/26050 (epoch 17.925), train_loss = 1.09404520, grad/param norm = 1.7191e-01, time/batch = 17.1523s	
9340/26050 (epoch 17.927), train_loss = 0.95562963, grad/param norm = 1.4628e-01, time/batch = 18.2266s	
9341/26050 (epoch 17.929), train_loss = 0.97548638, grad/param norm = 1.7666e-01, time/batch = 17.6549s	
9342/26050 (epoch 17.931), train_loss = 1.28355033, grad/param norm = 2.0577e-01, time/batch = 18.4891s	
9343/26050 (epoch 17.933), train_loss = 1.04896840, grad/param norm = 1.7499e-01, time/batch = 17.3985s	
9344/26050 (epoch 17.935), train_loss = 1.07004261, grad/param norm = 1.8274e-01, time/batch = 18.3798s	
9345/26050 (epoch 17.937), train_loss = 1.18185271, grad/param norm = 1.7847e-01, time/batch = 17.6368s	
9346/26050 (epoch 17.939), train_loss = 0.99741781, grad/param norm = 1.5458e-01, time/batch = 16.4733s	
9347/26050 (epoch 17.940), train_loss = 1.07009079, grad/param norm = 1.5815e-01, time/batch = 18.2343s	
9348/26050 (epoch 17.942), train_loss = 1.09949819, grad/param norm = 1.7643e-01, time/batch = 18.4086s	
9349/26050 (epoch 17.944), train_loss = 1.02954732, grad/param norm = 1.6601e-01, time/batch = 17.9040s	
9350/26050 (epoch 17.946), train_loss = 1.21771803, grad/param norm = 1.8529e-01, time/batch = 15.3812s	
9351/26050 (epoch 17.948), train_loss = 0.97121690, grad/param norm = 1.8743e-01, time/batch = 18.4114s	
9352/26050 (epoch 17.950), train_loss = 1.06722803, grad/param norm = 1.8871e-01, time/batch = 18.3890s	
9353/26050 (epoch 17.952), train_loss = 1.21215201, grad/param norm = 2.0345e-01, time/batch = 17.4918s	
9354/26050 (epoch 17.954), train_loss = 1.18706954, grad/param norm = 1.7824e-01, time/batch = 17.8161s	
9355/26050 (epoch 17.956), train_loss = 1.08341771, grad/param norm = 1.8452e-01, time/batch = 18.4754s	
9356/26050 (epoch 17.958), train_loss = 1.02667806, grad/param norm = 1.6762e-01, time/batch = 18.1317s	
9357/26050 (epoch 17.960), train_loss = 1.08954726, grad/param norm = 1.8499e-01, time/batch = 18.1551s	
9358/26050 (epoch 17.962), train_loss = 1.00598098, grad/param norm = 1.5521e-01, time/batch = 17.4940s	
9359/26050 (epoch 17.964), train_loss = 1.07764983, grad/param norm = 1.8174e-01, time/batch = 15.3878s	
9360/26050 (epoch 17.965), train_loss = 1.00612406, grad/param norm = 1.6807e-01, time/batch = 15.1485s	
9361/26050 (epoch 17.967), train_loss = 1.41479106, grad/param norm = 1.9343e-01, time/batch = 17.9801s	
9362/26050 (epoch 17.969), train_loss = 1.06205102, grad/param norm = 1.7339e-01, time/batch = 16.9945s	
9363/26050 (epoch 17.971), train_loss = 1.03574812, grad/param norm = 1.5740e-01, time/batch = 17.0496s	
9364/26050 (epoch 17.973), train_loss = 1.06616727, grad/param norm = 1.9026e-01, time/batch = 19.0563s	
9365/26050 (epoch 17.975), train_loss = 1.13628914, grad/param norm = 1.7024e-01, time/batch = 17.2434s	
9366/26050 (epoch 17.977), train_loss = 1.12362402, grad/param norm = 1.6104e-01, time/batch = 18.0582s	
9367/26050 (epoch 17.979), train_loss = 0.91856148, grad/param norm = 1.6676e-01, time/batch = 18.7310s	
9368/26050 (epoch 17.981), train_loss = 1.22068493, grad/param norm = 1.6908e-01, time/batch = 15.7205s	
9369/26050 (epoch 17.983), train_loss = 1.16762518, grad/param norm = 1.7801e-01, time/batch = 18.4656s	
9370/26050 (epoch 17.985), train_loss = 1.13504810, grad/param norm = 1.7963e-01, time/batch = 17.5696s	
9371/26050 (epoch 17.987), train_loss = 1.20113506, grad/param norm = 1.6961e-01, time/batch = 18.4932s	
9372/26050 (epoch 17.988), train_loss = 1.18276465, grad/param norm = 1.7648e-01, time/batch = 18.4950s	
9373/26050 (epoch 17.990), train_loss = 0.96527165, grad/param norm = 1.4961e-01, time/batch = 17.2972s	
9374/26050 (epoch 17.992), train_loss = 1.24146291, grad/param norm = 1.8871e-01, time/batch = 15.4743s	
9375/26050 (epoch 17.994), train_loss = 1.06455795, grad/param norm = 1.8441e-01, time/batch = 17.4047s	
9376/26050 (epoch 17.996), train_loss = 1.04797485, grad/param norm = 1.9281e-01, time/batch = 16.3172s	
9377/26050 (epoch 17.998), train_loss = 1.10124955, grad/param norm = 1.6910e-01, time/batch = 16.6316s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
9378/26050 (epoch 18.000), train_loss = 1.03674574, grad/param norm = 1.8916e-01, time/batch = 18.1423s	
9379/26050 (epoch 18.002), train_loss = 1.17127179, grad/param norm = 2.0334e-01, time/batch = 18.1508s	
9380/26050 (epoch 18.004), train_loss = 1.00038258, grad/param norm = 1.7761e-01, time/batch = 18.0749s	
9381/26050 (epoch 18.006), train_loss = 1.02792889, grad/param norm = 1.8319e-01, time/batch = 17.8884s	
9382/26050 (epoch 18.008), train_loss = 1.00043291, grad/param norm = 1.9181e-01, time/batch = 16.0381s	
9383/26050 (epoch 18.010), train_loss = 1.01447972, grad/param norm = 1.6908e-01, time/batch = 17.6516s	
9384/26050 (epoch 18.012), train_loss = 1.10409271, grad/param norm = 1.7444e-01, time/batch = 17.3018s	
9385/26050 (epoch 18.013), train_loss = 1.41910102, grad/param norm = 2.1691e-01, time/batch = 17.8234s	
9386/26050 (epoch 18.015), train_loss = 1.03212546, grad/param norm = 1.5458e-01, time/batch = 18.2279s	
9387/26050 (epoch 18.017), train_loss = 1.10662979, grad/param norm = 1.7599e-01, time/batch = 17.3121s	
9388/26050 (epoch 18.019), train_loss = 0.92780563, grad/param norm = 1.5424e-01, time/batch = 17.6706s	
9389/26050 (epoch 18.021), train_loss = 1.15389193, grad/param norm = 1.7262e-01, time/batch = 14.4724s	
9390/26050 (epoch 18.023), train_loss = 0.92723456, grad/param norm = 1.8213e-01, time/batch = 18.1592s	
9391/26050 (epoch 18.025), train_loss = 1.08466323, grad/param norm = 1.7457e-01, time/batch = 17.8147s	
9392/26050 (epoch 18.027), train_loss = 0.87887357, grad/param norm = 1.6918e-01, time/batch = 17.3099s	
9393/26050 (epoch 18.029), train_loss = 1.10949891, grad/param norm = 1.6730e-01, time/batch = 17.0555s	
9394/26050 (epoch 18.031), train_loss = 1.22562722, grad/param norm = 2.2103e-01, time/batch = 15.3767s	
9395/26050 (epoch 18.033), train_loss = 1.12651111, grad/param norm = 1.8775e-01, time/batch = 17.2354s	
9396/26050 (epoch 18.035), train_loss = 1.13903583, grad/param norm = 1.7655e-01, time/batch = 17.5078s	
9397/26050 (epoch 18.036), train_loss = 0.99851764, grad/param norm = 1.8999e-01, time/batch = 17.7335s	
9398/26050 (epoch 18.038), train_loss = 0.90310533, grad/param norm = 1.6101e-01, time/batch = 18.0726s	
9399/26050 (epoch 18.040), train_loss = 1.09715074, grad/param norm = 1.9726e-01, time/batch = 17.4993s	
9400/26050 (epoch 18.042), train_loss = 0.93005822, grad/param norm = 1.6297e-01, time/batch = 18.7370s	
9401/26050 (epoch 18.044), train_loss = 1.17197897, grad/param norm = 1.6737e-01, time/batch = 17.4083s	
9402/26050 (epoch 18.046), train_loss = 0.86225966, grad/param norm = 1.3752e-01, time/batch = 18.4697s	
9403/26050 (epoch 18.048), train_loss = 1.10035861, grad/param norm = 1.7584e-01, time/batch = 17.8205s	
9404/26050 (epoch 18.050), train_loss = 1.00176123, grad/param norm = 1.6519e-01, time/batch = 17.3221s	
9405/26050 (epoch 18.052), train_loss = 1.03449728, grad/param norm = 1.9305e-01, time/batch = 15.8560s	
9406/26050 (epoch 18.054), train_loss = 0.92095995, grad/param norm = 1.5637e-01, time/batch = 14.3893s	
9407/26050 (epoch 18.056), train_loss = 0.87227509, grad/param norm = 1.4752e-01, time/batch = 17.8866s	
9408/26050 (epoch 18.058), train_loss = 1.04477942, grad/param norm = 1.6960e-01, time/batch = 18.2337s	
9409/26050 (epoch 18.060), train_loss = 1.12941436, grad/param norm = 1.7841e-01, time/batch = 18.2278s	
9410/26050 (epoch 18.061), train_loss = 0.98914984, grad/param norm = 1.6786e-01, time/batch = 18.5497s	
9411/26050 (epoch 18.063), train_loss = 1.13018857, grad/param norm = 1.8152e-01, time/batch = 15.3820s	
9412/26050 (epoch 18.065), train_loss = 0.89153596, grad/param norm = 1.5266e-01, time/batch = 18.8064s	
9413/26050 (epoch 18.067), train_loss = 1.09839339, grad/param norm = 1.8994e-01, time/batch = 16.4819s	
9414/26050 (epoch 18.069), train_loss = 1.13890164, grad/param norm = 1.8248e-01, time/batch = 14.9776s	
9415/26050 (epoch 18.071), train_loss = 1.14503911, grad/param norm = 1.7367e-01, time/batch = 16.0569s	
9416/26050 (epoch 18.073), train_loss = 1.26025525, grad/param norm = 1.9719e-01, time/batch = 18.2276s	
9417/26050 (epoch 18.075), train_loss = 1.00388818, grad/param norm = 1.7533e-01, time/batch = 18.0606s	
9418/26050 (epoch 18.077), train_loss = 0.99791016, grad/param norm = 1.6719e-01, time/batch = 17.1599s	
9419/26050 (epoch 18.079), train_loss = 1.11052469, grad/param norm = 1.8249e-01, time/batch = 18.8842s	
9420/26050 (epoch 18.081), train_loss = 1.04760891, grad/param norm = 1.9257e-01, time/batch = 18.0605s	
9421/26050 (epoch 18.083), train_loss = 1.14487600, grad/param norm = 1.6757e-01, time/batch = 18.3091s	
9422/26050 (epoch 18.084), train_loss = 1.09947255, grad/param norm = 1.9531e-01, time/batch = 16.7322s	
9423/26050 (epoch 18.086), train_loss = 1.23219984, grad/param norm = 1.9068e-01, time/batch = 15.7267s	
9424/26050 (epoch 18.088), train_loss = 0.97855207, grad/param norm = 1.7136e-01, time/batch = 18.3917s	
9425/26050 (epoch 18.090), train_loss = 1.11742740, grad/param norm = 1.8845e-01, time/batch = 16.0350s	
9426/26050 (epoch 18.092), train_loss = 1.13269238, grad/param norm = 1.7045e-01, time/batch = 16.9803s	
9427/26050 (epoch 18.094), train_loss = 1.02508367, grad/param norm = 1.6888e-01, time/batch = 17.4908s	
9428/26050 (epoch 18.096), train_loss = 1.06607272, grad/param norm = 1.6526e-01, time/batch = 17.7210s	
9429/26050 (epoch 18.098), train_loss = 1.03166090, grad/param norm = 1.7821e-01, time/batch = 18.2353s	
9430/26050 (epoch 18.100), train_loss = 0.96237041, grad/param norm = 1.7017e-01, time/batch = 17.9841s	
9431/26050 (epoch 18.102), train_loss = 1.10160032, grad/param norm = 1.7779e-01, time/batch = 18.4093s	
9432/26050 (epoch 18.104), train_loss = 1.09009419, grad/param norm = 1.9563e-01, time/batch = 18.1494s	
9433/26050 (epoch 18.106), train_loss = 1.08479804, grad/param norm = 1.9174e-01, time/batch = 18.3965s	
9434/26050 (epoch 18.107), train_loss = 0.86590620, grad/param norm = 1.5113e-01, time/batch = 17.5572s	
9435/26050 (epoch 18.109), train_loss = 1.00285416, grad/param norm = 1.7990e-01, time/batch = 16.3720s	
9436/26050 (epoch 18.111), train_loss = 1.25530459, grad/param norm = 1.9536e-01, time/batch = 16.9734s	
9437/26050 (epoch 18.113), train_loss = 1.02512408, grad/param norm = 1.7410e-01, time/batch = 15.6332s	
9438/26050 (epoch 18.115), train_loss = 1.17881426, grad/param norm = 1.7398e-01, time/batch = 17.8062s	
9439/26050 (epoch 18.117), train_loss = 1.10465164, grad/param norm = 1.7064e-01, time/batch = 18.1449s	
9440/26050 (epoch 18.119), train_loss = 0.90508079, grad/param norm = 1.6158e-01, time/batch = 18.5615s	
9441/26050 (epoch 18.121), train_loss = 1.10673489, grad/param norm = 1.7342e-01, time/batch = 16.4655s	
9442/26050 (epoch 18.123), train_loss = 0.96853002, grad/param norm = 1.6325e-01, time/batch = 17.3154s	
9443/26050 (epoch 18.125), train_loss = 0.94357546, grad/param norm = 1.6998e-01, time/batch = 18.9048s	
9444/26050 (epoch 18.127), train_loss = 0.86286808, grad/param norm = 1.6274e-01, time/batch = 17.6489s	
9445/26050 (epoch 18.129), train_loss = 0.91922337, grad/param norm = 1.8179e-01, time/batch = 17.3072s	
9446/26050 (epoch 18.131), train_loss = 1.04539200, grad/param norm = 1.7214e-01, time/batch = 18.0728s	
9447/26050 (epoch 18.132), train_loss = 1.04184606, grad/param norm = 1.6707e-01, time/batch = 18.6649s	
9448/26050 (epoch 18.134), train_loss = 1.07698334, grad/param norm = 1.9844e-01, time/batch = 17.4038s	
9449/26050 (epoch 18.136), train_loss = 1.06678744, grad/param norm = 1.6901e-01, time/batch = 17.9780s	
9450/26050 (epoch 18.138), train_loss = 0.83544551, grad/param norm = 1.5993e-01, time/batch = 16.6359s	
9451/26050 (epoch 18.140), train_loss = 0.90067086, grad/param norm = 1.7416e-01, time/batch = 15.3052s	
9452/26050 (epoch 18.142), train_loss = 0.94411882, grad/param norm = 1.7161e-01, time/batch = 16.5781s	
9453/26050 (epoch 18.144), train_loss = 0.87248059, grad/param norm = 1.5801e-01, time/batch = 18.5741s	
9454/26050 (epoch 18.146), train_loss = 0.80511814, grad/param norm = 1.6099e-01, time/batch = 18.0798s	
9455/26050 (epoch 18.148), train_loss = 0.84727959, grad/param norm = 1.4556e-01, time/batch = 17.9849s	
9456/26050 (epoch 18.150), train_loss = 1.04043000, grad/param norm = 1.8445e-01, time/batch = 17.9925s	
9457/26050 (epoch 18.152), train_loss = 1.25353242, grad/param norm = 2.2424e-01, time/batch = 14.8070s	
9458/26050 (epoch 18.154), train_loss = 0.83885947, grad/param norm = 1.9188e-01, time/batch = 17.8067s	
9459/26050 (epoch 18.155), train_loss = 0.87923828, grad/param norm = 1.5656e-01, time/batch = 17.3165s	
9460/26050 (epoch 18.157), train_loss = 0.99195270, grad/param norm = 2.0472e-01, time/batch = 17.9134s	
9461/26050 (epoch 18.159), train_loss = 1.05590168, grad/param norm = 1.9070e-01, time/batch = 17.9790s	
9462/26050 (epoch 18.161), train_loss = 1.12017687, grad/param norm = 1.9305e-01, time/batch = 18.6295s	
9463/26050 (epoch 18.163), train_loss = 0.88563446, grad/param norm = 1.6727e-01, time/batch = 31.5066s	
9464/26050 (epoch 18.165), train_loss = 0.80493199, grad/param norm = 1.6243e-01, time/batch = 23.9775s	
9465/26050 (epoch 18.167), train_loss = 1.14302106, grad/param norm = 1.8341e-01, time/batch = 17.7418s	
9466/26050 (epoch 18.169), train_loss = 1.10346813, grad/param norm = 1.8538e-01, time/batch = 16.7971s	
9467/26050 (epoch 18.171), train_loss = 0.86292513, grad/param norm = 1.5416e-01, time/batch = 18.3245s	
9468/26050 (epoch 18.173), train_loss = 0.98300390, grad/param norm = 1.7384e-01, time/batch = 17.4655s	
9469/26050 (epoch 18.175), train_loss = 1.03122133, grad/param norm = 1.6797e-01, time/batch = 19.0702s	
9470/26050 (epoch 18.177), train_loss = 1.15483348, grad/param norm = 1.7219e-01, time/batch = 14.4819s	
9471/26050 (epoch 18.179), train_loss = 0.82976205, grad/param norm = 1.6021e-01, time/batch = 17.4720s	
9472/26050 (epoch 18.180), train_loss = 1.27621285, grad/param norm = 1.8810e-01, time/batch = 18.3137s	
9473/26050 (epoch 18.182), train_loss = 1.27392471, grad/param norm = 1.8942e-01, time/batch = 15.8845s	
9474/26050 (epoch 18.184), train_loss = 1.08379817, grad/param norm = 1.7438e-01, time/batch = 18.2306s	
9475/26050 (epoch 18.186), train_loss = 0.87805992, grad/param norm = 1.5443e-01, time/batch = 17.3184s	
9476/26050 (epoch 18.188), train_loss = 1.04269513, grad/param norm = 1.7882e-01, time/batch = 17.7423s	
9477/26050 (epoch 18.190), train_loss = 1.11299445, grad/param norm = 1.8086e-01, time/batch = 17.4872s	
9478/26050 (epoch 18.192), train_loss = 1.11407145, grad/param norm = 1.6823e-01, time/batch = 17.6490s	
9479/26050 (epoch 18.194), train_loss = 1.09706544, grad/param norm = 1.7611e-01, time/batch = 18.3262s	
9480/26050 (epoch 18.196), train_loss = 1.14874612, grad/param norm = 1.8291e-01, time/batch = 18.3974s	
9481/26050 (epoch 18.198), train_loss = 0.97873831, grad/param norm = 1.6449e-01, time/batch = 17.4919s	
9482/26050 (epoch 18.200), train_loss = 0.97122536, grad/param norm = 1.6693e-01, time/batch = 17.3976s	
9483/26050 (epoch 18.202), train_loss = 1.03803221, grad/param norm = 1.7448e-01, time/batch = 18.8996s	
9484/26050 (epoch 18.203), train_loss = 1.18294262, grad/param norm = 1.9657e-01, time/batch = 17.0776s	
9485/26050 (epoch 18.205), train_loss = 0.99688322, grad/param norm = 1.7056e-01, time/batch = 16.1272s	
9486/26050 (epoch 18.207), train_loss = 0.99227241, grad/param norm = 1.6265e-01, time/batch = 18.3999s	
9487/26050 (epoch 18.209), train_loss = 1.09070761, grad/param norm = 1.7525e-01, time/batch = 16.5450s	
9488/26050 (epoch 18.211), train_loss = 0.89116019, grad/param norm = 1.5430e-01, time/batch = 17.9951s	
9489/26050 (epoch 18.213), train_loss = 1.11416743, grad/param norm = 1.8383e-01, time/batch = 18.2364s	
9490/26050 (epoch 18.215), train_loss = 1.04720081, grad/param norm = 1.8945e-01, time/batch = 18.3061s	
9491/26050 (epoch 18.217), train_loss = 1.03637654, grad/param norm = 1.7421e-01, time/batch = 16.5442s	
9492/26050 (epoch 18.219), train_loss = 1.03802589, grad/param norm = 1.9158e-01, time/batch = 17.8804s	
9493/26050 (epoch 18.221), train_loss = 0.96107114, grad/param norm = 1.7740e-01, time/batch = 18.5421s	
9494/26050 (epoch 18.223), train_loss = 1.07753916, grad/param norm = 1.7274e-01, time/batch = 18.3866s	
9495/26050 (epoch 18.225), train_loss = 0.95222367, grad/param norm = 1.6746e-01, time/batch = 16.5650s	
9496/26050 (epoch 18.226), train_loss = 1.11090793, grad/param norm = 1.9192e-01, time/batch = 17.9759s	
9497/26050 (epoch 18.228), train_loss = 1.18594653, grad/param norm = 1.8408e-01, time/batch = 18.8117s	
9498/26050 (epoch 18.230), train_loss = 1.09684536, grad/param norm = 1.7516e-01, time/batch = 17.5762s	
9499/26050 (epoch 18.232), train_loss = 1.16937236, grad/param norm = 1.9536e-01, time/batch = 16.3951s	
9500/26050 (epoch 18.234), train_loss = 0.93844977, grad/param norm = 1.7280e-01, time/batch = 15.3109s	
9501/26050 (epoch 18.236), train_loss = 1.15358038, grad/param norm = 1.9434e-01, time/batch = 18.2273s	
9502/26050 (epoch 18.238), train_loss = 0.91155875, grad/param norm = 1.5978e-01, time/batch = 17.7285s	
9503/26050 (epoch 18.240), train_loss = 1.05989016, grad/param norm = 1.9674e-01, time/batch = 14.9644s	
9504/26050 (epoch 18.242), train_loss = 1.07132698, grad/param norm = 1.6945e-01, time/batch = 17.7354s	
9505/26050 (epoch 18.244), train_loss = 1.04629841, grad/param norm = 1.9717e-01, time/batch = 17.4042s	
9506/26050 (epoch 18.246), train_loss = 0.99794093, grad/param norm = 1.7146e-01, time/batch = 18.1373s	
9507/26050 (epoch 18.248), train_loss = 1.05920617, grad/param norm = 1.7337e-01, time/batch = 18.5691s	
9508/26050 (epoch 18.250), train_loss = 1.07418767, grad/param norm = 2.0843e-01, time/batch = 18.0764s	
9509/26050 (epoch 18.251), train_loss = 1.02582996, grad/param norm = 1.7143e-01, time/batch = 17.4015s	
9510/26050 (epoch 18.253), train_loss = 0.92552038, grad/param norm = 1.6493e-01, time/batch = 17.9991s	
9511/26050 (epoch 18.255), train_loss = 1.23682411, grad/param norm = 1.8664e-01, time/batch = 18.1387s	
9512/26050 (epoch 18.257), train_loss = 1.04705411, grad/param norm = 1.8273e-01, time/batch = 16.4852s	
9513/26050 (epoch 18.259), train_loss = 1.19916247, grad/param norm = 1.8641e-01, time/batch = 18.8917s	
9514/26050 (epoch 18.261), train_loss = 0.95416581, grad/param norm = 1.7837e-01, time/batch = 15.6403s	
9515/26050 (epoch 18.263), train_loss = 1.11199498, grad/param norm = 1.7967e-01, time/batch = 17.7286s	
9516/26050 (epoch 18.265), train_loss = 1.23217878, grad/param norm = 1.9010e-01, time/batch = 17.5742s	
9517/26050 (epoch 18.267), train_loss = 1.16690985, grad/param norm = 1.7262e-01, time/batch = 18.4821s	
9518/26050 (epoch 18.269), train_loss = 1.21303228, grad/param norm = 1.8995e-01, time/batch = 17.5678s	
9519/26050 (epoch 18.271), train_loss = 1.11530244, grad/param norm = 1.7806e-01, time/batch = 17.9035s	
9520/26050 (epoch 18.273), train_loss = 1.02393055, grad/param norm = 1.9228e-01, time/batch = 17.3792s	
9521/26050 (epoch 18.274), train_loss = 1.02945810, grad/param norm = 1.6945e-01, time/batch = 18.2283s	
9522/26050 (epoch 18.276), train_loss = 1.01899011, grad/param norm = 1.8600e-01, time/batch = 15.4639s	
9523/26050 (epoch 18.278), train_loss = 1.18885758, grad/param norm = 1.7588e-01, time/batch = 17.7475s	
9524/26050 (epoch 18.280), train_loss = 1.05098372, grad/param norm = 1.6828e-01, time/batch = 18.1602s	
9525/26050 (epoch 18.282), train_loss = 1.08891242, grad/param norm = 1.6535e-01, time/batch = 15.2470s	
9526/26050 (epoch 18.284), train_loss = 1.00234776, grad/param norm = 1.7218e-01, time/batch = 16.8000s	
9527/26050 (epoch 18.286), train_loss = 1.07885425, grad/param norm = 1.7793e-01, time/batch = 16.4936s	
9528/26050 (epoch 18.288), train_loss = 0.91408746, grad/param norm = 1.5866e-01, time/batch = 18.1604s	
9529/26050 (epoch 18.290), train_loss = 1.06121515, grad/param norm = 1.8080e-01, time/batch = 17.5685s	
9530/26050 (epoch 18.292), train_loss = 0.97659781, grad/param norm = 1.6493e-01, time/batch = 15.3977s	
9531/26050 (epoch 18.294), train_loss = 1.09110819, grad/param norm = 1.9460e-01, time/batch = 18.8857s	
9532/26050 (epoch 18.296), train_loss = 1.17168558, grad/param norm = 1.8688e-01, time/batch = 18.1509s	
9533/26050 (epoch 18.298), train_loss = 1.06011988, grad/param norm = 1.6955e-01, time/batch = 18.1468s	
9534/26050 (epoch 18.299), train_loss = 0.83942043, grad/param norm = 1.4888e-01, time/batch = 18.1638s	
9535/26050 (epoch 18.301), train_loss = 0.94859562, grad/param norm = 1.8097e-01, time/batch = 17.8207s	
9536/26050 (epoch 18.303), train_loss = 1.07525659, grad/param norm = 1.8590e-01, time/batch = 17.1553s	
9537/26050 (epoch 18.305), train_loss = 0.89553312, grad/param norm = 1.8591e-01, time/batch = 14.5578s	
9538/26050 (epoch 18.307), train_loss = 0.97382363, grad/param norm = 1.6997e-01, time/batch = 17.3989s	
9539/26050 (epoch 18.309), train_loss = 1.04003898, grad/param norm = 1.7435e-01, time/batch = 16.9726s	
9540/26050 (epoch 18.311), train_loss = 1.16912359, grad/param norm = 2.2753e-01, time/batch = 18.1395s	
9541/26050 (epoch 18.313), train_loss = 1.04840902, grad/param norm = 1.9979e-01, time/batch = 18.8016s	
9542/26050 (epoch 18.315), train_loss = 1.16270881, grad/param norm = 1.8382e-01, time/batch = 17.7340s	
9543/26050 (epoch 18.317), train_loss = 1.05713065, grad/param norm = 1.7661e-01, time/batch = 15.7117s	
9544/26050 (epoch 18.319), train_loss = 1.00265973, grad/param norm = 1.7213e-01, time/batch = 18.4054s	
9545/26050 (epoch 18.321), train_loss = 1.03010851, grad/param norm = 1.7635e-01, time/batch = 17.1523s	
9546/26050 (epoch 18.322), train_loss = 1.08971316, grad/param norm = 1.7516e-01, time/batch = 17.7875s	
9547/26050 (epoch 18.324), train_loss = 0.89449219, grad/param norm = 1.7783e-01, time/batch = 18.1391s	
9548/26050 (epoch 18.326), train_loss = 1.20000526, grad/param norm = 1.8498e-01, time/batch = 15.6517s	
9549/26050 (epoch 18.328), train_loss = 1.10884792, grad/param norm = 1.7625e-01, time/batch = 17.5679s	
9550/26050 (epoch 18.330), train_loss = 0.94633056, grad/param norm = 1.7179e-01, time/batch = 17.4074s	
9551/26050 (epoch 18.332), train_loss = 1.10451012, grad/param norm = 1.6997e-01, time/batch = 18.5709s	
9552/26050 (epoch 18.334), train_loss = 1.02213828, grad/param norm = 1.8489e-01, time/batch = 17.3018s	
9553/26050 (epoch 18.336), train_loss = 0.99480444, grad/param norm = 1.7959e-01, time/batch = 17.2243s	
9554/26050 (epoch 18.338), train_loss = 0.93231250, grad/param norm = 1.5227e-01, time/batch = 17.9109s	
9555/26050 (epoch 18.340), train_loss = 1.16864070, grad/param norm = 1.9530e-01, time/batch = 17.7409s	
9556/26050 (epoch 18.342), train_loss = 1.18574709, grad/param norm = 1.9174e-01, time/batch = 18.4752s	
9557/26050 (epoch 18.344), train_loss = 1.01473230, grad/param norm = 1.8065e-01, time/batch = 17.7316s	
9558/26050 (epoch 18.345), train_loss = 1.02879003, grad/param norm = 1.6675e-01, time/batch = 18.1647s	
9559/26050 (epoch 18.347), train_loss = 1.18127750, grad/param norm = 1.8715e-01, time/batch = 15.4458s	
9560/26050 (epoch 18.349), train_loss = 1.11126089, grad/param norm = 1.8156e-01, time/batch = 16.6389s	
9561/26050 (epoch 18.351), train_loss = 1.07701735, grad/param norm = 1.7005e-01, time/batch = 18.5786s	
9562/26050 (epoch 18.353), train_loss = 1.06346520, grad/param norm = 1.8952e-01, time/batch = 17.0802s	
9563/26050 (epoch 18.355), train_loss = 1.12138071, grad/param norm = 1.9193e-01, time/batch = 17.8991s	
9564/26050 (epoch 18.357), train_loss = 0.99622358, grad/param norm = 1.6677e-01, time/batch = 17.9682s	
9565/26050 (epoch 18.359), train_loss = 1.14920055, grad/param norm = 1.7564e-01, time/batch = 18.5752s	
9566/26050 (epoch 18.361), train_loss = 0.99022548, grad/param norm = 1.7216e-01, time/batch = 17.3739s	
9567/26050 (epoch 18.363), train_loss = 1.12601741, grad/param norm = 1.7471e-01, time/batch = 17.2991s	
9568/26050 (epoch 18.365), train_loss = 1.04058581, grad/param norm = 1.6145e-01, time/batch = 18.3872s	
9569/26050 (epoch 18.367), train_loss = 1.09937007, grad/param norm = 1.6854e-01, time/batch = 17.0591s	
9570/26050 (epoch 18.369), train_loss = 1.02183282, grad/param norm = 1.6731e-01, time/batch = 17.7195s	
9571/26050 (epoch 18.370), train_loss = 0.94743669, grad/param norm = 1.5784e-01, time/batch = 17.5580s	
9572/26050 (epoch 18.372), train_loss = 1.12207392, grad/param norm = 1.8288e-01, time/batch = 17.7470s	
9573/26050 (epoch 18.374), train_loss = 1.20934055, grad/param norm = 1.9363e-01, time/batch = 18.5687s	
9574/26050 (epoch 18.376), train_loss = 1.27819471, grad/param norm = 1.8789e-01, time/batch = 17.1302s	
9575/26050 (epoch 18.378), train_loss = 1.04321382, grad/param norm = 1.7745e-01, time/batch = 18.2311s	
9576/26050 (epoch 18.380), train_loss = 1.26070616, grad/param norm = 2.0876e-01, time/batch = 18.2276s	
9577/26050 (epoch 18.382), train_loss = 1.34946494, grad/param norm = 2.2687e-01, time/batch = 15.3682s	
9578/26050 (epoch 18.384), train_loss = 1.06599555, grad/param norm = 1.9179e-01, time/batch = 17.8987s	
9579/26050 (epoch 18.386), train_loss = 1.15629062, grad/param norm = 2.1644e-01, time/batch = 17.3119s	
9580/26050 (epoch 18.388), train_loss = 1.08921304, grad/param norm = 1.8586e-01, time/batch = 17.9690s	
9581/26050 (epoch 18.390), train_loss = 0.99432250, grad/param norm = 1.7253e-01, time/batch = 18.2397s	
9582/26050 (epoch 18.392), train_loss = 0.93812697, grad/param norm = 1.5651e-01, time/batch = 18.2215s	
9583/26050 (epoch 18.393), train_loss = 1.12634867, grad/param norm = 2.0848e-01, time/batch = 17.2272s	
9584/26050 (epoch 18.395), train_loss = 1.12183186, grad/param norm = 1.6896e-01, time/batch = 17.2930s	
9585/26050 (epoch 18.397), train_loss = 1.13256886, grad/param norm = 2.1690e-01, time/batch = 18.2294s	
9586/26050 (epoch 18.399), train_loss = 0.98078751, grad/param norm = 1.7746e-01, time/batch = 17.9737s	
9587/26050 (epoch 18.401), train_loss = 1.05895228, grad/param norm = 1.6944e-01, time/batch = 17.3950s	
9588/26050 (epoch 18.403), train_loss = 1.10025252, grad/param norm = 1.8637e-01, time/batch = 18.4663s	
9589/26050 (epoch 18.405), train_loss = 1.08447873, grad/param norm = 1.7978e-01, time/batch = 18.5479s	
9590/26050 (epoch 18.407), train_loss = 1.21419851, grad/param norm = 1.9315e-01, time/batch = 15.1470s	
9591/26050 (epoch 18.409), train_loss = 1.25112046, grad/param norm = 1.9011e-01, time/batch = 17.8998s	
9592/26050 (epoch 18.411), train_loss = 1.14210584, grad/param norm = 2.2128e-01, time/batch = 16.0351s	
9593/26050 (epoch 18.413), train_loss = 1.22776133, grad/param norm = 1.7200e-01, time/batch = 18.6496s	
9594/26050 (epoch 18.415), train_loss = 1.19306454, grad/param norm = 2.0222e-01, time/batch = 17.2472s	
9595/26050 (epoch 18.417), train_loss = 1.29030003, grad/param norm = 1.9952e-01, time/batch = 18.7199s	
9596/26050 (epoch 18.418), train_loss = 1.19123115, grad/param norm = 2.0548e-01, time/batch = 17.8712s	
9597/26050 (epoch 18.420), train_loss = 0.91126748, grad/param norm = 1.6161e-01, time/batch = 15.7788s	
9598/26050 (epoch 18.422), train_loss = 0.92971051, grad/param norm = 1.6788e-01, time/batch = 17.7345s	
9599/26050 (epoch 18.424), train_loss = 1.22123525, grad/param norm = 2.0526e-01, time/batch = 18.3994s	
9600/26050 (epoch 18.426), train_loss = 1.19221791, grad/param norm = 1.8684e-01, time/batch = 15.2229s	
9601/26050 (epoch 18.428), train_loss = 0.99379513, grad/param norm = 1.6886e-01, time/batch = 17.4114s	
9602/26050 (epoch 18.430), train_loss = 1.17685501, grad/param norm = 1.8729e-01, time/batch = 14.6305s	
9603/26050 (epoch 18.432), train_loss = 1.04978349, grad/param norm = 1.7695e-01, time/batch = 15.4923s	
9604/26050 (epoch 18.434), train_loss = 1.05565038, grad/param norm = 1.9378e-01, time/batch = 18.2435s	
9605/26050 (epoch 18.436), train_loss = 1.19838216, grad/param norm = 1.8746e-01, time/batch = 15.4801s	
9606/26050 (epoch 18.438), train_loss = 1.08609296, grad/param norm = 1.8390e-01, time/batch = 18.0564s	
9607/26050 (epoch 18.440), train_loss = 1.09284722, grad/param norm = 1.7760e-01, time/batch = 18.7380s	
9608/26050 (epoch 18.441), train_loss = 1.07384231, grad/param norm = 1.8792e-01, time/batch = 17.6593s	
9609/26050 (epoch 18.443), train_loss = 0.91695121, grad/param norm = 1.5395e-01, time/batch = 17.7327s	
9610/26050 (epoch 18.445), train_loss = 0.98759072, grad/param norm = 1.6697e-01, time/batch = 18.6560s	
9611/26050 (epoch 18.447), train_loss = 1.21867306, grad/param norm = 1.9636e-01, time/batch = 16.9542s	
9612/26050 (epoch 18.449), train_loss = 0.98782577, grad/param norm = 1.8264e-01, time/batch = 15.3881s	
9613/26050 (epoch 18.451), train_loss = 1.23088331, grad/param norm = 1.8755e-01, time/batch = 17.3374s	
9614/26050 (epoch 18.453), train_loss = 0.99883157, grad/param norm = 1.5993e-01, time/batch = 18.9050s	
9615/26050 (epoch 18.455), train_loss = 1.10824735, grad/param norm = 1.6866e-01, time/batch = 17.2251s	
9616/26050 (epoch 18.457), train_loss = 1.09049937, grad/param norm = 1.7877e-01, time/batch = 18.1483s	
9617/26050 (epoch 18.459), train_loss = 1.19154194, grad/param norm = 1.9141e-01, time/batch = 17.9752s	
9618/26050 (epoch 18.461), train_loss = 1.16312362, grad/param norm = 1.9201e-01, time/batch = 17.5585s	
9619/26050 (epoch 18.463), train_loss = 1.03367363, grad/param norm = 1.6654e-01, time/batch = 16.0141s	
9620/26050 (epoch 18.464), train_loss = 1.12632399, grad/param norm = 1.8369e-01, time/batch = 18.0547s	
9621/26050 (epoch 18.466), train_loss = 1.16163506, grad/param norm = 2.0104e-01, time/batch = 18.0600s	
9622/26050 (epoch 18.468), train_loss = 1.16523222, grad/param norm = 1.6087e-01, time/batch = 18.8155s	
9623/26050 (epoch 18.470), train_loss = 1.25159924, grad/param norm = 2.0499e-01, time/batch = 18.0621s	
9624/26050 (epoch 18.472), train_loss = 1.21786661, grad/param norm = 2.0547e-01, time/batch = 15.3768s	
9625/26050 (epoch 18.474), train_loss = 1.26471164, grad/param norm = 1.7638e-01, time/batch = 16.1395s	
9626/26050 (epoch 18.476), train_loss = 1.21144647, grad/param norm = 1.7942e-01, time/batch = 18.0623s	
9627/26050 (epoch 18.478), train_loss = 1.04883887, grad/param norm = 1.7690e-01, time/batch = 18.2294s	
9628/26050 (epoch 18.480), train_loss = 1.10493432, grad/param norm = 1.7730e-01, time/batch = 17.5680s	
9629/26050 (epoch 18.482), train_loss = 1.04498703, grad/param norm = 1.8250e-01, time/batch = 18.4830s	
9630/26050 (epoch 18.484), train_loss = 1.03915972, grad/param norm = 1.8536e-01, time/batch = 16.8139s	
9631/26050 (epoch 18.486), train_loss = 1.23910039, grad/param norm = 1.8690e-01, time/batch = 15.5664s	
9632/26050 (epoch 18.488), train_loss = 1.34780095, grad/param norm = 1.9576e-01, time/batch = 16.4039s	
9633/26050 (epoch 18.489), train_loss = 1.30005073, grad/param norm = 2.1514e-01, time/batch = 18.5768s	
9634/26050 (epoch 18.491), train_loss = 0.99260390, grad/param norm = 1.7540e-01, time/batch = 15.0680s	
9635/26050 (epoch 18.493), train_loss = 1.10591729, grad/param norm = 1.8362e-01, time/batch = 17.7211s	
9636/26050 (epoch 18.495), train_loss = 1.07881322, grad/param norm = 1.7008e-01, time/batch = 17.5645s	
9637/26050 (epoch 18.497), train_loss = 1.00075977, grad/param norm = 1.6993e-01, time/batch = 18.0695s	
9638/26050 (epoch 18.499), train_loss = 1.04241537, grad/param norm = 1.7087e-01, time/batch = 18.6639s	
9639/26050 (epoch 18.501), train_loss = 1.15511773, grad/param norm = 1.8197e-01, time/batch = 17.4757s	
9640/26050 (epoch 18.503), train_loss = 1.03032150, grad/param norm = 1.7521e-01, time/batch = 18.3278s	
9641/26050 (epoch 18.505), train_loss = 1.21561787, grad/param norm = 1.6983e-01, time/batch = 16.7310s	
9642/26050 (epoch 18.507), train_loss = 1.16840412, grad/param norm = 1.9224e-01, time/batch = 15.5474s	
9643/26050 (epoch 18.509), train_loss = 1.27896761, grad/param norm = 1.8980e-01, time/batch = 16.3626s	
9644/26050 (epoch 18.511), train_loss = 1.00976496, grad/param norm = 1.6060e-01, time/batch = 16.4613s	
9645/26050 (epoch 18.512), train_loss = 1.02137835, grad/param norm = 1.9241e-01, time/batch = 18.7267s	
9646/26050 (epoch 18.514), train_loss = 1.16152308, grad/param norm = 1.7967e-01, time/batch = 18.2353s	
9647/26050 (epoch 18.516), train_loss = 1.21156291, grad/param norm = 1.9884e-01, time/batch = 17.9755s	
9648/26050 (epoch 18.518), train_loss = 1.10550529, grad/param norm = 1.8951e-01, time/batch = 18.1551s	
9649/26050 (epoch 18.520), train_loss = 1.08044854, grad/param norm = 1.7054e-01, time/batch = 15.6301s	
9650/26050 (epoch 18.522), train_loss = 0.87076830, grad/param norm = 1.6005e-01, time/batch = 18.4758s	
9651/26050 (epoch 18.524), train_loss = 1.18600770, grad/param norm = 2.0544e-01, time/batch = 14.4669s	
9652/26050 (epoch 18.526), train_loss = 1.21074645, grad/param norm = 2.5982e-01, time/batch = 18.2346s	
9653/26050 (epoch 18.528), train_loss = 1.14196064, grad/param norm = 1.9444e-01, time/batch = 16.8858s	
9654/26050 (epoch 18.530), train_loss = 1.07758057, grad/param norm = 1.8720e-01, time/batch = 18.6608s	
9655/26050 (epoch 18.532), train_loss = 1.08774945, grad/param norm = 1.7648e-01, time/batch = 17.9801s	
9656/26050 (epoch 18.534), train_loss = 1.16374831, grad/param norm = 2.4326e-01, time/batch = 17.4064s	
9657/26050 (epoch 18.536), train_loss = 1.09186620, grad/param norm = 1.7849e-01, time/batch = 18.4826s	
9658/26050 (epoch 18.537), train_loss = 1.17781817, grad/param norm = 2.0192e-01, time/batch = 15.7971s	
9659/26050 (epoch 18.539), train_loss = 1.08895720, grad/param norm = 1.7511e-01, time/batch = 17.8134s	
9660/26050 (epoch 18.541), train_loss = 1.30444690, grad/param norm = 2.0550e-01, time/batch = 17.7326s	
9661/26050 (epoch 18.543), train_loss = 0.92040780, grad/param norm = 1.7751e-01, time/batch = 18.8226s	
9662/26050 (epoch 18.545), train_loss = 1.16346265, grad/param norm = 1.9004e-01, time/batch = 18.4878s	
9663/26050 (epoch 18.547), train_loss = 1.08370451, grad/param norm = 1.7859e-01, time/batch = 18.1405s	
9664/26050 (epoch 18.549), train_loss = 0.90532555, grad/param norm = 1.7795e-01, time/batch = 18.9704s	
9665/26050 (epoch 18.551), train_loss = 1.14688688, grad/param norm = 1.8177e-01, time/batch = 16.6228s	
9666/26050 (epoch 18.553), train_loss = 1.01590527, grad/param norm = 1.6985e-01, time/batch = 20.5059s	
9667/26050 (epoch 18.555), train_loss = 1.02960617, grad/param norm = 1.6805e-01, time/batch = 33.8335s	
9668/26050 (epoch 18.557), train_loss = 1.15032830, grad/param norm = 1.6961e-01, time/batch = 19.6230s	
9669/26050 (epoch 18.559), train_loss = 1.08026286, grad/param norm = 1.6862e-01, time/batch = 15.1241s	
9670/26050 (epoch 18.560), train_loss = 1.05564683, grad/param norm = 1.7366e-01, time/batch = 15.4715s	
9671/26050 (epoch 18.562), train_loss = 1.05667884, grad/param norm = 1.7214e-01, time/batch = 18.9082s	
9672/26050 (epoch 18.564), train_loss = 1.26213548, grad/param norm = 1.7551e-01, time/batch = 17.7266s	
9673/26050 (epoch 18.566), train_loss = 0.99314331, grad/param norm = 1.7036e-01, time/batch = 18.4015s	
9674/26050 (epoch 18.568), train_loss = 1.12033052, grad/param norm = 1.7808e-01, time/batch = 17.9932s	
9675/26050 (epoch 18.570), train_loss = 1.17865028, grad/param norm = 1.8354e-01, time/batch = 17.4827s	
9676/26050 (epoch 18.572), train_loss = 1.05715330, grad/param norm = 1.8308e-01, time/batch = 15.8013s	
9677/26050 (epoch 18.574), train_loss = 1.15820853, grad/param norm = 2.0454e-01, time/batch = 18.4089s	
9678/26050 (epoch 18.576), train_loss = 1.11291813, grad/param norm = 1.8123e-01, time/batch = 18.1514s	
9679/26050 (epoch 18.578), train_loss = 1.05569708, grad/param norm = 1.7587e-01, time/batch = 18.3017s	
9680/26050 (epoch 18.580), train_loss = 1.01009416, grad/param norm = 1.8436e-01, time/batch = 17.4051s	
9681/26050 (epoch 18.582), train_loss = 1.11179136, grad/param norm = 1.6689e-01, time/batch = 15.8082s	
9682/26050 (epoch 18.583), train_loss = 1.20034960, grad/param norm = 1.7753e-01, time/batch = 16.4630s	
9683/26050 (epoch 18.585), train_loss = 0.96007080, grad/param norm = 1.7544e-01, time/batch = 18.3348s	
9684/26050 (epoch 18.587), train_loss = 1.13642306, grad/param norm = 1.9881e-01, time/batch = 15.1581s	
9685/26050 (epoch 18.589), train_loss = 1.24988773, grad/param norm = 2.0869e-01, time/batch = 17.2158s	
9686/26050 (epoch 18.591), train_loss = 1.07422117, grad/param norm = 1.7362e-01, time/batch = 18.0743s	
9687/26050 (epoch 18.593), train_loss = 0.95742712, grad/param norm = 1.6948e-01, time/batch = 17.9887s	
9688/26050 (epoch 18.595), train_loss = 1.17168448, grad/param norm = 2.0379e-01, time/batch = 17.6673s	
9689/26050 (epoch 18.597), train_loss = 1.13017190, grad/param norm = 1.8073e-01, time/batch = 17.6590s	
9690/26050 (epoch 18.599), train_loss = 1.08596949, grad/param norm = 1.8953e-01, time/batch = 16.5563s	
9691/26050 (epoch 18.601), train_loss = 1.27864608, grad/param norm = 1.8831e-01, time/batch = 17.5918s	
9692/26050 (epoch 18.603), train_loss = 1.13147199, grad/param norm = 1.8717e-01, time/batch = 17.4017s	
9693/26050 (epoch 18.605), train_loss = 1.03679249, grad/param norm = 1.7304e-01, time/batch = 17.8172s	
9694/26050 (epoch 18.607), train_loss = 1.19876843, grad/param norm = 1.9202e-01, time/batch = 18.5606s	
9695/26050 (epoch 18.608), train_loss = 0.95014962, grad/param norm = 1.4694e-01, time/batch = 18.8072s	
9696/26050 (epoch 18.610), train_loss = 1.07798922, grad/param norm = 1.9005e-01, time/batch = 18.0460s	
9697/26050 (epoch 18.612), train_loss = 1.09234586, grad/param norm = 1.8531e-01, time/batch = 18.3089s	
9698/26050 (epoch 18.614), train_loss = 1.13737429, grad/param norm = 1.7934e-01, time/batch = 17.4965s	
9699/26050 (epoch 18.616), train_loss = 1.25679429, grad/param norm = 2.0487e-01, time/batch = 14.2920s	
9700/26050 (epoch 18.618), train_loss = 1.04277962, grad/param norm = 1.9324e-01, time/batch = 18.2128s	
9701/26050 (epoch 18.620), train_loss = 1.12628334, grad/param norm = 1.8331e-01, time/batch = 17.5659s	
9702/26050 (epoch 18.622), train_loss = 0.95845218, grad/param norm = 1.5323e-01, time/batch = 18.2271s	
9703/26050 (epoch 18.624), train_loss = 0.95656348, grad/param norm = 1.6385e-01, time/batch = 18.2328s	
9704/26050 (epoch 18.626), train_loss = 1.13879044, grad/param norm = 1.8008e-01, time/batch = 17.1379s	
9705/26050 (epoch 18.628), train_loss = 1.01768909, grad/param norm = 1.8020e-01, time/batch = 16.1579s	
9706/26050 (epoch 18.630), train_loss = 1.20051548, grad/param norm = 1.8389e-01, time/batch = 16.5568s	
9707/26050 (epoch 18.631), train_loss = 1.25109047, grad/param norm = 1.8547e-01, time/batch = 18.8291s	
9708/26050 (epoch 18.633), train_loss = 0.99006703, grad/param norm = 1.6672e-01, time/batch = 17.4071s	
9709/26050 (epoch 18.635), train_loss = 1.00378388, grad/param norm = 1.5326e-01, time/batch = 17.7083s	
9710/26050 (epoch 18.637), train_loss = 0.98359499, grad/param norm = 1.7749e-01, time/batch = 17.4789s	
9711/26050 (epoch 18.639), train_loss = 1.19559587, grad/param norm = 1.7634e-01, time/batch = 18.4872s	
9712/26050 (epoch 18.641), train_loss = 1.05303393, grad/param norm = 1.6386e-01, time/batch = 16.4703s	
9713/26050 (epoch 18.643), train_loss = 0.97109006, grad/param norm = 1.5939e-01, time/batch = 16.9749s	
9714/26050 (epoch 18.645), train_loss = 1.09572661, grad/param norm = 1.8143e-01, time/batch = 17.3952s	
9715/26050 (epoch 18.647), train_loss = 1.03614106, grad/param norm = 1.7523e-01, time/batch = 17.4038s	
9716/26050 (epoch 18.649), train_loss = 1.12960273, grad/param norm = 2.0914e-01, time/batch = 17.5491s	
9717/26050 (epoch 18.651), train_loss = 1.02003495, grad/param norm = 1.9026e-01, time/batch = 17.4851s	
9718/26050 (epoch 18.653), train_loss = 1.09966703, grad/param norm = 1.7095e-01, time/batch = 18.5624s	
9719/26050 (epoch 18.655), train_loss = 1.01531847, grad/param norm = 1.6821e-01, time/batch = 15.7848s	
9720/26050 (epoch 18.656), train_loss = 0.93335268, grad/param norm = 1.7557e-01, time/batch = 18.2204s	
9721/26050 (epoch 18.658), train_loss = 1.27124968, grad/param norm = 1.8940e-01, time/batch = 18.5576s	
9722/26050 (epoch 18.660), train_loss = 0.96176166, grad/param norm = 1.6868e-01, time/batch = 18.5587s	
9723/26050 (epoch 18.662), train_loss = 0.99789104, grad/param norm = 1.6657e-01, time/batch = 17.4096s	
9724/26050 (epoch 18.664), train_loss = 1.06518718, grad/param norm = 1.8193e-01, time/batch = 18.0823s	
9725/26050 (epoch 18.666), train_loss = 1.05997673, grad/param norm = 1.8912e-01, time/batch = 16.4065s	
9726/26050 (epoch 18.668), train_loss = 0.91560402, grad/param norm = 1.8919e-01, time/batch = 14.3816s	
9727/26050 (epoch 18.670), train_loss = 1.23740473, grad/param norm = 1.9907e-01, time/batch = 18.0761s	
9728/26050 (epoch 18.672), train_loss = 1.05582546, grad/param norm = 1.9556e-01, time/batch = 18.3307s	
9729/26050 (epoch 18.674), train_loss = 1.00054915, grad/param norm = 1.7659e-01, time/batch = 18.7273s	
9730/26050 (epoch 18.676), train_loss = 1.13376699, grad/param norm = 2.0801e-01, time/batch = 17.6467s	
9731/26050 (epoch 18.678), train_loss = 1.20247640, grad/param norm = 1.9136e-01, time/batch = 17.7453s	
9732/26050 (epoch 18.679), train_loss = 1.27685199, grad/param norm = 2.0885e-01, time/batch = 16.6197s	
9733/26050 (epoch 18.681), train_loss = 1.10484822, grad/param norm = 1.8848e-01, time/batch = 17.3933s	
9734/26050 (epoch 18.683), train_loss = 0.98118158, grad/param norm = 2.2811e-01, time/batch = 18.8007s	
9735/26050 (epoch 18.685), train_loss = 1.02723517, grad/param norm = 1.6810e-01, time/batch = 17.3830s	
9736/26050 (epoch 18.687), train_loss = 0.91718818, grad/param norm = 1.7258e-01, time/batch = 14.8898s	
9737/26050 (epoch 18.689), train_loss = 1.06291105, grad/param norm = 2.1350e-01, time/batch = 17.8953s	
9738/26050 (epoch 18.691), train_loss = 0.84210821, grad/param norm = 1.5029e-01, time/batch = 18.9014s	
9739/26050 (epoch 18.693), train_loss = 0.97697717, grad/param norm = 1.6723e-01, time/batch = 17.5741s	
9740/26050 (epoch 18.695), train_loss = 1.08114268, grad/param norm = 1.7547e-01, time/batch = 17.8257s	
9741/26050 (epoch 18.697), train_loss = 0.98412297, grad/param norm = 1.7366e-01, time/batch = 18.0596s	
9742/26050 (epoch 18.699), train_loss = 1.13518052, grad/param norm = 1.9082e-01, time/batch = 14.5724s	
9743/26050 (epoch 18.701), train_loss = 0.97577330, grad/param norm = 1.7600e-01, time/batch = 17.8254s	
9744/26050 (epoch 18.702), train_loss = 1.19612777, grad/param norm = 1.8231e-01, time/batch = 17.2418s	
9745/26050 (epoch 18.704), train_loss = 1.15551332, grad/param norm = 1.6407e-01, time/batch = 16.5473s	
9746/26050 (epoch 18.706), train_loss = 1.07562336, grad/param norm = 2.0103e-01, time/batch = 18.0787s	
9747/26050 (epoch 18.708), train_loss = 1.17918755, grad/param norm = 1.9031e-01, time/batch = 16.7353s	
9748/26050 (epoch 18.710), train_loss = 1.15855605, grad/param norm = 1.9249e-01, time/batch = 17.9098s	
9749/26050 (epoch 18.712), train_loss = 1.16923938, grad/param norm = 2.0106e-01, time/batch = 15.3030s	
9750/26050 (epoch 18.714), train_loss = 0.92083020, grad/param norm = 1.6085e-01, time/batch = 18.0658s	
9751/26050 (epoch 18.716), train_loss = 1.32511401, grad/param norm = 1.9755e-01, time/batch = 18.0465s	
9752/26050 (epoch 18.718), train_loss = 1.18586495, grad/param norm = 1.8505e-01, time/batch = 18.2438s	
9753/26050 (epoch 18.720), train_loss = 1.06283659, grad/param norm = 1.8717e-01, time/batch = 17.8193s	
9754/26050 (epoch 18.722), train_loss = 0.95105425, grad/param norm = 1.7159e-01, time/batch = 14.7298s	
9755/26050 (epoch 18.724), train_loss = 1.00219621, grad/param norm = 1.9412e-01, time/batch = 16.9731s	
9756/26050 (epoch 18.726), train_loss = 1.16979268, grad/param norm = 1.9092e-01, time/batch = 18.9664s	
9757/26050 (epoch 18.727), train_loss = 1.18054514, grad/param norm = 2.0003e-01, time/batch = 17.6675s	
9758/26050 (epoch 18.729), train_loss = 1.12302918, grad/param norm = 1.8049e-01, time/batch = 17.4190s	
9759/26050 (epoch 18.731), train_loss = 1.12272114, grad/param norm = 1.8871e-01, time/batch = 18.3292s	
9760/26050 (epoch 18.733), train_loss = 1.04621487, grad/param norm = 2.2486e-01, time/batch = 18.5637s	
9761/26050 (epoch 18.735), train_loss = 1.27898673, grad/param norm = 1.9627e-01, time/batch = 18.3913s	
9762/26050 (epoch 18.737), train_loss = 1.04187820, grad/param norm = 1.7058e-01, time/batch = 18.1603s	
9763/26050 (epoch 18.739), train_loss = 1.12525642, grad/param norm = 1.8288e-01, time/batch = 16.6355s	
9764/26050 (epoch 18.741), train_loss = 1.01108062, grad/param norm = 1.8564e-01, time/batch = 16.9881s	
9765/26050 (epoch 18.743), train_loss = 1.12149778, grad/param norm = 2.1444e-01, time/batch = 17.7208s	
9766/26050 (epoch 18.745), train_loss = 0.95041366, grad/param norm = 1.8088e-01, time/batch = 17.8895s	
9767/26050 (epoch 18.747), train_loss = 0.98690980, grad/param norm = 1.7086e-01, time/batch = 15.9634s	
9768/26050 (epoch 18.749), train_loss = 1.21496810, grad/param norm = 1.9164e-01, time/batch = 15.3081s	
9769/26050 (epoch 18.750), train_loss = 1.06519207, grad/param norm = 1.6451e-01, time/batch = 18.3087s	
9770/26050 (epoch 18.752), train_loss = 1.06191105, grad/param norm = 1.9977e-01, time/batch = 18.4677s	
9771/26050 (epoch 18.754), train_loss = 1.10283251, grad/param norm = 1.8963e-01, time/batch = 17.8929s	
9772/26050 (epoch 18.756), train_loss = 1.08416932, grad/param norm = 1.9238e-01, time/batch = 17.9835s	
9773/26050 (epoch 18.758), train_loss = 1.07573661, grad/param norm = 1.8641e-01, time/batch = 15.3177s	
9774/26050 (epoch 18.760), train_loss = 1.24563426, grad/param norm = 1.8199e-01, time/batch = 17.8156s	
9775/26050 (epoch 18.762), train_loss = 1.02104052, grad/param norm = 1.7866e-01, time/batch = 15.2188s	
9776/26050 (epoch 18.764), train_loss = 1.10583718, grad/param norm = 1.8188e-01, time/batch = 18.1430s	
9777/26050 (epoch 18.766), train_loss = 1.16101865, grad/param norm = 1.9572e-01, time/batch = 14.0958s	
9778/26050 (epoch 18.768), train_loss = 0.98530648, grad/param norm = 1.7414e-01, time/batch = 14.0631s	
9779/26050 (epoch 18.770), train_loss = 1.06692220, grad/param norm = 1.8798e-01, time/batch = 14.0955s	
9780/26050 (epoch 18.772), train_loss = 1.05987614, grad/param norm = 1.5739e-01, time/batch = 13.9365s	
9781/26050 (epoch 18.774), train_loss = 0.94477577, grad/param norm = 1.7416e-01, time/batch = 18.2181s	
9782/26050 (epoch 18.775), train_loss = 0.77187449, grad/param norm = 1.5272e-01, time/batch = 16.0618s	
9783/26050 (epoch 18.777), train_loss = 0.99795366, grad/param norm = 1.6562e-01, time/batch = 18.7378s	
9784/26050 (epoch 18.779), train_loss = 1.05248939, grad/param norm = 1.8625e-01, time/batch = 16.8263s	
9785/26050 (epoch 18.781), train_loss = 0.98182836, grad/param norm = 1.7294e-01, time/batch = 17.7301s	
9786/26050 (epoch 18.783), train_loss = 0.96613507, grad/param norm = 1.7096e-01, time/batch = 17.6416s	
9787/26050 (epoch 18.785), train_loss = 1.05276932, grad/param norm = 1.6962e-01, time/batch = 18.6316s	
9788/26050 (epoch 18.787), train_loss = 0.99927299, grad/param norm = 1.7385e-01, time/batch = 16.9700s	
9789/26050 (epoch 18.789), train_loss = 0.99811613, grad/param norm = 1.9644e-01, time/batch = 15.8927s	
9790/26050 (epoch 18.791), train_loss = 1.03100583, grad/param norm = 1.7336e-01, time/batch = 18.3985s	
9791/26050 (epoch 18.793), train_loss = 1.04269526, grad/param norm = 1.9735e-01, time/batch = 17.3082s	
9792/26050 (epoch 18.795), train_loss = 0.88573151, grad/param norm = 1.5869e-01, time/batch = 14.4642s	
9793/26050 (epoch 18.797), train_loss = 0.98272115, grad/param norm = 1.5706e-01, time/batch = 17.8256s	
9794/26050 (epoch 18.798), train_loss = 0.90892482, grad/param norm = 1.6950e-01, time/batch = 17.5584s	
9795/26050 (epoch 18.800), train_loss = 0.92125075, grad/param norm = 1.5839e-01, time/batch = 17.4743s	
9796/26050 (epoch 18.802), train_loss = 1.01262777, grad/param norm = 1.7685e-01, time/batch = 17.3906s	
9797/26050 (epoch 18.804), train_loss = 1.04006895, grad/param norm = 1.7762e-01, time/batch = 18.5638s	
9798/26050 (epoch 18.806), train_loss = 1.17914383, grad/param norm = 2.0143e-01, time/batch = 18.4717s	
9799/26050 (epoch 18.808), train_loss = 1.06564253, grad/param norm = 1.7497e-01, time/batch = 17.9641s	
9800/26050 (epoch 18.810), train_loss = 1.00062505, grad/param norm = 1.9411e-01, time/batch = 16.2976s	
9801/26050 (epoch 18.812), train_loss = 0.96153442, grad/param norm = 1.8750e-01, time/batch = 17.9070s	
9802/26050 (epoch 18.814), train_loss = 0.95585620, grad/param norm = 2.2559e-01, time/batch = 18.0877s	
9803/26050 (epoch 18.816), train_loss = 1.17602951, grad/param norm = 2.0414e-01, time/batch = 17.5625s	
9804/26050 (epoch 18.818), train_loss = 1.18854815, grad/param norm = 2.1161e-01, time/batch = 14.7780s	
9805/26050 (epoch 18.820), train_loss = 1.07697447, grad/param norm = 1.8051e-01, time/batch = 18.4089s	
9806/26050 (epoch 18.821), train_loss = 1.20913447, grad/param norm = 1.9104e-01, time/batch = 17.1530s	
9807/26050 (epoch 18.823), train_loss = 1.22082716, grad/param norm = 1.9684e-01, time/batch = 17.2106s	
9808/26050 (epoch 18.825), train_loss = 1.05743314, grad/param norm = 1.8736e-01, time/batch = 18.3138s	
9809/26050 (epoch 18.827), train_loss = 1.09186469, grad/param norm = 2.0498e-01, time/batch = 17.9083s	
9810/26050 (epoch 18.829), train_loss = 1.15048648, grad/param norm = 1.8927e-01, time/batch = 18.3183s	
9811/26050 (epoch 18.831), train_loss = 1.19400682, grad/param norm = 1.7148e-01, time/batch = 18.4087s	
9812/26050 (epoch 18.833), train_loss = 1.29058810, grad/param norm = 1.9914e-01, time/batch = 18.3205s	
9813/26050 (epoch 18.835), train_loss = 1.26039460, grad/param norm = 1.8991e-01, time/batch = 17.8031s	
9814/26050 (epoch 18.837), train_loss = 1.07434285, grad/param norm = 1.8159e-01, time/batch = 15.0596s	
9815/26050 (epoch 18.839), train_loss = 1.09769090, grad/param norm = 1.9129e-01, time/batch = 18.7383s	
9816/26050 (epoch 18.841), train_loss = 1.20436876, grad/param norm = 1.8654e-01, time/batch = 17.0698s	
9817/26050 (epoch 18.843), train_loss = 1.08272448, grad/param norm = 1.7355e-01, time/batch = 18.4674s	
9818/26050 (epoch 18.845), train_loss = 1.01292145, grad/param norm = 1.6043e-01, time/batch = 17.4867s	
9819/26050 (epoch 18.846), train_loss = 1.16851093, grad/param norm = 1.7283e-01, time/batch = 17.0607s	
9820/26050 (epoch 18.848), train_loss = 1.07201586, grad/param norm = 1.7196e-01, time/batch = 16.6965s	
9821/26050 (epoch 18.850), train_loss = 0.98693929, grad/param norm = 1.6548e-01, time/batch = 18.1716s	
9822/26050 (epoch 18.852), train_loss = 1.07181551, grad/param norm = 1.8198e-01, time/batch = 17.7534s	
9823/26050 (epoch 18.854), train_loss = 1.06683794, grad/param norm = 1.9515e-01, time/batch = 17.4779s	
9824/26050 (epoch 18.856), train_loss = 1.04077308, grad/param norm = 1.8988e-01, time/batch = 18.2029s	
9825/26050 (epoch 18.858), train_loss = 0.97742825, grad/param norm = 1.7287e-01, time/batch = 18.3917s	
9826/26050 (epoch 18.860), train_loss = 1.10840002, grad/param norm = 1.8582e-01, time/batch = 14.6370s	
9827/26050 (epoch 18.862), train_loss = 1.12887927, grad/param norm = 1.8314e-01, time/batch = 17.4936s	
9828/26050 (epoch 18.864), train_loss = 1.11730653, grad/param norm = 2.0742e-01, time/batch = 15.7816s	
9829/26050 (epoch 18.866), train_loss = 1.01988826, grad/param norm = 1.7079e-01, time/batch = 17.9057s	
9830/26050 (epoch 18.868), train_loss = 1.12905597, grad/param norm = 1.7901e-01, time/batch = 17.4071s	
9831/26050 (epoch 18.869), train_loss = 0.96333290, grad/param norm = 1.6643e-01, time/batch = 18.3986s	
9832/26050 (epoch 18.871), train_loss = 0.90475875, grad/param norm = 1.7275e-01, time/batch = 18.7347s	
9833/26050 (epoch 18.873), train_loss = 1.12086710, grad/param norm = 1.9465e-01, time/batch = 18.0747s	
9834/26050 (epoch 18.875), train_loss = 1.07020988, grad/param norm = 1.8729e-01, time/batch = 16.4744s	
9835/26050 (epoch 18.877), train_loss = 0.96943779, grad/param norm = 1.7483e-01, time/batch = 17.5498s	
9836/26050 (epoch 18.879), train_loss = 1.09963235, grad/param norm = 1.7042e-01, time/batch = 18.4777s	
9837/26050 (epoch 18.881), train_loss = 1.19781137, grad/param norm = 1.9201e-01, time/batch = 17.2355s	
9838/26050 (epoch 18.883), train_loss = 1.12894016, grad/param norm = 1.8563e-01, time/batch = 17.7536s	
9839/26050 (epoch 18.885), train_loss = 0.81096831, grad/param norm = 1.6004e-01, time/batch = 18.2366s	
9840/26050 (epoch 18.887), train_loss = 1.11156625, grad/param norm = 1.7961e-01, time/batch = 15.3936s	
9841/26050 (epoch 18.889), train_loss = 1.03078289, grad/param norm = 1.7047e-01, time/batch = 18.6581s	
9842/26050 (epoch 18.891), train_loss = 0.87233281, grad/param norm = 1.5938e-01, time/batch = 16.9548s	
9843/26050 (epoch 18.893), train_loss = 0.92594958, grad/param norm = 1.6969e-01, time/batch = 17.5765s	
9844/26050 (epoch 18.894), train_loss = 1.02678219, grad/param norm = 1.7089e-01, time/batch = 18.2299s	
9845/26050 (epoch 18.896), train_loss = 1.16515405, grad/param norm = 1.7313e-01, time/batch = 17.9829s	
9846/26050 (epoch 18.898), train_loss = 1.01182031, grad/param norm = 1.7936e-01, time/batch = 18.2282s	
9847/26050 (epoch 18.900), train_loss = 1.11098175, grad/param norm = 1.8091e-01, time/batch = 18.0505s	
9848/26050 (epoch 18.902), train_loss = 1.05367681, grad/param norm = 1.7415e-01, time/batch = 17.5543s	
9849/26050 (epoch 18.904), train_loss = 1.05025852, grad/param norm = 1.7169e-01, time/batch = 18.3063s	
9850/26050 (epoch 18.906), train_loss = 1.04569210, grad/param norm = 1.8924e-01, time/batch = 17.8960s	
9851/26050 (epoch 18.908), train_loss = 1.05511344, grad/param norm = 1.7527e-01, time/batch = 14.6475s	
9852/26050 (epoch 18.910), train_loss = 1.00524950, grad/param norm = 1.6731e-01, time/batch = 16.4780s	
9853/26050 (epoch 18.912), train_loss = 1.28885051, grad/param norm = 2.0498e-01, time/batch = 17.9502s	
9854/26050 (epoch 18.914), train_loss = 1.42091973, grad/param norm = 2.1016e-01, time/batch = 18.3012s	
9855/26050 (epoch 18.916), train_loss = 1.17634131, grad/param norm = 1.9470e-01, time/batch = 17.9781s	
9856/26050 (epoch 18.917), train_loss = 1.09033921, grad/param norm = 2.1650e-01, time/batch = 18.1271s	
9857/26050 (epoch 18.919), train_loss = 1.15965031, grad/param norm = 2.1154e-01, time/batch = 17.4013s	
9858/26050 (epoch 18.921), train_loss = 1.02679153, grad/param norm = 1.8589e-01, time/batch = 19.2030s	
9859/26050 (epoch 18.923), train_loss = 1.09866263, grad/param norm = 1.9330e-01, time/batch = 18.5454s	
9860/26050 (epoch 18.925), train_loss = 1.07646911, grad/param norm = 1.8157e-01, time/batch = 16.8166s	
9861/26050 (epoch 18.927), train_loss = 0.93861979, grad/param norm = 1.4595e-01, time/batch = 18.8007s	
9862/26050 (epoch 18.929), train_loss = 0.94557071, grad/param norm = 1.7358e-01, time/batch = 15.2966s	
9863/26050 (epoch 18.931), train_loss = 1.26592321, grad/param norm = 2.1554e-01, time/batch = 15.2302s	
9864/26050 (epoch 18.933), train_loss = 1.01682720, grad/param norm = 1.7030e-01, time/batch = 17.1467s	
9865/26050 (epoch 18.935), train_loss = 1.05442349, grad/param norm = 1.8277e-01, time/batch = 18.2430s	
9866/26050 (epoch 18.937), train_loss = 1.15597174, grad/param norm = 1.7899e-01, time/batch = 15.2820s	
9867/26050 (epoch 18.939), train_loss = 0.96948405, grad/param norm = 1.4896e-01, time/batch = 17.7354s	
9868/26050 (epoch 18.940), train_loss = 1.05031824, grad/param norm = 1.6335e-01, time/batch = 18.1394s	
9869/26050 (epoch 18.942), train_loss = 1.07805247, grad/param norm = 1.7524e-01, time/batch = 17.9046s	
9870/26050 (epoch 18.944), train_loss = 1.00636630, grad/param norm = 1.6226e-01, time/batch = 17.9689s	
9871/26050 (epoch 18.946), train_loss = 1.19935331, grad/param norm = 1.9295e-01, time/batch = 25.6946s	
9872/26050 (epoch 18.948), train_loss = 0.95089986, grad/param norm = 1.9052e-01, time/batch = 30.8175s	
9873/26050 (epoch 18.950), train_loss = 1.04556748, grad/param norm = 1.8442e-01, time/batch = 15.4223s	
9874/26050 (epoch 18.952), train_loss = 1.18633906, grad/param norm = 1.9939e-01, time/batch = 17.7342s	
9875/26050 (epoch 18.954), train_loss = 1.17309084, grad/param norm = 1.8281e-01, time/batch = 17.8296s	
9876/26050 (epoch 18.956), train_loss = 1.05947873, grad/param norm = 1.8475e-01, time/batch = 18.2216s	
9877/26050 (epoch 18.958), train_loss = 1.01584488, grad/param norm = 1.7196e-01, time/batch = 18.8626s	
9878/26050 (epoch 18.960), train_loss = 1.07580162, grad/param norm = 1.8121e-01, time/batch = 17.7339s	
9879/26050 (epoch 18.962), train_loss = 0.99966562, grad/param norm = 1.6260e-01, time/batch = 18.2402s	
9880/26050 (epoch 18.964), train_loss = 1.06427061, grad/param norm = 1.8631e-01, time/batch = 17.5554s	
9881/26050 (epoch 18.965), train_loss = 0.99252234, grad/param norm = 1.7585e-01, time/batch = 18.3103s	
9882/26050 (epoch 18.967), train_loss = 1.39858346, grad/param norm = 1.9457e-01, time/batch = 15.4829s	
9883/26050 (epoch 18.969), train_loss = 1.05157203, grad/param norm = 1.7755e-01, time/batch = 17.8980s	
9884/26050 (epoch 18.971), train_loss = 1.02101861, grad/param norm = 1.6004e-01, time/batch = 18.4796s	
9885/26050 (epoch 18.973), train_loss = 1.05038881, grad/param norm = 1.9869e-01, time/batch = 17.0715s	
9886/26050 (epoch 18.975), train_loss = 1.11173496, grad/param norm = 1.6773e-01, time/batch = 18.0657s	
9887/26050 (epoch 18.977), train_loss = 1.10045171, grad/param norm = 1.5958e-01, time/batch = 17.8131s	
9888/26050 (epoch 18.979), train_loss = 0.89871687, grad/param norm = 1.6698e-01, time/batch = 17.8248s	
9889/26050 (epoch 18.981), train_loss = 1.20861374, grad/param norm = 1.6844e-01, time/batch = 18.1644s	
9890/26050 (epoch 18.983), train_loss = 1.15461555, grad/param norm = 1.8545e-01, time/batch = 17.3306s	
9891/26050 (epoch 18.985), train_loss = 1.11071181, grad/param norm = 1.7192e-01, time/batch = 18.5664s	
9892/26050 (epoch 18.987), train_loss = 1.18246821, grad/param norm = 1.7666e-01, time/batch = 17.9824s	
9893/26050 (epoch 18.988), train_loss = 1.16840155, grad/param norm = 1.8041e-01, time/batch = 15.2137s	
9894/26050 (epoch 18.990), train_loss = 0.95175232, grad/param norm = 1.4968e-01, time/batch = 14.4831s	
9895/26050 (epoch 18.992), train_loss = 1.22570379, grad/param norm = 1.9061e-01, time/batch = 17.9079s	
9896/26050 (epoch 18.994), train_loss = 1.03767690, grad/param norm = 1.8652e-01, time/batch = 17.7226s	
9897/26050 (epoch 18.996), train_loss = 1.02308824, grad/param norm = 1.9140e-01, time/batch = 17.1443s	
9898/26050 (epoch 18.998), train_loss = 1.08142489, grad/param norm = 1.6911e-01, time/batch = 15.7949s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
9899/26050 (epoch 19.000), train_loss = 1.01295031, grad/param norm = 1.8071e-01, time/batch = 18.3973s	
9900/26050 (epoch 19.002), train_loss = 1.14899936, grad/param norm = 2.0063e-01, time/batch = 17.9821s	
9901/26050 (epoch 19.004), train_loss = 0.97913564, grad/param norm = 1.7249e-01, time/batch = 18.5508s	
9902/26050 (epoch 19.006), train_loss = 1.01621861, grad/param norm = 1.8551e-01, time/batch = 17.3222s	
9903/26050 (epoch 19.008), train_loss = 0.97689775, grad/param norm = 1.8829e-01, time/batch = 16.3858s	
9904/26050 (epoch 19.010), train_loss = 0.99717960, grad/param norm = 1.7674e-01, time/batch = 17.1275s	
9905/26050 (epoch 19.012), train_loss = 1.07799531, grad/param norm = 1.7193e-01, time/batch = 18.5602s	
9906/26050 (epoch 19.013), train_loss = 1.38542988, grad/param norm = 2.1083e-01, time/batch = 16.0581s	
9907/26050 (epoch 19.015), train_loss = 1.02224529, grad/param norm = 1.5962e-01, time/batch = 16.6512s	
9908/26050 (epoch 19.017), train_loss = 1.08345018, grad/param norm = 1.7346e-01, time/batch = 17.9044s	
9909/26050 (epoch 19.019), train_loss = 0.91467958, grad/param norm = 1.5707e-01, time/batch = 18.4882s	
9910/26050 (epoch 19.021), train_loss = 1.13290047, grad/param norm = 1.8459e-01, time/batch = 18.2994s	
9911/26050 (epoch 19.023), train_loss = 0.90720788, grad/param norm = 1.6788e-01, time/batch = 17.3831s	
9912/26050 (epoch 19.025), train_loss = 1.07037116, grad/param norm = 1.7345e-01, time/batch = 18.0759s	
9913/26050 (epoch 19.027), train_loss = 0.86784208, grad/param norm = 1.8125e-01, time/batch = 18.8069s	
9914/26050 (epoch 19.029), train_loss = 1.08508265, grad/param norm = 1.6772e-01, time/batch = 17.3941s	
9915/26050 (epoch 19.031), train_loss = 1.19864250, grad/param norm = 2.1270e-01, time/batch = 17.2267s	
9916/26050 (epoch 19.033), train_loss = 1.10334562, grad/param norm = 1.8341e-01, time/batch = 16.6903s	
9917/26050 (epoch 19.035), train_loss = 1.12775418, grad/param norm = 1.8933e-01, time/batch = 17.9785s	
9918/26050 (epoch 19.036), train_loss = 0.97922467, grad/param norm = 1.9633e-01, time/batch = 18.4018s	
9919/26050 (epoch 19.038), train_loss = 0.90107832, grad/param norm = 1.9720e-01, time/batch = 17.2235s	
9920/26050 (epoch 19.040), train_loss = 1.06660979, grad/param norm = 1.8214e-01, time/batch = 18.4102s	
9921/26050 (epoch 19.042), train_loss = 0.91692469, grad/param norm = 1.6382e-01, time/batch = 6.8877s	
9922/26050 (epoch 19.044), train_loss = 1.15214524, grad/param norm = 1.6727e-01, time/batch = 0.6500s	
9923/26050 (epoch 19.046), train_loss = 0.86079883, grad/param norm = 1.5048e-01, time/batch = 0.6833s	
9924/26050 (epoch 19.048), train_loss = 1.07955473, grad/param norm = 1.7793e-01, time/batch = 0.6614s	
9925/26050 (epoch 19.050), train_loss = 0.98188424, grad/param norm = 1.6648e-01, time/batch = 0.6444s	
9926/26050 (epoch 19.052), train_loss = 1.01863883, grad/param norm = 1.9103e-01, time/batch = 0.6502s	
9927/26050 (epoch 19.054), train_loss = 0.90550305, grad/param norm = 1.5437e-01, time/batch = 0.6466s	
9928/26050 (epoch 19.056), train_loss = 0.85558948, grad/param norm = 1.4660e-01, time/batch = 0.6671s	
9929/26050 (epoch 19.058), train_loss = 1.02456739, grad/param norm = 1.7068e-01, time/batch = 0.9425s	
9930/26050 (epoch 19.060), train_loss = 1.11972557, grad/param norm = 1.8147e-01, time/batch = 0.9425s	
9931/26050 (epoch 19.061), train_loss = 0.97351675, grad/param norm = 1.7158e-01, time/batch = 0.9443s	
9932/26050 (epoch 19.063), train_loss = 1.10802090, grad/param norm = 1.8271e-01, time/batch = 0.9403s	
9933/26050 (epoch 19.065), train_loss = 0.86631894, grad/param norm = 1.4753e-01, time/batch = 0.9326s	
9934/26050 (epoch 19.067), train_loss = 1.07143694, grad/param norm = 1.7716e-01, time/batch = 1.6053s	
9935/26050 (epoch 19.069), train_loss = 1.11389127, grad/param norm = 1.7223e-01, time/batch = 1.8136s	
9936/26050 (epoch 19.071), train_loss = 1.12234666, grad/param norm = 1.7522e-01, time/batch = 1.7348s	
9937/26050 (epoch 19.073), train_loss = 1.25249229, grad/param norm = 2.0003e-01, time/batch = 16.9760s	
9938/26050 (epoch 19.075), train_loss = 0.97781332, grad/param norm = 1.6255e-01, time/batch = 17.8129s	
9939/26050 (epoch 19.077), train_loss = 0.98717912, grad/param norm = 1.6936e-01, time/batch = 17.4820s	
9940/26050 (epoch 19.079), train_loss = 1.09121624, grad/param norm = 1.9471e-01, time/batch = 17.8327s	
9941/26050 (epoch 19.081), train_loss = 1.02628626, grad/param norm = 1.6928e-01, time/batch = 18.2478s	
9942/26050 (epoch 19.083), train_loss = 1.14274669, grad/param norm = 1.7589e-01, time/batch = 15.8958s	
9943/26050 (epoch 19.084), train_loss = 1.08194662, grad/param norm = 1.9574e-01, time/batch = 18.3858s	
9944/26050 (epoch 19.086), train_loss = 1.21618194, grad/param norm = 1.8484e-01, time/batch = 18.0082s	
9945/26050 (epoch 19.088), train_loss = 0.96628274, grad/param norm = 1.6651e-01, time/batch = 17.6551s	
9946/26050 (epoch 19.090), train_loss = 1.08781754, grad/param norm = 1.8172e-01, time/batch = 15.6347s	
9947/26050 (epoch 19.092), train_loss = 1.10991128, grad/param norm = 1.7293e-01, time/batch = 15.1955s	
9948/26050 (epoch 19.094), train_loss = 1.00170267, grad/param norm = 1.7383e-01, time/batch = 18.1429s	
9949/26050 (epoch 19.096), train_loss = 1.04290333, grad/param norm = 1.6340e-01, time/batch = 17.3962s	
9950/26050 (epoch 19.098), train_loss = 1.01498744, grad/param norm = 1.8163e-01, time/batch = 18.3937s	
9951/26050 (epoch 19.100), train_loss = 0.94757245, grad/param norm = 1.6845e-01, time/batch = 17.3860s	
9952/26050 (epoch 19.102), train_loss = 1.08938760, grad/param norm = 1.7363e-01, time/batch = 17.2363s	
9953/26050 (epoch 19.104), train_loss = 1.07085590, grad/param norm = 1.9465e-01, time/batch = 16.9747s	
9954/26050 (epoch 19.106), train_loss = 1.07028494, grad/param norm = 1.9948e-01, time/batch = 18.5638s	
9955/26050 (epoch 19.107), train_loss = 0.84968830, grad/param norm = 1.6459e-01, time/batch = 17.1478s	
9956/26050 (epoch 19.109), train_loss = 0.98666930, grad/param norm = 1.8323e-01, time/batch = 16.7954s	
9957/26050 (epoch 19.111), train_loss = 1.22676420, grad/param norm = 1.8727e-01, time/batch = 18.1539s	
9958/26050 (epoch 19.113), train_loss = 1.00150019, grad/param norm = 1.7150e-01, time/batch = 18.3998s	
9959/26050 (epoch 19.115), train_loss = 1.15589931, grad/param norm = 1.7761e-01, time/batch = 17.6586s	
9960/26050 (epoch 19.117), train_loss = 1.07540809, grad/param norm = 1.6828e-01, time/batch = 14.6248s	
9961/26050 (epoch 19.119), train_loss = 0.88422942, grad/param norm = 1.6252e-01, time/batch = 17.7386s	
9962/26050 (epoch 19.121), train_loss = 1.08474273, grad/param norm = 1.8025e-01, time/batch = 14.3824s	
9963/26050 (epoch 19.123), train_loss = 0.95462912, grad/param norm = 1.6452e-01, time/batch = 15.1932s	
9964/26050 (epoch 19.125), train_loss = 0.91198432, grad/param norm = 1.6282e-01, time/batch = 15.6096s	
9965/26050 (epoch 19.127), train_loss = 0.84372574, grad/param norm = 1.6147e-01, time/batch = 18.4030s	
9966/26050 (epoch 19.129), train_loss = 0.90213022, grad/param norm = 1.7401e-01, time/batch = 18.2139s	
9967/26050 (epoch 19.131), train_loss = 1.01537902, grad/param norm = 1.6923e-01, time/batch = 17.8996s	
9968/26050 (epoch 19.132), train_loss = 1.02277264, grad/param norm = 1.6848e-01, time/batch = 18.8016s	
9969/26050 (epoch 19.134), train_loss = 1.05601957, grad/param norm = 2.0754e-01, time/batch = 19.0329s	
9970/26050 (epoch 19.136), train_loss = 1.04580562, grad/param norm = 1.7346e-01, time/batch = 17.8000s	
9971/26050 (epoch 19.138), train_loss = 0.81152019, grad/param norm = 1.6062e-01, time/batch = 17.6596s	
9972/26050 (epoch 19.140), train_loss = 0.88426944, grad/param norm = 1.7862e-01, time/batch = 17.2085s	
9973/26050 (epoch 19.142), train_loss = 0.91210407, grad/param norm = 1.5962e-01, time/batch = 17.6481s	
9974/26050 (epoch 19.144), train_loss = 0.85329934, grad/param norm = 1.6585e-01, time/batch = 17.6469s	
9975/26050 (epoch 19.146), train_loss = 0.79534909, grad/param norm = 1.6121e-01, time/batch = 18.7510s	
9976/26050 (epoch 19.148), train_loss = 0.82778882, grad/param norm = 1.4585e-01, time/batch = 16.2121s	
9977/26050 (epoch 19.150), train_loss = 1.02208898, grad/param norm = 1.9295e-01, time/batch = 18.2407s	
9978/26050 (epoch 19.152), train_loss = 1.23123831, grad/param norm = 2.1289e-01, time/batch = 17.9687s	
9979/26050 (epoch 19.154), train_loss = 0.81469138, grad/param norm = 1.6311e-01, time/batch = 18.5649s	
9980/26050 (epoch 19.155), train_loss = 0.85543783, grad/param norm = 1.5365e-01, time/batch = 16.3121s	
9981/26050 (epoch 19.157), train_loss = 0.98990169, grad/param norm = 2.0848e-01, time/batch = 16.8834s	
9982/26050 (epoch 19.159), train_loss = 1.04695821, grad/param norm = 1.9462e-01, time/batch = 16.1344s	
9983/26050 (epoch 19.161), train_loss = 1.09811839, grad/param norm = 1.8499e-01, time/batch = 17.7856s	
9984/26050 (epoch 19.163), train_loss = 0.85398633, grad/param norm = 1.5334e-01, time/batch = 18.5739s	
9985/26050 (epoch 19.165), train_loss = 0.80181313, grad/param norm = 1.5598e-01, time/batch = 17.9787s	
9986/26050 (epoch 19.167), train_loss = 1.12311884, grad/param norm = 1.8478e-01, time/batch = 18.4090s	
9987/26050 (epoch 19.169), train_loss = 1.07620365, grad/param norm = 1.7784e-01, time/batch = 17.7185s	
9988/26050 (epoch 19.171), train_loss = 0.85337989, grad/param norm = 1.5379e-01, time/batch = 18.6537s	
9989/26050 (epoch 19.173), train_loss = 0.96887976, grad/param norm = 1.8743e-01, time/batch = 18.7930s	
9990/26050 (epoch 19.175), train_loss = 1.00341564, grad/param norm = 1.6462e-01, time/batch = 17.3096s	
9991/26050 (epoch 19.177), train_loss = 1.13673471, grad/param norm = 1.7017e-01, time/batch = 15.3777s	
9992/26050 (epoch 19.179), train_loss = 0.80537844, grad/param norm = 1.5534e-01, time/batch = 18.3096s	
9993/26050 (epoch 19.180), train_loss = 1.25146169, grad/param norm = 1.9144e-01, time/batch = 16.3850s	
9994/26050 (epoch 19.182), train_loss = 1.26066722, grad/param norm = 1.9566e-01, time/batch = 17.4994s	
9995/26050 (epoch 19.184), train_loss = 1.06562157, grad/param norm = 1.6855e-01, time/batch = 17.4957s	
9996/26050 (epoch 19.186), train_loss = 0.86913712, grad/param norm = 1.5464e-01, time/batch = 17.1215s	
9997/26050 (epoch 19.188), train_loss = 1.02897469, grad/param norm = 1.7947e-01, time/batch = 17.5508s	
9998/26050 (epoch 19.190), train_loss = 1.09727880, grad/param norm = 1.8518e-01, time/batch = 18.3000s	
9999/26050 (epoch 19.192), train_loss = 1.09336813, grad/param norm = 1.6482e-01, time/batch = 16.5626s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch19.19_1.6589.t7	
10000/26050 (epoch 19.194), train_loss = 1.08363924, grad/param norm = 1.7402e-01, time/batch = 16.9639s	
10001/26050 (epoch 19.196), train_loss = 1.38796217, grad/param norm = 2.0191e-01, time/batch = 17.5731s	
10002/26050 (epoch 19.198), train_loss = 0.95058395, grad/param norm = 1.6218e-01, time/batch = 17.4859s	
10003/26050 (epoch 19.200), train_loss = 0.95559945, grad/param norm = 1.7809e-01, time/batch = 18.5569s	
10004/26050 (epoch 19.202), train_loss = 1.03658352, grad/param norm = 1.7949e-01, time/batch = 16.8834s	
10005/26050 (epoch 19.203), train_loss = 1.16214436, grad/param norm = 1.9278e-01, time/batch = 18.2059s	
10006/26050 (epoch 19.205), train_loss = 0.97650992, grad/param norm = 1.7034e-01, time/batch = 15.4754s	
10007/26050 (epoch 19.207), train_loss = 0.97706866, grad/param norm = 1.6762e-01, time/batch = 18.6483s	
10008/26050 (epoch 19.209), train_loss = 1.08484616, grad/param norm = 1.8288e-01, time/batch = 14.8823s	
10009/26050 (epoch 19.211), train_loss = 0.87875010, grad/param norm = 1.5728e-01, time/batch = 18.2406s	
10010/26050 (epoch 19.213), train_loss = 1.08845318, grad/param norm = 1.9157e-01, time/batch = 18.1789s	
10011/26050 (epoch 19.215), train_loss = 1.04030529, grad/param norm = 2.0408e-01, time/batch = 17.5700s	
10012/26050 (epoch 19.217), train_loss = 1.00921803, grad/param norm = 1.7108e-01, time/batch = 18.1495s	
10013/26050 (epoch 19.219), train_loss = 1.01467133, grad/param norm = 1.9930e-01, time/batch = 17.4738s	
10014/26050 (epoch 19.221), train_loss = 0.94616014, grad/param norm = 1.8108e-01, time/batch = 17.5692s	
10015/26050 (epoch 19.223), train_loss = 1.07040130, grad/param norm = 1.8013e-01, time/batch = 16.5500s	
10016/26050 (epoch 19.225), train_loss = 0.92820155, grad/param norm = 1.7116e-01, time/batch = 17.8243s	
10017/26050 (epoch 19.226), train_loss = 1.08676003, grad/param norm = 1.9853e-01, time/batch = 17.7406s	
10018/26050 (epoch 19.228), train_loss = 1.16933557, grad/param norm = 1.8009e-01, time/batch = 15.2870s	
10019/26050 (epoch 19.230), train_loss = 1.06683914, grad/param norm = 1.6605e-01, time/batch = 18.1421s	
10020/26050 (epoch 19.232), train_loss = 1.13295475, grad/param norm = 1.9607e-01, time/batch = 18.7976s	
10021/26050 (epoch 19.234), train_loss = 0.92262226, grad/param norm = 1.7210e-01, time/batch = 14.9663s	
10022/26050 (epoch 19.236), train_loss = 1.12894634, grad/param norm = 1.9197e-01, time/batch = 18.3704s	
10023/26050 (epoch 19.238), train_loss = 0.89785727, grad/param norm = 1.6710e-01, time/batch = 18.1555s	
10024/26050 (epoch 19.240), train_loss = 1.02877354, grad/param norm = 1.7797e-01, time/batch = 17.2048s	
10025/26050 (epoch 19.242), train_loss = 1.04427012, grad/param norm = 1.6798e-01, time/batch = 17.6186s	
10026/26050 (epoch 19.244), train_loss = 1.03103134, grad/param norm = 1.9651e-01, time/batch = 18.4786s	
10027/26050 (epoch 19.246), train_loss = 0.97371296, grad/param norm = 1.7781e-01, time/batch = 18.7320s	
10028/26050 (epoch 19.248), train_loss = 1.04974781, grad/param norm = 1.7850e-01, time/batch = 17.6548s	
10029/26050 (epoch 19.250), train_loss = 1.04673758, grad/param norm = 2.0984e-01, time/batch = 18.4869s	
10030/26050 (epoch 19.251), train_loss = 1.00659822, grad/param norm = 1.6462e-01, time/batch = 14.7231s	
10031/26050 (epoch 19.253), train_loss = 0.89962013, grad/param norm = 1.6386e-01, time/batch = 17.7352s	
10032/26050 (epoch 19.255), train_loss = 1.22318130, grad/param norm = 1.8140e-01, time/batch = 18.2961s	
10033/26050 (epoch 19.257), train_loss = 1.03836435, grad/param norm = 1.9472e-01, time/batch = 17.4878s	
10034/26050 (epoch 19.259), train_loss = 1.18583817, grad/param norm = 1.9344e-01, time/batch = 18.6641s	
10035/26050 (epoch 19.261), train_loss = 0.93352297, grad/param norm = 1.7386e-01, time/batch = 17.2214s	
10036/26050 (epoch 19.263), train_loss = 1.10550812, grad/param norm = 1.9319e-01, time/batch = 17.7320s	
10037/26050 (epoch 19.265), train_loss = 1.21292485, grad/param norm = 2.0557e-01, time/batch = 18.6633s	
10038/26050 (epoch 19.267), train_loss = 1.15650197, grad/param norm = 1.7033e-01, time/batch = 16.9107s	
10039/26050 (epoch 19.269), train_loss = 1.18668193, grad/param norm = 1.9122e-01, time/batch = 15.6043s	
10040/26050 (epoch 19.271), train_loss = 1.10290936, grad/param norm = 1.8424e-01, time/batch = 17.8392s	
10041/26050 (epoch 19.273), train_loss = 1.00706648, grad/param norm = 1.9185e-01, time/batch = 18.0799s	
10042/26050 (epoch 19.274), train_loss = 1.01391434, grad/param norm = 1.7145e-01, time/batch = 18.3091s	
10043/26050 (epoch 19.276), train_loss = 1.00601141, grad/param norm = 2.0011e-01, time/batch = 16.6378s	
10044/26050 (epoch 19.278), train_loss = 1.17664271, grad/param norm = 1.7396e-01, time/batch = 15.4881s	
10045/26050 (epoch 19.280), train_loss = 1.03582396, grad/param norm = 1.6783e-01, time/batch = 17.2316s	
10046/26050 (epoch 19.282), train_loss = 1.07983164, grad/param norm = 1.7900e-01, time/batch = 18.6541s	
10047/26050 (epoch 19.284), train_loss = 0.99285113, grad/param norm = 1.7264e-01, time/batch = 17.0825s	
10048/26050 (epoch 19.286), train_loss = 1.06498747, grad/param norm = 1.9018e-01, time/batch = 17.4164s	
10049/26050 (epoch 19.288), train_loss = 0.90058345, grad/param norm = 1.6436e-01, time/batch = 17.5661s	
10050/26050 (epoch 19.290), train_loss = 1.05985320, grad/param norm = 2.0227e-01, time/batch = 17.9094s	
10051/26050 (epoch 19.292), train_loss = 0.95201064, grad/param norm = 1.5631e-01, time/batch = 18.6585s	
10052/26050 (epoch 19.294), train_loss = 1.06457587, grad/param norm = 1.9388e-01, time/batch = 17.4845s	
10053/26050 (epoch 19.296), train_loss = 1.14438497, grad/param norm = 1.8155e-01, time/batch = 16.5686s	
10054/26050 (epoch 19.298), train_loss = 1.04706021, grad/param norm = 1.7213e-01, time/batch = 15.2707s	
10055/26050 (epoch 19.299), train_loss = 0.83553604, grad/param norm = 1.4898e-01, time/batch = 16.4876s	
10056/26050 (epoch 19.301), train_loss = 0.91677729, grad/param norm = 1.7739e-01, time/batch = 18.4785s	
10057/26050 (epoch 19.303), train_loss = 1.05763692, grad/param norm = 1.9611e-01, time/batch = 18.4746s	
10058/26050 (epoch 19.305), train_loss = 0.87107063, grad/param norm = 1.7314e-01, time/batch = 18.8120s	
10059/26050 (epoch 19.307), train_loss = 0.96342352, grad/param norm = 1.7478e-01, time/batch = 16.9726s	
10060/26050 (epoch 19.309), train_loss = 1.02204018, grad/param norm = 1.9144e-01, time/batch = 18.4861s	
10061/26050 (epoch 19.311), train_loss = 1.15137883, grad/param norm = 2.2632e-01, time/batch = 17.3273s	
10062/26050 (epoch 19.313), train_loss = 1.04184792, grad/param norm = 2.0673e-01, time/batch = 17.5596s	
10063/26050 (epoch 19.315), train_loss = 1.15512618, grad/param norm = 2.0099e-01, time/batch = 14.9767s	
10064/26050 (epoch 19.317), train_loss = 1.05181455, grad/param norm = 1.8538e-01, time/batch = 14.6292s	
10065/26050 (epoch 19.319), train_loss = 0.97355408, grad/param norm = 1.7023e-01, time/batch = 18.7254s	
10066/26050 (epoch 19.321), train_loss = 0.99825867, grad/param norm = 1.6518e-01, time/batch = 17.6413s	
10067/26050 (epoch 19.322), train_loss = 1.05861523, grad/param norm = 1.6209e-01, time/batch = 18.3923s	
10068/26050 (epoch 19.324), train_loss = 0.87005437, grad/param norm = 1.7158e-01, time/batch = 16.7936s	
10069/26050 (epoch 19.326), train_loss = 1.17230485, grad/param norm = 1.8322e-01, time/batch = 17.1402s	
10070/26050 (epoch 19.328), train_loss = 1.08926815, grad/param norm = 1.7740e-01, time/batch = 17.7394s	
10071/26050 (epoch 19.330), train_loss = 0.93163886, grad/param norm = 1.7359e-01, time/batch = 17.5797s	
10072/26050 (epoch 19.332), train_loss = 1.08264991, grad/param norm = 1.7858e-01, time/batch = 18.2149s	
10073/26050 (epoch 19.334), train_loss = 1.00878210, grad/param norm = 1.8432e-01, time/batch = 18.0443s	
10074/26050 (epoch 19.336), train_loss = 0.97496796, grad/param norm = 1.7457e-01, time/batch = 18.3184s	
10075/26050 (epoch 19.338), train_loss = 0.91993642, grad/param norm = 1.5186e-01, time/batch = 18.6495s	
10076/26050 (epoch 19.340), train_loss = 1.14657327, grad/param norm = 1.9952e-01, time/batch = 16.3780s	
10077/26050 (epoch 19.342), train_loss = 1.16239750, grad/param norm = 1.9303e-01, time/batch = 18.2336s	
10078/26050 (epoch 19.344), train_loss = 0.99037764, grad/param norm = 1.8345e-01, time/batch = 18.3898s	
10079/26050 (epoch 19.345), train_loss = 1.01758068, grad/param norm = 1.8448e-01, time/batch = 15.8770s	
10080/26050 (epoch 19.347), train_loss = 1.16670937, grad/param norm = 1.8697e-01, time/batch = 17.9641s	
10081/26050 (epoch 19.349), train_loss = 1.10391161, grad/param norm = 1.9502e-01, time/batch = 14.9597s	
10082/26050 (epoch 19.351), train_loss = 1.06929763, grad/param norm = 1.9913e-01, time/batch = 18.5663s	
10083/26050 (epoch 19.353), train_loss = 1.05098150, grad/param norm = 2.0934e-01, time/batch = 24.9507s	
10084/26050 (epoch 19.355), train_loss = 1.09693650, grad/param norm = 1.9955e-01, time/batch = 32.5429s	
10085/26050 (epoch 19.357), train_loss = 0.97605026, grad/param norm = 1.5900e-01, time/batch = 17.2883s	
10086/26050 (epoch 19.359), train_loss = 1.13287690, grad/param norm = 1.7839e-01, time/batch = 18.1484s	
10087/26050 (epoch 19.361), train_loss = 0.96451997, grad/param norm = 1.6575e-01, time/batch = 18.8041s	
10088/26050 (epoch 19.363), train_loss = 1.10735145, grad/param norm = 1.7402e-01, time/batch = 18.0788s	
10089/26050 (epoch 19.365), train_loss = 1.00960384, grad/param norm = 1.5854e-01, time/batch = 17.9079s	
10090/26050 (epoch 19.367), train_loss = 1.09122380, grad/param norm = 1.8333e-01, time/batch = 16.6358s	
10091/26050 (epoch 19.369), train_loss = 0.99585487, grad/param norm = 1.7424e-01, time/batch = 18.8045s	
10092/26050 (epoch 19.370), train_loss = 0.93639267, grad/param norm = 1.5943e-01, time/batch = 18.3969s	
10093/26050 (epoch 19.372), train_loss = 1.09908539, grad/param norm = 1.7334e-01, time/batch = 15.8043s	
10094/26050 (epoch 19.374), train_loss = 1.18234622, grad/param norm = 1.8935e-01, time/batch = 18.4031s	
10095/26050 (epoch 19.376), train_loss = 1.25325782, grad/param norm = 1.9184e-01, time/batch = 14.8749s	
10096/26050 (epoch 19.378), train_loss = 1.01980878, grad/param norm = 1.6888e-01, time/batch = 17.8983s	
10097/26050 (epoch 19.380), train_loss = 1.23474127, grad/param norm = 2.0506e-01, time/batch = 17.1645s	
10098/26050 (epoch 19.382), train_loss = 1.32624496, grad/param norm = 2.1606e-01, time/batch = 17.2348s	
10099/26050 (epoch 19.384), train_loss = 1.06119857, grad/param norm = 1.9594e-01, time/batch = 18.2937s	
10100/26050 (epoch 19.386), train_loss = 1.13705015, grad/param norm = 2.3498e-01, time/batch = 18.1521s	
10101/26050 (epoch 19.388), train_loss = 1.06469165, grad/param norm = 1.9236e-01, time/batch = 18.5641s	
10102/26050 (epoch 19.390), train_loss = 0.98651625, grad/param norm = 1.7563e-01, time/batch = 16.7309s	
10103/26050 (epoch 19.392), train_loss = 0.92914833, grad/param norm = 1.6666e-01, time/batch = 18.8310s	
10104/26050 (epoch 19.393), train_loss = 1.10958461, grad/param norm = 1.8947e-01, time/batch = 18.0880s	
10105/26050 (epoch 19.395), train_loss = 1.10110313, grad/param norm = 1.7354e-01, time/batch = 18.1365s	
10106/26050 (epoch 19.397), train_loss = 1.10214825, grad/param norm = 1.9376e-01, time/batch = 18.6434s	
10107/26050 (epoch 19.399), train_loss = 0.96642111, grad/param norm = 1.7407e-01, time/batch = 15.8977s	
10108/26050 (epoch 19.401), train_loss = 1.05965017, grad/param norm = 2.0250e-01, time/batch = 18.1497s	
10109/26050 (epoch 19.403), train_loss = 1.07369333, grad/param norm = 1.8154e-01, time/batch = 17.9515s	
10110/26050 (epoch 19.405), train_loss = 1.06508178, grad/param norm = 1.7872e-01, time/batch = 18.7359s	
10111/26050 (epoch 19.407), train_loss = 1.19107651, grad/param norm = 1.8524e-01, time/batch = 19.0612s	
10112/26050 (epoch 19.409), train_loss = 1.23105997, grad/param norm = 1.9816e-01, time/batch = 17.8002s	
10113/26050 (epoch 19.411), train_loss = 1.10727486, grad/param norm = 1.9089e-01, time/batch = 16.4076s	
10114/26050 (epoch 19.413), train_loss = 1.22061024, grad/param norm = 1.7738e-01, time/batch = 16.4742s	
10115/26050 (epoch 19.415), train_loss = 1.17643109, grad/param norm = 2.0314e-01, time/batch = 17.7292s	
10116/26050 (epoch 19.417), train_loss = 1.27542608, grad/param norm = 2.0517e-01, time/batch = 17.1608s	
10117/26050 (epoch 19.418), train_loss = 1.16915802, grad/param norm = 2.0333e-01, time/batch = 18.4025s	
10118/26050 (epoch 19.420), train_loss = 0.89689765, grad/param norm = 1.8195e-01, time/batch = 16.8783s	
10119/26050 (epoch 19.422), train_loss = 0.90954532, grad/param norm = 1.7148e-01, time/batch = 17.1329s	
10120/26050 (epoch 19.424), train_loss = 1.20300103, grad/param norm = 2.2042e-01, time/batch = 16.4685s	
10121/26050 (epoch 19.426), train_loss = 1.18050242, grad/param norm = 1.9078e-01, time/batch = 18.3982s	
10122/26050 (epoch 19.428), train_loss = 0.97825973, grad/param norm = 1.5699e-01, time/batch = 16.8133s	
10123/26050 (epoch 19.430), train_loss = 1.15862027, grad/param norm = 1.7456e-01, time/batch = 18.9613s	
10124/26050 (epoch 19.432), train_loss = 1.02460611, grad/param norm = 1.8019e-01, time/batch = 17.8154s	
10125/26050 (epoch 19.434), train_loss = 1.03700574, grad/param norm = 1.9359e-01, time/batch = 15.8094s	
10126/26050 (epoch 19.436), train_loss = 1.18301411, grad/param norm = 1.9540e-01, time/batch = 18.0463s	
10127/26050 (epoch 19.438), train_loss = 1.07640180, grad/param norm = 1.7975e-01, time/batch = 18.2999s	
10128/26050 (epoch 19.440), train_loss = 1.07394479, grad/param norm = 1.8218e-01, time/batch = 18.1323s	
10129/26050 (epoch 19.441), train_loss = 1.06306300, grad/param norm = 1.8763e-01, time/batch = 17.1518s	
10130/26050 (epoch 19.443), train_loss = 0.90224866, grad/param norm = 1.5235e-01, time/batch = 18.3262s	
10131/26050 (epoch 19.445), train_loss = 0.98342469, grad/param norm = 1.6875e-01, time/batch = 17.0827s	
10132/26050 (epoch 19.447), train_loss = 1.21206733, grad/param norm = 2.0478e-01, time/batch = 17.6526s	
10133/26050 (epoch 19.449), train_loss = 0.97575897, grad/param norm = 1.6898e-01, time/batch = 18.0751s	
10134/26050 (epoch 19.451), train_loss = 1.21793277, grad/param norm = 1.9434e-01, time/batch = 15.3117s	
10135/26050 (epoch 19.453), train_loss = 0.98826447, grad/param norm = 1.6369e-01, time/batch = 16.8269s	
10136/26050 (epoch 19.455), train_loss = 1.08861981, grad/param norm = 1.7224e-01, time/batch = 16.0489s	
10137/26050 (epoch 19.457), train_loss = 1.06475616, grad/param norm = 1.7906e-01, time/batch = 18.7353s	
10138/26050 (epoch 19.459), train_loss = 1.16919252, grad/param norm = 1.8630e-01, time/batch = 18.7379s	
10139/26050 (epoch 19.461), train_loss = 1.16197916, grad/param norm = 2.1327e-01, time/batch = 17.5708s	
10140/26050 (epoch 19.463), train_loss = 1.02753029, grad/param norm = 1.7656e-01, time/batch = 14.9803s	
10141/26050 (epoch 19.464), train_loss = 1.10938862, grad/param norm = 1.7868e-01, time/batch = 17.7497s	
10142/26050 (epoch 19.466), train_loss = 1.12746520, grad/param norm = 1.8814e-01, time/batch = 18.5717s	
10143/26050 (epoch 19.468), train_loss = 1.14996102, grad/param norm = 1.6599e-01, time/batch = 18.1568s	
10144/26050 (epoch 19.470), train_loss = 1.21701162, grad/param norm = 2.0393e-01, time/batch = 18.3178s	
10145/26050 (epoch 19.472), train_loss = 1.21291863, grad/param norm = 2.1153e-01, time/batch = 17.8117s	
10146/26050 (epoch 19.474), train_loss = 1.23638807, grad/param norm = 1.8606e-01, time/batch = 15.3136s	
10147/26050 (epoch 19.476), train_loss = 1.19405248, grad/param norm = 1.8007e-01, time/batch = 18.7124s	
10148/26050 (epoch 19.478), train_loss = 1.04742849, grad/param norm = 1.8172e-01, time/batch = 17.6513s	
10149/26050 (epoch 19.480), train_loss = 1.06559485, grad/param norm = 1.6204e-01, time/batch = 15.4037s	
10150/26050 (epoch 19.482), train_loss = 1.02090238, grad/param norm = 1.8014e-01, time/batch = 17.5367s	
10151/26050 (epoch 19.484), train_loss = 1.02012967, grad/param norm = 1.8044e-01, time/batch = 18.7070s	
10152/26050 (epoch 19.486), train_loss = 1.21725671, grad/param norm = 1.9065e-01, time/batch = 18.4800s	
10153/26050 (epoch 19.488), train_loss = 1.31803139, grad/param norm = 2.0374e-01, time/batch = 17.1625s	
10154/26050 (epoch 19.489), train_loss = 1.26830981, grad/param norm = 2.1826e-01, time/batch = 17.5770s	
10155/26050 (epoch 19.491), train_loss = 0.97837746, grad/param norm = 1.7940e-01, time/batch = 18.2378s	
10156/26050 (epoch 19.493), train_loss = 1.09765269, grad/param norm = 1.9143e-01, time/batch = 18.3155s	
10157/26050 (epoch 19.495), train_loss = 1.06640766, grad/param norm = 1.7375e-01, time/batch = 18.5637s	
10158/26050 (epoch 19.497), train_loss = 0.98121762, grad/param norm = 1.7079e-01, time/batch = 17.6426s	
10159/26050 (epoch 19.499), train_loss = 1.02792359, grad/param norm = 1.7502e-01, time/batch = 15.7990s	
10160/26050 (epoch 19.501), train_loss = 1.14912144, grad/param norm = 1.9604e-01, time/batch = 17.9732s	
10161/26050 (epoch 19.503), train_loss = 1.01715093, grad/param norm = 1.7382e-01, time/batch = 18.5687s	
10162/26050 (epoch 19.505), train_loss = 1.19599967, grad/param norm = 1.7080e-01, time/batch = 18.4844s	
10163/26050 (epoch 19.507), train_loss = 1.15297149, grad/param norm = 1.9015e-01, time/batch = 16.6364s	
10164/26050 (epoch 19.509), train_loss = 1.26227465, grad/param norm = 1.8379e-01, time/batch = 17.9936s	
10165/26050 (epoch 19.511), train_loss = 1.00081663, grad/param norm = 1.6372e-01, time/batch = 17.7492s	
10166/26050 (epoch 19.512), train_loss = 0.99980358, grad/param norm = 1.7447e-01, time/batch = 15.7990s	
10167/26050 (epoch 19.514), train_loss = 1.13890520, grad/param norm = 1.9066e-01, time/batch = 18.3147s	
10168/26050 (epoch 19.516), train_loss = 1.19548944, grad/param norm = 1.9327e-01, time/batch = 18.7373s	
10169/26050 (epoch 19.518), train_loss = 1.07647071, grad/param norm = 1.8911e-01, time/batch = 17.7350s	
10170/26050 (epoch 19.520), train_loss = 1.04747786, grad/param norm = 1.6873e-01, time/batch = 14.4566s	
10171/26050 (epoch 19.522), train_loss = 0.84383030, grad/param norm = 1.5552e-01, time/batch = 16.2245s	
10172/26050 (epoch 19.524), train_loss = 1.16819856, grad/param norm = 2.0192e-01, time/batch = 18.0713s	
10173/26050 (epoch 19.526), train_loss = 1.18819247, grad/param norm = 2.0684e-01, time/batch = 16.9574s	
10174/26050 (epoch 19.528), train_loss = 1.13170456, grad/param norm = 2.1920e-01, time/batch = 18.5683s	
10175/26050 (epoch 19.530), train_loss = 1.05343764, grad/param norm = 1.8694e-01, time/batch = 17.6521s	
10176/26050 (epoch 19.532), train_loss = 1.07950586, grad/param norm = 1.7682e-01, time/batch = 18.7124s	
10177/26050 (epoch 19.534), train_loss = 1.13723788, grad/param norm = 2.0678e-01, time/batch = 17.3887s	
10178/26050 (epoch 19.536), train_loss = 1.06397626, grad/param norm = 1.7732e-01, time/batch = 16.9645s	
10179/26050 (epoch 19.537), train_loss = 1.15772140, grad/param norm = 1.8842e-01, time/batch = 18.0676s	
10180/26050 (epoch 19.539), train_loss = 1.09257863, grad/param norm = 2.0632e-01, time/batch = 17.0640s	
10181/26050 (epoch 19.541), train_loss = 1.29759968, grad/param norm = 2.1350e-01, time/batch = 18.8049s	
10182/26050 (epoch 19.543), train_loss = 0.91741920, grad/param norm = 1.8221e-01, time/batch = 17.9778s	
10183/26050 (epoch 19.545), train_loss = 1.14061156, grad/param norm = 1.9315e-01, time/batch = 17.9046s	
10184/26050 (epoch 19.547), train_loss = 1.06619588, grad/param norm = 1.7524e-01, time/batch = 18.1401s	
10185/26050 (epoch 19.549), train_loss = 0.88607872, grad/param norm = 1.6574e-01, time/batch = 17.0659s	
10186/26050 (epoch 19.551), train_loss = 1.14031947, grad/param norm = 1.7898e-01, time/batch = 14.4543s	
10187/26050 (epoch 19.553), train_loss = 0.99638195, grad/param norm = 1.6995e-01, time/batch = 16.9977s	
10188/26050 (epoch 19.555), train_loss = 1.01376463, grad/param norm = 1.6954e-01, time/batch = 18.3274s	
10189/26050 (epoch 19.557), train_loss = 1.12969379, grad/param norm = 1.7471e-01, time/batch = 18.3924s	
10190/26050 (epoch 19.559), train_loss = 1.05811789, grad/param norm = 1.7341e-01, time/batch = 17.8074s	
10191/26050 (epoch 19.560), train_loss = 1.04043794, grad/param norm = 1.8295e-01, time/batch = 18.1509s	
10192/26050 (epoch 19.562), train_loss = 1.03624854, grad/param norm = 1.7768e-01, time/batch = 16.2937s	
10193/26050 (epoch 19.564), train_loss = 1.23831862, grad/param norm = 1.7681e-01, time/batch = 18.3836s	
10194/26050 (epoch 19.566), train_loss = 0.97765650, grad/param norm = 1.6385e-01, time/batch = 19.7130s	
10195/26050 (epoch 19.568), train_loss = 1.10748322, grad/param norm = 1.8822e-01, time/batch = 18.1467s	
10196/26050 (epoch 19.570), train_loss = 1.14849652, grad/param norm = 1.9246e-01, time/batch = 18.1512s	
10197/26050 (epoch 19.572), train_loss = 1.04518748, grad/param norm = 1.8956e-01, time/batch = 16.9778s	
10198/26050 (epoch 19.574), train_loss = 1.13445075, grad/param norm = 2.1135e-01, time/batch = 18.5691s	
10199/26050 (epoch 19.576), train_loss = 1.09398429, grad/param norm = 1.8162e-01, time/batch = 16.3039s	
10200/26050 (epoch 19.578), train_loss = 1.04024027, grad/param norm = 1.8215e-01, time/batch = 16.4534s	
10201/26050 (epoch 19.580), train_loss = 0.99642679, grad/param norm = 1.8499e-01, time/batch = 17.8601s	
10202/26050 (epoch 19.582), train_loss = 1.10238150, grad/param norm = 1.8423e-01, time/batch = 17.8850s	
10203/26050 (epoch 19.583), train_loss = 1.18247971, grad/param norm = 1.7667e-01, time/batch = 18.2205s	
10204/26050 (epoch 19.585), train_loss = 0.94789374, grad/param norm = 1.8207e-01, time/batch = 17.5468s	
10205/26050 (epoch 19.587), train_loss = 1.12685716, grad/param norm = 2.0029e-01, time/batch = 18.9046s	
10206/26050 (epoch 19.589), train_loss = 1.22919945, grad/param norm = 2.0403e-01, time/batch = 18.1644s	
10207/26050 (epoch 19.591), train_loss = 1.04285753, grad/param norm = 1.7118e-01, time/batch = 17.2284s	
10208/26050 (epoch 19.593), train_loss = 0.94451441, grad/param norm = 1.7144e-01, time/batch = 16.7446s	
10209/26050 (epoch 19.595), train_loss = 1.16045995, grad/param norm = 2.0795e-01, time/batch = 16.5394s	
10210/26050 (epoch 19.597), train_loss = 1.10262163, grad/param norm = 1.7875e-01, time/batch = 14.6559s	
10211/26050 (epoch 19.599), train_loss = 1.07637763, grad/param norm = 1.9514e-01, time/batch = 18.1494s	
10212/26050 (epoch 19.601), train_loss = 1.24850309, grad/param norm = 1.8504e-01, time/batch = 18.7965s	
10213/26050 (epoch 19.603), train_loss = 1.10282013, grad/param norm = 1.8612e-01, time/batch = 17.8982s	
10214/26050 (epoch 19.605), train_loss = 1.01781458, grad/param norm = 1.7607e-01, time/batch = 14.4803s	
10215/26050 (epoch 19.607), train_loss = 1.18417271, grad/param norm = 1.9723e-01, time/batch = 18.4894s	
10216/26050 (epoch 19.608), train_loss = 0.92995352, grad/param norm = 1.5097e-01, time/batch = 17.1528s	
10217/26050 (epoch 19.610), train_loss = 1.05249216, grad/param norm = 1.9054e-01, time/batch = 17.7323s	
10218/26050 (epoch 19.612), train_loss = 1.07050392, grad/param norm = 1.9036e-01, time/batch = 17.3280s	
10219/26050 (epoch 19.614), train_loss = 1.10919503, grad/param norm = 1.8470e-01, time/batch = 15.7149s	
10220/26050 (epoch 19.616), train_loss = 1.23655223, grad/param norm = 2.0781e-01, time/batch = 17.9010s	
10221/26050 (epoch 19.618), train_loss = 1.02632945, grad/param norm = 1.9264e-01, time/batch = 14.9730s	
10222/26050 (epoch 19.620), train_loss = 1.10783546, grad/param norm = 1.7903e-01, time/batch = 16.8795s	
10223/26050 (epoch 19.622), train_loss = 0.94488207, grad/param norm = 1.4951e-01, time/batch = 18.5806s	
10224/26050 (epoch 19.624), train_loss = 0.93228318, grad/param norm = 1.5937e-01, time/batch = 17.9762s	
10225/26050 (epoch 19.626), train_loss = 1.12428611, grad/param norm = 1.8227e-01, time/batch = 18.1361s	
10226/26050 (epoch 19.628), train_loss = 0.99365332, grad/param norm = 1.7344e-01, time/batch = 18.2124s	
10227/26050 (epoch 19.630), train_loss = 1.18208375, grad/param norm = 1.7922e-01, time/batch = 18.2386s	
10228/26050 (epoch 19.631), train_loss = 1.22928710, grad/param norm = 1.8676e-01, time/batch = 15.5550s	
10229/26050 (epoch 19.633), train_loss = 0.96675470, grad/param norm = 1.6593e-01, time/batch = 17.8133s	
10230/26050 (epoch 19.635), train_loss = 0.98823824, grad/param norm = 1.6053e-01, time/batch = 17.8981s	
10231/26050 (epoch 19.637), train_loss = 0.95875498, grad/param norm = 1.7254e-01, time/batch = 17.4645s	
10232/26050 (epoch 19.639), train_loss = 1.16817746, grad/param norm = 1.7840e-01, time/batch = 18.6392s	
10233/26050 (epoch 19.641), train_loss = 1.03914823, grad/param norm = 1.6751e-01, time/batch = 14.8936s	
10234/26050 (epoch 19.643), train_loss = 0.95056819, grad/param norm = 1.5269e-01, time/batch = 18.2323s	
10235/26050 (epoch 19.645), train_loss = 1.07045836, grad/param norm = 1.7997e-01, time/batch = 18.2972s	
10236/26050 (epoch 19.647), train_loss = 1.00962123, grad/param norm = 1.8361e-01, time/batch = 18.6425s	
10237/26050 (epoch 19.649), train_loss = 1.09784877, grad/param norm = 1.9607e-01, time/batch = 18.1365s	
10238/26050 (epoch 19.651), train_loss = 1.00396697, grad/param norm = 1.8277e-01, time/batch = 16.7157s	
10239/26050 (epoch 19.653), train_loss = 1.08104191, grad/param norm = 1.7546e-01, time/batch = 17.7906s	
10240/26050 (epoch 19.655), train_loss = 0.99483359, grad/param norm = 1.7106e-01, time/batch = 18.4751s	
10241/26050 (epoch 19.656), train_loss = 0.92022576, grad/param norm = 1.6766e-01, time/batch = 17.5647s	
10242/26050 (epoch 19.658), train_loss = 1.25833747, grad/param norm = 1.9782e-01, time/batch = 18.9131s	
10243/26050 (epoch 19.660), train_loss = 0.94624917, grad/param norm = 1.7507e-01, time/batch = 18.2345s	
10244/26050 (epoch 19.662), train_loss = 0.99274127, grad/param norm = 1.7162e-01, time/batch = 16.1236s	
10245/26050 (epoch 19.664), train_loss = 1.04194258, grad/param norm = 1.7663e-01, time/batch = 18.2079s	
10246/26050 (epoch 19.666), train_loss = 1.04263363, grad/param norm = 1.9912e-01, time/batch = 18.6608s	
10247/26050 (epoch 19.668), train_loss = 0.89462101, grad/param norm = 1.8303e-01, time/batch = 17.8995s	
10248/26050 (epoch 19.670), train_loss = 1.20413109, grad/param norm = 2.0066e-01, time/batch = 17.0553s	
10249/26050 (epoch 19.672), train_loss = 1.03369540, grad/param norm = 1.7614e-01, time/batch = 17.9881s	
10250/26050 (epoch 19.674), train_loss = 0.97351390, grad/param norm = 1.7125e-01, time/batch = 16.3898s	
10251/26050 (epoch 19.676), train_loss = 1.11365819, grad/param norm = 1.9805e-01, time/batch = 17.2249s	
10252/26050 (epoch 19.678), train_loss = 1.18817760, grad/param norm = 2.0213e-01, time/batch = 16.9940s	
10253/26050 (epoch 19.679), train_loss = 1.24818605, grad/param norm = 1.9706e-01, time/batch = 18.7967s	
10254/26050 (epoch 19.681), train_loss = 1.07509084, grad/param norm = 1.8340e-01, time/batch = 16.4599s	
10255/26050 (epoch 19.683), train_loss = 0.96377768, grad/param norm = 1.9699e-01, time/batch = 14.8055s	
10256/26050 (epoch 19.685), train_loss = 1.00699575, grad/param norm = 1.7285e-01, time/batch = 17.7527s	
10257/26050 (epoch 19.687), train_loss = 0.90334348, grad/param norm = 1.6599e-01, time/batch = 18.3277s	
10258/26050 (epoch 19.689), train_loss = 1.03394664, grad/param norm = 1.8623e-01, time/batch = 17.5778s	
10259/26050 (epoch 19.691), train_loss = 0.83814729, grad/param norm = 1.5694e-01, time/batch = 16.7336s	
10260/26050 (epoch 19.693), train_loss = 0.95383706, grad/param norm = 1.7545e-01, time/batch = 17.2208s	
10261/26050 (epoch 19.695), train_loss = 1.06109066, grad/param norm = 1.7702e-01, time/batch = 18.4910s	
10262/26050 (epoch 19.697), train_loss = 0.96707766, grad/param norm = 1.7334e-01, time/batch = 16.3706s	
10263/26050 (epoch 19.699), train_loss = 1.10534333, grad/param norm = 1.8873e-01, time/batch = 17.4834s	
10264/26050 (epoch 19.701), train_loss = 0.95792618, grad/param norm = 1.6698e-01, time/batch = 18.7351s	
10265/26050 (epoch 19.702), train_loss = 1.17137602, grad/param norm = 1.8182e-01, time/batch = 17.9033s	
10266/26050 (epoch 19.704), train_loss = 1.14421068, grad/param norm = 1.6351e-01, time/batch = 18.4928s	
10267/26050 (epoch 19.706), train_loss = 1.04983950, grad/param norm = 1.9744e-01, time/batch = 17.8298s	
10268/26050 (epoch 19.708), train_loss = 1.14497644, grad/param norm = 1.8318e-01, time/batch = 17.1686s	
10269/26050 (epoch 19.710), train_loss = 1.13667482, grad/param norm = 2.0222e-01, time/batch = 18.2114s	
10270/26050 (epoch 19.712), train_loss = 1.13968024, grad/param norm = 1.8999e-01, time/batch = 15.7225s	
10271/26050 (epoch 19.714), train_loss = 0.90922000, grad/param norm = 1.6311e-01, time/batch = 18.0496s	
10272/26050 (epoch 19.716), train_loss = 1.30496288, grad/param norm = 2.0566e-01, time/batch = 17.1469s	
10273/26050 (epoch 19.718), train_loss = 1.16150234, grad/param norm = 1.8909e-01, time/batch = 16.2288s	
10274/26050 (epoch 19.720), train_loss = 1.03860161, grad/param norm = 1.9030e-01, time/batch = 17.2300s	
10275/26050 (epoch 19.722), train_loss = 0.93389312, grad/param norm = 1.7330e-01, time/batch = 15.0617s	
10276/26050 (epoch 19.724), train_loss = 0.97927616, grad/param norm = 1.8895e-01, time/batch = 17.0356s	
10277/26050 (epoch 19.726), train_loss = 1.14970714, grad/param norm = 1.9275e-01, time/batch = 17.9886s	
10278/26050 (epoch 19.727), train_loss = 1.14865325, grad/param norm = 1.9734e-01, time/batch = 18.5712s	
10279/26050 (epoch 19.729), train_loss = 1.10406511, grad/param norm = 1.8271e-01, time/batch = 17.6387s	
10280/26050 (epoch 19.731), train_loss = 1.10237083, grad/param norm = 1.9455e-01, time/batch = 18.1603s	
10281/26050 (epoch 19.733), train_loss = 1.02553965, grad/param norm = 2.1379e-01, time/batch = 18.5807s	
10282/26050 (epoch 19.735), train_loss = 1.25603261, grad/param norm = 1.9829e-01, time/batch = 16.8278s	
10283/26050 (epoch 19.737), train_loss = 1.00542183, grad/param norm = 1.7232e-01, time/batch = 14.7779s	
10284/26050 (epoch 19.739), train_loss = 1.08777550, grad/param norm = 1.7853e-01, time/batch = 18.4070s	
10285/26050 (epoch 19.741), train_loss = 0.97079996, grad/param norm = 1.7875e-01, time/batch = 18.6402s	
10286/26050 (epoch 19.743), train_loss = 1.09094105, grad/param norm = 2.0533e-01, time/batch = 26.3748s	
10287/26050 (epoch 19.745), train_loss = 0.93649414, grad/param norm = 1.6870e-01, time/batch = 30.3005s	
10288/26050 (epoch 19.747), train_loss = 0.95569479, grad/param norm = 1.6854e-01, time/batch = 15.9229s	
10289/26050 (epoch 19.749), train_loss = 1.18267294, grad/param norm = 1.9167e-01, time/batch = 18.3950s	
10290/26050 (epoch 19.750), train_loss = 1.04593111, grad/param norm = 1.6833e-01, time/batch = 18.4999s	
10291/26050 (epoch 19.752), train_loss = 1.03837516, grad/param norm = 1.9495e-01, time/batch = 17.4006s	
10292/26050 (epoch 19.754), train_loss = 1.08445077, grad/param norm = 1.8749e-01, time/batch = 17.9194s	
10293/26050 (epoch 19.756), train_loss = 1.06239327, grad/param norm = 1.9367e-01, time/batch = 17.3275s	
10294/26050 (epoch 19.758), train_loss = 1.05306705, grad/param norm = 1.9458e-01, time/batch = 18.4902s	
10295/26050 (epoch 19.760), train_loss = 1.23892758, grad/param norm = 1.8701e-01, time/batch = 15.6286s	
10296/26050 (epoch 19.762), train_loss = 0.99424122, grad/param norm = 1.7038e-01, time/batch = 18.4851s	
10297/26050 (epoch 19.764), train_loss = 1.08847298, grad/param norm = 1.9236e-01, time/batch = 18.5649s	
10298/26050 (epoch 19.766), train_loss = 1.12990318, grad/param norm = 1.9779e-01, time/batch = 16.9798s	
10299/26050 (epoch 19.768), train_loss = 0.95818300, grad/param norm = 1.6035e-01, time/batch = 16.9682s	
10300/26050 (epoch 19.770), train_loss = 1.05125421, grad/param norm = 1.9050e-01, time/batch = 15.6582s	
10301/26050 (epoch 19.772), train_loss = 1.04534944, grad/param norm = 1.6620e-01, time/batch = 18.1500s	
10302/26050 (epoch 19.774), train_loss = 0.91956867, grad/param norm = 1.6646e-01, time/batch = 17.3063s	
10303/26050 (epoch 19.775), train_loss = 0.76396393, grad/param norm = 1.6007e-01, time/batch = 18.0790s	
10304/26050 (epoch 19.777), train_loss = 0.98291381, grad/param norm = 1.7364e-01, time/batch = 17.9203s	
10305/26050 (epoch 19.779), train_loss = 1.03666040, grad/param norm = 1.9403e-01, time/batch = 16.8078s	
10306/26050 (epoch 19.781), train_loss = 0.97298483, grad/param norm = 1.9837e-01, time/batch = 18.4757s	
10307/26050 (epoch 19.783), train_loss = 0.95261671, grad/param norm = 1.8229e-01, time/batch = 17.5359s	
10308/26050 (epoch 19.785), train_loss = 1.04256954, grad/param norm = 1.7625e-01, time/batch = 17.6399s	
10309/26050 (epoch 19.787), train_loss = 0.97959525, grad/param norm = 1.7096e-01, time/batch = 16.7996s	
10310/26050 (epoch 19.789), train_loss = 1.00469819, grad/param norm = 2.1777e-01, time/batch = 17.8992s	
10311/26050 (epoch 19.791), train_loss = 1.00899384, grad/param norm = 1.8397e-01, time/batch = 18.4834s	
10312/26050 (epoch 19.793), train_loss = 1.04138428, grad/param norm = 1.9144e-01, time/batch = 14.5526s	
10313/26050 (epoch 19.795), train_loss = 0.86097085, grad/param norm = 1.4533e-01, time/batch = 18.4863s	
10314/26050 (epoch 19.797), train_loss = 0.96439586, grad/param norm = 1.5788e-01, time/batch = 18.8229s	
10315/26050 (epoch 19.798), train_loss = 0.89095824, grad/param norm = 1.6962e-01, time/batch = 14.6296s	
10316/26050 (epoch 19.800), train_loss = 0.90829040, grad/param norm = 1.5192e-01, time/batch = 18.5582s	
10317/26050 (epoch 19.802), train_loss = 1.00091142, grad/param norm = 1.8546e-01, time/batch = 18.1379s	
10318/26050 (epoch 19.804), train_loss = 1.02913072, grad/param norm = 1.8720e-01, time/batch = 18.3281s	
10319/26050 (epoch 19.806), train_loss = 1.14535088, grad/param norm = 1.9079e-01, time/batch = 17.6320s	
10320/26050 (epoch 19.808), train_loss = 1.04307449, grad/param norm = 1.7112e-01, time/batch = 18.6595s	
10321/26050 (epoch 19.810), train_loss = 0.99567868, grad/param norm = 1.8430e-01, time/batch = 18.5395s	
10322/26050 (epoch 19.812), train_loss = 0.95063042, grad/param norm = 1.8797e-01, time/batch = 17.1529s	
10323/26050 (epoch 19.814), train_loss = 0.94580413, grad/param norm = 2.0946e-01, time/batch = 18.1260s	
10324/26050 (epoch 19.816), train_loss = 1.15162380, grad/param norm = 2.0028e-01, time/batch = 17.4613s	
10325/26050 (epoch 19.818), train_loss = 1.16103816, grad/param norm = 2.1160e-01, time/batch = 17.5530s	
10326/26050 (epoch 19.820), train_loss = 1.06331011, grad/param norm = 1.7473e-01, time/batch = 17.8836s	
10327/26050 (epoch 19.821), train_loss = 1.19767559, grad/param norm = 2.0312e-01, time/batch = 18.3887s	
10328/26050 (epoch 19.823), train_loss = 1.19041227, grad/param norm = 1.9703e-01, time/batch = 17.8903s	
10329/26050 (epoch 19.825), train_loss = 1.03787400, grad/param norm = 1.8181e-01, time/batch = 17.8867s	
10330/26050 (epoch 19.827), train_loss = 1.06290404, grad/param norm = 2.0831e-01, time/batch = 18.4005s	
10331/26050 (epoch 19.829), train_loss = 1.15781403, grad/param norm = 1.9926e-01, time/batch = 17.0707s	
10332/26050 (epoch 19.831), train_loss = 1.17744016, grad/param norm = 1.9755e-01, time/batch = 17.0375s	
10333/26050 (epoch 19.833), train_loss = 1.26031074, grad/param norm = 1.9919e-01, time/batch = 18.5696s	
10334/26050 (epoch 19.835), train_loss = 1.24315704, grad/param norm = 1.9607e-01, time/batch = 17.6386s	
10335/26050 (epoch 19.837), train_loss = 1.05395424, grad/param norm = 1.7632e-01, time/batch = 17.5505s	
10336/26050 (epoch 19.839), train_loss = 1.09130604, grad/param norm = 2.1308e-01, time/batch = 18.3122s	
10337/26050 (epoch 19.841), train_loss = 1.19257833, grad/param norm = 2.0103e-01, time/batch = 18.3161s	
10338/26050 (epoch 19.843), train_loss = 1.05044787, grad/param norm = 1.7227e-01, time/batch = 18.0734s	
10339/26050 (epoch 19.845), train_loss = 1.00153765, grad/param norm = 1.6311e-01, time/batch = 14.9721s	
10340/26050 (epoch 19.846), train_loss = 1.14539924, grad/param norm = 1.7404e-01, time/batch = 16.6257s	
10341/26050 (epoch 19.848), train_loss = 1.04521621, grad/param norm = 1.7942e-01, time/batch = 18.8986s	
10342/26050 (epoch 19.850), train_loss = 0.96775522, grad/param norm = 1.6449e-01, time/batch = 15.9684s	
10343/26050 (epoch 19.852), train_loss = 1.06342931, grad/param norm = 1.7891e-01, time/batch = 18.5512s	
10344/26050 (epoch 19.854), train_loss = 1.03312868, grad/param norm = 1.7739e-01, time/batch = 17.4829s	
10345/26050 (epoch 19.856), train_loss = 1.02296394, grad/param norm = 1.8841e-01, time/batch = 17.9134s	
10346/26050 (epoch 19.858), train_loss = 0.95146519, grad/param norm = 1.7080e-01, time/batch = 18.4815s	
10347/26050 (epoch 19.860), train_loss = 1.08914317, grad/param norm = 1.8990e-01, time/batch = 18.3975s	
10348/26050 (epoch 19.862), train_loss = 1.11760445, grad/param norm = 1.7946e-01, time/batch = 18.2263s	
10349/26050 (epoch 19.864), train_loss = 1.09751476, grad/param norm = 2.1056e-01, time/batch = 17.1432s	
10350/26050 (epoch 19.866), train_loss = 1.00988963, grad/param norm = 1.6730e-01, time/batch = 16.0755s	
10351/26050 (epoch 19.868), train_loss = 1.10769957, grad/param norm = 1.8356e-01, time/batch = 15.3770s	
10352/26050 (epoch 19.869), train_loss = 0.94371299, grad/param norm = 1.6736e-01, time/batch = 17.1503s	
10353/26050 (epoch 19.871), train_loss = 0.88149120, grad/param norm = 1.6237e-01, time/batch = 17.6518s	
10354/26050 (epoch 19.873), train_loss = 1.09896888, grad/param norm = 2.0444e-01, time/batch = 18.2505s	
10355/26050 (epoch 19.875), train_loss = 1.04400119, grad/param norm = 1.9235e-01, time/batch = 18.2437s	
10356/26050 (epoch 19.877), train_loss = 0.95061389, grad/param norm = 1.7039e-01, time/batch = 14.4653s	
10357/26050 (epoch 19.879), train_loss = 1.07671840, grad/param norm = 1.7119e-01, time/batch = 18.3942s	
10358/26050 (epoch 19.881), train_loss = 1.16627137, grad/param norm = 1.9465e-01, time/batch = 16.4007s	
10359/26050 (epoch 19.883), train_loss = 1.10554004, grad/param norm = 1.8268e-01, time/batch = 17.1355s	
10360/26050 (epoch 19.885), train_loss = 0.78895855, grad/param norm = 1.5346e-01, time/batch = 18.1500s	
10361/26050 (epoch 19.887), train_loss = 1.10002417, grad/param norm = 1.8101e-01, time/batch = 17.9852s	
10362/26050 (epoch 19.889), train_loss = 1.01370245, grad/param norm = 1.7568e-01, time/batch = 18.6488s	
10363/26050 (epoch 19.891), train_loss = 0.85968860, grad/param norm = 1.5926e-01, time/batch = 15.5237s	
10364/26050 (epoch 19.893), train_loss = 0.91410371, grad/param norm = 1.6905e-01, time/batch = 18.2890s	
10365/26050 (epoch 19.894), train_loss = 1.01053964, grad/param norm = 1.7178e-01, time/batch = 18.4833s	
10366/26050 (epoch 19.896), train_loss = 1.14117562, grad/param norm = 1.7332e-01, time/batch = 17.7309s	
10367/26050 (epoch 19.898), train_loss = 0.98552071, grad/param norm = 1.7969e-01, time/batch = 18.9080s	
10368/26050 (epoch 19.900), train_loss = 1.08620720, grad/param norm = 1.8538e-01, time/batch = 17.5525s	
10369/26050 (epoch 19.902), train_loss = 1.03171587, grad/param norm = 1.7478e-01, time/batch = 17.9037s	
10370/26050 (epoch 19.904), train_loss = 1.03125050, grad/param norm = 1.7808e-01, time/batch = 14.4730s	
10371/26050 (epoch 19.906), train_loss = 1.03646694, grad/param norm = 1.9491e-01, time/batch = 18.4795s	
10372/26050 (epoch 19.908), train_loss = 1.03926232, grad/param norm = 1.7654e-01, time/batch = 17.9852s	
10373/26050 (epoch 19.910), train_loss = 0.98711756, grad/param norm = 1.6391e-01, time/batch = 16.8985s	
10374/26050 (epoch 19.912), train_loss = 1.25985723, grad/param norm = 2.0403e-01, time/batch = 17.5704s	
10375/26050 (epoch 19.914), train_loss = 1.40449786, grad/param norm = 2.2014e-01, time/batch = 18.5686s	
10376/26050 (epoch 19.916), train_loss = 1.16388435, grad/param norm = 2.0731e-01, time/batch = 17.1471s	
10377/26050 (epoch 19.917), train_loss = 1.07628041, grad/param norm = 2.1582e-01, time/batch = 18.8220s	
10378/26050 (epoch 19.919), train_loss = 1.14632745, grad/param norm = 2.1178e-01, time/batch = 17.9978s	
10379/26050 (epoch 19.921), train_loss = 1.00212307, grad/param norm = 1.9324e-01, time/batch = 16.7388s	
10380/26050 (epoch 19.923), train_loss = 1.06123093, grad/param norm = 1.8143e-01, time/batch = 17.0298s	
10381/26050 (epoch 19.925), train_loss = 1.05039396, grad/param norm = 1.8012e-01, time/batch = 18.7386s	
10382/26050 (epoch 19.927), train_loss = 0.92033158, grad/param norm = 1.4784e-01, time/batch = 18.3236s	
10383/26050 (epoch 19.929), train_loss = 0.91612010, grad/param norm = 1.7058e-01, time/batch = 17.4866s	
10384/26050 (epoch 19.931), train_loss = 1.24829838, grad/param norm = 2.1945e-01, time/batch = 14.9708s	
10385/26050 (epoch 19.933), train_loss = 0.99830675, grad/param norm = 1.7332e-01, time/batch = 16.8808s	
10386/26050 (epoch 19.935), train_loss = 1.03554505, grad/param norm = 1.8664e-01, time/batch = 17.4497s	
10387/26050 (epoch 19.937), train_loss = 1.14297716, grad/param norm = 1.8366e-01, time/batch = 17.4074s	
10388/26050 (epoch 19.939), train_loss = 0.96744325, grad/param norm = 1.5750e-01, time/batch = 18.7393s	
10389/26050 (epoch 19.940), train_loss = 1.02739673, grad/param norm = 1.6614e-01, time/batch = 18.3349s	
10390/26050 (epoch 19.942), train_loss = 1.04850384, grad/param norm = 1.8071e-01, time/batch = 17.3015s	
10391/26050 (epoch 19.944), train_loss = 0.98877240, grad/param norm = 1.6162e-01, time/batch = 16.4675s	
10392/26050 (epoch 19.946), train_loss = 1.18837752, grad/param norm = 1.9599e-01, time/batch = 18.5538s	
10393/26050 (epoch 19.948), train_loss = 0.94636475, grad/param norm = 1.9005e-01, time/batch = 17.0717s	
10394/26050 (epoch 19.950), train_loss = 1.01840430, grad/param norm = 1.7693e-01, time/batch = 18.3220s	
10395/26050 (epoch 19.952), train_loss = 1.15727343, grad/param norm = 1.9752e-01, time/batch = 17.5546s	
10396/26050 (epoch 19.954), train_loss = 1.15651309, grad/param norm = 1.9118e-01, time/batch = 17.3121s	
10397/26050 (epoch 19.956), train_loss = 1.05286742, grad/param norm = 1.8950e-01, time/batch = 16.8687s	
10398/26050 (epoch 19.958), train_loss = 0.99342159, grad/param norm = 1.7008e-01, time/batch = 18.6382s	
10399/26050 (epoch 19.960), train_loss = 1.06760348, grad/param norm = 1.8761e-01, time/batch = 18.4994s	
10400/26050 (epoch 19.962), train_loss = 0.97765247, grad/param norm = 1.5650e-01, time/batch = 17.1471s	
10401/26050 (epoch 19.964), train_loss = 1.04523472, grad/param norm = 1.8414e-01, time/batch = 15.1378s	
10402/26050 (epoch 19.965), train_loss = 0.97468721, grad/param norm = 1.7995e-01, time/batch = 17.8956s	
10403/26050 (epoch 19.967), train_loss = 1.37616023, grad/param norm = 1.9845e-01, time/batch = 15.5591s	
10404/26050 (epoch 19.969), train_loss = 1.04143019, grad/param norm = 1.7520e-01, time/batch = 17.2055s	
10405/26050 (epoch 19.971), train_loss = 1.00158689, grad/param norm = 1.6187e-01, time/batch = 17.6626s	
10406/26050 (epoch 19.973), train_loss = 1.04008363, grad/param norm = 1.8674e-01, time/batch = 17.8222s	
10407/26050 (epoch 19.975), train_loss = 1.08143293, grad/param norm = 1.6765e-01, time/batch = 16.8244s	
10408/26050 (epoch 19.977), train_loss = 1.08066940, grad/param norm = 1.6362e-01, time/batch = 18.7312s	
10409/26050 (epoch 19.979), train_loss = 0.88646081, grad/param norm = 1.6874e-01, time/batch = 18.8984s	
10410/26050 (epoch 19.981), train_loss = 1.18091102, grad/param norm = 1.7225e-01, time/batch = 17.3041s	
10411/26050 (epoch 19.983), train_loss = 1.13893051, grad/param norm = 2.1206e-01, time/batch = 17.2897s	
10412/26050 (epoch 19.985), train_loss = 1.10949976, grad/param norm = 1.8891e-01, time/batch = 15.0660s	
10413/26050 (epoch 19.987), train_loss = 1.16033191, grad/param norm = 1.7784e-01, time/batch = 18.2335s	
10414/26050 (epoch 19.988), train_loss = 1.14826179, grad/param norm = 1.9068e-01, time/batch = 17.5679s	
10415/26050 (epoch 19.990), train_loss = 0.94150737, grad/param norm = 1.5239e-01, time/batch = 18.6495s	
10416/26050 (epoch 19.992), train_loss = 1.21865335, grad/param norm = 2.0164e-01, time/batch = 17.9107s	
10417/26050 (epoch 19.994), train_loss = 1.02745981, grad/param norm = 1.9576e-01, time/batch = 17.7317s	
10418/26050 (epoch 19.996), train_loss = 1.00939404, grad/param norm = 1.9083e-01, time/batch = 18.4861s	
10419/26050 (epoch 19.998), train_loss = 1.05756894, grad/param norm = 1.6616e-01, time/batch = 17.1510s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
10420/26050 (epoch 20.000), train_loss = 1.00792353, grad/param norm = 1.9161e-01, time/batch = 17.0591s	
10421/26050 (epoch 20.002), train_loss = 1.12647427, grad/param norm = 2.0029e-01, time/batch = 18.6344s	
10422/26050 (epoch 20.004), train_loss = 0.96585121, grad/param norm = 1.7772e-01, time/batch = 15.3882s	
10423/26050 (epoch 20.006), train_loss = 0.99866725, grad/param norm = 1.8554e-01, time/batch = 16.5418s	
10424/26050 (epoch 20.008), train_loss = 0.96287615, grad/param norm = 1.8864e-01, time/batch = 15.6442s	
10425/26050 (epoch 20.010), train_loss = 0.97634437, grad/param norm = 1.8276e-01, time/batch = 16.7474s	
10426/26050 (epoch 20.012), train_loss = 1.05766842, grad/param norm = 1.7855e-01, time/batch = 18.5792s	
10427/26050 (epoch 20.013), train_loss = 1.36216590, grad/param norm = 2.0809e-01, time/batch = 18.1480s	
10428/26050 (epoch 20.015), train_loss = 1.00151305, grad/param norm = 1.5505e-01, time/batch = 18.6169s	
10429/26050 (epoch 20.017), train_loss = 1.06147664, grad/param norm = 1.7646e-01, time/batch = 15.2403s	
10430/26050 (epoch 20.019), train_loss = 0.90464343, grad/param norm = 1.5749e-01, time/batch = 18.4803s	
10431/26050 (epoch 20.021), train_loss = 1.11301648, grad/param norm = 1.8283e-01, time/batch = 17.3903s	
10432/26050 (epoch 20.023), train_loss = 0.88066326, grad/param norm = 1.6616e-01, time/batch = 18.8133s	
10433/26050 (epoch 20.025), train_loss = 1.05146888, grad/param norm = 1.7743e-01, time/batch = 18.0712s	
10434/26050 (epoch 20.027), train_loss = 0.84984600, grad/param norm = 1.7534e-01, time/batch = 17.1439s	
10435/26050 (epoch 20.029), train_loss = 1.06566043, grad/param norm = 1.6559e-01, time/batch = 18.3202s	
10436/26050 (epoch 20.031), train_loss = 1.18378969, grad/param norm = 2.1152e-01, time/batch = 15.6568s	
10437/26050 (epoch 20.033), train_loss = 1.07425010, grad/param norm = 1.8259e-01, time/batch = 18.7193s	
10438/26050 (epoch 20.035), train_loss = 1.10128978, grad/param norm = 1.8159e-01, time/batch = 16.3798s	
10439/26050 (epoch 20.036), train_loss = 0.95691463, grad/param norm = 1.8861e-01, time/batch = 18.5687s	
10440/26050 (epoch 20.038), train_loss = 0.87941468, grad/param norm = 1.7487e-01, time/batch = 17.9919s	
10441/26050 (epoch 20.040), train_loss = 1.03676947, grad/param norm = 1.8474e-01, time/batch = 17.5682s	
10442/26050 (epoch 20.042), train_loss = 0.90281867, grad/param norm = 1.8930e-01, time/batch = 17.0535s	
10443/26050 (epoch 20.044), train_loss = 1.12931466, grad/param norm = 1.6580e-01, time/batch = 18.1562s	
10444/26050 (epoch 20.046), train_loss = 0.84693042, grad/param norm = 1.5048e-01, time/batch = 17.5697s	
10445/26050 (epoch 20.048), train_loss = 1.05738470, grad/param norm = 1.8099e-01, time/batch = 17.8138s	
10446/26050 (epoch 20.050), train_loss = 0.97680344, grad/param norm = 1.7145e-01, time/batch = 15.5482s	
10447/26050 (epoch 20.052), train_loss = 0.99420663, grad/param norm = 1.9459e-01, time/batch = 17.3063s	
10448/26050 (epoch 20.054), train_loss = 0.88364646, grad/param norm = 1.5735e-01, time/batch = 17.0248s	
10449/26050 (epoch 20.056), train_loss = 0.84610637, grad/param norm = 1.5334e-01, time/batch = 18.2271s	
10450/26050 (epoch 20.058), train_loss = 0.99980232, grad/param norm = 1.6905e-01, time/batch = 18.7949s	
10451/26050 (epoch 20.060), train_loss = 1.10814436, grad/param norm = 1.8243e-01, time/batch = 17.8068s	
10452/26050 (epoch 20.061), train_loss = 0.94828816, grad/param norm = 1.7368e-01, time/batch = 18.2413s	
10453/26050 (epoch 20.063), train_loss = 1.08560596, grad/param norm = 1.8059e-01, time/batch = 18.5478s	
10454/26050 (epoch 20.065), train_loss = 0.84907681, grad/param norm = 1.5166e-01, time/batch = 18.2284s	
10455/26050 (epoch 20.067), train_loss = 1.04979621, grad/param norm = 1.7634e-01, time/batch = 16.8188s	
10456/26050 (epoch 20.069), train_loss = 1.09199883, grad/param norm = 1.7498e-01, time/batch = 18.6374s	
10457/26050 (epoch 20.071), train_loss = 1.10799556, grad/param norm = 1.7948e-01, time/batch = 18.1672s	
10458/26050 (epoch 20.073), train_loss = 1.22928803, grad/param norm = 2.0047e-01, time/batch = 15.4519s	
10459/26050 (epoch 20.075), train_loss = 0.95914218, grad/param norm = 1.6636e-01, time/batch = 18.2171s	
10460/26050 (epoch 20.077), train_loss = 0.97859958, grad/param norm = 1.7518e-01, time/batch = 18.9788s	
10461/26050 (epoch 20.079), train_loss = 1.07009801, grad/param norm = 1.8557e-01, time/batch = 17.8066s	
10462/26050 (epoch 20.081), train_loss = 1.00128700, grad/param norm = 1.6678e-01, time/batch = 18.3091s	
10463/26050 (epoch 20.083), train_loss = 1.13011909, grad/param norm = 1.7511e-01, time/batch = 18.2424s	
10464/26050 (epoch 20.084), train_loss = 1.05407157, grad/param norm = 1.9088e-01, time/batch = 17.6541s	
10465/26050 (epoch 20.086), train_loss = 1.20585440, grad/param norm = 2.0556e-01, time/batch = 15.3901s	
10466/26050 (epoch 20.088), train_loss = 0.96288572, grad/param norm = 1.7736e-01, time/batch = 18.3945s	
10467/26050 (epoch 20.090), train_loss = 1.06248265, grad/param norm = 1.8361e-01, time/batch = 15.2312s	
10468/26050 (epoch 20.092), train_loss = 1.10065912, grad/param norm = 1.7928e-01, time/batch = 17.5688s	
10469/26050 (epoch 20.094), train_loss = 0.98467439, grad/param norm = 1.7939e-01, time/batch = 18.7185s	
10470/26050 (epoch 20.096), train_loss = 1.02491840, grad/param norm = 1.6981e-01, time/batch = 17.9053s	
10471/26050 (epoch 20.098), train_loss = 0.99579754, grad/param norm = 1.9053e-01, time/batch = 18.3092s	
10472/26050 (epoch 20.100), train_loss = 0.94013160, grad/param norm = 1.8014e-01, time/batch = 17.8038s	
10473/26050 (epoch 20.102), train_loss = 1.07280896, grad/param norm = 1.8033e-01, time/batch = 18.1634s	
10474/26050 (epoch 20.104), train_loss = 1.03682777, grad/param norm = 1.8575e-01, time/batch = 18.8179s	
10475/26050 (epoch 20.106), train_loss = 1.04296072, grad/param norm = 1.9810e-01, time/batch = 17.2192s	
10476/26050 (epoch 20.107), train_loss = 0.83593667, grad/param norm = 1.6118e-01, time/batch = 17.0574s	
10477/26050 (epoch 20.109), train_loss = 0.96179732, grad/param norm = 1.8081e-01, time/batch = 15.3590s	
10478/26050 (epoch 20.111), train_loss = 1.21626271, grad/param norm = 1.9693e-01, time/batch = 16.4745s	
10479/26050 (epoch 20.113), train_loss = 0.98347003, grad/param norm = 1.7761e-01, time/batch = 18.3987s	
10480/26050 (epoch 20.115), train_loss = 1.12838710, grad/param norm = 1.7445e-01, time/batch = 17.9062s	
10481/26050 (epoch 20.117), train_loss = 1.05961194, grad/param norm = 1.7535e-01, time/batch = 18.4947s	
10482/26050 (epoch 20.119), train_loss = 0.87351451, grad/param norm = 1.7154e-01, time/batch = 18.4750s	
10483/26050 (epoch 20.121), train_loss = 1.06395799, grad/param norm = 1.7166e-01, time/batch = 17.6641s	
10484/26050 (epoch 20.123), train_loss = 0.93898625, grad/param norm = 1.6327e-01, time/batch = 17.7454s	
10485/26050 (epoch 20.125), train_loss = 0.89120567, grad/param norm = 1.6691e-01, time/batch = 17.3993s	
10486/26050 (epoch 20.127), train_loss = 0.83101256, grad/param norm = 1.7649e-01, time/batch = 18.9055s	
10487/26050 (epoch 20.129), train_loss = 0.89226797, grad/param norm = 1.7727e-01, time/batch = 14.6879s	
10488/26050 (epoch 20.131), train_loss = 1.00083107, grad/param norm = 1.6825e-01, time/batch = 17.9754s	
10489/26050 (epoch 20.132), train_loss = 1.00331660, grad/param norm = 1.5976e-01, time/batch = 32.0147s	
10490/26050 (epoch 20.134), train_loss = 1.04565750, grad/param norm = 2.0446e-01, time/batch = 24.3867s	
10491/26050 (epoch 20.136), train_loss = 1.03707110, grad/param norm = 1.7612e-01, time/batch = 15.7217s	
10492/26050 (epoch 20.138), train_loss = 0.78539665, grad/param norm = 1.5493e-01, time/batch = 18.1439s	
10493/26050 (epoch 20.140), train_loss = 0.85729036, grad/param norm = 1.7372e-01, time/batch = 18.0746s	
10494/26050 (epoch 20.142), train_loss = 0.89777767, grad/param norm = 1.8878e-01, time/batch = 18.0632s	
10495/26050 (epoch 20.144), train_loss = 0.83414867, grad/param norm = 1.7177e-01, time/batch = 18.4001s	
10496/26050 (epoch 20.146), train_loss = 0.78539790, grad/param norm = 1.6690e-01, time/batch = 15.6664s	
10497/26050 (epoch 20.148), train_loss = 0.81427966, grad/param norm = 1.4440e-01, time/batch = 17.8830s	
10498/26050 (epoch 20.150), train_loss = 0.99752770, grad/param norm = 1.8102e-01, time/batch = 16.4683s	
10499/26050 (epoch 20.152), train_loss = 1.22170707, grad/param norm = 2.3680e-01, time/batch = 18.6273s	
10500/26050 (epoch 20.154), train_loss = 0.80872236, grad/param norm = 1.6369e-01, time/batch = 18.1538s	
10501/26050 (epoch 20.155), train_loss = 0.85388196, grad/param norm = 1.6560e-01, time/batch = 16.7357s	
10502/26050 (epoch 20.157), train_loss = 0.96876982, grad/param norm = 2.0401e-01, time/batch = 18.3967s	
10503/26050 (epoch 20.159), train_loss = 1.02716050, grad/param norm = 1.9074e-01, time/batch = 17.8258s	
10504/26050 (epoch 20.161), train_loss = 1.07491854, grad/param norm = 1.9188e-01, time/batch = 14.3069s	
10505/26050 (epoch 20.163), train_loss = 0.84389886, grad/param norm = 1.7134e-01, time/batch = 15.8811s	
10506/26050 (epoch 20.165), train_loss = 0.78473512, grad/param norm = 1.6149e-01, time/batch = 14.8980s	
10507/26050 (epoch 20.167), train_loss = 1.11725618, grad/param norm = 1.8893e-01, time/batch = 17.9877s	
10508/26050 (epoch 20.169), train_loss = 1.05633950, grad/param norm = 1.9589e-01, time/batch = 17.0733s	
10509/26050 (epoch 20.171), train_loss = 0.85327274, grad/param norm = 1.6007e-01, time/batch = 18.8166s	
10510/26050 (epoch 20.173), train_loss = 0.96059649, grad/param norm = 1.9261e-01, time/batch = 18.3913s	
10511/26050 (epoch 20.175), train_loss = 0.98025346, grad/param norm = 1.6076e-01, time/batch = 17.3914s	
10512/26050 (epoch 20.177), train_loss = 1.12389588, grad/param norm = 1.7756e-01, time/batch = 16.4871s	
10513/26050 (epoch 20.179), train_loss = 0.78783167, grad/param norm = 1.5875e-01, time/batch = 17.0591s	
10514/26050 (epoch 20.180), train_loss = 1.22342098, grad/param norm = 1.8252e-01, time/batch = 18.8124s	
10515/26050 (epoch 20.182), train_loss = 1.24272917, grad/param norm = 1.8867e-01, time/batch = 17.8919s	
10516/26050 (epoch 20.184), train_loss = 1.04244529, grad/param norm = 1.7335e-01, time/batch = 14.9063s	
10517/26050 (epoch 20.186), train_loss = 0.86035942, grad/param norm = 1.6147e-01, time/batch = 18.4127s	
10518/26050 (epoch 20.188), train_loss = 1.00798812, grad/param norm = 1.8144e-01, time/batch = 18.0492s	
10519/26050 (epoch 20.190), train_loss = 1.07420743, grad/param norm = 1.8710e-01, time/batch = 18.5698s	
10520/26050 (epoch 20.192), train_loss = 1.07135193, grad/param norm = 1.6511e-01, time/batch = 17.7159s	
10521/26050 (epoch 20.194), train_loss = 1.07310598, grad/param norm = 1.8723e-01, time/batch = 17.9802s	
10522/26050 (epoch 20.196), train_loss = 1.12450349, grad/param norm = 1.9264e-01, time/batch = 18.3739s	
10523/26050 (epoch 20.198), train_loss = 0.93725560, grad/param norm = 1.6668e-01, time/batch = 16.5448s	
10524/26050 (epoch 20.200), train_loss = 0.93176972, grad/param norm = 1.7287e-01, time/batch = 15.2934s	
10525/26050 (epoch 20.202), train_loss = 1.02546962, grad/param norm = 1.8496e-01, time/batch = 17.2274s	
10526/26050 (epoch 20.203), train_loss = 1.14179392, grad/param norm = 2.0046e-01, time/batch = 16.3858s	
10527/26050 (epoch 20.205), train_loss = 0.95757186, grad/param norm = 1.7047e-01, time/batch = 18.2348s	
10528/26050 (epoch 20.207), train_loss = 0.95416215, grad/param norm = 1.6819e-01, time/batch = 18.2551s	
10529/26050 (epoch 20.209), train_loss = 1.06073773, grad/param norm = 1.6801e-01, time/batch = 18.2942s	
10530/26050 (epoch 20.211), train_loss = 0.86502060, grad/param norm = 1.5842e-01, time/batch = 18.3125s	
10531/26050 (epoch 20.213), train_loss = 1.07373908, grad/param norm = 1.9032e-01, time/batch = 14.4859s	
10532/26050 (epoch 20.215), train_loss = 1.01282781, grad/param norm = 1.9321e-01, time/batch = 17.3106s	
10533/26050 (epoch 20.217), train_loss = 0.97982364, grad/param norm = 1.7036e-01, time/batch = 18.7242s	
10534/26050 (epoch 20.219), train_loss = 1.00995025, grad/param norm = 1.9683e-01, time/batch = 19.1496s	
10535/26050 (epoch 20.221), train_loss = 0.92837242, grad/param norm = 1.8157e-01, time/batch = 17.2320s	
10536/26050 (epoch 20.223), train_loss = 1.05415607, grad/param norm = 1.8862e-01, time/batch = 17.8260s	
10537/26050 (epoch 20.225), train_loss = 0.91376156, grad/param norm = 1.8488e-01, time/batch = 15.4875s	
10538/26050 (epoch 20.226), train_loss = 1.06829184, grad/param norm = 2.0673e-01, time/batch = 18.2120s	
10539/26050 (epoch 20.228), train_loss = 1.15536777, grad/param norm = 1.9094e-01, time/batch = 16.8092s	
10540/26050 (epoch 20.230), train_loss = 1.05796384, grad/param norm = 1.7275e-01, time/batch = 18.4149s	
10541/26050 (epoch 20.232), train_loss = 1.11331160, grad/param norm = 1.9947e-01, time/batch = 18.2357s	
10542/26050 (epoch 20.234), train_loss = 0.90831382, grad/param norm = 1.7472e-01, time/batch = 17.4927s	
10543/26050 (epoch 20.236), train_loss = 1.11751443, grad/param norm = 2.0074e-01, time/batch = 17.4780s	
10544/26050 (epoch 20.238), train_loss = 0.89028128, grad/param norm = 1.6820e-01, time/batch = 16.1274s	
10545/26050 (epoch 20.240), train_loss = 1.02262619, grad/param norm = 1.8133e-01, time/batch = 14.3001s	
10546/26050 (epoch 20.242), train_loss = 1.02660635, grad/param norm = 1.7161e-01, time/batch = 14.6201s	
10547/26050 (epoch 20.244), train_loss = 1.02771322, grad/param norm = 2.0466e-01, time/batch = 15.5358s	
10548/26050 (epoch 20.246), train_loss = 0.95103759, grad/param norm = 1.6506e-01, time/batch = 14.4424s	
10549/26050 (epoch 20.248), train_loss = 1.03353376, grad/param norm = 1.7697e-01, time/batch = 15.3063s	
10550/26050 (epoch 20.250), train_loss = 1.02294716, grad/param norm = 1.9818e-01, time/batch = 16.8040s	
10551/26050 (epoch 20.251), train_loss = 0.98844355, grad/param norm = 1.7040e-01, time/batch = 14.8916s	
10552/26050 (epoch 20.253), train_loss = 0.89482066, grad/param norm = 1.7186e-01, time/batch = 19.1485s	
10553/26050 (epoch 20.255), train_loss = 1.19507458, grad/param norm = 1.9450e-01, time/batch = 17.7429s	
10554/26050 (epoch 20.257), train_loss = 1.01599707, grad/param norm = 2.0468e-01, time/batch = 18.1577s	
10555/26050 (epoch 20.259), train_loss = 1.16889185, grad/param norm = 1.9834e-01, time/batch = 18.3152s	
10556/26050 (epoch 20.261), train_loss = 0.92021312, grad/param norm = 1.8379e-01, time/batch = 18.3325s	
10557/26050 (epoch 20.263), train_loss = 1.08812332, grad/param norm = 1.9243e-01, time/batch = 7.9824s	
10558/26050 (epoch 20.265), train_loss = 1.17213300, grad/param norm = 1.8238e-01, time/batch = 0.6513s	
10559/26050 (epoch 20.267), train_loss = 1.13596287, grad/param norm = 1.6985e-01, time/batch = 0.6506s	
10560/26050 (epoch 20.269), train_loss = 1.15993082, grad/param norm = 1.8789e-01, time/batch = 0.6571s	
10561/26050 (epoch 20.271), train_loss = 1.07467640, grad/param norm = 1.8550e-01, time/batch = 0.6605s	
10562/26050 (epoch 20.273), train_loss = 0.98626320, grad/param norm = 2.0141e-01, time/batch = 0.6521s	
10563/26050 (epoch 20.274), train_loss = 0.99881500, grad/param norm = 1.6897e-01, time/batch = 0.6569s	
10564/26050 (epoch 20.276), train_loss = 0.98262280, grad/param norm = 1.8414e-01, time/batch = 0.6519s	
10565/26050 (epoch 20.278), train_loss = 1.15325444, grad/param norm = 1.7551e-01, time/batch = 0.9089s	
10566/26050 (epoch 20.280), train_loss = 1.02517445, grad/param norm = 1.6975e-01, time/batch = 0.9651s	
10567/26050 (epoch 20.282), train_loss = 1.06806336, grad/param norm = 1.8965e-01, time/batch = 0.9452s	
10568/26050 (epoch 20.284), train_loss = 0.97993232, grad/param norm = 1.8283e-01, time/batch = 0.9396s	
10569/26050 (epoch 20.286), train_loss = 1.05159696, grad/param norm = 2.0050e-01, time/batch = 0.9405s	
10570/26050 (epoch 20.288), train_loss = 0.88247515, grad/param norm = 1.6191e-01, time/batch = 1.4386s	
10571/26050 (epoch 20.290), train_loss = 1.04393464, grad/param norm = 1.7997e-01, time/batch = 1.8110s	
10572/26050 (epoch 20.292), train_loss = 0.93375158, grad/param norm = 1.5929e-01, time/batch = 1.7631s	
10573/26050 (epoch 20.294), train_loss = 1.04895694, grad/param norm = 2.1241e-01, time/batch = 15.6460s	
10574/26050 (epoch 20.296), train_loss = 1.12272237, grad/param norm = 1.7997e-01, time/batch = 18.1423s	
10575/26050 (epoch 20.298), train_loss = 1.02842547, grad/param norm = 1.6469e-01, time/batch = 17.0412s	
10576/26050 (epoch 20.299), train_loss = 0.82351204, grad/param norm = 1.4632e-01, time/batch = 17.6488s	
10577/26050 (epoch 20.301), train_loss = 0.90655900, grad/param norm = 1.8039e-01, time/batch = 18.4826s	
10578/26050 (epoch 20.303), train_loss = 1.02105699, grad/param norm = 1.8789e-01, time/batch = 15.3796s	
10579/26050 (epoch 20.305), train_loss = 0.86165048, grad/param norm = 1.8262e-01, time/batch = 17.3020s	
10580/26050 (epoch 20.307), train_loss = 0.94487309, grad/param norm = 1.7783e-01, time/batch = 17.8296s	
10581/26050 (epoch 20.309), train_loss = 1.00858607, grad/param norm = 2.0787e-01, time/batch = 18.8998s	
10582/26050 (epoch 20.311), train_loss = 1.12829151, grad/param norm = 2.2285e-01, time/batch = 18.3792s	
10583/26050 (epoch 20.313), train_loss = 1.02935078, grad/param norm = 2.3337e-01, time/batch = 18.4022s	
10584/26050 (epoch 20.315), train_loss = 1.13486423, grad/param norm = 1.9406e-01, time/batch = 18.1663s	
10585/26050 (epoch 20.317), train_loss = 1.03811419, grad/param norm = 1.8154e-01, time/batch = 16.4151s	
10586/26050 (epoch 20.319), train_loss = 0.95195907, grad/param norm = 1.7875e-01, time/batch = 18.7416s	
10587/26050 (epoch 20.321), train_loss = 0.98780647, grad/param norm = 1.7253e-01, time/batch = 15.3144s	
10588/26050 (epoch 20.322), train_loss = 1.04866161, grad/param norm = 1.6880e-01, time/batch = 14.8022s	
10589/26050 (epoch 20.324), train_loss = 0.85975875, grad/param norm = 1.8215e-01, time/batch = 20.6022s	
10590/26050 (epoch 20.326), train_loss = 1.16199527, grad/param norm = 2.1569e-01, time/batch = 20.5684s	
10591/26050 (epoch 20.328), train_loss = 1.06675872, grad/param norm = 1.8422e-01, time/batch = 23.5911s	
10592/26050 (epoch 20.330), train_loss = 0.91450561, grad/param norm = 1.6749e-01, time/batch = 24.4760s	
10593/26050 (epoch 20.332), train_loss = 1.07491842, grad/param norm = 1.7467e-01, time/batch = 25.0104s	
10594/26050 (epoch 20.334), train_loss = 0.97979286, grad/param norm = 1.9597e-01, time/batch = 23.9230s	
10595/26050 (epoch 20.336), train_loss = 0.97470833, grad/param norm = 1.8605e-01, time/batch = 21.9107s	
10596/26050 (epoch 20.338), train_loss = 0.90031764, grad/param norm = 1.5225e-01, time/batch = 18.2237s	
10597/26050 (epoch 20.340), train_loss = 1.12243054, grad/param norm = 1.8910e-01, time/batch = 23.3824s	
10598/26050 (epoch 20.342), train_loss = 1.14020457, grad/param norm = 1.8776e-01, time/batch = 22.4760s	
10599/26050 (epoch 20.344), train_loss = 0.97181593, grad/param norm = 1.8974e-01, time/batch = 23.2487s	
10600/26050 (epoch 20.345), train_loss = 1.00913400, grad/param norm = 2.0305e-01, time/batch = 24.2292s	
10601/26050 (epoch 20.347), train_loss = 1.15313138, grad/param norm = 1.9243e-01, time/batch = 24.3166s	
10602/26050 (epoch 20.349), train_loss = 1.08564791, grad/param norm = 1.9698e-01, time/batch = 22.4899s	
10603/26050 (epoch 20.351), train_loss = 1.05134288, grad/param norm = 1.7772e-01, time/batch = 23.8415s	
10604/26050 (epoch 20.353), train_loss = 1.02905209, grad/param norm = 1.8070e-01, time/batch = 19.4353s	
10605/26050 (epoch 20.355), train_loss = 1.08548494, grad/param norm = 2.0500e-01, time/batch = 33.8651s	
10606/26050 (epoch 20.357), train_loss = 0.95830593, grad/param norm = 1.6887e-01, time/batch = 18.7125s	
10607/26050 (epoch 20.359), train_loss = 1.12791047, grad/param norm = 1.8739e-01, time/batch = 17.8032s	
10608/26050 (epoch 20.361), train_loss = 0.94594855, grad/param norm = 1.6778e-01, time/batch = 14.6458s	
10609/26050 (epoch 20.363), train_loss = 1.09671700, grad/param norm = 1.8137e-01, time/batch = 16.1443s	
10610/26050 (epoch 20.365), train_loss = 0.98936673, grad/param norm = 1.6040e-01, time/batch = 16.3937s	
10611/26050 (epoch 20.367), train_loss = 1.07744022, grad/param norm = 1.7190e-01, time/batch = 18.7434s	
10612/26050 (epoch 20.369), train_loss = 0.97708233, grad/param norm = 1.6341e-01, time/batch = 17.0934s	
10613/26050 (epoch 20.370), train_loss = 0.91462172, grad/param norm = 1.5570e-01, time/batch = 13.9178s	
10614/26050 (epoch 20.372), train_loss = 1.08700754, grad/param norm = 1.9106e-01, time/batch = 14.0737s	
10615/26050 (epoch 20.374), train_loss = 1.16111280, grad/param norm = 1.8570e-01, time/batch = 14.0137s	
10616/26050 (epoch 20.376), train_loss = 1.24672786, grad/param norm = 1.9853e-01, time/batch = 13.8456s	
10617/26050 (epoch 20.378), train_loss = 0.98371734, grad/param norm = 1.6954e-01, time/batch = 16.7203s	
10618/26050 (epoch 20.380), train_loss = 1.22671076, grad/param norm = 2.2534e-01, time/batch = 16.8910s	
10619/26050 (epoch 20.382), train_loss = 1.29586258, grad/param norm = 2.2139e-01, time/batch = 17.8207s	
10620/26050 (epoch 20.384), train_loss = 1.03379324, grad/param norm = 2.0251e-01, time/batch = 16.7210s	
10621/26050 (epoch 20.386), train_loss = 1.10962806, grad/param norm = 2.1787e-01, time/batch = 17.3286s	
10622/26050 (epoch 20.388), train_loss = 1.04685664, grad/param norm = 1.8218e-01, time/batch = 17.7312s	
10623/26050 (epoch 20.390), train_loss = 0.96914577, grad/param norm = 1.7467e-01, time/batch = 18.5757s	
10624/26050 (epoch 20.392), train_loss = 0.91044418, grad/param norm = 1.5692e-01, time/batch = 15.1546s	
10625/26050 (epoch 20.393), train_loss = 1.07982314, grad/param norm = 1.9158e-01, time/batch = 16.3204s	
10626/26050 (epoch 20.395), train_loss = 1.07864270, grad/param norm = 1.6997e-01, time/batch = 17.7321s	
10627/26050 (epoch 20.397), train_loss = 1.08229514, grad/param norm = 1.9727e-01, time/batch = 17.9715s	
10628/26050 (epoch 20.399), train_loss = 0.96052342, grad/param norm = 1.9225e-01, time/batch = 17.4021s	
10629/26050 (epoch 20.401), train_loss = 1.03564242, grad/param norm = 1.9835e-01, time/batch = 17.5577s	
10630/26050 (epoch 20.403), train_loss = 1.05187995, grad/param norm = 1.8938e-01, time/batch = 18.3126s	
10631/26050 (epoch 20.405), train_loss = 1.05794722, grad/param norm = 1.8149e-01, time/batch = 16.5687s	
10632/26050 (epoch 20.407), train_loss = 1.18764982, grad/param norm = 1.8783e-01, time/batch = 15.2971s	
10633/26050 (epoch 20.409), train_loss = 1.20742779, grad/param norm = 2.0048e-01, time/batch = 17.1449s	
10634/26050 (epoch 20.411), train_loss = 1.10053886, grad/param norm = 1.9911e-01, time/batch = 17.8312s	
10635/26050 (epoch 20.413), train_loss = 1.19981472, grad/param norm = 1.7845e-01, time/batch = 17.4765s	
10636/26050 (epoch 20.415), train_loss = 1.15565115, grad/param norm = 1.8392e-01, time/batch = 17.1450s	
10637/26050 (epoch 20.417), train_loss = 1.24781419, grad/param norm = 1.9180e-01, time/batch = 18.4918s	
10638/26050 (epoch 20.418), train_loss = 1.15933387, grad/param norm = 2.1312e-01, time/batch = 18.4772s	
10639/26050 (epoch 20.420), train_loss = 0.88946277, grad/param norm = 1.6639e-01, time/batch = 15.6365s	
10640/26050 (epoch 20.422), train_loss = 0.89362912, grad/param norm = 1.7612e-01, time/batch = 18.0749s	
10641/26050 (epoch 20.424), train_loss = 1.17645390, grad/param norm = 2.0537e-01, time/batch = 18.1561s	
10642/26050 (epoch 20.426), train_loss = 1.15381173, grad/param norm = 1.8412e-01, time/batch = 17.2277s	
10643/26050 (epoch 20.428), train_loss = 0.97156814, grad/param norm = 1.6069e-01, time/batch = 18.5568s	
10644/26050 (epoch 20.430), train_loss = 1.15671552, grad/param norm = 1.7770e-01, time/batch = 18.0711s	
10645/26050 (epoch 20.432), train_loss = 1.01048285, grad/param norm = 1.7612e-01, time/batch = 16.6306s	
10646/26050 (epoch 20.434), train_loss = 1.02115389, grad/param norm = 1.9640e-01, time/batch = 16.5539s	
10647/26050 (epoch 20.436), train_loss = 1.16591282, grad/param norm = 1.9404e-01, time/batch = 17.8854s	
10648/26050 (epoch 20.438), train_loss = 1.08340475, grad/param norm = 1.9595e-01, time/batch = 18.7485s	
10649/26050 (epoch 20.440), train_loss = 1.06036738, grad/param norm = 1.8815e-01, time/batch = 17.5779s	
10650/26050 (epoch 20.441), train_loss = 1.02214336, grad/param norm = 1.7536e-01, time/batch = 18.6566s	
10651/26050 (epoch 20.443), train_loss = 0.89341582, grad/param norm = 1.4991e-01, time/batch = 17.6556s	
10652/26050 (epoch 20.445), train_loss = 0.96760115, grad/param norm = 1.7868e-01, time/batch = 16.7216s	
10653/26050 (epoch 20.447), train_loss = 1.18133361, grad/param norm = 1.9780e-01, time/batch = 17.6374s	
10654/26050 (epoch 20.449), train_loss = 0.95599305, grad/param norm = 1.6562e-01, time/batch = 17.9991s	
10655/26050 (epoch 20.451), train_loss = 1.20336903, grad/param norm = 1.9958e-01, time/batch = 18.0799s	
10656/26050 (epoch 20.453), train_loss = 0.96401419, grad/param norm = 1.5998e-01, time/batch = 16.7435s	
10657/26050 (epoch 20.455), train_loss = 1.07599320, grad/param norm = 1.7937e-01, time/batch = 18.0514s	
10658/26050 (epoch 20.457), train_loss = 1.03368585, grad/param norm = 1.7050e-01, time/batch = 15.5139s	
10659/26050 (epoch 20.459), train_loss = 1.14588284, grad/param norm = 1.8562e-01, time/batch = 15.8880s	
10660/26050 (epoch 20.461), train_loss = 1.14419752, grad/param norm = 2.0886e-01, time/batch = 18.0701s	
10661/26050 (epoch 20.463), train_loss = 1.01079338, grad/param norm = 1.7099e-01, time/batch = 18.3171s	
10662/26050 (epoch 20.464), train_loss = 1.08794960, grad/param norm = 1.8075e-01, time/batch = 17.7260s	
10663/26050 (epoch 20.466), train_loss = 1.11054248, grad/param norm = 1.9420e-01, time/batch = 16.0649s	
10664/26050 (epoch 20.468), train_loss = 1.13419919, grad/param norm = 1.6943e-01, time/batch = 17.7293s	
10665/26050 (epoch 20.470), train_loss = 1.19008617, grad/param norm = 1.9672e-01, time/batch = 18.6632s	
10666/26050 (epoch 20.472), train_loss = 1.18085087, grad/param norm = 2.0423e-01, time/batch = 17.2325s	
10667/26050 (epoch 20.474), train_loss = 1.19205657, grad/param norm = 1.7381e-01, time/batch = 18.6558s	
10668/26050 (epoch 20.476), train_loss = 1.17104078, grad/param norm = 1.8393e-01, time/batch = 17.8147s	
10669/26050 (epoch 20.478), train_loss = 1.03559517, grad/param norm = 1.8002e-01, time/batch = 17.2265s	
10670/26050 (epoch 20.480), train_loss = 1.05444684, grad/param norm = 1.7112e-01, time/batch = 18.2261s	
10671/26050 (epoch 20.482), train_loss = 0.99984898, grad/param norm = 1.7700e-01, time/batch = 18.2192s	
10672/26050 (epoch 20.484), train_loss = 0.99906425, grad/param norm = 1.8455e-01, time/batch = 17.9814s	
10673/26050 (epoch 20.486), train_loss = 1.18585946, grad/param norm = 1.8124e-01, time/batch = 14.7984s	
10674/26050 (epoch 20.488), train_loss = 1.28665319, grad/param norm = 1.9892e-01, time/batch = 17.9450s	
10675/26050 (epoch 20.489), train_loss = 1.22432025, grad/param norm = 2.1970e-01, time/batch = 17.7093s	
10676/26050 (epoch 20.491), train_loss = 0.97050389, grad/param norm = 1.7974e-01, time/batch = 15.7960s	
10677/26050 (epoch 20.493), train_loss = 1.06256450, grad/param norm = 1.9235e-01, time/batch = 17.7320s	
10678/26050 (epoch 20.495), train_loss = 1.04286793, grad/param norm = 1.6598e-01, time/batch = 17.8900s	
10679/26050 (epoch 20.497), train_loss = 0.97102820, grad/param norm = 1.7247e-01, time/batch = 18.3082s	
10680/26050 (epoch 20.499), train_loss = 1.01309247, grad/param norm = 1.7259e-01, time/batch = 18.0555s	
10681/26050 (epoch 20.501), train_loss = 1.12526185, grad/param norm = 1.9134e-01, time/batch = 18.6449s	
10682/26050 (epoch 20.503), train_loss = 1.00696718, grad/param norm = 1.7500e-01, time/batch = 18.1516s	
10683/26050 (epoch 20.505), train_loss = 1.18325508, grad/param norm = 1.7979e-01, time/batch = 17.8878s	
10684/26050 (epoch 20.507), train_loss = 1.12945915, grad/param norm = 1.9401e-01, time/batch = 17.8193s	
10685/26050 (epoch 20.509), train_loss = 1.23422344, grad/param norm = 1.8139e-01, time/batch = 17.1519s	
10686/26050 (epoch 20.511), train_loss = 0.98954406, grad/param norm = 1.6281e-01, time/batch = 17.4104s	
10687/26050 (epoch 20.512), train_loss = 0.97754873, grad/param norm = 1.8165e-01, time/batch = 18.8052s	
10688/26050 (epoch 20.514), train_loss = 1.13059133, grad/param norm = 1.9300e-01, time/batch = 18.4991s	
10689/26050 (epoch 20.516), train_loss = 1.17978215, grad/param norm = 1.7890e-01, time/batch = 17.9802s	
10690/26050 (epoch 20.518), train_loss = 1.05316030, grad/param norm = 1.8439e-01, time/batch = 18.3229s	
10691/26050 (epoch 20.520), train_loss = 1.03788113, grad/param norm = 1.7203e-01, time/batch = 18.5673s	
10692/26050 (epoch 20.522), train_loss = 0.82535443, grad/param norm = 1.5799e-01, time/batch = 18.7428s	
10693/26050 (epoch 20.524), train_loss = 1.14209493, grad/param norm = 2.2525e-01, time/batch = 16.3674s	
10694/26050 (epoch 20.526), train_loss = 1.17279441, grad/param norm = 2.2659e-01, time/batch = 18.8079s	
10695/26050 (epoch 20.528), train_loss = 1.10613619, grad/param norm = 1.9110e-01, time/batch = 17.6443s	
10696/26050 (epoch 20.530), train_loss = 1.02585340, grad/param norm = 1.8710e-01, time/batch = 15.8843s	
10697/26050 (epoch 20.532), train_loss = 1.06896805, grad/param norm = 1.8448e-01, time/batch = 18.4739s	
10698/26050 (epoch 20.534), train_loss = 1.12551756, grad/param norm = 2.0416e-01, time/batch = 14.3879s	
10699/26050 (epoch 20.536), train_loss = 1.05203563, grad/param norm = 1.7803e-01, time/batch = 17.9714s	
10700/26050 (epoch 20.537), train_loss = 1.14222184, grad/param norm = 1.9501e-01, time/batch = 17.9690s	
10701/26050 (epoch 20.539), train_loss = 1.04966364, grad/param norm = 1.8026e-01, time/batch = 14.8288s	
10702/26050 (epoch 20.541), train_loss = 1.27456003, grad/param norm = 2.1646e-01, time/batch = 17.6411s	
10703/26050 (epoch 20.543), train_loss = 0.89928914, grad/param norm = 1.6545e-01, time/batch = 20.7467s	
10704/26050 (epoch 20.545), train_loss = 1.11422050, grad/param norm = 1.8814e-01, time/batch = 32.3305s	
10705/26050 (epoch 20.547), train_loss = 1.05178614, grad/param norm = 1.7854e-01, time/batch = 20.6428s	
10706/26050 (epoch 20.549), train_loss = 0.88474839, grad/param norm = 1.7522e-01, time/batch = 18.5461s	
10707/26050 (epoch 20.551), train_loss = 1.10587274, grad/param norm = 1.7811e-01, time/batch = 18.3942s	
10708/26050 (epoch 20.553), train_loss = 0.98387892, grad/param norm = 1.7141e-01, time/batch = 18.1502s	
10709/26050 (epoch 20.555), train_loss = 0.99059081, grad/param norm = 1.7531e-01, time/batch = 17.7221s	
10710/26050 (epoch 20.557), train_loss = 1.10213597, grad/param norm = 1.6993e-01, time/batch = 14.8636s	
10711/26050 (epoch 20.559), train_loss = 1.03845186, grad/param norm = 1.7879e-01, time/batch = 18.1448s	
10712/26050 (epoch 20.560), train_loss = 1.02174502, grad/param norm = 1.8300e-01, time/batch = 18.4579s	
10713/26050 (epoch 20.562), train_loss = 1.01393630, grad/param norm = 1.7250e-01, time/batch = 18.1372s	
10714/26050 (epoch 20.564), train_loss = 1.21932093, grad/param norm = 1.7773e-01, time/batch = 18.6435s	
10715/26050 (epoch 20.566), train_loss = 0.95787052, grad/param norm = 1.7347e-01, time/batch = 17.4616s	
10716/26050 (epoch 20.568), train_loss = 1.09322311, grad/param norm = 1.8986e-01, time/batch = 16.5531s	
10717/26050 (epoch 20.570), train_loss = 1.12098995, grad/param norm = 1.8330e-01, time/batch = 18.0708s	
10718/26050 (epoch 20.572), train_loss = 1.01380090, grad/param norm = 1.8412e-01, time/batch = 17.9824s	
10719/26050 (epoch 20.574), train_loss = 1.11313961, grad/param norm = 2.0840e-01, time/batch = 17.2092s	
10720/26050 (epoch 20.576), train_loss = 1.07691570, grad/param norm = 1.8829e-01, time/batch = 17.7211s	
10721/26050 (epoch 20.578), train_loss = 1.02135571, grad/param norm = 1.8963e-01, time/batch = 18.5676s	
10722/26050 (epoch 20.580), train_loss = 0.97969455, grad/param norm = 1.8426e-01, time/batch = 17.7197s	
10723/26050 (epoch 20.582), train_loss = 1.08268069, grad/param norm = 1.8434e-01, time/batch = 17.2287s	
10724/26050 (epoch 20.583), train_loss = 1.15396892, grad/param norm = 1.7963e-01, time/batch = 17.8912s	
10725/26050 (epoch 20.585), train_loss = 0.92336379, grad/param norm = 1.8640e-01, time/batch = 18.2374s	
10726/26050 (epoch 20.587), train_loss = 1.10600639, grad/param norm = 2.0110e-01, time/batch = 18.3125s	
10727/26050 (epoch 20.589), train_loss = 1.20436601, grad/param norm = 2.0878e-01, time/batch = 18.0072s	
10728/26050 (epoch 20.591), train_loss = 1.02687524, grad/param norm = 1.8149e-01, time/batch = 14.9969s	
10729/26050 (epoch 20.593), train_loss = 0.92679118, grad/param norm = 1.7625e-01, time/batch = 16.7508s	
10730/26050 (epoch 20.595), train_loss = 1.12753206, grad/param norm = 2.2459e-01, time/batch = 17.9088s	
10731/26050 (epoch 20.597), train_loss = 1.09198165, grad/param norm = 1.8660e-01, time/batch = 17.1708s	
10732/26050 (epoch 20.599), train_loss = 1.06479156, grad/param norm = 1.9961e-01, time/batch = 17.4749s	
10733/26050 (epoch 20.601), train_loss = 1.23718243, grad/param norm = 1.7937e-01, time/batch = 16.1193s	
10734/26050 (epoch 20.603), train_loss = 1.08413310, grad/param norm = 1.8162e-01, time/batch = 16.7882s	
10735/26050 (epoch 20.605), train_loss = 1.00646579, grad/param norm = 1.8782e-01, time/batch = 17.4026s	
10736/26050 (epoch 20.607), train_loss = 1.15830446, grad/param norm = 1.9137e-01, time/batch = 17.5575s	
10737/26050 (epoch 20.608), train_loss = 0.91185080, grad/param norm = 1.5544e-01, time/batch = 17.7420s	
10738/26050 (epoch 20.610), train_loss = 1.03532585, grad/param norm = 1.8180e-01, time/batch = 18.1409s	
10739/26050 (epoch 20.612), train_loss = 1.04974395, grad/param norm = 1.8457e-01, time/batch = 17.1462s	
10740/26050 (epoch 20.614), train_loss = 1.08362318, grad/param norm = 1.8181e-01, time/batch = 17.3175s	
10741/26050 (epoch 20.616), train_loss = 1.21183195, grad/param norm = 2.1379e-01, time/batch = 18.4102s	
10742/26050 (epoch 20.618), train_loss = 1.00645102, grad/param norm = 1.9329e-01, time/batch = 15.3973s	
10743/26050 (epoch 20.620), train_loss = 1.10027416, grad/param norm = 1.9158e-01, time/batch = 17.3891s	
10744/26050 (epoch 20.622), train_loss = 0.93427515, grad/param norm = 1.5152e-01, time/batch = 17.8127s	
10745/26050 (epoch 20.624), train_loss = 0.92161803, grad/param norm = 1.6962e-01, time/batch = 18.2423s	
10746/26050 (epoch 20.626), train_loss = 1.11450260, grad/param norm = 1.8344e-01, time/batch = 16.2251s	
10747/26050 (epoch 20.628), train_loss = 0.97776892, grad/param norm = 1.9328e-01, time/batch = 18.4754s	
10748/26050 (epoch 20.630), train_loss = 1.17002985, grad/param norm = 1.8728e-01, time/batch = 15.5558s	
10749/26050 (epoch 20.631), train_loss = 1.21981989, grad/param norm = 1.9211e-01, time/batch = 16.3740s	
10750/26050 (epoch 20.633), train_loss = 0.95049365, grad/param norm = 1.6867e-01, time/batch = 17.4067s	
10751/26050 (epoch 20.635), train_loss = 0.97242378, grad/param norm = 1.5610e-01, time/batch = 18.0662s	
10752/26050 (epoch 20.637), train_loss = 0.95381604, grad/param norm = 1.8059e-01, time/batch = 18.0688s	
10753/26050 (epoch 20.639), train_loss = 1.15245789, grad/param norm = 1.7698e-01, time/batch = 17.7188s	
10754/26050 (epoch 20.641), train_loss = 1.02478064, grad/param norm = 1.6750e-01, time/batch = 17.9918s	
10755/26050 (epoch 20.643), train_loss = 0.94166868, grad/param norm = 1.5655e-01, time/batch = 17.3900s	
10756/26050 (epoch 20.645), train_loss = 1.04299001, grad/param norm = 1.8142e-01, time/batch = 17.7332s	
10757/26050 (epoch 20.647), train_loss = 0.99352677, grad/param norm = 1.7849e-01, time/batch = 16.5631s	
10758/26050 (epoch 20.649), train_loss = 1.06741201, grad/param norm = 1.9586e-01, time/batch = 15.5487s	
10759/26050 (epoch 20.651), train_loss = 0.98437888, grad/param norm = 1.8515e-01, time/batch = 18.3877s	
10760/26050 (epoch 20.653), train_loss = 1.05126750, grad/param norm = 1.8017e-01, time/batch = 18.1302s	
10761/26050 (epoch 20.655), train_loss = 0.97779275, grad/param norm = 1.7288e-01, time/batch = 17.7406s	
10762/26050 (epoch 20.656), train_loss = 0.89913312, grad/param norm = 1.6984e-01, time/batch = 16.2150s	
10763/26050 (epoch 20.658), train_loss = 1.23369976, grad/param norm = 1.8768e-01, time/batch = 17.4058s	
10764/26050 (epoch 20.660), train_loss = 0.92531495, grad/param norm = 1.7605e-01, time/batch = 17.8962s	
10765/26050 (epoch 20.662), train_loss = 0.98391393, grad/param norm = 1.7259e-01, time/batch = 14.9748s	
10766/26050 (epoch 20.664), train_loss = 1.02137732, grad/param norm = 1.8219e-01, time/batch = 17.9889s	
10767/26050 (epoch 20.666), train_loss = 1.02248342, grad/param norm = 2.0472e-01, time/batch = 16.5696s	
10768/26050 (epoch 20.668), train_loss = 0.87791597, grad/param norm = 2.2620e-01, time/batch = 15.9604s	
10769/26050 (epoch 20.670), train_loss = 1.18121991, grad/param norm = 2.1797e-01, time/batch = 18.2274s	
10770/26050 (epoch 20.672), train_loss = 1.02848029, grad/param norm = 1.8329e-01, time/batch = 17.3067s	
10771/26050 (epoch 20.674), train_loss = 0.95882361, grad/param norm = 1.8211e-01, time/batch = 18.3983s	
10772/26050 (epoch 20.676), train_loss = 1.09485795, grad/param norm = 1.9431e-01, time/batch = 17.2389s	
10773/26050 (epoch 20.678), train_loss = 1.17707201, grad/param norm = 1.9964e-01, time/batch = 18.5671s	
10774/26050 (epoch 20.679), train_loss = 1.23251424, grad/param norm = 2.1500e-01, time/batch = 16.9669s	
10775/26050 (epoch 20.681), train_loss = 1.06720712, grad/param norm = 1.9855e-01, time/batch = 18.5530s	
10776/26050 (epoch 20.683), train_loss = 0.95294870, grad/param norm = 2.2760e-01, time/batch = 17.5553s	
10777/26050 (epoch 20.685), train_loss = 1.00360880, grad/param norm = 1.7465e-01, time/batch = 16.8723s	
10778/26050 (epoch 20.687), train_loss = 0.89295380, grad/param norm = 1.6553e-01, time/batch = 16.1395s	
10779/26050 (epoch 20.689), train_loss = 1.01505666, grad/param norm = 1.9198e-01, time/batch = 17.4093s	
10780/26050 (epoch 20.691), train_loss = 0.83223434, grad/param norm = 1.7820e-01, time/batch = 18.8070s	
10781/26050 (epoch 20.693), train_loss = 0.96349522, grad/param norm = 1.8608e-01, time/batch = 18.0488s	
10782/26050 (epoch 20.695), train_loss = 1.04009708, grad/param norm = 1.7757e-01, time/batch = 17.5490s	
10783/26050 (epoch 20.697), train_loss = 0.94924861, grad/param norm = 1.7288e-01, time/batch = 14.8226s	
10784/26050 (epoch 20.699), train_loss = 1.08481944, grad/param norm = 1.8999e-01, time/batch = 17.6388s	
10785/26050 (epoch 20.701), train_loss = 0.94228303, grad/param norm = 1.6203e-01, time/batch = 17.8256s	
10786/26050 (epoch 20.702), train_loss = 1.16013594, grad/param norm = 1.8947e-01, time/batch = 18.3803s	
10787/26050 (epoch 20.704), train_loss = 1.12231421, grad/param norm = 1.6855e-01, time/batch = 18.2245s	
10788/26050 (epoch 20.706), train_loss = 1.02721935, grad/param norm = 1.9761e-01, time/batch = 18.4716s	
10789/26050 (epoch 20.708), train_loss = 1.11673504, grad/param norm = 1.9009e-01, time/batch = 15.7101s	
10790/26050 (epoch 20.710), train_loss = 1.10576056, grad/param norm = 1.9029e-01, time/batch = 17.2143s	
10791/26050 (epoch 20.712), train_loss = 1.12255229, grad/param norm = 2.0057e-01, time/batch = 16.7408s	
10792/26050 (epoch 20.714), train_loss = 0.89577780, grad/param norm = 1.6873e-01, time/batch = 17.5698s	
10793/26050 (epoch 20.716), train_loss = 1.28456690, grad/param norm = 2.0022e-01, time/batch = 18.7277s	
10794/26050 (epoch 20.718), train_loss = 1.13626666, grad/param norm = 1.8334e-01, time/batch = 18.1601s	
10795/26050 (epoch 20.720), train_loss = 1.01584128, grad/param norm = 1.9197e-01, time/batch = 18.4107s	
10796/26050 (epoch 20.722), train_loss = 0.90360860, grad/param norm = 1.7059e-01, time/batch = 17.5791s	
10797/26050 (epoch 20.724), train_loss = 0.96122671, grad/param norm = 1.8818e-01, time/batch = 18.4854s	
10798/26050 (epoch 20.726), train_loss = 1.12143641, grad/param norm = 2.0265e-01, time/batch = 17.8946s	
10799/26050 (epoch 20.727), train_loss = 1.11601331, grad/param norm = 1.9741e-01, time/batch = 18.3963s	
10800/26050 (epoch 20.729), train_loss = 1.09125752, grad/param norm = 1.8150e-01, time/batch = 18.3837s	
10801/26050 (epoch 20.731), train_loss = 1.07464040, grad/param norm = 1.8215e-01, time/batch = 17.9664s	
10802/26050 (epoch 20.733), train_loss = 1.00951560, grad/param norm = 2.1850e-01, time/batch = 18.4900s	
10803/26050 (epoch 20.735), train_loss = 1.25615164, grad/param norm = 2.0824e-01, time/batch = 16.6630s	
10804/26050 (epoch 20.737), train_loss = 0.99129041, grad/param norm = 1.7978e-01, time/batch = 14.3019s	
10805/26050 (epoch 20.739), train_loss = 1.06947014, grad/param norm = 1.7997e-01, time/batch = 18.3171s	
10806/26050 (epoch 20.741), train_loss = 0.96480960, grad/param norm = 1.9038e-01, time/batch = 17.3048s	
10807/26050 (epoch 20.743), train_loss = 1.08317314, grad/param norm = 1.9745e-01, time/batch = 14.8823s	
10808/26050 (epoch 20.745), train_loss = 0.92135534, grad/param norm = 1.7019e-01, time/batch = 17.5653s	
10809/26050 (epoch 20.747), train_loss = 0.95033242, grad/param norm = 1.7382e-01, time/batch = 18.7372s	
10810/26050 (epoch 20.749), train_loss = 1.16221841, grad/param norm = 1.9907e-01, time/batch = 16.0571s	
10811/26050 (epoch 20.750), train_loss = 1.03734593, grad/param norm = 1.7541e-01, time/batch = 17.0722s	
10812/26050 (epoch 20.752), train_loss = 1.00575726, grad/param norm = 1.9338e-01, time/batch = 18.6518s	
10813/26050 (epoch 20.754), train_loss = 1.05610551, grad/param norm = 1.8172e-01, time/batch = 17.4122s	
10814/26050 (epoch 20.756), train_loss = 1.04347131, grad/param norm = 1.9590e-01, time/batch = 16.2282s	
10815/26050 (epoch 20.758), train_loss = 1.03677877, grad/param norm = 2.0434e-01, time/batch = 17.4697s	
10816/26050 (epoch 20.760), train_loss = 1.22260693, grad/param norm = 1.9522e-01, time/batch = 18.2338s	
10817/26050 (epoch 20.762), train_loss = 0.98617619, grad/param norm = 1.8030e-01, time/batch = 18.1518s	
10818/26050 (epoch 20.764), train_loss = 1.05894342, grad/param norm = 1.9215e-01, time/batch = 17.3961s	
10819/26050 (epoch 20.766), train_loss = 1.10590607, grad/param norm = 2.0342e-01, time/batch = 18.5406s	
10820/26050 (epoch 20.768), train_loss = 0.94566741, grad/param norm = 1.7558e-01, time/batch = 17.6494s	
10821/26050 (epoch 20.770), train_loss = 1.02583561, grad/param norm = 1.9352e-01, time/batch = 17.8165s	
10822/26050 (epoch 20.772), train_loss = 1.02704790, grad/param norm = 1.6851e-01, time/batch = 15.0523s	
10823/26050 (epoch 20.774), train_loss = 0.91125127, grad/param norm = 1.8296e-01, time/batch = 17.9017s	
10824/26050 (epoch 20.775), train_loss = 0.74844408, grad/param norm = 1.5614e-01, time/batch = 18.0742s	
10825/26050 (epoch 20.777), train_loss = 0.97594162, grad/param norm = 1.7526e-01, time/batch = 17.0636s	
10826/26050 (epoch 20.779), train_loss = 1.01157879, grad/param norm = 1.8553e-01, time/batch = 17.3250s	
10827/26050 (epoch 20.781), train_loss = 0.93991033, grad/param norm = 1.8155e-01, time/batch = 18.8969s	
10828/26050 (epoch 20.783), train_loss = 0.92001746, grad/param norm = 1.6359e-01, time/batch = 17.8276s	
10829/26050 (epoch 20.785), train_loss = 1.02226484, grad/param norm = 1.7618e-01, time/batch = 18.1505s	
10830/26050 (epoch 20.787), train_loss = 0.95384323, grad/param norm = 1.7873e-01, time/batch = 17.3303s	
10831/26050 (epoch 20.789), train_loss = 0.97636232, grad/param norm = 2.0160e-01, time/batch = 14.3016s	
10832/26050 (epoch 20.791), train_loss = 0.98543588, grad/param norm = 1.7819e-01, time/batch = 16.3076s	
10833/26050 (epoch 20.793), train_loss = 1.02639204, grad/param norm = 1.9887e-01, time/batch = 17.9798s	
10834/26050 (epoch 20.795), train_loss = 0.84401490, grad/param norm = 1.4847e-01, time/batch = 16.7107s	
10835/26050 (epoch 20.797), train_loss = 0.94786018, grad/param norm = 1.5879e-01, time/batch = 17.3336s	
10836/26050 (epoch 20.798), train_loss = 0.87936904, grad/param norm = 1.6935e-01, time/batch = 17.8268s	
10837/26050 (epoch 20.800), train_loss = 0.90711877, grad/param norm = 1.6524e-01, time/batch = 15.8130s	
10838/26050 (epoch 20.802), train_loss = 0.98674149, grad/param norm = 1.7598e-01, time/batch = 17.8874s	
10839/26050 (epoch 20.804), train_loss = 1.02321226, grad/param norm = 1.8360e-01, time/batch = 16.6312s	
10840/26050 (epoch 20.806), train_loss = 1.13031201, grad/param norm = 1.9329e-01, time/batch = 15.9788s	
10841/26050 (epoch 20.808), train_loss = 1.02102092, grad/param norm = 1.7824e-01, time/batch = 15.1548s	
10842/26050 (epoch 20.810), train_loss = 0.98227061, grad/param norm = 1.9039e-01, time/batch = 17.6456s	
10843/26050 (epoch 20.812), train_loss = 0.92943118, grad/param norm = 1.8965e-01, time/batch = 18.1485s	
10844/26050 (epoch 20.814), train_loss = 0.92116806, grad/param norm = 1.9196e-01, time/batch = 18.5551s	
10845/26050 (epoch 20.816), train_loss = 1.13133407, grad/param norm = 2.0258e-01, time/batch = 18.6471s	
10846/26050 (epoch 20.818), train_loss = 1.14226638, grad/param norm = 2.2164e-01, time/batch = 17.8152s	
10847/26050 (epoch 20.820), train_loss = 1.03434075, grad/param norm = 1.7362e-01, time/batch = 15.5618s	
10848/26050 (epoch 20.821), train_loss = 1.16365964, grad/param norm = 1.9496e-01, time/batch = 18.1526s	
10849/26050 (epoch 20.823), train_loss = 1.16998964, grad/param norm = 1.9981e-01, time/batch = 17.7145s	
10850/26050 (epoch 20.825), train_loss = 1.01775816, grad/param norm = 1.8403e-01, time/batch = 16.2186s	
10851/26050 (epoch 20.827), train_loss = 1.05939668, grad/param norm = 2.0357e-01, time/batch = 18.3924s	
10852/26050 (epoch 20.829), train_loss = 1.12748186, grad/param norm = 2.0323e-01, time/batch = 18.6446s	
10853/26050 (epoch 20.831), train_loss = 1.15843179, grad/param norm = 1.8120e-01, time/batch = 18.6416s	
10854/26050 (epoch 20.833), train_loss = 1.23351211, grad/param norm = 1.9773e-01, time/batch = 18.2340s	
10855/26050 (epoch 20.835), train_loss = 1.23132830, grad/param norm = 2.2446e-01, time/batch = 16.0469s	
10856/26050 (epoch 20.837), train_loss = 1.03618342, grad/param norm = 1.8137e-01, time/batch = 14.3673s	
10857/26050 (epoch 20.839), train_loss = 1.06790221, grad/param norm = 2.3349e-01, time/batch = 17.9612s	
10858/26050 (epoch 20.841), train_loss = 1.18115394, grad/param norm = 1.9720e-01, time/batch = 18.4906s	
10859/26050 (epoch 20.843), train_loss = 1.03196354, grad/param norm = 1.7207e-01, time/batch = 18.1443s	
10860/26050 (epoch 20.845), train_loss = 0.98731375, grad/param norm = 1.7073e-01, time/batch = 14.7930s	
10861/26050 (epoch 20.846), train_loss = 1.11865481, grad/param norm = 1.7267e-01, time/batch = 18.8098s	
10862/26050 (epoch 20.848), train_loss = 1.02722853, grad/param norm = 1.7942e-01, time/batch = 18.2323s	
10863/26050 (epoch 20.850), train_loss = 0.94061689, grad/param norm = 1.6258e-01, time/batch = 17.6387s	
10864/26050 (epoch 20.852), train_loss = 1.04164975, grad/param norm = 1.7750e-01, time/batch = 17.8239s	
10865/26050 (epoch 20.854), train_loss = 1.02572216, grad/param norm = 1.8656e-01, time/batch = 18.1505s	
10866/26050 (epoch 20.856), train_loss = 1.00377484, grad/param norm = 1.9041e-01, time/batch = 17.8170s	
10867/26050 (epoch 20.858), train_loss = 0.94316626, grad/param norm = 1.7446e-01, time/batch = 18.2327s	
10868/26050 (epoch 20.860), train_loss = 1.06908461, grad/param norm = 1.8816e-01, time/batch = 17.9047s	
10869/26050 (epoch 20.862), train_loss = 1.10312477, grad/param norm = 1.8548e-01, time/batch = 14.3035s	
10870/26050 (epoch 20.864), train_loss = 1.07488866, grad/param norm = 2.1236e-01, time/batch = 16.4747s	
10871/26050 (epoch 20.866), train_loss = 0.98877889, grad/param norm = 1.7665e-01, time/batch = 17.7201s	
10872/26050 (epoch 20.868), train_loss = 1.08359049, grad/param norm = 1.8250e-01, time/batch = 17.7351s	
10873/26050 (epoch 20.869), train_loss = 0.93470831, grad/param norm = 1.7118e-01, time/batch = 17.1545s	
10874/26050 (epoch 20.871), train_loss = 0.87353079, grad/param norm = 1.7079e-01, time/batch = 17.9129s	
10875/26050 (epoch 20.873), train_loss = 1.08899263, grad/param norm = 2.0429e-01, time/batch = 16.1424s	
10876/26050 (epoch 20.875), train_loss = 1.03262391, grad/param norm = 1.9565e-01, time/batch = 17.8033s	
10877/26050 (epoch 20.877), train_loss = 0.92324714, grad/param norm = 1.6599e-01, time/batch = 17.3141s	
10878/26050 (epoch 20.879), train_loss = 1.05211896, grad/param norm = 1.6520e-01, time/batch = 18.6335s	
10879/26050 (epoch 20.881), train_loss = 1.15868193, grad/param norm = 2.0617e-01, time/batch = 16.6176s	
10880/26050 (epoch 20.883), train_loss = 1.09155501, grad/param norm = 1.8359e-01, time/batch = 17.7279s	
10881/26050 (epoch 20.885), train_loss = 0.78054582, grad/param norm = 1.5943e-01, time/batch = 18.2293s	
10882/26050 (epoch 20.887), train_loss = 1.07517948, grad/param norm = 1.8317e-01, time/batch = 18.1697s	
10883/26050 (epoch 20.889), train_loss = 0.99549494, grad/param norm = 1.7568e-01, time/batch = 17.1630s	
10884/26050 (epoch 20.891), train_loss = 0.84996508, grad/param norm = 1.6194e-01, time/batch = 18.0705s	
10885/26050 (epoch 20.893), train_loss = 0.90475926, grad/param norm = 1.7589e-01, time/batch = 18.4000s	
10886/26050 (epoch 20.894), train_loss = 0.98450989, grad/param norm = 1.6757e-01, time/batch = 18.8978s	
10887/26050 (epoch 20.896), train_loss = 1.12318404, grad/param norm = 1.8538e-01, time/batch = 18.0514s	
10888/26050 (epoch 20.898), train_loss = 0.96442635, grad/param norm = 1.8307e-01, time/batch = 18.5614s	
10889/26050 (epoch 20.900), train_loss = 1.06379145, grad/param norm = 1.8793e-01, time/batch = 17.8060s	
10890/26050 (epoch 20.902), train_loss = 1.01316262, grad/param norm = 1.7608e-01, time/batch = 16.3899s	
10891/26050 (epoch 20.904), train_loss = 1.01417043, grad/param norm = 1.7333e-01, time/batch = 18.0565s	
10892/26050 (epoch 20.906), train_loss = 1.01076179, grad/param norm = 1.9153e-01, time/batch = 17.9939s	
10893/26050 (epoch 20.908), train_loss = 1.03171990, grad/param norm = 1.8057e-01, time/batch = 17.9164s	
10894/26050 (epoch 20.910), train_loss = 0.98073386, grad/param norm = 1.6592e-01, time/batch = 14.7298s	
10895/26050 (epoch 20.912), train_loss = 1.22849284, grad/param norm = 2.0440e-01, time/batch = 16.9717s	
10896/26050 (epoch 20.914), train_loss = 1.39122427, grad/param norm = 2.3009e-01, time/batch = 18.2327s	
10897/26050 (epoch 20.916), train_loss = 1.14143625, grad/param norm = 2.0160e-01, time/batch = 17.5793s	
10898/26050 (epoch 20.917), train_loss = 1.04843777, grad/param norm = 2.1018e-01, time/batch = 18.3159s	
10899/26050 (epoch 20.919), train_loss = 1.12353007, grad/param norm = 2.0913e-01, time/batch = 17.5541s	
10900/26050 (epoch 20.921), train_loss = 0.98593056, grad/param norm = 1.8035e-01, time/batch = 17.8175s	
10901/26050 (epoch 20.923), train_loss = 1.04967060, grad/param norm = 1.8925e-01, time/batch = 17.8318s	
10902/26050 (epoch 20.925), train_loss = 1.02581576, grad/param norm = 1.7503e-01, time/batch = 18.2443s	
10903/26050 (epoch 20.927), train_loss = 0.90870521, grad/param norm = 1.4849e-01, time/batch = 16.2404s	
10904/26050 (epoch 20.929), train_loss = 0.89611816, grad/param norm = 1.7342e-01, time/batch = 18.1341s	
10905/26050 (epoch 20.931), train_loss = 1.21019029, grad/param norm = 2.1487e-01, time/batch = 18.0735s	
10906/26050 (epoch 20.933), train_loss = 0.97973822, grad/param norm = 1.7170e-01, time/batch = 17.3130s	
10907/26050 (epoch 20.935), train_loss = 1.01871338, grad/param norm = 1.7593e-01, time/batch = 22.5713s	
10908/26050 (epoch 20.937), train_loss = 1.11712186, grad/param norm = 1.8107e-01, time/batch = 28.6680s	
10909/26050 (epoch 20.939), train_loss = 0.95479559, grad/param norm = 1.6128e-01, time/batch = 18.7704s	
10910/26050 (epoch 20.940), train_loss = 0.99982384, grad/param norm = 1.6400e-01, time/batch = 18.5562s	
10911/26050 (epoch 20.942), train_loss = 1.02316694, grad/param norm = 1.7732e-01, time/batch = 17.3252s	
10912/26050 (epoch 20.944), train_loss = 0.97909711, grad/param norm = 1.7701e-01, time/batch = 18.4859s	
10913/26050 (epoch 20.946), train_loss = 1.17061290, grad/param norm = 1.9463e-01, time/batch = 17.4815s	
10914/26050 (epoch 20.948), train_loss = 0.92569192, grad/param norm = 1.8750e-01, time/batch = 18.6713s	
10915/26050 (epoch 20.950), train_loss = 1.00517889, grad/param norm = 1.8533e-01, time/batch = 18.0753s	
10916/26050 (epoch 20.952), train_loss = 1.13978260, grad/param norm = 1.9469e-01, time/batch = 14.9823s	
10917/26050 (epoch 20.954), train_loss = 1.13769989, grad/param norm = 1.9634e-01, time/batch = 18.0658s	
10918/26050 (epoch 20.956), train_loss = 1.02794921, grad/param norm = 1.9748e-01, time/batch = 18.1438s	
10919/26050 (epoch 20.958), train_loss = 0.98383962, grad/param norm = 1.8641e-01, time/batch = 17.9784s	
10920/26050 (epoch 20.960), train_loss = 1.05556355, grad/param norm = 1.9039e-01, time/batch = 17.8860s	
10921/26050 (epoch 20.962), train_loss = 0.96974078, grad/param norm = 1.5372e-01, time/batch = 18.7492s	
10922/26050 (epoch 20.964), train_loss = 1.03113271, grad/param norm = 1.9070e-01, time/batch = 17.6539s	
10923/26050 (epoch 20.965), train_loss = 0.96131028, grad/param norm = 1.7654e-01, time/batch = 17.3934s	
10924/26050 (epoch 20.967), train_loss = 1.35686560, grad/param norm = 1.9759e-01, time/batch = 16.5618s	
10925/26050 (epoch 20.969), train_loss = 1.03169690, grad/param norm = 1.8195e-01, time/batch = 17.0793s	
10926/26050 (epoch 20.971), train_loss = 0.97857036, grad/param norm = 1.5943e-01, time/batch = 18.0630s	
10927/26050 (epoch 20.973), train_loss = 1.03734255, grad/param norm = 2.0961e-01, time/batch = 17.3247s	
10928/26050 (epoch 20.975), train_loss = 1.06331301, grad/param norm = 1.6900e-01, time/batch = 15.2378s	
10929/26050 (epoch 20.977), train_loss = 1.06837172, grad/param norm = 1.6286e-01, time/batch = 18.1401s	
10930/26050 (epoch 20.979), train_loss = 0.87885813, grad/param norm = 1.7400e-01, time/batch = 14.8125s	
10931/26050 (epoch 20.981), train_loss = 1.16071583, grad/param norm = 1.7663e-01, time/batch = 18.0625s	
10932/26050 (epoch 20.983), train_loss = 1.12147583, grad/param norm = 2.0537e-01, time/batch = 18.0709s	
10933/26050 (epoch 20.985), train_loss = 1.08611495, grad/param norm = 1.7489e-01, time/batch = 18.2407s	
10934/26050 (epoch 20.987), train_loss = 1.15217486, grad/param norm = 1.7803e-01, time/batch = 17.9912s	
10935/26050 (epoch 20.988), train_loss = 1.12005996, grad/param norm = 1.8318e-01, time/batch = 17.7199s	
10936/26050 (epoch 20.990), train_loss = 0.92197718, grad/param norm = 1.5675e-01, time/batch = 16.2266s	
10937/26050 (epoch 20.992), train_loss = 1.19003911, grad/param norm = 1.8966e-01, time/batch = 16.8856s	
10938/26050 (epoch 20.994), train_loss = 0.99775384, grad/param norm = 1.8279e-01, time/batch = 18.3353s	
10939/26050 (epoch 20.996), train_loss = 0.98326630, grad/param norm = 1.8532e-01, time/batch = 17.5568s	
10940/26050 (epoch 20.998), train_loss = 1.03990260, grad/param norm = 1.7449e-01, time/batch = 17.6425s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
10941/26050 (epoch 21.000), train_loss = 0.99137793, grad/param norm = 1.9293e-01, time/batch = 16.5542s	
10942/26050 (epoch 21.002), train_loss = 1.10815182, grad/param norm = 2.0565e-01, time/batch = 18.2359s	
10943/26050 (epoch 21.004), train_loss = 0.94761817, grad/param norm = 1.7521e-01, time/batch = 17.7375s	
10944/26050 (epoch 21.006), train_loss = 0.97714366, grad/param norm = 1.8499e-01, time/batch = 18.2570s	
10945/26050 (epoch 21.008), train_loss = 0.96195017, grad/param norm = 1.9299e-01, time/batch = 18.7294s	
10946/26050 (epoch 21.010), train_loss = 0.95749963, grad/param norm = 1.7369e-01, time/batch = 17.7433s	
10947/26050 (epoch 21.012), train_loss = 1.05355385, grad/param norm = 1.8679e-01, time/batch = 18.3149s	
10948/26050 (epoch 21.013), train_loss = 1.33751765, grad/param norm = 2.4062e-01, time/batch = 17.9806s	
10949/26050 (epoch 21.015), train_loss = 0.99580394, grad/param norm = 1.6337e-01, time/batch = 18.3210s	
10950/26050 (epoch 21.017), train_loss = 1.04129136, grad/param norm = 1.7745e-01, time/batch = 17.1203s	
10951/26050 (epoch 21.019), train_loss = 0.89769033, grad/param norm = 1.6598e-01, time/batch = 18.6471s	
10952/26050 (epoch 21.021), train_loss = 1.09229102, grad/param norm = 1.7850e-01, time/batch = 16.4791s	
10953/26050 (epoch 21.023), train_loss = 0.87595539, grad/param norm = 1.8475e-01, time/batch = 17.2925s	
10954/26050 (epoch 21.025), train_loss = 1.04368767, grad/param norm = 1.8484e-01, time/batch = 15.0597s	
10955/26050 (epoch 21.027), train_loss = 0.83976521, grad/param norm = 1.8109e-01, time/batch = 17.3913s	
10956/26050 (epoch 21.029), train_loss = 1.05336914, grad/param norm = 1.6852e-01, time/batch = 16.5653s	
10957/26050 (epoch 21.031), train_loss = 1.17168726, grad/param norm = 2.0818e-01, time/batch = 17.8936s	
10958/26050 (epoch 21.033), train_loss = 1.06333341, grad/param norm = 1.8016e-01, time/batch = 18.3862s	
10959/26050 (epoch 21.035), train_loss = 1.07293989, grad/param norm = 1.8043e-01, time/batch = 16.0657s	
10960/26050 (epoch 21.036), train_loss = 0.93010230, grad/param norm = 1.7975e-01, time/batch = 17.9687s	
10961/26050 (epoch 21.038), train_loss = 0.85694055, grad/param norm = 1.6190e-01, time/batch = 18.2325s	
10962/26050 (epoch 21.040), train_loss = 1.02398241, grad/param norm = 1.9407e-01, time/batch = 18.4068s	
10963/26050 (epoch 21.042), train_loss = 0.88909151, grad/param norm = 1.7346e-01, time/batch = 18.3155s	
10964/26050 (epoch 21.044), train_loss = 1.11154891, grad/param norm = 1.7074e-01, time/batch = 15.6415s	
10965/26050 (epoch 21.046), train_loss = 0.83592875, grad/param norm = 1.4833e-01, time/batch = 17.7892s	
10966/26050 (epoch 21.048), train_loss = 1.03695789, grad/param norm = 1.7982e-01, time/batch = 17.8980s	
10967/26050 (epoch 21.050), train_loss = 0.95870197, grad/param norm = 1.7327e-01, time/batch = 16.8230s	
10968/26050 (epoch 21.052), train_loss = 0.97452729, grad/param norm = 1.8583e-01, time/batch = 18.5580s	
10969/26050 (epoch 21.054), train_loss = 0.86770285, grad/param norm = 1.6368e-01, time/batch = 18.0616s	
10970/26050 (epoch 21.056), train_loss = 0.83142285, grad/param norm = 1.5236e-01, time/batch = 16.8040s	
10971/26050 (epoch 21.058), train_loss = 0.97768520, grad/param norm = 1.6842e-01, time/batch = 18.3856s	
10972/26050 (epoch 21.060), train_loss = 1.08798517, grad/param norm = 1.8191e-01, time/batch = 19.0536s	
10973/26050 (epoch 21.061), train_loss = 0.93411469, grad/param norm = 1.7067e-01, time/batch = 17.8148s	
10974/26050 (epoch 21.063), train_loss = 1.06581214, grad/param norm = 1.7743e-01, time/batch = 16.8217s	
10975/26050 (epoch 21.065), train_loss = 0.83209824, grad/param norm = 1.5386e-01, time/batch = 16.7378s	
10976/26050 (epoch 21.067), train_loss = 1.02623773, grad/param norm = 1.8048e-01, time/batch = 14.7106s	
10977/26050 (epoch 21.069), train_loss = 1.07846318, grad/param norm = 2.0811e-01, time/batch = 17.2010s	
10978/26050 (epoch 21.071), train_loss = 1.09552282, grad/param norm = 1.8559e-01, time/batch = 17.0531s	
10979/26050 (epoch 21.073), train_loss = 1.21839952, grad/param norm = 2.0896e-01, time/batch = 18.8201s	
10980/26050 (epoch 21.075), train_loss = 0.94517612, grad/param norm = 1.6778e-01, time/batch = 18.3254s	
10981/26050 (epoch 21.077), train_loss = 0.95853205, grad/param norm = 1.8271e-01, time/batch = 16.9061s	
10982/26050 (epoch 21.079), train_loss = 1.04539950, grad/param norm = 1.8241e-01, time/batch = 18.4049s	
10983/26050 (epoch 21.081), train_loss = 0.98865835, grad/param norm = 1.7025e-01, time/batch = 18.3125s	
10984/26050 (epoch 21.083), train_loss = 1.12336152, grad/param norm = 1.8329e-01, time/batch = 15.3922s	
10985/26050 (epoch 21.084), train_loss = 1.04431772, grad/param norm = 2.0959e-01, time/batch = 18.3279s	
10986/26050 (epoch 21.086), train_loss = 1.19420071, grad/param norm = 2.0054e-01, time/batch = 17.7430s	
10987/26050 (epoch 21.088), train_loss = 0.95055574, grad/param norm = 1.7518e-01, time/batch = 18.4096s	
10988/26050 (epoch 21.090), train_loss = 1.04396339, grad/param norm = 1.9143e-01, time/batch = 18.4892s	
10989/26050 (epoch 21.092), train_loss = 1.07983175, grad/param norm = 1.8001e-01, time/batch = 18.0614s	
10990/26050 (epoch 21.094), train_loss = 0.95676325, grad/param norm = 1.7804e-01, time/batch = 17.4028s	
10991/26050 (epoch 21.096), train_loss = 1.01657905, grad/param norm = 1.7197e-01, time/batch = 17.8224s	
10992/26050 (epoch 21.098), train_loss = 0.96684482, grad/param norm = 1.7568e-01, time/batch = 18.1341s	
10993/26050 (epoch 21.100), train_loss = 0.92675146, grad/param norm = 1.8228e-01, time/batch = 16.7324s	
10994/26050 (epoch 21.102), train_loss = 1.05846790, grad/param norm = 1.9369e-01, time/batch = 17.5316s	
10995/26050 (epoch 21.104), train_loss = 1.00817881, grad/param norm = 1.9072e-01, time/batch = 18.2154s	
10996/26050 (epoch 21.106), train_loss = 1.02490805, grad/param norm = 1.9450e-01, time/batch = 18.8241s	
10997/26050 (epoch 21.107), train_loss = 0.82527389, grad/param norm = 1.7448e-01, time/batch = 14.9695s	
10998/26050 (epoch 21.109), train_loss = 0.93715338, grad/param norm = 1.8330e-01, time/batch = 16.2145s	
10999/26050 (epoch 21.111), train_loss = 1.18556488, grad/param norm = 1.9910e-01, time/batch = 18.8861s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch21.11_1.6813.t7	
11000/26050 (epoch 21.113), train_loss = 0.96332794, grad/param norm = 1.7974e-01, time/batch = 15.8828s	
11001/26050 (epoch 21.115), train_loss = 1.51738745, grad/param norm = 2.1567e-01, time/batch = 18.0515s	
11002/26050 (epoch 21.117), train_loss = 1.04834925, grad/param norm = 1.8086e-01, time/batch = 16.5680s	
11003/26050 (epoch 21.119), train_loss = 0.85352291, grad/param norm = 1.5687e-01, time/batch = 18.4956s	
11004/26050 (epoch 21.121), train_loss = 1.04298911, grad/param norm = 1.6939e-01, time/batch = 18.6408s	
11005/26050 (epoch 21.123), train_loss = 0.92362259, grad/param norm = 1.6552e-01, time/batch = 17.8021s	
11006/26050 (epoch 21.125), train_loss = 0.88578420, grad/param norm = 1.6579e-01, time/batch = 18.4728s	
11007/26050 (epoch 21.127), train_loss = 0.81810809, grad/param norm = 1.6578e-01, time/batch = 18.8985s	
11008/26050 (epoch 21.129), train_loss = 0.86965697, grad/param norm = 1.7079e-01, time/batch = 17.0467s	
11009/26050 (epoch 21.131), train_loss = 0.99150696, grad/param norm = 1.7482e-01, time/batch = 18.6499s	
11010/26050 (epoch 21.132), train_loss = 0.98653653, grad/param norm = 1.6620e-01, time/batch = 18.7295s	
11011/26050 (epoch 21.134), train_loss = 1.03546405, grad/param norm = 2.0179e-01, time/batch = 18.2310s	
11012/26050 (epoch 21.136), train_loss = 1.02120145, grad/param norm = 1.8281e-01, time/batch = 17.6352s	
11013/26050 (epoch 21.138), train_loss = 0.77402406, grad/param norm = 1.6751e-01, time/batch = 18.4761s	
11014/26050 (epoch 21.140), train_loss = 0.85003388, grad/param norm = 1.7790e-01, time/batch = 17.7324s	
11015/26050 (epoch 21.142), train_loss = 0.88238014, grad/param norm = 1.7084e-01, time/batch = 15.2232s	
11016/26050 (epoch 21.144), train_loss = 0.81315610, grad/param norm = 1.6234e-01, time/batch = 18.4064s	
11017/26050 (epoch 21.146), train_loss = 0.76148600, grad/param norm = 1.6340e-01, time/batch = 18.5626s	
11018/26050 (epoch 21.148), train_loss = 0.80028573, grad/param norm = 1.4914e-01, time/batch = 18.2957s	
11019/26050 (epoch 21.150), train_loss = 0.98107572, grad/param norm = 1.8670e-01, time/batch = 15.1299s	
11020/26050 (epoch 21.152), train_loss = 1.20322342, grad/param norm = 2.4080e-01, time/batch = 17.9821s	
11021/26050 (epoch 21.154), train_loss = 0.80234955, grad/param norm = 1.8543e-01, time/batch = 18.2271s	
11022/26050 (epoch 21.155), train_loss = 0.84585657, grad/param norm = 1.6866e-01, time/batch = 17.3101s	
11023/26050 (epoch 21.157), train_loss = 0.95238965, grad/param norm = 1.9417e-01, time/batch = 15.3849s	
11024/26050 (epoch 21.159), train_loss = 1.01396157, grad/param norm = 2.0773e-01, time/batch = 18.1473s	
11025/26050 (epoch 21.161), train_loss = 1.05361910, grad/param norm = 2.0224e-01, time/batch = 16.1953s	
11026/26050 (epoch 21.163), train_loss = 0.84869420, grad/param norm = 1.8790e-01, time/batch = 18.1531s	
11027/26050 (epoch 21.165), train_loss = 0.78053637, grad/param norm = 1.6097e-01, time/batch = 17.6440s	
11028/26050 (epoch 21.167), train_loss = 1.10831559, grad/param norm = 1.8708e-01, time/batch = 18.3164s	
11029/26050 (epoch 21.169), train_loss = 1.02850190, grad/param norm = 1.8419e-01, time/batch = 16.1381s	
11030/26050 (epoch 21.171), train_loss = 0.83686583, grad/param norm = 1.5649e-01, time/batch = 18.1428s	
11031/26050 (epoch 21.173), train_loss = 0.93975153, grad/param norm = 1.9387e-01, time/batch = 18.1639s	
11032/26050 (epoch 21.175), train_loss = 0.96792447, grad/param norm = 1.6371e-01, time/batch = 17.8993s	
11033/26050 (epoch 21.177), train_loss = 1.09551537, grad/param norm = 1.7483e-01, time/batch = 15.3174s	
11034/26050 (epoch 21.179), train_loss = 0.76334771, grad/param norm = 1.6391e-01, time/batch = 18.4720s	
11035/26050 (epoch 21.180), train_loss = 1.20011901, grad/param norm = 1.8830e-01, time/batch = 18.1463s	
11036/26050 (epoch 21.182), train_loss = 1.22561090, grad/param norm = 1.9737e-01, time/batch = 17.3869s	
11037/26050 (epoch 21.184), train_loss = 1.03705044, grad/param norm = 1.7758e-01, time/batch = 18.2234s	
11038/26050 (epoch 21.186), train_loss = 0.83765626, grad/param norm = 1.5569e-01, time/batch = 18.0582s	
11039/26050 (epoch 21.188), train_loss = 0.99796547, grad/param norm = 1.7801e-01, time/batch = 17.4964s	
11040/26050 (epoch 21.190), train_loss = 1.04968516, grad/param norm = 1.7743e-01, time/batch = 18.0068s	
11041/26050 (epoch 21.192), train_loss = 1.06616978, grad/param norm = 1.7731e-01, time/batch = 14.8666s	
11042/26050 (epoch 21.194), train_loss = 1.05961578, grad/param norm = 1.9376e-01, time/batch = 18.0631s	
11043/26050 (epoch 21.196), train_loss = 1.10566341, grad/param norm = 1.9733e-01, time/batch = 18.0536s	
11044/26050 (epoch 21.198), train_loss = 0.91883331, grad/param norm = 1.6594e-01, time/batch = 18.3099s	
11045/26050 (epoch 21.200), train_loss = 0.92482770, grad/param norm = 1.7863e-01, time/batch = 18.6358s	
11046/26050 (epoch 21.202), train_loss = 1.01665021, grad/param norm = 1.8176e-01, time/batch = 17.7342s	
11047/26050 (epoch 21.203), train_loss = 1.12002183, grad/param norm = 1.9864e-01, time/batch = 15.9554s	
11048/26050 (epoch 21.205), train_loss = 0.94864802, grad/param norm = 1.7276e-01, time/batch = 18.4755s	
11049/26050 (epoch 21.207), train_loss = 0.93794655, grad/param norm = 1.6802e-01, time/batch = 17.3144s	
11050/26050 (epoch 21.209), train_loss = 1.05032265, grad/param norm = 1.6939e-01, time/batch = 17.9060s	
11051/26050 (epoch 21.211), train_loss = 0.83923515, grad/param norm = 1.5631e-01, time/batch = 18.5587s	
11052/26050 (epoch 21.213), train_loss = 1.05611526, grad/param norm = 1.9854e-01, time/batch = 18.3719s	
11053/26050 (epoch 21.215), train_loss = 0.99228436, grad/param norm = 1.9990e-01, time/batch = 18.6455s	
11054/26050 (epoch 21.217), train_loss = 0.96237524, grad/param norm = 1.7133e-01, time/batch = 18.3176s	
11055/26050 (epoch 21.219), train_loss = 0.97408031, grad/param norm = 1.9135e-01, time/batch = 16.3895s	
11056/26050 (epoch 21.221), train_loss = 0.91123819, grad/param norm = 1.8863e-01, time/batch = 16.5768s	
11057/26050 (epoch 21.223), train_loss = 1.04301192, grad/param norm = 1.8364e-01, time/batch = 18.0592s	
11058/26050 (epoch 21.225), train_loss = 0.89437063, grad/param norm = 1.7806e-01, time/batch = 16.0468s	
11059/26050 (epoch 21.226), train_loss = 1.05682378, grad/param norm = 2.2032e-01, time/batch = 17.6115s	
11060/26050 (epoch 21.228), train_loss = 1.14711141, grad/param norm = 1.9314e-01, time/batch = 18.2196s	
11061/26050 (epoch 21.230), train_loss = 1.04027695, grad/param norm = 1.7322e-01, time/batch = 18.4126s	
11062/26050 (epoch 21.232), train_loss = 1.09424155, grad/param norm = 2.1431e-01, time/batch = 18.7481s	
11063/26050 (epoch 21.234), train_loss = 0.88604976, grad/param norm = 1.7051e-01, time/batch = 16.1519s	
11064/26050 (epoch 21.236), train_loss = 1.09434719, grad/param norm = 1.9064e-01, time/batch = 18.4767s	
11065/26050 (epoch 21.238), train_loss = 0.87214713, grad/param norm = 1.6772e-01, time/batch = 17.4102s	
11066/26050 (epoch 21.240), train_loss = 1.01576291, grad/param norm = 1.8565e-01, time/batch = 17.5616s	
11067/26050 (epoch 21.242), train_loss = 1.00051206, grad/param norm = 1.7120e-01, time/batch = 18.9727s	
11068/26050 (epoch 21.244), train_loss = 1.00325731, grad/param norm = 1.9804e-01, time/batch = 17.6608s	
11069/26050 (epoch 21.246), train_loss = 0.93053042, grad/param norm = 1.7405e-01, time/batch = 17.3176s	
11070/26050 (epoch 21.248), train_loss = 1.01871298, grad/param norm = 1.8617e-01, time/batch = 17.1494s	
11071/26050 (epoch 21.250), train_loss = 1.00346831, grad/param norm = 1.9206e-01, time/batch = 15.9724s	
11072/26050 (epoch 21.251), train_loss = 0.96553557, grad/param norm = 1.6760e-01, time/batch = 16.8838s	
11073/26050 (epoch 21.253), train_loss = 0.88595850, grad/param norm = 1.7467e-01, time/batch = 14.9811s	
11074/26050 (epoch 21.255), train_loss = 1.17916754, grad/param norm = 1.8889e-01, time/batch = 18.8288s	
11075/26050 (epoch 21.257), train_loss = 0.99840315, grad/param norm = 1.9364e-01, time/batch = 18.0609s	
11076/26050 (epoch 21.259), train_loss = 1.13518155, grad/param norm = 1.8586e-01, time/batch = 17.6266s	
11077/26050 (epoch 21.261), train_loss = 0.89936733, grad/param norm = 1.7367e-01, time/batch = 17.7286s	
11078/26050 (epoch 21.263), train_loss = 1.06737431, grad/param norm = 1.9535e-01, time/batch = 15.9724s	
11079/26050 (epoch 21.265), train_loss = 1.15793142, grad/param norm = 1.9584e-01, time/batch = 18.2470s	
11080/26050 (epoch 21.267), train_loss = 1.12522361, grad/param norm = 1.7407e-01, time/batch = 16.2387s	
11081/26050 (epoch 21.269), train_loss = 1.13155596, grad/param norm = 2.0365e-01, time/batch = 18.5702s	
11082/26050 (epoch 21.271), train_loss = 1.05764026, grad/param norm = 1.8833e-01, time/batch = 18.6497s	
11083/26050 (epoch 21.273), train_loss = 0.97428493, grad/param norm = 1.9838e-01, time/batch = 16.9042s	
11084/26050 (epoch 21.274), train_loss = 0.98393318, grad/param norm = 1.6905e-01, time/batch = 17.9899s	
11085/26050 (epoch 21.276), train_loss = 0.96272214, grad/param norm = 2.0123e-01, time/batch = 18.1390s	
11086/26050 (epoch 21.278), train_loss = 1.14387233, grad/param norm = 1.8526e-01, time/batch = 18.2167s	
11087/26050 (epoch 21.280), train_loss = 1.00394180, grad/param norm = 1.7695e-01, time/batch = 18.4086s	
11088/26050 (epoch 21.282), train_loss = 1.04279879, grad/param norm = 1.8426e-01, time/batch = 14.7974s	
11089/26050 (epoch 21.284), train_loss = 0.96656434, grad/param norm = 1.7186e-01, time/batch = 18.1364s	
11090/26050 (epoch 21.286), train_loss = 1.02700411, grad/param norm = 1.9524e-01, time/batch = 15.8201s	
11091/26050 (epoch 21.288), train_loss = 0.87141757, grad/param norm = 1.6188e-01, time/batch = 17.9028s	
11092/26050 (epoch 21.290), train_loss = 1.02052939, grad/param norm = 1.8005e-01, time/batch = 18.9636s	
11093/26050 (epoch 21.292), train_loss = 0.92216526, grad/param norm = 1.6015e-01, time/batch = 17.5805s	
11094/26050 (epoch 21.294), train_loss = 1.02451092, grad/param norm = 2.0371e-01, time/batch = 17.5567s	
11095/26050 (epoch 21.296), train_loss = 1.10905943, grad/param norm = 1.8839e-01, time/batch = 17.1400s	
11096/26050 (epoch 21.298), train_loss = 1.02453504, grad/param norm = 1.7795e-01, time/batch = 16.9553s	
11097/26050 (epoch 21.299), train_loss = 0.81677615, grad/param norm = 1.5003e-01, time/batch = 16.9819s	
11098/26050 (epoch 21.301), train_loss = 0.87981675, grad/param norm = 1.7612e-01, time/batch = 18.7353s	
11099/26050 (epoch 21.303), train_loss = 1.00421257, grad/param norm = 1.8922e-01, time/batch = 17.9616s	
11100/26050 (epoch 21.305), train_loss = 0.83748952, grad/param norm = 1.7317e-01, time/batch = 14.8924s	
11101/26050 (epoch 21.307), train_loss = 0.93598032, grad/param norm = 1.8508e-01, time/batch = 18.7913s	
11102/26050 (epoch 21.309), train_loss = 0.99326119, grad/param norm = 1.9267e-01, time/batch = 18.1609s	
11103/26050 (epoch 21.311), train_loss = 1.09981899, grad/param norm = 2.0495e-01, time/batch = 18.6354s	
11104/26050 (epoch 21.313), train_loss = 1.00655786, grad/param norm = 2.1296e-01, time/batch = 31.7985s	
11105/26050 (epoch 21.315), train_loss = 1.11557188, grad/param norm = 1.9889e-01, time/batch = 25.8291s	
11106/26050 (epoch 21.317), train_loss = 1.01995884, grad/param norm = 1.8521e-01, time/batch = 17.8310s	
11107/26050 (epoch 21.319), train_loss = 0.92792052, grad/param norm = 1.6546e-01, time/batch = 18.8064s	
11108/26050 (epoch 21.321), train_loss = 0.97028007, grad/param norm = 1.7604e-01, time/batch = 17.4025s	
11109/26050 (epoch 21.322), train_loss = 1.02738543, grad/param norm = 1.6841e-01, time/batch = 16.0295s	
11110/26050 (epoch 21.324), train_loss = 0.83612868, grad/param norm = 1.7100e-01, time/batch = 16.8780s	
11111/26050 (epoch 21.326), train_loss = 1.15018109, grad/param norm = 1.9891e-01, time/batch = 18.4027s	
11112/26050 (epoch 21.328), train_loss = 1.04517025, grad/param norm = 1.8175e-01, time/batch = 17.7351s	
11113/26050 (epoch 21.330), train_loss = 0.89687453, grad/param norm = 1.7415e-01, time/batch = 17.9900s	
11114/26050 (epoch 21.332), train_loss = 1.05761262, grad/param norm = 1.8877e-01, time/batch = 18.3151s	
11115/26050 (epoch 21.334), train_loss = 0.96264049, grad/param norm = 1.8331e-01, time/batch = 16.8079s	
11116/26050 (epoch 21.336), train_loss = 0.97017233, grad/param norm = 1.9461e-01, time/batch = 17.1506s	
11117/26050 (epoch 21.338), train_loss = 0.88487092, grad/param norm = 1.5747e-01, time/batch = 18.6508s	
11118/26050 (epoch 21.340), train_loss = 1.09976633, grad/param norm = 1.9269e-01, time/batch = 17.7301s	
11119/26050 (epoch 21.342), train_loss = 1.10622724, grad/param norm = 1.8715e-01, time/batch = 16.8093s	
11120/26050 (epoch 21.344), train_loss = 0.95616800, grad/param norm = 1.9130e-01, time/batch = 17.7399s	
11121/26050 (epoch 21.345), train_loss = 0.99908606, grad/param norm = 1.8821e-01, time/batch = 16.8884s	
11122/26050 (epoch 21.347), train_loss = 1.13791052, grad/param norm = 2.0349e-01, time/batch = 18.2243s	
11123/26050 (epoch 21.349), train_loss = 1.07568331, grad/param norm = 2.0628e-01, time/batch = 17.3066s	
11124/26050 (epoch 21.351), train_loss = 1.03839523, grad/param norm = 1.7958e-01, time/batch = 17.1483s	
11125/26050 (epoch 21.353), train_loss = 1.01872673, grad/param norm = 1.9658e-01, time/batch = 15.1443s	
11126/26050 (epoch 21.355), train_loss = 1.06441002, grad/param norm = 1.9684e-01, time/batch = 16.7227s	
11127/26050 (epoch 21.357), train_loss = 0.94495605, grad/param norm = 1.6517e-01, time/batch = 17.9099s	
11128/26050 (epoch 21.359), train_loss = 1.12147302, grad/param norm = 1.8496e-01, time/batch = 18.2201s	
11129/26050 (epoch 21.361), train_loss = 0.93015829, grad/param norm = 1.6415e-01, time/batch = 18.4798s	
11130/26050 (epoch 21.363), train_loss = 1.07447779, grad/param norm = 1.8073e-01, time/batch = 17.8198s	
11131/26050 (epoch 21.365), train_loss = 0.96452582, grad/param norm = 1.6240e-01, time/batch = 18.9619s	
11132/26050 (epoch 21.367), train_loss = 1.05887350, grad/param norm = 1.7434e-01, time/batch = 18.5652s	
11133/26050 (epoch 21.369), train_loss = 0.96851619, grad/param norm = 1.9664e-01, time/batch = 17.1595s	
11134/26050 (epoch 21.370), train_loss = 0.89347180, grad/param norm = 1.5663e-01, time/batch = 17.4172s	
11135/26050 (epoch 21.372), train_loss = 1.05010727, grad/param norm = 1.8516e-01, time/batch = 17.5652s	
11136/26050 (epoch 21.374), train_loss = 1.13010615, grad/param norm = 1.8877e-01, time/batch = 16.8732s	
11137/26050 (epoch 21.376), train_loss = 1.22786649, grad/param norm = 2.0840e-01, time/batch = 15.2214s	
11138/26050 (epoch 21.378), train_loss = 0.97023466, grad/param norm = 1.7673e-01, time/batch = 17.9198s	
11139/26050 (epoch 21.380), train_loss = 1.20023624, grad/param norm = 2.1482e-01, time/batch = 18.2322s	
11140/26050 (epoch 21.382), train_loss = 1.28327619, grad/param norm = 2.2503e-01, time/batch = 17.4653s	
11141/26050 (epoch 21.384), train_loss = 1.01287437, grad/param norm = 1.9726e-01, time/batch = 18.2405s	
11142/26050 (epoch 21.386), train_loss = 1.08219858, grad/param norm = 2.2229e-01, time/batch = 17.8938s	
11143/26050 (epoch 21.388), train_loss = 1.02297552, grad/param norm = 1.8683e-01, time/batch = 17.9648s	
11144/26050 (epoch 21.390), train_loss = 0.95221787, grad/param norm = 1.8417e-01, time/batch = 15.1418s	
11145/26050 (epoch 21.392), train_loss = 0.90238553, grad/param norm = 1.6850e-01, time/batch = 17.7435s	
11146/26050 (epoch 21.393), train_loss = 1.06392020, grad/param norm = 1.9757e-01, time/batch = 18.2373s	
11147/26050 (epoch 21.395), train_loss = 1.06774457, grad/param norm = 1.7591e-01, time/batch = 17.7509s	
11148/26050 (epoch 21.397), train_loss = 1.07660030, grad/param norm = 1.9996e-01, time/batch = 18.6603s	
11149/26050 (epoch 21.399), train_loss = 0.94468520, grad/param norm = 1.8446e-01, time/batch = 18.1545s	
11150/26050 (epoch 21.401), train_loss = 1.02535605, grad/param norm = 1.8611e-01, time/batch = 14.5604s	
11151/26050 (epoch 21.403), train_loss = 1.04115891, grad/param norm = 1.9370e-01, time/batch = 17.3007s	
11152/26050 (epoch 21.405), train_loss = 1.03240888, grad/param norm = 1.8408e-01, time/batch = 17.7113s	
11153/26050 (epoch 21.407), train_loss = 1.16573321, grad/param norm = 1.8662e-01, time/batch = 17.6444s	
11154/26050 (epoch 21.409), train_loss = 1.17428486, grad/param norm = 2.0430e-01, time/batch = 18.0551s	
11155/26050 (epoch 21.411), train_loss = 1.07683168, grad/param norm = 1.8847e-01, time/batch = 18.7242s	
11156/26050 (epoch 21.413), train_loss = 1.17571656, grad/param norm = 1.7576e-01, time/batch = 16.6403s	
11157/26050 (epoch 21.415), train_loss = 1.14381199, grad/param norm = 2.0059e-01, time/batch = 17.9101s	
11158/26050 (epoch 21.417), train_loss = 1.24332325, grad/param norm = 2.0435e-01, time/batch = 18.9717s	
11159/26050 (epoch 21.418), train_loss = 1.14334057, grad/param norm = 2.0499e-01, time/batch = 18.0663s	
11160/26050 (epoch 21.420), train_loss = 0.87620489, grad/param norm = 1.7894e-01, time/batch = 17.9765s	
11161/26050 (epoch 21.422), train_loss = 0.87885685, grad/param norm = 1.7382e-01, time/batch = 15.9832s	
11162/26050 (epoch 21.424), train_loss = 1.17915785, grad/param norm = 2.1673e-01, time/batch = 17.8382s	
11163/26050 (epoch 21.426), train_loss = 1.13141409, grad/param norm = 1.8557e-01, time/batch = 17.9017s	
11164/26050 (epoch 21.428), train_loss = 0.94930210, grad/param norm = 1.5585e-01, time/batch = 17.6490s	
11165/26050 (epoch 21.430), train_loss = 1.14260543, grad/param norm = 1.8482e-01, time/batch = 18.6516s	
11166/26050 (epoch 21.432), train_loss = 0.98994179, grad/param norm = 1.7392e-01, time/batch = 15.2098s	
11167/26050 (epoch 21.434), train_loss = 1.00709969, grad/param norm = 2.0201e-01, time/batch = 16.9839s	
11168/26050 (epoch 21.436), train_loss = 1.15710075, grad/param norm = 2.1143e-01, time/batch = 17.7434s	
11169/26050 (epoch 21.438), train_loss = 1.07730267, grad/param norm = 2.0929e-01, time/batch = 18.7957s	
11170/26050 (epoch 21.440), train_loss = 1.05193826, grad/param norm = 1.9926e-01, time/batch = 17.2350s	
11171/26050 (epoch 21.441), train_loss = 1.01820961, grad/param norm = 1.7730e-01, time/batch = 4.2457s	
11172/26050 (epoch 21.443), train_loss = 0.87713665, grad/param norm = 1.5165e-01, time/batch = 0.6655s	
11173/26050 (epoch 21.445), train_loss = 0.95765678, grad/param norm = 1.7798e-01, time/batch = 0.6859s	
11174/26050 (epoch 21.447), train_loss = 1.16959624, grad/param norm = 2.0523e-01, time/batch = 0.6570s	
11175/26050 (epoch 21.449), train_loss = 0.93729662, grad/param norm = 1.7518e-01, time/batch = 0.6579s	
11176/26050 (epoch 21.451), train_loss = 1.18742219, grad/param norm = 1.9636e-01, time/batch = 0.6683s	
11177/26050 (epoch 21.453), train_loss = 0.94144420, grad/param norm = 1.5833e-01, time/batch = 0.6588s	
11178/26050 (epoch 21.455), train_loss = 1.03648878, grad/param norm = 1.7581e-01, time/batch = 0.7180s	
11179/26050 (epoch 21.457), train_loss = 1.01538925, grad/param norm = 1.7771e-01, time/batch = 0.9522s	
11180/26050 (epoch 21.459), train_loss = 1.12027062, grad/param norm = 1.8485e-01, time/batch = 0.9584s	
11181/26050 (epoch 21.461), train_loss = 1.12373211, grad/param norm = 2.1768e-01, time/batch = 0.9683s	
11182/26050 (epoch 21.463), train_loss = 0.99587746, grad/param norm = 1.7095e-01, time/batch = 0.9437s	
11183/26050 (epoch 21.464), train_loss = 1.06478168, grad/param norm = 1.7356e-01, time/batch = 0.9399s	
11184/26050 (epoch 21.466), train_loss = 1.08948653, grad/param norm = 1.9461e-01, time/batch = 1.7696s	
11185/26050 (epoch 21.468), train_loss = 1.12764770, grad/param norm = 1.7264e-01, time/batch = 1.7486s	
11186/26050 (epoch 21.470), train_loss = 1.16505412, grad/param norm = 2.0695e-01, time/batch = 5.0010s	
11187/26050 (epoch 21.472), train_loss = 1.17643260, grad/param norm = 2.2216e-01, time/batch = 18.8335s	
11188/26050 (epoch 21.474), train_loss = 1.17040251, grad/param norm = 1.7578e-01, time/batch = 16.5758s	
11189/26050 (epoch 21.476), train_loss = 1.15259939, grad/param norm = 1.7982e-01, time/batch = 14.9673s	
11190/26050 (epoch 21.478), train_loss = 1.02076279, grad/param norm = 1.8227e-01, time/batch = 18.1404s	
11191/26050 (epoch 21.480), train_loss = 1.02643167, grad/param norm = 1.6665e-01, time/batch = 18.7211s	
11192/26050 (epoch 21.482), train_loss = 0.98724319, grad/param norm = 1.8183e-01, time/batch = 17.5608s	
11193/26050 (epoch 21.484), train_loss = 0.97938605, grad/param norm = 1.8272e-01, time/batch = 18.4086s	
11194/26050 (epoch 21.486), train_loss = 1.16332785, grad/param norm = 1.8898e-01, time/batch = 16.3924s	
11195/26050 (epoch 21.488), train_loss = 1.26956911, grad/param norm = 2.0360e-01, time/batch = 16.9718s	
11196/26050 (epoch 21.489), train_loss = 1.19606424, grad/param norm = 2.2643e-01, time/batch = 17.8132s	
11197/26050 (epoch 21.491), train_loss = 0.95900559, grad/param norm = 1.7880e-01, time/batch = 18.0707s	
11198/26050 (epoch 21.493), train_loss = 1.05309130, grad/param norm = 1.9807e-01, time/batch = 17.9070s	
11199/26050 (epoch 21.495), train_loss = 1.02770473, grad/param norm = 1.7756e-01, time/batch = 17.7322s	
11200/26050 (epoch 21.497), train_loss = 0.95716510, grad/param norm = 1.7396e-01, time/batch = 18.6538s	
11201/26050 (epoch 21.499), train_loss = 1.00011116, grad/param norm = 1.7457e-01, time/batch = 17.2336s	
11202/26050 (epoch 21.501), train_loss = 1.10763951, grad/param norm = 1.9196e-01, time/batch = 15.4735s	
11203/26050 (epoch 21.503), train_loss = 0.98458405, grad/param norm = 1.8348e-01, time/batch = 17.3921s	
11204/26050 (epoch 21.505), train_loss = 1.16606858, grad/param norm = 1.7985e-01, time/batch = 15.2261s	
11205/26050 (epoch 21.507), train_loss = 1.10657850, grad/param norm = 1.9164e-01, time/batch = 17.5722s	
11206/26050 (epoch 21.509), train_loss = 1.20958360, grad/param norm = 1.8009e-01, time/batch = 17.7240s	
11207/26050 (epoch 21.511), train_loss = 0.97745573, grad/param norm = 1.6540e-01, time/batch = 17.9892s	
11208/26050 (epoch 21.512), train_loss = 0.95922210, grad/param norm = 1.9630e-01, time/batch = 18.3170s	
11209/26050 (epoch 21.514), train_loss = 1.10107200, grad/param norm = 1.9502e-01, time/batch = 16.9821s	
11210/26050 (epoch 21.516), train_loss = 1.17049580, grad/param norm = 2.0323e-01, time/batch = 18.1351s	
11211/26050 (epoch 21.518), train_loss = 1.04172910, grad/param norm = 1.9125e-01, time/batch = 17.3309s	
11212/26050 (epoch 21.520), train_loss = 1.01717226, grad/param norm = 1.7518e-01, time/batch = 15.7109s	
11213/26050 (epoch 21.522), train_loss = 0.80882232, grad/param norm = 1.5473e-01, time/batch = 15.9048s	
11214/26050 (epoch 21.524), train_loss = 1.11670296, grad/param norm = 2.0008e-01, time/batch = 17.7258s	
11215/26050 (epoch 21.526), train_loss = 1.15321355, grad/param norm = 1.9199e-01, time/batch = 18.2234s	
11216/26050 (epoch 21.528), train_loss = 1.09663819, grad/param norm = 2.0577e-01, time/batch = 16.6593s	
11217/26050 (epoch 21.530), train_loss = 1.00432766, grad/param norm = 1.7899e-01, time/batch = 18.2361s	
11218/26050 (epoch 21.532), train_loss = 1.05446247, grad/param norm = 1.8372e-01, time/batch = 18.5801s	
11219/26050 (epoch 21.534), train_loss = 1.10569504, grad/param norm = 2.0951e-01, time/batch = 16.7387s	
11220/26050 (epoch 21.536), train_loss = 1.03611734, grad/param norm = 1.7636e-01, time/batch = 17.4873s	
11221/26050 (epoch 21.537), train_loss = 1.11170697, grad/param norm = 1.9426e-01, time/batch = 14.9599s	
11222/26050 (epoch 21.539), train_loss = 1.04893157, grad/param norm = 1.8613e-01, time/batch = 18.9116s	
11223/26050 (epoch 21.541), train_loss = 1.24278421, grad/param norm = 2.0545e-01, time/batch = 17.8217s	
11224/26050 (epoch 21.543), train_loss = 0.88780484, grad/param norm = 1.9653e-01, time/batch = 14.7998s	
11225/26050 (epoch 21.545), train_loss = 1.09812091, grad/param norm = 1.9421e-01, time/batch = 18.8819s	
11226/26050 (epoch 21.547), train_loss = 1.02464704, grad/param norm = 1.7460e-01, time/batch = 17.7377s	
11227/26050 (epoch 21.549), train_loss = 0.86357852, grad/param norm = 1.7375e-01, time/batch = 15.6508s	
11228/26050 (epoch 21.551), train_loss = 1.09039071, grad/param norm = 1.8333e-01, time/batch = 17.3985s	
11229/26050 (epoch 21.553), train_loss = 0.97116790, grad/param norm = 1.7559e-01, time/batch = 18.7399s	
11230/26050 (epoch 21.555), train_loss = 0.98183631, grad/param norm = 1.7784e-01, time/batch = 18.2285s	
11231/26050 (epoch 21.557), train_loss = 1.06833909, grad/param norm = 1.6821e-01, time/batch = 17.9802s	
11232/26050 (epoch 21.559), train_loss = 1.01184299, grad/param norm = 1.8146e-01, time/batch = 19.0668s	
11233/26050 (epoch 21.560), train_loss = 1.00413361, grad/param norm = 1.9463e-01, time/batch = 17.1468s	
11234/26050 (epoch 21.562), train_loss = 1.01049031, grad/param norm = 1.8044e-01, time/batch = 17.9876s	
11235/26050 (epoch 21.564), train_loss = 1.20347848, grad/param norm = 1.8242e-01, time/batch = 17.9828s	
11236/26050 (epoch 21.566), train_loss = 0.93758757, grad/param norm = 1.7099e-01, time/batch = 17.3122s	
11237/26050 (epoch 21.568), train_loss = 1.07738400, grad/param norm = 1.7859e-01, time/batch = 18.3940s	
11238/26050 (epoch 21.570), train_loss = 1.10004759, grad/param norm = 1.9100e-01, time/batch = 15.0686s	
11239/26050 (epoch 21.572), train_loss = 1.00949867, grad/param norm = 1.8713e-01, time/batch = 18.3218s	
11240/26050 (epoch 21.574), train_loss = 1.07934382, grad/param norm = 2.1072e-01, time/batch = 16.3782s	
11241/26050 (epoch 21.576), train_loss = 1.05957352, grad/param norm = 1.8689e-01, time/batch = 18.3192s	
11242/26050 (epoch 21.578), train_loss = 1.00751680, grad/param norm = 1.8882e-01, time/batch = 18.4828s	
11243/26050 (epoch 21.580), train_loss = 0.97760493, grad/param norm = 1.9570e-01, time/batch = 17.4004s	
11244/26050 (epoch 21.582), train_loss = 1.05702963, grad/param norm = 1.8135e-01, time/batch = 18.6548s	
11245/26050 (epoch 21.583), train_loss = 1.13717904, grad/param norm = 1.7387e-01, time/batch = 15.6616s	
11246/26050 (epoch 21.585), train_loss = 0.89906642, grad/param norm = 1.8599e-01, time/batch = 17.9867s	
11247/26050 (epoch 21.587), train_loss = 1.08692616, grad/param norm = 2.0965e-01, time/batch = 17.2205s	
11248/26050 (epoch 21.589), train_loss = 1.19849727, grad/param norm = 2.0499e-01, time/batch = 16.6310s	
11249/26050 (epoch 21.591), train_loss = 1.01140682, grad/param norm = 1.9015e-01, time/batch = 18.6658s	
11250/26050 (epoch 21.593), train_loss = 0.92030458, grad/param norm = 1.7967e-01, time/batch = 17.7268s	
11251/26050 (epoch 21.595), train_loss = 1.09810053, grad/param norm = 2.0284e-01, time/batch = 16.3908s	
11252/26050 (epoch 21.597), train_loss = 1.06472373, grad/param norm = 1.8971e-01, time/batch = 18.5594s	
11253/26050 (epoch 21.599), train_loss = 1.05209735, grad/param norm = 1.9732e-01, time/batch = 16.5496s	
11254/26050 (epoch 21.601), train_loss = 1.21763748, grad/param norm = 1.8898e-01, time/batch = 17.6621s	
11255/26050 (epoch 21.603), train_loss = 1.05393903, grad/param norm = 1.8264e-01, time/batch = 16.0608s	
11256/26050 (epoch 21.605), train_loss = 0.98142923, grad/param norm = 1.7363e-01, time/batch = 18.8242s	
11257/26050 (epoch 21.607), train_loss = 1.15749637, grad/param norm = 2.0793e-01, time/batch = 17.1504s	
11258/26050 (epoch 21.608), train_loss = 0.89761744, grad/param norm = 1.5748e-01, time/batch = 18.3143s	
11259/26050 (epoch 21.610), train_loss = 1.02466702, grad/param norm = 1.8834e-01, time/batch = 18.4155s	
11260/26050 (epoch 21.612), train_loss = 1.02869155, grad/param norm = 1.8970e-01, time/batch = 16.5457s	
11261/26050 (epoch 21.614), train_loss = 1.05773243, grad/param norm = 1.7852e-01, time/batch = 14.8090s	
11262/26050 (epoch 21.616), train_loss = 1.18401182, grad/param norm = 2.1918e-01, time/batch = 17.6493s	
11263/26050 (epoch 21.618), train_loss = 0.98498391, grad/param norm = 1.9063e-01, time/batch = 17.4614s	
11264/26050 (epoch 21.620), train_loss = 1.08170958, grad/param norm = 1.8133e-01, time/batch = 17.4802s	
11265/26050 (epoch 21.622), train_loss = 0.91207218, grad/param norm = 1.5134e-01, time/batch = 17.7340s	
11266/26050 (epoch 21.624), train_loss = 0.89785112, grad/param norm = 1.7393e-01, time/batch = 18.8971s	
11267/26050 (epoch 21.626), train_loss = 1.10372471, grad/param norm = 1.9304e-01, time/batch = 17.5584s	
11268/26050 (epoch 21.628), train_loss = 0.95850499, grad/param norm = 1.7681e-01, time/batch = 18.5664s	
11269/26050 (epoch 21.630), train_loss = 1.16439476, grad/param norm = 1.8133e-01, time/batch = 18.3277s	
11270/26050 (epoch 21.631), train_loss = 1.19717168, grad/param norm = 1.9441e-01, time/batch = 17.6426s	
11271/26050 (epoch 21.633), train_loss = 0.92507641, grad/param norm = 1.6458e-01, time/batch = 18.1475s	
11272/26050 (epoch 21.635), train_loss = 0.95093932, grad/param norm = 1.6177e-01, time/batch = 15.9529s	
11273/26050 (epoch 21.637), train_loss = 0.93350305, grad/param norm = 1.8103e-01, time/batch = 17.7918s	
11274/26050 (epoch 21.639), train_loss = 1.13588428, grad/param norm = 1.8341e-01, time/batch = 16.7947s	
11275/26050 (epoch 21.641), train_loss = 1.00461341, grad/param norm = 1.6695e-01, time/batch = 18.1960s	
11276/26050 (epoch 21.643), train_loss = 0.92880343, grad/param norm = 1.6107e-01, time/batch = 18.5692s	
11277/26050 (epoch 21.645), train_loss = 1.02100286, grad/param norm = 1.7884e-01, time/batch = 17.7334s	
11278/26050 (epoch 21.647), train_loss = 0.97778356, grad/param norm = 1.8087e-01, time/batch = 15.3020s	
11279/26050 (epoch 21.649), train_loss = 1.05357282, grad/param norm = 2.1386e-01, time/batch = 17.9049s	
11280/26050 (epoch 21.651), train_loss = 0.97883469, grad/param norm = 1.8237e-01, time/batch = 18.6329s	
11281/26050 (epoch 21.653), train_loss = 1.03221672, grad/param norm = 1.7832e-01, time/batch = 18.5410s	
11282/26050 (epoch 21.655), train_loss = 0.96215664, grad/param norm = 1.7856e-01, time/batch = 15.4713s	
11283/26050 (epoch 21.656), train_loss = 0.88575717, grad/param norm = 1.6377e-01, time/batch = 17.2163s	
11284/26050 (epoch 21.658), train_loss = 1.21140969, grad/param norm = 1.9428e-01, time/batch = 16.2047s	
11285/26050 (epoch 21.660), train_loss = 0.90333198, grad/param norm = 1.8157e-01, time/batch = 18.1565s	
11286/26050 (epoch 21.662), train_loss = 0.98832548, grad/param norm = 1.8001e-01, time/batch = 18.7282s	
11287/26050 (epoch 21.664), train_loss = 1.01589527, grad/param norm = 1.7967e-01, time/batch = 17.4878s	
11288/26050 (epoch 21.666), train_loss = 0.99394792, grad/param norm = 1.9168e-01, time/batch = 17.8858s	
11289/26050 (epoch 21.668), train_loss = 0.84875339, grad/param norm = 1.9523e-01, time/batch = 18.7377s	
11290/26050 (epoch 21.670), train_loss = 1.16677265, grad/param norm = 2.1202e-01, time/batch = 19.0570s	
11291/26050 (epoch 21.672), train_loss = 1.02577827, grad/param norm = 2.0272e-01, time/batch = 17.4740s	
11292/26050 (epoch 21.674), train_loss = 0.94103677, grad/param norm = 1.7642e-01, time/batch = 18.9747s	
11293/26050 (epoch 21.676), train_loss = 1.07762973, grad/param norm = 2.0318e-01, time/batch = 18.0627s	
11294/26050 (epoch 21.678), train_loss = 1.15689737, grad/param norm = 2.0406e-01, time/batch = 17.1411s	
11295/26050 (epoch 21.679), train_loss = 1.22089874, grad/param norm = 2.0568e-01, time/batch = 18.1285s	
11296/26050 (epoch 21.681), train_loss = 1.04530160, grad/param norm = 1.8507e-01, time/batch = 17.8162s	
11297/26050 (epoch 21.683), train_loss = 0.95412322, grad/param norm = 2.5738e-01, time/batch = 17.8116s	
11298/26050 (epoch 21.685), train_loss = 1.00076316, grad/param norm = 1.9295e-01, time/batch = 17.4806s	
11299/26050 (epoch 21.687), train_loss = 0.89185974, grad/param norm = 1.7988e-01, time/batch = 15.2324s	
11300/26050 (epoch 21.689), train_loss = 0.99403577, grad/param norm = 1.9605e-01, time/batch = 17.9784s	
11301/26050 (epoch 21.691), train_loss = 0.81634359, grad/param norm = 1.6275e-01, time/batch = 17.1480s	
11302/26050 (epoch 21.693), train_loss = 0.93587739, grad/param norm = 1.8737e-01, time/batch = 14.9012s	
11303/26050 (epoch 21.695), train_loss = 1.03340170, grad/param norm = 1.8761e-01, time/batch = 18.4061s	
11304/26050 (epoch 21.697), train_loss = 0.92624208, grad/param norm = 1.6448e-01, time/batch = 14.9635s	
11305/26050 (epoch 21.699), train_loss = 1.08126839, grad/param norm = 2.0323e-01, time/batch = 17.0309s	
11306/26050 (epoch 21.701), train_loss = 0.92281962, grad/param norm = 1.6472e-01, time/batch = 17.6593s	
11307/26050 (epoch 21.702), train_loss = 1.14561093, grad/param norm = 1.9342e-01, time/batch = 18.9797s	
11308/26050 (epoch 21.704), train_loss = 1.11465968, grad/param norm = 1.7023e-01, time/batch = 17.1533s	
11309/26050 (epoch 21.706), train_loss = 1.00615127, grad/param norm = 2.0505e-01, time/batch = 17.3202s	
11310/26050 (epoch 21.708), train_loss = 1.10342264, grad/param norm = 1.8836e-01, time/batch = 18.3083s	
11311/26050 (epoch 21.710), train_loss = 1.09206416, grad/param norm = 2.0098e-01, time/batch = 15.2929s	
11312/26050 (epoch 21.712), train_loss = 1.07350234, grad/param norm = 1.8895e-01, time/batch = 18.3178s	
11313/26050 (epoch 21.714), train_loss = 0.88897487, grad/param norm = 1.8456e-01, time/batch = 17.4868s	
11314/26050 (epoch 21.716), train_loss = 1.26575520, grad/param norm = 2.0176e-01, time/batch = 18.8193s	
11315/26050 (epoch 21.718), train_loss = 1.11568842, grad/param norm = 1.9362e-01, time/batch = 16.9045s	
11316/26050 (epoch 21.720), train_loss = 1.00835046, grad/param norm = 1.9040e-01, time/batch = 18.8920s	
11317/26050 (epoch 21.722), train_loss = 0.89053143, grad/param norm = 1.7372e-01, time/batch = 16.7129s	
11318/26050 (epoch 21.724), train_loss = 0.95388350, grad/param norm = 1.9001e-01, time/batch = 16.9903s	
11319/26050 (epoch 21.726), train_loss = 1.09862671, grad/param norm = 1.9722e-01, time/batch = 18.8976s	
11320/26050 (epoch 21.727), train_loss = 1.08029926, grad/param norm = 1.9227e-01, time/batch = 18.4650s	
11321/26050 (epoch 21.729), train_loss = 1.08504323, grad/param norm = 1.8751e-01, time/batch = 18.2920s	
11322/26050 (epoch 21.731), train_loss = 1.05522307, grad/param norm = 1.7386e-01, time/batch = 32.1080s	
11323/26050 (epoch 21.733), train_loss = 0.99817961, grad/param norm = 2.2465e-01, time/batch = 24.3087s	
11324/26050 (epoch 21.735), train_loss = 1.23087923, grad/param norm = 2.0416e-01, time/batch = 16.2669s	
11325/26050 (epoch 21.737), train_loss = 0.97368061, grad/param norm = 1.8545e-01, time/batch = 16.9689s	
11326/26050 (epoch 21.739), train_loss = 1.04704073, grad/param norm = 1.7691e-01, time/batch = 18.9886s	
11327/26050 (epoch 21.741), train_loss = 0.95511792, grad/param norm = 1.9894e-01, time/batch = 17.3973s	
11328/26050 (epoch 21.743), train_loss = 1.08431406, grad/param norm = 2.8605e-01, time/batch = 18.8851s	
11329/26050 (epoch 21.745), train_loss = 0.90703959, grad/param norm = 1.8361e-01, time/batch = 18.3209s	
11330/26050 (epoch 21.747), train_loss = 0.92876884, grad/param norm = 1.7545e-01, time/batch = 17.6650s	
11331/26050 (epoch 21.749), train_loss = 1.15379354, grad/param norm = 1.9324e-01, time/batch = 17.9922s	
11332/26050 (epoch 21.750), train_loss = 1.01739390, grad/param norm = 1.6275e-01, time/batch = 18.6474s	
11333/26050 (epoch 21.752), train_loss = 1.00705017, grad/param norm = 2.2877e-01, time/batch = 17.4755s	
11334/26050 (epoch 21.754), train_loss = 1.04702766, grad/param norm = 1.8781e-01, time/batch = 18.0329s	
11335/26050 (epoch 21.756), train_loss = 1.02668919, grad/param norm = 2.2510e-01, time/batch = 18.3161s	
11336/26050 (epoch 21.758), train_loss = 1.01385171, grad/param norm = 2.1024e-01, time/batch = 16.1293s	
11337/26050 (epoch 21.760), train_loss = 1.21917959, grad/param norm = 2.0167e-01, time/batch = 17.0585s	
11338/26050 (epoch 21.762), train_loss = 0.97958282, grad/param norm = 1.8337e-01, time/batch = 18.7130s	
11339/26050 (epoch 21.764), train_loss = 1.04314328, grad/param norm = 1.8875e-01, time/batch = 18.4887s	
11340/26050 (epoch 21.766), train_loss = 1.09246211, grad/param norm = 2.2554e-01, time/batch = 17.5800s	
11341/26050 (epoch 21.768), train_loss = 0.92345830, grad/param norm = 1.6635e-01, time/batch = 15.1462s	
11342/26050 (epoch 21.770), train_loss = 1.02495195, grad/param norm = 2.2013e-01, time/batch = 17.9848s	
11343/26050 (epoch 21.772), train_loss = 1.02369031, grad/param norm = 1.7106e-01, time/batch = 18.8107s	
11344/26050 (epoch 21.774), train_loss = 0.89209702, grad/param norm = 1.8862e-01, time/batch = 17.4154s	
11345/26050 (epoch 21.775), train_loss = 0.74174894, grad/param norm = 1.6026e-01, time/batch = 16.8790s	
11346/26050 (epoch 21.777), train_loss = 0.95337292, grad/param norm = 1.8070e-01, time/batch = 18.0662s	
11347/26050 (epoch 21.779), train_loss = 0.98818618, grad/param norm = 1.8415e-01, time/batch = 18.3191s	
11348/26050 (epoch 21.781), train_loss = 0.91170567, grad/param norm = 1.7897e-01, time/batch = 18.4704s	
11349/26050 (epoch 21.783), train_loss = 0.90715536, grad/param norm = 1.8288e-01, time/batch = 15.0546s	
11350/26050 (epoch 21.785), train_loss = 1.01276336, grad/param norm = 1.8542e-01, time/batch = 17.8167s	
11351/26050 (epoch 21.787), train_loss = 0.93588106, grad/param norm = 1.8616e-01, time/batch = 18.4639s	
11352/26050 (epoch 21.789), train_loss = 0.96248684, grad/param norm = 2.1049e-01, time/batch = 18.4854s	
11353/26050 (epoch 21.791), train_loss = 0.96353889, grad/param norm = 1.8999e-01, time/batch = 17.5675s	
11354/26050 (epoch 21.793), train_loss = 1.01810828, grad/param norm = 1.9689e-01, time/batch = 16.4847s	
11355/26050 (epoch 21.795), train_loss = 0.82991103, grad/param norm = 1.5314e-01, time/batch = 18.2407s	
11356/26050 (epoch 21.797), train_loss = 0.94050353, grad/param norm = 1.7307e-01, time/batch = 18.1530s	
11357/26050 (epoch 21.798), train_loss = 0.86917751, grad/param norm = 1.7256e-01, time/batch = 17.8250s	
11358/26050 (epoch 21.800), train_loss = 0.88493555, grad/param norm = 1.6218e-01, time/batch = 18.5488s	
11359/26050 (epoch 21.802), train_loss = 0.96980509, grad/param norm = 1.9263e-01, time/batch = 17.4028s	
11360/26050 (epoch 21.804), train_loss = 1.01025386, grad/param norm = 1.8773e-01, time/batch = 17.7938s	
11361/26050 (epoch 21.806), train_loss = 1.09561296, grad/param norm = 1.8725e-01, time/batch = 17.9581s	
11362/26050 (epoch 21.808), train_loss = 1.00894515, grad/param norm = 1.7509e-01, time/batch = 18.8045s	
11363/26050 (epoch 21.810), train_loss = 0.96890540, grad/param norm = 1.8274e-01, time/batch = 18.6501s	
11364/26050 (epoch 21.812), train_loss = 0.90108507, grad/param norm = 1.8431e-01, time/batch = 16.6418s	
11365/26050 (epoch 21.814), train_loss = 0.90269287, grad/param norm = 1.9287e-01, time/batch = 17.2727s	
11366/26050 (epoch 21.816), train_loss = 1.10110902, grad/param norm = 2.0307e-01, time/batch = 18.6607s	
11367/26050 (epoch 21.818), train_loss = 1.10919743, grad/param norm = 2.0173e-01, time/batch = 17.0803s	
11368/26050 (epoch 21.820), train_loss = 1.03063181, grad/param norm = 1.8550e-01, time/batch = 17.7393s	
11369/26050 (epoch 21.821), train_loss = 1.14253506, grad/param norm = 2.0098e-01, time/batch = 18.7285s	
11370/26050 (epoch 21.823), train_loss = 1.15904657, grad/param norm = 1.9988e-01, time/batch = 17.9773s	
11371/26050 (epoch 21.825), train_loss = 1.00094481, grad/param norm = 1.9386e-01, time/batch = 18.6978s	
11372/26050 (epoch 21.827), train_loss = 1.04086591, grad/param norm = 2.0331e-01, time/batch = 15.9726s	
11373/26050 (epoch 21.829), train_loss = 1.11161397, grad/param norm = 2.0116e-01, time/batch = 15.4987s	
11374/26050 (epoch 21.831), train_loss = 1.15605621, grad/param norm = 1.8147e-01, time/batch = 16.2253s	
11375/26050 (epoch 21.833), train_loss = 1.21994276, grad/param norm = 2.0093e-01, time/batch = 17.7427s	
11376/26050 (epoch 21.835), train_loss = 1.20366812, grad/param norm = 1.9553e-01, time/batch = 15.2245s	
11377/26050 (epoch 21.837), train_loss = 1.02324023, grad/param norm = 1.7184e-01, time/batch = 18.6583s	
11378/26050 (epoch 21.839), train_loss = 1.04896025, grad/param norm = 2.1039e-01, time/batch = 17.6364s	
11379/26050 (epoch 21.841), train_loss = 1.17034646, grad/param norm = 1.9400e-01, time/batch = 18.7376s	
11380/26050 (epoch 21.843), train_loss = 1.01402339, grad/param norm = 1.7747e-01, time/batch = 18.2988s	
11381/26050 (epoch 21.845), train_loss = 0.97697913, grad/param norm = 1.7439e-01, time/batch = 16.8777s	
11382/26050 (epoch 21.846), train_loss = 1.10613613, grad/param norm = 1.7760e-01, time/batch = 15.0688s	
11383/26050 (epoch 21.848), train_loss = 1.00697876, grad/param norm = 1.7766e-01, time/batch = 15.2368s	
11384/26050 (epoch 21.850), train_loss = 0.93136521, grad/param norm = 1.7450e-01, time/batch = 17.9062s	
11385/26050 (epoch 21.852), train_loss = 1.02133517, grad/param norm = 1.7774e-01, time/batch = 18.0549s	
11386/26050 (epoch 21.854), train_loss = 1.00787243, grad/param norm = 1.8523e-01, time/batch = 18.9902s	
11387/26050 (epoch 21.856), train_loss = 0.98752590, grad/param norm = 1.9698e-01, time/batch = 16.9013s	
11388/26050 (epoch 21.858), train_loss = 0.93491107, grad/param norm = 1.8443e-01, time/batch = 16.6325s	
11389/26050 (epoch 21.860), train_loss = 1.04864672, grad/param norm = 1.8195e-01, time/batch = 18.5776s	
11390/26050 (epoch 21.862), train_loss = 1.09034816, grad/param norm = 1.9047e-01, time/batch = 18.4007s	
11391/26050 (epoch 21.864), train_loss = 1.05571561, grad/param norm = 2.0814e-01, time/batch = 18.0643s	
11392/26050 (epoch 21.866), train_loss = 0.97509938, grad/param norm = 1.6666e-01, time/batch = 17.3922s	
11393/26050 (epoch 21.868), train_loss = 1.06588529, grad/param norm = 1.9570e-01, time/batch = 16.2161s	
11394/26050 (epoch 21.869), train_loss = 0.91518998, grad/param norm = 1.6539e-01, time/batch = 15.2229s	
11395/26050 (epoch 21.871), train_loss = 0.85194791, grad/param norm = 1.6392e-01, time/batch = 17.5608s	
11396/26050 (epoch 21.873), train_loss = 1.08391421, grad/param norm = 2.0901e-01, time/batch = 17.9648s	
11397/26050 (epoch 21.875), train_loss = 1.02384906, grad/param norm = 2.0008e-01, time/batch = 14.7313s	
11398/26050 (epoch 21.877), train_loss = 0.90785066, grad/param norm = 1.6892e-01, time/batch = 17.6638s	
11399/26050 (epoch 21.879), train_loss = 1.03453904, grad/param norm = 1.6602e-01, time/batch = 18.0654s	
11400/26050 (epoch 21.881), train_loss = 1.12232552, grad/param norm = 2.0002e-01, time/batch = 18.7308s	
11401/26050 (epoch 21.883), train_loss = 1.06425770, grad/param norm = 1.7749e-01, time/batch = 19.0696s	
11402/26050 (epoch 21.885), train_loss = 0.77591237, grad/param norm = 1.6290e-01, time/batch = 16.4591s	
11403/26050 (epoch 21.887), train_loss = 1.06511396, grad/param norm = 1.8132e-01, time/batch = 16.2248s	
11404/26050 (epoch 21.889), train_loss = 0.96924637, grad/param norm = 1.7612e-01, time/batch = 18.3257s	
11405/26050 (epoch 21.891), train_loss = 0.84614711, grad/param norm = 1.6553e-01, time/batch = 17.3699s	
11406/26050 (epoch 21.893), train_loss = 0.88527899, grad/param norm = 1.7091e-01, time/batch = 16.8887s	
11407/26050 (epoch 21.894), train_loss = 0.96620723, grad/param norm = 1.7153e-01, time/batch = 17.4561s	
11408/26050 (epoch 21.896), train_loss = 1.10370104, grad/param norm = 1.8482e-01, time/batch = 18.7195s	
11409/26050 (epoch 21.898), train_loss = 0.95502620, grad/param norm = 1.8986e-01, time/batch = 17.1542s	
11410/26050 (epoch 21.900), train_loss = 1.05491742, grad/param norm = 1.8635e-01, time/batch = 18.6372s	
11411/26050 (epoch 21.902), train_loss = 1.00038702, grad/param norm = 1.7707e-01, time/batch = 18.5646s	
11412/26050 (epoch 21.904), train_loss = 1.00270301, grad/param norm = 1.8752e-01, time/batch = 14.7031s	
11413/26050 (epoch 21.906), train_loss = 1.00643063, grad/param norm = 1.9438e-01, time/batch = 18.1691s	
11414/26050 (epoch 21.908), train_loss = 1.01270795, grad/param norm = 1.7205e-01, time/batch = 15.1532s	
11415/26050 (epoch 21.910), train_loss = 0.97960291, grad/param norm = 1.8081e-01, time/batch = 18.1576s	
11416/26050 (epoch 21.912), train_loss = 1.21732607, grad/param norm = 2.0349e-01, time/batch = 18.0680s	
11417/26050 (epoch 21.914), train_loss = 1.36731189, grad/param norm = 2.2289e-01, time/batch = 18.4835s	
11418/26050 (epoch 21.916), train_loss = 1.12979391, grad/param norm = 2.0134e-01, time/batch = 18.6584s	
11419/26050 (epoch 21.917), train_loss = 1.02689704, grad/param norm = 2.0913e-01, time/batch = 16.3719s	
11420/26050 (epoch 21.919), train_loss = 1.09866064, grad/param norm = 2.0296e-01, time/batch = 17.6373s	
11421/26050 (epoch 21.921), train_loss = 0.97075144, grad/param norm = 1.9160e-01, time/batch = 17.7367s	
11422/26050 (epoch 21.923), train_loss = 1.03307914, grad/param norm = 1.9185e-01, time/batch = 16.2278s	
11423/26050 (epoch 21.925), train_loss = 1.00736504, grad/param norm = 1.7468e-01, time/batch = 18.0847s	
11424/26050 (epoch 21.927), train_loss = 0.90063595, grad/param norm = 1.4757e-01, time/batch = 18.3904s	
11425/26050 (epoch 21.929), train_loss = 0.88096398, grad/param norm = 1.7219e-01, time/batch = 16.8811s	
11426/26050 (epoch 21.931), train_loss = 1.18066994, grad/param norm = 2.1458e-01, time/batch = 14.4626s	
11427/26050 (epoch 21.933), train_loss = 0.97361674, grad/param norm = 1.7665e-01, time/batch = 14.8883s	
11428/26050 (epoch 21.935), train_loss = 0.99645673, grad/param norm = 1.8203e-01, time/batch = 18.8188s	
11429/26050 (epoch 21.937), train_loss = 1.10909466, grad/param norm = 1.8617e-01, time/batch = 17.4862s	
11430/26050 (epoch 21.939), train_loss = 0.93487030, grad/param norm = 1.5439e-01, time/batch = 15.4839s	
11431/26050 (epoch 21.940), train_loss = 0.97588626, grad/param norm = 1.5879e-01, time/batch = 18.5659s	
11432/26050 (epoch 21.942), train_loss = 1.00573136, grad/param norm = 1.8057e-01, time/batch = 18.2355s	
11433/26050 (epoch 21.944), train_loss = 0.97034175, grad/param norm = 1.6324e-01, time/batch = 17.5669s	
11434/26050 (epoch 21.946), train_loss = 1.15102592, grad/param norm = 1.9566e-01, time/batch = 18.8155s	
11435/26050 (epoch 21.948), train_loss = 0.91084603, grad/param norm = 2.0052e-01, time/batch = 18.2390s	
11436/26050 (epoch 21.950), train_loss = 0.99114230, grad/param norm = 1.7858e-01, time/batch = 16.4983s	
11437/26050 (epoch 21.952), train_loss = 1.09713687, grad/param norm = 1.9455e-01, time/batch = 15.2340s	
11438/26050 (epoch 21.954), train_loss = 1.11070855, grad/param norm = 1.8364e-01, time/batch = 15.3411s	
11439/26050 (epoch 21.956), train_loss = 1.00813969, grad/param norm = 1.8652e-01, time/batch = 13.9247s	
11440/26050 (epoch 21.958), train_loss = 0.96080364, grad/param norm = 1.7137e-01, time/batch = 14.2153s	
11441/26050 (epoch 21.960), train_loss = 1.04210673, grad/param norm = 1.9561e-01, time/batch = 14.1549s	
11442/26050 (epoch 21.962), train_loss = 0.96191628, grad/param norm = 1.6063e-01, time/batch = 18.0438s	
11443/26050 (epoch 21.964), train_loss = 1.01452134, grad/param norm = 1.8638e-01, time/batch = 18.1646s	
11444/26050 (epoch 21.965), train_loss = 0.94280062, grad/param norm = 1.7965e-01, time/batch = 16.8111s	
11445/26050 (epoch 21.967), train_loss = 1.34446000, grad/param norm = 1.9378e-01, time/batch = 17.6534s	
11446/26050 (epoch 21.969), train_loss = 1.04076284, grad/param norm = 2.1051e-01, time/batch = 16.8078s	
11447/26050 (epoch 21.971), train_loss = 0.97003714, grad/param norm = 1.6836e-01, time/batch = 17.8958s	
11448/26050 (epoch 21.973), train_loss = 1.02975191, grad/param norm = 1.9058e-01, time/batch = 17.8985s	
11449/26050 (epoch 21.975), train_loss = 1.04994718, grad/param norm = 1.8227e-01, time/batch = 14.3928s	
11450/26050 (epoch 21.977), train_loss = 1.04114070, grad/param norm = 1.6971e-01, time/batch = 18.8891s	
11451/26050 (epoch 21.979), train_loss = 0.85332446, grad/param norm = 1.6948e-01, time/batch = 16.9189s	
11452/26050 (epoch 21.981), train_loss = 1.15540512, grad/param norm = 1.7858e-01, time/batch = 15.7171s	
11453/26050 (epoch 21.983), train_loss = 1.09625986, grad/param norm = 1.9460e-01, time/batch = 18.7341s	
11454/26050 (epoch 21.985), train_loss = 1.06534215, grad/param norm = 1.8749e-01, time/batch = 17.0738s	
11455/26050 (epoch 21.987), train_loss = 1.12473593, grad/param norm = 1.8080e-01, time/batch = 18.1504s	
11456/26050 (epoch 21.988), train_loss = 1.09454641, grad/param norm = 1.9266e-01, time/batch = 18.3249s	
11457/26050 (epoch 21.990), train_loss = 0.91060071, grad/param norm = 1.5607e-01, time/batch = 16.8163s	
11458/26050 (epoch 21.992), train_loss = 1.17540343, grad/param norm = 1.9021e-01, time/batch = 18.0545s	
11459/26050 (epoch 21.994), train_loss = 0.98545771, grad/param norm = 1.8225e-01, time/batch = 17.7361s	
11460/26050 (epoch 21.996), train_loss = 0.96426591, grad/param norm = 1.7943e-01, time/batch = 18.6515s	
11461/26050 (epoch 21.998), train_loss = 1.02438629, grad/param norm = 1.8057e-01, time/batch = 17.8858s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
11462/26050 (epoch 22.000), train_loss = 0.97834458, grad/param norm = 1.9822e-01, time/batch = 17.6543s	
11463/26050 (epoch 22.002), train_loss = 1.08734840, grad/param norm = 2.0014e-01, time/batch = 14.3724s	
11464/26050 (epoch 22.004), train_loss = 0.93632318, grad/param norm = 1.8381e-01, time/batch = 18.1346s	
11465/26050 (epoch 22.006), train_loss = 0.96355399, grad/param norm = 1.9367e-01, time/batch = 18.1451s	
11466/26050 (epoch 22.008), train_loss = 0.96054295, grad/param norm = 1.9387e-01, time/batch = 16.8062s	
11467/26050 (epoch 22.010), train_loss = 0.94783320, grad/param norm = 1.9131e-01, time/batch = 18.4750s	
11468/26050 (epoch 22.012), train_loss = 1.02916341, grad/param norm = 1.8670e-01, time/batch = 18.3003s	
11469/26050 (epoch 22.013), train_loss = 1.32580297, grad/param norm = 2.2975e-01, time/batch = 16.5580s	
11470/26050 (epoch 22.015), train_loss = 0.97636654, grad/param norm = 1.6781e-01, time/batch = 17.9805s	
11471/26050 (epoch 22.017), train_loss = 1.01928146, grad/param norm = 1.7547e-01, time/batch = 17.6461s	
11472/26050 (epoch 22.019), train_loss = 0.88376512, grad/param norm = 1.6575e-01, time/batch = 17.9005s	
11473/26050 (epoch 22.021), train_loss = 1.07762958, grad/param norm = 1.7945e-01, time/batch = 18.6416s	
11474/26050 (epoch 22.023), train_loss = 0.84481682, grad/param norm = 1.7900e-01, time/batch = 17.2294s	
11475/26050 (epoch 22.025), train_loss = 1.02013953, grad/param norm = 1.7451e-01, time/batch = 16.5119s	
11476/26050 (epoch 22.027), train_loss = 0.82622741, grad/param norm = 1.7969e-01, time/batch = 18.7496s	
11477/26050 (epoch 22.029), train_loss = 1.03936158, grad/param norm = 1.7497e-01, time/batch = 18.6540s	
11478/26050 (epoch 22.031), train_loss = 1.14333417, grad/param norm = 2.1044e-01, time/batch = 15.9015s	
11479/26050 (epoch 22.033), train_loss = 1.04231821, grad/param norm = 1.8515e-01, time/batch = 17.6363s	
11480/26050 (epoch 22.035), train_loss = 1.04219636, grad/param norm = 1.6770e-01, time/batch = 16.5523s	
11481/26050 (epoch 22.036), train_loss = 0.90381361, grad/param norm = 1.8109e-01, time/batch = 16.9048s	
11482/26050 (epoch 22.038), train_loss = 0.83972905, grad/param norm = 1.6103e-01, time/batch = 18.4719s	
11483/26050 (epoch 22.040), train_loss = 0.99744547, grad/param norm = 1.8192e-01, time/batch = 18.1420s	
11484/26050 (epoch 22.042), train_loss = 0.86714728, grad/param norm = 2.0138e-01, time/batch = 18.3113s	
11485/26050 (epoch 22.044), train_loss = 1.08229420, grad/param norm = 1.6634e-01, time/batch = 15.1374s	
11486/26050 (epoch 22.046), train_loss = 0.82780136, grad/param norm = 1.6989e-01, time/batch = 14.7247s	
11487/26050 (epoch 22.048), train_loss = 1.01707019, grad/param norm = 1.7406e-01, time/batch = 18.6543s	
11488/26050 (epoch 22.050), train_loss = 0.95222773, grad/param norm = 1.7578e-01, time/batch = 17.4815s	
11489/26050 (epoch 22.052), train_loss = 0.93871861, grad/param norm = 1.8046e-01, time/batch = 18.2264s	
11490/26050 (epoch 22.054), train_loss = 0.85386970, grad/param norm = 1.6505e-01, time/batch = 18.6479s	
11491/26050 (epoch 22.056), train_loss = 0.82277565, grad/param norm = 1.5729e-01, time/batch = 17.3170s	
11492/26050 (epoch 22.058), train_loss = 0.96336505, grad/param norm = 1.6199e-01, time/batch = 16.0479s	
11493/26050 (epoch 22.060), train_loss = 1.07934620, grad/param norm = 1.8582e-01, time/batch = 18.3207s	
11494/26050 (epoch 22.061), train_loss = 0.92386638, grad/param norm = 1.7405e-01, time/batch = 16.4795s	
11495/26050 (epoch 22.063), train_loss = 1.04333517, grad/param norm = 1.7836e-01, time/batch = 16.3906s	
11496/26050 (epoch 22.065), train_loss = 0.82034545, grad/param norm = 1.4984e-01, time/batch = 17.8883s	
11497/26050 (epoch 22.067), train_loss = 1.00172435, grad/param norm = 1.8077e-01, time/batch = 19.0581s	
11498/26050 (epoch 22.069), train_loss = 1.05760192, grad/param norm = 1.8915e-01, time/batch = 17.4077s	
11499/26050 (epoch 22.071), train_loss = 1.08085189, grad/param norm = 1.9102e-01, time/batch = 18.5548s	
11500/26050 (epoch 22.073), train_loss = 1.18896902, grad/param norm = 2.0131e-01, time/batch = 16.6304s	
11501/26050 (epoch 22.075), train_loss = 0.94106551, grad/param norm = 1.7435e-01, time/batch = 18.8920s	
11502/26050 (epoch 22.077), train_loss = 0.94635316, grad/param norm = 1.9259e-01, time/batch = 17.8072s	
11503/26050 (epoch 22.079), train_loss = 1.02941706, grad/param norm = 1.8191e-01, time/batch = 17.6691s	
11504/26050 (epoch 22.081), train_loss = 0.96205138, grad/param norm = 1.6877e-01, time/batch = 17.0684s	
11505/26050 (epoch 22.083), train_loss = 1.11904864, grad/param norm = 1.8892e-01, time/batch = 17.1335s	
11506/26050 (epoch 22.084), train_loss = 1.03252189, grad/param norm = 2.0620e-01, time/batch = 18.8151s	
11507/26050 (epoch 22.086), train_loss = 1.18962386, grad/param norm = 2.2235e-01, time/batch = 17.6506s	
11508/26050 (epoch 22.088), train_loss = 0.95448657, grad/param norm = 1.8987e-01, time/batch = 17.2154s	
11509/26050 (epoch 22.090), train_loss = 1.02934122, grad/param norm = 1.9982e-01, time/batch = 16.8776s	
11510/26050 (epoch 22.092), train_loss = 1.06893391, grad/param norm = 1.7681e-01, time/batch = 14.9759s	
11511/26050 (epoch 22.094), train_loss = 0.94530813, grad/param norm = 1.8808e-01, time/batch = 15.9613s	
11512/26050 (epoch 22.096), train_loss = 1.00337682, grad/param norm = 1.7152e-01, time/batch = 17.5657s	
11513/26050 (epoch 22.098), train_loss = 0.95820817, grad/param norm = 1.9545e-01, time/batch = 17.9123s	
11514/26050 (epoch 22.100), train_loss = 0.90106527, grad/param norm = 1.7630e-01, time/batch = 17.6574s	
11515/26050 (epoch 22.102), train_loss = 1.05911978, grad/param norm = 1.9367e-01, time/batch = 18.0640s	
11516/26050 (epoch 22.104), train_loss = 0.99234025, grad/param norm = 1.8871e-01, time/batch = 18.9793s	
11517/26050 (epoch 22.106), train_loss = 1.01020617, grad/param norm = 2.0167e-01, time/batch = 18.2343s	
11518/26050 (epoch 22.107), train_loss = 0.80932227, grad/param norm = 1.6543e-01, time/batch = 17.6514s	
11519/26050 (epoch 22.109), train_loss = 0.93057571, grad/param norm = 1.9568e-01, time/batch = 17.5695s	
11520/26050 (epoch 22.111), train_loss = 1.17624349, grad/param norm = 2.1552e-01, time/batch = 16.2341s	
11521/26050 (epoch 22.113), train_loss = 0.94964710, grad/param norm = 1.7982e-01, time/batch = 15.8881s	
11522/26050 (epoch 22.115), train_loss = 1.10963597, grad/param norm = 1.8382e-01, time/batch = 17.3983s	
11523/26050 (epoch 22.117), train_loss = 1.02690660, grad/param norm = 1.8140e-01, time/batch = 18.5663s	
11524/26050 (epoch 22.119), train_loss = 0.84514444, grad/param norm = 1.6149e-01, time/batch = 18.4081s	
11525/26050 (epoch 22.121), train_loss = 1.02357664, grad/param norm = 1.7129e-01, time/batch = 18.2364s	
11526/26050 (epoch 22.123), train_loss = 0.91338473, grad/param norm = 1.7852e-01, time/batch = 30.3274s	
11527/26050 (epoch 22.125), train_loss = 0.86697374, grad/param norm = 1.6797e-01, time/batch = 24.6067s	
11528/26050 (epoch 22.127), train_loss = 0.81433077, grad/param norm = 1.8908e-01, time/batch = 16.8134s	
11529/26050 (epoch 22.129), train_loss = 0.85962554, grad/param norm = 1.6997e-01, time/batch = 18.6373s	
11530/26050 (epoch 22.131), train_loss = 0.97949309, grad/param norm = 1.9200e-01, time/batch = 18.0765s	
11531/26050 (epoch 22.132), train_loss = 0.97861682, grad/param norm = 1.6932e-01, time/batch = 15.9649s	
11532/26050 (epoch 22.134), train_loss = 1.02004578, grad/param norm = 2.0605e-01, time/batch = 17.9870s	
11533/26050 (epoch 22.136), train_loss = 1.00437422, grad/param norm = 1.8501e-01, time/batch = 15.4788s	
11534/26050 (epoch 22.138), train_loss = 0.75755904, grad/param norm = 1.6046e-01, time/batch = 18.8900s	
11535/26050 (epoch 22.140), train_loss = 0.83565802, grad/param norm = 1.7655e-01, time/batch = 18.5429s	
11536/26050 (epoch 22.142), train_loss = 0.87071733, grad/param norm = 1.6969e-01, time/batch = 17.8955s	
11537/26050 (epoch 22.144), train_loss = 0.80199013, grad/param norm = 1.7614e-01, time/batch = 18.1612s	
11538/26050 (epoch 22.146), train_loss = 0.75130171, grad/param norm = 1.6249e-01, time/batch = 15.9871s	
11539/26050 (epoch 22.148), train_loss = 0.78555779, grad/param norm = 1.5212e-01, time/batch = 17.3319s	
11540/26050 (epoch 22.150), train_loss = 0.95773697, grad/param norm = 1.8376e-01, time/batch = 18.4002s	
11541/26050 (epoch 22.152), train_loss = 1.18413430, grad/param norm = 2.4635e-01, time/batch = 15.6154s	
11542/26050 (epoch 22.154), train_loss = 0.78583768, grad/param norm = 1.8180e-01, time/batch = 18.4664s	
11543/26050 (epoch 22.155), train_loss = 0.83147559, grad/param norm = 1.7095e-01, time/batch = 18.4067s	
11544/26050 (epoch 22.157), train_loss = 0.94786898, grad/param norm = 2.1431e-01, time/batch = 18.4804s	
11545/26050 (epoch 22.159), train_loss = 0.99769328, grad/param norm = 1.9184e-01, time/batch = 17.0608s	
11546/26050 (epoch 22.161), train_loss = 1.02676739, grad/param norm = 1.9498e-01, time/batch = 18.4723s	
11547/26050 (epoch 22.163), train_loss = 0.81819228, grad/param norm = 1.6926e-01, time/batch = 16.8118s	
11548/26050 (epoch 22.165), train_loss = 0.75868116, grad/param norm = 1.6166e-01, time/batch = 17.8890s	
11549/26050 (epoch 22.167), train_loss = 1.09254217, grad/param norm = 1.8772e-01, time/batch = 18.1550s	
11550/26050 (epoch 22.169), train_loss = 1.00815740, grad/param norm = 1.8770e-01, time/batch = 18.1582s	
11551/26050 (epoch 22.171), train_loss = 0.83130707, grad/param norm = 1.7005e-01, time/batch = 17.8107s	
11552/26050 (epoch 22.173), train_loss = 0.93548128, grad/param norm = 2.0252e-01, time/batch = 16.2936s	
11553/26050 (epoch 22.175), train_loss = 0.95135418, grad/param norm = 1.6395e-01, time/batch = 18.7357s	
11554/26050 (epoch 22.177), train_loss = 1.08917433, grad/param norm = 1.8547e-01, time/batch = 17.8960s	
11555/26050 (epoch 22.179), train_loss = 0.74066343, grad/param norm = 1.5316e-01, time/batch = 17.4777s	
11556/26050 (epoch 22.180), train_loss = 1.18523009, grad/param norm = 1.9271e-01, time/batch = 17.8241s	
11557/26050 (epoch 22.182), train_loss = 1.20360632, grad/param norm = 1.8911e-01, time/batch = 17.1647s	
11558/26050 (epoch 22.184), train_loss = 1.01224426, grad/param norm = 1.7989e-01, time/batch = 16.9556s	
11559/26050 (epoch 22.186), train_loss = 0.82687186, grad/param norm = 1.6581e-01, time/batch = 18.0696s	
11560/26050 (epoch 22.188), train_loss = 0.98027387, grad/param norm = 1.7780e-01, time/batch = 18.4128s	
11561/26050 (epoch 22.190), train_loss = 1.02694430, grad/param norm = 1.7329e-01, time/batch = 16.6417s	
11562/26050 (epoch 22.192), train_loss = 1.04221612, grad/param norm = 1.6268e-01, time/batch = 17.8836s	
11563/26050 (epoch 22.194), train_loss = 1.03358574, grad/param norm = 1.8000e-01, time/batch = 15.1443s	
11564/26050 (epoch 22.196), train_loss = 1.08216172, grad/param norm = 1.8337e-01, time/batch = 16.8097s	
11565/26050 (epoch 22.198), train_loss = 0.90433047, grad/param norm = 1.6527e-01, time/batch = 17.4696s	
11566/26050 (epoch 22.200), train_loss = 0.91033098, grad/param norm = 1.8806e-01, time/batch = 18.1497s	
11567/26050 (epoch 22.202), train_loss = 1.00582036, grad/param norm = 1.8446e-01, time/batch = 17.9893s	
11568/26050 (epoch 22.203), train_loss = 1.10559795, grad/param norm = 1.9797e-01, time/batch = 16.7146s	
11569/26050 (epoch 22.205), train_loss = 0.93365276, grad/param norm = 1.7574e-01, time/batch = 18.1619s	
11570/26050 (epoch 22.207), train_loss = 0.92816163, grad/param norm = 1.8240e-01, time/batch = 18.3077s	
11571/26050 (epoch 22.209), train_loss = 1.03448210, grad/param norm = 1.6773e-01, time/batch = 18.5607s	
11572/26050 (epoch 22.211), train_loss = 0.82461160, grad/param norm = 1.6104e-01, time/batch = 17.4875s	
11573/26050 (epoch 22.213), train_loss = 1.02963690, grad/param norm = 1.8319e-01, time/batch = 17.1713s	
11574/26050 (epoch 22.215), train_loss = 0.97891124, grad/param norm = 2.0026e-01, time/batch = 18.6564s	
11575/26050 (epoch 22.217), train_loss = 0.94143332, grad/param norm = 1.6452e-01, time/batch = 17.2980s	
11576/26050 (epoch 22.219), train_loss = 0.96960199, grad/param norm = 1.9756e-01, time/batch = 18.0499s	
11577/26050 (epoch 22.221), train_loss = 0.89082542, grad/param norm = 1.8809e-01, time/batch = 15.4706s	
11578/26050 (epoch 22.223), train_loss = 1.03090849, grad/param norm = 1.9238e-01, time/batch = 19.2298s	
11579/26050 (epoch 22.225), train_loss = 0.88478316, grad/param norm = 1.8709e-01, time/batch = 17.5484s	
11580/26050 (epoch 22.226), train_loss = 1.03947083, grad/param norm = 2.1747e-01, time/batch = 15.4531s	
11581/26050 (epoch 22.228), train_loss = 1.11868545, grad/param norm = 1.9105e-01, time/batch = 18.3094s	
11582/26050 (epoch 22.230), train_loss = 1.01650117, grad/param norm = 1.7162e-01, time/batch = 17.9821s	
11583/26050 (epoch 22.232), train_loss = 1.08452489, grad/param norm = 2.1416e-01, time/batch = 16.9792s	
11584/26050 (epoch 22.234), train_loss = 0.87399873, grad/param norm = 1.6678e-01, time/batch = 16.1412s	
11585/26050 (epoch 22.236), train_loss = 1.08667002, grad/param norm = 1.9116e-01, time/batch = 18.9009s	
11586/26050 (epoch 22.238), train_loss = 0.87061517, grad/param norm = 1.8766e-01, time/batch = 18.1446s	
11587/26050 (epoch 22.240), train_loss = 0.98412396, grad/param norm = 1.8656e-01, time/batch = 18.8088s	
11588/26050 (epoch 22.242), train_loss = 0.98227784, grad/param norm = 1.7467e-01, time/batch = 17.6312s	
11589/26050 (epoch 22.244), train_loss = 0.99020375, grad/param norm = 2.0393e-01, time/batch = 16.8093s	
11590/26050 (epoch 22.246), train_loss = 0.91215397, grad/param norm = 1.7890e-01, time/batch = 17.8987s	
11591/26050 (epoch 22.248), train_loss = 1.00433016, grad/param norm = 1.9141e-01, time/batch = 18.7345s	
11592/26050 (epoch 22.250), train_loss = 0.99074413, grad/param norm = 2.1311e-01, time/batch = 14.7193s	
11593/26050 (epoch 22.251), train_loss = 0.94565973, grad/param norm = 1.7122e-01, time/batch = 17.7234s	
11594/26050 (epoch 22.253), train_loss = 0.87400065, grad/param norm = 1.7325e-01, time/batch = 18.3882s	
11595/26050 (epoch 22.255), train_loss = 1.15518409, grad/param norm = 1.8864e-01, time/batch = 16.5337s	
11596/26050 (epoch 22.257), train_loss = 0.97394800, grad/param norm = 1.8914e-01, time/batch = 16.5491s	
11597/26050 (epoch 22.259), train_loss = 1.11807001, grad/param norm = 1.9364e-01, time/batch = 15.1495s	
11598/26050 (epoch 22.261), train_loss = 0.88957208, grad/param norm = 1.8919e-01, time/batch = 17.4768s	
11599/26050 (epoch 22.263), train_loss = 1.05113847, grad/param norm = 1.9247e-01, time/batch = 18.0728s	
11600/26050 (epoch 22.265), train_loss = 1.13231494, grad/param norm = 1.8847e-01, time/batch = 17.6631s	
11601/26050 (epoch 22.267), train_loss = 1.09143499, grad/param norm = 1.7081e-01, time/batch = 18.4731s	
11602/26050 (epoch 22.269), train_loss = 1.11544140, grad/param norm = 1.8610e-01, time/batch = 15.8105s	
11603/26050 (epoch 22.271), train_loss = 1.03762819, grad/param norm = 1.7807e-01, time/batch = 17.0625s	
11604/26050 (epoch 22.273), train_loss = 0.94951288, grad/param norm = 1.9698e-01, time/batch = 18.3853s	
11605/26050 (epoch 22.274), train_loss = 0.97032899, grad/param norm = 1.6869e-01, time/batch = 18.9748s	
11606/26050 (epoch 22.276), train_loss = 0.94316507, grad/param norm = 1.9201e-01, time/batch = 17.4901s	
11607/26050 (epoch 22.278), train_loss = 1.12104940, grad/param norm = 1.8661e-01, time/batch = 18.4003s	
11608/26050 (epoch 22.280), train_loss = 0.98454593, grad/param norm = 1.7667e-01, time/batch = 17.9082s	
11609/26050 (epoch 22.282), train_loss = 1.03166045, grad/param norm = 1.9019e-01, time/batch = 17.7300s	
11610/26050 (epoch 22.284), train_loss = 0.96466030, grad/param norm = 1.9538e-01, time/batch = 15.9702s	
11611/26050 (epoch 22.286), train_loss = 1.01262921, grad/param norm = 2.0437e-01, time/batch = 17.0398s	
11612/26050 (epoch 22.288), train_loss = 0.84807058, grad/param norm = 1.5084e-01, time/batch = 18.4650s	
11613/26050 (epoch 22.290), train_loss = 1.00116411, grad/param norm = 1.9215e-01, time/batch = 15.9789s	
11614/26050 (epoch 22.292), train_loss = 0.91077071, grad/param norm = 1.6413e-01, time/batch = 17.5530s	
11615/26050 (epoch 22.294), train_loss = 1.00090385, grad/param norm = 1.9758e-01, time/batch = 18.4046s	
11616/26050 (epoch 22.296), train_loss = 1.10145555, grad/param norm = 1.9139e-01, time/batch = 17.4700s	
11617/26050 (epoch 22.298), train_loss = 1.01673515, grad/param norm = 1.8828e-01, time/batch = 18.2487s	
11618/26050 (epoch 22.299), train_loss = 0.82423189, grad/param norm = 1.6297e-01, time/batch = 18.3102s	
11619/26050 (epoch 22.301), train_loss = 0.87164453, grad/param norm = 1.7466e-01, time/batch = 18.2111s	
11620/26050 (epoch 22.303), train_loss = 0.99725535, grad/param norm = 1.9384e-01, time/batch = 17.7384s	
11621/26050 (epoch 22.305), train_loss = 0.81581962, grad/param norm = 1.6778e-01, time/batch = 16.3320s	
11622/26050 (epoch 22.307), train_loss = 0.92159950, grad/param norm = 1.8710e-01, time/batch = 17.8951s	
11623/26050 (epoch 22.309), train_loss = 0.97683001, grad/param norm = 1.9370e-01, time/batch = 15.8234s	
11624/26050 (epoch 22.311), train_loss = 1.09039115, grad/param norm = 2.5364e-01, time/batch = 17.5424s	
11625/26050 (epoch 22.313), train_loss = 1.00081454, grad/param norm = 2.1891e-01, time/batch = 18.5717s	
11626/26050 (epoch 22.315), train_loss = 1.08782681, grad/param norm = 1.9516e-01, time/batch = 17.8991s	
11627/26050 (epoch 22.317), train_loss = 1.00836254, grad/param norm = 1.8587e-01, time/batch = 17.2339s	
11628/26050 (epoch 22.319), train_loss = 0.90676714, grad/param norm = 1.7239e-01, time/batch = 18.9015s	
11629/26050 (epoch 22.321), train_loss = 0.95708833, grad/param norm = 1.7119e-01, time/batch = 18.5695s	
11630/26050 (epoch 22.322), train_loss = 1.01310748, grad/param norm = 1.6415e-01, time/batch = 17.2411s	
11631/26050 (epoch 22.324), train_loss = 0.81840596, grad/param norm = 1.6790e-01, time/batch = 18.2311s	
11632/26050 (epoch 22.326), train_loss = 1.12715267, grad/param norm = 1.8981e-01, time/batch = 14.9927s	
11633/26050 (epoch 22.328), train_loss = 1.02332064, grad/param norm = 1.7506e-01, time/batch = 18.0676s	
11634/26050 (epoch 22.330), train_loss = 0.87477615, grad/param norm = 1.8059e-01, time/batch = 18.4729s	
11635/26050 (epoch 22.332), train_loss = 1.04846858, grad/param norm = 1.9226e-01, time/batch = 17.4210s	
11636/26050 (epoch 22.334), train_loss = 0.93901209, grad/param norm = 2.0149e-01, time/batch = 18.3162s	
11637/26050 (epoch 22.336), train_loss = 0.95496106, grad/param norm = 1.8178e-01, time/batch = 18.1407s	
11638/26050 (epoch 22.338), train_loss = 0.87241304, grad/param norm = 1.6319e-01, time/batch = 17.5570s	
11639/26050 (epoch 22.340), train_loss = 1.07021888, grad/param norm = 2.0069e-01, time/batch = 17.8947s	
11640/26050 (epoch 22.342), train_loss = 1.09765737, grad/param norm = 1.9535e-01, time/batch = 17.4772s	
11641/26050 (epoch 22.344), train_loss = 0.93096422, grad/param norm = 2.0097e-01, time/batch = 15.1472s	
11642/26050 (epoch 22.345), train_loss = 0.98679805, grad/param norm = 2.2161e-01, time/batch = 19.1543s	
11643/26050 (epoch 22.347), train_loss = 1.12060117, grad/param norm = 2.0013e-01, time/batch = 15.0770s	
11644/26050 (epoch 22.349), train_loss = 1.04272040, grad/param norm = 1.8818e-01, time/batch = 17.9715s	
11645/26050 (epoch 22.351), train_loss = 1.04857057, grad/param norm = 1.9697e-01, time/batch = 18.0609s	
11646/26050 (epoch 22.353), train_loss = 0.99853131, grad/param norm = 1.8966e-01, time/batch = 17.9912s	
11647/26050 (epoch 22.355), train_loss = 1.04701404, grad/param norm = 2.0763e-01, time/batch = 16.4038s	
11648/26050 (epoch 22.357), train_loss = 0.93255952, grad/param norm = 1.7475e-01, time/batch = 17.1657s	
11649/26050 (epoch 22.359), train_loss = 1.10146444, grad/param norm = 1.9086e-01, time/batch = 15.3156s	
11650/26050 (epoch 22.361), train_loss = 0.91569600, grad/param norm = 1.6443e-01, time/batch = 17.9771s	
11651/26050 (epoch 22.363), train_loss = 1.06018871, grad/param norm = 1.7653e-01, time/batch = 17.8938s	
11652/26050 (epoch 22.365), train_loss = 0.95248253, grad/param norm = 1.6292e-01, time/batch = 18.2417s	
11653/26050 (epoch 22.367), train_loss = 1.04952982, grad/param norm = 1.7921e-01, time/batch = 17.4945s	
11654/26050 (epoch 22.369), train_loss = 0.93824711, grad/param norm = 1.6925e-01, time/batch = 14.2698s	
11655/26050 (epoch 22.370), train_loss = 0.88331931, grad/param norm = 1.6301e-01, time/batch = 18.4085s	
11656/26050 (epoch 22.372), train_loss = 1.03847234, grad/param norm = 1.9738e-01, time/batch = 18.1552s	
11657/26050 (epoch 22.374), train_loss = 1.12818103, grad/param norm = 1.9385e-01, time/batch = 18.0694s	
11658/26050 (epoch 22.376), train_loss = 1.20913061, grad/param norm = 2.0344e-01, time/batch = 17.9037s	
11659/26050 (epoch 22.378), train_loss = 0.94233578, grad/param norm = 1.6652e-01, time/batch = 18.0738s	
11660/26050 (epoch 22.380), train_loss = 1.18887807, grad/param norm = 2.2463e-01, time/batch = 18.3136s	
11661/26050 (epoch 22.382), train_loss = 1.27908408, grad/param norm = 2.2802e-01, time/batch = 18.2107s	
11662/26050 (epoch 22.384), train_loss = 1.00490249, grad/param norm = 2.0061e-01, time/batch = 18.6428s	
11663/26050 (epoch 22.386), train_loss = 1.06146356, grad/param norm = 2.1784e-01, time/batch = 18.8044s	
11664/26050 (epoch 22.388), train_loss = 1.01789045, grad/param norm = 1.8274e-01, time/batch = 16.7536s	
11665/26050 (epoch 22.390), train_loss = 0.93754377, grad/param norm = 1.7600e-01, time/batch = 18.3190s	
11666/26050 (epoch 22.392), train_loss = 0.88028311, grad/param norm = 1.6028e-01, time/batch = 16.9072s	
11667/26050 (epoch 22.393), train_loss = 1.05272699, grad/param norm = 1.9844e-01, time/batch = 16.2059s	
11668/26050 (epoch 22.395), train_loss = 1.05118814, grad/param norm = 1.8190e-01, time/batch = 17.0465s	
11669/26050 (epoch 22.397), train_loss = 1.06906088, grad/param norm = 2.1444e-01, time/batch = 17.7394s	
11670/26050 (epoch 22.399), train_loss = 0.93449829, grad/param norm = 1.9662e-01, time/batch = 16.5690s	
11671/26050 (epoch 22.401), train_loss = 1.01224145, grad/param norm = 1.8785e-01, time/batch = 17.8174s	
11672/26050 (epoch 22.403), train_loss = 1.01334352, grad/param norm = 1.9487e-01, time/batch = 16.2412s	
11673/26050 (epoch 22.405), train_loss = 1.01334578, grad/param norm = 1.7784e-01, time/batch = 18.0533s	
11674/26050 (epoch 22.407), train_loss = 1.15789909, grad/param norm = 1.9628e-01, time/batch = 17.1354s	
11675/26050 (epoch 22.409), train_loss = 1.15017640, grad/param norm = 2.0539e-01, time/batch = 18.4906s	
11676/26050 (epoch 22.411), train_loss = 1.06740758, grad/param norm = 1.9410e-01, time/batch = 18.5011s	
11677/26050 (epoch 22.413), train_loss = 1.15795626, grad/param norm = 1.7933e-01, time/batch = 17.5737s	
11678/26050 (epoch 22.415), train_loss = 1.12136937, grad/param norm = 2.4904e-01, time/batch = 18.2117s	
11679/26050 (epoch 22.417), train_loss = 1.23708319, grad/param norm = 2.1791e-01, time/batch = 17.9177s	
11680/26050 (epoch 22.418), train_loss = 1.12415627, grad/param norm = 2.2103e-01, time/batch = 17.1442s	
11681/26050 (epoch 22.420), train_loss = 0.86684563, grad/param norm = 1.7048e-01, time/batch = 14.5333s	
11682/26050 (epoch 22.422), train_loss = 0.86363115, grad/param norm = 1.8272e-01, time/batch = 15.4155s	
11683/26050 (epoch 22.424), train_loss = 1.15458880, grad/param norm = 2.0690e-01, time/batch = 18.6417s	
11684/26050 (epoch 22.426), train_loss = 1.12368317, grad/param norm = 1.9328e-01, time/batch = 18.3062s	
11685/26050 (epoch 22.428), train_loss = 0.94576843, grad/param norm = 1.6150e-01, time/batch = 17.4657s	
11686/26050 (epoch 22.430), train_loss = 1.12905520, grad/param norm = 1.8685e-01, time/batch = 16.7153s	
11687/26050 (epoch 22.432), train_loss = 0.99076500, grad/param norm = 1.9305e-01, time/batch = 18.8143s	
11688/26050 (epoch 22.434), train_loss = 0.99553532, grad/param norm = 2.0331e-01, time/batch = 17.5561s	
11689/26050 (epoch 22.436), train_loss = 1.13691203, grad/param norm = 2.0167e-01, time/batch = 18.0840s	
11690/26050 (epoch 22.438), train_loss = 1.07120200, grad/param norm = 1.8639e-01, time/batch = 16.5419s	
11691/26050 (epoch 22.440), train_loss = 1.03705291, grad/param norm = 2.1663e-01, time/batch = 17.7284s	
11692/26050 (epoch 22.441), train_loss = 1.01254476, grad/param norm = 1.9065e-01, time/batch = 17.4922s	
11693/26050 (epoch 22.443), train_loss = 0.86598471, grad/param norm = 1.5467e-01, time/batch = 18.7265s	
11694/26050 (epoch 22.445), train_loss = 0.93710319, grad/param norm = 1.7349e-01, time/batch = 17.4126s	
11695/26050 (epoch 22.447), train_loss = 1.14807771, grad/param norm = 2.1912e-01, time/batch = 16.5516s	
11696/26050 (epoch 22.449), train_loss = 0.93053237, grad/param norm = 1.7439e-01, time/batch = 16.8555s	
11697/26050 (epoch 22.451), train_loss = 1.16355783, grad/param norm = 2.0078e-01, time/batch = 18.0612s	
11698/26050 (epoch 22.453), train_loss = 0.94115799, grad/param norm = 1.6204e-01, time/batch = 18.0668s	
11699/26050 (epoch 22.455), train_loss = 1.02823442, grad/param norm = 1.8612e-01, time/batch = 17.7402s	
11700/26050 (epoch 22.457), train_loss = 0.99061470, grad/param norm = 1.7286e-01, time/batch = 18.1595s	
11701/26050 (epoch 22.459), train_loss = 1.10940074, grad/param norm = 1.8467e-01, time/batch = 18.1522s	
11702/26050 (epoch 22.461), train_loss = 1.11307510, grad/param norm = 2.3235e-01, time/batch = 15.1478s	
11703/26050 (epoch 22.463), train_loss = 0.98512787, grad/param norm = 1.7760e-01, time/batch = 17.8082s	
11704/26050 (epoch 22.464), train_loss = 1.05069419, grad/param norm = 1.7599e-01, time/batch = 18.4929s	
11705/26050 (epoch 22.466), train_loss = 1.06918380, grad/param norm = 1.9880e-01, time/batch = 17.2300s	
11706/26050 (epoch 22.468), train_loss = 1.11744409, grad/param norm = 1.6879e-01, time/batch = 16.5577s	
11707/26050 (epoch 22.470), train_loss = 1.15307865, grad/param norm = 2.2120e-01, time/batch = 17.4180s	
11708/26050 (epoch 22.472), train_loss = 1.14589369, grad/param norm = 2.1175e-01, time/batch = 17.9931s	
11709/26050 (epoch 22.474), train_loss = 1.13931710, grad/param norm = 1.7215e-01, time/batch = 17.9117s	
11710/26050 (epoch 22.476), train_loss = 1.14292583, grad/param norm = 1.9063e-01, time/batch = 17.7518s	
11711/26050 (epoch 22.478), train_loss = 1.00907125, grad/param norm = 1.8389e-01, time/batch = 18.1536s	
11712/26050 (epoch 22.480), train_loss = 1.01658995, grad/param norm = 1.7732e-01, time/batch = 17.1501s	
11713/26050 (epoch 22.482), train_loss = 0.97112514, grad/param norm = 1.7627e-01, time/batch = 18.0934s	
11714/26050 (epoch 22.484), train_loss = 0.95691819, grad/param norm = 1.7796e-01, time/batch = 17.1451s	
11715/26050 (epoch 22.486), train_loss = 1.13542727, grad/param norm = 1.8039e-01, time/batch = 16.0470s	
11716/26050 (epoch 22.488), train_loss = 1.25476705, grad/param norm = 2.1444e-01, time/batch = 18.2334s	
11717/26050 (epoch 22.489), train_loss = 1.17389553, grad/param norm = 2.1139e-01, time/batch = 17.8950s	
11718/26050 (epoch 22.491), train_loss = 0.95059893, grad/param norm = 1.8747e-01, time/batch = 18.3054s	
11719/26050 (epoch 22.493), train_loss = 1.03099704, grad/param norm = 1.9592e-01, time/batch = 16.2270s	
11720/26050 (epoch 22.495), train_loss = 1.01233947, grad/param norm = 1.7641e-01, time/batch = 18.2904s	
11721/26050 (epoch 22.497), train_loss = 0.94075393, grad/param norm = 1.8411e-01, time/batch = 14.9693s	
11722/26050 (epoch 22.499), train_loss = 0.99063515, grad/param norm = 1.7943e-01, time/batch = 17.7330s	
11723/26050 (epoch 22.501), train_loss = 1.09092531, grad/param norm = 1.8810e-01, time/batch = 17.8185s	
11724/26050 (epoch 22.503), train_loss = 0.97445725, grad/param norm = 1.7882e-01, time/batch = 18.4869s	
11725/26050 (epoch 22.505), train_loss = 1.14171268, grad/param norm = 1.8688e-01, time/batch = 17.2329s	
11726/26050 (epoch 22.507), train_loss = 1.09364919, grad/param norm = 2.0998e-01, time/batch = 18.3218s	
11727/26050 (epoch 22.509), train_loss = 1.19712416, grad/param norm = 1.8634e-01, time/batch = 17.3816s	
11728/26050 (epoch 22.511), train_loss = 0.96870636, grad/param norm = 1.7348e-01, time/batch = 17.4874s	
11729/26050 (epoch 22.512), train_loss = 0.93818559, grad/param norm = 1.9416e-01, time/batch = 25.4374s	
11730/26050 (epoch 22.514), train_loss = 1.09123497, grad/param norm = 1.9946e-01, time/batch = 31.1464s	
11731/26050 (epoch 22.516), train_loss = 1.15637391, grad/param norm = 2.0101e-01, time/batch = 17.6080s	
11732/26050 (epoch 22.518), train_loss = 1.02975094, grad/param norm = 2.0193e-01, time/batch = 18.3076s	
11733/26050 (epoch 22.520), train_loss = 1.00348790, grad/param norm = 1.7443e-01, time/batch = 17.5415s	
11734/26050 (epoch 22.522), train_loss = 0.80099225, grad/param norm = 1.6505e-01, time/batch = 17.5638s	
11735/26050 (epoch 22.524), train_loss = 1.09851810, grad/param norm = 2.3914e-01, time/batch = 18.7952s	
11736/26050 (epoch 22.526), train_loss = 1.13340660, grad/param norm = 2.0350e-01, time/batch = 17.7443s	
11737/26050 (epoch 22.528), train_loss = 1.07604517, grad/param norm = 2.1011e-01, time/batch = 14.7973s	
11738/26050 (epoch 22.530), train_loss = 0.97475767, grad/param norm = 1.8244e-01, time/batch = 17.5622s	
11739/26050 (epoch 22.532), train_loss = 1.04030264, grad/param norm = 1.8492e-01, time/batch = 17.7198s	
11740/26050 (epoch 22.534), train_loss = 1.08517124, grad/param norm = 2.1415e-01, time/batch = 18.0606s	
11741/26050 (epoch 22.536), train_loss = 1.01960809, grad/param norm = 1.7585e-01, time/batch = 17.2326s	
11742/26050 (epoch 22.537), train_loss = 1.10153902, grad/param norm = 2.2862e-01, time/batch = 18.5529s	
11743/26050 (epoch 22.539), train_loss = 1.02073666, grad/param norm = 1.8994e-01, time/batch = 18.6480s	
11744/26050 (epoch 22.541), train_loss = 1.21917267, grad/param norm = 2.1486e-01, time/batch = 16.8998s	
11745/26050 (epoch 22.543), train_loss = 0.88372259, grad/param norm = 1.7903e-01, time/batch = 17.4841s	
11746/26050 (epoch 22.545), train_loss = 1.06300202, grad/param norm = 1.9052e-01, time/batch = 18.2307s	
11747/26050 (epoch 22.547), train_loss = 1.01751255, grad/param norm = 1.8296e-01, time/batch = 16.6312s	
11748/26050 (epoch 22.549), train_loss = 0.85696039, grad/param norm = 1.8249e-01, time/batch = 17.5464s	
11749/26050 (epoch 22.551), train_loss = 1.07978190, grad/param norm = 1.7822e-01, time/batch = 16.3908s	
11750/26050 (epoch 22.553), train_loss = 0.95244238, grad/param norm = 1.7857e-01, time/batch = 17.9696s	
11751/26050 (epoch 22.555), train_loss = 0.95600559, grad/param norm = 1.7772e-01, time/batch = 17.7408s	
11752/26050 (epoch 22.557), train_loss = 1.04758681, grad/param norm = 1.6583e-01, time/batch = 18.5609s	
11753/26050 (epoch 22.559), train_loss = 0.99776481, grad/param norm = 1.8303e-01, time/batch = 17.9066s	
11754/26050 (epoch 22.560), train_loss = 0.98753481, grad/param norm = 1.7942e-01, time/batch = 18.4713s	
11755/26050 (epoch 22.562), train_loss = 1.00167948, grad/param norm = 1.7796e-01, time/batch = 17.4733s	
11756/26050 (epoch 22.564), train_loss = 1.18079318, grad/param norm = 1.7934e-01, time/batch = 18.4940s	
11757/26050 (epoch 22.566), train_loss = 0.92227959, grad/param norm = 1.7417e-01, time/batch = 18.0846s	
11758/26050 (epoch 22.568), train_loss = 1.05793590, grad/param norm = 1.7756e-01, time/batch = 15.2162s	
11759/26050 (epoch 22.570), train_loss = 1.08805874, grad/param norm = 2.0457e-01, time/batch = 18.4778s	
11760/26050 (epoch 22.572), train_loss = 0.98888470, grad/param norm = 1.9304e-01, time/batch = 18.5537s	
11761/26050 (epoch 22.574), train_loss = 1.05769674, grad/param norm = 2.1038e-01, time/batch = 17.3152s	
11762/26050 (epoch 22.576), train_loss = 1.05199776, grad/param norm = 1.9739e-01, time/batch = 14.8034s	
11763/26050 (epoch 22.578), train_loss = 0.97651929, grad/param norm = 1.8464e-01, time/batch = 18.5698s	
11764/26050 (epoch 22.580), train_loss = 0.94585315, grad/param norm = 1.8536e-01, time/batch = 18.7494s	
11765/26050 (epoch 22.582), train_loss = 1.04417033, grad/param norm = 1.8705e-01, time/batch = 15.9609s	
11766/26050 (epoch 22.583), train_loss = 1.12476135, grad/param norm = 1.8527e-01, time/batch = 17.9749s	
11767/26050 (epoch 22.585), train_loss = 0.89359818, grad/param norm = 1.9653e-01, time/batch = 17.8304s	
11768/26050 (epoch 22.587), train_loss = 1.08373858, grad/param norm = 2.0675e-01, time/batch = 18.2394s	
11769/26050 (epoch 22.589), train_loss = 1.16947547, grad/param norm = 2.0408e-01, time/batch = 18.4049s	
11770/26050 (epoch 22.591), train_loss = 0.99633802, grad/param norm = 1.7978e-01, time/batch = 17.3283s	
11771/26050 (epoch 22.593), train_loss = 0.88950842, grad/param norm = 1.7916e-01, time/batch = 18.4022s	
11772/26050 (epoch 22.595), train_loss = 1.07508989, grad/param norm = 2.0257e-01, time/batch = 17.2956s	
11773/26050 (epoch 22.597), train_loss = 1.05721783, grad/param norm = 1.9169e-01, time/batch = 17.7106s	
11774/26050 (epoch 22.599), train_loss = 1.04488274, grad/param norm = 1.9050e-01, time/batch = 17.8084s	
11775/26050 (epoch 22.601), train_loss = 1.20428616, grad/param norm = 1.9569e-01, time/batch = 17.1358s	
11776/26050 (epoch 22.603), train_loss = 1.04601749, grad/param norm = 1.9239e-01, time/batch = 18.6472s	
11777/26050 (epoch 22.605), train_loss = 0.96411670, grad/param norm = 1.7421e-01, time/batch = 18.6637s	
11778/26050 (epoch 22.607), train_loss = 1.13473482, grad/param norm = 2.0204e-01, time/batch = 15.6999s	
11779/26050 (epoch 22.608), train_loss = 0.89325102, grad/param norm = 1.6873e-01, time/batch = 14.9070s	
11780/26050 (epoch 22.610), train_loss = 1.00795217, grad/param norm = 1.8633e-01, time/batch = 18.4738s	
11781/26050 (epoch 22.612), train_loss = 1.00224564, grad/param norm = 1.8449e-01, time/batch = 18.0042s	
11782/26050 (epoch 22.614), train_loss = 1.03380361, grad/param norm = 1.7694e-01, time/batch = 17.2301s	
11783/26050 (epoch 22.616), train_loss = 1.15962394, grad/param norm = 2.1480e-01, time/batch = 17.9902s	
11784/26050 (epoch 22.618), train_loss = 0.96810788, grad/param norm = 1.8654e-01, time/batch = 18.2496s	
11785/26050 (epoch 22.620), train_loss = 1.07286157, grad/param norm = 1.9978e-01, time/batch = 17.0491s	
11786/26050 (epoch 22.622), train_loss = 0.90593622, grad/param norm = 1.8773e-01, time/batch = 18.4005s	
11787/26050 (epoch 22.624), train_loss = 0.87842051, grad/param norm = 1.7589e-01, time/batch = 15.3854s	
11788/26050 (epoch 22.626), train_loss = 1.08716390, grad/param norm = 1.8975e-01, time/batch = 18.8742s	
11789/26050 (epoch 22.628), train_loss = 0.95430418, grad/param norm = 1.8324e-01, time/batch = 14.5487s	
11790/26050 (epoch 22.630), train_loss = 1.15185974, grad/param norm = 1.9307e-01, time/batch = 17.7060s	
11791/26050 (epoch 22.631), train_loss = 1.18431253, grad/param norm = 2.0572e-01, time/batch = 18.8025s	
11792/26050 (epoch 22.633), train_loss = 0.90978254, grad/param norm = 1.6787e-01, time/batch = 17.0717s	
11793/26050 (epoch 22.635), train_loss = 0.93561794, grad/param norm = 1.5748e-01, time/batch = 18.0721s	
11794/26050 (epoch 22.637), train_loss = 0.91567858, grad/param norm = 1.8440e-01, time/batch = 17.3196s	
11795/26050 (epoch 22.639), train_loss = 1.11452436, grad/param norm = 1.8171e-01, time/batch = 16.3768s	
11796/26050 (epoch 22.641), train_loss = 0.98069762, grad/param norm = 1.7674e-01, time/batch = 17.0526s	
11797/26050 (epoch 22.643), train_loss = 0.92278585, grad/param norm = 1.5997e-01, time/batch = 17.9852s	
11798/26050 (epoch 22.645), train_loss = 1.00029508, grad/param norm = 1.8273e-01, time/batch = 18.2253s	
11799/26050 (epoch 22.647), train_loss = 0.96516390, grad/param norm = 1.9749e-01, time/batch = 17.4005s	
11800/26050 (epoch 22.649), train_loss = 1.02310275, grad/param norm = 1.9175e-01, time/batch = 18.6476s	
11801/26050 (epoch 22.651), train_loss = 0.96548469, grad/param norm = 1.8494e-01, time/batch = 17.8982s	
11802/26050 (epoch 22.653), train_loss = 1.01020204, grad/param norm = 1.7811e-01, time/batch = 16.7990s	
11803/26050 (epoch 22.655), train_loss = 0.93682704, grad/param norm = 1.7503e-01, time/batch = 18.3142s	
11804/26050 (epoch 22.656), train_loss = 0.87114046, grad/param norm = 1.6898e-01, time/batch = 18.1451s	
11805/26050 (epoch 22.658), train_loss = 1.20352433, grad/param norm = 2.0085e-01, time/batch = 18.5771s	
11806/26050 (epoch 22.660), train_loss = 0.88943315, grad/param norm = 1.8068e-01, time/batch = 15.5550s	
11807/26050 (epoch 22.662), train_loss = 0.97883330, grad/param norm = 1.8909e-01, time/batch = 18.0496s	
11808/26050 (epoch 22.664), train_loss = 0.98995161, grad/param norm = 1.7937e-01, time/batch = 18.5708s	
11809/26050 (epoch 22.666), train_loss = 0.97078319, grad/param norm = 1.9033e-01, time/batch = 17.8187s	
11810/26050 (epoch 22.668), train_loss = 0.83832222, grad/param norm = 2.4938e-01, time/batch = 19.2986s	
11811/26050 (epoch 22.670), train_loss = 1.14158456, grad/param norm = 2.3777e-01, time/batch = 17.6418s	
11812/26050 (epoch 22.672), train_loss = 1.01438286, grad/param norm = 1.9264e-01, time/batch = 16.3142s	
11813/26050 (epoch 22.674), train_loss = 0.93486632, grad/param norm = 1.9755e-01, time/batch = 6.1760s	
11814/26050 (epoch 22.676), train_loss = 1.07294479, grad/param norm = 1.9229e-01, time/batch = 0.6646s	
11815/26050 (epoch 22.678), train_loss = 1.14796340, grad/param norm = 2.0491e-01, time/batch = 0.6528s	
11816/26050 (epoch 22.679), train_loss = 1.19742900, grad/param norm = 2.2272e-01, time/batch = 0.6539s	
11817/26050 (epoch 22.681), train_loss = 1.02096488, grad/param norm = 1.8624e-01, time/batch = 0.6577s	
11818/26050 (epoch 22.683), train_loss = 0.92548411, grad/param norm = 2.1422e-01, time/batch = 0.6537s	
11819/26050 (epoch 22.685), train_loss = 0.98262297, grad/param norm = 1.9825e-01, time/batch = 0.6546s	
11820/26050 (epoch 22.687), train_loss = 0.87390477, grad/param norm = 1.8097e-01, time/batch = 0.6501s	
11821/26050 (epoch 22.689), train_loss = 0.98765152, grad/param norm = 1.9546e-01, time/batch = 0.9348s	
11822/26050 (epoch 22.691), train_loss = 0.81474117, grad/param norm = 1.6366e-01, time/batch = 0.9487s	
11823/26050 (epoch 22.693), train_loss = 0.91775300, grad/param norm = 1.7962e-01, time/batch = 0.9332s	
11824/26050 (epoch 22.695), train_loss = 1.00926359, grad/param norm = 1.7484e-01, time/batch = 0.9317s	
11825/26050 (epoch 22.697), train_loss = 0.92133290, grad/param norm = 1.7334e-01, time/batch = 0.9535s	
11826/26050 (epoch 22.699), train_loss = 1.06781293, grad/param norm = 2.0984e-01, time/batch = 1.6250s	
11827/26050 (epoch 22.701), train_loss = 0.91850616, grad/param norm = 1.6613e-01, time/batch = 1.7608s	
11828/26050 (epoch 22.702), train_loss = 1.11967070, grad/param norm = 1.9196e-01, time/batch = 1.7664s	
11829/26050 (epoch 22.704), train_loss = 1.10339234, grad/param norm = 1.8178e-01, time/batch = 17.4762s	
11830/26050 (epoch 22.706), train_loss = 0.96957969, grad/param norm = 1.8962e-01, time/batch = 16.8881s	
11831/26050 (epoch 22.708), train_loss = 1.08451063, grad/param norm = 2.0105e-01, time/batch = 17.5581s	
11832/26050 (epoch 22.710), train_loss = 1.06815077, grad/param norm = 2.0367e-01, time/batch = 18.3981s	
11833/26050 (epoch 22.712), train_loss = 1.05052952, grad/param norm = 1.9717e-01, time/batch = 18.3137s	
11834/26050 (epoch 22.714), train_loss = 0.86996393, grad/param norm = 1.7645e-01, time/batch = 15.1383s	
11835/26050 (epoch 22.716), train_loss = 1.25278935, grad/param norm = 2.1622e-01, time/batch = 18.5617s	
11836/26050 (epoch 22.718), train_loss = 1.09382599, grad/param norm = 1.9062e-01, time/batch = 17.9148s	
11837/26050 (epoch 22.720), train_loss = 0.99885766, grad/param norm = 1.9335e-01, time/batch = 17.5551s	
11838/26050 (epoch 22.722), train_loss = 0.87505409, grad/param norm = 1.7404e-01, time/batch = 17.7234s	
11839/26050 (epoch 22.724), train_loss = 0.91720321, grad/param norm = 1.7493e-01, time/batch = 15.9743s	
11840/26050 (epoch 22.726), train_loss = 1.07882669, grad/param norm = 1.9836e-01, time/batch = 17.9675s	
11841/26050 (epoch 22.727), train_loss = 1.07388754, grad/param norm = 2.0709e-01, time/batch = 17.2347s	
11842/26050 (epoch 22.729), train_loss = 1.06034441, grad/param norm = 1.7842e-01, time/batch = 18.3116s	
11843/26050 (epoch 22.731), train_loss = 1.03873311, grad/param norm = 1.7696e-01, time/batch = 18.4049s	
11844/26050 (epoch 22.733), train_loss = 0.97760316, grad/param norm = 2.1327e-01, time/batch = 16.8852s	
11845/26050 (epoch 22.735), train_loss = 1.21642795, grad/param norm = 2.2628e-01, time/batch = 18.2213s	
11846/26050 (epoch 22.737), train_loss = 0.94382107, grad/param norm = 1.8376e-01, time/batch = 18.1482s	
11847/26050 (epoch 22.739), train_loss = 1.03808182, grad/param norm = 1.8280e-01, time/batch = 18.4070s	
11848/26050 (epoch 22.741), train_loss = 0.94027476, grad/param norm = 1.8869e-01, time/batch = 18.0650s	
11849/26050 (epoch 22.743), train_loss = 1.04102098, grad/param norm = 2.0898e-01, time/batch = 17.3025s	
11850/26050 (epoch 22.745), train_loss = 0.88994262, grad/param norm = 1.8267e-01, time/batch = 18.0730s	
11851/26050 (epoch 22.747), train_loss = 0.91733263, grad/param norm = 1.7089e-01, time/batch = 14.8095s	
11852/26050 (epoch 22.749), train_loss = 1.12939850, grad/param norm = 1.9792e-01, time/batch = 18.6507s	
11853/26050 (epoch 22.750), train_loss = 1.01946902, grad/param norm = 1.7866e-01, time/batch = 17.9811s	
11854/26050 (epoch 22.752), train_loss = 0.96939078, grad/param norm = 2.1096e-01, time/batch = 17.6336s	
11855/26050 (epoch 22.754), train_loss = 1.01846385, grad/param norm = 1.8958e-01, time/batch = 16.2985s	
11856/26050 (epoch 22.756), train_loss = 0.99673842, grad/param norm = 1.9684e-01, time/batch = 18.2177s	
11857/26050 (epoch 22.758), train_loss = 0.98921779, grad/param norm = 1.8958e-01, time/batch = 17.9774s	
11858/26050 (epoch 22.760), train_loss = 1.19195668, grad/param norm = 2.0694e-01, time/batch = 17.2940s	
11859/26050 (epoch 22.762), train_loss = 0.96489739, grad/param norm = 1.7741e-01, time/batch = 18.9000s	
11860/26050 (epoch 22.764), train_loss = 1.02414125, grad/param norm = 2.1431e-01, time/batch = 18.0636s	
11861/26050 (epoch 22.766), train_loss = 1.07393730, grad/param norm = 2.2243e-01, time/batch = 17.8066s	
11862/26050 (epoch 22.768), train_loss = 0.91492441, grad/param norm = 1.7077e-01, time/batch = 16.1342s	
11863/26050 (epoch 22.770), train_loss = 0.99152649, grad/param norm = 1.9233e-01, time/batch = 17.4718s	
11864/26050 (epoch 22.772), train_loss = 1.00408722, grad/param norm = 1.7466e-01, time/batch = 15.1545s	
11865/26050 (epoch 22.774), train_loss = 0.86995049, grad/param norm = 1.8378e-01, time/batch = 17.3084s	
11866/26050 (epoch 22.775), train_loss = 0.73683586, grad/param norm = 1.6354e-01, time/batch = 17.6419s	
11867/26050 (epoch 22.777), train_loss = 0.95902680, grad/param norm = 1.8927e-01, time/batch = 17.8093s	
11868/26050 (epoch 22.779), train_loss = 0.97086764, grad/param norm = 1.8432e-01, time/batch = 17.4021s	
11869/26050 (epoch 22.781), train_loss = 0.89451674, grad/param norm = 1.7444e-01, time/batch = 18.8264s	
11870/26050 (epoch 22.783), train_loss = 0.88659876, grad/param norm = 1.6968e-01, time/batch = 15.4200s	
11871/26050 (epoch 22.785), train_loss = 1.01268853, grad/param norm = 1.9493e-01, time/batch = 17.9941s	
11872/26050 (epoch 22.787), train_loss = 0.91867959, grad/param norm = 1.7083e-01, time/batch = 17.9821s	
11873/26050 (epoch 22.789), train_loss = 0.94473481, grad/param norm = 1.9198e-01, time/batch = 18.5538s	
11874/26050 (epoch 22.791), train_loss = 0.93809580, grad/param norm = 1.8466e-01, time/batch = 16.9752s	
11875/26050 (epoch 22.793), train_loss = 0.99447805, grad/param norm = 2.0257e-01, time/batch = 17.3227s	
11876/26050 (epoch 22.795), train_loss = 0.81720624, grad/param norm = 1.4894e-01, time/batch = 15.3127s	
11877/26050 (epoch 22.797), train_loss = 0.92396635, grad/param norm = 1.7894e-01, time/batch = 16.8918s	
11878/26050 (epoch 22.798), train_loss = 0.87212028, grad/param norm = 1.8931e-01, time/batch = 15.9777s	
11879/26050 (epoch 22.800), train_loss = 0.87265336, grad/param norm = 1.6609e-01, time/batch = 17.4051s	
11880/26050 (epoch 22.802), train_loss = 0.94729843, grad/param norm = 1.8565e-01, time/batch = 18.7329s	
11881/26050 (epoch 22.804), train_loss = 0.99672862, grad/param norm = 1.9607e-01, time/batch = 18.8159s	
11882/26050 (epoch 22.806), train_loss = 1.08815175, grad/param norm = 1.9200e-01, time/batch = 17.3964s	
11883/26050 (epoch 22.808), train_loss = 0.99295788, grad/param norm = 2.0187e-01, time/batch = 18.2206s	
11884/26050 (epoch 22.810), train_loss = 0.93993881, grad/param norm = 1.7714e-01, time/batch = 15.2220s	
11885/26050 (epoch 22.812), train_loss = 0.87360224, grad/param norm = 1.7913e-01, time/batch = 17.7336s	
11886/26050 (epoch 22.814), train_loss = 0.89642909, grad/param norm = 2.0297e-01, time/batch = 16.9594s	
11887/26050 (epoch 22.816), train_loss = 1.08056664, grad/param norm = 2.0418e-01, time/batch = 18.3086s	
11888/26050 (epoch 22.818), train_loss = 1.10426978, grad/param norm = 2.4156e-01, time/batch = 18.4735s	
11889/26050 (epoch 22.820), train_loss = 1.00386607, grad/param norm = 1.7725e-01, time/batch = 18.4741s	
11890/26050 (epoch 22.821), train_loss = 1.12455346, grad/param norm = 2.1218e-01, time/batch = 18.0568s	
11891/26050 (epoch 22.823), train_loss = 1.15813518, grad/param norm = 2.0263e-01, time/batch = 18.4731s	
11892/26050 (epoch 22.825), train_loss = 0.98393361, grad/param norm = 1.8418e-01, time/batch = 15.4774s	
11893/26050 (epoch 22.827), train_loss = 1.03104121, grad/param norm = 2.0875e-01, time/batch = 17.9607s	
11894/26050 (epoch 22.829), train_loss = 1.09178401, grad/param norm = 2.0238e-01, time/batch = 17.8191s	
11895/26050 (epoch 22.831), train_loss = 1.13994396, grad/param norm = 1.9620e-01, time/batch = 17.2279s	
11896/26050 (epoch 22.833), train_loss = 1.19236063, grad/param norm = 2.0005e-01, time/batch = 17.8067s	
11897/26050 (epoch 22.835), train_loss = 1.18322505, grad/param norm = 2.0381e-01, time/batch = 18.9074s	
11898/26050 (epoch 22.837), train_loss = 1.00985843, grad/param norm = 1.8059e-01, time/batch = 18.4927s	
11899/26050 (epoch 22.839), train_loss = 1.02444657, grad/param norm = 2.2196e-01, time/batch = 16.6495s	
11900/26050 (epoch 22.841), train_loss = 1.14331009, grad/param norm = 1.9529e-01, time/batch = 17.0489s	
11901/26050 (epoch 22.843), train_loss = 0.98229586, grad/param norm = 1.6518e-01, time/batch = 14.6879s	
11902/26050 (epoch 22.845), train_loss = 0.95432157, grad/param norm = 1.6759e-01, time/batch = 18.3057s	
11903/26050 (epoch 22.846), train_loss = 1.08927779, grad/param norm = 1.9601e-01, time/batch = 18.6516s	
11904/26050 (epoch 22.848), train_loss = 0.98246153, grad/param norm = 1.7827e-01, time/batch = 17.8262s	
11905/26050 (epoch 22.850), train_loss = 0.90185058, grad/param norm = 1.6669e-01, time/batch = 17.4879s	
11906/26050 (epoch 22.852), train_loss = 1.00944485, grad/param norm = 1.7776e-01, time/batch = 17.3871s	
11907/26050 (epoch 22.854), train_loss = 1.00047907, grad/param norm = 1.9119e-01, time/batch = 18.8276s	
11908/26050 (epoch 22.856), train_loss = 0.97295315, grad/param norm = 1.9939e-01, time/batch = 18.7408s	
11909/26050 (epoch 22.858), train_loss = 0.93105921, grad/param norm = 1.8419e-01, time/batch = 15.0559s	
11910/26050 (epoch 22.860), train_loss = 1.03756991, grad/param norm = 1.9404e-01, time/batch = 16.4940s	
11911/26050 (epoch 22.862), train_loss = 1.06987374, grad/param norm = 1.9298e-01, time/batch = 18.3996s	
11912/26050 (epoch 22.864), train_loss = 1.04084665, grad/param norm = 2.2650e-01, time/batch = 17.2967s	
11913/26050 (epoch 22.866), train_loss = 0.96359444, grad/param norm = 1.8048e-01, time/batch = 14.6406s	
11914/26050 (epoch 22.868), train_loss = 1.04535927, grad/param norm = 1.9002e-01, time/batch = 17.3991s	
11915/26050 (epoch 22.869), train_loss = 0.90694615, grad/param norm = 1.7503e-01, time/batch = 18.5737s	
11916/26050 (epoch 22.871), train_loss = 0.84171865, grad/param norm = 1.6761e-01, time/batch = 17.2348s	
11917/26050 (epoch 22.873), train_loss = 1.05353121, grad/param norm = 2.1199e-01, time/batch = 17.2205s	
11918/26050 (epoch 22.875), train_loss = 1.00455508, grad/param norm = 1.9187e-01, time/batch = 16.6075s	
11919/26050 (epoch 22.877), train_loss = 0.89819692, grad/param norm = 1.6801e-01, time/batch = 18.0758s	
11920/26050 (epoch 22.879), train_loss = 1.02517611, grad/param norm = 1.6951e-01, time/batch = 17.9133s	
11921/26050 (epoch 22.881), train_loss = 1.12048182, grad/param norm = 2.3355e-01, time/batch = 18.1585s	
11922/26050 (epoch 22.883), train_loss = 1.05664485, grad/param norm = 1.9019e-01, time/batch = 17.5732s	
11923/26050 (epoch 22.885), train_loss = 0.76734365, grad/param norm = 1.6752e-01, time/batch = 17.2860s	
11924/26050 (epoch 22.887), train_loss = 1.05062942, grad/param norm = 1.8472e-01, time/batch = 17.8936s	
11925/26050 (epoch 22.889), train_loss = 0.95750864, grad/param norm = 1.7850e-01, time/batch = 18.6639s	
11926/26050 (epoch 22.891), train_loss = 0.83666304, grad/param norm = 1.6714e-01, time/batch = 17.7438s	
11927/26050 (epoch 22.893), train_loss = 0.87758541, grad/param norm = 1.7502e-01, time/batch = 18.3177s	
11928/26050 (epoch 22.894), train_loss = 0.94709537, grad/param norm = 1.6714e-01, time/batch = 18.9018s	
11929/26050 (epoch 22.896), train_loss = 1.09402058, grad/param norm = 2.0015e-01, time/batch = 16.5604s	
11930/26050 (epoch 22.898), train_loss = 0.94354746, grad/param norm = 1.9704e-01, time/batch = 15.8030s	
11931/26050 (epoch 22.900), train_loss = 1.02576743, grad/param norm = 1.7539e-01, time/batch = 14.7984s	
11932/26050 (epoch 22.902), train_loss = 0.98847612, grad/param norm = 1.8698e-01, time/batch = 17.3910s	
11933/26050 (epoch 22.904), train_loss = 0.99152839, grad/param norm = 1.8029e-01, time/batch = 17.4855s	
11934/26050 (epoch 22.906), train_loss = 0.97943386, grad/param norm = 2.0496e-01, time/batch = 18.2981s	
11935/26050 (epoch 22.908), train_loss = 1.00393652, grad/param norm = 1.7381e-01, time/batch = 18.3132s	
11936/26050 (epoch 22.910), train_loss = 0.96084314, grad/param norm = 1.6663e-01, time/batch = 17.5679s	
11937/26050 (epoch 22.912), train_loss = 1.19354542, grad/param norm = 2.0897e-01, time/batch = 18.0723s	
11938/26050 (epoch 22.914), train_loss = 1.35006130, grad/param norm = 2.2328e-01, time/batch = 18.5687s	
11939/26050 (epoch 22.916), train_loss = 1.10240217, grad/param norm = 2.1382e-01, time/batch = 16.0650s	
11940/26050 (epoch 22.917), train_loss = 1.01508880, grad/param norm = 2.0474e-01, time/batch = 16.4427s	
11941/26050 (epoch 22.919), train_loss = 1.07451289, grad/param norm = 1.9630e-01, time/batch = 17.4042s	
11942/26050 (epoch 22.921), train_loss = 0.95196268, grad/param norm = 2.1077e-01, time/batch = 18.5618s	
11943/26050 (epoch 22.923), train_loss = 1.01680309, grad/param norm = 1.8813e-01, time/batch = 17.7990s	
11944/26050 (epoch 22.925), train_loss = 1.00465219, grad/param norm = 1.7589e-01, time/batch = 18.6370s	
11945/26050 (epoch 22.927), train_loss = 0.88209312, grad/param norm = 1.4948e-01, time/batch = 18.3976s	
11946/26050 (epoch 22.929), train_loss = 0.86286815, grad/param norm = 1.6706e-01, time/batch = 15.0648s	
11947/26050 (epoch 22.931), train_loss = 1.18002662, grad/param norm = 2.4674e-01, time/batch = 31.1402s	
11948/26050 (epoch 22.933), train_loss = 0.95753583, grad/param norm = 1.8478e-01, time/batch = 25.2151s	
11949/26050 (epoch 22.935), train_loss = 0.99144486, grad/param norm = 1.9089e-01, time/batch = 16.2096s	
11950/26050 (epoch 22.937), train_loss = 1.09371016, grad/param norm = 1.8729e-01, time/batch = 18.5590s	
11951/26050 (epoch 22.939), train_loss = 0.92072638, grad/param norm = 1.6283e-01, time/batch = 18.0667s	
11952/26050 (epoch 22.940), train_loss = 0.96514095, grad/param norm = 1.6957e-01, time/batch = 17.3843s	
11953/26050 (epoch 22.942), train_loss = 0.99002916, grad/param norm = 1.8414e-01, time/batch = 17.8190s	
11954/26050 (epoch 22.944), train_loss = 0.96709459, grad/param norm = 2.7123e-01, time/batch = 15.5485s	
11955/26050 (epoch 22.946), train_loss = 1.14342353, grad/param norm = 2.0539e-01, time/batch = 18.4014s	
11956/26050 (epoch 22.948), train_loss = 0.89309427, grad/param norm = 1.8693e-01, time/batch = 17.4665s	
11957/26050 (epoch 22.950), train_loss = 0.97300546, grad/param norm = 1.9611e-01, time/batch = 18.4900s	
11958/26050 (epoch 22.952), train_loss = 1.08115142, grad/param norm = 1.9049e-01, time/batch = 16.8971s	
11959/26050 (epoch 22.954), train_loss = 1.09110239, grad/param norm = 1.8599e-01, time/batch = 17.9869s	
11960/26050 (epoch 22.956), train_loss = 0.99463942, grad/param norm = 1.9760e-01, time/batch = 17.9918s	
11961/26050 (epoch 22.958), train_loss = 0.94043457, grad/param norm = 1.8493e-01, time/batch = 18.5689s	
11962/26050 (epoch 22.960), train_loss = 1.03421571, grad/param norm = 2.0925e-01, time/batch = 17.0671s	
11963/26050 (epoch 22.962), train_loss = 0.96296324, grad/param norm = 1.7060e-01, time/batch = 14.9736s	
11964/26050 (epoch 22.964), train_loss = 1.00428865, grad/param norm = 1.8923e-01, time/batch = 14.8201s	
11965/26050 (epoch 22.965), train_loss = 0.92399997, grad/param norm = 2.1080e-01, time/batch = 18.2343s	
11966/26050 (epoch 22.967), train_loss = 1.31710539, grad/param norm = 1.9104e-01, time/batch = 17.2323s	
11967/26050 (epoch 22.969), train_loss = 1.02098516, grad/param norm = 1.8183e-01, time/batch = 18.0594s	
11968/26050 (epoch 22.971), train_loss = 0.95469008, grad/param norm = 1.6449e-01, time/batch = 17.1334s	
11969/26050 (epoch 22.973), train_loss = 1.00720543, grad/param norm = 1.9032e-01, time/batch = 15.3785s	
11970/26050 (epoch 22.975), train_loss = 1.04145314, grad/param norm = 1.8855e-01, time/batch = 18.6490s	
11971/26050 (epoch 22.977), train_loss = 1.01837253, grad/param norm = 1.6699e-01, time/batch = 16.4171s	
11972/26050 (epoch 22.979), train_loss = 0.83390597, grad/param norm = 1.6589e-01, time/batch = 18.5654s	
11973/26050 (epoch 22.981), train_loss = 1.13433933, grad/param norm = 1.8606e-01, time/batch = 17.6592s	
11974/26050 (epoch 22.983), train_loss = 1.08105351, grad/param norm = 2.0889e-01, time/batch = 16.8851s	
11975/26050 (epoch 22.985), train_loss = 1.06059317, grad/param norm = 1.9187e-01, time/batch = 18.6450s	
11976/26050 (epoch 22.987), train_loss = 1.11864464, grad/param norm = 1.8581e-01, time/batch = 17.1453s	
11977/26050 (epoch 22.988), train_loss = 1.07829008, grad/param norm = 1.8908e-01, time/batch = 18.8115s	
11978/26050 (epoch 22.990), train_loss = 0.89172911, grad/param norm = 1.5730e-01, time/batch = 17.8127s	
11979/26050 (epoch 22.992), train_loss = 1.16073271, grad/param norm = 1.8822e-01, time/batch = 17.8119s	
11980/26050 (epoch 22.994), train_loss = 0.96182209, grad/param norm = 1.9143e-01, time/batch = 18.3053s	
11981/26050 (epoch 22.996), train_loss = 0.94481486, grad/param norm = 1.8521e-01, time/batch = 18.5646s	
11982/26050 (epoch 22.998), train_loss = 1.01138800, grad/param norm = 1.7670e-01, time/batch = 18.0686s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
11983/26050 (epoch 23.000), train_loss = 0.97530846, grad/param norm = 2.1745e-01, time/batch = 14.3903s	
11984/26050 (epoch 23.002), train_loss = 1.06584306, grad/param norm = 2.0110e-01, time/batch = 15.3010s	
11985/26050 (epoch 23.004), train_loss = 0.91293457, grad/param norm = 1.8373e-01, time/batch = 18.7439s	
11986/26050 (epoch 23.006), train_loss = 0.95975533, grad/param norm = 2.0972e-01, time/batch = 17.8255s	
11987/26050 (epoch 23.008), train_loss = 0.95186302, grad/param norm = 2.0392e-01, time/batch = 18.2363s	
11988/26050 (epoch 23.010), train_loss = 0.94293342, grad/param norm = 1.8700e-01, time/batch = 18.5602s	
11989/26050 (epoch 23.012), train_loss = 1.01546608, grad/param norm = 1.8049e-01, time/batch = 17.5715s	
11990/26050 (epoch 23.013), train_loss = 1.28206472, grad/param norm = 2.1114e-01, time/batch = 17.4812s	
11991/26050 (epoch 23.015), train_loss = 0.96867687, grad/param norm = 1.6929e-01, time/batch = 16.8044s	
11992/26050 (epoch 23.017), train_loss = 1.00645722, grad/param norm = 1.7498e-01, time/batch = 18.9361s	
11993/26050 (epoch 23.019), train_loss = 0.87931559, grad/param norm = 1.7309e-01, time/batch = 16.9043s	
11994/26050 (epoch 23.021), train_loss = 1.07065883, grad/param norm = 1.9558e-01, time/batch = 18.4863s	
11995/26050 (epoch 23.023), train_loss = 0.83067921, grad/param norm = 1.7084e-01, time/batch = 18.4161s	
11996/26050 (epoch 23.025), train_loss = 1.00682992, grad/param norm = 1.7955e-01, time/batch = 15.3919s	
11997/26050 (epoch 23.027), train_loss = 0.81179778, grad/param norm = 1.8072e-01, time/batch = 17.8986s	
11998/26050 (epoch 23.029), train_loss = 1.01761987, grad/param norm = 1.6759e-01, time/batch = 17.7351s	
11999/26050 (epoch 23.031), train_loss = 1.12726690, grad/param norm = 2.0844e-01, time/batch = 17.8129s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch23.03_1.6794.t7	
12000/26050 (epoch 23.033), train_loss = 1.03011296, grad/param norm = 1.8792e-01, time/batch = 16.9066s	
12001/26050 (epoch 23.035), train_loss = 1.33231940, grad/param norm = 2.2849e-01, time/batch = 18.6429s	
12002/26050 (epoch 23.036), train_loss = 0.88577970, grad/param norm = 2.0047e-01, time/batch = 17.2497s	
12003/26050 (epoch 23.038), train_loss = 0.82059166, grad/param norm = 1.6613e-01, time/batch = 16.0219s	
12004/26050 (epoch 23.040), train_loss = 0.98534577, grad/param norm = 1.9060e-01, time/batch = 16.4869s	
12005/26050 (epoch 23.042), train_loss = 0.84299885, grad/param norm = 1.8111e-01, time/batch = 18.3127s	
12006/26050 (epoch 23.044), train_loss = 1.08722258, grad/param norm = 1.8597e-01, time/batch = 17.6467s	
12007/26050 (epoch 23.046), train_loss = 0.80933249, grad/param norm = 1.5528e-01, time/batch = 15.8889s	
12008/26050 (epoch 23.048), train_loss = 1.00187506, grad/param norm = 1.7437e-01, time/batch = 18.0613s	
12009/26050 (epoch 23.050), train_loss = 0.94219611, grad/param norm = 1.8087e-01, time/batch = 17.9088s	
12010/26050 (epoch 23.052), train_loss = 0.93603761, grad/param norm = 2.1027e-01, time/batch = 18.5714s	
12011/26050 (epoch 23.054), train_loss = 0.83753206, grad/param norm = 1.6980e-01, time/batch = 17.2330s	
12012/26050 (epoch 23.056), train_loss = 0.81770468, grad/param norm = 1.6197e-01, time/batch = 18.5534s	
12013/26050 (epoch 23.058), train_loss = 0.96430070, grad/param norm = 1.6750e-01, time/batch = 18.2956s	
12014/26050 (epoch 23.060), train_loss = 1.05764049, grad/param norm = 1.8103e-01, time/batch = 17.3959s	
12015/26050 (epoch 23.061), train_loss = 0.90449048, grad/param norm = 1.7310e-01, time/batch = 18.7938s	
12016/26050 (epoch 23.063), train_loss = 1.03036407, grad/param norm = 1.7733e-01, time/batch = 14.8567s	
12017/26050 (epoch 23.065), train_loss = 0.80080988, grad/param norm = 1.4878e-01, time/batch = 15.4598s	
12018/26050 (epoch 23.067), train_loss = 0.99961440, grad/param norm = 1.9086e-01, time/batch = 15.2146s	
12019/26050 (epoch 23.069), train_loss = 1.03803043, grad/param norm = 1.8969e-01, time/batch = 16.3223s	
12020/26050 (epoch 23.071), train_loss = 1.05769638, grad/param norm = 1.9703e-01, time/batch = 18.4783s	
12021/26050 (epoch 23.073), train_loss = 1.16544434, grad/param norm = 1.9283e-01, time/batch = 17.6550s	
12022/26050 (epoch 23.075), train_loss = 0.91523240, grad/param norm = 1.7297e-01, time/batch = 17.9937s	
12023/26050 (epoch 23.077), train_loss = 0.93783420, grad/param norm = 1.8612e-01, time/batch = 18.1590s	
12024/26050 (epoch 23.079), train_loss = 1.00778233, grad/param norm = 1.8279e-01, time/batch = 17.6599s	
12025/26050 (epoch 23.081), train_loss = 0.95539841, grad/param norm = 1.7774e-01, time/batch = 17.5231s	
12026/26050 (epoch 23.083), train_loss = 1.09461604, grad/param norm = 1.8070e-01, time/batch = 16.3904s	
12027/26050 (epoch 23.084), train_loss = 1.02537345, grad/param norm = 2.2081e-01, time/batch = 18.4095s	
12028/26050 (epoch 23.086), train_loss = 1.17159034, grad/param norm = 2.1428e-01, time/batch = 16.4093s	
12029/26050 (epoch 23.088), train_loss = 0.94090490, grad/param norm = 1.8894e-01, time/batch = 17.7314s	
12030/26050 (epoch 23.090), train_loss = 1.00678038, grad/param norm = 1.9013e-01, time/batch = 16.3854s	
12031/26050 (epoch 23.092), train_loss = 1.05020270, grad/param norm = 1.7655e-01, time/batch = 17.1664s	
12032/26050 (epoch 23.094), train_loss = 0.92172145, grad/param norm = 1.8626e-01, time/batch = 14.6439s	
12033/26050 (epoch 23.096), train_loss = 0.99255662, grad/param norm = 1.7059e-01, time/batch = 17.3216s	
12034/26050 (epoch 23.098), train_loss = 0.94228465, grad/param norm = 1.8706e-01, time/batch = 15.8176s	
12035/26050 (epoch 23.100), train_loss = 0.88919448, grad/param norm = 1.7434e-01, time/batch = 16.8197s	
12036/26050 (epoch 23.102), train_loss = 1.05050938, grad/param norm = 1.9922e-01, time/batch = 16.9060s	
12037/26050 (epoch 23.104), train_loss = 0.97715986, grad/param norm = 1.8059e-01, time/batch = 17.4886s	
12038/26050 (epoch 23.106), train_loss = 0.99413557, grad/param norm = 2.0287e-01, time/batch = 17.9038s	
12039/26050 (epoch 23.107), train_loss = 0.81279508, grad/param norm = 1.8561e-01, time/batch = 16.9088s	
12040/26050 (epoch 23.109), train_loss = 0.91773212, grad/param norm = 1.8954e-01, time/batch = 16.9891s	
12041/26050 (epoch 23.111), train_loss = 1.15481264, grad/param norm = 2.0081e-01, time/batch = 17.7457s	
12042/26050 (epoch 23.113), train_loss = 0.92899059, grad/param norm = 1.8311e-01, time/batch = 15.7329s	
12043/26050 (epoch 23.115), train_loss = 1.08199278, grad/param norm = 1.8539e-01, time/batch = 16.7418s	
12044/26050 (epoch 23.117), train_loss = 1.01666727, grad/param norm = 1.8469e-01, time/batch = 14.4795s	
12045/26050 (epoch 23.119), train_loss = 0.83267381, grad/param norm = 1.6456e-01, time/batch = 17.4798s	
12046/26050 (epoch 23.121), train_loss = 1.00282862, grad/param norm = 1.7432e-01, time/batch = 15.0472s	
12047/26050 (epoch 23.123), train_loss = 0.88359041, grad/param norm = 1.7070e-01, time/batch = 15.6423s	
12048/26050 (epoch 23.125), train_loss = 0.86254980, grad/param norm = 1.6513e-01, time/batch = 17.4162s	
12049/26050 (epoch 23.127), train_loss = 0.79771436, grad/param norm = 1.7974e-01, time/batch = 17.3254s	
12050/26050 (epoch 23.129), train_loss = 0.84118715, grad/param norm = 1.8418e-01, time/batch = 16.5637s	
12051/26050 (epoch 23.131), train_loss = 0.95038566, grad/param norm = 1.7386e-01, time/batch = 17.0747s	
12052/26050 (epoch 23.132), train_loss = 0.96878822, grad/param norm = 1.7540e-01, time/batch = 17.1583s	
12053/26050 (epoch 23.134), train_loss = 1.00446989, grad/param norm = 2.1422e-01, time/batch = 16.9117s	
12054/26050 (epoch 23.136), train_loss = 0.99048099, grad/param norm = 1.8346e-01, time/batch = 17.1693s	
12055/26050 (epoch 23.138), train_loss = 0.74527469, grad/param norm = 1.6343e-01, time/batch = 16.9804s	
12056/26050 (epoch 23.140), train_loss = 0.83845349, grad/param norm = 1.8313e-01, time/batch = 17.6632s	
12057/26050 (epoch 23.142), train_loss = 0.85443290, grad/param norm = 1.7106e-01, time/batch = 15.5509s	
12058/26050 (epoch 23.144), train_loss = 0.79149541, grad/param norm = 1.7003e-01, time/batch = 17.1449s	
12059/26050 (epoch 23.146), train_loss = 0.74388953, grad/param norm = 1.6714e-01, time/batch = 16.3964s	
12060/26050 (epoch 23.148), train_loss = 0.77898324, grad/param norm = 1.5209e-01, time/batch = 16.3083s	
12061/26050 (epoch 23.150), train_loss = 0.95391174, grad/param norm = 1.9981e-01, time/batch = 17.1463s	
12062/26050 (epoch 23.152), train_loss = 1.16393794, grad/param norm = 2.4712e-01, time/batch = 17.0686s	
12063/26050 (epoch 23.154), train_loss = 0.78140320, grad/param norm = 1.7630e-01, time/batch = 17.6637s	
12064/26050 (epoch 23.155), train_loss = 0.81695429, grad/param norm = 1.8097e-01, time/batch = 17.1467s	
12065/26050 (epoch 23.157), train_loss = 0.94444604, grad/param norm = 2.2175e-01, time/batch = 17.2358s	
12066/26050 (epoch 23.159), train_loss = 0.98166999, grad/param norm = 1.9306e-01, time/batch = 14.8032s	
12067/26050 (epoch 23.161), train_loss = 1.00967601, grad/param norm = 2.0267e-01, time/batch = 17.1676s	
12068/26050 (epoch 23.163), train_loss = 0.79839798, grad/param norm = 1.5834e-01, time/batch = 16.8345s	
12069/26050 (epoch 23.165), train_loss = 0.76241232, grad/param norm = 1.7565e-01, time/batch = 17.0744s	
12070/26050 (epoch 23.167), train_loss = 1.08123725, grad/param norm = 2.0279e-01, time/batch = 17.4147s	
12071/26050 (epoch 23.169), train_loss = 0.99143323, grad/param norm = 2.1419e-01, time/batch = 14.9642s	
12072/26050 (epoch 23.171), train_loss = 0.81472404, grad/param norm = 1.6509e-01, time/batch = 14.8194s	
12073/26050 (epoch 23.173), train_loss = 0.91780158, grad/param norm = 1.9484e-01, time/batch = 16.8172s	
12074/26050 (epoch 23.175), train_loss = 0.94926220, grad/param norm = 1.8652e-01, time/batch = 16.7184s	
12075/26050 (epoch 23.177), train_loss = 1.06736629, grad/param norm = 1.8302e-01, time/batch = 16.8046s	
12076/26050 (epoch 23.179), train_loss = 0.73028610, grad/param norm = 1.5470e-01, time/batch = 17.4170s	
12077/26050 (epoch 23.180), train_loss = 1.17482947, grad/param norm = 1.9736e-01, time/batch = 17.4940s	
12078/26050 (epoch 23.182), train_loss = 1.19911888, grad/param norm = 2.0181e-01, time/batch = 16.0640s	
12079/26050 (epoch 23.184), train_loss = 1.00522571, grad/param norm = 1.8692e-01, time/batch = 16.8936s	
12080/26050 (epoch 23.186), train_loss = 0.80338463, grad/param norm = 1.6157e-01, time/batch = 17.2404s	
12081/26050 (epoch 23.188), train_loss = 0.96885066, grad/param norm = 1.8266e-01, time/batch = 17.8088s	
12082/26050 (epoch 23.190), train_loss = 1.01798914, grad/param norm = 1.9457e-01, time/batch = 16.0734s	
12083/26050 (epoch 23.192), train_loss = 1.03015449, grad/param norm = 1.7330e-01, time/batch = 17.3282s	
12084/26050 (epoch 23.194), train_loss = 1.02132276, grad/param norm = 1.9353e-01, time/batch = 17.5044s	
12085/26050 (epoch 23.196), train_loss = 1.05878889, grad/param norm = 1.9269e-01, time/batch = 16.9156s	
12086/26050 (epoch 23.198), train_loss = 0.89330966, grad/param norm = 1.7040e-01, time/batch = 17.4974s	
12087/26050 (epoch 23.200), train_loss = 0.88645289, grad/param norm = 1.8695e-01, time/batch = 17.0891s	
12088/26050 (epoch 23.202), train_loss = 0.98885743, grad/param norm = 1.8383e-01, time/batch = 17.6483s	
12089/26050 (epoch 23.203), train_loss = 1.08748044, grad/param norm = 1.9728e-01, time/batch = 15.9373s	
12090/26050 (epoch 23.205), train_loss = 0.92214214, grad/param norm = 1.8627e-01, time/batch = 18.1347s	
12091/26050 (epoch 23.207), train_loss = 0.89989126, grad/param norm = 1.7577e-01, time/batch = 18.6562s	
12092/26050 (epoch 23.209), train_loss = 1.03675793, grad/param norm = 1.8848e-01, time/batch = 17.3137s	
12093/26050 (epoch 23.211), train_loss = 0.81467075, grad/param norm = 1.6497e-01, time/batch = 18.0580s	
12094/26050 (epoch 23.213), train_loss = 1.01704615, grad/param norm = 2.0225e-01, time/batch = 16.7428s	
12095/26050 (epoch 23.215), train_loss = 0.96605048, grad/param norm = 2.0402e-01, time/batch = 15.9543s	
12096/26050 (epoch 23.217), train_loss = 0.93588706, grad/param norm = 1.7666e-01, time/batch = 17.7304s	
12097/26050 (epoch 23.219), train_loss = 0.94829728, grad/param norm = 1.8886e-01, time/batch = 18.1432s	
12098/26050 (epoch 23.221), train_loss = 0.88341220, grad/param norm = 1.8551e-01, time/batch = 18.6507s	
12099/26050 (epoch 23.223), train_loss = 1.02077564, grad/param norm = 1.8933e-01, time/batch = 16.5499s	
12100/26050 (epoch 23.225), train_loss = 0.87759081, grad/param norm = 1.8716e-01, time/batch = 17.3921s	
12101/26050 (epoch 23.226), train_loss = 1.01764598, grad/param norm = 2.0883e-01, time/batch = 18.3267s	
12102/26050 (epoch 23.228), train_loss = 1.10834425, grad/param norm = 1.8884e-01, time/batch = 17.9032s	
12103/26050 (epoch 23.230), train_loss = 0.99119444, grad/param norm = 1.7709e-01, time/batch = 18.2289s	
12104/26050 (epoch 23.232), train_loss = 1.06815450, grad/param norm = 2.3083e-01, time/batch = 17.3259s	
12105/26050 (epoch 23.234), train_loss = 0.86580810, grad/param norm = 1.7204e-01, time/batch = 16.1473s	
12106/26050 (epoch 23.236), train_loss = 1.06521597, grad/param norm = 1.8711e-01, time/batch = 18.3111s	
12107/26050 (epoch 23.238), train_loss = 0.85059267, grad/param norm = 1.8113e-01, time/batch = 18.6338s	
12108/26050 (epoch 23.240), train_loss = 0.97154170, grad/param norm = 1.8554e-01, time/batch = 17.4659s	
12109/26050 (epoch 23.242), train_loss = 0.95359138, grad/param norm = 1.7133e-01, time/batch = 17.4694s	
12110/26050 (epoch 23.244), train_loss = 0.99093070, grad/param norm = 2.1135e-01, time/batch = 18.2350s	
12111/26050 (epoch 23.246), train_loss = 0.89116389, grad/param norm = 1.7730e-01, time/batch = 18.7340s	
12112/26050 (epoch 23.248), train_loss = 0.99646222, grad/param norm = 1.9215e-01, time/batch = 16.4693s	
12113/26050 (epoch 23.250), train_loss = 0.96889338, grad/param norm = 2.0343e-01, time/batch = 14.7676s	
12114/26050 (epoch 23.251), train_loss = 0.92840858, grad/param norm = 1.6695e-01, time/batch = 18.8089s	
12115/26050 (epoch 23.253), train_loss = 0.86384012, grad/param norm = 1.8339e-01, time/batch = 19.1551s	
12116/26050 (epoch 23.255), train_loss = 1.13545103, grad/param norm = 1.9723e-01, time/batch = 16.9790s	
12117/26050 (epoch 23.257), train_loss = 0.96918933, grad/param norm = 1.9174e-01, time/batch = 17.9850s	
12118/26050 (epoch 23.259), train_loss = 1.09279549, grad/param norm = 1.9763e-01, time/batch = 15.3806s	
12119/26050 (epoch 23.261), train_loss = 0.86939244, grad/param norm = 1.8190e-01, time/batch = 17.3113s	
12120/26050 (epoch 23.263), train_loss = 1.04478021, grad/param norm = 2.0504e-01, time/batch = 18.0616s	
12121/26050 (epoch 23.265), train_loss = 1.11831990, grad/param norm = 1.8725e-01, time/batch = 17.6436s	
12122/26050 (epoch 23.267), train_loss = 1.07874124, grad/param norm = 1.7110e-01, time/batch = 18.6518s	
12123/26050 (epoch 23.269), train_loss = 1.08716955, grad/param norm = 1.9259e-01, time/batch = 17.4907s	
12124/26050 (epoch 23.271), train_loss = 1.03547904, grad/param norm = 1.9432e-01, time/batch = 16.3854s	
12125/26050 (epoch 23.273), train_loss = 0.92065268, grad/param norm = 2.0018e-01, time/batch = 17.2321s	
12126/26050 (epoch 23.274), train_loss = 0.95497234, grad/param norm = 1.7512e-01, time/batch = 14.9829s	
12127/26050 (epoch 23.276), train_loss = 0.93603397, grad/param norm = 1.9114e-01, time/batch = 16.7445s	
12128/26050 (epoch 23.278), train_loss = 1.10396092, grad/param norm = 1.8654e-01, time/batch = 17.4679s	
12129/26050 (epoch 23.280), train_loss = 0.97146022, grad/param norm = 1.8037e-01, time/batch = 18.0678s	
12130/26050 (epoch 23.282), train_loss = 1.00998219, grad/param norm = 1.9388e-01, time/batch = 17.7175s	
12131/26050 (epoch 23.284), train_loss = 0.94543628, grad/param norm = 1.7781e-01, time/batch = 17.9910s	
12132/26050 (epoch 23.286), train_loss = 0.98446993, grad/param norm = 1.9330e-01, time/batch = 17.8163s	
12133/26050 (epoch 23.288), train_loss = 0.83558290, grad/param norm = 1.5912e-01, time/batch = 14.6003s	
12134/26050 (epoch 23.290), train_loss = 0.98632280, grad/param norm = 1.8298e-01, time/batch = 16.4679s	
12135/26050 (epoch 23.292), train_loss = 0.89720776, grad/param norm = 1.5683e-01, time/batch = 18.4827s	
12136/26050 (epoch 23.294), train_loss = 0.99223275, grad/param norm = 2.0007e-01, time/batch = 18.3105s	
12137/26050 (epoch 23.296), train_loss = 1.07774434, grad/param norm = 1.8256e-01, time/batch = 16.3724s	
12138/26050 (epoch 23.298), train_loss = 1.00100965, grad/param norm = 1.8466e-01, time/batch = 18.2241s	
12139/26050 (epoch 23.299), train_loss = 0.79910859, grad/param norm = 1.5394e-01, time/batch = 15.9096s	
12140/26050 (epoch 23.301), train_loss = 0.84369746, grad/param norm = 1.7458e-01, time/batch = 16.1241s	
12141/26050 (epoch 23.303), train_loss = 0.98271570, grad/param norm = 2.0553e-01, time/batch = 17.3066s	
12142/26050 (epoch 23.305), train_loss = 0.79450592, grad/param norm = 1.6904e-01, time/batch = 17.8993s	
12143/26050 (epoch 23.307), train_loss = 0.89513423, grad/param norm = 1.8588e-01, time/batch = 17.7359s	
12144/26050 (epoch 23.309), train_loss = 0.95501266, grad/param norm = 1.8205e-01, time/batch = 17.8849s	
12145/26050 (epoch 23.311), train_loss = 1.06211409, grad/param norm = 2.1291e-01, time/batch = 15.6394s	
12146/26050 (epoch 23.313), train_loss = 0.98248273, grad/param norm = 2.1818e-01, time/batch = 16.5711s	
12147/26050 (epoch 23.315), train_loss = 1.06844555, grad/param norm = 1.9127e-01, time/batch = 22.1481s	
12148/26050 (epoch 23.317), train_loss = 1.00496081, grad/param norm = 1.9123e-01, time/batch = 34.3526s	
12149/26050 (epoch 23.319), train_loss = 0.88955664, grad/param norm = 1.7130e-01, time/batch = 16.4085s	
12150/26050 (epoch 23.321), train_loss = 0.94971601, grad/param norm = 1.6297e-01, time/batch = 18.1446s	
12151/26050 (epoch 23.322), train_loss = 1.02304134, grad/param norm = 1.8919e-01, time/batch = 15.0440s	
12152/26050 (epoch 23.324), train_loss = 0.79732223, grad/param norm = 1.6930e-01, time/batch = 18.8002s	
12153/26050 (epoch 23.326), train_loss = 1.10953565, grad/param norm = 1.8683e-01, time/batch = 18.5564s	
12154/26050 (epoch 23.328), train_loss = 0.99278593, grad/param norm = 1.7386e-01, time/batch = 18.7380s	
12155/26050 (epoch 23.330), train_loss = 0.85332951, grad/param norm = 1.7732e-01, time/batch = 18.2450s	
12156/26050 (epoch 23.332), train_loss = 1.03213851, grad/param norm = 2.0512e-01, time/batch = 15.2315s	
12157/26050 (epoch 23.334), train_loss = 0.92692758, grad/param norm = 1.9837e-01, time/batch = 16.3730s	
12158/26050 (epoch 23.336), train_loss = 0.94033756, grad/param norm = 1.8937e-01, time/batch = 17.9940s	
12159/26050 (epoch 23.338), train_loss = 0.85686748, grad/param norm = 1.5968e-01, time/batch = 18.0763s	
12160/26050 (epoch 23.340), train_loss = 1.05638342, grad/param norm = 2.0138e-01, time/batch = 16.9935s	
12161/26050 (epoch 23.342), train_loss = 1.06593424, grad/param norm = 1.9047e-01, time/batch = 17.3992s	
12162/26050 (epoch 23.344), train_loss = 0.90499407, grad/param norm = 1.9149e-01, time/batch = 17.3159s	
12163/26050 (epoch 23.345), train_loss = 0.96302192, grad/param norm = 1.7820e-01, time/batch = 15.4440s	
12164/26050 (epoch 23.347), train_loss = 1.10782386, grad/param norm = 1.8701e-01, time/batch = 18.5388s	
12165/26050 (epoch 23.349), train_loss = 1.02462297, grad/param norm = 1.9299e-01, time/batch = 18.9916s	
12166/26050 (epoch 23.351), train_loss = 1.03122945, grad/param norm = 1.9100e-01, time/batch = 14.8869s	
12167/26050 (epoch 23.353), train_loss = 0.99370465, grad/param norm = 2.0316e-01, time/batch = 15.7878s	
12168/26050 (epoch 23.355), train_loss = 1.02991426, grad/param norm = 2.0429e-01, time/batch = 14.3690s	
12169/26050 (epoch 23.357), train_loss = 0.91204445, grad/param norm = 1.6922e-01, time/batch = 14.7930s	
12170/26050 (epoch 23.359), train_loss = 1.09436748, grad/param norm = 1.9350e-01, time/batch = 14.6068s	
12171/26050 (epoch 23.361), train_loss = 0.90256302, grad/param norm = 1.6643e-01, time/batch = 14.5348s	
12172/26050 (epoch 23.363), train_loss = 1.05093074, grad/param norm = 1.8638e-01, time/batch = 15.4458s	
12173/26050 (epoch 23.365), train_loss = 0.94319883, grad/param norm = 1.6109e-01, time/batch = 17.5738s	
12174/26050 (epoch 23.367), train_loss = 1.04063388, grad/param norm = 1.7559e-01, time/batch = 18.0789s	
12175/26050 (epoch 23.369), train_loss = 0.91148327, grad/param norm = 1.6335e-01, time/batch = 18.1730s	
12176/26050 (epoch 23.370), train_loss = 0.87527322, grad/param norm = 1.6506e-01, time/batch = 18.4030s	
12177/26050 (epoch 23.372), train_loss = 1.00390573, grad/param norm = 2.0257e-01, time/batch = 18.2305s	
12178/26050 (epoch 23.374), train_loss = 1.09890299, grad/param norm = 1.8481e-01, time/batch = 15.8084s	
12179/26050 (epoch 23.376), train_loss = 1.18413481, grad/param norm = 2.1001e-01, time/batch = 17.2473s	
12180/26050 (epoch 23.378), train_loss = 0.92634340, grad/param norm = 1.6814e-01, time/batch = 17.3825s	
12181/26050 (epoch 23.380), train_loss = 1.14924896, grad/param norm = 2.1364e-01, time/batch = 17.3010s	
12182/26050 (epoch 23.382), train_loss = 1.26648064, grad/param norm = 2.7132e-01, time/batch = 18.4965s	
12183/26050 (epoch 23.384), train_loss = 0.96864093, grad/param norm = 1.9116e-01, time/batch = 18.6586s	
12184/26050 (epoch 23.386), train_loss = 1.05508241, grad/param norm = 2.1577e-01, time/batch = 17.1566s	
12185/26050 (epoch 23.388), train_loss = 1.00283445, grad/param norm = 1.9370e-01, time/batch = 17.4647s	
12186/26050 (epoch 23.390), train_loss = 0.93353746, grad/param norm = 1.8844e-01, time/batch = 18.8954s	
12187/26050 (epoch 23.392), train_loss = 0.86042051, grad/param norm = 1.7560e-01, time/batch = 18.0744s	
12188/26050 (epoch 23.393), train_loss = 1.02955923, grad/param norm = 1.9009e-01, time/batch = 17.7276s	
12189/26050 (epoch 23.395), train_loss = 1.04529193, grad/param norm = 1.9589e-01, time/batch = 17.0584s	
12190/26050 (epoch 23.397), train_loss = 1.03504499, grad/param norm = 2.0990e-01, time/batch = 18.1343s	
12191/26050 (epoch 23.399), train_loss = 0.92872950, grad/param norm = 1.9062e-01, time/batch = 15.3008s	
12192/26050 (epoch 23.401), train_loss = 1.01062169, grad/param norm = 2.1277e-01, time/batch = 17.4580s	
12193/26050 (epoch 23.403), train_loss = 1.00718001, grad/param norm = 1.9751e-01, time/batch = 18.6312s	
12194/26050 (epoch 23.405), train_loss = 0.99635699, grad/param norm = 1.8612e-01, time/batch = 17.9905s	
12195/26050 (epoch 23.407), train_loss = 1.14780364, grad/param norm = 2.1247e-01, time/batch = 14.8992s	
12196/26050 (epoch 23.409), train_loss = 1.13521357, grad/param norm = 2.1559e-01, time/batch = 18.5612s	
12197/26050 (epoch 23.411), train_loss = 1.05944117, grad/param norm = 2.6048e-01, time/batch = 18.1524s	
12198/26050 (epoch 23.413), train_loss = 1.15285493, grad/param norm = 1.8746e-01, time/batch = 17.6430s	
12199/26050 (epoch 23.415), train_loss = 1.12271035, grad/param norm = 2.2665e-01, time/batch = 18.1544s	
12200/26050 (epoch 23.417), train_loss = 1.23263714, grad/param norm = 2.2209e-01, time/batch = 17.0433s	
12201/26050 (epoch 23.418), train_loss = 1.08896035, grad/param norm = 2.0977e-01, time/batch = 18.3144s	
12202/26050 (epoch 23.420), train_loss = 0.84481597, grad/param norm = 1.8071e-01, time/batch = 17.3847s	
12203/26050 (epoch 23.422), train_loss = 0.85067503, grad/param norm = 1.8075e-01, time/batch = 18.3157s	
12204/26050 (epoch 23.424), train_loss = 1.13642130, grad/param norm = 2.0494e-01, time/batch = 17.8147s	
12205/26050 (epoch 23.426), train_loss = 1.10150727, grad/param norm = 1.9216e-01, time/batch = 14.8699s	
12206/26050 (epoch 23.428), train_loss = 0.95107501, grad/param norm = 1.7160e-01, time/batch = 17.0655s	
12207/26050 (epoch 23.430), train_loss = 1.13373055, grad/param norm = 1.9232e-01, time/batch = 18.6561s	
12208/26050 (epoch 23.432), train_loss = 0.97466508, grad/param norm = 1.9228e-01, time/batch = 17.9746s	
12209/26050 (epoch 23.434), train_loss = 0.98437245, grad/param norm = 2.0939e-01, time/batch = 17.9152s	
12210/26050 (epoch 23.436), train_loss = 1.12617821, grad/param norm = 2.0589e-01, time/batch = 17.9783s	
12211/26050 (epoch 23.438), train_loss = 1.07349649, grad/param norm = 2.4511e-01, time/batch = 17.3071s	
12212/26050 (epoch 23.440), train_loss = 1.01871811, grad/param norm = 1.9237e-01, time/batch = 18.4735s	
12213/26050 (epoch 23.441), train_loss = 1.00428066, grad/param norm = 1.8729e-01, time/batch = 16.4615s	
12214/26050 (epoch 23.443), train_loss = 0.85170569, grad/param norm = 1.5491e-01, time/batch = 15.5719s	
12215/26050 (epoch 23.445), train_loss = 0.93309840, grad/param norm = 1.8278e-01, time/batch = 16.8655s	
12216/26050 (epoch 23.447), train_loss = 1.13011781, grad/param norm = 2.0210e-01, time/batch = 18.3259s	
12217/26050 (epoch 23.449), train_loss = 0.90959118, grad/param norm = 1.7051e-01, time/batch = 18.2304s	
12218/26050 (epoch 23.451), train_loss = 1.14571586, grad/param norm = 2.0268e-01, time/batch = 17.3204s	
12219/26050 (epoch 23.453), train_loss = 0.93236434, grad/param norm = 1.6151e-01, time/batch = 18.5603s	
12220/26050 (epoch 23.455), train_loss = 1.00798904, grad/param norm = 1.9007e-01, time/batch = 18.6594s	
12221/26050 (epoch 23.457), train_loss = 0.97501017, grad/param norm = 1.7735e-01, time/batch = 16.9999s	
12222/26050 (epoch 23.459), train_loss = 1.08603192, grad/param norm = 1.9098e-01, time/batch = 15.3863s	
12223/26050 (epoch 23.461), train_loss = 1.08999004, grad/param norm = 2.1287e-01, time/batch = 18.2340s	
12224/26050 (epoch 23.463), train_loss = 0.95692373, grad/param norm = 1.6954e-01, time/batch = 18.9805s	
12225/26050 (epoch 23.464), train_loss = 1.03751796, grad/param norm = 1.7475e-01, time/batch = 17.9689s	
12226/26050 (epoch 23.466), train_loss = 1.06335359, grad/param norm = 1.9624e-01, time/batch = 14.9587s	
12227/26050 (epoch 23.468), train_loss = 1.09798370, grad/param norm = 1.7180e-01, time/batch = 16.7921s	
12228/26050 (epoch 23.470), train_loss = 1.13285186, grad/param norm = 2.1830e-01, time/batch = 18.0708s	
12229/26050 (epoch 23.472), train_loss = 1.15462024, grad/param norm = 2.4648e-01, time/batch = 17.8261s	
12230/26050 (epoch 23.474), train_loss = 1.13534482, grad/param norm = 1.9056e-01, time/batch = 18.3148s	
12231/26050 (epoch 23.476), train_loss = 1.13206286, grad/param norm = 1.8408e-01, time/batch = 17.9884s	
12232/26050 (epoch 23.478), train_loss = 1.00216306, grad/param norm = 1.9288e-01, time/batch = 16.8088s	
12233/26050 (epoch 23.480), train_loss = 1.00943691, grad/param norm = 1.8367e-01, time/batch = 15.0354s	
12234/26050 (epoch 23.482), train_loss = 0.97199631, grad/param norm = 1.9221e-01, time/batch = 18.3105s	
12235/26050 (epoch 23.484), train_loss = 0.95595762, grad/param norm = 1.9037e-01, time/batch = 17.7229s	
12236/26050 (epoch 23.486), train_loss = 1.12715320, grad/param norm = 1.7842e-01, time/batch = 17.7230s	
12237/26050 (epoch 23.488), train_loss = 1.22750431, grad/param norm = 2.1860e-01, time/batch = 18.3053s	
12238/26050 (epoch 23.489), train_loss = 1.16943774, grad/param norm = 2.2853e-01, time/batch = 18.3943s	
12239/26050 (epoch 23.491), train_loss = 0.93316994, grad/param norm = 1.8787e-01, time/batch = 15.0583s	
12240/26050 (epoch 23.493), train_loss = 1.01940727, grad/param norm = 1.9616e-01, time/batch = 18.1477s	
12241/26050 (epoch 23.495), train_loss = 0.99950272, grad/param norm = 1.8608e-01, time/batch = 18.4022s	
12242/26050 (epoch 23.497), train_loss = 0.91858473, grad/param norm = 1.7043e-01, time/batch = 17.3030s	
12243/26050 (epoch 23.499), train_loss = 0.97115066, grad/param norm = 1.9539e-01, time/batch = 14.5542s	
12244/26050 (epoch 23.501), train_loss = 1.08502363, grad/param norm = 1.9515e-01, time/batch = 18.2404s	
12245/26050 (epoch 23.503), train_loss = 0.96324708, grad/param norm = 1.8877e-01, time/batch = 18.4198s	
12246/26050 (epoch 23.505), train_loss = 1.12397732, grad/param norm = 1.8051e-01, time/batch = 18.5579s	
12247/26050 (epoch 23.507), train_loss = 1.06960010, grad/param norm = 1.9104e-01, time/batch = 17.9845s	
12248/26050 (epoch 23.509), train_loss = 1.17475065, grad/param norm = 1.7905e-01, time/batch = 18.5664s	
12249/26050 (epoch 23.511), train_loss = 0.95134632, grad/param norm = 1.6684e-01, time/batch = 15.1844s	
12250/26050 (epoch 23.512), train_loss = 0.91875644, grad/param norm = 1.8766e-01, time/batch = 14.2081s	
12251/26050 (epoch 23.514), train_loss = 1.07081905, grad/param norm = 1.9854e-01, time/batch = 13.6870s	
12252/26050 (epoch 23.516), train_loss = 1.13361016, grad/param norm = 1.9474e-01, time/batch = 13.8247s	
12253/26050 (epoch 23.518), train_loss = 1.01010723, grad/param norm = 1.9382e-01, time/batch = 13.8378s	
12254/26050 (epoch 23.520), train_loss = 0.98703730, grad/param norm = 1.8411e-01, time/batch = 13.7590s	
12255/26050 (epoch 23.522), train_loss = 0.79306362, grad/param norm = 1.7536e-01, time/batch = 14.0638s	
12256/26050 (epoch 23.524), train_loss = 1.08432297, grad/param norm = 2.2490e-01, time/batch = 13.6013s	
12257/26050 (epoch 23.526), train_loss = 1.10877597, grad/param norm = 2.1369e-01, time/batch = 14.3756s	
12258/26050 (epoch 23.528), train_loss = 1.07375281, grad/param norm = 2.8479e-01, time/batch = 13.8450s	
12259/26050 (epoch 23.530), train_loss = 0.97359434, grad/param norm = 1.8776e-01, time/batch = 14.0098s	
12260/26050 (epoch 23.532), train_loss = 1.03748635, grad/param norm = 1.9630e-01, time/batch = 13.8463s	
12261/26050 (epoch 23.534), train_loss = 1.08457170, grad/param norm = 2.1140e-01, time/batch = 13.7659s	
12262/26050 (epoch 23.536), train_loss = 1.00633949, grad/param norm = 1.7599e-01, time/batch = 13.9161s	
12263/26050 (epoch 23.537), train_loss = 1.09256844, grad/param norm = 2.0808e-01, time/batch = 14.7173s	
12264/26050 (epoch 23.539), train_loss = 1.01569933, grad/param norm = 1.9570e-01, time/batch = 13.7650s	
12265/26050 (epoch 23.541), train_loss = 1.19931457, grad/param norm = 2.1694e-01, time/batch = 13.7730s	
12266/26050 (epoch 23.543), train_loss = 0.86052258, grad/param norm = 1.7964e-01, time/batch = 13.9203s	
12267/26050 (epoch 23.545), train_loss = 1.05038653, grad/param norm = 1.9863e-01, time/batch = 13.8297s	
12268/26050 (epoch 23.547), train_loss = 0.99204450, grad/param norm = 1.8845e-01, time/batch = 13.8440s	
12269/26050 (epoch 23.549), train_loss = 0.84611449, grad/param norm = 1.7438e-01, time/batch = 13.8444s	
12270/26050 (epoch 23.551), train_loss = 1.06764792, grad/param norm = 1.9003e-01, time/batch = 14.0869s	
12271/26050 (epoch 23.553), train_loss = 0.93539333, grad/param norm = 1.7850e-01, time/batch = 13.9296s	
12272/26050 (epoch 23.555), train_loss = 0.92743245, grad/param norm = 1.7493e-01, time/batch = 14.3867s	
12273/26050 (epoch 23.557), train_loss = 1.04129921, grad/param norm = 1.7786e-01, time/batch = 13.8382s	
12274/26050 (epoch 23.559), train_loss = 0.99638510, grad/param norm = 1.8908e-01, time/batch = 13.7614s	
12275/26050 (epoch 23.560), train_loss = 0.97669247, grad/param norm = 1.8800e-01, time/batch = 14.1542s	
12276/26050 (epoch 23.562), train_loss = 0.98833788, grad/param norm = 1.9494e-01, time/batch = 13.9131s	
12277/26050 (epoch 23.564), train_loss = 1.17181510, grad/param norm = 1.9307e-01, time/batch = 13.9152s	
12278/26050 (epoch 23.566), train_loss = 0.91734240, grad/param norm = 1.8255e-01, time/batch = 13.7636s	
12279/26050 (epoch 23.568), train_loss = 1.04825656, grad/param norm = 1.8136e-01, time/batch = 13.9319s	
12280/26050 (epoch 23.570), train_loss = 1.05267570, grad/param norm = 2.1827e-01, time/batch = 13.8551s	
12281/26050 (epoch 23.572), train_loss = 0.97539971, grad/param norm = 1.9318e-01, time/batch = 13.9344s	
12282/26050 (epoch 23.574), train_loss = 1.02346484, grad/param norm = 2.1977e-01, time/batch = 13.9072s	
12283/26050 (epoch 23.576), train_loss = 1.04778990, grad/param norm = 2.0180e-01, time/batch = 13.8456s	
12284/26050 (epoch 23.578), train_loss = 0.95995013, grad/param norm = 1.8045e-01, time/batch = 13.8475s	
12285/26050 (epoch 23.580), train_loss = 0.94316094, grad/param norm = 1.9811e-01, time/batch = 13.7524s	
12286/26050 (epoch 23.582), train_loss = 1.01884017, grad/param norm = 1.7255e-01, time/batch = 13.6098s	
12287/26050 (epoch 23.583), train_loss = 1.10309783, grad/param norm = 1.7780e-01, time/batch = 13.7559s	
12288/26050 (epoch 23.585), train_loss = 0.88324337, grad/param norm = 1.9500e-01, time/batch = 13.7583s	
12289/26050 (epoch 23.587), train_loss = 1.05953866, grad/param norm = 2.0217e-01, time/batch = 13.9005s	
12290/26050 (epoch 23.589), train_loss = 1.15634073, grad/param norm = 2.0494e-01, time/batch = 13.7651s	
12291/26050 (epoch 23.591), train_loss = 0.99306050, grad/param norm = 1.8241e-01, time/batch = 13.8487s	
12292/26050 (epoch 23.593), train_loss = 0.87337758, grad/param norm = 1.6403e-01, time/batch = 13.8391s	
12293/26050 (epoch 23.595), train_loss = 1.05668567, grad/param norm = 2.0072e-01, time/batch = 14.3110s	
12294/26050 (epoch 23.597), train_loss = 1.02589017, grad/param norm = 1.9227e-01, time/batch = 13.8493s	
12295/26050 (epoch 23.599), train_loss = 1.01721086, grad/param norm = 1.9219e-01, time/batch = 13.6936s	
12296/26050 (epoch 23.601), train_loss = 1.18547062, grad/param norm = 1.9629e-01, time/batch = 14.0729s	
12297/26050 (epoch 23.603), train_loss = 1.02640450, grad/param norm = 1.8191e-01, time/batch = 13.8483s	
12298/26050 (epoch 23.605), train_loss = 0.95386253, grad/param norm = 1.9041e-01, time/batch = 13.8547s	
12299/26050 (epoch 23.607), train_loss = 1.12069850, grad/param norm = 2.0801e-01, time/batch = 13.6766s	
12300/26050 (epoch 23.608), train_loss = 0.87811466, grad/param norm = 1.6500e-01, time/batch = 13.8367s	
12301/26050 (epoch 23.610), train_loss = 0.99211786, grad/param norm = 1.8506e-01, time/batch = 13.7647s	
12302/26050 (epoch 23.612), train_loss = 0.99019738, grad/param norm = 2.0003e-01, time/batch = 13.7739s	
12303/26050 (epoch 23.614), train_loss = 1.03152454, grad/param norm = 1.9559e-01, time/batch = 13.9364s	
12304/26050 (epoch 23.616), train_loss = 1.13328112, grad/param norm = 2.1320e-01, time/batch = 14.2220s	
12305/26050 (epoch 23.618), train_loss = 0.95729828, grad/param norm = 1.9126e-01, time/batch = 13.8392s	
12306/26050 (epoch 23.620), train_loss = 1.05381003, grad/param norm = 1.9038e-01, time/batch = 13.7612s	
12307/26050 (epoch 23.622), train_loss = 0.88735776, grad/param norm = 1.5492e-01, time/batch = 13.7599s	
12308/26050 (epoch 23.624), train_loss = 0.85971835, grad/param norm = 1.7194e-01, time/batch = 13.6819s	
12309/26050 (epoch 23.626), train_loss = 1.07541860, grad/param norm = 2.0099e-01, time/batch = 13.7666s	
12310/26050 (epoch 23.628), train_loss = 0.93155944, grad/param norm = 1.8729e-01, time/batch = 13.7587s	
12311/26050 (epoch 23.630), train_loss = 1.13407929, grad/param norm = 1.8792e-01, time/batch = 13.6866s	
12312/26050 (epoch 23.631), train_loss = 1.16816528, grad/param norm = 2.0878e-01, time/batch = 13.6812s	
12313/26050 (epoch 23.633), train_loss = 0.89117247, grad/param norm = 1.6278e-01, time/batch = 14.1562s	
12314/26050 (epoch 23.635), train_loss = 0.92631305, grad/param norm = 1.6248e-01, time/batch = 14.0674s	
12315/26050 (epoch 23.637), train_loss = 0.90361782, grad/param norm = 1.8334e-01, time/batch = 13.7647s	
12316/26050 (epoch 23.639), train_loss = 1.07544971, grad/param norm = 1.7886e-01, time/batch = 13.6821s	
12317/26050 (epoch 23.641), train_loss = 0.96626579, grad/param norm = 1.7601e-01, time/batch = 13.9902s	
12318/26050 (epoch 23.643), train_loss = 0.90406772, grad/param norm = 1.6138e-01, time/batch = 13.9122s	
12319/26050 (epoch 23.645), train_loss = 0.97579181, grad/param norm = 1.7726e-01, time/batch = 14.3775s	
12320/26050 (epoch 23.647), train_loss = 0.94110139, grad/param norm = 1.8985e-01, time/batch = 13.7581s	
12321/26050 (epoch 23.649), train_loss = 1.00877096, grad/param norm = 2.1114e-01, time/batch = 13.7670s	
12322/26050 (epoch 23.651), train_loss = 0.95213778, grad/param norm = 1.8289e-01, time/batch = 14.0496s	
12323/26050 (epoch 23.653), train_loss = 1.00000533, grad/param norm = 1.8464e-01, time/batch = 13.9212s	
12324/26050 (epoch 23.655), train_loss = 0.92680939, grad/param norm = 1.7947e-01, time/batch = 13.7659s	
12325/26050 (epoch 23.656), train_loss = 0.86923239, grad/param norm = 1.7392e-01, time/batch = 13.6060s	
12326/26050 (epoch 23.658), train_loss = 1.17016103, grad/param norm = 1.9655e-01, time/batch = 13.7463s	
12327/26050 (epoch 23.660), train_loss = 0.87322148, grad/param norm = 1.9759e-01, time/batch = 13.8458s	
12328/26050 (epoch 23.662), train_loss = 0.96578768, grad/param norm = 1.8604e-01, time/batch = 13.7656s	
12329/26050 (epoch 23.664), train_loss = 0.98398794, grad/param norm = 1.8311e-01, time/batch = 13.6871s	
12330/26050 (epoch 23.666), train_loss = 0.94429545, grad/param norm = 1.9658e-01, time/batch = 13.8441s	
12331/26050 (epoch 23.668), train_loss = 0.83069506, grad/param norm = 2.1883e-01, time/batch = 13.9872s	
12332/26050 (epoch 23.670), train_loss = 1.13509605, grad/param norm = 2.2586e-01, time/batch = 13.6932s	
12333/26050 (epoch 23.672), train_loss = 1.00139472, grad/param norm = 1.9240e-01, time/batch = 13.8446s	
12334/26050 (epoch 23.674), train_loss = 0.90597299, grad/param norm = 1.7588e-01, time/batch = 14.0596s	
12335/26050 (epoch 23.676), train_loss = 1.05959092, grad/param norm = 1.9858e-01, time/batch = 13.9135s	
12336/26050 (epoch 23.678), train_loss = 1.12685938, grad/param norm = 2.0672e-01, time/batch = 13.8402s	
12337/26050 (epoch 23.679), train_loss = 1.17828653, grad/param norm = 2.2372e-01, time/batch = 13.8439s	
12338/26050 (epoch 23.681), train_loss = 1.00544222, grad/param norm = 1.8720e-01, time/batch = 13.6817s	
12339/26050 (epoch 23.683), train_loss = 0.91536737, grad/param norm = 2.1797e-01, time/batch = 13.7660s	
12340/26050 (epoch 23.685), train_loss = 0.98426870, grad/param norm = 2.0315e-01, time/batch = 13.6863s	
12341/26050 (epoch 23.687), train_loss = 0.86769033, grad/param norm = 1.8145e-01, time/batch = 13.8428s	
12342/26050 (epoch 23.689), train_loss = 0.95345117, grad/param norm = 1.9496e-01, time/batch = 13.7408s	
12343/26050 (epoch 23.691), train_loss = 0.81409672, grad/param norm = 1.7692e-01, time/batch = 13.7582s	
12344/26050 (epoch 23.693), train_loss = 0.92069488, grad/param norm = 2.0673e-01, time/batch = 13.8353s	
12345/26050 (epoch 23.695), train_loss = 0.99856885, grad/param norm = 1.8379e-01, time/batch = 13.8347s	
12346/26050 (epoch 23.697), train_loss = 0.90419755, grad/param norm = 1.7264e-01, time/batch = 13.6815s	
12347/26050 (epoch 23.699), train_loss = 1.05958115, grad/param norm = 2.1793e-01, time/batch = 13.6924s	
12348/26050 (epoch 23.701), train_loss = 0.90428108, grad/param norm = 1.6070e-01, time/batch = 13.8473s	
12349/26050 (epoch 23.702), train_loss = 1.10211238, grad/param norm = 1.9491e-01, time/batch = 13.9712s	
12350/26050 (epoch 23.704), train_loss = 1.08263341, grad/param norm = 1.8069e-01, time/batch = 13.6818s	
12351/26050 (epoch 23.706), train_loss = 0.95037865, grad/param norm = 1.9582e-01, time/batch = 13.7662s	
12352/26050 (epoch 23.708), train_loss = 1.06850829, grad/param norm = 2.0256e-01, time/batch = 14.0714s	
12353/26050 (epoch 23.710), train_loss = 1.05131927, grad/param norm = 2.0603e-01, time/batch = 14.2456s	
12354/26050 (epoch 23.712), train_loss = 1.02091233, grad/param norm = 1.9331e-01, time/batch = 14.0499s	
12355/26050 (epoch 23.714), train_loss = 0.86607754, grad/param norm = 1.8037e-01, time/batch = 13.6869s	
12356/26050 (epoch 23.716), train_loss = 1.24255543, grad/param norm = 2.1601e-01, time/batch = 13.8479s	
12357/26050 (epoch 23.718), train_loss = 1.07764255, grad/param norm = 1.9315e-01, time/batch = 14.0881s	
12358/26050 (epoch 23.720), train_loss = 0.98725155, grad/param norm = 1.8920e-01, time/batch = 14.0933s	
12359/26050 (epoch 23.722), train_loss = 0.87240311, grad/param norm = 1.7847e-01, time/batch = 13.9302s	
12360/26050 (epoch 23.724), train_loss = 0.91870957, grad/param norm = 1.9109e-01, time/batch = 13.7718s	
12361/26050 (epoch 23.726), train_loss = 1.04717748, grad/param norm = 1.8668e-01, time/batch = 14.0069s	
12362/26050 (epoch 23.727), train_loss = 1.05140568, grad/param norm = 2.0750e-01, time/batch = 13.9760s	
12363/26050 (epoch 23.729), train_loss = 1.05620450, grad/param norm = 1.8521e-01, time/batch = 13.6863s	
12364/26050 (epoch 23.731), train_loss = 1.03284824, grad/param norm = 1.8412e-01, time/batch = 13.6888s	
12365/26050 (epoch 23.733), train_loss = 0.95869231, grad/param norm = 2.2799e-01, time/batch = 14.1003s	
12366/26050 (epoch 23.735), train_loss = 1.18870205, grad/param norm = 2.1933e-01, time/batch = 17.5731s	
12367/26050 (epoch 23.737), train_loss = 0.94081273, grad/param norm = 1.8903e-01, time/batch = 17.9129s	
12368/26050 (epoch 23.739), train_loss = 1.03666010, grad/param norm = 1.9783e-01, time/batch = 18.2550s	
12369/26050 (epoch 23.741), train_loss = 0.92824964, grad/param norm = 1.9167e-01, time/batch = 15.0476s	
12370/26050 (epoch 23.743), train_loss = 1.04482941, grad/param norm = 2.4560e-01, time/batch = 17.1481s	
12371/26050 (epoch 23.745), train_loss = 0.87871297, grad/param norm = 2.0347e-01, time/batch = 18.0031s	
12372/26050 (epoch 23.747), train_loss = 0.91538091, grad/param norm = 1.8276e-01, time/batch = 17.8139s	
12373/26050 (epoch 23.749), train_loss = 1.10743250, grad/param norm = 2.0799e-01, time/batch = 18.0886s	
12374/26050 (epoch 23.750), train_loss = 1.00337785, grad/param norm = 1.7111e-01, time/batch = 18.5619s	
12375/26050 (epoch 23.752), train_loss = 0.96172740, grad/param norm = 2.3202e-01, time/batch = 14.9578s	
12376/26050 (epoch 23.754), train_loss = 1.01748089, grad/param norm = 1.9568e-01, time/batch = 23.3596s	
12377/26050 (epoch 23.756), train_loss = 0.98507044, grad/param norm = 2.0542e-01, time/batch = 29.7289s	
12378/26050 (epoch 23.758), train_loss = 0.97647299, grad/param norm = 2.0407e-01, time/batch = 17.1961s	
12379/26050 (epoch 23.760), train_loss = 1.17283950, grad/param norm = 2.0504e-01, time/batch = 18.3253s	
12380/26050 (epoch 23.762), train_loss = 0.95546835, grad/param norm = 2.0766e-01, time/batch = 15.3749s	
12381/26050 (epoch 23.764), train_loss = 0.99384406, grad/param norm = 2.1188e-01, time/batch = 18.0626s	
12382/26050 (epoch 23.766), train_loss = 1.05457549, grad/param norm = 2.2365e-01, time/batch = 15.1471s	
12383/26050 (epoch 23.768), train_loss = 0.89290979, grad/param norm = 1.7368e-01, time/batch = 16.2872s	
12384/26050 (epoch 23.770), train_loss = 0.98326664, grad/param norm = 2.1267e-01, time/batch = 18.7321s	
12385/26050 (epoch 23.772), train_loss = 0.99364216, grad/param norm = 1.7046e-01, time/batch = 16.5722s	
12386/26050 (epoch 23.774), train_loss = 0.85311665, grad/param norm = 1.8260e-01, time/batch = 19.0713s	
12387/26050 (epoch 23.775), train_loss = 0.72147661, grad/param norm = 1.6543e-01, time/batch = 16.9775s	
12388/26050 (epoch 23.777), train_loss = 0.93958657, grad/param norm = 1.8905e-01, time/batch = 15.6486s	
12389/26050 (epoch 23.779), train_loss = 0.97438091, grad/param norm = 1.9981e-01, time/batch = 17.9002s	
12390/26050 (epoch 23.781), train_loss = 0.88100997, grad/param norm = 1.9598e-01, time/batch = 18.1571s	
12391/26050 (epoch 23.783), train_loss = 0.87294066, grad/param norm = 1.8306e-01, time/batch = 15.4675s	
12392/26050 (epoch 23.785), train_loss = 1.01494592, grad/param norm = 2.1450e-01, time/batch = 17.8758s	
12393/26050 (epoch 23.787), train_loss = 0.90528264, grad/param norm = 1.7897e-01, time/batch = 18.1650s	
12394/26050 (epoch 23.789), train_loss = 0.94339741, grad/param norm = 2.0299e-01, time/batch = 18.4906s	
12395/26050 (epoch 23.791), train_loss = 0.92184665, grad/param norm = 1.8171e-01, time/batch = 17.7227s	
12396/26050 (epoch 23.793), train_loss = 0.97717345, grad/param norm = 2.0008e-01, time/batch = 17.9840s	
12397/26050 (epoch 23.795), train_loss = 0.79680185, grad/param norm = 1.4938e-01, time/batch = 18.1470s	
12398/26050 (epoch 23.797), train_loss = 0.90109879, grad/param norm = 1.7636e-01, time/batch = 18.1626s	
12399/26050 (epoch 23.798), train_loss = 0.86110129, grad/param norm = 1.8679e-01, time/batch = 18.5690s	
12400/26050 (epoch 23.800), train_loss = 0.86186228, grad/param norm = 1.6983e-01, time/batch = 17.3057s	
12401/26050 (epoch 23.802), train_loss = 0.91975586, grad/param norm = 1.8809e-01, time/batch = 17.5240s	
12402/26050 (epoch 23.804), train_loss = 0.98130359, grad/param norm = 1.9667e-01, time/batch = 17.8193s	
12403/26050 (epoch 23.806), train_loss = 1.07044850, grad/param norm = 1.8998e-01, time/batch = 18.4833s	
12404/26050 (epoch 23.808), train_loss = 0.98344110, grad/param norm = 1.8381e-01, time/batch = 17.8200s	
12405/26050 (epoch 23.810), train_loss = 0.93515505, grad/param norm = 1.9487e-01, time/batch = 18.4082s	
12406/26050 (epoch 23.812), train_loss = 0.86356604, grad/param norm = 1.8704e-01, time/batch = 18.3175s	
12407/26050 (epoch 23.814), train_loss = 0.88649229, grad/param norm = 2.3720e-01, time/batch = 18.2393s	
12408/26050 (epoch 23.816), train_loss = 1.05314939, grad/param norm = 2.0058e-01, time/batch = 17.4842s	
12409/26050 (epoch 23.818), train_loss = 1.07772615, grad/param norm = 2.2682e-01, time/batch = 18.3177s	
12410/26050 (epoch 23.820), train_loss = 1.01061620, grad/param norm = 1.8703e-01, time/batch = 18.6598s	
12411/26050 (epoch 23.821), train_loss = 1.10330190, grad/param norm = 2.0695e-01, time/batch = 17.0796s	
12412/26050 (epoch 23.823), train_loss = 1.14518006, grad/param norm = 2.0023e-01, time/batch = 14.4544s	
12413/26050 (epoch 23.825), train_loss = 0.98010808, grad/param norm = 1.8456e-01, time/batch = 18.5632s	
12414/26050 (epoch 23.827), train_loss = 1.02858233, grad/param norm = 2.1369e-01, time/batch = 16.3969s	
12415/26050 (epoch 23.829), train_loss = 1.06917455, grad/param norm = 2.1748e-01, time/batch = 16.8792s	
12416/26050 (epoch 23.831), train_loss = 1.13386329, grad/param norm = 2.0291e-01, time/batch = 18.3134s	
12417/26050 (epoch 23.833), train_loss = 1.19234788, grad/param norm = 2.1506e-01, time/batch = 18.3127s	
12418/26050 (epoch 23.835), train_loss = 1.16510592, grad/param norm = 1.9996e-01, time/batch = 16.7453s	
12419/26050 (epoch 23.837), train_loss = 0.99339722, grad/param norm = 1.8414e-01, time/batch = 17.8809s	
12420/26050 (epoch 23.839), train_loss = 0.99350483, grad/param norm = 2.0563e-01, time/batch = 15.9797s	
12421/26050 (epoch 23.841), train_loss = 1.13505041, grad/param norm = 1.9685e-01, time/batch = 18.8071s	
12422/26050 (epoch 23.843), train_loss = 0.97116685, grad/param norm = 1.7629e-01, time/batch = 16.0516s	
12423/26050 (epoch 23.845), train_loss = 0.95582503, grad/param norm = 1.7704e-01, time/batch = 18.2248s	
12424/26050 (epoch 23.846), train_loss = 1.06862374, grad/param norm = 1.9864e-01, time/batch = 17.8898s	
12425/26050 (epoch 23.848), train_loss = 0.97210720, grad/param norm = 1.8563e-01, time/batch = 17.6533s	
12426/26050 (epoch 23.850), train_loss = 0.89827846, grad/param norm = 1.7490e-01, time/batch = 17.1476s	
12427/26050 (epoch 23.852), train_loss = 0.99611152, grad/param norm = 1.7789e-01, time/batch = 16.6395s	
12428/26050 (epoch 23.854), train_loss = 0.97744213, grad/param norm = 1.8940e-01, time/batch = 18.7315s	
12429/26050 (epoch 23.856), train_loss = 0.95350461, grad/param norm = 1.9547e-01, time/batch = 16.8746s	
12430/26050 (epoch 23.858), train_loss = 0.90962462, grad/param norm = 1.7418e-01, time/batch = 17.0713s	
12431/26050 (epoch 23.860), train_loss = 1.03700176, grad/param norm = 2.0140e-01, time/batch = 16.1080s	
12432/26050 (epoch 23.862), train_loss = 1.05472379, grad/param norm = 1.9989e-01, time/batch = 18.0606s	
12433/26050 (epoch 23.864), train_loss = 1.02209518, grad/param norm = 2.1703e-01, time/batch = 18.0655s	
12434/26050 (epoch 23.866), train_loss = 0.94887312, grad/param norm = 1.7498e-01, time/batch = 18.5618s	
12435/26050 (epoch 23.868), train_loss = 1.04572593, grad/param norm = 2.0639e-01, time/batch = 18.4978s	
12436/26050 (epoch 23.869), train_loss = 0.89358328, grad/param norm = 1.7412e-01, time/batch = 17.4940s	
12437/26050 (epoch 23.871), train_loss = 0.82452358, grad/param norm = 1.5836e-01, time/batch = 17.1649s	
12438/26050 (epoch 23.873), train_loss = 1.03134561, grad/param norm = 2.0386e-01, time/batch = 18.9073s	
12439/26050 (epoch 23.875), train_loss = 0.97527900, grad/param norm = 1.9191e-01, time/batch = 17.2412s	
12440/26050 (epoch 23.877), train_loss = 0.88642526, grad/param norm = 1.7575e-01, time/batch = 18.2427s	
12441/26050 (epoch 23.879), train_loss = 1.00924264, grad/param norm = 1.7558e-01, time/batch = 18.9043s	
12442/26050 (epoch 23.881), train_loss = 1.09984039, grad/param norm = 2.1418e-01, time/batch = 16.9095s	
12443/26050 (epoch 23.883), train_loss = 1.03823538, grad/param norm = 1.8185e-01, time/batch = 18.1570s	
12444/26050 (epoch 23.885), train_loss = 0.75627333, grad/param norm = 1.6292e-01, time/batch = 18.4850s	
12445/26050 (epoch 23.887), train_loss = 1.04623082, grad/param norm = 1.8985e-01, time/batch = 16.3917s	
12446/26050 (epoch 23.889), train_loss = 0.93640134, grad/param norm = 1.7897e-01, time/batch = 17.5614s	
12447/26050 (epoch 23.891), train_loss = 0.81189507, grad/param norm = 1.6119e-01, time/batch = 17.9828s	
12448/26050 (epoch 23.893), train_loss = 0.86219464, grad/param norm = 1.7590e-01, time/batch = 18.9118s	
12449/26050 (epoch 23.894), train_loss = 0.94174082, grad/param norm = 1.8076e-01, time/batch = 17.2307s	
12450/26050 (epoch 23.896), train_loss = 1.07171948, grad/param norm = 2.0159e-01, time/batch = 18.0761s	
12451/26050 (epoch 23.898), train_loss = 0.92946389, grad/param norm = 1.9931e-01, time/batch = 18.0812s	
12452/26050 (epoch 23.900), train_loss = 1.02750218, grad/param norm = 2.0327e-01, time/batch = 17.8221s	
12453/26050 (epoch 23.902), train_loss = 0.98464719, grad/param norm = 1.9919e-01, time/batch = 14.4749s	
12454/26050 (epoch 23.904), train_loss = 0.97098002, grad/param norm = 1.7686e-01, time/batch = 17.3531s	
12455/26050 (epoch 23.906), train_loss = 0.96466169, grad/param norm = 2.0315e-01, time/batch = 15.1403s	
12456/26050 (epoch 23.908), train_loss = 0.97873792, grad/param norm = 1.8044e-01, time/batch = 18.0583s	
12457/26050 (epoch 23.910), train_loss = 0.95087623, grad/param norm = 1.6889e-01, time/batch = 18.4882s	
12458/26050 (epoch 23.912), train_loss = 1.19049470, grad/param norm = 2.2040e-01, time/batch = 17.7194s	
12459/26050 (epoch 23.914), train_loss = 1.33849942, grad/param norm = 2.1989e-01, time/batch = 16.9051s	
12460/26050 (epoch 23.916), train_loss = 1.07068854, grad/param norm = 1.9697e-01, time/batch = 16.3035s	
12461/26050 (epoch 23.917), train_loss = 0.98823650, grad/param norm = 2.0058e-01, time/batch = 17.4820s	
12462/26050 (epoch 23.919), train_loss = 1.05052138, grad/param norm = 2.1228e-01, time/batch = 18.1301s	
12463/26050 (epoch 23.921), train_loss = 0.94267717, grad/param norm = 1.9882e-01, time/batch = 17.2407s	
12464/26050 (epoch 23.923), train_loss = 0.99947130, grad/param norm = 1.9388e-01, time/batch = 17.9004s	
12465/26050 (epoch 23.925), train_loss = 0.98566512, grad/param norm = 1.7451e-01, time/batch = 14.8237s	
12466/26050 (epoch 23.927), train_loss = 0.88724801, grad/param norm = 1.5501e-01, time/batch = 18.3209s	
12467/26050 (epoch 23.929), train_loss = 0.84254191, grad/param norm = 1.6592e-01, time/batch = 18.3969s	
12468/26050 (epoch 23.931), train_loss = 1.14366068, grad/param norm = 2.4505e-01, time/batch = 17.4154s	
12469/26050 (epoch 23.933), train_loss = 0.94882105, grad/param norm = 1.9349e-01, time/batch = 18.5726s	
12470/26050 (epoch 23.935), train_loss = 0.97745750, grad/param norm = 1.9474e-01, time/batch = 17.0828s	
12471/26050 (epoch 23.937), train_loss = 1.08086668, grad/param norm = 1.8334e-01, time/batch = 18.4747s	
12472/26050 (epoch 23.939), train_loss = 0.90900554, grad/param norm = 1.6253e-01, time/batch = 18.8979s	
12473/26050 (epoch 23.940), train_loss = 0.94694448, grad/param norm = 1.7055e-01, time/batch = 15.6486s	
12474/26050 (epoch 23.942), train_loss = 0.97786262, grad/param norm = 1.9119e-01, time/batch = 17.9724s	
12475/26050 (epoch 23.944), train_loss = 0.95285543, grad/param norm = 1.7155e-01, time/batch = 17.6445s	
12476/26050 (epoch 23.946), train_loss = 1.11657429, grad/param norm = 2.0522e-01, time/batch = 17.5579s	
12477/26050 (epoch 23.948), train_loss = 0.86094062, grad/param norm = 1.8750e-01, time/batch = 5.7083s	
12478/26050 (epoch 23.950), train_loss = 0.95987971, grad/param norm = 1.9311e-01, time/batch = 0.6428s	
12479/26050 (epoch 23.952), train_loss = 1.07824905, grad/param norm = 2.1004e-01, time/batch = 0.6424s	
12480/26050 (epoch 23.954), train_loss = 1.07380218, grad/param norm = 1.8823e-01, time/batch = 0.6416s	
12481/26050 (epoch 23.956), train_loss = 0.96520173, grad/param norm = 1.8501e-01, time/batch = 0.6439s	
12482/26050 (epoch 23.958), train_loss = 0.92199798, grad/param norm = 1.8127e-01, time/batch = 0.6583s	
12483/26050 (epoch 23.960), train_loss = 1.01535041, grad/param norm = 1.8835e-01, time/batch = 0.6448s	
12484/26050 (epoch 23.962), train_loss = 0.96212974, grad/param norm = 1.8649e-01, time/batch = 0.6407s	
12485/26050 (epoch 23.964), train_loss = 0.99126479, grad/param norm = 1.8770e-01, time/batch = 0.9491s	
12486/26050 (epoch 23.965), train_loss = 0.91072976, grad/param norm = 1.8990e-01, time/batch = 0.9463s	
12487/26050 (epoch 23.967), train_loss = 1.30125334, grad/param norm = 1.9360e-01, time/batch = 0.9951s	
12488/26050 (epoch 23.969), train_loss = 1.02254226, grad/param norm = 1.9587e-01, time/batch = 0.9444s	
12489/26050 (epoch 23.971), train_loss = 0.94641415, grad/param norm = 1.8537e-01, time/batch = 0.9411s	
12490/26050 (epoch 23.973), train_loss = 1.00460698, grad/param norm = 1.9430e-01, time/batch = 1.5501s	
12491/26050 (epoch 23.975), train_loss = 1.01668417, grad/param norm = 1.9212e-01, time/batch = 1.7695s	
12492/26050 (epoch 23.977), train_loss = 1.00265007, grad/param norm = 1.7168e-01, time/batch = 1.7677s	
12493/26050 (epoch 23.979), train_loss = 0.81752686, grad/param norm = 1.7695e-01, time/batch = 18.0514s	
12494/26050 (epoch 23.981), train_loss = 1.13092650, grad/param norm = 2.0452e-01, time/batch = 18.3209s	
12495/26050 (epoch 23.983), train_loss = 1.07112666, grad/param norm = 2.1687e-01, time/batch = 17.2977s	
12496/26050 (epoch 23.985), train_loss = 1.04510892, grad/param norm = 2.0548e-01, time/batch = 16.3967s	
12497/26050 (epoch 23.987), train_loss = 1.09864279, grad/param norm = 1.9020e-01, time/batch = 18.9042s	
12498/26050 (epoch 23.988), train_loss = 1.04593915, grad/param norm = 1.8225e-01, time/batch = 16.7386s	
12499/26050 (epoch 23.990), train_loss = 0.87753559, grad/param norm = 1.6358e-01, time/batch = 16.1444s	
12500/26050 (epoch 23.992), train_loss = 1.14096933, grad/param norm = 1.9255e-01, time/batch = 17.6744s	
12501/26050 (epoch 23.994), train_loss = 0.95729601, grad/param norm = 2.5614e-01, time/batch = 18.2419s	
12502/26050 (epoch 23.996), train_loss = 0.93329906, grad/param norm = 1.9156e-01, time/batch = 18.2287s	
12503/26050 (epoch 23.998), train_loss = 0.99273196, grad/param norm = 1.7988e-01, time/batch = 18.0615s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
12504/26050 (epoch 24.000), train_loss = 0.96321441, grad/param norm = 2.2004e-01, time/batch = 15.1563s	
12505/26050 (epoch 24.002), train_loss = 1.05398156, grad/param norm = 2.1253e-01, time/batch = 17.2362s	
12506/26050 (epoch 24.004), train_loss = 0.89913741, grad/param norm = 1.9919e-01, time/batch = 18.6507s	
12507/26050 (epoch 24.006), train_loss = 0.94598907, grad/param norm = 2.0398e-01, time/batch = 18.4017s	
12508/26050 (epoch 24.008), train_loss = 0.95348463, grad/param norm = 2.2256e-01, time/batch = 17.4716s	
12509/26050 (epoch 24.010), train_loss = 0.91759743, grad/param norm = 1.7240e-01, time/batch = 14.5564s	
12510/26050 (epoch 24.012), train_loss = 1.00320586, grad/param norm = 1.8740e-01, time/batch = 18.4765s	
12511/26050 (epoch 24.013), train_loss = 1.26916545, grad/param norm = 2.1695e-01, time/batch = 15.2363s	
12512/26050 (epoch 24.015), train_loss = 0.95238209, grad/param norm = 1.7539e-01, time/batch = 17.6420s	
12513/26050 (epoch 24.017), train_loss = 1.00947034, grad/param norm = 1.8262e-01, time/batch = 17.5710s	
12514/26050 (epoch 24.019), train_loss = 0.86927260, grad/param norm = 1.7283e-01, time/batch = 18.7403s	
12515/26050 (epoch 24.021), train_loss = 1.06396441, grad/param norm = 1.8294e-01, time/batch = 17.1642s	
12516/26050 (epoch 24.023), train_loss = 0.80636259, grad/param norm = 1.7251e-01, time/batch = 17.8112s	
12517/26050 (epoch 24.025), train_loss = 0.99065858, grad/param norm = 1.8047e-01, time/batch = 17.6598s	
12518/26050 (epoch 24.027), train_loss = 0.80314369, grad/param norm = 1.9036e-01, time/batch = 18.7423s	
12519/26050 (epoch 24.029), train_loss = 1.00193953, grad/param norm = 1.7322e-01, time/batch = 18.0756s	
12520/26050 (epoch 24.031), train_loss = 1.12659129, grad/param norm = 2.1360e-01, time/batch = 16.7131s	
12521/26050 (epoch 24.033), train_loss = 1.00351597, grad/param norm = 2.1260e-01, time/batch = 18.8870s	
12522/26050 (epoch 24.035), train_loss = 1.02411143, grad/param norm = 1.8454e-01, time/batch = 17.3270s	
12523/26050 (epoch 24.036), train_loss = 0.87407360, grad/param norm = 2.0355e-01, time/batch = 18.4835s	
12524/26050 (epoch 24.038), train_loss = 0.80874598, grad/param norm = 1.8142e-01, time/batch = 18.8295s	
12525/26050 (epoch 24.040), train_loss = 0.96218851, grad/param norm = 1.8200e-01, time/batch = 16.7396s	
12526/26050 (epoch 24.042), train_loss = 0.83567783, grad/param norm = 1.7960e-01, time/batch = 16.1539s	
12527/26050 (epoch 24.044), train_loss = 1.04319993, grad/param norm = 1.7247e-01, time/batch = 15.4774s	
12528/26050 (epoch 24.046), train_loss = 0.79882856, grad/param norm = 1.6405e-01, time/batch = 18.8270s	
12529/26050 (epoch 24.048), train_loss = 0.98159153, grad/param norm = 1.7219e-01, time/batch = 17.4938s	
12530/26050 (epoch 24.050), train_loss = 0.92449917, grad/param norm = 1.8161e-01, time/batch = 16.6532s	
12531/26050 (epoch 24.052), train_loss = 0.90186653, grad/param norm = 1.8434e-01, time/batch = 17.8714s	
12532/26050 (epoch 24.054), train_loss = 0.83277610, grad/param norm = 1.7870e-01, time/batch = 18.1510s	
12533/26050 (epoch 24.056), train_loss = 0.80455353, grad/param norm = 1.6903e-01, time/batch = 17.5711s	
12534/26050 (epoch 24.058), train_loss = 0.95121877, grad/param norm = 1.7275e-01, time/batch = 18.3146s	
12535/26050 (epoch 24.060), train_loss = 1.05216136, grad/param norm = 1.8964e-01, time/batch = 18.5308s	
12536/26050 (epoch 24.061), train_loss = 0.89030735, grad/param norm = 1.6402e-01, time/batch = 17.4690s	
12537/26050 (epoch 24.063), train_loss = 1.01049022, grad/param norm = 1.7410e-01, time/batch = 16.8899s	
12538/26050 (epoch 24.065), train_loss = 0.79578267, grad/param norm = 1.6304e-01, time/batch = 18.8202s	
12539/26050 (epoch 24.067), train_loss = 0.97898994, grad/param norm = 2.0299e-01, time/batch = 17.4807s	
12540/26050 (epoch 24.069), train_loss = 1.03246793, grad/param norm = 2.2515e-01, time/batch = 17.5747s	
12541/26050 (epoch 24.071), train_loss = 1.03051664, grad/param norm = 1.8712e-01, time/batch = 18.7373s	
12542/26050 (epoch 24.073), train_loss = 1.15176357, grad/param norm = 2.0053e-01, time/batch = 17.3169s	
12543/26050 (epoch 24.075), train_loss = 0.91403066, grad/param norm = 1.8965e-01, time/batch = 18.6340s	
12544/26050 (epoch 24.077), train_loss = 0.92699115, grad/param norm = 1.9144e-01, time/batch = 15.7327s	
12545/26050 (epoch 24.079), train_loss = 0.99279477, grad/param norm = 1.8373e-01, time/batch = 17.7298s	
12546/26050 (epoch 24.081), train_loss = 0.93726425, grad/param norm = 1.7797e-01, time/batch = 16.8984s	
12547/26050 (epoch 24.083), train_loss = 1.07191948, grad/param norm = 1.7871e-01, time/batch = 17.4740s	
12548/26050 (epoch 24.084), train_loss = 0.98879033, grad/param norm = 2.0499e-01, time/batch = 15.9646s	
12549/26050 (epoch 24.086), train_loss = 1.15679792, grad/param norm = 2.2379e-01, time/batch = 17.4022s	
12550/26050 (epoch 24.088), train_loss = 0.94369460, grad/param norm = 2.0910e-01, time/batch = 18.0633s	
12551/26050 (epoch 24.090), train_loss = 0.99196383, grad/param norm = 1.7891e-01, time/batch = 17.8243s	
12552/26050 (epoch 24.092), train_loss = 1.04255612, grad/param norm = 1.8113e-01, time/batch = 17.3097s	
12553/26050 (epoch 24.094), train_loss = 0.90224776, grad/param norm = 1.8498e-01, time/batch = 17.2974s	
12554/26050 (epoch 24.096), train_loss = 0.98616860, grad/param norm = 1.7879e-01, time/batch = 18.6625s	
12555/26050 (epoch 24.098), train_loss = 0.93070888, grad/param norm = 1.9367e-01, time/batch = 17.4834s	
12556/26050 (epoch 24.100), train_loss = 0.87132368, grad/param norm = 1.7755e-01, time/batch = 14.5638s	
12557/26050 (epoch 24.102), train_loss = 1.03191267, grad/param norm = 2.1172e-01, time/batch = 18.0606s	
12558/26050 (epoch 24.104), train_loss = 0.96053284, grad/param norm = 1.9138e-01, time/batch = 18.2377s	
12559/26050 (epoch 24.106), train_loss = 0.96933620, grad/param norm = 1.9878e-01, time/batch = 16.4694s	
12560/26050 (epoch 24.107), train_loss = 0.79431457, grad/param norm = 1.7277e-01, time/batch = 17.4745s	
12561/26050 (epoch 24.109), train_loss = 0.89282403, grad/param norm = 1.8630e-01, time/batch = 18.5527s	
12562/26050 (epoch 24.111), train_loss = 1.12406793, grad/param norm = 1.9188e-01, time/batch = 18.5703s	
12563/26050 (epoch 24.113), train_loss = 0.93576575, grad/param norm = 1.8694e-01, time/batch = 17.5723s	
12564/26050 (epoch 24.115), train_loss = 1.06497422, grad/param norm = 1.9133e-01, time/batch = 16.5437s	
12565/26050 (epoch 24.117), train_loss = 0.98766984, grad/param norm = 1.8799e-01, time/batch = 18.6369s	
12566/26050 (epoch 24.119), train_loss = 0.82564873, grad/param norm = 1.7116e-01, time/batch = 17.8122s	
12567/26050 (epoch 24.121), train_loss = 0.98819975, grad/param norm = 1.8394e-01, time/batch = 17.6505s	
12568/26050 (epoch 24.123), train_loss = 0.88254290, grad/param norm = 1.6836e-01, time/batch = 14.7341s	
12569/26050 (epoch 24.125), train_loss = 0.84514767, grad/param norm = 1.7274e-01, time/batch = 19.1327s	
12570/26050 (epoch 24.127), train_loss = 0.78614177, grad/param norm = 1.6823e-01, time/batch = 17.2362s	
12571/26050 (epoch 24.129), train_loss = 0.83105958, grad/param norm = 1.7918e-01, time/batch = 18.4024s	
12572/26050 (epoch 24.131), train_loss = 0.92941312, grad/param norm = 1.8482e-01, time/batch = 17.9899s	
12573/26050 (epoch 24.132), train_loss = 0.94971582, grad/param norm = 1.6527e-01, time/batch = 17.8988s	
12574/26050 (epoch 24.134), train_loss = 0.98707721, grad/param norm = 2.0060e-01, time/batch = 17.1249s	
12575/26050 (epoch 24.136), train_loss = 0.97041629, grad/param norm = 1.7720e-01, time/batch = 18.5725s	
12576/26050 (epoch 24.138), train_loss = 0.73073041, grad/param norm = 1.5606e-01, time/batch = 17.3021s	
12577/26050 (epoch 24.140), train_loss = 0.81710819, grad/param norm = 1.7619e-01, time/batch = 17.7430s	
12578/26050 (epoch 24.142), train_loss = 0.84745236, grad/param norm = 1.7093e-01, time/batch = 18.2927s	
12579/26050 (epoch 24.144), train_loss = 0.77835192, grad/param norm = 1.7615e-01, time/batch = 18.9014s	
12580/26050 (epoch 24.146), train_loss = 0.72708125, grad/param norm = 1.6318e-01, time/batch = 14.6303s	
12581/26050 (epoch 24.148), train_loss = 0.76029480, grad/param norm = 1.4952e-01, time/batch = 17.3955s	
12582/26050 (epoch 24.150), train_loss = 0.92441383, grad/param norm = 1.8549e-01, time/batch = 18.7287s	
12583/26050 (epoch 24.152), train_loss = 1.13170680, grad/param norm = 2.4542e-01, time/batch = 17.8908s	
12584/26050 (epoch 24.154), train_loss = 0.76799015, grad/param norm = 1.9328e-01, time/batch = 18.5631s	
12585/26050 (epoch 24.155), train_loss = 0.81155250, grad/param norm = 1.7869e-01, time/batch = 17.6438s	
12586/26050 (epoch 24.157), train_loss = 0.93581535, grad/param norm = 2.1289e-01, time/batch = 14.8954s	
12587/26050 (epoch 24.159), train_loss = 0.98631615, grad/param norm = 2.0887e-01, time/batch = 17.8893s	
12588/26050 (epoch 24.161), train_loss = 0.99647768, grad/param norm = 2.2174e-01, time/batch = 16.5391s	
12589/26050 (epoch 24.163), train_loss = 0.80069962, grad/param norm = 1.7050e-01, time/batch = 17.9751s	
12590/26050 (epoch 24.165), train_loss = 0.75324108, grad/param norm = 1.8150e-01, time/batch = 17.4036s	
12591/26050 (epoch 24.167), train_loss = 1.08764670, grad/param norm = 2.1423e-01, time/batch = 18.9077s	
12592/26050 (epoch 24.169), train_loss = 0.97901492, grad/param norm = 2.0466e-01, time/batch = 17.6589s	
12593/26050 (epoch 24.171), train_loss = 0.81471655, grad/param norm = 1.7269e-01, time/batch = 14.8023s	
12594/26050 (epoch 24.173), train_loss = 0.91846739, grad/param norm = 1.9422e-01, time/batch = 29.0790s	
12595/26050 (epoch 24.175), train_loss = 0.93293356, grad/param norm = 1.8181e-01, time/batch = 29.0575s	
12596/26050 (epoch 24.177), train_loss = 1.04713384, grad/param norm = 1.7953e-01, time/batch = 17.5835s	
12597/26050 (epoch 24.179), train_loss = 0.71293323, grad/param norm = 1.5733e-01, time/batch = 18.2498s	
12598/26050 (epoch 24.180), train_loss = 1.15185266, grad/param norm = 1.8947e-01, time/batch = 17.1523s	
12599/26050 (epoch 24.182), train_loss = 1.18577080, grad/param norm = 2.1817e-01, time/batch = 16.2986s	
12600/26050 (epoch 24.184), train_loss = 1.00006231, grad/param norm = 1.8793e-01, time/batch = 18.7429s	
12601/26050 (epoch 24.186), train_loss = 0.78689768, grad/param norm = 1.6710e-01, time/batch = 17.5798s	
12602/26050 (epoch 24.188), train_loss = 0.96990095, grad/param norm = 1.8676e-01, time/batch = 18.2311s	
12603/26050 (epoch 24.190), train_loss = 1.00904481, grad/param norm = 2.0700e-01, time/batch = 18.1400s	
12604/26050 (epoch 24.192), train_loss = 1.01011902, grad/param norm = 1.6760e-01, time/batch = 15.2743s	
12605/26050 (epoch 24.194), train_loss = 1.00479783, grad/param norm = 1.8895e-01, time/batch = 17.2255s	
12606/26050 (epoch 24.196), train_loss = 1.04695545, grad/param norm = 1.9647e-01, time/batch = 16.7034s	
12607/26050 (epoch 24.198), train_loss = 0.88062697, grad/param norm = 1.7266e-01, time/batch = 18.3190s	
12608/26050 (epoch 24.200), train_loss = 0.87269490, grad/param norm = 1.8466e-01, time/batch = 18.3034s	
12609/26050 (epoch 24.202), train_loss = 0.97399186, grad/param norm = 1.7634e-01, time/batch = 16.6468s	
12610/26050 (epoch 24.203), train_loss = 1.07597697, grad/param norm = 1.9262e-01, time/batch = 17.9046s	
12611/26050 (epoch 24.205), train_loss = 0.92150202, grad/param norm = 1.9953e-01, time/batch = 15.8623s	
12612/26050 (epoch 24.207), train_loss = 0.89286184, grad/param norm = 1.8275e-01, time/batch = 18.4861s	
12613/26050 (epoch 24.209), train_loss = 1.02526338, grad/param norm = 1.9032e-01, time/batch = 17.5531s	
12614/26050 (epoch 24.211), train_loss = 0.80484867, grad/param norm = 1.6718e-01, time/batch = 15.9719s	
12615/26050 (epoch 24.213), train_loss = 1.00119562, grad/param norm = 1.9856e-01, time/batch = 18.7258s	
12616/26050 (epoch 24.215), train_loss = 0.94942931, grad/param norm = 2.2191e-01, time/batch = 17.3953s	
12617/26050 (epoch 24.217), train_loss = 0.91985642, grad/param norm = 1.7607e-01, time/batch = 17.2335s	
12618/26050 (epoch 24.219), train_loss = 0.92930126, grad/param norm = 1.8844e-01, time/batch = 17.2331s	
12619/26050 (epoch 24.221), train_loss = 0.88345312, grad/param norm = 2.2357e-01, time/batch = 18.9022s	
12620/26050 (epoch 24.223), train_loss = 0.99990367, grad/param norm = 1.9387e-01, time/batch = 17.8994s	
12621/26050 (epoch 24.225), train_loss = 0.86374736, grad/param norm = 1.8442e-01, time/batch = 18.3255s	
12622/26050 (epoch 24.226), train_loss = 1.00488650, grad/param norm = 2.1003e-01, time/batch = 18.4899s	
12623/26050 (epoch 24.228), train_loss = 1.09457268, grad/param norm = 1.9114e-01, time/batch = 14.9809s	
12624/26050 (epoch 24.230), train_loss = 0.98493055, grad/param norm = 1.8498e-01, time/batch = 18.5505s	
12625/26050 (epoch 24.232), train_loss = 1.04799646, grad/param norm = 2.0888e-01, time/batch = 15.2983s	
12626/26050 (epoch 24.234), train_loss = 0.84972389, grad/param norm = 1.7266e-01, time/batch = 17.6526s	
12627/26050 (epoch 24.236), train_loss = 1.04906352, grad/param norm = 1.8339e-01, time/batch = 17.6477s	
12628/26050 (epoch 24.238), train_loss = 0.84661259, grad/param norm = 1.9107e-01, time/batch = 16.6438s	
12629/26050 (epoch 24.240), train_loss = 0.96767129, grad/param norm = 1.9471e-01, time/batch = 18.2426s	
12630/26050 (epoch 24.242), train_loss = 0.93562967, grad/param norm = 1.7611e-01, time/batch = 17.5670s	
12631/26050 (epoch 24.244), train_loss = 0.97867572, grad/param norm = 2.0929e-01, time/batch = 16.8830s	
12632/26050 (epoch 24.246), train_loss = 0.88243899, grad/param norm = 1.8294e-01, time/batch = 16.3991s	
12633/26050 (epoch 24.248), train_loss = 0.97872365, grad/param norm = 1.9917e-01, time/batch = 17.4033s	
12634/26050 (epoch 24.250), train_loss = 0.95760066, grad/param norm = 2.2165e-01, time/batch = 18.3922s	
12635/26050 (epoch 24.251), train_loss = 0.91761314, grad/param norm = 1.7199e-01, time/batch = 18.0599s	
12636/26050 (epoch 24.253), train_loss = 0.85936067, grad/param norm = 1.7518e-01, time/batch = 18.1473s	
12637/26050 (epoch 24.255), train_loss = 1.11899626, grad/param norm = 1.9440e-01, time/batch = 17.4029s	
12638/26050 (epoch 24.257), train_loss = 0.95434731, grad/param norm = 1.9527e-01, time/batch = 16.2152s	
12639/26050 (epoch 24.259), train_loss = 1.08137572, grad/param norm = 1.9206e-01, time/batch = 18.4947s	
12640/26050 (epoch 24.261), train_loss = 0.86119821, grad/param norm = 1.8237e-01, time/batch = 17.4726s	
12641/26050 (epoch 24.263), train_loss = 1.03723502, grad/param norm = 2.0694e-01, time/batch = 17.9127s	
12642/26050 (epoch 24.265), train_loss = 1.11438687, grad/param norm = 2.1380e-01, time/batch = 18.4923s	
12643/26050 (epoch 24.267), train_loss = 1.07007965, grad/param norm = 1.7482e-01, time/batch = 17.4057s	
12644/26050 (epoch 24.269), train_loss = 1.07884379, grad/param norm = 1.9653e-01, time/batch = 18.1505s	
12645/26050 (epoch 24.271), train_loss = 1.00164904, grad/param norm = 1.9840e-01, time/batch = 18.0593s	
12646/26050 (epoch 24.273), train_loss = 0.91121777, grad/param norm = 2.3071e-01, time/batch = 17.0666s	
12647/26050 (epoch 24.274), train_loss = 0.94947320, grad/param norm = 1.6650e-01, time/batch = 16.1370s	
12648/26050 (epoch 24.276), train_loss = 0.92836674, grad/param norm = 1.9302e-01, time/batch = 15.6546s	
12649/26050 (epoch 24.278), train_loss = 1.08154367, grad/param norm = 1.9923e-01, time/batch = 17.7936s	
12650/26050 (epoch 24.280), train_loss = 0.95514543, grad/param norm = 1.7928e-01, time/batch = 18.1537s	
12651/26050 (epoch 24.282), train_loss = 1.00536377, grad/param norm = 1.9256e-01, time/batch = 17.5736s	
12652/26050 (epoch 24.284), train_loss = 0.95412367, grad/param norm = 1.8551e-01, time/batch = 17.7461s	
12653/26050 (epoch 24.286), train_loss = 0.98085885, grad/param norm = 2.0873e-01, time/batch = 16.6247s	
12654/26050 (epoch 24.288), train_loss = 0.82462291, grad/param norm = 1.7774e-01, time/batch = 17.0034s	
12655/26050 (epoch 24.290), train_loss = 0.97586795, grad/param norm = 1.9436e-01, time/batch = 17.6470s	
12656/26050 (epoch 24.292), train_loss = 0.88411568, grad/param norm = 1.6437e-01, time/batch = 18.0783s	
12657/26050 (epoch 24.294), train_loss = 0.96615199, grad/param norm = 1.9732e-01, time/batch = 17.2859s	
12658/26050 (epoch 24.296), train_loss = 1.06386918, grad/param norm = 1.8837e-01, time/batch = 18.0655s	
12659/26050 (epoch 24.298), train_loss = 0.98830554, grad/param norm = 1.8309e-01, time/batch = 18.1465s	
12660/26050 (epoch 24.299), train_loss = 0.80078147, grad/param norm = 1.5924e-01, time/batch = 17.3191s	
12661/26050 (epoch 24.301), train_loss = 0.82453881, grad/param norm = 1.7418e-01, time/batch = 18.1305s	
12662/26050 (epoch 24.303), train_loss = 0.96409055, grad/param norm = 2.0889e-01, time/batch = 18.4798s	
12663/26050 (epoch 24.305), train_loss = 0.79704335, grad/param norm = 1.9130e-01, time/batch = 18.8992s	
12664/26050 (epoch 24.307), train_loss = 0.89478199, grad/param norm = 1.8633e-01, time/batch = 17.2316s	
12665/26050 (epoch 24.309), train_loss = 0.94195035, grad/param norm = 1.7937e-01, time/batch = 18.0659s	
12666/26050 (epoch 24.311), train_loss = 1.04689923, grad/param norm = 2.5114e-01, time/batch = 18.0688s	
12667/26050 (epoch 24.313), train_loss = 0.96729493, grad/param norm = 2.1405e-01, time/batch = 15.6404s	
12668/26050 (epoch 24.315), train_loss = 1.04178344, grad/param norm = 2.0110e-01, time/batch = 16.6506s	
12669/26050 (epoch 24.317), train_loss = 0.99027589, grad/param norm = 1.9800e-01, time/batch = 15.3905s	
12670/26050 (epoch 24.319), train_loss = 0.86931064, grad/param norm = 1.6969e-01, time/batch = 18.6564s	
12671/26050 (epoch 24.321), train_loss = 0.93637194, grad/param norm = 1.9127e-01, time/batch = 15.8073s	
12672/26050 (epoch 24.322), train_loss = 0.99169623, grad/param norm = 1.7222e-01, time/batch = 17.8541s	
12673/26050 (epoch 24.324), train_loss = 0.79230827, grad/param norm = 1.7128e-01, time/batch = 17.2003s	
12674/26050 (epoch 24.326), train_loss = 1.09383423, grad/param norm = 1.9982e-01, time/batch = 17.9784s	
12675/26050 (epoch 24.328), train_loss = 0.97917514, grad/param norm = 1.7891e-01, time/batch = 18.0732s	
12676/26050 (epoch 24.330), train_loss = 0.83996993, grad/param norm = 1.7495e-01, time/batch = 18.4880s	
12677/26050 (epoch 24.332), train_loss = 1.02876355, grad/param norm = 2.0376e-01, time/batch = 15.3180s	
12678/26050 (epoch 24.334), train_loss = 0.89890404, grad/param norm = 1.9302e-01, time/batch = 17.2996s	
12679/26050 (epoch 24.336), train_loss = 0.92257586, grad/param norm = 2.1023e-01, time/batch = 18.3221s	
12680/26050 (epoch 24.338), train_loss = 0.84903594, grad/param norm = 1.7156e-01, time/batch = 18.2373s	
12681/26050 (epoch 24.340), train_loss = 1.03929972, grad/param norm = 2.1064e-01, time/batch = 17.3128s	
12682/26050 (epoch 24.342), train_loss = 1.06100108, grad/param norm = 2.1050e-01, time/batch = 18.6542s	
12683/26050 (epoch 24.344), train_loss = 0.89059403, grad/param norm = 1.9997e-01, time/batch = 18.4029s	
12684/26050 (epoch 24.345), train_loss = 0.97604497, grad/param norm = 2.0645e-01, time/batch = 17.6584s	
12685/26050 (epoch 24.347), train_loss = 1.07424429, grad/param norm = 1.8863e-01, time/batch = 18.1441s	
12686/26050 (epoch 24.349), train_loss = 1.00456575, grad/param norm = 1.9434e-01, time/batch = 14.6787s	
12687/26050 (epoch 24.351), train_loss = 1.02318171, grad/param norm = 2.0236e-01, time/batch = 18.5581s	
12688/26050 (epoch 24.353), train_loss = 0.98350611, grad/param norm = 2.0434e-01, time/batch = 16.5736s	
12689/26050 (epoch 24.355), train_loss = 1.00215881, grad/param norm = 2.2078e-01, time/batch = 18.7329s	
12690/26050 (epoch 24.357), train_loss = 0.89514341, grad/param norm = 1.7258e-01, time/batch = 18.6451s	
12691/26050 (epoch 24.359), train_loss = 1.07180465, grad/param norm = 1.9524e-01, time/batch = 17.8953s	
12692/26050 (epoch 24.361), train_loss = 0.87918192, grad/param norm = 1.6714e-01, time/batch = 17.6347s	
12693/26050 (epoch 24.363), train_loss = 1.03080388, grad/param norm = 1.8557e-01, time/batch = 18.6412s	
12694/26050 (epoch 24.365), train_loss = 0.93460156, grad/param norm = 1.7039e-01, time/batch = 17.4780s	
12695/26050 (epoch 24.367), train_loss = 1.03299557, grad/param norm = 1.7836e-01, time/batch = 17.2402s	
12696/26050 (epoch 24.369), train_loss = 0.89735506, grad/param norm = 1.7173e-01, time/batch = 18.6477s	
12697/26050 (epoch 24.370), train_loss = 0.85445084, grad/param norm = 1.6218e-01, time/batch = 17.0493s	
12698/26050 (epoch 24.372), train_loss = 0.99159309, grad/param norm = 1.9205e-01, time/batch = 14.6348s	
12699/26050 (epoch 24.374), train_loss = 1.09332595, grad/param norm = 1.9125e-01, time/batch = 17.8896s	
12700/26050 (epoch 24.376), train_loss = 1.15707869, grad/param norm = 2.3068e-01, time/batch = 18.2393s	
12701/26050 (epoch 24.378), train_loss = 0.90317945, grad/param norm = 1.6131e-01, time/batch = 15.8798s	
12702/26050 (epoch 24.380), train_loss = 1.12931633, grad/param norm = 2.2337e-01, time/batch = 17.8275s	
12703/26050 (epoch 24.382), train_loss = 1.25921927, grad/param norm = 2.6895e-01, time/batch = 18.0703s	
12704/26050 (epoch 24.384), train_loss = 0.96397173, grad/param norm = 2.1036e-01, time/batch = 18.7982s	
12705/26050 (epoch 24.386), train_loss = 1.03722080, grad/param norm = 2.3662e-01, time/batch = 17.8089s	
12706/26050 (epoch 24.388), train_loss = 0.98330487, grad/param norm = 2.1120e-01, time/batch = 17.4978s	
12707/26050 (epoch 24.390), train_loss = 0.92102580, grad/param norm = 1.8841e-01, time/batch = 16.5576s	
12708/26050 (epoch 24.392), train_loss = 0.85113247, grad/param norm = 1.6294e-01, time/batch = 17.8312s	
12709/26050 (epoch 24.393), train_loss = 1.02414921, grad/param norm = 2.1915e-01, time/batch = 16.3929s	
12710/26050 (epoch 24.395), train_loss = 1.03003496, grad/param norm = 1.8933e-01, time/batch = 17.5553s	
12711/26050 (epoch 24.397), train_loss = 1.04412480, grad/param norm = 2.1361e-01, time/batch = 16.1279s	
12712/26050 (epoch 24.399), train_loss = 0.93020536, grad/param norm = 1.9978e-01, time/batch = 16.8681s	
12713/26050 (epoch 24.401), train_loss = 1.00133936, grad/param norm = 1.9871e-01, time/batch = 18.0712s	
12714/26050 (epoch 24.403), train_loss = 0.98694889, grad/param norm = 1.9956e-01, time/batch = 18.2401s	
12715/26050 (epoch 24.405), train_loss = 0.98091570, grad/param norm = 1.9103e-01, time/batch = 16.9130s	
12716/26050 (epoch 24.407), train_loss = 1.12622439, grad/param norm = 2.0494e-01, time/batch = 18.3144s	
12717/26050 (epoch 24.409), train_loss = 1.11254942, grad/param norm = 2.0146e-01, time/batch = 14.9771s	
12718/26050 (epoch 24.411), train_loss = 1.03011211, grad/param norm = 1.8831e-01, time/batch = 18.1590s	
12719/26050 (epoch 24.413), train_loss = 1.12370495, grad/param norm = 1.7974e-01, time/batch = 18.1428s	
12720/26050 (epoch 24.415), train_loss = 1.12791218, grad/param norm = 3.3100e-01, time/batch = 17.8187s	
12721/26050 (epoch 24.417), train_loss = 1.20609345, grad/param norm = 2.1880e-01, time/batch = 18.1586s	
12722/26050 (epoch 24.418), train_loss = 1.08695601, grad/param norm = 2.2295e-01, time/batch = 16.9958s	
12723/26050 (epoch 24.420), train_loss = 0.83842878, grad/param norm = 1.7800e-01, time/batch = 16.3908s	
12724/26050 (epoch 24.422), train_loss = 0.83362041, grad/param norm = 1.8718e-01, time/batch = 18.1387s	
12725/26050 (epoch 24.424), train_loss = 1.12858521, grad/param norm = 2.2409e-01, time/batch = 15.3207s	
12726/26050 (epoch 24.426), train_loss = 1.07838154, grad/param norm = 1.9300e-01, time/batch = 17.6480s	
12727/26050 (epoch 24.428), train_loss = 0.93561581, grad/param norm = 1.6769e-01, time/batch = 14.7954s	
12728/26050 (epoch 24.430), train_loss = 1.10973100, grad/param norm = 1.8489e-01, time/batch = 18.3296s	
12729/26050 (epoch 24.432), train_loss = 0.96280169, grad/param norm = 1.8814e-01, time/batch = 16.1505s	
12730/26050 (epoch 24.434), train_loss = 0.97339481, grad/param norm = 1.8729e-01, time/batch = 17.8272s	
12731/26050 (epoch 24.436), train_loss = 1.11586775, grad/param norm = 2.0384e-01, time/batch = 18.2330s	
12732/26050 (epoch 24.438), train_loss = 1.05504020, grad/param norm = 1.8971e-01, time/batch = 17.3432s	
12733/26050 (epoch 24.440), train_loss = 1.00990696, grad/param norm = 1.9904e-01, time/batch = 15.4638s	
12734/26050 (epoch 24.441), train_loss = 0.98843248, grad/param norm = 1.8457e-01, time/batch = 18.3922s	
12735/26050 (epoch 24.443), train_loss = 0.83865912, grad/param norm = 1.4938e-01, time/batch = 18.6523s	
12736/26050 (epoch 24.445), train_loss = 0.90621867, grad/param norm = 1.7333e-01, time/batch = 17.4846s	
12737/26050 (epoch 24.447), train_loss = 1.09491387, grad/param norm = 2.1151e-01, time/batch = 16.3897s	
12738/26050 (epoch 24.449), train_loss = 0.90005146, grad/param norm = 1.7534e-01, time/batch = 18.3139s	
12739/26050 (epoch 24.451), train_loss = 1.13886430, grad/param norm = 1.9383e-01, time/batch = 17.3914s	
12740/26050 (epoch 24.453), train_loss = 0.91996328, grad/param norm = 1.7262e-01, time/batch = 18.6340s	
12741/26050 (epoch 24.455), train_loss = 0.99525910, grad/param norm = 1.9196e-01, time/batch = 18.2348s	
12742/26050 (epoch 24.457), train_loss = 0.97033743, grad/param norm = 1.8491e-01, time/batch = 15.4714s	
12743/26050 (epoch 24.459), train_loss = 1.07544036, grad/param norm = 1.9946e-01, time/batch = 15.9635s	
12744/26050 (epoch 24.461), train_loss = 1.07676431, grad/param norm = 2.1419e-01, time/batch = 16.8778s	
12745/26050 (epoch 24.463), train_loss = 0.94342255, grad/param norm = 1.7499e-01, time/batch = 15.3067s	
12746/26050 (epoch 24.464), train_loss = 1.01757335, grad/param norm = 1.7842e-01, time/batch = 17.0769s	
12747/26050 (epoch 24.466), train_loss = 1.05426263, grad/param norm = 2.0072e-01, time/batch = 18.3187s	
12748/26050 (epoch 24.468), train_loss = 1.08568238, grad/param norm = 1.7289e-01, time/batch = 18.9165s	
12749/26050 (epoch 24.470), train_loss = 1.09790953, grad/param norm = 2.3161e-01, time/batch = 17.8256s	
12750/26050 (epoch 24.472), train_loss = 1.12590487, grad/param norm = 2.1755e-01, time/batch = 16.4757s	
12751/26050 (epoch 24.474), train_loss = 1.12496817, grad/param norm = 1.8694e-01, time/batch = 14.7250s	
12752/26050 (epoch 24.476), train_loss = 1.12260388, grad/param norm = 1.9929e-01, time/batch = 18.1464s	
12753/26050 (epoch 24.478), train_loss = 0.96806411, grad/param norm = 1.7370e-01, time/batch = 17.8952s	
12754/26050 (epoch 24.480), train_loss = 0.98993749, grad/param norm = 1.9094e-01, time/batch = 18.3302s	
12755/26050 (epoch 24.482), train_loss = 0.94446795, grad/param norm = 1.8233e-01, time/batch = 17.5681s	
12756/26050 (epoch 24.484), train_loss = 0.92776683, grad/param norm = 1.8227e-01, time/batch = 18.4969s	
12757/26050 (epoch 24.486), train_loss = 1.11573743, grad/param norm = 1.8457e-01, time/batch = 18.1444s	
12758/26050 (epoch 24.488), train_loss = 1.22626897, grad/param norm = 2.2369e-01, time/batch = 18.0755s	
12759/26050 (epoch 24.489), train_loss = 1.15360787, grad/param norm = 2.3391e-01, time/batch = 17.0480s	
12760/26050 (epoch 24.491), train_loss = 0.93856702, grad/param norm = 2.1727e-01, time/batch = 17.4099s	
12761/26050 (epoch 24.493), train_loss = 1.00412734, grad/param norm = 1.8828e-01, time/batch = 15.4668s	
12762/26050 (epoch 24.495), train_loss = 0.96981609, grad/param norm = 1.7761e-01, time/batch = 18.4836s	
12763/26050 (epoch 24.497), train_loss = 0.90184460, grad/param norm = 1.8148e-01, time/batch = 17.6438s	
12764/26050 (epoch 24.499), train_loss = 0.95992849, grad/param norm = 1.8782e-01, time/batch = 16.6511s	
12765/26050 (epoch 24.501), train_loss = 1.06307439, grad/param norm = 2.0587e-01, time/batch = 16.4846s	
12766/26050 (epoch 24.503), train_loss = 0.93982556, grad/param norm = 1.7953e-01, time/batch = 18.7531s	
12767/26050 (epoch 24.505), train_loss = 1.10695387, grad/param norm = 1.8732e-01, time/batch = 17.4826s	
12768/26050 (epoch 24.507), train_loss = 1.05936599, grad/param norm = 2.0187e-01, time/batch = 17.5606s	
12769/26050 (epoch 24.509), train_loss = 1.15730498, grad/param norm = 1.9163e-01, time/batch = 18.8185s	
12770/26050 (epoch 24.511), train_loss = 0.94525562, grad/param norm = 1.7037e-01, time/batch = 18.3028s	
12771/26050 (epoch 24.512), train_loss = 0.88707664, grad/param norm = 1.9869e-01, time/batch = 17.3178s	
12772/26050 (epoch 24.514), train_loss = 1.06072774, grad/param norm = 2.2155e-01, time/batch = 18.0709s	
12773/26050 (epoch 24.516), train_loss = 1.12009528, grad/param norm = 2.6500e-01, time/batch = 18.2334s	
12774/26050 (epoch 24.518), train_loss = 1.00511467, grad/param norm = 1.9714e-01, time/batch = 18.4148s	
12775/26050 (epoch 24.520), train_loss = 0.98011666, grad/param norm = 1.9218e-01, time/batch = 15.7074s	
12776/26050 (epoch 24.522), train_loss = 0.77725439, grad/param norm = 1.7426e-01, time/batch = 17.4076s	
12777/26050 (epoch 24.524), train_loss = 1.07241849, grad/param norm = 2.4498e-01, time/batch = 17.7268s	
12778/26050 (epoch 24.526), train_loss = 1.09917304, grad/param norm = 2.1956e-01, time/batch = 18.8091s	
12779/26050 (epoch 24.528), train_loss = 1.04592770, grad/param norm = 2.1822e-01, time/batch = 18.1549s	
12780/26050 (epoch 24.530), train_loss = 0.95506093, grad/param norm = 2.0161e-01, time/batch = 16.6389s	
12781/26050 (epoch 24.532), train_loss = 1.02252018, grad/param norm = 1.8693e-01, time/batch = 17.9687s	
12782/26050 (epoch 24.534), train_loss = 1.05694143, grad/param norm = 2.3934e-01, time/batch = 18.7486s	
12783/26050 (epoch 24.536), train_loss = 0.99649247, grad/param norm = 1.8187e-01, time/batch = 18.4840s	
12784/26050 (epoch 24.537), train_loss = 1.06363150, grad/param norm = 2.1304e-01, time/batch = 18.3084s	
12785/26050 (epoch 24.539), train_loss = 0.99519361, grad/param norm = 1.8627e-01, time/batch = 18.3193s	
12786/26050 (epoch 24.541), train_loss = 1.17816235, grad/param norm = 2.2998e-01, time/batch = 14.9050s	
12787/26050 (epoch 24.543), train_loss = 0.85097288, grad/param norm = 1.9371e-01, time/batch = 17.7335s	
12788/26050 (epoch 24.545), train_loss = 1.02788946, grad/param norm = 1.8895e-01, time/batch = 18.3049s	
12789/26050 (epoch 24.547), train_loss = 0.96778159, grad/param norm = 1.8771e-01, time/batch = 18.3944s	
12790/26050 (epoch 24.549), train_loss = 0.83445850, grad/param norm = 1.8415e-01, time/batch = 16.1183s	
12791/26050 (epoch 24.551), train_loss = 1.05667360, grad/param norm = 1.9170e-01, time/batch = 18.1270s	
12792/26050 (epoch 24.553), train_loss = 0.93539695, grad/param norm = 1.8322e-01, time/batch = 16.6571s	
12793/26050 (epoch 24.555), train_loss = 0.90646663, grad/param norm = 1.7468e-01, time/batch = 18.8093s	
12794/26050 (epoch 24.557), train_loss = 1.02343796, grad/param norm = 1.7630e-01, time/batch = 17.2434s	
12795/26050 (epoch 24.559), train_loss = 0.98393795, grad/param norm = 1.9393e-01, time/batch = 18.4022s	
12796/26050 (epoch 24.560), train_loss = 0.96870527, grad/param norm = 1.9461e-01, time/batch = 17.5533s	
12797/26050 (epoch 24.562), train_loss = 0.98258863, grad/param norm = 1.9867e-01, time/batch = 19.6939s	
12798/26050 (epoch 24.564), train_loss = 1.16343712, grad/param norm = 1.9397e-01, time/batch = 35.4488s	
12799/26050 (epoch 24.566), train_loss = 0.89976683, grad/param norm = 1.7588e-01, time/batch = 16.8877s	
12800/26050 (epoch 24.568), train_loss = 1.02285059, grad/param norm = 1.7987e-01, time/batch = 18.1500s	
12801/26050 (epoch 24.570), train_loss = 1.04127622, grad/param norm = 2.0739e-01, time/batch = 15.3062s	
12802/26050 (epoch 24.572), train_loss = 0.95152990, grad/param norm = 1.9018e-01, time/batch = 18.2464s	
12803/26050 (epoch 24.574), train_loss = 0.99887977, grad/param norm = 2.1661e-01, time/batch = 17.7410s	
12804/26050 (epoch 24.576), train_loss = 1.03522617, grad/param norm = 2.1699e-01, time/batch = 17.9025s	
12805/26050 (epoch 24.578), train_loss = 0.96565958, grad/param norm = 1.8902e-01, time/batch = 18.0868s	
12806/26050 (epoch 24.580), train_loss = 0.92416680, grad/param norm = 1.9495e-01, time/batch = 17.3994s	
12807/26050 (epoch 24.582), train_loss = 1.01252598, grad/param norm = 1.8545e-01, time/batch = 16.3879s	
12808/26050 (epoch 24.583), train_loss = 1.08436372, grad/param norm = 1.8322e-01, time/batch = 17.8805s	
12809/26050 (epoch 24.585), train_loss = 0.86633416, grad/param norm = 1.9339e-01, time/batch = 16.3868s	
12810/26050 (epoch 24.587), train_loss = 1.04958395, grad/param norm = 2.0360e-01, time/batch = 17.4732s	
12811/26050 (epoch 24.589), train_loss = 1.14039910, grad/param norm = 2.1392e-01, time/batch = 17.7282s	
12812/26050 (epoch 24.591), train_loss = 0.97804326, grad/param norm = 1.8171e-01, time/batch = 16.0523s	
12813/26050 (epoch 24.593), train_loss = 0.87434148, grad/param norm = 1.8570e-01, time/batch = 16.9645s	
12814/26050 (epoch 24.595), train_loss = 1.05247201, grad/param norm = 2.0040e-01, time/batch = 17.4612s	
12815/26050 (epoch 24.597), train_loss = 1.00564543, grad/param norm = 1.8762e-01, time/batch = 18.5733s	
12816/26050 (epoch 24.599), train_loss = 1.01180526, grad/param norm = 1.8066e-01, time/batch = 18.4085s	
12817/26050 (epoch 24.601), train_loss = 1.17850668, grad/param norm = 2.0745e-01, time/batch = 17.9823s	
12818/26050 (epoch 24.603), train_loss = 1.01416738, grad/param norm = 1.9402e-01, time/batch = 18.4734s	
12819/26050 (epoch 24.605), train_loss = 0.95735211, grad/param norm = 2.0083e-01, time/batch = 18.0681s	
12820/26050 (epoch 24.607), train_loss = 1.09733312, grad/param norm = 2.0110e-01, time/batch = 17.2428s	
12821/26050 (epoch 24.608), train_loss = 0.88533142, grad/param norm = 1.7508e-01, time/batch = 16.3809s	
12822/26050 (epoch 24.610), train_loss = 0.97683898, grad/param norm = 2.0231e-01, time/batch = 17.2417s	
12823/26050 (epoch 24.612), train_loss = 0.96371532, grad/param norm = 1.8957e-01, time/batch = 15.7420s	
12824/26050 (epoch 24.614), train_loss = 0.99461447, grad/param norm = 1.8351e-01, time/batch = 18.3314s	
12825/26050 (epoch 24.616), train_loss = 1.10765169, grad/param norm = 2.2215e-01, time/batch = 16.4087s	
12826/26050 (epoch 24.618), train_loss = 0.94485858, grad/param norm = 1.8910e-01, time/batch = 17.1286s	
12827/26050 (epoch 24.620), train_loss = 1.04017211, grad/param norm = 1.8051e-01, time/batch = 17.4843s	
12828/26050 (epoch 24.622), train_loss = 0.87305071, grad/param norm = 1.5831e-01, time/batch = 17.9149s	
12829/26050 (epoch 24.624), train_loss = 0.83910362, grad/param norm = 1.7376e-01, time/batch = 18.3994s	
12830/26050 (epoch 24.626), train_loss = 1.06182525, grad/param norm = 1.9751e-01, time/batch = 16.3172s	
12831/26050 (epoch 24.628), train_loss = 0.93045169, grad/param norm = 1.9532e-01, time/batch = 18.7445s	
12832/26050 (epoch 24.630), train_loss = 1.12066351, grad/param norm = 1.8862e-01, time/batch = 18.1616s	
12833/26050 (epoch 24.631), train_loss = 1.16153654, grad/param norm = 2.0469e-01, time/batch = 16.2845s	
12834/26050 (epoch 24.633), train_loss = 0.88853010, grad/param norm = 1.8696e-01, time/batch = 17.9909s	
12835/26050 (epoch 24.635), train_loss = 0.91579782, grad/param norm = 1.6475e-01, time/batch = 18.9897s	
12836/26050 (epoch 24.637), train_loss = 0.88184689, grad/param norm = 1.7297e-01, time/batch = 18.8205s	
12837/26050 (epoch 24.639), train_loss = 1.07203107, grad/param norm = 1.9565e-01, time/batch = 17.7267s	
12838/26050 (epoch 24.641), train_loss = 0.94972854, grad/param norm = 1.8846e-01, time/batch = 17.8150s	
12839/26050 (epoch 24.643), train_loss = 0.89077037, grad/param norm = 1.6782e-01, time/batch = 18.2288s	
12840/26050 (epoch 24.645), train_loss = 0.95257564, grad/param norm = 1.8973e-01, time/batch = 17.3004s	
12841/26050 (epoch 24.647), train_loss = 0.94167486, grad/param norm = 1.9131e-01, time/batch = 15.9329s	
12842/26050 (epoch 24.649), train_loss = 0.98537395, grad/param norm = 1.9808e-01, time/batch = 18.3087s	
12843/26050 (epoch 24.651), train_loss = 0.94125360, grad/param norm = 1.7754e-01, time/batch = 18.1530s	
12844/26050 (epoch 24.653), train_loss = 0.98134704, grad/param norm = 1.9052e-01, time/batch = 18.2166s	
12845/26050 (epoch 24.655), train_loss = 0.90464095, grad/param norm = 1.7532e-01, time/batch = 16.5535s	
12846/26050 (epoch 24.656), train_loss = 0.84303217, grad/param norm = 1.6266e-01, time/batch = 17.1432s	
12847/26050 (epoch 24.658), train_loss = 1.16026003, grad/param norm = 2.0565e-01, time/batch = 17.0577s	
12848/26050 (epoch 24.660), train_loss = 0.85705470, grad/param norm = 1.8728e-01, time/batch = 18.7232s	
12849/26050 (epoch 24.662), train_loss = 0.97148365, grad/param norm = 1.9699e-01, time/batch = 16.7220s	
12850/26050 (epoch 24.664), train_loss = 0.96301770, grad/param norm = 1.9315e-01, time/batch = 15.9702s	
12851/26050 (epoch 24.666), train_loss = 0.91408025, grad/param norm = 1.9243e-01, time/batch = 19.0605s	
12852/26050 (epoch 24.668), train_loss = 0.82581635, grad/param norm = 2.1293e-01, time/batch = 17.7425s	
12853/26050 (epoch 24.670), train_loss = 1.11230802, grad/param norm = 2.3014e-01, time/batch = 18.8240s	
12854/26050 (epoch 24.672), train_loss = 0.98117969, grad/param norm = 1.8975e-01, time/batch = 17.5739s	
12855/26050 (epoch 24.674), train_loss = 0.90329121, grad/param norm = 1.9680e-01, time/batch = 17.0477s	
12856/26050 (epoch 24.676), train_loss = 1.05880871, grad/param norm = 2.0066e-01, time/batch = 15.1404s	
12857/26050 (epoch 24.678), train_loss = 1.10691484, grad/param norm = 2.1355e-01, time/batch = 18.2327s	
12858/26050 (epoch 24.679), train_loss = 1.16005815, grad/param norm = 2.2014e-01, time/batch = 18.0568s	
12859/26050 (epoch 24.681), train_loss = 0.99263918, grad/param norm = 1.9625e-01, time/batch = 18.0611s	
12860/26050 (epoch 24.683), train_loss = 0.88906055, grad/param norm = 2.6979e-01, time/batch = 18.0733s	
12861/26050 (epoch 24.685), train_loss = 0.95408940, grad/param norm = 1.8523e-01, time/batch = 18.5537s	
12862/26050 (epoch 24.687), train_loss = 0.85795035, grad/param norm = 1.8300e-01, time/batch = 18.0460s	
12863/26050 (epoch 24.689), train_loss = 0.96595720, grad/param norm = 2.0766e-01, time/batch = 18.6525s	
12864/26050 (epoch 24.691), train_loss = 0.79795276, grad/param norm = 1.6930e-01, time/batch = 16.3101s	
12865/26050 (epoch 24.693), train_loss = 0.89145294, grad/param norm = 1.8027e-01, time/batch = 18.3112s	
12866/26050 (epoch 24.695), train_loss = 0.97949188, grad/param norm = 1.8435e-01, time/batch = 18.4697s	
12867/26050 (epoch 24.697), train_loss = 0.89976789, grad/param norm = 1.7754e-01, time/batch = 16.3904s	
12868/26050 (epoch 24.699), train_loss = 1.04613315, grad/param norm = 2.1986e-01, time/batch = 17.5591s	
12869/26050 (epoch 24.701), train_loss = 0.87296100, grad/param norm = 1.5056e-01, time/batch = 19.0685s	
12870/26050 (epoch 24.702), train_loss = 1.08189534, grad/param norm = 1.9600e-01, time/batch = 15.3868s	
12871/26050 (epoch 24.704), train_loss = 1.07140586, grad/param norm = 1.7869e-01, time/batch = 15.3124s	
12872/26050 (epoch 24.706), train_loss = 0.93415997, grad/param norm = 1.9532e-01, time/batch = 17.2244s	
12873/26050 (epoch 24.708), train_loss = 1.05871691, grad/param norm = 2.0438e-01, time/batch = 18.3883s	
12874/26050 (epoch 24.710), train_loss = 1.03272517, grad/param norm = 2.1080e-01, time/batch = 17.5620s	
12875/26050 (epoch 24.712), train_loss = 0.99707850, grad/param norm = 1.9186e-01, time/batch = 17.2870s	
12876/26050 (epoch 24.714), train_loss = 0.85261558, grad/param norm = 1.6948e-01, time/batch = 18.6489s	
12877/26050 (epoch 24.716), train_loss = 1.23251607, grad/param norm = 2.2362e-01, time/batch = 18.4878s	
12878/26050 (epoch 24.718), train_loss = 1.05598363, grad/param norm = 1.9377e-01, time/batch = 17.3151s	
12879/26050 (epoch 24.720), train_loss = 0.98126529, grad/param norm = 2.0153e-01, time/batch = 15.9809s	
12880/26050 (epoch 24.722), train_loss = 0.86070129, grad/param norm = 1.6933e-01, time/batch = 18.6406s	
12881/26050 (epoch 24.724), train_loss = 0.90543726, grad/param norm = 2.0794e-01, time/batch = 17.1304s	
12882/26050 (epoch 24.726), train_loss = 1.03564036, grad/param norm = 2.0062e-01, time/batch = 18.1380s	
12883/26050 (epoch 24.727), train_loss = 1.03594863, grad/param norm = 1.9882e-01, time/batch = 15.9450s	
12884/26050 (epoch 24.729), train_loss = 1.02929941, grad/param norm = 1.8556e-01, time/batch = 18.6399s	
12885/26050 (epoch 24.731), train_loss = 1.02412294, grad/param norm = 1.8894e-01, time/batch = 18.1545s	
12886/26050 (epoch 24.733), train_loss = 0.94745910, grad/param norm = 2.1684e-01, time/batch = 17.9791s	
12887/26050 (epoch 24.735), train_loss = 1.17828927, grad/param norm = 2.1647e-01, time/batch = 18.7217s	
12888/26050 (epoch 24.737), train_loss = 0.91864175, grad/param norm = 1.9064e-01, time/batch = 15.0434s	
12889/26050 (epoch 24.739), train_loss = 1.01227819, grad/param norm = 1.8541e-01, time/batch = 18.4941s	
12890/26050 (epoch 24.741), train_loss = 0.91546548, grad/param norm = 1.8285e-01, time/batch = 14.2270s	
12891/26050 (epoch 24.743), train_loss = 1.00951561, grad/param norm = 2.4469e-01, time/batch = 17.9845s	
12892/26050 (epoch 24.745), train_loss = 0.86609085, grad/param norm = 1.9015e-01, time/batch = 17.7382s	
12893/26050 (epoch 24.747), train_loss = 0.90261571, grad/param norm = 1.7401e-01, time/batch = 18.3278s	
12894/26050 (epoch 24.749), train_loss = 1.10453484, grad/param norm = 2.0864e-01, time/batch = 18.0787s	
12895/26050 (epoch 24.750), train_loss = 0.99505120, grad/param norm = 1.7579e-01, time/batch = 16.3707s	
12896/26050 (epoch 24.752), train_loss = 0.93572185, grad/param norm = 2.3973e-01, time/batch = 17.9883s	
12897/26050 (epoch 24.754), train_loss = 1.01085052, grad/param norm = 2.0651e-01, time/batch = 18.1651s	
12898/26050 (epoch 24.756), train_loss = 0.97516388, grad/param norm = 2.0112e-01, time/batch = 17.0726s	
12899/26050 (epoch 24.758), train_loss = 0.97164931, grad/param norm = 2.2586e-01, time/batch = 16.5492s	
12900/26050 (epoch 24.760), train_loss = 1.16051837, grad/param norm = 2.1011e-01, time/batch = 17.9864s	
12901/26050 (epoch 24.762), train_loss = 0.93431543, grad/param norm = 1.8561e-01, time/batch = 17.7473s	
12902/26050 (epoch 24.764), train_loss = 0.97998070, grad/param norm = 2.2879e-01, time/batch = 17.9786s	
12903/26050 (epoch 24.766), train_loss = 1.04594628, grad/param norm = 2.2456e-01, time/batch = 18.9756s	
12904/26050 (epoch 24.768), train_loss = 0.88220791, grad/param norm = 1.7391e-01, time/batch = 17.9730s	
12905/26050 (epoch 24.770), train_loss = 0.96504778, grad/param norm = 2.1210e-01, time/batch = 16.0675s	
12906/26050 (epoch 24.772), train_loss = 0.98278916, grad/param norm = 1.7349e-01, time/batch = 17.7798s	
12907/26050 (epoch 24.774), train_loss = 0.84745267, grad/param norm = 1.9033e-01, time/batch = 14.8907s	
12908/26050 (epoch 24.775), train_loss = 0.72035027, grad/param norm = 1.8454e-01, time/batch = 17.3994s	
12909/26050 (epoch 24.777), train_loss = 0.93454674, grad/param norm = 1.8708e-01, time/batch = 18.3867s	
12910/26050 (epoch 24.779), train_loss = 0.94718438, grad/param norm = 1.8655e-01, time/batch = 18.8143s	
12911/26050 (epoch 24.781), train_loss = 0.87112201, grad/param norm = 1.8786e-01, time/batch = 18.4810s	
12912/26050 (epoch 24.783), train_loss = 0.84898505, grad/param norm = 1.7096e-01, time/batch = 17.5689s	
12913/26050 (epoch 24.785), train_loss = 0.99889576, grad/param norm = 2.1354e-01, time/batch = 18.4123s	
12914/26050 (epoch 24.787), train_loss = 0.88730511, grad/param norm = 1.8930e-01, time/batch = 18.3254s	
12915/26050 (epoch 24.789), train_loss = 0.90470713, grad/param norm = 1.9610e-01, time/batch = 16.4752s	
12916/26050 (epoch 24.791), train_loss = 0.91318172, grad/param norm = 1.8832e-01, time/batch = 18.4801s	
12917/26050 (epoch 24.793), train_loss = 0.94540514, grad/param norm = 1.9171e-01, time/batch = 17.8996s	
12918/26050 (epoch 24.795), train_loss = 0.80331150, grad/param norm = 1.5327e-01, time/batch = 16.3094s	
12919/26050 (epoch 24.797), train_loss = 0.87935171, grad/param norm = 1.8958e-01, time/batch = 18.0602s	
12920/26050 (epoch 24.798), train_loss = 0.85089521, grad/param norm = 1.8816e-01, time/batch = 18.3983s	
12921/26050 (epoch 24.800), train_loss = 0.85155128, grad/param norm = 1.7031e-01, time/batch = 17.7120s	
12922/26050 (epoch 24.802), train_loss = 0.92268071, grad/param norm = 1.8576e-01, time/batch = 15.1972s	
12923/26050 (epoch 24.804), train_loss = 0.96871790, grad/param norm = 1.9486e-01, time/batch = 17.6509s	
12924/26050 (epoch 24.806), train_loss = 1.04942537, grad/param norm = 1.9709e-01, time/batch = 18.3259s	
12925/26050 (epoch 24.808), train_loss = 0.96593224, grad/param norm = 1.9695e-01, time/batch = 14.7215s	
12926/26050 (epoch 24.810), train_loss = 0.91823517, grad/param norm = 1.9591e-01, time/batch = 17.9691s	
12927/26050 (epoch 24.812), train_loss = 0.84030735, grad/param norm = 1.8642e-01, time/batch = 18.6488s	
12928/26050 (epoch 24.814), train_loss = 0.89226223, grad/param norm = 2.0343e-01, time/batch = 18.8327s	
12929/26050 (epoch 24.816), train_loss = 1.04014800, grad/param norm = 2.1759e-01, time/batch = 17.7345s	
12930/26050 (epoch 24.818), train_loss = 1.06690947, grad/param norm = 2.6820e-01, time/batch = 18.3974s	
12931/26050 (epoch 24.820), train_loss = 0.99264820, grad/param norm = 1.7783e-01, time/batch = 18.9047s	
12932/26050 (epoch 24.821), train_loss = 1.08221944, grad/param norm = 2.0338e-01, time/batch = 16.1443s	
12933/26050 (epoch 24.823), train_loss = 1.13176837, grad/param norm = 2.0006e-01, time/batch = 18.5679s	
12934/26050 (epoch 24.825), train_loss = 0.97132000, grad/param norm = 1.9436e-01, time/batch = 17.8117s	
12935/26050 (epoch 24.827), train_loss = 0.99513191, grad/param norm = 2.0818e-01, time/batch = 15.3894s	
12936/26050 (epoch 24.829), train_loss = 1.04450493, grad/param norm = 2.0005e-01, time/batch = 17.7841s	
12937/26050 (epoch 24.831), train_loss = 1.11717339, grad/param norm = 2.0117e-01, time/batch = 18.5597s	
12938/26050 (epoch 24.833), train_loss = 1.16772732, grad/param norm = 2.2676e-01, time/batch = 16.4700s	
12939/26050 (epoch 24.835), train_loss = 1.15256832, grad/param norm = 2.0271e-01, time/batch = 17.3036s	
12940/26050 (epoch 24.837), train_loss = 0.97754026, grad/param norm = 1.8722e-01, time/batch = 18.3210s	
12941/26050 (epoch 24.839), train_loss = 0.98344677, grad/param norm = 2.1276e-01, time/batch = 16.9917s	
12942/26050 (epoch 24.841), train_loss = 1.10656662, grad/param norm = 1.9325e-01, time/batch = 17.3958s	
12943/26050 (epoch 24.843), train_loss = 0.96073516, grad/param norm = 1.7899e-01, time/batch = 18.4751s	
12944/26050 (epoch 24.845), train_loss = 0.94401824, grad/param norm = 1.8427e-01, time/batch = 18.5611s	
12945/26050 (epoch 24.846), train_loss = 1.06415469, grad/param norm = 2.0517e-01, time/batch = 17.9876s	
12946/26050 (epoch 24.848), train_loss = 0.96214225, grad/param norm = 1.8140e-01, time/batch = 18.4756s	
12947/26050 (epoch 24.850), train_loss = 0.88767497, grad/param norm = 1.7325e-01, time/batch = 18.3929s	
12948/26050 (epoch 24.852), train_loss = 0.98437939, grad/param norm = 1.8550e-01, time/batch = 14.8032s	
12949/26050 (epoch 24.854), train_loss = 0.96313528, grad/param norm = 1.8935e-01, time/batch = 16.2253s	
12950/26050 (epoch 24.856), train_loss = 0.92787262, grad/param norm = 1.9398e-01, time/batch = 18.6511s	
12951/26050 (epoch 24.858), train_loss = 0.91031001, grad/param norm = 1.8396e-01, time/batch = 17.5525s	
12952/26050 (epoch 24.860), train_loss = 1.02230268, grad/param norm = 1.9430e-01, time/batch = 17.1341s	
12953/26050 (epoch 24.862), train_loss = 1.03923738, grad/param norm = 2.0287e-01, time/batch = 16.2998s	
12954/26050 (epoch 24.864), train_loss = 1.01840799, grad/param norm = 2.3992e-01, time/batch = 18.2218s	
12955/26050 (epoch 24.866), train_loss = 0.93517825, grad/param norm = 1.7732e-01, time/batch = 18.4605s	
12956/26050 (epoch 24.868), train_loss = 1.02232290, grad/param norm = 1.8838e-01, time/batch = 17.5622s	
12957/26050 (epoch 24.869), train_loss = 0.87956874, grad/param norm = 1.8917e-01, time/batch = 15.9845s	
12958/26050 (epoch 24.871), train_loss = 0.82204329, grad/param norm = 1.7003e-01, time/batch = 17.4649s	
12959/26050 (epoch 24.873), train_loss = 1.01709874, grad/param norm = 2.1726e-01, time/batch = 17.4872s	
12960/26050 (epoch 24.875), train_loss = 0.96475741, grad/param norm = 1.8841e-01, time/batch = 18.1465s	
12961/26050 (epoch 24.877), train_loss = 0.87484557, grad/param norm = 1.7803e-01, time/batch = 18.2056s	
12962/26050 (epoch 24.879), train_loss = 1.00037155, grad/param norm = 1.7889e-01, time/batch = 18.6248s	
12963/26050 (epoch 24.881), train_loss = 1.07966985, grad/param norm = 2.2539e-01, time/batch = 18.6370s	
12964/26050 (epoch 24.883), train_loss = 1.03128195, grad/param norm = 1.8600e-01, time/batch = 17.4948s	
12965/26050 (epoch 24.885), train_loss = 0.74449217, grad/param norm = 1.6245e-01, time/batch = 18.2362s	
12966/26050 (epoch 24.887), train_loss = 1.03177835, grad/param norm = 2.0346e-01, time/batch = 16.6524s	
12967/26050 (epoch 24.889), train_loss = 0.92540954, grad/param norm = 1.8232e-01, time/batch = 17.8233s	
12968/26050 (epoch 24.891), train_loss = 0.80482450, grad/param norm = 1.7542e-01, time/batch = 15.8914s	
12969/26050 (epoch 24.893), train_loss = 0.85145231, grad/param norm = 1.7863e-01, time/batch = 17.8187s	
12970/26050 (epoch 24.894), train_loss = 0.93048768, grad/param norm = 1.7427e-01, time/batch = 17.2985s	
12971/26050 (epoch 24.896), train_loss = 1.08259801, grad/param norm = 2.1749e-01, time/batch = 18.3299s	
12972/26050 (epoch 24.898), train_loss = 0.91763445, grad/param norm = 1.9513e-01, time/batch = 18.6610s	
12973/26050 (epoch 24.900), train_loss = 1.01185204, grad/param norm = 2.1047e-01, time/batch = 18.3946s	
12974/26050 (epoch 24.902), train_loss = 0.97871930, grad/param norm = 2.0732e-01, time/batch = 17.9902s	
12975/26050 (epoch 24.904), train_loss = 0.94740091, grad/param norm = 1.9763e-01, time/batch = 18.3865s	
12976/26050 (epoch 24.906), train_loss = 0.94074008, grad/param norm = 1.9677e-01, time/batch = 17.5742s	
12977/26050 (epoch 24.908), train_loss = 0.97133581, grad/param norm = 1.7810e-01, time/batch = 15.3927s	
12978/26050 (epoch 24.910), train_loss = 0.93953069, grad/param norm = 1.7540e-01, time/batch = 18.9043s	
12979/26050 (epoch 24.912), train_loss = 1.16865065, grad/param norm = 2.2091e-01, time/batch = 17.0846s	
12980/26050 (epoch 24.914), train_loss = 1.34040825, grad/param norm = 2.3999e-01, time/batch = 14.8755s	
12981/26050 (epoch 24.916), train_loss = 1.07486037, grad/param norm = 2.2074e-01, time/batch = 18.3086s	
12982/26050 (epoch 24.917), train_loss = 0.98467142, grad/param norm = 2.1357e-01, time/batch = 18.9043s	
12983/26050 (epoch 24.919), train_loss = 1.02778365, grad/param norm = 2.0345e-01, time/batch = 16.7269s	
12984/26050 (epoch 24.921), train_loss = 0.93211702, grad/param norm = 2.0079e-01, time/batch = 15.8115s	
12985/26050 (epoch 24.923), train_loss = 0.98758058, grad/param norm = 1.8580e-01, time/batch = 17.8150s	
12986/26050 (epoch 24.925), train_loss = 0.97242285, grad/param norm = 1.8438e-01, time/batch = 17.8201s	
12987/26050 (epoch 24.927), train_loss = 0.87879733, grad/param norm = 1.5540e-01, time/batch = 17.3991s	
12988/26050 (epoch 24.929), train_loss = 0.82858608, grad/param norm = 1.6851e-01, time/batch = 18.1465s	
12989/26050 (epoch 24.931), train_loss = 1.13454646, grad/param norm = 2.1475e-01, time/batch = 18.3173s	
12990/26050 (epoch 24.933), train_loss = 0.93522217, grad/param norm = 1.9050e-01, time/batch = 17.6452s	
12991/26050 (epoch 24.935), train_loss = 0.94954839, grad/param norm = 1.8995e-01, time/batch = 18.0763s	
12992/26050 (epoch 24.937), train_loss = 1.06255708, grad/param norm = 1.8174e-01, time/batch = 18.4984s	
12993/26050 (epoch 24.939), train_loss = 0.89586546, grad/param norm = 1.6776e-01, time/batch = 17.8990s	
12994/26050 (epoch 24.940), train_loss = 0.93208035, grad/param norm = 1.7971e-01, time/batch = 17.6360s	
12995/26050 (epoch 24.942), train_loss = 0.94949776, grad/param norm = 1.8567e-01, time/batch = 18.7925s	
12996/26050 (epoch 24.944), train_loss = 0.92740170, grad/param norm = 1.6941e-01, time/batch = 17.3232s	
12997/26050 (epoch 24.946), train_loss = 1.08792342, grad/param norm = 1.8913e-01, time/batch = 15.5499s	
12998/26050 (epoch 24.948), train_loss = 0.83865157, grad/param norm = 1.7976e-01, time/batch = 15.5664s	
12999/26050 (epoch 24.950), train_loss = 0.93932880, grad/param norm = 1.8675e-01, time/batch = 18.7304s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch24.95_1.7335.t7	
13000/26050 (epoch 24.952), train_loss = 1.04517387, grad/param norm = 1.9073e-01, time/batch = 23.7303s	
13001/26050 (epoch 24.954), train_loss = 1.53925726, grad/param norm = 2.7180e-01, time/batch = 18.2198s	
13002/26050 (epoch 24.956), train_loss = 0.97145476, grad/param norm = 2.0690e-01, time/batch = 16.8048s	
13003/26050 (epoch 24.958), train_loss = 0.90189976, grad/param norm = 1.8813e-01, time/batch = 17.8967s	
13004/26050 (epoch 24.960), train_loss = 1.01620559, grad/param norm = 2.0227e-01, time/batch = 16.3975s	
13005/26050 (epoch 24.962), train_loss = 0.96168038, grad/param norm = 1.8729e-01, time/batch = 18.2251s	
13006/26050 (epoch 24.964), train_loss = 0.98376807, grad/param norm = 1.9198e-01, time/batch = 17.1490s	
13007/26050 (epoch 24.965), train_loss = 0.88608093, grad/param norm = 1.9522e-01, time/batch = 18.8916s	
13008/26050 (epoch 24.967), train_loss = 1.28971853, grad/param norm = 2.0650e-01, time/batch = 18.8228s	
13009/26050 (epoch 24.969), train_loss = 1.00667619, grad/param norm = 2.1755e-01, time/batch = 17.2113s	
13010/26050 (epoch 24.971), train_loss = 0.92829050, grad/param norm = 1.6834e-01, time/batch = 17.8148s	
13011/26050 (epoch 24.973), train_loss = 0.97555189, grad/param norm = 1.7831e-01, time/batch = 19.0599s	
13012/26050 (epoch 24.975), train_loss = 1.01363237, grad/param norm = 1.9798e-01, time/batch = 15.5552s	
13013/26050 (epoch 24.977), train_loss = 0.97825366, grad/param norm = 1.5898e-01, time/batch = 17.8116s	
13014/26050 (epoch 24.979), train_loss = 0.80242181, grad/param norm = 1.7997e-01, time/batch = 17.9119s	
13015/26050 (epoch 24.981), train_loss = 1.11032754, grad/param norm = 1.9654e-01, time/batch = 18.1507s	
13016/26050 (epoch 24.983), train_loss = 1.05945356, grad/param norm = 2.0551e-01, time/batch = 16.9086s	
13017/26050 (epoch 24.985), train_loss = 1.03370168, grad/param norm = 1.9918e-01, time/batch = 18.5774s	
13018/26050 (epoch 24.987), train_loss = 1.08981608, grad/param norm = 1.9964e-01, time/batch = 15.3980s	
13019/26050 (epoch 24.988), train_loss = 1.03350014, grad/param norm = 1.8375e-01, time/batch = 18.8940s	
13020/26050 (epoch 24.990), train_loss = 0.86545969, grad/param norm = 1.5934e-01, time/batch = 14.9561s	
13021/26050 (epoch 24.992), train_loss = 1.12561771, grad/param norm = 1.9377e-01, time/batch = 18.0762s	
13022/26050 (epoch 24.994), train_loss = 0.95227482, grad/param norm = 2.2598e-01, time/batch = 18.9893s	
13023/26050 (epoch 24.996), train_loss = 0.92414867, grad/param norm = 2.1461e-01, time/batch = 15.3135s	
13024/26050 (epoch 24.998), train_loss = 0.98737852, grad/param norm = 1.8490e-01, time/batch = 18.1302s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
13025/26050 (epoch 25.000), train_loss = 0.93473942, grad/param norm = 2.1041e-01, time/batch = 18.7264s	
13026/26050 (epoch 25.002), train_loss = 1.03168100, grad/param norm = 2.1192e-01, time/batch = 17.3149s	
13027/26050 (epoch 25.004), train_loss = 0.88998120, grad/param norm = 1.9301e-01, time/batch = 18.0635s	
13028/26050 (epoch 25.006), train_loss = 0.92822506, grad/param norm = 2.0099e-01, time/batch = 18.0633s	
13029/26050 (epoch 25.008), train_loss = 0.92298410, grad/param norm = 1.9605e-01, time/batch = 18.7376s	
13030/26050 (epoch 25.010), train_loss = 0.92416130, grad/param norm = 1.8715e-01, time/batch = 15.7390s	
13031/26050 (epoch 25.012), train_loss = 0.97638632, grad/param norm = 1.7687e-01, time/batch = 15.6367s	
13032/26050 (epoch 25.013), train_loss = 1.25692809, grad/param norm = 2.1460e-01, time/batch = 16.1982s	
13033/26050 (epoch 25.015), train_loss = 0.94858641, grad/param norm = 1.8389e-01, time/batch = 17.9756s	
13034/26050 (epoch 25.017), train_loss = 0.98641430, grad/param norm = 1.8410e-01, time/batch = 18.8751s	
13035/26050 (epoch 25.019), train_loss = 0.86423309, grad/param norm = 1.7628e-01, time/batch = 17.6575s	
13036/26050 (epoch 25.021), train_loss = 1.05499073, grad/param norm = 1.8518e-01, time/batch = 18.0611s	
13037/26050 (epoch 25.023), train_loss = 0.80427134, grad/param norm = 1.7908e-01, time/batch = 17.2373s	
13038/26050 (epoch 25.025), train_loss = 0.96723724, grad/param norm = 1.7923e-01, time/batch = 18.4940s	
13039/26050 (epoch 25.027), train_loss = 0.80388736, grad/param norm = 1.8499e-01, time/batch = 16.2949s	
13040/26050 (epoch 25.029), train_loss = 0.99470647, grad/param norm = 1.7772e-01, time/batch = 17.5001s	
13041/26050 (epoch 25.031), train_loss = 1.11061727, grad/param norm = 2.2194e-01, time/batch = 18.2428s	
13042/26050 (epoch 25.033), train_loss = 0.98871879, grad/param norm = 1.9283e-01, time/batch = 18.7485s	
13043/26050 (epoch 25.035), train_loss = 0.99950173, grad/param norm = 1.7536e-01, time/batch = 17.4779s	
13044/26050 (epoch 25.036), train_loss = 0.85614570, grad/param norm = 2.0592e-01, time/batch = 17.9075s	
13045/26050 (epoch 25.038), train_loss = 0.78927080, grad/param norm = 1.7742e-01, time/batch = 17.8340s	
13046/26050 (epoch 25.040), train_loss = 0.96087845, grad/param norm = 1.9716e-01, time/batch = 19.0899s	
13047/26050 (epoch 25.042), train_loss = 0.81993008, grad/param norm = 1.8971e-01, time/batch = 17.9593s	
13048/26050 (epoch 25.044), train_loss = 1.04262493, grad/param norm = 1.8308e-01, time/batch = 17.7251s	
13049/26050 (epoch 25.046), train_loss = 0.80414415, grad/param norm = 1.8131e-01, time/batch = 18.9123s	
13050/26050 (epoch 25.048), train_loss = 0.99133283, grad/param norm = 1.8236e-01, time/batch = 16.7230s	
13051/26050 (epoch 25.050), train_loss = 0.91963410, grad/param norm = 1.8579e-01, time/batch = 16.2755s	
13052/26050 (epoch 25.052), train_loss = 0.89513607, grad/param norm = 1.9856e-01, time/batch = 18.1525s	
13053/26050 (epoch 25.054), train_loss = 0.81317304, grad/param norm = 1.7577e-01, time/batch = 18.2362s	
13054/26050 (epoch 25.056), train_loss = 0.78714583, grad/param norm = 1.6099e-01, time/batch = 16.7205s	
13055/26050 (epoch 25.058), train_loss = 0.93881838, grad/param norm = 1.6600e-01, time/batch = 15.6327s	
13056/26050 (epoch 25.060), train_loss = 1.03805612, grad/param norm = 1.9465e-01, time/batch = 18.4879s	
13057/26050 (epoch 25.061), train_loss = 0.87124371, grad/param norm = 1.7484e-01, time/batch = 17.2293s	
13058/26050 (epoch 25.063), train_loss = 1.00396876, grad/param norm = 1.8619e-01, time/batch = 17.6670s	
13059/26050 (epoch 25.065), train_loss = 0.78130408, grad/param norm = 1.5456e-01, time/batch = 18.7351s	
13060/26050 (epoch 25.067), train_loss = 0.95644106, grad/param norm = 1.9332e-01, time/batch = 17.6438s	
13061/26050 (epoch 25.069), train_loss = 1.01906268, grad/param norm = 2.3149e-01, time/batch = 17.8896s	
13062/26050 (epoch 25.071), train_loss = 1.03015029, grad/param norm = 1.9415e-01, time/batch = 18.6626s	
13063/26050 (epoch 25.073), train_loss = 1.14079771, grad/param norm = 2.0822e-01, time/batch = 15.3183s	
13064/26050 (epoch 25.075), train_loss = 0.89484017, grad/param norm = 1.8536e-01, time/batch = 18.1378s	
13065/26050 (epoch 25.077), train_loss = 0.93156542, grad/param norm = 2.0648e-01, time/batch = 18.2423s	
13066/26050 (epoch 25.079), train_loss = 0.97624554, grad/param norm = 1.9004e-01, time/batch = 17.6555s	
13067/26050 (epoch 25.081), train_loss = 0.93038782, grad/param norm = 1.9237e-01, time/batch = 17.2336s	
13068/26050 (epoch 25.083), train_loss = 1.07009825, grad/param norm = 1.8471e-01, time/batch = 17.1330s	
13069/26050 (epoch 25.084), train_loss = 0.98866463, grad/param norm = 2.1415e-01, time/batch = 16.9866s	
13070/26050 (epoch 25.086), train_loss = 1.12663642, grad/param norm = 2.1721e-01, time/batch = 16.3707s	
13071/26050 (epoch 25.088), train_loss = 0.92027668, grad/param norm = 1.9584e-01, time/batch = 18.8852s	
13072/26050 (epoch 25.090), train_loss = 0.96939824, grad/param norm = 1.8688e-01, time/batch = 18.2156s	
13073/26050 (epoch 25.092), train_loss = 1.02587969, grad/param norm = 1.7396e-01, time/batch = 17.8146s	
13074/26050 (epoch 25.094), train_loss = 0.89148057, grad/param norm = 2.0001e-01, time/batch = 17.0665s	
13075/26050 (epoch 25.096), train_loss = 0.96635712, grad/param norm = 1.7326e-01, time/batch = 15.5744s	
13076/26050 (epoch 25.098), train_loss = 0.91227446, grad/param norm = 1.7458e-01, time/batch = 15.5455s	
13077/26050 (epoch 25.100), train_loss = 0.86998650, grad/param norm = 1.8464e-01, time/batch = 17.9765s	
13078/26050 (epoch 25.102), train_loss = 1.02380059, grad/param norm = 1.9636e-01, time/batch = 18.3955s	
13079/26050 (epoch 25.104), train_loss = 0.92953023, grad/param norm = 1.8351e-01, time/batch = 19.0648s	
13080/26050 (epoch 25.106), train_loss = 0.96530338, grad/param norm = 1.9916e-01, time/batch = 18.2262s	
13081/26050 (epoch 25.107), train_loss = 0.78596588, grad/param norm = 1.8181e-01, time/batch = 18.1364s	
13082/26050 (epoch 25.109), train_loss = 0.89294684, grad/param norm = 1.8854e-01, time/batch = 16.7242s	
13083/26050 (epoch 25.111), train_loss = 1.11393133, grad/param norm = 1.9816e-01, time/batch = 18.4827s	
13084/26050 (epoch 25.113), train_loss = 0.91997718, grad/param norm = 1.9064e-01, time/batch = 18.0637s	
13085/26050 (epoch 25.115), train_loss = 1.04929722, grad/param norm = 1.9640e-01, time/batch = 18.3939s	
13086/26050 (epoch 25.117), train_loss = 0.97387068, grad/param norm = 1.9842e-01, time/batch = 17.4098s	
13087/26050 (epoch 25.119), train_loss = 0.81041068, grad/param norm = 1.7601e-01, time/batch = 15.2127s	
13088/26050 (epoch 25.121), train_loss = 0.97313240, grad/param norm = 1.8453e-01, time/batch = 17.5604s	
13089/26050 (epoch 25.123), train_loss = 0.87705605, grad/param norm = 1.9282e-01, time/batch = 18.9848s	
13090/26050 (epoch 25.125), train_loss = 0.83183031, grad/param norm = 1.6427e-01, time/batch = 18.6615s	
13091/26050 (epoch 25.127), train_loss = 0.78787505, grad/param norm = 1.7740e-01, time/batch = 17.0707s	
13092/26050 (epoch 25.129), train_loss = 0.80587224, grad/param norm = 1.7342e-01, time/batch = 18.3370s	
13093/26050 (epoch 25.131), train_loss = 0.91861012, grad/param norm = 1.9346e-01, time/batch = 15.8839s	
13094/26050 (epoch 25.132), train_loss = 0.93767601, grad/param norm = 1.7219e-01, time/batch = 17.2266s	
13095/26050 (epoch 25.134), train_loss = 0.98163792, grad/param norm = 2.1904e-01, time/batch = 0.7131s	
13096/26050 (epoch 25.136), train_loss = 0.95192926, grad/param norm = 1.8770e-01, time/batch = 0.6434s	
13097/26050 (epoch 25.138), train_loss = 0.72354468, grad/param norm = 1.6219e-01, time/batch = 0.6419s	
13098/26050 (epoch 25.140), train_loss = 0.81054385, grad/param norm = 1.8276e-01, time/batch = 0.6423s	
13099/26050 (epoch 25.142), train_loss = 0.83654504, grad/param norm = 1.7974e-01, time/batch = 0.6435s	
13100/26050 (epoch 25.144), train_loss = 0.74952036, grad/param norm = 1.7211e-01, time/batch = 0.6695s	
13101/26050 (epoch 25.146), train_loss = 0.70175604, grad/param norm = 1.5810e-01, time/batch = 0.6424s	
13102/26050 (epoch 25.148), train_loss = 0.74361533, grad/param norm = 1.4275e-01, time/batch = 0.7467s	
13103/26050 (epoch 25.150), train_loss = 0.90083987, grad/param norm = 1.8610e-01, time/batch = 0.9441s	
13104/26050 (epoch 25.152), train_loss = 1.10774976, grad/param norm = 2.2773e-01, time/batch = 0.9544s	
13105/26050 (epoch 25.154), train_loss = 0.76163064, grad/param norm = 1.9141e-01, time/batch = 0.9600s	
13106/26050 (epoch 25.155), train_loss = 0.80485368, grad/param norm = 1.8970e-01, time/batch = 0.9476s	
13107/26050 (epoch 25.157), train_loss = 0.92427796, grad/param norm = 2.0787e-01, time/batch = 0.9924s	
13108/26050 (epoch 25.159), train_loss = 0.96076158, grad/param norm = 2.2444e-01, time/batch = 1.7617s	
13109/26050 (epoch 25.161), train_loss = 0.96240174, grad/param norm = 1.9297e-01, time/batch = 1.8079s	
13110/26050 (epoch 25.163), train_loss = 0.79069297, grad/param norm = 1.7918e-01, time/batch = 5.5776s	
13111/26050 (epoch 25.165), train_loss = 0.73629075, grad/param norm = 1.9071e-01, time/batch = 17.3897s	
13112/26050 (epoch 25.167), train_loss = 1.05907368, grad/param norm = 2.0751e-01, time/batch = 18.3901s	
13113/26050 (epoch 25.169), train_loss = 0.96353990, grad/param norm = 1.9651e-01, time/batch = 18.0739s	
13114/26050 (epoch 25.171), train_loss = 0.79804121, grad/param norm = 1.7095e-01, time/batch = 16.6548s	
13115/26050 (epoch 25.173), train_loss = 0.90238966, grad/param norm = 2.0813e-01, time/batch = 17.3975s	
13116/26050 (epoch 25.175), train_loss = 0.91378052, grad/param norm = 1.7464e-01, time/batch = 17.5730s	
13117/26050 (epoch 25.177), train_loss = 1.03034624, grad/param norm = 1.8629e-01, time/batch = 18.4907s	
13118/26050 (epoch 25.179), train_loss = 0.70654853, grad/param norm = 1.5810e-01, time/batch = 17.6613s	
13119/26050 (epoch 25.180), train_loss = 1.14075756, grad/param norm = 1.9315e-01, time/batch = 18.0721s	
13120/26050 (epoch 25.182), train_loss = 1.18353550, grad/param norm = 2.1441e-01, time/batch = 16.6561s	
13121/26050 (epoch 25.184), train_loss = 0.97874543, grad/param norm = 1.7818e-01, time/batch = 15.2371s	
13122/26050 (epoch 25.186), train_loss = 0.78485180, grad/param norm = 1.7483e-01, time/batch = 18.5741s	
13123/26050 (epoch 25.188), train_loss = 0.96876646, grad/param norm = 2.0167e-01, time/batch = 17.9737s	
13124/26050 (epoch 25.190), train_loss = 0.97849257, grad/param norm = 1.8566e-01, time/batch = 17.9876s	
13125/26050 (epoch 25.192), train_loss = 0.98493854, grad/param norm = 1.6434e-01, time/batch = 18.4031s	
13126/26050 (epoch 25.194), train_loss = 0.99324586, grad/param norm = 1.9808e-01, time/batch = 16.3009s	
13127/26050 (epoch 25.196), train_loss = 1.02006052, grad/param norm = 1.9508e-01, time/batch = 16.3005s	
13128/26050 (epoch 25.198), train_loss = 0.87733050, grad/param norm = 1.7742e-01, time/batch = 17.7206s	
13129/26050 (epoch 25.200), train_loss = 0.85297921, grad/param norm = 1.8062e-01, time/batch = 16.4804s	
13130/26050 (epoch 25.202), train_loss = 0.96273216, grad/param norm = 1.8381e-01, time/batch = 15.0620s	
13131/26050 (epoch 25.203), train_loss = 1.06431646, grad/param norm = 1.9156e-01, time/batch = 15.2603s	
13132/26050 (epoch 25.205), train_loss = 0.89865362, grad/param norm = 1.7822e-01, time/batch = 14.6196s	
13133/26050 (epoch 25.207), train_loss = 0.87062487, grad/param norm = 1.7354e-01, time/batch = 14.1516s	
13134/26050 (epoch 25.209), train_loss = 1.01459660, grad/param norm = 2.0618e-01, time/batch = 14.2485s	
13135/26050 (epoch 25.211), train_loss = 0.78768102, grad/param norm = 1.8218e-01, time/batch = 17.2495s	
13136/26050 (epoch 25.213), train_loss = 0.98403102, grad/param norm = 1.9897e-01, time/batch = 17.3981s	
13137/26050 (epoch 25.215), train_loss = 0.93461252, grad/param norm = 2.0848e-01, time/batch = 17.7312s	
13138/26050 (epoch 25.217), train_loss = 0.91345693, grad/param norm = 1.7805e-01, time/batch = 15.7317s	
13139/26050 (epoch 25.219), train_loss = 0.91950304, grad/param norm = 1.9308e-01, time/batch = 18.8165s	
13140/26050 (epoch 25.221), train_loss = 0.86198101, grad/param norm = 2.0326e-01, time/batch = 18.7395s	
13141/26050 (epoch 25.223), train_loss = 1.00689661, grad/param norm = 2.0669e-01, time/batch = 17.8123s	
13142/26050 (epoch 25.225), train_loss = 0.86017887, grad/param norm = 1.9618e-01, time/batch = 17.8128s	
13143/26050 (epoch 25.226), train_loss = 0.99270019, grad/param norm = 2.1687e-01, time/batch = 18.4770s	
13144/26050 (epoch 25.228), train_loss = 1.08511782, grad/param norm = 1.9159e-01, time/batch = 16.9139s	
13145/26050 (epoch 25.230), train_loss = 0.97505137, grad/param norm = 1.8647e-01, time/batch = 18.4017s	
13146/26050 (epoch 25.232), train_loss = 1.03981340, grad/param norm = 2.1782e-01, time/batch = 18.3319s	
13147/26050 (epoch 25.234), train_loss = 0.84730539, grad/param norm = 2.0890e-01, time/batch = 18.1486s	
13148/26050 (epoch 25.236), train_loss = 1.04211794, grad/param norm = 2.0158e-01, time/batch = 17.0755s	
13149/26050 (epoch 25.238), train_loss = 0.82258104, grad/param norm = 2.0308e-01, time/batch = 14.7306s	
13150/26050 (epoch 25.240), train_loss = 0.96064922, grad/param norm = 2.0085e-01, time/batch = 17.5970s	
13151/26050 (epoch 25.242), train_loss = 0.92567116, grad/param norm = 1.7381e-01, time/batch = 17.9841s	
13152/26050 (epoch 25.244), train_loss = 0.96345923, grad/param norm = 2.0066e-01, time/batch = 18.3132s	
13153/26050 (epoch 25.246), train_loss = 0.87303303, grad/param norm = 1.7652e-01, time/batch = 18.5681s	
13154/26050 (epoch 25.248), train_loss = 0.95624102, grad/param norm = 1.8297e-01, time/batch = 18.3152s	
13155/26050 (epoch 25.250), train_loss = 0.93749346, grad/param norm = 2.0731e-01, time/batch = 15.7305s	
13156/26050 (epoch 25.251), train_loss = 0.90270081, grad/param norm = 1.7457e-01, time/batch = 16.7848s	
13157/26050 (epoch 25.253), train_loss = 0.83783019, grad/param norm = 1.7667e-01, time/batch = 17.9138s	
13158/26050 (epoch 25.255), train_loss = 1.09847552, grad/param norm = 1.9146e-01, time/batch = 18.8142s	
13159/26050 (epoch 25.257), train_loss = 0.94210285, grad/param norm = 1.9266e-01, time/batch = 17.4926s	
13160/26050 (epoch 25.259), train_loss = 1.05461561, grad/param norm = 1.9441e-01, time/batch = 18.7397s	
13161/26050 (epoch 25.261), train_loss = 0.85396351, grad/param norm = 1.9631e-01, time/batch = 16.4851s	
13162/26050 (epoch 25.263), train_loss = 1.03864098, grad/param norm = 2.1116e-01, time/batch = 18.5594s	
13163/26050 (epoch 25.265), train_loss = 1.09677831, grad/param norm = 2.1035e-01, time/batch = 16.0564s	
13164/26050 (epoch 25.267), train_loss = 1.05771128, grad/param norm = 1.7350e-01, time/batch = 15.9088s	
13165/26050 (epoch 25.269), train_loss = 1.06915668, grad/param norm = 2.0824e-01, time/batch = 15.6471s	
13166/26050 (epoch 25.271), train_loss = 1.00046704, grad/param norm = 1.9010e-01, time/batch = 16.2767s	
13167/26050 (epoch 25.273), train_loss = 0.89942068, grad/param norm = 2.2316e-01, time/batch = 17.8075s	
13168/26050 (epoch 25.274), train_loss = 0.92525737, grad/param norm = 1.7020e-01, time/batch = 18.0410s	
13169/26050 (epoch 25.276), train_loss = 0.90144267, grad/param norm = 1.8696e-01, time/batch = 17.8857s	
13170/26050 (epoch 25.278), train_loss = 1.06496599, grad/param norm = 1.8959e-01, time/batch = 17.9685s	
13171/26050 (epoch 25.280), train_loss = 0.94837508, grad/param norm = 1.8298e-01, time/batch = 17.3150s	
13172/26050 (epoch 25.282), train_loss = 0.98812724, grad/param norm = 1.9504e-01, time/batch = 18.4717s	
13173/26050 (epoch 25.284), train_loss = 0.92875062, grad/param norm = 1.8109e-01, time/batch = 18.3948s	
13174/26050 (epoch 25.286), train_loss = 0.95817690, grad/param norm = 1.9848e-01, time/batch = 18.5543s	
13175/26050 (epoch 25.288), train_loss = 0.81339676, grad/param norm = 1.8130e-01, time/batch = 17.8158s	
13176/26050 (epoch 25.290), train_loss = 0.96966902, grad/param norm = 2.0916e-01, time/batch = 18.8342s	
13177/26050 (epoch 25.292), train_loss = 0.86564346, grad/param norm = 1.6504e-01, time/batch = 17.7513s	
13178/26050 (epoch 25.294), train_loss = 0.95293234, grad/param norm = 2.0278e-01, time/batch = 16.0617s	
13179/26050 (epoch 25.296), train_loss = 1.06636852, grad/param norm = 2.0284e-01, time/batch = 16.3045s	
13180/26050 (epoch 25.298), train_loss = 0.97787258, grad/param norm = 1.9272e-01, time/batch = 17.9937s	
13181/26050 (epoch 25.299), train_loss = 0.77984615, grad/param norm = 1.5303e-01, time/batch = 17.4009s	
13182/26050 (epoch 25.301), train_loss = 0.81764731, grad/param norm = 1.9674e-01, time/batch = 17.3067s	
13183/26050 (epoch 25.303), train_loss = 0.96171062, grad/param norm = 2.0672e-01, time/batch = 18.9674s	
13184/26050 (epoch 25.305), train_loss = 0.77773263, grad/param norm = 1.8067e-01, time/batch = 18.3212s	
13185/26050 (epoch 25.307), train_loss = 0.88294232, grad/param norm = 1.8656e-01, time/batch = 15.0957s	
13186/26050 (epoch 25.309), train_loss = 0.93322060, grad/param norm = 1.8202e-01, time/batch = 18.3125s	
13187/26050 (epoch 25.311), train_loss = 1.03275935, grad/param norm = 2.1796e-01, time/batch = 17.5670s	
13188/26050 (epoch 25.313), train_loss = 0.94889320, grad/param norm = 2.1189e-01, time/batch = 18.2341s	
13189/26050 (epoch 25.315), train_loss = 1.03396309, grad/param norm = 1.8867e-01, time/batch = 18.2367s	
13190/26050 (epoch 25.317), train_loss = 0.97828547, grad/param norm = 1.9767e-01, time/batch = 18.7429s	
13191/26050 (epoch 25.319), train_loss = 0.87155047, grad/param norm = 1.7386e-01, time/batch = 17.9934s	
13192/26050 (epoch 25.321), train_loss = 0.93435839, grad/param norm = 1.8165e-01, time/batch = 18.3154s	
13193/26050 (epoch 25.322), train_loss = 1.00388533, grad/param norm = 1.8815e-01, time/batch = 18.9006s	
13194/26050 (epoch 25.324), train_loss = 0.76413042, grad/param norm = 1.6465e-01, time/batch = 18.6703s	
13195/26050 (epoch 25.326), train_loss = 1.08379119, grad/param norm = 2.0717e-01, time/batch = 18.1379s	
13196/26050 (epoch 25.328), train_loss = 0.97487153, grad/param norm = 1.8354e-01, time/batch = 17.6507s	
13197/26050 (epoch 25.330), train_loss = 0.81586163, grad/param norm = 1.8348e-01, time/batch = 16.9013s	
13198/26050 (epoch 25.332), train_loss = 1.01463513, grad/param norm = 2.0108e-01, time/batch = 17.7994s	
13199/26050 (epoch 25.334), train_loss = 0.88479710, grad/param norm = 1.8220e-01, time/batch = 14.4641s	
13200/26050 (epoch 25.336), train_loss = 0.90270568, grad/param norm = 1.8578e-01, time/batch = 17.8189s	
13201/26050 (epoch 25.338), train_loss = 0.83686989, grad/param norm = 1.7077e-01, time/batch = 18.5600s	
13202/26050 (epoch 25.340), train_loss = 1.02738862, grad/param norm = 2.1453e-01, time/batch = 18.2198s	
13203/26050 (epoch 25.342), train_loss = 1.03261865, grad/param norm = 1.9212e-01, time/batch = 17.7457s	
13204/26050 (epoch 25.344), train_loss = 0.86944481, grad/param norm = 1.9280e-01, time/batch = 16.5450s	
13205/26050 (epoch 25.345), train_loss = 0.93681023, grad/param norm = 1.8933e-01, time/batch = 17.6443s	
13206/26050 (epoch 25.347), train_loss = 1.08136418, grad/param norm = 1.9823e-01, time/batch = 18.3156s	
13207/26050 (epoch 25.349), train_loss = 0.99650985, grad/param norm = 2.0006e-01, time/batch = 18.0517s	
13208/26050 (epoch 25.351), train_loss = 1.00351018, grad/param norm = 1.8779e-01, time/batch = 15.1331s	
13209/26050 (epoch 25.353), train_loss = 0.96785823, grad/param norm = 1.9432e-01, time/batch = 18.4801s	
13210/26050 (epoch 25.355), train_loss = 0.99593466, grad/param norm = 2.0612e-01, time/batch = 17.8228s	
13211/26050 (epoch 25.357), train_loss = 0.88904781, grad/param norm = 1.7120e-01, time/batch = 17.9983s	
13212/26050 (epoch 25.359), train_loss = 1.06735158, grad/param norm = 2.2586e-01, time/batch = 25.1181s	
13213/26050 (epoch 25.361), train_loss = 0.87591252, grad/param norm = 1.7220e-01, time/batch = 30.2457s	
13214/26050 (epoch 25.363), train_loss = 1.02678088, grad/param norm = 1.7989e-01, time/batch = 15.9108s	
13215/26050 (epoch 25.365), train_loss = 0.92105916, grad/param norm = 1.6979e-01, time/batch = 18.4804s	
13216/26050 (epoch 25.367), train_loss = 1.00815592, grad/param norm = 1.8147e-01, time/batch = 17.9701s	
13217/26050 (epoch 25.369), train_loss = 0.88447414, grad/param norm = 1.8964e-01, time/batch = 17.6595s	
13218/26050 (epoch 25.370), train_loss = 0.84700020, grad/param norm = 1.6916e-01, time/batch = 18.2524s	
13219/26050 (epoch 25.372), train_loss = 0.97191662, grad/param norm = 1.9719e-01, time/batch = 18.0922s	
13220/26050 (epoch 25.374), train_loss = 1.08120127, grad/param norm = 1.9067e-01, time/batch = 18.6575s	
13221/26050 (epoch 25.376), train_loss = 1.13529330, grad/param norm = 2.1924e-01, time/batch = 17.3155s	
13222/26050 (epoch 25.378), train_loss = 0.89164186, grad/param norm = 1.7062e-01, time/batch = 15.9640s	
13223/26050 (epoch 25.380), train_loss = 1.12678996, grad/param norm = 2.3083e-01, time/batch = 18.3917s	
13224/26050 (epoch 25.382), train_loss = 1.24801844, grad/param norm = 2.5546e-01, time/batch = 17.1463s	
13225/26050 (epoch 25.384), train_loss = 0.92398230, grad/param norm = 1.9360e-01, time/batch = 18.3914s	
13226/26050 (epoch 25.386), train_loss = 1.04361486, grad/param norm = 2.4344e-01, time/batch = 17.6478s	
13227/26050 (epoch 25.388), train_loss = 0.97707232, grad/param norm = 2.0161e-01, time/batch = 16.4008s	
13228/26050 (epoch 25.390), train_loss = 0.90409686, grad/param norm = 1.7456e-01, time/batch = 15.6837s	
13229/26050 (epoch 25.392), train_loss = 0.84824810, grad/param norm = 1.8290e-01, time/batch = 18.2237s	
13230/26050 (epoch 25.393), train_loss = 1.00555450, grad/param norm = 2.0288e-01, time/batch = 18.8128s	
13231/26050 (epoch 25.395), train_loss = 1.04189860, grad/param norm = 2.4011e-01, time/batch = 16.9881s	
13232/26050 (epoch 25.397), train_loss = 1.03249542, grad/param norm = 2.1034e-01, time/batch = 16.9661s	
13233/26050 (epoch 25.399), train_loss = 0.91288394, grad/param norm = 2.1216e-01, time/batch = 17.9054s	
13234/26050 (epoch 25.401), train_loss = 0.99822683, grad/param norm = 2.2170e-01, time/batch = 15.0563s	
13235/26050 (epoch 25.403), train_loss = 0.99219477, grad/param norm = 2.1451e-01, time/batch = 18.3874s	
13236/26050 (epoch 25.405), train_loss = 0.96645287, grad/param norm = 1.9141e-01, time/batch = 17.8898s	
13237/26050 (epoch 25.407), train_loss = 1.10446012, grad/param norm = 2.0877e-01, time/batch = 18.1456s	
13238/26050 (epoch 25.409), train_loss = 1.10788093, grad/param norm = 2.2617e-01, time/batch = 17.5605s	
13239/26050 (epoch 25.411), train_loss = 1.03415560, grad/param norm = 2.1690e-01, time/batch = 18.4035s	
13240/26050 (epoch 25.413), train_loss = 1.12729017, grad/param norm = 1.9320e-01, time/batch = 17.8352s	
13241/26050 (epoch 25.415), train_loss = 1.10452075, grad/param norm = 2.1803e-01, time/batch = 17.9884s	
13242/26050 (epoch 25.417), train_loss = 1.18937461, grad/param norm = 2.3141e-01, time/batch = 16.4740s	
13243/26050 (epoch 25.418), train_loss = 1.06378152, grad/param norm = 2.2481e-01, time/batch = 17.7185s	
13244/26050 (epoch 25.420), train_loss = 0.83138110, grad/param norm = 1.7029e-01, time/batch = 15.6149s	
13245/26050 (epoch 25.422), train_loss = 0.82829940, grad/param norm = 1.7934e-01, time/batch = 18.2933s	
13246/26050 (epoch 25.424), train_loss = 1.09455552, grad/param norm = 2.0556e-01, time/batch = 18.2169s	
13247/26050 (epoch 25.426), train_loss = 1.06985618, grad/param norm = 1.9916e-01, time/batch = 17.9963s	
13248/26050 (epoch 25.428), train_loss = 0.93206164, grad/param norm = 1.7333e-01, time/batch = 16.1330s	
13249/26050 (epoch 25.430), train_loss = 1.11358252, grad/param norm = 2.0301e-01, time/batch = 17.9885s	
13250/26050 (epoch 25.432), train_loss = 0.95239907, grad/param norm = 1.9431e-01, time/batch = 18.7445s	
13251/26050 (epoch 25.434), train_loss = 0.95151421, grad/param norm = 1.9108e-01, time/batch = 17.3089s	
13252/26050 (epoch 25.436), train_loss = 1.10561955, grad/param norm = 2.1511e-01, time/batch = 18.4050s	
13253/26050 (epoch 25.438), train_loss = 1.03403581, grad/param norm = 2.0489e-01, time/batch = 14.5483s	
13254/26050 (epoch 25.440), train_loss = 0.99837923, grad/param norm = 2.1492e-01, time/batch = 18.0688s	
13255/26050 (epoch 25.441), train_loss = 0.98628763, grad/param norm = 1.8969e-01, time/batch = 16.9806s	
13256/26050 (epoch 25.443), train_loss = 0.83071255, grad/param norm = 1.5649e-01, time/batch = 18.2994s	
13257/26050 (epoch 25.445), train_loss = 0.88994039, grad/param norm = 1.7101e-01, time/batch = 18.3884s	
13258/26050 (epoch 25.447), train_loss = 1.09907794, grad/param norm = 2.1604e-01, time/batch = 15.4643s	
13259/26050 (epoch 25.449), train_loss = 0.88763832, grad/param norm = 1.7971e-01, time/batch = 17.9870s	
13260/26050 (epoch 25.451), train_loss = 1.12067851, grad/param norm = 2.0152e-01, time/batch = 18.5586s	
13261/26050 (epoch 25.453), train_loss = 0.91296966, grad/param norm = 1.6296e-01, time/batch = 19.0617s	
13262/26050 (epoch 25.455), train_loss = 0.97617611, grad/param norm = 1.7585e-01, time/batch = 16.8082s	
13263/26050 (epoch 25.457), train_loss = 0.95926588, grad/param norm = 1.7528e-01, time/batch = 14.7333s	
13264/26050 (epoch 25.459), train_loss = 1.06358653, grad/param norm = 2.0262e-01, time/batch = 18.4069s	
13265/26050 (epoch 25.461), train_loss = 1.06173787, grad/param norm = 2.2131e-01, time/batch = 17.0231s	
13266/26050 (epoch 25.463), train_loss = 0.92877716, grad/param norm = 1.7022e-01, time/batch = 17.8230s	
13267/26050 (epoch 25.464), train_loss = 0.99921264, grad/param norm = 1.7608e-01, time/batch = 18.1592s	
13268/26050 (epoch 25.466), train_loss = 1.02885383, grad/param norm = 2.0862e-01, time/batch = 16.5697s	
13269/26050 (epoch 25.468), train_loss = 1.07514811, grad/param norm = 1.6816e-01, time/batch = 17.3713s	
13270/26050 (epoch 25.470), train_loss = 1.07852361, grad/param norm = 2.1195e-01, time/batch = 17.5710s	
13271/26050 (epoch 25.472), train_loss = 1.11884247, grad/param norm = 2.2919e-01, time/batch = 18.3220s	
13272/26050 (epoch 25.474), train_loss = 1.10201983, grad/param norm = 1.8621e-01, time/batch = 17.6529s	
13273/26050 (epoch 25.476), train_loss = 1.10475509, grad/param norm = 1.9403e-01, time/batch = 18.0757s	
13274/26050 (epoch 25.478), train_loss = 0.96485001, grad/param norm = 1.9479e-01, time/batch = 18.3201s	
13275/26050 (epoch 25.480), train_loss = 0.98054041, grad/param norm = 1.8089e-01, time/batch = 17.6290s	
13276/26050 (epoch 25.482), train_loss = 0.94333904, grad/param norm = 1.8579e-01, time/batch = 14.9724s	
13277/26050 (epoch 25.484), train_loss = 0.92604107, grad/param norm = 1.8932e-01, time/batch = 18.5543s	
13278/26050 (epoch 25.486), train_loss = 1.11020208, grad/param norm = 1.8854e-01, time/batch = 18.7127s	
13279/26050 (epoch 25.488), train_loss = 1.19899889, grad/param norm = 2.0710e-01, time/batch = 17.6344s	
13280/26050 (epoch 25.489), train_loss = 1.15205892, grad/param norm = 3.0345e-01, time/batch = 18.4018s	
13281/26050 (epoch 25.491), train_loss = 0.91582437, grad/param norm = 2.2046e-01, time/batch = 17.4627s	
13282/26050 (epoch 25.493), train_loss = 1.00679580, grad/param norm = 2.0012e-01, time/batch = 16.5397s	
13283/26050 (epoch 25.495), train_loss = 0.96418016, grad/param norm = 1.9085e-01, time/batch = 17.8868s	
13284/26050 (epoch 25.497), train_loss = 0.88548132, grad/param norm = 1.8113e-01, time/batch = 17.6620s	
13285/26050 (epoch 25.499), train_loss = 0.94038049, grad/param norm = 1.8700e-01, time/batch = 17.8285s	
13286/26050 (epoch 25.501), train_loss = 1.05343742, grad/param norm = 1.9963e-01, time/batch = 17.4457s	
13287/26050 (epoch 25.503), train_loss = 0.92333233, grad/param norm = 1.9106e-01, time/batch = 17.5737s	
13288/26050 (epoch 25.505), train_loss = 1.09761575, grad/param norm = 1.9376e-01, time/batch = 15.2950s	
13289/26050 (epoch 25.507), train_loss = 1.05167731, grad/param norm = 2.5707e-01, time/batch = 17.7909s	
13290/26050 (epoch 25.509), train_loss = 1.13947327, grad/param norm = 1.8619e-01, time/batch = 16.0570s	
13291/26050 (epoch 25.511), train_loss = 0.92636605, grad/param norm = 1.6164e-01, time/batch = 17.8008s	
13292/26050 (epoch 25.512), train_loss = 0.87914298, grad/param norm = 2.0289e-01, time/batch = 17.2170s	
13293/26050 (epoch 25.514), train_loss = 1.05111240, grad/param norm = 2.2117e-01, time/batch = 18.3957s	
13294/26050 (epoch 25.516), train_loss = 1.10796912, grad/param norm = 1.9473e-01, time/batch = 18.0495s	
13295/26050 (epoch 25.518), train_loss = 0.98338755, grad/param norm = 2.0061e-01, time/batch = 18.7218s	
13296/26050 (epoch 25.520), train_loss = 0.96382258, grad/param norm = 1.8465e-01, time/batch = 15.1142s	
13297/26050 (epoch 25.522), train_loss = 0.77568618, grad/param norm = 1.7078e-01, time/batch = 17.7409s	
13298/26050 (epoch 25.524), train_loss = 1.05552367, grad/param norm = 2.3154e-01, time/batch = 18.3303s	
13299/26050 (epoch 25.526), train_loss = 1.07894675, grad/param norm = 2.1712e-01, time/batch = 17.4823s	
13300/26050 (epoch 25.528), train_loss = 1.02377290, grad/param norm = 2.0367e-01, time/batch = 17.3195s	
13301/26050 (epoch 25.530), train_loss = 0.93545293, grad/param norm = 1.9642e-01, time/batch = 17.8215s	
13302/26050 (epoch 25.532), train_loss = 1.00761839, grad/param norm = 1.9378e-01, time/batch = 18.1670s	
13303/26050 (epoch 25.534), train_loss = 1.05910047, grad/param norm = 2.1715e-01, time/batch = 17.4039s	
13304/26050 (epoch 25.536), train_loss = 0.98019570, grad/param norm = 1.8737e-01, time/batch = 17.8284s	
13305/26050 (epoch 25.537), train_loss = 1.06643901, grad/param norm = 2.1640e-01, time/batch = 15.8692s	
13306/26050 (epoch 25.539), train_loss = 0.98906237, grad/param norm = 1.9155e-01, time/batch = 16.8217s	
13307/26050 (epoch 25.541), train_loss = 1.15902403, grad/param norm = 2.1804e-01, time/batch = 17.5653s	
13308/26050 (epoch 25.543), train_loss = 0.81813321, grad/param norm = 1.7763e-01, time/batch = 18.5651s	
13309/26050 (epoch 25.545), train_loss = 1.01316468, grad/param norm = 2.0116e-01, time/batch = 17.8305s	
13310/26050 (epoch 25.547), train_loss = 0.96351324, grad/param norm = 1.8975e-01, time/batch = 18.7264s	
13311/26050 (epoch 25.549), train_loss = 0.81631339, grad/param norm = 1.9221e-01, time/batch = 18.3115s	
13312/26050 (epoch 25.551), train_loss = 1.04617301, grad/param norm = 2.0360e-01, time/batch = 18.5776s	
13313/26050 (epoch 25.553), train_loss = 0.91601659, grad/param norm = 1.7802e-01, time/batch = 17.7087s	
13314/26050 (epoch 25.555), train_loss = 0.89743377, grad/param norm = 1.8481e-01, time/batch = 14.5550s	
13315/26050 (epoch 25.557), train_loss = 1.00891607, grad/param norm = 1.8717e-01, time/batch = 18.2303s	
13316/26050 (epoch 25.559), train_loss = 0.97293666, grad/param norm = 1.9982e-01, time/batch = 16.2118s	
13317/26050 (epoch 25.560), train_loss = 0.95077612, grad/param norm = 1.9674e-01, time/batch = 17.3086s	
13318/26050 (epoch 25.562), train_loss = 0.96361434, grad/param norm = 1.8092e-01, time/batch = 17.6402s	
13319/26050 (epoch 25.564), train_loss = 1.15485243, grad/param norm = 2.0418e-01, time/batch = 18.2476s	
13320/26050 (epoch 25.566), train_loss = 0.88151419, grad/param norm = 1.7374e-01, time/batch = 17.2428s	
13321/26050 (epoch 25.568), train_loss = 1.02658625, grad/param norm = 1.9540e-01, time/batch = 18.5712s	
13322/26050 (epoch 25.570), train_loss = 1.02659491, grad/param norm = 2.0799e-01, time/batch = 18.7974s	
13323/26050 (epoch 25.572), train_loss = 0.95497785, grad/param norm = 2.1099e-01, time/batch = 16.7338s	
13324/26050 (epoch 25.574), train_loss = 0.99444913, grad/param norm = 2.0281e-01, time/batch = 18.6453s	
13325/26050 (epoch 25.576), train_loss = 1.01409921, grad/param norm = 2.0255e-01, time/batch = 18.5797s	
13326/26050 (epoch 25.578), train_loss = 0.94045823, grad/param norm = 1.8366e-01, time/batch = 15.2248s	
13327/26050 (epoch 25.580), train_loss = 0.90774387, grad/param norm = 1.9347e-01, time/batch = 14.7215s	
13328/26050 (epoch 25.582), train_loss = 0.99577667, grad/param norm = 1.7364e-01, time/batch = 18.4849s	
13329/26050 (epoch 25.583), train_loss = 1.07562533, grad/param norm = 1.9425e-01, time/batch = 18.2488s	
13330/26050 (epoch 25.585), train_loss = 0.85214918, grad/param norm = 1.8974e-01, time/batch = 16.9881s	
13331/26050 (epoch 25.587), train_loss = 1.02787306, grad/param norm = 2.0375e-01, time/batch = 18.3300s	
13332/26050 (epoch 25.589), train_loss = 1.12659746, grad/param norm = 2.1176e-01, time/batch = 17.8648s	
13333/26050 (epoch 25.591), train_loss = 0.97218319, grad/param norm = 1.9774e-01, time/batch = 18.1560s	
13334/26050 (epoch 25.593), train_loss = 0.85794617, grad/param norm = 1.7911e-01, time/batch = 17.8230s	
13335/26050 (epoch 25.595), train_loss = 1.04709007, grad/param norm = 2.1669e-01, time/batch = 17.9700s	
13336/26050 (epoch 25.597), train_loss = 0.98768119, grad/param norm = 1.9779e-01, time/batch = 18.4751s	
13337/26050 (epoch 25.599), train_loss = 1.00832328, grad/param norm = 1.9798e-01, time/batch = 17.4941s	
13338/26050 (epoch 25.601), train_loss = 1.14800150, grad/param norm = 1.8837e-01, time/batch = 15.2427s	
13339/26050 (epoch 25.603), train_loss = 1.00886396, grad/param norm = 1.9618e-01, time/batch = 18.4084s	
13340/26050 (epoch 25.605), train_loss = 0.94579499, grad/param norm = 1.8982e-01, time/batch = 17.8147s	
13341/26050 (epoch 25.607), train_loss = 1.07537714, grad/param norm = 2.0752e-01, time/batch = 17.3205s	
13342/26050 (epoch 25.608), train_loss = 0.87016694, grad/param norm = 1.8116e-01, time/batch = 18.3048s	
13343/26050 (epoch 25.610), train_loss = 0.97529060, grad/param norm = 1.8900e-01, time/batch = 17.9896s	
13344/26050 (epoch 25.612), train_loss = 0.95519129, grad/param norm = 1.9766e-01, time/batch = 18.0597s	
13345/26050 (epoch 25.614), train_loss = 0.98662779, grad/param norm = 1.8052e-01, time/batch = 16.4878s	
13346/26050 (epoch 25.616), train_loss = 1.09660337, grad/param norm = 2.1532e-01, time/batch = 16.3048s	
13347/26050 (epoch 25.618), train_loss = 0.93327130, grad/param norm = 2.0069e-01, time/batch = 16.7256s	
13348/26050 (epoch 25.620), train_loss = 1.02890950, grad/param norm = 1.9590e-01, time/batch = 18.4879s	
13349/26050 (epoch 25.622), train_loss = 0.87399209, grad/param norm = 1.6440e-01, time/batch = 17.6327s	
13350/26050 (epoch 25.624), train_loss = 0.83128627, grad/param norm = 1.6887e-01, time/batch = 17.7197s	
13351/26050 (epoch 25.626), train_loss = 1.03545933, grad/param norm = 1.8990e-01, time/batch = 14.8000s	
13352/26050 (epoch 25.628), train_loss = 0.90773881, grad/param norm = 1.9939e-01, time/batch = 18.3098s	
13353/26050 (epoch 25.630), train_loss = 1.10299021, grad/param norm = 1.8466e-01, time/batch = 18.8931s	
13354/26050 (epoch 25.631), train_loss = 1.13960900, grad/param norm = 2.0898e-01, time/batch = 18.0665s	
13355/26050 (epoch 25.633), train_loss = 0.87793567, grad/param norm = 1.7750e-01, time/batch = 18.1517s	
13356/26050 (epoch 25.635), train_loss = 0.90656684, grad/param norm = 1.7304e-01, time/batch = 17.8250s	
13357/26050 (epoch 25.637), train_loss = 0.87037735, grad/param norm = 1.8186e-01, time/batch = 17.5715s	
13358/26050 (epoch 25.639), train_loss = 1.05521894, grad/param norm = 1.9391e-01, time/batch = 17.4923s	
13359/26050 (epoch 25.641), train_loss = 0.92902400, grad/param norm = 1.8211e-01, time/batch = 18.4698s	
13360/26050 (epoch 25.643), train_loss = 0.88244144, grad/param norm = 1.6381e-01, time/batch = 16.2907s	
13361/26050 (epoch 25.645), train_loss = 0.92429681, grad/param norm = 1.8094e-01, time/batch = 18.7261s	
13362/26050 (epoch 25.647), train_loss = 0.91943544, grad/param norm = 2.0093e-01, time/batch = 18.3065s	
13363/26050 (epoch 25.649), train_loss = 0.96146023, grad/param norm = 1.7682e-01, time/batch = 18.8091s	
13364/26050 (epoch 25.651), train_loss = 0.93253781, grad/param norm = 1.8958e-01, time/batch = 17.1991s	
13365/26050 (epoch 25.653), train_loss = 0.97334557, grad/param norm = 2.0608e-01, time/batch = 15.5377s	
13366/26050 (epoch 25.655), train_loss = 0.90135962, grad/param norm = 1.9600e-01, time/batch = 18.0684s	
13367/26050 (epoch 25.656), train_loss = 0.84139981, grad/param norm = 1.7453e-01, time/batch = 17.7253s	
13368/26050 (epoch 25.658), train_loss = 1.14701152, grad/param norm = 2.0650e-01, time/batch = 17.2889s	
13369/26050 (epoch 25.660), train_loss = 0.84124084, grad/param norm = 1.8492e-01, time/batch = 16.9164s	
13370/26050 (epoch 25.662), train_loss = 0.95924115, grad/param norm = 1.9496e-01, time/batch = 14.8792s	
13371/26050 (epoch 25.664), train_loss = 0.95435425, grad/param norm = 1.9561e-01, time/batch = 18.7319s	
13372/26050 (epoch 25.666), train_loss = 0.90648070, grad/param norm = 1.9845e-01, time/batch = 18.0720s	
13373/26050 (epoch 25.668), train_loss = 0.79350108, grad/param norm = 2.0514e-01, time/batch = 18.5704s	
13374/26050 (epoch 25.670), train_loss = 1.09759458, grad/param norm = 2.1848e-01, time/batch = 16.7389s	
13375/26050 (epoch 25.672), train_loss = 0.97286699, grad/param norm = 1.8929e-01, time/batch = 18.5023s	
13376/26050 (epoch 25.674), train_loss = 0.87597807, grad/param norm = 1.8900e-01, time/batch = 18.1522s	
13377/26050 (epoch 25.676), train_loss = 1.02179814, grad/param norm = 2.0020e-01, time/batch = 17.7304s	
13378/26050 (epoch 25.678), train_loss = 1.06039335, grad/param norm = 2.0022e-01, time/batch = 18.6528s	
13379/26050 (epoch 25.679), train_loss = 1.13512662, grad/param norm = 2.0872e-01, time/batch = 18.1570s	
13380/26050 (epoch 25.681), train_loss = 0.98632287, grad/param norm = 1.9112e-01, time/batch = 16.3064s	
13381/26050 (epoch 25.683), train_loss = 0.87068083, grad/param norm = 2.5384e-01, time/batch = 17.8854s	
13382/26050 (epoch 25.685), train_loss = 0.95794511, grad/param norm = 2.0333e-01, time/batch = 17.7238s	
13383/26050 (epoch 25.687), train_loss = 0.84920009, grad/param norm = 1.8138e-01, time/batch = 18.7366s	
13384/26050 (epoch 25.689), train_loss = 0.93268324, grad/param norm = 1.9369e-01, time/batch = 17.5799s	
13385/26050 (epoch 25.691), train_loss = 0.78894174, grad/param norm = 1.6679e-01, time/batch = 15.5256s	
13386/26050 (epoch 25.693), train_loss = 0.89469684, grad/param norm = 1.8606e-01, time/batch = 17.6654s	
13387/26050 (epoch 25.695), train_loss = 0.96665762, grad/param norm = 1.8262e-01, time/batch = 18.2505s	
13388/26050 (epoch 25.697), train_loss = 0.87855133, grad/param norm = 1.8389e-01, time/batch = 17.0622s	
13389/26050 (epoch 25.699), train_loss = 1.01803542, grad/param norm = 2.1241e-01, time/batch = 17.8270s	
13390/26050 (epoch 25.701), train_loss = 0.87038136, grad/param norm = 1.6659e-01, time/batch = 15.8136s	
13391/26050 (epoch 25.702), train_loss = 1.06740315, grad/param norm = 1.9720e-01, time/batch = 17.3145s	
13392/26050 (epoch 25.704), train_loss = 1.06744801, grad/param norm = 1.8405e-01, time/batch = 18.5794s	
13393/26050 (epoch 25.706), train_loss = 0.93024008, grad/param norm = 2.1206e-01, time/batch = 17.8204s	
13394/26050 (epoch 25.708), train_loss = 1.05581273, grad/param norm = 2.0704e-01, time/batch = 14.7149s	
13395/26050 (epoch 25.710), train_loss = 1.03435762, grad/param norm = 2.3103e-01, time/batch = 18.1470s	
13396/26050 (epoch 25.712), train_loss = 0.98235547, grad/param norm = 1.8522e-01, time/batch = 18.4968s	
13397/26050 (epoch 25.714), train_loss = 0.85282780, grad/param norm = 1.7633e-01, time/batch = 15.4851s	
13398/26050 (epoch 25.716), train_loss = 1.20532272, grad/param norm = 2.2280e-01, time/batch = 16.7919s	
13399/26050 (epoch 25.718), train_loss = 1.03863402, grad/param norm = 1.9673e-01, time/batch = 18.4882s	
13400/26050 (epoch 25.720), train_loss = 0.95801929, grad/param norm = 1.9845e-01, time/batch = 17.1345s	
13401/26050 (epoch 25.722), train_loss = 0.85257390, grad/param norm = 1.6607e-01, time/batch = 18.0763s	
13402/26050 (epoch 25.724), train_loss = 0.90175744, grad/param norm = 1.8735e-01, time/batch = 18.1292s	
13403/26050 (epoch 25.726), train_loss = 1.01668609, grad/param norm = 1.8792e-01, time/batch = 17.9126s	
13404/26050 (epoch 25.727), train_loss = 1.02618244, grad/param norm = 2.0296e-01, time/batch = 18.7198s	
13405/26050 (epoch 25.729), train_loss = 1.00709661, grad/param norm = 1.9628e-01, time/batch = 18.0562s	
13406/26050 (epoch 25.731), train_loss = 1.00972950, grad/param norm = 1.8889e-01, time/batch = 18.1469s	
13407/26050 (epoch 25.733), train_loss = 0.94235361, grad/param norm = 2.1606e-01, time/batch = 15.2257s	
13408/26050 (epoch 25.735), train_loss = 1.15912505, grad/param norm = 2.1309e-01, time/batch = 18.0529s	
13409/26050 (epoch 25.737), train_loss = 0.91264043, grad/param norm = 1.9193e-01, time/batch = 17.5682s	
13410/26050 (epoch 25.739), train_loss = 1.01186906, grad/param norm = 1.8812e-01, time/batch = 17.1449s	
13411/26050 (epoch 25.741), train_loss = 0.90428432, grad/param norm = 1.9486e-01, time/batch = 17.5513s	
13412/26050 (epoch 25.743), train_loss = 1.00419353, grad/param norm = 2.3263e-01, time/batch = 17.5712s	
13413/26050 (epoch 25.745), train_loss = 0.87086398, grad/param norm = 1.9661e-01, time/batch = 18.8281s	
13414/26050 (epoch 25.747), train_loss = 0.88913509, grad/param norm = 1.8476e-01, time/batch = 15.1274s	
13415/26050 (epoch 25.749), train_loss = 1.08400609, grad/param norm = 2.0614e-01, time/batch = 23.9820s	
13416/26050 (epoch 25.750), train_loss = 0.96770249, grad/param norm = 1.6923e-01, time/batch = 32.8494s	
13417/26050 (epoch 25.752), train_loss = 0.91765622, grad/param norm = 2.1796e-01, time/batch = 16.8511s	
13418/26050 (epoch 25.754), train_loss = 0.99353865, grad/param norm = 2.0336e-01, time/batch = 18.5599s	
13419/26050 (epoch 25.756), train_loss = 0.97012724, grad/param norm = 2.0800e-01, time/batch = 18.8066s	
13420/26050 (epoch 25.758), train_loss = 0.94282193, grad/param norm = 2.0340e-01, time/batch = 15.1508s	
13421/26050 (epoch 25.760), train_loss = 1.14544076, grad/param norm = 2.2808e-01, time/batch = 18.5700s	
13422/26050 (epoch 25.762), train_loss = 0.93593620, grad/param norm = 2.0647e-01, time/batch = 18.0737s	
13423/26050 (epoch 25.764), train_loss = 0.95509037, grad/param norm = 1.9795e-01, time/batch = 18.7458s	
13424/26050 (epoch 25.766), train_loss = 1.01789734, grad/param norm = 2.1293e-01, time/batch = 17.1666s	
13425/26050 (epoch 25.768), train_loss = 0.85749016, grad/param norm = 1.7883e-01, time/batch = 18.6552s	
13426/26050 (epoch 25.770), train_loss = 0.95071819, grad/param norm = 2.1863e-01, time/batch = 16.6538s	
13427/26050 (epoch 25.772), train_loss = 0.96811640, grad/param norm = 1.8067e-01, time/batch = 17.5399s	
13428/26050 (epoch 25.774), train_loss = 0.84123821, grad/param norm = 2.0398e-01, time/batch = 18.3789s	
13429/26050 (epoch 25.775), train_loss = 0.71696863, grad/param norm = 1.8935e-01, time/batch = 14.8828s	
13430/26050 (epoch 25.777), train_loss = 0.91612830, grad/param norm = 1.8889e-01, time/batch = 18.8227s	
13431/26050 (epoch 25.779), train_loss = 0.94405469, grad/param norm = 2.0172e-01, time/batch = 16.5444s	
13432/26050 (epoch 25.781), train_loss = 0.84308129, grad/param norm = 1.8131e-01, time/batch = 18.2340s	
13433/26050 (epoch 25.783), train_loss = 0.83982005, grad/param norm = 1.8504e-01, time/batch = 17.4083s	
13434/26050 (epoch 25.785), train_loss = 0.98742003, grad/param norm = 2.1045e-01, time/batch = 15.3755s	
13435/26050 (epoch 25.787), train_loss = 0.87021273, grad/param norm = 2.0126e-01, time/batch = 18.6610s	
13436/26050 (epoch 25.789), train_loss = 0.91263436, grad/param norm = 2.0249e-01, time/batch = 17.9909s	
13437/26050 (epoch 25.791), train_loss = 0.89501648, grad/param norm = 1.8840e-01, time/batch = 15.3112s	
13438/26050 (epoch 25.793), train_loss = 0.93189635, grad/param norm = 1.8823e-01, time/batch = 18.7231s	
13439/26050 (epoch 25.795), train_loss = 0.78862634, grad/param norm = 1.5563e-01, time/batch = 17.8981s	
13440/26050 (epoch 25.797), train_loss = 0.86278662, grad/param norm = 1.9729e-01, time/batch = 17.7394s	
13441/26050 (epoch 25.798), train_loss = 0.82551400, grad/param norm = 1.8530e-01, time/batch = 17.3955s	
13442/26050 (epoch 25.800), train_loss = 0.83049233, grad/param norm = 1.6964e-01, time/batch = 18.3377s	
13443/26050 (epoch 25.802), train_loss = 0.91436260, grad/param norm = 1.9674e-01, time/batch = 18.3231s	
13444/26050 (epoch 25.804), train_loss = 0.95113720, grad/param norm = 2.0279e-01, time/batch = 17.4036s	
13445/26050 (epoch 25.806), train_loss = 1.03746751, grad/param norm = 1.9704e-01, time/batch = 18.8967s	
13446/26050 (epoch 25.808), train_loss = 0.96119331, grad/param norm = 2.1288e-01, time/batch = 18.5656s	
13447/26050 (epoch 25.810), train_loss = 0.89871250, grad/param norm = 1.9261e-01, time/batch = 15.3056s	
13448/26050 (epoch 25.812), train_loss = 0.82730910, grad/param norm = 1.9056e-01, time/batch = 16.7188s	
13449/26050 (epoch 25.814), train_loss = 0.87321373, grad/param norm = 2.3764e-01, time/batch = 18.4859s	
13450/26050 (epoch 25.816), train_loss = 1.02446434, grad/param norm = 2.2251e-01, time/batch = 17.9875s	
13451/26050 (epoch 25.818), train_loss = 1.05590763, grad/param norm = 2.2252e-01, time/batch = 17.6466s	
13452/26050 (epoch 25.820), train_loss = 0.98158789, grad/param norm = 1.8713e-01, time/batch = 18.8122s	
13453/26050 (epoch 25.821), train_loss = 1.07402554, grad/param norm = 2.1712e-01, time/batch = 18.9020s	
13454/26050 (epoch 25.823), train_loss = 1.13031142, grad/param norm = 1.9965e-01, time/batch = 16.2296s	
13455/26050 (epoch 25.825), train_loss = 0.95161697, grad/param norm = 2.0194e-01, time/batch = 18.1469s	
13456/26050 (epoch 25.827), train_loss = 0.99740500, grad/param norm = 2.1748e-01, time/batch = 16.2207s	
13457/26050 (epoch 25.829), train_loss = 1.02498155, grad/param norm = 2.0472e-01, time/batch = 16.1282s	
13458/26050 (epoch 25.831), train_loss = 1.10024728, grad/param norm = 1.9501e-01, time/batch = 15.8746s	
13459/26050 (epoch 25.833), train_loss = 1.13868699, grad/param norm = 2.1706e-01, time/batch = 17.4791s	
13460/26050 (epoch 25.835), train_loss = 1.13285982, grad/param norm = 2.0425e-01, time/batch = 18.5782s	
13461/26050 (epoch 25.837), train_loss = 0.96486997, grad/param norm = 1.7149e-01, time/batch = 17.9014s	
13462/26050 (epoch 25.839), train_loss = 0.96780307, grad/param norm = 2.2389e-01, time/batch = 18.2386s	
13463/26050 (epoch 25.841), train_loss = 1.09381455, grad/param norm = 2.0188e-01, time/batch = 18.2352s	
13464/26050 (epoch 25.843), train_loss = 0.94846536, grad/param norm = 1.7979e-01, time/batch = 15.3923s	
13465/26050 (epoch 25.845), train_loss = 0.92333666, grad/param norm = 1.7806e-01, time/batch = 17.1376s	
13466/26050 (epoch 25.846), train_loss = 1.03595698, grad/param norm = 2.1109e-01, time/batch = 18.2297s	
13467/26050 (epoch 25.848), train_loss = 0.93849428, grad/param norm = 1.8272e-01, time/batch = 17.0662s	
13468/26050 (epoch 25.850), train_loss = 0.87263386, grad/param norm = 1.8377e-01, time/batch = 15.8697s	
13469/26050 (epoch 25.852), train_loss = 0.98300648, grad/param norm = 1.9668e-01, time/batch = 18.3252s	
13470/26050 (epoch 25.854), train_loss = 0.94046672, grad/param norm = 1.8501e-01, time/batch = 14.6462s	
13471/26050 (epoch 25.856), train_loss = 0.90302261, grad/param norm = 1.8911e-01, time/batch = 17.9898s	
13472/26050 (epoch 25.858), train_loss = 0.89560061, grad/param norm = 1.8557e-01, time/batch = 18.4664s	
13473/26050 (epoch 25.860), train_loss = 1.00142544, grad/param norm = 1.9729e-01, time/batch = 17.9786s	
13474/26050 (epoch 25.862), train_loss = 1.04289081, grad/param norm = 1.9587e-01, time/batch = 18.3094s	
13475/26050 (epoch 25.864), train_loss = 0.99324787, grad/param norm = 2.1889e-01, time/batch = 17.7312s	
13476/26050 (epoch 25.866), train_loss = 0.92019393, grad/param norm = 1.6963e-01, time/batch = 18.3913s	
13477/26050 (epoch 25.868), train_loss = 1.00276845, grad/param norm = 2.0352e-01, time/batch = 15.7200s	
13478/26050 (epoch 25.869), train_loss = 0.86978248, grad/param norm = 1.8775e-01, time/batch = 17.2885s	
13479/26050 (epoch 25.871), train_loss = 0.80188360, grad/param norm = 1.7050e-01, time/batch = 17.4798s	
13480/26050 (epoch 25.873), train_loss = 0.99743061, grad/param norm = 1.9837e-01, time/batch = 15.3971s	
13481/26050 (epoch 25.875), train_loss = 0.95414902, grad/param norm = 2.0092e-01, time/batch = 18.2318s	
13482/26050 (epoch 25.877), train_loss = 0.86154998, grad/param norm = 1.6636e-01, time/batch = 16.5723s	
13483/26050 (epoch 25.879), train_loss = 0.98155034, grad/param norm = 1.6793e-01, time/batch = 17.4983s	
13484/26050 (epoch 25.881), train_loss = 1.07488777, grad/param norm = 2.2131e-01, time/batch = 18.7451s	
13485/26050 (epoch 25.883), train_loss = 1.01331988, grad/param norm = 1.9216e-01, time/batch = 17.9947s	
13486/26050 (epoch 25.885), train_loss = 0.74518133, grad/param norm = 1.7772e-01, time/batch = 17.7369s	
13487/26050 (epoch 25.887), train_loss = 1.02296811, grad/param norm = 2.0615e-01, time/batch = 17.9885s	
13488/26050 (epoch 25.889), train_loss = 0.89628478, grad/param norm = 1.7915e-01, time/batch = 18.7229s	
13489/26050 (epoch 25.891), train_loss = 0.79532567, grad/param norm = 1.6778e-01, time/batch = 18.2268s	
13490/26050 (epoch 25.893), train_loss = 0.84530844, grad/param norm = 1.8761e-01, time/batch = 18.1386s	
13491/26050 (epoch 25.894), train_loss = 0.92852058, grad/param norm = 1.9250e-01, time/batch = 18.4058s	
13492/26050 (epoch 25.896), train_loss = 1.05532795, grad/param norm = 2.1438e-01, time/batch = 16.3104s	
13493/26050 (epoch 25.898), train_loss = 0.91966701, grad/param norm = 2.2509e-01, time/batch = 18.2281s	
13494/26050 (epoch 25.900), train_loss = 1.00039243, grad/param norm = 2.2308e-01, time/batch = 17.2093s	
13495/26050 (epoch 25.902), train_loss = 0.95192700, grad/param norm = 2.0097e-01, time/batch = 17.2046s	
13496/26050 (epoch 25.904), train_loss = 0.92744524, grad/param norm = 1.9090e-01, time/batch = 15.4768s	
13497/26050 (epoch 25.906), train_loss = 0.92938948, grad/param norm = 2.0956e-01, time/batch = 17.5487s	
13498/26050 (epoch 25.908), train_loss = 0.95832168, grad/param norm = 1.8527e-01, time/batch = 18.2349s	
13499/26050 (epoch 25.910), train_loss = 0.92884735, grad/param norm = 1.7170e-01, time/batch = 16.7245s	
13500/26050 (epoch 25.912), train_loss = 1.15529516, grad/param norm = 2.2059e-01, time/batch = 18.4743s	
13501/26050 (epoch 25.914), train_loss = 1.30741651, grad/param norm = 2.2930e-01, time/batch = 18.1443s	
13502/26050 (epoch 25.916), train_loss = 1.05032040, grad/param norm = 2.1073e-01, time/batch = 17.7345s	
13503/26050 (epoch 25.917), train_loss = 0.96932706, grad/param norm = 2.0772e-01, time/batch = 17.4682s	
13504/26050 (epoch 25.919), train_loss = 1.00827162, grad/param norm = 2.0769e-01, time/batch = 17.3985s	
13505/26050 (epoch 25.921), train_loss = 0.91909709, grad/param norm = 1.9824e-01, time/batch = 15.8901s	
13506/26050 (epoch 25.923), train_loss = 0.98055625, grad/param norm = 1.9150e-01, time/batch = 17.6355s	
13507/26050 (epoch 25.925), train_loss = 0.97210499, grad/param norm = 1.9701e-01, time/batch = 17.8015s	
13508/26050 (epoch 25.927), train_loss = 0.86025790, grad/param norm = 1.5374e-01, time/batch = 18.0681s	
13509/26050 (epoch 25.929), train_loss = 0.82485363, grad/param norm = 1.7188e-01, time/batch = 17.6453s	
13510/26050 (epoch 25.931), train_loss = 1.13039465, grad/param norm = 2.4072e-01, time/batch = 17.8244s	
13511/26050 (epoch 25.933), train_loss = 0.91370756, grad/param norm = 1.9031e-01, time/batch = 19.0683s	
13512/26050 (epoch 25.935), train_loss = 0.93766462, grad/param norm = 1.9477e-01, time/batch = 18.0672s	
13513/26050 (epoch 25.937), train_loss = 1.05034925, grad/param norm = 1.8822e-01, time/batch = 18.5728s	
13514/26050 (epoch 25.939), train_loss = 0.87586665, grad/param norm = 1.5965e-01, time/batch = 18.5739s	
13515/26050 (epoch 25.940), train_loss = 0.91003262, grad/param norm = 1.6576e-01, time/batch = 17.8976s	
13516/26050 (epoch 25.942), train_loss = 0.94416763, grad/param norm = 1.8859e-01, time/batch = 17.6254s	
13517/26050 (epoch 25.944), train_loss = 0.92670956, grad/param norm = 1.7050e-01, time/batch = 14.8248s	
13518/26050 (epoch 25.946), train_loss = 1.08855442, grad/param norm = 2.0120e-01, time/batch = 18.6520s	
13519/26050 (epoch 25.948), train_loss = 0.82192762, grad/param norm = 1.7954e-01, time/batch = 16.3100s	
13520/26050 (epoch 25.950), train_loss = 0.92450163, grad/param norm = 1.8703e-01, time/batch = 17.9720s	
13521/26050 (epoch 25.952), train_loss = 1.03780234, grad/param norm = 1.9995e-01, time/batch = 18.6546s	
13522/26050 (epoch 25.954), train_loss = 1.07107286, grad/param norm = 2.1161e-01, time/batch = 18.3221s	
13523/26050 (epoch 25.956), train_loss = 0.94122422, grad/param norm = 2.0382e-01, time/batch = 18.7281s	
13524/26050 (epoch 25.958), train_loss = 0.88771090, grad/param norm = 1.8570e-01, time/batch = 18.1539s	
13525/26050 (epoch 25.960), train_loss = 1.00022025, grad/param norm = 2.0729e-01, time/batch = 19.2296s	
13526/26050 (epoch 25.962), train_loss = 0.93891773, grad/param norm = 1.8160e-01, time/batch = 16.6348s	
13527/26050 (epoch 25.964), train_loss = 0.96896258, grad/param norm = 1.8832e-01, time/batch = 18.3984s	
13528/26050 (epoch 25.965), train_loss = 0.88456734, grad/param norm = 1.9179e-01, time/batch = 14.8992s	
13529/26050 (epoch 25.967), train_loss = 1.28321052, grad/param norm = 2.0948e-01, time/batch = 17.2376s	
13530/26050 (epoch 25.969), train_loss = 0.99475894, grad/param norm = 1.9856e-01, time/batch = 18.3078s	
13531/26050 (epoch 25.971), train_loss = 0.92660699, grad/param norm = 1.9678e-01, time/batch = 18.7401s	
13532/26050 (epoch 25.973), train_loss = 0.95976876, grad/param norm = 1.9698e-01, time/batch = 18.0585s	
13533/26050 (epoch 25.975), train_loss = 0.99863491, grad/param norm = 2.0868e-01, time/batch = 15.0606s	
13534/26050 (epoch 25.977), train_loss = 0.97908747, grad/param norm = 1.7877e-01, time/batch = 17.8200s	
13535/26050 (epoch 25.979), train_loss = 0.80085665, grad/param norm = 1.8145e-01, time/batch = 18.5686s	
13536/26050 (epoch 25.981), train_loss = 1.10011972, grad/param norm = 1.9341e-01, time/batch = 17.4965s	
13537/26050 (epoch 25.983), train_loss = 1.04211242, grad/param norm = 2.1612e-01, time/batch = 18.1625s	
13538/26050 (epoch 25.985), train_loss = 1.00832248, grad/param norm = 1.8297e-01, time/batch = 16.3067s	
13539/26050 (epoch 25.987), train_loss = 1.07309365, grad/param norm = 2.0431e-01, time/batch = 17.5690s	
13540/26050 (epoch 25.988), train_loss = 1.01022341, grad/param norm = 1.9774e-01, time/batch = 18.0606s	
13541/26050 (epoch 25.990), train_loss = 0.85719235, grad/param norm = 1.6873e-01, time/batch = 17.8227s	
13542/26050 (epoch 25.992), train_loss = 1.12163769, grad/param norm = 1.9819e-01, time/batch = 15.4797s	
13543/26050 (epoch 25.994), train_loss = 0.92568772, grad/param norm = 2.1632e-01, time/batch = 16.9805s	
13544/26050 (epoch 25.996), train_loss = 0.88731085, grad/param norm = 2.0230e-01, time/batch = 15.2070s	
13545/26050 (epoch 25.998), train_loss = 0.96911061, grad/param norm = 1.7813e-01, time/batch = 18.2438s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
13546/26050 (epoch 26.000), train_loss = 0.93589349, grad/param norm = 2.2345e-01, time/batch = 17.9809s	
13547/26050 (epoch 26.002), train_loss = 1.03026804, grad/param norm = 2.2731e-01, time/batch = 18.2280s	
13548/26050 (epoch 26.004), train_loss = 0.86489637, grad/param norm = 1.9116e-01, time/batch = 18.2342s	
13549/26050 (epoch 26.006), train_loss = 0.91342133, grad/param norm = 2.0983e-01, time/batch = 18.2338s	
13550/26050 (epoch 26.008), train_loss = 0.89706286, grad/param norm = 1.9742e-01, time/batch = 16.8892s	
13551/26050 (epoch 26.010), train_loss = 0.89623791, grad/param norm = 1.9366e-01, time/batch = 18.3873s	
13552/26050 (epoch 26.012), train_loss = 0.96690019, grad/param norm = 1.8760e-01, time/batch = 18.8099s	
13553/26050 (epoch 26.013), train_loss = 1.21924454, grad/param norm = 2.1396e-01, time/batch = 16.3014s	
13554/26050 (epoch 26.015), train_loss = 0.94066112, grad/param norm = 1.7491e-01, time/batch = 16.3726s	
13555/26050 (epoch 26.017), train_loss = 0.98708401, grad/param norm = 1.9192e-01, time/batch = 16.7138s	
13556/26050 (epoch 26.019), train_loss = 0.85810550, grad/param norm = 1.7830e-01, time/batch = 18.2343s	
13557/26050 (epoch 26.021), train_loss = 1.05087895, grad/param norm = 2.0543e-01, time/batch = 18.7216s	
13558/26050 (epoch 26.023), train_loss = 0.78519805, grad/param norm = 1.7189e-01, time/batch = 15.3744s	
13559/26050 (epoch 26.025), train_loss = 0.95115846, grad/param norm = 1.8152e-01, time/batch = 16.9675s	
13560/26050 (epoch 26.027), train_loss = 0.78830974, grad/param norm = 1.8512e-01, time/batch = 16.7167s	
13561/26050 (epoch 26.029), train_loss = 0.97766187, grad/param norm = 1.7883e-01, time/batch = 18.8936s	
13562/26050 (epoch 26.031), train_loss = 1.08768674, grad/param norm = 2.1572e-01, time/batch = 18.2188s	
13563/26050 (epoch 26.033), train_loss = 0.97527072, grad/param norm = 2.0249e-01, time/batch = 18.3777s	
13564/26050 (epoch 26.035), train_loss = 0.98052763, grad/param norm = 1.8333e-01, time/batch = 18.2906s	
13565/26050 (epoch 26.036), train_loss = 0.82672649, grad/param norm = 1.9237e-01, time/batch = 18.0614s	
13566/26050 (epoch 26.038), train_loss = 0.77132225, grad/param norm = 1.8175e-01, time/batch = 18.3971s	
13567/26050 (epoch 26.040), train_loss = 0.93965582, grad/param norm = 1.9171e-01, time/batch = 18.1279s	
13568/26050 (epoch 26.042), train_loss = 0.81786870, grad/param norm = 1.9182e-01, time/batch = 16.1102s	
13569/26050 (epoch 26.044), train_loss = 1.01840603, grad/param norm = 1.7872e-01, time/batch = 17.6339s	
13570/26050 (epoch 26.046), train_loss = 0.78515879, grad/param norm = 1.7187e-01, time/batch = 17.4040s	
13571/26050 (epoch 26.048), train_loss = 0.96430622, grad/param norm = 1.7872e-01, time/batch = 16.5642s	
13572/26050 (epoch 26.050), train_loss = 0.90601252, grad/param norm = 1.8621e-01, time/batch = 18.0490s	
13573/26050 (epoch 26.052), train_loss = 0.87858500, grad/param norm = 1.9189e-01, time/batch = 17.8836s	
13574/26050 (epoch 26.054), train_loss = 0.80058456, grad/param norm = 1.7774e-01, time/batch = 17.7996s	
13575/26050 (epoch 26.056), train_loss = 0.78551673, grad/param norm = 1.7649e-01, time/batch = 17.7198s	
13576/26050 (epoch 26.058), train_loss = 0.93883311, grad/param norm = 1.8304e-01, time/batch = 17.1483s	
13577/26050 (epoch 26.060), train_loss = 1.02931596, grad/param norm = 1.9551e-01, time/batch = 17.0465s	
13578/26050 (epoch 26.061), train_loss = 0.86902858, grad/param norm = 1.7531e-01, time/batch = 18.6411s	
13579/26050 (epoch 26.063), train_loss = 0.98865275, grad/param norm = 1.8873e-01, time/batch = 17.9185s	
13580/26050 (epoch 26.065), train_loss = 0.78307479, grad/param norm = 1.6371e-01, time/batch = 17.3888s	
13581/26050 (epoch 26.067), train_loss = 0.94018397, grad/param norm = 1.9570e-01, time/batch = 19.0660s	
13582/26050 (epoch 26.069), train_loss = 0.99928553, grad/param norm = 1.9586e-01, time/batch = 18.2236s	
13583/26050 (epoch 26.071), train_loss = 1.00371909, grad/param norm = 1.9528e-01, time/batch = 17.6321s	
13584/26050 (epoch 26.073), train_loss = 1.09450349, grad/param norm = 1.8600e-01, time/batch = 17.9746s	
13585/26050 (epoch 26.075), train_loss = 0.87831086, grad/param norm = 1.7744e-01, time/batch = 18.8254s	
13586/26050 (epoch 26.077), train_loss = 0.91625694, grad/param norm = 2.0280e-01, time/batch = 17.9900s	
13587/26050 (epoch 26.079), train_loss = 0.94772068, grad/param norm = 1.9080e-01, time/batch = 17.8804s	
13588/26050 (epoch 26.081), train_loss = 0.93212923, grad/param norm = 1.9058e-01, time/batch = 17.9113s	
13589/26050 (epoch 26.083), train_loss = 1.05077583, grad/param norm = 1.8091e-01, time/batch = 18.4122s	
13590/26050 (epoch 26.084), train_loss = 0.97630142, grad/param norm = 2.8857e-01, time/batch = 17.1612s	
13591/26050 (epoch 26.086), train_loss = 1.12866312, grad/param norm = 2.2652e-01, time/batch = 16.7309s	
13592/26050 (epoch 26.088), train_loss = 0.90720674, grad/param norm = 2.0298e-01, time/batch = 16.0329s	
13593/26050 (epoch 26.090), train_loss = 0.94624731, grad/param norm = 1.9175e-01, time/batch = 15.1368s	
13594/26050 (epoch 26.092), train_loss = 1.01640956, grad/param norm = 1.9651e-01, time/batch = 16.8211s	
13595/26050 (epoch 26.094), train_loss = 0.86865559, grad/param norm = 1.9003e-01, time/batch = 18.0668s	
13596/26050 (epoch 26.096), train_loss = 0.96033957, grad/param norm = 1.8131e-01, time/batch = 18.5578s	
13597/26050 (epoch 26.098), train_loss = 0.89720752, grad/param norm = 1.7446e-01, time/batch = 17.5561s	
13598/26050 (epoch 26.100), train_loss = 0.86406456, grad/param norm = 1.7704e-01, time/batch = 17.8116s	
13599/26050 (epoch 26.102), train_loss = 1.01276223, grad/param norm = 2.1397e-01, time/batch = 18.5688s	
13600/26050 (epoch 26.104), train_loss = 0.91470064, grad/param norm = 1.8970e-01, time/batch = 17.7188s	
13601/26050 (epoch 26.106), train_loss = 0.94200172, grad/param norm = 2.1848e-01, time/batch = 17.7161s	
13602/26050 (epoch 26.107), train_loss = 0.77156310, grad/param norm = 1.8370e-01, time/batch = 18.8091s	
13603/26050 (epoch 26.109), train_loss = 0.87450284, grad/param norm = 1.8818e-01, time/batch = 15.1527s	
13604/26050 (epoch 26.111), train_loss = 1.11147046, grad/param norm = 2.0426e-01, time/batch = 17.6537s	
13605/26050 (epoch 26.113), train_loss = 0.90868206, grad/param norm = 1.8848e-01, time/batch = 18.0650s	
13606/26050 (epoch 26.115), train_loss = 1.04459611, grad/param norm = 2.0328e-01, time/batch = 17.3269s	
13607/26050 (epoch 26.117), train_loss = 0.94568404, grad/param norm = 1.8347e-01, time/batch = 16.2007s	
13608/26050 (epoch 26.119), train_loss = 0.79368229, grad/param norm = 1.7008e-01, time/batch = 18.1531s	
13609/26050 (epoch 26.121), train_loss = 0.95895981, grad/param norm = 1.7762e-01, time/batch = 17.6416s	
13610/26050 (epoch 26.123), train_loss = 0.87077137, grad/param norm = 1.8615e-01, time/batch = 18.3217s	
13611/26050 (epoch 26.125), train_loss = 0.83406715, grad/param norm = 1.7161e-01, time/batch = 18.9807s	
13612/26050 (epoch 26.127), train_loss = 0.77490212, grad/param norm = 1.7761e-01, time/batch = 17.0539s	
13613/26050 (epoch 26.129), train_loss = 0.79378724, grad/param norm = 1.8748e-01, time/batch = 17.7262s	
13614/26050 (epoch 26.131), train_loss = 0.90738377, grad/param norm = 1.8058e-01, time/batch = 15.3249s	
13615/26050 (epoch 26.132), train_loss = 0.92124640, grad/param norm = 1.7521e-01, time/batch = 16.3085s	
13616/26050 (epoch 26.134), train_loss = 0.95732882, grad/param norm = 1.9998e-01, time/batch = 18.3240s	
13617/26050 (epoch 26.136), train_loss = 0.93271655, grad/param norm = 1.8339e-01, time/batch = 15.0573s	
13618/26050 (epoch 26.138), train_loss = 0.71469695, grad/param norm = 1.7528e-01, time/batch = 27.6593s	
13619/26050 (epoch 26.140), train_loss = 0.79407291, grad/param norm = 1.8887e-01, time/batch = 28.4480s	
13620/26050 (epoch 26.142), train_loss = 0.82251422, grad/param norm = 1.7886e-01, time/batch = 17.5474s	
13621/26050 (epoch 26.144), train_loss = 0.75419019, grad/param norm = 1.9135e-01, time/batch = 18.8850s	
13622/26050 (epoch 26.146), train_loss = 0.71113881, grad/param norm = 1.6818e-01, time/batch = 17.9029s	
13623/26050 (epoch 26.148), train_loss = 0.74311694, grad/param norm = 1.5560e-01, time/batch = 17.2367s	
13624/26050 (epoch 26.150), train_loss = 0.89579398, grad/param norm = 1.9763e-01, time/batch = 18.8777s	
13625/26050 (epoch 26.152), train_loss = 1.09287621, grad/param norm = 2.4801e-01, time/batch = 15.8799s	
13626/26050 (epoch 26.154), train_loss = 0.74566707, grad/param norm = 1.7958e-01, time/batch = 18.2933s	
13627/26050 (epoch 26.155), train_loss = 0.81597303, grad/param norm = 2.4315e-01, time/batch = 18.3085s	
13628/26050 (epoch 26.157), train_loss = 0.90748231, grad/param norm = 2.1930e-01, time/batch = 18.6516s	
13629/26050 (epoch 26.159), train_loss = 0.95590122, grad/param norm = 2.0898e-01, time/batch = 17.9879s	
13630/26050 (epoch 26.161), train_loss = 0.95051601, grad/param norm = 2.0089e-01, time/batch = 17.0575s	
13631/26050 (epoch 26.163), train_loss = 0.76473333, grad/param norm = 1.6548e-01, time/batch = 17.8324s	
13632/26050 (epoch 26.165), train_loss = 0.73692385, grad/param norm = 1.8951e-01, time/batch = 17.1505s	
13633/26050 (epoch 26.167), train_loss = 1.05919345, grad/param norm = 2.1411e-01, time/batch = 17.1187s	
13634/26050 (epoch 26.169), train_loss = 0.93972278, grad/param norm = 1.9851e-01, time/batch = 18.1496s	
13635/26050 (epoch 26.171), train_loss = 0.79341049, grad/param norm = 1.7073e-01, time/batch = 15.7135s	
13636/26050 (epoch 26.173), train_loss = 0.89305795, grad/param norm = 1.9624e-01, time/batch = 17.6451s	
13637/26050 (epoch 26.175), train_loss = 0.89639779, grad/param norm = 1.8168e-01, time/batch = 17.8892s	
13638/26050 (epoch 26.177), train_loss = 1.02578212, grad/param norm = 1.9275e-01, time/batch = 18.3195s	
13639/26050 (epoch 26.179), train_loss = 0.67905302, grad/param norm = 1.5343e-01, time/batch = 17.5013s	
13640/26050 (epoch 26.180), train_loss = 1.13019646, grad/param norm = 1.9533e-01, time/batch = 17.6584s	
13641/26050 (epoch 26.182), train_loss = 1.15759412, grad/param norm = 2.0821e-01, time/batch = 17.3129s	
13642/26050 (epoch 26.184), train_loss = 0.96296046, grad/param norm = 1.8149e-01, time/batch = 16.6158s	
13643/26050 (epoch 26.186), train_loss = 0.78102474, grad/param norm = 1.8087e-01, time/batch = 17.9843s	
13644/26050 (epoch 26.188), train_loss = 0.95249490, grad/param norm = 1.8740e-01, time/batch = 17.3095s	
13645/26050 (epoch 26.190), train_loss = 0.97786452, grad/param norm = 1.9550e-01, time/batch = 18.1404s	
13646/26050 (epoch 26.192), train_loss = 0.98392531, grad/param norm = 1.8362e-01, time/batch = 18.5715s	
13647/26050 (epoch 26.194), train_loss = 0.97533573, grad/param norm = 1.9311e-01, time/batch = 17.7347s	
13648/26050 (epoch 26.196), train_loss = 1.00734697, grad/param norm = 1.9453e-01, time/batch = 17.2324s	
13649/26050 (epoch 26.198), train_loss = 0.85608994, grad/param norm = 1.7176e-01, time/batch = 18.1463s	
13650/26050 (epoch 26.200), train_loss = 0.83775056, grad/param norm = 1.8029e-01, time/batch = 14.8840s	
13651/26050 (epoch 26.202), train_loss = 0.94602647, grad/param norm = 1.7148e-01, time/batch = 17.1658s	
13652/26050 (epoch 26.203), train_loss = 1.04586277, grad/param norm = 1.9003e-01, time/batch = 16.4015s	
13653/26050 (epoch 26.205), train_loss = 0.90321295, grad/param norm = 1.9144e-01, time/batch = 16.7270s	
13654/26050 (epoch 26.207), train_loss = 0.86478757, grad/param norm = 1.8482e-01, time/batch = 16.3271s	
13655/26050 (epoch 26.209), train_loss = 0.99188235, grad/param norm = 1.8612e-01, time/batch = 18.3173s	
13656/26050 (epoch 26.211), train_loss = 0.77764797, grad/param norm = 1.7094e-01, time/batch = 18.4142s	
13657/26050 (epoch 26.213), train_loss = 0.96375789, grad/param norm = 2.0632e-01, time/batch = 17.0710s	
13658/26050 (epoch 26.215), train_loss = 0.92829912, grad/param norm = 2.2448e-01, time/batch = 18.6552s	
13659/26050 (epoch 26.217), train_loss = 0.89754138, grad/param norm = 1.7785e-01, time/batch = 16.3881s	
13660/26050 (epoch 26.219), train_loss = 0.91320052, grad/param norm = 2.0178e-01, time/batch = 17.5648s	
13661/26050 (epoch 26.221), train_loss = 0.85731623, grad/param norm = 2.0433e-01, time/batch = 16.3754s	
13662/26050 (epoch 26.223), train_loss = 0.99941372, grad/param norm = 1.9472e-01, time/batch = 15.0508s	
13663/26050 (epoch 26.225), train_loss = 0.85670523, grad/param norm = 2.0490e-01, time/batch = 17.9893s	
13664/26050 (epoch 26.226), train_loss = 0.98060340, grad/param norm = 2.1183e-01, time/batch = 17.6519s	
13665/26050 (epoch 26.228), train_loss = 1.06718947, grad/param norm = 1.9581e-01, time/batch = 18.5731s	
13666/26050 (epoch 26.230), train_loss = 0.94782813, grad/param norm = 1.8694e-01, time/batch = 17.9840s	
13667/26050 (epoch 26.232), train_loss = 1.02208022, grad/param norm = 2.1951e-01, time/batch = 18.3185s	
13668/26050 (epoch 26.234), train_loss = 0.83614627, grad/param norm = 1.9300e-01, time/batch = 17.2668s	
13669/26050 (epoch 26.236), train_loss = 1.03077509, grad/param norm = 1.8969e-01, time/batch = 18.3993s	
13670/26050 (epoch 26.238), train_loss = 0.82355185, grad/param norm = 1.9978e-01, time/batch = 16.0847s	
13671/26050 (epoch 26.240), train_loss = 0.95727264, grad/param norm = 2.4869e-01, time/batch = 17.0533s	
13672/26050 (epoch 26.242), train_loss = 0.91680073, grad/param norm = 1.8684e-01, time/batch = 17.8112s	
13673/26050 (epoch 26.244), train_loss = 0.95214458, grad/param norm = 1.9822e-01, time/batch = 15.8030s	
13674/26050 (epoch 26.246), train_loss = 0.86390407, grad/param norm = 2.1538e-01, time/batch = 15.4685s	
13675/26050 (epoch 26.248), train_loss = 0.94909666, grad/param norm = 1.9977e-01, time/batch = 18.3032s	
13676/26050 (epoch 26.250), train_loss = 0.92862247, grad/param norm = 2.0638e-01, time/batch = 17.4866s	
13677/26050 (epoch 26.251), train_loss = 0.88275634, grad/param norm = 1.7328e-01, time/batch = 18.4807s	
13678/26050 (epoch 26.253), train_loss = 0.83547226, grad/param norm = 1.8285e-01, time/batch = 17.4117s	
13679/26050 (epoch 26.255), train_loss = 1.09159726, grad/param norm = 2.1115e-01, time/batch = 18.2394s	
13680/26050 (epoch 26.257), train_loss = 0.93682219, grad/param norm = 2.2297e-01, time/batch = 18.7402s	
13681/26050 (epoch 26.259), train_loss = 1.04840431, grad/param norm = 1.9952e-01, time/batch = 14.6265s	
13682/26050 (epoch 26.261), train_loss = 0.84055196, grad/param norm = 2.0909e-01, time/batch = 18.0671s	
13683/26050 (epoch 26.263), train_loss = 1.04170882, grad/param norm = 2.1598e-01, time/batch = 18.5632s	
13684/26050 (epoch 26.265), train_loss = 1.08257695, grad/param norm = 2.0400e-01, time/batch = 16.3067s	
13685/26050 (epoch 26.267), train_loss = 1.05092275, grad/param norm = 1.8454e-01, time/batch = 16.4686s	
13686/26050 (epoch 26.269), train_loss = 1.05557287, grad/param norm = 1.9931e-01, time/batch = 17.7603s	
13687/26050 (epoch 26.271), train_loss = 0.99469103, grad/param norm = 2.1935e-01, time/batch = 18.3302s	
13688/26050 (epoch 26.273), train_loss = 0.88279992, grad/param norm = 2.3031e-01, time/batch = 17.8947s	
13689/26050 (epoch 26.274), train_loss = 0.92092389, grad/param norm = 1.7812e-01, time/batch = 17.2295s	
13690/26050 (epoch 26.276), train_loss = 0.91461722, grad/param norm = 2.1761e-01, time/batch = 18.1629s	
13691/26050 (epoch 26.278), train_loss = 1.04556682, grad/param norm = 1.9088e-01, time/batch = 18.3250s	
13692/26050 (epoch 26.280), train_loss = 0.93284066, grad/param norm = 1.7631e-01, time/batch = 17.5508s	
13693/26050 (epoch 26.282), train_loss = 0.98180102, grad/param norm = 1.9572e-01, time/batch = 15.6066s	
13694/26050 (epoch 26.284), train_loss = 0.92734024, grad/param norm = 1.9508e-01, time/batch = 17.9692s	
13695/26050 (epoch 26.286), train_loss = 0.96292114, grad/param norm = 2.1920e-01, time/batch = 17.9151s	
13696/26050 (epoch 26.288), train_loss = 0.80800129, grad/param norm = 1.7425e-01, time/batch = 16.5480s	
13697/26050 (epoch 26.290), train_loss = 0.95199224, grad/param norm = 1.9427e-01, time/batch = 18.3935s	
13698/26050 (epoch 26.292), train_loss = 0.87611131, grad/param norm = 1.8137e-01, time/batch = 17.5701s	
13699/26050 (epoch 26.294), train_loss = 0.94481664, grad/param norm = 2.0958e-01, time/batch = 16.6381s	
13700/26050 (epoch 26.296), train_loss = 1.04470913, grad/param norm = 1.9987e-01, time/batch = 18.8102s	
13701/26050 (epoch 26.298), train_loss = 0.95824649, grad/param norm = 1.6925e-01, time/batch = 17.1520s	
13702/26050 (epoch 26.299), train_loss = 0.78851526, grad/param norm = 1.6073e-01, time/batch = 16.1791s	
13703/26050 (epoch 26.301), train_loss = 0.80128762, grad/param norm = 1.8985e-01, time/batch = 18.0533s	
13704/26050 (epoch 26.303), train_loss = 0.95514088, grad/param norm = 2.6557e-01, time/batch = 18.5657s	
13705/26050 (epoch 26.305), train_loss = 0.75835258, grad/param norm = 1.8868e-01, time/batch = 17.4076s	
13706/26050 (epoch 26.307), train_loss = 0.85983094, grad/param norm = 2.0081e-01, time/batch = 18.6671s	
13707/26050 (epoch 26.309), train_loss = 0.91890708, grad/param norm = 2.1073e-01, time/batch = 16.6434s	
13708/26050 (epoch 26.311), train_loss = 1.01881940, grad/param norm = 2.4622e-01, time/batch = 17.6416s	
13709/26050 (epoch 26.313), train_loss = 0.93267613, grad/param norm = 2.3774e-01, time/batch = 17.4875s	
13710/26050 (epoch 26.315), train_loss = 1.01585654, grad/param norm = 1.9329e-01, time/batch = 18.1592s	
13711/26050 (epoch 26.317), train_loss = 0.95869149, grad/param norm = 1.9444e-01, time/batch = 18.2348s	
13712/26050 (epoch 26.319), train_loss = 0.85985594, grad/param norm = 2.0742e-01, time/batch = 17.2329s	
13713/26050 (epoch 26.321), train_loss = 0.92400321, grad/param norm = 1.9653e-01, time/batch = 15.3182s	
13714/26050 (epoch 26.322), train_loss = 0.99189203, grad/param norm = 1.8439e-01, time/batch = 18.7377s	
13715/26050 (epoch 26.324), train_loss = 0.75832162, grad/param norm = 1.6387e-01, time/batch = 17.2438s	
13716/26050 (epoch 26.326), train_loss = 1.07413722, grad/param norm = 2.0979e-01, time/batch = 18.1499s	
13717/26050 (epoch 26.328), train_loss = 0.94232614, grad/param norm = 1.6906e-01, time/batch = 18.4891s	
13718/26050 (epoch 26.330), train_loss = 0.79975076, grad/param norm = 1.8147e-01, time/batch = 17.4876s	
13719/26050 (epoch 26.332), train_loss = 1.00711987, grad/param norm = 2.1264e-01, time/batch = 14.3900s	
13720/26050 (epoch 26.334), train_loss = 0.86818487, grad/param norm = 1.8348e-01, time/batch = 18.0741s	
13721/26050 (epoch 26.336), train_loss = 0.87466651, grad/param norm = 1.8175e-01, time/batch = 18.3230s	
13722/26050 (epoch 26.338), train_loss = 0.82814820, grad/param norm = 1.7607e-01, time/batch = 17.8196s	
13723/26050 (epoch 26.340), train_loss = 1.01243404, grad/param norm = 2.0806e-01, time/batch = 18.0763s	
13724/26050 (epoch 26.342), train_loss = 1.02789398, grad/param norm = 1.8795e-01, time/batch = 17.9921s	
13725/26050 (epoch 26.344), train_loss = 0.86491557, grad/param norm = 1.9287e-01, time/batch = 14.7102s	
13726/26050 (epoch 26.345), train_loss = 0.92897481, grad/param norm = 2.0364e-01, time/batch = 17.6514s	
13727/26050 (epoch 26.347), train_loss = 1.06969538, grad/param norm = 1.9994e-01, time/batch = 17.2031s	
13728/26050 (epoch 26.349), train_loss = 0.99813877, grad/param norm = 2.1310e-01, time/batch = 14.3784s	
13729/26050 (epoch 26.351), train_loss = 0.98810546, grad/param norm = 1.9717e-01, time/batch = 14.1497s	
13730/26050 (epoch 26.353), train_loss = 0.95504445, grad/param norm = 2.1447e-01, time/batch = 15.9634s	
13731/26050 (epoch 26.355), train_loss = 0.97148855, grad/param norm = 2.1415e-01, time/batch = 14.3858s	
13732/26050 (epoch 26.357), train_loss = 0.88144667, grad/param norm = 1.7477e-01, time/batch = 15.2268s	
13733/26050 (epoch 26.359), train_loss = 1.04288462, grad/param norm = 2.1607e-01, time/batch = 16.1221s	
13734/26050 (epoch 26.361), train_loss = 0.87031900, grad/param norm = 1.8177e-01, time/batch = 15.4798s	
13735/26050 (epoch 26.363), train_loss = 1.01779378, grad/param norm = 1.8461e-01, time/batch = 18.9754s	
13736/26050 (epoch 26.365), train_loss = 0.90393838, grad/param norm = 1.6982e-01, time/batch = 18.5709s	
13737/26050 (epoch 26.367), train_loss = 1.01549298, grad/param norm = 1.8067e-01, time/batch = 10.9101s	
13738/26050 (epoch 26.369), train_loss = 0.86055257, grad/param norm = 1.6947e-01, time/batch = 0.6550s	
13739/26050 (epoch 26.370), train_loss = 0.84642183, grad/param norm = 1.6274e-01, time/batch = 0.6535s	
13740/26050 (epoch 26.372), train_loss = 0.95737713, grad/param norm = 1.9378e-01, time/batch = 0.6523s	
13741/26050 (epoch 26.374), train_loss = 1.05326947, grad/param norm = 1.9117e-01, time/batch = 0.6564s	
13742/26050 (epoch 26.376), train_loss = 1.11434901, grad/param norm = 2.1229e-01, time/batch = 0.6512s	
13743/26050 (epoch 26.378), train_loss = 0.88578819, grad/param norm = 1.7706e-01, time/batch = 0.6764s	
13744/26050 (epoch 26.380), train_loss = 1.10832518, grad/param norm = 2.2257e-01, time/batch = 0.6571s	
13745/26050 (epoch 26.382), train_loss = 1.20584402, grad/param norm = 2.1440e-01, time/batch = 0.9226s	
13746/26050 (epoch 26.384), train_loss = 0.92724125, grad/param norm = 2.5272e-01, time/batch = 0.9529s	
13747/26050 (epoch 26.386), train_loss = 1.00232309, grad/param norm = 2.4328e-01, time/batch = 0.9552s	
13748/26050 (epoch 26.388), train_loss = 0.96128009, grad/param norm = 1.9992e-01, time/batch = 0.9626s	
13749/26050 (epoch 26.390), train_loss = 0.90049424, grad/param norm = 1.8909e-01, time/batch = 0.9672s	
13750/26050 (epoch 26.392), train_loss = 0.83225568, grad/param norm = 1.7606e-01, time/batch = 1.4878s	
13751/26050 (epoch 26.393), train_loss = 0.99112223, grad/param norm = 1.9442e-01, time/batch = 1.8374s	
13752/26050 (epoch 26.395), train_loss = 1.02421591, grad/param norm = 2.1592e-01, time/batch = 1.7787s	
13753/26050 (epoch 26.397), train_loss = 1.02070014, grad/param norm = 2.3860e-01, time/batch = 12.8992s	
13754/26050 (epoch 26.399), train_loss = 0.89206620, grad/param norm = 1.9112e-01, time/batch = 15.6346s	
13755/26050 (epoch 26.401), train_loss = 0.97799463, grad/param norm = 1.9716e-01, time/batch = 17.5621s	
13756/26050 (epoch 26.403), train_loss = 0.97199870, grad/param norm = 2.1546e-01, time/batch = 18.9869s	
13757/26050 (epoch 26.405), train_loss = 0.95442001, grad/param norm = 1.9639e-01, time/batch = 16.6645s	
13758/26050 (epoch 26.407), train_loss = 1.10665975, grad/param norm = 2.0580e-01, time/batch = 17.3946s	
13759/26050 (epoch 26.409), train_loss = 1.08104130, grad/param norm = 2.1420e-01, time/batch = 18.4663s	
13760/26050 (epoch 26.411), train_loss = 1.00152612, grad/param norm = 1.9984e-01, time/batch = 18.2999s	
13761/26050 (epoch 26.413), train_loss = 1.10045188, grad/param norm = 1.8697e-01, time/batch = 14.8782s	
13762/26050 (epoch 26.415), train_loss = 1.10848564, grad/param norm = 2.4930e-01, time/batch = 15.1008s	
13763/26050 (epoch 26.417), train_loss = 1.16105107, grad/param norm = 2.2617e-01, time/batch = 17.8176s	
13764/26050 (epoch 26.418), train_loss = 1.04125142, grad/param norm = 2.2112e-01, time/batch = 17.9923s	
13765/26050 (epoch 26.420), train_loss = 0.81236123, grad/param norm = 1.6592e-01, time/batch = 17.7317s	
13766/26050 (epoch 26.422), train_loss = 0.80965778, grad/param norm = 1.8887e-01, time/batch = 18.8114s	
13767/26050 (epoch 26.424), train_loss = 1.08552104, grad/param norm = 2.1470e-01, time/batch = 15.1448s	
13768/26050 (epoch 26.426), train_loss = 1.05423522, grad/param norm = 2.0812e-01, time/batch = 17.9844s	
13769/26050 (epoch 26.428), train_loss = 0.91468193, grad/param norm = 1.7453e-01, time/batch = 16.3773s	
13770/26050 (epoch 26.430), train_loss = 1.10617607, grad/param norm = 1.9879e-01, time/batch = 18.2952s	
13771/26050 (epoch 26.432), train_loss = 0.93502360, grad/param norm = 1.8263e-01, time/batch = 17.3131s	
13772/26050 (epoch 26.434), train_loss = 0.94771897, grad/param norm = 1.9747e-01, time/batch = 16.6299s	
13773/26050 (epoch 26.436), train_loss = 1.09192378, grad/param norm = 2.0476e-01, time/batch = 17.5596s	
13774/26050 (epoch 26.438), train_loss = 1.02989593, grad/param norm = 2.2126e-01, time/batch = 17.0577s	
13775/26050 (epoch 26.440), train_loss = 0.98566157, grad/param norm = 1.9301e-01, time/batch = 18.6440s	
13776/26050 (epoch 26.441), train_loss = 0.96462906, grad/param norm = 1.8857e-01, time/batch = 17.8163s	
13777/26050 (epoch 26.443), train_loss = 0.81480976, grad/param norm = 1.5054e-01, time/batch = 18.0602s	
13778/26050 (epoch 26.445), train_loss = 0.88468138, grad/param norm = 1.7321e-01, time/batch = 18.4839s	
13779/26050 (epoch 26.447), train_loss = 1.06826803, grad/param norm = 2.0683e-01, time/batch = 17.7372s	
13780/26050 (epoch 26.449), train_loss = 0.89619157, grad/param norm = 1.8443e-01, time/batch = 17.9773s	
13781/26050 (epoch 26.451), train_loss = 1.10387278, grad/param norm = 1.9745e-01, time/batch = 15.3959s	
13782/26050 (epoch 26.453), train_loss = 0.90021458, grad/param norm = 1.7448e-01, time/batch = 18.3082s	
13783/26050 (epoch 26.455), train_loss = 0.96462866, grad/param norm = 1.8268e-01, time/batch = 16.3766s	
13784/26050 (epoch 26.457), train_loss = 0.94701312, grad/param norm = 1.8560e-01, time/batch = 16.7207s	
13785/26050 (epoch 26.459), train_loss = 1.03886021, grad/param norm = 1.9040e-01, time/batch = 18.6533s	
13786/26050 (epoch 26.461), train_loss = 1.05619196, grad/param norm = 2.4617e-01, time/batch = 16.2077s	
13787/26050 (epoch 26.463), train_loss = 0.91178376, grad/param norm = 1.6097e-01, time/batch = 18.7258s	
13788/26050 (epoch 26.464), train_loss = 1.00502006, grad/param norm = 2.1069e-01, time/batch = 15.8056s	
13789/26050 (epoch 26.466), train_loss = 1.02519176, grad/param norm = 2.0967e-01, time/batch = 18.0486s	
13790/26050 (epoch 26.468), train_loss = 1.06512384, grad/param norm = 1.8136e-01, time/batch = 16.7351s	
13791/26050 (epoch 26.470), train_loss = 1.06239554, grad/param norm = 2.2625e-01, time/batch = 18.3174s	
13792/26050 (epoch 26.472), train_loss = 1.09289164, grad/param norm = 2.3258e-01, time/batch = 17.9034s	
13793/26050 (epoch 26.474), train_loss = 1.08917643, grad/param norm = 2.0204e-01, time/batch = 15.3090s	
13794/26050 (epoch 26.476), train_loss = 1.09151337, grad/param norm = 1.9929e-01, time/batch = 18.1491s	
13795/26050 (epoch 26.478), train_loss = 0.94699078, grad/param norm = 1.8244e-01, time/batch = 17.7421s	
13796/26050 (epoch 26.480), train_loss = 0.97309627, grad/param norm = 1.7964e-01, time/batch = 17.9833s	
13797/26050 (epoch 26.482), train_loss = 0.92645535, grad/param norm = 1.9769e-01, time/batch = 18.3237s	
13798/26050 (epoch 26.484), train_loss = 0.90873004, grad/param norm = 1.9102e-01, time/batch = 18.6462s	
13799/26050 (epoch 26.486), train_loss = 1.09008987, grad/param norm = 1.9244e-01, time/batch = 18.3086s	
13800/26050 (epoch 26.488), train_loss = 1.16299730, grad/param norm = 2.1505e-01, time/batch = 18.1377s	
13801/26050 (epoch 26.489), train_loss = 1.12497930, grad/param norm = 2.2224e-01, time/batch = 17.4856s	
13802/26050 (epoch 26.491), train_loss = 0.90822310, grad/param norm = 2.1820e-01, time/batch = 15.6179s	
13803/26050 (epoch 26.493), train_loss = 0.98081742, grad/param norm = 2.0677e-01, time/batch = 16.4696s	
13804/26050 (epoch 26.495), train_loss = 0.93553792, grad/param norm = 1.7613e-01, time/batch = 18.7225s	
13805/26050 (epoch 26.497), train_loss = 0.87633332, grad/param norm = 1.7720e-01, time/batch = 18.4041s	
13806/26050 (epoch 26.499), train_loss = 0.92820784, grad/param norm = 1.8872e-01, time/batch = 17.3096s	
13807/26050 (epoch 26.501), train_loss = 1.03618216, grad/param norm = 1.9681e-01, time/batch = 18.5577s	
13808/26050 (epoch 26.503), train_loss = 0.91987182, grad/param norm = 1.9142e-01, time/batch = 18.6570s	
13809/26050 (epoch 26.505), train_loss = 1.07783969, grad/param norm = 1.9450e-01, time/batch = 18.5632s	
13810/26050 (epoch 26.507), train_loss = 1.04379588, grad/param norm = 2.2658e-01, time/batch = 16.8810s	
13811/26050 (epoch 26.509), train_loss = 1.12294393, grad/param norm = 1.9732e-01, time/batch = 17.3127s	
13812/26050 (epoch 26.511), train_loss = 0.92649911, grad/param norm = 1.7687e-01, time/batch = 18.6506s	
13813/26050 (epoch 26.512), train_loss = 0.85136340, grad/param norm = 1.9313e-01, time/batch = 17.6424s	
13814/26050 (epoch 26.514), train_loss = 1.04710116, grad/param norm = 2.3630e-01, time/batch = 18.0822s	
13815/26050 (epoch 26.516), train_loss = 1.10749979, grad/param norm = 2.3928e-01, time/batch = 19.0719s	
13816/26050 (epoch 26.518), train_loss = 0.96827743, grad/param norm = 2.0281e-01, time/batch = 16.8264s	
13817/26050 (epoch 26.520), train_loss = 0.96577095, grad/param norm = 1.9914e-01, time/batch = 17.5639s	
13818/26050 (epoch 26.522), train_loss = 0.75692862, grad/param norm = 1.6224e-01, time/batch = 18.6424s	
13819/26050 (epoch 26.524), train_loss = 1.03970966, grad/param norm = 2.4147e-01, time/batch = 18.7140s	
13820/26050 (epoch 26.526), train_loss = 1.06448735, grad/param norm = 2.1257e-01, time/batch = 16.1079s	
13821/26050 (epoch 26.528), train_loss = 1.00840631, grad/param norm = 2.0511e-01, time/batch = 18.1536s	
13822/26050 (epoch 26.530), train_loss = 0.91571201, grad/param norm = 2.0149e-01, time/batch = 18.5788s	
13823/26050 (epoch 26.532), train_loss = 1.00854806, grad/param norm = 1.9752e-01, time/batch = 16.8926s	
13824/26050 (epoch 26.534), train_loss = 1.06119125, grad/param norm = 4.6001e-01, time/batch = 15.5420s	
13825/26050 (epoch 26.536), train_loss = 0.98903844, grad/param norm = 1.9573e-01, time/batch = 17.9912s	
13826/26050 (epoch 26.537), train_loss = 1.06156398, grad/param norm = 2.1796e-01, time/batch = 14.5519s	
13827/26050 (epoch 26.539), train_loss = 0.99698690, grad/param norm = 2.1559e-01, time/batch = 16.2958s	
13828/26050 (epoch 26.541), train_loss = 1.16094563, grad/param norm = 2.3950e-01, time/batch = 18.4893s	
13829/26050 (epoch 26.543), train_loss = 0.82889176, grad/param norm = 2.9899e-01, time/batch = 17.9827s	
13830/26050 (epoch 26.545), train_loss = 1.00244641, grad/param norm = 2.1609e-01, time/batch = 17.7241s	
13831/26050 (epoch 26.547), train_loss = 0.95695671, grad/param norm = 2.0110e-01, time/batch = 19.0762s	
13832/26050 (epoch 26.549), train_loss = 0.80924801, grad/param norm = 1.9555e-01, time/batch = 17.8879s	
13833/26050 (epoch 26.551), train_loss = 1.03708184, grad/param norm = 2.0158e-01, time/batch = 17.8130s	
13834/26050 (epoch 26.553), train_loss = 0.92638822, grad/param norm = 1.9830e-01, time/batch = 15.9792s	
13835/26050 (epoch 26.555), train_loss = 0.88275245, grad/param norm = 1.8819e-01, time/batch = 18.9714s	
13836/26050 (epoch 26.557), train_loss = 1.00732050, grad/param norm = 1.8828e-01, time/batch = 18.4923s	
13837/26050 (epoch 26.559), train_loss = 0.97199289, grad/param norm = 1.9905e-01, time/batch = 24.7535s	
13838/26050 (epoch 26.560), train_loss = 0.95314355, grad/param norm = 2.0691e-01, time/batch = 31.3806s	
13839/26050 (epoch 26.562), train_loss = 0.95691606, grad/param norm = 1.9917e-01, time/batch = 15.4968s	
13840/26050 (epoch 26.564), train_loss = 1.13771595, grad/param norm = 2.0253e-01, time/batch = 18.3853s	
13841/26050 (epoch 26.566), train_loss = 0.88500807, grad/param norm = 1.8237e-01, time/batch = 18.0621s	
13842/26050 (epoch 26.568), train_loss = 1.01000567, grad/param norm = 1.9044e-01, time/batch = 17.9738s	
13843/26050 (epoch 26.570), train_loss = 0.99462738, grad/param norm = 2.0469e-01, time/batch = 15.3042s	
13844/26050 (epoch 26.572), train_loss = 0.95880895, grad/param norm = 2.0391e-01, time/batch = 18.2181s	
13845/26050 (epoch 26.574), train_loss = 0.99222740, grad/param norm = 2.3352e-01, time/batch = 17.6428s	
13846/26050 (epoch 26.576), train_loss = 1.02934426, grad/param norm = 2.2913e-01, time/batch = 15.4615s	
13847/26050 (epoch 26.578), train_loss = 0.94323866, grad/param norm = 2.1423e-01, time/batch = 19.0740s	
13848/26050 (epoch 26.580), train_loss = 0.91002851, grad/param norm = 2.0558e-01, time/batch = 18.4134s	
13849/26050 (epoch 26.582), train_loss = 0.98703329, grad/param norm = 1.8592e-01, time/batch = 17.9007s	
13850/26050 (epoch 26.583), train_loss = 1.04787084, grad/param norm = 1.9103e-01, time/batch = 17.2412s	
13851/26050 (epoch 26.585), train_loss = 0.85523974, grad/param norm = 2.1336e-01, time/batch = 17.0593s	
13852/26050 (epoch 26.587), train_loss = 1.00476851, grad/param norm = 2.0392e-01, time/batch = 18.4911s	
13853/26050 (epoch 26.589), train_loss = 1.11925322, grad/param norm = 2.2920e-01, time/batch = 18.2976s	
13854/26050 (epoch 26.591), train_loss = 0.96186976, grad/param norm = 1.8644e-01, time/batch = 18.3934s	
13855/26050 (epoch 26.593), train_loss = 0.84829714, grad/param norm = 1.7783e-01, time/batch = 18.0748s	
13856/26050 (epoch 26.595), train_loss = 1.04207446, grad/param norm = 2.1787e-01, time/batch = 17.1592s	
13857/26050 (epoch 26.597), train_loss = 0.98032499, grad/param norm = 1.9143e-01, time/batch = 18.6432s	
13858/26050 (epoch 26.599), train_loss = 0.99081836, grad/param norm = 1.9920e-01, time/batch = 15.6313s	
13859/26050 (epoch 26.601), train_loss = 1.13505440, grad/param norm = 1.9420e-01, time/batch = 17.7396s	
13860/26050 (epoch 26.603), train_loss = 1.00467118, grad/param norm = 2.0227e-01, time/batch = 17.9019s	
13861/26050 (epoch 26.605), train_loss = 0.93639186, grad/param norm = 2.0395e-01, time/batch = 17.6609s	
13862/26050 (epoch 26.607), train_loss = 1.05347555, grad/param norm = 2.1394e-01, time/batch = 16.5484s	
13863/26050 (epoch 26.608), train_loss = 0.85942326, grad/param norm = 1.7761e-01, time/batch = 15.2262s	
13864/26050 (epoch 26.610), train_loss = 0.96370250, grad/param norm = 1.9024e-01, time/batch = 16.5436s	
13865/26050 (epoch 26.612), train_loss = 0.94970806, grad/param norm = 2.0497e-01, time/batch = 17.5518s	
13866/26050 (epoch 26.614), train_loss = 0.97843856, grad/param norm = 2.0641e-01, time/batch = 17.6579s	
13867/26050 (epoch 26.616), train_loss = 1.08066098, grad/param norm = 2.3429e-01, time/batch = 18.4818s	
13868/26050 (epoch 26.618), train_loss = 0.91165423, grad/param norm = 1.9108e-01, time/batch = 18.4012s	
13869/26050 (epoch 26.620), train_loss = 1.00829930, grad/param norm = 1.9344e-01, time/batch = 18.7215s	
13870/26050 (epoch 26.622), train_loss = 0.86682034, grad/param norm = 1.6607e-01, time/batch = 16.1390s	
13871/26050 (epoch 26.624), train_loss = 0.82244363, grad/param norm = 1.7811e-01, time/batch = 17.7215s	
13872/26050 (epoch 26.626), train_loss = 1.02905885, grad/param norm = 2.0113e-01, time/batch = 17.6593s	
13873/26050 (epoch 26.628), train_loss = 0.89700655, grad/param norm = 1.8429e-01, time/batch = 17.4860s	
13874/26050 (epoch 26.630), train_loss = 1.09295823, grad/param norm = 1.8949e-01, time/batch = 18.3269s	
13875/26050 (epoch 26.631), train_loss = 1.12509565, grad/param norm = 2.0405e-01, time/batch = 17.1547s	
13876/26050 (epoch 26.633), train_loss = 0.87351146, grad/param norm = 1.9199e-01, time/batch = 17.4835s	
13877/26050 (epoch 26.635), train_loss = 0.91503562, grad/param norm = 2.0252e-01, time/batch = 18.0662s	
13878/26050 (epoch 26.637), train_loss = 0.86431388, grad/param norm = 1.8653e-01, time/batch = 17.8363s	
13879/26050 (epoch 26.639), train_loss = 1.04944601, grad/param norm = 2.0033e-01, time/batch = 14.9656s	
13880/26050 (epoch 26.641), train_loss = 0.92328396, grad/param norm = 1.9117e-01, time/batch = 17.0699s	
13881/26050 (epoch 26.643), train_loss = 0.86923728, grad/param norm = 1.5765e-01, time/batch = 17.3132s	
13882/26050 (epoch 26.645), train_loss = 0.91292851, grad/param norm = 1.8790e-01, time/batch = 15.1411s	
13883/26050 (epoch 26.647), train_loss = 0.91288135, grad/param norm = 2.1000e-01, time/batch = 17.9985s	
13884/26050 (epoch 26.649), train_loss = 0.96561584, grad/param norm = 2.5441e-01, time/batch = 17.8304s	
13885/26050 (epoch 26.651), train_loss = 0.91339112, grad/param norm = 2.0291e-01, time/batch = 18.6670s	
13886/26050 (epoch 26.653), train_loss = 0.94501570, grad/param norm = 1.8482e-01, time/batch = 18.2300s	
13887/26050 (epoch 26.655), train_loss = 0.87144783, grad/param norm = 1.7683e-01, time/batch = 17.2271s	
13888/26050 (epoch 26.656), train_loss = 0.82518998, grad/param norm = 1.6214e-01, time/batch = 14.9863s	
13889/26050 (epoch 26.658), train_loss = 1.13557229, grad/param norm = 2.1528e-01, time/batch = 17.1444s	
13890/26050 (epoch 26.660), train_loss = 0.82986427, grad/param norm = 1.9722e-01, time/batch = 15.8850s	
13891/26050 (epoch 26.662), train_loss = 0.95003362, grad/param norm = 2.0461e-01, time/batch = 17.8179s	
13892/26050 (epoch 26.664), train_loss = 0.93333445, grad/param norm = 1.9612e-01, time/batch = 15.3080s	
13893/26050 (epoch 26.666), train_loss = 0.89471060, grad/param norm = 1.9574e-01, time/batch = 17.6683s	
13894/26050 (epoch 26.668), train_loss = 0.78132674, grad/param norm = 2.2688e-01, time/batch = 16.9632s	
13895/26050 (epoch 26.670), train_loss = 1.10577173, grad/param norm = 2.7429e-01, time/batch = 18.7977s	
13896/26050 (epoch 26.672), train_loss = 0.96580649, grad/param norm = 2.0091e-01, time/batch = 18.0602s	
13897/26050 (epoch 26.674), train_loss = 0.86083062, grad/param norm = 2.0266e-01, time/batch = 17.6575s	
13898/26050 (epoch 26.676), train_loss = 1.00982850, grad/param norm = 1.9395e-01, time/batch = 17.8258s	
13899/26050 (epoch 26.678), train_loss = 1.06619058, grad/param norm = 2.0872e-01, time/batch = 18.3259s	
13900/26050 (epoch 26.679), train_loss = 1.13000301, grad/param norm = 2.2198e-01, time/batch = 15.5465s	
13901/26050 (epoch 26.681), train_loss = 0.96746973, grad/param norm = 1.9960e-01, time/batch = 17.2897s	
13902/26050 (epoch 26.683), train_loss = 0.86050621, grad/param norm = 2.2626e-01, time/batch = 17.9837s	
13903/26050 (epoch 26.685), train_loss = 0.94553633, grad/param norm = 1.9299e-01, time/batch = 17.6661s	
13904/26050 (epoch 26.687), train_loss = 0.84365388, grad/param norm = 1.8863e-01, time/batch = 17.0752s	
13905/26050 (epoch 26.689), train_loss = 0.92771134, grad/param norm = 2.1832e-01, time/batch = 18.4840s	
13906/26050 (epoch 26.691), train_loss = 0.78757884, grad/param norm = 1.7030e-01, time/batch = 18.7431s	
13907/26050 (epoch 26.693), train_loss = 0.88155566, grad/param norm = 1.8709e-01, time/batch = 17.8961s	
13908/26050 (epoch 26.695), train_loss = 0.95541549, grad/param norm = 1.7439e-01, time/batch = 17.5743s	
13909/26050 (epoch 26.697), train_loss = 0.88718506, grad/param norm = 2.0917e-01, time/batch = 17.3936s	
13910/26050 (epoch 26.699), train_loss = 1.01149339, grad/param norm = 2.1408e-01, time/batch = 17.5812s	
13911/26050 (epoch 26.701), train_loss = 0.86266954, grad/param norm = 1.6415e-01, time/batch = 17.8231s	
13912/26050 (epoch 26.702), train_loss = 1.05820128, grad/param norm = 2.0041e-01, time/batch = 18.4831s	
13913/26050 (epoch 26.704), train_loss = 1.05132121, grad/param norm = 1.8420e-01, time/batch = 16.8830s	
13914/26050 (epoch 26.706), train_loss = 0.90265691, grad/param norm = 2.0092e-01, time/batch = 17.7271s	
13915/26050 (epoch 26.708), train_loss = 1.04406856, grad/param norm = 2.1142e-01, time/batch = 18.5719s	
13916/26050 (epoch 26.710), train_loss = 0.99246461, grad/param norm = 2.1234e-01, time/batch = 16.6561s	
13917/26050 (epoch 26.712), train_loss = 0.96932674, grad/param norm = 1.9881e-01, time/batch = 17.8189s	
13918/26050 (epoch 26.714), train_loss = 0.83765361, grad/param norm = 1.7643e-01, time/batch = 17.3852s	
13919/26050 (epoch 26.716), train_loss = 1.21280876, grad/param norm = 2.4015e-01, time/batch = 18.7257s	
13920/26050 (epoch 26.718), train_loss = 1.01959938, grad/param norm = 1.9299e-01, time/batch = 18.1531s	
13921/26050 (epoch 26.720), train_loss = 0.95581805, grad/param norm = 2.0994e-01, time/batch = 16.2985s	
13922/26050 (epoch 26.722), train_loss = 0.84124497, grad/param norm = 1.6045e-01, time/batch = 15.6457s	
13923/26050 (epoch 26.724), train_loss = 0.88566300, grad/param norm = 1.9276e-01, time/batch = 18.0490s	
13924/26050 (epoch 26.726), train_loss = 0.99725449, grad/param norm = 1.9750e-01, time/batch = 17.8944s	
13925/26050 (epoch 26.727), train_loss = 1.01757640, grad/param norm = 1.9873e-01, time/batch = 17.3901s	
13926/26050 (epoch 26.729), train_loss = 0.99101706, grad/param norm = 1.9000e-01, time/batch = 18.7317s	
13927/26050 (epoch 26.731), train_loss = 0.99605060, grad/param norm = 1.9278e-01, time/batch = 18.2317s	
13928/26050 (epoch 26.733), train_loss = 0.94447737, grad/param norm = 2.6212e-01, time/batch = 14.9768s	
13929/26050 (epoch 26.735), train_loss = 1.13764490, grad/param norm = 2.0698e-01, time/batch = 17.8763s	
13930/26050 (epoch 26.737), train_loss = 0.90923399, grad/param norm = 2.0501e-01, time/batch = 18.3254s	
13931/26050 (epoch 26.739), train_loss = 0.98956054, grad/param norm = 1.8970e-01, time/batch = 17.8125s	
13932/26050 (epoch 26.741), train_loss = 0.88728305, grad/param norm = 1.9173e-01, time/batch = 18.4085s	
13933/26050 (epoch 26.743), train_loss = 0.99081106, grad/param norm = 2.4163e-01, time/batch = 16.7236s	
13934/26050 (epoch 26.745), train_loss = 0.84164797, grad/param norm = 1.8211e-01, time/batch = 17.0497s	
13935/26050 (epoch 26.747), train_loss = 0.87858869, grad/param norm = 1.7975e-01, time/batch = 17.9857s	
13936/26050 (epoch 26.749), train_loss = 1.07111443, grad/param norm = 2.1027e-01, time/batch = 17.5699s	
13937/26050 (epoch 26.750), train_loss = 0.95335842, grad/param norm = 1.6653e-01, time/batch = 16.6379s	
13938/26050 (epoch 26.752), train_loss = 0.92141930, grad/param norm = 2.3311e-01, time/batch = 16.8807s	
13939/26050 (epoch 26.754), train_loss = 0.97359614, grad/param norm = 1.9647e-01, time/batch = 18.0452s	
13940/26050 (epoch 26.756), train_loss = 0.94806307, grad/param norm = 2.3032e-01, time/batch = 18.7434s	
13941/26050 (epoch 26.758), train_loss = 0.92958687, grad/param norm = 2.0804e-01, time/batch = 15.6435s	
13942/26050 (epoch 26.760), train_loss = 1.11999449, grad/param norm = 2.1996e-01, time/batch = 18.6256s	
13943/26050 (epoch 26.762), train_loss = 0.92006446, grad/param norm = 2.2615e-01, time/batch = 17.8966s	
13944/26050 (epoch 26.764), train_loss = 0.94344362, grad/param norm = 2.1200e-01, time/batch = 18.2342s	
13945/26050 (epoch 26.766), train_loss = 0.99298010, grad/param norm = 2.0467e-01, time/batch = 17.0710s	
13946/26050 (epoch 26.768), train_loss = 0.84797920, grad/param norm = 1.7409e-01, time/batch = 18.0657s	
13947/26050 (epoch 26.770), train_loss = 0.93852386, grad/param norm = 1.9477e-01, time/batch = 18.7293s	
13948/26050 (epoch 26.772), train_loss = 0.95676307, grad/param norm = 1.8009e-01, time/batch = 17.4566s	
13949/26050 (epoch 26.774), train_loss = 0.83197739, grad/param norm = 2.1247e-01, time/batch = 18.6439s	
13950/26050 (epoch 26.775), train_loss = 0.68619703, grad/param norm = 1.7862e-01, time/batch = 18.4922s	
13951/26050 (epoch 26.777), train_loss = 0.89927031, grad/param norm = 1.9171e-01, time/batch = 17.5685s	
13952/26050 (epoch 26.779), train_loss = 0.94410447, grad/param norm = 2.2282e-01, time/batch = 15.8847s	
13953/26050 (epoch 26.781), train_loss = 0.84413499, grad/param norm = 2.0295e-01, time/batch = 15.4588s	
13954/26050 (epoch 26.783), train_loss = 0.82396407, grad/param norm = 1.7747e-01, time/batch = 15.3888s	
13955/26050 (epoch 26.785), train_loss = 0.97314088, grad/param norm = 2.0488e-01, time/batch = 16.8540s	
13956/26050 (epoch 26.787), train_loss = 0.86804680, grad/param norm = 1.9495e-01, time/batch = 18.4781s	
13957/26050 (epoch 26.789), train_loss = 0.89076287, grad/param norm = 1.9865e-01, time/batch = 18.3146s	
13958/26050 (epoch 26.791), train_loss = 0.88146466, grad/param norm = 1.9220e-01, time/batch = 17.2374s	
13959/26050 (epoch 26.793), train_loss = 0.92008700, grad/param norm = 1.9646e-01, time/batch = 17.7311s	
13960/26050 (epoch 26.795), train_loss = 0.77233413, grad/param norm = 1.5321e-01, time/batch = 16.6628s	
13961/26050 (epoch 26.797), train_loss = 0.85243452, grad/param norm = 2.0624e-01, time/batch = 18.0723s	
13962/26050 (epoch 26.798), train_loss = 0.82231185, grad/param norm = 1.9166e-01, time/batch = 17.0730s	
13963/26050 (epoch 26.800), train_loss = 0.82445919, grad/param norm = 1.7715e-01, time/batch = 15.0042s	
13964/26050 (epoch 26.802), train_loss = 0.89672841, grad/param norm = 1.8248e-01, time/batch = 14.4146s	
13965/26050 (epoch 26.804), train_loss = 0.93346582, grad/param norm = 1.9005e-01, time/batch = 14.4798s	
13966/26050 (epoch 26.806), train_loss = 1.02264955, grad/param norm = 2.0482e-01, time/batch = 14.5443s	
13967/26050 (epoch 26.808), train_loss = 0.94374486, grad/param norm = 1.9039e-01, time/batch = 18.0572s	
13968/26050 (epoch 26.810), train_loss = 0.89526999, grad/param norm = 2.1427e-01, time/batch = 18.5630s	
13969/26050 (epoch 26.812), train_loss = 0.82980278, grad/param norm = 2.0375e-01, time/batch = 17.6539s	
13970/26050 (epoch 26.814), train_loss = 0.87539433, grad/param norm = 2.2213e-01, time/batch = 15.9830s	
13971/26050 (epoch 26.816), train_loss = 1.01427615, grad/param norm = 2.2912e-01, time/batch = 18.0679s	
13972/26050 (epoch 26.818), train_loss = 1.03951779, grad/param norm = 2.2390e-01, time/batch = 18.6633s	
13973/26050 (epoch 26.820), train_loss = 0.96725206, grad/param norm = 1.9024e-01, time/batch = 16.8935s	
13974/26050 (epoch 26.821), train_loss = 1.06234792, grad/param norm = 2.2519e-01, time/batch = 17.3051s	
13975/26050 (epoch 26.823), train_loss = 1.11638946, grad/param norm = 2.0723e-01, time/batch = 16.8008s	
13976/26050 (epoch 26.825), train_loss = 0.94046421, grad/param norm = 1.8789e-01, time/batch = 17.6542s	
13977/26050 (epoch 26.827), train_loss = 0.96781726, grad/param norm = 2.0802e-01, time/batch = 14.9771s	
13978/26050 (epoch 26.829), train_loss = 1.00212067, grad/param norm = 1.9172e-01, time/batch = 18.6443s	
13979/26050 (epoch 26.831), train_loss = 1.09525232, grad/param norm = 2.1313e-01, time/batch = 18.1701s	
13980/26050 (epoch 26.833), train_loss = 1.11670723, grad/param norm = 2.3286e-01, time/batch = 18.3048s	
13981/26050 (epoch 26.835), train_loss = 1.11864075, grad/param norm = 1.9449e-01, time/batch = 17.9927s	
13982/26050 (epoch 26.837), train_loss = 0.93695011, grad/param norm = 1.7995e-01, time/batch = 16.5609s	
13983/26050 (epoch 26.839), train_loss = 0.93631855, grad/param norm = 1.9776e-01, time/batch = 16.2068s	
13984/26050 (epoch 26.841), train_loss = 1.06926305, grad/param norm = 2.0248e-01, time/batch = 18.8147s	
13985/26050 (epoch 26.843), train_loss = 0.92337254, grad/param norm = 1.8469e-01, time/batch = 18.9045s	
13986/26050 (epoch 26.845), train_loss = 0.91719618, grad/param norm = 1.8827e-01, time/batch = 17.4036s	
13987/26050 (epoch 26.846), train_loss = 1.01406923, grad/param norm = 2.1126e-01, time/batch = 17.8173s	
13988/26050 (epoch 26.848), train_loss = 0.94057053, grad/param norm = 1.9083e-01, time/batch = 18.5561s	
13989/26050 (epoch 26.850), train_loss = 0.86526428, grad/param norm = 1.8631e-01, time/batch = 18.9094s	
13990/26050 (epoch 26.852), train_loss = 0.97356972, grad/param norm = 1.9783e-01, time/batch = 17.7917s	
13991/26050 (epoch 26.854), train_loss = 0.93895524, grad/param norm = 1.9308e-01, time/batch = 18.6527s	
13992/26050 (epoch 26.856), train_loss = 0.89913385, grad/param norm = 2.0085e-01, time/batch = 18.1617s	
13993/26050 (epoch 26.858), train_loss = 0.87359439, grad/param norm = 1.8381e-01, time/batch = 17.1164s	
13994/26050 (epoch 26.860), train_loss = 0.99678370, grad/param norm = 2.1458e-01, time/batch = 17.2393s	
13995/26050 (epoch 26.862), train_loss = 1.02774322, grad/param norm = 2.0991e-01, time/batch = 18.3191s	
13996/26050 (epoch 26.864), train_loss = 0.97716130, grad/param norm = 2.1263e-01, time/batch = 15.1510s	
13997/26050 (epoch 26.866), train_loss = 0.91057776, grad/param norm = 1.8325e-01, time/batch = 17.9064s	
13998/26050 (epoch 26.868), train_loss = 0.99239737, grad/param norm = 1.9781e-01, time/batch = 16.9800s	
13999/26050 (epoch 26.869), train_loss = 0.84930514, grad/param norm = 1.7935e-01, time/batch = 16.3023s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch26.87_1.7838.t7	
14000/26050 (epoch 26.871), train_loss = 0.78010578, grad/param norm = 1.6782e-01, time/batch = 17.3231s	
14001/26050 (epoch 26.873), train_loss = 1.33553928, grad/param norm = 2.5398e-01, time/batch = 16.8763s	
14002/26050 (epoch 26.875), train_loss = 0.96046021, grad/param norm = 2.1423e-01, time/batch = 18.4042s	
14003/26050 (epoch 26.877), train_loss = 0.86019161, grad/param norm = 1.9558e-01, time/batch = 15.2207s	
14004/26050 (epoch 26.879), train_loss = 0.98645033, grad/param norm = 1.8877e-01, time/batch = 17.6277s	
14005/26050 (epoch 26.881), train_loss = 1.05991273, grad/param norm = 2.1745e-01, time/batch = 17.9042s	
14006/26050 (epoch 26.883), train_loss = 1.01053279, grad/param norm = 2.0386e-01, time/batch = 18.0721s	
14007/26050 (epoch 26.885), train_loss = 0.73893320, grad/param norm = 1.7384e-01, time/batch = 16.0596s	
14008/26050 (epoch 26.887), train_loss = 1.00377362, grad/param norm = 2.0400e-01, time/batch = 14.4768s	
14009/26050 (epoch 26.889), train_loss = 0.89519553, grad/param norm = 1.8602e-01, time/batch = 18.3872s	
14010/26050 (epoch 26.891), train_loss = 0.78563376, grad/param norm = 1.7473e-01, time/batch = 18.4017s	
14011/26050 (epoch 26.893), train_loss = 0.83196028, grad/param norm = 1.7308e-01, time/batch = 18.1435s	
14012/26050 (epoch 26.894), train_loss = 0.91876074, grad/param norm = 1.7944e-01, time/batch = 18.5709s	
14013/26050 (epoch 26.896), train_loss = 1.04297952, grad/param norm = 2.3607e-01, time/batch = 18.6442s	
14014/26050 (epoch 26.898), train_loss = 0.90063964, grad/param norm = 1.9369e-01, time/batch = 17.6468s	
14015/26050 (epoch 26.900), train_loss = 0.99683124, grad/param norm = 2.0082e-01, time/batch = 18.2340s	
14016/26050 (epoch 26.902), train_loss = 0.94901680, grad/param norm = 2.1323e-01, time/batch = 18.3894s	
14017/26050 (epoch 26.904), train_loss = 0.90636351, grad/param norm = 1.8610e-01, time/batch = 17.7286s	
14018/26050 (epoch 26.906), train_loss = 0.92823607, grad/param norm = 2.1177e-01, time/batch = 18.6420s	
14019/26050 (epoch 26.908), train_loss = 0.95454401, grad/param norm = 1.8971e-01, time/batch = 18.2199s	
14020/26050 (epoch 26.910), train_loss = 0.91850509, grad/param norm = 1.7269e-01, time/batch = 18.7476s	
14021/26050 (epoch 26.912), train_loss = 1.13321388, grad/param norm = 2.1814e-01, time/batch = 17.5684s	
14022/26050 (epoch 26.914), train_loss = 1.32069544, grad/param norm = 2.3288e-01, time/batch = 18.4030s	
14023/26050 (epoch 26.916), train_loss = 1.05258285, grad/param norm = 2.4387e-01, time/batch = 17.8941s	
14024/26050 (epoch 26.917), train_loss = 0.96379935, grad/param norm = 2.1767e-01, time/batch = 17.5468s	
14025/26050 (epoch 26.919), train_loss = 0.99819571, grad/param norm = 2.0434e-01, time/batch = 17.4471s	
14026/26050 (epoch 26.921), train_loss = 0.91051844, grad/param norm = 2.0442e-01, time/batch = 16.7104s	
14027/26050 (epoch 26.923), train_loss = 0.95500969, grad/param norm = 1.8814e-01, time/batch = 18.0692s	
14028/26050 (epoch 26.925), train_loss = 0.95460307, grad/param norm = 1.9381e-01, time/batch = 15.4847s	
14029/26050 (epoch 26.927), train_loss = 0.85558960, grad/param norm = 1.6108e-01, time/batch = 17.0482s	
14030/26050 (epoch 26.929), train_loss = 0.81439828, grad/param norm = 1.6716e-01, time/batch = 18.8206s	
14031/26050 (epoch 26.931), train_loss = 1.13082519, grad/param norm = 2.7660e-01, time/batch = 16.9055s	
14032/26050 (epoch 26.933), train_loss = 0.90375305, grad/param norm = 1.8843e-01, time/batch = 18.4819s	
14033/26050 (epoch 26.935), train_loss = 0.91026561, grad/param norm = 1.8243e-01, time/batch = 18.9046s	
14034/26050 (epoch 26.937), train_loss = 1.03951246, grad/param norm = 1.8865e-01, time/batch = 17.1625s	
14035/26050 (epoch 26.939), train_loss = 0.86694693, grad/param norm = 1.6851e-01, time/batch = 30.8292s	
14036/26050 (epoch 26.940), train_loss = 0.90195667, grad/param norm = 1.7321e-01, time/batch = 24.2422s	
14037/26050 (epoch 26.942), train_loss = 0.93322664, grad/param norm = 1.8880e-01, time/batch = 18.5801s	
14038/26050 (epoch 26.944), train_loss = 0.90769699, grad/param norm = 1.8525e-01, time/batch = 18.3986s	
14039/26050 (epoch 26.946), train_loss = 1.06643804, grad/param norm = 1.9201e-01, time/batch = 18.3110s	
14040/26050 (epoch 26.948), train_loss = 0.81123400, grad/param norm = 1.8861e-01, time/batch = 16.6460s	
14041/26050 (epoch 26.950), train_loss = 0.91892947, grad/param norm = 1.8885e-01, time/batch = 17.5758s	
14042/26050 (epoch 26.952), train_loss = 1.00845581, grad/param norm = 2.0107e-01, time/batch = 17.8814s	
14043/26050 (epoch 26.954), train_loss = 1.04544971, grad/param norm = 1.9816e-01, time/batch = 18.1578s	
14044/26050 (epoch 26.956), train_loss = 0.93060222, grad/param norm = 1.9771e-01, time/batch = 18.6446s	
14045/26050 (epoch 26.958), train_loss = 0.86301418, grad/param norm = 1.6206e-01, time/batch = 17.9908s	
14046/26050 (epoch 26.960), train_loss = 0.97440935, grad/param norm = 1.9918e-01, time/batch = 18.1577s	
14047/26050 (epoch 26.962), train_loss = 0.91624945, grad/param norm = 1.7971e-01, time/batch = 18.1448s	
14048/26050 (epoch 26.964), train_loss = 0.94222927, grad/param norm = 1.8622e-01, time/batch = 18.8211s	
14049/26050 (epoch 26.965), train_loss = 0.86839616, grad/param norm = 2.3242e-01, time/batch = 18.5619s	
14050/26050 (epoch 26.967), train_loss = 1.26594748, grad/param norm = 2.1437e-01, time/batch = 15.3645s	
14051/26050 (epoch 26.969), train_loss = 0.98218576, grad/param norm = 2.1396e-01, time/batch = 18.0483s	
14052/26050 (epoch 26.971), train_loss = 0.91087559, grad/param norm = 1.7502e-01, time/batch = 17.7255s	
14053/26050 (epoch 26.973), train_loss = 0.95153458, grad/param norm = 1.9778e-01, time/batch = 17.9835s	
14054/26050 (epoch 26.975), train_loss = 1.00369825, grad/param norm = 2.0502e-01, time/batch = 18.3225s	
14055/26050 (epoch 26.977), train_loss = 0.95252724, grad/param norm = 1.6680e-01, time/batch = 18.1472s	
14056/26050 (epoch 26.979), train_loss = 0.78787709, grad/param norm = 1.9643e-01, time/batch = 17.5707s	
14057/26050 (epoch 26.981), train_loss = 1.08002456, grad/param norm = 1.9573e-01, time/batch = 16.5782s	
14058/26050 (epoch 26.983), train_loss = 1.02561343, grad/param norm = 1.9037e-01, time/batch = 17.5584s	
14059/26050 (epoch 26.985), train_loss = 1.00138849, grad/param norm = 1.9455e-01, time/batch = 18.8224s	
14060/26050 (epoch 26.987), train_loss = 1.05408514, grad/param norm = 1.9633e-01, time/batch = 17.4020s	
14061/26050 (epoch 26.988), train_loss = 1.00947550, grad/param norm = 1.9911e-01, time/batch = 18.0555s	
14062/26050 (epoch 26.990), train_loss = 0.83948983, grad/param norm = 1.7437e-01, time/batch = 15.8945s	
14063/26050 (epoch 26.992), train_loss = 1.09507067, grad/param norm = 1.9430e-01, time/batch = 15.7912s	
14064/26050 (epoch 26.994), train_loss = 0.91215128, grad/param norm = 2.0299e-01, time/batch = 17.3045s	
14065/26050 (epoch 26.996), train_loss = 0.89242727, grad/param norm = 2.2644e-01, time/batch = 18.1448s	
14066/26050 (epoch 26.998), train_loss = 0.97801829, grad/param norm = 2.3336e-01, time/batch = 19.0590s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
14067/26050 (epoch 27.000), train_loss = 0.91416928, grad/param norm = 2.2822e-01, time/batch = 16.4772s	
14068/26050 (epoch 27.002), train_loss = 1.00616303, grad/param norm = 2.0222e-01, time/batch = 18.0782s	
14069/26050 (epoch 27.004), train_loss = 0.85537235, grad/param norm = 1.8880e-01, time/batch = 18.1428s	
14070/26050 (epoch 27.006), train_loss = 0.88011763, grad/param norm = 2.0367e-01, time/batch = 16.7893s	
14071/26050 (epoch 27.008), train_loss = 0.89185588, grad/param norm = 1.9153e-01, time/batch = 16.2893s	
14072/26050 (epoch 27.010), train_loss = 0.89479772, grad/param norm = 2.0468e-01, time/batch = 18.4770s	
14073/26050 (epoch 27.012), train_loss = 0.95469513, grad/param norm = 1.8322e-01, time/batch = 18.6575s	
14074/26050 (epoch 27.013), train_loss = 1.22902038, grad/param norm = 2.4711e-01, time/batch = 18.0573s	
14075/26050 (epoch 27.015), train_loss = 0.93958762, grad/param norm = 1.9895e-01, time/batch = 16.2855s	
14076/26050 (epoch 27.017), train_loss = 0.96346209, grad/param norm = 1.8720e-01, time/batch = 16.9027s	
14077/26050 (epoch 27.019), train_loss = 0.84601758, grad/param norm = 1.7615e-01, time/batch = 17.8798s	
14078/26050 (epoch 27.021), train_loss = 1.03165941, grad/param norm = 1.9659e-01, time/batch = 17.5575s	
14079/26050 (epoch 27.023), train_loss = 0.79104340, grad/param norm = 1.7612e-01, time/batch = 17.0752s	
14080/26050 (epoch 27.025), train_loss = 0.94177542, grad/param norm = 1.8540e-01, time/batch = 15.7906s	
14081/26050 (epoch 27.027), train_loss = 0.78226934, grad/param norm = 1.8899e-01, time/batch = 18.4666s	
14082/26050 (epoch 27.029), train_loss = 0.96918388, grad/param norm = 1.8540e-01, time/batch = 17.7357s	
14083/26050 (epoch 27.031), train_loss = 1.06892253, grad/param norm = 2.0770e-01, time/batch = 18.9935s	
14084/26050 (epoch 27.033), train_loss = 0.97056032, grad/param norm = 1.9383e-01, time/batch = 17.0497s	
14085/26050 (epoch 27.035), train_loss = 0.98517428, grad/param norm = 2.0710e-01, time/batch = 18.7259s	
14086/26050 (epoch 27.036), train_loss = 0.82533809, grad/param norm = 1.8533e-01, time/batch = 15.3019s	
14087/26050 (epoch 27.038), train_loss = 0.76153932, grad/param norm = 1.8536e-01, time/batch = 16.7046s	
14088/26050 (epoch 27.040), train_loss = 0.92661764, grad/param norm = 1.8819e-01, time/batch = 18.3083s	
14089/26050 (epoch 27.042), train_loss = 0.79996940, grad/param norm = 1.8004e-01, time/batch = 18.0595s	
14090/26050 (epoch 27.044), train_loss = 1.01114982, grad/param norm = 1.7851e-01, time/batch = 15.8693s	
14091/26050 (epoch 27.046), train_loss = 0.77305787, grad/param norm = 1.6218e-01, time/batch = 16.0349s	
14092/26050 (epoch 27.048), train_loss = 0.95634359, grad/param norm = 1.9061e-01, time/batch = 17.7973s	
14093/26050 (epoch 27.050), train_loss = 0.88038200, grad/param norm = 1.7591e-01, time/batch = 18.2482s	
14094/26050 (epoch 27.052), train_loss = 0.87349706, grad/param norm = 2.1207e-01, time/batch = 18.0773s	
14095/26050 (epoch 27.054), train_loss = 0.78490069, grad/param norm = 1.7087e-01, time/batch = 15.8854s	
14096/26050 (epoch 27.056), train_loss = 0.76329699, grad/param norm = 1.5839e-01, time/batch = 18.1618s	
14097/26050 (epoch 27.058), train_loss = 0.90829476, grad/param norm = 1.7209e-01, time/batch = 18.4823s	
14098/26050 (epoch 27.060), train_loss = 1.01828570, grad/param norm = 1.9792e-01, time/batch = 18.6377s	
14099/26050 (epoch 27.061), train_loss = 0.85247575, grad/param norm = 1.7770e-01, time/batch = 18.4946s	
14100/26050 (epoch 27.063), train_loss = 0.95884283, grad/param norm = 1.8214e-01, time/batch = 18.8230s	
14101/26050 (epoch 27.065), train_loss = 0.75710357, grad/param norm = 1.5191e-01, time/batch = 17.0655s	
14102/26050 (epoch 27.067), train_loss = 0.91758235, grad/param norm = 1.9578e-01, time/batch = 18.0705s	
14103/26050 (epoch 27.069), train_loss = 0.97200646, grad/param norm = 2.0371e-01, time/batch = 18.0769s	
14104/26050 (epoch 27.071), train_loss = 0.97148727, grad/param norm = 1.7717e-01, time/batch = 17.7383s	
14105/26050 (epoch 27.073), train_loss = 1.08610195, grad/param norm = 2.0525e-01, time/batch = 16.8117s	
14106/26050 (epoch 27.075), train_loss = 0.88624453, grad/param norm = 1.8409e-01, time/batch = 17.2067s	
14107/26050 (epoch 27.077), train_loss = 0.90718761, grad/param norm = 1.9727e-01, time/batch = 18.4921s	
14108/26050 (epoch 27.079), train_loss = 0.92953481, grad/param norm = 1.9319e-01, time/batch = 15.1980s	
14109/26050 (epoch 27.081), train_loss = 0.90604594, grad/param norm = 1.7785e-01, time/batch = 17.8112s	
14110/26050 (epoch 27.083), train_loss = 1.03744242, grad/param norm = 1.8155e-01, time/batch = 18.0536s	
14111/26050 (epoch 27.084), train_loss = 0.96451332, grad/param norm = 2.1298e-01, time/batch = 16.4558s	
14112/26050 (epoch 27.086), train_loss = 1.10791152, grad/param norm = 2.1196e-01, time/batch = 15.8894s	
14113/26050 (epoch 27.088), train_loss = 0.88903909, grad/param norm = 1.8301e-01, time/batch = 17.2274s	
14114/26050 (epoch 27.090), train_loss = 0.95511769, grad/param norm = 1.9579e-01, time/batch = 18.5598s	
14115/26050 (epoch 27.092), train_loss = 0.99101269, grad/param norm = 1.7388e-01, time/batch = 18.3983s	
14116/26050 (epoch 27.094), train_loss = 0.84627410, grad/param norm = 1.8672e-01, time/batch = 18.0607s	
14117/26050 (epoch 27.096), train_loss = 0.96114310, grad/param norm = 1.9033e-01, time/batch = 16.4755s	
14118/26050 (epoch 27.098), train_loss = 0.88733019, grad/param norm = 1.8954e-01, time/batch = 17.0443s	
14119/26050 (epoch 27.100), train_loss = 0.85005961, grad/param norm = 1.8964e-01, time/batch = 18.6536s	
14120/26050 (epoch 27.102), train_loss = 0.99350124, grad/param norm = 1.9264e-01, time/batch = 17.9886s	
14121/26050 (epoch 27.104), train_loss = 0.90181549, grad/param norm = 1.9889e-01, time/batch = 17.9000s	
14122/26050 (epoch 27.106), train_loss = 0.94323948, grad/param norm = 1.9516e-01, time/batch = 14.6332s	
14123/26050 (epoch 27.107), train_loss = 0.76081717, grad/param norm = 1.6794e-01, time/batch = 18.2189s	
14124/26050 (epoch 27.109), train_loss = 0.84779932, grad/param norm = 1.7961e-01, time/batch = 15.3181s	
14125/26050 (epoch 27.111), train_loss = 1.09302491, grad/param norm = 2.0643e-01, time/batch = 17.6382s	
14126/26050 (epoch 27.113), train_loss = 0.88890232, grad/param norm = 1.7949e-01, time/batch = 18.2302s	
14127/26050 (epoch 27.115), train_loss = 1.02625335, grad/param norm = 2.0371e-01, time/batch = 17.9038s	
14128/26050 (epoch 27.117), train_loss = 0.92831569, grad/param norm = 1.9795e-01, time/batch = 17.1295s	
14129/26050 (epoch 27.119), train_loss = 0.78417576, grad/param norm = 1.8249e-01, time/batch = 18.2197s	
14130/26050 (epoch 27.121), train_loss = 0.95436168, grad/param norm = 1.9435e-01, time/batch = 18.6410s	
14131/26050 (epoch 27.123), train_loss = 0.86821358, grad/param norm = 2.0560e-01, time/batch = 16.3555s	
14132/26050 (epoch 27.125), train_loss = 0.82190663, grad/param norm = 1.7149e-01, time/batch = 17.8806s	
14133/26050 (epoch 27.127), train_loss = 0.76743256, grad/param norm = 1.9308e-01, time/batch = 18.7347s	
14134/26050 (epoch 27.129), train_loss = 0.77272100, grad/param norm = 1.7928e-01, time/batch = 18.0652s	
14135/26050 (epoch 27.131), train_loss = 0.90390823, grad/param norm = 2.0833e-01, time/batch = 15.8833s	
14136/26050 (epoch 27.132), train_loss = 0.89997236, grad/param norm = 1.6691e-01, time/batch = 15.8074s	
14137/26050 (epoch 27.134), train_loss = 0.94651681, grad/param norm = 2.1324e-01, time/batch = 18.1617s	
14138/26050 (epoch 27.136), train_loss = 0.92072705, grad/param norm = 1.9974e-01, time/batch = 18.0549s	
14139/26050 (epoch 27.138), train_loss = 0.70425929, grad/param norm = 1.7876e-01, time/batch = 17.6405s	
14140/26050 (epoch 27.140), train_loss = 0.78197258, grad/param norm = 1.9392e-01, time/batch = 18.8106s	
14141/26050 (epoch 27.142), train_loss = 0.81649657, grad/param norm = 1.9191e-01, time/batch = 15.8054s	
14142/26050 (epoch 27.144), train_loss = 0.74431009, grad/param norm = 1.8712e-01, time/batch = 16.7553s	
14143/26050 (epoch 27.146), train_loss = 0.68063716, grad/param norm = 1.5793e-01, time/batch = 18.5704s	
14144/26050 (epoch 27.148), train_loss = 0.72707864, grad/param norm = 1.4964e-01, time/batch = 17.5822s	
14145/26050 (epoch 27.150), train_loss = 0.89178020, grad/param norm = 2.2419e-01, time/batch = 17.7227s	
14146/26050 (epoch 27.152), train_loss = 1.07219107, grad/param norm = 2.3385e-01, time/batch = 18.1571s	
14147/26050 (epoch 27.154), train_loss = 0.73946962, grad/param norm = 1.7598e-01, time/batch = 17.5464s	
14148/26050 (epoch 27.155), train_loss = 0.79617513, grad/param norm = 2.0350e-01, time/batch = 18.2239s	
14149/26050 (epoch 27.157), train_loss = 0.90461545, grad/param norm = 2.3783e-01, time/batch = 17.5338s	
14150/26050 (epoch 27.159), train_loss = 0.94654179, grad/param norm = 2.0910e-01, time/batch = 18.7269s	
14151/26050 (epoch 27.161), train_loss = 0.93464506, grad/param norm = 2.0303e-01, time/batch = 18.4062s	
14152/26050 (epoch 27.163), train_loss = 0.75877961, grad/param norm = 1.7119e-01, time/batch = 16.8206s	
14153/26050 (epoch 27.165), train_loss = 0.72079827, grad/param norm = 1.8415e-01, time/batch = 17.5858s	
14154/26050 (epoch 27.167), train_loss = 1.04759879, grad/param norm = 2.1336e-01, time/batch = 16.4948s	
14155/26050 (epoch 27.169), train_loss = 0.93188930, grad/param norm = 2.1818e-01, time/batch = 17.4814s	
14156/26050 (epoch 27.171), train_loss = 0.78459260, grad/param norm = 1.6935e-01, time/batch = 18.1531s	
14157/26050 (epoch 27.173), train_loss = 0.88098846, grad/param norm = 2.0561e-01, time/batch = 17.3111s	
14158/26050 (epoch 27.175), train_loss = 0.88359582, grad/param norm = 1.8993e-01, time/batch = 17.9083s	
14159/26050 (epoch 27.177), train_loss = 1.01587871, grad/param norm = 1.9235e-01, time/batch = 17.4911s	
14160/26050 (epoch 27.179), train_loss = 0.69345370, grad/param norm = 1.7893e-01, time/batch = 16.8168s	
14161/26050 (epoch 27.180), train_loss = 1.11377623, grad/param norm = 1.9154e-01, time/batch = 16.6367s	
14162/26050 (epoch 27.182), train_loss = 1.13258299, grad/param norm = 2.1084e-01, time/batch = 17.3241s	
14163/26050 (epoch 27.184), train_loss = 0.95040028, grad/param norm = 1.9162e-01, time/batch = 18.1388s	
14164/26050 (epoch 27.186), train_loss = 0.75574471, grad/param norm = 1.6977e-01, time/batch = 16.3951s	
14165/26050 (epoch 27.188), train_loss = 0.94852607, grad/param norm = 1.9349e-01, time/batch = 18.5552s	
14166/26050 (epoch 27.190), train_loss = 0.96612614, grad/param norm = 2.0546e-01, time/batch = 18.4731s	
14167/26050 (epoch 27.192), train_loss = 0.95582508, grad/param norm = 1.7068e-01, time/batch = 18.0731s	
14168/26050 (epoch 27.194), train_loss = 0.96379365, grad/param norm = 1.9834e-01, time/batch = 18.1452s	
14169/26050 (epoch 27.196), train_loss = 0.98433362, grad/param norm = 1.9767e-01, time/batch = 16.8038s	
14170/26050 (epoch 27.198), train_loss = 0.84312412, grad/param norm = 1.7645e-01, time/batch = 17.8109s	
14171/26050 (epoch 27.200), train_loss = 0.83411930, grad/param norm = 1.9286e-01, time/batch = 17.9865s	
14172/26050 (epoch 27.202), train_loss = 0.93641739, grad/param norm = 1.7005e-01, time/batch = 18.4023s	
14173/26050 (epoch 27.203), train_loss = 1.03346100, grad/param norm = 1.8782e-01, time/batch = 15.2134s	
14174/26050 (epoch 27.205), train_loss = 0.88254167, grad/param norm = 1.8680e-01, time/batch = 18.2458s	
14175/26050 (epoch 27.207), train_loss = 0.84722003, grad/param norm = 1.7773e-01, time/batch = 18.2479s	
14176/26050 (epoch 27.209), train_loss = 0.96889304, grad/param norm = 1.7835e-01, time/batch = 17.3133s	
14177/26050 (epoch 27.211), train_loss = 0.77884683, grad/param norm = 2.0100e-01, time/batch = 13.6758s	
14178/26050 (epoch 27.213), train_loss = 0.95474565, grad/param norm = 2.1941e-01, time/batch = 14.0848s	
14179/26050 (epoch 27.215), train_loss = 0.89593097, grad/param norm = 2.1512e-01, time/batch = 17.8708s	
14180/26050 (epoch 27.217), train_loss = 0.87220912, grad/param norm = 1.7750e-01, time/batch = 14.8625s	
14181/26050 (epoch 27.219), train_loss = 0.88870181, grad/param norm = 1.9393e-01, time/batch = 17.8280s	
14182/26050 (epoch 27.221), train_loss = 0.84446801, grad/param norm = 2.0579e-01, time/batch = 18.9778s	
14183/26050 (epoch 27.223), train_loss = 0.99493554, grad/param norm = 2.1353e-01, time/batch = 17.3938s	
14184/26050 (epoch 27.225), train_loss = 0.83560814, grad/param norm = 1.9283e-01, time/batch = 18.7185s	
14185/26050 (epoch 27.226), train_loss = 0.95803970, grad/param norm = 2.0321e-01, time/batch = 18.6390s	
14186/26050 (epoch 27.228), train_loss = 1.05525699, grad/param norm = 1.9431e-01, time/batch = 17.4731s	
14187/26050 (epoch 27.230), train_loss = 0.94088891, grad/param norm = 1.9704e-01, time/batch = 18.2176s	
14188/26050 (epoch 27.232), train_loss = 1.01022849, grad/param norm = 2.2460e-01, time/batch = 15.2232s	
14189/26050 (epoch 27.234), train_loss = 0.83421824, grad/param norm = 1.9585e-01, time/batch = 18.3724s	
14190/26050 (epoch 27.236), train_loss = 1.01572740, grad/param norm = 1.9539e-01, time/batch = 16.2313s	
14191/26050 (epoch 27.238), train_loss = 0.80170540, grad/param norm = 1.9843e-01, time/batch = 17.6409s	
14192/26050 (epoch 27.240), train_loss = 0.93117914, grad/param norm = 1.9110e-01, time/batch = 18.1635s	
14193/26050 (epoch 27.242), train_loss = 0.89876608, grad/param norm = 1.9289e-01, time/batch = 17.1454s	
14194/26050 (epoch 27.244), train_loss = 0.94538809, grad/param norm = 2.2345e-01, time/batch = 17.0701s	
14195/26050 (epoch 27.246), train_loss = 0.85385208, grad/param norm = 1.8474e-01, time/batch = 17.4989s	
14196/26050 (epoch 27.248), train_loss = 0.94048639, grad/param norm = 1.8612e-01, time/batch = 17.1331s	
14197/26050 (epoch 27.250), train_loss = 0.91504830, grad/param norm = 2.2692e-01, time/batch = 18.4076s	
14198/26050 (epoch 27.251), train_loss = 0.88588831, grad/param norm = 1.7671e-01, time/batch = 15.3803s	
14199/26050 (epoch 27.253), train_loss = 0.82537385, grad/param norm = 1.7254e-01, time/batch = 18.8923s	
14200/26050 (epoch 27.255), train_loss = 1.07689398, grad/param norm = 1.9235e-01, time/batch = 17.8079s	
14201/26050 (epoch 27.257), train_loss = 0.92488318, grad/param norm = 2.2772e-01, time/batch = 18.1642s	
14202/26050 (epoch 27.259), train_loss = 1.00833723, grad/param norm = 1.8591e-01, time/batch = 15.2236s	
14203/26050 (epoch 27.261), train_loss = 0.83663357, grad/param norm = 2.1551e-01, time/batch = 17.7416s	
14204/26050 (epoch 27.263), train_loss = 1.02375763, grad/param norm = 2.1510e-01, time/batch = 16.8299s	
14205/26050 (epoch 27.265), train_loss = 1.06930988, grad/param norm = 2.2273e-01, time/batch = 17.8143s	
14206/26050 (epoch 27.267), train_loss = 1.04264700, grad/param norm = 1.7601e-01, time/batch = 19.2380s	
14207/26050 (epoch 27.269), train_loss = 1.04040895, grad/param norm = 2.0883e-01, time/batch = 16.1335s	
14208/26050 (epoch 27.271), train_loss = 0.95138538, grad/param norm = 1.9330e-01, time/batch = 17.4661s	
14209/26050 (epoch 27.273), train_loss = 0.85796438, grad/param norm = 1.9230e-01, time/batch = 19.0579s	
14210/26050 (epoch 27.274), train_loss = 0.90608456, grad/param norm = 1.7387e-01, time/batch = 17.4807s	
14211/26050 (epoch 27.276), train_loss = 0.88971993, grad/param norm = 1.9329e-01, time/batch = 18.0662s	
14212/26050 (epoch 27.278), train_loss = 1.03788814, grad/param norm = 1.9956e-01, time/batch = 17.6521s	
14213/26050 (epoch 27.280), train_loss = 0.91812389, grad/param norm = 1.7911e-01, time/batch = 16.2159s	
14214/26050 (epoch 27.282), train_loss = 0.98288455, grad/param norm = 1.9958e-01, time/batch = 17.9723s	
14215/26050 (epoch 27.284), train_loss = 0.90865798, grad/param norm = 1.9435e-01, time/batch = 18.4841s	
14216/26050 (epoch 27.286), train_loss = 0.94658649, grad/param norm = 2.1707e-01, time/batch = 16.3779s	
14217/26050 (epoch 27.288), train_loss = 0.78405586, grad/param norm = 1.6719e-01, time/batch = 15.1260s	
14218/26050 (epoch 27.290), train_loss = 0.95027038, grad/param norm = 2.0701e-01, time/batch = 18.2279s	
14219/26050 (epoch 27.292), train_loss = 0.86067097, grad/param norm = 1.7968e-01, time/batch = 18.4870s	
14220/26050 (epoch 27.294), train_loss = 0.92270993, grad/param norm = 2.0253e-01, time/batch = 17.6572s	
14221/26050 (epoch 27.296), train_loss = 1.03098433, grad/param norm = 2.0245e-01, time/batch = 15.2204s	
14222/26050 (epoch 27.298), train_loss = 0.96184847, grad/param norm = 1.7921e-01, time/batch = 18.2328s	
14223/26050 (epoch 27.299), train_loss = 0.76891909, grad/param norm = 1.6825e-01, time/batch = 18.7304s	
14224/26050 (epoch 27.301), train_loss = 0.79494940, grad/param norm = 1.9186e-01, time/batch = 16.8145s	
14225/26050 (epoch 27.303), train_loss = 0.93239321, grad/param norm = 1.9983e-01, time/batch = 18.8907s	
14226/26050 (epoch 27.305), train_loss = 0.76344115, grad/param norm = 1.9065e-01, time/batch = 17.0369s	
14227/26050 (epoch 27.307), train_loss = 0.86881280, grad/param norm = 2.0786e-01, time/batch = 17.7204s	
14228/26050 (epoch 27.309), train_loss = 0.92246497, grad/param norm = 1.9489e-01, time/batch = 17.0344s	
14229/26050 (epoch 27.311), train_loss = 0.99790910, grad/param norm = 2.2840e-01, time/batch = 17.9828s	
14230/26050 (epoch 27.313), train_loss = 0.91227208, grad/param norm = 2.0367e-01, time/batch = 18.4018s	
14231/26050 (epoch 27.315), train_loss = 1.01095472, grad/param norm = 2.1961e-01, time/batch = 18.1480s	
14232/26050 (epoch 27.317), train_loss = 0.95417295, grad/param norm = 2.0287e-01, time/batch = 17.9948s	
14233/26050 (epoch 27.319), train_loss = 0.85015187, grad/param norm = 2.0011e-01, time/batch = 18.5646s	
14234/26050 (epoch 27.321), train_loss = 0.90962957, grad/param norm = 2.0632e-01, time/batch = 17.7291s	
14235/26050 (epoch 27.322), train_loss = 0.97867772, grad/param norm = 1.8666e-01, time/batch = 17.9951s	
14236/26050 (epoch 27.324), train_loss = 0.74363657, grad/param norm = 1.5858e-01, time/batch = 16.5463s	
14237/26050 (epoch 27.326), train_loss = 1.05642306, grad/param norm = 2.0901e-01, time/batch = 15.7886s	
14238/26050 (epoch 27.328), train_loss = 0.95166811, grad/param norm = 1.7529e-01, time/batch = 31.4203s	
14239/26050 (epoch 27.330), train_loss = 0.79248789, grad/param norm = 1.7795e-01, time/batch = 26.6450s	
14240/26050 (epoch 27.332), train_loss = 0.97600036, grad/param norm = 1.9200e-01, time/batch = 16.5165s	
14241/26050 (epoch 27.334), train_loss = 0.84953036, grad/param norm = 1.8579e-01, time/batch = 18.2468s	
14242/26050 (epoch 27.336), train_loss = 0.87581008, grad/param norm = 1.9116e-01, time/batch = 17.9049s	
14243/26050 (epoch 27.338), train_loss = 0.81885586, grad/param norm = 1.9204e-01, time/batch = 16.3190s	
14244/26050 (epoch 27.340), train_loss = 0.98297608, grad/param norm = 1.8726e-01, time/batch = 17.7221s	
14245/26050 (epoch 27.342), train_loss = 1.01088654, grad/param norm = 1.7894e-01, time/batch = 17.8104s	
14246/26050 (epoch 27.344), train_loss = 0.85124438, grad/param norm = 1.9169e-01, time/batch = 16.3809s	
14247/26050 (epoch 27.345), train_loss = 0.91089613, grad/param norm = 2.0309e-01, time/batch = 18.0536s	
14248/26050 (epoch 27.347), train_loss = 1.06259687, grad/param norm = 2.2924e-01, time/batch = 18.5685s	
14249/26050 (epoch 27.349), train_loss = 0.97758743, grad/param norm = 2.0184e-01, time/batch = 18.2399s	
14250/26050 (epoch 27.351), train_loss = 0.96777717, grad/param norm = 2.0138e-01, time/batch = 17.8848s	
14251/26050 (epoch 27.353), train_loss = 0.93994664, grad/param norm = 1.9687e-01, time/batch = 18.3926s	
14252/26050 (epoch 27.355), train_loss = 0.96500679, grad/param norm = 2.3823e-01, time/batch = 18.2393s	
14253/26050 (epoch 27.357), train_loss = 0.87376423, grad/param norm = 1.7631e-01, time/batch = 17.0468s	
14254/26050 (epoch 27.359), train_loss = 1.03070291, grad/param norm = 2.0823e-01, time/batch = 15.1407s	
14255/26050 (epoch 27.361), train_loss = 0.85262349, grad/param norm = 1.7606e-01, time/batch = 18.3204s	
14256/26050 (epoch 27.363), train_loss = 1.00908588, grad/param norm = 1.9188e-01, time/batch = 18.4826s	
14257/26050 (epoch 27.365), train_loss = 0.88968189, grad/param norm = 1.7604e-01, time/batch = 16.3868s	
14258/26050 (epoch 27.367), train_loss = 0.99244771, grad/param norm = 1.8185e-01, time/batch = 15.1890s	
14259/26050 (epoch 27.369), train_loss = 0.84361089, grad/param norm = 1.8227e-01, time/batch = 17.9752s	
14260/26050 (epoch 27.370), train_loss = 0.82950292, grad/param norm = 1.7048e-01, time/batch = 15.9550s	
14261/26050 (epoch 27.372), train_loss = 0.93265845, grad/param norm = 1.9486e-01, time/batch = 17.8899s	
14262/26050 (epoch 27.374), train_loss = 1.05427459, grad/param norm = 2.0558e-01, time/batch = 17.4919s	
14263/26050 (epoch 27.376), train_loss = 1.11209010, grad/param norm = 2.2583e-01, time/batch = 18.3115s	
14264/26050 (epoch 27.378), train_loss = 0.88124728, grad/param norm = 1.7986e-01, time/batch = 18.6513s	
14265/26050 (epoch 27.380), train_loss = 1.09862665, grad/param norm = 2.3820e-01, time/batch = 17.4980s	
14266/26050 (epoch 27.382), train_loss = 1.20334417, grad/param norm = 2.5612e-01, time/batch = 17.9178s	
14267/26050 (epoch 27.384), train_loss = 0.91536646, grad/param norm = 2.0257e-01, time/batch = 16.4685s	
14268/26050 (epoch 27.386), train_loss = 1.00791189, grad/param norm = 2.5753e-01, time/batch = 15.2804s	
14269/26050 (epoch 27.388), train_loss = 0.96736478, grad/param norm = 2.0987e-01, time/batch = 17.0527s	
14270/26050 (epoch 27.390), train_loss = 0.88409128, grad/param norm = 1.7956e-01, time/batch = 17.4629s	
14271/26050 (epoch 27.392), train_loss = 0.82316195, grad/param norm = 1.8451e-01, time/batch = 18.3766s	
14272/26050 (epoch 27.393), train_loss = 0.96673516, grad/param norm = 2.0440e-01, time/batch = 16.4468s	
14273/26050 (epoch 27.395), train_loss = 1.01577626, grad/param norm = 2.4939e-01, time/batch = 18.3746s	
14274/26050 (epoch 27.397), train_loss = 1.00899295, grad/param norm = 2.1848e-01, time/batch = 17.0530s	
14275/26050 (epoch 27.399), train_loss = 0.88124493, grad/param norm = 2.0299e-01, time/batch = 18.4770s	
14276/26050 (epoch 27.401), train_loss = 0.96693978, grad/param norm = 1.9713e-01, time/batch = 18.2335s	
14277/26050 (epoch 27.403), train_loss = 0.97431418, grad/param norm = 2.2548e-01, time/batch = 17.6381s	
14278/26050 (epoch 27.405), train_loss = 0.95144952, grad/param norm = 2.0291e-01, time/batch = 18.4138s	
14279/26050 (epoch 27.407), train_loss = 1.08234453, grad/param norm = 2.1192e-01, time/batch = 17.7457s	
14280/26050 (epoch 27.409), train_loss = 1.07720475, grad/param norm = 2.2843e-01, time/batch = 18.2304s	
14281/26050 (epoch 27.411), train_loss = 1.00509026, grad/param norm = 2.1667e-01, time/batch = 18.3179s	
14282/26050 (epoch 27.413), train_loss = 1.09820195, grad/param norm = 1.9125e-01, time/batch = 17.7186s	
14283/26050 (epoch 27.415), train_loss = 1.09980362, grad/param norm = 2.3978e-01, time/batch = 16.7302s	
14284/26050 (epoch 27.417), train_loss = 1.14369105, grad/param norm = 2.3211e-01, time/batch = 16.8236s	
14285/26050 (epoch 27.418), train_loss = 1.03758429, grad/param norm = 2.1858e-01, time/batch = 18.6588s	
14286/26050 (epoch 27.420), train_loss = 0.82216877, grad/param norm = 1.7906e-01, time/batch = 18.4842s	
14287/26050 (epoch 27.422), train_loss = 0.80259418, grad/param norm = 1.8257e-01, time/batch = 16.6412s	
14288/26050 (epoch 27.424), train_loss = 1.07720601, grad/param norm = 2.2192e-01, time/batch = 16.1609s	
14289/26050 (epoch 27.426), train_loss = 1.03537271, grad/param norm = 1.9489e-01, time/batch = 16.1423s	
14290/26050 (epoch 27.428), train_loss = 0.89813259, grad/param norm = 1.8586e-01, time/batch = 16.8863s	
14291/26050 (epoch 27.430), train_loss = 1.09131897, grad/param norm = 2.0572e-01, time/batch = 17.1671s	
14292/26050 (epoch 27.432), train_loss = 0.92566492, grad/param norm = 1.8485e-01, time/batch = 18.5735s	
14293/26050 (epoch 27.434), train_loss = 0.91846856, grad/param norm = 1.8040e-01, time/batch = 17.9884s	
14294/26050 (epoch 27.436), train_loss = 1.07619576, grad/param norm = 2.1986e-01, time/batch = 16.9790s	
14295/26050 (epoch 27.438), train_loss = 1.02542277, grad/param norm = 2.1508e-01, time/batch = 18.2474s	
14296/26050 (epoch 27.440), train_loss = 0.96822140, grad/param norm = 2.1261e-01, time/batch = 17.9197s	
14297/26050 (epoch 27.441), train_loss = 0.96220119, grad/param norm = 1.8862e-01, time/batch = 18.3151s	
14298/26050 (epoch 27.443), train_loss = 0.80994782, grad/param norm = 1.5776e-01, time/batch = 15.8995s	
14299/26050 (epoch 27.445), train_loss = 0.86426937, grad/param norm = 1.8034e-01, time/batch = 18.3992s	
14300/26050 (epoch 27.447), train_loss = 1.06111231, grad/param norm = 2.0399e-01, time/batch = 18.4055s	
14301/26050 (epoch 27.449), train_loss = 0.87621958, grad/param norm = 1.9509e-01, time/batch = 16.9863s	
14302/26050 (epoch 27.451), train_loss = 1.10629793, grad/param norm = 2.0064e-01, time/batch = 18.4862s	
14303/26050 (epoch 27.453), train_loss = 0.87808232, grad/param norm = 1.6569e-01, time/batch = 16.9082s	
14304/26050 (epoch 27.455), train_loss = 0.95523293, grad/param norm = 1.8194e-01, time/batch = 17.8020s	
14305/26050 (epoch 27.457), train_loss = 0.94087950, grad/param norm = 1.9078e-01, time/batch = 15.1482s	
14306/26050 (epoch 27.459), train_loss = 1.04659520, grad/param norm = 1.9759e-01, time/batch = 17.9664s	
14307/26050 (epoch 27.461), train_loss = 1.04726372, grad/param norm = 2.1565e-01, time/batch = 18.8976s	
14308/26050 (epoch 27.463), train_loss = 0.90470301, grad/param norm = 1.7017e-01, time/batch = 16.7394s	
14309/26050 (epoch 27.464), train_loss = 0.98238152, grad/param norm = 1.8475e-01, time/batch = 16.9637s	
14310/26050 (epoch 27.466), train_loss = 0.99135576, grad/param norm = 1.8559e-01, time/batch = 18.3191s	
14311/26050 (epoch 27.468), train_loss = 1.04040946, grad/param norm = 1.7458e-01, time/batch = 17.4813s	
14312/26050 (epoch 27.470), train_loss = 1.06064136, grad/param norm = 2.6186e-01, time/batch = 17.7320s	
14313/26050 (epoch 27.472), train_loss = 1.07181707, grad/param norm = 2.4626e-01, time/batch = 16.1571s	
14314/26050 (epoch 27.474), train_loss = 1.06729668, grad/param norm = 2.0631e-01, time/batch = 18.9099s	
14315/26050 (epoch 27.476), train_loss = 1.07533201, grad/param norm = 1.9555e-01, time/batch = 18.4778s	
14316/26050 (epoch 27.478), train_loss = 0.92142900, grad/param norm = 1.8586e-01, time/batch = 18.0806s	
14317/26050 (epoch 27.480), train_loss = 0.94170922, grad/param norm = 1.7715e-01, time/batch = 17.4035s	
14318/26050 (epoch 27.482), train_loss = 0.90175544, grad/param norm = 1.8866e-01, time/batch = 14.7810s	
14319/26050 (epoch 27.484), train_loss = 0.89742322, grad/param norm = 1.8555e-01, time/batch = 18.3010s	
14320/26050 (epoch 27.486), train_loss = 1.08538453, grad/param norm = 1.8463e-01, time/batch = 14.7207s	
14321/26050 (epoch 27.488), train_loss = 1.14370670, grad/param norm = 2.0673e-01, time/batch = 18.2493s	
14322/26050 (epoch 27.489), train_loss = 1.10497880, grad/param norm = 2.2149e-01, time/batch = 16.9728s	
14323/26050 (epoch 27.491), train_loss = 0.88558179, grad/param norm = 2.0755e-01, time/batch = 18.0563s	
14324/26050 (epoch 27.493), train_loss = 0.97784145, grad/param norm = 2.0725e-01, time/batch = 18.3278s	
14325/26050 (epoch 27.495), train_loss = 0.93886155, grad/param norm = 1.8581e-01, time/batch = 17.3190s	
14326/26050 (epoch 27.497), train_loss = 0.86414707, grad/param norm = 1.7912e-01, time/batch = 18.7330s	
14327/26050 (epoch 27.499), train_loss = 0.91972339, grad/param norm = 1.9519e-01, time/batch = 18.4097s	
14328/26050 (epoch 27.501), train_loss = 1.02726304, grad/param norm = 2.0180e-01, time/batch = 17.7324s	
14329/26050 (epoch 27.503), train_loss = 0.89151354, grad/param norm = 1.8748e-01, time/batch = 18.9014s	
14330/26050 (epoch 27.505), train_loss = 1.06978489, grad/param norm = 1.9977e-01, time/batch = 18.0650s	
14331/26050 (epoch 27.507), train_loss = 1.03083177, grad/param norm = 2.5788e-01, time/batch = 15.8764s	
14332/26050 (epoch 27.509), train_loss = 1.11985766, grad/param norm = 2.0107e-01, time/batch = 18.2241s	
14333/26050 (epoch 27.511), train_loss = 0.90939197, grad/param norm = 1.8162e-01, time/batch = 18.3263s	
14334/26050 (epoch 27.512), train_loss = 0.82951219, grad/param norm = 1.8958e-01, time/batch = 14.9834s	
14335/26050 (epoch 27.514), train_loss = 1.02581258, grad/param norm = 2.2026e-01, time/batch = 17.8881s	
14336/26050 (epoch 27.516), train_loss = 1.08881324, grad/param norm = 2.1410e-01, time/batch = 18.1743s	
14337/26050 (epoch 27.518), train_loss = 0.94818607, grad/param norm = 1.9857e-01, time/batch = 18.2355s	
14338/26050 (epoch 27.520), train_loss = 0.95145735, grad/param norm = 1.9352e-01, time/batch = 17.6538s	
14339/26050 (epoch 27.522), train_loss = 0.74884378, grad/param norm = 1.6687e-01, time/batch = 18.1389s	
14340/26050 (epoch 27.524), train_loss = 1.01865134, grad/param norm = 2.1979e-01, time/batch = 18.2290s	
14341/26050 (epoch 27.526), train_loss = 1.05775569, grad/param norm = 2.0773e-01, time/batch = 15.9751s	
14342/26050 (epoch 27.528), train_loss = 0.98248527, grad/param norm = 2.0024e-01, time/batch = 17.6151s	
14343/26050 (epoch 27.530), train_loss = 0.91531204, grad/param norm = 2.0610e-01, time/batch = 18.0797s	
14344/26050 (epoch 27.532), train_loss = 0.99438864, grad/param norm = 2.0989e-01, time/batch = 16.6554s	
14345/26050 (epoch 27.534), train_loss = 1.04404558, grad/param norm = 2.7430e-01, time/batch = 17.6263s	
14346/26050 (epoch 27.536), train_loss = 0.97794543, grad/param norm = 2.1221e-01, time/batch = 18.1544s	
14347/26050 (epoch 27.537), train_loss = 1.03444705, grad/param norm = 2.0833e-01, time/batch = 18.2227s	
14348/26050 (epoch 27.539), train_loss = 0.96231753, grad/param norm = 2.0918e-01, time/batch = 17.7904s	
14349/26050 (epoch 27.541), train_loss = 1.15311649, grad/param norm = 2.3575e-01, time/batch = 17.9715s	
14350/26050 (epoch 27.543), train_loss = 0.79906906, grad/param norm = 1.9194e-01, time/batch = 18.6500s	
14351/26050 (epoch 27.545), train_loss = 0.98085772, grad/param norm = 1.9741e-01, time/batch = 18.9011s	
14352/26050 (epoch 27.547), train_loss = 0.94436009, grad/param norm = 2.0086e-01, time/batch = 17.3872s	
14353/26050 (epoch 27.549), train_loss = 0.81494970, grad/param norm = 2.1661e-01, time/batch = 18.1459s	
14354/26050 (epoch 27.551), train_loss = 1.01953212, grad/param norm = 2.1366e-01, time/batch = 16.2274s	
14355/26050 (epoch 27.553), train_loss = 0.90433528, grad/param norm = 1.8393e-01, time/batch = 16.1261s	
14356/26050 (epoch 27.555), train_loss = 0.85583278, grad/param norm = 1.8625e-01, time/batch = 17.6579s	
14357/26050 (epoch 27.557), train_loss = 0.98487188, grad/param norm = 1.8743e-01, time/batch = 15.1577s	
14358/26050 (epoch 27.559), train_loss = 0.95144764, grad/param norm = 1.9452e-01, time/batch = 18.3920s	
14359/26050 (epoch 27.560), train_loss = 0.92912588, grad/param norm = 2.0846e-01, time/batch = 18.0674s	
14360/26050 (epoch 27.562), train_loss = 0.93605777, grad/param norm = 2.0381e-01, time/batch = 17.2345s	
14361/26050 (epoch 27.564), train_loss = 1.12449690, grad/param norm = 2.0500e-01, time/batch = 17.3907s	
14362/26050 (epoch 27.566), train_loss = 0.88068122, grad/param norm = 1.8475e-01, time/batch = 18.0717s	
14363/26050 (epoch 27.568), train_loss = 1.00013887, grad/param norm = 2.0099e-01, time/batch = 18.5546s	
14364/26050 (epoch 27.570), train_loss = 0.99001067, grad/param norm = 2.0141e-01, time/batch = 18.1469s	
14365/26050 (epoch 27.572), train_loss = 0.95682611, grad/param norm = 1.9515e-01, time/batch = 14.4784s	
14366/26050 (epoch 27.574), train_loss = 0.97020614, grad/param norm = 2.3648e-01, time/batch = 17.7231s	
14367/26050 (epoch 27.576), train_loss = 0.99511115, grad/param norm = 2.1775e-01, time/batch = 17.7018s	
14368/26050 (epoch 27.578), train_loss = 0.94146780, grad/param norm = 1.9481e-01, time/batch = 15.3105s	
14369/26050 (epoch 27.580), train_loss = 0.88549249, grad/param norm = 1.9682e-01, time/batch = 17.1538s	
14370/26050 (epoch 27.582), train_loss = 0.98525238, grad/param norm = 1.9278e-01, time/batch = 18.3934s	
14371/26050 (epoch 27.583), train_loss = 1.04535715, grad/param norm = 2.0496e-01, time/batch = 19.0533s	
14372/26050 (epoch 27.585), train_loss = 0.83942558, grad/param norm = 2.0258e-01, time/batch = 17.5607s	
14373/26050 (epoch 27.587), train_loss = 0.98614424, grad/param norm = 1.9286e-01, time/batch = 3.3788s	
14374/26050 (epoch 27.589), train_loss = 1.11671718, grad/param norm = 2.3008e-01, time/batch = 0.6444s	
14375/26050 (epoch 27.591), train_loss = 0.95598845, grad/param norm = 1.9999e-01, time/batch = 0.6529s	
14376/26050 (epoch 27.593), train_loss = 0.84012113, grad/param norm = 1.8467e-01, time/batch = 0.6420s	
14377/26050 (epoch 27.595), train_loss = 1.02783230, grad/param norm = 2.0731e-01, time/batch = 0.6403s	
14378/26050 (epoch 27.597), train_loss = 0.96596191, grad/param norm = 1.9125e-01, time/batch = 0.6472s	
14379/26050 (epoch 27.599), train_loss = 0.99268648, grad/param norm = 2.0243e-01, time/batch = 0.6733s	
14380/26050 (epoch 27.601), train_loss = 1.12117147, grad/param norm = 2.1795e-01, time/batch = 0.7366s	
14381/26050 (epoch 27.603), train_loss = 0.98573997, grad/param norm = 2.1889e-01, time/batch = 0.9606s	
14382/26050 (epoch 27.605), train_loss = 0.93177507, grad/param norm = 2.1773e-01, time/batch = 0.9587s	
14383/26050 (epoch 27.607), train_loss = 1.05232429, grad/param norm = 2.2102e-01, time/batch = 0.9616s	
14384/26050 (epoch 27.608), train_loss = 0.86577789, grad/param norm = 1.8036e-01, time/batch = 0.9576s	
14385/26050 (epoch 27.610), train_loss = 0.96227258, grad/param norm = 2.1041e-01, time/batch = 1.0237s	
14386/26050 (epoch 27.612), train_loss = 0.92787696, grad/param norm = 1.9477e-01, time/batch = 1.7836s	
14387/26050 (epoch 27.614), train_loss = 0.96601447, grad/param norm = 1.8812e-01, time/batch = 1.8068s	
14388/26050 (epoch 27.616), train_loss = 1.05397529, grad/param norm = 2.3180e-01, time/batch = 6.4593s	
14389/26050 (epoch 27.618), train_loss = 0.91405919, grad/param norm = 2.0679e-01, time/batch = 15.0495s	
14390/26050 (epoch 27.620), train_loss = 1.01019440, grad/param norm = 1.9353e-01, time/batch = 18.3249s	
14391/26050 (epoch 27.622), train_loss = 0.84991764, grad/param norm = 1.7407e-01, time/batch = 17.8109s	
14392/26050 (epoch 27.624), train_loss = 0.80790637, grad/param norm = 1.7483e-01, time/batch = 18.3220s	
14393/26050 (epoch 27.626), train_loss = 1.01004874, grad/param norm = 1.9514e-01, time/batch = 16.2305s	
14394/26050 (epoch 27.628), train_loss = 0.90175892, grad/param norm = 2.1722e-01, time/batch = 17.4108s	
14395/26050 (epoch 27.630), train_loss = 1.09787843, grad/param norm = 1.9270e-01, time/batch = 17.5711s	
14396/26050 (epoch 27.631), train_loss = 1.11974681, grad/param norm = 2.1433e-01, time/batch = 17.9761s	
14397/26050 (epoch 27.633), train_loss = 0.86590322, grad/param norm = 1.8138e-01, time/batch = 18.0580s	
14398/26050 (epoch 27.635), train_loss = 0.90459716, grad/param norm = 1.7020e-01, time/batch = 17.9737s	
14399/26050 (epoch 27.637), train_loss = 0.83267521, grad/param norm = 1.8516e-01, time/batch = 18.6527s	
14400/26050 (epoch 27.639), train_loss = 1.03223886, grad/param norm = 2.0004e-01, time/batch = 14.8806s	
14401/26050 (epoch 27.641), train_loss = 0.91564698, grad/param norm = 1.9581e-01, time/batch = 17.7187s	
14402/26050 (epoch 27.643), train_loss = 0.86939465, grad/param norm = 1.6309e-01, time/batch = 18.2288s	
14403/26050 (epoch 27.645), train_loss = 0.89165906, grad/param norm = 1.8709e-01, time/batch = 18.0700s	
14404/26050 (epoch 27.647), train_loss = 0.89017115, grad/param norm = 2.0473e-01, time/batch = 16.8997s	
14405/26050 (epoch 27.649), train_loss = 0.94784019, grad/param norm = 2.0916e-01, time/batch = 18.1472s	
14406/26050 (epoch 27.651), train_loss = 0.90074644, grad/param norm = 1.9714e-01, time/batch = 18.3828s	
14407/26050 (epoch 27.653), train_loss = 0.94047593, grad/param norm = 2.0734e-01, time/batch = 18.1369s	
14408/26050 (epoch 27.655), train_loss = 0.87220113, grad/param norm = 1.9512e-01, time/batch = 16.5386s	
14409/26050 (epoch 27.656), train_loss = 0.81604463, grad/param norm = 1.6634e-01, time/batch = 18.3931s	
14410/26050 (epoch 27.658), train_loss = 1.13335357, grad/param norm = 2.0916e-01, time/batch = 17.7446s	
14411/26050 (epoch 27.660), train_loss = 0.82028822, grad/param norm = 1.8983e-01, time/batch = 15.4216s	
14412/26050 (epoch 27.662), train_loss = 0.92803233, grad/param norm = 1.8826e-01, time/batch = 18.0672s	
14413/26050 (epoch 27.664), train_loss = 0.93099941, grad/param norm = 1.9797e-01, time/batch = 17.8194s	
14414/26050 (epoch 27.666), train_loss = 0.88848043, grad/param norm = 1.9086e-01, time/batch = 17.8163s	
14415/26050 (epoch 27.668), train_loss = 0.76843427, grad/param norm = 2.0397e-01, time/batch = 17.9003s	
14416/26050 (epoch 27.670), train_loss = 1.07682458, grad/param norm = 2.1894e-01, time/batch = 18.6522s	
14417/26050 (epoch 27.672), train_loss = 0.95665414, grad/param norm = 2.0679e-01, time/batch = 16.2314s	
14418/26050 (epoch 27.674), train_loss = 0.84201200, grad/param norm = 1.8951e-01, time/batch = 17.7931s	
14419/26050 (epoch 27.676), train_loss = 1.01076032, grad/param norm = 2.1858e-01, time/batch = 17.5791s	
14420/26050 (epoch 27.678), train_loss = 1.02867607, grad/param norm = 2.1852e-01, time/batch = 18.4903s	
14421/26050 (epoch 27.679), train_loss = 1.10496547, grad/param norm = 2.1217e-01, time/batch = 16.5524s	
14422/26050 (epoch 27.681), train_loss = 0.96908940, grad/param norm = 1.9448e-01, time/batch = 17.9090s	
14423/26050 (epoch 27.683), train_loss = 0.85226677, grad/param norm = 2.2948e-01, time/batch = 18.5774s	
14424/26050 (epoch 27.685), train_loss = 0.91689632, grad/param norm = 1.8558e-01, time/batch = 17.2404s	
14425/26050 (epoch 27.687), train_loss = 0.82019543, grad/param norm = 1.8688e-01, time/batch = 18.3214s	
14426/26050 (epoch 27.689), train_loss = 0.90501816, grad/param norm = 1.9115e-01, time/batch = 19.0602s	
14427/26050 (epoch 27.691), train_loss = 0.77031013, grad/param norm = 1.5735e-01, time/batch = 15.2321s	
14428/26050 (epoch 27.693), train_loss = 0.87985314, grad/param norm = 1.9294e-01, time/batch = 17.8116s	
14429/26050 (epoch 27.695), train_loss = 0.93860325, grad/param norm = 1.7158e-01, time/batch = 18.4900s	
14430/26050 (epoch 27.697), train_loss = 0.86880265, grad/param norm = 1.8547e-01, time/batch = 18.3938s	
14431/26050 (epoch 27.699), train_loss = 0.99270650, grad/param norm = 2.1156e-01, time/batch = 16.0546s	
14432/26050 (epoch 27.701), train_loss = 0.84592010, grad/param norm = 1.7867e-01, time/batch = 17.8063s	
14433/26050 (epoch 27.702), train_loss = 1.04028094, grad/param norm = 1.9980e-01, time/batch = 18.0376s	
14434/26050 (epoch 27.704), train_loss = 1.04599217, grad/param norm = 1.8725e-01, time/batch = 15.4820s	
14435/26050 (epoch 27.706), train_loss = 0.88310696, grad/param norm = 1.9279e-01, time/batch = 18.0496s	
14436/26050 (epoch 27.708), train_loss = 1.02125119, grad/param norm = 2.0230e-01, time/batch = 18.0741s	
14437/26050 (epoch 27.710), train_loss = 0.96949187, grad/param norm = 2.1435e-01, time/batch = 18.5689s	
14438/26050 (epoch 27.712), train_loss = 0.95271496, grad/param norm = 1.8961e-01, time/batch = 16.4020s	
14439/26050 (epoch 27.714), train_loss = 0.83240178, grad/param norm = 1.7447e-01, time/batch = 18.1600s	
14440/26050 (epoch 27.716), train_loss = 1.19084267, grad/param norm = 2.2022e-01, time/batch = 18.4153s	
14441/26050 (epoch 27.718), train_loss = 1.01828673, grad/param norm = 2.0636e-01, time/batch = 17.3715s	
14442/26050 (epoch 27.720), train_loss = 0.94617681, grad/param norm = 2.0398e-01, time/batch = 17.4951s	
14443/26050 (epoch 27.722), train_loss = 0.83804642, grad/param norm = 1.7922e-01, time/batch = 15.8057s	
14444/26050 (epoch 27.724), train_loss = 0.88453954, grad/param norm = 1.9434e-01, time/batch = 18.0706s	
14445/26050 (epoch 27.726), train_loss = 0.99631369, grad/param norm = 2.1084e-01, time/batch = 17.2441s	
14446/26050 (epoch 27.727), train_loss = 1.00477265, grad/param norm = 2.0867e-01, time/batch = 14.6462s	
14447/26050 (epoch 27.729), train_loss = 0.98280062, grad/param norm = 1.9213e-01, time/batch = 16.5865s	
14448/26050 (epoch 27.731), train_loss = 0.98038873, grad/param norm = 1.9276e-01, time/batch = 17.9794s	
14449/26050 (epoch 27.733), train_loss = 0.92019312, grad/param norm = 2.2363e-01, time/batch = 17.7367s	
14450/26050 (epoch 27.735), train_loss = 1.12474006, grad/param norm = 2.2572e-01, time/batch = 18.9942s	
14451/26050 (epoch 27.737), train_loss = 0.90017228, grad/param norm = 2.1454e-01, time/batch = 18.3075s	
14452/26050 (epoch 27.739), train_loss = 0.98469512, grad/param norm = 1.8902e-01, time/batch = 15.2144s	
14453/26050 (epoch 27.741), train_loss = 0.89338831, grad/param norm = 2.0176e-01, time/batch = 18.4819s	
14454/26050 (epoch 27.743), train_loss = 0.97655232, grad/param norm = 2.2046e-01, time/batch = 18.2441s	
14455/26050 (epoch 27.745), train_loss = 0.84362453, grad/param norm = 1.9726e-01, time/batch = 19.1092s	
14456/26050 (epoch 27.747), train_loss = 0.87034294, grad/param norm = 1.9388e-01, time/batch = 35.1824s	
14457/26050 (epoch 27.749), train_loss = 1.04301866, grad/param norm = 2.0876e-01, time/batch = 21.1856s	
14458/26050 (epoch 27.750), train_loss = 0.94182993, grad/param norm = 1.6785e-01, time/batch = 17.8425s	
14459/26050 (epoch 27.752), train_loss = 0.89481892, grad/param norm = 2.1222e-01, time/batch = 18.6610s	
14460/26050 (epoch 27.754), train_loss = 0.95294598, grad/param norm = 1.9864e-01, time/batch = 18.1504s	
14461/26050 (epoch 27.756), train_loss = 0.93975253, grad/param norm = 2.6779e-01, time/batch = 15.4659s	
14462/26050 (epoch 27.758), train_loss = 0.92993784, grad/param norm = 2.1088e-01, time/batch = 18.3778s	
14463/26050 (epoch 27.760), train_loss = 1.11155037, grad/param norm = 2.0763e-01, time/batch = 18.4158s	
14464/26050 (epoch 27.762), train_loss = 0.90376285, grad/param norm = 1.9879e-01, time/batch = 17.3026s	
14465/26050 (epoch 27.764), train_loss = 0.94724483, grad/param norm = 2.4722e-01, time/batch = 18.3864s	
14466/26050 (epoch 27.766), train_loss = 0.98489036, grad/param norm = 2.1861e-01, time/batch = 14.6417s	
14467/26050 (epoch 27.768), train_loss = 0.84092246, grad/param norm = 1.7250e-01, time/batch = 18.0601s	
14468/26050 (epoch 27.770), train_loss = 0.92747623, grad/param norm = 2.1679e-01, time/batch = 18.2293s	
14469/26050 (epoch 27.772), train_loss = 0.94525017, grad/param norm = 1.7695e-01, time/batch = 18.8987s	
14470/26050 (epoch 27.774), train_loss = 0.82375648, grad/param norm = 2.0651e-01, time/batch = 18.9073s	
14471/26050 (epoch 27.775), train_loss = 0.68314595, grad/param norm = 1.8212e-01, time/batch = 16.7060s	
14472/26050 (epoch 27.777), train_loss = 0.88967825, grad/param norm = 1.9489e-01, time/batch = 14.9679s	
14473/26050 (epoch 27.779), train_loss = 0.93399033, grad/param norm = 2.4942e-01, time/batch = 18.7329s	
14474/26050 (epoch 27.781), train_loss = 0.83960992, grad/param norm = 1.9031e-01, time/batch = 17.4069s	
14475/26050 (epoch 27.783), train_loss = 0.82030603, grad/param norm = 1.8364e-01, time/batch = 18.2148s	
14476/26050 (epoch 27.785), train_loss = 0.97161937, grad/param norm = 2.0455e-01, time/batch = 18.3892s	
14477/26050 (epoch 27.787), train_loss = 0.85557300, grad/param norm = 2.2117e-01, time/batch = 17.6433s	
14478/26050 (epoch 27.789), train_loss = 0.88015745, grad/param norm = 2.0614e-01, time/batch = 17.2291s	
14479/26050 (epoch 27.791), train_loss = 0.85939169, grad/param norm = 1.9321e-01, time/batch = 17.1291s	
14480/26050 (epoch 27.793), train_loss = 0.90595525, grad/param norm = 2.2231e-01, time/batch = 18.5673s	
14481/26050 (epoch 27.795), train_loss = 0.76492469, grad/param norm = 1.4949e-01, time/batch = 17.7434s	
14482/26050 (epoch 27.797), train_loss = 0.83134441, grad/param norm = 1.9156e-01, time/batch = 14.5580s	
14483/26050 (epoch 27.798), train_loss = 0.83316080, grad/param norm = 2.0176e-01, time/batch = 18.4118s	
14484/26050 (epoch 27.800), train_loss = 0.81997405, grad/param norm = 1.7783e-01, time/batch = 16.7380s	
14485/26050 (epoch 27.802), train_loss = 0.88764143, grad/param norm = 1.9804e-01, time/batch = 18.6600s	
14486/26050 (epoch 27.804), train_loss = 0.91662180, grad/param norm = 2.0621e-01, time/batch = 18.3288s	
14487/26050 (epoch 27.806), train_loss = 1.00108308, grad/param norm = 2.1649e-01, time/batch = 15.0670s	
14488/26050 (epoch 27.808), train_loss = 0.93207715, grad/param norm = 1.8511e-01, time/batch = 15.8879s	
14489/26050 (epoch 27.810), train_loss = 0.88409953, grad/param norm = 1.8267e-01, time/batch = 19.0669s	
14490/26050 (epoch 27.812), train_loss = 0.79989291, grad/param norm = 1.9871e-01, time/batch = 17.8962s	
14491/26050 (epoch 27.814), train_loss = 0.85495381, grad/param norm = 2.0391e-01, time/batch = 18.2139s	
14492/26050 (epoch 27.816), train_loss = 0.98890431, grad/param norm = 2.2192e-01, time/batch = 18.2329s	
14493/26050 (epoch 27.818), train_loss = 1.02077353, grad/param norm = 2.3436e-01, time/batch = 18.5789s	
14494/26050 (epoch 27.820), train_loss = 0.94739384, grad/param norm = 1.9009e-01, time/batch = 17.8403s	
14495/26050 (epoch 27.821), train_loss = 1.04418679, grad/param norm = 2.1025e-01, time/batch = 18.8974s	
14496/26050 (epoch 27.823), train_loss = 1.11666491, grad/param norm = 2.0957e-01, time/batch = 17.8345s	
14497/26050 (epoch 27.825), train_loss = 0.94034296, grad/param norm = 2.1517e-01, time/batch = 16.2963s	
14498/26050 (epoch 27.827), train_loss = 0.96155988, grad/param norm = 2.2252e-01, time/batch = 16.6310s	
14499/26050 (epoch 27.829), train_loss = 1.00096991, grad/param norm = 2.0027e-01, time/batch = 18.3846s	
14500/26050 (epoch 27.831), train_loss = 1.08300903, grad/param norm = 2.2224e-01, time/batch = 18.7419s	
14501/26050 (epoch 27.833), train_loss = 1.09903763, grad/param norm = 2.2979e-01, time/batch = 18.3168s	
14502/26050 (epoch 27.835), train_loss = 1.08783999, grad/param norm = 2.0772e-01, time/batch = 17.7337s	
14503/26050 (epoch 27.837), train_loss = 0.93752463, grad/param norm = 1.8035e-01, time/batch = 15.0679s	
14504/26050 (epoch 27.839), train_loss = 0.92852801, grad/param norm = 2.0902e-01, time/batch = 18.5696s	
14505/26050 (epoch 27.841), train_loss = 1.05521719, grad/param norm = 2.1717e-01, time/batch = 16.1344s	
14506/26050 (epoch 27.843), train_loss = 0.90176774, grad/param norm = 1.6923e-01, time/batch = 17.5312s	
14507/26050 (epoch 27.845), train_loss = 0.90248091, grad/param norm = 1.8053e-01, time/batch = 18.9046s	
14508/26050 (epoch 27.846), train_loss = 1.00143780, grad/param norm = 2.1877e-01, time/batch = 17.4049s	
14509/26050 (epoch 27.848), train_loss = 0.92680987, grad/param norm = 1.9985e-01, time/batch = 18.3180s	
14510/26050 (epoch 27.850), train_loss = 0.85122454, grad/param norm = 1.8796e-01, time/batch = 18.5722s	
14511/26050 (epoch 27.852), train_loss = 0.96041688, grad/param norm = 1.9989e-01, time/batch = 17.3223s	
14512/26050 (epoch 27.854), train_loss = 0.91115717, grad/param norm = 1.8671e-01, time/batch = 18.2440s	
14513/26050 (epoch 27.856), train_loss = 0.89831143, grad/param norm = 2.1276e-01, time/batch = 16.2931s	
14514/26050 (epoch 27.858), train_loss = 0.87708598, grad/param norm = 2.0089e-01, time/batch = 18.4692s	
14515/26050 (epoch 27.860), train_loss = 0.98232121, grad/param norm = 1.9557e-01, time/batch = 17.4590s	
14516/26050 (epoch 27.862), train_loss = 1.02861163, grad/param norm = 1.9252e-01, time/batch = 18.5651s	
14517/26050 (epoch 27.864), train_loss = 0.97045006, grad/param norm = 2.2200e-01, time/batch = 18.2099s	
14518/26050 (epoch 27.866), train_loss = 0.90047905, grad/param norm = 1.7078e-01, time/batch = 17.5589s	
14519/26050 (epoch 27.868), train_loss = 0.99291358, grad/param norm = 2.0979e-01, time/batch = 17.7244s	
14520/26050 (epoch 27.869), train_loss = 0.84179885, grad/param norm = 1.8490e-01, time/batch = 18.2258s	
14521/26050 (epoch 27.871), train_loss = 0.79924559, grad/param norm = 1.8909e-01, time/batch = 17.0436s	
14522/26050 (epoch 27.873), train_loss = 0.97361556, grad/param norm = 2.1152e-01, time/batch = 16.5396s	
14523/26050 (epoch 27.875), train_loss = 0.93164019, grad/param norm = 2.1175e-01, time/batch = 18.4884s	
14524/26050 (epoch 27.877), train_loss = 0.85166535, grad/param norm = 1.8434e-01, time/batch = 15.7372s	
14525/26050 (epoch 27.879), train_loss = 0.95068346, grad/param norm = 1.6704e-01, time/batch = 16.8822s	
14526/26050 (epoch 27.881), train_loss = 1.02565727, grad/param norm = 2.1843e-01, time/batch = 18.6529s	
14527/26050 (epoch 27.883), train_loss = 0.97582054, grad/param norm = 1.9152e-01, time/batch = 18.8945s	
14528/26050 (epoch 27.885), train_loss = 0.72027944, grad/param norm = 1.6087e-01, time/batch = 17.3318s	
14529/26050 (epoch 27.887), train_loss = 0.99998229, grad/param norm = 2.1192e-01, time/batch = 18.3062s	
14530/26050 (epoch 27.889), train_loss = 0.87809921, grad/param norm = 1.8278e-01, time/batch = 15.6276s	
14531/26050 (epoch 27.891), train_loss = 0.76909424, grad/param norm = 1.7355e-01, time/batch = 16.6360s	
14532/26050 (epoch 27.893), train_loss = 0.81964904, grad/param norm = 1.8166e-01, time/batch = 17.4708s	
14533/26050 (epoch 27.894), train_loss = 0.89771241, grad/param norm = 1.9205e-01, time/batch = 18.4009s	
14534/26050 (epoch 27.896), train_loss = 1.02894589, grad/param norm = 2.1186e-01, time/batch = 18.7458s	
14535/26050 (epoch 27.898), train_loss = 0.90485403, grad/param norm = 2.2282e-01, time/batch = 14.5535s	
14536/26050 (epoch 27.900), train_loss = 0.98220533, grad/param norm = 2.0700e-01, time/batch = 17.9735s	
14537/26050 (epoch 27.902), train_loss = 0.93151572, grad/param norm = 2.1334e-01, time/batch = 18.3147s	
14538/26050 (epoch 27.904), train_loss = 0.89618327, grad/param norm = 1.8849e-01, time/batch = 16.3947s	
14539/26050 (epoch 27.906), train_loss = 0.89452170, grad/param norm = 1.9915e-01, time/batch = 16.1807s	
14540/26050 (epoch 27.908), train_loss = 0.93164460, grad/param norm = 1.8766e-01, time/batch = 18.4862s	
14541/26050 (epoch 27.910), train_loss = 0.90832668, grad/param norm = 1.8772e-01, time/batch = 15.3781s	
14542/26050 (epoch 27.912), train_loss = 1.13298908, grad/param norm = 2.2562e-01, time/batch = 17.4881s	
14543/26050 (epoch 27.914), train_loss = 1.29174536, grad/param norm = 2.4999e-01, time/batch = 16.8807s	
14544/26050 (epoch 27.916), train_loss = 1.04115779, grad/param norm = 2.3526e-01, time/batch = 17.3027s	
14545/26050 (epoch 27.917), train_loss = 0.94685183, grad/param norm = 2.1823e-01, time/batch = 17.2432s	
14546/26050 (epoch 27.919), train_loss = 1.00368741, grad/param norm = 2.5938e-01, time/batch = 17.8930s	
14547/26050 (epoch 27.921), train_loss = 0.88924780, grad/param norm = 2.1465e-01, time/batch = 17.9112s	
14548/26050 (epoch 27.923), train_loss = 0.95879712, grad/param norm = 1.9180e-01, time/batch = 18.1622s	
14549/26050 (epoch 27.925), train_loss = 0.94055154, grad/param norm = 1.9363e-01, time/batch = 17.8192s	
14550/26050 (epoch 27.927), train_loss = 0.83918005, grad/param norm = 1.5348e-01, time/batch = 18.5541s	
14551/26050 (epoch 27.929), train_loss = 0.79849802, grad/param norm = 1.7147e-01, time/batch = 18.1578s	
14552/26050 (epoch 27.931), train_loss = 1.11614989, grad/param norm = 2.3822e-01, time/batch = 17.0620s	
14553/26050 (epoch 27.933), train_loss = 0.89560976, grad/param norm = 1.9012e-01, time/batch = 17.4571s	
14554/26050 (epoch 27.935), train_loss = 0.90443321, grad/param norm = 1.8850e-01, time/batch = 15.3646s	
14555/26050 (epoch 27.937), train_loss = 1.02743374, grad/param norm = 1.9867e-01, time/batch = 18.2290s	
14556/26050 (epoch 27.939), train_loss = 0.85556598, grad/param norm = 1.6713e-01, time/batch = 15.8665s	
14557/26050 (epoch 27.940), train_loss = 0.87815327, grad/param norm = 1.6032e-01, time/batch = 15.3094s	
14558/26050 (epoch 27.942), train_loss = 0.92110948, grad/param norm = 1.9485e-01, time/batch = 18.5663s	
14559/26050 (epoch 27.944), train_loss = 0.90343546, grad/param norm = 1.7679e-01, time/batch = 17.2307s	
14560/26050 (epoch 27.946), train_loss = 1.05225006, grad/param norm = 1.9646e-01, time/batch = 18.4035s	
14561/26050 (epoch 27.948), train_loss = 0.79480362, grad/param norm = 1.8394e-01, time/batch = 18.9084s	
14562/26050 (epoch 27.950), train_loss = 0.91282245, grad/param norm = 1.9951e-01, time/batch = 18.4893s	
14563/26050 (epoch 27.952), train_loss = 1.01040310, grad/param norm = 2.3251e-01, time/batch = 18.3047s	
14564/26050 (epoch 27.954), train_loss = 1.01870793, grad/param norm = 1.9744e-01, time/batch = 14.8909s	
14565/26050 (epoch 27.956), train_loss = 0.90970718, grad/param norm = 2.0983e-01, time/batch = 18.3917s	
14566/26050 (epoch 27.958), train_loss = 0.85719185, grad/param norm = 1.7665e-01, time/batch = 16.7379s	
14567/26050 (epoch 27.960), train_loss = 0.96084597, grad/param norm = 1.9580e-01, time/batch = 18.7545s	
14568/26050 (epoch 27.962), train_loss = 0.91466332, grad/param norm = 1.9208e-01, time/batch = 18.4786s	
14569/26050 (epoch 27.964), train_loss = 0.92042484, grad/param norm = 1.7772e-01, time/batch = 16.7966s	
14570/26050 (epoch 27.965), train_loss = 0.85806787, grad/param norm = 1.8236e-01, time/batch = 15.4567s	
14571/26050 (epoch 27.967), train_loss = 1.25778497, grad/param norm = 2.2196e-01, time/batch = 18.8860s	
14572/26050 (epoch 27.969), train_loss = 0.96973741, grad/param norm = 2.0216e-01, time/batch = 17.4977s	
14573/26050 (epoch 27.971), train_loss = 0.90761504, grad/param norm = 1.8335e-01, time/batch = 15.1257s	
14574/26050 (epoch 27.973), train_loss = 0.92445397, grad/param norm = 1.8255e-01, time/batch = 18.4798s	
14575/26050 (epoch 27.975), train_loss = 0.98792847, grad/param norm = 2.2802e-01, time/batch = 18.8153s	
14576/26050 (epoch 27.977), train_loss = 0.95485398, grad/param norm = 1.9403e-01, time/batch = 18.0662s	
14577/26050 (epoch 27.979), train_loss = 0.77003507, grad/param norm = 1.9267e-01, time/batch = 15.1473s	
14578/26050 (epoch 27.981), train_loss = 1.06607085, grad/param norm = 1.9594e-01, time/batch = 18.7376s	
14579/26050 (epoch 27.983), train_loss = 1.01513407, grad/param norm = 2.1112e-01, time/batch = 17.4954s	
14580/26050 (epoch 27.985), train_loss = 0.99025682, grad/param norm = 1.8813e-01, time/batch = 17.7284s	
14581/26050 (epoch 27.987), train_loss = 1.03941858, grad/param norm = 2.1764e-01, time/batch = 17.6267s	
14582/26050 (epoch 27.988), train_loss = 0.98359740, grad/param norm = 1.9429e-01, time/batch = 18.5618s	
14583/26050 (epoch 27.990), train_loss = 0.83200007, grad/param norm = 1.6677e-01, time/batch = 17.8984s	
14584/26050 (epoch 27.992), train_loss = 1.07829313, grad/param norm = 1.9236e-01, time/batch = 15.8898s	
14585/26050 (epoch 27.994), train_loss = 0.91575768, grad/param norm = 2.1948e-01, time/batch = 17.6622s	
14586/26050 (epoch 27.996), train_loss = 0.87342870, grad/param norm = 2.3595e-01, time/batch = 18.6453s	
14587/26050 (epoch 27.998), train_loss = 0.94802831, grad/param norm = 1.8102e-01, time/batch = 16.7258s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
14588/26050 (epoch 28.000), train_loss = 0.89064760, grad/param norm = 2.2127e-01, time/batch = 18.4240s	
14589/26050 (epoch 28.002), train_loss = 1.00624448, grad/param norm = 2.2541e-01, time/batch = 17.8288s	
14590/26050 (epoch 28.004), train_loss = 0.82556884, grad/param norm = 1.8821e-01, time/batch = 16.3171s	
14591/26050 (epoch 28.006), train_loss = 0.88488492, grad/param norm = 2.1243e-01, time/batch = 16.1408s	
14592/26050 (epoch 28.008), train_loss = 0.88304031, grad/param norm = 2.1777e-01, time/batch = 18.1518s	
14593/26050 (epoch 28.010), train_loss = 0.87338972, grad/param norm = 1.9108e-01, time/batch = 17.9771s	
14594/26050 (epoch 28.012), train_loss = 0.93031858, grad/param norm = 1.8992e-01, time/batch = 18.3059s	
14595/26050 (epoch 28.013), train_loss = 1.18936091, grad/param norm = 2.3175e-01, time/batch = 15.6342s	
14596/26050 (epoch 28.015), train_loss = 0.93235435, grad/param norm = 1.8648e-01, time/batch = 17.7213s	
14597/26050 (epoch 28.017), train_loss = 0.95917177, grad/param norm = 1.9200e-01, time/batch = 16.9428s	
14598/26050 (epoch 28.019), train_loss = 0.83935326, grad/param norm = 1.8448e-01, time/batch = 18.9793s	
14599/26050 (epoch 28.021), train_loss = 1.02349255, grad/param norm = 2.0433e-01, time/batch = 18.2432s	
14600/26050 (epoch 28.023), train_loss = 0.77356656, grad/param norm = 1.9512e-01, time/batch = 15.0507s	
14601/26050 (epoch 28.025), train_loss = 0.90694918, grad/param norm = 1.7025e-01, time/batch = 18.3135s	
14602/26050 (epoch 28.027), train_loss = 0.76809941, grad/param norm = 2.0449e-01, time/batch = 18.2469s	
14603/26050 (epoch 28.029), train_loss = 0.95522243, grad/param norm = 1.8635e-01, time/batch = 18.2415s	
14604/26050 (epoch 28.031), train_loss = 1.05190461, grad/param norm = 2.1252e-01, time/batch = 18.3181s	
14605/26050 (epoch 28.033), train_loss = 0.94928203, grad/param norm = 1.9545e-01, time/batch = 18.1471s	
14606/26050 (epoch 28.035), train_loss = 0.95610207, grad/param norm = 1.8359e-01, time/batch = 15.2095s	
14607/26050 (epoch 28.036), train_loss = 0.81138105, grad/param norm = 2.1257e-01, time/batch = 16.0403s	
14608/26050 (epoch 28.038), train_loss = 0.74819698, grad/param norm = 1.7881e-01, time/batch = 17.9915s	
14609/26050 (epoch 28.040), train_loss = 0.91016440, grad/param norm = 1.8783e-01, time/batch = 18.3860s	
14610/26050 (epoch 28.042), train_loss = 0.78718234, grad/param norm = 1.8048e-01, time/batch = 15.2306s	
14611/26050 (epoch 28.044), train_loss = 1.01094324, grad/param norm = 1.8235e-01, time/batch = 16.2494s	
14612/26050 (epoch 28.046), train_loss = 0.75425656, grad/param norm = 1.6619e-01, time/batch = 17.7282s	
14613/26050 (epoch 28.048), train_loss = 0.93720807, grad/param norm = 1.8071e-01, time/batch = 17.9704s	
14614/26050 (epoch 28.050), train_loss = 0.87748868, grad/param norm = 1.8147e-01, time/batch = 17.3959s	
14615/26050 (epoch 28.052), train_loss = 0.85014106, grad/param norm = 2.0251e-01, time/batch = 18.4732s	
14616/26050 (epoch 28.054), train_loss = 0.77439402, grad/param norm = 1.7675e-01, time/batch = 17.8912s	
14617/26050 (epoch 28.056), train_loss = 0.76065872, grad/param norm = 1.7695e-01, time/batch = 17.9854s	
14618/26050 (epoch 28.058), train_loss = 0.90901976, grad/param norm = 1.8182e-01, time/batch = 17.5673s	
14619/26050 (epoch 28.060), train_loss = 0.99004597, grad/param norm = 1.9895e-01, time/batch = 17.2011s	
14620/26050 (epoch 28.061), train_loss = 0.84662292, grad/param norm = 1.8409e-01, time/batch = 18.0832s	
14621/26050 (epoch 28.063), train_loss = 0.94061291, grad/param norm = 1.8480e-01, time/batch = 17.3947s	
14622/26050 (epoch 28.065), train_loss = 0.75738010, grad/param norm = 1.6118e-01, time/batch = 18.7289s	
14623/26050 (epoch 28.067), train_loss = 0.91106304, grad/param norm = 2.1375e-01, time/batch = 18.5632s	
14624/26050 (epoch 28.069), train_loss = 0.96950868, grad/param norm = 2.0250e-01, time/batch = 17.2110s	
14625/26050 (epoch 28.071), train_loss = 0.96536069, grad/param norm = 1.9199e-01, time/batch = 18.2316s	
14626/26050 (epoch 28.073), train_loss = 1.06146185, grad/param norm = 1.9230e-01, time/batch = 18.5737s	
14627/26050 (epoch 28.075), train_loss = 0.86491260, grad/param norm = 1.7978e-01, time/batch = 14.7934s	
14628/26050 (epoch 28.077), train_loss = 0.89127895, grad/param norm = 1.9865e-01, time/batch = 18.2909s	
14629/26050 (epoch 28.079), train_loss = 0.91763383, grad/param norm = 1.9876e-01, time/batch = 16.7127s	
14630/26050 (epoch 28.081), train_loss = 0.90418293, grad/param norm = 1.9461e-01, time/batch = 18.4878s	
14631/26050 (epoch 28.083), train_loss = 1.02509246, grad/param norm = 1.8758e-01, time/batch = 17.7438s	
14632/26050 (epoch 28.084), train_loss = 0.93442597, grad/param norm = 2.3073e-01, time/batch = 18.4141s	
14633/26050 (epoch 28.086), train_loss = 1.08962057, grad/param norm = 2.2414e-01, time/batch = 18.0820s	
14634/26050 (epoch 28.088), train_loss = 0.87956212, grad/param norm = 1.9139e-01, time/batch = 17.9778s	
14635/26050 (epoch 28.090), train_loss = 0.92536680, grad/param norm = 1.9858e-01, time/batch = 16.4656s	
14636/26050 (epoch 28.092), train_loss = 0.97427522, grad/param norm = 1.7172e-01, time/batch = 17.6533s	
14637/26050 (epoch 28.094), train_loss = 0.82424863, grad/param norm = 1.9907e-01, time/batch = 17.4614s	
14638/26050 (epoch 28.096), train_loss = 0.93606641, grad/param norm = 1.8188e-01, time/batch = 17.9625s	
14639/26050 (epoch 28.098), train_loss = 0.87906345, grad/param norm = 1.7907e-01, time/batch = 18.3197s	
14640/26050 (epoch 28.100), train_loss = 0.85156411, grad/param norm = 2.0745e-01, time/batch = 17.9897s	
14641/26050 (epoch 28.102), train_loss = 0.98365481, grad/param norm = 2.1309e-01, time/batch = 15.8066s	
14642/26050 (epoch 28.104), train_loss = 0.89713215, grad/param norm = 1.9516e-01, time/batch = 18.1325s	
14643/26050 (epoch 28.106), train_loss = 0.93137421, grad/param norm = 2.1059e-01, time/batch = 18.1370s	
14644/26050 (epoch 28.107), train_loss = 0.75888713, grad/param norm = 1.8322e-01, time/batch = 17.4779s	
14645/26050 (epoch 28.109), train_loss = 0.85598904, grad/param norm = 2.0240e-01, time/batch = 15.1499s	
14646/26050 (epoch 28.111), train_loss = 1.07871551, grad/param norm = 2.1489e-01, time/batch = 18.7367s	
14647/26050 (epoch 28.113), train_loss = 0.87557012, grad/param norm = 1.9639e-01, time/batch = 17.5768s	
14648/26050 (epoch 28.115), train_loss = 1.01587017, grad/param norm = 2.0951e-01, time/batch = 16.3192s	
14649/26050 (epoch 28.117), train_loss = 0.92287319, grad/param norm = 1.9035e-01, time/batch = 16.4754s	
14650/26050 (epoch 28.119), train_loss = 0.78361093, grad/param norm = 1.8356e-01, time/batch = 18.8039s	
14651/26050 (epoch 28.121), train_loss = 0.93890192, grad/param norm = 1.9217e-01, time/batch = 17.6387s	
14652/26050 (epoch 28.123), train_loss = 0.85208962, grad/param norm = 2.0154e-01, time/batch = 15.2270s	
14653/26050 (epoch 28.125), train_loss = 0.80712807, grad/param norm = 1.7900e-01, time/batch = 18.8979s	
14654/26050 (epoch 28.127), train_loss = 0.76202178, grad/param norm = 1.8024e-01, time/batch = 18.3292s	
14655/26050 (epoch 28.129), train_loss = 0.75663821, grad/param norm = 1.8281e-01, time/batch = 17.9900s	
14656/26050 (epoch 28.131), train_loss = 0.88122719, grad/param norm = 2.0645e-01, time/batch = 18.1612s	
14657/26050 (epoch 28.132), train_loss = 0.88845011, grad/param norm = 1.7414e-01, time/batch = 18.4877s	
14658/26050 (epoch 28.134), train_loss = 0.93893140, grad/param norm = 2.0663e-01, time/batch = 19.1628s	
14659/26050 (epoch 28.136), train_loss = 0.90227628, grad/param norm = 1.8381e-01, time/batch = 33.6018s	
14660/26050 (epoch 28.138), train_loss = 0.69456107, grad/param norm = 1.7546e-01, time/batch = 19.9107s	
14661/26050 (epoch 28.140), train_loss = 0.78161796, grad/param norm = 2.1775e-01, time/batch = 17.1340s	
14662/26050 (epoch 28.142), train_loss = 0.80114094, grad/param norm = 1.8295e-01, time/batch = 18.1440s	
14663/26050 (epoch 28.144), train_loss = 0.73577480, grad/param norm = 2.4699e-01, time/batch = 18.8175s	
14664/26050 (epoch 28.146), train_loss = 0.69960910, grad/param norm = 1.7887e-01, time/batch = 15.0535s	
14665/26050 (epoch 28.148), train_loss = 0.72951382, grad/param norm = 1.6702e-01, time/batch = 18.1444s	
14666/26050 (epoch 28.150), train_loss = 0.87698557, grad/param norm = 2.0695e-01, time/batch = 18.1492s	
14667/26050 (epoch 28.152), train_loss = 1.07941366, grad/param norm = 2.6146e-01, time/batch = 17.0691s	
14668/26050 (epoch 28.154), train_loss = 0.75102359, grad/param norm = 2.1252e-01, time/batch = 17.5822s	
14669/26050 (epoch 28.155), train_loss = 0.77911788, grad/param norm = 1.8440e-01, time/batch = 18.0714s	
14670/26050 (epoch 28.157), train_loss = 0.90675816, grad/param norm = 2.6842e-01, time/batch = 16.7157s	
14671/26050 (epoch 28.159), train_loss = 0.95510143, grad/param norm = 2.2365e-01, time/batch = 18.8219s	
14672/26050 (epoch 28.161), train_loss = 0.92122364, grad/param norm = 1.9423e-01, time/batch = 18.4817s	
14673/26050 (epoch 28.163), train_loss = 0.76290344, grad/param norm = 1.8273e-01, time/batch = 18.5571s	
14674/26050 (epoch 28.165), train_loss = 0.72780826, grad/param norm = 1.8719e-01, time/batch = 17.1299s	
14675/26050 (epoch 28.167), train_loss = 1.03313152, grad/param norm = 2.1887e-01, time/batch = 18.2295s	
14676/26050 (epoch 28.169), train_loss = 0.92293824, grad/param norm = 2.2017e-01, time/batch = 17.9081s	
14677/26050 (epoch 28.171), train_loss = 0.77872015, grad/param norm = 1.7124e-01, time/batch = 17.5585s	
14678/26050 (epoch 28.173), train_loss = 0.88974198, grad/param norm = 1.9667e-01, time/batch = 18.7437s	
14679/26050 (epoch 28.175), train_loss = 0.88346143, grad/param norm = 1.8720e-01, time/batch = 18.5681s	
14680/26050 (epoch 28.177), train_loss = 0.99785884, grad/param norm = 2.0033e-01, time/batch = 15.9840s	
14681/26050 (epoch 28.179), train_loss = 0.66072215, grad/param norm = 1.4975e-01, time/batch = 14.7166s	
14682/26050 (epoch 28.180), train_loss = 1.11192306, grad/param norm = 1.9545e-01, time/batch = 17.7417s	
14683/26050 (epoch 28.182), train_loss = 1.11434221, grad/param norm = 2.2192e-01, time/batch = 18.7232s	
14684/26050 (epoch 28.184), train_loss = 0.94213531, grad/param norm = 1.8165e-01, time/batch = 15.8964s	
14685/26050 (epoch 28.186), train_loss = 0.76213660, grad/param norm = 1.8223e-01, time/batch = 18.2287s	
14686/26050 (epoch 28.188), train_loss = 0.93151960, grad/param norm = 1.9378e-01, time/batch = 18.4863s	
14687/26050 (epoch 28.190), train_loss = 0.95681896, grad/param norm = 2.0953e-01, time/batch = 17.6535s	
14688/26050 (epoch 28.192), train_loss = 0.95593135, grad/param norm = 1.7218e-01, time/batch = 17.0742s	
14689/26050 (epoch 28.194), train_loss = 0.96077353, grad/param norm = 1.9748e-01, time/batch = 18.8198s	
14690/26050 (epoch 28.196), train_loss = 0.97516156, grad/param norm = 1.9531e-01, time/batch = 16.3934s	
14691/26050 (epoch 28.198), train_loss = 0.82645283, grad/param norm = 1.7547e-01, time/batch = 15.8074s	
14692/26050 (epoch 28.200), train_loss = 0.81629129, grad/param norm = 1.8829e-01, time/batch = 18.3994s	
14693/26050 (epoch 28.202), train_loss = 0.91946161, grad/param norm = 1.7756e-01, time/batch = 17.9189s	
14694/26050 (epoch 28.203), train_loss = 1.02372372, grad/param norm = 1.9174e-01, time/batch = 16.2281s	
14695/26050 (epoch 28.205), train_loss = 0.86275065, grad/param norm = 1.8451e-01, time/batch = 18.0529s	
14696/26050 (epoch 28.207), train_loss = 0.83853623, grad/param norm = 1.9755e-01, time/batch = 17.1174s	
14697/26050 (epoch 28.209), train_loss = 0.96343056, grad/param norm = 1.9421e-01, time/batch = 16.4912s	
14698/26050 (epoch 28.211), train_loss = 0.77254229, grad/param norm = 2.0239e-01, time/batch = 16.8085s	
14699/26050 (epoch 28.213), train_loss = 0.93951087, grad/param norm = 2.0198e-01, time/batch = 17.8988s	
14700/26050 (epoch 28.215), train_loss = 0.89145035, grad/param norm = 2.2562e-01, time/batch = 18.7247s	
14701/26050 (epoch 28.217), train_loss = 0.85548963, grad/param norm = 1.7200e-01, time/batch = 17.3973s	
14702/26050 (epoch 28.219), train_loss = 0.88180981, grad/param norm = 1.9735e-01, time/batch = 18.2373s	
14703/26050 (epoch 28.221), train_loss = 0.81028848, grad/param norm = 1.7490e-01, time/batch = 15.3052s	
14704/26050 (epoch 28.223), train_loss = 0.98294493, grad/param norm = 2.1201e-01, time/batch = 18.0588s	
14705/26050 (epoch 28.225), train_loss = 0.83960688, grad/param norm = 2.1239e-01, time/batch = 18.0558s	
14706/26050 (epoch 28.226), train_loss = 0.95818429, grad/param norm = 2.1356e-01, time/batch = 17.9854s	
14707/26050 (epoch 28.228), train_loss = 1.04334245, grad/param norm = 1.9278e-01, time/batch = 18.7221s	
14708/26050 (epoch 28.230), train_loss = 0.94224424, grad/param norm = 2.1015e-01, time/batch = 14.7124s	
14709/26050 (epoch 28.232), train_loss = 1.00075781, grad/param norm = 2.1811e-01, time/batch = 18.4913s	
14710/26050 (epoch 28.234), train_loss = 0.81922170, grad/param norm = 1.9464e-01, time/batch = 18.5708s	
14711/26050 (epoch 28.236), train_loss = 0.98814535, grad/param norm = 2.0037e-01, time/batch = 17.9823s	
14712/26050 (epoch 28.238), train_loss = 0.79302651, grad/param norm = 2.0976e-01, time/batch = 18.8896s	
14713/26050 (epoch 28.240), train_loss = 0.91820131, grad/param norm = 1.9719e-01, time/batch = 17.2258s	
14714/26050 (epoch 28.242), train_loss = 0.89259335, grad/param norm = 1.9448e-01, time/batch = 17.6542s	
14715/26050 (epoch 28.244), train_loss = 0.93939796, grad/param norm = 2.1695e-01, time/batch = 18.2303s	
14716/26050 (epoch 28.246), train_loss = 0.84635989, grad/param norm = 1.9316e-01, time/batch = 15.0563s	
14717/26050 (epoch 28.248), train_loss = 0.91621897, grad/param norm = 1.9135e-01, time/batch = 18.5684s	
14718/26050 (epoch 28.250), train_loss = 0.91707425, grad/param norm = 2.8199e-01, time/batch = 17.4058s	
14719/26050 (epoch 28.251), train_loss = 0.87171098, grad/param norm = 1.8429e-01, time/batch = 18.9062s	
14720/26050 (epoch 28.253), train_loss = 0.81080353, grad/param norm = 1.9009e-01, time/batch = 18.9899s	
14721/26050 (epoch 28.255), train_loss = 1.08657802, grad/param norm = 2.0358e-01, time/batch = 16.8142s	
14722/26050 (epoch 28.257), train_loss = 0.89712233, grad/param norm = 2.2837e-01, time/batch = 18.0515s	
14723/26050 (epoch 28.259), train_loss = 1.01046907, grad/param norm = 2.0107e-01, time/batch = 15.7121s	
14724/26050 (epoch 28.261), train_loss = 0.81205239, grad/param norm = 2.1626e-01, time/batch = 18.4024s	
14725/26050 (epoch 28.263), train_loss = 1.00789095, grad/param norm = 2.2208e-01, time/batch = 16.0596s	
14726/26050 (epoch 28.265), train_loss = 1.05659449, grad/param norm = 2.0145e-01, time/batch = 18.4171s	
14727/26050 (epoch 28.267), train_loss = 1.02496920, grad/param norm = 1.7732e-01, time/batch = 18.7439s	
14728/26050 (epoch 28.269), train_loss = 1.01725385, grad/param norm = 2.1395e-01, time/batch = 16.1335s	
14729/26050 (epoch 28.271), train_loss = 0.95154359, grad/param norm = 2.1261e-01, time/batch = 18.1500s	
14730/26050 (epoch 28.273), train_loss = 0.84941660, grad/param norm = 2.2061e-01, time/batch = 18.7387s	
14731/26050 (epoch 28.274), train_loss = 0.88614804, grad/param norm = 1.7554e-01, time/batch = 18.2295s	
14732/26050 (epoch 28.276), train_loss = 0.88045407, grad/param norm = 1.9755e-01, time/batch = 18.8092s	
14733/26050 (epoch 28.278), train_loss = 1.02086427, grad/param norm = 1.9833e-01, time/batch = 18.4007s	
14734/26050 (epoch 28.280), train_loss = 0.91181156, grad/param norm = 1.9148e-01, time/batch = 17.3952s	
14735/26050 (epoch 28.282), train_loss = 0.96155383, grad/param norm = 1.8816e-01, time/batch = 15.8725s	
14736/26050 (epoch 28.284), train_loss = 0.88587362, grad/param norm = 1.8210e-01, time/batch = 14.5735s	
14737/26050 (epoch 28.286), train_loss = 0.94639991, grad/param norm = 2.0713e-01, time/batch = 18.7339s	
14738/26050 (epoch 28.288), train_loss = 0.79799196, grad/param norm = 2.2439e-01, time/batch = 17.8864s	
14739/26050 (epoch 28.290), train_loss = 0.92971195, grad/param norm = 2.0561e-01, time/batch = 17.3204s	
14740/26050 (epoch 28.292), train_loss = 0.84912082, grad/param norm = 1.8234e-01, time/batch = 18.6533s	
14741/26050 (epoch 28.294), train_loss = 0.91405740, grad/param norm = 2.1027e-01, time/batch = 18.8188s	
14742/26050 (epoch 28.296), train_loss = 1.02156822, grad/param norm = 2.2012e-01, time/batch = 17.1896s	
14743/26050 (epoch 28.298), train_loss = 0.95499697, grad/param norm = 1.7220e-01, time/batch = 18.4885s	
14744/26050 (epoch 28.299), train_loss = 0.76633979, grad/param norm = 1.6986e-01, time/batch = 18.5638s	
14745/26050 (epoch 28.301), train_loss = 0.77821057, grad/param norm = 2.0883e-01, time/batch = 17.3951s	
14746/26050 (epoch 28.303), train_loss = 0.92750437, grad/param norm = 2.3276e-01, time/batch = 15.3157s	
14747/26050 (epoch 28.305), train_loss = 0.75119581, grad/param norm = 1.8729e-01, time/batch = 18.3250s	
14748/26050 (epoch 28.307), train_loss = 0.84935032, grad/param norm = 2.0021e-01, time/batch = 17.0014s	
14749/26050 (epoch 28.309), train_loss = 0.89380136, grad/param norm = 1.9309e-01, time/batch = 18.7494s	
14750/26050 (epoch 28.311), train_loss = 0.98126290, grad/param norm = 2.3626e-01, time/batch = 17.9937s	
14751/26050 (epoch 28.313), train_loss = 0.91076964, grad/param norm = 2.1398e-01, time/batch = 18.3935s	
14752/26050 (epoch 28.315), train_loss = 0.99486111, grad/param norm = 1.9947e-01, time/batch = 15.8955s	
14753/26050 (epoch 28.317), train_loss = 0.94694162, grad/param norm = 2.0752e-01, time/batch = 18.3854s	
14754/26050 (epoch 28.319), train_loss = 0.83655001, grad/param norm = 1.8216e-01, time/batch = 18.7493s	
14755/26050 (epoch 28.321), train_loss = 0.90765278, grad/param norm = 2.1148e-01, time/batch = 14.4607s	
14756/26050 (epoch 28.322), train_loss = 0.96776495, grad/param norm = 1.8322e-01, time/batch = 18.5686s	
14757/26050 (epoch 28.324), train_loss = 0.73665929, grad/param norm = 1.6866e-01, time/batch = 18.6516s	
14758/26050 (epoch 28.326), train_loss = 1.04512636, grad/param norm = 2.0730e-01, time/batch = 18.3217s	
14759/26050 (epoch 28.328), train_loss = 0.93885419, grad/param norm = 1.8057e-01, time/batch = 14.7824s	
14760/26050 (epoch 28.330), train_loss = 0.78789162, grad/param norm = 1.8891e-01, time/batch = 18.9846s	
14761/26050 (epoch 28.332), train_loss = 0.97587794, grad/param norm = 1.9969e-01, time/batch = 18.4871s	
14762/26050 (epoch 28.334), train_loss = 0.84021141, grad/param norm = 1.8096e-01, time/batch = 16.8978s	
14763/26050 (epoch 28.336), train_loss = 0.85660320, grad/param norm = 1.8845e-01, time/batch = 18.7980s	
14764/26050 (epoch 28.338), train_loss = 0.81161036, grad/param norm = 1.8913e-01, time/batch = 18.5595s	
14765/26050 (epoch 28.340), train_loss = 0.97556489, grad/param norm = 1.8981e-01, time/batch = 17.1614s	
14766/26050 (epoch 28.342), train_loss = 1.02098921, grad/param norm = 2.0057e-01, time/batch = 17.9815s	
14767/26050 (epoch 28.344), train_loss = 0.83669855, grad/param norm = 2.0008e-01, time/batch = 15.7742s	
14768/26050 (epoch 28.345), train_loss = 0.90766440, grad/param norm = 2.1155e-01, time/batch = 18.1608s	
14769/26050 (epoch 28.347), train_loss = 1.03949907, grad/param norm = 1.9389e-01, time/batch = 16.4724s	
14770/26050 (epoch 28.349), train_loss = 0.95556356, grad/param norm = 1.9152e-01, time/batch = 17.7207s	
14771/26050 (epoch 28.351), train_loss = 0.95904788, grad/param norm = 1.9915e-01, time/batch = 18.3298s	
14772/26050 (epoch 28.353), train_loss = 0.93006365, grad/param norm = 2.0651e-01, time/batch = 17.8128s	
14773/26050 (epoch 28.355), train_loss = 0.94317802, grad/param norm = 2.2657e-01, time/batch = 18.3203s	
14774/26050 (epoch 28.357), train_loss = 0.86509340, grad/param norm = 1.7815e-01, time/batch = 18.3845s	
14775/26050 (epoch 28.359), train_loss = 1.00189761, grad/param norm = 2.0244e-01, time/batch = 18.2175s	
14776/26050 (epoch 28.361), train_loss = 0.82750616, grad/param norm = 1.7034e-01, time/batch = 18.0541s	
14777/26050 (epoch 28.363), train_loss = 1.00821469, grad/param norm = 2.1119e-01, time/batch = 17.9820s	
14778/26050 (epoch 28.365), train_loss = 0.88051756, grad/param norm = 1.7379e-01, time/batch = 18.5639s	
14779/26050 (epoch 28.367), train_loss = 0.98052885, grad/param norm = 1.8790e-01, time/batch = 17.0370s	
14780/26050 (epoch 28.369), train_loss = 0.83770305, grad/param norm = 1.7241e-01, time/batch = 18.0644s	
14781/26050 (epoch 28.370), train_loss = 0.82833741, grad/param norm = 1.7014e-01, time/batch = 18.3970s	
14782/26050 (epoch 28.372), train_loss = 0.94516583, grad/param norm = 2.0513e-01, time/batch = 14.7739s	
14783/26050 (epoch 28.374), train_loss = 1.04217043, grad/param norm = 1.9784e-01, time/batch = 18.8132s	
14784/26050 (epoch 28.376), train_loss = 1.08212350, grad/param norm = 2.0915e-01, time/batch = 18.0687s	
14785/26050 (epoch 28.378), train_loss = 0.85634900, grad/param norm = 1.7347e-01, time/batch = 18.0652s	
14786/26050 (epoch 28.380), train_loss = 1.06798330, grad/param norm = 2.1873e-01, time/batch = 15.9290s	
14787/26050 (epoch 28.382), train_loss = 1.17083606, grad/param norm = 2.3656e-01, time/batch = 14.0852s	
14788/26050 (epoch 28.384), train_loss = 0.89648929, grad/param norm = 2.2022e-01, time/batch = 14.1651s	
14789/26050 (epoch 28.386), train_loss = 0.98814940, grad/param norm = 2.4188e-01, time/batch = 14.0656s	
14790/26050 (epoch 28.388), train_loss = 0.96014230, grad/param norm = 2.1570e-01, time/batch = 16.1636s	
14791/26050 (epoch 28.390), train_loss = 0.86929523, grad/param norm = 1.7476e-01, time/batch = 14.9522s	
14792/26050 (epoch 28.392), train_loss = 0.81677863, grad/param norm = 1.9376e-01, time/batch = 18.4061s	
14793/26050 (epoch 28.393), train_loss = 0.96118253, grad/param norm = 2.0953e-01, time/batch = 16.5540s	
14794/26050 (epoch 28.395), train_loss = 1.00262433, grad/param norm = 2.0494e-01, time/batch = 17.6394s	
14795/26050 (epoch 28.397), train_loss = 0.99761875, grad/param norm = 2.3429e-01, time/batch = 14.1365s	
14796/26050 (epoch 28.399), train_loss = 0.86273992, grad/param norm = 1.8270e-01, time/batch = 17.8887s	
14797/26050 (epoch 28.401), train_loss = 0.93900537, grad/param norm = 1.9063e-01, time/batch = 17.3066s	
14798/26050 (epoch 28.403), train_loss = 0.94114825, grad/param norm = 2.1682e-01, time/batch = 18.3135s	
14799/26050 (epoch 28.405), train_loss = 0.94073063, grad/param norm = 1.9980e-01, time/batch = 18.6467s	
14800/26050 (epoch 28.407), train_loss = 1.06225607, grad/param norm = 2.1033e-01, time/batch = 16.6578s	
14801/26050 (epoch 28.409), train_loss = 1.06695874, grad/param norm = 2.2144e-01, time/batch = 17.7407s	
14802/26050 (epoch 28.411), train_loss = 0.98525540, grad/param norm = 2.1858e-01, time/batch = 16.5664s	
14803/26050 (epoch 28.413), train_loss = 1.08643938, grad/param norm = 1.9072e-01, time/batch = 18.1381s	
14804/26050 (epoch 28.415), train_loss = 1.10992042, grad/param norm = 3.3486e-01, time/batch = 17.3004s	
14805/26050 (epoch 28.417), train_loss = 1.13004423, grad/param norm = 2.3257e-01, time/batch = 16.8944s	
14806/26050 (epoch 28.418), train_loss = 1.00791071, grad/param norm = 2.2695e-01, time/batch = 18.2242s	
14807/26050 (epoch 28.420), train_loss = 0.81033365, grad/param norm = 1.7209e-01, time/batch = 17.0648s	
14808/26050 (epoch 28.422), train_loss = 0.79287053, grad/param norm = 1.8600e-01, time/batch = 18.2413s	
14809/26050 (epoch 28.424), train_loss = 1.05955511, grad/param norm = 2.1882e-01, time/batch = 16.5615s	
14810/26050 (epoch 28.426), train_loss = 1.02222900, grad/param norm = 2.1489e-01, time/batch = 15.1188s	
14811/26050 (epoch 28.428), train_loss = 0.88658051, grad/param norm = 1.9019e-01, time/batch = 17.8110s	
14812/26050 (epoch 28.430), train_loss = 1.08666837, grad/param norm = 2.1651e-01, time/batch = 17.9915s	
14813/26050 (epoch 28.432), train_loss = 0.91279821, grad/param norm = 2.2131e-01, time/batch = 18.8051s	
14814/26050 (epoch 28.434), train_loss = 0.91896618, grad/param norm = 1.9984e-01, time/batch = 16.4623s	
14815/26050 (epoch 28.436), train_loss = 1.06598579, grad/param norm = 2.1586e-01, time/batch = 17.2465s	
14816/26050 (epoch 28.438), train_loss = 1.01080719, grad/param norm = 2.1892e-01, time/batch = 18.3047s	
14817/26050 (epoch 28.440), train_loss = 0.97214192, grad/param norm = 2.0639e-01, time/batch = 15.7183s	
14818/26050 (epoch 28.441), train_loss = 0.96550952, grad/param norm = 2.2571e-01, time/batch = 18.1678s	
14819/26050 (epoch 28.443), train_loss = 0.79698834, grad/param norm = 1.5884e-01, time/batch = 17.9815s	
14820/26050 (epoch 28.445), train_loss = 0.85313973, grad/param norm = 1.7842e-01, time/batch = 18.4776s	
14821/26050 (epoch 28.447), train_loss = 1.05208327, grad/param norm = 2.0463e-01, time/batch = 17.5744s	
14822/26050 (epoch 28.449), train_loss = 0.86875312, grad/param norm = 1.8709e-01, time/batch = 18.6517s	
14823/26050 (epoch 28.451), train_loss = 1.07664786, grad/param norm = 2.1369e-01, time/batch = 17.2472s	
14824/26050 (epoch 28.453), train_loss = 0.87227769, grad/param norm = 1.6741e-01, time/batch = 16.9746s	
14825/26050 (epoch 28.455), train_loss = 0.93362808, grad/param norm = 1.7826e-01, time/batch = 18.1594s	
14826/26050 (epoch 28.457), train_loss = 0.93261325, grad/param norm = 2.1144e-01, time/batch = 17.7341s	
14827/26050 (epoch 28.459), train_loss = 1.03771418, grad/param norm = 2.0396e-01, time/batch = 16.4681s	
14828/26050 (epoch 28.461), train_loss = 1.04096738, grad/param norm = 2.4288e-01, time/batch = 17.8179s	
14829/26050 (epoch 28.463), train_loss = 0.88945818, grad/param norm = 1.6858e-01, time/batch = 18.3444s	
14830/26050 (epoch 28.464), train_loss = 0.96845409, grad/param norm = 1.9431e-01, time/batch = 18.8197s	
14831/26050 (epoch 28.466), train_loss = 0.97814491, grad/param norm = 2.2513e-01, time/batch = 17.7291s	
14832/26050 (epoch 28.468), train_loss = 1.02740144, grad/param norm = 1.7639e-01, time/batch = 18.3214s	
14833/26050 (epoch 28.470), train_loss = 1.03631247, grad/param norm = 2.2959e-01, time/batch = 15.3705s	
14834/26050 (epoch 28.472), train_loss = 1.06998955, grad/param norm = 2.2410e-01, time/batch = 14.7921s	
14835/26050 (epoch 28.474), train_loss = 1.05812669, grad/param norm = 2.0806e-01, time/batch = 16.9752s	
14836/26050 (epoch 28.476), train_loss = 1.05678265, grad/param norm = 1.9369e-01, time/batch = 17.9023s	
14837/26050 (epoch 28.478), train_loss = 0.91308737, grad/param norm = 1.8654e-01, time/batch = 18.8985s	
14838/26050 (epoch 28.480), train_loss = 0.92907443, grad/param norm = 1.8651e-01, time/batch = 17.3858s	
14839/26050 (epoch 28.482), train_loss = 0.91509585, grad/param norm = 1.9365e-01, time/batch = 18.0641s	
14840/26050 (epoch 28.484), train_loss = 0.88451132, grad/param norm = 1.9308e-01, time/batch = 16.1955s	
14841/26050 (epoch 28.486), train_loss = 1.08641086, grad/param norm = 2.0992e-01, time/batch = 17.8256s	
14842/26050 (epoch 28.488), train_loss = 1.10285352, grad/param norm = 2.1341e-01, time/batch = 17.4912s	
14843/26050 (epoch 28.489), train_loss = 1.12260860, grad/param norm = 2.7985e-01, time/batch = 18.3964s	
14844/26050 (epoch 28.491), train_loss = 0.86499233, grad/param norm = 2.0775e-01, time/batch = 16.6293s	
14845/26050 (epoch 28.493), train_loss = 0.97300216, grad/param norm = 2.1870e-01, time/batch = 16.7197s	
14846/26050 (epoch 28.495), train_loss = 0.92841299, grad/param norm = 1.8919e-01, time/batch = 18.4117s	
14847/26050 (epoch 28.497), train_loss = 0.84325975, grad/param norm = 1.8464e-01, time/batch = 18.5869s	
14848/26050 (epoch 28.499), train_loss = 0.90939172, grad/param norm = 1.9395e-01, time/batch = 17.0663s	
14849/26050 (epoch 28.501), train_loss = 1.02695391, grad/param norm = 2.0455e-01, time/batch = 18.4798s	
14850/26050 (epoch 28.503), train_loss = 0.88200929, grad/param norm = 1.8856e-01, time/batch = 18.6514s	
14851/26050 (epoch 28.505), train_loss = 1.05276707, grad/param norm = 2.0227e-01, time/batch = 17.3073s	
14852/26050 (epoch 28.507), train_loss = 1.01959620, grad/param norm = 2.2223e-01, time/batch = 17.7926s	
14853/26050 (epoch 28.509), train_loss = 1.09513875, grad/param norm = 1.8884e-01, time/batch = 15.6254s	
14854/26050 (epoch 28.511), train_loss = 0.89712377, grad/param norm = 1.6805e-01, time/batch = 18.5640s	
14855/26050 (epoch 28.512), train_loss = 0.83494652, grad/param norm = 2.3070e-01, time/batch = 16.8938s	
14856/26050 (epoch 28.514), train_loss = 1.00311860, grad/param norm = 2.2353e-01, time/batch = 18.2268s	
14857/26050 (epoch 28.516), train_loss = 1.06511660, grad/param norm = 2.0781e-01, time/batch = 17.7336s	
14858/26050 (epoch 28.518), train_loss = 0.91603496, grad/param norm = 1.9763e-01, time/batch = 14.8914s	
14859/26050 (epoch 28.520), train_loss = 0.94056977, grad/param norm = 1.9359e-01, time/batch = 18.0765s	
14860/26050 (epoch 28.522), train_loss = 0.74736858, grad/param norm = 1.7689e-01, time/batch = 18.8224s	
14861/26050 (epoch 28.524), train_loss = 1.04006864, grad/param norm = 2.3595e-01, time/batch = 18.2241s	
14862/26050 (epoch 28.526), train_loss = 1.03601354, grad/param norm = 2.0503e-01, time/batch = 29.4027s	
14863/26050 (epoch 28.528), train_loss = 0.98291285, grad/param norm = 2.0878e-01, time/batch = 27.6093s	
14864/26050 (epoch 28.530), train_loss = 0.90035428, grad/param norm = 2.1984e-01, time/batch = 18.7257s	
14865/26050 (epoch 28.532), train_loss = 0.98614672, grad/param norm = 2.1934e-01, time/batch = 17.4868s	
14866/26050 (epoch 28.534), train_loss = 1.01928628, grad/param norm = 2.3802e-01, time/batch = 17.5457s	
14867/26050 (epoch 28.536), train_loss = 0.95867194, grad/param norm = 1.9179e-01, time/batch = 16.9709s	
14868/26050 (epoch 28.537), train_loss = 1.02515085, grad/param norm = 2.0333e-01, time/batch = 18.4775s	
14869/26050 (epoch 28.539), train_loss = 0.95150069, grad/param norm = 2.0225e-01, time/batch = 18.3980s	
14870/26050 (epoch 28.541), train_loss = 1.12082453, grad/param norm = 2.2126e-01, time/batch = 14.7974s	
14871/26050 (epoch 28.543), train_loss = 0.78908719, grad/param norm = 1.9068e-01, time/batch = 16.7125s	
14872/26050 (epoch 28.545), train_loss = 0.95205285, grad/param norm = 1.8660e-01, time/batch = 18.8842s	
14873/26050 (epoch 28.547), train_loss = 0.92706943, grad/param norm = 2.0303e-01, time/batch = 17.7413s	
14874/26050 (epoch 28.549), train_loss = 0.78848725, grad/param norm = 1.9298e-01, time/batch = 17.3164s	
14875/26050 (epoch 28.551), train_loss = 1.01077764, grad/param norm = 2.0358e-01, time/batch = 18.2370s	
14876/26050 (epoch 28.553), train_loss = 0.87508902, grad/param norm = 1.7983e-01, time/batch = 18.2381s	
14877/26050 (epoch 28.555), train_loss = 0.84515329, grad/param norm = 1.9431e-01, time/batch = 16.4862s	
14878/26050 (epoch 28.557), train_loss = 0.97374775, grad/param norm = 1.9365e-01, time/batch = 17.5773s	
14879/26050 (epoch 28.559), train_loss = 0.95052937, grad/param norm = 2.0265e-01, time/batch = 18.7456s	
14880/26050 (epoch 28.560), train_loss = 0.90322217, grad/param norm = 2.1397e-01, time/batch = 18.3214s	
14881/26050 (epoch 28.562), train_loss = 0.93455332, grad/param norm = 2.1057e-01, time/batch = 17.5555s	
14882/26050 (epoch 28.564), train_loss = 1.10902279, grad/param norm = 1.8987e-01, time/batch = 16.0522s	
14883/26050 (epoch 28.566), train_loss = 0.87021232, grad/param norm = 1.8086e-01, time/batch = 18.6454s	
14884/26050 (epoch 28.568), train_loss = 0.99032361, grad/param norm = 2.0139e-01, time/batch = 17.2370s	
14885/26050 (epoch 28.570), train_loss = 0.96630945, grad/param norm = 2.0277e-01, time/batch = 18.0752s	
14886/26050 (epoch 28.572), train_loss = 0.94496534, grad/param norm = 2.1184e-01, time/batch = 17.8293s	
14887/26050 (epoch 28.574), train_loss = 0.94996438, grad/param norm = 2.2222e-01, time/batch = 17.6338s	
14888/26050 (epoch 28.576), train_loss = 0.99450244, grad/param norm = 2.2069e-01, time/batch = 17.3799s	
14889/26050 (epoch 28.578), train_loss = 0.93727310, grad/param norm = 2.1204e-01, time/batch = 17.5554s	
14890/26050 (epoch 28.580), train_loss = 0.86713270, grad/param norm = 2.0125e-01, time/batch = 18.1644s	
14891/26050 (epoch 28.582), train_loss = 0.95893100, grad/param norm = 1.8834e-01, time/batch = 17.9660s	
14892/26050 (epoch 28.583), train_loss = 1.02887985, grad/param norm = 1.9124e-01, time/batch = 15.6397s	
14893/26050 (epoch 28.585), train_loss = 0.83902969, grad/param norm = 1.9450e-01, time/batch = 15.8139s	
14894/26050 (epoch 28.587), train_loss = 0.96712737, grad/param norm = 1.9730e-01, time/batch = 16.9812s	
14895/26050 (epoch 28.589), train_loss = 1.11375416, grad/param norm = 2.8526e-01, time/batch = 18.8392s	
14896/26050 (epoch 28.591), train_loss = 0.93448601, grad/param norm = 1.8227e-01, time/batch = 18.3248s	
14897/26050 (epoch 28.593), train_loss = 0.82868961, grad/param norm = 1.9002e-01, time/batch = 17.4845s	
14898/26050 (epoch 28.595), train_loss = 1.01472022, grad/param norm = 2.2855e-01, time/batch = 17.8860s	
14899/26050 (epoch 28.597), train_loss = 0.95650854, grad/param norm = 1.9570e-01, time/batch = 18.5313s	
14900/26050 (epoch 28.599), train_loss = 0.97799455, grad/param norm = 2.1209e-01, time/batch = 15.8119s	
14901/26050 (epoch 28.601), train_loss = 1.10970097, grad/param norm = 2.0926e-01, time/batch = 17.4867s	
14902/26050 (epoch 28.603), train_loss = 1.00008894, grad/param norm = 2.1430e-01, time/batch = 18.3002s	
14903/26050 (epoch 28.605), train_loss = 0.91376989, grad/param norm = 2.0468e-01, time/batch = 18.0708s	
14904/26050 (epoch 28.607), train_loss = 1.03874681, grad/param norm = 2.3354e-01, time/batch = 15.2047s	
14905/26050 (epoch 28.608), train_loss = 0.85901805, grad/param norm = 1.8979e-01, time/batch = 18.2070s	
14906/26050 (epoch 28.610), train_loss = 0.95739445, grad/param norm = 2.1246e-01, time/batch = 18.0548s	
14907/26050 (epoch 28.612), train_loss = 0.91477355, grad/param norm = 1.9235e-01, time/batch = 18.7992s	
14908/26050 (epoch 28.614), train_loss = 0.96468828, grad/param norm = 2.0081e-01, time/batch = 17.4731s	
14909/26050 (epoch 28.616), train_loss = 1.03294625, grad/param norm = 2.1469e-01, time/batch = 18.0760s	
14910/26050 (epoch 28.618), train_loss = 0.90028521, grad/param norm = 1.9888e-01, time/batch = 18.1541s	
14911/26050 (epoch 28.620), train_loss = 1.00543767, grad/param norm = 2.1270e-01, time/batch = 16.9810s	
14912/26050 (epoch 28.622), train_loss = 0.83889510, grad/param norm = 1.6608e-01, time/batch = 15.8753s	
14913/26050 (epoch 28.624), train_loss = 0.80779319, grad/param norm = 1.8849e-01, time/batch = 18.5721s	
14914/26050 (epoch 28.626), train_loss = 0.99626883, grad/param norm = 1.9914e-01, time/batch = 17.9072s	
14915/26050 (epoch 28.628), train_loss = 0.88829276, grad/param norm = 2.1370e-01, time/batch = 18.3876s	
14916/26050 (epoch 28.630), train_loss = 1.06954282, grad/param norm = 1.8470e-01, time/batch = 15.6503s	
14917/26050 (epoch 28.631), train_loss = 1.10713154, grad/param norm = 2.0893e-01, time/batch = 17.8094s	
14918/26050 (epoch 28.633), train_loss = 0.85473491, grad/param norm = 1.8539e-01, time/batch = 18.1357s	
14919/26050 (epoch 28.635), train_loss = 0.90137817, grad/param norm = 1.8803e-01, time/batch = 17.9161s	
14920/26050 (epoch 28.637), train_loss = 0.82659613, grad/param norm = 1.8038e-01, time/batch = 18.8236s	
14921/26050 (epoch 28.639), train_loss = 1.01102351, grad/param norm = 1.9003e-01, time/batch = 18.4753s	
14922/26050 (epoch 28.641), train_loss = 0.90072089, grad/param norm = 1.8411e-01, time/batch = 15.4621s	
14923/26050 (epoch 28.643), train_loss = 0.85026702, grad/param norm = 1.5748e-01, time/batch = 17.7116s	
14924/26050 (epoch 28.645), train_loss = 0.89131138, grad/param norm = 1.9727e-01, time/batch = 18.1612s	
14925/26050 (epoch 28.647), train_loss = 0.88082666, grad/param norm = 2.0961e-01, time/batch = 17.4754s	
14926/26050 (epoch 28.649), train_loss = 0.93765189, grad/param norm = 2.0223e-01, time/batch = 17.8284s	
14927/26050 (epoch 28.651), train_loss = 0.88849819, grad/param norm = 2.0584e-01, time/batch = 16.4645s	
14928/26050 (epoch 28.653), train_loss = 0.92115728, grad/param norm = 2.0124e-01, time/batch = 17.1281s	
14929/26050 (epoch 28.655), train_loss = 0.85852245, grad/param norm = 1.9841e-01, time/batch = 18.1487s	
14930/26050 (epoch 28.656), train_loss = 0.81594584, grad/param norm = 1.9199e-01, time/batch = 17.8846s	
14931/26050 (epoch 28.658), train_loss = 1.13107650, grad/param norm = 2.1894e-01, time/batch = 17.5441s	
14932/26050 (epoch 28.660), train_loss = 0.82180106, grad/param norm = 2.3200e-01, time/batch = 14.3464s	
14933/26050 (epoch 28.662), train_loss = 0.94193035, grad/param norm = 2.2025e-01, time/batch = 16.0633s	
14934/26050 (epoch 28.664), train_loss = 0.92047347, grad/param norm = 1.9623e-01, time/batch = 18.1492s	
14935/26050 (epoch 28.666), train_loss = 0.87309666, grad/param norm = 1.9362e-01, time/batch = 17.4744s	
14936/26050 (epoch 28.668), train_loss = 0.74919480, grad/param norm = 2.1738e-01, time/batch = 18.3129s	
14937/26050 (epoch 28.670), train_loss = 1.06820098, grad/param norm = 2.2523e-01, time/batch = 15.3240s	
14938/26050 (epoch 28.672), train_loss = 0.94319106, grad/param norm = 1.9362e-01, time/batch = 17.8756s	
14939/26050 (epoch 28.674), train_loss = 0.83633310, grad/param norm = 1.9774e-01, time/batch = 17.5239s	
14940/26050 (epoch 28.676), train_loss = 0.98615804, grad/param norm = 2.1697e-01, time/batch = 18.3966s	
14941/26050 (epoch 28.678), train_loss = 1.02287971, grad/param norm = 2.1993e-01, time/batch = 16.2179s	
14942/26050 (epoch 28.679), train_loss = 1.07935277, grad/param norm = 2.3429e-01, time/batch = 16.4754s	
14943/26050 (epoch 28.681), train_loss = 0.95521300, grad/param norm = 2.0840e-01, time/batch = 18.0611s	
14944/26050 (epoch 28.683), train_loss = 0.82906608, grad/param norm = 2.7711e-01, time/batch = 18.5676s	
14945/26050 (epoch 28.685), train_loss = 0.91860822, grad/param norm = 1.9713e-01, time/batch = 17.6388s	
14946/26050 (epoch 28.687), train_loss = 0.83464301, grad/param norm = 1.9664e-01, time/batch = 17.7281s	
14947/26050 (epoch 28.689), train_loss = 0.89844305, grad/param norm = 2.0713e-01, time/batch = 17.9764s	
14948/26050 (epoch 28.691), train_loss = 0.74797823, grad/param norm = 1.5660e-01, time/batch = 18.8265s	
14949/26050 (epoch 28.693), train_loss = 0.86781716, grad/param norm = 1.8659e-01, time/batch = 17.3173s	
14950/26050 (epoch 28.695), train_loss = 0.93284972, grad/param norm = 1.9158e-01, time/batch = 17.4866s	
14951/26050 (epoch 28.697), train_loss = 0.85855832, grad/param norm = 1.9343e-01, time/batch = 17.7110s	
14952/26050 (epoch 28.699), train_loss = 0.98793428, grad/param norm = 2.2200e-01, time/batch = 16.6751s	
14953/26050 (epoch 28.701), train_loss = 0.82909302, grad/param norm = 1.6777e-01, time/batch = 17.2085s	
14954/26050 (epoch 28.702), train_loss = 1.02037183, grad/param norm = 2.1056e-01, time/batch = 17.5594s	
14955/26050 (epoch 28.704), train_loss = 1.02083461, grad/param norm = 1.9018e-01, time/batch = 18.0496s	
14956/26050 (epoch 28.706), train_loss = 0.87783595, grad/param norm = 1.9299e-01, time/batch = 18.0755s	
14957/26050 (epoch 28.708), train_loss = 1.02415836, grad/param norm = 2.2308e-01, time/batch = 18.3379s	
14958/26050 (epoch 28.710), train_loss = 0.96284797, grad/param norm = 2.2568e-01, time/batch = 15.2083s	
14959/26050 (epoch 28.712), train_loss = 0.93833075, grad/param norm = 2.0661e-01, time/batch = 17.2521s	
14960/26050 (epoch 28.714), train_loss = 0.82337649, grad/param norm = 1.7189e-01, time/batch = 18.1601s	
14961/26050 (epoch 28.716), train_loss = 1.17818393, grad/param norm = 2.4694e-01, time/batch = 18.3183s	
14962/26050 (epoch 28.718), train_loss = 1.00679702, grad/param norm = 2.1241e-01, time/batch = 14.5400s	
14963/26050 (epoch 28.720), train_loss = 0.91213289, grad/param norm = 1.9016e-01, time/batch = 17.6641s	
14964/26050 (epoch 28.722), train_loss = 0.83237001, grad/param norm = 1.8132e-01, time/batch = 18.0562s	
14965/26050 (epoch 28.724), train_loss = 0.87586108, grad/param norm = 2.0697e-01, time/batch = 16.9632s	
14966/26050 (epoch 28.726), train_loss = 0.98538494, grad/param norm = 2.0554e-01, time/batch = 17.4024s	
14967/26050 (epoch 28.727), train_loss = 0.99209755, grad/param norm = 2.0678e-01, time/batch = 17.8175s	
14968/26050 (epoch 28.729), train_loss = 0.98587297, grad/param norm = 1.9601e-01, time/batch = 18.6567s	
14969/26050 (epoch 28.731), train_loss = 0.97657734, grad/param norm = 1.8762e-01, time/batch = 17.4756s	
14970/26050 (epoch 28.733), train_loss = 0.89842551, grad/param norm = 2.1391e-01, time/batch = 18.8909s	
14971/26050 (epoch 28.735), train_loss = 1.11202763, grad/param norm = 2.2809e-01, time/batch = 18.4168s	
14972/26050 (epoch 28.737), train_loss = 0.88560246, grad/param norm = 1.8876e-01, time/batch = 16.4943s	
14973/26050 (epoch 28.739), train_loss = 0.96531882, grad/param norm = 1.9029e-01, time/batch = 17.4630s	
14974/26050 (epoch 28.741), train_loss = 0.87456690, grad/param norm = 1.9875e-01, time/batch = 18.5773s	
14975/26050 (epoch 28.743), train_loss = 0.95450774, grad/param norm = 2.2261e-01, time/batch = 18.9940s	
14976/26050 (epoch 28.745), train_loss = 0.82465699, grad/param norm = 1.9314e-01, time/batch = 16.1305s	
14977/26050 (epoch 28.747), train_loss = 0.86751254, grad/param norm = 1.8809e-01, time/batch = 17.9986s	
14978/26050 (epoch 28.749), train_loss = 1.02554557, grad/param norm = 2.0717e-01, time/batch = 18.0764s	
14979/26050 (epoch 28.750), train_loss = 0.93681259, grad/param norm = 1.7919e-01, time/batch = 14.5543s	
14980/26050 (epoch 28.752), train_loss = 0.88042523, grad/param norm = 2.2753e-01, time/batch = 14.8157s	
14981/26050 (epoch 28.754), train_loss = 0.94674923, grad/param norm = 1.8713e-01, time/batch = 18.8279s	
14982/26050 (epoch 28.756), train_loss = 0.93974346, grad/param norm = 2.5262e-01, time/batch = 18.4169s	
14983/26050 (epoch 28.758), train_loss = 0.90759915, grad/param norm = 2.0129e-01, time/batch = 17.3971s	
14984/26050 (epoch 28.760), train_loss = 1.08947656, grad/param norm = 2.1572e-01, time/batch = 16.0545s	
14985/26050 (epoch 28.762), train_loss = 0.88995923, grad/param norm = 2.3634e-01, time/batch = 18.3975s	
14986/26050 (epoch 28.764), train_loss = 0.93220288, grad/param norm = 2.2854e-01, time/batch = 17.6386s	
14987/26050 (epoch 28.766), train_loss = 0.96139864, grad/param norm = 2.1689e-01, time/batch = 17.4968s	
14988/26050 (epoch 28.768), train_loss = 0.83227924, grad/param norm = 1.7781e-01, time/batch = 16.9480s	
14989/26050 (epoch 28.770), train_loss = 0.90583009, grad/param norm = 2.0138e-01, time/batch = 18.7338s	
14990/26050 (epoch 28.772), train_loss = 0.92568633, grad/param norm = 1.9058e-01, time/batch = 18.0590s	
14991/26050 (epoch 28.774), train_loss = 0.81494267, grad/param norm = 2.1084e-01, time/batch = 18.1522s	
14992/26050 (epoch 28.775), train_loss = 0.68659239, grad/param norm = 1.9283e-01, time/batch = 18.7360s	
14993/26050 (epoch 28.777), train_loss = 0.89657993, grad/param norm = 1.9623e-01, time/batch = 17.4874s	
14994/26050 (epoch 28.779), train_loss = 0.93193780, grad/param norm = 2.2164e-01, time/batch = 18.3980s	
14995/26050 (epoch 28.781), train_loss = 0.80652162, grad/param norm = 1.8272e-01, time/batch = 17.9782s	
14996/26050 (epoch 28.783), train_loss = 0.80464741, grad/param norm = 1.7771e-01, time/batch = 15.5667s	
14997/26050 (epoch 28.785), train_loss = 0.94461215, grad/param norm = 2.1311e-01, time/batch = 15.0599s	
14998/26050 (epoch 28.787), train_loss = 0.84168382, grad/param norm = 1.9751e-01, time/batch = 18.4634s	
14999/26050 (epoch 28.789), train_loss = 0.86529310, grad/param norm = 2.1423e-01, time/batch = 18.6509s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch28.79_1.8085.t7	
15000/26050 (epoch 28.791), train_loss = 0.85482827, grad/param norm = 1.9122e-01, time/batch = 17.3113s	
15001/26050 (epoch 28.793), train_loss = 1.43552928, grad/param norm = 2.9472e-01, time/batch = 17.7923s	
15002/26050 (epoch 28.795), train_loss = 0.74597847, grad/param norm = 1.5903e-01, time/batch = 18.1592s	
15003/26050 (epoch 28.797), train_loss = 0.81308238, grad/param norm = 1.9143e-01, time/batch = 18.2333s	
15004/26050 (epoch 28.798), train_loss = 0.82937728, grad/param norm = 2.1315e-01, time/batch = 18.2199s	
15005/26050 (epoch 28.800), train_loss = 0.81919084, grad/param norm = 1.8327e-01, time/batch = 18.5812s	
15006/26050 (epoch 28.802), train_loss = 0.88207428, grad/param norm = 1.9359e-01, time/batch = 18.3278s	
15007/26050 (epoch 28.804), train_loss = 0.91644021, grad/param norm = 2.0723e-01, time/batch = 12.6107s	
15008/26050 (epoch 28.806), train_loss = 0.98908727, grad/param norm = 2.2444e-01, time/batch = 0.6779s	
15009/26050 (epoch 28.808), train_loss = 0.92739517, grad/param norm = 2.1017e-01, time/batch = 0.6708s	
15010/26050 (epoch 28.810), train_loss = 0.88623702, grad/param norm = 2.1612e-01, time/batch = 0.6736s	
15011/26050 (epoch 28.812), train_loss = 0.79903015, grad/param norm = 1.9885e-01, time/batch = 0.6601s	
15012/26050 (epoch 28.814), train_loss = 0.85164654, grad/param norm = 2.3929e-01, time/batch = 0.6574s	
15013/26050 (epoch 28.816), train_loss = 0.96369372, grad/param norm = 2.0846e-01, time/batch = 0.6447s	
15014/26050 (epoch 28.818), train_loss = 1.01300359, grad/param norm = 2.4805e-01, time/batch = 0.6416s	
15015/26050 (epoch 28.820), train_loss = 0.94516636, grad/param norm = 2.0403e-01, time/batch = 0.8485s	
15016/26050 (epoch 28.821), train_loss = 1.02849416, grad/param norm = 2.2748e-01, time/batch = 0.9452s	
15017/26050 (epoch 28.823), train_loss = 1.08992031, grad/param norm = 2.0181e-01, time/batch = 0.9422s	
15018/26050 (epoch 28.825), train_loss = 0.94466635, grad/param norm = 2.1298e-01, time/batch = 0.9425s	
15019/26050 (epoch 28.827), train_loss = 0.94599631, grad/param norm = 2.1864e-01, time/batch = 0.9329s	
15020/26050 (epoch 28.829), train_loss = 0.98895119, grad/param norm = 2.0882e-01, time/batch = 1.2381s	
15021/26050 (epoch 28.831), train_loss = 1.05987397, grad/param norm = 2.0332e-01, time/batch = 1.7823s	
15022/26050 (epoch 28.833), train_loss = 1.08128725, grad/param norm = 2.1815e-01, time/batch = 1.7689s	
15023/26050 (epoch 28.835), train_loss = 1.08489267, grad/param norm = 2.2509e-01, time/batch = 11.9516s	
15024/26050 (epoch 28.837), train_loss = 0.91928456, grad/param norm = 1.7591e-01, time/batch = 18.5005s	
15025/26050 (epoch 28.839), train_loss = 0.92395104, grad/param norm = 2.1907e-01, time/batch = 17.2358s	
15026/26050 (epoch 28.841), train_loss = 1.02621849, grad/param norm = 2.0875e-01, time/batch = 17.4850s	
15027/26050 (epoch 28.843), train_loss = 0.90420353, grad/param norm = 1.8323e-01, time/batch = 18.2365s	
15028/26050 (epoch 28.845), train_loss = 0.88613916, grad/param norm = 1.8568e-01, time/batch = 15.8931s	
15029/26050 (epoch 28.846), train_loss = 0.99639283, grad/param norm = 2.0211e-01, time/batch = 17.0577s	
15030/26050 (epoch 28.848), train_loss = 0.89740185, grad/param norm = 1.8790e-01, time/batch = 17.7420s	
15031/26050 (epoch 28.850), train_loss = 0.84383514, grad/param norm = 1.8878e-01, time/batch = 18.7135s	
15032/26050 (epoch 28.852), train_loss = 0.94430277, grad/param norm = 1.8955e-01, time/batch = 17.1508s	
15033/26050 (epoch 28.854), train_loss = 0.92026286, grad/param norm = 2.1300e-01, time/batch = 18.1523s	
15034/26050 (epoch 28.856), train_loss = 0.88171470, grad/param norm = 2.1149e-01, time/batch = 16.7927s	
15035/26050 (epoch 28.858), train_loss = 0.85234518, grad/param norm = 1.9569e-01, time/batch = 15.9648s	
15036/26050 (epoch 28.860), train_loss = 0.97267861, grad/param norm = 2.0948e-01, time/batch = 18.4837s	
15037/26050 (epoch 28.862), train_loss = 1.00206922, grad/param norm = 1.9684e-01, time/batch = 18.6573s	
15038/26050 (epoch 28.864), train_loss = 0.97512660, grad/param norm = 2.4642e-01, time/batch = 18.1629s	
15039/26050 (epoch 28.866), train_loss = 0.88650644, grad/param norm = 1.7426e-01, time/batch = 17.3739s	
15040/26050 (epoch 28.868), train_loss = 0.97604101, grad/param norm = 2.2537e-01, time/batch = 18.3309s	
15041/26050 (epoch 28.869), train_loss = 0.84357873, grad/param norm = 1.9350e-01, time/batch = 17.9146s	
15042/26050 (epoch 28.871), train_loss = 0.78730959, grad/param norm = 1.7735e-01, time/batch = 15.2224s	
15043/26050 (epoch 28.873), train_loss = 0.97045879, grad/param norm = 2.0673e-01, time/batch = 18.4922s	
15044/26050 (epoch 28.875), train_loss = 0.91510385, grad/param norm = 2.0294e-01, time/batch = 18.3170s	
15045/26050 (epoch 28.877), train_loss = 0.85652210, grad/param norm = 1.9192e-01, time/batch = 17.4060s	
15046/26050 (epoch 28.879), train_loss = 0.95017583, grad/param norm = 1.8296e-01, time/batch = 16.3873s	
15047/26050 (epoch 28.881), train_loss = 1.01050098, grad/param norm = 2.2117e-01, time/batch = 17.8297s	
15048/26050 (epoch 28.883), train_loss = 0.96594713, grad/param norm = 1.8773e-01, time/batch = 18.9125s	
15049/26050 (epoch 28.885), train_loss = 0.72194399, grad/param norm = 1.8863e-01, time/batch = 17.1135s	
15050/26050 (epoch 28.887), train_loss = 0.99032800, grad/param norm = 2.1074e-01, time/batch = 18.6455s	
15051/26050 (epoch 28.889), train_loss = 0.87254428, grad/param norm = 1.9493e-01, time/batch = 16.1448s	
15052/26050 (epoch 28.891), train_loss = 0.77288024, grad/param norm = 1.7482e-01, time/batch = 15.9799s	
15053/26050 (epoch 28.893), train_loss = 0.80845182, grad/param norm = 1.8294e-01, time/batch = 18.4079s	
15054/26050 (epoch 28.894), train_loss = 0.88509835, grad/param norm = 1.9048e-01, time/batch = 17.2423s	
15055/26050 (epoch 28.896), train_loss = 1.01565798, grad/param norm = 2.3756e-01, time/batch = 18.9147s	
15056/26050 (epoch 28.898), train_loss = 0.88682340, grad/param norm = 2.1816e-01, time/batch = 17.1282s	
15057/26050 (epoch 28.900), train_loss = 0.98926923, grad/param norm = 2.2623e-01, time/batch = 16.1405s	
15058/26050 (epoch 28.902), train_loss = 0.91139604, grad/param norm = 2.3367e-01, time/batch = 18.0683s	
15059/26050 (epoch 28.904), train_loss = 0.88220907, grad/param norm = 1.8212e-01, time/batch = 17.7450s	
15060/26050 (epoch 28.906), train_loss = 0.89508015, grad/param norm = 2.2199e-01, time/batch = 18.2276s	
15061/26050 (epoch 28.908), train_loss = 0.92753511, grad/param norm = 1.9200e-01, time/batch = 15.2258s	
15062/26050 (epoch 28.910), train_loss = 0.89420761, grad/param norm = 2.1936e-01, time/batch = 18.1377s	
15063/26050 (epoch 28.912), train_loss = 1.11052213, grad/param norm = 2.1580e-01, time/batch = 16.8197s	
15064/26050 (epoch 28.914), train_loss = 1.26961525, grad/param norm = 2.3812e-01, time/batch = 17.9594s	
15065/26050 (epoch 28.916), train_loss = 1.01500180, grad/param norm = 2.0801e-01, time/batch = 17.3148s	
15066/26050 (epoch 28.917), train_loss = 0.93472134, grad/param norm = 2.1634e-01, time/batch = 17.5682s	
15067/26050 (epoch 28.919), train_loss = 0.96121462, grad/param norm = 2.3048e-01, time/batch = 18.4074s	
15068/26050 (epoch 28.921), train_loss = 0.86868012, grad/param norm = 2.1367e-01, time/batch = 17.2926s	
15069/26050 (epoch 28.923), train_loss = 0.94829917, grad/param norm = 1.9923e-01, time/batch = 16.2297s	
15070/26050 (epoch 28.925), train_loss = 0.91675066, grad/param norm = 1.9175e-01, time/batch = 16.6027s	
15071/26050 (epoch 28.927), train_loss = 0.83112667, grad/param norm = 1.5329e-01, time/batch = 18.0550s	
15072/26050 (epoch 28.929), train_loss = 0.79503566, grad/param norm = 1.7742e-01, time/batch = 18.9003s	
15073/26050 (epoch 28.931), train_loss = 1.10341314, grad/param norm = 2.3701e-01, time/batch = 24.1929s	
15074/26050 (epoch 28.933), train_loss = 0.90021814, grad/param norm = 1.8627e-01, time/batch = 30.5990s	
15075/26050 (epoch 28.935), train_loss = 0.88780041, grad/param norm = 1.9269e-01, time/batch = 17.6498s	
15076/26050 (epoch 28.937), train_loss = 1.01587824, grad/param norm = 1.9109e-01, time/batch = 18.6505s	
15077/26050 (epoch 28.939), train_loss = 0.83910349, grad/param norm = 1.6902e-01, time/batch = 18.2523s	
15078/26050 (epoch 28.940), train_loss = 0.88453747, grad/param norm = 1.7678e-01, time/batch = 17.4972s	
15079/26050 (epoch 28.942), train_loss = 0.90560910, grad/param norm = 1.9551e-01, time/batch = 18.4700s	
15080/26050 (epoch 28.944), train_loss = 0.88253974, grad/param norm = 1.7367e-01, time/batch = 17.9762s	
15081/26050 (epoch 28.946), train_loss = 1.04176926, grad/param norm = 1.9943e-01, time/batch = 18.9916s	
15082/26050 (epoch 28.948), train_loss = 0.77789475, grad/param norm = 1.8763e-01, time/batch = 18.6468s	
15083/26050 (epoch 28.950), train_loss = 0.91188255, grad/param norm = 2.1018e-01, time/batch = 15.4817s	
15084/26050 (epoch 28.952), train_loss = 0.98336455, grad/param norm = 2.1048e-01, time/batch = 17.2292s	
15085/26050 (epoch 28.954), train_loss = 1.01700713, grad/param norm = 2.2064e-01, time/batch = 15.2362s	
15086/26050 (epoch 28.956), train_loss = 0.89181787, grad/param norm = 1.9183e-01, time/batch = 14.4568s	
15087/26050 (epoch 28.958), train_loss = 0.83961678, grad/param norm = 1.6650e-01, time/batch = 18.6572s	
15088/26050 (epoch 28.960), train_loss = 0.96773338, grad/param norm = 2.3039e-01, time/batch = 18.1539s	
15089/26050 (epoch 28.962), train_loss = 0.91526208, grad/param norm = 1.9039e-01, time/batch = 17.2285s	
15090/26050 (epoch 28.964), train_loss = 0.92018826, grad/param norm = 1.9436e-01, time/batch = 17.8969s	
15091/26050 (epoch 28.965), train_loss = 0.84178231, grad/param norm = 2.0823e-01, time/batch = 18.8230s	
15092/26050 (epoch 28.967), train_loss = 1.23244001, grad/param norm = 2.1266e-01, time/batch = 17.4032s	
15093/26050 (epoch 28.969), train_loss = 0.95068447, grad/param norm = 2.0357e-01, time/batch = 18.7212s	
15094/26050 (epoch 28.971), train_loss = 0.90186213, grad/param norm = 1.8591e-01, time/batch = 18.3225s	
15095/26050 (epoch 28.973), train_loss = 0.92976723, grad/param norm = 2.0211e-01, time/batch = 15.5575s	
15096/26050 (epoch 28.975), train_loss = 0.96630623, grad/param norm = 2.0896e-01, time/batch = 15.0416s	
15097/26050 (epoch 28.977), train_loss = 0.92837577, grad/param norm = 1.7482e-01, time/batch = 18.2203s	
15098/26050 (epoch 28.979), train_loss = 0.76293657, grad/param norm = 1.9165e-01, time/batch = 17.3846s	
15099/26050 (epoch 28.981), train_loss = 1.04852959, grad/param norm = 2.0409e-01, time/batch = 17.2295s	
15100/26050 (epoch 28.983), train_loss = 0.99656577, grad/param norm = 1.9323e-01, time/batch = 18.2447s	
15101/26050 (epoch 28.985), train_loss = 0.97340895, grad/param norm = 2.0154e-01, time/batch = 18.6515s	
15102/26050 (epoch 28.987), train_loss = 1.01290900, grad/param norm = 1.9316e-01, time/batch = 18.5565s	
15103/26050 (epoch 28.988), train_loss = 0.98245921, grad/param norm = 2.1714e-01, time/batch = 16.5540s	
15104/26050 (epoch 28.990), train_loss = 0.81806304, grad/param norm = 1.6493e-01, time/batch = 16.2806s	
15105/26050 (epoch 28.992), train_loss = 1.08327288, grad/param norm = 2.1778e-01, time/batch = 18.9738s	
15106/26050 (epoch 28.994), train_loss = 0.88519131, grad/param norm = 2.0530e-01, time/batch = 16.9023s	
15107/26050 (epoch 28.996), train_loss = 0.85123733, grad/param norm = 2.0232e-01, time/batch = 18.3256s	
15108/26050 (epoch 28.998), train_loss = 0.92957000, grad/param norm = 1.7730e-01, time/batch = 18.5629s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
15109/26050 (epoch 29.000), train_loss = 0.86800240, grad/param norm = 2.0443e-01, time/batch = 18.0629s	
15110/26050 (epoch 29.002), train_loss = 0.98256947, grad/param norm = 2.1978e-01, time/batch = 17.8097s	
15111/26050 (epoch 29.004), train_loss = 0.82253584, grad/param norm = 1.8776e-01, time/batch = 17.3867s	
15112/26050 (epoch 29.006), train_loss = 0.86943008, grad/param norm = 2.2950e-01, time/batch = 18.3150s	
15113/26050 (epoch 29.008), train_loss = 0.86663132, grad/param norm = 1.8889e-01, time/batch = 17.9970s	
15114/26050 (epoch 29.010), train_loss = 0.84765842, grad/param norm = 1.8329e-01, time/batch = 17.8297s	
15115/26050 (epoch 29.012), train_loss = 0.92295631, grad/param norm = 1.8682e-01, time/batch = 15.1322s	
15116/26050 (epoch 29.013), train_loss = 1.17827900, grad/param norm = 2.3770e-01, time/batch = 17.1426s	
15117/26050 (epoch 29.015), train_loss = 0.91161574, grad/param norm = 1.8763e-01, time/batch = 17.6549s	
15118/26050 (epoch 29.017), train_loss = 0.95751405, grad/param norm = 2.1792e-01, time/batch = 16.3797s	
15119/26050 (epoch 29.019), train_loss = 0.82038306, grad/param norm = 1.7417e-01, time/batch = 18.0601s	
15120/26050 (epoch 29.021), train_loss = 1.01357114, grad/param norm = 1.8816e-01, time/batch = 17.9818s	
15121/26050 (epoch 29.023), train_loss = 0.77075537, grad/param norm = 1.8016e-01, time/batch = 18.4131s	
15122/26050 (epoch 29.025), train_loss = 0.91404956, grad/param norm = 1.8218e-01, time/batch = 18.2272s	
15123/26050 (epoch 29.027), train_loss = 0.75836579, grad/param norm = 1.8780e-01, time/batch = 17.4528s	
15124/26050 (epoch 29.029), train_loss = 0.93454269, grad/param norm = 1.7526e-01, time/batch = 17.3901s	
15125/26050 (epoch 29.031), train_loss = 1.02743419, grad/param norm = 2.1079e-01, time/batch = 16.7394s	
15126/26050 (epoch 29.033), train_loss = 0.94565292, grad/param norm = 1.9747e-01, time/batch = 17.1232s	
15127/26050 (epoch 29.035), train_loss = 0.94921495, grad/param norm = 2.0475e-01, time/batch = 17.8298s	
15128/26050 (epoch 29.036), train_loss = 0.79437967, grad/param norm = 2.0421e-01, time/batch = 18.8987s	
15129/26050 (epoch 29.038), train_loss = 0.74138020, grad/param norm = 1.8511e-01, time/batch = 17.8143s	
15130/26050 (epoch 29.040), train_loss = 0.90083080, grad/param norm = 2.0438e-01, time/batch = 14.8803s	
15131/26050 (epoch 29.042), train_loss = 0.77007213, grad/param norm = 1.7244e-01, time/batch = 16.1355s	
15132/26050 (epoch 29.044), train_loss = 0.98793424, grad/param norm = 1.8396e-01, time/batch = 17.8341s	
15133/26050 (epoch 29.046), train_loss = 0.76085703, grad/param norm = 1.6623e-01, time/batch = 16.6712s	
15134/26050 (epoch 29.048), train_loss = 0.91768345, grad/param norm = 1.8433e-01, time/batch = 18.0767s	
15135/26050 (epoch 29.050), train_loss = 0.87387548, grad/param norm = 1.8898e-01, time/batch = 18.8212s	
15136/26050 (epoch 29.052), train_loss = 0.84401743, grad/param norm = 1.9103e-01, time/batch = 17.7948s	
15137/26050 (epoch 29.054), train_loss = 0.77137616, grad/param norm = 1.8489e-01, time/batch = 17.7357s	
15138/26050 (epoch 29.056), train_loss = 0.74326583, grad/param norm = 1.7035e-01, time/batch = 14.9675s	
15139/26050 (epoch 29.058), train_loss = 0.89479472, grad/param norm = 1.8491e-01, time/batch = 18.6367s	
15140/26050 (epoch 29.060), train_loss = 0.96862669, grad/param norm = 1.9295e-01, time/batch = 16.0666s	
15141/26050 (epoch 29.061), train_loss = 0.81792659, grad/param norm = 1.7238e-01, time/batch = 17.9913s	
15142/26050 (epoch 29.063), train_loss = 0.92587945, grad/param norm = 1.8768e-01, time/batch = 15.2266s	
15143/26050 (epoch 29.065), train_loss = 0.73557906, grad/param norm = 1.4863e-01, time/batch = 16.1214s	
15144/26050 (epoch 29.067), train_loss = 0.90529578, grad/param norm = 1.9781e-01, time/batch = 18.1623s	
15145/26050 (epoch 29.069), train_loss = 0.95838814, grad/param norm = 2.2160e-01, time/batch = 17.3402s	
15146/26050 (epoch 29.071), train_loss = 0.95348657, grad/param norm = 1.8406e-01, time/batch = 18.8313s	
15147/26050 (epoch 29.073), train_loss = 1.06276980, grad/param norm = 2.1188e-01, time/batch = 17.3698s	
15148/26050 (epoch 29.075), train_loss = 0.86136163, grad/param norm = 1.8605e-01, time/batch = 17.8169s	
15149/26050 (epoch 29.077), train_loss = 0.88876389, grad/param norm = 2.4441e-01, time/batch = 17.2289s	
15150/26050 (epoch 29.079), train_loss = 0.90664369, grad/param norm = 2.1327e-01, time/batch = 17.9939s	
15151/26050 (epoch 29.081), train_loss = 0.88359607, grad/param norm = 1.8638e-01, time/batch = 16.1294s	
15152/26050 (epoch 29.083), train_loss = 1.01512592, grad/param norm = 1.8976e-01, time/batch = 17.2476s	
15153/26050 (epoch 29.084), train_loss = 0.94434004, grad/param norm = 3.5307e-01, time/batch = 18.8166s	
15154/26050 (epoch 29.086), train_loss = 1.09360767, grad/param norm = 2.2335e-01, time/batch = 17.4028s	
15155/26050 (epoch 29.088), train_loss = 0.87854998, grad/param norm = 2.0390e-01, time/batch = 15.4832s	
15156/26050 (epoch 29.090), train_loss = 0.91712400, grad/param norm = 2.0357e-01, time/batch = 17.3180s	
15157/26050 (epoch 29.092), train_loss = 0.94794876, grad/param norm = 1.8110e-01, time/batch = 17.6520s	
15158/26050 (epoch 29.094), train_loss = 0.81745105, grad/param norm = 2.0988e-01, time/batch = 17.9079s	
15159/26050 (epoch 29.096), train_loss = 0.93661636, grad/param norm = 1.8613e-01, time/batch = 18.0028s	
15160/26050 (epoch 29.098), train_loss = 0.87682625, grad/param norm = 1.8336e-01, time/batch = 17.7355s	
15161/26050 (epoch 29.100), train_loss = 0.83652797, grad/param norm = 2.0539e-01, time/batch = 18.5622s	
15162/26050 (epoch 29.102), train_loss = 0.96251768, grad/param norm = 1.9743e-01, time/batch = 18.4942s	
15163/26050 (epoch 29.104), train_loss = 0.86856097, grad/param norm = 1.9141e-01, time/batch = 18.4862s	
15164/26050 (epoch 29.106), train_loss = 0.92489569, grad/param norm = 2.2030e-01, time/batch = 17.8111s	
15165/26050 (epoch 29.107), train_loss = 0.76043355, grad/param norm = 1.9158e-01, time/batch = 18.1497s	
15166/26050 (epoch 29.109), train_loss = 0.83895520, grad/param norm = 1.8834e-01, time/batch = 15.1925s	
15167/26050 (epoch 29.111), train_loss = 1.07073945, grad/param norm = 2.1241e-01, time/batch = 14.4700s	
15168/26050 (epoch 29.113), train_loss = 0.88026741, grad/param norm = 2.0015e-01, time/batch = 18.5553s	
15169/26050 (epoch 29.115), train_loss = 1.01213127, grad/param norm = 2.1769e-01, time/batch = 18.3247s	
15170/26050 (epoch 29.117), train_loss = 0.91225159, grad/param norm = 1.9028e-01, time/batch = 18.4856s	
15171/26050 (epoch 29.119), train_loss = 0.76817535, grad/param norm = 1.7723e-01, time/batch = 18.0599s	
15172/26050 (epoch 29.121), train_loss = 0.92680948, grad/param norm = 1.9569e-01, time/batch = 17.3308s	
15173/26050 (epoch 29.123), train_loss = 0.82551739, grad/param norm = 1.9032e-01, time/batch = 16.3161s	
15174/26050 (epoch 29.125), train_loss = 0.78878417, grad/param norm = 1.7449e-01, time/batch = 17.2349s	
15175/26050 (epoch 29.127), train_loss = 0.74572121, grad/param norm = 1.7997e-01, time/batch = 16.6361s	
15176/26050 (epoch 29.129), train_loss = 0.74131916, grad/param norm = 1.8843e-01, time/batch = 18.2260s	
15177/26050 (epoch 29.131), train_loss = 0.87470886, grad/param norm = 1.9781e-01, time/batch = 18.0554s	
15178/26050 (epoch 29.132), train_loss = 0.88457267, grad/param norm = 1.7029e-01, time/batch = 18.8932s	
15179/26050 (epoch 29.134), train_loss = 0.93317630, grad/param norm = 2.2185e-01, time/batch = 18.1313s	
15180/26050 (epoch 29.136), train_loss = 0.89038519, grad/param norm = 1.9162e-01, time/batch = 18.3365s	
15181/26050 (epoch 29.138), train_loss = 0.68327844, grad/param norm = 1.7555e-01, time/batch = 18.3997s	
15182/26050 (epoch 29.140), train_loss = 0.75868469, grad/param norm = 1.8402e-01, time/batch = 18.3187s	
15183/26050 (epoch 29.142), train_loss = 0.79801585, grad/param norm = 1.7812e-01, time/batch = 14.6869s	
15184/26050 (epoch 29.144), train_loss = 0.72095533, grad/param norm = 1.9928e-01, time/batch = 17.6429s	
15185/26050 (epoch 29.146), train_loss = 0.67692953, grad/param norm = 1.8026e-01, time/batch = 18.2340s	
15186/26050 (epoch 29.148), train_loss = 0.72274774, grad/param norm = 1.7532e-01, time/batch = 17.9905s	
15187/26050 (epoch 29.150), train_loss = 0.85665503, grad/param norm = 1.9579e-01, time/batch = 16.3856s	
15188/26050 (epoch 29.152), train_loss = 1.04857759, grad/param norm = 2.3104e-01, time/batch = 18.3771s	
15189/26050 (epoch 29.154), train_loss = 0.72917693, grad/param norm = 2.0864e-01, time/batch = 18.8175s	
15190/26050 (epoch 29.155), train_loss = 0.77870711, grad/param norm = 2.1122e-01, time/batch = 16.9901s	
15191/26050 (epoch 29.157), train_loss = 0.89558493, grad/param norm = 3.0789e-01, time/batch = 16.0596s	
15192/26050 (epoch 29.159), train_loss = 0.93459451, grad/param norm = 2.3150e-01, time/batch = 18.3323s	
15193/26050 (epoch 29.161), train_loss = 0.91121382, grad/param norm = 2.0726e-01, time/batch = 15.4663s	
15194/26050 (epoch 29.163), train_loss = 0.75504213, grad/param norm = 1.9674e-01, time/batch = 17.8255s	
15195/26050 (epoch 29.165), train_loss = 0.72038048, grad/param norm = 2.0812e-01, time/batch = 18.4804s	
15196/26050 (epoch 29.167), train_loss = 1.02325928, grad/param norm = 2.2292e-01, time/batch = 16.9507s	
15197/26050 (epoch 29.169), train_loss = 0.91855444, grad/param norm = 2.1640e-01, time/batch = 17.5402s	
15198/26050 (epoch 29.171), train_loss = 0.77629839, grad/param norm = 1.8156e-01, time/batch = 16.9020s	
15199/26050 (epoch 29.173), train_loss = 0.86730353, grad/param norm = 2.1359e-01, time/batch = 15.9653s	
15200/26050 (epoch 29.175), train_loss = 0.88232182, grad/param norm = 1.9112e-01, time/batch = 14.3824s	
15201/26050 (epoch 29.177), train_loss = 0.99009938, grad/param norm = 2.0111e-01, time/batch = 15.6204s	
15202/26050 (epoch 29.179), train_loss = 0.65936178, grad/param norm = 1.5844e-01, time/batch = 14.2870s	
15203/26050 (epoch 29.180), train_loss = 1.10760051, grad/param norm = 2.0184e-01, time/batch = 14.9791s	
15204/26050 (epoch 29.182), train_loss = 1.10709138, grad/param norm = 2.4929e-01, time/batch = 14.6175s	
15205/26050 (epoch 29.184), train_loss = 0.93193056, grad/param norm = 1.9286e-01, time/batch = 18.2080s	
15206/26050 (epoch 29.186), train_loss = 0.75183872, grad/param norm = 1.7156e-01, time/batch = 18.6395s	
15207/26050 (epoch 29.188), train_loss = 0.91342382, grad/param norm = 1.9652e-01, time/batch = 18.4017s	
15208/26050 (epoch 29.190), train_loss = 0.95615013, grad/param norm = 2.2695e-01, time/batch = 18.0748s	
15209/26050 (epoch 29.192), train_loss = 0.95774020, grad/param norm = 1.9108e-01, time/batch = 16.4019s	
15210/26050 (epoch 29.194), train_loss = 0.93131301, grad/param norm = 1.9517e-01, time/batch = 18.4780s	
15211/26050 (epoch 29.196), train_loss = 0.96088599, grad/param norm = 1.9483e-01, time/batch = 18.3061s	
15212/26050 (epoch 29.198), train_loss = 0.81560902, grad/param norm = 1.7670e-01, time/batch = 17.8223s	
15213/26050 (epoch 29.200), train_loss = 0.83287190, grad/param norm = 2.0437e-01, time/batch = 18.6463s	
15214/26050 (epoch 29.202), train_loss = 0.91229437, grad/param norm = 1.7715e-01, time/batch = 17.9032s	
15215/26050 (epoch 29.203), train_loss = 1.00783871, grad/param norm = 1.8546e-01, time/batch = 15.6396s	
15216/26050 (epoch 29.205), train_loss = 0.86633706, grad/param norm = 1.9843e-01, time/batch = 17.7225s	
15217/26050 (epoch 29.207), train_loss = 0.82445357, grad/param norm = 1.8359e-01, time/batch = 18.0650s	
15218/26050 (epoch 29.209), train_loss = 0.95300421, grad/param norm = 1.7679e-01, time/batch = 18.5713s	
15219/26050 (epoch 29.211), train_loss = 0.76459666, grad/param norm = 1.8994e-01, time/batch = 16.6621s	
15220/26050 (epoch 29.213), train_loss = 0.92397823, grad/param norm = 2.0178e-01, time/batch = 18.3770s	
15221/26050 (epoch 29.215), train_loss = 0.87397136, grad/param norm = 2.0476e-01, time/batch = 19.0741s	
15222/26050 (epoch 29.217), train_loss = 0.85632788, grad/param norm = 1.8196e-01, time/batch = 17.3987s	
15223/26050 (epoch 29.219), train_loss = 0.87745423, grad/param norm = 2.0257e-01, time/batch = 15.8019s	
15224/26050 (epoch 29.221), train_loss = 0.82286669, grad/param norm = 2.1483e-01, time/batch = 17.9935s	
15225/26050 (epoch 29.223), train_loss = 0.99004947, grad/param norm = 2.1684e-01, time/batch = 18.9930s	
15226/26050 (epoch 29.225), train_loss = 0.83048813, grad/param norm = 2.0889e-01, time/batch = 16.8953s	
15227/26050 (epoch 29.226), train_loss = 0.94260739, grad/param norm = 2.0371e-01, time/batch = 16.4666s	
15228/26050 (epoch 29.228), train_loss = 1.04270290, grad/param norm = 1.9317e-01, time/batch = 17.8177s	
15229/26050 (epoch 29.230), train_loss = 0.90817452, grad/param norm = 1.8572e-01, time/batch = 18.0597s	
15230/26050 (epoch 29.232), train_loss = 0.98447414, grad/param norm = 2.2473e-01, time/batch = 17.3578s	
15231/26050 (epoch 29.234), train_loss = 0.80764137, grad/param norm = 1.9688e-01, time/batch = 18.4878s	
15232/26050 (epoch 29.236), train_loss = 0.97806622, grad/param norm = 2.0122e-01, time/batch = 17.3271s	
15233/26050 (epoch 29.238), train_loss = 0.76754168, grad/param norm = 2.0190e-01, time/batch = 15.2333s	
15234/26050 (epoch 29.240), train_loss = 0.91851097, grad/param norm = 1.9877e-01, time/batch = 18.2360s	
15235/26050 (epoch 29.242), train_loss = 0.87903728, grad/param norm = 1.9969e-01, time/batch = 18.2501s	
15236/26050 (epoch 29.244), train_loss = 0.93002785, grad/param norm = 2.2525e-01, time/batch = 17.0796s	
15237/26050 (epoch 29.246), train_loss = 0.84490600, grad/param norm = 1.8654e-01, time/batch = 18.3229s	
15238/26050 (epoch 29.248), train_loss = 0.92012231, grad/param norm = 1.9929e-01, time/batch = 18.5730s	
15239/26050 (epoch 29.250), train_loss = 0.90517909, grad/param norm = 2.2423e-01, time/batch = 18.3256s	
15240/26050 (epoch 29.251), train_loss = 0.86449980, grad/param norm = 1.9434e-01, time/batch = 18.8906s	
15241/26050 (epoch 29.253), train_loss = 0.80422939, grad/param norm = 1.9624e-01, time/batch = 18.5654s	
15242/26050 (epoch 29.255), train_loss = 1.05581165, grad/param norm = 1.9506e-01, time/batch = 15.5511s	
15243/26050 (epoch 29.257), train_loss = 0.89560724, grad/param norm = 2.2372e-01, time/batch = 16.0447s	
15244/26050 (epoch 29.259), train_loss = 1.01017194, grad/param norm = 2.0873e-01, time/batch = 15.9499s	
15245/26050 (epoch 29.261), train_loss = 0.80388872, grad/param norm = 2.0607e-01, time/batch = 18.6780s	
15246/26050 (epoch 29.263), train_loss = 0.99016412, grad/param norm = 2.1237e-01, time/batch = 16.9981s	
15247/26050 (epoch 29.265), train_loss = 1.05510777, grad/param norm = 2.3151e-01, time/batch = 19.0724s	
15248/26050 (epoch 29.267), train_loss = 1.02632786, grad/param norm = 1.9905e-01, time/batch = 18.0754s	
15249/26050 (epoch 29.269), train_loss = 1.00178557, grad/param norm = 2.0456e-01, time/batch = 17.8867s	
15250/26050 (epoch 29.271), train_loss = 0.91421087, grad/param norm = 1.8588e-01, time/batch = 18.6299s	
15251/26050 (epoch 29.273), train_loss = 0.82315423, grad/param norm = 2.1913e-01, time/batch = 16.7977s	
15252/26050 (epoch 29.274), train_loss = 0.87786457, grad/param norm = 1.7832e-01, time/batch = 18.5499s	
15253/26050 (epoch 29.276), train_loss = 0.87293805, grad/param norm = 1.8747e-01, time/batch = 17.8117s	
15254/26050 (epoch 29.278), train_loss = 1.01322511, grad/param norm = 2.0152e-01, time/batch = 17.7340s	
15255/26050 (epoch 29.280), train_loss = 0.90928081, grad/param norm = 1.7839e-01, time/batch = 17.0722s	
15256/26050 (epoch 29.282), train_loss = 0.95795240, grad/param norm = 1.9800e-01, time/batch = 15.7171s	
15257/26050 (epoch 29.284), train_loss = 0.87951683, grad/param norm = 1.8442e-01, time/batch = 18.8126s	
15258/26050 (epoch 29.286), train_loss = 0.93090926, grad/param norm = 2.0175e-01, time/batch = 17.5068s	
15259/26050 (epoch 29.288), train_loss = 0.77321660, grad/param norm = 1.7202e-01, time/batch = 18.3065s	
15260/26050 (epoch 29.290), train_loss = 0.90963956, grad/param norm = 1.9986e-01, time/batch = 17.6321s	
15261/26050 (epoch 29.292), train_loss = 0.84228927, grad/param norm = 1.8491e-01, time/batch = 18.5654s	
15262/26050 (epoch 29.294), train_loss = 0.92115133, grad/param norm = 2.2260e-01, time/batch = 17.8663s	
15263/26050 (epoch 29.296), train_loss = 0.99623177, grad/param norm = 1.9653e-01, time/batch = 15.9958s	
15264/26050 (epoch 29.298), train_loss = 0.93492271, grad/param norm = 1.7632e-01, time/batch = 18.7257s	
15265/26050 (epoch 29.299), train_loss = 0.76138428, grad/param norm = 1.7583e-01, time/batch = 18.3232s	
15266/26050 (epoch 29.301), train_loss = 0.78311441, grad/param norm = 1.9986e-01, time/batch = 17.3915s	
15267/26050 (epoch 29.303), train_loss = 0.91605586, grad/param norm = 2.0633e-01, time/batch = 16.0513s	
15268/26050 (epoch 29.305), train_loss = 0.74602896, grad/param norm = 1.9413e-01, time/batch = 18.2237s	
15269/26050 (epoch 29.307), train_loss = 0.82171485, grad/param norm = 1.9891e-01, time/batch = 17.8845s	
15270/26050 (epoch 29.309), train_loss = 0.89430817, grad/param norm = 2.0314e-01, time/batch = 17.9574s	
15271/26050 (epoch 29.311), train_loss = 0.93933980, grad/param norm = 1.9151e-01, time/batch = 17.9944s	
15272/26050 (epoch 29.313), train_loss = 0.89375391, grad/param norm = 2.0872e-01, time/batch = 17.9102s	
15273/26050 (epoch 29.315), train_loss = 0.98193728, grad/param norm = 1.8768e-01, time/batch = 16.9953s	
15274/26050 (epoch 29.317), train_loss = 0.94328738, grad/param norm = 2.2007e-01, time/batch = 18.8903s	
15275/26050 (epoch 29.319), train_loss = 0.82675889, grad/param norm = 2.0526e-01, time/batch = 16.0559s	
15276/26050 (epoch 29.321), train_loss = 0.87520483, grad/param norm = 1.8685e-01, time/batch = 17.3689s	
15277/26050 (epoch 29.322), train_loss = 0.94900546, grad/param norm = 1.9276e-01, time/batch = 33.3482s	
15278/26050 (epoch 29.324), train_loss = 0.71629335, grad/param norm = 1.7282e-01, time/batch = 20.8868s	
15279/26050 (epoch 29.326), train_loss = 1.01600987, grad/param norm = 2.0121e-01, time/batch = 17.7110s	
15280/26050 (epoch 29.328), train_loss = 0.93210743, grad/param norm = 1.7358e-01, time/batch = 18.9661s	
15281/26050 (epoch 29.330), train_loss = 0.78167892, grad/param norm = 1.8613e-01, time/batch = 18.5786s	
15282/26050 (epoch 29.332), train_loss = 0.95059966, grad/param norm = 1.8517e-01, time/batch = 17.5737s	
15283/26050 (epoch 29.334), train_loss = 0.82231329, grad/param norm = 1.8537e-01, time/batch = 15.2557s	
15284/26050 (epoch 29.336), train_loss = 0.84831153, grad/param norm = 1.7188e-01, time/batch = 17.8165s	
15285/26050 (epoch 29.338), train_loss = 0.79556995, grad/param norm = 1.8167e-01, time/batch = 17.7288s	
15286/26050 (epoch 29.340), train_loss = 0.96490276, grad/param norm = 1.9726e-01, time/batch = 18.8068s	
15287/26050 (epoch 29.342), train_loss = 0.99419348, grad/param norm = 1.9397e-01, time/batch = 18.3271s	
15288/26050 (epoch 29.344), train_loss = 0.82568076, grad/param norm = 2.2845e-01, time/batch = 16.8767s	
15289/26050 (epoch 29.345), train_loss = 0.89108317, grad/param norm = 2.1891e-01, time/batch = 17.5727s	
15290/26050 (epoch 29.347), train_loss = 1.02537817, grad/param norm = 1.9741e-01, time/batch = 17.4985s	
15291/26050 (epoch 29.349), train_loss = 0.94492167, grad/param norm = 1.9141e-01, time/batch = 18.4923s	
15292/26050 (epoch 29.351), train_loss = 0.94797026, grad/param norm = 1.9625e-01, time/batch = 17.4000s	
15293/26050 (epoch 29.353), train_loss = 0.91115146, grad/param norm = 2.0155e-01, time/batch = 18.8926s	
15294/26050 (epoch 29.355), train_loss = 0.92649993, grad/param norm = 2.2418e-01, time/batch = 16.4596s	
15295/26050 (epoch 29.357), train_loss = 0.86087421, grad/param norm = 1.7616e-01, time/batch = 15.5550s	
15296/26050 (epoch 29.359), train_loss = 0.98642808, grad/param norm = 2.1002e-01, time/batch = 18.4780s	
15297/26050 (epoch 29.361), train_loss = 0.81966176, grad/param norm = 1.7438e-01, time/batch = 14.7079s	
15298/26050 (epoch 29.363), train_loss = 0.99242756, grad/param norm = 1.9527e-01, time/batch = 17.8048s	
15299/26050 (epoch 29.365), train_loss = 0.87478395, grad/param norm = 1.8329e-01, time/batch = 17.5500s	
15300/26050 (epoch 29.367), train_loss = 0.97477856, grad/param norm = 1.9119e-01, time/batch = 18.3153s	
15301/26050 (epoch 29.369), train_loss = 0.81442457, grad/param norm = 1.6744e-01, time/batch = 17.5737s	
15302/26050 (epoch 29.370), train_loss = 0.81767922, grad/param norm = 1.7834e-01, time/batch = 17.9925s	
15303/26050 (epoch 29.372), train_loss = 0.91166872, grad/param norm = 2.0059e-01, time/batch = 15.3946s	
15304/26050 (epoch 29.374), train_loss = 1.03058428, grad/param norm = 2.0525e-01, time/batch = 19.1546s	
15305/26050 (epoch 29.376), train_loss = 1.07257098, grad/param norm = 2.1742e-01, time/batch = 18.0719s	
15306/26050 (epoch 29.378), train_loss = 0.85386288, grad/param norm = 1.8016e-01, time/batch = 16.0779s	
15307/26050 (epoch 29.380), train_loss = 1.05735012, grad/param norm = 2.1895e-01, time/batch = 18.8240s	
15308/26050 (epoch 29.382), train_loss = 1.16750184, grad/param norm = 2.5047e-01, time/batch = 18.5685s	
15309/26050 (epoch 29.384), train_loss = 0.88971985, grad/param norm = 2.1385e-01, time/batch = 17.4726s	
15310/26050 (epoch 29.386), train_loss = 0.97196855, grad/param norm = 2.7297e-01, time/batch = 15.9473s	
15311/26050 (epoch 29.388), train_loss = 0.93471018, grad/param norm = 2.0795e-01, time/batch = 15.5810s	
15312/26050 (epoch 29.390), train_loss = 0.87051870, grad/param norm = 1.8456e-01, time/batch = 18.0674s	
15313/26050 (epoch 29.392), train_loss = 0.81335849, grad/param norm = 1.9229e-01, time/batch = 17.3127s	
15314/26050 (epoch 29.393), train_loss = 0.96694793, grad/param norm = 2.3066e-01, time/batch = 17.0631s	
15315/26050 (epoch 29.395), train_loss = 1.00374579, grad/param norm = 2.6837e-01, time/batch = 18.2417s	
15316/26050 (epoch 29.397), train_loss = 0.98115457, grad/param norm = 2.2873e-01, time/batch = 17.4865s	
15317/26050 (epoch 29.399), train_loss = 0.86278506, grad/param norm = 2.0608e-01, time/batch = 18.1519s	
15318/26050 (epoch 29.401), train_loss = 0.93131034, grad/param norm = 1.9797e-01, time/batch = 17.2353s	
15319/26050 (epoch 29.403), train_loss = 0.93564060, grad/param norm = 2.2249e-01, time/batch = 18.3086s	
15320/26050 (epoch 29.405), train_loss = 0.91839849, grad/param norm = 2.1561e-01, time/batch = 17.8168s	
15321/26050 (epoch 29.407), train_loss = 1.05990569, grad/param norm = 2.2430e-01, time/batch = 17.5762s	
15322/26050 (epoch 29.409), train_loss = 1.04258420, grad/param norm = 2.2974e-01, time/batch = 14.9799s	
15323/26050 (epoch 29.411), train_loss = 0.98344684, grad/param norm = 2.1002e-01, time/batch = 15.9843s	
15324/26050 (epoch 29.413), train_loss = 1.08778032, grad/param norm = 1.9662e-01, time/batch = 17.1358s	
15325/26050 (epoch 29.415), train_loss = 1.05901173, grad/param norm = 2.3052e-01, time/batch = 18.1608s	
15326/26050 (epoch 29.417), train_loss = 1.11703343, grad/param norm = 2.4554e-01, time/batch = 17.8989s	
15327/26050 (epoch 29.418), train_loss = 1.00585887, grad/param norm = 2.1835e-01, time/batch = 17.1423s	
15328/26050 (epoch 29.420), train_loss = 0.79843970, grad/param norm = 1.7874e-01, time/batch = 14.9851s	
15329/26050 (epoch 29.422), train_loss = 0.78865074, grad/param norm = 2.0309e-01, time/batch = 17.7411s	
15330/26050 (epoch 29.424), train_loss = 1.03560801, grad/param norm = 2.1088e-01, time/batch = 17.8694s	
15331/26050 (epoch 29.426), train_loss = 1.01824756, grad/param norm = 2.1989e-01, time/batch = 18.8017s	
15332/26050 (epoch 29.428), train_loss = 0.87905675, grad/param norm = 1.9657e-01, time/batch = 18.0747s	
15333/26050 (epoch 29.430), train_loss = 1.07917651, grad/param norm = 2.1687e-01, time/batch = 16.8776s	
15334/26050 (epoch 29.432), train_loss = 0.89207230, grad/param norm = 1.9405e-01, time/batch = 17.6435s	
15335/26050 (epoch 29.434), train_loss = 0.90114142, grad/param norm = 2.1117e-01, time/batch = 17.7455s	
15336/26050 (epoch 29.436), train_loss = 1.04063077, grad/param norm = 2.0906e-01, time/batch = 18.1521s	
15337/26050 (epoch 29.438), train_loss = 0.99019542, grad/param norm = 2.2217e-01, time/batch = 17.7960s	
15338/26050 (epoch 29.440), train_loss = 0.94778968, grad/param norm = 1.8946e-01, time/batch = 18.1385s	
15339/26050 (epoch 29.441), train_loss = 0.93784579, grad/param norm = 1.8818e-01, time/batch = 15.3656s	
15340/26050 (epoch 29.443), train_loss = 0.78357902, grad/param norm = 1.5351e-01, time/batch = 17.5258s	
15341/26050 (epoch 29.445), train_loss = 0.83819310, grad/param norm = 1.7971e-01, time/batch = 18.6491s	
15342/26050 (epoch 29.447), train_loss = 1.03050458, grad/param norm = 2.0941e-01, time/batch = 18.4897s	
15343/26050 (epoch 29.449), train_loss = 0.85409278, grad/param norm = 1.9457e-01, time/batch = 17.6574s	
15344/26050 (epoch 29.451), train_loss = 1.06921918, grad/param norm = 2.0878e-01, time/batch = 17.4799s	
15345/26050 (epoch 29.453), train_loss = 0.86694039, grad/param norm = 1.6848e-01, time/batch = 18.4080s	
15346/26050 (epoch 29.455), train_loss = 0.93144389, grad/param norm = 1.8090e-01, time/batch = 16.3154s	
15347/26050 (epoch 29.457), train_loss = 0.91899993, grad/param norm = 1.8893e-01, time/batch = 17.6159s	
15348/26050 (epoch 29.459), train_loss = 1.04090557, grad/param norm = 2.2173e-01, time/batch = 15.2850s	
15349/26050 (epoch 29.461), train_loss = 1.02331138, grad/param norm = 2.1820e-01, time/batch = 17.9670s	
15350/26050 (epoch 29.463), train_loss = 0.87931375, grad/param norm = 1.6702e-01, time/batch = 17.9779s	
15351/26050 (epoch 29.464), train_loss = 0.96823958, grad/param norm = 1.9739e-01, time/batch = 17.9040s	
15352/26050 (epoch 29.466), train_loss = 0.96330623, grad/param norm = 2.0300e-01, time/batch = 18.4211s	
15353/26050 (epoch 29.468), train_loss = 1.01806753, grad/param norm = 1.8061e-01, time/batch = 18.8118s	
15354/26050 (epoch 29.470), train_loss = 1.03201494, grad/param norm = 2.4359e-01, time/batch = 18.2183s	
15355/26050 (epoch 29.472), train_loss = 1.03409263, grad/param norm = 2.1817e-01, time/batch = 19.0659s	
15356/26050 (epoch 29.474), train_loss = 1.03393247, grad/param norm = 2.0413e-01, time/batch = 17.7403s	
15357/26050 (epoch 29.476), train_loss = 1.04190049, grad/param norm = 1.9767e-01, time/batch = 16.5352s	
15358/26050 (epoch 29.478), train_loss = 0.89262164, grad/param norm = 1.8040e-01, time/batch = 18.0665s	
15359/26050 (epoch 29.480), train_loss = 0.91210568, grad/param norm = 1.8817e-01, time/batch = 18.3382s	
15360/26050 (epoch 29.482), train_loss = 0.88271140, grad/param norm = 1.9245e-01, time/batch = 17.1563s	
15361/26050 (epoch 29.484), train_loss = 0.86441523, grad/param norm = 1.9345e-01, time/batch = 16.0327s	
15362/26050 (epoch 29.486), train_loss = 1.06099972, grad/param norm = 1.9463e-01, time/batch = 19.0629s	
15363/26050 (epoch 29.488), train_loss = 1.09676687, grad/param norm = 2.2931e-01, time/batch = 16.9686s	
15364/26050 (epoch 29.489), train_loss = 1.10595509, grad/param norm = 2.4589e-01, time/batch = 17.4060s	
15365/26050 (epoch 29.491), train_loss = 0.85791664, grad/param norm = 2.1121e-01, time/batch = 16.7133s	
15366/26050 (epoch 29.493), train_loss = 0.96184655, grad/param norm = 2.3608e-01, time/batch = 18.9116s	
15367/26050 (epoch 29.495), train_loss = 0.91362532, grad/param norm = 1.8089e-01, time/batch = 15.2996s	
15368/26050 (epoch 29.497), train_loss = 0.83429703, grad/param norm = 1.8927e-01, time/batch = 18.1405s	
15369/26050 (epoch 29.499), train_loss = 0.90311828, grad/param norm = 2.0096e-01, time/batch = 17.2388s	
15370/26050 (epoch 29.501), train_loss = 1.00894002, grad/param norm = 1.9986e-01, time/batch = 18.4150s	
15371/26050 (epoch 29.503), train_loss = 0.87167806, grad/param norm = 1.9419e-01, time/batch = 17.3871s	
15372/26050 (epoch 29.505), train_loss = 1.04365832, grad/param norm = 2.0410e-01, time/batch = 14.8993s	
15373/26050 (epoch 29.507), train_loss = 1.01479697, grad/param norm = 2.6602e-01, time/batch = 18.3189s	
15374/26050 (epoch 29.509), train_loss = 1.06797927, grad/param norm = 1.8618e-01, time/batch = 17.8118s	
15375/26050 (epoch 29.511), train_loss = 0.89860101, grad/param norm = 1.7594e-01, time/batch = 18.8100s	
15376/26050 (epoch 29.512), train_loss = 0.82777087, grad/param norm = 2.2306e-01, time/batch = 14.3904s	
15377/26050 (epoch 29.514), train_loss = 1.01041242, grad/param norm = 2.5477e-01, time/batch = 18.3075s	
15378/26050 (epoch 29.516), train_loss = 1.07220159, grad/param norm = 2.3430e-01, time/batch = 17.2201s	
15379/26050 (epoch 29.518), train_loss = 0.92456794, grad/param norm = 2.1749e-01, time/batch = 18.3982s	
15380/26050 (epoch 29.520), train_loss = 0.92534271, grad/param norm = 1.9150e-01, time/batch = 17.5783s	
15381/26050 (epoch 29.522), train_loss = 0.74398211, grad/param norm = 1.7930e-01, time/batch = 18.1536s	
15382/26050 (epoch 29.524), train_loss = 1.01013229, grad/param norm = 2.3537e-01, time/batch = 18.2310s	
15383/26050 (epoch 29.526), train_loss = 1.03781489, grad/param norm = 2.9947e-01, time/batch = 18.9935s	
15384/26050 (epoch 29.528), train_loss = 0.96128935, grad/param norm = 1.9972e-01, time/batch = 15.2254s	
15385/26050 (epoch 29.530), train_loss = 0.90472428, grad/param norm = 2.3628e-01, time/batch = 16.5617s	
15386/26050 (epoch 29.532), train_loss = 0.96613811, grad/param norm = 2.0215e-01, time/batch = 17.0530s	
15387/26050 (epoch 29.534), train_loss = 1.01203813, grad/param norm = 2.4568e-01, time/batch = 18.0752s	
15388/26050 (epoch 29.536), train_loss = 0.95737681, grad/param norm = 2.1705e-01, time/batch = 15.8892s	
15389/26050 (epoch 29.537), train_loss = 1.01406854, grad/param norm = 2.1322e-01, time/batch = 17.4847s	
15390/26050 (epoch 29.539), train_loss = 0.92409557, grad/param norm = 2.0003e-01, time/batch = 17.3917s	
15391/26050 (epoch 29.541), train_loss = 1.10366806, grad/param norm = 2.2365e-01, time/batch = 15.8012s	
15392/26050 (epoch 29.543), train_loss = 0.76733582, grad/param norm = 1.9842e-01, time/batch = 17.5850s	
15393/26050 (epoch 29.545), train_loss = 0.94403922, grad/param norm = 1.9627e-01, time/batch = 18.9965s	
15394/26050 (epoch 29.547), train_loss = 0.90486497, grad/param norm = 2.0062e-01, time/batch = 14.9741s	
15395/26050 (epoch 29.549), train_loss = 0.77973947, grad/param norm = 2.0147e-01, time/batch = 17.1351s	
15396/26050 (epoch 29.551), train_loss = 0.99326344, grad/param norm = 2.0376e-01, time/batch = 18.2415s	
15397/26050 (epoch 29.553), train_loss = 0.88239884, grad/param norm = 1.9085e-01, time/batch = 17.9888s	
15398/26050 (epoch 29.555), train_loss = 0.83573940, grad/param norm = 1.9189e-01, time/batch = 17.2408s	
15399/26050 (epoch 29.557), train_loss = 0.95394871, grad/param norm = 1.8860e-01, time/batch = 18.4016s	
15400/26050 (epoch 29.559), train_loss = 0.93939954, grad/param norm = 2.0386e-01, time/batch = 18.1556s	
15401/26050 (epoch 29.560), train_loss = 0.89193850, grad/param norm = 2.0684e-01, time/batch = 17.9971s	
15402/26050 (epoch 29.562), train_loss = 0.90694705, grad/param norm = 2.2811e-01, time/batch = 18.5548s	
15403/26050 (epoch 29.564), train_loss = 1.10364714, grad/param norm = 2.0407e-01, time/batch = 15.8825s	
15404/26050 (epoch 29.566), train_loss = 0.87043813, grad/param norm = 1.9441e-01, time/batch = 17.9032s	
15405/26050 (epoch 29.568), train_loss = 0.96206654, grad/param norm = 1.9365e-01, time/batch = 17.6611s	
15406/26050 (epoch 29.570), train_loss = 0.95912887, grad/param norm = 1.9931e-01, time/batch = 18.3202s	
15407/26050 (epoch 29.572), train_loss = 0.93714496, grad/param norm = 2.0386e-01, time/batch = 15.2294s	
15408/26050 (epoch 29.574), train_loss = 0.94187303, grad/param norm = 2.2720e-01, time/batch = 16.3826s	
15409/26050 (epoch 29.576), train_loss = 0.98015173, grad/param norm = 1.9847e-01, time/batch = 18.4003s	
15410/26050 (epoch 29.578), train_loss = 0.91604446, grad/param norm = 1.9855e-01, time/batch = 14.5542s	
15411/26050 (epoch 29.580), train_loss = 0.86476080, grad/param norm = 2.1228e-01, time/batch = 18.2413s	
15412/26050 (epoch 29.582), train_loss = 0.94924502, grad/param norm = 1.8825e-01, time/batch = 16.3141s	
15413/26050 (epoch 29.583), train_loss = 1.00150868, grad/param norm = 1.9435e-01, time/batch = 15.4731s	
15414/26050 (epoch 29.585), train_loss = 0.82099224, grad/param norm = 1.8808e-01, time/batch = 18.4030s	
15415/26050 (epoch 29.587), train_loss = 0.96961739, grad/param norm = 2.0627e-01, time/batch = 17.6636s	
15416/26050 (epoch 29.589), train_loss = 1.08455484, grad/param norm = 2.3609e-01, time/batch = 18.3279s	
15417/26050 (epoch 29.591), train_loss = 0.92711219, grad/param norm = 1.9681e-01, time/batch = 18.6614s	
15418/26050 (epoch 29.593), train_loss = 0.81849186, grad/param norm = 1.8219e-01, time/batch = 18.0715s	
15419/26050 (epoch 29.595), train_loss = 1.00131779, grad/param norm = 2.1024e-01, time/batch = 18.3093s	
15420/26050 (epoch 29.597), train_loss = 0.95403221, grad/param norm = 2.0439e-01, time/batch = 17.2201s	
15421/26050 (epoch 29.599), train_loss = 0.96618166, grad/param norm = 2.0354e-01, time/batch = 18.4743s	
15422/26050 (epoch 29.601), train_loss = 1.09118492, grad/param norm = 1.9649e-01, time/batch = 15.9595s	
15423/26050 (epoch 29.603), train_loss = 0.98745440, grad/param norm = 2.2162e-01, time/batch = 18.1414s	
15424/26050 (epoch 29.605), train_loss = 0.92906004, grad/param norm = 2.3589e-01, time/batch = 18.4843s	
15425/26050 (epoch 29.607), train_loss = 1.03311068, grad/param norm = 2.3904e-01, time/batch = 17.8063s	
15426/26050 (epoch 29.608), train_loss = 0.83236397, grad/param norm = 1.7281e-01, time/batch = 18.3850s	
15427/26050 (epoch 29.610), train_loss = 0.94429873, grad/param norm = 2.0672e-01, time/batch = 14.4052s	
15428/26050 (epoch 29.612), train_loss = 0.90330687, grad/param norm = 1.9871e-01, time/batch = 18.6540s	
15429/26050 (epoch 29.614), train_loss = 0.94984387, grad/param norm = 1.9540e-01, time/batch = 15.8677s	
15430/26050 (epoch 29.616), train_loss = 1.01204588, grad/param norm = 2.0945e-01, time/batch = 17.9072s	
15431/26050 (epoch 29.618), train_loss = 0.88512999, grad/param norm = 2.0039e-01, time/batch = 19.4042s	
15432/26050 (epoch 29.620), train_loss = 1.00428508, grad/param norm = 2.0837e-01, time/batch = 17.4741s	
15433/26050 (epoch 29.622), train_loss = 0.84415797, grad/param norm = 1.8729e-01, time/batch = 16.1560s	
15434/26050 (epoch 29.624), train_loss = 0.78764547, grad/param norm = 1.7820e-01, time/batch = 18.9021s	
15435/26050 (epoch 29.626), train_loss = 0.98784941, grad/param norm = 2.1042e-01, time/batch = 17.1496s	
15436/26050 (epoch 29.628), train_loss = 0.88622050, grad/param norm = 2.2301e-01, time/batch = 17.2219s	
15437/26050 (epoch 29.630), train_loss = 1.07881459, grad/param norm = 1.9311e-01, time/batch = 18.2310s	
15438/26050 (epoch 29.631), train_loss = 1.08637553, grad/param norm = 2.0890e-01, time/batch = 18.9055s	
15439/26050 (epoch 29.633), train_loss = 0.85136601, grad/param norm = 2.0323e-01, time/batch = 16.6419s	
15440/26050 (epoch 29.635), train_loss = 0.88033556, grad/param norm = 1.7402e-01, time/batch = 16.8056s	
15441/26050 (epoch 29.637), train_loss = 0.82369218, grad/param norm = 1.8650e-01, time/batch = 18.7172s	
15442/26050 (epoch 29.639), train_loss = 1.00343275, grad/param norm = 2.1124e-01, time/batch = 16.6412s	
15443/26050 (epoch 29.641), train_loss = 0.88530009, grad/param norm = 1.9038e-01, time/batch = 14.8642s	
15444/26050 (epoch 29.643), train_loss = 0.85233943, grad/param norm = 1.6712e-01, time/batch = 17.5719s	
15445/26050 (epoch 29.645), train_loss = 0.88339309, grad/param norm = 1.8887e-01, time/batch = 18.8947s	
15446/26050 (epoch 29.647), train_loss = 0.86718829, grad/param norm = 2.0709e-01, time/batch = 16.8103s	
15447/26050 (epoch 29.649), train_loss = 0.89841754, grad/param norm = 1.8980e-01, time/batch = 17.4598s	
15448/26050 (epoch 29.651), train_loss = 0.87742554, grad/param norm = 1.8917e-01, time/batch = 18.4060s	
15449/26050 (epoch 29.653), train_loss = 0.91549081, grad/param norm = 2.2610e-01, time/batch = 17.7056s	
15450/26050 (epoch 29.655), train_loss = 0.84040772, grad/param norm = 1.9563e-01, time/batch = 18.6519s	
15451/26050 (epoch 29.656), train_loss = 0.80949192, grad/param norm = 1.7067e-01, time/batch = 18.1435s	
15452/26050 (epoch 29.658), train_loss = 1.11184427, grad/param norm = 2.0735e-01, time/batch = 18.0547s	
15453/26050 (epoch 29.660), train_loss = 0.80162936, grad/param norm = 1.9510e-01, time/batch = 18.6366s	
15454/26050 (epoch 29.662), train_loss = 0.92326439, grad/param norm = 2.0140e-01, time/batch = 16.5579s	
15455/26050 (epoch 29.664), train_loss = 0.91105349, grad/param norm = 1.8664e-01, time/batch = 18.3023s	
15456/26050 (epoch 29.666), train_loss = 0.87735282, grad/param norm = 2.0600e-01, time/batch = 17.3270s	
15457/26050 (epoch 29.668), train_loss = 0.73437463, grad/param norm = 2.0614e-01, time/batch = 18.8256s	
15458/26050 (epoch 29.670), train_loss = 1.05999884, grad/param norm = 2.4342e-01, time/batch = 18.0734s	
15459/26050 (epoch 29.672), train_loss = 0.92100403, grad/param norm = 1.8763e-01, time/batch = 16.9855s	
15460/26050 (epoch 29.674), train_loss = 0.82302944, grad/param norm = 2.1068e-01, time/batch = 18.0622s	
15461/26050 (epoch 29.676), train_loss = 0.97633408, grad/param norm = 2.0687e-01, time/batch = 18.4895s	
15462/26050 (epoch 29.678), train_loss = 1.01112879, grad/param norm = 2.2262e-01, time/batch = 17.8920s	
15463/26050 (epoch 29.679), train_loss = 1.06500791, grad/param norm = 2.2769e-01, time/batch = 17.3144s	
15464/26050 (epoch 29.681), train_loss = 0.95768495, grad/param norm = 1.9973e-01, time/batch = 14.6405s	
15465/26050 (epoch 29.683), train_loss = 0.81737226, grad/param norm = 2.1650e-01, time/batch = 19.0661s	
15466/26050 (epoch 29.685), train_loss = 0.89528446, grad/param norm = 1.9565e-01, time/batch = 16.2139s	
15467/26050 (epoch 29.687), train_loss = 0.81740629, grad/param norm = 1.8866e-01, time/batch = 18.7301s	
15468/26050 (epoch 29.689), train_loss = 0.87309088, grad/param norm = 2.0374e-01, time/batch = 15.7859s	
15469/26050 (epoch 29.691), train_loss = 0.74921248, grad/param norm = 1.6654e-01, time/batch = 18.3033s	
15470/26050 (epoch 29.693), train_loss = 0.87117812, grad/param norm = 2.0218e-01, time/batch = 17.6367s	
15471/26050 (epoch 29.695), train_loss = 0.91205082, grad/param norm = 1.8537e-01, time/batch = 18.4881s	
15472/26050 (epoch 29.697), train_loss = 0.86071609, grad/param norm = 1.8097e-01, time/batch = 18.7249s	
15473/26050 (epoch 29.699), train_loss = 0.96357122, grad/param norm = 2.1410e-01, time/batch = 17.3909s	
15474/26050 (epoch 29.701), train_loss = 0.83577324, grad/param norm = 1.7799e-01, time/batch = 18.6417s	
15475/26050 (epoch 29.702), train_loss = 1.00985000, grad/param norm = 2.1292e-01, time/batch = 18.2417s	
15476/26050 (epoch 29.704), train_loss = 1.01238763, grad/param norm = 1.9107e-01, time/batch = 17.8077s	
15477/26050 (epoch 29.706), train_loss = 0.86373011, grad/param norm = 2.0954e-01, time/batch = 16.3914s	
15478/26050 (epoch 29.708), train_loss = 1.01112125, grad/param norm = 2.2489e-01, time/batch = 18.6426s	
15479/26050 (epoch 29.710), train_loss = 0.94976675, grad/param norm = 2.3635e-01, time/batch = 18.6467s	
15480/26050 (epoch 29.712), train_loss = 0.93757254, grad/param norm = 1.9973e-01, time/batch = 24.0842s	
15481/26050 (epoch 29.714), train_loss = 0.81161671, grad/param norm = 1.6937e-01, time/batch = 30.3201s	
15482/26050 (epoch 29.716), train_loss = 1.16094688, grad/param norm = 2.2983e-01, time/batch = 16.7947s	
15483/26050 (epoch 29.718), train_loss = 0.98569307, grad/param norm = 2.0234e-01, time/batch = 17.9122s	
15484/26050 (epoch 29.720), train_loss = 0.91710120, grad/param norm = 2.0560e-01, time/batch = 18.4900s	
15485/26050 (epoch 29.722), train_loss = 0.83178995, grad/param norm = 1.9242e-01, time/batch = 16.8251s	
15486/26050 (epoch 29.724), train_loss = 0.86972502, grad/param norm = 2.2623e-01, time/batch = 18.8135s	
15487/26050 (epoch 29.726), train_loss = 0.97238350, grad/param norm = 2.1122e-01, time/batch = 15.5559s	
15488/26050 (epoch 29.727), train_loss = 0.98179574, grad/param norm = 2.2898e-01, time/batch = 17.5520s	
15489/26050 (epoch 29.729), train_loss = 0.95473384, grad/param norm = 2.0043e-01, time/batch = 18.1402s	
15490/26050 (epoch 29.731), train_loss = 0.96398007, grad/param norm = 2.0420e-01, time/batch = 15.2992s	
15491/26050 (epoch 29.733), train_loss = 0.91553213, grad/param norm = 2.6498e-01, time/batch = 18.0679s	
15492/26050 (epoch 29.735), train_loss = 1.08739249, grad/param norm = 2.2161e-01, time/batch = 16.3869s	
15493/26050 (epoch 29.737), train_loss = 0.87374194, grad/param norm = 1.9702e-01, time/batch = 18.1409s	
15494/26050 (epoch 29.739), train_loss = 0.95296997, grad/param norm = 1.9950e-01, time/batch = 17.8899s	
15495/26050 (epoch 29.741), train_loss = 0.86671900, grad/param norm = 1.9760e-01, time/batch = 18.4711s	
15496/26050 (epoch 29.743), train_loss = 0.95600089, grad/param norm = 2.2081e-01, time/batch = 17.0747s	
15497/26050 (epoch 29.745), train_loss = 0.81830015, grad/param norm = 1.9478e-01, time/batch = 18.8185s	
15498/26050 (epoch 29.747), train_loss = 0.85338691, grad/param norm = 2.0199e-01, time/batch = 14.6405s	
15499/26050 (epoch 29.749), train_loss = 1.02815758, grad/param norm = 2.2128e-01, time/batch = 17.2374s	
15500/26050 (epoch 29.750), train_loss = 0.91326872, grad/param norm = 1.6583e-01, time/batch = 17.9636s	
15501/26050 (epoch 29.752), train_loss = 0.87608715, grad/param norm = 2.3186e-01, time/batch = 17.9686s	
15502/26050 (epoch 29.754), train_loss = 0.92700138, grad/param norm = 1.9185e-01, time/batch = 15.5422s	
15503/26050 (epoch 29.756), train_loss = 0.90766720, grad/param norm = 2.1328e-01, time/batch = 17.9535s	
15504/26050 (epoch 29.758), train_loss = 0.90636100, grad/param norm = 2.0365e-01, time/batch = 16.5474s	
15505/26050 (epoch 29.760), train_loss = 1.06099437, grad/param norm = 2.1129e-01, time/batch = 18.0535s	
15506/26050 (epoch 29.762), train_loss = 0.85880024, grad/param norm = 1.8448e-01, time/batch = 17.4798s	
15507/26050 (epoch 29.764), train_loss = 0.90898457, grad/param norm = 2.2885e-01, time/batch = 18.4897s	
15508/26050 (epoch 29.766), train_loss = 0.95137907, grad/param norm = 2.3451e-01, time/batch = 18.9749s	
15509/26050 (epoch 29.768), train_loss = 0.82531745, grad/param norm = 1.8775e-01, time/batch = 17.0834s	
15510/26050 (epoch 29.770), train_loss = 0.89051248, grad/param norm = 2.1450e-01, time/batch = 15.7244s	
15511/26050 (epoch 29.772), train_loss = 0.92274513, grad/param norm = 1.8163e-01, time/batch = 18.1509s	
15512/26050 (epoch 29.774), train_loss = 0.80973999, grad/param norm = 2.1314e-01, time/batch = 18.9945s	
15513/26050 (epoch 29.775), train_loss = 0.65769384, grad/param norm = 1.6103e-01, time/batch = 16.9693s	
15514/26050 (epoch 29.777), train_loss = 0.87395274, grad/param norm = 1.9656e-01, time/batch = 18.4845s	
15515/26050 (epoch 29.779), train_loss = 0.90955853, grad/param norm = 2.0897e-01, time/batch = 17.9539s	
15516/26050 (epoch 29.781), train_loss = 0.80407233, grad/param norm = 1.8268e-01, time/batch = 15.4887s	
15517/26050 (epoch 29.783), train_loss = 0.80889817, grad/param norm = 2.0522e-01, time/batch = 18.9701s	
15518/26050 (epoch 29.785), train_loss = 0.92342911, grad/param norm = 2.0471e-01, time/batch = 17.9805s	
15519/26050 (epoch 29.787), train_loss = 0.83717900, grad/param norm = 2.1097e-01, time/batch = 17.6472s	
15520/26050 (epoch 29.789), train_loss = 0.84733956, grad/param norm = 2.2000e-01, time/batch = 18.0619s	
15521/26050 (epoch 29.791), train_loss = 0.84800213, grad/param norm = 2.2070e-01, time/batch = 17.1583s	
15522/26050 (epoch 29.793), train_loss = 0.92504793, grad/param norm = 2.3328e-01, time/batch = 15.3976s	
15523/26050 (epoch 29.795), train_loss = 0.73972775, grad/param norm = 1.5928e-01, time/batch = 16.5679s	
15524/26050 (epoch 29.797), train_loss = 0.80741083, grad/param norm = 1.9834e-01, time/batch = 17.4058s	
15525/26050 (epoch 29.798), train_loss = 0.80711157, grad/param norm = 1.8842e-01, time/batch = 18.8076s	
15526/26050 (epoch 29.800), train_loss = 0.80656947, grad/param norm = 1.9719e-01, time/batch = 14.9779s	
15527/26050 (epoch 29.802), train_loss = 0.85445844, grad/param norm = 2.0093e-01, time/batch = 18.0589s	
15528/26050 (epoch 29.804), train_loss = 0.87582254, grad/param norm = 1.8778e-01, time/batch = 16.9103s	
15529/26050 (epoch 29.806), train_loss = 0.97911906, grad/param norm = 2.0358e-01, time/batch = 18.8069s	
15530/26050 (epoch 29.808), train_loss = 0.91264632, grad/param norm = 2.1124e-01, time/batch = 16.6147s	
15531/26050 (epoch 29.810), train_loss = 0.87872221, grad/param norm = 2.1206e-01, time/batch = 18.4846s	
15532/26050 (epoch 29.812), train_loss = 0.77643754, grad/param norm = 1.8377e-01, time/batch = 15.5712s	
15533/26050 (epoch 29.814), train_loss = 0.82964999, grad/param norm = 2.0188e-01, time/batch = 17.8856s	
15534/26050 (epoch 29.816), train_loss = 0.96377411, grad/param norm = 2.3413e-01, time/batch = 18.3051s	
15535/26050 (epoch 29.818), train_loss = 1.00703596, grad/param norm = 2.5372e-01, time/batch = 18.3045s	
15536/26050 (epoch 29.820), train_loss = 0.92561628, grad/param norm = 1.9977e-01, time/batch = 16.5673s	
15537/26050 (epoch 29.821), train_loss = 1.02501609, grad/param norm = 2.1179e-01, time/batch = 17.6936s	
15538/26050 (epoch 29.823), train_loss = 1.09086404, grad/param norm = 2.2047e-01, time/batch = 18.1379s	
15539/26050 (epoch 29.825), train_loss = 0.91773999, grad/param norm = 2.1119e-01, time/batch = 18.3231s	
15540/26050 (epoch 29.827), train_loss = 0.93110135, grad/param norm = 2.1732e-01, time/batch = 17.4861s	
15541/26050 (epoch 29.829), train_loss = 0.99070838, grad/param norm = 2.1900e-01, time/batch = 18.8952s	
15542/26050 (epoch 29.831), train_loss = 1.06128659, grad/param norm = 2.2813e-01, time/batch = 17.6572s	
15543/26050 (epoch 29.833), train_loss = 1.05881527, grad/param norm = 2.3157e-01, time/batch = 17.3865s	
15544/26050 (epoch 29.835), train_loss = 1.06265184, grad/param norm = 2.0552e-01, time/batch = 18.4844s	
15545/26050 (epoch 29.837), train_loss = 0.91537754, grad/param norm = 1.8574e-01, time/batch = 18.4867s	
15546/26050 (epoch 29.839), train_loss = 0.91505871, grad/param norm = 2.1537e-01, time/batch = 15.1907s	
15547/26050 (epoch 29.841), train_loss = 1.00594204, grad/param norm = 2.0299e-01, time/batch = 16.6272s	
15548/26050 (epoch 29.843), train_loss = 0.89515987, grad/param norm = 1.7922e-01, time/batch = 18.5616s	
15549/26050 (epoch 29.845), train_loss = 0.87205681, grad/param norm = 1.8308e-01, time/batch = 18.0671s	
15550/26050 (epoch 29.846), train_loss = 0.97958525, grad/param norm = 2.0534e-01, time/batch = 17.3143s	
15551/26050 (epoch 29.848), train_loss = 0.90717139, grad/param norm = 1.9536e-01, time/batch = 18.5662s	
15552/26050 (epoch 29.850), train_loss = 0.83055444, grad/param norm = 1.9066e-01, time/batch = 18.4896s	
15553/26050 (epoch 29.852), train_loss = 0.93261917, grad/param norm = 1.8924e-01, time/batch = 17.3276s	
15554/26050 (epoch 29.854), train_loss = 0.90795096, grad/param norm = 2.0304e-01, time/batch = 15.6458s	
15555/26050 (epoch 29.856), train_loss = 0.88323391, grad/param norm = 2.2245e-01, time/batch = 18.0514s	
15556/26050 (epoch 29.858), train_loss = 0.84068910, grad/param norm = 1.8948e-01, time/batch = 18.7446s	
15557/26050 (epoch 29.860), train_loss = 0.95555176, grad/param norm = 1.9515e-01, time/batch = 17.2472s	
15558/26050 (epoch 29.862), train_loss = 0.99763689, grad/param norm = 2.1206e-01, time/batch = 17.2120s	
15559/26050 (epoch 29.864), train_loss = 0.95245529, grad/param norm = 2.3065e-01, time/batch = 18.4920s	
15560/26050 (epoch 29.866), train_loss = 0.87728659, grad/param norm = 1.7948e-01, time/batch = 17.4756s	
15561/26050 (epoch 29.868), train_loss = 0.96736020, grad/param norm = 2.0191e-01, time/batch = 18.2146s	
15562/26050 (epoch 29.869), train_loss = 0.82727331, grad/param norm = 1.8546e-01, time/batch = 18.3242s	
15563/26050 (epoch 29.871), train_loss = 0.78382591, grad/param norm = 1.9386e-01, time/batch = 18.7186s	
15564/26050 (epoch 29.873), train_loss = 0.96262711, grad/param norm = 2.2679e-01, time/batch = 21.0631s	
15565/26050 (epoch 29.875), train_loss = 0.89394797, grad/param norm = 1.9877e-01, time/batch = 19.0965s	
15566/26050 (epoch 29.877), train_loss = 0.84784288, grad/param norm = 1.8797e-01, time/batch = 20.9255s	
15567/26050 (epoch 29.879), train_loss = 0.93390485, grad/param norm = 1.8105e-01, time/batch = 22.6640s	
15568/26050 (epoch 29.881), train_loss = 1.00122825, grad/param norm = 2.2715e-01, time/batch = 23.6686s	
15569/26050 (epoch 29.883), train_loss = 0.95658936, grad/param norm = 2.0061e-01, time/batch = 21.8468s	
15570/26050 (epoch 29.885), train_loss = 0.70905488, grad/param norm = 1.8632e-01, time/batch = 24.2491s	
15571/26050 (epoch 29.887), train_loss = 0.98442845, grad/param norm = 2.3290e-01, time/batch = 23.4353s	
15572/26050 (epoch 29.889), train_loss = 0.84317428, grad/param norm = 1.8152e-01, time/batch = 24.1369s	
15573/26050 (epoch 29.891), train_loss = 0.76872976, grad/param norm = 1.8930e-01, time/batch = 24.5355s	
15574/26050 (epoch 29.893), train_loss = 0.80522875, grad/param norm = 1.9518e-01, time/batch = 24.0019s	
15575/26050 (epoch 29.894), train_loss = 0.87006112, grad/param norm = 1.9035e-01, time/batch = 24.0088s	
15576/26050 (epoch 29.896), train_loss = 1.01970682, grad/param norm = 2.3022e-01, time/batch = 24.0689s	
15577/26050 (epoch 29.898), train_loss = 0.87104154, grad/param norm = 2.2043e-01, time/batch = 23.3443s	
15578/26050 (epoch 29.900), train_loss = 0.95110672, grad/param norm = 2.0591e-01, time/batch = 24.1737s	
15579/26050 (epoch 29.902), train_loss = 0.89606962, grad/param norm = 1.9907e-01, time/batch = 22.6622s	
15580/26050 (epoch 29.904), train_loss = 0.87335625, grad/param norm = 1.8199e-01, time/batch = 30.4908s	
15581/26050 (epoch 29.906), train_loss = 0.90311064, grad/param norm = 2.5059e-01, time/batch = 14.7893s	
15582/26050 (epoch 29.908), train_loss = 0.92302260, grad/param norm = 1.9636e-01, time/batch = 17.8200s	
15583/26050 (epoch 29.910), train_loss = 0.88146262, grad/param norm = 2.1108e-01, time/batch = 18.5575s	
15584/26050 (epoch 29.912), train_loss = 1.10029877, grad/param norm = 2.3307e-01, time/batch = 16.8850s	
15585/26050 (epoch 29.914), train_loss = 1.25053127, grad/param norm = 2.4514e-01, time/batch = 16.9795s	
15586/26050 (epoch 29.916), train_loss = 1.00518952, grad/param norm = 2.6227e-01, time/batch = 18.4879s	
15587/26050 (epoch 29.917), train_loss = 0.92599279, grad/param norm = 2.1438e-01, time/batch = 18.8108s	
15588/26050 (epoch 29.919), train_loss = 0.95391163, grad/param norm = 2.1971e-01, time/batch = 17.6424s	
15589/26050 (epoch 29.921), train_loss = 0.87566260, grad/param norm = 2.2151e-01, time/batch = 17.5667s	
15590/26050 (epoch 29.923), train_loss = 0.93274343, grad/param norm = 1.8962e-01, time/batch = 15.6652s	
15591/26050 (epoch 29.925), train_loss = 0.90411135, grad/param norm = 1.9167e-01, time/batch = 18.8281s	
15592/26050 (epoch 29.927), train_loss = 0.82662972, grad/param norm = 1.5167e-01, time/batch = 16.6486s	
15593/26050 (epoch 29.929), train_loss = 0.77767287, grad/param norm = 1.7941e-01, time/batch = 18.1390s	
15594/26050 (epoch 29.931), train_loss = 1.10735603, grad/param norm = 2.9536e-01, time/batch = 16.1383s	
15595/26050 (epoch 29.933), train_loss = 0.88936293, grad/param norm = 1.9751e-01, time/batch = 18.2357s	
15596/26050 (epoch 29.935), train_loss = 0.88112506, grad/param norm = 2.0453e-01, time/batch = 17.7375s	
15597/26050 (epoch 29.937), train_loss = 1.00390149, grad/param norm = 2.0837e-01, time/batch = 18.3222s	
15598/26050 (epoch 29.939), train_loss = 0.84568421, grad/param norm = 1.7542e-01, time/batch = 16.3957s	
15599/26050 (epoch 29.940), train_loss = 0.86217362, grad/param norm = 1.8497e-01, time/batch = 15.2058s	
15600/26050 (epoch 29.942), train_loss = 0.89912595, grad/param norm = 2.0177e-01, time/batch = 17.8299s	
15601/26050 (epoch 29.944), train_loss = 0.87646256, grad/param norm = 1.7080e-01, time/batch = 18.7301s	
15602/26050 (epoch 29.946), train_loss = 1.04564984, grad/param norm = 1.9608e-01, time/batch = 15.5441s	
15603/26050 (epoch 29.948), train_loss = 0.77557302, grad/param norm = 2.0166e-01, time/batch = 17.7372s	
15604/26050 (epoch 29.950), train_loss = 0.89301220, grad/param norm = 1.9415e-01, time/batch = 18.4959s	
15605/26050 (epoch 29.952), train_loss = 0.97521550, grad/param norm = 2.0483e-01, time/batch = 18.3255s	
15606/26050 (epoch 29.954), train_loss = 0.98514302, grad/param norm = 2.0150e-01, time/batch = 15.5081s	
15607/26050 (epoch 29.956), train_loss = 0.88098654, grad/param norm = 1.9904e-01, time/batch = 14.8898s	
15608/26050 (epoch 29.958), train_loss = 0.82670730, grad/param norm = 1.7672e-01, time/batch = 14.7965s	
15609/26050 (epoch 29.960), train_loss = 0.94754432, grad/param norm = 2.1065e-01, time/batch = 13.8950s	
15610/26050 (epoch 29.962), train_loss = 0.87521946, grad/param norm = 1.7245e-01, time/batch = 16.3028s	
15611/26050 (epoch 29.964), train_loss = 0.90318882, grad/param norm = 1.9132e-01, time/batch = 18.2508s	
15612/26050 (epoch 29.965), train_loss = 0.83499280, grad/param norm = 1.9085e-01, time/batch = 17.3181s	
15613/26050 (epoch 29.967), train_loss = 1.22055113, grad/param norm = 2.0319e-01, time/batch = 16.3162s	
15614/26050 (epoch 29.969), train_loss = 0.93535494, grad/param norm = 1.9939e-01, time/batch = 18.9082s	
15615/26050 (epoch 29.971), train_loss = 0.89719233, grad/param norm = 2.0040e-01, time/batch = 18.4916s	
15616/26050 (epoch 29.973), train_loss = 0.92898381, grad/param norm = 2.0896e-01, time/batch = 17.9881s	
15617/26050 (epoch 29.975), train_loss = 0.95027263, grad/param norm = 2.0499e-01, time/batch = 18.5675s	
15618/26050 (epoch 29.977), train_loss = 0.91708342, grad/param norm = 1.7203e-01, time/batch = 17.2503s	
15619/26050 (epoch 29.979), train_loss = 0.75412023, grad/param norm = 2.0082e-01, time/batch = 15.0514s	
15620/26050 (epoch 29.981), train_loss = 1.04074062, grad/param norm = 2.0849e-01, time/batch = 16.2115s	
15621/26050 (epoch 29.983), train_loss = 0.99101056, grad/param norm = 2.0384e-01, time/batch = 18.3126s	
15622/26050 (epoch 29.985), train_loss = 0.96226472, grad/param norm = 2.0294e-01, time/batch = 18.1574s	
15623/26050 (epoch 29.987), train_loss = 1.01686238, grad/param norm = 1.9212e-01, time/batch = 15.7131s	
15624/26050 (epoch 29.988), train_loss = 0.95862602, grad/param norm = 2.2474e-01, time/batch = 18.2250s	
15625/26050 (epoch 29.990), train_loss = 0.79987198, grad/param norm = 1.6584e-01, time/batch = 18.4804s	
15626/26050 (epoch 29.992), train_loss = 1.05609292, grad/param norm = 1.9653e-01, time/batch = 18.0794s	
15627/26050 (epoch 29.994), train_loss = 0.86842812, grad/param norm = 2.0636e-01, time/batch = 17.4499s	
15628/26050 (epoch 29.996), train_loss = 0.85509174, grad/param norm = 2.4614e-01, time/batch = 18.8109s	
15629/26050 (epoch 29.998), train_loss = 0.92936585, grad/param norm = 1.8594e-01, time/batch = 17.4979s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
15630/26050 (epoch 30.000), train_loss = 0.86030617, grad/param norm = 2.0445e-01, time/batch = 17.3139s	
15631/26050 (epoch 30.002), train_loss = 0.96278609, grad/param norm = 2.1859e-01, time/batch = 16.9809s	
15632/26050 (epoch 30.004), train_loss = 0.81516915, grad/param norm = 1.9627e-01, time/batch = 18.6350s	
15633/26050 (epoch 30.006), train_loss = 0.86084404, grad/param norm = 2.1519e-01, time/batch = 15.7134s	
15634/26050 (epoch 30.008), train_loss = 0.85150570, grad/param norm = 2.0826e-01, time/batch = 17.4150s	
15635/26050 (epoch 30.010), train_loss = 0.83581271, grad/param norm = 1.9539e-01, time/batch = 18.0667s	
15636/26050 (epoch 30.012), train_loss = 0.91291400, grad/param norm = 1.8838e-01, time/batch = 16.8895s	
15637/26050 (epoch 30.013), train_loss = 1.16260112, grad/param norm = 2.5301e-01, time/batch = 16.9886s	
15638/26050 (epoch 30.015), train_loss = 0.90217373, grad/param norm = 1.8559e-01, time/batch = 18.8117s	
15639/26050 (epoch 30.017), train_loss = 0.94006719, grad/param norm = 1.9130e-01, time/batch = 14.7392s	
15640/26050 (epoch 30.019), train_loss = 0.80652389, grad/param norm = 1.7470e-01, time/batch = 17.8895s	
15641/26050 (epoch 30.021), train_loss = 1.00024084, grad/param norm = 1.9553e-01, time/batch = 17.8827s	
15642/26050 (epoch 30.023), train_loss = 0.75072445, grad/param norm = 1.9715e-01, time/batch = 18.9086s	
15643/26050 (epoch 30.025), train_loss = 0.88996203, grad/param norm = 1.8108e-01, time/batch = 17.8230s	
15644/26050 (epoch 30.027), train_loss = 0.73925870, grad/param norm = 1.9752e-01, time/batch = 8.8454s	
15645/26050 (epoch 30.029), train_loss = 0.92964888, grad/param norm = 1.9377e-01, time/batch = 0.6678s	
15646/26050 (epoch 30.031), train_loss = 1.02832638, grad/param norm = 2.2141e-01, time/batch = 0.6673s	
15647/26050 (epoch 30.033), train_loss = 0.93803455, grad/param norm = 2.0261e-01, time/batch = 0.6671s	
15648/26050 (epoch 30.035), train_loss = 0.93930654, grad/param norm = 1.9321e-01, time/batch = 0.6551s	
15649/26050 (epoch 30.036), train_loss = 0.78556152, grad/param norm = 2.1040e-01, time/batch = 0.6573s	
15650/26050 (epoch 30.038), train_loss = 0.72919628, grad/param norm = 1.7660e-01, time/batch = 0.6529s	
15651/26050 (epoch 30.040), train_loss = 0.89120109, grad/param norm = 2.0368e-01, time/batch = 0.6480s	
15652/26050 (epoch 30.042), train_loss = 0.77052436, grad/param norm = 1.8848e-01, time/batch = 0.9394s	
15653/26050 (epoch 30.044), train_loss = 0.97724975, grad/param norm = 1.8489e-01, time/batch = 0.9655s	
15654/26050 (epoch 30.046), train_loss = 0.74314996, grad/param norm = 1.6542e-01, time/batch = 0.9642s	
15655/26050 (epoch 30.048), train_loss = 0.90290574, grad/param norm = 1.8822e-01, time/batch = 0.9412s	
15656/26050 (epoch 30.050), train_loss = 0.86353020, grad/param norm = 1.8861e-01, time/batch = 0.9512s	
15657/26050 (epoch 30.052), train_loss = 0.82731096, grad/param norm = 2.1997e-01, time/batch = 1.5457s	
15658/26050 (epoch 30.054), train_loss = 0.75181240, grad/param norm = 1.7595e-01, time/batch = 1.7631s	
15659/26050 (epoch 30.056), train_loss = 0.74390075, grad/param norm = 1.7433e-01, time/batch = 1.7941s	
15660/26050 (epoch 30.058), train_loss = 0.88393520, grad/param norm = 1.8475e-01, time/batch = 17.1281s	
15661/26050 (epoch 30.060), train_loss = 0.95231916, grad/param norm = 1.9572e-01, time/batch = 18.5717s	
15662/26050 (epoch 30.061), train_loss = 0.80605762, grad/param norm = 1.7802e-01, time/batch = 16.6910s	
15663/26050 (epoch 30.063), train_loss = 0.90401878, grad/param norm = 1.9068e-01, time/batch = 18.1636s	
15664/26050 (epoch 30.065), train_loss = 0.74022663, grad/param norm = 1.5602e-01, time/batch = 18.9024s	
15665/26050 (epoch 30.067), train_loss = 0.88831174, grad/param norm = 2.0140e-01, time/batch = 17.3937s	
15666/26050 (epoch 30.069), train_loss = 0.93577947, grad/param norm = 2.0427e-01, time/batch = 17.6464s	
15667/26050 (epoch 30.071), train_loss = 0.94129952, grad/param norm = 1.8782e-01, time/batch = 16.6384s	
15668/26050 (epoch 30.073), train_loss = 1.04464116, grad/param norm = 2.0359e-01, time/batch = 17.6229s	
15669/26050 (epoch 30.075), train_loss = 0.85006881, grad/param norm = 1.9079e-01, time/batch = 17.2362s	
15670/26050 (epoch 30.077), train_loss = 0.86904318, grad/param norm = 2.4128e-01, time/batch = 17.6386s	
15671/26050 (epoch 30.079), train_loss = 0.90444458, grad/param norm = 2.2201e-01, time/batch = 18.9097s	
15672/26050 (epoch 30.081), train_loss = 0.86853908, grad/param norm = 1.8564e-01, time/batch = 17.6394s	
15673/26050 (epoch 30.083), train_loss = 1.00085197, grad/param norm = 1.9346e-01, time/batch = 17.9881s	
15674/26050 (epoch 30.084), train_loss = 0.92002633, grad/param norm = 2.4417e-01, time/batch = 18.3304s	
15675/26050 (epoch 30.086), train_loss = 1.07169683, grad/param norm = 2.4062e-01, time/batch = 16.5417s	
15676/26050 (epoch 30.088), train_loss = 0.85868974, grad/param norm = 1.9091e-01, time/batch = 16.3646s	
15677/26050 (epoch 30.090), train_loss = 0.92575384, grad/param norm = 2.2497e-01, time/batch = 17.6434s	
15678/26050 (epoch 30.092), train_loss = 0.94233775, grad/param norm = 2.0810e-01, time/batch = 16.0641s	
15679/26050 (epoch 30.094), train_loss = 0.79373190, grad/param norm = 1.8792e-01, time/batch = 17.7413s	
15680/26050 (epoch 30.096), train_loss = 0.92290506, grad/param norm = 1.8568e-01, time/batch = 18.8961s	
15681/26050 (epoch 30.098), train_loss = 0.87892005, grad/param norm = 1.9738e-01, time/batch = 18.2309s	
15682/26050 (epoch 30.100), train_loss = 0.83563719, grad/param norm = 2.1133e-01, time/batch = 17.1404s	
15683/26050 (epoch 30.102), train_loss = 0.95688669, grad/param norm = 2.0423e-01, time/batch = 18.3177s	
15684/26050 (epoch 30.104), train_loss = 0.87211588, grad/param norm = 2.0061e-01, time/batch = 18.2293s	
15685/26050 (epoch 30.106), train_loss = 0.93574175, grad/param norm = 2.1519e-01, time/batch = 17.7310s	
15686/26050 (epoch 30.107), train_loss = 0.75309357, grad/param norm = 1.9300e-01, time/batch = 18.0613s	
15687/26050 (epoch 30.109), train_loss = 0.84054566, grad/param norm = 1.8847e-01, time/batch = 18.2391s	
15688/26050 (epoch 30.111), train_loss = 1.05432267, grad/param norm = 2.5720e-01, time/batch = 18.4016s	
15689/26050 (epoch 30.113), train_loss = 0.86154053, grad/param norm = 1.8958e-01, time/batch = 18.3997s	
15690/26050 (epoch 30.115), train_loss = 0.99222291, grad/param norm = 1.8316e-01, time/batch = 16.3004s	
15691/26050 (epoch 30.117), train_loss = 0.90178795, grad/param norm = 1.8959e-01, time/batch = 18.9903s	
15692/26050 (epoch 30.119), train_loss = 0.77229861, grad/param norm = 1.9322e-01, time/batch = 20.1431s	
15693/26050 (epoch 30.121), train_loss = 0.93149037, grad/param norm = 2.0556e-01, time/batch = 31.6776s	
15694/26050 (epoch 30.123), train_loss = 0.84087529, grad/param norm = 1.9194e-01, time/batch = 19.6523s	
15695/26050 (epoch 30.125), train_loss = 0.78209026, grad/param norm = 1.7837e-01, time/batch = 18.4804s	
15696/26050 (epoch 30.127), train_loss = 0.73966976, grad/param norm = 1.7060e-01, time/batch = 15.8907s	
15697/26050 (epoch 30.129), train_loss = 0.72510577, grad/param norm = 1.7718e-01, time/batch = 17.5529s	
15698/26050 (epoch 30.131), train_loss = 0.86995920, grad/param norm = 2.2759e-01, time/batch = 17.3971s	
15699/26050 (epoch 30.132), train_loss = 0.87487843, grad/param norm = 1.6745e-01, time/batch = 18.5627s	
15700/26050 (epoch 30.134), train_loss = 0.92747787, grad/param norm = 2.2977e-01, time/batch = 18.7266s	
15701/26050 (epoch 30.136), train_loss = 0.87705714, grad/param norm = 1.8331e-01, time/batch = 15.8764s	
15702/26050 (epoch 30.138), train_loss = 0.66414073, grad/param norm = 1.8438e-01, time/batch = 17.4757s	
15703/26050 (epoch 30.140), train_loss = 0.75839545, grad/param norm = 2.0862e-01, time/batch = 18.7295s	
15704/26050 (epoch 30.142), train_loss = 0.78062899, grad/param norm = 1.9233e-01, time/batch = 16.8176s	
15705/26050 (epoch 30.144), train_loss = 0.70297019, grad/param norm = 1.8059e-01, time/batch = 17.8094s	
15706/26050 (epoch 30.146), train_loss = 0.66992184, grad/param norm = 1.7715e-01, time/batch = 17.5884s	
15707/26050 (epoch 30.148), train_loss = 0.70940777, grad/param norm = 1.5933e-01, time/batch = 18.5684s	
15708/26050 (epoch 30.150), train_loss = 0.83497090, grad/param norm = 1.9149e-01, time/batch = 15.8646s	
15709/26050 (epoch 30.152), train_loss = 1.04302454, grad/param norm = 3.0511e-01, time/batch = 16.2418s	
15710/26050 (epoch 30.154), train_loss = 0.72513003, grad/param norm = 1.9266e-01, time/batch = 17.2215s	
15711/26050 (epoch 30.155), train_loss = 0.76676591, grad/param norm = 1.9921e-01, time/batch = 17.2404s	
15712/26050 (epoch 30.157), train_loss = 0.87489473, grad/param norm = 2.1718e-01, time/batch = 18.6539s	
15713/26050 (epoch 30.159), train_loss = 0.92528236, grad/param norm = 2.2765e-01, time/batch = 15.0670s	
15714/26050 (epoch 30.161), train_loss = 0.90606542, grad/param norm = 2.1936e-01, time/batch = 17.0000s	
15715/26050 (epoch 30.163), train_loss = 0.74616427, grad/param norm = 1.8952e-01, time/batch = 17.2252s	
15716/26050 (epoch 30.165), train_loss = 0.69421657, grad/param norm = 1.7992e-01, time/batch = 18.7372s	
15717/26050 (epoch 30.167), train_loss = 1.03300050, grad/param norm = 2.2361e-01, time/batch = 18.0791s	
15718/26050 (epoch 30.169), train_loss = 0.89770089, grad/param norm = 2.1074e-01, time/batch = 17.3306s	
15719/26050 (epoch 30.171), train_loss = 0.75689424, grad/param norm = 1.7029e-01, time/batch = 17.9706s	
15720/26050 (epoch 30.173), train_loss = 0.85380603, grad/param norm = 1.9363e-01, time/batch = 15.5525s	
15721/26050 (epoch 30.175), train_loss = 0.87001982, grad/param norm = 1.8687e-01, time/batch = 18.3275s	
15722/26050 (epoch 30.177), train_loss = 0.97325285, grad/param norm = 2.0040e-01, time/batch = 17.7441s	
15723/26050 (epoch 30.179), train_loss = 0.65028334, grad/param norm = 1.6667e-01, time/batch = 18.3247s	
15724/26050 (epoch 30.180), train_loss = 1.11051623, grad/param norm = 2.1074e-01, time/batch = 18.0832s	
15725/26050 (epoch 30.182), train_loss = 1.08027036, grad/param norm = 2.2869e-01, time/batch = 16.7335s	
15726/26050 (epoch 30.184), train_loss = 0.92925192, grad/param norm = 1.8817e-01, time/batch = 18.0670s	
15727/26050 (epoch 30.186), train_loss = 0.74867001, grad/param norm = 1.8567e-01, time/batch = 18.2384s	
15728/26050 (epoch 30.188), train_loss = 0.90470554, grad/param norm = 2.0530e-01, time/batch = 17.6529s	
15729/26050 (epoch 30.190), train_loss = 0.93235898, grad/param norm = 2.0801e-01, time/batch = 14.4775s	
15730/26050 (epoch 30.192), train_loss = 0.96045276, grad/param norm = 1.9634e-01, time/batch = 18.7301s	
15731/26050 (epoch 30.194), train_loss = 0.93703454, grad/param norm = 1.9759e-01, time/batch = 15.7139s	
15732/26050 (epoch 30.196), train_loss = 0.95052050, grad/param norm = 2.0031e-01, time/batch = 16.6304s	
15733/26050 (epoch 30.198), train_loss = 0.81407148, grad/param norm = 1.8445e-01, time/batch = 18.4821s	
15734/26050 (epoch 30.200), train_loss = 0.80048491, grad/param norm = 1.8927e-01, time/batch = 17.2454s	
15735/26050 (epoch 30.202), train_loss = 0.90630400, grad/param norm = 1.7870e-01, time/batch = 16.4514s	
15736/26050 (epoch 30.203), train_loss = 0.99237586, grad/param norm = 1.9435e-01, time/batch = 17.5673s	
15737/26050 (epoch 30.205), train_loss = 0.84870989, grad/param norm = 2.0208e-01, time/batch = 18.4101s	
15738/26050 (epoch 30.207), train_loss = 0.82405026, grad/param norm = 2.1561e-01, time/batch = 18.5763s	
15739/26050 (epoch 30.209), train_loss = 0.94368896, grad/param norm = 1.9042e-01, time/batch = 17.9841s	
15740/26050 (epoch 30.211), train_loss = 0.75790756, grad/param norm = 1.8712e-01, time/batch = 18.2245s	
15741/26050 (epoch 30.213), train_loss = 0.91844821, grad/param norm = 2.3321e-01, time/batch = 18.6415s	
15742/26050 (epoch 30.215), train_loss = 0.86401202, grad/param norm = 2.1381e-01, time/batch = 16.6667s	
15743/26050 (epoch 30.217), train_loss = 0.84104871, grad/param norm = 1.8106e-01, time/batch = 17.6500s	
15744/26050 (epoch 30.219), train_loss = 0.85484673, grad/param norm = 2.1306e-01, time/batch = 17.9891s	
15745/26050 (epoch 30.221), train_loss = 0.79765212, grad/param norm = 1.8957e-01, time/batch = 17.9831s	
15746/26050 (epoch 30.223), train_loss = 0.97341197, grad/param norm = 2.2218e-01, time/batch = 18.4103s	
15747/26050 (epoch 30.225), train_loss = 0.82221249, grad/param norm = 2.1579e-01, time/batch = 17.9800s	
15748/26050 (epoch 30.226), train_loss = 0.92782732, grad/param norm = 2.1872e-01, time/batch = 15.7030s	
15749/26050 (epoch 30.228), train_loss = 1.02753856, grad/param norm = 2.0278e-01, time/batch = 16.8076s	
15750/26050 (epoch 30.230), train_loss = 0.90002587, grad/param norm = 2.0715e-01, time/batch = 14.3150s	
15751/26050 (epoch 30.232), train_loss = 0.97073313, grad/param norm = 2.3039e-01, time/batch = 18.3065s	
15752/26050 (epoch 30.234), train_loss = 0.79974345, grad/param norm = 1.9203e-01, time/batch = 17.6695s	
15753/26050 (epoch 30.236), train_loss = 0.96838026, grad/param norm = 1.9768e-01, time/batch = 17.8278s	
15754/26050 (epoch 30.238), train_loss = 0.76182566, grad/param norm = 1.9636e-01, time/batch = 18.1603s	
15755/26050 (epoch 30.240), train_loss = 0.89767846, grad/param norm = 1.9682e-01, time/batch = 18.6485s	
15756/26050 (epoch 30.242), train_loss = 0.86760203, grad/param norm = 2.0194e-01, time/batch = 17.5567s	
15757/26050 (epoch 30.244), train_loss = 0.92697771, grad/param norm = 2.3002e-01, time/batch = 14.8975s	
15758/26050 (epoch 30.246), train_loss = 0.83798773, grad/param norm = 1.8780e-01, time/batch = 18.3144s	
15759/26050 (epoch 30.248), train_loss = 0.89824408, grad/param norm = 2.0950e-01, time/batch = 17.7358s	
15760/26050 (epoch 30.250), train_loss = 0.89259938, grad/param norm = 2.2468e-01, time/batch = 15.1258s	
15761/26050 (epoch 30.251), train_loss = 0.84697852, grad/param norm = 2.0170e-01, time/batch = 18.8021s	
15762/26050 (epoch 30.253), train_loss = 0.79699527, grad/param norm = 1.9721e-01, time/batch = 17.7370s	
15763/26050 (epoch 30.255), train_loss = 1.05927445, grad/param norm = 2.1038e-01, time/batch = 18.0539s	
15764/26050 (epoch 30.257), train_loss = 0.88058156, grad/param norm = 2.3143e-01, time/batch = 18.8829s	
15765/26050 (epoch 30.259), train_loss = 0.97755390, grad/param norm = 2.0160e-01, time/batch = 19.1291s	
15766/26050 (epoch 30.261), train_loss = 0.79127290, grad/param norm = 2.0070e-01, time/batch = 17.1464s	
15767/26050 (epoch 30.263), train_loss = 0.98874128, grad/param norm = 2.2246e-01, time/batch = 18.3252s	
15768/26050 (epoch 30.265), train_loss = 1.03497521, grad/param norm = 2.2492e-01, time/batch = 18.3152s	
15769/26050 (epoch 30.267), train_loss = 1.01095364, grad/param norm = 1.8928e-01, time/batch = 16.2922s	
15770/26050 (epoch 30.269), train_loss = 1.00922456, grad/param norm = 2.4086e-01, time/batch = 18.7417s	
15771/26050 (epoch 30.271), train_loss = 0.93966976, grad/param norm = 2.2602e-01, time/batch = 15.3813s	
15772/26050 (epoch 30.273), train_loss = 0.83032076, grad/param norm = 2.0826e-01, time/batch = 18.9727s	
15773/26050 (epoch 30.274), train_loss = 0.86492743, grad/param norm = 1.7355e-01, time/batch = 18.0487s	
15774/26050 (epoch 30.276), train_loss = 0.86125449, grad/param norm = 2.0003e-01, time/batch = 18.1637s	
15775/26050 (epoch 30.278), train_loss = 0.98521067, grad/param norm = 1.9795e-01, time/batch = 14.8953s	
15776/26050 (epoch 30.280), train_loss = 0.89686167, grad/param norm = 1.8558e-01, time/batch = 17.3978s	
15777/26050 (epoch 30.282), train_loss = 0.94683439, grad/param norm = 1.8987e-01, time/batch = 17.3995s	
15778/26050 (epoch 30.284), train_loss = 0.88126949, grad/param norm = 1.9809e-01, time/batch = 18.2230s	
15779/26050 (epoch 30.286), train_loss = 0.93056301, grad/param norm = 2.2387e-01, time/batch = 18.4051s	
15780/26050 (epoch 30.288), train_loss = 0.77059403, grad/param norm = 1.7266e-01, time/batch = 18.5647s	
15781/26050 (epoch 30.290), train_loss = 0.90666491, grad/param norm = 2.0302e-01, time/batch = 18.7355s	
15782/26050 (epoch 30.292), train_loss = 0.83963040, grad/param norm = 2.0069e-01, time/batch = 17.9852s	
15783/26050 (epoch 30.294), train_loss = 0.90370320, grad/param norm = 2.1189e-01, time/batch = 17.6377s	
15784/26050 (epoch 30.296), train_loss = 0.97533340, grad/param norm = 1.9098e-01, time/batch = 18.4047s	
15785/26050 (epoch 30.298), train_loss = 0.91782555, grad/param norm = 1.8757e-01, time/batch = 18.1514s	
15786/26050 (epoch 30.299), train_loss = 0.73868623, grad/param norm = 1.7035e-01, time/batch = 17.7209s	
15787/26050 (epoch 30.301), train_loss = 0.76993779, grad/param norm = 1.9280e-01, time/batch = 18.6529s	
15788/26050 (epoch 30.303), train_loss = 0.89773829, grad/param norm = 2.0505e-01, time/batch = 18.4885s	
15789/26050 (epoch 30.305), train_loss = 0.71728730, grad/param norm = 1.8668e-01, time/batch = 16.2935s	
15790/26050 (epoch 30.307), train_loss = 0.81303638, grad/param norm = 2.0017e-01, time/batch = 18.7329s	
15791/26050 (epoch 30.309), train_loss = 0.88920866, grad/param norm = 1.9603e-01, time/batch = 17.9812s	
15792/26050 (epoch 30.311), train_loss = 0.93126431, grad/param norm = 2.1840e-01, time/batch = 17.8001s	
15793/26050 (epoch 30.313), train_loss = 0.87712288, grad/param norm = 2.0298e-01, time/batch = 17.3860s	
15794/26050 (epoch 30.315), train_loss = 0.97269133, grad/param norm = 1.9646e-01, time/batch = 15.1214s	
15795/26050 (epoch 30.317), train_loss = 0.93472059, grad/param norm = 2.3624e-01, time/batch = 17.8882s	
15796/26050 (epoch 30.319), train_loss = 0.81385635, grad/param norm = 2.0154e-01, time/batch = 17.8123s	
15797/26050 (epoch 30.321), train_loss = 0.87066783, grad/param norm = 2.1006e-01, time/batch = 18.0711s	
15798/26050 (epoch 30.322), train_loss = 0.94106981, grad/param norm = 1.9439e-01, time/batch = 18.2214s	
15799/26050 (epoch 30.324), train_loss = 0.71070120, grad/param norm = 1.7468e-01, time/batch = 17.8198s	
15800/26050 (epoch 30.326), train_loss = 1.01346090, grad/param norm = 2.0452e-01, time/batch = 18.2181s	
15801/26050 (epoch 30.328), train_loss = 0.91019504, grad/param norm = 1.7353e-01, time/batch = 18.6626s	
15802/26050 (epoch 30.330), train_loss = 0.77608589, grad/param norm = 1.9182e-01, time/batch = 18.9916s	
15803/26050 (epoch 30.332), train_loss = 0.95499542, grad/param norm = 1.9637e-01, time/batch = 17.3042s	
15804/26050 (epoch 30.334), train_loss = 0.80493587, grad/param norm = 1.7854e-01, time/batch = 17.5561s	
15805/26050 (epoch 30.336), train_loss = 0.83337998, grad/param norm = 1.9450e-01, time/batch = 15.8495s	
15806/26050 (epoch 30.338), train_loss = 0.77999696, grad/param norm = 1.8412e-01, time/batch = 17.3790s	
15807/26050 (epoch 30.340), train_loss = 0.94637347, grad/param norm = 1.9745e-01, time/batch = 18.1453s	
15808/26050 (epoch 30.342), train_loss = 0.98079372, grad/param norm = 2.0769e-01, time/batch = 18.1313s	
15809/26050 (epoch 30.344), train_loss = 0.81230169, grad/param norm = 2.0607e-01, time/batch = 17.7398s	
15810/26050 (epoch 30.345), train_loss = 0.88722931, grad/param norm = 2.1100e-01, time/batch = 15.8685s	
15811/26050 (epoch 30.347), train_loss = 1.02405537, grad/param norm = 2.0649e-01, time/batch = 18.6293s	
15812/26050 (epoch 30.349), train_loss = 0.93738707, grad/param norm = 2.0822e-01, time/batch = 16.9465s	
15813/26050 (epoch 30.351), train_loss = 0.92961926, grad/param norm = 2.3106e-01, time/batch = 17.8920s	
15814/26050 (epoch 30.353), train_loss = 0.90419734, grad/param norm = 2.0715e-01, time/batch = 17.7369s	
15815/26050 (epoch 30.355), train_loss = 0.90743985, grad/param norm = 2.2663e-01, time/batch = 18.8968s	
15816/26050 (epoch 30.357), train_loss = 0.84307144, grad/param norm = 1.7559e-01, time/batch = 17.8826s	
15817/26050 (epoch 30.359), train_loss = 0.97436753, grad/param norm = 2.1257e-01, time/batch = 17.8154s	
15818/26050 (epoch 30.361), train_loss = 0.79787003, grad/param norm = 1.6431e-01, time/batch = 15.4757s	
15819/26050 (epoch 30.363), train_loss = 0.97446374, grad/param norm = 2.0204e-01, time/batch = 18.8103s	
15820/26050 (epoch 30.365), train_loss = 0.85463633, grad/param norm = 1.8717e-01, time/batch = 15.4804s	
15821/26050 (epoch 30.367), train_loss = 0.96311147, grad/param norm = 2.1128e-01, time/batch = 17.8999s	
15822/26050 (epoch 30.369), train_loss = 0.80252712, grad/param norm = 1.7046e-01, time/batch = 18.5705s	
15823/26050 (epoch 30.370), train_loss = 0.80142719, grad/param norm = 1.6874e-01, time/batch = 17.9789s	
15824/26050 (epoch 30.372), train_loss = 0.91280221, grad/param norm = 2.1540e-01, time/batch = 17.6615s	
15825/26050 (epoch 30.374), train_loss = 1.03466776, grad/param norm = 2.1382e-01, time/batch = 17.6527s	
15826/26050 (epoch 30.376), train_loss = 1.05343925, grad/param norm = 2.2223e-01, time/batch = 15.7102s	
15827/26050 (epoch 30.378), train_loss = 0.84570743, grad/param norm = 1.8872e-01, time/batch = 17.4632s	
15828/26050 (epoch 30.380), train_loss = 1.04519134, grad/param norm = 2.2961e-01, time/batch = 18.4000s	
15829/26050 (epoch 30.382), train_loss = 1.14083907, grad/param norm = 2.5809e-01, time/batch = 16.7369s	
15830/26050 (epoch 30.384), train_loss = 0.85547566, grad/param norm = 2.2252e-01, time/batch = 17.4632s	
15831/26050 (epoch 30.386), train_loss = 0.97009035, grad/param norm = 3.0714e-01, time/batch = 17.6197s	
15832/26050 (epoch 30.388), train_loss = 0.94602469, grad/param norm = 2.3575e-01, time/batch = 18.8321s	
15833/26050 (epoch 30.390), train_loss = 0.85136364, grad/param norm = 1.9127e-01, time/batch = 17.9007s	
15834/26050 (epoch 30.392), train_loss = 0.80368478, grad/param norm = 1.7831e-01, time/batch = 14.8968s	
15835/26050 (epoch 30.393), train_loss = 0.93466639, grad/param norm = 2.3478e-01, time/batch = 17.6646s	
15836/26050 (epoch 30.395), train_loss = 0.96473178, grad/param norm = 2.1722e-01, time/batch = 17.9134s	
15837/26050 (epoch 30.397), train_loss = 0.98022626, grad/param norm = 2.3617e-01, time/batch = 17.8962s	
15838/26050 (epoch 30.399), train_loss = 0.85582845, grad/param norm = 1.9584e-01, time/batch = 18.5723s	
15839/26050 (epoch 30.401), train_loss = 0.90744103, grad/param norm = 1.8845e-01, time/batch = 15.0619s	
15840/26050 (epoch 30.403), train_loss = 0.92851108, grad/param norm = 2.2385e-01, time/batch = 17.5641s	
15841/26050 (epoch 30.405), train_loss = 0.92327650, grad/param norm = 2.2534e-01, time/batch = 18.0735s	
15842/26050 (epoch 30.407), train_loss = 1.05276537, grad/param norm = 2.2564e-01, time/batch = 18.3217s	
15843/26050 (epoch 30.409), train_loss = 1.04751537, grad/param norm = 2.4233e-01, time/batch = 18.3858s	
15844/26050 (epoch 30.411), train_loss = 0.97492304, grad/param norm = 2.3604e-01, time/batch = 17.0343s	
15845/26050 (epoch 30.413), train_loss = 1.07742299, grad/param norm = 2.0901e-01, time/batch = 16.5359s	
15846/26050 (epoch 30.415), train_loss = 1.08188853, grad/param norm = 2.4879e-01, time/batch = 18.4104s	
15847/26050 (epoch 30.417), train_loss = 1.10289450, grad/param norm = 2.2940e-01, time/batch = 16.8297s	
15848/26050 (epoch 30.418), train_loss = 0.99305078, grad/param norm = 2.2952e-01, time/batch = 16.3269s	
15849/26050 (epoch 30.420), train_loss = 0.79399371, grad/param norm = 1.9356e-01, time/batch = 18.8202s	
15850/26050 (epoch 30.422), train_loss = 0.76702296, grad/param norm = 1.7932e-01, time/batch = 17.9038s	
15851/26050 (epoch 30.424), train_loss = 1.04422145, grad/param norm = 2.3278e-01, time/batch = 16.8874s	
15852/26050 (epoch 30.426), train_loss = 1.00050973, grad/param norm = 2.1698e-01, time/batch = 17.6640s	
15853/26050 (epoch 30.428), train_loss = 0.85500225, grad/param norm = 1.9466e-01, time/batch = 17.4990s	
15854/26050 (epoch 30.430), train_loss = 1.06193368, grad/param norm = 1.9802e-01, time/batch = 16.7968s	
15855/26050 (epoch 30.432), train_loss = 0.88060590, grad/param norm = 1.8977e-01, time/batch = 17.9043s	
15856/26050 (epoch 30.434), train_loss = 0.87328684, grad/param norm = 1.8792e-01, time/batch = 15.4876s	
15857/26050 (epoch 30.436), train_loss = 1.02263200, grad/param norm = 2.1072e-01, time/batch = 17.3948s	
15858/26050 (epoch 30.438), train_loss = 0.97048333, grad/param norm = 2.2048e-01, time/batch = 18.2334s	
15859/26050 (epoch 30.440), train_loss = 0.94275929, grad/param norm = 2.2214e-01, time/batch = 18.3097s	
15860/26050 (epoch 30.441), train_loss = 0.93635289, grad/param norm = 2.0157e-01, time/batch = 18.7927s	
15861/26050 (epoch 30.443), train_loss = 0.77666092, grad/param norm = 1.5790e-01, time/batch = 17.0563s	
15862/26050 (epoch 30.445), train_loss = 0.82941488, grad/param norm = 1.7705e-01, time/batch = 17.8180s	
15863/26050 (epoch 30.447), train_loss = 1.03126696, grad/param norm = 2.0774e-01, time/batch = 18.5704s	
15864/26050 (epoch 30.449), train_loss = 0.82247248, grad/param norm = 1.8898e-01, time/batch = 17.8276s	
15865/26050 (epoch 30.451), train_loss = 1.05000744, grad/param norm = 2.0797e-01, time/batch = 18.1474s	
15866/26050 (epoch 30.453), train_loss = 0.83926294, grad/param norm = 1.6356e-01, time/batch = 15.3832s	
15867/26050 (epoch 30.455), train_loss = 0.92087449, grad/param norm = 1.8774e-01, time/batch = 14.1506s	
15868/26050 (epoch 30.457), train_loss = 0.91038228, grad/param norm = 2.0592e-01, time/batch = 16.8832s	
15869/26050 (epoch 30.459), train_loss = 1.02649590, grad/param norm = 2.3275e-01, time/batch = 17.9890s	
15870/26050 (epoch 30.461), train_loss = 1.01350927, grad/param norm = 2.1038e-01, time/batch = 18.3174s	
15871/26050 (epoch 30.463), train_loss = 0.87288311, grad/param norm = 1.6856e-01, time/batch = 17.7378s	
15872/26050 (epoch 30.464), train_loss = 0.95132402, grad/param norm = 2.0021e-01, time/batch = 18.3226s	
15873/26050 (epoch 30.466), train_loss = 0.94568545, grad/param norm = 2.1253e-01, time/batch = 18.1637s	
15874/26050 (epoch 30.468), train_loss = 1.00813659, grad/param norm = 1.8185e-01, time/batch = 18.2337s	
15875/26050 (epoch 30.470), train_loss = 1.02900106, grad/param norm = 2.3746e-01, time/batch = 17.6560s	
15876/26050 (epoch 30.472), train_loss = 1.03618670, grad/param norm = 2.5131e-01, time/batch = 15.0667s	
15877/26050 (epoch 30.474), train_loss = 1.02405948, grad/param norm = 2.1805e-01, time/batch = 17.7445s	
15878/26050 (epoch 30.476), train_loss = 1.02849027, grad/param norm = 1.9354e-01, time/batch = 16.0392s	
15879/26050 (epoch 30.478), train_loss = 0.88487050, grad/param norm = 1.8636e-01, time/batch = 18.2924s	
15880/26050 (epoch 30.480), train_loss = 0.89608642, grad/param norm = 1.8318e-01, time/batch = 18.7389s	
15881/26050 (epoch 30.482), train_loss = 0.86497916, grad/param norm = 2.0712e-01, time/batch = 17.8242s	
15882/26050 (epoch 30.484), train_loss = 0.85222176, grad/param norm = 1.9481e-01, time/batch = 18.7324s	
15883/26050 (epoch 30.486), train_loss = 1.04612280, grad/param norm = 1.9321e-01, time/batch = 17.7516s	
15884/26050 (epoch 30.488), train_loss = 1.07491912, grad/param norm = 2.0831e-01, time/batch = 17.8293s	
15885/26050 (epoch 30.489), train_loss = 1.08448212, grad/param norm = 2.3028e-01, time/batch = 18.3180s	
15886/26050 (epoch 30.491), train_loss = 0.83976394, grad/param norm = 2.1171e-01, time/batch = 16.5626s	
15887/26050 (epoch 30.493), train_loss = 0.93803009, grad/param norm = 1.9977e-01, time/batch = 17.4843s	
15888/26050 (epoch 30.495), train_loss = 0.90127231, grad/param norm = 1.7502e-01, time/batch = 17.6447s	
15889/26050 (epoch 30.497), train_loss = 0.81601339, grad/param norm = 1.9468e-01, time/batch = 18.2469s	
15890/26050 (epoch 30.499), train_loss = 0.87072239, grad/param norm = 2.0792e-01, time/batch = 16.6490s	
15891/26050 (epoch 30.501), train_loss = 0.99609891, grad/param norm = 2.0300e-01, time/batch = 16.4741s	
15892/26050 (epoch 30.503), train_loss = 0.85104371, grad/param norm = 1.8710e-01, time/batch = 17.8095s	
15893/26050 (epoch 30.505), train_loss = 1.03619757, grad/param norm = 2.0679e-01, time/batch = 18.6546s	
15894/26050 (epoch 30.507), train_loss = 0.97994407, grad/param norm = 2.2719e-01, time/batch = 18.8976s	
15895/26050 (epoch 30.509), train_loss = 1.06142777, grad/param norm = 1.8464e-01, time/batch = 26.9296s	
15896/26050 (epoch 30.511), train_loss = 0.88086361, grad/param norm = 1.7244e-01, time/batch = 30.5574s	
15897/26050 (epoch 30.512), train_loss = 0.80536701, grad/param norm = 2.1962e-01, time/batch = 16.8606s	
15898/26050 (epoch 30.514), train_loss = 0.96755740, grad/param norm = 2.1614e-01, time/batch = 18.1683s	
15899/26050 (epoch 30.516), train_loss = 1.05218633, grad/param norm = 2.1268e-01, time/batch = 14.5549s	
15900/26050 (epoch 30.518), train_loss = 0.90129155, grad/param norm = 2.0385e-01, time/batch = 17.5690s	
15901/26050 (epoch 30.520), train_loss = 0.91860304, grad/param norm = 2.0064e-01, time/batch = 18.8923s	
15902/26050 (epoch 30.522), train_loss = 0.72878922, grad/param norm = 1.7408e-01, time/batch = 17.6611s	
15903/26050 (epoch 30.524), train_loss = 1.01410964, grad/param norm = 2.4731e-01, time/batch = 18.4941s	
15904/26050 (epoch 30.526), train_loss = 1.03235122, grad/param norm = 2.9174e-01, time/batch = 17.7985s	
15905/26050 (epoch 30.528), train_loss = 0.97634115, grad/param norm = 2.5874e-01, time/batch = 16.9662s	
15906/26050 (epoch 30.530), train_loss = 0.86920795, grad/param norm = 2.2578e-01, time/batch = 16.7940s	
15907/26050 (epoch 30.532), train_loss = 0.96613728, grad/param norm = 2.3590e-01, time/batch = 17.4863s	
15908/26050 (epoch 30.534), train_loss = 0.98714560, grad/param norm = 2.6065e-01, time/batch = 17.8996s	
15909/26050 (epoch 30.536), train_loss = 0.93761751, grad/param norm = 2.0128e-01, time/batch = 18.8117s	
15910/26050 (epoch 30.537), train_loss = 0.99984881, grad/param norm = 2.1640e-01, time/batch = 17.6432s	
15911/26050 (epoch 30.539), train_loss = 0.91693405, grad/param norm = 2.0323e-01, time/batch = 17.3935s	
15912/26050 (epoch 30.541), train_loss = 1.09409645, grad/param norm = 2.2318e-01, time/batch = 16.1349s	
15913/26050 (epoch 30.543), train_loss = 0.76209315, grad/param norm = 1.9948e-01, time/batch = 18.4686s	
15914/26050 (epoch 30.545), train_loss = 0.92553859, grad/param norm = 1.9615e-01, time/batch = 17.5543s	
15915/26050 (epoch 30.547), train_loss = 0.89016243, grad/param norm = 2.0025e-01, time/batch = 18.4037s	
15916/26050 (epoch 30.549), train_loss = 0.78386862, grad/param norm = 2.1198e-01, time/batch = 18.9894s	
15917/26050 (epoch 30.551), train_loss = 0.98244026, grad/param norm = 2.0776e-01, time/batch = 16.5487s	
15918/26050 (epoch 30.553), train_loss = 0.87876223, grad/param norm = 1.9963e-01, time/batch = 17.6667s	
15919/26050 (epoch 30.555), train_loss = 0.82188426, grad/param norm = 2.1074e-01, time/batch = 17.8061s	
15920/26050 (epoch 30.557), train_loss = 0.94451163, grad/param norm = 1.9004e-01, time/batch = 16.3679s	
15921/26050 (epoch 30.559), train_loss = 0.94378334, grad/param norm = 1.9745e-01, time/batch = 18.4630s	
15922/26050 (epoch 30.560), train_loss = 0.88412069, grad/param norm = 2.2819e-01, time/batch = 17.7383s	
15923/26050 (epoch 30.562), train_loss = 0.90979707, grad/param norm = 2.3705e-01, time/batch = 18.6606s	
15924/26050 (epoch 30.564), train_loss = 1.09226071, grad/param norm = 2.1805e-01, time/batch = 14.7824s	
15925/26050 (epoch 30.566), train_loss = 0.85427768, grad/param norm = 2.0049e-01, time/batch = 18.4777s	
15926/26050 (epoch 30.568), train_loss = 0.96610158, grad/param norm = 2.0683e-01, time/batch = 17.1546s	
15927/26050 (epoch 30.570), train_loss = 0.93980714, grad/param norm = 2.1191e-01, time/batch = 17.9845s	
15928/26050 (epoch 30.572), train_loss = 0.92936165, grad/param norm = 2.1743e-01, time/batch = 17.2209s	
15929/26050 (epoch 30.574), train_loss = 0.93431159, grad/param norm = 2.3617e-01, time/batch = 17.5612s	
15930/26050 (epoch 30.576), train_loss = 0.96687093, grad/param norm = 2.1198e-01, time/batch = 18.4820s	
15931/26050 (epoch 30.578), train_loss = 0.90587639, grad/param norm = 1.9924e-01, time/batch = 17.4880s	
15932/26050 (epoch 30.580), train_loss = 0.84442368, grad/param norm = 1.9881e-01, time/batch = 18.5668s	
15933/26050 (epoch 30.582), train_loss = 0.93329448, grad/param norm = 1.8773e-01, time/batch = 17.8301s	
15934/26050 (epoch 30.583), train_loss = 1.00031317, grad/param norm = 1.9403e-01, time/batch = 15.5517s	
15935/26050 (epoch 30.585), train_loss = 0.82578675, grad/param norm = 2.0433e-01, time/batch = 18.3148s	
15936/26050 (epoch 30.587), train_loss = 0.93926036, grad/param norm = 1.9985e-01, time/batch = 14.8833s	
15937/26050 (epoch 30.589), train_loss = 1.06842152, grad/param norm = 2.2379e-01, time/batch = 17.6120s	
15938/26050 (epoch 30.591), train_loss = 0.91888841, grad/param norm = 2.2156e-01, time/batch = 18.2212s	
15939/26050 (epoch 30.593), train_loss = 0.80554143, grad/param norm = 1.7952e-01, time/batch = 14.7082s	
15940/26050 (epoch 30.595), train_loss = 0.99687843, grad/param norm = 2.1011e-01, time/batch = 18.8100s	
15941/26050 (epoch 30.597), train_loss = 0.93209064, grad/param norm = 2.1216e-01, time/batch = 18.1404s	
15942/26050 (epoch 30.599), train_loss = 0.95648489, grad/param norm = 1.9915e-01, time/batch = 18.3099s	
15943/26050 (epoch 30.601), train_loss = 1.08275965, grad/param norm = 2.0060e-01, time/batch = 18.2356s	
15944/26050 (epoch 30.603), train_loss = 0.96450752, grad/param norm = 2.0913e-01, time/batch = 16.2264s	
15945/26050 (epoch 30.605), train_loss = 0.89036842, grad/param norm = 2.0712e-01, time/batch = 17.8811s	
15946/26050 (epoch 30.607), train_loss = 1.01811152, grad/param norm = 2.5907e-01, time/batch = 18.5727s	
15947/26050 (epoch 30.608), train_loss = 0.83827244, grad/param norm = 1.8645e-01, time/batch = 18.7271s	
15948/26050 (epoch 30.610), train_loss = 0.93226566, grad/param norm = 2.1073e-01, time/batch = 17.6574s	
15949/26050 (epoch 30.612), train_loss = 0.91283821, grad/param norm = 2.1576e-01, time/batch = 17.7419s	
15950/26050 (epoch 30.614), train_loss = 0.93845497, grad/param norm = 2.0541e-01, time/batch = 18.8188s	
15951/26050 (epoch 30.616), train_loss = 1.01374983, grad/param norm = 2.3072e-01, time/batch = 18.3068s	
15952/26050 (epoch 30.618), train_loss = 0.90039943, grad/param norm = 2.2834e-01, time/batch = 17.0653s	
15953/26050 (epoch 30.620), train_loss = 0.97018787, grad/param norm = 2.1444e-01, time/batch = 16.4528s	
15954/26050 (epoch 30.622), train_loss = 0.82523559, grad/param norm = 1.7886e-01, time/batch = 18.3267s	
15955/26050 (epoch 30.624), train_loss = 0.79322237, grad/param norm = 1.9016e-01, time/batch = 18.3129s	
15956/26050 (epoch 30.626), train_loss = 0.97390386, grad/param norm = 1.8885e-01, time/batch = 16.8714s	
15957/26050 (epoch 30.628), train_loss = 0.87469557, grad/param norm = 2.4640e-01, time/batch = 18.7430s	
15958/26050 (epoch 30.630), train_loss = 1.06124425, grad/param norm = 1.8807e-01, time/batch = 16.2013s	
15959/26050 (epoch 30.631), train_loss = 1.06824408, grad/param norm = 2.1981e-01, time/batch = 18.4659s	
15960/26050 (epoch 30.633), train_loss = 0.86096043, grad/param norm = 2.1854e-01, time/batch = 18.6603s	
15961/26050 (epoch 30.635), train_loss = 0.87824244, grad/param norm = 1.8205e-01, time/batch = 16.8807s	
15962/26050 (epoch 30.637), train_loss = 0.81282216, grad/param norm = 1.9429e-01, time/batch = 17.8991s	
15963/26050 (epoch 30.639), train_loss = 0.98463743, grad/param norm = 1.9646e-01, time/batch = 17.9086s	
15964/26050 (epoch 30.641), train_loss = 0.87852012, grad/param norm = 1.8991e-01, time/batch = 18.0024s	
15965/26050 (epoch 30.643), train_loss = 0.82849073, grad/param norm = 1.5609e-01, time/batch = 15.9522s	
15966/26050 (epoch 30.645), train_loss = 0.86389489, grad/param norm = 1.9962e-01, time/batch = 15.5657s	
15967/26050 (epoch 30.647), train_loss = 0.85943218, grad/param norm = 2.1744e-01, time/batch = 18.7291s	
15968/26050 (epoch 30.649), train_loss = 0.89276055, grad/param norm = 1.8654e-01, time/batch = 17.3175s	
15969/26050 (epoch 30.651), train_loss = 0.86694803, grad/param norm = 1.9261e-01, time/batch = 18.2482s	
15970/26050 (epoch 30.653), train_loss = 0.91209315, grad/param norm = 2.2106e-01, time/batch = 16.2312s	
15971/26050 (epoch 30.655), train_loss = 0.85139063, grad/param norm = 2.1152e-01, time/batch = 18.3346s	
15972/26050 (epoch 30.656), train_loss = 0.80609679, grad/param norm = 1.7014e-01, time/batch = 18.1486s	
15973/26050 (epoch 30.658), train_loss = 1.10505019, grad/param norm = 2.1378e-01, time/batch = 17.9223s	
15974/26050 (epoch 30.660), train_loss = 0.78825148, grad/param norm = 2.1174e-01, time/batch = 18.3317s	
15975/26050 (epoch 30.662), train_loss = 0.89600420, grad/param norm = 2.0493e-01, time/batch = 16.9060s	
15976/26050 (epoch 30.664), train_loss = 0.89908875, grad/param norm = 1.9768e-01, time/batch = 17.4839s	
15977/26050 (epoch 30.666), train_loss = 0.84502955, grad/param norm = 1.8378e-01, time/batch = 17.8058s	
15978/26050 (epoch 30.668), train_loss = 0.72251199, grad/param norm = 2.0189e-01, time/batch = 17.6544s	
15979/26050 (epoch 30.670), train_loss = 1.03932337, grad/param norm = 2.4167e-01, time/batch = 17.4876s	
15980/26050 (epoch 30.672), train_loss = 0.91000439, grad/param norm = 1.9370e-01, time/batch = 17.0529s	
15981/26050 (epoch 30.674), train_loss = 0.81645002, grad/param norm = 2.0907e-01, time/batch = 18.7978s	
15982/26050 (epoch 30.676), train_loss = 0.97120615, grad/param norm = 2.1694e-01, time/batch = 18.9689s	
15983/26050 (epoch 30.678), train_loss = 1.00210354, grad/param norm = 2.1740e-01, time/batch = 17.9900s	
15984/26050 (epoch 30.679), train_loss = 1.04807840, grad/param norm = 2.1846e-01, time/batch = 17.5687s	
15985/26050 (epoch 30.681), train_loss = 0.94929560, grad/param norm = 2.1354e-01, time/batch = 16.1252s	
15986/26050 (epoch 30.683), train_loss = 0.82135598, grad/param norm = 3.2155e-01, time/batch = 18.3929s	
15987/26050 (epoch 30.685), train_loss = 0.89083885, grad/param norm = 1.8775e-01, time/batch = 17.9964s	
15988/26050 (epoch 30.687), train_loss = 0.81195907, grad/param norm = 1.9786e-01, time/batch = 18.3097s	
15989/26050 (epoch 30.689), train_loss = 0.87188492, grad/param norm = 2.0511e-01, time/batch = 18.4667s	
15990/26050 (epoch 30.691), train_loss = 0.73458052, grad/param norm = 1.5523e-01, time/batch = 16.3833s	
15991/26050 (epoch 30.693), train_loss = 0.87341415, grad/param norm = 2.0335e-01, time/batch = 18.9122s	
15992/26050 (epoch 30.695), train_loss = 0.89342395, grad/param norm = 1.8476e-01, time/batch = 18.2249s	
15993/26050 (epoch 30.697), train_loss = 0.84287584, grad/param norm = 2.0031e-01, time/batch = 18.3213s	
15994/26050 (epoch 30.699), train_loss = 0.96078495, grad/param norm = 2.2533e-01, time/batch = 17.9914s	
15995/26050 (epoch 30.701), train_loss = 0.81770463, grad/param norm = 1.7762e-01, time/batch = 17.2352s	
15996/26050 (epoch 30.702), train_loss = 0.98511106, grad/param norm = 2.1271e-01, time/batch = 18.4862s	
15997/26050 (epoch 30.704), train_loss = 0.99427364, grad/param norm = 1.9791e-01, time/batch = 18.1552s	
15998/26050 (epoch 30.706), train_loss = 0.85243951, grad/param norm = 2.1262e-01, time/batch = 16.8960s	
15999/26050 (epoch 30.708), train_loss = 0.99111223, grad/param norm = 2.1777e-01, time/batch = 17.0505s	
evaluating loss over split index 2	
1/28...	
2/28...	
3/28...	
4/28...	
5/28...	
6/28...	
7/28...	
8/28...	
9/28...	
10/28...	
11/28...	
12/28...	
13/28...	
14/28...	
15/28...	
16/28...	
17/28...	
18/28...	
19/28...	
20/28...	
21/28...	
22/28...	
23/28...	
24/28...	
25/28...	
26/28...	
27/28...	
28/28...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_nasahubble_epoch30.71_1.8289.t7	
16000/26050 (epoch 30.710), train_loss = 0.92856126, grad/param norm = 2.6184e-01, time/batch = 18.7426s	
16001/26050 (epoch 30.712), train_loss = 1.41547349, grad/param norm = 2.7264e-01, time/batch = 16.9616s	
16002/26050 (epoch 30.714), train_loss = 0.81304027, grad/param norm = 1.7710e-01, time/batch = 15.0544s	
16003/26050 (epoch 30.716), train_loss = 1.14714749, grad/param norm = 2.4170e-01, time/batch = 18.4945s	
16004/26050 (epoch 30.718), train_loss = 0.96739466, grad/param norm = 2.1555e-01, time/batch = 18.0778s	
16005/26050 (epoch 30.720), train_loss = 0.91060877, grad/param norm = 2.0389e-01, time/batch = 18.9739s	
16006/26050 (epoch 30.722), train_loss = 0.82276652, grad/param norm = 2.3114e-01, time/batch = 16.5438s	
16007/26050 (epoch 30.724), train_loss = 0.86296467, grad/param norm = 2.0313e-01, time/batch = 17.9845s	
16008/26050 (epoch 30.726), train_loss = 0.98283891, grad/param norm = 2.0940e-01, time/batch = 18.8316s	
16009/26050 (epoch 30.727), train_loss = 0.97206135, grad/param norm = 2.1919e-01, time/batch = 17.6493s	
16010/26050 (epoch 30.729), train_loss = 0.96847951, grad/param norm = 2.0925e-01, time/batch = 18.3899s	
16011/26050 (epoch 30.731), train_loss = 0.96451025, grad/param norm = 2.0889e-01, time/batch = 18.5006s	
16012/26050 (epoch 30.733), train_loss = 0.88905851, grad/param norm = 2.2370e-01, time/batch = 18.1609s	
16013/26050 (epoch 30.735), train_loss = 1.09569548, grad/param norm = 2.4242e-01, time/batch = 17.8933s	
16014/26050 (epoch 30.737), train_loss = 0.87228485, grad/param norm = 2.1632e-01, time/batch = 17.1681s	
16015/26050 (epoch 30.739), train_loss = 0.94123291, grad/param norm = 1.8384e-01, time/batch = 18.4077s	
16016/26050 (epoch 30.741), train_loss = 0.84580482, grad/param norm = 1.8586e-01, time/batch = 17.9554s	
16017/26050 (epoch 30.743), train_loss = 0.93652620, grad/param norm = 2.6094e-01, time/batch = 17.2242s	
16018/26050 (epoch 30.745), train_loss = 0.79763461, grad/param norm = 1.9095e-01, time/batch = 17.7424s	
16019/26050 (epoch 30.747), train_loss = 0.84485165, grad/param norm = 2.0230e-01, time/batch = 15.3074s	
16020/26050 (epoch 30.749), train_loss = 1.01971229, grad/param norm = 2.1804e-01, time/batch = 17.9787s	
16021/26050 (epoch 30.750), train_loss = 0.90004669, grad/param norm = 1.7327e-01, time/batch = 18.4864s	
16022/26050 (epoch 30.752), train_loss = 0.85499892, grad/param norm = 2.0417e-01, time/batch = 17.8097s	
16023/26050 (epoch 30.754), train_loss = 0.91462820, grad/param norm = 1.9929e-01, time/batch = 17.9083s	
16024/26050 (epoch 30.756), train_loss = 0.89615945, grad/param norm = 2.0750e-01, time/batch = 15.5463s	
16025/26050 (epoch 30.758), train_loss = 0.88047461, grad/param norm = 2.1466e-01, time/batch = 15.8034s	
16026/26050 (epoch 30.760), train_loss = 1.05678517, grad/param norm = 2.4172e-01, time/batch = 17.0617s	
16027/26050 (epoch 30.762), train_loss = 0.84916681, grad/param norm = 1.8797e-01, time/batch = 18.4832s	
16028/26050 (epoch 30.764), train_loss = 0.89410854, grad/param norm = 2.5707e-01, time/batch = 18.1497s	
16029/26050 (epoch 30.766), train_loss = 0.94137048, grad/param norm = 2.3634e-01, time/batch = 16.4668s	
16030/26050 (epoch 30.768), train_loss = 0.81588659, grad/param norm = 1.8930e-01, time/batch = 18.2290s	
16031/26050 (epoch 30.770), train_loss = 0.88363876, grad/param norm = 2.0718e-01, time/batch = 17.8922s	
16032/26050 (epoch 30.772), train_loss = 0.89965745, grad/param norm = 1.8668e-01, time/batch = 18.2998s	
16033/26050 (epoch 30.774), train_loss = 0.80271522, grad/param norm = 2.2912e-01, time/batch = 16.2227s	
16034/26050 (epoch 30.775), train_loss = 0.67044361, grad/param norm = 1.9358e-01, time/batch = 17.9976s	
16035/26050 (epoch 30.777), train_loss = 0.87510129, grad/param norm = 1.9593e-01, time/batch = 15.4900s	
16036/26050 (epoch 30.779), train_loss = 0.91835552, grad/param norm = 2.6064e-01, time/batch = 17.8098s	
16037/26050 (epoch 30.781), train_loss = 0.79952939, grad/param norm = 1.9323e-01, time/batch = 17.9872s	
16038/26050 (epoch 30.783), train_loss = 0.79337787, grad/param norm = 1.9636e-01, time/batch = 17.8265s	
16039/26050 (epoch 30.785), train_loss = 0.90565819, grad/param norm = 2.0817e-01, time/batch = 18.5771s	
16040/26050 (epoch 30.787), train_loss = 0.82496836, grad/param norm = 2.0532e-01, time/batch = 17.6227s	
16041/26050 (epoch 30.789), train_loss = 0.83265432, grad/param norm = 2.3346e-01, time/batch = 18.8017s	
16042/26050 (epoch 30.791), train_loss = 0.84094377, grad/param norm = 2.1823e-01, time/batch = 18.9732s	
16043/26050 (epoch 30.793), train_loss = 0.89843746, grad/param norm = 2.2525e-01, time/batch = 16.8019s	
16044/26050 (epoch 30.795), train_loss = 0.73507078, grad/param norm = 1.6202e-01, time/batch = 18.1435s	
16045/26050 (epoch 30.797), train_loss = 0.79756210, grad/param norm = 2.0267e-01, time/batch = 18.1557s	
16046/26050 (epoch 30.798), train_loss = 0.80496875, grad/param norm = 2.0909e-01, time/batch = 14.6051s	
16047/26050 (epoch 30.800), train_loss = 0.79064398, grad/param norm = 1.9048e-01, time/batch = 17.8141s	
16048/26050 (epoch 30.802), train_loss = 0.85083775, grad/param norm = 2.0321e-01, time/batch = 17.9130s	
16049/26050 (epoch 30.804), train_loss = 0.87360289, grad/param norm = 2.0719e-01, time/batch = 17.2169s	
16050/26050 (epoch 30.806), train_loss = 0.96652645, grad/param norm = 2.1408e-01, time/batch = 17.7241s	
16051/26050 (epoch 30.808), train_loss = 0.91000809, grad/param norm = 2.4092e-01, time/batch = 18.5451s	
16052/26050 (epoch 30.810), train_loss = 0.85959311, grad/param norm = 2.0266e-01, time/batch = 18.1554s	
16053/26050 (epoch 30.812), train_loss = 0.75875731, grad/param norm = 1.8109e-01, time/batch = 17.5549s	
16054/26050 (epoch 30.814), train_loss = 0.83169866, grad/param norm = 2.3872e-01, time/batch = 18.3167s	
16055/26050 (epoch 30.816), train_loss = 0.93697094, grad/param norm = 2.2549e-01, time/batch = 17.4863s	
16056/26050 (epoch 30.818), train_loss = 0.98346727, grad/param norm = 2.4081e-01, time/batch = 14.6488s	
16057/26050 (epoch 30.820), train_loss = 0.92689487, grad/param norm = 2.3770e-01, time/batch = 16.6356s	
16058/26050 (epoch 30.821), train_loss = 1.02629243, grad/param norm = 2.3125e-01, time/batch = 18.6351s	
16059/26050 (epoch 30.823), train_loss = 1.07124144, grad/param norm = 2.1052e-01, time/batch = 17.7437s	
16060/26050 (epoch 30.825), train_loss = 0.89766474, grad/param norm = 2.1549e-01, time/batch = 17.2383s	
16061/26050 (epoch 30.827), train_loss = 0.91843131, grad/param norm = 2.2081e-01, time/batch = 18.2412s	
16062/26050 (epoch 30.829), train_loss = 0.97882079, grad/param norm = 2.0485e-01, time/batch = 18.8287s	
16063/26050 (epoch 30.831), train_loss = 1.04230697, grad/param norm = 2.3259e-01, time/batch = 16.8150s	
16064/26050 (epoch 30.833), train_loss = 1.03917219, grad/param norm = 2.2455e-01, time/batch = 15.4548s	
16065/26050 (epoch 30.835), train_loss = 1.05277460, grad/param norm = 2.2769e-01, time/batch = 16.9595s	
16066/26050 (epoch 30.837), train_loss = 0.90825620, grad/param norm = 1.8277e-01, time/batch = 18.5731s	
16067/26050 (epoch 30.839), train_loss = 0.90021363, grad/param norm = 2.3439e-01, time/batch = 17.8131s	
16068/26050 (epoch 30.841), train_loss = 1.00956782, grad/param norm = 2.4235e-01, time/batch = 18.0726s	
16069/26050 (epoch 30.843), train_loss = 0.88918791, grad/param norm = 1.9193e-01, time/batch = 18.7248s	
16070/26050 (epoch 30.845), train_loss = 0.86455250, grad/param norm = 1.8695e-01, time/batch = 17.4738s	
16071/26050 (epoch 30.846), train_loss = 0.95121620, grad/param norm = 2.0738e-01, time/batch = 19.2390s	
16072/26050 (epoch 30.848), train_loss = 0.88901095, grad/param norm = 1.9631e-01, time/batch = 18.1548s	
16073/26050 (epoch 30.850), train_loss = 0.82030396, grad/param norm = 1.8382e-01, time/batch = 17.1511s	
16074/26050 (epoch 30.852), train_loss = 0.91421201, grad/param norm = 1.8773e-01, time/batch = 17.3233s	
16075/26050 (epoch 30.854), train_loss = 0.91685156, grad/param norm = 2.3096e-01, time/batch = 18.0651s	
16076/26050 (epoch 30.856), train_loss = 0.86489437, grad/param norm = 2.1150e-01, time/batch = 16.4586s	
16077/26050 (epoch 30.858), train_loss = 0.83480422, grad/param norm = 1.9465e-01, time/batch = 17.4809s	
16078/26050 (epoch 30.860), train_loss = 0.96568920, grad/param norm = 2.0415e-01, time/batch = 17.5618s	
16079/26050 (epoch 30.862), train_loss = 0.99220435, grad/param norm = 2.0066e-01, time/batch = 18.0643s	
16080/26050 (epoch 30.864), train_loss = 0.94678858, grad/param norm = 2.3712e-01, time/batch = 17.8183s	
16081/26050 (epoch 30.866), train_loss = 0.86192647, grad/param norm = 1.8193e-01, time/batch = 17.3989s	
16082/26050 (epoch 30.868), train_loss = 0.96441426, grad/param norm = 2.4753e-01, time/batch = 16.4856s	
16083/26050 (epoch 30.869), train_loss = 0.82365767, grad/param norm = 1.9301e-01, time/batch = 14.3775s	
16084/26050 (epoch 30.871), train_loss = 0.77660845, grad/param norm = 1.9294e-01, time/batch = 17.6602s	
16085/26050 (epoch 30.873), train_loss = 0.95090048, grad/param norm = 2.2718e-01, time/batch = 17.7350s	
16086/26050 (epoch 30.875), train_loss = 0.88187688, grad/param norm = 2.1633e-01, time/batch = 18.4887s	
16087/26050 (epoch 30.877), train_loss = 0.83641946, grad/param norm = 1.9744e-01, time/batch = 17.3065s	
16088/26050 (epoch 30.879), train_loss = 0.92580303, grad/param norm = 1.7687e-01, time/batch = 16.9683s	
16089/26050 (epoch 30.881), train_loss = 0.99223159, grad/param norm = 2.4399e-01, time/batch = 18.1166s	
16090/26050 (epoch 30.883), train_loss = 0.94401559, grad/param norm = 2.0844e-01, time/batch = 18.1578s	
16091/26050 (epoch 30.885), train_loss = 0.70483974, grad/param norm = 1.8681e-01, time/batch = 30.3574s	
16092/26050 (epoch 30.887), train_loss = 0.97061119, grad/param norm = 1.9647e-01, time/batch = 25.5936s	
16093/26050 (epoch 30.889), train_loss = 0.84387294, grad/param norm = 2.1375e-01, time/batch = 18.1668s	
16094/26050 (epoch 30.891), train_loss = 0.75366709, grad/param norm = 1.7643e-01, time/batch = 18.7414s	
16095/26050 (epoch 30.893), train_loss = 0.78232928, grad/param norm = 1.7627e-01, time/batch = 14.7807s	
16096/26050 (epoch 30.894), train_loss = 0.85926570, grad/param norm = 1.9075e-01, time/batch = 18.0644s	
16097/26050 (epoch 30.896), train_loss = 0.99611763, grad/param norm = 2.2620e-01, time/batch = 18.8820s	
16098/26050 (epoch 30.898), train_loss = 0.85944299, grad/param norm = 2.1027e-01, time/batch = 18.2349s	
16099/26050 (epoch 30.900), train_loss = 0.94195836, grad/param norm = 2.1212e-01, time/batch = 17.5227s	
16100/26050 (epoch 30.902), train_loss = 0.88335994, grad/param norm = 2.0720e-01, time/batch = 17.5578s	
16101/26050 (epoch 30.904), train_loss = 0.87216583, grad/param norm = 1.9406e-01, time/batch = 18.0561s	
16102/26050 (epoch 30.906), train_loss = 0.88565703, grad/param norm = 2.4039e-01, time/batch = 18.7379s	
16103/26050 (epoch 30.908), train_loss = 0.91690896, grad/param norm = 2.0232e-01, time/batch = 16.8806s	
16104/26050 (epoch 30.910), train_loss = 0.87783972, grad/param norm = 2.1111e-01, time/batch = 17.2176s	
16105/26050 (epoch 30.912), train_loss = 1.09217328, grad/param norm = 2.3348e-01, time/batch = 18.4091s	
16106/26050 (epoch 30.914), train_loss = 1.22634167, grad/param norm = 2.2761e-01, time/batch = 17.9848s	
16107/26050 (epoch 30.916), train_loss = 0.99804666, grad/param norm = 2.5245e-01, time/batch = 17.5645s	
16108/26050 (epoch 30.917), train_loss = 0.91281543, grad/param norm = 2.1151e-01, time/batch = 18.2303s	
16109/26050 (epoch 30.919), train_loss = 0.94889692, grad/param norm = 2.1881e-01, time/batch = 18.0672s	
16110/26050 (epoch 30.921), train_loss = 0.85879811, grad/param norm = 2.2217e-01, time/batch = 18.3140s	
16111/26050 (epoch 30.923), train_loss = 0.94189868, grad/param norm = 2.1870e-01, time/batch = 18.6488s	
16112/26050 (epoch 30.925), train_loss = 0.89907885, grad/param norm = 2.0294e-01, time/batch = 16.9627s	
16113/26050 (epoch 30.927), train_loss = 0.82994620, grad/param norm = 1.6582e-01, time/batch = 17.5538s	
16114/26050 (epoch 30.929), train_loss = 0.77214732, grad/param norm = 1.7302e-01, time/batch = 17.8225s	
16115/26050 (epoch 30.931), train_loss = 1.09149446, grad/param norm = 2.4777e-01, time/batch = 15.4811s	
16116/26050 (epoch 30.933), train_loss = 0.88032332, grad/param norm = 2.0306e-01, time/batch = 16.9888s	
16117/26050 (epoch 30.935), train_loss = 0.88120416, grad/param norm = 2.0150e-01, time/batch = 16.3860s	
16118/26050 (epoch 30.937), train_loss = 0.99056520, grad/param norm = 2.0457e-01, time/batch = 15.4873s	
16119/26050 (epoch 30.939), train_loss = 0.82986208, grad/param norm = 1.8266e-01, time/batch = 18.1510s	
16120/26050 (epoch 30.940), train_loss = 0.85259279, grad/param norm = 1.8855e-01, time/batch = 17.5638s	
16121/26050 (epoch 30.942), train_loss = 0.89518073, grad/param norm = 2.1703e-01, time/batch = 18.6476s	
16122/26050 (epoch 30.944), train_loss = 0.86442145, grad/param norm = 1.7624e-01, time/batch = 18.3089s	
16123/26050 (epoch 30.946), train_loss = 1.01813225, grad/param norm = 1.9037e-01, time/batch = 17.4117s	
16124/26050 (epoch 30.948), train_loss = 0.75573504, grad/param norm = 2.0156e-01, time/batch = 16.5802s	
16125/26050 (epoch 30.950), train_loss = 0.88229520, grad/param norm = 1.9317e-01, time/batch = 17.7262s	
16126/26050 (epoch 30.952), train_loss = 0.96587428, grad/param norm = 2.0977e-01, time/batch = 18.4865s	
16127/26050 (epoch 30.954), train_loss = 0.97849996, grad/param norm = 2.4459e-01, time/batch = 18.4082s	
16128/26050 (epoch 30.956), train_loss = 0.88344050, grad/param norm = 2.0308e-01, time/batch = 18.5782s	
16129/26050 (epoch 30.958), train_loss = 0.82134199, grad/param norm = 1.8021e-01, time/batch = 17.9882s	
16130/26050 (epoch 30.960), train_loss = 0.92750707, grad/param norm = 2.1017e-01, time/batch = 16.7252s	
16131/26050 (epoch 30.962), train_loss = 0.87504427, grad/param norm = 1.8683e-01, time/batch = 17.1462s	
16132/26050 (epoch 30.964), train_loss = 0.90297168, grad/param norm = 2.0394e-01, time/batch = 18.0765s	
16133/26050 (epoch 30.965), train_loss = 0.82367446, grad/param norm = 1.9106e-01, time/batch = 14.5645s	
16134/26050 (epoch 30.967), train_loss = 1.19776038, grad/param norm = 2.0649e-01, time/batch = 18.1484s	
16135/26050 (epoch 30.969), train_loss = 0.91879887, grad/param norm = 2.0256e-01, time/batch = 15.0618s	
16136/26050 (epoch 30.971), train_loss = 0.88363668, grad/param norm = 1.9631e-01, time/batch = 17.8996s	
16137/26050 (epoch 30.973), train_loss = 0.91161119, grad/param norm = 1.9987e-01, time/batch = 17.7214s	
16138/26050 (epoch 30.975), train_loss = 0.94651503, grad/param norm = 2.0338e-01, time/batch = 18.4043s	
16139/26050 (epoch 30.977), train_loss = 0.90401956, grad/param norm = 1.8980e-01, time/batch = 16.9012s	
16140/26050 (epoch 30.979), train_loss = 0.75646450, grad/param norm = 2.0410e-01, time/batch = 16.6314s	
16141/26050 (epoch 30.981), train_loss = 1.02432605, grad/param norm = 2.1063e-01, time/batch = 17.7385s	
16142/26050 (epoch 30.983), train_loss = 0.96409619, grad/param norm = 1.9474e-01, time/batch = 18.5856s	
16143/26050 (epoch 30.985), train_loss = 0.94409554, grad/param norm = 2.0928e-01, time/batch = 18.5762s	
16144/26050 (epoch 30.987), train_loss = 0.99933116, grad/param norm = 2.0145e-01, time/batch = 17.7063s	
16145/26050 (epoch 30.988), train_loss = 0.93594411, grad/param norm = 2.0011e-01, time/batch = 17.5671s	
16146/26050 (epoch 30.990), train_loss = 0.78804318, grad/param norm = 1.6334e-01, time/batch = 18.1590s	
16147/26050 (epoch 30.992), train_loss = 1.03815845, grad/param norm = 2.0718e-01, time/batch = 17.8176s	
16148/26050 (epoch 30.994), train_loss = 0.85114917, grad/param norm = 2.2416e-01, time/batch = 18.4839s	
16149/26050 (epoch 30.996), train_loss = 0.82314471, grad/param norm = 2.0954e-01, time/batch = 17.6684s	
16150/26050 (epoch 30.998), train_loss = 0.92818441, grad/param norm = 2.0797e-01, time/batch = 17.9931s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
16151/26050 (epoch 31.000), train_loss = 0.84640789, grad/param norm = 2.0730e-01, time/batch = 18.3247s	
16152/26050 (epoch 31.002), train_loss = 0.96541301, grad/param norm = 2.1970e-01, time/batch = 18.4918s	
16153/26050 (epoch 31.004), train_loss = 0.78789705, grad/param norm = 1.8216e-01, time/batch = 17.0501s	
16154/26050 (epoch 31.006), train_loss = 0.84529663, grad/param norm = 2.1579e-01, time/batch = 17.7870s	
16155/26050 (epoch 31.008), train_loss = 0.84297540, grad/param norm = 2.0315e-01, time/batch = 14.9057s	
16156/26050 (epoch 31.010), train_loss = 0.83586020, grad/param norm = 2.0723e-01, time/batch = 18.4011s	
16157/26050 (epoch 31.012), train_loss = 0.89956879, grad/param norm = 1.9282e-01, time/batch = 16.3844s	
16158/26050 (epoch 31.013), train_loss = 1.14872908, grad/param norm = 2.4543e-01, time/batch = 17.3038s	
16159/26050 (epoch 31.015), train_loss = 0.88905655, grad/param norm = 1.8996e-01, time/batch = 18.3090s	
16160/26050 (epoch 31.017), train_loss = 0.94342892, grad/param norm = 2.1901e-01, time/batch = 17.5561s	
16161/26050 (epoch 31.019), train_loss = 0.79191743, grad/param norm = 1.6864e-01, time/batch = 18.6452s	
16162/26050 (epoch 31.021), train_loss = 0.99359143, grad/param norm = 2.0383e-01, time/batch = 17.6488s	
16163/26050 (epoch 31.023), train_loss = 0.74173709, grad/param norm = 2.0477e-01, time/batch = 17.0471s	
16164/26050 (epoch 31.025), train_loss = 0.88525403, grad/param norm = 1.8067e-01, time/batch = 17.7308s	
16165/26050 (epoch 31.027), train_loss = 0.72983758, grad/param norm = 2.0198e-01, time/batch = 18.6356s	
16166/26050 (epoch 31.029), train_loss = 0.91671108, grad/param norm = 1.8801e-01, time/batch = 17.8178s	
16167/26050 (epoch 31.031), train_loss = 1.01863308, grad/param norm = 2.5996e-01, time/batch = 17.3964s	
16168/26050 (epoch 31.033), train_loss = 0.92582234, grad/param norm = 2.1122e-01, time/batch = 18.5771s	
16169/26050 (epoch 31.035), train_loss = 0.93267407, grad/param norm = 2.0248e-01, time/batch = 15.2144s	
16170/26050 (epoch 31.036), train_loss = 0.79601249, grad/param norm = 2.3603e-01, time/batch = 18.1648s	
16171/26050 (epoch 31.038), train_loss = 0.73216579, grad/param norm = 1.8264e-01, time/batch = 18.4784s	
16172/26050 (epoch 31.040), train_loss = 0.88024316, grad/param norm = 1.9181e-01, time/batch = 18.0734s	
16173/26050 (epoch 31.042), train_loss = 0.77356880, grad/param norm = 1.9867e-01, time/batch = 18.8065s	
16174/26050 (epoch 31.044), train_loss = 0.96871645, grad/param norm = 1.9396e-01, time/batch = 16.9802s	
16175/26050 (epoch 31.046), train_loss = 0.75568106, grad/param norm = 1.7552e-01, time/batch = 18.8169s	
16176/26050 (epoch 31.048), train_loss = 0.90211249, grad/param norm = 2.0006e-01, time/batch = 15.7209s	
16177/26050 (epoch 31.050), train_loss = 0.84046090, grad/param norm = 1.8004e-01, time/batch = 17.7226s	
16178/26050 (epoch 31.052), train_loss = 0.83414967, grad/param norm = 2.3691e-01, time/batch = 17.8078s	
16179/26050 (epoch 31.054), train_loss = 0.73613586, grad/param norm = 1.8162e-01, time/batch = 18.6557s	
16180/26050 (epoch 31.056), train_loss = 0.73802756, grad/param norm = 1.8006e-01, time/batch = 18.6375s	
16181/26050 (epoch 31.058), train_loss = 0.86775659, grad/param norm = 1.7683e-01, time/batch = 17.2270s	
16182/26050 (epoch 31.060), train_loss = 0.93754059, grad/param norm = 1.9214e-01, time/batch = 18.1392s	
16183/26050 (epoch 31.061), train_loss = 0.80093463, grad/param norm = 1.8098e-01, time/batch = 14.9429s	
16184/26050 (epoch 31.063), train_loss = 0.89012699, grad/param norm = 1.9090e-01, time/batch = 18.0468s	
16185/26050 (epoch 31.065), train_loss = 0.74028171, grad/param norm = 1.9267e-01, time/batch = 18.3041s	
16186/26050 (epoch 31.067), train_loss = 0.87215780, grad/param norm = 1.9640e-01, time/batch = 18.4900s	
16187/26050 (epoch 31.069), train_loss = 0.92633015, grad/param norm = 2.4357e-01, time/batch = 17.7321s	
16188/26050 (epoch 31.071), train_loss = 0.94261739, grad/param norm = 2.0767e-01, time/batch = 18.7412s	
16189/26050 (epoch 31.073), train_loss = 1.03611769, grad/param norm = 2.0444e-01, time/batch = 18.3820s	
16190/26050 (epoch 31.075), train_loss = 0.82125877, grad/param norm = 1.8146e-01, time/batch = 15.3212s	
16191/26050 (epoch 31.077), train_loss = 0.85683560, grad/param norm = 2.2702e-01, time/batch = 16.3151s	
16192/26050 (epoch 31.079), train_loss = 0.88888417, grad/param norm = 2.1045e-01, time/batch = 18.2394s	
16193/26050 (epoch 31.081), train_loss = 0.85841867, grad/param norm = 2.0534e-01, time/batch = 18.4080s	
16194/26050 (epoch 31.083), train_loss = 0.99063954, grad/param norm = 1.8800e-01, time/batch = 17.6455s	
16195/26050 (epoch 31.084), train_loss = 0.90647743, grad/param norm = 2.5151e-01, time/batch = 18.6623s	
16196/26050 (epoch 31.086), train_loss = 1.06867679, grad/param norm = 2.2475e-01, time/batch = 15.6321s	
16197/26050 (epoch 31.088), train_loss = 0.84822090, grad/param norm = 1.9493e-01, time/batch = 17.3755s	
16198/26050 (epoch 31.090), train_loss = 0.90076283, grad/param norm = 2.1014e-01, time/batch = 18.1393s	
16199/26050 (epoch 31.092), train_loss = 0.94558389, grad/param norm = 1.8894e-01, time/batch = 18.1606s	
16200/26050 (epoch 31.094), train_loss = 0.77995994, grad/param norm = 2.1301e-01, time/batch = 18.1540s	
16201/26050 (epoch 31.096), train_loss = 0.91636531, grad/param norm = 1.8971e-01, time/batch = 17.8223s	
16202/26050 (epoch 31.098), train_loss = 0.87409897, grad/param norm = 1.9931e-01, time/batch = 14.5569s	
16203/26050 (epoch 31.100), train_loss = 0.80317974, grad/param norm = 1.9580e-01, time/batch = 17.5632s	
16204/26050 (epoch 31.102), train_loss = 0.93959004, grad/param norm = 2.0782e-01, time/batch = 17.9011s	
16205/26050 (epoch 31.104), train_loss = 0.85989106, grad/param norm = 1.9897e-01, time/batch = 18.6384s	
16206/26050 (epoch 31.106), train_loss = 0.92511308, grad/param norm = 2.1570e-01, time/batch = 18.8911s	
16207/26050 (epoch 31.107), train_loss = 0.74614836, grad/param norm = 2.0265e-01, time/batch = 17.7276s	
16208/26050 (epoch 31.109), train_loss = 0.82475036, grad/param norm = 1.9841e-01, time/batch = 16.8924s	
16209/26050 (epoch 31.111), train_loss = 1.04211453, grad/param norm = 2.2362e-01, time/batch = 17.4067s	
16210/26050 (epoch 31.113), train_loss = 0.83626967, grad/param norm = 1.9738e-01, time/batch = 16.3888s	
16211/26050 (epoch 31.115), train_loss = 0.99474251, grad/param norm = 2.1882e-01, time/batch = 17.4642s	
16212/26050 (epoch 31.117), train_loss = 0.88973102, grad/param norm = 1.9168e-01, time/batch = 18.0649s	
16213/26050 (epoch 31.119), train_loss = 0.76684252, grad/param norm = 1.8448e-01, time/batch = 18.8394s	
16214/26050 (epoch 31.121), train_loss = 0.91204046, grad/param norm = 2.0460e-01, time/batch = 18.4127s	
16215/26050 (epoch 31.123), train_loss = 0.81159746, grad/param norm = 1.9382e-01, time/batch = 17.3251s	
16216/26050 (epoch 31.125), train_loss = 0.76613935, grad/param norm = 1.7745e-01, time/batch = 18.1567s	
16217/26050 (epoch 31.127), train_loss = 0.73459636, grad/param norm = 1.7195e-01, time/batch = 18.3273s	
16218/26050 (epoch 31.129), train_loss = 0.72412055, grad/param norm = 1.8794e-01, time/batch = 15.2362s	
16219/26050 (epoch 31.131), train_loss = 0.84749561, grad/param norm = 2.0078e-01, time/batch = 17.3027s	
16220/26050 (epoch 31.132), train_loss = 0.87867639, grad/param norm = 1.8124e-01, time/batch = 17.7399s	
16221/26050 (epoch 31.134), train_loss = 0.90745352, grad/param norm = 2.2048e-01, time/batch = 16.5514s	
16222/26050 (epoch 31.136), train_loss = 0.86409443, grad/param norm = 1.8909e-01, time/batch = 18.3056s	
16223/26050 (epoch 31.138), train_loss = 0.65890058, grad/param norm = 1.8562e-01, time/batch = 16.3011s	
16224/26050 (epoch 31.140), train_loss = 0.72804976, grad/param norm = 1.8265e-01, time/batch = 18.9037s	
16225/26050 (epoch 31.142), train_loss = 0.76989609, grad/param norm = 1.9006e-01, time/batch = 16.9031s	
16226/26050 (epoch 31.144), train_loss = 0.71370943, grad/param norm = 2.0730e-01, time/batch = 15.6555s	
16227/26050 (epoch 31.146), train_loss = 0.67164341, grad/param norm = 1.8655e-01, time/batch = 17.3185s	
16228/26050 (epoch 31.148), train_loss = 0.70169639, grad/param norm = 1.6449e-01, time/batch = 18.0653s	
16229/26050 (epoch 31.150), train_loss = 0.83138173, grad/param norm = 1.9754e-01, time/batch = 18.3995s	
16230/26050 (epoch 31.152), train_loss = 1.04306070, grad/param norm = 2.7237e-01, time/batch = 18.0796s	
16231/26050 (epoch 31.154), train_loss = 0.71018117, grad/param norm = 1.9146e-01, time/batch = 17.3819s	
16232/26050 (epoch 31.155), train_loss = 0.77139054, grad/param norm = 2.2556e-01, time/batch = 17.6215s	
16233/26050 (epoch 31.157), train_loss = 0.86494549, grad/param norm = 2.3663e-01, time/batch = 18.3202s	
16234/26050 (epoch 31.159), train_loss = 0.90784609, grad/param norm = 2.0711e-01, time/batch = 18.7199s	
16235/26050 (epoch 31.161), train_loss = 0.90207735, grad/param norm = 2.0758e-01, time/batch = 17.3125s	
16236/26050 (epoch 31.163), train_loss = 0.73364165, grad/param norm = 1.9884e-01, time/batch = 17.8122s	
16237/26050 (epoch 31.165), train_loss = 0.68862960, grad/param norm = 1.8910e-01, time/batch = 17.4882s	
16238/26050 (epoch 31.167), train_loss = 1.00741478, grad/param norm = 2.4110e-01, time/batch = 16.3075s	
16239/26050 (epoch 31.169), train_loss = 0.90755539, grad/param norm = 2.6523e-01, time/batch = 18.6287s	
16240/26050 (epoch 31.171), train_loss = 0.76391654, grad/param norm = 1.7995e-01, time/batch = 17.0688s	
16241/26050 (epoch 31.173), train_loss = 0.85564539, grad/param norm = 2.0867e-01, time/batch = 15.3893s	
16242/26050 (epoch 31.175), train_loss = 0.86104268, grad/param norm = 1.8650e-01, time/batch = 17.0714s	
16243/26050 (epoch 31.177), train_loss = 0.95422600, grad/param norm = 1.9662e-01, time/batch = 16.5380s	
16244/26050 (epoch 31.179), train_loss = 0.66012886, grad/param norm = 1.7097e-01, time/batch = 15.3790s	
16245/26050 (epoch 31.180), train_loss = 1.09206565, grad/param norm = 2.0573e-01, time/batch = 18.0663s	
16246/26050 (epoch 31.182), train_loss = 1.05413977, grad/param norm = 2.2409e-01, time/batch = 15.8230s	
16247/26050 (epoch 31.184), train_loss = 0.89593318, grad/param norm = 1.9116e-01, time/batch = 17.9931s	
16248/26050 (epoch 31.186), train_loss = 0.73642109, grad/param norm = 1.8385e-01, time/batch = 17.4989s	
16249/26050 (epoch 31.188), train_loss = 0.90258682, grad/param norm = 2.2170e-01, time/batch = 15.5682s	
16250/26050 (epoch 31.190), train_loss = 0.93218744, grad/param norm = 2.3263e-01, time/batch = 18.3999s	
16251/26050 (epoch 31.192), train_loss = 0.94950870, grad/param norm = 1.8469e-01, time/batch = 17.4925s	
16252/26050 (epoch 31.194), train_loss = 0.91996510, grad/param norm = 1.8972e-01, time/batch = 18.4682s	
16253/26050 (epoch 31.196), train_loss = 0.95004425, grad/param norm = 2.0126e-01, time/batch = 15.4596s	
16254/26050 (epoch 31.198), train_loss = 0.79309535, grad/param norm = 1.6722e-01, time/batch = 18.9788s	
16255/26050 (epoch 31.200), train_loss = 0.79092579, grad/param norm = 1.9848e-01, time/batch = 18.1766s	
16256/26050 (epoch 31.202), train_loss = 0.89224515, grad/param norm = 1.8683e-01, time/batch = 17.0722s	
16257/26050 (epoch 31.203), train_loss = 0.97480190, grad/param norm = 1.8333e-01, time/batch = 18.0730s	
16258/26050 (epoch 31.205), train_loss = 0.82960880, grad/param norm = 1.9548e-01, time/batch = 18.4059s	
16259/26050 (epoch 31.207), train_loss = 0.80431863, grad/param norm = 1.9662e-01, time/batch = 16.7292s	
16260/26050 (epoch 31.209), train_loss = 0.94224197, grad/param norm = 1.9454e-01, time/batch = 1.7725s	
16261/26050 (epoch 31.211), train_loss = 0.75571658, grad/param norm = 1.9335e-01, time/batch = 0.6418s	
16262/26050 (epoch 31.213), train_loss = 0.91869080, grad/param norm = 2.4195e-01, time/batch = 0.6498s	
16263/26050 (epoch 31.215), train_loss = 0.84810212, grad/param norm = 2.1248e-01, time/batch = 0.6410s	
16264/26050 (epoch 31.217), train_loss = 0.83682735, grad/param norm = 2.0329e-01, time/batch = 0.6425s	
16265/26050 (epoch 31.219), train_loss = 0.84224512, grad/param norm = 2.0580e-01, time/batch = 0.6422s	
16266/26050 (epoch 31.221), train_loss = 0.78747213, grad/param norm = 2.0009e-01, time/batch = 0.6412s	
16267/26050 (epoch 31.223), train_loss = 0.96113078, grad/param norm = 2.0630e-01, time/batch = 0.7000s	
16268/26050 (epoch 31.225), train_loss = 0.80818717, grad/param norm = 2.2976e-01, time/batch = 0.9683s	
16269/26050 (epoch 31.226), train_loss = 0.91264480, grad/param norm = 2.0492e-01, time/batch = 0.9648s	
16270/26050 (epoch 31.228), train_loss = 1.01908212, grad/param norm = 2.0038e-01, time/batch = 0.9470s	
16271/26050 (epoch 31.230), train_loss = 0.88125574, grad/param norm = 1.8639e-01, time/batch = 0.9447s	
16272/26050 (epoch 31.232), train_loss = 0.95970140, grad/param norm = 2.2130e-01, time/batch = 0.9996s	
16273/26050 (epoch 31.234), train_loss = 0.78455319, grad/param norm = 1.9479e-01, time/batch = 1.8189s	
16274/26050 (epoch 31.236), train_loss = 0.95685756, grad/param norm = 1.9893e-01, time/batch = 1.7699s	
16275/26050 (epoch 31.238), train_loss = 0.74807060, grad/param norm = 2.3113e-01, time/batch = 6.2693s	
16276/26050 (epoch 31.240), train_loss = 0.88449480, grad/param norm = 2.0435e-01, time/batch = 18.6591s	
16277/26050 (epoch 31.242), train_loss = 0.84966106, grad/param norm = 1.9628e-01, time/batch = 17.7235s	
16278/26050 (epoch 31.244), train_loss = 0.90453514, grad/param norm = 2.2545e-01, time/batch = 17.3136s	
16279/26050 (epoch 31.246), train_loss = 0.83810301, grad/param norm = 1.9759e-01, time/batch = 18.7268s	
16280/26050 (epoch 31.248), train_loss = 0.91524129, grad/param norm = 2.2631e-01, time/batch = 15.7088s	
16281/26050 (epoch 31.250), train_loss = 0.89632527, grad/param norm = 2.5184e-01, time/batch = 18.0402s	
16282/26050 (epoch 31.251), train_loss = 0.84379374, grad/param norm = 2.0524e-01, time/batch = 18.0652s	
16283/26050 (epoch 31.253), train_loss = 0.79901886, grad/param norm = 2.1065e-01, time/batch = 18.3694s	
16284/26050 (epoch 31.255), train_loss = 1.04763475, grad/param norm = 2.1130e-01, time/batch = 17.6505s	
16285/26050 (epoch 31.257), train_loss = 0.87809761, grad/param norm = 2.1863e-01, time/batch = 18.0740s	
16286/26050 (epoch 31.259), train_loss = 0.97363940, grad/param norm = 2.1511e-01, time/batch = 14.8195s	
16287/26050 (epoch 31.261), train_loss = 0.77495989, grad/param norm = 1.9282e-01, time/batch = 18.3245s	
16288/26050 (epoch 31.263), train_loss = 0.98825033, grad/param norm = 2.3815e-01, time/batch = 17.2278s	
16289/26050 (epoch 31.265), train_loss = 1.04199935, grad/param norm = 2.9387e-01, time/batch = 18.4936s	
16290/26050 (epoch 31.267), train_loss = 0.99599464, grad/param norm = 1.9240e-01, time/batch = 18.1427s	
16291/26050 (epoch 31.269), train_loss = 1.00369755, grad/param norm = 2.4767e-01, time/batch = 16.4661s	
16292/26050 (epoch 31.271), train_loss = 0.91439472, grad/param norm = 1.9955e-01, time/batch = 18.0330s	
16293/26050 (epoch 31.273), train_loss = 0.81019593, grad/param norm = 1.9468e-01, time/batch = 17.8252s	
16294/26050 (epoch 31.274), train_loss = 0.85406630, grad/param norm = 1.7847e-01, time/batch = 17.7367s	
16295/26050 (epoch 31.276), train_loss = 0.84329369, grad/param norm = 1.8020e-01, time/batch = 14.9636s	
16296/26050 (epoch 31.278), train_loss = 0.97431460, grad/param norm = 2.0829e-01, time/batch = 18.9773s	
16297/26050 (epoch 31.280), train_loss = 0.89124307, grad/param norm = 1.9234e-01, time/batch = 18.8144s	
16298/26050 (epoch 31.282), train_loss = 0.92780727, grad/param norm = 1.8791e-01, time/batch = 17.8878s	
16299/26050 (epoch 31.284), train_loss = 0.86019679, grad/param norm = 1.9179e-01, time/batch = 18.2234s	
16300/26050 (epoch 31.286), train_loss = 0.90833328, grad/param norm = 1.9386e-01, time/batch = 18.7213s	
16301/26050 (epoch 31.288), train_loss = 0.77293617, grad/param norm = 1.8359e-01, time/batch = 14.7941s	
16302/26050 (epoch 31.290), train_loss = 0.89257842, grad/param norm = 1.8469e-01, time/batch = 16.9825s	
16303/26050 (epoch 31.292), train_loss = 0.82677895, grad/param norm = 2.1743e-01, time/batch = 18.0777s	
16304/26050 (epoch 31.294), train_loss = 0.89185443, grad/param norm = 2.1181e-01, time/batch = 18.0648s	
16305/26050 (epoch 31.296), train_loss = 0.96726173, grad/param norm = 2.0108e-01, time/batch = 17.5594s	
16306/26050 (epoch 31.298), train_loss = 0.91874118, grad/param norm = 1.8346e-01, time/batch = 17.5361s	
16307/26050 (epoch 31.299), train_loss = 0.73435802, grad/param norm = 1.8005e-01, time/batch = 18.7331s	
16308/26050 (epoch 31.301), train_loss = 0.75913565, grad/param norm = 2.1227e-01, time/batch = 25.3555s	
16309/26050 (epoch 31.303), train_loss = 0.89534740, grad/param norm = 2.1214e-01, time/batch = 29.5344s	
16310/26050 (epoch 31.305), train_loss = 0.72149200, grad/param norm = 1.8510e-01, time/batch = 17.8351s	
16311/26050 (epoch 31.307), train_loss = 0.81727558, grad/param norm = 2.1717e-01, time/batch = 18.4774s	
16312/26050 (epoch 31.309), train_loss = 0.87558702, grad/param norm = 1.9304e-01, time/batch = 18.4064s	
16313/26050 (epoch 31.311), train_loss = 0.94475479, grad/param norm = 2.5570e-01, time/batch = 17.9829s	
16314/26050 (epoch 31.313), train_loss = 0.89460107, grad/param norm = 2.4396e-01, time/batch = 18.3907s	
16315/26050 (epoch 31.315), train_loss = 0.95803709, grad/param norm = 1.9249e-01, time/batch = 17.9981s	
16316/26050 (epoch 31.317), train_loss = 0.90430687, grad/param norm = 2.1729e-01, time/batch = 17.5509s	
16317/26050 (epoch 31.319), train_loss = 0.80844438, grad/param norm = 2.0508e-01, time/batch = 18.0584s	
16318/26050 (epoch 31.321), train_loss = 0.86466850, grad/param norm = 1.9712e-01, time/batch = 18.2436s	
16319/26050 (epoch 31.322), train_loss = 0.93151350, grad/param norm = 1.8216e-01, time/batch = 17.9188s	
16320/26050 (epoch 31.324), train_loss = 0.70277650, grad/param norm = 1.7562e-01, time/batch = 15.4548s	
16321/26050 (epoch 31.326), train_loss = 0.99904986, grad/param norm = 2.0055e-01, time/batch = 18.3294s	
16322/26050 (epoch 31.328), train_loss = 0.90954021, grad/param norm = 1.7889e-01, time/batch = 18.0582s	
16323/26050 (epoch 31.330), train_loss = 0.77497289, grad/param norm = 2.0608e-01, time/batch = 18.2236s	
16324/26050 (epoch 31.332), train_loss = 0.93981091, grad/param norm = 1.9034e-01, time/batch = 14.8791s	
16325/26050 (epoch 31.334), train_loss = 0.80199971, grad/param norm = 1.9547e-01, time/batch = 18.5588s	
16326/26050 (epoch 31.336), train_loss = 0.82175895, grad/param norm = 2.0822e-01, time/batch = 18.4289s	
16327/26050 (epoch 31.338), train_loss = 0.77349206, grad/param norm = 1.7730e-01, time/batch = 16.2105s	
16328/26050 (epoch 31.340), train_loss = 0.93345235, grad/param norm = 2.0916e-01, time/batch = 18.5007s	
16329/26050 (epoch 31.342), train_loss = 0.96683950, grad/param norm = 2.0201e-01, time/batch = 17.8269s	
16330/26050 (epoch 31.344), train_loss = 0.80548075, grad/param norm = 2.0515e-01, time/batch = 17.5671s	
16331/26050 (epoch 31.345), train_loss = 0.87027987, grad/param norm = 2.1211e-01, time/batch = 16.9042s	
16332/26050 (epoch 31.347), train_loss = 0.99777370, grad/param norm = 2.0117e-01, time/batch = 17.1464s	
16333/26050 (epoch 31.349), train_loss = 0.92432306, grad/param norm = 2.0057e-01, time/batch = 18.5644s	
16334/26050 (epoch 31.351), train_loss = 0.91411910, grad/param norm = 1.9732e-01, time/batch = 17.9778s	
16335/26050 (epoch 31.353), train_loss = 0.90943483, grad/param norm = 2.2627e-01, time/batch = 15.2239s	
16336/26050 (epoch 31.355), train_loss = 0.89968858, grad/param norm = 2.6601e-01, time/batch = 18.3152s	
16337/26050 (epoch 31.357), train_loss = 0.84226434, grad/param norm = 1.8293e-01, time/batch = 17.7363s	
16338/26050 (epoch 31.359), train_loss = 0.95005827, grad/param norm = 2.0749e-01, time/batch = 18.0019s	
16339/26050 (epoch 31.361), train_loss = 0.79261115, grad/param norm = 1.7314e-01, time/batch = 18.5784s	
16340/26050 (epoch 31.363), train_loss = 0.96591576, grad/param norm = 1.9438e-01, time/batch = 17.8140s	
16341/26050 (epoch 31.365), train_loss = 0.84925806, grad/param norm = 1.8575e-01, time/batch = 17.3886s	
16342/26050 (epoch 31.367), train_loss = 0.95099323, grad/param norm = 1.7999e-01, time/batch = 18.6370s	
16343/26050 (epoch 31.369), train_loss = 0.79793738, grad/param norm = 1.7005e-01, time/batch = 16.6391s	
16344/26050 (epoch 31.370), train_loss = 0.79139512, grad/param norm = 1.6533e-01, time/batch = 17.4754s	
16345/26050 (epoch 31.372), train_loss = 0.88579910, grad/param norm = 2.0004e-01, time/batch = 17.8300s	
16346/26050 (epoch 31.374), train_loss = 1.02538129, grad/param norm = 2.1191e-01, time/batch = 18.4875s	
16347/26050 (epoch 31.376), train_loss = 1.04580860, grad/param norm = 2.2265e-01, time/batch = 16.9038s	
16348/26050 (epoch 31.378), train_loss = 0.83210042, grad/param norm = 1.9152e-01, time/batch = 17.2936s	
16349/26050 (epoch 31.380), train_loss = 1.03197627, grad/param norm = 2.4726e-01, time/batch = 17.8332s	
16350/26050 (epoch 31.382), train_loss = 1.13250631, grad/param norm = 2.4134e-01, time/batch = 18.3102s	
16351/26050 (epoch 31.384), train_loss = 0.84979209, grad/param norm = 2.0142e-01, time/batch = 16.8809s	
16352/26050 (epoch 31.386), train_loss = 0.95326923, grad/param norm = 2.2470e-01, time/batch = 17.8161s	
16353/26050 (epoch 31.388), train_loss = 0.92605092, grad/param norm = 2.5068e-01, time/batch = 18.4115s	
16354/26050 (epoch 31.390), train_loss = 0.84381551, grad/param norm = 1.8873e-01, time/batch = 17.1345s	
16355/26050 (epoch 31.392), train_loss = 0.78472602, grad/param norm = 1.8101e-01, time/batch = 14.5351s	
16356/26050 (epoch 31.393), train_loss = 0.94913347, grad/param norm = 2.4124e-01, time/batch = 18.3741s	
16357/26050 (epoch 31.395), train_loss = 0.96294724, grad/param norm = 2.2709e-01, time/batch = 17.8989s	
16358/26050 (epoch 31.397), train_loss = 0.94908196, grad/param norm = 2.0531e-01, time/batch = 17.1385s	
16359/26050 (epoch 31.399), train_loss = 0.83486060, grad/param norm = 1.9378e-01, time/batch = 19.0597s	
16360/26050 (epoch 31.401), train_loss = 0.89524169, grad/param norm = 1.9704e-01, time/batch = 18.5464s	
16361/26050 (epoch 31.403), train_loss = 0.92218359, grad/param norm = 2.3471e-01, time/batch = 17.8841s	
16362/26050 (epoch 31.405), train_loss = 0.89570661, grad/param norm = 1.9982e-01, time/batch = 18.2353s	
16363/26050 (epoch 31.407), train_loss = 1.02296144, grad/param norm = 2.1316e-01, time/batch = 17.8129s	
16364/26050 (epoch 31.409), train_loss = 1.02784053, grad/param norm = 2.2812e-01, time/batch = 17.9871s	
16365/26050 (epoch 31.411), train_loss = 0.95914699, grad/param norm = 2.0462e-01, time/batch = 17.8982s	
16366/26050 (epoch 31.413), train_loss = 1.05313009, grad/param norm = 1.9900e-01, time/batch = 18.1461s	
16367/26050 (epoch 31.415), train_loss = 1.05290886, grad/param norm = 2.2062e-01, time/batch = 14.9777s	
16368/26050 (epoch 31.417), train_loss = 1.08526408, grad/param norm = 2.2767e-01, time/batch = 18.1559s	
16369/26050 (epoch 31.418), train_loss = 0.97059747, grad/param norm = 2.3454e-01, time/batch = 16.4776s	
16370/26050 (epoch 31.420), train_loss = 0.78743001, grad/param norm = 1.8425e-01, time/batch = 17.5300s	
16371/26050 (epoch 31.422), train_loss = 0.76898780, grad/param norm = 1.9780e-01, time/batch = 16.9701s	
16372/26050 (epoch 31.424), train_loss = 1.00198052, grad/param norm = 2.1295e-01, time/batch = 18.0553s	
16373/26050 (epoch 31.426), train_loss = 0.97501020, grad/param norm = 2.2057e-01, time/batch = 18.8114s	
16374/26050 (epoch 31.428), train_loss = 0.84250465, grad/param norm = 1.9492e-01, time/batch = 17.5688s	
16375/26050 (epoch 31.430), train_loss = 1.05222075, grad/param norm = 2.0262e-01, time/batch = 16.2375s	
16376/26050 (epoch 31.432), train_loss = 0.87114427, grad/param norm = 2.0500e-01, time/batch = 16.0597s	
16377/26050 (epoch 31.434), train_loss = 0.86407460, grad/param norm = 1.8965e-01, time/batch = 18.7513s	
16378/26050 (epoch 31.436), train_loss = 1.00103910, grad/param norm = 1.9460e-01, time/batch = 16.2227s	
16379/26050 (epoch 31.438), train_loss = 0.95480719, grad/param norm = 2.1223e-01, time/batch = 16.7174s	
16380/26050 (epoch 31.440), train_loss = 0.93837768, grad/param norm = 2.0164e-01, time/batch = 18.9091s	
16381/26050 (epoch 31.441), train_loss = 0.91562397, grad/param norm = 1.8578e-01, time/batch = 17.7444s	
16382/26050 (epoch 31.443), train_loss = 0.76717125, grad/param norm = 1.5677e-01, time/batch = 17.6565s	
16383/26050 (epoch 31.445), train_loss = 0.81591712, grad/param norm = 1.7971e-01, time/batch = 18.0702s	
16384/26050 (epoch 31.447), train_loss = 1.02009232, grad/param norm = 2.0499e-01, time/batch = 17.9074s	
16385/26050 (epoch 31.449), train_loss = 0.83124951, grad/param norm = 1.9315e-01, time/batch = 16.4413s	
16386/26050 (epoch 31.451), train_loss = 1.03592577, grad/param norm = 2.0176e-01, time/batch = 15.3263s	
16387/26050 (epoch 31.453), train_loss = 0.84786639, grad/param norm = 1.7415e-01, time/batch = 18.2413s	
16388/26050 (epoch 31.455), train_loss = 0.90391759, grad/param norm = 1.8861e-01, time/batch = 17.3980s	
16389/26050 (epoch 31.457), train_loss = 0.88929162, grad/param norm = 1.9421e-01, time/batch = 18.4709s	
16390/26050 (epoch 31.459), train_loss = 1.00747850, grad/param norm = 2.2841e-01, time/batch = 18.3174s	
16391/26050 (epoch 31.461), train_loss = 1.00409930, grad/param norm = 2.1552e-01, time/batch = 17.5620s	
16392/26050 (epoch 31.463), train_loss = 0.86973971, grad/param norm = 1.6763e-01, time/batch = 17.3065s	
16393/26050 (epoch 31.464), train_loss = 0.93611688, grad/param norm = 1.9591e-01, time/batch = 16.3995s	
16394/26050 (epoch 31.466), train_loss = 0.91944904, grad/param norm = 2.0721e-01, time/batch = 17.1240s	
16395/26050 (epoch 31.468), train_loss = 0.99726671, grad/param norm = 1.9247e-01, time/batch = 15.8756s	
16396/26050 (epoch 31.470), train_loss = 1.00053766, grad/param norm = 2.3095e-01, time/batch = 18.6482s	
16397/26050 (epoch 31.472), train_loss = 1.01317155, grad/param norm = 2.3679e-01, time/batch = 18.3131s	
16398/26050 (epoch 31.474), train_loss = 1.01735977, grad/param norm = 2.0273e-01, time/batch = 17.5661s	
16399/26050 (epoch 31.476), train_loss = 0.98337651, grad/param norm = 1.8593e-01, time/batch = 15.6499s	
16400/26050 (epoch 31.478), train_loss = 0.87738070, grad/param norm = 1.8939e-01, time/batch = 16.9792s	
16401/26050 (epoch 31.480), train_loss = 0.87497253, grad/param norm = 1.8121e-01, time/batch = 17.9857s	
16402/26050 (epoch 31.482), train_loss = 0.85907987, grad/param norm = 1.9250e-01, time/batch = 16.6711s	
16403/26050 (epoch 31.484), train_loss = 0.84990374, grad/param norm = 1.9990e-01, time/batch = 18.4026s	
16404/26050 (epoch 31.486), train_loss = 1.04031587, grad/param norm = 2.0044e-01, time/batch = 18.5740s	
16405/26050 (epoch 31.488), train_loss = 1.07129734, grad/param norm = 2.3236e-01, time/batch = 16.7449s	
16406/26050 (epoch 31.489), train_loss = 1.08301416, grad/param norm = 2.5625e-01, time/batch = 16.8123s	
16407/26050 (epoch 31.491), train_loss = 0.83045200, grad/param norm = 2.0465e-01, time/batch = 17.8147s	
16408/26050 (epoch 31.493), train_loss = 0.93671703, grad/param norm = 2.2400e-01, time/batch = 18.5682s	
16409/26050 (epoch 31.495), train_loss = 0.88279578, grad/param norm = 1.7876e-01, time/batch = 16.3901s	
16410/26050 (epoch 31.497), train_loss = 0.80331256, grad/param norm = 1.9035e-01, time/batch = 18.5657s	
16411/26050 (epoch 31.499), train_loss = 0.85378486, grad/param norm = 1.8903e-01, time/batch = 15.8963s	
16412/26050 (epoch 31.501), train_loss = 0.98251247, grad/param norm = 1.9675e-01, time/batch = 16.3004s	
16413/26050 (epoch 31.503), train_loss = 0.84996583, grad/param norm = 1.9088e-01, time/batch = 17.9877s	
16414/26050 (epoch 31.505), train_loss = 1.02627555, grad/param norm = 2.0748e-01, time/batch = 18.9061s	
16415/26050 (epoch 31.507), train_loss = 0.98226863, grad/param norm = 2.8524e-01, time/batch = 17.9033s	
16416/26050 (epoch 31.509), train_loss = 1.04959208, grad/param norm = 2.0904e-01, time/batch = 18.1568s	
16417/26050 (epoch 31.511), train_loss = 0.87011663, grad/param norm = 1.7534e-01, time/batch = 17.9116s	
16418/26050 (epoch 31.512), train_loss = 0.79522107, grad/param norm = 2.0598e-01, time/batch = 18.6538s	
16419/26050 (epoch 31.514), train_loss = 0.97923216, grad/param norm = 2.3172e-01, time/batch = 15.7996s	
16420/26050 (epoch 31.516), train_loss = 1.03803629, grad/param norm = 2.1242e-01, time/batch = 17.4775s	
16421/26050 (epoch 31.518), train_loss = 0.88425811, grad/param norm = 2.2003e-01, time/batch = 18.6561s	
16422/26050 (epoch 31.520), train_loss = 0.91766002, grad/param norm = 2.1956e-01, time/batch = 15.2081s	
16423/26050 (epoch 31.522), train_loss = 0.72204375, grad/param norm = 1.8159e-01, time/batch = 17.9902s	
16424/26050 (epoch 31.524), train_loss = 1.00603244, grad/param norm = 2.4129e-01, time/batch = 15.6337s	
16425/26050 (epoch 31.526), train_loss = 1.01772094, grad/param norm = 2.2002e-01, time/batch = 18.3298s	
16426/26050 (epoch 31.528), train_loss = 0.94583422, grad/param norm = 2.1800e-01, time/batch = 17.4666s	
16427/26050 (epoch 31.530), train_loss = 0.88740901, grad/param norm = 2.3818e-01, time/batch = 16.6217s	
16428/26050 (epoch 31.532), train_loss = 0.94138748, grad/param norm = 1.8939e-01, time/batch = 18.7341s	
16429/26050 (epoch 31.534), train_loss = 0.95932397, grad/param norm = 2.5605e-01, time/batch = 17.0785s	
16430/26050 (epoch 31.536), train_loss = 0.93203698, grad/param norm = 1.9929e-01, time/batch = 18.8125s	
16431/26050 (epoch 31.537), train_loss = 0.98133054, grad/param norm = 2.2253e-01, time/batch = 17.9811s	
16432/26050 (epoch 31.539), train_loss = 0.90573286, grad/param norm = 1.9751e-01, time/batch = 18.0496s	
16433/26050 (epoch 31.541), train_loss = 1.07149991, grad/param norm = 2.3262e-01, time/batch = 17.5667s	
16434/26050 (epoch 31.543), train_loss = 0.76497748, grad/param norm = 2.3751e-01, time/batch = 16.9026s	
16435/26050 (epoch 31.545), train_loss = 0.91943602, grad/param norm = 2.0538e-01, time/batch = 18.0597s	
16436/26050 (epoch 31.547), train_loss = 0.89735729, grad/param norm = 2.2457e-01, time/batch = 17.6541s	
16437/26050 (epoch 31.549), train_loss = 0.77922654, grad/param norm = 2.4408e-01, time/batch = 18.1602s	
16438/26050 (epoch 31.551), train_loss = 0.96208966, grad/param norm = 2.1091e-01, time/batch = 18.0835s	
16439/26050 (epoch 31.553), train_loss = 0.86643574, grad/param norm = 2.1114e-01, time/batch = 17.7338s	
16440/26050 (epoch 31.555), train_loss = 0.80988654, grad/param norm = 2.0625e-01, time/batch = 15.4774s	
16441/26050 (epoch 31.557), train_loss = 0.94271190, grad/param norm = 2.1209e-01, time/batch = 18.6304s	
16442/26050 (epoch 31.559), train_loss = 0.92569303, grad/param norm = 1.9080e-01, time/batch = 17.9818s	
16443/26050 (epoch 31.560), train_loss = 0.86247263, grad/param norm = 2.0242e-01, time/batch = 14.4989s	
16444/26050 (epoch 31.562), train_loss = 0.89557709, grad/param norm = 2.1096e-01, time/batch = 14.4554s	
16445/26050 (epoch 31.564), train_loss = 1.08337946, grad/param norm = 2.1097e-01, time/batch = 14.0750s	
16446/26050 (epoch 31.566), train_loss = 0.84690920, grad/param norm = 1.9800e-01, time/batch = 14.1531s	
16447/26050 (epoch 31.568), train_loss = 0.94365810, grad/param norm = 1.9446e-01, time/batch = 16.8878s	
16448/26050 (epoch 31.570), train_loss = 0.91743041, grad/param norm = 2.2000e-01, time/batch = 18.5742s	
16449/26050 (epoch 31.572), train_loss = 0.91149951, grad/param norm = 1.9951e-01, time/batch = 19.0534s	
16450/26050 (epoch 31.574), train_loss = 0.91395373, grad/param norm = 2.0251e-01, time/batch = 15.0405s	
16451/26050 (epoch 31.576), train_loss = 0.96173718, grad/param norm = 2.2852e-01, time/batch = 14.5445s	
16452/26050 (epoch 31.578), train_loss = 0.90543386, grad/param norm = 2.2570e-01, time/batch = 15.8788s	
16453/26050 (epoch 31.580), train_loss = 0.83119958, grad/param norm = 2.0667e-01, time/batch = 14.3792s	
16454/26050 (epoch 31.582), train_loss = 0.93872642, grad/param norm = 2.0533e-01, time/batch = 14.8859s	
16455/26050 (epoch 31.583), train_loss = 0.99817062, grad/param norm = 2.0333e-01, time/batch = 16.2193s	
16456/26050 (epoch 31.585), train_loss = 0.80957037, grad/param norm = 1.9789e-01, time/batch = 18.5694s	
16457/26050 (epoch 31.587), train_loss = 0.94619641, grad/param norm = 2.4151e-01, time/batch = 14.9095s	
16458/26050 (epoch 31.589), train_loss = 1.04557545, grad/param norm = 2.0950e-01, time/batch = 18.0651s	
16459/26050 (epoch 31.591), train_loss = 0.91211104, grad/param norm = 2.0891e-01, time/batch = 14.9873s	
16460/26050 (epoch 31.593), train_loss = 0.79296893, grad/param norm = 1.8063e-01, time/batch = 18.5857s	
16461/26050 (epoch 31.595), train_loss = 1.00069029, grad/param norm = 2.4870e-01, time/batch = 17.8904s	
16462/26050 (epoch 31.597), train_loss = 0.92189061, grad/param norm = 2.1580e-01, time/batch = 17.9809s	
16463/26050 (epoch 31.599), train_loss = 0.95018740, grad/param norm = 2.1999e-01, time/batch = 17.4885s	
16464/26050 (epoch 31.601), train_loss = 1.07674549, grad/param norm = 1.9810e-01, time/batch = 17.8258s	
16465/26050 (epoch 31.603), train_loss = 0.99233972, grad/param norm = 2.2354e-01, time/batch = 15.5921s	
16466/26050 (epoch 31.605), train_loss = 0.88501603, grad/param norm = 2.3809e-01, time/batch = 17.8819s	
16467/26050 (epoch 31.607), train_loss = 1.01956922, grad/param norm = 2.4366e-01, time/batch = 16.0619s	
16468/26050 (epoch 31.608), train_loss = 0.83151157, grad/param norm = 1.8284e-01, time/batch = 15.3926s	
16469/26050 (epoch 31.610), train_loss = 0.91769980, grad/param norm = 2.2800e-01, time/batch = 17.3803s	
16470/26050 (epoch 31.612), train_loss = 0.87330056, grad/param norm = 1.7925e-01, time/batch = 17.1449s	
16471/26050 (epoch 31.614), train_loss = 0.91897774, grad/param norm = 1.9691e-01, time/batch = 18.5637s	
16472/26050 (epoch 31.616), train_loss = 0.98655340, grad/param norm = 2.1675e-01, time/batch = 15.9606s	
16473/26050 (epoch 31.618), train_loss = 0.86358472, grad/param norm = 1.9813e-01, time/batch = 18.7348s	
16474/26050 (epoch 31.620), train_loss = 0.98032713, grad/param norm = 2.2007e-01, time/batch = 18.3203s	
16475/26050 (epoch 31.622), train_loss = 0.82126827, grad/param norm = 1.9190e-01, time/batch = 16.8981s	
16476/26050 (epoch 31.624), train_loss = 0.76764068, grad/param norm = 1.7150e-01, time/batch = 18.8935s	
16477/26050 (epoch 31.626), train_loss = 0.96153188, grad/param norm = 2.0840e-01, time/batch = 18.5384s	
16478/26050 (epoch 31.628), train_loss = 0.86416937, grad/param norm = 2.4163e-01, time/batch = 17.3940s	
16479/26050 (epoch 31.630), train_loss = 1.04678552, grad/param norm = 1.9209e-01, time/batch = 15.4526s	
16480/26050 (epoch 31.631), train_loss = 1.07385020, grad/param norm = 2.4026e-01, time/batch = 18.4992s	
16481/26050 (epoch 31.633), train_loss = 0.83052948, grad/param norm = 2.0198e-01, time/batch = 18.3188s	
16482/26050 (epoch 31.635), train_loss = 0.87682767, grad/param norm = 1.8806e-01, time/batch = 15.3732s	
16483/26050 (epoch 31.637), train_loss = 0.80866392, grad/param norm = 2.0090e-01, time/batch = 18.8171s	
16484/26050 (epoch 31.639), train_loss = 0.97271857, grad/param norm = 1.9757e-01, time/batch = 17.9040s	
16485/26050 (epoch 31.641), train_loss = 0.86858922, grad/param norm = 1.9833e-01, time/batch = 17.5615s	
16486/26050 (epoch 31.643), train_loss = 0.83665074, grad/param norm = 1.7193e-01, time/batch = 18.6628s	
16487/26050 (epoch 31.645), train_loss = 0.86210476, grad/param norm = 2.0275e-01, time/batch = 15.1156s	
16488/26050 (epoch 31.647), train_loss = 0.82798027, grad/param norm = 1.9286e-01, time/batch = 18.0745s	
16489/26050 (epoch 31.649), train_loss = 0.88737163, grad/param norm = 2.2941e-01, time/batch = 17.8180s	
16490/26050 (epoch 31.651), train_loss = 0.86594077, grad/param norm = 1.9904e-01, time/batch = 18.1561s	
16491/26050 (epoch 31.653), train_loss = 0.88921993, grad/param norm = 2.0546e-01, time/batch = 18.6719s	
16492/26050 (epoch 31.655), train_loss = 0.83545930, grad/param norm = 1.9138e-01, time/batch = 17.2243s	
16493/26050 (epoch 31.656), train_loss = 0.81600979, grad/param norm = 1.8583e-01, time/batch = 18.4736s	
16494/26050 (epoch 31.658), train_loss = 1.08786078, grad/param norm = 2.0953e-01, time/batch = 18.7232s	
16495/26050 (epoch 31.660), train_loss = 0.78499541, grad/param norm = 2.2806e-01, time/batch = 16.8987s	
16496/26050 (epoch 31.662), train_loss = 0.88307915, grad/param norm = 1.8944e-01, time/batch = 15.3793s	
16497/26050 (epoch 31.664), train_loss = 0.89541786, grad/param norm = 1.8814e-01, time/batch = 18.3957s	
16498/26050 (epoch 31.666), train_loss = 0.84930101, grad/param norm = 2.0400e-01, time/batch = 17.6601s	
16499/26050 (epoch 31.668), train_loss = 0.71858645, grad/param norm = 2.0605e-01, time/batch = 17.4754s	
16500/26050 (epoch 31.670), train_loss = 1.04041093, grad/param norm = 2.5071e-01, time/batch = 15.6526s	
16501/26050 (epoch 31.672), train_loss = 0.89580825, grad/param norm = 2.2025e-01, time/batch = 18.4684s	
16502/26050 (epoch 31.674), train_loss = 0.80326851, grad/param norm = 2.1904e-01, time/batch = 18.0596s	
16503/26050 (epoch 31.676), train_loss = 0.95994690, grad/param norm = 2.4237e-01, time/batch = 18.2317s	
16504/26050 (epoch 31.678), train_loss = 0.99275366, grad/param norm = 2.2543e-01, time/batch = 17.3847s	
16505/26050 (epoch 31.679), train_loss = 1.04487302, grad/param norm = 2.3378e-01, time/batch = 18.0291s	
16506/26050 (epoch 31.681), train_loss = 0.93903213, grad/param norm = 2.1600e-01, time/batch = 14.8818s	
16507/26050 (epoch 31.683), train_loss = 0.81263285, grad/param norm = 2.4257e-01, time/batch = 16.2537s	
16508/26050 (epoch 31.685), train_loss = 0.88375226, grad/param norm = 2.1490e-01, time/batch = 17.1578s	
16509/26050 (epoch 31.687), train_loss = 0.80045881, grad/param norm = 1.8754e-01, time/batch = 17.9839s	
16510/26050 (epoch 31.689), train_loss = 0.86821459, grad/param norm = 2.1037e-01, time/batch = 18.2234s	
16511/26050 (epoch 31.691), train_loss = 0.73230587, grad/param norm = 1.6567e-01, time/batch = 17.3016s	
16512/26050 (epoch 31.693), train_loss = 0.85381909, grad/param norm = 1.8818e-01, time/batch = 17.1996s	
16513/26050 (epoch 31.695), train_loss = 0.88863015, grad/param norm = 2.0717e-01, time/batch = 30.8185s	
16514/26050 (epoch 31.697), train_loss = 0.84352517, grad/param norm = 2.0820e-01, time/batch = 26.5153s	
16515/26050 (epoch 31.699), train_loss = 0.93238277, grad/param norm = 2.0900e-01, time/batch = 18.2316s	
16516/26050 (epoch 31.701), train_loss = 0.81331913, grad/param norm = 1.9165e-01, time/batch = 18.5634s	
16517/26050 (epoch 31.702), train_loss = 0.98988174, grad/param norm = 2.2100e-01, time/batch = 17.7940s	
16518/26050 (epoch 31.704), train_loss = 0.99968893, grad/param norm = 2.0900e-01, time/batch = 16.9573s	
16519/26050 (epoch 31.706), train_loss = 0.82962782, grad/param norm = 1.9189e-01, time/batch = 18.5690s	
16520/26050 (epoch 31.708), train_loss = 0.97183873, grad/param norm = 2.1234e-01, time/batch = 18.3292s	
16521/26050 (epoch 31.710), train_loss = 0.92069353, grad/param norm = 2.2676e-01, time/batch = 18.4842s	
16522/26050 (epoch 31.712), train_loss = 0.92776294, grad/param norm = 2.3288e-01, time/batch = 18.6499s	
16523/26050 (epoch 31.714), train_loss = 0.79902418, grad/param norm = 1.6848e-01, time/batch = 16.3024s	
16524/26050 (epoch 31.716), train_loss = 1.12992795, grad/param norm = 2.3377e-01, time/batch = 15.3844s	
16525/26050 (epoch 31.718), train_loss = 0.96684251, grad/param norm = 2.1947e-01, time/batch = 17.7323s	
16526/26050 (epoch 31.720), train_loss = 0.89662910, grad/param norm = 2.1240e-01, time/batch = 15.9663s	
16527/26050 (epoch 31.722), train_loss = 0.80946700, grad/param norm = 1.8289e-01, time/batch = 18.2565s	
16528/26050 (epoch 31.724), train_loss = 0.83697640, grad/param norm = 2.0458e-01, time/batch = 16.3172s	
16529/26050 (epoch 31.726), train_loss = 0.95674798, grad/param norm = 1.9460e-01, time/batch = 16.5542s	
16530/26050 (epoch 31.727), train_loss = 0.96273871, grad/param norm = 2.0971e-01, time/batch = 18.0667s	
16531/26050 (epoch 31.729), train_loss = 0.93404381, grad/param norm = 1.9885e-01, time/batch = 18.3240s	
16532/26050 (epoch 31.731), train_loss = 0.94653086, grad/param norm = 1.9979e-01, time/batch = 17.7329s	
16533/26050 (epoch 31.733), train_loss = 0.87710614, grad/param norm = 2.2591e-01, time/batch = 18.2341s	
16534/26050 (epoch 31.735), train_loss = 1.06583125, grad/param norm = 2.1882e-01, time/batch = 18.9030s	
16535/26050 (epoch 31.737), train_loss = 0.86239489, grad/param norm = 2.0073e-01, time/batch = 16.8164s	
16536/26050 (epoch 31.739), train_loss = 0.94579700, grad/param norm = 1.9250e-01, time/batch = 15.4084s	
16537/26050 (epoch 31.741), train_loss = 0.83636682, grad/param norm = 1.9519e-01, time/batch = 18.0581s	
16538/26050 (epoch 31.743), train_loss = 0.91011926, grad/param norm = 2.2524e-01, time/batch = 18.4047s	
16539/26050 (epoch 31.745), train_loss = 0.78940145, grad/param norm = 1.8678e-01, time/batch = 17.6509s	
16540/26050 (epoch 31.747), train_loss = 0.81473746, grad/param norm = 1.9148e-01, time/batch = 15.7002s	
16541/26050 (epoch 31.749), train_loss = 0.99464695, grad/param norm = 2.0761e-01, time/batch = 16.4678s	
16542/26050 (epoch 31.750), train_loss = 0.88166757, grad/param norm = 1.7217e-01, time/batch = 16.7065s	
16543/26050 (epoch 31.752), train_loss = 0.85805021, grad/param norm = 2.3967e-01, time/batch = 17.9012s	
16544/26050 (epoch 31.754), train_loss = 0.91124789, grad/param norm = 1.9709e-01, time/batch = 17.3285s	
16545/26050 (epoch 31.756), train_loss = 0.89431221, grad/param norm = 3.1182e-01, time/batch = 17.5646s	
16546/26050 (epoch 31.758), train_loss = 0.87658948, grad/param norm = 2.2263e-01, time/batch = 17.3808s	
16547/26050 (epoch 31.760), train_loss = 1.03762357, grad/param norm = 2.1133e-01, time/batch = 18.3232s	
16548/26050 (epoch 31.762), train_loss = 0.87354998, grad/param norm = 2.7806e-01, time/batch = 16.2990s	
16549/26050 (epoch 31.764), train_loss = 0.90139240, grad/param norm = 2.7810e-01, time/batch = 17.1576s	
16550/26050 (epoch 31.766), train_loss = 0.91978607, grad/param norm = 2.1593e-01, time/batch = 17.2438s	
16551/26050 (epoch 31.768), train_loss = 0.79385163, grad/param norm = 1.8949e-01, time/batch = 16.9790s	
16552/26050 (epoch 31.770), train_loss = 0.86313997, grad/param norm = 2.0859e-01, time/batch = 18.4793s	
16553/26050 (epoch 31.772), train_loss = 0.89600927, grad/param norm = 1.8402e-01, time/batch = 14.8988s	
16554/26050 (epoch 31.774), train_loss = 0.78640566, grad/param norm = 2.2728e-01, time/batch = 18.4869s	
16555/26050 (epoch 31.775), train_loss = 0.64708327, grad/param norm = 1.8772e-01, time/batch = 18.8056s	
16556/26050 (epoch 31.777), train_loss = 0.86277255, grad/param norm = 1.9661e-01, time/batch = 18.0542s	
16557/26050 (epoch 31.779), train_loss = 0.88951266, grad/param norm = 2.0307e-01, time/batch = 17.9865s	
16558/26050 (epoch 31.781), train_loss = 0.79425687, grad/param norm = 1.9564e-01, time/batch = 17.4088s	
16559/26050 (epoch 31.783), train_loss = 0.79471944, grad/param norm = 2.0313e-01, time/batch = 16.4825s	
16560/26050 (epoch 31.785), train_loss = 0.89634100, grad/param norm = 2.0126e-01, time/batch = 16.3131s	
16561/26050 (epoch 31.787), train_loss = 0.82667689, grad/param norm = 2.2998e-01, time/batch = 15.4629s	
16562/26050 (epoch 31.789), train_loss = 0.83492104, grad/param norm = 2.2009e-01, time/batch = 18.3110s	
16563/26050 (epoch 31.791), train_loss = 0.83526503, grad/param norm = 2.2380e-01, time/batch = 17.8047s	
16564/26050 (epoch 31.793), train_loss = 0.88968903, grad/param norm = 2.2263e-01, time/batch = 18.9020s	
16565/26050 (epoch 31.795), train_loss = 0.72163370, grad/param norm = 1.6527e-01, time/batch = 17.9026s	
16566/26050 (epoch 31.797), train_loss = 0.78698813, grad/param norm = 1.9581e-01, time/batch = 14.6339s	
16567/26050 (epoch 31.798), train_loss = 0.79889324, grad/param norm = 1.9414e-01, time/batch = 17.8835s	
16568/26050 (epoch 31.800), train_loss = 0.78558307, grad/param norm = 2.0571e-01, time/batch = 17.4829s	
16569/26050 (epoch 31.802), train_loss = 0.86034213, grad/param norm = 2.4398e-01, time/batch = 17.9936s	
16570/26050 (epoch 31.804), train_loss = 0.85720892, grad/param norm = 1.8998e-01, time/batch = 16.9701s	
16571/26050 (epoch 31.806), train_loss = 0.95464974, grad/param norm = 2.3452e-01, time/batch = 18.4755s	
16572/26050 (epoch 31.808), train_loss = 0.89685761, grad/param norm = 2.0895e-01, time/batch = 18.5691s	
16573/26050 (epoch 31.810), train_loss = 0.86879326, grad/param norm = 2.1255e-01, time/batch = 16.8747s	
16574/26050 (epoch 31.812), train_loss = 0.77424609, grad/param norm = 2.2636e-01, time/batch = 16.8950s	
16575/26050 (epoch 31.814), train_loss = 0.81169785, grad/param norm = 2.2798e-01, time/batch = 14.4647s	
16576/26050 (epoch 31.816), train_loss = 0.93141088, grad/param norm = 2.2990e-01, time/batch = 16.9698s	
16577/26050 (epoch 31.818), train_loss = 0.97773588, grad/param norm = 2.5035e-01, time/batch = 17.4907s	
16578/26050 (epoch 31.820), train_loss = 0.89637542, grad/param norm = 2.0052e-01, time/batch = 18.3934s	
16579/26050 (epoch 31.821), train_loss = 0.98893868, grad/param norm = 2.2739e-01, time/batch = 18.8140s	
16580/26050 (epoch 31.823), train_loss = 1.06944518, grad/param norm = 2.1830e-01, time/batch = 17.8071s	
16581/26050 (epoch 31.825), train_loss = 0.90679631, grad/param norm = 2.1858e-01, time/batch = 18.5606s	
16582/26050 (epoch 31.827), train_loss = 0.90888017, grad/param norm = 2.3328e-01, time/batch = 18.3161s	
16583/26050 (epoch 31.829), train_loss = 0.98256380, grad/param norm = 2.3273e-01, time/batch = 17.0536s	
16584/26050 (epoch 31.831), train_loss = 1.05377977, grad/param norm = 2.9959e-01, time/batch = 17.9901s	
16585/26050 (epoch 31.833), train_loss = 1.04421529, grad/param norm = 2.3411e-01, time/batch = 18.3321s	
16586/26050 (epoch 31.835), train_loss = 1.04296394, grad/param norm = 2.2413e-01, time/batch = 16.4617s	
16587/26050 (epoch 31.837), train_loss = 0.90270338, grad/param norm = 1.9396e-01, time/batch = 18.0622s	
16588/26050 (epoch 31.839), train_loss = 0.89681993, grad/param norm = 2.2827e-01, time/batch = 18.0751s	
16589/26050 (epoch 31.841), train_loss = 0.98071337, grad/param norm = 2.1366e-01, time/batch = 16.9677s	
16590/26050 (epoch 31.843), train_loss = 0.88353465, grad/param norm = 2.0081e-01, time/batch = 16.5617s	
16591/26050 (epoch 31.845), train_loss = 0.85499395, grad/param norm = 1.9915e-01, time/batch = 16.6486s	
16592/26050 (epoch 31.846), train_loss = 0.94685941, grad/param norm = 2.1990e-01, time/batch = 18.4905s	
16593/26050 (epoch 31.848), train_loss = 0.87683249, grad/param norm = 1.9639e-01, time/batch = 18.1469s	
16594/26050 (epoch 31.850), train_loss = 0.80598492, grad/param norm = 1.8981e-01, time/batch = 17.6562s	
16595/26050 (epoch 31.852), train_loss = 0.92435881, grad/param norm = 1.9620e-01, time/batch = 18.7419s	
16596/26050 (epoch 31.854), train_loss = 0.89714477, grad/param norm = 2.0884e-01, time/batch = 17.8808s	
16597/26050 (epoch 31.856), train_loss = 0.86747703, grad/param norm = 2.5598e-01, time/batch = 16.5662s	
16598/26050 (epoch 31.858), train_loss = 0.81604799, grad/param norm = 1.9557e-01, time/batch = 17.4554s	
16599/26050 (epoch 31.860), train_loss = 0.95267862, grad/param norm = 2.0949e-01, time/batch = 17.7245s	
16600/26050 (epoch 31.862), train_loss = 0.97752591, grad/param norm = 1.9772e-01, time/batch = 15.3070s	
16601/26050 (epoch 31.864), train_loss = 0.91830059, grad/param norm = 2.1946e-01, time/batch = 18.5496s	
16602/26050 (epoch 31.866), train_loss = 0.85051927, grad/param norm = 1.8540e-01, time/batch = 18.8188s	
16603/26050 (epoch 31.868), train_loss = 0.94635530, grad/param norm = 2.2931e-01, time/batch = 17.9778s	
16604/26050 (epoch 31.869), train_loss = 0.80827811, grad/param norm = 1.9855e-01, time/batch = 17.2384s	
16605/26050 (epoch 31.871), train_loss = 0.76533791, grad/param norm = 1.8869e-01, time/batch = 18.6603s	
16606/26050 (epoch 31.873), train_loss = 0.94317221, grad/param norm = 2.1346e-01, time/batch = 18.2382s	
16607/26050 (epoch 31.875), train_loss = 0.86278082, grad/param norm = 2.0222e-01, time/batch = 18.1428s	
16608/26050 (epoch 31.877), train_loss = 0.84367849, grad/param norm = 2.0286e-01, time/batch = 18.4854s	
16609/26050 (epoch 31.879), train_loss = 0.91316753, grad/param norm = 1.9278e-01, time/batch = 16.9827s	
16610/26050 (epoch 31.881), train_loss = 0.97408962, grad/param norm = 2.1999e-01, time/batch = 16.2864s	
16611/26050 (epoch 31.883), train_loss = 0.93432099, grad/param norm = 2.1692e-01, time/batch = 17.7297s	
16612/26050 (epoch 31.885), train_loss = 0.69044497, grad/param norm = 1.9509e-01, time/batch = 18.6614s	
16613/26050 (epoch 31.887), train_loss = 0.95837648, grad/param norm = 2.0903e-01, time/batch = 15.3045s	
16614/26050 (epoch 31.889), train_loss = 0.83301423, grad/param norm = 1.9422e-01, time/batch = 16.9820s	
16615/26050 (epoch 31.891), train_loss = 0.74692787, grad/param norm = 1.9048e-01, time/batch = 18.7346s	
16616/26050 (epoch 31.893), train_loss = 0.77271517, grad/param norm = 1.9848e-01, time/batch = 18.8236s	
16617/26050 (epoch 31.894), train_loss = 0.84720745, grad/param norm = 2.0405e-01, time/batch = 17.6362s	
16618/26050 (epoch 31.896), train_loss = 0.99710597, grad/param norm = 2.4424e-01, time/batch = 18.4798s	
16619/26050 (epoch 31.898), train_loss = 0.84426908, grad/param norm = 1.9422e-01, time/batch = 18.7269s	
16620/26050 (epoch 31.900), train_loss = 0.92982951, grad/param norm = 2.2631e-01, time/batch = 15.3738s	
16621/26050 (epoch 31.902), train_loss = 0.86572933, grad/param norm = 2.0360e-01, time/batch = 18.6619s	
16622/26050 (epoch 31.904), train_loss = 0.85408075, grad/param norm = 1.8832e-01, time/batch = 17.3422s	
16623/26050 (epoch 31.906), train_loss = 0.86445618, grad/param norm = 2.1244e-01, time/batch = 16.5439s	
16624/26050 (epoch 31.908), train_loss = 0.90710715, grad/param norm = 2.0117e-01, time/batch = 18.0713s	
16625/26050 (epoch 31.910), train_loss = 0.87478223, grad/param norm = 2.1688e-01, time/batch = 17.6437s	
16626/26050 (epoch 31.912), train_loss = 1.07160252, grad/param norm = 2.3884e-01, time/batch = 18.0544s	
16627/26050 (epoch 31.914), train_loss = 1.21700356, grad/param norm = 2.3279e-01, time/batch = 18.0435s	
16628/26050 (epoch 31.916), train_loss = 0.99940446, grad/param norm = 2.6720e-01, time/batch = 18.2348s	
16629/26050 (epoch 31.917), train_loss = 0.90699200, grad/param norm = 2.2334e-01, time/batch = 15.9813s	
16630/26050 (epoch 31.919), train_loss = 0.96789402, grad/param norm = 2.9410e-01, time/batch = 17.1453s	
16631/26050 (epoch 31.921), train_loss = 0.86486347, grad/param norm = 2.4944e-01, time/batch = 14.7195s	
16632/26050 (epoch 31.923), train_loss = 0.91583956, grad/param norm = 2.0810e-01, time/batch = 16.9661s	
16633/26050 (epoch 31.925), train_loss = 0.88944146, grad/param norm = 1.9743e-01, time/batch = 18.6628s	
16634/26050 (epoch 31.927), train_loss = 0.81633197, grad/param norm = 1.5778e-01, time/batch = 17.1502s	
16635/26050 (epoch 31.929), train_loss = 0.75107967, grad/param norm = 1.8036e-01, time/batch = 18.8168s	
16636/26050 (epoch 31.931), train_loss = 1.10212745, grad/param norm = 2.8714e-01, time/batch = 18.5553s	
16637/26050 (epoch 31.933), train_loss = 0.87525155, grad/param norm = 2.1108e-01, time/batch = 17.5663s	
16638/26050 (epoch 31.935), train_loss = 0.86790230, grad/param norm = 1.9578e-01, time/batch = 17.9272s	
16639/26050 (epoch 31.937), train_loss = 0.96836212, grad/param norm = 2.0229e-01, time/batch = 18.0743s	
16640/26050 (epoch 31.939), train_loss = 0.82069030, grad/param norm = 1.8499e-01, time/batch = 16.1616s	
16641/26050 (epoch 31.940), train_loss = 0.85691045, grad/param norm = 1.8970e-01, time/batch = 17.8888s	
16642/26050 (epoch 31.942), train_loss = 0.88179607, grad/param norm = 2.0587e-01, time/batch = 17.4911s	
16643/26050 (epoch 31.944), train_loss = 0.85461261, grad/param norm = 1.8438e-01, time/batch = 15.8041s	
16644/26050 (epoch 31.946), train_loss = 1.01085262, grad/param norm = 1.9756e-01, time/batch = 17.9795s	
16645/26050 (epoch 31.948), train_loss = 0.75232812, grad/param norm = 1.9030e-01, time/batch = 18.1491s	
16646/26050 (epoch 31.950), train_loss = 0.88748152, grad/param norm = 2.2132e-01, time/batch = 16.2371s	
16647/26050 (epoch 31.952), train_loss = 0.95268528, grad/param norm = 2.1206e-01, time/batch = 17.9661s	
16648/26050 (epoch 31.954), train_loss = 0.97708007, grad/param norm = 2.1835e-01, time/batch = 16.9809s	
16649/26050 (epoch 31.956), train_loss = 0.86127853, grad/param norm = 2.0855e-01, time/batch = 18.5562s	
16650/26050 (epoch 31.958), train_loss = 0.80423669, grad/param norm = 1.7491e-01, time/batch = 18.9832s	
16651/26050 (epoch 31.960), train_loss = 0.92571137, grad/param norm = 2.1034e-01, time/batch = 17.0556s	
16652/26050 (epoch 31.962), train_loss = 0.85811667, grad/param norm = 1.7478e-01, time/batch = 15.3863s	
16653/26050 (epoch 31.964), train_loss = 0.87613964, grad/param norm = 2.0754e-01, time/batch = 18.9082s	
16654/26050 (epoch 31.965), train_loss = 0.82075207, grad/param norm = 2.2512e-01, time/batch = 18.2390s	
16655/26050 (epoch 31.967), train_loss = 1.19721140, grad/param norm = 2.0422e-01, time/batch = 18.5651s	
16656/26050 (epoch 31.969), train_loss = 0.90415866, grad/param norm = 1.9351e-01, time/batch = 17.8297s	
16657/26050 (epoch 31.971), train_loss = 0.88491710, grad/param norm = 1.9536e-01, time/batch = 18.0688s	
16658/26050 (epoch 31.973), train_loss = 0.89094842, grad/param norm = 1.8663e-01, time/batch = 17.9058s	
16659/26050 (epoch 31.975), train_loss = 0.92924485, grad/param norm = 2.0320e-01, time/batch = 17.9567s	
16660/26050 (epoch 31.977), train_loss = 0.89775988, grad/param norm = 1.8481e-01, time/batch = 18.5748s	
16661/26050 (epoch 31.979), train_loss = 0.73616720, grad/param norm = 1.9846e-01, time/batch = 14.4640s	
16662/26050 (epoch 31.981), train_loss = 1.00684494, grad/param norm = 1.9582e-01, time/batch = 18.4971s	
16663/26050 (epoch 31.983), train_loss = 0.94724047, grad/param norm = 2.0149e-01, time/batch = 17.8250s	
16664/26050 (epoch 31.985), train_loss = 0.93366479, grad/param norm = 2.0686e-01, time/batch = 17.1458s	
16665/26050 (epoch 31.987), train_loss = 1.00057705, grad/param norm = 2.2239e-01, time/batch = 17.2357s	
16666/26050 (epoch 31.988), train_loss = 0.93836650, grad/param norm = 2.4016e-01, time/batch = 16.7398s	
16667/26050 (epoch 31.990), train_loss = 0.78087472, grad/param norm = 1.7176e-01, time/batch = 18.3067s	
16668/26050 (epoch 31.992), train_loss = 1.03799067, grad/param norm = 2.1191e-01, time/batch = 16.4047s	
16669/26050 (epoch 31.994), train_loss = 0.85573229, grad/param norm = 2.1948e-01, time/batch = 18.3071s	
16670/26050 (epoch 31.996), train_loss = 0.82013581, grad/param norm = 2.3006e-01, time/batch = 18.7313s	
16671/26050 (epoch 31.998), train_loss = 0.90713887, grad/param norm = 2.0448e-01, time/batch = 17.4016s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
16672/26050 (epoch 32.000), train_loss = 0.84726465, grad/param norm = 2.2167e-01, time/batch = 16.8877s	
16673/26050 (epoch 32.002), train_loss = 0.94726042, grad/param norm = 2.1630e-01, time/batch = 17.4082s	
16674/26050 (epoch 32.004), train_loss = 0.79611668, grad/param norm = 2.1852e-01, time/batch = 15.2327s	
16675/26050 (epoch 32.006), train_loss = 0.84267894, grad/param norm = 2.3563e-01, time/batch = 17.5626s	
16676/26050 (epoch 32.008), train_loss = 0.84065522, grad/param norm = 2.0321e-01, time/batch = 15.1389s	
16677/26050 (epoch 32.010), train_loss = 0.81725989, grad/param norm = 1.8857e-01, time/batch = 18.2444s	
16678/26050 (epoch 32.012), train_loss = 0.89948700, grad/param norm = 1.9567e-01, time/batch = 17.6385s	
16679/26050 (epoch 32.013), train_loss = 1.12469875, grad/param norm = 2.2758e-01, time/batch = 17.6634s	
16680/26050 (epoch 32.015), train_loss = 0.88004206, grad/param norm = 1.7238e-01, time/batch = 17.2466s	
16681/26050 (epoch 32.017), train_loss = 0.93737563, grad/param norm = 1.9892e-01, time/batch = 18.5681s	
16682/26050 (epoch 32.019), train_loss = 0.78021854, grad/param norm = 1.6118e-01, time/batch = 16.4637s	
16683/26050 (epoch 32.021), train_loss = 0.98374241, grad/param norm = 1.9547e-01, time/batch = 17.8969s	
16684/26050 (epoch 32.023), train_loss = 0.73557059, grad/param norm = 1.9104e-01, time/batch = 16.2263s	
16685/26050 (epoch 32.025), train_loss = 0.88140333, grad/param norm = 1.9727e-01, time/batch = 16.1368s	
16686/26050 (epoch 32.027), train_loss = 0.72313823, grad/param norm = 2.0525e-01, time/batch = 16.1189s	
16687/26050 (epoch 32.029), train_loss = 0.90558834, grad/param norm = 1.8133e-01, time/batch = 18.6329s	
16688/26050 (epoch 32.031), train_loss = 1.01032918, grad/param norm = 2.2879e-01, time/batch = 18.2351s	
16689/26050 (epoch 32.033), train_loss = 0.91510798, grad/param norm = 2.0173e-01, time/batch = 18.0622s	
16690/26050 (epoch 32.035), train_loss = 0.91965261, grad/param norm = 1.8837e-01, time/batch = 15.3898s	
16691/26050 (epoch 32.036), train_loss = 0.79442989, grad/param norm = 2.3360e-01, time/batch = 18.4900s	
16692/26050 (epoch 32.038), train_loss = 0.73062661, grad/param norm = 1.8359e-01, time/batch = 17.2335s	
16693/26050 (epoch 32.040), train_loss = 0.86410323, grad/param norm = 2.0108e-01, time/batch = 17.8904s	
16694/26050 (epoch 32.042), train_loss = 0.75422990, grad/param norm = 2.0090e-01, time/batch = 18.3927s	
16695/26050 (epoch 32.044), train_loss = 0.96065487, grad/param norm = 1.9198e-01, time/batch = 17.9043s	
16696/26050 (epoch 32.046), train_loss = 0.73768798, grad/param norm = 1.6856e-01, time/batch = 17.1463s	
16697/26050 (epoch 32.048), train_loss = 0.87929269, grad/param norm = 1.8879e-01, time/batch = 17.6425s	
16698/26050 (epoch 32.050), train_loss = 0.83105644, grad/param norm = 1.9773e-01, time/batch = 18.4190s	
16699/26050 (epoch 32.052), train_loss = 0.80930971, grad/param norm = 1.9984e-01, time/batch = 16.2908s	
16700/26050 (epoch 32.054), train_loss = 0.73111081, grad/param norm = 1.9057e-01, time/batch = 17.8913s	
16701/26050 (epoch 32.056), train_loss = 0.70993837, grad/param norm = 1.6712e-01, time/batch = 16.8200s	
16702/26050 (epoch 32.058), train_loss = 0.86880672, grad/param norm = 1.8912e-01, time/batch = 15.8956s	
16703/26050 (epoch 32.060), train_loss = 0.93913637, grad/param norm = 2.0161e-01, time/batch = 17.9160s	
16704/26050 (epoch 32.061), train_loss = 0.80031338, grad/param norm = 1.8826e-01, time/batch = 17.4672s	
16705/26050 (epoch 32.063), train_loss = 0.87254885, grad/param norm = 1.7835e-01, time/batch = 18.2311s	
16706/26050 (epoch 32.065), train_loss = 0.72671005, grad/param norm = 1.6663e-01, time/batch = 17.8793s	
16707/26050 (epoch 32.067), train_loss = 0.86439165, grad/param norm = 1.9640e-01, time/batch = 18.0755s	
16708/26050 (epoch 32.069), train_loss = 0.91555616, grad/param norm = 2.1622e-01, time/batch = 16.7321s	
16709/26050 (epoch 32.071), train_loss = 0.93127902, grad/param norm = 2.0354e-01, time/batch = 18.1347s	
16710/26050 (epoch 32.073), train_loss = 1.02220052, grad/param norm = 2.0032e-01, time/batch = 18.7436s	
16711/26050 (epoch 32.075), train_loss = 0.83460317, grad/param norm = 1.9424e-01, time/batch = 18.5827s	
16712/26050 (epoch 32.077), train_loss = 0.83764221, grad/param norm = 1.9483e-01, time/batch = 17.6529s	
16713/26050 (epoch 32.079), train_loss = 0.87058928, grad/param norm = 2.2176e-01, time/batch = 18.3927s	
16714/26050 (epoch 32.081), train_loss = 0.85069414, grad/param norm = 1.8142e-01, time/batch = 17.0620s	
16715/26050 (epoch 32.083), train_loss = 0.98537823, grad/param norm = 1.9618e-01, time/batch = 18.1393s	
16716/26050 (epoch 32.084), train_loss = 0.89035089, grad/param norm = 2.4325e-01, time/batch = 50.6896s	
