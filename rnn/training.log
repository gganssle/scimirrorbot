tput: No value for $TERM and no -T specified
vocab.t7 or data.t7 detected as stale. Re-running preprocessing...	
one-time setup: preprocessing input text file /home/ubuntu/scimirrorbot/dat/training/input.txt...	
loading text file...	
creating vocabulary mapping...	
putting data into tensor...	
saving /home/ubuntu/scimirrorbot/dat/training/vocab.t7	
saving /home/ubuntu/scimirrorbot/dat/training/data.t7	
loading data files...	
cutting off end of data so that the batches/sequences divide evenly	
reshaping tensor...	
data load done. Number of data batches in train: 455, val: 24, test: 0	
vocab size: 167	
creating an lstm with 2 layers	
setting forget gate biases to 1 in LSTM layer 1	
setting forget gate biases to 1 in LSTM layer 2	
number of parameters in the model: 305703	
cloning rnn	
cloning criterion	
1/22750 (epoch 0.002), train_loss = 5.09721118, grad/param norm = 4.1292e-01, time/batch = 0.7765s	
2/22750 (epoch 0.004), train_loss = 4.77010475, grad/param norm = 1.4888e+00, time/batch = 0.7159s	
3/22750 (epoch 0.007), train_loss = 4.29072892, grad/param norm = 1.0968e+00, time/batch = 0.7061s	
4/22750 (epoch 0.009), train_loss = 4.61846826, grad/param norm = 1.2378e+00, time/batch = 0.7382s	
5/22750 (epoch 0.011), train_loss = 4.32260996, grad/param norm = 1.0794e+00, time/batch = 0.7190s	
6/22750 (epoch 0.013), train_loss = 4.35623602, grad/param norm = 7.9464e-01, time/batch = 0.6993s	
7/22750 (epoch 0.015), train_loss = 4.24686416, grad/param norm = 6.1236e-01, time/batch = 0.6945s	
8/22750 (epoch 0.018), train_loss = 4.23696722, grad/param norm = 5.6177e-01, time/batch = 0.7054s	
9/22750 (epoch 0.020), train_loss = 4.26972774, grad/param norm = 6.4742e-01, time/batch = 0.7016s	
10/22750 (epoch 0.022), train_loss = 4.21803980, grad/param norm = 7.1547e-01, time/batch = 0.6958s	
11/22750 (epoch 0.024), train_loss = 4.10627629, grad/param norm = 6.0702e-01, time/batch = 0.7018s	
12/22750 (epoch 0.026), train_loss = 4.33948658, grad/param norm = 8.9670e-01, time/batch = 0.7038s	
13/22750 (epoch 0.029), train_loss = 4.17702946, grad/param norm = 9.2428e-01, time/batch = 0.7003s	
14/22750 (epoch 0.031), train_loss = 4.45303672, grad/param norm = 8.5426e-01, time/batch = 0.6974s	
15/22750 (epoch 0.033), train_loss = 4.36719507, grad/param norm = 4.8566e-01, time/batch = 0.7027s	
16/22750 (epoch 0.035), train_loss = 4.34913377, grad/param norm = 7.1507e-01, time/batch = 0.6979s	
17/22750 (epoch 0.037), train_loss = 4.38080194, grad/param norm = 5.5927e-01, time/batch = 0.6980s	
18/22750 (epoch 0.040), train_loss = 4.30641058, grad/param norm = 7.4206e-01, time/batch = 0.7012s	
19/22750 (epoch 0.042), train_loss = 4.32661646, grad/param norm = 4.6530e-01, time/batch = 0.7050s	
20/22750 (epoch 0.044), train_loss = 4.22582494, grad/param norm = 7.1318e-01, time/batch = 0.6988s	
21/22750 (epoch 0.046), train_loss = 4.05638776, grad/param norm = 8.0192e-01, time/batch = 0.7028s	
22/22750 (epoch 0.048), train_loss = 4.18185808, grad/param norm = 8.2153e-01, time/batch = 0.6959s	
23/22750 (epoch 0.051), train_loss = 4.18061437, grad/param norm = 6.4739e-01, time/batch = 0.7009s	
24/22750 (epoch 0.053), train_loss = 4.17862542, grad/param norm = 7.6203e-01, time/batch = 0.6999s	
25/22750 (epoch 0.055), train_loss = 4.35683233, grad/param norm = 6.4828e-01, time/batch = 0.7039s	
26/22750 (epoch 0.057), train_loss = 4.22379745, grad/param norm = 7.2841e-01, time/batch = 0.6986s	
27/22750 (epoch 0.059), train_loss = 4.24749123, grad/param norm = 5.9709e-01, time/batch = 0.7009s	
28/22750 (epoch 0.062), train_loss = 4.15507573, grad/param norm = 5.6424e-01, time/batch = 0.7009s	
29/22750 (epoch 0.064), train_loss = 4.10994731, grad/param norm = 7.4910e-01, time/batch = 0.6970s	
30/22750 (epoch 0.066), train_loss = 3.94137728, grad/param norm = 5.9111e-01, time/batch = 0.6969s	
31/22750 (epoch 0.068), train_loss = 4.13859606, grad/param norm = 1.0643e+00, time/batch = 0.7035s	
32/22750 (epoch 0.070), train_loss = 3.90578065, grad/param norm = 1.2052e+00, time/batch = 0.7015s	
33/22750 (epoch 0.073), train_loss = 4.06569778, grad/param norm = 7.7661e-01, time/batch = 0.7198s	
34/22750 (epoch 0.075), train_loss = 4.17158813, grad/param norm = 5.6096e-01, time/batch = 0.7064s	
35/22750 (epoch 0.077), train_loss = 4.04790278, grad/param norm = 5.4535e-01, time/batch = 0.7048s	
36/22750 (epoch 0.079), train_loss = 3.92155731, grad/param norm = 7.1104e-01, time/batch = 0.6989s	
37/22750 (epoch 0.081), train_loss = 4.16011858, grad/param norm = 8.0361e-01, time/batch = 0.7013s	
38/22750 (epoch 0.084), train_loss = 4.21836724, grad/param norm = 7.0903e-01, time/batch = 0.6983s	
39/22750 (epoch 0.086), train_loss = 4.24073574, grad/param norm = 7.4814e-01, time/batch = 0.7012s	
40/22750 (epoch 0.088), train_loss = 4.12748379, grad/param norm = 5.9654e-01, time/batch = 0.7038s	
41/22750 (epoch 0.090), train_loss = 4.18457370, grad/param norm = 6.2748e-01, time/batch = 0.7010s	
42/22750 (epoch 0.092), train_loss = 4.20166961, grad/param norm = 7.5727e-01, time/batch = 0.6966s	
43/22750 (epoch 0.095), train_loss = 4.22537622, grad/param norm = 5.7661e-01, time/batch = 0.6990s	
44/22750 (epoch 0.097), train_loss = 4.22888286, grad/param norm = 5.5113e-01, time/batch = 0.7071s	
45/22750 (epoch 0.099), train_loss = 4.24796850, grad/param norm = 5.6525e-01, time/batch = 0.6990s	
46/22750 (epoch 0.101), train_loss = 4.11073626, grad/param norm = 5.6529e-01, time/batch = 0.7007s	
47/22750 (epoch 0.103), train_loss = 4.16760221, grad/param norm = 1.7116e+00, time/batch = 0.7006s	
48/22750 (epoch 0.105), train_loss = 4.09434707, grad/param norm = 1.1982e+00, time/batch = 0.7026s	
49/22750 (epoch 0.108), train_loss = 4.05560855, grad/param norm = 1.9812e+00, time/batch = 0.7033s	
50/22750 (epoch 0.110), train_loss = 4.04694312, grad/param norm = 7.0581e-01, time/batch = 0.7036s	
51/22750 (epoch 0.112), train_loss = 3.95920981, grad/param norm = 5.4017e-01, time/batch = 0.6987s	
52/22750 (epoch 0.114), train_loss = 3.77479366, grad/param norm = 6.5542e-01, time/batch = 0.6970s	
53/22750 (epoch 0.116), train_loss = 3.70144288, grad/param norm = 4.8145e-01, time/batch = 0.7010s	
54/22750 (epoch 0.119), train_loss = 3.82856810, grad/param norm = 5.5176e-01, time/batch = 0.6980s	
55/22750 (epoch 0.121), train_loss = 3.87182315, grad/param norm = 7.2951e-01, time/batch = 0.6983s	
56/22750 (epoch 0.123), train_loss = 3.73841775, grad/param norm = 5.5333e-01, time/batch = 0.6997s	
57/22750 (epoch 0.125), train_loss = 3.71960465, grad/param norm = 5.1348e-01, time/batch = 0.7031s	
58/22750 (epoch 0.127), train_loss = 3.66878748, grad/param norm = 5.1442e-01, time/batch = 0.7023s	
59/22750 (epoch 0.130), train_loss = 3.79687100, grad/param norm = 5.5933e-01, time/batch = 0.7145s	
60/22750 (epoch 0.132), train_loss = 3.68850334, grad/param norm = 6.6329e-01, time/batch = 0.7043s	
61/22750 (epoch 0.134), train_loss = 3.80027181, grad/param norm = 8.5956e-01, time/batch = 0.7057s	
62/22750 (epoch 0.136), train_loss = 3.76414562, grad/param norm = 1.8906e+00, time/batch = 0.7007s	
63/22750 (epoch 0.138), train_loss = 3.64370238, grad/param norm = 6.6937e-01, time/batch = 0.7030s	
64/22750 (epoch 0.141), train_loss = 3.75188986, grad/param norm = 5.9364e-01, time/batch = 0.6980s	
65/22750 (epoch 0.143), train_loss = 3.63764134, grad/param norm = 6.0826e-01, time/batch = 0.7029s	
66/22750 (epoch 0.145), train_loss = 3.68046210, grad/param norm = 5.5697e-01, time/batch = 0.7013s	
67/22750 (epoch 0.147), train_loss = 3.53982483, grad/param norm = 4.6986e-01, time/batch = 0.7041s	
68/22750 (epoch 0.149), train_loss = 3.57620191, grad/param norm = 5.1765e-01, time/batch = 0.7024s	
69/22750 (epoch 0.152), train_loss = 3.61802701, grad/param norm = 6.2889e-01, time/batch = 0.7030s	
70/22750 (epoch 0.154), train_loss = 3.64801967, grad/param norm = 5.2289e-01, time/batch = 0.7070s	
71/22750 (epoch 0.156), train_loss = 3.77713279, grad/param norm = 6.1940e-01, time/batch = 0.7070s	
72/22750 (epoch 0.158), train_loss = 3.89989268, grad/param norm = 1.7582e+00, time/batch = 0.7110s	
73/22750 (epoch 0.160), train_loss = 3.65838790, grad/param norm = 4.6099e-01, time/batch = 0.7221s	
74/22750 (epoch 0.163), train_loss = 3.61638084, grad/param norm = 5.9369e-01, time/batch = 0.7146s	
75/22750 (epoch 0.165), train_loss = 3.71225466, grad/param norm = 6.8692e-01, time/batch = 0.7238s	
76/22750 (epoch 0.167), train_loss = 3.68215552, grad/param norm = 6.0298e-01, time/batch = 0.7228s	
77/22750 (epoch 0.169), train_loss = 3.70361315, grad/param norm = 4.3974e-01, time/batch = 0.7114s	
78/22750 (epoch 0.171), train_loss = 3.60723664, grad/param norm = 4.4431e-01, time/batch = 0.7038s	
79/22750 (epoch 0.174), train_loss = 3.47399619, grad/param norm = 4.1663e-01, time/batch = 0.7067s	
80/22750 (epoch 0.176), train_loss = 3.48728256, grad/param norm = 4.5068e-01, time/batch = 0.7038s	
81/22750 (epoch 0.178), train_loss = 3.67747443, grad/param norm = 4.6992e-01, time/batch = 0.7052s	
82/22750 (epoch 0.180), train_loss = 3.66532699, grad/param norm = 5.1306e-01, time/batch = 0.7045s	
83/22750 (epoch 0.182), train_loss = 3.66876542, grad/param norm = 5.3338e-01, time/batch = 0.7039s	
84/22750 (epoch 0.185), train_loss = 3.61422024, grad/param norm = 5.5718e-01, time/batch = 0.7060s	
85/22750 (epoch 0.187), train_loss = 3.69587120, grad/param norm = 5.4494e-01, time/batch = 0.7021s	
86/22750 (epoch 0.189), train_loss = 3.57819790, grad/param norm = 4.9975e-01, time/batch = 0.7169s	
87/22750 (epoch 0.191), train_loss = 3.55014752, grad/param norm = 5.0425e-01, time/batch = 0.7090s	
88/22750 (epoch 0.193), train_loss = 3.55330075, grad/param norm = 3.6701e-01, time/batch = 0.7018s	
89/22750 (epoch 0.196), train_loss = 3.81388640, grad/param norm = 5.8564e-01, time/batch = 0.7098s	
90/22750 (epoch 0.198), train_loss = 3.66151936, grad/param norm = 9.7036e-01, time/batch = 0.6998s	
91/22750 (epoch 0.200), train_loss = 3.75476027, grad/param norm = 1.0319e+00, time/batch = 0.7005s	
92/22750 (epoch 0.202), train_loss = 3.80714956, grad/param norm = 4.8233e-01, time/batch = 0.7082s	
93/22750 (epoch 0.204), train_loss = 3.77143342, grad/param norm = 5.1312e-01, time/batch = 0.7301s	
94/22750 (epoch 0.207), train_loss = 3.46850251, grad/param norm = 5.4616e-01, time/batch = 0.7268s	
95/22750 (epoch 0.209), train_loss = 3.82626809, grad/param norm = 6.2729e-01, time/batch = 0.7252s	
96/22750 (epoch 0.211), train_loss = 3.55966605, grad/param norm = 6.5591e-01, time/batch = 0.7142s	
97/22750 (epoch 0.213), train_loss = 3.68249586, grad/param norm = 5.3157e-01, time/batch = 0.6966s	
98/22750 (epoch 0.215), train_loss = 3.81956919, grad/param norm = 6.8990e-01, time/batch = 0.7002s	
99/22750 (epoch 0.218), train_loss = 3.45765906, grad/param norm = 7.0479e-01, time/batch = 0.6984s	
100/22750 (epoch 0.220), train_loss = 3.81192045, grad/param norm = 1.0985e+00, time/batch = 0.7063s	
101/22750 (epoch 0.222), train_loss = 3.61466679, grad/param norm = 6.5254e-01, time/batch = 0.7054s	
102/22750 (epoch 0.224), train_loss = 3.69499253, grad/param norm = 5.8829e-01, time/batch = 0.7006s	
103/22750 (epoch 0.226), train_loss = 3.57308229, grad/param norm = 5.5773e-01, time/batch = 0.7046s	
104/22750 (epoch 0.229), train_loss = 3.77586798, grad/param norm = 6.5435e-01, time/batch = 0.7042s	
105/22750 (epoch 0.231), train_loss = 3.75537380, grad/param norm = 1.1235e+00, time/batch = 0.7024s	
106/22750 (epoch 0.233), train_loss = 3.71139041, grad/param norm = 7.6257e-01, time/batch = 0.7013s	
107/22750 (epoch 0.235), train_loss = 3.50689719, grad/param norm = 5.2078e-01, time/batch = 0.7048s	
108/22750 (epoch 0.237), train_loss = 3.51309209, grad/param norm = 5.9572e-01, time/batch = 0.7055s	
109/22750 (epoch 0.240), train_loss = 3.80153097, grad/param norm = 5.8140e-01, time/batch = 0.7057s	
110/22750 (epoch 0.242), train_loss = 3.53765136, grad/param norm = 5.2178e-01, time/batch = 0.7001s	
111/22750 (epoch 0.244), train_loss = 3.46599551, grad/param norm = 5.7969e-01, time/batch = 0.7046s	
112/22750 (epoch 0.246), train_loss = 3.81103895, grad/param norm = 6.7228e-01, time/batch = 0.7011s	
113/22750 (epoch 0.248), train_loss = 3.39887212, grad/param norm = 9.1796e-01, time/batch = 0.7031s	
114/22750 (epoch 0.251), train_loss = 3.60201614, grad/param norm = 8.7497e-01, time/batch = 0.6993s	
115/22750 (epoch 0.253), train_loss = 3.39700558, grad/param norm = 7.5227e-01, time/batch = 0.7000s	
116/22750 (epoch 0.255), train_loss = 3.58469240, grad/param norm = 7.0047e-01, time/batch = 0.6986s	
117/22750 (epoch 0.257), train_loss = 3.56294707, grad/param norm = 8.4463e-01, time/batch = 0.7066s	
118/22750 (epoch 0.259), train_loss = 3.57509562, grad/param norm = 7.7307e-01, time/batch = 0.6981s	
119/22750 (epoch 0.262), train_loss = 3.49741613, grad/param norm = 1.0596e+00, time/batch = 0.7001s	
120/22750 (epoch 0.264), train_loss = 3.59064673, grad/param norm = 9.3607e-01, time/batch = 0.6989s	
121/22750 (epoch 0.266), train_loss = 3.37065325, grad/param norm = 4.7621e-01, time/batch = 0.7016s	
122/22750 (epoch 0.268), train_loss = 3.33562172, grad/param norm = 3.9616e-01, time/batch = 0.7062s	
123/22750 (epoch 0.270), train_loss = 3.24245955, grad/param norm = 7.0559e-01, time/batch = 0.7044s	
124/22750 (epoch 0.273), train_loss = 3.32089860, grad/param norm = 6.2948e-01, time/batch = 0.7066s	
125/22750 (epoch 0.275), train_loss = 3.21426714, grad/param norm = 7.6727e-01, time/batch = 0.7066s	
126/22750 (epoch 0.277), train_loss = 3.57062415, grad/param norm = 9.1519e-01, time/batch = 0.7086s	
127/22750 (epoch 0.279), train_loss = 3.28926917, grad/param norm = 1.2233e+00, time/batch = 0.7022s	
128/22750 (epoch 0.281), train_loss = 3.20906601, grad/param norm = 7.0805e-01, time/batch = 0.7027s	
129/22750 (epoch 0.284), train_loss = 3.07658760, grad/param norm = 4.8012e-01, time/batch = 0.7032s	
130/22750 (epoch 0.286), train_loss = 3.26544021, grad/param norm = 4.8430e-01, time/batch = 0.7034s	
131/22750 (epoch 0.288), train_loss = 3.30878190, grad/param norm = 4.2683e-01, time/batch = 0.7045s	
132/22750 (epoch 0.290), train_loss = 3.07160088, grad/param norm = 5.8411e-01, time/batch = 0.7077s	
133/22750 (epoch 0.292), train_loss = 3.29920507, grad/param norm = 1.1807e+00, time/batch = 0.7073s	
134/22750 (epoch 0.295), train_loss = 3.32398617, grad/param norm = 1.5508e+00, time/batch = 0.7027s	
135/22750 (epoch 0.297), train_loss = 3.16450685, grad/param norm = 4.7503e-01, time/batch = 0.7309s	
136/22750 (epoch 0.299), train_loss = 3.26805584, grad/param norm = 3.9728e-01, time/batch = 0.7037s	
137/22750 (epoch 0.301), train_loss = 3.37550683, grad/param norm = 4.2566e-01, time/batch = 0.7137s	
138/22750 (epoch 0.303), train_loss = 3.28202875, grad/param norm = 4.0846e-01, time/batch = 0.7064s	
139/22750 (epoch 0.305), train_loss = 3.40687328, grad/param norm = 5.9728e-01, time/batch = 0.7022s	
140/22750 (epoch 0.308), train_loss = 3.14047314, grad/param norm = 7.8052e-01, time/batch = 0.7010s	
141/22750 (epoch 0.310), train_loss = 2.99944160, grad/param norm = 7.5520e-01, time/batch = 0.7059s	
142/22750 (epoch 0.312), train_loss = 3.11806430, grad/param norm = 8.2960e-01, time/batch = 0.6980s	
143/22750 (epoch 0.314), train_loss = 3.26892686, grad/param norm = 5.5660e-01, time/batch = 0.7013s	
144/22750 (epoch 0.316), train_loss = 3.09226476, grad/param norm = 4.0874e-01, time/batch = 0.7157s	
145/22750 (epoch 0.319), train_loss = 3.14930874, grad/param norm = 5.7482e-01, time/batch = 0.7045s	
146/22750 (epoch 0.321), train_loss = 3.21067452, grad/param norm = 6.6200e-01, time/batch = 0.7056s	
147/22750 (epoch 0.323), train_loss = 2.72519019, grad/param norm = 5.4453e-01, time/batch = 0.7001s	
148/22750 (epoch 0.325), train_loss = 3.08022773, grad/param norm = 6.5790e-01, time/batch = 0.7036s	
149/22750 (epoch 0.327), train_loss = 3.52480345, grad/param norm = 6.9543e-01, time/batch = 0.7010s	
150/22750 (epoch 0.330), train_loss = 3.25660661, grad/param norm = 6.7021e-01, time/batch = 0.7020s	
151/22750 (epoch 0.332), train_loss = 3.14711718, grad/param norm = 4.7170e-01, time/batch = 0.7077s	
152/22750 (epoch 0.334), train_loss = 3.12595270, grad/param norm = 7.7282e-01, time/batch = 0.7105s	
153/22750 (epoch 0.336), train_loss = 3.12414162, grad/param norm = 9.0822e-01, time/batch = 0.7071s	
154/22750 (epoch 0.338), train_loss = 3.35726464, grad/param norm = 6.3389e-01, time/batch = 0.7052s	
155/22750 (epoch 0.341), train_loss = 3.04255917, grad/param norm = 4.3435e-01, time/batch = 0.7075s	
156/22750 (epoch 0.343), train_loss = 3.00106661, grad/param norm = 3.0598e-01, time/batch = 0.7032s	
157/22750 (epoch 0.345), train_loss = 3.20109035, grad/param norm = 3.7097e-01, time/batch = 0.7012s	
158/22750 (epoch 0.347), train_loss = 3.07319258, grad/param norm = 4.7581e-01, time/batch = 0.7074s	
159/22750 (epoch 0.349), train_loss = 2.88907658, grad/param norm = 8.4049e-01, time/batch = 0.7105s	
160/22750 (epoch 0.352), train_loss = 3.15783234, grad/param norm = 8.9271e-01, time/batch = 0.7239s	
161/22750 (epoch 0.354), train_loss = 3.17208938, grad/param norm = 6.8542e-01, time/batch = 0.7264s	
162/22750 (epoch 0.356), train_loss = 3.16608241, grad/param norm = 5.0160e-01, time/batch = 0.7263s	
163/22750 (epoch 0.358), train_loss = 2.97607824, grad/param norm = 3.8184e-01, time/batch = 0.7252s	
164/22750 (epoch 0.360), train_loss = 3.25602322, grad/param norm = 4.1899e-01, time/batch = 0.7279s	
165/22750 (epoch 0.363), train_loss = 3.21954137, grad/param norm = 7.5652e-01, time/batch = 0.7190s	
166/22750 (epoch 0.365), train_loss = 2.69819196, grad/param norm = 8.6309e-01, time/batch = 0.7185s	
167/22750 (epoch 0.367), train_loss = 2.61783865, grad/param norm = 9.3302e-01, time/batch = 0.7137s	
168/22750 (epoch 0.369), train_loss = 2.87953800, grad/param norm = 5.9048e-01, time/batch = 0.7086s	
169/22750 (epoch 0.371), train_loss = 2.83344405, grad/param norm = 3.1483e-01, time/batch = 0.7145s	
170/22750 (epoch 0.374), train_loss = 2.67632476, grad/param norm = 3.9468e-01, time/batch = 0.7176s	
171/22750 (epoch 0.376), train_loss = 3.08786411, grad/param norm = 7.0804e-01, time/batch = 0.7106s	
172/22750 (epoch 0.378), train_loss = 2.93195164, grad/param norm = 7.5696e-01, time/batch = 0.7090s	
173/22750 (epoch 0.380), train_loss = 3.15079826, grad/param norm = 6.2745e-01, time/batch = 0.7235s	
174/22750 (epoch 0.382), train_loss = 2.86666256, grad/param norm = 5.8212e-01, time/batch = 0.7096s	
175/22750 (epoch 0.385), train_loss = 3.05870162, grad/param norm = 6.8437e-01, time/batch = 0.7158s	
176/22750 (epoch 0.387), train_loss = 2.99326574, grad/param norm = 6.2235e-01, time/batch = 0.7100s	
177/22750 (epoch 0.389), train_loss = 2.70372911, grad/param norm = 6.0638e-01, time/batch = 0.7029s	
178/22750 (epoch 0.391), train_loss = 2.77634087, grad/param norm = 4.0236e-01, time/batch = 0.7023s	
179/22750 (epoch 0.393), train_loss = 2.82520090, grad/param norm = 5.7035e-01, time/batch = 0.7066s	
180/22750 (epoch 0.396), train_loss = 3.01429399, grad/param norm = 4.2473e-01, time/batch = 0.7067s	
181/22750 (epoch 0.398), train_loss = 2.95846240, grad/param norm = 8.4526e-01, time/batch = 0.7146s	
182/22750 (epoch 0.400), train_loss = 3.05314646, grad/param norm = 8.4749e-01, time/batch = 0.7073s	
183/22750 (epoch 0.402), train_loss = 3.11181950, grad/param norm = 4.3371e-01, time/batch = 0.7105s	
184/22750 (epoch 0.404), train_loss = 3.10988210, grad/param norm = 4.1376e-01, time/batch = 0.7162s	
185/22750 (epoch 0.407), train_loss = 3.01089613, grad/param norm = 4.2534e-01, time/batch = 0.7148s	
186/22750 (epoch 0.409), train_loss = 2.99198378, grad/param norm = 4.3330e-01, time/batch = 0.7103s	
187/22750 (epoch 0.411), train_loss = 2.91855261, grad/param norm = 5.9521e-01, time/batch = 0.7274s	
188/22750 (epoch 0.413), train_loss = 2.95852643, grad/param norm = 7.1637e-01, time/batch = 0.7195s	
189/22750 (epoch 0.415), train_loss = 2.85031346, grad/param norm = 4.7057e-01, time/batch = 0.7221s	
190/22750 (epoch 0.418), train_loss = 2.68175300, grad/param norm = 4.1236e-01, time/batch = 0.7231s	
191/22750 (epoch 0.420), train_loss = 3.10344197, grad/param norm = 4.4243e-01, time/batch = 0.7216s	
192/22750 (epoch 0.422), train_loss = 3.12835922, grad/param norm = 4.6526e-01, time/batch = 0.7037s	
193/22750 (epoch 0.424), train_loss = 3.31618579, grad/param norm = 6.6803e-01, time/batch = 0.7018s	
194/22750 (epoch 0.426), train_loss = 3.09199545, grad/param norm = 6.7799e-01, time/batch = 0.6901s	
195/22750 (epoch 0.429), train_loss = 2.63216586, grad/param norm = 8.0584e-01, time/batch = 0.6924s	
196/22750 (epoch 0.431), train_loss = 2.85495550, grad/param norm = 6.6860e-01, time/batch = 0.6891s	
197/22750 (epoch 0.433), train_loss = 2.67596454, grad/param norm = 4.9554e-01, time/batch = 0.7076s	
198/22750 (epoch 0.435), train_loss = 3.02866404, grad/param norm = 5.4540e-01, time/batch = 0.7039s	
199/22750 (epoch 0.437), train_loss = 3.07877960, grad/param norm = 5.5736e-01, time/batch = 0.6972s	
200/22750 (epoch 0.440), train_loss = 3.16895509, grad/param norm = 8.3140e-01, time/batch = 0.6984s	
201/22750 (epoch 0.442), train_loss = 3.11360888, grad/param norm = 7.4651e-01, time/batch = 0.6954s	
202/22750 (epoch 0.444), train_loss = 3.21419030, grad/param norm = 4.5571e-01, time/batch = 0.6920s	
203/22750 (epoch 0.446), train_loss = 2.98612830, grad/param norm = 9.9194e-01, time/batch = 0.6875s	
204/22750 (epoch 0.448), train_loss = 3.22606651, grad/param norm = 7.2749e-01, time/batch = 0.6903s	
205/22750 (epoch 0.451), train_loss = 3.16718296, grad/param norm = 4.8284e-01, time/batch = 0.6895s	
206/22750 (epoch 0.453), train_loss = 3.25491447, grad/param norm = 4.6137e-01, time/batch = 0.6892s	
207/22750 (epoch 0.455), train_loss = 3.25842228, grad/param norm = 7.8133e-01, time/batch = 0.6943s	
208/22750 (epoch 0.457), train_loss = 3.38632683, grad/param norm = 1.9399e+00, time/batch = 0.6970s	
209/22750 (epoch 0.459), train_loss = 3.29228145, grad/param norm = 1.9142e+00, time/batch = 0.7057s	
210/22750 (epoch 0.462), train_loss = 2.99467293, grad/param norm = 5.5032e-01, time/batch = 0.7047s	
211/22750 (epoch 0.464), train_loss = 2.67106211, grad/param norm = 3.9540e-01, time/batch = 0.7025s	
212/22750 (epoch 0.466), train_loss = 2.84033581, grad/param norm = 3.9367e-01, time/batch = 0.7003s	
213/22750 (epoch 0.468), train_loss = 2.70555457, grad/param norm = 4.0430e-01, time/batch = 0.6986s	
214/22750 (epoch 0.470), train_loss = 2.94652767, grad/param norm = 4.5254e-01, time/batch = 0.7020s	
215/22750 (epoch 0.473), train_loss = 2.87629006, grad/param norm = 4.9914e-01, time/batch = 0.6996s	
216/22750 (epoch 0.475), train_loss = 2.98475950, grad/param norm = 4.3425e-01, time/batch = 0.6957s	
217/22750 (epoch 0.477), train_loss = 2.78739760, grad/param norm = 5.8592e-01, time/batch = 0.6895s	
218/22750 (epoch 0.479), train_loss = 2.87583185, grad/param norm = 4.5813e-01, time/batch = 0.7117s	
219/22750 (epoch 0.481), train_loss = 2.77913747, grad/param norm = 4.6558e-01, time/batch = 0.7024s	
220/22750 (epoch 0.484), train_loss = 2.73183012, grad/param norm = 3.4540e-01, time/batch = 0.6959s	
221/22750 (epoch 0.486), train_loss = 2.90468928, grad/param norm = 4.8981e-01, time/batch = 0.6984s	
222/22750 (epoch 0.488), train_loss = 2.56133371, grad/param norm = 7.0507e-01, time/batch = 0.6879s	
223/22750 (epoch 0.490), train_loss = 2.75352179, grad/param norm = 5.2793e-01, time/batch = 0.6938s	
224/22750 (epoch 0.492), train_loss = 2.92384309, grad/param norm = 4.0014e-01, time/batch = 0.6874s	
225/22750 (epoch 0.495), train_loss = 2.70444060, grad/param norm = 4.8763e-01, time/batch = 0.6844s	
226/22750 (epoch 0.497), train_loss = 2.84350366, grad/param norm = 5.9270e-01, time/batch = 0.6845s	
227/22750 (epoch 0.499), train_loss = 2.89896520, grad/param norm = 5.5962e-01, time/batch = 0.6867s	
228/22750 (epoch 0.501), train_loss = 2.76111256, grad/param norm = 3.6891e-01, time/batch = 0.6856s	
229/22750 (epoch 0.503), train_loss = 2.86102415, grad/param norm = 3.4280e-01, time/batch = 0.6963s	
230/22750 (epoch 0.505), train_loss = 2.76955275, grad/param norm = 3.8132e-01, time/batch = 0.6946s	
231/22750 (epoch 0.508), train_loss = 2.70001384, grad/param norm = 6.3625e-01, time/batch = 0.6888s	
232/22750 (epoch 0.510), train_loss = 2.81305099, grad/param norm = 6.3444e-01, time/batch = 0.6909s	
233/22750 (epoch 0.512), train_loss = 2.66766506, grad/param norm = 5.7086e-01, time/batch = 0.6892s	
234/22750 (epoch 0.514), train_loss = 2.95032049, grad/param norm = 4.7937e-01, time/batch = 0.6867s	
235/22750 (epoch 0.516), train_loss = 2.74756496, grad/param norm = 5.3980e-01, time/batch = 0.6907s	
236/22750 (epoch 0.519), train_loss = 2.98143561, grad/param norm = 6.6764e-01, time/batch = 0.6930s	
237/22750 (epoch 0.521), train_loss = 2.85832986, grad/param norm = 9.9091e-01, time/batch = 0.6926s	
238/22750 (epoch 0.523), train_loss = 2.76023996, grad/param norm = 9.9354e-01, time/batch = 0.6872s	
239/22750 (epoch 0.525), train_loss = 2.93836220, grad/param norm = 4.1938e-01, time/batch = 0.6858s	
240/22750 (epoch 0.527), train_loss = 2.85462488, grad/param norm = 4.4017e-01, time/batch = 0.6870s	
241/22750 (epoch 0.530), train_loss = 2.90406995, grad/param norm = 5.0771e-01, time/batch = 0.6881s	
242/22750 (epoch 0.532), train_loss = 2.92344991, grad/param norm = 6.5338e-01, time/batch = 0.6910s	
243/22750 (epoch 0.534), train_loss = 2.86847450, grad/param norm = 5.6075e-01, time/batch = 0.6918s	
244/22750 (epoch 0.536), train_loss = 2.86269572, grad/param norm = 4.6845e-01, time/batch = 0.6966s	
245/22750 (epoch 0.538), train_loss = 3.00870606, grad/param norm = 4.0258e-01, time/batch = 0.7130s	
246/22750 (epoch 0.541), train_loss = 2.58489998, grad/param norm = 3.8625e-01, time/batch = 0.7119s	
247/22750 (epoch 0.543), train_loss = 2.56411908, grad/param norm = 4.3298e-01, time/batch = 0.7021s	
248/22750 (epoch 0.545), train_loss = 2.78343000, grad/param norm = 3.6619e-01, time/batch = 0.7096s	
249/22750 (epoch 0.547), train_loss = 2.70652858, grad/param norm = 3.2323e-01, time/batch = 0.7027s	
250/22750 (epoch 0.549), train_loss = 2.68948019, grad/param norm = 4.2670e-01, time/batch = 0.6975s	
251/22750 (epoch 0.552), train_loss = 2.79044983, grad/param norm = 4.6035e-01, time/batch = 0.6970s	
252/22750 (epoch 0.554), train_loss = 2.76525739, grad/param norm = 6.4002e-01, time/batch = 0.6930s	
253/22750 (epoch 0.556), train_loss = 2.94701231, grad/param norm = 9.0020e-01, time/batch = 0.6896s	
254/22750 (epoch 0.558), train_loss = 3.04625143, grad/param norm = 9.0061e-01, time/batch = 0.6928s	
255/22750 (epoch 0.560), train_loss = 2.96016090, grad/param norm = 1.0215e+00, time/batch = 0.6928s	
256/22750 (epoch 0.563), train_loss = 3.01256543, grad/param norm = 7.2876e-01, time/batch = 0.6902s	
257/22750 (epoch 0.565), train_loss = 3.02135433, grad/param norm = 5.1830e-01, time/batch = 0.6910s	
258/22750 (epoch 0.567), train_loss = 2.72831436, grad/param norm = 4.9073e-01, time/batch = 0.7009s	
259/22750 (epoch 0.569), train_loss = 2.89179984, grad/param norm = 6.8848e-01, time/batch = 0.7140s	
260/22750 (epoch 0.571), train_loss = 2.77514982, grad/param norm = 5.6652e-01, time/batch = 0.7012s	
261/22750 (epoch 0.574), train_loss = 2.59214577, grad/param norm = 3.9703e-01, time/batch = 0.6957s	
262/22750 (epoch 0.576), train_loss = 2.62845712, grad/param norm = 3.2516e-01, time/batch = 0.6930s	
263/22750 (epoch 0.578), train_loss = 2.72139104, grad/param norm = 4.1884e-01, time/batch = 0.7089s	
264/22750 (epoch 0.580), train_loss = 2.73595273, grad/param norm = 3.4824e-01, time/batch = 0.7021s	
265/22750 (epoch 0.582), train_loss = 2.66559972, grad/param norm = 4.1330e-01, time/batch = 0.6940s	
266/22750 (epoch 0.585), train_loss = 2.49505386, grad/param norm = 4.4497e-01, time/batch = 0.6896s	
267/22750 (epoch 0.587), train_loss = 2.65058652, grad/param norm = 4.7896e-01, time/batch = 0.6893s	
268/22750 (epoch 0.589), train_loss = 2.76265173, grad/param norm = 5.2261e-01, time/batch = 0.6923s	
269/22750 (epoch 0.591), train_loss = 2.89562523, grad/param norm = 8.6182e-01, time/batch = 0.6904s	
270/22750 (epoch 0.593), train_loss = 3.15722587, grad/param norm = 2.4212e+00, time/batch = 0.6925s	
271/22750 (epoch 0.596), train_loss = 2.86822752, grad/param norm = 1.0507e+00, time/batch = 0.6924s	
272/22750 (epoch 0.598), train_loss = 2.85232315, grad/param norm = 2.8892e-01, time/batch = 0.6883s	
273/22750 (epoch 0.600), train_loss = 2.64398071, grad/param norm = 3.5429e-01, time/batch = 0.6963s	
274/22750 (epoch 0.602), train_loss = 2.69192629, grad/param norm = 4.2291e-01, time/batch = 0.6878s	
275/22750 (epoch 0.604), train_loss = 2.76311180, grad/param norm = 4.6606e-01, time/batch = 0.6915s	
276/22750 (epoch 0.607), train_loss = 2.51274250, grad/param norm = 5.3159e-01, time/batch = 0.6898s	
277/22750 (epoch 0.609), train_loss = 2.56184040, grad/param norm = 6.2125e-01, time/batch = 0.6873s	
278/22750 (epoch 0.611), train_loss = 2.62308343, grad/param norm = 4.7659e-01, time/batch = 0.6923s	
279/22750 (epoch 0.613), train_loss = 2.54252348, grad/param norm = 3.9786e-01, time/batch = 0.6964s	
280/22750 (epoch 0.615), train_loss = 2.65677662, grad/param norm = 5.4046e-01, time/batch = 0.6921s	
281/22750 (epoch 0.618), train_loss = 2.45510626, grad/param norm = 6.6729e-01, time/batch = 0.6935s	
282/22750 (epoch 0.620), train_loss = 2.62764142, grad/param norm = 5.6728e-01, time/batch = 0.6982s	
283/22750 (epoch 0.622), train_loss = 2.54021620, grad/param norm = 4.4017e-01, time/batch = 0.6937s	
284/22750 (epoch 0.624), train_loss = 2.96762760, grad/param norm = 5.7352e-01, time/batch = 0.6881s	
285/22750 (epoch 0.626), train_loss = 3.01286196, grad/param norm = 7.1226e-01, time/batch = 0.6946s	
286/22750 (epoch 0.629), train_loss = 2.81627882, grad/param norm = 6.7030e-01, time/batch = 0.7092s	
287/22750 (epoch 0.631), train_loss = 2.89363949, grad/param norm = 6.0527e-01, time/batch = 0.6952s	
288/22750 (epoch 0.633), train_loss = 2.74254621, grad/param norm = 5.5333e-01, time/batch = 0.6944s	
289/22750 (epoch 0.635), train_loss = 2.93772676, grad/param norm = 4.8240e-01, time/batch = 0.6906s	
290/22750 (epoch 0.637), train_loss = 2.99830975, grad/param norm = 4.7699e-01, time/batch = 0.6892s	
291/22750 (epoch 0.640), train_loss = 2.93667958, grad/param norm = 6.0710e-01, time/batch = 0.6942s	
292/22750 (epoch 0.642), train_loss = 2.96902127, grad/param norm = 5.1606e-01, time/batch = 0.6954s	
293/22750 (epoch 0.644), train_loss = 2.73947920, grad/param norm = 3.1417e-01, time/batch = 0.6985s	
294/22750 (epoch 0.646), train_loss = 2.64750431, grad/param norm = 3.6227e-01, time/batch = 0.6929s	
295/22750 (epoch 0.648), train_loss = 2.83255560, grad/param norm = 3.5990e-01, time/batch = 0.6947s	
296/22750 (epoch 0.651), train_loss = 2.80895799, grad/param norm = 3.9711e-01, time/batch = 0.6977s	
297/22750 (epoch 0.653), train_loss = 2.64690977, grad/param norm = 4.0171e-01, time/batch = 0.6927s	
298/22750 (epoch 0.655), train_loss = 2.72018163, grad/param norm = 4.8536e-01, time/batch = 0.6940s	
299/22750 (epoch 0.657), train_loss = 2.72312317, grad/param norm = 4.0633e-01, time/batch = 0.6930s	
300/22750 (epoch 0.659), train_loss = 2.69951487, grad/param norm = 4.2143e-01, time/batch = 0.6926s	
301/22750 (epoch 0.662), train_loss = 2.90669891, grad/param norm = 4.8146e-01, time/batch = 0.6972s	
302/22750 (epoch 0.664), train_loss = 2.84108956, grad/param norm = 7.6827e-01, time/batch = 0.6985s	
303/22750 (epoch 0.666), train_loss = 2.84807872, grad/param norm = 8.7321e-01, time/batch = 0.6990s	
304/22750 (epoch 0.668), train_loss = 2.77650615, grad/param norm = 5.8080e-01, time/batch = 0.6960s	
305/22750 (epoch 0.670), train_loss = 2.71630529, grad/param norm = 3.8346e-01, time/batch = 0.6964s	
306/22750 (epoch 0.673), train_loss = 2.71540142, grad/param norm = 4.1866e-01, time/batch = 0.6934s	
307/22750 (epoch 0.675), train_loss = 2.97167176, grad/param norm = 5.2126e-01, time/batch = 0.6897s	
308/22750 (epoch 0.677), train_loss = 2.78781150, grad/param norm = 4.8303e-01, time/batch = 0.6926s	
309/22750 (epoch 0.679), train_loss = 3.04993217, grad/param norm = 4.0934e-01, time/batch = 0.6925s	
310/22750 (epoch 0.681), train_loss = 2.77841031, grad/param norm = 4.0035e-01, time/batch = 0.6985s	
311/22750 (epoch 0.684), train_loss = 2.78941167, grad/param norm = 5.1875e-01, time/batch = 0.7144s	
312/22750 (epoch 0.686), train_loss = 2.76239623, grad/param norm = 5.1179e-01, time/batch = 0.7111s	
313/22750 (epoch 0.688), train_loss = 2.77378329, grad/param norm = 4.2778e-01, time/batch = 0.7270s	
314/22750 (epoch 0.690), train_loss = 2.65453788, grad/param norm = 4.4291e-01, time/batch = 0.7251s	
315/22750 (epoch 0.692), train_loss = 2.67990043, grad/param norm = 4.7902e-01, time/batch = 0.7099s	
316/22750 (epoch 0.695), train_loss = 2.67220093, grad/param norm = 4.1632e-01, time/batch = 0.7078s	
317/22750 (epoch 0.697), train_loss = 2.60292936, grad/param norm = 4.7044e-01, time/batch = 0.7044s	
318/22750 (epoch 0.699), train_loss = 2.81887110, grad/param norm = 1.2012e+00, time/batch = 0.7094s	
319/22750 (epoch 0.701), train_loss = 2.85925883, grad/param norm = 1.6603e+00, time/batch = 0.7032s	
320/22750 (epoch 0.703), train_loss = 2.68934762, grad/param norm = 1.2184e+00, time/batch = 0.7004s	
321/22750 (epoch 0.705), train_loss = 2.50623395, grad/param norm = 5.5172e-01, time/batch = 0.7180s	
322/22750 (epoch 0.708), train_loss = 2.72725443, grad/param norm = 4.4123e-01, time/batch = 0.7089s	
323/22750 (epoch 0.710), train_loss = 2.60065696, grad/param norm = 4.4818e-01, time/batch = 0.6999s	
324/22750 (epoch 0.712), train_loss = 2.65081870, grad/param norm = 3.1050e-01, time/batch = 0.7059s	
325/22750 (epoch 0.714), train_loss = 2.59695451, grad/param norm = 3.6594e-01, time/batch = 0.7072s	
326/22750 (epoch 0.716), train_loss = 2.67911138, grad/param norm = 4.3339e-01, time/batch = 0.7019s	
327/22750 (epoch 0.719), train_loss = 2.75623973, grad/param norm = 5.1582e-01, time/batch = 0.6962s	
328/22750 (epoch 0.721), train_loss = 2.65683846, grad/param norm = 5.6719e-01, time/batch = 0.6929s	
329/22750 (epoch 0.723), train_loss = 2.69606887, grad/param norm = 4.9791e-01, time/batch = 0.6895s	
330/22750 (epoch 0.725), train_loss = 2.56215868, grad/param norm = 4.0792e-01, time/batch = 0.7058s	
331/22750 (epoch 0.727), train_loss = 2.48206205, grad/param norm = 4.0304e-01, time/batch = 0.7130s	
332/22750 (epoch 0.730), train_loss = 2.37740002, grad/param norm = 3.7043e-01, time/batch = 0.7143s	
333/22750 (epoch 0.732), train_loss = 2.51332729, grad/param norm = 4.3026e-01, time/batch = 0.7045s	
334/22750 (epoch 0.734), train_loss = 2.32356480, grad/param norm = 5.5425e-01, time/batch = 0.6967s	
335/22750 (epoch 0.736), train_loss = 2.65398212, grad/param norm = 5.5283e-01, time/batch = 0.7031s	
336/22750 (epoch 0.738), train_loss = 2.50330399, grad/param norm = 4.2636e-01, time/batch = 0.7021s	
337/22750 (epoch 0.741), train_loss = 2.65754291, grad/param norm = 3.0501e-01, time/batch = 0.7044s	
338/22750 (epoch 0.743), train_loss = 2.68248811, grad/param norm = 2.9465e-01, time/batch = 0.7046s	
339/22750 (epoch 0.745), train_loss = 2.55020496, grad/param norm = 2.9120e-01, time/batch = 0.7111s	
340/22750 (epoch 0.747), train_loss = 2.41859447, grad/param norm = 3.5689e-01, time/batch = 0.7087s	
341/22750 (epoch 0.749), train_loss = 2.71279889, grad/param norm = 4.2121e-01, time/batch = 0.7007s	
342/22750 (epoch 0.752), train_loss = 2.42154971, grad/param norm = 5.4315e-01, time/batch = 0.6977s	
343/22750 (epoch 0.754), train_loss = 2.67902350, grad/param norm = 6.8638e-01, time/batch = 0.7086s	
344/22750 (epoch 0.756), train_loss = 2.48092185, grad/param norm = 7.6941e-01, time/batch = 0.7110s	
345/22750 (epoch 0.758), train_loss = 2.51394721, grad/param norm = 7.2011e-01, time/batch = 0.7024s	
346/22750 (epoch 0.760), train_loss = 2.73783777, grad/param norm = 4.2732e-01, time/batch = 0.6972s	
347/22750 (epoch 0.763), train_loss = 2.54180900, grad/param norm = 3.4049e-01, time/batch = 0.6988s	
348/22750 (epoch 0.765), train_loss = 2.47211973, grad/param norm = 4.2258e-01, time/batch = 0.6974s	
349/22750 (epoch 0.767), train_loss = 2.50880135, grad/param norm = 4.1805e-01, time/batch = 0.6926s	
350/22750 (epoch 0.769), train_loss = 2.66693716, grad/param norm = 3.7020e-01, time/batch = 0.7025s	
351/22750 (epoch 0.771), train_loss = 2.58057031, grad/param norm = 5.4897e-01, time/batch = 0.7030s	
352/22750 (epoch 0.774), train_loss = 2.76682129, grad/param norm = 1.0401e+00, time/batch = 0.6983s	
353/22750 (epoch 0.776), train_loss = 2.66372616, grad/param norm = 7.3604e-01, time/batch = 0.7081s	
354/22750 (epoch 0.778), train_loss = 2.81177128, grad/param norm = 3.7472e-01, time/batch = 0.7049s	
355/22750 (epoch 0.780), train_loss = 2.76791970, grad/param norm = 5.1088e-01, time/batch = 0.7036s	
356/22750 (epoch 0.782), train_loss = 2.67243699, grad/param norm = 5.2073e-01, time/batch = 0.6972s	
357/22750 (epoch 0.785), train_loss = 2.67890359, grad/param norm = 4.2521e-01, time/batch = 0.6936s	
358/22750 (epoch 0.787), train_loss = 2.56749779, grad/param norm = 4.5547e-01, time/batch = 0.6946s	
359/22750 (epoch 0.789), train_loss = 2.46740234, grad/param norm = 4.4263e-01, time/batch = 0.6938s	
360/22750 (epoch 0.791), train_loss = 2.56775001, grad/param norm = 3.3152e-01, time/batch = 0.7093s	
361/22750 (epoch 0.793), train_loss = 2.56255699, grad/param norm = 3.3290e-01, time/batch = 0.7099s	
362/22750 (epoch 0.796), train_loss = 2.49389438, grad/param norm = 2.7151e-01, time/batch = 0.7038s	
363/22750 (epoch 0.798), train_loss = 2.42619632, grad/param norm = 2.7190e-01, time/batch = 0.7044s	
364/22750 (epoch 0.800), train_loss = 2.53365865, grad/param norm = 2.8230e-01, time/batch = 0.7210s	
365/22750 (epoch 0.802), train_loss = 2.70443766, grad/param norm = 3.4297e-01, time/batch = 0.7179s	
366/22750 (epoch 0.804), train_loss = 2.74183054, grad/param norm = 3.3407e-01, time/batch = 0.7177s	
367/22750 (epoch 0.807), train_loss = 2.64527084, grad/param norm = 3.3957e-01, time/batch = 0.7128s	
368/22750 (epoch 0.809), train_loss = 2.91042074, grad/param norm = 5.3805e-01, time/batch = 0.7114s	
369/22750 (epoch 0.811), train_loss = 2.67634388, grad/param norm = 8.6045e-01, time/batch = 0.7199s	
370/22750 (epoch 0.813), train_loss = 2.85836044, grad/param norm = 6.5346e-01, time/batch = 0.7125s	
371/22750 (epoch 0.815), train_loss = 2.71961992, grad/param norm = 6.1597e-01, time/batch = 0.7245s	
372/22750 (epoch 0.818), train_loss = 2.77517507, grad/param norm = 5.6548e-01, time/batch = 0.7155s	
373/22750 (epoch 0.820), train_loss = 2.73092968, grad/param norm = 3.4774e-01, time/batch = 0.7206s	
374/22750 (epoch 0.822), train_loss = 2.55791651, grad/param norm = 3.0839e-01, time/batch = 0.7149s	
375/22750 (epoch 0.824), train_loss = 2.66900394, grad/param norm = 3.6938e-01, time/batch = 0.7078s	
376/22750 (epoch 0.826), train_loss = 2.63983013, grad/param norm = 3.4676e-01, time/batch = 0.7016s	
377/22750 (epoch 0.829), train_loss = 2.66477418, grad/param norm = 4.3624e-01, time/batch = 0.7046s	
378/22750 (epoch 0.831), train_loss = 2.66202338, grad/param norm = 5.3849e-01, time/batch = 0.7212s	
379/22750 (epoch 0.833), train_loss = 2.78568093, grad/param norm = 3.6414e-01, time/batch = 0.7228s	
380/22750 (epoch 0.835), train_loss = 2.70247592, grad/param norm = 3.3339e-01, time/batch = 0.7056s	
381/22750 (epoch 0.837), train_loss = 2.61143168, grad/param norm = 3.4961e-01, time/batch = 0.7102s	
382/22750 (epoch 0.840), train_loss = 2.68765813, grad/param norm = 3.7452e-01, time/batch = 0.7081s	
383/22750 (epoch 0.842), train_loss = 2.71474641, grad/param norm = 3.8673e-01, time/batch = 0.7042s	
384/22750 (epoch 0.844), train_loss = 2.67825453, grad/param norm = 5.1429e-01, time/batch = 0.7211s	
385/22750 (epoch 0.846), train_loss = 2.42280952, grad/param norm = 5.2708e-01, time/batch = 0.7058s	
386/22750 (epoch 0.848), train_loss = 2.53263390, grad/param norm = 5.2739e-01, time/batch = 0.7022s	
387/22750 (epoch 0.851), train_loss = 2.48457237, grad/param norm = 5.8573e-01, time/batch = 0.7058s	
388/22750 (epoch 0.853), train_loss = 2.46800234, grad/param norm = 4.5924e-01, time/batch = 0.7066s	
389/22750 (epoch 0.855), train_loss = 2.48081004, grad/param norm = 3.4010e-01, time/batch = 0.7121s	
390/22750 (epoch 0.857), train_loss = 2.53758777, grad/param norm = 3.3514e-01, time/batch = 0.7014s	
391/22750 (epoch 0.859), train_loss = 2.61098696, grad/param norm = 3.0299e-01, time/batch = 0.6991s	
392/22750 (epoch 0.862), train_loss = 2.57617592, grad/param norm = 3.1221e-01, time/batch = 0.7025s	
393/22750 (epoch 0.864), train_loss = 2.77451829, grad/param norm = 3.8977e-01, time/batch = 0.7052s	
394/22750 (epoch 0.866), train_loss = 2.51825755, grad/param norm = 3.5166e-01, time/batch = 0.7027s	
395/22750 (epoch 0.868), train_loss = 2.75335819, grad/param norm = 4.6424e-01, time/batch = 0.7162s	
396/22750 (epoch 0.870), train_loss = 2.37699601, grad/param norm = 4.0374e-01, time/batch = 0.7275s	
397/22750 (epoch 0.873), train_loss = 2.59342617, grad/param norm = 4.4309e-01, time/batch = 0.7025s	
398/22750 (epoch 0.875), train_loss = 2.58337327, grad/param norm = 4.8009e-01, time/batch = 0.7032s	
399/22750 (epoch 0.877), train_loss = 2.63783105, grad/param norm = 6.6772e-01, time/batch = 0.7074s	
400/22750 (epoch 0.879), train_loss = 2.74617604, grad/param norm = 6.7110e-01, time/batch = 0.7152s	
401/22750 (epoch 0.881), train_loss = 2.58766929, grad/param norm = 6.0679e-01, time/batch = 0.7126s	
402/22750 (epoch 0.884), train_loss = 2.76003282, grad/param norm = 6.1043e-01, time/batch = 0.7094s	
403/22750 (epoch 0.886), train_loss = 2.64727184, grad/param norm = 7.2986e-01, time/batch = 0.7254s	
404/22750 (epoch 0.888), train_loss = 2.55779038, grad/param norm = 3.7543e-01, time/batch = 0.7275s	
405/22750 (epoch 0.890), train_loss = 2.74861447, grad/param norm = 4.2616e-01, time/batch = 0.7284s	
406/22750 (epoch 0.892), train_loss = 2.89195921, grad/param norm = 4.7662e-01, time/batch = 0.7326s	
407/22750 (epoch 0.895), train_loss = 2.83045108, grad/param norm = 4.9143e-01, time/batch = 0.7267s	
408/22750 (epoch 0.897), train_loss = 2.64756280, grad/param norm = 4.0730e-01, time/batch = 0.7204s	
409/22750 (epoch 0.899), train_loss = 2.75968373, grad/param norm = 3.6196e-01, time/batch = 0.7290s	
410/22750 (epoch 0.901), train_loss = 2.65717719, grad/param norm = 3.3531e-01, time/batch = 0.7158s	
411/22750 (epoch 0.903), train_loss = 2.69136336, grad/param norm = 5.1289e-01, time/batch = 0.7263s	
412/22750 (epoch 0.905), train_loss = 2.58999297, grad/param norm = 4.9329e-01, time/batch = 0.7200s	
413/22750 (epoch 0.908), train_loss = 2.50384777, grad/param norm = 3.6761e-01, time/batch = 0.7064s	
414/22750 (epoch 0.910), train_loss = 2.50546991, grad/param norm = 4.5979e-01, time/batch = 0.7189s	
415/22750 (epoch 0.912), train_loss = 2.39349410, grad/param norm = 3.9849e-01, time/batch = 0.7252s	
416/22750 (epoch 0.914), train_loss = 2.42157362, grad/param norm = 5.7355e-01, time/batch = 0.7240s	
417/22750 (epoch 0.916), train_loss = 2.36806986, grad/param norm = 4.1624e-01, time/batch = 0.7157s	
418/22750 (epoch 0.919), train_loss = 2.26809773, grad/param norm = 2.9527e-01, time/batch = 0.7116s	
419/22750 (epoch 0.921), train_loss = 2.32221091, grad/param norm = 3.2430e-01, time/batch = 0.7123s	
420/22750 (epoch 0.923), train_loss = 2.55299964, grad/param norm = 2.9738e-01, time/batch = 0.7054s	
421/22750 (epoch 0.925), train_loss = 2.51838526, grad/param norm = 3.7363e-01, time/batch = 0.7215s	
422/22750 (epoch 0.927), train_loss = 2.28111542, grad/param norm = 4.7024e-01, time/batch = 0.7149s	
423/22750 (epoch 0.930), train_loss = 2.41280573, grad/param norm = 5.0272e-01, time/batch = 0.7095s	
424/22750 (epoch 0.932), train_loss = 2.73604357, grad/param norm = 4.5893e-01, time/batch = 0.7032s	
425/22750 (epoch 0.934), train_loss = 2.37801961, grad/param norm = 4.1159e-01, time/batch = 0.7172s	
426/22750 (epoch 0.936), train_loss = 2.59973334, grad/param norm = 4.1116e-01, time/batch = 0.7212s	
427/22750 (epoch 0.938), train_loss = 2.60743974, grad/param norm = 5.0720e-01, time/batch = 0.7146s	
428/22750 (epoch 0.941), train_loss = 2.91930552, grad/param norm = 6.3279e-01, time/batch = 0.7082s	
429/22750 (epoch 0.943), train_loss = 2.61697801, grad/param norm = 6.4820e-01, time/batch = 0.7010s	
430/22750 (epoch 0.945), train_loss = 2.56083913, grad/param norm = 4.1854e-01, time/batch = 0.7053s	
431/22750 (epoch 0.947), train_loss = 2.58042926, grad/param norm = 3.8012e-01, time/batch = 0.7034s	
432/22750 (epoch 0.949), train_loss = 2.46784954, grad/param norm = 3.3002e-01, time/batch = 0.7045s	
433/22750 (epoch 0.952), train_loss = 2.46222420, grad/param norm = 3.1393e-01, time/batch = 0.7015s	
434/22750 (epoch 0.954), train_loss = 2.40104622, grad/param norm = 2.8438e-01, time/batch = 0.7313s	
435/22750 (epoch 0.956), train_loss = 2.48043687, grad/param norm = 3.1836e-01, time/batch = 0.7093s	
436/22750 (epoch 0.958), train_loss = 2.54601055, grad/param norm = 3.7826e-01, time/batch = 0.7040s	
437/22750 (epoch 0.960), train_loss = 2.51901392, grad/param norm = 4.5123e-01, time/batch = 0.7099s	
438/22750 (epoch 0.963), train_loss = 2.41051399, grad/param norm = 3.9958e-01, time/batch = 0.7130s	
439/22750 (epoch 0.965), train_loss = 2.46983157, grad/param norm = 3.5521e-01, time/batch = 0.7172s	
440/22750 (epoch 0.967), train_loss = 2.54998122, grad/param norm = 3.5792e-01, time/batch = 0.7072s	
441/22750 (epoch 0.969), train_loss = 2.43559333, grad/param norm = 3.3318e-01, time/batch = 0.7125s	
442/22750 (epoch 0.971), train_loss = 2.44208855, grad/param norm = 2.6206e-01, time/batch = 0.7122s	
443/22750 (epoch 0.974), train_loss = 2.43003344, grad/param norm = 2.7115e-01, time/batch = 0.7029s	
444/22750 (epoch 0.976), train_loss = 2.53893578, grad/param norm = 3.3710e-01, time/batch = 0.6996s	
445/22750 (epoch 0.978), train_loss = 2.40782002, grad/param norm = 4.2263e-01, time/batch = 0.7066s	
446/22750 (epoch 0.980), train_loss = 2.44808774, grad/param norm = 3.7305e-01, time/batch = 0.7066s	
447/22750 (epoch 0.982), train_loss = 2.52552726, grad/param norm = 5.0977e-01, time/batch = 0.6953s	
448/22750 (epoch 0.985), train_loss = 2.78228811, grad/param norm = 6.1514e-01, time/batch = 0.7040s	
449/22750 (epoch 0.987), train_loss = 2.43474994, grad/param norm = 3.3846e-01, time/batch = 0.7015s	
450/22750 (epoch 0.989), train_loss = 2.42259185, grad/param norm = 3.0386e-01, time/batch = 0.7078s	
451/22750 (epoch 0.991), train_loss = 2.53450114, grad/param norm = 3.5352e-01, time/batch = 0.7029s	
452/22750 (epoch 0.993), train_loss = 2.52277922, grad/param norm = 3.7924e-01, time/batch = 0.6993s	
453/22750 (epoch 0.996), train_loss = 2.41115180, grad/param norm = 3.2106e-01, time/batch = 0.7014s	
454/22750 (epoch 0.998), train_loss = 2.64058450, grad/param norm = 3.7250e-01, time/batch = 0.6997s	
455/22750 (epoch 1.000), train_loss = 2.72905672, grad/param norm = 5.6194e-01, time/batch = 0.7046s	
456/22750 (epoch 1.002), train_loss = 2.68908361, grad/param norm = 7.3928e-01, time/batch = 0.7028s	
457/22750 (epoch 1.004), train_loss = 2.71269274, grad/param norm = 5.2376e-01, time/batch = 0.6997s	
458/22750 (epoch 1.007), train_loss = 2.68483883, grad/param norm = 5.4992e-01, time/batch = 0.6968s	
459/22750 (epoch 1.009), train_loss = 2.84775941, grad/param norm = 4.7196e-01, time/batch = 0.6982s	
460/22750 (epoch 1.011), train_loss = 2.56192291, grad/param norm = 4.1209e-01, time/batch = 0.6928s	
461/22750 (epoch 1.013), train_loss = 2.60281163, grad/param norm = 4.3236e-01, time/batch = 0.7001s	
462/22750 (epoch 1.015), train_loss = 2.47983022, grad/param norm = 3.1190e-01, time/batch = 0.7007s	
463/22750 (epoch 1.018), train_loss = 2.44863032, grad/param norm = 2.8921e-01, time/batch = 0.6986s	
464/22750 (epoch 1.020), train_loss = 2.57256424, grad/param norm = 3.7115e-01, time/batch = 0.7001s	
465/22750 (epoch 1.022), train_loss = 2.46441591, grad/param norm = 3.4689e-01, time/batch = 0.7004s	
466/22750 (epoch 1.024), train_loss = 2.36929892, grad/param norm = 2.9804e-01, time/batch = 0.6974s	
467/22750 (epoch 1.026), train_loss = 2.65585429, grad/param norm = 4.3295e-01, time/batch = 0.6980s	
468/22750 (epoch 1.029), train_loss = 2.35211864, grad/param norm = 4.7271e-01, time/batch = 0.7046s	
469/22750 (epoch 1.031), train_loss = 2.77693542, grad/param norm = 4.4765e-01, time/batch = 0.7136s	
470/22750 (epoch 1.033), train_loss = 2.62649339, grad/param norm = 3.3937e-01, time/batch = 0.7007s	
471/22750 (epoch 1.035), train_loss = 2.61134840, grad/param norm = 3.2533e-01, time/batch = 0.6998s	
472/22750 (epoch 1.037), train_loss = 2.74913941, grad/param norm = 3.4757e-01, time/batch = 0.6992s	
473/22750 (epoch 1.040), train_loss = 2.51404783, grad/param norm = 3.6368e-01, time/batch = 0.6957s	
474/22750 (epoch 1.042), train_loss = 2.58157378, grad/param norm = 3.3771e-01, time/batch = 0.6955s	
475/22750 (epoch 1.044), train_loss = 2.44550512, grad/param norm = 3.6103e-01, time/batch = 0.6983s	
476/22750 (epoch 1.046), train_loss = 2.44254641, grad/param norm = 4.1929e-01, time/batch = 0.7010s	
477/22750 (epoch 1.048), train_loss = 2.59222864, grad/param norm = 4.2127e-01, time/batch = 0.7005s	
478/22750 (epoch 1.051), train_loss = 2.64011702, grad/param norm = 3.3541e-01, time/batch = 0.6950s	
479/22750 (epoch 1.053), train_loss = 2.37250103, grad/param norm = 2.8420e-01, time/batch = 0.6949s	
480/22750 (epoch 1.055), train_loss = 2.60961121, grad/param norm = 4.3545e-01, time/batch = 0.6938s	
481/22750 (epoch 1.057), train_loss = 2.49433367, grad/param norm = 5.2775e-01, time/batch = 0.7011s	
482/22750 (epoch 1.059), train_loss = 2.42927880, grad/param norm = 5.4603e-01, time/batch = 0.6989s	
483/22750 (epoch 1.062), train_loss = 2.40299835, grad/param norm = 4.1826e-01, time/batch = 0.6962s	
484/22750 (epoch 1.064), train_loss = 2.45577331, grad/param norm = 3.4290e-01, time/batch = 0.7001s	
485/22750 (epoch 1.066), train_loss = 2.19464882, grad/param norm = 2.8555e-01, time/batch = 0.7104s	
486/22750 (epoch 1.068), train_loss = 2.31942265, grad/param norm = 2.7096e-01, time/batch = 0.6956s	
487/22750 (epoch 1.070), train_loss = 2.14516099, grad/param norm = 3.4143e-01, time/batch = 0.6974s	
488/22750 (epoch 1.073), train_loss = 2.34323377, grad/param norm = 3.5479e-01, time/batch = 0.6975s	
489/22750 (epoch 1.075), train_loss = 2.44092524, grad/param norm = 3.0668e-01, time/batch = 0.7121s	
490/22750 (epoch 1.077), train_loss = 2.24088982, grad/param norm = 3.6209e-01, time/batch = 0.7212s	
491/22750 (epoch 1.079), train_loss = 2.29450100, grad/param norm = 3.8231e-01, time/batch = 0.7264s	
492/22750 (epoch 1.081), train_loss = 2.45719116, grad/param norm = 4.9716e-01, time/batch = 0.7203s	
493/22750 (epoch 1.084), train_loss = 2.39592011, grad/param norm = 3.8988e-01, time/batch = 0.7153s	
494/22750 (epoch 1.086), train_loss = 2.43909825, grad/param norm = 3.6294e-01, time/batch = 0.7134s	
495/22750 (epoch 1.088), train_loss = 2.40916015, grad/param norm = 4.0882e-01, time/batch = 0.6883s	
496/22750 (epoch 1.090), train_loss = 2.48987418, grad/param norm = 4.0554e-01, time/batch = 0.7004s	
497/22750 (epoch 1.092), train_loss = 2.58443070, grad/param norm = 3.5140e-01, time/batch = 0.6961s	
498/22750 (epoch 1.095), train_loss = 2.42260607, grad/param norm = 3.7525e-01, time/batch = 0.6963s	
499/22750 (epoch 1.097), train_loss = 2.45881361, grad/param norm = 3.1622e-01, time/batch = 0.7231s	
500/22750 (epoch 1.099), train_loss = 2.65393966, grad/param norm = 5.2049e-01, time/batch = 0.7247s	
501/22750 (epoch 1.101), train_loss = 2.58195351, grad/param norm = 6.5106e-01, time/batch = 0.7049s	
502/22750 (epoch 1.103), train_loss = 2.31845883, grad/param norm = 3.7598e-01, time/batch = 0.7028s	
503/22750 (epoch 1.105), train_loss = 2.56348686, grad/param norm = 3.8847e-01, time/batch = 0.7049s	
504/22750 (epoch 1.108), train_loss = 2.41490945, grad/param norm = 4.0417e-01, time/batch = 0.7057s	
505/22750 (epoch 1.110), train_loss = 2.43810659, grad/param norm = 4.5398e-01, time/batch = 0.7020s	
506/22750 (epoch 1.112), train_loss = 2.30089189, grad/param norm = 3.6090e-01, time/batch = 0.7036s	
507/22750 (epoch 1.114), train_loss = 2.16467700, grad/param norm = 2.8056e-01, time/batch = 0.6980s	
508/22750 (epoch 1.116), train_loss = 2.26910651, grad/param norm = 2.9009e-01, time/batch = 0.7163s	
509/22750 (epoch 1.119), train_loss = 2.40943135, grad/param norm = 3.1607e-01, time/batch = 0.7049s	
510/22750 (epoch 1.121), train_loss = 2.48908972, grad/param norm = 3.1635e-01, time/batch = 0.6999s	
511/22750 (epoch 1.123), train_loss = 2.30947239, grad/param norm = 2.7949e-01, time/batch = 0.7187s	
512/22750 (epoch 1.125), train_loss = 2.48482875, grad/param norm = 2.7879e-01, time/batch = 0.7113s	
513/22750 (epoch 1.127), train_loss = 2.42472766, grad/param norm = 2.8771e-01, time/batch = 0.7152s	
514/22750 (epoch 1.130), train_loss = 2.51150775, grad/param norm = 3.0403e-01, time/batch = 0.6982s	
515/22750 (epoch 1.132), train_loss = 2.35783472, grad/param norm = 3.4791e-01, time/batch = 0.7090s	
516/22750 (epoch 1.134), train_loss = 2.43464688, grad/param norm = 4.2277e-01, time/batch = 0.6972s	
517/22750 (epoch 1.136), train_loss = 2.33846747, grad/param norm = 3.3398e-01, time/batch = 0.6957s	
518/22750 (epoch 1.138), train_loss = 2.39196017, grad/param norm = 4.4573e-01, time/batch = 0.6980s	
519/22750 (epoch 1.141), train_loss = 2.41878893, grad/param norm = 4.0839e-01, time/batch = 0.7133s	
520/22750 (epoch 1.143), train_loss = 2.37624070, grad/param norm = 3.1356e-01, time/batch = 0.7156s	
521/22750 (epoch 1.145), train_loss = 2.51486100, grad/param norm = 3.6680e-01, time/batch = 0.7038s	
522/22750 (epoch 1.147), train_loss = 2.42646989, grad/param norm = 3.5715e-01, time/batch = 0.6982s	
523/22750 (epoch 1.149), train_loss = 2.45392111, grad/param norm = 4.5261e-01, time/batch = 0.6999s	
524/22750 (epoch 1.152), train_loss = 2.52999849, grad/param norm = 5.5303e-01, time/batch = 0.6978s	
525/22750 (epoch 1.154), train_loss = 2.43461450, grad/param norm = 4.4788e-01, time/batch = 0.6972s	
526/22750 (epoch 1.156), train_loss = 2.43952160, grad/param norm = 3.1598e-01, time/batch = 0.7013s	
527/22750 (epoch 1.158), train_loss = 2.48613113, grad/param norm = 2.7842e-01, time/batch = 0.7028s	
528/22750 (epoch 1.160), train_loss = 2.42716156, grad/param norm = 3.1282e-01, time/batch = 0.7200s	
529/22750 (epoch 1.163), train_loss = 2.54014097, grad/param norm = 3.0186e-01, time/batch = 0.7094s	
530/22750 (epoch 1.165), train_loss = 2.45081457, grad/param norm = 3.2333e-01, time/batch = 0.7059s	
531/22750 (epoch 1.167), train_loss = 2.27661622, grad/param norm = 3.1244e-01, time/batch = 0.7069s	
532/22750 (epoch 1.169), train_loss = 2.34248300, grad/param norm = 3.3561e-01, time/batch = 0.7028s	
533/22750 (epoch 1.171), train_loss = 2.34060220, grad/param norm = 2.9155e-01, time/batch = 0.6995s	
534/22750 (epoch 1.174), train_loss = 2.21282682, grad/param norm = 2.7816e-01, time/batch = 0.7010s	
535/22750 (epoch 1.176), train_loss = 2.33871721, grad/param norm = 3.2840e-01, time/batch = 0.7000s	
536/22750 (epoch 1.178), train_loss = 2.38380777, grad/param norm = 3.6023e-01, time/batch = 0.6988s	
537/22750 (epoch 1.180), train_loss = 2.47021532, grad/param norm = 3.8306e-01, time/batch = 0.7004s	
538/22750 (epoch 1.182), train_loss = 2.46525445, grad/param norm = 3.2665e-01, time/batch = 0.7121s	
539/22750 (epoch 1.185), train_loss = 2.35616329, grad/param norm = 2.8935e-01, time/batch = 0.7059s	
540/22750 (epoch 1.187), train_loss = 2.32067721, grad/param norm = 3.1239e-01, time/batch = 0.6989s	
541/22750 (epoch 1.189), train_loss = 2.33150281, grad/param norm = 3.1651e-01, time/batch = 0.7025s	
542/22750 (epoch 1.191), train_loss = 2.28513279, grad/param norm = 3.9260e-01, time/batch = 0.6981s	
543/22750 (epoch 1.193), train_loss = 2.35020709, grad/param norm = 3.4842e-01, time/batch = 0.6971s	
544/22750 (epoch 1.196), train_loss = 2.51331618, grad/param norm = 3.2736e-01, time/batch = 0.7030s	
545/22750 (epoch 1.198), train_loss = 2.29260777, grad/param norm = 2.6054e-01, time/batch = 0.7034s	
546/22750 (epoch 1.200), train_loss = 2.43264162, grad/param norm = 2.7105e-01, time/batch = 0.7054s	
547/22750 (epoch 1.202), train_loss = 2.69069721, grad/param norm = 3.0082e-01, time/batch = 0.7046s	
548/22750 (epoch 1.204), train_loss = 2.61710691, grad/param norm = 3.4055e-01, time/batch = 0.7051s	
549/22750 (epoch 1.207), train_loss = 2.28588993, grad/param norm = 3.5207e-01, time/batch = 0.7009s	
550/22750 (epoch 1.209), train_loss = 2.41464917, grad/param norm = 3.2130e-01, time/batch = 0.7008s	
551/22750 (epoch 1.211), train_loss = 2.36584436, grad/param norm = 4.1148e-01, time/batch = 0.7022s	
552/22750 (epoch 1.213), train_loss = 2.37230455, grad/param norm = 5.6805e-01, time/batch = 0.7054s	
553/22750 (epoch 1.215), train_loss = 2.43925822, grad/param norm = 5.5786e-01, time/batch = 0.6987s	
554/22750 (epoch 1.218), train_loss = 2.17315097, grad/param norm = 4.7426e-01, time/batch = 0.7024s	
555/22750 (epoch 1.220), train_loss = 2.44870381, grad/param norm = 3.6804e-01, time/batch = 0.7076s	
556/22750 (epoch 1.222), train_loss = 2.24580065, grad/param norm = 3.3865e-01, time/batch = 0.7033s	
557/22750 (epoch 1.224), train_loss = 2.46823322, grad/param norm = 3.5416e-01, time/batch = 0.7075s	
558/22750 (epoch 1.226), train_loss = 2.34521933, grad/param norm = 3.1226e-01, time/batch = 0.7036s	
559/22750 (epoch 1.229), train_loss = 2.51885451, grad/param norm = 3.0732e-01, time/batch = 0.7001s	
560/22750 (epoch 1.231), train_loss = 2.44757203, grad/param norm = 2.9448e-01, time/batch = 0.7045s	
561/22750 (epoch 1.233), train_loss = 2.43866759, grad/param norm = 3.0871e-01, time/batch = 0.7068s	
562/22750 (epoch 1.235), train_loss = 2.24779148, grad/param norm = 3.1090e-01, time/batch = 0.7109s	
563/22750 (epoch 1.237), train_loss = 2.41428254, grad/param norm = 4.0813e-01, time/batch = 0.6972s	
564/22750 (epoch 1.240), train_loss = 2.66326214, grad/param norm = 5.2929e-01, time/batch = 0.7024s	
565/22750 (epoch 1.242), train_loss = 2.72852205, grad/param norm = 6.4751e-01, time/batch = 0.6987s	
566/22750 (epoch 1.244), train_loss = 2.56958079, grad/param norm = 7.1410e-01, time/batch = 0.7073s	
567/22750 (epoch 1.246), train_loss = 2.73251817, grad/param norm = 4.2674e-01, time/batch = 0.7146s	
568/22750 (epoch 1.248), train_loss = 2.25283312, grad/param norm = 3.5701e-01, time/batch = 0.7014s	
569/22750 (epoch 1.251), train_loss = 2.55692723, grad/param norm = 3.6741e-01, time/batch = 0.6991s	
570/22750 (epoch 1.253), train_loss = 2.39010359, grad/param norm = 2.5177e-01, time/batch = 0.7192s	
571/22750 (epoch 1.255), train_loss = 2.56410603, grad/param norm = 2.8924e-01, time/batch = 0.7064s	
572/22750 (epoch 1.257), train_loss = 2.41998412, grad/param norm = 3.7806e-01, time/batch = 0.7025s	
573/22750 (epoch 1.259), train_loss = 2.40611076, grad/param norm = 3.0584e-01, time/batch = 0.7189s	
574/22750 (epoch 1.262), train_loss = 2.34366683, grad/param norm = 3.5298e-01, time/batch = 0.7164s	
575/22750 (epoch 1.264), train_loss = 2.48524503, grad/param norm = 2.9470e-01, time/batch = 0.7090s	
576/22750 (epoch 1.266), train_loss = 2.21979074, grad/param norm = 3.3372e-01, time/batch = 0.7112s	
577/22750 (epoch 1.268), train_loss = 2.38280207, grad/param norm = 2.6569e-01, time/batch = 0.7032s	
578/22750 (epoch 1.270), train_loss = 2.22724426, grad/param norm = 3.0647e-01, time/batch = 0.7108s	
579/22750 (epoch 1.273), train_loss = 2.41469421, grad/param norm = 3.9877e-01, time/batch = 0.7072s	
580/22750 (epoch 1.275), train_loss = 2.31117222, grad/param norm = 3.0577e-01, time/batch = 0.7020s	
581/22750 (epoch 1.277), train_loss = 2.44893959, grad/param norm = 3.1781e-01, time/batch = 0.7080s	
582/22750 (epoch 1.279), train_loss = 2.19515658, grad/param norm = 3.0513e-01, time/batch = 0.7078s	
583/22750 (epoch 1.281), train_loss = 2.28920417, grad/param norm = 2.9229e-01, time/batch = 0.7103s	
584/22750 (epoch 1.284), train_loss = 2.24247792, grad/param norm = 2.9780e-01, time/batch = 0.7237s	
585/22750 (epoch 1.286), train_loss = 2.33510183, grad/param norm = 3.2911e-01, time/batch = 0.7126s	
586/22750 (epoch 1.288), train_loss = 2.44715750, grad/param norm = 3.1230e-01, time/batch = 0.7220s	
587/22750 (epoch 1.290), train_loss = 2.22843727, grad/param norm = 3.0326e-01, time/batch = 0.7044s	
588/22750 (epoch 1.292), train_loss = 2.29143059, grad/param norm = 2.6282e-01, time/batch = 0.7184s	
589/22750 (epoch 1.295), train_loss = 2.37876864, grad/param norm = 3.0398e-01, time/batch = 0.7039s	
590/22750 (epoch 1.297), train_loss = 2.25703349, grad/param norm = 3.2271e-01, time/batch = 0.7007s	
591/22750 (epoch 1.299), train_loss = 2.45977988, grad/param norm = 3.3300e-01, time/batch = 0.7078s	
592/22750 (epoch 1.301), train_loss = 2.42670308, grad/param norm = 3.3488e-01, time/batch = 0.7035s	
593/22750 (epoch 1.303), train_loss = 2.47764561, grad/param norm = 3.6539e-01, time/batch = 0.7067s	
594/22750 (epoch 1.305), train_loss = 2.49211324, grad/param norm = 3.2605e-01, time/batch = 0.7149s	
595/22750 (epoch 1.308), train_loss = 2.35699259, grad/param norm = 3.1853e-01, time/batch = 0.7069s	
596/22750 (epoch 1.310), train_loss = 2.22602530, grad/param norm = 3.1371e-01, time/batch = 0.7059s	
597/22750 (epoch 1.312), train_loss = 2.30943656, grad/param norm = 3.1718e-01, time/batch = 0.7023s	
598/22750 (epoch 1.314), train_loss = 2.40214096, grad/param norm = 3.1592e-01, time/batch = 0.7124s	
599/22750 (epoch 1.316), train_loss = 2.34034754, grad/param norm = 3.1360e-01, time/batch = 0.7110s	
600/22750 (epoch 1.319), train_loss = 2.41481985, grad/param norm = 3.2034e-01, time/batch = 0.6954s	
601/22750 (epoch 1.321), train_loss = 2.32074758, grad/param norm = 3.5724e-01, time/batch = 0.7053s	
602/22750 (epoch 1.323), train_loss = 2.10464902, grad/param norm = 3.1975e-01, time/batch = 0.7013s	
603/22750 (epoch 1.325), train_loss = 2.16104684, grad/param norm = 2.6179e-01, time/batch = 0.7088s	
604/22750 (epoch 1.327), train_loss = 2.63481694, grad/param norm = 3.6293e-01, time/batch = 0.7124s	
605/22750 (epoch 1.330), train_loss = 2.59291167, grad/param norm = 3.5652e-01, time/batch = 0.7029s	
606/22750 (epoch 1.332), train_loss = 2.34273783, grad/param norm = 3.2879e-01, time/batch = 0.7043s	
607/22750 (epoch 1.334), train_loss = 2.26104010, grad/param norm = 3.2157e-01, time/batch = 0.7047s	
608/22750 (epoch 1.336), train_loss = 2.36135205, grad/param norm = 3.2831e-01, time/batch = 0.6972s	
609/22750 (epoch 1.338), train_loss = 2.52382123, grad/param norm = 4.8172e-01, time/batch = 0.7082s	
610/22750 (epoch 1.341), train_loss = 2.38796064, grad/param norm = 3.5904e-01, time/batch = 0.7044s	
611/22750 (epoch 1.343), train_loss = 2.23438591, grad/param norm = 2.7169e-01, time/batch = 0.7100s	
612/22750 (epoch 1.345), train_loss = 2.57328630, grad/param norm = 3.1204e-01, time/batch = 0.7210s	
613/22750 (epoch 1.347), train_loss = 2.51495588, grad/param norm = 3.0985e-01, time/batch = 0.7148s	
614/22750 (epoch 1.349), train_loss = 2.09295929, grad/param norm = 3.6901e-01, time/batch = 0.7092s	
615/22750 (epoch 1.352), train_loss = 2.40332064, grad/param norm = 3.8148e-01, time/batch = 0.7111s	
616/22750 (epoch 1.354), train_loss = 2.42219302, grad/param norm = 3.1462e-01, time/batch = 0.7112s	
617/22750 (epoch 1.356), train_loss = 2.47151232, grad/param norm = 3.2169e-01, time/batch = 0.7096s	
618/22750 (epoch 1.358), train_loss = 2.21497295, grad/param norm = 3.1223e-01, time/batch = 0.7097s	
619/22750 (epoch 1.360), train_loss = 2.57679502, grad/param norm = 3.1626e-01, time/batch = 0.7119s	
620/22750 (epoch 1.363), train_loss = 2.44469810, grad/param norm = 2.7227e-01, time/batch = 0.6950s	
621/22750 (epoch 1.365), train_loss = 2.01899561, grad/param norm = 3.0720e-01, time/batch = 0.7063s	
622/22750 (epoch 1.367), train_loss = 1.92683107, grad/param norm = 2.9027e-01, time/batch = 0.7075s	
623/22750 (epoch 1.369), train_loss = 2.22325648, grad/param norm = 2.8728e-01, time/batch = 0.7072s	
624/22750 (epoch 1.371), train_loss = 2.25025709, grad/param norm = 3.5077e-01, time/batch = 0.7039s	
625/22750 (epoch 1.374), train_loss = 2.12113089, grad/param norm = 4.1565e-01, time/batch = 0.7105s	
626/22750 (epoch 1.376), train_loss = 2.43965587, grad/param norm = 3.7346e-01, time/batch = 0.7122s	
627/22750 (epoch 1.378), train_loss = 2.23023883, grad/param norm = 3.4195e-01, time/batch = 0.7026s	
628/22750 (epoch 1.380), train_loss = 2.47314713, grad/param norm = 3.5957e-01, time/batch = 0.7040s	
629/22750 (epoch 1.382), train_loss = 2.23078397, grad/param norm = 3.6747e-01, time/batch = 0.7022s	
630/22750 (epoch 1.385), train_loss = 2.33585295, grad/param norm = 4.1246e-01, time/batch = 0.7342s	
631/22750 (epoch 1.387), train_loss = 2.43091183, grad/param norm = 3.8937e-01, time/batch = 0.7262s	
632/22750 (epoch 1.389), train_loss = 2.05396594, grad/param norm = 3.4394e-01, time/batch = 0.7208s	
633/22750 (epoch 1.391), train_loss = 2.00235437, grad/param norm = 3.9663e-01, time/batch = 0.7061s	
634/22750 (epoch 1.393), train_loss = 2.25272047, grad/param norm = 4.1181e-01, time/batch = 0.7143s	
635/22750 (epoch 1.396), train_loss = 2.36007999, grad/param norm = 3.3621e-01, time/batch = 0.7059s	
636/22750 (epoch 1.398), train_loss = 2.26950190, grad/param norm = 4.2681e-01, time/batch = 0.7068s	
637/22750 (epoch 1.400), train_loss = 2.30496261, grad/param norm = 4.2285e-01, time/batch = 0.7080s	
638/22750 (epoch 1.402), train_loss = 2.32701957, grad/param norm = 3.6587e-01, time/batch = 0.6988s	
639/22750 (epoch 1.404), train_loss = 2.42724383, grad/param norm = 3.1221e-01, time/batch = 0.7003s	
640/22750 (epoch 1.407), train_loss = 2.32522905, grad/param norm = 2.9318e-01, time/batch = 0.7035s	
641/22750 (epoch 1.409), train_loss = 2.34675037, grad/param norm = 3.0195e-01, time/batch = 0.7020s	
642/22750 (epoch 1.411), train_loss = 2.33001320, grad/param norm = 2.8813e-01, time/batch = 0.6946s	
643/22750 (epoch 1.413), train_loss = 2.29983189, grad/param norm = 3.1425e-01, time/batch = 0.7038s	
644/22750 (epoch 1.415), train_loss = 2.15076772, grad/param norm = 3.3253e-01, time/batch = 0.7016s	
645/22750 (epoch 1.418), train_loss = 2.05046400, grad/param norm = 2.7122e-01, time/batch = 0.7020s	
646/22750 (epoch 1.420), train_loss = 2.42116803, grad/param norm = 3.0048e-01, time/batch = 0.7063s	
647/22750 (epoch 1.422), train_loss = 2.60587923, grad/param norm = 3.1677e-01, time/batch = 0.7045s	
648/22750 (epoch 1.424), train_loss = 2.61489076, grad/param norm = 3.2905e-01, time/batch = 0.7005s	
649/22750 (epoch 1.426), train_loss = 2.53962036, grad/param norm = 2.8926e-01, time/batch = 0.7011s	
650/22750 (epoch 1.429), train_loss = 2.06612209, grad/param norm = 3.2295e-01, time/batch = 0.7042s	
651/22750 (epoch 1.431), train_loss = 2.18151622, grad/param norm = 3.8936e-01, time/batch = 0.7085s	
652/22750 (epoch 1.433), train_loss = 2.18482491, grad/param norm = 3.6535e-01, time/batch = 0.7008s	
653/22750 (epoch 1.435), train_loss = 2.21454324, grad/param norm = 3.9982e-01, time/batch = 0.7018s	
654/22750 (epoch 1.437), train_loss = 2.15745212, grad/param norm = 2.7351e-01, time/batch = 0.7094s	
655/22750 (epoch 1.440), train_loss = 2.56122546, grad/param norm = 3.1495e-01, time/batch = 0.7147s	
656/22750 (epoch 1.442), train_loss = 2.38173425, grad/param norm = 3.7865e-01, time/batch = 0.7089s	
657/22750 (epoch 1.444), train_loss = 2.59354583, grad/param norm = 5.8074e-01, time/batch = 0.7120s	
658/22750 (epoch 1.446), train_loss = 2.44096139, grad/param norm = 4.6088e-01, time/batch = 0.7113s	
659/22750 (epoch 1.448), train_loss = 2.55988160, grad/param norm = 3.1396e-01, time/batch = 0.7090s	
660/22750 (epoch 1.451), train_loss = 2.44415180, grad/param norm = 3.2325e-01, time/batch = 0.7068s	
661/22750 (epoch 1.453), train_loss = 2.58388058, grad/param norm = 4.8629e-01, time/batch = 0.7158s	
662/22750 (epoch 1.455), train_loss = 2.52924764, grad/param norm = 3.9191e-01, time/batch = 0.7026s	
663/22750 (epoch 1.457), train_loss = 2.52924108, grad/param norm = 3.1735e-01, time/batch = 0.7040s	
664/22750 (epoch 1.459), train_loss = 2.38103986, grad/param norm = 2.9842e-01, time/batch = 0.6999s	
665/22750 (epoch 1.462), train_loss = 2.25097992, grad/param norm = 2.4508e-01, time/batch = 0.7065s	
666/22750 (epoch 1.464), train_loss = 2.12210531, grad/param norm = 2.6898e-01, time/batch = 0.7075s	
667/22750 (epoch 1.466), train_loss = 2.40856533, grad/param norm = 2.5930e-01, time/batch = 0.7196s	
668/22750 (epoch 1.468), train_loss = 2.25430413, grad/param norm = 3.2110e-01, time/batch = 0.7257s	
669/22750 (epoch 1.470), train_loss = 2.36338078, grad/param norm = 3.0040e-01, time/batch = 0.7227s	
670/22750 (epoch 1.473), train_loss = 2.34224147, grad/param norm = 2.6463e-01, time/batch = 0.7144s	
671/22750 (epoch 1.475), train_loss = 2.44157542, grad/param norm = 2.6501e-01, time/batch = 0.7124s	
672/22750 (epoch 1.477), train_loss = 2.17622841, grad/param norm = 2.9311e-01, time/batch = 0.7072s	
673/22750 (epoch 1.479), train_loss = 2.28992953, grad/param norm = 2.9086e-01, time/batch = 0.7038s	
674/22750 (epoch 1.481), train_loss = 2.19214446, grad/param norm = 3.2659e-01, time/batch = 0.7125s	
675/22750 (epoch 1.484), train_loss = 2.07126627, grad/param norm = 3.3361e-01, time/batch = 0.7050s	
676/22750 (epoch 1.486), train_loss = 2.28865242, grad/param norm = 3.6263e-01, time/batch = 0.7091s	
677/22750 (epoch 1.488), train_loss = 1.95283486, grad/param norm = 4.1779e-01, time/batch = 0.7171s	
678/22750 (epoch 1.490), train_loss = 2.17251210, grad/param norm = 3.1981e-01, time/batch = 0.7149s	
679/22750 (epoch 1.492), train_loss = 2.37589642, grad/param norm = 3.6628e-01, time/batch = 0.7080s	
680/22750 (epoch 1.495), train_loss = 2.23143992, grad/param norm = 3.4913e-01, time/batch = 0.7001s	
681/22750 (epoch 1.497), train_loss = 2.31916487, grad/param norm = 2.9284e-01, time/batch = 0.7096s	
682/22750 (epoch 1.499), train_loss = 2.24292033, grad/param norm = 2.7358e-01, time/batch = 0.7118s	
683/22750 (epoch 1.501), train_loss = 2.18572251, grad/param norm = 2.7324e-01, time/batch = 0.7276s	
684/22750 (epoch 1.503), train_loss = 2.34426633, grad/param norm = 2.8868e-01, time/batch = 0.7270s	
685/22750 (epoch 1.505), train_loss = 2.15414357, grad/param norm = 3.0928e-01, time/batch = 0.7191s	
686/22750 (epoch 1.508), train_loss = 2.08193445, grad/param norm = 3.0133e-01, time/batch = 0.7132s	
687/22750 (epoch 1.510), train_loss = 2.20089593, grad/param norm = 2.9005e-01, time/batch = 0.7082s	
688/22750 (epoch 1.512), train_loss = 2.12976273, grad/param norm = 2.7082e-01, time/batch = 0.7049s	
689/22750 (epoch 1.514), train_loss = 2.33543086, grad/param norm = 3.7121e-01, time/batch = 0.7001s	
690/22750 (epoch 1.516), train_loss = 2.10523583, grad/param norm = 3.3049e-01, time/batch = 0.7026s	
691/22750 (epoch 1.519), train_loss = 2.32990440, grad/param norm = 3.4910e-01, time/batch = 0.7081s	
692/22750 (epoch 1.521), train_loss = 2.14292624, grad/param norm = 3.1586e-01, time/batch = 0.7036s	
693/22750 (epoch 1.523), train_loss = 2.13955393, grad/param norm = 3.2005e-01, time/batch = 0.7052s	
694/22750 (epoch 1.525), train_loss = 2.37490743, grad/param norm = 3.1730e-01, time/batch = 0.7062s	
695/22750 (epoch 1.527), train_loss = 2.22564453, grad/param norm = 2.9754e-01, time/batch = 0.7085s	
696/22750 (epoch 1.530), train_loss = 2.22185398, grad/param norm = 4.3666e-01, time/batch = 0.7070s	
697/22750 (epoch 1.532), train_loss = 2.29810962, grad/param norm = 4.4119e-01, time/batch = 0.7058s	
698/22750 (epoch 1.534), train_loss = 2.36519200, grad/param norm = 3.7715e-01, time/batch = 0.7017s	
699/22750 (epoch 1.536), train_loss = 2.33298994, grad/param norm = 3.3218e-01, time/batch = 0.7047s	
700/22750 (epoch 1.538), train_loss = 2.44546087, grad/param norm = 3.0822e-01, time/batch = 0.7080s	
701/22750 (epoch 1.541), train_loss = 1.97181740, grad/param norm = 2.8705e-01, time/batch = 0.7035s	
702/22750 (epoch 1.543), train_loss = 1.95799810, grad/param norm = 2.3157e-01, time/batch = 0.7133s	
703/22750 (epoch 1.545), train_loss = 2.37354802, grad/param norm = 3.0636e-01, time/batch = 0.7231s	
704/22750 (epoch 1.547), train_loss = 2.12469376, grad/param norm = 2.5353e-01, time/batch = 0.7062s	
705/22750 (epoch 1.549), train_loss = 2.06854727, grad/param norm = 2.7856e-01, time/batch = 0.7149s	
706/22750 (epoch 1.552), train_loss = 2.32144913, grad/param norm = 2.9479e-01, time/batch = 0.7108s	
707/22750 (epoch 1.554), train_loss = 2.25647649, grad/param norm = 2.9051e-01, time/batch = 0.6984s	
708/22750 (epoch 1.556), train_loss = 2.28946944, grad/param norm = 3.5443e-01, time/batch = 0.6942s	
709/22750 (epoch 1.558), train_loss = 2.44510410, grad/param norm = 3.7047e-01, time/batch = 0.6927s	
710/22750 (epoch 1.560), train_loss = 2.25224821, grad/param norm = 3.2524e-01, time/batch = 0.7044s	
711/22750 (epoch 1.563), train_loss = 2.31485085, grad/param norm = 3.3447e-01, time/batch = 0.7102s	
712/22750 (epoch 1.565), train_loss = 2.49447732, grad/param norm = 2.8887e-01, time/batch = 0.6847s	
713/22750 (epoch 1.567), train_loss = 2.20862672, grad/param norm = 3.1712e-01, time/batch = 0.6840s	
714/22750 (epoch 1.569), train_loss = 2.29145807, grad/param norm = 3.7147e-01, time/batch = 0.6837s	
715/22750 (epoch 1.571), train_loss = 2.27945171, grad/param norm = 3.4013e-01, time/batch = 0.6853s	
716/22750 (epoch 1.574), train_loss = 2.10160142, grad/param norm = 3.4837e-01, time/batch = 0.6850s	
717/22750 (epoch 1.576), train_loss = 2.22016343, grad/param norm = 2.8707e-01, time/batch = 0.6920s	
718/22750 (epoch 1.578), train_loss = 2.11070826, grad/param norm = 2.9673e-01, time/batch = 0.6879s	
719/22750 (epoch 1.580), train_loss = 2.26748399, grad/param norm = 3.0964e-01, time/batch = 0.6886s	
720/22750 (epoch 1.582), train_loss = 2.11257035, grad/param norm = 3.3862e-01, time/batch = 0.6870s	
721/22750 (epoch 1.585), train_loss = 2.00146628, grad/param norm = 2.9915e-01, time/batch = 0.6874s	
722/22750 (epoch 1.587), train_loss = 2.14231028, grad/param norm = 2.8552e-01, time/batch = 0.7011s	
723/22750 (epoch 1.589), train_loss = 2.18239278, grad/param norm = 3.0600e-01, time/batch = 0.7076s	
724/22750 (epoch 1.591), train_loss = 2.25501255, grad/param norm = 2.9285e-01, time/batch = 0.6880s	
725/22750 (epoch 1.593), train_loss = 2.38839558, grad/param norm = 3.1321e-01, time/batch = 0.6865s	
726/22750 (epoch 1.596), train_loss = 2.27902075, grad/param norm = 2.6396e-01, time/batch = 0.6854s	
727/22750 (epoch 1.598), train_loss = 2.41301129, grad/param norm = 2.5507e-01, time/batch = 0.6826s	
728/22750 (epoch 1.600), train_loss = 2.15235950, grad/param norm = 2.9519e-01, time/batch = 0.6865s	
729/22750 (epoch 1.602), train_loss = 2.02218140, grad/param norm = 3.0432e-01, time/batch = 0.6844s	
730/22750 (epoch 1.604), train_loss = 2.22982599, grad/param norm = 2.9689e-01, time/batch = 0.6845s	
731/22750 (epoch 1.607), train_loss = 1.83681963, grad/param norm = 2.5513e-01, time/batch = 0.6885s	
732/22750 (epoch 1.609), train_loss = 1.96005524, grad/param norm = 2.4869e-01, time/batch = 0.6896s	
733/22750 (epoch 1.611), train_loss = 2.12454978, grad/param norm = 3.0702e-01, time/batch = 0.7014s	
734/22750 (epoch 1.613), train_loss = 2.07377570, grad/param norm = 3.4038e-01, time/batch = 0.6833s	
735/22750 (epoch 1.615), train_loss = 2.17533773, grad/param norm = 3.8033e-01, time/batch = 0.7021s	
736/22750 (epoch 1.618), train_loss = 2.08939733, grad/param norm = 3.6668e-01, time/batch = 0.6906s	
737/22750 (epoch 1.620), train_loss = 2.16967106, grad/param norm = 3.3400e-01, time/batch = 0.7022s	
738/22750 (epoch 1.622), train_loss = 2.08721086, grad/param norm = 4.5644e-01, time/batch = 0.6996s	
739/22750 (epoch 1.624), train_loss = 2.45017345, grad/param norm = 4.7786e-01, time/batch = 0.6962s	
740/22750 (epoch 1.626), train_loss = 2.39817796, grad/param norm = 6.7667e-01, time/batch = 0.7156s	
741/22750 (epoch 1.629), train_loss = 2.30556100, grad/param norm = 4.7663e-01, time/batch = 0.7070s	
742/22750 (epoch 1.631), train_loss = 2.34456452, grad/param norm = 2.5425e-01, time/batch = 0.7046s	
743/22750 (epoch 1.633), train_loss = 2.05400653, grad/param norm = 2.6638e-01, time/batch = 0.7051s	
744/22750 (epoch 1.635), train_loss = 2.38459707, grad/param norm = 2.8416e-01, time/batch = 0.6850s	
745/22750 (epoch 1.637), train_loss = 2.37594649, grad/param norm = 3.3551e-01, time/batch = 0.6838s	
746/22750 (epoch 1.640), train_loss = 2.46168296, grad/param norm = 2.8894e-01, time/batch = 0.6840s	
747/22750 (epoch 1.642), train_loss = 2.36114026, grad/param norm = 2.7205e-01, time/batch = 0.6851s	
748/22750 (epoch 1.644), train_loss = 2.20468376, grad/param norm = 2.5876e-01, time/batch = 0.6880s	
749/22750 (epoch 1.646), train_loss = 2.17928687, grad/param norm = 2.9221e-01, time/batch = 0.6967s	
750/22750 (epoch 1.648), train_loss = 2.24364561, grad/param norm = 2.9181e-01, time/batch = 0.7091s	
751/22750 (epoch 1.651), train_loss = 2.35807933, grad/param norm = 3.0691e-01, time/batch = 0.6874s	
752/22750 (epoch 1.653), train_loss = 2.18769392, grad/param norm = 3.0662e-01, time/batch = 0.6919s	
753/22750 (epoch 1.655), train_loss = 2.25183371, grad/param norm = 3.3881e-01, time/batch = 0.7062s	
754/22750 (epoch 1.657), train_loss = 2.36699836, grad/param norm = 2.4405e-01, time/batch = 0.7083s	
755/22750 (epoch 1.659), train_loss = 2.34334983, grad/param norm = 2.7492e-01, time/batch = 0.7116s	
756/22750 (epoch 1.662), train_loss = 2.51305047, grad/param norm = 2.9898e-01, time/batch = 0.7057s	
757/22750 (epoch 1.664), train_loss = 2.28062148, grad/param norm = 3.3454e-01, time/batch = 0.6910s	
758/22750 (epoch 1.666), train_loss = 2.24921907, grad/param norm = 4.3461e-01, time/batch = 0.6952s	
759/22750 (epoch 1.668), train_loss = 2.23426158, grad/param norm = 3.0375e-01, time/batch = 0.7102s	
760/22750 (epoch 1.670), train_loss = 2.25453919, grad/param norm = 3.1002e-01, time/batch = 0.7029s	
761/22750 (epoch 1.673), train_loss = 2.28138553, grad/param norm = 3.0808e-01, time/batch = 0.6918s	
762/22750 (epoch 1.675), train_loss = 2.58023981, grad/param norm = 3.7987e-01, time/batch = 0.6970s	
763/22750 (epoch 1.677), train_loss = 2.36580686, grad/param norm = 3.5294e-01, time/batch = 0.6873s	
764/22750 (epoch 1.679), train_loss = 2.49261650, grad/param norm = 2.5801e-01, time/batch = 0.6859s	
765/22750 (epoch 1.681), train_loss = 2.32166245, grad/param norm = 2.8396e-01, time/batch = 0.6944s	
766/22750 (epoch 1.684), train_loss = 2.37070168, grad/param norm = 2.8114e-01, time/batch = 0.6915s	
767/22750 (epoch 1.686), train_loss = 2.28047205, grad/param norm = 2.8527e-01, time/batch = 0.6876s	
768/22750 (epoch 1.688), train_loss = 2.31637916, grad/param norm = 2.9824e-01, time/batch = 0.6942s	
769/22750 (epoch 1.690), train_loss = 2.25157463, grad/param norm = 3.0794e-01, time/batch = 0.6987s	
770/22750 (epoch 1.692), train_loss = 2.36676083, grad/param norm = 3.1514e-01, time/batch = 0.6847s	
771/22750 (epoch 1.695), train_loss = 2.24428952, grad/param norm = 2.7628e-01, time/batch = 0.6862s	
772/22750 (epoch 1.697), train_loss = 2.11177548, grad/param norm = 2.7020e-01, time/batch = 0.6849s	
773/22750 (epoch 1.699), train_loss = 2.30791446, grad/param norm = 2.8969e-01, time/batch = 0.6880s	
774/22750 (epoch 1.701), train_loss = 2.23680953, grad/param norm = 2.6078e-01, time/batch = 0.6902s	
775/22750 (epoch 1.703), train_loss = 2.23698151, grad/param norm = 3.0229e-01, time/batch = 0.6874s	
776/22750 (epoch 1.705), train_loss = 2.04500909, grad/param norm = 2.9373e-01, time/batch = 0.6889s	
777/22750 (epoch 1.708), train_loss = 2.31288597, grad/param norm = 2.5759e-01, time/batch = 0.6851s	
778/22750 (epoch 1.710), train_loss = 2.03732713, grad/param norm = 3.1276e-01, time/batch = 0.6883s	
779/22750 (epoch 1.712), train_loss = 2.15588675, grad/param norm = 3.0189e-01, time/batch = 0.6932s	
780/22750 (epoch 1.714), train_loss = 2.08413835, grad/param norm = 2.9926e-01, time/batch = 0.6936s	
781/22750 (epoch 1.716), train_loss = 2.18351435, grad/param norm = 3.0736e-01, time/batch = 0.6921s	
782/22750 (epoch 1.719), train_loss = 2.32877743, grad/param norm = 4.0311e-01, time/batch = 0.6904s	
783/22750 (epoch 1.721), train_loss = 2.27690384, grad/param norm = 4.0242e-01, time/batch = 0.6913s	
784/22750 (epoch 1.723), train_loss = 2.22273025, grad/param norm = 2.8844e-01, time/batch = 0.6884s	
785/22750 (epoch 1.725), train_loss = 2.13385599, grad/param norm = 2.5376e-01, time/batch = 0.6877s	
786/22750 (epoch 1.727), train_loss = 2.07279842, grad/param norm = 2.7978e-01, time/batch = 0.6858s	
787/22750 (epoch 1.730), train_loss = 2.00638661, grad/param norm = 2.6011e-01, time/batch = 0.6909s	
788/22750 (epoch 1.732), train_loss = 2.22430496, grad/param norm = 3.4907e-01, time/batch = 0.7000s	
789/22750 (epoch 1.734), train_loss = 1.88221647, grad/param norm = 5.0332e-01, time/batch = 0.7104s	
790/22750 (epoch 1.736), train_loss = 2.17081266, grad/param norm = 3.7427e-01, time/batch = 0.6913s	
791/22750 (epoch 1.738), train_loss = 2.05022906, grad/param norm = 3.1464e-01, time/batch = 0.6934s	
792/22750 (epoch 1.741), train_loss = 2.26325090, grad/param norm = 2.4633e-01, time/batch = 0.6885s	
793/22750 (epoch 1.743), train_loss = 2.30977421, grad/param norm = 2.7517e-01, time/batch = 0.6947s	
794/22750 (epoch 1.745), train_loss = 2.08869169, grad/param norm = 3.0703e-01, time/batch = 0.6987s	
795/22750 (epoch 1.747), train_loss = 2.06111717, grad/param norm = 3.0766e-01, time/batch = 0.6941s	
796/22750 (epoch 1.749), train_loss = 2.30672808, grad/param norm = 3.1522e-01, time/batch = 0.6897s	
797/22750 (epoch 1.752), train_loss = 2.09046054, grad/param norm = 2.7072e-01, time/batch = 0.6930s	
798/22750 (epoch 1.754), train_loss = 2.24634493, grad/param norm = 3.6557e-01, time/batch = 0.6998s	
799/22750 (epoch 1.756), train_loss = 2.06441260, grad/param norm = 4.7327e-01, time/batch = 0.7095s	
800/22750 (epoch 1.758), train_loss = 2.01445562, grad/param norm = 3.2065e-01, time/batch = 0.6946s	
801/22750 (epoch 1.760), train_loss = 2.31484637, grad/param norm = 3.2408e-01, time/batch = 0.6934s	
802/22750 (epoch 1.763), train_loss = 2.17645997, grad/param norm = 3.3582e-01, time/batch = 0.7024s	
803/22750 (epoch 1.765), train_loss = 2.09419371, grad/param norm = 2.8507e-01, time/batch = 0.7095s	
804/22750 (epoch 1.767), train_loss = 2.05771261, grad/param norm = 2.2063e-01, time/batch = 0.7097s	
805/22750 (epoch 1.769), train_loss = 2.28746162, grad/param norm = 2.8131e-01, time/batch = 0.7023s	
806/22750 (epoch 1.771), train_loss = 2.19540292, grad/param norm = 3.0938e-01, time/batch = 0.6917s	
807/22750 (epoch 1.774), train_loss = 2.19399200, grad/param norm = 3.0918e-01, time/batch = 0.6943s	
808/22750 (epoch 1.776), train_loss = 2.17819897, grad/param norm = 3.1924e-01, time/batch = 0.6949s	
809/22750 (epoch 1.778), train_loss = 2.37461751, grad/param norm = 2.8385e-01, time/batch = 0.6970s	
810/22750 (epoch 1.780), train_loss = 2.26155698, grad/param norm = 3.0601e-01, time/batch = 0.6933s	
811/22750 (epoch 1.782), train_loss = 2.29597850, grad/param norm = 3.0963e-01, time/batch = 0.6932s	
812/22750 (epoch 1.785), train_loss = 2.26657395, grad/param norm = 2.7211e-01, time/batch = 0.6910s	
813/22750 (epoch 1.787), train_loss = 2.11912871, grad/param norm = 2.4389e-01, time/batch = 0.6884s	
814/22750 (epoch 1.789), train_loss = 2.01559088, grad/param norm = 2.3781e-01, time/batch = 0.6866s	
815/22750 (epoch 1.791), train_loss = 2.14824791, grad/param norm = 2.3076e-01, time/batch = 0.6889s	
816/22750 (epoch 1.793), train_loss = 2.14094098, grad/param norm = 2.6546e-01, time/batch = 0.6941s	
817/22750 (epoch 1.796), train_loss = 2.03890482, grad/param norm = 2.4467e-01, time/batch = 0.6972s	
818/22750 (epoch 1.798), train_loss = 2.13927296, grad/param norm = 2.7976e-01, time/batch = 0.6940s	
819/22750 (epoch 1.800), train_loss = 2.17940564, grad/param norm = 3.0434e-01, time/batch = 0.6920s	
820/22750 (epoch 1.802), train_loss = 2.30545586, grad/param norm = 2.9349e-01, time/batch = 0.6981s	
821/22750 (epoch 1.804), train_loss = 2.37542307, grad/param norm = 2.4402e-01, time/batch = 0.6925s	
822/22750 (epoch 1.807), train_loss = 2.18999696, grad/param norm = 2.2942e-01, time/batch = 0.6928s	
823/22750 (epoch 1.809), train_loss = 2.42933534, grad/param norm = 2.8568e-01, time/batch = 0.6885s	
824/22750 (epoch 1.811), train_loss = 2.19325069, grad/param norm = 2.8524e-01, time/batch = 0.6917s	
825/22750 (epoch 1.813), train_loss = 2.36122457, grad/param norm = 2.5587e-01, time/batch = 0.6942s	
826/22750 (epoch 1.815), train_loss = 2.34286701, grad/param norm = 3.5156e-01, time/batch = 0.6920s	
827/22750 (epoch 1.818), train_loss = 2.40375814, grad/param norm = 3.6078e-01, time/batch = 0.6981s	
828/22750 (epoch 1.820), train_loss = 2.38381094, grad/param norm = 3.1911e-01, time/batch = 0.6924s	
829/22750 (epoch 1.822), train_loss = 2.26839819, grad/param norm = 2.7893e-01, time/batch = 0.6943s	
830/22750 (epoch 1.824), train_loss = 2.26567707, grad/param norm = 2.7358e-01, time/batch = 0.6961s	
831/22750 (epoch 1.826), train_loss = 2.17803052, grad/param norm = 2.8145e-01, time/batch = 0.6961s	
832/22750 (epoch 1.829), train_loss = 2.32193402, grad/param norm = 2.7177e-01, time/batch = 0.6980s	
833/22750 (epoch 1.831), train_loss = 2.28030594, grad/param norm = 2.7523e-01, time/batch = 0.6950s	
834/22750 (epoch 1.833), train_loss = 2.40462183, grad/param norm = 2.5781e-01, time/batch = 0.6968s	
835/22750 (epoch 1.835), train_loss = 2.26173509, grad/param norm = 2.5495e-01, time/batch = 0.6914s	
836/22750 (epoch 1.837), train_loss = 2.21732014, grad/param norm = 2.6384e-01, time/batch = 0.6961s	
837/22750 (epoch 1.840), train_loss = 2.26979920, grad/param norm = 3.6098e-01, time/batch = 0.6952s	
838/22750 (epoch 1.842), train_loss = 2.28302873, grad/param norm = 3.6492e-01, time/batch = 0.6910s	
839/22750 (epoch 1.844), train_loss = 2.35518875, grad/param norm = 3.5868e-01, time/batch = 0.7047s	
840/22750 (epoch 1.846), train_loss = 2.07779383, grad/param norm = 2.9008e-01, time/batch = 0.7093s	
841/22750 (epoch 1.848), train_loss = 2.06523633, grad/param norm = 3.6271e-01, time/batch = 0.7175s	
842/22750 (epoch 1.851), train_loss = 2.15460848, grad/param norm = 3.9418e-01, time/batch = 0.6999s	
843/22750 (epoch 1.853), train_loss = 2.12245788, grad/param norm = 2.9467e-01, time/batch = 0.7151s	
844/22750 (epoch 1.855), train_loss = 2.02984940, grad/param norm = 2.3976e-01, time/batch = 0.7023s	
845/22750 (epoch 1.857), train_loss = 2.21419691, grad/param norm = 2.6021e-01, time/batch = 0.7028s	
846/22750 (epoch 1.859), train_loss = 2.20804710, grad/param norm = 2.7603e-01, time/batch = 0.7182s	
847/22750 (epoch 1.862), train_loss = 2.28033240, grad/param norm = 2.6426e-01, time/batch = 0.7032s	
848/22750 (epoch 1.864), train_loss = 2.28080954, grad/param norm = 2.9245e-01, time/batch = 0.6973s	
849/22750 (epoch 1.866), train_loss = 2.16479459, grad/param norm = 2.7093e-01, time/batch = 0.7025s	
850/22750 (epoch 1.868), train_loss = 2.21368787, grad/param norm = 2.7676e-01, time/batch = 0.6970s	
851/22750 (epoch 1.870), train_loss = 1.95158589, grad/param norm = 2.4703e-01, time/batch = 0.7032s	
852/22750 (epoch 1.873), train_loss = 2.16915778, grad/param norm = 2.7543e-01, time/batch = 0.7039s	
853/22750 (epoch 1.875), train_loss = 2.21100061, grad/param norm = 2.8476e-01, time/batch = 0.6968s	
854/22750 (epoch 1.877), train_loss = 2.08199341, grad/param norm = 2.9083e-01, time/batch = 0.6963s	
855/22750 (epoch 1.879), train_loss = 2.30859907, grad/param norm = 3.4099e-01, time/batch = 0.6917s	
856/22750 (epoch 1.881), train_loss = 2.22727965, grad/param norm = 3.4617e-01, time/batch = 0.6901s	
857/22750 (epoch 1.884), train_loss = 2.29432529, grad/param norm = 3.4354e-01, time/batch = 0.6917s	
858/22750 (epoch 1.886), train_loss = 2.25186996, grad/param norm = 3.0624e-01, time/batch = 0.6937s	
859/22750 (epoch 1.888), train_loss = 2.20333336, grad/param norm = 3.3414e-01, time/batch = 0.6912s	
860/22750 (epoch 1.890), train_loss = 2.20476078, grad/param norm = 3.8288e-01, time/batch = 0.6914s	
861/22750 (epoch 1.892), train_loss = 2.61653387, grad/param norm = 3.6566e-01, time/batch = 0.6874s	
862/22750 (epoch 1.895), train_loss = 2.39577270, grad/param norm = 3.0821e-01, time/batch = 0.6906s	
863/22750 (epoch 1.897), train_loss = 2.28347016, grad/param norm = 2.6363e-01, time/batch = 0.6935s	
864/22750 (epoch 1.899), train_loss = 2.32945954, grad/param norm = 2.6569e-01, time/batch = 0.6895s	
865/22750 (epoch 1.901), train_loss = 2.32608528, grad/param norm = 2.4910e-01, time/batch = 0.6914s	
866/22750 (epoch 1.903), train_loss = 2.25573990, grad/param norm = 2.8391e-01, time/batch = 0.6987s	
867/22750 (epoch 1.905), train_loss = 2.16139807, grad/param norm = 2.6114e-01, time/batch = 0.6893s	
868/22750 (epoch 1.908), train_loss = 2.20101561, grad/param norm = 3.2076e-01, time/batch = 0.6948s	
869/22750 (epoch 1.910), train_loss = 2.05141635, grad/param norm = 3.3002e-01, time/batch = 0.6918s	
870/22750 (epoch 1.912), train_loss = 2.03478103, grad/param norm = 2.8936e-01, time/batch = 0.6905s	
871/22750 (epoch 1.914), train_loss = 2.02350192, grad/param norm = 2.5652e-01, time/batch = 0.6865s	
872/22750 (epoch 1.916), train_loss = 1.93188373, grad/param norm = 2.1078e-01, time/batch = 0.6946s	
873/22750 (epoch 1.919), train_loss = 1.97266502, grad/param norm = 2.1615e-01, time/batch = 0.6965s	
874/22750 (epoch 1.921), train_loss = 1.84894583, grad/param norm = 2.4245e-01, time/batch = 0.6927s	
875/22750 (epoch 1.923), train_loss = 2.14293992, grad/param norm = 2.6062e-01, time/batch = 0.6933s	
876/22750 (epoch 1.925), train_loss = 2.13963922, grad/param norm = 2.5584e-01, time/batch = 0.6897s	
877/22750 (epoch 1.927), train_loss = 1.89772444, grad/param norm = 2.8239e-01, time/batch = 0.6934s	
878/22750 (epoch 1.930), train_loss = 2.00963337, grad/param norm = 3.0752e-01, time/batch = 0.6900s	
879/22750 (epoch 1.932), train_loss = 2.40747477, grad/param norm = 3.2509e-01, time/batch = 0.6904s	
880/22750 (epoch 1.934), train_loss = 1.89954802, grad/param norm = 3.0834e-01, time/batch = 0.6922s	
881/22750 (epoch 1.936), train_loss = 2.28171431, grad/param norm = 3.4370e-01, time/batch = 0.6991s	
882/22750 (epoch 1.938), train_loss = 2.20600889, grad/param norm = 3.4815e-01, time/batch = 0.6926s	
883/22750 (epoch 1.941), train_loss = 2.56088003, grad/param norm = 4.2464e-01, time/batch = 0.6966s	
884/22750 (epoch 1.943), train_loss = 2.26841557, grad/param norm = 3.3351e-01, time/batch = 0.6912s	
885/22750 (epoch 1.945), train_loss = 2.20446787, grad/param norm = 2.5541e-01, time/batch = 0.6880s	
886/22750 (epoch 1.947), train_loss = 2.25631163, grad/param norm = 2.9037e-01, time/batch = 0.6931s	
887/22750 (epoch 1.949), train_loss = 2.05616507, grad/param norm = 2.8829e-01, time/batch = 0.6874s	
888/22750 (epoch 1.952), train_loss = 2.09428487, grad/param norm = 2.4887e-01, time/batch = 0.6923s	
889/22750 (epoch 1.954), train_loss = 2.08713194, grad/param norm = 2.5668e-01, time/batch = 0.6935s	
890/22750 (epoch 1.956), train_loss = 2.15754402, grad/param norm = 2.8045e-01, time/batch = 0.6941s	
891/22750 (epoch 1.958), train_loss = 2.15697424, grad/param norm = 2.4527e-01, time/batch = 0.6890s	
892/22750 (epoch 1.960), train_loss = 2.14016037, grad/param norm = 2.6043e-01, time/batch = 0.6885s	
893/22750 (epoch 1.963), train_loss = 2.14470808, grad/param norm = 2.5904e-01, time/batch = 0.6887s	
894/22750 (epoch 1.965), train_loss = 2.15130542, grad/param norm = 2.7421e-01, time/batch = 0.6912s	
895/22750 (epoch 1.967), train_loss = 2.22243937, grad/param norm = 2.6138e-01, time/batch = 0.6928s	
896/22750 (epoch 1.969), train_loss = 2.13373262, grad/param norm = 2.4923e-01, time/batch = 0.6954s	
897/22750 (epoch 1.971), train_loss = 2.11710135, grad/param norm = 2.2893e-01, time/batch = 0.6918s	
898/22750 (epoch 1.974), train_loss = 2.13972675, grad/param norm = 2.5970e-01, time/batch = 0.6986s	
899/22750 (epoch 1.976), train_loss = 2.25565283, grad/param norm = 2.6405e-01, time/batch = 0.6928s	
900/22750 (epoch 1.978), train_loss = 2.08825396, grad/param norm = 3.0508e-01, time/batch = 0.6880s	
901/22750 (epoch 1.980), train_loss = 2.17967880, grad/param norm = 2.7581e-01, time/batch = 0.6962s	
902/22750 (epoch 1.982), train_loss = 2.10787733, grad/param norm = 2.9049e-01, time/batch = 0.6962s	
903/22750 (epoch 1.985), train_loss = 2.36614393, grad/param norm = 2.9729e-01, time/batch = 0.6917s	
904/22750 (epoch 1.987), train_loss = 2.02089081, grad/param norm = 3.1670e-01, time/batch = 0.6961s	
905/22750 (epoch 1.989), train_loss = 2.04772780, grad/param norm = 2.4878e-01, time/batch = 0.6928s	
906/22750 (epoch 1.991), train_loss = 2.23201265, grad/param norm = 2.5972e-01, time/batch = 0.6891s	
907/22750 (epoch 1.993), train_loss = 2.18005511, grad/param norm = 2.6848e-01, time/batch = 0.6923s	
908/22750 (epoch 1.996), train_loss = 2.09737515, grad/param norm = 2.5706e-01, time/batch = 0.6903s	
909/22750 (epoch 1.998), train_loss = 2.32294917, grad/param norm = 2.6015e-01, time/batch = 0.6928s	
910/22750 (epoch 2.000), train_loss = 2.29994974, grad/param norm = 2.5875e-01, time/batch = 0.6959s	
911/22750 (epoch 2.002), train_loss = 2.33135359, grad/param norm = 3.0709e-01, time/batch = 0.7054s	
912/22750 (epoch 2.004), train_loss = 2.27805018, grad/param norm = 3.6757e-01, time/batch = 0.7115s	
913/22750 (epoch 2.007), train_loss = 2.28813323, grad/param norm = 4.2105e-01, time/batch = 0.7027s	
914/22750 (epoch 2.009), train_loss = 2.45108782, grad/param norm = 3.9289e-01, time/batch = 0.6930s	
915/22750 (epoch 2.011), train_loss = 2.30050097, grad/param norm = 3.4516e-01, time/batch = 0.6913s	
916/22750 (epoch 2.013), train_loss = 2.28276570, grad/param norm = 3.3675e-01, time/batch = 0.6947s	
917/22750 (epoch 2.015), train_loss = 2.22311723, grad/param norm = 2.5413e-01, time/batch = 0.6913s	
918/22750 (epoch 2.018), train_loss = 2.13130915, grad/param norm = 2.4102e-01, time/batch = 0.6984s	
919/22750 (epoch 2.020), train_loss = 2.23815269, grad/param norm = 2.6613e-01, time/batch = 0.6898s	
920/22750 (epoch 2.022), train_loss = 2.15501110, grad/param norm = 2.5342e-01, time/batch = 0.7056s	
921/22750 (epoch 2.024), train_loss = 2.10528639, grad/param norm = 2.6198e-01, time/batch = 0.7061s	
922/22750 (epoch 2.026), train_loss = 2.35594392, grad/param norm = 3.5217e-01, time/batch = 0.7049s	
923/22750 (epoch 2.029), train_loss = 1.97787799, grad/param norm = 2.8652e-01, time/batch = 0.7023s	
924/22750 (epoch 2.031), train_loss = 2.40872871, grad/param norm = 2.6718e-01, time/batch = 0.7030s	
925/22750 (epoch 2.033), train_loss = 2.21196901, grad/param norm = 2.6932e-01, time/batch = 0.7256s	
926/22750 (epoch 2.035), train_loss = 2.29462273, grad/param norm = 2.7731e-01, time/batch = 0.7250s	
927/22750 (epoch 2.037), train_loss = 2.37740973, grad/param norm = 2.8175e-01, time/batch = 0.7205s	
928/22750 (epoch 2.040), train_loss = 2.10467622, grad/param norm = 2.9620e-01, time/batch = 0.7059s	
929/22750 (epoch 2.042), train_loss = 2.25680204, grad/param norm = 2.4172e-01, time/batch = 0.7286s	
930/22750 (epoch 2.044), train_loss = 2.09055762, grad/param norm = 2.8557e-01, time/batch = 0.7226s	
931/22750 (epoch 2.046), train_loss = 2.14839044, grad/param norm = 3.1660e-01, time/batch = 0.7223s	
932/22750 (epoch 2.048), train_loss = 2.20005773, grad/param norm = 3.5919e-01, time/batch = 0.7248s	
933/22750 (epoch 2.051), train_loss = 2.31036528, grad/param norm = 3.1679e-01, time/batch = 0.7310s	
934/22750 (epoch 2.053), train_loss = 2.02084914, grad/param norm = 2.8972e-01, time/batch = 0.7195s	
935/22750 (epoch 2.055), train_loss = 2.26889781, grad/param norm = 3.1223e-01, time/batch = 0.7039s	
936/22750 (epoch 2.057), train_loss = 2.20665897, grad/param norm = 3.1930e-01, time/batch = 0.7010s	
937/22750 (epoch 2.059), train_loss = 1.99633964, grad/param norm = 3.3233e-01, time/batch = 0.6992s	
938/22750 (epoch 2.062), train_loss = 2.01797603, grad/param norm = 2.5933e-01, time/batch = 0.7041s	
939/22750 (epoch 2.064), train_loss = 2.16637618, grad/param norm = 2.6252e-01, time/batch = 0.7048s	
940/22750 (epoch 2.066), train_loss = 1.95480316, grad/param norm = 2.4053e-01, time/batch = 0.6973s	
941/22750 (epoch 2.068), train_loss = 1.99783643, grad/param norm = 2.6037e-01, time/batch = 0.6981s	
942/22750 (epoch 2.070), train_loss = 1.83854329, grad/param norm = 2.6973e-01, time/batch = 0.6977s	
943/22750 (epoch 2.073), train_loss = 2.08344978, grad/param norm = 3.2505e-01, time/batch = 0.6982s	
944/22750 (epoch 2.075), train_loss = 2.17785575, grad/param norm = 2.5145e-01, time/batch = 0.6981s	
945/22750 (epoch 2.077), train_loss = 1.86182164, grad/param norm = 2.7723e-01, time/batch = 0.7035s	
946/22750 (epoch 2.079), train_loss = 2.06384483, grad/param norm = 2.6458e-01, time/batch = 0.7009s	
947/22750 (epoch 2.081), train_loss = 2.13770066, grad/param norm = 3.1661e-01, time/batch = 0.7191s	
948/22750 (epoch 2.084), train_loss = 2.06309842, grad/param norm = 2.8197e-01, time/batch = 0.7076s	
949/22750 (epoch 2.086), train_loss = 2.10928031, grad/param norm = 3.0077e-01, time/batch = 0.7007s	
950/22750 (epoch 2.088), train_loss = 2.11827309, grad/param norm = 2.8220e-01, time/batch = 0.7038s	
951/22750 (epoch 2.090), train_loss = 2.13123900, grad/param norm = 3.0978e-01, time/batch = 0.7053s	
952/22750 (epoch 2.092), train_loss = 2.27093224, grad/param norm = 2.8576e-01, time/batch = 0.7008s	
953/22750 (epoch 2.095), train_loss = 2.04334762, grad/param norm = 2.9912e-01, time/batch = 0.7026s	
954/22750 (epoch 2.097), train_loss = 2.08245211, grad/param norm = 2.7184e-01, time/batch = 0.6996s	
955/22750 (epoch 2.099), train_loss = 2.26113386, grad/param norm = 3.5079e-01, time/batch = 0.7006s	
956/22750 (epoch 2.101), train_loss = 2.19273313, grad/param norm = 3.1830e-01, time/batch = 0.7062s	
957/22750 (epoch 2.103), train_loss = 1.99504704, grad/param norm = 2.5768e-01, time/batch = 0.7217s	
958/22750 (epoch 2.105), train_loss = 2.32445948, grad/param norm = 2.8331e-01, time/batch = 0.7048s	
959/22750 (epoch 2.108), train_loss = 2.05825820, grad/param norm = 2.6425e-01, time/batch = 0.7076s	
960/22750 (epoch 2.110), train_loss = 2.07511923, grad/param norm = 2.8043e-01, time/batch = 0.7099s	
961/22750 (epoch 2.112), train_loss = 1.88740989, grad/param norm = 2.5854e-01, time/batch = 0.7222s	
962/22750 (epoch 2.114), train_loss = 1.86712764, grad/param norm = 2.6582e-01, time/batch = 0.7247s	
963/22750 (epoch 2.116), train_loss = 1.98449234, grad/param norm = 3.2546e-01, time/batch = 0.7149s	
964/22750 (epoch 2.119), train_loss = 2.07176532, grad/param norm = 2.5127e-01, time/batch = 0.7259s	
965/22750 (epoch 2.121), train_loss = 2.23325285, grad/param norm = 2.7176e-01, time/batch = 0.7208s	
966/22750 (epoch 2.123), train_loss = 2.03739748, grad/param norm = 2.4708e-01, time/batch = 0.7228s	
967/22750 (epoch 2.125), train_loss = 2.24717417, grad/param norm = 2.5895e-01, time/batch = 0.7064s	
968/22750 (epoch 2.127), train_loss = 2.19459420, grad/param norm = 2.9645e-01, time/batch = 0.7258s	
969/22750 (epoch 2.130), train_loss = 2.17747269, grad/param norm = 2.5960e-01, time/batch = 0.7079s	
970/22750 (epoch 2.132), train_loss = 2.15272022, grad/param norm = 2.5396e-01, time/batch = 0.6998s	
971/22750 (epoch 2.134), train_loss = 2.12834588, grad/param norm = 2.8874e-01, time/batch = 0.7025s	
972/22750 (epoch 2.136), train_loss = 2.03385810, grad/param norm = 2.5645e-01, time/batch = 0.6972s	
973/22750 (epoch 2.138), train_loss = 2.07334691, grad/param norm = 3.3645e-01, time/batch = 0.7062s	
974/22750 (epoch 2.141), train_loss = 2.02538322, grad/param norm = 3.4438e-01, time/batch = 0.7061s	
975/22750 (epoch 2.143), train_loss = 2.04651708, grad/param norm = 2.9618e-01, time/batch = 0.7120s	
976/22750 (epoch 2.145), train_loss = 2.16067900, grad/param norm = 2.8233e-01, time/batch = 0.7018s	
977/22750 (epoch 2.147), train_loss = 2.13703857, grad/param norm = 2.5144e-01, time/batch = 0.7008s	
978/22750 (epoch 2.149), train_loss = 2.14239420, grad/param norm = 2.6748e-01, time/batch = 0.7055s	
979/22750 (epoch 2.152), train_loss = 2.13766459, grad/param norm = 2.8434e-01, time/batch = 0.7129s	
980/22750 (epoch 2.154), train_loss = 1.99628089, grad/param norm = 2.6689e-01, time/batch = 0.7107s	
981/22750 (epoch 2.156), train_loss = 2.11493261, grad/param norm = 2.7262e-01, time/batch = 0.7051s	
982/22750 (epoch 2.158), train_loss = 2.11538638, grad/param norm = 2.6903e-01, time/batch = 0.7258s	
983/22750 (epoch 2.160), train_loss = 2.15603573, grad/param norm = 2.3328e-01, time/batch = 0.7096s	
984/22750 (epoch 2.163), train_loss = 2.28160505, grad/param norm = 2.8074e-01, time/batch = 0.7003s	
985/22750 (epoch 2.165), train_loss = 2.21115490, grad/param norm = 2.6702e-01, time/batch = 0.6981s	
986/22750 (epoch 2.167), train_loss = 1.99571969, grad/param norm = 2.6284e-01, time/batch = 0.7006s	
987/22750 (epoch 2.169), train_loss = 2.09291100, grad/param norm = 2.6277e-01, time/batch = 0.7007s	
988/22750 (epoch 2.171), train_loss = 2.04721743, grad/param norm = 2.4212e-01, time/batch = 0.7033s	
989/22750 (epoch 2.174), train_loss = 1.88405136, grad/param norm = 2.5356e-01, time/batch = 0.7034s	
990/22750 (epoch 2.176), train_loss = 2.08696820, grad/param norm = 2.6892e-01, time/batch = 0.7043s	
991/22750 (epoch 2.178), train_loss = 2.01965098, grad/param norm = 2.7001e-01, time/batch = 0.7157s	
992/22750 (epoch 2.180), train_loss = 2.18609027, grad/param norm = 2.9149e-01, time/batch = 0.7264s	
993/22750 (epoch 2.182), train_loss = 2.14538275, grad/param norm = 2.8407e-01, time/batch = 0.7247s	
994/22750 (epoch 2.185), train_loss = 2.09700049, grad/param norm = 2.6281e-01, time/batch = 0.7593s	
995/22750 (epoch 2.187), train_loss = 1.97261662, grad/param norm = 3.1327e-01, time/batch = 0.7289s	
996/22750 (epoch 2.189), train_loss = 2.02726842, grad/param norm = 3.0218e-01, time/batch = 0.7146s	
997/22750 (epoch 2.191), train_loss = 1.95794722, grad/param norm = 2.7464e-01, time/batch = 0.7494s	
998/22750 (epoch 2.193), train_loss = 2.09147786, grad/param norm = 2.5951e-01, time/batch = 0.7277s	
999/22750 (epoch 2.196), train_loss = 2.15055932, grad/param norm = 2.5448e-01, time/batch = 0.7170s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_wakata_epoch2.20_2.0764.t7	
1000/22750 (epoch 2.198), train_loss = 1.92268552, grad/param norm = 2.2317e-01, time/batch = 0.7243s	
1001/22750 (epoch 2.200), train_loss = 2.23626523, grad/param norm = 2.3907e-01, time/batch = 0.7078s	
1002/22750 (epoch 2.202), train_loss = 2.39004174, grad/param norm = 2.6490e-01, time/batch = 0.7175s	
1003/22750 (epoch 2.204), train_loss = 2.33343522, grad/param norm = 2.5848e-01, time/batch = 0.7339s	
1004/22750 (epoch 2.207), train_loss = 2.02060331, grad/param norm = 2.6830e-01, time/batch = 0.7269s	
1005/22750 (epoch 2.209), train_loss = 2.06969619, grad/param norm = 2.3406e-01, time/batch = 0.7139s	
1006/22750 (epoch 2.211), train_loss = 2.07694446, grad/param norm = 2.5593e-01, time/batch = 0.7114s	
1007/22750 (epoch 2.213), train_loss = 1.97845517, grad/param norm = 3.2431e-01, time/batch = 0.7155s	
1008/22750 (epoch 2.215), train_loss = 2.08543933, grad/param norm = 3.0685e-01, time/batch = 0.7166s	
1009/22750 (epoch 2.218), train_loss = 1.89002770, grad/param norm = 3.1061e-01, time/batch = 0.7211s	
1010/22750 (epoch 2.220), train_loss = 2.14874075, grad/param norm = 2.9256e-01, time/batch = 0.7123s	
1011/22750 (epoch 2.222), train_loss = 1.94820742, grad/param norm = 2.8135e-01, time/batch = 0.7138s	
1012/22750 (epoch 2.224), train_loss = 2.09152432, grad/param norm = 2.7893e-01, time/batch = 0.7228s	
1013/22750 (epoch 2.226), train_loss = 2.09200192, grad/param norm = 2.6188e-01, time/batch = 0.7257s	
1014/22750 (epoch 2.229), train_loss = 2.21257947, grad/param norm = 2.7525e-01, time/batch = 0.7234s	
1015/22750 (epoch 2.231), train_loss = 2.12567980, grad/param norm = 2.5885e-01, time/batch = 0.7144s	
1016/22750 (epoch 2.233), train_loss = 2.10086428, grad/param norm = 2.3914e-01, time/batch = 0.7273s	
1017/22750 (epoch 2.235), train_loss = 1.95639329, grad/param norm = 2.7920e-01, time/batch = 0.7267s	
1018/22750 (epoch 2.237), train_loss = 2.07862389, grad/param norm = 2.8436e-01, time/batch = 0.7213s	
1019/22750 (epoch 2.240), train_loss = 2.25357638, grad/param norm = 2.6890e-01, time/batch = 0.7247s	
1020/22750 (epoch 2.242), train_loss = 2.42267853, grad/param norm = 2.5628e-01, time/batch = 0.7187s	
1021/22750 (epoch 2.244), train_loss = 2.26760770, grad/param norm = 3.9144e-01, time/batch = 0.7249s	
1022/22750 (epoch 2.246), train_loss = 2.43518254, grad/param norm = 3.2940e-01, time/batch = 0.7047s	
1023/22750 (epoch 2.248), train_loss = 2.02399236, grad/param norm = 2.7909e-01, time/batch = 0.7081s	
1024/22750 (epoch 2.251), train_loss = 2.30526188, grad/param norm = 2.7693e-01, time/batch = 0.7169s	
1025/22750 (epoch 2.253), train_loss = 2.16222937, grad/param norm = 2.2488e-01, time/batch = 0.7136s	
1026/22750 (epoch 2.255), train_loss = 2.26469053, grad/param norm = 2.6779e-01, time/batch = 0.7163s	
1027/22750 (epoch 2.257), train_loss = 2.08531572, grad/param norm = 3.0222e-01, time/batch = 0.7120s	
1028/22750 (epoch 2.259), train_loss = 2.16280944, grad/param norm = 2.6454e-01, time/batch = 0.7212s	
1029/22750 (epoch 2.262), train_loss = 2.08494928, grad/param norm = 2.7238e-01, time/batch = 0.7194s	
1030/22750 (epoch 2.264), train_loss = 2.15877697, grad/param norm = 2.4581e-01, time/batch = 0.7189s	
1031/22750 (epoch 2.266), train_loss = 1.96200548, grad/param norm = 2.9475e-01, time/batch = 0.7248s	
1032/22750 (epoch 2.268), train_loss = 2.15750462, grad/param norm = 2.5949e-01, time/batch = 0.7261s	
1033/22750 (epoch 2.270), train_loss = 1.98085254, grad/param norm = 3.0585e-01, time/batch = 0.7266s	
1034/22750 (epoch 2.273), train_loss = 2.23508266, grad/param norm = 3.1790e-01, time/batch = 0.7261s	
1035/22750 (epoch 2.275), train_loss = 2.06882179, grad/param norm = 2.5926e-01, time/batch = 0.7210s	
1036/22750 (epoch 2.277), train_loss = 2.15633438, grad/param norm = 2.6474e-01, time/batch = 0.7181s	
1037/22750 (epoch 2.279), train_loss = 1.88942095, grad/param norm = 2.2468e-01, time/batch = 0.7135s	
1038/22750 (epoch 2.281), train_loss = 2.01500188, grad/param norm = 2.2565e-01, time/batch = 0.7105s	
1039/22750 (epoch 2.284), train_loss = 1.97314260, grad/param norm = 2.2219e-01, time/batch = 0.7110s	
1040/22750 (epoch 2.286), train_loss = 2.04559913, grad/param norm = 2.3980e-01, time/batch = 0.7233s	
1041/22750 (epoch 2.288), train_loss = 2.19917088, grad/param norm = 2.2842e-01, time/batch = 0.7245s	
1042/22750 (epoch 2.290), train_loss = 1.98584813, grad/param norm = 2.5818e-01, time/batch = 0.7196s	
1043/22750 (epoch 2.292), train_loss = 2.01788226, grad/param norm = 2.4497e-01, time/batch = 0.7208s	
1044/22750 (epoch 2.295), train_loss = 2.11843664, grad/param norm = 2.7224e-01, time/batch = 0.7197s	
1045/22750 (epoch 2.297), train_loss = 1.99716011, grad/param norm = 2.8175e-01, time/batch = 0.7107s	
1046/22750 (epoch 2.299), train_loss = 2.23070665, grad/param norm = 3.2525e-01, time/batch = 0.7227s	
1047/22750 (epoch 2.301), train_loss = 2.15631351, grad/param norm = 2.7080e-01, time/batch = 0.7261s	
1048/22750 (epoch 2.303), train_loss = 2.21104049, grad/param norm = 3.1484e-01, time/batch = 0.7276s	
1049/22750 (epoch 2.305), train_loss = 2.24224086, grad/param norm = 3.2111e-01, time/batch = 0.7255s	
1050/22750 (epoch 2.308), train_loss = 2.09187278, grad/param norm = 2.6134e-01, time/batch = 0.7194s	
1051/22750 (epoch 2.310), train_loss = 1.99785799, grad/param norm = 2.5636e-01, time/batch = 0.7273s	
1052/22750 (epoch 2.312), train_loss = 2.04746850, grad/param norm = 2.4269e-01, time/batch = 0.7265s	
1053/22750 (epoch 2.314), train_loss = 2.10623981, grad/param norm = 2.4629e-01, time/batch = 0.7184s	
1054/22750 (epoch 2.316), train_loss = 2.04678958, grad/param norm = 2.5511e-01, time/batch = 0.7245s	
1055/22750 (epoch 2.319), train_loss = 2.14397649, grad/param norm = 2.5369e-01, time/batch = 0.7213s	
1056/22750 (epoch 2.321), train_loss = 2.05119453, grad/param norm = 2.8894e-01, time/batch = 0.7325s	
1057/22750 (epoch 2.323), train_loss = 1.92927454, grad/param norm = 2.6818e-01, time/batch = 0.7215s	
1058/22750 (epoch 2.325), train_loss = 1.83184258, grad/param norm = 2.3444e-01, time/batch = 0.7243s	
1059/22750 (epoch 2.327), train_loss = 2.21438224, grad/param norm = 2.8175e-01, time/batch = 0.7228s	
1060/22750 (epoch 2.330), train_loss = 2.34759235, grad/param norm = 2.6645e-01, time/batch = 0.7116s	
1061/22750 (epoch 2.332), train_loss = 2.07011947, grad/param norm = 2.5259e-01, time/batch = 0.7140s	
1062/22750 (epoch 2.334), train_loss = 1.89753746, grad/param norm = 2.7929e-01, time/batch = 0.7145s	
1063/22750 (epoch 2.336), train_loss = 2.13356357, grad/param norm = 2.5128e-01, time/batch = 0.7241s	
1064/22750 (epoch 2.338), train_loss = 2.17429241, grad/param norm = 3.1047e-01, time/batch = 0.7253s	
1065/22750 (epoch 2.341), train_loss = 2.07276980, grad/param norm = 2.4035e-01, time/batch = 0.7191s	
1066/22750 (epoch 2.343), train_loss = 1.91887011, grad/param norm = 2.6801e-01, time/batch = 0.7189s	
1067/22750 (epoch 2.345), train_loss = 2.30180388, grad/param norm = 2.8025e-01, time/batch = 0.7138s	
1068/22750 (epoch 2.347), train_loss = 2.25031437, grad/param norm = 2.6830e-01, time/batch = 0.7076s	
1069/22750 (epoch 2.349), train_loss = 1.78888810, grad/param norm = 2.8097e-01, time/batch = 0.7221s	
1070/22750 (epoch 2.352), train_loss = 2.13595681, grad/param norm = 2.9993e-01, time/batch = 0.7209s	
1071/22750 (epoch 2.354), train_loss = 2.19379940, grad/param norm = 2.7155e-01, time/batch = 0.7154s	
1072/22750 (epoch 2.356), train_loss = 2.24730744, grad/param norm = 2.6462e-01, time/batch = 0.7182s	
1073/22750 (epoch 2.358), train_loss = 1.98094116, grad/param norm = 2.5309e-01, time/batch = 0.7123s	
1074/22750 (epoch 2.360), train_loss = 2.32691804, grad/param norm = 2.4852e-01, time/batch = 0.7219s	
1075/22750 (epoch 2.363), train_loss = 2.15934078, grad/param norm = 2.4767e-01, time/batch = 0.7265s	
1076/22750 (epoch 2.365), train_loss = 1.77577163, grad/param norm = 2.9980e-01, time/batch = 0.7166s	
1077/22750 (epoch 2.367), train_loss = 1.73829742, grad/param norm = 2.7096e-01, time/batch = 0.7085s	
1078/22750 (epoch 2.369), train_loss = 2.00231252, grad/param norm = 2.6004e-01, time/batch = 0.7106s	
1079/22750 (epoch 2.371), train_loss = 1.98598133, grad/param norm = 2.8606e-01, time/batch = 0.7123s	
1080/22750 (epoch 2.374), train_loss = 1.87706866, grad/param norm = 3.2872e-01, time/batch = 0.7127s	
1081/22750 (epoch 2.376), train_loss = 2.18167254, grad/param norm = 2.8156e-01, time/batch = 0.7123s	
1082/22750 (epoch 2.378), train_loss = 1.96117950, grad/param norm = 2.2571e-01, time/batch = 0.7109s	
1083/22750 (epoch 2.380), train_loss = 2.21462217, grad/param norm = 2.6992e-01, time/batch = 0.7135s	
1084/22750 (epoch 2.382), train_loss = 1.96765179, grad/param norm = 2.9382e-01, time/batch = 0.7150s	
1085/22750 (epoch 2.385), train_loss = 2.06255089, grad/param norm = 2.5555e-01, time/batch = 0.7245s	
1086/22750 (epoch 2.387), train_loss = 2.16169060, grad/param norm = 2.7613e-01, time/batch = 0.7242s	
1087/22750 (epoch 2.389), train_loss = 1.74968321, grad/param norm = 3.0611e-01, time/batch = 0.7256s	
1088/22750 (epoch 2.391), train_loss = 1.63618048, grad/param norm = 2.5741e-01, time/batch = 0.7198s	
1089/22750 (epoch 2.393), train_loss = 1.94429572, grad/param norm = 3.0848e-01, time/batch = 0.7168s	
1090/22750 (epoch 2.396), train_loss = 2.07576952, grad/param norm = 2.7215e-01, time/batch = 0.7219s	
1091/22750 (epoch 2.398), train_loss = 2.03089542, grad/param norm = 3.3977e-01, time/batch = 0.7258s	
1092/22750 (epoch 2.400), train_loss = 2.01638235, grad/param norm = 2.6559e-01, time/batch = 0.7402s	
1093/22750 (epoch 2.402), train_loss = 2.07225177, grad/param norm = 3.0425e-01, time/batch = 0.7411s	
1094/22750 (epoch 2.404), train_loss = 2.20703730, grad/param norm = 2.7402e-01, time/batch = 0.7261s	
1095/22750 (epoch 2.407), train_loss = 2.10574455, grad/param norm = 3.0203e-01, time/batch = 0.7250s	
1096/22750 (epoch 2.409), train_loss = 2.07012732, grad/param norm = 2.6759e-01, time/batch = 0.7195s	
1097/22750 (epoch 2.411), train_loss = 2.09511017, grad/param norm = 2.5766e-01, time/batch = 0.7134s	
1098/22750 (epoch 2.413), train_loss = 2.03934812, grad/param norm = 2.8793e-01, time/batch = 0.7204s	
1099/22750 (epoch 2.415), train_loss = 1.84315176, grad/param norm = 2.9075e-01, time/batch = 0.7122s	
1100/22750 (epoch 2.418), train_loss = 1.86351482, grad/param norm = 2.3435e-01, time/batch = 0.7237s	
1101/22750 (epoch 2.420), train_loss = 2.21253356, grad/param norm = 2.7073e-01, time/batch = 0.7162s	
1102/22750 (epoch 2.422), train_loss = 2.34219618, grad/param norm = 2.5218e-01, time/batch = 0.7084s	
1103/22750 (epoch 2.424), train_loss = 2.32159898, grad/param norm = 2.4617e-01, time/batch = 0.7080s	
1104/22750 (epoch 2.426), train_loss = 2.30332236, grad/param norm = 2.2967e-01, time/batch = 0.7106s	
1105/22750 (epoch 2.429), train_loss = 1.83418131, grad/param norm = 2.3564e-01, time/batch = 0.7081s	
1106/22750 (epoch 2.431), train_loss = 1.86267733, grad/param norm = 2.6598e-01, time/batch = 0.7084s	
1107/22750 (epoch 2.433), train_loss = 1.91442875, grad/param norm = 2.4524e-01, time/batch = 0.7100s	
1108/22750 (epoch 2.435), train_loss = 1.86319171, grad/param norm = 2.6970e-01, time/batch = 0.7076s	
1109/22750 (epoch 2.437), train_loss = 1.80106245, grad/param norm = 2.4270e-01, time/batch = 0.7208s	
1110/22750 (epoch 2.440), train_loss = 2.31824144, grad/param norm = 3.1793e-01, time/batch = 0.7090s	
1111/22750 (epoch 2.442), train_loss = 2.08313524, grad/param norm = 2.9952e-01, time/batch = 0.7146s	
1112/22750 (epoch 2.444), train_loss = 2.27198993, grad/param norm = 4.7018e-01, time/batch = 0.7150s	
1113/22750 (epoch 2.446), train_loss = 2.18169690, grad/param norm = 3.9281e-01, time/batch = 0.7179s	
1114/22750 (epoch 2.448), train_loss = 2.29006359, grad/param norm = 3.0213e-01, time/batch = 0.7171s	
1115/22750 (epoch 2.451), train_loss = 2.20419518, grad/param norm = 2.7259e-01, time/batch = 0.7112s	
1116/22750 (epoch 2.453), train_loss = 2.30209687, grad/param norm = 2.7478e-01, time/batch = 0.7110s	
1117/22750 (epoch 2.455), train_loss = 2.28882189, grad/param norm = 2.5493e-01, time/batch = 0.7124s	
1118/22750 (epoch 2.457), train_loss = 2.24877653, grad/param norm = 3.0810e-01, time/batch = 0.7147s	
1119/22750 (epoch 2.459), train_loss = 2.09022379, grad/param norm = 2.5951e-01, time/batch = 0.7183s	
1120/22750 (epoch 2.462), train_loss = 1.97476239, grad/param norm = 2.2022e-01, time/batch = 0.7119s	
1121/22750 (epoch 2.464), train_loss = 1.88352510, grad/param norm = 2.3851e-01, time/batch = 0.7127s	
1122/22750 (epoch 2.466), train_loss = 2.22550789, grad/param norm = 2.2663e-01, time/batch = 0.7145s	
1123/22750 (epoch 2.468), train_loss = 2.06205647, grad/param norm = 2.8514e-01, time/batch = 0.7116s	
1124/22750 (epoch 2.470), train_loss = 2.15199283, grad/param norm = 2.6929e-01, time/batch = 0.7123s	
1125/22750 (epoch 2.473), train_loss = 2.08760949, grad/param norm = 2.4194e-01, time/batch = 0.7094s	
1126/22750 (epoch 2.475), train_loss = 2.18976117, grad/param norm = 2.3251e-01, time/batch = 0.7163s	
1127/22750 (epoch 2.477), train_loss = 1.91889422, grad/param norm = 2.6215e-01, time/batch = 0.7105s	
1128/22750 (epoch 2.479), train_loss = 2.02252120, grad/param norm = 2.3279e-01, time/batch = 0.7120s	
1129/22750 (epoch 2.481), train_loss = 1.91635174, grad/param norm = 2.8382e-01, time/batch = 0.7142s	
1130/22750 (epoch 2.484), train_loss = 1.76947175, grad/param norm = 3.0373e-01, time/batch = 0.7155s	
1131/22750 (epoch 2.486), train_loss = 2.03120937, grad/param norm = 3.2450e-01, time/batch = 0.7218s	
1132/22750 (epoch 2.488), train_loss = 1.67763980, grad/param norm = 3.2657e-01, time/batch = 0.7190s	
1133/22750 (epoch 2.490), train_loss = 1.91445730, grad/param norm = 3.1739e-01, time/batch = 0.7233s	
1134/22750 (epoch 2.492), train_loss = 2.16181365, grad/param norm = 3.1016e-01, time/batch = 0.7241s	
1135/22750 (epoch 2.495), train_loss = 2.01077127, grad/param norm = 2.9949e-01, time/batch = 0.7234s	
1136/22750 (epoch 2.497), train_loss = 2.10713869, grad/param norm = 2.8696e-01, time/batch = 0.7180s	
1137/22750 (epoch 2.499), train_loss = 1.98598978, grad/param norm = 2.4600e-01, time/batch = 0.7214s	
1138/22750 (epoch 2.501), train_loss = 1.97773709, grad/param norm = 2.2779e-01, time/batch = 0.7221s	
1139/22750 (epoch 2.503), train_loss = 2.08214732, grad/param norm = 2.4666e-01, time/batch = 0.7213s	
1140/22750 (epoch 2.505), train_loss = 1.90198310, grad/param norm = 2.7255e-01, time/batch = 0.7214s	
1141/22750 (epoch 2.508), train_loss = 1.81949327, grad/param norm = 2.5940e-01, time/batch = 0.7214s	
1142/22750 (epoch 2.510), train_loss = 1.89648310, grad/param norm = 2.6555e-01, time/batch = 0.7131s	
1143/22750 (epoch 2.512), train_loss = 1.92090895, grad/param norm = 2.4053e-01, time/batch = 0.7137s	
1144/22750 (epoch 2.514), train_loss = 2.02784697, grad/param norm = 2.8211e-01, time/batch = 0.7112s	
1145/22750 (epoch 2.516), train_loss = 1.83789093, grad/param norm = 2.4834e-01, time/batch = 0.7120s	
1146/22750 (epoch 2.519), train_loss = 2.02685899, grad/param norm = 2.6551e-01, time/batch = 0.7088s	
1147/22750 (epoch 2.521), train_loss = 1.81659509, grad/param norm = 2.4532e-01, time/batch = 0.7124s	
1148/22750 (epoch 2.523), train_loss = 1.85366404, grad/param norm = 2.5826e-01, time/batch = 0.7124s	
1149/22750 (epoch 2.525), train_loss = 2.13396122, grad/param norm = 2.6949e-01, time/batch = 0.7095s	
1150/22750 (epoch 2.527), train_loss = 1.99520799, grad/param norm = 2.4633e-01, time/batch = 0.7093s	
1151/22750 (epoch 2.530), train_loss = 1.90873759, grad/param norm = 3.0287e-01, time/batch = 0.7100s	
1152/22750 (epoch 2.532), train_loss = 1.99756267, grad/param norm = 2.8602e-01, time/batch = 0.7125s	
1153/22750 (epoch 2.534), train_loss = 2.13513725, grad/param norm = 2.8694e-01, time/batch = 0.7093s	
1154/22750 (epoch 2.536), train_loss = 2.07675019, grad/param norm = 2.8516e-01, time/batch = 0.7170s	
1155/22750 (epoch 2.538), train_loss = 2.16774464, grad/param norm = 2.4166e-01, time/batch = 0.7164s	
1156/22750 (epoch 2.541), train_loss = 1.72075729, grad/param norm = 2.3628e-01, time/batch = 0.7128s	
1157/22750 (epoch 2.543), train_loss = 1.72711533, grad/param norm = 2.3242e-01, time/batch = 0.7104s	
1158/22750 (epoch 2.545), train_loss = 2.15274370, grad/param norm = 2.6297e-01, time/batch = 0.7226s	
1159/22750 (epoch 2.547), train_loss = 1.81276626, grad/param norm = 2.1859e-01, time/batch = 0.7159s	
1160/22750 (epoch 2.549), train_loss = 1.83052790, grad/param norm = 2.5807e-01, time/batch = 0.7083s	
1161/22750 (epoch 2.552), train_loss = 2.11521335, grad/param norm = 2.7692e-01, time/batch = 0.7174s	
1162/22750 (epoch 2.554), train_loss = 2.06497755, grad/param norm = 2.5471e-01, time/batch = 0.7106s	
1163/22750 (epoch 2.556), train_loss = 2.00189027, grad/param norm = 2.6926e-01, time/batch = 0.7156s	
1164/22750 (epoch 2.558), train_loss = 2.16367163, grad/param norm = 2.6241e-01, time/batch = 0.7132s	
1165/22750 (epoch 2.560), train_loss = 1.88997880, grad/param norm = 2.3109e-01, time/batch = 0.7142s	
1166/22750 (epoch 2.563), train_loss = 2.00883177, grad/param norm = 2.5352e-01, time/batch = 0.7088s	
1167/22750 (epoch 2.565), train_loss = 2.20215395, grad/param norm = 2.4521e-01, time/batch = 0.7032s	
1168/22750 (epoch 2.567), train_loss = 1.97850843, grad/param norm = 2.4588e-01, time/batch = 0.7129s	
1169/22750 (epoch 2.569), train_loss = 1.98393181, grad/param norm = 2.7052e-01, time/batch = 0.7322s	
1170/22750 (epoch 2.571), train_loss = 2.03463497, grad/param norm = 2.7142e-01, time/batch = 0.7337s	
1171/22750 (epoch 2.574), train_loss = 1.82640975, grad/param norm = 2.6277e-01, time/batch = 0.7334s	
1172/22750 (epoch 2.576), train_loss = 2.00783675, grad/param norm = 2.4405e-01, time/batch = 0.7112s	
1173/22750 (epoch 2.578), train_loss = 1.82758963, grad/param norm = 2.6488e-01, time/batch = 0.7097s	
1174/22750 (epoch 2.580), train_loss = 2.04608249, grad/param norm = 2.5031e-01, time/batch = 0.7042s	
1175/22750 (epoch 2.582), train_loss = 1.82572890, grad/param norm = 2.7706e-01, time/batch = 0.7076s	
1176/22750 (epoch 2.585), train_loss = 1.70678928, grad/param norm = 2.3000e-01, time/batch = 0.7081s	
1177/22750 (epoch 2.587), train_loss = 1.86436341, grad/param norm = 2.5529e-01, time/batch = 0.7080s	
1178/22750 (epoch 2.589), train_loss = 1.87971974, grad/param norm = 2.5975e-01, time/batch = 0.7185s	
1179/22750 (epoch 2.591), train_loss = 2.04112343, grad/param norm = 2.7551e-01, time/batch = 0.7052s	
1180/22750 (epoch 2.593), train_loss = 2.15232382, grad/param norm = 2.5687e-01, time/batch = 0.7140s	
1181/22750 (epoch 2.596), train_loss = 2.06941316, grad/param norm = 2.1949e-01, time/batch = 0.7120s	
1182/22750 (epoch 2.598), train_loss = 2.17009576, grad/param norm = 2.5463e-01, time/batch = 0.7150s	
1183/22750 (epoch 2.600), train_loss = 1.95842824, grad/param norm = 2.4994e-01, time/batch = 0.7103s	
1184/22750 (epoch 2.602), train_loss = 1.75158623, grad/param norm = 2.4474e-01, time/batch = 0.7146s	
1185/22750 (epoch 2.604), train_loss = 1.95768201, grad/param norm = 2.7223e-01, time/batch = 0.7131s	
1186/22750 (epoch 2.607), train_loss = 1.58296321, grad/param norm = 2.1663e-01, time/batch = 0.7018s	
1187/22750 (epoch 2.609), train_loss = 1.67451226, grad/param norm = 2.2300e-01, time/batch = 0.7043s	
1188/22750 (epoch 2.611), train_loss = 1.91137364, grad/param norm = 2.5049e-01, time/batch = 0.7041s	
1189/22750 (epoch 2.613), train_loss = 1.81553510, grad/param norm = 2.7350e-01, time/batch = 0.7081s	
1190/22750 (epoch 2.615), train_loss = 1.93735157, grad/param norm = 2.7016e-01, time/batch = 0.7040s	
1191/22750 (epoch 2.618), train_loss = 1.93376507, grad/param norm = 2.9417e-01, time/batch = 0.7078s	
1192/22750 (epoch 2.620), train_loss = 1.95041796, grad/param norm = 2.6303e-01, time/batch = 0.7036s	
1193/22750 (epoch 2.622), train_loss = 1.83539130, grad/param norm = 3.4180e-01, time/batch = 0.7031s	
1194/22750 (epoch 2.624), train_loss = 2.17547404, grad/param norm = 2.9535e-01, time/batch = 0.7015s	
1195/22750 (epoch 2.626), train_loss = 2.01556455, grad/param norm = 3.4890e-01, time/batch = 0.7002s	
1196/22750 (epoch 2.629), train_loss = 2.05312135, grad/param norm = 3.5855e-01, time/batch = 0.7032s	
1197/22750 (epoch 2.631), train_loss = 2.09501569, grad/param norm = 2.8775e-01, time/batch = 0.7112s	
1198/22750 (epoch 2.633), train_loss = 1.76407449, grad/param norm = 2.5924e-01, time/batch = 0.7070s	
1199/22750 (epoch 2.635), train_loss = 2.14069431, grad/param norm = 2.4303e-01, time/batch = 0.7214s	
1200/22750 (epoch 2.637), train_loss = 2.09592204, grad/param norm = 2.7403e-01, time/batch = 0.7235s	
1201/22750 (epoch 2.640), train_loss = 2.22287778, grad/param norm = 2.6389e-01, time/batch = 0.7154s	
1202/22750 (epoch 2.642), train_loss = 2.12873667, grad/param norm = 2.5071e-01, time/batch = 0.7070s	
1203/22750 (epoch 2.644), train_loss = 1.97935561, grad/param norm = 2.4846e-01, time/batch = 0.7074s	
1204/22750 (epoch 2.646), train_loss = 2.01998715, grad/param norm = 2.8618e-01, time/batch = 0.7018s	
1205/22750 (epoch 2.648), train_loss = 2.00692170, grad/param norm = 2.5727e-01, time/batch = 0.7051s	
1206/22750 (epoch 2.651), train_loss = 2.17308558, grad/param norm = 2.5542e-01, time/batch = 0.7054s	
1207/22750 (epoch 2.653), train_loss = 1.97474539, grad/param norm = 2.7249e-01, time/batch = 0.7019s	
1208/22750 (epoch 2.655), train_loss = 2.00599763, grad/param norm = 3.0564e-01, time/batch = 0.7114s	
1209/22750 (epoch 2.657), train_loss = 2.19135031, grad/param norm = 2.4407e-01, time/batch = 0.7056s	
1210/22750 (epoch 2.659), train_loss = 2.17957850, grad/param norm = 2.3077e-01, time/batch = 0.7159s	
1211/22750 (epoch 2.662), train_loss = 2.31026941, grad/param norm = 2.4342e-01, time/batch = 0.7115s	
1212/22750 (epoch 2.664), train_loss = 2.06006366, grad/param norm = 2.8419e-01, time/batch = 0.7084s	
1213/22750 (epoch 2.666), train_loss = 1.95888855, grad/param norm = 3.1039e-01, time/batch = 0.7126s	
1214/22750 (epoch 2.668), train_loss = 1.99575428, grad/param norm = 2.4601e-01, time/batch = 0.7207s	
1215/22750 (epoch 2.670), train_loss = 2.04943548, grad/param norm = 2.5736e-01, time/batch = 0.7179s	
1216/22750 (epoch 2.673), train_loss = 2.10693303, grad/param norm = 2.7757e-01, time/batch = 0.7072s	
1217/22750 (epoch 2.675), train_loss = 2.45206322, grad/param norm = 3.8739e-01, time/batch = 0.7087s	
1218/22750 (epoch 2.677), train_loss = 2.19254101, grad/param norm = 3.4111e-01, time/batch = 0.7077s	
1219/22750 (epoch 2.679), train_loss = 2.28119593, grad/param norm = 2.5304e-01, time/batch = 0.7110s	
1220/22750 (epoch 2.681), train_loss = 2.10875299, grad/param norm = 2.6336e-01, time/batch = 0.7066s	
1221/22750 (epoch 2.684), train_loss = 2.15722202, grad/param norm = 2.5519e-01, time/batch = 0.7063s	
1222/22750 (epoch 2.686), train_loss = 2.08688734, grad/param norm = 2.7356e-01, time/batch = 0.7096s	
1223/22750 (epoch 2.688), train_loss = 2.12837731, grad/param norm = 2.6213e-01, time/batch = 0.7088s	
1224/22750 (epoch 2.690), train_loss = 2.04661274, grad/param norm = 2.4778e-01, time/batch = 0.7122s	
1225/22750 (epoch 2.692), train_loss = 2.16884810, grad/param norm = 2.3244e-01, time/batch = 0.7108s	
1226/22750 (epoch 2.695), train_loss = 1.99266967, grad/param norm = 2.3420e-01, time/batch = 0.7095s	
1227/22750 (epoch 2.697), train_loss = 1.89763726, grad/param norm = 2.5017e-01, time/batch = 0.7113s	
1228/22750 (epoch 2.699), train_loss = 2.08182114, grad/param norm = 2.5680e-01, time/batch = 0.7099s	
1229/22750 (epoch 2.701), train_loss = 1.97555973, grad/param norm = 2.2346e-01, time/batch = 0.7264s	
1230/22750 (epoch 2.703), train_loss = 2.03942195, grad/param norm = 2.4924e-01, time/batch = 0.7269s	
1231/22750 (epoch 2.705), train_loss = 1.83266162, grad/param norm = 2.8535e-01, time/batch = 0.7325s	
1232/22750 (epoch 2.708), train_loss = 2.06789145, grad/param norm = 2.0789e-01, time/batch = 0.7158s	
1233/22750 (epoch 2.710), train_loss = 1.76850888, grad/param norm = 2.4606e-01, time/batch = 0.7079s	
1234/22750 (epoch 2.712), train_loss = 1.88521366, grad/param norm = 2.2939e-01, time/batch = 0.7098s	
1235/22750 (epoch 2.714), train_loss = 1.81203913, grad/param norm = 2.5880e-01, time/batch = 0.7074s	
1236/22750 (epoch 2.716), train_loss = 1.95730687, grad/param norm = 2.6561e-01, time/batch = 0.7077s	
1237/22750 (epoch 2.719), train_loss = 2.12930700, grad/param norm = 3.1443e-01, time/batch = 0.7080s	
1238/22750 (epoch 2.721), train_loss = 2.05063483, grad/param norm = 2.9126e-01, time/batch = 0.7145s	
1239/22750 (epoch 2.723), train_loss = 1.97067321, grad/param norm = 2.5058e-01, time/batch = 0.7113s	
1240/22750 (epoch 2.725), train_loss = 1.95254826, grad/param norm = 2.4267e-01, time/batch = 0.7116s	
1241/22750 (epoch 2.727), train_loss = 1.87647298, grad/param norm = 2.3063e-01, time/batch = 0.7280s	
1242/22750 (epoch 2.730), train_loss = 1.85234292, grad/param norm = 2.1994e-01, time/batch = 0.7320s	
1243/22750 (epoch 2.732), train_loss = 2.02294123, grad/param norm = 2.4642e-01, time/batch = 0.7335s	
1244/22750 (epoch 2.734), train_loss = 1.61821647, grad/param norm = 3.3003e-01, time/batch = 0.7326s	
1245/22750 (epoch 2.736), train_loss = 1.93153036, grad/param norm = 2.9569e-01, time/batch = 0.7151s	
1246/22750 (epoch 2.738), train_loss = 1.84946003, grad/param norm = 2.7761e-01, time/batch = 0.7147s	
1247/22750 (epoch 2.741), train_loss = 2.06771137, grad/param norm = 2.3047e-01, time/batch = 0.7170s	
1248/22750 (epoch 2.743), train_loss = 2.09283867, grad/param norm = 2.4335e-01, time/batch = 0.7308s	
1249/22750 (epoch 2.745), train_loss = 1.81192299, grad/param norm = 2.5256e-01, time/batch = 0.7144s	
1250/22750 (epoch 2.747), train_loss = 1.87865103, grad/param norm = 2.5347e-01, time/batch = 0.7109s	
1251/22750 (epoch 2.749), train_loss = 2.11114332, grad/param norm = 2.9089e-01, time/batch = 0.7079s	
1252/22750 (epoch 2.752), train_loss = 1.86834240, grad/param norm = 2.2550e-01, time/batch = 0.7205s	
1253/22750 (epoch 2.754), train_loss = 2.05520759, grad/param norm = 3.1985e-01, time/batch = 0.7230s	
1254/22750 (epoch 2.756), train_loss = 1.81076641, grad/param norm = 3.7953e-01, time/batch = 0.7535s	
1255/22750 (epoch 2.758), train_loss = 1.75616395, grad/param norm = 2.6537e-01, time/batch = 0.7345s	
1256/22750 (epoch 2.760), train_loss = 2.07647333, grad/param norm = 2.4803e-01, time/batch = 0.7403s	
1257/22750 (epoch 2.763), train_loss = 1.95897922, grad/param norm = 2.3989e-01, time/batch = 0.7294s	
1258/22750 (epoch 2.765), train_loss = 1.85190234, grad/param norm = 2.4038e-01, time/batch = 0.7244s	
1259/22750 (epoch 2.767), train_loss = 1.85928768, grad/param norm = 2.2039e-01, time/batch = 0.7220s	
1260/22750 (epoch 2.769), train_loss = 2.06470834, grad/param norm = 2.5843e-01, time/batch = 0.7168s	
1261/22750 (epoch 2.771), train_loss = 2.01120822, grad/param norm = 2.6278e-01, time/batch = 0.7153s	
1262/22750 (epoch 2.774), train_loss = 1.91158813, grad/param norm = 2.5006e-01, time/batch = 0.7134s	
1263/22750 (epoch 2.776), train_loss = 1.95247160, grad/param norm = 2.8779e-01, time/batch = 0.7128s	
1264/22750 (epoch 2.778), train_loss = 2.16284143, grad/param norm = 2.6106e-01, time/batch = 0.7127s	
1265/22750 (epoch 2.780), train_loss = 2.02494828, grad/param norm = 2.6790e-01, time/batch = 0.7150s	
1266/22750 (epoch 2.782), train_loss = 2.08097273, grad/param norm = 2.5287e-01, time/batch = 0.7188s	
1267/22750 (epoch 2.785), train_loss = 2.04006943, grad/param norm = 2.3902e-01, time/batch = 0.7196s	
1268/22750 (epoch 2.787), train_loss = 1.88571341, grad/param norm = 2.3961e-01, time/batch = 0.7146s	
1269/22750 (epoch 2.789), train_loss = 1.81244464, grad/param norm = 2.1818e-01, time/batch = 0.7131s	
1270/22750 (epoch 2.791), train_loss = 1.92612171, grad/param norm = 2.0930e-01, time/batch = 0.7114s	
1271/22750 (epoch 2.793), train_loss = 1.93766563, grad/param norm = 2.4266e-01, time/batch = 0.7158s	
1272/22750 (epoch 2.796), train_loss = 1.85216021, grad/param norm = 2.3621e-01, time/batch = 0.7134s	
1273/22750 (epoch 2.798), train_loss = 1.91436039, grad/param norm = 2.2700e-01, time/batch = 0.7174s	
1274/22750 (epoch 2.800), train_loss = 1.90932000, grad/param norm = 2.4211e-01, time/batch = 0.7168s	
1275/22750 (epoch 2.802), train_loss = 2.03619979, grad/param norm = 2.5571e-01, time/batch = 0.7102s	
1276/22750 (epoch 2.804), train_loss = 2.20085967, grad/param norm = 2.3123e-01, time/batch = 0.7125s	
1277/22750 (epoch 2.807), train_loss = 1.96877326, grad/param norm = 2.3379e-01, time/batch = 0.7076s	
1278/22750 (epoch 2.809), train_loss = 2.19495731, grad/param norm = 2.5011e-01, time/batch = 0.7133s	
1279/22750 (epoch 2.811), train_loss = 1.92836465, grad/param norm = 2.4065e-01, time/batch = 0.7125s	
1280/22750 (epoch 2.813), train_loss = 2.09868731, grad/param norm = 2.1444e-01, time/batch = 0.7143s	
1281/22750 (epoch 2.815), train_loss = 2.14749956, grad/param norm = 2.7613e-01, time/batch = 0.7137s	
1282/22750 (epoch 2.818), train_loss = 2.16540893, grad/param norm = 2.7914e-01, time/batch = 0.7134s	
1283/22750 (epoch 2.820), train_loss = 2.19969000, grad/param norm = 2.3737e-01, time/batch = 0.7085s	
1284/22750 (epoch 2.822), train_loss = 2.05124035, grad/param norm = 2.2932e-01, time/batch = 0.7109s	
1285/22750 (epoch 2.824), train_loss = 2.05547440, grad/param norm = 2.3955e-01, time/batch = 0.7115s	
1286/22750 (epoch 2.826), train_loss = 1.96537074, grad/param norm = 2.3882e-01, time/batch = 0.7115s	
1287/22750 (epoch 2.829), train_loss = 2.13502592, grad/param norm = 2.4409e-01, time/batch = 0.7115s	
1288/22750 (epoch 2.831), train_loss = 2.09956655, grad/param norm = 2.5452e-01, time/batch = 0.7055s	
1289/22750 (epoch 2.833), train_loss = 2.20292954, grad/param norm = 2.5328e-01, time/batch = 0.7060s	
1290/22750 (epoch 2.835), train_loss = 2.01584730, grad/param norm = 2.4045e-01, time/batch = 0.7117s	
1291/22750 (epoch 2.837), train_loss = 2.01710822, grad/param norm = 2.4967e-01, time/batch = 0.7094s	
1292/22750 (epoch 2.840), train_loss = 2.02474067, grad/param norm = 2.8422e-01, time/batch = 0.7151s	
1293/22750 (epoch 2.842), train_loss = 1.97823111, grad/param norm = 2.6196e-01, time/batch = 0.7175s	
1294/22750 (epoch 2.844), train_loss = 2.19142089, grad/param norm = 2.7733e-01, time/batch = 0.7155s	
1295/22750 (epoch 2.846), train_loss = 1.88226099, grad/param norm = 2.1525e-01, time/batch = 0.7139s	
1296/22750 (epoch 2.848), train_loss = 1.82876320, grad/param norm = 2.8710e-01, time/batch = 0.7108s	
1297/22750 (epoch 2.851), train_loss = 1.91975162, grad/param norm = 3.0929e-01, time/batch = 0.7137s	
1298/22750 (epoch 2.853), train_loss = 1.91545358, grad/param norm = 2.5138e-01, time/batch = 0.7128s	
1299/22750 (epoch 2.855), train_loss = 1.76836281, grad/param norm = 2.2226e-01, time/batch = 0.7179s	
1300/22750 (epoch 2.857), train_loss = 1.98261727, grad/param norm = 2.1720e-01, time/batch = 0.7167s	
1301/22750 (epoch 2.859), train_loss = 1.99964562, grad/param norm = 2.4358e-01, time/batch = 0.7162s	
1302/22750 (epoch 2.862), train_loss = 2.10325625, grad/param norm = 2.4720e-01, time/batch = 0.7122s	
1303/22750 (epoch 2.864), train_loss = 2.00729724, grad/param norm = 2.3641e-01, time/batch = 0.7107s	
1304/22750 (epoch 2.866), train_loss = 1.95953795, grad/param norm = 2.2982e-01, time/batch = 0.7066s	
1305/22750 (epoch 2.868), train_loss = 2.00096506, grad/param norm = 2.5098e-01, time/batch = 0.7132s	
1306/22750 (epoch 2.870), train_loss = 1.74359073, grad/param norm = 2.3307e-01, time/batch = 0.7164s	
1307/22750 (epoch 2.873), train_loss = 1.92213422, grad/param norm = 2.2942e-01, time/batch = 0.7077s	
1308/22750 (epoch 2.875), train_loss = 1.99046454, grad/param norm = 2.3273e-01, time/batch = 0.7092s	
1309/22750 (epoch 2.877), train_loss = 1.79843177, grad/param norm = 2.1106e-01, time/batch = 0.7117s	
1310/22750 (epoch 2.879), train_loss = 2.11328254, grad/param norm = 2.8763e-01, time/batch = 0.7044s	
1311/22750 (epoch 2.881), train_loss = 2.04530373, grad/param norm = 3.2172e-01, time/batch = 0.7081s	
1312/22750 (epoch 2.884), train_loss = 2.00710787, grad/param norm = 2.9531e-01, time/batch = 0.7034s	
1313/22750 (epoch 2.886), train_loss = 2.06603608, grad/param norm = 2.6292e-01, time/batch = 0.7075s	
1314/22750 (epoch 2.888), train_loss = 2.01057053, grad/param norm = 2.5739e-01, time/batch = 0.7062s	
1315/22750 (epoch 2.890), train_loss = 1.99550293, grad/param norm = 2.8694e-01, time/batch = 0.7059s	
1316/22750 (epoch 2.892), train_loss = 2.39945852, grad/param norm = 3.1675e-01, time/batch = 0.7072s	
1317/22750 (epoch 2.895), train_loss = 2.12295799, grad/param norm = 2.6248e-01, time/batch = 0.7075s	
1318/22750 (epoch 2.897), train_loss = 2.06669256, grad/param norm = 2.4870e-01, time/batch = 0.7059s	
1319/22750 (epoch 2.899), train_loss = 2.05977623, grad/param norm = 2.3860e-01, time/batch = 0.7092s	
1320/22750 (epoch 2.901), train_loss = 2.13369944, grad/param norm = 2.2464e-01, time/batch = 0.7035s	
1321/22750 (epoch 2.903), train_loss = 1.99568081, grad/param norm = 2.3924e-01, time/batch = 0.7085s	
1322/22750 (epoch 2.905), train_loss = 1.95530532, grad/param norm = 2.0348e-01, time/batch = 0.7119s	
1323/22750 (epoch 2.908), train_loss = 1.97750813, grad/param norm = 2.7557e-01, time/batch = 0.7128s	
1324/22750 (epoch 2.910), train_loss = 1.80986185, grad/param norm = 2.6314e-01, time/batch = 0.7080s	
1325/22750 (epoch 2.912), train_loss = 1.81042438, grad/param norm = 2.5362e-01, time/batch = 0.7126s	
1326/22750 (epoch 2.914), train_loss = 1.84409094, grad/param norm = 2.4801e-01, time/batch = 0.7116s	
1327/22750 (epoch 2.916), train_loss = 1.73803693, grad/param norm = 2.2415e-01, time/batch = 0.7183s	
1328/22750 (epoch 2.919), train_loss = 1.82737850, grad/param norm = 2.3114e-01, time/batch = 0.7122s	
1329/22750 (epoch 2.921), train_loss = 1.58424203, grad/param norm = 2.2936e-01, time/batch = 0.7062s	
1330/22750 (epoch 2.923), train_loss = 1.91127301, grad/param norm = 2.3554e-01, time/batch = 0.7139s	
1331/22750 (epoch 2.925), train_loss = 1.91131835, grad/param norm = 2.2866e-01, time/batch = 0.7262s	
1332/22750 (epoch 2.927), train_loss = 1.68699228, grad/param norm = 2.5143e-01, time/batch = 0.7258s	
1333/22750 (epoch 2.930), train_loss = 1.79940144, grad/param norm = 2.9623e-01, time/batch = 0.7241s	
1334/22750 (epoch 2.932), train_loss = 2.19605315, grad/param norm = 2.7926e-01, time/batch = 0.7236s	
1335/22750 (epoch 2.934), train_loss = 1.61359712, grad/param norm = 2.3606e-01, time/batch = 0.7214s	
1336/22750 (epoch 2.936), train_loss = 2.07670372, grad/param norm = 2.8858e-01, time/batch = 0.7215s	
1337/22750 (epoch 2.938), train_loss = 1.95941870, grad/param norm = 2.6457e-01, time/batch = 0.7292s	
1338/22750 (epoch 2.941), train_loss = 2.32319269, grad/param norm = 2.9166e-01, time/batch = 0.7456s	
1339/22750 (epoch 2.943), train_loss = 2.05383600, grad/param norm = 2.7308e-01, time/batch = 0.7072s	
1340/22750 (epoch 2.945), train_loss = 1.98036831, grad/param norm = 2.4446e-01, time/batch = 0.7108s	
1341/22750 (epoch 2.947), train_loss = 2.02681229, grad/param norm = 2.7113e-01, time/batch = 0.7127s	
1342/22750 (epoch 2.949), train_loss = 1.81809908, grad/param norm = 2.6303e-01, time/batch = 0.7187s	
1343/22750 (epoch 2.952), train_loss = 1.86086774, grad/param norm = 2.2235e-01, time/batch = 0.7154s	
1344/22750 (epoch 2.954), train_loss = 1.85718601, grad/param norm = 2.4116e-01, time/batch = 0.7118s	
1345/22750 (epoch 2.956), train_loss = 1.95752863, grad/param norm = 2.3716e-01, time/batch = 0.7140s	
1346/22750 (epoch 2.958), train_loss = 1.92372301, grad/param norm = 2.3761e-01, time/batch = 0.7126s	
1347/22750 (epoch 2.960), train_loss = 1.95740391, grad/param norm = 2.4151e-01, time/batch = 0.7255s	
1348/22750 (epoch 2.963), train_loss = 2.01574939, grad/param norm = 2.4203e-01, time/batch = 0.7076s	
1349/22750 (epoch 2.965), train_loss = 1.99467557, grad/param norm = 2.3282e-01, time/batch = 0.7102s	
1350/22750 (epoch 2.967), train_loss = 2.01490957, grad/param norm = 2.5219e-01, time/batch = 0.7111s	
1351/22750 (epoch 2.969), train_loss = 1.94072849, grad/param norm = 2.2707e-01, time/batch = 0.7179s	
1352/22750 (epoch 2.971), train_loss = 1.90643271, grad/param norm = 2.1265e-01, time/batch = 0.7155s	
1353/22750 (epoch 2.974), train_loss = 1.96526454, grad/param norm = 2.6146e-01, time/batch = 0.7080s	
1354/22750 (epoch 2.976), train_loss = 2.05789970, grad/param norm = 2.3749e-01, time/batch = 0.7087s	
1355/22750 (epoch 2.978), train_loss = 1.87454312, grad/param norm = 2.6988e-01, time/batch = 0.7094s	
1356/22750 (epoch 2.980), train_loss = 2.02198301, grad/param norm = 2.5985e-01, time/batch = 0.7236s	
1357/22750 (epoch 2.982), train_loss = 1.88566659, grad/param norm = 2.3960e-01, time/batch = 0.7268s	
1358/22750 (epoch 2.985), train_loss = 2.16804425, grad/param norm = 2.7097e-01, time/batch = 0.7111s	
1359/22750 (epoch 2.987), train_loss = 1.77491657, grad/param norm = 2.6628e-01, time/batch = 0.7121s	
1360/22750 (epoch 2.989), train_loss = 1.83169177, grad/param norm = 2.0800e-01, time/batch = 0.7056s	
1361/22750 (epoch 2.991), train_loss = 2.03016915, grad/param norm = 2.3040e-01, time/batch = 0.7083s	
1362/22750 (epoch 2.993), train_loss = 1.98704070, grad/param norm = 2.5204e-01, time/batch = 0.7096s	
1363/22750 (epoch 2.996), train_loss = 1.91101840, grad/param norm = 2.5600e-01, time/batch = 0.7340s	
1364/22750 (epoch 2.998), train_loss = 2.10125385, grad/param norm = 2.2511e-01, time/batch = 0.7241s	
1365/22750 (epoch 3.000), train_loss = 2.07166339, grad/param norm = 2.4527e-01, time/batch = 0.7163s	
1366/22750 (epoch 3.002), train_loss = 2.11099312, grad/param norm = 2.5851e-01, time/batch = 0.7090s	
1367/22750 (epoch 3.004), train_loss = 2.01083816, grad/param norm = 3.2674e-01, time/batch = 0.7099s	
1368/22750 (epoch 3.007), train_loss = 2.08391663, grad/param norm = 3.2219e-01, time/batch = 0.7080s	
1369/22750 (epoch 3.009), train_loss = 2.20604016, grad/param norm = 2.6909e-01, time/batch = 0.7151s	
1370/22750 (epoch 3.011), train_loss = 2.13255362, grad/param norm = 2.7216e-01, time/batch = 0.7087s	
1371/22750 (epoch 3.013), train_loss = 2.05221218, grad/param norm = 2.5765e-01, time/batch = 0.7154s	
1372/22750 (epoch 3.015), train_loss = 2.04379728, grad/param norm = 2.3607e-01, time/batch = 0.7054s	
1373/22750 (epoch 3.018), train_loss = 1.98330703, grad/param norm = 2.3837e-01, time/batch = 0.7138s	
1374/22750 (epoch 3.020), train_loss = 2.04843213, grad/param norm = 2.3537e-01, time/batch = 0.7117s	
1375/22750 (epoch 3.022), train_loss = 1.94402214, grad/param norm = 2.1849e-01, time/batch = 0.7105s	
1376/22750 (epoch 3.024), train_loss = 1.93152157, grad/param norm = 2.4688e-01, time/batch = 0.7100s	
1377/22750 (epoch 3.026), train_loss = 2.14796514, grad/param norm = 2.8855e-01, time/batch = 0.7126s	
1378/22750 (epoch 3.029), train_loss = 1.75853363, grad/param norm = 2.3951e-01, time/batch = 0.7106s	
1379/22750 (epoch 3.031), train_loss = 2.20887175, grad/param norm = 2.3528e-01, time/batch = 0.7116s	
1380/22750 (epoch 3.033), train_loss = 1.98447669, grad/param norm = 2.2217e-01, time/batch = 0.7109s	
1381/22750 (epoch 3.035), train_loss = 2.06120064, grad/param norm = 2.4091e-01, time/batch = 0.7104s	
1382/22750 (epoch 3.037), train_loss = 2.15375959, grad/param norm = 2.6649e-01, time/batch = 0.7124s	
1383/22750 (epoch 3.040), train_loss = 1.89021354, grad/param norm = 2.5778e-01, time/batch = 0.7103s	
1384/22750 (epoch 3.042), train_loss = 2.06005337, grad/param norm = 2.3862e-01, time/batch = 0.7148s	
1385/22750 (epoch 3.044), train_loss = 1.86756956, grad/param norm = 2.5715e-01, time/batch = 0.7174s	
1386/22750 (epoch 3.046), train_loss = 1.98151372, grad/param norm = 2.8726e-01, time/batch = 0.7290s	
1387/22750 (epoch 3.048), train_loss = 1.96844784, grad/param norm = 2.8809e-01, time/batch = 0.7145s	
1388/22750 (epoch 3.051), train_loss = 2.06576841, grad/param norm = 2.5790e-01, time/batch = 0.7081s	
1389/22750 (epoch 3.053), train_loss = 1.77949177, grad/param norm = 2.4597e-01, time/batch = 0.7071s	
1390/22750 (epoch 3.055), train_loss = 2.05264971, grad/param norm = 2.5701e-01, time/batch = 0.7089s	
1391/22750 (epoch 3.057), train_loss = 2.02654086, grad/param norm = 2.7688e-01, time/batch = 0.7130s	
1392/22750 (epoch 3.059), train_loss = 1.69678958, grad/param norm = 2.7966e-01, time/batch = 0.7078s	
1393/22750 (epoch 3.062), train_loss = 1.79346562, grad/param norm = 2.5195e-01, time/batch = 0.7006s	
1394/22750 (epoch 3.064), train_loss = 2.01078100, grad/param norm = 2.5226e-01, time/batch = 0.7020s	
1395/22750 (epoch 3.066), train_loss = 1.75309890, grad/param norm = 2.1540e-01, time/batch = 0.7049s	
1396/22750 (epoch 3.068), train_loss = 1.77711472, grad/param norm = 2.3249e-01, time/batch = 0.7101s	
1397/22750 (epoch 3.070), train_loss = 1.67002033, grad/param norm = 2.2850e-01, time/batch = 0.7048s	
1398/22750 (epoch 3.073), train_loss = 1.87969800, grad/param norm = 2.8082e-01, time/batch = 0.7083s	
1399/22750 (epoch 3.075), train_loss = 1.97145344, grad/param norm = 2.2577e-01, time/batch = 0.7057s	
1400/22750 (epoch 3.077), train_loss = 1.59610168, grad/param norm = 2.2406e-01, time/batch = 0.7035s	
1401/22750 (epoch 3.079), train_loss = 1.89191650, grad/param norm = 2.3568e-01, time/batch = 0.7077s	
1402/22750 (epoch 3.081), train_loss = 1.93298795, grad/param norm = 2.5864e-01, time/batch = 0.6993s	
1403/22750 (epoch 3.084), train_loss = 1.84145471, grad/param norm = 2.4296e-01, time/batch = 0.7043s	
1404/22750 (epoch 3.086), train_loss = 1.84984684, grad/param norm = 2.4704e-01, time/batch = 0.7052s	
1405/22750 (epoch 3.088), train_loss = 1.90272886, grad/param norm = 2.3936e-01, time/batch = 0.7109s	
1406/22750 (epoch 3.090), train_loss = 1.89341320, grad/param norm = 2.4021e-01, time/batch = 0.7095s	
1407/22750 (epoch 3.092), train_loss = 2.04821875, grad/param norm = 2.3403e-01, time/batch = 0.7151s	
1408/22750 (epoch 3.095), train_loss = 1.80003768, grad/param norm = 2.4712e-01, time/batch = 0.7058s	
1409/22750 (epoch 3.097), train_loss = 1.85674983, grad/param norm = 2.2927e-01, time/batch = 0.7167s	
1410/22750 (epoch 3.099), train_loss = 2.02681096, grad/param norm = 2.8365e-01, time/batch = 0.7234s	
1411/22750 (epoch 3.101), train_loss = 1.97020918, grad/param norm = 2.5562e-01, time/batch = 0.7201s	
1412/22750 (epoch 3.103), train_loss = 1.81882939, grad/param norm = 2.2922e-01, time/batch = 0.7033s	
1413/22750 (epoch 3.105), train_loss = 2.17408101, grad/param norm = 2.5770e-01, time/batch = 0.7019s	
1414/22750 (epoch 3.108), train_loss = 1.85322139, grad/param norm = 2.2716e-01, time/batch = 0.7017s	
1415/22750 (epoch 3.110), train_loss = 1.90385010, grad/param norm = 2.5068e-01, time/batch = 0.7183s	
1416/22750 (epoch 3.112), train_loss = 1.63424856, grad/param norm = 2.1678e-01, time/batch = 0.7232s	
1417/22750 (epoch 3.114), train_loss = 1.64714332, grad/param norm = 2.2826e-01, time/batch = 0.7066s	
1418/22750 (epoch 3.116), train_loss = 1.75377555, grad/param norm = 3.1384e-01, time/batch = 0.7075s	
1419/22750 (epoch 3.119), train_loss = 1.84794781, grad/param norm = 2.4053e-01, time/batch = 0.7148s	
1420/22750 (epoch 3.121), train_loss = 2.04356873, grad/param norm = 2.4341e-01, time/batch = 0.7224s	
1421/22750 (epoch 3.123), train_loss = 1.85150121, grad/param norm = 2.1173e-01, time/batch = 0.7246s	
1422/22750 (epoch 3.125), train_loss = 2.08175516, grad/param norm = 2.3444e-01, time/batch = 0.7228s	
1423/22750 (epoch 3.127), train_loss = 2.01712782, grad/param norm = 2.4730e-01, time/batch = 0.7104s	
1424/22750 (epoch 3.130), train_loss = 1.96964317, grad/param norm = 2.2803e-01, time/batch = 0.7111s	
1425/22750 (epoch 3.132), train_loss = 2.01094690, grad/param norm = 2.4199e-01, time/batch = 0.7283s	
1426/22750 (epoch 3.134), train_loss = 1.92175488, grad/param norm = 2.4736e-01, time/batch = 0.7241s	
1427/22750 (epoch 3.136), train_loss = 1.82039495, grad/param norm = 2.1981e-01, time/batch = 0.7103s	
1428/22750 (epoch 3.138), train_loss = 1.87166172, grad/param norm = 2.7511e-01, time/batch = 0.7115s	
1429/22750 (epoch 3.141), train_loss = 1.80128585, grad/param norm = 2.6403e-01, time/batch = 0.7112s	
1430/22750 (epoch 3.143), train_loss = 1.78020272, grad/param norm = 2.2932e-01, time/batch = 0.7128s	
1431/22750 (epoch 3.145), train_loss = 1.96059248, grad/param norm = 2.6792e-01, time/batch = 0.7133s	
1432/22750 (epoch 3.147), train_loss = 1.97648317, grad/param norm = 2.3450e-01, time/batch = 0.7096s	
1433/22750 (epoch 3.149), train_loss = 1.93938385, grad/param norm = 2.4558e-01, time/batch = 0.7117s	
1434/22750 (epoch 3.152), train_loss = 1.90599313, grad/param norm = 2.7014e-01, time/batch = 0.7118s	
1435/22750 (epoch 3.154), train_loss = 1.71987705, grad/param norm = 2.3554e-01, time/batch = 0.7318s	
1436/22750 (epoch 3.156), train_loss = 1.88339762, grad/param norm = 2.6192e-01, time/batch = 0.7199s	
1437/22750 (epoch 3.158), train_loss = 1.87791255, grad/param norm = 2.6978e-01, time/batch = 0.7100s	
1438/22750 (epoch 3.160), train_loss = 1.97418699, grad/param norm = 2.5280e-01, time/batch = 0.7023s	
1439/22750 (epoch 3.163), train_loss = 2.10263889, grad/param norm = 2.4229e-01, time/batch = 0.7163s	
1440/22750 (epoch 3.165), train_loss = 2.05532999, grad/param norm = 2.3626e-01, time/batch = 0.7171s	
1441/22750 (epoch 3.167), train_loss = 1.79963886, grad/param norm = 2.1917e-01, time/batch = 0.7069s	
1442/22750 (epoch 3.169), train_loss = 1.91731520, grad/param norm = 2.2350e-01, time/batch = 0.7020s	
1443/22750 (epoch 3.171), train_loss = 1.83054625, grad/param norm = 2.4165e-01, time/batch = 0.7046s	
1444/22750 (epoch 3.174), train_loss = 1.65802689, grad/param norm = 2.3267e-01, time/batch = 0.7108s	
1445/22750 (epoch 3.176), train_loss = 1.92343574, grad/param norm = 2.4461e-01, time/batch = 0.7280s	
1446/22750 (epoch 3.178), train_loss = 1.82901475, grad/param norm = 2.2221e-01, time/batch = 0.7065s	
1447/22750 (epoch 3.180), train_loss = 2.02270434, grad/param norm = 2.8569e-01, time/batch = 0.7063s	
1448/22750 (epoch 3.182), train_loss = 1.91843725, grad/param norm = 2.3418e-01, time/batch = 0.7149s	
1449/22750 (epoch 3.185), train_loss = 1.92082434, grad/param norm = 2.2698e-01, time/batch = 0.7310s	
1450/22750 (epoch 3.187), train_loss = 1.75844144, grad/param norm = 2.6295e-01, time/batch = 0.7206s	
1451/22750 (epoch 3.189), train_loss = 1.81377893, grad/param norm = 2.5917e-01, time/batch = 0.7245s	
1452/22750 (epoch 3.191), train_loss = 1.75328544, grad/param norm = 2.4242e-01, time/batch = 0.7238s	
1453/22750 (epoch 3.193), train_loss = 1.93250823, grad/param norm = 2.5699e-01, time/batch = 0.7228s	
1454/22750 (epoch 3.196), train_loss = 1.93798014, grad/param norm = 2.4709e-01, time/batch = 0.7246s	
1455/22750 (epoch 3.198), train_loss = 1.68116158, grad/param norm = 2.0815e-01, time/batch = 0.7179s	
1456/22750 (epoch 3.200), train_loss = 1.97221107, grad/param norm = 2.1370e-01, time/batch = 0.7081s	
1457/22750 (epoch 3.202), train_loss = 2.19831225, grad/param norm = 2.5364e-01, time/batch = 0.7129s	
1458/22750 (epoch 3.204), train_loss = 2.13095582, grad/param norm = 2.4445e-01, time/batch = 0.7038s	
1459/22750 (epoch 3.207), train_loss = 1.85493332, grad/param norm = 2.3876e-01, time/batch = 0.7032s	
1460/22750 (epoch 3.209), train_loss = 1.84665498, grad/param norm = 2.1150e-01, time/batch = 0.7037s	
1461/22750 (epoch 3.211), train_loss = 1.88096431, grad/param norm = 2.1183e-01, time/batch = 0.7101s	
1462/22750 (epoch 3.213), train_loss = 1.75392760, grad/param norm = 2.2562e-01, time/batch = 0.7087s	
1463/22750 (epoch 3.215), train_loss = 1.84674779, grad/param norm = 2.1468e-01, time/batch = 0.7082s	
1464/22750 (epoch 3.218), train_loss = 1.69729206, grad/param norm = 2.6384e-01, time/batch = 0.7074s	
1465/22750 (epoch 3.220), train_loss = 1.96606219, grad/param norm = 2.8063e-01, time/batch = 0.7050s	
1466/22750 (epoch 3.222), train_loss = 1.73244285, grad/param norm = 2.6016e-01, time/batch = 0.7091s	
1467/22750 (epoch 3.224), train_loss = 1.84365085, grad/param norm = 2.4507e-01, time/batch = 0.7045s	
1468/22750 (epoch 3.226), train_loss = 1.91364659, grad/param norm = 2.4155e-01, time/batch = 0.7104s	
1469/22750 (epoch 3.229), train_loss = 2.02101206, grad/param norm = 2.3224e-01, time/batch = 0.7071s	
1470/22750 (epoch 3.231), train_loss = 1.87957778, grad/param norm = 2.2071e-01, time/batch = 0.7027s	
1471/22750 (epoch 3.233), train_loss = 1.86561694, grad/param norm = 2.2746e-01, time/batch = 0.7057s	
1472/22750 (epoch 3.235), train_loss = 1.76431792, grad/param norm = 2.4230e-01, time/batch = 0.7054s	
1473/22750 (epoch 3.237), train_loss = 1.87420496, grad/param norm = 2.2928e-01, time/batch = 0.7069s	
1474/22750 (epoch 3.240), train_loss = 2.04816667, grad/param norm = 2.3632e-01, time/batch = 0.7085s	
1475/22750 (epoch 3.242), train_loss = 2.29662931, grad/param norm = 2.3728e-01, time/batch = 0.7092s	
1476/22750 (epoch 3.244), train_loss = 2.09598990, grad/param norm = 2.9982e-01, time/batch = 0.7045s	
1477/22750 (epoch 3.246), train_loss = 2.21336861, grad/param norm = 2.4262e-01, time/batch = 0.7058s	
1478/22750 (epoch 3.248), train_loss = 1.83931806, grad/param norm = 2.4958e-01, time/batch = 0.7039s	
1479/22750 (epoch 3.251), train_loss = 2.12449288, grad/param norm = 2.4383e-01, time/batch = 0.7039s	
1480/22750 (epoch 3.253), train_loss = 1.97214162, grad/param norm = 2.2572e-01, time/batch = 0.7046s	
1481/22750 (epoch 3.255), train_loss = 2.03331573, grad/param norm = 2.4092e-01, time/batch = 0.7056s	
1482/22750 (epoch 3.257), train_loss = 1.88560742, grad/param norm = 2.6205e-01, time/batch = 0.7038s	
1483/22750 (epoch 3.259), train_loss = 2.01512843, grad/param norm = 2.6785e-01, time/batch = 0.7037s	
1484/22750 (epoch 3.262), train_loss = 1.92670802, grad/param norm = 2.4648e-01, time/batch = 0.7006s	
1485/22750 (epoch 3.264), train_loss = 1.91476407, grad/param norm = 2.1072e-01, time/batch = 0.7035s	
1486/22750 (epoch 3.266), train_loss = 1.80499848, grad/param norm = 2.4379e-01, time/batch = 0.7049s	
1487/22750 (epoch 3.268), train_loss = 1.97500098, grad/param norm = 2.2588e-01, time/batch = 0.7060s	
1488/22750 (epoch 3.270), train_loss = 1.78647559, grad/param norm = 2.8197e-01, time/batch = 0.7084s	
1489/22750 (epoch 3.273), train_loss = 2.10008028, grad/param norm = 2.7964e-01, time/batch = 0.7083s	
1490/22750 (epoch 3.275), train_loss = 1.89215030, grad/param norm = 2.3425e-01, time/batch = 0.7088s	
1491/22750 (epoch 3.277), train_loss = 1.97631990, grad/param norm = 2.5110e-01, time/batch = 0.7088s	
1492/22750 (epoch 3.279), train_loss = 1.69691983, grad/param norm = 2.0677e-01, time/batch = 0.7026s	
1493/22750 (epoch 3.281), train_loss = 1.85269927, grad/param norm = 2.2007e-01, time/batch = 0.7057s	
1494/22750 (epoch 3.284), train_loss = 1.77842261, grad/param norm = 2.0433e-01, time/batch = 0.7059s	
1495/22750 (epoch 3.286), train_loss = 1.90609225, grad/param norm = 2.2463e-01, time/batch = 0.7190s	
1496/22750 (epoch 3.288), train_loss = 2.04305292, grad/param norm = 2.1621e-01, time/batch = 0.7117s	
1497/22750 (epoch 3.290), train_loss = 1.78878635, grad/param norm = 2.3799e-01, time/batch = 0.7105s	
1498/22750 (epoch 3.292), train_loss = 1.85697164, grad/param norm = 2.3539e-01, time/batch = 0.7058s	
1499/22750 (epoch 3.295), train_loss = 1.92538895, grad/param norm = 2.4674e-01, time/batch = 0.7094s	
1500/22750 (epoch 3.297), train_loss = 1.79746207, grad/param norm = 2.3318e-01, time/batch = 0.7087s	
1501/22750 (epoch 3.299), train_loss = 2.05251023, grad/param norm = 2.6565e-01, time/batch = 0.7104s	
1502/22750 (epoch 3.301), train_loss = 1.96113722, grad/param norm = 2.3197e-01, time/batch = 0.7095s	
1503/22750 (epoch 3.303), train_loss = 2.03551774, grad/param norm = 2.4491e-01, time/batch = 0.7087s	
1504/22750 (epoch 3.305), train_loss = 2.05278329, grad/param norm = 2.6255e-01, time/batch = 0.7256s	
1505/22750 (epoch 3.308), train_loss = 1.91457237, grad/param norm = 2.2436e-01, time/batch = 0.7283s	
1506/22750 (epoch 3.310), train_loss = 1.84968237, grad/param norm = 2.3503e-01, time/batch = 0.7387s	
1507/22750 (epoch 3.312), train_loss = 1.88138486, grad/param norm = 2.3039e-01, time/batch = 0.7178s	
1508/22750 (epoch 3.314), train_loss = 1.89411511, grad/param norm = 2.2806e-01, time/batch = 0.7139s	
1509/22750 (epoch 3.316), train_loss = 1.86353384, grad/param norm = 2.4658e-01, time/batch = 0.7094s	
1510/22750 (epoch 3.319), train_loss = 1.94765798, grad/param norm = 2.1701e-01, time/batch = 0.7130s	
1511/22750 (epoch 3.321), train_loss = 1.86192932, grad/param norm = 2.4901e-01, time/batch = 0.7134s	
1512/22750 (epoch 3.323), train_loss = 1.79045907, grad/param norm = 2.5121e-01, time/batch = 0.7135s	
1513/22750 (epoch 3.325), train_loss = 1.61841491, grad/param norm = 2.3664e-01, time/batch = 0.7143s	
1514/22750 (epoch 3.327), train_loss = 1.95636159, grad/param norm = 2.3116e-01, time/batch = 0.7159s	
1515/22750 (epoch 3.330), train_loss = 2.19196487, grad/param norm = 2.3965e-01, time/batch = 0.7115s	
1516/22750 (epoch 3.332), train_loss = 1.91932949, grad/param norm = 2.3426e-01, time/batch = 0.7058s	
1517/22750 (epoch 3.334), train_loss = 1.65018498, grad/param norm = 2.1620e-01, time/batch = 0.7092s	
1518/22750 (epoch 3.336), train_loss = 1.96989235, grad/param norm = 2.2879e-01, time/batch = 0.7098s	
1519/22750 (epoch 3.338), train_loss = 1.94240692, grad/param norm = 2.5114e-01, time/batch = 0.7093s	
1520/22750 (epoch 3.341), train_loss = 1.86683678, grad/param norm = 2.2053e-01, time/batch = 0.7074s	
1521/22750 (epoch 3.343), train_loss = 1.71062218, grad/param norm = 2.3270e-01, time/batch = 0.7080s	
1522/22750 (epoch 3.345), train_loss = 2.07501943, grad/param norm = 2.6341e-01, time/batch = 0.7102s	
1523/22750 (epoch 3.347), train_loss = 2.05386425, grad/param norm = 2.5555e-01, time/batch = 0.7079s	
1524/22750 (epoch 3.349), train_loss = 1.58763640, grad/param norm = 2.5614e-01, time/batch = 0.7082s	
1525/22750 (epoch 3.352), train_loss = 1.98219613, grad/param norm = 2.8895e-01, time/batch = 0.7078s	
1526/22750 (epoch 3.354), train_loss = 2.04708612, grad/param norm = 2.3940e-01, time/batch = 0.7085s	
1527/22750 (epoch 3.356), train_loss = 2.09641254, grad/param norm = 2.4303e-01, time/batch = 0.7053s	
1528/22750 (epoch 3.358), train_loss = 1.83368171, grad/param norm = 2.3677e-01, time/batch = 0.7082s	
1529/22750 (epoch 3.360), train_loss = 2.14318155, grad/param norm = 2.4052e-01, time/batch = 0.7062s	
1530/22750 (epoch 3.363), train_loss = 1.93640666, grad/param norm = 2.2439e-01, time/batch = 0.7083s	
1531/22750 (epoch 3.365), train_loss = 1.60915524, grad/param norm = 2.5548e-01, time/batch = 0.7124s	
1532/22750 (epoch 3.367), train_loss = 1.57758160, grad/param norm = 2.2193e-01, time/batch = 0.7117s	
1533/22750 (epoch 3.369), train_loss = 1.84433857, grad/param norm = 2.5421e-01, time/batch = 0.7081s	
1534/22750 (epoch 3.371), train_loss = 1.81884191, grad/param norm = 2.4321e-01, time/batch = 0.7073s	
1535/22750 (epoch 3.374), train_loss = 1.69564507, grad/param norm = 2.3806e-01, time/batch = 0.7074s	
1536/22750 (epoch 3.376), train_loss = 1.97973782, grad/param norm = 2.3616e-01, time/batch = 0.7111s	
1537/22750 (epoch 3.378), train_loss = 1.79716323, grad/param norm = 2.3021e-01, time/batch = 0.7118s	
1538/22750 (epoch 3.380), train_loss = 2.01759892, grad/param norm = 2.5151e-01, time/batch = 0.7114s	
1539/22750 (epoch 3.382), train_loss = 1.77653139, grad/param norm = 2.4058e-01, time/batch = 0.7116s	
1540/22750 (epoch 3.385), train_loss = 1.89095754, grad/param norm = 2.0864e-01, time/batch = 0.7080s	
1541/22750 (epoch 3.387), train_loss = 1.97772598, grad/param norm = 2.3644e-01, time/batch = 0.7107s	
1542/22750 (epoch 3.389), train_loss = 1.53390199, grad/param norm = 2.7075e-01, time/batch = 0.7052s	
1543/22750 (epoch 3.391), train_loss = 1.40508566, grad/param norm = 2.4342e-01, time/batch = 0.7091s	
1544/22750 (epoch 3.393), train_loss = 1.72420602, grad/param norm = 2.5932e-01, time/batch = 0.7115s	
1545/22750 (epoch 3.396), train_loss = 1.87620470, grad/param norm = 2.5045e-01, time/batch = 0.7129s	
1546/22750 (epoch 3.398), train_loss = 1.83941232, grad/param norm = 2.6991e-01, time/batch = 0.7211s	
1547/22750 (epoch 3.400), train_loss = 1.84774620, grad/param norm = 2.2389e-01, time/batch = 0.7131s	
1548/22750 (epoch 3.402), train_loss = 1.87208925, grad/param norm = 2.3394e-01, time/batch = 0.7074s	
1549/22750 (epoch 3.404), train_loss = 2.07531519, grad/param norm = 2.6122e-01, time/batch = 0.7108s	
1550/22750 (epoch 3.407), train_loss = 1.94443410, grad/param norm = 2.5157e-01, time/batch = 0.7095s	
1551/22750 (epoch 3.409), train_loss = 1.88551630, grad/param norm = 2.5912e-01, time/batch = 0.7066s	
1552/22750 (epoch 3.411), train_loss = 1.89991007, grad/param norm = 2.4574e-01, time/batch = 0.7111s	
1553/22750 (epoch 3.413), train_loss = 1.82637219, grad/param norm = 2.6023e-01, time/batch = 0.7182s	
1554/22750 (epoch 3.415), train_loss = 1.64650419, grad/param norm = 2.6017e-01, time/batch = 0.7091s	
1555/22750 (epoch 3.418), train_loss = 1.74741354, grad/param norm = 2.2323e-01, time/batch = 0.7089s	
1556/22750 (epoch 3.420), train_loss = 2.08708204, grad/param norm = 2.5468e-01, time/batch = 0.7087s	
1557/22750 (epoch 3.422), train_loss = 2.15994929, grad/param norm = 2.3013e-01, time/batch = 0.7099s	
1558/22750 (epoch 3.424), train_loss = 2.16413905, grad/param norm = 2.2866e-01, time/batch = 0.7089s	
1559/22750 (epoch 3.426), train_loss = 2.15218597, grad/param norm = 2.1888e-01, time/batch = 0.7081s	
1560/22750 (epoch 3.429), train_loss = 1.65502915, grad/param norm = 2.1388e-01, time/batch = 0.7065s	
1561/22750 (epoch 3.431), train_loss = 1.64330043, grad/param norm = 2.1597e-01, time/batch = 0.7087s	
1562/22750 (epoch 3.433), train_loss = 1.71550369, grad/param norm = 2.1205e-01, time/batch = 0.7093s	
1563/22750 (epoch 3.435), train_loss = 1.63974781, grad/param norm = 2.4157e-01, time/batch = 0.7094s	
1564/22750 (epoch 3.437), train_loss = 1.58241713, grad/param norm = 2.1641e-01, time/batch = 0.7057s	
1565/22750 (epoch 3.440), train_loss = 2.10852711, grad/param norm = 2.7092e-01, time/batch = 0.7127s	
1566/22750 (epoch 3.442), train_loss = 1.87524365, grad/param norm = 2.4333e-01, time/batch = 0.7074s	
1567/22750 (epoch 3.444), train_loss = 2.01805207, grad/param norm = 3.6452e-01, time/batch = 0.7078s	
1568/22750 (epoch 3.446), train_loss = 1.96565607, grad/param norm = 3.1937e-01, time/batch = 0.7082s	
1569/22750 (epoch 3.448), train_loss = 2.12038576, grad/param norm = 2.6545e-01, time/batch = 0.7007s	
1570/22750 (epoch 3.451), train_loss = 2.04126615, grad/param norm = 2.6041e-01, time/batch = 0.7001s	
1571/22750 (epoch 3.453), train_loss = 2.15147981, grad/param norm = 2.6287e-01, time/batch = 0.6970s	
1572/22750 (epoch 3.455), train_loss = 2.16804889, grad/param norm = 2.4210e-01, time/batch = 0.7023s	
1573/22750 (epoch 3.457), train_loss = 2.05027983, grad/param norm = 2.5850e-01, time/batch = 0.6937s	
1574/22750 (epoch 3.459), train_loss = 1.91587616, grad/param norm = 2.3867e-01, time/batch = 0.6923s	
1575/22750 (epoch 3.462), train_loss = 1.83635323, grad/param norm = 2.0221e-01, time/batch = 0.7021s	
1576/22750 (epoch 3.464), train_loss = 1.71413394, grad/param norm = 2.1464e-01, time/batch = 0.6983s	
1577/22750 (epoch 3.466), train_loss = 2.10407234, grad/param norm = 2.1934e-01, time/batch = 0.7018s	
1578/22750 (epoch 3.468), train_loss = 1.87272939, grad/param norm = 2.4534e-01, time/batch = 0.7097s	
1579/22750 (epoch 3.470), train_loss = 2.02329799, grad/param norm = 2.5299e-01, time/batch = 0.7008s	
1580/22750 (epoch 3.473), train_loss = 1.90196029, grad/param norm = 2.1966e-01, time/batch = 0.7084s	
1581/22750 (epoch 3.475), train_loss = 1.99204918, grad/param norm = 2.2074e-01, time/batch = 0.7077s	
1582/22750 (epoch 3.477), train_loss = 1.70130325, grad/param norm = 2.3326e-01, time/batch = 0.6938s	
1583/22750 (epoch 3.479), train_loss = 1.79333330, grad/param norm = 2.1507e-01, time/batch = 0.6955s	
1584/22750 (epoch 3.481), train_loss = 1.74052697, grad/param norm = 2.7260e-01, time/batch = 0.6866s	
1585/22750 (epoch 3.484), train_loss = 1.54699138, grad/param norm = 2.5127e-01, time/batch = 0.6952s	
1586/22750 (epoch 3.486), train_loss = 1.82480966, grad/param norm = 2.7730e-01, time/batch = 0.6903s	
1587/22750 (epoch 3.488), train_loss = 1.47637814, grad/param norm = 2.5740e-01, time/batch = 0.6861s	
1588/22750 (epoch 3.490), train_loss = 1.71380928, grad/param norm = 2.4546e-01, time/batch = 0.7123s	
1589/22750 (epoch 3.492), train_loss = 2.00907822, grad/param norm = 2.8109e-01, time/batch = 0.7110s	
1590/22750 (epoch 3.495), train_loss = 1.82485804, grad/param norm = 2.7984e-01, time/batch = 0.7217s	
1591/22750 (epoch 3.497), train_loss = 1.95545480, grad/param norm = 2.5750e-01, time/batch = 0.7136s	
1592/22750 (epoch 3.499), train_loss = 1.82192811, grad/param norm = 2.2544e-01, time/batch = 0.7107s	
1593/22750 (epoch 3.501), train_loss = 1.84682942, grad/param norm = 2.0880e-01, time/batch = 0.7135s	
1594/22750 (epoch 3.503), train_loss = 1.89095482, grad/param norm = 2.2654e-01, time/batch = 0.7011s	
1595/22750 (epoch 3.505), train_loss = 1.70930862, grad/param norm = 2.2200e-01, time/batch = 0.7216s	
1596/22750 (epoch 3.508), train_loss = 1.64264377, grad/param norm = 2.3086e-01, time/batch = 0.7137s	
1597/22750 (epoch 3.510), train_loss = 1.68087444, grad/param norm = 2.3358e-01, time/batch = 0.6998s	
1598/22750 (epoch 3.512), train_loss = 1.77442705, grad/param norm = 2.2354e-01, time/batch = 0.6817s	
1599/22750 (epoch 3.514), train_loss = 1.79784945, grad/param norm = 2.2604e-01, time/batch = 0.6967s	
1600/22750 (epoch 3.516), train_loss = 1.66955930, grad/param norm = 2.4014e-01, time/batch = 0.6996s	
1601/22750 (epoch 3.519), train_loss = 1.85833423, grad/param norm = 2.5426e-01, time/batch = 0.6864s	
1602/22750 (epoch 3.521), train_loss = 1.66586728, grad/param norm = 2.4872e-01, time/batch = 0.6903s	
1603/22750 (epoch 3.523), train_loss = 1.72968130, grad/param norm = 2.6249e-01, time/batch = 0.6973s	
1604/22750 (epoch 3.525), train_loss = 1.97004901, grad/param norm = 2.6312e-01, time/batch = 0.7005s	
1605/22750 (epoch 3.527), train_loss = 1.83249547, grad/param norm = 2.2663e-01, time/batch = 0.6769s	
1606/22750 (epoch 3.530), train_loss = 1.72460431, grad/param norm = 2.4564e-01, time/batch = 0.6824s	
1607/22750 (epoch 3.532), train_loss = 1.78261636, grad/param norm = 2.3481e-01, time/batch = 0.6876s	
1608/22750 (epoch 3.534), train_loss = 1.97960344, grad/param norm = 2.4996e-01, time/batch = 0.7099s	
1609/22750 (epoch 3.536), train_loss = 1.87853774, grad/param norm = 2.4767e-01, time/batch = 0.7048s	
1610/22750 (epoch 3.538), train_loss = 1.95069558, grad/param norm = 2.0919e-01, time/batch = 0.7121s	
1611/22750 (epoch 3.541), train_loss = 1.55845631, grad/param norm = 2.0454e-01, time/batch = 0.7274s	
1612/22750 (epoch 3.543), train_loss = 1.56807863, grad/param norm = 2.1269e-01, time/batch = 0.7261s	
1613/22750 (epoch 3.545), train_loss = 1.98763669, grad/param norm = 2.2911e-01, time/batch = 0.7179s	
1614/22750 (epoch 3.547), train_loss = 1.60410039, grad/param norm = 2.2090e-01, time/batch = 0.7051s	
1615/22750 (epoch 3.549), train_loss = 1.68608689, grad/param norm = 2.4103e-01, time/batch = 0.7134s	
1616/22750 (epoch 3.552), train_loss = 1.94206394, grad/param norm = 2.5943e-01, time/batch = 0.7036s	
1617/22750 (epoch 3.554), train_loss = 1.93710904, grad/param norm = 2.2715e-01, time/batch = 0.7208s	
1618/22750 (epoch 3.556), train_loss = 1.81932936, grad/param norm = 2.3152e-01, time/batch = 0.7262s	
1619/22750 (epoch 3.558), train_loss = 1.98536063, grad/param norm = 2.2526e-01, time/batch = 0.7077s	
1620/22750 (epoch 3.560), train_loss = 1.67543230, grad/param norm = 2.2113e-01, time/batch = 0.6983s	
1621/22750 (epoch 3.563), train_loss = 1.84700822, grad/param norm = 2.2670e-01, time/batch = 0.6977s	
1622/22750 (epoch 3.565), train_loss = 2.02577725, grad/param norm = 2.1525e-01, time/batch = 0.7001s	
1623/22750 (epoch 3.567), train_loss = 1.82437617, grad/param norm = 2.2478e-01, time/batch = 0.7043s	
1624/22750 (epoch 3.569), train_loss = 1.79524228, grad/param norm = 2.3915e-01, time/batch = 0.7090s	
1625/22750 (epoch 3.571), train_loss = 1.87905695, grad/param norm = 2.5254e-01, time/batch = 0.6998s	
1626/22750 (epoch 3.574), train_loss = 1.64273372, grad/param norm = 2.3489e-01, time/batch = 0.7013s	
1627/22750 (epoch 3.576), train_loss = 1.85811993, grad/param norm = 2.2239e-01, time/batch = 0.6973s	
1628/22750 (epoch 3.578), train_loss = 1.64589792, grad/param norm = 2.3772e-01, time/batch = 0.7053s	
1629/22750 (epoch 3.580), train_loss = 1.90849069, grad/param norm = 2.2855e-01, time/batch = 0.6989s	
1630/22750 (epoch 3.582), train_loss = 1.60907430, grad/param norm = 2.4909e-01, time/batch = 0.7015s	
1631/22750 (epoch 3.585), train_loss = 1.52487748, grad/param norm = 2.0499e-01, time/batch = 0.6990s	
1632/22750 (epoch 3.587), train_loss = 1.64896164, grad/param norm = 2.1128e-01, time/batch = 0.7026s	
1633/22750 (epoch 3.589), train_loss = 1.67323769, grad/param norm = 2.3505e-01, time/batch = 0.6975s	
1634/22750 (epoch 3.591), train_loss = 1.89032742, grad/param norm = 2.5696e-01, time/batch = 0.6978s	
1635/22750 (epoch 3.593), train_loss = 2.00181528, grad/param norm = 2.2211e-01, time/batch = 0.7002s	
1636/22750 (epoch 3.596), train_loss = 1.94878742, grad/param norm = 2.0453e-01, time/batch = 0.7070s	
1637/22750 (epoch 3.598), train_loss = 2.03059350, grad/param norm = 2.4117e-01, time/batch = 0.6994s	
1638/22750 (epoch 3.600), train_loss = 1.82823179, grad/param norm = 2.1680e-01, time/batch = 0.7138s	
1639/22750 (epoch 3.602), train_loss = 1.59008480, grad/param norm = 2.0088e-01, time/batch = 0.7070s	
1640/22750 (epoch 3.604), train_loss = 1.76257597, grad/param norm = 2.4292e-01, time/batch = 0.6965s	
1641/22750 (epoch 3.607), train_loss = 1.44639525, grad/param norm = 2.0215e-01, time/batch = 0.6985s	
1642/22750 (epoch 3.609), train_loss = 1.48638570, grad/param norm = 1.9688e-01, time/batch = 0.6982s	
1643/22750 (epoch 3.611), train_loss = 1.73743647, grad/param norm = 2.4456e-01, time/batch = 0.7000s	
1644/22750 (epoch 3.613), train_loss = 1.66507920, grad/param norm = 2.4550e-01, time/batch = 0.6981s	
1645/22750 (epoch 3.615), train_loss = 1.76685249, grad/param norm = 2.3587e-01, time/batch = 0.6990s	
1646/22750 (epoch 3.618), train_loss = 1.80728240, grad/param norm = 2.6786e-01, time/batch = 0.6995s	
1647/22750 (epoch 3.620), train_loss = 1.78286499, grad/param norm = 2.4362e-01, time/batch = 0.7014s	
1648/22750 (epoch 3.622), train_loss = 1.64091250, grad/param norm = 2.9362e-01, time/batch = 0.6985s	
1649/22750 (epoch 3.624), train_loss = 1.98686154, grad/param norm = 2.6907e-01, time/batch = 0.6941s	
1650/22750 (epoch 3.626), train_loss = 1.78718306, grad/param norm = 3.0738e-01, time/batch = 0.6968s	
1651/22750 (epoch 3.629), train_loss = 1.86960608, grad/param norm = 2.7853e-01, time/batch = 0.6993s	
1652/22750 (epoch 3.631), train_loss = 1.89933953, grad/param norm = 2.3250e-01, time/batch = 0.6927s	
1653/22750 (epoch 3.633), train_loss = 1.56746524, grad/param norm = 2.2416e-01, time/batch = 0.6923s	
1654/22750 (epoch 3.635), train_loss = 1.95337014, grad/param norm = 2.2339e-01, time/batch = 0.6915s	
1655/22750 (epoch 3.637), train_loss = 1.91504708, grad/param norm = 2.4335e-01, time/batch = 0.6932s	
1656/22750 (epoch 3.640), train_loss = 2.05162471, grad/param norm = 2.5883e-01, time/batch = 0.6938s	
1657/22750 (epoch 3.642), train_loss = 1.96992497, grad/param norm = 2.4688e-01, time/batch = 0.6965s	
1658/22750 (epoch 3.644), train_loss = 1.82334463, grad/param norm = 2.3293e-01, time/batch = 0.6981s	
1659/22750 (epoch 3.646), train_loss = 1.90439971, grad/param norm = 2.6701e-01, time/batch = 0.7001s	
1660/22750 (epoch 3.648), train_loss = 1.86433730, grad/param norm = 2.5330e-01, time/batch = 0.7004s	
1661/22750 (epoch 3.651), train_loss = 2.00924729, grad/param norm = 2.4263e-01, time/batch = 0.6947s	
1662/22750 (epoch 3.653), train_loss = 1.80474745, grad/param norm = 2.2431e-01, time/batch = 0.6936s	
1663/22750 (epoch 3.655), train_loss = 1.82884874, grad/param norm = 2.4010e-01, time/batch = 0.7123s	
1664/22750 (epoch 3.657), train_loss = 2.02968309, grad/param norm = 2.0782e-01, time/batch = 0.7118s	
1665/22750 (epoch 3.659), train_loss = 2.04880453, grad/param norm = 2.2122e-01, time/batch = 0.7156s	
1666/22750 (epoch 3.662), train_loss = 2.15742504, grad/param norm = 2.2969e-01, time/batch = 0.6922s	
1667/22750 (epoch 3.664), train_loss = 1.89064625, grad/param norm = 2.4374e-01, time/batch = 0.7141s	
1668/22750 (epoch 3.666), train_loss = 1.73801181, grad/param norm = 2.5520e-01, time/batch = 0.7138s	
1669/22750 (epoch 3.668), train_loss = 1.85723942, grad/param norm = 2.2929e-01, time/batch = 0.6902s	
1670/22750 (epoch 3.670), train_loss = 1.88332004, grad/param norm = 2.3247e-01, time/batch = 0.6910s	
1671/22750 (epoch 3.673), train_loss = 1.99951281, grad/param norm = 2.9175e-01, time/batch = 0.6959s	
1672/22750 (epoch 3.675), train_loss = 2.32554345, grad/param norm = 3.1142e-01, time/batch = 0.6959s	
1673/22750 (epoch 3.677), train_loss = 2.05941597, grad/param norm = 2.5888e-01, time/batch = 0.7089s	
1674/22750 (epoch 3.679), train_loss = 2.13205555, grad/param norm = 2.3485e-01, time/batch = 0.7216s	
1675/22750 (epoch 3.681), train_loss = 1.97470888, grad/param norm = 2.3844e-01, time/batch = 0.7371s	
1676/22750 (epoch 3.684), train_loss = 1.99766781, grad/param norm = 2.3398e-01, time/batch = 0.7231s	
1677/22750 (epoch 3.686), train_loss = 1.96491663, grad/param norm = 2.5519e-01, time/batch = 0.7103s	
1678/22750 (epoch 3.688), train_loss = 1.97116261, grad/param norm = 2.4270e-01, time/batch = 0.7164s	
1679/22750 (epoch 3.690), train_loss = 1.89213355, grad/param norm = 2.3082e-01, time/batch = 0.7019s	
1680/22750 (epoch 3.692), train_loss = 2.05178696, grad/param norm = 2.2920e-01, time/batch = 0.6983s	
1681/22750 (epoch 3.695), train_loss = 1.83742931, grad/param norm = 2.3357e-01, time/batch = 0.7064s	
1682/22750 (epoch 3.697), train_loss = 1.75561681, grad/param norm = 2.5673e-01, time/batch = 0.7003s	
1683/22750 (epoch 3.699), train_loss = 1.91567355, grad/param norm = 2.3148e-01, time/batch = 0.6893s	
1684/22750 (epoch 3.701), train_loss = 1.77905992, grad/param norm = 2.1578e-01, time/batch = 0.7077s	
1685/22750 (epoch 3.703), train_loss = 1.89494267, grad/param norm = 2.2525e-01, time/batch = 0.7000s	
1686/22750 (epoch 3.705), train_loss = 1.67072643, grad/param norm = 2.0534e-01, time/batch = 0.7090s	
1687/22750 (epoch 3.708), train_loss = 1.87484112, grad/param norm = 2.0454e-01, time/batch = 0.7244s	
1688/22750 (epoch 3.710), train_loss = 1.60279075, grad/param norm = 2.2763e-01, time/batch = 0.7150s	
1689/22750 (epoch 3.712), train_loss = 1.70785838, grad/param norm = 2.1537e-01, time/batch = 0.7193s	
1690/22750 (epoch 3.714), train_loss = 1.61927647, grad/param norm = 2.2442e-01, time/batch = 0.6935s	
1691/22750 (epoch 3.716), train_loss = 1.76895923, grad/param norm = 2.4067e-01, time/batch = 0.6950s	
1692/22750 (epoch 3.719), train_loss = 1.98746143, grad/param norm = 2.9281e-01, time/batch = 0.6954s	
1693/22750 (epoch 3.721), train_loss = 1.89621294, grad/param norm = 2.5350e-01, time/batch = 0.6975s	
1694/22750 (epoch 3.723), train_loss = 1.78691159, grad/param norm = 2.1902e-01, time/batch = 0.6993s	
1695/22750 (epoch 3.725), train_loss = 1.80879245, grad/param norm = 2.3903e-01, time/batch = 0.7007s	
1696/22750 (epoch 3.727), train_loss = 1.72257360, grad/param norm = 2.0953e-01, time/batch = 0.6928s	
1697/22750 (epoch 3.730), train_loss = 1.73872767, grad/param norm = 2.0762e-01, time/batch = 0.6931s	
1698/22750 (epoch 3.732), train_loss = 1.84828335, grad/param norm = 2.1061e-01, time/batch = 0.6975s	
1699/22750 (epoch 3.734), train_loss = 1.43899217, grad/param norm = 2.3992e-01, time/batch = 0.6996s	
1700/22750 (epoch 3.736), train_loss = 1.74766021, grad/param norm = 2.3706e-01, time/batch = 0.7136s	
1701/22750 (epoch 3.738), train_loss = 1.71945154, grad/param norm = 2.3899e-01, time/batch = 0.6993s	
1702/22750 (epoch 3.741), train_loss = 1.91996300, grad/param norm = 2.0781e-01, time/batch = 0.6962s	
1703/22750 (epoch 3.743), train_loss = 1.91672480, grad/param norm = 2.3246e-01, time/batch = 0.6944s	
1704/22750 (epoch 3.745), train_loss = 1.62047179, grad/param norm = 2.2711e-01, time/batch = 0.6952s	
1705/22750 (epoch 3.747), train_loss = 1.73709628, grad/param norm = 2.3149e-01, time/batch = 0.6964s	
1706/22750 (epoch 3.749), train_loss = 1.97584559, grad/param norm = 2.5182e-01, time/batch = 0.6940s	
1707/22750 (epoch 3.752), train_loss = 1.70665000, grad/param norm = 2.1832e-01, time/batch = 0.6920s	
1708/22750 (epoch 3.754), train_loss = 1.92054294, grad/param norm = 2.8027e-01, time/batch = 0.6947s	
1709/22750 (epoch 3.756), train_loss = 1.63823272, grad/param norm = 3.0692e-01, time/batch = 0.6938s	
1710/22750 (epoch 3.758), train_loss = 1.55654315, grad/param norm = 2.1503e-01, time/batch = 0.6921s	
1711/22750 (epoch 3.760), train_loss = 1.88993962, grad/param norm = 2.1921e-01, time/batch = 0.6947s	
1712/22750 (epoch 3.763), train_loss = 1.82825433, grad/param norm = 2.1422e-01, time/batch = 0.7127s	
1713/22750 (epoch 3.765), train_loss = 1.69671158, grad/param norm = 2.3482e-01, time/batch = 0.6999s	
1714/22750 (epoch 3.767), train_loss = 1.72551713, grad/param norm = 2.2882e-01, time/batch = 0.6903s	
1715/22750 (epoch 3.769), train_loss = 1.92315939, grad/param norm = 2.4712e-01, time/batch = 0.7008s	
1716/22750 (epoch 3.771), train_loss = 1.89076206, grad/param norm = 2.4296e-01, time/batch = 0.7257s	
1717/22750 (epoch 3.774), train_loss = 1.75106467, grad/param norm = 2.3655e-01, time/batch = 0.7255s	
1718/22750 (epoch 3.776), train_loss = 1.79947807, grad/param norm = 2.3782e-01, time/batch = 0.7318s	
1719/22750 (epoch 3.778), train_loss = 1.99402777, grad/param norm = 2.2152e-01, time/batch = 0.7220s	
1720/22750 (epoch 3.780), train_loss = 1.86029649, grad/param norm = 2.5173e-01, time/batch = 0.7238s	
1721/22750 (epoch 3.782), train_loss = 1.93361753, grad/param norm = 2.4042e-01, time/batch = 0.7405s	
1722/22750 (epoch 3.785), train_loss = 1.87612411, grad/param norm = 2.2339e-01, time/batch = 0.7253s	
1723/22750 (epoch 3.787), train_loss = 1.73038823, grad/param norm = 2.2999e-01, time/batch = 0.7292s	
1724/22750 (epoch 3.789), train_loss = 1.69437142, grad/param norm = 2.0863e-01, time/batch = 0.7255s	
1725/22750 (epoch 3.791), train_loss = 1.76232125, grad/param norm = 1.8350e-01, time/batch = 0.7364s	
1726/22750 (epoch 3.793), train_loss = 1.78011592, grad/param norm = 2.2594e-01, time/batch = 0.7209s	
1727/22750 (epoch 3.796), train_loss = 1.69815138, grad/param norm = 2.1569e-01, time/batch = 0.7212s	
1728/22750 (epoch 3.798), train_loss = 1.72407726, grad/param norm = 2.0169e-01, time/batch = 0.7373s	
1729/22750 (epoch 3.800), train_loss = 1.69838180, grad/param norm = 2.1867e-01, time/batch = 0.7045s	
1730/22750 (epoch 3.802), train_loss = 1.84308213, grad/param norm = 2.3506e-01, time/batch = 0.7180s	
1731/22750 (epoch 3.804), train_loss = 2.07120551, grad/param norm = 2.2149e-01, time/batch = 0.7207s	
1732/22750 (epoch 3.807), train_loss = 1.81118223, grad/param norm = 2.2146e-01, time/batch = 0.7263s	
1733/22750 (epoch 3.809), train_loss = 2.04806880, grad/param norm = 2.5106e-01, time/batch = 0.7089s	
1734/22750 (epoch 3.811), train_loss = 1.76071968, grad/param norm = 2.2386e-01, time/batch = 0.6970s	
1735/22750 (epoch 3.813), train_loss = 1.90041439, grad/param norm = 1.9530e-01, time/batch = 0.7046s	
1736/22750 (epoch 3.815), train_loss = 1.99854781, grad/param norm = 2.4964e-01, time/batch = 0.7243s	
1737/22750 (epoch 3.818), train_loss = 1.98924181, grad/param norm = 2.2924e-01, time/batch = 0.7071s	
1738/22750 (epoch 3.820), train_loss = 2.06567452, grad/param norm = 2.1648e-01, time/batch = 0.7068s	
1739/22750 (epoch 3.822), train_loss = 1.89006461, grad/param norm = 2.1148e-01, time/batch = 0.7041s	
1740/22750 (epoch 3.824), train_loss = 1.89370456, grad/param norm = 2.1814e-01, time/batch = 0.7028s	
1741/22750 (epoch 3.826), train_loss = 1.82652232, grad/param norm = 2.1417e-01, time/batch = 0.7075s	
1742/22750 (epoch 3.829), train_loss = 1.99908984, grad/param norm = 2.4352e-01, time/batch = 0.7236s	
1743/22750 (epoch 3.831), train_loss = 1.96579481, grad/param norm = 2.5171e-01, time/batch = 0.7072s	
1744/22750 (epoch 3.833), train_loss = 2.02088344, grad/param norm = 2.3579e-01, time/batch = 0.6962s	
1745/22750 (epoch 3.835), train_loss = 1.82514526, grad/param norm = 2.2927e-01, time/batch = 0.7031s	
1746/22750 (epoch 3.837), train_loss = 1.83011592, grad/param norm = 2.3259e-01, time/batch = 0.7041s	
1747/22750 (epoch 3.840), train_loss = 1.85317985, grad/param norm = 2.3759e-01, time/batch = 0.7133s	
1748/22750 (epoch 3.842), train_loss = 1.77095492, grad/param norm = 2.2531e-01, time/batch = 0.7236s	
1749/22750 (epoch 3.844), train_loss = 2.04683691, grad/param norm = 2.4800e-01, time/batch = 0.7246s	
1750/22750 (epoch 3.846), train_loss = 1.75039358, grad/param norm = 2.1515e-01, time/batch = 0.7297s	
1751/22750 (epoch 3.848), train_loss = 1.65718690, grad/param norm = 2.3723e-01, time/batch = 0.7269s	
1752/22750 (epoch 3.851), train_loss = 1.72059533, grad/param norm = 2.3884e-01, time/batch = 0.7254s	
1753/22750 (epoch 3.853), train_loss = 1.76510402, grad/param norm = 2.3590e-01, time/batch = 0.7272s	
1754/22750 (epoch 3.855), train_loss = 1.59061366, grad/param norm = 2.0708e-01, time/batch = 0.7250s	
1755/22750 (epoch 3.857), train_loss = 1.81161351, grad/param norm = 2.0380e-01, time/batch = 0.7248s	
1756/22750 (epoch 3.859), train_loss = 1.84307134, grad/param norm = 2.3325e-01, time/batch = 0.7211s	
1757/22750 (epoch 3.862), train_loss = 1.96760347, grad/param norm = 2.4141e-01, time/batch = 0.7247s	
1758/22750 (epoch 3.864), train_loss = 1.83529915, grad/param norm = 2.1842e-01, time/batch = 0.7244s	
1759/22750 (epoch 3.866), train_loss = 1.82353475, grad/param norm = 2.0080e-01, time/batch = 0.7286s	
1760/22750 (epoch 3.868), train_loss = 1.83740626, grad/param norm = 2.1333e-01, time/batch = 0.7284s	
1761/22750 (epoch 3.870), train_loss = 1.60314044, grad/param norm = 2.1554e-01, time/batch = 0.7090s	
1762/22750 (epoch 3.873), train_loss = 1.75945464, grad/param norm = 2.0552e-01, time/batch = 0.7104s	
1763/22750 (epoch 3.875), train_loss = 1.84422614, grad/param norm = 2.1579e-01, time/batch = 0.7125s	
1764/22750 (epoch 3.877), train_loss = 1.64289709, grad/param norm = 1.9676e-01, time/batch = 0.7290s	
1765/22750 (epoch 3.879), train_loss = 1.93890172, grad/param norm = 2.3821e-01, time/batch = 0.7253s	
1766/22750 (epoch 3.881), train_loss = 1.89111321, grad/param norm = 2.3850e-01, time/batch = 0.7261s	
1767/22750 (epoch 3.884), train_loss = 1.79399993, grad/param norm = 2.6402e-01, time/batch = 0.7234s	
1768/22750 (epoch 3.886), train_loss = 1.90800951, grad/param norm = 2.2503e-01, time/batch = 0.7109s	
1769/22750 (epoch 3.888), train_loss = 1.86419286, grad/param norm = 2.2092e-01, time/batch = 0.7067s	
1770/22750 (epoch 3.890), train_loss = 1.86340464, grad/param norm = 2.5613e-01, time/batch = 0.7088s	
1771/22750 (epoch 3.892), train_loss = 2.27950448, grad/param norm = 3.1053e-01, time/batch = 0.7115s	
1772/22750 (epoch 3.895), train_loss = 1.94220958, grad/param norm = 2.3461e-01, time/batch = 0.7093s	
1773/22750 (epoch 3.897), train_loss = 1.91487811, grad/param norm = 2.3846e-01, time/batch = 0.6989s	
1774/22750 (epoch 3.899), train_loss = 1.87217293, grad/param norm = 2.1638e-01, time/batch = 0.7014s	
1775/22750 (epoch 3.901), train_loss = 1.99647805, grad/param norm = 2.0956e-01, time/batch = 0.6959s	
1776/22750 (epoch 3.903), train_loss = 1.81962129, grad/param norm = 2.1713e-01, time/batch = 0.7072s	
1777/22750 (epoch 3.905), train_loss = 1.82146280, grad/param norm = 1.9947e-01, time/batch = 0.7189s	
1778/22750 (epoch 3.908), train_loss = 1.82838511, grad/param norm = 2.4743e-01, time/batch = 0.7043s	
1779/22750 (epoch 3.910), train_loss = 1.64626051, grad/param norm = 2.3634e-01, time/batch = 0.6990s	
1780/22750 (epoch 3.912), train_loss = 1.65997258, grad/param norm = 2.3099e-01, time/batch = 0.6991s	
1781/22750 (epoch 3.914), train_loss = 1.71766431, grad/param norm = 2.2403e-01, time/batch = 0.7230s	
1782/22750 (epoch 3.916), train_loss = 1.58220040, grad/param norm = 2.0194e-01, time/batch = 0.7279s	
1783/22750 (epoch 3.919), train_loss = 1.69942549, grad/param norm = 2.3080e-01, time/batch = 0.7193s	
1784/22750 (epoch 3.921), train_loss = 1.41176248, grad/param norm = 2.0610e-01, time/batch = 0.7119s	
1785/22750 (epoch 3.923), train_loss = 1.75564384, grad/param norm = 2.1478e-01, time/batch = 0.7179s	
1786/22750 (epoch 3.925), train_loss = 1.75642810, grad/param norm = 2.0889e-01, time/batch = 0.7122s	
1787/22750 (epoch 3.927), train_loss = 1.53861319, grad/param norm = 2.2147e-01, time/batch = 0.7000s	
1788/22750 (epoch 3.930), train_loss = 1.63277636, grad/param norm = 2.5214e-01, time/batch = 0.6998s	
1789/22750 (epoch 3.932), train_loss = 1.99842095, grad/param norm = 2.4894e-01, time/batch = 0.7002s	
1790/22750 (epoch 3.934), train_loss = 1.44005110, grad/param norm = 2.0482e-01, time/batch = 0.7011s	
1791/22750 (epoch 3.936), train_loss = 1.93204621, grad/param norm = 2.5139e-01, time/batch = 0.7073s	
1792/22750 (epoch 3.938), train_loss = 1.80486448, grad/param norm = 2.3199e-01, time/batch = 0.7058s	
1793/22750 (epoch 3.941), train_loss = 2.15367913, grad/param norm = 2.3867e-01, time/batch = 0.7039s	
1794/22750 (epoch 3.943), train_loss = 1.89957735, grad/param norm = 2.2762e-01, time/batch = 0.7044s	
1795/22750 (epoch 3.945), train_loss = 1.82088618, grad/param norm = 2.2464e-01, time/batch = 0.7097s	
1796/22750 (epoch 3.947), train_loss = 1.85030383, grad/param norm = 2.4425e-01, time/batch = 0.7185s	
1797/22750 (epoch 3.949), train_loss = 1.66579578, grad/param norm = 2.3195e-01, time/batch = 0.6978s	
1798/22750 (epoch 3.952), train_loss = 1.69337791, grad/param norm = 2.1284e-01, time/batch = 0.7015s	
1799/22750 (epoch 3.954), train_loss = 1.69392843, grad/param norm = 2.1720e-01, time/batch = 0.6981s	
1800/22750 (epoch 3.956), train_loss = 1.81101456, grad/param norm = 2.2780e-01, time/batch = 0.7001s	
1801/22750 (epoch 3.958), train_loss = 1.76539648, grad/param norm = 2.1794e-01, time/batch = 0.7118s	
1802/22750 (epoch 3.960), train_loss = 1.80480443, grad/param norm = 2.3505e-01, time/batch = 0.7238s	
1803/22750 (epoch 3.963), train_loss = 1.92053576, grad/param norm = 2.3506e-01, time/batch = 0.7072s	
1804/22750 (epoch 3.965), train_loss = 1.87028372, grad/param norm = 2.2634e-01, time/batch = 0.7017s	
1805/22750 (epoch 3.967), train_loss = 1.84011387, grad/param norm = 2.1820e-01, time/batch = 0.6953s	
1806/22750 (epoch 3.969), train_loss = 1.78173457, grad/param norm = 2.1090e-01, time/batch = 0.7020s	
1807/22750 (epoch 3.971), train_loss = 1.75363439, grad/param norm = 2.0476e-01, time/batch = 0.7002s	
1808/22750 (epoch 3.974), train_loss = 1.83050434, grad/param norm = 2.5449e-01, time/batch = 0.6941s	
1809/22750 (epoch 3.976), train_loss = 1.91447988, grad/param norm = 2.2051e-01, time/batch = 0.6953s	
1810/22750 (epoch 3.978), train_loss = 1.70133182, grad/param norm = 2.4369e-01, time/batch = 0.6982s	
1811/22750 (epoch 3.980), train_loss = 1.90524764, grad/param norm = 2.5219e-01, time/batch = 0.7007s	
1812/22750 (epoch 3.982), train_loss = 1.73352264, grad/param norm = 2.1797e-01, time/batch = 0.7241s	
1813/22750 (epoch 3.985), train_loss = 2.03664056, grad/param norm = 2.6224e-01, time/batch = 0.7044s	
1814/22750 (epoch 3.987), train_loss = 1.61561382, grad/param norm = 2.2559e-01, time/batch = 0.6959s	
1815/22750 (epoch 3.989), train_loss = 1.67493004, grad/param norm = 1.8892e-01, time/batch = 0.6965s	
1816/22750 (epoch 3.991), train_loss = 1.88514927, grad/param norm = 2.2298e-01, time/batch = 0.6979s	
1817/22750 (epoch 3.993), train_loss = 1.86401572, grad/param norm = 2.3997e-01, time/batch = 0.6944s	
1818/22750 (epoch 3.996), train_loss = 1.75698344, grad/param norm = 2.4240e-01, time/batch = 0.6998s	
1819/22750 (epoch 3.998), train_loss = 1.95012320, grad/param norm = 2.1349e-01, time/batch = 0.6948s	
1820/22750 (epoch 4.000), train_loss = 1.90139323, grad/param norm = 2.3011e-01, time/batch = 0.7000s	
1821/22750 (epoch 4.002), train_loss = 1.96077323, grad/param norm = 2.4576e-01, time/batch = 0.7094s	
1822/22750 (epoch 4.004), train_loss = 1.80594880, grad/param norm = 2.9013e-01, time/batch = 0.7238s	
1823/22750 (epoch 4.007), train_loss = 1.90982016, grad/param norm = 2.5333e-01, time/batch = 0.7018s	
1824/22750 (epoch 4.009), train_loss = 2.05902720, grad/param norm = 2.3137e-01, time/batch = 0.6962s	
1825/22750 (epoch 4.011), train_loss = 2.00032686, grad/param norm = 2.4191e-01, time/batch = 0.6945s	
1826/22750 (epoch 4.013), train_loss = 1.88466423, grad/param norm = 2.3439e-01, time/batch = 0.6949s	
1827/22750 (epoch 4.015), train_loss = 1.89268427, grad/param norm = 2.2605e-01, time/batch = 0.7047s	
1828/22750 (epoch 4.018), train_loss = 1.88105658, grad/param norm = 2.3652e-01, time/batch = 0.7009s	
1829/22750 (epoch 4.020), train_loss = 1.91901651, grad/param norm = 2.1329e-01, time/batch = 0.7107s	
1830/22750 (epoch 4.022), train_loss = 1.79767954, grad/param norm = 2.0277e-01, time/batch = 0.7051s	
1831/22750 (epoch 4.024), train_loss = 1.78999390, grad/param norm = 2.1946e-01, time/batch = 0.7138s	
1832/22750 (epoch 4.026), train_loss = 1.99423535, grad/param norm = 2.4355e-01, time/batch = 0.7254s	
1833/22750 (epoch 4.029), train_loss = 1.58513359, grad/param norm = 2.1502e-01, time/batch = 0.7017s	
1834/22750 (epoch 4.031), train_loss = 2.08356577, grad/param norm = 2.2616e-01, time/batch = 0.7083s	
1835/22750 (epoch 4.033), train_loss = 1.82907963, grad/param norm = 2.0125e-01, time/batch = 0.7039s	
1836/22750 (epoch 4.035), train_loss = 1.89411182, grad/param norm = 2.2057e-01, time/batch = 0.7012s	
1837/22750 (epoch 4.037), train_loss = 1.99475963, grad/param norm = 2.5113e-01, time/batch = 0.7037s	
1838/22750 (epoch 4.040), train_loss = 1.73330931, grad/param norm = 2.3819e-01, time/batch = 0.6952s	
1839/22750 (epoch 4.042), train_loss = 1.90693377, grad/param norm = 2.2153e-01, time/batch = 0.6978s	
1840/22750 (epoch 4.044), train_loss = 1.72239919, grad/param norm = 2.3674e-01, time/batch = 0.6998s	
1841/22750 (epoch 4.046), train_loss = 1.85982700, grad/param norm = 2.6128e-01, time/batch = 0.7207s	
1842/22750 (epoch 4.048), train_loss = 1.81765269, grad/param norm = 2.5656e-01, time/batch = 0.7246s	
1843/22750 (epoch 4.051), train_loss = 1.89373221, grad/param norm = 2.4088e-01, time/batch = 0.7229s	
1844/22750 (epoch 4.053), train_loss = 1.61616327, grad/param norm = 2.2424e-01, time/batch = 0.7035s	
1845/22750 (epoch 4.055), train_loss = 1.86520813, grad/param norm = 2.3070e-01, time/batch = 0.7047s	
1846/22750 (epoch 4.057), train_loss = 1.88870713, grad/param norm = 2.4250e-01, time/batch = 0.7232s	
1847/22750 (epoch 4.059), train_loss = 1.49399066, grad/param norm = 2.3401e-01, time/batch = 0.7274s	
1848/22750 (epoch 4.062), train_loss = 1.62157860, grad/param norm = 2.1526e-01, time/batch = 0.7243s	
1849/22750 (epoch 4.064), train_loss = 1.89053518, grad/param norm = 2.4783e-01, time/batch = 0.7207s	
1850/22750 (epoch 4.066), train_loss = 1.59911885, grad/param norm = 2.0509e-01, time/batch = 0.7072s	
1851/22750 (epoch 4.068), train_loss = 1.62976740, grad/param norm = 2.1350e-01, time/batch = 0.7221s	
1852/22750 (epoch 4.070), train_loss = 1.53300228, grad/param norm = 2.0650e-01, time/batch = 0.7133s	
1853/22750 (epoch 4.073), train_loss = 1.71508749, grad/param norm = 2.4751e-01, time/batch = 0.7114s	
1854/22750 (epoch 4.075), train_loss = 1.81190953, grad/param norm = 2.1460e-01, time/batch = 0.7046s	
1855/22750 (epoch 4.077), train_loss = 1.43809463, grad/param norm = 2.1189e-01, time/batch = 0.7142s	
1856/22750 (epoch 4.079), train_loss = 1.75014548, grad/param norm = 2.2765e-01, time/batch = 0.7131s	
1857/22750 (epoch 4.081), train_loss = 1.78204370, grad/param norm = 2.2508e-01, time/batch = 0.7179s	
1858/22750 (epoch 4.084), train_loss = 1.67658081, grad/param norm = 2.1166e-01, time/batch = 0.7040s	
1859/22750 (epoch 4.086), train_loss = 1.67820035, grad/param norm = 2.1777e-01, time/batch = 0.6981s	
1860/22750 (epoch 4.088), train_loss = 1.74459115, grad/param norm = 2.1752e-01, time/batch = 0.6940s	
1861/22750 (epoch 4.090), train_loss = 1.72991662, grad/param norm = 2.2141e-01, time/batch = 0.7247s	
1862/22750 (epoch 4.092), train_loss = 1.89378371, grad/param norm = 2.2290e-01, time/batch = 0.7230s	
1863/22750 (epoch 4.095), train_loss = 1.63994327, grad/param norm = 2.1212e-01, time/batch = 0.7128s	
1864/22750 (epoch 4.097), train_loss = 1.71364350, grad/param norm = 2.2168e-01, time/batch = 0.6944s	
1865/22750 (epoch 4.099), train_loss = 1.84701215, grad/param norm = 2.4841e-01, time/batch = 0.6940s	
1866/22750 (epoch 4.101), train_loss = 1.78843844, grad/param norm = 2.2325e-01, time/batch = 0.6911s	
1867/22750 (epoch 4.103), train_loss = 1.69503404, grad/param norm = 2.2531e-01, time/batch = 0.7016s	
1868/22750 (epoch 4.105), train_loss = 2.05134120, grad/param norm = 2.5324e-01, time/batch = 0.6986s	
1869/22750 (epoch 4.108), train_loss = 1.71788277, grad/param norm = 2.1968e-01, time/batch = 0.6986s	
1870/22750 (epoch 4.110), train_loss = 1.78296449, grad/param norm = 2.3996e-01, time/batch = 0.7023s	
1871/22750 (epoch 4.112), train_loss = 1.48315614, grad/param norm = 2.1273e-01, time/batch = 0.7136s	
1872/22750 (epoch 4.114), train_loss = 1.49331200, grad/param norm = 2.1298e-01, time/batch = 0.7171s	
1873/22750 (epoch 4.116), train_loss = 1.58860042, grad/param norm = 2.3779e-01, time/batch = 0.6999s	
1874/22750 (epoch 4.119), train_loss = 1.66269234, grad/param norm = 1.9888e-01, time/batch = 0.7050s	
1875/22750 (epoch 4.121), train_loss = 1.90024447, grad/param norm = 2.3078e-01, time/batch = 0.7032s	
1876/22750 (epoch 4.123), train_loss = 1.69037328, grad/param norm = 1.9082e-01, time/batch = 0.7224s	
1877/22750 (epoch 4.125), train_loss = 1.94379408, grad/param norm = 2.1846e-01, time/batch = 0.6953s	
1878/22750 (epoch 4.127), train_loss = 1.87175959, grad/param norm = 2.4362e-01, time/batch = 0.6905s	
1879/22750 (epoch 4.130), train_loss = 1.82417377, grad/param norm = 2.1032e-01, time/batch = 0.6859s	
1880/22750 (epoch 4.132), train_loss = 1.88934630, grad/param norm = 2.3491e-01, time/batch = 0.6894s	
1881/22750 (epoch 4.134), train_loss = 1.74244796, grad/param norm = 2.2358e-01, time/batch = 0.6924s	
1882/22750 (epoch 4.136), train_loss = 1.64617087, grad/param norm = 1.9278e-01, time/batch = 0.6863s	
1883/22750 (epoch 4.138), train_loss = 1.74301955, grad/param norm = 2.3824e-01, time/batch = 0.6840s	
1884/22750 (epoch 4.141), train_loss = 1.64012270, grad/param norm = 2.1224e-01, time/batch = 0.6851s	
1885/22750 (epoch 4.143), train_loss = 1.60375321, grad/param norm = 2.1265e-01, time/batch = 0.6850s	
1886/22750 (epoch 4.145), train_loss = 1.83546673, grad/param norm = 2.4038e-01, time/batch = 0.6872s	
1887/22750 (epoch 4.147), train_loss = 1.84779870, grad/param norm = 2.2163e-01, time/batch = 0.6804s	
1888/22750 (epoch 4.149), train_loss = 1.78159444, grad/param norm = 2.2082e-01, time/batch = 0.6800s	
1889/22750 (epoch 4.152), train_loss = 1.72713151, grad/param norm = 2.2613e-01, time/batch = 0.6800s	
1890/22750 (epoch 4.154), train_loss = 1.53253628, grad/param norm = 2.1546e-01, time/batch = 0.6770s	
1891/22750 (epoch 4.156), train_loss = 1.67518337, grad/param norm = 2.3245e-01, time/batch = 0.7072s	
1892/22750 (epoch 4.158), train_loss = 1.71416295, grad/param norm = 2.3429e-01, time/batch = 0.6859s	
1893/22750 (epoch 4.160), train_loss = 1.82650265, grad/param norm = 2.3399e-01, time/batch = 0.6848s	
1894/22750 (epoch 4.163), train_loss = 1.98548404, grad/param norm = 2.3559e-01, time/batch = 0.6782s	
1895/22750 (epoch 4.165), train_loss = 1.92534138, grad/param norm = 2.2564e-01, time/batch = 0.6772s	
1896/22750 (epoch 4.167), train_loss = 1.65754033, grad/param norm = 2.0578e-01, time/batch = 0.6825s	
1897/22750 (epoch 4.169), train_loss = 1.80142090, grad/param norm = 2.1555e-01, time/batch = 0.6777s	
1898/22750 (epoch 4.171), train_loss = 1.66998162, grad/param norm = 2.2569e-01, time/batch = 0.6822s	
1899/22750 (epoch 4.174), train_loss = 1.49235926, grad/param norm = 1.9779e-01, time/batch = 0.6897s	
1900/22750 (epoch 4.176), train_loss = 1.78773749, grad/param norm = 2.0603e-01, time/batch = 0.6848s	
1901/22750 (epoch 4.178), train_loss = 1.69364124, grad/param norm = 2.0085e-01, time/batch = 0.6849s	
1902/22750 (epoch 4.180), train_loss = 1.88884000, grad/param norm = 2.6407e-01, time/batch = 0.6881s	
1903/22750 (epoch 4.182), train_loss = 1.77790396, grad/param norm = 2.0354e-01, time/batch = 0.6945s	
1904/22750 (epoch 4.185), train_loss = 1.79588298, grad/param norm = 2.1719e-01, time/batch = 0.6840s	
1905/22750 (epoch 4.187), train_loss = 1.60974244, grad/param norm = 2.2889e-01, time/batch = 0.6895s	
1906/22750 (epoch 4.189), train_loss = 1.65580994, grad/param norm = 2.2634e-01, time/batch = 0.6785s	
1907/22750 (epoch 4.191), train_loss = 1.60375406, grad/param norm = 2.1728e-01, time/batch = 0.6815s	
1908/22750 (epoch 4.193), train_loss = 1.82805059, grad/param norm = 2.4502e-01, time/batch = 0.6806s	
1909/22750 (epoch 4.196), train_loss = 1.77320994, grad/param norm = 2.2430e-01, time/batch = 0.6800s	
1910/22750 (epoch 4.198), train_loss = 1.50252406, grad/param norm = 2.0029e-01, time/batch = 0.6816s	
1911/22750 (epoch 4.200), train_loss = 1.82368523, grad/param norm = 2.0589e-01, time/batch = 0.6810s	
1912/22750 (epoch 4.202), train_loss = 2.04792325, grad/param norm = 2.4916e-01, time/batch = 0.6815s	
1913/22750 (epoch 4.204), train_loss = 1.96131788, grad/param norm = 2.2779e-01, time/batch = 0.6874s	
1914/22750 (epoch 4.207), train_loss = 1.72577345, grad/param norm = 2.3313e-01, time/batch = 0.6861s	
1915/22750 (epoch 4.209), train_loss = 1.67233913, grad/param norm = 2.0890e-01, time/batch = 0.6877s	
1916/22750 (epoch 4.211), train_loss = 1.75423435, grad/param norm = 2.2086e-01, time/batch = 0.6951s	
1917/22750 (epoch 4.213), train_loss = 1.61871618, grad/param norm = 2.0823e-01, time/batch = 0.6844s	
1918/22750 (epoch 4.215), train_loss = 1.67929180, grad/param norm = 2.0974e-01, time/batch = 0.6813s	
1919/22750 (epoch 4.218), train_loss = 1.55535750, grad/param norm = 2.3493e-01, time/batch = 0.6806s	
1920/22750 (epoch 4.220), train_loss = 1.79557776, grad/param norm = 2.5838e-01, time/batch = 0.6850s	
1921/22750 (epoch 4.222), train_loss = 1.58723066, grad/param norm = 2.4031e-01, time/batch = 0.7166s	
1922/22750 (epoch 4.224), train_loss = 1.66836891, grad/param norm = 2.1768e-01, time/batch = 0.7120s	
1923/22750 (epoch 4.226), train_loss = 1.80109987, grad/param norm = 2.4268e-01, time/batch = 0.6837s	
1924/22750 (epoch 4.229), train_loss = 1.85496806, grad/param norm = 2.2511e-01, time/batch = 0.6817s	
1925/22750 (epoch 4.231), train_loss = 1.71465484, grad/param norm = 1.9953e-01, time/batch = 0.6804s	
1926/22750 (epoch 4.233), train_loss = 1.67269521, grad/param norm = 2.0583e-01, time/batch = 0.6826s	
1927/22750 (epoch 4.235), train_loss = 1.61608412, grad/param norm = 2.1606e-01, time/batch = 0.6919s	
1928/22750 (epoch 4.237), train_loss = 1.70851384, grad/param norm = 2.2124e-01, time/batch = 0.7109s	
1929/22750 (epoch 4.240), train_loss = 1.87950168, grad/param norm = 2.1156e-01, time/batch = 0.7034s	
1930/22750 (epoch 4.242), train_loss = 2.18451936, grad/param norm = 2.4422e-01, time/batch = 0.7214s	
1931/22750 (epoch 4.244), train_loss = 1.98129370, grad/param norm = 2.9436e-01, time/batch = 0.6910s	
1932/22750 (epoch 4.246), train_loss = 2.06108543, grad/param norm = 2.2085e-01, time/batch = 0.6935s	
1933/22750 (epoch 4.248), train_loss = 1.71988573, grad/param norm = 2.3271e-01, time/batch = 0.6835s	
1934/22750 (epoch 4.251), train_loss = 1.98583470, grad/param norm = 2.2660e-01, time/batch = 0.6844s	
1935/22750 (epoch 4.253), train_loss = 1.81719211, grad/param norm = 2.1218e-01, time/batch = 0.6856s	
1936/22750 (epoch 4.255), train_loss = 1.85947370, grad/param norm = 2.2502e-01, time/batch = 0.6802s	
1937/22750 (epoch 4.257), train_loss = 1.74763796, grad/param norm = 2.3137e-01, time/batch = 0.6829s	
1938/22750 (epoch 4.259), train_loss = 1.90407492, grad/param norm = 2.5568e-01, time/batch = 0.6789s	
1939/22750 (epoch 4.262), train_loss = 1.78601739, grad/param norm = 2.3665e-01, time/batch = 0.6830s	
1940/22750 (epoch 4.264), train_loss = 1.72367024, grad/param norm = 2.1793e-01, time/batch = 0.6792s	
1941/22750 (epoch 4.266), train_loss = 1.71469714, grad/param norm = 2.2779e-01, time/batch = 0.6784s	
1942/22750 (epoch 4.268), train_loss = 1.85188299, grad/param norm = 2.1099e-01, time/batch = 0.6800s	
1943/22750 (epoch 4.270), train_loss = 1.65121258, grad/param norm = 2.3862e-01, time/batch = 0.6804s	
1944/22750 (epoch 4.273), train_loss = 1.99270234, grad/param norm = 2.5968e-01, time/batch = 0.6778s	
1945/22750 (epoch 4.275), train_loss = 1.76505923, grad/param norm = 2.1987e-01, time/batch = 0.6831s	
1946/22750 (epoch 4.277), train_loss = 1.82828784, grad/param norm = 2.2987e-01, time/batch = 0.6852s	
1947/22750 (epoch 4.279), train_loss = 1.56545761, grad/param norm = 1.9403e-01, time/batch = 0.6822s	
1948/22750 (epoch 4.281), train_loss = 1.75196921, grad/param norm = 2.1806e-01, time/batch = 0.6792s	
1949/22750 (epoch 4.284), train_loss = 1.64422866, grad/param norm = 1.9586e-01, time/batch = 0.7037s	
1950/22750 (epoch 4.286), train_loss = 1.82519452, grad/param norm = 2.2176e-01, time/batch = 0.6970s	
1951/22750 (epoch 4.288), train_loss = 1.91289827, grad/param norm = 2.0986e-01, time/batch = 0.6921s	
1952/22750 (epoch 4.290), train_loss = 1.64132083, grad/param norm = 2.1110e-01, time/batch = 0.7148s	
1953/22750 (epoch 4.292), train_loss = 1.73827152, grad/param norm = 2.2558e-01, time/batch = 0.6910s	
1954/22750 (epoch 4.295), train_loss = 1.77294837, grad/param norm = 2.1273e-01, time/batch = 0.6817s	
1955/22750 (epoch 4.297), train_loss = 1.67881897, grad/param norm = 2.1232e-01, time/batch = 0.6814s	
1956/22750 (epoch 4.299), train_loss = 1.90213400, grad/param norm = 2.2574e-01, time/batch = 0.6838s	
1957/22750 (epoch 4.301), train_loss = 1.82328873, grad/param norm = 2.1015e-01, time/batch = 0.6840s	
1958/22750 (epoch 4.303), train_loss = 1.90725507, grad/param norm = 2.3324e-01, time/batch = 0.6813s	
1959/22750 (epoch 4.305), train_loss = 1.92341791, grad/param norm = 2.2719e-01, time/batch = 0.6778s	
1960/22750 (epoch 4.308), train_loss = 1.79096319, grad/param norm = 2.0374e-01, time/batch = 0.6812s	
1961/22750 (epoch 4.310), train_loss = 1.72958255, grad/param norm = 2.2739e-01, time/batch = 0.6827s	
1962/22750 (epoch 4.312), train_loss = 1.75869728, grad/param norm = 2.1327e-01, time/batch = 0.7108s	
1963/22750 (epoch 4.314), train_loss = 1.74283824, grad/param norm = 2.0864e-01, time/batch = 0.6936s	
1964/22750 (epoch 4.316), train_loss = 1.71414442, grad/param norm = 2.1674e-01, time/batch = 0.6787s	
1965/22750 (epoch 4.319), train_loss = 1.81520931, grad/param norm = 2.1026e-01, time/batch = 0.6777s	
1966/22750 (epoch 4.321), train_loss = 1.73717382, grad/param norm = 2.3660e-01, time/batch = 0.6827s	
1967/22750 (epoch 4.323), train_loss = 1.67167984, grad/param norm = 2.2767e-01, time/batch = 0.6752s	
1968/22750 (epoch 4.325), train_loss = 1.46169332, grad/param norm = 2.1201e-01, time/batch = 0.6785s	
1969/22750 (epoch 4.327), train_loss = 1.80112783, grad/param norm = 2.2339e-01, time/batch = 0.6782s	
1970/22750 (epoch 4.330), train_loss = 2.06264517, grad/param norm = 2.2920e-01, time/batch = 0.6835s	
1971/22750 (epoch 4.332), train_loss = 1.82295737, grad/param norm = 2.2112e-01, time/batch = 0.6889s	
1972/22750 (epoch 4.334), train_loss = 1.48507576, grad/param norm = 1.9640e-01, time/batch = 0.6892s	
1973/22750 (epoch 4.336), train_loss = 1.81668132, grad/param norm = 2.0742e-01, time/batch = 0.6897s	
1974/22750 (epoch 4.338), train_loss = 1.78037494, grad/param norm = 2.2410e-01, time/batch = 0.6881s	
1975/22750 (epoch 4.341), train_loss = 1.72387007, grad/param norm = 2.1297e-01, time/batch = 0.6977s	
1976/22750 (epoch 4.343), train_loss = 1.57099695, grad/param norm = 2.2306e-01, time/batch = 0.6895s	
1977/22750 (epoch 4.345), train_loss = 1.91613755, grad/param norm = 2.3808e-01, time/batch = 0.6819s	
1978/22750 (epoch 4.347), train_loss = 1.88862574, grad/param norm = 2.2821e-01, time/batch = 0.6968s	
1979/22750 (epoch 4.349), train_loss = 1.46052004, grad/param norm = 2.3416e-01, time/batch = 0.6891s	
1980/22750 (epoch 4.352), train_loss = 1.85339145, grad/param norm = 2.4987e-01, time/batch = 0.6806s	
1981/22750 (epoch 4.354), train_loss = 1.94286062, grad/param norm = 2.2550e-01, time/batch = 0.6882s	
1982/22750 (epoch 4.356), train_loss = 1.95560828, grad/param norm = 2.0944e-01, time/batch = 0.7033s	
1983/22750 (epoch 4.358), train_loss = 1.71436434, grad/param norm = 2.2659e-01, time/batch = 0.7047s	
1984/22750 (epoch 4.360), train_loss = 1.99797077, grad/param norm = 2.4100e-01, time/batch = 0.6860s	
1985/22750 (epoch 4.363), train_loss = 1.76293324, grad/param norm = 2.0723e-01, time/batch = 0.6845s	
1986/22750 (epoch 4.365), train_loss = 1.49064478, grad/param norm = 2.2954e-01, time/batch = 0.6840s	
1987/22750 (epoch 4.367), train_loss = 1.46253896, grad/param norm = 1.8656e-01, time/batch = 0.6823s	
1988/22750 (epoch 4.369), train_loss = 1.70852231, grad/param norm = 2.4368e-01, time/batch = 0.6810s	
1989/22750 (epoch 4.371), train_loss = 1.68496436, grad/param norm = 2.3509e-01, time/batch = 0.6848s	
1990/22750 (epoch 4.374), train_loss = 1.56975943, grad/param norm = 2.3459e-01, time/batch = 0.6847s	
1991/22750 (epoch 4.376), train_loss = 1.81588135, grad/param norm = 2.1770e-01, time/batch = 0.6853s	
1992/22750 (epoch 4.378), train_loss = 1.67331337, grad/param norm = 2.1294e-01, time/batch = 0.7009s	
1993/22750 (epoch 4.380), train_loss = 1.87851823, grad/param norm = 2.3561e-01, time/batch = 0.7083s	
1994/22750 (epoch 4.382), train_loss = 1.64188768, grad/param norm = 2.0798e-01, time/batch = 0.6811s	
1995/22750 (epoch 4.385), train_loss = 1.76807324, grad/param norm = 1.8920e-01, time/batch = 0.6831s	
1996/22750 (epoch 4.387), train_loss = 1.83966974, grad/param norm = 2.1304e-01, time/batch = 0.6787s	
1997/22750 (epoch 4.389), train_loss = 1.38602859, grad/param norm = 2.3881e-01, time/batch = 0.6797s	
1998/22750 (epoch 4.391), train_loss = 1.22456338, grad/param norm = 1.9998e-01, time/batch = 0.6802s	
1999/22750 (epoch 4.393), train_loss = 1.55861042, grad/param norm = 2.2199e-01, time/batch = 0.6817s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_wakata_epoch4.40_1.7480.t7	
2000/22750 (epoch 4.396), train_loss = 1.73519479, grad/param norm = 2.3567e-01, time/batch = 0.6885s	
2001/22750 (epoch 4.398), train_loss = 1.93869673, grad/param norm = 2.4878e-01, time/batch = 0.7049s	
2002/22750 (epoch 4.400), train_loss = 1.71371534, grad/param norm = 2.0652e-01, time/batch = 0.7004s	
2003/22750 (epoch 4.402), train_loss = 1.73339542, grad/param norm = 2.1079e-01, time/batch = 0.6930s	
2004/22750 (epoch 4.404), train_loss = 1.97241131, grad/param norm = 2.5001e-01, time/batch = 0.6810s	
2005/22750 (epoch 4.407), train_loss = 1.82931432, grad/param norm = 2.2093e-01, time/batch = 0.6919s	
2006/22750 (epoch 4.409), train_loss = 1.73739381, grad/param norm = 2.2698e-01, time/batch = 0.7064s	
2007/22750 (epoch 4.411), train_loss = 1.74601372, grad/param norm = 2.0740e-01, time/batch = 0.6934s	
2008/22750 (epoch 4.413), train_loss = 1.64875345, grad/param norm = 2.2727e-01, time/batch = 0.7199s	
2009/22750 (epoch 4.415), train_loss = 1.50468225, grad/param norm = 2.2880e-01, time/batch = 0.7122s	
2010/22750 (epoch 4.418), train_loss = 1.64874946, grad/param norm = 2.0893e-01, time/batch = 0.7294s	
2011/22750 (epoch 4.420), train_loss = 1.98181817, grad/param norm = 2.3683e-01, time/batch = 0.7135s	
2012/22750 (epoch 4.422), train_loss = 2.03583968, grad/param norm = 2.2861e-01, time/batch = 0.7006s	
2013/22750 (epoch 4.424), train_loss = 2.05369082, grad/param norm = 2.3730e-01, time/batch = 0.6925s	
2014/22750 (epoch 4.426), train_loss = 2.01929132, grad/param norm = 2.0627e-01, time/batch = 0.6950s	
2015/22750 (epoch 4.429), train_loss = 1.50067511, grad/param norm = 2.0249e-01, time/batch = 0.7059s	
2016/22750 (epoch 4.431), train_loss = 1.49304536, grad/param norm = 2.0253e-01, time/batch = 0.7235s	
2017/22750 (epoch 4.433), train_loss = 1.56944835, grad/param norm = 1.9526e-01, time/batch = 0.6984s	
2018/22750 (epoch 4.435), train_loss = 1.47715521, grad/param norm = 2.2032e-01, time/batch = 0.6934s	
2019/22750 (epoch 4.437), train_loss = 1.43032535, grad/param norm = 1.9706e-01, time/batch = 0.6969s	
2020/22750 (epoch 4.440), train_loss = 1.92411584, grad/param norm = 2.3921e-01, time/batch = 0.6990s	
2021/22750 (epoch 4.442), train_loss = 1.72635881, grad/param norm = 2.2001e-01, time/batch = 0.6972s	
2022/22750 (epoch 4.444), train_loss = 1.83053152, grad/param norm = 2.9709e-01, time/batch = 0.6944s	
2023/22750 (epoch 4.446), train_loss = 1.78138733, grad/param norm = 2.5162e-01, time/batch = 0.7104s	
2024/22750 (epoch 4.448), train_loss = 2.01130522, grad/param norm = 2.3245e-01, time/batch = 0.7047s	
2025/22750 (epoch 4.451), train_loss = 1.92624930, grad/param norm = 2.4036e-01, time/batch = 0.7026s	
2026/22750 (epoch 4.453), train_loss = 2.04009237, grad/param norm = 2.6281e-01, time/batch = 0.7152s	
2027/22750 (epoch 4.455), train_loss = 2.06168409, grad/param norm = 2.2134e-01, time/batch = 0.6985s	
2028/22750 (epoch 4.457), train_loss = 1.91702484, grad/param norm = 2.4381e-01, time/batch = 0.6961s	
2029/22750 (epoch 4.459), train_loss = 1.79090593, grad/param norm = 2.1277e-01, time/batch = 0.6935s	
2030/22750 (epoch 4.462), train_loss = 1.75104086, grad/param norm = 1.8852e-01, time/batch = 0.7028s	
2031/22750 (epoch 4.464), train_loss = 1.58868418, grad/param norm = 2.0480e-01, time/batch = 0.6974s	
2032/22750 (epoch 4.466), train_loss = 1.99681049, grad/param norm = 2.2666e-01, time/batch = 0.6966s	
2033/22750 (epoch 4.468), train_loss = 1.72356377, grad/param norm = 2.2703e-01, time/batch = 0.6981s	
2034/22750 (epoch 4.470), train_loss = 1.91441489, grad/param norm = 2.4180e-01, time/batch = 0.7031s	
2035/22750 (epoch 4.473), train_loss = 1.77472477, grad/param norm = 2.2292e-01, time/batch = 0.7114s	
2036/22750 (epoch 4.475), train_loss = 1.83704518, grad/param norm = 2.0880e-01, time/batch = 0.7222s	
2037/22750 (epoch 4.477), train_loss = 1.55098520, grad/param norm = 2.1245e-01, time/batch = 0.6978s	
2038/22750 (epoch 4.479), train_loss = 1.61077958, grad/param norm = 1.8928e-01, time/batch = 0.6956s	
2039/22750 (epoch 4.481), train_loss = 1.58381989, grad/param norm = 2.2527e-01, time/batch = 0.6935s	
2040/22750 (epoch 4.484), train_loss = 1.37983082, grad/param norm = 2.1863e-01, time/batch = 0.7027s	
2041/22750 (epoch 4.486), train_loss = 1.66869741, grad/param norm = 2.4850e-01, time/batch = 0.7023s	
2042/22750 (epoch 4.488), train_loss = 1.35830733, grad/param norm = 2.4353e-01, time/batch = 0.6966s	
2043/22750 (epoch 4.490), train_loss = 1.59319670, grad/param norm = 2.1863e-01, time/batch = 0.7011s	
2044/22750 (epoch 4.492), train_loss = 1.89400362, grad/param norm = 2.6437e-01, time/batch = 0.6919s	
2045/22750 (epoch 4.495), train_loss = 1.67441982, grad/param norm = 2.5200e-01, time/batch = 0.7117s	
2046/22750 (epoch 4.497), train_loss = 1.83269695, grad/param norm = 2.3207e-01, time/batch = 0.7210s	
2047/22750 (epoch 4.499), train_loss = 1.69931944, grad/param norm = 2.0779e-01, time/batch = 0.6988s	
2048/22750 (epoch 4.501), train_loss = 1.73945591, grad/param norm = 2.0729e-01, time/batch = 0.7004s	
2049/22750 (epoch 4.503), train_loss = 1.73768198, grad/param norm = 2.1560e-01, time/batch = 0.7018s	
2050/22750 (epoch 4.505), train_loss = 1.56443390, grad/param norm = 2.0152e-01, time/batch = 0.6978s	
2051/22750 (epoch 4.508), train_loss = 1.51955909, grad/param norm = 2.2715e-01, time/batch = 0.7046s	
2052/22750 (epoch 4.510), train_loss = 1.53516059, grad/param norm = 2.0781e-01, time/batch = 0.6973s	
2053/22750 (epoch 4.512), train_loss = 1.63610795, grad/param norm = 2.0415e-01, time/batch = 0.6967s	
2054/22750 (epoch 4.514), train_loss = 1.63323480, grad/param norm = 2.0360e-01, time/batch = 0.6964s	
2055/22750 (epoch 4.516), train_loss = 1.55337586, grad/param norm = 2.2905e-01, time/batch = 0.7105s	
2056/22750 (epoch 4.519), train_loss = 1.74116455, grad/param norm = 2.4029e-01, time/batch = 0.7176s	
2057/22750 (epoch 4.521), train_loss = 1.57491277, grad/param norm = 2.5229e-01, time/batch = 0.6974s	
2058/22750 (epoch 4.523), train_loss = 1.63446166, grad/param norm = 2.6119e-01, time/batch = 0.7025s	
2059/22750 (epoch 4.525), train_loss = 1.86294918, grad/param norm = 2.3746e-01, time/batch = 0.6973s	
2060/22750 (epoch 4.527), train_loss = 1.72416184, grad/param norm = 2.2558e-01, time/batch = 0.6953s	
2061/22750 (epoch 4.530), train_loss = 1.59049236, grad/param norm = 2.2054e-01, time/batch = 0.6972s	
2062/22750 (epoch 4.532), train_loss = 1.62519900, grad/param norm = 2.0557e-01, time/batch = 0.6994s	
2063/22750 (epoch 4.534), train_loss = 1.86493101, grad/param norm = 2.4441e-01, time/batch = 0.6987s	
2064/22750 (epoch 4.536), train_loss = 1.71445631, grad/param norm = 2.1619e-01, time/batch = 0.7004s	
2065/22750 (epoch 4.538), train_loss = 1.77618878, grad/param norm = 1.9463e-01, time/batch = 0.7109s	
2066/22750 (epoch 4.541), train_loss = 1.44492846, grad/param norm = 2.0301e-01, time/batch = 0.7345s	
2067/22750 (epoch 4.543), train_loss = 1.46467248, grad/param norm = 1.9967e-01, time/batch = 0.7086s	
2068/22750 (epoch 4.545), train_loss = 1.86578112, grad/param norm = 2.2010e-01, time/batch = 0.7034s	
2069/22750 (epoch 4.547), train_loss = 1.46916733, grad/param norm = 2.0127e-01, time/batch = 0.7008s	
2070/22750 (epoch 4.549), train_loss = 1.58464032, grad/param norm = 2.3763e-01, time/batch = 0.7124s	
2071/22750 (epoch 4.552), train_loss = 1.81598109, grad/param norm = 2.5044e-01, time/batch = 0.7030s	
2072/22750 (epoch 4.554), train_loss = 1.83677152, grad/param norm = 2.1055e-01, time/batch = 0.7043s	
2073/22750 (epoch 4.556), train_loss = 1.67701009, grad/param norm = 2.1622e-01, time/batch = 0.6992s	
2074/22750 (epoch 4.558), train_loss = 1.87261937, grad/param norm = 2.0831e-01, time/batch = 0.7008s	
2075/22750 (epoch 4.560), train_loss = 1.54238691, grad/param norm = 1.9561e-01, time/batch = 0.7214s	
2076/22750 (epoch 4.563), train_loss = 1.75283469, grad/param norm = 2.1624e-01, time/batch = 0.7154s	
2077/22750 (epoch 4.565), train_loss = 1.90098061, grad/param norm = 2.0087e-01, time/batch = 0.7016s	
2078/22750 (epoch 4.567), train_loss = 1.71231220, grad/param norm = 2.0831e-01, time/batch = 0.7027s	
2079/22750 (epoch 4.569), train_loss = 1.66051229, grad/param norm = 2.1834e-01, time/batch = 0.6999s	
2080/22750 (epoch 4.571), train_loss = 1.75396955, grad/param norm = 2.3327e-01, time/batch = 0.7051s	
2081/22750 (epoch 4.574), train_loss = 1.52936161, grad/param norm = 2.1987e-01, time/batch = 0.7065s	
2082/22750 (epoch 4.576), train_loss = 1.73992792, grad/param norm = 2.0491e-01, time/batch = 0.7029s	
2083/22750 (epoch 4.578), train_loss = 1.51292420, grad/param norm = 2.0801e-01, time/batch = 0.7031s	
2084/22750 (epoch 4.580), train_loss = 1.79048837, grad/param norm = 2.2059e-01, time/batch = 0.6993s	
2085/22750 (epoch 4.582), train_loss = 1.46881386, grad/param norm = 2.2241e-01, time/batch = 0.7257s	
2086/22750 (epoch 4.585), train_loss = 1.39746971, grad/param norm = 1.8918e-01, time/batch = 0.7217s	
2087/22750 (epoch 4.587), train_loss = 1.50501934, grad/param norm = 1.8659e-01, time/batch = 0.7021s	
2088/22750 (epoch 4.589), train_loss = 1.52433286, grad/param norm = 2.1903e-01, time/batch = 0.7048s	
2089/22750 (epoch 4.591), train_loss = 1.75735278, grad/param norm = 2.4608e-01, time/batch = 0.7021s	
2090/22750 (epoch 4.593), train_loss = 1.89824402, grad/param norm = 2.0603e-01, time/batch = 0.7198s	
2091/22750 (epoch 4.596), train_loss = 1.84733792, grad/param norm = 2.0229e-01, time/batch = 0.7006s	
2092/22750 (epoch 4.598), train_loss = 1.91222845, grad/param norm = 2.1680e-01, time/batch = 0.7201s	
2093/22750 (epoch 4.600), train_loss = 1.74432258, grad/param norm = 2.0696e-01, time/batch = 0.7326s	
2094/22750 (epoch 4.602), train_loss = 1.49432235, grad/param norm = 1.8497e-01, time/batch = 0.7400s	
2095/22750 (epoch 4.604), train_loss = 1.64256123, grad/param norm = 2.0801e-01, time/batch = 0.7308s	
2096/22750 (epoch 4.607), train_loss = 1.35045508, grad/param norm = 1.8712e-01, time/batch = 0.7217s	
2097/22750 (epoch 4.609), train_loss = 1.35233635, grad/param norm = 1.8486e-01, time/batch = 0.7164s	
2098/22750 (epoch 4.611), train_loss = 1.60186229, grad/param norm = 2.1951e-01, time/batch = 0.7320s	
2099/22750 (epoch 4.613), train_loss = 1.53888882, grad/param norm = 2.2436e-01, time/batch = 0.7323s	
2100/22750 (epoch 4.615), train_loss = 1.63075422, grad/param norm = 2.2201e-01, time/batch = 0.7005s	
2101/22750 (epoch 4.618), train_loss = 1.69820072, grad/param norm = 2.3894e-01, time/batch = 0.7149s	
2102/22750 (epoch 4.620), train_loss = 1.65119613, grad/param norm = 2.1135e-01, time/batch = 0.7077s	
2103/22750 (epoch 4.622), train_loss = 1.49713965, grad/param norm = 2.4162e-01, time/batch = 0.6988s	
2104/22750 (epoch 4.624), train_loss = 1.83618572, grad/param norm = 2.4267e-01, time/batch = 0.7161s	
2105/22750 (epoch 4.626), train_loss = 1.61621514, grad/param norm = 2.6083e-01, time/batch = 0.7251s	
2106/22750 (epoch 4.629), train_loss = 1.72362090, grad/param norm = 2.4020e-01, time/batch = 0.7075s	
2107/22750 (epoch 4.631), train_loss = 1.76195821, grad/param norm = 2.2388e-01, time/batch = 0.7066s	
2108/22750 (epoch 4.633), train_loss = 1.43619550, grad/param norm = 2.2143e-01, time/batch = 0.7018s	
2109/22750 (epoch 4.635), train_loss = 1.80962497, grad/param norm = 2.1613e-01, time/batch = 0.7052s	
2110/22750 (epoch 4.637), train_loss = 1.79247008, grad/param norm = 2.2480e-01, time/batch = 0.7062s	
2111/22750 (epoch 4.640), train_loss = 1.91014833, grad/param norm = 2.4239e-01, time/batch = 0.7067s	
2112/22750 (epoch 4.642), train_loss = 1.83893000, grad/param norm = 2.4298e-01, time/batch = 0.6965s	
2113/22750 (epoch 4.644), train_loss = 1.69986009, grad/param norm = 2.1645e-01, time/batch = 0.7026s	
2114/22750 (epoch 4.646), train_loss = 1.81382506, grad/param norm = 2.4851e-01, time/batch = 0.7175s	
2115/22750 (epoch 4.648), train_loss = 1.75116095, grad/param norm = 2.4566e-01, time/batch = 0.7223s	
2116/22750 (epoch 4.651), train_loss = 1.87913371, grad/param norm = 2.3351e-01, time/batch = 0.6963s	
2117/22750 (epoch 4.653), train_loss = 1.70007699, grad/param norm = 2.0840e-01, time/batch = 0.6980s	
2118/22750 (epoch 4.655), train_loss = 1.68806164, grad/param norm = 2.1394e-01, time/batch = 0.6993s	
2119/22750 (epoch 4.657), train_loss = 1.90813026, grad/param norm = 1.9955e-01, time/batch = 0.7017s	
2120/22750 (epoch 4.659), train_loss = 1.94639194, grad/param norm = 2.1678e-01, time/batch = 0.7002s	
2121/22750 (epoch 4.662), train_loss = 2.02936764, grad/param norm = 2.2681e-01, time/batch = 0.7083s	
2122/22750 (epoch 4.664), train_loss = 1.78496963, grad/param norm = 2.3698e-01, time/batch = 0.7031s	
2123/22750 (epoch 4.666), train_loss = 1.58404913, grad/param norm = 2.1996e-01, time/batch = 0.7016s	
2124/22750 (epoch 4.668), train_loss = 1.74476185, grad/param norm = 2.0943e-01, time/batch = 0.7220s	
2125/22750 (epoch 4.670), train_loss = 1.74584704, grad/param norm = 2.0931e-01, time/batch = 0.7208s	
2126/22750 (epoch 4.673), train_loss = 1.91486259, grad/param norm = 2.6213e-01, time/batch = 0.7035s	
2127/22750 (epoch 4.675), train_loss = 2.20822713, grad/param norm = 2.7705e-01, time/batch = 0.7073s	
2128/22750 (epoch 4.677), train_loss = 1.95891878, grad/param norm = 2.4120e-01, time/batch = 0.7056s	
2129/22750 (epoch 4.679), train_loss = 2.01778671, grad/param norm = 2.1968e-01, time/batch = 0.6983s	
2130/22750 (epoch 4.681), train_loss = 1.86914851, grad/param norm = 2.2665e-01, time/batch = 0.6974s	
2131/22750 (epoch 4.684), train_loss = 1.87521662, grad/param norm = 2.1925e-01, time/batch = 0.6951s	
2132/22750 (epoch 4.686), train_loss = 1.84980395, grad/param norm = 2.3339e-01, time/batch = 0.6976s	
2133/22750 (epoch 4.688), train_loss = 1.84005745, grad/param norm = 2.2069e-01, time/batch = 0.6970s	
2134/22750 (epoch 4.690), train_loss = 1.78558238, grad/param norm = 2.1798e-01, time/batch = 0.7013s	
2135/22750 (epoch 4.692), train_loss = 1.95622180, grad/param norm = 2.2581e-01, time/batch = 0.6942s	
2136/22750 (epoch 4.695), train_loss = 1.73284551, grad/param norm = 2.2407e-01, time/batch = 0.6945s	
2137/22750 (epoch 4.697), train_loss = 1.65590811, grad/param norm = 2.5036e-01, time/batch = 0.6934s	
2138/22750 (epoch 4.699), train_loss = 1.77718847, grad/param norm = 2.1531e-01, time/batch = 0.6928s	
2139/22750 (epoch 4.701), train_loss = 1.62256368, grad/param norm = 2.1035e-01, time/batch = 0.6938s	
2140/22750 (epoch 4.703), train_loss = 1.76008884, grad/param norm = 2.0710e-01, time/batch = 0.6927s	
2141/22750 (epoch 4.705), train_loss = 1.56049257, grad/param norm = 1.9008e-01, time/batch = 0.6923s	
2142/22750 (epoch 4.708), train_loss = 1.73635377, grad/param norm = 1.8821e-01, time/batch = 0.6995s	
2143/22750 (epoch 4.710), train_loss = 1.49306877, grad/param norm = 2.2161e-01, time/batch = 0.7051s	
2144/22750 (epoch 4.712), train_loss = 1.57805814, grad/param norm = 2.0772e-01, time/batch = 0.7001s	
2145/22750 (epoch 4.714), train_loss = 1.48505349, grad/param norm = 2.1972e-01, time/batch = 0.6979s	
2146/22750 (epoch 4.716), train_loss = 1.62645846, grad/param norm = 2.2851e-01, time/batch = 0.7103s	
2147/22750 (epoch 4.719), train_loss = 1.86981747, grad/param norm = 2.7998e-01, time/batch = 0.7103s	
2148/22750 (epoch 4.721), train_loss = 1.77792156, grad/param norm = 2.3167e-01, time/batch = 0.6918s	
2149/22750 (epoch 4.723), train_loss = 1.66286898, grad/param norm = 2.0104e-01, time/batch = 0.6921s	
2150/22750 (epoch 4.725), train_loss = 1.68732951, grad/param norm = 2.4170e-01, time/batch = 0.6916s	
2151/22750 (epoch 4.727), train_loss = 1.60153315, grad/param norm = 1.9779e-01, time/batch = 0.6962s	
2152/22750 (epoch 4.730), train_loss = 1.63162515, grad/param norm = 2.0017e-01, time/batch = 0.6890s	
2153/22750 (epoch 4.732), train_loss = 1.71154970, grad/param norm = 2.0565e-01, time/batch = 0.6935s	
2154/22750 (epoch 4.734), train_loss = 1.32836903, grad/param norm = 2.2500e-01, time/batch = 0.7186s	
2155/22750 (epoch 4.736), train_loss = 1.60795491, grad/param norm = 2.1584e-01, time/batch = 0.7226s	
2156/22750 (epoch 4.738), train_loss = 1.63630435, grad/param norm = 2.2545e-01, time/batch = 0.7008s	
2157/22750 (epoch 4.741), train_loss = 1.80843463, grad/param norm = 2.0181e-01, time/batch = 0.6994s	
2158/22750 (epoch 4.743), train_loss = 1.78711206, grad/param norm = 2.3068e-01, time/batch = 0.6998s	
2159/22750 (epoch 4.745), train_loss = 1.48010724, grad/param norm = 1.9795e-01, time/batch = 0.7003s	
2160/22750 (epoch 4.747), train_loss = 1.61872686, grad/param norm = 2.1591e-01, time/batch = 0.7035s	
2161/22750 (epoch 4.749), train_loss = 1.88255022, grad/param norm = 2.3307e-01, time/batch = 0.6957s	
2162/22750 (epoch 4.752), train_loss = 1.59510569, grad/param norm = 2.1165e-01, time/batch = 0.6955s	
2163/22750 (epoch 4.754), train_loss = 1.83736018, grad/param norm = 2.5689e-01, time/batch = 0.7157s	
2164/22750 (epoch 4.756), train_loss = 1.49890099, grad/param norm = 2.5668e-01, time/batch = 0.7193s	
2165/22750 (epoch 4.758), train_loss = 1.43487983, grad/param norm = 2.1127e-01, time/batch = 0.6931s	
2166/22750 (epoch 4.760), train_loss = 1.74483946, grad/param norm = 2.1434e-01, time/batch = 0.6893s	
2167/22750 (epoch 4.763), train_loss = 1.72810673, grad/param norm = 2.1011e-01, time/batch = 0.6924s	
2168/22750 (epoch 4.765), train_loss = 1.59021341, grad/param norm = 2.2806e-01, time/batch = 0.6933s	
2169/22750 (epoch 4.767), train_loss = 1.62779165, grad/param norm = 2.1799e-01, time/batch = 0.6934s	
2170/22750 (epoch 4.769), train_loss = 1.81905446, grad/param norm = 2.3890e-01, time/batch = 0.6972s	
2171/22750 (epoch 4.771), train_loss = 1.82211566, grad/param norm = 2.4183e-01, time/batch = 0.7036s	
2172/22750 (epoch 4.774), train_loss = 1.62489413, grad/param norm = 2.2470e-01, time/batch = 0.7011s	
2173/22750 (epoch 4.776), train_loss = 1.69413364, grad/param norm = 2.2101e-01, time/batch = 0.6949s	
2174/22750 (epoch 4.778), train_loss = 1.87411846, grad/param norm = 2.0095e-01, time/batch = 0.7241s	
2175/22750 (epoch 4.780), train_loss = 1.74724119, grad/param norm = 2.4061e-01, time/batch = 0.7086s	
2176/22750 (epoch 4.782), train_loss = 1.82153522, grad/param norm = 2.2711e-01, time/batch = 0.6960s	
2177/22750 (epoch 4.785), train_loss = 1.74373911, grad/param norm = 2.0719e-01, time/batch = 0.7172s	
2178/22750 (epoch 4.787), train_loss = 1.59955499, grad/param norm = 2.1147e-01, time/batch = 0.7261s	
2179/22750 (epoch 4.789), train_loss = 1.60003909, grad/param norm = 1.9806e-01, time/batch = 0.7192s	
2180/22750 (epoch 4.791), train_loss = 1.65602596, grad/param norm = 1.8160e-01, time/batch = 0.6979s	
2181/22750 (epoch 4.793), train_loss = 1.65780159, grad/param norm = 2.2158e-01, time/batch = 0.6959s	
2182/22750 (epoch 4.796), train_loss = 1.57786753, grad/param norm = 2.0823e-01, time/batch = 0.6969s	
2183/22750 (epoch 4.798), train_loss = 1.57690401, grad/param norm = 1.9119e-01, time/batch = 0.7024s	
2184/22750 (epoch 4.800), train_loss = 1.54635857, grad/param norm = 2.0310e-01, time/batch = 0.7261s	
2185/22750 (epoch 4.802), train_loss = 1.69084792, grad/param norm = 2.1613e-01, time/batch = 0.6999s	
2186/22750 (epoch 4.804), train_loss = 1.95067922, grad/param norm = 2.0285e-01, time/batch = 0.7114s	
2187/22750 (epoch 4.807), train_loss = 1.69815962, grad/param norm = 2.0488e-01, time/batch = 0.7176s	
2188/22750 (epoch 4.809), train_loss = 1.94102654, grad/param norm = 2.3051e-01, time/batch = 0.7024s	
2189/22750 (epoch 4.811), train_loss = 1.63300125, grad/param norm = 1.9541e-01, time/batch = 0.6913s	
2190/22750 (epoch 4.813), train_loss = 1.78001214, grad/param norm = 2.1250e-01, time/batch = 0.6909s	
2191/22750 (epoch 4.815), train_loss = 1.89274253, grad/param norm = 2.4014e-01, time/batch = 0.7012s	
2192/22750 (epoch 4.818), train_loss = 1.85966857, grad/param norm = 2.0837e-01, time/batch = 0.7245s	
2193/22750 (epoch 4.820), train_loss = 1.95528688, grad/param norm = 2.0154e-01, time/batch = 0.7178s	
2194/22750 (epoch 4.822), train_loss = 1.75460651, grad/param norm = 2.0305e-01, time/batch = 0.7269s	
2195/22750 (epoch 4.824), train_loss = 1.75269023, grad/param norm = 2.0342e-01, time/batch = 0.7169s	
2196/22750 (epoch 4.826), train_loss = 1.71475302, grad/param norm = 2.0385e-01, time/batch = 0.7112s	
2197/22750 (epoch 4.829), train_loss = 1.88944847, grad/param norm = 2.4678e-01, time/batch = 0.6985s	
2198/22750 (epoch 4.831), train_loss = 1.87318187, grad/param norm = 2.7693e-01, time/batch = 0.6978s	
2199/22750 (epoch 4.833), train_loss = 1.86693050, grad/param norm = 2.2913e-01, time/batch = 0.7024s	
2200/22750 (epoch 4.835), train_loss = 1.66884394, grad/param norm = 2.0997e-01, time/batch = 0.6964s	
2201/22750 (epoch 4.837), train_loss = 1.67606387, grad/param norm = 2.1545e-01, time/batch = 0.7167s	
2202/22750 (epoch 4.840), train_loss = 1.71369704, grad/param norm = 2.1855e-01, time/batch = 0.7249s	
2203/22750 (epoch 4.842), train_loss = 1.62277747, grad/param norm = 2.0594e-01, time/batch = 0.7242s	
2204/22750 (epoch 4.844), train_loss = 1.93359470, grad/param norm = 2.2968e-01, time/batch = 0.7227s	
2205/22750 (epoch 4.846), train_loss = 1.65215290, grad/param norm = 2.0272e-01, time/batch = 0.7193s	
2206/22750 (epoch 4.848), train_loss = 1.53050055, grad/param norm = 2.1441e-01, time/batch = 0.7121s	
2207/22750 (epoch 4.851), train_loss = 1.58308316, grad/param norm = 2.1300e-01, time/batch = 0.6904s	
2208/22750 (epoch 4.853), train_loss = 1.66190808, grad/param norm = 2.1729e-01, time/batch = 0.6938s	
2209/22750 (epoch 4.855), train_loss = 1.47434508, grad/param norm = 1.9654e-01, time/batch = 0.6904s	
2210/22750 (epoch 4.857), train_loss = 1.68327349, grad/param norm = 1.9590e-01, time/batch = 0.6924s	
2211/22750 (epoch 4.859), train_loss = 1.72368162, grad/param norm = 2.2668e-01, time/batch = 0.6958s	
2212/22750 (epoch 4.862), train_loss = 1.86915857, grad/param norm = 2.3404e-01, time/batch = 0.6940s	
2213/22750 (epoch 4.864), train_loss = 1.70448408, grad/param norm = 2.0342e-01, time/batch = 0.7139s	
2214/22750 (epoch 4.866), train_loss = 1.71247676, grad/param norm = 1.9612e-01, time/batch = 0.7222s	
2215/22750 (epoch 4.868), train_loss = 1.70745734, grad/param norm = 2.0355e-01, time/batch = 0.6935s	
2216/22750 (epoch 4.870), train_loss = 1.48487587, grad/param norm = 2.0945e-01, time/batch = 0.6931s	
2217/22750 (epoch 4.873), train_loss = 1.65224906, grad/param norm = 2.0178e-01, time/batch = 0.6997s	
2218/22750 (epoch 4.875), train_loss = 1.73870503, grad/param norm = 2.0855e-01, time/batch = 0.6925s	
2219/22750 (epoch 4.877), train_loss = 1.55862857, grad/param norm = 1.9639e-01, time/batch = 0.7007s	
2220/22750 (epoch 4.879), train_loss = 1.81519566, grad/param norm = 2.2211e-01, time/batch = 0.6934s	
2221/22750 (epoch 4.881), train_loss = 1.79207369, grad/param norm = 2.1802e-01, time/batch = 0.7019s	
2222/22750 (epoch 4.884), train_loss = 1.63458280, grad/param norm = 2.4661e-01, time/batch = 0.7051s	
2223/22750 (epoch 4.886), train_loss = 1.78446286, grad/param norm = 2.1061e-01, time/batch = 0.7012s	
2224/22750 (epoch 4.888), train_loss = 1.75171453, grad/param norm = 2.0329e-01, time/batch = 0.6988s	
2225/22750 (epoch 4.890), train_loss = 1.76304508, grad/param norm = 2.2249e-01, time/batch = 0.6995s	
2226/22750 (epoch 4.892), train_loss = 2.16226091, grad/param norm = 2.7367e-01, time/batch = 0.7022s	
2227/22750 (epoch 4.895), train_loss = 1.80033375, grad/param norm = 2.1290e-01, time/batch = 0.7174s	
2228/22750 (epoch 4.897), train_loss = 1.80891457, grad/param norm = 2.2673e-01, time/batch = 0.7100s	
2229/22750 (epoch 4.899), train_loss = 1.75961728, grad/param norm = 2.0511e-01, time/batch = 0.6958s	
2230/22750 (epoch 4.901), train_loss = 1.90243366, grad/param norm = 2.0799e-01, time/batch = 0.6912s	
2231/22750 (epoch 4.903), train_loss = 1.69181611, grad/param norm = 2.0494e-01, time/batch = 0.6953s	
2232/22750 (epoch 4.905), train_loss = 1.72594943, grad/param norm = 1.8907e-01, time/batch = 0.7006s	
2233/22750 (epoch 4.908), train_loss = 1.70440866, grad/param norm = 2.1897e-01, time/batch = 0.7000s	
2234/22750 (epoch 4.910), train_loss = 1.51896922, grad/param norm = 2.3184e-01, time/batch = 0.7078s	
2235/22750 (epoch 4.912), train_loss = 1.53884627, grad/param norm = 2.2108e-01, time/batch = 0.7042s	
2236/22750 (epoch 4.914), train_loss = 1.62148881, grad/param norm = 1.9953e-01, time/batch = 0.7006s	
2237/22750 (epoch 4.916), train_loss = 1.46223824, grad/param norm = 1.9436e-01, time/batch = 0.6972s	
2238/22750 (epoch 4.919), train_loss = 1.59238468, grad/param norm = 2.1553e-01, time/batch = 0.7030s	
2239/22750 (epoch 4.921), train_loss = 1.29007845, grad/param norm = 1.8899e-01, time/batch = 0.6994s	
2240/22750 (epoch 4.923), train_loss = 1.64711959, grad/param norm = 2.1060e-01, time/batch = 0.7000s	
2241/22750 (epoch 4.925), train_loss = 1.64281423, grad/param norm = 2.0838e-01, time/batch = 0.6936s	
2242/22750 (epoch 4.927), train_loss = 1.43072533, grad/param norm = 1.9741e-01, time/batch = 0.7005s	
2243/22750 (epoch 4.930), train_loss = 1.49805565, grad/param norm = 2.0671e-01, time/batch = 0.6958s	
2244/22750 (epoch 4.932), train_loss = 1.83415989, grad/param norm = 2.2457e-01, time/batch = 0.6946s	
2245/22750 (epoch 4.934), train_loss = 1.31416540, grad/param norm = 1.8719e-01, time/batch = 0.6994s	
2246/22750 (epoch 4.936), train_loss = 1.82523968, grad/param norm = 2.3665e-01, time/batch = 0.6982s	
2247/22750 (epoch 4.938), train_loss = 1.69958790, grad/param norm = 2.1731e-01, time/batch = 0.7023s	
2248/22750 (epoch 4.941), train_loss = 2.01850384, grad/param norm = 2.2590e-01, time/batch = 0.7008s	
2249/22750 (epoch 4.943), train_loss = 1.78221403, grad/param norm = 2.1003e-01, time/batch = 0.7071s	
2250/22750 (epoch 4.945), train_loss = 1.70372502, grad/param norm = 2.0550e-01, time/batch = 0.7000s	
2251/22750 (epoch 4.947), train_loss = 1.71524282, grad/param norm = 2.2485e-01, time/batch = 0.6997s	
2252/22750 (epoch 4.949), train_loss = 1.55568770, grad/param norm = 2.2165e-01, time/batch = 0.7021s	
2253/22750 (epoch 4.952), train_loss = 1.57731705, grad/param norm = 2.0314e-01, time/batch = 0.7187s	
2254/22750 (epoch 4.954), train_loss = 1.57527426, grad/param norm = 1.9795e-01, time/batch = 0.7153s	
2255/22750 (epoch 4.956), train_loss = 1.69638732, grad/param norm = 2.1036e-01, time/batch = 0.6962s	
2256/22750 (epoch 4.958), train_loss = 1.64117184, grad/param norm = 2.0299e-01, time/batch = 0.6966s	
2257/22750 (epoch 4.960), train_loss = 1.66627436, grad/param norm = 2.0614e-01, time/batch = 0.7102s	
2258/22750 (epoch 4.963), train_loss = 1.82815757, grad/param norm = 2.2285e-01, time/batch = 0.6985s	
2259/22750 (epoch 4.965), train_loss = 1.76652015, grad/param norm = 2.2441e-01, time/batch = 0.7009s	
2260/22750 (epoch 4.967), train_loss = 1.71669037, grad/param norm = 2.1958e-01, time/batch = 0.7020s	
2261/22750 (epoch 4.969), train_loss = 1.65445683, grad/param norm = 2.0788e-01, time/batch = 0.7005s	
2262/22750 (epoch 4.971), train_loss = 1.63531570, grad/param norm = 2.0225e-01, time/batch = 0.7229s	
2263/22750 (epoch 4.974), train_loss = 1.71398422, grad/param norm = 2.3928e-01, time/batch = 0.7271s	
2264/22750 (epoch 4.976), train_loss = 1.80679697, grad/param norm = 2.1560e-01, time/batch = 0.7129s	
2265/22750 (epoch 4.978), train_loss = 1.57074348, grad/param norm = 2.1078e-01, time/batch = 0.7066s	
2266/22750 (epoch 4.980), train_loss = 1.81070572, grad/param norm = 2.4109e-01, time/batch = 0.7009s	
2267/22750 (epoch 4.982), train_loss = 1.61197677, grad/param norm = 2.0000e-01, time/batch = 0.7025s	
2268/22750 (epoch 4.985), train_loss = 1.93208283, grad/param norm = 2.4461e-01, time/batch = 0.7028s	
2269/22750 (epoch 4.987), train_loss = 1.49458674, grad/param norm = 2.0859e-01, time/batch = 0.6979s	
2270/22750 (epoch 4.989), train_loss = 1.56972409, grad/param norm = 1.8111e-01, time/batch = 0.6979s	
2271/22750 (epoch 4.991), train_loss = 1.77217064, grad/param norm = 2.1383e-01, time/batch = 0.7040s	
2272/22750 (epoch 4.993), train_loss = 1.77016724, grad/param norm = 2.2665e-01, time/batch = 0.7005s	
2273/22750 (epoch 4.996), train_loss = 1.64370855, grad/param norm = 2.2728e-01, time/batch = 0.7260s	
2274/22750 (epoch 4.998), train_loss = 1.83886212, grad/param norm = 2.1155e-01, time/batch = 0.7047s	
2275/22750 (epoch 5.000), train_loss = 1.77036153, grad/param norm = 2.1700e-01, time/batch = 0.7221s	
2276/22750 (epoch 5.002), train_loss = 1.85499625, grad/param norm = 2.2999e-01, time/batch = 0.7197s	
2277/22750 (epoch 5.004), train_loss = 1.65843709, grad/param norm = 2.7038e-01, time/batch = 0.7237s	
2278/22750 (epoch 5.007), train_loss = 1.77333209, grad/param norm = 2.2972e-01, time/batch = 0.7066s	
2279/22750 (epoch 5.009), train_loss = 1.97286165, grad/param norm = 2.1981e-01, time/batch = 0.6998s	
2280/22750 (epoch 5.011), train_loss = 1.89872091, grad/param norm = 2.2046e-01, time/batch = 0.6976s	
2281/22750 (epoch 5.013), train_loss = 1.76148635, grad/param norm = 2.1465e-01, time/batch = 0.7140s	
2282/22750 (epoch 5.015), train_loss = 1.77856134, grad/param norm = 2.1629e-01, time/batch = 0.7028s	
2283/22750 (epoch 5.018), train_loss = 1.78603992, grad/param norm = 2.2258e-01, time/batch = 0.7024s	
2284/22750 (epoch 5.020), train_loss = 1.83682969, grad/param norm = 2.0607e-01, time/batch = 0.6969s	
2285/22750 (epoch 5.022), train_loss = 1.70358743, grad/param norm = 1.9806e-01, time/batch = 0.6997s	
2286/22750 (epoch 5.024), train_loss = 1.68153204, grad/param norm = 2.1068e-01, time/batch = 0.7043s	
2287/22750 (epoch 5.026), train_loss = 1.87858881, grad/param norm = 2.2735e-01, time/batch = 0.6981s	
2288/22750 (epoch 5.029), train_loss = 1.45627695, grad/param norm = 1.9942e-01, time/batch = 0.6917s	
2289/22750 (epoch 5.031), train_loss = 1.97513987, grad/param norm = 2.1884e-01, time/batch = 0.6962s	
2290/22750 (epoch 5.033), train_loss = 1.71449602, grad/param norm = 1.9421e-01, time/batch = 0.7031s	
2291/22750 (epoch 5.035), train_loss = 1.77787589, grad/param norm = 2.1250e-01, time/batch = 0.7081s	
2292/22750 (epoch 5.037), train_loss = 1.87135690, grad/param norm = 2.2304e-01, time/batch = 0.7067s	
2293/22750 (epoch 5.040), train_loss = 1.61934402, grad/param norm = 2.3180e-01, time/batch = 0.7071s	
2294/22750 (epoch 5.042), train_loss = 1.79656532, grad/param norm = 2.1705e-01, time/batch = 0.7105s	
2295/22750 (epoch 5.044), train_loss = 1.60842965, grad/param norm = 2.2008e-01, time/batch = 0.7090s	
2296/22750 (epoch 5.046), train_loss = 1.75492836, grad/param norm = 2.4120e-01, time/batch = 0.6966s	
2297/22750 (epoch 5.048), train_loss = 1.69853175, grad/param norm = 2.3357e-01, time/batch = 0.7028s	
2298/22750 (epoch 5.051), train_loss = 1.75063544, grad/param norm = 2.2519e-01, time/batch = 0.6931s	
2299/22750 (epoch 5.053), train_loss = 1.49391786, grad/param norm = 2.0605e-01, time/batch = 0.6994s	
2300/22750 (epoch 5.055), train_loss = 1.71827522, grad/param norm = 2.2100e-01, time/batch = 0.6991s	
2301/22750 (epoch 5.057), train_loss = 1.78704868, grad/param norm = 2.2417e-01, time/batch = 0.6983s	
2302/22750 (epoch 5.059), train_loss = 1.35986413, grad/param norm = 2.1401e-01, time/batch = 0.6958s	
2303/22750 (epoch 5.062), train_loss = 1.49702845, grad/param norm = 1.9711e-01, time/batch = 0.7007s	
2304/22750 (epoch 5.064), train_loss = 1.77769760, grad/param norm = 2.3960e-01, time/batch = 0.7010s	
2305/22750 (epoch 5.066), train_loss = 1.47218922, grad/param norm = 1.8568e-01, time/batch = 0.6984s	
2306/22750 (epoch 5.068), train_loss = 1.51765387, grad/param norm = 2.0036e-01, time/batch = 0.7026s	
2307/22750 (epoch 5.070), train_loss = 1.42703066, grad/param norm = 1.9182e-01, time/batch = 0.6982s	
2308/22750 (epoch 5.073), train_loss = 1.58365336, grad/param norm = 2.1288e-01, time/batch = 0.6961s	
2309/22750 (epoch 5.075), train_loss = 1.67752727, grad/param norm = 2.1137e-01, time/batch = 0.6974s	
2310/22750 (epoch 5.077), train_loss = 1.31585815, grad/param norm = 2.1074e-01, time/batch = 0.6953s	
2311/22750 (epoch 5.079), train_loss = 1.62708905, grad/param norm = 2.1346e-01, time/batch = 0.7066s	
2312/22750 (epoch 5.081), train_loss = 1.67151750, grad/param norm = 2.1331e-01, time/batch = 0.7043s	
2313/22750 (epoch 5.084), train_loss = 1.55984841, grad/param norm = 2.0814e-01, time/batch = 0.6957s	
2314/22750 (epoch 5.086), train_loss = 1.56317590, grad/param norm = 1.9979e-01, time/batch = 0.7047s	
2315/22750 (epoch 5.088), train_loss = 1.60944407, grad/param norm = 2.0352e-01, time/batch = 0.7083s	
2316/22750 (epoch 5.090), train_loss = 1.61811949, grad/param norm = 2.0289e-01, time/batch = 0.7120s	
2317/22750 (epoch 5.092), train_loss = 1.78748317, grad/param norm = 2.1030e-01, time/batch = 0.7162s	
2318/22750 (epoch 5.095), train_loss = 1.52182251, grad/param norm = 2.0727e-01, time/batch = 0.7136s	
2319/22750 (epoch 5.097), train_loss = 1.59833978, grad/param norm = 2.0473e-01, time/batch = 0.7117s	
2320/22750 (epoch 5.099), train_loss = 1.70620783, grad/param norm = 2.2234e-01, time/batch = 0.7148s	
2321/22750 (epoch 5.101), train_loss = 1.64166969, grad/param norm = 2.0606e-01, time/batch = 0.7091s	
2322/22750 (epoch 5.103), train_loss = 1.60997377, grad/param norm = 2.1910e-01, time/batch = 0.7063s	
2323/22750 (epoch 5.105), train_loss = 1.95391728, grad/param norm = 2.4607e-01, time/batch = 0.7247s	
2324/22750 (epoch 5.108), train_loss = 1.60819831, grad/param norm = 2.0640e-01, time/batch = 0.7246s	
2325/22750 (epoch 5.110), train_loss = 1.68624974, grad/param norm = 2.1922e-01, time/batch = 0.7223s	
2326/22750 (epoch 5.112), train_loss = 1.37544825, grad/param norm = 1.9593e-01, time/batch = 0.7203s	
2327/22750 (epoch 5.114), train_loss = 1.37129260, grad/param norm = 1.9921e-01, time/batch = 0.7499s	
2328/22750 (epoch 5.116), train_loss = 1.47124058, grad/param norm = 1.9928e-01, time/batch = 0.7263s	
2329/22750 (epoch 5.119), train_loss = 1.54657986, grad/param norm = 2.0116e-01, time/batch = 0.7408s	
2330/22750 (epoch 5.121), train_loss = 1.78655355, grad/param norm = 2.2938e-01, time/batch = 0.7276s	
2331/22750 (epoch 5.123), train_loss = 1.57374976, grad/param norm = 1.8644e-01, time/batch = 0.7184s	
2332/22750 (epoch 5.125), train_loss = 1.84180354, grad/param norm = 2.0712e-01, time/batch = 0.7043s	
2333/22750 (epoch 5.127), train_loss = 1.74923744, grad/param norm = 2.3390e-01, time/batch = 0.7284s	
2334/22750 (epoch 5.130), train_loss = 1.71200005, grad/param norm = 2.0589e-01, time/batch = 0.7546s	
2335/22750 (epoch 5.132), train_loss = 1.79298437, grad/param norm = 2.3945e-01, time/batch = 0.7231s	
2336/22750 (epoch 5.134), train_loss = 1.61139534, grad/param norm = 2.1088e-01, time/batch = 0.7421s	
2337/22750 (epoch 5.136), train_loss = 1.51372727, grad/param norm = 2.0218e-01, time/batch = 0.7174s	
2338/22750 (epoch 5.138), train_loss = 1.65174454, grad/param norm = 2.1657e-01, time/batch = 0.7083s	
2339/22750 (epoch 5.141), train_loss = 1.52117047, grad/param norm = 1.9835e-01, time/batch = 0.6975s	
2340/22750 (epoch 5.143), train_loss = 1.47814179, grad/param norm = 1.9737e-01, time/batch = 0.7020s	
2341/22750 (epoch 5.145), train_loss = 1.74358035, grad/param norm = 2.1486e-01, time/batch = 0.7157s	
2342/22750 (epoch 5.147), train_loss = 1.75265347, grad/param norm = 2.1119e-01, time/batch = 0.7007s	
2343/22750 (epoch 5.149), train_loss = 1.65757666, grad/param norm = 2.1240e-01, time/batch = 0.6988s	
2344/22750 (epoch 5.152), train_loss = 1.60056926, grad/param norm = 2.1435e-01, time/batch = 0.6964s	
2345/22750 (epoch 5.154), train_loss = 1.40474088, grad/param norm = 1.9870e-01, time/batch = 0.6977s	
2346/22750 (epoch 5.156), train_loss = 1.52477249, grad/param norm = 2.0764e-01, time/batch = 0.7120s	
2347/22750 (epoch 5.158), train_loss = 1.59894654, grad/param norm = 2.1422e-01, time/batch = 0.7248s	
2348/22750 (epoch 5.160), train_loss = 1.71296922, grad/param norm = 2.2873e-01, time/batch = 0.7210s	
2349/22750 (epoch 5.163), train_loss = 1.89768060, grad/param norm = 2.3239e-01, time/batch = 0.7133s	
2350/22750 (epoch 5.165), train_loss = 1.79674366, grad/param norm = 2.1394e-01, time/batch = 0.7161s	
2351/22750 (epoch 5.167), train_loss = 1.56252939, grad/param norm = 2.0224e-01, time/batch = 0.7221s	
2352/22750 (epoch 5.169), train_loss = 1.70333037, grad/param norm = 2.1201e-01, time/batch = 0.7075s	
2353/22750 (epoch 5.171), train_loss = 1.53872548, grad/param norm = 2.0749e-01, time/batch = 0.7228s	
2354/22750 (epoch 5.174), train_loss = 1.38331421, grad/param norm = 1.8808e-01, time/batch = 0.7242s	
2355/22750 (epoch 5.176), train_loss = 1.67246263, grad/param norm = 1.9075e-01, time/batch = 0.7051s	
2356/22750 (epoch 5.178), train_loss = 1.59422940, grad/param norm = 1.9437e-01, time/batch = 0.7171s	
2357/22750 (epoch 5.180), train_loss = 1.78470574, grad/param norm = 2.4787e-01, time/batch = 0.7195s	
2358/22750 (epoch 5.182), train_loss = 1.69995366, grad/param norm = 1.8984e-01, time/batch = 0.7003s	
2359/22750 (epoch 5.185), train_loss = 1.71835103, grad/param norm = 2.1150e-01, time/batch = 0.7079s	
2360/22750 (epoch 5.187), train_loss = 1.50770732, grad/param norm = 2.0240e-01, time/batch = 0.7275s	
2361/22750 (epoch 5.189), train_loss = 1.54136368, grad/param norm = 2.0138e-01, time/batch = 0.7180s	
2362/22750 (epoch 5.191), train_loss = 1.48437071, grad/param norm = 1.9834e-01, time/batch = 0.7139s	
2363/22750 (epoch 5.193), train_loss = 1.73048680, grad/param norm = 2.1701e-01, time/batch = 0.6961s	
2364/22750 (epoch 5.196), train_loss = 1.64077180, grad/param norm = 2.0727e-01, time/batch = 0.6978s	
2365/22750 (epoch 5.198), train_loss = 1.37579820, grad/param norm = 1.8045e-01, time/batch = 0.6937s	
2366/22750 (epoch 5.200), train_loss = 1.69988126, grad/param norm = 2.0081e-01, time/batch = 0.7010s	
2367/22750 (epoch 5.202), train_loss = 1.90178035, grad/param norm = 2.3644e-01, time/batch = 0.7119s	
2368/22750 (epoch 5.204), train_loss = 1.81508053, grad/param norm = 2.1277e-01, time/batch = 0.6998s	
2369/22750 (epoch 5.207), train_loss = 1.61437951, grad/param norm = 2.2254e-01, time/batch = 0.6946s	
2370/22750 (epoch 5.209), train_loss = 1.53494678, grad/param norm = 2.1020e-01, time/batch = 0.6991s	
2371/22750 (epoch 5.211), train_loss = 1.64799473, grad/param norm = 2.2044e-01, time/batch = 0.6926s	
2372/22750 (epoch 5.213), train_loss = 1.50913651, grad/param norm = 2.0232e-01, time/batch = 0.7007s	
2373/22750 (epoch 5.215), train_loss = 1.54934140, grad/param norm = 2.1246e-01, time/batch = 0.7173s	
2374/22750 (epoch 5.218), train_loss = 1.44321235, grad/param norm = 2.2469e-01, time/batch = 0.7183s	
2375/22750 (epoch 5.220), train_loss = 1.66787820, grad/param norm = 2.5325e-01, time/batch = 0.7095s	
2376/22750 (epoch 5.222), train_loss = 1.47135006, grad/param norm = 2.2499e-01, time/batch = 0.6980s	
2377/22750 (epoch 5.224), train_loss = 1.55776339, grad/param norm = 2.0277e-01, time/batch = 0.7179s	
2378/22750 (epoch 5.226), train_loss = 1.70062551, grad/param norm = 2.2632e-01, time/batch = 0.7061s	
2379/22750 (epoch 5.229), train_loss = 1.71677206, grad/param norm = 2.1488e-01, time/batch = 0.7090s	
2380/22750 (epoch 5.231), train_loss = 1.60193574, grad/param norm = 1.9954e-01, time/batch = 0.7053s	
2381/22750 (epoch 5.233), train_loss = 1.53127702, grad/param norm = 1.9611e-01, time/batch = 0.7095s	
2382/22750 (epoch 5.235), train_loss = 1.49710760, grad/param norm = 2.0415e-01, time/batch = 0.6908s	
2383/22750 (epoch 5.237), train_loss = 1.56549739, grad/param norm = 2.1089e-01, time/batch = 0.6894s	
2384/22750 (epoch 5.240), train_loss = 1.75482349, grad/param norm = 1.9402e-01, time/batch = 0.6974s	
2385/22750 (epoch 5.242), train_loss = 2.07293022, grad/param norm = 2.4178e-01, time/batch = 0.6945s	
2386/22750 (epoch 5.244), train_loss = 1.86858825, grad/param norm = 2.6329e-01, time/batch = 0.6951s	
2387/22750 (epoch 5.246), train_loss = 1.93349745, grad/param norm = 2.0413e-01, time/batch = 0.6958s	
2388/22750 (epoch 5.248), train_loss = 1.62340169, grad/param norm = 2.2450e-01, time/batch = 0.6975s	
2389/22750 (epoch 5.251), train_loss = 1.88354766, grad/param norm = 2.1259e-01, time/batch = 0.6961s	
2390/22750 (epoch 5.253), train_loss = 1.70372675, grad/param norm = 1.9802e-01, time/batch = 0.7245s	
2391/22750 (epoch 5.255), train_loss = 1.72570645, grad/param norm = 2.0515e-01, time/batch = 0.6986s	
2392/22750 (epoch 5.257), train_loss = 1.64291327, grad/param norm = 2.1380e-01, time/batch = 0.6971s	
2393/22750 (epoch 5.259), train_loss = 1.82113683, grad/param norm = 2.3934e-01, time/batch = 0.6957s	
2394/22750 (epoch 5.262), train_loss = 1.66766960, grad/param norm = 2.1994e-01, time/batch = 0.6976s	
2395/22750 (epoch 5.264), train_loss = 1.57844570, grad/param norm = 2.0854e-01, time/batch = 0.7230s	
2396/22750 (epoch 5.266), train_loss = 1.64556682, grad/param norm = 2.1875e-01, time/batch = 0.7244s	
2397/22750 (epoch 5.268), train_loss = 1.76688095, grad/param norm = 2.0725e-01, time/batch = 0.7275s	
2398/22750 (epoch 5.270), train_loss = 1.56744661, grad/param norm = 2.1402e-01, time/batch = 0.7279s	
2399/22750 (epoch 5.273), train_loss = 1.90658007, grad/param norm = 2.4367e-01, time/batch = 0.7094s	
2400/22750 (epoch 5.275), train_loss = 1.67510966, grad/param norm = 2.1394e-01, time/batch = 0.6955s	
2401/22750 (epoch 5.277), train_loss = 1.69637429, grad/param norm = 2.1378e-01, time/batch = 0.7027s	
2402/22750 (epoch 5.279), train_loss = 1.45849522, grad/param norm = 1.8507e-01, time/batch = 0.6955s	
2403/22750 (epoch 5.281), train_loss = 1.68004268, grad/param norm = 2.0807e-01, time/batch = 0.6922s	
2404/22750 (epoch 5.284), train_loss = 1.54178424, grad/param norm = 1.8434e-01, time/batch = 0.6939s	
2405/22750 (epoch 5.286), train_loss = 1.74500864, grad/param norm = 2.1281e-01, time/batch = 0.6917s	
2406/22750 (epoch 5.288), train_loss = 1.82068816, grad/param norm = 2.0608e-01, time/batch = 0.6931s	
2407/22750 (epoch 5.290), train_loss = 1.54224621, grad/param norm = 1.9383e-01, time/batch = 0.6989s	
2408/22750 (epoch 5.292), train_loss = 1.63999934, grad/param norm = 2.2078e-01, time/batch = 0.6938s	
2409/22750 (epoch 5.295), train_loss = 1.65085164, grad/param norm = 1.9075e-01, time/batch = 0.6939s	
2410/22750 (epoch 5.297), train_loss = 1.58272493, grad/param norm = 2.0067e-01, time/batch = 0.7263s	
2411/22750 (epoch 5.299), train_loss = 1.79806858, grad/param norm = 2.0841e-01, time/batch = 0.7260s	
2412/22750 (epoch 5.301), train_loss = 1.71629488, grad/param norm = 2.0348e-01, time/batch = 0.7218s	
2413/22750 (epoch 5.303), train_loss = 1.80130022, grad/param norm = 2.3095e-01, time/batch = 0.6992s	
2414/22750 (epoch 5.305), train_loss = 1.83411216, grad/param norm = 2.1368e-01, time/batch = 0.6953s	
2415/22750 (epoch 5.308), train_loss = 1.70893504, grad/param norm = 2.0637e-01, time/batch = 0.6929s	
2416/22750 (epoch 5.310), train_loss = 1.62357205, grad/param norm = 2.1965e-01, time/batch = 0.6946s	
2417/22750 (epoch 5.312), train_loss = 1.66985923, grad/param norm = 2.0920e-01, time/batch = 0.7021s	
2418/22750 (epoch 5.314), train_loss = 1.63364753, grad/param norm = 2.0167e-01, time/batch = 0.7073s	
2419/22750 (epoch 5.316), train_loss = 1.58754109, grad/param norm = 1.9229e-01, time/batch = 0.6962s	
2420/22750 (epoch 5.319), train_loss = 1.71281412, grad/param norm = 1.9580e-01, time/batch = 0.6977s	
2421/22750 (epoch 5.321), train_loss = 1.62639515, grad/param norm = 2.2270e-01, time/batch = 0.7059s	
2422/22750 (epoch 5.323), train_loss = 1.59409934, grad/param norm = 2.2250e-01, time/batch = 0.7217s	
2423/22750 (epoch 5.325), train_loss = 1.35760884, grad/param norm = 2.0640e-01, time/batch = 0.7078s	
2424/22750 (epoch 5.327), train_loss = 1.69555607, grad/param norm = 2.1640e-01, time/batch = 0.6910s	
2425/22750 (epoch 5.330), train_loss = 1.95287766, grad/param norm = 2.1566e-01, time/batch = 0.6889s	
2426/22750 (epoch 5.332), train_loss = 1.73932344, grad/param norm = 2.0071e-01, time/batch = 0.6971s	
2427/22750 (epoch 5.334), train_loss = 1.37567542, grad/param norm = 1.8938e-01, time/batch = 0.6923s	
2428/22750 (epoch 5.336), train_loss = 1.70523786, grad/param norm = 1.9722e-01, time/batch = 0.6928s	
2429/22750 (epoch 5.338), train_loss = 1.64804968, grad/param norm = 2.0632e-01, time/batch = 0.6902s	
2430/22750 (epoch 5.341), train_loss = 1.60607122, grad/param norm = 2.0828e-01, time/batch = 0.6949s	
2431/22750 (epoch 5.343), train_loss = 1.46586752, grad/param norm = 2.0686e-01, time/batch = 0.7191s	
2432/22750 (epoch 5.345), train_loss = 1.81854372, grad/param norm = 2.3288e-01, time/batch = 0.7251s	
2433/22750 (epoch 5.347), train_loss = 1.77876960, grad/param norm = 2.1770e-01, time/batch = 0.7107s	
2434/22750 (epoch 5.349), train_loss = 1.35414815, grad/param norm = 2.1709e-01, time/batch = 0.7050s	
2435/22750 (epoch 5.352), train_loss = 1.74933363, grad/param norm = 2.2497e-01, time/batch = 0.7014s	
2436/22750 (epoch 5.354), train_loss = 1.85538504, grad/param norm = 2.2254e-01, time/batch = 0.7054s	
2437/22750 (epoch 5.356), train_loss = 1.84328512, grad/param norm = 1.9996e-01, time/batch = 0.7110s	
2438/22750 (epoch 5.358), train_loss = 1.61954993, grad/param norm = 2.1949e-01, time/batch = 0.6956s	
2439/22750 (epoch 5.360), train_loss = 1.88160499, grad/param norm = 2.2948e-01, time/batch = 0.6958s	
2440/22750 (epoch 5.363), train_loss = 1.63819025, grad/param norm = 2.0286e-01, time/batch = 0.6941s	
2441/22750 (epoch 5.365), train_loss = 1.39779144, grad/param norm = 2.0897e-01, time/batch = 0.7042s	
2442/22750 (epoch 5.367), train_loss = 1.37549610, grad/param norm = 1.8460e-01, time/batch = 0.7045s	
2443/22750 (epoch 5.369), train_loss = 1.60050379, grad/param norm = 2.3324e-01, time/batch = 0.7049s	
2444/22750 (epoch 5.371), train_loss = 1.57258452, grad/param norm = 2.1573e-01, time/batch = 0.7262s	
2445/22750 (epoch 5.374), train_loss = 1.46327076, grad/param norm = 2.3374e-01, time/batch = 0.7210s	
2446/22750 (epoch 5.376), train_loss = 1.68546986, grad/param norm = 2.0684e-01, time/batch = 0.7081s	
2447/22750 (epoch 5.378), train_loss = 1.58252986, grad/param norm = 2.0358e-01, time/batch = 0.6892s	
2448/22750 (epoch 5.380), train_loss = 1.77804693, grad/param norm = 2.1385e-01, time/batch = 0.6909s	
2449/22750 (epoch 5.382), train_loss = 1.54596117, grad/param norm = 1.9578e-01, time/batch = 0.6898s	
2450/22750 (epoch 5.385), train_loss = 1.67394375, grad/param norm = 1.8401e-01, time/batch = 0.6912s	
2451/22750 (epoch 5.387), train_loss = 1.72409359, grad/param norm = 2.0535e-01, time/batch = 0.7064s	
2452/22750 (epoch 5.389), train_loss = 1.27306938, grad/param norm = 2.1118e-01, time/batch = 0.6946s	
2453/22750 (epoch 5.391), train_loss = 1.10236469, grad/param norm = 1.7550e-01, time/batch = 0.7171s	
2454/22750 (epoch 5.393), train_loss = 1.44230513, grad/param norm = 1.9554e-01, time/batch = 0.7265s	
2455/22750 (epoch 5.396), train_loss = 1.62418122, grad/param norm = 2.2086e-01, time/batch = 0.7236s	
2456/22750 (epoch 5.398), train_loss = 1.61273003, grad/param norm = 2.1480e-01, time/batch = 0.7371s	
2457/22750 (epoch 5.400), train_loss = 1.60909751, grad/param norm = 1.9943e-01, time/batch = 0.7352s	
2458/22750 (epoch 5.402), train_loss = 1.63822780, grad/param norm = 2.0116e-01, time/batch = 0.7202s	
2459/22750 (epoch 5.404), train_loss = 1.86534315, grad/param norm = 2.2242e-01, time/batch = 0.7200s	
2460/22750 (epoch 5.407), train_loss = 1.73297050, grad/param norm = 1.9891e-01, time/batch = 0.7051s	
2461/22750 (epoch 5.409), train_loss = 1.63011402, grad/param norm = 2.1023e-01, time/batch = 0.6984s	
2462/22750 (epoch 5.411), train_loss = 1.63770987, grad/param norm = 1.9587e-01, time/batch = 0.7121s	
2463/22750 (epoch 5.413), train_loss = 1.50620830, grad/param norm = 2.1545e-01, time/batch = 0.7099s	
2464/22750 (epoch 5.415), train_loss = 1.39795135, grad/param norm = 2.2262e-01, time/batch = 0.7015s	
2465/22750 (epoch 5.418), train_loss = 1.58441671, grad/param norm = 2.0654e-01, time/batch = 0.6965s	
2466/22750 (epoch 5.420), train_loss = 1.88175022, grad/param norm = 2.3225e-01, time/batch = 0.7162s	
2467/22750 (epoch 5.422), train_loss = 1.95494785, grad/param norm = 2.2924e-01, time/batch = 0.6985s	
2468/22750 (epoch 5.424), train_loss = 1.95367814, grad/param norm = 2.3935e-01, time/batch = 0.6993s	
2469/22750 (epoch 5.426), train_loss = 1.90124525, grad/param norm = 1.9763e-01, time/batch = 0.6987s	
2470/22750 (epoch 5.429), train_loss = 1.38925322, grad/param norm = 1.9967e-01, time/batch = 0.6989s	
2471/22750 (epoch 5.431), train_loss = 1.38196736, grad/param norm = 1.9218e-01, time/batch = 0.6941s	
2472/22750 (epoch 5.433), train_loss = 1.47089216, grad/param norm = 1.8678e-01, time/batch = 0.6976s	
2473/22750 (epoch 5.435), train_loss = 1.36336820, grad/param norm = 2.0581e-01, time/batch = 0.7027s	
2474/22750 (epoch 5.437), train_loss = 1.30105220, grad/param norm = 1.9407e-01, time/batch = 0.6995s	
2475/22750 (epoch 5.440), train_loss = 1.80470843, grad/param norm = 2.2444e-01, time/batch = 0.6991s	
2476/22750 (epoch 5.442), train_loss = 1.62899786, grad/param norm = 2.1356e-01, time/batch = 0.6989s	
2477/22750 (epoch 5.444), train_loss = 1.70086773, grad/param norm = 2.8636e-01, time/batch = 0.6998s	
2478/22750 (epoch 5.446), train_loss = 1.65512168, grad/param norm = 2.3971e-01, time/batch = 0.6980s	
2479/22750 (epoch 5.448), train_loss = 1.92313822, grad/param norm = 2.3238e-01, time/batch = 0.6951s	
2480/22750 (epoch 5.451), train_loss = 1.83335917, grad/param norm = 2.3444e-01, time/batch = 0.7064s	
2481/22750 (epoch 5.453), train_loss = 1.94812509, grad/param norm = 2.6902e-01, time/batch = 0.7057s	
2482/22750 (epoch 5.455), train_loss = 1.97790092, grad/param norm = 2.1267e-01, time/batch = 0.7199s	
2483/22750 (epoch 5.457), train_loss = 1.81783972, grad/param norm = 2.4599e-01, time/batch = 0.7274s	
2484/22750 (epoch 5.459), train_loss = 1.69355315, grad/param norm = 1.9998e-01, time/batch = 0.7217s	
2485/22750 (epoch 5.462), train_loss = 1.67735811, grad/param norm = 1.7857e-01, time/batch = 0.7096s	
2486/22750 (epoch 5.464), train_loss = 1.48286719, grad/param norm = 1.9333e-01, time/batch = 0.7143s	
2487/22750 (epoch 5.466), train_loss = 1.90833718, grad/param norm = 2.2193e-01, time/batch = 0.7106s	
2488/22750 (epoch 5.468), train_loss = 1.60915155, grad/param norm = 2.1597e-01, time/batch = 0.7118s	
2489/22750 (epoch 5.470), train_loss = 1.83667679, grad/param norm = 2.3406e-01, time/batch = 0.7098s	
2490/22750 (epoch 5.473), train_loss = 1.66423071, grad/param norm = 2.2447e-01, time/batch = 0.7081s	
2491/22750 (epoch 5.475), train_loss = 1.72671954, grad/param norm = 2.0493e-01, time/batch = 0.7130s	
2492/22750 (epoch 5.477), train_loss = 1.44725760, grad/param norm = 1.9425e-01, time/batch = 0.7059s	
2493/22750 (epoch 5.479), train_loss = 1.49446453, grad/param norm = 1.8409e-01, time/batch = 0.7106s	
2494/22750 (epoch 5.481), train_loss = 1.45644855, grad/param norm = 2.0904e-01, time/batch = 0.7086s	
2495/22750 (epoch 5.484), train_loss = 1.26958066, grad/param norm = 2.0290e-01, time/batch = 0.7175s	
2496/22750 (epoch 5.486), train_loss = 1.53705557, grad/param norm = 2.3094e-01, time/batch = 0.7000s	
2497/22750 (epoch 5.488), train_loss = 1.26544300, grad/param norm = 2.3153e-01, time/batch = 0.6963s	
2498/22750 (epoch 5.490), train_loss = 1.51468014, grad/param norm = 2.0737e-01, time/batch = 0.6919s	
2499/22750 (epoch 5.492), train_loss = 1.79869356, grad/param norm = 2.4537e-01, time/batch = 0.6999s	
2500/22750 (epoch 5.495), train_loss = 1.55139782, grad/param norm = 2.3075e-01, time/batch = 0.6954s	
2501/22750 (epoch 5.497), train_loss = 1.73206544, grad/param norm = 2.2320e-01, time/batch = 0.7003s	
2502/22750 (epoch 5.499), train_loss = 1.59815438, grad/param norm = 2.0949e-01, time/batch = 0.6961s	
2503/22750 (epoch 5.501), train_loss = 1.65361707, grad/param norm = 2.0684e-01, time/batch = 0.6996s	
2504/22750 (epoch 5.503), train_loss = 1.62209286, grad/param norm = 2.0955e-01, time/batch = 0.6955s	
2505/22750 (epoch 5.505), train_loss = 1.46038570, grad/param norm = 1.9072e-01, time/batch = 0.6967s	
2506/22750 (epoch 5.508), train_loss = 1.42258571, grad/param norm = 2.1697e-01, time/batch = 0.7011s	
2507/22750 (epoch 5.510), train_loss = 1.43467833, grad/param norm = 1.8589e-01, time/batch = 0.7024s	
2508/22750 (epoch 5.512), train_loss = 1.51943841, grad/param norm = 1.9152e-01, time/batch = 0.6931s	
2509/22750 (epoch 5.514), train_loss = 1.52067585, grad/param norm = 1.9203e-01, time/batch = 0.6926s	
2510/22750 (epoch 5.516), train_loss = 1.46083684, grad/param norm = 1.9888e-01, time/batch = 0.6976s	
2511/22750 (epoch 5.519), train_loss = 1.66392185, grad/param norm = 2.3393e-01, time/batch = 0.7048s	
2512/22750 (epoch 5.521), train_loss = 1.49558516, grad/param norm = 2.3384e-01, time/batch = 0.7004s	
2513/22750 (epoch 5.523), train_loss = 1.55073962, grad/param norm = 2.4982e-01, time/batch = 0.7029s	
2514/22750 (epoch 5.525), train_loss = 1.78957067, grad/param norm = 2.3000e-01, time/batch = 0.7066s	
2515/22750 (epoch 5.527), train_loss = 1.63288334, grad/param norm = 2.1038e-01, time/batch = 0.7044s	
2516/22750 (epoch 5.530), train_loss = 1.49339629, grad/param norm = 2.1777e-01, time/batch = 0.7221s	
2517/22750 (epoch 5.532), train_loss = 1.50534293, grad/param norm = 1.9086e-01, time/batch = 1.1423s	
2518/22750 (epoch 5.534), train_loss = 1.76065580, grad/param norm = 2.3823e-01, time/batch = 1.2195s	
2519/22750 (epoch 5.536), train_loss = 1.61082669, grad/param norm = 1.9954e-01, time/batch = 0.7120s	
2520/22750 (epoch 5.538), train_loss = 1.65673993, grad/param norm = 1.8325e-01, time/batch = 0.6849s	
2521/22750 (epoch 5.541), train_loss = 1.36605041, grad/param norm = 2.0153e-01, time/batch = 0.6959s	
2522/22750 (epoch 5.543), train_loss = 1.38013171, grad/param norm = 1.8777e-01, time/batch = 0.6889s	
2523/22750 (epoch 5.545), train_loss = 1.76080111, grad/param norm = 2.1225e-01, time/batch = 0.7337s	
2524/22750 (epoch 5.547), train_loss = 1.38405255, grad/param norm = 1.8437e-01, time/batch = 0.7031s	
2525/22750 (epoch 5.549), train_loss = 1.48547870, grad/param norm = 2.2244e-01, time/batch = 0.7079s	
2526/22750 (epoch 5.552), train_loss = 1.71180535, grad/param norm = 2.3635e-01, time/batch = 0.7022s	
2527/22750 (epoch 5.554), train_loss = 1.75148375, grad/param norm = 2.0844e-01, time/batch = 0.6929s	
2528/22750 (epoch 5.556), train_loss = 1.57669406, grad/param norm = 2.1061e-01, time/batch = 0.6993s	
2529/22750 (epoch 5.558), train_loss = 1.78586766, grad/param norm = 2.0049e-01, time/batch = 0.7262s	
2530/22750 (epoch 5.560), train_loss = 1.45724455, grad/param norm = 1.8710e-01, time/batch = 0.7183s	
2531/22750 (epoch 5.563), train_loss = 1.67793646, grad/param norm = 2.1087e-01, time/batch = 0.7004s	
2532/22750 (epoch 5.565), train_loss = 1.79628761, grad/param norm = 1.9756e-01, time/batch = 0.6889s	
2533/22750 (epoch 5.567), train_loss = 1.61557654, grad/param norm = 2.0286e-01, time/batch = 0.6847s	
2534/22750 (epoch 5.569), train_loss = 1.55478646, grad/param norm = 2.0433e-01, time/batch = 0.6863s	
2535/22750 (epoch 5.571), train_loss = 1.65032718, grad/param norm = 2.1301e-01, time/batch = 0.7110s	
2536/22750 (epoch 5.574), train_loss = 1.44861310, grad/param norm = 2.1358e-01, time/batch = 0.6973s	
2537/22750 (epoch 5.576), train_loss = 1.64031532, grad/param norm = 1.9285e-01, time/batch = 0.6852s	
2538/22750 (epoch 5.578), train_loss = 1.40940942, grad/param norm = 1.8326e-01, time/batch = 0.6919s	
2539/22750 (epoch 5.580), train_loss = 1.69760736, grad/param norm = 2.1616e-01, time/batch = 0.6861s	
2540/22750 (epoch 5.582), train_loss = 1.36765761, grad/param norm = 1.9981e-01, time/batch = 0.6928s	
2541/22750 (epoch 5.585), train_loss = 1.30071941, grad/param norm = 1.8058e-01, time/batch = 0.6874s	
2542/22750 (epoch 5.587), train_loss = 1.39595376, grad/param norm = 1.7340e-01, time/batch = 0.6889s	
2543/22750 (epoch 5.589), train_loss = 1.41599651, grad/param norm = 2.1059e-01, time/batch = 0.6880s	
2544/22750 (epoch 5.591), train_loss = 1.62921307, grad/param norm = 2.1915e-01, time/batch = 0.6983s	
2545/22750 (epoch 5.593), train_loss = 1.81153546, grad/param norm = 2.0024e-01, time/batch = 0.6926s	
2546/22750 (epoch 5.596), train_loss = 1.76566577, grad/param norm = 1.9770e-01, time/batch = 0.6948s	
2547/22750 (epoch 5.598), train_loss = 1.81966271, grad/param norm = 2.0906e-01, time/batch = 0.6999s	
2548/22750 (epoch 5.600), train_loss = 1.67488283, grad/param norm = 2.0488e-01, time/batch = 0.6993s	
2549/22750 (epoch 5.602), train_loss = 1.41763010, grad/param norm = 1.7665e-01, time/batch = 0.7023s	
2550/22750 (epoch 5.604), train_loss = 1.54716914, grad/param norm = 1.8893e-01, time/batch = 0.7038s	
2551/22750 (epoch 5.607), train_loss = 1.27498702, grad/param norm = 1.7284e-01, time/batch = 0.7015s	
2552/22750 (epoch 5.609), train_loss = 1.25349495, grad/param norm = 1.7657e-01, time/batch = 0.6988s	
2553/22750 (epoch 5.611), train_loss = 1.51181854, grad/param norm = 2.1052e-01, time/batch = 0.7159s	
2554/22750 (epoch 5.613), train_loss = 1.44201651, grad/param norm = 2.1144e-01, time/batch = 0.7116s	
2555/22750 (epoch 5.615), train_loss = 1.52391834, grad/param norm = 2.0175e-01, time/batch = 0.7220s	
2556/22750 (epoch 5.618), train_loss = 1.59856528, grad/param norm = 2.1438e-01, time/batch = 0.7190s	
2557/22750 (epoch 5.620), train_loss = 1.57079577, grad/param norm = 1.9690e-01, time/batch = 0.7178s	
2558/22750 (epoch 5.622), train_loss = 1.39310710, grad/param norm = 2.1809e-01, time/batch = 0.7185s	
2559/22750 (epoch 5.624), train_loss = 1.69913031, grad/param norm = 2.2661e-01, time/batch = 0.7159s	
2560/22750 (epoch 5.626), train_loss = 1.47985241, grad/param norm = 2.2884e-01, time/batch = 0.7192s	
2561/22750 (epoch 5.629), train_loss = 1.61071104, grad/param norm = 2.2850e-01, time/batch = 0.7209s	
2562/22750 (epoch 5.631), train_loss = 1.65147733, grad/param norm = 2.1847e-01, time/batch = 0.7157s	
2563/22750 (epoch 5.633), train_loss = 1.33758729, grad/param norm = 2.1019e-01, time/batch = 0.7174s	
2564/22750 (epoch 5.635), train_loss = 1.68741862, grad/param norm = 2.1146e-01, time/batch = 0.7117s	
2565/22750 (epoch 5.637), train_loss = 1.69879289, grad/param norm = 2.1308e-01, time/batch = 0.7051s	
2566/22750 (epoch 5.640), train_loss = 1.79555020, grad/param norm = 2.3544e-01, time/batch = 0.6985s	
2567/22750 (epoch 5.642), train_loss = 1.74710910, grad/param norm = 2.2915e-01, time/batch = 0.6932s	
2568/22750 (epoch 5.644), train_loss = 1.59901678, grad/param norm = 2.0262e-01, time/batch = 0.6974s	
2569/22750 (epoch 5.646), train_loss = 1.73983637, grad/param norm = 2.2892e-01, time/batch = 0.6953s	
2570/22750 (epoch 5.648), train_loss = 1.65480057, grad/param norm = 2.2796e-01, time/batch = 0.6949s	
2571/22750 (epoch 5.651), train_loss = 1.76035123, grad/param norm = 2.2140e-01, time/batch = 0.6964s	
2572/22750 (epoch 5.653), train_loss = 1.61331542, grad/param norm = 1.9344e-01, time/batch = 0.6942s	
2573/22750 (epoch 5.655), train_loss = 1.59280686, grad/param norm = 2.0451e-01, time/batch = 0.6940s	
2574/22750 (epoch 5.657), train_loss = 1.80734694, grad/param norm = 1.9761e-01, time/batch = 0.6999s	
2575/22750 (epoch 5.659), train_loss = 1.85843902, grad/param norm = 2.0444e-01, time/batch = 0.7036s	
2576/22750 (epoch 5.662), train_loss = 1.92908530, grad/param norm = 2.2635e-01, time/batch = 0.6987s	
2577/22750 (epoch 5.664), train_loss = 1.69626246, grad/param norm = 2.2475e-01, time/batch = 0.7030s	
2578/22750 (epoch 5.666), train_loss = 1.47239568, grad/param norm = 1.9600e-01, time/batch = 0.6999s	
2579/22750 (epoch 5.668), train_loss = 1.63836504, grad/param norm = 1.9711e-01, time/batch = 0.6960s	
2580/22750 (epoch 5.670), train_loss = 1.64521076, grad/param norm = 2.0551e-01, time/batch = 0.6982s	
2581/22750 (epoch 5.673), train_loss = 1.84932987, grad/param norm = 2.3899e-01, time/batch = 0.7012s	
2582/22750 (epoch 5.675), train_loss = 2.11541038, grad/param norm = 2.5655e-01, time/batch = 0.6963s	
2583/22750 (epoch 5.677), train_loss = 1.86747754, grad/param norm = 2.2516e-01, time/batch = 0.6963s	
2584/22750 (epoch 5.679), train_loss = 1.92081738, grad/param norm = 2.1818e-01, time/batch = 0.7002s	
2585/22750 (epoch 5.681), train_loss = 1.78182975, grad/param norm = 2.1855e-01, time/batch = 0.7020s	
2586/22750 (epoch 5.684), train_loss = 1.77091842, grad/param norm = 2.0636e-01, time/batch = 0.7013s	
2587/22750 (epoch 5.686), train_loss = 1.77094683, grad/param norm = 2.2463e-01, time/batch = 0.6996s	
2588/22750 (epoch 5.688), train_loss = 1.74458788, grad/param norm = 2.1164e-01, time/batch = 0.7021s	
2589/22750 (epoch 5.690), train_loss = 1.70434635, grad/param norm = 2.1614e-01, time/batch = 0.7106s	
2590/22750 (epoch 5.692), train_loss = 1.87663840, grad/param norm = 2.2871e-01, time/batch = 0.7065s	
2591/22750 (epoch 5.695), train_loss = 1.64138922, grad/param norm = 2.1122e-01, time/batch = 0.7007s	
2592/22750 (epoch 5.697), train_loss = 1.57972872, grad/param norm = 2.4171e-01, time/batch = 0.6995s	
2593/22750 (epoch 5.699), train_loss = 1.67041331, grad/param norm = 2.0358e-01, time/batch = 0.6969s	
2594/22750 (epoch 5.701), train_loss = 1.51278725, grad/param norm = 2.0621e-01, time/batch = 0.7048s	
2595/22750 (epoch 5.703), train_loss = 1.65923244, grad/param norm = 1.9945e-01, time/batch = 0.7124s	
2596/22750 (epoch 5.705), train_loss = 1.46826563, grad/param norm = 1.8200e-01, time/batch = 0.7113s	
2597/22750 (epoch 5.708), train_loss = 1.63966099, grad/param norm = 1.7415e-01, time/batch = 0.7001s	
2598/22750 (epoch 5.710), train_loss = 1.40280589, grad/param norm = 2.1518e-01, time/batch = 0.6968s	
2599/22750 (epoch 5.712), train_loss = 1.48850412, grad/param norm = 2.0102e-01, time/batch = 0.7145s	
2600/22750 (epoch 5.714), train_loss = 1.38635574, grad/param norm = 2.0129e-01, time/batch = 0.7252s	
2601/22750 (epoch 5.716), train_loss = 1.50962056, grad/param norm = 2.1195e-01, time/batch = 0.7254s	
2602/22750 (epoch 5.719), train_loss = 1.75948251, grad/param norm = 2.5790e-01, time/batch = 0.7105s	
2603/22750 (epoch 5.721), train_loss = 1.69001456, grad/param norm = 2.1755e-01, time/batch = 0.7150s	
2604/22750 (epoch 5.723), train_loss = 1.58147364, grad/param norm = 1.9877e-01, time/batch = 0.7261s	
2605/22750 (epoch 5.725), train_loss = 1.59929104, grad/param norm = 2.3351e-01, time/batch = 0.7216s	
2606/22750 (epoch 5.727), train_loss = 1.50905848, grad/param norm = 1.8627e-01, time/batch = 0.6998s	
2607/22750 (epoch 5.730), train_loss = 1.53732607, grad/param norm = 1.9977e-01, time/batch = 0.7051s	
2608/22750 (epoch 5.732), train_loss = 1.59927669, grad/param norm = 2.0506e-01, time/batch = 0.7102s	
2609/22750 (epoch 5.734), train_loss = 1.24933901, grad/param norm = 2.1280e-01, time/batch = 0.6990s	
2610/22750 (epoch 5.736), train_loss = 1.48884716, grad/param norm = 1.9769e-01, time/batch = 0.7136s	
2611/22750 (epoch 5.738), train_loss = 1.57069199, grad/param norm = 2.1919e-01, time/batch = 0.7116s	
2612/22750 (epoch 5.741), train_loss = 1.71057218, grad/param norm = 1.9455e-01, time/batch = 0.7068s	
2613/22750 (epoch 5.743), train_loss = 1.68507477, grad/param norm = 2.2025e-01, time/batch = 0.7183s	
2614/22750 (epoch 5.745), train_loss = 1.37899733, grad/param norm = 1.7757e-01, time/batch = 0.7103s	
2615/22750 (epoch 5.747), train_loss = 1.52807912, grad/param norm = 2.1278e-01, time/batch = 0.7027s	
2616/22750 (epoch 5.749), train_loss = 1.80522606, grad/param norm = 2.1944e-01, time/batch = 0.6999s	
2617/22750 (epoch 5.752), train_loss = 1.50855156, grad/param norm = 1.9958e-01, time/batch = 0.6949s	
2618/22750 (epoch 5.754), train_loss = 1.76861156, grad/param norm = 2.3793e-01, time/batch = 0.7001s	
2619/22750 (epoch 5.756), train_loss = 1.39504056, grad/param norm = 2.2687e-01, time/batch = 0.6970s	
2620/22750 (epoch 5.758), train_loss = 1.35389626, grad/param norm = 2.1199e-01, time/batch = 0.7206s	
2621/22750 (epoch 5.760), train_loss = 1.63274350, grad/param norm = 2.1199e-01, time/batch = 0.7128s	
2622/22750 (epoch 5.763), train_loss = 1.64422102, grad/param norm = 1.9922e-01, time/batch = 0.7051s	
2623/22750 (epoch 5.765), train_loss = 1.49814443, grad/param norm = 2.1197e-01, time/batch = 0.6963s	
2624/22750 (epoch 5.767), train_loss = 1.55087371, grad/param norm = 1.9818e-01, time/batch = 0.6956s	
2625/22750 (epoch 5.769), train_loss = 1.74718252, grad/param norm = 2.1471e-01, time/batch = 0.6902s	
2626/22750 (epoch 5.771), train_loss = 1.73961660, grad/param norm = 2.2099e-01, time/batch = 0.6987s	
2627/22750 (epoch 5.774), train_loss = 1.53162562, grad/param norm = 2.2502e-01, time/batch = 0.6981s	
2628/22750 (epoch 5.776), train_loss = 1.60407271, grad/param norm = 2.1458e-01, time/batch = 0.6924s	
2629/22750 (epoch 5.778), train_loss = 1.79298191, grad/param norm = 1.9490e-01, time/batch = 0.6902s	
2630/22750 (epoch 5.780), train_loss = 1.65172795, grad/param norm = 2.2798e-01, time/batch = 0.7235s	
2631/22750 (epoch 5.782), train_loss = 1.73665559, grad/param norm = 2.1615e-01, time/batch = 0.7383s	
2632/22750 (epoch 5.785), train_loss = 1.63415665, grad/param norm = 2.0249e-01, time/batch = 0.7329s	
2633/22750 (epoch 5.787), train_loss = 1.49721850, grad/param norm = 2.0864e-01, time/batch = 0.7403s	
2634/22750 (epoch 5.789), train_loss = 1.52321177, grad/param norm = 1.8853e-01, time/batch = 0.7303s	
2635/22750 (epoch 5.791), train_loss = 1.57127990, grad/param norm = 1.8468e-01, time/batch = 0.7308s	
2636/22750 (epoch 5.793), train_loss = 1.57243241, grad/param norm = 2.1867e-01, time/batch = 0.7323s	
2637/22750 (epoch 5.796), train_loss = 1.47354982, grad/param norm = 2.0278e-01, time/batch = 0.7022s	
2638/22750 (epoch 5.798), train_loss = 1.46556205, grad/param norm = 1.8168e-01, time/batch = 0.7185s	
2639/22750 (epoch 5.800), train_loss = 1.43391596, grad/param norm = 1.8946e-01, time/batch = 0.7178s	
2640/22750 (epoch 5.802), train_loss = 1.56061961, grad/param norm = 2.0325e-01, time/batch = 0.7213s	
2641/22750 (epoch 5.804), train_loss = 1.84865119, grad/param norm = 2.0503e-01, time/batch = 0.7261s	
2642/22750 (epoch 5.807), train_loss = 1.61751673, grad/param norm = 2.0199e-01, time/batch = 0.7047s	
2643/22750 (epoch 5.809), train_loss = 1.86765850, grad/param norm = 2.2258e-01, time/batch = 0.7276s	
2644/22750 (epoch 5.811), train_loss = 1.54713530, grad/param norm = 1.9533e-01, time/batch = 0.7183s	
2645/22750 (epoch 5.813), train_loss = 1.67030796, grad/param norm = 2.0845e-01, time/batch = 0.7249s	
2646/22750 (epoch 5.815), train_loss = 1.81211078, grad/param norm = 2.3258e-01, time/batch = 0.7049s	
2647/22750 (epoch 5.818), train_loss = 1.75979374, grad/param norm = 2.0491e-01, time/batch = 0.7084s	
2648/22750 (epoch 5.820), train_loss = 1.86657521, grad/param norm = 1.9347e-01, time/batch = 0.7162s	
2649/22750 (epoch 5.822), train_loss = 1.64017855, grad/param norm = 1.9613e-01, time/batch = 0.7202s	
2650/22750 (epoch 5.824), train_loss = 1.64248675, grad/param norm = 2.0220e-01, time/batch = 0.7206s	
2651/22750 (epoch 5.826), train_loss = 1.62462023, grad/param norm = 1.9697e-01, time/batch = 0.7081s	
2652/22750 (epoch 5.829), train_loss = 1.80207870, grad/param norm = 2.3407e-01, time/batch = 0.7214s	
2653/22750 (epoch 5.831), train_loss = 1.77920716, grad/param norm = 2.4618e-01, time/batch = 0.7140s	
2654/22750 (epoch 5.833), train_loss = 1.74554551, grad/param norm = 2.1991e-01, time/batch = 0.7164s	
2655/22750 (epoch 5.835), train_loss = 1.55534454, grad/param norm = 2.0500e-01, time/batch = 0.7146s	
2656/22750 (epoch 5.837), train_loss = 1.55910305, grad/param norm = 2.1268e-01, time/batch = 0.6990s	
2657/22750 (epoch 5.840), train_loss = 1.59790886, grad/param norm = 2.1206e-01, time/batch = 0.6942s	
2658/22750 (epoch 5.842), train_loss = 1.51943953, grad/param norm = 1.9079e-01, time/batch = 0.6916s	
2659/22750 (epoch 5.844), train_loss = 1.82267093, grad/param norm = 2.1858e-01, time/batch = 0.6848s	
2660/22750 (epoch 5.846), train_loss = 1.57563519, grad/param norm = 1.9703e-01, time/batch = 0.6842s	
2661/22750 (epoch 5.848), train_loss = 1.43135834, grad/param norm = 2.0340e-01, time/batch = 0.7001s	
2662/22750 (epoch 5.851), train_loss = 1.48064928, grad/param norm = 1.9624e-01, time/batch = 0.6886s	
2663/22750 (epoch 5.853), train_loss = 1.58328372, grad/param norm = 2.0493e-01, time/batch = 0.6806s	
2664/22750 (epoch 5.855), train_loss = 1.38694622, grad/param norm = 1.9479e-01, time/batch = 0.6905s	
2665/22750 (epoch 5.857), train_loss = 1.59692071, grad/param norm = 1.9295e-01, time/batch = 0.7107s	
2666/22750 (epoch 5.859), train_loss = 1.63857522, grad/param norm = 2.2320e-01, time/batch = 0.7132s	
2667/22750 (epoch 5.862), train_loss = 1.78957293, grad/param norm = 2.1625e-01, time/batch = 0.7144s	
2668/22750 (epoch 5.864), train_loss = 1.60135271, grad/param norm = 1.9877e-01, time/batch = 0.7139s	
2669/22750 (epoch 5.866), train_loss = 1.62473565, grad/param norm = 1.9504e-01, time/batch = 0.7003s	
2670/22750 (epoch 5.868), train_loss = 1.60058757, grad/param norm = 1.9929e-01, time/batch = 0.6874s	
2671/22750 (epoch 5.870), train_loss = 1.39221180, grad/param norm = 2.0107e-01, time/batch = 0.6922s	
2672/22750 (epoch 5.873), train_loss = 1.55967830, grad/param norm = 2.0416e-01, time/batch = 0.6887s	
2673/22750 (epoch 5.875), train_loss = 1.65616491, grad/param norm = 2.0080e-01, time/batch = 0.6926s	
2674/22750 (epoch 5.877), train_loss = 1.49510738, grad/param norm = 1.9170e-01, time/batch = 0.7112s	
2675/22750 (epoch 5.879), train_loss = 1.72068503, grad/param norm = 2.1384e-01, time/batch = 0.7118s	
2676/22750 (epoch 5.881), train_loss = 1.70528233, grad/param norm = 2.1109e-01, time/batch = 0.6895s	
2677/22750 (epoch 5.884), train_loss = 1.52022676, grad/param norm = 2.2899e-01, time/batch = 0.6762s	
2678/22750 (epoch 5.886), train_loss = 1.68841400, grad/param norm = 2.0051e-01, time/batch = 0.6962s	
2679/22750 (epoch 5.888), train_loss = 1.66071770, grad/param norm = 1.9296e-01, time/batch = 0.7054s	
2680/22750 (epoch 5.890), train_loss = 1.68800406, grad/param norm = 2.0540e-01, time/batch = 0.6954s	
2681/22750 (epoch 5.892), train_loss = 2.06185319, grad/param norm = 2.5081e-01, time/batch = 0.6819s	
2682/22750 (epoch 5.895), train_loss = 1.69948655, grad/param norm = 1.9575e-01, time/batch = 0.6997s	
2683/22750 (epoch 5.897), train_loss = 1.73805312, grad/param norm = 2.1872e-01, time/batch = 0.6938s	
2684/22750 (epoch 5.899), train_loss = 1.67320752, grad/param norm = 2.0411e-01, time/batch = 0.7102s	
2685/22750 (epoch 5.901), train_loss = 1.82061916, grad/param norm = 2.0721e-01, time/batch = 0.7249s	
2686/22750 (epoch 5.903), train_loss = 1.59801313, grad/param norm = 2.0361e-01, time/batch = 0.6967s	
2687/22750 (epoch 5.905), train_loss = 1.66355715, grad/param norm = 1.8311e-01, time/batch = 0.7134s	
2688/22750 (epoch 5.908), train_loss = 1.60782050, grad/param norm = 2.0962e-01, time/batch = 0.7127s	
2689/22750 (epoch 5.910), train_loss = 1.41510379, grad/param norm = 2.1444e-01, time/batch = 0.7125s	
2690/22750 (epoch 5.912), train_loss = 1.45334872, grad/param norm = 2.0971e-01, time/batch = 0.7015s	
2691/22750 (epoch 5.914), train_loss = 1.54205850, grad/param norm = 1.9632e-01, time/batch = 0.6916s	
2692/22750 (epoch 5.916), train_loss = 1.37468555, grad/param norm = 1.9058e-01, time/batch = 0.6975s	
2693/22750 (epoch 5.919), train_loss = 1.49930712, grad/param norm = 2.0450e-01, time/batch = 0.7208s	
2694/22750 (epoch 5.921), train_loss = 1.20530443, grad/param norm = 1.7375e-01, time/batch = 0.7241s	
2695/22750 (epoch 5.923), train_loss = 1.56198926, grad/param norm = 2.0364e-01, time/batch = 0.7223s	
2696/22750 (epoch 5.925), train_loss = 1.54179858, grad/param norm = 1.9761e-01, time/batch = 0.7248s	
2697/22750 (epoch 5.927), train_loss = 1.34254529, grad/param norm = 1.9418e-01, time/batch = 0.7117s	
2698/22750 (epoch 5.930), train_loss = 1.39074748, grad/param norm = 1.9650e-01, time/batch = 0.7173s	
2699/22750 (epoch 5.932), train_loss = 1.70550874, grad/param norm = 2.1105e-01, time/batch = 0.7260s	
2700/22750 (epoch 5.934), train_loss = 1.22064787, grad/param norm = 1.7761e-01, time/batch = 0.7026s	
2701/22750 (epoch 5.936), train_loss = 1.73664981, grad/param norm = 2.2876e-01, time/batch = 0.7092s	
2702/22750 (epoch 5.938), train_loss = 1.61956704, grad/param norm = 2.0625e-01, time/batch = 0.7116s	
2703/22750 (epoch 5.941), train_loss = 1.91582466, grad/param norm = 2.1744e-01, time/batch = 0.6989s	
2704/22750 (epoch 5.943), train_loss = 1.68577852, grad/param norm = 1.9831e-01, time/batch = 0.7001s	
2705/22750 (epoch 5.945), train_loss = 1.60762348, grad/param norm = 1.8720e-01, time/batch = 0.6961s	
2706/22750 (epoch 5.947), train_loss = 1.61292179, grad/param norm = 2.1674e-01, time/batch = 0.6977s	
2707/22750 (epoch 5.949), train_loss = 1.46817799, grad/param norm = 2.1616e-01, time/batch = 0.6928s	
2708/22750 (epoch 5.952), train_loss = 1.48685895, grad/param norm = 2.0301e-01, time/batch = 0.6944s	
2709/22750 (epoch 5.954), train_loss = 1.48761241, grad/param norm = 1.8943e-01, time/batch = 0.7042s	
2710/22750 (epoch 5.956), train_loss = 1.60132996, grad/param norm = 2.0021e-01, time/batch = 0.7023s	
2711/22750 (epoch 5.958), train_loss = 1.54278396, grad/param norm = 1.9165e-01, time/batch = 0.7012s	
2712/22750 (epoch 5.960), train_loss = 1.56481746, grad/param norm = 1.9484e-01, time/batch = 0.7052s	
2713/22750 (epoch 5.963), train_loss = 1.74925505, grad/param norm = 2.1466e-01, time/batch = 0.7241s	
2714/22750 (epoch 5.965), train_loss = 1.67499987, grad/param norm = 2.0930e-01, time/batch = 0.7205s	
2715/22750 (epoch 5.967), train_loss = 1.60880560, grad/param norm = 2.1567e-01, time/batch = 0.7174s	
2716/22750 (epoch 5.969), train_loss = 1.55132050, grad/param norm = 1.9977e-01, time/batch = 0.7192s	
2717/22750 (epoch 5.971), train_loss = 1.54211014, grad/param norm = 2.0227e-01, time/batch = 0.7208s	
2718/22750 (epoch 5.974), train_loss = 1.61416429, grad/param norm = 2.2899e-01, time/batch = 0.7244s	
2719/22750 (epoch 5.976), train_loss = 1.70753981, grad/param norm = 2.0810e-01, time/batch = 0.7132s	
2720/22750 (epoch 5.978), train_loss = 1.46409419, grad/param norm = 1.9299e-01, time/batch = 0.7086s	
2721/22750 (epoch 5.980), train_loss = 1.73665979, grad/param norm = 2.2599e-01, time/batch = 0.7199s	
2722/22750 (epoch 5.982), train_loss = 1.51219114, grad/param norm = 1.8031e-01, time/batch = 0.7252s	
2723/22750 (epoch 5.985), train_loss = 1.84092835, grad/param norm = 2.2675e-01, time/batch = 0.7241s	
2724/22750 (epoch 5.987), train_loss = 1.39445309, grad/param norm = 2.0067e-01, time/batch = 0.7254s	
2725/22750 (epoch 5.989), train_loss = 1.48828646, grad/param norm = 1.7992e-01, time/batch = 0.7136s	
2726/22750 (epoch 5.991), train_loss = 1.68414838, grad/param norm = 2.0095e-01, time/batch = 0.7120s	
2727/22750 (epoch 5.993), train_loss = 1.69007029, grad/param norm = 2.1087e-01, time/batch = 0.7173s	
2728/22750 (epoch 5.996), train_loss = 1.55786099, grad/param norm = 2.2190e-01, time/batch = 0.7222s	
2729/22750 (epoch 5.998), train_loss = 1.75366879, grad/param norm = 2.0737e-01, time/batch = 0.7227s	
2730/22750 (epoch 6.000), train_loss = 1.66215023, grad/param norm = 1.9808e-01, time/batch = 0.7241s	
2731/22750 (epoch 6.002), train_loss = 1.76133880, grad/param norm = 2.2459e-01, time/batch = 0.7250s	
2732/22750 (epoch 6.004), train_loss = 1.54447110, grad/param norm = 2.4394e-01, time/batch = 0.7262s	
2733/22750 (epoch 6.007), train_loss = 1.65647069, grad/param norm = 2.0808e-01, time/batch = 0.7166s	
2734/22750 (epoch 6.009), train_loss = 1.89476091, grad/param norm = 2.0551e-01, time/batch = 0.7074s	
2735/22750 (epoch 6.011), train_loss = 1.82857770, grad/param norm = 2.1264e-01, time/batch = 0.7008s	
2736/22750 (epoch 6.013), train_loss = 1.66819062, grad/param norm = 2.0206e-01, time/batch = 0.6987s	
2737/22750 (epoch 6.015), train_loss = 1.68029792, grad/param norm = 2.0802e-01, time/batch = 0.7038s	
2738/22750 (epoch 6.018), train_loss = 1.70584520, grad/param norm = 2.1202e-01, time/batch = 0.6977s	
2739/22750 (epoch 6.020), train_loss = 1.77756262, grad/param norm = 1.9965e-01, time/batch = 0.7031s	
2740/22750 (epoch 6.022), train_loss = 1.62384739, grad/param norm = 1.9403e-01, time/batch = 0.7018s	
2741/22750 (epoch 6.024), train_loss = 1.58781723, grad/param norm = 2.0561e-01, time/batch = 0.6951s	
2742/22750 (epoch 6.026), train_loss = 1.77734769, grad/param norm = 2.1501e-01, time/batch = 0.6958s	
2743/22750 (epoch 6.029), train_loss = 1.36744741, grad/param norm = 1.9029e-01, time/batch = 0.6986s	
2744/22750 (epoch 6.031), train_loss = 1.88597579, grad/param norm = 2.1074e-01, time/batch = 0.7054s	
2745/22750 (epoch 6.033), train_loss = 1.62232244, grad/param norm = 1.8912e-01, time/batch = 0.7213s	
2746/22750 (epoch 6.035), train_loss = 1.68508448, grad/param norm = 2.0383e-01, time/batch = 0.7238s	
2747/22750 (epoch 6.037), train_loss = 1.78015205, grad/param norm = 2.2591e-01, time/batch = 0.7251s	
2748/22750 (epoch 6.040), train_loss = 1.54025460, grad/param norm = 2.2527e-01, time/batch = 0.7223s	
2749/22750 (epoch 6.042), train_loss = 1.70748448, grad/param norm = 2.1280e-01, time/batch = 0.7202s	
2750/22750 (epoch 6.044), train_loss = 1.52097656, grad/param norm = 2.1305e-01, time/batch = 0.6983s	
2751/22750 (epoch 6.046), train_loss = 1.67132584, grad/param norm = 2.2556e-01, time/batch = 0.6981s	
2752/22750 (epoch 6.048), train_loss = 1.60262095, grad/param norm = 2.2084e-01, time/batch = 0.6945s	
2753/22750 (epoch 6.051), train_loss = 1.64613021, grad/param norm = 2.0710e-01, time/batch = 0.7028s	
2754/22750 (epoch 6.053), train_loss = 1.40245676, grad/param norm = 1.9303e-01, time/batch = 0.7040s	
2755/22750 (epoch 6.055), train_loss = 1.60616756, grad/param norm = 2.0271e-01, time/batch = 0.7037s	
2756/22750 (epoch 6.057), train_loss = 1.71539649, grad/param norm = 2.1717e-01, time/batch = 0.6992s	
2757/22750 (epoch 6.059), train_loss = 1.25854859, grad/param norm = 1.9867e-01, time/batch = 0.7140s	
2758/22750 (epoch 6.062), train_loss = 1.41256245, grad/param norm = 1.9561e-01, time/batch = 0.7240s	
2759/22750 (epoch 6.064), train_loss = 1.67959123, grad/param norm = 2.2908e-01, time/batch = 0.7222s	
2760/22750 (epoch 6.066), train_loss = 1.38046705, grad/param norm = 1.7498e-01, time/batch = 0.7128s	
2761/22750 (epoch 6.068), train_loss = 1.44285633, grad/param norm = 1.8499e-01, time/batch = 0.6959s	
2762/22750 (epoch 6.070), train_loss = 1.35217454, grad/param norm = 1.9791e-01, time/batch = 0.7001s	
2763/22750 (epoch 6.073), train_loss = 1.49414300, grad/param norm = 2.0653e-01, time/batch = 0.6966s	
2764/22750 (epoch 6.075), train_loss = 1.57132765, grad/param norm = 2.0175e-01, time/batch = 0.6940s	
2765/22750 (epoch 6.077), train_loss = 1.22467516, grad/param norm = 2.0197e-01, time/batch = 0.7132s	
2766/22750 (epoch 6.079), train_loss = 1.52947895, grad/param norm = 2.0239e-01, time/batch = 0.7128s	
2767/22750 (epoch 6.081), train_loss = 1.57889387, grad/param norm = 2.1170e-01, time/batch = 0.7124s	
2768/22750 (epoch 6.084), train_loss = 1.47636939, grad/param norm = 2.1478e-01, time/batch = 0.7216s	
2769/22750 (epoch 6.086), train_loss = 1.48202378, grad/param norm = 1.8963e-01, time/batch = 0.7276s	
2770/22750 (epoch 6.088), train_loss = 1.50868349, grad/param norm = 2.0458e-01, time/batch = 0.7098s	
2771/22750 (epoch 6.090), train_loss = 1.53349861, grad/param norm = 1.9247e-01, time/batch = 0.7324s	
2772/22750 (epoch 6.092), train_loss = 1.71588363, grad/param norm = 1.9895e-01, time/batch = 0.7109s	
2773/22750 (epoch 6.095), train_loss = 1.42624647, grad/param norm = 2.0243e-01, time/batch = 0.7079s	
2774/22750 (epoch 6.097), train_loss = 1.51107524, grad/param norm = 1.9727e-01, time/batch = 0.7090s	
2775/22750 (epoch 6.099), train_loss = 1.60016726, grad/param norm = 2.0793e-01, time/batch = 0.7103s	
2776/22750 (epoch 6.101), train_loss = 1.53877725, grad/param norm = 2.0291e-01, time/batch = 0.6954s	
2777/22750 (epoch 6.103), train_loss = 1.53544247, grad/param norm = 2.0977e-01, time/batch = 0.6966s	
2778/22750 (epoch 6.105), train_loss = 1.87170155, grad/param norm = 2.3250e-01, time/batch = 0.6991s	
2779/22750 (epoch 6.108), train_loss = 1.52184406, grad/param norm = 1.9712e-01, time/batch = 0.7151s	
2780/22750 (epoch 6.110), train_loss = 1.61444186, grad/param norm = 2.1098e-01, time/batch = 0.7073s	
2781/22750 (epoch 6.112), train_loss = 1.30099874, grad/param norm = 1.8690e-01, time/batch = 0.7031s	
2782/22750 (epoch 6.114), train_loss = 1.27774243, grad/param norm = 1.9653e-01, time/batch = 0.7006s	
2783/22750 (epoch 6.116), train_loss = 1.38634231, grad/param norm = 1.8210e-01, time/batch = 0.7066s	
2784/22750 (epoch 6.119), train_loss = 1.45001642, grad/param norm = 1.9661e-01, time/batch = 0.6975s	
2785/22750 (epoch 6.121), train_loss = 1.69797562, grad/param norm = 2.2608e-01, time/batch = 0.6954s	
2786/22750 (epoch 6.123), train_loss = 1.47561867, grad/param norm = 1.8310e-01, time/batch = 0.6992s	
2787/22750 (epoch 6.125), train_loss = 1.74930302, grad/param norm = 1.9961e-01, time/batch = 0.7003s	
2788/22750 (epoch 6.127), train_loss = 1.64248024, grad/param norm = 2.2135e-01, time/batch = 0.7075s	
2789/22750 (epoch 6.130), train_loss = 1.61809028, grad/param norm = 1.9527e-01, time/batch = 0.7215s	
2790/22750 (epoch 6.132), train_loss = 1.69510054, grad/param norm = 2.2866e-01, time/batch = 0.6984s	
2791/22750 (epoch 6.134), train_loss = 1.51007322, grad/param norm = 1.9686e-01, time/batch = 0.7048s	
2792/22750 (epoch 6.136), train_loss = 1.40262247, grad/param norm = 1.9649e-01, time/batch = 0.6945s	
2793/22750 (epoch 6.138), train_loss = 1.57602701, grad/param norm = 2.0666e-01, time/batch = 0.6977s	
2794/22750 (epoch 6.141), train_loss = 1.43659333, grad/param norm = 1.8898e-01, time/batch = 0.7023s	
2795/22750 (epoch 6.143), train_loss = 1.37995538, grad/param norm = 1.8166e-01, time/batch = 0.6989s	
2796/22750 (epoch 6.145), train_loss = 1.67305749, grad/param norm = 2.0000e-01, time/batch = 0.7054s	
2797/22750 (epoch 6.147), train_loss = 1.68129455, grad/param norm = 2.0747e-01, time/batch = 0.6950s	
2798/22750 (epoch 6.149), train_loss = 1.57050076, grad/param norm = 2.0854e-01, time/batch = 0.6972s	
2799/22750 (epoch 6.152), train_loss = 1.49247633, grad/param norm = 2.0237e-01, time/batch = 0.7073s	
2800/22750 (epoch 6.154), train_loss = 1.31276602, grad/param norm = 1.8782e-01, time/batch = 0.7143s	
2801/22750 (epoch 6.156), train_loss = 1.42033550, grad/param norm = 2.0944e-01, time/batch = 0.7219s	
2802/22750 (epoch 6.158), train_loss = 1.51294647, grad/param norm = 2.1165e-01, time/batch = 0.7250s	
2803/22750 (epoch 6.160), train_loss = 1.62396431, grad/param norm = 2.1355e-01, time/batch = 0.7248s	
2804/22750 (epoch 6.163), train_loss = 1.82481295, grad/param norm = 2.1890e-01, time/batch = 0.7081s	
2805/22750 (epoch 6.165), train_loss = 1.69076884, grad/param norm = 2.0320e-01, time/batch = 0.7051s	
2806/22750 (epoch 6.167), train_loss = 1.48816558, grad/param norm = 1.9717e-01, time/batch = 0.7044s	
2807/22750 (epoch 6.169), train_loss = 1.61580444, grad/param norm = 2.0583e-01, time/batch = 0.7253s	
2808/22750 (epoch 6.171), train_loss = 1.44019821, grad/param norm = 2.0171e-01, time/batch = 0.7216s	
2809/22750 (epoch 6.174), train_loss = 1.29265828, grad/param norm = 1.8798e-01, time/batch = 0.7261s	
2810/22750 (epoch 6.176), train_loss = 1.57924642, grad/param norm = 1.8875e-01, time/batch = 0.7244s	
2811/22750 (epoch 6.178), train_loss = 1.51980828, grad/param norm = 1.9022e-01, time/batch = 0.7192s	
2812/22750 (epoch 6.180), train_loss = 1.68684179, grad/param norm = 2.3095e-01, time/batch = 0.7237s	
2813/22750 (epoch 6.182), train_loss = 1.64922641, grad/param norm = 1.9387e-01, time/batch = 0.7234s	
2814/22750 (epoch 6.185), train_loss = 1.65510529, grad/param norm = 2.1639e-01, time/batch = 0.7226s	
2815/22750 (epoch 6.187), train_loss = 1.43543506, grad/param norm = 1.9194e-01, time/batch = 0.7142s	
2816/22750 (epoch 6.189), train_loss = 1.46420872, grad/param norm = 1.9780e-01, time/batch = 0.7257s	
2817/22750 (epoch 6.191), train_loss = 1.38519921, grad/param norm = 1.8111e-01, time/batch = 0.7219s	
2818/22750 (epoch 6.193), train_loss = 1.65454255, grad/param norm = 2.0356e-01, time/batch = 0.7248s	
2819/22750 (epoch 6.196), train_loss = 1.53937975, grad/param norm = 2.0234e-01, time/batch = 0.7198s	
2820/22750 (epoch 6.198), train_loss = 1.28506918, grad/param norm = 1.6689e-01, time/batch = 0.7228s	
2821/22750 (epoch 6.200), train_loss = 1.59541903, grad/param norm = 1.9778e-01, time/batch = 0.7253s	
2822/22750 (epoch 6.202), train_loss = 1.77547341, grad/param norm = 2.2494e-01, time/batch = 0.7152s	
2823/22750 (epoch 6.204), train_loss = 1.71606804, grad/param norm = 2.1084e-01, time/batch = 0.7182s	
2824/22750 (epoch 6.207), train_loss = 1.51326043, grad/param norm = 2.0324e-01, time/batch = 0.7143s	
2825/22750 (epoch 6.209), train_loss = 1.43325701, grad/param norm = 2.0274e-01, time/batch = 0.6994s	
2826/22750 (epoch 6.211), train_loss = 1.54943963, grad/param norm = 2.1168e-01, time/batch = 0.6995s	
2827/22750 (epoch 6.213), train_loss = 1.41875018, grad/param norm = 2.0021e-01, time/batch = 0.7047s	
2828/22750 (epoch 6.215), train_loss = 1.43117890, grad/param norm = 2.0110e-01, time/batch = 0.6996s	
2829/22750 (epoch 6.218), train_loss = 1.35943153, grad/param norm = 2.2389e-01, time/batch = 0.7009s	
2830/22750 (epoch 6.220), train_loss = 1.56749557, grad/param norm = 2.3721e-01, time/batch = 0.6953s	
2831/22750 (epoch 6.222), train_loss = 1.37991106, grad/param norm = 2.1130e-01, time/batch = 0.7009s	
2832/22750 (epoch 6.224), train_loss = 1.46640320, grad/param norm = 1.9714e-01, time/batch = 0.7107s	
2833/22750 (epoch 6.226), train_loss = 1.61613152, grad/param norm = 2.1819e-01, time/batch = 0.7025s	
2834/22750 (epoch 6.229), train_loss = 1.60967613, grad/param norm = 2.0793e-01, time/batch = 0.7040s	
2835/22750 (epoch 6.231), train_loss = 1.51163531, grad/param norm = 1.9747e-01, time/batch = 0.7070s	
2836/22750 (epoch 6.233), train_loss = 1.42486488, grad/param norm = 1.9031e-01, time/batch = 0.7015s	
2837/22750 (epoch 6.235), train_loss = 1.40905632, grad/param norm = 2.0107e-01, time/batch = 0.7106s	
2838/22750 (epoch 6.237), train_loss = 1.46679027, grad/param norm = 2.0267e-01, time/batch = 0.7063s	
2839/22750 (epoch 6.240), train_loss = 1.65173509, grad/param norm = 1.8782e-01, time/batch = 0.6987s	
2840/22750 (epoch 6.242), train_loss = 1.98029069, grad/param norm = 2.3459e-01, time/batch = 0.7093s	
2841/22750 (epoch 6.244), train_loss = 1.76854262, grad/param norm = 2.3609e-01, time/batch = 0.6977s	
2842/22750 (epoch 6.246), train_loss = 1.82945777, grad/param norm = 2.0361e-01, time/batch = 0.7075s	
2843/22750 (epoch 6.248), train_loss = 1.53026087, grad/param norm = 2.0806e-01, time/batch = 0.7048s	
2844/22750 (epoch 6.251), train_loss = 1.78797002, grad/param norm = 2.0312e-01, time/batch = 0.7022s	
2845/22750 (epoch 6.253), train_loss = 1.60974534, grad/param norm = 2.0250e-01, time/batch = 0.7068s	
2846/22750 (epoch 6.255), train_loss = 1.61544867, grad/param norm = 1.9652e-01, time/batch = 0.6995s	
2847/22750 (epoch 6.257), train_loss = 1.55444197, grad/param norm = 2.0329e-01, time/batch = 0.7183s	
2848/22750 (epoch 6.259), train_loss = 1.74694222, grad/param norm = 2.2314e-01, time/batch = 0.7222s	
2849/22750 (epoch 6.262), train_loss = 1.57013699, grad/param norm = 2.1416e-01, time/batch = 0.6980s	
2850/22750 (epoch 6.264), train_loss = 1.47208176, grad/param norm = 2.0021e-01, time/batch = 0.7059s	
2851/22750 (epoch 6.266), train_loss = 1.59118542, grad/param norm = 2.1579e-01, time/batch = 0.6994s	
2852/22750 (epoch 6.268), train_loss = 1.70217315, grad/param norm = 1.9978e-01, time/batch = 0.7232s	
2853/22750 (epoch 6.270), train_loss = 1.50378638, grad/param norm = 2.0480e-01, time/batch = 0.7250s	
2854/22750 (epoch 6.273), train_loss = 1.82556008, grad/param norm = 2.3321e-01, time/batch = 0.7254s	
2855/22750 (epoch 6.275), train_loss = 1.60126990, grad/param norm = 2.0644e-01, time/batch = 0.7247s	
2856/22750 (epoch 6.277), train_loss = 1.58490669, grad/param norm = 2.0116e-01, time/batch = 0.7356s	
2857/22750 (epoch 6.279), train_loss = 1.37354571, grad/param norm = 1.7814e-01, time/batch = 0.7228s	
2858/22750 (epoch 6.281), train_loss = 1.61784988, grad/param norm = 1.9462e-01, time/batch = 0.7203s	
2859/22750 (epoch 6.284), train_loss = 1.46344310, grad/param norm = 1.7543e-01, time/batch = 0.7232s	
2860/22750 (epoch 6.286), train_loss = 1.67672673, grad/param norm = 2.0279e-01, time/batch = 0.7246s	
2861/22750 (epoch 6.288), train_loss = 1.75109244, grad/param norm = 2.0355e-01, time/batch = 0.7204s	
2862/22750 (epoch 6.290), train_loss = 1.46698478, grad/param norm = 1.7861e-01, time/batch = 0.7160s	
2863/22750 (epoch 6.292), train_loss = 1.55736158, grad/param norm = 2.1536e-01, time/batch = 0.7213s	
2864/22750 (epoch 6.295), train_loss = 1.55363935, grad/param norm = 1.8672e-01, time/batch = 0.7218s	
2865/22750 (epoch 6.297), train_loss = 1.49436918, grad/param norm = 1.9681e-01, time/batch = 0.7205s	
2866/22750 (epoch 6.299), train_loss = 1.71541442, grad/param norm = 1.9748e-01, time/batch = 0.7247s	
2867/22750 (epoch 6.301), train_loss = 1.63195934, grad/param norm = 2.0295e-01, time/batch = 0.7190s	
2868/22750 (epoch 6.303), train_loss = 1.70751224, grad/param norm = 2.2195e-01, time/batch = 0.7010s	
2869/22750 (epoch 6.305), train_loss = 1.76287402, grad/param norm = 2.0938e-01, time/batch = 0.7103s	
2870/22750 (epoch 6.308), train_loss = 1.62171439, grad/param norm = 2.0148e-01, time/batch = 0.7146s	
2871/22750 (epoch 6.310), train_loss = 1.53551974, grad/param norm = 2.1508e-01, time/batch = 0.7151s	
2872/22750 (epoch 6.312), train_loss = 1.59996337, grad/param norm = 2.0776e-01, time/batch = 0.7163s	
2873/22750 (epoch 6.314), train_loss = 1.55581814, grad/param norm = 1.9582e-01, time/batch = 0.7110s	
2874/22750 (epoch 6.316), train_loss = 1.48790492, grad/param norm = 1.8625e-01, time/batch = 0.6910s	
2875/22750 (epoch 6.319), train_loss = 1.63479685, grad/param norm = 1.9445e-01, time/batch = 0.6954s	
2876/22750 (epoch 6.321), train_loss = 1.53637810, grad/param norm = 2.1119e-01, time/batch = 0.7055s	
2877/22750 (epoch 6.323), train_loss = 1.52927731, grad/param norm = 2.2230e-01, time/batch = 0.7150s	
2878/22750 (epoch 6.325), train_loss = 1.27476484, grad/param norm = 1.9778e-01, time/batch = 0.6989s	
2879/22750 (epoch 6.327), train_loss = 1.60893858, grad/param norm = 1.9842e-01, time/batch = 0.6960s	
2880/22750 (epoch 6.330), train_loss = 1.86340252, grad/param norm = 2.0378e-01, time/batch = 0.7231s	
2881/22750 (epoch 6.332), train_loss = 1.67705146, grad/param norm = 1.9694e-01, time/batch = 0.7163s	
2882/22750 (epoch 6.334), train_loss = 1.29589763, grad/param norm = 1.8446e-01, time/batch = 0.7174s	
2883/22750 (epoch 6.336), train_loss = 1.62269474, grad/param norm = 1.9409e-01, time/batch = 0.7119s	
2884/22750 (epoch 6.338), train_loss = 1.53395187, grad/param norm = 1.9381e-01, time/batch = 0.7035s	
2885/22750 (epoch 6.341), train_loss = 1.50945641, grad/param norm = 1.9821e-01, time/batch = 0.7106s	
2886/22750 (epoch 6.343), train_loss = 1.36640258, grad/param norm = 2.0276e-01, time/batch = 0.7157s	
2887/22750 (epoch 6.345), train_loss = 1.73386217, grad/param norm = 2.2216e-01, time/batch = 0.7179s	
2888/22750 (epoch 6.347), train_loss = 1.69664348, grad/param norm = 2.1013e-01, time/batch = 0.7157s	
2889/22750 (epoch 6.349), train_loss = 1.27533787, grad/param norm = 1.9959e-01, time/batch = 0.7134s	
2890/22750 (epoch 6.352), train_loss = 1.67052961, grad/param norm = 2.1734e-01, time/batch = 0.6957s	
2891/22750 (epoch 6.354), train_loss = 1.76611940, grad/param norm = 2.1212e-01, time/batch = 0.7107s	
2892/22750 (epoch 6.356), train_loss = 1.75743113, grad/param norm = 1.9459e-01, time/batch = 0.7139s	
2893/22750 (epoch 6.358), train_loss = 1.53686025, grad/param norm = 2.1518e-01, time/batch = 0.7130s	
2894/22750 (epoch 6.360), train_loss = 1.79108359, grad/param norm = 2.2213e-01, time/batch = 0.7177s	
2895/22750 (epoch 6.363), train_loss = 1.55673743, grad/param norm = 1.9777e-01, time/batch = 0.6993s	
2896/22750 (epoch 6.365), train_loss = 1.31105372, grad/param norm = 1.9955e-01, time/batch = 0.7062s	
2897/22750 (epoch 6.367), train_loss = 1.31371943, grad/param norm = 1.8368e-01, time/batch = 0.7036s	
2898/22750 (epoch 6.369), train_loss = 1.51425260, grad/param norm = 2.2202e-01, time/batch = 0.7005s	
2899/22750 (epoch 6.371), train_loss = 1.48354929, grad/param norm = 2.0056e-01, time/batch = 0.6930s	
2900/22750 (epoch 6.374), train_loss = 1.37520359, grad/param norm = 2.1608e-01, time/batch = 0.6892s	
2901/22750 (epoch 6.376), train_loss = 1.58312636, grad/param norm = 1.9309e-01, time/batch = 0.6985s	
2902/22750 (epoch 6.378), train_loss = 1.51753566, grad/param norm = 2.0214e-01, time/batch = 0.6939s	
2903/22750 (epoch 6.380), train_loss = 1.70752090, grad/param norm = 2.0322e-01, time/batch = 0.6902s	
2904/22750 (epoch 6.382), train_loss = 1.46775857, grad/param norm = 1.8982e-01, time/batch = 0.6881s	
2905/22750 (epoch 6.385), train_loss = 1.59247524, grad/param norm = 1.7890e-01, time/batch = 0.6927s	
2906/22750 (epoch 6.387), train_loss = 1.63912004, grad/param norm = 2.0012e-01, time/batch = 0.7123s	
2907/22750 (epoch 6.389), train_loss = 1.18718957, grad/param norm = 1.9459e-01, time/batch = 0.7226s	
2908/22750 (epoch 6.391), train_loss = 1.01987737, grad/param norm = 1.6432e-01, time/batch = 0.7160s	
2909/22750 (epoch 6.393), train_loss = 1.35978413, grad/param norm = 1.9256e-01, time/batch = 0.6995s	
2910/22750 (epoch 6.396), train_loss = 1.53426640, grad/param norm = 2.1249e-01, time/batch = 0.7148s	
2911/22750 (epoch 6.398), train_loss = 1.52922307, grad/param norm = 2.0823e-01, time/batch = 0.7236s	
2912/22750 (epoch 6.400), train_loss = 1.53118295, grad/param norm = 1.8878e-01, time/batch = 0.7194s	
2913/22750 (epoch 6.402), train_loss = 1.55816778, grad/param norm = 1.9329e-01, time/batch = 0.7106s	
2914/22750 (epoch 6.404), train_loss = 1.77927009, grad/param norm = 2.0342e-01, time/batch = 0.6967s	
2915/22750 (epoch 6.407), train_loss = 1.66836113, grad/param norm = 1.9413e-01, time/batch = 0.6889s	
2916/22750 (epoch 6.409), train_loss = 1.54084741, grad/param norm = 1.9900e-01, time/batch = 0.7176s	
2917/22750 (epoch 6.411), train_loss = 1.54952049, grad/param norm = 1.9089e-01, time/batch = 0.7043s	
2918/22750 (epoch 6.413), train_loss = 1.39874524, grad/param norm = 2.0388e-01, time/batch = 0.6916s	
2919/22750 (epoch 6.415), train_loss = 1.31226653, grad/param norm = 2.1058e-01, time/batch = 0.6941s	
2920/22750 (epoch 6.418), train_loss = 1.51390547, grad/param norm = 1.9605e-01, time/batch = 0.6911s	
2921/22750 (epoch 6.420), train_loss = 1.79092269, grad/param norm = 2.3034e-01, time/batch = 0.6967s	
2922/22750 (epoch 6.422), train_loss = 1.88069177, grad/param norm = 2.2357e-01, time/batch = 0.7182s	
2923/22750 (epoch 6.424), train_loss = 1.87112102, grad/param norm = 2.3840e-01, time/batch = 0.6951s	
2924/22750 (epoch 6.426), train_loss = 1.80530267, grad/param norm = 2.0021e-01, time/batch = 0.6970s	
2925/22750 (epoch 6.429), train_loss = 1.30047278, grad/param norm = 1.9840e-01, time/batch = 0.6933s	
2926/22750 (epoch 6.431), train_loss = 1.29756794, grad/param norm = 1.8668e-01, time/batch = 0.6946s	
2927/22750 (epoch 6.433), train_loss = 1.40547251, grad/param norm = 1.8575e-01, time/batch = 0.6955s	
2928/22750 (epoch 6.435), train_loss = 1.28186965, grad/param norm = 1.9791e-01, time/batch = 0.6962s	
2929/22750 (epoch 6.437), train_loss = 1.19754483, grad/param norm = 1.7791e-01, time/batch = 0.7017s	
2930/22750 (epoch 6.440), train_loss = 1.70100641, grad/param norm = 2.0733e-01, time/batch = 0.7158s	
2931/22750 (epoch 6.442), train_loss = 1.55491321, grad/param norm = 2.0105e-01, time/batch = 0.7156s	
2932/22750 (epoch 6.444), train_loss = 1.59187963, grad/param norm = 2.4878e-01, time/batch = 0.6912s	
2933/22750 (epoch 6.446), train_loss = 1.55497197, grad/param norm = 2.2031e-01, time/batch = 0.6893s	
2934/22750 (epoch 6.448), train_loss = 1.84074664, grad/param norm = 2.2641e-01, time/batch = 0.6978s	
2935/22750 (epoch 6.451), train_loss = 1.75428124, grad/param norm = 2.2627e-01, time/batch = 0.6963s	
2936/22750 (epoch 6.453), train_loss = 1.85629838, grad/param norm = 2.4824e-01, time/batch = 0.7110s	
2937/22750 (epoch 6.455), train_loss = 1.91171065, grad/param norm = 2.1112e-01, time/batch = 0.7090s	
2938/22750 (epoch 6.457), train_loss = 1.72881045, grad/param norm = 2.3450e-01, time/batch = 0.7059s	
2939/22750 (epoch 6.459), train_loss = 1.61585023, grad/param norm = 1.9382e-01, time/batch = 0.7120s	
2940/22750 (epoch 6.462), train_loss = 1.61717871, grad/param norm = 1.7236e-01, time/batch = 0.6912s	
2941/22750 (epoch 6.464), train_loss = 1.39163619, grad/param norm = 1.8291e-01, time/batch = 0.7043s	
2942/22750 (epoch 6.466), train_loss = 1.83034427, grad/param norm = 2.2424e-01, time/batch = 0.6852s	
2943/22750 (epoch 6.468), train_loss = 1.52214492, grad/param norm = 2.0887e-01, time/batch = 0.6855s	
2944/22750 (epoch 6.470), train_loss = 1.74414115, grad/param norm = 2.2684e-01, time/batch = 0.6837s	
2945/22750 (epoch 6.473), train_loss = 1.56799325, grad/param norm = 2.0670e-01, time/batch = 0.6909s	
2946/22750 (epoch 6.475), train_loss = 1.63599452, grad/param norm = 2.0937e-01, time/batch = 0.6826s	
2947/22750 (epoch 6.477), train_loss = 1.36580820, grad/param norm = 1.8651e-01, time/batch = 0.6817s	
2948/22750 (epoch 6.479), train_loss = 1.40462422, grad/param norm = 1.9061e-01, time/batch = 0.6864s	
2949/22750 (epoch 6.481), train_loss = 1.35138543, grad/param norm = 2.0318e-01, time/batch = 0.6864s	
2950/22750 (epoch 6.484), train_loss = 1.18735190, grad/param norm = 1.8919e-01, time/batch = 0.6891s	
2951/22750 (epoch 6.486), train_loss = 1.43658159, grad/param norm = 2.1935e-01, time/batch = 0.6896s	
2952/22750 (epoch 6.488), train_loss = 1.19365790, grad/param norm = 2.1098e-01, time/batch = 0.7089s	
2953/22750 (epoch 6.490), train_loss = 1.45340856, grad/param norm = 1.9842e-01, time/batch = 0.6882s	
2954/22750 (epoch 6.492), train_loss = 1.70767315, grad/param norm = 2.1384e-01, time/batch = 0.6957s	
2955/22750 (epoch 6.495), train_loss = 1.46265677, grad/param norm = 2.1421e-01, time/batch = 0.7116s	
2956/22750 (epoch 6.497), train_loss = 1.63867628, grad/param norm = 2.2045e-01, time/batch = 0.6961s	
2957/22750 (epoch 6.499), train_loss = 1.50729564, grad/param norm = 2.0699e-01, time/batch = 0.7071s	
2958/22750 (epoch 6.501), train_loss = 1.57378045, grad/param norm = 2.0926e-01, time/batch = 0.6909s	
2959/22750 (epoch 6.503), train_loss = 1.53078652, grad/param norm = 2.0364e-01, time/batch = 0.6848s	
2960/22750 (epoch 6.505), train_loss = 1.36890475, grad/param norm = 1.8181e-01, time/batch = 0.7020s	
2961/22750 (epoch 6.508), train_loss = 1.33365590, grad/param norm = 2.0007e-01, time/batch = 0.7065s	
2962/22750 (epoch 6.510), train_loss = 1.35423334, grad/param norm = 1.7999e-01, time/batch = 0.6867s	
2963/22750 (epoch 6.512), train_loss = 1.43076898, grad/param norm = 1.8394e-01, time/batch = 0.6952s	
2964/22750 (epoch 6.514), train_loss = 1.43101541, grad/param norm = 1.8401e-01, time/batch = 0.6944s	
2965/22750 (epoch 6.516), train_loss = 1.38640237, grad/param norm = 1.8739e-01, time/batch = 0.6929s	
2966/22750 (epoch 6.519), train_loss = 1.60585690, grad/param norm = 2.2547e-01, time/batch = 0.6837s	
2967/22750 (epoch 6.521), train_loss = 1.43550192, grad/param norm = 2.1537e-01, time/batch = 0.6810s	
2968/22750 (epoch 6.523), train_loss = 1.47822256, grad/param norm = 2.3740e-01, time/batch = 0.6859s	
2969/22750 (epoch 6.525), train_loss = 1.73629224, grad/param norm = 2.3307e-01, time/batch = 0.6852s	
2970/22750 (epoch 6.527), train_loss = 1.55886747, grad/param norm = 2.0434e-01, time/batch = 0.6872s	
2971/22750 (epoch 6.530), train_loss = 1.42401064, grad/param norm = 2.0906e-01, time/batch = 0.6848s	
2972/22750 (epoch 6.532), train_loss = 1.40213476, grad/param norm = 1.7400e-01, time/batch = 0.6871s	
2973/22750 (epoch 6.534), train_loss = 1.66047400, grad/param norm = 2.2463e-01, time/batch = 0.6835s	
2974/22750 (epoch 6.536), train_loss = 1.53417036, grad/param norm = 1.9883e-01, time/batch = 0.6868s	
2975/22750 (epoch 6.538), train_loss = 1.57016511, grad/param norm = 1.7873e-01, time/batch = 0.6869s	
2976/22750 (epoch 6.541), train_loss = 1.30504257, grad/param norm = 1.9857e-01, time/batch = 0.6856s	
2977/22750 (epoch 6.543), train_loss = 1.31348390, grad/param norm = 1.8109e-01, time/batch = 0.6838s	
2978/22750 (epoch 6.545), train_loss = 1.68605876, grad/param norm = 2.1001e-01, time/batch = 0.6827s	
2979/22750 (epoch 6.547), train_loss = 1.32356555, grad/param norm = 1.7933e-01, time/batch = 0.6855s	
2980/22750 (epoch 6.549), train_loss = 1.41071505, grad/param norm = 2.0832e-01, time/batch = 0.6839s	
2981/22750 (epoch 6.552), train_loss = 1.62459943, grad/param norm = 2.2443e-01, time/batch = 0.6863s	
2982/22750 (epoch 6.554), train_loss = 1.67996914, grad/param norm = 2.1592e-01, time/batch = 0.6856s	
2983/22750 (epoch 6.556), train_loss = 1.49930790, grad/param norm = 2.0455e-01, time/batch = 0.6780s	
2984/22750 (epoch 6.558), train_loss = 1.70190342, grad/param norm = 1.9213e-01, time/batch = 0.6827s	
2985/22750 (epoch 6.560), train_loss = 1.39466360, grad/param norm = 1.8240e-01, time/batch = 0.6828s	
2986/22750 (epoch 6.563), train_loss = 1.60931555, grad/param norm = 1.9722e-01, time/batch = 0.6865s	
2987/22750 (epoch 6.565), train_loss = 1.70705372, grad/param norm = 1.9662e-01, time/batch = 0.6854s	
2988/22750 (epoch 6.567), train_loss = 1.53691961, grad/param norm = 1.9845e-01, time/batch = 0.6911s	
2989/22750 (epoch 6.569), train_loss = 1.46971665, grad/param norm = 1.9954e-01, time/batch = 0.6810s	
2990/22750 (epoch 6.571), train_loss = 1.57528834, grad/param norm = 1.9783e-01, time/batch = 0.6863s	
2991/22750 (epoch 6.574), train_loss = 1.38043427, grad/param norm = 2.0540e-01, time/batch = 0.7093s	
2992/22750 (epoch 6.576), train_loss = 1.55072821, grad/param norm = 1.8423e-01, time/batch = 0.6910s	
2993/22750 (epoch 6.578), train_loss = 1.34031864, grad/param norm = 1.7601e-01, time/batch = 0.6910s	
2994/22750 (epoch 6.580), train_loss = 1.60481640, grad/param norm = 2.1233e-01, time/batch = 0.6836s	
2995/22750 (epoch 6.582), train_loss = 1.29554637, grad/param norm = 1.8562e-01, time/batch = 0.6842s	
2996/22750 (epoch 6.585), train_loss = 1.23929940, grad/param norm = 1.8502e-01, time/batch = 0.6874s	
2997/22750 (epoch 6.587), train_loss = 1.31712436, grad/param norm = 1.7178e-01, time/batch = 0.6849s	
2998/22750 (epoch 6.589), train_loss = 1.32483595, grad/param norm = 2.0213e-01, time/batch = 0.6847s	
2999/22750 (epoch 6.591), train_loss = 1.53840738, grad/param norm = 2.1049e-01, time/batch = 0.6865s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_wakata_epoch6.59_1.5944.t7	
3000/22750 (epoch 6.593), train_loss = 1.73725790, grad/param norm = 1.9347e-01, time/batch = 0.6864s	
3001/22750 (epoch 6.596), train_loss = 1.98168891, grad/param norm = 2.1507e-01, time/batch = 0.6939s	
3002/22750 (epoch 6.598), train_loss = 1.74543127, grad/param norm = 2.1511e-01, time/batch = 0.6940s	
3003/22750 (epoch 6.600), train_loss = 1.62283598, grad/param norm = 2.0574e-01, time/batch = 0.6879s	
3004/22750 (epoch 6.602), train_loss = 1.35009283, grad/param norm = 1.6635e-01, time/batch = 0.7026s	
3005/22750 (epoch 6.604), train_loss = 1.46712692, grad/param norm = 1.8217e-01, time/batch = 0.7069s	
3006/22750 (epoch 6.607), train_loss = 1.22348137, grad/param norm = 1.6516e-01, time/batch = 0.6876s	
3007/22750 (epoch 6.609), train_loss = 1.17947252, grad/param norm = 1.5988e-01, time/batch = 0.6910s	
3008/22750 (epoch 6.611), train_loss = 1.44277902, grad/param norm = 2.0711e-01, time/batch = 0.6879s	
3009/22750 (epoch 6.613), train_loss = 1.35210818, grad/param norm = 2.0255e-01, time/batch = 0.6953s	
3010/22750 (epoch 6.615), train_loss = 1.44158867, grad/param norm = 1.9090e-01, time/batch = 0.6887s	
3011/22750 (epoch 6.618), train_loss = 1.50791965, grad/param norm = 2.0464e-01, time/batch = 0.7273s	
3012/22750 (epoch 6.620), train_loss = 1.50187061, grad/param norm = 1.9393e-01, time/batch = 0.7092s	
3013/22750 (epoch 6.622), train_loss = 1.31050372, grad/param norm = 2.0497e-01, time/batch = 0.7117s	
3014/22750 (epoch 6.624), train_loss = 1.58485278, grad/param norm = 2.1325e-01, time/batch = 0.7127s	
3015/22750 (epoch 6.626), train_loss = 1.38156847, grad/param norm = 2.0776e-01, time/batch = 0.7136s	
3016/22750 (epoch 6.629), train_loss = 1.51882378, grad/param norm = 2.1260e-01, time/batch = 0.7113s	
3017/22750 (epoch 6.631), train_loss = 1.55614918, grad/param norm = 2.0903e-01, time/batch = 0.7168s	
3018/22750 (epoch 6.633), train_loss = 1.25799672, grad/param norm = 2.0789e-01, time/batch = 0.7276s	
3019/22750 (epoch 6.635), train_loss = 1.58099483, grad/param norm = 2.1089e-01, time/batch = 0.7115s	
3020/22750 (epoch 6.637), train_loss = 1.62517606, grad/param norm = 2.0281e-01, time/batch = 0.6923s	
3021/22750 (epoch 6.640), train_loss = 1.69661257, grad/param norm = 2.2983e-01, time/batch = 0.6827s	
3022/22750 (epoch 6.642), train_loss = 1.66610913, grad/param norm = 2.0829e-01, time/batch = 0.6879s	
3023/22750 (epoch 6.644), train_loss = 1.52199039, grad/param norm = 1.9691e-01, time/batch = 0.6901s	
3024/22750 (epoch 6.646), train_loss = 1.66909559, grad/param norm = 2.1321e-01, time/batch = 0.6897s	
3025/22750 (epoch 6.648), train_loss = 1.57056500, grad/param norm = 2.1554e-01, time/batch = 0.6779s	
3026/22750 (epoch 6.651), train_loss = 1.65861297, grad/param norm = 2.1007e-01, time/batch = 0.6838s	
3027/22750 (epoch 6.653), train_loss = 1.55069798, grad/param norm = 1.9332e-01, time/batch = 0.6874s	
3028/22750 (epoch 6.655), train_loss = 1.51122809, grad/param norm = 1.9742e-01, time/batch = 0.6950s	
3029/22750 (epoch 6.657), train_loss = 1.72185989, grad/param norm = 1.9862e-01, time/batch = 0.6835s	
3030/22750 (epoch 6.659), train_loss = 1.78078151, grad/param norm = 1.9701e-01, time/batch = 0.6889s	
3031/22750 (epoch 6.662), train_loss = 1.84386325, grad/param norm = 2.2506e-01, time/batch = 0.6942s	
3032/22750 (epoch 6.664), train_loss = 1.61675537, grad/param norm = 2.1286e-01, time/batch = 0.6925s	
3033/22750 (epoch 6.666), train_loss = 1.38618101, grad/param norm = 1.9006e-01, time/batch = 0.6863s	
3034/22750 (epoch 6.668), train_loss = 1.55105178, grad/param norm = 1.9160e-01, time/batch = 0.6867s	
3035/22750 (epoch 6.670), train_loss = 1.56751129, grad/param norm = 2.0279e-01, time/batch = 0.6885s	
3036/22750 (epoch 6.673), train_loss = 1.79151319, grad/param norm = 2.2876e-01, time/batch = 0.6884s	
3037/22750 (epoch 6.675), train_loss = 2.03799117, grad/param norm = 2.3820e-01, time/batch = 0.6862s	
3038/22750 (epoch 6.677), train_loss = 1.79086853, grad/param norm = 2.1442e-01, time/batch = 0.7068s	
3039/22750 (epoch 6.679), train_loss = 1.84815362, grad/param norm = 2.2108e-01, time/batch = 0.7024s	
3040/22750 (epoch 6.681), train_loss = 1.72547401, grad/param norm = 2.1390e-01, time/batch = 0.6900s	
3041/22750 (epoch 6.684), train_loss = 1.70048552, grad/param norm = 1.9856e-01, time/batch = 0.6903s	
3042/22750 (epoch 6.686), train_loss = 1.70118894, grad/param norm = 2.1701e-01, time/batch = 0.6913s	
3043/22750 (epoch 6.688), train_loss = 1.66976317, grad/param norm = 2.0743e-01, time/batch = 0.6909s	
3044/22750 (epoch 6.690), train_loss = 1.63737104, grad/param norm = 2.0771e-01, time/batch = 0.6842s	
3045/22750 (epoch 6.692), train_loss = 1.79711343, grad/param norm = 2.2257e-01, time/batch = 0.6847s	
3046/22750 (epoch 6.695), train_loss = 1.55779181, grad/param norm = 1.9922e-01, time/batch = 0.6810s	
3047/22750 (epoch 6.697), train_loss = 1.51959501, grad/param norm = 2.2760e-01, time/batch = 0.6768s	
3048/22750 (epoch 6.699), train_loss = 1.57854085, grad/param norm = 1.9107e-01, time/batch = 0.6813s	
3049/22750 (epoch 6.701), train_loss = 1.41736056, grad/param norm = 1.9923e-01, time/batch = 0.6864s	
3050/22750 (epoch 6.703), train_loss = 1.58990943, grad/param norm = 1.9301e-01, time/batch = 0.6880s	
3051/22750 (epoch 6.705), train_loss = 1.39694257, grad/param norm = 1.7122e-01, time/batch = 0.6968s	
3052/22750 (epoch 6.708), train_loss = 1.56336657, grad/param norm = 1.7303e-01, time/batch = 0.6926s	
3053/22750 (epoch 6.710), train_loss = 1.32596989, grad/param norm = 2.0438e-01, time/batch = 0.6875s	
3054/22750 (epoch 6.712), train_loss = 1.43234922, grad/param norm = 1.9973e-01, time/batch = 0.6867s	
3055/22750 (epoch 6.714), train_loss = 1.31355251, grad/param norm = 1.8989e-01, time/batch = 0.6846s	
3056/22750 (epoch 6.716), train_loss = 1.42151852, grad/param norm = 2.0066e-01, time/batch = 0.6828s	
3057/22750 (epoch 6.719), train_loss = 1.66718979, grad/param norm = 2.4341e-01, time/batch = 0.6833s	
3058/22750 (epoch 6.721), train_loss = 1.61696613, grad/param norm = 2.1127e-01, time/batch = 0.6808s	
3059/22750 (epoch 6.723), train_loss = 1.52494059, grad/param norm = 1.9936e-01, time/batch = 0.6850s	
3060/22750 (epoch 6.725), train_loss = 1.53511543, grad/param norm = 2.2314e-01, time/batch = 0.7043s	
3061/22750 (epoch 6.727), train_loss = 1.44749935, grad/param norm = 1.8217e-01, time/batch = 0.7083s	
3062/22750 (epoch 6.730), train_loss = 1.46231383, grad/param norm = 1.9430e-01, time/batch = 0.7077s	
3063/22750 (epoch 6.732), train_loss = 1.50585932, grad/param norm = 2.0039e-01, time/batch = 0.6950s	
3064/22750 (epoch 6.734), train_loss = 1.18647400, grad/param norm = 1.9848e-01, time/batch = 0.6956s	
3065/22750 (epoch 6.736), train_loss = 1.40542908, grad/param norm = 1.9126e-01, time/batch = 0.6891s	
3066/22750 (epoch 6.738), train_loss = 1.51149101, grad/param norm = 2.1092e-01, time/batch = 0.6889s	
3067/22750 (epoch 6.741), train_loss = 1.63822573, grad/param norm = 1.9132e-01, time/batch = 0.6939s	
3068/22750 (epoch 6.743), train_loss = 1.59452460, grad/param norm = 2.0887e-01, time/batch = 0.6894s	
3069/22750 (epoch 6.745), train_loss = 1.31147040, grad/param norm = 1.7017e-01, time/batch = 0.6823s	
3070/22750 (epoch 6.747), train_loss = 1.44740942, grad/param norm = 2.0391e-01, time/batch = 0.7046s	
3071/22750 (epoch 6.749), train_loss = 1.73040323, grad/param norm = 2.1153e-01, time/batch = 0.7048s	
3072/22750 (epoch 6.752), train_loss = 1.44299383, grad/param norm = 1.9417e-01, time/batch = 0.6879s	
3073/22750 (epoch 6.754), train_loss = 1.70566482, grad/param norm = 2.3385e-01, time/batch = 0.6893s	
3074/22750 (epoch 6.756), train_loss = 1.33563231, grad/param norm = 2.1273e-01, time/batch = 0.6801s	
3075/22750 (epoch 6.758), train_loss = 1.29319470, grad/param norm = 1.9225e-01, time/batch = 0.6811s	
3076/22750 (epoch 6.760), train_loss = 1.54478482, grad/param norm = 2.0265e-01, time/batch = 0.6760s	
3077/22750 (epoch 6.763), train_loss = 1.56929754, grad/param norm = 1.8883e-01, time/batch = 0.6763s	
3078/22750 (epoch 6.765), train_loss = 1.44037406, grad/param norm = 2.1183e-01, time/batch = 0.6769s	
3079/22750 (epoch 6.767), train_loss = 1.49125344, grad/param norm = 1.8329e-01, time/batch = 0.6789s	
3080/22750 (epoch 6.769), train_loss = 1.69608043, grad/param norm = 2.0391e-01, time/batch = 0.6990s	
3081/22750 (epoch 6.771), train_loss = 1.66686291, grad/param norm = 2.0405e-01, time/batch = 0.7073s	
3082/22750 (epoch 6.774), train_loss = 1.44445115, grad/param norm = 2.2516e-01, time/batch = 0.6851s	
3083/22750 (epoch 6.776), train_loss = 1.53278998, grad/param norm = 2.1265e-01, time/batch = 0.6829s	
3084/22750 (epoch 6.778), train_loss = 1.72822739, grad/param norm = 1.8906e-01, time/batch = 0.6822s	
3085/22750 (epoch 6.780), train_loss = 1.57380054, grad/param norm = 2.1823e-01, time/batch = 0.6838s	
3086/22750 (epoch 6.782), train_loss = 1.66425004, grad/param norm = 2.1151e-01, time/batch = 0.6815s	
3087/22750 (epoch 6.785), train_loss = 1.54309489, grad/param norm = 1.9487e-01, time/batch = 0.6779s	
3088/22750 (epoch 6.787), train_loss = 1.41698604, grad/param norm = 1.9314e-01, time/batch = 0.6846s	
3089/22750 (epoch 6.789), train_loss = 1.45353670, grad/param norm = 1.8061e-01, time/batch = 0.6886s	
3090/22750 (epoch 6.791), train_loss = 1.49899119, grad/param norm = 1.8447e-01, time/batch = 0.6967s	
3091/22750 (epoch 6.793), train_loss = 1.50056596, grad/param norm = 2.2361e-01, time/batch = 0.7100s	
3092/22750 (epoch 6.796), train_loss = 1.37940517, grad/param norm = 1.9778e-01, time/batch = 0.6862s	
3093/22750 (epoch 6.798), train_loss = 1.37898210, grad/param norm = 1.6843e-01, time/batch = 0.6862s	
3094/22750 (epoch 6.800), train_loss = 1.34755130, grad/param norm = 1.8006e-01, time/batch = 0.6892s	
3095/22750 (epoch 6.802), train_loss = 1.46588588, grad/param norm = 1.9438e-01, time/batch = 0.6834s	
3096/22750 (epoch 6.804), train_loss = 1.76543595, grad/param norm = 2.0520e-01, time/batch = 0.6798s	
3097/22750 (epoch 6.807), train_loss = 1.55854395, grad/param norm = 2.0447e-01, time/batch = 0.6859s	
3098/22750 (epoch 6.809), train_loss = 1.79902676, grad/param norm = 2.1827e-01, time/batch = 0.6838s	
3099/22750 (epoch 6.811), train_loss = 1.47997010, grad/param norm = 1.9216e-01, time/batch = 0.6798s	
3100/22750 (epoch 6.813), train_loss = 1.58535316, grad/param norm = 1.9459e-01, time/batch = 0.6863s	
3101/22750 (epoch 6.815), train_loss = 1.73278109, grad/param norm = 2.2056e-01, time/batch = 0.7106s	
3102/22750 (epoch 6.818), train_loss = 1.67997211, grad/param norm = 2.0420e-01, time/batch = 0.7061s	
3103/22750 (epoch 6.820), train_loss = 1.79478336, grad/param norm = 1.8639e-01, time/batch = 0.7067s	
3104/22750 (epoch 6.822), train_loss = 1.55608124, grad/param norm = 1.9169e-01, time/batch = 0.7071s	
3105/22750 (epoch 6.824), train_loss = 1.54228841, grad/param norm = 1.9116e-01, time/batch = 0.6879s	
3106/22750 (epoch 6.826), train_loss = 1.55795177, grad/param norm = 1.9133e-01, time/batch = 0.6894s	
3107/22750 (epoch 6.829), train_loss = 1.72166935, grad/param norm = 2.2534e-01, time/batch = 0.6978s	
3108/22750 (epoch 6.831), train_loss = 1.69330481, grad/param norm = 2.1739e-01, time/batch = 0.6931s	
3109/22750 (epoch 6.833), train_loss = 1.65947278, grad/param norm = 2.1911e-01, time/batch = 0.6888s	
3110/22750 (epoch 6.835), train_loss = 1.46279653, grad/param norm = 1.8884e-01, time/batch = 0.6864s	
3111/22750 (epoch 6.837), train_loss = 1.46470991, grad/param norm = 2.0468e-01, time/batch = 0.7089s	
3112/22750 (epoch 6.840), train_loss = 1.50080437, grad/param norm = 2.0639e-01, time/batch = 0.6873s	
3113/22750 (epoch 6.842), train_loss = 1.44395561, grad/param norm = 1.8502e-01, time/batch = 0.6812s	
3114/22750 (epoch 6.844), train_loss = 1.72998834, grad/param norm = 2.1271e-01, time/batch = 0.6814s	
3115/22750 (epoch 6.846), train_loss = 1.51556411, grad/param norm = 1.9650e-01, time/batch = 0.6749s	
3116/22750 (epoch 6.848), train_loss = 1.36348531, grad/param norm = 2.0115e-01, time/batch = 0.6830s	
3117/22750 (epoch 6.851), train_loss = 1.40028143, grad/param norm = 1.8860e-01, time/batch = 0.6978s	
3118/22750 (epoch 6.853), train_loss = 1.51816546, grad/param norm = 1.9351e-01, time/batch = 0.6974s	
3119/22750 (epoch 6.855), train_loss = 1.31645759, grad/param norm = 1.9310e-01, time/batch = 0.6953s	
3120/22750 (epoch 6.857), train_loss = 1.52991911, grad/param norm = 1.8581e-01, time/batch = 0.7001s	
3121/22750 (epoch 6.859), train_loss = 1.56175102, grad/param norm = 2.0584e-01, time/batch = 0.7106s	
3122/22750 (epoch 6.862), train_loss = 1.72712579, grad/param norm = 2.0471e-01, time/batch = 0.6945s	
3123/22750 (epoch 6.864), train_loss = 1.51777146, grad/param norm = 1.9414e-01, time/batch = 0.7036s	
3124/22750 (epoch 6.866), train_loss = 1.55481796, grad/param norm = 1.8984e-01, time/batch = 0.6939s	
3125/22750 (epoch 6.868), train_loss = 1.50868639, grad/param norm = 1.9308e-01, time/batch = 0.6919s	
3126/22750 (epoch 6.870), train_loss = 1.32226015, grad/param norm = 1.9487e-01, time/batch = 0.6880s	
3127/22750 (epoch 6.873), train_loss = 1.47807622, grad/param norm = 2.0051e-01, time/batch = 0.6914s	
3128/22750 (epoch 6.875), train_loss = 1.58465036, grad/param norm = 1.8872e-01, time/batch = 0.6885s	
3129/22750 (epoch 6.877), train_loss = 1.44063751, grad/param norm = 1.8541e-01, time/batch = 0.6861s	
3130/22750 (epoch 6.879), train_loss = 1.65238143, grad/param norm = 2.1237e-01, time/batch = 0.6768s	
3131/22750 (epoch 6.881), train_loss = 1.63963716, grad/param norm = 2.1244e-01, time/batch = 0.7186s	
3132/22750 (epoch 6.884), train_loss = 1.43564359, grad/param norm = 2.1300e-01, time/batch = 0.6990s	
3133/22750 (epoch 6.886), train_loss = 1.61421402, grad/param norm = 1.9496e-01, time/batch = 0.6899s	
3134/22750 (epoch 6.888), train_loss = 1.58373878, grad/param norm = 1.8779e-01, time/batch = 0.6896s	
3135/22750 (epoch 6.890), train_loss = 1.61974080, grad/param norm = 1.9766e-01, time/batch = 0.6874s	
3136/22750 (epoch 6.892), train_loss = 1.96748359, grad/param norm = 2.3406e-01, time/batch = 0.6935s	
3137/22750 (epoch 6.895), train_loss = 1.63606335, grad/param norm = 1.8724e-01, time/batch = 0.6872s	
3138/22750 (epoch 6.897), train_loss = 1.67335378, grad/param norm = 2.0872e-01, time/batch = 0.6771s	
3139/22750 (epoch 6.899), train_loss = 1.60560710, grad/param norm = 2.0018e-01, time/batch = 0.6789s	
3140/22750 (epoch 6.901), train_loss = 1.75106343, grad/param norm = 2.0725e-01, time/batch = 0.6794s	
3141/22750 (epoch 6.903), train_loss = 1.52096511, grad/param norm = 1.9553e-01, time/batch = 0.6801s	
3142/22750 (epoch 6.905), train_loss = 1.60488254, grad/param norm = 1.8063e-01, time/batch = 0.6800s	
3143/22750 (epoch 6.908), train_loss = 1.52047150, grad/param norm = 2.0446e-01, time/batch = 0.6837s	
3144/22750 (epoch 6.910), train_loss = 1.33053218, grad/param norm = 2.0085e-01, time/batch = 0.6783s	
3145/22750 (epoch 6.912), train_loss = 1.39507081, grad/param norm = 1.9755e-01, time/batch = 0.6825s	
3146/22750 (epoch 6.914), train_loss = 1.46898960, grad/param norm = 1.9166e-01, time/batch = 0.6846s	
3147/22750 (epoch 6.916), train_loss = 1.30708050, grad/param norm = 1.8630e-01, time/batch = 0.6783s	
3148/22750 (epoch 6.919), train_loss = 1.41605288, grad/param norm = 1.9566e-01, time/batch = 0.6820s	
3149/22750 (epoch 6.921), train_loss = 1.13373293, grad/param norm = 1.6518e-01, time/batch = 0.6777s	
3150/22750 (epoch 6.923), train_loss = 1.48610187, grad/param norm = 1.9729e-01, time/batch = 0.6830s	
3151/22750 (epoch 6.925), train_loss = 1.46423761, grad/param norm = 1.8549e-01, time/batch = 0.7070s	
3152/22750 (epoch 6.927), train_loss = 1.26413115, grad/param norm = 1.8779e-01, time/batch = 0.7074s	
3153/22750 (epoch 6.930), train_loss = 1.30553087, grad/param norm = 1.8820e-01, time/batch = 0.7083s	
3154/22750 (epoch 6.932), train_loss = 1.60502089, grad/param norm = 1.9513e-01, time/batch = 0.6974s	
3155/22750 (epoch 6.934), train_loss = 1.15263838, grad/param norm = 1.6955e-01, time/batch = 0.6820s	
3156/22750 (epoch 6.936), train_loss = 1.66374839, grad/param norm = 2.2045e-01, time/batch = 0.6818s	
3157/22750 (epoch 6.938), train_loss = 1.55486230, grad/param norm = 1.9807e-01, time/batch = 0.6937s	
3158/22750 (epoch 6.941), train_loss = 1.82866493, grad/param norm = 2.1584e-01, time/batch = 0.6812s	
3159/22750 (epoch 6.943), train_loss = 1.60656419, grad/param norm = 1.8951e-01, time/batch = 0.6863s	
3160/22750 (epoch 6.945), train_loss = 1.53185878, grad/param norm = 1.7939e-01, time/batch = 0.6896s	
3161/22750 (epoch 6.947), train_loss = 1.52203886, grad/param norm = 2.1219e-01, time/batch = 0.6868s	
3162/22750 (epoch 6.949), train_loss = 1.38383863, grad/param norm = 2.0350e-01, time/batch = 0.6850s	
3163/22750 (epoch 6.952), train_loss = 1.41986987, grad/param norm = 2.0248e-01, time/batch = 0.6811s	
3164/22750 (epoch 6.954), train_loss = 1.41256948, grad/param norm = 1.7788e-01, time/batch = 0.6821s	
3165/22750 (epoch 6.956), train_loss = 1.52406121, grad/param norm = 1.9414e-01, time/batch = 0.6834s	
3166/22750 (epoch 6.958), train_loss = 1.46702667, grad/param norm = 1.8401e-01, time/batch = 0.6805s	
3167/22750 (epoch 6.960), train_loss = 1.49059910, grad/param norm = 1.8695e-01, time/batch = 0.6848s	
3168/22750 (epoch 6.963), train_loss = 1.68231218, grad/param norm = 2.0767e-01, time/batch = 0.6809s	
3169/22750 (epoch 6.965), train_loss = 1.60817699, grad/param norm = 2.0285e-01, time/batch = 0.6800s	
3170/22750 (epoch 6.967), train_loss = 1.52776594, grad/param norm = 2.1084e-01, time/batch = 0.6809s	
3171/22750 (epoch 6.969), train_loss = 1.46408016, grad/param norm = 1.9346e-01, time/batch = 0.6897s	
3172/22750 (epoch 6.971), train_loss = 1.46943039, grad/param norm = 1.9740e-01, time/batch = 0.7073s	
3173/22750 (epoch 6.974), train_loss = 1.52538397, grad/param norm = 2.1275e-01, time/batch = 0.6813s	
3174/22750 (epoch 6.976), train_loss = 1.62999043, grad/param norm = 2.0058e-01, time/batch = 0.6832s	
3175/22750 (epoch 6.978), train_loss = 1.37869500, grad/param norm = 1.7918e-01, time/batch = 0.6851s	
3176/22750 (epoch 6.980), train_loss = 1.66831926, grad/param norm = 2.1635e-01, time/batch = 0.6844s	
3177/22750 (epoch 6.982), train_loss = 1.44105687, grad/param norm = 1.7894e-01, time/batch = 0.6892s	
3178/22750 (epoch 6.985), train_loss = 1.77882348, grad/param norm = 2.2049e-01, time/batch = 0.6828s	
3179/22750 (epoch 6.987), train_loss = 1.30754908, grad/param norm = 1.8283e-01, time/batch = 0.6875s	
3180/22750 (epoch 6.989), train_loss = 1.42481389, grad/param norm = 1.8105e-01, time/batch = 0.6851s	
3181/22750 (epoch 6.991), train_loss = 1.60923771, grad/param norm = 1.9101e-01, time/batch = 0.6919s	
3182/22750 (epoch 6.993), train_loss = 1.62727044, grad/param norm = 2.0646e-01, time/batch = 0.6815s	
3183/22750 (epoch 6.996), train_loss = 1.49119658, grad/param norm = 2.1137e-01, time/batch = 0.7033s	
3184/22750 (epoch 6.998), train_loss = 1.67687077, grad/param norm = 1.9853e-01, time/batch = 0.7133s	
3185/22750 (epoch 7.000), train_loss = 1.58213864, grad/param norm = 1.9536e-01, time/batch = 0.7122s	
3186/22750 (epoch 7.002), train_loss = 1.68696521, grad/param norm = 2.1869e-01, time/batch = 0.7043s	
3187/22750 (epoch 7.004), train_loss = 1.45854202, grad/param norm = 2.2233e-01, time/batch = 0.6876s	
3188/22750 (epoch 7.007), train_loss = 1.56439068, grad/param norm = 2.0217e-01, time/batch = 0.6881s	
3189/22750 (epoch 7.009), train_loss = 1.82282945, grad/param norm = 1.9776e-01, time/batch = 0.7047s	
3190/22750 (epoch 7.011), train_loss = 1.76035301, grad/param norm = 2.0032e-01, time/batch = 0.7066s	
3191/22750 (epoch 7.013), train_loss = 1.60506924, grad/param norm = 1.9587e-01, time/batch = 0.7094s	
3192/22750 (epoch 7.015), train_loss = 1.60083804, grad/param norm = 2.0765e-01, time/batch = 0.7036s	
3193/22750 (epoch 7.018), train_loss = 1.63864452, grad/param norm = 2.0377e-01, time/batch = 0.6981s	
3194/22750 (epoch 7.020), train_loss = 1.71895875, grad/param norm = 1.9413e-01, time/batch = 0.6996s	
3195/22750 (epoch 7.022), train_loss = 1.53709850, grad/param norm = 1.8047e-01, time/batch = 0.6811s	
3196/22750 (epoch 7.024), train_loss = 1.51919737, grad/param norm = 2.0742e-01, time/batch = 0.6826s	
3197/22750 (epoch 7.026), train_loss = 1.68466834, grad/param norm = 2.1495e-01, time/batch = 0.6851s	
3198/22750 (epoch 7.029), train_loss = 1.29660850, grad/param norm = 1.7891e-01, time/batch = 0.6882s	
3199/22750 (epoch 7.031), train_loss = 1.81629063, grad/param norm = 2.0627e-01, time/batch = 0.6918s	
3200/22750 (epoch 7.033), train_loss = 1.54787408, grad/param norm = 1.9294e-01, time/batch = 0.7053s	
3201/22750 (epoch 7.035), train_loss = 1.61471001, grad/param norm = 2.1168e-01, time/batch = 0.6975s	
3202/22750 (epoch 7.037), train_loss = 1.70633078, grad/param norm = 2.2214e-01, time/batch = 0.7141s	
3203/22750 (epoch 7.040), train_loss = 1.46837082, grad/param norm = 2.1652e-01, time/batch = 0.6874s	
3204/22750 (epoch 7.042), train_loss = 1.63735204, grad/param norm = 2.0280e-01, time/batch = 0.6938s	
3205/22750 (epoch 7.044), train_loss = 1.45626533, grad/param norm = 2.1777e-01, time/batch = 0.6893s	
3206/22750 (epoch 7.046), train_loss = 1.60492698, grad/param norm = 2.2072e-01, time/batch = 0.6947s	
3207/22750 (epoch 7.048), train_loss = 1.52336756, grad/param norm = 2.0596e-01, time/batch = 0.6855s	
3208/22750 (epoch 7.051), train_loss = 1.56553748, grad/param norm = 1.9295e-01, time/batch = 0.6866s	
3209/22750 (epoch 7.053), train_loss = 1.33591939, grad/param norm = 1.9257e-01, time/batch = 0.6867s	
3210/22750 (epoch 7.055), train_loss = 1.52445675, grad/param norm = 2.0524e-01, time/batch = 0.6887s	
3211/22750 (epoch 7.057), train_loss = 1.65562024, grad/param norm = 2.0746e-01, time/batch = 0.6957s	
3212/22750 (epoch 7.059), train_loss = 1.17443541, grad/param norm = 1.8161e-01, time/batch = 0.7131s	
3213/22750 (epoch 7.062), train_loss = 1.33747356, grad/param norm = 1.8308e-01, time/batch = 0.6884s	
3214/22750 (epoch 7.064), train_loss = 1.58176661, grad/param norm = 2.1410e-01, time/batch = 0.6866s	
3215/22750 (epoch 7.066), train_loss = 1.31405069, grad/param norm = 1.7403e-01, time/batch = 0.6890s	
3216/22750 (epoch 7.068), train_loss = 1.37911680, grad/param norm = 1.7797e-01, time/batch = 0.6852s	
3217/22750 (epoch 7.070), train_loss = 1.29021599, grad/param norm = 1.9246e-01, time/batch = 0.6850s	
3218/22750 (epoch 7.073), train_loss = 1.42722394, grad/param norm = 1.9879e-01, time/batch = 0.6855s	
3219/22750 (epoch 7.075), train_loss = 1.48434080, grad/param norm = 1.9463e-01, time/batch = 0.6865s	
3220/22750 (epoch 7.077), train_loss = 1.15869744, grad/param norm = 1.8882e-01, time/batch = 0.6845s	
3221/22750 (epoch 7.079), train_loss = 1.45177866, grad/param norm = 1.9518e-01, time/batch = 0.6865s	
3222/22750 (epoch 7.081), train_loss = 1.49852548, grad/param norm = 2.1626e-01, time/batch = 0.6849s	
3223/22750 (epoch 7.084), train_loss = 1.40558480, grad/param norm = 2.0615e-01, time/batch = 0.6823s	
3224/22750 (epoch 7.086), train_loss = 1.41565861, grad/param norm = 1.7849e-01, time/batch = 0.6829s	
3225/22750 (epoch 7.088), train_loss = 1.42891439, grad/param norm = 2.0342e-01, time/batch = 0.6882s	
3226/22750 (epoch 7.090), train_loss = 1.46415934, grad/param norm = 1.8665e-01, time/batch = 0.6860s	
3227/22750 (epoch 7.092), train_loss = 1.65784727, grad/param norm = 1.9316e-01, time/batch = 0.6865s	
3228/22750 (epoch 7.095), train_loss = 1.34105214, grad/param norm = 1.9176e-01, time/batch = 0.6834s	
3229/22750 (epoch 7.097), train_loss = 1.43391116, grad/param norm = 1.8621e-01, time/batch = 0.6861s	
3230/22750 (epoch 7.099), train_loss = 1.51484622, grad/param norm = 1.9177e-01, time/batch = 0.6801s	
3231/22750 (epoch 7.101), train_loss = 1.45959851, grad/param norm = 1.9584e-01, time/batch = 0.6804s	
3232/22750 (epoch 7.103), train_loss = 1.47524829, grad/param norm = 2.0274e-01, time/batch = 0.6933s	
3233/22750 (epoch 7.105), train_loss = 1.79996867, grad/param norm = 2.2385e-01, time/batch = 0.6828s	
3234/22750 (epoch 7.108), train_loss = 1.44716326, grad/param norm = 1.8764e-01, time/batch = 0.6887s	
3235/22750 (epoch 7.110), train_loss = 1.55330809, grad/param norm = 2.0438e-01, time/batch = 0.6825s	
3236/22750 (epoch 7.112), train_loss = 1.23768517, grad/param norm = 1.7713e-01, time/batch = 0.6808s	
3237/22750 (epoch 7.114), train_loss = 1.20398589, grad/param norm = 1.8866e-01, time/batch = 0.6883s	
3238/22750 (epoch 7.116), train_loss = 1.32184415, grad/param norm = 1.7598e-01, time/batch = 0.6851s	
3239/22750 (epoch 7.119), train_loss = 1.36936540, grad/param norm = 1.8788e-01, time/batch = 0.6870s	
3240/22750 (epoch 7.121), train_loss = 1.61432828, grad/param norm = 2.2495e-01, time/batch = 0.6869s	
3241/22750 (epoch 7.123), train_loss = 1.39215093, grad/param norm = 1.7535e-01, time/batch = 0.6863s	
3242/22750 (epoch 7.125), train_loss = 1.66446261, grad/param norm = 1.9532e-01, time/batch = 0.6837s	
3243/22750 (epoch 7.127), train_loss = 1.54945285, grad/param norm = 2.0599e-01, time/batch = 0.6824s	
3244/22750 (epoch 7.130), train_loss = 1.54736940, grad/param norm = 1.8958e-01, time/batch = 0.6822s	
3245/22750 (epoch 7.132), train_loss = 1.60162388, grad/param norm = 2.2249e-01, time/batch = 0.6861s	
3246/22750 (epoch 7.134), train_loss = 1.44206697, grad/param norm = 1.9143e-01, time/batch = 0.6857s	
3247/22750 (epoch 7.136), train_loss = 1.31415221, grad/param norm = 1.8289e-01, time/batch = 0.6837s	
3248/22750 (epoch 7.138), train_loss = 1.51657965, grad/param norm = 2.0198e-01, time/batch = 0.6803s	
3249/22750 (epoch 7.141), train_loss = 1.37755169, grad/param norm = 1.8374e-01, time/batch = 0.6832s	
3250/22750 (epoch 7.143), train_loss = 1.30337026, grad/param norm = 1.7219e-01, time/batch = 0.6824s	
3251/22750 (epoch 7.145), train_loss = 1.61637112, grad/param norm = 1.9392e-01, time/batch = 0.6903s	
3252/22750 (epoch 7.147), train_loss = 1.62941340, grad/param norm = 2.1120e-01, time/batch = 0.6933s	
3253/22750 (epoch 7.149), train_loss = 1.48967268, grad/param norm = 1.9910e-01, time/batch = 0.6874s	
3254/22750 (epoch 7.152), train_loss = 1.41828965, grad/param norm = 2.0468e-01, time/batch = 0.6846s	
3255/22750 (epoch 7.154), train_loss = 1.24786392, grad/param norm = 1.8596e-01, time/batch = 0.6858s	
3256/22750 (epoch 7.156), train_loss = 1.33360125, grad/param norm = 1.9178e-01, time/batch = 0.6941s	
3257/22750 (epoch 7.158), train_loss = 1.44464223, grad/param norm = 2.0670e-01, time/batch = 0.6874s	
3258/22750 (epoch 7.160), train_loss = 1.55444225, grad/param norm = 2.0213e-01, time/batch = 0.6828s	
3259/22750 (epoch 7.163), train_loss = 1.76338181, grad/param norm = 2.1994e-01, time/batch = 0.6859s	
3260/22750 (epoch 7.165), train_loss = 1.61339175, grad/param norm = 1.9984e-01, time/batch = 0.6837s	
3261/22750 (epoch 7.167), train_loss = 1.43000727, grad/param norm = 1.9556e-01, time/batch = 0.6887s	
3262/22750 (epoch 7.169), train_loss = 1.53559647, grad/param norm = 1.9781e-01, time/batch = 0.6903s	
3263/22750 (epoch 7.171), train_loss = 1.35361753, grad/param norm = 1.9655e-01, time/batch = 0.6896s	
3264/22750 (epoch 7.174), train_loss = 1.21983087, grad/param norm = 1.8548e-01, time/batch = 0.6859s	
3265/22750 (epoch 7.176), train_loss = 1.49865464, grad/param norm = 1.8530e-01, time/batch = 0.6885s	
3266/22750 (epoch 7.178), train_loss = 1.45413442, grad/param norm = 1.8575e-01, time/batch = 0.6907s	
3267/22750 (epoch 7.180), train_loss = 1.60437321, grad/param norm = 2.1937e-01, time/batch = 0.6865s	
3268/22750 (epoch 7.182), train_loss = 1.59578400, grad/param norm = 1.8350e-01, time/batch = 0.6916s	
3269/22750 (epoch 7.185), train_loss = 1.59301240, grad/param norm = 2.0713e-01, time/batch = 0.6866s	
3270/22750 (epoch 7.187), train_loss = 1.37796375, grad/param norm = 1.8647e-01, time/batch = 0.6845s	
3271/22750 (epoch 7.189), train_loss = 1.40499727, grad/param norm = 1.9747e-01, time/batch = 0.6877s	
3272/22750 (epoch 7.191), train_loss = 1.30721800, grad/param norm = 1.6920e-01, time/batch = 0.6846s	
3273/22750 (epoch 7.193), train_loss = 1.58277126, grad/param norm = 1.9666e-01, time/batch = 0.6901s	
3274/22750 (epoch 7.196), train_loss = 1.46911246, grad/param norm = 1.9774e-01, time/batch = 0.6887s	
3275/22750 (epoch 7.198), train_loss = 1.21220916, grad/param norm = 1.5589e-01, time/batch = 0.7076s	
3276/22750 (epoch 7.200), train_loss = 1.50952313, grad/param norm = 1.9355e-01, time/batch = 0.7104s	
3277/22750 (epoch 7.202), train_loss = 1.67312395, grad/param norm = 2.1705e-01, time/batch = 0.7305s	
3278/22750 (epoch 7.204), train_loss = 1.63132280, grad/param norm = 2.0174e-01, time/batch = 0.7107s	
3279/22750 (epoch 7.207), train_loss = 1.43324893, grad/param norm = 1.9196e-01, time/batch = 0.7000s	
3280/22750 (epoch 7.209), train_loss = 1.35493161, grad/param norm = 1.9347e-01, time/batch = 0.6924s	
3281/22750 (epoch 7.211), train_loss = 1.45790352, grad/param norm = 2.0465e-01, time/batch = 0.7002s	
3282/22750 (epoch 7.213), train_loss = 1.33748720, grad/param norm = 1.9097e-01, time/batch = 0.7167s	
3283/22750 (epoch 7.215), train_loss = 1.33464088, grad/param norm = 1.9758e-01, time/batch = 0.7131s	
3284/22750 (epoch 7.218), train_loss = 1.29854937, grad/param norm = 2.2306e-01, time/batch = 0.7135s	
3285/22750 (epoch 7.220), train_loss = 1.46743694, grad/param norm = 2.1130e-01, time/batch = 0.7100s	
3286/22750 (epoch 7.222), train_loss = 1.30615238, grad/param norm = 2.0070e-01, time/batch = 0.7105s	
3287/22750 (epoch 7.224), train_loss = 1.37817285, grad/param norm = 1.8838e-01, time/batch = 0.7129s	
3288/22750 (epoch 7.226), train_loss = 1.55549434, grad/param norm = 2.1285e-01, time/batch = 0.7044s	
3289/22750 (epoch 7.229), train_loss = 1.52932513, grad/param norm = 2.0397e-01, time/batch = 0.7147s	
3290/22750 (epoch 7.231), train_loss = 1.43781550, grad/param norm = 1.9010e-01, time/batch = 0.7121s	
3291/22750 (epoch 7.233), train_loss = 1.33875559, grad/param norm = 1.8554e-01, time/batch = 0.6904s	
3292/22750 (epoch 7.235), train_loss = 1.34025578, grad/param norm = 1.9710e-01, time/batch = 0.6987s	
3293/22750 (epoch 7.237), train_loss = 1.39757948, grad/param norm = 2.0045e-01, time/batch = 0.7149s	
3294/22750 (epoch 7.240), train_loss = 1.56368403, grad/param norm = 1.8362e-01, time/batch = 0.7147s	
3295/22750 (epoch 7.242), train_loss = 1.89713472, grad/param norm = 2.1881e-01, time/batch = 0.6912s	
3296/22750 (epoch 7.244), train_loss = 1.68279178, grad/param norm = 2.1890e-01, time/batch = 0.6923s	
3297/22750 (epoch 7.246), train_loss = 1.73798362, grad/param norm = 1.9872e-01, time/batch = 0.7169s	
3298/22750 (epoch 7.248), train_loss = 1.44912742, grad/param norm = 2.0363e-01, time/batch = 0.6930s	
3299/22750 (epoch 7.251), train_loss = 1.71540100, grad/param norm = 1.9265e-01, time/batch = 0.6982s	
3300/22750 (epoch 7.253), train_loss = 1.51810419, grad/param norm = 1.9329e-01, time/batch = 0.6962s	
3301/22750 (epoch 7.255), train_loss = 1.52890995, grad/param norm = 1.9448e-01, time/batch = 0.7143s	
3302/22750 (epoch 7.257), train_loss = 1.47149826, grad/param norm = 1.9058e-01, time/batch = 0.7132s	
3303/22750 (epoch 7.259), train_loss = 1.67935179, grad/param norm = 2.2012e-01, time/batch = 0.7116s	
3304/22750 (epoch 7.262), train_loss = 1.47075309, grad/param norm = 2.0227e-01, time/batch = 0.7119s	
3305/22750 (epoch 7.264), train_loss = 1.38439382, grad/param norm = 1.8867e-01, time/batch = 0.7122s	
3306/22750 (epoch 7.266), train_loss = 1.52185237, grad/param norm = 2.1364e-01, time/batch = 0.7196s	
3307/22750 (epoch 7.268), train_loss = 1.64529302, grad/param norm = 2.0109e-01, time/batch = 0.7078s	
3308/22750 (epoch 7.270), train_loss = 1.45615682, grad/param norm = 2.0696e-01, time/batch = 0.6817s	
3309/22750 (epoch 7.273), train_loss = 1.75855465, grad/param norm = 2.2526e-01, time/batch = 0.6842s	
3310/22750 (epoch 7.275), train_loss = 1.53754929, grad/param norm = 1.9386e-01, time/batch = 0.6833s	
3311/22750 (epoch 7.277), train_loss = 1.50099118, grad/param norm = 1.9516e-01, time/batch = 0.6823s	
3312/22750 (epoch 7.279), train_loss = 1.30862424, grad/param norm = 1.7571e-01, time/batch = 0.6999s	
3313/22750 (epoch 7.281), train_loss = 1.55484715, grad/param norm = 1.8536e-01, time/batch = 0.6954s	
3314/22750 (epoch 7.284), train_loss = 1.40281043, grad/param norm = 1.7124e-01, time/batch = 0.6966s	
3315/22750 (epoch 7.286), train_loss = 1.61994056, grad/param norm = 2.0122e-01, time/batch = 0.7006s	
3316/22750 (epoch 7.288), train_loss = 1.68302074, grad/param norm = 2.0048e-01, time/batch = 0.7026s	
3317/22750 (epoch 7.290), train_loss = 1.40307156, grad/param norm = 1.7339e-01, time/batch = 0.7024s	
3318/22750 (epoch 7.292), train_loss = 1.49472822, grad/param norm = 2.0932e-01, time/batch = 0.7311s	
3319/22750 (epoch 7.295), train_loss = 1.47351878, grad/param norm = 1.8138e-01, time/batch = 0.7084s	
3320/22750 (epoch 7.297), train_loss = 1.42365968, grad/param norm = 1.9026e-01, time/batch = 0.7068s	
3321/22750 (epoch 7.299), train_loss = 1.63949161, grad/param norm = 1.8443e-01, time/batch = 0.7118s	
3322/22750 (epoch 7.301), train_loss = 1.55908683, grad/param norm = 2.0120e-01, time/batch = 0.7066s	
3323/22750 (epoch 7.303), train_loss = 1.63187120, grad/param norm = 2.1962e-01, time/batch = 0.6894s	
3324/22750 (epoch 7.305), train_loss = 1.70323517, grad/param norm = 2.0474e-01, time/batch = 0.6894s	
3325/22750 (epoch 7.308), train_loss = 1.55215837, grad/param norm = 1.9540e-01, time/batch = 0.7288s	
3326/22750 (epoch 7.310), train_loss = 1.44824386, grad/param norm = 2.0404e-01, time/batch = 0.6909s	
3327/22750 (epoch 7.312), train_loss = 1.54023709, grad/param norm = 2.0334e-01, time/batch = 0.6852s	
3328/22750 (epoch 7.314), train_loss = 1.49358223, grad/param norm = 1.9594e-01, time/batch = 0.6826s	
3329/22750 (epoch 7.316), train_loss = 1.41446623, grad/param norm = 1.8669e-01, time/batch = 0.6913s	
3330/22750 (epoch 7.319), train_loss = 1.55950200, grad/param norm = 1.9182e-01, time/batch = 0.6898s	
3331/22750 (epoch 7.321), train_loss = 1.46636356, grad/param norm = 2.0259e-01, time/batch = 0.6837s	
3332/22750 (epoch 7.323), train_loss = 1.46527032, grad/param norm = 2.2058e-01, time/batch = 0.6927s	
3333/22750 (epoch 7.325), train_loss = 1.20745593, grad/param norm = 1.8378e-01, time/batch = 0.6843s	
3334/22750 (epoch 7.327), train_loss = 1.53911657, grad/param norm = 1.9127e-01, time/batch = 0.6822s	
3335/22750 (epoch 7.330), train_loss = 1.78523862, grad/param norm = 2.0013e-01, time/batch = 0.6832s	
3336/22750 (epoch 7.332), train_loss = 1.63244051, grad/param norm = 1.9633e-01, time/batch = 0.6835s	
3337/22750 (epoch 7.334), train_loss = 1.23695059, grad/param norm = 1.8316e-01, time/batch = 0.6835s	
3338/22750 (epoch 7.336), train_loss = 1.55485655, grad/param norm = 1.9235e-01, time/batch = 0.6825s	
3339/22750 (epoch 7.338), train_loss = 1.45011514, grad/param norm = 1.8763e-01, time/batch = 0.6857s	
3340/22750 (epoch 7.341), train_loss = 1.43256948, grad/param norm = 1.8809e-01, time/batch = 0.6818s	
3341/22750 (epoch 7.343), train_loss = 1.28245417, grad/param norm = 2.0044e-01, time/batch = 0.6886s	
3342/22750 (epoch 7.345), train_loss = 1.65861690, grad/param norm = 2.1544e-01, time/batch = 0.6857s	
3343/22750 (epoch 7.347), train_loss = 1.62960714, grad/param norm = 2.0457e-01, time/batch = 0.6833s	
3344/22750 (epoch 7.349), train_loss = 1.21745965, grad/param norm = 1.8900e-01, time/batch = 0.6883s	
3345/22750 (epoch 7.352), train_loss = 1.60420747, grad/param norm = 2.1136e-01, time/batch = 0.6870s	
3346/22750 (epoch 7.354), train_loss = 1.68359585, grad/param norm = 2.0304e-01, time/batch = 0.6876s	
3347/22750 (epoch 7.356), train_loss = 1.68540268, grad/param norm = 1.9409e-01, time/batch = 0.6885s	
3348/22750 (epoch 7.358), train_loss = 1.47330439, grad/param norm = 2.0772e-01, time/batch = 0.6874s	
3349/22750 (epoch 7.360), train_loss = 1.71647598, grad/param norm = 2.1633e-01, time/batch = 0.6932s	
3350/22750 (epoch 7.363), train_loss = 1.48900502, grad/param norm = 1.8963e-01, time/batch = 0.6871s	
3351/22750 (epoch 7.365), train_loss = 1.24470262, grad/param norm = 1.8941e-01, time/batch = 0.6911s	
3352/22750 (epoch 7.367), train_loss = 1.26765850, grad/param norm = 1.8453e-01, time/batch = 0.7021s	
3353/22750 (epoch 7.369), train_loss = 1.43540398, grad/param norm = 2.1395e-01, time/batch = 0.7062s	
3354/22750 (epoch 7.371), train_loss = 1.40293327, grad/param norm = 1.9421e-01, time/batch = 0.6856s	
3355/22750 (epoch 7.374), train_loss = 1.30791897, grad/param norm = 1.9839e-01, time/batch = 0.6856s	
3356/22750 (epoch 7.376), train_loss = 1.49323263, grad/param norm = 1.8229e-01, time/batch = 0.6845s	
3357/22750 (epoch 7.378), train_loss = 1.46424048, grad/param norm = 1.9827e-01, time/batch = 0.6861s	
3358/22750 (epoch 7.380), train_loss = 1.64602243, grad/param norm = 1.9936e-01, time/batch = 0.6821s	
3359/22750 (epoch 7.382), train_loss = 1.40278917, grad/param norm = 1.8503e-01, time/batch = 0.6826s	
3360/22750 (epoch 7.385), train_loss = 1.52632164, grad/param norm = 1.7856e-01, time/batch = 0.6817s	
3361/22750 (epoch 7.387), train_loss = 1.56299255, grad/param norm = 1.9913e-01, time/batch = 0.7076s	
3362/22750 (epoch 7.389), train_loss = 1.12615490, grad/param norm = 1.8788e-01, time/batch = 0.7108s	
3363/22750 (epoch 7.391), train_loss = 0.96347857, grad/param norm = 1.5791e-01, time/batch = 0.7169s	
3364/22750 (epoch 7.393), train_loss = 1.29178466, grad/param norm = 1.8536e-01, time/batch = 0.7130s	
3365/22750 (epoch 7.396), train_loss = 1.46888898, grad/param norm = 2.0526e-01, time/batch = 0.6990s	
3366/22750 (epoch 7.398), train_loss = 1.45312700, grad/param norm = 2.0395e-01, time/batch = 0.6992s	
3367/22750 (epoch 7.400), train_loss = 1.46614220, grad/param norm = 1.8256e-01, time/batch = 0.6823s	
3368/22750 (epoch 7.402), train_loss = 1.49752675, grad/param norm = 1.8539e-01, time/batch = 0.6863s	
3369/22750 (epoch 7.404), train_loss = 1.70504386, grad/param norm = 1.9528e-01, time/batch = 0.6836s	
3370/22750 (epoch 7.407), train_loss = 1.60776698, grad/param norm = 1.8960e-01, time/batch = 0.6853s	
3371/22750 (epoch 7.409), train_loss = 1.46264565, grad/param norm = 1.8620e-01, time/batch = 0.6968s	
3372/22750 (epoch 7.411), train_loss = 1.47574579, grad/param norm = 1.8657e-01, time/batch = 0.7029s	
3373/22750 (epoch 7.413), train_loss = 1.30541970, grad/param norm = 1.8572e-01, time/batch = 0.6832s	
3374/22750 (epoch 7.415), train_loss = 1.23200758, grad/param norm = 1.9326e-01, time/batch = 0.7055s	
3375/22750 (epoch 7.418), train_loss = 1.44070969, grad/param norm = 1.9202e-01, time/batch = 0.6898s	
3376/22750 (epoch 7.420), train_loss = 1.71316912, grad/param norm = 2.2827e-01, time/batch = 0.7097s	
3377/22750 (epoch 7.422), train_loss = 1.81223385, grad/param norm = 2.1967e-01, time/batch = 0.7325s	
3378/22750 (epoch 7.424), train_loss = 1.79726136, grad/param norm = 2.2834e-01, time/batch = 0.7055s	
3379/22750 (epoch 7.426), train_loss = 1.71533591, grad/param norm = 1.9296e-01, time/batch = 0.6957s	
3380/22750 (epoch 7.429), train_loss = 1.23248082, grad/param norm = 1.9537e-01, time/batch = 0.6790s	
3381/22750 (epoch 7.431), train_loss = 1.22713486, grad/param norm = 1.7665e-01, time/batch = 0.6918s	
3382/22750 (epoch 7.433), train_loss = 1.34978448, grad/param norm = 1.8210e-01, time/batch = 0.6924s	
3383/22750 (epoch 7.435), train_loss = 1.20932111, grad/param norm = 1.8421e-01, time/batch = 0.6825s	
3384/22750 (epoch 7.437), train_loss = 1.11715106, grad/param norm = 1.7359e-01, time/batch = 0.6817s	
3385/22750 (epoch 7.440), train_loss = 1.61093463, grad/param norm = 2.0859e-01, time/batch = 0.6848s	
3386/22750 (epoch 7.442), train_loss = 1.50311037, grad/param norm = 2.0166e-01, time/batch = 0.6792s	
3387/22750 (epoch 7.444), train_loss = 1.50815689, grad/param norm = 2.2349e-01, time/batch = 0.6830s	
3388/22750 (epoch 7.446), train_loss = 1.48541271, grad/param norm = 2.1857e-01, time/batch = 0.6809s	
3389/22750 (epoch 7.448), train_loss = 1.77265398, grad/param norm = 2.1973e-01, time/batch = 0.6812s	
3390/22750 (epoch 7.451), train_loss = 1.68444372, grad/param norm = 2.1381e-01, time/batch = 0.6863s	
3391/22750 (epoch 7.453), train_loss = 1.76999382, grad/param norm = 2.2469e-01, time/batch = 0.6822s	
3392/22750 (epoch 7.455), train_loss = 1.84867619, grad/param norm = 2.0524e-01, time/batch = 0.6800s	
3393/22750 (epoch 7.457), train_loss = 1.64899057, grad/param norm = 2.2154e-01, time/batch = 0.6806s	
3394/22750 (epoch 7.459), train_loss = 1.55286487, grad/param norm = 1.9158e-01, time/batch = 0.6819s	
3395/22750 (epoch 7.462), train_loss = 1.57011580, grad/param norm = 1.6856e-01, time/batch = 0.6839s	
3396/22750 (epoch 7.464), train_loss = 1.31879405, grad/param norm = 1.8086e-01, time/batch = 0.6793s	
3397/22750 (epoch 7.466), train_loss = 1.75809288, grad/param norm = 2.2428e-01, time/batch = 0.6846s	
3398/22750 (epoch 7.468), train_loss = 1.44762112, grad/param norm = 1.9948e-01, time/batch = 0.6818s	
3399/22750 (epoch 7.470), train_loss = 1.65980084, grad/param norm = 2.1326e-01, time/batch = 0.6842s	
3400/22750 (epoch 7.473), train_loss = 1.50259377, grad/param norm = 2.0212e-01, time/batch = 0.6860s	
3401/22750 (epoch 7.475), train_loss = 1.55552212, grad/param norm = 2.1096e-01, time/batch = 0.6857s	
3402/22750 (epoch 7.477), train_loss = 1.29644852, grad/param norm = 1.8562e-01, time/batch = 0.7096s	
3403/22750 (epoch 7.479), train_loss = 1.32832589, grad/param norm = 1.9431e-01, time/batch = 0.7123s	
3404/22750 (epoch 7.481), train_loss = 1.26064189, grad/param norm = 1.9125e-01, time/batch = 0.7072s	
3405/22750 (epoch 7.484), train_loss = 1.12726425, grad/param norm = 1.8604e-01, time/batch = 0.7173s	
3406/22750 (epoch 7.486), train_loss = 1.35143440, grad/param norm = 2.0206e-01, time/batch = 0.7017s	
3407/22750 (epoch 7.488), train_loss = 1.13978344, grad/param norm = 2.0218e-01, time/batch = 0.7098s	
3408/22750 (epoch 7.490), train_loss = 1.40501850, grad/param norm = 1.9212e-01, time/batch = 0.7346s	
3409/22750 (epoch 7.492), train_loss = 1.63978025, grad/param norm = 2.0220e-01, time/batch = 0.7243s	
3410/22750 (epoch 7.495), train_loss = 1.38233710, grad/param norm = 2.0102e-01, time/batch = 0.7208s	
3411/22750 (epoch 7.497), train_loss = 1.55287994, grad/param norm = 2.1674e-01, time/batch = 0.7158s	
3412/22750 (epoch 7.499), train_loss = 1.41563247, grad/param norm = 1.9998e-01, time/batch = 0.7373s	
3413/22750 (epoch 7.501), train_loss = 1.51459577, grad/param norm = 2.1616e-01, time/batch = 0.7572s	
3414/22750 (epoch 7.503), train_loss = 1.45743037, grad/param norm = 1.9945e-01, time/batch = 0.7286s	
3415/22750 (epoch 7.505), train_loss = 1.30290292, grad/param norm = 1.7959e-01, time/batch = 0.7192s	
3416/22750 (epoch 7.508), train_loss = 1.26219632, grad/param norm = 1.9669e-01, time/batch = 0.7198s	
3417/22750 (epoch 7.510), train_loss = 1.28666868, grad/param norm = 1.7749e-01, time/batch = 0.7356s	
3418/22750 (epoch 7.512), train_loss = 1.35504549, grad/param norm = 1.8103e-01, time/batch = 0.7231s	
3419/22750 (epoch 7.514), train_loss = 1.35940149, grad/param norm = 1.7981e-01, time/batch = 0.7187s	
3420/22750 (epoch 7.516), train_loss = 1.33068832, grad/param norm = 1.8533e-01, time/batch = 0.6987s	
3421/22750 (epoch 7.519), train_loss = 1.55400147, grad/param norm = 2.1865e-01, time/batch = 0.6965s	
3422/22750 (epoch 7.521), train_loss = 1.38200944, grad/param norm = 2.0373e-01, time/batch = 0.7016s	
3423/22750 (epoch 7.523), train_loss = 1.40480939, grad/param norm = 2.2587e-01, time/batch = 0.6991s	
3424/22750 (epoch 7.525), train_loss = 1.69026063, grad/param norm = 2.3595e-01, time/batch = 0.6998s	
3425/22750 (epoch 7.527), train_loss = 1.48992639, grad/param norm = 1.9548e-01, time/batch = 0.6966s	
3426/22750 (epoch 7.530), train_loss = 1.36773243, grad/param norm = 2.0956e-01, time/batch = 0.7008s	
3427/22750 (epoch 7.532), train_loss = 1.32316399, grad/param norm = 1.6915e-01, time/batch = 0.7037s	
3428/22750 (epoch 7.534), train_loss = 1.58543859, grad/param norm = 2.1672e-01, time/batch = 0.7001s	
3429/22750 (epoch 7.536), train_loss = 1.47206525, grad/param norm = 1.9696e-01, time/batch = 0.6905s	
3430/22750 (epoch 7.538), train_loss = 1.50025324, grad/param norm = 1.7391e-01, time/batch = 0.7005s	
3431/22750 (epoch 7.541), train_loss = 1.24842722, grad/param norm = 1.9251e-01, time/batch = 0.6924s	
3432/22750 (epoch 7.543), train_loss = 1.26018768, grad/param norm = 1.7620e-01, time/batch = 0.7035s	
3433/22750 (epoch 7.545), train_loss = 1.61911106, grad/param norm = 2.0618e-01, time/batch = 0.7144s	
3434/22750 (epoch 7.547), train_loss = 1.26857683, grad/param norm = 1.7214e-01, time/batch = 0.6932s	
3435/22750 (epoch 7.549), train_loss = 1.34756263, grad/param norm = 1.9976e-01, time/batch = 0.6983s	
3436/22750 (epoch 7.552), train_loss = 1.55477520, grad/param norm = 2.1778e-01, time/batch = 0.6966s	
3437/22750 (epoch 7.554), train_loss = 1.60959343, grad/param norm = 2.1283e-01, time/batch = 0.7075s	
3438/22750 (epoch 7.556), train_loss = 1.44476098, grad/param norm = 2.0132e-01, time/batch = 0.6976s	
3439/22750 (epoch 7.558), train_loss = 1.63319009, grad/param norm = 1.8682e-01, time/batch = 0.6915s	
3440/22750 (epoch 7.560), train_loss = 1.34715610, grad/param norm = 1.7953e-01, time/batch = 0.6919s	
3441/22750 (epoch 7.563), train_loss = 1.54389801, grad/param norm = 1.8223e-01, time/batch = 0.7016s	
3442/22750 (epoch 7.565), train_loss = 1.61917495, grad/param norm = 1.9087e-01, time/batch = 0.7062s	
3443/22750 (epoch 7.567), train_loss = 1.47646423, grad/param norm = 1.9901e-01, time/batch = 0.7070s	
3444/22750 (epoch 7.569), train_loss = 1.40395853, grad/param norm = 1.9191e-01, time/batch = 0.6987s	
3445/22750 (epoch 7.571), train_loss = 1.51219177, grad/param norm = 1.9802e-01, time/batch = 0.6960s	
3446/22750 (epoch 7.574), train_loss = 1.32397204, grad/param norm = 2.0097e-01, time/batch = 0.7149s	
3447/22750 (epoch 7.576), train_loss = 1.47847457, grad/param norm = 1.8476e-01, time/batch = 0.7322s	
3448/22750 (epoch 7.578), train_loss = 1.28519431, grad/param norm = 1.7590e-01, time/batch = 0.7251s	
3449/22750 (epoch 7.580), train_loss = 1.51135066, grad/param norm = 2.0639e-01, time/batch = 0.7047s	
3450/22750 (epoch 7.582), train_loss = 1.23927646, grad/param norm = 1.7651e-01, time/batch = 0.7131s	
3451/22750 (epoch 7.585), train_loss = 1.18255971, grad/param norm = 1.8815e-01, time/batch = 0.7092s	
3452/22750 (epoch 7.587), train_loss = 1.25310070, grad/param norm = 1.7146e-01, time/batch = 0.7107s	
3453/22750 (epoch 7.589), train_loss = 1.24828153, grad/param norm = 1.9285e-01, time/batch = 0.7339s	
3454/22750 (epoch 7.591), train_loss = 1.46293659, grad/param norm = 2.0506e-01, time/batch = 0.7108s	
3455/22750 (epoch 7.593), train_loss = 1.66931854, grad/param norm = 1.9014e-01, time/batch = 0.6953s	
3456/22750 (epoch 7.596), train_loss = 1.65435487, grad/param norm = 2.0431e-01, time/batch = 0.7062s	
3457/22750 (epoch 7.598), train_loss = 1.66424507, grad/param norm = 1.9386e-01, time/batch = 0.7112s	
3458/22750 (epoch 7.600), train_loss = 1.58045830, grad/param norm = 1.9722e-01, time/batch = 0.7003s	
3459/22750 (epoch 7.602), train_loss = 1.29104052, grad/param norm = 1.7015e-01, time/batch = 0.7236s	
3460/22750 (epoch 7.604), train_loss = 1.40608253, grad/param norm = 1.8263e-01, time/batch = 0.7252s	
3461/22750 (epoch 7.607), train_loss = 1.17576626, grad/param norm = 1.5976e-01, time/batch = 0.7205s	
3462/22750 (epoch 7.609), train_loss = 1.12244621, grad/param norm = 1.5516e-01, time/batch = 0.7101s	
3463/22750 (epoch 7.611), train_loss = 1.37389528, grad/param norm = 1.9933e-01, time/batch = 0.7191s	
3464/22750 (epoch 7.613), train_loss = 1.29355377, grad/param norm = 2.0341e-01, time/batch = 0.7143s	
3465/22750 (epoch 7.615), train_loss = 1.37225361, grad/param norm = 1.8819e-01, time/batch = 0.7215s	
3466/22750 (epoch 7.618), train_loss = 1.43114993, grad/param norm = 2.0032e-01, time/batch = 0.7057s	
3467/22750 (epoch 7.620), train_loss = 1.43395604, grad/param norm = 1.9099e-01, time/batch = 0.7283s	
3468/22750 (epoch 7.622), train_loss = 1.23453973, grad/param norm = 1.9530e-01, time/batch = 0.7241s	
3469/22750 (epoch 7.624), train_loss = 1.48624604, grad/param norm = 2.0499e-01, time/batch = 0.7098s	
3470/22750 (epoch 7.626), train_loss = 1.29241976, grad/param norm = 1.9291e-01, time/batch = 0.7025s	
3471/22750 (epoch 7.629), train_loss = 1.43744424, grad/param norm = 2.0506e-01, time/batch = 0.7190s	
3472/22750 (epoch 7.631), train_loss = 1.48229472, grad/param norm = 2.0418e-01, time/batch = 0.7050s	
3473/22750 (epoch 7.633), train_loss = 1.19654576, grad/param norm = 2.0154e-01, time/batch = 0.6962s	
3474/22750 (epoch 7.635), train_loss = 1.48681653, grad/param norm = 2.0361e-01, time/batch = 0.7001s	
3475/22750 (epoch 7.637), train_loss = 1.56654740, grad/param norm = 2.0143e-01, time/batch = 0.6999s	
3476/22750 (epoch 7.640), train_loss = 1.61033406, grad/param norm = 2.2014e-01, time/batch = 0.7013s	
3477/22750 (epoch 7.642), train_loss = 1.59676681, grad/param norm = 1.9528e-01, time/batch = 0.7036s	
3478/22750 (epoch 7.644), train_loss = 1.45983525, grad/param norm = 1.9807e-01, time/batch = 0.7034s	
3479/22750 (epoch 7.646), train_loss = 1.60257819, grad/param norm = 2.0996e-01, time/batch = 0.7261s	
3480/22750 (epoch 7.648), train_loss = 1.49613307, grad/param norm = 2.1016e-01, time/batch = 0.7244s	
3481/22750 (epoch 7.651), train_loss = 1.58702960, grad/param norm = 2.1022e-01, time/batch = 0.7256s	
3482/22750 (epoch 7.653), train_loss = 1.50277209, grad/param norm = 1.9356e-01, time/batch = 0.7196s	
3483/22750 (epoch 7.655), train_loss = 1.43612873, grad/param norm = 1.9624e-01, time/batch = 0.7013s	
3484/22750 (epoch 7.657), train_loss = 1.65013931, grad/param norm = 1.9905e-01, time/batch = 0.7210s	
3485/22750 (epoch 7.659), train_loss = 1.71714222, grad/param norm = 1.9588e-01, time/batch = 0.7144s	
3486/22750 (epoch 7.662), train_loss = 1.76911251, grad/param norm = 2.1856e-01, time/batch = 0.7045s	
3487/22750 (epoch 7.664), train_loss = 1.54613493, grad/param norm = 1.9988e-01, time/batch = 0.6951s	
3488/22750 (epoch 7.666), train_loss = 1.31279291, grad/param norm = 1.8650e-01, time/batch = 0.6967s	
3489/22750 (epoch 7.668), train_loss = 1.48041056, grad/param norm = 1.8345e-01, time/batch = 0.7167s	
3490/22750 (epoch 7.670), train_loss = 1.49829719, grad/param norm = 1.9266e-01, time/batch = 0.7253s	
3491/22750 (epoch 7.673), train_loss = 1.73264661, grad/param norm = 2.1538e-01, time/batch = 0.7256s	
3492/22750 (epoch 7.675), train_loss = 1.95985999, grad/param norm = 2.2779e-01, time/batch = 0.7113s	
3493/22750 (epoch 7.677), train_loss = 1.71787595, grad/param norm = 2.1356e-01, time/batch = 0.7018s	
3494/22750 (epoch 7.679), train_loss = 1.77306390, grad/param norm = 2.1179e-01, time/batch = 0.6992s	
3495/22750 (epoch 7.681), train_loss = 1.67489943, grad/param norm = 2.1220e-01, time/batch = 0.7096s	
3496/22750 (epoch 7.684), train_loss = 1.63863948, grad/param norm = 1.9733e-01, time/batch = 0.7062s	
3497/22750 (epoch 7.686), train_loss = 1.63977740, grad/param norm = 2.0973e-01, time/batch = 0.7012s	
3498/22750 (epoch 7.688), train_loss = 1.60135115, grad/param norm = 2.0895e-01, time/batch = 0.6984s	
3499/22750 (epoch 7.690), train_loss = 1.58574826, grad/param norm = 2.1238e-01, time/batch = 0.7221s	
3500/22750 (epoch 7.692), train_loss = 1.72703260, grad/param norm = 2.1463e-01, time/batch = 0.7232s	
3501/22750 (epoch 7.695), train_loss = 1.49360182, grad/param norm = 1.9441e-01, time/batch = 0.7051s	
3502/22750 (epoch 7.697), train_loss = 1.46430065, grad/param norm = 2.0894e-01, time/batch = 0.7264s	
3503/22750 (epoch 7.699), train_loss = 1.50675159, grad/param norm = 1.8247e-01, time/batch = 0.7228s	
3504/22750 (epoch 7.701), train_loss = 1.33260675, grad/param norm = 1.8373e-01, time/batch = 0.7281s	
3505/22750 (epoch 7.703), train_loss = 1.52564236, grad/param norm = 1.8945e-01, time/batch = 0.7108s	
3506/22750 (epoch 7.705), train_loss = 1.34456560, grad/param norm = 1.6994e-01, time/batch = 0.7002s	
3507/22750 (epoch 7.708), train_loss = 1.49707830, grad/param norm = 1.6782e-01, time/batch = 0.7190s	
3508/22750 (epoch 7.710), train_loss = 1.26370542, grad/param norm = 2.0671e-01, time/batch = 0.7193s	
3509/22750 (epoch 7.712), train_loss = 1.37463772, grad/param norm = 1.8988e-01, time/batch = 0.7225s	
3510/22750 (epoch 7.714), train_loss = 1.24402320, grad/param norm = 1.8008e-01, time/batch = 0.7041s	
3511/22750 (epoch 7.716), train_loss = 1.35011091, grad/param norm = 1.9700e-01, time/batch = 0.7038s	
3512/22750 (epoch 7.719), train_loss = 1.59514478, grad/param norm = 2.3692e-01, time/batch = 0.7236s	
3513/22750 (epoch 7.721), train_loss = 1.55136960, grad/param norm = 2.0405e-01, time/batch = 0.7135s	
3514/22750 (epoch 7.723), train_loss = 1.46830137, grad/param norm = 2.0012e-01, time/batch = 0.7048s	
3515/22750 (epoch 7.725), train_loss = 1.48007541, grad/param norm = 2.2353e-01, time/batch = 0.6973s	
3516/22750 (epoch 7.727), train_loss = 1.39749857, grad/param norm = 1.8213e-01, time/batch = 0.7035s	
3517/22750 (epoch 7.730), train_loss = 1.40501532, grad/param norm = 1.9264e-01, time/batch = 0.7033s	
3518/22750 (epoch 7.732), train_loss = 1.43215110, grad/param norm = 2.0147e-01, time/batch = 0.6967s	
3519/22750 (epoch 7.734), train_loss = 1.14264974, grad/param norm = 1.9032e-01, time/batch = 0.7025s	
3520/22750 (epoch 7.736), train_loss = 1.34520831, grad/param norm = 1.8135e-01, time/batch = 0.6985s	
3521/22750 (epoch 7.738), train_loss = 1.45600774, grad/param norm = 1.9884e-01, time/batch = 0.7115s	
3522/22750 (epoch 7.741), train_loss = 1.56944574, grad/param norm = 1.8756e-01, time/batch = 0.6993s	
3523/22750 (epoch 7.743), train_loss = 1.52875627, grad/param norm = 1.9784e-01, time/batch = 0.6983s	
3524/22750 (epoch 7.745), train_loss = 1.25004873, grad/param norm = 1.6472e-01, time/batch = 0.6954s	
3525/22750 (epoch 7.747), train_loss = 1.38249739, grad/param norm = 1.9822e-01, time/batch = 0.6955s	
3526/22750 (epoch 7.749), train_loss = 1.66784739, grad/param norm = 2.0830e-01, time/batch = 0.6972s	
3527/22750 (epoch 7.752), train_loss = 1.38579415, grad/param norm = 1.9662e-01, time/batch = 0.6987s	
3528/22750 (epoch 7.754), train_loss = 1.64925431, grad/param norm = 2.3627e-01, time/batch = 0.7006s	
3529/22750 (epoch 7.756), train_loss = 1.29494586, grad/param norm = 2.1387e-01, time/batch = 0.6946s	
3530/22750 (epoch 7.758), train_loss = 1.25219860, grad/param norm = 1.8663e-01, time/batch = 0.7090s	
3531/22750 (epoch 7.760), train_loss = 1.47391773, grad/param norm = 1.9575e-01, time/batch = 0.7237s	
3532/22750 (epoch 7.763), train_loss = 1.50889347, grad/param norm = 1.8403e-01, time/batch = 0.7178s	
3533/22750 (epoch 7.765), train_loss = 1.38446541, grad/param norm = 2.1255e-01, time/batch = 0.7168s	
3534/22750 (epoch 7.767), train_loss = 1.44286445, grad/param norm = 1.7925e-01, time/batch = 0.7036s	
3535/22750 (epoch 7.769), train_loss = 1.64497629, grad/param norm = 2.0368e-01, time/batch = 0.7040s	
3536/22750 (epoch 7.771), train_loss = 1.60530232, grad/param norm = 1.9374e-01, time/batch = 0.7009s	
3537/22750 (epoch 7.774), train_loss = 1.36484839, grad/param norm = 2.2096e-01, time/batch = 0.7041s	
3538/22750 (epoch 7.776), train_loss = 1.46570868, grad/param norm = 2.0454e-01, time/batch = 0.7005s	
3539/22750 (epoch 7.778), train_loss = 1.67246886, grad/param norm = 1.8789e-01, time/batch = 0.7236s	
3540/22750 (epoch 7.780), train_loss = 1.50394749, grad/param norm = 2.0692e-01, time/batch = 0.7164s	
3541/22750 (epoch 7.782), train_loss = 1.60150161, grad/param norm = 2.0167e-01, time/batch = 0.7164s	
3542/22750 (epoch 7.785), train_loss = 1.46677317, grad/param norm = 1.8735e-01, time/batch = 0.7077s	
3543/22750 (epoch 7.787), train_loss = 1.35299369, grad/param norm = 1.8811e-01, time/batch = 0.7058s	
3544/22750 (epoch 7.789), train_loss = 1.39531985, grad/param norm = 1.7542e-01, time/batch = 0.7101s	
3545/22750 (epoch 7.791), train_loss = 1.42759732, grad/param norm = 1.8156e-01, time/batch = 0.6995s	
3546/22750 (epoch 7.793), train_loss = 1.42169597, grad/param norm = 2.2747e-01, time/batch = 0.7083s	
3547/22750 (epoch 7.796), train_loss = 1.30118417, grad/param norm = 1.9636e-01, time/batch = 0.7054s	
3548/22750 (epoch 7.798), train_loss = 1.31252690, grad/param norm = 1.6593e-01, time/batch = 0.6967s	
3549/22750 (epoch 7.800), train_loss = 1.28829242, grad/param norm = 1.7408e-01, time/batch = 0.7003s	
3550/22750 (epoch 7.802), train_loss = 1.38323063, grad/param norm = 1.8832e-01, time/batch = 0.7081s	
3551/22750 (epoch 7.804), train_loss = 1.69510841, grad/param norm = 2.0271e-01, time/batch = 0.7281s	
3552/22750 (epoch 7.807), train_loss = 1.50227688, grad/param norm = 1.9634e-01, time/batch = 0.7228s	
3553/22750 (epoch 7.809), train_loss = 1.73400070, grad/param norm = 2.2116e-01, time/batch = 0.6990s	
3554/22750 (epoch 7.811), train_loss = 1.41537105, grad/param norm = 1.8811e-01, time/batch = 0.7002s	
3555/22750 (epoch 7.813), train_loss = 1.51345337, grad/param norm = 1.8462e-01, time/batch = 0.6928s	
3556/22750 (epoch 7.815), train_loss = 1.66968800, grad/param norm = 2.2019e-01, time/batch = 0.7007s	
3557/22750 (epoch 7.818), train_loss = 1.61689279, grad/param norm = 2.0144e-01, time/batch = 0.6966s	
3558/22750 (epoch 7.820), train_loss = 1.73148147, grad/param norm = 1.8235e-01, time/batch = 0.6999s	
3559/22750 (epoch 7.822), train_loss = 1.49074822, grad/param norm = 1.8743e-01, time/batch = 0.7074s	
3560/22750 (epoch 7.824), train_loss = 1.46133896, grad/param norm = 1.8809e-01, time/batch = 0.7083s	
3561/22750 (epoch 7.826), train_loss = 1.49915697, grad/param norm = 1.9155e-01, time/batch = 0.7225s	
3562/22750 (epoch 7.829), train_loss = 1.66577685, grad/param norm = 2.2451e-01, time/batch = 0.7200s	
3563/22750 (epoch 7.831), train_loss = 1.62831233, grad/param norm = 2.0921e-01, time/batch = 0.7092s	
3564/22750 (epoch 7.833), train_loss = 1.58264979, grad/param norm = 2.1614e-01, time/batch = 0.7117s	
3565/22750 (epoch 7.835), train_loss = 1.39534672, grad/param norm = 1.8244e-01, time/batch = 0.7005s	
3566/22750 (epoch 7.837), train_loss = 1.39568293, grad/param norm = 1.9862e-01, time/batch = 0.6974s	
3567/22750 (epoch 7.840), train_loss = 1.42649746, grad/param norm = 2.0876e-01, time/batch = 0.6930s	
3568/22750 (epoch 7.842), train_loss = 1.39178015, grad/param norm = 1.7454e-01, time/batch = 0.7096s	
3569/22750 (epoch 7.844), train_loss = 1.65218001, grad/param norm = 2.0794e-01, time/batch = 0.7151s	
3570/22750 (epoch 7.846), train_loss = 1.45437739, grad/param norm = 1.8953e-01, time/batch = 0.7056s	
3571/22750 (epoch 7.848), train_loss = 1.30635224, grad/param norm = 1.9390e-01, time/batch = 0.7087s	
3572/22750 (epoch 7.851), train_loss = 1.33430501, grad/param norm = 1.8595e-01, time/batch = 0.7107s	
3573/22750 (epoch 7.853), train_loss = 1.45742114, grad/param norm = 1.8633e-01, time/batch = 0.6971s	
3574/22750 (epoch 7.855), train_loss = 1.26153157, grad/param norm = 1.9793e-01, time/batch = 0.7089s	
3575/22750 (epoch 7.857), train_loss = 1.47804140, grad/param norm = 1.7841e-01, time/batch = 0.7163s	
3576/22750 (epoch 7.859), train_loss = 1.50112266, grad/param norm = 2.0480e-01, time/batch = 0.7098s	
3577/22750 (epoch 7.862), train_loss = 1.67101015, grad/param norm = 1.9499e-01, time/batch = 0.7211s	
3578/22750 (epoch 7.864), train_loss = 1.44879874, grad/param norm = 1.9030e-01, time/batch = 0.7164s	
3579/22750 (epoch 7.866), train_loss = 1.49361464, grad/param norm = 1.8998e-01, time/batch = 0.7200s	
3580/22750 (epoch 7.868), train_loss = 1.42841349, grad/param norm = 1.8418e-01, time/batch = 0.7087s	
3581/22750 (epoch 7.870), train_loss = 1.26051890, grad/param norm = 1.8490e-01, time/batch = 0.7099s	
3582/22750 (epoch 7.873), train_loss = 1.41496131, grad/param norm = 1.9718e-01, time/batch = 0.7275s	
3583/22750 (epoch 7.875), train_loss = 1.52389770, grad/param norm = 1.8329e-01, time/batch = 0.7247s	
3584/22750 (epoch 7.877), train_loss = 1.38625078, grad/param norm = 1.8468e-01, time/batch = 0.7280s	
3585/22750 (epoch 7.879), train_loss = 1.59833279, grad/param norm = 2.1158e-01, time/batch = 0.7279s	
3586/22750 (epoch 7.881), train_loss = 1.57694489, grad/param norm = 2.0700e-01, time/batch = 0.7260s	
3587/22750 (epoch 7.884), train_loss = 1.35718004, grad/param norm = 1.9271e-01, time/batch = 0.7206s	
3588/22750 (epoch 7.886), train_loss = 1.54985952, grad/param norm = 1.9497e-01, time/batch = 0.7040s	
3589/22750 (epoch 7.888), train_loss = 1.52192866, grad/param norm = 1.8462e-01, time/batch = 0.7008s	
3590/22750 (epoch 7.890), train_loss = 1.57244159, grad/param norm = 1.9568e-01, time/batch = 0.6975s	
3591/22750 (epoch 7.892), train_loss = 1.89720733, grad/param norm = 2.2443e-01, time/batch = 0.7002s	
3592/22750 (epoch 7.895), train_loss = 1.58362764, grad/param norm = 1.8588e-01, time/batch = 0.7138s	
3593/22750 (epoch 7.897), train_loss = 1.61326115, grad/param norm = 2.0965e-01, time/batch = 0.7077s	
3594/22750 (epoch 7.899), train_loss = 1.54035315, grad/param norm = 1.9531e-01, time/batch = 0.7027s	
3595/22750 (epoch 7.901), train_loss = 1.68576943, grad/param norm = 2.0376e-01, time/batch = 0.6969s	
3596/22750 (epoch 7.903), train_loss = 1.45698626, grad/param norm = 1.8934e-01, time/batch = 0.7060s	
3597/22750 (epoch 7.905), train_loss = 1.55146435, grad/param norm = 1.7954e-01, time/batch = 0.7133s	
3598/22750 (epoch 7.908), train_loss = 1.44644707, grad/param norm = 2.0277e-01, time/batch = 0.6989s	
3599/22750 (epoch 7.910), train_loss = 1.26163488, grad/param norm = 1.9894e-01, time/batch = 0.6955s	
3600/22750 (epoch 7.912), train_loss = 1.34335933, grad/param norm = 1.8566e-01, time/batch = 0.6924s	
3601/22750 (epoch 7.914), train_loss = 1.41091877, grad/param norm = 1.8657e-01, time/batch = 0.7029s	
3602/22750 (epoch 7.916), train_loss = 1.25231175, grad/param norm = 1.8381e-01, time/batch = 0.7007s	
3603/22750 (epoch 7.919), train_loss = 1.34876087, grad/param norm = 1.8858e-01, time/batch = 0.7059s	
3604/22750 (epoch 7.921), train_loss = 1.07114516, grad/param norm = 1.6406e-01, time/batch = 0.7036s	
3605/22750 (epoch 7.923), train_loss = 1.40566789, grad/param norm = 1.8443e-01, time/batch = 0.7012s	
3606/22750 (epoch 7.925), train_loss = 1.40420765, grad/param norm = 1.8076e-01, time/batch = 0.7113s	
3607/22750 (epoch 7.927), train_loss = 1.19203307, grad/param norm = 1.8009e-01, time/batch = 0.7188s	
3608/22750 (epoch 7.930), train_loss = 1.23695274, grad/param norm = 1.7853e-01, time/batch = 0.7241s	
3609/22750 (epoch 7.932), train_loss = 1.53604398, grad/param norm = 1.9542e-01, time/batch = 0.7184s	
3610/22750 (epoch 7.934), train_loss = 1.09356439, grad/param norm = 1.6028e-01, time/batch = 0.7062s	
3611/22750 (epoch 7.936), train_loss = 1.59993556, grad/param norm = 2.1377e-01, time/batch = 0.6921s	
3612/22750 (epoch 7.938), train_loss = 1.50123576, grad/param norm = 1.9334e-01, time/batch = 0.6920s	
3613/22750 (epoch 7.941), train_loss = 1.74679458, grad/param norm = 2.0853e-01, time/batch = 0.6908s	
3614/22750 (epoch 7.943), train_loss = 1.54581341, grad/param norm = 1.9370e-01, time/batch = 0.6965s	
3615/22750 (epoch 7.945), train_loss = 1.46876503, grad/param norm = 1.8292e-01, time/batch = 0.7269s	
3616/22750 (epoch 7.947), train_loss = 1.43627507, grad/param norm = 2.0789e-01, time/batch = 0.7333s	
3617/22750 (epoch 7.949), train_loss = 1.31877194, grad/param norm = 1.9641e-01, time/batch = 0.7395s	
3618/22750 (epoch 7.952), train_loss = 1.35996623, grad/param norm = 1.9831e-01, time/batch = 0.7258s	
3619/22750 (epoch 7.954), train_loss = 1.34377530, grad/param norm = 1.7411e-01, time/batch = 0.7069s	
3620/22750 (epoch 7.956), train_loss = 1.45793414, grad/param norm = 1.8885e-01, time/batch = 0.7057s	
3621/22750 (epoch 7.958), train_loss = 1.40265420, grad/param norm = 1.8105e-01, time/batch = 0.7217s	
3622/22750 (epoch 7.960), train_loss = 1.41971721, grad/param norm = 1.7841e-01, time/batch = 0.7049s	
3623/22750 (epoch 7.963), train_loss = 1.61829326, grad/param norm = 1.9782e-01, time/batch = 0.7072s	
3624/22750 (epoch 7.965), train_loss = 1.55192576, grad/param norm = 1.9827e-01, time/batch = 0.6975s	
3625/22750 (epoch 7.967), train_loss = 1.47168525, grad/param norm = 2.1132e-01, time/batch = 0.6985s	
3626/22750 (epoch 7.969), train_loss = 1.40101848, grad/param norm = 1.9349e-01, time/batch = 0.7186s	
3627/22750 (epoch 7.971), train_loss = 1.39904804, grad/param norm = 1.9154e-01, time/batch = 0.6998s	
3628/22750 (epoch 7.974), train_loss = 1.45889848, grad/param norm = 2.0291e-01, time/batch = 0.6962s	
3629/22750 (epoch 7.976), train_loss = 1.56047816, grad/param norm = 1.9872e-01, time/batch = 0.6971s	
3630/22750 (epoch 7.978), train_loss = 1.31486643, grad/param norm = 1.7779e-01, time/batch = 0.7044s	
3631/22750 (epoch 7.980), train_loss = 1.60293329, grad/param norm = 2.1154e-01, time/batch = 0.7022s	
3632/22750 (epoch 7.982), train_loss = 1.38129748, grad/param norm = 1.7778e-01, time/batch = 0.6979s	
3633/22750 (epoch 7.985), train_loss = 1.71883782, grad/param norm = 2.2418e-01, time/batch = 0.6962s	
3634/22750 (epoch 7.987), train_loss = 1.24172235, grad/param norm = 1.7138e-01, time/batch = 0.6984s	
3635/22750 (epoch 7.989), train_loss = 1.36206103, grad/param norm = 1.7077e-01, time/batch = 0.7005s	
3636/22750 (epoch 7.991), train_loss = 1.54292016, grad/param norm = 1.8596e-01, time/batch = 0.6955s	
3637/22750 (epoch 7.993), train_loss = 1.57101605, grad/param norm = 2.0079e-01, time/batch = 0.6995s	
3638/22750 (epoch 7.996), train_loss = 1.42879690, grad/param norm = 2.1026e-01, time/batch = 0.6946s	
3639/22750 (epoch 7.998), train_loss = 1.61439065, grad/param norm = 1.9457e-01, time/batch = 0.6953s	
3640/22750 (epoch 8.000), train_loss = 1.51316484, grad/param norm = 1.9192e-01, time/batch = 0.6983s	
3641/22750 (epoch 8.002), train_loss = 1.60988593, grad/param norm = 2.1115e-01, time/batch = 0.6942s	
3642/22750 (epoch 8.004), train_loss = 1.38635234, grad/param norm = 2.0550e-01, time/batch = 0.6984s	
3643/22750 (epoch 8.007), train_loss = 1.48220283, grad/param norm = 1.9617e-01, time/batch = 0.7008s	
3644/22750 (epoch 8.009), train_loss = 1.75535407, grad/param norm = 1.9260e-01, time/batch = 0.6964s	
3645/22750 (epoch 8.011), train_loss = 1.70225048, grad/param norm = 2.0103e-01, time/batch = 0.6954s	
3646/22750 (epoch 8.013), train_loss = 1.55428745, grad/param norm = 1.8704e-01, time/batch = 0.6934s	
3647/22750 (epoch 8.015), train_loss = 1.52878557, grad/param norm = 1.9948e-01, time/batch = 0.6916s	
3648/22750 (epoch 8.018), train_loss = 1.57437469, grad/param norm = 2.0145e-01, time/batch = 0.6984s	
3649/22750 (epoch 8.020), train_loss = 1.66280972, grad/param norm = 1.9011e-01, time/batch = 0.7003s	
3650/22750 (epoch 8.022), train_loss = 1.45658642, grad/param norm = 1.7473e-01, time/batch = 0.7010s	
3651/22750 (epoch 8.024), train_loss = 1.45469395, grad/param norm = 2.0449e-01, time/batch = 0.7044s	
3652/22750 (epoch 8.026), train_loss = 1.60447207, grad/param norm = 2.1357e-01, time/batch = 0.6994s	
3653/22750 (epoch 8.029), train_loss = 1.23154602, grad/param norm = 1.6941e-01, time/batch = 0.6960s	
3654/22750 (epoch 8.031), train_loss = 1.76257643, grad/param norm = 2.0907e-01, time/batch = 0.6918s	
3655/22750 (epoch 8.033), train_loss = 1.49199506, grad/param norm = 1.9881e-01, time/batch = 0.6993s	
3656/22750 (epoch 8.035), train_loss = 1.54711261, grad/param norm = 2.1470e-01, time/batch = 0.6963s	
3657/22750 (epoch 8.037), train_loss = 1.62678979, grad/param norm = 2.1074e-01, time/batch = 0.6926s	
3658/22750 (epoch 8.040), train_loss = 1.40078966, grad/param norm = 2.0836e-01, time/batch = 0.6996s	
3659/22750 (epoch 8.042), train_loss = 1.57924627, grad/param norm = 2.0416e-01, time/batch = 0.6986s	
3660/22750 (epoch 8.044), train_loss = 1.40198254, grad/param norm = 2.0465e-01, time/batch = 0.7008s	
3661/22750 (epoch 8.046), train_loss = 1.55838916, grad/param norm = 2.2093e-01, time/batch = 0.6915s	
3662/22750 (epoch 8.048), train_loss = 1.45369082, grad/param norm = 1.9428e-01, time/batch = 0.6941s	
3663/22750 (epoch 8.051), train_loss = 1.49252545, grad/param norm = 1.8154e-01, time/batch = 0.7052s	
3664/22750 (epoch 8.053), train_loss = 1.28447500, grad/param norm = 1.8636e-01, time/batch = 0.6999s	
3665/22750 (epoch 8.055), train_loss = 1.44457533, grad/param norm = 1.9587e-01, time/batch = 0.6985s	
3666/22750 (epoch 8.057), train_loss = 1.60784842, grad/param norm = 2.0258e-01, time/batch = 0.6953s	
3667/22750 (epoch 8.059), train_loss = 1.10892497, grad/param norm = 1.7348e-01, time/batch = 0.6950s	
3668/22750 (epoch 8.062), train_loss = 1.26967965, grad/param norm = 1.7600e-01, time/batch = 0.6945s	
3669/22750 (epoch 8.064), train_loss = 1.50102599, grad/param norm = 2.0364e-01, time/batch = 0.7036s	
3670/22750 (epoch 8.066), train_loss = 1.25941825, grad/param norm = 1.7445e-01, time/batch = 0.7109s	
3671/22750 (epoch 8.068), train_loss = 1.32254327, grad/param norm = 1.6939e-01, time/batch = 0.7033s	
3672/22750 (epoch 8.070), train_loss = 1.23537533, grad/param norm = 1.7994e-01, time/batch = 0.6984s	
3673/22750 (epoch 8.073), train_loss = 1.36223852, grad/param norm = 1.8313e-01, time/batch = 0.7022s	
3674/22750 (epoch 8.075), train_loss = 1.40898829, grad/param norm = 1.8475e-01, time/batch = 0.7088s	
3675/22750 (epoch 8.077), train_loss = 1.10264616, grad/param norm = 1.7735e-01, time/batch = 0.6959s	
3676/22750 (epoch 8.079), train_loss = 1.39807002, grad/param norm = 1.9715e-01, time/batch = 0.6939s	
3677/22750 (epoch 8.081), train_loss = 1.43319867, grad/param norm = 2.2030e-01, time/batch = 0.6937s	
3678/22750 (epoch 8.084), train_loss = 1.34784406, grad/param norm = 1.9698e-01, time/batch = 0.6981s	
3679/22750 (epoch 8.086), train_loss = 1.35912418, grad/param norm = 1.6855e-01, time/batch = 0.6951s	
3680/22750 (epoch 8.088), train_loss = 1.36920493, grad/param norm = 2.0347e-01, time/batch = 0.6921s	
3681/22750 (epoch 8.090), train_loss = 1.39675302, grad/param norm = 1.7424e-01, time/batch = 0.6949s	
3682/22750 (epoch 8.092), train_loss = 1.60606949, grad/param norm = 1.8986e-01, time/batch = 0.6956s	
3683/22750 (epoch 8.095), train_loss = 1.28026880, grad/param norm = 1.8064e-01, time/batch = 0.6957s	
3684/22750 (epoch 8.097), train_loss = 1.37330945, grad/param norm = 1.8208e-01, time/batch = 0.6988s	
3685/22750 (epoch 8.099), train_loss = 1.44634899, grad/param norm = 1.9229e-01, time/batch = 0.6971s	
3686/22750 (epoch 8.101), train_loss = 1.38094775, grad/param norm = 1.8905e-01, time/batch = 0.6938s	
3687/22750 (epoch 8.103), train_loss = 1.41815792, grad/param norm = 1.9322e-01, time/batch = 0.7001s	
3688/22750 (epoch 8.105), train_loss = 1.74292283, grad/param norm = 2.2274e-01, time/batch = 0.6949s	
3689/22750 (epoch 8.108), train_loss = 1.38983435, grad/param norm = 1.8087e-01, time/batch = 0.6931s	
3690/22750 (epoch 8.110), train_loss = 1.49640253, grad/param norm = 1.8704e-01, time/batch = 0.6945s	
3691/22750 (epoch 8.112), train_loss = 1.18766089, grad/param norm = 1.6741e-01, time/batch = 0.7067s	
3692/22750 (epoch 8.114), train_loss = 1.14021378, grad/param norm = 1.8163e-01, time/batch = 0.6969s	
3693/22750 (epoch 8.116), train_loss = 1.26816265, grad/param norm = 1.7241e-01, time/batch = 0.6964s	
3694/22750 (epoch 8.119), train_loss = 1.30844333, grad/param norm = 1.7666e-01, time/batch = 0.7015s	
3695/22750 (epoch 8.121), train_loss = 1.53781153, grad/param norm = 2.1856e-01, time/batch = 0.6969s	
3696/22750 (epoch 8.123), train_loss = 1.31849924, grad/param norm = 1.6822e-01, time/batch = 0.6976s	
3697/22750 (epoch 8.125), train_loss = 1.59098001, grad/param norm = 1.9596e-01, time/batch = 0.6975s	
3698/22750 (epoch 8.127), train_loss = 1.47194854, grad/param norm = 2.0188e-01, time/batch = 0.6973s	
3699/22750 (epoch 8.130), train_loss = 1.48915955, grad/param norm = 1.8503e-01, time/batch = 0.6981s	
3700/22750 (epoch 8.132), train_loss = 1.51559703, grad/param norm = 2.1411e-01, time/batch = 0.7185s	
3701/22750 (epoch 8.134), train_loss = 1.38928169, grad/param norm = 1.9023e-01, time/batch = 0.7301s	
3702/22750 (epoch 8.136), train_loss = 1.24437536, grad/param norm = 1.7540e-01, time/batch = 0.7116s	
3703/22750 (epoch 8.138), train_loss = 1.45781920, grad/param norm = 2.0209e-01, time/batch = 0.7024s	
3704/22750 (epoch 8.141), train_loss = 1.32926475, grad/param norm = 1.7732e-01, time/batch = 0.7007s	
3705/22750 (epoch 8.143), train_loss = 1.24499435, grad/param norm = 1.7243e-01, time/batch = 0.6991s	
3706/22750 (epoch 8.145), train_loss = 1.56490166, grad/param norm = 1.9042e-01, time/batch = 0.6979s	
3707/22750 (epoch 8.147), train_loss = 1.57616659, grad/param norm = 2.1034e-01, time/batch = 0.7077s	
3708/22750 (epoch 8.149), train_loss = 1.43196432, grad/param norm = 1.9378e-01, time/batch = 0.7246s	
3709/22750 (epoch 8.152), train_loss = 1.35374966, grad/param norm = 1.9541e-01, time/batch = 0.7110s	
3710/22750 (epoch 8.154), train_loss = 1.19400519, grad/param norm = 1.8663e-01, time/batch = 0.7007s	
3711/22750 (epoch 8.156), train_loss = 1.25738647, grad/param norm = 1.8019e-01, time/batch = 0.7003s	
3712/22750 (epoch 8.158), train_loss = 1.38270190, grad/param norm = 2.0401e-01, time/batch = 0.7015s	
3713/22750 (epoch 8.160), train_loss = 1.49026838, grad/param norm = 1.9412e-01, time/batch = 0.6976s	
3714/22750 (epoch 8.163), train_loss = 1.70756373, grad/param norm = 2.2073e-01, time/batch = 0.6973s	
3715/22750 (epoch 8.165), train_loss = 1.55150401, grad/param norm = 2.0288e-01, time/batch = 0.7022s	
3716/22750 (epoch 8.167), train_loss = 1.36915356, grad/param norm = 1.9344e-01, time/batch = 0.6958s	
3717/22750 (epoch 8.169), train_loss = 1.47233043, grad/param norm = 1.9810e-01, time/batch = 0.7031s	
3718/22750 (epoch 8.171), train_loss = 1.28490999, grad/param norm = 1.9074e-01, time/batch = 0.6979s	
3719/22750 (epoch 8.174), train_loss = 1.16944309, grad/param norm = 1.8011e-01, time/batch = 0.7004s	
3720/22750 (epoch 8.176), train_loss = 1.43072554, grad/param norm = 1.8405e-01, time/batch = 0.6980s	
3721/22750 (epoch 8.178), train_loss = 1.39183653, grad/param norm = 1.8078e-01, time/batch = 0.7038s	
3722/22750 (epoch 8.180), train_loss = 1.53789963, grad/param norm = 2.1798e-01, time/batch = 0.7209s	
3723/22750 (epoch 8.182), train_loss = 1.55059475, grad/param norm = 1.8097e-01, time/batch = 0.6964s	
3724/22750 (epoch 8.185), train_loss = 1.54372757, grad/param norm = 2.0083e-01, time/batch = 0.6954s	
3725/22750 (epoch 8.187), train_loss = 1.32037913, grad/param norm = 1.8417e-01, time/batch = 0.6994s	
3726/22750 (epoch 8.189), train_loss = 1.34543018, grad/param norm = 1.9086e-01, time/batch = 0.6922s	
3727/22750 (epoch 8.191), train_loss = 1.24936242, grad/param norm = 1.6066e-01, time/batch = 0.6970s	
3728/22750 (epoch 8.193), train_loss = 1.51134520, grad/param norm = 1.9195e-01, time/batch = 0.7007s	
3729/22750 (epoch 8.196), train_loss = 1.41172316, grad/param norm = 1.8962e-01, time/batch = 0.6964s	
3730/22750 (epoch 8.198), train_loss = 1.14861341, grad/param norm = 1.5259e-01, time/batch = 0.6983s	
3731/22750 (epoch 8.200), train_loss = 1.43619660, grad/param norm = 1.8830e-01, time/batch = 0.6981s	
3732/22750 (epoch 8.202), train_loss = 1.59770036, grad/param norm = 2.0640e-01, time/batch = 0.7188s	
3733/22750 (epoch 8.204), train_loss = 1.55858291, grad/param norm = 1.9578e-01, time/batch = 0.7092s	
3734/22750 (epoch 8.207), train_loss = 1.36393452, grad/param norm = 1.8399e-01, time/batch = 0.7089s	
3735/22750 (epoch 8.209), train_loss = 1.27862306, grad/param norm = 1.8195e-01, time/batch = 0.6975s	
3736/22750 (epoch 8.211), train_loss = 1.36943292, grad/param norm = 2.0034e-01, time/batch = 0.6965s	
3737/22750 (epoch 8.213), train_loss = 1.27257225, grad/param norm = 1.9244e-01, time/batch = 0.6992s	
3738/22750 (epoch 8.215), train_loss = 1.25876462, grad/param norm = 1.9122e-01, time/batch = 0.6970s	
3739/22750 (epoch 8.218), train_loss = 1.24497195, grad/param norm = 2.1340e-01, time/batch = 0.6927s	
3740/22750 (epoch 8.220), train_loss = 1.38754206, grad/param norm = 1.9762e-01, time/batch = 0.6981s	
3741/22750 (epoch 8.222), train_loss = 1.24615028, grad/param norm = 1.9592e-01, time/batch = 0.7107s	
3742/22750 (epoch 8.224), train_loss = 1.30957019, grad/param norm = 1.8127e-01, time/batch = 0.7002s	
3743/22750 (epoch 8.226), train_loss = 1.51285040, grad/param norm = 2.1077e-01, time/batch = 0.7087s	
3744/22750 (epoch 8.229), train_loss = 1.46596632, grad/param norm = 2.0249e-01, time/batch = 0.7023s	
3745/22750 (epoch 8.231), train_loss = 1.36592341, grad/param norm = 1.8617e-01, time/batch = 0.7099s	
3746/22750 (epoch 8.233), train_loss = 1.27483590, grad/param norm = 1.8544e-01, time/batch = 0.6997s	
3747/22750 (epoch 8.235), train_loss = 1.28224725, grad/param norm = 1.9786e-01, time/batch = 0.7016s	
3748/22750 (epoch 8.237), train_loss = 1.33261134, grad/param norm = 1.9517e-01, time/batch = 0.7061s	
3749/22750 (epoch 8.240), train_loss = 1.48055941, grad/param norm = 1.7558e-01, time/batch = 0.7092s	
3750/22750 (epoch 8.242), train_loss = 1.82089144, grad/param norm = 2.0952e-01, time/batch = 0.7234s	
3751/22750 (epoch 8.244), train_loss = 1.61415546, grad/param norm = 2.1204e-01, time/batch = 0.7071s	
3752/22750 (epoch 8.246), train_loss = 1.66590177, grad/param norm = 1.9284e-01, time/batch = 0.6996s	
3753/22750 (epoch 8.248), train_loss = 1.38076777, grad/param norm = 1.9684e-01, time/batch = 0.7030s	
3754/22750 (epoch 8.251), train_loss = 1.65905489, grad/param norm = 1.8856e-01, time/batch = 0.6995s	
3755/22750 (epoch 8.253), train_loss = 1.43709397, grad/param norm = 1.8635e-01, time/batch = 0.7054s	
3756/22750 (epoch 8.255), train_loss = 1.46258881, grad/param norm = 1.9329e-01, time/batch = 0.7239s	
3757/22750 (epoch 8.257), train_loss = 1.39599320, grad/param norm = 1.9603e-01, time/batch = 0.7037s	
3758/22750 (epoch 8.259), train_loss = 1.61789509, grad/param norm = 2.1474e-01, time/batch = 0.6977s	
3759/22750 (epoch 8.262), train_loss = 1.40463616, grad/param norm = 1.9169e-01, time/batch = 0.6924s	
3760/22750 (epoch 8.264), train_loss = 1.30542728, grad/param norm = 1.7738e-01, time/batch = 0.7078s	
3761/22750 (epoch 8.266), train_loss = 1.45362649, grad/param norm = 2.1192e-01, time/batch = 0.7040s	
3762/22750 (epoch 8.268), train_loss = 1.59284835, grad/param norm = 2.0224e-01, time/batch = 0.7020s	
3763/22750 (epoch 8.270), train_loss = 1.39877173, grad/param norm = 2.0487e-01, time/batch = 0.7053s	
3764/22750 (epoch 8.273), train_loss = 1.71715195, grad/param norm = 2.3018e-01, time/batch = 0.6955s	
3765/22750 (epoch 8.275), train_loss = 1.48341478, grad/param norm = 1.8876e-01, time/batch = 0.7001s	
3766/22750 (epoch 8.277), train_loss = 1.43370710, grad/param norm = 1.9126e-01, time/batch = 0.7061s	
3767/22750 (epoch 8.279), train_loss = 1.25193074, grad/param norm = 1.7629e-01, time/batch = 0.7070s	
3768/22750 (epoch 8.281), train_loss = 1.50069649, grad/param norm = 1.8288e-01, time/batch = 0.6981s	
3769/22750 (epoch 8.284), train_loss = 1.35116709, grad/param norm = 1.7049e-01, time/batch = 0.7088s	
3770/22750 (epoch 8.286), train_loss = 1.56711043, grad/param norm = 1.9104e-01, time/batch = 0.7178s	
3771/22750 (epoch 8.288), train_loss = 1.62297717, grad/param norm = 1.8788e-01, time/batch = 0.7002s	
3772/22750 (epoch 8.290), train_loss = 1.35544138, grad/param norm = 1.7385e-01, time/batch = 0.7020s	
3773/22750 (epoch 8.292), train_loss = 1.44832383, grad/param norm = 2.0411e-01, time/batch = 0.6999s	
3774/22750 (epoch 8.295), train_loss = 1.41446748, grad/param norm = 1.7519e-01, time/batch = 0.6974s	
3775/22750 (epoch 8.297), train_loss = 1.35863770, grad/param norm = 1.8276e-01, time/batch = 0.6970s	
3776/22750 (epoch 8.299), train_loss = 1.57246899, grad/param norm = 1.8076e-01, time/batch = 0.6959s	
3777/22750 (epoch 8.301), train_loss = 1.49233999, grad/param norm = 2.0064e-01, time/batch = 0.7024s	
3778/22750 (epoch 8.303), train_loss = 1.55752047, grad/param norm = 2.1008e-01, time/batch = 0.6991s	
3779/22750 (epoch 8.305), train_loss = 1.64762763, grad/param norm = 1.9931e-01, time/batch = 0.7118s	
3780/22750 (epoch 8.308), train_loss = 1.49563680, grad/param norm = 1.9097e-01, time/batch = 0.7184s	
3781/22750 (epoch 8.310), train_loss = 1.37186648, grad/param norm = 2.0249e-01, time/batch = 0.6990s	
3782/22750 (epoch 8.312), train_loss = 1.48323524, grad/param norm = 1.9801e-01, time/batch = 0.7010s	
3783/22750 (epoch 8.314), train_loss = 1.43606672, grad/param norm = 1.9333e-01, time/batch = 0.7037s	
3784/22750 (epoch 8.316), train_loss = 1.35448762, grad/param norm = 1.8375e-01, time/batch = 0.6972s	
3785/22750 (epoch 8.319), train_loss = 1.48661682, grad/param norm = 1.8670e-01, time/batch = 0.7227s	
3786/22750 (epoch 8.321), train_loss = 1.40629159, grad/param norm = 2.0507e-01, time/batch = 0.7272s	
3787/22750 (epoch 8.323), train_loss = 1.40379331, grad/param norm = 2.0998e-01, time/batch = 0.7766s	
3788/22750 (epoch 8.325), train_loss = 1.14777450, grad/param norm = 1.7211e-01, time/batch = 0.7431s	
3789/22750 (epoch 8.327), train_loss = 1.47217002, grad/param norm = 1.8895e-01, time/batch = 0.7346s	
3790/22750 (epoch 8.330), train_loss = 1.71804238, grad/param norm = 1.9870e-01, time/batch = 0.7113s	
3791/22750 (epoch 8.332), train_loss = 1.59112499, grad/param norm = 1.9449e-01, time/batch = 0.7076s	
3792/22750 (epoch 8.334), train_loss = 1.18785239, grad/param norm = 1.8128e-01, time/batch = 0.7047s	
3793/22750 (epoch 8.336), train_loss = 1.49025294, grad/param norm = 1.9424e-01, time/batch = 0.7066s	
3794/22750 (epoch 8.338), train_loss = 1.38538728, grad/param norm = 1.8436e-01, time/batch = 0.7088s	
3795/22750 (epoch 8.341), train_loss = 1.37728653, grad/param norm = 1.7885e-01, time/batch = 0.6993s	
3796/22750 (epoch 8.343), train_loss = 1.21198790, grad/param norm = 1.8547e-01, time/batch = 0.7018s	
3797/22750 (epoch 8.345), train_loss = 1.60285545, grad/param norm = 2.1274e-01, time/batch = 0.7004s	
3798/22750 (epoch 8.347), train_loss = 1.56967427, grad/param norm = 2.0486e-01, time/batch = 0.6988s	
3799/22750 (epoch 8.349), train_loss = 1.16966782, grad/param norm = 1.8345e-01, time/batch = 0.7065s	
3800/22750 (epoch 8.352), train_loss = 1.53757349, grad/param norm = 2.1060e-01, time/batch = 0.7162s	
3801/22750 (epoch 8.354), train_loss = 1.60968440, grad/param norm = 1.9902e-01, time/batch = 0.7073s	
3802/22750 (epoch 8.356), train_loss = 1.62735820, grad/param norm = 1.9934e-01, time/batch = 0.6959s	
3803/22750 (epoch 8.358), train_loss = 1.42730394, grad/param norm = 2.0777e-01, time/batch = 0.6983s	
3804/22750 (epoch 8.360), train_loss = 1.65173786, grad/param norm = 2.0602e-01, time/batch = 0.7021s	
3805/22750 (epoch 8.363), train_loss = 1.43033149, grad/param norm = 1.7984e-01, time/batch = 0.6955s	
3806/22750 (epoch 8.365), train_loss = 1.18418791, grad/param norm = 1.8716e-01, time/batch = 0.6985s	
3807/22750 (epoch 8.367), train_loss = 1.22886605, grad/param norm = 1.8161e-01, time/batch = 0.7068s	
3808/22750 (epoch 8.369), train_loss = 1.37106117, grad/param norm = 1.9920e-01, time/batch = 0.7090s	
3809/22750 (epoch 8.371), train_loss = 1.33676217, grad/param norm = 1.8632e-01, time/batch = 0.7200s	
3810/22750 (epoch 8.374), train_loss = 1.25659678, grad/param norm = 1.8566e-01, time/batch = 0.7025s	
3811/22750 (epoch 8.376), train_loss = 1.41993823, grad/param norm = 1.7523e-01, time/batch = 0.7034s	
3812/22750 (epoch 8.378), train_loss = 1.40969381, grad/param norm = 1.9223e-01, time/batch = 0.6986s	
3813/22750 (epoch 8.380), train_loss = 1.59566227, grad/param norm = 2.0033e-01, time/batch = 0.7028s	
3814/22750 (epoch 8.382), train_loss = 1.34376305, grad/param norm = 1.7974e-01, time/batch = 0.7025s	
3815/22750 (epoch 8.385), train_loss = 1.47356271, grad/param norm = 1.7825e-01, time/batch = 0.7079s	
3816/22750 (epoch 8.387), train_loss = 1.48974739, grad/param norm = 1.9162e-01, time/batch = 0.7249s	
3817/22750 (epoch 8.389), train_loss = 1.07996953, grad/param norm = 1.7894e-01, time/batch = 0.7230s	
3818/22750 (epoch 8.391), train_loss = 0.92105350, grad/param norm = 1.5184e-01, time/batch = 0.7176s	
3819/22750 (epoch 8.393), train_loss = 1.24264362, grad/param norm = 1.8248e-01, time/batch = 0.7098s	
3820/22750 (epoch 8.396), train_loss = 1.41823441, grad/param norm = 2.0013e-01, time/batch = 0.7198s	
3821/22750 (epoch 8.398), train_loss = 1.38760671, grad/param norm = 1.9467e-01, time/batch = 0.7240s	
3822/22750 (epoch 8.400), train_loss = 1.40245036, grad/param norm = 1.7341e-01, time/batch = 0.7066s	
3823/22750 (epoch 8.402), train_loss = 1.44895544, grad/param norm = 1.7929e-01, time/batch = 0.7059s	
3824/22750 (epoch 8.404), train_loss = 1.63719247, grad/param norm = 1.9371e-01, time/batch = 0.7039s	
3825/22750 (epoch 8.407), train_loss = 1.54520049, grad/param norm = 1.8302e-01, time/batch = 0.7133s	
3826/22750 (epoch 8.409), train_loss = 1.40545686, grad/param norm = 1.8227e-01, time/batch = 0.7156s	
3827/22750 (epoch 8.411), train_loss = 1.40888787, grad/param norm = 1.7678e-01, time/batch = 0.6984s	
3828/22750 (epoch 8.413), train_loss = 1.23340118, grad/param norm = 1.9023e-01, time/batch = 0.7172s	
3829/22750 (epoch 8.415), train_loss = 1.16447816, grad/param norm = 1.8510e-01, time/batch = 0.7195s	
3830/22750 (epoch 8.418), train_loss = 1.38112707, grad/param norm = 1.9136e-01, time/batch = 0.7075s	
3831/22750 (epoch 8.420), train_loss = 1.64106052, grad/param norm = 2.1902e-01, time/batch = 0.6990s	
3832/22750 (epoch 8.422), train_loss = 1.74363460, grad/param norm = 2.1730e-01, time/batch = 0.7077s	
3833/22750 (epoch 8.424), train_loss = 1.72117549, grad/param norm = 2.2399e-01, time/batch = 0.6995s	
3834/22750 (epoch 8.426), train_loss = 1.65115471, grad/param norm = 1.8948e-01, time/batch = 0.7116s	
3835/22750 (epoch 8.429), train_loss = 1.17903689, grad/param norm = 1.8728e-01, time/batch = 0.6979s	
3836/22750 (epoch 8.431), train_loss = 1.16632996, grad/param norm = 1.6669e-01, time/batch = 0.7014s	
3837/22750 (epoch 8.433), train_loss = 1.30011861, grad/param norm = 1.7862e-01, time/batch = 0.6937s	
3838/22750 (epoch 8.435), train_loss = 1.15259106, grad/param norm = 1.7999e-01, time/batch = 0.7170s	
3839/22750 (epoch 8.437), train_loss = 1.05034293, grad/param norm = 1.7193e-01, time/batch = 0.7177s	
3840/22750 (epoch 8.440), train_loss = 1.53182588, grad/param norm = 1.9917e-01, time/batch = 0.6964s	
3841/22750 (epoch 8.442), train_loss = 1.45582997, grad/param norm = 1.9471e-01, time/batch = 0.7069s	
3842/22750 (epoch 8.444), train_loss = 1.44476930, grad/param norm = 2.2261e-01, time/batch = 0.6969s	
3843/22750 (epoch 8.446), train_loss = 1.43293580, grad/param norm = 2.2735e-01, time/batch = 0.6956s	
3844/22750 (epoch 8.448), train_loss = 1.72541331, grad/param norm = 2.2339e-01, time/batch = 0.6964s	
3845/22750 (epoch 8.451), train_loss = 1.62672505, grad/param norm = 2.2000e-01, time/batch = 0.6971s	
3846/22750 (epoch 8.453), train_loss = 1.69176797, grad/param norm = 2.0628e-01, time/batch = 0.6956s	
3847/22750 (epoch 8.455), train_loss = 1.78192044, grad/param norm = 2.0369e-01, time/batch = 0.6956s	
3848/22750 (epoch 8.457), train_loss = 1.60002501, grad/param norm = 2.1704e-01, time/batch = 0.7021s	
3849/22750 (epoch 8.459), train_loss = 1.50528816, grad/param norm = 1.9241e-01, time/batch = 0.6989s	
3850/22750 (epoch 8.462), train_loss = 1.52459404, grad/param norm = 1.6318e-01, time/batch = 0.6946s	
3851/22750 (epoch 8.464), train_loss = 1.25426291, grad/param norm = 1.8119e-01, time/batch = 0.6971s	
3852/22750 (epoch 8.466), train_loss = 1.69288083, grad/param norm = 2.2127e-01, time/batch = 0.6970s	
3853/22750 (epoch 8.468), train_loss = 1.39775017, grad/param norm = 1.9636e-01, time/batch = 0.6942s	
3854/22750 (epoch 8.470), train_loss = 1.59001952, grad/param norm = 2.0361e-01, time/batch = 0.6939s	
3855/22750 (epoch 8.473), train_loss = 1.44707177, grad/param norm = 1.9855e-01, time/batch = 0.6973s	
3856/22750 (epoch 8.475), train_loss = 1.49213783, grad/param norm = 2.1349e-01, time/batch = 0.6990s	
3857/22750 (epoch 8.477), train_loss = 1.22477454, grad/param norm = 1.8189e-01, time/batch = 0.6979s	
3858/22750 (epoch 8.479), train_loss = 1.26427830, grad/param norm = 1.9221e-01, time/batch = 0.7217s	
3859/22750 (epoch 8.481), train_loss = 1.18399339, grad/param norm = 1.8277e-01, time/batch = 0.7122s	
3860/22750 (epoch 8.484), train_loss = 1.08693129, grad/param norm = 1.8776e-01, time/batch = 0.7196s	
3861/22750 (epoch 8.486), train_loss = 1.28039219, grad/param norm = 2.0295e-01, time/batch = 0.7093s	
3862/22750 (epoch 8.488), train_loss = 1.09576601, grad/param norm = 2.0588e-01, time/batch = 0.7342s	
3863/22750 (epoch 8.490), train_loss = 1.36503183, grad/param norm = 1.8529e-01, time/batch = 0.7530s	
3864/22750 (epoch 8.492), train_loss = 1.57904314, grad/param norm = 1.9992e-01, time/batch = 0.7221s	
3865/22750 (epoch 8.495), train_loss = 1.31894269, grad/param norm = 1.9695e-01, time/batch = 0.7204s	
3866/22750 (epoch 8.497), train_loss = 1.48659845, grad/param norm = 2.2066e-01, time/batch = 0.7292s	
3867/22750 (epoch 8.499), train_loss = 1.34490545, grad/param norm = 1.9606e-01, time/batch = 0.7130s	
3868/22750 (epoch 8.501), train_loss = 1.45807582, grad/param norm = 2.1068e-01, time/batch = 0.7051s	
3869/22750 (epoch 8.503), train_loss = 1.39615081, grad/param norm = 1.8970e-01, time/batch = 0.7087s	
3870/22750 (epoch 8.505), train_loss = 1.24877393, grad/param norm = 1.7871e-01, time/batch = 0.7271s	
3871/22750 (epoch 8.508), train_loss = 1.19801719, grad/param norm = 1.9088e-01, time/batch = 0.7237s	
3872/22750 (epoch 8.510), train_loss = 1.22910277, grad/param norm = 1.7659e-01, time/batch = 0.7352s	
3873/22750 (epoch 8.512), train_loss = 1.29049774, grad/param norm = 1.7379e-01, time/batch = 0.7147s	
3874/22750 (epoch 8.514), train_loss = 1.30277894, grad/param norm = 1.7381e-01, time/batch = 0.7146s	
3875/22750 (epoch 8.516), train_loss = 1.27693375, grad/param norm = 1.8253e-01, time/batch = 0.7036s	
3876/22750 (epoch 8.519), train_loss = 1.49913972, grad/param norm = 2.0242e-01, time/batch = 0.7050s	
3877/22750 (epoch 8.521), train_loss = 1.32897427, grad/param norm = 1.9643e-01, time/batch = 0.6937s	
3878/22750 (epoch 8.523), train_loss = 1.34332063, grad/param norm = 2.1730e-01, time/batch = 0.7037s	
3879/22750 (epoch 8.525), train_loss = 1.62944073, grad/param norm = 2.3870e-01, time/batch = 0.7136s	
3880/22750 (epoch 8.527), train_loss = 1.42420619, grad/param norm = 1.9016e-01, time/batch = 0.7117s	
3881/22750 (epoch 8.530), train_loss = 1.32362686, grad/param norm = 1.9841e-01, time/batch = 0.7115s	
3882/22750 (epoch 8.532), train_loss = 1.25831637, grad/param norm = 1.6620e-01, time/batch = 0.7112s	
3883/22750 (epoch 8.534), train_loss = 1.52374652, grad/param norm = 2.0561e-01, time/batch = 0.7335s	
3884/22750 (epoch 8.536), train_loss = 1.42385227, grad/param norm = 1.9806e-01, time/batch = 0.7237s	
3885/22750 (epoch 8.538), train_loss = 1.43827208, grad/param norm = 1.7146e-01, time/batch = 0.7072s	
3886/22750 (epoch 8.541), train_loss = 1.19849648, grad/param norm = 1.8501e-01, time/batch = 0.7102s	
3887/22750 (epoch 8.543), train_loss = 1.21614403, grad/param norm = 1.7084e-01, time/batch = 0.7097s	
3888/22750 (epoch 8.545), train_loss = 1.55774775, grad/param norm = 1.9541e-01, time/batch = 0.7172s	
3889/22750 (epoch 8.547), train_loss = 1.21740707, grad/param norm = 1.6347e-01, time/batch = 0.6988s	
3890/22750 (epoch 8.549), train_loss = 1.30235119, grad/param norm = 1.9331e-01, time/batch = 0.7146s	
3891/22750 (epoch 8.552), train_loss = 1.49237624, grad/param norm = 2.0631e-01, time/batch = 0.7277s	
3892/22750 (epoch 8.554), train_loss = 1.54178138, grad/param norm = 2.0959e-01, time/batch = 0.7272s	
3893/22750 (epoch 8.556), train_loss = 1.39457647, grad/param norm = 1.9864e-01, time/batch = 0.7176s	
3894/22750 (epoch 8.558), train_loss = 1.57501770, grad/param norm = 1.9190e-01, time/batch = 0.6995s	
3895/22750 (epoch 8.560), train_loss = 1.30808264, grad/param norm = 1.7817e-01, time/batch = 0.6939s	
3896/22750 (epoch 8.563), train_loss = 1.48906814, grad/param norm = 1.7321e-01, time/batch = 0.6986s	
3897/22750 (epoch 8.565), train_loss = 1.54647889, grad/param norm = 1.9209e-01, time/batch = 0.7251s	
3898/22750 (epoch 8.567), train_loss = 1.42474903, grad/param norm = 1.9647e-01, time/batch = 0.7222s	
3899/22750 (epoch 8.569), train_loss = 1.34904317, grad/param norm = 1.8797e-01, time/batch = 0.7233s	
3900/22750 (epoch 8.571), train_loss = 1.45635145, grad/param norm = 2.0383e-01, time/batch = 0.7267s	
3901/22750 (epoch 8.574), train_loss = 1.27302667, grad/param norm = 1.9415e-01, time/batch = 0.7233s	
3902/22750 (epoch 8.576), train_loss = 1.42249846, grad/param norm = 1.8337e-01, time/batch = 0.7287s	
3903/22750 (epoch 8.578), train_loss = 1.23496349, grad/param norm = 1.7623e-01, time/batch = 0.7231s	
3904/22750 (epoch 8.580), train_loss = 1.44629656, grad/param norm = 2.0252e-01, time/batch = 0.7210s	
3905/22750 (epoch 8.582), train_loss = 1.19321642, grad/param norm = 1.7025e-01, time/batch = 0.7072s	
3906/22750 (epoch 8.585), train_loss = 1.12738610, grad/param norm = 1.8604e-01, time/batch = 0.7086s	
3907/22750 (epoch 8.587), train_loss = 1.19342942, grad/param norm = 1.6864e-01, time/batch = 0.6943s	
3908/22750 (epoch 8.589), train_loss = 1.19079538, grad/param norm = 1.8733e-01, time/batch = 0.7056s	
3909/22750 (epoch 8.591), train_loss = 1.39516752, grad/param norm = 2.0581e-01, time/batch = 0.6963s	
3910/22750 (epoch 8.593), train_loss = 1.60664281, grad/param norm = 1.8171e-01, time/batch = 0.7059s	
3911/22750 (epoch 8.596), train_loss = 1.59075856, grad/param norm = 1.9557e-01, time/batch = 0.7228s	
3912/22750 (epoch 8.598), train_loss = 1.60827300, grad/param norm = 1.9436e-01, time/batch = 0.7137s	
3913/22750 (epoch 8.600), train_loss = 1.54852175, grad/param norm = 1.9431e-01, time/batch = 0.7243s	
3914/22750 (epoch 8.602), train_loss = 1.23508127, grad/param norm = 1.6820e-01, time/batch = 0.7270s	
3915/22750 (epoch 8.604), train_loss = 1.34924017, grad/param norm = 1.8508e-01, time/batch = 0.7276s	
3916/22750 (epoch 8.607), train_loss = 1.13766669, grad/param norm = 1.6061e-01, time/batch = 0.7236s	
3917/22750 (epoch 8.609), train_loss = 1.07198695, grad/param norm = 1.5402e-01, time/batch = 0.7262s	
3918/22750 (epoch 8.611), train_loss = 1.31728824, grad/param norm = 1.9371e-01, time/batch = 0.7147s	
3919/22750 (epoch 8.613), train_loss = 1.24261652, grad/param norm = 2.0273e-01, time/batch = 0.7171s	
3920/22750 (epoch 8.615), train_loss = 1.30846078, grad/param norm = 1.8132e-01, time/batch = 0.7283s	
3921/22750 (epoch 8.618), train_loss = 1.35844416, grad/param norm = 1.9217e-01, time/batch = 0.7274s	
3922/22750 (epoch 8.620), train_loss = 1.37813508, grad/param norm = 1.8646e-01, time/batch = 0.7268s	
3923/22750 (epoch 8.622), train_loss = 1.17166045, grad/param norm = 1.8528e-01, time/batch = 0.7265s	
3924/22750 (epoch 8.624), train_loss = 1.39485110, grad/param norm = 1.9634e-01, time/batch = 0.7133s	
3925/22750 (epoch 8.626), train_loss = 1.22321153, grad/param norm = 1.8540e-01, time/batch = 0.7257s	
3926/22750 (epoch 8.629), train_loss = 1.37883810, grad/param norm = 2.0259e-01, time/batch = 0.7164s	
3927/22750 (epoch 8.631), train_loss = 1.41040617, grad/param norm = 1.9481e-01, time/batch = 0.7063s	
3928/22750 (epoch 8.633), train_loss = 1.14391922, grad/param norm = 1.9400e-01, time/batch = 0.6980s	
3929/22750 (epoch 8.635), train_loss = 1.41557292, grad/param norm = 2.0591e-01, time/batch = 0.7046s	
3930/22750 (epoch 8.637), train_loss = 1.50400994, grad/param norm = 2.0879e-01, time/batch = 0.7064s	
3931/22750 (epoch 8.640), train_loss = 1.54220856, grad/param norm = 2.1566e-01, time/batch = 0.6979s	
3932/22750 (epoch 8.642), train_loss = 1.54025299, grad/param norm = 1.9287e-01, time/batch = 0.6971s	
3933/22750 (epoch 8.644), train_loss = 1.40673956, grad/param norm = 1.9913e-01, time/batch = 0.7211s	
3934/22750 (epoch 8.646), train_loss = 1.53250882, grad/param norm = 2.0165e-01, time/batch = 0.7147s	
3935/22750 (epoch 8.648), train_loss = 1.43223889, grad/param norm = 2.0731e-01, time/batch = 0.6952s	
3936/22750 (epoch 8.651), train_loss = 1.53010330, grad/param norm = 2.1293e-01, time/batch = 0.6939s	
3937/22750 (epoch 8.653), train_loss = 1.45307008, grad/param norm = 1.9208e-01, time/batch = 0.6947s	
3938/22750 (epoch 8.655), train_loss = 1.37376269, grad/param norm = 1.9226e-01, time/batch = 0.6958s	
3939/22750 (epoch 8.657), train_loss = 1.58816209, grad/param norm = 1.9719e-01, time/batch = 0.7064s	
3940/22750 (epoch 8.659), train_loss = 1.67100935, grad/param norm = 1.9392e-01, time/batch = 0.7291s	
3941/22750 (epoch 8.662), train_loss = 1.70299452, grad/param norm = 2.1579e-01, time/batch = 0.7298s	
3942/22750 (epoch 8.664), train_loss = 1.48211695, grad/param norm = 1.9307e-01, time/batch = 0.7290s	
3943/22750 (epoch 8.666), train_loss = 1.25332980, grad/param norm = 1.8254e-01, time/batch = 0.6955s	
3944/22750 (epoch 8.668), train_loss = 1.42304616, grad/param norm = 1.8598e-01, time/batch = 0.7151s	
3945/22750 (epoch 8.670), train_loss = 1.43717541, grad/param norm = 1.9036e-01, time/batch = 0.7263s	
3946/22750 (epoch 8.673), train_loss = 1.68034300, grad/param norm = 2.1286e-01, time/batch = 0.7269s	
3947/22750 (epoch 8.675), train_loss = 1.89553774, grad/param norm = 2.2285e-01, time/batch = 0.7090s	
3948/22750 (epoch 8.677), train_loss = 1.65045542, grad/param norm = 2.1496e-01, time/batch = 0.7059s	
3949/22750 (epoch 8.679), train_loss = 1.70529793, grad/param norm = 2.1093e-01, time/batch = 0.7016s	
3950/22750 (epoch 8.681), train_loss = 1.62549581, grad/param norm = 2.1156e-01, time/batch = 0.7156s	
3951/22750 (epoch 8.684), train_loss = 1.58459412, grad/param norm = 1.9353e-01, time/batch = 0.7041s	
3952/22750 (epoch 8.686), train_loss = 1.58315544, grad/param norm = 2.1218e-01, time/batch = 0.7041s	
3953/22750 (epoch 8.688), train_loss = 1.54448878, grad/param norm = 2.0289e-01, time/batch = 0.7235s	
3954/22750 (epoch 8.690), train_loss = 1.53059720, grad/param norm = 1.9817e-01, time/batch = 0.7348s	
3955/22750 (epoch 8.692), train_loss = 1.66502052, grad/param norm = 2.0041e-01, time/batch = 0.7386s	
3956/22750 (epoch 8.695), train_loss = 1.42980668, grad/param norm = 1.8874e-01, time/batch = 0.7224s	
3957/22750 (epoch 8.697), train_loss = 1.41850583, grad/param norm = 2.0489e-01, time/batch = 0.7059s	
3958/22750 (epoch 8.699), train_loss = 1.44537606, grad/param norm = 1.7927e-01, time/batch = 0.6994s	
3959/22750 (epoch 8.701), train_loss = 1.26989807, grad/param norm = 1.7668e-01, time/batch = 0.7064s	
3960/22750 (epoch 8.703), train_loss = 1.46340352, grad/param norm = 1.8420e-01, time/batch = 0.7051s	
3961/22750 (epoch 8.705), train_loss = 1.29141633, grad/param norm = 1.7000e-01, time/batch = 0.7056s	
3962/22750 (epoch 8.708), train_loss = 1.44427372, grad/param norm = 1.6589e-01, time/batch = 0.7191s	
3963/22750 (epoch 8.710), train_loss = 1.21562461, grad/param norm = 1.9448e-01, time/batch = 0.7291s	
3964/22750 (epoch 8.712), train_loss = 1.31408591, grad/param norm = 1.7533e-01, time/batch = 0.7270s	
3965/22750 (epoch 8.714), train_loss = 1.18349412, grad/param norm = 1.7290e-01, time/batch = 0.7243s	
3966/22750 (epoch 8.716), train_loss = 1.29041821, grad/param norm = 1.8610e-01, time/batch = 0.7215s	
3967/22750 (epoch 8.719), train_loss = 1.53125851, grad/param norm = 2.2134e-01, time/batch = 0.7083s	
3968/22750 (epoch 8.721), train_loss = 1.49479781, grad/param norm = 2.0110e-01, time/batch = 0.7077s	
3969/22750 (epoch 8.723), train_loss = 1.42125501, grad/param norm = 1.9802e-01, time/batch = 0.7025s	
3970/22750 (epoch 8.725), train_loss = 1.42958942, grad/param norm = 2.1213e-01, time/batch = 0.7013s	
3971/22750 (epoch 8.727), train_loss = 1.33433708, grad/param norm = 1.7535e-01, time/batch = 0.7107s	
3972/22750 (epoch 8.730), train_loss = 1.35461454, grad/param norm = 1.8932e-01, time/batch = 0.6997s	
3973/22750 (epoch 8.732), train_loss = 1.36245242, grad/param norm = 1.9396e-01, time/batch = 0.7016s	
3974/22750 (epoch 8.734), train_loss = 1.10381331, grad/param norm = 1.8398e-01, time/batch = 0.7193s	
3975/22750 (epoch 8.736), train_loss = 1.29521948, grad/param norm = 1.7650e-01, time/batch = 0.7287s	
3976/22750 (epoch 8.738), train_loss = 1.41152643, grad/param norm = 2.0118e-01, time/batch = 0.7282s	
3977/22750 (epoch 8.741), train_loss = 1.51375419, grad/param norm = 1.8516e-01, time/batch = 0.7259s	
3978/22750 (epoch 8.743), train_loss = 1.46725040, grad/param norm = 1.9392e-01, time/batch = 0.7039s	
3979/22750 (epoch 8.745), train_loss = 1.19947340, grad/param norm = 1.6632e-01, time/batch = 0.7014s	
3980/22750 (epoch 8.747), train_loss = 1.32447751, grad/param norm = 1.8881e-01, time/batch = 0.7012s	
3981/22750 (epoch 8.749), train_loss = 1.61760605, grad/param norm = 2.0627e-01, time/batch = 0.7275s	
3982/22750 (epoch 8.752), train_loss = 1.32681467, grad/param norm = 1.9120e-01, time/batch = 0.7204s	
3983/22750 (epoch 8.754), train_loss = 1.58622843, grad/param norm = 2.3341e-01, time/batch = 0.7157s	
3984/22750 (epoch 8.756), train_loss = 1.24938775, grad/param norm = 2.1397e-01, time/batch = 0.7312s	
3985/22750 (epoch 8.758), train_loss = 1.20963019, grad/param norm = 1.7497e-01, time/batch = 0.7129s	
3986/22750 (epoch 8.760), train_loss = 1.41258264, grad/param norm = 1.9305e-01, time/batch = 0.7184s	
3987/22750 (epoch 8.763), train_loss = 1.45996866, grad/param norm = 1.8385e-01, time/batch = 0.7093s	
3988/22750 (epoch 8.765), train_loss = 1.33737832, grad/param norm = 2.0837e-01, time/batch = 0.7002s	
3989/22750 (epoch 8.767), train_loss = 1.40727122, grad/param norm = 1.8257e-01, time/batch = 0.7027s	
3990/22750 (epoch 8.769), train_loss = 1.60072664, grad/param norm = 1.9723e-01, time/batch = 0.6975s	
3991/22750 (epoch 8.771), train_loss = 1.55316983, grad/param norm = 1.8937e-01, time/batch = 0.7051s	
3992/22750 (epoch 8.774), train_loss = 1.30119159, grad/param norm = 2.0940e-01, time/batch = 0.6991s	
3993/22750 (epoch 8.776), train_loss = 1.41107532, grad/param norm = 1.9914e-01, time/batch = 0.6987s	
3994/22750 (epoch 8.778), train_loss = 1.61854260, grad/param norm = 1.9078e-01, time/batch = 0.6995s	
3995/22750 (epoch 8.780), train_loss = 1.44978813, grad/param norm = 1.9970e-01, time/batch = 0.6991s	
3996/22750 (epoch 8.782), train_loss = 1.55802344, grad/param norm = 1.9481e-01, time/batch = 0.7040s	
3997/22750 (epoch 8.785), train_loss = 1.40138614, grad/param norm = 1.8383e-01, time/batch = 0.7042s	
3998/22750 (epoch 8.787), train_loss = 1.30549434, grad/param norm = 1.9421e-01, time/batch = 0.7087s	
3999/22750 (epoch 8.789), train_loss = 1.34788398, grad/param norm = 1.7415e-01, time/batch = 0.7044s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_wakata_epoch8.79_1.5194.t7	
4000/22750 (epoch 8.791), train_loss = 1.37376811, grad/param norm = 1.8006e-01, time/batch = 0.7172s	
4001/22750 (epoch 8.793), train_loss = 1.57834434, grad/param norm = 2.3994e-01, time/batch = 0.7067s	
4002/22750 (epoch 8.796), train_loss = 1.24224048, grad/param norm = 1.9579e-01, time/batch = 0.7058s	
4003/22750 (epoch 8.798), train_loss = 1.24928591, grad/param norm = 1.6468e-01, time/batch = 0.7016s	
4004/22750 (epoch 8.800), train_loss = 1.24075242, grad/param norm = 1.6899e-01, time/batch = 0.7000s	
4005/22750 (epoch 8.802), train_loss = 1.30983337, grad/param norm = 1.8328e-01, time/batch = 0.6974s	
4006/22750 (epoch 8.804), train_loss = 1.63313463, grad/param norm = 1.9739e-01, time/batch = 0.7056s	
4007/22750 (epoch 8.807), train_loss = 1.44820227, grad/param norm = 1.9468e-01, time/batch = 0.7024s	
4008/22750 (epoch 8.809), train_loss = 1.67539662, grad/param norm = 2.1451e-01, time/batch = 0.7014s	
4009/22750 (epoch 8.811), train_loss = 1.35411138, grad/param norm = 1.8436e-01, time/batch = 0.7080s	
4010/22750 (epoch 8.813), train_loss = 1.44241209, grad/param norm = 1.7735e-01, time/batch = 0.7003s	
4011/22750 (epoch 8.815), train_loss = 1.62397192, grad/param norm = 2.1649e-01, time/batch = 0.7100s	
4012/22750 (epoch 8.818), train_loss = 1.56599336, grad/param norm = 1.9623e-01, time/batch = 0.7080s	
4013/22750 (epoch 8.820), train_loss = 1.67654998, grad/param norm = 1.8275e-01, time/batch = 0.7160s	
4014/22750 (epoch 8.822), train_loss = 1.44622127, grad/param norm = 1.7892e-01, time/batch = 0.6953s	
4015/22750 (epoch 8.824), train_loss = 1.39006422, grad/param norm = 1.8210e-01, time/batch = 0.7061s	
4016/22750 (epoch 8.826), train_loss = 1.45243570, grad/param norm = 1.9065e-01, time/batch = 0.6998s	
4017/22750 (epoch 8.829), train_loss = 1.62017783, grad/param norm = 2.1668e-01, time/batch = 0.6927s	
4018/22750 (epoch 8.831), train_loss = 1.57597771, grad/param norm = 1.9916e-01, time/batch = 0.7091s	
4019/22750 (epoch 8.833), train_loss = 1.51559424, grad/param norm = 2.2801e-01, time/batch = 0.7278s	
4020/22750 (epoch 8.835), train_loss = 1.33872815, grad/param norm = 1.7962e-01, time/batch = 0.7257s	
4021/22750 (epoch 8.837), train_loss = 1.34091560, grad/param norm = 1.9803e-01, time/batch = 0.7031s	
4022/22750 (epoch 8.840), train_loss = 1.33942154, grad/param norm = 1.8593e-01, time/batch = 0.7007s	
4023/22750 (epoch 8.842), train_loss = 1.34192313, grad/param norm = 1.7301e-01, time/batch = 0.6953s	
4024/22750 (epoch 8.844), train_loss = 1.57442035, grad/param norm = 1.9977e-01, time/batch = 0.6964s	
4025/22750 (epoch 8.846), train_loss = 1.40197708, grad/param norm = 1.8207e-01, time/batch = 0.6950s	
4026/22750 (epoch 8.848), train_loss = 1.26486323, grad/param norm = 1.9532e-01, time/batch = 0.7061s	
4027/22750 (epoch 8.851), train_loss = 1.28760468, grad/param norm = 1.8510e-01, time/batch = 0.7202s	
4028/22750 (epoch 8.853), train_loss = 1.40847566, grad/param norm = 1.8046e-01, time/batch = 0.7176s	
4029/22750 (epoch 8.855), train_loss = 1.20996476, grad/param norm = 1.9032e-01, time/batch = 0.6964s	
4030/22750 (epoch 8.857), train_loss = 1.42719612, grad/param norm = 1.7869e-01, time/batch = 0.7077s	
4031/22750 (epoch 8.859), train_loss = 1.44212372, grad/param norm = 1.9103e-01, time/batch = 0.7292s	
4032/22750 (epoch 8.862), train_loss = 1.61551994, grad/param norm = 2.0093e-01, time/batch = 0.7243s	
4033/22750 (epoch 8.864), train_loss = 1.38908398, grad/param norm = 1.9137e-01, time/batch = 0.7250s	
4034/22750 (epoch 8.866), train_loss = 1.43766563, grad/param norm = 1.8266e-01, time/batch = 0.7224s	
4035/22750 (epoch 8.868), train_loss = 1.35459522, grad/param norm = 1.7315e-01, time/batch = 0.7194s	
4036/22750 (epoch 8.870), train_loss = 1.20867428, grad/param norm = 1.8132e-01, time/batch = 0.7077s	
4037/22750 (epoch 8.873), train_loss = 1.36391836, grad/param norm = 1.9445e-01, time/batch = 0.7055s	
4038/22750 (epoch 8.875), train_loss = 1.46305557, grad/param norm = 1.7809e-01, time/batch = 0.7043s	
4039/22750 (epoch 8.877), train_loss = 1.33222702, grad/param norm = 1.8545e-01, time/batch = 0.7105s	
4040/22750 (epoch 8.879), train_loss = 1.53836978, grad/param norm = 2.0330e-01, time/batch = 0.7081s	
4041/22750 (epoch 8.881), train_loss = 1.51861007, grad/param norm = 1.8970e-01, time/batch = 0.7089s	
4042/22750 (epoch 8.884), train_loss = 1.30528295, grad/param norm = 1.8779e-01, time/batch = 0.7077s	
4043/22750 (epoch 8.886), train_loss = 1.48898598, grad/param norm = 1.9517e-01, time/batch = 0.7037s	
4044/22750 (epoch 8.888), train_loss = 1.47490987, grad/param norm = 1.8557e-01, time/batch = 0.7077s	
4045/22750 (epoch 8.890), train_loss = 1.52760492, grad/param norm = 1.9274e-01, time/batch = 0.7044s	
4046/22750 (epoch 8.892), train_loss = 1.84944946, grad/param norm = 2.3148e-01, time/batch = 0.7053s	
4047/22750 (epoch 8.895), train_loss = 1.52492956, grad/param norm = 1.8197e-01, time/batch = 0.7039s	
4048/22750 (epoch 8.897), train_loss = 1.55771440, grad/param norm = 1.9960e-01, time/batch = 0.7011s	
4049/22750 (epoch 8.899), train_loss = 1.47697951, grad/param norm = 1.8062e-01, time/batch = 0.7155s	
4050/22750 (epoch 8.901), train_loss = 1.62980094, grad/param norm = 1.9958e-01, time/batch = 0.7107s	
4051/22750 (epoch 8.903), train_loss = 1.40059610, grad/param norm = 1.9251e-01, time/batch = 0.7043s	
4052/22750 (epoch 8.905), train_loss = 1.49970367, grad/param norm = 1.7690e-01, time/batch = 0.7040s	
4053/22750 (epoch 8.908), train_loss = 1.38244366, grad/param norm = 1.9843e-01, time/batch = 0.7028s	
4054/22750 (epoch 8.910), train_loss = 1.20167935, grad/param norm = 1.9655e-01, time/batch = 0.7088s	
4055/22750 (epoch 8.912), train_loss = 1.29844548, grad/param norm = 1.7844e-01, time/batch = 0.7028s	
4056/22750 (epoch 8.914), train_loss = 1.36299496, grad/param norm = 1.8451e-01, time/batch = 0.6977s	
4057/22750 (epoch 8.916), train_loss = 1.19689542, grad/param norm = 1.7617e-01, time/batch = 0.6997s	
4058/22750 (epoch 8.919), train_loss = 1.29527912, grad/param norm = 1.8895e-01, time/batch = 0.7108s	
4059/22750 (epoch 8.921), train_loss = 1.01471300, grad/param norm = 1.6179e-01, time/batch = 0.7278s	
4060/22750 (epoch 8.923), train_loss = 1.34739833, grad/param norm = 1.8542e-01, time/batch = 0.7013s	
4061/22750 (epoch 8.925), train_loss = 1.34296569, grad/param norm = 1.7101e-01, time/batch = 0.7044s	
4062/22750 (epoch 8.927), train_loss = 1.13204770, grad/param norm = 1.7983e-01, time/batch = 0.7038s	
4063/22750 (epoch 8.930), train_loss = 1.17714103, grad/param norm = 1.7281e-01, time/batch = 0.7035s	
4064/22750 (epoch 8.932), train_loss = 1.47546009, grad/param norm = 1.9479e-01, time/batch = 0.7043s	
4065/22750 (epoch 8.934), train_loss = 1.04678870, grad/param norm = 1.5445e-01, time/batch = 0.7041s	
4066/22750 (epoch 8.936), train_loss = 1.53848038, grad/param norm = 2.0432e-01, time/batch = 0.7030s	
4067/22750 (epoch 8.938), train_loss = 1.44332772, grad/param norm = 1.8697e-01, time/batch = 0.7109s	
4068/22750 (epoch 8.941), train_loss = 1.68072071, grad/param norm = 1.9974e-01, time/batch = 0.7148s	
4069/22750 (epoch 8.943), train_loss = 1.47984871, grad/param norm = 1.8854e-01, time/batch = 0.7257s	
4070/22750 (epoch 8.945), train_loss = 1.41140287, grad/param norm = 1.8013e-01, time/batch = 0.7235s	
4071/22750 (epoch 8.947), train_loss = 1.36229277, grad/param norm = 2.0034e-01, time/batch = 0.7278s	
4072/22750 (epoch 8.949), train_loss = 1.26735421, grad/param norm = 1.9117e-01, time/batch = 0.7127s	
4073/22750 (epoch 8.952), train_loss = 1.30653466, grad/param norm = 1.9201e-01, time/batch = 0.7209s	
4074/22750 (epoch 8.954), train_loss = 1.27853456, grad/param norm = 1.6885e-01, time/batch = 0.7032s	
4075/22750 (epoch 8.956), train_loss = 1.39994071, grad/param norm = 1.7956e-01, time/batch = 0.7094s	
4076/22750 (epoch 8.958), train_loss = 1.35153634, grad/param norm = 1.7975e-01, time/batch = 0.7173s	
4077/22750 (epoch 8.960), train_loss = 1.36017687, grad/param norm = 1.7213e-01, time/batch = 0.7063s	
4078/22750 (epoch 8.963), train_loss = 1.56444959, grad/param norm = 1.9664e-01, time/batch = 0.7048s	
4079/22750 (epoch 8.965), train_loss = 1.49760263, grad/param norm = 1.9320e-01, time/batch = 0.7041s	
4080/22750 (epoch 8.967), train_loss = 1.42119331, grad/param norm = 2.1249e-01, time/batch = 0.7085s	
4081/22750 (epoch 8.969), train_loss = 1.34062996, grad/param norm = 1.8796e-01, time/batch = 0.7027s	
4082/22750 (epoch 8.971), train_loss = 1.33062330, grad/param norm = 1.7866e-01, time/batch = 0.6992s	
4083/22750 (epoch 8.974), train_loss = 1.40685154, grad/param norm = 1.9370e-01, time/batch = 0.6940s	
4084/22750 (epoch 8.976), train_loss = 1.50387766, grad/param norm = 1.9846e-01, time/batch = 0.6995s	
4085/22750 (epoch 8.978), train_loss = 1.25428057, grad/param norm = 1.7090e-01, time/batch = 0.7032s	
4086/22750 (epoch 8.980), train_loss = 1.54160177, grad/param norm = 2.0425e-01, time/batch = 0.7026s	
4087/22750 (epoch 8.982), train_loss = 1.33039894, grad/param norm = 1.7753e-01, time/batch = 0.7055s	
4088/22750 (epoch 8.985), train_loss = 1.65034133, grad/param norm = 2.1669e-01, time/batch = 0.7203s	
4089/22750 (epoch 8.987), train_loss = 1.18248994, grad/param norm = 1.7210e-01, time/batch = 0.7292s	
4090/22750 (epoch 8.989), train_loss = 1.31307001, grad/param norm = 1.6953e-01, time/batch = 0.7263s	
4091/22750 (epoch 8.991), train_loss = 1.48649062, grad/param norm = 1.8979e-01, time/batch = 0.7169s	
4092/22750 (epoch 8.993), train_loss = 1.53053321, grad/param norm = 2.0007e-01, time/batch = 0.7159s	
4093/22750 (epoch 8.996), train_loss = 1.36156879, grad/param norm = 2.0697e-01, time/batch = 0.7252s	
4094/22750 (epoch 8.998), train_loss = 1.56727742, grad/param norm = 1.9460e-01, time/batch = 0.7144s	
4095/22750 (epoch 9.000), train_loss = 1.45332553, grad/param norm = 1.9396e-01, time/batch = 0.7118s	
4096/22750 (epoch 9.002), train_loss = 1.54313239, grad/param norm = 2.0661e-01, time/batch = 0.7071s	
4097/22750 (epoch 9.004), train_loss = 1.32297909, grad/param norm = 1.9490e-01, time/batch = 0.7058s	
4098/22750 (epoch 9.007), train_loss = 1.41124173, grad/param norm = 1.8920e-01, time/batch = 0.6995s	
4099/22750 (epoch 9.009), train_loss = 1.69540480, grad/param norm = 1.9529e-01, time/batch = 0.6980s	
4100/22750 (epoch 9.011), train_loss = 1.64748816, grad/param norm = 1.9189e-01, time/batch = 0.6986s	
4101/22750 (epoch 9.013), train_loss = 1.50929191, grad/param norm = 1.8100e-01, time/batch = 0.7018s	
4102/22750 (epoch 9.015), train_loss = 1.46993945, grad/param norm = 1.9179e-01, time/batch = 0.7219s	
4103/22750 (epoch 9.018), train_loss = 1.51789903, grad/param norm = 1.9929e-01, time/batch = 0.7227s	
4104/22750 (epoch 9.020), train_loss = 1.60837745, grad/param norm = 1.9569e-01, time/batch = 0.7541s	
4105/22750 (epoch 9.022), train_loss = 1.39483797, grad/param norm = 1.7597e-01, time/batch = 0.7366s	
4106/22750 (epoch 9.024), train_loss = 1.40581950, grad/param norm = 1.9909e-01, time/batch = 0.7250s	
4107/22750 (epoch 9.026), train_loss = 1.52973655, grad/param norm = 2.0847e-01, time/batch = 0.7238s	
4108/22750 (epoch 9.029), train_loss = 1.17841359, grad/param norm = 1.7051e-01, time/batch = 0.7197s	
4109/22750 (epoch 9.031), train_loss = 1.71163265, grad/param norm = 2.1416e-01, time/batch = 0.7089s	
4110/22750 (epoch 9.033), train_loss = 1.44356245, grad/param norm = 1.9288e-01, time/batch = 0.6992s	
4111/22750 (epoch 9.035), train_loss = 1.48464219, grad/param norm = 1.9442e-01, time/batch = 0.6973s	
4112/22750 (epoch 9.037), train_loss = 1.55426856, grad/param norm = 2.1040e-01, time/batch = 0.6957s	
4113/22750 (epoch 9.040), train_loss = 1.34575445, grad/param norm = 2.0075e-01, time/batch = 0.6950s	
4114/22750 (epoch 9.042), train_loss = 1.52591116, grad/param norm = 2.0498e-01, time/batch = 0.7073s	
4115/22750 (epoch 9.044), train_loss = 1.34476861, grad/param norm = 1.9786e-01, time/batch = 0.7261s	
4116/22750 (epoch 9.046), train_loss = 1.52620563, grad/param norm = 2.2738e-01, time/batch = 0.7181s	
4117/22750 (epoch 9.048), train_loss = 1.39688375, grad/param norm = 1.8925e-01, time/batch = 0.7156s	
4118/22750 (epoch 9.051), train_loss = 1.43758858, grad/param norm = 1.8049e-01, time/batch = 0.7318s	
4119/22750 (epoch 9.053), train_loss = 1.25193060, grad/param norm = 1.8749e-01, time/batch = 0.7130s	
4120/22750 (epoch 9.055), train_loss = 1.37887493, grad/param norm = 1.8830e-01, time/batch = 0.7096s	
4121/22750 (epoch 9.057), train_loss = 1.56156208, grad/param norm = 1.9824e-01, time/batch = 0.7151s	
4122/22750 (epoch 9.059), train_loss = 1.06232402, grad/param norm = 1.7200e-01, time/batch = 0.7109s	
4123/22750 (epoch 9.062), train_loss = 1.21678058, grad/param norm = 1.6996e-01, time/batch = 0.7103s	
4124/22750 (epoch 9.064), train_loss = 1.43802204, grad/param norm = 1.9520e-01, time/batch = 0.7047s	
4125/22750 (epoch 9.066), train_loss = 1.20563361, grad/param norm = 1.6712e-01, time/batch = 0.7105s	
4126/22750 (epoch 9.068), train_loss = 1.27213294, grad/param norm = 1.6080e-01, time/batch = 0.7094s	
4127/22750 (epoch 9.070), train_loss = 1.17694750, grad/param norm = 1.7396e-01, time/batch = 0.7085s	
4128/22750 (epoch 9.073), train_loss = 1.30798435, grad/param norm = 1.7237e-01, time/batch = 0.7051s	
4129/22750 (epoch 9.075), train_loss = 1.35045098, grad/param norm = 1.7775e-01, time/batch = 0.7017s	
4130/22750 (epoch 9.077), train_loss = 1.06214472, grad/param norm = 1.7147e-01, time/batch = 0.7049s	
4131/22750 (epoch 9.079), train_loss = 1.34847403, grad/param norm = 1.8799e-01, time/batch = 0.7013s	
4132/22750 (epoch 9.081), train_loss = 1.37602628, grad/param norm = 2.1746e-01, time/batch = 0.6981s	
4133/22750 (epoch 9.084), train_loss = 1.30651164, grad/param norm = 1.9901e-01, time/batch = 0.7026s	
4134/22750 (epoch 9.086), train_loss = 1.31208444, grad/param norm = 1.6354e-01, time/batch = 0.6989s	
4135/22750 (epoch 9.088), train_loss = 1.31697473, grad/param norm = 1.9310e-01, time/batch = 0.6993s	
4136/22750 (epoch 9.090), train_loss = 1.34407241, grad/param norm = 1.7171e-01, time/batch = 0.6997s	
4137/22750 (epoch 9.092), train_loss = 1.55943605, grad/param norm = 1.9124e-01, time/batch = 0.7191s	
4138/22750 (epoch 9.095), train_loss = 1.22412061, grad/param norm = 1.7376e-01, time/batch = 0.7008s	
4139/22750 (epoch 9.097), train_loss = 1.32533535, grad/param norm = 1.8111e-01, time/batch = 0.6980s	
4140/22750 (epoch 9.099), train_loss = 1.39211877, grad/param norm = 1.9620e-01, time/batch = 0.7014s	
4141/22750 (epoch 9.101), train_loss = 1.30899387, grad/param norm = 1.8828e-01, time/batch = 0.7010s	
4142/22750 (epoch 9.103), train_loss = 1.36408529, grad/param norm = 1.9101e-01, time/batch = 0.7028s	
4143/22750 (epoch 9.105), train_loss = 1.68831595, grad/param norm = 2.2100e-01, time/batch = 0.7017s	
4144/22750 (epoch 9.108), train_loss = 1.34041581, grad/param norm = 1.7881e-01, time/batch = 0.6960s	
4145/22750 (epoch 9.110), train_loss = 1.45617652, grad/param norm = 1.8027e-01, time/batch = 0.6979s	
4146/22750 (epoch 9.112), train_loss = 1.15116995, grad/param norm = 1.6193e-01, time/batch = 0.6962s	
4147/22750 (epoch 9.114), train_loss = 1.08793436, grad/param norm = 1.7587e-01, time/batch = 0.7006s	
4148/22750 (epoch 9.116), train_loss = 1.22746956, grad/param norm = 1.7052e-01, time/batch = 0.7017s	
4149/22750 (epoch 9.119), train_loss = 1.25916714, grad/param norm = 1.6740e-01, time/batch = 0.7061s	
4150/22750 (epoch 9.121), train_loss = 1.47602933, grad/param norm = 2.0437e-01, time/batch = 0.6997s	
4151/22750 (epoch 9.123), train_loss = 1.26606336, grad/param norm = 1.6875e-01, time/batch = 0.6989s	
4152/22750 (epoch 9.125), train_loss = 1.52533389, grad/param norm = 1.8258e-01, time/batch = 0.7085s	
4153/22750 (epoch 9.127), train_loss = 1.40421088, grad/param norm = 1.9724e-01, time/batch = 0.7249s	
4154/22750 (epoch 9.130), train_loss = 1.44267489, grad/param norm = 1.8336e-01, time/batch = 0.7017s	
4155/22750 (epoch 9.132), train_loss = 1.42807940, grad/param norm = 2.0351e-01, time/batch = 0.7006s	
4156/22750 (epoch 9.134), train_loss = 1.32806531, grad/param norm = 1.7907e-01, time/batch = 0.7007s	
4157/22750 (epoch 9.136), train_loss = 1.19483858, grad/param norm = 1.7614e-01, time/batch = 0.7011s	
4158/22750 (epoch 9.138), train_loss = 1.40389931, grad/param norm = 1.9742e-01, time/batch = 0.7025s	
4159/22750 (epoch 9.141), train_loss = 1.29261755, grad/param norm = 1.7332e-01, time/batch = 0.6960s	
4160/22750 (epoch 9.143), train_loss = 1.19724365, grad/param norm = 1.7578e-01, time/batch = 0.7011s	
4161/22750 (epoch 9.145), train_loss = 1.51763524, grad/param norm = 1.8982e-01, time/batch = 0.6948s	
4162/22750 (epoch 9.147), train_loss = 1.52491649, grad/param norm = 2.0613e-01, time/batch = 0.7001s	
4163/22750 (epoch 9.149), train_loss = 1.38027543, grad/param norm = 1.8819e-01, time/batch = 0.6933s	
4164/22750 (epoch 9.152), train_loss = 1.30037287, grad/param norm = 1.9402e-01, time/batch = 0.6960s	
4165/22750 (epoch 9.154), train_loss = 1.14702946, grad/param norm = 1.8402e-01, time/batch = 0.7040s	
4166/22750 (epoch 9.156), train_loss = 1.19637358, grad/param norm = 1.7268e-01, time/batch = 0.7007s	
4167/22750 (epoch 9.158), train_loss = 1.32846174, grad/param norm = 2.0461e-01, time/batch = 0.6968s	
4168/22750 (epoch 9.160), train_loss = 1.44482348, grad/param norm = 1.9604e-01, time/batch = 0.6996s	
4169/22750 (epoch 9.163), train_loss = 1.65235595, grad/param norm = 2.2165e-01, time/batch = 0.6986s	
4170/22750 (epoch 9.165), train_loss = 1.48609178, grad/param norm = 2.0217e-01, time/batch = 0.6972s	
4171/22750 (epoch 9.167), train_loss = 1.31433801, grad/param norm = 1.8836e-01, time/batch = 0.6998s	
4172/22750 (epoch 9.169), train_loss = 1.41477677, grad/param norm = 2.0175e-01, time/batch = 0.7113s	
4173/22750 (epoch 9.171), train_loss = 1.23153198, grad/param norm = 1.8865e-01, time/batch = 0.7165s	
4174/22750 (epoch 9.174), train_loss = 1.12967765, grad/param norm = 1.7828e-01, time/batch = 0.7021s	
4175/22750 (epoch 9.176), train_loss = 1.37179626, grad/param norm = 1.8446e-01, time/batch = 0.7020s	
4176/22750 (epoch 9.178), train_loss = 1.33049337, grad/param norm = 1.7909e-01, time/batch = 0.7014s	
4177/22750 (epoch 9.180), train_loss = 1.48801163, grad/param norm = 2.2219e-01, time/batch = 0.7009s	
4178/22750 (epoch 9.182), train_loss = 1.51109283, grad/param norm = 1.8572e-01, time/batch = 0.7065s	
4179/22750 (epoch 9.185), train_loss = 1.49626921, grad/param norm = 1.9720e-01, time/batch = 0.7017s	
4180/22750 (epoch 9.187), train_loss = 1.26839191, grad/param norm = 1.8793e-01, time/batch = 0.7006s	
4181/22750 (epoch 9.189), train_loss = 1.28976551, grad/param norm = 1.8362e-01, time/batch = 0.7041s	
4182/22750 (epoch 9.191), train_loss = 1.20645768, grad/param norm = 1.5410e-01, time/batch = 0.7016s	
4183/22750 (epoch 9.193), train_loss = 1.45573249, grad/param norm = 1.9141e-01, time/batch = 0.7015s	
4184/22750 (epoch 9.196), train_loss = 1.35572981, grad/param norm = 1.8185e-01, time/batch = 0.7017s	
4185/22750 (epoch 9.198), train_loss = 1.08587079, grad/param norm = 1.4631e-01, time/batch = 0.7018s	
4186/22750 (epoch 9.200), train_loss = 1.37124048, grad/param norm = 1.8364e-01, time/batch = 0.7000s	
4187/22750 (epoch 9.202), train_loss = 1.52782988, grad/param norm = 2.0259e-01, time/batch = 0.7026s	
4188/22750 (epoch 9.204), train_loss = 1.49712195, grad/param norm = 1.9233e-01, time/batch = 0.7106s	
4189/22750 (epoch 9.207), train_loss = 1.30486125, grad/param norm = 1.7990e-01, time/batch = 0.6947s	
4190/22750 (epoch 9.209), train_loss = 1.22051825, grad/param norm = 1.7659e-01, time/batch = 0.7028s	
4191/22750 (epoch 9.211), train_loss = 1.29373934, grad/param norm = 1.9797e-01, time/batch = 0.7026s	
4192/22750 (epoch 9.213), train_loss = 1.20719455, grad/param norm = 1.9097e-01, time/batch = 0.7208s	
4193/22750 (epoch 9.215), train_loss = 1.18368906, grad/param norm = 1.8314e-01, time/batch = 0.7225s	
4194/22750 (epoch 9.218), train_loss = 1.18972010, grad/param norm = 2.0580e-01, time/batch = 0.7004s	
4195/22750 (epoch 9.220), train_loss = 1.32132770, grad/param norm = 1.9609e-01, time/batch = 0.7061s	
4196/22750 (epoch 9.222), train_loss = 1.19136799, grad/param norm = 1.9442e-01, time/batch = 0.7012s	
4197/22750 (epoch 9.224), train_loss = 1.26441236, grad/param norm = 1.8063e-01, time/batch = 0.7043s	
4198/22750 (epoch 9.226), train_loss = 1.47318917, grad/param norm = 2.0950e-01, time/batch = 0.7030s	
4199/22750 (epoch 9.229), train_loss = 1.41645764, grad/param norm = 1.9998e-01, time/batch = 0.7179s	
4200/22750 (epoch 9.231), train_loss = 1.29627675, grad/param norm = 1.8204e-01, time/batch = 0.7254s	
4201/22750 (epoch 9.233), train_loss = 1.22155774, grad/param norm = 1.8377e-01, time/batch = 0.7280s	
4202/22750 (epoch 9.235), train_loss = 1.23193320, grad/param norm = 1.9883e-01, time/batch = 0.7287s	
4203/22750 (epoch 9.237), train_loss = 1.27073982, grad/param norm = 1.9480e-01, time/batch = 0.7293s	
4204/22750 (epoch 9.240), train_loss = 1.41599024, grad/param norm = 1.6641e-01, time/batch = 0.7126s	
4205/22750 (epoch 9.242), train_loss = 1.75604580, grad/param norm = 2.0899e-01, time/batch = 0.7095s	
4206/22750 (epoch 9.244), train_loss = 1.56128828, grad/param norm = 2.1175e-01, time/batch = 0.7023s	
4207/22750 (epoch 9.246), train_loss = 1.60474041, grad/param norm = 1.9603e-01, time/batch = 0.7071s	
4208/22750 (epoch 9.248), train_loss = 1.33444707, grad/param norm = 1.9441e-01, time/batch = 0.7152s	
4209/22750 (epoch 9.251), train_loss = 1.60838894, grad/param norm = 1.8496e-01, time/batch = 0.7133s	
4210/22750 (epoch 9.253), train_loss = 1.37767155, grad/param norm = 1.8660e-01, time/batch = 0.7074s	
4211/22750 (epoch 9.255), train_loss = 1.40371274, grad/param norm = 1.9223e-01, time/batch = 0.7165s	
4212/22750 (epoch 9.257), train_loss = 1.32917470, grad/param norm = 1.8898e-01, time/batch = 0.7122s	
4213/22750 (epoch 9.259), train_loss = 1.56220683, grad/param norm = 2.1438e-01, time/batch = 0.7317s	
4214/22750 (epoch 9.262), train_loss = 1.35133170, grad/param norm = 1.8470e-01, time/batch = 0.7250s	
4215/22750 (epoch 9.264), train_loss = 1.23779744, grad/param norm = 1.7238e-01, time/batch = 0.7045s	
4216/22750 (epoch 9.266), train_loss = 1.40338111, grad/param norm = 2.1972e-01, time/batch = 0.7033s	
4217/22750 (epoch 9.268), train_loss = 1.54169390, grad/param norm = 2.0162e-01, time/batch = 0.6918s	
4218/22750 (epoch 9.270), train_loss = 1.33664205, grad/param norm = 1.9649e-01, time/batch = 0.7016s	
4219/22750 (epoch 9.273), train_loss = 1.67984925, grad/param norm = 2.2630e-01, time/batch = 0.7040s	
4220/22750 (epoch 9.275), train_loss = 1.43461221, grad/param norm = 1.8567e-01, time/batch = 0.7079s	
4221/22750 (epoch 9.277), train_loss = 1.36923906, grad/param norm = 1.9530e-01, time/batch = 0.7136s	
4222/22750 (epoch 9.279), train_loss = 1.19375184, grad/param norm = 1.6985e-01, time/batch = 0.7268s	
4223/22750 (epoch 9.281), train_loss = 1.45378991, grad/param norm = 1.7933e-01, time/batch = 0.7050s	
4224/22750 (epoch 9.284), train_loss = 1.30293889, grad/param norm = 1.6913e-01, time/batch = 0.7039s	
4225/22750 (epoch 9.286), train_loss = 1.51850196, grad/param norm = 1.8986e-01, time/batch = 0.7089s	
4226/22750 (epoch 9.288), train_loss = 1.57571309, grad/param norm = 1.9476e-01, time/batch = 0.7078s	
4227/22750 (epoch 9.290), train_loss = 1.31931327, grad/param norm = 1.7564e-01, time/batch = 0.7059s	
4228/22750 (epoch 9.292), train_loss = 1.41629330, grad/param norm = 2.0458e-01, time/batch = 0.7006s	
4229/22750 (epoch 9.295), train_loss = 1.37100458, grad/param norm = 1.7235e-01, time/batch = 0.6988s	
4230/22750 (epoch 9.297), train_loss = 1.30565625, grad/param norm = 1.8121e-01, time/batch = 0.7008s	
4231/22750 (epoch 9.299), train_loss = 1.51471770, grad/param norm = 1.7822e-01, time/batch = 0.7143s	
4232/22750 (epoch 9.301), train_loss = 1.42542709, grad/param norm = 2.0044e-01, time/batch = 0.7218s	
4233/22750 (epoch 9.303), train_loss = 1.49197092, grad/param norm = 2.0347e-01, time/batch = 0.7146s	
4234/22750 (epoch 9.305), train_loss = 1.61557985, grad/param norm = 2.0022e-01, time/batch = 0.7180s	
4235/22750 (epoch 9.308), train_loss = 1.44260108, grad/param norm = 1.8440e-01, time/batch = 0.7010s	
4236/22750 (epoch 9.310), train_loss = 1.29597343, grad/param norm = 2.0041e-01, time/batch = 0.7052s	
4237/22750 (epoch 9.312), train_loss = 1.44146605, grad/param norm = 1.9569e-01, time/batch = 0.7013s	
4238/22750 (epoch 9.314), train_loss = 1.38433597, grad/param norm = 1.8803e-01, time/batch = 0.6963s	
4239/22750 (epoch 9.316), train_loss = 1.30098451, grad/param norm = 1.7911e-01, time/batch = 0.7005s	
4240/22750 (epoch 9.319), train_loss = 1.43074561, grad/param norm = 1.8855e-01, time/batch = 0.7030s	
4241/22750 (epoch 9.321), train_loss = 1.35512320, grad/param norm = 2.0240e-01, time/batch = 0.6993s	
4242/22750 (epoch 9.323), train_loss = 1.35105820, grad/param norm = 2.0497e-01, time/batch = 0.6998s	
4243/22750 (epoch 9.325), train_loss = 1.10479923, grad/param norm = 1.7110e-01, time/batch = 0.7050s	
4244/22750 (epoch 9.327), train_loss = 1.41524070, grad/param norm = 1.8870e-01, time/batch = 0.7132s	
4245/22750 (epoch 9.330), train_loss = 1.65535175, grad/param norm = 1.9821e-01, time/batch = 0.7050s	
4246/22750 (epoch 9.332), train_loss = 1.55343045, grad/param norm = 1.9111e-01, time/batch = 0.6999s	
4247/22750 (epoch 9.334), train_loss = 1.14384300, grad/param norm = 1.7881e-01, time/batch = 0.7058s	
4248/22750 (epoch 9.336), train_loss = 1.43004034, grad/param norm = 1.9592e-01, time/batch = 0.7085s	
4249/22750 (epoch 9.338), train_loss = 1.33123861, grad/param norm = 1.8371e-01, time/batch = 0.7106s	
4250/22750 (epoch 9.341), train_loss = 1.32781144, grad/param norm = 1.7460e-01, time/batch = 0.7058s	
4251/22750 (epoch 9.343), train_loss = 1.16153531, grad/param norm = 1.8426e-01, time/batch = 0.7036s	
4252/22750 (epoch 9.345), train_loss = 1.55082581, grad/param norm = 2.0175e-01, time/batch = 0.7065s	
4253/22750 (epoch 9.347), train_loss = 1.52128710, grad/param norm = 2.0741e-01, time/batch = 0.7186s	
4254/22750 (epoch 9.349), train_loss = 1.11946174, grad/param norm = 1.8112e-01, time/batch = 0.7045s	
4255/22750 (epoch 9.352), train_loss = 1.47109084, grad/param norm = 2.0243e-01, time/batch = 0.7012s	
4256/22750 (epoch 9.354), train_loss = 1.55949782, grad/param norm = 2.0179e-01, time/batch = 0.7021s	
4257/22750 (epoch 9.356), train_loss = 1.57445787, grad/param norm = 2.0506e-01, time/batch = 0.7045s	
4258/22750 (epoch 9.358), train_loss = 1.38496071, grad/param norm = 2.1198e-01, time/batch = 0.7016s	
4259/22750 (epoch 9.360), train_loss = 1.60678481, grad/param norm = 2.0912e-01, time/batch = 0.6998s	
4260/22750 (epoch 9.363), train_loss = 1.37526182, grad/param norm = 1.7345e-01, time/batch = 0.6988s	
4261/22750 (epoch 9.365), train_loss = 1.13177442, grad/param norm = 1.8479e-01, time/batch = 0.7255s	
4262/22750 (epoch 9.367), train_loss = 1.19541649, grad/param norm = 1.8582e-01, time/batch = 0.7173s	
4263/22750 (epoch 9.369), train_loss = 1.31741027, grad/param norm = 1.9142e-01, time/batch = 0.7018s	
4264/22750 (epoch 9.371), train_loss = 1.28265280, grad/param norm = 1.8591e-01, time/batch = 0.7045s	
4265/22750 (epoch 9.374), train_loss = 1.21905837, grad/param norm = 1.8495e-01, time/batch = 0.7067s	
4266/22750 (epoch 9.376), train_loss = 1.36920156, grad/param norm = 1.7474e-01, time/batch = 0.7239s	
4267/22750 (epoch 9.378), train_loss = 1.35847599, grad/param norm = 1.8915e-01, time/batch = 0.7346s	
4268/22750 (epoch 9.380), train_loss = 1.53756441, grad/param norm = 1.9730e-01, time/batch = 0.7213s	
4269/22750 (epoch 9.382), train_loss = 1.29097419, grad/param norm = 1.7361e-01, time/batch = 0.7372s	
4270/22750 (epoch 9.385), train_loss = 1.42485683, grad/param norm = 1.7531e-01, time/batch = 0.7232s	
4271/22750 (epoch 9.387), train_loss = 1.42593658, grad/param norm = 1.8596e-01, time/batch = 0.7228s	
4272/22750 (epoch 9.389), train_loss = 1.04575382, grad/param norm = 1.7446e-01, time/batch = 0.7310s	
4273/22750 (epoch 9.391), train_loss = 0.88379350, grad/param norm = 1.5044e-01, time/batch = 0.7279s	
4274/22750 (epoch 9.393), train_loss = 1.19994259, grad/param norm = 1.7404e-01, time/batch = 0.7211s	
4275/22750 (epoch 9.396), train_loss = 1.37000247, grad/param norm = 1.9896e-01, time/batch = 0.7206s	
4276/22750 (epoch 9.398), train_loss = 1.32660761, grad/param norm = 1.8458e-01, time/batch = 0.7159s	
4277/22750 (epoch 9.400), train_loss = 1.34338462, grad/param norm = 1.6817e-01, time/batch = 0.7373s	
4278/22750 (epoch 9.402), train_loss = 1.40939537, grad/param norm = 1.7734e-01, time/batch = 0.7222s	
4279/22750 (epoch 9.404), train_loss = 1.58088671, grad/param norm = 1.9224e-01, time/batch = 0.7209s	
4280/22750 (epoch 9.407), train_loss = 1.49305996, grad/param norm = 1.8079e-01, time/batch = 0.7152s	
4281/22750 (epoch 9.409), train_loss = 1.35378074, grad/param norm = 1.7583e-01, time/batch = 0.7056s	
4282/22750 (epoch 9.411), train_loss = 1.35480167, grad/param norm = 1.7542e-01, time/batch = 0.7122s	
4283/22750 (epoch 9.413), train_loss = 1.16872963, grad/param norm = 1.9340e-01, time/batch = 0.7230s	
4284/22750 (epoch 9.415), train_loss = 1.10327871, grad/param norm = 1.8323e-01, time/batch = 0.7295s	
4285/22750 (epoch 9.418), train_loss = 1.32241760, grad/param norm = 1.9452e-01, time/batch = 0.7330s	
4286/22750 (epoch 9.420), train_loss = 1.57803533, grad/param norm = 2.1011e-01, time/batch = 0.7137s	
4287/22750 (epoch 9.422), train_loss = 1.67642239, grad/param norm = 2.1522e-01, time/batch = 0.7044s	
4288/22750 (epoch 9.424), train_loss = 1.65608338, grad/param norm = 2.2390e-01, time/batch = 0.7247s	
4289/22750 (epoch 9.426), train_loss = 1.60730594, grad/param norm = 1.9604e-01, time/batch = 0.7159s	
4290/22750 (epoch 9.429), train_loss = 1.13448917, grad/param norm = 1.8180e-01, time/batch = 0.7240s	
4291/22750 (epoch 9.431), train_loss = 1.12577077, grad/param norm = 1.6611e-01, time/batch = 0.7202s	
4292/22750 (epoch 9.433), train_loss = 1.25526209, grad/param norm = 1.8280e-01, time/batch = 0.7254s	
4293/22750 (epoch 9.435), train_loss = 1.10699123, grad/param norm = 1.7545e-01, time/batch = 0.7173s	
4294/22750 (epoch 9.437), train_loss = 0.99758430, grad/param norm = 1.6215e-01, time/batch = 0.7068s	
4295/22750 (epoch 9.440), train_loss = 1.45824746, grad/param norm = 1.9422e-01, time/batch = 0.7031s	
4296/22750 (epoch 9.442), train_loss = 1.40957871, grad/param norm = 1.9422e-01, time/batch = 0.7110s	
4297/22750 (epoch 9.444), train_loss = 1.37514326, grad/param norm = 2.1041e-01, time/batch = 0.7008s	
4298/22750 (epoch 9.446), train_loss = 1.37298192, grad/param norm = 2.1806e-01, time/batch = 0.7025s	
4299/22750 (epoch 9.448), train_loss = 1.66474789, grad/param norm = 2.1387e-01, time/batch = 0.7096s	
4300/22750 (epoch 9.451), train_loss = 1.56776257, grad/param norm = 2.0095e-01, time/batch = 0.7056s	
4301/22750 (epoch 9.453), train_loss = 1.62680893, grad/param norm = 1.9960e-01, time/batch = 0.6998s	
4302/22750 (epoch 9.455), train_loss = 1.71507842, grad/param norm = 1.9780e-01, time/batch = 0.7118s	
4303/22750 (epoch 9.457), train_loss = 1.55000347, grad/param norm = 2.1019e-01, time/batch = 0.7108s	
4304/22750 (epoch 9.459), train_loss = 1.46175498, grad/param norm = 1.9023e-01, time/batch = 0.7049s	
4305/22750 (epoch 9.462), train_loss = 1.48850273, grad/param norm = 1.6726e-01, time/batch = 0.7082s	
4306/22750 (epoch 9.464), train_loss = 1.19296020, grad/param norm = 1.7897e-01, time/batch = 0.7261s	
4307/22750 (epoch 9.466), train_loss = 1.63383761, grad/param norm = 2.1565e-01, time/batch = 0.7036s	
4308/22750 (epoch 9.468), train_loss = 1.34444515, grad/param norm = 1.9337e-01, time/batch = 0.7075s	
4309/22750 (epoch 9.470), train_loss = 1.51993114, grad/param norm = 1.9666e-01, time/batch = 0.7071s	
4310/22750 (epoch 9.473), train_loss = 1.38820402, grad/param norm = 1.9774e-01, time/batch = 0.7071s	
4311/22750 (epoch 9.475), train_loss = 1.43851763, grad/param norm = 2.0325e-01, time/batch = 0.7140s	
4312/22750 (epoch 9.477), train_loss = 1.16460568, grad/param norm = 1.7242e-01, time/batch = 0.7177s	
4313/22750 (epoch 9.479), train_loss = 1.20235500, grad/param norm = 1.8044e-01, time/batch = 0.7261s	
4314/22750 (epoch 9.481), train_loss = 1.11426675, grad/param norm = 1.7082e-01, time/batch = 0.7274s	
4315/22750 (epoch 9.484), train_loss = 1.04369170, grad/param norm = 1.8181e-01, time/batch = 0.7289s	
4316/22750 (epoch 9.486), train_loss = 1.23024266, grad/param norm = 1.9661e-01, time/batch = 0.7300s	
4317/22750 (epoch 9.488), train_loss = 1.05482611, grad/param norm = 2.0581e-01, time/batch = 0.7281s	
4318/22750 (epoch 9.490), train_loss = 1.32928611, grad/param norm = 1.8676e-01, time/batch = 0.7366s	
4319/22750 (epoch 9.492), train_loss = 1.52395566, grad/param norm = 1.9947e-01, time/batch = 0.7195s	
4320/22750 (epoch 9.495), train_loss = 1.27574876, grad/param norm = 2.0944e-01, time/batch = 0.7094s	
4321/22750 (epoch 9.497), train_loss = 1.42935754, grad/param norm = 2.1572e-01, time/batch = 0.7005s	
4322/22750 (epoch 9.499), train_loss = 1.28785012, grad/param norm = 1.9377e-01, time/batch = 0.7008s	
4323/22750 (epoch 9.501), train_loss = 1.39951986, grad/param norm = 2.0767e-01, time/batch = 0.7036s	
4324/22750 (epoch 9.503), train_loss = 1.35229340, grad/param norm = 1.8347e-01, time/batch = 0.7094s	
4325/22750 (epoch 9.505), train_loss = 1.19904481, grad/param norm = 1.8245e-01, time/batch = 0.7042s	
4326/22750 (epoch 9.508), train_loss = 1.14357336, grad/param norm = 1.8817e-01, time/batch = 0.7130s	
4327/22750 (epoch 9.510), train_loss = 1.18247481, grad/param norm = 1.7564e-01, time/batch = 0.7061s	
4328/22750 (epoch 9.512), train_loss = 1.23357901, grad/param norm = 1.7119e-01, time/batch = 0.7084s	
4329/22750 (epoch 9.514), train_loss = 1.25490135, grad/param norm = 1.7380e-01, time/batch = 0.7199s	
4330/22750 (epoch 9.516), train_loss = 1.22875291, grad/param norm = 1.7945e-01, time/batch = 0.7065s	
4331/22750 (epoch 9.519), train_loss = 1.45469995, grad/param norm = 1.8959e-01, time/batch = 0.7078s	
4332/22750 (epoch 9.521), train_loss = 1.27596324, grad/param norm = 1.8281e-01, time/batch = 0.7076s	
4333/22750 (epoch 9.523), train_loss = 1.29101692, grad/param norm = 2.0770e-01, time/batch = 0.7078s	
4334/22750 (epoch 9.525), train_loss = 1.58680213, grad/param norm = 2.2873e-01, time/batch = 0.7100s	
4335/22750 (epoch 9.527), train_loss = 1.37116673, grad/param norm = 1.8644e-01, time/batch = 0.7182s	
4336/22750 (epoch 9.530), train_loss = 1.28562834, grad/param norm = 1.9362e-01, time/batch = 0.7096s	
4337/22750 (epoch 9.532), train_loss = 1.20199780, grad/param norm = 1.6611e-01, time/batch = 0.7038s	
4338/22750 (epoch 9.534), train_loss = 1.46639548, grad/param norm = 1.9787e-01, time/batch = 0.7065s	
4339/22750 (epoch 9.536), train_loss = 1.37117387, grad/param norm = 1.8912e-01, time/batch = 0.7097s	
4340/22750 (epoch 9.538), train_loss = 1.37768988, grad/param norm = 1.6644e-01, time/batch = 0.7125s	
4341/22750 (epoch 9.541), train_loss = 1.15672374, grad/param norm = 1.7661e-01, time/batch = 0.7169s	
4342/22750 (epoch 9.543), train_loss = 1.17810067, grad/param norm = 1.6956e-01, time/batch = 0.7178s	
4343/22750 (epoch 9.545), train_loss = 1.51351905, grad/param norm = 1.8993e-01, time/batch = 0.7189s	
4344/22750 (epoch 9.547), train_loss = 1.17504029, grad/param norm = 1.6127e-01, time/batch = 0.7219s	
4345/22750 (epoch 9.549), train_loss = 1.26656153, grad/param norm = 1.8955e-01, time/batch = 0.7225s	
4346/22750 (epoch 9.552), train_loss = 1.44005923, grad/param norm = 2.0068e-01, time/batch = 0.7057s	
4347/22750 (epoch 9.554), train_loss = 1.47963542, grad/param norm = 2.0681e-01, time/batch = 0.7007s	
4348/22750 (epoch 9.556), train_loss = 1.34444842, grad/param norm = 1.9459e-01, time/batch = 0.7010s	
4349/22750 (epoch 9.558), train_loss = 1.51275235, grad/param norm = 1.9135e-01, time/batch = 0.7003s	
4350/22750 (epoch 9.560), train_loss = 1.27245775, grad/param norm = 1.8092e-01, time/batch = 0.6967s	
4351/22750 (epoch 9.563), train_loss = 1.44992134, grad/param norm = 1.7075e-01, time/batch = 0.6966s	
4352/22750 (epoch 9.565), train_loss = 1.47967134, grad/param norm = 1.8757e-01, time/batch = 0.6972s	
4353/22750 (epoch 9.567), train_loss = 1.38211711, grad/param norm = 1.8931e-01, time/batch = 0.6994s	
4354/22750 (epoch 9.569), train_loss = 1.30165851, grad/param norm = 1.8248e-01, time/batch = 0.6983s	
4355/22750 (epoch 9.571), train_loss = 1.39825079, grad/param norm = 1.9963e-01, time/batch = 0.7032s	
4356/22750 (epoch 9.574), train_loss = 1.23139678, grad/param norm = 1.8812e-01, time/batch = 0.7022s	
4357/22750 (epoch 9.576), train_loss = 1.37517428, grad/param norm = 1.8022e-01, time/batch = 0.6994s	
4358/22750 (epoch 9.578), train_loss = 1.19391490, grad/param norm = 1.7713e-01, time/batch = 0.6980s	
4359/22750 (epoch 9.580), train_loss = 1.39404039, grad/param norm = 2.0115e-01, time/batch = 0.7307s	
4360/22750 (epoch 9.582), train_loss = 1.15902330, grad/param norm = 1.7009e-01, time/batch = 0.7212s	
4361/22750 (epoch 9.585), train_loss = 1.07937448, grad/param norm = 1.8303e-01, time/batch = 0.7020s	
4362/22750 (epoch 9.587), train_loss = 1.14576762, grad/param norm = 1.6642e-01, time/batch = 0.6996s	
4363/22750 (epoch 9.589), train_loss = 1.14019926, grad/param norm = 1.8298e-01, time/batch = 0.7026s	
4364/22750 (epoch 9.591), train_loss = 1.33475138, grad/param norm = 1.9049e-01, time/batch = 0.7027s	
4365/22750 (epoch 9.593), train_loss = 1.54983102, grad/param norm = 1.9190e-01, time/batch = 0.6978s	
4366/22750 (epoch 9.596), train_loss = 1.53636914, grad/param norm = 1.9246e-01, time/batch = 0.6989s	
4367/22750 (epoch 9.598), train_loss = 1.56765299, grad/param norm = 1.9666e-01, time/batch = 0.7128s	
4368/22750 (epoch 9.600), train_loss = 1.51557337, grad/param norm = 1.9063e-01, time/batch = 0.7272s	
4369/22750 (epoch 9.602), train_loss = 1.19120740, grad/param norm = 1.6152e-01, time/batch = 0.7069s	
4370/22750 (epoch 9.604), train_loss = 1.29607002, grad/param norm = 1.8352e-01, time/batch = 0.7110s	
4371/22750 (epoch 9.607), train_loss = 1.10087923, grad/param norm = 1.6575e-01, time/batch = 0.7045s	
4372/22750 (epoch 9.609), train_loss = 1.03932548, grad/param norm = 1.5782e-01, time/batch = 0.7119s	
4373/22750 (epoch 9.611), train_loss = 1.26569152, grad/param norm = 1.8823e-01, time/batch = 0.7001s	
4374/22750 (epoch 9.613), train_loss = 1.19306822, grad/param norm = 1.9308e-01, time/batch = 0.7001s	
4375/22750 (epoch 9.615), train_loss = 1.25344484, grad/param norm = 1.7372e-01, time/batch = 0.7014s	
4376/22750 (epoch 9.618), train_loss = 1.30105402, grad/param norm = 1.8260e-01, time/batch = 0.6991s	
4377/22750 (epoch 9.620), train_loss = 1.32897909, grad/param norm = 1.8393e-01, time/batch = 0.6980s	
4378/22750 (epoch 9.622), train_loss = 1.12222083, grad/param norm = 1.7869e-01, time/batch = 0.6931s	
4379/22750 (epoch 9.624), train_loss = 1.31708770, grad/param norm = 1.9436e-01, time/batch = 0.6956s	
4380/22750 (epoch 9.626), train_loss = 1.16679941, grad/param norm = 1.8617e-01, time/batch = 0.7371s	
4381/22750 (epoch 9.629), train_loss = 1.31852281, grad/param norm = 1.9829e-01, time/batch = 0.7095s	
4382/22750 (epoch 9.631), train_loss = 1.35552896, grad/param norm = 1.9744e-01, time/batch = 0.7097s	
4383/22750 (epoch 9.633), train_loss = 1.10032056, grad/param norm = 1.8346e-01, time/batch = 0.7224s	
4384/22750 (epoch 9.635), train_loss = 1.36336191, grad/param norm = 2.0970e-01, time/batch = 0.7041s	
4385/22750 (epoch 9.637), train_loss = 1.43704724, grad/param norm = 2.0157e-01, time/batch = 0.7000s	
4386/22750 (epoch 9.640), train_loss = 1.47531259, grad/param norm = 2.1009e-01, time/batch = 0.6975s	
4387/22750 (epoch 9.642), train_loss = 1.49929779, grad/param norm = 1.9434e-01, time/batch = 0.6965s	
4388/22750 (epoch 9.644), train_loss = 1.35553165, grad/param norm = 1.9379e-01, time/batch = 0.6987s	
4389/22750 (epoch 9.646), train_loss = 1.48214017, grad/param norm = 2.0491e-01, time/batch = 0.6981s	
4390/22750 (epoch 9.648), train_loss = 1.36937363, grad/param norm = 2.0993e-01, time/batch = 0.7267s	
4391/22750 (epoch 9.651), train_loss = 1.48191301, grad/param norm = 2.1155e-01, time/batch = 0.7069s	
4392/22750 (epoch 9.653), train_loss = 1.40120847, grad/param norm = 1.9230e-01, time/batch = 0.6980s	
4393/22750 (epoch 9.655), train_loss = 1.32374627, grad/param norm = 1.8477e-01, time/batch = 0.6996s	
4394/22750 (epoch 9.657), train_loss = 1.54168932, grad/param norm = 1.9648e-01, time/batch = 0.7001s	
4395/22750 (epoch 9.659), train_loss = 1.63052320, grad/param norm = 1.9442e-01, time/batch = 0.7089s	
4396/22750 (epoch 9.662), train_loss = 1.65262081, grad/param norm = 2.2347e-01, time/batch = 0.7146s	
4397/22750 (epoch 9.664), train_loss = 1.42855267, grad/param norm = 1.9876e-01, time/batch = 0.7114s	
4398/22750 (epoch 9.666), train_loss = 1.20788547, grad/param norm = 1.8348e-01, time/batch = 0.7098s	
4399/22750 (epoch 9.668), train_loss = 1.37337102, grad/param norm = 1.8740e-01, time/batch = 0.7092s	
4400/22750 (epoch 9.670), train_loss = 1.38168710, grad/param norm = 1.8667e-01, time/batch = 0.7101s	
4401/22750 (epoch 9.673), train_loss = 1.63562243, grad/param norm = 2.1470e-01, time/batch = 0.7067s	
4402/22750 (epoch 9.675), train_loss = 1.83817658, grad/param norm = 2.1913e-01, time/batch = 0.7114s	
4403/22750 (epoch 9.677), train_loss = 1.58507156, grad/param norm = 2.2243e-01, time/batch = 0.7049s	
4404/22750 (epoch 9.679), train_loss = 1.64519459, grad/param norm = 2.1876e-01, time/batch = 0.7052s	
4405/22750 (epoch 9.681), train_loss = 1.57964013, grad/param norm = 2.0825e-01, time/batch = 0.6965s	
4406/22750 (epoch 9.684), train_loss = 1.53770649, grad/param norm = 1.9501e-01, time/batch = 0.6958s	
4407/22750 (epoch 9.686), train_loss = 1.52660008, grad/param norm = 2.1537e-01, time/batch = 0.7025s	
4408/22750 (epoch 9.688), train_loss = 1.50059579, grad/param norm = 2.0187e-01, time/batch = 0.7125s	
4409/22750 (epoch 9.690), train_loss = 1.48158069, grad/param norm = 1.9765e-01, time/batch = 0.7042s	
4410/22750 (epoch 9.692), train_loss = 1.60786100, grad/param norm = 1.9274e-01, time/batch = 0.6963s	
4411/22750 (epoch 9.695), train_loss = 1.37784614, grad/param norm = 1.8754e-01, time/batch = 0.7040s	
4412/22750 (epoch 9.697), train_loss = 1.37746617, grad/param norm = 2.0748e-01, time/batch = 0.7192s	
4413/22750 (epoch 9.699), train_loss = 1.38968634, grad/param norm = 1.7629e-01, time/batch = 0.7128s	
4414/22750 (epoch 9.701), train_loss = 1.21564350, grad/param norm = 1.7750e-01, time/batch = 0.7211s	
4415/22750 (epoch 9.703), train_loss = 1.41211084, grad/param norm = 1.7820e-01, time/batch = 0.7078s	
4416/22750 (epoch 9.705), train_loss = 1.24914882, grad/param norm = 1.6771e-01, time/batch = 0.7004s	
4417/22750 (epoch 9.708), train_loss = 1.40192166, grad/param norm = 1.7034e-01, time/batch = 0.7037s	
4418/22750 (epoch 9.710), train_loss = 1.17097530, grad/param norm = 1.8048e-01, time/batch = 0.7056s	
4419/22750 (epoch 9.712), train_loss = 1.26829282, grad/param norm = 1.6966e-01, time/batch = 0.7157s	
4420/22750 (epoch 9.714), train_loss = 1.13829008, grad/param norm = 1.7341e-01, time/batch = 0.7254s	
4421/22750 (epoch 9.716), train_loss = 1.24207894, grad/param norm = 1.8369e-01, time/batch = 0.7046s	
4422/22750 (epoch 9.719), train_loss = 1.47785277, grad/param norm = 2.1749e-01, time/batch = 0.7033s	
4423/22750 (epoch 9.721), train_loss = 1.44778927, grad/param norm = 1.9475e-01, time/batch = 0.7021s	
4424/22750 (epoch 9.723), train_loss = 1.37288415, grad/param norm = 1.9673e-01, time/batch = 0.7041s	
4425/22750 (epoch 9.725), train_loss = 1.36411516, grad/param norm = 1.9863e-01, time/batch = 0.7018s	
4426/22750 (epoch 9.727), train_loss = 1.27439690, grad/param norm = 1.6898e-01, time/batch = 0.7034s	
4427/22750 (epoch 9.730), train_loss = 1.31227352, grad/param norm = 1.8867e-01, time/batch = 0.7032s	
4428/22750 (epoch 9.732), train_loss = 1.30005368, grad/param norm = 1.7816e-01, time/batch = 0.6977s	
4429/22750 (epoch 9.734), train_loss = 1.06663197, grad/param norm = 1.7735e-01, time/batch = 0.7043s	
4430/22750 (epoch 9.736), train_loss = 1.24825728, grad/param norm = 1.7295e-01, time/batch = 0.7110s	
4431/22750 (epoch 9.738), train_loss = 1.37695291, grad/param norm = 1.9540e-01, time/batch = 0.7207s	
4432/22750 (epoch 9.741), train_loss = 1.46562053, grad/param norm = 1.8533e-01, time/batch = 0.7126s	
4433/22750 (epoch 9.743), train_loss = 1.40795227, grad/param norm = 1.9539e-01, time/batch = 0.7069s	
4434/22750 (epoch 9.745), train_loss = 1.16524228, grad/param norm = 1.6952e-01, time/batch = 0.6980s	
4435/22750 (epoch 9.747), train_loss = 1.27323090, grad/param norm = 1.8064e-01, time/batch = 0.6997s	
4436/22750 (epoch 9.749), train_loss = 1.57457727, grad/param norm = 2.0209e-01, time/batch = 0.7004s	
4437/22750 (epoch 9.752), train_loss = 1.27945348, grad/param norm = 1.8696e-01, time/batch = 0.7047s	
4438/22750 (epoch 9.754), train_loss = 1.50911124, grad/param norm = 2.2798e-01, time/batch = 0.7081s	
4439/22750 (epoch 9.756), train_loss = 1.20433990, grad/param norm = 2.1147e-01, time/batch = 0.7098s	
4440/22750 (epoch 9.758), train_loss = 1.16942948, grad/param norm = 1.7355e-01, time/batch = 0.7083s	
4441/22750 (epoch 9.760), train_loss = 1.35276909, grad/param norm = 1.8605e-01, time/batch = 0.7074s	
4442/22750 (epoch 9.763), train_loss = 1.42067406, grad/param norm = 1.8958e-01, time/batch = 0.7030s	
4443/22750 (epoch 9.765), train_loss = 1.29992526, grad/param norm = 2.0941e-01, time/batch = 0.7146s	
4444/22750 (epoch 9.767), train_loss = 1.36715947, grad/param norm = 1.8332e-01, time/batch = 0.7045s	
4445/22750 (epoch 9.769), train_loss = 1.56379044, grad/param norm = 1.9694e-01, time/batch = 0.6998s	
4446/22750 (epoch 9.771), train_loss = 1.51005125, grad/param norm = 1.8839e-01, time/batch = 0.7054s	
4447/22750 (epoch 9.774), train_loss = 1.25650820, grad/param norm = 2.0112e-01, time/batch = 0.7022s	
4448/22750 (epoch 9.776), train_loss = 1.36512405, grad/param norm = 1.9350e-01, time/batch = 0.7026s	
4449/22750 (epoch 9.778), train_loss = 1.57077234, grad/param norm = 1.8655e-01, time/batch = 0.7051s	
4450/22750 (epoch 9.780), train_loss = 1.39909663, grad/param norm = 1.9049e-01, time/batch = 0.6979s	
4451/22750 (epoch 9.782), train_loss = 1.52245024, grad/param norm = 1.8840e-01, time/batch = 0.7054s	
4452/22750 (epoch 9.785), train_loss = 1.35696607, grad/param norm = 1.8000e-01, time/batch = 0.7297s	
4453/22750 (epoch 9.787), train_loss = 1.25233938, grad/param norm = 1.8565e-01, time/batch = 0.7229s	
4454/22750 (epoch 9.789), train_loss = 1.30301414, grad/param norm = 1.7586e-01, time/batch = 0.7083s	
4455/22750 (epoch 9.791), train_loss = 1.33084579, grad/param norm = 1.7924e-01, time/batch = 0.7024s	
4456/22750 (epoch 9.793), train_loss = 1.31779090, grad/param norm = 2.1086e-01, time/batch = 0.7038s	
4457/22750 (epoch 9.796), train_loss = 1.18974352, grad/param norm = 1.9093e-01, time/batch = 0.7136s	
4458/22750 (epoch 9.798), train_loss = 1.20513462, grad/param norm = 1.6376e-01, time/batch = 0.7143s	
4459/22750 (epoch 9.800), train_loss = 1.20493437, grad/param norm = 1.6976e-01, time/batch = 0.7286s	
4460/22750 (epoch 9.802), train_loss = 1.24791262, grad/param norm = 1.8117e-01, time/batch = 0.7096s	
4461/22750 (epoch 9.804), train_loss = 1.57955846, grad/param norm = 1.9888e-01, time/batch = 0.7041s	
4462/22750 (epoch 9.807), train_loss = 1.40135213, grad/param norm = 1.9525e-01, time/batch = 0.7012s	
4463/22750 (epoch 9.809), train_loss = 1.61802357, grad/param norm = 2.0584e-01, time/batch = 0.7038s	
4464/22750 (epoch 9.811), train_loss = 1.29699395, grad/param norm = 1.7840e-01, time/batch = 0.7186s	
4465/22750 (epoch 9.813), train_loss = 1.38281135, grad/param norm = 1.7166e-01, time/batch = 0.7088s	
4466/22750 (epoch 9.815), train_loss = 1.58631298, grad/param norm = 2.1620e-01, time/batch = 0.7026s	
4467/22750 (epoch 9.818), train_loss = 1.52004022, grad/param norm = 1.9052e-01, time/batch = 0.7030s	
4468/22750 (epoch 9.820), train_loss = 1.62614034, grad/param norm = 1.8722e-01, time/batch = 0.7130s	
4469/22750 (epoch 9.822), train_loss = 1.38779910, grad/param norm = 1.7424e-01, time/batch = 0.7279s	
4470/22750 (epoch 9.824), train_loss = 1.32460946, grad/param norm = 1.7887e-01, time/batch = 0.7028s	
4471/22750 (epoch 9.826), train_loss = 1.40667059, grad/param norm = 1.8604e-01, time/batch = 0.7086s	
4472/22750 (epoch 9.829), train_loss = 1.56628644, grad/param norm = 2.0432e-01, time/batch = 0.7085s	
4473/22750 (epoch 9.831), train_loss = 1.52718908, grad/param norm = 1.9683e-01, time/batch = 0.7012s	
4474/22750 (epoch 9.833), train_loss = 1.44451609, grad/param norm = 2.1494e-01, time/batch = 0.7104s	
4475/22750 (epoch 9.835), train_loss = 1.29746245, grad/param norm = 1.8181e-01, time/batch = 0.7076s	
4476/22750 (epoch 9.837), train_loss = 1.29955425, grad/param norm = 1.9592e-01, time/batch = 0.7030s	
4477/22750 (epoch 9.840), train_loss = 1.28501069, grad/param norm = 1.9162e-01, time/batch = 0.7143s	
4478/22750 (epoch 9.842), train_loss = 1.29659353, grad/param norm = 1.6824e-01, time/batch = 0.7172s	
4479/22750 (epoch 9.844), train_loss = 1.50677486, grad/param norm = 1.9866e-01, time/batch = 0.7072s	
4480/22750 (epoch 9.846), train_loss = 1.35463525, grad/param norm = 1.7580e-01, time/batch = 0.7095s	
4481/22750 (epoch 9.848), train_loss = 1.22462546, grad/param norm = 1.8602e-01, time/batch = 0.7069s	
4482/22750 (epoch 9.851), train_loss = 1.24925459, grad/param norm = 1.7942e-01, time/batch = 0.7036s	
4483/22750 (epoch 9.853), train_loss = 1.37001614, grad/param norm = 1.7806e-01, time/batch = 0.7016s	
4484/22750 (epoch 9.855), train_loss = 1.15987255, grad/param norm = 1.8898e-01, time/batch = 0.7014s	
4485/22750 (epoch 9.857), train_loss = 1.37814513, grad/param norm = 1.8029e-01, time/batch = 0.7089s	
4486/22750 (epoch 9.859), train_loss = 1.39664928, grad/param norm = 1.9093e-01, time/batch = 0.7061s	
4487/22750 (epoch 9.862), train_loss = 1.56096584, grad/param norm = 1.9760e-01, time/batch = 0.7221s	
4488/22750 (epoch 9.864), train_loss = 1.33384317, grad/param norm = 1.8368e-01, time/batch = 0.7238s	
4489/22750 (epoch 9.866), train_loss = 1.38829325, grad/param norm = 1.7976e-01, time/batch = 0.7253s	
4490/22750 (epoch 9.868), train_loss = 1.29456919, grad/param norm = 1.6602e-01, time/batch = 0.7276s	
4491/22750 (epoch 9.870), train_loss = 1.16505845, grad/param norm = 1.8092e-01, time/batch = 0.7055s	
4492/22750 (epoch 9.873), train_loss = 1.31209024, grad/param norm = 1.8565e-01, time/batch = 0.7130s	
4493/22750 (epoch 9.875), train_loss = 1.41605930, grad/param norm = 1.7513e-01, time/batch = 0.7228s	
4494/22750 (epoch 9.877), train_loss = 1.27650880, grad/param norm = 1.7702e-01, time/batch = 0.7079s	
4495/22750 (epoch 9.879), train_loss = 1.48319566, grad/param norm = 2.0233e-01, time/batch = 0.7138s	
4496/22750 (epoch 9.881), train_loss = 1.47016635, grad/param norm = 1.8641e-01, time/batch = 0.7178s	
4497/22750 (epoch 9.884), train_loss = 1.25041919, grad/param norm = 1.8038e-01, time/batch = 0.7124s	
4498/22750 (epoch 9.886), train_loss = 1.43125426, grad/param norm = 1.8552e-01, time/batch = 0.7197s	
4499/22750 (epoch 9.888), train_loss = 1.42778652, grad/param norm = 1.8265e-01, time/batch = 0.7113s	
4500/22750 (epoch 9.890), train_loss = 1.47951234, grad/param norm = 1.8600e-01, time/batch = 0.6986s	
4501/22750 (epoch 9.892), train_loss = 1.80265782, grad/param norm = 2.3528e-01, time/batch = 0.7048s	
4502/22750 (epoch 9.895), train_loss = 1.47433772, grad/param norm = 1.8051e-01, time/batch = 0.7007s	
4503/22750 (epoch 9.897), train_loss = 1.49987545, grad/param norm = 1.8990e-01, time/batch = 0.6997s	
4504/22750 (epoch 9.899), train_loss = 1.41571049, grad/param norm = 1.7056e-01, time/batch = 0.7046s	
4505/22750 (epoch 9.901), train_loss = 1.58180380, grad/param norm = 2.0195e-01, time/batch = 0.7144s	
4506/22750 (epoch 9.903), train_loss = 1.35258799, grad/param norm = 1.9096e-01, time/batch = 0.7315s	
4507/22750 (epoch 9.905), train_loss = 1.45495862, grad/param norm = 1.7814e-01, time/batch = 0.7143s	
4508/22750 (epoch 9.908), train_loss = 1.33278175, grad/param norm = 1.9979e-01, time/batch = 0.7158s	
4509/22750 (epoch 9.910), train_loss = 1.14347809, grad/param norm = 1.9323e-01, time/batch = 0.7079s	
4510/22750 (epoch 9.912), train_loss = 1.26366564, grad/param norm = 1.8020e-01, time/batch = 0.7047s	
4511/22750 (epoch 9.914), train_loss = 1.32875778, grad/param norm = 1.8435e-01, time/batch = 0.7041s	
4512/22750 (epoch 9.916), train_loss = 1.15299299, grad/param norm = 1.6928e-01, time/batch = 0.7037s	
4513/22750 (epoch 9.919), train_loss = 1.25689282, grad/param norm = 1.9406e-01, time/batch = 0.7049s	
4514/22750 (epoch 9.921), train_loss = 0.96493925, grad/param norm = 1.5513e-01, time/batch = 0.7043s	
4515/22750 (epoch 9.923), train_loss = 1.28799738, grad/param norm = 1.8474e-01, time/batch = 0.7262s	
4516/22750 (epoch 9.925), train_loss = 1.29735281, grad/param norm = 1.6800e-01, time/batch = 0.7262s	
4517/22750 (epoch 9.927), train_loss = 1.07933292, grad/param norm = 1.7902e-01, time/batch = 0.7290s	
4518/22750 (epoch 9.930), train_loss = 1.12653791, grad/param norm = 1.7247e-01, time/batch = 0.7260s	
4519/22750 (epoch 9.932), train_loss = 1.42154858, grad/param norm = 1.8870e-01, time/batch = 0.7060s	
4520/22750 (epoch 9.934), train_loss = 1.00623583, grad/param norm = 1.4688e-01, time/batch = 0.7038s	
4521/22750 (epoch 9.936), train_loss = 1.47812025, grad/param norm = 1.9885e-01, time/batch = 0.7039s	
4522/22750 (epoch 9.938), train_loss = 1.39011235, grad/param norm = 1.7750e-01, time/batch = 0.7150s	
4523/22750 (epoch 9.941), train_loss = 1.62324701, grad/param norm = 1.9880e-01, time/batch = 0.7102s	
4524/22750 (epoch 9.943), train_loss = 1.42178937, grad/param norm = 1.8670e-01, time/batch = 0.7004s	
4525/22750 (epoch 9.945), train_loss = 1.35978745, grad/param norm = 1.8132e-01, time/batch = 0.7036s	
4526/22750 (epoch 9.947), train_loss = 1.30090680, grad/param norm = 1.9345e-01, time/batch = 0.6982s	
4527/22750 (epoch 9.949), train_loss = 1.21808051, grad/param norm = 1.8970e-01, time/batch = 0.7037s	
4528/22750 (epoch 9.952), train_loss = 1.26406770, grad/param norm = 1.8211e-01, time/batch = 0.7215s	
4529/22750 (epoch 9.954), train_loss = 1.21907129, grad/param norm = 1.6641e-01, time/batch = 0.7003s	
4530/22750 (epoch 9.956), train_loss = 1.35459950, grad/param norm = 1.7894e-01, time/batch = 0.7150s	
4531/22750 (epoch 9.958), train_loss = 1.29838814, grad/param norm = 1.7572e-01, time/batch = 0.7023s	
4532/22750 (epoch 9.960), train_loss = 1.30669770, grad/param norm = 1.7086e-01, time/batch = 0.7063s	
4533/22750 (epoch 9.963), train_loss = 1.51001809, grad/param norm = 1.9083e-01, time/batch = 0.7035s	
4534/22750 (epoch 9.965), train_loss = 1.45073711, grad/param norm = 1.8677e-01, time/batch = 0.7027s	
4535/22750 (epoch 9.967), train_loss = 1.37498959, grad/param norm = 2.0848e-01, time/batch = 0.7031s	
4536/22750 (epoch 9.969), train_loss = 1.29713883, grad/param norm = 1.8749e-01, time/batch = 0.7251s	
4537/22750 (epoch 9.971), train_loss = 1.27528646, grad/param norm = 1.7305e-01, time/batch = 0.7268s	
4538/22750 (epoch 9.974), train_loss = 1.36686145, grad/param norm = 1.9468e-01, time/batch = 0.7076s	
4539/22750 (epoch 9.976), train_loss = 1.45490044, grad/param norm = 1.9525e-01, time/batch = 0.7074s	
4540/22750 (epoch 9.978), train_loss = 1.20478668, grad/param norm = 1.6862e-01, time/batch = 0.7239s	
4541/22750 (epoch 9.980), train_loss = 1.49834028, grad/param norm = 2.0001e-01, time/batch = 0.7337s	
4542/22750 (epoch 9.982), train_loss = 1.28540191, grad/param norm = 1.7667e-01, time/batch = 0.7468s	
4543/22750 (epoch 9.985), train_loss = 1.59974192, grad/param norm = 2.1191e-01, time/batch = 0.7421s	
4544/22750 (epoch 9.987), train_loss = 1.12809599, grad/param norm = 1.7113e-01, time/batch = 0.7372s	
4545/22750 (epoch 9.989), train_loss = 1.27549076, grad/param norm = 1.8005e-01, time/batch = 0.7383s	
4546/22750 (epoch 9.991), train_loss = 1.42705573, grad/param norm = 1.9385e-01, time/batch = 0.7444s	
4547/22750 (epoch 9.993), train_loss = 1.49024567, grad/param norm = 1.9778e-01, time/batch = 0.7368s	
4548/22750 (epoch 9.996), train_loss = 1.29678370, grad/param norm = 1.9913e-01, time/batch = 0.7524s	
4549/22750 (epoch 9.998), train_loss = 1.52815212, grad/param norm = 1.9836e-01, time/batch = 0.7320s	
decayed learning rate by a factor 0.97 to 0.00194	
4550/22750 (epoch 10.000), train_loss = 1.40328290, grad/param norm = 1.9212e-01, time/batch = 0.7252s	
4551/22750 (epoch 10.002), train_loss = 1.48795332, grad/param norm = 2.0218e-01, time/batch = 0.7336s	
4552/22750 (epoch 10.004), train_loss = 1.27056182, grad/param norm = 1.8446e-01, time/batch = 0.7298s	
4553/22750 (epoch 10.007), train_loss = 1.34433861, grad/param norm = 1.8284e-01, time/batch = 0.7304s	
4554/22750 (epoch 10.009), train_loss = 1.63683014, grad/param norm = 1.9282e-01, time/batch = 0.7203s	
4555/22750 (epoch 10.011), train_loss = 1.60566806, grad/param norm = 1.9002e-01, time/batch = 0.7149s	
4556/22750 (epoch 10.013), train_loss = 1.45954064, grad/param norm = 1.7790e-01, time/batch = 0.7284s	
4557/22750 (epoch 10.015), train_loss = 1.41827770, grad/param norm = 1.8402e-01, time/batch = 0.7247s	
4558/22750 (epoch 10.018), train_loss = 1.45119926, grad/param norm = 1.8897e-01, time/batch = 0.7028s	
4559/22750 (epoch 10.020), train_loss = 1.55931842, grad/param norm = 1.9461e-01, time/batch = 0.7007s	
4560/22750 (epoch 10.022), train_loss = 1.33504503, grad/param norm = 1.7657e-01, time/batch = 0.6977s	
4561/22750 (epoch 10.024), train_loss = 1.36289203, grad/param norm = 1.9664e-01, time/batch = 0.7054s	
4562/22750 (epoch 10.026), train_loss = 1.47227617, grad/param norm = 2.0440e-01, time/batch = 0.7275s	
4563/22750 (epoch 10.029), train_loss = 1.13468943, grad/param norm = 1.7153e-01, time/batch = 0.7222s	
4564/22750 (epoch 10.031), train_loss = 1.66675444, grad/param norm = 2.1394e-01, time/batch = 0.7193s	
4565/22750 (epoch 10.033), train_loss = 1.39235845, grad/param norm = 1.8985e-01, time/batch = 0.7172s	
4566/22750 (epoch 10.035), train_loss = 1.42504881, grad/param norm = 1.8843e-01, time/batch = 0.7169s	
4567/22750 (epoch 10.037), train_loss = 1.48734125, grad/param norm = 1.8694e-01, time/batch = 0.7174s	
4568/22750 (epoch 10.040), train_loss = 1.30251602, grad/param norm = 2.0252e-01, time/batch = 0.7025s	
4569/22750 (epoch 10.042), train_loss = 1.47896143, grad/param norm = 1.9985e-01, time/batch = 0.7013s	
4570/22750 (epoch 10.044), train_loss = 1.29381771, grad/param norm = 1.9416e-01, time/batch = 0.6978s	
4571/22750 (epoch 10.046), train_loss = 1.47583158, grad/param norm = 2.2492e-01, time/batch = 0.7063s	
4572/22750 (epoch 10.048), train_loss = 1.34339836, grad/param norm = 1.8474e-01, time/batch = 0.7197s	
4573/22750 (epoch 10.051), train_loss = 1.38783715, grad/param norm = 1.7606e-01, time/batch = 0.7011s	
4574/22750 (epoch 10.053), train_loss = 1.21056666, grad/param norm = 1.8310e-01, time/batch = 0.6967s	
4575/22750 (epoch 10.055), train_loss = 1.31481092, grad/param norm = 1.7690e-01, time/batch = 0.6962s	
4576/22750 (epoch 10.057), train_loss = 1.51385119, grad/param norm = 1.9335e-01, time/batch = 0.7169s	
4577/22750 (epoch 10.059), train_loss = 1.01717290, grad/param norm = 1.7388e-01, time/batch = 0.7226s	
4578/22750 (epoch 10.062), train_loss = 1.17188576, grad/param norm = 1.6654e-01, time/batch = 0.7211s	
4579/22750 (epoch 10.064), train_loss = 1.38773223, grad/param norm = 1.9044e-01, time/batch = 0.7175s	
4580/22750 (epoch 10.066), train_loss = 1.15727768, grad/param norm = 1.5906e-01, time/batch = 0.7276s	
4581/22750 (epoch 10.068), train_loss = 1.22367457, grad/param norm = 1.5591e-01, time/batch = 0.7177s	
4582/22750 (epoch 10.070), train_loss = 1.11670389, grad/param norm = 1.6915e-01, time/batch = 0.7157s	
4583/22750 (epoch 10.073), train_loss = 1.25955616, grad/param norm = 1.8122e-01, time/batch = 0.7221s	
4584/22750 (epoch 10.075), train_loss = 1.29681562, grad/param norm = 1.7828e-01, time/batch = 0.7098s	
4585/22750 (epoch 10.077), train_loss = 1.03267012, grad/param norm = 1.7244e-01, time/batch = 0.7051s	
4586/22750 (epoch 10.079), train_loss = 1.30147300, grad/param norm = 1.8655e-01, time/batch = 0.7076s	
4587/22750 (epoch 10.081), train_loss = 1.31441364, grad/param norm = 2.0554e-01, time/batch = 0.6998s	
4588/22750 (epoch 10.084), train_loss = 1.25961049, grad/param norm = 1.9101e-01, time/batch = 0.6956s	
4589/22750 (epoch 10.086), train_loss = 1.27209357, grad/param norm = 1.5988e-01, time/batch = 0.7001s	
4590/22750 (epoch 10.088), train_loss = 1.26380093, grad/param norm = 1.8424e-01, time/batch = 0.7075s	
4591/22750 (epoch 10.090), train_loss = 1.28579034, grad/param norm = 1.7069e-01, time/batch = 0.7027s	
4592/22750 (epoch 10.092), train_loss = 1.51461338, grad/param norm = 1.9185e-01, time/batch = 0.6981s	
4593/22750 (epoch 10.095), train_loss = 1.17792382, grad/param norm = 1.7100e-01, time/batch = 0.7027s	
4594/22750 (epoch 10.097), train_loss = 1.28627983, grad/param norm = 1.7935e-01, time/batch = 0.6997s	
4595/22750 (epoch 10.099), train_loss = 1.33677635, grad/param norm = 1.8172e-01, time/batch = 0.7083s	
4596/22750 (epoch 10.101), train_loss = 1.24413880, grad/param norm = 1.8173e-01, time/batch = 0.7007s	
4597/22750 (epoch 10.103), train_loss = 1.31128067, grad/param norm = 1.8693e-01, time/batch = 0.6992s	
4598/22750 (epoch 10.105), train_loss = 1.63404924, grad/param norm = 2.1369e-01, time/batch = 0.7029s	
4599/22750 (epoch 10.108), train_loss = 1.29546152, grad/param norm = 1.7854e-01, time/batch = 0.7008s	
4600/22750 (epoch 10.110), train_loss = 1.42168565, grad/param norm = 1.7754e-01, time/batch = 0.6960s	
4601/22750 (epoch 10.112), train_loss = 1.11637169, grad/param norm = 1.5925e-01, time/batch = 0.7167s	
4602/22750 (epoch 10.114), train_loss = 1.04691684, grad/param norm = 1.7146e-01, time/batch = 0.7185s	
4603/22750 (epoch 10.116), train_loss = 1.18619053, grad/param norm = 1.7060e-01, time/batch = 0.6960s	
4604/22750 (epoch 10.119), train_loss = 1.21443327, grad/param norm = 1.6310e-01, time/batch = 0.6960s	
4605/22750 (epoch 10.121), train_loss = 1.41466629, grad/param norm = 2.0674e-01, time/batch = 0.6986s	
4606/22750 (epoch 10.123), train_loss = 1.21733796, grad/param norm = 1.7153e-01, time/batch = 0.6949s	
4607/22750 (epoch 10.125), train_loss = 1.46585089, grad/param norm = 1.7582e-01, time/batch = 0.7064s	
4608/22750 (epoch 10.127), train_loss = 1.34016221, grad/param norm = 1.8814e-01, time/batch = 0.6978s	
4609/22750 (epoch 10.130), train_loss = 1.39230184, grad/param norm = 1.8076e-01, time/batch = 0.7015s	
4610/22750 (epoch 10.132), train_loss = 1.34984876, grad/param norm = 1.9675e-01, time/batch = 0.7007s	
4611/22750 (epoch 10.134), train_loss = 1.27189531, grad/param norm = 1.7299e-01, time/batch = 0.7049s	
4612/22750 (epoch 10.136), train_loss = 1.15038752, grad/param norm = 1.7451e-01, time/batch = 0.6969s	
4613/22750 (epoch 10.138), train_loss = 1.35315583, grad/param norm = 1.9028e-01, time/batch = 0.6993s	
4614/22750 (epoch 10.141), train_loss = 1.26240809, grad/param norm = 1.7621e-01, time/batch = 0.6986s	
4615/22750 (epoch 10.143), train_loss = 1.14860226, grad/param norm = 1.7378e-01, time/batch = 0.6986s	
4616/22750 (epoch 10.145), train_loss = 1.47502207, grad/param norm = 1.9635e-01, time/batch = 0.6965s	
4617/22750 (epoch 10.147), train_loss = 1.47454303, grad/param norm = 2.0327e-01, time/batch = 0.7073s	
4618/22750 (epoch 10.149), train_loss = 1.32360972, grad/param norm = 1.7862e-01, time/batch = 0.6990s	
4619/22750 (epoch 10.152), train_loss = 1.25476684, grad/param norm = 1.8738e-01, time/batch = 0.7088s	
4620/22750 (epoch 10.154), train_loss = 1.09445399, grad/param norm = 1.7603e-01, time/batch = 0.7267s	
4621/22750 (epoch 10.156), train_loss = 1.14233879, grad/param norm = 1.7135e-01, time/batch = 0.7292s	
4622/22750 (epoch 10.158), train_loss = 1.26739651, grad/param norm = 1.9883e-01, time/batch = 0.7312s	
4623/22750 (epoch 10.160), train_loss = 1.40281561, grad/param norm = 1.9204e-01, time/batch = 0.7109s	
4624/22750 (epoch 10.163), train_loss = 1.58814851, grad/param norm = 2.0160e-01, time/batch = 0.7138s	
4625/22750 (epoch 10.165), train_loss = 1.42466359, grad/param norm = 1.9614e-01, time/batch = 0.7207s	
4626/22750 (epoch 10.167), train_loss = 1.26954367, grad/param norm = 1.8143e-01, time/batch = 0.7208s	
4627/22750 (epoch 10.169), train_loss = 1.35932552, grad/param norm = 2.0127e-01, time/batch = 0.7031s	
4628/22750 (epoch 10.171), train_loss = 1.18692168, grad/param norm = 1.9060e-01, time/batch = 0.7300s	
4629/22750 (epoch 10.174), train_loss = 1.09826811, grad/param norm = 1.7802e-01, time/batch = 0.7015s	
4630/22750 (epoch 10.176), train_loss = 1.31268251, grad/param norm = 1.7957e-01, time/batch = 0.6983s	
4631/22750 (epoch 10.178), train_loss = 1.28491379, grad/param norm = 1.8182e-01, time/batch = 0.7093s	
4632/22750 (epoch 10.180), train_loss = 1.44756868, grad/param norm = 2.2100e-01, time/batch = 0.7000s	
4633/22750 (epoch 10.182), train_loss = 1.46266135, grad/param norm = 1.8396e-01, time/batch = 0.6998s	
4634/22750 (epoch 10.185), train_loss = 1.46321848, grad/param norm = 2.0261e-01, time/batch = 0.6970s	
4635/22750 (epoch 10.187), train_loss = 1.21973017, grad/param norm = 1.8884e-01, time/batch = 0.7034s	
4636/22750 (epoch 10.189), train_loss = 1.24027439, grad/param norm = 1.7696e-01, time/batch = 0.7100s	
4637/22750 (epoch 10.191), train_loss = 1.16799411, grad/param norm = 1.5477e-01, time/batch = 0.7064s	
4638/22750 (epoch 10.193), train_loss = 1.41025891, grad/param norm = 1.9811e-01, time/batch = 0.7020s	
4639/22750 (epoch 10.196), train_loss = 1.31201236, grad/param norm = 1.8617e-01, time/batch = 0.6933s	
4640/22750 (epoch 10.198), train_loss = 1.04014528, grad/param norm = 1.4664e-01, time/batch = 0.7032s	
4641/22750 (epoch 10.200), train_loss = 1.32171783, grad/param norm = 1.8288e-01, time/batch = 0.7072s	
4642/22750 (epoch 10.202), train_loss = 1.47274854, grad/param norm = 2.0258e-01, time/batch = 0.6983s	
4643/22750 (epoch 10.204), train_loss = 1.43126636, grad/param norm = 1.8643e-01, time/batch = 0.7038s	
4644/22750 (epoch 10.207), train_loss = 1.25583471, grad/param norm = 1.7351e-01, time/batch = 0.6967s	
4645/22750 (epoch 10.209), train_loss = 1.17771574, grad/param norm = 1.7571e-01, time/batch = 0.7032s	
4646/22750 (epoch 10.211), train_loss = 1.23714643, grad/param norm = 1.9985e-01, time/batch = 0.7005s	
4647/22750 (epoch 10.213), train_loss = 1.14463710, grad/param norm = 1.8557e-01, time/batch = 0.7019s	
4648/22750 (epoch 10.215), train_loss = 1.11911512, grad/param norm = 1.7990e-01, time/batch = 0.7049s	
4649/22750 (epoch 10.218), train_loss = 1.13368957, grad/param norm = 1.9733e-01, time/batch = 0.7028s	
4650/22750 (epoch 10.220), train_loss = 1.25648974, grad/param norm = 1.9562e-01, time/batch = 0.6996s	
4651/22750 (epoch 10.222), train_loss = 1.14484695, grad/param norm = 1.8880e-01, time/batch = 0.6986s	
4652/22750 (epoch 10.224), train_loss = 1.22785377, grad/param norm = 1.8311e-01, time/batch = 0.7006s	
4653/22750 (epoch 10.226), train_loss = 1.43097124, grad/param norm = 2.0724e-01, time/batch = 0.7019s	
4654/22750 (epoch 10.229), train_loss = 1.37116985, grad/param norm = 1.9515e-01, time/batch = 0.6940s	
4655/22750 (epoch 10.231), train_loss = 1.23371125, grad/param norm = 1.7744e-01, time/batch = 0.6978s	
4656/22750 (epoch 10.233), train_loss = 1.17227924, grad/param norm = 1.8283e-01, time/batch = 0.6960s	
4657/22750 (epoch 10.235), train_loss = 1.17386309, grad/param norm = 1.9715e-01, time/batch = 0.7035s	
4658/22750 (epoch 10.237), train_loss = 1.21565300, grad/param norm = 1.9455e-01, time/batch = 0.6993s	
4659/22750 (epoch 10.240), train_loss = 1.35611075, grad/param norm = 1.6244e-01, time/batch = 0.6977s	
4660/22750 (epoch 10.242), train_loss = 1.68749775, grad/param norm = 2.1100e-01, time/batch = 0.6989s	
4661/22750 (epoch 10.244), train_loss = 1.50702934, grad/param norm = 2.0942e-01, time/batch = 0.6990s	
4662/22750 (epoch 10.246), train_loss = 1.56166449, grad/param norm = 1.9734e-01, time/batch = 0.6986s	
4663/22750 (epoch 10.248), train_loss = 1.28976639, grad/param norm = 1.9010e-01, time/batch = 0.7309s	
4664/22750 (epoch 10.251), train_loss = 1.56198490, grad/param norm = 1.8187e-01, time/batch = 0.7070s	
4665/22750 (epoch 10.253), train_loss = 1.32940420, grad/param norm = 1.8419e-01, time/batch = 0.7237s	
4666/22750 (epoch 10.255), train_loss = 1.34100075, grad/param norm = 1.8247e-01, time/batch = 0.7083s	
4667/22750 (epoch 10.257), train_loss = 1.27220385, grad/param norm = 1.8365e-01, time/batch = 0.7001s	
4668/22750 (epoch 10.259), train_loss = 1.50541735, grad/param norm = 2.1279e-01, time/batch = 0.7037s	
4669/22750 (epoch 10.262), train_loss = 1.29537317, grad/param norm = 1.7677e-01, time/batch = 0.7000s	
4670/22750 (epoch 10.264), train_loss = 1.17756991, grad/param norm = 1.6718e-01, time/batch = 0.7000s	
4671/22750 (epoch 10.266), train_loss = 1.36377377, grad/param norm = 2.2476e-01, time/batch = 0.7008s	
4672/22750 (epoch 10.268), train_loss = 1.48156323, grad/param norm = 1.9639e-01, time/batch = 0.7097s	
4673/22750 (epoch 10.270), train_loss = 1.27946785, grad/param norm = 1.9184e-01, time/batch = 0.7092s	
4674/22750 (epoch 10.273), train_loss = 1.63548429, grad/param norm = 2.1770e-01, time/batch = 0.7232s	
4675/22750 (epoch 10.275), train_loss = 1.39338977, grad/param norm = 1.8547e-01, time/batch = 0.7235s	
4676/22750 (epoch 10.277), train_loss = 1.31358533, grad/param norm = 1.9397e-01, time/batch = 0.7004s	
4677/22750 (epoch 10.279), train_loss = 1.14665310, grad/param norm = 1.6999e-01, time/batch = 0.7028s	
4678/22750 (epoch 10.281), train_loss = 1.41608605, grad/param norm = 1.8021e-01, time/batch = 0.7007s	
4679/22750 (epoch 10.284), train_loss = 1.25209115, grad/param norm = 1.6135e-01, time/batch = 0.7077s	
4680/22750 (epoch 10.286), train_loss = 1.46408489, grad/param norm = 1.8720e-01, time/batch = 0.6981s	
4681/22750 (epoch 10.288), train_loss = 1.52517290, grad/param norm = 1.8318e-01, time/batch = 0.7024s	
4682/22750 (epoch 10.290), train_loss = 1.28552242, grad/param norm = 1.8276e-01, time/batch = 0.7041s	
4683/22750 (epoch 10.292), train_loss = 1.37515568, grad/param norm = 1.9267e-01, time/batch = 0.7065s	
4684/22750 (epoch 10.295), train_loss = 1.34083846, grad/param norm = 1.7275e-01, time/batch = 0.7144s	
4685/22750 (epoch 10.297), train_loss = 1.24966412, grad/param norm = 1.7881e-01, time/batch = 0.7260s	
4686/22750 (epoch 10.299), train_loss = 1.46318332, grad/param norm = 1.8108e-01, time/batch = 0.7028s	
4687/22750 (epoch 10.301), train_loss = 1.37404434, grad/param norm = 1.9344e-01, time/batch = 0.6985s	
4688/22750 (epoch 10.303), train_loss = 1.43063812, grad/param norm = 1.9666e-01, time/batch = 0.7005s	
4689/22750 (epoch 10.305), train_loss = 1.56759907, grad/param norm = 1.9514e-01, time/batch = 0.6990s	
4690/22750 (epoch 10.308), train_loss = 1.39143816, grad/param norm = 1.8496e-01, time/batch = 0.6978s	
4691/22750 (epoch 10.310), train_loss = 1.23403466, grad/param norm = 1.9483e-01, time/batch = 0.6944s	
4692/22750 (epoch 10.312), train_loss = 1.39945544, grad/param norm = 1.9716e-01, time/batch = 0.7001s	
4693/22750 (epoch 10.314), train_loss = 1.33753027, grad/param norm = 1.8242e-01, time/batch = 0.7052s	
4694/22750 (epoch 10.316), train_loss = 1.25933582, grad/param norm = 1.8012e-01, time/batch = 0.7019s	
4695/22750 (epoch 10.319), train_loss = 1.38238270, grad/param norm = 1.9213e-01, time/batch = 0.7002s	
4696/22750 (epoch 10.321), train_loss = 1.29987755, grad/param norm = 1.9972e-01, time/batch = 0.7160s	
4697/22750 (epoch 10.323), train_loss = 1.30168749, grad/param norm = 1.9926e-01, time/batch = 0.7248s	
4698/22750 (epoch 10.325), train_loss = 1.06969188, grad/param norm = 1.7827e-01, time/batch = 0.7128s	
4699/22750 (epoch 10.327), train_loss = 1.35718920, grad/param norm = 1.8754e-01, time/batch = 0.6960s	
4700/22750 (epoch 10.330), train_loss = 1.60257625, grad/param norm = 1.9720e-01, time/batch = 0.7047s	
4701/22750 (epoch 10.332), train_loss = 1.51809683, grad/param norm = 1.9436e-01, time/batch = 0.6978s	
4702/22750 (epoch 10.334), train_loss = 1.09831141, grad/param norm = 1.6992e-01, time/batch = 0.6990s	
4703/22750 (epoch 10.336), train_loss = 1.38138767, grad/param norm = 1.9221e-01, time/batch = 0.6974s	
4704/22750 (epoch 10.338), train_loss = 1.28241772, grad/param norm = 1.8517e-01, time/batch = 0.7128s	
4705/22750 (epoch 10.341), train_loss = 1.28668692, grad/param norm = 1.7237e-01, time/batch = 0.7251s	
4706/22750 (epoch 10.343), train_loss = 1.11813403, grad/param norm = 1.8668e-01, time/batch = 0.7171s	
4707/22750 (epoch 10.345), train_loss = 1.49613510, grad/param norm = 2.0422e-01, time/batch = 0.6987s	
4708/22750 (epoch 10.347), train_loss = 1.47751861, grad/param norm = 2.1495e-01, time/batch = 0.7000s	
4709/22750 (epoch 10.349), train_loss = 1.07548891, grad/param norm = 1.8097e-01, time/batch = 0.7042s	
4710/22750 (epoch 10.352), train_loss = 1.42868262, grad/param norm = 1.9940e-01, time/batch = 0.7047s	
4711/22750 (epoch 10.354), train_loss = 1.50707838, grad/param norm = 2.0505e-01, time/batch = 0.7138s	
4712/22750 (epoch 10.356), train_loss = 1.51710290, grad/param norm = 2.0267e-01, time/batch = 0.7126s	
4713/22750 (epoch 10.358), train_loss = 1.34299711, grad/param norm = 2.1939e-01, time/batch = 0.7013s	
4714/22750 (epoch 10.360), train_loss = 1.55234873, grad/param norm = 2.0594e-01, time/batch = 0.7118s	
4715/22750 (epoch 10.363), train_loss = 1.32404104, grad/param norm = 1.7478e-01, time/batch = 0.7066s	
4716/22750 (epoch 10.365), train_loss = 1.08273153, grad/param norm = 1.8220e-01, time/batch = 0.7005s	
4717/22750 (epoch 10.367), train_loss = 1.16008600, grad/param norm = 1.8576e-01, time/batch = 0.7011s	
4718/22750 (epoch 10.369), train_loss = 1.27309169, grad/param norm = 1.8798e-01, time/batch = 0.6936s	
4719/22750 (epoch 10.371), train_loss = 1.24228121, grad/param norm = 1.8275e-01, time/batch = 0.6943s	
4720/22750 (epoch 10.374), train_loss = 1.18918068, grad/param norm = 1.7697e-01, time/batch = 0.6958s	
4721/22750 (epoch 10.376), train_loss = 1.31617267, grad/param norm = 1.7522e-01, time/batch = 0.6970s	
4722/22750 (epoch 10.378), train_loss = 1.31440460, grad/param norm = 1.8829e-01, time/batch = 0.7055s	
4723/22750 (epoch 10.380), train_loss = 1.49017471, grad/param norm = 1.9688e-01, time/batch = 0.6991s	
4724/22750 (epoch 10.382), train_loss = 1.24465404, grad/param norm = 1.7327e-01, time/batch = 0.6999s	
4725/22750 (epoch 10.385), train_loss = 1.38093987, grad/param norm = 1.7916e-01, time/batch = 0.7019s	
4726/22750 (epoch 10.387), train_loss = 1.36828981, grad/param norm = 1.8427e-01, time/batch = 0.7170s	
4727/22750 (epoch 10.389), train_loss = 1.01867714, grad/param norm = 1.7558e-01, time/batch = 0.7058s	
4728/22750 (epoch 10.391), train_loss = 0.84333742, grad/param norm = 1.4621e-01, time/batch = 0.7006s	
4729/22750 (epoch 10.393), train_loss = 1.15760908, grad/param norm = 1.7222e-01, time/batch = 0.7014s	
4730/22750 (epoch 10.396), train_loss = 1.32776405, grad/param norm = 1.9688e-01, time/batch = 0.7286s	
4731/22750 (epoch 10.398), train_loss = 1.26910830, grad/param norm = 1.7829e-01, time/batch = 0.7191s	
4732/22750 (epoch 10.400), train_loss = 1.28605034, grad/param norm = 1.7074e-01, time/batch = 0.7128s	
4733/22750 (epoch 10.402), train_loss = 1.35960107, grad/param norm = 1.7156e-01, time/batch = 0.6937s	
4734/22750 (epoch 10.404), train_loss = 1.52718622, grad/param norm = 1.8662e-01, time/batch = 0.6954s	
4735/22750 (epoch 10.407), train_loss = 1.44299314, grad/param norm = 1.8003e-01, time/batch = 0.6918s	
4736/22750 (epoch 10.409), train_loss = 1.30518818, grad/param norm = 1.7442e-01, time/batch = 0.6946s	
4737/22750 (epoch 10.411), train_loss = 1.29937511, grad/param norm = 1.7433e-01, time/batch = 0.6952s	
4738/22750 (epoch 10.413), train_loss = 1.10351438, grad/param norm = 1.8557e-01, time/batch = 0.6941s	
4739/22750 (epoch 10.415), train_loss = 1.04503874, grad/param norm = 1.8093e-01, time/batch = 0.7054s	
4740/22750 (epoch 10.418), train_loss = 1.25859119, grad/param norm = 1.8903e-01, time/batch = 0.7239s	
4741/22750 (epoch 10.420), train_loss = 1.51195549, grad/param norm = 2.1564e-01, time/batch = 0.7009s	
4742/22750 (epoch 10.422), train_loss = 1.61736412, grad/param norm = 2.1883e-01, time/batch = 0.6973s	
4743/22750 (epoch 10.424), train_loss = 1.59382734, grad/param norm = 2.1256e-01, time/batch = 0.6938s	
4744/22750 (epoch 10.426), train_loss = 1.56768401, grad/param norm = 2.0339e-01, time/batch = 0.7014s	
4745/22750 (epoch 10.429), train_loss = 1.10000157, grad/param norm = 1.8215e-01, time/batch = 0.6973s	
4746/22750 (epoch 10.431), train_loss = 1.08893003, grad/param norm = 1.7519e-01, time/batch = 0.6925s	
4747/22750 (epoch 10.433), train_loss = 1.21353849, grad/param norm = 1.8426e-01, time/batch = 0.6971s	
4748/22750 (epoch 10.435), train_loss = 1.05623931, grad/param norm = 1.6936e-01, time/batch = 0.6941s	
4749/22750 (epoch 10.437), train_loss = 0.95149149, grad/param norm = 1.5762e-01, time/batch = 0.6973s	
4750/22750 (epoch 10.440), train_loss = 1.39301731, grad/param norm = 1.9143e-01, time/batch = 0.7005s	
4751/22750 (epoch 10.442), train_loss = 1.36397007, grad/param norm = 1.9131e-01, time/batch = 0.7013s	
4752/22750 (epoch 10.444), train_loss = 1.31048309, grad/param norm = 1.8794e-01, time/batch = 0.6964s	
4753/22750 (epoch 10.446), train_loss = 1.32334727, grad/param norm = 2.0893e-01, time/batch = 0.7007s	
4754/22750 (epoch 10.448), train_loss = 1.61414826, grad/param norm = 2.0805e-01, time/batch = 0.7028s	
4755/22750 (epoch 10.451), train_loss = 1.50791737, grad/param norm = 1.9018e-01, time/batch = 0.7026s	
4756/22750 (epoch 10.453), train_loss = 1.57279187, grad/param norm = 1.9961e-01, time/batch = 0.6960s	
4757/22750 (epoch 10.455), train_loss = 1.65299138, grad/param norm = 1.9614e-01, time/batch = 0.6918s	
4758/22750 (epoch 10.457), train_loss = 1.50475527, grad/param norm = 2.2638e-01, time/batch = 0.7014s	
4759/22750 (epoch 10.459), train_loss = 1.42962824, grad/param norm = 1.9729e-01, time/batch = 0.6992s	
4760/22750 (epoch 10.462), train_loss = 1.44260150, grad/param norm = 1.7166e-01, time/batch = 0.6953s	
4761/22750 (epoch 10.464), train_loss = 1.13911280, grad/param norm = 1.7975e-01, time/batch = 0.7026s	
4762/22750 (epoch 10.466), train_loss = 1.57808171, grad/param norm = 2.1879e-01, time/batch = 0.6985s	
4763/22750 (epoch 10.468), train_loss = 1.30068022, grad/param norm = 1.9925e-01, time/batch = 0.7001s	
4764/22750 (epoch 10.470), train_loss = 1.46540459, grad/param norm = 2.0040e-01, time/batch = 0.7014s	
4765/22750 (epoch 10.473), train_loss = 1.32535957, grad/param norm = 1.9614e-01, time/batch = 0.6931s	
4766/22750 (epoch 10.475), train_loss = 1.38466972, grad/param norm = 2.0361e-01, time/batch = 0.6967s	
4767/22750 (epoch 10.477), train_loss = 1.11384015, grad/param norm = 1.6951e-01, time/batch = 0.6986s	
4768/22750 (epoch 10.479), train_loss = 1.14634635, grad/param norm = 1.7373e-01, time/batch = 0.7043s	
4769/22750 (epoch 10.481), train_loss = 1.06064587, grad/param norm = 1.6941e-01, time/batch = 0.7076s	
4770/22750 (epoch 10.484), train_loss = 1.00474669, grad/param norm = 1.8485e-01, time/batch = 0.7177s	
4771/22750 (epoch 10.486), train_loss = 1.18187626, grad/param norm = 1.9162e-01, time/batch = 0.7130s	
4772/22750 (epoch 10.488), train_loss = 1.01894368, grad/param norm = 2.0560e-01, time/batch = 0.6983s	
4773/22750 (epoch 10.490), train_loss = 1.29136031, grad/param norm = 1.8208e-01, time/batch = 0.7036s	
4774/22750 (epoch 10.492), train_loss = 1.46835146, grad/param norm = 1.9848e-01, time/batch = 0.6924s	
4775/22750 (epoch 10.495), train_loss = 1.22467427, grad/param norm = 1.9540e-01, time/batch = 0.7008s	
4776/22750 (epoch 10.497), train_loss = 1.37648118, grad/param norm = 2.1704e-01, time/batch = 0.7003s	
4777/22750 (epoch 10.499), train_loss = 1.22748487, grad/param norm = 1.8810e-01, time/batch = 0.7060s	
4778/22750 (epoch 10.501), train_loss = 1.34435916, grad/param norm = 2.0629e-01, time/batch = 0.7038s	
4779/22750 (epoch 10.503), train_loss = 1.31847699, grad/param norm = 1.8278e-01, time/batch = 0.7122s	
4780/22750 (epoch 10.505), train_loss = 1.15848160, grad/param norm = 1.8754e-01, time/batch = 0.7216s	
4781/22750 (epoch 10.508), train_loss = 1.09374042, grad/param norm = 1.8537e-01, time/batch = 0.7018s	
4782/22750 (epoch 10.510), train_loss = 1.13703206, grad/param norm = 1.7113e-01, time/batch = 0.6989s	
4783/22750 (epoch 10.512), train_loss = 1.18637101, grad/param norm = 1.7211e-01, time/batch = 0.6957s	
4784/22750 (epoch 10.514), train_loss = 1.21022951, grad/param norm = 1.7467e-01, time/batch = 0.6995s	
4785/22750 (epoch 10.516), train_loss = 1.19143297, grad/param norm = 1.8243e-01, time/batch = 0.6989s	
4786/22750 (epoch 10.519), train_loss = 1.40859907, grad/param norm = 1.8394e-01, time/batch = 0.6987s	
4787/22750 (epoch 10.521), train_loss = 1.23392569, grad/param norm = 1.8608e-01, time/batch = 0.7082s	
4788/22750 (epoch 10.523), train_loss = 1.25106059, grad/param norm = 2.0431e-01, time/batch = 0.7051s	
4789/22750 (epoch 10.525), train_loss = 1.53189697, grad/param norm = 2.0791e-01, time/batch = 0.7177s	
4790/22750 (epoch 10.527), train_loss = 1.30959868, grad/param norm = 1.8001e-01, time/batch = 0.7233s	
4791/22750 (epoch 10.530), train_loss = 1.24715557, grad/param norm = 1.9049e-01, time/batch = 0.7091s	
4792/22750 (epoch 10.532), train_loss = 1.15487278, grad/param norm = 1.6698e-01, time/batch = 0.7105s	
4793/22750 (epoch 10.534), train_loss = 1.41665807, grad/param norm = 1.9451e-01, time/batch = 0.7037s	
4794/22750 (epoch 10.536), train_loss = 1.32328706, grad/param norm = 1.8378e-01, time/batch = 0.7003s	
4795/22750 (epoch 10.538), train_loss = 1.32340065, grad/param norm = 1.6656e-01, time/batch = 0.7041s	
4796/22750 (epoch 10.541), train_loss = 1.11704775, grad/param norm = 1.7512e-01, time/batch = 0.7207s	
4797/22750 (epoch 10.543), train_loss = 1.13913707, grad/param norm = 1.7267e-01, time/batch = 0.7024s	
4798/22750 (epoch 10.545), train_loss = 1.46061970, grad/param norm = 1.8525e-01, time/batch = 0.6976s	
4799/22750 (epoch 10.547), train_loss = 1.14210797, grad/param norm = 1.5970e-01, time/batch = 0.7144s	
4800/22750 (epoch 10.549), train_loss = 1.23279769, grad/param norm = 1.8874e-01, time/batch = 0.7156s	
4801/22750 (epoch 10.552), train_loss = 1.38576394, grad/param norm = 1.9578e-01, time/batch = 0.6992s	
4802/22750 (epoch 10.554), train_loss = 1.41322795, grad/param norm = 2.0521e-01, time/batch = 0.6919s	
4803/22750 (epoch 10.556), train_loss = 1.29788539, grad/param norm = 1.9286e-01, time/batch = 0.7025s	
4804/22750 (epoch 10.558), train_loss = 1.45411607, grad/param norm = 1.8781e-01, time/batch = 0.6940s	
4805/22750 (epoch 10.560), train_loss = 1.23552455, grad/param norm = 1.8099e-01, time/batch = 0.6968s	
4806/22750 (epoch 10.563), train_loss = 1.41669035, grad/param norm = 1.7644e-01, time/batch = 0.6961s	
4807/22750 (epoch 10.565), train_loss = 1.41137516, grad/param norm = 1.7844e-01, time/batch = 0.7072s	
4808/22750 (epoch 10.567), train_loss = 1.34058588, grad/param norm = 1.8845e-01, time/batch = 0.6959s	
4809/22750 (epoch 10.569), train_loss = 1.25984846, grad/param norm = 1.7865e-01, time/batch = 0.7201s	
4810/22750 (epoch 10.571), train_loss = 1.34049027, grad/param norm = 1.9709e-01, time/batch = 0.7242s	
4811/22750 (epoch 10.574), train_loss = 1.18673413, grad/param norm = 1.8116e-01, time/batch = 0.7285s	
4812/22750 (epoch 10.576), train_loss = 1.32785897, grad/param norm = 1.8290e-01, time/batch = 0.7255s	
4813/22750 (epoch 10.578), train_loss = 1.14665806, grad/param norm = 1.7529e-01, time/batch = 0.7083s	
4814/22750 (epoch 10.580), train_loss = 1.34257990, grad/param norm = 2.0128e-01, time/batch = 0.6972s	
4815/22750 (epoch 10.582), train_loss = 1.12347130, grad/param norm = 1.6951e-01, time/batch = 0.6975s	
4816/22750 (epoch 10.585), train_loss = 1.03889574, grad/param norm = 1.7771e-01, time/batch = 0.6991s	
4817/22750 (epoch 10.587), train_loss = 1.09642647, grad/param norm = 1.6562e-01, time/batch = 0.6991s	
4818/22750 (epoch 10.589), train_loss = 1.09746831, grad/param norm = 1.9062e-01, time/batch = 0.7166s	
4819/22750 (epoch 10.591), train_loss = 1.28104973, grad/param norm = 1.8490e-01, time/batch = 0.7238s	
4820/22750 (epoch 10.593), train_loss = 1.50461434, grad/param norm = 1.8676e-01, time/batch = 0.7129s	
4821/22750 (epoch 10.596), train_loss = 1.49030339, grad/param norm = 1.9596e-01, time/batch = 0.7054s	
4822/22750 (epoch 10.598), train_loss = 1.51153320, grad/param norm = 1.9470e-01, time/batch = 0.7145s	
4823/22750 (epoch 10.600), train_loss = 1.47239048, grad/param norm = 1.9744e-01, time/batch = 0.7211s	
4824/22750 (epoch 10.602), train_loss = 1.15429253, grad/param norm = 1.6115e-01, time/batch = 0.7017s	
4825/22750 (epoch 10.604), train_loss = 1.24250211, grad/param norm = 1.8117e-01, time/batch = 0.7068s	
4826/22750 (epoch 10.607), train_loss = 1.06573311, grad/param norm = 1.6776e-01, time/batch = 0.7166s	
4827/22750 (epoch 10.609), train_loss = 1.00429626, grad/param norm = 1.5736e-01, time/batch = 0.7051s	
4828/22750 (epoch 10.611), train_loss = 1.22280203, grad/param norm = 1.8956e-01, time/batch = 0.7087s	
4829/22750 (epoch 10.613), train_loss = 1.14849524, grad/param norm = 1.8804e-01, time/batch = 0.7266s	
4830/22750 (epoch 10.615), train_loss = 1.20541210, grad/param norm = 1.7283e-01, time/batch = 0.7090s	
4831/22750 (epoch 10.618), train_loss = 1.24424007, grad/param norm = 1.7694e-01, time/batch = 0.7125s	
4832/22750 (epoch 10.620), train_loss = 1.27046069, grad/param norm = 1.8181e-01, time/batch = 0.7177s	
4833/22750 (epoch 10.622), train_loss = 1.07225971, grad/param norm = 1.6828e-01, time/batch = 0.7012s	
4834/22750 (epoch 10.624), train_loss = 1.24627012, grad/param norm = 1.8586e-01, time/batch = 0.6983s	
4835/22750 (epoch 10.626), train_loss = 1.11309528, grad/param norm = 1.8543e-01, time/batch = 0.7003s	
4836/22750 (epoch 10.629), train_loss = 1.26845938, grad/param norm = 1.9849e-01, time/batch = 0.6975s	
4837/22750 (epoch 10.631), train_loss = 1.29811585, grad/param norm = 1.9324e-01, time/batch = 0.7079s	
4838/22750 (epoch 10.633), train_loss = 1.06283378, grad/param norm = 1.8417e-01, time/batch = 0.7099s	
4839/22750 (epoch 10.635), train_loss = 1.31956294, grad/param norm = 2.1376e-01, time/batch = 0.7078s	
4840/22750 (epoch 10.637), train_loss = 1.38446470, grad/param norm = 2.0096e-01, time/batch = 0.6939s	
4841/22750 (epoch 10.640), train_loss = 1.41766221, grad/param norm = 2.0623e-01, time/batch = 0.6962s	
4842/22750 (epoch 10.642), train_loss = 1.45920093, grad/param norm = 1.9418e-01, time/batch = 0.6981s	
4843/22750 (epoch 10.644), train_loss = 1.30978184, grad/param norm = 1.8581e-01, time/batch = 0.7018s	
4844/22750 (epoch 10.646), train_loss = 1.43668886, grad/param norm = 2.0572e-01, time/batch = 0.6993s	
4845/22750 (epoch 10.648), train_loss = 1.31040262, grad/param norm = 2.0066e-01, time/batch = 0.7017s	
4846/22750 (epoch 10.651), train_loss = 1.42634609, grad/param norm = 2.0396e-01, time/batch = 0.7168s	
4847/22750 (epoch 10.653), train_loss = 1.35866022, grad/param norm = 1.9008e-01, time/batch = 0.7057s	
4848/22750 (epoch 10.655), train_loss = 1.28851745, grad/param norm = 1.8609e-01, time/batch = 0.7006s	
4849/22750 (epoch 10.657), train_loss = 1.49746535, grad/param norm = 1.9487e-01, time/batch = 0.6928s	
4850/22750 (epoch 10.659), train_loss = 1.58438903, grad/param norm = 1.9628e-01, time/batch = 0.7065s	
4851/22750 (epoch 10.662), train_loss = 1.60622926, grad/param norm = 2.2961e-01, time/batch = 0.6957s	
4852/22750 (epoch 10.664), train_loss = 1.37489772, grad/param norm = 2.0078e-01, time/batch = 0.6938s	
4853/22750 (epoch 10.666), train_loss = 1.16761684, grad/param norm = 1.8400e-01, time/batch = 0.6965s	
4854/22750 (epoch 10.668), train_loss = 1.32728108, grad/param norm = 1.8649e-01, time/batch = 0.6931s	
4855/22750 (epoch 10.670), train_loss = 1.33225804, grad/param norm = 1.8560e-01, time/batch = 0.6948s	
4856/22750 (epoch 10.673), train_loss = 1.59901617, grad/param norm = 2.1306e-01, time/batch = 0.6919s	
4857/22750 (epoch 10.675), train_loss = 1.77640233, grad/param norm = 2.1078e-01, time/batch = 0.6947s	
4858/22750 (epoch 10.677), train_loss = 1.52614541, grad/param norm = 2.2272e-01, time/batch = 0.7034s	
4859/22750 (epoch 10.679), train_loss = 1.58252891, grad/param norm = 2.1530e-01, time/batch = 0.7225s	
4860/22750 (epoch 10.681), train_loss = 1.52281287, grad/param norm = 2.0214e-01, time/batch = 0.6932s	
4861/22750 (epoch 10.684), train_loss = 1.48946534, grad/param norm = 1.9679e-01, time/batch = 0.6954s	
4862/22750 (epoch 10.686), train_loss = 1.47666393, grad/param norm = 2.1043e-01, time/batch = 0.6958s	
4863/22750 (epoch 10.688), train_loss = 1.45813320, grad/param norm = 2.0057e-01, time/batch = 0.7036s	
4864/22750 (epoch 10.690), train_loss = 1.43688034, grad/param norm = 1.9836e-01, time/batch = 0.7005s	
4865/22750 (epoch 10.692), train_loss = 1.55180082, grad/param norm = 1.9817e-01, time/batch = 0.6918s	
4866/22750 (epoch 10.695), train_loss = 1.33309473, grad/param norm = 1.8361e-01, time/batch = 0.7120s	
4867/22750 (epoch 10.697), train_loss = 1.32292380, grad/param norm = 2.0769e-01, time/batch = 0.6978s	
4868/22750 (epoch 10.699), train_loss = 1.33386660, grad/param norm = 1.7473e-01, time/batch = 0.6934s	
4869/22750 (epoch 10.701), train_loss = 1.15990183, grad/param norm = 1.7574e-01, time/batch = 0.6945s	
4870/22750 (epoch 10.703), train_loss = 1.36050414, grad/param norm = 1.7657e-01, time/batch = 0.6897s	
4871/22750 (epoch 10.705), train_loss = 1.20387766, grad/param norm = 1.6534e-01, time/batch = 0.6964s	
4872/22750 (epoch 10.708), train_loss = 1.34828597, grad/param norm = 1.7675e-01, time/batch = 0.6936s	
4873/22750 (epoch 10.710), train_loss = 1.12946449, grad/param norm = 1.7690e-01, time/batch = 0.7269s	
4874/22750 (epoch 10.712), train_loss = 1.20989492, grad/param norm = 1.6568e-01, time/batch = 0.7271s	
4875/22750 (epoch 10.714), train_loss = 1.09076601, grad/param norm = 1.7123e-01, time/batch = 0.7511s	
4876/22750 (epoch 10.716), train_loss = 1.18959945, grad/param norm = 1.8410e-01, time/batch = 0.7523s	
4877/22750 (epoch 10.719), train_loss = 1.41821968, grad/param norm = 2.1599e-01, time/batch = 0.7369s	
4878/22750 (epoch 10.721), train_loss = 1.40590739, grad/param norm = 1.9108e-01, time/batch = 0.7312s	
4879/22750 (epoch 10.723), train_loss = 1.32772319, grad/param norm = 1.9346e-01, time/batch = 0.7238s	
4880/22750 (epoch 10.725), train_loss = 1.29582591, grad/param norm = 1.8993e-01, time/batch = 0.7184s	
4881/22750 (epoch 10.727), train_loss = 1.22408189, grad/param norm = 1.6858e-01, time/batch = 0.7246s	
4882/22750 (epoch 10.730), train_loss = 1.26453420, grad/param norm = 1.8510e-01, time/batch = 0.7183s	
4883/22750 (epoch 10.732), train_loss = 1.24712255, grad/param norm = 1.7326e-01, time/batch = 0.7225s	
4884/22750 (epoch 10.734), train_loss = 1.03420426, grad/param norm = 1.7763e-01, time/batch = 0.7302s	
4885/22750 (epoch 10.736), train_loss = 1.20794398, grad/param norm = 1.7396e-01, time/batch = 0.7328s	
4886/22750 (epoch 10.738), train_loss = 1.34122883, grad/param norm = 1.9529e-01, time/batch = 0.7250s	
4887/22750 (epoch 10.741), train_loss = 1.42512690, grad/param norm = 1.9164e-01, time/batch = 0.7216s	
4888/22750 (epoch 10.743), train_loss = 1.34988324, grad/param norm = 1.8758e-01, time/batch = 0.7152s	
4889/22750 (epoch 10.745), train_loss = 1.12995303, grad/param norm = 1.6779e-01, time/batch = 0.7014s	
4890/22750 (epoch 10.747), train_loss = 1.22841527, grad/param norm = 1.7560e-01, time/batch = 0.7118s	
4891/22750 (epoch 10.749), train_loss = 1.53035683, grad/param norm = 2.0758e-01, time/batch = 0.7171s	
4892/22750 (epoch 10.752), train_loss = 1.23787236, grad/param norm = 1.8588e-01, time/batch = 0.7126s	
4893/22750 (epoch 10.754), train_loss = 1.43015880, grad/param norm = 2.2244e-01, time/batch = 0.7212s	
4894/22750 (epoch 10.756), train_loss = 1.15815833, grad/param norm = 2.0645e-01, time/batch = 0.7234s	
4895/22750 (epoch 10.758), train_loss = 1.14334136, grad/param norm = 1.7556e-01, time/batch = 0.7108s	
4896/22750 (epoch 10.760), train_loss = 1.29517998, grad/param norm = 1.7884e-01, time/batch = 0.7233s	
4897/22750 (epoch 10.763), train_loss = 1.37052687, grad/param norm = 1.8750e-01, time/batch = 0.7058s	
4898/22750 (epoch 10.765), train_loss = 1.26664851, grad/param norm = 2.1103e-01, time/batch = 0.7077s	
4899/22750 (epoch 10.767), train_loss = 1.32319615, grad/param norm = 1.8044e-01, time/batch = 0.7152s	
4900/22750 (epoch 10.769), train_loss = 1.52881043, grad/param norm = 1.9354e-01, time/batch = 0.7141s	
4901/22750 (epoch 10.771), train_loss = 1.47340740, grad/param norm = 1.9054e-01, time/batch = 0.7005s	
4902/22750 (epoch 10.774), train_loss = 1.21244252, grad/param norm = 1.9755e-01, time/batch = 0.6969s	
4903/22750 (epoch 10.776), train_loss = 1.31477353, grad/param norm = 1.9451e-01, time/batch = 0.7196s	
4904/22750 (epoch 10.778), train_loss = 1.52343917, grad/param norm = 1.9015e-01, time/batch = 0.7163s	
4905/22750 (epoch 10.780), train_loss = 1.34992027, grad/param norm = 1.8834e-01, time/batch = 0.6943s	
4906/22750 (epoch 10.782), train_loss = 1.47974463, grad/param norm = 1.8598e-01, time/batch = 0.7021s	
4907/22750 (epoch 10.785), train_loss = 1.32063426, grad/param norm = 1.8110e-01, time/batch = 0.7174s	
4908/22750 (epoch 10.787), train_loss = 1.20664512, grad/param norm = 1.8523e-01, time/batch = 0.7196s	
4909/22750 (epoch 10.789), train_loss = 1.26645140, grad/param norm = 1.7949e-01, time/batch = 0.7177s	
4910/22750 (epoch 10.791), train_loss = 1.28074201, grad/param norm = 1.7803e-01, time/batch = 0.7070s	
4911/22750 (epoch 10.793), train_loss = 1.26262870, grad/param norm = 2.0005e-01, time/batch = 0.7197s	
4912/22750 (epoch 10.796), train_loss = 1.12953504, grad/param norm = 1.7715e-01, time/batch = 0.7205s	
4913/22750 (epoch 10.798), train_loss = 1.16405704, grad/param norm = 1.6301e-01, time/batch = 0.6967s	
4914/22750 (epoch 10.800), train_loss = 1.17481134, grad/param norm = 1.6591e-01, time/batch = 0.7208s	
4915/22750 (epoch 10.802), train_loss = 1.19105153, grad/param norm = 1.7386e-01, time/batch = 0.7192s	
4916/22750 (epoch 10.804), train_loss = 1.52269273, grad/param norm = 1.9418e-01, time/batch = 0.7067s	
4917/22750 (epoch 10.807), train_loss = 1.35231327, grad/param norm = 1.8552e-01, time/batch = 0.7104s	
4918/22750 (epoch 10.809), train_loss = 1.57305778, grad/param norm = 2.0659e-01, time/batch = 0.7039s	
4919/22750 (epoch 10.811), train_loss = 1.24126966, grad/param norm = 1.7389e-01, time/batch = 0.7246s	
4920/22750 (epoch 10.813), train_loss = 1.33198718, grad/param norm = 1.7045e-01, time/batch = 0.7038s	
4921/22750 (epoch 10.815), train_loss = 1.53484553, grad/param norm = 2.1243e-01, time/batch = 0.7012s	
4922/22750 (epoch 10.818), train_loss = 1.47297199, grad/param norm = 1.8422e-01, time/batch = 0.7020s	
4923/22750 (epoch 10.820), train_loss = 1.57830464, grad/param norm = 1.8654e-01, time/batch = 0.7024s	
4924/22750 (epoch 10.822), train_loss = 1.33599911, grad/param norm = 1.7601e-01, time/batch = 0.6978s	
4925/22750 (epoch 10.824), train_loss = 1.27321669, grad/param norm = 1.8523e-01, time/batch = 0.7136s	
4926/22750 (epoch 10.826), train_loss = 1.35245896, grad/param norm = 1.8447e-01, time/batch = 0.7256s	
4927/22750 (epoch 10.829), train_loss = 1.51493351, grad/param norm = 1.9582e-01, time/batch = 0.7003s	
4928/22750 (epoch 10.831), train_loss = 1.47394090, grad/param norm = 1.9091e-01, time/batch = 0.7117s	
4929/22750 (epoch 10.833), train_loss = 1.37206060, grad/param norm = 2.0119e-01, time/batch = 0.7054s	
4930/22750 (epoch 10.835), train_loss = 1.26252405, grad/param norm = 1.7944e-01, time/batch = 0.7153s	
4931/22750 (epoch 10.837), train_loss = 1.25832945, grad/param norm = 1.9010e-01, time/batch = 0.7065s	
4932/22750 (epoch 10.840), train_loss = 1.21443175, grad/param norm = 1.7520e-01, time/batch = 0.6973s	
4933/22750 (epoch 10.842), train_loss = 1.25470380, grad/param norm = 1.7220e-01, time/batch = 0.6973s	
4934/22750 (epoch 10.844), train_loss = 1.43748481, grad/param norm = 1.9131e-01, time/batch = 0.6961s	
4935/22750 (epoch 10.846), train_loss = 1.30991116, grad/param norm = 1.7915e-01, time/batch = 0.7090s	
4936/22750 (epoch 10.848), train_loss = 1.18797264, grad/param norm = 1.8265e-01, time/batch = 0.6963s	
4937/22750 (epoch 10.851), train_loss = 1.20972211, grad/param norm = 1.7756e-01, time/batch = 0.6975s	
4938/22750 (epoch 10.853), train_loss = 1.32841121, grad/param norm = 1.7865e-01, time/batch = 0.6915s	
4939/22750 (epoch 10.855), train_loss = 1.11532150, grad/param norm = 1.9308e-01, time/batch = 0.6957s	
4940/22750 (epoch 10.857), train_loss = 1.33363591, grad/param norm = 1.8054e-01, time/batch = 0.6960s	
4941/22750 (epoch 10.859), train_loss = 1.36492713, grad/param norm = 1.9337e-01, time/batch = 0.6974s	
4942/22750 (epoch 10.862), train_loss = 1.51221541, grad/param norm = 1.9877e-01, time/batch = 0.7070s	
4943/22750 (epoch 10.864), train_loss = 1.29082093, grad/param norm = 1.8190e-01, time/batch = 0.7060s	
4944/22750 (epoch 10.866), train_loss = 1.34289019, grad/param norm = 1.7748e-01, time/batch = 0.7037s	
4945/22750 (epoch 10.868), train_loss = 1.24084040, grad/param norm = 1.6746e-01, time/batch = 0.6985s	
4946/22750 (epoch 10.870), train_loss = 1.11981730, grad/param norm = 1.7800e-01, time/batch = 0.7014s	
4947/22750 (epoch 10.873), train_loss = 1.25729495, grad/param norm = 1.8419e-01, time/batch = 0.7069s	
4948/22750 (epoch 10.875), train_loss = 1.37647053, grad/param norm = 1.7913e-01, time/batch = 0.7026s	
4949/22750 (epoch 10.877), train_loss = 1.23587110, grad/param norm = 1.7375e-01, time/batch = 0.6943s	
4950/22750 (epoch 10.879), train_loss = 1.43364006, grad/param norm = 2.0188e-01, time/batch = 0.6994s	
4951/22750 (epoch 10.881), train_loss = 1.42327467, grad/param norm = 1.8718e-01, time/batch = 0.7013s	
4952/22750 (epoch 10.884), train_loss = 1.19559688, grad/param norm = 1.7924e-01, time/batch = 0.7102s	
4953/22750 (epoch 10.886), train_loss = 1.38668762, grad/param norm = 1.8865e-01, time/batch = 0.7229s	
4954/22750 (epoch 10.888), train_loss = 1.38746604, grad/param norm = 1.8674e-01, time/batch = 0.6944s	
4955/22750 (epoch 10.890), train_loss = 1.43825930, grad/param norm = 1.8894e-01, time/batch = 0.6954s	
4956/22750 (epoch 10.892), train_loss = 1.74373253, grad/param norm = 2.3363e-01, time/batch = 0.6994s	
4957/22750 (epoch 10.895), train_loss = 1.42194162, grad/param norm = 1.7595e-01, time/batch = 0.6973s	
4958/22750 (epoch 10.897), train_loss = 1.44777987, grad/param norm = 1.8968e-01, time/batch = 0.7204s	
4959/22750 (epoch 10.899), train_loss = 1.35431986, grad/param norm = 1.6692e-01, time/batch = 0.7260s	
4960/22750 (epoch 10.901), train_loss = 1.53323190, grad/param norm = 2.0320e-01, time/batch = 0.7142s	
4961/22750 (epoch 10.903), train_loss = 1.30462757, grad/param norm = 1.9332e-01, time/batch = 0.7044s	
4962/22750 (epoch 10.905), train_loss = 1.41122819, grad/param norm = 1.8360e-01, time/batch = 0.7102s	
4963/22750 (epoch 10.908), train_loss = 1.28419544, grad/param norm = 2.0528e-01, time/batch = 0.7149s	
4964/22750 (epoch 10.910), train_loss = 1.09842418, grad/param norm = 1.9359e-01, time/batch = 0.7026s	
4965/22750 (epoch 10.912), train_loss = 1.22823392, grad/param norm = 1.8517e-01, time/batch = 0.7073s	
4966/22750 (epoch 10.914), train_loss = 1.29745546, grad/param norm = 1.8786e-01, time/batch = 0.7094s	
4967/22750 (epoch 10.916), train_loss = 1.11529626, grad/param norm = 1.6877e-01, time/batch = 0.6990s	
4968/22750 (epoch 10.919), train_loss = 1.21616195, grad/param norm = 1.9236e-01, time/batch = 0.6947s	
4969/22750 (epoch 10.921), train_loss = 0.92281360, grad/param norm = 1.4794e-01, time/batch = 0.7192s	
4970/22750 (epoch 10.923), train_loss = 1.23012852, grad/param norm = 1.7361e-01, time/batch = 0.7117s	
4971/22750 (epoch 10.925), train_loss = 1.25668510, grad/param norm = 1.6763e-01, time/batch = 0.7075s	
4972/22750 (epoch 10.927), train_loss = 1.03645072, grad/param norm = 1.7509e-01, time/batch = 0.7032s	
4973/22750 (epoch 10.930), train_loss = 1.08749022, grad/param norm = 1.7781e-01, time/batch = 0.7226s	
4974/22750 (epoch 10.932), train_loss = 1.37033858, grad/param norm = 1.8923e-01, time/batch = 0.7273s	
4975/22750 (epoch 10.934), train_loss = 0.97256697, grad/param norm = 1.4459e-01, time/batch = 0.7281s	
4976/22750 (epoch 10.936), train_loss = 1.42202060, grad/param norm = 1.9775e-01, time/batch = 0.7117s	
4977/22750 (epoch 10.938), train_loss = 1.34041587, grad/param norm = 1.6874e-01, time/batch = 0.7159s	
4978/22750 (epoch 10.941), train_loss = 1.57093544, grad/param norm = 1.9980e-01, time/batch = 0.7259s	
4979/22750 (epoch 10.943), train_loss = 1.36759795, grad/param norm = 1.8527e-01, time/batch = 0.7058s	
4980/22750 (epoch 10.945), train_loss = 1.31248635, grad/param norm = 1.8594e-01, time/batch = 0.7279s	
4981/22750 (epoch 10.947), train_loss = 1.25107982, grad/param norm = 1.8959e-01, time/batch = 0.7282s	
4982/22750 (epoch 10.949), train_loss = 1.17047948, grad/param norm = 1.8378e-01, time/batch = 0.7279s	
4983/22750 (epoch 10.952), train_loss = 1.21317579, grad/param norm = 1.7314e-01, time/batch = 0.7092s	
4984/22750 (epoch 10.954), train_loss = 1.16195703, grad/param norm = 1.6663e-01, time/batch = 0.7059s	
4985/22750 (epoch 10.956), train_loss = 1.30732471, grad/param norm = 1.7796e-01, time/batch = 0.6952s	
4986/22750 (epoch 10.958), train_loss = 1.24241027, grad/param norm = 1.7040e-01, time/batch = 0.7018s	
4987/22750 (epoch 10.960), train_loss = 1.25279079, grad/param norm = 1.7336e-01, time/batch = 0.6966s	
4988/22750 (epoch 10.963), train_loss = 1.45685380, grad/param norm = 1.8803e-01, time/batch = 0.6994s	
4989/22750 (epoch 10.965), train_loss = 1.40613969, grad/param norm = 1.8725e-01, time/batch = 0.7022s	
4990/22750 (epoch 10.967), train_loss = 1.31671536, grad/param norm = 2.0485e-01, time/batch = 0.6977s	
4991/22750 (epoch 10.969), train_loss = 1.24716446, grad/param norm = 1.8458e-01, time/batch = 0.7019s	
4992/22750 (epoch 10.971), train_loss = 1.23416752, grad/param norm = 1.7417e-01, time/batch = 0.7266s	
4993/22750 (epoch 10.974), train_loss = 1.32727602, grad/param norm = 1.9866e-01, time/batch = 0.7269s	
4994/22750 (epoch 10.976), train_loss = 1.40761163, grad/param norm = 1.9884e-01, time/batch = 0.7243s	
4995/22750 (epoch 10.978), train_loss = 1.15686088, grad/param norm = 1.6324e-01, time/batch = 0.7277s	
4996/22750 (epoch 10.980), train_loss = 1.45562015, grad/param norm = 2.0695e-01, time/batch = 0.7177s	
4997/22750 (epoch 10.982), train_loss = 1.23640602, grad/param norm = 1.7410e-01, time/batch = 0.7225s	
4998/22750 (epoch 10.985), train_loss = 1.54356775, grad/param norm = 2.0813e-01, time/batch = 0.7202s	
4999/22750 (epoch 10.987), train_loss = 1.07698151, grad/param norm = 1.6753e-01, time/batch = 0.7086s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_wakata_epoch10.99_1.4722.t7	
5000/22750 (epoch 10.989), train_loss = 1.24044952, grad/param norm = 1.8207e-01, time/batch = 0.7020s	
5001/22750 (epoch 10.991), train_loss = 1.71609871, grad/param norm = 2.1639e-01, time/batch = 0.7451s	
5002/22750 (epoch 10.993), train_loss = 1.44254242, grad/param norm = 1.9101e-01, time/batch = 0.7225s	
5003/22750 (epoch 10.996), train_loss = 1.24655604, grad/param norm = 2.0362e-01, time/batch = 0.7421s	
5004/22750 (epoch 10.998), train_loss = 1.48583625, grad/param norm = 1.9318e-01, time/batch = 0.7224s	
decayed learning rate by a factor 0.97 to 0.0018818	
5005/22750 (epoch 11.000), train_loss = 1.36026163, grad/param norm = 1.9491e-01, time/batch = 0.7137s	
5006/22750 (epoch 11.002), train_loss = 1.42588857, grad/param norm = 1.9692e-01, time/batch = 0.7304s	
5007/22750 (epoch 11.004), train_loss = 1.21675647, grad/param norm = 1.7444e-01, time/batch = 0.7125s	
5008/22750 (epoch 11.007), train_loss = 1.29301841, grad/param norm = 1.9510e-01, time/batch = 0.7014s	
5009/22750 (epoch 11.009), train_loss = 1.58155940, grad/param norm = 1.9380e-01, time/batch = 0.7278s	
5010/22750 (epoch 11.011), train_loss = 1.56340579, grad/param norm = 1.8909e-01, time/batch = 0.7344s	
5011/22750 (epoch 11.013), train_loss = 1.40994882, grad/param norm = 1.7743e-01, time/batch = 0.7048s	
5012/22750 (epoch 11.015), train_loss = 1.37360051, grad/param norm = 1.8659e-01, time/batch = 0.6941s	
5013/22750 (epoch 11.018), train_loss = 1.38922769, grad/param norm = 1.8419e-01, time/batch = 0.7064s	
5014/22750 (epoch 11.020), train_loss = 1.51882609, grad/param norm = 1.9083e-01, time/batch = 0.6994s	
5015/22750 (epoch 11.022), train_loss = 1.28341553, grad/param norm = 1.7579e-01, time/batch = 0.7022s	
5016/22750 (epoch 11.024), train_loss = 1.32314616, grad/param norm = 2.0068e-01, time/batch = 0.7232s	
5017/22750 (epoch 11.026), train_loss = 1.41747437, grad/param norm = 2.0019e-01, time/batch = 0.6998s	
5018/22750 (epoch 11.029), train_loss = 1.09804274, grad/param norm = 1.7005e-01, time/batch = 0.7010s	
5019/22750 (epoch 11.031), train_loss = 1.61476115, grad/param norm = 2.0844e-01, time/batch = 0.7034s	
5020/22750 (epoch 11.033), train_loss = 1.34466220, grad/param norm = 1.8837e-01, time/batch = 0.7030s	
5021/22750 (epoch 11.035), train_loss = 1.37354742, grad/param norm = 1.9419e-01, time/batch = 0.7030s	
5022/22750 (epoch 11.037), train_loss = 1.44631115, grad/param norm = 1.9394e-01, time/batch = 0.6973s	
5023/22750 (epoch 11.040), train_loss = 1.26020355, grad/param norm = 1.9098e-01, time/batch = 0.7034s	
5024/22750 (epoch 11.042), train_loss = 1.42729560, grad/param norm = 1.9026e-01, time/batch = 0.7025s	
5025/22750 (epoch 11.044), train_loss = 1.25566043, grad/param norm = 1.8924e-01, time/batch = 0.7082s	
5026/22750 (epoch 11.046), train_loss = 1.42247784, grad/param norm = 2.2260e-01, time/batch = 0.7234s	
5027/22750 (epoch 11.048), train_loss = 1.29924139, grad/param norm = 1.8326e-01, time/batch = 0.7119s	
5028/22750 (epoch 11.051), train_loss = 1.34784432, grad/param norm = 1.7671e-01, time/batch = 0.7284s	
5029/22750 (epoch 11.053), train_loss = 1.16920150, grad/param norm = 1.7807e-01, time/batch = 0.7176s	
5030/22750 (epoch 11.055), train_loss = 1.25621432, grad/param norm = 1.7349e-01, time/batch = 0.7274s	
5031/22750 (epoch 11.057), train_loss = 1.47243091, grad/param norm = 1.9447e-01, time/batch = 0.7025s	
5032/22750 (epoch 11.059), train_loss = 0.97081996, grad/param norm = 1.7801e-01, time/batch = 0.6936s	
5033/22750 (epoch 11.062), train_loss = 1.13819070, grad/param norm = 1.7288e-01, time/batch = 0.6961s	
5034/22750 (epoch 11.064), train_loss = 1.34747394, grad/param norm = 1.9134e-01, time/batch = 0.7072s	
5035/22750 (epoch 11.066), train_loss = 1.12016242, grad/param norm = 1.6220e-01, time/batch = 0.7279s	
5036/22750 (epoch 11.068), train_loss = 1.18707730, grad/param norm = 1.5710e-01, time/batch = 0.7256s	
5037/22750 (epoch 11.070), train_loss = 1.07211229, grad/param norm = 1.7631e-01, time/batch = 0.7534s	
5038/22750 (epoch 11.073), train_loss = 1.22411027, grad/param norm = 1.9020e-01, time/batch = 0.7517s	
5039/22750 (epoch 11.075), train_loss = 1.25247887, grad/param norm = 1.8045e-01, time/batch = 0.7286s	
5040/22750 (epoch 11.077), train_loss = 1.00365597, grad/param norm = 1.7729e-01, time/batch = 0.7241s	
5041/22750 (epoch 11.079), train_loss = 1.25393398, grad/param norm = 1.9129e-01, time/batch = 0.7243s	
5042/22750 (epoch 11.081), train_loss = 1.26438863, grad/param norm = 1.9965e-01, time/batch = 0.7049s	
5043/22750 (epoch 11.084), train_loss = 1.21847244, grad/param norm = 1.9006e-01, time/batch = 0.7197s	
5044/22750 (epoch 11.086), train_loss = 1.22730331, grad/param norm = 1.5832e-01, time/batch = 0.7378s	
5045/22750 (epoch 11.088), train_loss = 1.21488591, grad/param norm = 1.7943e-01, time/batch = 0.7442s	
5046/22750 (epoch 11.090), train_loss = 1.22788177, grad/param norm = 1.7493e-01, time/batch = 0.7320s	
5047/22750 (epoch 11.092), train_loss = 1.46676325, grad/param norm = 1.9245e-01, time/batch = 0.7132s	
5048/22750 (epoch 11.095), train_loss = 1.13901897, grad/param norm = 1.7698e-01, time/batch = 0.7134s	
5049/22750 (epoch 11.097), train_loss = 1.24431046, grad/param norm = 1.7833e-01, time/batch = 0.7072s	
5050/22750 (epoch 11.099), train_loss = 1.29062544, grad/param norm = 1.7714e-01, time/batch = 0.6930s	
5051/22750 (epoch 11.101), train_loss = 1.19640218, grad/param norm = 1.7983e-01, time/batch = 0.7263s	
5052/22750 (epoch 11.103), train_loss = 1.26097314, grad/param norm = 1.8437e-01, time/batch = 0.7290s	
5053/22750 (epoch 11.105), train_loss = 1.57846110, grad/param norm = 2.1437e-01, time/batch = 0.7227s	
5054/22750 (epoch 11.108), train_loss = 1.25418147, grad/param norm = 1.8119e-01, time/batch = 0.7212s	
5055/22750 (epoch 11.110), train_loss = 1.39081793, grad/param norm = 1.8485e-01, time/batch = 0.7196s	
5056/22750 (epoch 11.112), train_loss = 1.07887759, grad/param norm = 1.6003e-01, time/batch = 0.7166s	
5057/22750 (epoch 11.114), train_loss = 1.00878619, grad/param norm = 1.6838e-01, time/batch = 0.7143s	
5058/22750 (epoch 11.116), train_loss = 1.14658144, grad/param norm = 1.6682e-01, time/batch = 0.7143s	
5059/22750 (epoch 11.119), train_loss = 1.16571867, grad/param norm = 1.5998e-01, time/batch = 0.6990s	
5060/22750 (epoch 11.121), train_loss = 1.35020674, grad/param norm = 2.0182e-01, time/batch = 0.7162s	
5061/22750 (epoch 11.123), train_loss = 1.16805768, grad/param norm = 1.7393e-01, time/batch = 0.7265s	
5062/22750 (epoch 11.125), train_loss = 1.41501807, grad/param norm = 1.7552e-01, time/batch = 0.7213s	
5063/22750 (epoch 11.127), train_loss = 1.28459069, grad/param norm = 1.9173e-01, time/batch = 0.7204s	
5064/22750 (epoch 11.130), train_loss = 1.34973065, grad/param norm = 1.8455e-01, time/batch = 0.7137s	
5065/22750 (epoch 11.132), train_loss = 1.28771068, grad/param norm = 1.8765e-01, time/batch = 0.7184s	
5066/22750 (epoch 11.134), train_loss = 1.22506458, grad/param norm = 1.7151e-01, time/batch = 0.7157s	
5067/22750 (epoch 11.136), train_loss = 1.10720340, grad/param norm = 1.7378e-01, time/batch = 0.7187s	
5068/22750 (epoch 11.138), train_loss = 1.31513541, grad/param norm = 1.9134e-01, time/batch = 0.7108s	
5069/22750 (epoch 11.141), train_loss = 1.23306151, grad/param norm = 1.7509e-01, time/batch = 0.7103s	
5070/22750 (epoch 11.143), train_loss = 1.10569777, grad/param norm = 1.7050e-01, time/batch = 0.7171s	
5071/22750 (epoch 11.145), train_loss = 1.43766263, grad/param norm = 1.9367e-01, time/batch = 0.7150s	
5072/22750 (epoch 11.147), train_loss = 1.42217866, grad/param norm = 1.9975e-01, time/batch = 0.7159s	
5073/22750 (epoch 11.149), train_loss = 1.27188875, grad/param norm = 1.7954e-01, time/batch = 0.7166s	
5074/22750 (epoch 11.152), train_loss = 1.21891408, grad/param norm = 1.8617e-01, time/batch = 0.7132s	
5075/22750 (epoch 11.154), train_loss = 1.05687959, grad/param norm = 1.7825e-01, time/batch = 0.6984s	
5076/22750 (epoch 11.156), train_loss = 1.10353103, grad/param norm = 1.7455e-01, time/batch = 0.6937s	
5077/22750 (epoch 11.158), train_loss = 1.21864320, grad/param norm = 1.9661e-01, time/batch = 0.6910s	
5078/22750 (epoch 11.160), train_loss = 1.36214192, grad/param norm = 1.8717e-01, time/batch = 0.6902s	
5079/22750 (epoch 11.163), train_loss = 1.53927228, grad/param norm = 1.9314e-01, time/batch = 0.6956s	
5080/22750 (epoch 11.165), train_loss = 1.37291156, grad/param norm = 1.8690e-01, time/batch = 0.6984s	
5081/22750 (epoch 11.167), train_loss = 1.23557496, grad/param norm = 1.8552e-01, time/batch = 0.7027s	
5082/22750 (epoch 11.169), train_loss = 1.30457439, grad/param norm = 1.9361e-01, time/batch = 0.7137s	
5083/22750 (epoch 11.171), train_loss = 1.14005154, grad/param norm = 1.7776e-01, time/batch = 0.7174s	
5084/22750 (epoch 11.174), train_loss = 1.06588877, grad/param norm = 1.8128e-01, time/batch = 0.7206s	
5085/22750 (epoch 11.176), train_loss = 1.25665096, grad/param norm = 1.7542e-01, time/batch = 0.7181s	
5086/22750 (epoch 11.178), train_loss = 1.24803193, grad/param norm = 1.8432e-01, time/batch = 0.7142s	
5087/22750 (epoch 11.180), train_loss = 1.39822897, grad/param norm = 2.1517e-01, time/batch = 0.6957s	
5088/22750 (epoch 11.182), train_loss = 1.41386439, grad/param norm = 1.8101e-01, time/batch = 0.7199s	
5089/22750 (epoch 11.185), train_loss = 1.43241802, grad/param norm = 2.0904e-01, time/batch = 0.7099s	
5090/22750 (epoch 11.187), train_loss = 1.17646166, grad/param norm = 1.8414e-01, time/batch = 0.7020s	
5091/22750 (epoch 11.189), train_loss = 1.20092237, grad/param norm = 1.7672e-01, time/batch = 0.6962s	
5092/22750 (epoch 11.191), train_loss = 1.12919589, grad/param norm = 1.5770e-01, time/batch = 0.6938s	
5093/22750 (epoch 11.193), train_loss = 1.37005726, grad/param norm = 2.0050e-01, time/batch = 0.7011s	
5094/22750 (epoch 11.196), train_loss = 1.26503737, grad/param norm = 1.8119e-01, time/batch = 0.7130s	
5095/22750 (epoch 11.198), train_loss = 0.99514476, grad/param norm = 1.4464e-01, time/batch = 0.7018s	
5096/22750 (epoch 11.200), train_loss = 1.27247015, grad/param norm = 1.8254e-01, time/batch = 0.6938s	
5097/22750 (epoch 11.202), train_loss = 1.41866392, grad/param norm = 2.0284e-01, time/batch = 0.6913s	
5098/22750 (epoch 11.204), train_loss = 1.36774428, grad/param norm = 1.7772e-01, time/batch = 0.6956s	
5099/22750 (epoch 11.207), train_loss = 1.21747667, grad/param norm = 1.7501e-01, time/batch = 0.6977s	
5100/22750 (epoch 11.209), train_loss = 1.14151385, grad/param norm = 1.7891e-01, time/batch = 0.6940s	
5101/22750 (epoch 11.211), train_loss = 1.19342366, grad/param norm = 1.9968e-01, time/batch = 0.6980s	
5102/22750 (epoch 11.213), train_loss = 1.09457755, grad/param norm = 1.8464e-01, time/batch = 0.6928s	
5103/22750 (epoch 11.215), train_loss = 1.05801093, grad/param norm = 1.7696e-01, time/batch = 0.6963s	
5104/22750 (epoch 11.218), train_loss = 1.09317719, grad/param norm = 1.9336e-01, time/batch = 0.7172s	
5105/22750 (epoch 11.220), train_loss = 1.19221707, grad/param norm = 1.9366e-01, time/batch = 0.7010s	
5106/22750 (epoch 11.222), train_loss = 1.09303186, grad/param norm = 1.8885e-01, time/batch = 0.6940s	
5107/22750 (epoch 11.224), train_loss = 1.18917325, grad/param norm = 1.8603e-01, time/batch = 0.6965s	
5108/22750 (epoch 11.226), train_loss = 1.38728492, grad/param norm = 2.0169e-01, time/batch = 0.6935s	
5109/22750 (epoch 11.229), train_loss = 1.32868771, grad/param norm = 1.9188e-01, time/batch = 0.7098s	
5110/22750 (epoch 11.231), train_loss = 1.18583022, grad/param norm = 1.7444e-01, time/batch = 0.7084s	
5111/22750 (epoch 11.233), train_loss = 1.12358228, grad/param norm = 1.7348e-01, time/batch = 0.7230s	
5112/22750 (epoch 11.235), train_loss = 1.10884570, grad/param norm = 1.8546e-01, time/batch = 0.7203s	
5113/22750 (epoch 11.237), train_loss = 1.17990119, grad/param norm = 1.9013e-01, time/batch = 0.7266s	
5114/22750 (epoch 11.240), train_loss = 1.29649034, grad/param norm = 1.5952e-01, time/batch = 0.7259s	
5115/22750 (epoch 11.242), train_loss = 1.62809385, grad/param norm = 2.1850e-01, time/batch = 0.7250s	
5116/22750 (epoch 11.244), train_loss = 1.44786532, grad/param norm = 2.0430e-01, time/batch = 0.7126s	
5117/22750 (epoch 11.246), train_loss = 1.50837223, grad/param norm = 1.9544e-01, time/batch = 0.7000s	
5118/22750 (epoch 11.248), train_loss = 1.24343729, grad/param norm = 1.8973e-01, time/batch = 0.7239s	
5119/22750 (epoch 11.251), train_loss = 1.52213929, grad/param norm = 1.8856e-01, time/batch = 0.7272s	
5120/22750 (epoch 11.253), train_loss = 1.28707422, grad/param norm = 1.8349e-01, time/batch = 0.7235s	
5121/22750 (epoch 11.255), train_loss = 1.29299350, grad/param norm = 1.8259e-01, time/batch = 0.7241s	
5122/22750 (epoch 11.257), train_loss = 1.22912724, grad/param norm = 1.8612e-01, time/batch = 0.7220s	
5123/22750 (epoch 11.259), train_loss = 1.46342013, grad/param norm = 2.0623e-01, time/batch = 0.7213s	
5124/22750 (epoch 11.262), train_loss = 1.24897422, grad/param norm = 1.7335e-01, time/batch = 0.7237s	
5125/22750 (epoch 11.264), train_loss = 1.12643324, grad/param norm = 1.6748e-01, time/batch = 0.7245s	
5126/22750 (epoch 11.266), train_loss = 1.32781585, grad/param norm = 2.2981e-01, time/batch = 0.7253s	
5127/22750 (epoch 11.268), train_loss = 1.43307218, grad/param norm = 1.9260e-01, time/batch = 0.7185s	
5128/22750 (epoch 11.270), train_loss = 1.22585699, grad/param norm = 1.8913e-01, time/batch = 0.7222s	
5129/22750 (epoch 11.273), train_loss = 1.59540883, grad/param norm = 2.0863e-01, time/batch = 0.7026s	
5130/22750 (epoch 11.275), train_loss = 1.35715938, grad/param norm = 1.8847e-01, time/batch = 0.7249s	
5131/22750 (epoch 11.277), train_loss = 1.25942041, grad/param norm = 1.8622e-01, time/batch = 0.7033s	
5132/22750 (epoch 11.279), train_loss = 1.10195222, grad/param norm = 1.6951e-01, time/batch = 0.7027s	
5133/22750 (epoch 11.281), train_loss = 1.38657377, grad/param norm = 1.7957e-01, time/batch = 0.7226s	
5134/22750 (epoch 11.284), train_loss = 1.21198868, grad/param norm = 1.6195e-01, time/batch = 0.7122s	
5135/22750 (epoch 11.286), train_loss = 1.42066501, grad/param norm = 1.9159e-01, time/batch = 0.7120s	
5136/22750 (epoch 11.288), train_loss = 1.48724629, grad/param norm = 1.8513e-01, time/batch = 0.7107s	
5137/22750 (epoch 11.290), train_loss = 1.24717053, grad/param norm = 1.7803e-01, time/batch = 0.7001s	
5138/22750 (epoch 11.292), train_loss = 1.33714352, grad/param norm = 2.0191e-01, time/batch = 0.6994s	
5139/22750 (epoch 11.295), train_loss = 1.30573844, grad/param norm = 1.6552e-01, time/batch = 0.7101s	
5140/22750 (epoch 11.297), train_loss = 1.20163009, grad/param norm = 1.7174e-01, time/batch = 0.7128s	
5141/22750 (epoch 11.299), train_loss = 1.41931444, grad/param norm = 1.8317e-01, time/batch = 0.7028s	
5142/22750 (epoch 11.301), train_loss = 1.32609779, grad/param norm = 1.8960e-01, time/batch = 0.6982s	
5143/22750 (epoch 11.303), train_loss = 1.38271022, grad/param norm = 1.9261e-01, time/batch = 0.7201s	
5144/22750 (epoch 11.305), train_loss = 1.52531702, grad/param norm = 1.9305e-01, time/batch = 0.7064s	
5145/22750 (epoch 11.308), train_loss = 1.35384149, grad/param norm = 1.9136e-01, time/batch = 0.6979s	
5146/22750 (epoch 11.310), train_loss = 1.18198548, grad/param norm = 1.8752e-01, time/batch = 0.7083s	
5147/22750 (epoch 11.312), train_loss = 1.36082758, grad/param norm = 2.0007e-01, time/batch = 0.7063s	
5148/22750 (epoch 11.314), train_loss = 1.29676511, grad/param norm = 1.7997e-01, time/batch = 0.7068s	
5149/22750 (epoch 11.316), train_loss = 1.22479884, grad/param norm = 1.8223e-01, time/batch = 0.7005s	
5150/22750 (epoch 11.319), train_loss = 1.33977985, grad/param norm = 2.0151e-01, time/batch = 0.6943s	
5151/22750 (epoch 11.321), train_loss = 1.25343456, grad/param norm = 1.9449e-01, time/batch = 0.6992s	
5152/22750 (epoch 11.323), train_loss = 1.24849390, grad/param norm = 1.9259e-01, time/batch = 0.7069s	
5153/22750 (epoch 11.325), train_loss = 1.04033190, grad/param norm = 1.7858e-01, time/batch = 0.7184s	
5154/22750 (epoch 11.327), train_loss = 1.30975004, grad/param norm = 1.8908e-01, time/batch = 0.7062s	
5155/22750 (epoch 11.330), train_loss = 1.55761833, grad/param norm = 1.9968e-01, time/batch = 0.7000s	
5156/22750 (epoch 11.332), train_loss = 1.48037569, grad/param norm = 1.9345e-01, time/batch = 0.7006s	
5157/22750 (epoch 11.334), train_loss = 1.05735629, grad/param norm = 1.6766e-01, time/batch = 0.6969s	
5158/22750 (epoch 11.336), train_loss = 1.34465394, grad/param norm = 1.9017e-01, time/batch = 0.7109s	
5159/22750 (epoch 11.338), train_loss = 1.23670774, grad/param norm = 1.8449e-01, time/batch = 0.7064s	
5160/22750 (epoch 11.341), train_loss = 1.24065531, grad/param norm = 1.7187e-01, time/batch = 0.6980s	
5161/22750 (epoch 11.343), train_loss = 1.08493360, grad/param norm = 1.8678e-01, time/batch = 0.7063s	
5162/22750 (epoch 11.345), train_loss = 1.43559745, grad/param norm = 2.0442e-01, time/batch = 0.7046s	
5163/22750 (epoch 11.347), train_loss = 1.44307843, grad/param norm = 2.0791e-01, time/batch = 0.7213s	
5164/22750 (epoch 11.349), train_loss = 1.03705314, grad/param norm = 1.8191e-01, time/batch = 0.7017s	
5165/22750 (epoch 11.352), train_loss = 1.39251506, grad/param norm = 1.9680e-01, time/batch = 0.7006s	
5166/22750 (epoch 11.354), train_loss = 1.45666385, grad/param norm = 2.0238e-01, time/batch = 0.6956s	
5167/22750 (epoch 11.356), train_loss = 1.46620131, grad/param norm = 2.0748e-01, time/batch = 0.6961s	
5168/22750 (epoch 11.358), train_loss = 1.29807138, grad/param norm = 2.1395e-01, time/batch = 0.7022s	
5169/22750 (epoch 11.360), train_loss = 1.50203282, grad/param norm = 2.0002e-01, time/batch = 0.7039s	
5170/22750 (epoch 11.363), train_loss = 1.26440841, grad/param norm = 1.7617e-01, time/batch = 0.6968s	
5171/22750 (epoch 11.365), train_loss = 1.04444499, grad/param norm = 1.8410e-01, time/batch = 0.6970s	
5172/22750 (epoch 11.367), train_loss = 1.12209592, grad/param norm = 1.8485e-01, time/batch = 0.7218s	
5173/22750 (epoch 11.369), train_loss = 1.24212396, grad/param norm = 1.8950e-01, time/batch = 0.7282s	
5174/22750 (epoch 11.371), train_loss = 1.20258944, grad/param norm = 1.7500e-01, time/batch = 0.7021s	
5175/22750 (epoch 11.374), train_loss = 1.15228627, grad/param norm = 1.7493e-01, time/batch = 0.7019s	
5176/22750 (epoch 11.376), train_loss = 1.26719392, grad/param norm = 1.7964e-01, time/batch = 0.6948s	
5177/22750 (epoch 11.378), train_loss = 1.27916518, grad/param norm = 1.8913e-01, time/batch = 0.7015s	
5178/22750 (epoch 11.380), train_loss = 1.44284721, grad/param norm = 1.9598e-01, time/batch = 0.6991s	
5179/22750 (epoch 11.382), train_loss = 1.21039692, grad/param norm = 1.7208e-01, time/batch = 0.6982s	
5180/22750 (epoch 11.385), train_loss = 1.34233401, grad/param norm = 1.7955e-01, time/batch = 0.6939s	
5181/22750 (epoch 11.387), train_loss = 1.32063647, grad/param norm = 1.8742e-01, time/batch = 0.7018s	
5182/22750 (epoch 11.389), train_loss = 0.97980044, grad/param norm = 1.6879e-01, time/batch = 0.7046s	
5183/22750 (epoch 11.391), train_loss = 0.81184977, grad/param norm = 1.4478e-01, time/batch = 0.7138s	
5184/22750 (epoch 11.393), train_loss = 1.12359334, grad/param norm = 1.7089e-01, time/batch = 0.6980s	
5185/22750 (epoch 11.396), train_loss = 1.28774185, grad/param norm = 1.9584e-01, time/batch = 0.6988s	
5186/22750 (epoch 11.398), train_loss = 1.22663519, grad/param norm = 1.7843e-01, time/batch = 0.6963s	
5187/22750 (epoch 11.400), train_loss = 1.23835565, grad/param norm = 1.7746e-01, time/batch = 0.6938s	
5188/22750 (epoch 11.402), train_loss = 1.32037150, grad/param norm = 1.7348e-01, time/batch = 0.7062s	
5189/22750 (epoch 11.404), train_loss = 1.47853287, grad/param norm = 1.8931e-01, time/batch = 0.6955s	
5190/22750 (epoch 11.407), train_loss = 1.39150029, grad/param norm = 1.8014e-01, time/batch = 0.6990s	
5191/22750 (epoch 11.409), train_loss = 1.26928688, grad/param norm = 1.8572e-01, time/batch = 0.7004s	
5192/22750 (epoch 11.411), train_loss = 1.24746806, grad/param norm = 1.7372e-01, time/batch = 0.7139s	
5193/22750 (epoch 11.413), train_loss = 1.05081892, grad/param norm = 1.8144e-01, time/batch = 0.7227s	
5194/22750 (epoch 11.415), train_loss = 0.99276168, grad/param norm = 1.8308e-01, time/batch = 0.6970s	
5195/22750 (epoch 11.418), train_loss = 1.20731121, grad/param norm = 1.8232e-01, time/batch = 0.7014s	
5196/22750 (epoch 11.420), train_loss = 1.45740644, grad/param norm = 2.3398e-01, time/batch = 0.7103s	
5197/22750 (epoch 11.422), train_loss = 1.57393620, grad/param norm = 2.4536e-01, time/batch = 0.7236s	
5198/22750 (epoch 11.424), train_loss = 1.54335152, grad/param norm = 2.0804e-01, time/batch = 0.7256s	
5199/22750 (epoch 11.426), train_loss = 1.52625144, grad/param norm = 2.0573e-01, time/batch = 0.7164s	
5200/22750 (epoch 11.429), train_loss = 1.06654330, grad/param norm = 1.7375e-01, time/batch = 0.6975s	
5201/22750 (epoch 11.431), train_loss = 1.05425910, grad/param norm = 1.8271e-01, time/batch = 0.6999s	
5202/22750 (epoch 11.433), train_loss = 1.17522091, grad/param norm = 1.7693e-01, time/batch = 0.6976s	
5203/22750 (epoch 11.435), train_loss = 1.01395972, grad/param norm = 1.6541e-01, time/batch = 0.7066s	
5204/22750 (epoch 11.437), train_loss = 0.90808770, grad/param norm = 1.5938e-01, time/batch = 0.7252s	
5205/22750 (epoch 11.440), train_loss = 1.35132508, grad/param norm = 1.9532e-01, time/batch = 0.7301s	
5206/22750 (epoch 11.442), train_loss = 1.31973940, grad/param norm = 1.9498e-01, time/batch = 0.7223s	
5207/22750 (epoch 11.444), train_loss = 1.25860952, grad/param norm = 1.8829e-01, time/batch = 0.7242s	
5208/22750 (epoch 11.446), train_loss = 1.28194627, grad/param norm = 2.0284e-01, time/batch = 0.7223s	
5209/22750 (epoch 11.448), train_loss = 1.57174385, grad/param norm = 2.0742e-01, time/batch = 0.7068s	
5210/22750 (epoch 11.451), train_loss = 1.45442687, grad/param norm = 1.8326e-01, time/batch = 0.7000s	
5211/22750 (epoch 11.453), train_loss = 1.52202332, grad/param norm = 2.0202e-01, time/batch = 0.7001s	
5212/22750 (epoch 11.455), train_loss = 1.61007969, grad/param norm = 2.0004e-01, time/batch = 0.7009s	
5213/22750 (epoch 11.457), train_loss = 1.45189373, grad/param norm = 2.1830e-01, time/batch = 0.7031s	
5214/22750 (epoch 11.459), train_loss = 1.39057341, grad/param norm = 1.9778e-01, time/batch = 0.6978s	
5215/22750 (epoch 11.462), train_loss = 1.40147856, grad/param norm = 1.7661e-01, time/batch = 0.6952s	
5216/22750 (epoch 11.464), train_loss = 1.09417844, grad/param norm = 1.8087e-01, time/batch = 0.7074s	
5217/22750 (epoch 11.466), train_loss = 1.52439005, grad/param norm = 2.1903e-01, time/batch = 0.7231s	
5218/22750 (epoch 11.468), train_loss = 1.25428173, grad/param norm = 1.9578e-01, time/batch = 0.7002s	
5219/22750 (epoch 11.470), train_loss = 1.42205599, grad/param norm = 2.0121e-01, time/batch = 0.6986s	
5220/22750 (epoch 11.473), train_loss = 1.27058227, grad/param norm = 1.8829e-01, time/batch = 0.6994s	
5221/22750 (epoch 11.475), train_loss = 1.31793034, grad/param norm = 1.9780e-01, time/batch = 0.7057s	
5222/22750 (epoch 11.477), train_loss = 1.07294489, grad/param norm = 1.6837e-01, time/batch = 0.7258s	
5223/22750 (epoch 11.479), train_loss = 1.10162802, grad/param norm = 1.7092e-01, time/batch = 0.7093s	
5224/22750 (epoch 11.481), train_loss = 1.01791697, grad/param norm = 1.6804e-01, time/batch = 0.7020s	
5225/22750 (epoch 11.484), train_loss = 0.96958085, grad/param norm = 1.8760e-01, time/batch = 0.6950s	
5226/22750 (epoch 11.486), train_loss = 1.13882697, grad/param norm = 1.9446e-01, time/batch = 0.7026s	
5227/22750 (epoch 11.488), train_loss = 0.98687186, grad/param norm = 2.1332e-01, time/batch = 0.6988s	
5228/22750 (epoch 11.490), train_loss = 1.26062508, grad/param norm = 1.8113e-01, time/batch = 0.6925s	
5229/22750 (epoch 11.492), train_loss = 1.41862458, grad/param norm = 1.9562e-01, time/batch = 0.6964s	
5230/22750 (epoch 11.495), train_loss = 1.17092634, grad/param norm = 1.8543e-01, time/batch = 0.6998s	
5231/22750 (epoch 11.497), train_loss = 1.31548666, grad/param norm = 2.1215e-01, time/batch = 0.6971s	
5232/22750 (epoch 11.499), train_loss = 1.17494565, grad/param norm = 1.8164e-01, time/batch = 0.7036s	
5233/22750 (epoch 11.501), train_loss = 1.29220139, grad/param norm = 2.0025e-01, time/batch = 0.7223s	
5234/22750 (epoch 11.503), train_loss = 1.27831214, grad/param norm = 1.8542e-01, time/batch = 0.7150s	
5235/22750 (epoch 11.505), train_loss = 1.11994075, grad/param norm = 1.8550e-01, time/batch = 0.7184s	
5236/22750 (epoch 11.508), train_loss = 1.05727058, grad/param norm = 1.8471e-01, time/batch = 0.7140s	
5237/22750 (epoch 11.510), train_loss = 1.10031270, grad/param norm = 1.6711e-01, time/batch = 0.7147s	
5238/22750 (epoch 11.512), train_loss = 1.14770752, grad/param norm = 1.6888e-01, time/batch = 0.7136s	
5239/22750 (epoch 11.514), train_loss = 1.17485935, grad/param norm = 1.7349e-01, time/batch = 0.7014s	
5240/22750 (epoch 11.516), train_loss = 1.15064676, grad/param norm = 1.8301e-01, time/batch = 0.6983s	
5241/22750 (epoch 11.519), train_loss = 1.36741508, grad/param norm = 1.8073e-01, time/batch = 0.7061s	
5242/22750 (epoch 11.521), train_loss = 1.19747368, grad/param norm = 1.7453e-01, time/batch = 0.6951s	
5243/22750 (epoch 11.523), train_loss = 1.20165120, grad/param norm = 1.9953e-01, time/batch = 0.7035s	
5244/22750 (epoch 11.525), train_loss = 1.49203927, grad/param norm = 2.0425e-01, time/batch = 0.6985s	
5245/22750 (epoch 11.527), train_loss = 1.26237164, grad/param norm = 1.7476e-01, time/batch = 0.6968s	
5246/22750 (epoch 11.530), train_loss = 1.21035399, grad/param norm = 1.9127e-01, time/batch = 0.7035s	
5247/22750 (epoch 11.532), train_loss = 1.10405321, grad/param norm = 1.6481e-01, time/batch = 0.7013s	
5248/22750 (epoch 11.534), train_loss = 1.37137601, grad/param norm = 1.9120e-01, time/batch = 0.7092s	
5249/22750 (epoch 11.536), train_loss = 1.28534290, grad/param norm = 1.8540e-01, time/batch = 0.7133s	
5250/22750 (epoch 11.538), train_loss = 1.27052649, grad/param norm = 1.6563e-01, time/batch = 0.7034s	
5251/22750 (epoch 11.541), train_loss = 1.08218880, grad/param norm = 1.7501e-01, time/batch = 0.7041s	
5252/22750 (epoch 11.543), train_loss = 1.10494298, grad/param norm = 1.7503e-01, time/batch = 0.6986s	
5253/22750 (epoch 11.545), train_loss = 1.40489432, grad/param norm = 1.7923e-01, time/batch = 0.7014s	
5254/22750 (epoch 11.547), train_loss = 1.10703031, grad/param norm = 1.5562e-01, time/batch = 0.6979s	
5255/22750 (epoch 11.549), train_loss = 1.18449985, grad/param norm = 1.8509e-01, time/batch = 0.6977s	
5256/22750 (epoch 11.552), train_loss = 1.34251412, grad/param norm = 1.9492e-01, time/batch = 0.6994s	
5257/22750 (epoch 11.554), train_loss = 1.35902021, grad/param norm = 2.0396e-01, time/batch = 0.6949s	
5258/22750 (epoch 11.556), train_loss = 1.26035581, grad/param norm = 1.9090e-01, time/batch = 0.6980s	
5259/22750 (epoch 11.558), train_loss = 1.39671859, grad/param norm = 1.8752e-01, time/batch = 0.7001s	
5260/22750 (epoch 11.560), train_loss = 1.19141842, grad/param norm = 1.7551e-01, time/batch = 0.7041s	
5261/22750 (epoch 11.563), train_loss = 1.38336028, grad/param norm = 1.8123e-01, time/batch = 0.7044s	
5262/22750 (epoch 11.565), train_loss = 1.35589976, grad/param norm = 1.9176e-01, time/batch = 0.7023s	
5263/22750 (epoch 11.567), train_loss = 1.30953327, grad/param norm = 1.9378e-01, time/batch = 0.6985s	
5264/22750 (epoch 11.569), train_loss = 1.21884720, grad/param norm = 1.7592e-01, time/batch = 0.7022s	
5265/22750 (epoch 11.571), train_loss = 1.29515217, grad/param norm = 2.0389e-01, time/batch = 0.6987s	
5266/22750 (epoch 11.574), train_loss = 1.15053338, grad/param norm = 1.7826e-01, time/batch = 0.6942s	
5267/22750 (epoch 11.576), train_loss = 1.28304042, grad/param norm = 1.9030e-01, time/batch = 0.7085s	
5268/22750 (epoch 11.578), train_loss = 1.10540900, grad/param norm = 1.7514e-01, time/batch = 0.7115s	
5269/22750 (epoch 11.580), train_loss = 1.29688444, grad/param norm = 2.0487e-01, time/batch = 0.6991s	
5270/22750 (epoch 11.582), train_loss = 1.08993818, grad/param norm = 1.6930e-01, time/batch = 0.7016s	
5271/22750 (epoch 11.585), train_loss = 1.01400508, grad/param norm = 1.8045e-01, time/batch = 0.7074s	
5272/22750 (epoch 11.587), train_loss = 1.05283673, grad/param norm = 1.6203e-01, time/batch = 0.7222s	
5273/22750 (epoch 11.589), train_loss = 1.05637514, grad/param norm = 1.8396e-01, time/batch = 0.6902s	
5274/22750 (epoch 11.591), train_loss = 1.22330168, grad/param norm = 1.8400e-01, time/batch = 0.6924s	
5275/22750 (epoch 11.593), train_loss = 1.45921442, grad/param norm = 1.9719e-01, time/batch = 0.6909s	
5276/22750 (epoch 11.596), train_loss = 1.45588482, grad/param norm = 2.0038e-01, time/batch = 0.6932s	
5277/22750 (epoch 11.598), train_loss = 1.47519454, grad/param norm = 1.9776e-01, time/batch = 0.6944s	
5278/22750 (epoch 11.600), train_loss = 1.42757668, grad/param norm = 1.9699e-01, time/batch = 0.6959s	
5279/22750 (epoch 11.602), train_loss = 1.12484497, grad/param norm = 1.5792e-01, time/batch = 0.6949s	
5280/22750 (epoch 11.604), train_loss = 1.19725962, grad/param norm = 1.7322e-01, time/batch = 0.6995s	
5281/22750 (epoch 11.607), train_loss = 1.03051239, grad/param norm = 1.6535e-01, time/batch = 0.7360s	
5282/22750 (epoch 11.609), train_loss = 0.97637236, grad/param norm = 1.5910e-01, time/batch = 0.7277s	
5283/22750 (epoch 11.611), train_loss = 1.18725120, grad/param norm = 1.8928e-01, time/batch = 0.6929s	
5284/22750 (epoch 11.613), train_loss = 1.11126118, grad/param norm = 1.8292e-01, time/batch = 0.6894s	
5285/22750 (epoch 11.615), train_loss = 1.16989918, grad/param norm = 1.7036e-01, time/batch = 0.6910s	
5286/22750 (epoch 11.618), train_loss = 1.19923283, grad/param norm = 1.7408e-01, time/batch = 0.6931s	
5287/22750 (epoch 11.620), train_loss = 1.22646880, grad/param norm = 1.8585e-01, time/batch = 0.7141s	
5288/22750 (epoch 11.622), train_loss = 1.02616283, grad/param norm = 1.6719e-01, time/batch = 0.7179s	
5289/22750 (epoch 11.624), train_loss = 1.18937867, grad/param norm = 1.8675e-01, time/batch = 0.7189s	
5290/22750 (epoch 11.626), train_loss = 1.07311282, grad/param norm = 1.8946e-01, time/batch = 0.7192s	
5291/22750 (epoch 11.629), train_loss = 1.21768198, grad/param norm = 1.9232e-01, time/batch = 0.7111s	
5292/22750 (epoch 11.631), train_loss = 1.24129119, grad/param norm = 1.8373e-01, time/batch = 0.7081s	
5293/22750 (epoch 11.633), train_loss = 1.03453193, grad/param norm = 1.7971e-01, time/batch = 0.6953s	
5294/22750 (epoch 11.635), train_loss = 1.26865645, grad/param norm = 2.0206e-01, time/batch = 0.7015s	
5295/22750 (epoch 11.637), train_loss = 1.33682182, grad/param norm = 1.9788e-01, time/batch = 0.6977s	
5296/22750 (epoch 11.640), train_loss = 1.36350930, grad/param norm = 1.9950e-01, time/batch = 0.6948s	
5297/22750 (epoch 11.642), train_loss = 1.41438402, grad/param norm = 1.9027e-01, time/batch = 0.6991s	
5298/22750 (epoch 11.644), train_loss = 1.27205015, grad/param norm = 1.8379e-01, time/batch = 0.7132s	
5299/22750 (epoch 11.646), train_loss = 1.39349233, grad/param norm = 2.0584e-01, time/batch = 0.7286s	
5300/22750 (epoch 11.648), train_loss = 1.27449899, grad/param norm = 2.0387e-01, time/batch = 0.7005s	
5301/22750 (epoch 11.651), train_loss = 1.37418921, grad/param norm = 1.9900e-01, time/batch = 0.6979s	
5302/22750 (epoch 11.653), train_loss = 1.32434813, grad/param norm = 1.9081e-01, time/batch = 0.7066s	
5303/22750 (epoch 11.655), train_loss = 1.25121446, grad/param norm = 1.8283e-01, time/batch = 0.6951s	
5304/22750 (epoch 11.657), train_loss = 1.45853166, grad/param norm = 1.9377e-01, time/batch = 0.6957s	
5305/22750 (epoch 11.659), train_loss = 1.53891449, grad/param norm = 1.9872e-01, time/batch = 0.7002s	
5306/22750 (epoch 11.662), train_loss = 1.55893575, grad/param norm = 2.4535e-01, time/batch = 0.7005s	
5307/22750 (epoch 11.664), train_loss = 1.32905574, grad/param norm = 2.0402e-01, time/batch = 0.6979s	
5308/22750 (epoch 11.666), train_loss = 1.12565982, grad/param norm = 1.8133e-01, time/batch = 0.7012s	
5309/22750 (epoch 11.668), train_loss = 1.28694682, grad/param norm = 1.8496e-01, time/batch = 0.7024s	
5310/22750 (epoch 11.670), train_loss = 1.28879936, grad/param norm = 1.8454e-01, time/batch = 0.6964s	
5311/22750 (epoch 11.673), train_loss = 1.57099887, grad/param norm = 2.2714e-01, time/batch = 0.7181s	
5312/22750 (epoch 11.675), train_loss = 1.73594080, grad/param norm = 2.0810e-01, time/batch = 0.7163s	
5313/22750 (epoch 11.677), train_loss = 1.48978216, grad/param norm = 2.3077e-01, time/batch = 0.7125s	
5314/22750 (epoch 11.679), train_loss = 1.53751730, grad/param norm = 2.1043e-01, time/batch = 0.7152s	
5315/22750 (epoch 11.681), train_loss = 1.47825059, grad/param norm = 2.0399e-01, time/batch = 0.7219s	
5316/22750 (epoch 11.684), train_loss = 1.45195304, grad/param norm = 2.0146e-01, time/batch = 0.7206s	
5317/22750 (epoch 11.686), train_loss = 1.42398034, grad/param norm = 2.0112e-01, time/batch = 0.7118s	
5318/22750 (epoch 11.688), train_loss = 1.41219208, grad/param norm = 1.9908e-01, time/batch = 0.7055s	
5319/22750 (epoch 11.690), train_loss = 1.40097172, grad/param norm = 1.9807e-01, time/batch = 0.7060s	
5320/22750 (epoch 11.692), train_loss = 1.50663646, grad/param norm = 2.0153e-01, time/batch = 0.7028s	
5321/22750 (epoch 11.695), train_loss = 1.29345991, grad/param norm = 1.8136e-01, time/batch = 0.7250s	
5322/22750 (epoch 11.697), train_loss = 1.26938901, grad/param norm = 2.0189e-01, time/batch = 0.7068s	
5323/22750 (epoch 11.699), train_loss = 1.29462153, grad/param norm = 1.7772e-01, time/batch = 0.6971s	
5324/22750 (epoch 11.701), train_loss = 1.12314951, grad/param norm = 1.7722e-01, time/batch = 0.6939s	
5325/22750 (epoch 11.703), train_loss = 1.31045981, grad/param norm = 1.7993e-01, time/batch = 0.6929s	
5326/22750 (epoch 11.705), train_loss = 1.17487547, grad/param norm = 1.6767e-01, time/batch = 0.6974s	
5327/22750 (epoch 11.708), train_loss = 1.29957996, grad/param norm = 1.7745e-01, time/batch = 0.6999s	
5328/22750 (epoch 11.710), train_loss = 1.09793772, grad/param norm = 1.7356e-01, time/batch = 0.6984s	
5329/22750 (epoch 11.712), train_loss = 1.17638292, grad/param norm = 1.7214e-01, time/batch = 0.6927s	
5330/22750 (epoch 11.714), train_loss = 1.04914722, grad/param norm = 1.6907e-01, time/batch = 0.6970s	
5331/22750 (epoch 11.716), train_loss = 1.14744707, grad/param norm = 1.8545e-01, time/batch = 0.7244s	
5332/22750 (epoch 11.719), train_loss = 1.35954542, grad/param norm = 2.0984e-01, time/batch = 0.7007s	
5333/22750 (epoch 11.721), train_loss = 1.37349450, grad/param norm = 1.8428e-01, time/batch = 0.6977s	
5334/22750 (epoch 11.723), train_loss = 1.28498132, grad/param norm = 1.8667e-01, time/batch = 0.7001s	
5335/22750 (epoch 11.725), train_loss = 1.24507505, grad/param norm = 1.8643e-01, time/batch = 0.6986s	
5336/22750 (epoch 11.727), train_loss = 1.18748601, grad/param norm = 1.6993e-01, time/batch = 0.6941s	
5337/22750 (epoch 11.730), train_loss = 1.21983633, grad/param norm = 1.8174e-01, time/batch = 0.6923s	
5338/22750 (epoch 11.732), train_loss = 1.20594483, grad/param norm = 1.7771e-01, time/batch = 0.6995s	
5339/22750 (epoch 11.734), train_loss = 0.99741619, grad/param norm = 1.7301e-01, time/batch = 0.6946s	
5340/22750 (epoch 11.736), train_loss = 1.17890672, grad/param norm = 1.8327e-01, time/batch = 0.6998s	
5341/22750 (epoch 11.738), train_loss = 1.30811652, grad/param norm = 2.0585e-01, time/batch = 0.7243s	
5342/22750 (epoch 11.741), train_loss = 1.38954285, grad/param norm = 2.0074e-01, time/batch = 0.7047s	
5343/22750 (epoch 11.743), train_loss = 1.30599962, grad/param norm = 1.8761e-01, time/batch = 0.6976s	
5344/22750 (epoch 11.745), train_loss = 1.10280377, grad/param norm = 1.6780e-01, time/batch = 0.6988s	
5345/22750 (epoch 11.747), train_loss = 1.19016784, grad/param norm = 1.7703e-01, time/batch = 0.6969s	
5346/22750 (epoch 11.749), train_loss = 1.48468718, grad/param norm = 2.1182e-01, time/batch = 0.6932s	
5347/22750 (epoch 11.752), train_loss = 1.19948807, grad/param norm = 1.8333e-01, time/batch = 0.6972s	
5348/22750 (epoch 11.754), train_loss = 1.36178155, grad/param norm = 2.1546e-01, time/batch = 0.7022s	
5349/22750 (epoch 11.756), train_loss = 1.12462315, grad/param norm = 2.0585e-01, time/batch = 0.6941s	
5350/22750 (epoch 11.758), train_loss = 1.11470369, grad/param norm = 1.7330e-01, time/batch = 0.7018s	
5351/22750 (epoch 11.760), train_loss = 1.24904475, grad/param norm = 1.7626e-01, time/batch = 0.7243s	
5352/22750 (epoch 11.763), train_loss = 1.32218057, grad/param norm = 1.9153e-01, time/batch = 0.7056s	
5353/22750 (epoch 11.765), train_loss = 1.23474675, grad/param norm = 2.1225e-01, time/batch = 0.7030s	
5354/22750 (epoch 11.767), train_loss = 1.27457691, grad/param norm = 1.7823e-01, time/batch = 0.6974s	
5355/22750 (epoch 11.769), train_loss = 1.49332628, grad/param norm = 1.9775e-01, time/batch = 0.6949s	
5356/22750 (epoch 11.771), train_loss = 1.44035534, grad/param norm = 1.9287e-01, time/batch = 0.6962s	
5357/22750 (epoch 11.774), train_loss = 1.17825401, grad/param norm = 2.0004e-01, time/batch = 0.6967s	
5358/22750 (epoch 11.776), train_loss = 1.27602917, grad/param norm = 1.9941e-01, time/batch = 0.6955s	
5359/22750 (epoch 11.778), train_loss = 1.47343403, grad/param norm = 1.9007e-01, time/batch = 0.6970s	
5360/22750 (epoch 11.780), train_loss = 1.31200985, grad/param norm = 1.9099e-01, time/batch = 0.7076s	
5361/22750 (epoch 11.782), train_loss = 1.44343748, grad/param norm = 1.8516e-01, time/batch = 0.7266s	
5362/22750 (epoch 11.785), train_loss = 1.27741940, grad/param norm = 1.8196e-01, time/batch = 0.7002s	
5363/22750 (epoch 11.787), train_loss = 1.15079829, grad/param norm = 1.8583e-01, time/batch = 0.7050s	
5364/22750 (epoch 11.789), train_loss = 1.23701955, grad/param norm = 1.8348e-01, time/batch = 0.7035s	
5365/22750 (epoch 11.791), train_loss = 1.24185991, grad/param norm = 1.7959e-01, time/batch = 0.7014s	
5366/22750 (epoch 11.793), train_loss = 1.20677800, grad/param norm = 1.8738e-01, time/batch = 0.7041s	
5367/22750 (epoch 11.796), train_loss = 1.08816272, grad/param norm = 1.8169e-01, time/batch = 0.6963s	
5368/22750 (epoch 11.798), train_loss = 1.12214486, grad/param norm = 1.6123e-01, time/batch = 0.7010s	
5369/22750 (epoch 11.800), train_loss = 1.14642050, grad/param norm = 1.6582e-01, time/batch = 0.7054s	
5370/22750 (epoch 11.802), train_loss = 1.13469477, grad/param norm = 1.7084e-01, time/batch = 0.7193s	
5371/22750 (epoch 11.804), train_loss = 1.47874888, grad/param norm = 1.9197e-01, time/batch = 0.7324s	
5372/22750 (epoch 11.807), train_loss = 1.30611072, grad/param norm = 1.8043e-01, time/batch = 0.7264s	
5373/22750 (epoch 11.809), train_loss = 1.53138738, grad/param norm = 2.1101e-01, time/batch = 0.7591s	
5374/22750 (epoch 11.811), train_loss = 1.19558407, grad/param norm = 1.7172e-01, time/batch = 0.7454s	
5375/22750 (epoch 11.813), train_loss = 1.28990486, grad/param norm = 1.6901e-01, time/batch = 0.7391s	
5376/22750 (epoch 11.815), train_loss = 1.47045027, grad/param norm = 2.0334e-01, time/batch = 0.7309s	
5377/22750 (epoch 11.818), train_loss = 1.43218100, grad/param norm = 1.8195e-01, time/batch = 0.7302s	
5378/22750 (epoch 11.820), train_loss = 1.54737630, grad/param norm = 1.9136e-01, time/batch = 0.7256s	
5379/22750 (epoch 11.822), train_loss = 1.29814565, grad/param norm = 1.7961e-01, time/batch = 0.7342s	
5380/22750 (epoch 11.824), train_loss = 1.21741448, grad/param norm = 1.7883e-01, time/batch = 0.7340s	
5381/22750 (epoch 11.826), train_loss = 1.30599385, grad/param norm = 1.8296e-01, time/batch = 0.7449s	
5382/22750 (epoch 11.829), train_loss = 1.46919629, grad/param norm = 1.9313e-01, time/batch = 0.7313s	
5383/22750 (epoch 11.831), train_loss = 1.43541106, grad/param norm = 1.9345e-01, time/batch = 0.7196s	
5384/22750 (epoch 11.833), train_loss = 1.31011110, grad/param norm = 1.8652e-01, time/batch = 0.7283s	
5385/22750 (epoch 11.835), train_loss = 1.22675776, grad/param norm = 1.8325e-01, time/batch = 0.7190s	
5386/22750 (epoch 11.837), train_loss = 1.21888817, grad/param norm = 1.9130e-01, time/batch = 0.7155s	
5387/22750 (epoch 11.840), train_loss = 1.16569512, grad/param norm = 1.7154e-01, time/batch = 0.7095s	
5388/22750 (epoch 11.842), train_loss = 1.21488192, grad/param norm = 1.8567e-01, time/batch = 0.7053s	
5389/22750 (epoch 11.844), train_loss = 1.38159116, grad/param norm = 1.8403e-01, time/batch = 0.7208s	
5390/22750 (epoch 11.846), train_loss = 1.26992243, grad/param norm = 1.7724e-01, time/batch = 0.7133s	
5391/22750 (epoch 11.848), train_loss = 1.15492151, grad/param norm = 1.7904e-01, time/batch = 0.7084s	
5392/22750 (epoch 11.851), train_loss = 1.17099559, grad/param norm = 1.7304e-01, time/batch = 0.7196s	
5393/22750 (epoch 11.853), train_loss = 1.29219946, grad/param norm = 1.7761e-01, time/batch = 0.7127s	
5394/22750 (epoch 11.855), train_loss = 1.07611081, grad/param norm = 1.8573e-01, time/batch = 0.7058s	
5395/22750 (epoch 11.857), train_loss = 1.29596307, grad/param norm = 1.8397e-01, time/batch = 0.7046s	
5396/22750 (epoch 11.859), train_loss = 1.33193469, grad/param norm = 2.0113e-01, time/batch = 0.7065s	
5397/22750 (epoch 11.862), train_loss = 1.47027927, grad/param norm = 2.0706e-01, time/batch = 0.7109s	
5398/22750 (epoch 11.864), train_loss = 1.25358392, grad/param norm = 1.8055e-01, time/batch = 0.7008s	
5399/22750 (epoch 11.866), train_loss = 1.30495686, grad/param norm = 1.7158e-01, time/batch = 0.7024s	
5400/22750 (epoch 11.868), train_loss = 1.19508945, grad/param norm = 1.6658e-01, time/batch = 0.7050s	
5401/22750 (epoch 11.870), train_loss = 1.07597441, grad/param norm = 1.7346e-01, time/batch = 0.7049s	
5402/22750 (epoch 11.873), train_loss = 1.20461228, grad/param norm = 1.7363e-01, time/batch = 0.6978s	
5403/22750 (epoch 11.875), train_loss = 1.33791097, grad/param norm = 1.7850e-01, time/batch = 0.7036s	
5404/22750 (epoch 11.877), train_loss = 1.19746517, grad/param norm = 1.7369e-01, time/batch = 0.6997s	
5405/22750 (epoch 11.879), train_loss = 1.39254104, grad/param norm = 1.9434e-01, time/batch = 0.7035s	
5406/22750 (epoch 11.881), train_loss = 1.38551823, grad/param norm = 1.9346e-01, time/batch = 0.7088s	
5407/22750 (epoch 11.884), train_loss = 1.15364166, grad/param norm = 1.7839e-01, time/batch = 0.7022s	
5408/22750 (epoch 11.886), train_loss = 1.34552102, grad/param norm = 1.8552e-01, time/batch = 0.7040s	
5409/22750 (epoch 11.888), train_loss = 1.34359573, grad/param norm = 1.8584e-01, time/batch = 0.7109s	
5410/22750 (epoch 11.890), train_loss = 1.39957984, grad/param norm = 1.8940e-01, time/batch = 0.7211s	
5411/22750 (epoch 11.892), train_loss = 1.69339486, grad/param norm = 2.2786e-01, time/batch = 0.7173s	
5412/22750 (epoch 11.895), train_loss = 1.36687456, grad/param norm = 1.7566e-01, time/batch = 0.7176s	
5413/22750 (epoch 11.897), train_loss = 1.40219212, grad/param norm = 1.8855e-01, time/batch = 0.7154s	
5414/22750 (epoch 11.899), train_loss = 1.30629804, grad/param norm = 1.6907e-01, time/batch = 0.7174s	
5415/22750 (epoch 11.901), train_loss = 1.49186598, grad/param norm = 2.0323e-01, time/batch = 0.7140s	
5416/22750 (epoch 11.903), train_loss = 1.26769960, grad/param norm = 2.0005e-01, time/batch = 0.7141s	
5417/22750 (epoch 11.905), train_loss = 1.37027898, grad/param norm = 1.8044e-01, time/batch = 0.7116s	
5418/22750 (epoch 11.908), train_loss = 1.23169642, grad/param norm = 2.0069e-01, time/batch = 0.7054s	
5419/22750 (epoch 11.910), train_loss = 1.05241014, grad/param norm = 1.9220e-01, time/batch = 0.7134s	
5420/22750 (epoch 11.912), train_loss = 1.18620272, grad/param norm = 1.8110e-01, time/batch = 0.7015s	
5421/22750 (epoch 11.914), train_loss = 1.26208520, grad/param norm = 1.8527e-01, time/batch = 0.7075s	
5422/22750 (epoch 11.916), train_loss = 1.07882164, grad/param norm = 1.7079e-01, time/batch = 0.7002s	
5423/22750 (epoch 11.919), train_loss = 1.17944668, grad/param norm = 1.8307e-01, time/batch = 0.7107s	
5424/22750 (epoch 11.921), train_loss = 0.89080369, grad/param norm = 1.4708e-01, time/batch = 0.7064s	
5425/22750 (epoch 11.923), train_loss = 1.17863396, grad/param norm = 1.7214e-01, time/batch = 0.7028s	
5426/22750 (epoch 11.925), train_loss = 1.22262914, grad/param norm = 1.7149e-01, time/batch = 0.7115s	
5427/22750 (epoch 11.927), train_loss = 1.00712151, grad/param norm = 1.7674e-01, time/batch = 0.7053s	
5428/22750 (epoch 11.930), train_loss = 1.05600627, grad/param norm = 1.7783e-01, time/batch = 0.6989s	
5429/22750 (epoch 11.932), train_loss = 1.32105001, grad/param norm = 1.9003e-01, time/batch = 0.7021s	
5430/22750 (epoch 11.934), train_loss = 0.94152464, grad/param norm = 1.4188e-01, time/batch = 0.7035s	
5431/22750 (epoch 11.936), train_loss = 1.37737048, grad/param norm = 1.9897e-01, time/batch = 0.7073s	
5432/22750 (epoch 11.938), train_loss = 1.30338184, grad/param norm = 1.7011e-01, time/batch = 0.7007s	
5433/22750 (epoch 11.941), train_loss = 1.51575903, grad/param norm = 1.9312e-01, time/batch = 0.6994s	
5434/22750 (epoch 11.943), train_loss = 1.32247637, grad/param norm = 1.8875e-01, time/batch = 0.7005s	
5435/22750 (epoch 11.945), train_loss = 1.27864646, grad/param norm = 1.8959e-01, time/batch = 0.7002s	
5436/22750 (epoch 11.947), train_loss = 1.20822078, grad/param norm = 1.9064e-01, time/batch = 0.7021s	
5437/22750 (epoch 11.949), train_loss = 1.13281004, grad/param norm = 1.8871e-01, time/batch = 0.6994s	
5438/22750 (epoch 11.952), train_loss = 1.16768746, grad/param norm = 1.7096e-01, time/batch = 0.7055s	
5439/22750 (epoch 11.954), train_loss = 1.11681348, grad/param norm = 1.6523e-01, time/batch = 0.6971s	
5440/22750 (epoch 11.956), train_loss = 1.26008153, grad/param norm = 1.7506e-01, time/batch = 0.7009s	
5441/22750 (epoch 11.958), train_loss = 1.18635808, grad/param norm = 1.6727e-01, time/batch = 0.7046s	
5442/22750 (epoch 11.960), train_loss = 1.19906685, grad/param norm = 1.7295e-01, time/batch = 0.6967s	
5443/22750 (epoch 11.963), train_loss = 1.40465984, grad/param norm = 1.8854e-01, time/batch = 0.7019s	
5444/22750 (epoch 11.965), train_loss = 1.36359207, grad/param norm = 1.9072e-01, time/batch = 0.6977s	
5445/22750 (epoch 11.967), train_loss = 1.26897164, grad/param norm = 2.0605e-01, time/batch = 0.7041s	
5446/22750 (epoch 11.969), train_loss = 1.20624584, grad/param norm = 1.8847e-01, time/batch = 0.7104s	
5447/22750 (epoch 11.971), train_loss = 1.18682697, grad/param norm = 1.7569e-01, time/batch = 0.7087s	
5448/22750 (epoch 11.974), train_loss = 1.28264033, grad/param norm = 1.9381e-01, time/batch = 0.7043s	
5449/22750 (epoch 11.976), train_loss = 1.36456716, grad/param norm = 2.0277e-01, time/batch = 0.7118s	
5450/22750 (epoch 11.978), train_loss = 1.11701005, grad/param norm = 1.6131e-01, time/batch = 0.7249s	
5451/22750 (epoch 11.980), train_loss = 1.41431542, grad/param norm = 2.0500e-01, time/batch = 0.7181s	
5452/22750 (epoch 11.982), train_loss = 1.19612720, grad/param norm = 1.7080e-01, time/batch = 0.7090s	
5453/22750 (epoch 11.985), train_loss = 1.50074443, grad/param norm = 2.0707e-01, time/batch = 0.7032s	
5454/22750 (epoch 11.987), train_loss = 1.03244766, grad/param norm = 1.6795e-01, time/batch = 0.7038s	
5455/22750 (epoch 11.989), train_loss = 1.20247085, grad/param norm = 1.8001e-01, time/batch = 0.6971s	
5456/22750 (epoch 11.991), train_loss = 1.33326317, grad/param norm = 2.0084e-01, time/batch = 0.6993s	
5457/22750 (epoch 11.993), train_loss = 1.39984552, grad/param norm = 1.9434e-01, time/batch = 0.7171s	
5458/22750 (epoch 11.996), train_loss = 1.20386268, grad/param norm = 2.1544e-01, time/batch = 0.7397s	
5459/22750 (epoch 11.998), train_loss = 1.43476788, grad/param norm = 1.9144e-01, time/batch = 0.7414s	
decayed learning rate by a factor 0.97 to 0.001825346	
5460/22750 (epoch 12.000), train_loss = 1.32085458, grad/param norm = 1.9689e-01, time/batch = 0.7270s	
5461/22750 (epoch 12.002), train_loss = 1.38842467, grad/param norm = 1.9969e-01, time/batch = 0.7324s	
5462/22750 (epoch 12.004), train_loss = 1.17420344, grad/param norm = 1.7095e-01, time/batch = 0.7147s	
5463/22750 (epoch 12.007), train_loss = 1.24418231, grad/param norm = 1.9424e-01, time/batch = 0.7023s	
5464/22750 (epoch 12.009), train_loss = 1.51967939, grad/param norm = 1.9191e-01, time/batch = 0.7045s	
5465/22750 (epoch 12.011), train_loss = 1.53304315, grad/param norm = 1.9748e-01, time/batch = 0.7050s	
5466/22750 (epoch 12.013), train_loss = 1.36108801, grad/param norm = 1.7746e-01, time/batch = 0.7004s	
5467/22750 (epoch 12.015), train_loss = 1.32667752, grad/param norm = 1.8756e-01, time/batch = 0.7135s	
5468/22750 (epoch 12.018), train_loss = 1.33580640, grad/param norm = 1.8699e-01, time/batch = 0.6977s	
5469/22750 (epoch 12.020), train_loss = 1.47376503, grad/param norm = 1.9365e-01, time/batch = 0.7182s	
5470/22750 (epoch 12.022), train_loss = 1.24113346, grad/param norm = 1.7903e-01, time/batch = 0.7037s	
5471/22750 (epoch 12.024), train_loss = 1.28199623, grad/param norm = 1.9701e-01, time/batch = 0.7026s	
5472/22750 (epoch 12.026), train_loss = 1.36851927, grad/param norm = 2.0139e-01, time/batch = 0.7005s	
5473/22750 (epoch 12.029), train_loss = 1.05107885, grad/param norm = 1.6938e-01, time/batch = 0.6864s	
5474/22750 (epoch 12.031), train_loss = 1.57070667, grad/param norm = 2.0581e-01, time/batch = 0.6858s	
5475/22750 (epoch 12.033), train_loss = 1.29832203, grad/param norm = 1.9460e-01, time/batch = 0.6969s	
5476/22750 (epoch 12.035), train_loss = 1.32935324, grad/param norm = 1.8538e-01, time/batch = 0.6878s	
5477/22750 (epoch 12.037), train_loss = 1.40677659, grad/param norm = 1.8031e-01, time/batch = 0.6903s	
5478/22750 (epoch 12.040), train_loss = 1.22076249, grad/param norm = 1.9016e-01, time/batch = 0.6906s	
5479/22750 (epoch 12.042), train_loss = 1.38686782, grad/param norm = 1.9490e-01, time/batch = 0.6802s	
5480/22750 (epoch 12.044), train_loss = 1.21688885, grad/param norm = 1.8526e-01, time/batch = 0.6906s	
5481/22750 (epoch 12.046), train_loss = 1.37018615, grad/param norm = 2.1553e-01, time/batch = 0.6803s	
5482/22750 (epoch 12.048), train_loss = 1.26050101, grad/param norm = 1.7973e-01, time/batch = 0.6822s	
5483/22750 (epoch 12.051), train_loss = 1.31469060, grad/param norm = 1.7664e-01, time/batch = 0.6779s	
5484/22750 (epoch 12.053), train_loss = 1.13035097, grad/param norm = 1.7502e-01, time/batch = 0.6823s	
5485/22750 (epoch 12.055), train_loss = 1.21210835, grad/param norm = 1.7405e-01, time/batch = 0.6823s	
5486/22750 (epoch 12.057), train_loss = 1.43244028, grad/param norm = 1.9257e-01, time/batch = 0.6854s	
5487/22750 (epoch 12.059), train_loss = 0.93608373, grad/param norm = 1.7228e-01, time/batch = 0.6827s	
5488/22750 (epoch 12.062), train_loss = 1.11029209, grad/param norm = 1.8138e-01, time/batch = 0.6894s	
5489/22750 (epoch 12.064), train_loss = 1.30991013, grad/param norm = 1.8827e-01, time/batch = 0.7106s	
5490/22750 (epoch 12.066), train_loss = 1.08636491, grad/param norm = 1.6407e-01, time/batch = 0.6832s	
5491/22750 (epoch 12.068), train_loss = 1.15628830, grad/param norm = 1.5702e-01, time/batch = 0.6907s	
5492/22750 (epoch 12.070), train_loss = 1.02645590, grad/param norm = 1.7079e-01, time/batch = 0.6811s	
5493/22750 (epoch 12.073), train_loss = 1.18042080, grad/param norm = 1.9063e-01, time/batch = 0.6819s	
5494/22750 (epoch 12.075), train_loss = 1.21284812, grad/param norm = 1.7723e-01, time/batch = 0.6832s	
5495/22750 (epoch 12.077), train_loss = 0.96669184, grad/param norm = 1.7861e-01, time/batch = 0.6859s	
5496/22750 (epoch 12.079), train_loss = 1.19761583, grad/param norm = 1.9132e-01, time/batch = 0.6845s	
5497/22750 (epoch 12.081), train_loss = 1.22032458, grad/param norm = 1.9881e-01, time/batch = 0.6868s	
5498/22750 (epoch 12.084), train_loss = 1.18330385, grad/param norm = 1.8447e-01, time/batch = 0.6972s	
5499/22750 (epoch 12.086), train_loss = 1.18313271, grad/param norm = 1.6038e-01, time/batch = 0.7088s	
5500/22750 (epoch 12.088), train_loss = 1.17377964, grad/param norm = 1.8474e-01, time/batch = 0.6961s	
5501/22750 (epoch 12.090), train_loss = 1.17551776, grad/param norm = 1.7342e-01, time/batch = 0.6940s	
5502/22750 (epoch 12.092), train_loss = 1.42012789, grad/param norm = 1.8813e-01, time/batch = 0.6914s	
5503/22750 (epoch 12.095), train_loss = 1.11004906, grad/param norm = 1.8470e-01, time/batch = 0.6901s	
5504/22750 (epoch 12.097), train_loss = 1.20744804, grad/param norm = 1.8116e-01, time/batch = 0.6909s	
5505/22750 (epoch 12.099), train_loss = 1.24792090, grad/param norm = 1.8393e-01, time/batch = 0.6786s	
5506/22750 (epoch 12.101), train_loss = 1.15764976, grad/param norm = 1.8494e-01, time/batch = 0.6771s	
5507/22750 (epoch 12.103), train_loss = 1.21481565, grad/param norm = 1.8199e-01, time/batch = 0.6883s	
5508/22750 (epoch 12.105), train_loss = 1.52685924, grad/param norm = 2.0736e-01, time/batch = 0.6781s	
5509/22750 (epoch 12.108), train_loss = 1.20638051, grad/param norm = 1.8163e-01, time/batch = 0.6760s	
5510/22750 (epoch 12.110), train_loss = 1.35900468, grad/param norm = 1.9525e-01, time/batch = 0.6814s	
5511/22750 (epoch 12.112), train_loss = 1.04013129, grad/param norm = 1.6256e-01, time/batch = 0.6812s	
5512/22750 (epoch 12.114), train_loss = 0.98177284, grad/param norm = 1.7496e-01, time/batch = 0.6786s	
5513/22750 (epoch 12.116), train_loss = 1.11402294, grad/param norm = 1.6523e-01, time/batch = 0.6795s	
5514/22750 (epoch 12.119), train_loss = 1.12606650, grad/param norm = 1.6159e-01, time/batch = 0.6801s	
5515/22750 (epoch 12.121), train_loss = 1.29237169, grad/param norm = 1.9465e-01, time/batch = 0.6811s	
5516/22750 (epoch 12.123), train_loss = 1.11779672, grad/param norm = 1.7127e-01, time/batch = 0.6813s	
5517/22750 (epoch 12.125), train_loss = 1.38617268, grad/param norm = 1.8242e-01, time/batch = 0.6816s	
5518/22750 (epoch 12.127), train_loss = 1.23482770, grad/param norm = 1.9234e-01, time/batch = 0.6800s	
5519/22750 (epoch 12.130), train_loss = 1.31320874, grad/param norm = 1.8368e-01, time/batch = 0.6800s	
5520/22750 (epoch 12.132), train_loss = 1.22878810, grad/param norm = 1.8753e-01, time/batch = 0.6836s	
5521/22750 (epoch 12.134), train_loss = 1.18787673, grad/param norm = 1.7413e-01, time/batch = 0.6839s	
5522/22750 (epoch 12.136), train_loss = 1.07456460, grad/param norm = 1.7736e-01, time/batch = 0.6864s	
5523/22750 (epoch 12.138), train_loss = 1.28090967, grad/param norm = 1.9204e-01, time/batch = 0.7019s	
5524/22750 (epoch 12.141), train_loss = 1.20541837, grad/param norm = 1.7703e-01, time/batch = 0.7061s	
5525/22750 (epoch 12.143), train_loss = 1.05950130, grad/param norm = 1.6486e-01, time/batch = 0.6794s	
5526/22750 (epoch 12.145), train_loss = 1.40024469, grad/param norm = 1.9382e-01, time/batch = 0.6830s	
5527/22750 (epoch 12.147), train_loss = 1.38017914, grad/param norm = 1.9284e-01, time/batch = 0.6777s	
5528/22750 (epoch 12.149), train_loss = 1.23401677, grad/param norm = 1.8138e-01, time/batch = 0.6760s	
5529/22750 (epoch 12.152), train_loss = 1.17829380, grad/param norm = 1.7879e-01, time/batch = 0.6782s	
5530/22750 (epoch 12.154), train_loss = 1.02654219, grad/param norm = 1.8138e-01, time/batch = 0.6776s	
5531/22750 (epoch 12.156), train_loss = 1.06560676, grad/param norm = 1.7301e-01, time/batch = 0.6774s	
5532/22750 (epoch 12.158), train_loss = 1.17581795, grad/param norm = 2.0497e-01, time/batch = 0.6807s	
5533/22750 (epoch 12.160), train_loss = 1.31146513, grad/param norm = 1.8483e-01, time/batch = 0.6933s	
5534/22750 (epoch 12.163), train_loss = 1.49994489, grad/param norm = 1.9725e-01, time/batch = 0.7105s	
5535/22750 (epoch 12.165), train_loss = 1.32946919, grad/param norm = 1.8270e-01, time/batch = 0.6832s	
5536/22750 (epoch 12.167), train_loss = 1.19871546, grad/param norm = 1.8244e-01, time/batch = 0.7016s	
5537/22750 (epoch 12.169), train_loss = 1.26587554, grad/param norm = 1.9819e-01, time/batch = 0.6995s	
5538/22750 (epoch 12.171), train_loss = 1.10118640, grad/param norm = 1.7367e-01, time/batch = 0.7053s	
5539/22750 (epoch 12.174), train_loss = 1.03421602, grad/param norm = 1.8017e-01, time/batch = 0.6874s	
5540/22750 (epoch 12.176), train_loss = 1.20398996, grad/param norm = 1.7515e-01, time/batch = 0.6800s	
5541/22750 (epoch 12.178), train_loss = 1.19839043, grad/param norm = 1.7309e-01, time/batch = 0.6875s	
5542/22750 (epoch 12.180), train_loss = 1.35862204, grad/param norm = 2.0967e-01, time/batch = 0.6842s	
5543/22750 (epoch 12.182), train_loss = 1.36678053, grad/param norm = 1.8057e-01, time/batch = 0.6966s	
5544/22750 (epoch 12.185), train_loss = 1.38690715, grad/param norm = 2.0668e-01, time/batch = 0.7125s	
5545/22750 (epoch 12.187), train_loss = 1.13754798, grad/param norm = 1.8315e-01, time/batch = 0.7024s	
5546/22750 (epoch 12.189), train_loss = 1.16840400, grad/param norm = 1.8154e-01, time/batch = 0.6929s	
5547/22750 (epoch 12.191), train_loss = 1.09626706, grad/param norm = 1.5796e-01, time/batch = 0.7000s	
5548/22750 (epoch 12.193), train_loss = 1.32759980, grad/param norm = 2.0270e-01, time/batch = 0.7076s	
5549/22750 (epoch 12.196), train_loss = 1.22623503, grad/param norm = 1.7864e-01, time/batch = 0.7073s	
5550/22750 (epoch 12.198), train_loss = 0.95867103, grad/param norm = 1.4510e-01, time/batch = 0.6989s	
5551/22750 (epoch 12.200), train_loss = 1.23259539, grad/param norm = 1.8499e-01, time/batch = 0.6994s	
5552/22750 (epoch 12.202), train_loss = 1.37327398, grad/param norm = 2.0668e-01, time/batch = 0.7109s	
5553/22750 (epoch 12.204), train_loss = 1.31730844, grad/param norm = 1.7465e-01, time/batch = 0.6972s	
5554/22750 (epoch 12.207), train_loss = 1.18964505, grad/param norm = 1.7561e-01, time/batch = 0.6977s	
5555/22750 (epoch 12.209), train_loss = 1.11276450, grad/param norm = 1.7858e-01, time/batch = 0.6833s	
5556/22750 (epoch 12.211), train_loss = 1.15807012, grad/param norm = 1.9512e-01, time/batch = 0.7198s	
5557/22750 (epoch 12.213), train_loss = 1.05247655, grad/param norm = 1.8205e-01, time/batch = 0.7034s	
5558/22750 (epoch 12.215), train_loss = 1.00128985, grad/param norm = 1.6864e-01, time/batch = 0.6934s	
5559/22750 (epoch 12.218), train_loss = 1.06166917, grad/param norm = 1.9609e-01, time/batch = 0.6914s	
5560/22750 (epoch 12.220), train_loss = 1.13574674, grad/param norm = 1.9018e-01, time/batch = 0.6969s	
5561/22750 (epoch 12.222), train_loss = 1.04476505, grad/param norm = 1.8624e-01, time/batch = 0.6855s	
5562/22750 (epoch 12.224), train_loss = 1.14721602, grad/param norm = 1.8837e-01, time/batch = 0.6843s	
5563/22750 (epoch 12.226), train_loss = 1.34127367, grad/param norm = 1.9567e-01, time/batch = 0.6891s	
5564/22750 (epoch 12.229), train_loss = 1.28837771, grad/param norm = 1.9385e-01, time/batch = 0.7061s	
5565/22750 (epoch 12.231), train_loss = 1.14953356, grad/param norm = 1.7403e-01, time/batch = 0.7080s	
5566/22750 (epoch 12.233), train_loss = 1.08915769, grad/param norm = 1.6920e-01, time/batch = 0.7096s	
5567/22750 (epoch 12.235), train_loss = 1.05017397, grad/param norm = 1.7682e-01, time/batch = 0.6890s	
5568/22750 (epoch 12.237), train_loss = 1.14563563, grad/param norm = 1.9542e-01, time/batch = 0.7101s	
5569/22750 (epoch 12.240), train_loss = 1.24495959, grad/param norm = 1.5973e-01, time/batch = 0.7061s	
5570/22750 (epoch 12.242), train_loss = 1.56792467, grad/param norm = 2.2234e-01, time/batch = 0.7050s	
5571/22750 (epoch 12.244), train_loss = 1.39693176, grad/param norm = 2.0332e-01, time/batch = 0.6814s	
5572/22750 (epoch 12.246), train_loss = 1.45967604, grad/param norm = 1.9729e-01, time/batch = 0.6883s	
5573/22750 (epoch 12.248), train_loss = 1.20529740, grad/param norm = 1.9543e-01, time/batch = 0.7077s	
5574/22750 (epoch 12.251), train_loss = 1.47533254, grad/param norm = 1.9034e-01, time/batch = 0.6764s	
5575/22750 (epoch 12.253), train_loss = 1.24568983, grad/param norm = 1.8142e-01, time/batch = 0.7145s	
5576/22750 (epoch 12.255), train_loss = 1.24813682, grad/param norm = 1.8190e-01, time/batch = 0.7018s	
5577/22750 (epoch 12.257), train_loss = 1.19243023, grad/param norm = 1.9200e-01, time/batch = 0.7151s	
5578/22750 (epoch 12.259), train_loss = 1.41729838, grad/param norm = 2.0684e-01, time/batch = 0.6929s	
5579/22750 (epoch 12.262), train_loss = 1.21203193, grad/param norm = 1.7635e-01, time/batch = 0.7048s	
5580/22750 (epoch 12.264), train_loss = 1.07954460, grad/param norm = 1.7295e-01, time/batch = 0.7027s	
5581/22750 (epoch 12.266), train_loss = 1.28991253, grad/param norm = 2.2911e-01, time/batch = 0.6774s	
5582/22750 (epoch 12.268), train_loss = 1.39313322, grad/param norm = 1.9197e-01, time/batch = 0.6799s	
5583/22750 (epoch 12.270), train_loss = 1.17945171, grad/param norm = 1.8811e-01, time/batch = 0.6915s	
5584/22750 (epoch 12.273), train_loss = 1.54892316, grad/param norm = 2.1033e-01, time/batch = 0.7094s	
5585/22750 (epoch 12.275), train_loss = 1.31416380, grad/param norm = 1.8786e-01, time/batch = 0.7055s	
5586/22750 (epoch 12.277), train_loss = 1.21261383, grad/param norm = 1.9669e-01, time/batch = 0.6897s	
5587/22750 (epoch 12.279), train_loss = 1.06205069, grad/param norm = 1.7459e-01, time/batch = 0.6828s	
5588/22750 (epoch 12.281), train_loss = 1.35493240, grad/param norm = 1.8779e-01, time/batch = 0.7034s	
5589/22750 (epoch 12.284), train_loss = 1.18551121, grad/param norm = 1.6792e-01, time/batch = 0.7138s	
5590/22750 (epoch 12.286), train_loss = 1.38998628, grad/param norm = 1.9929e-01, time/batch = 0.7159s	
5591/22750 (epoch 12.288), train_loss = 1.44373283, grad/param norm = 1.8878e-01, time/batch = 0.7138s	
5592/22750 (epoch 12.290), train_loss = 1.21653076, grad/param norm = 1.8384e-01, time/batch = 0.6829s	
5593/22750 (epoch 12.292), train_loss = 1.29825401, grad/param norm = 2.0739e-01, time/batch = 0.6975s	
5594/22750 (epoch 12.295), train_loss = 1.27171082, grad/param norm = 1.6450e-01, time/batch = 0.7098s	
5595/22750 (epoch 12.297), train_loss = 1.16618783, grad/param norm = 1.6819e-01, time/batch = 0.6880s	
5596/22750 (epoch 12.299), train_loss = 1.37785816, grad/param norm = 1.8746e-01, time/batch = 0.6879s	
5597/22750 (epoch 12.301), train_loss = 1.27697324, grad/param norm = 1.9743e-01, time/batch = 0.6867s	
5598/22750 (epoch 12.303), train_loss = 1.35289800, grad/param norm = 1.9795e-01, time/batch = 0.6817s	
5599/22750 (epoch 12.305), train_loss = 1.48066489, grad/param norm = 1.9091e-01, time/batch = 0.6979s	
5600/22750 (epoch 12.308), train_loss = 1.30651100, grad/param norm = 1.9218e-01, time/batch = 0.7045s	
5601/22750 (epoch 12.310), train_loss = 1.14516439, grad/param norm = 1.9750e-01, time/batch = 0.7227s	
5602/22750 (epoch 12.312), train_loss = 1.31208813, grad/param norm = 1.9828e-01, time/batch = 0.7298s	
5603/22750 (epoch 12.314), train_loss = 1.25924290, grad/param norm = 1.7847e-01, time/batch = 0.7325s	
5604/22750 (epoch 12.316), train_loss = 1.19223089, grad/param norm = 1.8599e-01, time/batch = 0.7103s	
5605/22750 (epoch 12.319), train_loss = 1.30127313, grad/param norm = 2.0033e-01, time/batch = 0.7036s	
5606/22750 (epoch 12.321), train_loss = 1.20453607, grad/param norm = 1.9565e-01, time/batch = 0.7070s	
5607/22750 (epoch 12.323), train_loss = 1.20242220, grad/param norm = 1.8612e-01, time/batch = 0.6882s	
5608/22750 (epoch 12.325), train_loss = 1.01420301, grad/param norm = 1.8122e-01, time/batch = 0.6789s	
5609/22750 (epoch 12.327), train_loss = 1.26250159, grad/param norm = 1.9033e-01, time/batch = 0.6975s	
5610/22750 (epoch 12.330), train_loss = 1.52156577, grad/param norm = 2.0529e-01, time/batch = 0.6963s	
5611/22750 (epoch 12.332), train_loss = 1.44623140, grad/param norm = 1.9270e-01, time/batch = 0.6798s	
5612/22750 (epoch 12.334), train_loss = 1.02608347, grad/param norm = 1.7199e-01, time/batch = 0.6851s	
5613/22750 (epoch 12.336), train_loss = 1.30366401, grad/param norm = 1.8552e-01, time/batch = 0.6841s	
5614/22750 (epoch 12.338), train_loss = 1.19739634, grad/param norm = 1.8402e-01, time/batch = 0.6826s	
5615/22750 (epoch 12.341), train_loss = 1.20095710, grad/param norm = 1.7367e-01, time/batch = 0.6808s	
5616/22750 (epoch 12.343), train_loss = 1.05091843, grad/param norm = 1.8222e-01, time/batch = 0.6770s	
5617/22750 (epoch 12.345), train_loss = 1.39233831, grad/param norm = 2.0747e-01, time/batch = 0.6808s	
5618/22750 (epoch 12.347), train_loss = 1.41101116, grad/param norm = 2.0583e-01, time/batch = 0.6784s	
5619/22750 (epoch 12.349), train_loss = 0.99918619, grad/param norm = 1.7439e-01, time/batch = 0.6860s	
5620/22750 (epoch 12.352), train_loss = 1.34437487, grad/param norm = 1.9550e-01, time/batch = 0.6804s	
5621/22750 (epoch 12.354), train_loss = 1.40695792, grad/param norm = 1.9766e-01, time/batch = 0.6805s	
5622/22750 (epoch 12.356), train_loss = 1.41932929, grad/param norm = 2.0850e-01, time/batch = 0.6837s	
5623/22750 (epoch 12.358), train_loss = 1.25498266, grad/param norm = 2.1194e-01, time/batch = 0.6919s	
5624/22750 (epoch 12.360), train_loss = 1.45474910, grad/param norm = 1.9524e-01, time/batch = 0.7096s	
5625/22750 (epoch 12.363), train_loss = 1.21979370, grad/param norm = 1.7811e-01, time/batch = 0.6853s	
5626/22750 (epoch 12.365), train_loss = 1.01534386, grad/param norm = 1.8647e-01, time/batch = 0.6799s	
5627/22750 (epoch 12.367), train_loss = 1.08834910, grad/param norm = 1.8780e-01, time/batch = 0.6802s	
5628/22750 (epoch 12.369), train_loss = 1.20832986, grad/param norm = 1.9086e-01, time/batch = 0.6805s	
5629/22750 (epoch 12.371), train_loss = 1.17467045, grad/param norm = 1.7342e-01, time/batch = 0.6933s	
5630/22750 (epoch 12.374), train_loss = 1.11549576, grad/param norm = 1.6914e-01, time/batch = 0.7109s	
5631/22750 (epoch 12.376), train_loss = 1.22138161, grad/param norm = 1.8255e-01, time/batch = 0.7068s	
5632/22750 (epoch 12.378), train_loss = 1.24258993, grad/param norm = 1.8418e-01, time/batch = 0.7084s	
5633/22750 (epoch 12.380), train_loss = 1.39729737, grad/param norm = 1.9678e-01, time/batch = 0.7071s	
5634/22750 (epoch 12.382), train_loss = 1.18195132, grad/param norm = 1.7160e-01, time/batch = 0.7127s	
5635/22750 (epoch 12.385), train_loss = 1.30802388, grad/param norm = 1.8299e-01, time/batch = 0.7121s	
5636/22750 (epoch 12.387), train_loss = 1.28513260, grad/param norm = 1.8567e-01, time/batch = 0.7021s	
5637/22750 (epoch 12.389), train_loss = 0.95088338, grad/param norm = 1.6846e-01, time/batch = 0.7010s	
5638/22750 (epoch 12.391), train_loss = 0.78572999, grad/param norm = 1.4396e-01, time/batch = 0.6929s	
5639/22750 (epoch 12.393), train_loss = 1.09108508, grad/param norm = 1.6975e-01, time/batch = 0.6944s	
5640/22750 (epoch 12.396), train_loss = 1.25507351, grad/param norm = 1.9415e-01, time/batch = 0.6926s	
5641/22750 (epoch 12.398), train_loss = 1.18572695, grad/param norm = 1.7363e-01, time/batch = 0.6989s	
5642/22750 (epoch 12.400), train_loss = 1.19782482, grad/param norm = 1.7333e-01, time/batch = 0.7188s	
5643/22750 (epoch 12.402), train_loss = 1.28560282, grad/param norm = 1.7433e-01, time/batch = 0.7084s	
5644/22750 (epoch 12.404), train_loss = 1.43055851, grad/param norm = 1.8755e-01, time/batch = 0.7111s	
5645/22750 (epoch 12.407), train_loss = 1.35241582, grad/param norm = 1.8424e-01, time/batch = 0.6817s	
5646/22750 (epoch 12.409), train_loss = 1.23443724, grad/param norm = 2.0117e-01, time/batch = 0.6945s	
5647/22750 (epoch 12.411), train_loss = 1.20001628, grad/param norm = 1.7097e-01, time/batch = 0.7050s	
5648/22750 (epoch 12.413), train_loss = 1.01076029, grad/param norm = 1.8684e-01, time/batch = 0.7084s	
5649/22750 (epoch 12.415), train_loss = 0.94270930, grad/param norm = 1.7301e-01, time/batch = 0.6914s	
5650/22750 (epoch 12.418), train_loss = 1.17350268, grad/param norm = 1.8442e-01, time/batch = 0.6913s	
5651/22750 (epoch 12.420), train_loss = 1.40171990, grad/param norm = 2.2156e-01, time/batch = 0.6836s	
5652/22750 (epoch 12.422), train_loss = 1.51270849, grad/param norm = 2.2775e-01, time/batch = 0.6853s	
5653/22750 (epoch 12.424), train_loss = 1.51109519, grad/param norm = 2.1941e-01, time/batch = 0.6949s	
5654/22750 (epoch 12.426), train_loss = 1.48416470, grad/param norm = 2.0600e-01, time/batch = 0.7102s	
5655/22750 (epoch 12.429), train_loss = 1.04411477, grad/param norm = 1.7255e-01, time/batch = 0.6846s	
5656/22750 (epoch 12.431), train_loss = 1.02890155, grad/param norm = 1.9071e-01, time/batch = 0.6835s	
5657/22750 (epoch 12.433), train_loss = 1.13989446, grad/param norm = 1.6802e-01, time/batch = 0.6875s	
5658/22750 (epoch 12.435), train_loss = 0.96997183, grad/param norm = 1.6111e-01, time/batch = 0.6873s	
5659/22750 (epoch 12.437), train_loss = 0.86735108, grad/param norm = 1.6569e-01, time/batch = 0.6967s	
5660/22750 (epoch 12.440), train_loss = 1.29129895, grad/param norm = 1.9221e-01, time/batch = 0.6956s	
5661/22750 (epoch 12.442), train_loss = 1.28601941, grad/param norm = 2.0367e-01, time/batch = 0.6974s	
5662/22750 (epoch 12.444), train_loss = 1.22323039, grad/param norm = 1.9776e-01, time/batch = 0.6986s	
5663/22750 (epoch 12.446), train_loss = 1.24092521, grad/param norm = 1.9316e-01, time/batch = 0.7029s	
5664/22750 (epoch 12.448), train_loss = 1.54394140, grad/param norm = 2.1700e-01, time/batch = 0.7103s	
5665/22750 (epoch 12.451), train_loss = 1.41841856, grad/param norm = 1.8934e-01, time/batch = 0.6911s	
5666/22750 (epoch 12.453), train_loss = 1.47363968, grad/param norm = 2.0457e-01, time/batch = 0.6875s	
5667/22750 (epoch 12.455), train_loss = 1.56594205, grad/param norm = 2.1109e-01, time/batch = 0.6849s	
5668/22750 (epoch 12.457), train_loss = 1.40906401, grad/param norm = 2.3340e-01, time/batch = 0.6843s	
5669/22750 (epoch 12.459), train_loss = 1.36022641, grad/param norm = 2.0946e-01, time/batch = 0.6854s	
5670/22750 (epoch 12.462), train_loss = 1.36148962, grad/param norm = 1.7758e-01, time/batch = 0.6854s	
5671/22750 (epoch 12.464), train_loss = 1.06214286, grad/param norm = 1.8327e-01, time/batch = 0.6875s	
5672/22750 (epoch 12.466), train_loss = 1.47608633, grad/param norm = 2.1461e-01, time/batch = 0.6813s	
5673/22750 (epoch 12.468), train_loss = 1.21746455, grad/param norm = 1.9076e-01, time/batch = 0.6851s	
5674/22750 (epoch 12.470), train_loss = 1.38193458, grad/param norm = 2.0262e-01, time/batch = 0.6812s	
5675/22750 (epoch 12.473), train_loss = 1.23263102, grad/param norm = 1.9614e-01, time/batch = 0.6890s	
5676/22750 (epoch 12.475), train_loss = 1.26322584, grad/param norm = 1.9946e-01, time/batch = 0.6880s	
5677/22750 (epoch 12.477), train_loss = 1.03955026, grad/param norm = 1.6738e-01, time/batch = 0.6843s	
5678/22750 (epoch 12.479), train_loss = 1.05817168, grad/param norm = 1.6795e-01, time/batch = 0.6853s	
5679/22750 (epoch 12.481), train_loss = 0.98032305, grad/param norm = 1.6645e-01, time/batch = 0.6865s	
5680/22750 (epoch 12.484), train_loss = 0.93195250, grad/param norm = 1.8573e-01, time/batch = 0.6809s	
5681/22750 (epoch 12.486), train_loss = 1.08996236, grad/param norm = 1.9101e-01, time/batch = 0.6915s	
5682/22750 (epoch 12.488), train_loss = 0.95361702, grad/param norm = 2.1018e-01, time/batch = 0.6846s	
5683/22750 (epoch 12.490), train_loss = 1.23031911, grad/param norm = 1.8210e-01, time/batch = 0.6909s	
5684/22750 (epoch 12.492), train_loss = 1.37735537, grad/param norm = 1.9611e-01, time/batch = 0.6858s	
5685/22750 (epoch 12.495), train_loss = 1.12706926, grad/param norm = 1.7683e-01, time/batch = 0.6851s	
5686/22750 (epoch 12.497), train_loss = 1.26254141, grad/param norm = 2.0876e-01, time/batch = 0.6855s	
5687/22750 (epoch 12.499), train_loss = 1.13547983, grad/param norm = 1.8389e-01, time/batch = 0.6841s	
5688/22750 (epoch 12.501), train_loss = 1.24430272, grad/param norm = 1.9668e-01, time/batch = 0.6865s	
5689/22750 (epoch 12.503), train_loss = 1.24467826, grad/param norm = 1.8796e-01, time/batch = 0.6905s	
5690/22750 (epoch 12.505), train_loss = 1.08536940, grad/param norm = 1.8123e-01, time/batch = 0.6806s	
5691/22750 (epoch 12.508), train_loss = 1.02710609, grad/param norm = 1.8064e-01, time/batch = 0.6940s	
5692/22750 (epoch 12.510), train_loss = 1.06834192, grad/param norm = 1.6975e-01, time/batch = 0.6865s	
5693/22750 (epoch 12.512), train_loss = 1.11130264, grad/param norm = 1.6814e-01, time/batch = 0.6880s	
5694/22750 (epoch 12.514), train_loss = 1.13674710, grad/param norm = 1.6710e-01, time/batch = 0.6816s	
5695/22750 (epoch 12.516), train_loss = 1.11239675, grad/param norm = 1.8000e-01, time/batch = 0.6830s	
5696/22750 (epoch 12.519), train_loss = 1.32579298, grad/param norm = 1.8037e-01, time/batch = 0.6787s	
5697/22750 (epoch 12.521), train_loss = 1.17939005, grad/param norm = 1.7929e-01, time/batch = 0.6939s	
5698/22750 (epoch 12.523), train_loss = 1.15779473, grad/param norm = 1.8967e-01, time/batch = 0.6928s	
5699/22750 (epoch 12.525), train_loss = 1.43055035, grad/param norm = 1.9014e-01, time/batch = 0.6828s	
5700/22750 (epoch 12.527), train_loss = 1.22883908, grad/param norm = 1.7666e-01, time/batch = 0.6857s	
5701/22750 (epoch 12.530), train_loss = 1.17634704, grad/param norm = 1.9932e-01, time/batch = 0.6855s	
5702/22750 (epoch 12.532), train_loss = 1.05498995, grad/param norm = 1.6012e-01, time/batch = 0.6855s	
5703/22750 (epoch 12.534), train_loss = 1.33053704, grad/param norm = 1.8845e-01, time/batch = 0.6867s	
5704/22750 (epoch 12.536), train_loss = 1.24973442, grad/param norm = 1.8465e-01, time/batch = 0.6898s	
5705/22750 (epoch 12.538), train_loss = 1.22801856, grad/param norm = 1.6729e-01, time/batch = 0.6936s	
5706/22750 (epoch 12.541), train_loss = 1.04968589, grad/param norm = 1.7969e-01, time/batch = 0.6838s	
5707/22750 (epoch 12.543), train_loss = 1.07138634, grad/param norm = 1.7288e-01, time/batch = 0.6830s	
5708/22750 (epoch 12.545), train_loss = 1.35491461, grad/param norm = 1.7818e-01, time/batch = 0.6909s	
5709/22750 (epoch 12.547), train_loss = 1.07548896, grad/param norm = 1.5161e-01, time/batch = 0.6861s	
5710/22750 (epoch 12.549), train_loss = 1.14777916, grad/param norm = 1.8239e-01, time/batch = 0.6903s	
5711/22750 (epoch 12.552), train_loss = 1.30537592, grad/param norm = 1.9800e-01, time/batch = 0.6852s	
5712/22750 (epoch 12.554), train_loss = 1.32188518, grad/param norm = 2.0011e-01, time/batch = 0.6831s	
5713/22750 (epoch 12.556), train_loss = 1.23250503, grad/param norm = 1.9305e-01, time/batch = 0.6909s	
5714/22750 (epoch 12.558), train_loss = 1.35354118, grad/param norm = 1.8801e-01, time/batch = 0.6960s	
5715/22750 (epoch 12.560), train_loss = 1.15217495, grad/param norm = 1.7424e-01, time/batch = 0.7021s	
5716/22750 (epoch 12.563), train_loss = 1.34174831, grad/param norm = 1.7625e-01, time/batch = 0.7189s	
5717/22750 (epoch 12.565), train_loss = 1.29783591, grad/param norm = 1.8268e-01, time/batch = 0.7116s	
5718/22750 (epoch 12.567), train_loss = 1.28575656, grad/param norm = 1.9780e-01, time/batch = 0.7009s	
5719/22750 (epoch 12.569), train_loss = 1.19236081, grad/param norm = 1.7852e-01, time/batch = 0.6858s	
5720/22750 (epoch 12.571), train_loss = 1.24034228, grad/param norm = 1.8976e-01, time/batch = 0.7056s	
5721/22750 (epoch 12.574), train_loss = 1.11390500, grad/param norm = 1.7404e-01, time/batch = 0.7058s	
5722/22750 (epoch 12.576), train_loss = 1.24040621, grad/param norm = 1.9297e-01, time/batch = 0.6868s	
5723/22750 (epoch 12.578), train_loss = 1.07951270, grad/param norm = 1.7907e-01, time/batch = 0.6813s	
5724/22750 (epoch 12.580), train_loss = 1.25063195, grad/param norm = 2.0779e-01, time/batch = 0.6833s	
5725/22750 (epoch 12.582), train_loss = 1.06583320, grad/param norm = 1.6938e-01, time/batch = 0.6813s	
5726/22750 (epoch 12.585), train_loss = 0.99706727, grad/param norm = 1.8228e-01, time/batch = 0.6793s	
5727/22750 (epoch 12.587), train_loss = 1.02213605, grad/param norm = 1.6179e-01, time/batch = 0.7218s	
5728/22750 (epoch 12.589), train_loss = 1.01695858, grad/param norm = 1.7547e-01, time/batch = 0.7086s	
5729/22750 (epoch 12.591), train_loss = 1.17076271, grad/param norm = 1.8102e-01, time/batch = 0.7126s	
5730/22750 (epoch 12.593), train_loss = 1.42119904, grad/param norm = 1.8931e-01, time/batch = 0.7112s	
5731/22750 (epoch 12.596), train_loss = 1.40996024, grad/param norm = 2.0011e-01, time/batch = 0.7147s	
5732/22750 (epoch 12.598), train_loss = 1.43179854, grad/param norm = 1.9290e-01, time/batch = 0.7109s	
5733/22750 (epoch 12.600), train_loss = 1.37755745, grad/param norm = 1.9476e-01, time/batch = 0.6936s	
5734/22750 (epoch 12.602), train_loss = 1.09165352, grad/param norm = 1.6059e-01, time/batch = 0.6918s	
5735/22750 (epoch 12.604), train_loss = 1.15202273, grad/param norm = 1.7250e-01, time/batch = 0.6814s	
5736/22750 (epoch 12.607), train_loss = 0.99985819, grad/param norm = 1.6226e-01, time/batch = 0.6918s	
5737/22750 (epoch 12.609), train_loss = 0.94688883, grad/param norm = 1.5663e-01, time/batch = 0.6871s	
5738/22750 (epoch 12.611), train_loss = 1.15456323, grad/param norm = 1.8378e-01, time/batch = 0.6825s	
5739/22750 (epoch 12.613), train_loss = 1.07734318, grad/param norm = 1.8364e-01, time/batch = 0.6868s	
5740/22750 (epoch 12.615), train_loss = 1.13908032, grad/param norm = 1.6976e-01, time/batch = 0.6843s	
5741/22750 (epoch 12.618), train_loss = 1.15704641, grad/param norm = 1.6922e-01, time/batch = 0.6796s	
5742/22750 (epoch 12.620), train_loss = 1.19251115, grad/param norm = 1.8545e-01, time/batch = 0.6827s	
5743/22750 (epoch 12.622), train_loss = 0.98618095, grad/param norm = 1.6457e-01, time/batch = 0.6867s	
5744/22750 (epoch 12.624), train_loss = 1.13922768, grad/param norm = 1.8228e-01, time/batch = 0.7032s	
5745/22750 (epoch 12.626), train_loss = 1.04135775, grad/param norm = 1.8744e-01, time/batch = 0.6908s	
5746/22750 (epoch 12.629), train_loss = 1.16541186, grad/param norm = 1.8513e-01, time/batch = 0.6829s	
5747/22750 (epoch 12.631), train_loss = 1.18463918, grad/param norm = 1.8009e-01, time/batch = 0.6834s	
5748/22750 (epoch 12.633), train_loss = 1.00420875, grad/param norm = 1.7047e-01, time/batch = 0.6793s	
5749/22750 (epoch 12.635), train_loss = 1.22217801, grad/param norm = 1.9421e-01, time/batch = 0.8216s	
5750/22750 (epoch 12.637), train_loss = 1.29722956, grad/param norm = 2.1416e-01, time/batch = 1.0004s	
5751/22750 (epoch 12.640), train_loss = 1.31130330, grad/param norm = 1.8673e-01, time/batch = 0.9994s	
5752/22750 (epoch 12.642), train_loss = 1.37169124, grad/param norm = 1.9220e-01, time/batch = 1.0016s	
5753/22750 (epoch 12.644), train_loss = 1.23686612, grad/param norm = 1.8853e-01, time/batch = 0.9969s	
5754/22750 (epoch 12.646), train_loss = 1.34568878, grad/param norm = 2.0534e-01, time/batch = 1.4127s	
5755/22750 (epoch 12.648), train_loss = 1.23506204, grad/param norm = 2.0421e-01, time/batch = 1.8624s	
5756/22750 (epoch 12.651), train_loss = 1.32165512, grad/param norm = 1.9511e-01, time/batch = 1.8931s	
5757/22750 (epoch 12.653), train_loss = 1.29223601, grad/param norm = 1.8906e-01, time/batch = 17.5251s	
5758/22750 (epoch 12.655), train_loss = 1.21736273, grad/param norm = 1.8343e-01, time/batch = 19.0216s	
5759/22750 (epoch 12.657), train_loss = 1.41987295, grad/param norm = 2.0002e-01, time/batch = 18.8446s	
5760/22750 (epoch 12.659), train_loss = 1.49700725, grad/param norm = 1.9930e-01, time/batch = 18.7427s	
5761/22750 (epoch 12.662), train_loss = 1.50823585, grad/param norm = 2.2615e-01, time/batch = 17.0655s	
5762/22750 (epoch 12.664), train_loss = 1.29324949, grad/param norm = 1.9930e-01, time/batch = 3.7770s	
5763/22750 (epoch 12.666), train_loss = 1.09115831, grad/param norm = 1.8462e-01, time/batch = 0.6956s	
5764/22750 (epoch 12.668), train_loss = 1.25068213, grad/param norm = 1.8218e-01, time/batch = 0.7103s	
5765/22750 (epoch 12.670), train_loss = 1.24423569, grad/param norm = 1.8412e-01, time/batch = 0.7230s	
5766/22750 (epoch 12.673), train_loss = 1.53271601, grad/param norm = 2.1902e-01, time/batch = 0.7120s	
5767/22750 (epoch 12.675), train_loss = 1.70195339, grad/param norm = 2.1614e-01, time/batch = 0.6855s	
5768/22750 (epoch 12.677), train_loss = 1.44598111, grad/param norm = 2.3068e-01, time/batch = 0.6916s	
5769/22750 (epoch 12.679), train_loss = 1.49311298, grad/param norm = 2.1090e-01, time/batch = 0.8980s	
5770/22750 (epoch 12.681), train_loss = 1.43380480, grad/param norm = 2.1185e-01, time/batch = 1.0169s	
5771/22750 (epoch 12.684), train_loss = 1.40886527, grad/param norm = 2.0097e-01, time/batch = 1.0205s	
5772/22750 (epoch 12.686), train_loss = 1.38114035, grad/param norm = 2.0024e-01, time/batch = 1.0111s	
5773/22750 (epoch 12.688), train_loss = 1.37559336, grad/param norm = 2.0443e-01, time/batch = 1.0369s	
5774/22750 (epoch 12.690), train_loss = 1.37424987, grad/param norm = 2.0896e-01, time/batch = 1.7502s	
5775/22750 (epoch 12.692), train_loss = 1.45987238, grad/param norm = 1.9819e-01, time/batch = 1.9034s	
5776/22750 (epoch 12.695), train_loss = 1.26790529, grad/param norm = 1.8644e-01, time/batch = 4.8452s	
5777/22750 (epoch 12.697), train_loss = 1.21334904, grad/param norm = 1.8662e-01, time/batch = 16.8407s	
5778/22750 (epoch 12.699), train_loss = 1.26128925, grad/param norm = 1.8745e-01, time/batch = 17.0207s	
5779/22750 (epoch 12.701), train_loss = 1.08718037, grad/param norm = 1.7990e-01, time/batch = 15.7952s	
5780/22750 (epoch 12.703), train_loss = 1.26462012, grad/param norm = 1.7910e-01, time/batch = 20.1209s	
5781/22750 (epoch 12.705), train_loss = 1.14353098, grad/param norm = 1.6828e-01, time/batch = 18.4316s	
5782/22750 (epoch 12.708), train_loss = 1.25916095, grad/param norm = 1.8286e-01, time/batch = 16.6157s	
5783/22750 (epoch 12.710), train_loss = 1.06943343, grad/param norm = 1.7480e-01, time/batch = 15.9511s	
5784/22750 (epoch 12.712), train_loss = 1.14067994, grad/param norm = 1.7866e-01, time/batch = 17.5993s	
5785/22750 (epoch 12.714), train_loss = 1.01341206, grad/param norm = 1.6998e-01, time/batch = 18.0890s	
5786/22750 (epoch 12.716), train_loss = 1.10300769, grad/param norm = 1.8066e-01, time/batch = 17.6862s	
5787/22750 (epoch 12.719), train_loss = 1.32040422, grad/param norm = 2.0739e-01, time/batch = 16.6786s	
5788/22750 (epoch 12.721), train_loss = 1.34195139, grad/param norm = 1.8245e-01, time/batch = 19.4200s	
5789/22750 (epoch 12.723), train_loss = 1.24897507, grad/param norm = 1.8733e-01, time/batch = 17.9449s	
5790/22750 (epoch 12.725), train_loss = 1.20876729, grad/param norm = 1.8640e-01, time/batch = 19.7828s	
5791/22750 (epoch 12.727), train_loss = 1.15337787, grad/param norm = 1.7219e-01, time/batch = 19.9486s	
5792/22750 (epoch 12.730), train_loss = 1.18263000, grad/param norm = 1.8412e-01, time/batch = 17.0035s	
5793/22750 (epoch 12.732), train_loss = 1.15333084, grad/param norm = 1.7520e-01, time/batch = 17.0974s	
5794/22750 (epoch 12.734), train_loss = 0.96594389, grad/param norm = 1.7254e-01, time/batch = 17.4300s	
5795/22750 (epoch 12.736), train_loss = 1.14381786, grad/param norm = 1.8410e-01, time/batch = 18.4171s	
5796/22750 (epoch 12.738), train_loss = 1.26496460, grad/param norm = 2.0388e-01, time/batch = 19.0734s	
5797/22750 (epoch 12.741), train_loss = 1.34625110, grad/param norm = 2.0251e-01, time/batch = 17.6797s	
5798/22750 (epoch 12.743), train_loss = 1.26437759, grad/param norm = 1.8438e-01, time/batch = 19.5184s	
5799/22750 (epoch 12.745), train_loss = 1.07381058, grad/param norm = 1.6894e-01, time/batch = 18.9978s	
5800/22750 (epoch 12.747), train_loss = 1.15056549, grad/param norm = 1.7918e-01, time/batch = 19.7536s	
5801/22750 (epoch 12.749), train_loss = 1.44676753, grad/param norm = 2.1447e-01, time/batch = 18.5601s	
5802/22750 (epoch 12.752), train_loss = 1.17063003, grad/param norm = 1.8303e-01, time/batch = 16.9201s	
5803/22750 (epoch 12.754), train_loss = 1.31608737, grad/param norm = 2.1721e-01, time/batch = 17.0087s	
5804/22750 (epoch 12.756), train_loss = 1.09945489, grad/param norm = 2.0505e-01, time/batch = 18.3896s	
5805/22750 (epoch 12.758), train_loss = 1.08593574, grad/param norm = 1.7677e-01, time/batch = 18.3279s	
5806/22750 (epoch 12.760), train_loss = 1.20852480, grad/param norm = 1.7812e-01, time/batch = 19.2553s	
5807/22750 (epoch 12.763), train_loss = 1.28517603, grad/param norm = 1.9719e-01, time/batch = 20.8517s	
5808/22750 (epoch 12.765), train_loss = 1.20134823, grad/param norm = 2.0684e-01, time/batch = 19.1743s	
5809/22750 (epoch 12.767), train_loss = 1.24024851, grad/param norm = 1.9035e-01, time/batch = 20.5914s	
5810/22750 (epoch 12.769), train_loss = 1.46556995, grad/param norm = 2.1900e-01, time/batch = 17.9973s	
5811/22750 (epoch 12.771), train_loss = 1.41012428, grad/param norm = 1.9621e-01, time/batch = 18.0563s	
5812/22750 (epoch 12.774), train_loss = 1.14554683, grad/param norm = 1.9348e-01, time/batch = 19.0638s	
5813/22750 (epoch 12.776), train_loss = 1.24135442, grad/param norm = 1.9607e-01, time/batch = 19.3170s	
5814/22750 (epoch 12.778), train_loss = 1.43485127, grad/param norm = 1.8713e-01, time/batch = 17.3970s	
5815/22750 (epoch 12.780), train_loss = 1.26821877, grad/param norm = 1.8982e-01, time/batch = 16.3455s	
5816/22750 (epoch 12.782), train_loss = 1.40916612, grad/param norm = 1.8559e-01, time/batch = 16.4038s	
5817/22750 (epoch 12.785), train_loss = 1.22886223, grad/param norm = 1.8208e-01, time/batch = 17.8777s	
5818/22750 (epoch 12.787), train_loss = 1.11378525, grad/param norm = 1.8125e-01, time/batch = 17.7834s	
5819/22750 (epoch 12.789), train_loss = 1.20183037, grad/param norm = 1.8709e-01, time/batch = 18.5828s	
5820/22750 (epoch 12.791), train_loss = 1.20152004, grad/param norm = 1.7979e-01, time/batch = 19.8315s	
5821/22750 (epoch 12.793), train_loss = 1.14977841, grad/param norm = 1.8288e-01, time/batch = 16.8274s	
5822/22750 (epoch 12.796), train_loss = 1.04247793, grad/param norm = 1.7313e-01, time/batch = 16.9275s	
5823/22750 (epoch 12.798), train_loss = 1.09184710, grad/param norm = 1.6450e-01, time/batch = 19.9051s	
5824/22750 (epoch 12.800), train_loss = 1.11613619, grad/param norm = 1.6995e-01, time/batch = 17.7518s	
5825/22750 (epoch 12.802), train_loss = 1.08734296, grad/param norm = 1.8337e-01, time/batch = 19.9982s	
5826/22750 (epoch 12.804), train_loss = 1.43168806, grad/param norm = 1.9032e-01, time/batch = 19.1189s	
5827/22750 (epoch 12.807), train_loss = 1.26941803, grad/param norm = 1.7534e-01, time/batch = 18.5010s	
5828/22750 (epoch 12.809), train_loss = 1.48283082, grad/param norm = 2.1665e-01, time/batch = 19.0698s	
5829/22750 (epoch 12.811), train_loss = 1.15279375, grad/param norm = 1.7026e-01, time/batch = 20.4775s	
5830/22750 (epoch 12.813), train_loss = 1.25527820, grad/param norm = 1.6780e-01, time/batch = 19.9043s	
5831/22750 (epoch 12.815), train_loss = 1.41997054, grad/param norm = 2.0134e-01, time/batch = 19.6545s	
5832/22750 (epoch 12.818), train_loss = 1.39440038, grad/param norm = 1.8377e-01, time/batch = 19.1493s	
5833/22750 (epoch 12.820), train_loss = 1.51100121, grad/param norm = 1.9090e-01, time/batch = 18.8241s	
5834/22750 (epoch 12.822), train_loss = 1.26592382, grad/param norm = 1.8469e-01, time/batch = 19.8395s	
5835/22750 (epoch 12.824), train_loss = 1.16695531, grad/param norm = 1.7929e-01, time/batch = 19.2823s	
5836/22750 (epoch 12.826), train_loss = 1.25996885, grad/param norm = 1.8282e-01, time/batch = 15.3804s	
5837/22750 (epoch 12.829), train_loss = 1.43082415, grad/param norm = 1.9512e-01, time/batch = 18.4294s	
5838/22750 (epoch 12.831), train_loss = 1.39040302, grad/param norm = 1.9072e-01, time/batch = 16.3200s	
5839/22750 (epoch 12.833), train_loss = 1.26892647, grad/param norm = 1.8288e-01, time/batch = 16.9200s	
5840/22750 (epoch 12.835), train_loss = 1.19195712, grad/param norm = 1.7977e-01, time/batch = 20.8823s	
5841/22750 (epoch 12.837), train_loss = 1.18303366, grad/param norm = 1.9261e-01, time/batch = 26.5295s	
5842/22750 (epoch 12.840), train_loss = 1.12391826, grad/param norm = 1.6906e-01, time/batch = 19.0068s	
5843/22750 (epoch 12.842), train_loss = 1.17319210, grad/param norm = 1.8472e-01, time/batch = 18.6090s	
5844/22750 (epoch 12.844), train_loss = 1.33470364, grad/param norm = 1.8403e-01, time/batch = 20.2749s	
5845/22750 (epoch 12.846), train_loss = 1.23780459, grad/param norm = 1.8257e-01, time/batch = 20.4374s	
5846/22750 (epoch 12.848), train_loss = 1.11919663, grad/param norm = 1.7302e-01, time/batch = 17.9036s	
5847/22750 (epoch 12.851), train_loss = 1.12974920, grad/param norm = 1.7337e-01, time/batch = 18.0191s	
5848/22750 (epoch 12.853), train_loss = 1.25754623, grad/param norm = 1.7375e-01, time/batch = 18.5053s	
5849/22750 (epoch 12.855), train_loss = 1.04578646, grad/param norm = 1.7875e-01, time/batch = 18.0855s	
5850/22750 (epoch 12.857), train_loss = 1.26209538, grad/param norm = 1.8248e-01, time/batch = 19.0741s	
5851/22750 (epoch 12.859), train_loss = 1.29570706, grad/param norm = 1.9622e-01, time/batch = 18.3406s	
5852/22750 (epoch 12.862), train_loss = 1.42866778, grad/param norm = 2.0182e-01, time/batch = 15.7283s	
5853/22750 (epoch 12.864), train_loss = 1.22043775, grad/param norm = 1.8150e-01, time/batch = 18.4879s	
5854/22750 (epoch 12.866), train_loss = 1.26523326, grad/param norm = 1.6963e-01, time/batch = 20.4434s	
5855/22750 (epoch 12.868), train_loss = 1.15768394, grad/param norm = 1.6289e-01, time/batch = 19.9035s	
5856/22750 (epoch 12.870), train_loss = 1.03992315, grad/param norm = 1.7577e-01, time/batch = 17.0620s	
5857/22750 (epoch 12.873), train_loss = 1.17211388, grad/param norm = 1.7655e-01, time/batch = 17.4151s	
5858/22750 (epoch 12.875), train_loss = 1.30298235, grad/param norm = 1.8051e-01, time/batch = 17.2647s	
5859/22750 (epoch 12.877), train_loss = 1.16027292, grad/param norm = 1.7480e-01, time/batch = 17.2664s	
5860/22750 (epoch 12.879), train_loss = 1.35722065, grad/param norm = 1.9313e-01, time/batch = 18.0231s	
5861/22750 (epoch 12.881), train_loss = 1.35131826, grad/param norm = 1.9332e-01, time/batch = 20.8510s	
5862/22750 (epoch 12.884), train_loss = 1.11660501, grad/param norm = 1.7994e-01, time/batch = 20.2687s	
5863/22750 (epoch 12.886), train_loss = 1.30342354, grad/param norm = 1.8131e-01, time/batch = 18.3396s	
5864/22750 (epoch 12.888), train_loss = 1.30245800, grad/param norm = 1.8405e-01, time/batch = 16.9680s	
5865/22750 (epoch 12.890), train_loss = 1.36224162, grad/param norm = 1.9196e-01, time/batch = 16.5765s	
5866/22750 (epoch 12.892), train_loss = 1.65400670, grad/param norm = 2.4078e-01, time/batch = 16.0644s	
5867/22750 (epoch 12.895), train_loss = 1.32336104, grad/param norm = 1.7640e-01, time/batch = 15.6622s	
5868/22750 (epoch 12.897), train_loss = 1.35960734, grad/param norm = 1.9370e-01, time/batch = 15.2765s	
5869/22750 (epoch 12.899), train_loss = 1.27162078, grad/param norm = 1.7569e-01, time/batch = 15.6126s	
5870/22750 (epoch 12.901), train_loss = 1.45024842, grad/param norm = 1.9978e-01, time/batch = 15.7688s	
5871/22750 (epoch 12.903), train_loss = 1.22898021, grad/param norm = 1.9407e-01, time/batch = 16.3296s	
5872/22750 (epoch 12.905), train_loss = 1.33596295, grad/param norm = 1.8282e-01, time/batch = 15.5265s	
5873/22750 (epoch 12.908), train_loss = 1.18959165, grad/param norm = 2.0493e-01, time/batch = 15.7001s	
5874/22750 (epoch 12.910), train_loss = 1.00758680, grad/param norm = 1.8993e-01, time/batch = 15.6840s	
5875/22750 (epoch 12.912), train_loss = 1.15211593, grad/param norm = 1.8237e-01, time/batch = 15.1248s	
5876/22750 (epoch 12.914), train_loss = 1.23063067, grad/param norm = 1.8681e-01, time/batch = 15.0406s	
5877/22750 (epoch 12.916), train_loss = 1.03648180, grad/param norm = 1.6925e-01, time/batch = 16.1539s	
5878/22750 (epoch 12.919), train_loss = 1.14689377, grad/param norm = 1.8024e-01, time/batch = 15.4483s	
5879/22750 (epoch 12.921), train_loss = 0.86689365, grad/param norm = 1.4752e-01, time/batch = 15.3655s	
5880/22750 (epoch 12.923), train_loss = 1.13184792, grad/param norm = 1.7364e-01, time/batch = 15.0712s	
5881/22750 (epoch 12.925), train_loss = 1.19048577, grad/param norm = 1.7158e-01, time/batch = 15.5607s	
5882/22750 (epoch 12.927), train_loss = 0.96931294, grad/param norm = 1.7855e-01, time/batch = 15.6306s	
5883/22750 (epoch 12.930), train_loss = 1.01346928, grad/param norm = 1.7137e-01, time/batch = 15.3838s	
5884/22750 (epoch 12.932), train_loss = 1.27275358, grad/param norm = 1.8663e-01, time/batch = 15.3636s	
5885/22750 (epoch 12.934), train_loss = 0.91185156, grad/param norm = 1.4105e-01, time/batch = 15.9296s	
5886/22750 (epoch 12.936), train_loss = 1.33862151, grad/param norm = 1.9695e-01, time/batch = 15.1211s	
5887/22750 (epoch 12.938), train_loss = 1.27398252, grad/param norm = 1.7258e-01, time/batch = 15.2806s	
5888/22750 (epoch 12.941), train_loss = 1.46371548, grad/param norm = 1.9105e-01, time/batch = 16.2088s	
5889/22750 (epoch 12.943), train_loss = 1.27917863, grad/param norm = 1.8949e-01, time/batch = 16.3167s	
5890/22750 (epoch 12.945), train_loss = 1.24835437, grad/param norm = 1.8826e-01, time/batch = 15.7128s	
5891/22750 (epoch 12.947), train_loss = 1.17636600, grad/param norm = 1.9616e-01, time/batch = 16.4711s	
5892/22750 (epoch 12.949), train_loss = 1.09772629, grad/param norm = 1.8942e-01, time/batch = 17.1163s	
5893/22750 (epoch 12.952), train_loss = 1.13365154, grad/param norm = 1.7204e-01, time/batch = 17.8707s	
5894/22750 (epoch 12.954), train_loss = 1.09115653, grad/param norm = 1.7082e-01, time/batch = 17.0927s	
5895/22750 (epoch 12.956), train_loss = 1.21317390, grad/param norm = 1.7207e-01, time/batch = 16.7864s	
5896/22750 (epoch 12.958), train_loss = 1.14278202, grad/param norm = 1.6958e-01, time/batch = 17.5856s	
5897/22750 (epoch 12.960), train_loss = 1.14450575, grad/param norm = 1.6949e-01, time/batch = 18.3483s	
5898/22750 (epoch 12.963), train_loss = 1.36999309, grad/param norm = 1.9566e-01, time/batch = 20.0753s	
5899/22750 (epoch 12.965), train_loss = 1.31553395, grad/param norm = 1.8976e-01, time/batch = 16.9031s	
5900/22750 (epoch 12.967), train_loss = 1.21427386, grad/param norm = 1.9922e-01, time/batch = 18.3602s	
5901/22750 (epoch 12.969), train_loss = 1.16066466, grad/param norm = 1.8176e-01, time/batch = 20.4341s	
5902/22750 (epoch 12.971), train_loss = 1.14902946, grad/param norm = 1.8208e-01, time/batch = 16.5044s	
5903/22750 (epoch 12.974), train_loss = 1.23757847, grad/param norm = 1.9477e-01, time/batch = 17.5584s	
5904/22750 (epoch 12.976), train_loss = 1.31351869, grad/param norm = 2.1216e-01, time/batch = 19.9928s	
5905/22750 (epoch 12.978), train_loss = 1.08832202, grad/param norm = 1.6280e-01, time/batch = 19.0875s	
5906/22750 (epoch 12.980), train_loss = 1.38365813, grad/param norm = 2.0424e-01, time/batch = 18.4097s	
5907/22750 (epoch 12.982), train_loss = 1.15066256, grad/param norm = 1.6496e-01, time/batch = 17.1665s	
5908/22750 (epoch 12.985), train_loss = 1.46098437, grad/param norm = 2.1294e-01, time/batch = 17.5585s	
5909/22750 (epoch 12.987), train_loss = 0.98547236, grad/param norm = 1.6182e-01, time/batch = 16.8901s	
5910/22750 (epoch 12.989), train_loss = 1.15789888, grad/param norm = 1.7381e-01, time/batch = 18.2752s	
5911/22750 (epoch 12.991), train_loss = 1.29399783, grad/param norm = 1.9888e-01, time/batch = 17.9460s	
5912/22750 (epoch 12.993), train_loss = 1.35579300, grad/param norm = 1.9326e-01, time/batch = 17.2995s	
5913/22750 (epoch 12.996), train_loss = 1.16165795, grad/param norm = 2.1288e-01, time/batch = 17.3458s	
5914/22750 (epoch 12.998), train_loss = 1.39263525, grad/param norm = 1.9569e-01, time/batch = 18.0971s	
decayed learning rate by a factor 0.97 to 0.00177058562	
5915/22750 (epoch 13.000), train_loss = 1.27906705, grad/param norm = 1.9570e-01, time/batch = 18.5908s	
5916/22750 (epoch 13.002), train_loss = 1.34928042, grad/param norm = 2.0224e-01, time/batch = 15.7749s	
5917/22750 (epoch 13.004), train_loss = 1.13707666, grad/param norm = 1.7538e-01, time/batch = 16.8503s	
5918/22750 (epoch 13.007), train_loss = 1.20693968, grad/param norm = 1.9561e-01, time/batch = 16.9066s	
5919/22750 (epoch 13.009), train_loss = 1.46766802, grad/param norm = 1.9160e-01, time/batch = 17.5404s	
5920/22750 (epoch 13.011), train_loss = 1.49450207, grad/param norm = 1.9853e-01, time/batch = 18.7048s	
5921/22750 (epoch 13.013), train_loss = 1.31959779, grad/param norm = 1.7970e-01, time/batch = 19.3742s	
5922/22750 (epoch 13.015), train_loss = 1.28686565, grad/param norm = 1.9690e-01, time/batch = 17.4216s	
5923/22750 (epoch 13.018), train_loss = 1.29573030, grad/param norm = 1.9234e-01, time/batch = 17.7583s	
5924/22750 (epoch 13.020), train_loss = 1.42747387, grad/param norm = 1.9929e-01, time/batch = 19.6629s	
5925/22750 (epoch 13.022), train_loss = 1.20310760, grad/param norm = 1.8049e-01, time/batch = 18.8140s	
5926/22750 (epoch 13.024), train_loss = 1.24736650, grad/param norm = 1.9723e-01, time/batch = 19.5712s	
5927/22750 (epoch 13.026), train_loss = 1.33016959, grad/param norm = 2.0147e-01, time/batch = 18.5182s	
5928/22750 (epoch 13.029), train_loss = 1.01577621, grad/param norm = 1.6953e-01, time/batch = 16.1935s	
5929/22750 (epoch 13.031), train_loss = 1.52947753, grad/param norm = 2.0186e-01, time/batch = 16.6012s	
5930/22750 (epoch 13.033), train_loss = 1.24484153, grad/param norm = 1.8709e-01, time/batch = 16.2453s	
5931/22750 (epoch 13.035), train_loss = 1.29869154, grad/param norm = 1.9282e-01, time/batch = 15.7261s	
5932/22750 (epoch 13.037), train_loss = 1.37635573, grad/param norm = 1.8572e-01, time/batch = 16.2494s	
5933/22750 (epoch 13.040), train_loss = 1.17792246, grad/param norm = 1.8296e-01, time/batch = 16.0199s	
5934/22750 (epoch 13.042), train_loss = 1.34579615, grad/param norm = 1.9510e-01, time/batch = 17.6642s	
5935/22750 (epoch 13.044), train_loss = 1.17891899, grad/param norm = 1.8445e-01, time/batch = 19.3337s	
5936/22750 (epoch 13.046), train_loss = 1.32893120, grad/param norm = 2.0760e-01, time/batch = 16.2634s	
5937/22750 (epoch 13.048), train_loss = 1.22207261, grad/param norm = 1.7903e-01, time/batch = 16.8540s	
5938/22750 (epoch 13.051), train_loss = 1.28424585, grad/param norm = 1.8026e-01, time/batch = 16.5611s	
5939/22750 (epoch 13.053), train_loss = 1.09970527, grad/param norm = 1.7324e-01, time/batch = 16.8371s	
5940/22750 (epoch 13.055), train_loss = 1.16507826, grad/param norm = 1.7840e-01, time/batch = 17.2001s	
5941/22750 (epoch 13.057), train_loss = 1.39328924, grad/param norm = 1.9136e-01, time/batch = 16.6809s	
5942/22750 (epoch 13.059), train_loss = 0.91428130, grad/param norm = 1.7057e-01, time/batch = 17.1751s	
5943/22750 (epoch 13.062), train_loss = 1.07747648, grad/param norm = 1.7863e-01, time/batch = 16.7102s	
5944/22750 (epoch 13.064), train_loss = 1.27759198, grad/param norm = 1.9715e-01, time/batch = 16.1598s	
5945/22750 (epoch 13.066), train_loss = 1.05292550, grad/param norm = 1.6556e-01, time/batch = 15.2819s	
5946/22750 (epoch 13.068), train_loss = 1.12482121, grad/param norm = 1.5722e-01, time/batch = 15.1266s	
5947/22750 (epoch 13.070), train_loss = 0.98932954, grad/param norm = 1.6994e-01, time/batch = 15.6095s	
5948/22750 (epoch 13.073), train_loss = 1.14355296, grad/param norm = 1.9900e-01, time/batch = 15.1569s	
5949/22750 (epoch 13.075), train_loss = 1.18748190, grad/param norm = 1.7991e-01, time/batch = 15.9372s	
5950/22750 (epoch 13.077), train_loss = 0.93972541, grad/param norm = 1.7701e-01, time/batch = 15.7616s	
5951/22750 (epoch 13.079), train_loss = 1.16684406, grad/param norm = 1.9425e-01, time/batch = 15.6921s	
5952/22750 (epoch 13.081), train_loss = 1.17841331, grad/param norm = 1.9502e-01, time/batch = 15.4503s	
5953/22750 (epoch 13.084), train_loss = 1.14969541, grad/param norm = 1.7903e-01, time/batch = 15.2800s	
5954/22750 (epoch 13.086), train_loss = 1.14702441, grad/param norm = 1.6153e-01, time/batch = 15.3547s	
5955/22750 (epoch 13.088), train_loss = 1.13650151, grad/param norm = 1.8784e-01, time/batch = 15.6628s	
5956/22750 (epoch 13.090), train_loss = 1.12486143, grad/param norm = 1.7046e-01, time/batch = 15.2044s	
5957/22750 (epoch 13.092), train_loss = 1.36906816, grad/param norm = 1.7999e-01, time/batch = 15.2085s	
5958/22750 (epoch 13.095), train_loss = 1.07930490, grad/param norm = 1.8200e-01, time/batch = 15.5327s	
5959/22750 (epoch 13.097), train_loss = 1.17337769, grad/param norm = 1.7706e-01, time/batch = 15.3698s	
5960/22750 (epoch 13.099), train_loss = 1.20971212, grad/param norm = 1.8304e-01, time/batch = 15.2969s	
5961/22750 (epoch 13.101), train_loss = 1.11294242, grad/param norm = 1.8889e-01, time/batch = 15.3080s	
5962/22750 (epoch 13.103), train_loss = 1.18431779, grad/param norm = 1.8416e-01, time/batch = 15.7840s	
5963/22750 (epoch 13.105), train_loss = 1.47698379, grad/param norm = 2.0233e-01, time/batch = 15.4429s	
5964/22750 (epoch 13.108), train_loss = 1.15907907, grad/param norm = 1.8236e-01, time/batch = 15.0449s	
5965/22750 (epoch 13.110), train_loss = 1.33253184, grad/param norm = 1.9723e-01, time/batch = 15.1048s	
5966/22750 (epoch 13.112), train_loss = 1.00769715, grad/param norm = 1.6424e-01, time/batch = 15.7585s	
5967/22750 (epoch 13.114), train_loss = 0.95316346, grad/param norm = 1.7471e-01, time/batch = 15.3613s	
5968/22750 (epoch 13.116), train_loss = 1.08015398, grad/param norm = 1.6619e-01, time/batch = 15.3603s	
5969/22750 (epoch 13.119), train_loss = 1.08412903, grad/param norm = 1.5802e-01, time/batch = 16.3224s	
5970/22750 (epoch 13.121), train_loss = 1.25431519, grad/param norm = 1.9692e-01, time/batch = 16.1784s	
5971/22750 (epoch 13.123), train_loss = 1.07536603, grad/param norm = 1.7179e-01, time/batch = 16.5211s	
5972/22750 (epoch 13.125), train_loss = 1.36385449, grad/param norm = 1.8563e-01, time/batch = 16.2618s	
5973/22750 (epoch 13.127), train_loss = 1.18946323, grad/param norm = 1.9168e-01, time/batch = 15.7034s	
5974/22750 (epoch 13.130), train_loss = 1.27027311, grad/param norm = 1.8206e-01, time/batch = 15.4617s	
5975/22750 (epoch 13.132), train_loss = 1.18002022, grad/param norm = 1.9016e-01, time/batch = 16.0037s	
5976/22750 (epoch 13.134), train_loss = 1.15225589, grad/param norm = 1.7441e-01, time/batch = 15.9284s	
5977/22750 (epoch 13.136), train_loss = 1.04205917, grad/param norm = 1.7841e-01, time/batch = 15.7655s	
5978/22750 (epoch 13.138), train_loss = 1.24709613, grad/param norm = 1.8734e-01, time/batch = 16.1019s	
5979/22750 (epoch 13.141), train_loss = 1.18713653, grad/param norm = 1.8411e-01, time/batch = 15.5480s	
5980/22750 (epoch 13.143), train_loss = 1.02725120, grad/param norm = 1.6701e-01, time/batch = 15.7301s	
5981/22750 (epoch 13.145), train_loss = 1.36895808, grad/param norm = 1.9186e-01, time/batch = 16.4440s	
5982/22750 (epoch 13.147), train_loss = 1.34690139, grad/param norm = 1.9424e-01, time/batch = 15.7135s	
5983/22750 (epoch 13.149), train_loss = 1.20517058, grad/param norm = 1.8102e-01, time/batch = 15.2166s	
5984/22750 (epoch 13.152), train_loss = 1.14834089, grad/param norm = 1.7800e-01, time/batch = 15.2074s	
5985/22750 (epoch 13.154), train_loss = 0.99572601, grad/param norm = 1.7797e-01, time/batch = 15.4425s	
5986/22750 (epoch 13.156), train_loss = 1.03775296, grad/param norm = 1.7015e-01, time/batch = 15.0436s	
5987/22750 (epoch 13.158), train_loss = 1.13158424, grad/param norm = 2.0124e-01, time/batch = 15.0120s	
5988/22750 (epoch 13.160), train_loss = 1.26467461, grad/param norm = 1.8355e-01, time/batch = 15.0438s	
5989/22750 (epoch 13.163), train_loss = 1.46675191, grad/param norm = 2.0306e-01, time/batch = 15.3534s	
5990/22750 (epoch 13.165), train_loss = 1.29319571, grad/param norm = 1.8464e-01, time/batch = 15.4457s	
5991/22750 (epoch 13.167), train_loss = 1.15936682, grad/param norm = 1.8459e-01, time/batch = 15.3874s	
5992/22750 (epoch 13.169), train_loss = 1.23205078, grad/param norm = 1.9241e-01, time/batch = 15.9207s	
5993/22750 (epoch 13.171), train_loss = 1.07122951, grad/param norm = 1.7287e-01, time/batch = 16.0286s	
5994/22750 (epoch 13.174), train_loss = 1.01004436, grad/param norm = 1.8804e-01, time/batch = 15.4665s	
5995/22750 (epoch 13.176), train_loss = 1.15504081, grad/param norm = 1.7276e-01, time/batch = 15.5398s	
5996/22750 (epoch 13.178), train_loss = 1.16088179, grad/param norm = 1.7304e-01, time/batch = 15.2150s	
5997/22750 (epoch 13.180), train_loss = 1.33179535, grad/param norm = 2.1346e-01, time/batch = 15.9113s	
5998/22750 (epoch 13.182), train_loss = 1.32115326, grad/param norm = 1.8003e-01, time/batch = 15.6212s	
5999/22750 (epoch 13.185), train_loss = 1.34689641, grad/param norm = 2.0301e-01, time/batch = 16.2405s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_wakata_epoch13.19_1.4794.t7	
6000/22750 (epoch 13.187), train_loss = 1.10307732, grad/param norm = 1.8782e-01, time/batch = 16.0188s	
6001/22750 (epoch 13.189), train_loss = 1.57619588, grad/param norm = 2.0592e-01, time/batch = 15.4461s	
6002/22750 (epoch 13.191), train_loss = 1.07206074, grad/param norm = 1.5915e-01, time/batch = 16.0879s	
6003/22750 (epoch 13.193), train_loss = 1.29388399, grad/param norm = 2.0819e-01, time/batch = 15.9221s	
6004/22750 (epoch 13.196), train_loss = 1.18628924, grad/param norm = 1.7489e-01, time/batch = 15.2935s	
6005/22750 (epoch 13.198), train_loss = 0.92598191, grad/param norm = 1.4770e-01, time/batch = 15.0639s	
6006/22750 (epoch 13.200), train_loss = 1.20066897, grad/param norm = 1.8266e-01, time/batch = 15.8823s	
6007/22750 (epoch 13.202), train_loss = 1.32911783, grad/param norm = 2.0314e-01, time/batch = 15.6378s	
6008/22750 (epoch 13.204), train_loss = 1.27376977, grad/param norm = 1.7388e-01, time/batch = 15.2342s	
6009/22750 (epoch 13.207), train_loss = 1.16383522, grad/param norm = 1.7678e-01, time/batch = 15.4607s	
6010/22750 (epoch 13.209), train_loss = 1.09503234, grad/param norm = 1.8615e-01, time/batch = 16.0219s	
6011/22750 (epoch 13.211), train_loss = 1.12549262, grad/param norm = 1.9590e-01, time/batch = 15.2846s	
6012/22750 (epoch 13.213), train_loss = 1.01853837, grad/param norm = 1.8182e-01, time/batch = 15.2059s	
6013/22750 (epoch 13.215), train_loss = 0.95934716, grad/param norm = 1.6732e-01, time/batch = 15.6864s	
6014/22750 (epoch 13.218), train_loss = 1.03459912, grad/param norm = 2.0119e-01, time/batch = 15.5972s	
6015/22750 (epoch 13.220), train_loss = 1.08207708, grad/param norm = 1.8499e-01, time/batch = 15.0469s	
6016/22750 (epoch 13.222), train_loss = 1.00539158, grad/param norm = 1.8672e-01, time/batch = 15.6303s	
6017/22750 (epoch 13.224), train_loss = 1.11121536, grad/param norm = 1.8749e-01, time/batch = 15.4762s	
6018/22750 (epoch 13.226), train_loss = 1.30202626, grad/param norm = 1.9418e-01, time/batch = 15.0713s	
6019/22750 (epoch 13.229), train_loss = 1.23938348, grad/param norm = 1.9693e-01, time/batch = 15.0770s	
6020/22750 (epoch 13.231), train_loss = 1.11407743, grad/param norm = 1.7404e-01, time/batch = 15.2174s	
6021/22750 (epoch 13.233), train_loss = 1.05774323, grad/param norm = 1.7302e-01, time/batch = 15.6885s	
6022/22750 (epoch 13.235), train_loss = 1.01114488, grad/param norm = 1.7907e-01, time/batch = 15.6894s	
6023/22750 (epoch 13.237), train_loss = 1.10895773, grad/param norm = 1.9169e-01, time/batch = 16.0106s	
6024/22750 (epoch 13.240), train_loss = 1.20040018, grad/param norm = 1.5894e-01, time/batch = 15.2129s	
6025/22750 (epoch 13.242), train_loss = 1.49641997, grad/param norm = 2.2102e-01, time/batch = 15.9201s	
6026/22750 (epoch 13.244), train_loss = 1.35250740, grad/param norm = 2.0217e-01, time/batch = 15.4199s	
6027/22750 (epoch 13.246), train_loss = 1.41828288, grad/param norm = 2.0223e-01, time/batch = 15.3366s	
6028/22750 (epoch 13.248), train_loss = 1.17219942, grad/param norm = 1.9242e-01, time/batch = 15.1425s	
6029/22750 (epoch 13.251), train_loss = 1.41697874, grad/param norm = 1.8934e-01, time/batch = 15.4757s	
6030/22750 (epoch 13.253), train_loss = 1.20745566, grad/param norm = 1.7711e-01, time/batch = 15.7164s	
6031/22750 (epoch 13.255), train_loss = 1.21192187, grad/param norm = 1.8418e-01, time/batch = 17.2174s	
6032/22750 (epoch 13.257), train_loss = 1.15717502, grad/param norm = 1.9111e-01, time/batch = 16.0025s	
6033/22750 (epoch 13.259), train_loss = 1.37384066, grad/param norm = 2.1195e-01, time/batch = 16.6659s	
6034/22750 (epoch 13.262), train_loss = 1.17884952, grad/param norm = 1.8216e-01, time/batch = 16.2709s	
6035/22750 (epoch 13.264), train_loss = 1.04179749, grad/param norm = 1.7575e-01, time/batch = 17.9259s	
6036/22750 (epoch 13.266), train_loss = 1.24577452, grad/param norm = 2.2896e-01, time/batch = 17.9218s	
6037/22750 (epoch 13.268), train_loss = 1.35397103, grad/param norm = 1.9435e-01, time/batch = 20.0237s	
6038/22750 (epoch 13.270), train_loss = 1.13925309, grad/param norm = 1.9078e-01, time/batch = 19.2828s	
6039/22750 (epoch 13.273), train_loss = 1.50385613, grad/param norm = 2.0823e-01, time/batch = 18.5076s	
6040/22750 (epoch 13.275), train_loss = 1.28121752, grad/param norm = 1.8406e-01, time/batch = 17.8228s	
6041/22750 (epoch 13.277), train_loss = 1.17616195, grad/param norm = 1.9551e-01, time/batch = 17.2636s	
6042/22750 (epoch 13.279), train_loss = 1.02586671, grad/param norm = 1.7442e-01, time/batch = 19.3190s	
6043/22750 (epoch 13.281), train_loss = 1.32369382, grad/param norm = 1.9060e-01, time/batch = 18.5035s	
6044/22750 (epoch 13.284), train_loss = 1.15720031, grad/param norm = 1.7303e-01, time/batch = 20.0023s	
6045/22750 (epoch 13.286), train_loss = 1.35003978, grad/param norm = 2.0110e-01, time/batch = 19.8336s	
6046/22750 (epoch 13.288), train_loss = 1.39913587, grad/param norm = 1.8941e-01, time/batch = 20.4204s	
6047/22750 (epoch 13.290), train_loss = 1.18789760, grad/param norm = 1.8629e-01, time/batch = 17.1278s	
6048/22750 (epoch 13.292), train_loss = 1.25657495, grad/param norm = 2.0817e-01, time/batch = 16.8318s	
6049/22750 (epoch 13.295), train_loss = 1.23930321, grad/param norm = 1.6453e-01, time/batch = 33.9259s	
6050/22750 (epoch 13.297), train_loss = 1.13628191, grad/param norm = 1.6974e-01, time/batch = 18.1527s	
6051/22750 (epoch 13.299), train_loss = 1.33841841, grad/param norm = 1.8452e-01, time/batch = 18.3111s	
6052/22750 (epoch 13.301), train_loss = 1.23645325, grad/param norm = 1.9025e-01, time/batch = 16.3074s	
6053/22750 (epoch 13.303), train_loss = 1.31483261, grad/param norm = 1.9324e-01, time/batch = 18.4333s	
6054/22750 (epoch 13.305), train_loss = 1.43774780, grad/param norm = 1.8985e-01, time/batch = 15.1629s	
6055/22750 (epoch 13.308), train_loss = 1.26537126, grad/param norm = 1.8655e-01, time/batch = 15.5604s	
6056/22750 (epoch 13.310), train_loss = 1.10447479, grad/param norm = 1.9408e-01, time/batch = 16.1016s	
6057/22750 (epoch 13.312), train_loss = 1.27023385, grad/param norm = 1.9414e-01, time/batch = 15.2922s	
6058/22750 (epoch 13.314), train_loss = 1.22781712, grad/param norm = 1.8126e-01, time/batch = 15.6193s	
6059/22750 (epoch 13.316), train_loss = 1.15837547, grad/param norm = 1.8575e-01, time/batch = 16.1029s	
6060/22750 (epoch 13.319), train_loss = 1.25810613, grad/param norm = 1.9888e-01, time/batch = 15.8581s	
6061/22750 (epoch 13.321), train_loss = 1.16651075, grad/param norm = 1.9617e-01, time/batch = 16.0806s	
6062/22750 (epoch 13.323), train_loss = 1.16899738, grad/param norm = 1.8258e-01, time/batch = 15.7837s	
6063/22750 (epoch 13.325), train_loss = 0.98842288, grad/param norm = 1.8461e-01, time/batch = 15.4717s	
6064/22750 (epoch 13.327), train_loss = 1.21836485, grad/param norm = 1.9074e-01, time/batch = 15.3959s	
6065/22750 (epoch 13.330), train_loss = 1.48255473, grad/param norm = 2.0656e-01, time/batch = 15.3147s	
6066/22750 (epoch 13.332), train_loss = 1.41774752, grad/param norm = 1.8736e-01, time/batch = 15.8749s	
6067/22750 (epoch 13.334), train_loss = 0.99892560, grad/param norm = 1.7358e-01, time/batch = 15.9297s	
6068/22750 (epoch 13.336), train_loss = 1.26733432, grad/param norm = 1.8671e-01, time/batch = 15.2840s	
6069/22750 (epoch 13.338), train_loss = 1.16228681, grad/param norm = 1.8498e-01, time/batch = 15.0464s	
6070/22750 (epoch 13.341), train_loss = 1.16488540, grad/param norm = 1.7605e-01, time/batch = 15.2121s	
6071/22750 (epoch 13.343), train_loss = 1.02290686, grad/param norm = 1.8673e-01, time/batch = 16.6332s	
6072/22750 (epoch 13.345), train_loss = 1.35309735, grad/param norm = 2.1159e-01, time/batch = 15.8349s	
6073/22750 (epoch 13.347), train_loss = 1.37910583, grad/param norm = 2.1037e-01, time/batch = 15.3746s	
6074/22750 (epoch 13.349), train_loss = 0.96144375, grad/param norm = 1.7867e-01, time/batch = 15.4016s	
6075/22750 (epoch 13.352), train_loss = 1.31455534, grad/param norm = 1.9703e-01, time/batch = 15.4732s	
6076/22750 (epoch 13.354), train_loss = 1.35980971, grad/param norm = 1.9814e-01, time/batch = 14.9888s	
6077/22750 (epoch 13.356), train_loss = 1.37235606, grad/param norm = 2.0377e-01, time/batch = 15.3067s	
6078/22750 (epoch 13.358), train_loss = 1.20819120, grad/param norm = 1.9728e-01, time/batch = 15.6677s	
6079/22750 (epoch 13.360), train_loss = 1.41951894, grad/param norm = 1.9375e-01, time/batch = 15.2061s	
6080/22750 (epoch 13.363), train_loss = 1.18475079, grad/param norm = 1.7222e-01, time/batch = 15.2896s	
6081/22750 (epoch 13.365), train_loss = 0.98214845, grad/param norm = 1.8163e-01, time/batch = 15.2979s	
6082/22750 (epoch 13.367), train_loss = 1.05859466, grad/param norm = 1.9243e-01, time/batch = 15.9374s	
6083/22750 (epoch 13.369), train_loss = 1.17345125, grad/param norm = 1.8524e-01, time/batch = 15.1376s	
6084/22750 (epoch 13.371), train_loss = 1.14618352, grad/param norm = 1.7931e-01, time/batch = 15.1369s	
6085/22750 (epoch 13.374), train_loss = 1.08296287, grad/param norm = 1.6908e-01, time/batch = 15.3092s	
6086/22750 (epoch 13.376), train_loss = 1.17724948, grad/param norm = 1.8474e-01, time/batch = 15.3599s	
6087/22750 (epoch 13.378), train_loss = 1.21413069, grad/param norm = 1.8162e-01, time/batch = 15.3010s	
6088/22750 (epoch 13.380), train_loss = 1.36281651, grad/param norm = 1.9644e-01, time/batch = 15.3716s	
6089/22750 (epoch 13.382), train_loss = 1.14628584, grad/param norm = 1.7130e-01, time/batch = 15.6096s	
6090/22750 (epoch 13.385), train_loss = 1.27352692, grad/param norm = 1.7662e-01, time/batch = 16.0102s	
6091/22750 (epoch 13.387), train_loss = 1.24766017, grad/param norm = 1.8697e-01, time/batch = 15.3672s	
6092/22750 (epoch 13.389), train_loss = 0.92636229, grad/param norm = 1.6719e-01, time/batch = 15.2161s	
6093/22750 (epoch 13.391), train_loss = 0.75306769, grad/param norm = 1.4097e-01, time/batch = 15.4490s	
6094/22750 (epoch 13.393), train_loss = 1.05946919, grad/param norm = 1.7216e-01, time/batch = 15.5306s	
6095/22750 (epoch 13.396), train_loss = 1.22639598, grad/param norm = 1.9249e-01, time/batch = 15.1386s	
6096/22750 (epoch 13.398), train_loss = 1.15019715, grad/param norm = 1.7264e-01, time/batch = 14.9900s	
6097/22750 (epoch 13.400), train_loss = 1.16320644, grad/param norm = 1.7186e-01, time/batch = 15.4755s	
6098/22750 (epoch 13.402), train_loss = 1.25169746, grad/param norm = 1.7307e-01, time/batch = 15.1537s	
6099/22750 (epoch 13.404), train_loss = 1.38317905, grad/param norm = 1.8097e-01, time/batch = 16.1555s	
6100/22750 (epoch 13.407), train_loss = 1.31946572, grad/param norm = 1.8453e-01, time/batch = 15.6863s	
6101/22750 (epoch 13.409), train_loss = 1.19217558, grad/param norm = 1.8252e-01, time/batch = 15.8608s	
6102/22750 (epoch 13.411), train_loss = 1.15705653, grad/param norm = 1.7316e-01, time/batch = 15.2004s	
6103/22750 (epoch 13.413), train_loss = 0.97222195, grad/param norm = 1.8731e-01, time/batch = 15.3805s	
6104/22750 (epoch 13.415), train_loss = 0.91435953, grad/param norm = 1.6543e-01, time/batch = 15.4482s	
6105/22750 (epoch 13.418), train_loss = 1.13892542, grad/param norm = 1.8843e-01, time/batch = 16.0788s	
6106/22750 (epoch 13.420), train_loss = 1.35494452, grad/param norm = 2.6635e-01, time/batch = 15.3869s	
6107/22750 (epoch 13.422), train_loss = 1.46275137, grad/param norm = 2.4002e-01, time/batch = 15.7017s	
6108/22750 (epoch 13.424), train_loss = 1.47754805, grad/param norm = 2.2675e-01, time/batch = 15.3126s	
6109/22750 (epoch 13.426), train_loss = 1.44347128, grad/param norm = 1.9996e-01, time/batch = 15.3827s	
6110/22750 (epoch 13.429), train_loss = 1.02008603, grad/param norm = 1.7706e-01, time/batch = 15.2171s	
6111/22750 (epoch 13.431), train_loss = 0.99767279, grad/param norm = 1.9162e-01, time/batch = 15.5239s	
6112/22750 (epoch 13.433), train_loss = 1.10995828, grad/param norm = 1.6946e-01, time/batch = 15.3722s	
6113/22750 (epoch 13.435), train_loss = 0.93408505, grad/param norm = 1.5954e-01, time/batch = 15.7453s	
6114/22750 (epoch 13.437), train_loss = 0.82862090, grad/param norm = 1.6737e-01, time/batch = 15.5008s	
6115/22750 (epoch 13.440), train_loss = 1.24486403, grad/param norm = 1.9344e-01, time/batch = 15.3585s	
6116/22750 (epoch 13.442), train_loss = 1.24912562, grad/param norm = 2.0657e-01, time/batch = 15.5901s	
6117/22750 (epoch 13.444), train_loss = 1.18724172, grad/param norm = 2.0432e-01, time/batch = 15.4586s	
6118/22750 (epoch 13.446), train_loss = 1.19561531, grad/param norm = 1.9033e-01, time/batch = 15.2234s	
6119/22750 (epoch 13.448), train_loss = 1.49588879, grad/param norm = 2.1251e-01, time/batch = 15.0714s	
6120/22750 (epoch 13.451), train_loss = 1.38296498, grad/param norm = 1.9488e-01, time/batch = 15.3046s	
6121/22750 (epoch 13.453), train_loss = 1.42278683, grad/param norm = 1.9962e-01, time/batch = 16.2463s	
6122/22750 (epoch 13.455), train_loss = 1.51087879, grad/param norm = 2.1011e-01, time/batch = 15.8344s	
6123/22750 (epoch 13.457), train_loss = 1.36888028, grad/param norm = 2.4136e-01, time/batch = 15.3484s	
6124/22750 (epoch 13.459), train_loss = 1.31183098, grad/param norm = 1.9473e-01, time/batch = 15.9130s	
6125/22750 (epoch 13.462), train_loss = 1.31450870, grad/param norm = 1.7797e-01, time/batch = 16.0694s	
6126/22750 (epoch 13.464), train_loss = 1.02857812, grad/param norm = 1.9091e-01, time/batch = 15.5391s	
6127/22750 (epoch 13.466), train_loss = 1.43085429, grad/param norm = 2.1660e-01, time/batch = 15.1329s	
6128/22750 (epoch 13.468), train_loss = 1.18961990, grad/param norm = 1.9081e-01, time/batch = 16.2667s	
6129/22750 (epoch 13.470), train_loss = 1.34641085, grad/param norm = 2.1197e-01, time/batch = 15.2348s	
6130/22750 (epoch 13.473), train_loss = 1.20461706, grad/param norm = 1.9667e-01, time/batch = 15.3137s	
6131/22750 (epoch 13.475), train_loss = 1.23020156, grad/param norm = 2.2278e-01, time/batch = 15.4442s	
6132/22750 (epoch 13.477), train_loss = 1.01627110, grad/param norm = 1.6968e-01, time/batch = 16.2112s	
6133/22750 (epoch 13.479), train_loss = 1.03346340, grad/param norm = 1.7220e-01, time/batch = 16.2341s	
6134/22750 (epoch 13.481), train_loss = 0.95363002, grad/param norm = 1.7592e-01, time/batch = 15.2872s	
6135/22750 (epoch 13.484), train_loss = 0.90172516, grad/param norm = 1.9549e-01, time/batch = 15.8490s	
6136/22750 (epoch 13.486), train_loss = 1.04899022, grad/param norm = 1.9114e-01, time/batch = 15.2032s	
6137/22750 (epoch 13.488), train_loss = 0.91842576, grad/param norm = 1.9378e-01, time/batch = 15.0475s	
6138/22750 (epoch 13.490), train_loss = 1.21499078, grad/param norm = 1.8570e-01, time/batch = 15.3040s	
6139/22750 (epoch 13.492), train_loss = 1.34748895, grad/param norm = 1.9579e-01, time/batch = 15.2948s	
6140/22750 (epoch 13.495), train_loss = 1.08400172, grad/param norm = 1.7158e-01, time/batch = 15.8700s	
6141/22750 (epoch 13.497), train_loss = 1.22131525, grad/param norm = 2.1082e-01, time/batch = 15.3109s	
6142/22750 (epoch 13.499), train_loss = 1.10438159, grad/param norm = 1.8832e-01, time/batch = 15.1631s	
6143/22750 (epoch 13.501), train_loss = 1.20484329, grad/param norm = 1.9313e-01, time/batch = 16.0121s	
6144/22750 (epoch 13.503), train_loss = 1.21241982, grad/param norm = 1.9424e-01, time/batch = 16.4606s	
6145/22750 (epoch 13.505), train_loss = 1.05113849, grad/param norm = 1.7821e-01, time/batch = 15.7702s	
6146/22750 (epoch 13.508), train_loss = 0.99267071, grad/param norm = 1.7806e-01, time/batch = 15.3750s	
6147/22750 (epoch 13.510), train_loss = 1.03269553, grad/param norm = 1.6865e-01, time/batch = 15.7783s	
6148/22750 (epoch 13.512), train_loss = 1.08066249, grad/param norm = 1.6844e-01, time/batch = 15.6878s	
6149/22750 (epoch 13.514), train_loss = 1.10546106, grad/param norm = 1.7043e-01, time/batch = 15.4450s	
6150/22750 (epoch 13.516), train_loss = 1.08147380, grad/param norm = 1.8037e-01, time/batch = 15.0689s	
6151/22750 (epoch 13.519), train_loss = 1.28966374, grad/param norm = 1.8500e-01, time/batch = 15.3979s	
6152/22750 (epoch 13.521), train_loss = 1.15177123, grad/param norm = 1.8680e-01, time/batch = 15.7903s	
6153/22750 (epoch 13.523), train_loss = 1.13441668, grad/param norm = 2.0045e-01, time/batch = 15.1555s	
6154/22750 (epoch 13.525), train_loss = 1.36780305, grad/param norm = 1.8972e-01, time/batch = 15.3044s	
6155/22750 (epoch 13.527), train_loss = 1.18477693, grad/param norm = 1.7634e-01, time/batch = 16.0906s	
6156/22750 (epoch 13.530), train_loss = 1.13840445, grad/param norm = 2.0714e-01, time/batch = 15.3789s	
6157/22750 (epoch 13.532), train_loss = 1.01719372, grad/param norm = 1.5992e-01, time/batch = 15.4550s	
6158/22750 (epoch 13.534), train_loss = 1.29561512, grad/param norm = 1.9182e-01, time/batch = 15.2883s	
6159/22750 (epoch 13.536), train_loss = 1.21732663, grad/param norm = 1.8176e-01, time/batch = 15.5484s	
6160/22750 (epoch 13.538), train_loss = 1.19204770, grad/param norm = 1.6656e-01, time/batch = 15.3725s	
6161/22750 (epoch 13.541), train_loss = 1.02619701, grad/param norm = 1.8225e-01, time/batch = 15.2378s	
6162/22750 (epoch 13.543), train_loss = 1.03728766, grad/param norm = 1.7284e-01, time/batch = 15.9409s	
6163/22750 (epoch 13.545), train_loss = 1.31485990, grad/param norm = 1.7456e-01, time/batch = 15.7120s	
6164/22750 (epoch 13.547), train_loss = 1.04980619, grad/param norm = 1.5826e-01, time/batch = 16.1966s	
6165/22750 (epoch 13.549), train_loss = 1.12626063, grad/param norm = 1.8412e-01, time/batch = 15.9245s	
6166/22750 (epoch 13.552), train_loss = 1.26591763, grad/param norm = 1.9493e-01, time/batch = 16.5560s	
6167/22750 (epoch 13.554), train_loss = 1.28422496, grad/param norm = 1.9418e-01, time/batch = 16.7222s	
6168/22750 (epoch 13.556), train_loss = 1.19762694, grad/param norm = 1.9210e-01, time/batch = 15.6176s	
6169/22750 (epoch 13.558), train_loss = 1.30913961, grad/param norm = 1.9185e-01, time/batch = 15.2156s	
6170/22750 (epoch 13.560), train_loss = 1.12601849, grad/param norm = 1.7643e-01, time/batch = 15.8583s	
6171/22750 (epoch 13.563), train_loss = 1.30344711, grad/param norm = 1.7491e-01, time/batch = 15.9329s	
6172/22750 (epoch 13.565), train_loss = 1.25944324, grad/param norm = 1.8691e-01, time/batch = 15.4050s	
6173/22750 (epoch 13.567), train_loss = 1.24781363, grad/param norm = 1.9034e-01, time/batch = 15.5554s	
6174/22750 (epoch 13.569), train_loss = 1.16876071, grad/param norm = 1.8733e-01, time/batch = 16.1145s	
6175/22750 (epoch 13.571), train_loss = 1.19974670, grad/param norm = 1.9021e-01, time/batch = 16.1723s	
6176/22750 (epoch 13.574), train_loss = 1.07672112, grad/param norm = 1.7786e-01, time/batch = 15.6150s	
6177/22750 (epoch 13.576), train_loss = 1.19895849, grad/param norm = 1.9239e-01, time/batch = 15.9201s	
6178/22750 (epoch 13.578), train_loss = 1.04717399, grad/param norm = 1.8099e-01, time/batch = 16.4032s	
6179/22750 (epoch 13.580), train_loss = 1.21986330, grad/param norm = 2.0855e-01, time/batch = 16.0919s	
6180/22750 (epoch 13.582), train_loss = 1.03907788, grad/param norm = 1.7075e-01, time/batch = 16.2337s	
6181/22750 (epoch 13.585), train_loss = 0.97467145, grad/param norm = 1.8055e-01, time/batch = 16.4341s	
6182/22750 (epoch 13.587), train_loss = 0.99744145, grad/param norm = 1.5854e-01, time/batch = 16.1186s	
6183/22750 (epoch 13.589), train_loss = 0.98037860, grad/param norm = 1.6930e-01, time/batch = 16.1096s	
6184/22750 (epoch 13.591), train_loss = 1.13357606, grad/param norm = 1.7800e-01, time/batch = 15.5665s	
6185/22750 (epoch 13.593), train_loss = 1.37848921, grad/param norm = 1.8717e-01, time/batch = 15.7044s	
6186/22750 (epoch 13.596), train_loss = 1.36926148, grad/param norm = 1.9675e-01, time/batch = 15.6944s	
6187/22750 (epoch 13.598), train_loss = 1.40199991, grad/param norm = 1.9350e-01, time/batch = 15.6161s	
6188/22750 (epoch 13.600), train_loss = 1.33815490, grad/param norm = 1.9416e-01, time/batch = 15.4488s	
6189/22750 (epoch 13.602), train_loss = 1.06551507, grad/param norm = 1.6328e-01, time/batch = 16.0907s	
6190/22750 (epoch 13.604), train_loss = 1.11761026, grad/param norm = 1.6999e-01, time/batch = 16.0013s	
6191/22750 (epoch 13.607), train_loss = 0.97209359, grad/param norm = 1.6337e-01, time/batch = 15.7790s	
6192/22750 (epoch 13.609), train_loss = 0.92689617, grad/param norm = 1.5852e-01, time/batch = 16.0325s	
6193/22750 (epoch 13.611), train_loss = 1.12364618, grad/param norm = 1.8072e-01, time/batch = 15.9529s	
6194/22750 (epoch 13.613), train_loss = 1.04934026, grad/param norm = 1.8487e-01, time/batch = 16.4505s	
6195/22750 (epoch 13.615), train_loss = 1.10878890, grad/param norm = 1.7116e-01, time/batch = 15.3946s	
6196/22750 (epoch 13.618), train_loss = 1.12809951, grad/param norm = 1.7410e-01, time/batch = 16.0309s	
6197/22750 (epoch 13.620), train_loss = 1.15796651, grad/param norm = 1.8531e-01, time/batch = 15.7788s	
6198/22750 (epoch 13.622), train_loss = 0.94746626, grad/param norm = 1.5966e-01, time/batch = 15.7733s	
6199/22750 (epoch 13.624), train_loss = 1.09833596, grad/param norm = 1.8778e-01, time/batch = 15.4577s	
6200/22750 (epoch 13.626), train_loss = 1.00334795, grad/param norm = 1.7885e-01, time/batch = 16.3220s	
6201/22750 (epoch 13.629), train_loss = 1.11628607, grad/param norm = 1.7946e-01, time/batch = 16.5668s	
6202/22750 (epoch 13.631), train_loss = 1.13571009, grad/param norm = 1.8001e-01, time/batch = 15.4545s	
6203/22750 (epoch 13.633), train_loss = 0.98349696, grad/param norm = 1.7312e-01, time/batch = 15.3961s	
6204/22750 (epoch 13.635), train_loss = 1.18097540, grad/param norm = 1.8810e-01, time/batch = 15.7810s	
6205/22750 (epoch 13.637), train_loss = 1.25139664, grad/param norm = 2.0034e-01, time/batch = 15.3827s	
6206/22750 (epoch 13.640), train_loss = 1.27964989, grad/param norm = 1.9124e-01, time/batch = 15.3073s	
6207/22750 (epoch 13.642), train_loss = 1.33379475, grad/param norm = 1.8830e-01, time/batch = 16.1553s	
6208/22750 (epoch 13.644), train_loss = 1.18932717, grad/param norm = 1.8626e-01, time/batch = 15.9950s	
6209/22750 (epoch 13.646), train_loss = 1.29017263, grad/param norm = 2.0841e-01, time/batch = 16.1656s	
6210/22750 (epoch 13.648), train_loss = 1.20555354, grad/param norm = 2.0335e-01, time/batch = 16.2685s	
6211/22750 (epoch 13.651), train_loss = 1.27689516, grad/param norm = 1.9418e-01, time/batch = 16.3350s	
6212/22750 (epoch 13.653), train_loss = 1.25492287, grad/param norm = 1.8700e-01, time/batch = 15.6120s	
6213/22750 (epoch 13.655), train_loss = 1.18568295, grad/param norm = 1.8383e-01, time/batch = 16.2573s	
6214/22750 (epoch 13.657), train_loss = 1.37694706, grad/param norm = 1.9763e-01, time/batch = 15.4740s	
6215/22750 (epoch 13.659), train_loss = 1.46359037, grad/param norm = 2.0023e-01, time/batch = 15.9500s	
6216/22750 (epoch 13.662), train_loss = 1.46289205, grad/param norm = 2.4127e-01, time/batch = 15.3920s	
6217/22750 (epoch 13.664), train_loss = 1.26090411, grad/param norm = 2.0435e-01, time/batch = 16.0056s	
6218/22750 (epoch 13.666), train_loss = 1.05458792, grad/param norm = 1.9149e-01, time/batch = 16.1383s	
6219/22750 (epoch 13.668), train_loss = 1.20937240, grad/param norm = 1.7961e-01, time/batch = 16.4956s	
6220/22750 (epoch 13.670), train_loss = 1.20377267, grad/param norm = 1.8719e-01, time/batch = 15.6012s	
6221/22750 (epoch 13.673), train_loss = 1.49391808, grad/param norm = 2.1904e-01, time/batch = 15.9323s	
6222/22750 (epoch 13.675), train_loss = 1.65281206, grad/param norm = 2.2261e-01, time/batch = 15.8415s	
6223/22750 (epoch 13.677), train_loss = 1.41000234, grad/param norm = 2.2630e-01, time/batch = 16.6494s	
6224/22750 (epoch 13.679), train_loss = 1.45989882, grad/param norm = 2.1529e-01, time/batch = 15.4589s	
6225/22750 (epoch 13.681), train_loss = 1.39428797, grad/param norm = 2.0970e-01, time/batch = 16.1079s	
6226/22750 (epoch 13.684), train_loss = 1.36325593, grad/param norm = 1.9912e-01, time/batch = 16.4303s	
6227/22750 (epoch 13.686), train_loss = 1.35312922, grad/param norm = 2.0526e-01, time/batch = 16.1869s	
6228/22750 (epoch 13.688), train_loss = 1.34079620, grad/param norm = 2.0131e-01, time/batch = 15.7017s	
6229/22750 (epoch 13.690), train_loss = 1.34559006, grad/param norm = 2.0686e-01, time/batch = 15.9190s	
6230/22750 (epoch 13.692), train_loss = 1.42120025, grad/param norm = 1.9914e-01, time/batch = 16.0218s	
6231/22750 (epoch 13.695), train_loss = 1.24961505, grad/param norm = 1.9534e-01, time/batch = 15.7710s	
6232/22750 (epoch 13.697), train_loss = 1.17197736, grad/param norm = 1.8124e-01, time/batch = 15.6992s	
6233/22750 (epoch 13.699), train_loss = 1.21917313, grad/param norm = 1.8753e-01, time/batch = 15.6097s	
6234/22750 (epoch 13.701), train_loss = 1.05702562, grad/param norm = 1.8107e-01, time/batch = 16.2471s	
6235/22750 (epoch 13.703), train_loss = 1.22103834, grad/param norm = 1.7769e-01, time/batch = 16.0454s	
6236/22750 (epoch 13.705), train_loss = 1.11432211, grad/param norm = 1.7003e-01, time/batch = 15.8750s	
6237/22750 (epoch 13.708), train_loss = 1.20607062, grad/param norm = 1.8247e-01, time/batch = 16.0199s	
6238/22750 (epoch 13.710), train_loss = 1.03983689, grad/param norm = 1.7806e-01, time/batch = 16.3143s	
6239/22750 (epoch 13.712), train_loss = 1.10047763, grad/param norm = 1.7640e-01, time/batch = 15.6909s	
6240/22750 (epoch 13.714), train_loss = 0.98173472, grad/param norm = 1.7383e-01, time/batch = 16.1586s	
6241/22750 (epoch 13.716), train_loss = 1.06791905, grad/param norm = 1.8046e-01, time/batch = 16.1628s	
6242/22750 (epoch 13.719), train_loss = 1.27856406, grad/param norm = 2.0187e-01, time/batch = 16.1547s	
6243/22750 (epoch 13.721), train_loss = 1.30506292, grad/param norm = 1.8083e-01, time/batch = 15.7733s	
6244/22750 (epoch 13.723), train_loss = 1.21481803, grad/param norm = 1.8818e-01, time/batch = 15.5278s	
6245/22750 (epoch 13.725), train_loss = 1.17292848, grad/param norm = 1.8022e-01, time/batch = 16.1184s	
6246/22750 (epoch 13.727), train_loss = 1.11778401, grad/param norm = 1.7100e-01, time/batch = 16.1124s	
6247/22750 (epoch 13.730), train_loss = 1.14139883, grad/param norm = 1.8454e-01, time/batch = 15.5515s	
6248/22750 (epoch 13.732), train_loss = 1.10905122, grad/param norm = 1.7262e-01, time/batch = 16.1115s	
6249/22750 (epoch 13.734), train_loss = 0.93270164, grad/param norm = 1.6833e-01, time/batch = 15.7740s	
6250/22750 (epoch 13.736), train_loss = 1.09918997, grad/param norm = 1.8088e-01, time/batch = 16.2377s	
6251/22750 (epoch 13.738), train_loss = 1.23216824, grad/param norm = 2.1077e-01, time/batch = 15.7799s	
6252/22750 (epoch 13.741), train_loss = 1.30944678, grad/param norm = 2.0550e-01, time/batch = 15.7724s	
6253/22750 (epoch 13.743), train_loss = 1.22847495, grad/param norm = 1.8176e-01, time/batch = 16.9517s	
6254/22750 (epoch 13.745), train_loss = 1.04468572, grad/param norm = 1.7389e-01, time/batch = 15.9131s	
6255/22750 (epoch 13.747), train_loss = 1.12197589, grad/param norm = 1.8565e-01, time/batch = 16.5233s	
6256/22750 (epoch 13.749), train_loss = 1.40541838, grad/param norm = 2.1659e-01, time/batch = 16.6675s	
6257/22750 (epoch 13.752), train_loss = 1.14484077, grad/param norm = 1.8008e-01, time/batch = 18.2722s	
6258/22750 (epoch 13.754), train_loss = 1.25858300, grad/param norm = 2.1303e-01, time/batch = 19.5136s	
6259/22750 (epoch 13.756), train_loss = 1.07267710, grad/param norm = 2.0275e-01, time/batch = 17.6553s	
6260/22750 (epoch 13.758), train_loss = 1.05894380, grad/param norm = 1.8057e-01, time/batch = 17.3537s	
6261/22750 (epoch 13.760), train_loss = 1.17065617, grad/param norm = 1.8202e-01, time/batch = 17.3408s	
6262/22750 (epoch 13.763), train_loss = 1.24757264, grad/param norm = 1.9490e-01, time/batch = 18.3287s	
6263/22750 (epoch 13.765), train_loss = 1.17004020, grad/param norm = 2.0303e-01, time/batch = 18.1736s	
6264/22750 (epoch 13.767), train_loss = 1.21673492, grad/param norm = 1.9838e-01, time/batch = 18.6512s	
6265/22750 (epoch 13.769), train_loss = 1.43029367, grad/param norm = 2.0591e-01, time/batch = 20.4519s	
6266/22750 (epoch 13.771), train_loss = 1.38114299, grad/param norm = 2.0080e-01, time/batch = 17.9332s	
6267/22750 (epoch 13.774), train_loss = 1.12350143, grad/param norm = 1.9459e-01, time/batch = 20.6761s	
6268/22750 (epoch 13.776), train_loss = 1.21131594, grad/param norm = 2.0382e-01, time/batch = 19.3147s	
6269/22750 (epoch 13.778), train_loss = 1.40265412, grad/param norm = 1.8766e-01, time/batch = 18.5099s	
6270/22750 (epoch 13.780), train_loss = 1.23302775, grad/param norm = 1.9075e-01, time/batch = 19.0701s	
6271/22750 (epoch 13.782), train_loss = 1.38297337, grad/param norm = 1.9059e-01, time/batch = 17.2658s	
6272/22750 (epoch 13.785), train_loss = 1.18732538, grad/param norm = 1.7318e-01, time/batch = 25.3533s	
6273/22750 (epoch 13.787), train_loss = 1.08179065, grad/param norm = 1.9528e-01, time/batch = 27.0781s	
6274/22750 (epoch 13.789), train_loss = 1.17286441, grad/param norm = 1.8421e-01, time/batch = 17.7286s	
6275/22750 (epoch 13.791), train_loss = 1.17245214, grad/param norm = 1.8015e-01, time/batch = 16.3522s	
6276/22750 (epoch 13.793), train_loss = 1.09748444, grad/param norm = 1.8107e-01, time/batch = 17.5159s	
6277/22750 (epoch 13.796), train_loss = 1.01271847, grad/param norm = 1.6873e-01, time/batch = 19.5912s	
6278/22750 (epoch 13.798), train_loss = 1.05951491, grad/param norm = 1.6764e-01, time/batch = 17.9207s	
6279/22750 (epoch 13.800), train_loss = 1.08956704, grad/param norm = 1.7264e-01, time/batch = 16.9247s	
6280/22750 (epoch 13.802), train_loss = 1.04058611, grad/param norm = 1.7393e-01, time/batch = 18.6637s	
6281/22750 (epoch 13.804), train_loss = 1.38093924, grad/param norm = 1.8185e-01, time/batch = 16.9864s	
6282/22750 (epoch 13.807), train_loss = 1.24535073, grad/param norm = 1.7967e-01, time/batch = 16.8330s	
6283/22750 (epoch 13.809), train_loss = 1.43847344, grad/param norm = 2.1611e-01, time/batch = 20.5840s	
6284/22750 (epoch 13.811), train_loss = 1.11456002, grad/param norm = 1.6753e-01, time/batch = 19.9006s	
6285/22750 (epoch 13.813), train_loss = 1.22621437, grad/param norm = 1.6955e-01, time/batch = 17.9410s	
6286/22750 (epoch 13.815), train_loss = 1.37895146, grad/param norm = 1.9885e-01, time/batch = 18.0838s	
6287/22750 (epoch 13.818), train_loss = 1.35513721, grad/param norm = 1.8146e-01, time/batch = 19.6755s	
6288/22750 (epoch 13.820), train_loss = 1.47518574, grad/param norm = 1.9298e-01, time/batch = 17.6555s	
6289/22750 (epoch 13.822), train_loss = 1.23318171, grad/param norm = 1.8613e-01, time/batch = 17.5207s	
6290/22750 (epoch 13.824), train_loss = 1.11714739, grad/param norm = 1.7525e-01, time/batch = 15.9529s	
6291/22750 (epoch 13.826), train_loss = 1.21303157, grad/param norm = 1.8697e-01, time/batch = 17.2394s	
6292/22750 (epoch 13.829), train_loss = 1.39353979, grad/param norm = 1.9931e-01, time/batch = 18.9237s	
6293/22750 (epoch 13.831), train_loss = 1.35185147, grad/param norm = 1.8854e-01, time/batch = 19.6067s	
6294/22750 (epoch 13.833), train_loss = 1.23585031, grad/param norm = 1.8831e-01, time/batch = 19.5169s	
6295/22750 (epoch 13.835), train_loss = 1.15417800, grad/param norm = 1.7802e-01, time/batch = 17.7553s	
6296/22750 (epoch 13.837), train_loss = 1.14863191, grad/param norm = 1.8601e-01, time/batch = 19.4123s	
6297/22750 (epoch 13.840), train_loss = 1.08747381, grad/param norm = 1.6769e-01, time/batch = 19.2392s	
6298/22750 (epoch 13.842), train_loss = 1.13182452, grad/param norm = 1.8249e-01, time/batch = 18.3813s	
6299/22750 (epoch 13.844), train_loss = 1.29085791, grad/param norm = 1.8475e-01, time/batch = 19.8054s	
6300/22750 (epoch 13.846), train_loss = 1.20918509, grad/param norm = 1.8175e-01, time/batch = 17.8922s	
6301/22750 (epoch 13.848), train_loss = 1.08669294, grad/param norm = 1.6771e-01, time/batch = 17.4101s	
6302/22750 (epoch 13.851), train_loss = 1.09468310, grad/param norm = 1.7541e-01, time/batch = 20.9403s	
6303/22750 (epoch 13.853), train_loss = 1.22160163, grad/param norm = 1.6876e-01, time/batch = 20.4555s	
6304/22750 (epoch 13.855), train_loss = 1.01903169, grad/param norm = 1.7748e-01, time/batch = 18.4860s	
6305/22750 (epoch 13.857), train_loss = 1.22608314, grad/param norm = 1.8144e-01, time/batch = 17.2640s	
6306/22750 (epoch 13.859), train_loss = 1.26172280, grad/param norm = 1.9595e-01, time/batch = 16.6298s	
6307/22750 (epoch 13.862), train_loss = 1.38187598, grad/param norm = 1.9793e-01, time/batch = 15.9284s	
6308/22750 (epoch 13.864), train_loss = 1.18942441, grad/param norm = 1.8571e-01, time/batch = 17.1048s	
6309/22750 (epoch 13.866), train_loss = 1.23096455, grad/param norm = 1.6648e-01, time/batch = 17.2594s	
6310/22750 (epoch 13.868), train_loss = 1.12038718, grad/param norm = 1.6386e-01, time/batch = 19.8533s	
6311/22750 (epoch 13.870), train_loss = 1.00320962, grad/param norm = 1.7845e-01, time/batch = 19.1811s	
6312/22750 (epoch 13.873), train_loss = 1.13493700, grad/param norm = 1.7911e-01, time/batch = 19.5919s	
6313/22750 (epoch 13.875), train_loss = 1.26545226, grad/param norm = 1.8521e-01, time/batch = 18.1066s	
6314/22750 (epoch 13.877), train_loss = 1.11981818, grad/param norm = 1.6752e-01, time/batch = 17.6762s	
6315/22750 (epoch 13.879), train_loss = 1.32940714, grad/param norm = 1.9852e-01, time/batch = 19.5691s	
6316/22750 (epoch 13.881), train_loss = 1.31134010, grad/param norm = 1.8872e-01, time/batch = 18.2657s	
6317/22750 (epoch 13.884), train_loss = 1.08511389, grad/param norm = 1.7768e-01, time/batch = 18.3502s	
6318/22750 (epoch 13.886), train_loss = 1.27046128, grad/param norm = 1.8344e-01, time/batch = 19.6447s	
6319/22750 (epoch 13.888), train_loss = 1.25750428, grad/param norm = 1.8225e-01, time/batch = 20.3537s	
6320/22750 (epoch 13.890), train_loss = 1.32665300, grad/param norm = 1.9933e-01, time/batch = 18.0958s	
6321/22750 (epoch 13.892), train_loss = 1.60724056, grad/param norm = 2.2839e-01, time/batch = 18.0922s	
6322/22750 (epoch 13.895), train_loss = 1.27610105, grad/param norm = 1.7250e-01, time/batch = 19.4223s	
6323/22750 (epoch 13.897), train_loss = 1.32005367, grad/param norm = 1.8950e-01, time/batch = 18.5817s	
6324/22750 (epoch 13.899), train_loss = 1.24519784, grad/param norm = 1.8405e-01, time/batch = 18.7403s	
6325/22750 (epoch 13.901), train_loss = 1.41997004, grad/param norm = 2.0695e-01, time/batch = 20.4955s	
6326/22750 (epoch 13.903), train_loss = 1.19544346, grad/param norm = 1.9840e-01, time/batch = 18.2576s	
6327/22750 (epoch 13.905), train_loss = 1.30217445, grad/param norm = 1.8627e-01, time/batch = 17.2610s	
6328/22750 (epoch 13.908), train_loss = 1.15602505, grad/param norm = 2.0912e-01, time/batch = 19.5231s	
6329/22750 (epoch 13.910), train_loss = 0.97848966, grad/param norm = 1.8759e-01, time/batch = 19.8550s	
6330/22750 (epoch 13.912), train_loss = 1.12039024, grad/param norm = 1.8207e-01, time/batch = 16.5663s	
6331/22750 (epoch 13.914), train_loss = 1.19494578, grad/param norm = 1.8192e-01, time/batch = 16.9415s	
6332/22750 (epoch 13.916), train_loss = 1.00024482, grad/param norm = 1.7279e-01, time/batch = 16.9430s	
6333/22750 (epoch 13.919), train_loss = 1.12099371, grad/param norm = 1.8160e-01, time/batch = 16.1899s	
6334/22750 (epoch 13.921), train_loss = 0.84716513, grad/param norm = 1.5028e-01, time/batch = 17.0971s	
6335/22750 (epoch 13.923), train_loss = 1.09491400, grad/param norm = 1.8895e-01, time/batch = 16.7524s	
6336/22750 (epoch 13.925), train_loss = 1.15689209, grad/param norm = 1.7213e-01, time/batch = 19.1498s	
6337/22750 (epoch 13.927), train_loss = 0.94649330, grad/param norm = 1.8773e-01, time/batch = 16.9905s	
6338/22750 (epoch 13.930), train_loss = 0.97269057, grad/param norm = 1.6853e-01, time/batch = 19.8678s	
6339/22750 (epoch 13.932), train_loss = 1.22814981, grad/param norm = 1.8721e-01, time/batch = 17.9354s	
6340/22750 (epoch 13.934), train_loss = 0.88500233, grad/param norm = 1.4369e-01, time/batch = 17.5439s	
6341/22750 (epoch 13.936), train_loss = 1.30056863, grad/param norm = 1.9946e-01, time/batch = 19.6892s	
6342/22750 (epoch 13.938), train_loss = 1.24392227, grad/param norm = 1.7454e-01, time/batch = 17.9134s	
6343/22750 (epoch 13.941), train_loss = 1.41525314, grad/param norm = 1.9352e-01, time/batch = 18.1613s	
6344/22750 (epoch 13.943), train_loss = 1.23991476, grad/param norm = 1.8902e-01, time/batch = 18.1643s	
6345/22750 (epoch 13.945), train_loss = 1.21968612, grad/param norm = 1.8619e-01, time/batch = 19.2424s	
6346/22750 (epoch 13.947), train_loss = 1.14954030, grad/param norm = 1.9370e-01, time/batch = 18.3419s	
6347/22750 (epoch 13.949), train_loss = 1.06818089, grad/param norm = 1.7693e-01, time/batch = 19.5311s	
6348/22750 (epoch 13.952), train_loss = 1.10023288, grad/param norm = 1.7236e-01, time/batch = 19.0347s	
6349/22750 (epoch 13.954), train_loss = 1.05887211, grad/param norm = 1.7307e-01, time/batch = 18.9579s	
6350/22750 (epoch 13.956), train_loss = 1.17668032, grad/param norm = 1.7076e-01, time/batch = 15.9481s	
6351/22750 (epoch 13.958), train_loss = 1.10529033, grad/param norm = 1.7479e-01, time/batch = 16.2343s	
6352/22750 (epoch 13.960), train_loss = 1.10466968, grad/param norm = 1.7426e-01, time/batch = 16.1794s	
6353/22750 (epoch 13.963), train_loss = 1.32995136, grad/param norm = 1.9473e-01, time/batch = 15.9239s	
6354/22750 (epoch 13.965), train_loss = 1.27268977, grad/param norm = 1.8514e-01, time/batch = 16.6189s	
6355/22750 (epoch 13.967), train_loss = 1.17221156, grad/param norm = 1.9133e-01, time/batch = 16.8364s	
6356/22750 (epoch 13.969), train_loss = 1.11636225, grad/param norm = 1.8508e-01, time/batch = 18.4389s	
6357/22750 (epoch 13.971), train_loss = 1.11916159, grad/param norm = 1.9033e-01, time/batch = 16.5245s	
6358/22750 (epoch 13.974), train_loss = 1.19900540, grad/param norm = 2.0093e-01, time/batch = 17.1673s	
6359/22750 (epoch 13.976), train_loss = 1.26937095, grad/param norm = 2.0723e-01, time/batch = 19.4540s	
6360/22750 (epoch 13.978), train_loss = 1.06649269, grad/param norm = 1.6721e-01, time/batch = 17.5098s	
6361/22750 (epoch 13.980), train_loss = 1.35611286, grad/param norm = 2.1102e-01, time/batch = 18.1641s	
6362/22750 (epoch 13.982), train_loss = 1.11231494, grad/param norm = 1.6542e-01, time/batch = 19.7421s	
6363/22750 (epoch 13.985), train_loss = 1.42859810, grad/param norm = 2.0661e-01, time/batch = 17.9166s	
6364/22750 (epoch 13.987), train_loss = 0.95502087, grad/param norm = 1.6235e-01, time/batch = 18.2598s	
6365/22750 (epoch 13.989), train_loss = 1.11838343, grad/param norm = 1.7700e-01, time/batch = 18.4834s	
6366/22750 (epoch 13.991), train_loss = 1.25852819, grad/param norm = 1.9272e-01, time/batch = 19.6983s	
6367/22750 (epoch 13.993), train_loss = 1.31099005, grad/param norm = 1.9573e-01, time/batch = 21.4269s	
6368/22750 (epoch 13.996), train_loss = 1.11975581, grad/param norm = 2.0505e-01, time/batch = 19.5195s	
6369/22750 (epoch 13.998), train_loss = 1.35428766, grad/param norm = 2.0375e-01, time/batch = 16.2357s	
decayed learning rate by a factor 0.97 to 0.0017174680514	
6370/22750 (epoch 14.000), train_loss = 1.23495260, grad/param norm = 1.8877e-01, time/batch = 16.9990s	
6371/22750 (epoch 14.002), train_loss = 1.30738997, grad/param norm = 1.9506e-01, time/batch = 15.1301s	
6372/22750 (epoch 14.004), train_loss = 1.10457661, grad/param norm = 1.8074e-01, time/batch = 15.0555s	
6373/22750 (epoch 14.007), train_loss = 1.16849777, grad/param norm = 1.9532e-01, time/batch = 15.6113s	
6374/22750 (epoch 14.009), train_loss = 1.42360943, grad/param norm = 2.0029e-01, time/batch = 15.3783s	
6375/22750 (epoch 14.011), train_loss = 1.46261931, grad/param norm = 2.0254e-01, time/batch = 14.9712s	
6376/22750 (epoch 14.013), train_loss = 1.28119263, grad/param norm = 1.7893e-01, time/batch = 14.9124s	
6377/22750 (epoch 14.015), train_loss = 1.24078976, grad/param norm = 1.9712e-01, time/batch = 15.6277s	
6378/22750 (epoch 14.018), train_loss = 1.26495151, grad/param norm = 1.9449e-01, time/batch = 15.9321s	
6379/22750 (epoch 14.020), train_loss = 1.37848201, grad/param norm = 2.0485e-01, time/batch = 16.4872s	
6380/22750 (epoch 14.022), train_loss = 1.16306258, grad/param norm = 1.8712e-01, time/batch = 15.1425s	
6381/22750 (epoch 14.024), train_loss = 1.20916728, grad/param norm = 1.9704e-01, time/batch = 15.5326s	
6382/22750 (epoch 14.026), train_loss = 1.29847862, grad/param norm = 2.0572e-01, time/batch = 15.0423s	
6383/22750 (epoch 14.029), train_loss = 0.99007702, grad/param norm = 1.7169e-01, time/batch = 15.1428s	
6384/22750 (epoch 14.031), train_loss = 1.48419887, grad/param norm = 2.0256e-01, time/batch = 14.8886s	
6385/22750 (epoch 14.033), train_loss = 1.20579618, grad/param norm = 1.8154e-01, time/batch = 16.0008s	
6386/22750 (epoch 14.035), train_loss = 1.26852265, grad/param norm = 1.9348e-01, time/batch = 14.9693s	
6387/22750 (epoch 14.037), train_loss = 1.34105028, grad/param norm = 1.9043e-01, time/batch = 14.9992s	
6388/22750 (epoch 14.040), train_loss = 1.14768729, grad/param norm = 1.8434e-01, time/batch = 14.5855s	
6389/22750 (epoch 14.042), train_loss = 1.29935165, grad/param norm = 1.9480e-01, time/batch = 15.6221s	
6390/22750 (epoch 14.044), train_loss = 1.14626344, grad/param norm = 1.8063e-01, time/batch = 15.2192s	
6391/22750 (epoch 14.046), train_loss = 1.29604609, grad/param norm = 2.0731e-01, time/batch = 16.1542s	
6392/22750 (epoch 14.048), train_loss = 1.18173671, grad/param norm = 1.8324e-01, time/batch = 15.3556s	
6393/22750 (epoch 14.051), train_loss = 1.24966397, grad/param norm = 1.8220e-01, time/batch = 15.5366s	
6394/22750 (epoch 14.053), train_loss = 1.07105242, grad/param norm = 1.7188e-01, time/batch = 15.6886s	
6395/22750 (epoch 14.055), train_loss = 1.12341145, grad/param norm = 1.7752e-01, time/batch = 15.3732s	
6396/22750 (epoch 14.057), train_loss = 1.35770402, grad/param norm = 1.9064e-01, time/batch = 15.3622s	
6397/22750 (epoch 14.059), train_loss = 0.89535757, grad/param norm = 1.7160e-01, time/batch = 15.3928s	
6398/22750 (epoch 14.062), train_loss = 1.04600094, grad/param norm = 1.7927e-01, time/batch = 15.5288s	
6399/22750 (epoch 14.064), train_loss = 1.24238408, grad/param norm = 1.9444e-01, time/batch = 15.0731s	
6400/22750 (epoch 14.066), train_loss = 1.01559947, grad/param norm = 1.6254e-01, time/batch = 15.3980s	
6401/22750 (epoch 14.068), train_loss = 1.09534418, grad/param norm = 1.5756e-01, time/batch = 15.2206s	
6402/22750 (epoch 14.070), train_loss = 0.95335796, grad/param norm = 1.7173e-01, time/batch = 15.2925s	
6403/22750 (epoch 14.073), train_loss = 1.10752882, grad/param norm = 1.8983e-01, time/batch = 15.2858s	
6404/22750 (epoch 14.075), train_loss = 1.15282930, grad/param norm = 1.8262e-01, time/batch = 15.2829s	
6405/22750 (epoch 14.077), train_loss = 0.91571717, grad/param norm = 1.8404e-01, time/batch = 15.2972s	
6406/22750 (epoch 14.079), train_loss = 1.13649858, grad/param norm = 1.9686e-01, time/batch = 15.1217s	
6407/22750 (epoch 14.081), train_loss = 1.13867523, grad/param norm = 2.0048e-01, time/batch = 15.2040s	
6408/22750 (epoch 14.084), train_loss = 1.12030524, grad/param norm = 1.7838e-01, time/batch = 15.6078s	
6409/22750 (epoch 14.086), train_loss = 1.12089358, grad/param norm = 1.5979e-01, time/batch = 15.2386s	
6410/22750 (epoch 14.088), train_loss = 1.09947258, grad/param norm = 1.8685e-01, time/batch = 15.2275s	
6411/22750 (epoch 14.090), train_loss = 1.08238260, grad/param norm = 1.6980e-01, time/batch = 15.2368s	
6412/22750 (epoch 14.092), train_loss = 1.32704621, grad/param norm = 1.7535e-01, time/batch = 15.4687s	
6413/22750 (epoch 14.095), train_loss = 1.05524871, grad/param norm = 1.8000e-01, time/batch = 15.6105s	
6414/22750 (epoch 14.097), train_loss = 1.14143227, grad/param norm = 1.7706e-01, time/batch = 15.2032s	
6415/22750 (epoch 14.099), train_loss = 1.17309158, grad/param norm = 1.8642e-01, time/batch = 15.6877s	
6416/22750 (epoch 14.101), train_loss = 1.07243463, grad/param norm = 1.9362e-01, time/batch = 15.7869s	
6417/22750 (epoch 14.103), train_loss = 1.14986760, grad/param norm = 1.7938e-01, time/batch = 16.1608s	
6418/22750 (epoch 14.105), train_loss = 1.44179638, grad/param norm = 2.1112e-01, time/batch = 15.2165s	
6419/22750 (epoch 14.108), train_loss = 1.12347788, grad/param norm = 1.8532e-01, time/batch = 15.1403s	
6420/22750 (epoch 14.110), train_loss = 1.29744528, grad/param norm = 1.8740e-01, time/batch = 15.4543s	
6421/22750 (epoch 14.112), train_loss = 0.97526999, grad/param norm = 1.5993e-01, time/batch = 16.1630s	
6422/22750 (epoch 14.114), train_loss = 0.92418759, grad/param norm = 1.6934e-01, time/batch = 15.3887s	
6423/22750 (epoch 14.116), train_loss = 1.05110629, grad/param norm = 1.6683e-01, time/batch = 15.4629s	
6424/22750 (epoch 14.119), train_loss = 1.05437444, grad/param norm = 1.6184e-01, time/batch = 16.0960s	
6425/22750 (epoch 14.121), train_loss = 1.21814809, grad/param norm = 1.9717e-01, time/batch = 15.3620s	
6426/22750 (epoch 14.123), train_loss = 1.04532620, grad/param norm = 1.7156e-01, time/batch = 15.2193s	
6427/22750 (epoch 14.125), train_loss = 1.34035364, grad/param norm = 1.8452e-01, time/batch = 15.6046s	
6428/22750 (epoch 14.127), train_loss = 1.13974596, grad/param norm = 1.8815e-01, time/batch = 15.3473s	
6429/22750 (epoch 14.130), train_loss = 1.22759941, grad/param norm = 1.8312e-01, time/batch = 15.2689s	
6430/22750 (epoch 14.132), train_loss = 1.13771375, grad/param norm = 1.9043e-01, time/batch = 15.9084s	
6431/22750 (epoch 14.134), train_loss = 1.11727806, grad/param norm = 1.7724e-01, time/batch = 15.6267s	
6432/22750 (epoch 14.136), train_loss = 1.01402302, grad/param norm = 1.8810e-01, time/batch = 15.2181s	
6433/22750 (epoch 14.138), train_loss = 1.21718002, grad/param norm = 1.8932e-01, time/batch = 15.1534s	
6434/22750 (epoch 14.141), train_loss = 1.16515098, grad/param norm = 1.8628e-01, time/batch = 15.2050s	
6435/22750 (epoch 14.143), train_loss = 0.99891633, grad/param norm = 1.7002e-01, time/batch = 15.7603s	
6436/22750 (epoch 14.145), train_loss = 1.33924838, grad/param norm = 1.8946e-01, time/batch = 15.4504s	
6437/22750 (epoch 14.147), train_loss = 1.31125058, grad/param norm = 1.8786e-01, time/batch = 14.7144s	
6438/22750 (epoch 14.149), train_loss = 1.17457590, grad/param norm = 1.8454e-01, time/batch = 14.7059s	
6439/22750 (epoch 14.152), train_loss = 1.12099255, grad/param norm = 1.7876e-01, time/batch = 15.0366s	
6440/22750 (epoch 14.154), train_loss = 0.96830118, grad/param norm = 1.7434e-01, time/batch = 14.9620s	
6441/22750 (epoch 14.156), train_loss = 1.00235107, grad/param norm = 1.6686e-01, time/batch = 15.4457s	
6442/22750 (epoch 14.158), train_loss = 1.09598397, grad/param norm = 1.9235e-01, time/batch = 14.8277s	
6443/22750 (epoch 14.160), train_loss = 1.21469383, grad/param norm = 1.8693e-01, time/batch = 15.3896s	
6444/22750 (epoch 14.163), train_loss = 1.42914802, grad/param norm = 2.0913e-01, time/batch = 15.2284s	
6445/22750 (epoch 14.165), train_loss = 1.25379950, grad/param norm = 1.9598e-01, time/batch = 15.2948s	
6446/22750 (epoch 14.167), train_loss = 1.11961536, grad/param norm = 1.8727e-01, time/batch = 15.2911s	
6447/22750 (epoch 14.169), train_loss = 1.19032359, grad/param norm = 1.8695e-01, time/batch = 16.2165s	
6448/22750 (epoch 14.171), train_loss = 1.04118569, grad/param norm = 1.7526e-01, time/batch = 15.2813s	
6449/22750 (epoch 14.174), train_loss = 0.98655426, grad/param norm = 1.8420e-01, time/batch = 15.5276s	
6450/22750 (epoch 14.176), train_loss = 1.11070359, grad/param norm = 1.7054e-01, time/batch = 15.7657s	
6451/22750 (epoch 14.178), train_loss = 1.11792995, grad/param norm = 1.6862e-01, time/batch = 15.8504s	
6452/22750 (epoch 14.180), train_loss = 1.29012639, grad/param norm = 2.1586e-01, time/batch = 15.2883s	
6453/22750 (epoch 14.182), train_loss = 1.29260873, grad/param norm = 1.8330e-01, time/batch = 15.2271s	
6454/22750 (epoch 14.185), train_loss = 1.30495366, grad/param norm = 1.9649e-01, time/batch = 16.1939s	
6455/22750 (epoch 14.187), train_loss = 1.06786993, grad/param norm = 1.8736e-01, time/batch = 15.5453s	
6456/22750 (epoch 14.189), train_loss = 1.10938364, grad/param norm = 1.8756e-01, time/batch = 15.4697s	
6457/22750 (epoch 14.191), train_loss = 1.04320665, grad/param norm = 1.5823e-01, time/batch = 15.1392s	
6458/22750 (epoch 14.193), train_loss = 1.25075491, grad/param norm = 1.9448e-01, time/batch = 15.6955s	
6459/22750 (epoch 14.196), train_loss = 1.15525750, grad/param norm = 1.8053e-01, time/batch = 15.6123s	
6460/22750 (epoch 14.198), train_loss = 0.89301738, grad/param norm = 1.4990e-01, time/batch = 14.9750s	
6461/22750 (epoch 14.200), train_loss = 1.17276676, grad/param norm = 1.8452e-01, time/batch = 15.1311s	
6462/22750 (epoch 14.202), train_loss = 1.29358434, grad/param norm = 2.0575e-01, time/batch = 15.9099s	
6463/22750 (epoch 14.204), train_loss = 1.23035033, grad/param norm = 1.7495e-01, time/batch = 23.7772s	
6464/22750 (epoch 14.207), train_loss = 1.14153367, grad/param norm = 1.8271e-01, time/batch = 20.2607s	
6465/22750 (epoch 14.209), train_loss = 1.07255054, grad/param norm = 1.8569e-01, time/batch = 16.3764s	
6466/22750 (epoch 14.211), train_loss = 1.09425599, grad/param norm = 1.9638e-01, time/batch = 19.6044s	
6467/22750 (epoch 14.213), train_loss = 0.98168963, grad/param norm = 1.7730e-01, time/batch = 18.1728s	
6468/22750 (epoch 14.215), train_loss = 0.92207106, grad/param norm = 1.6545e-01, time/batch = 18.9134s	
6469/22750 (epoch 14.218), train_loss = 0.99578953, grad/param norm = 1.9691e-01, time/batch = 16.8270s	
6470/22750 (epoch 14.220), train_loss = 1.04039762, grad/param norm = 1.7683e-01, time/batch = 20.2324s	
6471/22750 (epoch 14.222), train_loss = 0.97239203, grad/param norm = 2.0434e-01, time/batch = 19.3311s	
6472/22750 (epoch 14.224), train_loss = 1.08099212, grad/param norm = 1.8818e-01, time/batch = 20.4762s	
6473/22750 (epoch 14.226), train_loss = 1.26851986, grad/param norm = 1.9843e-01, time/batch = 20.1712s	
6474/22750 (epoch 14.229), train_loss = 1.19260838, grad/param norm = 1.9916e-01, time/batch = 15.4173s	
6475/22750 (epoch 14.231), train_loss = 1.08655141, grad/param norm = 1.8355e-01, time/batch = 16.9441s	
6476/22750 (epoch 14.233), train_loss = 1.02623272, grad/param norm = 1.7940e-01, time/batch = 18.6321s	
6477/22750 (epoch 14.235), train_loss = 0.98550594, grad/param norm = 1.8489e-01, time/batch = 18.8428s	
6478/22750 (epoch 14.237), train_loss = 1.07622553, grad/param norm = 1.9186e-01, time/batch = 18.5630s	
6479/22750 (epoch 14.240), train_loss = 1.15777646, grad/param norm = 1.6005e-01, time/batch = 20.1532s	
6480/22750 (epoch 14.242), train_loss = 1.43690597, grad/param norm = 2.1446e-01, time/batch = 16.8255s	
6481/22750 (epoch 14.244), train_loss = 1.30382762, grad/param norm = 1.9124e-01, time/batch = 19.0823s	
6482/22750 (epoch 14.246), train_loss = 1.36649549, grad/param norm = 1.8984e-01, time/batch = 29.9541s	
6483/22750 (epoch 14.248), train_loss = 1.14003006, grad/param norm = 1.9781e-01, time/batch = 19.6072s	
6484/22750 (epoch 14.251), train_loss = 1.35771045, grad/param norm = 1.8955e-01, time/batch = 16.8406s	
6485/22750 (epoch 14.253), train_loss = 1.17701247, grad/param norm = 1.8603e-01, time/batch = 19.1607s	
6486/22750 (epoch 14.255), train_loss = 1.17740064, grad/param norm = 1.8495e-01, time/batch = 17.9220s	
6487/22750 (epoch 14.257), train_loss = 1.11865579, grad/param norm = 1.8960e-01, time/batch = 17.0659s	
6488/22750 (epoch 14.259), train_loss = 1.33099776, grad/param norm = 2.1781e-01, time/batch = 18.1643s	
6489/22750 (epoch 14.262), train_loss = 1.13900268, grad/param norm = 1.8403e-01, time/batch = 19.9830s	
6490/22750 (epoch 14.264), train_loss = 1.00473161, grad/param norm = 1.8347e-01, time/batch = 18.0049s	
6491/22750 (epoch 14.266), train_loss = 1.20571744, grad/param norm = 2.3424e-01, time/batch = 20.4210s	
6492/22750 (epoch 14.268), train_loss = 1.32432257, grad/param norm = 2.0329e-01, time/batch = 18.6958s	
6493/22750 (epoch 14.270), train_loss = 1.09786553, grad/param norm = 1.8511e-01, time/batch = 20.1050s	
6494/22750 (epoch 14.273), train_loss = 1.46303201, grad/param norm = 2.2073e-01, time/batch = 18.9142s	
6495/22750 (epoch 14.275), train_loss = 1.25627007, grad/param norm = 1.8174e-01, time/batch = 20.0844s	
6496/22750 (epoch 14.277), train_loss = 1.13244328, grad/param norm = 1.9352e-01, time/batch = 19.9182s	
6497/22750 (epoch 14.279), train_loss = 0.99778258, grad/param norm = 1.8269e-01, time/batch = 18.5819s	
6498/22750 (epoch 14.281), train_loss = 1.29437156, grad/param norm = 1.9625e-01, time/batch = 19.5715s	
6499/22750 (epoch 14.284), train_loss = 1.13878568, grad/param norm = 1.8178e-01, time/batch = 20.0688s	
6500/22750 (epoch 14.286), train_loss = 1.31561068, grad/param norm = 1.9996e-01, time/batch = 18.7670s	
6501/22750 (epoch 14.288), train_loss = 1.35454286, grad/param norm = 1.9309e-01, time/batch = 21.1022s	
6502/22750 (epoch 14.290), train_loss = 1.15751265, grad/param norm = 1.9001e-01, time/batch = 19.0903s	
6503/22750 (epoch 14.292), train_loss = 1.23094158, grad/param norm = 2.0514e-01, time/batch = 15.8777s	
6504/22750 (epoch 14.295), train_loss = 1.21348386, grad/param norm = 1.7374e-01, time/batch = 16.9778s	
6505/22750 (epoch 14.297), train_loss = 1.10956110, grad/param norm = 1.7264e-01, time/batch = 16.2583s	
6506/22750 (epoch 14.299), train_loss = 1.30853885, grad/param norm = 1.9445e-01, time/batch = 16.3539s	
6507/22750 (epoch 14.301), train_loss = 1.20230736, grad/param norm = 1.9605e-01, time/batch = 15.8665s	
6508/22750 (epoch 14.303), train_loss = 1.27864830, grad/param norm = 1.9330e-01, time/batch = 18.5051s	
6509/22750 (epoch 14.305), train_loss = 1.40366368, grad/param norm = 1.9172e-01, time/batch = 17.1475s	
6510/22750 (epoch 14.308), train_loss = 1.22539269, grad/param norm = 1.7930e-01, time/batch = 17.9277s	
6511/22750 (epoch 14.310), train_loss = 1.07154172, grad/param norm = 1.9695e-01, time/batch = 19.3663s	
6512/22750 (epoch 14.312), train_loss = 1.23480646, grad/param norm = 1.9794e-01, time/batch = 19.8511s	
6513/22750 (epoch 14.314), train_loss = 1.19398184, grad/param norm = 1.7789e-01, time/batch = 16.6772s	
6514/22750 (epoch 14.316), train_loss = 1.13190535, grad/param norm = 1.9139e-01, time/batch = 20.3197s	
6515/22750 (epoch 14.319), train_loss = 1.22079540, grad/param norm = 1.9828e-01, time/batch = 17.5080s	
6516/22750 (epoch 14.321), train_loss = 1.12623026, grad/param norm = 1.9563e-01, time/batch = 18.2538s	
6517/22750 (epoch 14.323), train_loss = 1.14709312, grad/param norm = 1.8386e-01, time/batch = 19.3308s	
6518/22750 (epoch 14.325), train_loss = 0.96382098, grad/param norm = 1.8674e-01, time/batch = 19.4989s	
6519/22750 (epoch 14.327), train_loss = 1.17990485, grad/param norm = 1.9097e-01, time/batch = 19.1927s	
6520/22750 (epoch 14.330), train_loss = 1.44238170, grad/param norm = 2.0704e-01, time/batch = 17.2695s	
6521/22750 (epoch 14.332), train_loss = 1.38915561, grad/param norm = 1.8863e-01, time/batch = 20.1887s	
6522/22750 (epoch 14.334), train_loss = 0.96765271, grad/param norm = 1.6848e-01, time/batch = 18.0316s	
6523/22750 (epoch 14.336), train_loss = 1.24126332, grad/param norm = 1.9278e-01, time/batch = 17.9112s	
6524/22750 (epoch 14.338), train_loss = 1.13640349, grad/param norm = 1.8932e-01, time/batch = 18.5972s	
6525/22750 (epoch 14.341), train_loss = 1.14853780, grad/param norm = 1.8833e-01, time/batch = 19.5079s	
6526/22750 (epoch 14.343), train_loss = 0.99375751, grad/param norm = 1.8294e-01, time/batch = 17.7539s	
6527/22750 (epoch 14.345), train_loss = 1.31304335, grad/param norm = 1.9958e-01, time/batch = 19.0024s	
6528/22750 (epoch 14.347), train_loss = 1.34807500, grad/param norm = 2.0902e-01, time/batch = 20.0214s	
6529/22750 (epoch 14.349), train_loss = 0.94158991, grad/param norm = 1.9911e-01, time/batch = 18.6790s	
6530/22750 (epoch 14.352), train_loss = 1.26979286, grad/param norm = 1.8838e-01, time/batch = 18.2622s	
6531/22750 (epoch 14.354), train_loss = 1.31719784, grad/param norm = 2.0333e-01, time/batch = 16.6898s	
6532/22750 (epoch 14.356), train_loss = 1.33059915, grad/param norm = 1.9603e-01, time/batch = 16.7512s	
6533/22750 (epoch 14.358), train_loss = 1.17774221, grad/param norm = 1.9401e-01, time/batch = 16.6170s	
6534/22750 (epoch 14.360), train_loss = 1.37865929, grad/param norm = 1.8470e-01, time/batch = 17.5162s	
6535/22750 (epoch 14.363), train_loss = 1.14707179, grad/param norm = 1.7115e-01, time/batch = 18.3943s	
6536/22750 (epoch 14.365), train_loss = 0.95268370, grad/param norm = 1.7589e-01, time/batch = 18.7474s	
6537/22750 (epoch 14.367), train_loss = 1.03067386, grad/param norm = 1.9876e-01, time/batch = 17.6620s	
6538/22750 (epoch 14.369), train_loss = 1.14661307, grad/param norm = 1.8377e-01, time/batch = 20.5887s	
6539/22750 (epoch 14.371), train_loss = 1.10856164, grad/param norm = 1.7471e-01, time/batch = 17.3527s	
6540/22750 (epoch 14.374), train_loss = 1.05349960, grad/param norm = 1.7926e-01, time/batch = 19.2046s	
6541/22750 (epoch 14.376), train_loss = 1.13881890, grad/param norm = 1.8112e-01, time/batch = 19.3455s	
6542/22750 (epoch 14.378), train_loss = 1.19931746, grad/param norm = 1.8993e-01, time/batch = 17.7598s	
6543/22750 (epoch 14.380), train_loss = 1.32698268, grad/param norm = 1.9929e-01, time/batch = 18.8282s	
6544/22750 (epoch 14.382), train_loss = 1.11140519, grad/param norm = 1.8011e-01, time/batch = 19.7484s	
6545/22750 (epoch 14.385), train_loss = 1.24857531, grad/param norm = 1.7501e-01, time/batch = 16.9286s	
6546/22750 (epoch 14.387), train_loss = 1.21722184, grad/param norm = 1.8039e-01, time/batch = 18.5106s	
6547/22750 (epoch 14.389), train_loss = 0.90332248, grad/param norm = 1.7139e-01, time/batch = 19.5280s	
6548/22750 (epoch 14.391), train_loss = 0.73408512, grad/param norm = 1.4419e-01, time/batch = 18.0990s	
6549/22750 (epoch 14.393), train_loss = 1.03188702, grad/param norm = 1.7434e-01, time/batch = 19.2749s	
6550/22750 (epoch 14.396), train_loss = 1.19882119, grad/param norm = 1.9716e-01, time/batch = 19.9946s	
6551/22750 (epoch 14.398), train_loss = 1.11817841, grad/param norm = 1.7397e-01, time/batch = 20.2312s	
6552/22750 (epoch 14.400), train_loss = 1.12874792, grad/param norm = 1.6972e-01, time/batch = 19.2381s	
6553/22750 (epoch 14.402), train_loss = 1.22362860, grad/param norm = 1.7595e-01, time/batch = 19.1599s	
6554/22750 (epoch 14.404), train_loss = 1.34318466, grad/param norm = 1.8322e-01, time/batch = 19.4856s	
6555/22750 (epoch 14.407), train_loss = 1.28773254, grad/param norm = 1.8802e-01, time/batch = 17.2111s	
6556/22750 (epoch 14.409), train_loss = 1.15708496, grad/param norm = 1.8088e-01, time/batch = 18.3572s	
6557/22750 (epoch 14.411), train_loss = 1.12706784, grad/param norm = 1.7535e-01, time/batch = 18.2056s	
6558/22750 (epoch 14.413), train_loss = 0.93238120, grad/param norm = 1.8198e-01, time/batch = 17.6986s	
6559/22750 (epoch 14.415), train_loss = 0.89595681, grad/param norm = 1.6006e-01, time/batch = 17.9747s	
6560/22750 (epoch 14.418), train_loss = 1.10946040, grad/param norm = 1.9249e-01, time/batch = 18.7558s	
6561/22750 (epoch 14.420), train_loss = 1.30493170, grad/param norm = 2.4474e-01, time/batch = 18.6513s	
6562/22750 (epoch 14.422), train_loss = 1.40617922, grad/param norm = 2.1833e-01, time/batch = 19.0695s	
6563/22750 (epoch 14.424), train_loss = 1.43721836, grad/param norm = 2.2703e-01, time/batch = 19.2563s	
6564/22750 (epoch 14.426), train_loss = 1.39562287, grad/param norm = 1.9705e-01, time/batch = 17.8346s	
6565/22750 (epoch 14.429), train_loss = 1.00004276, grad/param norm = 1.8539e-01, time/batch = 19.7714s	
6566/22750 (epoch 14.431), train_loss = 0.97212509, grad/param norm = 1.8648e-01, time/batch = 20.1948s	
6567/22750 (epoch 14.433), train_loss = 1.07829751, grad/param norm = 1.6849e-01, time/batch = 19.5149s	
6568/22750 (epoch 14.435), train_loss = 0.90823674, grad/param norm = 1.6185e-01, time/batch = 19.7404s	
6569/22750 (epoch 14.437), train_loss = 0.79675879, grad/param norm = 1.6420e-01, time/batch = 16.7640s	
6570/22750 (epoch 14.440), train_loss = 1.19666661, grad/param norm = 1.9130e-01, time/batch = 15.6375s	
6571/22750 (epoch 14.442), train_loss = 1.21422330, grad/param norm = 2.0531e-01, time/batch = 16.6801s	
6572/22750 (epoch 14.444), train_loss = 1.15268471, grad/param norm = 2.0456e-01, time/batch = 19.0906s	
6573/22750 (epoch 14.446), train_loss = 1.15935049, grad/param norm = 1.9639e-01, time/batch = 19.2508s	
6574/22750 (epoch 14.448), train_loss = 1.45604288, grad/param norm = 2.0110e-01, time/batch = 16.7623s	
6575/22750 (epoch 14.451), train_loss = 1.34473788, grad/param norm = 1.9513e-01, time/batch = 19.9424s	
6576/22750 (epoch 14.453), train_loss = 1.37988344, grad/param norm = 1.9496e-01, time/batch = 17.1574s	
6577/22750 (epoch 14.455), train_loss = 1.47119617, grad/param norm = 2.1112e-01, time/batch = 17.4259s	
6578/22750 (epoch 14.457), train_loss = 1.32105014, grad/param norm = 2.4934e-01, time/batch = 15.7681s	
6579/22750 (epoch 14.459), train_loss = 1.28083218, grad/param norm = 1.9014e-01, time/batch = 15.3617s	
6580/22750 (epoch 14.462), train_loss = 1.27156298, grad/param norm = 1.8081e-01, time/batch = 15.3611s	
6581/22750 (epoch 14.464), train_loss = 0.99899550, grad/param norm = 2.0723e-01, time/batch = 15.5249s	
6582/22750 (epoch 14.466), train_loss = 1.39701273, grad/param norm = 2.1682e-01, time/batch = 15.4576s	
6583/22750 (epoch 14.468), train_loss = 1.15857493, grad/param norm = 1.9046e-01, time/batch = 15.2829s	
6584/22750 (epoch 14.470), train_loss = 1.30720313, grad/param norm = 1.9677e-01, time/batch = 15.5978s	
6585/22750 (epoch 14.473), train_loss = 1.16641594, grad/param norm = 1.9833e-01, time/batch = 15.4838s	
6586/22750 (epoch 14.475), train_loss = 1.19294396, grad/param norm = 2.0255e-01, time/batch = 15.1564s	
6587/22750 (epoch 14.477), train_loss = 0.98418515, grad/param norm = 1.6617e-01, time/batch = 14.9826s	
6588/22750 (epoch 14.479), train_loss = 1.00032040, grad/param norm = 1.7332e-01, time/batch = 15.5389s	
6589/22750 (epoch 14.481), train_loss = 0.93087440, grad/param norm = 1.6914e-01, time/batch = 15.5298s	
6590/22750 (epoch 14.484), train_loss = 0.86603279, grad/param norm = 1.8547e-01, time/batch = 15.3654s	
6591/22750 (epoch 14.486), train_loss = 1.00856074, grad/param norm = 1.8470e-01, time/batch = 15.0465s	
6592/22750 (epoch 14.488), train_loss = 0.88426445, grad/param norm = 1.8713e-01, time/batch = 14.8868s	
6593/22750 (epoch 14.490), train_loss = 1.19025126, grad/param norm = 1.8412e-01, time/batch = 15.7702s	
6594/22750 (epoch 14.492), train_loss = 1.31410465, grad/param norm = 1.9659e-01, time/batch = 14.9593s	
6595/22750 (epoch 14.495), train_loss = 1.04996890, grad/param norm = 1.6938e-01, time/batch = 14.9004s	
6596/22750 (epoch 14.497), train_loss = 1.19097469, grad/param norm = 2.1538e-01, time/batch = 14.7483s	
6597/22750 (epoch 14.499), train_loss = 1.06902724, grad/param norm = 1.8387e-01, time/batch = 13.6689s	
6598/22750 (epoch 14.501), train_loss = 1.17207214, grad/param norm = 1.9221e-01, time/batch = 0.6889s	
6599/22750 (epoch 14.503), train_loss = 1.18458132, grad/param norm = 1.9678e-01, time/batch = 0.6918s	
6600/22750 (epoch 14.505), train_loss = 1.02468820, grad/param norm = 1.7913e-01, time/batch = 0.6878s	
6601/22750 (epoch 14.508), train_loss = 0.95442667, grad/param norm = 1.6953e-01, time/batch = 0.6846s	
6602/22750 (epoch 14.510), train_loss = 1.00408131, grad/param norm = 1.7177e-01, time/batch = 0.6869s	
6603/22750 (epoch 14.512), train_loss = 1.04419898, grad/param norm = 1.6530e-01, time/batch = 0.6908s	
6604/22750 (epoch 14.514), train_loss = 1.07182327, grad/param norm = 1.7244e-01, time/batch = 0.6856s	
6605/22750 (epoch 14.516), train_loss = 1.06241359, grad/param norm = 1.8096e-01, time/batch = 1.0158s	
6606/22750 (epoch 14.519), train_loss = 1.25175693, grad/param norm = 1.8802e-01, time/batch = 1.0075s	
6607/22750 (epoch 14.521), train_loss = 1.12879871, grad/param norm = 1.9035e-01, time/batch = 1.0138s	
6608/22750 (epoch 14.523), train_loss = 1.10585200, grad/param norm = 2.0118e-01, time/batch = 1.0023s	
6609/22750 (epoch 14.525), train_loss = 1.33207043, grad/param norm = 1.9297e-01, time/batch = 1.0324s	
6610/22750 (epoch 14.527), train_loss = 1.15979588, grad/param norm = 1.8032e-01, time/batch = 1.8920s	
6611/22750 (epoch 14.530), train_loss = 1.08802865, grad/param norm = 1.9297e-01, time/batch = 1.8831s	
6612/22750 (epoch 14.532), train_loss = 0.98455756, grad/param norm = 1.6186e-01, time/batch = 7.4597s	
6613/22750 (epoch 14.534), train_loss = 1.25784908, grad/param norm = 1.8601e-01, time/batch = 14.9754s	
6614/22750 (epoch 14.536), train_loss = 1.17862263, grad/param norm = 1.7783e-01, time/batch = 14.8893s	
6615/22750 (epoch 14.538), train_loss = 1.16509241, grad/param norm = 1.6838e-01, time/batch = 15.5524s	
6616/22750 (epoch 14.541), train_loss = 0.99750354, grad/param norm = 1.7966e-01, time/batch = 15.3745s	
6617/22750 (epoch 14.543), train_loss = 1.01107866, grad/param norm = 2.0013e-01, time/batch = 16.3164s	
6618/22750 (epoch 14.545), train_loss = 1.28048454, grad/param norm = 1.7743e-01, time/batch = 15.3551s	
6619/22750 (epoch 14.547), train_loss = 1.03333539, grad/param norm = 1.7131e-01, time/batch = 15.2937s	
6620/22750 (epoch 14.549), train_loss = 1.10103897, grad/param norm = 1.8425e-01, time/batch = 15.5156s	
6621/22750 (epoch 14.552), train_loss = 1.23629787, grad/param norm = 1.9390e-01, time/batch = 15.4731s	
6622/22750 (epoch 14.554), train_loss = 1.25150550, grad/param norm = 1.9074e-01, time/batch = 15.6997s	
6623/22750 (epoch 14.556), train_loss = 1.16033118, grad/param norm = 1.9585e-01, time/batch = 14.9220s	
6624/22750 (epoch 14.558), train_loss = 1.26883758, grad/param norm = 1.9100e-01, time/batch = 15.0541s	
6625/22750 (epoch 14.560), train_loss = 1.09439843, grad/param norm = 1.8125e-01, time/batch = 15.2146s	
6626/22750 (epoch 14.563), train_loss = 1.27248737, grad/param norm = 1.8194e-01, time/batch = 15.4460s	
6627/22750 (epoch 14.565), train_loss = 1.21032963, grad/param norm = 1.8975e-01, time/batch = 15.4502s	
6628/22750 (epoch 14.567), train_loss = 1.21285934, grad/param norm = 1.9325e-01, time/batch = 15.2161s	
6629/22750 (epoch 14.569), train_loss = 1.14202506, grad/param norm = 1.8899e-01, time/batch = 15.0502s	
6630/22750 (epoch 14.571), train_loss = 1.16255011, grad/param norm = 1.8810e-01, time/batch = 15.5101s	
6631/22750 (epoch 14.574), train_loss = 1.04142158, grad/param norm = 1.7705e-01, time/batch = 15.5400s	
6632/22750 (epoch 14.576), train_loss = 1.15728153, grad/param norm = 1.8953e-01, time/batch = 14.9129s	
6633/22750 (epoch 14.578), train_loss = 1.01102464, grad/param norm = 1.8210e-01, time/batch = 14.9053s	
6634/22750 (epoch 14.580), train_loss = 1.18664480, grad/param norm = 2.0954e-01, time/batch = 15.6297s	
6635/22750 (epoch 14.582), train_loss = 1.01775828, grad/param norm = 1.7144e-01, time/batch = 15.1420s	
6636/22750 (epoch 14.585), train_loss = 0.96098089, grad/param norm = 1.8378e-01, time/batch = 15.4333s	
6637/22750 (epoch 14.587), train_loss = 0.97057684, grad/param norm = 1.5887e-01, time/batch = 15.1132s	
6638/22750 (epoch 14.589), train_loss = 0.94601907, grad/param norm = 1.6665e-01, time/batch = 15.5399s	
6639/22750 (epoch 14.591), train_loss = 1.10994536, grad/param norm = 1.8332e-01, time/batch = 15.6771s	
6640/22750 (epoch 14.593), train_loss = 1.34088893, grad/param norm = 1.9173e-01, time/batch = 15.2039s	
6641/22750 (epoch 14.596), train_loss = 1.34137802, grad/param norm = 1.9344e-01, time/batch = 15.2915s	
6642/22750 (epoch 14.598), train_loss = 1.37327573, grad/param norm = 1.9676e-01, time/batch = 15.6345s	
6643/22750 (epoch 14.600), train_loss = 1.30548217, grad/param norm = 1.9554e-01, time/batch = 15.0793s	
6644/22750 (epoch 14.602), train_loss = 1.03996085, grad/param norm = 1.6691e-01, time/batch = 15.8767s	
6645/22750 (epoch 14.604), train_loss = 1.09235536, grad/param norm = 1.7475e-01, time/batch = 15.1603s	
6646/22750 (epoch 14.607), train_loss = 0.94955504, grad/param norm = 1.6657e-01, time/batch = 15.4440s	
6647/22750 (epoch 14.609), train_loss = 0.90328645, grad/param norm = 1.6373e-01, time/batch = 15.2237s	
6648/22750 (epoch 14.611), train_loss = 1.10315850, grad/param norm = 1.8451e-01, time/batch = 15.7602s	
6649/22750 (epoch 14.613), train_loss = 1.03046031, grad/param norm = 1.8111e-01, time/batch = 15.7707s	
6650/22750 (epoch 14.615), train_loss = 1.07832743, grad/param norm = 1.7549e-01, time/batch = 15.7671s	
6651/22750 (epoch 14.618), train_loss = 1.09268298, grad/param norm = 1.7465e-01, time/batch = 15.2825s	
6652/22750 (epoch 14.620), train_loss = 1.13099157, grad/param norm = 1.9048e-01, time/batch = 15.2216s	
6653/22750 (epoch 14.622), train_loss = 0.92123001, grad/param norm = 1.5880e-01, time/batch = 15.2371s	
6654/22750 (epoch 14.624), train_loss = 1.06079015, grad/param norm = 1.9173e-01, time/batch = 15.1478s	
6655/22750 (epoch 14.626), train_loss = 0.96715792, grad/param norm = 1.7324e-01, time/batch = 14.9168s	
6656/22750 (epoch 14.629), train_loss = 1.07577238, grad/param norm = 1.7822e-01, time/batch = 14.9910s	
6657/22750 (epoch 14.631), train_loss = 1.09710243, grad/param norm = 1.8002e-01, time/batch = 15.2964s	
6658/22750 (epoch 14.633), train_loss = 0.95507718, grad/param norm = 1.6855e-01, time/batch = 15.4552s	
6659/22750 (epoch 14.635), train_loss = 1.14944375, grad/param norm = 1.8529e-01, time/batch = 15.2047s	
6660/22750 (epoch 14.637), train_loss = 1.21207001, grad/param norm = 1.9332e-01, time/batch = 15.1244s	
6661/22750 (epoch 14.640), train_loss = 1.24378541, grad/param norm = 1.9505e-01, time/batch = 15.4589s	
6662/22750 (epoch 14.642), train_loss = 1.29783387, grad/param norm = 1.8955e-01, time/batch = 15.3664s	
6663/22750 (epoch 14.644), train_loss = 1.15742873, grad/param norm = 1.8857e-01, time/batch = 15.6092s	
6664/22750 (epoch 14.646), train_loss = 1.24339298, grad/param norm = 2.0980e-01, time/batch = 14.9162s	
6665/22750 (epoch 14.648), train_loss = 1.17649264, grad/param norm = 2.0077e-01, time/batch = 15.3974s	
6666/22750 (epoch 14.651), train_loss = 1.23027762, grad/param norm = 1.9102e-01, time/batch = 15.1382s	
6667/22750 (epoch 14.653), train_loss = 1.21428915, grad/param norm = 1.8675e-01, time/batch = 15.2213s	
6668/22750 (epoch 14.655), train_loss = 1.15528675, grad/param norm = 1.8537e-01, time/batch = 16.4614s	
6669/22750 (epoch 14.657), train_loss = 1.34314896, grad/param norm = 2.0005e-01, time/batch = 16.1520s	
6670/22750 (epoch 14.659), train_loss = 1.43345834, grad/param norm = 2.0899e-01, time/batch = 15.3699s	
6671/22750 (epoch 14.662), train_loss = 1.41530878, grad/param norm = 2.2476e-01, time/batch = 15.6928s	
6672/22750 (epoch 14.664), train_loss = 1.22066726, grad/param norm = 1.9587e-01, time/batch = 15.1313s	
6673/22750 (epoch 14.666), train_loss = 1.01343374, grad/param norm = 1.8870e-01, time/batch = 15.7681s	
6674/22750 (epoch 14.668), train_loss = 1.17666183, grad/param norm = 1.8282e-01, time/batch = 14.9888s	
6675/22750 (epoch 14.670), train_loss = 1.16615762, grad/param norm = 1.8358e-01, time/batch = 14.9938s	
6676/22750 (epoch 14.673), train_loss = 1.45449283, grad/param norm = 2.1247e-01, time/batch = 15.0735s	
6677/22750 (epoch 14.675), train_loss = 1.59792248, grad/param norm = 2.2105e-01, time/batch = 15.6202s	
6678/22750 (epoch 14.677), train_loss = 1.38725486, grad/param norm = 2.3979e-01, time/batch = 15.7012s	
6679/22750 (epoch 14.679), train_loss = 1.41810386, grad/param norm = 2.1502e-01, time/batch = 15.1297s	
6680/22750 (epoch 14.681), train_loss = 1.35447576, grad/param norm = 2.1184e-01, time/batch = 15.3725s	
6681/22750 (epoch 14.684), train_loss = 1.33873600, grad/param norm = 2.0403e-01, time/batch = 15.4536s	
6682/22750 (epoch 14.686), train_loss = 1.32641666, grad/param norm = 2.0801e-01, time/batch = 15.1274s	
6683/22750 (epoch 14.688), train_loss = 1.31128221, grad/param norm = 2.0184e-01, time/batch = 15.1304s	
6684/22750 (epoch 14.690), train_loss = 1.31436560, grad/param norm = 2.0704e-01, time/batch = 15.3619s	
6685/22750 (epoch 14.692), train_loss = 1.38849233, grad/param norm = 2.0242e-01, time/batch = 16.6125s	
6686/22750 (epoch 14.695), train_loss = 1.22583218, grad/param norm = 2.0349e-01, time/batch = 19.1983s	
6687/22750 (epoch 14.697), train_loss = 1.15093610, grad/param norm = 1.8935e-01, time/batch = 16.5720s	
6688/22750 (epoch 14.699), train_loss = 1.17592665, grad/param norm = 1.8418e-01, time/batch = 18.3402s	
6689/22750 (epoch 14.701), train_loss = 1.02588567, grad/param norm = 1.7970e-01, time/batch = 18.6685s	
6690/22750 (epoch 14.703), train_loss = 1.17930298, grad/param norm = 1.7550e-01, time/batch = 18.6706s	
6691/22750 (epoch 14.705), train_loss = 1.08163997, grad/param norm = 1.8144e-01, time/batch = 17.7400s	
6692/22750 (epoch 14.708), train_loss = 1.18229534, grad/param norm = 2.0552e-01, time/batch = 17.8935s	
6693/22750 (epoch 14.710), train_loss = 1.01893909, grad/param norm = 1.8157e-01, time/batch = 18.3402s	
6694/22750 (epoch 14.712), train_loss = 1.05956620, grad/param norm = 1.7468e-01, time/batch = 16.9914s	
6695/22750 (epoch 14.714), train_loss = 0.95569496, grad/param norm = 1.7278e-01, time/batch = 16.2790s	
6696/22750 (epoch 14.716), train_loss = 1.03332286, grad/param norm = 1.8039e-01, time/batch = 17.4488s	
6697/22750 (epoch 14.719), train_loss = 1.24555034, grad/param norm = 2.0889e-01, time/batch = 17.3731s	
6698/22750 (epoch 14.721), train_loss = 1.27451442, grad/param norm = 1.8179e-01, time/batch = 16.9259s	
6699/22750 (epoch 14.723), train_loss = 1.19401575, grad/param norm = 1.9542e-01, time/batch = 16.2380s	
6700/22750 (epoch 14.725), train_loss = 1.14273929, grad/param norm = 1.8842e-01, time/batch = 17.6065s	
6701/22750 (epoch 14.727), train_loss = 1.08558875, grad/param norm = 1.6925e-01, time/batch = 18.4235s	
6702/22750 (epoch 14.730), train_loss = 1.10754095, grad/param norm = 1.8764e-01, time/batch = 18.0924s	
6703/22750 (epoch 14.732), train_loss = 1.08093062, grad/param norm = 1.7659e-01, time/batch = 18.2405s	
6704/22750 (epoch 14.734), train_loss = 0.91606052, grad/param norm = 1.7287e-01, time/batch = 17.0967s	
6705/22750 (epoch 14.736), train_loss = 1.06445708, grad/param norm = 1.7418e-01, time/batch = 31.9898s	
6706/22750 (epoch 14.738), train_loss = 1.20140106, grad/param norm = 2.1143e-01, time/batch = 18.6829s	
6707/22750 (epoch 14.741), train_loss = 1.27319331, grad/param norm = 2.0123e-01, time/batch = 18.9229s	
6708/22750 (epoch 14.743), train_loss = 1.20281685, grad/param norm = 1.8571e-01, time/batch = 18.1677s	
6709/22750 (epoch 14.745), train_loss = 1.01428917, grad/param norm = 1.7230e-01, time/batch = 18.8374s	
6710/22750 (epoch 14.747), train_loss = 1.09296988, grad/param norm = 1.7783e-01, time/batch = 19.1575s	
6711/22750 (epoch 14.749), train_loss = 1.36516825, grad/param norm = 2.1832e-01, time/batch = 19.1634s	
6712/22750 (epoch 14.752), train_loss = 1.11677607, grad/param norm = 1.8057e-01, time/batch = 16.5392s	
6713/22750 (epoch 14.754), train_loss = 1.21270123, grad/param norm = 2.1829e-01, time/batch = 17.2033s	
6714/22750 (epoch 14.756), train_loss = 1.04217156, grad/param norm = 2.0776e-01, time/batch = 16.5217s	
6715/22750 (epoch 14.758), train_loss = 1.03245739, grad/param norm = 1.8787e-01, time/batch = 15.9583s	
6716/22750 (epoch 14.760), train_loss = 1.13876698, grad/param norm = 1.9064e-01, time/batch = 15.9307s	
6717/22750 (epoch 14.763), train_loss = 1.21872518, grad/param norm = 1.9137e-01, time/batch = 17.5084s	
6718/22750 (epoch 14.765), train_loss = 1.14971625, grad/param norm = 1.9866e-01, time/batch = 17.2634s	
6719/22750 (epoch 14.767), train_loss = 1.18827851, grad/param norm = 1.9233e-01, time/batch = 17.7562s	
6720/22750 (epoch 14.769), train_loss = 1.40835362, grad/param norm = 2.1162e-01, time/batch = 17.1005s	
6721/22750 (epoch 14.771), train_loss = 1.33663029, grad/param norm = 2.0119e-01, time/batch = 16.9093s	
6722/22750 (epoch 14.774), train_loss = 1.10499232, grad/param norm = 2.0320e-01, time/batch = 16.9193s	
6723/22750 (epoch 14.776), train_loss = 1.19786516, grad/param norm = 2.0676e-01, time/batch = 18.0015s	
6724/22750 (epoch 14.778), train_loss = 1.36654213, grad/param norm = 1.8641e-01, time/batch = 17.4197s	
6725/22750 (epoch 14.780), train_loss = 1.19992943, grad/param norm = 1.9896e-01, time/batch = 16.9541s	
6726/22750 (epoch 14.782), train_loss = 1.34424647, grad/param norm = 1.9342e-01, time/batch = 17.8473s	
6727/22750 (epoch 14.785), train_loss = 1.15064262, grad/param norm = 1.7189e-01, time/batch = 18.3252s	
6728/22750 (epoch 14.787), train_loss = 1.05511865, grad/param norm = 2.0107e-01, time/batch = 18.5668s	
6729/22750 (epoch 14.789), train_loss = 1.14590447, grad/param norm = 1.8620e-01, time/batch = 17.5914s	
6730/22750 (epoch 14.791), train_loss = 1.13730430, grad/param norm = 1.8835e-01, time/batch = 17.2449s	
6731/22750 (epoch 14.793), train_loss = 1.05710681, grad/param norm = 1.8475e-01, time/batch = 18.2015s	
6732/22750 (epoch 14.796), train_loss = 0.98248244, grad/param norm = 1.6336e-01, time/batch = 19.9379s	
6733/22750 (epoch 14.798), train_loss = 1.03420088, grad/param norm = 1.7342e-01, time/batch = 16.7910s	
6734/22750 (epoch 14.800), train_loss = 1.05861888, grad/param norm = 1.7001e-01, time/batch = 17.7854s	
6735/22750 (epoch 14.802), train_loss = 1.00453979, grad/param norm = 1.8190e-01, time/batch = 18.9289s	
6736/22750 (epoch 14.804), train_loss = 1.33433405, grad/param norm = 1.8351e-01, time/batch = 18.3465s	
6737/22750 (epoch 14.807), train_loss = 1.21956545, grad/param norm = 1.8780e-01, time/batch = 19.3334s	
6738/22750 (epoch 14.809), train_loss = 1.39402308, grad/param norm = 2.1565e-01, time/batch = 17.3341s	
6739/22750 (epoch 14.811), train_loss = 1.08124563, grad/param norm = 1.7541e-01, time/batch = 18.3503s	
6740/22750 (epoch 14.813), train_loss = 1.19510116, grad/param norm = 1.7406e-01, time/batch = 19.3579s	
6741/22750 (epoch 14.815), train_loss = 1.33650641, grad/param norm = 1.9869e-01, time/batch = 16.6052s	
6742/22750 (epoch 14.818), train_loss = 1.32811119, grad/param norm = 1.8230e-01, time/batch = 16.2504s	
6743/22750 (epoch 14.820), train_loss = 1.43928860, grad/param norm = 1.9190e-01, time/batch = 15.5138s	
6744/22750 (epoch 14.822), train_loss = 1.20937160, grad/param norm = 1.8648e-01, time/batch = 16.1734s	
6745/22750 (epoch 14.824), train_loss = 1.07846517, grad/param norm = 1.7721e-01, time/batch = 16.7445s	
6746/22750 (epoch 14.826), train_loss = 1.16412679, grad/param norm = 1.8379e-01, time/batch = 16.2515s	
6747/22750 (epoch 14.829), train_loss = 1.35793296, grad/param norm = 1.9529e-01, time/batch = 16.2647s	
6748/22750 (epoch 14.831), train_loss = 1.31258077, grad/param norm = 1.8673e-01, time/batch = 17.0898s	
6749/22750 (epoch 14.833), train_loss = 1.20725090, grad/param norm = 1.9716e-01, time/batch = 16.9489s	
6750/22750 (epoch 14.835), train_loss = 1.11588265, grad/param norm = 1.7650e-01, time/batch = 15.6792s	
6751/22750 (epoch 14.837), train_loss = 1.11233954, grad/param norm = 1.8154e-01, time/batch = 16.5345s	
6752/22750 (epoch 14.840), train_loss = 1.05628281, grad/param norm = 1.7153e-01, time/batch = 17.2095s	
6753/22750 (epoch 14.842), train_loss = 1.10449739, grad/param norm = 1.8114e-01, time/batch = 16.9920s	
6754/22750 (epoch 14.844), train_loss = 1.25768377, grad/param norm = 1.9032e-01, time/batch = 19.0051s	
6755/22750 (epoch 14.846), train_loss = 1.18455208, grad/param norm = 1.8317e-01, time/batch = 18.1754s	
6756/22750 (epoch 14.848), train_loss = 1.05804603, grad/param norm = 1.7212e-01, time/batch = 17.1747s	
6757/22750 (epoch 14.851), train_loss = 1.04955649, grad/param norm = 1.7151e-01, time/batch = 16.0152s	
6758/22750 (epoch 14.853), train_loss = 1.19633457, grad/param norm = 1.7077e-01, time/batch = 16.1659s	
6759/22750 (epoch 14.855), train_loss = 0.99210072, grad/param norm = 1.6373e-01, time/batch = 16.3386s	
6760/22750 (epoch 14.857), train_loss = 1.18580256, grad/param norm = 1.7730e-01, time/batch = 17.8445s	
6761/22750 (epoch 14.859), train_loss = 1.23347343, grad/param norm = 2.0183e-01, time/batch = 17.9598s	
6762/22750 (epoch 14.862), train_loss = 1.34810083, grad/param norm = 1.9378e-01, time/batch = 17.5922s	
6763/22750 (epoch 14.864), train_loss = 1.16336700, grad/param norm = 1.8789e-01, time/batch = 19.4270s	
6764/22750 (epoch 14.866), train_loss = 1.20023477, grad/param norm = 1.6854e-01, time/batch = 18.3326s	
6765/22750 (epoch 14.868), train_loss = 1.08575726, grad/param norm = 1.6587e-01, time/batch = 17.5599s	
6766/22750 (epoch 14.870), train_loss = 0.96642350, grad/param norm = 1.8350e-01, time/batch = 18.1729s	
6767/22750 (epoch 14.873), train_loss = 1.09774785, grad/param norm = 1.7650e-01, time/batch = 19.0880s	
6768/22750 (epoch 14.875), train_loss = 1.22399205, grad/param norm = 1.7987e-01, time/batch = 19.4868s	
6769/22750 (epoch 14.877), train_loss = 1.08241216, grad/param norm = 1.6716e-01, time/batch = 19.0980s	
6770/22750 (epoch 14.879), train_loss = 1.29942773, grad/param norm = 1.9833e-01, time/batch = 19.3733s	
6771/22750 (epoch 14.881), train_loss = 1.26049218, grad/param norm = 1.8542e-01, time/batch = 15.9229s	
6772/22750 (epoch 14.884), train_loss = 1.05105362, grad/param norm = 1.7709e-01, time/batch = 16.4338s	
6773/22750 (epoch 14.886), train_loss = 1.24014289, grad/param norm = 1.8421e-01, time/batch = 17.1770s	
6774/22750 (epoch 14.888), train_loss = 1.22004700, grad/param norm = 1.8109e-01, time/batch = 17.0223s	
6775/22750 (epoch 14.890), train_loss = 1.28787678, grad/param norm = 1.9300e-01, time/batch = 17.6637s	
6776/22750 (epoch 14.892), train_loss = 1.56733723, grad/param norm = 2.3750e-01, time/batch = 18.8235s	
6777/22750 (epoch 14.895), train_loss = 1.23481916, grad/param norm = 1.7311e-01, time/batch = 20.2371s	
6778/22750 (epoch 14.897), train_loss = 1.28871710, grad/param norm = 1.9008e-01, time/batch = 17.0951s	
6779/22750 (epoch 14.899), train_loss = 1.21742120, grad/param norm = 1.8558e-01, time/batch = 16.5197s	
6780/22750 (epoch 14.901), train_loss = 1.38154468, grad/param norm = 2.1536e-01, time/batch = 18.5188s	
6781/22750 (epoch 14.903), train_loss = 1.16162913, grad/param norm = 1.9750e-01, time/batch = 20.4431s	
6782/22750 (epoch 14.905), train_loss = 1.27112039, grad/param norm = 1.9083e-01, time/batch = 19.0973s	
6783/22750 (epoch 14.908), train_loss = 1.12321234, grad/param norm = 2.0778e-01, time/batch = 18.4980s	
6784/22750 (epoch 14.910), train_loss = 0.95460559, grad/param norm = 1.9245e-01, time/batch = 17.5828s	
6785/22750 (epoch 14.912), train_loss = 1.09761993, grad/param norm = 1.8504e-01, time/batch = 17.2706s	
6786/22750 (epoch 14.914), train_loss = 1.16577158, grad/param norm = 1.7980e-01, time/batch = 19.6704s	
6787/22750 (epoch 14.916), train_loss = 0.97637342, grad/param norm = 1.7066e-01, time/batch = 18.9196s	
6788/22750 (epoch 14.919), train_loss = 1.09802444, grad/param norm = 1.8743e-01, time/batch = 18.7392s	
6789/22750 (epoch 14.921), train_loss = 0.82578492, grad/param norm = 1.5144e-01, time/batch = 20.0746s	
6790/22750 (epoch 14.923), train_loss = 1.05551724, grad/param norm = 1.9164e-01, time/batch = 19.4447s	
6791/22750 (epoch 14.925), train_loss = 1.12766135, grad/param norm = 1.6820e-01, time/batch = 19.2509s	
6792/22750 (epoch 14.927), train_loss = 0.91648777, grad/param norm = 1.9084e-01, time/batch = 18.9027s	
6793/22750 (epoch 14.930), train_loss = 0.93685736, grad/param norm = 1.6376e-01, time/batch = 18.9990s	
6794/22750 (epoch 14.932), train_loss = 1.18542016, grad/param norm = 1.8412e-01, time/batch = 18.4829s	
6795/22750 (epoch 14.934), train_loss = 0.86475002, grad/param norm = 1.4696e-01, time/batch = 18.7371s	
6796/22750 (epoch 14.936), train_loss = 1.27151889, grad/param norm = 2.0676e-01, time/batch = 15.9619s	
6797/22750 (epoch 14.938), train_loss = 1.21653371, grad/param norm = 1.7565e-01, time/batch = 17.8504s	
6798/22750 (epoch 14.941), train_loss = 1.37206517, grad/param norm = 1.9487e-01, time/batch = 17.1257s	
6799/22750 (epoch 14.943), train_loss = 1.19998429, grad/param norm = 1.8566e-01, time/batch = 16.7858s	
6800/22750 (epoch 14.945), train_loss = 1.19310181, grad/param norm = 1.8469e-01, time/batch = 17.0299s	
6801/22750 (epoch 14.947), train_loss = 1.11094644, grad/param norm = 1.9122e-01, time/batch = 16.8399s	
6802/22750 (epoch 14.949), train_loss = 1.03491615, grad/param norm = 1.7145e-01, time/batch = 19.1563s	
6803/22750 (epoch 14.952), train_loss = 1.06065145, grad/param norm = 1.6842e-01, time/batch = 20.5667s	
6804/22750 (epoch 14.954), train_loss = 1.03146867, grad/param norm = 1.7904e-01, time/batch = 18.8118s	
6805/22750 (epoch 14.956), train_loss = 1.14861566, grad/param norm = 1.7340e-01, time/batch = 16.3271s	
6806/22750 (epoch 14.958), train_loss = 1.07636082, grad/param norm = 1.7407e-01, time/batch = 19.6719s	
6807/22750 (epoch 14.960), train_loss = 1.06885317, grad/param norm = 1.8363e-01, time/batch = 20.2741s	
6808/22750 (epoch 14.963), train_loss = 1.28631504, grad/param norm = 1.9740e-01, time/batch = 19.8581s	
6809/22750 (epoch 14.965), train_loss = 1.24300485, grad/param norm = 1.8966e-01, time/batch = 18.7556s	
6810/22750 (epoch 14.967), train_loss = 1.13819539, grad/param norm = 1.9150e-01, time/batch = 19.9905s	
6811/22750 (epoch 14.969), train_loss = 1.07977465, grad/param norm = 1.7949e-01, time/batch = 17.7478s	
6812/22750 (epoch 14.971), train_loss = 1.08945396, grad/param norm = 1.8734e-01, time/batch = 16.8432s	
6813/22750 (epoch 14.974), train_loss = 1.15138424, grad/param norm = 2.0175e-01, time/batch = 18.0839s	
6814/22750 (epoch 14.976), train_loss = 1.22375730, grad/param norm = 1.9968e-01, time/batch = 16.6451s	
6815/22750 (epoch 14.978), train_loss = 1.04261885, grad/param norm = 1.7098e-01, time/batch = 20.5088s	
6816/22750 (epoch 14.980), train_loss = 1.32821887, grad/param norm = 2.1618e-01, time/batch = 20.6088s	
6817/22750 (epoch 14.982), train_loss = 1.07480052, grad/param norm = 1.6488e-01, time/batch = 18.1702s	
6818/22750 (epoch 14.985), train_loss = 1.38985878, grad/param norm = 2.1483e-01, time/batch = 16.5189s	
6819/22750 (epoch 14.987), train_loss = 0.92329188, grad/param norm = 1.6648e-01, time/batch = 17.3470s	
6820/22750 (epoch 14.989), train_loss = 1.07908241, grad/param norm = 1.7908e-01, time/batch = 18.7480s	
6821/22750 (epoch 14.991), train_loss = 1.22536787, grad/param norm = 1.9517e-01, time/batch = 18.7350s	
6822/22750 (epoch 14.993), train_loss = 1.26830323, grad/param norm = 1.9763e-01, time/batch = 17.9846s	
6823/22750 (epoch 14.996), train_loss = 1.07982652, grad/param norm = 2.0136e-01, time/batch = 17.0749s	
6824/22750 (epoch 14.998), train_loss = 1.31484067, grad/param norm = 2.0450e-01, time/batch = 16.4509s	
decayed learning rate by a factor 0.97 to 0.001665944009858	
6825/22750 (epoch 15.000), train_loss = 1.20314340, grad/param norm = 1.8755e-01, time/batch = 17.1602s	
6826/22750 (epoch 15.002), train_loss = 1.28695665, grad/param norm = 1.9980e-01, time/batch = 18.8644s	
6827/22750 (epoch 15.004), train_loss = 1.07664785, grad/param norm = 1.8517e-01, time/batch = 16.8473s	
6828/22750 (epoch 15.007), train_loss = 1.12933075, grad/param norm = 1.9061e-01, time/batch = 17.9159s	
6829/22750 (epoch 15.009), train_loss = 1.38292759, grad/param norm = 2.0143e-01, time/batch = 17.7303s	
6830/22750 (epoch 15.011), train_loss = 1.41519567, grad/param norm = 2.0179e-01, time/batch = 18.0115s	
6831/22750 (epoch 15.013), train_loss = 1.25215435, grad/param norm = 1.7951e-01, time/batch = 16.9274s	
6832/22750 (epoch 15.015), train_loss = 1.20042792, grad/param norm = 2.0093e-01, time/batch = 18.4286s	
6833/22750 (epoch 15.018), train_loss = 1.23367563, grad/param norm = 1.8964e-01, time/batch = 19.1069s	
6834/22750 (epoch 15.020), train_loss = 1.33317260, grad/param norm = 2.0133e-01, time/batch = 18.4457s	
6835/22750 (epoch 15.022), train_loss = 1.12947923, grad/param norm = 1.8313e-01, time/batch = 20.7627s	
6836/22750 (epoch 15.024), train_loss = 1.17236950, grad/param norm = 1.9244e-01, time/batch = 18.6704s	
6837/22750 (epoch 15.026), train_loss = 1.26846031, grad/param norm = 2.0613e-01, time/batch = 17.7412s	
6838/22750 (epoch 15.029), train_loss = 0.96086441, grad/param norm = 1.7425e-01, time/batch = 17.3397s	
6839/22750 (epoch 15.031), train_loss = 1.43776244, grad/param norm = 1.9589e-01, time/batch = 19.9903s	
6840/22750 (epoch 15.033), train_loss = 1.17027623, grad/param norm = 1.8265e-01, time/batch = 18.1619s	
6841/22750 (epoch 15.035), train_loss = 1.23863244, grad/param norm = 1.9717e-01, time/batch = 18.0983s	
6842/22750 (epoch 15.037), train_loss = 1.30755001, grad/param norm = 1.9081e-01, time/batch = 20.1935s	
6843/22750 (epoch 15.040), train_loss = 1.11062615, grad/param norm = 1.8464e-01, time/batch = 19.5851s	
6844/22750 (epoch 15.042), train_loss = 1.25842265, grad/param norm = 1.9704e-01, time/batch = 17.8809s	
6845/22750 (epoch 15.044), train_loss = 1.11475157, grad/param norm = 1.7668e-01, time/batch = 17.4919s	
6846/22750 (epoch 15.046), train_loss = 1.27714744, grad/param norm = 2.1262e-01, time/batch = 15.6988s	
6847/22750 (epoch 15.048), train_loss = 1.13871006, grad/param norm = 1.8280e-01, time/batch = 16.7321s	
6848/22750 (epoch 15.051), train_loss = 1.21987516, grad/param norm = 1.8136e-01, time/batch = 17.4897s	
6849/22750 (epoch 15.053), train_loss = 1.04795050, grad/param norm = 1.6639e-01, time/batch = 16.9361s	
6850/22750 (epoch 15.055), train_loss = 1.08113683, grad/param norm = 1.7762e-01, time/batch = 18.4111s	
6851/22750 (epoch 15.057), train_loss = 1.32921440, grad/param norm = 1.8898e-01, time/batch = 19.3244s	
6852/22750 (epoch 15.059), train_loss = 0.87269047, grad/param norm = 1.7110e-01, time/batch = 20.4472s	
6853/22750 (epoch 15.062), train_loss = 1.01190915, grad/param norm = 1.7745e-01, time/batch = 19.3445s	
6854/22750 (epoch 15.064), train_loss = 1.21236505, grad/param norm = 1.9501e-01, time/batch = 16.0134s	
6855/22750 (epoch 15.066), train_loss = 0.98751757, grad/param norm = 1.6775e-01, time/batch = 18.2651s	
6856/22750 (epoch 15.068), train_loss = 1.07295190, grad/param norm = 1.5995e-01, time/batch = 19.5746s	
6857/22750 (epoch 15.070), train_loss = 0.91541923, grad/param norm = 1.6935e-01, time/batch = 19.0589s	
6858/22750 (epoch 15.073), train_loss = 1.07076461, grad/param norm = 1.8397e-01, time/batch = 19.4961s	
6859/22750 (epoch 15.075), train_loss = 1.11761108, grad/param norm = 1.7495e-01, time/batch = 19.9863s	
6860/22750 (epoch 15.077), train_loss = 0.89031256, grad/param norm = 1.8650e-01, time/batch = 18.1793s	
6861/22750 (epoch 15.079), train_loss = 1.11156366, grad/param norm = 2.0257e-01, time/batch = 16.9242s	
6862/22750 (epoch 15.081), train_loss = 1.10671119, grad/param norm = 2.0531e-01, time/batch = 16.5812s	
6863/22750 (epoch 15.084), train_loss = 1.08713044, grad/param norm = 1.7793e-01, time/batch = 15.6313s	
6864/22750 (epoch 15.086), train_loss = 1.10351405, grad/param norm = 1.6005e-01, time/batch = 16.3739s	
6865/22750 (epoch 15.088), train_loss = 1.06542386, grad/param norm = 1.8276e-01, time/batch = 16.5878s	
6866/22750 (epoch 15.090), train_loss = 1.04521324, grad/param norm = 1.7141e-01, time/batch = 17.4424s	
6867/22750 (epoch 15.092), train_loss = 1.29081750, grad/param norm = 1.7655e-01, time/batch = 16.9275s	
6868/22750 (epoch 15.095), train_loss = 1.03245188, grad/param norm = 1.8017e-01, time/batch = 18.4340s	
6869/22750 (epoch 15.097), train_loss = 1.12055501, grad/param norm = 1.7939e-01, time/batch = 16.4389s	
6870/22750 (epoch 15.099), train_loss = 1.14403913, grad/param norm = 2.0056e-01, time/batch = 17.6160s	
6871/22750 (epoch 15.101), train_loss = 1.03549430, grad/param norm = 2.0636e-01, time/batch = 18.2589s	
6872/22750 (epoch 15.103), train_loss = 1.12203942, grad/param norm = 1.8217e-01, time/batch = 18.5429s	
6873/22750 (epoch 15.105), train_loss = 1.40587192, grad/param norm = 2.1283e-01, time/batch = 18.6671s	
6874/22750 (epoch 15.108), train_loss = 1.09140488, grad/param norm = 1.8578e-01, time/batch = 18.6640s	
6875/22750 (epoch 15.110), train_loss = 1.27023098, grad/param norm = 1.9047e-01, time/batch = 19.5774s	
6876/22750 (epoch 15.112), train_loss = 0.94830382, grad/param norm = 1.6241e-01, time/batch = 18.6749s	
6877/22750 (epoch 15.114), train_loss = 0.90436462, grad/param norm = 1.7335e-01, time/batch = 18.1593s	
6878/22750 (epoch 15.116), train_loss = 1.02272634, grad/param norm = 1.6718e-01, time/batch = 17.2587s	
6879/22750 (epoch 15.119), train_loss = 1.02597256, grad/param norm = 1.5942e-01, time/batch = 20.0288s	
6880/22750 (epoch 15.121), train_loss = 1.19153072, grad/param norm = 2.0519e-01, time/batch = 18.3527s	
6881/22750 (epoch 15.123), train_loss = 1.01220038, grad/param norm = 1.6905e-01, time/batch = 19.5345s	
6882/22750 (epoch 15.125), train_loss = 1.30692333, grad/param norm = 1.8867e-01, time/batch = 19.6618s	
6883/22750 (epoch 15.127), train_loss = 1.11111180, grad/param norm = 1.9183e-01, time/batch = 17.1022s	
6884/22750 (epoch 15.130), train_loss = 1.17768359, grad/param norm = 1.8019e-01, time/batch = 20.2383s	
6885/22750 (epoch 15.132), train_loss = 1.10022867, grad/param norm = 1.9114e-01, time/batch = 18.5194s	
6886/22750 (epoch 15.134), train_loss = 1.08433528, grad/param norm = 1.7081e-01, time/batch = 18.5053s	
6887/22750 (epoch 15.136), train_loss = 0.97735577, grad/param norm = 1.9745e-01, time/batch = 19.0037s	
6888/22750 (epoch 15.138), train_loss = 1.18793884, grad/param norm = 1.9732e-01, time/batch = 17.2208s	
6889/22750 (epoch 15.141), train_loss = 1.14791049, grad/param norm = 1.9728e-01, time/batch = 17.5167s	
6890/22750 (epoch 15.143), train_loss = 0.98245061, grad/param norm = 1.7512e-01, time/batch = 18.1024s	
6891/22750 (epoch 15.145), train_loss = 1.31172922, grad/param norm = 1.9172e-01, time/batch = 20.0654s	
6892/22750 (epoch 15.147), train_loss = 1.27758292, grad/param norm = 1.8602e-01, time/batch = 17.7520s	
6893/22750 (epoch 15.149), train_loss = 1.14284148, grad/param norm = 1.8703e-01, time/batch = 18.5674s	
6894/22750 (epoch 15.152), train_loss = 1.10714244, grad/param norm = 1.8087e-01, time/batch = 18.2450s	
6895/22750 (epoch 15.154), train_loss = 0.94084038, grad/param norm = 1.7227e-01, time/batch = 19.8898s	
6896/22750 (epoch 15.156), train_loss = 0.97483279, grad/param norm = 1.7090e-01, time/batch = 18.2527s	
6897/22750 (epoch 15.158), train_loss = 1.06515357, grad/param norm = 1.8918e-01, time/batch = 20.6897s	
6898/22750 (epoch 15.160), train_loss = 1.17636688, grad/param norm = 1.9301e-01, time/batch = 19.4521s	
6899/22750 (epoch 15.163), train_loss = 1.39642250, grad/param norm = 2.1271e-01, time/batch = 18.8629s	
6900/22750 (epoch 15.165), train_loss = 1.21157037, grad/param norm = 1.9968e-01, time/batch = 20.1490s	
6901/22750 (epoch 15.167), train_loss = 1.08654774, grad/param norm = 1.9416e-01, time/batch = 18.9124s	
6902/22750 (epoch 15.169), train_loss = 1.15324860, grad/param norm = 1.9275e-01, time/batch = 24.6551s	
6903/22750 (epoch 15.171), train_loss = 1.01529462, grad/param norm = 1.8408e-01, time/batch = 20.2922s	
6904/22750 (epoch 15.174), train_loss = 0.95949307, grad/param norm = 1.8690e-01, time/batch = 15.0536s	
6905/22750 (epoch 15.176), train_loss = 1.07464097, grad/param norm = 1.6767e-01, time/batch = 15.9323s	
6906/22750 (epoch 15.178), train_loss = 1.08842771, grad/param norm = 1.7200e-01, time/batch = 15.1409s	
6907/22750 (epoch 15.180), train_loss = 1.24319411, grad/param norm = 2.1154e-01, time/batch = 15.3954s	
6908/22750 (epoch 15.182), train_loss = 1.25916093, grad/param norm = 1.8446e-01, time/batch = 15.0737s	
6909/22750 (epoch 15.185), train_loss = 1.27979453, grad/param norm = 1.9784e-01, time/batch = 15.6338s	
6910/22750 (epoch 15.187), train_loss = 1.03953948, grad/param norm = 1.8986e-01, time/batch = 15.3654s	
6911/22750 (epoch 15.189), train_loss = 1.08069423, grad/param norm = 1.9067e-01, time/batch = 16.1490s	
6912/22750 (epoch 15.191), train_loss = 1.01663801, grad/param norm = 1.6220e-01, time/batch = 15.1278s	
6913/22750 (epoch 15.193), train_loss = 1.21350120, grad/param norm = 1.8703e-01, time/batch = 15.9361s	
6914/22750 (epoch 15.196), train_loss = 1.11529024, grad/param norm = 1.8054e-01, time/batch = 15.1290s	
6915/22750 (epoch 15.198), train_loss = 0.86267028, grad/param norm = 1.4558e-01, time/batch = 15.1225s	
6916/22750 (epoch 15.200), train_loss = 1.14236224, grad/param norm = 1.7623e-01, time/batch = 14.6421s	
6917/22750 (epoch 15.202), train_loss = 1.25543765, grad/param norm = 2.0823e-01, time/batch = 15.3825s	
6918/22750 (epoch 15.204), train_loss = 1.18038809, grad/param norm = 1.7660e-01, time/batch = 14.8147s	
6919/22750 (epoch 15.207), train_loss = 1.11226095, grad/param norm = 1.8521e-01, time/batch = 14.5837s	
6920/22750 (epoch 15.209), train_loss = 1.04577688, grad/param norm = 1.8315e-01, time/batch = 15.3657s	
6921/22750 (epoch 15.211), train_loss = 1.06683035, grad/param norm = 1.9842e-01, time/batch = 16.0001s	
6922/22750 (epoch 15.213), train_loss = 0.95421026, grad/param norm = 1.7540e-01, time/batch = 15.6022s	
6923/22750 (epoch 15.215), train_loss = 0.88748578, grad/param norm = 1.7167e-01, time/batch = 15.2061s	
6924/22750 (epoch 15.218), train_loss = 0.96035932, grad/param norm = 1.9139e-01, time/batch = 15.1308s	
6925/22750 (epoch 15.220), train_loss = 1.00033674, grad/param norm = 1.7910e-01, time/batch = 15.4556s	
6926/22750 (epoch 15.222), train_loss = 0.93847070, grad/param norm = 1.7756e-01, time/batch = 15.1356s	
6927/22750 (epoch 15.224), train_loss = 1.03433509, grad/param norm = 1.8292e-01, time/batch = 15.0369s	
6928/22750 (epoch 15.226), train_loss = 1.22296195, grad/param norm = 1.9658e-01, time/batch = 15.0667s	
6929/22750 (epoch 15.229), train_loss = 1.16470321, grad/param norm = 2.0767e-01, time/batch = 15.9158s	
6930/22750 (epoch 15.231), train_loss = 1.05959072, grad/param norm = 1.8279e-01, time/batch = 16.1582s	
6931/22750 (epoch 15.233), train_loss = 0.98762018, grad/param norm = 1.7779e-01, time/batch = 15.4590s	
6932/22750 (epoch 15.235), train_loss = 0.95499531, grad/param norm = 1.8871e-01, time/batch = 15.8540s	
6933/22750 (epoch 15.237), train_loss = 1.04228623, grad/param norm = 1.8775e-01, time/batch = 15.2740s	
6934/22750 (epoch 15.240), train_loss = 1.12194389, grad/param norm = 1.6832e-01, time/batch = 15.2979s	
6935/22750 (epoch 15.242), train_loss = 1.38731071, grad/param norm = 2.1638e-01, time/batch = 15.1919s	
6936/22750 (epoch 15.244), train_loss = 1.26989939, grad/param norm = 1.9268e-01, time/batch = 15.3702s	
6937/22750 (epoch 15.246), train_loss = 1.33495141, grad/param norm = 1.9796e-01, time/batch = 15.4499s	
6938/22750 (epoch 15.248), train_loss = 1.10639712, grad/param norm = 2.0210e-01, time/batch = 15.2332s	
6939/22750 (epoch 15.251), train_loss = 1.31310532, grad/param norm = 1.9168e-01, time/batch = 15.0798s	
6940/22750 (epoch 15.253), train_loss = 1.15773054, grad/param norm = 1.9701e-01, time/batch = 15.6301s	
6941/22750 (epoch 15.255), train_loss = 1.14355028, grad/param norm = 1.7515e-01, time/batch = 15.2151s	
6942/22750 (epoch 15.257), train_loss = 1.07402828, grad/param norm = 1.9029e-01, time/batch = 15.4456s	
6943/22750 (epoch 15.259), train_loss = 1.28761982, grad/param norm = 2.1420e-01, time/batch = 15.2814s	
6944/22750 (epoch 15.262), train_loss = 1.10513333, grad/param norm = 1.8477e-01, time/batch = 15.5368s	
6945/22750 (epoch 15.264), train_loss = 0.97152827, grad/param norm = 1.7927e-01, time/batch = 15.1334s	
6946/22750 (epoch 15.266), train_loss = 1.16537910, grad/param norm = 2.3543e-01, time/batch = 15.0369s	
6947/22750 (epoch 15.268), train_loss = 1.29058318, grad/param norm = 2.0785e-01, time/batch = 14.9666s	
6948/22750 (epoch 15.270), train_loss = 1.06813108, grad/param norm = 1.9630e-01, time/batch = 15.8568s	
6949/22750 (epoch 15.273), train_loss = 1.41884723, grad/param norm = 2.1475e-01, time/batch = 15.2217s	
6950/22750 (epoch 15.275), train_loss = 1.23807579, grad/param norm = 1.8633e-01, time/batch = 15.2387s	
6951/22750 (epoch 15.277), train_loss = 1.10494898, grad/param norm = 2.1495e-01, time/batch = 15.0848s	
6952/22750 (epoch 15.279), train_loss = 0.97254225, grad/param norm = 1.8962e-01, time/batch = 15.2999s	
6953/22750 (epoch 15.281), train_loss = 1.26666491, grad/param norm = 2.0267e-01, time/batch = 15.2839s	
6954/22750 (epoch 15.284), train_loss = 1.10838258, grad/param norm = 1.8309e-01, time/batch = 15.2756s	
6955/22750 (epoch 15.286), train_loss = 1.28118080, grad/param norm = 2.0159e-01, time/batch = 15.0576s	
6956/22750 (epoch 15.288), train_loss = 1.32011644, grad/param norm = 1.9662e-01, time/batch = 15.3645s	
6957/22750 (epoch 15.290), train_loss = 1.13709496, grad/param norm = 2.0073e-01, time/batch = 15.0383s	
6958/22750 (epoch 15.292), train_loss = 1.20513465, grad/param norm = 2.1074e-01, time/batch = 15.2150s	
6959/22750 (epoch 15.295), train_loss = 1.19518539, grad/param norm = 1.8154e-01, time/batch = 15.1305s	
6960/22750 (epoch 15.297), train_loss = 1.07834066, grad/param norm = 1.7268e-01, time/batch = 16.0188s	
6961/22750 (epoch 15.299), train_loss = 1.28593703, grad/param norm = 2.0148e-01, time/batch = 15.7838s	
6962/22750 (epoch 15.301), train_loss = 1.17975288, grad/param norm = 1.9027e-01, time/batch = 15.3096s	
6963/22750 (epoch 15.303), train_loss = 1.24997258, grad/param norm = 1.8734e-01, time/batch = 15.3890s	
6964/22750 (epoch 15.305), train_loss = 1.36311065, grad/param norm = 1.9054e-01, time/batch = 16.6077s	
6965/22750 (epoch 15.308), train_loss = 1.19060857, grad/param norm = 1.6993e-01, time/batch = 15.6966s	
6966/22750 (epoch 15.310), train_loss = 1.03362553, grad/param norm = 1.9670e-01, time/batch = 16.0381s	
6967/22750 (epoch 15.312), train_loss = 1.19293796, grad/param norm = 1.9483e-01, time/batch = 15.5389s	
6968/22750 (epoch 15.314), train_loss = 1.16229000, grad/param norm = 1.7778e-01, time/batch = 15.2941s	
6969/22750 (epoch 15.316), train_loss = 1.10897679, grad/param norm = 1.9515e-01, time/batch = 15.2806s	
6970/22750 (epoch 15.319), train_loss = 1.18836945, grad/param norm = 1.9890e-01, time/batch = 15.2186s	
6971/22750 (epoch 15.321), train_loss = 1.09173196, grad/param norm = 1.8706e-01, time/batch = 15.3944s	
6972/22750 (epoch 15.323), train_loss = 1.12567287, grad/param norm = 1.8825e-01, time/batch = 15.2425s	
6973/22750 (epoch 15.325), train_loss = 0.94059268, grad/param norm = 1.8440e-01, time/batch = 14.9165s	
6974/22750 (epoch 15.327), train_loss = 1.14251702, grad/param norm = 1.9292e-01, time/batch = 15.1568s	
6975/22750 (epoch 15.330), train_loss = 1.40153516, grad/param norm = 2.1159e-01, time/batch = 15.6819s	
6976/22750 (epoch 15.332), train_loss = 1.35438758, grad/param norm = 1.8862e-01, time/batch = 15.1963s	
6977/22750 (epoch 15.334), train_loss = 0.94127418, grad/param norm = 1.7395e-01, time/batch = 15.0440s	
6978/22750 (epoch 15.336), train_loss = 1.21961768, grad/param norm = 1.9512e-01, time/batch = 15.2048s	
6979/22750 (epoch 15.338), train_loss = 1.10723218, grad/param norm = 1.8200e-01, time/batch = 15.8548s	
6980/22750 (epoch 15.341), train_loss = 1.12509651, grad/param norm = 1.8829e-01, time/batch = 15.1198s	
6981/22750 (epoch 15.343), train_loss = 0.98000115, grad/param norm = 1.9610e-01, time/batch = 15.1437s	
6982/22750 (epoch 15.345), train_loss = 1.28026207, grad/param norm = 1.9811e-01, time/batch = 15.2366s	
6983/22750 (epoch 15.347), train_loss = 1.32090282, grad/param norm = 2.1761e-01, time/batch = 15.4804s	
6984/22750 (epoch 15.349), train_loss = 0.92240747, grad/param norm = 1.9135e-01, time/batch = 15.1464s	
6985/22750 (epoch 15.352), train_loss = 1.23694403, grad/param norm = 1.9113e-01, time/batch = 15.2798s	
6986/22750 (epoch 15.354), train_loss = 1.27846452, grad/param norm = 2.0577e-01, time/batch = 15.0500s	
6987/22750 (epoch 15.356), train_loss = 1.29648938, grad/param norm = 1.9854e-01, time/batch = 16.0548s	
6988/22750 (epoch 15.358), train_loss = 1.14702640, grad/param norm = 2.0017e-01, time/batch = 16.0736s	
6989/22750 (epoch 15.360), train_loss = 1.34926724, grad/param norm = 1.8787e-01, time/batch = 15.2217s	
6990/22750 (epoch 15.363), train_loss = 1.11283214, grad/param norm = 1.7347e-01, time/batch = 15.8491s	
6991/22750 (epoch 15.365), train_loss = 0.92426444, grad/param norm = 1.7651e-01, time/batch = 15.9469s	
6992/22750 (epoch 15.367), train_loss = 0.99743649, grad/param norm = 1.9276e-01, time/batch = 15.7025s	
6993/22750 (epoch 15.369), train_loss = 1.13165952, grad/param norm = 1.8919e-01, time/batch = 15.2297s	
6994/22750 (epoch 15.371), train_loss = 1.07851244, grad/param norm = 1.7325e-01, time/batch = 15.3171s	
6995/22750 (epoch 15.374), train_loss = 1.02292129, grad/param norm = 1.7538e-01, time/batch = 15.9588s	
6996/22750 (epoch 15.376), train_loss = 1.09727327, grad/param norm = 1.7589e-01, time/batch = 17.6930s	
6997/22750 (epoch 15.378), train_loss = 1.17781432, grad/param norm = 1.9259e-01, time/batch = 16.8315s	
6998/22750 (epoch 15.380), train_loss = 1.30019005, grad/param norm = 2.0088e-01, time/batch = 16.1848s	
6999/22750 (epoch 15.382), train_loss = 1.07774365, grad/param norm = 1.7388e-01, time/batch = 17.0063s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_wakata_epoch15.38_1.4841.t7	
7000/22750 (epoch 15.385), train_loss = 1.21932684, grad/param norm = 1.7810e-01, time/batch = 16.9378s	
7001/22750 (epoch 15.387), train_loss = 1.45908408, grad/param norm = 2.0178e-01, time/batch = 20.0003s	
7002/22750 (epoch 15.389), train_loss = 0.89189250, grad/param norm = 1.8225e-01, time/batch = 17.9011s	
7003/22750 (epoch 15.391), train_loss = 0.72126911, grad/param norm = 1.4587e-01, time/batch = 16.2292s	
7004/22750 (epoch 15.393), train_loss = 0.99773086, grad/param norm = 1.7094e-01, time/batch = 16.5047s	
7005/22750 (epoch 15.396), train_loss = 1.16807454, grad/param norm = 1.9498e-01, time/batch = 17.3447s	
7006/22750 (epoch 15.398), train_loss = 1.09145976, grad/param norm = 1.8031e-01, time/batch = 17.0370s	
7007/22750 (epoch 15.400), train_loss = 1.10759703, grad/param norm = 1.7191e-01, time/batch = 20.6017s	
7008/22750 (epoch 15.402), train_loss = 1.19921348, grad/param norm = 1.7897e-01, time/batch = 20.1961s	
7009/22750 (epoch 15.404), train_loss = 1.30728549, grad/param norm = 1.8776e-01, time/batch = 17.3556s	
7010/22750 (epoch 15.407), train_loss = 1.25751219, grad/param norm = 1.9291e-01, time/batch = 18.9166s	
7011/22750 (epoch 15.409), train_loss = 1.12014311, grad/param norm = 1.8360e-01, time/batch = 17.9032s	
7012/22750 (epoch 15.411), train_loss = 1.10742908, grad/param norm = 1.7750e-01, time/batch = 18.4984s	
7013/22750 (epoch 15.413), train_loss = 0.90064561, grad/param norm = 1.9031e-01, time/batch = 19.8865s	
7014/22750 (epoch 15.415), train_loss = 0.87544638, grad/param norm = 1.6311e-01, time/batch = 20.7382s	
7015/22750 (epoch 15.418), train_loss = 1.07771785, grad/param norm = 1.9364e-01, time/batch = 19.3334s	
7016/22750 (epoch 15.420), train_loss = 1.26417651, grad/param norm = 2.3061e-01, time/batch = 18.6096s	
7017/22750 (epoch 15.422), train_loss = 1.37870897, grad/param norm = 2.3603e-01, time/batch = 20.5913s	
7018/22750 (epoch 15.424), train_loss = 1.40203748, grad/param norm = 2.1553e-01, time/batch = 18.5223s	
7019/22750 (epoch 15.426), train_loss = 1.35144213, grad/param norm = 1.9370e-01, time/batch = 16.5607s	
7020/22750 (epoch 15.429), train_loss = 0.97362022, grad/param norm = 1.9386e-01, time/batch = 16.2424s	
7021/22750 (epoch 15.431), train_loss = 0.94422014, grad/param norm = 1.8171e-01, time/batch = 17.6819s	
7022/22750 (epoch 15.433), train_loss = 1.05933838, grad/param norm = 1.7274e-01, time/batch = 16.7589s	
7023/22750 (epoch 15.435), train_loss = 0.88059908, grad/param norm = 1.6553e-01, time/batch = 18.3248s	
7024/22750 (epoch 15.437), train_loss = 0.78145172, grad/param norm = 1.7010e-01, time/batch = 16.2693s	
7025/22750 (epoch 15.440), train_loss = 1.16291173, grad/param norm = 1.9331e-01, time/batch = 17.3577s	
7026/22750 (epoch 15.442), train_loss = 1.17864678, grad/param norm = 2.0976e-01, time/batch = 19.1627s	
7027/22750 (epoch 15.444), train_loss = 1.10807618, grad/param norm = 2.0024e-01, time/batch = 18.2135s	
7028/22750 (epoch 15.446), train_loss = 1.12086517, grad/param norm = 1.9679e-01, time/batch = 18.9414s	
7029/22750 (epoch 15.448), train_loss = 1.41874589, grad/param norm = 2.0150e-01, time/batch = 17.4337s	
7030/22750 (epoch 15.451), train_loss = 1.30805486, grad/param norm = 1.9562e-01, time/batch = 18.5837s	
7031/22750 (epoch 15.453), train_loss = 1.34910973, grad/param norm = 2.0145e-01, time/batch = 17.9858s	
7032/22750 (epoch 15.455), train_loss = 1.43016769, grad/param norm = 2.1288e-01, time/batch = 16.7535s	
7033/22750 (epoch 15.457), train_loss = 1.27528136, grad/param norm = 2.3028e-01, time/batch = 17.6725s	
7034/22750 (epoch 15.459), train_loss = 1.24821297, grad/param norm = 1.8444e-01, time/batch = 19.7719s	
7035/22750 (epoch 15.462), train_loss = 1.22803823, grad/param norm = 1.7615e-01, time/batch = 17.9538s	
7036/22750 (epoch 15.464), train_loss = 0.96763513, grad/param norm = 1.9222e-01, time/batch = 19.5359s	
7037/22750 (epoch 15.466), train_loss = 1.35063411, grad/param norm = 2.2091e-01, time/batch = 18.6032s	
7038/22750 (epoch 15.468), train_loss = 1.12366496, grad/param norm = 1.8913e-01, time/batch = 18.2546s	
7039/22750 (epoch 15.470), train_loss = 1.28745046, grad/param norm = 2.0565e-01, time/batch = 17.1683s	
7040/22750 (epoch 15.473), train_loss = 1.14000266, grad/param norm = 1.9351e-01, time/batch = 16.2437s	
7041/22750 (epoch 15.475), train_loss = 1.17456172, grad/param norm = 2.1929e-01, time/batch = 15.8591s	
7042/22750 (epoch 15.477), train_loss = 0.96083021, grad/param norm = 1.6967e-01, time/batch = 16.3403s	
7043/22750 (epoch 15.479), train_loss = 0.96944941, grad/param norm = 1.7600e-01, time/batch = 15.9459s	
7044/22750 (epoch 15.481), train_loss = 0.90561964, grad/param norm = 1.6906e-01, time/batch = 17.6837s	
7045/22750 (epoch 15.484), train_loss = 0.84019803, grad/param norm = 1.9730e-01, time/batch = 18.8547s	
7046/22750 (epoch 15.486), train_loss = 0.97902922, grad/param norm = 1.8516e-01, time/batch = 17.2063s	
7047/22750 (epoch 15.488), train_loss = 0.85868774, grad/param norm = 1.7603e-01, time/batch = 19.0241s	
7048/22750 (epoch 15.490), train_loss = 1.15807948, grad/param norm = 1.8357e-01, time/batch = 17.0220s	
7049/22750 (epoch 15.492), train_loss = 1.28374238, grad/param norm = 1.9609e-01, time/batch = 16.5025s	
7050/22750 (epoch 15.495), train_loss = 1.02126331, grad/param norm = 1.7776e-01, time/batch = 18.0761s	
7051/22750 (epoch 15.497), train_loss = 1.16386404, grad/param norm = 2.1642e-01, time/batch = 17.9985s	
7052/22750 (epoch 15.499), train_loss = 1.03250660, grad/param norm = 1.8050e-01, time/batch = 17.0697s	
7053/22750 (epoch 15.501), train_loss = 1.13535776, grad/param norm = 1.8607e-01, time/batch = 17.3533s	
7054/22750 (epoch 15.503), train_loss = 1.14920049, grad/param norm = 1.9910e-01, time/batch = 20.1144s	
7055/22750 (epoch 15.505), train_loss = 0.99284427, grad/param norm = 1.8445e-01, time/batch = 19.5037s	
7056/22750 (epoch 15.508), train_loss = 0.93355683, grad/param norm = 1.7612e-01, time/batch = 19.3339s	
7057/22750 (epoch 15.510), train_loss = 0.97471630, grad/param norm = 1.6787e-01, time/batch = 18.9993s	
7058/22750 (epoch 15.512), train_loss = 1.01308282, grad/param norm = 1.6403e-01, time/batch = 19.4913s	
7059/22750 (epoch 15.514), train_loss = 1.05739960, grad/param norm = 1.8439e-01, time/batch = 17.8436s	
7060/22750 (epoch 15.516), train_loss = 1.04793009, grad/param norm = 1.8940e-01, time/batch = 18.3410s	
7061/22750 (epoch 15.519), train_loss = 1.22226107, grad/param norm = 1.9135e-01, time/batch = 18.0738s	
7062/22750 (epoch 15.521), train_loss = 1.11279050, grad/param norm = 1.8740e-01, time/batch = 18.7671s	
7063/22750 (epoch 15.523), train_loss = 1.08833233, grad/param norm = 2.0493e-01, time/batch = 20.0321s	
7064/22750 (epoch 15.525), train_loss = 1.29803744, grad/param norm = 1.9612e-01, time/batch = 19.3679s	
7065/22750 (epoch 15.527), train_loss = 1.12152571, grad/param norm = 1.8654e-01, time/batch = 16.7673s	
7066/22750 (epoch 15.530), train_loss = 1.05235908, grad/param norm = 1.9120e-01, time/batch = 16.1033s	
7067/22750 (epoch 15.532), train_loss = 0.95417633, grad/param norm = 1.6277e-01, time/batch = 16.8212s	
7068/22750 (epoch 15.534), train_loss = 1.22299514, grad/param norm = 1.8523e-01, time/batch = 17.9043s	
7069/22750 (epoch 15.536), train_loss = 1.15176962, grad/param norm = 1.7723e-01, time/batch = 18.0805s	
7070/22750 (epoch 15.538), train_loss = 1.13165640, grad/param norm = 1.6501e-01, time/batch = 19.7371s	
7071/22750 (epoch 15.541), train_loss = 0.97020280, grad/param norm = 1.7774e-01, time/batch = 19.9299s	
7072/22750 (epoch 15.543), train_loss = 0.97896986, grad/param norm = 1.7375e-01, time/batch = 19.0122s	
7073/22750 (epoch 15.545), train_loss = 1.24461448, grad/param norm = 1.8627e-01, time/batch = 15.9168s	
7074/22750 (epoch 15.547), train_loss = 1.00864213, grad/param norm = 1.6857e-01, time/batch = 15.8633s	
7075/22750 (epoch 15.549), train_loss = 1.07346541, grad/param norm = 1.8683e-01, time/batch = 16.9077s	
7076/22750 (epoch 15.552), train_loss = 1.20343494, grad/param norm = 1.9890e-01, time/batch = 18.5907s	
7077/22750 (epoch 15.554), train_loss = 1.22513916, grad/param norm = 1.9131e-01, time/batch = 17.6711s	
7078/22750 (epoch 15.556), train_loss = 1.12503318, grad/param norm = 1.8930e-01, time/batch = 18.1700s	
7079/22750 (epoch 15.558), train_loss = 1.23415114, grad/param norm = 1.9651e-01, time/batch = 19.8232s	
7080/22750 (epoch 15.560), train_loss = 1.05955467, grad/param norm = 1.8697e-01, time/batch = 17.6173s	
7081/22750 (epoch 15.563), train_loss = 1.23738989, grad/param norm = 1.8003e-01, time/batch = 15.9003s	
7082/22750 (epoch 15.565), train_loss = 1.18635434, grad/param norm = 1.9311e-01, time/batch = 18.5167s	
7083/22750 (epoch 15.567), train_loss = 1.17729954, grad/param norm = 1.8830e-01, time/batch = 17.3387s	
7084/22750 (epoch 15.569), train_loss = 1.10985411, grad/param norm = 1.8451e-01, time/batch = 19.6593s	
7085/22750 (epoch 15.571), train_loss = 1.13214192, grad/param norm = 1.8887e-01, time/batch = 17.0021s	
7086/22750 (epoch 15.574), train_loss = 1.01681208, grad/param norm = 1.7574e-01, time/batch = 19.4988s	
7087/22750 (epoch 15.576), train_loss = 1.12267932, grad/param norm = 1.9457e-01, time/batch = 17.1538s	
7088/22750 (epoch 15.578), train_loss = 0.97959726, grad/param norm = 1.8695e-01, time/batch = 16.3374s	
7089/22750 (epoch 15.580), train_loss = 1.14828334, grad/param norm = 2.0534e-01, time/batch = 16.9519s	
7090/22750 (epoch 15.582), train_loss = 0.98841577, grad/param norm = 1.7035e-01, time/batch = 17.8614s	
7091/22750 (epoch 15.585), train_loss = 0.93389889, grad/param norm = 1.9351e-01, time/batch = 19.9426s	
7092/22750 (epoch 15.587), train_loss = 0.94617893, grad/param norm = 1.6158e-01, time/batch = 17.1663s	
7093/22750 (epoch 15.589), train_loss = 0.91193690, grad/param norm = 1.6718e-01, time/batch = 18.4144s	
7094/22750 (epoch 15.591), train_loss = 1.07499790, grad/param norm = 1.8134e-01, time/batch = 17.3459s	
7095/22750 (epoch 15.593), train_loss = 1.29775924, grad/param norm = 1.8548e-01, time/batch = 16.6038s	
7096/22750 (epoch 15.596), train_loss = 1.31001697, grad/param norm = 1.9806e-01, time/batch = 17.5264s	
7097/22750 (epoch 15.598), train_loss = 1.34738153, grad/param norm = 1.9584e-01, time/batch = 18.3470s	
7098/22750 (epoch 15.600), train_loss = 1.26905940, grad/param norm = 1.9422e-01, time/batch = 18.5926s	
7099/22750 (epoch 15.602), train_loss = 1.01926843, grad/param norm = 1.7261e-01, time/batch = 18.5896s	
7100/22750 (epoch 15.604), train_loss = 1.05829383, grad/param norm = 1.7613e-01, time/batch = 18.0364s	
7101/22750 (epoch 15.607), train_loss = 0.91503668, grad/param norm = 1.5845e-01, time/batch = 18.3690s	
7102/22750 (epoch 15.609), train_loss = 0.87657656, grad/param norm = 1.5894e-01, time/batch = 16.8180s	
7103/22750 (epoch 15.611), train_loss = 1.07563699, grad/param norm = 1.8360e-01, time/batch = 20.2358s	
7104/22750 (epoch 15.613), train_loss = 1.01455544, grad/param norm = 1.8056e-01, time/batch = 20.4875s	
7105/22750 (epoch 15.615), train_loss = 1.04507071, grad/param norm = 1.7458e-01, time/batch = 16.2241s	
7106/22750 (epoch 15.618), train_loss = 1.05860226, grad/param norm = 1.7471e-01, time/batch = 19.8163s	
7107/22750 (epoch 15.620), train_loss = 1.09716490, grad/param norm = 1.8746e-01, time/batch = 17.6048s	
7108/22750 (epoch 15.622), train_loss = 0.89391877, grad/param norm = 1.6445e-01, time/batch = 28.3102s	
7109/22750 (epoch 15.624), train_loss = 1.02612089, grad/param norm = 1.8890e-01, time/batch = 25.6214s	
7110/22750 (epoch 15.626), train_loss = 0.93767480, grad/param norm = 1.7776e-01, time/batch = 15.9095s	
7111/22750 (epoch 15.629), train_loss = 1.03726597, grad/param norm = 1.7256e-01, time/batch = 16.9212s	
7112/22750 (epoch 15.631), train_loss = 1.07067476, grad/param norm = 1.7521e-01, time/batch = 15.6055s	
7113/22750 (epoch 15.633), train_loss = 0.92930207, grad/param norm = 1.6747e-01, time/batch = 15.1364s	
7114/22750 (epoch 15.635), train_loss = 1.11815148, grad/param norm = 1.8663e-01, time/batch = 15.7689s	
7115/22750 (epoch 15.637), train_loss = 1.17800315, grad/param norm = 1.9283e-01, time/batch = 15.9186s	
7116/22750 (epoch 15.640), train_loss = 1.20376416, grad/param norm = 2.0328e-01, time/batch = 15.8334s	
7117/22750 (epoch 15.642), train_loss = 1.26705182, grad/param norm = 1.8901e-01, time/batch = 14.9894s	
7118/22750 (epoch 15.644), train_loss = 1.13384086, grad/param norm = 1.9107e-01, time/batch = 15.6360s	
7119/22750 (epoch 15.646), train_loss = 1.20358336, grad/param norm = 2.2104e-01, time/batch = 15.1417s	
7120/22750 (epoch 15.648), train_loss = 1.14970438, grad/param norm = 2.2084e-01, time/batch = 15.0756s	
7121/22750 (epoch 15.651), train_loss = 1.18274385, grad/param norm = 1.8865e-01, time/batch = 15.2975s	
7122/22750 (epoch 15.653), train_loss = 1.18364073, grad/param norm = 1.8838e-01, time/batch = 15.8256s	
7123/22750 (epoch 15.655), train_loss = 1.13337387, grad/param norm = 1.8499e-01, time/batch = 15.1174s	
7124/22750 (epoch 15.657), train_loss = 1.31710737, grad/param norm = 1.9977e-01, time/batch = 15.8494s	
7125/22750 (epoch 15.659), train_loss = 1.39188161, grad/param norm = 2.0708e-01, time/batch = 15.1261s	
7126/22750 (epoch 15.662), train_loss = 1.37688493, grad/param norm = 2.2703e-01, time/batch = 15.8509s	
7127/22750 (epoch 15.664), train_loss = 1.18356604, grad/param norm = 1.9837e-01, time/batch = 14.9655s	
7128/22750 (epoch 15.666), train_loss = 0.97596666, grad/param norm = 1.9720e-01, time/batch = 15.2298s	
7129/22750 (epoch 15.668), train_loss = 1.14651913, grad/param norm = 1.9002e-01, time/batch = 15.3755s	
7130/22750 (epoch 15.670), train_loss = 1.13468922, grad/param norm = 1.9008e-01, time/batch = 15.7893s	
7131/22750 (epoch 15.673), train_loss = 1.42088179, grad/param norm = 2.1498e-01, time/batch = 15.0805s	
7132/22750 (epoch 15.675), train_loss = 1.54633888, grad/param norm = 2.2167e-01, time/batch = 15.3776s	
7133/22750 (epoch 15.677), train_loss = 1.33069135, grad/param norm = 2.2835e-01, time/batch = 15.2083s	
7134/22750 (epoch 15.679), train_loss = 1.38234406, grad/param norm = 2.1293e-01, time/batch = 15.6893s	
7135/22750 (epoch 15.681), train_loss = 1.31048228, grad/param norm = 2.0490e-01, time/batch = 15.8570s	
7136/22750 (epoch 15.684), train_loss = 1.30708906, grad/param norm = 2.0993e-01, time/batch = 16.0891s	
7137/22750 (epoch 15.686), train_loss = 1.29952329, grad/param norm = 2.0573e-01, time/batch = 15.3776s	
7138/22750 (epoch 15.688), train_loss = 1.28537848, grad/param norm = 2.0638e-01, time/batch = 15.2097s	
7139/22750 (epoch 15.690), train_loss = 1.27790451, grad/param norm = 2.0175e-01, time/batch = 15.0708s	
7140/22750 (epoch 15.692), train_loss = 1.35185175, grad/param norm = 2.0369e-01, time/batch = 15.9268s	
7141/22750 (epoch 15.695), train_loss = 1.18869433, grad/param norm = 2.0049e-01, time/batch = 15.3801s	
7142/22750 (epoch 15.697), train_loss = 1.13360831, grad/param norm = 1.8992e-01, time/batch = 15.4807s	
7143/22750 (epoch 15.699), train_loss = 1.13790253, grad/param norm = 1.8654e-01, time/batch = 15.2903s	
7144/22750 (epoch 15.701), train_loss = 0.99605221, grad/param norm = 1.8304e-01, time/batch = 15.3652s	
7145/22750 (epoch 15.703), train_loss = 1.14138564, grad/param norm = 1.7416e-01, time/batch = 15.2825s	
7146/22750 (epoch 15.705), train_loss = 1.04888495, grad/param norm = 1.8377e-01, time/batch = 15.3607s	
7147/22750 (epoch 15.708), train_loss = 1.14851129, grad/param norm = 1.9690e-01, time/batch = 15.4532s	
7148/22750 (epoch 15.710), train_loss = 0.99629034, grad/param norm = 1.9443e-01, time/batch = 15.2055s	
7149/22750 (epoch 15.712), train_loss = 1.03134939, grad/param norm = 1.8090e-01, time/batch = 15.3791s	
7150/22750 (epoch 15.714), train_loss = 0.92778849, grad/param norm = 1.6717e-01, time/batch = 15.7939s	
7151/22750 (epoch 15.716), train_loss = 1.00654289, grad/param norm = 1.8849e-01, time/batch = 15.4884s	
7152/22750 (epoch 15.719), train_loss = 1.21513853, grad/param norm = 2.1676e-01, time/batch = 15.5414s	
7153/22750 (epoch 15.721), train_loss = 1.24391038, grad/param norm = 1.8011e-01, time/batch = 15.9389s	
7154/22750 (epoch 15.723), train_loss = 1.16804990, grad/param norm = 1.9025e-01, time/batch = 15.3692s	
7155/22750 (epoch 15.725), train_loss = 1.11767478, grad/param norm = 1.8968e-01, time/batch = 15.4476s	
7156/22750 (epoch 15.727), train_loss = 1.06224250, grad/param norm = 1.6725e-01, time/batch = 15.0567s	
7157/22750 (epoch 15.730), train_loss = 1.07885343, grad/param norm = 1.9271e-01, time/batch = 15.7761s	
7158/22750 (epoch 15.732), train_loss = 1.04463537, grad/param norm = 1.6938e-01, time/batch = 15.1379s	
7159/22750 (epoch 15.734), train_loss = 0.88498264, grad/param norm = 1.6152e-01, time/batch = 15.3716s	
7160/22750 (epoch 15.736), train_loss = 1.04033491, grad/param norm = 1.7926e-01, time/batch = 15.2185s	
7161/22750 (epoch 15.738), train_loss = 1.15794410, grad/param norm = 2.0452e-01, time/batch = 15.4814s	
7162/22750 (epoch 15.741), train_loss = 1.24049655, grad/param norm = 1.9208e-01, time/batch = 15.0775s	
7163/22750 (epoch 15.743), train_loss = 1.18271711, grad/param norm = 1.8630e-01, time/batch = 15.1558s	
7164/22750 (epoch 15.745), train_loss = 0.98313939, grad/param norm = 1.7517e-01, time/batch = 15.3947s	
7165/22750 (epoch 15.747), train_loss = 1.05863185, grad/param norm = 1.7212e-01, time/batch = 15.9219s	
7166/22750 (epoch 15.749), train_loss = 1.32707925, grad/param norm = 2.1813e-01, time/batch = 15.1283s	
7167/22750 (epoch 15.752), train_loss = 1.09365531, grad/param norm = 1.8708e-01, time/batch = 14.9687s	
7168/22750 (epoch 15.754), train_loss = 1.17276119, grad/param norm = 2.1608e-01, time/batch = 15.1341s	
7169/22750 (epoch 15.756), train_loss = 1.00709396, grad/param norm = 2.0408e-01, time/batch = 15.9330s	
7170/22750 (epoch 15.758), train_loss = 0.99033324, grad/param norm = 1.7948e-01, time/batch = 15.2708s	
7171/22750 (epoch 15.760), train_loss = 1.10227265, grad/param norm = 1.9614e-01, time/batch = 15.5162s	
7172/22750 (epoch 15.763), train_loss = 1.19039343, grad/param norm = 1.9447e-01, time/batch = 15.7764s	
7173/22750 (epoch 15.765), train_loss = 1.12984414, grad/param norm = 2.1247e-01, time/batch = 15.6157s	
7174/22750 (epoch 15.767), train_loss = 1.16733898, grad/param norm = 2.0681e-01, time/batch = 15.3933s	
7175/22750 (epoch 15.769), train_loss = 1.37652818, grad/param norm = 2.2747e-01, time/batch = 14.8232s	
7176/22750 (epoch 15.771), train_loss = 1.29508332, grad/param norm = 2.0079e-01, time/batch = 15.2149s	
7177/22750 (epoch 15.774), train_loss = 1.06361124, grad/param norm = 1.9458e-01, time/batch = 15.6527s	
7178/22750 (epoch 15.776), train_loss = 1.17181664, grad/param norm = 2.1346e-01, time/batch = 14.8056s	
7179/22750 (epoch 15.778), train_loss = 1.33626787, grad/param norm = 1.9241e-01, time/batch = 15.0428s	
7180/22750 (epoch 15.780), train_loss = 1.16356603, grad/param norm = 1.9363e-01, time/batch = 15.2096s	
7181/22750 (epoch 15.782), train_loss = 1.30303094, grad/param norm = 1.9678e-01, time/batch = 14.7306s	
7182/22750 (epoch 15.785), train_loss = 1.12766387, grad/param norm = 1.9179e-01, time/batch = 14.8937s	
7183/22750 (epoch 15.787), train_loss = 1.02801442, grad/param norm = 1.9660e-01, time/batch = 14.9796s	
7184/22750 (epoch 15.789), train_loss = 1.11155774, grad/param norm = 1.8663e-01, time/batch = 15.3932s	
7185/22750 (epoch 15.791), train_loss = 1.10536363, grad/param norm = 1.8373e-01, time/batch = 16.1450s	
7186/22750 (epoch 15.793), train_loss = 1.02831301, grad/param norm = 1.8106e-01, time/batch = 15.3819s	
7187/22750 (epoch 15.796), train_loss = 0.94881788, grad/param norm = 1.8153e-01, time/batch = 15.5240s	
7188/22750 (epoch 15.798), train_loss = 1.00637187, grad/param norm = 1.7297e-01, time/batch = 15.5347s	
7189/22750 (epoch 15.800), train_loss = 1.03515018, grad/param norm = 1.7453e-01, time/batch = 19.4109s	
7190/22750 (epoch 15.802), train_loss = 0.97834596, grad/param norm = 1.8332e-01, time/batch = 18.2544s	
7191/22750 (epoch 15.804), train_loss = 1.29882982, grad/param norm = 1.8897e-01, time/batch = 18.3326s	
7192/22750 (epoch 15.807), train_loss = 1.19194016, grad/param norm = 1.8656e-01, time/batch = 16.4487s	
7193/22750 (epoch 15.809), train_loss = 1.35843291, grad/param norm = 2.1336e-01, time/batch = 18.2849s	
7194/22750 (epoch 15.811), train_loss = 1.05326914, grad/param norm = 1.8179e-01, time/batch = 16.3273s	
7195/22750 (epoch 15.813), train_loss = 1.17308970, grad/param norm = 1.7782e-01, time/batch = 17.5991s	
7196/22750 (epoch 15.815), train_loss = 1.30609277, grad/param norm = 2.0305e-01, time/batch = 16.4381s	
7197/22750 (epoch 15.818), train_loss = 1.30068162, grad/param norm = 1.8463e-01, time/batch = 17.4357s	
7198/22750 (epoch 15.820), train_loss = 1.41446358, grad/param norm = 1.9744e-01, time/batch = 17.5127s	
7199/22750 (epoch 15.822), train_loss = 1.18478927, grad/param norm = 1.8978e-01, time/batch = 17.7642s	
7200/22750 (epoch 15.824), train_loss = 1.04043235, grad/param norm = 1.7060e-01, time/batch = 17.5806s	
7201/22750 (epoch 15.826), train_loss = 1.12853629, grad/param norm = 1.8740e-01, time/batch = 17.5193s	
7202/22750 (epoch 15.829), train_loss = 1.31463144, grad/param norm = 2.0113e-01, time/batch = 18.1035s	
7203/22750 (epoch 15.831), train_loss = 1.27417752, grad/param norm = 1.8684e-01, time/batch = 19.0342s	
7204/22750 (epoch 15.833), train_loss = 1.18798333, grad/param norm = 2.0557e-01, time/batch = 20.1052s	
7205/22750 (epoch 15.835), train_loss = 1.08457591, grad/param norm = 1.7665e-01, time/batch = 18.3387s	
7206/22750 (epoch 15.837), train_loss = 1.08604086, grad/param norm = 1.9130e-01, time/batch = 19.6467s	
7207/22750 (epoch 15.840), train_loss = 1.02272530, grad/param norm = 1.6890e-01, time/batch = 19.9932s	
7208/22750 (epoch 15.842), train_loss = 1.07797588, grad/param norm = 1.8510e-01, time/batch = 17.2435s	
7209/22750 (epoch 15.844), train_loss = 1.21868689, grad/param norm = 1.9774e-01, time/batch = 18.2493s	
7210/22750 (epoch 15.846), train_loss = 1.16034901, grad/param norm = 1.9204e-01, time/batch = 19.3359s	
7211/22750 (epoch 15.848), train_loss = 1.03276102, grad/param norm = 1.7183e-01, time/batch = 17.5170s	
7212/22750 (epoch 15.851), train_loss = 1.01650935, grad/param norm = 1.7424e-01, time/batch = 18.8843s	
7213/22750 (epoch 15.853), train_loss = 1.16965424, grad/param norm = 1.7696e-01, time/batch = 20.3658s	
7214/22750 (epoch 15.855), train_loss = 0.96503634, grad/param norm = 1.5990e-01, time/batch = 18.6940s	
7215/22750 (epoch 15.857), train_loss = 1.16063116, grad/param norm = 1.8345e-01, time/batch = 16.7550s	
7216/22750 (epoch 15.859), train_loss = 1.20189665, grad/param norm = 1.9748e-01, time/batch = 15.6687s	
7217/22750 (epoch 15.862), train_loss = 1.31692011, grad/param norm = 1.9063e-01, time/batch = 16.1203s	
7218/22750 (epoch 15.864), train_loss = 1.12825921, grad/param norm = 1.8722e-01, time/batch = 16.7250s	
7219/22750 (epoch 15.866), train_loss = 1.16929218, grad/param norm = 1.6912e-01, time/batch = 15.9314s	
7220/22750 (epoch 15.868), train_loss = 1.05516504, grad/param norm = 1.6540e-01, time/batch = 15.6873s	
7221/22750 (epoch 15.870), train_loss = 0.93204960, grad/param norm = 1.8438e-01, time/batch = 15.9978s	
7222/22750 (epoch 15.873), train_loss = 1.06411778, grad/param norm = 1.7284e-01, time/batch = 16.2454s	
7223/22750 (epoch 15.875), train_loss = 1.19356543, grad/param norm = 1.8264e-01, time/batch = 15.4513s	
7224/22750 (epoch 15.877), train_loss = 1.04659613, grad/param norm = 1.7231e-01, time/batch = 15.3797s	
7225/22750 (epoch 15.879), train_loss = 1.26562435, grad/param norm = 1.9870e-01, time/batch = 15.6754s	
7226/22750 (epoch 15.881), train_loss = 1.21641710, grad/param norm = 1.8430e-01, time/batch = 16.0050s	
7227/22750 (epoch 15.884), train_loss = 1.02942130, grad/param norm = 1.8813e-01, time/batch = 16.6329s	
7228/22750 (epoch 15.886), train_loss = 1.20916342, grad/param norm = 1.8936e-01, time/batch = 15.5223s	
7229/22750 (epoch 15.888), train_loss = 1.18898648, grad/param norm = 1.8336e-01, time/batch = 15.9287s	
7230/22750 (epoch 15.890), train_loss = 1.25293002, grad/param norm = 1.9527e-01, time/batch = 15.7612s	
7231/22750 (epoch 15.892), train_loss = 1.52340187, grad/param norm = 2.2997e-01, time/batch = 16.1032s	
7232/22750 (epoch 15.895), train_loss = 1.19534486, grad/param norm = 1.7978e-01, time/batch = 15.7066s	
7233/22750 (epoch 15.897), train_loss = 1.25617433, grad/param norm = 1.9449e-01, time/batch = 16.5796s	
7234/22750 (epoch 15.899), train_loss = 1.18874221, grad/param norm = 1.8930e-01, time/batch = 15.5491s	
7235/22750 (epoch 15.901), train_loss = 1.33235269, grad/param norm = 2.1126e-01, time/batch = 15.9308s	
7236/22750 (epoch 15.903), train_loss = 1.12471517, grad/param norm = 1.9764e-01, time/batch = 16.0639s	
7237/22750 (epoch 15.905), train_loss = 1.24091955, grad/param norm = 1.9599e-01, time/batch = 16.2403s	
7238/22750 (epoch 15.908), train_loss = 1.09280267, grad/param norm = 2.1974e-01, time/batch = 16.1683s	
7239/22750 (epoch 15.910), train_loss = 0.92708757, grad/param norm = 1.9510e-01, time/batch = 15.6846s	
7240/22750 (epoch 15.912), train_loss = 1.06504142, grad/param norm = 1.8036e-01, time/batch = 15.8438s	
7241/22750 (epoch 15.914), train_loss = 1.13708285, grad/param norm = 1.8372e-01, time/batch = 16.0898s	
7242/22750 (epoch 15.916), train_loss = 0.96014849, grad/param norm = 1.7813e-01, time/batch = 15.6934s	
7243/22750 (epoch 15.919), train_loss = 1.08274367, grad/param norm = 2.1510e-01, time/batch = 15.6186s	
7244/22750 (epoch 15.921), train_loss = 0.80320301, grad/param norm = 1.4768e-01, time/batch = 15.7789s	
7245/22750 (epoch 15.923), train_loss = 1.01436569, grad/param norm = 1.7311e-01, time/batch = 15.6935s	
7246/22750 (epoch 15.925), train_loss = 1.10333761, grad/param norm = 1.7600e-01, time/batch = 15.7501s	
7247/22750 (epoch 15.927), train_loss = 0.88659187, grad/param norm = 1.8180e-01, time/batch = 15.6036s	
7248/22750 (epoch 15.930), train_loss = 0.91318725, grad/param norm = 1.6542e-01, time/batch = 16.1693s	
7249/22750 (epoch 15.932), train_loss = 1.15666067, grad/param norm = 1.8407e-01, time/batch = 15.3489s	
7250/22750 (epoch 15.934), train_loss = 0.84098572, grad/param norm = 1.4838e-01, time/batch = 15.3553s	
7251/22750 (epoch 15.936), train_loss = 1.24174605, grad/param norm = 2.0130e-01, time/batch = 15.4385s	
7252/22750 (epoch 15.938), train_loss = 1.18924435, grad/param norm = 1.7554e-01, time/batch = 16.6374s	
7253/22750 (epoch 15.941), train_loss = 1.33748000, grad/param norm = 1.9891e-01, time/batch = 15.3803s	
7254/22750 (epoch 15.943), train_loss = 1.16508376, grad/param norm = 1.8468e-01, time/batch = 15.3044s	
7255/22750 (epoch 15.945), train_loss = 1.16582728, grad/param norm = 1.9073e-01, time/batch = 15.6264s	
7256/22750 (epoch 15.947), train_loss = 1.08191259, grad/param norm = 1.9308e-01, time/batch = 16.0897s	
7257/22750 (epoch 15.949), train_loss = 1.00411186, grad/param norm = 1.7310e-01, time/batch = 15.3555s	
7258/22750 (epoch 15.952), train_loss = 1.03461992, grad/param norm = 1.6534e-01, time/batch = 15.4320s	
7259/22750 (epoch 15.954), train_loss = 1.00888788, grad/param norm = 1.8111e-01, time/batch = 15.3662s	
7260/22750 (epoch 15.956), train_loss = 1.11885175, grad/param norm = 1.7499e-01, time/batch = 15.6036s	
7261/22750 (epoch 15.958), train_loss = 1.05358411, grad/param norm = 1.7194e-01, time/batch = 15.9720s	
7262/22750 (epoch 15.960), train_loss = 1.03330706, grad/param norm = 1.7276e-01, time/batch = 15.5161s	
7263/22750 (epoch 15.963), train_loss = 1.24891765, grad/param norm = 1.9991e-01, time/batch = 15.7574s	
7264/22750 (epoch 15.965), train_loss = 1.20840647, grad/param norm = 1.8836e-01, time/batch = 15.7703s	
7265/22750 (epoch 15.967), train_loss = 1.11008704, grad/param norm = 1.9367e-01, time/batch = 16.0140s	
7266/22750 (epoch 15.969), train_loss = 1.04191669, grad/param norm = 1.8733e-01, time/batch = 15.7076s	
7267/22750 (epoch 15.971), train_loss = 1.06203566, grad/param norm = 1.8514e-01, time/batch = 16.4008s	
7268/22750 (epoch 15.974), train_loss = 1.11869265, grad/param norm = 2.0153e-01, time/batch = 15.9071s	
7269/22750 (epoch 15.976), train_loss = 1.18059169, grad/param norm = 1.9320e-01, time/batch = 15.9911s	
7270/22750 (epoch 15.978), train_loss = 1.01702859, grad/param norm = 1.7130e-01, time/batch = 15.5261s	
7271/22750 (epoch 15.980), train_loss = 1.29817313, grad/param norm = 2.2623e-01, time/batch = 15.9279s	
7272/22750 (epoch 15.982), train_loss = 1.04226921, grad/param norm = 1.6606e-01, time/batch = 15.9310s	
7273/22750 (epoch 15.985), train_loss = 1.36223299, grad/param norm = 2.1963e-01, time/batch = 15.3709s	
7274/22750 (epoch 15.987), train_loss = 0.89945651, grad/param norm = 1.7346e-01, time/batch = 16.0237s	
7275/22750 (epoch 15.989), train_loss = 1.05008782, grad/param norm = 1.7985e-01, time/batch = 6.8372s	
7276/22750 (epoch 15.991), train_loss = 1.18859301, grad/param norm = 2.0067e-01, time/batch = 0.7347s	
7277/22750 (epoch 15.993), train_loss = 1.23042049, grad/param norm = 2.0166e-01, time/batch = 0.7527s	
7278/22750 (epoch 15.996), train_loss = 1.04297264, grad/param norm = 1.9613e-01, time/batch = 0.7451s	
7279/22750 (epoch 15.998), train_loss = 1.28943612, grad/param norm = 2.0726e-01, time/batch = 0.7450s	
decayed learning rate by a factor 0.97 to 0.0016159656895623	
7280/22750 (epoch 16.000), train_loss = 1.16103812, grad/param norm = 1.8080e-01, time/batch = 0.7474s	
7281/22750 (epoch 16.002), train_loss = 1.26368938, grad/param norm = 2.0307e-01, time/batch = 0.7434s	
7282/22750 (epoch 16.004), train_loss = 1.04805865, grad/param norm = 1.8469e-01, time/batch = 1.0206s	
7283/22750 (epoch 16.007), train_loss = 1.09636437, grad/param norm = 1.9236e-01, time/batch = 1.1187s	
7284/22750 (epoch 16.009), train_loss = 1.34698590, grad/param norm = 2.0690e-01, time/batch = 1.0802s	
7285/22750 (epoch 16.011), train_loss = 1.38107660, grad/param norm = 2.0144e-01, time/batch = 1.0856s	
7286/22750 (epoch 16.013), train_loss = 1.22050628, grad/param norm = 1.8350e-01, time/batch = 1.3498s	
7287/22750 (epoch 16.015), train_loss = 1.16830833, grad/param norm = 2.0842e-01, time/batch = 1.9839s	
7288/22750 (epoch 16.018), train_loss = 1.21330413, grad/param norm = 1.9325e-01, time/batch = 1.9478s	
7289/22750 (epoch 16.020), train_loss = 1.29423516, grad/param norm = 1.9777e-01, time/batch = 12.7788s	
7290/22750 (epoch 16.022), train_loss = 1.10698043, grad/param norm = 1.8250e-01, time/batch = 15.7032s	
7291/22750 (epoch 16.024), train_loss = 1.14908906, grad/param norm = 1.9286e-01, time/batch = 16.1021s	
7292/22750 (epoch 16.026), train_loss = 1.22920703, grad/param norm = 2.0339e-01, time/batch = 16.0975s	
7293/22750 (epoch 16.029), train_loss = 0.93546366, grad/param norm = 1.7842e-01, time/batch = 15.7675s	
7294/22750 (epoch 16.031), train_loss = 1.39905384, grad/param norm = 1.9613e-01, time/batch = 15.5331s	
7295/22750 (epoch 16.033), train_loss = 1.14872775, grad/param norm = 1.8719e-01, time/batch = 16.0906s	
7296/22750 (epoch 16.035), train_loss = 1.20091291, grad/param norm = 1.9109e-01, time/batch = 15.7598s	
7297/22750 (epoch 16.037), train_loss = 1.27238468, grad/param norm = 1.9364e-01, time/batch = 15.6909s	
7298/22750 (epoch 16.040), train_loss = 1.08772874, grad/param norm = 1.9591e-01, time/batch = 15.6807s	
7299/22750 (epoch 16.042), train_loss = 1.21588593, grad/param norm = 1.9644e-01, time/batch = 15.8756s	
7300/22750 (epoch 16.044), train_loss = 1.08674980, grad/param norm = 1.7726e-01, time/batch = 15.8622s	
7301/22750 (epoch 16.046), train_loss = 1.25693934, grad/param norm = 2.1519e-01, time/batch = 15.5414s	
7302/22750 (epoch 16.048), train_loss = 1.10737790, grad/param norm = 1.7957e-01, time/batch = 15.8699s	
7303/22750 (epoch 16.051), train_loss = 1.18797264, grad/param norm = 1.7844e-01, time/batch = 15.9390s	
7304/22750 (epoch 16.053), train_loss = 1.02277213, grad/param norm = 1.6608e-01, time/batch = 15.6848s	
7305/22750 (epoch 16.055), train_loss = 1.04668101, grad/param norm = 1.8036e-01, time/batch = 15.4496s	
7306/22750 (epoch 16.057), train_loss = 1.29832732, grad/param norm = 1.8559e-01, time/batch = 16.1657s	
7307/22750 (epoch 16.059), train_loss = 0.85000089, grad/param norm = 1.7010e-01, time/batch = 15.8439s	
7308/22750 (epoch 16.062), train_loss = 0.98694879, grad/param norm = 1.8751e-01, time/batch = 16.0056s	
7309/22750 (epoch 16.064), train_loss = 1.18404785, grad/param norm = 1.9982e-01, time/batch = 15.5316s	
7310/22750 (epoch 16.066), train_loss = 0.96727920, grad/param norm = 1.6768e-01, time/batch = 16.1095s	
7311/22750 (epoch 16.068), train_loss = 1.05104098, grad/param norm = 1.6578e-01, time/batch = 15.5514s	
7312/22750 (epoch 16.070), train_loss = 0.88377095, grad/param norm = 1.6360e-01, time/batch = 15.4617s	
7313/22750 (epoch 16.073), train_loss = 1.04931855, grad/param norm = 1.8650e-01, time/batch = 15.3878s	
7314/22750 (epoch 16.075), train_loss = 1.08538199, grad/param norm = 1.7191e-01, time/batch = 16.5454s	
7315/22750 (epoch 16.077), train_loss = 0.87203738, grad/param norm = 2.0225e-01, time/batch = 15.9975s	
7316/22750 (epoch 16.079), train_loss = 1.08645816, grad/param norm = 1.9685e-01, time/batch = 15.6021s	
7317/22750 (epoch 16.081), train_loss = 1.06912200, grad/param norm = 1.8528e-01, time/batch = 15.6985s	
7318/22750 (epoch 16.084), train_loss = 1.05358862, grad/param norm = 1.8525e-01, time/batch = 16.7240s	
7319/22750 (epoch 16.086), train_loss = 1.08390305, grad/param norm = 1.6190e-01, time/batch = 15.5259s	
7320/22750 (epoch 16.088), train_loss = 1.03720372, grad/param norm = 1.8379e-01, time/batch = 15.5359s	
7321/22750 (epoch 16.090), train_loss = 1.01470918, grad/param norm = 1.7222e-01, time/batch = 15.7002s	
7322/22750 (epoch 16.092), train_loss = 1.25365389, grad/param norm = 1.7857e-01, time/batch = 15.7124s	
7323/22750 (epoch 16.095), train_loss = 1.00318237, grad/param norm = 1.8058e-01, time/batch = 18.9468s	
7324/22750 (epoch 16.097), train_loss = 1.10250700, grad/param norm = 1.8258e-01, time/batch = 19.0919s	
7325/22750 (epoch 16.099), train_loss = 1.11593747, grad/param norm = 1.9947e-01, time/batch = 16.2482s	
7326/22750 (epoch 16.101), train_loss = 0.99308353, grad/param norm = 1.8466e-01, time/batch = 18.8141s	
7327/22750 (epoch 16.103), train_loss = 1.10091057, grad/param norm = 1.8871e-01, time/batch = 19.4788s	
7328/22750 (epoch 16.105), train_loss = 1.35914560, grad/param norm = 2.1453e-01, time/batch = 17.9252s	
7329/22750 (epoch 16.108), train_loss = 1.07032081, grad/param norm = 1.8945e-01, time/batch = 21.2211s	
7330/22750 (epoch 16.110), train_loss = 1.24742252, grad/param norm = 1.8725e-01, time/batch = 20.9003s	
7331/22750 (epoch 16.112), train_loss = 0.92514957, grad/param norm = 1.6249e-01, time/batch = 18.3998s	
7332/22750 (epoch 16.114), train_loss = 0.88554853, grad/param norm = 1.7133e-01, time/batch = 16.3248s	
7333/22750 (epoch 16.116), train_loss = 0.99865103, grad/param norm = 1.6765e-01, time/batch = 16.1277s	
7334/22750 (epoch 16.119), train_loss = 1.00357440, grad/param norm = 1.5863e-01, time/batch = 16.7465s	
7335/22750 (epoch 16.121), train_loss = 1.15456831, grad/param norm = 2.0440e-01, time/batch = 17.5235s	
7336/22750 (epoch 16.123), train_loss = 0.98630487, grad/param norm = 1.6797e-01, time/batch = 17.8334s	
7337/22750 (epoch 16.125), train_loss = 1.27819521, grad/param norm = 1.9760e-01, time/batch = 18.2748s	
7338/22750 (epoch 16.127), train_loss = 1.07768584, grad/param norm = 1.8920e-01, time/batch = 17.3379s	
7339/22750 (epoch 16.130), train_loss = 1.13474408, grad/param norm = 1.7688e-01, time/batch = 20.8976s	
7340/22750 (epoch 16.132), train_loss = 1.06514767, grad/param norm = 2.0169e-01, time/batch = 17.5767s	
7341/22750 (epoch 16.134), train_loss = 1.05771335, grad/param norm = 1.7298e-01, time/batch = 30.1453s	
7342/22750 (epoch 16.136), train_loss = 0.94435377, grad/param norm = 1.9111e-01, time/batch = 19.0105s	
7343/22750 (epoch 16.138), train_loss = 1.15912259, grad/param norm = 1.9798e-01, time/batch = 17.3130s	
7344/22750 (epoch 16.141), train_loss = 1.12513431, grad/param norm = 2.0110e-01, time/batch = 16.4629s	
7345/22750 (epoch 16.143), train_loss = 0.96142872, grad/param norm = 1.6982e-01, time/batch = 18.4770s	
7346/22750 (epoch 16.145), train_loss = 1.27165714, grad/param norm = 1.9219e-01, time/batch = 15.2840s	
7347/22750 (epoch 16.147), train_loss = 1.24884622, grad/param norm = 1.8559e-01, time/batch = 15.4503s	
7348/22750 (epoch 16.149), train_loss = 1.11401628, grad/param norm = 1.8597e-01, time/batch = 15.5335s	
7349/22750 (epoch 16.152), train_loss = 1.09390981, grad/param norm = 1.8972e-01, time/batch = 15.9396s	
7350/22750 (epoch 16.154), train_loss = 0.92169044, grad/param norm = 1.7802e-01, time/batch = 15.3002s	
7351/22750 (epoch 16.156), train_loss = 0.95454416, grad/param norm = 1.8116e-01, time/batch = 15.8049s	
7352/22750 (epoch 16.158), train_loss = 1.03992783, grad/param norm = 1.9301e-01, time/batch = 15.0567s	
7353/22750 (epoch 16.160), train_loss = 1.14706465, grad/param norm = 1.8824e-01, time/batch = 14.7409s	
7354/22750 (epoch 16.163), train_loss = 1.35044518, grad/param norm = 2.1240e-01, time/batch = 14.7256s	
7355/22750 (epoch 16.165), train_loss = 1.17322433, grad/param norm = 1.9610e-01, time/batch = 15.4484s	
7356/22750 (epoch 16.167), train_loss = 1.05924743, grad/param norm = 1.9668e-01, time/batch = 15.4381s	
7357/22750 (epoch 16.169), train_loss = 1.11544940, grad/param norm = 1.9179e-01, time/batch = 15.7716s	
7358/22750 (epoch 16.171), train_loss = 0.99103544, grad/param norm = 1.8799e-01, time/batch = 16.0049s	
7359/22750 (epoch 16.174), train_loss = 0.93026340, grad/param norm = 1.7967e-01, time/batch = 16.0098s	
7360/22750 (epoch 16.176), train_loss = 1.04200036, grad/param norm = 1.7207e-01, time/batch = 15.9281s	
7361/22750 (epoch 16.178), train_loss = 1.05660786, grad/param norm = 1.7942e-01, time/batch = 15.3096s	
7362/22750 (epoch 16.180), train_loss = 1.19919316, grad/param norm = 2.1390e-01, time/batch = 15.1394s	
7363/22750 (epoch 16.182), train_loss = 1.23630200, grad/param norm = 1.9389e-01, time/batch = 15.7126s	
7364/22750 (epoch 16.185), train_loss = 1.25099627, grad/param norm = 1.8952e-01, time/batch = 15.1475s	
7365/22750 (epoch 16.187), train_loss = 1.00067904, grad/param norm = 1.8919e-01, time/batch = 15.2975s	
7366/22750 (epoch 16.189), train_loss = 1.04425171, grad/param norm = 1.9060e-01, time/batch = 15.1305s	
7367/22750 (epoch 16.191), train_loss = 0.99872300, grad/param norm = 1.6391e-01, time/batch = 15.5320s	
7368/22750 (epoch 16.193), train_loss = 1.18354660, grad/param norm = 1.8516e-01, time/batch = 15.3738s	
7369/22750 (epoch 16.196), train_loss = 1.07688918, grad/param norm = 1.7858e-01, time/batch = 15.3682s	
7370/22750 (epoch 16.198), train_loss = 0.83510988, grad/param norm = 1.4328e-01, time/batch = 15.3768s	
7371/22750 (epoch 16.200), train_loss = 1.11325120, grad/param norm = 1.7212e-01, time/batch = 15.3750s	
7372/22750 (epoch 16.202), train_loss = 1.21726206, grad/param norm = 2.0001e-01, time/batch = 15.2089s	
7373/22750 (epoch 16.204), train_loss = 1.13327628, grad/param norm = 1.7401e-01, time/batch = 15.3865s	
7374/22750 (epoch 16.207), train_loss = 1.07451390, grad/param norm = 1.7805e-01, time/batch = 15.1573s	
7375/22750 (epoch 16.209), train_loss = 1.01197026, grad/param norm = 1.8451e-01, time/batch = 15.2403s	
7376/22750 (epoch 16.211), train_loss = 1.02870639, grad/param norm = 1.9246e-01, time/batch = 14.9120s	
7377/22750 (epoch 16.213), train_loss = 0.93494919, grad/param norm = 1.8041e-01, time/batch = 15.1363s	
7378/22750 (epoch 16.215), train_loss = 0.86259313, grad/param norm = 1.7834e-01, time/batch = 15.4292s	
7379/22750 (epoch 16.218), train_loss = 0.94502585, grad/param norm = 1.8869e-01, time/batch = 15.9250s	
7380/22750 (epoch 16.220), train_loss = 0.96127056, grad/param norm = 1.7463e-01, time/batch = 15.2859s	
7381/22750 (epoch 16.222), train_loss = 0.91341800, grad/param norm = 1.8348e-01, time/batch = 14.7290s	
7382/22750 (epoch 16.224), train_loss = 0.99712334, grad/param norm = 1.7939e-01, time/batch = 15.4440s	
7383/22750 (epoch 16.226), train_loss = 1.18379562, grad/param norm = 1.9584e-01, time/batch = 15.9017s	
7384/22750 (epoch 16.229), train_loss = 1.12842891, grad/param norm = 1.8622e-01, time/batch = 15.3671s	
7385/22750 (epoch 16.231), train_loss = 1.03243796, grad/param norm = 1.8406e-01, time/batch = 15.4749s	
7386/22750 (epoch 16.233), train_loss = 0.96352867, grad/param norm = 1.8542e-01, time/batch = 15.7792s	
7387/22750 (epoch 16.235), train_loss = 0.91634648, grad/param norm = 1.8521e-01, time/batch = 15.2326s	
7388/22750 (epoch 16.237), train_loss = 1.01078761, grad/param norm = 1.8426e-01, time/batch = 16.0111s	
7389/22750 (epoch 16.240), train_loss = 1.08157118, grad/param norm = 1.6556e-01, time/batch = 15.6854s	
7390/22750 (epoch 16.242), train_loss = 1.35084809, grad/param norm = 2.1631e-01, time/batch = 16.0015s	
7391/22750 (epoch 16.244), train_loss = 1.23353406, grad/param norm = 1.9271e-01, time/batch = 15.2080s	
7392/22750 (epoch 16.246), train_loss = 1.31489545, grad/param norm = 2.0909e-01, time/batch = 15.2187s	
7393/22750 (epoch 16.248), train_loss = 1.07656004, grad/param norm = 2.1112e-01, time/batch = 15.0482s	
7394/22750 (epoch 16.251), train_loss = 1.26762806, grad/param norm = 1.8961e-01, time/batch = 15.6018s	
7395/22750 (epoch 16.253), train_loss = 1.12377588, grad/param norm = 1.9337e-01, time/batch = 16.0830s	
7396/22750 (epoch 16.255), train_loss = 1.10683926, grad/param norm = 1.7077e-01, time/batch = 15.2052s	
7397/22750 (epoch 16.257), train_loss = 1.03221430, grad/param norm = 1.8546e-01, time/batch = 15.0590s	
7398/22750 (epoch 16.259), train_loss = 1.24419005, grad/param norm = 2.2116e-01, time/batch = 15.7022s	
7399/22750 (epoch 16.262), train_loss = 1.08829890, grad/param norm = 1.8971e-01, time/batch = 14.9077s	
7400/22750 (epoch 16.264), train_loss = 0.93780640, grad/param norm = 1.8321e-01, time/batch = 15.1246s	
7401/22750 (epoch 16.266), train_loss = 1.12556592, grad/param norm = 2.1997e-01, time/batch = 15.5451s	
7402/22750 (epoch 16.268), train_loss = 1.25975549, grad/param norm = 2.0252e-01, time/batch = 15.4599s	
7403/22750 (epoch 16.270), train_loss = 1.03978488, grad/param norm = 2.1113e-01, time/batch = 15.2162s	
7404/22750 (epoch 16.273), train_loss = 1.39269965, grad/param norm = 2.2398e-01, time/batch = 15.9320s	
7405/22750 (epoch 16.275), train_loss = 1.20482315, grad/param norm = 1.8333e-01, time/batch = 15.6972s	
7406/22750 (epoch 16.277), train_loss = 1.06700122, grad/param norm = 2.0444e-01, time/batch = 15.6852s	
7407/22750 (epoch 16.279), train_loss = 0.94744574, grad/param norm = 1.7999e-01, time/batch = 15.6981s	
7408/22750 (epoch 16.281), train_loss = 1.24150315, grad/param norm = 2.0466e-01, time/batch = 14.9883s	
7409/22750 (epoch 16.284), train_loss = 1.08733454, grad/param norm = 1.9030e-01, time/batch = 15.3074s	
7410/22750 (epoch 16.286), train_loss = 1.25578138, grad/param norm = 2.0344e-01, time/batch = 15.5309s	
7411/22750 (epoch 16.288), train_loss = 1.29702369, grad/param norm = 2.0545e-01, time/batch = 15.2297s	
7412/22750 (epoch 16.290), train_loss = 1.11070193, grad/param norm = 2.0113e-01, time/batch = 15.1795s	
7413/22750 (epoch 16.292), train_loss = 1.18199933, grad/param norm = 2.0967e-01, time/batch = 15.6839s	
7414/22750 (epoch 16.295), train_loss = 1.16852788, grad/param norm = 1.8907e-01, time/batch = 15.4582s	
7415/22750 (epoch 16.297), train_loss = 1.04926313, grad/param norm = 1.7323e-01, time/batch = 16.2434s	
7416/22750 (epoch 16.299), train_loss = 1.25084951, grad/param norm = 2.0987e-01, time/batch = 15.1322s	
7417/22750 (epoch 16.301), train_loss = 1.14689629, grad/param norm = 1.9192e-01, time/batch = 15.9982s	
7418/22750 (epoch 16.303), train_loss = 1.22505801, grad/param norm = 1.9276e-01, time/batch = 15.2114s	
7419/22750 (epoch 16.305), train_loss = 1.32794019, grad/param norm = 1.8560e-01, time/batch = 15.3112s	
7420/22750 (epoch 16.308), train_loss = 1.15963092, grad/param norm = 1.6634e-01, time/batch = 14.9709s	
7421/22750 (epoch 16.310), train_loss = 1.00708198, grad/param norm = 1.9677e-01, time/batch = 15.4745s	
7422/22750 (epoch 16.312), train_loss = 1.15565075, grad/param norm = 2.0060e-01, time/batch = 15.3048s	
7423/22750 (epoch 16.314), train_loss = 1.13065659, grad/param norm = 1.8109e-01, time/batch = 15.7657s	
7424/22750 (epoch 16.316), train_loss = 1.08080846, grad/param norm = 1.9231e-01, time/batch = 15.9840s	
7425/22750 (epoch 16.319), train_loss = 1.15031026, grad/param norm = 2.0442e-01, time/batch = 16.5929s	
7426/22750 (epoch 16.321), train_loss = 1.06965399, grad/param norm = 2.0129e-01, time/batch = 16.0257s	
7427/22750 (epoch 16.323), train_loss = 1.10863256, grad/param norm = 1.9574e-01, time/batch = 16.8546s	
7428/22750 (epoch 16.325), train_loss = 0.92344790, grad/param norm = 1.8154e-01, time/batch = 16.6740s	
7429/22750 (epoch 16.327), train_loss = 1.11063747, grad/param norm = 1.9820e-01, time/batch = 16.7777s	
7430/22750 (epoch 16.330), train_loss = 1.36623574, grad/param norm = 2.0684e-01, time/batch = 19.2646s	
7431/22750 (epoch 16.332), train_loss = 1.32489089, grad/param norm = 1.9135e-01, time/batch = 17.1957s	
7432/22750 (epoch 16.334), train_loss = 0.91250515, grad/param norm = 1.7257e-01, time/batch = 18.5864s	
7433/22750 (epoch 16.336), train_loss = 1.19122485, grad/param norm = 2.0036e-01, time/batch = 16.0863s	
7434/22750 (epoch 16.338), train_loss = 1.08062256, grad/param norm = 1.8370e-01, time/batch = 16.7327s	
7435/22750 (epoch 16.341), train_loss = 1.09837308, grad/param norm = 1.8914e-01, time/batch = 16.9908s	
7436/22750 (epoch 16.343), train_loss = 0.96027641, grad/param norm = 1.9841e-01, time/batch = 17.2347s	
7437/22750 (epoch 16.345), train_loss = 1.24267950, grad/param norm = 1.9436e-01, time/batch = 18.7604s	
7438/22750 (epoch 16.347), train_loss = 1.28299433, grad/param norm = 2.0463e-01, time/batch = 18.9193s	
7439/22750 (epoch 16.349), train_loss = 0.89136351, grad/param norm = 1.9416e-01, time/batch = 18.6815s	
7440/22750 (epoch 16.352), train_loss = 1.20946137, grad/param norm = 1.8933e-01, time/batch = 16.4991s	
7441/22750 (epoch 16.354), train_loss = 1.24589817, grad/param norm = 2.0468e-01, time/batch = 16.8487s	
7442/22750 (epoch 16.356), train_loss = 1.26019912, grad/param norm = 1.9979e-01, time/batch = 16.5790s	
7443/22750 (epoch 16.358), train_loss = 1.11496658, grad/param norm = 1.9888e-01, time/batch = 16.4675s	
7444/22750 (epoch 16.360), train_loss = 1.31764150, grad/param norm = 1.9111e-01, time/batch = 16.7367s	
7445/22750 (epoch 16.363), train_loss = 1.08354967, grad/param norm = 1.7908e-01, time/batch = 15.8225s	
7446/22750 (epoch 16.365), train_loss = 0.88868170, grad/param norm = 1.7002e-01, time/batch = 18.6592s	
7447/22750 (epoch 16.367), train_loss = 0.97197384, grad/param norm = 1.9867e-01, time/batch = 18.2483s	
7448/22750 (epoch 16.369), train_loss = 1.11676457, grad/param norm = 1.9347e-01, time/batch = 17.7753s	
7449/22750 (epoch 16.371), train_loss = 1.05157050, grad/param norm = 1.7138e-01, time/batch = 17.5391s	
7450/22750 (epoch 16.374), train_loss = 1.00379885, grad/param norm = 1.7922e-01, time/batch = 16.0087s	
7451/22750 (epoch 16.376), train_loss = 1.06512465, grad/param norm = 1.8076e-01, time/batch = 16.0724s	
7452/22750 (epoch 16.378), train_loss = 1.14650606, grad/param norm = 1.9222e-01, time/batch = 16.8338s	
7453/22750 (epoch 16.380), train_loss = 1.26775340, grad/param norm = 2.0503e-01, time/batch = 16.1868s	
7454/22750 (epoch 16.382), train_loss = 1.05269148, grad/param norm = 1.8054e-01, time/batch = 15.9300s	
7455/22750 (epoch 16.385), train_loss = 1.19849951, grad/param norm = 1.8176e-01, time/batch = 15.9434s	
7456/22750 (epoch 16.387), train_loss = 1.17064775, grad/param norm = 1.8553e-01, time/batch = 17.1417s	
7457/22750 (epoch 16.389), train_loss = 0.87501464, grad/param norm = 1.7310e-01, time/batch = 16.1070s	
7458/22750 (epoch 16.391), train_loss = 0.69620736, grad/param norm = 1.4831e-01, time/batch = 17.4333s	
7459/22750 (epoch 16.393), train_loss = 0.97078687, grad/param norm = 1.7873e-01, time/batch = 17.9312s	
7460/22750 (epoch 16.396), train_loss = 1.14161195, grad/param norm = 1.9177e-01, time/batch = 19.6907s	
7461/22750 (epoch 16.398), train_loss = 1.06041371, grad/param norm = 1.8127e-01, time/batch = 17.3442s	
7462/22750 (epoch 16.400), train_loss = 1.08388041, grad/param norm = 1.7414e-01, time/batch = 18.8267s	
7463/22750 (epoch 16.402), train_loss = 1.17617189, grad/param norm = 1.8551e-01, time/batch = 17.0016s	
7464/22750 (epoch 16.404), train_loss = 1.27467437, grad/param norm = 1.9351e-01, time/batch = 19.0006s	
7465/22750 (epoch 16.407), train_loss = 1.22577996, grad/param norm = 1.9614e-01, time/batch = 20.7418s	
7466/22750 (epoch 16.409), train_loss = 1.09645022, grad/param norm = 1.9169e-01, time/batch = 17.9922s	
7467/22750 (epoch 16.411), train_loss = 1.07954721, grad/param norm = 1.7483e-01, time/batch = 16.7202s	
7468/22750 (epoch 16.413), train_loss = 0.87011936, grad/param norm = 1.7495e-01, time/batch = 20.2802s	
7469/22750 (epoch 16.415), train_loss = 0.84423570, grad/param norm = 1.6134e-01, time/batch = 18.1189s	
7470/22750 (epoch 16.418), train_loss = 1.05424218, grad/param norm = 1.9331e-01, time/batch = 19.0896s	
7471/22750 (epoch 16.420), train_loss = 1.22884222, grad/param norm = 2.6277e-01, time/batch = 19.0905s	
7472/22750 (epoch 16.422), train_loss = 1.33552431, grad/param norm = 2.3114e-01, time/batch = 18.3532s	
7473/22750 (epoch 16.424), train_loss = 1.35268579, grad/param norm = 2.2546e-01, time/batch = 19.3216s	
7474/22750 (epoch 16.426), train_loss = 1.31293209, grad/param norm = 1.9767e-01, time/batch = 17.9120s	
7475/22750 (epoch 16.429), train_loss = 0.95841278, grad/param norm = 1.9333e-01, time/batch = 18.5707s	
7476/22750 (epoch 16.431), train_loss = 0.92947800, grad/param norm = 1.8582e-01, time/batch = 19.4447s	
7477/22750 (epoch 16.433), train_loss = 1.03303133, grad/param norm = 1.7923e-01, time/batch = 19.2722s	
7478/22750 (epoch 16.435), train_loss = 0.85771779, grad/param norm = 1.6598e-01, time/batch = 20.5107s	
7479/22750 (epoch 16.437), train_loss = 0.75637856, grad/param norm = 1.7197e-01, time/batch = 16.4444s	
7480/22750 (epoch 16.440), train_loss = 1.12251164, grad/param norm = 1.9328e-01, time/batch = 18.0032s	
7481/22750 (epoch 16.442), train_loss = 1.14821660, grad/param norm = 2.1067e-01, time/batch = 20.2976s	
7482/22750 (epoch 16.444), train_loss = 1.08229871, grad/param norm = 2.0830e-01, time/batch = 18.3389s	
7483/22750 (epoch 16.446), train_loss = 1.10666163, grad/param norm = 2.1621e-01, time/batch = 17.9764s	
7484/22750 (epoch 16.448), train_loss = 1.40007345, grad/param norm = 2.0815e-01, time/batch = 16.6584s	
7485/22750 (epoch 16.451), train_loss = 1.28918206, grad/param norm = 2.0181e-01, time/batch = 15.7824s	
7486/22750 (epoch 16.453), train_loss = 1.30512600, grad/param norm = 1.9476e-01, time/batch = 17.8567s	
7487/22750 (epoch 16.455), train_loss = 1.40389653, grad/param norm = 2.2136e-01, time/batch = 17.1183s	
7488/22750 (epoch 16.457), train_loss = 1.24603447, grad/param norm = 2.6892e-01, time/batch = 18.8562s	
7489/22750 (epoch 16.459), train_loss = 1.21972877, grad/param norm = 1.9518e-01, time/batch = 18.9972s	
7490/22750 (epoch 16.462), train_loss = 1.20020894, grad/param norm = 1.7900e-01, time/batch = 17.0700s	
7491/22750 (epoch 16.464), train_loss = 0.94096982, grad/param norm = 1.9392e-01, time/batch = 17.8397s	
7492/22750 (epoch 16.466), train_loss = 1.32020599, grad/param norm = 2.2158e-01, time/batch = 17.1790s	
7493/22750 (epoch 16.468), train_loss = 1.09633802, grad/param norm = 1.9607e-01, time/batch = 17.7603s	
7494/22750 (epoch 16.470), train_loss = 1.25371824, grad/param norm = 1.9865e-01, time/batch = 17.7068s	
7495/22750 (epoch 16.473), train_loss = 1.12246202, grad/param norm = 2.0502e-01, time/batch = 19.6216s	
7496/22750 (epoch 16.475), train_loss = 1.14285896, grad/param norm = 2.0840e-01, time/batch = 18.8608s	
7497/22750 (epoch 16.477), train_loss = 0.94209621, grad/param norm = 1.7069e-01, time/batch = 20.2491s	
7498/22750 (epoch 16.479), train_loss = 0.94687771, grad/param norm = 1.7866e-01, time/batch = 19.7406s	
7499/22750 (epoch 16.481), train_loss = 0.87703453, grad/param norm = 1.6195e-01, time/batch = 19.0767s	
7500/22750 (epoch 16.484), train_loss = 0.81664121, grad/param norm = 1.8406e-01, time/batch = 19.5877s	
7501/22750 (epoch 16.486), train_loss = 0.95067894, grad/param norm = 1.8905e-01, time/batch = 18.8294s	
7502/22750 (epoch 16.488), train_loss = 0.83618062, grad/param norm = 1.7775e-01, time/batch = 19.4121s	
7503/22750 (epoch 16.490), train_loss = 1.12225676, grad/param norm = 1.8169e-01, time/batch = 20.4379s	
7504/22750 (epoch 16.492), train_loss = 1.24779660, grad/param norm = 2.0216e-01, time/batch = 18.9522s	
7505/22750 (epoch 16.495), train_loss = 0.99898810, grad/param norm = 1.8278e-01, time/batch = 18.7774s	
7506/22750 (epoch 16.497), train_loss = 1.13228758, grad/param norm = 2.1615e-01, time/batch = 19.1719s	
7507/22750 (epoch 16.499), train_loss = 1.00392646, grad/param norm = 1.8361e-01, time/batch = 16.7291s	
7508/22750 (epoch 16.501), train_loss = 1.09963612, grad/param norm = 1.8769e-01, time/batch = 16.7459s	
7509/22750 (epoch 16.503), train_loss = 1.11839767, grad/param norm = 1.9029e-01, time/batch = 16.4955s	
7510/22750 (epoch 16.505), train_loss = 0.96360841, grad/param norm = 1.8319e-01, time/batch = 16.5308s	
7511/22750 (epoch 16.508), train_loss = 0.91338440, grad/param norm = 1.7811e-01, time/batch = 17.0899s	
7512/22750 (epoch 16.510), train_loss = 0.94312519, grad/param norm = 1.6855e-01, time/batch = 18.0167s	
7513/22750 (epoch 16.512), train_loss = 0.97955961, grad/param norm = 1.6785e-01, time/batch = 16.7635s	
7514/22750 (epoch 16.514), train_loss = 1.03198774, grad/param norm = 1.8773e-01, time/batch = 20.0734s	
7515/22750 (epoch 16.516), train_loss = 1.02054766, grad/param norm = 1.8595e-01, time/batch = 18.2648s	
7516/22750 (epoch 16.519), train_loss = 1.18115885, grad/param norm = 1.8679e-01, time/batch = 19.4984s	
7517/22750 (epoch 16.521), train_loss = 1.08219274, grad/param norm = 1.8419e-01, time/batch = 20.0922s	
7518/22750 (epoch 16.523), train_loss = 1.05822382, grad/param norm = 1.9918e-01, time/batch = 18.0718s	
7519/22750 (epoch 16.525), train_loss = 1.25816700, grad/param norm = 2.0460e-01, time/batch = 20.3133s	
7520/22750 (epoch 16.527), train_loss = 1.08781082, grad/param norm = 1.8662e-01, time/batch = 21.1316s	
7521/22750 (epoch 16.530), train_loss = 1.02981249, grad/param norm = 1.9901e-01, time/batch = 17.6576s	
7522/22750 (epoch 16.532), train_loss = 0.92934977, grad/param norm = 1.6228e-01, time/batch = 19.7695s	
7523/22750 (epoch 16.534), train_loss = 1.18948440, grad/param norm = 1.8709e-01, time/batch = 19.7740s	
7524/22750 (epoch 16.536), train_loss = 1.13497802, grad/param norm = 1.8024e-01, time/batch = 18.4937s	
7525/22750 (epoch 16.538), train_loss = 1.10789910, grad/param norm = 1.7471e-01, time/batch = 18.6677s	
7526/22750 (epoch 16.541), train_loss = 0.94783826, grad/param norm = 1.7916e-01, time/batch = 19.9816s	
7527/22750 (epoch 16.543), train_loss = 0.96403287, grad/param norm = 1.9792e-01, time/batch = 16.7864s	
7528/22750 (epoch 16.545), train_loss = 1.20579257, grad/param norm = 1.8822e-01, time/batch = 15.7490s	
7529/22750 (epoch 16.547), train_loss = 0.99329686, grad/param norm = 1.7207e-01, time/batch = 15.3036s	
7530/22750 (epoch 16.549), train_loss = 1.03765653, grad/param norm = 1.8092e-01, time/batch = 15.3253s	
7531/22750 (epoch 16.552), train_loss = 1.17027525, grad/param norm = 1.9950e-01, time/batch = 16.0348s	
7532/22750 (epoch 16.554), train_loss = 1.18946254, grad/param norm = 1.9236e-01, time/batch = 15.4040s	
7533/22750 (epoch 16.556), train_loss = 1.09986551, grad/param norm = 2.0972e-01, time/batch = 15.2243s	
7534/22750 (epoch 16.558), train_loss = 1.21124304, grad/param norm = 2.0398e-01, time/batch = 15.2036s	
7535/22750 (epoch 16.560), train_loss = 1.03132077, grad/param norm = 1.8970e-01, time/batch = 15.8418s	
7536/22750 (epoch 16.563), train_loss = 1.21500094, grad/param norm = 1.8647e-01, time/batch = 15.3787s	
7537/22750 (epoch 16.565), train_loss = 1.15617112, grad/param norm = 1.9660e-01, time/batch = 15.3704s	
7538/22750 (epoch 16.567), train_loss = 1.13341674, grad/param norm = 1.7849e-01, time/batch = 16.1680s	
7539/22750 (epoch 16.569), train_loss = 1.07864499, grad/param norm = 1.8601e-01, time/batch = 15.5379s	
7540/22750 (epoch 16.571), train_loss = 1.10857331, grad/param norm = 1.9307e-01, time/batch = 15.3957s	
7541/22750 (epoch 16.574), train_loss = 0.99106384, grad/param norm = 1.7615e-01, time/batch = 15.1517s	
7542/22750 (epoch 16.576), train_loss = 1.09214146, grad/param norm = 2.0497e-01, time/batch = 15.4754s	
7543/22750 (epoch 16.578), train_loss = 0.95690180, grad/param norm = 1.8465e-01, time/batch = 15.5641s	
7544/22750 (epoch 16.580), train_loss = 1.11797236, grad/param norm = 2.0224e-01, time/batch = 15.4426s	
7545/22750 (epoch 16.582), train_loss = 0.96388271, grad/param norm = 1.6686e-01, time/batch = 15.1331s	
7546/22750 (epoch 16.585), train_loss = 0.91991952, grad/param norm = 1.9237e-01, time/batch = 15.3726s	
7547/22750 (epoch 16.587), train_loss = 0.93002905, grad/param norm = 1.6347e-01, time/batch = 15.2853s	
7548/22750 (epoch 16.589), train_loss = 0.89016342, grad/param norm = 1.6723e-01, time/batch = 15.9816s	
7549/22750 (epoch 16.591), train_loss = 1.04765252, grad/param norm = 1.8486e-01, time/batch = 15.1266s	
7550/22750 (epoch 16.593), train_loss = 1.25901995, grad/param norm = 1.8262e-01, time/batch = 15.5341s	
7551/22750 (epoch 16.596), train_loss = 1.26846928, grad/param norm = 2.0331e-01, time/batch = 15.5612s	
7552/22750 (epoch 16.598), train_loss = 1.32656474, grad/param norm = 2.0637e-01, time/batch = 15.7207s	
7553/22750 (epoch 16.600), train_loss = 1.24527119, grad/param norm = 1.9464e-01, time/batch = 15.9578s	
7554/22750 (epoch 16.602), train_loss = 0.99389211, grad/param norm = 1.7928e-01, time/batch = 28.2363s	
7555/22750 (epoch 16.604), train_loss = 1.03140057, grad/param norm = 1.7904e-01, time/batch = 17.1803s	
7556/22750 (epoch 16.607), train_loss = 0.89320992, grad/param norm = 1.5850e-01, time/batch = 15.4543s	
7557/22750 (epoch 16.609), train_loss = 0.85204140, grad/param norm = 1.5772e-01, time/batch = 15.9686s	
7558/22750 (epoch 16.611), train_loss = 1.05321615, grad/param norm = 1.9310e-01, time/batch = 15.3627s	
7559/22750 (epoch 16.613), train_loss = 0.98744734, grad/param norm = 1.7654e-01, time/batch = 15.4471s	
7560/22750 (epoch 16.615), train_loss = 1.01739758, grad/param norm = 1.7145e-01, time/batch = 15.2868s	
7561/22750 (epoch 16.618), train_loss = 1.03895751, grad/param norm = 1.7953e-01, time/batch = 15.9314s	
7562/22750 (epoch 16.620), train_loss = 1.06588074, grad/param norm = 1.8653e-01, time/batch = 15.4630s	
7563/22750 (epoch 16.622), train_loss = 0.87474854, grad/param norm = 1.6546e-01, time/batch = 15.0673s	
7564/22750 (epoch 16.624), train_loss = 0.99908483, grad/param norm = 1.9193e-01, time/batch = 15.2912s	
7565/22750 (epoch 16.626), train_loss = 0.91021402, grad/param norm = 1.7474e-01, time/batch = 16.4615s	
7566/22750 (epoch 16.629), train_loss = 1.00384822, grad/param norm = 1.8079e-01, time/batch = 15.9950s	
7567/22750 (epoch 16.631), train_loss = 1.05226643, grad/param norm = 1.7430e-01, time/batch = 16.2268s	
7568/22750 (epoch 16.633), train_loss = 0.90653302, grad/param norm = 1.6802e-01, time/batch = 16.4881s	
7569/22750 (epoch 16.635), train_loss = 1.08890054, grad/param norm = 1.8518e-01, time/batch = 15.7013s	
7570/22750 (epoch 16.637), train_loss = 1.14206739, grad/param norm = 1.9575e-01, time/batch = 15.9236s	
7571/22750 (epoch 16.640), train_loss = 1.16486683, grad/param norm = 2.0411e-01, time/batch = 15.3623s	
7572/22750 (epoch 16.642), train_loss = 1.22732854, grad/param norm = 1.9197e-01, time/batch = 16.4668s	
7573/22750 (epoch 16.644), train_loss = 1.11009693, grad/param norm = 1.9461e-01, time/batch = 15.9107s	
7574/22750 (epoch 16.646), train_loss = 1.17090663, grad/param norm = 2.5283e-01, time/batch = 15.6208s	
7575/22750 (epoch 16.648), train_loss = 1.11936080, grad/param norm = 2.1587e-01, time/batch = 15.8710s	
7576/22750 (epoch 16.651), train_loss = 1.14504087, grad/param norm = 1.9728e-01, time/batch = 15.9389s	
7577/22750 (epoch 16.653), train_loss = 1.15721933, grad/param norm = 1.9432e-01, time/batch = 15.9341s	
7578/22750 (epoch 16.655), train_loss = 1.11605104, grad/param norm = 1.8877e-01, time/batch = 16.0181s	
7579/22750 (epoch 16.657), train_loss = 1.28396591, grad/param norm = 2.1048e-01, time/batch = 16.7230s	
7580/22750 (epoch 16.659), train_loss = 1.35286090, grad/param norm = 2.0887e-01, time/batch = 15.6138s	
7581/22750 (epoch 16.662), train_loss = 1.33653550, grad/param norm = 2.1423e-01, time/batch = 16.3281s	
7582/22750 (epoch 16.664), train_loss = 1.16119524, grad/param norm = 2.1108e-01, time/batch = 15.9451s	
7583/22750 (epoch 16.666), train_loss = 0.93455445, grad/param norm = 1.7767e-01, time/batch = 16.0448s	
7584/22750 (epoch 16.668), train_loss = 1.10635280, grad/param norm = 1.8728e-01, time/batch = 15.8052s	
7585/22750 (epoch 16.670), train_loss = 1.10512942, grad/param norm = 1.9863e-01, time/batch = 15.5601s	
7586/22750 (epoch 16.673), train_loss = 1.38799951, grad/param norm = 2.2610e-01, time/batch = 15.2946s	
7587/22750 (epoch 16.675), train_loss = 1.52066926, grad/param norm = 2.3067e-01, time/batch = 15.6090s	
7588/22750 (epoch 16.677), train_loss = 1.29865636, grad/param norm = 2.3707e-01, time/batch = 15.3772s	
7589/22750 (epoch 16.679), train_loss = 1.34368069, grad/param norm = 2.1238e-01, time/batch = 15.7791s	
7590/22750 (epoch 16.681), train_loss = 1.28736994, grad/param norm = 1.9987e-01, time/batch = 15.2963s	
7591/22750 (epoch 16.684), train_loss = 1.28610833, grad/param norm = 2.1255e-01, time/batch = 16.0041s	
7592/22750 (epoch 16.686), train_loss = 1.28196158, grad/param norm = 2.0961e-01, time/batch = 15.1280s	
7593/22750 (epoch 16.688), train_loss = 1.26054402, grad/param norm = 2.1166e-01, time/batch = 15.9517s	
7594/22750 (epoch 16.690), train_loss = 1.24928251, grad/param norm = 2.1359e-01, time/batch = 15.1526s	
7595/22750 (epoch 16.692), train_loss = 1.31030979, grad/param norm = 2.0372e-01, time/batch = 15.5560s	
7596/22750 (epoch 16.695), train_loss = 1.16165396, grad/param norm = 1.9890e-01, time/batch = 14.9827s	
7597/22750 (epoch 16.697), train_loss = 1.10896913, grad/param norm = 1.9798e-01, time/batch = 16.6271s	
7598/22750 (epoch 16.699), train_loss = 1.10963714, grad/param norm = 1.8640e-01, time/batch = 15.8276s	
7599/22750 (epoch 16.701), train_loss = 0.97013260, grad/param norm = 1.8204e-01, time/batch = 15.7789s	
7600/22750 (epoch 16.703), train_loss = 1.10672689, grad/param norm = 1.7856e-01, time/batch = 15.7768s	
7601/22750 (epoch 16.705), train_loss = 1.02993748, grad/param norm = 1.9341e-01, time/batch = 15.4564s	
7602/22750 (epoch 16.708), train_loss = 1.11983807, grad/param norm = 2.1395e-01, time/batch = 16.0183s	
7603/22750 (epoch 16.710), train_loss = 0.96940081, grad/param norm = 1.9109e-01, time/batch = 16.1140s	
7604/22750 (epoch 16.712), train_loss = 0.99842154, grad/param norm = 1.8144e-01, time/batch = 15.6392s	
7605/22750 (epoch 16.714), train_loss = 0.90267494, grad/param norm = 1.6884e-01, time/batch = 15.8028s	
7606/22750 (epoch 16.716), train_loss = 0.98658164, grad/param norm = 1.9651e-01, time/batch = 15.7900s	
7607/22750 (epoch 16.719), train_loss = 1.18368964, grad/param norm = 2.2229e-01, time/batch = 15.9036s	
7608/22750 (epoch 16.721), train_loss = 1.22325338, grad/param norm = 1.8411e-01, time/batch = 15.1320s	
7609/22750 (epoch 16.723), train_loss = 1.15850347, grad/param norm = 1.9608e-01, time/batch = 15.2031s	
7610/22750 (epoch 16.725), train_loss = 1.09501307, grad/param norm = 1.9009e-01, time/batch = 16.0172s	
7611/22750 (epoch 16.727), train_loss = 1.03634522, grad/param norm = 1.6870e-01, time/batch = 15.3001s	
7612/22750 (epoch 16.730), train_loss = 1.05099597, grad/param norm = 1.9673e-01, time/batch = 17.3980s	
7613/22750 (epoch 16.732), train_loss = 1.01040904, grad/param norm = 1.7915e-01, time/batch = 15.7679s	
7614/22750 (epoch 16.734), train_loss = 0.86509308, grad/param norm = 1.6098e-01, time/batch = 16.6098s	
7615/22750 (epoch 16.736), train_loss = 1.01882629, grad/param norm = 1.7858e-01, time/batch = 19.1221s	
7616/22750 (epoch 16.738), train_loss = 1.14105541, grad/param norm = 2.1190e-01, time/batch = 19.1023s	
7617/22750 (epoch 16.741), train_loss = 1.20887667, grad/param norm = 1.8753e-01, time/batch = 16.9080s	
7618/22750 (epoch 16.743), train_loss = 1.15641605, grad/param norm = 1.8579e-01, time/batch = 16.2762s	
7619/22750 (epoch 16.745), train_loss = 0.96106575, grad/param norm = 1.7285e-01, time/batch = 16.7980s	
7620/22750 (epoch 16.747), train_loss = 1.02471671, grad/param norm = 1.7109e-01, time/batch = 17.1431s	
7621/22750 (epoch 16.749), train_loss = 1.28933899, grad/param norm = 2.1631e-01, time/batch = 17.2413s	
7622/22750 (epoch 16.752), train_loss = 1.07358652, grad/param norm = 1.9089e-01, time/batch = 18.3053s	
7623/22750 (epoch 16.754), train_loss = 1.13915908, grad/param norm = 2.1025e-01, time/batch = 18.6252s	
7624/22750 (epoch 16.756), train_loss = 0.98080775, grad/param norm = 2.2152e-01, time/batch = 17.2346s	
7625/22750 (epoch 16.758), train_loss = 0.96724913, grad/param norm = 1.7982e-01, time/batch = 17.7446s	
7626/22750 (epoch 16.760), train_loss = 1.06914237, grad/param norm = 1.9601e-01, time/batch = 17.4072s	
7627/22750 (epoch 16.763), train_loss = 1.15268437, grad/param norm = 2.0054e-01, time/batch = 17.2825s	
7628/22750 (epoch 16.765), train_loss = 1.10741272, grad/param norm = 2.1280e-01, time/batch = 16.3245s	
7629/22750 (epoch 16.767), train_loss = 1.13892163, grad/param norm = 1.9586e-01, time/batch = 18.4775s	
7630/22750 (epoch 16.769), train_loss = 1.35476425, grad/param norm = 2.2470e-01, time/batch = 16.9093s	
7631/22750 (epoch 16.771), train_loss = 1.27087387, grad/param norm = 2.1542e-01, time/batch = 16.5648s	
7632/22750 (epoch 16.774), train_loss = 1.04934574, grad/param norm = 2.1670e-01, time/batch = 15.4328s	
7633/22750 (epoch 16.776), train_loss = 1.15733014, grad/param norm = 2.1146e-01, time/batch = 20.6805s	
7634/22750 (epoch 16.778), train_loss = 1.30483415, grad/param norm = 2.0088e-01, time/batch = 17.3843s	
7635/22750 (epoch 16.780), train_loss = 1.13290163, grad/param norm = 2.0861e-01, time/batch = 17.9897s	
7636/22750 (epoch 16.782), train_loss = 1.27358811, grad/param norm = 1.9839e-01, time/batch = 20.0672s	
7637/22750 (epoch 16.785), train_loss = 1.09504552, grad/param norm = 1.8355e-01, time/batch = 17.5083s	
7638/22750 (epoch 16.787), train_loss = 0.99259445, grad/param norm = 1.8991e-01, time/batch = 16.3086s	
7639/22750 (epoch 16.789), train_loss = 1.07583275, grad/param norm = 1.8173e-01, time/batch = 16.2242s	
7640/22750 (epoch 16.791), train_loss = 1.07786698, grad/param norm = 1.8162e-01, time/batch = 17.4110s	
7641/22750 (epoch 16.793), train_loss = 0.99969639, grad/param norm = 1.8812e-01, time/batch = 16.6375s	
7642/22750 (epoch 16.796), train_loss = 0.91670115, grad/param norm = 1.7124e-01, time/batch = 15.8137s	
7643/22750 (epoch 16.798), train_loss = 0.97589293, grad/param norm = 1.7706e-01, time/batch = 14.9847s	
7644/22750 (epoch 16.800), train_loss = 1.01244507, grad/param norm = 1.7982e-01, time/batch = 14.9025s	
7645/22750 (epoch 16.802), train_loss = 0.94678591, grad/param norm = 1.7646e-01, time/batch = 15.6087s	
7646/22750 (epoch 16.804), train_loss = 1.27083392, grad/param norm = 1.9469e-01, time/batch = 15.2589s	
7647/22750 (epoch 16.807), train_loss = 1.17131234, grad/param norm = 1.8611e-01, time/batch = 15.5746s	
7648/22750 (epoch 16.809), train_loss = 1.32145408, grad/param norm = 2.1468e-01, time/batch = 15.5410s	
7649/22750 (epoch 16.811), train_loss = 1.03826262, grad/param norm = 1.9127e-01, time/batch = 15.8367s	
7650/22750 (epoch 16.813), train_loss = 1.14936364, grad/param norm = 1.8246e-01, time/batch = 16.3388s	
7651/22750 (epoch 16.815), train_loss = 1.27495827, grad/param norm = 1.9779e-01, time/batch = 18.3241s	
7652/22750 (epoch 16.818), train_loss = 1.26272967, grad/param norm = 1.8709e-01, time/batch = 18.2505s	
7653/22750 (epoch 16.820), train_loss = 1.38985764, grad/param norm = 1.9873e-01, time/batch = 17.9326s	
7654/22750 (epoch 16.822), train_loss = 1.15159437, grad/param norm = 1.8216e-01, time/batch = 20.0809s	
7655/22750 (epoch 16.824), train_loss = 1.01630054, grad/param norm = 1.7140e-01, time/batch = 17.1753s	
7656/22750 (epoch 16.826), train_loss = 1.09008652, grad/param norm = 1.7360e-01, time/batch = 17.5805s	
7657/22750 (epoch 16.829), train_loss = 1.28300782, grad/param norm = 2.0737e-01, time/batch = 19.4920s	
7658/22750 (epoch 16.831), train_loss = 1.23405806, grad/param norm = 1.8470e-01, time/batch = 18.5814s	
7659/22750 (epoch 16.833), train_loss = 1.16520671, grad/param norm = 2.1052e-01, time/batch = 18.4243s	
7660/22750 (epoch 16.835), train_loss = 1.06081315, grad/param norm = 1.8227e-01, time/batch = 18.6670s	
7661/22750 (epoch 16.837), train_loss = 1.05772367, grad/param norm = 1.7659e-01, time/batch = 19.0703s	
7662/22750 (epoch 16.840), train_loss = 1.00063487, grad/param norm = 1.6904e-01, time/batch = 16.9981s	
7663/22750 (epoch 16.842), train_loss = 1.05338797, grad/param norm = 1.8725e-01, time/batch = 17.1222s	
7664/22750 (epoch 16.844), train_loss = 1.18299719, grad/param norm = 2.0316e-01, time/batch = 16.9386s	
7665/22750 (epoch 16.846), train_loss = 1.14604332, grad/param norm = 1.9604e-01, time/batch = 16.0129s	
7666/22750 (epoch 16.848), train_loss = 1.00817164, grad/param norm = 1.6487e-01, time/batch = 15.6114s	
7667/22750 (epoch 16.851), train_loss = 0.98275158, grad/param norm = 1.7255e-01, time/batch = 15.5269s	
7668/22750 (epoch 16.853), train_loss = 1.14054972, grad/param norm = 1.8128e-01, time/batch = 15.4456s	
7669/22750 (epoch 16.855), train_loss = 0.94593425, grad/param norm = 1.6183e-01, time/batch = 15.9319s	
7670/22750 (epoch 16.857), train_loss = 1.13236229, grad/param norm = 1.8537e-01, time/batch = 15.8610s	
7671/22750 (epoch 16.859), train_loss = 1.17408301, grad/param norm = 2.2127e-01, time/batch = 16.0970s	
7672/22750 (epoch 16.862), train_loss = 1.29668208, grad/param norm = 1.9713e-01, time/batch = 15.7303s	
7673/22750 (epoch 16.864), train_loss = 1.10669617, grad/param norm = 1.8540e-01, time/batch = 16.2833s	
7674/22750 (epoch 16.866), train_loss = 1.14077877, grad/param norm = 1.7108e-01, time/batch = 15.6359s	
7675/22750 (epoch 16.868), train_loss = 1.03651464, grad/param norm = 1.7498e-01, time/batch = 16.3302s	
7676/22750 (epoch 16.870), train_loss = 0.90066038, grad/param norm = 1.7693e-01, time/batch = 15.7632s	
7677/22750 (epoch 16.873), train_loss = 1.04390972, grad/param norm = 1.7326e-01, time/batch = 16.1700s	
7678/22750 (epoch 16.875), train_loss = 1.17123624, grad/param norm = 1.8586e-01, time/batch = 15.6986s	
7679/22750 (epoch 16.877), train_loss = 1.01281284, grad/param norm = 1.7443e-01, time/batch = 15.7585s	
7680/22750 (epoch 16.879), train_loss = 1.23951609, grad/param norm = 1.9967e-01, time/batch = 16.4150s	
7681/22750 (epoch 16.881), train_loss = 1.19310698, grad/param norm = 1.9490e-01, time/batch = 16.0136s	
7682/22750 (epoch 16.884), train_loss = 1.00571263, grad/param norm = 1.9311e-01, time/batch = 15.9360s	
7683/22750 (epoch 16.886), train_loss = 1.17817395, grad/param norm = 1.9046e-01, time/batch = 16.5806s	
7684/22750 (epoch 16.888), train_loss = 1.16449588, grad/param norm = 1.8794e-01, time/batch = 16.6239s	
7685/22750 (epoch 16.890), train_loss = 1.21967572, grad/param norm = 1.9693e-01, time/batch = 16.6120s	
7686/22750 (epoch 16.892), train_loss = 1.48818103, grad/param norm = 2.3173e-01, time/batch = 16.4430s	
7687/22750 (epoch 16.895), train_loss = 1.15476321, grad/param norm = 1.7487e-01, time/batch = 16.4293s	
7688/22750 (epoch 16.897), train_loss = 1.23260854, grad/param norm = 2.0057e-01, time/batch = 16.3343s	
7689/22750 (epoch 16.899), train_loss = 1.15518339, grad/param norm = 1.8393e-01, time/batch = 16.7137s	
7690/22750 (epoch 16.901), train_loss = 1.30393839, grad/param norm = 2.1693e-01, time/batch = 17.0448s	
7691/22750 (epoch 16.903), train_loss = 1.10040352, grad/param norm = 1.9677e-01, time/batch = 16.6662s	
7692/22750 (epoch 16.905), train_loss = 1.21148340, grad/param norm = 1.9736e-01, time/batch = 17.0933s	
7693/22750 (epoch 16.908), train_loss = 1.04713542, grad/param norm = 1.9996e-01, time/batch = 17.0176s	
7694/22750 (epoch 16.910), train_loss = 0.89701343, grad/param norm = 1.8928e-01, time/batch = 16.6096s	
7695/22750 (epoch 16.912), train_loss = 1.05348423, grad/param norm = 1.8758e-01, time/batch = 16.9710s	
7696/22750 (epoch 16.914), train_loss = 1.10957409, grad/param norm = 1.7974e-01, time/batch = 16.5002s	
7697/22750 (epoch 16.916), train_loss = 0.94457699, grad/param norm = 1.9060e-01, time/batch = 16.4799s	
7698/22750 (epoch 16.919), train_loss = 1.05495954, grad/param norm = 2.1321e-01, time/batch = 16.5832s	
7699/22750 (epoch 16.921), train_loss = 0.79242231, grad/param norm = 1.5208e-01, time/batch = 15.7544s	
7700/22750 (epoch 16.923), train_loss = 0.98248385, grad/param norm = 1.7887e-01, time/batch = 15.5247s	
7701/22750 (epoch 16.925), train_loss = 1.08572335, grad/param norm = 1.8169e-01, time/batch = 15.4383s	
7702/22750 (epoch 16.927), train_loss = 0.86681620, grad/param norm = 1.8947e-01, time/batch = 16.0994s	
7703/22750 (epoch 16.930), train_loss = 0.88304877, grad/param norm = 1.6356e-01, time/batch = 15.4627s	
7704/22750 (epoch 16.932), train_loss = 1.12888664, grad/param norm = 1.8577e-01, time/batch = 15.7026s	
7705/22750 (epoch 16.934), train_loss = 0.82786331, grad/param norm = 1.5804e-01, time/batch = 16.2502s	
7706/22750 (epoch 16.936), train_loss = 1.21399933, grad/param norm = 2.1677e-01, time/batch = 16.3988s	
7707/22750 (epoch 16.938), train_loss = 1.15739597, grad/param norm = 1.7259e-01, time/batch = 15.6707s	
7708/22750 (epoch 16.941), train_loss = 1.29425907, grad/param norm = 1.9915e-01, time/batch = 16.0829s	
7709/22750 (epoch 16.943), train_loss = 1.13279411, grad/param norm = 1.8552e-01, time/batch = 16.1579s	
7710/22750 (epoch 16.945), train_loss = 1.12966433, grad/param norm = 1.9202e-01, time/batch = 16.3226s	
7711/22750 (epoch 16.947), train_loss = 1.04938455, grad/param norm = 1.9087e-01, time/batch = 15.4465s	
7712/22750 (epoch 16.949), train_loss = 0.98275769, grad/param norm = 1.8238e-01, time/batch = 15.2026s	
7713/22750 (epoch 16.952), train_loss = 1.00832050, grad/param norm = 1.6690e-01, time/batch = 15.6952s	
7714/22750 (epoch 16.954), train_loss = 0.98509157, grad/param norm = 1.8111e-01, time/batch = 15.7141s	
7715/22750 (epoch 16.956), train_loss = 1.09584107, grad/param norm = 1.7870e-01, time/batch = 15.7755s	
7716/22750 (epoch 16.958), train_loss = 1.03377816, grad/param norm = 1.7149e-01, time/batch = 15.3739s	
7717/22750 (epoch 16.960), train_loss = 1.00162149, grad/param norm = 1.7104e-01, time/batch = 16.1683s	
7718/22750 (epoch 16.963), train_loss = 1.20056835, grad/param norm = 1.9272e-01, time/batch = 15.7534s	
7719/22750 (epoch 16.965), train_loss = 1.17940212, grad/param norm = 1.8643e-01, time/batch = 15.4366s	
7720/22750 (epoch 16.967), train_loss = 1.08910683, grad/param norm = 1.8789e-01, time/batch = 15.2758s	
7721/22750 (epoch 16.969), train_loss = 1.00015454, grad/param norm = 1.8327e-01, time/batch = 16.1366s	
7722/22750 (epoch 16.971), train_loss = 1.04249228, grad/param norm = 1.8965e-01, time/batch = 15.7394s	
7723/22750 (epoch 16.974), train_loss = 1.08675134, grad/param norm = 2.0350e-01, time/batch = 16.6988s	
7724/22750 (epoch 16.976), train_loss = 1.14303232, grad/param norm = 1.8786e-01, time/batch = 15.8667s	
7725/22750 (epoch 16.978), train_loss = 0.99075382, grad/param norm = 1.7357e-01, time/batch = 16.6477s	
7726/22750 (epoch 16.980), train_loss = 1.26219824, grad/param norm = 2.1867e-01, time/batch = 16.0085s	
7727/22750 (epoch 16.982), train_loss = 1.00840970, grad/param norm = 1.6752e-01, time/batch = 15.8326s	
7728/22750 (epoch 16.985), train_loss = 1.31600353, grad/param norm = 2.0718e-01, time/batch = 16.1625s	
7729/22750 (epoch 16.987), train_loss = 0.86924542, grad/param norm = 1.7476e-01, time/batch = 16.1650s	
7730/22750 (epoch 16.989), train_loss = 1.03491603, grad/param norm = 1.8993e-01, time/batch = 15.6038s	
7731/22750 (epoch 16.991), train_loss = 1.15291488, grad/param norm = 1.9876e-01, time/batch = 15.7654s	
7732/22750 (epoch 16.993), train_loss = 1.19527516, grad/param norm = 2.0755e-01, time/batch = 16.0138s	
7733/22750 (epoch 16.996), train_loss = 1.00941450, grad/param norm = 2.0657e-01, time/batch = 15.5326s	
7734/22750 (epoch 16.998), train_loss = 1.26038742, grad/param norm = 1.9765e-01, time/batch = 15.4822s	
decayed learning rate by a factor 0.97 to 0.0015674867188754	
7735/22750 (epoch 17.000), train_loss = 1.13750645, grad/param norm = 1.8098e-01, time/batch = 15.5442s	
7736/22750 (epoch 17.002), train_loss = 1.23805764, grad/param norm = 1.9825e-01, time/batch = 16.1099s	
7737/22750 (epoch 17.004), train_loss = 1.02199510, grad/param norm = 1.8468e-01, time/batch = 15.9507s	
7738/22750 (epoch 17.007), train_loss = 1.06213401, grad/param norm = 1.8965e-01, time/batch = 15.6102s	
7739/22750 (epoch 17.009), train_loss = 1.30281590, grad/param norm = 2.0083e-01, time/batch = 16.5651s	
7740/22750 (epoch 17.011), train_loss = 1.35876717, grad/param norm = 2.1548e-01, time/batch = 15.9168s	
7741/22750 (epoch 17.013), train_loss = 1.20631104, grad/param norm = 1.9955e-01, time/batch = 15.9290s	
7742/22750 (epoch 17.015), train_loss = 1.13655223, grad/param norm = 2.0640e-01, time/batch = 16.1625s	
7743/22750 (epoch 17.018), train_loss = 1.18614215, grad/param norm = 1.8815e-01, time/batch = 16.0807s	
7744/22750 (epoch 17.020), train_loss = 1.25356383, grad/param norm = 1.9456e-01, time/batch = 15.7050s	
7745/22750 (epoch 17.022), train_loss = 1.08658199, grad/param norm = 1.9187e-01, time/batch = 16.4076s	
7746/22750 (epoch 17.024), train_loss = 1.12075438, grad/param norm = 1.9321e-01, time/batch = 16.2277s	
7747/22750 (epoch 17.026), train_loss = 1.19311010, grad/param norm = 2.0190e-01, time/batch = 16.1727s	
7748/22750 (epoch 17.029), train_loss = 0.91461521, grad/param norm = 1.7136e-01, time/batch = 16.0796s	
7749/22750 (epoch 17.031), train_loss = 1.36169251, grad/param norm = 1.9016e-01, time/batch = 15.8506s	
7750/22750 (epoch 17.033), train_loss = 1.12300820, grad/param norm = 1.8371e-01, time/batch = 15.7686s	
7751/22750 (epoch 17.035), train_loss = 1.16466115, grad/param norm = 1.9086e-01, time/batch = 15.9290s	
7752/22750 (epoch 17.037), train_loss = 1.23757668, grad/param norm = 1.8669e-01, time/batch = 15.3686s	
7753/22750 (epoch 17.040), train_loss = 1.06629040, grad/param norm = 1.9863e-01, time/batch = 15.4568s	
7754/22750 (epoch 17.042), train_loss = 1.18669489, grad/param norm = 1.9918e-01, time/batch = 15.5432s	
7755/22750 (epoch 17.044), train_loss = 1.06487706, grad/param norm = 1.8437e-01, time/batch = 16.1124s	
7756/22750 (epoch 17.046), train_loss = 1.23653202, grad/param norm = 2.1839e-01, time/batch = 15.4022s	
7757/22750 (epoch 17.048), train_loss = 1.08442373, grad/param norm = 1.8451e-01, time/batch = 15.5652s	
7758/22750 (epoch 17.051), train_loss = 1.17131970, grad/param norm = 1.8545e-01, time/batch = 15.8623s	
7759/22750 (epoch 17.053), train_loss = 1.00461437, grad/param norm = 1.6763e-01, time/batch = 15.6954s	
7760/22750 (epoch 17.055), train_loss = 1.02555676, grad/param norm = 1.8289e-01, time/batch = 15.3697s	
7761/22750 (epoch 17.057), train_loss = 1.27758536, grad/param norm = 1.8399e-01, time/batch = 16.2483s	
7762/22750 (epoch 17.059), train_loss = 0.83235070, grad/param norm = 1.7736e-01, time/batch = 15.6305s	
7763/22750 (epoch 17.062), train_loss = 0.95261738, grad/param norm = 1.8268e-01, time/batch = 15.6308s	
7764/22750 (epoch 17.064), train_loss = 1.15948894, grad/param norm = 2.0130e-01, time/batch = 15.7843s	
7765/22750 (epoch 17.066), train_loss = 0.94831907, grad/param norm = 1.6984e-01, time/batch = 15.1617s	
7766/22750 (epoch 17.068), train_loss = 1.02334395, grad/param norm = 1.6872e-01, time/batch = 15.8035s	
7767/22750 (epoch 17.070), train_loss = 0.85268764, grad/param norm = 1.6268e-01, time/batch = 15.2422s	
7768/22750 (epoch 17.073), train_loss = 1.02475472, grad/param norm = 1.8475e-01, time/batch = 15.6355s	
7769/22750 (epoch 17.075), train_loss = 1.06150104, grad/param norm = 1.7601e-01, time/batch = 15.3902s	
7770/22750 (epoch 17.077), train_loss = 0.84556922, grad/param norm = 1.9343e-01, time/batch = 16.1864s	
7771/22750 (epoch 17.079), train_loss = 1.06505524, grad/param norm = 2.1898e-01, time/batch = 15.6189s	
7772/22750 (epoch 17.081), train_loss = 1.04963518, grad/param norm = 1.8938e-01, time/batch = 15.5368s	
7773/22750 (epoch 17.084), train_loss = 1.02328576, grad/param norm = 1.7721e-01, time/batch = 15.7007s	
7774/22750 (epoch 17.086), train_loss = 1.06020404, grad/param norm = 1.6689e-01, time/batch = 29.2049s	
7775/22750 (epoch 17.088), train_loss = 1.00868107, grad/param norm = 1.9031e-01, time/batch = 15.7012s	
7776/22750 (epoch 17.090), train_loss = 0.98889367, grad/param norm = 1.7256e-01, time/batch = 15.6188s	
7777/22750 (epoch 17.092), train_loss = 1.22099544, grad/param norm = 1.8141e-01, time/batch = 16.2796s	
7778/22750 (epoch 17.095), train_loss = 0.97539777, grad/param norm = 1.8054e-01, time/batch = 16.0145s	
7779/22750 (epoch 17.097), train_loss = 1.06469498, grad/param norm = 1.8244e-01, time/batch = 16.1705s	
7780/22750 (epoch 17.099), train_loss = 1.08872692, grad/param norm = 2.0226e-01, time/batch = 15.8431s	
7781/22750 (epoch 17.101), train_loss = 0.96258710, grad/param norm = 1.8024e-01, time/batch = 16.0868s	
7782/22750 (epoch 17.103), train_loss = 1.07463369, grad/param norm = 1.8192e-01, time/batch = 16.1776s	
7783/22750 (epoch 17.105), train_loss = 1.31655069, grad/param norm = 2.0857e-01, time/batch = 15.7598s	
7784/22750 (epoch 17.108), train_loss = 1.04447252, grad/param norm = 1.8859e-01, time/batch = 15.9190s	
7785/22750 (epoch 17.110), train_loss = 1.21742474, grad/param norm = 1.8391e-01, time/batch = 15.7935s	
7786/22750 (epoch 17.112), train_loss = 0.90629804, grad/param norm = 1.6175e-01, time/batch = 15.5443s	
7787/22750 (epoch 17.114), train_loss = 0.85799628, grad/param norm = 1.7566e-01, time/batch = 16.4750s	
7788/22750 (epoch 17.116), train_loss = 0.97684026, grad/param norm = 1.6861e-01, time/batch = 16.3491s	
7789/22750 (epoch 17.119), train_loss = 0.98337080, grad/param norm = 1.6168e-01, time/batch = 16.2477s	
7790/22750 (epoch 17.121), train_loss = 1.12397911, grad/param norm = 2.1111e-01, time/batch = 15.5249s	
7791/22750 (epoch 17.123), train_loss = 0.96525004, grad/param norm = 1.7104e-01, time/batch = 15.7733s	
7792/22750 (epoch 17.125), train_loss = 1.25376347, grad/param norm = 1.9566e-01, time/batch = 15.7624s	
7793/22750 (epoch 17.127), train_loss = 1.05083243, grad/param norm = 1.9090e-01, time/batch = 15.2794s	
7794/22750 (epoch 17.130), train_loss = 1.09034354, grad/param norm = 1.7090e-01, time/batch = 15.6900s	
7795/22750 (epoch 17.132), train_loss = 1.02718576, grad/param norm = 1.9901e-01, time/batch = 15.6958s	
7796/22750 (epoch 17.134), train_loss = 1.02981861, grad/param norm = 1.7427e-01, time/batch = 15.5432s	
7797/22750 (epoch 17.136), train_loss = 0.90874218, grad/param norm = 1.9192e-01, time/batch = 15.7873s	
7798/22750 (epoch 17.138), train_loss = 1.13387490, grad/param norm = 2.0054e-01, time/batch = 15.4652s	
7799/22750 (epoch 17.141), train_loss = 1.09234068, grad/param norm = 1.9735e-01, time/batch = 15.8678s	
7800/22750 (epoch 17.143), train_loss = 0.94406926, grad/param norm = 1.7032e-01, time/batch = 15.8492s	
7801/22750 (epoch 17.145), train_loss = 1.23816925, grad/param norm = 1.8715e-01, time/batch = 16.0933s	
7802/22750 (epoch 17.147), train_loss = 1.21778395, grad/param norm = 1.8874e-01, time/batch = 15.6963s	
7803/22750 (epoch 17.149), train_loss = 1.08580072, grad/param norm = 1.8292e-01, time/batch = 16.4003s	
7804/22750 (epoch 17.152), train_loss = 1.08001871, grad/param norm = 1.9122e-01, time/batch = 15.6136s	
7805/22750 (epoch 17.154), train_loss = 0.89461172, grad/param norm = 1.7414e-01, time/batch = 15.7726s	
7806/22750 (epoch 17.156), train_loss = 0.92946300, grad/param norm = 1.7976e-01, time/batch = 15.6226s	
7807/22750 (epoch 17.158), train_loss = 1.00932163, grad/param norm = 1.9205e-01, time/batch = 15.7829s	
7808/22750 (epoch 17.160), train_loss = 1.12165341, grad/param norm = 1.9612e-01, time/batch = 15.3034s	
7809/22750 (epoch 17.163), train_loss = 1.31459204, grad/param norm = 2.0873e-01, time/batch = 15.3774s	
7810/22750 (epoch 17.165), train_loss = 1.14824332, grad/param norm = 2.0731e-01, time/batch = 15.7002s	
7811/22750 (epoch 17.167), train_loss = 1.03489174, grad/param norm = 2.0115e-01, time/batch = 17.0174s	
7812/22750 (epoch 17.169), train_loss = 1.08423845, grad/param norm = 1.9873e-01, time/batch = 15.5099s	
7813/22750 (epoch 17.171), train_loss = 0.96627077, grad/param norm = 1.8905e-01, time/batch = 15.5332s	
7814/22750 (epoch 17.174), train_loss = 0.91202605, grad/param norm = 1.8353e-01, time/batch = 15.9158s	
7815/22750 (epoch 17.176), train_loss = 1.01280837, grad/param norm = 1.8262e-01, time/batch = 15.7694s	
7816/22750 (epoch 17.178), train_loss = 1.02554418, grad/param norm = 1.8344e-01, time/batch = 15.9349s	
7817/22750 (epoch 17.180), train_loss = 1.16781628, grad/param norm = 2.1220e-01, time/batch = 16.5447s	
7818/22750 (epoch 17.182), train_loss = 1.21311552, grad/param norm = 2.1177e-01, time/batch = 15.8729s	
7819/22750 (epoch 17.185), train_loss = 1.23098715, grad/param norm = 1.9402e-01, time/batch = 15.8787s	
7820/22750 (epoch 17.187), train_loss = 0.97941603, grad/param norm = 1.8885e-01, time/batch = 16.1715s	
7821/22750 (epoch 17.189), train_loss = 1.01381877, grad/param norm = 1.9126e-01, time/batch = 15.8400s	
7822/22750 (epoch 17.191), train_loss = 0.97953771, grad/param norm = 1.6502e-01, time/batch = 16.3997s	
7823/22750 (epoch 17.193), train_loss = 1.15661264, grad/param norm = 1.8611e-01, time/batch = 16.1791s	
7824/22750 (epoch 17.196), train_loss = 1.04406871, grad/param norm = 1.8336e-01, time/batch = 16.0575s	
7825/22750 (epoch 17.198), train_loss = 0.81141729, grad/param norm = 1.4775e-01, time/batch = 16.0839s	
7826/22750 (epoch 17.200), train_loss = 1.09748743, grad/param norm = 1.7863e-01, time/batch = 16.0189s	
7827/22750 (epoch 17.202), train_loss = 1.18788632, grad/param norm = 2.0436e-01, time/batch = 15.7731s	
7828/22750 (epoch 17.204), train_loss = 1.09059671, grad/param norm = 1.7069e-01, time/batch = 15.5607s	
7829/22750 (epoch 17.207), train_loss = 1.04275725, grad/param norm = 1.7301e-01, time/batch = 16.0245s	
7830/22750 (epoch 17.209), train_loss = 0.99377469, grad/param norm = 1.8907e-01, time/batch = 15.5418s	
7831/22750 (epoch 17.211), train_loss = 1.01157819, grad/param norm = 1.9503e-01, time/batch = 15.8484s	
7832/22750 (epoch 17.213), train_loss = 0.90075736, grad/param norm = 1.7290e-01, time/batch = 15.4362s	
7833/22750 (epoch 17.215), train_loss = 0.83573893, grad/param norm = 1.6840e-01, time/batch = 16.1760s	
7834/22750 (epoch 17.218), train_loss = 0.93188482, grad/param norm = 1.9198e-01, time/batch = 15.8562s	
7835/22750 (epoch 17.220), train_loss = 0.93387563, grad/param norm = 1.8168e-01, time/batch = 16.0894s	
7836/22750 (epoch 17.222), train_loss = 0.89743757, grad/param norm = 1.8403e-01, time/batch = 16.0665s	
7837/22750 (epoch 17.224), train_loss = 0.96689220, grad/param norm = 1.8008e-01, time/batch = 16.2369s	
7838/22750 (epoch 17.226), train_loss = 1.15272787, grad/param norm = 2.0253e-01, time/batch = 16.0264s	
7839/22750 (epoch 17.229), train_loss = 1.09995595, grad/param norm = 1.8543e-01, time/batch = 16.0139s	
7840/22750 (epoch 17.231), train_loss = 0.99721884, grad/param norm = 1.8513e-01, time/batch = 15.5525s	
7841/22750 (epoch 17.233), train_loss = 0.93451875, grad/param norm = 2.2186e-01, time/batch = 16.1136s	
7842/22750 (epoch 17.235), train_loss = 0.88608465, grad/param norm = 1.9530e-01, time/batch = 15.6118s	
7843/22750 (epoch 17.237), train_loss = 0.98953406, grad/param norm = 1.9675e-01, time/batch = 15.4391s	
7844/22750 (epoch 17.240), train_loss = 1.04598647, grad/param norm = 1.7433e-01, time/batch = 16.2506s	
7845/22750 (epoch 17.242), train_loss = 1.31068308, grad/param norm = 2.1468e-01, time/batch = 16.2328s	
7846/22750 (epoch 17.244), train_loss = 1.20110734, grad/param norm = 1.9286e-01, time/batch = 15.5092s	
7847/22750 (epoch 17.246), train_loss = 1.27522100, grad/param norm = 2.1034e-01, time/batch = 15.5259s	
7848/22750 (epoch 17.248), train_loss = 1.04452584, grad/param norm = 2.1171e-01, time/batch = 15.9440s	
7849/22750 (epoch 17.251), train_loss = 1.23254040, grad/param norm = 1.8942e-01, time/batch = 15.6515s	
7850/22750 (epoch 17.253), train_loss = 1.10424579, grad/param norm = 2.0607e-01, time/batch = 15.6378s	
7851/22750 (epoch 17.255), train_loss = 1.07697711, grad/param norm = 1.8191e-01, time/batch = 15.8540s	
7852/22750 (epoch 17.257), train_loss = 0.99837383, grad/param norm = 1.8856e-01, time/batch = 15.7829s	
7853/22750 (epoch 17.259), train_loss = 1.21759418, grad/param norm = 2.3096e-01, time/batch = 15.5342s	
7854/22750 (epoch 17.262), train_loss = 1.05797882, grad/param norm = 1.7808e-01, time/batch = 15.6192s	
7855/22750 (epoch 17.264), train_loss = 0.90592319, grad/param norm = 1.8188e-01, time/batch = 15.5464s	
7856/22750 (epoch 17.266), train_loss = 1.10240122, grad/param norm = 2.1671e-01, time/batch = 15.9378s	
7857/22750 (epoch 17.268), train_loss = 1.24357848, grad/param norm = 2.1201e-01, time/batch = 15.6955s	
7858/22750 (epoch 17.270), train_loss = 0.99440821, grad/param norm = 2.0778e-01, time/batch = 15.7086s	
7859/22750 (epoch 17.273), train_loss = 1.37282947, grad/param norm = 2.2502e-01, time/batch = 15.7977s	
7860/22750 (epoch 17.275), train_loss = 1.19099624, grad/param norm = 1.9262e-01, time/batch = 15.7959s	
7861/22750 (epoch 17.277), train_loss = 1.03549082, grad/param norm = 2.1554e-01, time/batch = 15.2500s	
7862/22750 (epoch 17.279), train_loss = 0.92666886, grad/param norm = 1.9933e-01, time/batch = 15.3923s	
7863/22750 (epoch 17.281), train_loss = 1.22098312, grad/param norm = 2.0713e-01, time/batch = 16.0960s	
7864/22750 (epoch 17.284), train_loss = 1.04939419, grad/param norm = 1.7809e-01, time/batch = 16.3007s	
7865/22750 (epoch 17.286), train_loss = 1.22474904, grad/param norm = 2.0735e-01, time/batch = 15.6282s	
7866/22750 (epoch 17.288), train_loss = 1.26499681, grad/param norm = 2.0542e-01, time/batch = 15.6105s	
7867/22750 (epoch 17.290), train_loss = 1.10368987, grad/param norm = 2.0248e-01, time/batch = 16.1796s	
7868/22750 (epoch 17.292), train_loss = 1.15768757, grad/param norm = 2.1004e-01, time/batch = 15.5415s	
7869/22750 (epoch 17.295), train_loss = 1.13760673, grad/param norm = 1.8673e-01, time/batch = 15.5503s	
7870/22750 (epoch 17.297), train_loss = 1.03355351, grad/param norm = 1.7948e-01, time/batch = 16.1314s	
7871/22750 (epoch 17.299), train_loss = 1.21599675, grad/param norm = 2.0429e-01, time/batch = 15.8120s	
7872/22750 (epoch 17.301), train_loss = 1.11833137, grad/param norm = 1.9791e-01, time/batch = 15.4854s	
7873/22750 (epoch 17.303), train_loss = 1.19153052, grad/param norm = 1.9943e-01, time/batch = 15.5531s	
7874/22750 (epoch 17.305), train_loss = 1.29918383, grad/param norm = 1.8828e-01, time/batch = 15.7758s	
7875/22750 (epoch 17.308), train_loss = 1.13739797, grad/param norm = 1.6893e-01, time/batch = 15.7061s	
7876/22750 (epoch 17.310), train_loss = 0.97811415, grad/param norm = 1.9775e-01, time/batch = 15.8702s	
7877/22750 (epoch 17.312), train_loss = 1.12123019, grad/param norm = 1.9163e-01, time/batch = 15.6256s	
7878/22750 (epoch 17.314), train_loss = 1.10482184, grad/param norm = 1.8667e-01, time/batch = 15.7729s	
7879/22750 (epoch 17.316), train_loss = 1.04909002, grad/param norm = 1.9477e-01, time/batch = 15.7747s	
7880/22750 (epoch 17.319), train_loss = 1.11887975, grad/param norm = 2.0306e-01, time/batch = 15.7733s	
7881/22750 (epoch 17.321), train_loss = 1.03861199, grad/param norm = 1.9120e-01, time/batch = 15.5616s	
7882/22750 (epoch 17.323), train_loss = 1.08974377, grad/param norm = 2.0558e-01, time/batch = 15.8880s	
7883/22750 (epoch 17.325), train_loss = 0.91603025, grad/param norm = 1.9336e-01, time/batch = 15.8065s	
7884/22750 (epoch 17.327), train_loss = 1.08187209, grad/param norm = 2.0314e-01, time/batch = 15.8641s	
7885/22750 (epoch 17.330), train_loss = 1.33789073, grad/param norm = 2.1018e-01, time/batch = 16.5705s	
7886/22750 (epoch 17.332), train_loss = 1.30821621, grad/param norm = 1.9469e-01, time/batch = 16.5670s	
7887/22750 (epoch 17.334), train_loss = 0.89788342, grad/param norm = 1.8817e-01, time/batch = 16.4216s	
7888/22750 (epoch 17.336), train_loss = 1.16493232, grad/param norm = 1.9313e-01, time/batch = 16.3443s	
7889/22750 (epoch 17.338), train_loss = 1.05259082, grad/param norm = 1.8704e-01, time/batch = 16.1057s	
7890/22750 (epoch 17.341), train_loss = 1.07623850, grad/param norm = 1.8982e-01, time/batch = 16.6600s	
7891/22750 (epoch 17.343), train_loss = 0.93049429, grad/param norm = 1.8695e-01, time/batch = 16.3417s	
7892/22750 (epoch 17.345), train_loss = 1.21999004, grad/param norm = 2.1149e-01, time/batch = 16.4837s	
7893/22750 (epoch 17.347), train_loss = 1.26434521, grad/param norm = 2.1159e-01, time/batch = 16.4999s	
7894/22750 (epoch 17.349), train_loss = 0.87048986, grad/param norm = 2.0178e-01, time/batch = 15.8572s	
7895/22750 (epoch 17.352), train_loss = 1.18414304, grad/param norm = 1.9241e-01, time/batch = 16.0012s	
7896/22750 (epoch 17.354), train_loss = 1.21308698, grad/param norm = 1.9668e-01, time/batch = 15.8447s	
7897/22750 (epoch 17.356), train_loss = 1.23107324, grad/param norm = 2.0960e-01, time/batch = 16.1758s	
7898/22750 (epoch 17.358), train_loss = 1.09012093, grad/param norm = 2.0126e-01, time/batch = 15.8487s	
7899/22750 (epoch 17.360), train_loss = 1.28860946, grad/param norm = 1.8926e-01, time/batch = 15.6073s	
7900/22750 (epoch 17.363), train_loss = 1.05225212, grad/param norm = 1.7919e-01, time/batch = 15.6071s	
7901/22750 (epoch 17.365), train_loss = 0.87492321, grad/param norm = 1.7487e-01, time/batch = 16.1909s	
7902/22750 (epoch 17.367), train_loss = 0.95651851, grad/param norm = 2.1271e-01, time/batch = 15.5576s	
7903/22750 (epoch 17.369), train_loss = 1.09148488, grad/param norm = 1.9380e-01, time/batch = 15.6371s	
7904/22750 (epoch 17.371), train_loss = 1.03775093, grad/param norm = 1.8154e-01, time/batch = 15.9576s	
7905/22750 (epoch 17.374), train_loss = 0.98745492, grad/param norm = 1.8326e-01, time/batch = 15.9289s	
7906/22750 (epoch 17.376), train_loss = 1.03570603, grad/param norm = 1.8159e-01, time/batch = 16.1577s	
7907/22750 (epoch 17.378), train_loss = 1.11323824, grad/param norm = 1.9314e-01, time/batch = 15.5273s	
7908/22750 (epoch 17.380), train_loss = 1.23113452, grad/param norm = 2.0286e-01, time/batch = 16.0066s	
7909/22750 (epoch 17.382), train_loss = 1.02699611, grad/param norm = 1.7609e-01, time/batch = 15.6893s	
7910/22750 (epoch 17.385), train_loss = 1.16724714, grad/param norm = 1.8453e-01, time/batch = 15.9282s	
7911/22750 (epoch 17.387), train_loss = 1.13057421, grad/param norm = 1.8371e-01, time/batch = 15.6187s	
7912/22750 (epoch 17.389), train_loss = 0.85913377, grad/param norm = 1.7497e-01, time/batch = 16.1221s	
7913/22750 (epoch 17.391), train_loss = 0.67784548, grad/param norm = 1.4967e-01, time/batch = 15.7949s	
7914/22750 (epoch 17.393), train_loss = 0.93571602, grad/param norm = 1.7326e-01, time/batch = 15.7822s	
7915/22750 (epoch 17.396), train_loss = 1.11302685, grad/param norm = 1.9195e-01, time/batch = 15.5591s	
7916/22750 (epoch 17.398), train_loss = 1.04084113, grad/param norm = 1.8476e-01, time/batch = 16.6338s	
7917/22750 (epoch 17.400), train_loss = 1.06255032, grad/param norm = 1.7705e-01, time/batch = 15.5986s	
7918/22750 (epoch 17.402), train_loss = 1.14652702, grad/param norm = 1.9071e-01, time/batch = 15.9344s	
7919/22750 (epoch 17.404), train_loss = 1.24432015, grad/param norm = 2.0209e-01, time/batch = 15.8570s	
7920/22750 (epoch 17.407), train_loss = 1.19469789, grad/param norm = 1.9105e-01, time/batch = 16.0214s	
7921/22750 (epoch 17.409), train_loss = 1.06188657, grad/param norm = 1.8155e-01, time/batch = 16.2572s	
7922/22750 (epoch 17.411), train_loss = 1.05597966, grad/param norm = 1.7645e-01, time/batch = 15.7009s	
7923/22750 (epoch 17.413), train_loss = 0.84223480, grad/param norm = 1.7549e-01, time/batch = 16.5718s	
7924/22750 (epoch 17.415), train_loss = 0.82208831, grad/param norm = 1.6254e-01, time/batch = 16.3236s	
7925/22750 (epoch 17.418), train_loss = 1.02474420, grad/param norm = 1.8894e-01, time/batch = 15.6222s	
7926/22750 (epoch 17.420), train_loss = 1.18452792, grad/param norm = 2.5418e-01, time/batch = 15.4567s	
7927/22750 (epoch 17.422), train_loss = 1.31578156, grad/param norm = 2.3136e-01, time/batch = 16.0124s	
7928/22750 (epoch 17.424), train_loss = 1.31525318, grad/param norm = 2.4189e-01, time/batch = 15.4505s	
7929/22750 (epoch 17.426), train_loss = 1.29306608, grad/param norm = 1.9689e-01, time/batch = 15.3609s	
7930/22750 (epoch 17.429), train_loss = 0.95001137, grad/param norm = 1.9713e-01, time/batch = 15.6859s	
7931/22750 (epoch 17.431), train_loss = 0.91031105, grad/param norm = 1.8816e-01, time/batch = 16.0222s	
7932/22750 (epoch 17.433), train_loss = 1.00841832, grad/param norm = 1.7696e-01, time/batch = 16.1692s	
7933/22750 (epoch 17.435), train_loss = 0.83035408, grad/param norm = 1.6910e-01, time/batch = 16.0108s	
7934/22750 (epoch 17.437), train_loss = 0.73700179, grad/param norm = 1.7442e-01, time/batch = 15.7922s	
7935/22750 (epoch 17.440), train_loss = 1.09668551, grad/param norm = 1.9201e-01, time/batch = 16.3439s	
7936/22750 (epoch 17.442), train_loss = 1.12225078, grad/param norm = 2.2453e-01, time/batch = 15.9375s	
7937/22750 (epoch 17.444), train_loss = 1.05466692, grad/param norm = 2.1171e-01, time/batch = 15.2134s	
7938/22750 (epoch 17.446), train_loss = 1.08078091, grad/param norm = 2.0988e-01, time/batch = 15.6835s	
7939/22750 (epoch 17.448), train_loss = 1.36829623, grad/param norm = 2.0951e-01, time/batch = 15.8369s	
7940/22750 (epoch 17.451), train_loss = 1.26918674, grad/param norm = 2.0359e-01, time/batch = 15.8495s	
7941/22750 (epoch 17.453), train_loss = 1.27812998, grad/param norm = 2.0105e-01, time/batch = 15.6923s	
7942/22750 (epoch 17.455), train_loss = 1.37193440, grad/param norm = 2.1559e-01, time/batch = 16.4095s	
7943/22750 (epoch 17.457), train_loss = 1.20661721, grad/param norm = 2.5880e-01, time/batch = 15.6008s	
7944/22750 (epoch 17.459), train_loss = 1.19818186, grad/param norm = 1.9995e-01, time/batch = 15.5420s	
7945/22750 (epoch 17.462), train_loss = 1.16986554, grad/param norm = 1.8234e-01, time/batch = 15.8699s	
7946/22750 (epoch 17.464), train_loss = 0.92171318, grad/param norm = 1.9180e-01, time/batch = 15.9569s	
7947/22750 (epoch 17.466), train_loss = 1.28901206, grad/param norm = 2.2591e-01, time/batch = 16.4254s	
7948/22750 (epoch 17.468), train_loss = 1.06423234, grad/param norm = 1.9804e-01, time/batch = 15.9775s	
7949/22750 (epoch 17.470), train_loss = 1.22335754, grad/param norm = 1.9626e-01, time/batch = 16.1032s	
7950/22750 (epoch 17.473), train_loss = 1.08657269, grad/param norm = 1.9944e-01, time/batch = 16.2514s	
7951/22750 (epoch 17.475), train_loss = 1.11934569, grad/param norm = 2.1299e-01, time/batch = 16.4085s	
7952/22750 (epoch 17.477), train_loss = 0.92979361, grad/param norm = 1.7840e-01, time/batch = 15.4436s	
7953/22750 (epoch 17.479), train_loss = 0.92655546, grad/param norm = 1.8982e-01, time/batch = 16.1767s	
7954/22750 (epoch 17.481), train_loss = 0.85770107, grad/param norm = 1.6108e-01, time/batch = 15.5442s	
7955/22750 (epoch 17.484), train_loss = 0.79686103, grad/param norm = 1.8886e-01, time/batch = 15.7926s	
7956/22750 (epoch 17.486), train_loss = 0.93192645, grad/param norm = 1.9478e-01, time/batch = 15.4010s	
7957/22750 (epoch 17.488), train_loss = 0.81362207, grad/param norm = 1.8622e-01, time/batch = 15.8730s	
7958/22750 (epoch 17.490), train_loss = 1.09551012, grad/param norm = 1.8258e-01, time/batch = 15.6242s	
7959/22750 (epoch 17.492), train_loss = 1.22609161, grad/param norm = 2.1616e-01, time/batch = 15.7650s	
7960/22750 (epoch 17.495), train_loss = 0.96872584, grad/param norm = 1.7448e-01, time/batch = 15.1139s	
7961/22750 (epoch 17.497), train_loss = 1.08622628, grad/param norm = 2.0784e-01, time/batch = 16.4179s	
7962/22750 (epoch 17.499), train_loss = 0.98369967, grad/param norm = 1.8708e-01, time/batch = 15.4563s	
7963/22750 (epoch 17.501), train_loss = 1.07280248, grad/param norm = 1.8761e-01, time/batch = 15.9219s	
7964/22750 (epoch 17.503), train_loss = 1.08917106, grad/param norm = 1.9214e-01, time/batch = 15.4561s	
7965/22750 (epoch 17.505), train_loss = 0.92708485, grad/param norm = 1.7769e-01, time/batch = 16.3160s	
7966/22750 (epoch 17.508), train_loss = 0.89272900, grad/param norm = 1.8353e-01, time/batch = 15.4675s	
7967/22750 (epoch 17.510), train_loss = 0.90828499, grad/param norm = 1.6328e-01, time/batch = 15.5424s	
7968/22750 (epoch 17.512), train_loss = 0.94573187, grad/param norm = 1.6900e-01, time/batch = 15.6325s	
7969/22750 (epoch 17.514), train_loss = 1.00558795, grad/param norm = 1.9270e-01, time/batch = 15.6976s	
7970/22750 (epoch 17.516), train_loss = 0.98565185, grad/param norm = 1.8727e-01, time/batch = 15.9281s	
7971/22750 (epoch 17.519), train_loss = 1.15648568, grad/param norm = 1.9476e-01, time/batch = 16.0065s	
7972/22750 (epoch 17.521), train_loss = 1.07362287, grad/param norm = 1.9082e-01, time/batch = 16.1763s	
7973/22750 (epoch 17.523), train_loss = 1.02815462, grad/param norm = 2.0133e-01, time/batch = 15.7760s	
7974/22750 (epoch 17.525), train_loss = 1.23136909, grad/param norm = 2.1879e-01, time/batch = 15.1968s	
7975/22750 (epoch 17.527), train_loss = 1.07309623, grad/param norm = 1.9107e-01, time/batch = 15.2856s	
7976/22750 (epoch 17.530), train_loss = 0.99714007, grad/param norm = 1.9713e-01, time/batch = 15.7087s	
7977/22750 (epoch 17.532), train_loss = 0.90585020, grad/param norm = 1.6240e-01, time/batch = 19.2823s	
7978/22750 (epoch 17.534), train_loss = 1.16040331, grad/param norm = 1.9295e-01, time/batch = 15.7945s	
7979/22750 (epoch 17.536), train_loss = 1.10012411, grad/param norm = 1.7693e-01, time/batch = 16.1232s	
7980/22750 (epoch 17.538), train_loss = 1.08345907, grad/param norm = 1.7936e-01, time/batch = 3.5988s	
7981/22750 (epoch 17.541), train_loss = 0.92091791, grad/param norm = 1.7519e-01, time/batch = 0.7042s	
7982/22750 (epoch 17.543), train_loss = 0.93483942, grad/param norm = 1.7925e-01, time/batch = 0.7034s	
7983/22750 (epoch 17.545), train_loss = 1.17864137, grad/param norm = 1.8975e-01, time/batch = 0.7042s	
7984/22750 (epoch 17.547), train_loss = 0.97636042, grad/param norm = 1.6715e-01, time/batch = 0.6988s	
7985/22750 (epoch 17.549), train_loss = 1.01268363, grad/param norm = 1.8678e-01, time/batch = 0.7022s	
7986/22750 (epoch 17.552), train_loss = 1.13635518, grad/param norm = 2.0277e-01, time/batch = 0.7030s	
7987/22750 (epoch 17.554), train_loss = 1.15571411, grad/param norm = 2.0628e-01, time/batch = 0.9326s	
7988/22750 (epoch 17.556), train_loss = 1.06636439, grad/param norm = 1.8981e-01, time/batch = 1.0338s	
7989/22750 (epoch 17.558), train_loss = 1.17738115, grad/param norm = 2.0220e-01, time/batch = 1.0144s	
7990/22750 (epoch 17.560), train_loss = 1.00620833, grad/param norm = 1.9661e-01, time/batch = 1.0508s	
7991/22750 (epoch 17.563), train_loss = 1.18525378, grad/param norm = 1.9455e-01, time/batch = 1.0585s	
7992/22750 (epoch 17.565), train_loss = 1.13143829, grad/param norm = 2.0617e-01, time/batch = 1.9119s	
7993/22750 (epoch 17.567), train_loss = 1.11447105, grad/param norm = 1.8665e-01, time/batch = 1.9238s	
7994/22750 (epoch 17.569), train_loss = 1.04702653, grad/param norm = 1.8851e-01, time/batch = 7.4550s	
7995/22750 (epoch 17.571), train_loss = 1.07988075, grad/param norm = 1.9351e-01, time/batch = 17.2433s	
7996/22750 (epoch 17.574), train_loss = 0.96962554, grad/param norm = 1.7685e-01, time/batch = 19.5712s	
7997/22750 (epoch 17.576), train_loss = 1.04723954, grad/param norm = 2.0389e-01, time/batch = 19.1507s	
7998/22750 (epoch 17.578), train_loss = 0.93368463, grad/param norm = 1.8264e-01, time/batch = 18.7359s	
7999/22750 (epoch 17.580), train_loss = 1.09496116, grad/param norm = 2.0898e-01, time/batch = 20.3545s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_wakata_epoch17.58_1.5055.t7	
8000/22750 (epoch 17.582), train_loss = 0.94080073, grad/param norm = 1.6987e-01, time/batch = 20.0177s	
8001/22750 (epoch 17.585), train_loss = 1.38078531, grad/param norm = 2.5037e-01, time/batch = 19.4945s	
8002/22750 (epoch 17.587), train_loss = 0.92094130, grad/param norm = 1.9215e-01, time/batch = 21.4346s	
8003/22750 (epoch 17.589), train_loss = 0.87732769, grad/param norm = 1.7571e-01, time/batch = 21.8839s	
8004/22750 (epoch 17.591), train_loss = 1.04243320, grad/param norm = 1.9558e-01, time/batch = 29.9873s	
8005/22750 (epoch 17.593), train_loss = 1.23286944, grad/param norm = 1.8715e-01, time/batch = 17.5814s	
8006/22750 (epoch 17.596), train_loss = 1.23044909, grad/param norm = 1.8915e-01, time/batch = 18.6357s	
8007/22750 (epoch 17.598), train_loss = 1.29172511, grad/param norm = 2.0794e-01, time/batch = 17.7584s	
8008/22750 (epoch 17.600), train_loss = 1.22273936, grad/param norm = 1.9959e-01, time/batch = 16.5621s	
8009/22750 (epoch 17.602), train_loss = 0.97312367, grad/param norm = 1.7176e-01, time/batch = 16.4065s	
8010/22750 (epoch 17.604), train_loss = 1.00754617, grad/param norm = 1.8722e-01, time/batch = 17.3510s	
8011/22750 (epoch 17.607), train_loss = 0.87292895, grad/param norm = 1.5667e-01, time/batch = 16.8604s	
8012/22750 (epoch 17.609), train_loss = 0.83515491, grad/param norm = 1.5888e-01, time/batch = 20.5323s	
8013/22750 (epoch 17.611), train_loss = 1.02369696, grad/param norm = 1.8411e-01, time/batch = 18.2682s	
8014/22750 (epoch 17.613), train_loss = 0.96471122, grad/param norm = 1.7893e-01, time/batch = 18.9175s	
8015/22750 (epoch 17.615), train_loss = 0.99004658, grad/param norm = 1.6984e-01, time/batch = 17.5977s	
8016/22750 (epoch 17.618), train_loss = 1.01407756, grad/param norm = 1.7819e-01, time/batch = 17.2617s	
8017/22750 (epoch 17.620), train_loss = 1.03678212, grad/param norm = 1.8399e-01, time/batch = 18.9225s	
8018/22750 (epoch 17.622), train_loss = 0.85473898, grad/param norm = 1.6537e-01, time/batch = 19.2447s	
8019/22750 (epoch 17.624), train_loss = 0.97109156, grad/param norm = 1.9217e-01, time/batch = 18.4939s	
8020/22750 (epoch 17.626), train_loss = 0.88136770, grad/param norm = 1.7722e-01, time/batch = 18.8370s	
8021/22750 (epoch 17.629), train_loss = 0.97660133, grad/param norm = 1.8652e-01, time/batch = 16.7229s	
8022/22750 (epoch 17.631), train_loss = 1.03292468, grad/param norm = 1.7645e-01, time/batch = 18.6823s	
8023/22750 (epoch 17.633), train_loss = 0.88597195, grad/param norm = 1.6685e-01, time/batch = 19.0743s	
8024/22750 (epoch 17.635), train_loss = 1.06430421, grad/param norm = 1.8218e-01, time/batch = 17.4013s	
8025/22750 (epoch 17.637), train_loss = 1.11604873, grad/param norm = 1.9251e-01, time/batch = 19.4143s	
8026/22750 (epoch 17.640), train_loss = 1.12156356, grad/param norm = 1.9696e-01, time/batch = 18.4994s	
8027/22750 (epoch 17.642), train_loss = 1.20583187, grad/param norm = 2.0708e-01, time/batch = 18.1716s	
8028/22750 (epoch 17.644), train_loss = 1.08056884, grad/param norm = 1.9878e-01, time/batch = 20.9120s	
8029/22750 (epoch 17.646), train_loss = 1.12424244, grad/param norm = 2.3607e-01, time/batch = 18.3564s	
8030/22750 (epoch 17.648), train_loss = 1.08379508, grad/param norm = 2.0251e-01, time/batch = 20.2849s	
8031/22750 (epoch 17.651), train_loss = 1.11483637, grad/param norm = 1.8884e-01, time/batch = 20.7573s	
8032/22750 (epoch 17.653), train_loss = 1.12137881, grad/param norm = 1.8487e-01, time/batch = 17.9121s	
8033/22750 (epoch 17.655), train_loss = 1.08681298, grad/param norm = 1.9067e-01, time/batch = 18.2647s	
8034/22750 (epoch 17.657), train_loss = 1.24837901, grad/param norm = 2.0624e-01, time/batch = 18.4256s	
8035/22750 (epoch 17.659), train_loss = 1.31569029, grad/param norm = 2.1549e-01, time/batch = 17.4498s	
8036/22750 (epoch 17.662), train_loss = 1.28895803, grad/param norm = 2.1431e-01, time/batch = 17.0628s	
8037/22750 (epoch 17.664), train_loss = 1.13022999, grad/param norm = 2.1403e-01, time/batch = 18.7504s	
8038/22750 (epoch 17.666), train_loss = 0.91475788, grad/param norm = 1.8351e-01, time/batch = 18.5945s	
8039/22750 (epoch 17.668), train_loss = 1.07771417, grad/param norm = 1.8828e-01, time/batch = 19.5297s	
8040/22750 (epoch 17.670), train_loss = 1.07978095, grad/param norm = 2.0638e-01, time/batch = 17.9242s	
8041/22750 (epoch 17.673), train_loss = 1.35406195, grad/param norm = 2.2101e-01, time/batch = 20.0670s	
8042/22750 (epoch 17.675), train_loss = 1.48640490, grad/param norm = 2.4186e-01, time/batch = 27.7038s	
8043/22750 (epoch 17.677), train_loss = 1.23796713, grad/param norm = 2.1039e-01, time/batch = 19.4857s	
8044/22750 (epoch 17.679), train_loss = 1.31615387, grad/param norm = 2.1814e-01, time/batch = 15.7164s	
8045/22750 (epoch 17.681), train_loss = 1.25059320, grad/param norm = 2.0380e-01, time/batch = 15.2794s	
8046/22750 (epoch 17.684), train_loss = 1.26710871, grad/param norm = 2.1469e-01, time/batch = 19.2700s	
8047/22750 (epoch 17.686), train_loss = 1.25929806, grad/param norm = 2.0884e-01, time/batch = 19.9438s	
8048/22750 (epoch 17.688), train_loss = 1.23510159, grad/param norm = 2.0452e-01, time/batch = 18.8649s	
8049/22750 (epoch 17.690), train_loss = 1.22917059, grad/param norm = 2.0804e-01, time/batch = 20.6566s	
8050/22750 (epoch 17.692), train_loss = 1.26387418, grad/param norm = 1.9691e-01, time/batch = 19.5792s	
8051/22750 (epoch 17.695), train_loss = 1.13085505, grad/param norm = 1.9388e-01, time/batch = 17.5550s	
8052/22750 (epoch 17.697), train_loss = 1.08816595, grad/param norm = 1.9251e-01, time/batch = 15.7421s	
8053/22750 (epoch 17.699), train_loss = 1.08104615, grad/param norm = 1.9470e-01, time/batch = 16.0001s	
8054/22750 (epoch 17.701), train_loss = 0.93669010, grad/param norm = 1.8099e-01, time/batch = 16.8484s	
8055/22750 (epoch 17.703), train_loss = 1.07864740, grad/param norm = 1.8028e-01, time/batch = 17.7690s	
8056/22750 (epoch 17.705), train_loss = 1.00194724, grad/param norm = 1.8206e-01, time/batch = 17.4383s	
8057/22750 (epoch 17.708), train_loss = 1.10106110, grad/param norm = 1.9441e-01, time/batch = 18.5913s	
8058/22750 (epoch 17.710), train_loss = 0.95155495, grad/param norm = 1.9628e-01, time/batch = 18.4288s	
8059/22750 (epoch 17.712), train_loss = 0.96432847, grad/param norm = 1.8129e-01, time/batch = 17.3344s	
8060/22750 (epoch 17.714), train_loss = 0.88168769, grad/param norm = 1.7112e-01, time/batch = 18.0058s	
8061/22750 (epoch 17.716), train_loss = 0.95512179, grad/param norm = 1.9003e-01, time/batch = 17.5747s	
8062/22750 (epoch 17.719), train_loss = 1.15122894, grad/param norm = 2.2190e-01, time/batch = 16.9900s	
8063/22750 (epoch 17.721), train_loss = 1.19532447, grad/param norm = 1.8720e-01, time/batch = 19.4838s	
8064/22750 (epoch 17.723), train_loss = 1.13777987, grad/param norm = 2.0592e-01, time/batch = 17.8424s	
8065/22750 (epoch 17.725), train_loss = 1.06766608, grad/param norm = 2.0975e-01, time/batch = 17.5448s	
8066/22750 (epoch 17.727), train_loss = 1.01674241, grad/param norm = 1.7213e-01, time/batch = 20.6854s	
8067/22750 (epoch 17.730), train_loss = 1.02970726, grad/param norm = 2.0468e-01, time/batch = 19.2537s	
8068/22750 (epoch 17.732), train_loss = 0.96939609, grad/param norm = 1.7223e-01, time/batch = 18.4132s	
8069/22750 (epoch 17.734), train_loss = 0.84485511, grad/param norm = 1.6041e-01, time/batch = 19.1609s	
8070/22750 (epoch 17.736), train_loss = 0.99436049, grad/param norm = 1.8161e-01, time/batch = 19.2445s	
8071/22750 (epoch 17.738), train_loss = 1.11649669, grad/param norm = 2.0934e-01, time/batch = 18.3220s	
8072/22750 (epoch 17.741), train_loss = 1.18904844, grad/param norm = 1.9857e-01, time/batch = 20.0777s	
8073/22750 (epoch 17.743), train_loss = 1.12597814, grad/param norm = 1.8201e-01, time/batch = 19.4965s	
8074/22750 (epoch 17.745), train_loss = 0.94264573, grad/param norm = 1.7455e-01, time/batch = 19.6567s	
8075/22750 (epoch 17.747), train_loss = 0.99456754, grad/param norm = 1.7316e-01, time/batch = 18.8519s	
8076/22750 (epoch 17.749), train_loss = 1.26163562, grad/param norm = 2.1559e-01, time/batch = 19.7424s	
8077/22750 (epoch 17.752), train_loss = 1.05016333, grad/param norm = 1.9384e-01, time/batch = 17.6646s	
8078/22750 (epoch 17.754), train_loss = 1.10575009, grad/param norm = 2.0298e-01, time/batch = 18.6716s	
8079/22750 (epoch 17.756), train_loss = 0.95455206, grad/param norm = 2.0148e-01, time/batch = 15.7028s	
8080/22750 (epoch 17.758), train_loss = 0.94717306, grad/param norm = 1.8191e-01, time/batch = 16.4999s	
8081/22750 (epoch 17.760), train_loss = 1.03785421, grad/param norm = 1.9074e-01, time/batch = 19.3266s	
8082/22750 (epoch 17.763), train_loss = 1.11249178, grad/param norm = 1.9792e-01, time/batch = 19.2626s	
8083/22750 (epoch 17.765), train_loss = 1.07337581, grad/param norm = 2.0981e-01, time/batch = 17.2666s	
8084/22750 (epoch 17.767), train_loss = 1.12812490, grad/param norm = 2.0910e-01, time/batch = 18.6806s	
8085/22750 (epoch 17.769), train_loss = 1.32873064, grad/param norm = 2.2031e-01, time/batch = 17.7571s	
8086/22750 (epoch 17.771), train_loss = 1.23504209, grad/param norm = 2.1402e-01, time/batch = 19.0099s	
8087/22750 (epoch 17.774), train_loss = 1.03959625, grad/param norm = 2.1940e-01, time/batch = 18.0918s	
8088/22750 (epoch 17.776), train_loss = 1.12509508, grad/param norm = 2.1222e-01, time/batch = 16.1510s	
8089/22750 (epoch 17.778), train_loss = 1.26206816, grad/param norm = 1.9337e-01, time/batch = 17.0998s	
8090/22750 (epoch 17.780), train_loss = 1.09571628, grad/param norm = 1.9276e-01, time/batch = 16.6092s	
8091/22750 (epoch 17.782), train_loss = 1.24762758, grad/param norm = 2.0690e-01, time/batch = 17.6724s	
8092/22750 (epoch 17.785), train_loss = 1.07674871, grad/param norm = 1.9359e-01, time/batch = 17.2701s	
8093/22750 (epoch 17.787), train_loss = 0.97656562, grad/param norm = 1.9262e-01, time/batch = 17.6881s	
8094/22750 (epoch 17.789), train_loss = 1.04974844, grad/param norm = 1.8403e-01, time/batch = 17.3663s	
8095/22750 (epoch 17.791), train_loss = 1.04500035, grad/param norm = 1.8697e-01, time/batch = 18.1670s	
8096/22750 (epoch 17.793), train_loss = 0.96818448, grad/param norm = 1.7907e-01, time/batch = 17.5751s	
8097/22750 (epoch 17.796), train_loss = 0.88702119, grad/param norm = 1.7250e-01, time/batch = 18.4891s	
8098/22750 (epoch 17.798), train_loss = 0.94553481, grad/param norm = 1.7075e-01, time/batch = 17.5957s	
8099/22750 (epoch 17.800), train_loss = 0.99734125, grad/param norm = 1.9807e-01, time/batch = 20.4089s	
8100/22750 (epoch 17.802), train_loss = 0.92032586, grad/param norm = 1.8261e-01, time/batch = 18.1666s	
8101/22750 (epoch 17.804), train_loss = 1.24054996, grad/param norm = 1.9987e-01, time/batch = 20.7703s	
8102/22750 (epoch 17.807), train_loss = 1.14299876, grad/param norm = 1.9311e-01, time/batch = 19.6128s	
8103/22750 (epoch 17.809), train_loss = 1.28042969, grad/param norm = 2.1378e-01, time/batch = 18.0942s	
8104/22750 (epoch 17.811), train_loss = 1.01927914, grad/param norm = 1.9041e-01, time/batch = 18.4901s	
8105/22750 (epoch 17.813), train_loss = 1.11899227, grad/param norm = 1.8327e-01, time/batch = 17.5824s	
8106/22750 (epoch 17.815), train_loss = 1.25372085, grad/param norm = 2.0272e-01, time/batch = 18.9146s	
8107/22750 (epoch 17.818), train_loss = 1.22309513, grad/param norm = 1.8542e-01, time/batch = 17.3400s	
8108/22750 (epoch 17.820), train_loss = 1.35492247, grad/param norm = 1.9850e-01, time/batch = 16.3772s	
8109/22750 (epoch 17.822), train_loss = 1.13367905, grad/param norm = 1.9008e-01, time/batch = 15.2273s	
8110/22750 (epoch 17.824), train_loss = 0.99156594, grad/param norm = 1.7577e-01, time/batch = 15.3061s	
8111/22750 (epoch 17.826), train_loss = 1.06350883, grad/param norm = 1.8379e-01, time/batch = 15.7870s	
8112/22750 (epoch 17.829), train_loss = 1.24902034, grad/param norm = 2.0556e-01, time/batch = 15.0781s	
8113/22750 (epoch 17.831), train_loss = 1.20920558, grad/param norm = 1.8876e-01, time/batch = 14.8880s	
8114/22750 (epoch 17.833), train_loss = 1.13489565, grad/param norm = 2.1005e-01, time/batch = 15.9145s	
8115/22750 (epoch 17.835), train_loss = 1.02753050, grad/param norm = 1.8210e-01, time/batch = 15.3686s	
8116/22750 (epoch 17.837), train_loss = 1.02836901, grad/param norm = 1.7817e-01, time/batch = 16.5498s	
8117/22750 (epoch 17.840), train_loss = 0.96729497, grad/param norm = 1.6564e-01, time/batch = 16.1596s	
8118/22750 (epoch 17.842), train_loss = 1.01350105, grad/param norm = 1.8001e-01, time/batch = 15.8347s	
8119/22750 (epoch 17.844), train_loss = 1.14853262, grad/param norm = 2.0118e-01, time/batch = 15.1273s	
8120/22750 (epoch 17.846), train_loss = 1.11952685, grad/param norm = 2.0247e-01, time/batch = 15.6228s	
8121/22750 (epoch 17.848), train_loss = 0.98695251, grad/param norm = 1.6671e-01, time/batch = 15.1568s	
8122/22750 (epoch 17.851), train_loss = 0.96119383, grad/param norm = 1.8018e-01, time/batch = 15.4005s	
8123/22750 (epoch 17.853), train_loss = 1.11401172, grad/param norm = 1.8545e-01, time/batch = 15.6136s	
8124/22750 (epoch 17.855), train_loss = 0.93097503, grad/param norm = 1.5949e-01, time/batch = 15.1218s	
8125/22750 (epoch 17.857), train_loss = 1.10012566, grad/param norm = 1.7492e-01, time/batch = 15.2115s	
8126/22750 (epoch 17.859), train_loss = 1.15125867, grad/param norm = 2.1702e-01, time/batch = 15.4475s	
8127/22750 (epoch 17.862), train_loss = 1.25849564, grad/param norm = 1.9675e-01, time/batch = 15.1317s	
8128/22750 (epoch 17.864), train_loss = 1.09496415, grad/param norm = 1.9336e-01, time/batch = 15.8413s	
8129/22750 (epoch 17.866), train_loss = 1.11916189, grad/param norm = 1.7281e-01, time/batch = 15.6859s	
8130/22750 (epoch 17.868), train_loss = 1.00353657, grad/param norm = 1.7306e-01, time/batch = 15.3704s	
8131/22750 (epoch 17.870), train_loss = 0.87379231, grad/param norm = 1.8065e-01, time/batch = 15.1625s	
8132/22750 (epoch 17.873), train_loss = 1.02830088, grad/param norm = 1.7123e-01, time/batch = 14.9988s	
8133/22750 (epoch 17.875), train_loss = 1.14072673, grad/param norm = 1.8521e-01, time/batch = 15.5503s	
8134/22750 (epoch 17.877), train_loss = 0.97746538, grad/param norm = 1.6807e-01, time/batch = 15.2258s	
8135/22750 (epoch 17.879), train_loss = 1.22810614, grad/param norm = 2.1473e-01, time/batch = 16.4770s	
8136/22750 (epoch 17.881), train_loss = 1.16218004, grad/param norm = 1.9896e-01, time/batch = 15.1780s	
8137/22750 (epoch 17.884), train_loss = 0.99722291, grad/param norm = 1.9440e-01, time/batch = 15.6069s	
8138/22750 (epoch 17.886), train_loss = 1.15143189, grad/param norm = 1.9196e-01, time/batch = 15.3627s	
8139/22750 (epoch 17.888), train_loss = 1.14149254, grad/param norm = 1.8871e-01, time/batch = 15.2148s	
8140/22750 (epoch 17.890), train_loss = 1.18473440, grad/param norm = 1.9836e-01, time/batch = 15.7462s	
8141/22750 (epoch 17.892), train_loss = 1.44821409, grad/param norm = 2.3357e-01, time/batch = 15.5468s	
8142/22750 (epoch 17.895), train_loss = 1.13034367, grad/param norm = 1.8095e-01, time/batch = 15.1513s	
8143/22750 (epoch 17.897), train_loss = 1.20140306, grad/param norm = 1.9890e-01, time/batch = 14.8203s	
8144/22750 (epoch 17.899), train_loss = 1.13221850, grad/param norm = 1.8751e-01, time/batch = 14.7444s	
8145/22750 (epoch 17.901), train_loss = 1.25999870, grad/param norm = 2.0968e-01, time/batch = 15.8759s	
8146/22750 (epoch 17.903), train_loss = 1.07199615, grad/param norm = 1.9980e-01, time/batch = 15.0575s	
8147/22750 (epoch 17.905), train_loss = 1.17568145, grad/param norm = 1.9523e-01, time/batch = 15.2819s	
8148/22750 (epoch 17.908), train_loss = 1.01582996, grad/param norm = 2.0999e-01, time/batch = 14.8088s	
8149/22750 (epoch 17.910), train_loss = 0.87605042, grad/param norm = 1.9257e-01, time/batch = 15.4499s	
8150/22750 (epoch 17.912), train_loss = 1.02350603, grad/param norm = 1.8237e-01, time/batch = 15.0418s	
8151/22750 (epoch 17.914), train_loss = 1.08118831, grad/param norm = 1.7963e-01, time/batch = 14.8918s	
8152/22750 (epoch 17.916), train_loss = 0.91997413, grad/param norm = 1.8977e-01, time/batch = 14.8023s	
8153/22750 (epoch 17.919), train_loss = 1.03848303, grad/param norm = 2.1283e-01, time/batch = 15.8539s	
8154/22750 (epoch 17.921), train_loss = 0.77810601, grad/param norm = 1.5214e-01, time/batch = 15.0698s	
8155/22750 (epoch 17.923), train_loss = 0.95656514, grad/param norm = 1.7805e-01, time/batch = 14.7476s	
8156/22750 (epoch 17.925), train_loss = 1.05577925, grad/param norm = 1.8191e-01, time/batch = 14.6714s	
8157/22750 (epoch 17.927), train_loss = 0.84501313, grad/param norm = 1.8754e-01, time/batch = 15.9207s	
8158/22750 (epoch 17.930), train_loss = 0.85833160, grad/param norm = 1.6622e-01, time/batch = 15.0389s	
8159/22750 (epoch 17.932), train_loss = 1.09798388, grad/param norm = 1.8720e-01, time/batch = 15.0416s	
8160/22750 (epoch 17.934), train_loss = 0.81358913, grad/param norm = 1.5857e-01, time/batch = 14.8084s	
8161/22750 (epoch 17.936), train_loss = 1.18115536, grad/param norm = 1.9679e-01, time/batch = 15.4466s	
8162/22750 (epoch 17.938), train_loss = 1.13151295, grad/param norm = 1.6856e-01, time/batch = 15.9218s	
8163/22750 (epoch 17.941), train_loss = 1.25538045, grad/param norm = 1.9016e-01, time/batch = 15.7710s	
8164/22750 (epoch 17.943), train_loss = 1.11054620, grad/param norm = 1.9030e-01, time/batch = 15.4511s	
8165/22750 (epoch 17.945), train_loss = 1.09403056, grad/param norm = 1.8455e-01, time/batch = 15.4540s	
8166/22750 (epoch 17.947), train_loss = 1.03065698, grad/param norm = 1.9461e-01, time/batch = 15.0633s	
8167/22750 (epoch 17.949), train_loss = 0.95933810, grad/param norm = 1.8047e-01, time/batch = 15.8611s	
8168/22750 (epoch 17.952), train_loss = 0.98361635, grad/param norm = 1.7266e-01, time/batch = 15.1562s	
8169/22750 (epoch 17.954), train_loss = 0.96647642, grad/param norm = 1.7819e-01, time/batch = 15.4663s	
8170/22750 (epoch 17.956), train_loss = 1.07320404, grad/param norm = 1.8270e-01, time/batch = 15.4324s	
8171/22750 (epoch 17.958), train_loss = 1.00366233, grad/param norm = 1.6717e-01, time/batch = 15.6129s	
8172/22750 (epoch 17.960), train_loss = 0.96412103, grad/param norm = 1.6638e-01, time/batch = 16.0929s	
8173/22750 (epoch 17.963), train_loss = 1.17305777, grad/param norm = 1.9802e-01, time/batch = 15.4568s	
8174/22750 (epoch 17.965), train_loss = 1.14873783, grad/param norm = 1.8702e-01, time/batch = 15.3681s	
8175/22750 (epoch 17.967), train_loss = 1.06729203, grad/param norm = 1.9051e-01, time/batch = 15.1280s	
8176/22750 (epoch 17.969), train_loss = 0.97377540, grad/param norm = 1.9352e-01, time/batch = 15.3430s	
8177/22750 (epoch 17.971), train_loss = 1.02155380, grad/param norm = 1.8901e-01, time/batch = 14.9822s	
8178/22750 (epoch 17.974), train_loss = 1.05842923, grad/param norm = 2.0578e-01, time/batch = 15.1531s	
8179/22750 (epoch 17.976), train_loss = 1.11140932, grad/param norm = 1.9448e-01, time/batch = 15.2093s	
8180/22750 (epoch 17.978), train_loss = 0.97277793, grad/param norm = 1.7782e-01, time/batch = 15.5232s	
8181/22750 (epoch 17.980), train_loss = 1.22488245, grad/param norm = 2.1841e-01, time/batch = 15.9006s	
8182/22750 (epoch 17.982), train_loss = 0.98481314, grad/param norm = 1.6924e-01, time/batch = 15.5063s	
8183/22750 (epoch 17.985), train_loss = 1.27487189, grad/param norm = 1.9295e-01, time/batch = 15.0509s	
8184/22750 (epoch 17.987), train_loss = 0.84722291, grad/param norm = 1.6989e-01, time/batch = 15.5338s	
8185/22750 (epoch 17.989), train_loss = 1.01885766, grad/param norm = 1.9855e-01, time/batch = 15.3682s	
8186/22750 (epoch 17.991), train_loss = 1.13039439, grad/param norm = 2.0358e-01, time/batch = 15.8486s	
8187/22750 (epoch 17.993), train_loss = 1.15659985, grad/param norm = 2.0933e-01, time/batch = 14.8094s	
8188/22750 (epoch 17.996), train_loss = 0.97920617, grad/param norm = 2.0686e-01, time/batch = 15.9240s	
8189/22750 (epoch 17.998), train_loss = 1.22862550, grad/param norm = 1.9828e-01, time/batch = 15.4510s	
decayed learning rate by a factor 0.97 to 0.0015204621173091	
8190/22750 (epoch 18.000), train_loss = 1.11680154, grad/param norm = 1.8823e-01, time/batch = 15.3215s	
8191/22750 (epoch 18.002), train_loss = 1.22992068, grad/param norm = 2.1890e-01, time/batch = 15.2207s	
8192/22750 (epoch 18.004), train_loss = 1.00060077, grad/param norm = 1.8447e-01, time/batch = 15.5276s	
8193/22750 (epoch 18.007), train_loss = 1.03148913, grad/param norm = 1.8843e-01, time/batch = 15.2986s	
8194/22750 (epoch 18.009), train_loss = 1.27437436, grad/param norm = 2.1017e-01, time/batch = 15.6244s	
8195/22750 (epoch 18.011), train_loss = 1.33102903, grad/param norm = 2.1355e-01, time/batch = 16.3271s	
8196/22750 (epoch 18.013), train_loss = 1.18470787, grad/param norm = 1.9755e-01, time/batch = 16.5433s	
8197/22750 (epoch 18.015), train_loss = 1.10137647, grad/param norm = 2.0431e-01, time/batch = 15.8909s	
8198/22750 (epoch 18.018), train_loss = 1.16211779, grad/param norm = 1.9158e-01, time/batch = 15.8703s	
8199/22750 (epoch 18.020), train_loss = 1.21832603, grad/param norm = 1.9311e-01, time/batch = 15.8036s	
8200/22750 (epoch 18.022), train_loss = 1.07199692, grad/param norm = 1.9140e-01, time/batch = 15.4113s	
8201/22750 (epoch 18.024), train_loss = 1.08413768, grad/param norm = 1.8631e-01, time/batch = 15.6372s	
8202/22750 (epoch 18.026), train_loss = 1.15723563, grad/param norm = 2.0545e-01, time/batch = 15.3106s	
8203/22750 (epoch 18.029), train_loss = 0.89655248, grad/param norm = 1.7997e-01, time/batch = 16.0944s	
8204/22750 (epoch 18.031), train_loss = 1.34615977, grad/param norm = 2.0100e-01, time/batch = 15.6842s	
8205/22750 (epoch 18.033), train_loss = 1.10229006, grad/param norm = 1.8593e-01, time/batch = 15.3701s	
8206/22750 (epoch 18.035), train_loss = 1.13288339, grad/param norm = 1.8746e-01, time/batch = 15.6092s	
8207/22750 (epoch 18.037), train_loss = 1.22416747, grad/param norm = 1.9008e-01, time/batch = 15.4557s	
8208/22750 (epoch 18.040), train_loss = 1.04197532, grad/param norm = 1.9473e-01, time/batch = 15.2124s	
8209/22750 (epoch 18.042), train_loss = 1.16189364, grad/param norm = 1.9811e-01, time/batch = 15.4464s	
8210/22750 (epoch 18.044), train_loss = 1.02995387, grad/param norm = 1.8599e-01, time/batch = 14.9151s	
8211/22750 (epoch 18.046), train_loss = 1.21000240, grad/param norm = 2.2031e-01, time/batch = 15.7945s	
8212/22750 (epoch 18.048), train_loss = 1.06396950, grad/param norm = 1.8738e-01, time/batch = 15.0801s	
8213/22750 (epoch 18.051), train_loss = 1.15343665, grad/param norm = 1.9341e-01, time/batch = 15.5664s	
8214/22750 (epoch 18.053), train_loss = 0.97038454, grad/param norm = 1.6260e-01, time/batch = 16.8584s	
8215/22750 (epoch 18.055), train_loss = 1.00289458, grad/param norm = 1.8422e-01, time/batch = 28.1472s	
8216/22750 (epoch 18.057), train_loss = 1.24896758, grad/param norm = 1.8609e-01, time/batch = 16.0900s	
8217/22750 (epoch 18.059), train_loss = 0.81843101, grad/param norm = 1.8499e-01, time/batch = 16.0895s	
8218/22750 (epoch 18.062), train_loss = 0.93986841, grad/param norm = 1.8128e-01, time/batch = 15.6005s	
8219/22750 (epoch 18.064), train_loss = 1.14029597, grad/param norm = 2.0555e-01, time/batch = 15.8412s	
8220/22750 (epoch 18.066), train_loss = 0.93107147, grad/param norm = 1.7683e-01, time/batch = 16.0821s	
8221/22750 (epoch 18.068), train_loss = 1.00241073, grad/param norm = 1.7612e-01, time/batch = 16.0255s	
8222/22750 (epoch 18.070), train_loss = 0.83024933, grad/param norm = 1.6282e-01, time/batch = 16.7153s	
8223/22750 (epoch 18.073), train_loss = 1.01377464, grad/param norm = 2.0064e-01, time/batch = 16.3121s	
8224/22750 (epoch 18.075), train_loss = 1.03386287, grad/param norm = 1.7241e-01, time/batch = 15.7695s	
8225/22750 (epoch 18.077), train_loss = 0.82545569, grad/param norm = 2.0395e-01, time/batch = 16.6387s	
8226/22750 (epoch 18.079), train_loss = 1.03949152, grad/param norm = 2.0954e-01, time/batch = 16.0119s	
8227/22750 (epoch 18.081), train_loss = 1.02985325, grad/param norm = 1.8916e-01, time/batch = 15.6946s	
8228/22750 (epoch 18.084), train_loss = 1.00167129, grad/param norm = 1.8357e-01, time/batch = 16.0863s	
8229/22750 (epoch 18.086), train_loss = 1.03271243, grad/param norm = 1.6393e-01, time/batch = 16.0904s	
8230/22750 (epoch 18.088), train_loss = 0.97712825, grad/param norm = 1.8380e-01, time/batch = 16.0277s	
8231/22750 (epoch 18.090), train_loss = 0.97160043, grad/param norm = 1.8047e-01, time/batch = 16.6581s	
8232/22750 (epoch 18.092), train_loss = 1.19170109, grad/param norm = 1.8440e-01, time/batch = 16.6546s	
8233/22750 (epoch 18.095), train_loss = 0.94591125, grad/param norm = 1.8235e-01, time/batch = 16.8248s	
8234/22750 (epoch 18.097), train_loss = 1.04918874, grad/param norm = 1.8588e-01, time/batch = 16.7331s	
8235/22750 (epoch 18.099), train_loss = 1.05307180, grad/param norm = 1.8694e-01, time/batch = 16.8987s	
8236/22750 (epoch 18.101), train_loss = 0.92554751, grad/param norm = 1.7826e-01, time/batch = 17.0568s	
8237/22750 (epoch 18.103), train_loss = 1.05681732, grad/param norm = 1.8198e-01, time/batch = 16.9788s	
8238/22750 (epoch 18.105), train_loss = 1.27406329, grad/param norm = 2.0829e-01, time/batch = 16.9781s	
8239/22750 (epoch 18.108), train_loss = 1.02784274, grad/param norm = 1.9768e-01, time/batch = 16.6647s	
8240/22750 (epoch 18.110), train_loss = 1.19666177, grad/param norm = 1.8500e-01, time/batch = 17.0611s	
8241/22750 (epoch 18.112), train_loss = 0.89396221, grad/param norm = 1.7317e-01, time/batch = 17.5119s	
8242/22750 (epoch 18.114), train_loss = 0.84048710, grad/param norm = 1.7806e-01, time/batch = 20.1843s	
8243/22750 (epoch 18.116), train_loss = 0.95921260, grad/param norm = 1.6860e-01, time/batch = 18.7719s	
8244/22750 (epoch 18.119), train_loss = 0.97116733, grad/param norm = 1.7018e-01, time/batch = 16.3817s	
8245/22750 (epoch 18.121), train_loss = 1.09572768, grad/param norm = 2.2989e-01, time/batch = 16.0207s	
8246/22750 (epoch 18.123), train_loss = 0.93389215, grad/param norm = 1.6804e-01, time/batch = 17.5032s	
8247/22750 (epoch 18.125), train_loss = 1.21484479, grad/param norm = 1.8930e-01, time/batch = 17.8272s	
8248/22750 (epoch 18.127), train_loss = 1.02338001, grad/param norm = 1.8601e-01, time/batch = 16.7759s	
8249/22750 (epoch 18.130), train_loss = 1.06164837, grad/param norm = 1.7006e-01, time/batch = 18.2346s	
8250/22750 (epoch 18.132), train_loss = 0.98595284, grad/param norm = 1.9384e-01, time/batch = 16.1720s	
8251/22750 (epoch 18.134), train_loss = 1.00369823, grad/param norm = 1.7462e-01, time/batch = 17.7849s	
8252/22750 (epoch 18.136), train_loss = 0.89548828, grad/param norm = 1.9971e-01, time/batch = 20.0296s	
8253/22750 (epoch 18.138), train_loss = 1.11346902, grad/param norm = 2.0160e-01, time/batch = 18.8593s	
8254/22750 (epoch 18.141), train_loss = 1.07160579, grad/param norm = 1.9713e-01, time/batch = 18.6641s	
8255/22750 (epoch 18.143), train_loss = 0.93499258, grad/param norm = 1.7607e-01, time/batch = 19.8353s	
8256/22750 (epoch 18.145), train_loss = 1.20697450, grad/param norm = 1.9589e-01, time/batch = 18.3304s	
8257/22750 (epoch 18.147), train_loss = 1.19937598, grad/param norm = 1.9583e-01, time/batch = 18.0976s	
8258/22750 (epoch 18.149), train_loss = 1.06129134, grad/param norm = 1.8797e-01, time/batch = 18.2427s	
8259/22750 (epoch 18.152), train_loss = 1.06127826, grad/param norm = 1.8430e-01, time/batch = 18.4151s	
8260/22750 (epoch 18.154), train_loss = 0.87272142, grad/param norm = 1.7566e-01, time/batch = 17.3552s	
8261/22750 (epoch 18.156), train_loss = 0.91204984, grad/param norm = 1.8862e-01, time/batch = 20.6923s	
8262/22750 (epoch 18.158), train_loss = 0.97541912, grad/param norm = 1.9480e-01, time/batch = 18.4506s	
8263/22750 (epoch 18.160), train_loss = 1.09874363, grad/param norm = 1.9693e-01, time/batch = 17.3993s	
8264/22750 (epoch 18.163), train_loss = 1.28832195, grad/param norm = 2.1080e-01, time/batch = 19.0816s	
8265/22750 (epoch 18.165), train_loss = 1.12781582, grad/param norm = 2.0991e-01, time/batch = 17.6610s	
8266/22750 (epoch 18.167), train_loss = 1.00720830, grad/param norm = 2.0236e-01, time/batch = 18.1479s	
8267/22750 (epoch 18.169), train_loss = 1.05404246, grad/param norm = 1.9691e-01, time/batch = 19.6558s	
8268/22750 (epoch 18.171), train_loss = 0.93114066, grad/param norm = 1.8430e-01, time/batch = 19.4986s	
8269/22750 (epoch 18.174), train_loss = 0.88258429, grad/param norm = 1.8423e-01, time/batch = 17.8437s	
8270/22750 (epoch 18.176), train_loss = 0.98358740, grad/param norm = 1.7518e-01, time/batch = 20.0985s	
8271/22750 (epoch 18.178), train_loss = 1.00057452, grad/param norm = 1.8497e-01, time/batch = 16.9887s	
8272/22750 (epoch 18.180), train_loss = 1.15042736, grad/param norm = 2.4709e-01, time/batch = 16.8538s	
8273/22750 (epoch 18.182), train_loss = 1.18694721, grad/param norm = 2.0639e-01, time/batch = 16.2741s	
8274/22750 (epoch 18.185), train_loss = 1.21033675, grad/param norm = 2.0313e-01, time/batch = 16.6109s	
8275/22750 (epoch 18.187), train_loss = 0.96404807, grad/param norm = 1.9390e-01, time/batch = 17.5721s	
8276/22750 (epoch 18.189), train_loss = 0.98951684, grad/param norm = 1.9098e-01, time/batch = 17.9992s	
8277/22750 (epoch 18.191), train_loss = 0.95675518, grad/param norm = 1.6851e-01, time/batch = 18.0061s	
8278/22750 (epoch 18.193), train_loss = 1.12801704, grad/param norm = 1.9044e-01, time/batch = 19.5715s	
8279/22750 (epoch 18.196), train_loss = 1.02634125, grad/param norm = 1.9272e-01, time/batch = 16.0969s	
8280/22750 (epoch 18.198), train_loss = 0.78919902, grad/param norm = 1.5232e-01, time/batch = 18.2780s	
8281/22750 (epoch 18.200), train_loss = 1.06996870, grad/param norm = 1.8250e-01, time/batch = 18.3304s	
8282/22750 (epoch 18.202), train_loss = 1.15690771, grad/param norm = 2.0346e-01, time/batch = 18.5872s	
8283/22750 (epoch 18.204), train_loss = 1.05603252, grad/param norm = 1.7047e-01, time/batch = 19.4241s	
8284/22750 (epoch 18.207), train_loss = 1.01697806, grad/param norm = 1.7465e-01, time/batch = 19.0043s	
8285/22750 (epoch 18.209), train_loss = 0.96007134, grad/param norm = 1.8847e-01, time/batch = 18.7155s	
8286/22750 (epoch 18.211), train_loss = 0.98011949, grad/param norm = 1.9513e-01, time/batch = 20.0855s	
8287/22750 (epoch 18.213), train_loss = 0.87373556, grad/param norm = 1.6868e-01, time/batch = 19.1650s	
8288/22750 (epoch 18.215), train_loss = 0.81408459, grad/param norm = 1.6974e-01, time/batch = 18.8365s	
8289/22750 (epoch 18.218), train_loss = 0.91190913, grad/param norm = 1.8809e-01, time/batch = 18.0083s	
8290/22750 (epoch 18.220), train_loss = 0.90190048, grad/param norm = 1.8054e-01, time/batch = 18.1762s	
8291/22750 (epoch 18.222), train_loss = 0.87857039, grad/param norm = 1.7878e-01, time/batch = 19.6107s	
8292/22750 (epoch 18.224), train_loss = 0.93685319, grad/param norm = 1.7557e-01, time/batch = 18.6860s	
8293/22750 (epoch 18.226), train_loss = 1.11681208, grad/param norm = 1.9666e-01, time/batch = 19.7647s	
8294/22750 (epoch 18.229), train_loss = 1.07193528, grad/param norm = 1.9093e-01, time/batch = 16.7343s	
8295/22750 (epoch 18.231), train_loss = 0.96631819, grad/param norm = 1.8761e-01, time/batch = 18.0274s	
8296/22750 (epoch 18.233), train_loss = 0.90763393, grad/param norm = 1.9677e-01, time/batch = 20.3348s	
8297/22750 (epoch 18.235), train_loss = 0.85478417, grad/param norm = 1.7906e-01, time/batch = 19.1748s	
8298/22750 (epoch 18.237), train_loss = 0.96586774, grad/param norm = 1.9610e-01, time/batch = 17.2652s	
8299/22750 (epoch 18.240), train_loss = 1.02700185, grad/param norm = 1.7718e-01, time/batch = 17.2438s	
8300/22750 (epoch 18.242), train_loss = 1.27243336, grad/param norm = 2.1471e-01, time/batch = 16.7444s	
8301/22750 (epoch 18.244), train_loss = 1.18144066, grad/param norm = 2.0269e-01, time/batch = 18.5080s	
8302/22750 (epoch 18.246), train_loss = 1.25057756, grad/param norm = 2.1853e-01, time/batch = 19.0217s	
8303/22750 (epoch 18.248), train_loss = 1.01864681, grad/param norm = 2.1124e-01, time/batch = 19.3590s	
8304/22750 (epoch 18.251), train_loss = 1.20063253, grad/param norm = 1.9667e-01, time/batch = 19.3641s	
8305/22750 (epoch 18.253), train_loss = 1.07082874, grad/param norm = 1.8886e-01, time/batch = 18.8539s	
8306/22750 (epoch 18.255), train_loss = 1.05148761, grad/param norm = 1.7782e-01, time/batch = 17.2693s	
8307/22750 (epoch 18.257), train_loss = 0.96809956, grad/param norm = 1.8721e-01, time/batch = 19.9997s	
8308/22750 (epoch 18.259), train_loss = 1.17251448, grad/param norm = 2.2254e-01, time/batch = 18.2673s	
8309/22750 (epoch 18.262), train_loss = 1.05076198, grad/param norm = 1.9131e-01, time/batch = 19.0893s	
8310/22750 (epoch 18.264), train_loss = 0.87883769, grad/param norm = 1.9031e-01, time/batch = 19.5135s	
8311/22750 (epoch 18.266), train_loss = 1.07447769, grad/param norm = 2.1632e-01, time/batch = 16.5991s	
8312/22750 (epoch 18.268), train_loss = 1.20898414, grad/param norm = 2.0909e-01, time/batch = 17.2515s	
8313/22750 (epoch 18.270), train_loss = 0.97094735, grad/param norm = 2.0469e-01, time/batch = 16.7940s	
8314/22750 (epoch 18.273), train_loss = 1.34019388, grad/param norm = 2.3821e-01, time/batch = 16.0042s	
8315/22750 (epoch 18.275), train_loss = 1.17935263, grad/param norm = 1.9395e-01, time/batch = 15.7738s	
8316/22750 (epoch 18.277), train_loss = 1.00686658, grad/param norm = 1.9770e-01, time/batch = 14.9053s	
8317/22750 (epoch 18.279), train_loss = 0.89554001, grad/param norm = 1.9612e-01, time/batch = 15.2891s	
8318/22750 (epoch 18.281), train_loss = 1.19137219, grad/param norm = 2.0301e-01, time/batch = 15.1120s	
8319/22750 (epoch 18.284), train_loss = 1.03016730, grad/param norm = 1.8446e-01, time/batch = 15.2144s	
8320/22750 (epoch 18.286), train_loss = 1.18709414, grad/param norm = 2.0217e-01, time/batch = 15.2149s	
8321/22750 (epoch 18.288), train_loss = 1.23696597, grad/param norm = 2.0394e-01, time/batch = 15.3022s	
8322/22750 (epoch 18.290), train_loss = 1.07312935, grad/param norm = 1.9452e-01, time/batch = 15.3010s	
8323/22750 (epoch 18.292), train_loss = 1.13309609, grad/param norm = 2.1578e-01, time/batch = 15.3801s	
8324/22750 (epoch 18.295), train_loss = 1.11682199, grad/param norm = 1.9106e-01, time/batch = 15.2790s	
8325/22750 (epoch 18.297), train_loss = 1.02123152, grad/param norm = 1.8333e-01, time/batch = 15.2182s	
8326/22750 (epoch 18.299), train_loss = 1.18683291, grad/param norm = 1.9029e-01, time/batch = 15.6388s	
8327/22750 (epoch 18.301), train_loss = 1.08787458, grad/param norm = 1.9472e-01, time/batch = 15.8669s	
8328/22750 (epoch 18.303), train_loss = 1.15798229, grad/param norm = 1.9674e-01, time/batch = 15.1513s	
8329/22750 (epoch 18.305), train_loss = 1.27131172, grad/param norm = 1.8963e-01, time/batch = 14.9087s	
8330/22750 (epoch 18.308), train_loss = 1.12272161, grad/param norm = 1.7710e-01, time/batch = 15.5983s	
8331/22750 (epoch 18.310), train_loss = 0.95479834, grad/param norm = 2.0059e-01, time/batch = 15.2857s	
8332/22750 (epoch 18.312), train_loss = 1.08983877, grad/param norm = 1.9398e-01, time/batch = 15.4583s	
8333/22750 (epoch 18.314), train_loss = 1.07253116, grad/param norm = 1.9832e-01, time/batch = 15.2171s	
8334/22750 (epoch 18.316), train_loss = 1.02147593, grad/param norm = 1.8607e-01, time/batch = 16.0105s	
8335/22750 (epoch 18.319), train_loss = 1.07431463, grad/param norm = 1.9852e-01, time/batch = 15.4512s	
8336/22750 (epoch 18.321), train_loss = 1.01520074, grad/param norm = 1.8886e-01, time/batch = 15.8556s	
8337/22750 (epoch 18.323), train_loss = 1.06917268, grad/param norm = 2.1138e-01, time/batch = 15.0648s	
8338/22750 (epoch 18.325), train_loss = 0.89486643, grad/param norm = 1.8098e-01, time/batch = 15.3853s	
8339/22750 (epoch 18.327), train_loss = 1.03983014, grad/param norm = 1.8513e-01, time/batch = 14.9874s	
8340/22750 (epoch 18.330), train_loss = 1.31195055, grad/param norm = 2.1803e-01, time/batch = 15.4723s	
8341/22750 (epoch 18.332), train_loss = 1.28122213, grad/param norm = 1.9190e-01, time/batch = 15.6866s	
8342/22750 (epoch 18.334), train_loss = 0.87761425, grad/param norm = 1.8622e-01, time/batch = 15.6990s	
8343/22750 (epoch 18.336), train_loss = 1.13659527, grad/param norm = 1.9559e-01, time/batch = 14.9680s	
8344/22750 (epoch 18.338), train_loss = 1.03146952, grad/param norm = 1.8862e-01, time/batch = 15.4500s	
8345/22750 (epoch 18.341), train_loss = 1.05046536, grad/param norm = 1.8456e-01, time/batch = 15.1234s	
8346/22750 (epoch 18.343), train_loss = 0.91953132, grad/param norm = 1.9213e-01, time/batch = 15.4445s	
8347/22750 (epoch 18.345), train_loss = 1.18563542, grad/param norm = 2.1237e-01, time/batch = 15.1392s	
8348/22750 (epoch 18.347), train_loss = 1.22589781, grad/param norm = 2.0812e-01, time/batch = 15.2991s	
8349/22750 (epoch 18.349), train_loss = 0.84787781, grad/param norm = 2.0114e-01, time/batch = 15.1483s	
8350/22750 (epoch 18.352), train_loss = 1.15872043, grad/param norm = 1.9405e-01, time/batch = 15.0746s	
8351/22750 (epoch 18.354), train_loss = 1.18299268, grad/param norm = 1.9652e-01, time/batch = 15.2246s	
8352/22750 (epoch 18.356), train_loss = 1.21065131, grad/param norm = 2.1028e-01, time/batch = 15.2992s	
8353/22750 (epoch 18.358), train_loss = 1.07000395, grad/param norm = 1.9688e-01, time/batch = 15.3716s	
8354/22750 (epoch 18.360), train_loss = 1.25325255, grad/param norm = 1.8935e-01, time/batch = 16.2279s	
8355/22750 (epoch 18.363), train_loss = 1.03003203, grad/param norm = 1.8257e-01, time/batch = 16.2280s	
8356/22750 (epoch 18.365), train_loss = 0.85848878, grad/param norm = 1.8402e-01, time/batch = 15.5190s	
8357/22750 (epoch 18.367), train_loss = 0.92991206, grad/param norm = 2.0433e-01, time/batch = 15.8590s	
8358/22750 (epoch 18.369), train_loss = 1.06127140, grad/param norm = 1.9110e-01, time/batch = 15.2148s	
8359/22750 (epoch 18.371), train_loss = 1.01700188, grad/param norm = 1.9103e-01, time/batch = 15.0838s	
8360/22750 (epoch 18.374), train_loss = 0.97607457, grad/param norm = 1.8612e-01, time/batch = 15.1341s	
8361/22750 (epoch 18.376), train_loss = 1.01601620, grad/param norm = 1.9361e-01, time/batch = 15.7721s	
8362/22750 (epoch 18.378), train_loss = 1.08162533, grad/param norm = 1.8945e-01, time/batch = 15.2678s	
8363/22750 (epoch 18.380), train_loss = 1.18237395, grad/param norm = 2.0379e-01, time/batch = 15.5230s	
8364/22750 (epoch 18.382), train_loss = 1.00178572, grad/param norm = 1.7805e-01, time/batch = 15.2812s	
8365/22750 (epoch 18.385), train_loss = 1.14637072, grad/param norm = 1.8857e-01, time/batch = 16.0214s	
8366/22750 (epoch 18.387), train_loss = 1.10282584, grad/param norm = 1.8093e-01, time/batch = 15.3761s	
8367/22750 (epoch 18.389), train_loss = 0.84747114, grad/param norm = 1.7973e-01, time/batch = 15.3699s	
8368/22750 (epoch 18.391), train_loss = 0.66254986, grad/param norm = 1.4854e-01, time/batch = 14.9545s	
8369/22750 (epoch 18.393), train_loss = 0.91592905, grad/param norm = 1.7634e-01, time/batch = 15.3989s	
8370/22750 (epoch 18.396), train_loss = 1.09845180, grad/param norm = 1.8898e-01, time/batch = 15.0752s	
8371/22750 (epoch 18.398), train_loss = 1.01640653, grad/param norm = 1.8720e-01, time/batch = 15.5476s	
8372/22750 (epoch 18.400), train_loss = 1.04049334, grad/param norm = 1.8120e-01, time/batch = 15.0732s	
8373/22750 (epoch 18.402), train_loss = 1.11919593, grad/param norm = 1.9292e-01, time/batch = 15.8400s	
8374/22750 (epoch 18.404), train_loss = 1.21063148, grad/param norm = 2.0598e-01, time/batch = 15.3676s	
8375/22750 (epoch 18.407), train_loss = 1.16801303, grad/param norm = 1.9043e-01, time/batch = 15.6847s	
8376/22750 (epoch 18.409), train_loss = 1.03713999, grad/param norm = 1.9156e-01, time/batch = 16.0846s	
8377/22750 (epoch 18.411), train_loss = 1.03410064, grad/param norm = 1.8535e-01, time/batch = 15.5315s	
8378/22750 (epoch 18.413), train_loss = 0.82179839, grad/param norm = 1.7399e-01, time/batch = 15.7726s	
8379/22750 (epoch 18.415), train_loss = 0.80921137, grad/param norm = 1.6266e-01, time/batch = 16.0853s	
8380/22750 (epoch 18.418), train_loss = 1.00133289, grad/param norm = 1.9613e-01, time/batch = 15.6040s	
8381/22750 (epoch 18.420), train_loss = 1.14773010, grad/param norm = 2.6403e-01, time/batch = 15.3446s	
8382/22750 (epoch 18.422), train_loss = 1.29372951, grad/param norm = 2.4781e-01, time/batch = 15.7561s	
8383/22750 (epoch 18.424), train_loss = 1.28544006, grad/param norm = 2.2179e-01, time/batch = 15.5900s	
8384/22750 (epoch 18.426), train_loss = 1.28252559, grad/param norm = 2.1498e-01, time/batch = 15.6025s	
8385/22750 (epoch 18.429), train_loss = 0.94170172, grad/param norm = 1.9114e-01, time/batch = 15.2937s	
8386/22750 (epoch 18.431), train_loss = 0.88639861, grad/param norm = 1.9472e-01, time/batch = 16.3813s	
8387/22750 (epoch 18.433), train_loss = 0.98810764, grad/param norm = 1.8521e-01, time/batch = 15.7565s	
8388/22750 (epoch 18.435), train_loss = 0.81076247, grad/param norm = 1.7625e-01, time/batch = 16.3312s	
8389/22750 (epoch 18.437), train_loss = 0.71712998, grad/param norm = 1.7446e-01, time/batch = 15.5441s	
8390/22750 (epoch 18.440), train_loss = 1.07649032, grad/param norm = 2.0111e-01, time/batch = 15.1478s	
8391/22750 (epoch 18.442), train_loss = 1.08901760, grad/param norm = 2.1806e-01, time/batch = 15.3272s	
8392/22750 (epoch 18.444), train_loss = 1.03523005, grad/param norm = 2.0592e-01, time/batch = 15.6219s	
8393/22750 (epoch 18.446), train_loss = 1.07053405, grad/param norm = 2.2335e-01, time/batch = 15.5319s	
8394/22750 (epoch 18.448), train_loss = 1.34307099, grad/param norm = 2.1489e-01, time/batch = 15.6872s	
8395/22750 (epoch 18.451), train_loss = 1.24887037, grad/param norm = 2.0127e-01, time/batch = 15.3751s	
8396/22750 (epoch 18.453), train_loss = 1.24138363, grad/param norm = 2.1272e-01, time/batch = 15.7742s	
8397/22750 (epoch 18.455), train_loss = 1.34327485, grad/param norm = 2.1240e-01, time/batch = 15.1283s	
8398/22750 (epoch 18.457), train_loss = 1.18402311, grad/param norm = 3.0394e-01, time/batch = 15.1308s	
8399/22750 (epoch 18.459), train_loss = 1.16488766, grad/param norm = 1.9205e-01, time/batch = 15.2914s	
8400/22750 (epoch 18.462), train_loss = 1.14935593, grad/param norm = 1.9115e-01, time/batch = 15.1261s	
8401/22750 (epoch 18.464), train_loss = 0.89911801, grad/param norm = 1.8759e-01, time/batch = 15.3085s	
8402/22750 (epoch 18.466), train_loss = 1.26000884, grad/param norm = 2.2938e-01, time/batch = 15.4729s	
8403/22750 (epoch 18.468), train_loss = 1.04072007, grad/param norm = 1.8839e-01, time/batch = 15.8552s	
8404/22750 (epoch 18.470), train_loss = 1.20274873, grad/param norm = 2.0352e-01, time/batch = 15.5288s	
8405/22750 (epoch 18.473), train_loss = 1.06644165, grad/param norm = 1.9748e-01, time/batch = 15.3619s	
8406/22750 (epoch 18.475), train_loss = 1.10462547, grad/param norm = 2.2480e-01, time/batch = 15.1295s	
8407/22750 (epoch 18.477), train_loss = 0.92092052, grad/param norm = 2.0191e-01, time/batch = 15.5327s	
8408/22750 (epoch 18.479), train_loss = 0.91266556, grad/param norm = 1.9252e-01, time/batch = 17.6824s	
8409/22750 (epoch 18.481), train_loss = 0.84362130, grad/param norm = 1.6636e-01, time/batch = 17.5272s	
8410/22750 (epoch 18.484), train_loss = 0.77348785, grad/param norm = 1.8782e-01, time/batch = 15.7142s	
8411/22750 (epoch 18.486), train_loss = 0.89922105, grad/param norm = 1.9185e-01, time/batch = 17.7625s	
8412/22750 (epoch 18.488), train_loss = 0.80257476, grad/param norm = 1.9184e-01, time/batch = 17.4540s	
8413/22750 (epoch 18.490), train_loss = 1.06506444, grad/param norm = 1.8070e-01, time/batch = 17.3640s	
8414/22750 (epoch 18.492), train_loss = 1.20664033, grad/param norm = 2.1523e-01, time/batch = 17.4227s	
8415/22750 (epoch 18.495), train_loss = 0.94979269, grad/param norm = 1.7590e-01, time/batch = 17.6795s	
8416/22750 (epoch 18.497), train_loss = 1.05076827, grad/param norm = 2.1714e-01, time/batch = 17.1524s	
8417/22750 (epoch 18.499), train_loss = 0.95751765, grad/param norm = 1.9001e-01, time/batch = 17.4994s	
8418/22750 (epoch 18.501), train_loss = 1.04866226, grad/param norm = 1.9694e-01, time/batch = 17.9155s	
8419/22750 (epoch 18.503), train_loss = 1.06591108, grad/param norm = 1.9649e-01, time/batch = 18.4202s	
8420/22750 (epoch 18.505), train_loss = 0.90539510, grad/param norm = 1.7754e-01, time/batch = 19.3536s	
8421/22750 (epoch 18.508), train_loss = 0.86694191, grad/param norm = 1.8913e-01, time/batch = 19.0744s	
8422/22750 (epoch 18.510), train_loss = 0.88190345, grad/param norm = 1.6282e-01, time/batch = 19.9352s	
8423/22750 (epoch 18.512), train_loss = 0.92555604, grad/param norm = 1.7722e-01, time/batch = 16.6080s	
8424/22750 (epoch 18.514), train_loss = 0.98832607, grad/param norm = 2.0911e-01, time/batch = 17.8355s	
8425/22750 (epoch 18.516), train_loss = 0.96908483, grad/param norm = 1.9403e-01, time/batch = 17.5055s	
8426/22750 (epoch 18.519), train_loss = 1.11670130, grad/param norm = 1.9602e-01, time/batch = 17.5649s	
8427/22750 (epoch 18.521), train_loss = 1.04852326, grad/param norm = 2.0179e-01, time/batch = 17.9637s	
8428/22750 (epoch 18.523), train_loss = 0.99331761, grad/param norm = 2.0450e-01, time/batch = 33.8074s	
8429/22750 (epoch 18.525), train_loss = 1.19718545, grad/param norm = 2.1277e-01, time/batch = 16.0701s	
8430/22750 (epoch 18.527), train_loss = 1.05444192, grad/param norm = 1.9878e-01, time/batch = 16.6818s	
8431/22750 (epoch 18.530), train_loss = 0.97269234, grad/param norm = 2.0656e-01, time/batch = 15.5545s	
8432/22750 (epoch 18.532), train_loss = 0.88910379, grad/param norm = 1.6778e-01, time/batch = 15.0574s	
8433/22750 (epoch 18.534), train_loss = 1.13866798, grad/param norm = 2.0083e-01, time/batch = 15.2895s	
8434/22750 (epoch 18.536), train_loss = 1.06531094, grad/param norm = 1.7531e-01, time/batch = 15.6873s	
8435/22750 (epoch 18.538), train_loss = 1.05825193, grad/param norm = 1.8413e-01, time/batch = 15.3782s	
8436/22750 (epoch 18.541), train_loss = 0.90708196, grad/param norm = 1.8417e-01, time/batch = 15.6839s	
8437/22750 (epoch 18.543), train_loss = 0.91175564, grad/param norm = 1.8275e-01, time/batch = 15.0501s	
8438/22750 (epoch 18.545), train_loss = 1.14800888, grad/param norm = 1.9447e-01, time/batch = 16.0063s	
8439/22750 (epoch 18.547), train_loss = 0.95708554, grad/param norm = 1.6821e-01, time/batch = 15.4707s	
8440/22750 (epoch 18.549), train_loss = 0.98852095, grad/param norm = 1.7807e-01, time/batch = 15.6174s	
8441/22750 (epoch 18.552), train_loss = 1.09615538, grad/param norm = 2.0457e-01, time/batch = 15.3181s	
8442/22750 (epoch 18.554), train_loss = 1.12528003, grad/param norm = 2.0941e-01, time/batch = 15.7120s	
8443/22750 (epoch 18.556), train_loss = 1.04043173, grad/param norm = 1.8780e-01, time/batch = 15.2922s	
8444/22750 (epoch 18.558), train_loss = 1.15336149, grad/param norm = 2.0505e-01, time/batch = 15.4646s	
8445/22750 (epoch 18.560), train_loss = 0.98712528, grad/param norm = 1.9727e-01, time/batch = 15.5370s	
8446/22750 (epoch 18.563), train_loss = 1.14751499, grad/param norm = 1.9390e-01, time/batch = 15.5186s	
8447/22750 (epoch 18.565), train_loss = 1.10383476, grad/param norm = 2.0228e-01, time/batch = 15.1264s	
8448/22750 (epoch 18.567), train_loss = 1.08311755, grad/param norm = 1.8673e-01, time/batch = 15.4426s	
8449/22750 (epoch 18.569), train_loss = 1.01889616, grad/param norm = 1.8560e-01, time/batch = 15.2881s	
8450/22750 (epoch 18.571), train_loss = 1.04202783, grad/param norm = 1.9165e-01, time/batch = 15.3047s	
8451/22750 (epoch 18.574), train_loss = 0.95448338, grad/param norm = 1.8106e-01, time/batch = 15.2417s	
8452/22750 (epoch 18.576), train_loss = 1.01935385, grad/param norm = 2.0788e-01, time/batch = 15.2362s	
8453/22750 (epoch 18.578), train_loss = 0.90431465, grad/param norm = 1.8106e-01, time/batch = 15.5513s	
8454/22750 (epoch 18.580), train_loss = 1.07398913, grad/param norm = 2.0491e-01, time/batch = 15.1363s	
8455/22750 (epoch 18.582), train_loss = 0.93000676, grad/param norm = 1.8402e-01, time/batch = 16.7735s	
8456/22750 (epoch 18.585), train_loss = 0.90666393, grad/param norm = 1.9646e-01, time/batch = 15.6639s	
8457/22750 (epoch 18.587), train_loss = 0.89161160, grad/param norm = 1.6665e-01, time/batch = 16.0832s	
8458/22750 (epoch 18.589), train_loss = 0.85085027, grad/param norm = 1.7080e-01, time/batch = 15.5244s	
8459/22750 (epoch 18.591), train_loss = 1.00939490, grad/param norm = 1.9374e-01, time/batch = 15.1941s	
8460/22750 (epoch 18.593), train_loss = 1.20380496, grad/param norm = 1.8599e-01, time/batch = 15.1345s	
8461/22750 (epoch 18.596), train_loss = 1.20512915, grad/param norm = 1.9276e-01, time/batch = 15.7670s	
8462/22750 (epoch 18.598), train_loss = 1.25422055, grad/param norm = 2.0558e-01, time/batch = 15.5579s	
8463/22750 (epoch 18.600), train_loss = 1.19483102, grad/param norm = 2.0379e-01, time/batch = 15.0614s	
8464/22750 (epoch 18.602), train_loss = 0.95353529, grad/param norm = 1.7722e-01, time/batch = 15.1347s	
8465/22750 (epoch 18.604), train_loss = 0.98800850, grad/param norm = 1.9819e-01, time/batch = 15.5905s	
8466/22750 (epoch 18.607), train_loss = 0.86663544, grad/param norm = 1.5772e-01, time/batch = 15.2864s	
8467/22750 (epoch 18.609), train_loss = 0.81648651, grad/param norm = 1.5643e-01, time/batch = 15.4295s	
8468/22750 (epoch 18.611), train_loss = 1.00283344, grad/param norm = 1.8745e-01, time/batch = 15.4301s	
8469/22750 (epoch 18.613), train_loss = 0.94381346, grad/param norm = 1.7992e-01, time/batch = 15.6013s	
8470/22750 (epoch 18.615), train_loss = 0.96995533, grad/param norm = 1.7746e-01, time/batch = 15.3674s	
8471/22750 (epoch 18.618), train_loss = 0.99808475, grad/param norm = 1.8865e-01, time/batch = 15.4578s	
8472/22750 (epoch 18.620), train_loss = 1.01245472, grad/param norm = 1.8370e-01, time/batch = 15.5562s	
8473/22750 (epoch 18.622), train_loss = 0.84300147, grad/param norm = 1.7444e-01, time/batch = 15.5582s	
8474/22750 (epoch 18.624), train_loss = 0.93624435, grad/param norm = 1.8059e-01, time/batch = 16.0563s	
8475/22750 (epoch 18.626), train_loss = 0.85578470, grad/param norm = 1.7273e-01, time/batch = 15.6697s	
8476/22750 (epoch 18.629), train_loss = 0.95865805, grad/param norm = 1.9077e-01, time/batch = 16.0737s	
8477/22750 (epoch 18.631), train_loss = 1.01590123, grad/param norm = 1.8068e-01, time/batch = 15.6751s	
8478/22750 (epoch 18.633), train_loss = 0.87841420, grad/param norm = 1.8010e-01, time/batch = 15.1283s	
8479/22750 (epoch 18.635), train_loss = 1.03824780, grad/param norm = 1.8037e-01, time/batch = 15.7483s	
8480/22750 (epoch 18.637), train_loss = 1.09927964, grad/param norm = 2.0703e-01, time/batch = 15.7721s	
8481/22750 (epoch 18.640), train_loss = 1.09925413, grad/param norm = 1.9907e-01, time/batch = 15.0609s	
8482/22750 (epoch 18.642), train_loss = 1.16658008, grad/param norm = 2.1357e-01, time/batch = 14.9880s	
8483/22750 (epoch 18.644), train_loss = 1.04712554, grad/param norm = 2.0194e-01, time/batch = 14.9921s	
8484/22750 (epoch 18.646), train_loss = 1.10116387, grad/param norm = 2.4018e-01, time/batch = 15.9400s	
8485/22750 (epoch 18.648), train_loss = 1.06121677, grad/param norm = 1.9680e-01, time/batch = 14.9758s	
8486/22750 (epoch 18.651), train_loss = 1.08666518, grad/param norm = 1.8922e-01, time/batch = 15.2112s	
8487/22750 (epoch 18.653), train_loss = 1.10253110, grad/param norm = 1.8935e-01, time/batch = 15.3495s	
8488/22750 (epoch 18.655), train_loss = 1.06037199, grad/param norm = 1.8453e-01, time/batch = 16.1545s	
8489/22750 (epoch 18.657), train_loss = 1.21934689, grad/param norm = 2.0478e-01, time/batch = 16.4576s	
8490/22750 (epoch 18.659), train_loss = 1.28077937, grad/param norm = 2.1682e-01, time/batch = 15.1133s	
8491/22750 (epoch 18.662), train_loss = 1.26594528, grad/param norm = 2.1742e-01, time/batch = 15.2898s	
8492/22750 (epoch 18.664), train_loss = 1.10022991, grad/param norm = 2.0628e-01, time/batch = 15.5341s	
8493/22750 (epoch 18.666), train_loss = 0.89747937, grad/param norm = 1.8862e-01, time/batch = 14.9805s	
8494/22750 (epoch 18.668), train_loss = 1.05258025, grad/param norm = 1.8777e-01, time/batch = 15.4647s	
8495/22750 (epoch 18.670), train_loss = 1.05359833, grad/param norm = 2.1692e-01, time/batch = 15.1270s	
8496/22750 (epoch 18.673), train_loss = 1.32120694, grad/param norm = 2.2443e-01, time/batch = 15.3086s	
8497/22750 (epoch 18.675), train_loss = 1.45134786, grad/param norm = 2.3948e-01, time/batch = 15.0503s	
8498/22750 (epoch 18.677), train_loss = 1.21469735, grad/param norm = 2.0911e-01, time/batch = 15.2114s	
8499/22750 (epoch 18.679), train_loss = 1.28215188, grad/param norm = 2.1699e-01, time/batch = 15.3802s	
8500/22750 (epoch 18.681), train_loss = 1.22309657, grad/param norm = 1.9681e-01, time/batch = 15.5257s	
8501/22750 (epoch 18.684), train_loss = 1.23914524, grad/param norm = 2.1566e-01, time/batch = 15.2913s	
8502/22750 (epoch 18.686), train_loss = 1.23984759, grad/param norm = 2.1886e-01, time/batch = 15.2068s	
8503/22750 (epoch 18.688), train_loss = 1.21168839, grad/param norm = 2.1351e-01, time/batch = 16.0125s	
8504/22750 (epoch 18.690), train_loss = 1.20240261, grad/param norm = 2.1959e-01, time/batch = 15.2333s	
8505/22750 (epoch 18.692), train_loss = 1.24439719, grad/param norm = 2.0648e-01, time/batch = 15.2257s	
8506/22750 (epoch 18.695), train_loss = 1.11176408, grad/param norm = 1.9506e-01, time/batch = 15.6224s	
8507/22750 (epoch 18.697), train_loss = 1.06432947, grad/param norm = 1.9903e-01, time/batch = 15.5515s	
8508/22750 (epoch 18.699), train_loss = 1.06829683, grad/param norm = 2.0707e-01, time/batch = 19.3301s	
8509/22750 (epoch 18.701), train_loss = 0.91817911, grad/param norm = 1.8790e-01, time/batch = 19.1705s	
8510/22750 (epoch 18.703), train_loss = 1.05382908, grad/param norm = 1.8758e-01, time/batch = 19.0798s	
8511/22750 (epoch 18.705), train_loss = 0.98756212, grad/param norm = 1.8259e-01, time/batch = 16.4846s	
8512/22750 (epoch 18.708), train_loss = 1.07165084, grad/param norm = 1.8456e-01, time/batch = 15.8325s	
8513/22750 (epoch 18.710), train_loss = 0.93537501, grad/param norm = 2.2002e-01, time/batch = 16.6345s	
8514/22750 (epoch 18.712), train_loss = 0.92991738, grad/param norm = 1.8334e-01, time/batch = 16.6377s	
8515/22750 (epoch 18.714), train_loss = 0.86204137, grad/param norm = 1.7738e-01, time/batch = 18.8695s	
8516/22750 (epoch 18.716), train_loss = 0.93489716, grad/param norm = 1.9413e-01, time/batch = 19.9372s	
8517/22750 (epoch 18.719), train_loss = 1.12580561, grad/param norm = 2.3472e-01, time/batch = 17.7543s	
8518/22750 (epoch 18.721), train_loss = 1.16690891, grad/param norm = 1.8909e-01, time/batch = 17.8600s	
8519/22750 (epoch 18.723), train_loss = 1.12980352, grad/param norm = 2.1475e-01, time/batch = 17.7721s	
8520/22750 (epoch 18.725), train_loss = 1.03590010, grad/param norm = 2.0875e-01, time/batch = 18.2498s	
8521/22750 (epoch 18.727), train_loss = 0.99560665, grad/param norm = 1.8389e-01, time/batch = 19.8915s	
8522/22750 (epoch 18.730), train_loss = 1.00912531, grad/param norm = 2.0904e-01, time/batch = 18.2792s	
8523/22750 (epoch 18.732), train_loss = 0.94093061, grad/param norm = 1.7282e-01, time/batch = 19.6874s	
8524/22750 (epoch 18.734), train_loss = 0.82319006, grad/param norm = 1.6497e-01, time/batch = 19.8587s	
8525/22750 (epoch 18.736), train_loss = 0.98195776, grad/param norm = 1.9453e-01, time/batch = 16.9376s	
8526/22750 (epoch 18.738), train_loss = 1.10316530, grad/param norm = 2.1185e-01, time/batch = 15.6162s	
8527/22750 (epoch 18.741), train_loss = 1.17073754, grad/param norm = 2.1395e-01, time/batch = 16.2717s	
8528/22750 (epoch 18.743), train_loss = 1.09917786, grad/param norm = 1.8147e-01, time/batch = 18.7589s	
8529/22750 (epoch 18.745), train_loss = 0.91743181, grad/param norm = 1.8013e-01, time/batch = 17.9964s	
8530/22750 (epoch 18.747), train_loss = 0.97627522, grad/param norm = 1.7798e-01, time/batch = 18.4067s	
8531/22750 (epoch 18.749), train_loss = 1.22636224, grad/param norm = 2.1980e-01, time/batch = 18.1689s	
8532/22750 (epoch 18.752), train_loss = 1.02462184, grad/param norm = 1.9101e-01, time/batch = 19.6184s	
8533/22750 (epoch 18.754), train_loss = 1.07648138, grad/param norm = 2.0960e-01, time/batch = 19.6197s	
8534/22750 (epoch 18.756), train_loss = 0.93808817, grad/param norm = 2.0654e-01, time/batch = 19.1862s	
8535/22750 (epoch 18.758), train_loss = 0.93244804, grad/param norm = 1.8885e-01, time/batch = 18.9108s	
8536/22750 (epoch 18.760), train_loss = 1.00831281, grad/param norm = 1.9299e-01, time/batch = 17.2746s	
8537/22750 (epoch 18.763), train_loss = 1.07261236, grad/param norm = 1.9453e-01, time/batch = 17.1502s	
8538/22750 (epoch 18.765), train_loss = 1.04331959, grad/param norm = 2.0920e-01, time/batch = 18.0894s	
8539/22750 (epoch 18.767), train_loss = 1.08935476, grad/param norm = 1.8824e-01, time/batch = 15.9916s	
8540/22750 (epoch 18.769), train_loss = 1.30617689, grad/param norm = 2.3777e-01, time/batch = 16.0212s	
8541/22750 (epoch 18.771), train_loss = 1.20370733, grad/param norm = 2.3116e-01, time/batch = 16.8075s	
8542/22750 (epoch 18.774), train_loss = 1.01340697, grad/param norm = 2.3298e-01, time/batch = 17.6790s	
8543/22750 (epoch 18.776), train_loss = 1.11280315, grad/param norm = 2.2519e-01, time/batch = 18.6825s	
8544/22750 (epoch 18.778), train_loss = 1.24547477, grad/param norm = 2.1340e-01, time/batch = 17.0052s	
8545/22750 (epoch 18.780), train_loss = 1.08014048, grad/param norm = 1.9904e-01, time/batch = 19.0840s	
8546/22750 (epoch 18.782), train_loss = 1.21975997, grad/param norm = 2.1092e-01, time/batch = 17.0141s	
8547/22750 (epoch 18.785), train_loss = 1.05881442, grad/param norm = 1.9302e-01, time/batch = 16.6533s	
8548/22750 (epoch 18.787), train_loss = 0.96103041, grad/param norm = 2.0153e-01, time/batch = 17.6473s	
8549/22750 (epoch 18.789), train_loss = 1.02536453, grad/param norm = 1.8332e-01, time/batch = 18.9228s	
8550/22750 (epoch 18.791), train_loss = 1.01618433, grad/param norm = 1.8798e-01, time/batch = 18.6674s	
8551/22750 (epoch 18.793), train_loss = 0.95950728, grad/param norm = 1.9506e-01, time/batch = 19.8370s	
8552/22750 (epoch 18.796), train_loss = 0.85938039, grad/param norm = 1.6637e-01, time/batch = 20.8551s	
8553/22750 (epoch 18.798), train_loss = 0.92761118, grad/param norm = 1.7505e-01, time/batch = 19.0929s	
8554/22750 (epoch 18.800), train_loss = 0.96601488, grad/param norm = 1.7801e-01, time/batch = 19.5774s	
8555/22750 (epoch 18.802), train_loss = 0.89765109, grad/param norm = 1.9176e-01, time/batch = 19.6562s	
8556/22750 (epoch 18.804), train_loss = 1.20905805, grad/param norm = 2.0312e-01, time/batch = 18.0046s	
8557/22750 (epoch 18.807), train_loss = 1.13055848, grad/param norm = 1.9697e-01, time/batch = 18.1760s	
8558/22750 (epoch 18.809), train_loss = 1.23856880, grad/param norm = 2.1187e-01, time/batch = 17.5680s	
8559/22750 (epoch 18.811), train_loss = 0.99477437, grad/param norm = 1.8759e-01, time/batch = 20.4276s	
8560/22750 (epoch 18.813), train_loss = 1.10714816, grad/param norm = 1.8917e-01, time/batch = 19.0215s	
8561/22750 (epoch 18.815), train_loss = 1.22646263, grad/param norm = 2.0354e-01, time/batch = 18.8639s	
8562/22750 (epoch 18.818), train_loss = 1.18690084, grad/param norm = 1.9009e-01, time/batch = 18.1885s	
8563/22750 (epoch 18.820), train_loss = 1.31006528, grad/param norm = 1.8973e-01, time/batch = 16.7672s	
8564/22750 (epoch 18.822), train_loss = 1.10826991, grad/param norm = 1.8870e-01, time/batch = 18.5877s	
8565/22750 (epoch 18.824), train_loss = 0.97055564, grad/param norm = 1.7184e-01, time/batch = 17.3368s	
8566/22750 (epoch 18.826), train_loss = 1.03975858, grad/param norm = 1.7455e-01, time/batch = 18.1569s	
8567/22750 (epoch 18.829), train_loss = 1.22558093, grad/param norm = 2.1016e-01, time/batch = 17.3510s	
8568/22750 (epoch 18.831), train_loss = 1.17720943, grad/param norm = 1.8885e-01, time/batch = 17.4226s	
8569/22750 (epoch 18.833), train_loss = 1.10397068, grad/param norm = 2.1014e-01, time/batch = 19.8510s	
8570/22750 (epoch 18.835), train_loss = 0.98637953, grad/param norm = 1.8111e-01, time/batch = 18.0999s	
8571/22750 (epoch 18.837), train_loss = 1.00802178, grad/param norm = 1.9358e-01, time/batch = 18.6744s	
8572/22750 (epoch 18.840), train_loss = 0.94023953, grad/param norm = 1.8658e-01, time/batch = 18.6752s	
8573/22750 (epoch 18.842), train_loss = 0.99210037, grad/param norm = 2.1395e-01, time/batch = 16.1803s	
8574/22750 (epoch 18.844), train_loss = 1.12090489, grad/param norm = 1.9992e-01, time/batch = 17.4131s	
8575/22750 (epoch 18.846), train_loss = 1.09474569, grad/param norm = 2.0942e-01, time/batch = 16.3561s	
8576/22750 (epoch 18.848), train_loss = 0.97896643, grad/param norm = 1.6827e-01, time/batch = 17.3308s	
8577/22750 (epoch 18.851), train_loss = 0.94258350, grad/param norm = 1.8015e-01, time/batch = 17.9162s	
8578/22750 (epoch 18.853), train_loss = 1.10366581, grad/param norm = 1.9295e-01, time/batch = 18.0217s	
8579/22750 (epoch 18.855), train_loss = 0.91859546, grad/param norm = 1.6426e-01, time/batch = 19.8573s	
8580/22750 (epoch 18.857), train_loss = 1.07820152, grad/param norm = 1.7795e-01, time/batch = 18.5317s	
8581/22750 (epoch 18.859), train_loss = 1.12750346, grad/param norm = 2.1323e-01, time/batch = 16.3490s	
8582/22750 (epoch 18.862), train_loss = 1.23664488, grad/param norm = 2.0947e-01, time/batch = 18.6589s	
8583/22750 (epoch 18.864), train_loss = 1.07044499, grad/param norm = 1.9302e-01, time/batch = 17.7442s	
8584/22750 (epoch 18.866), train_loss = 1.08938686, grad/param norm = 1.6921e-01, time/batch = 16.6320s	
8585/22750 (epoch 18.868), train_loss = 0.98274041, grad/param norm = 1.7490e-01, time/batch = 17.5088s	
8586/22750 (epoch 18.870), train_loss = 0.85169237, grad/param norm = 1.8289e-01, time/batch = 16.7603s	
8587/22750 (epoch 18.873), train_loss = 1.00333934, grad/param norm = 1.7131e-01, time/batch = 17.8372s	
8588/22750 (epoch 18.875), train_loss = 1.12509098, grad/param norm = 1.9602e-01, time/batch = 19.0243s	
8589/22750 (epoch 18.877), train_loss = 0.94679566, grad/param norm = 1.7622e-01, time/batch = 18.8707s	
8590/22750 (epoch 18.879), train_loss = 1.20736607, grad/param norm = 2.0939e-01, time/batch = 18.4431s	
8591/22750 (epoch 18.881), train_loss = 1.13596900, grad/param norm = 1.9851e-01, time/batch = 16.6815s	
8592/22750 (epoch 18.884), train_loss = 0.97793623, grad/param norm = 1.9569e-01, time/batch = 19.0093s	
8593/22750 (epoch 18.886), train_loss = 1.11952804, grad/param norm = 1.8727e-01, time/batch = 18.0815s	
8594/22750 (epoch 18.888), train_loss = 1.11890122, grad/param norm = 1.8804e-01, time/batch = 18.6664s	
8595/22750 (epoch 18.890), train_loss = 1.15072300, grad/param norm = 1.9315e-01, time/batch = 18.5783s	
8596/22750 (epoch 18.892), train_loss = 1.41550915, grad/param norm = 2.2986e-01, time/batch = 17.4260s	
8597/22750 (epoch 18.895), train_loss = 1.11078957, grad/param norm = 2.0264e-01, time/batch = 18.7069s	
8598/22750 (epoch 18.897), train_loss = 1.17174939, grad/param norm = 2.0478e-01, time/batch = 20.1820s	
8599/22750 (epoch 18.899), train_loss = 1.10949670, grad/param norm = 1.9404e-01, time/batch = 17.4230s	
8600/22750 (epoch 18.901), train_loss = 1.22747146, grad/param norm = 2.1223e-01, time/batch = 19.0666s	
8601/22750 (epoch 18.903), train_loss = 1.05445966, grad/param norm = 2.1005e-01, time/batch = 16.8530s	
8602/22750 (epoch 18.905), train_loss = 1.16873342, grad/param norm = 2.0611e-01, time/batch = 18.4992s	
8603/22750 (epoch 18.908), train_loss = 0.98283600, grad/param norm = 1.9774e-01, time/batch = 18.8002s	
8604/22750 (epoch 18.910), train_loss = 0.86074590, grad/param norm = 1.9797e-01, time/batch = 19.4078s	
8605/22750 (epoch 18.912), train_loss = 1.00916308, grad/param norm = 1.9777e-01, time/batch = 18.2694s	
8606/22750 (epoch 18.914), train_loss = 1.05568292, grad/param norm = 1.7887e-01, time/batch = 18.3468s	
8607/22750 (epoch 18.916), train_loss = 0.89587802, grad/param norm = 1.8664e-01, time/batch = 19.1939s	
8608/22750 (epoch 18.919), train_loss = 1.02165531, grad/param norm = 2.1618e-01, time/batch = 20.3651s	
8609/22750 (epoch 18.921), train_loss = 0.77255562, grad/param norm = 1.6309e-01, time/batch = 18.5974s	
8610/22750 (epoch 18.923), train_loss = 0.93527118, grad/param norm = 1.7406e-01, time/batch = 18.1760s	
8611/22750 (epoch 18.925), train_loss = 1.02721279, grad/param norm = 1.7701e-01, time/batch = 17.3919s	
8612/22750 (epoch 18.927), train_loss = 0.82315865, grad/param norm = 1.8946e-01, time/batch = 16.9705s	
8613/22750 (epoch 18.930), train_loss = 0.83671129, grad/param norm = 1.6562e-01, time/batch = 19.4834s	
8614/22750 (epoch 18.932), train_loss = 1.07032006, grad/param norm = 1.9181e-01, time/batch = 19.7459s	
8615/22750 (epoch 18.934), train_loss = 0.79701468, grad/param norm = 1.5166e-01, time/batch = 19.1239s	
8616/22750 (epoch 18.936), train_loss = 1.16600582, grad/param norm = 2.1614e-01, time/batch = 19.0378s	
8617/22750 (epoch 18.938), train_loss = 1.10478866, grad/param norm = 1.7071e-01, time/batch = 19.7848s	
8618/22750 (epoch 18.941), train_loss = 1.22840675, grad/param norm = 1.9578e-01, time/batch = 18.9223s	
8619/22750 (epoch 18.943), train_loss = 1.08268004, grad/param norm = 1.9173e-01, time/batch = 18.7493s	
8620/22750 (epoch 18.945), train_loss = 1.07017750, grad/param norm = 2.0379e-01, time/batch = 19.1700s	
8621/22750 (epoch 18.947), train_loss = 1.01066920, grad/param norm = 2.1166e-01, time/batch = 19.1708s	
8622/22750 (epoch 18.949), train_loss = 0.93913611, grad/param norm = 1.8319e-01, time/batch = 17.3962s	
8623/22750 (epoch 18.952), train_loss = 0.95595708, grad/param norm = 1.6483e-01, time/batch = 19.9935s	
8624/22750 (epoch 18.954), train_loss = 0.94094763, grad/param norm = 1.7839e-01, time/batch = 20.4353s	
8625/22750 (epoch 18.956), train_loss = 1.05020836, grad/param norm = 1.8233e-01, time/batch = 19.0904s	
8626/22750 (epoch 18.958), train_loss = 0.97830892, grad/param norm = 1.6229e-01, time/batch = 17.8363s	
8627/22750 (epoch 18.960), train_loss = 0.93888411, grad/param norm = 1.6864e-01, time/batch = 19.9041s	
8628/22750 (epoch 18.963), train_loss = 1.14863030, grad/param norm = 2.0314e-01, time/batch = 18.3348s	
8629/22750 (epoch 18.965), train_loss = 1.12670993, grad/param norm = 1.8663e-01, time/batch = 18.9081s	
8630/22750 (epoch 18.967), train_loss = 1.04093542, grad/param norm = 1.9081e-01, time/batch = 20.0611s	
8631/22750 (epoch 18.969), train_loss = 0.95648017, grad/param norm = 1.9098e-01, time/batch = 17.8298s	
8632/22750 (epoch 18.971), train_loss = 1.00198460, grad/param norm = 1.9352e-01, time/batch = 20.1524s	
8633/22750 (epoch 18.974), train_loss = 1.02953597, grad/param norm = 2.0411e-01, time/batch = 19.0307s	
8634/22750 (epoch 18.976), train_loss = 1.08309138, grad/param norm = 1.9365e-01, time/batch = 26.6569s	
8635/22750 (epoch 18.978), train_loss = 0.95304626, grad/param norm = 1.8194e-01, time/batch = 25.3357s	
8636/22750 (epoch 18.980), train_loss = 1.18559213, grad/param norm = 2.1974e-01, time/batch = 15.9027s	
8637/22750 (epoch 18.982), train_loss = 0.95842545, grad/param norm = 1.7028e-01, time/batch = 17.0664s	
8638/22750 (epoch 18.985), train_loss = 1.24254897, grad/param norm = 2.0031e-01, time/batch = 16.0176s	
8639/22750 (epoch 18.987), train_loss = 0.82374149, grad/param norm = 1.6723e-01, time/batch = 15.3686s	
8640/22750 (epoch 18.989), train_loss = 0.98864065, grad/param norm = 1.8660e-01, time/batch = 15.2926s	
8641/22750 (epoch 18.991), train_loss = 1.10007166, grad/param norm = 2.0170e-01, time/batch = 15.7829s	
8642/22750 (epoch 18.993), train_loss = 1.12407143, grad/param norm = 2.0810e-01, time/batch = 15.4533s	
8643/22750 (epoch 18.996), train_loss = 0.96303106, grad/param norm = 2.1665e-01, time/batch = 15.4658s	
8644/22750 (epoch 18.998), train_loss = 1.19127843, grad/param norm = 2.0402e-01, time/batch = 15.3167s	
decayed learning rate by a factor 0.97 to 0.0014748482537899	
8645/22750 (epoch 19.000), train_loss = 1.09498872, grad/param norm = 2.0128e-01, time/batch = 15.4741s	
8646/22750 (epoch 19.002), train_loss = 1.19911192, grad/param norm = 2.0090e-01, time/batch = 15.3852s	
8647/22750 (epoch 19.004), train_loss = 0.97846396, grad/param norm = 1.8222e-01, time/batch = 15.2142s	
8648/22750 (epoch 19.007), train_loss = 1.00249140, grad/param norm = 1.8810e-01, time/batch = 16.1508s	
8649/22750 (epoch 19.009), train_loss = 1.24816545, grad/param norm = 2.2559e-01, time/batch = 15.5379s	
8650/22750 (epoch 19.011), train_loss = 1.29635024, grad/param norm = 2.2133e-01, time/batch = 15.2941s	
8651/22750 (epoch 19.013), train_loss = 1.16912028, grad/param norm = 2.0334e-01, time/batch = 15.3752s	
8652/22750 (epoch 19.015), train_loss = 1.08207899, grad/param norm = 2.1778e-01, time/batch = 11.3479s	
8653/22750 (epoch 19.018), train_loss = 1.13601022, grad/param norm = 1.9412e-01, time/batch = 0.7065s	
8654/22750 (epoch 19.020), train_loss = 1.19347374, grad/param norm = 1.9321e-01, time/batch = 0.6980s	
8655/22750 (epoch 19.022), train_loss = 1.06548198, grad/param norm = 2.0104e-01, time/batch = 0.7119s	
8656/22750 (epoch 19.024), train_loss = 1.06259379, grad/param norm = 1.9936e-01, time/batch = 0.7069s	
8657/22750 (epoch 19.026), train_loss = 1.13051717, grad/param norm = 2.0926e-01, time/batch = 0.7111s	
8658/22750 (epoch 19.029), train_loss = 0.87025431, grad/param norm = 1.7185e-01, time/batch = 0.6993s	
8659/22750 (epoch 19.031), train_loss = 1.31809765, grad/param norm = 2.0422e-01, time/batch = 0.7618s	
8660/22750 (epoch 19.033), train_loss = 1.07673504, grad/param norm = 1.8606e-01, time/batch = 1.0416s	
8661/22750 (epoch 19.035), train_loss = 1.11687982, grad/param norm = 1.9061e-01, time/batch = 1.0498s	
8662/22750 (epoch 19.037), train_loss = 1.19638940, grad/param norm = 1.9737e-01, time/batch = 1.0297s	
8663/22750 (epoch 19.040), train_loss = 1.03027320, grad/param norm = 2.0548e-01, time/batch = 1.0302s	
8664/22750 (epoch 19.042), train_loss = 1.14313390, grad/param norm = 2.1727e-01, time/batch = 1.4574s	
8665/22750 (epoch 19.044), train_loss = 1.01463618, grad/param norm = 1.9719e-01, time/batch = 1.9369s	
8666/22750 (epoch 19.046), train_loss = 1.17675597, grad/param norm = 2.2342e-01, time/batch = 1.9031s	
8667/22750 (epoch 19.048), train_loss = 1.05299746, grad/param norm = 1.9108e-01, time/batch = 13.5304s	
8668/22750 (epoch 19.051), train_loss = 1.13682601, grad/param norm = 1.9878e-01, time/batch = 14.9108s	
8669/22750 (epoch 19.053), train_loss = 0.95527894, grad/param norm = 1.6487e-01, time/batch = 15.3159s	
8670/22750 (epoch 19.055), train_loss = 0.97530818, grad/param norm = 1.8814e-01, time/batch = 15.1509s	
8671/22750 (epoch 19.057), train_loss = 1.22604053, grad/param norm = 1.9246e-01, time/batch = 15.8502s	
8672/22750 (epoch 19.059), train_loss = 0.79872812, grad/param norm = 1.7573e-01, time/batch = 15.1258s	
8673/22750 (epoch 19.062), train_loss = 0.92201823, grad/param norm = 1.8819e-01, time/batch = 15.2698s	
8674/22750 (epoch 19.064), train_loss = 1.12383070, grad/param norm = 2.1204e-01, time/batch = 15.0400s	
8675/22750 (epoch 19.066), train_loss = 0.90793538, grad/param norm = 1.7598e-01, time/batch = 15.2921s	
8676/22750 (epoch 19.068), train_loss = 0.97418999, grad/param norm = 1.7641e-01, time/batch = 15.1107s	
8677/22750 (epoch 19.070), train_loss = 0.79954246, grad/param norm = 1.5808e-01, time/batch = 15.8575s	
8678/22750 (epoch 19.073), train_loss = 0.99400343, grad/param norm = 2.0304e-01, time/batch = 14.8314s	
8679/22750 (epoch 19.075), train_loss = 1.01551194, grad/param norm = 1.7971e-01, time/batch = 14.6655s	
8680/22750 (epoch 19.077), train_loss = 0.80549315, grad/param norm = 1.8840e-01, time/batch = 14.9807s	
8681/22750 (epoch 19.079), train_loss = 1.00792922, grad/param norm = 2.1789e-01, time/batch = 15.5497s	
8682/22750 (epoch 19.081), train_loss = 1.00068164, grad/param norm = 1.9515e-01, time/batch = 15.2888s	
8683/22750 (epoch 19.084), train_loss = 0.99189803, grad/param norm = 1.8557e-01, time/batch = 15.2920s	
8684/22750 (epoch 19.086), train_loss = 0.99999374, grad/param norm = 1.6789e-01, time/batch = 15.2877s	
8685/22750 (epoch 19.088), train_loss = 0.95828913, grad/param norm = 1.9273e-01, time/batch = 15.8387s	
8686/22750 (epoch 19.090), train_loss = 0.94611518, grad/param norm = 1.7676e-01, time/batch = 15.0488s	
8687/22750 (epoch 19.092), train_loss = 1.16545110, grad/param norm = 1.8347e-01, time/batch = 15.4440s	
8688/22750 (epoch 19.095), train_loss = 0.92719593, grad/param norm = 1.8613e-01, time/batch = 15.0553s	
8689/22750 (epoch 19.097), train_loss = 1.02646495, grad/param norm = 1.8624e-01, time/batch = 15.7328s	
8690/22750 (epoch 19.099), train_loss = 1.01859415, grad/param norm = 1.8917e-01, time/batch = 14.9047s	
8691/22750 (epoch 19.101), train_loss = 0.90743577, grad/param norm = 1.7989e-01, time/batch = 14.9892s	
8692/22750 (epoch 19.103), train_loss = 1.04031037, grad/param norm = 1.8157e-01, time/batch = 15.7045s	
8693/22750 (epoch 19.105), train_loss = 1.24445693, grad/param norm = 2.1356e-01, time/batch = 15.6936s	
8694/22750 (epoch 19.108), train_loss = 1.00727697, grad/param norm = 1.9313e-01, time/batch = 15.2086s	
8695/22750 (epoch 19.110), train_loss = 1.17041251, grad/param norm = 1.8713e-01, time/batch = 15.4431s	
8696/22750 (epoch 19.112), train_loss = 0.88201776, grad/param norm = 1.7357e-01, time/batch = 14.9650s	
8697/22750 (epoch 19.114), train_loss = 0.82551160, grad/param norm = 1.7873e-01, time/batch = 15.8346s	
8698/22750 (epoch 19.116), train_loss = 0.94381993, grad/param norm = 1.7079e-01, time/batch = 16.4623s	
8699/22750 (epoch 19.119), train_loss = 0.95163111, grad/param norm = 1.7414e-01, time/batch = 16.0216s	
8700/22750 (epoch 19.121), train_loss = 1.06487625, grad/param norm = 2.0007e-01, time/batch = 15.2211s	
8701/22750 (epoch 19.123), train_loss = 0.91683443, grad/param norm = 1.9143e-01, time/batch = 15.4732s	
8702/22750 (epoch 19.125), train_loss = 1.19258946, grad/param norm = 1.9218e-01, time/batch = 15.1480s	
8703/22750 (epoch 19.127), train_loss = 0.99854221, grad/param norm = 1.9269e-01, time/batch = 14.9825s	
8704/22750 (epoch 19.130), train_loss = 1.02575455, grad/param norm = 1.7130e-01, time/batch = 15.6068s	
8705/22750 (epoch 19.132), train_loss = 0.95492738, grad/param norm = 1.9277e-01, time/batch = 15.3694s	
8706/22750 (epoch 19.134), train_loss = 0.98266322, grad/param norm = 1.9081e-01, time/batch = 15.6095s	
8707/22750 (epoch 19.136), train_loss = 0.87749215, grad/param norm = 2.0219e-01, time/batch = 15.2859s	
8708/22750 (epoch 19.138), train_loss = 1.08479791, grad/param norm = 1.8410e-01, time/batch = 15.7752s	
8709/22750 (epoch 19.141), train_loss = 1.03999566, grad/param norm = 1.8987e-01, time/batch = 15.3450s	
8710/22750 (epoch 19.143), train_loss = 0.91253736, grad/param norm = 1.7302e-01, time/batch = 15.8943s	
8711/22750 (epoch 19.145), train_loss = 1.18125142, grad/param norm = 2.0227e-01, time/batch = 15.3620s	
8712/22750 (epoch 19.147), train_loss = 1.17910464, grad/param norm = 1.9999e-01, time/batch = 15.6959s	
8713/22750 (epoch 19.149), train_loss = 1.04458112, grad/param norm = 1.9477e-01, time/batch = 15.6563s	
8714/22750 (epoch 19.152), train_loss = 1.03244111, grad/param norm = 1.8294e-01, time/batch = 15.6729s	
8715/22750 (epoch 19.154), train_loss = 0.86261812, grad/param norm = 1.8268e-01, time/batch = 15.3516s	
8716/22750 (epoch 19.156), train_loss = 0.89163212, grad/param norm = 1.8356e-01, time/batch = 15.7616s	
8717/22750 (epoch 19.158), train_loss = 0.95618210, grad/param norm = 2.0220e-01, time/batch = 15.2883s	
8718/22750 (epoch 19.160), train_loss = 1.08423038, grad/param norm = 2.0031e-01, time/batch = 15.2799s	
8719/22750 (epoch 19.163), train_loss = 1.26292803, grad/param norm = 2.1153e-01, time/batch = 15.3572s	
8720/22750 (epoch 19.165), train_loss = 1.09973560, grad/param norm = 1.9678e-01, time/batch = 15.9081s	
8721/22750 (epoch 19.167), train_loss = 0.99831851, grad/param norm = 2.1213e-01, time/batch = 15.6783s	
8722/22750 (epoch 19.169), train_loss = 1.02814416, grad/param norm = 2.0965e-01, time/batch = 15.4078s	
8723/22750 (epoch 19.171), train_loss = 0.91044753, grad/param norm = 1.9126e-01, time/batch = 15.2725s	
8724/22750 (epoch 19.174), train_loss = 0.85314995, grad/param norm = 1.8304e-01, time/batch = 15.4382s	
8725/22750 (epoch 19.176), train_loss = 0.96626758, grad/param norm = 1.8217e-01, time/batch = 15.4385s	
8726/22750 (epoch 19.178), train_loss = 0.96643958, grad/param norm = 1.7969e-01, time/batch = 15.1926s	
8727/22750 (epoch 19.180), train_loss = 1.13166046, grad/param norm = 2.2423e-01, time/batch = 15.2824s	
8728/22750 (epoch 19.182), train_loss = 1.16137309, grad/param norm = 2.0692e-01, time/batch = 16.3732s	
8729/22750 (epoch 19.185), train_loss = 1.18669490, grad/param norm = 2.1222e-01, time/batch = 16.6724s	
8730/22750 (epoch 19.187), train_loss = 0.94814913, grad/param norm = 1.9530e-01, time/batch = 17.5014s	
8731/22750 (epoch 19.189), train_loss = 0.95437334, grad/param norm = 1.9054e-01, time/batch = 17.5382s	
8732/22750 (epoch 19.191), train_loss = 0.93460450, grad/param norm = 1.6991e-01, time/batch = 18.5779s	
8733/22750 (epoch 19.193), train_loss = 1.10180558, grad/param norm = 1.9951e-01, time/batch = 18.6003s	
8734/22750 (epoch 19.196), train_loss = 1.01178959, grad/param norm = 1.9737e-01, time/batch = 18.2599s	
8735/22750 (epoch 19.198), train_loss = 0.76182414, grad/param norm = 1.5181e-01, time/batch = 18.5868s	
8736/22750 (epoch 19.200), train_loss = 1.04903372, grad/param norm = 1.8457e-01, time/batch = 15.7795s	
8737/22750 (epoch 19.202), train_loss = 1.12611389, grad/param norm = 2.0654e-01, time/batch = 17.4756s	
8738/22750 (epoch 19.204), train_loss = 1.01926956, grad/param norm = 1.7060e-01, time/batch = 18.0037s	
8739/22750 (epoch 19.207), train_loss = 0.99855481, grad/param norm = 1.8444e-01, time/batch = 17.9219s	
8740/22750 (epoch 19.209), train_loss = 0.94200491, grad/param norm = 1.9255e-01, time/batch = 19.4205s	
8741/22750 (epoch 19.211), train_loss = 0.94729593, grad/param norm = 1.9665e-01, time/batch = 17.0065s	
8742/22750 (epoch 19.213), train_loss = 0.84796349, grad/param norm = 1.6930e-01, time/batch = 19.7647s	
8743/22750 (epoch 19.215), train_loss = 0.78337471, grad/param norm = 1.6610e-01, time/batch = 19.6123s	
8744/22750 (epoch 19.218), train_loss = 0.88728636, grad/param norm = 1.8877e-01, time/batch = 17.5044s	
8745/22750 (epoch 19.220), train_loss = 0.87163548, grad/param norm = 1.7303e-01, time/batch = 17.7661s	
8746/22750 (epoch 19.222), train_loss = 0.86033757, grad/param norm = 1.8488e-01, time/batch = 19.1628s	
8747/22750 (epoch 19.224), train_loss = 0.92826623, grad/param norm = 1.8398e-01, time/batch = 18.3353s	
8748/22750 (epoch 19.226), train_loss = 1.08921630, grad/param norm = 1.9853e-01, time/batch = 16.8524s	
8749/22750 (epoch 19.229), train_loss = 1.04523773, grad/param norm = 2.0746e-01, time/batch = 17.7600s	
8750/22750 (epoch 19.231), train_loss = 0.94217035, grad/param norm = 1.9436e-01, time/batch = 20.8489s	
8751/22750 (epoch 19.233), train_loss = 0.88430911, grad/param norm = 1.9447e-01, time/batch = 18.3683s	
8752/22750 (epoch 19.235), train_loss = 0.83065407, grad/param norm = 1.8252e-01, time/batch = 18.3346s	
8753/22750 (epoch 19.237), train_loss = 0.94713220, grad/param norm = 2.0277e-01, time/batch = 16.7536s	
8754/22750 (epoch 19.240), train_loss = 0.99454499, grad/param norm = 1.7990e-01, time/batch = 17.7725s	
8755/22750 (epoch 19.242), train_loss = 1.25107527, grad/param norm = 2.2326e-01, time/batch = 18.5815s	
8756/22750 (epoch 19.244), train_loss = 1.15607027, grad/param norm = 1.9291e-01, time/batch = 15.6953s	
8757/22750 (epoch 19.246), train_loss = 1.21268696, grad/param norm = 2.1106e-01, time/batch = 16.6670s	
8758/22750 (epoch 19.248), train_loss = 1.00919764, grad/param norm = 2.1750e-01, time/batch = 17.7370s	
8759/22750 (epoch 19.251), train_loss = 1.16678724, grad/param norm = 1.9579e-01, time/batch = 16.9250s	
8760/22750 (epoch 19.253), train_loss = 1.04672843, grad/param norm = 2.2327e-01, time/batch = 16.3394s	
8761/22750 (epoch 19.255), train_loss = 1.02496082, grad/param norm = 1.8399e-01, time/batch = 16.8954s	
8762/22750 (epoch 19.257), train_loss = 0.94677352, grad/param norm = 1.9243e-01, time/batch = 16.7048s	
8763/22750 (epoch 19.259), train_loss = 1.14635233, grad/param norm = 2.2221e-01, time/batch = 15.8831s	
8764/22750 (epoch 19.262), train_loss = 1.02591233, grad/param norm = 1.8560e-01, time/batch = 15.9049s	
8765/22750 (epoch 19.264), train_loss = 0.85646289, grad/param norm = 1.9134e-01, time/batch = 17.0077s	
8766/22750 (epoch 19.266), train_loss = 1.04375943, grad/param norm = 2.1375e-01, time/batch = 18.3345s	
8767/22750 (epoch 19.268), train_loss = 1.18527917, grad/param norm = 2.0979e-01, time/batch = 17.4979s	
8768/22750 (epoch 19.270), train_loss = 0.94616837, grad/param norm = 1.9514e-01, time/batch = 17.6898s	
8769/22750 (epoch 19.273), train_loss = 1.31593552, grad/param norm = 2.2355e-01, time/batch = 18.4992s	
8770/22750 (epoch 19.275), train_loss = 1.15593842, grad/param norm = 1.9299e-01, time/batch = 20.1945s	
8771/22750 (epoch 19.277), train_loss = 0.97201336, grad/param norm = 1.9933e-01, time/batch = 18.0227s	
8772/22750 (epoch 19.279), train_loss = 0.86662782, grad/param norm = 1.9446e-01, time/batch = 19.4061s	
8773/22750 (epoch 19.281), train_loss = 1.16739072, grad/param norm = 2.1020e-01, time/batch = 19.0747s	
8774/22750 (epoch 19.284), train_loss = 1.00353760, grad/param norm = 1.8334e-01, time/batch = 17.9822s	
8775/22750 (epoch 19.286), train_loss = 1.15138657, grad/param norm = 2.0068e-01, time/batch = 18.1662s	
8776/22750 (epoch 19.288), train_loss = 1.20568053, grad/param norm = 2.0145e-01, time/batch = 18.4298s	
8777/22750 (epoch 19.290), train_loss = 1.05488816, grad/param norm = 1.9915e-01, time/batch = 20.0258s	
8778/22750 (epoch 19.292), train_loss = 1.11843640, grad/param norm = 2.1809e-01, time/batch = 19.6899s	
8779/22750 (epoch 19.295), train_loss = 1.09302006, grad/param norm = 1.8790e-01, time/batch = 20.5213s	
8780/22750 (epoch 19.297), train_loss = 1.00751777, grad/param norm = 1.8510e-01, time/batch = 18.3000s	
8781/22750 (epoch 19.299), train_loss = 1.16203656, grad/param norm = 1.9462e-01, time/batch = 16.9803s	
8782/22750 (epoch 19.301), train_loss = 1.05924900, grad/param norm = 1.9087e-01, time/batch = 16.8507s	
8783/22750 (epoch 19.303), train_loss = 1.11870142, grad/param norm = 1.9672e-01, time/batch = 15.8469s	
8784/22750 (epoch 19.305), train_loss = 1.25563901, grad/param norm = 2.0342e-01, time/batch = 17.7571s	
8785/22750 (epoch 19.308), train_loss = 1.10065601, grad/param norm = 1.7871e-01, time/batch = 17.2333s	
8786/22750 (epoch 19.310), train_loss = 0.93257196, grad/param norm = 2.0170e-01, time/batch = 20.4472s	
8787/22750 (epoch 19.312), train_loss = 1.06602260, grad/param norm = 1.9854e-01, time/batch = 19.2657s	
8788/22750 (epoch 19.314), train_loss = 1.03349762, grad/param norm = 1.9285e-01, time/batch = 18.2792s	
8789/22750 (epoch 19.316), train_loss = 1.00204063, grad/param norm = 1.8845e-01, time/batch = 19.0233s	
8790/22750 (epoch 19.319), train_loss = 1.04541729, grad/param norm = 1.9685e-01, time/batch = 19.1667s	
8791/22750 (epoch 19.321), train_loss = 0.99058032, grad/param norm = 1.9424e-01, time/batch = 18.2520s	
8792/22750 (epoch 19.323), train_loss = 1.04429956, grad/param norm = 2.0659e-01, time/batch = 17.8303s	
8793/22750 (epoch 19.325), train_loss = 0.88710861, grad/param norm = 1.9920e-01, time/batch = 18.2394s	
8794/22750 (epoch 19.327), train_loss = 1.00887628, grad/param norm = 1.8569e-01, time/batch = 18.9135s	
8795/22750 (epoch 19.330), train_loss = 1.28011941, grad/param norm = 2.0422e-01, time/batch = 18.8815s	
8796/22750 (epoch 19.332), train_loss = 1.25290631, grad/param norm = 1.9462e-01, time/batch = 20.9410s	
8797/22750 (epoch 19.334), train_loss = 0.86214685, grad/param norm = 1.7838e-01, time/batch = 18.1043s	
8798/22750 (epoch 19.336), train_loss = 1.11349546, grad/param norm = 1.9527e-01, time/batch = 18.6072s	
8799/22750 (epoch 19.338), train_loss = 1.00945760, grad/param norm = 1.8909e-01, time/batch = 17.2195s	
8800/22750 (epoch 19.341), train_loss = 1.03274431, grad/param norm = 1.9528e-01, time/batch = 17.9159s	
8801/22750 (epoch 19.343), train_loss = 0.90076878, grad/param norm = 1.8897e-01, time/batch = 19.8131s	
8802/22750 (epoch 19.345), train_loss = 1.14651203, grad/param norm = 2.3218e-01, time/batch = 19.4900s	
8803/22750 (epoch 19.347), train_loss = 1.20067749, grad/param norm = 2.1143e-01, time/batch = 18.7351s	
8804/22750 (epoch 19.349), train_loss = 0.82144339, grad/param norm = 1.8633e-01, time/batch = 18.4425s	
8805/22750 (epoch 19.352), train_loss = 1.14460888, grad/param norm = 2.0657e-01, time/batch = 20.6676s	
8806/22750 (epoch 19.354), train_loss = 1.15715826, grad/param norm = 2.0203e-01, time/batch = 19.4303s	
8807/22750 (epoch 19.356), train_loss = 1.18598658, grad/param norm = 2.1131e-01, time/batch = 17.2559s	
8808/22750 (epoch 19.358), train_loss = 1.05175755, grad/param norm = 1.9733e-01, time/batch = 16.8899s	
8809/22750 (epoch 19.360), train_loss = 1.22945981, grad/param norm = 1.9322e-01, time/batch = 16.7584s	
8810/22750 (epoch 19.363), train_loss = 1.00760851, grad/param norm = 1.8478e-01, time/batch = 16.9922s	
8811/22750 (epoch 19.365), train_loss = 0.83894211, grad/param norm = 1.8308e-01, time/batch = 19.9023s	
8812/22750 (epoch 19.367), train_loss = 0.91334026, grad/param norm = 2.0402e-01, time/batch = 18.6606s	
8813/22750 (epoch 19.369), train_loss = 1.03505964, grad/param norm = 2.0433e-01, time/batch = 18.1874s	
8814/22750 (epoch 19.371), train_loss = 1.01091421, grad/param norm = 1.9684e-01, time/batch = 21.1802s	
8815/22750 (epoch 19.374), train_loss = 0.95773159, grad/param norm = 1.9074e-01, time/batch = 18.8558s	
8816/22750 (epoch 19.376), train_loss = 1.00116123, grad/param norm = 1.8486e-01, time/batch = 17.9266s	
8817/22750 (epoch 19.378), train_loss = 1.04739496, grad/param norm = 1.9134e-01, time/batch = 18.4735s	
8818/22750 (epoch 19.380), train_loss = 1.14979909, grad/param norm = 2.0060e-01, time/batch = 19.0867s	
8819/22750 (epoch 19.382), train_loss = 0.97676909, grad/param norm = 1.7656e-01, time/batch = 19.5690s	
8820/22750 (epoch 19.385), train_loss = 1.11267546, grad/param norm = 1.9288e-01, time/batch = 18.7606s	
8821/22750 (epoch 19.387), train_loss = 1.06176106, grad/param norm = 1.7662e-01, time/batch = 19.4249s	
8822/22750 (epoch 19.389), train_loss = 0.83331731, grad/param norm = 1.7825e-01, time/batch = 19.6788s	
8823/22750 (epoch 19.391), train_loss = 0.64737950, grad/param norm = 1.4676e-01, time/batch = 17.1120s	
8824/22750 (epoch 19.393), train_loss = 0.88145299, grad/param norm = 1.6616e-01, time/batch = 16.9213s	
8825/22750 (epoch 19.396), train_loss = 1.07475878, grad/param norm = 1.9002e-01, time/batch = 18.2418s	
8826/22750 (epoch 19.398), train_loss = 0.99597711, grad/param norm = 1.8831e-01, time/batch = 18.5087s	
8827/22750 (epoch 19.400), train_loss = 1.02094101, grad/param norm = 1.8098e-01, time/batch = 19.2516s	
8828/22750 (epoch 19.402), train_loss = 1.09817547, grad/param norm = 1.9209e-01, time/batch = 17.5915s	
8829/22750 (epoch 19.404), train_loss = 1.18071451, grad/param norm = 2.0628e-01, time/batch = 18.0171s	
8830/22750 (epoch 19.407), train_loss = 1.14052874, grad/param norm = 1.8767e-01, time/batch = 19.2663s	
8831/22750 (epoch 19.409), train_loss = 0.99960232, grad/param norm = 1.9276e-01, time/batch = 19.0201s	
8832/22750 (epoch 19.411), train_loss = 1.01915176, grad/param norm = 1.9981e-01, time/batch = 19.0288s	
8833/22750 (epoch 19.413), train_loss = 0.79469258, grad/param norm = 1.8678e-01, time/batch = 19.4220s	
8834/22750 (epoch 19.415), train_loss = 0.78583555, grad/param norm = 1.7868e-01, time/batch = 18.3127s	
8835/22750 (epoch 19.418), train_loss = 0.97540244, grad/param norm = 1.9495e-01, time/batch = 18.6570s	
8836/22750 (epoch 19.420), train_loss = 1.11656858, grad/param norm = 2.6893e-01, time/batch = 15.7077s	
8837/22750 (epoch 19.422), train_loss = 1.27462750, grad/param norm = 2.5872e-01, time/batch = 19.2479s	
8838/22750 (epoch 19.424), train_loss = 1.25431128, grad/param norm = 2.2693e-01, time/batch = 19.0037s	
8839/22750 (epoch 19.426), train_loss = 1.23749858, grad/param norm = 1.9999e-01, time/batch = 18.5941s	
8840/22750 (epoch 19.429), train_loss = 0.92359652, grad/param norm = 1.8668e-01, time/batch = 19.6198s	
8841/22750 (epoch 19.431), train_loss = 0.85816680, grad/param norm = 1.8389e-01, time/batch = 19.7063s	
8842/22750 (epoch 19.433), train_loss = 0.96392521, grad/param norm = 1.9956e-01, time/batch = 17.9446s	
8843/22750 (epoch 19.435), train_loss = 0.79834215, grad/param norm = 1.7813e-01, time/batch = 19.4013s	
8844/22750 (epoch 19.437), train_loss = 0.69417431, grad/param norm = 1.6701e-01, time/batch = 19.2515s	
8845/22750 (epoch 19.440), train_loss = 1.04111496, grad/param norm = 2.0052e-01, time/batch = 16.4878s	
8846/22750 (epoch 19.442), train_loss = 1.05336615, grad/param norm = 2.1200e-01, time/batch = 15.4491s	
8847/22750 (epoch 19.444), train_loss = 1.01972600, grad/param norm = 2.0768e-01, time/batch = 17.6794s	
8848/22750 (epoch 19.446), train_loss = 1.02299805, grad/param norm = 2.0656e-01, time/batch = 18.5120s	
8849/22750 (epoch 19.448), train_loss = 1.31222895, grad/param norm = 2.0715e-01, time/batch = 18.3655s	
8850/22750 (epoch 19.451), train_loss = 1.23128643, grad/param norm = 2.0130e-01, time/batch = 20.6961s	
8851/22750 (epoch 19.453), train_loss = 1.20312900, grad/param norm = 2.0665e-01, time/batch = 20.0270s	
8852/22750 (epoch 19.455), train_loss = 1.29965353, grad/param norm = 2.0545e-01, time/batch = 18.0070s	
8853/22750 (epoch 19.457), train_loss = 1.16248766, grad/param norm = 3.1209e-01, time/batch = 19.6640s	
8854/22750 (epoch 19.459), train_loss = 1.15331827, grad/param norm = 2.0506e-01, time/batch = 19.0857s	
8855/22750 (epoch 19.462), train_loss = 1.12489668, grad/param norm = 1.8964e-01, time/batch = 28.9391s	
8856/22750 (epoch 19.464), train_loss = 0.88523207, grad/param norm = 2.0288e-01, time/batch = 15.1996s	
8857/22750 (epoch 19.466), train_loss = 1.22998603, grad/param norm = 2.3074e-01, time/batch = 15.6148s	
8858/22750 (epoch 19.468), train_loss = 1.02203994, grad/param norm = 1.9973e-01, time/batch = 16.5094s	
8859/22750 (epoch 19.470), train_loss = 1.17794907, grad/param norm = 2.0625e-01, time/batch = 15.8557s	
8860/22750 (epoch 19.473), train_loss = 1.03458232, grad/param norm = 1.9453e-01, time/batch = 15.7307s	
8861/22750 (epoch 19.475), train_loss = 1.06747555, grad/param norm = 2.0162e-01, time/batch = 15.5252s	
8862/22750 (epoch 19.477), train_loss = 0.89138278, grad/param norm = 1.8241e-01, time/batch = 15.1302s	
8863/22750 (epoch 19.479), train_loss = 0.89374735, grad/param norm = 2.0182e-01, time/batch = 15.3583s	
8864/22750 (epoch 19.481), train_loss = 0.82960997, grad/param norm = 1.7829e-01, time/batch = 15.4391s	
8865/22750 (epoch 19.484), train_loss = 0.75554661, grad/param norm = 1.8048e-01, time/batch = 15.0563s	
8866/22750 (epoch 19.486), train_loss = 0.87200253, grad/param norm = 1.8978e-01, time/batch = 15.6861s	
8867/22750 (epoch 19.488), train_loss = 0.77650650, grad/param norm = 1.8754e-01, time/batch = 15.1595s	
8868/22750 (epoch 19.490), train_loss = 1.03992991, grad/param norm = 1.8374e-01, time/batch = 14.9909s	
8869/22750 (epoch 19.492), train_loss = 1.18611278, grad/param norm = 2.2640e-01, time/batch = 15.4507s	
8870/22750 (epoch 19.495), train_loss = 0.93001502, grad/param norm = 1.9265e-01, time/batch = 15.2287s	
8871/22750 (epoch 19.497), train_loss = 1.02765025, grad/param norm = 2.1493e-01, time/batch = 15.2146s	
8872/22750 (epoch 19.499), train_loss = 0.93711442, grad/param norm = 1.9826e-01, time/batch = 14.9722s	
8873/22750 (epoch 19.501), train_loss = 1.01566530, grad/param norm = 1.8429e-01, time/batch = 15.7765s	
8874/22750 (epoch 19.503), train_loss = 1.02973743, grad/param norm = 1.8784e-01, time/batch = 15.2862s	
8875/22750 (epoch 19.505), train_loss = 0.88434364, grad/param norm = 1.8644e-01, time/batch = 15.2081s	
8876/22750 (epoch 19.508), train_loss = 0.84310498, grad/param norm = 1.8290e-01, time/batch = 15.6000s	
8877/22750 (epoch 19.510), train_loss = 0.85724045, grad/param norm = 1.6489e-01, time/batch = 15.5182s	
8878/22750 (epoch 19.512), train_loss = 0.89786699, grad/param norm = 1.7642e-01, time/batch = 14.9887s	
8879/22750 (epoch 19.514), train_loss = 0.96043862, grad/param norm = 2.1378e-01, time/batch = 15.2358s	
8880/22750 (epoch 19.516), train_loss = 0.94166952, grad/param norm = 1.9007e-01, time/batch = 14.9853s	
8881/22750 (epoch 19.519), train_loss = 1.10669404, grad/param norm = 1.9773e-01, time/batch = 15.3975s	
8882/22750 (epoch 19.521), train_loss = 1.02268691, grad/param norm = 1.9609e-01, time/batch = 15.0512s	
8883/22750 (epoch 19.523), train_loss = 0.97759580, grad/param norm = 2.1666e-01, time/batch = 15.4556s	
8884/22750 (epoch 19.525), train_loss = 1.18497622, grad/param norm = 2.2058e-01, time/batch = 15.2935s	
8885/22750 (epoch 19.527), train_loss = 1.02675256, grad/param norm = 1.9980e-01, time/batch = 15.7736s	
8886/22750 (epoch 19.530), train_loss = 0.93705532, grad/param norm = 1.9916e-01, time/batch = 15.3674s	
8887/22750 (epoch 19.532), train_loss = 0.86315582, grad/param norm = 1.7310e-01, time/batch = 15.1349s	
8888/22750 (epoch 19.534), train_loss = 1.11842188, grad/param norm = 2.0487e-01, time/batch = 15.0556s	
8889/22750 (epoch 19.536), train_loss = 1.04740695, grad/param norm = 1.8040e-01, time/batch = 15.4611s	
8890/22750 (epoch 19.538), train_loss = 1.03510699, grad/param norm = 1.8044e-01, time/batch = 14.9135s	
8891/22750 (epoch 19.541), train_loss = 0.88618835, grad/param norm = 1.9028e-01, time/batch = 15.0691s	
8892/22750 (epoch 19.543), train_loss = 0.90058070, grad/param norm = 1.9742e-01, time/batch = 15.2184s	
8893/22750 (epoch 19.545), train_loss = 1.12552994, grad/param norm = 1.9903e-01, time/batch = 15.7619s	
8894/22750 (epoch 19.547), train_loss = 0.94039762, grad/param norm = 1.7023e-01, time/batch = 14.8019s	
8895/22750 (epoch 19.549), train_loss = 0.96449219, grad/param norm = 1.8417e-01, time/batch = 15.0271s	
8896/22750 (epoch 19.552), train_loss = 1.07793509, grad/param norm = 2.1834e-01, time/batch = 14.7968s	
8897/22750 (epoch 19.554), train_loss = 1.09132869, grad/param norm = 2.0610e-01, time/batch = 15.1175s	
8898/22750 (epoch 19.556), train_loss = 1.02176687, grad/param norm = 1.9033e-01, time/batch = 15.1991s	
8899/22750 (epoch 19.558), train_loss = 1.12445967, grad/param norm = 2.0512e-01, time/batch = 15.0711s	
8900/22750 (epoch 19.560), train_loss = 0.96461342, grad/param norm = 2.0767e-01, time/batch = 14.8377s	
8901/22750 (epoch 19.563), train_loss = 1.13678553, grad/param norm = 2.0119e-01, time/batch = 15.2248s	
8902/22750 (epoch 19.565), train_loss = 1.08088903, grad/param norm = 2.0105e-01, time/batch = 14.9748s	
8903/22750 (epoch 19.567), train_loss = 1.06061517, grad/param norm = 1.8770e-01, time/batch = 15.5463s	
8904/22750 (epoch 19.569), train_loss = 0.99214266, grad/param norm = 1.7779e-01, time/batch = 15.6717s	
8905/22750 (epoch 19.571), train_loss = 1.02129682, grad/param norm = 2.0196e-01, time/batch = 15.6150s	
8906/22750 (epoch 19.574), train_loss = 0.93769021, grad/param norm = 1.8763e-01, time/batch = 15.2869s	
8907/22750 (epoch 19.576), train_loss = 0.97194123, grad/param norm = 1.9656e-01, time/batch = 15.0517s	
8908/22750 (epoch 19.578), train_loss = 0.87716742, grad/param norm = 1.8175e-01, time/batch = 15.4457s	
8909/22750 (epoch 19.580), train_loss = 1.05221478, grad/param norm = 2.1168e-01, time/batch = 15.0387s	
8910/22750 (epoch 19.582), train_loss = 0.89792544, grad/param norm = 1.8397e-01, time/batch = 15.4690s	
8911/22750 (epoch 19.585), train_loss = 0.87634341, grad/param norm = 1.8961e-01, time/batch = 16.3913s	
8912/22750 (epoch 19.587), train_loss = 0.87405266, grad/param norm = 1.7472e-01, time/batch = 15.7765s	
8913/22750 (epoch 19.589), train_loss = 0.82229296, grad/param norm = 1.7232e-01, time/batch = 15.4557s	
8914/22750 (epoch 19.591), train_loss = 0.98606180, grad/param norm = 1.8944e-01, time/batch = 15.2810s	
8915/22750 (epoch 19.593), train_loss = 1.17720038, grad/param norm = 1.8599e-01, time/batch = 15.2144s	
8916/22750 (epoch 19.596), train_loss = 1.16819474, grad/param norm = 2.0316e-01, time/batch = 15.9332s	
8917/22750 (epoch 19.598), train_loss = 1.22594338, grad/param norm = 2.0814e-01, time/batch = 15.3656s	
8918/22750 (epoch 19.600), train_loss = 1.17300114, grad/param norm = 2.0887e-01, time/batch = 15.2827s	
8919/22750 (epoch 19.602), train_loss = 0.93049845, grad/param norm = 1.8137e-01, time/batch = 15.3680s	
8920/22750 (epoch 19.604), train_loss = 0.96478359, grad/param norm = 1.9067e-01, time/batch = 15.8651s	
8921/22750 (epoch 19.607), train_loss = 0.85180329, grad/param norm = 1.5947e-01, time/batch = 15.3084s	
8922/22750 (epoch 19.609), train_loss = 0.79285546, grad/param norm = 1.6298e-01, time/batch = 15.6328s	
8923/22750 (epoch 19.611), train_loss = 0.98452536, grad/param norm = 1.8995e-01, time/batch = 14.9176s	
8924/22750 (epoch 19.613), train_loss = 0.92649167, grad/param norm = 1.8432e-01, time/batch = 15.5478s	
8925/22750 (epoch 19.615), train_loss = 0.94019213, grad/param norm = 1.7261e-01, time/batch = 15.0534s	
8926/22750 (epoch 19.618), train_loss = 0.97323452, grad/param norm = 1.8122e-01, time/batch = 15.3726s	
8927/22750 (epoch 19.620), train_loss = 0.98499136, grad/param norm = 1.8428e-01, time/batch = 15.2821s	
8928/22750 (epoch 19.622), train_loss = 0.82056319, grad/param norm = 1.6531e-01, time/batch = 15.5166s	
8929/22750 (epoch 19.624), train_loss = 0.90884980, grad/param norm = 1.7890e-01, time/batch = 15.4450s	
8930/22750 (epoch 19.626), train_loss = 0.84069757, grad/param norm = 1.8446e-01, time/batch = 15.0536s	
8931/22750 (epoch 19.629), train_loss = 0.93757443, grad/param norm = 1.8288e-01, time/batch = 15.0759s	
8932/22750 (epoch 19.631), train_loss = 0.99325765, grad/param norm = 1.7787e-01, time/batch = 15.6973s	
8933/22750 (epoch 19.633), train_loss = 0.86308097, grad/param norm = 1.8238e-01, time/batch = 15.1546s	
8934/22750 (epoch 19.635), train_loss = 1.01828203, grad/param norm = 1.8738e-01, time/batch = 14.9815s	
8935/22750 (epoch 19.637), train_loss = 1.07525269, grad/param norm = 2.4451e-01, time/batch = 15.1247s	
8936/22750 (epoch 19.640), train_loss = 1.06366755, grad/param norm = 1.9463e-01, time/batch = 15.2787s	
8937/22750 (epoch 19.642), train_loss = 1.13426693, grad/param norm = 1.9800e-01, time/batch = 14.9732s	
8938/22750 (epoch 19.644), train_loss = 1.01702424, grad/param norm = 1.8861e-01, time/batch = 15.8249s	
8939/22750 (epoch 19.646), train_loss = 1.06363670, grad/param norm = 2.4352e-01, time/batch = 15.5917s	
8940/22750 (epoch 19.648), train_loss = 1.03797138, grad/param norm = 1.9793e-01, time/batch = 17.8360s	
8941/22750 (epoch 19.651), train_loss = 1.06935533, grad/param norm = 1.9364e-01, time/batch = 18.0946s	
8942/22750 (epoch 19.653), train_loss = 1.08414610, grad/param norm = 1.8769e-01, time/batch = 19.5227s	
8943/22750 (epoch 19.655), train_loss = 1.04430581, grad/param norm = 1.8745e-01, time/batch = 17.8139s	
8944/22750 (epoch 19.657), train_loss = 1.19157604, grad/param norm = 2.1570e-01, time/batch = 19.1200s	
8945/22750 (epoch 19.659), train_loss = 1.25438409, grad/param norm = 2.2514e-01, time/batch = 20.9026s	
8946/22750 (epoch 19.662), train_loss = 1.22453760, grad/param norm = 2.1372e-01, time/batch = 17.1866s	
8947/22750 (epoch 19.664), train_loss = 1.07386925, grad/param norm = 2.0394e-01, time/batch = 16.4481s	
8948/22750 (epoch 19.666), train_loss = 0.86990818, grad/param norm = 1.8030e-01, time/batch = 19.4184s	
8949/22750 (epoch 19.668), train_loss = 1.03224883, grad/param norm = 1.9456e-01, time/batch = 17.4227s	
8950/22750 (epoch 19.670), train_loss = 1.03723420, grad/param norm = 2.1348e-01, time/batch = 16.4746s	
8951/22750 (epoch 19.673), train_loss = 1.29784851, grad/param norm = 2.3069e-01, time/batch = 17.7680s	
8952/22750 (epoch 19.675), train_loss = 1.42726299, grad/param norm = 2.4063e-01, time/batch = 17.8511s	
8953/22750 (epoch 19.677), train_loss = 1.20893195, grad/param norm = 2.2093e-01, time/batch = 16.7616s	
8954/22750 (epoch 19.679), train_loss = 1.26750185, grad/param norm = 2.3525e-01, time/batch = 16.8612s	
8955/22750 (epoch 19.681), train_loss = 1.20024557, grad/param norm = 1.9377e-01, time/batch = 19.3973s	
8956/22750 (epoch 19.684), train_loss = 1.21128808, grad/param norm = 2.1853e-01, time/batch = 16.1844s	
8957/22750 (epoch 19.686), train_loss = 1.22826559, grad/param norm = 2.3139e-01, time/batch = 17.1624s	
8958/22750 (epoch 19.688), train_loss = 1.18167539, grad/param norm = 2.0836e-01, time/batch = 17.1675s	
8959/22750 (epoch 19.690), train_loss = 1.17604995, grad/param norm = 2.2605e-01, time/batch = 18.1016s	
8960/22750 (epoch 19.692), train_loss = 1.21273398, grad/param norm = 2.1145e-01, time/batch = 16.2178s	
8961/22750 (epoch 19.695), train_loss = 1.09003038, grad/param norm = 1.9528e-01, time/batch = 19.3497s	
8962/22750 (epoch 19.697), train_loss = 1.04240373, grad/param norm = 1.9782e-01, time/batch = 19.6834s	
8963/22750 (epoch 19.699), train_loss = 1.04164080, grad/param norm = 2.0398e-01, time/batch = 17.3394s	
8964/22750 (epoch 19.701), train_loss = 0.90050792, grad/param norm = 1.9875e-01, time/batch = 19.1706s	
8965/22750 (epoch 19.703), train_loss = 1.02938794, grad/param norm = 1.8792e-01, time/batch = 19.6743s	
8966/22750 (epoch 19.705), train_loss = 0.96901504, grad/param norm = 1.8620e-01, time/batch = 17.3142s	
8967/22750 (epoch 19.708), train_loss = 1.05986790, grad/param norm = 1.9022e-01, time/batch = 18.5037s	
8968/22750 (epoch 19.710), train_loss = 0.91372555, grad/param norm = 1.9055e-01, time/batch = 16.8474s	
8969/22750 (epoch 19.712), train_loss = 0.90627564, grad/param norm = 1.9133e-01, time/batch = 17.3351s	
8970/22750 (epoch 19.714), train_loss = 0.85185122, grad/param norm = 1.7929e-01, time/batch = 20.2579s	
8971/22750 (epoch 19.716), train_loss = 0.90517104, grad/param norm = 1.9033e-01, time/batch = 18.7752s	
8972/22750 (epoch 19.719), train_loss = 1.09058764, grad/param norm = 2.3863e-01, time/batch = 18.9235s	
8973/22750 (epoch 19.721), train_loss = 1.14710163, grad/param norm = 1.9543e-01, time/batch = 19.2454s	
8974/22750 (epoch 19.723), train_loss = 1.10340721, grad/param norm = 2.1761e-01, time/batch = 18.5721s	
8975/22750 (epoch 19.725), train_loss = 1.02860721, grad/param norm = 2.2283e-01, time/batch = 19.0679s	
8976/22750 (epoch 19.727), train_loss = 0.98035056, grad/param norm = 1.9156e-01, time/batch = 17.2464s	
8977/22750 (epoch 19.730), train_loss = 0.99877190, grad/param norm = 2.1546e-01, time/batch = 17.8304s	
8978/22750 (epoch 19.732), train_loss = 0.92097746, grad/param norm = 1.7453e-01, time/batch = 16.0693s	
8979/22750 (epoch 19.734), train_loss = 0.79737745, grad/param norm = 1.6031e-01, time/batch = 17.1696s	
8980/22750 (epoch 19.736), train_loss = 0.96493046, grad/param norm = 1.9761e-01, time/batch = 20.8516s	
8981/22750 (epoch 19.738), train_loss = 1.09248414, grad/param norm = 2.2131e-01, time/batch = 17.5130s	
8982/22750 (epoch 19.741), train_loss = 1.13709904, grad/param norm = 2.1069e-01, time/batch = 17.5704s	
8983/22750 (epoch 19.743), train_loss = 1.07396330, grad/param norm = 1.8347e-01, time/batch = 18.5603s	
8984/22750 (epoch 19.745), train_loss = 0.88535802, grad/param norm = 1.7350e-01, time/batch = 20.1586s	
8985/22750 (epoch 19.747), train_loss = 0.95793108, grad/param norm = 1.7543e-01, time/batch = 18.2540s	
8986/22750 (epoch 19.749), train_loss = 1.18957311, grad/param norm = 2.2397e-01, time/batch = 19.1785s	
8987/22750 (epoch 19.752), train_loss = 1.00334250, grad/param norm = 1.9522e-01, time/batch = 19.6931s	
8988/22750 (epoch 19.754), train_loss = 1.04673823, grad/param norm = 2.0512e-01, time/batch = 19.3590s	
8989/22750 (epoch 19.756), train_loss = 0.92300608, grad/param norm = 2.0729e-01, time/batch = 18.4397s	
8990/22750 (epoch 19.758), train_loss = 0.91105999, grad/param norm = 1.9200e-01, time/batch = 18.8344s	
8991/22750 (epoch 19.760), train_loss = 0.98151365, grad/param norm = 1.9522e-01, time/batch = 16.0145s	
8992/22750 (epoch 19.763), train_loss = 1.05457311, grad/param norm = 2.1549e-01, time/batch = 17.1566s	
8993/22750 (epoch 19.765), train_loss = 1.01598540, grad/param norm = 2.0590e-01, time/batch = 19.7447s	
8994/22750 (epoch 19.767), train_loss = 1.06942697, grad/param norm = 2.1339e-01, time/batch = 19.5771s	
8995/22750 (epoch 19.769), train_loss = 1.27681071, grad/param norm = 2.2839e-01, time/batch = 18.2610s	
8996/22750 (epoch 19.771), train_loss = 1.18315278, grad/param norm = 2.3940e-01, time/batch = 20.7779s	
8997/22750 (epoch 19.774), train_loss = 0.99824201, grad/param norm = 2.1812e-01, time/batch = 20.6036s	
8998/22750 (epoch 19.776), train_loss = 1.08294510, grad/param norm = 2.1222e-01, time/batch = 17.9219s	
8999/22750 (epoch 19.778), train_loss = 1.20849369, grad/param norm = 2.1198e-01, time/batch = 17.9919s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_wakata_epoch19.78_1.5207.t7	
9000/22750 (epoch 19.780), train_loss = 1.05860592, grad/param norm = 2.0332e-01, time/batch = 17.6621s	
9001/22750 (epoch 19.782), train_loss = 1.71433318, grad/param norm = 2.6411e-01, time/batch = 17.1173s	
9002/22750 (epoch 19.785), train_loss = 1.04558878, grad/param norm = 1.9930e-01, time/batch = 17.0413s	
9003/22750 (epoch 19.787), train_loss = 0.94165948, grad/param norm = 2.4240e-01, time/batch = 17.2874s	
9004/22750 (epoch 19.789), train_loss = 1.00157273, grad/param norm = 1.8591e-01, time/batch = 17.1906s	
9005/22750 (epoch 19.791), train_loss = 0.99860243, grad/param norm = 2.0646e-01, time/batch = 17.2083s	
9006/22750 (epoch 19.793), train_loss = 0.94689995, grad/param norm = 2.0595e-01, time/batch = 16.8866s	
9007/22750 (epoch 19.796), train_loss = 0.84253314, grad/param norm = 1.6644e-01, time/batch = 17.5703s	
9008/22750 (epoch 19.798), train_loss = 0.90070629, grad/param norm = 1.6943e-01, time/batch = 19.2547s	
9009/22750 (epoch 19.800), train_loss = 0.94049804, grad/param norm = 1.9033e-01, time/batch = 18.2697s	
9010/22750 (epoch 19.802), train_loss = 0.87920585, grad/param norm = 1.8286e-01, time/batch = 17.4251s	
9011/22750 (epoch 19.804), train_loss = 1.19100785, grad/param norm = 2.0880e-01, time/batch = 17.6840s	
9012/22750 (epoch 19.807), train_loss = 1.10060878, grad/param norm = 1.9011e-01, time/batch = 17.9272s	
9013/22750 (epoch 19.809), train_loss = 1.21846441, grad/param norm = 2.3323e-01, time/batch = 16.9140s	
9014/22750 (epoch 19.811), train_loss = 0.97481645, grad/param norm = 1.9007e-01, time/batch = 17.1766s	
9015/22750 (epoch 19.813), train_loss = 1.08533124, grad/param norm = 1.8642e-01, time/batch = 18.6701s	
9016/22750 (epoch 19.815), train_loss = 1.20322848, grad/param norm = 1.9858e-01, time/batch = 17.5053s	
9017/22750 (epoch 19.818), train_loss = 1.16106534, grad/param norm = 1.8438e-01, time/batch = 19.3305s	
9018/22750 (epoch 19.820), train_loss = 1.28689569, grad/param norm = 1.9060e-01, time/batch = 17.8493s	
9019/22750 (epoch 19.822), train_loss = 1.09204885, grad/param norm = 2.0069e-01, time/batch = 18.9367s	
9020/22750 (epoch 19.824), train_loss = 0.94551820, grad/param norm = 1.6923e-01, time/batch = 20.1063s	
9021/22750 (epoch 19.826), train_loss = 1.01853908, grad/param norm = 1.8034e-01, time/batch = 18.9414s	
9022/22750 (epoch 19.829), train_loss = 1.21309705, grad/param norm = 2.0989e-01, time/batch = 19.3304s	
9023/22750 (epoch 19.831), train_loss = 1.15537586, grad/param norm = 1.9082e-01, time/batch = 16.9563s	
9024/22750 (epoch 19.833), train_loss = 1.07204255, grad/param norm = 2.1449e-01, time/batch = 16.9208s	
9025/22750 (epoch 19.835), train_loss = 0.97487149, grad/param norm = 1.9318e-01, time/batch = 17.5199s	
9026/22750 (epoch 19.837), train_loss = 0.98716423, grad/param norm = 1.8183e-01, time/batch = 17.6455s	
9027/22750 (epoch 19.840), train_loss = 0.90875536, grad/param norm = 1.6730e-01, time/batch = 17.7630s	
9028/22750 (epoch 19.842), train_loss = 0.95921617, grad/param norm = 1.8312e-01, time/batch = 17.4356s	
9029/22750 (epoch 19.844), train_loss = 1.10781065, grad/param norm = 2.1574e-01, time/batch = 17.9480s	
9030/22750 (epoch 19.846), train_loss = 1.07157082, grad/param norm = 2.0934e-01, time/batch = 20.3316s	
9031/22750 (epoch 19.848), train_loss = 0.95790962, grad/param norm = 1.6904e-01, time/batch = 19.9443s	
9032/22750 (epoch 19.851), train_loss = 0.91540438, grad/param norm = 1.7680e-01, time/batch = 18.1065s	
9033/22750 (epoch 19.853), train_loss = 1.08075881, grad/param norm = 1.8782e-01, time/batch = 19.4332s	
9034/22750 (epoch 19.855), train_loss = 0.89348882, grad/param norm = 1.6720e-01, time/batch = 17.2586s	
9035/22750 (epoch 19.857), train_loss = 1.05630407, grad/param norm = 1.7975e-01, time/batch = 19.2487s	
9036/22750 (epoch 19.859), train_loss = 1.10446009, grad/param norm = 2.1380e-01, time/batch = 19.2391s	
9037/22750 (epoch 19.862), train_loss = 1.20929420, grad/param norm = 2.0618e-01, time/batch = 18.0920s	
9038/22750 (epoch 19.864), train_loss = 1.04159536, grad/param norm = 1.9840e-01, time/batch = 17.0335s	
9039/22750 (epoch 19.866), train_loss = 1.06459323, grad/param norm = 1.7340e-01, time/batch = 16.3364s	
9040/22750 (epoch 19.868), train_loss = 0.96629464, grad/param norm = 1.8238e-01, time/batch = 19.1792s	
9041/22750 (epoch 19.870), train_loss = 0.83485338, grad/param norm = 1.7621e-01, time/batch = 18.4287s	
9042/22750 (epoch 19.873), train_loss = 0.98571264, grad/param norm = 1.7826e-01, time/batch = 18.5071s	
9043/22750 (epoch 19.875), train_loss = 1.10448639, grad/param norm = 2.0329e-01, time/batch = 17.0238s	
9044/22750 (epoch 19.877), train_loss = 0.92725215, grad/param norm = 1.7915e-01, time/batch = 19.5978s	
9045/22750 (epoch 19.879), train_loss = 1.18805876, grad/param norm = 2.1128e-01, time/batch = 17.1046s	
9046/22750 (epoch 19.881), train_loss = 1.11260634, grad/param norm = 1.9403e-01, time/batch = 16.8543s	
9047/22750 (epoch 19.884), train_loss = 0.96240680, grad/param norm = 2.0272e-01, time/batch = 17.0994s	
9048/22750 (epoch 19.886), train_loss = 1.10664743, grad/param norm = 1.8652e-01, time/batch = 19.7410s	
9049/22750 (epoch 19.888), train_loss = 1.09506698, grad/param norm = 1.8492e-01, time/batch = 15.6964s	
9050/22750 (epoch 19.890), train_loss = 1.11973629, grad/param norm = 1.9865e-01, time/batch = 15.2581s	
9051/22750 (epoch 19.892), train_loss = 1.37660674, grad/param norm = 2.2618e-01, time/batch = 15.5868s	
9052/22750 (epoch 19.895), train_loss = 1.07906807, grad/param norm = 1.9501e-01, time/batch = 17.1762s	
9053/22750 (epoch 19.897), train_loss = 1.13938129, grad/param norm = 2.1469e-01, time/batch = 19.1171s	
9054/22750 (epoch 19.899), train_loss = 1.08438705, grad/param norm = 1.9630e-01, time/batch = 19.2846s	
9055/22750 (epoch 19.901), train_loss = 1.18699179, grad/param norm = 2.0954e-01, time/batch = 19.1039s	
9056/22750 (epoch 19.903), train_loss = 1.03406898, grad/param norm = 2.1754e-01, time/batch = 17.8487s	
9057/22750 (epoch 19.905), train_loss = 1.14897273, grad/param norm = 2.2196e-01, time/batch = 18.2609s	
9058/22750 (epoch 19.908), train_loss = 0.96500376, grad/param norm = 2.2194e-01, time/batch = 19.1713s	
9059/22750 (epoch 19.910), train_loss = 0.84288209, grad/param norm = 2.0316e-01, time/batch = 32.5508s	
9060/22750 (epoch 19.912), train_loss = 0.98722025, grad/param norm = 1.9134e-01, time/batch = 18.4205s	
9061/22750 (epoch 19.914), train_loss = 1.01813334, grad/param norm = 1.7335e-01, time/batch = 18.4132s	
9062/22750 (epoch 19.916), train_loss = 0.87336308, grad/param norm = 1.8910e-01, time/batch = 18.9403s	
9063/22750 (epoch 19.919), train_loss = 1.00615844, grad/param norm = 2.4614e-01, time/batch = 19.6085s	
9064/22750 (epoch 19.921), train_loss = 0.77220230, grad/param norm = 1.6334e-01, time/batch = 16.5686s	
9065/22750 (epoch 19.923), train_loss = 0.91250645, grad/param norm = 1.7748e-01, time/batch = 16.4971s	
9066/22750 (epoch 19.925), train_loss = 1.00353545, grad/param norm = 1.7429e-01, time/batch = 17.0125s	
9067/22750 (epoch 19.927), train_loss = 0.80345462, grad/param norm = 1.8750e-01, time/batch = 16.1818s	
9068/22750 (epoch 19.930), train_loss = 0.82893352, grad/param norm = 1.7450e-01, time/batch = 17.4197s	
9069/22750 (epoch 19.932), train_loss = 1.03599417, grad/param norm = 1.8651e-01, time/batch = 19.3255s	
9070/22750 (epoch 19.934), train_loss = 0.78329644, grad/param norm = 1.5693e-01, time/batch = 17.3483s	
9071/22750 (epoch 19.936), train_loss = 1.14388433, grad/param norm = 1.9504e-01, time/batch = 18.9268s	
9072/22750 (epoch 19.938), train_loss = 1.09124897, grad/param norm = 1.7680e-01, time/batch = 17.3745s	
9073/22750 (epoch 19.941), train_loss = 1.19931324, grad/param norm = 1.9976e-01, time/batch = 17.3177s	
9074/22750 (epoch 19.943), train_loss = 1.04246795, grad/param norm = 1.9166e-01, time/batch = 19.9947s	
9075/22750 (epoch 19.945), train_loss = 1.04502089, grad/param norm = 2.0862e-01, time/batch = 18.0053s	
9076/22750 (epoch 19.947), train_loss = 0.98661040, grad/param norm = 2.0898e-01, time/batch = 18.3377s	
9077/22750 (epoch 19.949), train_loss = 0.91614220, grad/param norm = 1.9540e-01, time/batch = 19.3341s	
9078/22750 (epoch 19.952), train_loss = 0.93549358, grad/param norm = 1.6917e-01, time/batch = 17.8309s	
9079/22750 (epoch 19.954), train_loss = 0.91975382, grad/param norm = 1.8047e-01, time/batch = 20.2367s	
9080/22750 (epoch 19.956), train_loss = 1.04186053, grad/param norm = 1.9665e-01, time/batch = 20.3468s	
9081/22750 (epoch 19.958), train_loss = 0.96149094, grad/param norm = 1.6880e-01, time/batch = 20.3510s	
9082/22750 (epoch 19.960), train_loss = 0.91556174, grad/param norm = 1.6568e-01, time/batch = 21.0222s	
9083/22750 (epoch 19.963), train_loss = 1.11859304, grad/param norm = 2.0701e-01, time/batch = 17.7210s	
9084/22750 (epoch 19.965), train_loss = 1.10213640, grad/param norm = 1.8996e-01, time/batch = 17.7423s	
9085/22750 (epoch 19.967), train_loss = 1.01633275, grad/param norm = 1.8971e-01, time/batch = 20.2423s	
9086/22750 (epoch 19.969), train_loss = 0.93602914, grad/param norm = 1.8719e-01, time/batch = 18.5041s	
9087/22750 (epoch 19.971), train_loss = 0.97710266, grad/param norm = 2.0191e-01, time/batch = 16.4265s	
9088/22750 (epoch 19.974), train_loss = 1.00100360, grad/param norm = 2.0193e-01, time/batch = 19.9138s	
9089/22750 (epoch 19.976), train_loss = 1.07796429, grad/param norm = 2.0805e-01, time/batch = 20.5290s	
9090/22750 (epoch 19.978), train_loss = 0.94204276, grad/param norm = 1.7991e-01, time/batch = 19.3546s	
9091/22750 (epoch 19.980), train_loss = 1.15214291, grad/param norm = 2.1926e-01, time/batch = 19.9308s	
9092/22750 (epoch 19.982), train_loss = 0.93193581, grad/param norm = 1.7504e-01, time/batch = 18.6824s	
9093/22750 (epoch 19.985), train_loss = 1.20883683, grad/param norm = 2.0801e-01, time/batch = 16.5873s	
9094/22750 (epoch 19.987), train_loss = 0.80259304, grad/param norm = 1.6860e-01, time/batch = 17.0097s	
9095/22750 (epoch 19.989), train_loss = 0.97535754, grad/param norm = 1.9730e-01, time/batch = 18.7250s	
9096/22750 (epoch 19.991), train_loss = 1.07719291, grad/param norm = 2.1002e-01, time/batch = 17.7519s	
9097/22750 (epoch 19.993), train_loss = 1.08702794, grad/param norm = 2.0503e-01, time/batch = 18.3221s	
9098/22750 (epoch 19.996), train_loss = 0.94411971, grad/param norm = 2.1465e-01, time/batch = 18.7006s	
9099/22750 (epoch 19.998), train_loss = 1.15235946, grad/param norm = 2.0592e-01, time/batch = 17.0166s	
decayed learning rate by a factor 0.97 to 0.0014306028061762	
9100/22750 (epoch 20.000), train_loss = 1.07209575, grad/param norm = 2.0107e-01, time/batch = 16.7396s	
9101/22750 (epoch 20.002), train_loss = 1.17488023, grad/param norm = 2.2818e-01, time/batch = 17.4979s	
9102/22750 (epoch 20.004), train_loss = 0.94907134, grad/param norm = 1.8087e-01, time/batch = 17.5070s	
9103/22750 (epoch 20.007), train_loss = 0.98949238, grad/param norm = 1.9805e-01, time/batch = 16.9272s	
9104/22750 (epoch 20.009), train_loss = 1.20920682, grad/param norm = 2.1408e-01, time/batch = 17.3479s	
9105/22750 (epoch 20.011), train_loss = 1.27740537, grad/param norm = 2.1574e-01, time/batch = 18.9949s	
9106/22750 (epoch 20.013), train_loss = 1.13290144, grad/param norm = 1.9709e-01, time/batch = 19.4975s	
9107/22750 (epoch 20.015), train_loss = 1.04252098, grad/param norm = 2.0674e-01, time/batch = 17.5088s	
9108/22750 (epoch 20.018), train_loss = 1.10275276, grad/param norm = 2.0626e-01, time/batch = 19.8606s	
9109/22750 (epoch 20.020), train_loss = 1.16964531, grad/param norm = 1.8646e-01, time/batch = 19.9408s	
9110/22750 (epoch 20.022), train_loss = 1.04969841, grad/param norm = 2.0314e-01, time/batch = 18.1135s	
9111/22750 (epoch 20.024), train_loss = 1.03306434, grad/param norm = 1.8975e-01, time/batch = 18.3351s	
9112/22750 (epoch 20.026), train_loss = 1.10181276, grad/param norm = 2.0219e-01, time/batch = 18.6728s	
9113/22750 (epoch 20.029), train_loss = 0.85954633, grad/param norm = 1.8401e-01, time/batch = 18.3227s	
9114/22750 (epoch 20.031), train_loss = 1.29058628, grad/param norm = 2.0315e-01, time/batch = 19.3219s	
9115/22750 (epoch 20.033), train_loss = 1.05986669, grad/param norm = 1.9792e-01, time/batch = 17.0773s	
9116/22750 (epoch 20.035), train_loss = 1.09172283, grad/param norm = 1.9067e-01, time/batch = 19.1673s	
9117/22750 (epoch 20.037), train_loss = 1.16650947, grad/param norm = 1.9584e-01, time/batch = 19.3639s	
9118/22750 (epoch 20.040), train_loss = 1.00892577, grad/param norm = 2.0205e-01, time/batch = 20.8525s	
9119/22750 (epoch 20.042), train_loss = 1.10161271, grad/param norm = 1.9172e-01, time/batch = 18.7755s	
9120/22750 (epoch 20.044), train_loss = 0.98927907, grad/param norm = 1.9652e-01, time/batch = 19.4842s	
9121/22750 (epoch 20.046), train_loss = 1.15030487, grad/param norm = 2.1611e-01, time/batch = 19.8278s	
9122/22750 (epoch 20.048), train_loss = 1.03461300, grad/param norm = 2.0019e-01, time/batch = 19.3202s	
9123/22750 (epoch 20.051), train_loss = 1.09967494, grad/param norm = 1.9546e-01, time/batch = 20.3015s	
9124/22750 (epoch 20.053), train_loss = 0.93118450, grad/param norm = 1.6111e-01, time/batch = 18.5883s	
9125/22750 (epoch 20.055), train_loss = 0.95043454, grad/param norm = 1.9047e-01, time/batch = 18.6940s	
9126/22750 (epoch 20.057), train_loss = 1.19473065, grad/param norm = 1.9037e-01, time/batch = 17.1034s	
9127/22750 (epoch 20.059), train_loss = 0.77808724, grad/param norm = 1.7072e-01, time/batch = 17.7504s	
9128/22750 (epoch 20.062), train_loss = 0.90619601, grad/param norm = 1.9288e-01, time/batch = 20.0359s	
9129/22750 (epoch 20.064), train_loss = 1.09765272, grad/param norm = 2.0699e-01, time/batch = 18.1642s	
9130/22750 (epoch 20.066), train_loss = 0.88726053, grad/param norm = 1.6885e-01, time/batch = 18.8466s	
9131/22750 (epoch 20.068), train_loss = 0.94885955, grad/param norm = 1.7441e-01, time/batch = 18.5788s	
9132/22750 (epoch 20.070), train_loss = 0.78581218, grad/param norm = 1.5722e-01, time/batch = 17.9197s	
9133/22750 (epoch 20.073), train_loss = 0.96397962, grad/param norm = 1.9590e-01, time/batch = 18.5921s	
9134/22750 (epoch 20.075), train_loss = 1.00011535, grad/param norm = 1.8028e-01, time/batch = 18.7502s	
9135/22750 (epoch 20.077), train_loss = 0.78435397, grad/param norm = 1.9064e-01, time/batch = 18.8746s	
9136/22750 (epoch 20.079), train_loss = 1.00005438, grad/param norm = 2.3694e-01, time/batch = 19.7887s	
9137/22750 (epoch 20.081), train_loss = 0.97916915, grad/param norm = 1.8958e-01, time/batch = 18.0159s	
9138/22750 (epoch 20.084), train_loss = 0.96753726, grad/param norm = 1.8640e-01, time/batch = 19.2351s	
9139/22750 (epoch 20.086), train_loss = 0.97547092, grad/param norm = 1.6466e-01, time/batch = 18.8990s	
9140/22750 (epoch 20.088), train_loss = 0.93356868, grad/param norm = 1.9261e-01, time/batch = 18.5103s	
9141/22750 (epoch 20.090), train_loss = 0.93149526, grad/param norm = 1.8198e-01, time/batch = 18.5916s	
9142/22750 (epoch 20.092), train_loss = 1.14248828, grad/param norm = 1.8680e-01, time/batch = 19.7357s	
9143/22750 (epoch 20.095), train_loss = 0.90286987, grad/param norm = 1.8357e-01, time/batch = 18.2617s	
9144/22750 (epoch 20.097), train_loss = 1.02055973, grad/param norm = 1.9553e-01, time/batch = 21.2716s	
9145/22750 (epoch 20.099), train_loss = 0.98291945, grad/param norm = 1.8776e-01, time/batch = 20.1721s	
9146/22750 (epoch 20.101), train_loss = 0.87134170, grad/param norm = 1.6868e-01, time/batch = 20.1228s	
9147/22750 (epoch 20.103), train_loss = 1.01555515, grad/param norm = 1.7877e-01, time/batch = 20.3161s	
9148/22750 (epoch 20.105), train_loss = 1.21205349, grad/param norm = 2.1603e-01, time/batch = 19.4934s	
9149/22750 (epoch 20.108), train_loss = 0.98873697, grad/param norm = 1.9701e-01, time/batch = 19.4220s	
9150/22750 (epoch 20.110), train_loss = 1.15403768, grad/param norm = 1.9316e-01, time/batch = 18.5094s	
9151/22750 (epoch 20.112), train_loss = 0.87086116, grad/param norm = 1.8602e-01, time/batch = 19.2436s	
9152/22750 (epoch 20.114), train_loss = 0.80271513, grad/param norm = 1.8246e-01, time/batch = 18.5161s	
9153/22750 (epoch 20.116), train_loss = 0.92545563, grad/param norm = 1.7034e-01, time/batch = 20.1568s	
9154/22750 (epoch 20.119), train_loss = 0.92803150, grad/param norm = 1.7497e-01, time/batch = 18.2658s	
9155/22750 (epoch 20.121), train_loss = 1.03783290, grad/param norm = 2.0518e-01, time/batch = 17.9536s	
9156/22750 (epoch 20.123), train_loss = 0.89016218, grad/param norm = 1.7906e-01, time/batch = 18.1291s	
9157/22750 (epoch 20.125), train_loss = 1.16455548, grad/param norm = 1.8264e-01, time/batch = 16.1797s	
9158/22750 (epoch 20.127), train_loss = 0.96319978, grad/param norm = 1.9011e-01, time/batch = 16.3076s	
9159/22750 (epoch 20.130), train_loss = 0.99621025, grad/param norm = 1.7443e-01, time/batch = 16.1853s	
9160/22750 (epoch 20.132), train_loss = 0.92933411, grad/param norm = 1.8977e-01, time/batch = 16.1059s	
9161/22750 (epoch 20.134), train_loss = 0.95988959, grad/param norm = 1.8516e-01, time/batch = 16.1025s	
9162/22750 (epoch 20.136), train_loss = 0.85685928, grad/param norm = 2.0955e-01, time/batch = 17.0170s	
9163/22750 (epoch 20.138), train_loss = 1.05978511, grad/param norm = 1.8086e-01, time/batch = 17.9934s	
9164/22750 (epoch 20.141), train_loss = 1.02252887, grad/param norm = 2.0733e-01, time/batch = 18.7468s	
9165/22750 (epoch 20.143), train_loss = 0.89736711, grad/param norm = 1.7480e-01, time/batch = 19.6959s	
9166/22750 (epoch 20.145), train_loss = 1.14400413, grad/param norm = 2.0223e-01, time/batch = 17.2902s	
9167/22750 (epoch 20.147), train_loss = 1.17286311, grad/param norm = 2.0815e-01, time/batch = 18.7599s	
9168/22750 (epoch 20.149), train_loss = 1.02944481, grad/param norm = 1.9651e-01, time/batch = 17.2736s	
9169/22750 (epoch 20.152), train_loss = 1.01344756, grad/param norm = 2.0074e-01, time/batch = 18.2414s	
9170/22750 (epoch 20.154), train_loss = 0.84971701, grad/param norm = 1.8046e-01, time/batch = 19.3271s	
9171/22750 (epoch 20.156), train_loss = 0.87167854, grad/param norm = 1.7961e-01, time/batch = 18.7293s	
9172/22750 (epoch 20.158), train_loss = 0.92127922, grad/param norm = 1.9012e-01, time/batch = 18.7414s	
9173/22750 (epoch 20.160), train_loss = 1.04858632, grad/param norm = 1.8420e-01, time/batch = 20.5063s	
9174/22750 (epoch 20.163), train_loss = 1.23757203, grad/param norm = 2.1087e-01, time/batch = 18.4328s	
9175/22750 (epoch 20.165), train_loss = 1.08225288, grad/param norm = 1.9911e-01, time/batch = 19.2981s	
9176/22750 (epoch 20.167), train_loss = 0.97844312, grad/param norm = 2.1158e-01, time/batch = 18.6777s	
9177/22750 (epoch 20.169), train_loss = 1.00092146, grad/param norm = 2.0431e-01, time/batch = 17.4304s	
9178/22750 (epoch 20.171), train_loss = 0.87845315, grad/param norm = 1.8667e-01, time/batch = 18.5824s	
9179/22750 (epoch 20.174), train_loss = 0.83257339, grad/param norm = 1.8111e-01, time/batch = 17.6624s	
9180/22750 (epoch 20.176), train_loss = 0.93345934, grad/param norm = 1.8019e-01, time/batch = 18.3467s	
9181/22750 (epoch 20.178), train_loss = 0.94375732, grad/param norm = 1.8041e-01, time/batch = 18.9115s	
9182/22750 (epoch 20.180), train_loss = 1.11161526, grad/param norm = 2.5108e-01, time/batch = 20.0309s	
9183/22750 (epoch 20.182), train_loss = 1.13479279, grad/param norm = 1.9993e-01, time/batch = 19.1185s	
9184/22750 (epoch 20.185), train_loss = 1.16676293, grad/param norm = 2.0734e-01, time/batch = 19.9357s	
9185/22750 (epoch 20.187), train_loss = 0.92088497, grad/param norm = 1.9504e-01, time/batch = 16.8127s	
9186/22750 (epoch 20.189), train_loss = 0.93781707, grad/param norm = 1.9813e-01, time/batch = 15.9295s	
9187/22750 (epoch 20.191), train_loss = 0.91720460, grad/param norm = 1.7112e-01, time/batch = 16.4823s	
9188/22750 (epoch 20.193), train_loss = 1.07998913, grad/param norm = 1.9483e-01, time/batch = 18.9038s	
9189/22750 (epoch 20.196), train_loss = 0.98017342, grad/param norm = 1.8823e-01, time/batch = 18.4265s	
9190/22750 (epoch 20.198), train_loss = 0.74931460, grad/param norm = 1.5643e-01, time/batch = 17.4816s	
9191/22750 (epoch 20.200), train_loss = 1.01875720, grad/param norm = 1.8990e-01, time/batch = 20.0880s	
9192/22750 (epoch 20.202), train_loss = 1.09876557, grad/param norm = 2.1258e-01, time/batch = 18.3700s	
9193/22750 (epoch 20.204), train_loss = 0.99791385, grad/param norm = 1.7137e-01, time/batch = 19.4393s	
9194/22750 (epoch 20.207), train_loss = 0.97888968, grad/param norm = 1.8572e-01, time/batch = 17.7774s	
9195/22750 (epoch 20.209), train_loss = 0.92921185, grad/param norm = 1.9204e-01, time/batch = 17.7574s	
9196/22750 (epoch 20.211), train_loss = 0.91890501, grad/param norm = 2.0048e-01, time/batch = 19.1736s	
9197/22750 (epoch 20.213), train_loss = 0.81897969, grad/param norm = 1.7567e-01, time/batch = 17.1763s	
9198/22750 (epoch 20.215), train_loss = 0.77258934, grad/param norm = 1.7212e-01, time/batch = 19.0825s	
9199/22750 (epoch 20.218), train_loss = 0.87360753, grad/param norm = 1.9944e-01, time/batch = 17.7885s	
9200/22750 (epoch 20.220), train_loss = 0.83875881, grad/param norm = 1.6990e-01, time/batch = 15.9421s	
9201/22750 (epoch 20.222), train_loss = 0.84262852, grad/param norm = 1.8830e-01, time/batch = 19.6896s	
9202/22750 (epoch 20.224), train_loss = 0.90040668, grad/param norm = 1.8107e-01, time/batch = 20.5248s	
9203/22750 (epoch 20.226), train_loss = 1.05657969, grad/param norm = 2.0159e-01, time/batch = 18.5932s	
9204/22750 (epoch 20.229), train_loss = 1.01698173, grad/param norm = 1.8997e-01, time/batch = 18.9803s	
9205/22750 (epoch 20.231), train_loss = 0.92845426, grad/param norm = 2.0281e-01, time/batch = 18.2526s	
9206/22750 (epoch 20.233), train_loss = 0.85257137, grad/param norm = 1.8781e-01, time/batch = 17.1737s	
9207/22750 (epoch 20.235), train_loss = 0.80993226, grad/param norm = 1.7695e-01, time/batch = 16.7688s	
9208/22750 (epoch 20.237), train_loss = 0.92026772, grad/param norm = 1.8863e-01, time/batch = 16.9056s	
9209/22750 (epoch 20.240), train_loss = 0.96479794, grad/param norm = 1.8774e-01, time/batch = 19.7427s	
9210/22750 (epoch 20.242), train_loss = 1.22657032, grad/param norm = 2.2782e-01, time/batch = 19.3503s	
9211/22750 (epoch 20.244), train_loss = 1.13701004, grad/param norm = 1.9514e-01, time/batch = 19.2870s	
9212/22750 (epoch 20.246), train_loss = 1.17940027, grad/param norm = 2.1391e-01, time/batch = 19.1073s	
9213/22750 (epoch 20.248), train_loss = 0.97019892, grad/param norm = 2.0694e-01, time/batch = 17.4805s	
9214/22750 (epoch 20.251), train_loss = 1.13302887, grad/param norm = 1.9317e-01, time/batch = 15.7513s	
9215/22750 (epoch 20.253), train_loss = 1.02898444, grad/param norm = 2.2283e-01, time/batch = 16.7711s	
9216/22750 (epoch 20.255), train_loss = 1.00756030, grad/param norm = 1.8821e-01, time/batch = 17.0941s	
9217/22750 (epoch 20.257), train_loss = 0.91123082, grad/param norm = 1.8634e-01, time/batch = 19.2477s	
9218/22750 (epoch 20.259), train_loss = 1.13589529, grad/param norm = 2.4270e-01, time/batch = 16.7631s	
9219/22750 (epoch 20.262), train_loss = 1.01866466, grad/param norm = 1.9187e-01, time/batch = 17.5996s	
9220/22750 (epoch 20.264), train_loss = 0.83213544, grad/param norm = 2.0366e-01, time/batch = 18.2490s	
9221/22750 (epoch 20.266), train_loss = 0.99956453, grad/param norm = 2.0641e-01, time/batch = 19.5343s	
9222/22750 (epoch 20.268), train_loss = 1.15992797, grad/param norm = 2.1341e-01, time/batch = 17.6162s	
9223/22750 (epoch 20.270), train_loss = 0.93044378, grad/param norm = 2.2168e-01, time/batch = 17.3151s	
9224/22750 (epoch 20.273), train_loss = 1.29133499, grad/param norm = 2.2347e-01, time/batch = 18.8255s	
9225/22750 (epoch 20.275), train_loss = 1.12671340, grad/param norm = 1.8725e-01, time/batch = 18.1582s	
9226/22750 (epoch 20.277), train_loss = 0.95020953, grad/param norm = 2.2767e-01, time/batch = 19.6559s	
9227/22750 (epoch 20.279), train_loss = 0.85411717, grad/param norm = 1.9706e-01, time/batch = 17.7595s	
9228/22750 (epoch 20.281), train_loss = 1.14205479, grad/param norm = 1.9880e-01, time/batch = 16.5862s	
9229/22750 (epoch 20.284), train_loss = 0.98348386, grad/param norm = 1.8647e-01, time/batch = 19.4394s	
9230/22750 (epoch 20.286), train_loss = 1.12886857, grad/param norm = 2.0138e-01, time/batch = 19.4514s	
9231/22750 (epoch 20.288), train_loss = 1.17877455, grad/param norm = 2.0297e-01, time/batch = 18.1671s	
9232/22750 (epoch 20.290), train_loss = 1.02600759, grad/param norm = 1.9464e-01, time/batch = 19.2365s	
9233/22750 (epoch 20.292), train_loss = 1.08109466, grad/param norm = 2.3341e-01, time/batch = 18.2469s	
9234/22750 (epoch 20.295), train_loss = 1.06940549, grad/param norm = 1.8738e-01, time/batch = 19.7273s	
9235/22750 (epoch 20.297), train_loss = 0.99580374, grad/param norm = 1.9373e-01, time/batch = 19.4079s	
9236/22750 (epoch 20.299), train_loss = 1.15561475, grad/param norm = 1.9741e-01, time/batch = 17.4091s	
9237/22750 (epoch 20.301), train_loss = 1.03853269, grad/param norm = 1.8869e-01, time/batch = 19.7668s	
9238/22750 (epoch 20.303), train_loss = 1.09040702, grad/param norm = 1.9217e-01, time/batch = 19.8860s	
9239/22750 (epoch 20.305), train_loss = 1.22610592, grad/param norm = 2.0097e-01, time/batch = 17.0442s	
9240/22750 (epoch 20.308), train_loss = 1.08826545, grad/param norm = 1.8284e-01, time/batch = 19.9350s	
9241/22750 (epoch 20.310), train_loss = 0.90654235, grad/param norm = 1.9651e-01, time/batch = 16.5979s	
9242/22750 (epoch 20.312), train_loss = 1.03547376, grad/param norm = 1.8381e-01, time/batch = 16.8998s	
9243/22750 (epoch 20.314), train_loss = 1.01481373, grad/param norm = 1.9218e-01, time/batch = 17.7943s	
9244/22750 (epoch 20.316), train_loss = 0.97832160, grad/param norm = 1.8933e-01, time/batch = 16.8172s	
9245/22750 (epoch 20.319), train_loss = 1.02783560, grad/param norm = 1.9786e-01, time/batch = 16.2537s	
9246/22750 (epoch 20.321), train_loss = 0.97004062, grad/param norm = 2.0373e-01, time/batch = 16.9258s	
9247/22750 (epoch 20.323), train_loss = 1.04426079, grad/param norm = 2.2606e-01, time/batch = 17.6932s	
9248/22750 (epoch 20.325), train_loss = 0.87359942, grad/param norm = 2.0089e-01, time/batch = 18.9346s	
9249/22750 (epoch 20.327), train_loss = 0.98971071, grad/param norm = 1.8914e-01, time/batch = 18.8549s	
9250/22750 (epoch 20.330), train_loss = 1.25001274, grad/param norm = 2.1105e-01, time/batch = 18.6062s	
9251/22750 (epoch 20.332), train_loss = 1.23018677, grad/param norm = 1.9921e-01, time/batch = 18.2748s	
9252/22750 (epoch 20.334), train_loss = 0.84061475, grad/param norm = 1.8159e-01, time/batch = 22.8341s	
9253/22750 (epoch 20.336), train_loss = 1.09336601, grad/param norm = 1.9794e-01, time/batch = 28.2909s	
9254/22750 (epoch 20.338), train_loss = 0.98753050, grad/param norm = 1.8953e-01, time/batch = 18.9328s	
9255/22750 (epoch 20.341), train_loss = 1.00449751, grad/param norm = 2.0198e-01, time/batch = 18.2628s	
9256/22750 (epoch 20.343), train_loss = 0.88318881, grad/param norm = 2.0460e-01, time/batch = 20.2670s	
9257/22750 (epoch 20.345), train_loss = 1.11262619, grad/param norm = 2.2350e-01, time/batch = 20.8452s	
9258/22750 (epoch 20.347), train_loss = 1.16371458, grad/param norm = 2.1460e-01, time/batch = 18.1128s	
9259/22750 (epoch 20.349), train_loss = 0.81253611, grad/param norm = 2.0247e-01, time/batch = 18.4033s	
9260/22750 (epoch 20.352), train_loss = 1.12541658, grad/param norm = 2.0951e-01, time/batch = 18.4021s	
9261/22750 (epoch 20.354), train_loss = 1.12696450, grad/param norm = 1.9573e-01, time/batch = 17.9237s	
9262/22750 (epoch 20.356), train_loss = 1.14675579, grad/param norm = 2.0693e-01, time/batch = 19.0812s	
9263/22750 (epoch 20.358), train_loss = 1.02528055, grad/param norm = 2.0798e-01, time/batch = 18.4186s	
9264/22750 (epoch 20.360), train_loss = 1.21316960, grad/param norm = 1.9578e-01, time/batch = 18.5994s	
9265/22750 (epoch 20.363), train_loss = 0.98491231, grad/param norm = 1.8436e-01, time/batch = 17.1492s	
9266/22750 (epoch 20.365), train_loss = 0.82874055, grad/param norm = 1.9508e-01, time/batch = 16.4316s	
9267/22750 (epoch 20.367), train_loss = 0.89866037, grad/param norm = 1.9894e-01, time/batch = 16.2313s	
9268/22750 (epoch 20.369), train_loss = 1.00121602, grad/param norm = 1.9811e-01, time/batch = 16.3317s	
9269/22750 (epoch 20.371), train_loss = 0.99417507, grad/param norm = 1.9235e-01, time/batch = 18.0997s	
9270/22750 (epoch 20.374), train_loss = 0.93381712, grad/param norm = 1.8640e-01, time/batch = 17.4283s	
9271/22750 (epoch 20.376), train_loss = 0.98149365, grad/param norm = 1.8992e-01, time/batch = 17.1218s	
9272/22750 (epoch 20.378), train_loss = 1.01932546, grad/param norm = 1.9038e-01, time/batch = 17.0412s	
9273/22750 (epoch 20.380), train_loss = 1.12266573, grad/param norm = 2.0030e-01, time/batch = 17.5021s	
9274/22750 (epoch 20.382), train_loss = 0.96179287, grad/param norm = 1.8386e-01, time/batch = 18.2635s	
9275/22750 (epoch 20.385), train_loss = 1.09444355, grad/param norm = 1.8486e-01, time/batch = 18.3609s	
9276/22750 (epoch 20.387), train_loss = 1.04303278, grad/param norm = 1.7698e-01, time/batch = 18.3502s	
9277/22750 (epoch 20.389), train_loss = 0.82148833, grad/param norm = 1.8974e-01, time/batch = 18.5898s	
9278/22750 (epoch 20.391), train_loss = 0.63418766, grad/param norm = 1.4406e-01, time/batch = 16.7666s	
9279/22750 (epoch 20.393), train_loss = 0.86247785, grad/param norm = 1.6812e-01, time/batch = 17.8376s	
9280/22750 (epoch 20.396), train_loss = 1.06379517, grad/param norm = 1.9508e-01, time/batch = 18.6709s	
9281/22750 (epoch 20.398), train_loss = 0.97298651, grad/param norm = 1.8437e-01, time/batch = 18.6625s	
9282/22750 (epoch 20.400), train_loss = 1.00117536, grad/param norm = 1.8322e-01, time/batch = 19.0747s	
9283/22750 (epoch 20.402), train_loss = 1.07137457, grad/param norm = 1.9508e-01, time/batch = 19.5813s	
9284/22750 (epoch 20.404), train_loss = 1.15400610, grad/param norm = 2.0138e-01, time/batch = 19.1068s	
9285/22750 (epoch 20.407), train_loss = 1.11136846, grad/param norm = 1.9168e-01, time/batch = 20.5807s	
9286/22750 (epoch 20.409), train_loss = 0.96698754, grad/param norm = 1.8693e-01, time/batch = 18.5885s	
9287/22750 (epoch 20.411), train_loss = 0.99593000, grad/param norm = 2.0464e-01, time/batch = 19.1467s	
9288/22750 (epoch 20.413), train_loss = 0.77351337, grad/param norm = 1.9287e-01, time/batch = 19.5691s	
9289/22750 (epoch 20.415), train_loss = 0.76682522, grad/param norm = 1.6625e-01, time/batch = 18.8219s	
9290/22750 (epoch 20.418), train_loss = 0.95545432, grad/param norm = 2.1103e-01, time/batch = 19.5757s	
9291/22750 (epoch 20.420), train_loss = 1.09058745, grad/param norm = 2.3000e-01, time/batch = 18.9167s	
9292/22750 (epoch 20.422), train_loss = 1.24782812, grad/param norm = 2.5395e-01, time/batch = 19.3603s	
9293/22750 (epoch 20.424), train_loss = 1.23947539, grad/param norm = 2.2841e-01, time/batch = 19.5143s	
9294/22750 (epoch 20.426), train_loss = 1.23228221, grad/param norm = 2.1523e-01, time/batch = 18.4249s	
9295/22750 (epoch 20.429), train_loss = 0.90309522, grad/param norm = 1.8922e-01, time/batch = 17.5749s	
9296/22750 (epoch 20.431), train_loss = 0.83030386, grad/param norm = 1.8418e-01, time/batch = 19.7513s	
9297/22750 (epoch 20.433), train_loss = 0.94457961, grad/param norm = 2.0027e-01, time/batch = 17.9221s	
9298/22750 (epoch 20.435), train_loss = 0.79000834, grad/param norm = 1.7912e-01, time/batch = 16.7556s	
9299/22750 (epoch 20.437), train_loss = 0.68277518, grad/param norm = 1.8028e-01, time/batch = 17.5152s	
9300/22750 (epoch 20.440), train_loss = 1.02155071, grad/param norm = 2.2152e-01, time/batch = 17.1450s	
9301/22750 (epoch 20.442), train_loss = 1.03000297, grad/param norm = 2.1420e-01, time/batch = 0.7006s	
9302/22750 (epoch 20.444), train_loss = 1.00521519, grad/param norm = 2.2537e-01, time/batch = 0.7166s	
9303/22750 (epoch 20.446), train_loss = 1.01352445, grad/param norm = 2.1425e-01, time/batch = 0.7076s	
9304/22750 (epoch 20.448), train_loss = 1.28563618, grad/param norm = 2.1968e-01, time/batch = 0.6942s	
9305/22750 (epoch 20.451), train_loss = 1.20999787, grad/param norm = 2.0815e-01, time/batch = 0.6943s	
9306/22750 (epoch 20.453), train_loss = 1.18806070, grad/param norm = 2.1931e-01, time/batch = 0.6917s	
9307/22750 (epoch 20.455), train_loss = 1.28754611, grad/param norm = 2.3123e-01, time/batch = 0.6919s	
9308/22750 (epoch 20.457), train_loss = 1.13114673, grad/param norm = 3.6159e-01, time/batch = 0.9751s	
9309/22750 (epoch 20.459), train_loss = 1.13290566, grad/param norm = 1.9544e-01, time/batch = 1.0180s	
9310/22750 (epoch 20.462), train_loss = 1.10683956, grad/param norm = 1.9260e-01, time/batch = 1.0197s	
9311/22750 (epoch 20.464), train_loss = 0.86997964, grad/param norm = 2.0347e-01, time/batch = 1.0228s	
9312/22750 (epoch 20.466), train_loss = 1.20297253, grad/param norm = 2.3258e-01, time/batch = 1.0157s	
9313/22750 (epoch 20.468), train_loss = 1.01356234, grad/param norm = 2.0299e-01, time/batch = 1.8998s	
9314/22750 (epoch 20.470), train_loss = 1.14998232, grad/param norm = 2.1394e-01, time/batch = 1.9051s	
9315/22750 (epoch 20.473), train_loss = 1.01587262, grad/param norm = 1.9691e-01, time/batch = 9.6456s	
9316/22750 (epoch 20.475), train_loss = 1.04193691, grad/param norm = 2.1710e-01, time/batch = 18.5992s	
9317/22750 (epoch 20.477), train_loss = 0.87104265, grad/param norm = 1.8522e-01, time/batch = 18.2774s	
9318/22750 (epoch 20.479), train_loss = 0.86106261, grad/param norm = 1.9458e-01, time/batch = 16.9078s	
9319/22750 (epoch 20.481), train_loss = 0.81844330, grad/param norm = 1.9521e-01, time/batch = 17.9348s	
9320/22750 (epoch 20.484), train_loss = 0.72847738, grad/param norm = 1.9410e-01, time/batch = 18.3924s	
9321/22750 (epoch 20.486), train_loss = 0.85496898, grad/param norm = 2.0431e-01, time/batch = 18.7331s	
9322/22750 (epoch 20.488), train_loss = 0.75534421, grad/param norm = 1.8690e-01, time/batch = 18.3386s	
9323/22750 (epoch 20.490), train_loss = 1.00591126, grad/param norm = 1.8888e-01, time/batch = 19.0665s	
9324/22750 (epoch 20.492), train_loss = 1.15640879, grad/param norm = 2.1561e-01, time/batch = 18.3607s	
9325/22750 (epoch 20.495), train_loss = 0.88884196, grad/param norm = 1.7779e-01, time/batch = 19.6891s	
9326/22750 (epoch 20.497), train_loss = 0.99978845, grad/param norm = 2.3269e-01, time/batch = 20.3500s	
9327/22750 (epoch 20.499), train_loss = 0.91734462, grad/param norm = 2.0644e-01, time/batch = 18.0669s	
9328/22750 (epoch 20.501), train_loss = 0.99584865, grad/param norm = 1.9443e-01, time/batch = 19.1613s	
9329/22750 (epoch 20.503), train_loss = 1.00897731, grad/param norm = 1.9360e-01, time/batch = 19.4911s	
9330/22750 (epoch 20.505), train_loss = 0.86560548, grad/param norm = 1.7816e-01, time/batch = 18.4140s	
9331/22750 (epoch 20.508), train_loss = 0.82354526, grad/param norm = 1.9748e-01, time/batch = 18.7379s	
9332/22750 (epoch 20.510), train_loss = 0.84054904, grad/param norm = 1.7602e-01, time/batch = 19.9380s	
9333/22750 (epoch 20.512), train_loss = 0.88250382, grad/param norm = 1.8113e-01, time/batch = 19.6020s	
9334/22750 (epoch 20.514), train_loss = 0.94322133, grad/param norm = 1.9944e-01, time/batch = 19.1592s	
9335/22750 (epoch 20.516), train_loss = 0.92283551, grad/param norm = 1.8913e-01, time/batch = 19.1848s	
9336/22750 (epoch 20.519), train_loss = 1.08287503, grad/param norm = 2.0691e-01, time/batch = 17.5761s	
9337/22750 (epoch 20.521), train_loss = 1.00728375, grad/param norm = 2.0858e-01, time/batch = 18.9095s	
9338/22750 (epoch 20.523), train_loss = 0.94735844, grad/param norm = 2.2286e-01, time/batch = 16.5540s	
9339/22750 (epoch 20.525), train_loss = 1.14784750, grad/param norm = 2.2387e-01, time/batch = 16.2544s	
9340/22750 (epoch 20.527), train_loss = 1.01579549, grad/param norm = 2.0904e-01, time/batch = 16.2588s	
9341/22750 (epoch 20.530), train_loss = 0.92285720, grad/param norm = 2.1206e-01, time/batch = 18.8413s	
9342/22750 (epoch 20.532), train_loss = 0.85320417, grad/param norm = 1.7615e-01, time/batch = 19.8404s	
9343/22750 (epoch 20.534), train_loss = 1.09525453, grad/param norm = 2.0660e-01, time/batch = 18.1116s	
9344/22750 (epoch 20.536), train_loss = 1.03583903, grad/param norm = 1.8098e-01, time/batch = 19.6748s	
9345/22750 (epoch 20.538), train_loss = 1.01318410, grad/param norm = 1.8335e-01, time/batch = 17.7630s	
9346/22750 (epoch 20.541), train_loss = 0.86817866, grad/param norm = 1.9499e-01, time/batch = 18.6595s	
9347/22750 (epoch 20.543), train_loss = 0.87812112, grad/param norm = 2.0831e-01, time/batch = 19.8417s	
9348/22750 (epoch 20.545), train_loss = 1.09864187, grad/param norm = 1.9860e-01, time/batch = 18.1766s	
9349/22750 (epoch 20.547), train_loss = 0.91917736, grad/param norm = 1.8413e-01, time/batch = 17.6812s	
9350/22750 (epoch 20.549), train_loss = 0.94417471, grad/param norm = 1.8019e-01, time/batch = 18.8425s	
9351/22750 (epoch 20.552), train_loss = 1.04510209, grad/param norm = 2.2294e-01, time/batch = 21.0170s	
9352/22750 (epoch 20.554), train_loss = 1.07172522, grad/param norm = 2.1192e-01, time/batch = 17.3519s	
9353/22750 (epoch 20.556), train_loss = 0.99833642, grad/param norm = 1.8077e-01, time/batch = 18.7617s	
9354/22750 (epoch 20.558), train_loss = 1.10189810, grad/param norm = 2.1193e-01, time/batch = 20.0758s	
9355/22750 (epoch 20.560), train_loss = 0.94026848, grad/param norm = 1.8887e-01, time/batch = 19.5632s	
9356/22750 (epoch 20.563), train_loss = 1.10534792, grad/param norm = 2.1139e-01, time/batch = 19.4024s	
9357/22750 (epoch 20.565), train_loss = 1.04977311, grad/param norm = 1.9792e-01, time/batch = 19.8740s	
9358/22750 (epoch 20.567), train_loss = 1.02830593, grad/param norm = 1.8103e-01, time/batch = 19.5738s	
9359/22750 (epoch 20.569), train_loss = 0.98596695, grad/param norm = 1.9066e-01, time/batch = 17.7754s	
9360/22750 (epoch 20.571), train_loss = 1.00529217, grad/param norm = 2.1146e-01, time/batch = 17.5868s	
9361/22750 (epoch 20.574), train_loss = 0.92597132, grad/param norm = 1.8800e-01, time/batch = 19.6700s	
9362/22750 (epoch 20.576), train_loss = 0.93788398, grad/param norm = 1.9221e-01, time/batch = 16.7398s	
9363/22750 (epoch 20.578), train_loss = 0.85941767, grad/param norm = 1.8652e-01, time/batch = 16.8537s	
9364/22750 (epoch 20.580), train_loss = 1.02047109, grad/param norm = 2.0598e-01, time/batch = 15.3766s	
9365/22750 (epoch 20.582), train_loss = 0.90742137, grad/param norm = 1.9583e-01, time/batch = 15.2764s	
9366/22750 (epoch 20.585), train_loss = 0.85676125, grad/param norm = 1.8891e-01, time/batch = 15.8354s	
9367/22750 (epoch 20.587), train_loss = 0.84248207, grad/param norm = 1.6985e-01, time/batch = 15.3543s	
9368/22750 (epoch 20.589), train_loss = 0.80684150, grad/param norm = 1.8240e-01, time/batch = 15.6861s	
9369/22750 (epoch 20.591), train_loss = 0.97100605, grad/param norm = 1.9647e-01, time/batch = 15.1345s	
9370/22750 (epoch 20.593), train_loss = 1.15735624, grad/param norm = 1.9681e-01, time/batch = 15.0557s	
9371/22750 (epoch 20.596), train_loss = 1.14479454, grad/param norm = 1.9484e-01, time/batch = 14.9088s	
9372/22750 (epoch 20.598), train_loss = 1.19442200, grad/param norm = 2.1253e-01, time/batch = 15.4500s	
9373/22750 (epoch 20.600), train_loss = 1.15415921, grad/param norm = 2.1893e-01, time/batch = 14.9756s	
9374/22750 (epoch 20.602), train_loss = 0.91436416, grad/param norm = 1.8304e-01, time/batch = 15.1920s	
9375/22750 (epoch 20.604), train_loss = 0.94576458, grad/param norm = 2.0013e-01, time/batch = 14.7205s	
9376/22750 (epoch 20.607), train_loss = 0.83476611, grad/param norm = 1.6146e-01, time/batch = 15.2646s	
9377/22750 (epoch 20.609), train_loss = 0.78168376, grad/param norm = 1.6907e-01, time/batch = 14.8938s	
9378/22750 (epoch 20.611), train_loss = 0.95008691, grad/param norm = 1.8648e-01, time/batch = 15.1230s	
9379/22750 (epoch 20.613), train_loss = 0.90639368, grad/param norm = 1.7557e-01, time/batch = 14.8806s	
9380/22750 (epoch 20.615), train_loss = 0.92409825, grad/param norm = 1.7740e-01, time/batch = 14.8685s	
9381/22750 (epoch 20.618), train_loss = 0.96335697, grad/param norm = 1.9051e-01, time/batch = 15.3897s	
9382/22750 (epoch 20.620), train_loss = 0.95987008, grad/param norm = 1.8206e-01, time/batch = 14.9726s	
9383/22750 (epoch 20.622), train_loss = 0.80277233, grad/param norm = 1.6718e-01, time/batch = 14.6572s	
9384/22750 (epoch 20.624), train_loss = 0.88953892, grad/param norm = 1.8831e-01, time/batch = 14.9764s	
9385/22750 (epoch 20.626), train_loss = 0.81435814, grad/param norm = 1.7919e-01, time/batch = 15.6198s	
9386/22750 (epoch 20.629), train_loss = 0.91931447, grad/param norm = 1.9828e-01, time/batch = 15.6774s	
9387/22750 (epoch 20.631), train_loss = 0.97658412, grad/param norm = 1.8526e-01, time/batch = 15.0464s	
9388/22750 (epoch 20.633), train_loss = 0.84308872, grad/param norm = 1.7899e-01, time/batch = 15.2051s	
9389/22750 (epoch 20.635), train_loss = 0.99326566, grad/param norm = 1.8761e-01, time/batch = 15.5173s	
9390/22750 (epoch 20.637), train_loss = 1.05308502, grad/param norm = 2.2411e-01, time/batch = 15.2838s	
9391/22750 (epoch 20.640), train_loss = 1.04670200, grad/param norm = 1.9282e-01, time/batch = 15.8630s	
9392/22750 (epoch 20.642), train_loss = 1.11912698, grad/param norm = 2.0908e-01, time/batch = 15.3895s	
9393/22750 (epoch 20.644), train_loss = 0.98742961, grad/param norm = 1.9070e-01, time/batch = 15.3225s	
9394/22750 (epoch 20.646), train_loss = 1.03098392, grad/param norm = 2.4945e-01, time/batch = 15.3135s	
9395/22750 (epoch 20.648), train_loss = 1.03008051, grad/param norm = 2.0342e-01, time/batch = 15.1374s	
9396/22750 (epoch 20.651), train_loss = 1.04971917, grad/param norm = 1.9599e-01, time/batch = 15.0481s	
9397/22750 (epoch 20.653), train_loss = 1.07448696, grad/param norm = 1.8458e-01, time/batch = 15.7701s	
9398/22750 (epoch 20.655), train_loss = 1.01492548, grad/param norm = 1.8503e-01, time/batch = 15.0485s	
9399/22750 (epoch 20.657), train_loss = 1.16802312, grad/param norm = 2.1033e-01, time/batch = 15.0362s	
9400/22750 (epoch 20.659), train_loss = 1.22787587, grad/param norm = 2.2947e-01, time/batch = 15.1312s	
9401/22750 (epoch 20.662), train_loss = 1.19833277, grad/param norm = 2.2261e-01, time/batch = 15.5232s	
9402/22750 (epoch 20.664), train_loss = 1.05627575, grad/param norm = 2.0129e-01, time/batch = 15.2002s	
9403/22750 (epoch 20.666), train_loss = 0.85428081, grad/param norm = 1.8197e-01, time/batch = 15.0782s	
9404/22750 (epoch 20.668), train_loss = 1.00561885, grad/param norm = 1.9138e-01, time/batch = 15.1537s	
9405/22750 (epoch 20.670), train_loss = 1.01218291, grad/param norm = 2.0909e-01, time/batch = 15.4724s	
9406/22750 (epoch 20.673), train_loss = 1.28757322, grad/param norm = 2.6314e-01, time/batch = 14.9865s	
9407/22750 (epoch 20.675), train_loss = 1.40907144, grad/param norm = 2.6019e-01, time/batch = 15.4399s	
9408/22750 (epoch 20.677), train_loss = 1.17150548, grad/param norm = 2.1596e-01, time/batch = 15.2531s	
9409/22750 (epoch 20.679), train_loss = 1.23597790, grad/param norm = 2.2942e-01, time/batch = 15.5685s	
9410/22750 (epoch 20.681), train_loss = 1.17129706, grad/param norm = 1.9106e-01, time/batch = 15.3586s	
9411/22750 (epoch 20.684), train_loss = 1.18772227, grad/param norm = 2.3106e-01, time/batch = 15.6065s	
9412/22750 (epoch 20.686), train_loss = 1.21001321, grad/param norm = 2.3140e-01, time/batch = 15.0394s	
9413/22750 (epoch 20.688), train_loss = 1.16222211, grad/param norm = 2.0859e-01, time/batch = 15.5415s	
9414/22750 (epoch 20.690), train_loss = 1.15820762, grad/param norm = 2.2661e-01, time/batch = 14.9960s	
9415/22750 (epoch 20.692), train_loss = 1.18676287, grad/param norm = 2.1395e-01, time/batch = 15.0738s	
9416/22750 (epoch 20.695), train_loss = 1.05437493, grad/param norm = 1.9809e-01, time/batch = 14.7515s	
9417/22750 (epoch 20.697), train_loss = 1.01904861, grad/param norm = 1.9400e-01, time/batch = 15.6229s	
9418/22750 (epoch 20.699), train_loss = 1.03031741, grad/param norm = 2.1766e-01, time/batch = 15.2029s	
9419/22750 (epoch 20.701), train_loss = 0.88192288, grad/param norm = 1.9869e-01, time/batch = 15.6914s	
9420/22750 (epoch 20.703), train_loss = 1.00107593, grad/param norm = 1.9295e-01, time/batch = 15.1266s	
9421/22750 (epoch 20.705), train_loss = 0.94822842, grad/param norm = 1.9232e-01, time/batch = 15.2783s	
9422/22750 (epoch 20.708), train_loss = 1.03303747, grad/param norm = 1.8911e-01, time/batch = 15.1279s	
9423/22750 (epoch 20.710), train_loss = 0.89996974, grad/param norm = 2.0521e-01, time/batch = 15.2109s	
9424/22750 (epoch 20.712), train_loss = 0.87931742, grad/param norm = 1.8890e-01, time/batch = 15.1481s	
9425/22750 (epoch 20.714), train_loss = 0.82730399, grad/param norm = 1.7709e-01, time/batch = 15.2305s	
9426/22750 (epoch 20.716), train_loss = 0.87812210, grad/param norm = 1.9606e-01, time/batch = 14.8383s	
9427/22750 (epoch 20.719), train_loss = 1.05805288, grad/param norm = 2.5410e-01, time/batch = 15.0028s	
9428/22750 (epoch 20.721), train_loss = 1.11548678, grad/param norm = 2.0364e-01, time/batch = 15.3879s	
9429/22750 (epoch 20.723), train_loss = 1.08671509, grad/param norm = 2.3177e-01, time/batch = 15.1239s	
9430/22750 (epoch 20.725), train_loss = 1.00719663, grad/param norm = 2.1903e-01, time/batch = 15.0522s	
9431/22750 (epoch 20.727), train_loss = 0.96152590, grad/param norm = 1.8937e-01, time/batch = 15.6132s	
9432/22750 (epoch 20.730), train_loss = 0.96641479, grad/param norm = 2.1079e-01, time/batch = 15.4559s	
9433/22750 (epoch 20.732), train_loss = 0.89534499, grad/param norm = 1.7802e-01, time/batch = 14.7984s	
9434/22750 (epoch 20.734), train_loss = 0.78912784, grad/param norm = 1.6673e-01, time/batch = 15.3513s	
9435/22750 (epoch 20.736), train_loss = 0.94359043, grad/param norm = 1.9982e-01, time/batch = 14.5551s	
9436/22750 (epoch 20.738), train_loss = 1.07482811, grad/param norm = 2.1470e-01, time/batch = 14.9948s	
9437/22750 (epoch 20.741), train_loss = 1.11715545, grad/param norm = 2.1649e-01, time/batch = 14.9200s	
9438/22750 (epoch 20.743), train_loss = 1.05526602, grad/param norm = 1.9183e-01, time/batch = 14.9011s	
9439/22750 (epoch 20.745), train_loss = 0.86419727, grad/param norm = 1.7427e-01, time/batch = 14.9030s	
9440/22750 (epoch 20.747), train_loss = 0.94277902, grad/param norm = 1.7692e-01, time/batch = 15.4446s	
9441/22750 (epoch 20.749), train_loss = 1.16906634, grad/param norm = 2.1875e-01, time/batch = 14.8838s	
9442/22750 (epoch 20.752), train_loss = 0.98735058, grad/param norm = 1.9912e-01, time/batch = 14.6409s	
9443/22750 (epoch 20.754), train_loss = 1.01559593, grad/param norm = 2.0097e-01, time/batch = 14.8076s	
9444/22750 (epoch 20.756), train_loss = 0.90941870, grad/param norm = 2.0595e-01, time/batch = 15.8506s	
9445/22750 (epoch 20.758), train_loss = 0.89016518, grad/param norm = 1.8768e-01, time/batch = 15.1198s	
9446/22750 (epoch 20.760), train_loss = 0.95600564, grad/param norm = 1.9562e-01, time/batch = 14.7957s	
9447/22750 (epoch 20.763), train_loss = 1.03173341, grad/param norm = 2.1630e-01, time/batch = 14.7322s	
9448/22750 (epoch 20.765), train_loss = 1.00347235, grad/param norm = 2.1393e-01, time/batch = 15.2153s	
9449/22750 (epoch 20.767), train_loss = 1.05238199, grad/param norm = 2.3865e-01, time/batch = 14.9072s	
9450/22750 (epoch 20.769), train_loss = 1.24500982, grad/param norm = 2.2896e-01, time/batch = 14.7311s	
9451/22750 (epoch 20.771), train_loss = 1.16046132, grad/param norm = 2.3277e-01, time/batch = 15.1188s	
9452/22750 (epoch 20.774), train_loss = 0.97633941, grad/param norm = 2.1301e-01, time/batch = 15.3708s	
9453/22750 (epoch 20.776), train_loss = 1.06798657, grad/param norm = 2.0585e-01, time/batch = 15.2890s	
9454/22750 (epoch 20.778), train_loss = 1.18478540, grad/param norm = 2.1899e-01, time/batch = 15.1923s	
9455/22750 (epoch 20.780), train_loss = 1.02592299, grad/param norm = 2.0376e-01, time/batch = 14.8086s	
9456/22750 (epoch 20.782), train_loss = 1.18309171, grad/param norm = 2.2372e-01, time/batch = 15.4366s	
9457/22750 (epoch 20.785), train_loss = 1.01537221, grad/param norm = 2.0219e-01, time/batch = 15.3682s	
9458/22750 (epoch 20.787), train_loss = 0.91001840, grad/param norm = 2.0682e-01, time/batch = 17.0581s	
9459/22750 (epoch 20.789), train_loss = 0.99021879, grad/param norm = 1.8440e-01, time/batch = 15.2315s	
9460/22750 (epoch 20.791), train_loss = 0.95517022, grad/param norm = 1.8778e-01, time/batch = 16.0347s	
9461/22750 (epoch 20.793), train_loss = 0.93067130, grad/param norm = 2.1351e-01, time/batch = 19.5148s	
9462/22750 (epoch 20.796), train_loss = 0.82586897, grad/param norm = 1.7152e-01, time/batch = 18.3889s	
9463/22750 (epoch 20.798), train_loss = 0.89514463, grad/param norm = 1.8024e-01, time/batch = 17.9295s	
9464/22750 (epoch 20.800), train_loss = 0.92469723, grad/param norm = 1.9682e-01, time/batch = 19.2500s	
9465/22750 (epoch 20.802), train_loss = 0.86580215, grad/param norm = 2.0250e-01, time/batch = 18.3417s	
9466/22750 (epoch 20.804), train_loss = 1.15859565, grad/param norm = 2.1760e-01, time/batch = 18.5164s	
9467/22750 (epoch 20.807), train_loss = 1.08360887, grad/param norm = 1.9105e-01, time/batch = 18.9369s	
9468/22750 (epoch 20.809), train_loss = 1.17051965, grad/param norm = 2.1400e-01, time/batch = 18.8643s	
9469/22750 (epoch 20.811), train_loss = 0.96258858, grad/param norm = 2.0324e-01, time/batch = 18.8630s	
9470/22750 (epoch 20.813), train_loss = 1.05835879, grad/param norm = 2.0173e-01, time/batch = 19.5255s	
9471/22750 (epoch 20.815), train_loss = 1.19691274, grad/param norm = 2.1179e-01, time/batch = 16.3394s	
9472/22750 (epoch 20.818), train_loss = 1.13506314, grad/param norm = 1.9169e-01, time/batch = 16.0149s	
9473/22750 (epoch 20.820), train_loss = 1.26386344, grad/param norm = 1.8887e-01, time/batch = 17.1399s	
9474/22750 (epoch 20.822), train_loss = 1.07312891, grad/param norm = 1.9790e-01, time/batch = 16.0838s	
9475/22750 (epoch 20.824), train_loss = 0.92493040, grad/param norm = 1.7301e-01, time/batch = 15.9084s	
9476/22750 (epoch 20.826), train_loss = 0.99080510, grad/param norm = 1.7700e-01, time/batch = 15.8180s	
9477/22750 (epoch 20.829), train_loss = 1.19753051, grad/param norm = 2.2229e-01, time/batch = 31.7184s	
9478/22750 (epoch 20.831), train_loss = 1.11635349, grad/param norm = 1.8779e-01, time/batch = 18.2648s	
9479/22750 (epoch 20.833), train_loss = 1.04630285, grad/param norm = 2.0929e-01, time/batch = 17.5201s	
9480/22750 (epoch 20.835), train_loss = 0.94304174, grad/param norm = 1.8636e-01, time/batch = 15.5894s	
9481/22750 (epoch 20.837), train_loss = 0.97466668, grad/param norm = 1.8458e-01, time/batch = 15.7367s	
9482/22750 (epoch 20.840), train_loss = 0.88513641, grad/param norm = 1.7208e-01, time/batch = 17.6645s	
9483/22750 (epoch 20.842), train_loss = 0.93166643, grad/param norm = 1.8362e-01, time/batch = 18.1554s	
9484/22750 (epoch 20.844), train_loss = 1.08335932, grad/param norm = 2.1254e-01, time/batch = 19.9920s	
9485/22750 (epoch 20.846), train_loss = 1.04559610, grad/param norm = 2.0470e-01, time/batch = 17.2117s	
9486/22750 (epoch 20.848), train_loss = 0.92983271, grad/param norm = 1.7361e-01, time/batch = 18.6708s	
9487/22750 (epoch 20.851), train_loss = 0.90001999, grad/param norm = 1.8142e-01, time/batch = 19.8494s	
9488/22750 (epoch 20.853), train_loss = 1.06447260, grad/param norm = 1.8953e-01, time/batch = 18.5286s	
9489/22750 (epoch 20.855), train_loss = 0.88518845, grad/param norm = 1.7278e-01, time/batch = 17.0195s	
9490/22750 (epoch 20.857), train_loss = 1.03436967, grad/param norm = 1.8235e-01, time/batch = 19.4779s	
9491/22750 (epoch 20.859), train_loss = 1.08414217, grad/param norm = 2.0937e-01, time/batch = 17.3147s	
9492/22750 (epoch 20.862), train_loss = 1.18474006, grad/param norm = 2.1725e-01, time/batch = 17.4086s	
9493/22750 (epoch 20.864), train_loss = 1.00872886, grad/param norm = 1.9490e-01, time/batch = 17.4149s	
9494/22750 (epoch 20.866), train_loss = 1.04597028, grad/param norm = 1.7652e-01, time/batch = 17.5867s	
9495/22750 (epoch 20.868), train_loss = 0.93807031, grad/param norm = 1.7540e-01, time/batch = 19.2503s	
9496/22750 (epoch 20.870), train_loss = 0.82400590, grad/param norm = 1.6959e-01, time/batch = 18.0134s	
9497/22750 (epoch 20.873), train_loss = 0.96443064, grad/param norm = 1.7912e-01, time/batch = 19.1994s	
9498/22750 (epoch 20.875), train_loss = 1.08459128, grad/param norm = 2.0360e-01, time/batch = 19.4529s	
9499/22750 (epoch 20.877), train_loss = 0.89641509, grad/param norm = 1.8235e-01, time/batch = 19.2666s	
9500/22750 (epoch 20.879), train_loss = 1.16129721, grad/param norm = 2.0481e-01, time/batch = 18.6748s	
9501/22750 (epoch 20.881), train_loss = 1.09065835, grad/param norm = 1.8884e-01, time/batch = 17.5097s	
9502/22750 (epoch 20.884), train_loss = 0.94899935, grad/param norm = 2.0951e-01, time/batch = 18.4210s	
9503/22750 (epoch 20.886), train_loss = 1.08271791, grad/param norm = 1.9693e-01, time/batch = 19.5624s	
9504/22750 (epoch 20.888), train_loss = 1.07220640, grad/param norm = 1.8513e-01, time/batch = 17.9959s	
9505/22750 (epoch 20.890), train_loss = 1.09698072, grad/param norm = 2.0250e-01, time/batch = 17.7653s	
9506/22750 (epoch 20.892), train_loss = 1.35184216, grad/param norm = 2.3495e-01, time/batch = 19.7769s	
9507/22750 (epoch 20.895), train_loss = 1.04514962, grad/param norm = 1.9906e-01, time/batch = 19.6880s	
9508/22750 (epoch 20.897), train_loss = 1.11293827, grad/param norm = 2.0728e-01, time/batch = 20.2450s	
9509/22750 (epoch 20.899), train_loss = 1.07080822, grad/param norm = 1.9781e-01, time/batch = 17.7520s	
9510/22750 (epoch 20.901), train_loss = 1.16858260, grad/param norm = 2.1985e-01, time/batch = 18.5640s	
9511/22750 (epoch 20.903), train_loss = 1.01710738, grad/param norm = 2.1237e-01, time/batch = 20.2459s	
9512/22750 (epoch 20.905), train_loss = 1.11184990, grad/param norm = 1.9755e-01, time/batch = 18.0839s	
9513/22750 (epoch 20.908), train_loss = 0.94194276, grad/param norm = 2.0792e-01, time/batch = 19.1704s	
9514/22750 (epoch 20.910), train_loss = 0.81661935, grad/param norm = 1.9078e-01, time/batch = 16.9427s	
9515/22750 (epoch 20.912), train_loss = 0.97278647, grad/param norm = 1.9288e-01, time/batch = 19.4383s	
9516/22750 (epoch 20.914), train_loss = 0.99626132, grad/param norm = 1.8511e-01, time/batch = 20.5205s	
9517/22750 (epoch 20.916), train_loss = 0.84271530, grad/param norm = 1.8095e-01, time/batch = 18.8519s	
9518/22750 (epoch 20.919), train_loss = 0.98617774, grad/param norm = 2.2640e-01, time/batch = 17.0980s	
9519/22750 (epoch 20.921), train_loss = 0.76024920, grad/param norm = 1.6638e-01, time/batch = 17.9253s	
9520/22750 (epoch 20.923), train_loss = 0.90828281, grad/param norm = 1.9323e-01, time/batch = 16.4991s	
9521/22750 (epoch 20.925), train_loss = 0.97511851, grad/param norm = 1.7411e-01, time/batch = 15.6551s	
9522/22750 (epoch 20.927), train_loss = 0.78409709, grad/param norm = 1.8985e-01, time/batch = 17.3372s	
9523/22750 (epoch 20.930), train_loss = 0.79899684, grad/param norm = 1.7355e-01, time/batch = 17.7861s	
9524/22750 (epoch 20.932), train_loss = 1.00681855, grad/param norm = 1.9038e-01, time/batch = 18.2734s	
9525/22750 (epoch 20.934), train_loss = 0.76562592, grad/param norm = 1.5340e-01, time/batch = 17.9301s	
9526/22750 (epoch 20.936), train_loss = 1.12744367, grad/param norm = 2.0356e-01, time/batch = 19.9331s	
9527/22750 (epoch 20.938), train_loss = 1.07547004, grad/param norm = 1.7036e-01, time/batch = 18.4326s	
9528/22750 (epoch 20.941), train_loss = 1.18575260, grad/param norm = 2.1112e-01, time/batch = 17.6605s	
9529/22750 (epoch 20.943), train_loss = 1.02895605, grad/param norm = 2.0448e-01, time/batch = 17.7579s	
9530/22750 (epoch 20.945), train_loss = 1.02246929, grad/param norm = 1.9833e-01, time/batch = 20.3284s	
9531/22750 (epoch 20.947), train_loss = 0.96567311, grad/param norm = 2.0526e-01, time/batch = 18.7408s	
9532/22750 (epoch 20.949), train_loss = 0.90560133, grad/param norm = 1.9535e-01, time/batch = 19.2428s	
9533/22750 (epoch 20.952), train_loss = 0.91770754, grad/param norm = 1.6859e-01, time/batch = 18.6123s	
9534/22750 (epoch 20.954), train_loss = 0.89145047, grad/param norm = 1.8091e-01, time/batch = 16.4874s	
9535/22750 (epoch 20.956), train_loss = 1.01383797, grad/param norm = 1.8994e-01, time/batch = 19.8500s	
9536/22750 (epoch 20.958), train_loss = 0.94304998, grad/param norm = 1.6953e-01, time/batch = 19.1707s	
9537/22750 (epoch 20.960), train_loss = 0.89162543, grad/param norm = 1.7436e-01, time/batch = 20.3286s	
9538/22750 (epoch 20.963), train_loss = 1.08752691, grad/param norm = 2.0956e-01, time/batch = 18.7233s	
9539/22750 (epoch 20.965), train_loss = 1.07951157, grad/param norm = 1.7865e-01, time/batch = 18.1807s	
9540/22750 (epoch 20.967), train_loss = 1.00206329, grad/param norm = 1.9358e-01, time/batch = 16.5251s	
9541/22750 (epoch 20.969), train_loss = 0.91881904, grad/param norm = 2.0254e-01, time/batch = 18.4121s	
9542/22750 (epoch 20.971), train_loss = 0.95831183, grad/param norm = 2.0525e-01, time/batch = 17.0148s	
9543/22750 (epoch 20.974), train_loss = 0.98289394, grad/param norm = 2.0199e-01, time/batch = 17.7849s	
9544/22750 (epoch 20.976), train_loss = 1.04894952, grad/param norm = 2.1074e-01, time/batch = 17.3782s	
9545/22750 (epoch 20.978), train_loss = 0.92310059, grad/param norm = 1.8519e-01, time/batch = 17.5444s	
9546/22750 (epoch 20.980), train_loss = 1.13165341, grad/param norm = 2.1887e-01, time/batch = 18.9970s	
9547/22750 (epoch 20.982), train_loss = 0.90545528, grad/param norm = 1.7833e-01, time/batch = 20.3241s	
9548/22750 (epoch 20.985), train_loss = 1.17941217, grad/param norm = 2.0315e-01, time/batch = 16.3505s	
9549/22750 (epoch 20.987), train_loss = 0.77851510, grad/param norm = 1.6381e-01, time/batch = 17.3250s	
9550/22750 (epoch 20.989), train_loss = 0.95282558, grad/param norm = 1.9782e-01, time/batch = 16.7430s	
9551/22750 (epoch 20.991), train_loss = 1.05245132, grad/param norm = 2.0362e-01, time/batch = 17.4883s	
9552/22750 (epoch 20.993), train_loss = 1.08118711, grad/param norm = 2.3345e-01, time/batch = 15.4580s	
9553/22750 (epoch 20.996), train_loss = 0.92643023, grad/param norm = 2.2306e-01, time/batch = 19.2839s	
9554/22750 (epoch 20.998), train_loss = 1.12791901, grad/param norm = 2.0990e-01, time/batch = 19.8655s	
decayed learning rate by a factor 0.97 to 0.0013876847219909	
9555/22750 (epoch 21.000), train_loss = 1.04947788, grad/param norm = 1.9882e-01, time/batch = 20.1841s	
9556/22750 (epoch 21.002), train_loss = 1.15650168, grad/param norm = 2.1041e-01, time/batch = 19.3314s	
9557/22750 (epoch 21.004), train_loss = 0.93110197, grad/param norm = 1.8321e-01, time/batch = 19.7980s	
9558/22750 (epoch 21.007), train_loss = 0.96916654, grad/param norm = 2.0014e-01, time/batch = 20.6223s	
9559/22750 (epoch 21.009), train_loss = 1.18297851, grad/param norm = 2.3168e-01, time/batch = 22.1002s	
9560/22750 (epoch 21.011), train_loss = 1.25585586, grad/param norm = 2.2724e-01, time/batch = 20.9594s	
9561/22750 (epoch 21.013), train_loss = 1.11798600, grad/param norm = 1.9919e-01, time/batch = 24.2214s	
9562/22750 (epoch 21.015), train_loss = 1.03166985, grad/param norm = 2.1064e-01, time/batch = 22.5458s	
9563/22750 (epoch 21.018), train_loss = 1.09522101, grad/param norm = 2.1569e-01, time/batch = 22.3860s	
9564/22750 (epoch 21.020), train_loss = 1.14497574, grad/param norm = 1.8835e-01, time/batch = 23.6226s	
9565/22750 (epoch 21.022), train_loss = 1.04009636, grad/param norm = 2.1229e-01, time/batch = 23.7702s	
9566/22750 (epoch 21.024), train_loss = 1.01049209, grad/param norm = 1.8962e-01, time/batch = 23.7687s	
9567/22750 (epoch 21.026), train_loss = 1.07941074, grad/param norm = 2.0053e-01, time/batch = 24.5267s	
9568/22750 (epoch 21.029), train_loss = 0.82965065, grad/param norm = 1.8024e-01, time/batch = 23.1374s	
9569/22750 (epoch 21.031), train_loss = 1.26522670, grad/param norm = 2.0689e-01, time/batch = 24.9683s	
9570/22750 (epoch 21.033), train_loss = 1.04728163, grad/param norm = 2.2175e-01, time/batch = 21.4359s	
9571/22750 (epoch 21.035), train_loss = 1.06974707, grad/param norm = 1.9076e-01, time/batch = 20.2602s	
9572/22750 (epoch 21.037), train_loss = 1.14065807, grad/param norm = 1.9571e-01, time/batch = 18.6497s	
9573/22750 (epoch 21.040), train_loss = 0.98814767, grad/param norm = 1.9739e-01, time/batch = 18.2426s	
9574/22750 (epoch 21.042), train_loss = 1.07222962, grad/param norm = 1.9251e-01, time/batch = 18.4042s	
9575/22750 (epoch 21.044), train_loss = 0.96927881, grad/param norm = 2.1074e-01, time/batch = 17.9241s	
9576/22750 (epoch 21.046), train_loss = 1.12924528, grad/param norm = 2.1991e-01, time/batch = 23.5442s	
9577/22750 (epoch 21.048), train_loss = 1.01708690, grad/param norm = 1.9986e-01, time/batch = 15.2239s	
9578/22750 (epoch 21.051), train_loss = 1.07970179, grad/param norm = 1.9700e-01, time/batch = 14.8111s	
9579/22750 (epoch 21.053), train_loss = 0.92589456, grad/param norm = 1.7062e-01, time/batch = 15.1380s	
9580/22750 (epoch 21.055), train_loss = 0.92881455, grad/param norm = 1.9003e-01, time/batch = 15.1214s	
9581/22750 (epoch 21.057), train_loss = 1.17497552, grad/param norm = 1.9087e-01, time/batch = 15.2188s	
9582/22750 (epoch 21.059), train_loss = 0.75781069, grad/param norm = 1.6784e-01, time/batch = 14.9739s	
9583/22750 (epoch 21.062), train_loss = 0.87909477, grad/param norm = 1.8847e-01, time/batch = 15.2054s	
9584/22750 (epoch 21.064), train_loss = 1.07903573, grad/param norm = 2.0659e-01, time/batch = 15.3691s	
9585/22750 (epoch 21.066), train_loss = 0.85724112, grad/param norm = 1.6329e-01, time/batch = 15.3700s	
9586/22750 (epoch 21.068), train_loss = 0.92541651, grad/param norm = 1.6578e-01, time/batch = 15.1314s	
9587/22750 (epoch 21.070), train_loss = 0.77202963, grad/param norm = 1.6635e-01, time/batch = 15.2244s	
9588/22750 (epoch 21.073), train_loss = 0.95822354, grad/param norm = 2.0781e-01, time/batch = 15.7957s	
9589/22750 (epoch 21.075), train_loss = 0.98535353, grad/param norm = 1.9221e-01, time/batch = 16.2501s	
9590/22750 (epoch 21.077), train_loss = 0.77736657, grad/param norm = 1.9752e-01, time/batch = 15.6098s	
9591/22750 (epoch 21.079), train_loss = 0.96376722, grad/param norm = 2.2672e-01, time/batch = 15.2144s	
9592/22750 (epoch 21.081), train_loss = 0.97240092, grad/param norm = 1.9319e-01, time/batch = 15.4480s	
9593/22750 (epoch 21.084), train_loss = 0.94928904, grad/param norm = 1.9686e-01, time/batch = 15.2179s	
9594/22750 (epoch 21.086), train_loss = 0.96201747, grad/param norm = 1.7246e-01, time/batch = 15.2004s	
9595/22750 (epoch 21.088), train_loss = 0.91077130, grad/param norm = 1.8428e-01, time/batch = 15.0518s	
9596/22750 (epoch 21.090), train_loss = 0.90914281, grad/param norm = 1.8273e-01, time/batch = 15.6151s	
9597/22750 (epoch 21.092), train_loss = 1.12650956, grad/param norm = 1.8950e-01, time/batch = 15.2809s	
9598/22750 (epoch 21.095), train_loss = 0.88126975, grad/param norm = 1.8331e-01, time/batch = 14.9936s	
9599/22750 (epoch 21.097), train_loss = 1.00380384, grad/param norm = 1.9568e-01, time/batch = 15.1297s	
9600/22750 (epoch 21.099), train_loss = 0.95256616, grad/param norm = 1.9470e-01, time/batch = 15.7154s	
9601/22750 (epoch 21.101), train_loss = 0.85691249, grad/param norm = 1.6530e-01, time/batch = 15.0748s	
9602/22750 (epoch 21.103), train_loss = 1.00315327, grad/param norm = 1.9262e-01, time/batch = 15.8609s	
9603/22750 (epoch 21.105), train_loss = 1.18312476, grad/param norm = 2.1764e-01, time/batch = 15.5243s	
9604/22750 (epoch 21.108), train_loss = 0.96751866, grad/param norm = 1.9877e-01, time/batch = 15.8503s	
9605/22750 (epoch 21.110), train_loss = 1.13214279, grad/param norm = 2.0293e-01, time/batch = 14.9663s	
9606/22750 (epoch 21.112), train_loss = 0.84807262, grad/param norm = 1.8155e-01, time/batch = 15.1259s	
9607/22750 (epoch 21.114), train_loss = 0.77451870, grad/param norm = 1.7829e-01, time/batch = 14.8699s	
9608/22750 (epoch 21.116), train_loss = 0.91548223, grad/param norm = 1.7990e-01, time/batch = 15.6745s	
9609/22750 (epoch 21.119), train_loss = 0.90417725, grad/param norm = 1.7853e-01, time/batch = 14.9157s	
9610/22750 (epoch 21.121), train_loss = 1.01114840, grad/param norm = 2.0068e-01, time/batch = 15.0750s	
9611/22750 (epoch 21.123), train_loss = 0.87906787, grad/param norm = 2.0214e-01, time/batch = 14.9153s	
9612/22750 (epoch 21.125), train_loss = 1.13767893, grad/param norm = 1.8926e-01, time/batch = 15.3073s	
9613/22750 (epoch 21.127), train_loss = 0.95290774, grad/param norm = 2.0034e-01, time/batch = 15.2912s	
9614/22750 (epoch 21.130), train_loss = 0.97313528, grad/param norm = 1.7276e-01, time/batch = 15.0521s	
9615/22750 (epoch 21.132), train_loss = 0.90716643, grad/param norm = 1.8918e-01, time/batch = 15.2020s	
9616/22750 (epoch 21.134), train_loss = 0.93646328, grad/param norm = 1.8979e-01, time/batch = 15.2881s	
9617/22750 (epoch 21.136), train_loss = 0.82778457, grad/param norm = 1.9692e-01, time/batch = 15.2102s	
9618/22750 (epoch 21.138), train_loss = 1.04890721, grad/param norm = 1.8976e-01, time/batch = 15.3749s	
9619/22750 (epoch 21.141), train_loss = 0.99233803, grad/param norm = 1.9431e-01, time/batch = 15.7698s	
9620/22750 (epoch 21.143), train_loss = 0.87833444, grad/param norm = 1.7899e-01, time/batch = 15.0751s	
9621/22750 (epoch 21.145), train_loss = 1.10798721, grad/param norm = 1.9709e-01, time/batch = 15.0708s	
9622/22750 (epoch 21.147), train_loss = 1.16732733, grad/param norm = 2.1444e-01, time/batch = 16.0528s	
9623/22750 (epoch 21.149), train_loss = 0.99897205, grad/param norm = 1.8856e-01, time/batch = 15.6822s	
9624/22750 (epoch 21.152), train_loss = 0.98347179, grad/param norm = 1.8283e-01, time/batch = 15.4450s	
9625/22750 (epoch 21.154), train_loss = 0.84254166, grad/param norm = 1.9637e-01, time/batch = 15.2819s	
9626/22750 (epoch 21.156), train_loss = 0.87084466, grad/param norm = 1.8674e-01, time/batch = 15.2672s	
9627/22750 (epoch 21.158), train_loss = 0.90577825, grad/param norm = 1.9385e-01, time/batch = 15.9066s	
9628/22750 (epoch 21.160), train_loss = 1.02718099, grad/param norm = 1.9402e-01, time/batch = 15.4424s	
9629/22750 (epoch 21.163), train_loss = 1.20767148, grad/param norm = 2.1637e-01, time/batch = 15.3582s	
9630/22750 (epoch 21.165), train_loss = 1.03994359, grad/param norm = 1.9490e-01, time/batch = 14.8862s	
9631/22750 (epoch 21.167), train_loss = 0.96501624, grad/param norm = 2.2826e-01, time/batch = 15.3755s	
9632/22750 (epoch 21.169), train_loss = 0.98126517, grad/param norm = 1.9551e-01, time/batch = 15.9977s	
9633/22750 (epoch 21.171), train_loss = 0.86070289, grad/param norm = 1.8131e-01, time/batch = 15.5319s	
9634/22750 (epoch 21.174), train_loss = 0.81410752, grad/param norm = 1.7886e-01, time/batch = 15.3611s	
9635/22750 (epoch 21.176), train_loss = 0.90851929, grad/param norm = 1.8755e-01, time/batch = 15.6869s	
9636/22750 (epoch 21.178), train_loss = 0.92156902, grad/param norm = 1.8890e-01, time/batch = 15.1183s	
9637/22750 (epoch 21.180), train_loss = 1.08498477, grad/param norm = 2.4179e-01, time/batch = 15.4377s	
9638/22750 (epoch 21.182), train_loss = 1.10912367, grad/param norm = 2.1253e-01, time/batch = 15.1940s	
9639/22750 (epoch 21.185), train_loss = 1.14150725, grad/param norm = 2.2434e-01, time/batch = 15.6899s	
9640/22750 (epoch 21.187), train_loss = 0.89586934, grad/param norm = 2.0981e-01, time/batch = 15.5223s	
9641/22750 (epoch 21.189), train_loss = 0.90280169, grad/param norm = 1.9463e-01, time/batch = 15.6743s	
9642/22750 (epoch 21.191), train_loss = 0.89637291, grad/param norm = 1.7075e-01, time/batch = 15.3580s	
9643/22750 (epoch 21.193), train_loss = 1.05421033, grad/param norm = 1.9220e-01, time/batch = 15.7630s	
9644/22750 (epoch 21.196), train_loss = 0.95864734, grad/param norm = 1.9045e-01, time/batch = 15.2873s	
9645/22750 (epoch 21.198), train_loss = 0.74512745, grad/param norm = 1.7157e-01, time/batch = 15.3604s	
9646/22750 (epoch 21.200), train_loss = 0.99175956, grad/param norm = 1.8906e-01, time/batch = 15.6280s	
9647/22750 (epoch 21.202), train_loss = 1.07975448, grad/param norm = 2.3051e-01, time/batch = 14.8687s	
9648/22750 (epoch 21.204), train_loss = 0.98271471, grad/param norm = 1.8303e-01, time/batch = 14.7233s	
9649/22750 (epoch 21.207), train_loss = 0.96109202, grad/param norm = 1.8885e-01, time/batch = 16.0523s	
9650/22750 (epoch 21.209), train_loss = 0.90879594, grad/param norm = 1.9340e-01, time/batch = 15.1831s	
9651/22750 (epoch 21.211), train_loss = 0.89056072, grad/param norm = 1.9255e-01, time/batch = 15.1883s	
9652/22750 (epoch 21.213), train_loss = 0.78964063, grad/param norm = 1.7577e-01, time/batch = 14.6527s	
9653/22750 (epoch 21.215), train_loss = 0.75717721, grad/param norm = 1.7368e-01, time/batch = 14.8138s	
9654/22750 (epoch 21.218), train_loss = 0.85606921, grad/param norm = 1.9841e-01, time/batch = 14.9915s	
9655/22750 (epoch 21.220), train_loss = 0.82672525, grad/param norm = 1.7783e-01, time/batch = 14.8991s	
9656/22750 (epoch 21.222), train_loss = 0.82946722, grad/param norm = 1.9012e-01, time/batch = 15.1376s	
9657/22750 (epoch 21.224), train_loss = 0.87911207, grad/param norm = 1.7939e-01, time/batch = 15.6052s	
9658/22750 (epoch 21.226), train_loss = 1.02553690, grad/param norm = 1.9843e-01, time/batch = 15.2303s	
9659/22750 (epoch 21.229), train_loss = 0.99726665, grad/param norm = 1.9125e-01, time/batch = 15.6894s	
9660/22750 (epoch 21.231), train_loss = 0.89164530, grad/param norm = 2.0235e-01, time/batch = 15.7566s	
9661/22750 (epoch 21.233), train_loss = 0.82425644, grad/param norm = 1.8414e-01, time/batch = 15.2060s	
9662/22750 (epoch 21.235), train_loss = 0.79252866, grad/param norm = 1.8405e-01, time/batch = 15.4630s	
9663/22750 (epoch 21.237), train_loss = 0.90707686, grad/param norm = 2.2918e-01, time/batch = 15.9526s	
9664/22750 (epoch 21.240), train_loss = 0.94815527, grad/param norm = 1.8332e-01, time/batch = 19.7691s	
9665/22750 (epoch 21.242), train_loss = 1.20932405, grad/param norm = 2.3247e-01, time/batch = 16.4011s	
9666/22750 (epoch 21.244), train_loss = 1.12570439, grad/param norm = 2.0609e-01, time/batch = 19.3905s	
9667/22750 (epoch 21.246), train_loss = 1.15153490, grad/param norm = 2.1075e-01, time/batch = 18.8366s	
9668/22750 (epoch 21.248), train_loss = 0.97206480, grad/param norm = 2.0998e-01, time/batch = 18.7651s	
9669/22750 (epoch 21.251), train_loss = 1.09414586, grad/param norm = 1.8978e-01, time/batch = 17.6610s	
9670/22750 (epoch 21.253), train_loss = 1.01614744, grad/param norm = 2.6343e-01, time/batch = 19.0919s	
9671/22750 (epoch 21.255), train_loss = 0.98167979, grad/param norm = 1.9869e-01, time/batch = 20.3202s	
9672/22750 (epoch 21.257), train_loss = 0.89678599, grad/param norm = 1.9430e-01, time/batch = 18.7633s	
9673/22750 (epoch 21.259), train_loss = 1.10288378, grad/param norm = 2.1797e-01, time/batch = 19.3652s	
9674/22750 (epoch 21.262), train_loss = 0.99719306, grad/param norm = 2.0511e-01, time/batch = 18.0879s	
9675/22750 (epoch 21.264), train_loss = 0.81387507, grad/param norm = 1.9361e-01, time/batch = 18.9325s	
9676/22750 (epoch 21.266), train_loss = 0.97240387, grad/param norm = 2.0835e-01, time/batch = 19.5697s	
9677/22750 (epoch 21.268), train_loss = 1.14018139, grad/param norm = 2.1601e-01, time/batch = 18.5108s	
9678/22750 (epoch 21.270), train_loss = 0.90478946, grad/param norm = 2.2957e-01, time/batch = 18.5820s	
9679/22750 (epoch 21.273), train_loss = 1.27702610, grad/param norm = 2.5603e-01, time/batch = 18.5080s	
9680/22750 (epoch 21.275), train_loss = 1.11151295, grad/param norm = 1.9290e-01, time/batch = 19.8309s	
9681/22750 (epoch 21.277), train_loss = 0.93068440, grad/param norm = 2.0373e-01, time/batch = 18.0663s	
9682/22750 (epoch 21.279), train_loss = 0.83071305, grad/param norm = 1.9551e-01, time/batch = 30.5879s	
9683/22750 (epoch 21.281), train_loss = 1.12423098, grad/param norm = 2.0308e-01, time/batch = 23.4654s	
9684/22750 (epoch 21.284), train_loss = 0.97022273, grad/param norm = 1.8240e-01, time/batch = 16.4618s	
9685/22750 (epoch 21.286), train_loss = 1.09045568, grad/param norm = 2.0167e-01, time/batch = 19.5602s	
9686/22750 (epoch 21.288), train_loss = 1.16147276, grad/param norm = 2.1658e-01, time/batch = 16.4043s	
9687/22750 (epoch 21.290), train_loss = 1.00457141, grad/param norm = 1.9769e-01, time/batch = 16.1512s	
9688/22750 (epoch 21.292), train_loss = 1.06067677, grad/param norm = 2.2372e-01, time/batch = 16.1618s	
9689/22750 (epoch 21.295), train_loss = 1.04822885, grad/param norm = 1.8788e-01, time/batch = 17.6015s	
9690/22750 (epoch 21.297), train_loss = 0.97745568, grad/param norm = 1.9811e-01, time/batch = 18.1989s	
9691/22750 (epoch 21.299), train_loss = 1.12131492, grad/param norm = 2.0083e-01, time/batch = 16.7025s	
9692/22750 (epoch 21.301), train_loss = 1.01282837, grad/param norm = 1.9552e-01, time/batch = 20.1842s	
9693/22750 (epoch 21.303), train_loss = 1.06841859, grad/param norm = 1.9603e-01, time/batch = 16.5183s	
9694/22750 (epoch 21.305), train_loss = 1.20314519, grad/param norm = 2.1294e-01, time/batch = 18.1680s	
9695/22750 (epoch 21.308), train_loss = 1.06321767, grad/param norm = 1.8593e-01, time/batch = 19.2431s	
9696/22750 (epoch 21.310), train_loss = 0.88770796, grad/param norm = 2.0053e-01, time/batch = 19.3279s	
9697/22750 (epoch 21.312), train_loss = 1.02899220, grad/param norm = 1.9565e-01, time/batch = 17.0711s	
9698/22750 (epoch 21.314), train_loss = 0.99645737, grad/param norm = 1.9548e-01, time/batch = 16.8297s	
9699/22750 (epoch 21.316), train_loss = 0.96605262, grad/param norm = 1.9204e-01, time/batch = 17.2719s	
9700/22750 (epoch 21.319), train_loss = 1.00076460, grad/param norm = 2.0308e-01, time/batch = 18.6289s	
9701/22750 (epoch 21.321), train_loss = 0.92034205, grad/param norm = 1.9410e-01, time/batch = 20.3502s	
9702/22750 (epoch 21.323), train_loss = 1.03042416, grad/param norm = 2.2825e-01, time/batch = 19.5840s	
9703/22750 (epoch 21.325), train_loss = 0.85893930, grad/param norm = 1.9998e-01, time/batch = 19.0045s	
9704/22750 (epoch 21.327), train_loss = 0.97166570, grad/param norm = 1.9417e-01, time/batch = 18.6485s	
9705/22750 (epoch 21.330), train_loss = 1.21981819, grad/param norm = 2.2417e-01, time/batch = 17.8392s	
9706/22750 (epoch 21.332), train_loss = 1.19541763, grad/param norm = 2.0362e-01, time/batch = 18.1727s	
9707/22750 (epoch 21.334), train_loss = 0.82408838, grad/param norm = 1.7982e-01, time/batch = 17.9984s	
9708/22750 (epoch 21.336), train_loss = 1.07005752, grad/param norm = 1.8846e-01, time/batch = 20.6073s	
9709/22750 (epoch 21.338), train_loss = 0.95929170, grad/param norm = 1.9332e-01, time/batch = 20.6085s	
9710/22750 (epoch 21.341), train_loss = 0.97509552, grad/param norm = 1.9421e-01, time/batch = 17.7577s	
9711/22750 (epoch 21.343), train_loss = 0.87437498, grad/param norm = 1.9904e-01, time/batch = 20.4896s	
9712/22750 (epoch 21.345), train_loss = 1.08071491, grad/param norm = 2.2641e-01, time/batch = 19.1700s	
9713/22750 (epoch 21.347), train_loss = 1.13334881, grad/param norm = 2.1158e-01, time/batch = 17.5787s	
9714/22750 (epoch 21.349), train_loss = 0.78312284, grad/param norm = 1.8903e-01, time/batch = 17.6601s	
9715/22750 (epoch 21.352), train_loss = 1.09610542, grad/param norm = 2.1391e-01, time/batch = 17.5020s	
9716/22750 (epoch 21.354), train_loss = 1.10729796, grad/param norm = 2.0636e-01, time/batch = 18.7326s	
9717/22750 (epoch 21.356), train_loss = 1.14653537, grad/param norm = 2.1608e-01, time/batch = 19.4194s	
9718/22750 (epoch 21.358), train_loss = 1.00132829, grad/param norm = 2.0933e-01, time/batch = 20.6826s	
9719/22750 (epoch 21.360), train_loss = 1.19760731, grad/param norm = 1.9862e-01, time/batch = 18.1064s	
9720/22750 (epoch 21.363), train_loss = 0.96918902, grad/param norm = 1.9129e-01, time/batch = 18.5066s	
9721/22750 (epoch 21.365), train_loss = 0.80904879, grad/param norm = 1.8852e-01, time/batch = 18.5877s	
9722/22750 (epoch 21.367), train_loss = 0.87373907, grad/param norm = 1.9944e-01, time/batch = 18.9057s	
9723/22750 (epoch 21.369), train_loss = 0.98842332, grad/param norm = 2.0110e-01, time/batch = 18.7552s	
9724/22750 (epoch 21.371), train_loss = 0.96756658, grad/param norm = 2.0376e-01, time/batch = 18.8375s	
9725/22750 (epoch 21.374), train_loss = 0.91491706, grad/param norm = 2.1061e-01, time/batch = 21.0061s	
9726/22750 (epoch 21.376), train_loss = 0.96494565, grad/param norm = 1.9069e-01, time/batch = 19.4228s	
9727/22750 (epoch 21.378), train_loss = 0.99923001, grad/param norm = 1.8875e-01, time/batch = 20.0353s	
9728/22750 (epoch 21.380), train_loss = 1.10947571, grad/param norm = 2.0399e-01, time/batch = 19.6581s	
9729/22750 (epoch 21.382), train_loss = 0.94259286, grad/param norm = 1.8238e-01, time/batch = 17.9923s	
9730/22750 (epoch 21.385), train_loss = 1.07234879, grad/param norm = 1.9052e-01, time/batch = 18.3403s	
9731/22750 (epoch 21.387), train_loss = 1.03071341, grad/param norm = 1.8451e-01, time/batch = 18.4214s	
9732/22750 (epoch 21.389), train_loss = 0.81161961, grad/param norm = 1.9143e-01, time/batch = 17.4893s	
9733/22750 (epoch 21.391), train_loss = 0.62602502, grad/param norm = 1.5375e-01, time/batch = 18.1745s	
9734/22750 (epoch 21.393), train_loss = 0.83895672, grad/param norm = 1.6807e-01, time/batch = 20.3552s	
9735/22750 (epoch 21.396), train_loss = 1.05133171, grad/param norm = 2.1362e-01, time/batch = 15.5446s	
9736/22750 (epoch 21.398), train_loss = 0.97020893, grad/param norm = 1.9202e-01, time/batch = 17.6987s	
9737/22750 (epoch 21.400), train_loss = 0.97869539, grad/param norm = 1.9534e-01, time/batch = 17.7453s	
9738/22750 (epoch 21.402), train_loss = 1.04898914, grad/param norm = 2.0078e-01, time/batch = 17.4842s	
9739/22750 (epoch 21.404), train_loss = 1.13418716, grad/param norm = 2.0890e-01, time/batch = 16.3805s	
9740/22750 (epoch 21.407), train_loss = 1.09751375, grad/param norm = 1.9629e-01, time/batch = 16.7696s	
9741/22750 (epoch 21.409), train_loss = 0.94428424, grad/param norm = 1.9506e-01, time/batch = 16.1828s	
9742/22750 (epoch 21.411), train_loss = 0.97489705, grad/param norm = 2.0581e-01, time/batch = 17.4257s	
9743/22750 (epoch 21.413), train_loss = 0.75302941, grad/param norm = 1.7806e-01, time/batch = 18.4530s	
9744/22750 (epoch 21.415), train_loss = 0.74608370, grad/param norm = 1.7037e-01, time/batch = 19.8620s	
9745/22750 (epoch 21.418), train_loss = 0.92143999, grad/param norm = 1.9465e-01, time/batch = 19.9210s	
9746/22750 (epoch 21.420), train_loss = 1.05319476, grad/param norm = 2.9748e-01, time/batch = 17.7522s	
9747/22750 (epoch 21.422), train_loss = 1.22804105, grad/param norm = 2.5366e-01, time/batch = 17.5201s	
9748/22750 (epoch 21.424), train_loss = 1.20307787, grad/param norm = 2.1251e-01, time/batch = 17.9951s	
9749/22750 (epoch 21.426), train_loss = 1.21010348, grad/param norm = 2.1612e-01, time/batch = 15.9792s	
9750/22750 (epoch 21.429), train_loss = 0.89297248, grad/param norm = 1.8644e-01, time/batch = 15.7939s	
9751/22750 (epoch 21.431), train_loss = 0.81109109, grad/param norm = 1.8776e-01, time/batch = 17.5630s	
9752/22750 (epoch 21.433), train_loss = 0.92691528, grad/param norm = 2.0765e-01, time/batch = 19.0768s	
9753/22750 (epoch 21.435), train_loss = 0.76101483, grad/param norm = 1.7780e-01, time/batch = 20.2488s	
9754/22750 (epoch 21.437), train_loss = 0.66943224, grad/param norm = 1.9296e-01, time/batch = 18.7538s	
9755/22750 (epoch 21.440), train_loss = 0.99715765, grad/param norm = 2.2200e-01, time/batch = 18.8984s	
9756/22750 (epoch 21.442), train_loss = 0.99449221, grad/param norm = 2.1020e-01, time/batch = 19.3219s	
9757/22750 (epoch 21.444), train_loss = 0.97574322, grad/param norm = 2.1530e-01, time/batch = 18.5052s	
9758/22750 (epoch 21.446), train_loss = 0.98759300, grad/param norm = 2.0484e-01, time/batch = 19.2432s	
9759/22750 (epoch 21.448), train_loss = 1.25908174, grad/param norm = 2.1917e-01, time/batch = 18.2588s	
9760/22750 (epoch 21.451), train_loss = 1.18849751, grad/param norm = 2.0541e-01, time/batch = 20.0787s	
9761/22750 (epoch 21.453), train_loss = 1.15887625, grad/param norm = 2.3110e-01, time/batch = 20.6152s	
9762/22750 (epoch 21.455), train_loss = 1.25486179, grad/param norm = 2.2799e-01, time/batch = 20.0039s	
9763/22750 (epoch 21.457), train_loss = 1.13352194, grad/param norm = 3.6786e-01, time/batch = 19.4541s	
9764/22750 (epoch 21.459), train_loss = 1.10306474, grad/param norm = 1.9881e-01, time/batch = 18.3536s	
9765/22750 (epoch 21.462), train_loss = 1.07430949, grad/param norm = 1.9062e-01, time/batch = 17.0787s	
9766/22750 (epoch 21.464), train_loss = 0.84754161, grad/param norm = 2.0292e-01, time/batch = 17.7321s	
9767/22750 (epoch 21.466), train_loss = 1.16838296, grad/param norm = 2.2935e-01, time/batch = 19.3150s	
9768/22750 (epoch 21.468), train_loss = 1.01222219, grad/param norm = 2.0664e-01, time/batch = 17.7504s	
9769/22750 (epoch 21.470), train_loss = 1.15668216, grad/param norm = 2.3361e-01, time/batch = 17.8350s	
9770/22750 (epoch 21.473), train_loss = 0.99731724, grad/param norm = 2.0453e-01, time/batch = 18.4399s	
9771/22750 (epoch 21.475), train_loss = 1.02925452, grad/param norm = 2.0998e-01, time/batch = 20.0262s	
9772/22750 (epoch 21.477), train_loss = 0.86125410, grad/param norm = 1.7871e-01, time/batch = 18.5273s	
9773/22750 (epoch 21.479), train_loss = 0.84669523, grad/param norm = 1.9001e-01, time/batch = 19.2631s	
9774/22750 (epoch 21.481), train_loss = 0.79757638, grad/param norm = 1.6715e-01, time/batch = 18.5970s	
9775/22750 (epoch 21.484), train_loss = 0.71667798, grad/param norm = 2.0053e-01, time/batch = 18.4293s	
9776/22750 (epoch 21.486), train_loss = 0.83945097, grad/param norm = 1.9828e-01, time/batch = 19.2433s	
9777/22750 (epoch 21.488), train_loss = 0.73022971, grad/param norm = 1.6974e-01, time/batch = 19.0752s	
9778/22750 (epoch 21.490), train_loss = 0.98005534, grad/param norm = 1.8945e-01, time/batch = 16.7419s	
9779/22750 (epoch 21.492), train_loss = 1.13938972, grad/param norm = 2.2278e-01, time/batch = 15.4925s	
9780/22750 (epoch 21.495), train_loss = 0.88946558, grad/param norm = 1.9045e-01, time/batch = 15.5190s	
9781/22750 (epoch 21.497), train_loss = 0.97711623, grad/param norm = 2.1699e-01, time/batch = 15.8303s	
9782/22750 (epoch 21.499), train_loss = 0.90773129, grad/param norm = 2.0236e-01, time/batch = 16.4350s	
9783/22750 (epoch 21.501), train_loss = 0.96982218, grad/param norm = 1.8153e-01, time/batch = 16.0436s	
9784/22750 (epoch 21.503), train_loss = 0.98369853, grad/param norm = 1.9650e-01, time/batch = 15.2111s	
9785/22750 (epoch 21.505), train_loss = 0.85328858, grad/param norm = 1.9756e-01, time/batch = 15.7886s	
9786/22750 (epoch 21.508), train_loss = 0.80593870, grad/param norm = 1.9700e-01, time/batch = 15.2959s	
9787/22750 (epoch 21.510), train_loss = 0.82313891, grad/param norm = 1.7774e-01, time/batch = 15.5554s	
9788/22750 (epoch 21.512), train_loss = 0.85610884, grad/param norm = 1.7896e-01, time/batch = 15.8695s	
9789/22750 (epoch 21.514), train_loss = 0.91829171, grad/param norm = 1.9913e-01, time/batch = 16.0381s	
9790/22750 (epoch 21.516), train_loss = 0.90494774, grad/param norm = 1.9215e-01, time/batch = 15.4646s	
9791/22750 (epoch 21.519), train_loss = 1.04609157, grad/param norm = 1.9925e-01, time/batch = 15.7088s	
9792/22750 (epoch 21.521), train_loss = 0.97384528, grad/param norm = 2.0569e-01, time/batch = 15.3793s	
9793/22750 (epoch 21.523), train_loss = 0.92835709, grad/param norm = 2.2431e-01, time/batch = 15.7890s	
9794/22750 (epoch 21.525), train_loss = 1.11948631, grad/param norm = 2.1964e-01, time/batch = 15.5507s	
9795/22750 (epoch 21.527), train_loss = 0.98236746, grad/param norm = 2.0608e-01, time/batch = 15.3096s	
9796/22750 (epoch 21.530), train_loss = 0.90244028, grad/param norm = 2.1744e-01, time/batch = 15.3000s	
9797/22750 (epoch 21.532), train_loss = 0.83115297, grad/param norm = 1.6544e-01, time/batch = 15.7852s	
9798/22750 (epoch 21.534), train_loss = 1.08116765, grad/param norm = 2.1815e-01, time/batch = 15.5336s	
9799/22750 (epoch 21.536), train_loss = 1.01960465, grad/param norm = 1.8701e-01, time/batch = 15.1511s	
9800/22750 (epoch 21.538), train_loss = 0.98349419, grad/param norm = 1.7777e-01, time/batch = 15.4679s	
9801/22750 (epoch 21.541), train_loss = 0.85159494, grad/param norm = 1.9291e-01, time/batch = 15.3769s	
9802/22750 (epoch 21.543), train_loss = 0.86197609, grad/param norm = 1.9171e-01, time/batch = 15.3700s	
9803/22750 (epoch 21.545), train_loss = 1.07050167, grad/param norm = 2.0234e-01, time/batch = 15.7341s	
9804/22750 (epoch 21.547), train_loss = 0.89556947, grad/param norm = 1.7871e-01, time/batch = 15.7170s	
9805/22750 (epoch 21.549), train_loss = 0.91809666, grad/param norm = 1.8184e-01, time/batch = 15.6320s	
9806/22750 (epoch 21.552), train_loss = 1.01957251, grad/param norm = 2.0641e-01, time/batch = 15.4576s	
9807/22750 (epoch 21.554), train_loss = 1.04151194, grad/param norm = 2.0767e-01, time/batch = 15.7033s	
9808/22750 (epoch 21.556), train_loss = 0.98739930, grad/param norm = 1.8891e-01, time/batch = 15.8612s	
9809/22750 (epoch 21.558), train_loss = 1.07559741, grad/param norm = 2.2019e-01, time/batch = 15.3764s	
9810/22750 (epoch 21.560), train_loss = 0.91720741, grad/param norm = 1.9766e-01, time/batch = 15.5380s	
9811/22750 (epoch 21.563), train_loss = 1.08748112, grad/param norm = 2.0806e-01, time/batch = 15.3893s	
9812/22750 (epoch 21.565), train_loss = 1.03451416, grad/param norm = 2.0048e-01, time/batch = 15.8106s	
9813/22750 (epoch 21.567), train_loss = 1.01127979, grad/param norm = 1.8567e-01, time/batch = 16.3571s	
9814/22750 (epoch 21.569), train_loss = 0.95191096, grad/param norm = 1.8667e-01, time/batch = 15.7974s	
9815/22750 (epoch 21.571), train_loss = 0.97126845, grad/param norm = 2.0689e-01, time/batch = 15.3804s	
9816/22750 (epoch 21.574), train_loss = 0.91810118, grad/param norm = 1.9632e-01, time/batch = 16.0282s	
9817/22750 (epoch 21.576), train_loss = 0.91836752, grad/param norm = 1.8987e-01, time/batch = 15.3684s	
9818/22750 (epoch 21.578), train_loss = 0.84194020, grad/param norm = 1.9100e-01, time/batch = 15.3927s	
9819/22750 (epoch 21.580), train_loss = 1.00221260, grad/param norm = 2.1435e-01, time/batch = 15.2023s	
9820/22750 (epoch 21.582), train_loss = 0.87904765, grad/param norm = 1.9035e-01, time/batch = 15.5429s	
9821/22750 (epoch 21.585), train_loss = 0.83534699, grad/param norm = 1.8664e-01, time/batch = 15.6244s	
9822/22750 (epoch 21.587), train_loss = 0.82992426, grad/param norm = 1.7595e-01, time/batch = 15.6302s	
9823/22750 (epoch 21.589), train_loss = 0.78403397, grad/param norm = 1.8228e-01, time/batch = 16.0251s	
9824/22750 (epoch 21.591), train_loss = 0.95207298, grad/param norm = 2.0113e-01, time/batch = 15.3834s	
9825/22750 (epoch 21.593), train_loss = 1.12488967, grad/param norm = 1.9155e-01, time/batch = 15.4529s	
9826/22750 (epoch 21.596), train_loss = 1.12487810, grad/param norm = 2.0615e-01, time/batch = 15.7022s	
9827/22750 (epoch 21.598), train_loss = 1.17219714, grad/param norm = 2.1887e-01, time/batch = 15.7032s	
9828/22750 (epoch 21.600), train_loss = 1.13327728, grad/param norm = 2.1777e-01, time/batch = 15.2974s	
9829/22750 (epoch 21.602), train_loss = 0.90025481, grad/param norm = 1.8399e-01, time/batch = 15.5506s	
9830/22750 (epoch 21.604), train_loss = 0.91903875, grad/param norm = 1.8423e-01, time/batch = 16.0340s	
9831/22750 (epoch 21.607), train_loss = 0.81570491, grad/param norm = 1.5968e-01, time/batch = 15.8647s	
9832/22750 (epoch 21.609), train_loss = 0.76945473, grad/param norm = 1.7745e-01, time/batch = 15.5516s	
9833/22750 (epoch 21.611), train_loss = 0.93603870, grad/param norm = 1.9521e-01, time/batch = 15.4777s	
9834/22750 (epoch 21.613), train_loss = 0.88322316, grad/param norm = 1.7755e-01, time/batch = 15.5695s	
9835/22750 (epoch 21.615), train_loss = 0.90711414, grad/param norm = 1.8001e-01, time/batch = 16.2012s	
9836/22750 (epoch 21.618), train_loss = 0.94388344, grad/param norm = 1.8082e-01, time/batch = 15.7936s	
9837/22750 (epoch 21.620), train_loss = 0.93850604, grad/param norm = 1.8060e-01, time/batch = 15.7059s	
9838/22750 (epoch 21.622), train_loss = 0.79430723, grad/param norm = 1.7407e-01, time/batch = 15.4492s	
9839/22750 (epoch 21.624), train_loss = 0.86836172, grad/param norm = 1.7913e-01, time/batch = 15.9446s	
9840/22750 (epoch 21.626), train_loss = 0.80262215, grad/param norm = 1.8762e-01, time/batch = 15.4564s	
9841/22750 (epoch 21.629), train_loss = 0.89914661, grad/param norm = 2.0381e-01, time/batch = 15.6228s	
9842/22750 (epoch 21.631), train_loss = 0.96168790, grad/param norm = 1.7939e-01, time/batch = 15.5486s	
9843/22750 (epoch 21.633), train_loss = 0.83393651, grad/param norm = 1.8912e-01, time/batch = 15.5443s	
9844/22750 (epoch 21.635), train_loss = 0.97377390, grad/param norm = 1.8950e-01, time/batch = 15.4636s	
9845/22750 (epoch 21.637), train_loss = 1.03677062, grad/param norm = 2.2027e-01, time/batch = 16.2679s	
9846/22750 (epoch 21.640), train_loss = 1.02802038, grad/param norm = 1.9622e-01, time/batch = 15.9557s	
9847/22750 (epoch 21.642), train_loss = 1.08784076, grad/param norm = 2.0763e-01, time/batch = 16.2185s	
9848/22750 (epoch 21.644), train_loss = 0.95975179, grad/param norm = 2.0755e-01, time/batch = 15.3617s	
9849/22750 (epoch 21.646), train_loss = 1.00248027, grad/param norm = 2.1498e-01, time/batch = 15.2944s	
9850/22750 (epoch 21.648), train_loss = 1.00487127, grad/param norm = 2.0539e-01, time/batch = 15.8569s	
9851/22750 (epoch 21.651), train_loss = 1.02723980, grad/param norm = 2.0740e-01, time/batch = 15.6179s	
9852/22750 (epoch 21.653), train_loss = 1.07167471, grad/param norm = 1.9547e-01, time/batch = 15.6111s	
9853/22750 (epoch 21.655), train_loss = 0.99135765, grad/param norm = 1.8910e-01, time/batch = 15.4534s	
9854/22750 (epoch 21.657), train_loss = 1.15363768, grad/param norm = 2.2051e-01, time/batch = 15.9098s	
9855/22750 (epoch 21.659), train_loss = 1.19304207, grad/param norm = 2.1326e-01, time/batch = 15.7838s	
9856/22750 (epoch 21.662), train_loss = 1.17347348, grad/param norm = 2.2987e-01, time/batch = 15.8885s	
9857/22750 (epoch 21.664), train_loss = 1.02021051, grad/param norm = 2.0372e-01, time/batch = 15.7254s	
9858/22750 (epoch 21.666), train_loss = 0.82675532, grad/param norm = 1.7587e-01, time/batch = 16.0280s	
9859/22750 (epoch 21.668), train_loss = 0.98870814, grad/param norm = 1.9687e-01, time/batch = 15.4662s	
9860/22750 (epoch 21.670), train_loss = 0.99659591, grad/param norm = 2.1340e-01, time/batch = 15.5331s	
9861/22750 (epoch 21.673), train_loss = 1.23481557, grad/param norm = 2.2438e-01, time/batch = 15.5361s	
9862/22750 (epoch 21.675), train_loss = 1.37880388, grad/param norm = 2.5272e-01, time/batch = 15.6195s	
9863/22750 (epoch 21.677), train_loss = 1.15035887, grad/param norm = 2.1578e-01, time/batch = 15.3683s	
9864/22750 (epoch 21.679), train_loss = 1.21965708, grad/param norm = 2.4646e-01, time/batch = 15.6862s	
9865/22750 (epoch 21.681), train_loss = 1.15238703, grad/param norm = 1.9572e-01, time/batch = 15.6886s	
9866/22750 (epoch 21.684), train_loss = 1.17241911, grad/param norm = 2.3684e-01, time/batch = 15.6885s	
9867/22750 (epoch 21.686), train_loss = 1.19304889, grad/param norm = 2.3877e-01, time/batch = 15.3889s	
9868/22750 (epoch 21.688), train_loss = 1.13118399, grad/param norm = 2.1563e-01, time/batch = 15.3115s	
9869/22750 (epoch 21.690), train_loss = 1.13417632, grad/param norm = 2.2451e-01, time/batch = 15.6308s	
9870/22750 (epoch 21.692), train_loss = 1.16717295, grad/param norm = 2.2239e-01, time/batch = 20.1854s	
9871/22750 (epoch 21.695), train_loss = 1.04404495, grad/param norm = 2.1518e-01, time/batch = 18.5833s	
9872/22750 (epoch 21.697), train_loss = 1.00472496, grad/param norm = 2.0450e-01, time/batch = 18.2385s	
9873/22750 (epoch 21.699), train_loss = 0.98730763, grad/param norm = 1.9626e-01, time/batch = 19.2264s	
9874/22750 (epoch 21.701), train_loss = 0.85975044, grad/param norm = 1.8713e-01, time/batch = 17.8437s	
9875/22750 (epoch 21.703), train_loss = 0.98962092, grad/param norm = 1.9363e-01, time/batch = 16.5090s	
9876/22750 (epoch 21.705), train_loss = 0.93042508, grad/param norm = 1.9796e-01, time/batch = 18.1616s	
9877/22750 (epoch 21.708), train_loss = 1.00971432, grad/param norm = 1.8685e-01, time/batch = 21.1014s	
9878/22750 (epoch 21.710), train_loss = 0.88209759, grad/param norm = 1.9840e-01, time/batch = 19.9355s	
9879/22750 (epoch 21.712), train_loss = 0.86353236, grad/param norm = 1.9189e-01, time/batch = 18.4469s	
9880/22750 (epoch 21.714), train_loss = 0.82417867, grad/param norm = 1.8380e-01, time/batch = 19.0896s	
9881/22750 (epoch 21.716), train_loss = 0.85748797, grad/param norm = 1.8862e-01, time/batch = 18.0955s	
9882/22750 (epoch 21.719), train_loss = 1.02857423, grad/param norm = 2.4877e-01, time/batch = 17.8432s	
9883/22750 (epoch 21.721), train_loss = 1.09116233, grad/param norm = 2.0458e-01, time/batch = 18.0068s	
9884/22750 (epoch 21.723), train_loss = 1.06326640, grad/param norm = 2.0805e-01, time/batch = 17.9066s	
9885/22750 (epoch 21.725), train_loss = 0.97256358, grad/param norm = 2.0484e-01, time/batch = 17.5008s	
9886/22750 (epoch 21.727), train_loss = 0.94243190, grad/param norm = 1.9528e-01, time/batch = 18.9416s	
9887/22750 (epoch 21.730), train_loss = 0.94417543, grad/param norm = 2.1089e-01, time/batch = 19.4478s	
9888/22750 (epoch 21.732), train_loss = 0.88729806, grad/param norm = 1.8641e-01, time/batch = 16.6955s	
9889/22750 (epoch 21.734), train_loss = 0.77837432, grad/param norm = 1.7305e-01, time/batch = 32.9801s	
9890/22750 (epoch 21.736), train_loss = 0.92348159, grad/param norm = 2.0432e-01, time/batch = 18.7505s	
9891/22750 (epoch 21.738), train_loss = 1.05193550, grad/param norm = 2.1660e-01, time/batch = 17.6719s	
9892/22750 (epoch 21.741), train_loss = 1.08113660, grad/param norm = 2.0433e-01, time/batch = 18.5074s	
9893/22750 (epoch 21.743), train_loss = 1.02654142, grad/param norm = 1.9593e-01, time/batch = 19.3317s	
9894/22750 (epoch 21.745), train_loss = 0.84147799, grad/param norm = 1.7258e-01, time/batch = 19.3320s	
9895/22750 (epoch 21.747), train_loss = 0.92949976, grad/param norm = 1.8818e-01, time/batch = 19.7578s	
9896/22750 (epoch 21.749), train_loss = 1.13670871, grad/param norm = 2.3208e-01, time/batch = 17.3463s	
9897/22750 (epoch 21.752), train_loss = 0.96617581, grad/param norm = 1.9640e-01, time/batch = 18.6888s	
9898/22750 (epoch 21.754), train_loss = 0.99910158, grad/param norm = 1.9532e-01, time/batch = 16.2146s	
9899/22750 (epoch 21.756), train_loss = 0.89481851, grad/param norm = 2.1055e-01, time/batch = 16.3496s	
9900/22750 (epoch 21.758), train_loss = 0.87468015, grad/param norm = 1.9092e-01, time/batch = 15.9511s	
9901/22750 (epoch 21.760), train_loss = 0.93065048, grad/param norm = 1.8708e-01, time/batch = 17.4179s	
9902/22750 (epoch 21.763), train_loss = 1.01350460, grad/param norm = 2.1081e-01, time/batch = 19.1879s	
9903/22750 (epoch 21.765), train_loss = 0.99109062, grad/param norm = 2.2210e-01, time/batch = 17.9855s	
9904/22750 (epoch 21.767), train_loss = 1.02103914, grad/param norm = 2.2353e-01, time/batch = 17.7633s	
9905/22750 (epoch 21.769), train_loss = 1.21608628, grad/param norm = 2.3183e-01, time/batch = 20.0235s	
9906/22750 (epoch 21.771), train_loss = 1.13962211, grad/param norm = 2.4808e-01, time/batch = 19.2082s	
9907/22750 (epoch 21.774), train_loss = 0.97387664, grad/param norm = 2.2235e-01, time/batch = 19.6900s	
9908/22750 (epoch 21.776), train_loss = 1.06311039, grad/param norm = 2.2488e-01, time/batch = 17.7592s	
9909/22750 (epoch 21.778), train_loss = 1.17226455, grad/param norm = 2.3607e-01, time/batch = 19.2419s	
9910/22750 (epoch 21.780), train_loss = 1.00854047, grad/param norm = 2.0424e-01, time/batch = 19.5859s	
9911/22750 (epoch 21.782), train_loss = 1.15851799, grad/param norm = 2.2136e-01, time/batch = 19.7370s	
9912/22750 (epoch 21.785), train_loss = 0.98238357, grad/param norm = 1.9949e-01, time/batch = 19.2431s	
9913/22750 (epoch 21.787), train_loss = 0.87682105, grad/param norm = 2.0596e-01, time/batch = 19.9147s	
9914/22750 (epoch 21.789), train_loss = 0.96676320, grad/param norm = 1.9882e-01, time/batch = 19.0148s	
9915/22750 (epoch 21.791), train_loss = 0.93043037, grad/param norm = 1.8507e-01, time/batch = 20.9367s	
9916/22750 (epoch 21.793), train_loss = 0.91172736, grad/param norm = 2.2837e-01, time/batch = 19.5170s	
9917/22750 (epoch 21.796), train_loss = 0.81484213, grad/param norm = 1.8291e-01, time/batch = 19.2457s	
9918/22750 (epoch 21.798), train_loss = 0.86928882, grad/param norm = 1.8095e-01, time/batch = 20.1665s	
9919/22750 (epoch 21.800), train_loss = 0.90248606, grad/param norm = 1.9871e-01, time/batch = 19.4901s	
9920/22750 (epoch 21.802), train_loss = 0.83851192, grad/param norm = 1.9480e-01, time/batch = 17.3107s	
9921/22750 (epoch 21.804), train_loss = 1.12091114, grad/param norm = 2.1182e-01, time/batch = 19.5001s	
9922/22750 (epoch 21.807), train_loss = 1.07070913, grad/param norm = 1.9968e-01, time/batch = 19.5313s	
9923/22750 (epoch 21.809), train_loss = 1.13421775, grad/param norm = 2.0796e-01, time/batch = 18.1027s	
9924/22750 (epoch 21.811), train_loss = 0.94533679, grad/param norm = 1.9592e-01, time/batch = 18.1078s	
9925/22750 (epoch 21.813), train_loss = 1.02917442, grad/param norm = 1.9721e-01, time/batch = 18.6316s	
9926/22750 (epoch 21.815), train_loss = 1.15652047, grad/param norm = 2.0040e-01, time/batch = 17.8457s	
9927/22750 (epoch 21.818), train_loss = 1.10816665, grad/param norm = 1.9341e-01, time/batch = 19.5899s	
9928/22750 (epoch 21.820), train_loss = 1.24726250, grad/param norm = 1.9577e-01, time/batch = 17.3524s	
9929/22750 (epoch 21.822), train_loss = 1.04707456, grad/param norm = 2.0657e-01, time/batch = 18.2550s	
9930/22750 (epoch 21.824), train_loss = 0.89420269, grad/param norm = 1.8016e-01, time/batch = 19.4151s	
9931/22750 (epoch 21.826), train_loss = 0.96680573, grad/param norm = 1.9596e-01, time/batch = 18.9191s	
9932/22750 (epoch 21.829), train_loss = 1.16443555, grad/param norm = 2.1931e-01, time/batch = 19.1817s	
9933/22750 (epoch 21.831), train_loss = 1.09142241, grad/param norm = 2.0281e-01, time/batch = 19.9974s	
9934/22750 (epoch 21.833), train_loss = 1.03193135, grad/param norm = 2.0663e-01, time/batch = 19.5963s	
9935/22750 (epoch 21.835), train_loss = 0.91834089, grad/param norm = 1.8674e-01, time/batch = 19.4795s	
9936/22750 (epoch 21.837), train_loss = 0.95851994, grad/param norm = 1.8027e-01, time/batch = 15.7742s	
9937/22750 (epoch 21.840), train_loss = 0.85620808, grad/param norm = 1.5981e-01, time/batch = 15.4377s	
9938/22750 (epoch 21.842), train_loss = 0.91151372, grad/param norm = 1.8186e-01, time/batch = 15.6903s	
9939/22750 (epoch 21.844), train_loss = 1.06434059, grad/param norm = 2.1153e-01, time/batch = 15.7696s	
9940/22750 (epoch 21.846), train_loss = 1.01376929, grad/param norm = 1.9578e-01, time/batch = 15.9356s	
9941/22750 (epoch 21.848), train_loss = 0.90894211, grad/param norm = 1.6926e-01, time/batch = 15.5275s	
9942/22750 (epoch 21.851), train_loss = 0.88265201, grad/param norm = 1.9512e-01, time/batch = 15.5244s	
9943/22750 (epoch 21.853), train_loss = 1.03807446, grad/param norm = 1.9415e-01, time/batch = 16.4194s	
9944/22750 (epoch 21.855), train_loss = 0.87991462, grad/param norm = 1.8191e-01, time/batch = 15.6917s	
9945/22750 (epoch 21.857), train_loss = 1.01225107, grad/param norm = 1.8326e-01, time/batch = 15.6116s	
9946/22750 (epoch 21.859), train_loss = 1.06625897, grad/param norm = 2.1932e-01, time/batch = 16.0163s	
9947/22750 (epoch 21.862), train_loss = 1.16591393, grad/param norm = 2.1705e-01, time/batch = 16.0120s	
9948/22750 (epoch 21.864), train_loss = 0.98821418, grad/param norm = 2.0253e-01, time/batch = 15.6061s	
9949/22750 (epoch 21.866), train_loss = 1.03135002, grad/param norm = 1.7884e-01, time/batch = 15.9235s	
9950/22750 (epoch 21.868), train_loss = 0.91473987, grad/param norm = 1.8053e-01, time/batch = 15.6130s	
9951/22750 (epoch 21.870), train_loss = 0.81199381, grad/param norm = 1.9375e-01, time/batch = 16.3513s	
9952/22750 (epoch 21.873), train_loss = 0.95644938, grad/param norm = 1.8996e-01, time/batch = 15.8563s	
9953/22750 (epoch 21.875), train_loss = 1.05914249, grad/param norm = 1.9259e-01, time/batch = 15.8597s	
9954/22750 (epoch 21.877), train_loss = 0.87714598, grad/param norm = 1.7782e-01, time/batch = 16.1833s	
9955/22750 (epoch 21.879), train_loss = 1.13766483, grad/param norm = 2.0422e-01, time/batch = 16.0103s	
9956/22750 (epoch 21.881), train_loss = 1.06074255, grad/param norm = 1.9425e-01, time/batch = 15.6143s	
9957/22750 (epoch 21.884), train_loss = 0.91490925, grad/param norm = 1.9927e-01, time/batch = 15.7679s	
9958/22750 (epoch 21.886), train_loss = 1.05853906, grad/param norm = 2.0598e-01, time/batch = 16.0124s	
9959/22750 (epoch 21.888), train_loss = 1.06161631, grad/param norm = 1.8692e-01, time/batch = 15.6130s	
9960/22750 (epoch 21.890), train_loss = 1.07485486, grad/param norm = 2.0014e-01, time/batch = 15.6885s	
9961/22750 (epoch 21.892), train_loss = 1.31241441, grad/param norm = 2.2867e-01, time/batch = 15.6872s	
9962/22750 (epoch 21.895), train_loss = 1.01918974, grad/param norm = 1.9759e-01, time/batch = 16.1784s	
9963/22750 (epoch 21.897), train_loss = 1.07978171, grad/param norm = 2.0345e-01, time/batch = 15.6947s	
9964/22750 (epoch 21.899), train_loss = 1.05188814, grad/param norm = 2.0316e-01, time/batch = 15.8459s	
9965/22750 (epoch 21.901), train_loss = 1.14061174, grad/param norm = 2.2961e-01, time/batch = 15.9316s	
9966/22750 (epoch 21.903), train_loss = 0.99013246, grad/param norm = 2.0542e-01, time/batch = 16.0234s	
9967/22750 (epoch 21.905), train_loss = 1.08057696, grad/param norm = 2.0489e-01, time/batch = 15.6927s	
9968/22750 (epoch 21.908), train_loss = 0.91969353, grad/param norm = 2.0895e-01, time/batch = 15.6949s	
9969/22750 (epoch 21.910), train_loss = 0.79216075, grad/param norm = 1.9074e-01, time/batch = 15.8563s	
9970/22750 (epoch 21.912), train_loss = 0.94289746, grad/param norm = 1.8834e-01, time/batch = 15.5237s	
9971/22750 (epoch 21.914), train_loss = 0.97716118, grad/param norm = 2.0134e-01, time/batch = 15.6140s	
9972/22750 (epoch 21.916), train_loss = 0.82965363, grad/param norm = 1.9203e-01, time/batch = 15.6954s	
9973/22750 (epoch 21.919), train_loss = 0.96029677, grad/param norm = 2.0806e-01, time/batch = 14.8634s	
9974/22750 (epoch 21.921), train_loss = 0.75923755, grad/param norm = 1.7554e-01, time/batch = 0.7238s	
9975/22750 (epoch 21.923), train_loss = 0.88671283, grad/param norm = 1.8950e-01, time/batch = 0.7181s	
9976/22750 (epoch 21.925), train_loss = 0.95119059, grad/param norm = 1.7756e-01, time/batch = 0.7201s	
9977/22750 (epoch 21.927), train_loss = 0.76520253, grad/param norm = 1.8508e-01, time/batch = 0.7233s	
9978/22750 (epoch 21.930), train_loss = 0.77840741, grad/param norm = 1.7246e-01, time/batch = 0.7231s	
9979/22750 (epoch 21.932), train_loss = 0.98327527, grad/param norm = 2.0221e-01, time/batch = 0.7216s	
9980/22750 (epoch 21.934), train_loss = 0.76637194, grad/param norm = 1.5800e-01, time/batch = 0.7702s	
9981/22750 (epoch 21.936), train_loss = 1.09798679, grad/param norm = 2.1127e-01, time/batch = 1.0544s	
9982/22750 (epoch 21.938), train_loss = 1.06671127, grad/param norm = 1.7898e-01, time/batch = 1.0452s	
9983/22750 (epoch 21.941), train_loss = 1.16271826, grad/param norm = 2.1107e-01, time/batch = 1.0537s	
9984/22750 (epoch 21.943), train_loss = 0.99919739, grad/param norm = 1.9737e-01, time/batch = 1.0524s	
9985/22750 (epoch 21.945), train_loss = 1.01734610, grad/param norm = 2.1903e-01, time/batch = 1.4709s	
9986/22750 (epoch 21.947), train_loss = 0.94169668, grad/param norm = 2.1130e-01, time/batch = 1.9441s	
9987/22750 (epoch 21.949), train_loss = 0.88567963, grad/param norm = 1.9818e-01, time/batch = 1.9454s	
9988/22750 (epoch 21.952), train_loss = 0.90509371, grad/param norm = 1.7201e-01, time/batch = 14.0562s	
9989/22750 (epoch 21.954), train_loss = 0.87371870, grad/param norm = 1.7850e-01, time/batch = 15.9477s	
9990/22750 (epoch 21.956), train_loss = 0.99413877, grad/param norm = 1.9139e-01, time/batch = 15.6896s	
9991/22750 (epoch 21.958), train_loss = 0.92569110, grad/param norm = 1.7195e-01, time/batch = 15.6936s	
9992/22750 (epoch 21.960), train_loss = 0.87543011, grad/param norm = 1.7940e-01, time/batch = 15.8557s	
9993/22750 (epoch 21.963), train_loss = 1.06064635, grad/param norm = 2.0717e-01, time/batch = 15.6880s	
9994/22750 (epoch 21.965), train_loss = 1.05712102, grad/param norm = 1.8381e-01, time/batch = 16.0979s	
9995/22750 (epoch 21.967), train_loss = 0.98658659, grad/param norm = 2.0230e-01, time/batch = 15.6919s	
9996/22750 (epoch 21.969), train_loss = 0.90949737, grad/param norm = 2.0786e-01, time/batch = 15.6063s	
9997/22750 (epoch 21.971), train_loss = 0.93555886, grad/param norm = 2.0348e-01, time/batch = 15.4523s	
9998/22750 (epoch 21.974), train_loss = 0.96908067, grad/param norm = 2.1151e-01, time/batch = 15.9356s	
9999/22750 (epoch 21.976), train_loss = 1.02401790, grad/param norm = 2.0469e-01, time/batch = 15.3688s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_wakata_epoch21.98_1.5368.t7	
10000/22750 (epoch 21.978), train_loss = 0.91375105, grad/param norm = 2.0042e-01, time/batch = 15.3593s	
10001/22750 (epoch 21.980), train_loss = 1.62037207, grad/param norm = 2.8965e-01, time/batch = 16.1002s	
10002/22750 (epoch 21.982), train_loss = 0.89457277, grad/param norm = 1.8822e-01, time/batch = 15.6938s	
10003/22750 (epoch 21.985), train_loss = 1.14841285, grad/param norm = 2.1684e-01, time/batch = 16.2619s	
10004/22750 (epoch 21.987), train_loss = 0.77413754, grad/param norm = 1.7712e-01, time/batch = 15.6864s	
10005/22750 (epoch 21.989), train_loss = 0.94077582, grad/param norm = 2.1018e-01, time/batch = 15.4450s	
10006/22750 (epoch 21.991), train_loss = 1.03787382, grad/param norm = 2.0432e-01, time/batch = 15.6901s	
10007/22750 (epoch 21.993), train_loss = 1.05279277, grad/param norm = 2.2952e-01, time/batch = 16.1002s	
10008/22750 (epoch 21.996), train_loss = 0.90902472, grad/param norm = 2.1601e-01, time/batch = 15.8560s	
10009/22750 (epoch 21.998), train_loss = 1.10254444, grad/param norm = 2.1313e-01, time/batch = 16.0150s	
decayed learning rate by a factor 0.97 to 0.0013460541803311	
10010/22750 (epoch 22.000), train_loss = 1.02356227, grad/param norm = 2.0243e-01, time/batch = 16.2597s	
10011/22750 (epoch 22.002), train_loss = 1.13613352, grad/param norm = 2.3862e-01, time/batch = 15.8497s	
10012/22750 (epoch 22.004), train_loss = 0.92018964, grad/param norm = 1.8103e-01, time/batch = 15.6072s	
10013/22750 (epoch 22.007), train_loss = 0.94535093, grad/param norm = 1.9781e-01, time/batch = 15.8578s	
10014/22750 (epoch 22.009), train_loss = 1.15470091, grad/param norm = 2.1229e-01, time/batch = 16.0990s	
10015/22750 (epoch 22.011), train_loss = 1.24480548, grad/param norm = 2.2987e-01, time/batch = 15.6084s	
10016/22750 (epoch 22.013), train_loss = 1.09482506, grad/param norm = 2.0086e-01, time/batch = 15.8530s	
10017/22750 (epoch 22.015), train_loss = 1.00341144, grad/param norm = 2.0357e-01, time/batch = 15.6980s	
10018/22750 (epoch 22.018), train_loss = 1.07024235, grad/param norm = 2.0847e-01, time/batch = 16.3407s	
10019/22750 (epoch 22.020), train_loss = 1.12424987, grad/param norm = 1.9707e-01, time/batch = 15.6119s	
10020/22750 (epoch 22.022), train_loss = 1.00267995, grad/param norm = 2.0653e-01, time/batch = 15.9348s	
10021/22750 (epoch 22.024), train_loss = 0.99822204, grad/param norm = 1.9745e-01, time/batch = 15.4117s	
10022/22750 (epoch 22.026), train_loss = 1.05459205, grad/param norm = 2.0744e-01, time/batch = 15.5275s	
10023/22750 (epoch 22.029), train_loss = 0.81060276, grad/param norm = 1.9516e-01, time/batch = 15.1232s	
10024/22750 (epoch 22.031), train_loss = 1.24904766, grad/param norm = 2.0881e-01, time/batch = 15.3035s	
10025/22750 (epoch 22.033), train_loss = 1.01756759, grad/param norm = 2.2668e-01, time/batch = 15.2051s	
10026/22750 (epoch 22.035), train_loss = 1.03521839, grad/param norm = 1.7744e-01, time/batch = 15.7684s	
10027/22750 (epoch 22.037), train_loss = 1.10913420, grad/param norm = 1.8408e-01, time/batch = 15.2132s	
10028/22750 (epoch 22.040), train_loss = 0.95642026, grad/param norm = 1.9301e-01, time/batch = 15.3884s	
10029/22750 (epoch 22.042), train_loss = 1.04609482, grad/param norm = 1.9719e-01, time/batch = 15.7645s	
10030/22750 (epoch 22.044), train_loss = 0.94939671, grad/param norm = 1.9969e-01, time/batch = 16.7280s	
10031/22750 (epoch 22.046), train_loss = 1.10791096, grad/param norm = 2.1260e-01, time/batch = 16.5898s	
10032/22750 (epoch 22.048), train_loss = 0.99185391, grad/param norm = 1.8966e-01, time/batch = 16.0993s	
10033/22750 (epoch 22.051), train_loss = 1.04295810, grad/param norm = 1.9850e-01, time/batch = 16.5718s	
10034/22750 (epoch 22.053), train_loss = 0.90429356, grad/param norm = 1.6290e-01, time/batch = 15.7875s	
10035/22750 (epoch 22.055), train_loss = 0.90055394, grad/param norm = 1.8180e-01, time/batch = 16.6164s	
10036/22750 (epoch 22.057), train_loss = 1.16738196, grad/param norm = 1.9401e-01, time/batch = 16.2801s	
10037/22750 (epoch 22.059), train_loss = 0.75064838, grad/param norm = 1.6959e-01, time/batch = 16.8896s	
10038/22750 (epoch 22.062), train_loss = 0.87027330, grad/param norm = 2.0061e-01, time/batch = 16.5158s	
10039/22750 (epoch 22.064), train_loss = 1.06853571, grad/param norm = 2.1520e-01, time/batch = 15.5655s	
10040/22750 (epoch 22.066), train_loss = 0.84767153, grad/param norm = 1.6865e-01, time/batch = 15.3143s	
10041/22750 (epoch 22.068), train_loss = 0.91354111, grad/param norm = 1.7169e-01, time/batch = 15.7998s	
10042/22750 (epoch 22.070), train_loss = 0.76659067, grad/param norm = 1.7723e-01, time/batch = 15.8509s	
10043/22750 (epoch 22.073), train_loss = 0.93325040, grad/param norm = 1.9995e-01, time/batch = 15.2116s	
10044/22750 (epoch 22.075), train_loss = 0.96622046, grad/param norm = 1.9238e-01, time/batch = 15.7761s	
10045/22750 (epoch 22.077), train_loss = 0.75267589, grad/param norm = 1.9900e-01, time/batch = 15.1303s	
10046/22750 (epoch 22.079), train_loss = 0.94260466, grad/param norm = 2.1227e-01, time/batch = 15.2936s	
10047/22750 (epoch 22.081), train_loss = 0.95981860, grad/param norm = 2.0237e-01, time/batch = 15.6968s	
10048/22750 (epoch 22.084), train_loss = 0.93767733, grad/param norm = 2.0190e-01, time/batch = 15.7873s	
10049/22750 (epoch 22.086), train_loss = 0.94485762, grad/param norm = 1.7356e-01, time/batch = 15.3230s	
10050/22750 (epoch 22.088), train_loss = 0.89894928, grad/param norm = 1.8889e-01, time/batch = 15.4786s	
10051/22750 (epoch 22.090), train_loss = 0.89532147, grad/param norm = 1.8977e-01, time/batch = 15.4821s	
10052/22750 (epoch 22.092), train_loss = 1.09515597, grad/param norm = 1.8676e-01, time/batch = 15.8732s	
10053/22750 (epoch 22.095), train_loss = 0.86784737, grad/param norm = 1.8563e-01, time/batch = 15.2933s	
10054/22750 (epoch 22.097), train_loss = 0.98241931, grad/param norm = 1.9121e-01, time/batch = 15.5268s	
10055/22750 (epoch 22.099), train_loss = 0.92649698, grad/param norm = 2.0714e-01, time/batch = 15.2936s	
10056/22750 (epoch 22.101), train_loss = 0.84193300, grad/param norm = 1.8214e-01, time/batch = 16.4702s	
10057/22750 (epoch 22.103), train_loss = 0.98493854, grad/param norm = 1.8969e-01, time/batch = 15.7850s	
10058/22750 (epoch 22.105), train_loss = 1.16077705, grad/param norm = 2.2604e-01, time/batch = 16.1254s	
10059/22750 (epoch 22.108), train_loss = 0.94366386, grad/param norm = 1.8985e-01, time/batch = 16.0379s	
10060/22750 (epoch 22.110), train_loss = 1.10252913, grad/param norm = 2.1203e-01, time/batch = 15.8860s	
10061/22750 (epoch 22.112), train_loss = 0.82795111, grad/param norm = 1.8444e-01, time/batch = 15.8191s	
10062/22750 (epoch 22.114), train_loss = 0.76358076, grad/param norm = 1.8022e-01, time/batch = 15.6565s	
10063/22750 (epoch 22.116), train_loss = 0.90160235, grad/param norm = 1.8387e-01, time/batch = 15.7297s	
10064/22750 (epoch 22.119), train_loss = 0.88499439, grad/param norm = 1.8196e-01, time/batch = 15.8907s	
10065/22750 (epoch 22.121), train_loss = 1.00086219, grad/param norm = 2.4265e-01, time/batch = 15.7287s	
10066/22750 (epoch 22.123), train_loss = 0.85020241, grad/param norm = 1.8781e-01, time/batch = 15.9037s	
10067/22750 (epoch 22.125), train_loss = 1.12196171, grad/param norm = 1.8845e-01, time/batch = 16.3046s	
10068/22750 (epoch 22.127), train_loss = 0.93164415, grad/param norm = 2.0560e-01, time/batch = 15.4222s	
10069/22750 (epoch 22.130), train_loss = 0.95820685, grad/param norm = 1.7455e-01, time/batch = 16.0580s	
10070/22750 (epoch 22.132), train_loss = 0.89225672, grad/param norm = 1.8979e-01, time/batch = 15.6503s	
10071/22750 (epoch 22.134), train_loss = 0.93510323, grad/param norm = 1.9144e-01, time/batch = 15.9801s	
10072/22750 (epoch 22.136), train_loss = 0.81865470, grad/param norm = 2.0041e-01, time/batch = 15.5419s	
10073/22750 (epoch 22.138), train_loss = 1.02792455, grad/param norm = 1.9897e-01, time/batch = 15.7792s	
10074/22750 (epoch 22.141), train_loss = 0.98571186, grad/param norm = 1.9999e-01, time/batch = 15.2959s	
10075/22750 (epoch 22.143), train_loss = 0.85662870, grad/param norm = 1.7530e-01, time/batch = 15.7688s	
10076/22750 (epoch 22.145), train_loss = 1.07898051, grad/param norm = 2.0336e-01, time/batch = 15.2983s	
10077/22750 (epoch 22.147), train_loss = 1.14408829, grad/param norm = 2.0936e-01, time/batch = 15.3032s	
10078/22750 (epoch 22.149), train_loss = 0.97142485, grad/param norm = 1.8796e-01, time/batch = 15.2792s	
10079/22750 (epoch 22.152), train_loss = 0.96362484, grad/param norm = 1.9505e-01, time/batch = 15.2140s	
10080/22750 (epoch 22.154), train_loss = 0.82787774, grad/param norm = 2.0854e-01, time/batch = 15.3812s	
10081/22750 (epoch 22.156), train_loss = 0.84697916, grad/param norm = 1.8199e-01, time/batch = 15.3925s	
10082/22750 (epoch 22.158), train_loss = 0.86372121, grad/param norm = 1.8944e-01, time/batch = 15.3937s	
10083/22750 (epoch 22.160), train_loss = 1.00344998, grad/param norm = 2.0651e-01, time/batch = 15.1456s	
10084/22750 (epoch 22.163), train_loss = 1.17643692, grad/param norm = 2.1628e-01, time/batch = 14.9595s	
10085/22750 (epoch 22.165), train_loss = 1.03170208, grad/param norm = 2.0342e-01, time/batch = 15.5169s	
10086/22750 (epoch 22.167), train_loss = 0.94962625, grad/param norm = 2.1107e-01, time/batch = 15.2162s	
10087/22750 (epoch 22.169), train_loss = 0.96473609, grad/param norm = 1.9920e-01, time/batch = 15.5175s	
10088/22750 (epoch 22.171), train_loss = 0.84654908, grad/param norm = 2.0030e-01, time/batch = 15.3764s	
10089/22750 (epoch 22.174), train_loss = 0.79379151, grad/param norm = 1.7746e-01, time/batch = 15.6137s	
10090/22750 (epoch 22.176), train_loss = 0.87439794, grad/param norm = 1.8070e-01, time/batch = 15.9295s	
10091/22750 (epoch 22.178), train_loss = 0.87395335, grad/param norm = 1.8128e-01, time/batch = 15.9404s	
10092/22750 (epoch 22.180), train_loss = 1.06215327, grad/param norm = 2.3206e-01, time/batch = 19.6123s	
10093/22750 (epoch 22.182), train_loss = 1.07825818, grad/param norm = 2.1068e-01, time/batch = 18.2763s	
10094/22750 (epoch 22.185), train_loss = 1.11029297, grad/param norm = 2.2261e-01, time/batch = 19.0073s	
10095/22750 (epoch 22.187), train_loss = 0.86546116, grad/param norm = 1.9653e-01, time/batch = 18.9996s	
10096/22750 (epoch 22.189), train_loss = 0.88102904, grad/param norm = 2.0260e-01, time/batch = 17.6813s	
10097/22750 (epoch 22.191), train_loss = 0.88122164, grad/param norm = 1.7764e-01, time/batch = 17.6572s	
10098/22750 (epoch 22.193), train_loss = 1.03153856, grad/param norm = 1.9665e-01, time/batch = 18.4178s	
10099/22750 (epoch 22.196), train_loss = 0.94395743, grad/param norm = 2.1119e-01, time/batch = 20.0696s	
10100/22750 (epoch 22.198), train_loss = 0.72748355, grad/param norm = 1.6880e-01, time/batch = 17.3242s	
10101/22750 (epoch 22.200), train_loss = 0.97030318, grad/param norm = 1.8789e-01, time/batch = 20.0965s	
10102/22750 (epoch 22.202), train_loss = 1.05052806, grad/param norm = 2.3286e-01, time/batch = 19.1830s	
10103/22750 (epoch 22.204), train_loss = 0.95752106, grad/param norm = 1.8125e-01, time/batch = 18.1048s	
10104/22750 (epoch 22.207), train_loss = 0.94127361, grad/param norm = 1.8978e-01, time/batch = 20.2352s	
10105/22750 (epoch 22.209), train_loss = 0.89498969, grad/param norm = 2.0230e-01, time/batch = 17.7365s	
10106/22750 (epoch 22.211), train_loss = 0.88950864, grad/param norm = 2.1753e-01, time/batch = 18.3317s	
10107/22750 (epoch 22.213), train_loss = 0.77569315, grad/param norm = 1.8474e-01, time/batch = 20.1616s	
10108/22750 (epoch 22.215), train_loss = 0.74305222, grad/param norm = 1.7155e-01, time/batch = 19.0852s	
10109/22750 (epoch 22.218), train_loss = 0.84428763, grad/param norm = 2.1479e-01, time/batch = 20.4026s	
10110/22750 (epoch 22.220), train_loss = 0.79762617, grad/param norm = 1.7338e-01, time/batch = 31.9227s	
10111/22750 (epoch 22.222), train_loss = 0.81228335, grad/param norm = 1.8470e-01, time/batch = 17.8543s	
10112/22750 (epoch 22.224), train_loss = 0.85919065, grad/param norm = 1.8213e-01, time/batch = 17.5102s	
10113/22750 (epoch 22.226), train_loss = 0.99262862, grad/param norm = 2.1046e-01, time/batch = 16.3799s	
10114/22750 (epoch 22.229), train_loss = 0.98141869, grad/param norm = 2.1769e-01, time/batch = 16.0713s	
10115/22750 (epoch 22.231), train_loss = 0.87414571, grad/param norm = 2.0289e-01, time/batch = 16.1019s	
10116/22750 (epoch 22.233), train_loss = 0.81646809, grad/param norm = 2.0135e-01, time/batch = 18.6469s	
10117/22750 (epoch 22.235), train_loss = 0.78711082, grad/param norm = 1.9093e-01, time/batch = 16.7556s	
10118/22750 (epoch 22.237), train_loss = 0.88243113, grad/param norm = 2.0995e-01, time/batch = 19.0209s	
10119/22750 (epoch 22.240), train_loss = 0.92881433, grad/param norm = 1.8592e-01, time/batch = 18.9190s	
10120/22750 (epoch 22.242), train_loss = 1.17990054, grad/param norm = 2.3469e-01, time/batch = 19.9327s	
10121/22750 (epoch 22.244), train_loss = 1.10661098, grad/param norm = 2.2249e-01, time/batch = 18.1664s	
10122/22750 (epoch 22.246), train_loss = 1.13164061, grad/param norm = 2.0618e-01, time/batch = 17.7415s	
10123/22750 (epoch 22.248), train_loss = 0.93617731, grad/param norm = 2.0471e-01, time/batch = 18.9958s	
10124/22750 (epoch 22.251), train_loss = 1.06778659, grad/param norm = 1.9793e-01, time/batch = 18.7515s	
10125/22750 (epoch 22.253), train_loss = 0.99592260, grad/param norm = 2.3689e-01, time/batch = 18.5710s	
10126/22750 (epoch 22.255), train_loss = 0.96123671, grad/param norm = 1.8736e-01, time/batch = 18.0780s	
10127/22750 (epoch 22.257), train_loss = 0.87625521, grad/param norm = 1.8724e-01, time/batch = 18.6967s	
10128/22750 (epoch 22.259), train_loss = 1.09974660, grad/param norm = 2.5119e-01, time/batch = 19.2609s	
10129/22750 (epoch 22.262), train_loss = 0.98208895, grad/param norm = 1.9665e-01, time/batch = 19.4290s	
10130/22750 (epoch 22.264), train_loss = 0.78864779, grad/param norm = 2.1066e-01, time/batch = 18.4261s	
10131/22750 (epoch 22.266), train_loss = 0.95059400, grad/param norm = 2.0529e-01, time/batch = 18.9822s	
10132/22750 (epoch 22.268), train_loss = 1.12103605, grad/param norm = 2.3047e-01, time/batch = 18.4154s	
10133/22750 (epoch 22.270), train_loss = 0.90109547, grad/param norm = 2.5036e-01, time/batch = 19.7425s	
10134/22750 (epoch 22.273), train_loss = 1.25734412, grad/param norm = 2.3465e-01, time/batch = 18.1553s	
10135/22750 (epoch 22.275), train_loss = 1.08721075, grad/param norm = 1.9031e-01, time/batch = 18.1593s	
10136/22750 (epoch 22.277), train_loss = 0.90999998, grad/param norm = 2.7069e-01, time/batch = 20.1787s	
10137/22750 (epoch 22.279), train_loss = 0.83035905, grad/param norm = 2.0072e-01, time/batch = 20.6174s	
10138/22750 (epoch 22.281), train_loss = 1.10080339, grad/param norm = 2.0811e-01, time/batch = 18.4344s	
10139/22750 (epoch 22.284), train_loss = 0.95008097, grad/param norm = 1.7920e-01, time/batch = 18.7576s	
10140/22750 (epoch 22.286), train_loss = 1.07268569, grad/param norm = 2.0106e-01, time/batch = 19.1659s	
10141/22750 (epoch 22.288), train_loss = 1.13160375, grad/param norm = 2.1245e-01, time/batch = 16.4208s	
10142/22750 (epoch 22.290), train_loss = 0.98211347, grad/param norm = 1.9204e-01, time/batch = 17.4959s	
10143/22750 (epoch 22.292), train_loss = 1.03912593, grad/param norm = 2.2669e-01, time/batch = 17.4913s	
10144/22750 (epoch 22.295), train_loss = 1.03130474, grad/param norm = 1.9429e-01, time/batch = 19.1606s	
10145/22750 (epoch 22.297), train_loss = 0.96029668, grad/param norm = 2.0429e-01, time/batch = 19.0345s	
10146/22750 (epoch 22.299), train_loss = 1.10547485, grad/param norm = 2.0761e-01, time/batch = 20.3663s	
10147/22750 (epoch 22.301), train_loss = 1.00226882, grad/param norm = 2.0442e-01, time/batch = 19.6815s	
10148/22750 (epoch 22.303), train_loss = 1.04993373, grad/param norm = 2.0630e-01, time/batch = 17.9963s	
10149/22750 (epoch 22.305), train_loss = 1.18646967, grad/param norm = 2.1338e-01, time/batch = 18.8180s	
10150/22750 (epoch 22.308), train_loss = 1.04624435, grad/param norm = 1.8916e-01, time/batch = 19.2237s	
10151/22750 (epoch 22.310), train_loss = 0.86019020, grad/param norm = 1.9499e-01, time/batch = 18.5822s	
10152/22750 (epoch 22.312), train_loss = 1.00528060, grad/param norm = 1.9243e-01, time/batch = 17.6565s	
10153/22750 (epoch 22.314), train_loss = 0.98281292, grad/param norm = 1.9268e-01, time/batch = 19.6710s	
10154/22750 (epoch 22.316), train_loss = 0.96472764, grad/param norm = 2.0810e-01, time/batch = 18.8378s	
10155/22750 (epoch 22.319), train_loss = 0.98823414, grad/param norm = 2.1093e-01, time/batch = 19.5152s	
10156/22750 (epoch 22.321), train_loss = 0.91456266, grad/param norm = 2.0252e-01, time/batch = 19.9330s	
10157/22750 (epoch 22.323), train_loss = 1.01622264, grad/param norm = 2.1309e-01, time/batch = 18.8195s	
10158/22750 (epoch 22.325), train_loss = 0.84784210, grad/param norm = 1.9821e-01, time/batch = 19.3253s	
10159/22750 (epoch 22.327), train_loss = 0.95574395, grad/param norm = 2.0539e-01, time/batch = 19.4116s	
10160/22750 (epoch 22.330), train_loss = 1.17342497, grad/param norm = 2.0679e-01, time/batch = 17.6796s	
10161/22750 (epoch 22.332), train_loss = 1.17522793, grad/param norm = 2.1230e-01, time/batch = 20.1525s	
10162/22750 (epoch 22.334), train_loss = 0.81039846, grad/param norm = 1.8129e-01, time/batch = 20.0050s	
10163/22750 (epoch 22.336), train_loss = 1.06792394, grad/param norm = 2.0358e-01, time/batch = 18.4375s	
10164/22750 (epoch 22.338), train_loss = 0.94064152, grad/param norm = 1.8955e-01, time/batch = 20.6019s	
10165/22750 (epoch 22.341), train_loss = 0.97096282, grad/param norm = 1.8912e-01, time/batch = 18.0839s	
10166/22750 (epoch 22.343), train_loss = 0.86473859, grad/param norm = 2.0757e-01, time/batch = 18.9786s	
10167/22750 (epoch 22.345), train_loss = 1.06448539, grad/param norm = 2.6118e-01, time/batch = 18.8200s	
10168/22750 (epoch 22.347), train_loss = 1.11633246, grad/param norm = 2.2335e-01, time/batch = 19.7388s	
10169/22750 (epoch 22.349), train_loss = 0.77765281, grad/param norm = 1.8679e-01, time/batch = 19.0829s	
10170/22750 (epoch 22.352), train_loss = 1.08521194, grad/param norm = 2.2797e-01, time/batch = 16.8347s	
10171/22750 (epoch 22.354), train_loss = 1.08492347, grad/param norm = 2.0654e-01, time/batch = 20.6836s	
10172/22750 (epoch 22.356), train_loss = 1.09798540, grad/param norm = 2.1043e-01, time/batch = 19.1921s	
10173/22750 (epoch 22.358), train_loss = 0.97619728, grad/param norm = 2.3364e-01, time/batch = 19.2755s	
10174/22750 (epoch 22.360), train_loss = 1.17765546, grad/param norm = 1.9891e-01, time/batch = 19.3188s	
10175/22750 (epoch 22.363), train_loss = 0.96216490, grad/param norm = 2.0489e-01, time/batch = 17.4082s	
10176/22750 (epoch 22.365), train_loss = 0.80422743, grad/param norm = 2.2913e-01, time/batch = 18.6621s	
10177/22750 (epoch 22.367), train_loss = 0.87396747, grad/param norm = 2.0229e-01, time/batch = 20.0800s	
10178/22750 (epoch 22.369), train_loss = 0.97149954, grad/param norm = 2.0436e-01, time/batch = 20.8254s	
10179/22750 (epoch 22.371), train_loss = 0.96058220, grad/param norm = 2.0376e-01, time/batch = 19.1852s	
10180/22750 (epoch 22.374), train_loss = 0.89197586, grad/param norm = 1.9205e-01, time/batch = 19.7747s	
10181/22750 (epoch 22.376), train_loss = 0.94053614, grad/param norm = 1.8856e-01, time/batch = 19.6856s	
10182/22750 (epoch 22.378), train_loss = 0.97251300, grad/param norm = 1.9067e-01, time/batch = 19.6668s	
10183/22750 (epoch 22.380), train_loss = 1.08308185, grad/param norm = 2.0756e-01, time/batch = 19.5728s	
10184/22750 (epoch 22.382), train_loss = 0.93467895, grad/param norm = 1.9141e-01, time/batch = 19.8061s	
10185/22750 (epoch 22.385), train_loss = 1.04960635, grad/param norm = 1.8648e-01, time/batch = 19.4046s	
10186/22750 (epoch 22.387), train_loss = 1.00638443, grad/param norm = 1.8519e-01, time/batch = 18.0014s	
10187/22750 (epoch 22.389), train_loss = 0.79294865, grad/param norm = 1.9443e-01, time/batch = 18.7608s	
10188/22750 (epoch 22.391), train_loss = 0.62729141, grad/param norm = 1.5985e-01, time/batch = 16.4146s	
10189/22750 (epoch 22.393), train_loss = 0.83131007, grad/param norm = 1.7837e-01, time/batch = 15.1460s	
10190/22750 (epoch 22.396), train_loss = 1.03384812, grad/param norm = 2.0179e-01, time/batch = 15.9584s	
10191/22750 (epoch 22.398), train_loss = 0.94657419, grad/param norm = 1.8550e-01, time/batch = 15.2328s	
10192/22750 (epoch 22.400), train_loss = 0.96529665, grad/param norm = 1.9675e-01, time/batch = 16.1041s	
10193/22750 (epoch 22.402), train_loss = 1.03599044, grad/param norm = 2.0083e-01, time/batch = 15.3696s	
10194/22750 (epoch 22.404), train_loss = 1.10274495, grad/param norm = 1.9548e-01, time/batch = 15.3770s	
10195/22750 (epoch 22.407), train_loss = 1.06902495, grad/param norm = 1.9569e-01, time/batch = 19.1412s	
10196/22750 (epoch 22.409), train_loss = 0.90851322, grad/param norm = 1.9972e-01, time/batch = 18.0770s	
10197/22750 (epoch 22.411), train_loss = 0.93811902, grad/param norm = 1.9381e-01, time/batch = 19.6789s	
10198/22750 (epoch 22.413), train_loss = 0.73479496, grad/param norm = 1.8240e-01, time/batch = 19.6748s	
10199/22750 (epoch 22.415), train_loss = 0.73853056, grad/param norm = 1.6323e-01, time/batch = 19.2036s	
10200/22750 (epoch 22.418), train_loss = 0.89630668, grad/param norm = 1.9381e-01, time/batch = 20.0946s	
10201/22750 (epoch 22.420), train_loss = 1.05104468, grad/param norm = 2.4424e-01, time/batch = 19.8995s	
10202/22750 (epoch 22.422), train_loss = 1.20442839, grad/param norm = 2.6581e-01, time/batch = 17.0762s	
10203/22750 (epoch 22.424), train_loss = 1.19404794, grad/param norm = 2.2243e-01, time/batch = 20.0731s	
10204/22750 (epoch 22.426), train_loss = 1.19005399, grad/param norm = 2.0851e-01, time/batch = 19.3346s	
10205/22750 (epoch 22.429), train_loss = 0.87745339, grad/param norm = 1.9071e-01, time/batch = 16.3080s	
10206/22750 (epoch 22.431), train_loss = 0.78862094, grad/param norm = 1.7810e-01, time/batch = 18.2417s	
10207/22750 (epoch 22.433), train_loss = 0.91179242, grad/param norm = 2.0891e-01, time/batch = 14.9668s	
10208/22750 (epoch 22.435), train_loss = 0.74374158, grad/param norm = 1.8059e-01, time/batch = 14.9846s	
10209/22750 (epoch 22.437), train_loss = 0.64867855, grad/param norm = 1.7115e-01, time/batch = 15.0681s	
10210/22750 (epoch 22.440), train_loss = 0.97078455, grad/param norm = 2.3428e-01, time/batch = 14.9672s	
10211/22750 (epoch 22.442), train_loss = 0.97523788, grad/param norm = 1.9897e-01, time/batch = 14.9580s	
10212/22750 (epoch 22.444), train_loss = 0.96504972, grad/param norm = 2.3125e-01, time/batch = 15.0552s	
10213/22750 (epoch 22.446), train_loss = 0.96686150, grad/param norm = 2.1215e-01, time/batch = 14.9604s	
10214/22750 (epoch 22.448), train_loss = 1.24236711, grad/param norm = 2.1814e-01, time/batch = 14.8767s	
10215/22750 (epoch 22.451), train_loss = 1.16460939, grad/param norm = 2.0449e-01, time/batch = 15.1218s	
10216/22750 (epoch 22.453), train_loss = 1.12515132, grad/param norm = 2.2779e-01, time/batch = 14.9582s	
10217/22750 (epoch 22.455), train_loss = 1.20880585, grad/param norm = 2.2196e-01, time/batch = 15.3757s	
10218/22750 (epoch 22.457), train_loss = 1.09082764, grad/param norm = 2.7485e-01, time/batch = 15.6171s	
10219/22750 (epoch 22.459), train_loss = 1.07772228, grad/param norm = 2.0063e-01, time/batch = 15.1391s	
10220/22750 (epoch 22.462), train_loss = 1.06370404, grad/param norm = 2.0256e-01, time/batch = 14.9953s	
10221/22750 (epoch 22.464), train_loss = 0.81924472, grad/param norm = 1.9812e-01, time/batch = 15.3689s	
10222/22750 (epoch 22.466), train_loss = 1.13466347, grad/param norm = 2.2825e-01, time/batch = 14.9716s	
10223/22750 (epoch 22.468), train_loss = 0.98580396, grad/param norm = 2.1264e-01, time/batch = 14.7982s	
10224/22750 (epoch 22.470), train_loss = 1.11764059, grad/param norm = 2.2147e-01, time/batch = 15.6932s	
10225/22750 (epoch 22.473), train_loss = 0.97494374, grad/param norm = 2.0251e-01, time/batch = 14.8768s	
10226/22750 (epoch 22.475), train_loss = 0.99642401, grad/param norm = 2.0415e-01, time/batch = 15.0465s	
10227/22750 (epoch 22.477), train_loss = 0.84851396, grad/param norm = 1.8646e-01, time/batch = 14.9636s	
10228/22750 (epoch 22.479), train_loss = 0.83765449, grad/param norm = 1.9240e-01, time/batch = 15.2152s	
10229/22750 (epoch 22.481), train_loss = 0.77731493, grad/param norm = 1.6166e-01, time/batch = 15.0689s	
10230/22750 (epoch 22.484), train_loss = 0.69351999, grad/param norm = 1.9684e-01, time/batch = 15.1299s	
10231/22750 (epoch 22.486), train_loss = 0.81747408, grad/param norm = 1.9209e-01, time/batch = 14.9131s	
10232/22750 (epoch 22.488), train_loss = 0.72615262, grad/param norm = 1.9600e-01, time/batch = 15.4305s	
10233/22750 (epoch 22.490), train_loss = 0.95191363, grad/param norm = 1.8658e-01, time/batch = 15.4299s	
10234/22750 (epoch 22.492), train_loss = 1.09823965, grad/param norm = 2.3056e-01, time/batch = 14.8810s	
10235/22750 (epoch 22.495), train_loss = 0.86514240, grad/param norm = 1.9001e-01, time/batch = 15.5103s	
10236/22750 (epoch 22.497), train_loss = 0.95928072, grad/param norm = 2.2426e-01, time/batch = 15.6864s	
10237/22750 (epoch 22.499), train_loss = 0.88263929, grad/param norm = 1.9959e-01, time/batch = 15.6031s	
10238/22750 (epoch 22.501), train_loss = 0.95844844, grad/param norm = 1.9676e-01, time/batch = 15.3663s	
10239/22750 (epoch 22.503), train_loss = 0.96921680, grad/param norm = 2.0429e-01, time/batch = 15.0775s	
10240/22750 (epoch 22.505), train_loss = 0.83237215, grad/param norm = 1.8614e-01, time/batch = 15.5526s	
10241/22750 (epoch 22.508), train_loss = 0.78666254, grad/param norm = 1.9310e-01, time/batch = 15.1434s	
10242/22750 (epoch 22.510), train_loss = 0.81606262, grad/param norm = 1.8154e-01, time/batch = 16.1661s	
10243/22750 (epoch 22.512), train_loss = 0.84002127, grad/param norm = 1.7868e-01, time/batch = 15.8693s	
10244/22750 (epoch 22.514), train_loss = 0.90900719, grad/param norm = 1.9875e-01, time/batch = 16.0917s	
10245/22750 (epoch 22.516), train_loss = 0.89451260, grad/param norm = 1.9503e-01, time/batch = 15.5184s	
10246/22750 (epoch 22.519), train_loss = 1.03969389, grad/param norm = 2.1910e-01, time/batch = 16.0138s	
10247/22750 (epoch 22.521), train_loss = 0.97086651, grad/param norm = 2.2017e-01, time/batch = 15.6136s	
10248/22750 (epoch 22.523), train_loss = 0.92435665, grad/param norm = 2.4765e-01, time/batch = 15.6201s	
10249/22750 (epoch 22.525), train_loss = 1.09437894, grad/param norm = 2.1860e-01, time/batch = 15.4674s	
10250/22750 (epoch 22.527), train_loss = 0.96576617, grad/param norm = 2.0968e-01, time/batch = 15.3134s	
10251/22750 (epoch 22.530), train_loss = 0.88220746, grad/param norm = 2.1677e-01, time/batch = 15.5638s	
10252/22750 (epoch 22.532), train_loss = 0.81455785, grad/param norm = 1.7443e-01, time/batch = 16.2005s	
10253/22750 (epoch 22.534), train_loss = 1.05342423, grad/param norm = 2.1253e-01, time/batch = 15.3141s	
10254/22750 (epoch 22.536), train_loss = 0.99166045, grad/param norm = 1.7996e-01, time/batch = 15.6087s	
10255/22750 (epoch 22.538), train_loss = 0.96357721, grad/param norm = 1.8667e-01, time/batch = 15.5296s	
10256/22750 (epoch 22.541), train_loss = 0.84136360, grad/param norm = 2.0815e-01, time/batch = 15.1370s	
10257/22750 (epoch 22.543), train_loss = 0.83926016, grad/param norm = 1.9945e-01, time/batch = 15.2870s	
10258/22750 (epoch 22.545), train_loss = 1.03445835, grad/param norm = 1.9513e-01, time/batch = 15.2145s	
10259/22750 (epoch 22.547), train_loss = 0.87983930, grad/param norm = 1.9038e-01, time/batch = 15.7514s	
10260/22750 (epoch 22.549), train_loss = 0.89789126, grad/param norm = 1.8359e-01, time/batch = 15.1381s	
10261/22750 (epoch 22.552), train_loss = 0.98464785, grad/param norm = 2.0975e-01, time/batch = 14.9052s	
10262/22750 (epoch 22.554), train_loss = 1.02717544, grad/param norm = 2.3597e-01, time/batch = 14.8319s	
10263/22750 (epoch 22.556), train_loss = 0.98186892, grad/param norm = 2.0107e-01, time/batch = 15.6139s	
10264/22750 (epoch 22.558), train_loss = 1.05391630, grad/param norm = 2.0590e-01, time/batch = 15.1379s	
10265/22750 (epoch 22.560), train_loss = 0.90653247, grad/param norm = 2.0727e-01, time/batch = 16.0947s	
10266/22750 (epoch 22.563), train_loss = 1.08975682, grad/param norm = 2.3531e-01, time/batch = 15.3677s	
10267/22750 (epoch 22.565), train_loss = 1.01288693, grad/param norm = 2.2065e-01, time/batch = 16.0757s	
10268/22750 (epoch 22.567), train_loss = 0.98573754, grad/param norm = 1.9105e-01, time/batch = 15.2461s	
10269/22750 (epoch 22.569), train_loss = 0.93248884, grad/param norm = 1.8879e-01, time/batch = 15.2093s	
10270/22750 (epoch 22.571), train_loss = 0.96687979, grad/param norm = 2.1510e-01, time/batch = 15.3601s	
10271/22750 (epoch 22.574), train_loss = 0.88952379, grad/param norm = 2.0294e-01, time/batch = 15.7991s	
10272/22750 (epoch 22.576), train_loss = 0.89459518, grad/param norm = 2.5328e-01, time/batch = 15.6295s	
10273/22750 (epoch 22.578), train_loss = 0.83076341, grad/param norm = 2.0108e-01, time/batch = 15.3013s	
10274/22750 (epoch 22.580), train_loss = 0.98394014, grad/param norm = 2.2237e-01, time/batch = 15.4362s	
10275/22750 (epoch 22.582), train_loss = 0.87915977, grad/param norm = 1.9604e-01, time/batch = 15.2018s	
10276/22750 (epoch 22.585), train_loss = 0.81526866, grad/param norm = 1.9321e-01, time/batch = 15.5108s	
10277/22750 (epoch 22.587), train_loss = 0.80802564, grad/param norm = 1.6861e-01, time/batch = 15.2858s	
10278/22750 (epoch 22.589), train_loss = 0.76814310, grad/param norm = 1.8277e-01, time/batch = 15.5083s	
10279/22750 (epoch 22.591), train_loss = 0.93435585, grad/param norm = 2.0389e-01, time/batch = 15.3764s	
10280/22750 (epoch 22.593), train_loss = 1.10540023, grad/param norm = 1.9272e-01, time/batch = 15.2108s	
10281/22750 (epoch 22.596), train_loss = 1.09880877, grad/param norm = 2.0530e-01, time/batch = 15.1326s	
10282/22750 (epoch 22.598), train_loss = 1.13174621, grad/param norm = 2.2800e-01, time/batch = 17.2629s	
10283/22750 (epoch 22.600), train_loss = 1.10899379, grad/param norm = 2.2439e-01, time/batch = 15.5524s	
10284/22750 (epoch 22.602), train_loss = 0.88884579, grad/param norm = 1.8438e-01, time/batch = 19.3576s	
10285/22750 (epoch 22.604), train_loss = 0.90134108, grad/param norm = 2.0027e-01, time/batch = 19.5458s	
10286/22750 (epoch 22.607), train_loss = 0.80127164, grad/param norm = 1.6107e-01, time/batch = 19.4884s	
10287/22750 (epoch 22.609), train_loss = 0.74851173, grad/param norm = 1.6693e-01, time/batch = 19.1668s	
10288/22750 (epoch 22.611), train_loss = 0.91001672, grad/param norm = 1.9326e-01, time/batch = 18.2618s	
10289/22750 (epoch 22.613), train_loss = 0.85510620, grad/param norm = 1.7600e-01, time/batch = 17.6610s	
10290/22750 (epoch 22.615), train_loss = 0.89904330, grad/param norm = 1.8672e-01, time/batch = 18.9147s	
10291/22750 (epoch 22.618), train_loss = 0.93573913, grad/param norm = 1.9397e-01, time/batch = 18.4999s	
10292/22750 (epoch 22.620), train_loss = 0.91402791, grad/param norm = 1.8585e-01, time/batch = 18.6105s	
10293/22750 (epoch 22.622), train_loss = 0.77589342, grad/param norm = 1.7736e-01, time/batch = 19.2666s	
10294/22750 (epoch 22.624), train_loss = 0.85364011, grad/param norm = 1.7505e-01, time/batch = 17.8443s	
10295/22750 (epoch 22.626), train_loss = 0.77098440, grad/param norm = 1.7639e-01, time/batch = 18.2657s	
10296/22750 (epoch 22.629), train_loss = 0.88721222, grad/param norm = 1.9952e-01, time/batch = 18.4184s	
10297/22750 (epoch 22.631), train_loss = 0.93422120, grad/param norm = 1.7909e-01, time/batch = 19.3198s	
10298/22750 (epoch 22.633), train_loss = 0.81586560, grad/param norm = 1.8696e-01, time/batch = 17.6731s	
10299/22750 (epoch 22.635), train_loss = 0.94559147, grad/param norm = 1.9106e-01, time/batch = 19.5652s	
10300/22750 (epoch 22.637), train_loss = 1.00183886, grad/param norm = 2.1350e-01, time/batch = 17.0011s	
10301/22750 (epoch 22.640), train_loss = 1.00710135, grad/param norm = 2.0596e-01, time/batch = 17.6945s	
10302/22750 (epoch 22.642), train_loss = 1.08747441, grad/param norm = 2.1039e-01, time/batch = 19.1026s	
10303/22750 (epoch 22.644), train_loss = 0.93633014, grad/param norm = 2.0412e-01, time/batch = 19.7728s	
10304/22750 (epoch 22.646), train_loss = 0.97368349, grad/param norm = 2.6174e-01, time/batch = 18.6106s	
10305/22750 (epoch 22.648), train_loss = 0.98961571, grad/param norm = 2.0385e-01, time/batch = 17.0189s	
10306/22750 (epoch 22.651), train_loss = 1.00849699, grad/param norm = 2.0368e-01, time/batch = 18.5896s	
10307/22750 (epoch 22.653), train_loss = 1.04944868, grad/param norm = 1.9919e-01, time/batch = 17.5143s	
10308/22750 (epoch 22.655), train_loss = 0.96985174, grad/param norm = 1.8290e-01, time/batch = 17.1867s	
10309/22750 (epoch 22.657), train_loss = 1.13671545, grad/param norm = 2.3268e-01, time/batch = 19.0096s	
10310/22750 (epoch 22.659), train_loss = 1.16573975, grad/param norm = 2.1627e-01, time/batch = 19.7736s	
10311/22750 (epoch 22.662), train_loss = 1.13841513, grad/param norm = 2.1447e-01, time/batch = 19.0429s	
10312/22750 (epoch 22.664), train_loss = 0.99632352, grad/param norm = 2.0723e-01, time/batch = 19.1748s	
10313/22750 (epoch 22.666), train_loss = 0.81164204, grad/param norm = 1.8044e-01, time/batch = 20.7643s	
10314/22750 (epoch 22.668), train_loss = 0.96928903, grad/param norm = 1.9695e-01, time/batch = 15.9512s	
10315/22750 (epoch 22.670), train_loss = 0.96529059, grad/param norm = 2.0817e-01, time/batch = 32.1674s	
10316/22750 (epoch 22.673), train_loss = 1.21088487, grad/param norm = 2.2960e-01, time/batch = 17.1845s	
10317/22750 (epoch 22.675), train_loss = 1.34236332, grad/param norm = 2.4421e-01, time/batch = 18.1334s	
10318/22750 (epoch 22.677), train_loss = 1.14660870, grad/param norm = 2.3380e-01, time/batch = 16.2348s	
10319/22750 (epoch 22.679), train_loss = 1.19019253, grad/param norm = 2.3885e-01, time/batch = 15.4587s	
10320/22750 (epoch 22.681), train_loss = 1.12718164, grad/param norm = 1.9267e-01, time/batch = 15.4056s	
10321/22750 (epoch 22.684), train_loss = 1.13243185, grad/param norm = 2.2849e-01, time/batch = 15.5546s	
10322/22750 (epoch 22.686), train_loss = 1.15164773, grad/param norm = 2.2419e-01, time/batch = 15.4611s	
10323/22750 (epoch 22.688), train_loss = 1.13164671, grad/param norm = 2.2203e-01, time/batch = 15.2034s	
10324/22750 (epoch 22.690), train_loss = 1.10446445, grad/param norm = 2.4857e-01, time/batch = 15.4553s	
10325/22750 (epoch 22.692), train_loss = 1.14626998, grad/param norm = 2.2579e-01, time/batch = 15.5423s	
10326/22750 (epoch 22.695), train_loss = 1.01219900, grad/param norm = 2.0301e-01, time/batch = 15.6143s	
10327/22750 (epoch 22.697), train_loss = 0.98640128, grad/param norm = 1.9827e-01, time/batch = 15.3599s	
10328/22750 (epoch 22.699), train_loss = 0.97503277, grad/param norm = 2.1152e-01, time/batch = 15.3621s	
10329/22750 (epoch 22.701), train_loss = 0.85262324, grad/param norm = 1.9390e-01, time/batch = 15.2975s	
10330/22750 (epoch 22.703), train_loss = 0.96070161, grad/param norm = 1.9748e-01, time/batch = 14.8299s	
10331/22750 (epoch 22.705), train_loss = 0.91437835, grad/param norm = 2.0297e-01, time/batch = 14.9801s	
10332/22750 (epoch 22.708), train_loss = 0.99391983, grad/param norm = 1.9501e-01, time/batch = 14.9846s	
10333/22750 (epoch 22.710), train_loss = 0.86550331, grad/param norm = 1.9856e-01, time/batch = 15.5968s	
10334/22750 (epoch 22.712), train_loss = 0.84561921, grad/param norm = 1.9562e-01, time/batch = 15.2884s	
10335/22750 (epoch 22.714), train_loss = 0.79521641, grad/param norm = 1.8043e-01, time/batch = 14.8896s	
10336/22750 (epoch 22.716), train_loss = 0.83140463, grad/param norm = 1.8480e-01, time/batch = 15.0443s	
10337/22750 (epoch 22.719), train_loss = 1.00286732, grad/param norm = 2.5015e-01, time/batch = 15.2088s	
10338/22750 (epoch 22.721), train_loss = 1.04757108, grad/param norm = 1.9835e-01, time/batch = 15.2787s	
10339/22750 (epoch 22.723), train_loss = 1.04258018, grad/param norm = 2.2101e-01, time/batch = 15.4198s	
10340/22750 (epoch 22.725), train_loss = 0.96463441, grad/param norm = 2.1814e-01, time/batch = 15.0473s	
10341/22750 (epoch 22.727), train_loss = 0.91117161, grad/param norm = 1.9875e-01, time/batch = 15.2263s	
10342/22750 (epoch 22.730), train_loss = 0.92455863, grad/param norm = 2.1261e-01, time/batch = 15.2295s	
10343/22750 (epoch 22.732), train_loss = 0.87767757, grad/param norm = 1.8233e-01, time/batch = 15.3925s	
10344/22750 (epoch 22.734), train_loss = 0.76156543, grad/param norm = 1.6392e-01, time/batch = 15.2948s	
10345/22750 (epoch 22.736), train_loss = 0.89631494, grad/param norm = 1.9829e-01, time/batch = 15.6032s	
10346/22750 (epoch 22.738), train_loss = 1.02299564, grad/param norm = 2.1200e-01, time/batch = 15.3675s	
10347/22750 (epoch 22.741), train_loss = 1.06244978, grad/param norm = 2.0490e-01, time/batch = 15.0464s	
10348/22750 (epoch 22.743), train_loss = 1.00475561, grad/param norm = 1.9306e-01, time/batch = 15.4459s	
10349/22750 (epoch 22.745), train_loss = 0.82558818, grad/param norm = 1.7936e-01, time/batch = 15.2880s	
10350/22750 (epoch 22.747), train_loss = 0.90554402, grad/param norm = 1.7760e-01, time/batch = 15.1277s	
10351/22750 (epoch 22.749), train_loss = 1.11346825, grad/param norm = 2.1801e-01, time/batch = 15.0606s	
10352/22750 (epoch 22.752), train_loss = 0.95551889, grad/param norm = 2.0274e-01, time/batch = 15.3076s	
10353/22750 (epoch 22.754), train_loss = 0.98133358, grad/param norm = 2.0000e-01, time/batch = 15.2987s	
10354/22750 (epoch 22.756), train_loss = 0.88140304, grad/param norm = 2.0224e-01, time/batch = 15.0777s	
10355/22750 (epoch 22.758), train_loss = 0.86603119, grad/param norm = 1.9087e-01, time/batch = 15.2084s	
10356/22750 (epoch 22.760), train_loss = 0.91886224, grad/param norm = 2.0053e-01, time/batch = 15.4533s	
10357/22750 (epoch 22.763), train_loss = 0.98684014, grad/param norm = 2.0182e-01, time/batch = 15.3581s	
10358/22750 (epoch 22.765), train_loss = 0.97320228, grad/param norm = 2.1487e-01, time/batch = 15.1181s	
10359/22750 (epoch 22.767), train_loss = 0.99908468, grad/param norm = 2.1918e-01, time/batch = 15.2149s	
10360/22750 (epoch 22.769), train_loss = 1.18006196, grad/param norm = 2.2835e-01, time/batch = 15.4603s	
10361/22750 (epoch 22.771), train_loss = 1.12996920, grad/param norm = 2.4565e-01, time/batch = 15.4556s	
10362/22750 (epoch 22.774), train_loss = 0.95900744, grad/param norm = 2.2456e-01, time/batch = 15.0571s	
10363/22750 (epoch 22.776), train_loss = 1.03268351, grad/param norm = 2.1830e-01, time/batch = 15.4710s	
10364/22750 (epoch 22.778), train_loss = 1.14226434, grad/param norm = 2.2345e-01, time/batch = 15.4704s	
10365/22750 (epoch 22.780), train_loss = 0.98039604, grad/param norm = 2.0646e-01, time/batch = 15.3648s	
10366/22750 (epoch 22.782), train_loss = 1.13090168, grad/param norm = 2.2050e-01, time/batch = 15.3791s	
10367/22750 (epoch 22.785), train_loss = 0.96016649, grad/param norm = 2.0111e-01, time/batch = 15.2935s	
10368/22750 (epoch 22.787), train_loss = 0.86009983, grad/param norm = 2.0847e-01, time/batch = 15.8397s	
10369/22750 (epoch 22.789), train_loss = 0.93812003, grad/param norm = 1.8384e-01, time/batch = 15.0527s	
10370/22750 (epoch 22.791), train_loss = 0.91259101, grad/param norm = 1.9867e-01, time/batch = 15.3686s	
10371/22750 (epoch 22.793), train_loss = 0.88698549, grad/param norm = 2.2272e-01, time/batch = 15.0486s	
10372/22750 (epoch 22.796), train_loss = 0.80467718, grad/param norm = 1.8347e-01, time/batch = 15.9150s	
10373/22750 (epoch 22.798), train_loss = 0.85027997, grad/param norm = 1.9848e-01, time/batch = 14.7503s	
10374/22750 (epoch 22.800), train_loss = 0.89586584, grad/param norm = 2.1551e-01, time/batch = 15.0731s	
10375/22750 (epoch 22.802), train_loss = 0.81556578, grad/param norm = 2.0522e-01, time/batch = 15.1551s	
10376/22750 (epoch 22.804), train_loss = 1.09363534, grad/param norm = 2.1244e-01, time/batch = 15.2264s	
10377/22750 (epoch 22.807), train_loss = 1.03643524, grad/param norm = 2.0076e-01, time/batch = 15.1360s	
10378/22750 (epoch 22.809), train_loss = 1.10735798, grad/param norm = 2.1588e-01, time/batch = 14.8040s	
10379/22750 (epoch 22.811), train_loss = 0.93309328, grad/param norm = 2.0531e-01, time/batch = 14.7955s	
10380/22750 (epoch 22.813), train_loss = 1.00571606, grad/param norm = 1.8965e-01, time/batch = 15.2791s	
10381/22750 (epoch 22.815), train_loss = 1.13489115, grad/param norm = 2.0635e-01, time/batch = 15.1250s	
10382/22750 (epoch 22.818), train_loss = 1.08312010, grad/param norm = 2.0060e-01, time/batch = 15.4944s	
10383/22750 (epoch 22.820), train_loss = 1.22260355, grad/param norm = 1.9102e-01, time/batch = 15.1245s	
10384/22750 (epoch 22.822), train_loss = 1.01941948, grad/param norm = 2.0347e-01, time/batch = 15.2916s	
10385/22750 (epoch 22.824), train_loss = 0.87384139, grad/param norm = 1.8649e-01, time/batch = 14.7499s	
10386/22750 (epoch 22.826), train_loss = 0.95274645, grad/param norm = 1.9106e-01, time/batch = 14.8742s	
10387/22750 (epoch 22.829), train_loss = 1.14076966, grad/param norm = 2.2408e-01, time/batch = 15.5380s	
10388/22750 (epoch 22.831), train_loss = 1.08028482, grad/param norm = 2.1716e-01, time/batch = 15.0696s	
10389/22750 (epoch 22.833), train_loss = 1.00243840, grad/param norm = 2.1143e-01, time/batch = 14.6420s	
10390/22750 (epoch 22.835), train_loss = 0.91091170, grad/param norm = 1.8309e-01, time/batch = 14.8031s	
10391/22750 (epoch 22.837), train_loss = 0.93867477, grad/param norm = 1.9561e-01, time/batch = 15.1249s	
10392/22750 (epoch 22.840), train_loss = 0.84344283, grad/param norm = 1.7549e-01, time/batch = 15.4259s	
10393/22750 (epoch 22.842), train_loss = 0.89474853, grad/param norm = 1.8604e-01, time/batch = 15.2756s	
10394/22750 (epoch 22.844), train_loss = 1.04280895, grad/param norm = 2.1579e-01, time/batch = 14.8797s	
10395/22750 (epoch 22.846), train_loss = 0.99230946, grad/param norm = 1.9451e-01, time/batch = 14.9485s	
10396/22750 (epoch 22.848), train_loss = 0.89463910, grad/param norm = 1.7110e-01, time/batch = 14.9940s	
10397/22750 (epoch 22.851), train_loss = 0.86956741, grad/param norm = 1.9259e-01, time/batch = 14.6582s	
10398/22750 (epoch 22.853), train_loss = 1.02460132, grad/param norm = 1.9353e-01, time/batch = 14.7428s	
10399/22750 (epoch 22.855), train_loss = 0.86493053, grad/param norm = 1.9003e-01, time/batch = 17.9364s	
10400/22750 (epoch 22.857), train_loss = 0.99026696, grad/param norm = 1.8821e-01, time/batch = 17.7412s	
10401/22750 (epoch 22.859), train_loss = 1.04802593, grad/param norm = 2.2104e-01, time/batch = 17.5933s	
10402/22750 (epoch 22.862), train_loss = 1.14291424, grad/param norm = 2.1640e-01, time/batch = 17.9056s	
10403/22750 (epoch 22.864), train_loss = 0.95838948, grad/param norm = 1.9980e-01, time/batch = 17.9213s	
10404/22750 (epoch 22.866), train_loss = 1.01562247, grad/param norm = 1.8158e-01, time/batch = 20.3203s	
10405/22750 (epoch 22.868), train_loss = 0.89233505, grad/param norm = 1.8119e-01, time/batch = 20.3517s	
10406/22750 (epoch 22.870), train_loss = 0.79851836, grad/param norm = 1.8482e-01, time/batch = 18.9294s	
10407/22750 (epoch 22.873), train_loss = 0.93825944, grad/param norm = 1.9459e-01, time/batch = 20.6059s	
10408/22750 (epoch 22.875), train_loss = 1.04945380, grad/param norm = 2.0647e-01, time/batch = 20.0143s	
10409/22750 (epoch 22.877), train_loss = 0.86893744, grad/param norm = 1.9301e-01, time/batch = 16.3339s	
10410/22750 (epoch 22.879), train_loss = 1.11471388, grad/param norm = 2.2375e-01, time/batch = 17.5993s	
10411/22750 (epoch 22.881), train_loss = 1.04590306, grad/param norm = 1.9497e-01, time/batch = 17.0086s	
10412/22750 (epoch 22.884), train_loss = 0.91641937, grad/param norm = 2.0854e-01, time/batch = 16.2827s	
10413/22750 (epoch 22.886), train_loss = 1.05137905, grad/param norm = 2.1641e-01, time/batch = 15.7380s	
10414/22750 (epoch 22.888), train_loss = 1.04794248, grad/param norm = 1.9220e-01, time/batch = 15.2192s	
10415/22750 (epoch 22.890), train_loss = 1.05168584, grad/param norm = 2.0716e-01, time/batch = 15.0641s	
10416/22750 (epoch 22.892), train_loss = 1.29106823, grad/param norm = 2.4136e-01, time/batch = 15.2936s	
10417/22750 (epoch 22.895), train_loss = 0.98902028, grad/param norm = 2.2491e-01, time/batch = 15.1417s	
10418/22750 (epoch 22.897), train_loss = 1.06787050, grad/param norm = 2.1827e-01, time/batch = 15.5374s	
10419/22750 (epoch 22.899), train_loss = 1.03359438, grad/param norm = 2.0185e-01, time/batch = 16.3211s	
10420/22750 (epoch 22.901), train_loss = 1.11731977, grad/param norm = 2.2487e-01, time/batch = 16.4798s	
10421/22750 (epoch 22.903), train_loss = 0.95349780, grad/param norm = 1.9390e-01, time/batch = 15.5976s	
10422/22750 (epoch 22.905), train_loss = 1.06177319, grad/param norm = 2.0568e-01, time/batch = 15.6736s	
10423/22750 (epoch 22.908), train_loss = 0.88483199, grad/param norm = 2.0055e-01, time/batch = 15.4441s	
10424/22750 (epoch 22.910), train_loss = 0.77400143, grad/param norm = 1.7994e-01, time/batch = 16.5730s	
10425/22750 (epoch 22.912), train_loss = 0.92703657, grad/param norm = 1.8541e-01, time/batch = 19.4283s	
10426/22750 (epoch 22.914), train_loss = 0.95872012, grad/param norm = 1.8745e-01, time/batch = 19.5983s	
10427/22750 (epoch 22.916), train_loss = 0.81906756, grad/param norm = 1.9873e-01, time/batch = 16.5725s	
10428/22750 (epoch 22.919), train_loss = 0.94191975, grad/param norm = 2.1266e-01, time/batch = 16.6065s	
10429/22750 (epoch 22.921), train_loss = 0.73843732, grad/param norm = 1.7814e-01, time/batch = 16.2170s	
10430/22750 (epoch 22.923), train_loss = 0.86699068, grad/param norm = 1.7859e-01, time/batch = 16.1191s	
10431/22750 (epoch 22.925), train_loss = 0.92799854, grad/param norm = 1.8039e-01, time/batch = 16.1504s	
10432/22750 (epoch 22.927), train_loss = 0.75304426, grad/param norm = 1.8725e-01, time/batch = 15.8388s	
10433/22750 (epoch 22.930), train_loss = 0.76350778, grad/param norm = 1.6831e-01, time/batch = 16.0612s	
10434/22750 (epoch 22.932), train_loss = 0.96466253, grad/param norm = 2.0730e-01, time/batch = 16.0056s	
10435/22750 (epoch 22.934), train_loss = 0.75285400, grad/param norm = 1.6509e-01, time/batch = 16.2017s	
10436/22750 (epoch 22.936), train_loss = 1.07467138, grad/param norm = 2.1409e-01, time/batch = 16.3518s	
10437/22750 (epoch 22.938), train_loss = 1.04621338, grad/param norm = 1.7913e-01, time/batch = 15.9609s	
10438/22750 (epoch 22.941), train_loss = 1.14179475, grad/param norm = 2.2771e-01, time/batch = 16.3353s	
10439/22750 (epoch 22.943), train_loss = 0.98750961, grad/param norm = 2.1248e-01, time/batch = 15.4332s	
10440/22750 (epoch 22.945), train_loss = 0.99898339, grad/param norm = 2.3014e-01, time/batch = 15.8357s	
10441/22750 (epoch 22.947), train_loss = 0.92425285, grad/param norm = 2.2129e-01, time/batch = 16.4087s	
10442/22750 (epoch 22.949), train_loss = 0.86028945, grad/param norm = 1.9311e-01, time/batch = 18.0603s	
10443/22750 (epoch 22.952), train_loss = 0.89013851, grad/param norm = 1.6936e-01, time/batch = 17.1702s	
10444/22750 (epoch 22.954), train_loss = 0.85303869, grad/param norm = 1.7687e-01, time/batch = 19.9167s	
10445/22750 (epoch 22.956), train_loss = 0.97718613, grad/param norm = 1.8644e-01, time/batch = 19.0125s	
10446/22750 (epoch 22.958), train_loss = 0.90161140, grad/param norm = 1.7077e-01, time/batch = 19.6006s	
10447/22750 (epoch 22.960), train_loss = 0.84980708, grad/param norm = 1.7431e-01, time/batch = 18.0081s	
10448/22750 (epoch 22.963), train_loss = 1.02270131, grad/param norm = 2.0179e-01, time/batch = 18.4869s	
10449/22750 (epoch 22.965), train_loss = 1.03906580, grad/param norm = 1.9612e-01, time/batch = 19.7312s	
10450/22750 (epoch 22.967), train_loss = 0.97370507, grad/param norm = 1.9643e-01, time/batch = 18.9007s	
10451/22750 (epoch 22.969), train_loss = 0.88834979, grad/param norm = 1.9230e-01, time/batch = 18.4910s	
10452/22750 (epoch 22.971), train_loss = 0.90366058, grad/param norm = 2.0032e-01, time/batch = 17.7622s	
10453/22750 (epoch 22.974), train_loss = 0.94178639, grad/param norm = 2.1521e-01, time/batch = 17.9167s	
10454/22750 (epoch 22.976), train_loss = 0.99889718, grad/param norm = 2.1020e-01, time/batch = 18.0357s	
10455/22750 (epoch 22.978), train_loss = 0.89058999, grad/param norm = 1.9192e-01, time/batch = 16.4852s	
10456/22750 (epoch 22.980), train_loss = 1.11137698, grad/param norm = 2.6010e-01, time/batch = 19.8527s	
10457/22750 (epoch 22.982), train_loss = 0.86931947, grad/param norm = 1.9194e-01, time/batch = 18.9217s	
10458/22750 (epoch 22.985), train_loss = 1.12055450, grad/param norm = 2.1276e-01, time/batch = 18.2561s	
10459/22750 (epoch 22.987), train_loss = 0.76144747, grad/param norm = 1.7882e-01, time/batch = 16.9048s	
10460/22750 (epoch 22.989), train_loss = 0.93062556, grad/param norm = 2.1468e-01, time/batch = 19.4951s	
10461/22750 (epoch 22.991), train_loss = 1.00463258, grad/param norm = 2.1400e-01, time/batch = 18.8961s	
10462/22750 (epoch 22.993), train_loss = 1.03042548, grad/param norm = 2.2937e-01, time/batch = 18.6719s	
10463/22750 (epoch 22.996), train_loss = 0.89535106, grad/param norm = 2.3287e-01, time/batch = 20.0174s	
10464/22750 (epoch 22.998), train_loss = 1.08793909, grad/param norm = 2.1359e-01, time/batch = 19.3556s	
decayed learning rate by a factor 0.97 to 0.0013056725549212	
10465/22750 (epoch 23.000), train_loss = 0.99074492, grad/param norm = 2.0950e-01, time/batch = 19.5096s	
10466/22750 (epoch 23.002), train_loss = 1.12677876, grad/param norm = 2.1360e-01, time/batch = 18.7305s	
10467/22750 (epoch 23.004), train_loss = 0.90006240, grad/param norm = 1.9642e-01, time/batch = 18.4762s	
10468/22750 (epoch 23.007), train_loss = 0.93352078, grad/param norm = 2.2683e-01, time/batch = 18.5848s	
10469/22750 (epoch 23.009), train_loss = 1.11472185, grad/param norm = 2.2218e-01, time/batch = 18.4330s	
10470/22750 (epoch 23.011), train_loss = 1.21260406, grad/param norm = 2.3647e-01, time/batch = 18.9270s	
10471/22750 (epoch 23.013), train_loss = 1.07986594, grad/param norm = 2.0616e-01, time/batch = 17.5964s	
10472/22750 (epoch 23.015), train_loss = 0.98188360, grad/param norm = 2.0738e-01, time/batch = 19.1815s	
10473/22750 (epoch 23.018), train_loss = 1.05459041, grad/param norm = 2.2008e-01, time/batch = 19.7764s	
10474/22750 (epoch 23.020), train_loss = 1.10619954, grad/param norm = 1.8966e-01, time/batch = 18.6055s	
10475/22750 (epoch 23.022), train_loss = 0.97193423, grad/param norm = 1.9416e-01, time/batch = 19.3322s	
10476/22750 (epoch 23.024), train_loss = 0.98092233, grad/param norm = 1.9862e-01, time/batch = 18.4293s	
10477/22750 (epoch 23.026), train_loss = 1.05283362, grad/param norm = 2.2325e-01, time/batch = 17.9194s	
10478/22750 (epoch 23.029), train_loss = 0.80102425, grad/param norm = 2.0175e-01, time/batch = 15.8753s	
10479/22750 (epoch 23.031), train_loss = 1.21580480, grad/param norm = 2.0845e-01, time/batch = 16.8356s	
10480/22750 (epoch 23.033), train_loss = 0.99993049, grad/param norm = 2.2546e-01, time/batch = 17.3135s	
10481/22750 (epoch 23.035), train_loss = 1.01877709, grad/param norm = 2.0818e-01, time/batch = 18.9433s	
10482/22750 (epoch 23.037), train_loss = 1.08768120, grad/param norm = 1.8976e-01, time/batch = 19.7728s	
10483/22750 (epoch 23.040), train_loss = 0.94006115, grad/param norm = 1.9971e-01, time/batch = 19.4559s	
10484/22750 (epoch 23.042), train_loss = 1.01341020, grad/param norm = 2.0610e-01, time/batch = 18.7522s	
10485/22750 (epoch 23.044), train_loss = 0.93548239, grad/param norm = 2.1929e-01, time/batch = 16.7601s	
10486/22750 (epoch 23.046), train_loss = 1.09560810, grad/param norm = 2.4881e-01, time/batch = 18.4274s	
10487/22750 (epoch 23.048), train_loss = 0.97501435, grad/param norm = 1.8555e-01, time/batch = 18.2518s	
10488/22750 (epoch 23.051), train_loss = 1.02095026, grad/param norm = 1.9319e-01, time/batch = 19.1593s	
10489/22750 (epoch 23.053), train_loss = 0.89490449, grad/param norm = 1.7540e-01, time/batch = 19.7316s	
10490/22750 (epoch 23.055), train_loss = 0.88033910, grad/param norm = 1.8470e-01, time/batch = 17.2730s	
10491/22750 (epoch 23.057), train_loss = 1.15094243, grad/param norm = 2.0092e-01, time/batch = 20.0317s	
10492/22750 (epoch 23.059), train_loss = 0.73557923, grad/param norm = 1.7901e-01, time/batch = 19.7049s	
10493/22750 (epoch 23.062), train_loss = 0.84355158, grad/param norm = 1.9471e-01, time/batch = 18.0705s	
10494/22750 (epoch 23.064), train_loss = 1.04143439, grad/param norm = 2.1852e-01, time/batch = 20.2387s	
10495/22750 (epoch 23.066), train_loss = 0.83951302, grad/param norm = 1.7959e-01, time/batch = 18.1714s	
10496/22750 (epoch 23.068), train_loss = 0.88772803, grad/param norm = 1.6672e-01, time/batch = 19.0677s	
10497/22750 (epoch 23.070), train_loss = 0.75105713, grad/param norm = 1.7928e-01, time/batch = 17.8229s	
10498/22750 (epoch 23.073), train_loss = 0.91144136, grad/param norm = 2.0111e-01, time/batch = 21.2424s	
10499/22750 (epoch 23.075), train_loss = 0.94993987, grad/param norm = 1.9005e-01, time/batch = 19.1988s	
10500/22750 (epoch 23.077), train_loss = 0.73138662, grad/param norm = 1.9307e-01, time/batch = 20.2828s	
10501/22750 (epoch 23.079), train_loss = 0.91553008, grad/param norm = 2.0564e-01, time/batch = 20.1643s	
10502/22750 (epoch 23.081), train_loss = 0.93646063, grad/param norm = 2.0999e-01, time/batch = 18.2395s	
10503/22750 (epoch 23.084), train_loss = 0.91290190, grad/param norm = 2.0601e-01, time/batch = 18.9935s	
10504/22750 (epoch 23.086), train_loss = 0.92975035, grad/param norm = 1.7271e-01, time/batch = 18.6384s	
10505/22750 (epoch 23.088), train_loss = 0.87392705, grad/param norm = 1.8835e-01, time/batch = 18.8329s	
10506/22750 (epoch 23.090), train_loss = 0.87855191, grad/param norm = 1.8972e-01, time/batch = 18.4163s	
10507/22750 (epoch 23.092), train_loss = 1.08708034, grad/param norm = 2.0084e-01, time/batch = 20.2754s	
10508/22750 (epoch 23.095), train_loss = 0.84667519, grad/param norm = 1.8703e-01, time/batch = 20.4544s	
10509/22750 (epoch 23.097), train_loss = 0.96145315, grad/param norm = 1.9703e-01, time/batch = 19.0822s	
10510/22750 (epoch 23.099), train_loss = 0.92420770, grad/param norm = 2.0935e-01, time/batch = 17.9081s	
10511/22750 (epoch 23.101), train_loss = 0.82258962, grad/param norm = 1.7728e-01, time/batch = 18.5076s	
10512/22750 (epoch 23.103), train_loss = 0.96729924, grad/param norm = 1.8587e-01, time/batch = 18.8222s	
10513/22750 (epoch 23.105), train_loss = 1.13501137, grad/param norm = 2.3403e-01, time/batch = 19.3187s	
10514/22750 (epoch 23.108), train_loss = 0.92537330, grad/param norm = 1.8920e-01, time/batch = 15.4506s	
10515/22750 (epoch 23.110), train_loss = 1.08821032, grad/param norm = 2.1312e-01, time/batch = 16.7656s	
10516/22750 (epoch 23.112), train_loss = 0.80050031, grad/param norm = 1.7290e-01, time/batch = 19.6936s	
10517/22750 (epoch 23.114), train_loss = 0.73818735, grad/param norm = 1.7960e-01, time/batch = 19.4322s	
10518/22750 (epoch 23.116), train_loss = 0.88247253, grad/param norm = 1.7508e-01, time/batch = 19.0190s	
10519/22750 (epoch 23.119), train_loss = 0.86328786, grad/param norm = 1.8112e-01, time/batch = 18.6634s	
10520/22750 (epoch 23.121), train_loss = 0.98080874, grad/param norm = 2.2168e-01, time/batch = 19.0809s	
10521/22750 (epoch 23.123), train_loss = 0.82937938, grad/param norm = 2.0335e-01, time/batch = 18.9895s	
10522/22750 (epoch 23.125), train_loss = 1.09022081, grad/param norm = 1.8562e-01, time/batch = 19.1638s	
10523/22750 (epoch 23.127), train_loss = 0.91666396, grad/param norm = 2.1264e-01, time/batch = 18.2445s	
10524/22750 (epoch 23.130), train_loss = 0.92327043, grad/param norm = 1.6863e-01, time/batch = 19.2588s	
10525/22750 (epoch 23.132), train_loss = 0.87043507, grad/param norm = 1.9016e-01, time/batch = 35.5680s	
10526/22750 (epoch 23.134), train_loss = 0.91872862, grad/param norm = 1.9797e-01, time/batch = 20.1012s	
10527/22750 (epoch 23.136), train_loss = 0.79364008, grad/param norm = 1.9470e-01, time/batch = 18.4195s	
10528/22750 (epoch 23.138), train_loss = 1.01094102, grad/param norm = 2.0090e-01, time/batch = 16.2195s	
10529/22750 (epoch 23.141), train_loss = 0.96681432, grad/param norm = 1.9268e-01, time/batch = 16.2496s	
10530/22750 (epoch 23.143), train_loss = 0.84429169, grad/param norm = 1.8173e-01, time/batch = 17.5875s	
10531/22750 (epoch 23.145), train_loss = 1.07200441, grad/param norm = 2.0572e-01, time/batch = 19.3977s	
10532/22750 (epoch 23.147), train_loss = 1.13148282, grad/param norm = 2.2215e-01, time/batch = 18.4260s	
10533/22750 (epoch 23.149), train_loss = 0.96510987, grad/param norm = 2.0186e-01, time/batch = 19.2724s	
10534/22750 (epoch 23.152), train_loss = 0.94146466, grad/param norm = 1.8725e-01, time/batch = 20.2752s	
10535/22750 (epoch 23.154), train_loss = 0.81550202, grad/param norm = 1.8460e-01, time/batch = 20.1805s	
10536/22750 (epoch 23.156), train_loss = 0.83928619, grad/param norm = 1.8054e-01, time/batch = 18.5002s	
10537/22750 (epoch 23.158), train_loss = 0.85181947, grad/param norm = 1.8731e-01, time/batch = 16.8276s	
10538/22750 (epoch 23.160), train_loss = 0.99062047, grad/param norm = 2.0840e-01, time/batch = 18.6695s	
10539/22750 (epoch 23.163), train_loss = 1.15844506, grad/param norm = 2.2060e-01, time/batch = 19.2547s	
10540/22750 (epoch 23.165), train_loss = 1.00104644, grad/param norm = 2.0160e-01, time/batch = 16.8985s	
10541/22750 (epoch 23.167), train_loss = 0.92625045, grad/param norm = 2.1568e-01, time/batch = 16.1194s	
10542/22750 (epoch 23.169), train_loss = 0.96143701, grad/param norm = 2.1333e-01, time/batch = 19.1182s	
10543/22750 (epoch 23.171), train_loss = 0.81724766, grad/param norm = 1.9150e-01, time/batch = 19.8564s	
10544/22750 (epoch 23.174), train_loss = 0.77543578, grad/param norm = 1.8801e-01, time/batch = 20.7661s	
10545/22750 (epoch 23.176), train_loss = 0.85490350, grad/param norm = 1.8551e-01, time/batch = 19.2494s	
10546/22750 (epoch 23.178), train_loss = 0.86874321, grad/param norm = 1.9918e-01, time/batch = 18.9117s	
10547/22750 (epoch 23.180), train_loss = 1.06095783, grad/param norm = 2.8574e-01, time/batch = 18.3303s	
10548/22750 (epoch 23.182), train_loss = 1.06309073, grad/param norm = 2.0720e-01, time/batch = 19.6616s	
10549/22750 (epoch 23.185), train_loss = 1.08476536, grad/param norm = 2.0918e-01, time/batch = 18.4949s	
10550/22750 (epoch 23.187), train_loss = 0.84776109, grad/param norm = 2.0372e-01, time/batch = 17.8495s	
10551/22750 (epoch 23.189), train_loss = 0.85165254, grad/param norm = 1.9485e-01, time/batch = 19.7784s	
10552/22750 (epoch 23.191), train_loss = 0.86063394, grad/param norm = 1.7604e-01, time/batch = 19.6966s	
10553/22750 (epoch 23.193), train_loss = 1.00819539, grad/param norm = 1.9201e-01, time/batch = 17.9595s	
10554/22750 (epoch 23.196), train_loss = 0.92228847, grad/param norm = 2.1557e-01, time/batch = 17.8340s	
10555/22750 (epoch 23.198), train_loss = 0.70110072, grad/param norm = 1.6347e-01, time/batch = 20.1579s	
10556/22750 (epoch 23.200), train_loss = 0.94910535, grad/param norm = 2.0164e-01, time/batch = 18.7265s	
10557/22750 (epoch 23.202), train_loss = 1.02219185, grad/param norm = 2.2370e-01, time/batch = 19.1484s	
10558/22750 (epoch 23.204), train_loss = 0.94561567, grad/param norm = 1.8200e-01, time/batch = 18.7415s	
10559/22750 (epoch 23.207), train_loss = 0.92825017, grad/param norm = 1.9661e-01, time/batch = 18.8552s	
10560/22750 (epoch 23.209), train_loss = 0.87235294, grad/param norm = 1.9695e-01, time/batch = 19.6947s	
10561/22750 (epoch 23.211), train_loss = 0.86242805, grad/param norm = 1.9739e-01, time/batch = 20.5310s	
10562/22750 (epoch 23.213), train_loss = 0.74543520, grad/param norm = 1.8161e-01, time/batch = 18.5916s	
10563/22750 (epoch 23.215), train_loss = 0.71603548, grad/param norm = 1.6528e-01, time/batch = 20.4980s	
10564/22750 (epoch 23.218), train_loss = 0.82101827, grad/param norm = 2.1569e-01, time/batch = 18.5760s	
10565/22750 (epoch 23.220), train_loss = 0.78445719, grad/param norm = 1.7735e-01, time/batch = 18.5823s	
10566/22750 (epoch 23.222), train_loss = 0.79257490, grad/param norm = 1.8102e-01, time/batch = 18.9268s	
10567/22750 (epoch 23.224), train_loss = 0.83505451, grad/param norm = 1.8032e-01, time/batch = 19.3923s	
10568/22750 (epoch 23.226), train_loss = 0.97692186, grad/param norm = 2.1777e-01, time/batch = 18.3458s	
10569/22750 (epoch 23.229), train_loss = 0.96005317, grad/param norm = 2.0324e-01, time/batch = 20.3670s	
10570/22750 (epoch 23.231), train_loss = 0.84604108, grad/param norm = 2.0537e-01, time/batch = 20.5413s	
10571/22750 (epoch 23.233), train_loss = 0.77704937, grad/param norm = 1.7742e-01, time/batch = 18.4938s	
10572/22750 (epoch 23.235), train_loss = 0.77442465, grad/param norm = 1.9752e-01, time/batch = 19.0777s	
10573/22750 (epoch 23.237), train_loss = 0.85242839, grad/param norm = 2.0052e-01, time/batch = 17.2635s	
10574/22750 (epoch 23.240), train_loss = 0.90738850, grad/param norm = 1.9235e-01, time/batch = 18.3446s	
10575/22750 (epoch 23.242), train_loss = 1.14937557, grad/param norm = 2.2677e-01, time/batch = 17.0150s	
10576/22750 (epoch 23.244), train_loss = 1.09486938, grad/param norm = 2.1586e-01, time/batch = 18.0736s	
10577/22750 (epoch 23.246), train_loss = 1.11183675, grad/param norm = 2.1148e-01, time/batch = 21.0301s	
10578/22750 (epoch 23.248), train_loss = 0.91627454, grad/param norm = 1.9914e-01, time/batch = 18.5252s	
10579/22750 (epoch 23.251), train_loss = 1.05328341, grad/param norm = 2.0468e-01, time/batch = 19.0281s	
10580/22750 (epoch 23.253), train_loss = 0.97767743, grad/param norm = 2.1347e-01, time/batch = 17.8526s	
10581/22750 (epoch 23.255), train_loss = 0.95454970, grad/param norm = 1.9796e-01, time/batch = 17.2433s	
10582/22750 (epoch 23.257), train_loss = 0.85785778, grad/param norm = 2.0190e-01, time/batch = 17.7557s	
10583/22750 (epoch 23.259), train_loss = 1.07265279, grad/param norm = 2.4534e-01, time/batch = 16.7449s	
10584/22750 (epoch 23.262), train_loss = 0.95444383, grad/param norm = 2.0338e-01, time/batch = 18.4041s	
10585/22750 (epoch 23.264), train_loss = 0.77159327, grad/param norm = 1.9936e-01, time/batch = 18.5604s	
10586/22750 (epoch 23.266), train_loss = 0.92919956, grad/param norm = 2.3455e-01, time/batch = 18.8772s	
10587/22750 (epoch 23.268), train_loss = 1.09260025, grad/param norm = 2.3570e-01, time/batch = 19.1131s	
10588/22750 (epoch 23.270), train_loss = 0.88857530, grad/param norm = 2.4137e-01, time/batch = 17.7881s	
10589/22750 (epoch 23.273), train_loss = 1.23897966, grad/param norm = 2.3999e-01, time/batch = 18.6042s	
10590/22750 (epoch 23.275), train_loss = 1.08088014, grad/param norm = 2.0065e-01, time/batch = 17.6587s	
10591/22750 (epoch 23.277), train_loss = 0.90713157, grad/param norm = 2.2798e-01, time/batch = 18.6482s	
10592/22750 (epoch 23.279), train_loss = 0.80201768, grad/param norm = 1.9784e-01, time/batch = 19.7453s	
10593/22750 (epoch 23.281), train_loss = 1.08611794, grad/param norm = 2.1560e-01, time/batch = 20.0866s	
10594/22750 (epoch 23.284), train_loss = 0.93727798, grad/param norm = 1.8538e-01, time/batch = 17.7508s	
10595/22750 (epoch 23.286), train_loss = 1.05211792, grad/param norm = 2.0690e-01, time/batch = 17.9136s	
10596/22750 (epoch 23.288), train_loss = 1.12378027, grad/param norm = 2.2613e-01, time/batch = 19.1882s	
10597/22750 (epoch 23.290), train_loss = 0.95539076, grad/param norm = 1.8633e-01, time/batch = 17.3623s	
10598/22750 (epoch 23.292), train_loss = 1.01697506, grad/param norm = 2.2389e-01, time/batch = 19.0226s	
10599/22750 (epoch 23.295), train_loss = 1.01121616, grad/param norm = 1.9884e-01, time/batch = 17.6790s	
10600/22750 (epoch 23.297), train_loss = 0.95671698, grad/param norm = 2.1378e-01, time/batch = 18.4210s	
10601/22750 (epoch 23.299), train_loss = 1.06949895, grad/param norm = 2.1736e-01, time/batch = 17.4178s	
10602/22750 (epoch 23.301), train_loss = 0.96580472, grad/param norm = 1.9264e-01, time/batch = 18.9177s	
10603/22750 (epoch 23.303), train_loss = 1.01120867, grad/param norm = 1.9847e-01, time/batch = 18.9247s	
10604/22750 (epoch 23.305), train_loss = 1.18206438, grad/param norm = 2.1880e-01, time/batch = 19.3412s	
10605/22750 (epoch 23.308), train_loss = 1.03638484, grad/param norm = 1.9605e-01, time/batch = 19.7819s	
10606/22750 (epoch 23.310), train_loss = 0.84558614, grad/param norm = 2.0284e-01, time/batch = 19.9311s	
10607/22750 (epoch 23.312), train_loss = 0.98433120, grad/param norm = 2.0338e-01, time/batch = 19.5679s	
10608/22750 (epoch 23.314), train_loss = 0.95570641, grad/param norm = 1.8640e-01, time/batch = 18.8310s	
10609/22750 (epoch 23.316), train_loss = 0.92882403, grad/param norm = 1.9731e-01, time/batch = 17.6631s	
10610/22750 (epoch 23.319), train_loss = 0.96255102, grad/param norm = 2.0076e-01, time/batch = 18.0792s	
10611/22750 (epoch 23.321), train_loss = 0.90132872, grad/param norm = 2.2579e-01, time/batch = 18.7346s	
10612/22750 (epoch 23.323), train_loss = 0.99882898, grad/param norm = 2.2814e-01, time/batch = 18.1774s	
10613/22750 (epoch 23.325), train_loss = 0.83778875, grad/param norm = 2.0690e-01, time/batch = 18.0703s	
10614/22750 (epoch 23.327), train_loss = 0.93365375, grad/param norm = 2.2706e-01, time/batch = 19.7659s	
10615/22750 (epoch 23.330), train_loss = 1.14488077, grad/param norm = 2.1356e-01, time/batch = 20.4501s	
10616/22750 (epoch 23.332), train_loss = 1.14776751, grad/param norm = 2.0664e-01, time/batch = 18.2506s	
10617/22750 (epoch 23.334), train_loss = 0.79840317, grad/param norm = 1.8729e-01, time/batch = 18.9052s	
10618/22750 (epoch 23.336), train_loss = 1.03200644, grad/param norm = 1.9368e-01, time/batch = 18.2500s	
10619/22750 (epoch 23.338), train_loss = 0.93109640, grad/param norm = 2.0430e-01, time/batch = 19.2355s	
10620/22750 (epoch 23.341), train_loss = 0.95128993, grad/param norm = 1.9685e-01, time/batch = 16.4834s	
10621/22750 (epoch 23.343), train_loss = 0.83678358, grad/param norm = 2.0242e-01, time/batch = 17.7417s	
10622/22750 (epoch 23.345), train_loss = 1.03836992, grad/param norm = 2.4136e-01, time/batch = 18.6978s	
10623/22750 (epoch 23.347), train_loss = 1.07614887, grad/param norm = 2.0776e-01, time/batch = 17.6966s	
10624/22750 (epoch 23.349), train_loss = 0.76259242, grad/param norm = 2.0244e-01, time/batch = 19.8536s	
10625/22750 (epoch 23.352), train_loss = 1.06272187, grad/param norm = 2.2715e-01, time/batch = 18.1815s	
10626/22750 (epoch 23.354), train_loss = 1.05882955, grad/param norm = 1.9712e-01, time/batch = 17.2649s	
10627/22750 (epoch 23.356), train_loss = 1.08173860, grad/param norm = 2.0960e-01, time/batch = 16.4449s	
10628/22750 (epoch 23.358), train_loss = 0.95002017, grad/param norm = 2.2614e-01, time/batch = 18.8407s	
10629/22750 (epoch 23.360), train_loss = 1.15940956, grad/param norm = 2.0619e-01, time/batch = 17.0007s	
10630/22750 (epoch 23.363), train_loss = 0.95567992, grad/param norm = 2.1366e-01, time/batch = 18.9101s	
10631/22750 (epoch 23.365), train_loss = 0.78883988, grad/param norm = 2.1632e-01, time/batch = 18.3423s	
10632/22750 (epoch 23.367), train_loss = 0.85297549, grad/param norm = 2.1276e-01, time/batch = 19.6901s	
10633/22750 (epoch 23.369), train_loss = 0.94920261, grad/param norm = 1.9529e-01, time/batch = 17.2775s	
10634/22750 (epoch 23.371), train_loss = 0.93945701, grad/param norm = 1.9597e-01, time/batch = 19.9969s	
10635/22750 (epoch 23.374), train_loss = 0.87777393, grad/param norm = 2.1073e-01, time/batch = 20.1612s	
10636/22750 (epoch 23.376), train_loss = 0.92453618, grad/param norm = 1.9000e-01, time/batch = 17.9838s	
10637/22750 (epoch 23.378), train_loss = 0.96528711, grad/param norm = 2.0694e-01, time/batch = 19.5794s	
10638/22750 (epoch 23.380), train_loss = 1.06978977, grad/param norm = 2.1522e-01, time/batch = 19.4832s	
10639/22750 (epoch 23.382), train_loss = 0.91947257, grad/param norm = 2.0192e-01, time/batch = 17.7595s	
10640/22750 (epoch 23.385), train_loss = 1.03169477, grad/param norm = 1.9032e-01, time/batch = 17.9440s	
10641/22750 (epoch 23.387), train_loss = 0.98323439, grad/param norm = 1.7976e-01, time/batch = 20.1135s	
10642/22750 (epoch 23.389), train_loss = 0.77642628, grad/param norm = 1.9526e-01, time/batch = 19.1799s	
10643/22750 (epoch 23.391), train_loss = 0.60523292, grad/param norm = 1.5433e-01, time/batch = 18.9193s	
10644/22750 (epoch 23.393), train_loss = 0.80450652, grad/param norm = 1.7774e-01, time/batch = 18.5818s	
10645/22750 (epoch 23.396), train_loss = 1.01283570, grad/param norm = 2.0114e-01, time/batch = 18.1610s	
10646/22750 (epoch 23.398), train_loss = 0.93031361, grad/param norm = 1.8396e-01, time/batch = 17.0999s	
10647/22750 (epoch 23.400), train_loss = 0.93880718, grad/param norm = 2.0158e-01, time/batch = 18.7357s	
10648/22750 (epoch 23.402), train_loss = 1.00595166, grad/param norm = 1.9943e-01, time/batch = 17.8031s	
10649/22750 (epoch 23.404), train_loss = 1.09377228, grad/param norm = 2.0431e-01, time/batch = 16.8225s	
10650/22750 (epoch 23.407), train_loss = 1.04717474, grad/param norm = 1.9339e-01, time/batch = 16.6090s	
10651/22750 (epoch 23.409), train_loss = 0.88591593, grad/param norm = 2.0112e-01, time/batch = 18.5271s	
10652/22750 (epoch 23.411), train_loss = 0.91218091, grad/param norm = 1.9091e-01, time/batch = 17.5012s	
10653/22750 (epoch 23.413), train_loss = 0.71544905, grad/param norm = 1.9597e-01, time/batch = 19.4791s	
10654/22750 (epoch 23.415), train_loss = 0.72469315, grad/param norm = 1.6884e-01, time/batch = 17.9995s	
10655/22750 (epoch 23.418), train_loss = 0.88334074, grad/param norm = 2.0314e-01, time/batch = 17.8288s	
10656/22750 (epoch 23.420), train_loss = 1.01585250, grad/param norm = 2.2224e-01, time/batch = 18.6803s	
10657/22750 (epoch 23.422), train_loss = 1.18457827, grad/param norm = 2.4941e-01, time/batch = 19.3260s	
10658/22750 (epoch 23.424), train_loss = 1.15859114, grad/param norm = 2.1199e-01, time/batch = 19.5928s	
10659/22750 (epoch 23.426), train_loss = 1.17084414, grad/param norm = 2.0749e-01, time/batch = 15.4614s	
10660/22750 (epoch 23.429), train_loss = 0.86459424, grad/param norm = 1.9509e-01, time/batch = 15.2234s	
10661/22750 (epoch 23.431), train_loss = 0.77742200, grad/param norm = 1.8116e-01, time/batch = 16.7538s	
10662/22750 (epoch 23.433), train_loss = 0.89944060, grad/param norm = 2.0388e-01, time/batch = 18.9022s	
10663/22750 (epoch 23.435), train_loss = 0.72303299, grad/param norm = 1.7953e-01, time/batch = 19.4304s	
10664/22750 (epoch 23.437), train_loss = 0.62821201, grad/param norm = 1.7397e-01, time/batch = 17.6744s	
10665/22750 (epoch 23.440), train_loss = 0.94680656, grad/param norm = 2.3883e-01, time/batch = 16.5720s	
10666/22750 (epoch 23.442), train_loss = 0.96228186, grad/param norm = 2.0492e-01, time/batch = 16.4142s	
10667/22750 (epoch 23.444), train_loss = 0.92684737, grad/param norm = 2.1928e-01, time/batch = 19.0995s	
10668/22750 (epoch 23.446), train_loss = 0.94304241, grad/param norm = 2.1282e-01, time/batch = 20.1830s	
10669/22750 (epoch 23.448), train_loss = 1.21365604, grad/param norm = 2.2343e-01, time/batch = 19.1672s	
10670/22750 (epoch 23.451), train_loss = 1.15462197, grad/param norm = 2.0472e-01, time/batch = 19.2671s	
10671/22750 (epoch 23.453), train_loss = 1.09822298, grad/param norm = 2.3815e-01, time/batch = 20.2523s	
10672/22750 (epoch 23.455), train_loss = 1.16795425, grad/param norm = 2.1327e-01, time/batch = 18.4982s	
10673/22750 (epoch 23.457), train_loss = 1.07407139, grad/param norm = 4.1587e-01, time/batch = 19.4072s	
10674/22750 (epoch 23.459), train_loss = 1.05103029, grad/param norm = 2.1817e-01, time/batch = 20.4024s	
10675/22750 (epoch 23.462), train_loss = 1.03729537, grad/param norm = 1.8815e-01, time/batch = 16.8353s	
10676/22750 (epoch 23.464), train_loss = 0.79641219, grad/param norm = 2.0816e-01, time/batch = 18.8340s	
10677/22750 (epoch 23.466), train_loss = 1.10339468, grad/param norm = 2.3538e-01, time/batch = 19.1067s	
10678/22750 (epoch 23.468), train_loss = 0.95898388, grad/param norm = 2.0027e-01, time/batch = 18.8539s	
10679/22750 (epoch 23.470), train_loss = 1.09886816, grad/param norm = 2.2223e-01, time/batch = 21.2658s	
10680/22750 (epoch 23.473), train_loss = 0.94880369, grad/param norm = 1.9843e-01, time/batch = 19.6668s	
10681/22750 (epoch 23.475), train_loss = 0.99102167, grad/param norm = 2.2026e-01, time/batch = 17.0952s	
10682/22750 (epoch 23.477), train_loss = 0.84181487, grad/param norm = 1.9671e-01, time/batch = 18.8176s	
10683/22750 (epoch 23.479), train_loss = 0.83999108, grad/param norm = 2.1245e-01, time/batch = 19.0838s	
10684/22750 (epoch 23.481), train_loss = 0.76957435, grad/param norm = 1.6803e-01, time/batch = 18.5586s	
10685/22750 (epoch 23.484), train_loss = 0.68014883, grad/param norm = 1.9496e-01, time/batch = 18.9982s	
10686/22750 (epoch 23.486), train_loss = 0.80225211, grad/param norm = 1.9084e-01, time/batch = 17.5048s	
10687/22750 (epoch 23.488), train_loss = 0.71966516, grad/param norm = 1.9552e-01, time/batch = 18.7036s	
10688/22750 (epoch 23.490), train_loss = 0.93182148, grad/param norm = 1.9662e-01, time/batch = 19.0388s	
10689/22750 (epoch 23.492), train_loss = 1.07261565, grad/param norm = 2.2200e-01, time/batch = 19.7570s	
10690/22750 (epoch 23.495), train_loss = 0.85939000, grad/param norm = 2.0243e-01, time/batch = 18.5923s	
10691/22750 (epoch 23.497), train_loss = 0.92772534, grad/param norm = 2.1913e-01, time/batch = 19.3300s	
10692/22750 (epoch 23.499), train_loss = 0.87006207, grad/param norm = 1.9870e-01, time/batch = 18.5747s	
10693/22750 (epoch 23.501), train_loss = 0.92913277, grad/param norm = 1.8499e-01, time/batch = 18.9999s	
10694/22750 (epoch 23.503), train_loss = 0.94309060, grad/param norm = 2.0172e-01, time/batch = 17.6698s	
10695/22750 (epoch 23.505), train_loss = 0.82770506, grad/param norm = 1.8909e-01, time/batch = 20.6549s	
10696/22750 (epoch 23.508), train_loss = 0.77106760, grad/param norm = 1.8905e-01, time/batch = 19.6114s	
10697/22750 (epoch 23.510), train_loss = 0.79514363, grad/param norm = 1.7857e-01, time/batch = 17.1207s	
10698/22750 (epoch 23.512), train_loss = 0.81611421, grad/param norm = 1.7706e-01, time/batch = 20.2041s	
10699/22750 (epoch 23.514), train_loss = 0.88890980, grad/param norm = 2.0608e-01, time/batch = 19.5829s	
10700/22750 (epoch 23.516), train_loss = 0.87778747, grad/param norm = 1.9843e-01, time/batch = 17.3313s	
10701/22750 (epoch 23.519), train_loss = 1.01079228, grad/param norm = 2.0014e-01, time/batch = 19.4921s	
10702/22750 (epoch 23.521), train_loss = 0.95997393, grad/param norm = 2.3774e-01, time/batch = 18.0944s	
10703/22750 (epoch 23.523), train_loss = 0.88578998, grad/param norm = 2.1398e-01, time/batch = 18.2305s	
10704/22750 (epoch 23.525), train_loss = 1.07484633, grad/param norm = 2.2549e-01, time/batch = 18.9426s	
10705/22750 (epoch 23.527), train_loss = 0.94114579, grad/param norm = 2.1970e-01, time/batch = 19.7876s	
10706/22750 (epoch 23.530), train_loss = 0.85103577, grad/param norm = 2.0463e-01, time/batch = 19.6992s	
10707/22750 (epoch 23.532), train_loss = 0.79338363, grad/param norm = 1.6937e-01, time/batch = 19.6676s	
10708/22750 (epoch 23.534), train_loss = 1.03352128, grad/param norm = 2.1416e-01, time/batch = 20.2487s	
10709/22750 (epoch 23.536), train_loss = 0.97634874, grad/param norm = 1.8275e-01, time/batch = 16.9709s	
10710/22750 (epoch 23.538), train_loss = 0.94543711, grad/param norm = 1.7709e-01, time/batch = 16.8349s	
10711/22750 (epoch 23.541), train_loss = 0.82738029, grad/param norm = 2.0291e-01, time/batch = 16.7596s	
10712/22750 (epoch 23.543), train_loss = 0.82174182, grad/param norm = 1.9481e-01, time/batch = 15.9490s	
10713/22750 (epoch 23.545), train_loss = 1.01820859, grad/param norm = 2.0404e-01, time/batch = 17.0964s	
10714/22750 (epoch 23.547), train_loss = 0.85586388, grad/param norm = 1.8232e-01, time/batch = 18.6286s	
10715/22750 (epoch 23.549), train_loss = 0.88797596, grad/param norm = 1.9274e-01, time/batch = 19.0412s	
10716/22750 (epoch 23.552), train_loss = 0.96906197, grad/param norm = 2.1632e-01, time/batch = 25.4391s	
10717/22750 (epoch 23.554), train_loss = 1.00082232, grad/param norm = 2.0551e-01, time/batch = 31.3535s	
10718/22750 (epoch 23.556), train_loss = 0.97355524, grad/param norm = 2.1383e-01, time/batch = 18.0962s	
10719/22750 (epoch 23.558), train_loss = 1.01572187, grad/param norm = 2.1545e-01, time/batch = 17.1867s	
10720/22750 (epoch 23.560), train_loss = 0.89297970, grad/param norm = 2.1463e-01, time/batch = 17.6762s	
10721/22750 (epoch 23.563), train_loss = 1.06143240, grad/param norm = 2.1517e-01, time/batch = 17.7555s	
10722/22750 (epoch 23.565), train_loss = 0.99322180, grad/param norm = 2.0102e-01, time/batch = 18.1084s	
10723/22750 (epoch 23.567), train_loss = 0.97617221, grad/param norm = 1.9930e-01, time/batch = 20.4455s	
10724/22750 (epoch 23.569), train_loss = 0.91423582, grad/param norm = 1.9361e-01, time/batch = 18.1920s	
10725/22750 (epoch 23.571), train_loss = 0.92877511, grad/param norm = 2.2148e-01, time/batch = 18.1107s	
10726/22750 (epoch 23.574), train_loss = 0.89647809, grad/param norm = 2.0157e-01, time/batch = 18.4352s	
10727/22750 (epoch 23.576), train_loss = 0.88126355, grad/param norm = 1.9997e-01, time/batch = 17.2640s	
10728/22750 (epoch 23.578), train_loss = 0.81627086, grad/param norm = 2.0857e-01, time/batch = 16.7502s	
10729/22750 (epoch 23.580), train_loss = 0.97091526, grad/param norm = 2.1599e-01, time/batch = 17.6760s	
10730/22750 (epoch 23.582), train_loss = 0.85307540, grad/param norm = 1.9405e-01, time/batch = 17.5955s	
10731/22750 (epoch 23.585), train_loss = 0.82092660, grad/param norm = 2.0019e-01, time/batch = 19.4235s	
10732/22750 (epoch 23.587), train_loss = 0.79796322, grad/param norm = 1.7799e-01, time/batch = 17.5936s	
10733/22750 (epoch 23.589), train_loss = 0.75074031, grad/param norm = 1.8092e-01, time/batch = 20.1905s	
10734/22750 (epoch 23.591), train_loss = 0.91675391, grad/param norm = 2.0418e-01, time/batch = 20.2799s	
10735/22750 (epoch 23.593), train_loss = 1.08675769, grad/param norm = 1.9458e-01, time/batch = 19.1673s	
10736/22750 (epoch 23.596), train_loss = 1.07766734, grad/param norm = 2.1027e-01, time/batch = 19.3302s	
10737/22750 (epoch 23.598), train_loss = 1.11079374, grad/param norm = 2.2319e-01, time/batch = 16.1810s	
10738/22750 (epoch 23.600), train_loss = 1.08675462, grad/param norm = 2.1664e-01, time/batch = 17.6722s	
10739/22750 (epoch 23.602), train_loss = 0.86730287, grad/param norm = 1.8457e-01, time/batch = 19.2965s	
10740/22750 (epoch 23.604), train_loss = 0.87040235, grad/param norm = 1.7890e-01, time/batch = 18.0714s	
10741/22750 (epoch 23.607), train_loss = 0.78513532, grad/param norm = 1.5635e-01, time/batch = 19.5612s	
10742/22750 (epoch 23.609), train_loss = 0.73640102, grad/param norm = 1.5914e-01, time/batch = 20.0118s	
10743/22750 (epoch 23.611), train_loss = 0.89247793, grad/param norm = 1.9370e-01, time/batch = 20.6836s	
10744/22750 (epoch 23.613), train_loss = 0.83850558, grad/param norm = 1.7951e-01, time/batch = 19.6025s	
10745/22750 (epoch 23.615), train_loss = 0.88063830, grad/param norm = 1.8359e-01, time/batch = 18.8239s	
10746/22750 (epoch 23.618), train_loss = 0.91694515, grad/param norm = 1.8929e-01, time/batch = 18.1603s	
10747/22750 (epoch 23.620), train_loss = 0.88677149, grad/param norm = 1.7885e-01, time/batch = 18.4932s	
10748/22750 (epoch 23.622), train_loss = 0.75998738, grad/param norm = 1.7605e-01, time/batch = 16.9922s	
10749/22750 (epoch 23.624), train_loss = 0.83960694, grad/param norm = 1.7904e-01, time/batch = 18.4991s	
10750/22750 (epoch 23.626), train_loss = 0.76121371, grad/param norm = 1.7533e-01, time/batch = 17.6864s	
10751/22750 (epoch 23.629), train_loss = 0.87208785, grad/param norm = 1.9421e-01, time/batch = 19.9239s	
10752/22750 (epoch 23.631), train_loss = 0.92423395, grad/param norm = 1.8739e-01, time/batch = 40.9501s	
10753/22750 (epoch 23.633), train_loss = 0.81006156, grad/param norm = 1.8750e-01, time/batch = 31.9685s	
10754/22750 (epoch 23.635), train_loss = 0.92337034, grad/param norm = 1.9980e-01, time/batch = 39.5897s	
10755/22750 (epoch 23.637), train_loss = 0.98871932, grad/param norm = 2.2807e-01, time/batch = 40.4496s	
10756/22750 (epoch 23.640), train_loss = 0.98406764, grad/param norm = 2.0218e-01, time/batch = 34.0400s	
10757/22750 (epoch 23.642), train_loss = 1.05696273, grad/param norm = 2.0423e-01, time/batch = 31.7763s	
10758/22750 (epoch 23.644), train_loss = 0.92169139, grad/param norm = 2.1812e-01, time/batch = 36.1115s	
10759/22750 (epoch 23.646), train_loss = 0.95877122, grad/param norm = 2.6192e-01, time/batch = 37.1432s	
10760/22750 (epoch 23.648), train_loss = 0.96844985, grad/param norm = 2.2318e-01, time/batch = 40.5208s	
10761/22750 (epoch 23.651), train_loss = 0.99257899, grad/param norm = 2.0715e-01, time/batch = 33.1820s	
10762/22750 (epoch 23.653), train_loss = 1.02690959, grad/param norm = 1.9430e-01, time/batch = 19.4380s	
10763/22750 (epoch 23.655), train_loss = 0.94898729, grad/param norm = 1.8498e-01, time/batch = 17.8165s	
10764/22750 (epoch 23.657), train_loss = 1.12060809, grad/param norm = 2.3682e-01, time/batch = 17.2644s	
10765/22750 (epoch 23.659), train_loss = 1.14084861, grad/param norm = 2.2313e-01, time/batch = 18.7423s	
10766/22750 (epoch 23.662), train_loss = 1.13346046, grad/param norm = 2.3194e-01, time/batch = 19.6677s	
10767/22750 (epoch 23.664), train_loss = 0.98043616, grad/param norm = 2.0429e-01, time/batch = 17.2469s	
10768/22750 (epoch 23.666), train_loss = 0.78892284, grad/param norm = 1.8739e-01, time/batch = 17.7583s	
10769/22750 (epoch 23.668), train_loss = 0.95895026, grad/param norm = 1.9838e-01, time/batch = 19.9444s	
10770/22750 (epoch 23.670), train_loss = 0.95467701, grad/param norm = 2.0961e-01, time/batch = 17.7813s	
10771/22750 (epoch 23.673), train_loss = 1.19111710, grad/param norm = 2.9297e-01, time/batch = 19.3648s	
10772/22750 (epoch 23.675), train_loss = 1.30898811, grad/param norm = 2.7040e-01, time/batch = 18.4374s	
10773/22750 (epoch 23.677), train_loss = 1.12548533, grad/param norm = 2.1886e-01, time/batch = 18.1047s	
10774/22750 (epoch 23.679), train_loss = 1.17001539, grad/param norm = 2.4137e-01, time/batch = 18.2582s	
10775/22750 (epoch 23.681), train_loss = 1.10441860, grad/param norm = 2.0309e-01, time/batch = 19.9117s	
10776/22750 (epoch 23.684), train_loss = 1.12156993, grad/param norm = 2.4001e-01, time/batch = 16.7581s	
10777/22750 (epoch 23.686), train_loss = 1.15017770, grad/param norm = 2.4293e-01, time/batch = 18.3366s	
10778/22750 (epoch 23.688), train_loss = 1.09818535, grad/param norm = 2.3164e-01, time/batch = 20.2492s	
10779/22750 (epoch 23.690), train_loss = 1.08254321, grad/param norm = 2.2093e-01, time/batch = 18.2737s	
10780/22750 (epoch 23.692), train_loss = 1.11913906, grad/param norm = 2.1990e-01, time/batch = 16.6183s	
10781/22750 (epoch 23.695), train_loss = 1.00351046, grad/param norm = 2.1507e-01, time/batch = 16.2736s	
10782/22750 (epoch 23.697), train_loss = 0.97953048, grad/param norm = 2.0616e-01, time/batch = 17.6752s	
10783/22750 (epoch 23.699), train_loss = 0.95606435, grad/param norm = 2.1142e-01, time/batch = 18.6642s	
10784/22750 (epoch 23.701), train_loss = 0.82555779, grad/param norm = 1.9740e-01, time/batch = 19.4817s	
10785/22750 (epoch 23.703), train_loss = 0.95049409, grad/param norm = 1.9164e-01, time/batch = 19.6561s	
10786/22750 (epoch 23.705), train_loss = 0.88765277, grad/param norm = 1.8683e-01, time/batch = 17.2508s	
10787/22750 (epoch 23.708), train_loss = 0.97247482, grad/param norm = 1.9559e-01, time/batch = 18.3415s	
10788/22750 (epoch 23.710), train_loss = 0.85664276, grad/param norm = 2.0577e-01, time/batch = 20.1955s	
10789/22750 (epoch 23.712), train_loss = 0.83164595, grad/param norm = 2.0206e-01, time/batch = 18.8575s	
10790/22750 (epoch 23.714), train_loss = 0.78038845, grad/param norm = 1.6587e-01, time/batch = 18.4375s	
10791/22750 (epoch 23.716), train_loss = 0.80830738, grad/param norm = 1.7725e-01, time/batch = 19.8163s	
10792/22750 (epoch 23.719), train_loss = 0.96858927, grad/param norm = 2.4288e-01, time/batch = 17.8099s	
10793/22750 (epoch 23.721), train_loss = 1.03080327, grad/param norm = 2.0046e-01, time/batch = 16.3287s	
10794/22750 (epoch 23.723), train_loss = 1.01914753, grad/param norm = 2.1331e-01, time/batch = 16.9229s	
10795/22750 (epoch 23.725), train_loss = 0.94184863, grad/param norm = 2.2834e-01, time/batch = 16.4208s	
10796/22750 (epoch 23.727), train_loss = 0.89411991, grad/param norm = 2.0570e-01, time/batch = 18.3342s	
10797/22750 (epoch 23.730), train_loss = 0.90155686, grad/param norm = 2.0624e-01, time/batch = 20.7526s	
10798/22750 (epoch 23.732), train_loss = 0.86076109, grad/param norm = 1.8816e-01, time/batch = 19.5268s	
10799/22750 (epoch 23.734), train_loss = 0.75562356, grad/param norm = 1.7270e-01, time/batch = 17.3381s	
10800/22750 (epoch 23.736), train_loss = 0.87845302, grad/param norm = 2.0294e-01, time/batch = 17.4370s	
10801/22750 (epoch 23.738), train_loss = 0.99878461, grad/param norm = 2.1235e-01, time/batch = 20.3934s	
10802/22750 (epoch 23.741), train_loss = 1.05394334, grad/param norm = 2.1975e-01, time/batch = 18.0076s	
10803/22750 (epoch 23.743), train_loss = 0.98778616, grad/param norm = 2.0548e-01, time/batch = 18.7998s	
10804/22750 (epoch 23.745), train_loss = 0.79773611, grad/param norm = 1.7113e-01, time/batch = 20.5596s	
10805/22750 (epoch 23.747), train_loss = 0.89882349, grad/param norm = 1.7837e-01, time/batch = 19.6003s	
10806/22750 (epoch 23.749), train_loss = 1.08910488, grad/param norm = 2.3128e-01, time/batch = 18.9595s	
10807/22750 (epoch 23.752), train_loss = 0.94264729, grad/param norm = 1.9387e-01, time/batch = 20.5175s	
10808/22750 (epoch 23.754), train_loss = 0.96838954, grad/param norm = 2.0500e-01, time/batch = 19.2542s	
10809/22750 (epoch 23.756), train_loss = 0.86177540, grad/param norm = 2.0455e-01, time/batch = 19.0555s	
10810/22750 (epoch 23.758), train_loss = 0.84780148, grad/param norm = 1.9914e-01, time/batch = 18.0779s	
10811/22750 (epoch 23.760), train_loss = 0.89313227, grad/param norm = 2.0141e-01, time/batch = 18.0784s	
10812/22750 (epoch 23.763), train_loss = 0.97138357, grad/param norm = 2.1012e-01, time/batch = 17.4966s	
10813/22750 (epoch 23.765), train_loss = 0.95731163, grad/param norm = 2.2664e-01, time/batch = 16.3111s	
10814/22750 (epoch 23.767), train_loss = 0.97950059, grad/param norm = 2.1982e-01, time/batch = 17.1164s	
10815/22750 (epoch 23.769), train_loss = 1.16135776, grad/param norm = 2.4070e-01, time/batch = 17.4405s	
10816/22750 (epoch 23.771), train_loss = 1.09342840, grad/param norm = 2.3084e-01, time/batch = 20.4340s	
10817/22750 (epoch 23.774), train_loss = 0.93267293, grad/param norm = 2.3237e-01, time/batch = 16.7606s	
10818/22750 (epoch 23.776), train_loss = 1.03546868, grad/param norm = 2.1788e-01, time/batch = 18.3365s	
10819/22750 (epoch 23.778), train_loss = 1.12810516, grad/param norm = 2.3077e-01, time/batch = 17.0615s	
10820/22750 (epoch 23.780), train_loss = 0.96357914, grad/param norm = 2.0397e-01, time/batch = 16.9404s	
10821/22750 (epoch 23.782), train_loss = 1.11336891, grad/param norm = 2.1736e-01, time/batch = 18.9931s	
10822/22750 (epoch 23.785), train_loss = 0.94230939, grad/param norm = 2.0053e-01, time/batch = 19.0588s	
10823/22750 (epoch 23.787), train_loss = 0.82709334, grad/param norm = 2.0186e-01, time/batch = 18.8544s	
10824/22750 (epoch 23.789), train_loss = 0.93278689, grad/param norm = 2.0289e-01, time/batch = 21.1043s	
10825/22750 (epoch 23.791), train_loss = 0.89053943, grad/param norm = 1.9662e-01, time/batch = 19.5955s	
10826/22750 (epoch 23.793), train_loss = 0.87574034, grad/param norm = 2.0928e-01, time/batch = 19.8245s	
10827/22750 (epoch 23.796), train_loss = 0.78389848, grad/param norm = 1.8831e-01, time/batch = 18.4919s	
10828/22750 (epoch 23.798), train_loss = 0.84026351, grad/param norm = 1.8914e-01, time/batch = 18.2367s	
10829/22750 (epoch 23.800), train_loss = 0.85680441, grad/param norm = 1.9850e-01, time/batch = 17.9300s	
10830/22750 (epoch 23.802), train_loss = 0.79532193, grad/param norm = 2.2400e-01, time/batch = 20.5629s	
10831/22750 (epoch 23.804), train_loss = 1.06068686, grad/param norm = 2.0365e-01, time/batch = 18.9160s	
10832/22750 (epoch 23.807), train_loss = 1.01605661, grad/param norm = 2.0886e-01, time/batch = 20.0192s	
10833/22750 (epoch 23.809), train_loss = 1.07529731, grad/param norm = 2.1549e-01, time/batch = 18.1861s	
10834/22750 (epoch 23.811), train_loss = 0.93459044, grad/param norm = 2.0406e-01, time/batch = 18.4285s	
10835/22750 (epoch 23.813), train_loss = 0.98649550, grad/param norm = 1.9254e-01, time/batch = 19.8146s	
10836/22750 (epoch 23.815), train_loss = 1.10607880, grad/param norm = 2.0832e-01, time/batch = 18.6435s	
10837/22750 (epoch 23.818), train_loss = 1.06337445, grad/param norm = 2.0073e-01, time/batch = 16.2929s	
10838/22750 (epoch 23.820), train_loss = 1.20299552, grad/param norm = 2.0500e-01, time/batch = 17.9944s	
10839/22750 (epoch 23.822), train_loss = 1.00398145, grad/param norm = 2.0673e-01, time/batch = 17.4329s	
10840/22750 (epoch 23.824), train_loss = 0.85947452, grad/param norm = 1.8958e-01, time/batch = 18.4094s	
10841/22750 (epoch 23.826), train_loss = 0.93104075, grad/param norm = 1.7417e-01, time/batch = 19.1887s	
10842/22750 (epoch 23.829), train_loss = 1.08345234, grad/param norm = 2.0164e-01, time/batch = 18.4496s	
10843/22750 (epoch 23.831), train_loss = 1.06213233, grad/param norm = 2.1673e-01, time/batch = 18.5111s	
10844/22750 (epoch 23.833), train_loss = 0.98255840, grad/param norm = 2.0563e-01, time/batch = 17.7563s	
10845/22750 (epoch 23.835), train_loss = 0.88714599, grad/param norm = 1.9546e-01, time/batch = 18.7251s	
10846/22750 (epoch 23.837), train_loss = 0.92522082, grad/param norm = 1.9298e-01, time/batch = 18.9197s	
10847/22750 (epoch 23.840), train_loss = 0.83435923, grad/param norm = 1.7833e-01, time/batch = 18.3378s	
10848/22750 (epoch 23.842), train_loss = 0.88466269, grad/param norm = 1.9056e-01, time/batch = 19.5716s	
10849/22750 (epoch 23.844), train_loss = 1.01682940, grad/param norm = 2.2833e-01, time/batch = 20.8570s	
10850/22750 (epoch 23.846), train_loss = 0.96902550, grad/param norm = 1.9198e-01, time/batch = 19.5240s	
10851/22750 (epoch 23.848), train_loss = 0.87172048, grad/param norm = 1.7225e-01, time/batch = 4.0812s	
10852/22750 (epoch 23.851), train_loss = 0.84845801, grad/param norm = 1.9273e-01, time/batch = 0.7013s	
10853/22750 (epoch 23.853), train_loss = 1.01497075, grad/param norm = 2.0704e-01, time/batch = 0.6976s	
10854/22750 (epoch 23.855), train_loss = 0.86055255, grad/param norm = 2.1196e-01, time/batch = 0.7183s	
10855/22750 (epoch 23.857), train_loss = 0.98145540, grad/param norm = 1.9193e-01, time/batch = 0.7190s	
10856/22750 (epoch 23.859), train_loss = 1.02682070, grad/param norm = 2.4739e-01, time/batch = 0.7208s	
10857/22750 (epoch 23.862), train_loss = 1.13304320, grad/param norm = 2.3013e-01, time/batch = 0.7083s	
10858/22750 (epoch 23.864), train_loss = 0.94278583, grad/param norm = 2.0558e-01, time/batch = 0.9480s	
10859/22750 (epoch 23.866), train_loss = 0.99359401, grad/param norm = 1.8215e-01, time/batch = 1.0242s	
10860/22750 (epoch 23.868), train_loss = 0.87043332, grad/param norm = 1.9171e-01, time/batch = 1.0350s	
10861/22750 (epoch 23.870), train_loss = 0.79019746, grad/param norm = 1.8170e-01, time/batch = 1.0276s	
10862/22750 (epoch 23.873), train_loss = 0.90825474, grad/param norm = 1.8614e-01, time/batch = 1.0213s	
10863/22750 (epoch 23.875), train_loss = 1.02540625, grad/param norm = 1.9832e-01, time/batch = 1.8701s	
10864/22750 (epoch 23.877), train_loss = 0.85622667, grad/param norm = 1.9327e-01, time/batch = 1.9205s	
10865/22750 (epoch 23.879), train_loss = 1.08496534, grad/param norm = 2.1095e-01, time/batch = 7.7840s	
10866/22750 (epoch 23.881), train_loss = 1.00588787, grad/param norm = 1.9712e-01, time/batch = 19.1645s	
10867/22750 (epoch 23.884), train_loss = 0.88984851, grad/param norm = 2.0764e-01, time/batch = 17.9198s	
10868/22750 (epoch 23.886), train_loss = 1.02023475, grad/param norm = 2.1079e-01, time/batch = 16.6845s	
10869/22750 (epoch 23.888), train_loss = 1.02893718, grad/param norm = 1.8725e-01, time/batch = 19.0964s	
10870/22750 (epoch 23.890), train_loss = 1.03958824, grad/param norm = 2.1285e-01, time/batch = 18.8325s	
10871/22750 (epoch 23.892), train_loss = 1.26546998, grad/param norm = 2.3077e-01, time/batch = 19.8291s	
10872/22750 (epoch 23.895), train_loss = 0.96053499, grad/param norm = 1.9307e-01, time/batch = 20.0264s	
10873/22750 (epoch 23.897), train_loss = 1.05083460, grad/param norm = 2.1576e-01, time/batch = 18.5307s	
10874/22750 (epoch 23.899), train_loss = 1.01922039, grad/param norm = 2.0322e-01, time/batch = 18.6749s	
10875/22750 (epoch 23.901), train_loss = 1.09604258, grad/param norm = 2.3134e-01, time/batch = 18.7540s	
10876/22750 (epoch 23.903), train_loss = 0.94292627, grad/param norm = 2.0089e-01, time/batch = 18.5858s	
10877/22750 (epoch 23.905), train_loss = 1.04167876, grad/param norm = 2.1463e-01, time/batch = 16.4924s	
10878/22750 (epoch 23.908), train_loss = 0.88181618, grad/param norm = 2.0353e-01, time/batch = 20.0940s	
10879/22750 (epoch 23.910), train_loss = 0.76173412, grad/param norm = 1.9856e-01, time/batch = 18.0118s	
10880/22750 (epoch 23.912), train_loss = 0.90956193, grad/param norm = 1.8730e-01, time/batch = 17.4503s	
10881/22750 (epoch 23.914), train_loss = 0.95644783, grad/param norm = 1.9713e-01, time/batch = 19.6627s	
10882/22750 (epoch 23.916), train_loss = 0.79090138, grad/param norm = 1.9785e-01, time/batch = 19.1747s	
10883/22750 (epoch 23.919), train_loss = 0.93261892, grad/param norm = 2.2613e-01, time/batch = 19.0948s	
10884/22750 (epoch 23.921), train_loss = 0.72885500, grad/param norm = 1.7633e-01, time/batch = 19.8350s	
10885/22750 (epoch 23.923), train_loss = 0.84472850, grad/param norm = 1.8293e-01, time/batch = 19.4237s	
10886/22750 (epoch 23.925), train_loss = 0.91037609, grad/param norm = 1.9268e-01, time/batch = 18.9992s	
10887/22750 (epoch 23.927), train_loss = 0.74580664, grad/param norm = 2.0240e-01, time/batch = 18.5874s	
10888/22750 (epoch 23.930), train_loss = 0.74481007, grad/param norm = 1.7110e-01, time/batch = 19.9911s	
10889/22750 (epoch 23.932), train_loss = 0.95908188, grad/param norm = 2.2553e-01, time/batch = 18.7778s	
10890/22750 (epoch 23.934), train_loss = 0.74918307, grad/param norm = 1.6621e-01, time/batch = 19.9349s	
10891/22750 (epoch 23.936), train_loss = 1.04133533, grad/param norm = 1.9821e-01, time/batch = 18.0494s	
10892/22750 (epoch 23.938), train_loss = 1.03468669, grad/param norm = 1.8091e-01, time/batch = 18.6655s	
10893/22750 (epoch 23.941), train_loss = 1.11266581, grad/param norm = 2.1778e-01, time/batch = 16.8274s	
10894/22750 (epoch 23.943), train_loss = 0.95402320, grad/param norm = 2.0817e-01, time/batch = 18.8168s	
10895/22750 (epoch 23.945), train_loss = 0.96848752, grad/param norm = 2.2354e-01, time/batch = 17.4744s	
10896/22750 (epoch 23.947), train_loss = 0.90677506, grad/param norm = 2.2620e-01, time/batch = 16.2666s	
10897/22750 (epoch 23.949), train_loss = 0.85026035, grad/param norm = 1.8724e-01, time/batch = 17.1664s	
10898/22750 (epoch 23.952), train_loss = 0.87055432, grad/param norm = 1.8735e-01, time/batch = 17.8685s	
10899/22750 (epoch 23.954), train_loss = 0.83920366, grad/param norm = 1.8164e-01, time/batch = 18.3428s	
10900/22750 (epoch 23.956), train_loss = 0.96207608, grad/param norm = 2.1033e-01, time/batch = 20.2773s	
10901/22750 (epoch 23.958), train_loss = 0.88737532, grad/param norm = 1.7560e-01, time/batch = 18.0337s	
10902/22750 (epoch 23.960), train_loss = 0.83479525, grad/param norm = 1.9587e-01, time/batch = 17.2629s	
10903/22750 (epoch 23.963), train_loss = 1.00056448, grad/param norm = 2.0608e-01, time/batch = 18.0053s	
10904/22750 (epoch 23.965), train_loss = 1.03311817, grad/param norm = 2.0714e-01, time/batch = 17.2733s	
10905/22750 (epoch 23.967), train_loss = 0.97054882, grad/param norm = 2.0524e-01, time/batch = 16.7572s	
10906/22750 (epoch 23.969), train_loss = 0.88019029, grad/param norm = 2.1191e-01, time/batch = 17.8561s	
10907/22750 (epoch 23.971), train_loss = 0.88349446, grad/param norm = 2.0129e-01, time/batch = 18.5957s	
10908/22750 (epoch 23.974), train_loss = 0.91680136, grad/param norm = 2.0879e-01, time/batch = 19.2251s	
10909/22750 (epoch 23.976), train_loss = 0.96359505, grad/param norm = 1.9730e-01, time/batch = 19.0321s	
10910/22750 (epoch 23.978), train_loss = 0.87802588, grad/param norm = 2.0355e-01, time/batch = 19.9418s	
10911/22750 (epoch 23.980), train_loss = 1.07211975, grad/param norm = 2.3017e-01, time/batch = 20.8979s	
10912/22750 (epoch 23.982), train_loss = 0.86041904, grad/param norm = 1.9380e-01, time/batch = 21.1138s	
10913/22750 (epoch 23.985), train_loss = 1.08662993, grad/param norm = 2.2721e-01, time/batch = 34.0400s	
10914/22750 (epoch 23.987), train_loss = 0.75590994, grad/param norm = 1.8661e-01, time/batch = 18.8275s	
10915/22750 (epoch 23.989), train_loss = 0.91543566, grad/param norm = 2.2465e-01, time/batch = 16.2408s	
10916/22750 (epoch 23.991), train_loss = 0.97708946, grad/param norm = 1.9909e-01, time/batch = 18.0819s	
10917/22750 (epoch 23.993), train_loss = 1.00271999, grad/param norm = 2.3379e-01, time/batch = 19.0118s	
10918/22750 (epoch 23.996), train_loss = 0.86671337, grad/param norm = 2.1928e-01, time/batch = 17.2470s	
10919/22750 (epoch 23.998), train_loss = 1.06779908, grad/param norm = 2.1994e-01, time/batch = 18.5610s	
decayed learning rate by a factor 0.97 to 0.0012665023782736	
10920/22750 (epoch 24.000), train_loss = 0.95990636, grad/param norm = 2.0377e-01, time/batch = 17.5048s	
10921/22750 (epoch 24.002), train_loss = 1.10229633, grad/param norm = 2.1355e-01, time/batch = 18.4892s	
10922/22750 (epoch 24.004), train_loss = 0.88771774, grad/param norm = 1.9280e-01, time/batch = 16.8562s	
10923/22750 (epoch 24.007), train_loss = 0.91676060, grad/param norm = 2.1586e-01, time/batch = 16.7520s	
10924/22750 (epoch 24.009), train_loss = 1.10790537, grad/param norm = 2.2424e-01, time/batch = 18.0793s	
10925/22750 (epoch 24.011), train_loss = 1.20739574, grad/param norm = 2.4516e-01, time/batch = 18.7757s	
10926/22750 (epoch 24.013), train_loss = 1.06350838, grad/param norm = 2.0439e-01, time/batch = 19.8562s	
10927/22750 (epoch 24.015), train_loss = 0.96783688, grad/param norm = 2.0514e-01, time/batch = 19.0312s	
10928/22750 (epoch 24.018), train_loss = 1.03321415, grad/param norm = 2.1333e-01, time/batch = 17.4942s	
10929/22750 (epoch 24.020), train_loss = 1.08723734, grad/param norm = 2.0458e-01, time/batch = 18.3172s	
10930/22750 (epoch 24.022), train_loss = 0.95943396, grad/param norm = 2.0173e-01, time/batch = 18.7494s	
10931/22750 (epoch 24.024), train_loss = 0.97577749, grad/param norm = 2.1668e-01, time/batch = 18.4932s	
10932/22750 (epoch 24.026), train_loss = 1.02209097, grad/param norm = 2.2155e-01, time/batch = 19.6540s	
10933/22750 (epoch 24.029), train_loss = 0.79432566, grad/param norm = 1.8928e-01, time/batch = 18.8382s	
10934/22750 (epoch 24.031), train_loss = 1.20209346, grad/param norm = 2.0784e-01, time/batch = 17.9405s	
10935/22750 (epoch 24.033), train_loss = 0.97718458, grad/param norm = 2.2146e-01, time/batch = 19.0192s	
10936/22750 (epoch 24.035), train_loss = 0.99772069, grad/param norm = 1.8826e-01, time/batch = 17.5869s	
10937/22750 (epoch 24.037), train_loss = 1.05760718, grad/param norm = 1.9022e-01, time/batch = 16.7574s	
10938/22750 (epoch 24.040), train_loss = 0.92096918, grad/param norm = 1.9890e-01, time/batch = 16.8518s	
10939/22750 (epoch 24.042), train_loss = 0.99903253, grad/param norm = 2.0940e-01, time/batch = 16.9316s	
10940/22750 (epoch 24.044), train_loss = 0.92568192, grad/param norm = 2.0375e-01, time/batch = 19.0817s	
10941/22750 (epoch 24.046), train_loss = 1.07845599, grad/param norm = 2.1889e-01, time/batch = 17.5061s	
10942/22750 (epoch 24.048), train_loss = 0.95193821, grad/param norm = 1.8679e-01, time/batch = 20.0035s	
10943/22750 (epoch 24.051), train_loss = 0.99834318, grad/param norm = 2.0125e-01, time/batch = 18.7748s	
10944/22750 (epoch 24.053), train_loss = 0.87295343, grad/param norm = 1.6444e-01, time/batch = 17.3538s	
10945/22750 (epoch 24.055), train_loss = 0.85299511, grad/param norm = 1.9558e-01, time/batch = 18.2636s	
10946/22750 (epoch 24.057), train_loss = 1.13272898, grad/param norm = 2.0887e-01, time/batch = 16.6525s	
10947/22750 (epoch 24.059), train_loss = 0.71935131, grad/param norm = 1.7320e-01, time/batch = 16.4992s	
10948/22750 (epoch 24.062), train_loss = 0.82385126, grad/param norm = 1.8970e-01, time/batch = 17.0826s	
10949/22750 (epoch 24.064), train_loss = 1.02312257, grad/param norm = 2.1881e-01, time/batch = 18.9328s	
10950/22750 (epoch 24.066), train_loss = 0.82271988, grad/param norm = 1.6734e-01, time/batch = 19.0883s	
10951/22750 (epoch 24.068), train_loss = 0.87379901, grad/param norm = 1.8010e-01, time/batch = 17.2766s	
10952/22750 (epoch 24.070), train_loss = 0.74232396, grad/param norm = 1.7961e-01, time/batch = 19.1109s	
10953/22750 (epoch 24.073), train_loss = 0.88586916, grad/param norm = 2.0150e-01, time/batch = 18.2502s	
10954/22750 (epoch 24.075), train_loss = 0.92465850, grad/param norm = 1.7658e-01, time/batch = 16.6473s	
10955/22750 (epoch 24.077), train_loss = 0.71707374, grad/param norm = 2.0639e-01, time/batch = 17.5860s	
10956/22750 (epoch 24.079), train_loss = 0.92085406, grad/param norm = 2.2840e-01, time/batch = 15.9342s	
10957/22750 (epoch 24.081), train_loss = 0.92038055, grad/param norm = 2.0840e-01, time/batch = 16.0265s	
10958/22750 (epoch 24.084), train_loss = 0.89842906, grad/param norm = 1.9443e-01, time/batch = 16.0285s	
10959/22750 (epoch 24.086), train_loss = 0.91113677, grad/param norm = 1.7326e-01, time/batch = 16.8527s	
10960/22750 (epoch 24.088), train_loss = 0.85951906, grad/param norm = 1.9133e-01, time/batch = 16.4258s	
10961/22750 (epoch 24.090), train_loss = 0.87136080, grad/param norm = 1.9592e-01, time/batch = 16.4514s	
10962/22750 (epoch 24.092), train_loss = 1.04252762, grad/param norm = 1.8636e-01, time/batch = 18.0199s	
10963/22750 (epoch 24.095), train_loss = 0.84696719, grad/param norm = 1.9883e-01, time/batch = 18.1215s	
10964/22750 (epoch 24.097), train_loss = 0.93583574, grad/param norm = 1.9599e-01, time/batch = 18.2736s	
10965/22750 (epoch 24.099), train_loss = 0.89039717, grad/param norm = 2.0178e-01, time/batch = 17.9171s	
10966/22750 (epoch 24.101), train_loss = 0.80035282, grad/param norm = 1.7554e-01, time/batch = 18.6660s	
10967/22750 (epoch 24.103), train_loss = 0.95824309, grad/param norm = 2.0735e-01, time/batch = 16.8612s	
10968/22750 (epoch 24.105), train_loss = 1.09654955, grad/param norm = 2.3506e-01, time/batch = 18.2487s	
10969/22750 (epoch 24.108), train_loss = 0.90585918, grad/param norm = 1.8895e-01, time/batch = 16.9145s	
10970/22750 (epoch 24.110), train_loss = 1.05790678, grad/param norm = 2.0400e-01, time/batch = 17.8517s	
10971/22750 (epoch 24.112), train_loss = 0.78247185, grad/param norm = 1.6948e-01, time/batch = 18.0968s	
10972/22750 (epoch 24.114), train_loss = 0.73242121, grad/param norm = 1.8676e-01, time/batch = 17.8747s	
10973/22750 (epoch 24.116), train_loss = 0.86589742, grad/param norm = 1.7872e-01, time/batch = 17.9510s	
10974/22750 (epoch 24.119), train_loss = 0.85655403, grad/param norm = 1.7674e-01, time/batch = 17.8321s	
10975/22750 (epoch 24.121), train_loss = 0.95550668, grad/param norm = 2.3832e-01, time/batch = 16.7481s	
10976/22750 (epoch 24.123), train_loss = 0.81616093, grad/param norm = 1.9096e-01, time/batch = 17.4088s	
10977/22750 (epoch 24.125), train_loss = 1.07870697, grad/param norm = 1.8542e-01, time/batch = 17.2637s	
10978/22750 (epoch 24.127), train_loss = 0.89249637, grad/param norm = 2.0034e-01, time/batch = 16.9846s	
10979/22750 (epoch 24.130), train_loss = 0.91777244, grad/param norm = 1.7315e-01, time/batch = 17.4088s	
10980/22750 (epoch 24.132), train_loss = 0.83988229, grad/param norm = 1.8529e-01, time/batch = 20.0284s	
10981/22750 (epoch 24.134), train_loss = 0.89967326, grad/param norm = 1.9426e-01, time/batch = 17.2028s	
10982/22750 (epoch 24.136), train_loss = 0.78327026, grad/param norm = 1.9596e-01, time/batch = 16.5634s	
10983/22750 (epoch 24.138), train_loss = 0.99512933, grad/param norm = 2.0382e-01, time/batch = 16.7652s	
10984/22750 (epoch 24.141), train_loss = 0.95340373, grad/param norm = 2.0155e-01, time/batch = 16.2674s	
10985/22750 (epoch 24.143), train_loss = 0.82553225, grad/param norm = 1.8121e-01, time/batch = 17.5061s	
10986/22750 (epoch 24.145), train_loss = 1.04218138, grad/param norm = 2.0657e-01, time/batch = 17.5967s	
10987/22750 (epoch 24.147), train_loss = 1.11217385, grad/param norm = 2.3764e-01, time/batch = 17.4275s	
10988/22750 (epoch 24.149), train_loss = 0.92777560, grad/param norm = 1.8947e-01, time/batch = 17.3297s	
10989/22750 (epoch 24.152), train_loss = 0.92400146, grad/param norm = 1.9297e-01, time/batch = 17.3486s	
10990/22750 (epoch 24.154), train_loss = 0.81500236, grad/param norm = 1.9501e-01, time/batch = 18.6969s	
10991/22750 (epoch 24.156), train_loss = 0.81633659, grad/param norm = 1.8389e-01, time/batch = 18.0929s	
10992/22750 (epoch 24.158), train_loss = 0.83528245, grad/param norm = 2.0406e-01, time/batch = 17.8597s	
10993/22750 (epoch 24.160), train_loss = 0.95593988, grad/param norm = 2.0169e-01, time/batch = 16.9532s	
10994/22750 (epoch 24.163), train_loss = 1.14269115, grad/param norm = 2.1972e-01, time/batch = 17.6798s	
10995/22750 (epoch 24.165), train_loss = 0.97743804, grad/param norm = 2.0219e-01, time/batch = 17.0033s	
10996/22750 (epoch 24.167), train_loss = 0.91135986, grad/param norm = 2.1277e-01, time/batch = 18.0851s	
10997/22750 (epoch 24.169), train_loss = 0.94155833, grad/param norm = 2.1649e-01, time/batch = 18.5879s	
10998/22750 (epoch 24.171), train_loss = 0.80442125, grad/param norm = 1.9293e-01, time/batch = 17.2414s	
10999/22750 (epoch 24.174), train_loss = 0.76234114, grad/param norm = 1.8859e-01, time/batch = 17.4304s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_wakata_epoch24.18_1.5643.t7	
11000/22750 (epoch 24.176), train_loss = 0.82463413, grad/param norm = 1.8649e-01, time/batch = 18.8630s	
11001/22750 (epoch 24.178), train_loss = 1.42049006, grad/param norm = 2.4647e-01, time/batch = 16.8254s	
11002/22750 (epoch 24.180), train_loss = 1.03300827, grad/param norm = 2.6130e-01, time/batch = 18.1749s	
11003/22750 (epoch 24.182), train_loss = 1.03732150, grad/param norm = 2.1590e-01, time/batch = 19.2849s	
11004/22750 (epoch 24.185), train_loss = 1.07563454, grad/param norm = 2.1504e-01, time/batch = 20.1166s	
11005/22750 (epoch 24.187), train_loss = 0.84155741, grad/param norm = 2.0295e-01, time/batch = 17.0445s	
11006/22750 (epoch 24.189), train_loss = 0.84343103, grad/param norm = 2.0440e-01, time/batch = 16.7503s	
11007/22750 (epoch 24.191), train_loss = 0.84396607, grad/param norm = 1.7580e-01, time/batch = 17.2367s	
11008/22750 (epoch 24.193), train_loss = 0.99205786, grad/param norm = 1.9712e-01, time/batch = 17.5882s	
11009/22750 (epoch 24.196), train_loss = 0.89097071, grad/param norm = 2.0037e-01, time/batch = 17.6639s	
11010/22750 (epoch 24.198), train_loss = 0.68084845, grad/param norm = 1.6215e-01, time/batch = 17.0780s	
11011/22750 (epoch 24.200), train_loss = 0.92723330, grad/param norm = 1.9265e-01, time/batch = 17.2428s	
11012/22750 (epoch 24.202), train_loss = 1.00673633, grad/param norm = 2.3355e-01, time/batch = 17.8466s	
11013/22750 (epoch 24.204), train_loss = 0.92415737, grad/param norm = 1.7767e-01, time/batch = 16.8881s	
11014/22750 (epoch 24.207), train_loss = 0.90556933, grad/param norm = 1.9567e-01, time/batch = 16.5395s	
11015/22750 (epoch 24.209), train_loss = 0.86342520, grad/param norm = 2.0329e-01, time/batch = 17.0897s	
11016/22750 (epoch 24.211), train_loss = 0.83884057, grad/param norm = 2.0059e-01, time/batch = 16.7504s	
11017/22750 (epoch 24.213), train_loss = 0.72687977, grad/param norm = 1.8133e-01, time/batch = 16.5885s	
11018/22750 (epoch 24.215), train_loss = 0.70531059, grad/param norm = 1.7079e-01, time/batch = 18.4236s	
11019/22750 (epoch 24.218), train_loss = 0.79762349, grad/param norm = 2.1380e-01, time/batch = 17.0905s	
11020/22750 (epoch 24.220), train_loss = 0.76656231, grad/param norm = 1.7353e-01, time/batch = 16.8501s	
11021/22750 (epoch 24.222), train_loss = 0.77664854, grad/param norm = 1.8435e-01, time/batch = 17.5976s	
11022/22750 (epoch 24.224), train_loss = 0.82279785, grad/param norm = 1.8786e-01, time/batch = 18.1111s	
11023/22750 (epoch 24.226), train_loss = 0.94598103, grad/param norm = 2.1537e-01, time/batch = 17.4336s	
11024/22750 (epoch 24.229), train_loss = 0.94402668, grad/param norm = 2.2785e-01, time/batch = 19.2713s	
11025/22750 (epoch 24.231), train_loss = 0.83850519, grad/param norm = 1.9689e-01, time/batch = 17.0061s	
11026/22750 (epoch 24.233), train_loss = 0.75098704, grad/param norm = 1.8316e-01, time/batch = 18.3358s	
11027/22750 (epoch 24.235), train_loss = 0.73891465, grad/param norm = 1.9073e-01, time/batch = 17.0945s	
11028/22750 (epoch 24.237), train_loss = 0.83304577, grad/param norm = 2.2884e-01, time/batch = 17.3321s	
11029/22750 (epoch 24.240), train_loss = 0.88535356, grad/param norm = 1.8368e-01, time/batch = 17.3488s	
11030/22750 (epoch 24.242), train_loss = 1.12529426, grad/param norm = 2.2635e-01, time/batch = 16.8405s	
11031/22750 (epoch 24.244), train_loss = 1.08068459, grad/param norm = 2.2589e-01, time/batch = 17.9323s	
11032/22750 (epoch 24.246), train_loss = 1.09618132, grad/param norm = 2.2751e-01, time/batch = 17.8663s	
11033/22750 (epoch 24.248), train_loss = 0.89608891, grad/param norm = 1.9903e-01, time/batch = 18.3604s	
11034/22750 (epoch 24.251), train_loss = 1.02165061, grad/param norm = 2.0806e-01, time/batch = 17.2851s	
11035/22750 (epoch 24.253), train_loss = 0.97069973, grad/param norm = 2.2924e-01, time/batch = 17.5871s	
11036/22750 (epoch 24.255), train_loss = 0.93055665, grad/param norm = 1.9298e-01, time/batch = 17.2704s	
11037/22750 (epoch 24.257), train_loss = 0.84581212, grad/param norm = 2.0767e-01, time/batch = 17.0878s	
11038/22750 (epoch 24.259), train_loss = 1.05817049, grad/param norm = 2.5757e-01, time/batch = 17.6673s	
11039/22750 (epoch 24.262), train_loss = 0.93509907, grad/param norm = 2.1128e-01, time/batch = 18.6627s	
11040/22750 (epoch 24.264), train_loss = 0.76459745, grad/param norm = 2.1373e-01, time/batch = 17.5151s	
11041/22750 (epoch 24.266), train_loss = 0.92768873, grad/param norm = 2.3822e-01, time/batch = 17.1862s	
11042/22750 (epoch 24.268), train_loss = 1.07726162, grad/param norm = 2.3445e-01, time/batch = 17.3347s	
11043/22750 (epoch 24.270), train_loss = 0.85802926, grad/param norm = 2.2113e-01, time/batch = 20.3531s	
11044/22750 (epoch 24.273), train_loss = 1.21119936, grad/param norm = 2.3515e-01, time/batch = 19.4843s	
11045/22750 (epoch 24.275), train_loss = 1.06381958, grad/param norm = 2.0239e-01, time/batch = 18.5795s	
11046/22750 (epoch 24.277), train_loss = 0.87843485, grad/param norm = 2.2184e-01, time/batch = 17.3389s	
11047/22750 (epoch 24.279), train_loss = 0.79300524, grad/param norm = 1.9324e-01, time/batch = 16.7381s	
11048/22750 (epoch 24.281), train_loss = 1.06932950, grad/param norm = 2.1595e-01, time/batch = 17.3436s	
11049/22750 (epoch 24.284), train_loss = 0.91929903, grad/param norm = 1.8756e-01, time/batch = 17.6576s	
11050/22750 (epoch 24.286), train_loss = 1.01809807, grad/param norm = 2.0053e-01, time/batch = 18.5029s	
11051/22750 (epoch 24.288), train_loss = 1.10707463, grad/param norm = 2.2466e-01, time/batch = 18.5302s	
11052/22750 (epoch 24.290), train_loss = 0.94172639, grad/param norm = 1.9208e-01, time/batch = 19.1897s	
11053/22750 (epoch 24.292), train_loss = 0.99717693, grad/param norm = 2.3382e-01, time/batch = 18.6719s	
11054/22750 (epoch 24.295), train_loss = 1.00835388, grad/param norm = 2.1676e-01, time/batch = 19.9869s	
11055/22750 (epoch 24.297), train_loss = 0.92798554, grad/param norm = 2.1291e-01, time/batch = 18.5009s	
11056/22750 (epoch 24.299), train_loss = 1.04364228, grad/param norm = 2.0971e-01, time/batch = 17.5047s	
11057/22750 (epoch 24.301), train_loss = 0.94810497, grad/param norm = 1.9508e-01, time/batch = 17.3980s	
11058/22750 (epoch 24.303), train_loss = 1.00449420, grad/param norm = 2.1812e-01, time/batch = 18.5875s	
11059/22750 (epoch 24.305), train_loss = 1.15096776, grad/param norm = 2.2884e-01, time/batch = 18.4371s	
11060/22750 (epoch 24.308), train_loss = 1.00873350, grad/param norm = 1.8621e-01, time/batch = 18.2641s	
11061/22750 (epoch 24.310), train_loss = 0.83027067, grad/param norm = 2.0744e-01, time/batch = 17.8595s	
11062/22750 (epoch 24.312), train_loss = 0.95453751, grad/param norm = 1.8883e-01, time/batch = 20.3649s	
11063/22750 (epoch 24.314), train_loss = 0.95257323, grad/param norm = 2.1406e-01, time/batch = 17.9301s	
11064/22750 (epoch 24.316), train_loss = 0.91307990, grad/param norm = 1.9167e-01, time/batch = 17.9315s	
11065/22750 (epoch 24.319), train_loss = 0.93615299, grad/param norm = 2.0046e-01, time/batch = 17.4999s	
11066/22750 (epoch 24.321), train_loss = 0.87496753, grad/param norm = 2.0210e-01, time/batch = 16.4980s	
11067/22750 (epoch 24.323), train_loss = 0.96555338, grad/param norm = 2.1478e-01, time/batch = 17.0617s	
11068/22750 (epoch 24.325), train_loss = 0.81906606, grad/param norm = 1.9268e-01, time/batch = 18.4100s	
11069/22750 (epoch 24.327), train_loss = 0.90586964, grad/param norm = 2.1241e-01, time/batch = 18.5355s	
11070/22750 (epoch 24.330), train_loss = 1.12873166, grad/param norm = 2.2097e-01, time/batch = 18.1942s	
11071/22750 (epoch 24.332), train_loss = 1.12236112, grad/param norm = 2.0726e-01, time/batch = 20.2702s	
11072/22750 (epoch 24.334), train_loss = 0.77896233, grad/param norm = 1.8245e-01, time/batch = 19.5035s	
11073/22750 (epoch 24.336), train_loss = 1.01862804, grad/param norm = 1.9050e-01, time/batch = 17.3158s	
11074/22750 (epoch 24.338), train_loss = 0.90251325, grad/param norm = 1.9752e-01, time/batch = 17.7513s	
11075/22750 (epoch 24.341), train_loss = 0.93391323, grad/param norm = 1.9248e-01, time/batch = 16.7551s	
11076/22750 (epoch 24.343), train_loss = 0.82549707, grad/param norm = 2.0936e-01, time/batch = 16.9996s	
11077/22750 (epoch 24.345), train_loss = 1.00931143, grad/param norm = 2.4313e-01, time/batch = 18.0761s	
11078/22750 (epoch 24.347), train_loss = 1.06512419, grad/param norm = 2.1360e-01, time/batch = 20.6085s	
11079/22750 (epoch 24.349), train_loss = 0.75673647, grad/param norm = 2.2026e-01, time/batch = 20.5983s	
11080/22750 (epoch 24.352), train_loss = 1.03845799, grad/param norm = 2.2396e-01, time/batch = 18.0288s	
11081/22750 (epoch 24.354), train_loss = 1.04730981, grad/param norm = 1.9219e-01, time/batch = 17.8414s	
11082/22750 (epoch 24.356), train_loss = 1.04953825, grad/param norm = 2.1523e-01, time/batch = 16.6803s	
11083/22750 (epoch 24.358), train_loss = 0.92954000, grad/param norm = 2.1710e-01, time/batch = 17.0941s	
11084/22750 (epoch 24.360), train_loss = 1.13003785, grad/param norm = 2.0863e-01, time/batch = 18.0807s	
11085/22750 (epoch 24.363), train_loss = 0.93991914, grad/param norm = 2.1844e-01, time/batch = 18.4976s	
11086/22750 (epoch 24.365), train_loss = 0.75865587, grad/param norm = 1.9641e-01, time/batch = 17.3388s	
11087/22750 (epoch 24.367), train_loss = 0.83839579, grad/param norm = 2.1984e-01, time/batch = 19.2839s	
11088/22750 (epoch 24.369), train_loss = 0.94390604, grad/param norm = 2.2845e-01, time/batch = 16.1030s	
11089/22750 (epoch 24.371), train_loss = 0.92797445, grad/param norm = 2.0476e-01, time/batch = 16.4141s	
11090/22750 (epoch 24.374), train_loss = 0.85403892, grad/param norm = 2.1186e-01, time/batch = 17.0581s	
11091/22750 (epoch 24.376), train_loss = 0.90181687, grad/param norm = 1.8519e-01, time/batch = 16.7153s	
11092/22750 (epoch 24.378), train_loss = 0.93876148, grad/param norm = 1.9577e-01, time/batch = 16.7245s	
11093/22750 (epoch 24.380), train_loss = 1.03506566, grad/param norm = 2.0648e-01, time/batch = 16.8751s	
11094/22750 (epoch 24.382), train_loss = 0.91129019, grad/param norm = 2.0741e-01, time/batch = 17.9945s	
11095/22750 (epoch 24.385), train_loss = 1.02292153, grad/param norm = 1.9992e-01, time/batch = 17.6764s	
11096/22750 (epoch 24.387), train_loss = 0.96199877, grad/param norm = 1.8890e-01, time/batch = 18.5096s	
11097/22750 (epoch 24.389), train_loss = 0.76339047, grad/param norm = 1.9824e-01, time/batch = 19.4252s	
11098/22750 (epoch 24.391), train_loss = 0.59275575, grad/param norm = 1.5690e-01, time/batch = 20.4427s	
11099/22750 (epoch 24.393), train_loss = 0.79971074, grad/param norm = 1.8563e-01, time/batch = 18.0177s	
11100/22750 (epoch 24.396), train_loss = 0.99500776, grad/param norm = 1.9616e-01, time/batch = 17.3405s	
11101/22750 (epoch 24.398), train_loss = 0.91407739, grad/param norm = 1.8826e-01, time/batch = 18.1655s	
11102/22750 (epoch 24.400), train_loss = 0.91147638, grad/param norm = 1.9994e-01, time/batch = 17.9347s	
11103/22750 (epoch 24.402), train_loss = 0.98019044, grad/param norm = 1.9637e-01, time/batch = 17.1867s	
11104/22750 (epoch 24.404), train_loss = 1.06359999, grad/param norm = 2.0145e-01, time/batch = 18.6520s	
11105/22750 (epoch 24.407), train_loss = 1.03389850, grad/param norm = 2.0411e-01, time/batch = 19.0756s	
11106/22750 (epoch 24.409), train_loss = 0.86458052, grad/param norm = 1.9646e-01, time/batch = 22.5444s	
11107/22750 (epoch 24.411), train_loss = 0.88792473, grad/param norm = 1.8678e-01, time/batch = 30.9623s	
11108/22750 (epoch 24.413), train_loss = 0.70303893, grad/param norm = 1.8733e-01, time/batch = 17.9052s	
11109/22750 (epoch 24.415), train_loss = 0.71216943, grad/param norm = 1.6247e-01, time/batch = 16.5807s	
11110/22750 (epoch 24.418), train_loss = 0.85989628, grad/param norm = 2.0238e-01, time/batch = 17.5051s	
11111/22750 (epoch 24.420), train_loss = 1.01065013, grad/param norm = 2.5476e-01, time/batch = 18.9884s	
11112/22750 (epoch 24.422), train_loss = 1.15879789, grad/param norm = 2.4492e-01, time/batch = 17.1801s	
11113/22750 (epoch 24.424), train_loss = 1.14250420, grad/param norm = 2.4568e-01, time/batch = 18.1495s	
11114/22750 (epoch 24.426), train_loss = 1.14332417, grad/param norm = 2.1251e-01, time/batch = 18.6929s	
11115/22750 (epoch 24.429), train_loss = 0.85142348, grad/param norm = 2.0390e-01, time/batch = 18.8392s	
11116/22750 (epoch 24.431), train_loss = 0.76514971, grad/param norm = 1.8241e-01, time/batch = 16.1472s	
11117/22750 (epoch 24.433), train_loss = 0.87303474, grad/param norm = 1.9261e-01, time/batch = 16.0302s	
11118/22750 (epoch 24.435), train_loss = 0.71551092, grad/param norm = 1.7527e-01, time/batch = 15.9532s	
11119/22750 (epoch 24.437), train_loss = 0.61382631, grad/param norm = 1.7802e-01, time/batch = 16.5862s	
11120/22750 (epoch 24.440), train_loss = 0.91548933, grad/param norm = 2.3070e-01, time/batch = 16.1021s	
11121/22750 (epoch 24.442), train_loss = 0.95376308, grad/param norm = 2.1515e-01, time/batch = 16.1034s	
11122/22750 (epoch 24.444), train_loss = 0.91421906, grad/param norm = 2.2226e-01, time/batch = 15.8732s	
11123/22750 (epoch 24.446), train_loss = 0.92880701, grad/param norm = 2.1656e-01, time/batch = 16.2392s	
11124/22750 (epoch 24.448), train_loss = 1.20703506, grad/param norm = 2.4312e-01, time/batch = 15.2461s	
11125/22750 (epoch 24.451), train_loss = 1.14892603, grad/param norm = 2.2419e-01, time/batch = 15.3287s	
11126/22750 (epoch 24.453), train_loss = 1.06508074, grad/param norm = 2.3881e-01, time/batch = 16.0576s	
11127/22750 (epoch 24.455), train_loss = 1.15704275, grad/param norm = 2.3919e-01, time/batch = 16.0303s	
11128/22750 (epoch 24.457), train_loss = 1.04512429, grad/param norm = 3.0221e-01, time/batch = 16.1875s	
11129/22750 (epoch 24.459), train_loss = 1.01564825, grad/param norm = 1.9666e-01, time/batch = 16.0341s	
11130/22750 (epoch 24.462), train_loss = 1.01229962, grad/param norm = 1.8897e-01, time/batch = 16.1956s	
11131/22750 (epoch 24.464), train_loss = 0.79372635, grad/param norm = 1.9758e-01, time/batch = 16.1133s	
11132/22750 (epoch 24.466), train_loss = 1.06976582, grad/param norm = 2.4215e-01, time/batch = 15.6155s	
11133/22750 (epoch 24.468), train_loss = 0.95370532, grad/param norm = 2.0802e-01, time/batch = 15.5285s	
11134/22750 (epoch 24.470), train_loss = 1.09370702, grad/param norm = 2.4192e-01, time/batch = 15.7946s	
11135/22750 (epoch 24.473), train_loss = 0.94646126, grad/param norm = 2.1214e-01, time/batch = 16.0575s	
11136/22750 (epoch 24.475), train_loss = 0.96816605, grad/param norm = 2.1740e-01, time/batch = 16.4371s	
11137/22750 (epoch 24.477), train_loss = 0.81239349, grad/param norm = 1.9333e-01, time/batch = 16.2898s	
11138/22750 (epoch 24.479), train_loss = 0.81163549, grad/param norm = 1.9451e-01, time/batch = 16.5009s	
11139/22750 (epoch 24.481), train_loss = 0.75625500, grad/param norm = 1.7331e-01, time/batch = 15.7844s	
11140/22750 (epoch 24.484), train_loss = 0.65626609, grad/param norm = 1.9662e-01, time/batch = 15.1283s	
11141/22750 (epoch 24.486), train_loss = 0.79907388, grad/param norm = 2.2203e-01, time/batch = 15.2884s	
11142/22750 (epoch 24.488), train_loss = 0.70048651, grad/param norm = 1.8929e-01, time/batch = 15.6884s	
11143/22750 (epoch 24.490), train_loss = 0.90305066, grad/param norm = 1.8791e-01, time/batch = 15.6146s	
11144/22750 (epoch 24.492), train_loss = 1.04229503, grad/param norm = 2.4374e-01, time/batch = 15.7892s	
11145/22750 (epoch 24.495), train_loss = 0.85122947, grad/param norm = 2.0917e-01, time/batch = 15.9515s	
11146/22750 (epoch 24.497), train_loss = 0.90552614, grad/param norm = 2.1112e-01, time/batch = 15.8963s	
11147/22750 (epoch 24.499), train_loss = 0.85781598, grad/param norm = 2.3169e-01, time/batch = 15.7262s	
11148/22750 (epoch 24.501), train_loss = 0.91211991, grad/param norm = 1.9446e-01, time/batch = 15.7285s	
11149/22750 (epoch 24.503), train_loss = 0.93740543, grad/param norm = 2.0508e-01, time/batch = 16.1784s	
11150/22750 (epoch 24.505), train_loss = 0.79761221, grad/param norm = 1.7679e-01, time/batch = 15.9322s	
11151/22750 (epoch 24.508), train_loss = 0.75101119, grad/param norm = 1.8661e-01, time/batch = 14.9667s	
11152/22750 (epoch 24.510), train_loss = 0.78290095, grad/param norm = 1.8689e-01, time/batch = 16.1024s	
11153/22750 (epoch 24.512), train_loss = 0.81040474, grad/param norm = 1.8806e-01, time/batch = 16.2680s	
11154/22750 (epoch 24.514), train_loss = 0.86519044, grad/param norm = 1.9048e-01, time/batch = 16.0932s	
11155/22750 (epoch 24.516), train_loss = 0.86205747, grad/param norm = 1.9899e-01, time/batch = 15.6249s	
11156/22750 (epoch 24.519), train_loss = 0.98520061, grad/param norm = 2.0628e-01, time/batch = 15.8679s	
11157/22750 (epoch 24.521), train_loss = 0.95392942, grad/param norm = 2.2490e-01, time/batch = 16.2875s	
11158/22750 (epoch 24.523), train_loss = 0.85787925, grad/param norm = 2.2691e-01, time/batch = 15.7992s	
11159/22750 (epoch 24.525), train_loss = 1.03000505, grad/param norm = 2.0520e-01, time/batch = 15.6290s	
11160/22750 (epoch 24.527), train_loss = 0.92559621, grad/param norm = 1.9784e-01, time/batch = 16.0247s	
11161/22750 (epoch 24.530), train_loss = 0.83353477, grad/param norm = 2.0883e-01, time/batch = 15.3664s	
11162/22750 (epoch 24.532), train_loss = 0.78156944, grad/param norm = 1.6644e-01, time/batch = 15.0279s	
11163/22750 (epoch 24.534), train_loss = 1.01711887, grad/param norm = 2.2346e-01, time/batch = 15.0970s	
11164/22750 (epoch 24.536), train_loss = 0.95805937, grad/param norm = 1.8593e-01, time/batch = 15.5331s	
11165/22750 (epoch 24.538), train_loss = 0.93296771, grad/param norm = 1.7664e-01, time/batch = 15.7823s	
11166/22750 (epoch 24.541), train_loss = 0.80563220, grad/param norm = 2.0967e-01, time/batch = 15.5668s	
11167/22750 (epoch 24.543), train_loss = 0.80227574, grad/param norm = 1.9995e-01, time/batch = 16.0419s	
11168/22750 (epoch 24.545), train_loss = 0.99987726, grad/param norm = 2.0110e-01, time/batch = 16.7368s	
11169/22750 (epoch 24.547), train_loss = 0.84317034, grad/param norm = 1.7922e-01, time/batch = 15.8612s	
11170/22750 (epoch 24.549), train_loss = 0.87349367, grad/param norm = 1.9502e-01, time/batch = 15.8448s	
11171/22750 (epoch 24.552), train_loss = 0.95953370, grad/param norm = 2.0859e-01, time/batch = 15.4451s	
11172/22750 (epoch 24.554), train_loss = 0.98396687, grad/param norm = 2.2880e-01, time/batch = 16.4893s	
11173/22750 (epoch 24.556), train_loss = 0.94278420, grad/param norm = 1.9612e-01, time/batch = 16.1626s	
11174/22750 (epoch 24.558), train_loss = 0.99763406, grad/param norm = 2.1841e-01, time/batch = 15.7673s	
11175/22750 (epoch 24.560), train_loss = 0.88168617, grad/param norm = 2.1919e-01, time/batch = 15.8644s	
11176/22750 (epoch 24.563), train_loss = 1.02218424, grad/param norm = 2.0653e-01, time/batch = 15.8665s	
11177/22750 (epoch 24.565), train_loss = 0.99317978, grad/param norm = 2.2637e-01, time/batch = 15.6444s	
11178/22750 (epoch 24.567), train_loss = 0.95406913, grad/param norm = 2.0587e-01, time/batch = 15.7021s	
11179/22750 (epoch 24.569), train_loss = 0.89547886, grad/param norm = 1.9609e-01, time/batch = 16.2614s	
11180/22750 (epoch 24.571), train_loss = 0.90967346, grad/param norm = 2.1108e-01, time/batch = 15.8460s	
11181/22750 (epoch 24.574), train_loss = 0.86027694, grad/param norm = 1.9558e-01, time/batch = 15.5356s	
11182/22750 (epoch 24.576), train_loss = 0.86057316, grad/param norm = 1.9308e-01, time/batch = 15.6159s	
11183/22750 (epoch 24.578), train_loss = 0.78716226, grad/param norm = 2.0525e-01, time/batch = 16.0097s	
11184/22750 (epoch 24.580), train_loss = 0.95120931, grad/param norm = 2.4409e-01, time/batch = 15.2839s	
11185/22750 (epoch 24.582), train_loss = 0.83999373, grad/param norm = 2.1007e-01, time/batch = 14.8835s	
11186/22750 (epoch 24.585), train_loss = 0.78973506, grad/param norm = 1.9620e-01, time/batch = 15.6072s	
11187/22750 (epoch 24.587), train_loss = 0.78873483, grad/param norm = 1.8677e-01, time/batch = 16.0339s	
11188/22750 (epoch 24.589), train_loss = 0.74030964, grad/param norm = 1.8938e-01, time/batch = 15.7271s	
11189/22750 (epoch 24.591), train_loss = 0.90074585, grad/param norm = 2.0179e-01, time/batch = 15.4862s	
11190/22750 (epoch 24.593), train_loss = 1.06139307, grad/param norm = 2.0243e-01, time/batch = 15.7252s	
11191/22750 (epoch 24.596), train_loss = 1.05488135, grad/param norm = 2.1289e-01, time/batch = 16.0395s	
11192/22750 (epoch 24.598), train_loss = 1.08370842, grad/param norm = 2.3567e-01, time/batch = 15.7038s	
11193/22750 (epoch 24.600), train_loss = 1.07468649, grad/param norm = 2.3973e-01, time/batch = 15.5331s	
11194/22750 (epoch 24.602), train_loss = 0.85091181, grad/param norm = 1.9666e-01, time/batch = 15.9406s	
11195/22750 (epoch 24.604), train_loss = 0.84886506, grad/param norm = 1.8156e-01, time/batch = 15.8570s	
11196/22750 (epoch 24.607), train_loss = 0.77624975, grad/param norm = 1.6039e-01, time/batch = 15.7065s	
11197/22750 (epoch 24.609), train_loss = 0.71998282, grad/param norm = 1.6165e-01, time/batch = 15.7883s	
11198/22750 (epoch 24.611), train_loss = 0.86999216, grad/param norm = 1.9586e-01, time/batch = 15.8749s	
11199/22750 (epoch 24.613), train_loss = 0.83109736, grad/param norm = 1.8493e-01, time/batch = 15.7975s	
11200/22750 (epoch 24.615), train_loss = 0.87684370, grad/param norm = 2.0589e-01, time/batch = 15.4640s	
11201/22750 (epoch 24.618), train_loss = 0.89618281, grad/param norm = 1.9090e-01, time/batch = 16.6734s	
11202/22750 (epoch 24.620), train_loss = 0.86981610, grad/param norm = 1.8564e-01, time/batch = 17.8355s	
11203/22750 (epoch 24.622), train_loss = 0.73363798, grad/param norm = 1.7872e-01, time/batch = 18.7578s	
11204/22750 (epoch 24.624), train_loss = 0.83736502, grad/param norm = 1.9181e-01, time/batch = 18.0655s	
11205/22750 (epoch 24.626), train_loss = 0.74728760, grad/param norm = 1.7772e-01, time/batch = 17.0774s	
11206/22750 (epoch 24.629), train_loss = 0.85411043, grad/param norm = 1.9875e-01, time/batch = 18.2463s	
11207/22750 (epoch 24.631), train_loss = 0.90299694, grad/param norm = 1.9209e-01, time/batch = 18.9246s	
11208/22750 (epoch 24.633), train_loss = 0.77350680, grad/param norm = 1.8726e-01, time/batch = 17.7908s	
11209/22750 (epoch 24.635), train_loss = 0.89171617, grad/param norm = 1.8969e-01, time/batch = 20.4346s	
11210/22750 (epoch 24.637), train_loss = 0.96803783, grad/param norm = 2.4180e-01, time/batch = 16.2164s	
11211/22750 (epoch 24.640), train_loss = 0.96315232, grad/param norm = 2.0176e-01, time/batch = 16.9127s	
11212/22750 (epoch 24.642), train_loss = 1.04554095, grad/param norm = 2.1280e-01, time/batch = 17.2573s	
11213/22750 (epoch 24.644), train_loss = 0.89879318, grad/param norm = 2.1089e-01, time/batch = 17.4257s	
11214/22750 (epoch 24.646), train_loss = 0.95006654, grad/param norm = 2.8822e-01, time/batch = 17.7539s	
11215/22750 (epoch 24.648), train_loss = 0.96607905, grad/param norm = 2.1752e-01, time/batch = 17.6496s	
11216/22750 (epoch 24.651), train_loss = 0.98640953, grad/param norm = 2.1330e-01, time/batch = 16.4642s	
11217/22750 (epoch 24.653), train_loss = 1.00557388, grad/param norm = 1.9771e-01, time/batch = 16.0170s	
11218/22750 (epoch 24.655), train_loss = 0.92663035, grad/param norm = 1.8593e-01, time/batch = 15.5496s	
11219/22750 (epoch 24.657), train_loss = 1.08698807, grad/param norm = 2.2314e-01, time/batch = 15.8836s	
11220/22750 (epoch 24.659), train_loss = 1.10570017, grad/param norm = 2.2092e-01, time/batch = 15.9514s	
11221/22750 (epoch 24.662), train_loss = 1.10238839, grad/param norm = 2.2004e-01, time/batch = 16.0950s	
11222/22750 (epoch 24.664), train_loss = 0.96466444, grad/param norm = 2.0276e-01, time/batch = 16.0111s	
11223/22750 (epoch 24.666), train_loss = 0.77155611, grad/param norm = 1.8629e-01, time/batch = 16.2479s	
11224/22750 (epoch 24.668), train_loss = 0.93784306, grad/param norm = 2.0792e-01, time/batch = 15.6953s	
11225/22750 (epoch 24.670), train_loss = 0.94229223, grad/param norm = 2.1907e-01, time/batch = 15.0356s	
11226/22750 (epoch 24.673), train_loss = 1.15910499, grad/param norm = 2.3422e-01, time/batch = 15.7656s	
11227/22750 (epoch 24.675), train_loss = 1.29111123, grad/param norm = 2.5111e-01, time/batch = 16.2486s	
11228/22750 (epoch 24.677), train_loss = 1.12253926, grad/param norm = 2.4703e-01, time/batch = 15.5478s	
11229/22750 (epoch 24.679), train_loss = 1.13224803, grad/param norm = 2.4368e-01, time/batch = 15.3185s	
11230/22750 (epoch 24.681), train_loss = 1.08301090, grad/param norm = 2.1120e-01, time/batch = 16.0110s	
11231/22750 (epoch 24.684), train_loss = 1.09256542, grad/param norm = 2.3969e-01, time/batch = 15.6184s	
11232/22750 (epoch 24.686), train_loss = 1.11626821, grad/param norm = 2.2422e-01, time/batch = 15.7805s	
11233/22750 (epoch 24.688), train_loss = 1.08709734, grad/param norm = 2.1859e-01, time/batch = 15.1280s	
11234/22750 (epoch 24.690), train_loss = 1.05899589, grad/param norm = 2.1435e-01, time/batch = 16.0926s	
11235/22750 (epoch 24.692), train_loss = 1.10380967, grad/param norm = 2.3251e-01, time/batch = 16.0185s	
11236/22750 (epoch 24.695), train_loss = 0.97319172, grad/param norm = 2.1487e-01, time/batch = 15.7857s	
11237/22750 (epoch 24.697), train_loss = 0.95439567, grad/param norm = 2.1061e-01, time/batch = 15.6264s	
11238/22750 (epoch 24.699), train_loss = 0.92889895, grad/param norm = 2.1253e-01, time/batch = 16.1008s	
11239/22750 (epoch 24.701), train_loss = 0.82049589, grad/param norm = 1.9510e-01, time/batch = 15.5514s	
11240/22750 (epoch 24.703), train_loss = 0.92217015, grad/param norm = 1.9338e-01, time/batch = 15.6370s	
11241/22750 (epoch 24.705), train_loss = 0.87413882, grad/param norm = 1.9181e-01, time/batch = 15.5500s	
11242/22750 (epoch 24.708), train_loss = 0.94888978, grad/param norm = 1.9274e-01, time/batch = 15.4680s	
11243/22750 (epoch 24.710), train_loss = 0.83394476, grad/param norm = 2.1107e-01, time/batch = 15.6104s	
11244/22750 (epoch 24.712), train_loss = 0.80829703, grad/param norm = 1.9646e-01, time/batch = 15.6157s	
11245/22750 (epoch 24.714), train_loss = 0.76598121, grad/param norm = 1.7402e-01, time/batch = 16.0185s	
11246/22750 (epoch 24.716), train_loss = 0.79220473, grad/param norm = 1.8184e-01, time/batch = 16.0194s	
11247/22750 (epoch 24.719), train_loss = 0.93379319, grad/param norm = 2.3067e-01, time/batch = 15.7016s	
11248/22750 (epoch 24.721), train_loss = 0.99363670, grad/param norm = 1.9748e-01, time/batch = 15.4791s	
11249/22750 (epoch 24.723), train_loss = 1.00465928, grad/param norm = 2.1391e-01, time/batch = 15.7288s	
11250/22750 (epoch 24.725), train_loss = 0.92791023, grad/param norm = 2.2299e-01, time/batch = 15.3116s	
11251/22750 (epoch 24.727), train_loss = 0.87363103, grad/param norm = 1.9737e-01, time/batch = 15.9449s	
11252/22750 (epoch 24.730), train_loss = 0.88522025, grad/param norm = 2.1256e-01, time/batch = 15.7014s	
11253/22750 (epoch 24.732), train_loss = 0.84667981, grad/param norm = 1.9151e-01, time/batch = 16.4934s	
11254/22750 (epoch 24.734), train_loss = 0.74447314, grad/param norm = 1.7652e-01, time/batch = 15.6978s	
11255/22750 (epoch 24.736), train_loss = 0.85395193, grad/param norm = 1.9903e-01, time/batch = 15.7921s	
11256/22750 (epoch 24.738), train_loss = 0.99265980, grad/param norm = 2.2092e-01, time/batch = 15.7031s	
11257/22750 (epoch 24.741), train_loss = 1.02810980, grad/param norm = 2.2149e-01, time/batch = 16.0117s	
11258/22750 (epoch 24.743), train_loss = 0.96376758, grad/param norm = 1.9833e-01, time/batch = 15.4520s	
11259/22750 (epoch 24.745), train_loss = 0.78564123, grad/param norm = 1.7650e-01, time/batch = 15.6382s	
11260/22750 (epoch 24.747), train_loss = 0.88522721, grad/param norm = 1.8838e-01, time/batch = 15.7190s	
11261/22750 (epoch 24.749), train_loss = 1.07458889, grad/param norm = 2.2388e-01, time/batch = 16.1203s	
11262/22750 (epoch 24.752), train_loss = 0.92133412, grad/param norm = 1.8800e-01, time/batch = 15.9708s	
11263/22750 (epoch 24.754), train_loss = 0.94565164, grad/param norm = 2.0379e-01, time/batch = 16.0149s	
11264/22750 (epoch 24.756), train_loss = 0.84383363, grad/param norm = 2.0448e-01, time/batch = 16.2547s	
11265/22750 (epoch 24.758), train_loss = 0.82518016, grad/param norm = 1.7893e-01, time/batch = 15.8673s	
11266/22750 (epoch 24.760), train_loss = 0.87423738, grad/param norm = 2.0178e-01, time/batch = 15.3790s	
11267/22750 (epoch 24.763), train_loss = 0.94250971, grad/param norm = 2.0860e-01, time/batch = 15.6142s	
11268/22750 (epoch 24.765), train_loss = 0.94185133, grad/param norm = 2.2884e-01, time/batch = 16.0233s	
11269/22750 (epoch 24.767), train_loss = 0.96297047, grad/param norm = 2.7597e-01, time/batch = 15.6329s	
11270/22750 (epoch 24.769), train_loss = 1.12911980, grad/param norm = 2.3519e-01, time/batch = 15.7153s	
11271/22750 (epoch 24.771), train_loss = 1.06748934, grad/param norm = 2.1790e-01, time/batch = 15.4864s	
11272/22750 (epoch 24.774), train_loss = 0.90115669, grad/param norm = 2.1056e-01, time/batch = 16.0423s	
11273/22750 (epoch 24.776), train_loss = 1.01991928, grad/param norm = 2.2470e-01, time/batch = 15.6301s	
11274/22750 (epoch 24.778), train_loss = 1.10964449, grad/param norm = 2.2944e-01, time/batch = 15.4459s	
11275/22750 (epoch 24.780), train_loss = 0.93986153, grad/param norm = 2.0173e-01, time/batch = 14.8917s	
11276/22750 (epoch 24.782), train_loss = 1.11596769, grad/param norm = 2.2583e-01, time/batch = 15.5294s	
11277/22750 (epoch 24.785), train_loss = 0.92079270, grad/param norm = 2.2346e-01, time/batch = 15.8413s	
11278/22750 (epoch 24.787), train_loss = 0.80820925, grad/param norm = 2.4420e-01, time/batch = 15.7873s	
11279/22750 (epoch 24.789), train_loss = 0.89874305, grad/param norm = 1.8467e-01, time/batch = 15.6991s	
11280/22750 (epoch 24.791), train_loss = 0.87023458, grad/param norm = 2.0017e-01, time/batch = 16.2872s	
11281/22750 (epoch 24.793), train_loss = 0.85004257, grad/param norm = 2.4118e-01, time/batch = 15.8057s	
11282/22750 (epoch 24.796), train_loss = 0.77768987, grad/param norm = 1.8579e-01, time/batch = 15.5567s	
11283/22750 (epoch 24.798), train_loss = 0.83932097, grad/param norm = 2.0718e-01, time/batch = 15.9543s	
11284/22750 (epoch 24.800), train_loss = 0.85791243, grad/param norm = 2.3006e-01, time/batch = 15.7134s	
11285/22750 (epoch 24.802), train_loss = 0.78076894, grad/param norm = 2.1003e-01, time/batch = 15.7791s	
11286/22750 (epoch 24.804), train_loss = 1.04865287, grad/param norm = 2.1361e-01, time/batch = 15.2186s	
11287/22750 (epoch 24.807), train_loss = 0.98601015, grad/param norm = 2.0720e-01, time/batch = 15.3725s	
11288/22750 (epoch 24.809), train_loss = 1.05548202, grad/param norm = 2.2098e-01, time/batch = 15.9431s	
11289/22750 (epoch 24.811), train_loss = 0.90726287, grad/param norm = 1.9635e-01, time/batch = 16.3300s	
11290/22750 (epoch 24.813), train_loss = 0.95586894, grad/param norm = 1.9571e-01, time/batch = 16.5698s	
11291/22750 (epoch 24.815), train_loss = 1.09677588, grad/param norm = 2.1506e-01, time/batch = 16.4974s	
11292/22750 (epoch 24.818), train_loss = 1.02516051, grad/param norm = 1.9502e-01, time/batch = 17.0703s	
11293/22750 (epoch 24.820), train_loss = 1.18519644, grad/param norm = 2.0749e-01, time/batch = 17.8556s	
11294/22750 (epoch 24.822), train_loss = 0.98989145, grad/param norm = 2.1501e-01, time/batch = 16.6902s	
11295/22750 (epoch 24.824), train_loss = 0.82953142, grad/param norm = 1.8637e-01, time/batch = 17.2552s	
11296/22750 (epoch 24.826), train_loss = 0.91060516, grad/param norm = 2.0140e-01, time/batch = 18.6553s	
11297/22750 (epoch 24.829), train_loss = 1.08708781, grad/param norm = 2.2814e-01, time/batch = 18.7533s	
11298/22750 (epoch 24.831), train_loss = 1.02509292, grad/param norm = 1.9857e-01, time/batch = 18.0794s	
11299/22750 (epoch 24.833), train_loss = 0.96237981, grad/param norm = 2.1326e-01, time/batch = 18.4960s	
11300/22750 (epoch 24.835), train_loss = 0.85344542, grad/param norm = 1.8578e-01, time/batch = 18.0888s	
11301/22750 (epoch 24.837), train_loss = 0.90825870, grad/param norm = 1.8948e-01, time/batch = 16.8756s	
11302/22750 (epoch 24.840), train_loss = 0.80660529, grad/param norm = 1.7837e-01, time/batch = 17.7647s	
11303/22750 (epoch 24.842), train_loss = 0.88172079, grad/param norm = 2.0185e-01, time/batch = 18.8360s	
11304/22750 (epoch 24.844), train_loss = 0.98917523, grad/param norm = 2.1794e-01, time/batch = 16.9201s	
11305/22750 (epoch 24.846), train_loss = 0.94837317, grad/param norm = 1.9676e-01, time/batch = 16.6006s	
11306/22750 (epoch 24.848), train_loss = 0.85289076, grad/param norm = 1.7456e-01, time/batch = 16.6808s	
11307/22750 (epoch 24.851), train_loss = 0.82247226, grad/param norm = 1.8560e-01, time/batch = 17.9204s	
11308/22750 (epoch 24.853), train_loss = 0.99548076, grad/param norm = 2.0487e-01, time/batch = 16.5712s	
11309/22750 (epoch 24.855), train_loss = 0.83766024, grad/param norm = 1.8762e-01, time/batch = 16.9137s	
11310/22750 (epoch 24.857), train_loss = 0.96813545, grad/param norm = 2.0010e-01, time/batch = 17.7541s	
11311/22750 (epoch 24.859), train_loss = 1.02014376, grad/param norm = 2.2869e-01, time/batch = 18.6099s	
11312/22750 (epoch 24.862), train_loss = 1.11432259, grad/param norm = 2.2355e-01, time/batch = 19.0993s	
11313/22750 (epoch 24.864), train_loss = 0.92680250, grad/param norm = 2.0494e-01, time/batch = 18.3407s	
11314/22750 (epoch 24.866), train_loss = 0.97596548, grad/param norm = 1.9246e-01, time/batch = 17.5078s	
11315/22750 (epoch 24.868), train_loss = 0.85630684, grad/param norm = 1.8389e-01, time/batch = 18.0941s	
11316/22750 (epoch 24.870), train_loss = 0.77722761, grad/param norm = 1.9165e-01, time/batch = 17.0057s	
11317/22750 (epoch 24.873), train_loss = 0.89351598, grad/param norm = 1.8366e-01, time/batch = 17.5910s	
11318/22750 (epoch 24.875), train_loss = 1.01594290, grad/param norm = 2.1215e-01, time/batch = 16.6645s	
11319/22750 (epoch 24.877), train_loss = 0.83846922, grad/param norm = 2.0936e-01, time/batch = 17.1622s	
11320/22750 (epoch 24.879), train_loss = 1.07066736, grad/param norm = 2.2590e-01, time/batch = 18.9402s	
11321/22750 (epoch 24.881), train_loss = 0.99507825, grad/param norm = 2.0752e-01, time/batch = 18.4514s	
11322/22750 (epoch 24.884), train_loss = 0.87635930, grad/param norm = 1.9665e-01, time/batch = 19.8359s	
11323/22750 (epoch 24.886), train_loss = 1.00785200, grad/param norm = 2.2285e-01, time/batch = 17.7599s	
11324/22750 (epoch 24.888), train_loss = 1.01006405, grad/param norm = 1.8922e-01, time/batch = 18.3651s	
11325/22750 (epoch 24.890), train_loss = 1.00379263, grad/param norm = 2.0901e-01, time/batch = 28.0295s	
11326/22750 (epoch 24.892), train_loss = 1.24741378, grad/param norm = 2.3666e-01, time/batch = 16.4259s	
11327/22750 (epoch 24.895), train_loss = 0.94353105, grad/param norm = 2.0729e-01, time/batch = 16.4279s	
11328/22750 (epoch 24.897), train_loss = 1.02054659, grad/param norm = 2.0847e-01, time/batch = 16.2614s	
11329/22750 (epoch 24.899), train_loss = 1.00054243, grad/param norm = 2.0263e-01, time/batch = 16.1790s	
11330/22750 (epoch 24.901), train_loss = 1.06564393, grad/param norm = 2.1847e-01, time/batch = 17.2424s	
11331/22750 (epoch 24.903), train_loss = 0.92073110, grad/param norm = 1.9632e-01, time/batch = 18.0213s	
11332/22750 (epoch 24.905), train_loss = 1.01129042, grad/param norm = 2.0957e-01, time/batch = 18.2427s	
11333/22750 (epoch 24.908), train_loss = 0.85637270, grad/param norm = 2.1571e-01, time/batch = 19.0112s	
11334/22750 (epoch 24.910), train_loss = 0.72225214, grad/param norm = 1.7728e-01, time/batch = 18.2484s	
11335/22750 (epoch 24.912), train_loss = 0.88975664, grad/param norm = 1.8679e-01, time/batch = 18.9962s	
11336/22750 (epoch 24.914), train_loss = 0.94135744, grad/param norm = 2.0423e-01, time/batch = 18.0847s	
11337/22750 (epoch 24.916), train_loss = 0.78158450, grad/param norm = 2.0872e-01, time/batch = 18.5910s	
11338/22750 (epoch 24.919), train_loss = 0.90533228, grad/param norm = 2.1304e-01, time/batch = 19.3919s	
11339/22750 (epoch 24.921), train_loss = 0.72082958, grad/param norm = 1.9333e-01, time/batch = 16.0731s	
11340/22750 (epoch 24.923), train_loss = 0.83031305, grad/param norm = 1.9087e-01, time/batch = 16.0667s	
11341/22750 (epoch 24.925), train_loss = 0.89472764, grad/param norm = 1.8582e-01, time/batch = 17.9918s	
11342/22750 (epoch 24.927), train_loss = 0.74025395, grad/param norm = 1.9682e-01, time/batch = 17.3238s	
11343/22750 (epoch 24.930), train_loss = 0.72541454, grad/param norm = 1.7490e-01, time/batch = 17.2640s	
11344/22750 (epoch 24.932), train_loss = 0.93571209, grad/param norm = 2.2361e-01, time/batch = 16.0998s	
11345/22750 (epoch 24.934), train_loss = 0.74048941, grad/param norm = 1.7390e-01, time/batch = 17.0069s	
11346/22750 (epoch 24.936), train_loss = 1.03068895, grad/param norm = 2.0193e-01, time/batch = 17.1020s	
11347/22750 (epoch 24.938), train_loss = 1.02085302, grad/param norm = 1.8396e-01, time/batch = 16.9439s	
11348/22750 (epoch 24.941), train_loss = 1.10992763, grad/param norm = 2.3971e-01, time/batch = 19.1048s	
11349/22750 (epoch 24.943), train_loss = 0.95530198, grad/param norm = 2.2347e-01, time/batch = 19.3678s	
11350/22750 (epoch 24.945), train_loss = 0.96486472, grad/param norm = 2.3394e-01, time/batch = 18.3705s	
11351/22750 (epoch 24.947), train_loss = 0.90114420, grad/param norm = 2.2046e-01, time/batch = 17.0736s	
11352/22750 (epoch 24.949), train_loss = 0.83630468, grad/param norm = 2.1602e-01, time/batch = 19.1665s	
11353/22750 (epoch 24.952), train_loss = 0.85247480, grad/param norm = 1.7557e-01, time/batch = 17.4358s	
11354/22750 (epoch 24.954), train_loss = 0.81711966, grad/param norm = 1.8080e-01, time/batch = 17.3394s	
11355/22750 (epoch 24.956), train_loss = 0.95954591, grad/param norm = 1.9621e-01, time/batch = 18.2665s	
11356/22750 (epoch 24.958), train_loss = 0.86696819, grad/param norm = 1.7593e-01, time/batch = 18.0092s	
11357/22750 (epoch 24.960), train_loss = 0.82864251, grad/param norm = 1.8210e-01, time/batch = 19.7670s	
11358/22750 (epoch 24.963), train_loss = 0.97309891, grad/param norm = 2.1236e-01, time/batch = 19.7610s	
11359/22750 (epoch 24.965), train_loss = 1.00046488, grad/param norm = 1.9418e-01, time/batch = 19.1951s	
11360/22750 (epoch 24.967), train_loss = 0.95279891, grad/param norm = 2.0476e-01, time/batch = 19.2612s	
11361/22750 (epoch 24.969), train_loss = 0.87274418, grad/param norm = 2.0969e-01, time/batch = 18.9938s	
11362/22750 (epoch 24.971), train_loss = 0.84771113, grad/param norm = 1.8417e-01, time/batch = 19.3223s	
11363/22750 (epoch 24.974), train_loss = 0.89621452, grad/param norm = 2.0232e-01, time/batch = 17.9185s	
11364/22750 (epoch 24.976), train_loss = 0.94020081, grad/param norm = 2.0539e-01, time/batch = 17.0037s	
11365/22750 (epoch 24.978), train_loss = 0.86887785, grad/param norm = 2.0650e-01, time/batch = 16.4454s	
11366/22750 (epoch 24.980), train_loss = 1.04879569, grad/param norm = 2.2529e-01, time/batch = 17.9304s	
11367/22750 (epoch 24.982), train_loss = 0.83657267, grad/param norm = 1.9805e-01, time/batch = 16.1231s	
11368/22750 (epoch 24.985), train_loss = 1.07302509, grad/param norm = 2.1699e-01, time/batch = 20.1956s	
11369/22750 (epoch 24.987), train_loss = 0.73376554, grad/param norm = 1.8299e-01, time/batch = 18.8591s	
11370/22750 (epoch 24.989), train_loss = 0.87975355, grad/param norm = 2.3519e-01, time/batch = 18.7267s	
11371/22750 (epoch 24.991), train_loss = 0.96180173, grad/param norm = 2.1737e-01, time/batch = 18.8271s	
11372/22750 (epoch 24.993), train_loss = 0.97200794, grad/param norm = 2.4022e-01, time/batch = 18.9296s	
11373/22750 (epoch 24.996), train_loss = 0.83738617, grad/param norm = 2.2125e-01, time/batch = 18.1131s	
11374/22750 (epoch 24.998), train_loss = 1.06662673, grad/param norm = 2.2737e-01, time/batch = 18.4105s	
decayed learning rate by a factor 0.97 to 0.0012285073069254	
11375/22750 (epoch 25.000), train_loss = 0.94541053, grad/param norm = 2.1031e-01, time/batch = 18.0825s	
11376/22750 (epoch 25.002), train_loss = 1.10157907, grad/param norm = 2.2136e-01, time/batch = 18.7524s	
11377/22750 (epoch 25.004), train_loss = 0.87401584, grad/param norm = 1.9056e-01, time/batch = 17.6743s	
11378/22750 (epoch 25.007), train_loss = 0.88017404, grad/param norm = 2.0537e-01, time/batch = 20.1820s	
11379/22750 (epoch 25.009), train_loss = 1.08243006, grad/param norm = 2.3398e-01, time/batch = 20.1026s	
11380/22750 (epoch 25.011), train_loss = 1.16847216, grad/param norm = 2.4892e-01, time/batch = 18.7703s	
11381/22750 (epoch 25.013), train_loss = 1.05410761, grad/param norm = 2.3260e-01, time/batch = 19.8490s	
11382/22750 (epoch 25.015), train_loss = 0.95129203, grad/param norm = 2.2066e-01, time/batch = 18.8360s	
11383/22750 (epoch 25.018), train_loss = 1.01532566, grad/param norm = 2.2293e-01, time/batch = 17.7457s	
11384/22750 (epoch 25.020), train_loss = 1.06566039, grad/param norm = 2.1315e-01, time/batch = 17.2515s	
11385/22750 (epoch 25.022), train_loss = 0.93309238, grad/param norm = 2.0086e-01, time/batch = 19.4197s	
11386/22750 (epoch 25.024), train_loss = 0.94390102, grad/param norm = 2.0446e-01, time/batch = 18.1605s	
11387/22750 (epoch 25.026), train_loss = 1.00868870, grad/param norm = 2.2010e-01, time/batch = 19.5951s	
11388/22750 (epoch 25.029), train_loss = 0.77757239, grad/param norm = 2.0575e-01, time/batch = 19.0310s	
11389/22750 (epoch 25.031), train_loss = 1.18490252, grad/param norm = 2.2274e-01, time/batch = 16.3154s	
11390/22750 (epoch 25.033), train_loss = 0.96067506, grad/param norm = 2.1407e-01, time/batch = 16.7189s	
11391/22750 (epoch 25.035), train_loss = 0.98259550, grad/param norm = 1.9410e-01, time/batch = 17.1833s	
11392/22750 (epoch 25.037), train_loss = 1.04192237, grad/param norm = 1.8670e-01, time/batch = 16.0371s	
11393/22750 (epoch 25.040), train_loss = 0.91325000, grad/param norm = 2.0154e-01, time/batch = 17.7462s	
11394/22750 (epoch 25.042), train_loss = 0.98166770, grad/param norm = 2.1011e-01, time/batch = 17.9295s	
11395/22750 (epoch 25.044), train_loss = 0.90516298, grad/param norm = 2.0510e-01, time/batch = 19.3297s	
11396/22750 (epoch 25.046), train_loss = 1.05104385, grad/param norm = 2.4398e-01, time/batch = 18.2592s	
11397/22750 (epoch 25.048), train_loss = 0.93463290, grad/param norm = 1.8557e-01, time/batch = 17.3784s	
11398/22750 (epoch 25.051), train_loss = 0.98886069, grad/param norm = 2.1536e-01, time/batch = 18.3715s	
11399/22750 (epoch 25.053), train_loss = 0.86175760, grad/param norm = 1.7455e-01, time/batch = 18.3610s	
11400/22750 (epoch 25.055), train_loss = 0.83577301, grad/param norm = 1.9843e-01, time/batch = 16.9513s	
11401/22750 (epoch 25.057), train_loss = 1.12053617, grad/param norm = 2.0681e-01, time/batch = 18.8962s	
11402/22750 (epoch 25.059), train_loss = 0.70769649, grad/param norm = 1.8763e-01, time/batch = 19.5794s	
11403/22750 (epoch 25.062), train_loss = 0.81326615, grad/param norm = 2.0163e-01, time/batch = 17.1715s	
11404/22750 (epoch 25.064), train_loss = 1.01062048, grad/param norm = 2.1352e-01, time/batch = 17.8409s	
11405/22750 (epoch 25.066), train_loss = 0.82149280, grad/param norm = 1.8812e-01, time/batch = 19.7665s	
11406/22750 (epoch 25.068), train_loss = 0.85609882, grad/param norm = 1.7560e-01, time/batch = 19.0129s	
11407/22750 (epoch 25.070), train_loss = 0.73050141, grad/param norm = 1.8282e-01, time/batch = 18.8628s	
11408/22750 (epoch 25.073), train_loss = 0.87573068, grad/param norm = 1.9767e-01, time/batch = 19.9411s	
11409/22750 (epoch 25.075), train_loss = 0.91243777, grad/param norm = 2.0102e-01, time/batch = 18.2621s	
11410/22750 (epoch 25.077), train_loss = 0.69381502, grad/param norm = 1.8239e-01, time/batch = 17.3211s	
11411/22750 (epoch 25.079), train_loss = 0.87529010, grad/param norm = 2.0573e-01, time/batch = 18.3328s	
11412/22750 (epoch 25.081), train_loss = 0.90173485, grad/param norm = 2.1492e-01, time/batch = 19.1673s	
11413/22750 (epoch 25.084), train_loss = 0.88272981, grad/param norm = 2.0292e-01, time/batch = 18.0768s	
11414/22750 (epoch 25.086), train_loss = 0.89945217, grad/param norm = 1.8174e-01, time/batch = 17.7859s	
11415/22750 (epoch 25.088), train_loss = 0.84280177, grad/param norm = 1.9546e-01, time/batch = 16.4650s	
11416/22750 (epoch 25.090), train_loss = 0.85605632, grad/param norm = 1.9243e-01, time/batch = 17.0996s	
11417/22750 (epoch 25.092), train_loss = 1.03500895, grad/param norm = 1.9877e-01, time/batch = 19.6115s	
11418/22750 (epoch 25.095), train_loss = 0.82162275, grad/param norm = 1.9519e-01, time/batch = 18.0220s	
11419/22750 (epoch 25.097), train_loss = 0.92519697, grad/param norm = 1.9768e-01, time/batch = 18.1743s	
11420/22750 (epoch 25.099), train_loss = 0.87377489, grad/param norm = 1.9064e-01, time/batch = 18.2623s	
11421/22750 (epoch 25.101), train_loss = 0.78993485, grad/param norm = 1.7836e-01, time/batch = 20.3258s	
11422/22750 (epoch 25.103), train_loss = 0.95229052, grad/param norm = 2.1008e-01, time/batch = 19.1647s	
11423/22750 (epoch 25.105), train_loss = 1.09044693, grad/param norm = 2.5802e-01, time/batch = 17.7566s	
11424/22750 (epoch 25.108), train_loss = 0.89457385, grad/param norm = 1.9383e-01, time/batch = 20.2874s	
11425/22750 (epoch 25.110), train_loss = 1.05116076, grad/param norm = 2.1485e-01, time/batch = 19.0351s	
11426/22750 (epoch 25.112), train_loss = 0.76147114, grad/param norm = 1.6874e-01, time/batch = 19.2669s	
11427/22750 (epoch 25.114), train_loss = 0.71648158, grad/param norm = 1.9313e-01, time/batch = 19.8255s	
11428/22750 (epoch 25.116), train_loss = 0.85363774, grad/param norm = 1.7471e-01, time/batch = 18.3223s	
11429/22750 (epoch 25.119), train_loss = 0.84399944, grad/param norm = 1.8446e-01, time/batch = 17.5777s	
11430/22750 (epoch 25.121), train_loss = 0.93071783, grad/param norm = 2.1958e-01, time/batch = 19.4041s	
11431/22750 (epoch 25.123), train_loss = 0.80061627, grad/param norm = 1.9304e-01, time/batch = 18.4187s	
11432/22750 (epoch 25.125), train_loss = 1.05867556, grad/param norm = 1.9631e-01, time/batch = 17.8491s	
11433/22750 (epoch 25.127), train_loss = 0.87967100, grad/param norm = 2.1194e-01, time/batch = 19.8562s	
11434/22750 (epoch 25.130), train_loss = 0.89443468, grad/param norm = 1.7422e-01, time/batch = 19.8603s	
11435/22750 (epoch 25.132), train_loss = 0.84163060, grad/param norm = 2.0248e-01, time/batch = 17.3241s	
11436/22750 (epoch 25.134), train_loss = 0.88386874, grad/param norm = 2.0828e-01, time/batch = 16.5735s	
11437/22750 (epoch 25.136), train_loss = 0.75448241, grad/param norm = 2.0273e-01, time/batch = 16.1099s	
11438/22750 (epoch 25.138), train_loss = 0.98422440, grad/param norm = 2.1515e-01, time/batch = 17.6689s	
11439/22750 (epoch 25.141), train_loss = 0.93396731, grad/param norm = 1.9913e-01, time/batch = 18.1478s	
11440/22750 (epoch 25.143), train_loss = 0.80797544, grad/param norm = 1.8311e-01, time/batch = 17.9971s	
11441/22750 (epoch 25.145), train_loss = 1.02942672, grad/param norm = 2.0456e-01, time/batch = 18.6600s	
11442/22750 (epoch 25.147), train_loss = 1.09063886, grad/param norm = 2.0855e-01, time/batch = 17.1097s	
11443/22750 (epoch 25.149), train_loss = 0.91681752, grad/param norm = 1.9985e-01, time/batch = 19.4430s	
11444/22750 (epoch 25.152), train_loss = 0.91461998, grad/param norm = 1.9383e-01, time/batch = 18.5833s	
11445/22750 (epoch 25.154), train_loss = 0.81114069, grad/param norm = 1.8670e-01, time/batch = 18.4850s	
11446/22750 (epoch 25.156), train_loss = 0.81074202, grad/param norm = 1.9456e-01, time/batch = 19.0718s	
11447/22750 (epoch 25.158), train_loss = 0.83052867, grad/param norm = 2.0802e-01, time/batch = 17.5136s	
11448/22750 (epoch 25.160), train_loss = 0.93028076, grad/param norm = 2.1047e-01, time/batch = 16.8379s	
11449/22750 (epoch 25.163), train_loss = 1.11987878, grad/param norm = 2.4023e-01, time/batch = 17.8973s	
11450/22750 (epoch 25.165), train_loss = 0.95638147, grad/param norm = 2.0262e-01, time/batch = 18.0061s	
11451/22750 (epoch 25.167), train_loss = 0.89904100, grad/param norm = 2.2397e-01, time/batch = 19.2827s	
11452/22750 (epoch 25.169), train_loss = 0.93235966, grad/param norm = 2.9789e-01, time/batch = 18.5961s	
11453/22750 (epoch 25.171), train_loss = 0.78419530, grad/param norm = 1.8860e-01, time/batch = 17.9445s	
11454/22750 (epoch 25.174), train_loss = 0.75288571, grad/param norm = 1.9734e-01, time/batch = 18.5018s	
11455/22750 (epoch 25.176), train_loss = 0.80686684, grad/param norm = 1.9072e-01, time/batch = 17.4184s	
11456/22750 (epoch 25.178), train_loss = 0.85454586, grad/param norm = 1.9964e-01, time/batch = 19.1621s	
11457/22750 (epoch 25.180), train_loss = 1.03125635, grad/param norm = 3.3073e-01, time/batch = 17.9998s	
11458/22750 (epoch 25.182), train_loss = 1.02580288, grad/param norm = 2.2504e-01, time/batch = 18.0870s	
11459/22750 (epoch 25.185), train_loss = 1.04722455, grad/param norm = 2.1704e-01, time/batch = 16.9244s	
11460/22750 (epoch 25.187), train_loss = 0.80568806, grad/param norm = 1.9506e-01, time/batch = 19.3653s	
11461/22750 (epoch 25.189), train_loss = 0.81442185, grad/param norm = 2.0762e-01, time/batch = 18.8611s	
11462/22750 (epoch 25.191), train_loss = 0.84276046, grad/param norm = 1.8087e-01, time/batch = 17.9300s	
11463/22750 (epoch 25.193), train_loss = 0.97799479, grad/param norm = 2.0010e-01, time/batch = 19.7425s	
11464/22750 (epoch 25.196), train_loss = 0.88741391, grad/param norm = 2.2389e-01, time/batch = 17.5996s	
11465/22750 (epoch 25.198), train_loss = 0.67333656, grad/param norm = 1.7338e-01, time/batch = 17.4199s	
11466/22750 (epoch 25.200), train_loss = 0.92007925, grad/param norm = 2.2477e-01, time/batch = 19.8947s	
11467/22750 (epoch 25.202), train_loss = 0.99680749, grad/param norm = 2.5457e-01, time/batch = 19.8988s	
11468/22750 (epoch 25.204), train_loss = 0.90807508, grad/param norm = 1.8142e-01, time/batch = 17.6874s	
11469/22750 (epoch 25.207), train_loss = 0.89720801, grad/param norm = 1.9400e-01, time/batch = 20.2763s	
11470/22750 (epoch 25.209), train_loss = 0.83137231, grad/param norm = 1.8517e-01, time/batch = 19.6839s	
11471/22750 (epoch 25.211), train_loss = 0.84316739, grad/param norm = 2.0196e-01, time/batch = 17.3411s	
11472/22750 (epoch 25.213), train_loss = 0.70654905, grad/param norm = 1.8714e-01, time/batch = 19.0733s	
11473/22750 (epoch 25.215), train_loss = 0.67748119, grad/param norm = 1.6192e-01, time/batch = 18.2438s	
11474/22750 (epoch 25.218), train_loss = 0.78843558, grad/param norm = 2.1090e-01, time/batch = 16.4231s	
11475/22750 (epoch 25.220), train_loss = 0.74194410, grad/param norm = 1.7998e-01, time/batch = 16.0142s	
11476/22750 (epoch 25.222), train_loss = 0.76651424, grad/param norm = 1.8019e-01, time/batch = 15.8404s	
11477/22750 (epoch 25.224), train_loss = 0.80498235, grad/param norm = 1.8132e-01, time/batch = 18.1753s	
11478/22750 (epoch 25.226), train_loss = 0.91543741, grad/param norm = 2.0270e-01, time/batch = 16.3674s	
11479/22750 (epoch 25.229), train_loss = 0.91315580, grad/param norm = 1.9975e-01, time/batch = 18.9514s	
11480/22750 (epoch 25.231), train_loss = 0.81499547, grad/param norm = 1.9637e-01, time/batch = 19.6998s	
11481/22750 (epoch 25.233), train_loss = 0.73138951, grad/param norm = 1.7169e-01, time/batch = 17.9229s	
11482/22750 (epoch 25.235), train_loss = 0.73726190, grad/param norm = 2.0745e-01, time/batch = 17.5753s	
11483/22750 (epoch 25.237), train_loss = 0.81241723, grad/param norm = 1.8128e-01, time/batch = 18.3975s	
11484/22750 (epoch 25.240), train_loss = 0.89610910, grad/param norm = 2.2855e-01, time/batch = 18.6630s	
11485/22750 (epoch 25.242), train_loss = 1.10428947, grad/param norm = 2.5996e-01, time/batch = 18.9764s	
11486/22750 (epoch 25.244), train_loss = 1.06003775, grad/param norm = 2.2497e-01, time/batch = 18.4959s	
11487/22750 (epoch 25.246), train_loss = 1.08186755, grad/param norm = 2.3319e-01, time/batch = 19.7570s	
11488/22750 (epoch 25.248), train_loss = 0.88538401, grad/param norm = 2.0766e-01, time/batch = 19.7653s	
11489/22750 (epoch 25.251), train_loss = 1.00549692, grad/param norm = 2.2077e-01, time/batch = 19.8556s	
11490/22750 (epoch 25.253), train_loss = 0.94836067, grad/param norm = 2.1155e-01, time/batch = 18.5960s	
11491/22750 (epoch 25.255), train_loss = 0.92559178, grad/param norm = 2.0090e-01, time/batch = 18.6649s	
11492/22750 (epoch 25.257), train_loss = 0.82275902, grad/param norm = 2.1557e-01, time/batch = 19.8308s	
11493/22750 (epoch 25.259), train_loss = 1.04202875, grad/param norm = 2.5779e-01, time/batch = 20.2518s	
11494/22750 (epoch 25.262), train_loss = 0.92310992, grad/param norm = 2.2225e-01, time/batch = 18.1752s	
11495/22750 (epoch 25.264), train_loss = 0.74298122, grad/param norm = 2.2786e-01, time/batch = 18.5843s	
11496/22750 (epoch 25.266), train_loss = 0.89212637, grad/param norm = 2.3576e-01, time/batch = 17.0959s	
11497/22750 (epoch 25.268), train_loss = 1.05658756, grad/param norm = 2.3846e-01, time/batch = 17.2873s	
11498/22750 (epoch 25.270), train_loss = 0.83938389, grad/param norm = 2.4488e-01, time/batch = 20.4470s	
11499/22750 (epoch 25.273), train_loss = 1.19357886, grad/param norm = 2.4981e-01, time/batch = 20.7397s	
11500/22750 (epoch 25.275), train_loss = 1.04576079, grad/param norm = 1.9426e-01, time/batch = 18.1801s	
11501/22750 (epoch 25.277), train_loss = 0.86706323, grad/param norm = 2.1894e-01, time/batch = 19.7648s	
11502/22750 (epoch 25.279), train_loss = 0.78250840, grad/param norm = 2.0094e-01, time/batch = 20.8275s	
11503/22750 (epoch 25.281), train_loss = 1.05334315, grad/param norm = 2.1489e-01, time/batch = 17.7565s	
11504/22750 (epoch 25.284), train_loss = 0.89834025, grad/param norm = 1.8789e-01, time/batch = 19.6730s	
11505/22750 (epoch 25.286), train_loss = 1.00152773, grad/param norm = 2.0837e-01, time/batch = 20.0043s	
11506/22750 (epoch 25.288), train_loss = 1.08094897, grad/param norm = 2.2720e-01, time/batch = 18.1897s	
11507/22750 (epoch 25.290), train_loss = 0.92726823, grad/param norm = 1.8593e-01, time/batch = 19.8334s	
11508/22750 (epoch 25.292), train_loss = 0.97718944, grad/param norm = 2.3238e-01, time/batch = 19.6026s	
11509/22750 (epoch 25.295), train_loss = 0.98855388, grad/param norm = 2.2098e-01, time/batch = 19.7667s	
11510/22750 (epoch 25.297), train_loss = 0.91762408, grad/param norm = 2.0447e-01, time/batch = 19.7613s	
11511/22750 (epoch 25.299), train_loss = 1.01475053, grad/param norm = 2.1506e-01, time/batch = 19.6720s	
11512/22750 (epoch 25.301), train_loss = 0.93123144, grad/param norm = 1.9983e-01, time/batch = 18.3447s	
11513/22750 (epoch 25.303), train_loss = 0.97049873, grad/param norm = 2.1400e-01, time/batch = 17.4185s	
11514/22750 (epoch 25.305), train_loss = 1.14212345, grad/param norm = 2.2975e-01, time/batch = 19.7557s	
11515/22750 (epoch 25.308), train_loss = 0.99442584, grad/param norm = 2.0121e-01, time/batch = 15.8991s	
11516/22750 (epoch 25.310), train_loss = 0.81912282, grad/param norm = 2.1191e-01, time/batch = 16.0126s	
11517/22750 (epoch 25.312), train_loss = 0.95368350, grad/param norm = 1.9758e-01, time/batch = 16.4378s	
11518/22750 (epoch 25.314), train_loss = 0.94107911, grad/param norm = 2.0305e-01, time/batch = 20.0966s	
11519/22750 (epoch 25.316), train_loss = 0.89664111, grad/param norm = 2.0534e-01, time/batch = 27.0793s	
11520/22750 (epoch 25.319), train_loss = 0.92679826, grad/param norm = 2.0467e-01, time/batch = 25.8840s	
11521/22750 (epoch 25.321), train_loss = 0.86336921, grad/param norm = 2.0891e-01, time/batch = 18.6612s	
11522/22750 (epoch 25.323), train_loss = 0.94907705, grad/param norm = 2.1891e-01, time/batch = 18.0839s	
11523/22750 (epoch 25.325), train_loss = 0.80822687, grad/param norm = 2.0046e-01, time/batch = 18.9242s	
11524/22750 (epoch 25.327), train_loss = 0.89725587, grad/param norm = 2.2672e-01, time/batch = 19.4236s	
11525/22750 (epoch 25.330), train_loss = 1.09867035, grad/param norm = 2.0908e-01, time/batch = 17.6708s	
11526/22750 (epoch 25.332), train_loss = 1.11244427, grad/param norm = 2.0636e-01, time/batch = 16.1138s	
11527/22750 (epoch 25.334), train_loss = 0.78329249, grad/param norm = 2.0051e-01, time/batch = 17.8410s	
11528/22750 (epoch 25.336), train_loss = 0.99877274, grad/param norm = 1.9816e-01, time/batch = 17.8513s	
11529/22750 (epoch 25.338), train_loss = 0.89617792, grad/param norm = 2.0250e-01, time/batch = 20.2127s	
11530/22750 (epoch 25.341), train_loss = 0.92172932, grad/param norm = 1.9569e-01, time/batch = 19.0223s	
11531/22750 (epoch 25.343), train_loss = 0.80163742, grad/param norm = 2.0568e-01, time/batch = 17.7436s	
11532/22750 (epoch 25.345), train_loss = 0.98135793, grad/param norm = 2.7333e-01, time/batch = 19.5898s	
11533/22750 (epoch 25.347), train_loss = 1.04676778, grad/param norm = 2.2151e-01, time/batch = 16.6747s	
11534/22750 (epoch 25.349), train_loss = 0.74676486, grad/param norm = 1.9929e-01, time/batch = 15.8207s	
11535/22750 (epoch 25.352), train_loss = 1.02168128, grad/param norm = 2.3800e-01, time/batch = 16.5064s	
11536/22750 (epoch 25.354), train_loss = 1.04143662, grad/param norm = 2.1794e-01, time/batch = 18.3335s	
11537/22750 (epoch 25.356), train_loss = 1.03369144, grad/param norm = 2.1441e-01, time/batch = 16.8638s	
11538/22750 (epoch 25.358), train_loss = 0.91319836, grad/param norm = 2.2687e-01, time/batch = 18.6171s	
11539/22750 (epoch 25.360), train_loss = 1.09722958, grad/param norm = 2.0465e-01, time/batch = 19.1819s	
11540/22750 (epoch 25.363), train_loss = 0.92260748, grad/param norm = 2.1926e-01, time/batch = 19.4274s	
11541/22750 (epoch 25.365), train_loss = 0.74802896, grad/param norm = 2.0959e-01, time/batch = 17.9981s	
11542/22750 (epoch 25.367), train_loss = 0.83356799, grad/param norm = 2.4159e-01, time/batch = 16.4814s	
11543/22750 (epoch 25.369), train_loss = 0.93323240, grad/param norm = 2.2124e-01, time/batch = 15.9164s	
11544/22750 (epoch 25.371), train_loss = 0.91845914, grad/param norm = 2.0451e-01, time/batch = 16.3165s	
11545/22750 (epoch 25.374), train_loss = 0.83719618, grad/param norm = 2.1014e-01, time/batch = 16.0050s	
11546/22750 (epoch 25.376), train_loss = 0.88250468, grad/param norm = 1.8824e-01, time/batch = 15.5207s	
11547/22750 (epoch 25.378), train_loss = 0.92162189, grad/param norm = 2.0916e-01, time/batch = 14.9894s	
11548/22750 (epoch 25.380), train_loss = 1.01772837, grad/param norm = 2.1496e-01, time/batch = 14.9236s	
11549/22750 (epoch 25.382), train_loss = 0.89192090, grad/param norm = 2.0251e-01, time/batch = 15.4641s	
11550/22750 (epoch 25.385), train_loss = 0.99963182, grad/param norm = 1.9949e-01, time/batch = 14.8965s	
11551/22750 (epoch 25.387), train_loss = 0.96376560, grad/param norm = 1.9802e-01, time/batch = 15.2166s	
11552/22750 (epoch 25.389), train_loss = 0.75372730, grad/param norm = 1.9707e-01, time/batch = 15.1098s	
11553/22750 (epoch 25.391), train_loss = 0.58033254, grad/param norm = 1.5803e-01, time/batch = 15.6753s	
11554/22750 (epoch 25.393), train_loss = 0.77361227, grad/param norm = 1.8698e-01, time/batch = 15.2030s	
11555/22750 (epoch 25.396), train_loss = 0.98847112, grad/param norm = 2.0884e-01, time/batch = 15.2817s	
11556/22750 (epoch 25.398), train_loss = 0.89633846, grad/param norm = 1.8458e-01, time/batch = 15.0572s	
11557/22750 (epoch 25.400), train_loss = 0.89796898, grad/param norm = 2.0873e-01, time/batch = 15.4589s	
11558/22750 (epoch 25.402), train_loss = 0.96241051, grad/param norm = 1.9841e-01, time/batch = 15.1561s	
11559/22750 (epoch 25.404), train_loss = 1.04460790, grad/param norm = 1.9678e-01, time/batch = 14.9099s	
11560/22750 (epoch 25.407), train_loss = 1.02273131, grad/param norm = 2.0750e-01, time/batch = 15.6075s	
11561/22750 (epoch 25.409), train_loss = 0.84619668, grad/param norm = 2.0510e-01, time/batch = 15.3910s	
11562/22750 (epoch 25.411), train_loss = 0.86345185, grad/param norm = 1.9629e-01, time/batch = 15.1318s	
11563/22750 (epoch 25.413), train_loss = 0.68985959, grad/param norm = 1.9051e-01, time/batch = 15.5946s	
11564/22750 (epoch 25.415), train_loss = 0.71199264, grad/param norm = 1.7864e-01, time/batch = 15.4445s	
11565/22750 (epoch 25.418), train_loss = 0.84647755, grad/param norm = 2.0363e-01, time/batch = 15.6088s	
11566/22750 (epoch 25.420), train_loss = 1.00955749, grad/param norm = 3.2489e-01, time/batch = 16.0042s	
11567/22750 (epoch 25.422), train_loss = 1.14409338, grad/param norm = 2.6034e-01, time/batch = 15.4496s	
11568/22750 (epoch 25.424), train_loss = 1.13325073, grad/param norm = 2.2874e-01, time/batch = 15.4553s	
11569/22750 (epoch 25.426), train_loss = 1.12819810, grad/param norm = 2.1842e-01, time/batch = 15.0692s	
11570/22750 (epoch 25.429), train_loss = 0.83975843, grad/param norm = 2.0644e-01, time/batch = 16.3912s	
11571/22750 (epoch 25.431), train_loss = 0.75451932, grad/param norm = 1.8718e-01, time/batch = 15.7608s	
11572/22750 (epoch 25.433), train_loss = 0.88138160, grad/param norm = 2.0799e-01, time/batch = 16.2558s	
11573/22750 (epoch 25.435), train_loss = 0.69353123, grad/param norm = 1.7510e-01, time/batch = 15.3638s	
11574/22750 (epoch 25.437), train_loss = 0.59854748, grad/param norm = 1.8159e-01, time/batch = 15.2882s	
11575/22750 (epoch 25.440), train_loss = 0.90091530, grad/param norm = 2.3901e-01, time/batch = 15.2970s	
11576/22750 (epoch 25.442), train_loss = 0.94577684, grad/param norm = 2.3659e-01, time/batch = 15.9304s	
11577/22750 (epoch 25.444), train_loss = 0.89063645, grad/param norm = 2.3723e-01, time/batch = 15.1236s	
11578/22750 (epoch 25.446), train_loss = 0.90616167, grad/param norm = 2.2766e-01, time/batch = 15.1292s	
11579/22750 (epoch 25.448), train_loss = 1.17957531, grad/param norm = 2.4645e-01, time/batch = 15.4288s	
11580/22750 (epoch 25.451), train_loss = 1.12898750, grad/param norm = 2.1993e-01, time/batch = 15.5476s	
11581/22750 (epoch 25.453), train_loss = 1.04550964, grad/param norm = 2.5777e-01, time/batch = 15.2400s	
11582/22750 (epoch 25.455), train_loss = 1.13170010, grad/param norm = 2.3495e-01, time/batch = 15.0675s	
11583/22750 (epoch 25.457), train_loss = 1.03837670, grad/param norm = 3.1607e-01, time/batch = 15.4748s	
11584/22750 (epoch 25.459), train_loss = 1.01335387, grad/param norm = 2.1591e-01, time/batch = 15.9367s	
11585/22750 (epoch 25.462), train_loss = 1.00501688, grad/param norm = 1.9568e-01, time/batch = 15.0634s	
11586/22750 (epoch 25.464), train_loss = 0.77072177, grad/param norm = 1.8053e-01, time/batch = 15.1391s	
11587/22750 (epoch 25.466), train_loss = 1.05011387, grad/param norm = 2.5238e-01, time/batch = 15.1105s	
11588/22750 (epoch 25.468), train_loss = 0.94946218, grad/param norm = 2.1278e-01, time/batch = 15.5258s	
11589/22750 (epoch 25.470), train_loss = 1.06984125, grad/param norm = 2.3047e-01, time/batch = 14.9710s	
11590/22750 (epoch 25.473), train_loss = 0.91887192, grad/param norm = 2.3024e-01, time/batch = 15.1265s	
11591/22750 (epoch 25.475), train_loss = 0.95753150, grad/param norm = 2.2175e-01, time/batch = 15.3032s	
11592/22750 (epoch 25.477), train_loss = 0.81501958, grad/param norm = 1.9294e-01, time/batch = 16.1807s	
11593/22750 (epoch 25.479), train_loss = 0.79982486, grad/param norm = 2.1043e-01, time/batch = 15.9123s	
11594/22750 (epoch 25.481), train_loss = 0.75639013, grad/param norm = 1.9309e-01, time/batch = 15.4675s	
11595/22750 (epoch 25.484), train_loss = 0.64245987, grad/param norm = 1.9603e-01, time/batch = 15.7066s	
11596/22750 (epoch 25.486), train_loss = 0.78033408, grad/param norm = 2.0392e-01, time/batch = 15.5428s	
11597/22750 (epoch 25.488), train_loss = 0.68353772, grad/param norm = 1.9427e-01, time/batch = 15.3703s	
11598/22750 (epoch 25.490), train_loss = 0.88757817, grad/param norm = 1.9615e-01, time/batch = 15.3651s	
11599/22750 (epoch 25.492), train_loss = 1.01810987, grad/param norm = 2.1758e-01, time/batch = 15.4501s	
11600/22750 (epoch 25.495), train_loss = 0.83375412, grad/param norm = 2.0629e-01, time/batch = 15.7661s	
11601/22750 (epoch 25.497), train_loss = 0.87999833, grad/param norm = 2.3026e-01, time/batch = 15.2869s	
11602/22750 (epoch 25.499), train_loss = 0.83780393, grad/param norm = 2.1206e-01, time/batch = 15.7061s	
11603/22750 (epoch 25.501), train_loss = 0.90415949, grad/param norm = 2.1633e-01, time/batch = 15.8056s	
11604/22750 (epoch 25.503), train_loss = 0.90823456, grad/param norm = 2.0843e-01, time/batch = 15.2344s	
11605/22750 (epoch 25.505), train_loss = 0.79460210, grad/param norm = 1.9367e-01, time/batch = 14.7489s	
11606/22750 (epoch 25.508), train_loss = 0.73857344, grad/param norm = 2.1347e-01, time/batch = 14.5810s	
11607/22750 (epoch 25.510), train_loss = 0.77822670, grad/param norm = 1.8865e-01, time/batch = 15.7685s	
11608/22750 (epoch 25.512), train_loss = 0.79852749, grad/param norm = 1.8740e-01, time/batch = 14.6490s	
11609/22750 (epoch 25.514), train_loss = 0.85191170, grad/param norm = 2.0060e-01, time/batch = 14.7963s	
11610/22750 (epoch 25.516), train_loss = 0.84338030, grad/param norm = 2.0251e-01, time/batch = 14.9666s	
11611/22750 (epoch 25.519), train_loss = 0.97559219, grad/param norm = 2.1808e-01, time/batch = 15.8517s	
11612/22750 (epoch 25.521), train_loss = 0.92640689, grad/param norm = 2.2066e-01, time/batch = 14.7228s	
11613/22750 (epoch 25.523), train_loss = 0.85230516, grad/param norm = 2.3174e-01, time/batch = 14.8120s	
11614/22750 (epoch 25.525), train_loss = 1.03327649, grad/param norm = 2.2651e-01, time/batch = 14.8304s	
11615/22750 (epoch 25.527), train_loss = 0.89280757, grad/param norm = 1.9679e-01, time/batch = 15.0637s	
11616/22750 (epoch 25.530), train_loss = 0.82752852, grad/param norm = 2.1261e-01, time/batch = 15.0624s	
11617/22750 (epoch 25.532), train_loss = 0.77045470, grad/param norm = 1.7194e-01, time/batch = 14.7254s	
11618/22750 (epoch 25.534), train_loss = 1.00720955, grad/param norm = 2.3426e-01, time/batch = 14.8099s	
11619/22750 (epoch 25.536), train_loss = 0.93858787, grad/param norm = 1.8665e-01, time/batch = 15.8377s	
11620/22750 (epoch 25.538), train_loss = 0.91547714, grad/param norm = 1.7747e-01, time/batch = 14.9551s	
11621/22750 (epoch 25.541), train_loss = 0.79855904, grad/param norm = 2.0768e-01, time/batch = 14.7262s	
11622/22750 (epoch 25.543), train_loss = 0.77844361, grad/param norm = 2.0526e-01, time/batch = 15.1194s	
11623/22750 (epoch 25.545), train_loss = 0.97955959, grad/param norm = 2.0142e-01, time/batch = 15.7034s	
11624/22750 (epoch 25.547), train_loss = 0.82088381, grad/param norm = 1.7435e-01, time/batch = 14.6434s	
11625/22750 (epoch 25.549), train_loss = 0.85989517, grad/param norm = 1.9267e-01, time/batch = 15.1419s	
11626/22750 (epoch 25.552), train_loss = 0.95596447, grad/param norm = 2.2770e-01, time/batch = 16.3842s	
11627/22750 (epoch 25.554), train_loss = 0.96164848, grad/param norm = 2.2010e-01, time/batch = 17.4182s	
11628/22750 (epoch 25.556), train_loss = 0.93190247, grad/param norm = 2.0658e-01, time/batch = 18.7678s	
11629/22750 (epoch 25.558), train_loss = 0.96704873, grad/param norm = 2.0454e-01, time/batch = 18.7404s	
11630/22750 (epoch 25.560), train_loss = 0.85681399, grad/param norm = 2.1047e-01, time/batch = 16.0644s	
11631/22750 (epoch 25.563), train_loss = 1.02166986, grad/param norm = 2.1961e-01, time/batch = 15.6053s	
11632/22750 (epoch 25.565), train_loss = 0.97192992, grad/param norm = 2.1745e-01, time/batch = 15.9335s	
11633/22750 (epoch 25.567), train_loss = 0.93524526, grad/param norm = 2.0564e-01, time/batch = 16.8630s	
11634/22750 (epoch 25.569), train_loss = 0.89486927, grad/param norm = 2.0261e-01, time/batch = 16.9239s	
11635/22750 (epoch 25.571), train_loss = 0.88132125, grad/param norm = 2.0433e-01, time/batch = 19.8595s	
11636/22750 (epoch 25.574), train_loss = 0.86958562, grad/param norm = 2.0810e-01, time/batch = 18.1188s	
11637/22750 (epoch 25.576), train_loss = 0.84380983, grad/param norm = 1.9611e-01, time/batch = 17.6914s	
11638/22750 (epoch 25.578), train_loss = 0.78353756, grad/param norm = 2.1575e-01, time/batch = 18.1060s	
11639/22750 (epoch 25.580), train_loss = 0.93964640, grad/param norm = 2.3554e-01, time/batch = 15.6864s	
11640/22750 (epoch 25.582), train_loss = 0.81863755, grad/param norm = 2.0011e-01, time/batch = 16.8838s	
11641/22750 (epoch 25.585), train_loss = 0.77105446, grad/param norm = 1.9551e-01, time/batch = 17.8435s	
11642/22750 (epoch 25.587), train_loss = 0.77610798, grad/param norm = 1.8862e-01, time/batch = 17.3475s	
11643/22750 (epoch 25.589), train_loss = 0.73618523, grad/param norm = 2.0272e-01, time/batch = 19.1774s	
11644/22750 (epoch 25.591), train_loss = 0.88151497, grad/param norm = 2.0417e-01, time/batch = 17.8359s	
11645/22750 (epoch 25.593), train_loss = 1.04815247, grad/param norm = 1.9018e-01, time/batch = 16.1167s	
11646/22750 (epoch 25.596), train_loss = 1.05389647, grad/param norm = 2.2912e-01, time/batch = 16.3939s	
11647/22750 (epoch 25.598), train_loss = 1.07339910, grad/param norm = 2.3408e-01, time/batch = 19.0952s	
11648/22750 (epoch 25.600), train_loss = 1.04106389, grad/param norm = 2.2766e-01, time/batch = 16.5580s	
11649/22750 (epoch 25.602), train_loss = 0.83540674, grad/param norm = 1.9724e-01, time/batch = 15.9246s	
11650/22750 (epoch 25.604), train_loss = 0.84622493, grad/param norm = 2.1309e-01, time/batch = 16.3532s	
11651/22750 (epoch 25.607), train_loss = 0.77005091, grad/param norm = 1.6251e-01, time/batch = 16.6541s	
11652/22750 (epoch 25.609), train_loss = 0.70961762, grad/param norm = 1.6577e-01, time/batch = 15.8408s	
11653/22750 (epoch 25.611), train_loss = 0.87218352, grad/param norm = 2.2179e-01, time/batch = 17.1827s	
11654/22750 (epoch 25.613), train_loss = 0.81478887, grad/param norm = 1.9312e-01, time/batch = 16.8438s	
11655/22750 (epoch 25.615), train_loss = 0.86131066, grad/param norm = 1.9628e-01, time/batch = 19.0365s	
11656/22750 (epoch 25.618), train_loss = 0.88060409, grad/param norm = 1.9436e-01, time/batch = 19.4404s	
11657/22750 (epoch 25.620), train_loss = 0.85193247, grad/param norm = 1.8080e-01, time/batch = 17.8600s	
11658/22750 (epoch 25.622), train_loss = 0.72544973, grad/param norm = 1.7223e-01, time/batch = 18.0796s	
11659/22750 (epoch 25.624), train_loss = 0.81940265, grad/param norm = 2.0388e-01, time/batch = 18.7497s	
11660/22750 (epoch 25.626), train_loss = 0.72145688, grad/param norm = 1.8501e-01, time/batch = 19.0075s	
11661/22750 (epoch 25.629), train_loss = 0.83672927, grad/param norm = 1.8324e-01, time/batch = 17.7243s	
11662/22750 (epoch 25.631), train_loss = 0.87992148, grad/param norm = 1.8808e-01, time/batch = 17.7573s	
11663/22750 (epoch 25.633), train_loss = 0.75831438, grad/param norm = 1.9054e-01, time/batch = 16.6397s	
11664/22750 (epoch 25.635), train_loss = 0.87655141, grad/param norm = 2.0112e-01, time/batch = 16.1996s	
11665/22750 (epoch 25.637), train_loss = 0.94306940, grad/param norm = 2.2591e-01, time/batch = 20.1786s	
11666/22750 (epoch 25.640), train_loss = 0.94203993, grad/param norm = 1.9278e-01, time/batch = 17.6719s	
11667/22750 (epoch 25.642), train_loss = 1.02251869, grad/param norm = 2.1130e-01, time/batch = 16.6494s	
11668/22750 (epoch 25.644), train_loss = 0.87814215, grad/param norm = 2.1718e-01, time/batch = 16.4825s	
11669/22750 (epoch 25.646), train_loss = 0.93296358, grad/param norm = 2.6572e-01, time/batch = 15.6635s	
11670/22750 (epoch 25.648), train_loss = 0.93920268, grad/param norm = 2.1067e-01, time/batch = 16.3360s	
11671/22750 (epoch 25.651), train_loss = 0.96458628, grad/param norm = 2.2513e-01, time/batch = 17.1679s	
11672/22750 (epoch 25.653), train_loss = 0.98747630, grad/param norm = 2.0844e-01, time/batch = 19.4947s	
11673/22750 (epoch 25.655), train_loss = 0.91117989, grad/param norm = 1.8802e-01, time/batch = 20.2626s	
11674/22750 (epoch 25.657), train_loss = 1.07378191, grad/param norm = 2.4096e-01, time/batch = 18.5237s	
11675/22750 (epoch 25.659), train_loss = 1.08348020, grad/param norm = 2.4211e-01, time/batch = 18.5281s	
11676/22750 (epoch 25.662), train_loss = 1.10219107, grad/param norm = 2.5929e-01, time/batch = 18.5758s	
11677/22750 (epoch 25.664), train_loss = 0.95657887, grad/param norm = 2.1535e-01, time/batch = 19.6528s	
11678/22750 (epoch 25.666), train_loss = 0.75952494, grad/param norm = 1.8882e-01, time/batch = 18.2417s	
11679/22750 (epoch 25.668), train_loss = 0.91594354, grad/param norm = 2.0479e-01, time/batch = 20.2361s	
11680/22750 (epoch 25.670), train_loss = 0.92291313, grad/param norm = 2.1736e-01, time/batch = 17.9980s	
11681/22750 (epoch 25.673), train_loss = 1.14408645, grad/param norm = 2.7864e-01, time/batch = 18.8101s	
11682/22750 (epoch 25.675), train_loss = 1.25452047, grad/param norm = 2.7771e-01, time/batch = 20.8470s	
11683/22750 (epoch 25.677), train_loss = 1.11625471, grad/param norm = 2.2606e-01, time/batch = 20.5234s	
11684/22750 (epoch 25.679), train_loss = 1.12060337, grad/param norm = 2.4624e-01, time/batch = 19.7484s	
11685/22750 (epoch 25.681), train_loss = 1.06982868, grad/param norm = 2.1424e-01, time/batch = 18.6755s	
11686/22750 (epoch 25.684), train_loss = 1.07703339, grad/param norm = 2.3231e-01, time/batch = 17.8280s	
11687/22750 (epoch 25.686), train_loss = 1.11129164, grad/param norm = 2.4936e-01, time/batch = 17.1806s	
11688/22750 (epoch 25.688), train_loss = 1.05160226, grad/param norm = 2.2098e-01, time/batch = 17.5892s	
11689/22750 (epoch 25.690), train_loss = 1.05053631, grad/param norm = 2.4897e-01, time/batch = 19.8152s	
11690/22750 (epoch 25.692), train_loss = 1.09048857, grad/param norm = 2.2959e-01, time/batch = 18.0817s	
11691/22750 (epoch 25.695), train_loss = 0.94908850, grad/param norm = 2.1023e-01, time/batch = 20.2816s	
11692/22750 (epoch 25.697), train_loss = 0.94476164, grad/param norm = 2.1465e-01, time/batch = 21.3459s	
11693/22750 (epoch 25.699), train_loss = 0.92047541, grad/param norm = 2.2311e-01, time/batch = 19.3359s	
11694/22750 (epoch 25.701), train_loss = 0.78437422, grad/param norm = 2.0123e-01, time/batch = 16.3943s	
11695/22750 (epoch 25.703), train_loss = 0.91129569, grad/param norm = 2.0214e-01, time/batch = 16.3488s	
11696/22750 (epoch 25.705), train_loss = 0.85552826, grad/param norm = 1.9115e-01, time/batch = 16.5990s	
11697/22750 (epoch 25.708), train_loss = 0.93239651, grad/param norm = 2.2956e-01, time/batch = 17.9016s	
11698/22750 (epoch 25.710), train_loss = 0.83433058, grad/param norm = 2.0779e-01, time/batch = 19.1421s	
11699/22750 (epoch 25.712), train_loss = 0.78817821, grad/param norm = 1.8956e-01, time/batch = 17.6865s	
11700/22750 (epoch 25.714), train_loss = 0.75595606, grad/param norm = 1.7371e-01, time/batch = 19.3298s	
11701/22750 (epoch 25.716), train_loss = 0.77704166, grad/param norm = 1.8447e-01, time/batch = 19.0972s	
11702/22750 (epoch 25.719), train_loss = 0.91463050, grad/param norm = 2.5183e-01, time/batch = 20.3507s	
11703/22750 (epoch 25.721), train_loss = 0.98925497, grad/param norm = 2.0492e-01, time/batch = 18.5138s	
11704/22750 (epoch 25.723), train_loss = 0.99733729, grad/param norm = 2.2911e-01, time/batch = 17.8204s	
11705/22750 (epoch 25.725), train_loss = 0.89880337, grad/param norm = 2.1897e-01, time/batch = 19.6667s	
11706/22750 (epoch 25.727), train_loss = 0.86300730, grad/param norm = 2.0072e-01, time/batch = 18.1650s	
11707/22750 (epoch 25.730), train_loss = 0.87042062, grad/param norm = 2.1668e-01, time/batch = 18.6697s	
11708/22750 (epoch 25.732), train_loss = 0.82644857, grad/param norm = 1.8699e-01, time/batch = 19.9046s	
11709/22750 (epoch 25.734), train_loss = 0.72772512, grad/param norm = 1.7355e-01, time/batch = 19.2436s	
11710/22750 (epoch 25.736), train_loss = 0.83889712, grad/param norm = 1.9623e-01, time/batch = 20.5927s	
11711/22750 (epoch 25.738), train_loss = 0.96968638, grad/param norm = 2.1512e-01, time/batch = 20.8441s	
11712/22750 (epoch 25.741), train_loss = 1.01476970, grad/param norm = 2.2455e-01, time/batch = 18.3329s	
11713/22750 (epoch 25.743), train_loss = 0.95186144, grad/param norm = 2.1477e-01, time/batch = 20.1558s	
11714/22750 (epoch 25.745), train_loss = 0.77153462, grad/param norm = 1.7981e-01, time/batch = 18.2484s	
11715/22750 (epoch 25.747), train_loss = 0.86662375, grad/param norm = 1.8704e-01, time/batch = 18.0928s	
11716/22750 (epoch 25.749), train_loss = 1.04633224, grad/param norm = 2.1414e-01, time/batch = 18.1673s	
11717/22750 (epoch 25.752), train_loss = 0.90907336, grad/param norm = 1.9747e-01, time/batch = 18.6746s	
11718/22750 (epoch 25.754), train_loss = 0.94560692, grad/param norm = 2.2583e-01, time/batch = 18.4980s	
11719/22750 (epoch 25.756), train_loss = 0.83597693, grad/param norm = 2.1147e-01, time/batch = 20.0201s	
11720/22750 (epoch 25.758), train_loss = 0.80899941, grad/param norm = 1.9073e-01, time/batch = 16.8770s	
11721/22750 (epoch 25.760), train_loss = 0.85830780, grad/param norm = 2.0865e-01, time/batch = 18.5879s	
11722/22750 (epoch 25.763), train_loss = 0.92728069, grad/param norm = 2.1519e-01, time/batch = 16.8810s	
11723/22750 (epoch 25.765), train_loss = 0.91978836, grad/param norm = 2.2021e-01, time/batch = 15.8283s	
11724/22750 (epoch 25.767), train_loss = 0.94766654, grad/param norm = 2.4443e-01, time/batch = 17.4146s	
11725/22750 (epoch 25.769), train_loss = 1.10444371, grad/param norm = 2.3210e-01, time/batch = 17.3263s	
11726/22750 (epoch 25.771), train_loss = 1.06322004, grad/param norm = 2.5515e-01, time/batch = 16.9345s	
11727/22750 (epoch 25.774), train_loss = 0.89510602, grad/param norm = 2.3133e-01, time/batch = 19.9293s	
11728/22750 (epoch 25.776), train_loss = 1.01227643, grad/param norm = 2.3101e-01, time/batch = 20.1882s	
11729/22750 (epoch 25.778), train_loss = 1.08879365, grad/param norm = 2.3533e-01, time/batch = 33.0507s	
11730/22750 (epoch 25.780), train_loss = 0.93533235, grad/param norm = 2.1406e-01, time/batch = 18.8315s	
11731/22750 (epoch 25.782), train_loss = 1.09311797, grad/param norm = 2.3058e-01, time/batch = 16.6440s	
11732/22750 (epoch 25.785), train_loss = 0.90055887, grad/param norm = 2.0599e-01, time/batch = 17.8374s	
11733/22750 (epoch 25.787), train_loss = 0.80023985, grad/param norm = 2.0976e-01, time/batch = 16.3380s	
11734/22750 (epoch 25.789), train_loss = 0.89584890, grad/param norm = 2.0512e-01, time/batch = 15.6033s	
11735/22750 (epoch 25.791), train_loss = 0.85649859, grad/param norm = 1.9096e-01, time/batch = 15.8495s	
11736/22750 (epoch 25.793), train_loss = 0.83415085, grad/param norm = 2.1530e-01, time/batch = 15.7871s	
11737/22750 (epoch 25.796), train_loss = 0.77281915, grad/param norm = 1.9512e-01, time/batch = 15.6387s	
11738/22750 (epoch 25.798), train_loss = 0.81286354, grad/param norm = 2.0403e-01, time/batch = 15.8725s	
11739/22750 (epoch 25.800), train_loss = 0.84301672, grad/param norm = 2.0628e-01, time/batch = 15.7682s	
11740/22750 (epoch 25.802), train_loss = 0.76475755, grad/param norm = 2.2963e-01, time/batch = 15.3602s	
11741/22750 (epoch 25.804), train_loss = 1.01573975, grad/param norm = 2.1680e-01, time/batch = 15.4386s	
11742/22750 (epoch 25.807), train_loss = 0.97128106, grad/param norm = 2.0703e-01, time/batch = 15.8438s	
11743/22750 (epoch 25.809), train_loss = 1.03242606, grad/param norm = 2.2082e-01, time/batch = 15.8494s	
11744/22750 (epoch 25.811), train_loss = 0.90188610, grad/param norm = 2.0629e-01, time/batch = 15.5977s	
11745/22750 (epoch 25.813), train_loss = 0.93681913, grad/param norm = 1.9434e-01, time/batch = 15.3675s	
11746/22750 (epoch 25.815), train_loss = 1.07503051, grad/param norm = 2.2394e-01, time/batch = 15.7794s	
11747/22750 (epoch 25.818), train_loss = 1.00477611, grad/param norm = 1.9141e-01, time/batch = 15.5441s	
11748/22750 (epoch 25.820), train_loss = 1.16416874, grad/param norm = 2.1171e-01, time/batch = 15.9384s	
11749/22750 (epoch 25.822), train_loss = 0.96870849, grad/param norm = 2.1315e-01, time/batch = 15.3826s	
11750/22750 (epoch 25.824), train_loss = 0.81522338, grad/param norm = 1.7998e-01, time/batch = 16.2780s	
11751/22750 (epoch 25.826), train_loss = 0.90282081, grad/param norm = 2.2395e-01, time/batch = 16.4186s	
11752/22750 (epoch 25.829), train_loss = 1.06477795, grad/param norm = 2.1831e-01, time/batch = 16.1920s	
11753/22750 (epoch 25.831), train_loss = 1.01652629, grad/param norm = 2.2148e-01, time/batch = 15.9273s	
11754/22750 (epoch 25.833), train_loss = 0.94387809, grad/param norm = 2.1446e-01, time/batch = 17.1052s	
11755/22750 (epoch 25.835), train_loss = 0.83892885, grad/param norm = 1.9926e-01, time/batch = 15.6611s	
11756/22750 (epoch 25.837), train_loss = 0.90383394, grad/param norm = 2.0757e-01, time/batch = 15.9345s	
11757/22750 (epoch 25.840), train_loss = 0.79668837, grad/param norm = 1.7938e-01, time/batch = 16.1024s	
11758/22750 (epoch 25.842), train_loss = 0.86227617, grad/param norm = 2.1055e-01, time/batch = 15.7192s	
11759/22750 (epoch 25.844), train_loss = 0.96420991, grad/param norm = 2.1954e-01, time/batch = 15.8784s	
11760/22750 (epoch 25.846), train_loss = 0.93778211, grad/param norm = 1.9383e-01, time/batch = 15.5325s	
11761/22750 (epoch 25.848), train_loss = 0.82861475, grad/param norm = 1.7299e-01, time/batch = 16.1735s	
11762/22750 (epoch 25.851), train_loss = 0.80151045, grad/param norm = 1.8233e-01, time/batch = 15.7713s	
11763/22750 (epoch 25.853), train_loss = 0.98657355, grad/param norm = 2.0604e-01, time/batch = 15.5236s	
11764/22750 (epoch 25.855), train_loss = 0.83816416, grad/param norm = 1.9472e-01, time/batch = 15.4434s	
11765/22750 (epoch 25.857), train_loss = 0.95433738, grad/param norm = 1.9738e-01, time/batch = 16.0144s	
11766/22750 (epoch 25.859), train_loss = 0.99085248, grad/param norm = 2.2739e-01, time/batch = 16.0042s	
11767/22750 (epoch 25.862), train_loss = 1.10108752, grad/param norm = 2.2832e-01, time/batch = 15.6902s	
11768/22750 (epoch 25.864), train_loss = 0.91197146, grad/param norm = 2.0682e-01, time/batch = 15.4621s	
11769/22750 (epoch 25.866), train_loss = 0.94840213, grad/param norm = 1.7247e-01, time/batch = 16.0331s	
11770/22750 (epoch 25.868), train_loss = 0.84198041, grad/param norm = 1.9923e-01, time/batch = 15.5489s	
11771/22750 (epoch 25.870), train_loss = 0.75891994, grad/param norm = 1.8677e-01, time/batch = 16.0054s	
11772/22750 (epoch 25.873), train_loss = 0.87449879, grad/param norm = 1.7931e-01, time/batch = 15.6841s	
11773/22750 (epoch 25.875), train_loss = 0.98881148, grad/param norm = 2.1169e-01, time/batch = 15.9338s	
11774/22750 (epoch 25.877), train_loss = 0.82556141, grad/param norm = 2.0542e-01, time/batch = 15.6089s	
11775/22750 (epoch 25.879), train_loss = 1.04557369, grad/param norm = 2.0900e-01, time/batch = 15.5277s	
11776/22750 (epoch 25.881), train_loss = 0.96537919, grad/param norm = 2.0081e-01, time/batch = 16.0020s	
11777/22750 (epoch 25.884), train_loss = 0.85156395, grad/param norm = 1.9353e-01, time/batch = 16.3115s	
11778/22750 (epoch 25.886), train_loss = 0.97660923, grad/param norm = 2.0379e-01, time/batch = 16.3395s	
11779/22750 (epoch 25.888), train_loss = 0.99655060, grad/param norm = 1.8541e-01, time/batch = 16.0537s	
11780/22750 (epoch 25.890), train_loss = 0.98745566, grad/param norm = 2.0660e-01, time/batch = 16.3493s	
11781/22750 (epoch 25.892), train_loss = 1.22352526, grad/param norm = 2.3339e-01, time/batch = 16.1105s	
11782/22750 (epoch 25.895), train_loss = 0.91763986, grad/param norm = 2.1806e-01, time/batch = 16.6545s	
11783/22750 (epoch 25.897), train_loss = 1.00345655, grad/param norm = 2.1331e-01, time/batch = 16.2561s	
11784/22750 (epoch 25.899), train_loss = 0.98401288, grad/param norm = 2.0933e-01, time/batch = 16.4093s	
11785/22750 (epoch 25.901), train_loss = 1.05444224, grad/param norm = 2.3686e-01, time/batch = 16.4754s	
11786/22750 (epoch 25.903), train_loss = 0.90794509, grad/param norm = 2.0108e-01, time/batch = 15.6208s	
11787/22750 (epoch 25.905), train_loss = 1.00070413, grad/param norm = 2.0106e-01, time/batch = 15.6867s	
11788/22750 (epoch 25.908), train_loss = 0.84762896, grad/param norm = 2.2718e-01, time/batch = 15.6979s	
11789/22750 (epoch 25.910), train_loss = 0.71564943, grad/param norm = 1.8609e-01, time/batch = 15.5995s	
11790/22750 (epoch 25.912), train_loss = 0.87657327, grad/param norm = 1.9748e-01, time/batch = 15.7051s	
11791/22750 (epoch 25.914), train_loss = 0.92381534, grad/param norm = 2.0111e-01, time/batch = 16.0197s	
11792/22750 (epoch 25.916), train_loss = 0.75101596, grad/param norm = 1.9969e-01, time/batch = 16.0726s	
11793/22750 (epoch 25.919), train_loss = 0.89518046, grad/param norm = 2.7922e-01, time/batch = 15.7614s	
11794/22750 (epoch 25.921), train_loss = 0.70228887, grad/param norm = 1.7110e-01, time/batch = 15.5962s	
11795/22750 (epoch 25.923), train_loss = 0.82383577, grad/param norm = 1.8366e-01, time/batch = 15.9142s	
11796/22750 (epoch 25.925), train_loss = 0.86599149, grad/param norm = 1.7909e-01, time/batch = 15.5303s	
11797/22750 (epoch 25.927), train_loss = 0.73148860, grad/param norm = 2.0985e-01, time/batch = 15.3595s	
11798/22750 (epoch 25.930), train_loss = 0.70959087, grad/param norm = 1.7067e-01, time/batch = 15.4417s	
11799/22750 (epoch 25.932), train_loss = 0.91798525, grad/param norm = 2.1056e-01, time/batch = 16.0228s	
11800/22750 (epoch 25.934), train_loss = 0.73151377, grad/param norm = 1.7099e-01, time/batch = 15.2966s	
11801/22750 (epoch 25.936), train_loss = 1.01232832, grad/param norm = 2.1389e-01, time/batch = 15.5474s	
11802/22750 (epoch 25.938), train_loss = 1.00261932, grad/param norm = 1.8967e-01, time/batch = 15.5334s	
11803/22750 (epoch 25.941), train_loss = 1.07663795, grad/param norm = 2.1954e-01, time/batch = 15.9255s	
11804/22750 (epoch 25.943), train_loss = 0.92662326, grad/param norm = 2.1241e-01, time/batch = 16.4744s	
11805/22750 (epoch 25.945), train_loss = 0.93616926, grad/param norm = 2.2841e-01, time/batch = 16.0878s	
11806/22750 (epoch 25.947), train_loss = 0.87998316, grad/param norm = 2.1177e-01, time/batch = 16.0134s	
11807/22750 (epoch 25.949), train_loss = 0.81882828, grad/param norm = 1.9045e-01, time/batch = 15.7785s	
11808/22750 (epoch 25.952), train_loss = 0.83737509, grad/param norm = 1.8056e-01, time/batch = 17.5734s	
11809/22750 (epoch 25.954), train_loss = 0.81222248, grad/param norm = 1.7949e-01, time/batch = 19.9178s	
11810/22750 (epoch 25.956), train_loss = 0.94050411, grad/param norm = 1.9319e-01, time/batch = 17.9470s	
11811/22750 (epoch 25.958), train_loss = 0.84941205, grad/param norm = 1.7345e-01, time/batch = 18.7689s	
11812/22750 (epoch 25.960), train_loss = 0.81407017, grad/param norm = 2.0744e-01, time/batch = 19.1151s	
11813/22750 (epoch 25.963), train_loss = 0.93484146, grad/param norm = 2.0446e-01, time/batch = 17.3289s	
11814/22750 (epoch 25.965), train_loss = 0.99032954, grad/param norm = 1.9946e-01, time/batch = 18.5110s	
11815/22750 (epoch 25.967), train_loss = 0.93798541, grad/param norm = 2.0724e-01, time/batch = 17.9888s	
11816/22750 (epoch 25.969), train_loss = 0.85502632, grad/param norm = 2.0950e-01, time/batch = 17.8364s	
11817/22750 (epoch 25.971), train_loss = 0.82797996, grad/param norm = 1.8838e-01, time/batch = 18.9151s	
11818/22750 (epoch 25.974), train_loss = 0.87086625, grad/param norm = 2.0780e-01, time/batch = 19.7583s	
11819/22750 (epoch 25.976), train_loss = 0.91564089, grad/param norm = 2.1305e-01, time/batch = 18.8115s	
11820/22750 (epoch 25.978), train_loss = 0.84630863, grad/param norm = 1.9833e-01, time/batch = 20.7002s	
11821/22750 (epoch 25.980), train_loss = 1.03035626, grad/param norm = 2.4275e-01, time/batch = 19.3590s	
11822/22750 (epoch 25.982), train_loss = 0.82346232, grad/param norm = 1.8535e-01, time/batch = 19.5101s	
11823/22750 (epoch 25.985), train_loss = 1.04523055, grad/param norm = 2.1837e-01, time/batch = 19.5809s	
11824/22750 (epoch 25.987), train_loss = 0.72812148, grad/param norm = 1.7632e-01, time/batch = 17.5586s	
11825/22750 (epoch 25.989), train_loss = 0.86229066, grad/param norm = 2.3095e-01, time/batch = 15.9930s	
11826/22750 (epoch 25.991), train_loss = 0.94353427, grad/param norm = 2.0322e-01, time/batch = 16.0774s	
11827/22750 (epoch 25.993), train_loss = 0.94816269, grad/param norm = 2.5369e-01, time/batch = 16.2568s	
11828/22750 (epoch 25.996), train_loss = 0.84167412, grad/param norm = 2.2502e-01, time/batch = 15.6052s	
11829/22750 (epoch 25.998), train_loss = 1.02602691, grad/param norm = 2.2276e-01, time/batch = 15.9285s	
decayed learning rate by a factor 0.97 to 0.0011916520877176	
11830/22750 (epoch 26.000), train_loss = 0.91746393, grad/param norm = 2.1103e-01, time/batch = 15.5565s	
11831/22750 (epoch 26.002), train_loss = 1.06588200, grad/param norm = 2.0878e-01, time/batch = 14.9224s	
11832/22750 (epoch 26.004), train_loss = 0.85501542, grad/param norm = 1.9755e-01, time/batch = 15.2366s	
11833/22750 (epoch 26.007), train_loss = 0.86732570, grad/param norm = 2.0547e-01, time/batch = 16.0693s	
11834/22750 (epoch 26.009), train_loss = 1.06998467, grad/param norm = 2.4925e-01, time/batch = 15.8513s	
11835/22750 (epoch 26.011), train_loss = 1.14037137, grad/param norm = 2.4181e-01, time/batch = 16.0207s	
11836/22750 (epoch 26.013), train_loss = 1.04058704, grad/param norm = 2.3420e-01, time/batch = 16.4009s	
11837/22750 (epoch 26.015), train_loss = 0.93917970, grad/param norm = 2.2139e-01, time/batch = 16.3191s	
11838/22750 (epoch 26.018), train_loss = 0.99349684, grad/param norm = 2.3660e-01, time/batch = 15.7511s	
11839/22750 (epoch 26.020), train_loss = 1.04657648, grad/param norm = 2.1610e-01, time/batch = 15.7801s	
11840/22750 (epoch 26.022), train_loss = 0.92038811, grad/param norm = 2.1068e-01, time/batch = 15.7054s	
11841/22750 (epoch 26.024), train_loss = 0.92638852, grad/param norm = 2.1391e-01, time/batch = 16.1251s	
11842/22750 (epoch 26.026), train_loss = 0.98583216, grad/param norm = 2.3652e-01, time/batch = 16.4078s	
11843/22750 (epoch 26.029), train_loss = 0.76762471, grad/param norm = 2.0227e-01, time/batch = 15.2264s	
11844/22750 (epoch 26.031), train_loss = 1.15726941, grad/param norm = 2.1982e-01, time/batch = 15.3673s	
11845/22750 (epoch 26.033), train_loss = 0.93358148, grad/param norm = 2.1476e-01, time/batch = 15.4496s	
11846/22750 (epoch 26.035), train_loss = 0.96698199, grad/param norm = 1.9572e-01, time/batch = 15.1236s	
11847/22750 (epoch 26.037), train_loss = 1.02055706, grad/param norm = 1.9009e-01, time/batch = 15.0503s	
11848/22750 (epoch 26.040), train_loss = 0.89352230, grad/param norm = 1.9650e-01, time/batch = 15.7703s	
11849/22750 (epoch 26.042), train_loss = 0.96118093, grad/param norm = 2.1223e-01, time/batch = 16.1670s	
11850/22750 (epoch 26.044), train_loss = 0.88812156, grad/param norm = 2.1587e-01, time/batch = 15.9181s	
11851/22750 (epoch 26.046), train_loss = 1.03089409, grad/param norm = 2.3054e-01, time/batch = 15.4787s	
11852/22750 (epoch 26.048), train_loss = 0.92582160, grad/param norm = 1.8950e-01, time/batch = 15.6215s	
11853/22750 (epoch 26.051), train_loss = 0.95461214, grad/param norm = 2.0785e-01, time/batch = 15.9570s	
11854/22750 (epoch 26.053), train_loss = 0.85015484, grad/param norm = 1.7000e-01, time/batch = 15.2252s	
11855/22750 (epoch 26.055), train_loss = 0.80786645, grad/param norm = 1.9930e-01, time/batch = 15.3826s	
11856/22750 (epoch 26.057), train_loss = 1.09409278, grad/param norm = 2.2032e-01, time/batch = 15.9131s	
11857/22750 (epoch 26.059), train_loss = 0.69849446, grad/param norm = 2.0058e-01, time/batch = 15.9341s	
11858/22750 (epoch 26.062), train_loss = 0.78407172, grad/param norm = 1.9126e-01, time/batch = 15.7791s	
11859/22750 (epoch 26.064), train_loss = 0.98789693, grad/param norm = 2.1917e-01, time/batch = 15.7746s	
11860/22750 (epoch 26.066), train_loss = 0.80796363, grad/param norm = 1.8278e-01, time/batch = 16.2378s	
11861/22750 (epoch 26.068), train_loss = 0.83631446, grad/param norm = 1.8022e-01, time/batch = 15.7203s	
11862/22750 (epoch 26.070), train_loss = 0.71527467, grad/param norm = 1.8350e-01, time/batch = 15.4703s	
11863/22750 (epoch 26.073), train_loss = 0.85593048, grad/param norm = 2.0411e-01, time/batch = 15.1542s	
11864/22750 (epoch 26.075), train_loss = 0.89264178, grad/param norm = 1.8929e-01, time/batch = 15.5435s	
11865/22750 (epoch 26.077), train_loss = 0.68113822, grad/param norm = 2.0666e-01, time/batch = 15.2122s	
11866/22750 (epoch 26.079), train_loss = 0.86487899, grad/param norm = 2.1103e-01, time/batch = 15.4388s	
11867/22750 (epoch 26.081), train_loss = 0.88806940, grad/param norm = 2.1890e-01, time/batch = 15.6913s	
11868/22750 (epoch 26.084), train_loss = 0.86440065, grad/param norm = 2.0092e-01, time/batch = 15.3769s	
11869/22750 (epoch 26.086), train_loss = 0.89166505, grad/param norm = 1.8369e-01, time/batch = 15.5372s	
11870/22750 (epoch 26.088), train_loss = 0.82574386, grad/param norm = 1.9020e-01, time/batch = 15.1329s	
11871/22750 (epoch 26.090), train_loss = 0.84359182, grad/param norm = 2.0415e-01, time/batch = 15.2984s	
11872/22750 (epoch 26.092), train_loss = 1.00426547, grad/param norm = 2.0538e-01, time/batch = 15.3923s	
11873/22750 (epoch 26.095), train_loss = 0.81834642, grad/param norm = 2.1078e-01, time/batch = 15.4716s	
11874/22750 (epoch 26.097), train_loss = 0.90401698, grad/param norm = 1.9460e-01, time/batch = 14.9116s	
11875/22750 (epoch 26.099), train_loss = 0.85067551, grad/param norm = 1.8610e-01, time/batch = 15.6226s	
11876/22750 (epoch 26.101), train_loss = 0.77287446, grad/param norm = 1.8989e-01, time/batch = 15.2844s	
11877/22750 (epoch 26.103), train_loss = 0.94850944, grad/param norm = 2.2116e-01, time/batch = 16.1606s	
11878/22750 (epoch 26.105), train_loss = 1.06405655, grad/param norm = 2.4568e-01, time/batch = 16.6608s	
11879/22750 (epoch 26.108), train_loss = 0.87716364, grad/param norm = 1.9974e-01, time/batch = 17.1427s	
11880/22750 (epoch 26.110), train_loss = 1.02852148, grad/param norm = 2.0861e-01, time/batch = 15.6123s	
11881/22750 (epoch 26.112), train_loss = 0.75490415, grad/param norm = 1.8061e-01, time/batch = 16.0121s	
11882/22750 (epoch 26.114), train_loss = 0.71418972, grad/param norm = 1.9888e-01, time/batch = 15.6121s	
11883/22750 (epoch 26.116), train_loss = 0.84488698, grad/param norm = 1.7463e-01, time/batch = 16.1747s	
11884/22750 (epoch 26.119), train_loss = 0.82973590, grad/param norm = 1.8023e-01, time/batch = 15.2360s	
11885/22750 (epoch 26.121), train_loss = 0.90135326, grad/param norm = 2.2674e-01, time/batch = 15.0695s	
11886/22750 (epoch 26.123), train_loss = 0.78426107, grad/param norm = 2.0297e-01, time/batch = 15.6834s	
11887/22750 (epoch 26.125), train_loss = 1.05119814, grad/param norm = 2.0166e-01, time/batch = 15.4594s	
11888/22750 (epoch 26.127), train_loss = 0.86377112, grad/param norm = 2.1233e-01, time/batch = 15.6139s	
11889/22750 (epoch 26.130), train_loss = 0.88797933, grad/param norm = 1.9552e-01, time/batch = 15.6100s	
11890/22750 (epoch 26.132), train_loss = 0.81703433, grad/param norm = 1.9214e-01, time/batch = 15.6197s	
11891/22750 (epoch 26.134), train_loss = 0.87544747, grad/param norm = 2.0982e-01, time/batch = 15.8576s	
11892/22750 (epoch 26.136), train_loss = 0.73378733, grad/param norm = 1.9471e-01, time/batch = 15.4567s	
11893/22750 (epoch 26.138), train_loss = 0.95537280, grad/param norm = 2.0480e-01, time/batch = 15.3137s	
11894/22750 (epoch 26.141), train_loss = 0.91641213, grad/param norm = 2.1380e-01, time/batch = 16.1224s	
11895/22750 (epoch 26.143), train_loss = 0.78808173, grad/param norm = 1.8290e-01, time/batch = 15.1517s	
11896/22750 (epoch 26.145), train_loss = 1.01577377, grad/param norm = 2.1073e-01, time/batch = 15.5557s	
11897/22750 (epoch 26.147), train_loss = 1.06176794, grad/param norm = 2.2173e-01, time/batch = 16.1630s	
11898/22750 (epoch 26.149), train_loss = 0.90168180, grad/param norm = 2.0198e-01, time/batch = 16.5489s	
11899/22750 (epoch 26.152), train_loss = 0.90166924, grad/param norm = 2.0420e-01, time/batch = 15.6688s	
11900/22750 (epoch 26.154), train_loss = 0.79990358, grad/param norm = 1.8141e-01, time/batch = 15.2997s	
11901/22750 (epoch 26.156), train_loss = 0.79932697, grad/param norm = 1.9128e-01, time/batch = 15.3830s	
11902/22750 (epoch 26.158), train_loss = 0.81784390, grad/param norm = 2.2106e-01, time/batch = 15.7086s	
11903/22750 (epoch 26.160), train_loss = 0.91935546, grad/param norm = 2.2788e-01, time/batch = 15.2918s	
11904/22750 (epoch 26.163), train_loss = 1.09028734, grad/param norm = 2.1992e-01, time/batch = 15.2198s	
11905/22750 (epoch 26.165), train_loss = 0.93837752, grad/param norm = 2.0104e-01, time/batch = 15.4507s	
11906/22750 (epoch 26.167), train_loss = 0.87579974, grad/param norm = 2.2969e-01, time/batch = 15.6221s	
11907/22750 (epoch 26.169), train_loss = 0.93219304, grad/param norm = 2.2700e-01, time/batch = 15.0716s	
11908/22750 (epoch 26.171), train_loss = 0.76525400, grad/param norm = 1.9061e-01, time/batch = 15.6266s	
11909/22750 (epoch 26.174), train_loss = 0.74095862, grad/param norm = 1.9151e-01, time/batch = 15.2374s	
11910/22750 (epoch 26.176), train_loss = 0.79689729, grad/param norm = 2.1086e-01, time/batch = 16.1477s	
11911/22750 (epoch 26.178), train_loss = 0.84007406, grad/param norm = 2.0012e-01, time/batch = 16.2493s	
11912/22750 (epoch 26.180), train_loss = 1.00690838, grad/param norm = 2.7032e-01, time/batch = 16.2014s	
11913/22750 (epoch 26.182), train_loss = 1.00555798, grad/param norm = 2.3409e-01, time/batch = 16.1894s	
11914/22750 (epoch 26.185), train_loss = 1.03565661, grad/param norm = 2.1911e-01, time/batch = 16.5451s	
11915/22750 (epoch 26.187), train_loss = 0.77549501, grad/param norm = 1.8557e-01, time/batch = 15.7027s	
11916/22750 (epoch 26.189), train_loss = 0.81178819, grad/param norm = 2.1386e-01, time/batch = 15.4008s	
11917/22750 (epoch 26.191), train_loss = 0.81610337, grad/param norm = 1.7651e-01, time/batch = 15.9551s	
11918/22750 (epoch 26.193), train_loss = 0.96825182, grad/param norm = 2.0087e-01, time/batch = 15.8712s	
11919/22750 (epoch 26.196), train_loss = 0.85980871, grad/param norm = 2.0627e-01, time/batch = 15.4644s	
11920/22750 (epoch 26.198), train_loss = 0.65465824, grad/param norm = 1.7266e-01, time/batch = 15.4944s	
11921/22750 (epoch 26.200), train_loss = 0.89427455, grad/param norm = 2.2099e-01, time/batch = 16.1409s	
11922/22750 (epoch 26.202), train_loss = 0.97506918, grad/param norm = 2.6248e-01, time/batch = 15.3111s	
11923/22750 (epoch 26.204), train_loss = 0.90150569, grad/param norm = 1.8517e-01, time/batch = 15.2318s	
11924/22750 (epoch 26.207), train_loss = 0.88435938, grad/param norm = 2.0261e-01, time/batch = 15.6766s	
11925/22750 (epoch 26.209), train_loss = 0.82623917, grad/param norm = 1.9351e-01, time/batch = 15.6914s	
11926/22750 (epoch 26.211), train_loss = 0.80652178, grad/param norm = 2.0464e-01, time/batch = 15.2113s	
11927/22750 (epoch 26.213), train_loss = 0.68984801, grad/param norm = 1.8798e-01, time/batch = 15.0518s	
11928/22750 (epoch 26.215), train_loss = 0.67651311, grad/param norm = 1.8541e-01, time/batch = 15.2867s	
11929/22750 (epoch 26.218), train_loss = 0.77788260, grad/param norm = 2.2221e-01, time/batch = 15.2204s	
11930/22750 (epoch 26.220), train_loss = 0.73391804, grad/param norm = 1.7724e-01, time/batch = 20.2796s	
11931/22750 (epoch 26.222), train_loss = 0.75261614, grad/param norm = 2.3012e-01, time/batch = 15.8719s	
11932/22750 (epoch 26.224), train_loss = 0.79958272, grad/param norm = 1.9514e-01, time/batch = 17.2068s	
11933/22750 (epoch 26.226), train_loss = 0.89573191, grad/param norm = 2.1349e-01, time/batch = 18.1954s	
11934/22750 (epoch 26.229), train_loss = 0.90920996, grad/param norm = 2.2989e-01, time/batch = 18.5183s	
11935/22750 (epoch 26.231), train_loss = 0.80068576, grad/param norm = 2.0214e-01, time/batch = 18.4220s	
11936/22750 (epoch 26.233), train_loss = 0.71350833, grad/param norm = 1.8438e-01, time/batch = 17.0570s	
11937/22750 (epoch 26.235), train_loss = 0.71802807, grad/param norm = 2.0290e-01, time/batch = 15.4208s	
11938/22750 (epoch 26.237), train_loss = 0.79052131, grad/param norm = 1.9575e-01, time/batch = 16.1154s	
11939/22750 (epoch 26.240), train_loss = 0.86385517, grad/param norm = 1.8660e-01, time/batch = 17.8588s	
11940/22750 (epoch 26.242), train_loss = 1.07291588, grad/param norm = 2.4295e-01, time/batch = 16.5393s	
11941/22750 (epoch 26.244), train_loss = 1.05207849, grad/param norm = 2.1014e-01, time/batch = 16.9972s	
11942/22750 (epoch 26.246), train_loss = 1.06508211, grad/param norm = 2.3954e-01, time/batch = 16.3889s	
11943/22750 (epoch 26.248), train_loss = 0.87258748, grad/param norm = 2.0950e-01, time/batch = 18.9096s	
11944/22750 (epoch 26.251), train_loss = 1.00586511, grad/param norm = 2.5066e-01, time/batch = 18.7589s	
11945/22750 (epoch 26.253), train_loss = 0.91828203, grad/param norm = 2.2358e-01, time/batch = 18.3160s	
11946/22750 (epoch 26.255), train_loss = 0.91162351, grad/param norm = 1.9629e-01, time/batch = 19.0009s	
11947/22750 (epoch 26.257), train_loss = 0.81909315, grad/param norm = 2.2380e-01, time/batch = 18.3587s	
11948/22750 (epoch 26.259), train_loss = 1.01361236, grad/param norm = 2.3574e-01, time/batch = 18.5241s	
11949/22750 (epoch 26.262), train_loss = 0.91102972, grad/param norm = 2.2753e-01, time/batch = 31.1268s	
11950/22750 (epoch 26.264), train_loss = 0.73487724, grad/param norm = 2.3978e-01, time/batch = 20.4232s	
11951/22750 (epoch 26.266), train_loss = 0.87983388, grad/param norm = 2.3137e-01, time/batch = 18.4577s	
11952/22750 (epoch 26.268), train_loss = 1.01686785, grad/param norm = 2.2652e-01, time/batch = 18.5419s	
11953/22750 (epoch 26.270), train_loss = 0.83381426, grad/param norm = 2.3410e-01, time/batch = 15.6911s	
11954/22750 (epoch 26.273), train_loss = 1.17250604, grad/param norm = 2.6372e-01, time/batch = 15.4534s	
11955/22750 (epoch 26.275), train_loss = 1.03727672, grad/param norm = 2.1225e-01, time/batch = 17.5994s	
11956/22750 (epoch 26.277), train_loss = 0.86659572, grad/param norm = 2.3754e-01, time/batch = 18.4194s	
11957/22750 (epoch 26.279), train_loss = 0.76750879, grad/param norm = 2.0209e-01, time/batch = 19.3359s	
11958/22750 (epoch 26.281), train_loss = 1.02416132, grad/param norm = 2.1323e-01, time/batch = 17.6729s	
11959/22750 (epoch 26.284), train_loss = 0.89088686, grad/param norm = 1.9502e-01, time/batch = 16.9335s	
11960/22750 (epoch 26.286), train_loss = 0.98029484, grad/param norm = 2.1762e-01, time/batch = 18.1051s	
11961/22750 (epoch 26.288), train_loss = 1.07334716, grad/param norm = 2.2544e-01, time/batch = 16.7800s	
11962/22750 (epoch 26.290), train_loss = 0.91988002, grad/param norm = 2.0477e-01, time/batch = 16.6164s	
11963/22750 (epoch 26.292), train_loss = 0.95265357, grad/param norm = 2.2164e-01, time/batch = 16.3527s	
11964/22750 (epoch 26.295), train_loss = 0.96285215, grad/param norm = 2.0754e-01, time/batch = 17.6143s	
11965/22750 (epoch 26.297), train_loss = 0.89540467, grad/param norm = 2.0678e-01, time/batch = 16.5923s	
11966/22750 (epoch 26.299), train_loss = 1.00393400, grad/param norm = 2.1890e-01, time/batch = 18.6078s	
11967/22750 (epoch 26.301), train_loss = 0.92288854, grad/param norm = 2.3146e-01, time/batch = 18.0247s	
11968/22750 (epoch 26.303), train_loss = 0.96087594, grad/param norm = 2.2503e-01, time/batch = 17.6709s	
11969/22750 (epoch 26.305), train_loss = 1.11787856, grad/param norm = 2.2849e-01, time/batch = 18.3388s	
11970/22750 (epoch 26.308), train_loss = 0.97452328, grad/param norm = 2.0424e-01, time/batch = 17.9322s	
11971/22750 (epoch 26.310), train_loss = 0.82292049, grad/param norm = 2.1644e-01, time/batch = 18.5273s	
11972/22750 (epoch 26.312), train_loss = 0.93193446, grad/param norm = 1.9741e-01, time/batch = 18.5188s	
11973/22750 (epoch 26.314), train_loss = 0.93104296, grad/param norm = 2.1662e-01, time/batch = 20.2021s	
11974/22750 (epoch 26.316), train_loss = 0.88585283, grad/param norm = 2.0818e-01, time/batch = 18.9307s	
11975/22750 (epoch 26.319), train_loss = 0.91021152, grad/param norm = 2.0720e-01, time/batch = 18.2427s	
11976/22750 (epoch 26.321), train_loss = 0.84959568, grad/param norm = 2.1562e-01, time/batch = 19.4143s	
11977/22750 (epoch 26.323), train_loss = 0.92775351, grad/param norm = 2.2692e-01, time/batch = 19.1746s	
11978/22750 (epoch 26.325), train_loss = 0.78331775, grad/param norm = 1.9351e-01, time/batch = 17.4345s	
11979/22750 (epoch 26.327), train_loss = 0.87419763, grad/param norm = 2.2493e-01, time/batch = 16.6626s	
11980/22750 (epoch 26.330), train_loss = 1.07724021, grad/param norm = 2.1535e-01, time/batch = 16.2640s	
11981/22750 (epoch 26.332), train_loss = 1.09234147, grad/param norm = 2.1341e-01, time/batch = 17.5144s	
11982/22750 (epoch 26.334), train_loss = 0.75428715, grad/param norm = 1.8187e-01, time/batch = 5.6267s	
11983/22750 (epoch 26.336), train_loss = 0.99128540, grad/param norm = 1.9747e-01, time/batch = 0.6978s	
11984/22750 (epoch 26.338), train_loss = 0.87368815, grad/param norm = 2.2539e-01, time/batch = 0.7086s	
11985/22750 (epoch 26.341), train_loss = 0.90957427, grad/param norm = 1.9484e-01, time/batch = 0.6894s	
11986/22750 (epoch 26.343), train_loss = 0.79155349, grad/param norm = 2.0882e-01, time/batch = 0.6907s	
11987/22750 (epoch 26.345), train_loss = 0.96749242, grad/param norm = 2.4395e-01, time/batch = 0.7021s	
11988/22750 (epoch 26.347), train_loss = 1.03153736, grad/param norm = 2.3627e-01, time/batch = 0.7054s	
11989/22750 (epoch 26.349), train_loss = 0.74655170, grad/param norm = 2.2392e-01, time/batch = 0.6963s	
11990/22750 (epoch 26.352), train_loss = 1.00864902, grad/param norm = 2.2452e-01, time/batch = 0.6947s	
11991/22750 (epoch 26.354), train_loss = 1.02957128, grad/param norm = 2.1731e-01, time/batch = 0.6853s	
11992/22750 (epoch 26.356), train_loss = 1.01016085, grad/param norm = 2.2094e-01, time/batch = 0.6836s	
11993/22750 (epoch 26.358), train_loss = 0.89258866, grad/param norm = 2.4476e-01, time/batch = 0.6997s	
11994/22750 (epoch 26.360), train_loss = 1.07327830, grad/param norm = 2.1162e-01, time/batch = 0.6894s	
11995/22750 (epoch 26.363), train_loss = 0.88556959, grad/param norm = 2.0596e-01, time/batch = 0.6854s	
11996/22750 (epoch 26.365), train_loss = 0.72509754, grad/param norm = 1.9623e-01, time/batch = 0.8061s	
11997/22750 (epoch 26.367), train_loss = 0.81820758, grad/param norm = 2.2150e-01, time/batch = 1.0047s	
11998/22750 (epoch 26.369), train_loss = 0.92281886, grad/param norm = 2.4402e-01, time/batch = 1.0068s	
11999/22750 (epoch 26.371), train_loss = 0.89814963, grad/param norm = 2.1551e-01, time/batch = 1.0014s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_wakata_epoch26.37_1.5897.t7	
12000/22750 (epoch 26.374), train_loss = 0.82384859, grad/param norm = 2.1715e-01, time/batch = 1.0373s	
12001/22750 (epoch 26.376), train_loss = 1.47030582, grad/param norm = 2.4831e-01, time/batch = 19.7623s	
12002/22750 (epoch 26.378), train_loss = 0.91905396, grad/param norm = 2.0145e-01, time/batch = 19.5039s	
12003/22750 (epoch 26.380), train_loss = 1.00671261, grad/param norm = 2.2335e-01, time/batch = 16.6912s	
12004/22750 (epoch 26.382), train_loss = 0.89798041, grad/param norm = 2.1795e-01, time/batch = 17.0844s	
12005/22750 (epoch 26.385), train_loss = 0.99759031, grad/param norm = 2.1739e-01, time/batch = 17.7505s	
12006/22750 (epoch 26.387), train_loss = 0.94728642, grad/param norm = 2.0182e-01, time/batch = 18.3422s	
12007/22750 (epoch 26.389), train_loss = 0.74385878, grad/param norm = 1.9553e-01, time/batch = 17.8206s	
12008/22750 (epoch 26.391), train_loss = 0.57544815, grad/param norm = 1.6120e-01, time/batch = 20.8699s	
12009/22750 (epoch 26.393), train_loss = 0.76071770, grad/param norm = 2.0434e-01, time/batch = 16.5492s	
12010/22750 (epoch 26.396), train_loss = 0.96220614, grad/param norm = 2.0105e-01, time/batch = 17.9450s	
12011/22750 (epoch 26.398), train_loss = 0.87902110, grad/param norm = 1.8943e-01, time/batch = 18.0812s	
12012/22750 (epoch 26.400), train_loss = 0.88601808, grad/param norm = 2.0627e-01, time/batch = 16.5604s	
12013/22750 (epoch 26.402), train_loss = 0.96332157, grad/param norm = 2.1209e-01, time/batch = 17.3001s	
12014/22750 (epoch 26.404), train_loss = 1.02177287, grad/param norm = 1.9565e-01, time/batch = 17.5091s	
12015/22750 (epoch 26.407), train_loss = 0.98542678, grad/param norm = 2.0445e-01, time/batch = 17.5018s	
12016/22750 (epoch 26.409), train_loss = 0.84131547, grad/param norm = 2.1626e-01, time/batch = 16.9817s	
12017/22750 (epoch 26.411), train_loss = 0.85241748, grad/param norm = 1.9979e-01, time/batch = 18.7550s	
12018/22750 (epoch 26.413), train_loss = 0.67571584, grad/param norm = 1.8886e-01, time/batch = 18.7658s	
12019/22750 (epoch 26.415), train_loss = 0.69515963, grad/param norm = 1.7178e-01, time/batch = 19.6036s	
12020/22750 (epoch 26.418), train_loss = 0.83024962, grad/param norm = 2.0963e-01, time/batch = 18.6022s	
12021/22750 (epoch 26.420), train_loss = 0.98498903, grad/param norm = 2.5603e-01, time/batch = 20.2675s	
12022/22750 (epoch 26.422), train_loss = 1.13182242, grad/param norm = 2.6035e-01, time/batch = 17.2336s	
12023/22750 (epoch 26.424), train_loss = 1.10077660, grad/param norm = 2.4969e-01, time/batch = 19.0909s	
12024/22750 (epoch 26.426), train_loss = 1.09673566, grad/param norm = 2.1640e-01, time/batch = 19.1682s	
12025/22750 (epoch 26.429), train_loss = 0.82250407, grad/param norm = 2.0496e-01, time/batch = 19.2400s	
12026/22750 (epoch 26.431), train_loss = 0.74589274, grad/param norm = 2.0787e-01, time/batch = 17.7381s	
12027/22750 (epoch 26.433), train_loss = 0.85469086, grad/param norm = 1.9538e-01, time/batch = 19.4899s	
12028/22750 (epoch 26.435), train_loss = 0.68057110, grad/param norm = 1.6906e-01, time/batch = 19.4251s	
12029/22750 (epoch 26.437), train_loss = 0.59214673, grad/param norm = 1.8337e-01, time/batch = 17.6733s	
12030/22750 (epoch 26.440), train_loss = 0.87731591, grad/param norm = 2.2868e-01, time/batch = 18.2626s	
12031/22750 (epoch 26.442), train_loss = 0.92434864, grad/param norm = 2.1514e-01, time/batch = 20.8358s	
12032/22750 (epoch 26.444), train_loss = 0.87226313, grad/param norm = 2.3931e-01, time/batch = 18.9110s	
12033/22750 (epoch 26.446), train_loss = 0.90906965, grad/param norm = 2.3352e-01, time/batch = 20.2414s	
12034/22750 (epoch 26.448), train_loss = 1.16365228, grad/param norm = 2.4309e-01, time/batch = 19.9099s	
12035/22750 (epoch 26.451), train_loss = 1.11138742, grad/param norm = 2.1306e-01, time/batch = 18.7515s	
12036/22750 (epoch 26.453), train_loss = 1.00397314, grad/param norm = 2.3222e-01, time/batch = 20.1553s	
12037/22750 (epoch 26.455), train_loss = 1.12201747, grad/param norm = 2.3835e-01, time/batch = 15.6213s	
12038/22750 (epoch 26.457), train_loss = 0.99021248, grad/param norm = 3.3624e-01, time/batch = 16.6851s	
12039/22750 (epoch 26.459), train_loss = 0.98668066, grad/param norm = 2.0295e-01, time/batch = 17.1854s	
12040/22750 (epoch 26.462), train_loss = 0.97262155, grad/param norm = 1.9204e-01, time/batch = 18.9215s	
12041/22750 (epoch 26.464), train_loss = 0.74936715, grad/param norm = 1.9383e-01, time/batch = 19.7748s	
12042/22750 (epoch 26.466), train_loss = 1.02884775, grad/param norm = 2.4697e-01, time/batch = 16.9636s	
12043/22750 (epoch 26.468), train_loss = 0.92375236, grad/param norm = 2.1506e-01, time/batch = 16.9170s	
12044/22750 (epoch 26.470), train_loss = 1.04533881, grad/param norm = 2.7513e-01, time/batch = 16.9229s	
12045/22750 (epoch 26.473), train_loss = 0.91157595, grad/param norm = 2.1265e-01, time/batch = 17.6444s	
12046/22750 (epoch 26.475), train_loss = 0.93309169, grad/param norm = 2.1573e-01, time/batch = 18.5830s	
12047/22750 (epoch 26.477), train_loss = 0.79939779, grad/param norm = 2.0586e-01, time/batch = 19.2564s	
12048/22750 (epoch 26.479), train_loss = 0.77628143, grad/param norm = 1.9141e-01, time/batch = 18.9135s	
12049/22750 (epoch 26.481), train_loss = 0.74547273, grad/param norm = 1.8406e-01, time/batch = 19.2464s	
12050/22750 (epoch 26.484), train_loss = 0.62839267, grad/param norm = 1.9621e-01, time/batch = 19.2007s	
12051/22750 (epoch 26.486), train_loss = 0.77017014, grad/param norm = 2.0147e-01, time/batch = 17.8553s	
12052/22750 (epoch 26.488), train_loss = 0.67932646, grad/param norm = 2.0027e-01, time/batch = 19.2652s	
12053/22750 (epoch 26.490), train_loss = 0.87635938, grad/param norm = 2.0617e-01, time/batch = 19.1783s	
12054/22750 (epoch 26.492), train_loss = 0.99630107, grad/param norm = 2.1991e-01, time/batch = 18.1686s	
12055/22750 (epoch 26.495), train_loss = 0.81481179, grad/param norm = 1.9333e-01, time/batch = 17.7349s	
12056/22750 (epoch 26.497), train_loss = 0.86939093, grad/param norm = 2.1220e-01, time/batch = 19.9989s	
12057/22750 (epoch 26.499), train_loss = 0.82132216, grad/param norm = 2.0092e-01, time/batch = 19.6525s	
12058/22750 (epoch 26.501), train_loss = 0.87751692, grad/param norm = 1.9638e-01, time/batch = 17.8347s	
12059/22750 (epoch 26.503), train_loss = 0.89180441, grad/param norm = 2.1549e-01, time/batch = 20.8371s	
12060/22750 (epoch 26.505), train_loss = 0.77560656, grad/param norm = 1.8468e-01, time/batch = 20.7657s	
12061/22750 (epoch 26.508), train_loss = 0.71498241, grad/param norm = 1.8302e-01, time/batch = 18.6609s	
12062/22750 (epoch 26.510), train_loss = 0.76718221, grad/param norm = 1.9682e-01, time/batch = 19.1856s	
12063/22750 (epoch 26.512), train_loss = 0.79003635, grad/param norm = 1.9419e-01, time/batch = 16.6802s	
12064/22750 (epoch 26.514), train_loss = 0.84080711, grad/param norm = 2.0317e-01, time/batch = 16.4984s	
12065/22750 (epoch 26.516), train_loss = 0.83531347, grad/param norm = 2.1385e-01, time/batch = 16.6691s	
12066/22750 (epoch 26.519), train_loss = 0.93833214, grad/param norm = 1.9791e-01, time/batch = 17.4360s	
12067/22750 (epoch 26.521), train_loss = 0.90124686, grad/param norm = 2.1787e-01, time/batch = 16.4324s	
12068/22750 (epoch 26.523), train_loss = 0.83187979, grad/param norm = 2.2343e-01, time/batch = 15.6695s	
12069/22750 (epoch 26.525), train_loss = 1.02024638, grad/param norm = 2.2587e-01, time/batch = 16.4456s	
12070/22750 (epoch 26.527), train_loss = 0.88768515, grad/param norm = 2.0313e-01, time/batch = 17.8572s	
12071/22750 (epoch 26.530), train_loss = 0.80319757, grad/param norm = 2.1203e-01, time/batch = 16.7603s	
12072/22750 (epoch 26.532), train_loss = 0.75978075, grad/param norm = 1.7674e-01, time/batch = 16.1467s	
12073/22750 (epoch 26.534), train_loss = 0.97622989, grad/param norm = 2.2343e-01, time/batch = 16.2267s	
12074/22750 (epoch 26.536), train_loss = 0.92027131, grad/param norm = 1.9700e-01, time/batch = 19.3166s	
12075/22750 (epoch 26.538), train_loss = 0.90609984, grad/param norm = 1.8246e-01, time/batch = 16.6671s	
12076/22750 (epoch 26.541), train_loss = 0.76640898, grad/param norm = 1.9261e-01, time/batch = 17.9987s	
12077/22750 (epoch 26.543), train_loss = 0.78287580, grad/param norm = 2.0667e-01, time/batch = 15.8509s	
12078/22750 (epoch 26.545), train_loss = 0.96764256, grad/param norm = 2.0644e-01, time/batch = 16.6488s	
12079/22750 (epoch 26.547), train_loss = 0.80937860, grad/param norm = 1.8612e-01, time/batch = 21.0073s	
12080/22750 (epoch 26.549), train_loss = 0.85867198, grad/param norm = 1.9794e-01, time/batch = 20.0315s	
12081/22750 (epoch 26.552), train_loss = 0.92913718, grad/param norm = 2.0916e-01, time/batch = 18.5264s	
12082/22750 (epoch 26.554), train_loss = 0.94426448, grad/param norm = 2.3111e-01, time/batch = 20.2337s	
12083/22750 (epoch 26.556), train_loss = 0.92165042, grad/param norm = 2.1729e-01, time/batch = 19.1665s	
12084/22750 (epoch 26.558), train_loss = 0.95496992, grad/param norm = 2.1048e-01, time/batch = 17.9086s	
12085/22750 (epoch 26.560), train_loss = 0.85100565, grad/param norm = 2.2054e-01, time/batch = 20.0667s	
12086/22750 (epoch 26.563), train_loss = 1.00681721, grad/param norm = 2.2096e-01, time/batch = 19.2503s	
12087/22750 (epoch 26.565), train_loss = 0.94547921, grad/param norm = 2.1348e-01, time/batch = 18.0225s	
12088/22750 (epoch 26.567), train_loss = 0.92894349, grad/param norm = 2.0581e-01, time/batch = 20.9425s	
12089/22750 (epoch 26.569), train_loss = 0.87801057, grad/param norm = 2.1667e-01, time/batch = 17.5282s	
12090/22750 (epoch 26.571), train_loss = 0.86953395, grad/param norm = 2.1618e-01, time/batch = 19.6841s	
12091/22750 (epoch 26.574), train_loss = 0.86384778, grad/param norm = 2.1344e-01, time/batch = 17.8472s	
12092/22750 (epoch 26.576), train_loss = 0.82860852, grad/param norm = 2.0453e-01, time/batch = 17.7619s	
12093/22750 (epoch 26.578), train_loss = 0.75907756, grad/param norm = 2.0381e-01, time/batch = 17.4113s	
12094/22750 (epoch 26.580), train_loss = 0.93706902, grad/param norm = 2.3521e-01, time/batch = 17.3195s	
12095/22750 (epoch 26.582), train_loss = 0.82232868, grad/param norm = 2.2669e-01, time/batch = 16.1460s	
12096/22750 (epoch 26.585), train_loss = 0.75367100, grad/param norm = 1.9526e-01, time/batch = 15.8823s	
12097/22750 (epoch 26.587), train_loss = 0.77203879, grad/param norm = 2.0180e-01, time/batch = 16.8833s	
12098/22750 (epoch 26.589), train_loss = 0.72380331, grad/param norm = 1.8475e-01, time/batch = 16.0912s	
12099/22750 (epoch 26.591), train_loss = 0.86600987, grad/param norm = 1.9998e-01, time/batch = 15.4515s	
12100/22750 (epoch 26.593), train_loss = 1.03979183, grad/param norm = 2.2005e-01, time/batch = 15.2009s	
12101/22750 (epoch 26.596), train_loss = 1.01165219, grad/param norm = 2.2941e-01, time/batch = 17.5804s	
12102/22750 (epoch 26.598), train_loss = 1.03928523, grad/param norm = 2.3961e-01, time/batch = 17.4071s	
12103/22750 (epoch 26.600), train_loss = 1.02567147, grad/param norm = 2.3355e-01, time/batch = 16.2793s	
12104/22750 (epoch 26.602), train_loss = 0.81160323, grad/param norm = 1.8671e-01, time/batch = 16.6756s	
12105/22750 (epoch 26.604), train_loss = 0.81859902, grad/param norm = 2.0661e-01, time/batch = 16.8559s	
12106/22750 (epoch 26.607), train_loss = 0.76725004, grad/param norm = 1.7354e-01, time/batch = 18.9031s	
12107/22750 (epoch 26.609), train_loss = 0.70191452, grad/param norm = 1.6429e-01, time/batch = 20.7830s	
12108/22750 (epoch 26.611), train_loss = 0.83913952, grad/param norm = 2.0080e-01, time/batch = 18.1939s	
12109/22750 (epoch 26.613), train_loss = 0.80903534, grad/param norm = 1.9549e-01, time/batch = 19.4078s	
12110/22750 (epoch 26.615), train_loss = 0.84550648, grad/param norm = 1.9522e-01, time/batch = 18.4067s	
12111/22750 (epoch 26.618), train_loss = 0.85509766, grad/param norm = 1.8405e-01, time/batch = 18.2439s	
12112/22750 (epoch 26.620), train_loss = 0.83732144, grad/param norm = 1.9460e-01, time/batch = 17.7586s	
12113/22750 (epoch 26.622), train_loss = 0.70734206, grad/param norm = 1.8186e-01, time/batch = 19.0773s	
12114/22750 (epoch 26.624), train_loss = 0.80149959, grad/param norm = 1.9144e-01, time/batch = 18.6634s	
12115/22750 (epoch 26.626), train_loss = 0.70527743, grad/param norm = 1.8520e-01, time/batch = 18.1570s	
12116/22750 (epoch 26.629), train_loss = 0.81508581, grad/param norm = 1.8080e-01, time/batch = 19.6830s	
12117/22750 (epoch 26.631), train_loss = 0.85763859, grad/param norm = 1.8099e-01, time/batch = 18.7493s	
12118/22750 (epoch 26.633), train_loss = 0.72670690, grad/param norm = 1.9084e-01, time/batch = 18.2458s	
12119/22750 (epoch 26.635), train_loss = 0.85634209, grad/param norm = 1.9129e-01, time/batch = 17.4177s	
12120/22750 (epoch 26.637), train_loss = 0.93081713, grad/param norm = 2.4588e-01, time/batch = 17.6717s	
12121/22750 (epoch 26.640), train_loss = 0.93709873, grad/param norm = 1.9978e-01, time/batch = 18.4131s	
12122/22750 (epoch 26.642), train_loss = 1.00704956, grad/param norm = 2.0832e-01, time/batch = 16.6181s	
12123/22750 (epoch 26.644), train_loss = 0.85714099, grad/param norm = 2.1716e-01, time/batch = 17.8357s	
12124/22750 (epoch 26.646), train_loss = 0.92261532, grad/param norm = 2.5290e-01, time/batch = 15.6950s	
12125/22750 (epoch 26.648), train_loss = 0.93339650, grad/param norm = 2.2247e-01, time/batch = 15.3221s	
12126/22750 (epoch 26.651), train_loss = 0.97300662, grad/param norm = 2.4206e-01, time/batch = 16.0304s	
12127/22750 (epoch 26.653), train_loss = 0.96877270, grad/param norm = 2.0027e-01, time/batch = 15.1473s	
12128/22750 (epoch 26.655), train_loss = 0.89697200, grad/param norm = 1.9022e-01, time/batch = 15.7978s	
12129/22750 (epoch 26.657), train_loss = 1.05521576, grad/param norm = 2.2362e-01, time/batch = 15.2793s	
12130/22750 (epoch 26.659), train_loss = 1.05895412, grad/param norm = 2.1503e-01, time/batch = 15.2104s	
12131/22750 (epoch 26.662), train_loss = 1.07478091, grad/param norm = 2.6336e-01, time/batch = 15.6355s	
12132/22750 (epoch 26.664), train_loss = 0.94322568, grad/param norm = 2.0408e-01, time/batch = 16.2488s	
12133/22750 (epoch 26.666), train_loss = 0.75504232, grad/param norm = 2.0069e-01, time/batch = 15.7048s	
12134/22750 (epoch 26.668), train_loss = 0.91336672, grad/param norm = 2.2146e-01, time/batch = 16.5050s	
12135/22750 (epoch 26.670), train_loss = 0.90272179, grad/param norm = 2.1311e-01, time/batch = 15.6252s	
12136/22750 (epoch 26.673), train_loss = 1.12077882, grad/param norm = 2.5545e-01, time/batch = 16.2722s	
12137/22750 (epoch 26.675), train_loss = 1.24260671, grad/param norm = 2.4340e-01, time/batch = 15.3134s	
12138/22750 (epoch 26.677), train_loss = 1.08404733, grad/param norm = 2.3186e-01, time/batch = 15.0699s	
12139/22750 (epoch 26.679), train_loss = 1.07807663, grad/param norm = 2.3272e-01, time/batch = 15.2971s	
12140/22750 (epoch 26.681), train_loss = 1.05688596, grad/param norm = 2.2570e-01, time/batch = 15.5265s	
12141/22750 (epoch 26.684), train_loss = 1.06504582, grad/param norm = 2.4077e-01, time/batch = 15.2045s	
12142/22750 (epoch 26.686), train_loss = 1.09256573, grad/param norm = 2.6237e-01, time/batch = 15.0489s	
12143/22750 (epoch 26.688), train_loss = 1.03355511, grad/param norm = 2.1780e-01, time/batch = 15.2062s	
12144/22750 (epoch 26.690), train_loss = 1.03101721, grad/param norm = 2.2282e-01, time/batch = 15.2906s	
12145/22750 (epoch 26.692), train_loss = 1.06758820, grad/param norm = 2.2983e-01, time/batch = 14.8783s	
12146/22750 (epoch 26.695), train_loss = 0.93371529, grad/param norm = 2.1254e-01, time/batch = 15.0479s	
12147/22750 (epoch 26.697), train_loss = 0.94238520, grad/param norm = 2.5078e-01, time/batch = 15.4741s	
12148/22750 (epoch 26.699), train_loss = 0.89313184, grad/param norm = 2.1319e-01, time/batch = 15.3032s	
12149/22750 (epoch 26.701), train_loss = 0.78379864, grad/param norm = 1.9485e-01, time/batch = 15.1581s	
12150/22750 (epoch 26.703), train_loss = 0.88169045, grad/param norm = 2.0646e-01, time/batch = 15.0764s	
12151/22750 (epoch 26.705), train_loss = 0.84962701, grad/param norm = 2.1486e-01, time/batch = 15.5378s	
12152/22750 (epoch 26.708), train_loss = 0.93162153, grad/param norm = 2.1844e-01, time/batch = 15.4590s	
12153/22750 (epoch 26.710), train_loss = 0.81942489, grad/param norm = 2.2232e-01, time/batch = 15.3650s	
12154/22750 (epoch 26.712), train_loss = 0.78296975, grad/param norm = 2.1188e-01, time/batch = 16.3168s	
12155/22750 (epoch 26.714), train_loss = 0.74116805, grad/param norm = 1.7178e-01, time/batch = 15.6885s	
12156/22750 (epoch 26.716), train_loss = 0.76844670, grad/param norm = 1.9009e-01, time/batch = 15.3680s	
12157/22750 (epoch 26.719), train_loss = 0.88118395, grad/param norm = 2.4203e-01, time/batch = 15.3766s	
12158/22750 (epoch 26.721), train_loss = 0.97324497, grad/param norm = 1.9950e-01, time/batch = 15.9492s	
12159/22750 (epoch 26.723), train_loss = 0.98072549, grad/param norm = 2.3282e-01, time/batch = 15.4621s	
12160/22750 (epoch 26.725), train_loss = 0.88666256, grad/param norm = 2.5256e-01, time/batch = 15.7813s	
12161/22750 (epoch 26.727), train_loss = 0.85007991, grad/param norm = 1.9825e-01, time/batch = 15.0685s	
12162/22750 (epoch 26.730), train_loss = 0.85824049, grad/param norm = 2.2122e-01, time/batch = 15.2145s	
12163/22750 (epoch 26.732), train_loss = 0.80162176, grad/param norm = 1.8524e-01, time/batch = 15.6151s	
12164/22750 (epoch 26.734), train_loss = 0.71884807, grad/param norm = 1.7644e-01, time/batch = 15.3685s	
12165/22750 (epoch 26.736), train_loss = 0.80907822, grad/param norm = 1.8642e-01, time/batch = 15.4559s	
12166/22750 (epoch 26.738), train_loss = 0.96116416, grad/param norm = 2.2528e-01, time/batch = 15.5430s	
12167/22750 (epoch 26.741), train_loss = 1.00716314, grad/param norm = 2.3690e-01, time/batch = 29.0057s	
12168/22750 (epoch 26.743), train_loss = 0.92335141, grad/param norm = 1.9861e-01, time/batch = 15.4637s	
12169/22750 (epoch 26.745), train_loss = 0.76328910, grad/param norm = 1.7717e-01, time/batch = 15.7754s	
12170/22750 (epoch 26.747), train_loss = 0.86127187, grad/param norm = 2.0427e-01, time/batch = 16.1681s	
12171/22750 (epoch 26.749), train_loss = 1.05115744, grad/param norm = 2.3394e-01, time/batch = 15.7068s	
12172/22750 (epoch 26.752), train_loss = 0.90005840, grad/param norm = 2.0270e-01, time/batch = 15.3025s	
12173/22750 (epoch 26.754), train_loss = 0.93329553, grad/param norm = 2.2152e-01, time/batch = 15.4527s	
12174/22750 (epoch 26.756), train_loss = 0.81248753, grad/param norm = 2.1779e-01, time/batch = 15.5352s	
12175/22750 (epoch 26.758), train_loss = 0.79847749, grad/param norm = 1.8286e-01, time/batch = 15.2840s	
12176/22750 (epoch 26.760), train_loss = 0.83931259, grad/param norm = 2.0340e-01, time/batch = 15.2148s	
12177/22750 (epoch 26.763), train_loss = 0.91749057, grad/param norm = 2.2341e-01, time/batch = 15.6860s	
12178/22750 (epoch 26.765), train_loss = 0.89231656, grad/param norm = 2.2568e-01, time/batch = 14.9694s	
12179/22750 (epoch 26.767), train_loss = 0.93011485, grad/param norm = 2.6096e-01, time/batch = 14.5074s	
12180/22750 (epoch 26.769), train_loss = 1.09149820, grad/param norm = 2.5670e-01, time/batch = 14.8234s	
12181/22750 (epoch 26.771), train_loss = 1.04484992, grad/param norm = 2.4112e-01, time/batch = 15.3867s	
12182/22750 (epoch 26.774), train_loss = 0.85702664, grad/param norm = 2.1281e-01, time/batch = 15.3818s	
12183/22750 (epoch 26.776), train_loss = 0.99715389, grad/param norm = 2.1465e-01, time/batch = 14.8909s	
12184/22750 (epoch 26.778), train_loss = 1.06768242, grad/param norm = 2.2385e-01, time/batch = 14.8917s	
12185/22750 (epoch 26.780), train_loss = 0.91084725, grad/param norm = 2.1483e-01, time/batch = 15.4504s	
12186/22750 (epoch 26.782), train_loss = 1.08947158, grad/param norm = 2.2279e-01, time/batch = 16.0739s	
12187/22750 (epoch 26.785), train_loss = 0.87833596, grad/param norm = 2.2934e-01, time/batch = 15.5986s	
12188/22750 (epoch 26.787), train_loss = 0.78669329, grad/param norm = 2.1114e-01, time/batch = 15.2105s	
12189/22750 (epoch 26.789), train_loss = 0.86841914, grad/param norm = 1.8401e-01, time/batch = 15.7702s	
12190/22750 (epoch 26.791), train_loss = 0.83848137, grad/param norm = 1.9334e-01, time/batch = 15.0643s	
12191/22750 (epoch 26.793), train_loss = 0.82836837, grad/param norm = 2.4980e-01, time/batch = 15.1500s	
12192/22750 (epoch 26.796), train_loss = 0.75605657, grad/param norm = 1.8415e-01, time/batch = 15.2260s	
12193/22750 (epoch 26.798), train_loss = 0.80169984, grad/param norm = 1.9389e-01, time/batch = 15.7058s	
12194/22750 (epoch 26.800), train_loss = 0.83099230, grad/param norm = 2.0302e-01, time/batch = 15.9089s	
12195/22750 (epoch 26.802), train_loss = 0.74258760, grad/param norm = 1.9007e-01, time/batch = 15.2007s	
12196/22750 (epoch 26.804), train_loss = 1.00178727, grad/param norm = 2.3532e-01, time/batch = 15.3755s	
12197/22750 (epoch 26.807), train_loss = 0.95415160, grad/param norm = 2.0668e-01, time/batch = 15.4460s	
12198/22750 (epoch 26.809), train_loss = 1.01239362, grad/param norm = 2.2151e-01, time/batch = 15.1242s	
12199/22750 (epoch 26.811), train_loss = 0.87405767, grad/param norm = 2.0068e-01, time/batch = 15.2062s	
12200/22750 (epoch 26.813), train_loss = 0.91604478, grad/param norm = 1.9162e-01, time/batch = 15.2100s	
12201/22750 (epoch 26.815), train_loss = 1.05795766, grad/param norm = 2.1992e-01, time/batch = 15.5537s	
12202/22750 (epoch 26.818), train_loss = 0.99082192, grad/param norm = 1.9085e-01, time/batch = 15.0703s	
12203/22750 (epoch 26.820), train_loss = 1.14449208, grad/param norm = 2.2861e-01, time/batch = 16.0156s	
12204/22750 (epoch 26.822), train_loss = 0.95057545, grad/param norm = 2.1637e-01, time/batch = 16.7174s	
12205/22750 (epoch 26.824), train_loss = 0.80199752, grad/param norm = 1.9930e-01, time/batch = 15.6090s	
12206/22750 (epoch 26.826), train_loss = 0.89476402, grad/param norm = 2.1912e-01, time/batch = 15.5279s	
12207/22750 (epoch 26.829), train_loss = 1.04489632, grad/param norm = 2.3292e-01, time/batch = 16.3223s	
12208/22750 (epoch 26.831), train_loss = 1.00444869, grad/param norm = 2.2652e-01, time/batch = 15.7683s	
12209/22750 (epoch 26.833), train_loss = 0.93449078, grad/param norm = 2.0953e-01, time/batch = 15.6163s	
12210/22750 (epoch 26.835), train_loss = 0.81131995, grad/param norm = 1.9531e-01, time/batch = 15.6828s	
12211/22750 (epoch 26.837), train_loss = 0.86009872, grad/param norm = 1.8856e-01, time/batch = 16.7098s	
12212/22750 (epoch 26.840), train_loss = 0.77230351, grad/param norm = 1.8237e-01, time/batch = 18.1959s	
12213/22750 (epoch 26.842), train_loss = 0.85301832, grad/param norm = 2.1229e-01, time/batch = 21.0134s	
12214/22750 (epoch 26.844), train_loss = 0.94488187, grad/param norm = 2.0969e-01, time/batch = 18.2553s	
12215/22750 (epoch 26.846), train_loss = 0.92128625, grad/param norm = 1.9884e-01, time/batch = 17.9918s	
12216/22750 (epoch 26.848), train_loss = 0.81001046, grad/param norm = 1.7247e-01, time/batch = 20.0727s	
12217/22750 (epoch 26.851), train_loss = 0.80326676, grad/param norm = 1.9833e-01, time/batch = 19.5938s	
12218/22750 (epoch 26.853), train_loss = 0.96933300, grad/param norm = 2.1471e-01, time/batch = 16.2772s	
12219/22750 (epoch 26.855), train_loss = 0.81973701, grad/param norm = 1.8954e-01, time/batch = 16.6534s	
12220/22750 (epoch 26.857), train_loss = 0.93739040, grad/param norm = 2.0037e-01, time/batch = 19.5114s	
12221/22750 (epoch 26.859), train_loss = 0.96401655, grad/param norm = 2.4748e-01, time/batch = 19.5979s	
12222/22750 (epoch 26.862), train_loss = 1.07560224, grad/param norm = 2.1242e-01, time/batch = 19.5235s	
12223/22750 (epoch 26.864), train_loss = 0.88784356, grad/param norm = 1.9837e-01, time/batch = 19.8398s	
12224/22750 (epoch 26.866), train_loss = 0.94243492, grad/param norm = 1.8590e-01, time/batch = 19.4866s	
12225/22750 (epoch 26.868), train_loss = 0.81446945, grad/param norm = 1.8384e-01, time/batch = 18.3299s	
12226/22750 (epoch 26.870), train_loss = 0.76463955, grad/param norm = 2.1070e-01, time/batch = 20.0020s	
12227/22750 (epoch 26.873), train_loss = 0.86198955, grad/param norm = 1.8897e-01, time/batch = 19.8314s	
12228/22750 (epoch 26.875), train_loss = 0.96827779, grad/param norm = 2.0121e-01, time/batch = 18.8865s	
12229/22750 (epoch 26.877), train_loss = 0.82229440, grad/param norm = 2.3326e-01, time/batch = 20.3504s	
12230/22750 (epoch 26.879), train_loss = 1.03513437, grad/param norm = 2.4934e-01, time/batch = 19.3173s	
12231/22750 (epoch 26.881), train_loss = 0.96631191, grad/param norm = 2.2012e-01, time/batch = 19.1850s	
12232/22750 (epoch 26.884), train_loss = 0.83897183, grad/param norm = 1.9761e-01, time/batch = 17.5723s	
12233/22750 (epoch 26.886), train_loss = 0.96198455, grad/param norm = 2.0491e-01, time/batch = 17.1665s	
12234/22750 (epoch 26.888), train_loss = 0.97145479, grad/param norm = 1.8806e-01, time/batch = 18.0808s	
12235/22750 (epoch 26.890), train_loss = 0.96933494, grad/param norm = 2.0524e-01, time/batch = 18.0959s	
12236/22750 (epoch 26.892), train_loss = 1.22527509, grad/param norm = 2.4649e-01, time/batch = 17.5863s	
12237/22750 (epoch 26.895), train_loss = 0.90298840, grad/param norm = 2.2267e-01, time/batch = 18.7633s	
12238/22750 (epoch 26.897), train_loss = 0.99048737, grad/param norm = 2.2281e-01, time/batch = 19.2824s	
12239/22750 (epoch 26.899), train_loss = 0.97237901, grad/param norm = 2.1109e-01, time/batch = 16.1805s	
12240/22750 (epoch 26.901), train_loss = 1.02321703, grad/param norm = 2.2029e-01, time/batch = 16.9358s	
12241/22750 (epoch 26.903), train_loss = 0.90146054, grad/param norm = 2.3632e-01, time/batch = 16.1012s	
12242/22750 (epoch 26.905), train_loss = 0.98976192, grad/param norm = 2.1332e-01, time/batch = 18.0938s	
12243/22750 (epoch 26.908), train_loss = 0.82364350, grad/param norm = 2.4936e-01, time/batch = 18.3453s	
12244/22750 (epoch 26.910), train_loss = 0.70766435, grad/param norm = 2.1329e-01, time/batch = 18.1841s	
12245/22750 (epoch 26.912), train_loss = 0.86597690, grad/param norm = 2.1236e-01, time/batch = 18.2506s	
12246/22750 (epoch 26.914), train_loss = 0.90252560, grad/param norm = 2.1094e-01, time/batch = 16.4327s	
12247/22750 (epoch 26.916), train_loss = 0.74178708, grad/param norm = 2.0011e-01, time/batch = 17.3647s	
12248/22750 (epoch 26.919), train_loss = 0.88595357, grad/param norm = 2.2309e-01, time/batch = 18.1663s	
12249/22750 (epoch 26.921), train_loss = 0.69376222, grad/param norm = 1.9589e-01, time/batch = 19.9993s	
12250/22750 (epoch 26.923), train_loss = 0.81062843, grad/param norm = 1.8419e-01, time/batch = 19.7311s	
12251/22750 (epoch 26.925), train_loss = 0.86224054, grad/param norm = 1.9565e-01, time/batch = 17.2447s	
12252/22750 (epoch 26.927), train_loss = 0.70627729, grad/param norm = 1.9491e-01, time/batch = 18.8354s	
12253/22750 (epoch 26.930), train_loss = 0.69978173, grad/param norm = 1.7504e-01, time/batch = 18.9992s	
12254/22750 (epoch 26.932), train_loss = 0.91474714, grad/param norm = 2.3154e-01, time/batch = 16.8386s	
12255/22750 (epoch 26.934), train_loss = 0.72983867, grad/param norm = 1.7693e-01, time/batch = 18.8154s	
12256/22750 (epoch 26.936), train_loss = 0.99680271, grad/param norm = 2.0213e-01, time/batch = 17.1805s	
12257/22750 (epoch 26.938), train_loss = 0.97364816, grad/param norm = 1.8992e-01, time/batch = 18.6228s	
12258/22750 (epoch 26.941), train_loss = 1.06595576, grad/param norm = 2.2547e-01, time/batch = 17.8759s	
12259/22750 (epoch 26.943), train_loss = 0.90385216, grad/param norm = 2.0590e-01, time/batch = 16.5436s	
12260/22750 (epoch 26.945), train_loss = 0.91731177, grad/param norm = 2.3235e-01, time/batch = 16.1090s	
12261/22750 (epoch 26.947), train_loss = 0.85578756, grad/param norm = 2.2069e-01, time/batch = 17.0184s	
12262/22750 (epoch 26.949), train_loss = 0.79624194, grad/param norm = 1.8565e-01, time/batch = 18.1782s	
12263/22750 (epoch 26.952), train_loss = 0.82962410, grad/param norm = 1.9283e-01, time/batch = 19.3235s	
12264/22750 (epoch 26.954), train_loss = 0.79397077, grad/param norm = 1.9032e-01, time/batch = 17.5808s	
12265/22750 (epoch 26.956), train_loss = 0.92879014, grad/param norm = 1.9829e-01, time/batch = 19.6100s	
12266/22750 (epoch 26.958), train_loss = 0.82038454, grad/param norm = 1.7079e-01, time/batch = 19.1145s	
12267/22750 (epoch 26.960), train_loss = 0.79986639, grad/param norm = 1.8977e-01, time/batch = 17.9636s	
12268/22750 (epoch 26.963), train_loss = 0.94158462, grad/param norm = 2.1682e-01, time/batch = 19.8930s	
12269/22750 (epoch 26.965), train_loss = 0.97463849, grad/param norm = 1.9892e-01, time/batch = 19.5752s	
12270/22750 (epoch 26.967), train_loss = 0.92994198, grad/param norm = 2.1132e-01, time/batch = 18.3394s	
12271/22750 (epoch 26.969), train_loss = 0.83964920, grad/param norm = 2.2171e-01, time/batch = 18.4277s	
12272/22750 (epoch 26.971), train_loss = 0.82169694, grad/param norm = 2.0847e-01, time/batch = 16.9270s	
12273/22750 (epoch 26.974), train_loss = 0.85322598, grad/param norm = 2.1560e-01, time/batch = 18.1873s	
12274/22750 (epoch 26.976), train_loss = 0.89293820, grad/param norm = 2.2600e-01, time/batch = 18.2086s	
12275/22750 (epoch 26.978), train_loss = 0.84231550, grad/param norm = 1.9969e-01, time/batch = 18.9610s	
12276/22750 (epoch 26.980), train_loss = 0.99759381, grad/param norm = 2.2049e-01, time/batch = 17.5127s	
12277/22750 (epoch 26.982), train_loss = 0.80771941, grad/param norm = 1.9493e-01, time/batch = 16.9315s	
12278/22750 (epoch 26.985), train_loss = 1.01909434, grad/param norm = 2.3180e-01, time/batch = 18.6797s	
12279/22750 (epoch 26.987), train_loss = 0.71496068, grad/param norm = 1.8105e-01, time/batch = 18.5135s	
12280/22750 (epoch 26.989), train_loss = 0.84165105, grad/param norm = 2.5971e-01, time/batch = 16.0149s	
12281/22750 (epoch 26.991), train_loss = 0.93956191, grad/param norm = 2.3100e-01, time/batch = 18.0054s	
12282/22750 (epoch 26.993), train_loss = 0.91409953, grad/param norm = 2.4149e-01, time/batch = 18.4189s	
12283/22750 (epoch 26.996), train_loss = 0.81422590, grad/param norm = 2.5046e-01, time/batch = 18.3566s	
12284/22750 (epoch 26.998), train_loss = 1.01126937, grad/param norm = 2.2900e-01, time/batch = 17.8457s	
decayed learning rate by a factor 0.97 to 0.0011559025250861	
12285/22750 (epoch 27.000), train_loss = 0.90300627, grad/param norm = 2.1126e-01, time/batch = 20.2876s	
12286/22750 (epoch 27.002), train_loss = 1.04245177, grad/param norm = 2.1257e-01, time/batch = 17.8717s	
12287/22750 (epoch 27.004), train_loss = 0.84975184, grad/param norm = 2.1272e-01, time/batch = 16.6640s	
12288/22750 (epoch 27.007), train_loss = 0.83970143, grad/param norm = 2.0546e-01, time/batch = 18.4079s	
12289/22750 (epoch 27.009), train_loss = 1.04937302, grad/param norm = 2.6841e-01, time/batch = 17.6661s	
12290/22750 (epoch 27.011), train_loss = 1.14643883, grad/param norm = 2.6391e-01, time/batch = 18.8270s	
12291/22750 (epoch 27.013), train_loss = 1.03549204, grad/param norm = 2.4268e-01, time/batch = 19.9676s	
12292/22750 (epoch 27.015), train_loss = 0.93381113, grad/param norm = 2.4109e-01, time/batch = 19.6046s	
12293/22750 (epoch 27.018), train_loss = 0.98704870, grad/param norm = 2.5689e-01, time/batch = 19.4361s	
12294/22750 (epoch 27.020), train_loss = 1.02440194, grad/param norm = 2.1053e-01, time/batch = 19.5702s	
12295/22750 (epoch 27.022), train_loss = 0.90983262, grad/param norm = 2.0401e-01, time/batch = 19.4255s	
12296/22750 (epoch 27.024), train_loss = 0.91976388, grad/param norm = 2.2442e-01, time/batch = 17.9874s	
12297/22750 (epoch 27.026), train_loss = 0.96119143, grad/param norm = 2.2025e-01, time/batch = 18.3405s	
12298/22750 (epoch 27.029), train_loss = 0.76135824, grad/param norm = 2.1576e-01, time/batch = 17.7637s	
12299/22750 (epoch 27.031), train_loss = 1.13986658, grad/param norm = 2.2337e-01, time/batch = 19.5914s	
12300/22750 (epoch 27.033), train_loss = 0.91857337, grad/param norm = 2.4161e-01, time/batch = 17.4246s	
12301/22750 (epoch 27.035), train_loss = 0.95799110, grad/param norm = 2.0327e-01, time/batch = 19.3428s	
12302/22750 (epoch 27.037), train_loss = 1.00819801, grad/param norm = 2.0808e-01, time/batch = 20.1190s	
12303/22750 (epoch 27.040), train_loss = 0.90096682, grad/param norm = 2.2071e-01, time/batch = 17.5858s	
12304/22750 (epoch 27.042), train_loss = 0.93991242, grad/param norm = 2.2107e-01, time/batch = 18.3450s	
12305/22750 (epoch 27.044), train_loss = 0.88076149, grad/param norm = 2.2263e-01, time/batch = 18.3407s	
12306/22750 (epoch 27.046), train_loss = 1.02081163, grad/param norm = 2.6110e-01, time/batch = 17.8396s	
12307/22750 (epoch 27.048), train_loss = 0.89830488, grad/param norm = 1.8579e-01, time/batch = 17.0023s	
12308/22750 (epoch 27.051), train_loss = 0.94692177, grad/param norm = 2.3635e-01, time/batch = 19.4179s	
12309/22750 (epoch 27.053), train_loss = 0.83792362, grad/param norm = 1.6994e-01, time/batch = 18.5936s	
12310/22750 (epoch 27.055), train_loss = 0.78272842, grad/param norm = 1.8774e-01, time/batch = 18.6877s	
12311/22750 (epoch 27.057), train_loss = 1.09020372, grad/param norm = 2.2635e-01, time/batch = 19.9420s	
12312/22750 (epoch 27.059), train_loss = 0.68071086, grad/param norm = 1.7489e-01, time/batch = 18.3538s	
12313/22750 (epoch 27.062), train_loss = 0.77683438, grad/param norm = 2.1403e-01, time/batch = 19.1714s	
12314/22750 (epoch 27.064), train_loss = 0.98450702, grad/param norm = 2.1381e-01, time/batch = 17.9411s	
12315/22750 (epoch 27.066), train_loss = 0.79398402, grad/param norm = 1.8273e-01, time/batch = 19.8328s	
12316/22750 (epoch 27.068), train_loss = 0.81672775, grad/param norm = 1.8043e-01, time/batch = 18.4203s	
12317/22750 (epoch 27.070), train_loss = 0.70288710, grad/param norm = 1.8267e-01, time/batch = 18.8474s	
12318/22750 (epoch 27.073), train_loss = 0.84289988, grad/param norm = 2.0514e-01, time/batch = 17.0635s	
12319/22750 (epoch 27.075), train_loss = 0.88594228, grad/param norm = 1.9582e-01, time/batch = 17.0637s	
12320/22750 (epoch 27.077), train_loss = 0.67779998, grad/param norm = 2.1032e-01, time/batch = 18.3703s	
12321/22750 (epoch 27.079), train_loss = 0.85870624, grad/param norm = 2.1837e-01, time/batch = 18.4527s	
12322/22750 (epoch 27.081), train_loss = 0.85298658, grad/param norm = 2.0211e-01, time/batch = 18.9308s	
12323/22750 (epoch 27.084), train_loss = 0.84816911, grad/param norm = 2.0722e-01, time/batch = 17.3270s	
12324/22750 (epoch 27.086), train_loss = 0.87175878, grad/param norm = 1.8331e-01, time/batch = 18.5086s	
12325/22750 (epoch 27.088), train_loss = 0.80994915, grad/param norm = 1.9196e-01, time/batch = 18.8409s	
12326/22750 (epoch 27.090), train_loss = 0.83321508, grad/param norm = 1.8941e-01, time/batch = 17.4216s	
12327/22750 (epoch 27.092), train_loss = 0.98711718, grad/param norm = 2.0265e-01, time/batch = 19.4985s	
12328/22750 (epoch 27.095), train_loss = 0.80359867, grad/param norm = 1.9944e-01, time/batch = 18.2555s	
12329/22750 (epoch 27.097), train_loss = 0.88927506, grad/param norm = 1.9597e-01, time/batch = 19.1098s	
12330/22750 (epoch 27.099), train_loss = 0.83573549, grad/param norm = 2.2750e-01, time/batch = 19.8608s	
12331/22750 (epoch 27.101), train_loss = 0.75505992, grad/param norm = 1.9125e-01, time/batch = 20.9425s	
12332/22750 (epoch 27.103), train_loss = 0.93154004, grad/param norm = 2.2270e-01, time/batch = 18.4006s	
12333/22750 (epoch 27.105), train_loss = 1.04402110, grad/param norm = 2.5134e-01, time/batch = 20.7254s	
12334/22750 (epoch 27.108), train_loss = 0.86551665, grad/param norm = 1.9636e-01, time/batch = 19.4072s	
12335/22750 (epoch 27.110), train_loss = 1.01457658, grad/param norm = 2.1160e-01, time/batch = 15.9319s	
12336/22750 (epoch 27.112), train_loss = 0.73885152, grad/param norm = 1.7376e-01, time/batch = 18.8426s	
12337/22750 (epoch 27.114), train_loss = 0.68084135, grad/param norm = 1.8768e-01, time/batch = 19.6750s	
12338/22750 (epoch 27.116), train_loss = 0.82815414, grad/param norm = 1.8236e-01, time/batch = 18.1986s	
12339/22750 (epoch 27.119), train_loss = 0.81424209, grad/param norm = 1.7894e-01, time/batch = 20.2028s	
12340/22750 (epoch 27.121), train_loss = 0.88610130, grad/param norm = 2.2485e-01, time/batch = 20.6815s	
12341/22750 (epoch 27.123), train_loss = 0.77363258, grad/param norm = 1.8418e-01, time/batch = 18.0794s	
12342/22750 (epoch 27.125), train_loss = 1.02436474, grad/param norm = 1.9870e-01, time/batch = 19.8915s	
12343/22750 (epoch 27.127), train_loss = 0.86084963, grad/param norm = 2.1812e-01, time/batch = 18.7406s	
12344/22750 (epoch 27.130), train_loss = 0.85897818, grad/param norm = 1.8390e-01, time/batch = 17.0068s	
12345/22750 (epoch 27.132), train_loss = 0.80713608, grad/param norm = 2.0609e-01, time/batch = 18.9078s	
12346/22750 (epoch 27.134), train_loss = 0.85644042, grad/param norm = 2.0367e-01, time/batch = 16.3436s	
12347/22750 (epoch 27.136), train_loss = 0.71718616, grad/param norm = 2.1012e-01, time/batch = 17.9891s	
12348/22750 (epoch 27.138), train_loss = 0.95129288, grad/param norm = 2.0310e-01, time/batch = 18.4407s	
12349/22750 (epoch 27.141), train_loss = 0.89663060, grad/param norm = 2.0882e-01, time/batch = 20.6907s	
12350/22750 (epoch 27.143), train_loss = 0.76037712, grad/param norm = 1.7117e-01, time/batch = 19.2515s	
12351/22750 (epoch 27.145), train_loss = 0.99598645, grad/param norm = 2.1391e-01, time/batch = 17.8101s	
12352/22750 (epoch 27.147), train_loss = 1.04569296, grad/param norm = 2.1328e-01, time/batch = 20.0714s	
12353/22750 (epoch 27.149), train_loss = 0.88631350, grad/param norm = 2.1823e-01, time/batch = 19.8298s	
12354/22750 (epoch 27.152), train_loss = 0.89181702, grad/param norm = 2.0949e-01, time/batch = 18.7442s	
12355/22750 (epoch 27.154), train_loss = 0.78820851, grad/param norm = 1.8690e-01, time/batch = 16.4854s	
12356/22750 (epoch 27.156), train_loss = 0.78176508, grad/param norm = 1.9020e-01, time/batch = 17.1711s	
12357/22750 (epoch 27.158), train_loss = 0.81915132, grad/param norm = 2.2678e-01, time/batch = 16.4171s	
12358/22750 (epoch 27.160), train_loss = 0.88990299, grad/param norm = 2.1982e-01, time/batch = 16.0770s	
12359/22750 (epoch 27.163), train_loss = 1.07897261, grad/param norm = 2.3449e-01, time/batch = 16.8510s	
12360/22750 (epoch 27.165), train_loss = 0.92226616, grad/param norm = 2.0906e-01, time/batch = 17.3817s	
12361/22750 (epoch 27.167), train_loss = 0.86099641, grad/param norm = 2.1739e-01, time/batch = 18.6339s	
12362/22750 (epoch 27.169), train_loss = 0.91072899, grad/param norm = 2.2912e-01, time/batch = 19.5666s	
12363/22750 (epoch 27.171), train_loss = 0.75226140, grad/param norm = 1.8471e-01, time/batch = 19.8354s	
12364/22750 (epoch 27.174), train_loss = 0.72800800, grad/param norm = 2.0873e-01, time/batch = 18.5758s	
12365/22750 (epoch 27.176), train_loss = 0.77579878, grad/param norm = 2.0002e-01, time/batch = 19.5958s	
12366/22750 (epoch 27.178), train_loss = 0.82013593, grad/param norm = 2.0978e-01, time/batch = 17.9571s	
12367/22750 (epoch 27.180), train_loss = 0.99859306, grad/param norm = 2.5965e-01, time/batch = 26.7338s	
12368/22750 (epoch 27.182), train_loss = 0.98010458, grad/param norm = 2.4273e-01, time/batch = 25.2064s	
12369/22750 (epoch 27.185), train_loss = 1.02038171, grad/param norm = 2.2203e-01, time/batch = 18.7477s	
12370/22750 (epoch 27.187), train_loss = 0.77296225, grad/param norm = 2.0493e-01, time/batch = 16.5897s	
12371/22750 (epoch 27.189), train_loss = 0.80959265, grad/param norm = 2.2988e-01, time/batch = 19.9981s	
12372/22750 (epoch 27.191), train_loss = 0.81338180, grad/param norm = 1.8651e-01, time/batch = 19.7433s	
12373/22750 (epoch 27.193), train_loss = 0.94865386, grad/param norm = 1.9651e-01, time/batch = 18.3327s	
12374/22750 (epoch 27.196), train_loss = 0.85027349, grad/param norm = 2.4499e-01, time/batch = 19.6713s	
12375/22750 (epoch 27.198), train_loss = 0.64631657, grad/param norm = 1.7821e-01, time/batch = 19.0322s	
12376/22750 (epoch 27.200), train_loss = 0.88520801, grad/param norm = 2.1377e-01, time/batch = 19.1774s	
12377/22750 (epoch 27.202), train_loss = 0.95341132, grad/param norm = 2.5856e-01, time/batch = 20.1777s	
12378/22750 (epoch 27.204), train_loss = 0.88931166, grad/param norm = 1.9831e-01, time/batch = 19.6702s	
12379/22750 (epoch 27.207), train_loss = 0.86483635, grad/param norm = 2.0344e-01, time/batch = 17.9240s	
12380/22750 (epoch 27.209), train_loss = 0.81301364, grad/param norm = 1.9099e-01, time/batch = 17.8311s	
12381/22750 (epoch 27.211), train_loss = 0.80093582, grad/param norm = 2.0078e-01, time/batch = 17.7366s	
12382/22750 (epoch 27.213), train_loss = 0.68315117, grad/param norm = 1.8458e-01, time/batch = 17.0760s	
12383/22750 (epoch 27.215), train_loss = 0.65635137, grad/param norm = 1.8983e-01, time/batch = 18.5934s	
12384/22750 (epoch 27.218), train_loss = 0.76750227, grad/param norm = 2.1463e-01, time/batch = 18.6081s	
12385/22750 (epoch 27.220), train_loss = 0.72236764, grad/param norm = 1.7959e-01, time/batch = 19.6962s	
12386/22750 (epoch 27.222), train_loss = 0.74041281, grad/param norm = 1.9112e-01, time/batch = 17.6649s	
12387/22750 (epoch 27.224), train_loss = 0.77753375, grad/param norm = 1.8371e-01, time/batch = 17.0014s	
12388/22750 (epoch 27.226), train_loss = 0.88914116, grad/param norm = 2.2779e-01, time/batch = 19.4920s	
12389/22750 (epoch 27.229), train_loss = 0.89695549, grad/param norm = 2.3357e-01, time/batch = 17.4885s	
12390/22750 (epoch 27.231), train_loss = 0.79187102, grad/param norm = 1.9944e-01, time/batch = 19.4029s	
12391/22750 (epoch 27.233), train_loss = 0.71082005, grad/param norm = 1.9928e-01, time/batch = 17.5977s	
12392/22750 (epoch 27.235), train_loss = 0.70104245, grad/param norm = 2.0339e-01, time/batch = 18.3303s	
12393/22750 (epoch 27.237), train_loss = 0.79188012, grad/param norm = 2.1646e-01, time/batch = 17.8931s	
12394/22750 (epoch 27.240), train_loss = 0.85693317, grad/param norm = 2.3737e-01, time/batch = 19.5356s	
12395/22750 (epoch 27.242), train_loss = 1.07147071, grad/param norm = 2.7904e-01, time/batch = 18.4461s	
12396/22750 (epoch 27.244), train_loss = 1.02693350, grad/param norm = 2.0844e-01, time/batch = 20.9351s	
12397/22750 (epoch 27.246), train_loss = 1.04482933, grad/param norm = 2.4820e-01, time/batch = 19.5759s	
12398/22750 (epoch 27.248), train_loss = 0.85237731, grad/param norm = 1.9565e-01, time/batch = 18.4979s	
12399/22750 (epoch 27.251), train_loss = 0.96959431, grad/param norm = 2.3206e-01, time/batch = 18.9920s	
12400/22750 (epoch 27.253), train_loss = 0.90846408, grad/param norm = 2.4552e-01, time/batch = 18.9240s	
12401/22750 (epoch 27.255), train_loss = 0.90708543, grad/param norm = 2.1747e-01, time/batch = 18.9115s	
12402/22750 (epoch 27.257), train_loss = 0.80144450, grad/param norm = 2.3137e-01, time/batch = 16.5561s	
12403/22750 (epoch 27.259), train_loss = 1.00282727, grad/param norm = 2.5072e-01, time/batch = 17.4959s	
12404/22750 (epoch 27.262), train_loss = 0.90294586, grad/param norm = 2.1896e-01, time/batch = 18.1150s	
12405/22750 (epoch 27.264), train_loss = 0.72956050, grad/param norm = 2.4076e-01, time/batch = 17.8471s	
12406/22750 (epoch 27.266), train_loss = 0.86910163, grad/param norm = 2.4393e-01, time/batch = 18.2842s	
12407/22750 (epoch 27.268), train_loss = 1.00118133, grad/param norm = 2.3079e-01, time/batch = 17.6813s	
12408/22750 (epoch 27.270), train_loss = 0.79460503, grad/param norm = 2.1513e-01, time/batch = 17.5888s	
12409/22750 (epoch 27.273), train_loss = 1.16685247, grad/param norm = 2.6970e-01, time/batch = 18.5092s	
12410/22750 (epoch 27.275), train_loss = 1.02067636, grad/param norm = 2.0499e-01, time/batch = 18.1867s	
12411/22750 (epoch 27.277), train_loss = 0.86251958, grad/param norm = 2.5911e-01, time/batch = 18.5800s	
12412/22750 (epoch 27.279), train_loss = 0.74251962, grad/param norm = 2.0000e-01, time/batch = 18.0742s	
12413/22750 (epoch 27.281), train_loss = 1.02143779, grad/param norm = 2.1588e-01, time/batch = 19.8342s	
12414/22750 (epoch 27.284), train_loss = 0.86884852, grad/param norm = 1.8830e-01, time/batch = 20.0932s	
12415/22750 (epoch 27.286), train_loss = 0.96375241, grad/param norm = 2.3464e-01, time/batch = 18.9335s	
12416/22750 (epoch 27.288), train_loss = 1.05729918, grad/param norm = 2.2657e-01, time/batch = 19.4362s	
12417/22750 (epoch 27.290), train_loss = 0.90877189, grad/param norm = 2.0764e-01, time/batch = 20.1597s	
12418/22750 (epoch 27.292), train_loss = 0.96320181, grad/param norm = 2.6057e-01, time/batch = 18.5171s	
12419/22750 (epoch 27.295), train_loss = 0.94101542, grad/param norm = 2.2030e-01, time/batch = 19.4127s	
12420/22750 (epoch 27.297), train_loss = 0.88215714, grad/param norm = 2.1128e-01, time/batch = 19.9948s	
12421/22750 (epoch 27.299), train_loss = 0.99366308, grad/param norm = 2.1873e-01, time/batch = 20.1480s	
12422/22750 (epoch 27.301), train_loss = 0.89723169, grad/param norm = 2.0770e-01, time/batch = 16.7589s	
12423/22750 (epoch 27.303), train_loss = 0.94365291, grad/param norm = 2.2671e-01, time/batch = 19.2405s	
12424/22750 (epoch 27.305), train_loss = 1.09380936, grad/param norm = 2.2943e-01, time/batch = 18.0133s	
12425/22750 (epoch 27.308), train_loss = 0.95910886, grad/param norm = 2.0107e-01, time/batch = 20.8580s	
12426/22750 (epoch 27.310), train_loss = 0.80578221, grad/param norm = 2.3527e-01, time/batch = 17.7556s	
12427/22750 (epoch 27.312), train_loss = 0.91938155, grad/param norm = 2.0122e-01, time/batch = 16.7996s	
12428/22750 (epoch 27.314), train_loss = 0.90396249, grad/param norm = 2.0706e-01, time/batch = 16.7001s	
12429/22750 (epoch 27.316), train_loss = 0.85567928, grad/param norm = 1.9773e-01, time/batch = 16.6674s	
12430/22750 (epoch 27.319), train_loss = 0.90706924, grad/param norm = 2.3850e-01, time/batch = 16.0272s	
12431/22750 (epoch 27.321), train_loss = 0.83249495, grad/param norm = 2.1172e-01, time/batch = 19.8104s	
12432/22750 (epoch 27.323), train_loss = 0.90809590, grad/param norm = 2.2232e-01, time/batch = 19.9932s	
12433/22750 (epoch 27.325), train_loss = 0.78496838, grad/param norm = 2.0577e-01, time/batch = 18.2463s	
12434/22750 (epoch 27.327), train_loss = 0.84395710, grad/param norm = 2.1899e-01, time/batch = 17.5958s	
12435/22750 (epoch 27.330), train_loss = 1.06882355, grad/param norm = 2.3122e-01, time/batch = 15.8958s	
12436/22750 (epoch 27.332), train_loss = 1.08324042, grad/param norm = 2.2512e-01, time/batch = 19.0271s	
12437/22750 (epoch 27.334), train_loss = 0.73855309, grad/param norm = 1.8553e-01, time/batch = 18.0117s	
12438/22750 (epoch 27.336), train_loss = 0.96508526, grad/param norm = 2.0194e-01, time/batch = 20.1684s	
12439/22750 (epoch 27.338), train_loss = 0.86504700, grad/param norm = 1.9987e-01, time/batch = 19.1646s	
12440/22750 (epoch 27.341), train_loss = 0.89779626, grad/param norm = 2.1433e-01, time/batch = 17.9973s	
12441/22750 (epoch 27.343), train_loss = 0.77995620, grad/param norm = 2.1868e-01, time/batch = 18.3456s	
12442/22750 (epoch 27.345), train_loss = 0.97554860, grad/param norm = 2.4152e-01, time/batch = 20.4774s	
12443/22750 (epoch 27.347), train_loss = 1.01752751, grad/param norm = 2.3533e-01, time/batch = 19.6427s	
12444/22750 (epoch 27.349), train_loss = 0.71483845, grad/param norm = 1.9608e-01, time/batch = 16.7619s	
12445/22750 (epoch 27.352), train_loss = 1.00217455, grad/param norm = 2.3272e-01, time/batch = 19.9382s	
12446/22750 (epoch 27.354), train_loss = 1.01710233, grad/param norm = 2.2785e-01, time/batch = 15.2181s	
12447/22750 (epoch 27.356), train_loss = 0.99239599, grad/param norm = 2.1581e-01, time/batch = 16.0952s	
12448/22750 (epoch 27.358), train_loss = 0.87749209, grad/param norm = 2.2612e-01, time/batch = 15.7763s	
12449/22750 (epoch 27.360), train_loss = 1.05572918, grad/param norm = 2.0815e-01, time/batch = 19.2496s	
12450/22750 (epoch 27.363), train_loss = 0.88453559, grad/param norm = 2.2385e-01, time/batch = 18.4147s	
12451/22750 (epoch 27.365), train_loss = 0.70379485, grad/param norm = 1.8858e-01, time/batch = 19.4248s	
12452/22750 (epoch 27.367), train_loss = 0.81934057, grad/param norm = 2.3139e-01, time/batch = 19.5050s	
12453/22750 (epoch 27.369), train_loss = 0.91127612, grad/param norm = 2.2691e-01, time/batch = 18.0895s	
12454/22750 (epoch 27.371), train_loss = 0.91003366, grad/param norm = 2.1615e-01, time/batch = 18.5045s	
12455/22750 (epoch 27.374), train_loss = 0.80318797, grad/param norm = 2.0230e-01, time/batch = 17.8479s	
12456/22750 (epoch 27.376), train_loss = 0.88084107, grad/param norm = 2.1936e-01, time/batch = 16.4685s	
12457/22750 (epoch 27.378), train_loss = 0.90830589, grad/param norm = 2.0572e-01, time/batch = 16.5197s	
12458/22750 (epoch 27.380), train_loss = 1.00055665, grad/param norm = 2.2771e-01, time/batch = 18.4465s	
12459/22750 (epoch 27.382), train_loss = 0.87575832, grad/param norm = 2.0747e-01, time/batch = 18.5161s	
12460/22750 (epoch 27.385), train_loss = 0.97273764, grad/param norm = 2.0800e-01, time/batch = 17.4194s	
12461/22750 (epoch 27.387), train_loss = 0.93064194, grad/param norm = 2.0326e-01, time/batch = 18.7479s	
12462/22750 (epoch 27.389), train_loss = 0.73922105, grad/param norm = 1.9687e-01, time/batch = 17.5063s	
12463/22750 (epoch 27.391), train_loss = 0.57208615, grad/param norm = 1.6697e-01, time/batch = 17.3427s	
12464/22750 (epoch 27.393), train_loss = 0.73681741, grad/param norm = 1.8965e-01, time/batch = 16.9275s	
12465/22750 (epoch 27.396), train_loss = 0.93969851, grad/param norm = 2.0754e-01, time/batch = 20.0187s	
12466/22750 (epoch 27.398), train_loss = 0.87102535, grad/param norm = 2.0253e-01, time/batch = 19.3740s	
12467/22750 (epoch 27.400), train_loss = 0.87023336, grad/param norm = 2.1536e-01, time/batch = 18.2624s	
12468/22750 (epoch 27.402), train_loss = 0.93127477, grad/param norm = 2.0419e-01, time/batch = 18.9231s	
12469/22750 (epoch 27.404), train_loss = 1.01591852, grad/param norm = 2.1194e-01, time/batch = 20.6448s	
12470/22750 (epoch 27.407), train_loss = 0.97908849, grad/param norm = 2.1723e-01, time/batch = 17.8369s	
12471/22750 (epoch 27.409), train_loss = 0.80151174, grad/param norm = 2.0024e-01, time/batch = 18.3362s	
12472/22750 (epoch 27.411), train_loss = 0.83919402, grad/param norm = 1.9355e-01, time/batch = 20.4834s	
12473/22750 (epoch 27.413), train_loss = 0.65830286, grad/param norm = 1.9572e-01, time/batch = 17.8971s	
12474/22750 (epoch 27.415), train_loss = 0.68515731, grad/param norm = 1.7703e-01, time/batch = 19.2665s	
12475/22750 (epoch 27.418), train_loss = 0.82125129, grad/param norm = 2.0776e-01, time/batch = 20.9373s	
12476/22750 (epoch 27.420), train_loss = 0.98629124, grad/param norm = 3.0272e-01, time/batch = 16.1693s	
12477/22750 (epoch 27.422), train_loss = 1.10572088, grad/param norm = 2.4596e-01, time/batch = 15.9291s	
12478/22750 (epoch 27.424), train_loss = 1.08754078, grad/param norm = 2.3256e-01, time/batch = 15.9311s	
12479/22750 (epoch 27.426), train_loss = 1.08276394, grad/param norm = 2.2229e-01, time/batch = 15.6989s	
12480/22750 (epoch 27.429), train_loss = 0.82022569, grad/param norm = 2.1265e-01, time/batch = 15.9263s	
12481/22750 (epoch 27.431), train_loss = 0.72705527, grad/param norm = 1.9575e-01, time/batch = 17.3201s	
12482/22750 (epoch 27.433), train_loss = 0.84619504, grad/param norm = 2.0600e-01, time/batch = 16.6862s	
12483/22750 (epoch 27.435), train_loss = 0.67089661, grad/param norm = 1.7347e-01, time/batch = 16.3585s	
12484/22750 (epoch 27.437), train_loss = 0.57295867, grad/param norm = 1.9285e-01, time/batch = 16.2486s	
12485/22750 (epoch 27.440), train_loss = 0.86446171, grad/param norm = 2.6627e-01, time/batch = 19.9230s	
12486/22750 (epoch 27.442), train_loss = 0.91124813, grad/param norm = 2.1379e-01, time/batch = 21.0990s	
12487/22750 (epoch 27.444), train_loss = 0.84582003, grad/param norm = 2.4380e-01, time/batch = 18.5128s	
12488/22750 (epoch 27.446), train_loss = 0.88023455, grad/param norm = 2.1782e-01, time/batch = 20.3307s	
12489/22750 (epoch 27.448), train_loss = 1.13160106, grad/param norm = 2.3784e-01, time/batch = 18.4259s	
12490/22750 (epoch 27.451), train_loss = 1.08659956, grad/param norm = 2.1120e-01, time/batch = 18.7364s	
12491/22750 (epoch 27.453), train_loss = 0.98290269, grad/param norm = 2.3642e-01, time/batch = 19.4296s	
12492/22750 (epoch 27.455), train_loss = 1.08160481, grad/param norm = 2.2374e-01, time/batch = 18.4947s	
12493/22750 (epoch 27.457), train_loss = 1.00124238, grad/param norm = 4.4828e-01, time/batch = 18.3452s	
12494/22750 (epoch 27.459), train_loss = 0.97542183, grad/param norm = 2.1298e-01, time/batch = 19.9067s	
12495/22750 (epoch 27.462), train_loss = 0.97330294, grad/param norm = 2.0547e-01, time/batch = 19.4402s	
12496/22750 (epoch 27.464), train_loss = 0.75393948, grad/param norm = 2.0331e-01, time/batch = 18.6698s	
12497/22750 (epoch 27.466), train_loss = 1.00178436, grad/param norm = 2.3395e-01, time/batch = 19.0383s	
12498/22750 (epoch 27.468), train_loss = 0.93857401, grad/param norm = 2.3677e-01, time/batch = 18.0899s	
12499/22750 (epoch 27.470), train_loss = 1.01991450, grad/param norm = 2.3119e-01, time/batch = 18.0020s	
12500/22750 (epoch 27.473), train_loss = 0.88040270, grad/param norm = 2.1541e-01, time/batch = 18.5087s	
12501/22750 (epoch 27.475), train_loss = 0.92650725, grad/param norm = 2.3857e-01, time/batch = 19.4034s	
12502/22750 (epoch 27.477), train_loss = 0.80844556, grad/param norm = 2.1199e-01, time/batch = 18.7706s	
12503/22750 (epoch 27.479), train_loss = 0.77092810, grad/param norm = 2.0097e-01, time/batch = 18.9235s	
12504/22750 (epoch 27.481), train_loss = 0.74725400, grad/param norm = 1.9340e-01, time/batch = 20.3365s	
12505/22750 (epoch 27.484), train_loss = 0.62404413, grad/param norm = 2.0714e-01, time/batch = 18.2540s	
12506/22750 (epoch 27.486), train_loss = 0.75650278, grad/param norm = 2.1953e-01, time/batch = 19.3509s	
12507/22750 (epoch 27.488), train_loss = 0.66490111, grad/param norm = 1.8514e-01, time/batch = 20.2591s	
12508/22750 (epoch 27.490), train_loss = 0.85906556, grad/param norm = 2.0464e-01, time/batch = 18.9538s	
12509/22750 (epoch 27.492), train_loss = 0.99454347, grad/param norm = 2.2699e-01, time/batch = 18.0953s	
12510/22750 (epoch 27.495), train_loss = 0.79913850, grad/param norm = 1.9883e-01, time/batch = 18.9723s	
12511/22750 (epoch 27.497), train_loss = 0.87020558, grad/param norm = 2.6892e-01, time/batch = 20.3410s	
12512/22750 (epoch 27.499), train_loss = 0.81165931, grad/param norm = 2.1322e-01, time/batch = 18.5770s	
12513/22750 (epoch 27.501), train_loss = 0.87040499, grad/param norm = 2.0661e-01, time/batch = 20.9046s	
12514/22750 (epoch 27.503), train_loss = 0.86804555, grad/param norm = 2.1288e-01, time/batch = 19.1589s	
12515/22750 (epoch 27.505), train_loss = 0.77301233, grad/param norm = 1.9843e-01, time/batch = 18.0845s	
12516/22750 (epoch 27.508), train_loss = 0.70398012, grad/param norm = 1.9948e-01, time/batch = 19.6770s	
12517/22750 (epoch 27.510), train_loss = 0.76991315, grad/param norm = 2.0513e-01, time/batch = 19.8607s	
12518/22750 (epoch 27.512), train_loss = 0.77887391, grad/param norm = 1.9575e-01, time/batch = 17.2039s	
12519/22750 (epoch 27.514), train_loss = 0.83143213, grad/param norm = 2.1289e-01, time/batch = 19.5319s	
12520/22750 (epoch 27.516), train_loss = 0.82317033, grad/param norm = 2.1892e-01, time/batch = 20.7446s	
12521/22750 (epoch 27.519), train_loss = 0.93707786, grad/param norm = 2.1739e-01, time/batch = 18.8189s	
12522/22750 (epoch 27.521), train_loss = 0.88692530, grad/param norm = 2.2578e-01, time/batch = 18.9946s	
12523/22750 (epoch 27.523), train_loss = 0.81531308, grad/param norm = 2.2047e-01, time/batch = 20.4897s	
12524/22750 (epoch 27.525), train_loss = 1.01901753, grad/param norm = 2.3506e-01, time/batch = 16.4597s	
12525/22750 (epoch 27.527), train_loss = 0.86640241, grad/param norm = 1.9680e-01, time/batch = 16.8430s	
12526/22750 (epoch 27.530), train_loss = 0.81266198, grad/param norm = 2.4593e-01, time/batch = 16.9236s	
12527/22750 (epoch 27.532), train_loss = 0.73061962, grad/param norm = 1.7125e-01, time/batch = 17.8589s	
12528/22750 (epoch 27.534), train_loss = 0.95803156, grad/param norm = 2.2970e-01, time/batch = 19.2364s	
12529/22750 (epoch 27.536), train_loss = 0.90038782, grad/param norm = 2.0194e-01, time/batch = 18.5338s	
12530/22750 (epoch 27.538), train_loss = 0.89560278, grad/param norm = 1.8869e-01, time/batch = 19.2691s	
12531/22750 (epoch 27.541), train_loss = 0.75675944, grad/param norm = 2.0669e-01, time/batch = 17.4227s	
12532/22750 (epoch 27.543), train_loss = 0.76640500, grad/param norm = 2.1955e-01, time/batch = 18.9140s	
12533/22750 (epoch 27.545), train_loss = 0.94468706, grad/param norm = 2.0888e-01, time/batch = 20.0767s	
12534/22750 (epoch 27.547), train_loss = 0.78953831, grad/param norm = 1.7204e-01, time/batch = 17.8402s	
12535/22750 (epoch 27.549), train_loss = 0.84621041, grad/param norm = 2.1173e-01, time/batch = 18.3287s	
12536/22750 (epoch 27.552), train_loss = 0.93084198, grad/param norm = 2.4443e-01, time/batch = 19.4478s	
12537/22750 (epoch 27.554), train_loss = 0.93469194, grad/param norm = 2.2893e-01, time/batch = 17.2785s	
12538/22750 (epoch 27.556), train_loss = 0.91160013, grad/param norm = 2.2183e-01, time/batch = 18.9372s	
12539/22750 (epoch 27.558), train_loss = 0.94192501, grad/param norm = 2.1936e-01, time/batch = 19.6374s	
12540/22750 (epoch 27.560), train_loss = 0.83800658, grad/param norm = 2.1043e-01, time/batch = 19.0850s	
12541/22750 (epoch 27.563), train_loss = 0.99991729, grad/param norm = 2.3199e-01, time/batch = 19.0054s	
12542/22750 (epoch 27.565), train_loss = 0.94194693, grad/param norm = 2.2842e-01, time/batch = 20.7210s	
12543/22750 (epoch 27.567), train_loss = 0.90893754, grad/param norm = 2.0338e-01, time/batch = 18.4896s	
12544/22750 (epoch 27.569), train_loss = 0.86115301, grad/param norm = 2.1140e-01, time/batch = 15.2047s	
12545/22750 (epoch 27.571), train_loss = 0.85166426, grad/param norm = 2.1762e-01, time/batch = 15.8155s	
12546/22750 (epoch 27.574), train_loss = 0.83619811, grad/param norm = 2.1071e-01, time/batch = 17.6997s	
12547/22750 (epoch 27.576), train_loss = 0.81307072, grad/param norm = 1.9229e-01, time/batch = 16.3993s	
12548/22750 (epoch 27.578), train_loss = 0.76197480, grad/param norm = 2.1046e-01, time/batch = 16.4185s	
12549/22750 (epoch 27.580), train_loss = 0.91596203, grad/param norm = 2.5813e-01, time/batch = 16.6090s	
12550/22750 (epoch 27.582), train_loss = 0.80290866, grad/param norm = 2.0901e-01, time/batch = 18.0775s	
12551/22750 (epoch 27.585), train_loss = 0.74913521, grad/param norm = 2.0446e-01, time/batch = 16.5276s	
12552/22750 (epoch 27.587), train_loss = 0.75468309, grad/param norm = 1.8938e-01, time/batch = 16.7747s	
12553/22750 (epoch 27.589), train_loss = 0.70180169, grad/param norm = 1.8814e-01, time/batch = 15.6030s	
12554/22750 (epoch 27.591), train_loss = 0.84908202, grad/param norm = 1.9530e-01, time/batch = 16.0207s	
12555/22750 (epoch 27.593), train_loss = 1.00791770, grad/param norm = 1.9668e-01, time/batch = 17.5695s	
12556/22750 (epoch 27.596), train_loss = 1.00322979, grad/param norm = 2.1399e-01, time/batch = 19.8411s	
12557/22750 (epoch 27.598), train_loss = 1.01295313, grad/param norm = 2.3731e-01, time/batch = 17.7601s	
12558/22750 (epoch 27.600), train_loss = 1.00756281, grad/param norm = 2.4003e-01, time/batch = 18.4201s	
12559/22750 (epoch 27.602), train_loss = 0.80342271, grad/param norm = 2.0487e-01, time/batch = 18.4361s	
12560/22750 (epoch 27.604), train_loss = 0.82016445, grad/param norm = 2.4120e-01, time/batch = 19.7504s	
12561/22750 (epoch 27.607), train_loss = 0.75088986, grad/param norm = 1.7904e-01, time/batch = 33.4594s	
12562/22750 (epoch 27.609), train_loss = 0.70097961, grad/param norm = 1.6727e-01, time/batch = 17.7624s	
12563/22750 (epoch 27.611), train_loss = 0.82950492, grad/param norm = 2.0068e-01, time/batch = 16.2384s	
12564/22750 (epoch 27.613), train_loss = 0.78716043, grad/param norm = 1.9713e-01, time/batch = 16.0576s	
12565/22750 (epoch 27.615), train_loss = 0.83026466, grad/param norm = 1.9671e-01, time/batch = 15.8362s	
12566/22750 (epoch 27.618), train_loss = 0.84230960, grad/param norm = 2.0085e-01, time/batch = 15.8826s	
12567/22750 (epoch 27.620), train_loss = 0.81777495, grad/param norm = 2.0043e-01, time/batch = 15.5558s	
12568/22750 (epoch 27.622), train_loss = 0.69615049, grad/param norm = 1.8740e-01, time/batch = 15.2317s	
12569/22750 (epoch 27.624), train_loss = 0.79188897, grad/param norm = 1.9310e-01, time/batch = 14.8327s	
12570/22750 (epoch 27.626), train_loss = 0.69082941, grad/param norm = 1.8968e-01, time/batch = 15.2120s	
12571/22750 (epoch 27.629), train_loss = 0.79773688, grad/param norm = 1.8489e-01, time/batch = 16.0206s	
12572/22750 (epoch 27.631), train_loss = 0.85815933, grad/param norm = 2.0205e-01, time/batch = 15.1243s	
12573/22750 (epoch 27.633), train_loss = 0.73213714, grad/param norm = 2.0671e-01, time/batch = 15.1370s	
12574/22750 (epoch 27.635), train_loss = 0.84374948, grad/param norm = 2.0329e-01, time/batch = 15.2868s	
12575/22750 (epoch 27.637), train_loss = 0.91372472, grad/param norm = 2.3274e-01, time/batch = 15.6968s	
12576/22750 (epoch 27.640), train_loss = 0.92299132, grad/param norm = 2.1095e-01, time/batch = 16.0840s	
12577/22750 (epoch 27.642), train_loss = 0.98651636, grad/param norm = 2.3301e-01, time/batch = 15.6249s	
12578/22750 (epoch 27.644), train_loss = 0.84168648, grad/param norm = 2.0989e-01, time/batch = 14.9908s	
12579/22750 (epoch 27.646), train_loss = 0.89332762, grad/param norm = 2.4610e-01, time/batch = 15.8565s	
12580/22750 (epoch 27.648), train_loss = 0.91803803, grad/param norm = 2.3323e-01, time/batch = 14.8738s	
12581/22750 (epoch 27.651), train_loss = 0.93280883, grad/param norm = 2.1947e-01, time/batch = 15.2937s	
12582/22750 (epoch 27.653), train_loss = 0.95139303, grad/param norm = 2.1015e-01, time/batch = 15.1328s	
12583/22750 (epoch 27.655), train_loss = 0.88334876, grad/param norm = 2.0771e-01, time/batch = 16.6197s	
12584/22750 (epoch 27.657), train_loss = 1.04238833, grad/param norm = 2.4026e-01, time/batch = 15.1976s	
12585/22750 (epoch 27.659), train_loss = 1.04406158, grad/param norm = 2.1079e-01, time/batch = 15.6099s	
12586/22750 (epoch 27.662), train_loss = 1.05954607, grad/param norm = 2.2331e-01, time/batch = 15.5296s	
12587/22750 (epoch 27.664), train_loss = 0.92913462, grad/param norm = 2.1066e-01, time/batch = 15.4488s	
12588/22750 (epoch 27.666), train_loss = 0.73998907, grad/param norm = 1.9432e-01, time/batch = 14.9851s	
12589/22750 (epoch 27.668), train_loss = 0.87501383, grad/param norm = 2.0013e-01, time/batch = 15.7058s	
12590/22750 (epoch 27.670), train_loss = 0.87771489, grad/param norm = 2.1324e-01, time/batch = 16.4737s	
12591/22750 (epoch 27.673), train_loss = 1.09214312, grad/param norm = 2.4268e-01, time/batch = 16.0321s	
12592/22750 (epoch 27.675), train_loss = 1.20749134, grad/param norm = 2.5046e-01, time/batch = 15.3691s	
12593/22750 (epoch 27.677), train_loss = 1.08969406, grad/param norm = 2.4520e-01, time/batch = 15.9329s	
12594/22750 (epoch 27.679), train_loss = 1.08082190, grad/param norm = 2.6993e-01, time/batch = 16.7288s	
12595/22750 (epoch 27.681), train_loss = 1.04354789, grad/param norm = 2.3180e-01, time/batch = 15.4556s	
12596/22750 (epoch 27.684), train_loss = 1.06507635, grad/param norm = 2.3661e-01, time/batch = 15.9461s	
12597/22750 (epoch 27.686), train_loss = 1.07340366, grad/param norm = 2.5080e-01, time/batch = 15.8542s	
12598/22750 (epoch 27.688), train_loss = 1.02819274, grad/param norm = 2.2616e-01, time/batch = 16.0055s	
12599/22750 (epoch 27.690), train_loss = 1.00262687, grad/param norm = 2.0253e-01, time/batch = 15.7130s	
12600/22750 (epoch 27.692), train_loss = 1.04706512, grad/param norm = 2.3064e-01, time/batch = 15.4011s	
12601/22750 (epoch 27.695), train_loss = 0.91709116, grad/param norm = 2.1907e-01, time/batch = 15.8889s	
12602/22750 (epoch 27.697), train_loss = 0.92254276, grad/param norm = 2.1317e-01, time/batch = 15.9300s	
12603/22750 (epoch 27.699), train_loss = 0.87575189, grad/param norm = 2.1249e-01, time/batch = 15.4461s	
12604/22750 (epoch 27.701), train_loss = 0.76140492, grad/param norm = 2.0891e-01, time/batch = 15.2049s	
12605/22750 (epoch 27.703), train_loss = 0.86839493, grad/param norm = 2.0416e-01, time/batch = 15.3772s	
12606/22750 (epoch 27.705), train_loss = 0.82059667, grad/param norm = 1.9117e-01, time/batch = 15.4291s	
12607/22750 (epoch 27.708), train_loss = 0.90980220, grad/param norm = 2.3108e-01, time/batch = 15.7752s	
12608/22750 (epoch 27.710), train_loss = 0.78390303, grad/param norm = 2.0434e-01, time/batch = 16.0095s	
12609/22750 (epoch 27.712), train_loss = 0.75820061, grad/param norm = 1.8261e-01, time/batch = 16.1592s	
12610/22750 (epoch 27.714), train_loss = 0.73635192, grad/param norm = 1.8515e-01, time/batch = 15.9458s	
12611/22750 (epoch 27.716), train_loss = 0.75751923, grad/param norm = 1.9071e-01, time/batch = 15.2282s	
12612/22750 (epoch 27.719), train_loss = 0.85077042, grad/param norm = 2.4392e-01, time/batch = 15.5552s	
12613/22750 (epoch 27.721), train_loss = 0.95662313, grad/param norm = 1.9380e-01, time/batch = 16.5561s	
12614/22750 (epoch 27.723), train_loss = 0.96240178, grad/param norm = 2.4507e-01, time/batch = 16.1658s	
12615/22750 (epoch 27.725), train_loss = 0.86567638, grad/param norm = 2.2599e-01, time/batch = 16.3070s	
12616/22750 (epoch 27.727), train_loss = 0.82015166, grad/param norm = 2.0073e-01, time/batch = 15.1309s	
12617/22750 (epoch 27.730), train_loss = 0.83379329, grad/param norm = 2.1920e-01, time/batch = 15.9228s	
12618/22750 (epoch 27.732), train_loss = 0.78444496, grad/param norm = 1.8829e-01, time/batch = 15.2974s	
12619/22750 (epoch 27.734), train_loss = 0.70142644, grad/param norm = 1.7604e-01, time/batch = 15.2074s	
12620/22750 (epoch 27.736), train_loss = 0.82155127, grad/param norm = 2.2481e-01, time/batch = 15.2299s	
12621/22750 (epoch 27.738), train_loss = 0.94066676, grad/param norm = 2.1795e-01, time/batch = 15.6367s	
12622/22750 (epoch 27.741), train_loss = 0.98176237, grad/param norm = 2.2906e-01, time/batch = 15.7795s	
12623/22750 (epoch 27.743), train_loss = 0.92091105, grad/param norm = 2.0676e-01, time/batch = 15.1556s	
12624/22750 (epoch 27.745), train_loss = 0.75050917, grad/param norm = 1.8128e-01, time/batch = 15.6231s	
12625/22750 (epoch 27.747), train_loss = 0.84843747, grad/param norm = 2.0320e-01, time/batch = 15.2167s	
12626/22750 (epoch 27.749), train_loss = 1.02749156, grad/param norm = 2.5296e-01, time/batch = 15.2100s	
12627/22750 (epoch 27.752), train_loss = 0.88294033, grad/param norm = 1.9391e-01, time/batch = 15.2781s	
12628/22750 (epoch 27.754), train_loss = 0.91961317, grad/param norm = 2.4116e-01, time/batch = 15.6958s	
12629/22750 (epoch 27.756), train_loss = 0.80694820, grad/param norm = 2.2248e-01, time/batch = 15.2062s	
12630/22750 (epoch 27.758), train_loss = 0.78128985, grad/param norm = 1.7833e-01, time/batch = 15.1290s	
12631/22750 (epoch 27.760), train_loss = 0.81440263, grad/param norm = 1.9436e-01, time/batch = 15.3052s	
12632/22750 (epoch 27.763), train_loss = 0.88347990, grad/param norm = 2.0861e-01, time/batch = 15.6321s	
12633/22750 (epoch 27.765), train_loss = 0.88528871, grad/param norm = 2.1790e-01, time/batch = 15.3237s	
12634/22750 (epoch 27.767), train_loss = 0.90580052, grad/param norm = 2.1967e-01, time/batch = 16.0905s	
12635/22750 (epoch 27.769), train_loss = 1.04222183, grad/param norm = 2.3480e-01, time/batch = 15.6003s	
12636/22750 (epoch 27.771), train_loss = 1.03684805, grad/param norm = 2.5835e-01, time/batch = 14.3611s	
12637/22750 (epoch 27.774), train_loss = 0.85420286, grad/param norm = 2.3296e-01, time/batch = 0.7233s	
12638/22750 (epoch 27.776), train_loss = 0.98039502, grad/param norm = 2.3679e-01, time/batch = 0.7022s	
12639/22750 (epoch 27.778), train_loss = 1.05539499, grad/param norm = 2.3921e-01, time/batch = 0.7062s	
12640/22750 (epoch 27.780), train_loss = 0.90652709, grad/param norm = 2.0920e-01, time/batch = 0.7063s	
12641/22750 (epoch 27.782), train_loss = 1.06785935, grad/param norm = 2.3313e-01, time/batch = 0.7000s	
12642/22750 (epoch 27.785), train_loss = 0.85796275, grad/param norm = 2.2168e-01, time/batch = 0.7042s	
12643/22750 (epoch 27.787), train_loss = 0.76275784, grad/param norm = 1.9582e-01, time/batch = 0.7253s	
12644/22750 (epoch 27.789), train_loss = 0.85398897, grad/param norm = 1.8863e-01, time/batch = 1.0262s	
12645/22750 (epoch 27.791), train_loss = 0.82496569, grad/param norm = 2.0326e-01, time/batch = 1.0387s	
12646/22750 (epoch 27.793), train_loss = 0.81698190, grad/param norm = 2.4306e-01, time/batch = 1.0463s	
12647/22750 (epoch 27.796), train_loss = 0.74309313, grad/param norm = 1.9637e-01, time/batch = 1.0501s	
12648/22750 (epoch 27.798), train_loss = 0.80047894, grad/param norm = 2.0818e-01, time/batch = 1.2910s	
12649/22750 (epoch 27.800), train_loss = 0.80228156, grad/param norm = 1.9572e-01, time/batch = 1.9331s	
12650/22750 (epoch 27.802), train_loss = 0.72663863, grad/param norm = 2.1733e-01, time/batch = 1.9524s	
12651/22750 (epoch 27.804), train_loss = 0.97145623, grad/param norm = 2.1550e-01, time/batch = 12.2070s	
12652/22750 (epoch 27.807), train_loss = 0.93864862, grad/param norm = 2.2470e-01, time/batch = 15.3678s	
12653/22750 (epoch 27.809), train_loss = 0.99252497, grad/param norm = 2.1651e-01, time/batch = 16.0886s	
12654/22750 (epoch 27.811), train_loss = 0.87078427, grad/param norm = 2.1373e-01, time/batch = 16.4758s	
12655/22750 (epoch 27.813), train_loss = 0.90501447, grad/param norm = 1.9580e-01, time/batch = 15.0667s	
12656/22750 (epoch 27.815), train_loss = 1.03577402, grad/param norm = 2.1065e-01, time/batch = 16.7983s	
12657/22750 (epoch 27.818), train_loss = 0.97511357, grad/param norm = 1.9876e-01, time/batch = 16.9306s	
12658/22750 (epoch 27.820), train_loss = 1.11891832, grad/param norm = 2.1758e-01, time/batch = 17.5372s	
12659/22750 (epoch 27.822), train_loss = 0.92108147, grad/param norm = 2.1963e-01, time/batch = 16.1715s	
12660/22750 (epoch 27.824), train_loss = 0.78472548, grad/param norm = 1.9949e-01, time/batch = 17.1498s	
12661/22750 (epoch 27.826), train_loss = 0.87569003, grad/param norm = 2.2309e-01, time/batch = 15.7105s	
12662/22750 (epoch 27.829), train_loss = 1.01731928, grad/param norm = 2.2277e-01, time/batch = 16.4428s	
12663/22750 (epoch 27.831), train_loss = 0.97761800, grad/param norm = 2.2856e-01, time/batch = 16.4689s	
12664/22750 (epoch 27.833), train_loss = 0.90557400, grad/param norm = 2.1418e-01, time/batch = 16.3555s	
12665/22750 (epoch 27.835), train_loss = 0.78754970, grad/param norm = 1.9121e-01, time/batch = 15.6837s	
12666/22750 (epoch 27.837), train_loss = 0.85295269, grad/param norm = 1.9418e-01, time/batch = 16.6142s	
12667/22750 (epoch 27.840), train_loss = 0.77221853, grad/param norm = 1.9822e-01, time/batch = 19.6076s	
12668/22750 (epoch 27.842), train_loss = 0.83219854, grad/param norm = 2.1212e-01, time/batch = 16.9764s	
12669/22750 (epoch 27.844), train_loss = 0.93041196, grad/param norm = 2.3321e-01, time/batch = 15.9260s	
12670/22750 (epoch 27.846), train_loss = 0.91948831, grad/param norm = 2.0469e-01, time/batch = 15.9324s	
12671/22750 (epoch 27.848), train_loss = 0.79938326, grad/param norm = 1.7255e-01, time/batch = 16.0065s	
12672/22750 (epoch 27.851), train_loss = 0.78081715, grad/param norm = 1.8483e-01, time/batch = 16.0236s	
12673/22750 (epoch 27.853), train_loss = 0.95034754, grad/param norm = 2.0779e-01, time/batch = 16.7711s	
12674/22750 (epoch 27.855), train_loss = 0.81854997, grad/param norm = 2.0258e-01, time/batch = 16.2001s	
12675/22750 (epoch 27.857), train_loss = 0.93228591, grad/param norm = 2.0047e-01, time/batch = 17.2729s	
12676/22750 (epoch 27.859), train_loss = 0.95466946, grad/param norm = 2.3879e-01, time/batch = 17.0911s	
12677/22750 (epoch 27.862), train_loss = 1.07041300, grad/param norm = 2.3232e-01, time/batch = 20.1802s	
12678/22750 (epoch 27.864), train_loss = 0.89365873, grad/param norm = 2.1276e-01, time/batch = 16.5146s	
12679/22750 (epoch 27.866), train_loss = 0.91988268, grad/param norm = 1.8215e-01, time/batch = 17.4590s	
12680/22750 (epoch 27.868), train_loss = 0.81140575, grad/param norm = 2.0270e-01, time/batch = 17.3504s	
12681/22750 (epoch 27.870), train_loss = 0.74195240, grad/param norm = 2.3028e-01, time/batch = 17.5922s	
12682/22750 (epoch 27.873), train_loss = 0.85684836, grad/param norm = 1.9671e-01, time/batch = 17.4057s	
12683/22750 (epoch 27.875), train_loss = 0.94908579, grad/param norm = 2.0262e-01, time/batch = 16.9279s	
12684/22750 (epoch 27.877), train_loss = 0.79877712, grad/param norm = 1.9008e-01, time/batch = 16.2021s	
12685/22750 (epoch 27.879), train_loss = 1.00894220, grad/param norm = 2.1562e-01, time/batch = 16.6960s	
12686/22750 (epoch 27.881), train_loss = 0.93748894, grad/param norm = 2.1850e-01, time/batch = 16.7960s	
12687/22750 (epoch 27.884), train_loss = 0.82670136, grad/param norm = 1.8931e-01, time/batch = 16.2971s	
12688/22750 (epoch 27.886), train_loss = 0.94686432, grad/param norm = 2.1227e-01, time/batch = 16.1183s	
12689/22750 (epoch 27.888), train_loss = 0.95799532, grad/param norm = 1.8734e-01, time/batch = 16.4823s	
12690/22750 (epoch 27.890), train_loss = 0.95811700, grad/param norm = 2.1486e-01, time/batch = 15.9989s	
12691/22750 (epoch 27.892), train_loss = 1.20679463, grad/param norm = 2.7229e-01, time/batch = 16.0061s	
12692/22750 (epoch 27.895), train_loss = 0.88938182, grad/param norm = 2.2209e-01, time/batch = 15.6034s	
12693/22750 (epoch 27.897), train_loss = 0.96859265, grad/param norm = 2.1978e-01, time/batch = 15.7807s	
12694/22750 (epoch 27.899), train_loss = 0.96124053, grad/param norm = 2.3388e-01, time/batch = 15.6096s	
12695/22750 (epoch 27.901), train_loss = 0.99803467, grad/param norm = 2.1886e-01, time/batch = 15.9335s	
12696/22750 (epoch 27.903), train_loss = 0.86388472, grad/param norm = 1.9929e-01, time/batch = 16.3494s	
12697/22750 (epoch 27.905), train_loss = 0.97267692, grad/param norm = 2.0470e-01, time/batch = 15.7114s	
12698/22750 (epoch 27.908), train_loss = 0.80792710, grad/param norm = 2.2303e-01, time/batch = 15.3896s	
12699/22750 (epoch 27.910), train_loss = 0.69861566, grad/param norm = 1.8389e-01, time/batch = 15.8795s	
12700/22750 (epoch 27.912), train_loss = 0.85125105, grad/param norm = 2.0567e-01, time/batch = 16.2515s	
12701/22750 (epoch 27.914), train_loss = 0.89330507, grad/param norm = 2.1603e-01, time/batch = 16.1693s	
12702/22750 (epoch 27.916), train_loss = 0.71322736, grad/param norm = 1.9116e-01, time/batch = 15.7660s	
12703/22750 (epoch 27.919), train_loss = 0.86165691, grad/param norm = 2.1718e-01, time/batch = 15.7719s	
12704/22750 (epoch 27.921), train_loss = 0.67614359, grad/param norm = 1.8371e-01, time/batch = 16.4017s	
12705/22750 (epoch 27.923), train_loss = 0.79462505, grad/param norm = 2.1176e-01, time/batch = 16.0042s	
12706/22750 (epoch 27.925), train_loss = 0.85770270, grad/param norm = 2.0094e-01, time/batch = 16.1759s	
12707/22750 (epoch 27.927), train_loss = 0.71592540, grad/param norm = 2.1192e-01, time/batch = 16.5598s	
12708/22750 (epoch 27.930), train_loss = 0.69014660, grad/param norm = 1.9004e-01, time/batch = 16.4283s	
12709/22750 (epoch 27.932), train_loss = 0.89625084, grad/param norm = 2.2943e-01, time/batch = 15.8755s	
12710/22750 (epoch 27.934), train_loss = 0.71329513, grad/param norm = 1.7586e-01, time/batch = 16.0234s	
12711/22750 (epoch 27.936), train_loss = 0.98815300, grad/param norm = 2.2275e-01, time/batch = 16.9629s	
12712/22750 (epoch 27.938), train_loss = 0.97427886, grad/param norm = 1.9895e-01, time/batch = 16.7139s	
12713/22750 (epoch 27.941), train_loss = 1.04604286, grad/param norm = 2.3256e-01, time/batch = 15.9881s	
12714/22750 (epoch 27.943), train_loss = 0.88961566, grad/param norm = 2.1178e-01, time/batch = 15.7523s	
12715/22750 (epoch 27.945), train_loss = 0.91853773, grad/param norm = 2.4855e-01, time/batch = 16.0799s	
12716/22750 (epoch 27.947), train_loss = 0.84830976, grad/param norm = 2.1459e-01, time/batch = 16.0977s	
12717/22750 (epoch 27.949), train_loss = 0.79254251, grad/param norm = 1.9585e-01, time/batch = 15.6211s	
12718/22750 (epoch 27.952), train_loss = 0.82125318, grad/param norm = 1.9496e-01, time/batch = 15.3777s	
12719/22750 (epoch 27.954), train_loss = 0.77645226, grad/param norm = 1.9315e-01, time/batch = 15.6308s	
12720/22750 (epoch 27.956), train_loss = 0.91700598, grad/param norm = 2.0236e-01, time/batch = 15.7480s	
12721/22750 (epoch 27.958), train_loss = 0.80168431, grad/param norm = 1.7560e-01, time/batch = 15.6478s	
12722/22750 (epoch 27.960), train_loss = 0.79044626, grad/param norm = 2.1782e-01, time/batch = 16.0703s	
12723/22750 (epoch 27.963), train_loss = 0.89907066, grad/param norm = 2.1025e-01, time/batch = 15.8328s	
12724/22750 (epoch 27.965), train_loss = 0.96085738, grad/param norm = 2.0772e-01, time/batch = 15.8532s	
12725/22750 (epoch 27.967), train_loss = 0.92210335, grad/param norm = 2.0530e-01, time/batch = 16.0707s	
12726/22750 (epoch 27.969), train_loss = 0.82643918, grad/param norm = 2.1146e-01, time/batch = 15.8536s	
12727/22750 (epoch 27.971), train_loss = 0.80415547, grad/param norm = 1.8363e-01, time/batch = 15.2174s	
12728/22750 (epoch 27.974), train_loss = 0.84165704, grad/param norm = 2.2308e-01, time/batch = 15.1453s	
12729/22750 (epoch 27.976), train_loss = 0.86542680, grad/param norm = 2.1344e-01, time/batch = 15.4688s	
12730/22750 (epoch 27.978), train_loss = 0.83445004, grad/param norm = 2.1419e-01, time/batch = 16.1868s	
12731/22750 (epoch 27.980), train_loss = 0.99409490, grad/param norm = 2.5323e-01, time/batch = 16.7950s	
12732/22750 (epoch 27.982), train_loss = 0.79848947, grad/param norm = 1.9652e-01, time/batch = 15.8372s	
12733/22750 (epoch 27.985), train_loss = 1.01592086, grad/param norm = 2.3667e-01, time/batch = 16.0149s	
12734/22750 (epoch 27.987), train_loss = 0.71128051, grad/param norm = 2.0576e-01, time/batch = 15.9286s	
12735/22750 (epoch 27.989), train_loss = 0.82963073, grad/param norm = 2.4311e-01, time/batch = 16.0070s	
12736/22750 (epoch 27.991), train_loss = 0.90561766, grad/param norm = 2.3367e-01, time/batch = 15.6844s	
12737/22750 (epoch 27.993), train_loss = 0.91033495, grad/param norm = 2.5685e-01, time/batch = 15.6441s	
12738/22750 (epoch 27.996), train_loss = 0.81012571, grad/param norm = 2.4393e-01, time/batch = 15.7946s	
12739/22750 (epoch 27.998), train_loss = 0.99750070, grad/param norm = 2.3392e-01, time/batch = 15.9528s	
decayed learning rate by a factor 0.97 to 0.0011212254493335	
12740/22750 (epoch 28.000), train_loss = 0.89046999, grad/param norm = 2.2481e-01, time/batch = 16.2787s	
12741/22750 (epoch 28.002), train_loss = 1.05536373, grad/param norm = 2.2670e-01, time/batch = 15.9269s	
12742/22750 (epoch 28.004), train_loss = 0.82631867, grad/param norm = 2.0052e-01, time/batch = 15.1999s	
12743/22750 (epoch 28.007), train_loss = 0.83427207, grad/param norm = 2.2150e-01, time/batch = 15.5147s	
12744/22750 (epoch 28.009), train_loss = 1.04156545, grad/param norm = 2.7770e-01, time/batch = 15.1994s	
12745/22750 (epoch 28.011), train_loss = 1.10802184, grad/param norm = 2.4929e-01, time/batch = 15.8574s	
12746/22750 (epoch 28.013), train_loss = 1.01085761, grad/param norm = 2.1786e-01, time/batch = 15.4533s	
12747/22750 (epoch 28.015), train_loss = 0.91036659, grad/param norm = 2.4267e-01, time/batch = 15.3695s	
12748/22750 (epoch 28.018), train_loss = 0.97453121, grad/param norm = 2.3266e-01, time/batch = 15.2223s	
12749/22750 (epoch 28.020), train_loss = 1.01372922, grad/param norm = 2.3306e-01, time/batch = 16.1123s	
12750/22750 (epoch 28.022), train_loss = 0.89129574, grad/param norm = 2.0635e-01, time/batch = 16.0900s	
12751/22750 (epoch 28.024), train_loss = 0.89659629, grad/param norm = 2.2558e-01, time/batch = 15.9529s	
12752/22750 (epoch 28.026), train_loss = 0.93418414, grad/param norm = 2.3630e-01, time/batch = 16.3931s	
12753/22750 (epoch 28.029), train_loss = 0.76000539, grad/param norm = 2.2008e-01, time/batch = 16.0043s	
12754/22750 (epoch 28.031), train_loss = 1.12403895, grad/param norm = 2.3970e-01, time/batch = 15.3582s	
12755/22750 (epoch 28.033), train_loss = 0.89997396, grad/param norm = 2.2435e-01, time/batch = 15.4481s	
12756/22750 (epoch 28.035), train_loss = 0.94394157, grad/param norm = 2.3854e-01, time/batch = 15.7669s	
12757/22750 (epoch 28.037), train_loss = 0.99567069, grad/param norm = 2.1053e-01, time/batch = 15.9224s	
12758/22750 (epoch 28.040), train_loss = 0.88077149, grad/param norm = 2.0305e-01, time/batch = 15.6341s	
12759/22750 (epoch 28.042), train_loss = 0.93146906, grad/param norm = 2.1177e-01, time/batch = 15.8667s	
12760/22750 (epoch 28.044), train_loss = 0.86760342, grad/param norm = 2.1721e-01, time/batch = 16.5445s	
12761/22750 (epoch 28.046), train_loss = 0.99686581, grad/param norm = 2.3695e-01, time/batch = 15.6943s	
12762/22750 (epoch 28.048), train_loss = 0.89138321, grad/param norm = 1.9518e-01, time/batch = 15.5281s	
12763/22750 (epoch 28.051), train_loss = 0.91935257, grad/param norm = 2.3355e-01, time/batch = 15.9290s	
12764/22750 (epoch 28.053), train_loss = 0.83097619, grad/param norm = 1.7491e-01, time/batch = 16.5000s	
12765/22750 (epoch 28.055), train_loss = 0.76163703, grad/param norm = 1.9403e-01, time/batch = 16.4730s	
12766/22750 (epoch 28.057), train_loss = 1.07032909, grad/param norm = 2.2408e-01, time/batch = 15.5354s	
12767/22750 (epoch 28.059), train_loss = 0.67976531, grad/param norm = 2.0810e-01, time/batch = 15.3743s	
12768/22750 (epoch 28.062), train_loss = 0.75310158, grad/param norm = 1.9284e-01, time/batch = 15.9280s	
12769/22750 (epoch 28.064), train_loss = 0.95557827, grad/param norm = 2.3421e-01, time/batch = 15.4821s	
12770/22750 (epoch 28.066), train_loss = 0.79152765, grad/param norm = 1.9001e-01, time/batch = 15.3944s	
12771/22750 (epoch 28.068), train_loss = 0.79833781, grad/param norm = 1.7762e-01, time/batch = 15.8811s	
12772/22750 (epoch 28.070), train_loss = 0.68801266, grad/param norm = 1.7883e-01, time/batch = 16.1195s	
12773/22750 (epoch 28.073), train_loss = 0.82028777, grad/param norm = 2.0950e-01, time/batch = 16.1671s	
12774/22750 (epoch 28.075), train_loss = 0.87033022, grad/param norm = 1.8930e-01, time/batch = 15.6722s	
12775/22750 (epoch 28.077), train_loss = 0.65427536, grad/param norm = 2.1086e-01, time/batch = 15.6985s	
12776/22750 (epoch 28.079), train_loss = 0.84551677, grad/param norm = 2.1981e-01, time/batch = 15.7810s	
12777/22750 (epoch 28.081), train_loss = 0.85672325, grad/param norm = 2.3672e-01, time/batch = 16.1864s	
12778/22750 (epoch 28.084), train_loss = 0.84094157, grad/param norm = 2.0264e-01, time/batch = 15.5427s	
12779/22750 (epoch 28.086), train_loss = 0.86249387, grad/param norm = 1.8329e-01, time/batch = 16.1057s	
12780/22750 (epoch 28.088), train_loss = 0.78290049, grad/param norm = 1.8856e-01, time/batch = 16.1248s	
12781/22750 (epoch 28.090), train_loss = 0.82566731, grad/param norm = 1.9874e-01, time/batch = 15.4885s	
12782/22750 (epoch 28.092), train_loss = 0.96949419, grad/param norm = 2.1023e-01, time/batch = 15.4052s	
12783/22750 (epoch 28.095), train_loss = 0.79891866, grad/param norm = 1.9554e-01, time/batch = 16.2640s	
12784/22750 (epoch 28.097), train_loss = 0.87544564, grad/param norm = 1.9647e-01, time/batch = 15.5431s	
12785/22750 (epoch 28.099), train_loss = 0.81868033, grad/param norm = 1.9626e-01, time/batch = 15.3751s	
12786/22750 (epoch 28.101), train_loss = 0.74460244, grad/param norm = 1.8821e-01, time/batch = 15.7003s	
12787/22750 (epoch 28.103), train_loss = 0.92135577, grad/param norm = 2.2079e-01, time/batch = 16.0266s	
12788/22750 (epoch 28.105), train_loss = 1.02090608, grad/param norm = 2.4137e-01, time/batch = 16.7944s	
12789/22750 (epoch 28.108), train_loss = 0.84756841, grad/param norm = 1.9943e-01, time/batch = 15.4713s	
12790/22750 (epoch 28.110), train_loss = 0.98382314, grad/param norm = 1.9507e-01, time/batch = 15.8025s	
12791/22750 (epoch 28.112), train_loss = 0.72912864, grad/param norm = 1.7575e-01, time/batch = 15.7271s	
12792/22750 (epoch 28.114), train_loss = 0.66464370, grad/param norm = 1.8741e-01, time/batch = 15.3155s	
12793/22750 (epoch 28.116), train_loss = 0.82542715, grad/param norm = 1.8229e-01, time/batch = 15.2348s	
12794/22750 (epoch 28.119), train_loss = 0.80068265, grad/param norm = 1.7507e-01, time/batch = 16.0116s	
12795/22750 (epoch 28.121), train_loss = 0.86157931, grad/param norm = 2.2380e-01, time/batch = 16.7332s	
12796/22750 (epoch 28.123), train_loss = 0.76449575, grad/param norm = 2.0615e-01, time/batch = 18.3983s	
12797/22750 (epoch 28.125), train_loss = 1.00661046, grad/param norm = 1.9695e-01, time/batch = 16.7768s	
12798/22750 (epoch 28.127), train_loss = 0.84067823, grad/param norm = 2.1109e-01, time/batch = 30.7560s	
12799/22750 (epoch 28.130), train_loss = 0.84616219, grad/param norm = 1.8243e-01, time/batch = 18.7806s	
12800/22750 (epoch 28.132), train_loss = 0.79199724, grad/param norm = 2.0155e-01, time/batch = 15.9041s	
12801/22750 (epoch 28.134), train_loss = 0.83803982, grad/param norm = 1.9713e-01, time/batch = 16.4334s	
12802/22750 (epoch 28.136), train_loss = 0.68769710, grad/param norm = 1.8588e-01, time/batch = 14.8126s	
12803/22750 (epoch 28.138), train_loss = 0.92803017, grad/param norm = 2.2739e-01, time/batch = 14.7959s	
12804/22750 (epoch 28.141), train_loss = 0.88375828, grad/param norm = 2.2043e-01, time/batch = 15.3688s	
12805/22750 (epoch 28.143), train_loss = 0.77793897, grad/param norm = 2.0056e-01, time/batch = 15.1983s	
12806/22750 (epoch 28.145), train_loss = 0.96317988, grad/param norm = 1.9632e-01, time/batch = 15.2186s	
12807/22750 (epoch 28.147), train_loss = 1.02794244, grad/param norm = 2.4665e-01, time/batch = 15.1244s	
12808/22750 (epoch 28.149), train_loss = 0.88100891, grad/param norm = 2.1802e-01, time/batch = 15.9209s	
12809/22750 (epoch 28.152), train_loss = 0.87047005, grad/param norm = 2.0749e-01, time/batch = 15.2309s	
12810/22750 (epoch 28.154), train_loss = 0.78120107, grad/param norm = 1.9228e-01, time/batch = 15.0748s	
12811/22750 (epoch 28.156), train_loss = 0.76740553, grad/param norm = 1.9347e-01, time/batch = 15.1481s	
12812/22750 (epoch 28.158), train_loss = 0.79106512, grad/param norm = 2.1757e-01, time/batch = 15.7177s	
12813/22750 (epoch 28.160), train_loss = 0.87245543, grad/param norm = 2.2067e-01, time/batch = 15.4470s	
12814/22750 (epoch 28.163), train_loss = 1.05256734, grad/param norm = 2.2835e-01, time/batch = 15.4493s	
12815/22750 (epoch 28.165), train_loss = 0.89998288, grad/param norm = 1.9774e-01, time/batch = 15.1950s	
12816/22750 (epoch 28.167), train_loss = 0.83303122, grad/param norm = 2.1895e-01, time/batch = 15.8372s	
12817/22750 (epoch 28.169), train_loss = 0.88992554, grad/param norm = 2.3007e-01, time/batch = 15.2186s	
12818/22750 (epoch 28.171), train_loss = 0.73942550, grad/param norm = 1.9503e-01, time/batch = 15.6827s	
12819/22750 (epoch 28.174), train_loss = 0.72546795, grad/param norm = 2.0506e-01, time/batch = 14.7977s	
12820/22750 (epoch 28.176), train_loss = 0.75923974, grad/param norm = 2.0992e-01, time/batch = 15.3043s	
12821/22750 (epoch 28.178), train_loss = 0.79816268, grad/param norm = 1.9332e-01, time/batch = 15.0701s	
12822/22750 (epoch 28.180), train_loss = 0.98038958, grad/param norm = 2.5138e-01, time/batch = 15.2402s	
12823/22750 (epoch 28.182), train_loss = 0.96341369, grad/param norm = 2.2802e-01, time/batch = 15.2358s	
12824/22750 (epoch 28.185), train_loss = 0.98267980, grad/param norm = 2.1794e-01, time/batch = 15.6103s	
12825/22750 (epoch 28.187), train_loss = 0.75324861, grad/param norm = 1.9539e-01, time/batch = 15.1167s	
12826/22750 (epoch 28.189), train_loss = 0.78603491, grad/param norm = 2.2402e-01, time/batch = 15.2112s	
12827/22750 (epoch 28.191), train_loss = 0.79611245, grad/param norm = 1.8658e-01, time/batch = 15.4262s	
12828/22750 (epoch 28.193), train_loss = 0.94330054, grad/param norm = 2.1401e-01, time/batch = 15.8302s	
12829/22750 (epoch 28.196), train_loss = 0.83017664, grad/param norm = 2.2038e-01, time/batch = 15.7724s	
12830/22750 (epoch 28.198), train_loss = 0.63489952, grad/param norm = 1.8677e-01, time/batch = 15.4542s	
12831/22750 (epoch 28.200), train_loss = 0.86568952, grad/param norm = 2.0313e-01, time/batch = 15.4693s	
12832/22750 (epoch 28.202), train_loss = 0.93480332, grad/param norm = 2.4599e-01, time/batch = 15.3145s	
12833/22750 (epoch 28.204), train_loss = 0.87911925, grad/param norm = 2.0646e-01, time/batch = 14.9943s	
12834/22750 (epoch 28.207), train_loss = 0.86388525, grad/param norm = 2.0570e-01, time/batch = 15.0712s	
12835/22750 (epoch 28.209), train_loss = 0.81360067, grad/param norm = 2.0068e-01, time/batch = 15.6641s	
12836/22750 (epoch 28.211), train_loss = 0.78905527, grad/param norm = 2.0788e-01, time/batch = 15.5296s	
12837/22750 (epoch 28.213), train_loss = 0.66708749, grad/param norm = 1.8339e-01, time/batch = 15.2013s	
12838/22750 (epoch 28.215), train_loss = 0.64900973, grad/param norm = 1.9118e-01, time/batch = 15.1261s	
12839/22750 (epoch 28.218), train_loss = 0.74408402, grad/param norm = 2.0837e-01, time/batch = 15.6093s	
12840/22750 (epoch 28.220), train_loss = 0.69724553, grad/param norm = 1.7297e-01, time/batch = 15.3646s	
12841/22750 (epoch 28.222), train_loss = 0.72173609, grad/param norm = 1.8997e-01, time/batch = 15.3766s	
12842/22750 (epoch 28.224), train_loss = 0.75573679, grad/param norm = 1.9078e-01, time/batch = 14.9908s	
12843/22750 (epoch 28.226), train_loss = 0.86379128, grad/param norm = 2.1344e-01, time/batch = 15.2414s	
12844/22750 (epoch 28.229), train_loss = 0.86634688, grad/param norm = 2.0211e-01, time/batch = 15.1397s	
12845/22750 (epoch 28.231), train_loss = 0.76649184, grad/param norm = 1.9996e-01, time/batch = 15.2063s	
12846/22750 (epoch 28.233), train_loss = 0.69716686, grad/param norm = 2.0454e-01, time/batch = 15.2023s	
12847/22750 (epoch 28.235), train_loss = 0.67891703, grad/param norm = 2.0504e-01, time/batch = 15.6049s	
12848/22750 (epoch 28.237), train_loss = 0.77362626, grad/param norm = 1.9712e-01, time/batch = 15.2983s	
12849/22750 (epoch 28.240), train_loss = 0.85089866, grad/param norm = 1.9406e-01, time/batch = 15.5749s	
12850/22750 (epoch 28.242), train_loss = 1.04251977, grad/param norm = 2.6667e-01, time/batch = 15.2911s	
12851/22750 (epoch 28.244), train_loss = 1.02066236, grad/param norm = 2.3036e-01, time/batch = 15.6866s	
12852/22750 (epoch 28.246), train_loss = 1.04283669, grad/param norm = 2.5431e-01, time/batch = 15.2184s	
12853/22750 (epoch 28.248), train_loss = 0.84980969, grad/param norm = 2.0086e-01, time/batch = 15.0739s	
12854/22750 (epoch 28.251), train_loss = 0.95561157, grad/param norm = 2.3139e-01, time/batch = 14.9900s	
12855/22750 (epoch 28.253), train_loss = 0.89658782, grad/param norm = 2.2379e-01, time/batch = 16.0058s	
12856/22750 (epoch 28.255), train_loss = 0.88696567, grad/param norm = 2.1566e-01, time/batch = 15.2153s	
12857/22750 (epoch 28.257), train_loss = 0.78929939, grad/param norm = 2.1538e-01, time/batch = 15.3627s	
12858/22750 (epoch 28.259), train_loss = 0.97274707, grad/param norm = 2.5172e-01, time/batch = 16.0617s	
12859/22750 (epoch 28.262), train_loss = 0.87511433, grad/param norm = 2.2569e-01, time/batch = 15.7723s	
12860/22750 (epoch 28.264), train_loss = 0.68898296, grad/param norm = 2.0252e-01, time/batch = 15.5251s	
12861/22750 (epoch 28.266), train_loss = 0.85885400, grad/param norm = 2.5247e-01, time/batch = 15.2939s	
12862/22750 (epoch 28.268), train_loss = 1.00449223, grad/param norm = 2.3613e-01, time/batch = 15.3776s	
12863/22750 (epoch 28.270), train_loss = 0.77419543, grad/param norm = 2.1529e-01, time/batch = 15.2218s	
12864/22750 (epoch 28.273), train_loss = 1.14310940, grad/param norm = 2.5822e-01, time/batch = 15.0627s	
12865/22750 (epoch 28.275), train_loss = 0.99490388, grad/param norm = 2.0757e-01, time/batch = 15.2105s	
12866/22750 (epoch 28.277), train_loss = 0.83913134, grad/param norm = 2.3077e-01, time/batch = 15.7070s	
12867/22750 (epoch 28.279), train_loss = 0.73316912, grad/param norm = 1.9151e-01, time/batch = 15.7044s	
12868/22750 (epoch 28.281), train_loss = 0.99975942, grad/param norm = 2.1681e-01, time/batch = 15.1322s	
12869/22750 (epoch 28.284), train_loss = 0.87399280, grad/param norm = 2.1281e-01, time/batch = 15.7859s	
12870/22750 (epoch 28.286), train_loss = 0.94682541, grad/param norm = 2.2354e-01, time/batch = 15.8570s	
12871/22750 (epoch 28.288), train_loss = 1.03686519, grad/param norm = 2.4238e-01, time/batch = 15.1263s	
12872/22750 (epoch 28.290), train_loss = 0.88432909, grad/param norm = 2.0080e-01, time/batch = 15.5286s	
12873/22750 (epoch 28.292), train_loss = 0.92697425, grad/param norm = 2.3163e-01, time/batch = 15.2200s	
12874/22750 (epoch 28.295), train_loss = 0.92280064, grad/param norm = 2.1963e-01, time/batch = 15.4636s	
12875/22750 (epoch 28.297), train_loss = 0.87362530, grad/param norm = 2.1582e-01, time/batch = 15.3101s	
12876/22750 (epoch 28.299), train_loss = 0.97158615, grad/param norm = 2.1800e-01, time/batch = 15.1366s	
12877/22750 (epoch 28.301), train_loss = 0.88860152, grad/param norm = 2.1091e-01, time/batch = 15.3066s	
12878/22750 (epoch 28.303), train_loss = 0.92655752, grad/param norm = 2.1331e-01, time/batch = 15.8420s	
12879/22750 (epoch 28.305), train_loss = 1.07255118, grad/param norm = 2.3210e-01, time/batch = 15.9586s	
12880/22750 (epoch 28.308), train_loss = 0.93759841, grad/param norm = 1.9461e-01, time/batch = 17.9097s	
12881/22750 (epoch 28.310), train_loss = 0.79823707, grad/param norm = 2.3811e-01, time/batch = 19.7400s	
12882/22750 (epoch 28.312), train_loss = 0.89585109, grad/param norm = 1.9999e-01, time/batch = 18.9937s	
12883/22750 (epoch 28.314), train_loss = 0.88751027, grad/param norm = 2.1504e-01, time/batch = 18.0701s	
12884/22750 (epoch 28.316), train_loss = 0.83836940, grad/param norm = 2.0929e-01, time/batch = 18.7660s	
12885/22750 (epoch 28.319), train_loss = 0.89689968, grad/param norm = 2.2920e-01, time/batch = 19.4331s	
12886/22750 (epoch 28.321), train_loss = 0.83305813, grad/param norm = 2.2170e-01, time/batch = 18.4480s	
12887/22750 (epoch 28.323), train_loss = 0.91437750, grad/param norm = 2.4227e-01, time/batch = 19.9229s	
12888/22750 (epoch 28.325), train_loss = 0.76199353, grad/param norm = 1.8590e-01, time/batch = 16.1975s	
12889/22750 (epoch 28.327), train_loss = 0.83968561, grad/param norm = 2.3446e-01, time/batch = 17.4989s	
12890/22750 (epoch 28.330), train_loss = 1.05132855, grad/param norm = 2.2516e-01, time/batch = 19.0539s	
12891/22750 (epoch 28.332), train_loss = 1.05956583, grad/param norm = 2.0679e-01, time/batch = 17.7501s	
12892/22750 (epoch 28.334), train_loss = 0.72220727, grad/param norm = 1.9404e-01, time/batch = 19.1690s	
12893/22750 (epoch 28.336), train_loss = 0.95098589, grad/param norm = 1.9851e-01, time/batch = 16.1608s	
12894/22750 (epoch 28.338), train_loss = 0.85271009, grad/param norm = 2.2995e-01, time/batch = 15.5341s	
12895/22750 (epoch 28.341), train_loss = 0.89206430, grad/param norm = 2.0568e-01, time/batch = 19.0398s	
12896/22750 (epoch 28.343), train_loss = 0.76043345, grad/param norm = 2.1119e-01, time/batch = 19.2930s	
12897/22750 (epoch 28.345), train_loss = 0.94246488, grad/param norm = 2.5714e-01, time/batch = 19.7907s	
12898/22750 (epoch 28.347), train_loss = 1.01798269, grad/param norm = 2.4052e-01, time/batch = 16.5233s	
12899/22750 (epoch 28.349), train_loss = 0.69903282, grad/param norm = 2.0678e-01, time/batch = 18.2676s	
12900/22750 (epoch 28.352), train_loss = 0.98551813, grad/param norm = 2.1801e-01, time/batch = 17.4253s	
12901/22750 (epoch 28.354), train_loss = 0.99545973, grad/param norm = 2.1285e-01, time/batch = 16.6572s	
12902/22750 (epoch 28.356), train_loss = 0.97926667, grad/param norm = 2.2828e-01, time/batch = 17.4992s	
12903/22750 (epoch 28.358), train_loss = 0.85942351, grad/param norm = 2.2916e-01, time/batch = 19.9000s	
12904/22750 (epoch 28.360), train_loss = 1.03118348, grad/param norm = 2.0796e-01, time/batch = 18.8450s	
12905/22750 (epoch 28.363), train_loss = 0.86500617, grad/param norm = 2.2647e-01, time/batch = 18.5282s	
12906/22750 (epoch 28.365), train_loss = 0.70301301, grad/param norm = 2.1718e-01, time/batch = 18.9542s	
12907/22750 (epoch 28.367), train_loss = 0.79858151, grad/param norm = 2.2783e-01, time/batch = 18.4127s	
12908/22750 (epoch 28.369), train_loss = 0.88697187, grad/param norm = 2.2710e-01, time/batch = 16.2406s	
12909/22750 (epoch 28.371), train_loss = 0.88982123, grad/param norm = 2.0971e-01, time/batch = 15.8444s	
12910/22750 (epoch 28.374), train_loss = 0.78099485, grad/param norm = 2.0735e-01, time/batch = 14.9663s	
12911/22750 (epoch 28.376), train_loss = 0.86245367, grad/param norm = 1.9388e-01, time/batch = 15.4596s	
12912/22750 (epoch 28.378), train_loss = 0.89760338, grad/param norm = 2.2196e-01, time/batch = 15.6851s	
12913/22750 (epoch 28.380), train_loss = 0.96192473, grad/param norm = 2.2569e-01, time/batch = 14.9467s	
12914/22750 (epoch 28.382), train_loss = 0.86652459, grad/param norm = 2.1202e-01, time/batch = 15.4641s	
12915/22750 (epoch 28.385), train_loss = 0.94288198, grad/param norm = 2.0763e-01, time/batch = 15.4703s	
12916/22750 (epoch 28.387), train_loss = 0.90488295, grad/param norm = 2.0431e-01, time/batch = 15.1538s	
12917/22750 (epoch 28.389), train_loss = 0.73412419, grad/param norm = 2.0694e-01, time/batch = 15.3037s	
12918/22750 (epoch 28.391), train_loss = 0.55467285, grad/param norm = 1.6222e-01, time/batch = 15.8137s	
12919/22750 (epoch 28.393), train_loss = 0.71956620, grad/param norm = 1.8469e-01, time/batch = 16.0948s	
12920/22750 (epoch 28.396), train_loss = 0.92142714, grad/param norm = 2.0933e-01, time/batch = 15.0534s	
12921/22750 (epoch 28.398), train_loss = 0.85077786, grad/param norm = 2.0183e-01, time/batch = 15.3766s	
12922/22750 (epoch 28.400), train_loss = 0.84081601, grad/param norm = 1.9416e-01, time/batch = 15.1309s	
12923/22750 (epoch 28.402), train_loss = 0.93040415, grad/param norm = 2.2262e-01, time/batch = 15.9300s	
12924/22750 (epoch 28.404), train_loss = 0.99658812, grad/param norm = 2.1574e-01, time/batch = 15.2108s	
12925/22750 (epoch 28.407), train_loss = 0.95577537, grad/param norm = 2.0515e-01, time/batch = 15.0678s	
12926/22750 (epoch 28.409), train_loss = 0.80031125, grad/param norm = 2.1387e-01, time/batch = 14.8405s	
12927/22750 (epoch 28.411), train_loss = 0.82079115, grad/param norm = 2.0904e-01, time/batch = 15.7868s	
12928/22750 (epoch 28.413), train_loss = 0.64436107, grad/param norm = 1.9181e-01, time/batch = 15.3144s	
12929/22750 (epoch 28.415), train_loss = 0.67892955, grad/param norm = 1.8647e-01, time/batch = 15.3019s	
12930/22750 (epoch 28.418), train_loss = 0.80869718, grad/param norm = 2.0871e-01, time/batch = 15.0459s	
12931/22750 (epoch 28.420), train_loss = 0.95174532, grad/param norm = 2.5150e-01, time/batch = 15.6143s	
12932/22750 (epoch 28.422), train_loss = 1.08951743, grad/param norm = 2.4209e-01, time/batch = 15.0452s	
12933/22750 (epoch 28.424), train_loss = 1.06777056, grad/param norm = 2.5868e-01, time/batch = 15.2103s	
12934/22750 (epoch 28.426), train_loss = 1.05845221, grad/param norm = 2.1244e-01, time/batch = 15.7639s	
12935/22750 (epoch 28.429), train_loss = 0.79391918, grad/param norm = 2.0682e-01, time/batch = 15.2959s	
12936/22750 (epoch 28.431), train_loss = 0.71159451, grad/param norm = 1.9425e-01, time/batch = 15.1332s	
12937/22750 (epoch 28.433), train_loss = 0.83092524, grad/param norm = 2.0379e-01, time/batch = 15.1242s	
12938/22750 (epoch 28.435), train_loss = 0.65775197, grad/param norm = 1.6674e-01, time/batch = 15.3674s	
12939/22750 (epoch 28.437), train_loss = 0.57514760, grad/param norm = 2.0032e-01, time/batch = 15.1589s	
12940/22750 (epoch 28.440), train_loss = 0.86702571, grad/param norm = 2.4712e-01, time/batch = 15.4361s	
12941/22750 (epoch 28.442), train_loss = 0.88652983, grad/param norm = 2.1379e-01, time/batch = 15.0576s	
12942/22750 (epoch 28.444), train_loss = 0.84171628, grad/param norm = 2.2402e-01, time/batch = 14.8767s	
12943/22750 (epoch 28.446), train_loss = 0.85587235, grad/param norm = 2.3119e-01, time/batch = 14.7230s	
12944/22750 (epoch 28.448), train_loss = 1.11822963, grad/param norm = 2.4758e-01, time/batch = 14.9771s	
12945/22750 (epoch 28.451), train_loss = 1.06656271, grad/param norm = 2.1516e-01, time/batch = 15.0532s	
12946/22750 (epoch 28.453), train_loss = 0.97994365, grad/param norm = 2.4308e-01, time/batch = 15.4558s	
12947/22750 (epoch 28.455), train_loss = 1.06110844, grad/param norm = 2.2665e-01, time/batch = 15.2849s	
12948/22750 (epoch 28.457), train_loss = 0.97580162, grad/param norm = 2.9981e-01, time/batch = 15.0532s	
12949/22750 (epoch 28.459), train_loss = 0.94120531, grad/param norm = 2.0988e-01, time/batch = 15.0399s	
12950/22750 (epoch 28.462), train_loss = 0.94059969, grad/param norm = 2.0285e-01, time/batch = 15.2228s	
12951/22750 (epoch 28.464), train_loss = 0.74378825, grad/param norm = 2.0122e-01, time/batch = 15.1595s	
12952/22750 (epoch 28.466), train_loss = 0.97996941, grad/param norm = 2.7197e-01, time/batch = 15.1347s	
12953/22750 (epoch 28.468), train_loss = 0.91958455, grad/param norm = 2.7260e-01, time/batch = 15.0688s	
12954/22750 (epoch 28.470), train_loss = 1.00274212, grad/param norm = 2.4515e-01, time/batch = 15.3864s	
12955/22750 (epoch 28.473), train_loss = 0.86606339, grad/param norm = 2.2971e-01, time/batch = 15.3620s	
12956/22750 (epoch 28.475), train_loss = 0.90068898, grad/param norm = 2.0547e-01, time/batch = 14.9751s	
12957/22750 (epoch 28.477), train_loss = 0.77636724, grad/param norm = 2.0412e-01, time/batch = 15.1885s	
12958/22750 (epoch 28.479), train_loss = 0.74647304, grad/param norm = 1.9746e-01, time/batch = 15.9231s	
12959/22750 (epoch 28.481), train_loss = 0.72256595, grad/param norm = 1.7550e-01, time/batch = 15.3610s	
12960/22750 (epoch 28.484), train_loss = 0.60654426, grad/param norm = 1.9271e-01, time/batch = 15.0467s	
12961/22750 (epoch 28.486), train_loss = 0.74350168, grad/param norm = 2.1385e-01, time/batch = 15.5274s	
12962/22750 (epoch 28.488), train_loss = 0.65912176, grad/param norm = 1.9202e-01, time/batch = 15.4731s	
12963/22750 (epoch 28.490), train_loss = 0.83432002, grad/param norm = 2.0564e-01, time/batch = 15.4818s	
12964/22750 (epoch 28.492), train_loss = 0.95091863, grad/param norm = 2.1136e-01, time/batch = 15.1622s	
12965/22750 (epoch 28.495), train_loss = 0.77954435, grad/param norm = 2.1650e-01, time/batch = 14.7422s	
12966/22750 (epoch 28.497), train_loss = 0.84002849, grad/param norm = 2.5799e-01, time/batch = 15.6024s	
12967/22750 (epoch 28.499), train_loss = 0.79303350, grad/param norm = 2.1224e-01, time/batch = 14.7978s	
12968/22750 (epoch 28.501), train_loss = 0.85878907, grad/param norm = 2.2504e-01, time/batch = 14.9624s	
12969/22750 (epoch 28.503), train_loss = 0.86150223, grad/param norm = 2.2338e-01, time/batch = 14.8944s	
12970/22750 (epoch 28.505), train_loss = 0.76205365, grad/param norm = 2.0906e-01, time/batch = 15.4625s	
12971/22750 (epoch 28.508), train_loss = 0.69735533, grad/param norm = 2.0293e-01, time/batch = 14.9613s	
12972/22750 (epoch 28.510), train_loss = 0.75019217, grad/param norm = 2.0618e-01, time/batch = 15.1365s	
12973/22750 (epoch 28.512), train_loss = 0.77247758, grad/param norm = 2.0999e-01, time/batch = 14.9925s	
12974/22750 (epoch 28.514), train_loss = 0.81181569, grad/param norm = 2.0851e-01, time/batch = 15.5551s	
12975/22750 (epoch 28.516), train_loss = 0.81797853, grad/param norm = 2.1406e-01, time/batch = 14.9991s	
12976/22750 (epoch 28.519), train_loss = 0.92369757, grad/param norm = 2.4093e-01, time/batch = 15.1548s	
12977/22750 (epoch 28.521), train_loss = 0.86856069, grad/param norm = 2.5489e-01, time/batch = 15.1950s	
12978/22750 (epoch 28.523), train_loss = 0.82317654, grad/param norm = 2.6827e-01, time/batch = 15.6872s	
12979/22750 (epoch 28.525), train_loss = 1.01216113, grad/param norm = 2.3951e-01, time/batch = 14.9750s	
12980/22750 (epoch 28.527), train_loss = 0.85684953, grad/param norm = 2.0273e-01, time/batch = 15.1290s	
12981/22750 (epoch 28.530), train_loss = 0.78419236, grad/param norm = 2.1900e-01, time/batch = 15.6822s	
12982/22750 (epoch 28.532), train_loss = 0.74082210, grad/param norm = 1.8617e-01, time/batch = 15.6118s	
12983/22750 (epoch 28.534), train_loss = 0.93756776, grad/param norm = 2.2572e-01, time/batch = 15.1346s	
12984/22750 (epoch 28.536), train_loss = 0.88303336, grad/param norm = 1.9782e-01, time/batch = 16.0889s	
12985/22750 (epoch 28.538), train_loss = 0.87140984, grad/param norm = 1.9127e-01, time/batch = 15.8455s	
12986/22750 (epoch 28.541), train_loss = 0.74544270, grad/param norm = 2.0297e-01, time/batch = 16.5192s	
12987/22750 (epoch 28.543), train_loss = 0.74573165, grad/param norm = 2.0334e-01, time/batch = 16.5033s	
12988/22750 (epoch 28.545), train_loss = 0.93106494, grad/param norm = 2.1338e-01, time/batch = 15.7018s	
12989/22750 (epoch 28.547), train_loss = 0.78653060, grad/param norm = 1.8072e-01, time/batch = 15.4563s	
12990/22750 (epoch 28.549), train_loss = 0.83587853, grad/param norm = 2.0136e-01, time/batch = 15.4511s	
12991/22750 (epoch 28.552), train_loss = 0.89937168, grad/param norm = 2.2348e-01, time/batch = 15.1271s	
12992/22750 (epoch 28.554), train_loss = 0.91945002, grad/param norm = 2.2422e-01, time/batch = 15.2906s	
12993/22750 (epoch 28.556), train_loss = 0.90423061, grad/param norm = 2.3058e-01, time/batch = 15.6986s	
12994/22750 (epoch 28.558), train_loss = 0.92482481, grad/param norm = 2.2300e-01, time/batch = 15.1376s	
12995/22750 (epoch 28.560), train_loss = 0.82135966, grad/param norm = 2.0937e-01, time/batch = 15.1555s	
12996/22750 (epoch 28.563), train_loss = 0.96313774, grad/param norm = 2.2418e-01, time/batch = 15.2420s	
12997/22750 (epoch 28.565), train_loss = 0.92650017, grad/param norm = 2.2652e-01, time/batch = 15.6246s	
12998/22750 (epoch 28.567), train_loss = 0.90971962, grad/param norm = 2.0677e-01, time/batch = 15.2241s	
12999/22750 (epoch 28.569), train_loss = 0.85502972, grad/param norm = 2.1852e-01, time/batch = 14.8605s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_wakata_epoch28.57_1.6440.t7	
13000/22750 (epoch 28.571), train_loss = 0.83671356, grad/param norm = 2.2332e-01, time/batch = 15.0506s	
13001/22750 (epoch 28.574), train_loss = 1.54012602, grad/param norm = 3.1709e-01, time/batch = 19.5354s	
13002/22750 (epoch 28.576), train_loss = 0.83057768, grad/param norm = 2.2199e-01, time/batch = 17.9334s	
13003/22750 (epoch 28.578), train_loss = 0.74411926, grad/param norm = 2.0819e-01, time/batch = 20.1547s	
13004/22750 (epoch 28.580), train_loss = 0.91727521, grad/param norm = 2.5767e-01, time/batch = 20.6432s	
13005/22750 (epoch 28.582), train_loss = 0.78678612, grad/param norm = 2.0685e-01, time/batch = 18.7588s	
13006/22750 (epoch 28.585), train_loss = 0.74391765, grad/param norm = 2.1338e-01, time/batch = 17.6745s	
13007/22750 (epoch 28.587), train_loss = 0.75317961, grad/param norm = 1.9846e-01, time/batch = 18.5256s	
13008/22750 (epoch 28.589), train_loss = 0.68624985, grad/param norm = 1.9023e-01, time/batch = 16.5178s	
13009/22750 (epoch 28.591), train_loss = 0.84546710, grad/param norm = 2.0788e-01, time/batch = 17.5720s	
13010/22750 (epoch 28.593), train_loss = 1.01407005, grad/param norm = 2.1260e-01, time/batch = 19.8498s	
13011/22750 (epoch 28.596), train_loss = 0.98144336, grad/param norm = 2.4136e-01, time/batch = 19.3031s	
13012/22750 (epoch 28.598), train_loss = 1.00699425, grad/param norm = 2.5505e-01, time/batch = 18.8368s	
13013/22750 (epoch 28.600), train_loss = 0.98491465, grad/param norm = 2.2892e-01, time/batch = 19.7464s	
13014/22750 (epoch 28.602), train_loss = 0.78826934, grad/param norm = 2.0299e-01, time/batch = 16.9246s	
13015/22750 (epoch 28.604), train_loss = 0.80459626, grad/param norm = 2.2209e-01, time/batch = 31.1705s	
13016/22750 (epoch 28.607), train_loss = 0.74150912, grad/param norm = 1.7745e-01, time/batch = 17.6600s	
13017/22750 (epoch 28.609), train_loss = 0.69012778, grad/param norm = 1.7496e-01, time/batch = 18.6126s	
13018/22750 (epoch 28.611), train_loss = 0.80972289, grad/param norm = 2.1086e-01, time/batch = 17.6557s	
13019/22750 (epoch 28.613), train_loss = 0.78683597, grad/param norm = 1.9827e-01, time/batch = 16.4306s	
13020/22750 (epoch 28.615), train_loss = 0.81071762, grad/param norm = 1.8934e-01, time/batch = 16.3457s	
13021/22750 (epoch 28.618), train_loss = 0.82680204, grad/param norm = 2.0228e-01, time/batch = 16.5144s	
13022/22750 (epoch 28.620), train_loss = 0.81326964, grad/param norm = 2.1108e-01, time/batch = 17.8407s	
13023/22750 (epoch 28.622), train_loss = 0.68063267, grad/param norm = 1.7821e-01, time/batch = 19.0151s	
13024/22750 (epoch 28.624), train_loss = 0.77933712, grad/param norm = 2.1801e-01, time/batch = 16.5898s	
13025/22750 (epoch 28.626), train_loss = 0.67753467, grad/param norm = 1.8525e-01, time/batch = 16.5314s	
13026/22750 (epoch 28.629), train_loss = 0.78745464, grad/param norm = 1.9590e-01, time/batch = 18.3706s	
13027/22750 (epoch 28.631), train_loss = 0.84040237, grad/param norm = 2.1695e-01, time/batch = 19.3717s	
13028/22750 (epoch 28.633), train_loss = 0.69881278, grad/param norm = 1.8751e-01, time/batch = 18.5270s	
13029/22750 (epoch 28.635), train_loss = 0.82949865, grad/param norm = 2.0595e-01, time/batch = 19.7596s	
13030/22750 (epoch 28.637), train_loss = 0.89605282, grad/param norm = 2.3528e-01, time/batch = 19.8204s	
13031/22750 (epoch 28.640), train_loss = 0.91507517, grad/param norm = 2.0984e-01, time/batch = 18.3979s	
13032/22750 (epoch 28.642), train_loss = 0.96691929, grad/param norm = 2.1129e-01, time/batch = 19.1606s	
13033/22750 (epoch 28.644), train_loss = 0.84081747, grad/param norm = 2.7071e-01, time/batch = 19.9110s	
13034/22750 (epoch 28.646), train_loss = 0.90923217, grad/param norm = 2.9654e-01, time/batch = 19.1634s	
13035/22750 (epoch 28.648), train_loss = 0.91126619, grad/param norm = 2.2107e-01, time/batch = 21.0167s	
13036/22750 (epoch 28.651), train_loss = 0.92505024, grad/param norm = 2.2418e-01, time/batch = 18.1108s	
13037/22750 (epoch 28.653), train_loss = 0.94558219, grad/param norm = 2.0788e-01, time/batch = 17.2391s	
13038/22750 (epoch 28.655), train_loss = 0.86034253, grad/param norm = 1.8540e-01, time/batch = 18.5080s	
13039/22750 (epoch 28.657), train_loss = 1.02482325, grad/param norm = 2.3058e-01, time/batch = 17.9686s	
13040/22750 (epoch 28.659), train_loss = 1.02373663, grad/param norm = 2.1933e-01, time/batch = 17.3263s	
13041/22750 (epoch 28.662), train_loss = 1.03701061, grad/param norm = 2.7442e-01, time/batch = 18.2546s	
13042/22750 (epoch 28.664), train_loss = 0.92016728, grad/param norm = 2.1165e-01, time/batch = 20.0745s	
13043/22750 (epoch 28.666), train_loss = 0.72477080, grad/param norm = 1.8513e-01, time/batch = 17.8429s	
13044/22750 (epoch 28.668), train_loss = 0.86467365, grad/param norm = 2.1013e-01, time/batch = 20.4548s	
13045/22750 (epoch 28.670), train_loss = 0.86036950, grad/param norm = 2.1392e-01, time/batch = 18.2702s	
13046/22750 (epoch 28.673), train_loss = 1.07602866, grad/param norm = 2.3789e-01, time/batch = 19.5910s	
13047/22750 (epoch 28.675), train_loss = 1.19683773, grad/param norm = 2.4799e-01, time/batch = 19.9749s	
13048/22750 (epoch 28.677), train_loss = 1.05109851, grad/param norm = 2.3245e-01, time/batch = 17.5143s	
13049/22750 (epoch 28.679), train_loss = 1.04920773, grad/param norm = 2.5563e-01, time/batch = 19.3230s	
13050/22750 (epoch 28.681), train_loss = 1.01552506, grad/param norm = 2.2194e-01, time/batch = 18.5821s	
13051/22750 (epoch 28.684), train_loss = 1.03653521, grad/param norm = 2.2926e-01, time/batch = 18.3437s	
13052/22750 (epoch 28.686), train_loss = 1.05997468, grad/param norm = 2.6854e-01, time/batch = 17.4197s	
13053/22750 (epoch 28.688), train_loss = 1.02044459, grad/param norm = 2.3845e-01, time/batch = 16.6843s	
13054/22750 (epoch 28.690), train_loss = 1.00981679, grad/param norm = 2.3641e-01, time/batch = 18.1140s	
13055/22750 (epoch 28.692), train_loss = 1.03108978, grad/param norm = 2.3472e-01, time/batch = 17.6183s	
13056/22750 (epoch 28.695), train_loss = 0.90242344, grad/param norm = 2.1002e-01, time/batch = 16.2502s	
13057/22750 (epoch 28.697), train_loss = 0.90084418, grad/param norm = 2.1789e-01, time/batch = 15.4269s	
13058/22750 (epoch 28.699), train_loss = 0.85506941, grad/param norm = 2.0735e-01, time/batch = 16.4157s	
13059/22750 (epoch 28.701), train_loss = 0.74193504, grad/param norm = 1.9346e-01, time/batch = 20.2398s	
13060/22750 (epoch 28.703), train_loss = 0.84044964, grad/param norm = 2.0572e-01, time/batch = 16.8148s	
13061/22750 (epoch 28.705), train_loss = 0.81195548, grad/param norm = 2.0828e-01, time/batch = 18.4210s	
13062/22750 (epoch 28.708), train_loss = 0.90596991, grad/param norm = 2.4619e-01, time/batch = 19.6718s	
13063/22750 (epoch 28.710), train_loss = 0.78163262, grad/param norm = 2.1044e-01, time/batch = 17.8476s	
13064/22750 (epoch 28.712), train_loss = 0.73994678, grad/param norm = 1.9069e-01, time/batch = 20.1860s	
13065/22750 (epoch 28.714), train_loss = 0.71270027, grad/param norm = 1.8617e-01, time/batch = 17.1944s	
13066/22750 (epoch 28.716), train_loss = 0.74662091, grad/param norm = 1.8483e-01, time/batch = 17.6629s	
13067/22750 (epoch 28.719), train_loss = 0.83551150, grad/param norm = 2.4351e-01, time/batch = 16.9066s	
13068/22750 (epoch 28.721), train_loss = 0.94455112, grad/param norm = 2.0042e-01, time/batch = 17.4228s	
13069/22750 (epoch 28.723), train_loss = 0.97069086, grad/param norm = 2.6693e-01, time/batch = 18.5977s	
13070/22750 (epoch 28.725), train_loss = 0.83656739, grad/param norm = 2.0894e-01, time/batch = 17.0105s	
13071/22750 (epoch 28.727), train_loss = 0.81193214, grad/param norm = 2.0199e-01, time/batch = 18.4323s	
13072/22750 (epoch 28.730), train_loss = 0.81755706, grad/param norm = 2.2342e-01, time/batch = 20.4496s	
13073/22750 (epoch 28.732), train_loss = 0.77683759, grad/param norm = 1.9374e-01, time/batch = 17.5303s	
13074/22750 (epoch 28.734), train_loss = 0.69482702, grad/param norm = 1.7288e-01, time/batch = 20.3220s	
13075/22750 (epoch 28.736), train_loss = 0.80291779, grad/param norm = 2.2350e-01, time/batch = 19.9026s	
13076/22750 (epoch 28.738), train_loss = 0.91588428, grad/param norm = 2.1812e-01, time/batch = 17.4186s	
13077/22750 (epoch 28.741), train_loss = 0.97014376, grad/param norm = 2.1885e-01, time/batch = 18.9184s	
13078/22750 (epoch 28.743), train_loss = 0.90765898, grad/param norm = 2.1395e-01, time/batch = 19.4987s	
13079/22750 (epoch 28.745), train_loss = 0.74108524, grad/param norm = 1.9166e-01, time/batch = 16.1822s	
13080/22750 (epoch 28.747), train_loss = 0.83300387, grad/param norm = 1.9495e-01, time/batch = 16.5739s	
13081/22750 (epoch 28.749), train_loss = 1.00756338, grad/param norm = 2.3657e-01, time/batch = 20.2759s	
13082/22750 (epoch 28.752), train_loss = 0.87778677, grad/param norm = 2.1361e-01, time/batch = 19.6097s	
13083/22750 (epoch 28.754), train_loss = 0.90765797, grad/param norm = 2.2600e-01, time/batch = 19.2437s	
13084/22750 (epoch 28.756), train_loss = 0.79732739, grad/param norm = 2.1922e-01, time/batch = 18.5872s	
13085/22750 (epoch 28.758), train_loss = 0.77701525, grad/param norm = 2.0583e-01, time/batch = 19.0868s	
13086/22750 (epoch 28.760), train_loss = 0.80939309, grad/param norm = 2.0622e-01, time/batch = 19.4833s	
13087/22750 (epoch 28.763), train_loss = 0.87129305, grad/param norm = 2.1565e-01, time/batch = 18.7526s	
13088/22750 (epoch 28.765), train_loss = 0.85293691, grad/param norm = 2.2606e-01, time/batch = 20.1471s	
13089/22750 (epoch 28.767), train_loss = 0.88302510, grad/param norm = 2.1950e-01, time/batch = 18.6587s	
13090/22750 (epoch 28.769), train_loss = 1.02942200, grad/param norm = 2.5386e-01, time/batch = 19.1079s	
13091/22750 (epoch 28.771), train_loss = 1.02531618, grad/param norm = 2.4308e-01, time/batch = 19.7822s	
13092/22750 (epoch 28.774), train_loss = 0.83629102, grad/param norm = 2.4993e-01, time/batch = 17.8509s	
13093/22750 (epoch 28.776), train_loss = 0.96469852, grad/param norm = 2.2249e-01, time/batch = 18.6574s	
13094/22750 (epoch 28.778), train_loss = 1.02786242, grad/param norm = 2.2335e-01, time/batch = 19.1604s	
13095/22750 (epoch 28.780), train_loss = 0.88107663, grad/param norm = 2.0793e-01, time/batch = 17.6553s	
13096/22750 (epoch 28.782), train_loss = 1.05725529, grad/param norm = 2.4083e-01, time/batch = 18.7329s	
13097/22750 (epoch 28.785), train_loss = 0.84846646, grad/param norm = 2.2277e-01, time/batch = 18.4334s	
13098/22750 (epoch 28.787), train_loss = 0.76139939, grad/param norm = 2.2356e-01, time/batch = 17.7605s	
13099/22750 (epoch 28.789), train_loss = 0.83868960, grad/param norm = 1.9564e-01, time/batch = 18.8737s	
13100/22750 (epoch 28.791), train_loss = 0.81531984, grad/param norm = 1.9755e-01, time/batch = 20.0982s	
13101/22750 (epoch 28.793), train_loss = 0.80046497, grad/param norm = 2.5825e-01, time/batch = 19.4242s	
13102/22750 (epoch 28.796), train_loss = 0.72350832, grad/param norm = 1.8593e-01, time/batch = 19.4092s	
13103/22750 (epoch 28.798), train_loss = 0.78091842, grad/param norm = 2.0043e-01, time/batch = 20.4157s	
13104/22750 (epoch 28.800), train_loss = 0.78454052, grad/param norm = 2.0071e-01, time/batch = 17.1722s	
13105/22750 (epoch 28.802), train_loss = 0.71487478, grad/param norm = 2.1886e-01, time/batch = 18.2200s	
13106/22750 (epoch 28.804), train_loss = 0.96624632, grad/param norm = 2.4550e-01, time/batch = 19.1718s	
13107/22750 (epoch 28.807), train_loss = 0.92913555, grad/param norm = 2.2423e-01, time/batch = 20.2550s	
13108/22750 (epoch 28.809), train_loss = 0.97440649, grad/param norm = 2.2577e-01, time/batch = 17.5745s	
13109/22750 (epoch 28.811), train_loss = 0.87406896, grad/param norm = 2.3995e-01, time/batch = 16.1785s	
13110/22750 (epoch 28.813), train_loss = 0.89931754, grad/param norm = 2.1237e-01, time/batch = 17.4314s	
13111/22750 (epoch 28.815), train_loss = 1.03034682, grad/param norm = 2.2925e-01, time/batch = 16.4749s	
13112/22750 (epoch 28.818), train_loss = 0.96290057, grad/param norm = 1.9727e-01, time/batch = 16.7362s	
13113/22750 (epoch 28.820), train_loss = 1.10069044, grad/param norm = 2.2557e-01, time/batch = 15.6977s	
13114/22750 (epoch 28.822), train_loss = 0.90423398, grad/param norm = 2.1804e-01, time/batch = 16.1025s	
13115/22750 (epoch 28.824), train_loss = 0.77689746, grad/param norm = 2.1819e-01, time/batch = 16.0930s	
13116/22750 (epoch 28.826), train_loss = 0.86460134, grad/param norm = 2.1584e-01, time/batch = 15.5246s	
13117/22750 (epoch 28.829), train_loss = 1.00420558, grad/param norm = 2.3901e-01, time/batch = 15.6910s	
13118/22750 (epoch 28.831), train_loss = 0.95790400, grad/param norm = 2.1507e-01, time/batch = 15.5441s	
13119/22750 (epoch 28.833), train_loss = 0.90609771, grad/param norm = 2.3346e-01, time/batch = 16.1079s	
13120/22750 (epoch 28.835), train_loss = 0.78180909, grad/param norm = 2.0589e-01, time/batch = 15.5433s	
13121/22750 (epoch 28.837), train_loss = 0.84194613, grad/param norm = 2.0205e-01, time/batch = 15.9309s	
13122/22750 (epoch 28.840), train_loss = 0.75771447, grad/param norm = 1.9964e-01, time/batch = 16.1640s	
13123/22750 (epoch 28.842), train_loss = 0.80311313, grad/param norm = 1.9667e-01, time/batch = 15.7664s	
13124/22750 (epoch 28.844), train_loss = 0.92174053, grad/param norm = 2.3934e-01, time/batch = 16.1668s	
13125/22750 (epoch 28.846), train_loss = 0.90408219, grad/param norm = 2.1008e-01, time/batch = 15.5253s	
13126/22750 (epoch 28.848), train_loss = 0.79192342, grad/param norm = 1.8126e-01, time/batch = 15.9269s	
13127/22750 (epoch 28.851), train_loss = 0.77741044, grad/param norm = 1.9225e-01, time/batch = 16.4594s	
13128/22750 (epoch 28.853), train_loss = 0.93611918, grad/param norm = 1.9718e-01, time/batch = 15.6168s	
13129/22750 (epoch 28.855), train_loss = 0.79374975, grad/param norm = 1.8775e-01, time/batch = 15.6277s	
13130/22750 (epoch 28.857), train_loss = 0.91013022, grad/param norm = 2.0571e-01, time/batch = 16.8842s	
13131/22750 (epoch 28.859), train_loss = 0.92352481, grad/param norm = 3.1074e-01, time/batch = 16.8948s	
13132/22750 (epoch 28.862), train_loss = 1.04211071, grad/param norm = 2.3910e-01, time/batch = 15.6907s	
13133/22750 (epoch 28.864), train_loss = 0.87187437, grad/param norm = 2.0925e-01, time/batch = 16.4190s	
13134/22750 (epoch 28.866), train_loss = 0.91201992, grad/param norm = 1.9409e-01, time/batch = 16.6278s	
13135/22750 (epoch 28.868), train_loss = 0.79299376, grad/param norm = 2.0871e-01, time/batch = 15.7633s	
13136/22750 (epoch 28.870), train_loss = 0.73178623, grad/param norm = 2.1406e-01, time/batch = 15.6875s	
13137/22750 (epoch 28.873), train_loss = 0.82328628, grad/param norm = 1.8940e-01, time/batch = 15.9376s	
13138/22750 (epoch 28.875), train_loss = 0.93854076, grad/param norm = 2.2823e-01, time/batch = 16.0985s	
13139/22750 (epoch 28.877), train_loss = 0.79168126, grad/param norm = 2.2864e-01, time/batch = 16.6575s	
13140/22750 (epoch 28.879), train_loss = 0.98280064, grad/param norm = 2.3796e-01, time/batch = 16.1836s	
13141/22750 (epoch 28.881), train_loss = 0.91706196, grad/param norm = 2.2313e-01, time/batch = 16.0935s	
13142/22750 (epoch 28.884), train_loss = 0.80706819, grad/param norm = 2.0045e-01, time/batch = 15.9311s	
13143/22750 (epoch 28.886), train_loss = 0.92238526, grad/param norm = 2.1187e-01, time/batch = 15.6809s	
13144/22750 (epoch 28.888), train_loss = 0.93488509, grad/param norm = 1.9076e-01, time/batch = 15.6007s	
13145/22750 (epoch 28.890), train_loss = 0.93124245, grad/param norm = 2.2809e-01, time/batch = 16.0524s	
13146/22750 (epoch 28.892), train_loss = 1.20220713, grad/param norm = 2.7291e-01, time/batch = 15.6825s	
13147/22750 (epoch 28.895), train_loss = 0.87404958, grad/param norm = 2.2736e-01, time/batch = 16.0847s	
13148/22750 (epoch 28.897), train_loss = 0.94529688, grad/param norm = 2.1103e-01, time/batch = 15.5984s	
13149/22750 (epoch 28.899), train_loss = 0.94017955, grad/param norm = 2.1387e-01, time/batch = 16.0041s	
13150/22750 (epoch 28.901), train_loss = 0.98589966, grad/param norm = 2.3140e-01, time/batch = 15.5433s	
13151/22750 (epoch 28.903), train_loss = 0.87000684, grad/param norm = 2.4852e-01, time/batch = 16.7160s	
13152/22750 (epoch 28.905), train_loss = 0.96168554, grad/param norm = 2.3067e-01, time/batch = 16.3431s	
13153/22750 (epoch 28.908), train_loss = 0.78824880, grad/param norm = 2.3052e-01, time/batch = 16.3719s	
13154/22750 (epoch 28.910), train_loss = 0.68849325, grad/param norm = 2.0526e-01, time/batch = 15.8585s	
13155/22750 (epoch 28.912), train_loss = 0.83534294, grad/param norm = 1.9758e-01, time/batch = 15.6112s	
13156/22750 (epoch 28.914), train_loss = 0.87261496, grad/param norm = 1.9600e-01, time/batch = 16.0169s	
13157/22750 (epoch 28.916), train_loss = 0.70576633, grad/param norm = 2.0249e-01, time/batch = 15.7719s	
13158/22750 (epoch 28.919), train_loss = 0.84972807, grad/param norm = 2.0976e-01, time/batch = 15.9202s	
13159/22750 (epoch 28.921), train_loss = 0.67759044, grad/param norm = 1.9734e-01, time/batch = 15.7735s	
13160/22750 (epoch 28.923), train_loss = 0.79346519, grad/param norm = 2.0115e-01, time/batch = 16.4268s	
13161/22750 (epoch 28.925), train_loss = 0.83036445, grad/param norm = 1.9630e-01, time/batch = 15.9406s	
13162/22750 (epoch 28.927), train_loss = 0.69561761, grad/param norm = 1.9456e-01, time/batch = 15.4718s	
13163/22750 (epoch 28.930), train_loss = 0.67925103, grad/param norm = 1.9022e-01, time/batch = 15.9308s	
13164/22750 (epoch 28.932), train_loss = 0.87833149, grad/param norm = 2.3585e-01, time/batch = 15.8557s	
13165/22750 (epoch 28.934), train_loss = 0.70486955, grad/param norm = 1.8157e-01, time/batch = 15.5305s	
13166/22750 (epoch 28.936), train_loss = 0.98632001, grad/param norm = 2.2871e-01, time/batch = 15.8517s	
13167/22750 (epoch 28.938), train_loss = 0.94315065, grad/param norm = 1.9338e-01, time/batch = 15.7742s	
13168/22750 (epoch 28.941), train_loss = 1.02435489, grad/param norm = 2.3502e-01, time/batch = 16.6322s	
13169/22750 (epoch 28.943), train_loss = 0.88277230, grad/param norm = 2.1476e-01, time/batch = 15.9876s	
13170/22750 (epoch 28.945), train_loss = 0.88892533, grad/param norm = 2.3371e-01, time/batch = 15.6356s	
13171/22750 (epoch 28.947), train_loss = 0.83293375, grad/param norm = 2.2351e-01, time/batch = 16.2776s	
13172/22750 (epoch 28.949), train_loss = 0.78511873, grad/param norm = 2.2372e-01, time/batch = 15.8689s	
13173/22750 (epoch 28.952), train_loss = 0.81070263, grad/param norm = 1.9451e-01, time/batch = 15.7026s	
13174/22750 (epoch 28.954), train_loss = 0.78881504, grad/param norm = 2.0450e-01, time/batch = 15.5383s	
13175/22750 (epoch 28.956), train_loss = 0.90580538, grad/param norm = 2.3296e-01, time/batch = 16.0136s	
13176/22750 (epoch 28.958), train_loss = 0.78952892, grad/param norm = 1.8169e-01, time/batch = 15.5241s	
13177/22750 (epoch 28.960), train_loss = 0.78583331, grad/param norm = 2.0832e-01, time/batch = 15.4472s	
13178/22750 (epoch 28.963), train_loss = 0.88730406, grad/param norm = 2.0280e-01, time/batch = 15.7792s	
13179/22750 (epoch 28.965), train_loss = 0.94767271, grad/param norm = 2.1214e-01, time/batch = 16.7146s	
13180/22750 (epoch 28.967), train_loss = 0.90483660, grad/param norm = 2.1122e-01, time/batch = 16.1777s	
13181/22750 (epoch 28.969), train_loss = 0.81320976, grad/param norm = 2.1391e-01, time/batch = 16.3598s	
13182/22750 (epoch 28.971), train_loss = 0.79126484, grad/param norm = 1.9587e-01, time/batch = 16.2914s	
13183/22750 (epoch 28.974), train_loss = 0.80373922, grad/param norm = 1.9775e-01, time/batch = 16.0481s	
13184/22750 (epoch 28.976), train_loss = 0.86095166, grad/param norm = 2.3628e-01, time/batch = 16.0224s	
13185/22750 (epoch 28.978), train_loss = 0.82509772, grad/param norm = 2.0936e-01, time/batch = 16.0218s	
13186/22750 (epoch 28.980), train_loss = 0.95882209, grad/param norm = 2.2800e-01, time/batch = 16.5715s	
13187/22750 (epoch 28.982), train_loss = 0.79013476, grad/param norm = 2.1111e-01, time/batch = 16.2652s	
13188/22750 (epoch 28.985), train_loss = 0.99984600, grad/param norm = 2.4106e-01, time/batch = 15.9395s	
13189/22750 (epoch 28.987), train_loss = 0.70151782, grad/param norm = 1.8969e-01, time/batch = 15.8714s	
13190/22750 (epoch 28.989), train_loss = 0.82300609, grad/param norm = 2.8327e-01, time/batch = 16.5649s	
13191/22750 (epoch 28.991), train_loss = 0.88751601, grad/param norm = 2.2007e-01, time/batch = 16.5188s	
13192/22750 (epoch 28.993), train_loss = 0.88309423, grad/param norm = 2.5126e-01, time/batch = 16.1377s	
13193/22750 (epoch 28.996), train_loss = 0.78617248, grad/param norm = 2.4748e-01, time/batch = 15.9565s	
13194/22750 (epoch 28.998), train_loss = 0.98584640, grad/param norm = 2.2901e-01, time/batch = 16.2738s	
decayed learning rate by a factor 0.97 to 0.0010875886858535	
13195/22750 (epoch 29.000), train_loss = 0.87089531, grad/param norm = 2.1259e-01, time/batch = 15.7774s	
13196/22750 (epoch 29.002), train_loss = 1.02279224, grad/param norm = 2.3532e-01, time/batch = 15.8502s	
13197/22750 (epoch 29.004), train_loss = 0.82512346, grad/param norm = 2.0168e-01, time/batch = 16.7438s	
13198/22750 (epoch 29.007), train_loss = 0.82845430, grad/param norm = 2.8859e-01, time/batch = 16.5674s	
13199/22750 (epoch 29.009), train_loss = 1.02517655, grad/param norm = 2.5643e-01, time/batch = 16.2387s	
13200/22750 (epoch 29.011), train_loss = 1.12409542, grad/param norm = 2.9320e-01, time/batch = 16.1834s	
13201/22750 (epoch 29.013), train_loss = 0.99451235, grad/param norm = 2.4179e-01, time/batch = 16.6722s	
13202/22750 (epoch 29.015), train_loss = 0.89876587, grad/param norm = 2.3717e-01, time/batch = 15.8773s	
13203/22750 (epoch 29.018), train_loss = 0.96213358, grad/param norm = 2.3690e-01, time/batch = 15.0611s	
13204/22750 (epoch 29.020), train_loss = 1.00739044, grad/param norm = 2.2448e-01, time/batch = 15.5434s	
13205/22750 (epoch 29.022), train_loss = 0.87487465, grad/param norm = 2.0501e-01, time/batch = 15.6918s	
13206/22750 (epoch 29.024), train_loss = 0.89747911, grad/param norm = 2.3330e-01, time/batch = 15.6875s	
13207/22750 (epoch 29.026), train_loss = 0.92549697, grad/param norm = 2.5281e-01, time/batch = 15.8390s	
13208/22750 (epoch 29.029), train_loss = 0.72869881, grad/param norm = 1.9885e-01, time/batch = 16.0322s	
13209/22750 (epoch 29.031), train_loss = 1.09440197, grad/param norm = 2.3349e-01, time/batch = 16.5706s	
13210/22750 (epoch 29.033), train_loss = 0.87225342, grad/param norm = 2.0911e-01, time/batch = 16.1710s	
13211/22750 (epoch 29.035), train_loss = 0.92429853, grad/param norm = 2.2435e-01, time/batch = 16.4376s	
13212/22750 (epoch 29.037), train_loss = 0.97307341, grad/param norm = 2.1528e-01, time/batch = 16.6725s	
13213/22750 (epoch 29.040), train_loss = 0.87649705, grad/param norm = 2.2774e-01, time/batch = 15.8681s	
13214/22750 (epoch 29.042), train_loss = 0.89447115, grad/param norm = 2.0727e-01, time/batch = 16.1017s	
13215/22750 (epoch 29.044), train_loss = 0.85676834, grad/param norm = 2.0588e-01, time/batch = 15.8651s	
13216/22750 (epoch 29.046), train_loss = 0.96992831, grad/param norm = 2.3956e-01, time/batch = 16.8174s	
13217/22750 (epoch 29.048), train_loss = 0.87661280, grad/param norm = 1.9037e-01, time/batch = 16.6803s	
13218/22750 (epoch 29.051), train_loss = 0.92140547, grad/param norm = 2.6254e-01, time/batch = 16.1836s	
13219/22750 (epoch 29.053), train_loss = 0.83165480, grad/param norm = 1.8620e-01, time/batch = 16.6720s	
13220/22750 (epoch 29.055), train_loss = 0.74614068, grad/param norm = 1.9053e-01, time/batch = 16.6051s	
13221/22750 (epoch 29.057), train_loss = 1.05982550, grad/param norm = 2.2556e-01, time/batch = 16.6090s	
13222/22750 (epoch 29.059), train_loss = 0.65281194, grad/param norm = 1.9905e-01, time/batch = 16.6096s	
13223/22750 (epoch 29.062), train_loss = 0.76127421, grad/param norm = 2.2613e-01, time/batch = 30.9541s	
13224/22750 (epoch 29.064), train_loss = 0.96478036, grad/param norm = 2.3378e-01, time/batch = 16.5094s	
13225/22750 (epoch 29.066), train_loss = 0.77608493, grad/param norm = 1.8735e-01, time/batch = 16.7182s	
13226/22750 (epoch 29.068), train_loss = 0.77557247, grad/param norm = 1.6906e-01, time/batch = 16.8109s	
13227/22750 (epoch 29.070), train_loss = 0.66049590, grad/param norm = 1.7482e-01, time/batch = 16.6478s	
13228/22750 (epoch 29.073), train_loss = 0.81349137, grad/param norm = 2.1294e-01, time/batch = 16.3436s	
13229/22750 (epoch 29.075), train_loss = 0.86458232, grad/param norm = 1.9576e-01, time/batch = 16.5867s	
13230/22750 (epoch 29.077), train_loss = 0.65361899, grad/param norm = 2.1326e-01, time/batch = 16.7370s	
13231/22750 (epoch 29.079), train_loss = 0.83906399, grad/param norm = 2.2592e-01, time/batch = 16.6866s	
13232/22750 (epoch 29.081), train_loss = 0.82317862, grad/param norm = 2.0639e-01, time/batch = 16.6156s	
13233/22750 (epoch 29.084), train_loss = 0.82675270, grad/param norm = 2.0435e-01, time/batch = 16.6859s	
13234/22750 (epoch 29.086), train_loss = 0.85518403, grad/param norm = 1.9506e-01, time/batch = 16.9796s	
13235/22750 (epoch 29.088), train_loss = 0.78010696, grad/param norm = 1.9328e-01, time/batch = 16.4367s	
13236/22750 (epoch 29.090), train_loss = 0.81102594, grad/param norm = 1.9119e-01, time/batch = 17.0511s	
13237/22750 (epoch 29.092), train_loss = 0.95266850, grad/param norm = 2.0704e-01, time/batch = 16.5932s	
13238/22750 (epoch 29.095), train_loss = 0.78145276, grad/param norm = 1.9621e-01, time/batch = 16.9066s	
13239/22750 (epoch 29.097), train_loss = 0.86146760, grad/param norm = 2.0727e-01, time/batch = 16.7268s	
13240/22750 (epoch 29.099), train_loss = 0.81638709, grad/param norm = 2.1081e-01, time/batch = 16.9782s	
13241/22750 (epoch 29.101), train_loss = 0.72962263, grad/param norm = 2.0592e-01, time/batch = 16.2881s	
13242/22750 (epoch 29.103), train_loss = 0.91012955, grad/param norm = 2.2901e-01, time/batch = 16.9045s	
13243/22750 (epoch 29.105), train_loss = 1.00724609, grad/param norm = 2.3982e-01, time/batch = 17.2496s	
13244/22750 (epoch 29.108), train_loss = 0.85806616, grad/param norm = 2.2153e-01, time/batch = 17.2219s	
13245/22750 (epoch 29.110), train_loss = 0.98458712, grad/param norm = 2.0361e-01, time/batch = 16.9659s	
13246/22750 (epoch 29.112), train_loss = 0.71942068, grad/param norm = 1.8259e-01, time/batch = 16.9193s	
13247/22750 (epoch 29.114), train_loss = 0.65182380, grad/param norm = 1.8907e-01, time/batch = 17.1463s	
13248/22750 (epoch 29.116), train_loss = 0.81820279, grad/param norm = 1.8449e-01, time/batch = 16.9087s	
13249/22750 (epoch 29.119), train_loss = 0.79883012, grad/param norm = 1.8025e-01, time/batch = 15.5215s	
13250/22750 (epoch 29.121), train_loss = 0.83615971, grad/param norm = 2.2689e-01, time/batch = 15.8340s	
13251/22750 (epoch 29.123), train_loss = 0.74784940, grad/param norm = 2.2509e-01, time/batch = 15.9453s	
13252/22750 (epoch 29.125), train_loss = 0.99273862, grad/param norm = 2.0932e-01, time/batch = 15.6223s	
13253/22750 (epoch 29.127), train_loss = 0.82535625, grad/param norm = 2.0854e-01, time/batch = 15.4694s	
13254/22750 (epoch 29.130), train_loss = 0.82959153, grad/param norm = 1.8144e-01, time/batch = 15.5403s	
13255/22750 (epoch 29.132), train_loss = 0.78442638, grad/param norm = 2.1649e-01, time/batch = 16.1659s	
13256/22750 (epoch 29.134), train_loss = 0.81481529, grad/param norm = 1.9496e-01, time/batch = 16.2409s	
13257/22750 (epoch 29.136), train_loss = 0.67795748, grad/param norm = 1.9436e-01, time/batch = 15.5346s	
13258/22750 (epoch 29.138), train_loss = 0.91698502, grad/param norm = 2.0846e-01, time/batch = 15.9081s	
13259/22750 (epoch 29.141), train_loss = 0.86828074, grad/param norm = 2.0817e-01, time/batch = 16.2910s	
13260/22750 (epoch 29.143), train_loss = 0.75560055, grad/param norm = 1.8948e-01, time/batch = 15.8414s	
13261/22750 (epoch 29.145), train_loss = 0.96015046, grad/param norm = 2.1485e-01, time/batch = 15.5393s	
13262/22750 (epoch 29.147), train_loss = 1.00869564, grad/param norm = 2.4163e-01, time/batch = 16.0347s	
13263/22750 (epoch 29.149), train_loss = 0.86035447, grad/param norm = 2.3038e-01, time/batch = 15.7141s	
13264/22750 (epoch 29.152), train_loss = 0.84697054, grad/param norm = 1.9849e-01, time/batch = 15.7826s	
13265/22750 (epoch 29.154), train_loss = 0.76419725, grad/param norm = 1.9053e-01, time/batch = 15.8493s	
13266/22750 (epoch 29.156), train_loss = 0.75980811, grad/param norm = 2.0200e-01, time/batch = 16.1790s	
13267/22750 (epoch 29.158), train_loss = 0.77941347, grad/param norm = 2.2511e-01, time/batch = 15.8530s	
13268/22750 (epoch 29.160), train_loss = 0.86602330, grad/param norm = 2.5093e-01, time/batch = 15.6848s	
13269/22750 (epoch 29.163), train_loss = 1.02992377, grad/param norm = 2.2213e-01, time/batch = 16.0836s	
13270/22750 (epoch 29.165), train_loss = 0.89743395, grad/param norm = 2.1588e-01, time/batch = 15.9299s	
13271/22750 (epoch 29.167), train_loss = 0.81921543, grad/param norm = 2.1607e-01, time/batch = 15.6941s	
13272/22750 (epoch 29.169), train_loss = 0.87901982, grad/param norm = 2.3867e-01, time/batch = 16.1152s	
13273/22750 (epoch 29.171), train_loss = 0.71778927, grad/param norm = 1.7838e-01, time/batch = 15.9571s	
13274/22750 (epoch 29.174), train_loss = 0.70570597, grad/param norm = 2.0721e-01, time/batch = 15.7838s	
13275/22750 (epoch 29.176), train_loss = 0.76147851, grad/param norm = 2.1084e-01, time/batch = 16.5494s	
13276/22750 (epoch 29.178), train_loss = 0.78478761, grad/param norm = 2.0819e-01, time/batch = 15.8464s	
13277/22750 (epoch 29.180), train_loss = 0.96822338, grad/param norm = 2.4296e-01, time/batch = 16.5793s	
13278/22750 (epoch 29.182), train_loss = 0.94866215, grad/param norm = 2.3631e-01, time/batch = 15.6097s	
13279/22750 (epoch 29.185), train_loss = 0.96973445, grad/param norm = 2.2911e-01, time/batch = 15.5302s	
13280/22750 (epoch 29.187), train_loss = 0.72699907, grad/param norm = 1.8136e-01, time/batch = 16.6469s	
13281/22750 (epoch 29.189), train_loss = 0.77774387, grad/param norm = 2.2943e-01, time/batch = 16.4949s	
13282/22750 (epoch 29.191), train_loss = 0.78697702, grad/param norm = 1.9654e-01, time/batch = 15.5484s	
13283/22750 (epoch 29.193), train_loss = 0.92364149, grad/param norm = 2.1675e-01, time/batch = 15.5718s	
13284/22750 (epoch 29.196), train_loss = 0.82007659, grad/param norm = 2.3373e-01, time/batch = 16.2050s	
13285/22750 (epoch 29.198), train_loss = 0.62838267, grad/param norm = 1.8790e-01, time/batch = 16.0320s	
13286/22750 (epoch 29.200), train_loss = 0.85859017, grad/param norm = 2.2735e-01, time/batch = 15.6097s	
13287/22750 (epoch 29.202), train_loss = 0.91287801, grad/param norm = 2.5209e-01, time/batch = 16.0261s	
13288/22750 (epoch 29.204), train_loss = 0.85693627, grad/param norm = 2.0720e-01, time/batch = 16.7415s	
13289/22750 (epoch 29.207), train_loss = 0.84796514, grad/param norm = 1.9517e-01, time/batch = 16.8742s	
13290/22750 (epoch 29.209), train_loss = 0.78788723, grad/param norm = 1.8773e-01, time/batch = 16.7367s	
13291/22750 (epoch 29.211), train_loss = 0.76642684, grad/param norm = 1.9955e-01, time/batch = 16.4189s	
13292/22750 (epoch 29.213), train_loss = 0.65466151, grad/param norm = 2.0707e-01, time/batch = 16.8293s	
13293/22750 (epoch 29.215), train_loss = 0.64143800, grad/param norm = 2.0411e-01, time/batch = 16.2894s	
13294/22750 (epoch 29.218), train_loss = 0.74383380, grad/param norm = 2.2446e-01, time/batch = 16.4525s	
13295/22750 (epoch 29.220), train_loss = 0.69145894, grad/param norm = 1.9923e-01, time/batch = 16.1922s	
13296/22750 (epoch 29.222), train_loss = 0.72210550, grad/param norm = 2.0282e-01, time/batch = 16.2534s	
13297/22750 (epoch 29.224), train_loss = 0.76280230, grad/param norm = 2.0059e-01, time/batch = 16.2335s	
13298/22750 (epoch 29.226), train_loss = 0.84811422, grad/param norm = 2.1629e-01, time/batch = 15.8226s	
13299/22750 (epoch 29.229), train_loss = 0.86559060, grad/param norm = 2.4622e-01, time/batch = 15.9372s	
13300/22750 (epoch 29.231), train_loss = 0.75604261, grad/param norm = 2.1034e-01, time/batch = 16.4835s	
13301/22750 (epoch 29.233), train_loss = 0.69751219, grad/param norm = 2.2641e-01, time/batch = 15.8558s	
13302/22750 (epoch 29.235), train_loss = 0.67087714, grad/param norm = 2.0850e-01, time/batch = 18.8906s	
13303/22750 (epoch 29.237), train_loss = 0.76065723, grad/param norm = 2.2697e-01, time/batch = 19.0082s	
13304/22750 (epoch 29.240), train_loss = 0.81734845, grad/param norm = 1.8224e-01, time/batch = 19.4599s	
13305/22750 (epoch 29.242), train_loss = 1.03708816, grad/param norm = 2.8271e-01, time/batch = 18.1770s	
13306/22750 (epoch 29.244), train_loss = 1.00230118, grad/param norm = 2.1837e-01, time/batch = 18.1465s	
13307/22750 (epoch 29.246), train_loss = 1.01710380, grad/param norm = 2.4959e-01, time/batch = 19.1521s	
13308/22750 (epoch 29.248), train_loss = 0.84018196, grad/param norm = 2.1909e-01, time/batch = 19.5741s	
13309/22750 (epoch 29.251), train_loss = 0.94947224, grad/param norm = 2.3502e-01, time/batch = 19.4129s	
13310/22750 (epoch 29.253), train_loss = 0.88467494, grad/param norm = 2.2593e-01, time/batch = 18.7421s	
13311/22750 (epoch 29.255), train_loss = 0.87324252, grad/param norm = 2.1807e-01, time/batch = 19.9801s	
13312/22750 (epoch 29.257), train_loss = 0.76800505, grad/param norm = 2.4395e-01, time/batch = 18.7401s	
13313/22750 (epoch 29.259), train_loss = 0.97901677, grad/param norm = 2.7671e-01, time/batch = 20.6821s	
13314/22750 (epoch 29.262), train_loss = 0.88071550, grad/param norm = 2.3420e-01, time/batch = 19.7802s	
13315/22750 (epoch 29.264), train_loss = 0.67529415, grad/param norm = 2.1012e-01, time/batch = 18.1020s	
13316/22750 (epoch 29.266), train_loss = 0.84093564, grad/param norm = 2.4065e-01, time/batch = 18.8251s	
13317/22750 (epoch 29.268), train_loss = 0.97717685, grad/param norm = 2.3943e-01, time/batch = 20.6509s	
13318/22750 (epoch 29.270), train_loss = 0.75220579, grad/param norm = 2.1780e-01, time/batch = 18.0790s	
13319/22750 (epoch 29.273), train_loss = 1.10880960, grad/param norm = 2.4656e-01, time/batch = 18.5703s	
13320/22750 (epoch 29.275), train_loss = 0.99091696, grad/param norm = 2.1204e-01, time/batch = 20.7360s	
13321/22750 (epoch 29.277), train_loss = 0.83285824, grad/param norm = 2.4478e-01, time/batch = 16.7987s	
13322/22750 (epoch 29.279), train_loss = 0.71811837, grad/param norm = 1.8458e-01, time/batch = 17.0789s	
13323/22750 (epoch 29.281), train_loss = 0.99006372, grad/param norm = 2.2445e-01, time/batch = 17.4296s	
13324/22750 (epoch 29.284), train_loss = 0.84550835, grad/param norm = 1.9040e-01, time/batch = 19.6036s	
13325/22750 (epoch 29.286), train_loss = 0.93133038, grad/param norm = 2.3621e-01, time/batch = 17.2499s	
13326/22750 (epoch 29.288), train_loss = 1.01785216, grad/param norm = 2.2451e-01, time/batch = 16.9066s	
13327/22750 (epoch 29.290), train_loss = 0.86948107, grad/param norm = 2.0570e-01, time/batch = 17.5133s	
13328/22750 (epoch 29.292), train_loss = 0.92422794, grad/param norm = 2.7457e-01, time/batch = 14.8985s	
13329/22750 (epoch 29.295), train_loss = 0.89517948, grad/param norm = 2.1531e-01, time/batch = 0.7172s	
13330/22750 (epoch 29.297), train_loss = 0.84865928, grad/param norm = 2.2321e-01, time/batch = 0.6988s	
13331/22750 (epoch 29.299), train_loss = 0.94581785, grad/param norm = 2.1547e-01, time/batch = 0.7040s	
13332/22750 (epoch 29.301), train_loss = 0.87406372, grad/param norm = 2.0872e-01, time/batch = 0.7003s	
13333/22750 (epoch 29.303), train_loss = 0.91375874, grad/param norm = 2.2377e-01, time/batch = 0.7044s	
13334/22750 (epoch 29.305), train_loss = 1.03115643, grad/param norm = 2.1970e-01, time/batch = 0.7070s	
13335/22750 (epoch 29.308), train_loss = 0.91693165, grad/param norm = 2.0490e-01, time/batch = 0.7546s	
13336/22750 (epoch 29.310), train_loss = 0.80254028, grad/param norm = 2.3681e-01, time/batch = 1.0409s	
13337/22750 (epoch 29.312), train_loss = 0.87947369, grad/param norm = 2.0197e-01, time/batch = 1.0326s	
13338/22750 (epoch 29.314), train_loss = 0.88120066, grad/param norm = 2.2274e-01, time/batch = 1.0494s	
13339/22750 (epoch 29.316), train_loss = 0.82194247, grad/param norm = 2.0962e-01, time/batch = 1.0417s	
13340/22750 (epoch 29.319), train_loss = 0.87486465, grad/param norm = 2.2285e-01, time/batch = 1.2939s	
13341/22750 (epoch 29.321), train_loss = 0.81953449, grad/param norm = 2.4181e-01, time/batch = 1.9719s	
13342/22750 (epoch 29.323), train_loss = 0.88223607, grad/param norm = 2.3474e-01, time/batch = 1.9435s	
13343/22750 (epoch 29.325), train_loss = 0.76212413, grad/param norm = 2.1252e-01, time/batch = 14.9739s	
13344/22750 (epoch 29.327), train_loss = 0.81115537, grad/param norm = 2.1423e-01, time/batch = 16.8519s	
13345/22750 (epoch 29.330), train_loss = 1.03148664, grad/param norm = 2.2476e-01, time/batch = 17.0867s	
13346/22750 (epoch 29.332), train_loss = 1.03823294, grad/param norm = 2.0692e-01, time/batch = 20.5223s	
13347/22750 (epoch 29.334), train_loss = 0.70335100, grad/param norm = 1.8256e-01, time/batch = 20.7724s	
13348/22750 (epoch 29.336), train_loss = 0.93979193, grad/param norm = 2.0081e-01, time/batch = 17.5075s	
13349/22750 (epoch 29.338), train_loss = 0.85244778, grad/param norm = 2.0638e-01, time/batch = 20.1559s	
13350/22750 (epoch 29.341), train_loss = 0.87243572, grad/param norm = 2.1987e-01, time/batch = 19.6681s	
13351/22750 (epoch 29.343), train_loss = 0.75357262, grad/param norm = 2.1510e-01, time/batch = 17.8161s	
13352/22750 (epoch 29.345), train_loss = 0.92743730, grad/param norm = 2.8323e-01, time/batch = 18.5758s	
13353/22750 (epoch 29.347), train_loss = 0.98682869, grad/param norm = 2.2729e-01, time/batch = 19.8351s	
13354/22750 (epoch 29.349), train_loss = 0.70316199, grad/param norm = 2.4914e-01, time/batch = 19.5231s	
13355/22750 (epoch 29.352), train_loss = 0.97265925, grad/param norm = 2.0905e-01, time/batch = 17.4083s	
13356/22750 (epoch 29.354), train_loss = 0.97931943, grad/param norm = 2.2219e-01, time/batch = 16.4216s	
13357/22750 (epoch 29.356), train_loss = 0.95072024, grad/param norm = 2.2090e-01, time/batch = 17.6640s	
13358/22750 (epoch 29.358), train_loss = 0.84163147, grad/param norm = 2.1173e-01, time/batch = 16.9005s	
13359/22750 (epoch 29.360), train_loss = 1.02198424, grad/param norm = 2.3534e-01, time/batch = 19.2412s	
13360/22750 (epoch 29.363), train_loss = 0.83977604, grad/param norm = 2.1715e-01, time/batch = 17.7564s	
13361/22750 (epoch 29.365), train_loss = 0.70196712, grad/param norm = 2.0788e-01, time/batch = 16.9959s	
13362/22750 (epoch 29.367), train_loss = 0.79573786, grad/param norm = 2.2669e-01, time/batch = 17.2225s	
13363/22750 (epoch 29.369), train_loss = 0.87393837, grad/param norm = 2.1312e-01, time/batch = 17.7644s	
13364/22750 (epoch 29.371), train_loss = 0.86125578, grad/param norm = 2.0629e-01, time/batch = 19.6681s	
13365/22750 (epoch 29.374), train_loss = 0.76643548, grad/param norm = 2.0081e-01, time/batch = 19.6718s	
13366/22750 (epoch 29.376), train_loss = 0.84555411, grad/param norm = 2.0204e-01, time/batch = 19.3141s	
13367/22750 (epoch 29.378), train_loss = 0.87763260, grad/param norm = 2.0372e-01, time/batch = 18.5600s	
13368/22750 (epoch 29.380), train_loss = 0.94332381, grad/param norm = 2.1067e-01, time/batch = 18.1612s	
13369/22750 (epoch 29.382), train_loss = 0.86185915, grad/param norm = 2.2259e-01, time/batch = 19.9781s	
13370/22750 (epoch 29.385), train_loss = 0.93007750, grad/param norm = 2.0135e-01, time/batch = 20.3174s	
13371/22750 (epoch 29.387), train_loss = 0.89732846, grad/param norm = 2.0162e-01, time/batch = 19.4052s	
13372/22750 (epoch 29.389), train_loss = 0.70956905, grad/param norm = 2.0021e-01, time/batch = 19.5063s	
13373/22750 (epoch 29.391), train_loss = 0.53978590, grad/param norm = 1.6809e-01, time/batch = 20.5078s	
13374/22750 (epoch 29.393), train_loss = 0.72546478, grad/param norm = 2.0371e-01, time/batch = 17.7493s	
13375/22750 (epoch 29.396), train_loss = 0.90778198, grad/param norm = 2.1608e-01, time/batch = 18.7576s	
13376/22750 (epoch 29.398), train_loss = 0.83934096, grad/param norm = 2.0259e-01, time/batch = 19.5790s	
13377/22750 (epoch 29.400), train_loss = 0.83446734, grad/param norm = 2.0332e-01, time/batch = 17.7354s	
13378/22750 (epoch 29.402), train_loss = 0.89755684, grad/param norm = 2.1492e-01, time/batch = 17.7771s	
13379/22750 (epoch 29.404), train_loss = 0.96778137, grad/param norm = 2.0667e-01, time/batch = 19.5769s	
13380/22750 (epoch 29.407), train_loss = 0.94096898, grad/param norm = 2.1166e-01, time/batch = 18.9747s	
13381/22750 (epoch 29.409), train_loss = 0.77957903, grad/param norm = 2.2985e-01, time/batch = 18.2523s	
13382/22750 (epoch 29.411), train_loss = 0.81796481, grad/param norm = 2.0430e-01, time/batch = 17.2505s	
13383/22750 (epoch 29.413), train_loss = 0.63716432, grad/param norm = 2.1895e-01, time/batch = 18.1500s	
13384/22750 (epoch 29.415), train_loss = 0.67894679, grad/param norm = 2.0061e-01, time/batch = 19.5769s	
13385/22750 (epoch 29.418), train_loss = 0.79138122, grad/param norm = 2.1157e-01, time/batch = 17.9299s	
13386/22750 (epoch 29.420), train_loss = 0.94945748, grad/param norm = 2.5859e-01, time/batch = 15.7534s	
13387/22750 (epoch 29.422), train_loss = 1.08125394, grad/param norm = 2.7058e-01, time/batch = 17.0724s	
13388/22750 (epoch 29.424), train_loss = 1.04741227, grad/param norm = 2.3893e-01, time/batch = 17.3470s	
13389/22750 (epoch 29.426), train_loss = 1.04271748, grad/param norm = 2.1670e-01, time/batch = 17.3309s	
13390/22750 (epoch 29.429), train_loss = 0.78555626, grad/param norm = 2.0540e-01, time/batch = 18.4846s	
13391/22750 (epoch 29.431), train_loss = 0.70695440, grad/param norm = 1.8990e-01, time/batch = 19.9015s	
13392/22750 (epoch 29.433), train_loss = 0.81556009, grad/param norm = 2.0836e-01, time/batch = 19.4046s	
13393/22750 (epoch 29.435), train_loss = 0.65307970, grad/param norm = 1.7142e-01, time/batch = 16.9968s	
13394/22750 (epoch 29.437), train_loss = 0.55431475, grad/param norm = 2.1484e-01, time/batch = 17.6501s	
13395/22750 (epoch 29.440), train_loss = 0.82726841, grad/param norm = 2.1930e-01, time/batch = 20.3199s	
13396/22750 (epoch 29.442), train_loss = 0.87204297, grad/param norm = 2.1905e-01, time/batch = 16.7463s	
13397/22750 (epoch 29.444), train_loss = 0.82377547, grad/param norm = 2.4830e-01, time/batch = 16.0438s	
13398/22750 (epoch 29.446), train_loss = 0.85236345, grad/param norm = 2.4587e-01, time/batch = 16.6604s	
13399/22750 (epoch 29.448), train_loss = 1.08207272, grad/param norm = 2.3612e-01, time/batch = 18.3215s	
13400/22750 (epoch 29.451), train_loss = 1.05164280, grad/param norm = 2.2333e-01, time/batch = 17.0486s	
13401/22750 (epoch 29.453), train_loss = 0.94808956, grad/param norm = 2.4709e-01, time/batch = 20.9889s	
13402/22750 (epoch 29.455), train_loss = 1.04394609, grad/param norm = 2.3005e-01, time/batch = 21.1577s	
13403/22750 (epoch 29.457), train_loss = 0.92640614, grad/param norm = 3.1392e-01, time/batch = 18.5884s	
13404/22750 (epoch 29.459), train_loss = 0.93435421, grad/param norm = 2.2659e-01, time/batch = 18.8349s	
13405/22750 (epoch 29.462), train_loss = 0.91920729, grad/param norm = 1.9496e-01, time/batch = 19.7387s	
13406/22750 (epoch 29.464), train_loss = 0.72580169, grad/param norm = 1.9226e-01, time/batch = 17.9918s	
13407/22750 (epoch 29.466), train_loss = 0.94660158, grad/param norm = 2.4778e-01, time/batch = 16.8131s	
13408/22750 (epoch 29.468), train_loss = 0.88567676, grad/param norm = 2.3445e-01, time/batch = 15.7366s	
13409/22750 (epoch 29.470), train_loss = 0.97398902, grad/param norm = 2.3141e-01, time/batch = 16.5957s	
13410/22750 (epoch 29.473), train_loss = 0.84928155, grad/param norm = 2.2137e-01, time/batch = 16.3494s	
13411/22750 (epoch 29.475), train_loss = 0.88463102, grad/param norm = 2.6918e-01, time/batch = 20.1865s	
13412/22750 (epoch 29.477), train_loss = 0.77846978, grad/param norm = 2.1945e-01, time/batch = 19.9356s	
13413/22750 (epoch 29.479), train_loss = 0.73698514, grad/param norm = 1.9191e-01, time/batch = 17.3556s	
13414/22750 (epoch 29.481), train_loss = 0.71880018, grad/param norm = 1.9013e-01, time/batch = 17.1013s	
13415/22750 (epoch 29.484), train_loss = 0.59580537, grad/param norm = 1.9790e-01, time/batch = 16.3331s	
13416/22750 (epoch 29.486), train_loss = 0.74331499, grad/param norm = 2.1582e-01, time/batch = 17.5730s	
13417/22750 (epoch 29.488), train_loss = 0.63755712, grad/param norm = 1.9144e-01, time/batch = 17.1502s	
13418/22750 (epoch 29.490), train_loss = 0.84894734, grad/param norm = 2.2856e-01, time/batch = 16.9959s	
13419/22750 (epoch 29.492), train_loss = 0.93393813, grad/param norm = 2.0876e-01, time/batch = 20.2420s	
13420/22750 (epoch 29.495), train_loss = 0.76313805, grad/param norm = 1.8751e-01, time/batch = 18.8237s	
13421/22750 (epoch 29.497), train_loss = 0.83802416, grad/param norm = 3.1344e-01, time/batch = 19.0152s	
13422/22750 (epoch 29.499), train_loss = 0.79471385, grad/param norm = 2.2478e-01, time/batch = 19.4391s	
13423/22750 (epoch 29.501), train_loss = 0.81384487, grad/param norm = 1.9645e-01, time/batch = 18.4161s	
13424/22750 (epoch 29.503), train_loss = 0.83409100, grad/param norm = 2.2174e-01, time/batch = 20.0750s	
13425/22750 (epoch 29.505), train_loss = 0.74483050, grad/param norm = 2.0387e-01, time/batch = 18.3292s	
13426/22750 (epoch 29.508), train_loss = 0.69275631, grad/param norm = 2.2134e-01, time/batch = 18.1712s	
13427/22750 (epoch 29.510), train_loss = 0.74198744, grad/param norm = 2.1376e-01, time/batch = 18.8369s	
13428/22750 (epoch 29.512), train_loss = 0.76279587, grad/param norm = 2.2505e-01, time/batch = 17.5757s	
13429/22750 (epoch 29.514), train_loss = 0.80052794, grad/param norm = 2.2580e-01, time/batch = 19.2392s	
13430/22750 (epoch 29.516), train_loss = 0.78908483, grad/param norm = 1.9860e-01, time/batch = 18.9809s	
13431/22750 (epoch 29.519), train_loss = 0.90372869, grad/param norm = 2.2148e-01, time/batch = 20.7551s	
13432/22750 (epoch 29.521), train_loss = 0.85321399, grad/param norm = 2.3150e-01, time/batch = 18.2544s	
13433/22750 (epoch 29.523), train_loss = 0.79177388, grad/param norm = 2.3926e-01, time/batch = 19.2434s	
13434/22750 (epoch 29.525), train_loss = 0.98996296, grad/param norm = 2.3687e-01, time/batch = 19.5668s	
13435/22750 (epoch 29.527), train_loss = 0.84303741, grad/param norm = 2.0197e-01, time/batch = 16.4855s	
13436/22750 (epoch 29.530), train_loss = 0.76861916, grad/param norm = 2.0069e-01, time/batch = 16.6203s	
13437/22750 (epoch 29.532), train_loss = 0.72229356, grad/param norm = 1.8160e-01, time/batch = 17.0406s	
13438/22750 (epoch 29.534), train_loss = 0.91853301, grad/param norm = 2.5077e-01, time/batch = 19.2344s	
13439/22750 (epoch 29.536), train_loss = 0.87819206, grad/param norm = 1.9935e-01, time/batch = 31.6547s	
13440/22750 (epoch 29.538), train_loss = 0.86044470, grad/param norm = 2.0828e-01, time/batch = 20.2351s	
13441/22750 (epoch 29.541), train_loss = 0.73742062, grad/param norm = 2.2077e-01, time/batch = 16.0606s	
13442/22750 (epoch 29.543), train_loss = 0.74145383, grad/param norm = 2.1546e-01, time/batch = 16.5565s	
13443/22750 (epoch 29.545), train_loss = 0.93336561, grad/param norm = 2.1730e-01, time/batch = 15.6831s	
13444/22750 (epoch 29.547), train_loss = 0.77254297, grad/param norm = 1.8641e-01, time/batch = 15.6748s	
13445/22750 (epoch 29.549), train_loss = 0.82278119, grad/param norm = 1.9728e-01, time/batch = 16.0058s	
13446/22750 (epoch 29.552), train_loss = 0.88802059, grad/param norm = 2.3408e-01, time/batch = 16.0156s	
13447/22750 (epoch 29.554), train_loss = 0.91183864, grad/param norm = 2.3708e-01, time/batch = 16.3434s	
13448/22750 (epoch 29.556), train_loss = 0.89246072, grad/param norm = 2.2478e-01, time/batch = 15.8045s	
13449/22750 (epoch 29.558), train_loss = 0.89702306, grad/param norm = 2.1415e-01, time/batch = 16.6622s	
13450/22750 (epoch 29.560), train_loss = 0.80169901, grad/param norm = 2.0375e-01, time/batch = 15.7208s	
13451/22750 (epoch 29.563), train_loss = 0.95162530, grad/param norm = 2.3821e-01, time/batch = 15.6985s	
13452/22750 (epoch 29.565), train_loss = 0.93145824, grad/param norm = 2.5892e-01, time/batch = 15.7753s	
13453/22750 (epoch 29.567), train_loss = 0.90492329, grad/param norm = 2.2034e-01, time/batch = 16.3325s	
13454/22750 (epoch 29.569), train_loss = 0.81872613, grad/param norm = 2.1380e-01, time/batch = 16.4233s	
13455/22750 (epoch 29.571), train_loss = 0.81652184, grad/param norm = 2.2189e-01, time/batch = 15.7702s	
13456/22750 (epoch 29.574), train_loss = 0.86254823, grad/param norm = 2.5262e-01, time/batch = 16.0940s	
13457/22750 (epoch 29.576), train_loss = 0.81025951, grad/param norm = 2.1870e-01, time/batch = 24.8977s	
13458/22750 (epoch 29.578), train_loss = 0.73341814, grad/param norm = 2.1055e-01, time/batch = 33.8948s	
13459/22750 (epoch 29.580), train_loss = 0.89085733, grad/param norm = 2.3458e-01, time/batch = 29.7660s	
13460/22750 (epoch 29.582), train_loss = 0.77907567, grad/param norm = 2.2818e-01, time/batch = 33.8171s	
13461/22750 (epoch 29.585), train_loss = 0.72525739, grad/param norm = 2.1091e-01, time/batch = 32.1119s	
13462/22750 (epoch 29.587), train_loss = 0.73458075, grad/param norm = 1.8394e-01, time/batch = 32.6193s	
13463/22750 (epoch 29.589), train_loss = 0.65978481, grad/param norm = 1.9217e-01, time/batch = 33.3761s	
13464/22750 (epoch 29.591), train_loss = 0.81519654, grad/param norm = 1.9063e-01, time/batch = 30.4932s	
13465/22750 (epoch 29.593), train_loss = 0.97743182, grad/param norm = 2.1546e-01, time/batch = 33.7438s	
13466/22750 (epoch 29.596), train_loss = 0.95672306, grad/param norm = 2.2480e-01, time/batch = 33.7676s	
13467/22750 (epoch 29.598), train_loss = 0.98232755, grad/param norm = 2.3243e-01, time/batch = 33.1042s	
13468/22750 (epoch 29.600), train_loss = 0.97814310, grad/param norm = 2.4593e-01, time/batch = 29.1069s	
13469/22750 (epoch 29.602), train_loss = 0.78026516, grad/param norm = 2.1019e-01, time/batch = 15.2097s	
13470/22750 (epoch 29.604), train_loss = 0.78578299, grad/param norm = 2.0814e-01, time/batch = 15.2950s	
13471/22750 (epoch 29.607), train_loss = 0.72711165, grad/param norm = 1.7600e-01, time/batch = 15.7611s	
13472/22750 (epoch 29.609), train_loss = 0.67199936, grad/param norm = 1.6469e-01, time/batch = 15.2838s	
13473/22750 (epoch 29.611), train_loss = 0.78790313, grad/param norm = 1.9833e-01, time/batch = 16.0839s	
13474/22750 (epoch 29.613), train_loss = 0.76018206, grad/param norm = 1.8748e-01, time/batch = 16.7178s	
13475/22750 (epoch 29.615), train_loss = 0.79635580, grad/param norm = 1.9928e-01, time/batch = 16.3383s	
13476/22750 (epoch 29.618), train_loss = 0.81477626, grad/param norm = 2.0557e-01, time/batch = 16.2416s	
13477/22750 (epoch 29.620), train_loss = 0.79839168, grad/param norm = 2.1134e-01, time/batch = 15.2940s	
13478/22750 (epoch 29.622), train_loss = 0.66433153, grad/param norm = 1.6840e-01, time/batch = 15.7113s	
13479/22750 (epoch 29.624), train_loss = 0.78453768, grad/param norm = 2.1903e-01, time/batch = 15.6181s	
13480/22750 (epoch 29.626), train_loss = 0.67805453, grad/param norm = 1.9945e-01, time/batch = 16.1132s	
13481/22750 (epoch 29.629), train_loss = 0.77457404, grad/param norm = 1.9129e-01, time/batch = 16.1629s	
13482/22750 (epoch 29.631), train_loss = 0.81976393, grad/param norm = 1.8661e-01, time/batch = 16.4070s	
13483/22750 (epoch 29.633), train_loss = 0.69616919, grad/param norm = 2.0290e-01, time/batch = 15.6672s	
13484/22750 (epoch 29.635), train_loss = 0.81263499, grad/param norm = 2.0118e-01, time/batch = 16.3290s	
13485/22750 (epoch 29.637), train_loss = 0.88095832, grad/param norm = 2.4282e-01, time/batch = 15.5347s	
13486/22750 (epoch 29.640), train_loss = 0.91215957, grad/param norm = 2.1979e-01, time/batch = 16.0085s	
13487/22750 (epoch 29.642), train_loss = 0.95280692, grad/param norm = 2.1048e-01, time/batch = 16.5411s	
13488/22750 (epoch 29.644), train_loss = 0.82887673, grad/param norm = 2.2620e-01, time/batch = 15.7597s	
13489/22750 (epoch 29.646), train_loss = 0.88326174, grad/param norm = 2.2921e-01, time/batch = 16.7202s	
13490/22750 (epoch 29.648), train_loss = 0.87201747, grad/param norm = 1.9740e-01, time/batch = 16.3461s	
13491/22750 (epoch 29.651), train_loss = 0.90867925, grad/param norm = 2.2000e-01, time/batch = 15.7935s	
13492/22750 (epoch 29.653), train_loss = 0.92106859, grad/param norm = 2.1266e-01, time/batch = 15.4552s	
13493/22750 (epoch 29.655), train_loss = 0.86886572, grad/param norm = 2.2162e-01, time/batch = 16.0986s	
13494/22750 (epoch 29.657), train_loss = 1.01114218, grad/param norm = 2.4533e-01, time/batch = 16.2319s	
13495/22750 (epoch 29.659), train_loss = 1.01224910, grad/param norm = 2.2773e-01, time/batch = 16.0158s	
13496/22750 (epoch 29.662), train_loss = 1.02124370, grad/param norm = 2.6715e-01, time/batch = 15.7643s	
13497/22750 (epoch 29.664), train_loss = 0.90531993, grad/param norm = 2.0736e-01, time/batch = 16.8113s	
13498/22750 (epoch 29.666), train_loss = 0.70787444, grad/param norm = 1.9437e-01, time/batch = 15.6223s	
13499/22750 (epoch 29.668), train_loss = 0.86044113, grad/param norm = 2.2646e-01, time/batch = 15.9555s	
13500/22750 (epoch 29.670), train_loss = 0.84366829, grad/param norm = 2.1715e-01, time/batch = 15.8010s	
13501/22750 (epoch 29.673), train_loss = 1.03423768, grad/param norm = 2.3653e-01, time/batch = 16.3483s	
13502/22750 (epoch 29.675), train_loss = 1.16940570, grad/param norm = 2.5815e-01, time/batch = 15.6123s	
13503/22750 (epoch 29.677), train_loss = 1.04533869, grad/param norm = 2.3171e-01, time/batch = 15.8392s	
13504/22750 (epoch 29.679), train_loss = 1.01516376, grad/param norm = 2.4162e-01, time/batch = 16.0796s	
13505/22750 (epoch 29.681), train_loss = 0.99832789, grad/param norm = 2.4535e-01, time/batch = 15.6265s	
13506/22750 (epoch 29.684), train_loss = 1.03158069, grad/param norm = 2.2202e-01, time/batch = 15.6232s	
13507/22750 (epoch 29.686), train_loss = 1.04219813, grad/param norm = 2.3849e-01, time/batch = 15.4627s	
13508/22750 (epoch 29.688), train_loss = 0.99807582, grad/param norm = 2.2542e-01, time/batch = 17.2346s	
13509/22750 (epoch 29.690), train_loss = 0.98045405, grad/param norm = 2.2675e-01, time/batch = 17.3458s	
13510/22750 (epoch 29.692), train_loss = 1.02057824, grad/param norm = 2.5167e-01, time/batch = 19.3354s	
13511/22750 (epoch 29.695), train_loss = 0.88879982, grad/param norm = 2.3173e-01, time/batch = 17.1397s	
13512/22750 (epoch 29.697), train_loss = 0.88542380, grad/param norm = 2.0673e-01, time/batch = 16.9088s	
13513/22750 (epoch 29.699), train_loss = 0.82399197, grad/param norm = 1.9792e-01, time/batch = 16.3285s	
13514/22750 (epoch 29.701), train_loss = 0.73145177, grad/param norm = 2.0579e-01, time/batch = 16.0338s	
13515/22750 (epoch 29.703), train_loss = 0.82711539, grad/param norm = 1.9629e-01, time/batch = 17.5522s	
13516/22750 (epoch 29.705), train_loss = 0.79434255, grad/param norm = 1.9153e-01, time/batch = 19.1441s	
13517/22750 (epoch 29.708), train_loss = 0.88340498, grad/param norm = 2.1664e-01, time/batch = 16.2098s	
13518/22750 (epoch 29.710), train_loss = 0.76172738, grad/param norm = 2.1724e-01, time/batch = 16.3796s	
13519/22750 (epoch 29.712), train_loss = 0.72490526, grad/param norm = 1.8769e-01, time/batch = 16.4842s	
13520/22750 (epoch 29.714), train_loss = 0.71116889, grad/param norm = 1.9059e-01, time/batch = 17.0463s	
13521/22750 (epoch 29.716), train_loss = 0.72790400, grad/param norm = 1.9841e-01, time/batch = 19.5971s	
13522/22750 (epoch 29.719), train_loss = 0.80206061, grad/param norm = 2.3553e-01, time/batch = 18.6908s	
13523/22750 (epoch 29.721), train_loss = 0.92615932, grad/param norm = 2.0357e-01, time/batch = 18.6870s	
13524/22750 (epoch 29.723), train_loss = 0.94174418, grad/param norm = 2.3346e-01, time/batch = 17.4426s	
13525/22750 (epoch 29.725), train_loss = 0.83144698, grad/param norm = 2.9888e-01, time/batch = 17.1671s	
13526/22750 (epoch 29.727), train_loss = 0.80483268, grad/param norm = 2.1440e-01, time/batch = 16.6635s	
13527/22750 (epoch 29.730), train_loss = 0.82029909, grad/param norm = 2.2947e-01, time/batch = 16.0611s	
13528/22750 (epoch 29.732), train_loss = 0.74914753, grad/param norm = 1.8329e-01, time/batch = 16.0159s	
13529/22750 (epoch 29.734), train_loss = 0.68445844, grad/param norm = 1.6883e-01, time/batch = 16.5584s	
13530/22750 (epoch 29.736), train_loss = 0.80889945, grad/param norm = 2.1837e-01, time/batch = 18.1734s	
13531/22750 (epoch 29.738), train_loss = 0.90531942, grad/param norm = 2.1398e-01, time/batch = 17.4122s	
13532/22750 (epoch 29.741), train_loss = 0.96012003, grad/param norm = 2.1294e-01, time/batch = 17.2959s	
13533/22750 (epoch 29.743), train_loss = 0.89817509, grad/param norm = 2.1997e-01, time/batch = 20.2351s	
13534/22750 (epoch 29.745), train_loss = 0.73093483, grad/param norm = 1.9846e-01, time/batch = 17.6713s	
13535/22750 (epoch 29.747), train_loss = 0.83568674, grad/param norm = 2.0647e-01, time/batch = 16.7069s	
13536/22750 (epoch 29.749), train_loss = 0.98083434, grad/param norm = 2.4934e-01, time/batch = 16.4151s	
13537/22750 (epoch 29.752), train_loss = 0.87115926, grad/param norm = 2.1996e-01, time/batch = 16.0056s	
13538/22750 (epoch 29.754), train_loss = 0.88954267, grad/param norm = 2.3387e-01, time/batch = 16.1783s	
13539/22750 (epoch 29.756), train_loss = 0.77863644, grad/param norm = 2.2008e-01, time/batch = 16.7617s	
13540/22750 (epoch 29.758), train_loss = 0.75197411, grad/param norm = 1.9456e-01, time/batch = 15.6924s	
13541/22750 (epoch 29.760), train_loss = 0.78756642, grad/param norm = 2.1242e-01, time/batch = 15.7521s	
13542/22750 (epoch 29.763), train_loss = 0.85049462, grad/param norm = 2.3521e-01, time/batch = 16.6023s	
13543/22750 (epoch 29.765), train_loss = 0.84038280, grad/param norm = 2.4435e-01, time/batch = 16.6730s	
13544/22750 (epoch 29.767), train_loss = 0.88620318, grad/param norm = 2.7113e-01, time/batch = 18.6621s	
13545/22750 (epoch 29.769), train_loss = 1.02091688, grad/param norm = 2.5519e-01, time/batch = 17.5932s	
13546/22750 (epoch 29.771), train_loss = 1.01347923, grad/param norm = 2.6492e-01, time/batch = 16.6419s	
13547/22750 (epoch 29.774), train_loss = 0.82318559, grad/param norm = 2.4075e-01, time/batch = 17.8467s	
13548/22750 (epoch 29.776), train_loss = 0.95967570, grad/param norm = 2.3142e-01, time/batch = 17.9974s	
13549/22750 (epoch 29.778), train_loss = 1.00707600, grad/param norm = 2.2657e-01, time/batch = 16.9109s	
13550/22750 (epoch 29.780), train_loss = 0.86996229, grad/param norm = 2.1830e-01, time/batch = 18.1557s	
13551/22750 (epoch 29.782), train_loss = 1.04951756, grad/param norm = 2.3679e-01, time/batch = 17.1461s	
13552/22750 (epoch 29.785), train_loss = 0.83095603, grad/param norm = 2.3354e-01, time/batch = 15.7909s	
13553/22750 (epoch 29.787), train_loss = 0.73701425, grad/param norm = 2.0582e-01, time/batch = 16.5825s	
13554/22750 (epoch 29.789), train_loss = 0.82149024, grad/param norm = 2.0104e-01, time/batch = 18.8335s	
13555/22750 (epoch 29.791), train_loss = 0.80605779, grad/param norm = 2.2237e-01, time/batch = 18.3372s	
13556/22750 (epoch 29.793), train_loss = 0.80061920, grad/param norm = 2.5660e-01, time/batch = 17.7637s	
13557/22750 (epoch 29.796), train_loss = 0.72580423, grad/param norm = 1.9747e-01, time/batch = 17.0076s	
13558/22750 (epoch 29.798), train_loss = 0.78463557, grad/param norm = 1.9819e-01, time/batch = 16.6496s	
13559/22750 (epoch 29.800), train_loss = 0.77548135, grad/param norm = 2.0589e-01, time/batch = 20.4965s	
13560/22750 (epoch 29.802), train_loss = 0.70315389, grad/param norm = 2.3787e-01, time/batch = 17.4287s	
13561/22750 (epoch 29.804), train_loss = 0.94146667, grad/param norm = 2.2912e-01, time/batch = 17.5881s	
13562/22750 (epoch 29.807), train_loss = 0.90772275, grad/param norm = 2.2165e-01, time/batch = 17.7005s	
13563/22750 (epoch 29.809), train_loss = 0.96995338, grad/param norm = 2.2584e-01, time/batch = 17.4052s	
13564/22750 (epoch 29.811), train_loss = 0.85117921, grad/param norm = 2.3197e-01, time/batch = 19.4939s	
13565/22750 (epoch 29.813), train_loss = 0.86504942, grad/param norm = 1.9651e-01, time/batch = 17.7942s	
13566/22750 (epoch 29.815), train_loss = 1.00626314, grad/param norm = 2.2136e-01, time/batch = 18.9964s	
13567/22750 (epoch 29.818), train_loss = 0.95720704, grad/param norm = 2.0898e-01, time/batch = 18.9252s	
13568/22750 (epoch 29.820), train_loss = 1.07924195, grad/param norm = 2.2942e-01, time/batch = 18.9982s	
13569/22750 (epoch 29.822), train_loss = 0.89340310, grad/param norm = 2.3634e-01, time/batch = 20.0086s	
13570/22750 (epoch 29.824), train_loss = 0.75432200, grad/param norm = 2.2330e-01, time/batch = 18.7554s	
13571/22750 (epoch 29.826), train_loss = 0.85554869, grad/param norm = 2.1061e-01, time/batch = 18.9415s	
13572/22750 (epoch 29.829), train_loss = 0.96812191, grad/param norm = 2.2295e-01, time/batch = 19.2210s	
13573/22750 (epoch 29.831), train_loss = 0.94753402, grad/param norm = 2.2332e-01, time/batch = 19.8276s	
13574/22750 (epoch 29.833), train_loss = 0.86909830, grad/param norm = 2.1282e-01, time/batch = 18.9911s	
13575/22750 (epoch 29.835), train_loss = 0.75077727, grad/param norm = 1.9476e-01, time/batch = 20.4776s	
13576/22750 (epoch 29.837), train_loss = 0.82844988, grad/param norm = 2.0724e-01, time/batch = 18.3344s	
13577/22750 (epoch 29.840), train_loss = 0.75791513, grad/param norm = 2.0103e-01, time/batch = 19.5709s	
13578/22750 (epoch 29.842), train_loss = 0.79236587, grad/param norm = 2.1924e-01, time/batch = 18.1719s	
13579/22750 (epoch 29.844), train_loss = 0.88601603, grad/param norm = 2.1525e-01, time/batch = 16.2732s	
13580/22750 (epoch 29.846), train_loss = 0.87815413, grad/param norm = 2.0461e-01, time/batch = 17.7661s	
13581/22750 (epoch 29.848), train_loss = 0.78049437, grad/param norm = 1.8209e-01, time/batch = 18.1832s	
13582/22750 (epoch 29.851), train_loss = 0.76410852, grad/param norm = 2.0389e-01, time/batch = 17.4099s	
13583/22750 (epoch 29.853), train_loss = 0.92462040, grad/param norm = 2.0087e-01, time/batch = 17.4042s	
13584/22750 (epoch 29.855), train_loss = 0.78540577, grad/param norm = 1.8773e-01, time/batch = 16.5955s	
13585/22750 (epoch 29.857), train_loss = 0.90722800, grad/param norm = 2.0651e-01, time/batch = 17.5817s	
13586/22750 (epoch 29.859), train_loss = 0.90043075, grad/param norm = 2.1712e-01, time/batch = 16.3479s	
13587/22750 (epoch 29.862), train_loss = 1.03491484, grad/param norm = 2.2728e-01, time/batch = 19.6851s	
13588/22750 (epoch 29.864), train_loss = 0.87817687, grad/param norm = 2.1965e-01, time/batch = 19.6121s	
13589/22750 (epoch 29.866), train_loss = 0.90450707, grad/param norm = 1.9273e-01, time/batch = 17.5108s	
13590/22750 (epoch 29.868), train_loss = 0.76864512, grad/param norm = 2.0991e-01, time/batch = 19.0851s	
13591/22750 (epoch 29.870), train_loss = 0.72438126, grad/param norm = 2.1134e-01, time/batch = 20.1436s	
13592/22750 (epoch 29.873), train_loss = 0.82026410, grad/param norm = 1.9102e-01, time/batch = 18.0022s	
13593/22750 (epoch 29.875), train_loss = 0.91909363, grad/param norm = 2.2755e-01, time/batch = 19.8938s	
13594/22750 (epoch 29.877), train_loss = 0.76951953, grad/param norm = 2.1987e-01, time/batch = 20.2420s	
13595/22750 (epoch 29.879), train_loss = 0.97006179, grad/param norm = 2.3481e-01, time/batch = 16.9643s	
13596/22750 (epoch 29.881), train_loss = 0.91377942, grad/param norm = 2.6225e-01, time/batch = 19.5954s	
13597/22750 (epoch 29.884), train_loss = 0.80672440, grad/param norm = 2.1283e-01, time/batch = 20.5308s	
13598/22750 (epoch 29.886), train_loss = 0.90667818, grad/param norm = 2.1192e-01, time/batch = 19.2689s	
13599/22750 (epoch 29.888), train_loss = 0.93750186, grad/param norm = 2.0227e-01, time/batch = 18.5324s	
13600/22750 (epoch 29.890), train_loss = 0.92141188, grad/param norm = 2.1917e-01, time/batch = 19.9871s	
13601/22750 (epoch 29.892), train_loss = 1.17289779, grad/param norm = 2.6122e-01, time/batch = 18.1581s	
13602/22750 (epoch 29.895), train_loss = 0.84238509, grad/param norm = 2.1487e-01, time/batch = 18.3276s	
13603/22750 (epoch 29.897), train_loss = 0.94295284, grad/param norm = 2.1772e-01, time/batch = 18.1767s	
13604/22750 (epoch 29.899), train_loss = 0.90297113, grad/param norm = 2.1346e-01, time/batch = 17.5208s	
13605/22750 (epoch 29.901), train_loss = 0.95830465, grad/param norm = 2.2243e-01, time/batch = 15.6967s	
13606/22750 (epoch 29.903), train_loss = 0.84982717, grad/param norm = 2.2627e-01, time/batch = 17.7556s	
13607/22750 (epoch 29.905), train_loss = 0.95069296, grad/param norm = 2.1727e-01, time/batch = 18.1694s	
13608/22750 (epoch 29.908), train_loss = 0.76506252, grad/param norm = 2.3728e-01, time/batch = 18.6804s	
13609/22750 (epoch 29.910), train_loss = 0.67600156, grad/param norm = 1.8410e-01, time/batch = 17.5959s	
13610/22750 (epoch 29.912), train_loss = 0.81276038, grad/param norm = 2.0381e-01, time/batch = 18.8333s	
13611/22750 (epoch 29.914), train_loss = 0.85094048, grad/param norm = 2.0481e-01, time/batch = 17.9198s	
13612/22750 (epoch 29.916), train_loss = 0.68859041, grad/param norm = 2.0298e-01, time/batch = 18.3231s	
13613/22750 (epoch 29.919), train_loss = 0.82695241, grad/param norm = 2.1082e-01, time/batch = 18.8428s	
13614/22750 (epoch 29.921), train_loss = 0.66977885, grad/param norm = 1.8678e-01, time/batch = 19.3312s	
13615/22750 (epoch 29.923), train_loss = 0.77760484, grad/param norm = 1.9923e-01, time/batch = 17.4821s	
13616/22750 (epoch 29.925), train_loss = 0.83110606, grad/param norm = 1.9644e-01, time/batch = 17.2821s	
13617/22750 (epoch 29.927), train_loss = 0.67745291, grad/param norm = 1.9328e-01, time/batch = 17.2056s	
13618/22750 (epoch 29.930), train_loss = 0.66666198, grad/param norm = 1.9903e-01, time/batch = 16.0853s	
13619/22750 (epoch 29.932), train_loss = 0.86289432, grad/param norm = 2.1859e-01, time/batch = 16.1852s	
13620/22750 (epoch 29.934), train_loss = 0.69433420, grad/param norm = 1.8176e-01, time/batch = 16.3528s	
13621/22750 (epoch 29.936), train_loss = 0.96195920, grad/param norm = 2.2338e-01, time/batch = 16.6881s	
13622/22750 (epoch 29.938), train_loss = 0.94552520, grad/param norm = 2.0614e-01, time/batch = 17.8317s	
13623/22750 (epoch 29.941), train_loss = 1.00220769, grad/param norm = 2.7387e-01, time/batch = 19.0819s	
13624/22750 (epoch 29.943), train_loss = 0.86048222, grad/param norm = 2.0401e-01, time/batch = 19.4298s	
13625/22750 (epoch 29.945), train_loss = 0.87609150, grad/param norm = 2.3232e-01, time/batch = 18.8668s	
13626/22750 (epoch 29.947), train_loss = 0.81757249, grad/param norm = 2.1596e-01, time/batch = 19.5359s	
13627/22750 (epoch 29.949), train_loss = 0.76662329, grad/param norm = 2.0322e-01, time/batch = 20.3311s	
13628/22750 (epoch 29.952), train_loss = 0.81157398, grad/param norm = 2.2190e-01, time/batch = 17.1028s	
13629/22750 (epoch 29.954), train_loss = 0.75947123, grad/param norm = 2.0373e-01, time/batch = 17.4198s	
13630/22750 (epoch 29.956), train_loss = 0.89829796, grad/param norm = 2.1716e-01, time/batch = 19.8294s	
13631/22750 (epoch 29.958), train_loss = 0.77158157, grad/param norm = 1.8033e-01, time/batch = 18.2376s	
13632/22750 (epoch 29.960), train_loss = 0.75459975, grad/param norm = 1.8636e-01, time/batch = 19.1030s	
13633/22750 (epoch 29.963), train_loss = 0.87454066, grad/param norm = 2.1186e-01, time/batch = 19.6115s	
13634/22750 (epoch 29.965), train_loss = 0.93393484, grad/param norm = 2.1694e-01, time/batch = 20.1404s	
13635/22750 (epoch 29.967), train_loss = 0.90006473, grad/param norm = 2.1438e-01, time/batch = 29.3815s	
13636/22750 (epoch 29.969), train_loss = 0.80647652, grad/param norm = 2.1334e-01, time/batch = 21.7080s	
13637/22750 (epoch 29.971), train_loss = 0.76153385, grad/param norm = 1.8827e-01, time/batch = 16.4704s	
13638/22750 (epoch 29.974), train_loss = 0.79838203, grad/param norm = 2.1567e-01, time/batch = 16.5896s	
13639/22750 (epoch 29.976), train_loss = 0.83235163, grad/param norm = 2.1922e-01, time/batch = 16.9277s	
13640/22750 (epoch 29.978), train_loss = 0.80400171, grad/param norm = 2.2203e-01, time/batch = 17.7519s	
13641/22750 (epoch 29.980), train_loss = 0.95244794, grad/param norm = 2.5886e-01, time/batch = 19.2569s	
13642/22750 (epoch 29.982), train_loss = 0.77225558, grad/param norm = 1.9070e-01, time/batch = 21.2610s	
13643/22750 (epoch 29.985), train_loss = 0.97719731, grad/param norm = 2.3878e-01, time/batch = 18.3610s	
13644/22750 (epoch 29.987), train_loss = 0.68748400, grad/param norm = 1.8815e-01, time/batch = 18.7320s	
13645/22750 (epoch 29.989), train_loss = 0.78761179, grad/param norm = 2.3812e-01, time/batch = 18.7674s	
13646/22750 (epoch 29.991), train_loss = 0.88054770, grad/param norm = 2.4241e-01, time/batch = 17.6609s	
13647/22750 (epoch 29.993), train_loss = 0.86189458, grad/param norm = 2.3611e-01, time/batch = 17.6545s	
13648/22750 (epoch 29.996), train_loss = 0.75880549, grad/param norm = 2.3729e-01, time/batch = 18.8119s	
13649/22750 (epoch 29.998), train_loss = 0.95342715, grad/param norm = 2.2244e-01, time/batch = 19.6460s	
decayed learning rate by a factor 0.97 to 0.0010549610252779	
13650/22750 (epoch 30.000), train_loss = 0.84684445, grad/param norm = 2.0227e-01, time/batch = 18.1626s	
13651/22750 (epoch 30.002), train_loss = 1.00787616, grad/param norm = 2.3088e-01, time/batch = 20.5107s	
13652/22750 (epoch 30.004), train_loss = 0.80233925, grad/param norm = 2.1104e-01, time/batch = 20.5907s	
13653/22750 (epoch 30.007), train_loss = 0.82061316, grad/param norm = 2.6972e-01, time/batch = 18.7380s	
13654/22750 (epoch 30.009), train_loss = 0.98390230, grad/param norm = 2.6050e-01, time/batch = 19.2304s	
13655/22750 (epoch 30.011), train_loss = 1.07732734, grad/param norm = 2.5391e-01, time/batch = 18.9957s	
13656/22750 (epoch 30.013), train_loss = 0.97857237, grad/param norm = 2.4425e-01, time/batch = 17.5125s	
13657/22750 (epoch 30.015), train_loss = 0.89095615, grad/param norm = 2.7499e-01, time/batch = 18.0894s	
13658/22750 (epoch 30.018), train_loss = 0.94378133, grad/param norm = 2.3849e-01, time/batch = 16.9244s	
13659/22750 (epoch 30.020), train_loss = 0.98196007, grad/param norm = 2.1048e-01, time/batch = 16.4974s	
13660/22750 (epoch 30.022), train_loss = 0.87830591, grad/param norm = 2.3105e-01, time/batch = 18.4025s	
13661/22750 (epoch 30.024), train_loss = 0.86203851, grad/param norm = 2.0956e-01, time/batch = 19.9175s	
13662/22750 (epoch 30.026), train_loss = 0.90708977, grad/param norm = 2.5483e-01, time/batch = 19.2647s	
13663/22750 (epoch 30.029), train_loss = 0.71979776, grad/param norm = 2.0397e-01, time/batch = 19.4095s	
13664/22750 (epoch 30.031), train_loss = 1.08819904, grad/param norm = 2.3819e-01, time/batch = 18.3246s	
13665/22750 (epoch 30.033), train_loss = 0.85867697, grad/param norm = 2.1648e-01, time/batch = 16.3037s	
13666/22750 (epoch 30.035), train_loss = 0.91124173, grad/param norm = 2.2072e-01, time/batch = 16.8702s	
13667/22750 (epoch 30.037), train_loss = 0.96074636, grad/param norm = 2.1459e-01, time/batch = 17.4166s	
13668/22750 (epoch 30.040), train_loss = 0.86538385, grad/param norm = 2.0338e-01, time/batch = 16.5900s	
13669/22750 (epoch 30.042), train_loss = 0.89179641, grad/param norm = 2.1936e-01, time/batch = 18.2651s	
13670/22750 (epoch 30.044), train_loss = 0.84627131, grad/param norm = 2.1536e-01, time/batch = 18.5898s	
13671/22750 (epoch 30.046), train_loss = 0.96122288, grad/param norm = 2.4509e-01, time/batch = 21.0218s	
13672/22750 (epoch 30.048), train_loss = 0.87421956, grad/param norm = 2.0158e-01, time/batch = 17.7653s	
13673/22750 (epoch 30.051), train_loss = 0.89031288, grad/param norm = 2.4607e-01, time/batch = 17.2614s	
13674/22750 (epoch 30.053), train_loss = 0.82607190, grad/param norm = 1.9471e-01, time/batch = 20.5730s	
13675/22750 (epoch 30.055), train_loss = 0.72749866, grad/param norm = 1.9229e-01, time/batch = 19.1554s	
13676/22750 (epoch 30.057), train_loss = 1.04077324, grad/param norm = 2.5403e-01, time/batch = 17.5888s	
13677/22750 (epoch 30.059), train_loss = 0.64967207, grad/param norm = 1.9930e-01, time/batch = 17.8239s	
13678/22750 (epoch 30.062), train_loss = 0.73218481, grad/param norm = 2.0326e-01, time/batch = 20.3888s	
13679/22750 (epoch 30.064), train_loss = 0.93799522, grad/param norm = 2.1478e-01, time/batch = 17.9369s	
13680/22750 (epoch 30.066), train_loss = 0.77307899, grad/param norm = 1.9811e-01, time/batch = 17.7464s	
13681/22750 (epoch 30.068), train_loss = 0.76430976, grad/param norm = 1.8297e-01, time/batch = 20.3587s	
13682/22750 (epoch 30.070), train_loss = 0.66833859, grad/param norm = 1.9060e-01, time/batch = 18.4123s	
13683/22750 (epoch 30.073), train_loss = 0.79074951, grad/param norm = 2.1227e-01, time/batch = 20.0676s	
13684/22750 (epoch 30.075), train_loss = 0.84489086, grad/param norm = 1.9095e-01, time/batch = 18.4974s	
13685/22750 (epoch 30.077), train_loss = 0.62833526, grad/param norm = 1.9530e-01, time/batch = 17.6771s	
13686/22750 (epoch 30.079), train_loss = 0.83324078, grad/param norm = 2.3349e-01, time/batch = 17.9983s	
13687/22750 (epoch 30.081), train_loss = 0.81677007, grad/param norm = 2.1387e-01, time/batch = 17.4775s	
13688/22750 (epoch 30.084), train_loss = 0.81611069, grad/param norm = 1.9985e-01, time/batch = 19.5807s	
13689/22750 (epoch 30.086), train_loss = 0.85076022, grad/param norm = 1.9581e-01, time/batch = 18.3359s	
13690/22750 (epoch 30.088), train_loss = 0.76488892, grad/param norm = 1.9061e-01, time/batch = 16.8845s	
13691/22750 (epoch 30.090), train_loss = 0.80028559, grad/param norm = 2.0277e-01, time/batch = 16.7656s	
13692/22750 (epoch 30.092), train_loss = 0.94325655, grad/param norm = 2.1414e-01, time/batch = 16.8949s	
13693/22750 (epoch 30.095), train_loss = 0.76915186, grad/param norm = 2.0611e-01, time/batch = 16.4892s	
13694/22750 (epoch 30.097), train_loss = 0.83685503, grad/param norm = 1.8735e-01, time/batch = 17.3002s	
13695/22750 (epoch 30.099), train_loss = 0.79588321, grad/param norm = 2.1309e-01, time/batch = 16.7443s	
13696/22750 (epoch 30.101), train_loss = 0.71590956, grad/param norm = 2.2621e-01, time/batch = 16.9840s	
13697/22750 (epoch 30.103), train_loss = 0.90203445, grad/param norm = 2.3239e-01, time/batch = 17.5015s	
13698/22750 (epoch 30.105), train_loss = 0.99539470, grad/param norm = 2.5037e-01, time/batch = 18.2811s	
13699/22750 (epoch 30.108), train_loss = 0.84579755, grad/param norm = 2.0412e-01, time/batch = 17.6651s	
13700/22750 (epoch 30.110), train_loss = 0.96009422, grad/param norm = 1.9694e-01, time/batch = 17.7648s	
13701/22750 (epoch 30.112), train_loss = 0.70552122, grad/param norm = 1.7782e-01, time/batch = 18.2437s	
13702/22750 (epoch 30.114), train_loss = 0.63031956, grad/param norm = 1.7873e-01, time/batch = 19.5636s	
13703/22750 (epoch 30.116), train_loss = 0.81150001, grad/param norm = 1.8445e-01, time/batch = 18.4879s	
13704/22750 (epoch 30.119), train_loss = 0.78295547, grad/param norm = 1.7863e-01, time/batch = 19.9863s	
13705/22750 (epoch 30.121), train_loss = 0.83793134, grad/param norm = 2.3616e-01, time/batch = 18.0801s	
13706/22750 (epoch 30.123), train_loss = 0.74010980, grad/param norm = 2.1677e-01, time/batch = 20.2494s	
13707/22750 (epoch 30.125), train_loss = 0.97878653, grad/param norm = 2.0880e-01, time/batch = 20.5201s	
13708/22750 (epoch 30.127), train_loss = 0.81069396, grad/param norm = 2.0679e-01, time/batch = 18.4435s	
13709/22750 (epoch 30.130), train_loss = 0.82280863, grad/param norm = 1.9024e-01, time/batch = 18.6794s	
13710/22750 (epoch 30.132), train_loss = 0.78180296, grad/param norm = 2.2459e-01, time/batch = 20.8897s	
13711/22750 (epoch 30.134), train_loss = 0.79653348, grad/param norm = 1.9568e-01, time/batch = 18.4090s	
13712/22750 (epoch 30.136), train_loss = 0.65660184, grad/param norm = 1.9598e-01, time/batch = 19.8258s	
13713/22750 (epoch 30.138), train_loss = 0.90034390, grad/param norm = 2.1692e-01, time/batch = 18.4047s	
13714/22750 (epoch 30.141), train_loss = 0.85797141, grad/param norm = 2.0060e-01, time/batch = 17.8986s	
13715/22750 (epoch 30.143), train_loss = 0.74483409, grad/param norm = 1.8884e-01, time/batch = 19.8123s	
13716/22750 (epoch 30.145), train_loss = 0.94755758, grad/param norm = 2.2802e-01, time/batch = 19.1756s	
13717/22750 (epoch 30.147), train_loss = 0.99803844, grad/param norm = 2.2880e-01, time/batch = 20.1780s	
13718/22750 (epoch 30.149), train_loss = 0.85814744, grad/param norm = 2.2594e-01, time/batch = 17.6749s	
13719/22750 (epoch 30.152), train_loss = 0.84266412, grad/param norm = 2.0601e-01, time/batch = 16.3865s	
13720/22750 (epoch 30.154), train_loss = 0.75958759, grad/param norm = 1.9471e-01, time/batch = 16.6134s	
13721/22750 (epoch 30.156), train_loss = 0.75026350, grad/param norm = 2.0326e-01, time/batch = 16.5860s	
13722/22750 (epoch 30.158), train_loss = 0.76430586, grad/param norm = 2.2380e-01, time/batch = 16.4603s	
13723/22750 (epoch 30.160), train_loss = 0.85099271, grad/param norm = 2.2217e-01, time/batch = 17.4210s	
13724/22750 (epoch 30.163), train_loss = 1.01604792, grad/param norm = 2.3410e-01, time/batch = 17.9215s	
13725/22750 (epoch 30.165), train_loss = 0.88215707, grad/param norm = 2.2147e-01, time/batch = 19.1847s	
13726/22750 (epoch 30.167), train_loss = 0.80291261, grad/param norm = 2.2799e-01, time/batch = 16.0532s	
13727/22750 (epoch 30.169), train_loss = 0.86776125, grad/param norm = 2.7984e-01, time/batch = 16.8883s	
13728/22750 (epoch 30.171), train_loss = 0.72890944, grad/param norm = 1.9749e-01, time/batch = 17.1874s	
13729/22750 (epoch 30.174), train_loss = 0.70035141, grad/param norm = 2.1612e-01, time/batch = 18.0143s	
13730/22750 (epoch 30.176), train_loss = 0.72630378, grad/param norm = 2.0222e-01, time/batch = 16.9374s	
13731/22750 (epoch 30.178), train_loss = 0.78090363, grad/param norm = 2.2495e-01, time/batch = 18.0002s	
13732/22750 (epoch 30.180), train_loss = 0.95585778, grad/param norm = 2.6231e-01, time/batch = 17.3371s	
13733/22750 (epoch 30.182), train_loss = 0.91609590, grad/param norm = 2.2199e-01, time/batch = 16.6737s	
13734/22750 (epoch 30.185), train_loss = 0.94020734, grad/param norm = 2.1259e-01, time/batch = 17.7614s	
13735/22750 (epoch 30.187), train_loss = 0.72978783, grad/param norm = 2.1345e-01, time/batch = 17.3433s	
13736/22750 (epoch 30.189), train_loss = 0.75888488, grad/param norm = 2.1993e-01, time/batch = 17.2771s	
13737/22750 (epoch 30.191), train_loss = 0.77823975, grad/param norm = 2.0934e-01, time/batch = 19.8620s	
13738/22750 (epoch 30.193), train_loss = 0.92691423, grad/param norm = 2.2598e-01, time/batch = 18.5028s	
13739/22750 (epoch 30.196), train_loss = 0.79609108, grad/param norm = 2.0510e-01, time/batch = 18.4283s	
13740/22750 (epoch 30.198), train_loss = 0.61712573, grad/param norm = 1.9188e-01, time/batch = 18.5928s	
13741/22750 (epoch 30.200), train_loss = 0.84527914, grad/param norm = 2.2006e-01, time/batch = 18.0769s	
13742/22750 (epoch 30.202), train_loss = 0.89975720, grad/param norm = 2.4362e-01, time/batch = 18.5004s	
13743/22750 (epoch 30.204), train_loss = 0.84912703, grad/param norm = 2.0253e-01, time/batch = 20.1610s	
13744/22750 (epoch 30.207), train_loss = 0.83448930, grad/param norm = 2.2154e-01, time/batch = 19.4369s	
13745/22750 (epoch 30.209), train_loss = 0.78468261, grad/param norm = 2.0712e-01, time/batch = 16.8996s	
13746/22750 (epoch 30.211), train_loss = 0.75761765, grad/param norm = 2.0926e-01, time/batch = 16.6036s	
13747/22750 (epoch 30.213), train_loss = 0.65465109, grad/param norm = 2.0494e-01, time/batch = 16.0313s	
13748/22750 (epoch 30.215), train_loss = 0.63281192, grad/param norm = 1.8113e-01, time/batch = 17.3792s	
13749/22750 (epoch 30.218), train_loss = 0.73495418, grad/param norm = 2.4174e-01, time/batch = 19.1557s	
13750/22750 (epoch 30.220), train_loss = 0.67022381, grad/param norm = 1.7320e-01, time/batch = 19.9956s	
13751/22750 (epoch 30.222), train_loss = 0.70486769, grad/param norm = 1.9925e-01, time/batch = 18.9133s	
13752/22750 (epoch 30.224), train_loss = 0.72899650, grad/param norm = 1.9040e-01, time/batch = 18.1533s	
13753/22750 (epoch 30.226), train_loss = 0.83340182, grad/param norm = 2.2223e-01, time/batch = 18.1725s	
13754/22750 (epoch 30.229), train_loss = 0.85121732, grad/param norm = 2.1703e-01, time/batch = 19.1745s	
13755/22750 (epoch 30.231), train_loss = 0.74528573, grad/param norm = 2.0577e-01, time/batch = 19.1779s	
13756/22750 (epoch 30.233), train_loss = 0.67050195, grad/param norm = 2.3219e-01, time/batch = 21.0022s	
13757/22750 (epoch 30.235), train_loss = 0.65527074, grad/param norm = 2.0330e-01, time/batch = 18.8517s	
13758/22750 (epoch 30.237), train_loss = 0.76003804, grad/param norm = 2.1322e-01, time/batch = 18.8291s	
13759/22750 (epoch 30.240), train_loss = 0.82597470, grad/param norm = 2.1304e-01, time/batch = 17.6611s	
13760/22750 (epoch 30.242), train_loss = 1.00089924, grad/param norm = 2.4523e-01, time/batch = 18.6543s	
13761/22750 (epoch 30.244), train_loss = 0.99437646, grad/param norm = 2.3138e-01, time/batch = 18.4044s	
13762/22750 (epoch 30.246), train_loss = 0.99657422, grad/param norm = 2.6089e-01, time/batch = 18.1721s	
13763/22750 (epoch 30.248), train_loss = 0.83152789, grad/param norm = 2.1388e-01, time/batch = 17.9879s	
13764/22750 (epoch 30.251), train_loss = 0.93408852, grad/param norm = 2.2369e-01, time/batch = 18.1036s	
13765/22750 (epoch 30.253), train_loss = 0.88752340, grad/param norm = 2.5605e-01, time/batch = 20.4278s	
13766/22750 (epoch 30.255), train_loss = 0.85927616, grad/param norm = 2.2083e-01, time/batch = 19.4273s	
13767/22750 (epoch 30.257), train_loss = 0.76627948, grad/param norm = 2.3952e-01, time/batch = 18.5793s	
13768/22750 (epoch 30.259), train_loss = 0.95413080, grad/param norm = 2.6346e-01, time/batch = 18.9912s	
13769/22750 (epoch 30.262), train_loss = 0.84818353, grad/param norm = 2.2853e-01, time/batch = 17.0881s	
13770/22750 (epoch 30.264), train_loss = 0.66166503, grad/param norm = 2.4318e-01, time/batch = 18.9196s	
13771/22750 (epoch 30.266), train_loss = 0.82009084, grad/param norm = 2.6721e-01, time/batch = 19.4881s	
13772/22750 (epoch 30.268), train_loss = 0.96495538, grad/param norm = 2.3138e-01, time/batch = 21.2017s	
13773/22750 (epoch 30.270), train_loss = 0.73822014, grad/param norm = 2.2203e-01, time/batch = 18.9154s	
13774/22750 (epoch 30.273), train_loss = 1.09456657, grad/param norm = 2.4715e-01, time/batch = 17.7708s	
13775/22750 (epoch 30.275), train_loss = 0.98822843, grad/param norm = 2.2848e-01, time/batch = 17.4893s	
13776/22750 (epoch 30.277), train_loss = 0.82568672, grad/param norm = 2.6442e-01, time/batch = 18.0444s	
13777/22750 (epoch 30.279), train_loss = 0.70880555, grad/param norm = 1.8905e-01, time/batch = 16.0524s	
13778/22750 (epoch 30.281), train_loss = 0.98179638, grad/param norm = 2.3625e-01, time/batch = 16.6791s	
13779/22750 (epoch 30.284), train_loss = 0.85469981, grad/param norm = 1.9367e-01, time/batch = 17.8426s	
13780/22750 (epoch 30.286), train_loss = 0.89847599, grad/param norm = 2.1981e-01, time/batch = 16.7430s	
13781/22750 (epoch 30.288), train_loss = 1.01453631, grad/param norm = 2.5407e-01, time/batch = 19.0932s	
13782/22750 (epoch 30.290), train_loss = 0.86856938, grad/param norm = 2.2213e-01, time/batch = 18.6874s	
13783/22750 (epoch 30.292), train_loss = 0.91305828, grad/param norm = 2.4397e-01, time/batch = 18.6830s	
13784/22750 (epoch 30.295), train_loss = 0.88405985, grad/param norm = 2.1118e-01, time/batch = 18.8410s	
13785/22750 (epoch 30.297), train_loss = 0.85640844, grad/param norm = 2.4833e-01, time/batch = 18.3355s	
13786/22750 (epoch 30.299), train_loss = 0.93987664, grad/param norm = 2.2962e-01, time/batch = 21.0416s	
13787/22750 (epoch 30.301), train_loss = 0.85446234, grad/param norm = 2.0319e-01, time/batch = 18.8383s	
13788/22750 (epoch 30.303), train_loss = 0.89091855, grad/param norm = 2.0466e-01, time/batch = 18.9988s	
13789/22750 (epoch 30.305), train_loss = 1.01315218, grad/param norm = 2.2704e-01, time/batch = 19.5769s	
13790/22750 (epoch 30.308), train_loss = 0.90434690, grad/param norm = 2.0358e-01, time/batch = 19.7675s	
13791/22750 (epoch 30.310), train_loss = 0.78578679, grad/param norm = 2.3039e-01, time/batch = 18.8764s	
13792/22750 (epoch 30.312), train_loss = 0.84977515, grad/param norm = 1.9511e-01, time/batch = 20.5186s	
13793/22750 (epoch 30.314), train_loss = 0.85598263, grad/param norm = 1.9518e-01, time/batch = 19.8861s	
13794/22750 (epoch 30.316), train_loss = 0.79759380, grad/param norm = 2.0732e-01, time/batch = 19.9720s	
13795/22750 (epoch 30.319), train_loss = 0.86845302, grad/param norm = 2.3215e-01, time/batch = 20.6418s	
13796/22750 (epoch 30.321), train_loss = 0.79017924, grad/param norm = 2.2614e-01, time/batch = 17.9794s	
13797/22750 (epoch 30.323), train_loss = 0.87465485, grad/param norm = 2.2670e-01, time/batch = 17.8445s	
13798/22750 (epoch 30.325), train_loss = 0.75841048, grad/param norm = 1.9898e-01, time/batch = 18.9241s	
13799/22750 (epoch 30.327), train_loss = 0.80755848, grad/param norm = 2.6061e-01, time/batch = 18.2022s	
13800/22750 (epoch 30.330), train_loss = 1.01168913, grad/param norm = 2.4011e-01, time/batch = 15.4080s	
13801/22750 (epoch 30.332), train_loss = 1.03318150, grad/param norm = 2.1091e-01, time/batch = 16.9697s	
13802/22750 (epoch 30.334), train_loss = 0.70451128, grad/param norm = 1.9377e-01, time/batch = 15.5428s	
13803/22750 (epoch 30.336), train_loss = 0.92417024, grad/param norm = 2.0192e-01, time/batch = 15.6929s	
13804/22750 (epoch 30.338), train_loss = 0.84159750, grad/param norm = 2.3402e-01, time/batch = 18.3249s	
13805/22750 (epoch 30.341), train_loss = 0.85507773, grad/param norm = 2.1233e-01, time/batch = 16.1555s	
13806/22750 (epoch 30.343), train_loss = 0.73311026, grad/param norm = 2.0945e-01, time/batch = 17.4007s	
13807/22750 (epoch 30.345), train_loss = 0.89310870, grad/param norm = 2.5279e-01, time/batch = 19.4920s	
13808/22750 (epoch 30.347), train_loss = 0.96580578, grad/param norm = 2.2912e-01, time/batch = 18.1536s	
13809/22750 (epoch 30.349), train_loss = 0.68611915, grad/param norm = 2.3134e-01, time/batch = 18.8675s	
13810/22750 (epoch 30.352), train_loss = 0.97751352, grad/param norm = 2.1957e-01, time/batch = 21.0969s	
13811/22750 (epoch 30.354), train_loss = 0.96085521, grad/param norm = 2.2331e-01, time/batch = 20.3433s	
13812/22750 (epoch 30.356), train_loss = 0.94027320, grad/param norm = 2.3800e-01, time/batch = 18.0712s	
13813/22750 (epoch 30.358), train_loss = 0.82923150, grad/param norm = 2.3142e-01, time/batch = 16.6411s	
13814/22750 (epoch 30.360), train_loss = 1.01425268, grad/param norm = 2.1591e-01, time/batch = 16.7299s	
13815/22750 (epoch 30.363), train_loss = 0.82948822, grad/param norm = 2.2687e-01, time/batch = 16.2358s	
13816/22750 (epoch 30.365), train_loss = 0.69491774, grad/param norm = 2.1741e-01, time/batch = 17.5013s	
13817/22750 (epoch 30.367), train_loss = 0.78755813, grad/param norm = 2.4774e-01, time/batch = 17.2693s	
13818/22750 (epoch 30.369), train_loss = 0.86524464, grad/param norm = 2.3955e-01, time/batch = 19.1076s	
13819/22750 (epoch 30.371), train_loss = 0.86522873, grad/param norm = 2.3312e-01, time/batch = 18.3641s	
13820/22750 (epoch 30.374), train_loss = 0.75928023, grad/param norm = 2.3490e-01, time/batch = 18.8558s	
13821/22750 (epoch 30.376), train_loss = 0.83330803, grad/param norm = 2.0289e-01, time/batch = 19.0023s	
13822/22750 (epoch 30.378), train_loss = 0.85965225, grad/param norm = 2.2166e-01, time/batch = 17.8862s	
13823/22750 (epoch 30.380), train_loss = 0.93724119, grad/param norm = 2.1596e-01, time/batch = 19.6581s	
13824/22750 (epoch 30.382), train_loss = 0.85085116, grad/param norm = 2.2167e-01, time/batch = 19.2472s	
13825/22750 (epoch 30.385), train_loss = 0.90552969, grad/param norm = 2.1323e-01, time/batch = 18.4998s	
13826/22750 (epoch 30.387), train_loss = 0.87764816, grad/param norm = 1.9758e-01, time/batch = 19.0067s	
13827/22750 (epoch 30.389), train_loss = 0.69367789, grad/param norm = 1.9322e-01, time/batch = 19.8482s	
13828/22750 (epoch 30.391), train_loss = 0.53140955, grad/param norm = 1.6436e-01, time/batch = 20.8467s	
13829/22750 (epoch 30.393), train_loss = 0.70857957, grad/param norm = 1.8640e-01, time/batch = 32.8097s	
13830/22750 (epoch 30.396), train_loss = 0.88173944, grad/param norm = 2.2115e-01, time/batch = 18.8302s	
13831/22750 (epoch 30.398), train_loss = 0.82869399, grad/param norm = 2.0604e-01, time/batch = 17.4041s	
13832/22750 (epoch 30.400), train_loss = 0.82508966, grad/param norm = 2.2438e-01, time/batch = 17.5797s	
13833/22750 (epoch 30.402), train_loss = 0.90296714, grad/param norm = 2.3640e-01, time/batch = 17.9266s	
13834/22750 (epoch 30.404), train_loss = 0.96213370, grad/param norm = 2.0926e-01, time/batch = 18.9065s	
13835/22750 (epoch 30.407), train_loss = 0.93514592, grad/param norm = 2.1757e-01, time/batch = 18.6651s	
13836/22750 (epoch 30.409), train_loss = 0.75906267, grad/param norm = 1.9524e-01, time/batch = 16.9023s	
13837/22750 (epoch 30.411), train_loss = 0.78866230, grad/param norm = 2.0537e-01, time/batch = 18.5066s	
13838/22750 (epoch 30.413), train_loss = 0.62369682, grad/param norm = 2.0037e-01, time/batch = 16.5690s	
13839/22750 (epoch 30.415), train_loss = 0.68038657, grad/param norm = 1.9255e-01, time/batch = 17.1576s	
13840/22750 (epoch 30.418), train_loss = 0.77950450, grad/param norm = 2.0983e-01, time/batch = 16.6797s	
13841/22750 (epoch 30.420), train_loss = 0.91612854, grad/param norm = 2.6443e-01, time/batch = 16.0944s	
13842/22750 (epoch 30.422), train_loss = 1.06507169, grad/param norm = 2.9717e-01, time/batch = 16.7323s	
13843/22750 (epoch 30.424), train_loss = 1.01647536, grad/param norm = 2.2274e-01, time/batch = 17.4148s	
13844/22750 (epoch 30.426), train_loss = 1.03412982, grad/param norm = 2.2832e-01, time/batch = 18.7536s	
13845/22750 (epoch 30.429), train_loss = 0.77454503, grad/param norm = 2.0745e-01, time/batch = 17.2408s	
13846/22750 (epoch 30.431), train_loss = 0.70300434, grad/param norm = 1.8582e-01, time/batch = 18.4602s	
13847/22750 (epoch 30.433), train_loss = 0.79685155, grad/param norm = 2.0846e-01, time/batch = 19.2701s	
13848/22750 (epoch 30.435), train_loss = 0.63446998, grad/param norm = 1.7144e-01, time/batch = 19.0006s	
13849/22750 (epoch 30.437), train_loss = 0.54973052, grad/param norm = 1.8335e-01, time/batch = 18.7590s	
13850/22750 (epoch 30.440), train_loss = 0.80847516, grad/param norm = 2.1853e-01, time/batch = 20.5737s	
13851/22750 (epoch 30.442), train_loss = 0.84540073, grad/param norm = 2.0619e-01, time/batch = 18.0912s	
13852/22750 (epoch 30.444), train_loss = 0.81203309, grad/param norm = 2.2958e-01, time/batch = 19.1684s	
13853/22750 (epoch 30.446), train_loss = 0.82671138, grad/param norm = 2.3065e-01, time/batch = 19.7455s	
13854/22750 (epoch 30.448), train_loss = 1.06533382, grad/param norm = 2.4027e-01, time/batch = 17.0328s	
13855/22750 (epoch 30.451), train_loss = 1.03811774, grad/param norm = 2.2898e-01, time/batch = 20.3418s	
13856/22750 (epoch 30.453), train_loss = 0.94197356, grad/param norm = 2.6964e-01, time/batch = 19.1219s	
13857/22750 (epoch 30.455), train_loss = 1.02953749, grad/param norm = 2.5783e-01, time/batch = 18.5997s	
13858/22750 (epoch 30.457), train_loss = 0.90399203, grad/param norm = 2.7361e-01, time/batch = 16.2132s	
13859/22750 (epoch 30.459), train_loss = 0.89951478, grad/param norm = 2.1731e-01, time/batch = 16.0122s	
13860/22750 (epoch 30.462), train_loss = 0.90521938, grad/param norm = 2.0326e-01, time/batch = 18.5034s	
13861/22750 (epoch 30.464), train_loss = 0.73366463, grad/param norm = 2.2419e-01, time/batch = 16.7301s	
13862/22750 (epoch 30.466), train_loss = 0.93604558, grad/param norm = 2.7712e-01, time/batch = 18.8342s	
13863/22750 (epoch 30.468), train_loss = 0.88478503, grad/param norm = 2.4546e-01, time/batch = 19.8442s	
13864/22750 (epoch 30.470), train_loss = 0.96901085, grad/param norm = 2.5467e-01, time/batch = 17.2060s	
13865/22750 (epoch 30.473), train_loss = 0.83686852, grad/param norm = 2.0570e-01, time/batch = 20.4464s	
13866/22750 (epoch 30.475), train_loss = 0.85966823, grad/param norm = 2.1857e-01, time/batch = 18.2670s	
13867/22750 (epoch 30.477), train_loss = 0.75561197, grad/param norm = 2.1833e-01, time/batch = 18.2577s	
13868/22750 (epoch 30.479), train_loss = 0.72163331, grad/param norm = 2.0277e-01, time/batch = 18.3264s	
13869/22750 (epoch 30.481), train_loss = 0.71584575, grad/param norm = 1.8685e-01, time/batch = 17.0805s	
13870/22750 (epoch 30.484), train_loss = 0.58922998, grad/param norm = 1.9472e-01, time/batch = 18.7430s	
13871/22750 (epoch 30.486), train_loss = 0.73027331, grad/param norm = 2.7867e-01, time/batch = 19.0623s	
13872/22750 (epoch 30.488), train_loss = 0.63873179, grad/param norm = 1.8724e-01, time/batch = 19.3650s	
13873/22750 (epoch 30.490), train_loss = 0.81297053, grad/param norm = 2.1486e-01, time/batch = 18.8976s	
13874/22750 (epoch 30.492), train_loss = 0.92191776, grad/param norm = 2.2404e-01, time/batch = 17.6982s	
13875/22750 (epoch 30.495), train_loss = 0.75246482, grad/param norm = 2.0159e-01, time/batch = 18.4318s	
13876/22750 (epoch 30.497), train_loss = 0.81499718, grad/param norm = 2.6527e-01, time/batch = 16.6651s	
13877/22750 (epoch 30.499), train_loss = 0.75369224, grad/param norm = 2.1240e-01, time/batch = 18.4962s	
13878/22750 (epoch 30.501), train_loss = 0.80525251, grad/param norm = 2.1626e-01, time/batch = 17.9821s	
13879/22750 (epoch 30.503), train_loss = 0.82091326, grad/param norm = 2.2397e-01, time/batch = 18.6837s	
13880/22750 (epoch 30.505), train_loss = 0.74835484, grad/param norm = 2.3847e-01, time/batch = 17.6770s	
13881/22750 (epoch 30.508), train_loss = 0.66684164, grad/param norm = 1.9345e-01, time/batch = 20.8406s	
13882/22750 (epoch 30.510), train_loss = 0.71747010, grad/param norm = 1.9610e-01, time/batch = 19.4495s	
13883/22750 (epoch 30.512), train_loss = 0.75468004, grad/param norm = 2.2114e-01, time/batch = 19.1150s	
13884/22750 (epoch 30.514), train_loss = 0.77571887, grad/param norm = 2.0626e-01, time/batch = 19.7673s	
13885/22750 (epoch 30.516), train_loss = 0.77811229, grad/param norm = 2.2049e-01, time/batch = 16.7625s	
13886/22750 (epoch 30.519), train_loss = 0.88713413, grad/param norm = 2.3985e-01, time/batch = 18.0773s	
13887/22750 (epoch 30.521), train_loss = 0.84229873, grad/param norm = 2.3373e-01, time/batch = 16.6016s	
13888/22750 (epoch 30.523), train_loss = 0.76978518, grad/param norm = 2.2773e-01, time/batch = 16.6167s	
13889/22750 (epoch 30.525), train_loss = 0.97235847, grad/param norm = 2.5882e-01, time/batch = 16.7941s	
13890/22750 (epoch 30.527), train_loss = 0.84085202, grad/param norm = 2.1439e-01, time/batch = 17.0382s	
13891/22750 (epoch 30.530), train_loss = 0.75679981, grad/param norm = 2.2418e-01, time/batch = 17.0693s	
13892/22750 (epoch 30.532), train_loss = 0.71166864, grad/param norm = 1.9018e-01, time/batch = 17.2224s	
13893/22750 (epoch 30.534), train_loss = 0.90829589, grad/param norm = 2.4541e-01, time/batch = 16.9657s	
13894/22750 (epoch 30.536), train_loss = 0.86605576, grad/param norm = 2.0701e-01, time/batch = 16.7897s	
13895/22750 (epoch 30.538), train_loss = 0.84886315, grad/param norm = 2.0608e-01, time/batch = 18.9771s	
13896/22750 (epoch 30.541), train_loss = 0.73929023, grad/param norm = 2.3355e-01, time/batch = 17.0884s	
13897/22750 (epoch 30.543), train_loss = 0.72432198, grad/param norm = 2.1520e-01, time/batch = 17.2639s	
13898/22750 (epoch 30.545), train_loss = 0.89519715, grad/param norm = 2.1096e-01, time/batch = 18.6860s	
13899/22750 (epoch 30.547), train_loss = 0.76616468, grad/param norm = 1.8849e-01, time/batch = 17.8879s	
13900/22750 (epoch 30.549), train_loss = 0.81250875, grad/param norm = 2.0258e-01, time/batch = 19.6777s	
13901/22750 (epoch 30.552), train_loss = 0.87565703, grad/param norm = 2.1960e-01, time/batch = 19.5407s	
13902/22750 (epoch 30.554), train_loss = 0.91091199, grad/param norm = 2.3673e-01, time/batch = 19.9470s	
13903/22750 (epoch 30.556), train_loss = 0.87434688, grad/param norm = 2.1917e-01, time/batch = 18.9227s	
13904/22750 (epoch 30.558), train_loss = 0.87628499, grad/param norm = 2.2032e-01, time/batch = 18.3144s	
13905/22750 (epoch 30.560), train_loss = 0.80573088, grad/param norm = 2.1168e-01, time/batch = 15.8985s	
13906/22750 (epoch 30.563), train_loss = 0.94875182, grad/param norm = 2.9243e-01, time/batch = 16.0416s	
13907/22750 (epoch 30.565), train_loss = 0.89986719, grad/param norm = 2.4516e-01, time/batch = 16.8468s	
13908/22750 (epoch 30.567), train_loss = 0.88842351, grad/param norm = 2.2860e-01, time/batch = 19.2524s	
13909/22750 (epoch 30.569), train_loss = 0.80937739, grad/param norm = 2.2873e-01, time/batch = 19.5025s	
13910/22750 (epoch 30.571), train_loss = 0.81759654, grad/param norm = 2.2313e-01, time/batch = 16.8555s	
13911/22750 (epoch 30.574), train_loss = 0.83449798, grad/param norm = 2.4869e-01, time/batch = 16.2824s	
13912/22750 (epoch 30.576), train_loss = 0.80220415, grad/param norm = 2.2466e-01, time/batch = 16.7315s	
13913/22750 (epoch 30.578), train_loss = 0.71801982, grad/param norm = 2.0078e-01, time/batch = 16.3381s	
13914/22750 (epoch 30.580), train_loss = 0.88762967, grad/param norm = 2.5254e-01, time/batch = 16.5807s	
13915/22750 (epoch 30.582), train_loss = 0.76042360, grad/param norm = 2.0078e-01, time/batch = 17.2600s	
13916/22750 (epoch 30.585), train_loss = 0.73087477, grad/param norm = 2.2100e-01, time/batch = 19.1487s	
13917/22750 (epoch 30.587), train_loss = 0.73641916, grad/param norm = 1.9642e-01, time/batch = 17.8294s	
13918/22750 (epoch 30.589), train_loss = 0.64248512, grad/param norm = 1.7697e-01, time/batch = 18.1854s	
13919/22750 (epoch 30.591), train_loss = 0.80730093, grad/param norm = 2.0402e-01, time/batch = 19.8267s	
13920/22750 (epoch 30.593), train_loss = 0.96506203, grad/param norm = 2.2257e-01, time/batch = 17.6781s	
13921/22750 (epoch 30.596), train_loss = 0.94061325, grad/param norm = 2.3269e-01, time/batch = 20.0272s	
13922/22750 (epoch 30.598), train_loss = 0.96379152, grad/param norm = 2.5626e-01, time/batch = 18.6751s	
13923/22750 (epoch 30.600), train_loss = 0.97326972, grad/param norm = 2.5449e-01, time/batch = 19.3483s	
13924/22750 (epoch 30.602), train_loss = 0.75479145, grad/param norm = 2.0156e-01, time/batch = 17.7438s	
13925/22750 (epoch 30.604), train_loss = 0.77610687, grad/param norm = 2.1389e-01, time/batch = 19.6530s	
13926/22750 (epoch 30.607), train_loss = 0.72490253, grad/param norm = 1.7941e-01, time/batch = 18.4980s	
13927/22750 (epoch 30.609), train_loss = 0.67374083, grad/param norm = 1.8030e-01, time/batch = 16.1499s	
13928/22750 (epoch 30.611), train_loss = 0.77307493, grad/param norm = 2.0535e-01, time/batch = 17.0024s	
13929/22750 (epoch 30.613), train_loss = 0.76565591, grad/param norm = 2.0142e-01, time/batch = 15.0338s	
13930/22750 (epoch 30.615), train_loss = 0.77830960, grad/param norm = 1.8997e-01, time/batch = 15.4691s	
13931/22750 (epoch 30.618), train_loss = 0.80844655, grad/param norm = 2.2604e-01, time/batch = 15.0710s	
13932/22750 (epoch 30.620), train_loss = 0.78478472, grad/param norm = 2.1927e-01, time/batch = 14.9945s	
13933/22750 (epoch 30.622), train_loss = 0.65995429, grad/param norm = 1.8986e-01, time/batch = 15.4709s	
13934/22750 (epoch 30.624), train_loss = 0.76382879, grad/param norm = 2.1328e-01, time/batch = 15.3688s	
13935/22750 (epoch 30.626), train_loss = 0.65950349, grad/param norm = 1.8972e-01, time/batch = 15.8389s	
13936/22750 (epoch 30.629), train_loss = 0.76153929, grad/param norm = 2.1110e-01, time/batch = 14.8854s	
13937/22750 (epoch 30.631), train_loss = 0.82011993, grad/param norm = 1.9485e-01, time/batch = 15.1080s	
13938/22750 (epoch 30.633), train_loss = 0.67483182, grad/param norm = 1.8518e-01, time/batch = 15.5074s	
13939/22750 (epoch 30.635), train_loss = 0.80381193, grad/param norm = 2.0352e-01, time/batch = 15.0400s	
13940/22750 (epoch 30.637), train_loss = 0.86645057, grad/param norm = 2.4277e-01, time/batch = 14.7279s	
13941/22750 (epoch 30.640), train_loss = 0.88144928, grad/param norm = 1.9898e-01, time/batch = 14.7417s	
13942/22750 (epoch 30.642), train_loss = 0.93280376, grad/param norm = 2.2222e-01, time/batch = 15.2188s	
13943/22750 (epoch 30.644), train_loss = 0.80233440, grad/param norm = 2.5164e-01, time/batch = 14.6711s	
13944/22750 (epoch 30.646), train_loss = 0.88423531, grad/param norm = 2.6578e-01, time/batch = 15.0612s	
13945/22750 (epoch 30.648), train_loss = 0.86669781, grad/param norm = 2.0995e-01, time/batch = 14.7147s	
13946/22750 (epoch 30.651), train_loss = 0.87627286, grad/param norm = 2.1817e-01, time/batch = 15.7518s	
13947/22750 (epoch 30.653), train_loss = 0.90630124, grad/param norm = 2.0628e-01, time/batch = 15.1769s	
13948/22750 (epoch 30.655), train_loss = 0.83839558, grad/param norm = 2.0645e-01, time/batch = 14.8774s	
13949/22750 (epoch 30.657), train_loss = 0.99343091, grad/param norm = 2.5632e-01, time/batch = 14.8721s	
13950/22750 (epoch 30.659), train_loss = 1.01305230, grad/param norm = 2.6053e-01, time/batch = 15.9378s	
13951/22750 (epoch 30.662), train_loss = 1.01168315, grad/param norm = 2.8050e-01, time/batch = 15.7432s	
13952/22750 (epoch 30.664), train_loss = 0.88790698, grad/param norm = 2.3339e-01, time/batch = 15.2292s	
13953/22750 (epoch 30.666), train_loss = 0.70638593, grad/param norm = 1.8018e-01, time/batch = 14.9909s	
13954/22750 (epoch 30.668), train_loss = 0.83724256, grad/param norm = 2.1701e-01, time/batch = 15.8691s	
13955/22750 (epoch 30.670), train_loss = 0.81259248, grad/param norm = 2.1351e-01, time/batch = 15.4753s	
13956/22750 (epoch 30.673), train_loss = 1.02277900, grad/param norm = 3.0277e-01, time/batch = 15.1300s	
13957/22750 (epoch 30.675), train_loss = 1.16694054, grad/param norm = 3.2593e-01, time/batch = 15.0342s	
13958/22750 (epoch 30.677), train_loss = 1.02282695, grad/param norm = 2.2721e-01, time/batch = 15.8423s	
13959/22750 (epoch 30.679), train_loss = 1.00935831, grad/param norm = 2.3319e-01, time/batch = 15.1089s	
13960/22750 (epoch 30.681), train_loss = 0.98167849, grad/param norm = 2.4848e-01, time/batch = 15.2894s	
13961/22750 (epoch 30.684), train_loss = 1.01118779, grad/param norm = 2.3030e-01, time/batch = 15.2875s	
13962/22750 (epoch 30.686), train_loss = 1.03551448, grad/param norm = 2.5408e-01, time/batch = 15.5491s	
13963/22750 (epoch 30.688), train_loss = 0.97593633, grad/param norm = 2.2777e-01, time/batch = 15.4654s	
13964/22750 (epoch 30.690), train_loss = 0.99195753, grad/param norm = 2.3077e-01, time/batch = 15.2340s	
13965/22750 (epoch 30.692), train_loss = 0.99028591, grad/param norm = 2.4618e-01, time/batch = 15.3036s	
13966/22750 (epoch 30.695), train_loss = 0.87236079, grad/param norm = 2.2176e-01, time/batch = 1.9104s	
13967/22750 (epoch 30.697), train_loss = 0.87654647, grad/param norm = 2.3106e-01, time/batch = 0.6965s	
13968/22750 (epoch 30.699), train_loss = 0.81992188, grad/param norm = 2.0666e-01, time/batch = 0.6935s	
13969/22750 (epoch 30.701), train_loss = 0.73014967, grad/param norm = 2.1914e-01, time/batch = 0.6917s	
13970/22750 (epoch 30.703), train_loss = 0.81645323, grad/param norm = 2.2187e-01, time/batch = 0.6919s	
13971/22750 (epoch 30.705), train_loss = 0.79226292, grad/param norm = 2.2154e-01, time/batch = 0.6908s	
13972/22750 (epoch 30.708), train_loss = 0.87761292, grad/param norm = 2.6344e-01, time/batch = 0.6924s	
13973/22750 (epoch 30.710), train_loss = 0.75522359, grad/param norm = 2.2361e-01, time/batch = 0.9361s	
13974/22750 (epoch 30.712), train_loss = 0.71175082, grad/param norm = 1.9646e-01, time/batch = 1.0478s	
13975/22750 (epoch 30.714), train_loss = 0.70188990, grad/param norm = 1.9518e-01, time/batch = 1.0262s	
13976/22750 (epoch 30.716), train_loss = 0.73313853, grad/param norm = 1.8925e-01, time/batch = 1.0259s	
13977/22750 (epoch 30.719), train_loss = 0.79751946, grad/param norm = 2.4805e-01, time/batch = 1.0207s	
13978/22750 (epoch 30.721), train_loss = 0.91927808, grad/param norm = 2.1201e-01, time/batch = 1.8445s	
13979/22750 (epoch 30.723), train_loss = 0.94905762, grad/param norm = 2.3818e-01, time/batch = 1.9293s	
13980/22750 (epoch 30.725), train_loss = 0.80480921, grad/param norm = 2.3282e-01, time/batch = 5.9931s	
13981/22750 (epoch 30.727), train_loss = 0.79610399, grad/param norm = 2.2276e-01, time/batch = 15.2171s	
13982/22750 (epoch 30.730), train_loss = 0.79960961, grad/param norm = 2.1939e-01, time/batch = 15.5137s	
13983/22750 (epoch 30.732), train_loss = 0.75528860, grad/param norm = 2.0179e-01, time/batch = 15.5299s	
13984/22750 (epoch 30.734), train_loss = 0.68779031, grad/param norm = 1.7853e-01, time/batch = 15.2098s	
13985/22750 (epoch 30.736), train_loss = 0.78127780, grad/param norm = 2.0467e-01, time/batch = 15.2107s	
13986/22750 (epoch 30.738), train_loss = 0.88056054, grad/param norm = 2.2201e-01, time/batch = 15.1272s	
13987/22750 (epoch 30.741), train_loss = 0.94859302, grad/param norm = 2.4798e-01, time/batch = 15.4521s	
13988/22750 (epoch 30.743), train_loss = 0.88801905, grad/param norm = 2.2806e-01, time/batch = 15.0778s	
13989/22750 (epoch 30.745), train_loss = 0.71329148, grad/param norm = 1.9302e-01, time/batch = 15.0527s	
13990/22750 (epoch 30.747), train_loss = 0.80699715, grad/param norm = 2.0124e-01, time/batch = 14.9027s	
13991/22750 (epoch 30.749), train_loss = 0.95757088, grad/param norm = 2.4842e-01, time/batch = 15.7703s	
13992/22750 (epoch 30.752), train_loss = 0.85319983, grad/param norm = 2.2857e-01, time/batch = 15.1279s	
13993/22750 (epoch 30.754), train_loss = 0.86715037, grad/param norm = 2.4128e-01, time/batch = 15.1261s	
13994/22750 (epoch 30.756), train_loss = 0.78072480, grad/param norm = 2.3813e-01, time/batch = 14.9715s	
13995/22750 (epoch 30.758), train_loss = 0.75060410, grad/param norm = 1.9983e-01, time/batch = 15.8316s	
13996/22750 (epoch 30.760), train_loss = 0.77793827, grad/param norm = 2.0351e-01, time/batch = 15.1218s	
13997/22750 (epoch 30.763), train_loss = 0.83933610, grad/param norm = 2.4001e-01, time/batch = 15.9277s	
13998/22750 (epoch 30.765), train_loss = 0.82061739, grad/param norm = 2.2300e-01, time/batch = 15.6102s	
13999/22750 (epoch 30.767), train_loss = 0.86190504, grad/param norm = 2.2495e-01, time/batch = 15.3064s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_wakata_epoch30.77_1.6775.t7	
14000/22750 (epoch 30.769), train_loss = 0.98943915, grad/param norm = 2.5390e-01, time/batch = 15.0612s	
14001/22750 (epoch 30.771), train_loss = 1.50303158, grad/param norm = 3.5480e-01, time/batch = 15.2094s	
14002/22750 (epoch 30.774), train_loss = 0.84500628, grad/param norm = 2.5107e-01, time/batch = 14.8034s	
14003/22750 (epoch 30.776), train_loss = 0.94576998, grad/param norm = 2.4117e-01, time/batch = 15.1276s	
14004/22750 (epoch 30.778), train_loss = 1.01728510, grad/param norm = 2.4683e-01, time/batch = 15.7923s	
14005/22750 (epoch 30.780), train_loss = 0.85576614, grad/param norm = 2.0650e-01, time/batch = 15.1498s	
14006/22750 (epoch 30.782), train_loss = 1.01381367, grad/param norm = 2.2890e-01, time/batch = 15.2358s	
14007/22750 (epoch 30.785), train_loss = 0.81339104, grad/param norm = 2.2738e-01, time/batch = 15.0553s	
14008/22750 (epoch 30.787), train_loss = 0.73922964, grad/param norm = 2.2838e-01, time/batch = 16.0922s	
14009/22750 (epoch 30.789), train_loss = 0.81596986, grad/param norm = 2.0901e-01, time/batch = 16.2260s	
14010/22750 (epoch 30.791), train_loss = 0.80312160, grad/param norm = 2.2680e-01, time/batch = 15.5315s	
14011/22750 (epoch 30.793), train_loss = 0.78256337, grad/param norm = 2.5752e-01, time/batch = 15.4531s	
14012/22750 (epoch 30.796), train_loss = 0.72271928, grad/param norm = 2.0436e-01, time/batch = 15.6854s	
14013/22750 (epoch 30.798), train_loss = 0.76050311, grad/param norm = 2.0824e-01, time/batch = 16.4238s	
14014/22750 (epoch 30.800), train_loss = 0.76581350, grad/param norm = 2.2412e-01, time/batch = 19.5286s	
14015/22750 (epoch 30.802), train_loss = 0.70174924, grad/param norm = 4.1695e-01, time/batch = 18.8633s	
14016/22750 (epoch 30.804), train_loss = 0.92395513, grad/param norm = 2.1821e-01, time/batch = 20.3624s	
14017/22750 (epoch 30.807), train_loss = 0.89554784, grad/param norm = 2.2521e-01, time/batch = 19.6864s	
14018/22750 (epoch 30.809), train_loss = 0.95385623, grad/param norm = 2.2906e-01, time/batch = 17.3442s	
14019/22750 (epoch 30.811), train_loss = 0.83583993, grad/param norm = 2.1705e-01, time/batch = 18.5097s	
14020/22750 (epoch 30.813), train_loss = 0.85644469, grad/param norm = 1.8787e-01, time/batch = 19.4919s	
14021/22750 (epoch 30.815), train_loss = 1.00535522, grad/param norm = 2.3057e-01, time/batch = 17.9183s	
14022/22750 (epoch 30.818), train_loss = 0.94016664, grad/param norm = 2.0357e-01, time/batch = 19.3340s	
14023/22750 (epoch 30.820), train_loss = 1.07021100, grad/param norm = 2.4446e-01, time/batch = 19.0333s	
14024/22750 (epoch 30.822), train_loss = 0.86916974, grad/param norm = 2.1662e-01, time/batch = 16.6280s	
14025/22750 (epoch 30.824), train_loss = 0.74288740, grad/param norm = 2.0612e-01, time/batch = 16.7921s	
14026/22750 (epoch 30.826), train_loss = 0.83920307, grad/param norm = 2.0604e-01, time/batch = 18.3527s	
14027/22750 (epoch 30.829), train_loss = 0.97536608, grad/param norm = 2.4407e-01, time/batch = 18.3308s	
14028/22750 (epoch 30.831), train_loss = 0.94051260, grad/param norm = 2.3388e-01, time/batch = 17.4139s	
14029/22750 (epoch 30.833), train_loss = 0.87137952, grad/param norm = 2.2224e-01, time/batch = 16.4471s	
14030/22750 (epoch 30.835), train_loss = 0.74101542, grad/param norm = 2.1128e-01, time/batch = 19.0061s	
14031/22750 (epoch 30.837), train_loss = 0.81336039, grad/param norm = 2.1564e-01, time/batch = 16.6579s	
14032/22750 (epoch 30.840), train_loss = 0.72773069, grad/param norm = 1.8375e-01, time/batch = 17.7749s	
14033/22750 (epoch 30.842), train_loss = 0.77466771, grad/param norm = 2.0330e-01, time/batch = 19.0353s	
14034/22750 (epoch 30.844), train_loss = 0.88599556, grad/param norm = 2.3946e-01, time/batch = 20.1131s	
14035/22750 (epoch 30.846), train_loss = 0.87436861, grad/param norm = 2.0772e-01, time/batch = 17.2664s	
14036/22750 (epoch 30.848), train_loss = 0.77015833, grad/param norm = 1.9169e-01, time/batch = 16.9919s	
14037/22750 (epoch 30.851), train_loss = 0.76027505, grad/param norm = 2.1379e-01, time/batch = 15.9410s	
14038/22750 (epoch 30.853), train_loss = 0.91091247, grad/param norm = 1.9878e-01, time/batch = 16.7219s	
14039/22750 (epoch 30.855), train_loss = 0.78350927, grad/param norm = 1.9603e-01, time/batch = 17.1641s	
14040/22750 (epoch 30.857), train_loss = 0.89510194, grad/param norm = 2.1235e-01, time/batch = 18.7505s	
14041/22750 (epoch 30.859), train_loss = 0.87858291, grad/param norm = 2.1096e-01, time/batch = 19.1667s	
14042/22750 (epoch 30.862), train_loss = 1.02034254, grad/param norm = 2.3109e-01, time/batch = 21.1004s	
14043/22750 (epoch 30.864), train_loss = 0.87036000, grad/param norm = 2.3311e-01, time/batch = 18.9338s	
14044/22750 (epoch 30.866), train_loss = 0.88797389, grad/param norm = 1.9565e-01, time/batch = 18.0854s	
14045/22750 (epoch 30.868), train_loss = 0.76362499, grad/param norm = 2.2246e-01, time/batch = 31.7811s	
14046/22750 (epoch 30.870), train_loss = 0.71478852, grad/param norm = 2.1173e-01, time/batch = 19.2314s	
14047/22750 (epoch 30.873), train_loss = 0.81603602, grad/param norm = 2.0417e-01, time/batch = 16.9958s	
14048/22750 (epoch 30.875), train_loss = 0.89271841, grad/param norm = 2.1736e-01, time/batch = 20.3878s	
14049/22750 (epoch 30.877), train_loss = 0.76707118, grad/param norm = 2.0254e-01, time/batch = 17.8379s	
14050/22750 (epoch 30.879), train_loss = 0.95793067, grad/param norm = 2.3466e-01, time/batch = 19.6862s	
14051/22750 (epoch 30.881), train_loss = 0.89354409, grad/param norm = 2.3775e-01, time/batch = 19.0981s	
14052/22750 (epoch 30.884), train_loss = 0.78146610, grad/param norm = 1.9748e-01, time/batch = 19.9141s	
14053/22750 (epoch 30.886), train_loss = 0.89107672, grad/param norm = 2.0714e-01, time/batch = 18.2445s	
14054/22750 (epoch 30.888), train_loss = 0.91120592, grad/param norm = 1.9860e-01, time/batch = 19.1691s	
14055/22750 (epoch 30.890), train_loss = 0.90185858, grad/param norm = 2.2411e-01, time/batch = 19.6545s	
14056/22750 (epoch 30.892), train_loss = 1.16164904, grad/param norm = 2.6193e-01, time/batch = 18.4134s	
14057/22750 (epoch 30.895), train_loss = 0.82516593, grad/param norm = 2.2790e-01, time/batch = 19.0969s	
14058/22750 (epoch 30.897), train_loss = 0.93085665, grad/param norm = 2.2322e-01, time/batch = 19.3404s	
14059/22750 (epoch 30.899), train_loss = 0.89815048, grad/param norm = 2.1857e-01, time/batch = 19.7738s	
14060/22750 (epoch 30.901), train_loss = 0.92934179, grad/param norm = 2.3463e-01, time/batch = 18.9309s	
14061/22750 (epoch 30.903), train_loss = 0.83905700, grad/param norm = 2.3273e-01, time/batch = 19.5946s	
14062/22750 (epoch 30.905), train_loss = 0.92674396, grad/param norm = 2.0866e-01, time/batch = 17.5255s	
14063/22750 (epoch 30.908), train_loss = 0.75614391, grad/param norm = 2.3746e-01, time/batch = 17.4057s	
14064/22750 (epoch 30.910), train_loss = 0.67282917, grad/param norm = 1.9411e-01, time/batch = 17.9935s	
14065/22750 (epoch 30.912), train_loss = 0.80227814, grad/param norm = 2.0408e-01, time/batch = 19.1707s	
14066/22750 (epoch 30.914), train_loss = 0.83668468, grad/param norm = 1.9877e-01, time/batch = 16.9140s	
14067/22750 (epoch 30.916), train_loss = 0.68172813, grad/param norm = 2.0704e-01, time/batch = 19.6574s	
14068/22750 (epoch 30.919), train_loss = 0.81230434, grad/param norm = 2.1645e-01, time/batch = 20.4381s	
14069/22750 (epoch 30.921), train_loss = 0.66574400, grad/param norm = 2.0235e-01, time/batch = 18.4390s	
14070/22750 (epoch 30.923), train_loss = 0.76229576, grad/param norm = 2.1314e-01, time/batch = 19.9340s	
14071/22750 (epoch 30.925), train_loss = 0.81329722, grad/param norm = 1.9883e-01, time/batch = 19.0121s	
14072/22750 (epoch 30.927), train_loss = 0.66887443, grad/param norm = 2.0590e-01, time/batch = 18.1521s	
14073/22750 (epoch 30.930), train_loss = 0.64535090, grad/param norm = 1.9329e-01, time/batch = 16.4640s	
14074/22750 (epoch 30.932), train_loss = 0.84143645, grad/param norm = 2.5331e-01, time/batch = 18.7470s	
14075/22750 (epoch 30.934), train_loss = 0.69383143, grad/param norm = 1.8332e-01, time/batch = 17.0689s	
14076/22750 (epoch 30.936), train_loss = 0.96188560, grad/param norm = 2.5651e-01, time/batch = 16.9767s	
14077/22750 (epoch 30.938), train_loss = 0.92578687, grad/param norm = 2.0995e-01, time/batch = 16.9303s	
14078/22750 (epoch 30.941), train_loss = 0.98750742, grad/param norm = 2.3133e-01, time/batch = 18.5799s	
14079/22750 (epoch 30.943), train_loss = 0.85270381, grad/param norm = 2.1507e-01, time/batch = 18.3545s	
14080/22750 (epoch 30.945), train_loss = 0.86015584, grad/param norm = 2.2531e-01, time/batch = 19.6025s	
14081/22750 (epoch 30.947), train_loss = 0.79963302, grad/param norm = 2.2044e-01, time/batch = 19.3342s	
14082/22750 (epoch 30.949), train_loss = 0.76668499, grad/param norm = 2.5542e-01, time/batch = 17.8421s	
14083/22750 (epoch 30.952), train_loss = 0.79446922, grad/param norm = 2.1090e-01, time/batch = 17.5019s	
14084/22750 (epoch 30.954), train_loss = 0.75391557, grad/param norm = 2.2819e-01, time/batch = 18.9809s	
14085/22750 (epoch 30.956), train_loss = 0.87113484, grad/param norm = 1.9409e-01, time/batch = 18.8358s	
14086/22750 (epoch 30.958), train_loss = 0.74889669, grad/param norm = 1.7640e-01, time/batch = 20.1639s	
14087/22750 (epoch 30.960), train_loss = 0.74213044, grad/param norm = 1.8571e-01, time/batch = 18.7026s	
14088/22750 (epoch 30.963), train_loss = 0.85907244, grad/param norm = 2.0563e-01, time/batch = 19.6131s	
14089/22750 (epoch 30.965), train_loss = 0.92245690, grad/param norm = 2.2849e-01, time/batch = 18.9492s	
14090/22750 (epoch 30.967), train_loss = 0.88872004, grad/param norm = 2.2942e-01, time/batch = 18.2720s	
14091/22750 (epoch 30.969), train_loss = 0.79727596, grad/param norm = 2.1696e-01, time/batch = 19.7492s	
14092/22750 (epoch 30.971), train_loss = 0.75914528, grad/param norm = 1.9718e-01, time/batch = 19.0646s	
14093/22750 (epoch 30.974), train_loss = 0.77203432, grad/param norm = 2.0453e-01, time/batch = 19.3210s	
14094/22750 (epoch 30.976), train_loss = 0.81996443, grad/param norm = 2.2135e-01, time/batch = 18.0713s	
14095/22750 (epoch 30.978), train_loss = 0.79002754, grad/param norm = 2.1985e-01, time/batch = 18.0964s	
14096/22750 (epoch 30.980), train_loss = 0.92698996, grad/param norm = 2.3464e-01, time/batch = 20.5163s	
14097/22750 (epoch 30.982), train_loss = 0.77600539, grad/param norm = 2.1451e-01, time/batch = 20.3589s	
14098/22750 (epoch 30.985), train_loss = 0.96447272, grad/param norm = 2.4635e-01, time/batch = 17.8558s	
14099/22750 (epoch 30.987), train_loss = 0.69185373, grad/param norm = 1.8788e-01, time/batch = 19.5058s	
14100/22750 (epoch 30.989), train_loss = 0.79529950, grad/param norm = 2.5406e-01, time/batch = 19.5003s	
14101/22750 (epoch 30.991), train_loss = 0.87425661, grad/param norm = 2.4533e-01, time/batch = 18.0886s	
14102/22750 (epoch 30.993), train_loss = 0.86259844, grad/param norm = 2.7343e-01, time/batch = 15.9432s	
14103/22750 (epoch 30.996), train_loss = 0.75868982, grad/param norm = 2.7037e-01, time/batch = 17.8311s	
14104/22750 (epoch 30.998), train_loss = 0.96113652, grad/param norm = 2.4214e-01, time/batch = 16.5593s	
decayed learning rate by a factor 0.97 to 0.0010233121945196	
14105/22750 (epoch 31.000), train_loss = 0.84149266, grad/param norm = 2.2116e-01, time/batch = 16.2526s	
14106/22750 (epoch 31.002), train_loss = 0.99497814, grad/param norm = 2.3199e-01, time/batch = 17.8576s	
14107/22750 (epoch 31.004), train_loss = 0.80690025, grad/param norm = 2.2084e-01, time/batch = 19.2087s	
14108/22750 (epoch 31.007), train_loss = 0.80439001, grad/param norm = 2.5546e-01, time/batch = 18.5095s	
14109/22750 (epoch 31.009), train_loss = 0.97808003, grad/param norm = 2.5413e-01, time/batch = 18.0247s	
14110/22750 (epoch 31.011), train_loss = 1.09094254, grad/param norm = 2.9617e-01, time/batch = 19.5842s	
14111/22750 (epoch 31.013), train_loss = 0.96868310, grad/param norm = 2.4028e-01, time/batch = 18.0004s	
14112/22750 (epoch 31.015), train_loss = 0.87742241, grad/param norm = 2.1920e-01, time/batch = 16.2010s	
14113/22750 (epoch 31.018), train_loss = 0.94647879, grad/param norm = 2.5157e-01, time/batch = 18.3447s	
14114/22750 (epoch 31.020), train_loss = 0.98825506, grad/param norm = 2.2279e-01, time/batch = 18.9104s	
14115/22750 (epoch 31.022), train_loss = 0.85611988, grad/param norm = 2.2717e-01, time/batch = 17.2552s	
14116/22750 (epoch 31.024), train_loss = 0.85459486, grad/param norm = 2.1540e-01, time/batch = 20.5047s	
14117/22750 (epoch 31.026), train_loss = 0.88818315, grad/param norm = 2.4509e-01, time/batch = 20.2666s	
14118/22750 (epoch 31.029), train_loss = 0.71600359, grad/param norm = 2.3124e-01, time/batch = 19.0757s	
14119/22750 (epoch 31.031), train_loss = 1.07469134, grad/param norm = 2.5439e-01, time/batch = 17.9838s	
14120/22750 (epoch 31.033), train_loss = 0.82654576, grad/param norm = 2.2963e-01, time/batch = 20.0630s	
14121/22750 (epoch 31.035), train_loss = 0.89180867, grad/param norm = 2.4339e-01, time/batch = 19.9805s	
14122/22750 (epoch 31.037), train_loss = 0.93841785, grad/param norm = 2.0339e-01, time/batch = 17.1780s	
14123/22750 (epoch 31.040), train_loss = 0.84177231, grad/param norm = 2.1065e-01, time/batch = 16.2488s	
14124/22750 (epoch 31.042), train_loss = 0.87046881, grad/param norm = 2.1782e-01, time/batch = 16.9029s	
14125/22750 (epoch 31.044), train_loss = 0.83418023, grad/param norm = 2.1221e-01, time/batch = 16.3942s	
14126/22750 (epoch 31.046), train_loss = 0.95265613, grad/param norm = 2.3652e-01, time/batch = 16.2481s	
14127/22750 (epoch 31.048), train_loss = 0.84071628, grad/param norm = 1.9106e-01, time/batch = 16.3667s	
14128/22750 (epoch 31.051), train_loss = 0.88081064, grad/param norm = 2.4418e-01, time/batch = 19.4040s	
14129/22750 (epoch 31.053), train_loss = 0.81622864, grad/param norm = 1.8392e-01, time/batch = 20.2431s	
14130/22750 (epoch 31.055), train_loss = 0.72500594, grad/param norm = 2.0398e-01, time/batch = 17.9021s	
14131/22750 (epoch 31.057), train_loss = 1.01515747, grad/param norm = 2.3647e-01, time/batch = 17.6739s	
14132/22750 (epoch 31.059), train_loss = 0.64533672, grad/param norm = 2.0789e-01, time/batch = 17.1657s	
14133/22750 (epoch 31.062), train_loss = 0.72782582, grad/param norm = 2.1330e-01, time/batch = 18.0765s	
14134/22750 (epoch 31.064), train_loss = 0.92940234, grad/param norm = 2.1722e-01, time/batch = 18.3386s	
14135/22750 (epoch 31.066), train_loss = 0.74738618, grad/param norm = 1.9194e-01, time/batch = 19.3615s	
14136/22750 (epoch 31.068), train_loss = 0.75707323, grad/param norm = 1.7255e-01, time/batch = 20.8668s	
14137/22750 (epoch 31.070), train_loss = 0.63155634, grad/param norm = 1.7467e-01, time/batch = 19.0946s	
14138/22750 (epoch 31.073), train_loss = 0.80714914, grad/param norm = 2.2135e-01, time/batch = 19.3430s	
14139/22750 (epoch 31.075), train_loss = 0.83004548, grad/param norm = 1.8687e-01, time/batch = 20.2561s	
14140/22750 (epoch 31.077), train_loss = 0.61786074, grad/param norm = 1.9707e-01, time/batch = 18.7340s	
14141/22750 (epoch 31.079), train_loss = 0.82370138, grad/param norm = 2.4207e-01, time/batch = 17.6482s	
14142/22750 (epoch 31.081), train_loss = 0.80307175, grad/param norm = 2.2017e-01, time/batch = 16.3476s	
14143/22750 (epoch 31.084), train_loss = 0.79433867, grad/param norm = 2.0911e-01, time/batch = 16.6880s	
14144/22750 (epoch 31.086), train_loss = 0.82704883, grad/param norm = 1.9221e-01, time/batch = 17.1920s	
14145/22750 (epoch 31.088), train_loss = 0.75876536, grad/param norm = 2.0129e-01, time/batch = 17.8626s	
14146/22750 (epoch 31.090), train_loss = 0.78467059, grad/param norm = 1.8888e-01, time/batch = 20.4428s	
14147/22750 (epoch 31.092), train_loss = 0.92157021, grad/param norm = 2.0897e-01, time/batch = 16.3464s	
14148/22750 (epoch 31.095), train_loss = 0.76345099, grad/param norm = 2.1117e-01, time/batch = 16.1822s	
14149/22750 (epoch 31.097), train_loss = 0.82508657, grad/param norm = 1.9131e-01, time/batch = 17.5747s	
14150/22750 (epoch 31.099), train_loss = 0.78789406, grad/param norm = 2.1166e-01, time/batch = 16.3583s	
14151/22750 (epoch 31.101), train_loss = 0.69928726, grad/param norm = 2.0529e-01, time/batch = 18.2455s	
14152/22750 (epoch 31.103), train_loss = 0.89196320, grad/param norm = 2.3091e-01, time/batch = 19.2449s	
14153/22750 (epoch 31.105), train_loss = 0.96697184, grad/param norm = 2.5355e-01, time/batch = 20.5083s	
14154/22750 (epoch 31.108), train_loss = 0.83073928, grad/param norm = 2.1918e-01, time/batch = 18.5199s	
14155/22750 (epoch 31.110), train_loss = 0.95881158, grad/param norm = 2.1674e-01, time/batch = 19.6016s	
14156/22750 (epoch 31.112), train_loss = 0.69384136, grad/param norm = 1.7397e-01, time/batch = 16.2964s	
14157/22750 (epoch 31.114), train_loss = 0.61955083, grad/param norm = 1.8072e-01, time/batch = 15.9261s	
14158/22750 (epoch 31.116), train_loss = 0.81390521, grad/param norm = 1.9996e-01, time/batch = 19.0658s	
14159/22750 (epoch 31.119), train_loss = 0.77147374, grad/param norm = 1.8257e-01, time/batch = 17.4076s	
14160/22750 (epoch 31.121), train_loss = 0.81280814, grad/param norm = 2.2168e-01, time/batch = 16.7521s	
14161/22750 (epoch 31.123), train_loss = 0.72150562, grad/param norm = 2.1302e-01, time/batch = 16.4788s	
14162/22750 (epoch 31.125), train_loss = 0.95241432, grad/param norm = 2.0080e-01, time/batch = 19.7447s	
14163/22750 (epoch 31.127), train_loss = 0.80175088, grad/param norm = 2.2552e-01, time/batch = 17.1793s	
14164/22750 (epoch 31.130), train_loss = 0.80681794, grad/param norm = 1.9525e-01, time/batch = 18.9253s	
14165/22750 (epoch 31.132), train_loss = 0.74916428, grad/param norm = 2.1076e-01, time/batch = 15.6642s	
14166/22750 (epoch 31.134), train_loss = 0.78822903, grad/param norm = 1.9545e-01, time/batch = 16.4491s	
14167/22750 (epoch 31.136), train_loss = 0.65632883, grad/param norm = 2.0623e-01, time/batch = 16.3437s	
14168/22750 (epoch 31.138), train_loss = 0.87285145, grad/param norm = 2.1609e-01, time/batch = 17.6758s	
14169/22750 (epoch 31.141), train_loss = 0.85956789, grad/param norm = 2.2852e-01, time/batch = 17.6043s	
14170/22750 (epoch 31.143), train_loss = 0.74167941, grad/param norm = 2.0222e-01, time/batch = 18.3431s	
14171/22750 (epoch 31.145), train_loss = 0.94069058, grad/param norm = 2.1071e-01, time/batch = 18.6798s	
14172/22750 (epoch 31.147), train_loss = 0.98014259, grad/param norm = 2.4885e-01, time/batch = 17.8614s	
14173/22750 (epoch 31.149), train_loss = 0.84172288, grad/param norm = 2.2774e-01, time/batch = 18.9549s	
14174/22750 (epoch 31.152), train_loss = 0.82762934, grad/param norm = 1.9656e-01, time/batch = 16.0702s	
14175/22750 (epoch 31.154), train_loss = 0.74171029, grad/param norm = 2.0040e-01, time/batch = 15.0869s	
14176/22750 (epoch 31.156), train_loss = 0.75114587, grad/param norm = 2.2281e-01, time/batch = 15.2005s	
14177/22750 (epoch 31.158), train_loss = 0.75134214, grad/param norm = 2.1797e-01, time/batch = 19.2296s	
14178/22750 (epoch 31.160), train_loss = 0.82725783, grad/param norm = 2.3756e-01, time/batch = 18.7430s	
14179/22750 (epoch 31.163), train_loss = 0.98072628, grad/param norm = 2.3480e-01, time/batch = 20.0835s	
14180/22750 (epoch 31.165), train_loss = 0.87287568, grad/param norm = 2.2029e-01, time/batch = 19.5033s	
14181/22750 (epoch 31.167), train_loss = 0.77412139, grad/param norm = 2.0548e-01, time/batch = 16.7235s	
14182/22750 (epoch 31.169), train_loss = 0.85708519, grad/param norm = 2.3795e-01, time/batch = 16.6535s	
14183/22750 (epoch 31.171), train_loss = 0.70975981, grad/param norm = 1.8689e-01, time/batch = 17.7914s	
14184/22750 (epoch 31.174), train_loss = 0.70097852, grad/param norm = 2.1151e-01, time/batch = 18.1922s	
14185/22750 (epoch 31.176), train_loss = 0.73752756, grad/param norm = 2.3435e-01, time/batch = 19.1156s	
14186/22750 (epoch 31.178), train_loss = 0.75447170, grad/param norm = 2.1813e-01, time/batch = 17.9381s	
14187/22750 (epoch 31.180), train_loss = 0.96920582, grad/param norm = 2.8215e-01, time/batch = 18.9158s	
14188/22750 (epoch 31.182), train_loss = 0.90233253, grad/param norm = 2.4101e-01, time/batch = 18.2317s	
14189/22750 (epoch 31.185), train_loss = 0.93277960, grad/param norm = 2.4185e-01, time/batch = 17.7521s	
14190/22750 (epoch 31.187), train_loss = 0.70531835, grad/param norm = 1.7158e-01, time/batch = 19.2560s	
14191/22750 (epoch 31.189), train_loss = 0.75341767, grad/param norm = 2.5232e-01, time/batch = 16.4278s	
14192/22750 (epoch 31.191), train_loss = 0.75498684, grad/param norm = 1.9460e-01, time/batch = 16.1759s	
14193/22750 (epoch 31.193), train_loss = 0.89631060, grad/param norm = 2.1829e-01, time/batch = 16.4379s	
14194/22750 (epoch 31.196), train_loss = 0.79341835, grad/param norm = 2.3336e-01, time/batch = 17.3454s	
14195/22750 (epoch 31.198), train_loss = 0.62034258, grad/param norm = 2.1476e-01, time/batch = 18.2088s	
14196/22750 (epoch 31.200), train_loss = 0.82391591, grad/param norm = 2.0331e-01, time/batch = 18.0211s	
14197/22750 (epoch 31.202), train_loss = 0.88872671, grad/param norm = 2.6195e-01, time/batch = 17.5111s	
14198/22750 (epoch 31.204), train_loss = 0.84221205, grad/param norm = 2.0721e-01, time/batch = 17.3362s	
14199/22750 (epoch 31.207), train_loss = 0.82235306, grad/param norm = 2.0990e-01, time/batch = 16.4354s	
14200/22750 (epoch 31.209), train_loss = 0.76919879, grad/param norm = 2.0434e-01, time/batch = 18.9282s	
14201/22750 (epoch 31.211), train_loss = 0.73172071, grad/param norm = 1.9814e-01, time/batch = 17.3421s	
14202/22750 (epoch 31.213), train_loss = 0.63238519, grad/param norm = 2.0009e-01, time/batch = 20.9949s	
14203/22750 (epoch 31.215), train_loss = 0.62466446, grad/param norm = 1.9327e-01, time/batch = 19.5983s	
14204/22750 (epoch 31.218), train_loss = 0.71367401, grad/param norm = 2.2671e-01, time/batch = 16.2827s	
14205/22750 (epoch 31.220), train_loss = 0.66944151, grad/param norm = 1.8762e-01, time/batch = 16.5312s	
14206/22750 (epoch 31.222), train_loss = 0.70471391, grad/param norm = 1.9762e-01, time/batch = 19.7754s	
14207/22750 (epoch 31.224), train_loss = 0.72959551, grad/param norm = 1.9408e-01, time/batch = 18.9088s	
14208/22750 (epoch 31.226), train_loss = 0.82311025, grad/param norm = 2.4081e-01, time/batch = 16.4024s	
14209/22750 (epoch 31.229), train_loss = 0.84667677, grad/param norm = 2.2403e-01, time/batch = 15.1652s	
14210/22750 (epoch 31.231), train_loss = 0.71299042, grad/param norm = 2.1296e-01, time/batch = 16.3449s	
14211/22750 (epoch 31.233), train_loss = 0.67762125, grad/param norm = 2.2626e-01, time/batch = 18.0904s	
14212/22750 (epoch 31.235), train_loss = 0.64992031, grad/param norm = 2.0661e-01, time/batch = 16.7024s	
14213/22750 (epoch 31.237), train_loss = 0.73004597, grad/param norm = 2.1438e-01, time/batch = 19.7458s	
14214/22750 (epoch 31.240), train_loss = 0.79223579, grad/param norm = 1.8907e-01, time/batch = 17.3436s	
14215/22750 (epoch 31.242), train_loss = 0.99066754, grad/param norm = 2.6082e-01, time/batch = 17.9791s	
14216/22750 (epoch 31.244), train_loss = 0.96496066, grad/param norm = 2.2658e-01, time/batch = 19.7773s	
14217/22750 (epoch 31.246), train_loss = 0.98081505, grad/param norm = 2.5119e-01, time/batch = 19.3586s	
14218/22750 (epoch 31.248), train_loss = 0.80629250, grad/param norm = 2.0870e-01, time/batch = 20.0802s	
14219/22750 (epoch 31.251), train_loss = 0.92986172, grad/param norm = 2.5477e-01, time/batch = 19.9952s	
14220/22750 (epoch 31.253), train_loss = 0.86651475, grad/param norm = 2.6814e-01, time/batch = 17.9220s	
14221/22750 (epoch 31.255), train_loss = 0.84471116, grad/param norm = 2.2253e-01, time/batch = 18.3369s	
14222/22750 (epoch 31.257), train_loss = 0.75166659, grad/param norm = 2.3333e-01, time/batch = 18.5056s	
14223/22750 (epoch 31.259), train_loss = 0.93162269, grad/param norm = 2.8940e-01, time/batch = 20.1635s	
14224/22750 (epoch 31.262), train_loss = 0.84994874, grad/param norm = 2.4524e-01, time/batch = 18.0703s	
14225/22750 (epoch 31.264), train_loss = 0.66731709, grad/param norm = 2.3072e-01, time/batch = 19.8448s	
14226/22750 (epoch 31.266), train_loss = 0.81151287, grad/param norm = 2.7174e-01, time/batch = 19.7597s	
14227/22750 (epoch 31.268), train_loss = 0.95485277, grad/param norm = 2.4652e-01, time/batch = 16.7373s	
14228/22750 (epoch 31.270), train_loss = 0.74404003, grad/param norm = 2.3377e-01, time/batch = 20.0217s	
14229/22750 (epoch 31.273), train_loss = 1.07692399, grad/param norm = 2.8064e-01, time/batch = 20.1214s	
14230/22750 (epoch 31.275), train_loss = 0.96000459, grad/param norm = 2.1760e-01, time/batch = 18.3441s	
14231/22750 (epoch 31.277), train_loss = 0.81593332, grad/param norm = 2.5035e-01, time/batch = 18.7645s	
14232/22750 (epoch 31.279), train_loss = 0.69734532, grad/param norm = 2.0294e-01, time/batch = 20.1770s	
14233/22750 (epoch 31.281), train_loss = 0.96536419, grad/param norm = 2.3658e-01, time/batch = 17.5942s	
14234/22750 (epoch 31.284), train_loss = 0.83155946, grad/param norm = 1.9755e-01, time/batch = 19.9229s	
14235/22750 (epoch 31.286), train_loss = 0.89613152, grad/param norm = 2.2853e-01, time/batch = 19.5010s	
14236/22750 (epoch 31.288), train_loss = 0.98530396, grad/param norm = 2.4691e-01, time/batch = 18.5127s	
14237/22750 (epoch 31.290), train_loss = 0.85658373, grad/param norm = 2.2848e-01, time/batch = 18.7625s	
14238/22750 (epoch 31.292), train_loss = 0.91216620, grad/param norm = 2.6683e-01, time/batch = 18.1173s	
14239/22750 (epoch 31.295), train_loss = 0.86506533, grad/param norm = 2.1606e-01, time/batch = 22.0656s	
14240/22750 (epoch 31.297), train_loss = 0.83732168, grad/param norm = 2.3548e-01, time/batch = 28.4087s	
14241/22750 (epoch 31.299), train_loss = 0.91874588, grad/param norm = 2.2191e-01, time/batch = 18.1826s	
14242/22750 (epoch 31.301), train_loss = 0.84947122, grad/param norm = 2.0795e-01, time/batch = 16.1178s	
14243/22750 (epoch 31.303), train_loss = 0.88492898, grad/param norm = 2.1646e-01, time/batch = 17.9140s	
14244/22750 (epoch 31.305), train_loss = 1.00023006, grad/param norm = 2.2716e-01, time/batch = 15.3592s	
14245/22750 (epoch 31.308), train_loss = 0.89157899, grad/param norm = 2.0999e-01, time/batch = 15.2683s	
14246/22750 (epoch 31.310), train_loss = 0.78216053, grad/param norm = 2.7024e-01, time/batch = 15.4267s	
14247/22750 (epoch 31.312), train_loss = 0.86557198, grad/param norm = 2.1955e-01, time/batch = 14.8044s	
14248/22750 (epoch 31.314), train_loss = 0.85282861, grad/param norm = 2.2247e-01, time/batch = 15.0666s	
14249/22750 (epoch 31.316), train_loss = 0.79976273, grad/param norm = 2.2298e-01, time/batch = 14.5819s	
14250/22750 (epoch 31.319), train_loss = 0.84774384, grad/param norm = 2.3142e-01, time/batch = 15.5345s	
14251/22750 (epoch 31.321), train_loss = 0.78674575, grad/param norm = 2.2625e-01, time/batch = 15.0522s	
14252/22750 (epoch 31.323), train_loss = 0.85821557, grad/param norm = 2.2558e-01, time/batch = 15.0562s	
14253/22750 (epoch 31.325), train_loss = 0.75190883, grad/param norm = 2.1079e-01, time/batch = 14.7339s	
14254/22750 (epoch 31.327), train_loss = 0.77506898, grad/param norm = 2.2340e-01, time/batch = 15.1408s	
14255/22750 (epoch 31.330), train_loss = 0.99261754, grad/param norm = 2.3029e-01, time/batch = 15.0461s	
14256/22750 (epoch 31.332), train_loss = 1.02372030, grad/param norm = 2.1100e-01, time/batch = 15.5361s	
14257/22750 (epoch 31.334), train_loss = 0.68584366, grad/param norm = 1.8908e-01, time/batch = 14.8875s	
14258/22750 (epoch 31.336), train_loss = 0.92123992, grad/param norm = 1.9866e-01, time/batch = 15.6749s	
14259/22750 (epoch 31.338), train_loss = 0.83775925, grad/param norm = 2.1790e-01, time/batch = 15.1413s	
14260/22750 (epoch 31.341), train_loss = 0.85615903, grad/param norm = 2.4511e-01, time/batch = 15.0759s	
14261/22750 (epoch 31.343), train_loss = 0.74122415, grad/param norm = 2.2273e-01, time/batch = 15.2249s	
14262/22750 (epoch 31.345), train_loss = 0.89112751, grad/param norm = 2.4039e-01, time/batch = 15.7854s	
14263/22750 (epoch 31.347), train_loss = 0.96295425, grad/param norm = 2.4542e-01, time/batch = 15.0719s	
14264/22750 (epoch 31.349), train_loss = 0.67131354, grad/param norm = 2.1263e-01, time/batch = 15.0600s	
14265/22750 (epoch 31.352), train_loss = 0.96126601, grad/param norm = 2.3334e-01, time/batch = 15.2188s	
14266/22750 (epoch 31.354), train_loss = 0.96567725, grad/param norm = 2.5209e-01, time/batch = 15.3837s	
14267/22750 (epoch 31.356), train_loss = 0.91340858, grad/param norm = 2.3210e-01, time/batch = 16.3870s	
14268/22750 (epoch 31.358), train_loss = 0.80598940, grad/param norm = 2.2272e-01, time/batch = 15.8216s	
14269/22750 (epoch 31.360), train_loss = 0.99353998, grad/param norm = 2.2838e-01, time/batch = 15.9945s	
14270/22750 (epoch 31.363), train_loss = 0.82284480, grad/param norm = 2.4280e-01, time/batch = 15.1296s	
14271/22750 (epoch 31.365), train_loss = 0.68095990, grad/param norm = 2.1796e-01, time/batch = 15.4592s	
14272/22750 (epoch 31.367), train_loss = 0.77452928, grad/param norm = 2.3820e-01, time/batch = 15.1386s	
14273/22750 (epoch 31.369), train_loss = 0.86599614, grad/param norm = 2.3747e-01, time/batch = 15.4665s	
14274/22750 (epoch 31.371), train_loss = 0.85630194, grad/param norm = 2.5535e-01, time/batch = 14.9937s	
14275/22750 (epoch 31.374), train_loss = 0.74318207, grad/param norm = 2.5890e-01, time/batch = 14.9904s	
14276/22750 (epoch 31.376), train_loss = 0.81627096, grad/param norm = 2.0132e-01, time/batch = 15.0579s	
14277/22750 (epoch 31.378), train_loss = 0.85362162, grad/param norm = 2.2562e-01, time/batch = 15.6189s	
14278/22750 (epoch 31.380), train_loss = 0.91339294, grad/param norm = 2.1675e-01, time/batch = 15.3013s	
14279/22750 (epoch 31.382), train_loss = 0.83025683, grad/param norm = 2.1300e-01, time/batch = 15.2022s	
14280/22750 (epoch 31.385), train_loss = 0.91044513, grad/param norm = 2.1480e-01, time/batch = 15.1125s	
14281/22750 (epoch 31.387), train_loss = 0.87166695, grad/param norm = 2.2017e-01, time/batch = 15.3621s	
14282/22750 (epoch 31.389), train_loss = 0.67955855, grad/param norm = 2.0081e-01, time/batch = 15.3756s	
14283/22750 (epoch 31.391), train_loss = 0.52890259, grad/param norm = 1.9366e-01, time/batch = 15.1332s	
14284/22750 (epoch 31.393), train_loss = 0.68881483, grad/param norm = 1.8384e-01, time/batch = 15.1349s	
14285/22750 (epoch 31.396), train_loss = 0.87744989, grad/param norm = 2.2173e-01, time/batch = 15.5354s	
14286/22750 (epoch 31.398), train_loss = 0.81744798, grad/param norm = 2.1342e-01, time/batch = 15.0746s	
14287/22750 (epoch 31.400), train_loss = 0.83478681, grad/param norm = 2.2252e-01, time/batch = 15.2458s	
14288/22750 (epoch 31.402), train_loss = 0.87148761, grad/param norm = 2.1052e-01, time/batch = 15.5513s	
14289/22750 (epoch 31.404), train_loss = 0.94236939, grad/param norm = 2.0788e-01, time/batch = 15.5408s	
14290/22750 (epoch 31.407), train_loss = 0.91026855, grad/param norm = 1.9941e-01, time/batch = 15.3001s	
14291/22750 (epoch 31.409), train_loss = 0.76432857, grad/param norm = 2.2169e-01, time/batch = 15.9201s	
14292/22750 (epoch 31.411), train_loss = 0.78062352, grad/param norm = 2.0565e-01, time/batch = 15.3697s	
14293/22750 (epoch 31.413), train_loss = 0.61998112, grad/param norm = 2.1951e-01, time/batch = 15.2880s	
14294/22750 (epoch 31.415), train_loss = 0.65723996, grad/param norm = 1.9849e-01, time/batch = 15.1366s	
14295/22750 (epoch 31.418), train_loss = 0.77638377, grad/param norm = 2.2501e-01, time/batch = 15.3859s	
14296/22750 (epoch 31.420), train_loss = 0.90587894, grad/param norm = 2.8191e-01, time/batch = 15.5368s	
14297/22750 (epoch 31.422), train_loss = 1.05816588, grad/param norm = 2.8348e-01, time/batch = 15.2973s	
14298/22750 (epoch 31.424), train_loss = 1.02194102, grad/param norm = 2.4007e-01, time/batch = 15.2271s	
14299/22750 (epoch 31.426), train_loss = 1.00745203, grad/param norm = 2.2814e-01, time/batch = 15.5439s	
14300/22750 (epoch 31.429), train_loss = 0.76099284, grad/param norm = 2.0171e-01, time/batch = 15.5559s	
14301/22750 (epoch 31.431), train_loss = 0.69477221, grad/param norm = 1.8854e-01, time/batch = 15.4064s	
14302/22750 (epoch 31.433), train_loss = 0.79154733, grad/param norm = 2.0114e-01, time/batch = 16.0107s	
14303/22750 (epoch 31.435), train_loss = 0.63776864, grad/param norm = 1.9867e-01, time/batch = 15.2149s	
14304/22750 (epoch 31.437), train_loss = 0.53227695, grad/param norm = 1.6079e-01, time/batch = 15.6919s	
14305/22750 (epoch 31.440), train_loss = 0.79889180, grad/param norm = 2.4443e-01, time/batch = 15.0427s	
14306/22750 (epoch 31.442), train_loss = 0.82204590, grad/param norm = 1.9889e-01, time/batch = 15.7644s	
14307/22750 (epoch 31.444), train_loss = 0.79374225, grad/param norm = 2.3086e-01, time/batch = 15.1373s	
14308/22750 (epoch 31.446), train_loss = 0.82350358, grad/param norm = 2.5715e-01, time/batch = 15.8517s	
14309/22750 (epoch 31.448), train_loss = 1.03834056, grad/param norm = 2.5686e-01, time/batch = 15.2150s	
14310/22750 (epoch 31.451), train_loss = 1.01988703, grad/param norm = 2.0987e-01, time/batch = 15.6808s	
14311/22750 (epoch 31.453), train_loss = 0.92014815, grad/param norm = 2.4586e-01, time/batch = 15.8138s	
14312/22750 (epoch 31.455), train_loss = 0.99545287, grad/param norm = 2.2707e-01, time/batch = 15.4386s	
14313/22750 (epoch 31.457), train_loss = 0.91686653, grad/param norm = 4.1519e-01, time/batch = 15.1533s	
14314/22750 (epoch 31.459), train_loss = 0.90424840, grad/param norm = 2.3955e-01, time/batch = 15.1318s	
14315/22750 (epoch 31.462), train_loss = 0.89377085, grad/param norm = 2.0214e-01, time/batch = 15.0322s	
14316/22750 (epoch 31.464), train_loss = 0.72938429, grad/param norm = 2.2496e-01, time/batch = 15.6775s	
14317/22750 (epoch 31.466), train_loss = 0.92478625, grad/param norm = 2.6579e-01, time/batch = 15.1342s	
14318/22750 (epoch 31.468), train_loss = 0.86653163, grad/param norm = 2.4471e-01, time/batch = 15.1337s	
14319/22750 (epoch 31.470), train_loss = 0.93917189, grad/param norm = 2.3318e-01, time/batch = 15.1967s	
14320/22750 (epoch 31.473), train_loss = 0.82879191, grad/param norm = 2.4252e-01, time/batch = 15.5294s	
14321/22750 (epoch 31.475), train_loss = 0.86396015, grad/param norm = 2.3943e-01, time/batch = 15.3114s	
14322/22750 (epoch 31.477), train_loss = 0.74499326, grad/param norm = 2.1677e-01, time/batch = 16.6390s	
14323/22750 (epoch 31.479), train_loss = 0.72689121, grad/param norm = 2.1761e-01, time/batch = 17.2695s	
14324/22750 (epoch 31.481), train_loss = 0.70062984, grad/param norm = 1.9111e-01, time/batch = 19.9415s	
14325/22750 (epoch 31.484), train_loss = 0.58096859, grad/param norm = 2.1816e-01, time/batch = 18.9204s	
14326/22750 (epoch 31.486), train_loss = 0.70195913, grad/param norm = 1.9316e-01, time/batch = 19.3257s	
14327/22750 (epoch 31.488), train_loss = 0.63502012, grad/param norm = 1.8645e-01, time/batch = 19.1585s	
14328/22750 (epoch 31.490), train_loss = 0.81539243, grad/param norm = 2.2456e-01, time/batch = 18.8355s	
14329/22750 (epoch 31.492), train_loss = 0.91826569, grad/param norm = 2.4615e-01, time/batch = 20.3130s	
14330/22750 (epoch 31.495), train_loss = 0.74176655, grad/param norm = 1.9795e-01, time/batch = 17.4996s	
14331/22750 (epoch 31.497), train_loss = 0.80535262, grad/param norm = 2.3787e-01, time/batch = 18.9581s	
14332/22750 (epoch 31.499), train_loss = 0.76323634, grad/param norm = 2.3928e-01, time/batch = 19.1924s	
14333/22750 (epoch 31.501), train_loss = 0.79181246, grad/param norm = 2.1044e-01, time/batch = 17.2734s	
14334/22750 (epoch 31.503), train_loss = 0.79843976, grad/param norm = 2.1081e-01, time/batch = 19.7480s	
14335/22750 (epoch 31.505), train_loss = 0.73563111, grad/param norm = 2.1868e-01, time/batch = 19.5812s	
14336/22750 (epoch 31.508), train_loss = 0.66437069, grad/param norm = 2.0571e-01, time/batch = 18.6774s	
14337/22750 (epoch 31.510), train_loss = 0.71303173, grad/param norm = 1.9033e-01, time/batch = 17.9265s	
14338/22750 (epoch 31.512), train_loss = 0.74347429, grad/param norm = 2.1081e-01, time/batch = 18.6817s	
14339/22750 (epoch 31.514), train_loss = 0.77002291, grad/param norm = 2.1713e-01, time/batch = 16.7039s	
14340/22750 (epoch 31.516), train_loss = 0.77518766, grad/param norm = 2.1594e-01, time/batch = 17.1246s	
14341/22750 (epoch 31.519), train_loss = 0.89047906, grad/param norm = 2.2475e-01, time/batch = 17.7505s	
14342/22750 (epoch 31.521), train_loss = 0.81547051, grad/param norm = 2.3943e-01, time/batch = 19.4238s	
14343/22750 (epoch 31.523), train_loss = 0.76934973, grad/param norm = 2.7311e-01, time/batch = 18.8210s	
14344/22750 (epoch 31.525), train_loss = 0.94410015, grad/param norm = 2.4027e-01, time/batch = 18.4144s	
14345/22750 (epoch 31.527), train_loss = 0.81508832, grad/param norm = 2.1829e-01, time/batch = 17.3422s	
14346/22750 (epoch 31.530), train_loss = 0.74089165, grad/param norm = 2.1172e-01, time/batch = 17.4231s	
14347/22750 (epoch 31.532), train_loss = 0.69732720, grad/param norm = 1.9259e-01, time/batch = 16.5659s	
14348/22750 (epoch 31.534), train_loss = 0.89732574, grad/param norm = 2.5588e-01, time/batch = 17.3502s	
14349/22750 (epoch 31.536), train_loss = 0.84572871, grad/param norm = 1.9955e-01, time/batch = 18.4341s	
14350/22750 (epoch 31.538), train_loss = 0.83204996, grad/param norm = 2.0017e-01, time/batch = 20.5199s	
14351/22750 (epoch 31.541), train_loss = 0.72571226, grad/param norm = 2.2977e-01, time/batch = 18.5675s	
14352/22750 (epoch 31.543), train_loss = 0.70690578, grad/param norm = 2.1185e-01, time/batch = 18.6635s	
14353/22750 (epoch 31.545), train_loss = 0.89825394, grad/param norm = 2.2920e-01, time/batch = 19.0852s	
14354/22750 (epoch 31.547), train_loss = 0.74916684, grad/param norm = 1.8804e-01, time/batch = 17.4197s	
14355/22750 (epoch 31.549), train_loss = 0.79232242, grad/param norm = 1.9208e-01, time/batch = 19.4165s	
14356/22750 (epoch 31.552), train_loss = 0.86871854, grad/param norm = 2.4249e-01, time/batch = 18.7544s	
14357/22750 (epoch 31.554), train_loss = 0.90901780, grad/param norm = 2.4548e-01, time/batch = 19.5979s	
14358/22750 (epoch 31.556), train_loss = 0.86915494, grad/param norm = 2.3667e-01, time/batch = 19.6223s	
14359/22750 (epoch 31.558), train_loss = 0.85632496, grad/param norm = 2.3225e-01, time/batch = 17.9396s	
14360/22750 (epoch 31.560), train_loss = 0.78615899, grad/param norm = 2.2046e-01, time/batch = 20.1059s	
14361/22750 (epoch 31.563), train_loss = 0.91286872, grad/param norm = 2.3422e-01, time/batch = 20.4827s	
14362/22750 (epoch 31.565), train_loss = 0.90008757, grad/param norm = 2.5388e-01, time/batch = 18.6550s	
14363/22750 (epoch 31.567), train_loss = 0.87850959, grad/param norm = 2.1547e-01, time/batch = 19.0757s	
14364/22750 (epoch 31.569), train_loss = 0.78971524, grad/param norm = 2.2132e-01, time/batch = 18.3479s	
14365/22750 (epoch 31.571), train_loss = 0.81410897, grad/param norm = 2.5320e-01, time/batch = 18.0792s	
14366/22750 (epoch 31.574), train_loss = 0.83654979, grad/param norm = 2.1773e-01, time/batch = 18.7467s	
14367/22750 (epoch 31.576), train_loss = 0.79252988, grad/param norm = 2.2876e-01, time/batch = 19.2702s	
14368/22750 (epoch 31.578), train_loss = 0.70237072, grad/param norm = 2.1516e-01, time/batch = 18.6085s	
14369/22750 (epoch 31.580), train_loss = 0.88379339, grad/param norm = 2.6115e-01, time/batch = 18.9306s	
14370/22750 (epoch 31.582), train_loss = 0.73131436, grad/param norm = 1.9420e-01, time/batch = 18.1791s	
14371/22750 (epoch 31.585), train_loss = 0.71115859, grad/param norm = 2.2339e-01, time/batch = 17.7569s	
14372/22750 (epoch 31.587), train_loss = 0.71620830, grad/param norm = 1.9177e-01, time/batch = 16.1081s	
14373/22750 (epoch 31.589), train_loss = 0.61937645, grad/param norm = 1.7649e-01, time/batch = 15.7827s	
14374/22750 (epoch 31.591), train_loss = 0.78880786, grad/param norm = 2.0047e-01, time/batch = 16.2288s	
14375/22750 (epoch 31.593), train_loss = 0.93767702, grad/param norm = 2.5350e-01, time/batch = 16.4996s	
14376/22750 (epoch 31.596), train_loss = 0.94144914, grad/param norm = 2.5000e-01, time/batch = 19.2596s	
14377/22750 (epoch 31.598), train_loss = 0.95051243, grad/param norm = 2.4111e-01, time/batch = 16.7557s	
14378/22750 (epoch 31.600), train_loss = 0.96087375, grad/param norm = 2.5768e-01, time/batch = 18.2632s	
14379/22750 (epoch 31.602), train_loss = 0.74924970, grad/param norm = 1.9792e-01, time/batch = 16.9222s	
14380/22750 (epoch 31.604), train_loss = 0.76725323, grad/param norm = 2.1920e-01, time/batch = 20.1629s	
14381/22750 (epoch 31.607), train_loss = 0.70996961, grad/param norm = 1.9031e-01, time/batch = 19.2506s	
14382/22750 (epoch 31.609), train_loss = 0.65722342, grad/param norm = 1.7974e-01, time/batch = 18.0780s	
14383/22750 (epoch 31.611), train_loss = 0.76005179, grad/param norm = 1.9949e-01, time/batch = 19.9059s	
14384/22750 (epoch 31.613), train_loss = 0.74833271, grad/param norm = 1.9409e-01, time/batch = 18.7416s	
14385/22750 (epoch 31.615), train_loss = 0.76412027, grad/param norm = 1.9258e-01, time/batch = 19.2790s	
14386/22750 (epoch 31.618), train_loss = 0.78650205, grad/param norm = 2.1769e-01, time/batch = 19.2528s	
14387/22750 (epoch 31.620), train_loss = 0.78061823, grad/param norm = 2.3705e-01, time/batch = 19.6660s	
14388/22750 (epoch 31.622), train_loss = 0.64391759, grad/param norm = 1.7840e-01, time/batch = 17.8494s	
14389/22750 (epoch 31.624), train_loss = 0.77557555, grad/param norm = 2.1707e-01, time/batch = 19.7420s	
14390/22750 (epoch 31.626), train_loss = 0.65399701, grad/param norm = 1.9675e-01, time/batch = 19.0156s	
14391/22750 (epoch 31.629), train_loss = 0.75481075, grad/param norm = 2.0945e-01, time/batch = 16.9898s	
14392/22750 (epoch 31.631), train_loss = 0.79405818, grad/param norm = 1.9254e-01, time/batch = 19.5727s	
14393/22750 (epoch 31.633), train_loss = 0.66996572, grad/param norm = 1.9766e-01, time/batch = 17.7385s	
14394/22750 (epoch 31.635), train_loss = 0.78076381, grad/param norm = 2.0328e-01, time/batch = 19.4320s	
14395/22750 (epoch 31.637), train_loss = 0.84094780, grad/param norm = 2.3905e-01, time/batch = 16.6613s	
14396/22750 (epoch 31.640), train_loss = 0.87932590, grad/param norm = 2.2409e-01, time/batch = 16.8518s	
14397/22750 (epoch 31.642), train_loss = 0.92203109, grad/param norm = 2.2708e-01, time/batch = 17.5895s	
14398/22750 (epoch 31.644), train_loss = 0.80542949, grad/param norm = 2.3950e-01, time/batch = 17.5855s	
14399/22750 (epoch 31.646), train_loss = 0.84856171, grad/param norm = 2.3098e-01, time/batch = 16.8372s	
14400/22750 (epoch 31.648), train_loss = 0.85928621, grad/param norm = 2.2819e-01, time/batch = 17.3190s	
14401/22750 (epoch 31.651), train_loss = 0.87337395, grad/param norm = 2.2564e-01, time/batch = 18.9214s	
14402/22750 (epoch 31.653), train_loss = 0.88250107, grad/param norm = 2.0417e-01, time/batch = 18.4230s	
14403/22750 (epoch 31.655), train_loss = 0.82910353, grad/param norm = 2.0102e-01, time/batch = 18.5366s	
14404/22750 (epoch 31.657), train_loss = 0.97916199, grad/param norm = 2.5521e-01, time/batch = 18.7890s	
14405/22750 (epoch 31.659), train_loss = 0.99168123, grad/param norm = 2.3645e-01, time/batch = 19.3758s	
14406/22750 (epoch 31.662), train_loss = 0.98489610, grad/param norm = 2.6726e-01, time/batch = 18.7579s	
14407/22750 (epoch 31.664), train_loss = 0.87728462, grad/param norm = 2.2151e-01, time/batch = 17.4146s	
14408/22750 (epoch 31.666), train_loss = 0.69261530, grad/param norm = 2.0342e-01, time/batch = 18.8156s	
14409/22750 (epoch 31.668), train_loss = 0.82863190, grad/param norm = 2.2421e-01, time/batch = 18.9949s	
14410/22750 (epoch 31.670), train_loss = 0.79868764, grad/param norm = 2.1506e-01, time/batch = 18.9949s	
14411/22750 (epoch 31.673), train_loss = 1.00982075, grad/param norm = 2.6911e-01, time/batch = 19.1513s	
14412/22750 (epoch 31.675), train_loss = 1.13027187, grad/param norm = 2.6213e-01, time/batch = 19.6948s	
14413/22750 (epoch 31.677), train_loss = 1.00978151, grad/param norm = 2.3698e-01, time/batch = 20.4587s	
14414/22750 (epoch 31.679), train_loss = 0.99164694, grad/param norm = 2.7882e-01, time/batch = 19.7526s	
14415/22750 (epoch 31.681), train_loss = 0.96295072, grad/param norm = 2.3510e-01, time/batch = 18.8272s	
14416/22750 (epoch 31.684), train_loss = 1.02615727, grad/param norm = 2.5218e-01, time/batch = 18.6838s	
14417/22750 (epoch 31.686), train_loss = 1.02004726, grad/param norm = 2.6386e-01, time/batch = 17.6846s	
14418/22750 (epoch 31.688), train_loss = 0.98667244, grad/param norm = 2.4207e-01, time/batch = 19.9090s	
14419/22750 (epoch 31.690), train_loss = 0.96353012, grad/param norm = 2.4005e-01, time/batch = 19.2613s	
14420/22750 (epoch 31.692), train_loss = 0.96706508, grad/param norm = 2.3800e-01, time/batch = 17.4301s	
14421/22750 (epoch 31.695), train_loss = 0.85498396, grad/param norm = 2.1711e-01, time/batch = 18.9737s	
14422/22750 (epoch 31.697), train_loss = 0.87610041, grad/param norm = 2.2301e-01, time/batch = 19.0374s	
14423/22750 (epoch 31.699), train_loss = 0.79405117, grad/param norm = 1.8979e-01, time/batch = 17.9442s	
14424/22750 (epoch 31.701), train_loss = 0.71367643, grad/param norm = 2.2237e-01, time/batch = 16.2126s	
14425/22750 (epoch 31.703), train_loss = 0.79157357, grad/param norm = 2.0574e-01, time/batch = 16.6115s	
14426/22750 (epoch 31.705), train_loss = 0.76947778, grad/param norm = 1.8989e-01, time/batch = 17.1468s	
14427/22750 (epoch 31.708), train_loss = 0.85532763, grad/param norm = 2.4008e-01, time/batch = 15.9888s	
14428/22750 (epoch 31.710), train_loss = 0.72507790, grad/param norm = 2.0872e-01, time/batch = 17.1761s	
14429/22750 (epoch 31.712), train_loss = 0.69680631, grad/param norm = 1.8724e-01, time/batch = 16.2786s	
14430/22750 (epoch 31.714), train_loss = 0.69549226, grad/param norm = 1.9763e-01, time/batch = 18.7452s	
14431/22750 (epoch 31.716), train_loss = 0.70996557, grad/param norm = 2.0014e-01, time/batch = 19.6061s	
14432/22750 (epoch 31.719), train_loss = 0.78544351, grad/param norm = 2.3441e-01, time/batch = 19.9431s	
14433/22750 (epoch 31.721), train_loss = 0.90415766, grad/param norm = 2.0893e-01, time/batch = 18.3426s	
14434/22750 (epoch 31.723), train_loss = 0.91420852, grad/param norm = 2.4045e-01, time/batch = 18.4998s	
14435/22750 (epoch 31.725), train_loss = 0.79387492, grad/param norm = 2.5595e-01, time/batch = 16.9956s	
14436/22750 (epoch 31.727), train_loss = 0.77866393, grad/param norm = 2.1479e-01, time/batch = 19.2700s	
14437/22750 (epoch 31.730), train_loss = 0.78823521, grad/param norm = 2.1560e-01, time/batch = 17.9209s	
14438/22750 (epoch 31.732), train_loss = 0.74564174, grad/param norm = 2.0645e-01, time/batch = 20.0739s	
14439/22750 (epoch 31.734), train_loss = 0.66247178, grad/param norm = 1.7154e-01, time/batch = 16.3830s	
14440/22750 (epoch 31.736), train_loss = 0.78419960, grad/param norm = 2.3155e-01, time/batch = 18.1096s	
14441/22750 (epoch 31.738), train_loss = 0.86704120, grad/param norm = 2.2734e-01, time/batch = 20.1885s	
14442/22750 (epoch 31.741), train_loss = 0.93244265, grad/param norm = 2.1367e-01, time/batch = 19.2370s	
14443/22750 (epoch 31.743), train_loss = 0.86810218, grad/param norm = 2.1656e-01, time/batch = 18.5885s	
14444/22750 (epoch 31.745), train_loss = 0.70913538, grad/param norm = 2.0117e-01, time/batch = 18.4273s	
14445/22750 (epoch 31.747), train_loss = 0.81156651, grad/param norm = 2.0734e-01, time/batch = 17.1717s	
14446/22750 (epoch 31.749), train_loss = 0.93562228, grad/param norm = 2.9484e-01, time/batch = 19.4548s	
14447/22750 (epoch 31.752), train_loss = 0.83779303, grad/param norm = 2.2304e-01, time/batch = 32.8959s	
14448/22750 (epoch 31.754), train_loss = 0.84431894, grad/param norm = 2.4606e-01, time/batch = 19.0000s	
14449/22750 (epoch 31.756), train_loss = 0.77874784, grad/param norm = 2.3791e-01, time/batch = 16.0873s	
14450/22750 (epoch 31.758), train_loss = 0.73761990, grad/param norm = 2.0885e-01, time/batch = 17.3352s	
14451/22750 (epoch 31.760), train_loss = 0.76565117, grad/param norm = 2.1374e-01, time/batch = 15.2045s	
14452/22750 (epoch 31.763), train_loss = 0.83387895, grad/param norm = 2.4552e-01, time/batch = 15.4560s	
14453/22750 (epoch 31.765), train_loss = 0.80646677, grad/param norm = 2.2550e-01, time/batch = 15.2114s	
14454/22750 (epoch 31.767), train_loss = 0.85670004, grad/param norm = 2.2747e-01, time/batch = 15.1275s	
14455/22750 (epoch 31.769), train_loss = 0.97924631, grad/param norm = 2.7480e-01, time/batch = 15.5203s	
14456/22750 (epoch 31.771), train_loss = 1.01749625, grad/param norm = 2.5781e-01, time/batch = 15.5252s	
14457/22750 (epoch 31.774), train_loss = 0.79715679, grad/param norm = 2.4105e-01, time/batch = 15.6718s	
14458/22750 (epoch 31.776), train_loss = 0.92196308, grad/param norm = 2.1248e-01, time/batch = 14.8885s	
14459/22750 (epoch 31.778), train_loss = 0.99553838, grad/param norm = 2.8250e-01, time/batch = 15.2954s	
14460/22750 (epoch 31.780), train_loss = 0.85593459, grad/param norm = 2.2063e-01, time/batch = 15.3009s	
14461/22750 (epoch 31.782), train_loss = 1.01551640, grad/param norm = 2.2993e-01, time/batch = 15.2257s	
14462/22750 (epoch 31.785), train_loss = 0.80295579, grad/param norm = 2.2580e-01, time/batch = 14.8994s	
14463/22750 (epoch 31.787), train_loss = 0.73019225, grad/param norm = 2.3037e-01, time/batch = 14.9717s	
14464/22750 (epoch 31.789), train_loss = 0.80229550, grad/param norm = 2.0151e-01, time/batch = 15.2803s	
14465/22750 (epoch 31.791), train_loss = 0.77754301, grad/param norm = 1.9971e-01, time/batch = 15.1125s	
14466/22750 (epoch 31.793), train_loss = 0.77198173, grad/param norm = 2.5850e-01, time/batch = 15.2228s	
14467/22750 (epoch 31.796), train_loss = 0.70128721, grad/param norm = 2.0794e-01, time/batch = 15.2065s	
14468/22750 (epoch 31.798), train_loss = 0.76441920, grad/param norm = 2.1610e-01, time/batch = 15.5395s	
14469/22750 (epoch 31.800), train_loss = 0.74749735, grad/param norm = 2.1443e-01, time/batch = 15.0534s	
14470/22750 (epoch 31.802), train_loss = 0.71249948, grad/param norm = 2.3188e-01, time/batch = 14.9163s	
14471/22750 (epoch 31.804), train_loss = 0.92141967, grad/param norm = 2.4716e-01, time/batch = 16.0349s	
14472/22750 (epoch 31.807), train_loss = 0.87889238, grad/param norm = 2.2994e-01, time/batch = 15.7093s	
14473/22750 (epoch 31.809), train_loss = 0.94636326, grad/param norm = 2.3131e-01, time/batch = 15.0701s	
14474/22750 (epoch 31.811), train_loss = 0.81296651, grad/param norm = 2.1632e-01, time/batch = 15.3779s	
14475/22750 (epoch 31.813), train_loss = 0.83920278, grad/param norm = 2.0731e-01, time/batch = 15.2137s	
14476/22750 (epoch 31.815), train_loss = 0.97542310, grad/param norm = 2.2452e-01, time/batch = 16.0982s	
14477/22750 (epoch 31.818), train_loss = 0.92249693, grad/param norm = 2.0921e-01, time/batch = 15.6085s	
14478/22750 (epoch 31.820), train_loss = 1.06302397, grad/param norm = 2.6187e-01, time/batch = 15.9296s	
14479/22750 (epoch 31.822), train_loss = 0.86861018, grad/param norm = 2.5164e-01, time/batch = 15.1162s	
14480/22750 (epoch 31.824), train_loss = 0.72029529, grad/param norm = 2.0947e-01, time/batch = 15.2869s	
14481/22750 (epoch 31.826), train_loss = 0.84847766, grad/param norm = 2.3941e-01, time/batch = 15.3062s	
14482/22750 (epoch 31.829), train_loss = 0.93886139, grad/param norm = 2.3267e-01, time/batch = 14.9956s	
14483/22750 (epoch 31.831), train_loss = 0.92587620, grad/param norm = 2.3336e-01, time/batch = 14.9929s	
14484/22750 (epoch 31.833), train_loss = 0.84829298, grad/param norm = 2.4543e-01, time/batch = 15.7670s	
14485/22750 (epoch 31.835), train_loss = 0.73762966, grad/param norm = 2.1532e-01, time/batch = 15.3712s	
14486/22750 (epoch 31.837), train_loss = 0.81247068, grad/param norm = 2.1829e-01, time/batch = 15.1963s	
14487/22750 (epoch 31.840), train_loss = 0.74309393, grad/param norm = 2.0162e-01, time/batch = 15.1998s	
14488/22750 (epoch 31.842), train_loss = 0.78545329, grad/param norm = 2.2666e-01, time/batch = 15.1961s	
14489/22750 (epoch 31.844), train_loss = 0.86993694, grad/param norm = 2.2976e-01, time/batch = 15.2888s	
14490/22750 (epoch 31.846), train_loss = 0.86616303, grad/param norm = 2.1009e-01, time/batch = 15.2012s	
14491/22750 (epoch 31.848), train_loss = 0.77422032, grad/param norm = 1.8787e-01, time/batch = 15.2848s	
14492/22750 (epoch 31.851), train_loss = 0.74306038, grad/param norm = 2.0961e-01, time/batch = 14.9108s	
14493/22750 (epoch 31.853), train_loss = 0.89798805, grad/param norm = 2.1068e-01, time/batch = 15.6324s	
14494/22750 (epoch 31.855), train_loss = 0.76678194, grad/param norm = 1.8947e-01, time/batch = 15.2169s	
14495/22750 (epoch 31.857), train_loss = 0.88877615, grad/param norm = 2.3014e-01, time/batch = 15.3146s	
14496/22750 (epoch 31.859), train_loss = 0.85654097, grad/param norm = 2.1702e-01, time/batch = 15.2807s	
14497/22750 (epoch 31.862), train_loss = 1.00549669, grad/param norm = 2.3036e-01, time/batch = 15.0533s	
14498/22750 (epoch 31.864), train_loss = 0.84006887, grad/param norm = 2.1462e-01, time/batch = 15.0554s	
14499/22750 (epoch 31.866), train_loss = 0.88365238, grad/param norm = 1.9609e-01, time/batch = 15.2085s	
14500/22750 (epoch 31.868), train_loss = 0.74570132, grad/param norm = 1.8807e-01, time/batch = 15.0326s	
14501/22750 (epoch 31.870), train_loss = 0.70517311, grad/param norm = 2.1989e-01, time/batch = 15.2003s	
14502/22750 (epoch 31.873), train_loss = 0.80395782, grad/param norm = 2.0464e-01, time/batch = 15.2847s	
14503/22750 (epoch 31.875), train_loss = 0.89228760, grad/param norm = 2.1817e-01, time/batch = 15.7853s	
14504/22750 (epoch 31.877), train_loss = 0.76078301, grad/param norm = 2.5161e-01, time/batch = 15.4488s	
14505/22750 (epoch 31.879), train_loss = 0.93756219, grad/param norm = 2.2708e-01, time/batch = 14.8308s	
14506/22750 (epoch 31.881), train_loss = 0.87971425, grad/param norm = 2.2673e-01, time/batch = 14.9901s	
14507/22750 (epoch 31.884), train_loss = 0.76983507, grad/param norm = 2.0475e-01, time/batch = 15.3744s	
14508/22750 (epoch 31.886), train_loss = 0.86654616, grad/param norm = 2.1677e-01, time/batch = 15.2978s	
14509/22750 (epoch 31.888), train_loss = 0.89811290, grad/param norm = 2.0076e-01, time/batch = 15.4450s	
14510/22750 (epoch 31.890), train_loss = 0.90766472, grad/param norm = 2.5281e-01, time/batch = 15.3522s	
14511/22750 (epoch 31.892), train_loss = 1.12976863, grad/param norm = 2.6585e-01, time/batch = 15.7079s	
14512/22750 (epoch 31.895), train_loss = 0.81237421, grad/param norm = 2.6290e-01, time/batch = 15.2970s	
14513/22750 (epoch 31.897), train_loss = 0.91713685, grad/param norm = 2.2995e-01, time/batch = 15.4469s	
14514/22750 (epoch 31.899), train_loss = 0.88000624, grad/param norm = 2.3298e-01, time/batch = 15.8407s	
14515/22750 (epoch 31.901), train_loss = 0.91087110, grad/param norm = 2.3631e-01, time/batch = 15.9429s	
14516/22750 (epoch 31.903), train_loss = 0.83020404, grad/param norm = 2.4333e-01, time/batch = 14.9880s	
14517/22750 (epoch 31.905), train_loss = 0.90455288, grad/param norm = 2.0709e-01, time/batch = 15.0630s	
14518/22750 (epoch 31.908), train_loss = 0.73434881, grad/param norm = 2.1940e-01, time/batch = 15.2736s	
14519/22750 (epoch 31.910), train_loss = 0.65738808, grad/param norm = 1.9469e-01, time/batch = 15.6067s	
14520/22750 (epoch 31.912), train_loss = 0.79485809, grad/param norm = 1.9216e-01, time/batch = 14.9753s	
14521/22750 (epoch 31.914), train_loss = 0.83122353, grad/param norm = 1.9642e-01, time/batch = 15.3687s	
14522/22750 (epoch 31.916), train_loss = 0.67040886, grad/param norm = 1.9322e-01, time/batch = 15.1303s	
14523/22750 (epoch 31.919), train_loss = 0.80031905, grad/param norm = 2.0807e-01, time/batch = 15.7642s	
14524/22750 (epoch 31.921), train_loss = 0.64162655, grad/param norm = 1.9704e-01, time/batch = 15.3739s	
14525/22750 (epoch 31.923), train_loss = 0.74952408, grad/param norm = 1.9952e-01, time/batch = 15.3120s	
14526/22750 (epoch 31.925), train_loss = 0.80553565, grad/param norm = 1.9859e-01, time/batch = 15.0594s	
14527/22750 (epoch 31.927), train_loss = 0.65858049, grad/param norm = 2.0853e-01, time/batch = 15.3881s	
14528/22750 (epoch 31.930), train_loss = 0.64458362, grad/param norm = 2.0168e-01, time/batch = 14.9888s	
14529/22750 (epoch 31.932), train_loss = 0.82812698, grad/param norm = 2.4141e-01, time/batch = 15.2851s	
14530/22750 (epoch 31.934), train_loss = 0.67186778, grad/param norm = 1.7780e-01, time/batch = 18.3319s	
14531/22750 (epoch 31.936), train_loss = 0.94029021, grad/param norm = 2.3742e-01, time/batch = 20.3191s	
14532/22750 (epoch 31.938), train_loss = 0.92067231, grad/param norm = 2.1452e-01, time/batch = 18.6638s	
14533/22750 (epoch 31.941), train_loss = 0.97735250, grad/param norm = 2.4338e-01, time/batch = 18.6697s	
14534/22750 (epoch 31.943), train_loss = 0.85719608, grad/param norm = 2.2797e-01, time/batch = 18.4133s	
14535/22750 (epoch 31.945), train_loss = 0.83224282, grad/param norm = 2.1020e-01, time/batch = 18.7482s	
14536/22750 (epoch 31.947), train_loss = 0.78586164, grad/param norm = 2.2848e-01, time/batch = 20.1115s	
14537/22750 (epoch 31.949), train_loss = 0.75949503, grad/param norm = 2.4846e-01, time/batch = 19.3679s	
14538/22750 (epoch 31.952), train_loss = 0.78822703, grad/param norm = 2.1111e-01, time/batch = 19.0877s	
14539/22750 (epoch 31.954), train_loss = 0.73971327, grad/param norm = 2.1439e-01, time/batch = 18.9295s	
14540/22750 (epoch 31.956), train_loss = 0.86771734, grad/param norm = 2.2644e-01, time/batch = 20.6372s	
14541/22750 (epoch 31.958), train_loss = 0.74271699, grad/param norm = 1.7536e-01, time/batch = 18.1736s	
14542/22750 (epoch 31.960), train_loss = 0.72356241, grad/param norm = 1.9633e-01, time/batch = 20.0143s	
14543/22750 (epoch 31.963), train_loss = 0.84081070, grad/param norm = 2.1072e-01, time/batch = 21.5907s	
14544/22750 (epoch 31.965), train_loss = 0.89586385, grad/param norm = 2.1470e-01, time/batch = 22.8116s	
14545/22750 (epoch 31.967), train_loss = 0.87476539, grad/param norm = 2.1606e-01, time/batch = 23.7403s	
14546/22750 (epoch 31.969), train_loss = 0.79097339, grad/param norm = 2.1402e-01, time/batch = 22.2090s	
14547/22750 (epoch 31.971), train_loss = 0.73971805, grad/param norm = 2.0159e-01, time/batch = 23.5426s	
14548/22750 (epoch 31.974), train_loss = 0.76855136, grad/param norm = 2.2325e-01, time/batch = 19.8069s	
14549/22750 (epoch 31.976), train_loss = 0.79735506, grad/param norm = 2.2225e-01, time/batch = 22.2960s	
14550/22750 (epoch 31.978), train_loss = 0.77829266, grad/param norm = 2.1719e-01, time/batch = 23.6957s	
14551/22750 (epoch 31.980), train_loss = 0.96247307, grad/param norm = 3.2655e-01, time/batch = 24.3039s	
14552/22750 (epoch 31.982), train_loss = 0.75870922, grad/param norm = 1.9849e-01, time/batch = 22.9048s	
14553/22750 (epoch 31.985), train_loss = 0.95605572, grad/param norm = 2.4023e-01, time/batch = 22.4718s	
14554/22750 (epoch 31.987), train_loss = 0.67985474, grad/param norm = 2.0439e-01, time/batch = 24.5941s	
14555/22750 (epoch 31.989), train_loss = 0.77104880, grad/param norm = 2.3596e-01, time/batch = 21.7163s	
14556/22750 (epoch 31.991), train_loss = 0.83793951, grad/param norm = 2.2215e-01, time/batch = 19.4386s	
14557/22750 (epoch 31.993), train_loss = 0.83264885, grad/param norm = 2.5261e-01, time/batch = 23.3974s	
14558/22750 (epoch 31.996), train_loss = 0.73992837, grad/param norm = 2.4359e-01, time/batch = 18.7487s	
14559/22750 (epoch 31.998), train_loss = 0.94241133, grad/param norm = 2.5517e-01, time/batch = 20.0926s	
decayed learning rate by a factor 0.97 to 0.00099261282868397	
14560/22750 (epoch 32.000), train_loss = 0.81954567, grad/param norm = 2.0374e-01, time/batch = 29.2061s	
14561/22750 (epoch 32.002), train_loss = 0.99283332, grad/param norm = 2.4854e-01, time/batch = 18.0129s	
14562/22750 (epoch 32.004), train_loss = 0.79457136, grad/param norm = 2.2498e-01, time/batch = 18.7397s	
14563/22750 (epoch 32.007), train_loss = 0.78461975, grad/param norm = 2.3044e-01, time/batch = 17.9816s	
14564/22750 (epoch 32.009), train_loss = 0.96748776, grad/param norm = 2.6910e-01, time/batch = 18.6850s	
14565/22750 (epoch 32.011), train_loss = 1.07282796, grad/param norm = 2.6868e-01, time/batch = 17.6532s	
14566/22750 (epoch 32.013), train_loss = 0.94941144, grad/param norm = 2.3807e-01, time/batch = 19.9226s	
14567/22750 (epoch 32.015), train_loss = 0.85738943, grad/param norm = 2.2512e-01, time/batch = 19.1093s	
14568/22750 (epoch 32.018), train_loss = 0.92687992, grad/param norm = 2.4729e-01, time/batch = 17.2666s	
14569/22750 (epoch 32.020), train_loss = 0.97065955, grad/param norm = 2.5873e-01, time/batch = 18.5993s	
14570/22750 (epoch 32.022), train_loss = 0.82663121, grad/param norm = 2.1222e-01, time/batch = 19.8552s	
14571/22750 (epoch 32.024), train_loss = 0.84952090, grad/param norm = 2.2821e-01, time/batch = 18.8255s	
14572/22750 (epoch 32.026), train_loss = 0.88809664, grad/param norm = 2.6383e-01, time/batch = 18.3251s	
14573/22750 (epoch 32.029), train_loss = 0.70381724, grad/param norm = 2.3123e-01, time/batch = 17.5771s	
14574/22750 (epoch 32.031), train_loss = 1.05240118, grad/param norm = 2.3087e-01, time/batch = 19.4860s	
14575/22750 (epoch 32.033), train_loss = 0.83456642, grad/param norm = 2.3588e-01, time/batch = 19.1685s	
14576/22750 (epoch 32.035), train_loss = 0.89894095, grad/param norm = 2.3417e-01, time/batch = 19.3556s	
14577/22750 (epoch 32.037), train_loss = 0.93297676, grad/param norm = 2.1305e-01, time/batch = 15.2803s	
14578/22750 (epoch 32.040), train_loss = 0.83122305, grad/param norm = 2.0158e-01, time/batch = 15.6746s	
14579/22750 (epoch 32.042), train_loss = 0.86915809, grad/param norm = 2.2216e-01, time/batch = 18.0183s	
14580/22750 (epoch 32.044), train_loss = 0.82974886, grad/param norm = 2.2504e-01, time/batch = 17.2243s	
14581/22750 (epoch 32.046), train_loss = 0.92615550, grad/param norm = 2.5787e-01, time/batch = 16.8385s	
14582/22750 (epoch 32.048), train_loss = 0.83381248, grad/param norm = 1.9163e-01, time/batch = 17.5955s	
14583/22750 (epoch 32.051), train_loss = 0.85380404, grad/param norm = 2.4993e-01, time/batch = 18.2636s	
14584/22750 (epoch 32.053), train_loss = 0.80943735, grad/param norm = 1.8942e-01, time/batch = 18.0819s	
14585/22750 (epoch 32.055), train_loss = 0.69776685, grad/param norm = 1.8591e-01, time/batch = 16.6150s	
14586/22750 (epoch 32.057), train_loss = 1.00259369, grad/param norm = 2.5155e-01, time/batch = 16.9370s	
14587/22750 (epoch 32.059), train_loss = 0.62976526, grad/param norm = 2.0810e-01, time/batch = 19.6108s	
14588/22750 (epoch 32.062), train_loss = 0.71353756, grad/param norm = 2.0581e-01, time/batch = 18.3862s	
14589/22750 (epoch 32.064), train_loss = 0.92072205, grad/param norm = 2.1237e-01, time/batch = 18.8999s	
14590/22750 (epoch 32.066), train_loss = 0.74098467, grad/param norm = 1.9894e-01, time/batch = 18.6366s	
14591/22750 (epoch 32.068), train_loss = 0.73873444, grad/param norm = 1.7877e-01, time/batch = 18.0901s	
14592/22750 (epoch 32.070), train_loss = 0.63847122, grad/param norm = 1.8037e-01, time/batch = 19.0809s	
14593/22750 (epoch 32.073), train_loss = 0.77320849, grad/param norm = 2.2835e-01, time/batch = 18.7614s	
14594/22750 (epoch 32.075), train_loss = 0.82329020, grad/param norm = 1.9453e-01, time/batch = 18.1762s	
14595/22750 (epoch 32.077), train_loss = 0.61811207, grad/param norm = 2.3924e-01, time/batch = 15.8676s	
14596/22750 (epoch 32.079), train_loss = 0.81536039, grad/param norm = 2.6116e-01, time/batch = 17.7727s	
14597/22750 (epoch 32.081), train_loss = 0.77427128, grad/param norm = 2.0680e-01, time/batch = 19.6118s	
14598/22750 (epoch 32.084), train_loss = 0.77914712, grad/param norm = 2.0710e-01, time/batch = 18.3353s	
14599/22750 (epoch 32.086), train_loss = 0.81948482, grad/param norm = 2.1053e-01, time/batch = 19.2513s	
14600/22750 (epoch 32.088), train_loss = 0.75827451, grad/param norm = 2.1540e-01, time/batch = 17.9211s	
14601/22750 (epoch 32.090), train_loss = 0.78610697, grad/param norm = 2.0990e-01, time/batch = 16.8251s	
14602/22750 (epoch 32.092), train_loss = 0.90122526, grad/param norm = 2.2166e-01, time/batch = 16.4328s	
14603/22750 (epoch 32.095), train_loss = 0.75007183, grad/param norm = 2.1732e-01, time/batch = 16.2681s	
14604/22750 (epoch 32.097), train_loss = 0.79295465, grad/param norm = 1.8498e-01, time/batch = 17.0360s	
14605/22750 (epoch 32.099), train_loss = 0.77306623, grad/param norm = 2.0851e-01, time/batch = 16.4164s	
14606/22750 (epoch 32.101), train_loss = 0.67304162, grad/param norm = 1.7959e-01, time/batch = 16.0067s	
14607/22750 (epoch 32.103), train_loss = 0.88388080, grad/param norm = 2.2577e-01, time/batch = 16.8709s	
14608/22750 (epoch 32.105), train_loss = 0.96122951, grad/param norm = 2.6662e-01, time/batch = 16.5984s	
14609/22750 (epoch 32.108), train_loss = 0.83819224, grad/param norm = 2.4094e-01, time/batch = 16.4887s	
14610/22750 (epoch 32.110), train_loss = 0.94178205, grad/param norm = 2.0845e-01, time/batch = 16.3535s	
14611/22750 (epoch 32.112), train_loss = 0.68747348, grad/param norm = 1.8562e-01, time/batch = 17.0134s	
14612/22750 (epoch 32.114), train_loss = 0.61003727, grad/param norm = 1.8053e-01, time/batch = 17.5846s	
14613/22750 (epoch 32.116), train_loss = 0.80331248, grad/param norm = 1.9077e-01, time/batch = 17.9385s	
14614/22750 (epoch 32.119), train_loss = 0.76047228, grad/param norm = 1.8779e-01, time/batch = 18.3667s	
14615/22750 (epoch 32.121), train_loss = 0.80245591, grad/param norm = 2.7101e-01, time/batch = 18.1922s	
14616/22750 (epoch 32.123), train_loss = 0.71365509, grad/param norm = 2.1797e-01, time/batch = 20.4423s	
14617/22750 (epoch 32.125), train_loss = 0.93558781, grad/param norm = 2.0085e-01, time/batch = 19.8167s	
14618/22750 (epoch 32.127), train_loss = 0.78749337, grad/param norm = 2.1985e-01, time/batch = 12.2783s	
14619/22750 (epoch 32.130), train_loss = 0.78889616, grad/param norm = 1.8740e-01, time/batch = 0.7283s	
14620/22750 (epoch 32.132), train_loss = 0.75127680, grad/param norm = 2.2656e-01, time/batch = 0.7245s	
14621/22750 (epoch 32.134), train_loss = 0.77258476, grad/param norm = 2.0041e-01, time/batch = 0.7297s	
14622/22750 (epoch 32.136), train_loss = 0.64920586, grad/param norm = 2.1363e-01, time/batch = 0.7296s	
14623/22750 (epoch 32.138), train_loss = 0.87396681, grad/param norm = 2.2591e-01, time/batch = 0.7318s	
14624/22750 (epoch 32.141), train_loss = 0.82700039, grad/param norm = 2.0717e-01, time/batch = 0.7284s	
14625/22750 (epoch 32.143), train_loss = 0.72679605, grad/param norm = 1.8977e-01, time/batch = 0.8865s	
14626/22750 (epoch 32.145), train_loss = 0.93472487, grad/param norm = 2.1999e-01, time/batch = 1.0556s	
14627/22750 (epoch 32.147), train_loss = 0.97148403, grad/param norm = 2.2678e-01, time/batch = 1.0556s	
14628/22750 (epoch 32.149), train_loss = 0.83371294, grad/param norm = 2.0651e-01, time/batch = 1.0578s	
14629/22750 (epoch 32.152), train_loss = 0.81602790, grad/param norm = 2.0697e-01, time/batch = 1.0551s	
14630/22750 (epoch 32.154), train_loss = 0.73710980, grad/param norm = 2.0472e-01, time/batch = 1.7770s	
14631/22750 (epoch 32.156), train_loss = 0.73181951, grad/param norm = 2.0021e-01, time/batch = 1.9994s	
14632/22750 (epoch 32.158), train_loss = 0.73424458, grad/param norm = 2.2548e-01, time/batch = 6.0290s	
14633/22750 (epoch 32.160), train_loss = 0.81862709, grad/param norm = 2.3609e-01, time/batch = 15.5226s	
14634/22750 (epoch 32.163), train_loss = 0.96901713, grad/param norm = 2.4054e-01, time/batch = 15.2790s	
14635/22750 (epoch 32.165), train_loss = 0.86663883, grad/param norm = 2.1524e-01, time/batch = 15.6845s	
14636/22750 (epoch 32.167), train_loss = 0.77223523, grad/param norm = 2.3295e-01, time/batch = 15.1062s	
14637/22750 (epoch 32.169), train_loss = 0.82774408, grad/param norm = 2.5745e-01, time/batch = 15.5855s	
14638/22750 (epoch 32.171), train_loss = 0.68901959, grad/param norm = 1.8508e-01, time/batch = 15.0194s	
14639/22750 (epoch 32.174), train_loss = 0.69244241, grad/param norm = 2.1284e-01, time/batch = 15.6755s	
14640/22750 (epoch 32.176), train_loss = 0.71872424, grad/param norm = 2.1566e-01, time/batch = 15.0232s	
14641/22750 (epoch 32.178), train_loss = 0.75077224, grad/param norm = 2.1656e-01, time/batch = 15.1906s	
14642/22750 (epoch 32.180), train_loss = 0.94181897, grad/param norm = 3.1966e-01, time/batch = 15.0281s	
14643/22750 (epoch 32.182), train_loss = 0.89334760, grad/param norm = 2.3889e-01, time/batch = 16.1865s	
14644/22750 (epoch 32.185), train_loss = 0.92350065, grad/param norm = 2.2350e-01, time/batch = 15.5987s	
14645/22750 (epoch 32.187), train_loss = 0.69838355, grad/param norm = 2.0076e-01, time/batch = 15.1884s	
14646/22750 (epoch 32.189), train_loss = 0.73728826, grad/param norm = 2.4484e-01, time/batch = 15.1114s	
14647/22750 (epoch 32.191), train_loss = 0.74603629, grad/param norm = 2.2132e-01, time/batch = 15.5099s	
14648/22750 (epoch 32.193), train_loss = 0.88572064, grad/param norm = 2.2900e-01, time/batch = 14.9494s	
14649/22750 (epoch 32.196), train_loss = 0.78368906, grad/param norm = 2.1850e-01, time/batch = 15.9325s	
14650/22750 (epoch 32.198), train_loss = 0.60565822, grad/param norm = 2.0174e-01, time/batch = 15.3614s	
14651/22750 (epoch 32.200), train_loss = 0.80362271, grad/param norm = 1.9883e-01, time/batch = 15.6002s	
14652/22750 (epoch 32.202), train_loss = 0.87215703, grad/param norm = 2.5170e-01, time/batch = 15.4405s	
14653/22750 (epoch 32.204), train_loss = 0.82378220, grad/param norm = 2.0365e-01, time/batch = 15.5199s	
14654/22750 (epoch 32.207), train_loss = 0.80868302, grad/param norm = 2.1282e-01, time/batch = 15.7708s	
14655/22750 (epoch 32.209), train_loss = 0.75488158, grad/param norm = 2.2140e-01, time/batch = 15.8577s	
14656/22750 (epoch 32.211), train_loss = 0.71856617, grad/param norm = 2.0439e-01, time/batch = 15.5926s	
14657/22750 (epoch 32.213), train_loss = 0.62608430, grad/param norm = 1.9506e-01, time/batch = 15.6779s	
14658/22750 (epoch 32.215), train_loss = 0.60840551, grad/param norm = 1.9035e-01, time/batch = 16.2597s	
14659/22750 (epoch 32.218), train_loss = 0.70699094, grad/param norm = 2.2601e-01, time/batch = 15.6072s	
14660/22750 (epoch 32.220), train_loss = 0.65747415, grad/param norm = 2.0173e-01, time/batch = 15.2785s	
14661/22750 (epoch 32.222), train_loss = 0.67963055, grad/param norm = 2.0634e-01, time/batch = 15.5300s	
14662/22750 (epoch 32.224), train_loss = 0.70723013, grad/param norm = 1.9924e-01, time/batch = 16.1722s	
14663/22750 (epoch 32.226), train_loss = 0.80125187, grad/param norm = 2.4589e-01, time/batch = 15.2710s	
14664/22750 (epoch 32.229), train_loss = 0.81560906, grad/param norm = 2.1761e-01, time/batch = 15.4391s	
14665/22750 (epoch 32.231), train_loss = 0.70751657, grad/param norm = 2.0232e-01, time/batch = 15.8519s	
14666/22750 (epoch 32.233), train_loss = 0.66049158, grad/param norm = 2.4850e-01, time/batch = 15.6907s	
14667/22750 (epoch 32.235), train_loss = 0.63469874, grad/param norm = 2.2182e-01, time/batch = 15.6807s	
14668/22750 (epoch 32.237), train_loss = 0.72775439, grad/param norm = 2.4479e-01, time/batch = 15.1169s	
14669/22750 (epoch 32.240), train_loss = 0.79509115, grad/param norm = 2.0040e-01, time/batch = 15.6020s	
14670/22750 (epoch 32.242), train_loss = 0.95396601, grad/param norm = 2.3594e-01, time/batch = 23.0418s	
14671/22750 (epoch 32.244), train_loss = 0.94136700, grad/param norm = 2.1663e-01, time/batch = 22.7971s	
14672/22750 (epoch 32.246), train_loss = 0.96578454, grad/param norm = 2.6336e-01, time/batch = 15.8491s	
14673/22750 (epoch 32.248), train_loss = 0.80703843, grad/param norm = 2.1340e-01, time/batch = 15.5249s	
14674/22750 (epoch 32.251), train_loss = 0.90516782, grad/param norm = 2.1805e-01, time/batch = 15.6869s	
14675/22750 (epoch 32.253), train_loss = 0.84910864, grad/param norm = 2.6971e-01, time/batch = 16.3748s	
14676/22750 (epoch 32.255), train_loss = 0.83033842, grad/param norm = 2.1731e-01, time/batch = 15.7786s	
14677/22750 (epoch 32.257), train_loss = 0.73623630, grad/param norm = 2.2206e-01, time/batch = 15.6031s	
14678/22750 (epoch 32.259), train_loss = 0.92967228, grad/param norm = 2.9895e-01, time/batch = 15.1359s	
14679/22750 (epoch 32.262), train_loss = 0.84351697, grad/param norm = 2.6007e-01, time/batch = 15.0692s	
14680/22750 (epoch 32.264), train_loss = 0.63945767, grad/param norm = 2.2809e-01, time/batch = 15.7892s	
14681/22750 (epoch 32.266), train_loss = 0.79555192, grad/param norm = 2.6223e-01, time/batch = 15.0707s	
14682/22750 (epoch 32.268), train_loss = 0.94222070, grad/param norm = 2.4923e-01, time/batch = 14.9995s	
14683/22750 (epoch 32.270), train_loss = 0.71903115, grad/param norm = 2.3566e-01, time/batch = 14.9763s	
14684/22750 (epoch 32.273), train_loss = 1.06041669, grad/param norm = 2.5151e-01, time/batch = 15.7666s	
14685/22750 (epoch 32.275), train_loss = 0.95701880, grad/param norm = 2.1980e-01, time/batch = 14.9733s	
14686/22750 (epoch 32.277), train_loss = 0.79514455, grad/param norm = 2.6130e-01, time/batch = 14.8887s	
14687/22750 (epoch 32.279), train_loss = 0.67868611, grad/param norm = 1.7279e-01, time/batch = 15.2123s	
14688/22750 (epoch 32.281), train_loss = 0.93800932, grad/param norm = 2.2575e-01, time/batch = 15.9323s	
14689/22750 (epoch 32.284), train_loss = 0.83447249, grad/param norm = 2.0418e-01, time/batch = 15.2842s	
14690/22750 (epoch 32.286), train_loss = 0.87633513, grad/param norm = 2.1166e-01, time/batch = 15.1223s	
14691/22750 (epoch 32.288), train_loss = 0.97431222, grad/param norm = 2.4512e-01, time/batch = 14.9983s	
14692/22750 (epoch 32.290), train_loss = 0.84784923, grad/param norm = 2.0528e-01, time/batch = 15.6308s	
14693/22750 (epoch 32.292), train_loss = 0.88976809, grad/param norm = 2.5859e-01, time/batch = 15.3880s	
14694/22750 (epoch 32.295), train_loss = 0.83623827, grad/param norm = 2.1626e-01, time/batch = 15.0586s	
14695/22750 (epoch 32.297), train_loss = 0.82102566, grad/param norm = 2.2751e-01, time/batch = 15.0440s	
14696/22750 (epoch 32.299), train_loss = 0.90100012, grad/param norm = 2.2576e-01, time/batch = 15.4306s	
14697/22750 (epoch 32.301), train_loss = 0.82326959, grad/param norm = 2.3201e-01, time/batch = 15.2161s	
14698/22750 (epoch 32.303), train_loss = 0.86928951, grad/param norm = 2.2613e-01, time/batch = 15.4419s	
14699/22750 (epoch 32.305), train_loss = 0.97861570, grad/param norm = 2.3843e-01, time/batch = 15.1238s	
14700/22750 (epoch 32.308), train_loss = 0.87547980, grad/param norm = 2.0778e-01, time/batch = 15.8321s	
14701/22750 (epoch 32.310), train_loss = 0.77031085, grad/param norm = 2.6006e-01, time/batch = 15.3664s	
14702/22750 (epoch 32.312), train_loss = 0.82570156, grad/param norm = 1.9868e-01, time/batch = 15.3894s	
14703/22750 (epoch 32.314), train_loss = 0.82930059, grad/param norm = 1.9450e-01, time/batch = 15.6238s	
14704/22750 (epoch 32.316), train_loss = 0.79389404, grad/param norm = 2.0980e-01, time/batch = 15.3101s	
14705/22750 (epoch 32.319), train_loss = 0.83990715, grad/param norm = 2.6495e-01, time/batch = 15.0694s	
14706/22750 (epoch 32.321), train_loss = 0.75593631, grad/param norm = 2.2279e-01, time/batch = 15.1393s	
14707/22750 (epoch 32.323), train_loss = 0.84876600, grad/param norm = 2.4682e-01, time/batch = 15.4469s	
14708/22750 (epoch 32.325), train_loss = 0.73813427, grad/param norm = 2.0695e-01, time/batch = 15.3601s	
14709/22750 (epoch 32.327), train_loss = 0.78078915, grad/param norm = 2.4715e-01, time/batch = 15.3665s	
14710/22750 (epoch 32.330), train_loss = 0.97254181, grad/param norm = 2.2792e-01, time/batch = 15.2188s	
14711/22750 (epoch 32.332), train_loss = 1.00902154, grad/param norm = 2.1722e-01, time/batch = 15.3705s	
14712/22750 (epoch 32.334), train_loss = 0.67466384, grad/param norm = 1.9157e-01, time/batch = 15.5548s	
14713/22750 (epoch 32.336), train_loss = 0.90747928, grad/param norm = 2.0356e-01, time/batch = 14.8259s	
14714/22750 (epoch 32.338), train_loss = 0.81267505, grad/param norm = 2.2405e-01, time/batch = 15.6270s	
14715/22750 (epoch 32.341), train_loss = 0.83317976, grad/param norm = 2.3199e-01, time/batch = 15.5566s	
14716/22750 (epoch 32.343), train_loss = 0.72124329, grad/param norm = 2.1977e-01, time/batch = 15.1291s	
14717/22750 (epoch 32.345), train_loss = 0.86739490, grad/param norm = 2.9892e-01, time/batch = 15.0527s	
14718/22750 (epoch 32.347), train_loss = 0.94045900, grad/param norm = 2.4031e-01, time/batch = 15.8467s	
14719/22750 (epoch 32.349), train_loss = 0.68886047, grad/param norm = 2.8107e-01, time/batch = 15.8543s	
14720/22750 (epoch 32.352), train_loss = 0.95369195, grad/param norm = 2.1193e-01, time/batch = 15.2030s	
14721/22750 (epoch 32.354), train_loss = 0.95379419, grad/param norm = 2.4106e-01, time/batch = 14.8036s	
14722/22750 (epoch 32.356), train_loss = 0.89574047, grad/param norm = 2.1978e-01, time/batch = 15.2923s	
14723/22750 (epoch 32.358), train_loss = 0.80480242, grad/param norm = 2.3263e-01, time/batch = 15.3867s	
14724/22750 (epoch 32.360), train_loss = 0.97337333, grad/param norm = 2.2295e-01, time/batch = 14.9797s	
14725/22750 (epoch 32.363), train_loss = 0.80178451, grad/param norm = 2.3315e-01, time/batch = 14.9918s	
14726/22750 (epoch 32.365), train_loss = 0.68716326, grad/param norm = 2.2709e-01, time/batch = 15.0705s	
14727/22750 (epoch 32.367), train_loss = 0.75841880, grad/param norm = 2.2123e-01, time/batch = 15.8428s	
14728/22750 (epoch 32.369), train_loss = 0.84345949, grad/param norm = 2.4214e-01, time/batch = 15.0452s	
14729/22750 (epoch 32.371), train_loss = 0.83628400, grad/param norm = 2.0797e-01, time/batch = 15.2069s	
14730/22750 (epoch 32.374), train_loss = 0.74006881, grad/param norm = 2.2286e-01, time/batch = 15.1142s	
14731/22750 (epoch 32.376), train_loss = 0.82146123, grad/param norm = 2.0317e-01, time/batch = 15.5306s	
14732/22750 (epoch 32.378), train_loss = 0.81852852, grad/param norm = 2.0596e-01, time/batch = 15.0398s	
14733/22750 (epoch 32.380), train_loss = 0.89821589, grad/param norm = 2.1801e-01, time/batch = 15.0488s	
14734/22750 (epoch 32.382), train_loss = 0.82799811, grad/param norm = 2.2010e-01, time/batch = 14.8905s	
14735/22750 (epoch 32.385), train_loss = 0.89065606, grad/param norm = 2.3683e-01, time/batch = 15.3989s	
14736/22750 (epoch 32.387), train_loss = 0.87088889, grad/param norm = 2.1268e-01, time/batch = 15.0457s	
14737/22750 (epoch 32.389), train_loss = 0.68037772, grad/param norm = 2.0964e-01, time/batch = 15.6948s	
14738/22750 (epoch 32.391), train_loss = 0.51409019, grad/param norm = 1.6027e-01, time/batch = 15.2806s	
14739/22750 (epoch 32.393), train_loss = 0.68892503, grad/param norm = 1.9537e-01, time/batch = 15.7636s	
14740/22750 (epoch 32.396), train_loss = 0.86040179, grad/param norm = 2.2656e-01, time/batch = 14.9596s	
14741/22750 (epoch 32.398), train_loss = 0.79505630, grad/param norm = 2.1029e-01, time/batch = 15.2149s	
14742/22750 (epoch 32.400), train_loss = 0.79965462, grad/param norm = 2.0115e-01, time/batch = 15.2074s	
14743/22750 (epoch 32.402), train_loss = 0.85431675, grad/param norm = 2.0364e-01, time/batch = 15.4539s	
14744/22750 (epoch 32.404), train_loss = 0.92740367, grad/param norm = 2.2286e-01, time/batch = 14.8970s	
14745/22750 (epoch 32.407), train_loss = 0.90252175, grad/param norm = 2.1473e-01, time/batch = 15.2276s	
14746/22750 (epoch 32.409), train_loss = 0.75088716, grad/param norm = 2.1091e-01, time/batch = 15.4480s	
14747/22750 (epoch 32.411), train_loss = 0.76555122, grad/param norm = 2.1403e-01, time/batch = 15.3157s	
14748/22750 (epoch 32.413), train_loss = 0.60330352, grad/param norm = 1.9843e-01, time/batch = 14.9144s	
14749/22750 (epoch 32.415), train_loss = 0.65415564, grad/param norm = 1.9455e-01, time/batch = 15.7677s	
14750/22750 (epoch 32.418), train_loss = 0.77356419, grad/param norm = 2.2404e-01, time/batch = 15.7529s	
14751/22750 (epoch 32.420), train_loss = 0.89552812, grad/param norm = 2.5468e-01, time/batch = 15.5406s	
14752/22750 (epoch 32.422), train_loss = 1.03493699, grad/param norm = 2.4812e-01, time/batch = 15.2991s	
14753/22750 (epoch 32.424), train_loss = 1.00148561, grad/param norm = 2.5461e-01, time/batch = 18.0160s	
14754/22750 (epoch 32.426), train_loss = 0.99969784, grad/param norm = 2.2768e-01, time/batch = 18.0682s	
14755/22750 (epoch 32.429), train_loss = 0.75690045, grad/param norm = 2.0817e-01, time/batch = 18.7610s	
14756/22750 (epoch 32.431), train_loss = 0.68243164, grad/param norm = 1.8609e-01, time/batch = 21.1034s	
14757/22750 (epoch 32.433), train_loss = 0.78104458, grad/param norm = 2.1185e-01, time/batch = 17.8592s	
14758/22750 (epoch 32.435), train_loss = 0.60122834, grad/param norm = 1.5982e-01, time/batch = 20.4335s	
14759/22750 (epoch 32.437), train_loss = 0.52923367, grad/param norm = 1.7462e-01, time/batch = 19.4130s	
14760/22750 (epoch 32.440), train_loss = 0.78043823, grad/param norm = 2.5482e-01, time/batch = 18.4218s	
14761/22750 (epoch 32.442), train_loss = 0.81988734, grad/param norm = 2.2100e-01, time/batch = 19.0039s	
14762/22750 (epoch 32.444), train_loss = 0.77740531, grad/param norm = 2.2704e-01, time/batch = 19.3417s	
14763/22750 (epoch 32.446), train_loss = 0.79856480, grad/param norm = 2.6348e-01, time/batch = 18.0808s	
14764/22750 (epoch 32.448), train_loss = 1.04266966, grad/param norm = 2.5905e-01, time/batch = 18.5880s	
14765/22750 (epoch 32.451), train_loss = 1.00170075, grad/param norm = 2.2577e-01, time/batch = 18.7851s	
14766/22750 (epoch 32.453), train_loss = 0.89238035, grad/param norm = 2.9877e-01, time/batch = 19.6014s	
14767/22750 (epoch 32.455), train_loss = 0.99190598, grad/param norm = 2.3099e-01, time/batch = 18.4420s	
14768/22750 (epoch 32.457), train_loss = 0.88365586, grad/param norm = 3.1827e-01, time/batch = 19.1650s	
14769/22750 (epoch 32.459), train_loss = 0.87428483, grad/param norm = 2.0221e-01, time/batch = 19.4135s	
14770/22750 (epoch 32.462), train_loss = 0.86886498, grad/param norm = 2.1464e-01, time/batch = 18.2338s	
14771/22750 (epoch 32.464), train_loss = 0.71030052, grad/param norm = 2.2311e-01, time/batch = 18.8326s	
14772/22750 (epoch 32.466), train_loss = 0.90509892, grad/param norm = 2.7608e-01, time/batch = 18.1647s	
14773/22750 (epoch 32.468), train_loss = 0.85556481, grad/param norm = 2.3456e-01, time/batch = 17.6887s	
14774/22750 (epoch 32.470), train_loss = 0.95095928, grad/param norm = 2.5885e-01, time/batch = 19.5289s	
14775/22750 (epoch 32.473), train_loss = 0.81295216, grad/param norm = 2.0364e-01, time/batch = 20.7796s	
14776/22750 (epoch 32.475), train_loss = 0.84051197, grad/param norm = 2.3565e-01, time/batch = 18.8342s	
14777/22750 (epoch 32.477), train_loss = 0.73531899, grad/param norm = 2.5013e-01, time/batch = 19.1612s	
14778/22750 (epoch 32.479), train_loss = 0.71470856, grad/param norm = 2.0693e-01, time/batch = 19.9190s	
14779/22750 (epoch 32.481), train_loss = 0.68348733, grad/param norm = 1.8790e-01, time/batch = 16.3975s	
14780/22750 (epoch 32.484), train_loss = 0.57793128, grad/param norm = 2.0083e-01, time/batch = 17.0009s	
14781/22750 (epoch 32.486), train_loss = 0.70237914, grad/param norm = 2.2119e-01, time/batch = 15.8521s	
14782/22750 (epoch 32.488), train_loss = 0.63751582, grad/param norm = 2.0183e-01, time/batch = 15.4397s	
14783/22750 (epoch 32.490), train_loss = 0.80603720, grad/param norm = 2.1607e-01, time/batch = 16.6480s	
14784/22750 (epoch 32.492), train_loss = 0.89598295, grad/param norm = 2.4335e-01, time/batch = 15.5476s	
14785/22750 (epoch 32.495), train_loss = 0.72509377, grad/param norm = 1.9888e-01, time/batch = 15.5507s	
14786/22750 (epoch 32.497), train_loss = 0.80352713, grad/param norm = 2.7392e-01, time/batch = 15.7756s	
14787/22750 (epoch 32.499), train_loss = 0.72572788, grad/param norm = 2.2356e-01, time/batch = 15.8576s	
14788/22750 (epoch 32.501), train_loss = 0.76207758, grad/param norm = 2.2060e-01, time/batch = 15.5248s	
14789/22750 (epoch 32.503), train_loss = 0.78215903, grad/param norm = 2.2258e-01, time/batch = 15.4486s	
14790/22750 (epoch 32.505), train_loss = 0.72175650, grad/param norm = 2.0986e-01, time/batch = 16.3965s	
14791/22750 (epoch 32.508), train_loss = 0.64103006, grad/param norm = 1.8854e-01, time/batch = 16.0005s	
14792/22750 (epoch 32.510), train_loss = 0.70936690, grad/param norm = 2.1863e-01, time/batch = 15.5258s	
14793/22750 (epoch 32.512), train_loss = 0.72444914, grad/param norm = 2.0957e-01, time/batch = 15.6220s	
14794/22750 (epoch 32.514), train_loss = 0.77029296, grad/param norm = 2.2205e-01, time/batch = 16.1069s	
14795/22750 (epoch 32.516), train_loss = 0.76604074, grad/param norm = 2.1635e-01, time/batch = 15.5493s	
14796/22750 (epoch 32.519), train_loss = 0.86867966, grad/param norm = 2.5374e-01, time/batch = 15.6171s	
14797/22750 (epoch 32.521), train_loss = 0.82711739, grad/param norm = 2.4379e-01, time/batch = 15.6092s	
14798/22750 (epoch 32.523), train_loss = 0.74533522, grad/param norm = 2.4947e-01, time/batch = 16.0840s	
14799/22750 (epoch 32.525), train_loss = 0.94105277, grad/param norm = 2.7924e-01, time/batch = 15.5882s	
14800/22750 (epoch 32.527), train_loss = 0.82306905, grad/param norm = 2.1266e-01, time/batch = 15.6844s	
14801/22750 (epoch 32.530), train_loss = 0.72911129, grad/param norm = 2.3245e-01, time/batch = 15.7690s	
14802/22750 (epoch 32.532), train_loss = 0.68161065, grad/param norm = 1.8183e-01, time/batch = 16.1635s	
14803/22750 (epoch 32.534), train_loss = 0.87102501, grad/param norm = 2.2157e-01, time/batch = 15.2037s	
14804/22750 (epoch 32.536), train_loss = 0.85302999, grad/param norm = 2.0330e-01, time/batch = 15.3851s	
14805/22750 (epoch 32.538), train_loss = 0.80898288, grad/param norm = 1.9343e-01, time/batch = 16.1642s	
14806/22750 (epoch 32.541), train_loss = 0.70712318, grad/param norm = 2.2374e-01, time/batch = 15.8737s	
14807/22750 (epoch 32.543), train_loss = 0.70026975, grad/param norm = 2.0589e-01, time/batch = 15.6910s	
14808/22750 (epoch 32.545), train_loss = 0.86402468, grad/param norm = 2.2661e-01, time/batch = 15.5340s	
14809/22750 (epoch 32.547), train_loss = 0.75201799, grad/param norm = 1.9237e-01, time/batch = 15.7695s	
14810/22750 (epoch 32.549), train_loss = 0.78003016, grad/param norm = 2.1674e-01, time/batch = 15.9087s	
14811/22750 (epoch 32.552), train_loss = 0.85438816, grad/param norm = 2.3105e-01, time/batch = 15.7669s	
14812/22750 (epoch 32.554), train_loss = 0.88989070, grad/param norm = 2.4717e-01, time/batch = 15.5253s	
14813/22750 (epoch 32.556), train_loss = 0.86306552, grad/param norm = 2.1805e-01, time/batch = 15.6854s	
14814/22750 (epoch 32.558), train_loss = 0.83813361, grad/param norm = 2.3664e-01, time/batch = 15.1371s	
14815/22750 (epoch 32.560), train_loss = 0.77674835, grad/param norm = 2.0525e-01, time/batch = 15.3010s	
14816/22750 (epoch 32.563), train_loss = 0.92569052, grad/param norm = 2.5453e-01, time/batch = 15.3867s	
14817/22750 (epoch 32.565), train_loss = 0.88066377, grad/param norm = 2.4618e-01, time/batch = 16.0209s	
14818/22750 (epoch 32.567), train_loss = 0.87539252, grad/param norm = 2.4460e-01, time/batch = 15.3656s	
14819/22750 (epoch 32.569), train_loss = 0.79430272, grad/param norm = 2.3216e-01, time/batch = 15.4486s	
14820/22750 (epoch 32.571), train_loss = 0.79180262, grad/param norm = 2.2807e-01, time/batch = 15.2023s	
14821/22750 (epoch 32.574), train_loss = 0.81855835, grad/param norm = 2.2899e-01, time/batch = 15.8536s	
14822/22750 (epoch 32.576), train_loss = 0.79424980, grad/param norm = 2.3999e-01, time/batch = 15.2032s	
14823/22750 (epoch 32.578), train_loss = 0.69841972, grad/param norm = 2.1406e-01, time/batch = 15.5268s	
14824/22750 (epoch 32.580), train_loss = 0.86434205, grad/param norm = 2.3172e-01, time/batch = 15.3605s	
14825/22750 (epoch 32.582), train_loss = 0.72563496, grad/param norm = 2.0650e-01, time/batch = 15.6861s	
14826/22750 (epoch 32.585), train_loss = 0.71040670, grad/param norm = 2.3003e-01, time/batch = 15.3775s	
14827/22750 (epoch 32.587), train_loss = 0.71086767, grad/param norm = 1.9566e-01, time/batch = 15.9207s	
14828/22750 (epoch 32.589), train_loss = 0.61686974, grad/param norm = 1.8563e-01, time/batch = 15.5456s	
14829/22750 (epoch 32.591), train_loss = 0.78051395, grad/param norm = 1.9653e-01, time/batch = 16.3342s	
14830/22750 (epoch 32.593), train_loss = 0.93533111, grad/param norm = 2.2969e-01, time/batch = 15.7008s	
14831/22750 (epoch 32.596), train_loss = 0.90959534, grad/param norm = 2.4655e-01, time/batch = 15.5394s	
14832/22750 (epoch 32.598), train_loss = 0.94849606, grad/param norm = 2.7070e-01, time/batch = 15.5231s	
14833/22750 (epoch 32.600), train_loss = 0.94871939, grad/param norm = 2.6021e-01, time/batch = 15.3579s	
14834/22750 (epoch 32.602), train_loss = 0.73888423, grad/param norm = 2.0683e-01, time/batch = 15.6835s	
14835/22750 (epoch 32.604), train_loss = 0.75375164, grad/param norm = 2.1942e-01, time/batch = 15.6988s	
14836/22750 (epoch 32.607), train_loss = 0.70333021, grad/param norm = 1.9817e-01, time/batch = 16.1157s	
14837/22750 (epoch 32.609), train_loss = 0.65297816, grad/param norm = 2.0835e-01, time/batch = 15.6267s	
14838/22750 (epoch 32.611), train_loss = 0.74952095, grad/param norm = 1.9751e-01, time/batch = 15.5474s	
14839/22750 (epoch 32.613), train_loss = 0.73909612, grad/param norm = 2.0841e-01, time/batch = 15.5407s	
14840/22750 (epoch 32.615), train_loss = 0.74816544, grad/param norm = 1.7543e-01, time/batch = 15.9371s	
14841/22750 (epoch 32.618), train_loss = 0.77747868, grad/param norm = 2.2885e-01, time/batch = 15.6871s	
14842/22750 (epoch 32.620), train_loss = 0.76243149, grad/param norm = 2.2216e-01, time/batch = 15.3612s	
14843/22750 (epoch 32.622), train_loss = 0.64219486, grad/param norm = 1.8585e-01, time/batch = 15.3742s	
14844/22750 (epoch 32.624), train_loss = 0.74650515, grad/param norm = 2.1941e-01, time/batch = 15.9241s	
14845/22750 (epoch 32.626), train_loss = 0.64138865, grad/param norm = 1.8817e-01, time/batch = 16.0083s	
14846/22750 (epoch 32.629), train_loss = 0.74189710, grad/param norm = 2.0606e-01, time/batch = 15.5400s	
14847/22750 (epoch 32.631), train_loss = 0.79266301, grad/param norm = 1.9721e-01, time/batch = 15.6265s	
14848/22750 (epoch 32.633), train_loss = 0.67247480, grad/param norm = 2.0379e-01, time/batch = 16.3259s	
14849/22750 (epoch 32.635), train_loss = 0.78513875, grad/param norm = 2.1784e-01, time/batch = 15.5375s	
14850/22750 (epoch 32.637), train_loss = 0.84513248, grad/param norm = 2.6047e-01, time/batch = 15.6902s	
14851/22750 (epoch 32.640), train_loss = 0.87147064, grad/param norm = 2.2760e-01, time/batch = 15.9178s	
14852/22750 (epoch 32.642), train_loss = 0.89954089, grad/param norm = 2.1619e-01, time/batch = 15.7690s	
14853/22750 (epoch 32.644), train_loss = 0.76820610, grad/param norm = 2.1318e-01, time/batch = 15.6890s	
14854/22750 (epoch 32.646), train_loss = 0.85940939, grad/param norm = 2.7689e-01, time/batch = 15.6142s	
14855/22750 (epoch 32.648), train_loss = 0.82326007, grad/param norm = 1.9980e-01, time/batch = 16.3343s	
14856/22750 (epoch 32.651), train_loss = 0.84458138, grad/param norm = 2.1856e-01, time/batch = 15.3672s	
14857/22750 (epoch 32.653), train_loss = 0.86314280, grad/param norm = 2.0465e-01, time/batch = 16.0269s	
14858/22750 (epoch 32.655), train_loss = 0.81229339, grad/param norm = 2.0328e-01, time/batch = 15.4751s	
14859/22750 (epoch 32.657), train_loss = 0.94030960, grad/param norm = 2.3050e-01, time/batch = 16.1968s	
14860/22750 (epoch 32.659), train_loss = 0.98189608, grad/param norm = 2.1962e-01, time/batch = 15.8355s	
14861/22750 (epoch 32.662), train_loss = 0.95931138, grad/param norm = 2.3717e-01, time/batch = 15.6075s	
14862/22750 (epoch 32.664), train_loss = 0.85974802, grad/param norm = 2.2128e-01, time/batch = 15.7677s	
14863/22750 (epoch 32.666), train_loss = 0.68332271, grad/param norm = 2.1128e-01, time/batch = 15.9305s	
14864/22750 (epoch 32.668), train_loss = 0.80685431, grad/param norm = 2.1791e-01, time/batch = 15.5984s	
14865/22750 (epoch 32.670), train_loss = 0.77726654, grad/param norm = 2.2179e-01, time/batch = 15.5305s	
14866/22750 (epoch 32.673), train_loss = 0.98975037, grad/param norm = 2.5336e-01, time/batch = 15.7069s	
14867/22750 (epoch 32.675), train_loss = 1.13171037, grad/param norm = 2.7760e-01, time/batch = 15.7858s	
14868/22750 (epoch 32.677), train_loss = 0.98501495, grad/param norm = 2.5633e-01, time/batch = 15.6286s	
14869/22750 (epoch 32.679), train_loss = 0.98168255, grad/param norm = 2.5592e-01, time/batch = 15.7113s	
14870/22750 (epoch 32.681), train_loss = 0.95450380, grad/param norm = 2.3886e-01, time/batch = 15.8589s	
14871/22750 (epoch 32.684), train_loss = 1.00659354, grad/param norm = 2.5788e-01, time/batch = 15.7641s	
14872/22750 (epoch 32.686), train_loss = 1.01546426, grad/param norm = 2.6667e-01, time/batch = 19.4087s	
14873/22750 (epoch 32.688), train_loss = 0.97299027, grad/param norm = 2.5449e-01, time/batch = 16.1909s	
14874/22750 (epoch 32.690), train_loss = 0.95716380, grad/param norm = 2.3953e-01, time/batch = 17.0763s	
14875/22750 (epoch 32.692), train_loss = 0.95263493, grad/param norm = 2.4660e-01, time/batch = 20.1455s	
14876/22750 (epoch 32.695), train_loss = 0.83966786, grad/param norm = 2.0014e-01, time/batch = 20.3418s	
14877/22750 (epoch 32.697), train_loss = 0.85294367, grad/param norm = 2.1487e-01, time/batch = 18.8376s	
14878/22750 (epoch 32.699), train_loss = 0.80687173, grad/param norm = 2.3372e-01, time/batch = 17.2481s	
14879/22750 (epoch 32.701), train_loss = 0.71000711, grad/param norm = 2.1135e-01, time/batch = 20.9395s	
14880/22750 (epoch 32.703), train_loss = 0.79124943, grad/param norm = 2.2718e-01, time/batch = 18.7498s	
14881/22750 (epoch 32.705), train_loss = 0.75813226, grad/param norm = 2.0244e-01, time/batch = 20.3157s	
14882/22750 (epoch 32.708), train_loss = 0.84301902, grad/param norm = 2.3617e-01, time/batch = 20.0792s	
14883/22750 (epoch 32.710), train_loss = 0.70841259, grad/param norm = 2.0100e-01, time/batch = 17.7391s	
14884/22750 (epoch 32.712), train_loss = 0.68997009, grad/param norm = 1.9314e-01, time/batch = 20.7172s	
14885/22750 (epoch 32.714), train_loss = 0.68571032, grad/param norm = 2.0313e-01, time/batch = 20.8435s	
14886/22750 (epoch 32.716), train_loss = 0.70565375, grad/param norm = 2.1832e-01, time/batch = 18.8562s	
14887/22750 (epoch 32.719), train_loss = 0.78252667, grad/param norm = 2.5670e-01, time/batch = 21.3572s	
14888/22750 (epoch 32.721), train_loss = 0.89329047, grad/param norm = 2.1695e-01, time/batch = 16.7434s	
14889/22750 (epoch 32.723), train_loss = 0.90749595, grad/param norm = 2.5344e-01, time/batch = 24.2159s	
14890/22750 (epoch 32.725), train_loss = 0.79736563, grad/param norm = 2.7541e-01, time/batch = 25.0500s	
14891/22750 (epoch 32.727), train_loss = 0.79368719, grad/param norm = 2.3652e-01, time/batch = 20.1652s	
14892/22750 (epoch 32.730), train_loss = 0.78363395, grad/param norm = 2.5044e-01, time/batch = 19.1604s	
14893/22750 (epoch 32.732), train_loss = 0.74385967, grad/param norm = 2.0593e-01, time/batch = 18.1934s	
14894/22750 (epoch 32.734), train_loss = 0.65603821, grad/param norm = 1.8040e-01, time/batch = 16.1481s	
14895/22750 (epoch 32.736), train_loss = 0.75231996, grad/param norm = 2.1237e-01, time/batch = 17.6770s	
14896/22750 (epoch 32.738), train_loss = 0.85107940, grad/param norm = 2.2376e-01, time/batch = 15.2283s	
14897/22750 (epoch 32.741), train_loss = 0.91663779, grad/param norm = 2.5250e-01, time/batch = 15.0609s	
14898/22750 (epoch 32.743), train_loss = 0.86346408, grad/param norm = 2.3292e-01, time/batch = 15.1398s	
14899/22750 (epoch 32.745), train_loss = 0.67827410, grad/param norm = 1.8780e-01, time/batch = 15.8546s	
14900/22750 (epoch 32.747), train_loss = 0.78411587, grad/param norm = 1.8370e-01, time/batch = 15.1265s	
14901/22750 (epoch 32.749), train_loss = 0.94162608, grad/param norm = 2.6084e-01, time/batch = 15.6847s	
14902/22750 (epoch 32.752), train_loss = 0.83004244, grad/param norm = 2.2989e-01, time/batch = 15.0473s	
14903/22750 (epoch 32.754), train_loss = 0.83354971, grad/param norm = 2.4110e-01, time/batch = 15.5289s	
14904/22750 (epoch 32.756), train_loss = 0.76578705, grad/param norm = 2.4067e-01, time/batch = 15.1402s	
14905/22750 (epoch 32.758), train_loss = 0.73424282, grad/param norm = 2.1112e-01, time/batch = 15.0529s	
14906/22750 (epoch 32.760), train_loss = 0.74520252, grad/param norm = 2.1721e-01, time/batch = 14.9981s	
14907/22750 (epoch 32.763), train_loss = 0.81077966, grad/param norm = 2.1987e-01, time/batch = 15.5280s	
14908/22750 (epoch 32.765), train_loss = 0.79756758, grad/param norm = 2.1756e-01, time/batch = 14.9784s	
14909/22750 (epoch 32.767), train_loss = 0.85163217, grad/param norm = 2.2639e-01, time/batch = 15.1336s	
14910/22750 (epoch 32.769), train_loss = 0.96685055, grad/param norm = 2.5747e-01, time/batch = 15.0409s	
14911/22750 (epoch 32.771), train_loss = 1.01044677, grad/param norm = 2.7923e-01, time/batch = 14.9618s	
14912/22750 (epoch 32.774), train_loss = 0.77862761, grad/param norm = 2.4138e-01, time/batch = 15.4319s	
14913/22750 (epoch 32.776), train_loss = 0.92076188, grad/param norm = 2.5695e-01, time/batch = 14.7169s	
14914/22750 (epoch 32.778), train_loss = 0.98849258, grad/param norm = 2.8756e-01, time/batch = 14.7966s	
14915/22750 (epoch 32.780), train_loss = 0.83592671, grad/param norm = 2.1899e-01, time/batch = 15.0473s	
14916/22750 (epoch 32.782), train_loss = 0.99287768, grad/param norm = 2.4477e-01, time/batch = 14.6546s	
14917/22750 (epoch 32.785), train_loss = 0.79451432, grad/param norm = 2.0846e-01, time/batch = 14.6620s	
14918/22750 (epoch 32.787), train_loss = 0.71797635, grad/param norm = 2.2981e-01, time/batch = 14.6728s	
14919/22750 (epoch 32.789), train_loss = 0.79232134, grad/param norm = 2.1607e-01, time/batch = 15.3054s	
14920/22750 (epoch 32.791), train_loss = 0.77296754, grad/param norm = 2.1781e-01, time/batch = 14.8805s	
14921/22750 (epoch 32.793), train_loss = 0.75173929, grad/param norm = 3.4200e-01, time/batch = 15.2100s	
14922/22750 (epoch 32.796), train_loss = 0.70161159, grad/param norm = 2.0279e-01, time/batch = 15.0461s	
14923/22750 (epoch 32.798), train_loss = 0.74329247, grad/param norm = 2.1097e-01, time/batch = 15.1205s	
14924/22750 (epoch 32.800), train_loss = 0.73582732, grad/param norm = 2.4095e-01, time/batch = 14.7169s	
14925/22750 (epoch 32.802), train_loss = 0.68568045, grad/param norm = 2.3001e-01, time/batch = 14.9638s	
14926/22750 (epoch 32.804), train_loss = 0.88967855, grad/param norm = 2.1793e-01, time/batch = 15.1272s	
14927/22750 (epoch 32.807), train_loss = 0.86445501, grad/param norm = 2.7018e-01, time/batch = 15.6910s	
14928/22750 (epoch 32.809), train_loss = 0.93461913, grad/param norm = 2.4713e-01, time/batch = 14.9935s	
14929/22750 (epoch 32.811), train_loss = 0.80883150, grad/param norm = 2.4739e-01, time/batch = 15.0838s	
14930/22750 (epoch 32.813), train_loss = 0.83198963, grad/param norm = 2.0072e-01, time/batch = 15.0740s	
14931/22750 (epoch 32.815), train_loss = 0.97171509, grad/param norm = 2.3835e-01, time/batch = 15.3965s	
14932/22750 (epoch 32.818), train_loss = 0.90045109, grad/param norm = 2.0056e-01, time/batch = 15.2107s	
14933/22750 (epoch 32.820), train_loss = 1.02899236, grad/param norm = 2.4570e-01, time/batch = 15.2178s	
14934/22750 (epoch 32.822), train_loss = 0.84197001, grad/param norm = 2.1124e-01, time/batch = 15.4566s	
14935/22750 (epoch 32.824), train_loss = 0.70336060, grad/param norm = 1.9190e-01, time/batch = 15.4605s	
14936/22750 (epoch 32.826), train_loss = 0.81807684, grad/param norm = 2.1358e-01, time/batch = 15.2939s	
14937/22750 (epoch 32.829), train_loss = 0.94453487, grad/param norm = 2.4561e-01, time/batch = 15.2192s	
14938/22750 (epoch 32.831), train_loss = 0.92518173, grad/param norm = 2.5781e-01, time/batch = 15.5254s	
14939/22750 (epoch 32.833), train_loss = 0.85057836, grad/param norm = 2.4156e-01, time/batch = 15.2160s	
14940/22750 (epoch 32.835), train_loss = 0.71314446, grad/param norm = 2.0431e-01, time/batch = 16.0843s	
14941/22750 (epoch 32.837), train_loss = 0.79758440, grad/param norm = 2.3096e-01, time/batch = 14.6688s	
14942/22750 (epoch 32.840), train_loss = 0.72093226, grad/param norm = 2.1325e-01, time/batch = 15.2331s	
14943/22750 (epoch 32.842), train_loss = 0.76878901, grad/param norm = 2.1998e-01, time/batch = 15.0451s	
14944/22750 (epoch 32.844), train_loss = 0.83987833, grad/param norm = 2.3026e-01, time/batch = 15.0454s	
14945/22750 (epoch 32.846), train_loss = 0.86188365, grad/param norm = 2.0454e-01, time/batch = 14.9618s	
14946/22750 (epoch 32.848), train_loss = 0.75516380, grad/param norm = 1.9821e-01, time/batch = 15.7653s	
14947/22750 (epoch 32.851), train_loss = 0.73948262, grad/param norm = 1.9941e-01, time/batch = 15.5976s	
14948/22750 (epoch 32.853), train_loss = 0.90002362, grad/param norm = 2.1932e-01, time/batch = 15.1314s	
14949/22750 (epoch 32.855), train_loss = 0.76563968, grad/param norm = 2.0934e-01, time/batch = 15.1286s	
14950/22750 (epoch 32.857), train_loss = 0.86342191, grad/param norm = 2.0796e-01, time/batch = 15.3776s	
14951/22750 (epoch 32.859), train_loss = 0.85646998, grad/param norm = 2.3474e-01, time/batch = 15.2276s	
14952/22750 (epoch 32.862), train_loss = 1.01169197, grad/param norm = 2.6348e-01, time/batch = 15.0667s	
14953/22750 (epoch 32.864), train_loss = 0.83188542, grad/param norm = 2.2322e-01, time/batch = 15.1517s	
14954/22750 (epoch 32.866), train_loss = 0.86996248, grad/param norm = 2.0728e-01, time/batch = 15.5320s	
14955/22750 (epoch 32.868), train_loss = 0.72802563, grad/param norm = 1.8546e-01, time/batch = 14.8813s	
14956/22750 (epoch 32.870), train_loss = 0.69103077, grad/param norm = 2.0113e-01, time/batch = 14.9548s	
14957/22750 (epoch 32.873), train_loss = 0.80197272, grad/param norm = 2.1719e-01, time/batch = 15.1367s	
14958/22750 (epoch 32.875), train_loss = 0.85965964, grad/param norm = 2.0034e-01, time/batch = 15.9133s	
14959/22750 (epoch 32.877), train_loss = 0.76219854, grad/param norm = 2.7631e-01, time/batch = 15.1183s	
14960/22750 (epoch 32.879), train_loss = 0.92959871, grad/param norm = 2.6661e-01, time/batch = 15.0506s	
14961/22750 (epoch 32.881), train_loss = 0.88590319, grad/param norm = 2.5254e-01, time/batch = 15.1389s	
14962/22750 (epoch 32.884), train_loss = 0.74935868, grad/param norm = 1.8667e-01, time/batch = 15.6406s	
14963/22750 (epoch 32.886), train_loss = 0.85047871, grad/param norm = 2.0630e-01, time/batch = 14.8305s	
14964/22750 (epoch 32.888), train_loss = 0.88375180, grad/param norm = 2.0572e-01, time/batch = 14.9133s	
14965/22750 (epoch 32.890), train_loss = 0.86972403, grad/param norm = 2.1039e-01, time/batch = 15.7831s	
14966/22750 (epoch 32.892), train_loss = 1.10920861, grad/param norm = 2.7431e-01, time/batch = 15.4401s	
14967/22750 (epoch 32.895), train_loss = 0.80874796, grad/param norm = 2.2489e-01, time/batch = 14.9744s	
14968/22750 (epoch 32.897), train_loss = 0.90452541, grad/param norm = 2.2141e-01, time/batch = 15.4516s	
14969/22750 (epoch 32.899), train_loss = 0.85833869, grad/param norm = 2.2243e-01, time/batch = 15.2177s	
14970/22750 (epoch 32.901), train_loss = 0.90681950, grad/param norm = 2.5069e-01, time/batch = 15.3684s	
14971/22750 (epoch 32.903), train_loss = 0.82747642, grad/param norm = 2.4972e-01, time/batch = 15.1163s	
14972/22750 (epoch 32.905), train_loss = 0.91189708, grad/param norm = 2.4910e-01, time/batch = 15.0533s	
14973/22750 (epoch 32.908), train_loss = 0.72752389, grad/param norm = 2.6435e-01, time/batch = 15.2330s	
14974/22750 (epoch 32.910), train_loss = 0.64297525, grad/param norm = 1.8949e-01, time/batch = 15.3188s	
14975/22750 (epoch 32.912), train_loss = 0.78892318, grad/param norm = 2.0947e-01, time/batch = 15.0710s	
14976/22750 (epoch 32.914), train_loss = 0.83123428, grad/param norm = 2.6968e-01, time/batch = 15.2235s	
14977/22750 (epoch 32.916), train_loss = 0.66295390, grad/param norm = 2.1850e-01, time/batch = 15.5205s	
14978/22750 (epoch 32.919), train_loss = 0.80939940, grad/param norm = 2.4817e-01, time/batch = 16.2361s	
14979/22750 (epoch 32.921), train_loss = 0.63791242, grad/param norm = 2.0039e-01, time/batch = 17.7507s	
14980/22750 (epoch 32.923), train_loss = 0.72962824, grad/param norm = 2.0215e-01, time/batch = 19.8343s	
14981/22750 (epoch 32.925), train_loss = 0.79748791, grad/param norm = 2.0633e-01, time/batch = 17.7499s	
14982/22750 (epoch 32.927), train_loss = 0.66248901, grad/param norm = 2.1327e-01, time/batch = 19.9962s	
14983/22750 (epoch 32.930), train_loss = 0.61250150, grad/param norm = 1.8626e-01, time/batch = 19.6939s	
14984/22750 (epoch 32.932), train_loss = 0.83285651, grad/param norm = 2.4674e-01, time/batch = 15.8864s	
14985/22750 (epoch 32.934), train_loss = 0.66768861, grad/param norm = 1.8019e-01, time/batch = 15.4039s	
14986/22750 (epoch 32.936), train_loss = 0.91307606, grad/param norm = 2.2751e-01, time/batch = 18.3396s	
14987/22750 (epoch 32.938), train_loss = 0.91740183, grad/param norm = 2.0794e-01, time/batch = 18.9217s	
14988/22750 (epoch 32.941), train_loss = 0.97301730, grad/param norm = 2.6145e-01, time/batch = 19.3357s	
14989/22750 (epoch 32.943), train_loss = 0.84147240, grad/param norm = 2.2020e-01, time/batch = 18.1672s	
14990/22750 (epoch 32.945), train_loss = 0.83461105, grad/param norm = 2.3484e-01, time/batch = 19.9951s	
14991/22750 (epoch 32.947), train_loss = 0.76624768, grad/param norm = 2.6585e-01, time/batch = 17.3099s	
14992/22750 (epoch 32.949), train_loss = 0.75473215, grad/param norm = 2.1392e-01, time/batch = 17.9055s	
14993/22750 (epoch 32.952), train_loss = 0.78068506, grad/param norm = 2.2313e-01, time/batch = 21.2781s	
14994/22750 (epoch 32.954), train_loss = 0.72987720, grad/param norm = 2.1205e-01, time/batch = 18.4343s	
14995/22750 (epoch 32.956), train_loss = 0.85211914, grad/param norm = 2.1620e-01, time/batch = 19.8706s	
14996/22750 (epoch 32.958), train_loss = 0.71985839, grad/param norm = 1.7737e-01, time/batch = 17.1609s	
14997/22750 (epoch 32.960), train_loss = 0.70586948, grad/param norm = 1.7720e-01, time/batch = 15.9087s	
14998/22750 (epoch 32.963), train_loss = 0.82198007, grad/param norm = 2.0217e-01, time/batch = 16.9309s	
14999/22750 (epoch 32.965), train_loss = 0.88829300, grad/param norm = 2.1366e-01, time/batch = 17.0899s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_wakata_epoch32.97_1.6947.t7	
15000/22750 (epoch 32.967), train_loss = 0.87433674, grad/param norm = 2.4947e-01, time/batch = 17.8143s	
15001/22750 (epoch 32.969), train_loss = 1.46199378, grad/param norm = 3.5378e-01, time/batch = 18.0657s	
15002/22750 (epoch 32.971), train_loss = 0.75082873, grad/param norm = 2.0884e-01, time/batch = 19.0630s	
15003/22750 (epoch 32.974), train_loss = 0.76686123, grad/param norm = 2.3562e-01, time/batch = 17.9208s	
15004/22750 (epoch 32.976), train_loss = 0.78657611, grad/param norm = 2.2294e-01, time/batch = 19.8218s	
15005/22750 (epoch 32.978), train_loss = 0.76298534, grad/param norm = 2.1830e-01, time/batch = 17.0630s	
15006/22750 (epoch 32.980), train_loss = 0.92006734, grad/param norm = 2.4005e-01, time/batch = 19.0809s	
15007/22750 (epoch 32.982), train_loss = 0.74747696, grad/param norm = 2.0706e-01, time/batch = 18.7814s	
15008/22750 (epoch 32.985), train_loss = 0.95863837, grad/param norm = 2.6445e-01, time/batch = 19.3379s	
15009/22750 (epoch 32.987), train_loss = 0.68276798, grad/param norm = 2.0466e-01, time/batch = 19.6027s	
15010/22750 (epoch 32.989), train_loss = 0.76902866, grad/param norm = 2.7414e-01, time/batch = 19.7566s	
15011/22750 (epoch 32.991), train_loss = 0.84923329, grad/param norm = 2.3343e-01, time/batch = 18.4059s	
15012/22750 (epoch 32.993), train_loss = 0.82509531, grad/param norm = 2.6118e-01, time/batch = 18.6611s	
15013/22750 (epoch 32.996), train_loss = 0.72864067, grad/param norm = 2.5059e-01, time/batch = 19.8074s	
15014/22750 (epoch 32.998), train_loss = 0.92021649, grad/param norm = 2.3435e-01, time/batch = 18.0787s	
decayed learning rate by a factor 0.97 to 0.00096283444382345	
15015/22750 (epoch 33.000), train_loss = 0.80829385, grad/param norm = 2.2314e-01, time/batch = 20.5679s	
15016/22750 (epoch 33.002), train_loss = 0.97789619, grad/param norm = 2.3552e-01, time/batch = 21.1133s	
15017/22750 (epoch 33.004), train_loss = 0.78108713, grad/param norm = 2.4211e-01, time/batch = 19.1822s	
15018/22750 (epoch 33.007), train_loss = 0.76884729, grad/param norm = 2.2928e-01, time/batch = 20.9308s	
15019/22750 (epoch 33.009), train_loss = 0.94584756, grad/param norm = 2.4483e-01, time/batch = 17.6655s	
15020/22750 (epoch 33.011), train_loss = 1.03986650, grad/param norm = 2.6398e-01, time/batch = 17.8206s	
15021/22750 (epoch 33.013), train_loss = 0.94120069, grad/param norm = 2.3195e-01, time/batch = 19.6360s	
15022/22750 (epoch 33.015), train_loss = 0.84790543, grad/param norm = 2.2721e-01, time/batch = 19.9081s	
15023/22750 (epoch 33.018), train_loss = 0.92168657, grad/param norm = 2.5645e-01, time/batch = 17.4000s	
15024/22750 (epoch 33.020), train_loss = 0.96674332, grad/param norm = 2.2366e-01, time/batch = 19.5277s	
15025/22750 (epoch 33.022), train_loss = 0.82187831, grad/param norm = 2.2406e-01, time/batch = 17.5033s	
15026/22750 (epoch 33.024), train_loss = 0.84006492, grad/param norm = 2.3468e-01, time/batch = 17.4437s	
15027/22750 (epoch 33.026), train_loss = 0.87002296, grad/param norm = 2.3223e-01, time/batch = 17.8760s	
15028/22750 (epoch 33.029), train_loss = 0.68244198, grad/param norm = 2.0972e-01, time/batch = 17.8901s	
15029/22750 (epoch 33.031), train_loss = 1.03151952, grad/param norm = 2.4234e-01, time/batch = 17.4880s	
15030/22750 (epoch 33.033), train_loss = 0.81709358, grad/param norm = 2.0802e-01, time/batch = 17.8145s	
15031/22750 (epoch 33.035), train_loss = 0.87392238, grad/param norm = 2.2577e-01, time/batch = 18.5683s	
15032/22750 (epoch 33.037), train_loss = 0.92154574, grad/param norm = 2.1012e-01, time/batch = 16.5880s	
15033/22750 (epoch 33.040), train_loss = 0.82001136, grad/param norm = 2.1560e-01, time/batch = 16.5827s	
15034/22750 (epoch 33.042), train_loss = 0.84770897, grad/param norm = 2.2507e-01, time/batch = 19.0621s	
15035/22750 (epoch 33.044), train_loss = 0.81510567, grad/param norm = 2.1118e-01, time/batch = 18.0719s	
15036/22750 (epoch 33.046), train_loss = 0.91661714, grad/param norm = 2.3583e-01, time/batch = 19.2251s	
15037/22750 (epoch 33.048), train_loss = 0.83039800, grad/param norm = 2.1066e-01, time/batch = 17.4848s	
15038/22750 (epoch 33.051), train_loss = 0.82924498, grad/param norm = 2.2055e-01, time/batch = 18.9179s	
15039/22750 (epoch 33.053), train_loss = 0.80034063, grad/param norm = 2.0391e-01, time/batch = 19.2333s	
15040/22750 (epoch 33.055), train_loss = 0.69582799, grad/param norm = 1.9275e-01, time/batch = 17.5045s	
15041/22750 (epoch 33.057), train_loss = 0.99152742, grad/param norm = 2.5856e-01, time/batch = 20.1421s	
15042/22750 (epoch 33.059), train_loss = 0.62480924, grad/param norm = 2.1850e-01, time/batch = 16.6597s	
15043/22750 (epoch 33.062), train_loss = 0.70480304, grad/param norm = 2.1698e-01, time/batch = 17.8323s	
15044/22750 (epoch 33.064), train_loss = 0.90946963, grad/param norm = 2.2410e-01, time/batch = 20.6511s	
15045/22750 (epoch 33.066), train_loss = 0.73937886, grad/param norm = 1.9384e-01, time/batch = 18.4979s	
15046/22750 (epoch 33.068), train_loss = 0.73658247, grad/param norm = 1.8477e-01, time/batch = 18.2576s	
15047/22750 (epoch 33.070), train_loss = 0.62037012, grad/param norm = 1.7968e-01, time/batch = 19.3791s	
15048/22750 (epoch 33.073), train_loss = 0.75687848, grad/param norm = 2.0745e-01, time/batch = 18.5018s	
15049/22750 (epoch 33.075), train_loss = 0.81580104, grad/param norm = 2.1105e-01, time/batch = 18.9635s	
15050/22750 (epoch 33.077), train_loss = 0.60566219, grad/param norm = 1.9729e-01, time/batch = 17.1611s	
15051/22750 (epoch 33.079), train_loss = 0.79813572, grad/param norm = 2.2515e-01, time/batch = 17.4555s	
15052/22750 (epoch 33.081), train_loss = 0.76228676, grad/param norm = 2.2010e-01, time/batch = 15.8489s	
15053/22750 (epoch 33.084), train_loss = 0.76660526, grad/param norm = 2.0172e-01, time/batch = 16.6566s	
15054/22750 (epoch 33.086), train_loss = 0.80275151, grad/param norm = 1.9672e-01, time/batch = 19.3314s	
15055/22750 (epoch 33.088), train_loss = 0.73927749, grad/param norm = 2.0151e-01, time/batch = 19.3213s	
15056/22750 (epoch 33.090), train_loss = 0.77688078, grad/param norm = 2.2618e-01, time/batch = 18.8474s	
15057/22750 (epoch 33.092), train_loss = 0.88871980, grad/param norm = 2.3238e-01, time/batch = 18.9989s	
15058/22750 (epoch 33.095), train_loss = 0.73015045, grad/param norm = 2.0579e-01, time/batch = 17.1080s	
15059/22750 (epoch 33.097), train_loss = 0.80428959, grad/param norm = 2.1671e-01, time/batch = 18.9131s	
15060/22750 (epoch 33.099), train_loss = 0.75186755, grad/param norm = 2.1412e-01, time/batch = 19.2339s	
15061/22750 (epoch 33.101), train_loss = 0.66582701, grad/param norm = 1.9098e-01, time/batch = 18.3374s	
15062/22750 (epoch 33.103), train_loss = 0.86015760, grad/param norm = 2.4339e-01, time/batch = 18.0643s	
15063/22750 (epoch 33.105), train_loss = 0.93572911, grad/param norm = 2.5194e-01, time/batch = 20.2625s	
15064/22750 (epoch 33.108), train_loss = 0.81769938, grad/param norm = 2.1426e-01, time/batch = 20.9878s	
15065/22750 (epoch 33.110), train_loss = 0.90883432, grad/param norm = 2.0364e-01, time/batch = 18.3508s	
15066/22750 (epoch 33.112), train_loss = 0.68484334, grad/param norm = 1.7873e-01, time/batch = 18.8428s	
15067/22750 (epoch 33.114), train_loss = 0.59541148, grad/param norm = 1.7862e-01, time/batch = 18.8293s	
15068/22750 (epoch 33.116), train_loss = 0.80828828, grad/param norm = 2.0367e-01, time/batch = 19.7438s	
15069/22750 (epoch 33.119), train_loss = 0.75400068, grad/param norm = 1.9291e-01, time/batch = 17.8369s	
15070/22750 (epoch 33.121), train_loss = 0.78427666, grad/param norm = 2.4288e-01, time/batch = 19.9945s	
15071/22750 (epoch 33.123), train_loss = 0.68648196, grad/param norm = 2.1505e-01, time/batch = 19.9918s	
15072/22750 (epoch 33.125), train_loss = 0.92794211, grad/param norm = 2.1149e-01, time/batch = 19.1850s	
15073/22750 (epoch 33.127), train_loss = 0.77386444, grad/param norm = 2.2486e-01, time/batch = 20.9348s	
15074/22750 (epoch 33.130), train_loss = 0.77192259, grad/param norm = 1.8928e-01, time/batch = 19.1954s	
15075/22750 (epoch 33.132), train_loss = 0.74346612, grad/param norm = 2.1139e-01, time/batch = 17.0933s	
15076/22750 (epoch 33.134), train_loss = 0.77009220, grad/param norm = 2.0443e-01, time/batch = 20.4120s	
15077/22750 (epoch 33.136), train_loss = 0.63092606, grad/param norm = 2.0616e-01, time/batch = 17.5907s	
15078/22750 (epoch 33.138), train_loss = 0.85118038, grad/param norm = 2.1493e-01, time/batch = 16.4241s	
15079/22750 (epoch 33.141), train_loss = 0.82016785, grad/param norm = 2.1482e-01, time/batch = 17.0619s	
15080/22750 (epoch 33.143), train_loss = 0.72703113, grad/param norm = 2.0712e-01, time/batch = 17.9768s	
15081/22750 (epoch 33.145), train_loss = 0.91769584, grad/param norm = 2.3756e-01, time/batch = 20.6515s	
15082/22750 (epoch 33.147), train_loss = 0.96109607, grad/param norm = 2.4152e-01, time/batch = 18.2853s	
15083/22750 (epoch 33.149), train_loss = 0.82341157, grad/param norm = 2.1919e-01, time/batch = 18.4583s	
15084/22750 (epoch 33.152), train_loss = 0.79735750, grad/param norm = 2.1079e-01, time/batch = 19.6873s	
15085/22750 (epoch 33.154), train_loss = 0.72581232, grad/param norm = 2.0699e-01, time/batch = 17.4897s	
15086/22750 (epoch 33.156), train_loss = 0.73437745, grad/param norm = 2.3500e-01, time/batch = 18.2464s	
15087/22750 (epoch 33.158), train_loss = 0.70985065, grad/param norm = 2.2414e-01, time/batch = 17.7379s	
15088/22750 (epoch 33.160), train_loss = 0.80490015, grad/param norm = 2.1976e-01, time/batch = 18.3364s	
15089/22750 (epoch 33.163), train_loss = 0.94514847, grad/param norm = 2.3518e-01, time/batch = 19.3264s	
15090/22750 (epoch 33.165), train_loss = 0.84635319, grad/param norm = 2.1192e-01, time/batch = 20.2514s	
15091/22750 (epoch 33.167), train_loss = 0.75289342, grad/param norm = 2.4557e-01, time/batch = 30.2032s	
15092/22750 (epoch 33.169), train_loss = 0.82002368, grad/param norm = 2.3175e-01, time/batch = 20.8229s	
15093/22750 (epoch 33.171), train_loss = 0.69341226, grad/param norm = 2.0785e-01, time/batch = 16.3118s	
15094/22750 (epoch 33.174), train_loss = 0.67582822, grad/param norm = 2.0867e-01, time/batch = 16.8543s	
15095/22750 (epoch 33.176), train_loss = 0.71136916, grad/param norm = 2.2829e-01, time/batch = 16.2812s	
15096/22750 (epoch 33.178), train_loss = 0.73990866, grad/param norm = 2.1438e-01, time/batch = 17.0826s	
15097/22750 (epoch 33.180), train_loss = 0.95975799, grad/param norm = 3.7946e-01, time/batch = 17.8383s	
15098/22750 (epoch 33.182), train_loss = 0.87861826, grad/param norm = 2.5372e-01, time/batch = 16.7667s	
15099/22750 (epoch 33.185), train_loss = 0.90351872, grad/param norm = 2.4328e-01, time/batch = 18.6049s	
15100/22750 (epoch 33.187), train_loss = 0.68923833, grad/param norm = 1.8969e-01, time/batch = 17.4568s	
15101/22750 (epoch 33.189), train_loss = 0.72071152, grad/param norm = 2.4289e-01, time/batch = 18.8415s	
15102/22750 (epoch 33.191), train_loss = 0.74147990, grad/param norm = 2.1894e-01, time/batch = 20.0071s	
15103/22750 (epoch 33.193), train_loss = 0.86542791, grad/param norm = 2.2065e-01, time/batch = 18.9169s	
15104/22750 (epoch 33.196), train_loss = 0.77404732, grad/param norm = 2.3207e-01, time/batch = 17.5750s	
15105/22750 (epoch 33.198), train_loss = 0.59647188, grad/param norm = 1.9004e-01, time/batch = 18.5768s	
15106/22750 (epoch 33.200), train_loss = 0.80578577, grad/param norm = 2.4865e-01, time/batch = 17.8556s	
15107/22750 (epoch 33.202), train_loss = 0.86691001, grad/param norm = 2.5522e-01, time/batch = 17.0941s	
15108/22750 (epoch 33.204), train_loss = 0.80738498, grad/param norm = 2.0196e-01, time/batch = 19.6816s	
15109/22750 (epoch 33.207), train_loss = 0.80803292, grad/param norm = 2.2852e-01, time/batch = 19.3734s	
15110/22750 (epoch 33.209), train_loss = 0.74807905, grad/param norm = 2.2250e-01, time/batch = 18.1895s	
15111/22750 (epoch 33.211), train_loss = 0.72016598, grad/param norm = 2.6594e-01, time/batch = 19.2566s	
15112/22750 (epoch 33.213), train_loss = 0.62420886, grad/param norm = 2.0261e-01, time/batch = 18.9163s	
15113/22750 (epoch 33.215), train_loss = 0.59767329, grad/param norm = 1.7624e-01, time/batch = 19.0088s	
15114/22750 (epoch 33.218), train_loss = 0.70178227, grad/param norm = 2.3463e-01, time/batch = 17.4204s	
15115/22750 (epoch 33.220), train_loss = 0.64949644, grad/param norm = 2.2144e-01, time/batch = 18.4885s	
15116/22750 (epoch 33.222), train_loss = 0.67274216, grad/param norm = 2.1383e-01, time/batch = 18.0561s	
15117/22750 (epoch 33.224), train_loss = 0.70231804, grad/param norm = 1.9533e-01, time/batch = 17.8137s	
15118/22750 (epoch 33.226), train_loss = 0.77821278, grad/param norm = 2.1212e-01, time/batch = 18.1591s	
15119/22750 (epoch 33.229), train_loss = 0.80680866, grad/param norm = 2.1473e-01, time/batch = 19.8295s	
15120/22750 (epoch 33.231), train_loss = 0.67795958, grad/param norm = 1.8970e-01, time/batch = 16.6917s	
15121/22750 (epoch 33.233), train_loss = 0.64722156, grad/param norm = 2.3009e-01, time/batch = 16.7343s	
15122/22750 (epoch 33.235), train_loss = 0.62073705, grad/param norm = 2.2319e-01, time/batch = 18.1598s	
15123/22750 (epoch 33.237), train_loss = 0.69918868, grad/param norm = 2.0445e-01, time/batch = 18.3169s	
15124/22750 (epoch 33.240), train_loss = 0.76724708, grad/param norm = 2.0090e-01, time/batch = 18.3874s	
15125/22750 (epoch 33.242), train_loss = 0.94470095, grad/param norm = 2.7329e-01, time/batch = 17.3342s	
15126/22750 (epoch 33.244), train_loss = 0.94495403, grad/param norm = 2.3637e-01, time/batch = 18.9937s	
15127/22750 (epoch 33.246), train_loss = 0.94292391, grad/param norm = 2.4416e-01, time/batch = 19.2508s	
15128/22750 (epoch 33.248), train_loss = 0.78507512, grad/param norm = 2.0167e-01, time/batch = 20.0106s	
15129/22750 (epoch 33.251), train_loss = 0.90064630, grad/param norm = 2.2413e-01, time/batch = 19.3332s	
15130/22750 (epoch 33.253), train_loss = 0.84054095, grad/param norm = 2.5932e-01, time/batch = 17.0745s	
15131/22750 (epoch 33.255), train_loss = 0.81325695, grad/param norm = 2.3284e-01, time/batch = 18.6393s	
15132/22750 (epoch 33.257), train_loss = 0.72533875, grad/param norm = 2.3995e-01, time/batch = 19.2326s	
15133/22750 (epoch 33.259), train_loss = 0.90776427, grad/param norm = 2.6568e-01, time/batch = 17.0429s	
15134/22750 (epoch 33.262), train_loss = 0.81730771, grad/param norm = 2.4983e-01, time/batch = 18.2344s	
15135/22750 (epoch 33.264), train_loss = 0.64090936, grad/param norm = 2.6175e-01, time/batch = 18.1321s	
15136/22750 (epoch 33.266), train_loss = 0.76693921, grad/param norm = 2.5173e-01, time/batch = 18.6797s	
15137/22750 (epoch 33.268), train_loss = 0.92807070, grad/param norm = 2.6604e-01, time/batch = 18.0901s	
15138/22750 (epoch 33.270), train_loss = 0.70973428, grad/param norm = 2.3847e-01, time/batch = 19.5719s	
15139/22750 (epoch 33.273), train_loss = 1.04618262, grad/param norm = 2.6518e-01, time/batch = 18.2327s	
15140/22750 (epoch 33.275), train_loss = 0.95390325, grad/param norm = 2.3926e-01, time/batch = 19.3867s	
15141/22750 (epoch 33.277), train_loss = 0.79496824, grad/param norm = 2.7414e-01, time/batch = 19.2278s	
15142/22750 (epoch 33.279), train_loss = 0.67642732, grad/param norm = 2.1117e-01, time/batch = 18.8871s	
15143/22750 (epoch 33.281), train_loss = 0.94393426, grad/param norm = 2.5812e-01, time/batch = 19.9727s	
15144/22750 (epoch 33.284), train_loss = 0.81871664, grad/param norm = 1.9884e-01, time/batch = 19.5927s	
15145/22750 (epoch 33.286), train_loss = 0.86915381, grad/param norm = 2.3283e-01, time/batch = 18.0701s	
15146/22750 (epoch 33.288), train_loss = 0.96481732, grad/param norm = 2.4374e-01, time/batch = 17.8624s	
15147/22750 (epoch 33.290), train_loss = 0.82944102, grad/param norm = 2.1304e-01, time/batch = 20.2301s	
15148/22750 (epoch 33.292), train_loss = 0.89906760, grad/param norm = 2.7857e-01, time/batch = 19.6562s	
15149/22750 (epoch 33.295), train_loss = 0.82244293, grad/param norm = 2.1304e-01, time/batch = 18.2294s	
15150/22750 (epoch 33.297), train_loss = 0.81650594, grad/param norm = 2.3165e-01, time/batch = 18.4116s	
15151/22750 (epoch 33.299), train_loss = 0.88326110, grad/param norm = 2.3638e-01, time/batch = 19.4847s	
15152/22750 (epoch 33.301), train_loss = 0.82019155, grad/param norm = 2.2059e-01, time/batch = 16.9202s	
15153/22750 (epoch 33.303), train_loss = 0.87113383, grad/param norm = 2.4035e-01, time/batch = 21.0636s	
15154/22750 (epoch 33.305), train_loss = 0.96949570, grad/param norm = 2.3623e-01, time/batch = 20.4046s	
15155/22750 (epoch 33.308), train_loss = 0.86537773, grad/param norm = 2.0707e-01, time/batch = 17.4950s	
15156/22750 (epoch 33.310), train_loss = 0.74676568, grad/param norm = 2.2878e-01, time/batch = 18.3914s	
15157/22750 (epoch 33.312), train_loss = 0.84612365, grad/param norm = 2.2540e-01, time/batch = 16.7219s	
15158/22750 (epoch 33.314), train_loss = 0.82866109, grad/param norm = 2.2552e-01, time/batch = 16.9836s	
15159/22750 (epoch 33.316), train_loss = 0.78254499, grad/param norm = 2.4354e-01, time/batch = 18.8879s	
15160/22750 (epoch 33.319), train_loss = 0.84326819, grad/param norm = 2.5766e-01, time/batch = 17.7262s	
15161/22750 (epoch 33.321), train_loss = 0.75632655, grad/param norm = 2.4116e-01, time/batch = 19.5517s	
15162/22750 (epoch 33.323), train_loss = 0.84207786, grad/param norm = 2.4673e-01, time/batch = 18.8199s	
15163/22750 (epoch 33.325), train_loss = 0.72449682, grad/param norm = 1.9112e-01, time/batch = 18.2254s	
15164/22750 (epoch 33.327), train_loss = 0.76498383, grad/param norm = 2.3328e-01, time/batch = 20.0602s	
15165/22750 (epoch 33.330), train_loss = 0.95833154, grad/param norm = 2.4794e-01, time/batch = 17.6390s	
15166/22750 (epoch 33.332), train_loss = 0.98253871, grad/param norm = 2.0764e-01, time/batch = 18.8864s	
15167/22750 (epoch 33.334), train_loss = 0.65764876, grad/param norm = 1.9729e-01, time/batch = 16.6391s	
15168/22750 (epoch 33.336), train_loss = 0.89074687, grad/param norm = 1.9725e-01, time/batch = 16.9059s	
15169/22750 (epoch 33.338), train_loss = 0.80367871, grad/param norm = 2.2678e-01, time/batch = 15.7611s	
15170/22750 (epoch 33.341), train_loss = 0.82646158, grad/param norm = 2.3153e-01, time/batch = 16.6482s	
15171/22750 (epoch 33.343), train_loss = 0.71831410, grad/param norm = 2.2377e-01, time/batch = 18.6687s	
15172/22750 (epoch 33.345), train_loss = 0.87930038, grad/param norm = 2.6108e-01, time/batch = 18.7326s	
15173/22750 (epoch 33.347), train_loss = 0.92589437, grad/param norm = 2.5557e-01, time/batch = 18.9196s	
15174/22750 (epoch 33.349), train_loss = 0.64588546, grad/param norm = 2.0994e-01, time/batch = 16.6913s	
15175/22750 (epoch 33.352), train_loss = 0.93560921, grad/param norm = 2.4778e-01, time/batch = 17.4048s	
15176/22750 (epoch 33.354), train_loss = 0.92457988, grad/param norm = 2.3972e-01, time/batch = 17.9024s	
15177/22750 (epoch 33.356), train_loss = 0.88654363, grad/param norm = 2.3292e-01, time/batch = 16.4071s	
15178/22750 (epoch 33.358), train_loss = 0.79338584, grad/param norm = 2.1893e-01, time/batch = 19.1407s	
15179/22750 (epoch 33.360), train_loss = 0.95670500, grad/param norm = 2.2027e-01, time/batch = 18.8145s	
15180/22750 (epoch 33.363), train_loss = 0.79513340, grad/param norm = 2.7501e-01, time/batch = 18.6330s	
15181/22750 (epoch 33.365), train_loss = 0.64242437, grad/param norm = 2.0156e-01, time/batch = 18.1829s	
15182/22750 (epoch 33.367), train_loss = 0.74473428, grad/param norm = 2.3512e-01, time/batch = 18.5788s	
15183/22750 (epoch 33.369), train_loss = 0.82895338, grad/param norm = 2.4481e-01, time/batch = 20.3088s	
15184/22750 (epoch 33.371), train_loss = 0.83182548, grad/param norm = 2.3000e-01, time/batch = 19.3893s	
15185/22750 (epoch 33.374), train_loss = 0.72964038, grad/param norm = 2.2599e-01, time/batch = 18.3976s	
15186/22750 (epoch 33.376), train_loss = 0.80451473, grad/param norm = 2.0653e-01, time/batch = 18.0664s	
15187/22750 (epoch 33.378), train_loss = 0.81662439, grad/param norm = 2.1072e-01, time/batch = 17.9845s	
15188/22750 (epoch 33.380), train_loss = 0.88814093, grad/param norm = 2.1740e-01, time/batch = 16.9664s	
15189/22750 (epoch 33.382), train_loss = 0.80745396, grad/param norm = 2.1377e-01, time/batch = 16.5925s	
15190/22750 (epoch 33.385), train_loss = 0.87217624, grad/param norm = 2.2249e-01, time/batch = 16.7467s	
15191/22750 (epoch 33.387), train_loss = 0.85317761, grad/param norm = 2.0685e-01, time/batch = 16.6057s	
15192/22750 (epoch 33.389), train_loss = 0.66660489, grad/param norm = 1.8947e-01, time/batch = 16.9278s	
15193/22750 (epoch 33.391), train_loss = 0.50835770, grad/param norm = 1.6865e-01, time/batch = 16.7507s	
15194/22750 (epoch 33.393), train_loss = 0.67390998, grad/param norm = 2.1095e-01, time/batch = 16.7545s	
15195/22750 (epoch 33.396), train_loss = 0.84551722, grad/param norm = 2.1880e-01, time/batch = 17.2263s	
15196/22750 (epoch 33.398), train_loss = 0.78040611, grad/param norm = 2.1345e-01, time/batch = 16.9082s	
15197/22750 (epoch 33.400), train_loss = 0.80790840, grad/param norm = 2.2423e-01, time/batch = 16.7448s	
15198/22750 (epoch 33.402), train_loss = 0.84552271, grad/param norm = 2.1051e-01, time/batch = 16.6812s	
15199/22750 (epoch 33.404), train_loss = 0.91657027, grad/param norm = 2.1758e-01, time/batch = 17.0653s	
15200/22750 (epoch 33.407), train_loss = 0.89941491, grad/param norm = 2.2187e-01, time/batch = 16.6888s	
15201/22750 (epoch 33.409), train_loss = 0.74219113, grad/param norm = 2.8436e-01, time/batch = 16.6993s	
15202/22750 (epoch 33.411), train_loss = 0.76134859, grad/param norm = 2.4126e-01, time/batch = 16.8509s	
15203/22750 (epoch 33.413), train_loss = 0.59740703, grad/param norm = 1.9923e-01, time/batch = 16.8373s	
15204/22750 (epoch 33.415), train_loss = 0.65128058, grad/param norm = 1.9736e-01, time/batch = 17.0497s	
15205/22750 (epoch 33.418), train_loss = 0.77694106, grad/param norm = 2.3856e-01, time/batch = 16.7595s	
15206/22750 (epoch 33.420), train_loss = 0.87276715, grad/param norm = 2.5466e-01, time/batch = 17.3168s	
15207/22750 (epoch 33.422), train_loss = 1.02670340, grad/param norm = 2.9513e-01, time/batch = 17.0768s	
15208/22750 (epoch 33.424), train_loss = 0.98705219, grad/param norm = 2.5769e-01, time/batch = 17.0016s	
15209/22750 (epoch 33.426), train_loss = 0.98142194, grad/param norm = 2.1718e-01, time/batch = 16.9355s	
15210/22750 (epoch 33.429), train_loss = 0.74447735, grad/param norm = 2.1388e-01, time/batch = 17.0189s	
15211/22750 (epoch 33.431), train_loss = 0.67351507, grad/param norm = 2.0490e-01, time/batch = 16.7850s	
15212/22750 (epoch 33.433), train_loss = 0.76397476, grad/param norm = 2.1168e-01, time/batch = 16.6648s	
15213/22750 (epoch 33.435), train_loss = 0.60567379, grad/param norm = 1.8234e-01, time/batch = 16.6761s	
15214/22750 (epoch 33.437), train_loss = 0.52568963, grad/param norm = 2.0353e-01, time/batch = 16.4282s	
15215/22750 (epoch 33.440), train_loss = 0.76086641, grad/param norm = 2.4441e-01, time/batch = 16.5739s	
15216/22750 (epoch 33.442), train_loss = 0.79857703, grad/param norm = 2.3024e-01, time/batch = 16.6598s	
15217/22750 (epoch 33.444), train_loss = 0.77223705, grad/param norm = 2.3526e-01, time/batch = 16.8428s	
15218/22750 (epoch 33.446), train_loss = 0.78975446, grad/param norm = 2.3832e-01, time/batch = 17.1264s	
15219/22750 (epoch 33.448), train_loss = 1.01049754, grad/param norm = 2.3997e-01, time/batch = 16.9969s	
15220/22750 (epoch 33.451), train_loss = 0.98471212, grad/param norm = 2.2142e-01, time/batch = 16.8533s	
15221/22750 (epoch 33.453), train_loss = 0.89050845, grad/param norm = 2.6442e-01, time/batch = 17.0206s	
15222/22750 (epoch 33.455), train_loss = 0.97816028, grad/param norm = 2.3597e-01, time/batch = 16.6164s	
15223/22750 (epoch 33.457), train_loss = 0.89614617, grad/param norm = 4.0085e-01, time/batch = 16.8290s	
15224/22750 (epoch 33.459), train_loss = 0.87305018, grad/param norm = 2.2429e-01, time/batch = 16.9890s	
15225/22750 (epoch 33.462), train_loss = 0.86515132, grad/param norm = 2.2013e-01, time/batch = 16.8173s	
15226/22750 (epoch 33.464), train_loss = 0.70115203, grad/param norm = 2.1140e-01, time/batch = 16.7565s	
15227/22750 (epoch 33.466), train_loss = 0.90480332, grad/param norm = 3.0371e-01, time/batch = 17.0062s	
15228/22750 (epoch 33.468), train_loss = 0.83966608, grad/param norm = 2.2390e-01, time/batch = 16.9948s	
15229/22750 (epoch 33.470), train_loss = 0.93593371, grad/param norm = 2.3662e-01, time/batch = 16.7699s	
15230/22750 (epoch 33.473), train_loss = 0.79688887, grad/param norm = 2.1821e-01, time/batch = 16.7772s	
15231/22750 (epoch 33.475), train_loss = 0.84112925, grad/param norm = 2.6201e-01, time/batch = 17.0201s	
15232/22750 (epoch 33.477), train_loss = 0.72526515, grad/param norm = 2.2112e-01, time/batch = 16.7773s	
15233/22750 (epoch 33.479), train_loss = 0.69117195, grad/param norm = 2.0614e-01, time/batch = 16.7481s	
15234/22750 (epoch 33.481), train_loss = 0.67779075, grad/param norm = 1.9572e-01, time/batch = 17.1511s	
15235/22750 (epoch 33.484), train_loss = 0.56772366, grad/param norm = 1.9989e-01, time/batch = 16.6756s	
15236/22750 (epoch 33.486), train_loss = 0.68929437, grad/param norm = 2.2992e-01, time/batch = 16.7503s	
15237/22750 (epoch 33.488), train_loss = 0.61096959, grad/param norm = 1.9704e-01, time/batch = 16.8879s	
15238/22750 (epoch 33.490), train_loss = 0.79430408, grad/param norm = 2.1471e-01, time/batch = 16.8373s	
15239/22750 (epoch 33.492), train_loss = 0.88193811, grad/param norm = 2.2161e-01, time/batch = 16.7619s	
15240/22750 (epoch 33.495), train_loss = 0.73142487, grad/param norm = 2.2091e-01, time/batch = 16.7838s	
15241/22750 (epoch 33.497), train_loss = 0.77772582, grad/param norm = 2.3173e-01, time/batch = 17.1591s	
15242/22750 (epoch 33.499), train_loss = 0.72217795, grad/param norm = 2.3100e-01, time/batch = 16.9351s	
15243/22750 (epoch 33.501), train_loss = 0.78175380, grad/param norm = 2.3297e-01, time/batch = 16.9933s	
15244/22750 (epoch 33.503), train_loss = 0.78861789, grad/param norm = 2.4424e-01, time/batch = 16.8415s	
15245/22750 (epoch 33.505), train_loss = 0.69531339, grad/param norm = 2.4043e-01, time/batch = 17.0042s	
15246/22750 (epoch 33.508), train_loss = 0.64012423, grad/param norm = 2.1726e-01, time/batch = 16.7394s	
15247/22750 (epoch 33.510), train_loss = 0.69322970, grad/param norm = 2.0551e-01, time/batch = 16.8974s	
15248/22750 (epoch 33.512), train_loss = 0.71861685, grad/param norm = 2.0777e-01, time/batch = 17.2950s	
15249/22750 (epoch 33.514), train_loss = 0.74451186, grad/param norm = 2.1683e-01, time/batch = 16.8450s	
15250/22750 (epoch 33.516), train_loss = 0.74984081, grad/param norm = 2.3498e-01, time/batch = 16.8504s	
15251/22750 (epoch 33.519), train_loss = 0.85280923, grad/param norm = 2.2077e-01, time/batch = 16.6142s	
15252/22750 (epoch 33.521), train_loss = 0.78825450, grad/param norm = 2.3809e-01, time/batch = 16.9991s	
15253/22750 (epoch 33.523), train_loss = 0.72506188, grad/param norm = 2.5206e-01, time/batch = 16.7583s	
15254/22750 (epoch 33.525), train_loss = 0.93050326, grad/param norm = 2.7223e-01, time/batch = 16.6591s	
15255/22750 (epoch 33.527), train_loss = 0.78895580, grad/param norm = 2.1163e-01, time/batch = 16.9048s	
15256/22750 (epoch 33.530), train_loss = 0.72283313, grad/param norm = 2.3661e-01, time/batch = 16.5896s	
15257/22750 (epoch 33.532), train_loss = 0.67503805, grad/param norm = 1.9831e-01, time/batch = 17.0126s	
15258/22750 (epoch 33.534), train_loss = 0.87266160, grad/param norm = 2.5818e-01, time/batch = 20.3067s	
15259/22750 (epoch 33.536), train_loss = 0.84001243, grad/param norm = 2.2188e-01, time/batch = 17.3405s	
15260/22750 (epoch 33.538), train_loss = 0.81086571, grad/param norm = 2.0330e-01, time/batch = 16.7309s	
15261/22750 (epoch 33.541), train_loss = 0.70640428, grad/param norm = 2.3958e-01, time/batch = 17.6794s	
15262/22750 (epoch 33.543), train_loss = 0.69350443, grad/param norm = 2.1705e-01, time/batch = 16.8538s	
15263/22750 (epoch 33.545), train_loss = 0.85731486, grad/param norm = 2.1489e-01, time/batch = 18.3428s	
15264/22750 (epoch 33.547), train_loss = 0.73267375, grad/param norm = 2.0350e-01, time/batch = 18.4855s	
15265/22750 (epoch 33.549), train_loss = 0.77167803, grad/param norm = 2.1178e-01, time/batch = 18.9821s	
15266/22750 (epoch 33.552), train_loss = 0.83003291, grad/param norm = 2.0756e-01, time/batch = 18.9923s	
15267/22750 (epoch 33.554), train_loss = 0.87533309, grad/param norm = 2.3193e-01, time/batch = 17.4236s	
15268/22750 (epoch 33.556), train_loss = 0.84170879, grad/param norm = 2.2801e-01, time/batch = 16.0298s	
15269/22750 (epoch 33.558), train_loss = 0.81900771, grad/param norm = 2.3520e-01, time/batch = 18.4294s	
15270/22750 (epoch 33.560), train_loss = 0.77453550, grad/param norm = 2.2010e-01, time/batch = 17.0452s	
15271/22750 (epoch 33.563), train_loss = 0.87870359, grad/param norm = 2.2551e-01, time/batch = 20.6647s	
15272/22750 (epoch 33.565), train_loss = 0.86257160, grad/param norm = 2.3461e-01, time/batch = 18.1660s	
15273/22750 (epoch 33.567), train_loss = 0.84807781, grad/param norm = 2.2171e-01, time/batch = 20.2422s	
15274/22750 (epoch 33.569), train_loss = 0.77083266, grad/param norm = 2.1743e-01, time/batch = 18.5076s	
15275/22750 (epoch 33.571), train_loss = 0.78351549, grad/param norm = 2.2938e-01, time/batch = 17.1632s	
15276/22750 (epoch 33.574), train_loss = 0.80084329, grad/param norm = 2.1500e-01, time/batch = 19.3128s	
15277/22750 (epoch 33.576), train_loss = 0.78395614, grad/param norm = 2.4920e-01, time/batch = 19.1745s	
15278/22750 (epoch 33.578), train_loss = 0.67661200, grad/param norm = 2.1935e-01, time/batch = 17.5716s	
15279/22750 (epoch 33.580), train_loss = 0.84631701, grad/param norm = 2.4711e-01, time/batch = 19.7673s	
15280/22750 (epoch 33.582), train_loss = 0.70583016, grad/param norm = 1.8825e-01, time/batch = 20.4951s	
15281/22750 (epoch 33.585), train_loss = 0.69740598, grad/param norm = 2.0643e-01, time/batch = 17.9926s	
15282/22750 (epoch 33.587), train_loss = 0.71742765, grad/param norm = 2.0534e-01, time/batch = 19.4038s	
15283/22750 (epoch 33.589), train_loss = 0.60094478, grad/param norm = 1.8837e-01, time/batch = 18.9977s	
15284/22750 (epoch 33.591), train_loss = 0.77396492, grad/param norm = 2.2296e-01, time/batch = 17.1655s	
15285/22750 (epoch 33.593), train_loss = 0.91407256, grad/param norm = 2.1719e-01, time/batch = 17.9149s	
15286/22750 (epoch 33.596), train_loss = 0.90694820, grad/param norm = 2.6030e-01, time/batch = 16.9619s	
15287/22750 (epoch 33.598), train_loss = 0.93023652, grad/param norm = 2.7171e-01, time/batch = 18.1032s	
15288/22750 (epoch 33.600), train_loss = 0.92826636, grad/param norm = 2.5282e-01, time/batch = 18.2376s	
15289/22750 (epoch 33.602), train_loss = 0.71895682, grad/param norm = 1.9860e-01, time/batch = 19.9253s	
15290/22750 (epoch 33.604), train_loss = 0.75957449, grad/param norm = 2.5883e-01, time/batch = 19.6502s	
15291/22750 (epoch 33.607), train_loss = 0.68692850, grad/param norm = 1.8430e-01, time/batch = 32.0396s	
15292/22750 (epoch 33.609), train_loss = 0.64349199, grad/param norm = 1.9105e-01, time/batch = 19.8093s	
15293/22750 (epoch 33.611), train_loss = 0.74864168, grad/param norm = 2.1576e-01, time/batch = 19.5658s	
15294/22750 (epoch 33.613), train_loss = 0.72633208, grad/param norm = 2.2921e-01, time/batch = 19.4271s	
15295/22750 (epoch 33.615), train_loss = 0.72954140, grad/param norm = 1.6815e-01, time/batch = 20.3515s	
15296/22750 (epoch 33.618), train_loss = 0.76113948, grad/param norm = 1.9798e-01, time/batch = 16.0734s	
15297/22750 (epoch 33.620), train_loss = 0.75634326, grad/param norm = 2.3416e-01, time/batch = 16.4227s	
15298/22750 (epoch 33.622), train_loss = 0.63362607, grad/param norm = 1.7295e-01, time/batch = 16.7309s	
15299/22750 (epoch 33.624), train_loss = 0.74402595, grad/param norm = 2.4069e-01, time/batch = 17.4109s	
15300/22750 (epoch 33.626), train_loss = 0.63342688, grad/param norm = 2.0002e-01, time/batch = 16.5133s	
15301/22750 (epoch 33.629), train_loss = 0.72187770, grad/param norm = 1.9310e-01, time/batch = 19.3944s	
15302/22750 (epoch 33.631), train_loss = 0.78101089, grad/param norm = 1.9630e-01, time/batch = 19.0766s	
15303/22750 (epoch 33.633), train_loss = 0.65709523, grad/param norm = 2.0784e-01, time/batch = 17.6715s	
15304/22750 (epoch 33.635), train_loss = 0.75962972, grad/param norm = 2.1405e-01, time/batch = 18.8534s	
15305/22750 (epoch 33.637), train_loss = 0.82638152, grad/param norm = 2.7252e-01, time/batch = 20.0022s	
15306/22750 (epoch 33.640), train_loss = 0.86316727, grad/param norm = 2.3197e-01, time/batch = 16.1184s	
15307/22750 (epoch 33.642), train_loss = 0.89512904, grad/param norm = 2.3029e-01, time/batch = 18.6441s	
15308/22750 (epoch 33.644), train_loss = 0.78642424, grad/param norm = 2.4174e-01, time/batch = 19.4856s	
15309/22750 (epoch 33.646), train_loss = 0.84188482, grad/param norm = 2.5091e-01, time/batch = 20.4905s	
15310/22750 (epoch 33.648), train_loss = 0.83118656, grad/param norm = 2.2839e-01, time/batch = 18.3237s	
15311/22750 (epoch 33.651), train_loss = 0.83991610, grad/param norm = 2.1751e-01, time/batch = 19.6620s	
15312/22750 (epoch 33.653), train_loss = 0.85773711, grad/param norm = 1.9810e-01, time/batch = 20.0199s	
15313/22750 (epoch 33.655), train_loss = 0.79859028, grad/param norm = 2.0585e-01, time/batch = 17.5785s	
15314/22750 (epoch 33.657), train_loss = 0.93712715, grad/param norm = 2.4488e-01, time/batch = 20.0193s	
15315/22750 (epoch 33.659), train_loss = 0.97164535, grad/param norm = 2.2481e-01, time/batch = 20.0011s	
15316/22750 (epoch 33.662), train_loss = 0.95727101, grad/param norm = 2.7090e-01, time/batch = 16.5899s	
15317/22750 (epoch 33.664), train_loss = 0.85084547, grad/param norm = 2.3144e-01, time/batch = 18.7464s	
15318/22750 (epoch 33.666), train_loss = 0.67950725, grad/param norm = 2.2283e-01, time/batch = 19.8114s	
15319/22750 (epoch 33.668), train_loss = 0.79284244, grad/param norm = 2.2144e-01, time/batch = 18.4297s	
15320/22750 (epoch 33.670), train_loss = 0.76122802, grad/param norm = 2.1240e-01, time/batch = 19.9847s	
15321/22750 (epoch 33.673), train_loss = 0.96667941, grad/param norm = 2.5043e-01, time/batch = 20.5949s	
15322/22750 (epoch 33.675), train_loss = 1.08779813, grad/param norm = 2.8655e-01, time/batch = 17.5265s	
15323/22750 (epoch 33.677), train_loss = 0.96265404, grad/param norm = 2.6107e-01, time/batch = 18.1056s	
15324/22750 (epoch 33.679), train_loss = 0.96375111, grad/param norm = 2.8468e-01, time/batch = 17.0736s	
15325/22750 (epoch 33.681), train_loss = 0.94212105, grad/param norm = 2.4100e-01, time/batch = 18.8301s	
15326/22750 (epoch 33.684), train_loss = 0.97585945, grad/param norm = 2.3660e-01, time/batch = 18.8284s	
15327/22750 (epoch 33.686), train_loss = 0.99086799, grad/param norm = 2.5597e-01, time/batch = 17.6781s	
15328/22750 (epoch 33.688), train_loss = 0.96090325, grad/param norm = 2.6510e-01, time/batch = 18.9216s	
15329/22750 (epoch 33.690), train_loss = 0.94896233, grad/param norm = 2.6978e-01, time/batch = 16.9226s	
15330/22750 (epoch 33.692), train_loss = 0.93382936, grad/param norm = 2.4404e-01, time/batch = 19.8336s	
15331/22750 (epoch 33.695), train_loss = 0.83866714, grad/param norm = 2.1154e-01, time/batch = 18.6622s	
15332/22750 (epoch 33.697), train_loss = 0.84053874, grad/param norm = 2.1882e-01, time/batch = 17.5070s	
15333/22750 (epoch 33.699), train_loss = 0.76997448, grad/param norm = 2.0013e-01, time/batch = 21.3417s	
15334/22750 (epoch 33.701), train_loss = 0.69555621, grad/param norm = 2.3032e-01, time/batch = 19.3246s	
15335/22750 (epoch 33.703), train_loss = 0.76753495, grad/param norm = 2.1291e-01, time/batch = 17.4126s	
15336/22750 (epoch 33.705), train_loss = 0.74154143, grad/param norm = 1.9921e-01, time/batch = 17.8158s	
15337/22750 (epoch 33.708), train_loss = 0.84213448, grad/param norm = 2.5978e-01, time/batch = 15.8075s	
15338/22750 (epoch 33.710), train_loss = 0.71509347, grad/param norm = 2.3284e-01, time/batch = 16.6737s	
15339/22750 (epoch 33.712), train_loss = 0.68032853, grad/param norm = 2.1753e-01, time/batch = 17.4791s	
15340/22750 (epoch 33.714), train_loss = 0.67685908, grad/param norm = 2.3092e-01, time/batch = 19.9956s	
15341/22750 (epoch 33.716), train_loss = 0.69786600, grad/param norm = 2.0854e-01, time/batch = 17.4285s	
15342/22750 (epoch 33.719), train_loss = 0.76580850, grad/param norm = 2.4020e-01, time/batch = 16.9081s	
15343/22750 (epoch 33.721), train_loss = 0.87439409, grad/param norm = 2.1214e-01, time/batch = 17.5688s	
15344/22750 (epoch 33.723), train_loss = 0.88376924, grad/param norm = 2.7889e-01, time/batch = 17.6629s	
15345/22750 (epoch 33.725), train_loss = 0.76379401, grad/param norm = 2.3941e-01, time/batch = 17.2472s	
15346/22750 (epoch 33.727), train_loss = 0.77690543, grad/param norm = 2.3687e-01, time/batch = 15.7433s	
15347/22750 (epoch 33.730), train_loss = 0.77727052, grad/param norm = 2.2711e-01, time/batch = 15.4139s	
15348/22750 (epoch 33.732), train_loss = 0.73761498, grad/param norm = 2.1313e-01, time/batch = 16.5651s	
15349/22750 (epoch 33.734), train_loss = 0.64855901, grad/param norm = 1.8204e-01, time/batch = 17.8762s	
15350/22750 (epoch 33.736), train_loss = 0.75357608, grad/param norm = 2.2342e-01, time/batch = 19.5336s	
15351/22750 (epoch 33.738), train_loss = 0.83981415, grad/param norm = 2.3924e-01, time/batch = 19.0359s	
15352/22750 (epoch 33.741), train_loss = 0.92733954, grad/param norm = 2.2567e-01, time/batch = 17.6306s	
15353/22750 (epoch 33.743), train_loss = 0.84699021, grad/param norm = 2.2921e-01, time/batch = 16.8967s	
15354/22750 (epoch 33.745), train_loss = 0.68132459, grad/param norm = 1.9474e-01, time/batch = 19.1096s	
15355/22750 (epoch 33.747), train_loss = 0.79082655, grad/param norm = 1.9962e-01, time/batch = 18.0419s	
15356/22750 (epoch 33.749), train_loss = 0.92096214, grad/param norm = 2.5498e-01, time/batch = 17.4526s	
15357/22750 (epoch 33.752), train_loss = 0.81458500, grad/param norm = 2.4454e-01, time/batch = 18.1179s	
15358/22750 (epoch 33.754), train_loss = 0.82186854, grad/param norm = 2.5171e-01, time/batch = 18.3685s	
15359/22750 (epoch 33.756), train_loss = 0.74819910, grad/param norm = 2.4600e-01, time/batch = 17.3959s	
15360/22750 (epoch 33.758), train_loss = 0.72017367, grad/param norm = 2.0260e-01, time/batch = 19.2789s	
15361/22750 (epoch 33.760), train_loss = 0.74279327, grad/param norm = 2.4238e-01, time/batch = 19.7049s	
15362/22750 (epoch 33.763), train_loss = 0.80718210, grad/param norm = 2.6137e-01, time/batch = 16.7166s	
15363/22750 (epoch 33.765), train_loss = 0.77595067, grad/param norm = 2.3152e-01, time/batch = 17.2191s	
15364/22750 (epoch 33.767), train_loss = 0.83525169, grad/param norm = 2.2111e-01, time/batch = 16.2360s	
15365/22750 (epoch 33.769), train_loss = 0.95071045, grad/param norm = 2.6452e-01, time/batch = 16.5697s	
15366/22750 (epoch 33.771), train_loss = 0.98650615, grad/param norm = 2.8326e-01, time/batch = 16.1440s	
15367/22750 (epoch 33.774), train_loss = 0.77779293, grad/param norm = 2.8346e-01, time/batch = 16.2138s	
15368/22750 (epoch 33.776), train_loss = 0.91189968, grad/param norm = 2.6837e-01, time/batch = 18.2884s	
15369/22750 (epoch 33.778), train_loss = 0.97127498, grad/param norm = 2.8562e-01, time/batch = 19.4682s	
15370/22750 (epoch 33.780), train_loss = 0.83566465, grad/param norm = 2.4044e-01, time/batch = 19.1272s	
15371/22750 (epoch 33.782), train_loss = 0.98116554, grad/param norm = 2.3488e-01, time/batch = 17.9257s	
15372/22750 (epoch 33.785), train_loss = 0.80856675, grad/param norm = 2.7307e-01, time/batch = 16.8218s	
15373/22750 (epoch 33.787), train_loss = 0.68879821, grad/param norm = 2.1241e-01, time/batch = 18.1294s	
15374/22750 (epoch 33.789), train_loss = 0.78097591, grad/param norm = 2.0063e-01, time/batch = 17.3108s	
15375/22750 (epoch 33.791), train_loss = 0.75666638, grad/param norm = 2.1542e-01, time/batch = 15.7414s	
15376/22750 (epoch 33.793), train_loss = 0.75129253, grad/param norm = 2.8596e-01, time/batch = 16.6481s	
15377/22750 (epoch 33.796), train_loss = 0.68976389, grad/param norm = 2.0960e-01, time/batch = 20.0831s	
15378/22750 (epoch 33.798), train_loss = 0.75031380, grad/param norm = 2.1704e-01, time/batch = 20.3591s	
15379/22750 (epoch 33.800), train_loss = 0.73356049, grad/param norm = 2.2879e-01, time/batch = 18.9482s	
15380/22750 (epoch 33.802), train_loss = 0.69148932, grad/param norm = 2.3447e-01, time/batch = 19.7596s	
15381/22750 (epoch 33.804), train_loss = 0.88969628, grad/param norm = 2.2926e-01, time/batch = 16.5707s	
15382/22750 (epoch 33.807), train_loss = 0.84688936, grad/param norm = 2.2698e-01, time/batch = 16.3518s	
15383/22750 (epoch 33.809), train_loss = 0.93689606, grad/param norm = 2.4224e-01, time/batch = 18.6467s	
15384/22750 (epoch 33.811), train_loss = 0.80897442, grad/param norm = 2.6246e-01, time/batch = 18.5041s	
15385/22750 (epoch 33.813), train_loss = 0.82636930, grad/param norm = 2.0278e-01, time/batch = 18.9182s	
15386/22750 (epoch 33.815), train_loss = 0.94967975, grad/param norm = 2.2251e-01, time/batch = 19.0060s	
15387/22750 (epoch 33.818), train_loss = 0.88104253, grad/param norm = 2.0499e-01, time/batch = 19.3435s	
15388/22750 (epoch 33.820), train_loss = 1.02068360, grad/param norm = 2.4012e-01, time/batch = 19.8544s	
15389/22750 (epoch 33.822), train_loss = 0.84810694, grad/param norm = 2.4795e-01, time/batch = 19.4131s	
15390/22750 (epoch 33.824), train_loss = 0.70143411, grad/param norm = 1.9874e-01, time/batch = 17.1659s	
15391/22750 (epoch 33.826), train_loss = 0.81538664, grad/param norm = 2.3770e-01, time/batch = 15.7132s	
15392/22750 (epoch 33.829), train_loss = 0.91897540, grad/param norm = 2.4546e-01, time/batch = 16.1966s	
15393/22750 (epoch 33.831), train_loss = 0.91262541, grad/param norm = 2.6483e-01, time/batch = 15.7134s	
15394/22750 (epoch 33.833), train_loss = 0.83609912, grad/param norm = 2.3180e-01, time/batch = 15.6352s	
15395/22750 (epoch 33.835), train_loss = 0.71594892, grad/param norm = 2.1485e-01, time/batch = 15.4796s	
15396/22750 (epoch 33.837), train_loss = 0.78705275, grad/param norm = 2.1432e-01, time/batch = 15.8895s	
15397/22750 (epoch 33.840), train_loss = 0.72193129, grad/param norm = 1.9965e-01, time/batch = 15.5677s	
15398/22750 (epoch 33.842), train_loss = 0.74799915, grad/param norm = 2.2425e-01, time/batch = 15.9642s	
15399/22750 (epoch 33.844), train_loss = 0.82150024, grad/param norm = 2.2525e-01, time/batch = 15.1483s	
15400/22750 (epoch 33.846), train_loss = 0.84712247, grad/param norm = 2.0512e-01, time/batch = 15.8782s	
15401/22750 (epoch 33.848), train_loss = 0.75021484, grad/param norm = 1.8401e-01, time/batch = 15.3084s	
15402/22750 (epoch 33.851), train_loss = 0.72589918, grad/param norm = 2.1744e-01, time/batch = 17.0702s	
15403/22750 (epoch 33.853), train_loss = 0.89519102, grad/param norm = 2.1673e-01, time/batch = 17.4241s	
15404/22750 (epoch 33.855), train_loss = 0.75437004, grad/param norm = 2.0287e-01, time/batch = 17.1652s	
15405/22750 (epoch 33.857), train_loss = 0.85476045, grad/param norm = 2.1176e-01, time/batch = 17.9181s	
15406/22750 (epoch 33.859), train_loss = 0.83228310, grad/param norm = 2.0833e-01, time/batch = 18.5780s	
15407/22750 (epoch 33.862), train_loss = 0.98750936, grad/param norm = 2.4758e-01, time/batch = 17.0838s	
15408/22750 (epoch 33.864), train_loss = 0.83287424, grad/param norm = 2.2300e-01, time/batch = 17.7862s	
15409/22750 (epoch 33.866), train_loss = 0.85954533, grad/param norm = 2.3643e-01, time/batch = 18.2118s	
15410/22750 (epoch 33.868), train_loss = 0.72677729, grad/param norm = 2.0978e-01, time/batch = 16.7933s	
15411/22750 (epoch 33.870), train_loss = 0.68917111, grad/param norm = 2.2278e-01, time/batch = 16.2460s	
15412/22750 (epoch 33.873), train_loss = 0.78048443, grad/param norm = 1.9763e-01, time/batch = 17.0140s	
15413/22750 (epoch 33.875), train_loss = 0.85941159, grad/param norm = 2.1320e-01, time/batch = 16.1993s	
15414/22750 (epoch 33.877), train_loss = 0.74381319, grad/param norm = 2.4782e-01, time/batch = 16.7467s	
15415/22750 (epoch 33.879), train_loss = 0.91169770, grad/param norm = 2.4502e-01, time/batch = 18.8338s	
15416/22750 (epoch 33.881), train_loss = 0.84744556, grad/param norm = 2.1423e-01, time/batch = 15.8532s	
15417/22750 (epoch 33.884), train_loss = 0.74260624, grad/param norm = 2.1114e-01, time/batch = 17.5295s	
15418/22750 (epoch 33.886), train_loss = 0.83833863, grad/param norm = 2.1224e-01, time/batch = 19.6857s	
15419/22750 (epoch 33.888), train_loss = 0.86433410, grad/param norm = 1.9556e-01, time/batch = 20.8493s	
15420/22750 (epoch 33.890), train_loss = 0.86555982, grad/param norm = 2.2928e-01, time/batch = 18.9135s	
15421/22750 (epoch 33.892), train_loss = 1.11476501, grad/param norm = 2.9739e-01, time/batch = 20.5710s	
15422/22750 (epoch 33.895), train_loss = 0.76951634, grad/param norm = 2.2038e-01, time/batch = 19.3185s	
15423/22750 (epoch 33.897), train_loss = 0.90869867, grad/param norm = 2.2879e-01, time/batch = 18.5750s	
15424/22750 (epoch 33.899), train_loss = 0.84795331, grad/param norm = 2.2772e-01, time/batch = 18.3318s	
15425/22750 (epoch 33.901), train_loss = 0.88593449, grad/param norm = 2.5269e-01, time/batch = 18.0654s	
15426/22750 (epoch 33.903), train_loss = 0.80386430, grad/param norm = 2.1539e-01, time/batch = 19.3423s	
15427/22750 (epoch 33.905), train_loss = 0.88406368, grad/param norm = 2.2680e-01, time/batch = 19.2749s	
15428/22750 (epoch 33.908), train_loss = 0.71816937, grad/param norm = 2.5107e-01, time/batch = 21.0158s	
15429/22750 (epoch 33.910), train_loss = 0.64358033, grad/param norm = 2.2495e-01, time/batch = 19.7633s	
15430/22750 (epoch 33.912), train_loss = 0.79363195, grad/param norm = 2.1943e-01, time/batch = 17.9971s	
15431/22750 (epoch 33.914), train_loss = 0.82361053, grad/param norm = 2.1835e-01, time/batch = 18.4241s	
15432/22750 (epoch 33.916), train_loss = 0.64901680, grad/param norm = 2.0848e-01, time/batch = 19.0794s	
15433/22750 (epoch 33.919), train_loss = 0.79076180, grad/param norm = 2.1140e-01, time/batch = 18.0558s	
15434/22750 (epoch 33.921), train_loss = 0.63466208, grad/param norm = 2.7055e-01, time/batch = 19.4057s	
15435/22750 (epoch 33.923), train_loss = 0.73381920, grad/param norm = 2.1633e-01, time/batch = 16.6558s	
15436/22750 (epoch 33.925), train_loss = 0.79656955, grad/param norm = 2.1563e-01, time/batch = 18.1599s	
15437/22750 (epoch 33.927), train_loss = 0.63653029, grad/param norm = 1.9637e-01, time/batch = 15.9713s	
15438/22750 (epoch 33.930), train_loss = 0.61483651, grad/param norm = 1.9692e-01, time/batch = 17.5720s	
15439/22750 (epoch 33.932), train_loss = 0.79624724, grad/param norm = 2.2002e-01, time/batch = 17.7653s	
15440/22750 (epoch 33.934), train_loss = 0.66949567, grad/param norm = 2.0387e-01, time/batch = 18.9775s	
15441/22750 (epoch 33.936), train_loss = 0.90613442, grad/param norm = 2.3034e-01, time/batch = 18.1728s	
15442/22750 (epoch 33.938), train_loss = 0.88919896, grad/param norm = 2.0008e-01, time/batch = 19.0108s	
15443/22750 (epoch 33.941), train_loss = 0.95051605, grad/param norm = 2.4328e-01, time/batch = 17.5216s	
15444/22750 (epoch 33.943), train_loss = 0.82104598, grad/param norm = 2.1921e-01, time/batch = 18.1028s	
15445/22750 (epoch 33.945), train_loss = 0.81816076, grad/param norm = 2.3065e-01, time/batch = 19.5320s	
15446/22750 (epoch 33.947), train_loss = 0.76004319, grad/param norm = 2.2507e-01, time/batch = 19.1883s	
15447/22750 (epoch 33.949), train_loss = 0.75162727, grad/param norm = 2.3484e-01, time/batch = 18.4939s	
15448/22750 (epoch 33.952), train_loss = 0.77192520, grad/param norm = 2.3220e-01, time/batch = 19.5017s	
15449/22750 (epoch 33.954), train_loss = 0.70824299, grad/param norm = 2.0789e-01, time/batch = 17.1488s	
15450/22750 (epoch 33.956), train_loss = 0.83565001, grad/param norm = 2.2066e-01, time/batch = 19.1618s	
15451/22750 (epoch 33.958), train_loss = 0.72224220, grad/param norm = 1.8281e-01, time/batch = 20.0713s	
15452/22750 (epoch 33.960), train_loss = 0.71396040, grad/param norm = 2.1770e-01, time/batch = 17.7491s	
15453/22750 (epoch 33.963), train_loss = 0.81103476, grad/param norm = 2.1361e-01, time/batch = 20.3467s	
15454/22750 (epoch 33.965), train_loss = 0.86924888, grad/param norm = 2.1237e-01, time/batch = 20.7754s	
15455/22750 (epoch 33.967), train_loss = 0.85314777, grad/param norm = 2.3425e-01, time/batch = 18.9435s	
15456/22750 (epoch 33.969), train_loss = 0.77985345, grad/param norm = 2.3788e-01, time/batch = 16.4414s	
15457/22750 (epoch 33.971), train_loss = 0.73583867, grad/param norm = 1.9740e-01, time/batch = 19.3306s	
15458/22750 (epoch 33.974), train_loss = 0.72470457, grad/param norm = 1.9229e-01, time/batch = 18.3353s	
15459/22750 (epoch 33.976), train_loss = 0.78526620, grad/param norm = 2.5580e-01, time/batch = 18.2629s	
15460/22750 (epoch 33.978), train_loss = 0.75609159, grad/param norm = 2.1128e-01, time/batch = 18.0786s	
15461/22750 (epoch 33.980), train_loss = 0.92195507, grad/param norm = 2.8055e-01, time/batch = 19.9122s	
15462/22750 (epoch 33.982), train_loss = 0.73104865, grad/param norm = 2.2270e-01, time/batch = 19.4504s	
15463/22750 (epoch 33.985), train_loss = 0.93757058, grad/param norm = 2.4487e-01, time/batch = 18.4315s	
15464/22750 (epoch 33.987), train_loss = 0.66861515, grad/param norm = 2.1335e-01, time/batch = 21.0222s	
15465/22750 (epoch 33.989), train_loss = 0.74869272, grad/param norm = 2.6226e-01, time/batch = 17.5844s	
15466/22750 (epoch 33.991), train_loss = 0.82832355, grad/param norm = 2.4235e-01, time/batch = 19.1573s	
15467/22750 (epoch 33.993), train_loss = 0.82177963, grad/param norm = 2.5463e-01, time/batch = 19.9015s	
15468/22750 (epoch 33.996), train_loss = 0.70817787, grad/param norm = 2.3055e-01, time/batch = 17.5699s	
15469/22750 (epoch 33.998), train_loss = 0.89378585, grad/param norm = 2.3144e-01, time/batch = 16.8122s	
decayed learning rate by a factor 0.97 to 0.00093394941050874	
15470/22750 (epoch 34.000), train_loss = 0.79316064, grad/param norm = 2.1643e-01, time/batch = 18.5051s	
15471/22750 (epoch 34.002), train_loss = 0.96528381, grad/param norm = 2.4509e-01, time/batch = 17.6159s	
15472/22750 (epoch 34.004), train_loss = 0.78635191, grad/param norm = 2.4523e-01, time/batch = 19.1167s	
15473/22750 (epoch 34.007), train_loss = 0.77772194, grad/param norm = 2.5556e-01, time/batch = 18.3385s	
15474/22750 (epoch 34.009), train_loss = 0.93508107, grad/param norm = 2.6023e-01, time/batch = 19.0697s	
15475/22750 (epoch 34.011), train_loss = 1.01321159, grad/param norm = 2.6961e-01, time/batch = 18.9059s	
15476/22750 (epoch 34.013), train_loss = 0.93343608, grad/param norm = 2.5381e-01, time/batch = 18.6670s	
15477/22750 (epoch 34.015), train_loss = 0.82164352, grad/param norm = 2.3041e-01, time/batch = 19.9921s	
15478/22750 (epoch 34.018), train_loss = 0.89115623, grad/param norm = 2.3437e-01, time/batch = 17.0946s	
15479/22750 (epoch 34.020), train_loss = 0.95118329, grad/param norm = 2.3563e-01, time/batch = 19.4393s	
15480/22750 (epoch 34.022), train_loss = 0.80659531, grad/param norm = 2.2790e-01, time/batch = 20.2035s	
15481/22750 (epoch 34.024), train_loss = 0.82896330, grad/param norm = 2.5072e-01, time/batch = 17.3406s	
15482/22750 (epoch 34.026), train_loss = 0.86448277, grad/param norm = 2.5285e-01, time/batch = 19.2742s	
15483/22750 (epoch 34.029), train_loss = 0.68466769, grad/param norm = 2.1242e-01, time/batch = 17.9697s	
15484/22750 (epoch 34.031), train_loss = 1.01814031, grad/param norm = 2.3789e-01, time/batch = 18.0060s	
15485/22750 (epoch 34.033), train_loss = 0.82698645, grad/param norm = 2.2050e-01, time/batch = 20.1532s	
15486/22750 (epoch 34.035), train_loss = 0.87519400, grad/param norm = 2.7906e-01, time/batch = 18.5167s	
15487/22750 (epoch 34.037), train_loss = 0.92072989, grad/param norm = 2.3690e-01, time/batch = 26.2148s	
15488/22750 (epoch 34.040), train_loss = 0.81057200, grad/param norm = 2.1865e-01, time/batch = 27.9274s	
15489/22750 (epoch 34.042), train_loss = 0.84177740, grad/param norm = 2.1626e-01, time/batch = 17.0864s	
15490/22750 (epoch 34.044), train_loss = 0.81627777, grad/param norm = 2.2053e-01, time/batch = 16.9879s	
15491/22750 (epoch 34.046), train_loss = 0.90006264, grad/param norm = 2.5110e-01, time/batch = 16.3430s	
15492/22750 (epoch 34.048), train_loss = 0.80913370, grad/param norm = 2.0694e-01, time/batch = 15.9385s	
15493/22750 (epoch 34.051), train_loss = 0.81894987, grad/param norm = 2.2513e-01, time/batch = 16.3389s	
15494/22750 (epoch 34.053), train_loss = 0.79474610, grad/param norm = 1.8451e-01, time/batch = 15.8534s	
15495/22750 (epoch 34.055), train_loss = 0.68830696, grad/param norm = 2.0591e-01, time/batch = 15.8555s	
15496/22750 (epoch 34.057), train_loss = 0.97157162, grad/param norm = 2.3442e-01, time/batch = 15.6132s	
15497/22750 (epoch 34.059), train_loss = 0.60418796, grad/param norm = 2.0978e-01, time/batch = 16.2629s	
15498/22750 (epoch 34.062), train_loss = 0.70626806, grad/param norm = 2.2599e-01, time/batch = 16.0335s	
15499/22750 (epoch 34.064), train_loss = 0.89699852, grad/param norm = 2.3504e-01, time/batch = 15.7971s	
15500/22750 (epoch 34.066), train_loss = 0.71864412, grad/param norm = 1.9127e-01, time/batch = 15.8656s	
15501/22750 (epoch 34.068), train_loss = 0.72936567, grad/param norm = 1.9062e-01, time/batch = 16.4824s	
15502/22750 (epoch 34.070), train_loss = 0.59961409, grad/param norm = 1.7131e-01, time/batch = 15.6954s	
15503/22750 (epoch 34.073), train_loss = 0.76409709, grad/param norm = 2.3096e-01, time/batch = 16.0902s	
15504/22750 (epoch 34.075), train_loss = 0.80289183, grad/param norm = 2.4237e-01, time/batch = 16.2498s	
15505/22750 (epoch 34.077), train_loss = 0.59267813, grad/param norm = 2.1634e-01, time/batch = 16.2543s	
15506/22750 (epoch 34.079), train_loss = 0.79762610, grad/param norm = 2.5721e-01, time/batch = 15.6189s	
15507/22750 (epoch 34.081), train_loss = 0.74923432, grad/param norm = 2.0889e-01, time/batch = 15.9391s	
15508/22750 (epoch 34.084), train_loss = 0.76929804, grad/param norm = 2.2092e-01, time/batch = 16.0497s	
15509/22750 (epoch 34.086), train_loss = 0.79416442, grad/param norm = 2.0188e-01, time/batch = 16.3476s	
15510/22750 (epoch 34.088), train_loss = 0.74014580, grad/param norm = 2.1161e-01, time/batch = 15.7099s	
15511/22750 (epoch 34.090), train_loss = 0.77000546, grad/param norm = 2.2269e-01, time/batch = 16.0169s	
15512/22750 (epoch 34.092), train_loss = 0.88008507, grad/param norm = 2.3784e-01, time/batch = 16.2390s	
15513/22750 (epoch 34.095), train_loss = 0.72556498, grad/param norm = 2.0598e-01, time/batch = 16.0131s	
15514/22750 (epoch 34.097), train_loss = 0.77699368, grad/param norm = 1.9478e-01, time/batch = 15.8609s	
15515/22750 (epoch 34.099), train_loss = 0.74064584, grad/param norm = 2.0995e-01, time/batch = 15.8574s	
15516/22750 (epoch 34.101), train_loss = 0.66331258, grad/param norm = 2.2476e-01, time/batch = 16.2453s	
15517/22750 (epoch 34.103), train_loss = 0.85835252, grad/param norm = 2.3820e-01, time/batch = 15.8549s	
15518/22750 (epoch 34.105), train_loss = 0.91790866, grad/param norm = 2.5815e-01, time/batch = 15.9570s	
15519/22750 (epoch 34.108), train_loss = 0.80808968, grad/param norm = 2.2977e-01, time/batch = 15.6299s	
15520/22750 (epoch 34.110), train_loss = 0.91167898, grad/param norm = 2.0827e-01, time/batch = 16.0260s	
15521/22750 (epoch 34.112), train_loss = 0.66134666, grad/param norm = 1.8304e-01, time/batch = 15.5468s	
15522/22750 (epoch 34.114), train_loss = 0.58565089, grad/param norm = 1.8326e-01, time/batch = 15.4471s	
15523/22750 (epoch 34.116), train_loss = 0.78957801, grad/param norm = 2.0348e-01, time/batch = 15.6022s	
15524/22750 (epoch 34.119), train_loss = 0.74768700, grad/param norm = 1.8935e-01, time/batch = 15.5356s	
15525/22750 (epoch 34.121), train_loss = 0.77298979, grad/param norm = 2.5018e-01, time/batch = 15.3610s	
15526/22750 (epoch 34.123), train_loss = 0.67589936, grad/param norm = 2.1488e-01, time/batch = 15.3532s	
15527/22750 (epoch 34.125), train_loss = 0.90512430, grad/param norm = 2.0665e-01, time/batch = 16.1577s	
15528/22750 (epoch 34.127), train_loss = 0.76544955, grad/param norm = 2.3449e-01, time/batch = 15.1944s	
15529/22750 (epoch 34.130), train_loss = 0.76741564, grad/param norm = 1.9396e-01, time/batch = 15.3797s	
15530/22750 (epoch 34.132), train_loss = 0.73010825, grad/param norm = 2.4596e-01, time/batch = 15.1185s	
15531/22750 (epoch 34.134), train_loss = 0.74339836, grad/param norm = 1.9710e-01, time/batch = 15.7788s	
15532/22750 (epoch 34.136), train_loss = 0.62666099, grad/param norm = 2.2257e-01, time/batch = 15.5432s	
15533/22750 (epoch 34.138), train_loss = 0.84410510, grad/param norm = 2.0635e-01, time/batch = 15.6113s	
15534/22750 (epoch 34.141), train_loss = 0.78988727, grad/param norm = 2.1245e-01, time/batch = 15.6925s	
15535/22750 (epoch 34.143), train_loss = 0.70273430, grad/param norm = 1.8973e-01, time/batch = 16.1709s	
15536/22750 (epoch 34.145), train_loss = 0.91283474, grad/param norm = 2.3945e-01, time/batch = 15.8510s	
15537/22750 (epoch 34.147), train_loss = 0.96139720, grad/param norm = 2.6410e-01, time/batch = 15.9211s	
15538/22750 (epoch 34.149), train_loss = 0.79784871, grad/param norm = 2.0400e-01, time/batch = 15.6019s	
15539/22750 (epoch 34.152), train_loss = 0.78419914, grad/param norm = 2.0850e-01, time/batch = 16.5530s	
15540/22750 (epoch 34.154), train_loss = 0.71817181, grad/param norm = 2.1838e-01, time/batch = 15.6124s	
15541/22750 (epoch 34.156), train_loss = 0.70571494, grad/param norm = 2.0687e-01, time/batch = 15.7790s	
15542/22750 (epoch 34.158), train_loss = 0.70411437, grad/param norm = 2.4318e-01, time/batch = 16.0404s	
15543/22750 (epoch 34.160), train_loss = 0.80182330, grad/param norm = 2.3911e-01, time/batch = 15.3598s	
15544/22750 (epoch 34.163), train_loss = 0.92501183, grad/param norm = 2.3004e-01, time/batch = 15.5930s	
15545/22750 (epoch 34.165), train_loss = 0.83765132, grad/param norm = 2.0858e-01, time/batch = 15.8349s	
15546/22750 (epoch 34.167), train_loss = 0.73480205, grad/param norm = 2.5521e-01, time/batch = 16.9390s	
15547/22750 (epoch 34.169), train_loss = 0.80313017, grad/param norm = 2.3864e-01, time/batch = 15.8487s	
15548/22750 (epoch 34.171), train_loss = 0.66786471, grad/param norm = 1.8633e-01, time/batch = 15.9247s	
15549/22750 (epoch 34.174), train_loss = 0.67818685, grad/param norm = 2.4149e-01, time/batch = 15.4665s	
15550/22750 (epoch 34.176), train_loss = 0.70324781, grad/param norm = 2.3876e-01, time/batch = 15.9387s	
15551/22750 (epoch 34.178), train_loss = 0.72978892, grad/param norm = 2.0839e-01, time/batch = 15.3814s	
15552/22750 (epoch 34.180), train_loss = 0.93431160, grad/param norm = 3.8948e-01, time/batch = 15.7883s	
15553/22750 (epoch 34.182), train_loss = 0.87178903, grad/param norm = 2.6701e-01, time/batch = 15.6219s	
15554/22750 (epoch 34.185), train_loss = 0.89237819, grad/param norm = 2.5681e-01, time/batch = 16.1765s	
15555/22750 (epoch 34.187), train_loss = 0.68527759, grad/param norm = 1.8969e-01, time/batch = 15.6940s	
15556/22750 (epoch 34.189), train_loss = 0.71540652, grad/param norm = 2.8258e-01, time/batch = 15.6798s	
15557/22750 (epoch 34.191), train_loss = 0.72952531, grad/param norm = 2.4585e-01, time/batch = 15.8498s	
15558/22750 (epoch 34.193), train_loss = 0.83894376, grad/param norm = 2.0974e-01, time/batch = 15.7588s	
15559/22750 (epoch 34.196), train_loss = 0.77519961, grad/param norm = 2.4344e-01, time/batch = 15.8426s	
15560/22750 (epoch 34.198), train_loss = 0.58897484, grad/param norm = 2.1940e-01, time/batch = 15.9128s	
15561/22750 (epoch 34.200), train_loss = 0.79571812, grad/param norm = 2.3188e-01, time/batch = 16.2005s	
15562/22750 (epoch 34.202), train_loss = 0.86206208, grad/param norm = 3.0587e-01, time/batch = 15.3802s	
15563/22750 (epoch 34.204), train_loss = 0.83037047, grad/param norm = 2.5746e-01, time/batch = 15.3051s	
15564/22750 (epoch 34.207), train_loss = 0.80056189, grad/param norm = 2.4033e-01, time/batch = 15.3725s	
15565/22750 (epoch 34.209), train_loss = 0.73771287, grad/param norm = 2.2061e-01, time/batch = 15.9248s	
15566/22750 (epoch 34.211), train_loss = 0.69373181, grad/param norm = 2.2143e-01, time/batch = 15.8518s	
15567/22750 (epoch 34.213), train_loss = 0.61169582, grad/param norm = 2.1346e-01, time/batch = 17.4043s	
15568/22750 (epoch 34.215), train_loss = 0.59402399, grad/param norm = 2.0528e-01, time/batch = 16.8111s	
15569/22750 (epoch 34.218), train_loss = 0.70270192, grad/param norm = 2.6482e-01, time/batch = 16.1867s	
15570/22750 (epoch 34.220), train_loss = 0.62853750, grad/param norm = 1.9679e-01, time/batch = 16.7494s	
15571/22750 (epoch 34.222), train_loss = 0.65592512, grad/param norm = 2.0714e-01, time/batch = 18.2813s	
15572/22750 (epoch 34.224), train_loss = 0.70543881, grad/param norm = 2.0490e-01, time/batch = 17.4360s	
15573/22750 (epoch 34.226), train_loss = 0.77812800, grad/param norm = 2.3809e-01, time/batch = 20.2608s	
15574/22750 (epoch 34.229), train_loss = 0.79700905, grad/param norm = 2.5333e-01, time/batch = 17.8478s	
15575/22750 (epoch 34.231), train_loss = 0.68070966, grad/param norm = 1.9909e-01, time/batch = 16.1861s	
15576/22750 (epoch 34.233), train_loss = 0.64566564, grad/param norm = 2.6995e-01, time/batch = 16.4977s	
15577/22750 (epoch 34.235), train_loss = 0.60105300, grad/param norm = 2.0349e-01, time/batch = 16.7544s	
15578/22750 (epoch 34.237), train_loss = 0.70491418, grad/param norm = 2.4029e-01, time/batch = 17.6093s	
15579/22750 (epoch 34.240), train_loss = 0.76878119, grad/param norm = 1.9893e-01, time/batch = 17.9038s	
15580/22750 (epoch 34.242), train_loss = 0.93550856, grad/param norm = 2.8099e-01, time/batch = 20.3285s	
15581/22750 (epoch 34.244), train_loss = 0.93534279, grad/param norm = 2.6022e-01, time/batch = 19.7719s	
15582/22750 (epoch 34.246), train_loss = 0.95041202, grad/param norm = 2.6024e-01, time/batch = 18.1022s	
15583/22750 (epoch 34.248), train_loss = 0.78535237, grad/param norm = 2.1469e-01, time/batch = 19.5161s	
15584/22750 (epoch 34.251), train_loss = 0.88852943, grad/param norm = 2.3702e-01, time/batch = 17.6726s	
15585/22750 (epoch 34.253), train_loss = 0.84370006, grad/param norm = 3.1373e-01, time/batch = 18.6629s	
15586/22750 (epoch 34.255), train_loss = 0.81347116, grad/param norm = 2.3571e-01, time/batch = 19.1666s	
15587/22750 (epoch 34.257), train_loss = 0.71364404, grad/param norm = 2.2238e-01, time/batch = 19.5757s	
15588/22750 (epoch 34.259), train_loss = 0.88522987, grad/param norm = 3.0334e-01, time/batch = 17.7136s	
15589/22750 (epoch 34.262), train_loss = 0.81218053, grad/param norm = 2.4073e-01, time/batch = 17.8973s	
15590/22750 (epoch 34.264), train_loss = 0.64672381, grad/param norm = 2.4544e-01, time/batch = 18.3036s	
15591/22750 (epoch 34.266), train_loss = 0.78296702, grad/param norm = 2.7110e-01, time/batch = 19.7656s	
15592/22750 (epoch 34.268), train_loss = 0.91274350, grad/param norm = 2.4400e-01, time/batch = 18.2556s	
15593/22750 (epoch 34.270), train_loss = 0.70179752, grad/param norm = 2.3953e-01, time/batch = 19.9940s	
15594/22750 (epoch 34.273), train_loss = 1.03789766, grad/param norm = 2.9500e-01, time/batch = 19.8161s	
15595/22750 (epoch 34.275), train_loss = 0.92350743, grad/param norm = 2.2909e-01, time/batch = 16.1762s	
15596/22750 (epoch 34.277), train_loss = 0.78654466, grad/param norm = 3.0783e-01, time/batch = 18.0942s	
15597/22750 (epoch 34.279), train_loss = 0.66698672, grad/param norm = 1.9900e-01, time/batch = 16.4785s	
15598/22750 (epoch 34.281), train_loss = 0.92236895, grad/param norm = 2.4800e-01, time/batch = 16.9177s	
15599/22750 (epoch 34.284), train_loss = 0.82518635, grad/param norm = 2.1349e-01, time/batch = 19.6926s	
15600/22750 (epoch 34.286), train_loss = 0.86701908, grad/param norm = 2.3759e-01, time/batch = 17.0063s	
15601/22750 (epoch 34.288), train_loss = 0.94263209, grad/param norm = 2.4184e-01, time/batch = 17.7443s	
15602/22750 (epoch 34.290), train_loss = 0.82185324, grad/param norm = 2.2363e-01, time/batch = 16.8914s	
15603/22750 (epoch 34.292), train_loss = 0.87830678, grad/param norm = 2.7718e-01, time/batch = 16.0019s	
15604/22750 (epoch 34.295), train_loss = 0.83988413, grad/param norm = 2.4846e-01, time/batch = 16.9333s	
15605/22750 (epoch 34.297), train_loss = 0.80513579, grad/param norm = 2.2164e-01, time/batch = 16.5096s	
15606/22750 (epoch 34.299), train_loss = 0.88030658, grad/param norm = 2.8367e-01, time/batch = 15.9708s	
15607/22750 (epoch 34.301), train_loss = 0.80718948, grad/param norm = 2.0918e-01, time/batch = 15.9167s	
15608/22750 (epoch 34.303), train_loss = 0.83809929, grad/param norm = 2.0382e-01, time/batch = 15.9184s	
15609/22750 (epoch 34.305), train_loss = 0.95492995, grad/param norm = 2.3349e-01, time/batch = 15.7614s	
15610/22750 (epoch 34.308), train_loss = 0.86622174, grad/param norm = 2.1363e-01, time/batch = 15.4739s	
15611/22750 (epoch 34.310), train_loss = 0.73349242, grad/param norm = 2.3525e-01, time/batch = 16.3569s	
15612/22750 (epoch 34.312), train_loss = 0.81735066, grad/param norm = 2.2529e-01, time/batch = 17.0140s	
15613/22750 (epoch 34.314), train_loss = 0.80779029, grad/param norm = 2.0103e-01, time/batch = 17.7446s	
15614/22750 (epoch 34.316), train_loss = 0.77190915, grad/param norm = 2.0779e-01, time/batch = 18.7535s	
15615/22750 (epoch 34.319), train_loss = 0.83684046, grad/param norm = 2.5213e-01, time/batch = 16.4277s	
15616/22750 (epoch 34.321), train_loss = 0.73646614, grad/param norm = 2.3507e-01, time/batch = 16.9918s	
15617/22750 (epoch 34.323), train_loss = 0.80958065, grad/param norm = 2.2466e-01, time/batch = 19.8142s	
15618/22750 (epoch 34.325), train_loss = 0.71304395, grad/param norm = 2.0519e-01, time/batch = 19.3537s	
15619/22750 (epoch 34.327), train_loss = 0.74999963, grad/param norm = 2.4566e-01, time/batch = 18.3605s	
15620/22750 (epoch 34.330), train_loss = 0.95612285, grad/param norm = 2.5051e-01, time/batch = 18.8609s	
15621/22750 (epoch 34.332), train_loss = 0.98403985, grad/param norm = 2.2480e-01, time/batch = 18.2649s	
15622/22750 (epoch 34.334), train_loss = 0.65939903, grad/param norm = 1.9295e-01, time/batch = 18.2551s	
15623/22750 (epoch 34.336), train_loss = 0.89087042, grad/param norm = 1.9960e-01, time/batch = 17.5727s	
15624/22750 (epoch 34.338), train_loss = 0.79637091, grad/param norm = 2.2323e-01, time/batch = 17.9131s	
15625/22750 (epoch 34.341), train_loss = 0.81064462, grad/param norm = 2.4272e-01, time/batch = 19.0767s	
15626/22750 (epoch 34.343), train_loss = 0.69428330, grad/param norm = 2.0805e-01, time/batch = 17.5091s	
15627/22750 (epoch 34.345), train_loss = 0.87036454, grad/param norm = 3.0101e-01, time/batch = 18.8603s	
15628/22750 (epoch 34.347), train_loss = 0.91863599, grad/param norm = 2.4786e-01, time/batch = 19.6510s	
15629/22750 (epoch 34.349), train_loss = 0.65400366, grad/param norm = 2.3737e-01, time/batch = 18.2447s	
15630/22750 (epoch 34.352), train_loss = 0.93014680, grad/param norm = 2.2555e-01, time/batch = 18.9283s	
15631/22750 (epoch 34.354), train_loss = 0.91181078, grad/param norm = 2.3998e-01, time/batch = 17.8526s	
15632/22750 (epoch 34.356), train_loss = 0.86903118, grad/param norm = 2.2836e-01, time/batch = 17.1708s	
15633/22750 (epoch 34.358), train_loss = 0.77073579, grad/param norm = 2.1787e-01, time/batch = 16.3152s	
15634/22750 (epoch 34.360), train_loss = 0.94673404, grad/param norm = 2.2892e-01, time/batch = 16.3140s	
15635/22750 (epoch 34.363), train_loss = 0.77963500, grad/param norm = 2.5676e-01, time/batch = 17.2534s	
15636/22750 (epoch 34.365), train_loss = 0.66687621, grad/param norm = 2.4769e-01, time/batch = 17.3105s	
15637/22750 (epoch 34.367), train_loss = 0.75211922, grad/param norm = 2.4374e-01, time/batch = 18.1290s	
15638/22750 (epoch 34.369), train_loss = 0.83097006, grad/param norm = 2.9248e-01, time/batch = 18.7956s	
15639/22750 (epoch 34.371), train_loss = 0.82273268, grad/param norm = 2.2561e-01, time/batch = 16.6029s	
15640/22750 (epoch 34.374), train_loss = 0.70823394, grad/param norm = 2.2252e-01, time/batch = 18.1746s	
15641/22750 (epoch 34.376), train_loss = 0.78426824, grad/param norm = 2.0626e-01, time/batch = 16.3946s	
15642/22750 (epoch 34.378), train_loss = 0.80256795, grad/param norm = 2.1744e-01, time/batch = 17.0259s	
15643/22750 (epoch 34.380), train_loss = 0.87031337, grad/param norm = 2.3448e-01, time/batch = 17.0990s	
15644/22750 (epoch 34.382), train_loss = 0.78239492, grad/param norm = 2.1664e-01, time/batch = 18.3473s	
15645/22750 (epoch 34.385), train_loss = 0.85757947, grad/param norm = 2.2082e-01, time/batch = 19.1118s	
15646/22750 (epoch 34.387), train_loss = 0.84635375, grad/param norm = 2.1929e-01, time/batch = 19.4013s	
15647/22750 (epoch 34.389), train_loss = 0.65719188, grad/param norm = 2.1771e-01, time/batch = 20.1984s	
15648/22750 (epoch 34.391), train_loss = 0.49913609, grad/param norm = 1.7101e-01, time/batch = 19.5198s	
15649/22750 (epoch 34.393), train_loss = 0.66394158, grad/param norm = 1.8969e-01, time/batch = 17.9193s	
15650/22750 (epoch 34.396), train_loss = 0.82661156, grad/param norm = 2.2736e-01, time/batch = 20.0788s	
15651/22750 (epoch 34.398), train_loss = 0.75669312, grad/param norm = 1.9358e-01, time/batch = 19.0798s	
15652/22750 (epoch 34.400), train_loss = 0.79669670, grad/param norm = 2.3797e-01, time/batch = 18.2578s	
15653/22750 (epoch 34.402), train_loss = 0.83393802, grad/param norm = 2.0168e-01, time/batch = 19.0607s	
15654/22750 (epoch 34.404), train_loss = 0.90309479, grad/param norm = 2.3674e-01, time/batch = 19.6677s	
15655/22750 (epoch 34.407), train_loss = 0.88253344, grad/param norm = 2.1720e-01, time/batch = 18.1794s	
15656/22750 (epoch 34.409), train_loss = 0.73069555, grad/param norm = 2.2152e-01, time/batch = 20.7675s	
15657/22750 (epoch 34.411), train_loss = 0.73406381, grad/param norm = 1.9821e-01, time/batch = 16.4078s	
15658/22750 (epoch 34.413), train_loss = 0.59005282, grad/param norm = 2.4593e-01, time/batch = 16.3528s	
15659/22750 (epoch 34.415), train_loss = 0.65307298, grad/param norm = 2.0162e-01, time/batch = 16.4882s	
15660/22750 (epoch 34.418), train_loss = 0.75160023, grad/param norm = 2.4068e-01, time/batch = 16.8509s	
15661/22750 (epoch 34.420), train_loss = 0.87501490, grad/param norm = 3.0717e-01, time/batch = 18.0099s	
15662/22750 (epoch 34.422), train_loss = 1.00650289, grad/param norm = 2.7929e-01, time/batch = 16.5855s	
15663/22750 (epoch 34.424), train_loss = 0.99565593, grad/param norm = 2.8540e-01, time/batch = 18.2481s	
15664/22750 (epoch 34.426), train_loss = 0.96982449, grad/param norm = 2.2157e-01, time/batch = 18.8195s	
15665/22750 (epoch 34.429), train_loss = 0.74551472, grad/param norm = 2.3392e-01, time/batch = 19.6036s	
15666/22750 (epoch 34.431), train_loss = 0.65318527, grad/param norm = 1.9941e-01, time/batch = 18.2762s	
15667/22750 (epoch 34.433), train_loss = 0.74778079, grad/param norm = 1.9997e-01, time/batch = 16.9317s	
15668/22750 (epoch 34.435), train_loss = 0.59401512, grad/param norm = 1.7444e-01, time/batch = 16.9868s	
15669/22750 (epoch 34.437), train_loss = 0.50696628, grad/param norm = 1.7211e-01, time/batch = 16.3554s	
15670/22750 (epoch 34.440), train_loss = 0.75478866, grad/param norm = 2.4907e-01, time/batch = 18.9190s	
15671/22750 (epoch 34.442), train_loss = 0.80392270, grad/param norm = 2.4645e-01, time/batch = 19.1445s	
15672/22750 (epoch 34.444), train_loss = 0.77012715, grad/param norm = 2.1983e-01, time/batch = 17.9909s	
15673/22750 (epoch 34.446), train_loss = 0.78498988, grad/param norm = 2.5360e-01, time/batch = 18.5823s	
15674/22750 (epoch 34.448), train_loss = 1.01348105, grad/param norm = 2.6891e-01, time/batch = 17.4053s	
15675/22750 (epoch 34.451), train_loss = 0.96117355, grad/param norm = 2.3922e-01, time/batch = 18.4942s	
15676/22750 (epoch 34.453), train_loss = 0.85585510, grad/param norm = 2.5603e-01, time/batch = 17.6842s	
15677/22750 (epoch 34.455), train_loss = 0.97870494, grad/param norm = 2.4319e-01, time/batch = 18.2569s	
15678/22750 (epoch 34.457), train_loss = 0.85167496, grad/param norm = 2.8143e-01, time/batch = 18.6563s	
15679/22750 (epoch 34.459), train_loss = 0.85505346, grad/param norm = 2.0274e-01, time/batch = 16.7096s	
15680/22750 (epoch 34.462), train_loss = 0.82959862, grad/param norm = 2.0166e-01, time/batch = 15.5996s	
15681/22750 (epoch 34.464), train_loss = 0.70591778, grad/param norm = 2.3506e-01, time/batch = 15.3080s	
15682/22750 (epoch 34.466), train_loss = 0.87383625, grad/param norm = 2.4168e-01, time/batch = 15.7058s	
15683/22750 (epoch 34.468), train_loss = 0.83593429, grad/param norm = 2.6065e-01, time/batch = 15.9094s	
15684/22750 (epoch 34.470), train_loss = 0.92763113, grad/param norm = 2.6642e-01, time/batch = 15.6187s	
15685/22750 (epoch 34.473), train_loss = 0.79240259, grad/param norm = 2.0730e-01, time/batch = 16.0457s	
15686/22750 (epoch 34.475), train_loss = 0.80361383, grad/param norm = 2.1902e-01, time/batch = 15.8736s	
15687/22750 (epoch 34.477), train_loss = 0.71012114, grad/param norm = 2.2077e-01, time/batch = 16.0116s	
15688/22750 (epoch 34.479), train_loss = 0.67659384, grad/param norm = 1.9458e-01, time/batch = 15.1337s	
15689/22750 (epoch 34.481), train_loss = 0.66398511, grad/param norm = 1.9130e-01, time/batch = 15.0529s	
15690/22750 (epoch 34.484), train_loss = 0.56758387, grad/param norm = 2.2186e-01, time/batch = 15.9283s	
15691/22750 (epoch 34.486), train_loss = 0.67908264, grad/param norm = 2.2520e-01, time/batch = 15.2004s	
15692/22750 (epoch 34.488), train_loss = 0.62134767, grad/param norm = 1.9801e-01, time/batch = 15.4448s	
15693/22750 (epoch 34.490), train_loss = 0.78431142, grad/param norm = 2.1356e-01, time/batch = 14.9574s	
15694/22750 (epoch 34.492), train_loss = 0.86427086, grad/param norm = 2.2802e-01, time/batch = 15.4592s	
15695/22750 (epoch 34.495), train_loss = 0.71320500, grad/param norm = 2.4303e-01, time/batch = 14.9120s	
15696/22750 (epoch 34.497), train_loss = 0.78197787, grad/param norm = 2.4429e-01, time/batch = 15.2327s	
15697/22750 (epoch 34.499), train_loss = 0.70486944, grad/param norm = 2.2785e-01, time/batch = 15.7825s	
15698/22750 (epoch 34.501), train_loss = 0.74498642, grad/param norm = 2.2715e-01, time/batch = 34.9601s	
15699/22750 (epoch 34.503), train_loss = 0.77129751, grad/param norm = 2.1862e-01, time/batch = 16.3975s	
15700/22750 (epoch 34.505), train_loss = 0.68594773, grad/param norm = 2.1552e-01, time/batch = 16.5579s	
15701/22750 (epoch 34.508), train_loss = 0.62331122, grad/param norm = 2.0467e-01, time/batch = 15.5242s	
15702/22750 (epoch 34.510), train_loss = 0.66852221, grad/param norm = 2.0599e-01, time/batch = 15.2851s	
15703/22750 (epoch 34.512), train_loss = 0.70705789, grad/param norm = 1.9815e-01, time/batch = 14.8995s	
15704/22750 (epoch 34.514), train_loss = 0.73006418, grad/param norm = 2.1114e-01, time/batch = 15.2253s	
15705/22750 (epoch 34.516), train_loss = 0.73281586, grad/param norm = 2.2019e-01, time/batch = 15.4534s	
15706/22750 (epoch 34.519), train_loss = 0.84962111, grad/param norm = 2.7484e-01, time/batch = 15.9344s	
15707/22750 (epoch 34.521), train_loss = 0.78409612, grad/param norm = 2.2379e-01, time/batch = 15.2160s	
15708/22750 (epoch 34.523), train_loss = 0.71257555, grad/param norm = 2.5867e-01, time/batch = 16.4768s	
15709/22750 (epoch 34.525), train_loss = 0.93327900, grad/param norm = 2.6029e-01, time/batch = 15.9949s	
15710/22750 (epoch 34.527), train_loss = 0.79282363, grad/param norm = 2.1846e-01, time/batch = 16.0517s	
15711/22750 (epoch 34.530), train_loss = 0.70522271, grad/param norm = 2.0139e-01, time/batch = 16.1565s	
15712/22750 (epoch 34.532), train_loss = 0.66471526, grad/param norm = 2.1274e-01, time/batch = 15.8264s	
15713/22750 (epoch 34.534), train_loss = 0.85338150, grad/param norm = 2.4183e-01, time/batch = 15.3271s	
15714/22750 (epoch 34.536), train_loss = 0.82086615, grad/param norm = 2.0164e-01, time/batch = 15.5420s	
15715/22750 (epoch 34.538), train_loss = 0.78873507, grad/param norm = 1.9529e-01, time/batch = 15.9473s	
15716/22750 (epoch 34.541), train_loss = 0.68590436, grad/param norm = 2.0847e-01, time/batch = 15.8679s	
15717/22750 (epoch 34.543), train_loss = 0.68410982, grad/param norm = 2.2309e-01, time/batch = 16.0174s	
15718/22750 (epoch 34.545), train_loss = 0.84697588, grad/param norm = 2.1328e-01, time/batch = 16.6504s	
15719/22750 (epoch 34.547), train_loss = 0.73974591, grad/param norm = 1.9858e-01, time/batch = 16.7799s	
15720/22750 (epoch 34.549), train_loss = 0.75842496, grad/param norm = 2.1855e-01, time/batch = 16.0789s	
15721/22750 (epoch 34.552), train_loss = 0.82841360, grad/param norm = 2.3211e-01, time/batch = 16.3892s	
15722/22750 (epoch 34.554), train_loss = 0.86231742, grad/param norm = 2.4956e-01, time/batch = 15.7962s	
15723/22750 (epoch 34.556), train_loss = 0.82244748, grad/param norm = 2.1621e-01, time/batch = 16.0708s	
15724/22750 (epoch 34.558), train_loss = 0.80204284, grad/param norm = 2.4589e-01, time/batch = 15.6762s	
15725/22750 (epoch 34.560), train_loss = 0.74398496, grad/param norm = 2.0628e-01, time/batch = 15.6189s	
15726/22750 (epoch 34.563), train_loss = 0.87430533, grad/param norm = 2.2264e-01, time/batch = 15.6533s	
15727/22750 (epoch 34.565), train_loss = 0.85695350, grad/param norm = 3.1470e-01, time/batch = 15.7249s	
15728/22750 (epoch 34.567), train_loss = 0.84312287, grad/param norm = 2.4725e-01, time/batch = 15.7970s	
15729/22750 (epoch 34.569), train_loss = 0.74711187, grad/param norm = 2.1004e-01, time/batch = 15.6386s	
15730/22750 (epoch 34.571), train_loss = 0.76952068, grad/param norm = 2.3190e-01, time/batch = 16.3576s	
15731/22750 (epoch 34.574), train_loss = 0.79590381, grad/param norm = 2.2360e-01, time/batch = 15.5129s	
15732/22750 (epoch 34.576), train_loss = 0.76292678, grad/param norm = 2.3056e-01, time/batch = 16.0692s	
15733/22750 (epoch 34.578), train_loss = 0.66629156, grad/param norm = 2.0455e-01, time/batch = 16.4694s	
15734/22750 (epoch 34.580), train_loss = 0.84767894, grad/param norm = 2.3982e-01, time/batch = 16.3826s	
15735/22750 (epoch 34.582), train_loss = 0.70259745, grad/param norm = 2.0646e-01, time/batch = 15.6053s	
15736/22750 (epoch 34.585), train_loss = 0.68068983, grad/param norm = 2.1482e-01, time/batch = 15.9493s	
15737/22750 (epoch 34.587), train_loss = 0.68355015, grad/param norm = 1.8531e-01, time/batch = 15.6271s	
15738/22750 (epoch 34.589), train_loss = 0.59719478, grad/param norm = 1.9263e-01, time/batch = 16.2629s	
15739/22750 (epoch 34.591), train_loss = 0.75890390, grad/param norm = 1.9522e-01, time/batch = 16.1045s	
15740/22750 (epoch 34.593), train_loss = 0.89790797, grad/param norm = 2.3381e-01, time/batch = 16.9359s	
15741/22750 (epoch 34.596), train_loss = 0.88108302, grad/param norm = 2.4557e-01, time/batch = 16.3915s	
15742/22750 (epoch 34.598), train_loss = 0.90246203, grad/param norm = 2.5953e-01, time/batch = 15.9194s	
15743/22750 (epoch 34.600), train_loss = 0.91455747, grad/param norm = 2.4895e-01, time/batch = 15.3733s	
15744/22750 (epoch 34.602), train_loss = 0.71731723, grad/param norm = 2.0929e-01, time/batch = 15.4598s	
15745/22750 (epoch 34.604), train_loss = 0.74635853, grad/param norm = 2.2372e-01, time/batch = 16.0880s	
15746/22750 (epoch 34.607), train_loss = 0.68399157, grad/param norm = 1.9081e-01, time/batch = 15.3809s	
15747/22750 (epoch 34.609), train_loss = 0.65731657, grad/param norm = 2.3406e-01, time/batch = 15.1364s	
15748/22750 (epoch 34.611), train_loss = 0.74201883, grad/param norm = 2.1988e-01, time/batch = 15.0256s	
15749/22750 (epoch 34.613), train_loss = 0.71582829, grad/param norm = 2.0267e-01, time/batch = 15.4632s	
15750/22750 (epoch 34.615), train_loss = 0.72393246, grad/param norm = 1.7689e-01, time/batch = 14.8909s	
15751/22750 (epoch 34.618), train_loss = 0.74220390, grad/param norm = 2.1066e-01, time/batch = 17.1655s	
15752/22750 (epoch 34.620), train_loss = 0.75293822, grad/param norm = 2.2926e-01, time/batch = 17.2360s	
15753/22750 (epoch 34.622), train_loss = 0.62259213, grad/param norm = 1.7784e-01, time/batch = 15.6760s	
15754/22750 (epoch 34.624), train_loss = 0.72303267, grad/param norm = 2.3648e-01, time/batch = 18.0196s	
15755/22750 (epoch 34.626), train_loss = 0.63747023, grad/param norm = 2.3523e-01, time/batch = 17.5796s	
15756/22750 (epoch 34.629), train_loss = 0.71828994, grad/param norm = 2.1641e-01, time/batch = 15.8683s	
15757/22750 (epoch 34.631), train_loss = 0.76270906, grad/param norm = 1.8926e-01, time/batch = 15.8946s	
15758/22750 (epoch 34.633), train_loss = 0.65113351, grad/param norm = 2.1347e-01, time/batch = 17.2553s	
15759/22750 (epoch 34.635), train_loss = 0.75549781, grad/param norm = 2.1391e-01, time/batch = 20.2546s	
15760/22750 (epoch 34.637), train_loss = 0.82473795, grad/param norm = 2.7582e-01, time/batch = 18.3535s	
15761/22750 (epoch 34.640), train_loss = 0.84714736, grad/param norm = 2.3292e-01, time/batch = 17.4836s	
15762/22750 (epoch 34.642), train_loss = 0.87146581, grad/param norm = 2.1923e-01, time/batch = 16.4468s	
15763/22750 (epoch 34.644), train_loss = 0.78088800, grad/param norm = 3.1966e-01, time/batch = 16.6303s	
15764/22750 (epoch 34.646), train_loss = 0.83915285, grad/param norm = 2.8130e-01, time/batch = 17.6415s	
15765/22750 (epoch 34.648), train_loss = 0.81749369, grad/param norm = 2.4337e-01, time/batch = 17.3219s	
15766/22750 (epoch 34.651), train_loss = 0.83870474, grad/param norm = 2.3413e-01, time/batch = 16.0683s	
15767/22750 (epoch 34.653), train_loss = 0.84091842, grad/param norm = 1.9563e-01, time/batch = 16.2137s	
15768/22750 (epoch 34.655), train_loss = 0.79716113, grad/param norm = 2.0645e-01, time/batch = 18.4442s	
15769/22750 (epoch 34.657), train_loss = 0.93679303, grad/param norm = 2.6498e-01, time/batch = 18.4320s	
15770/22750 (epoch 34.659), train_loss = 0.95193876, grad/param norm = 2.3268e-01, time/batch = 16.8834s	
15771/22750 (epoch 34.662), train_loss = 0.93305337, grad/param norm = 2.6683e-01, time/batch = 20.4709s	
15772/22750 (epoch 34.664), train_loss = 0.83259270, grad/param norm = 2.2331e-01, time/batch = 17.2499s	
15773/22750 (epoch 34.666), train_loss = 0.66611109, grad/param norm = 2.0880e-01, time/batch = 17.3318s	
15774/22750 (epoch 34.668), train_loss = 0.77601018, grad/param norm = 2.2963e-01, time/batch = 19.9106s	
15775/22750 (epoch 34.670), train_loss = 0.74401331, grad/param norm = 2.1366e-01, time/batch = 19.9320s	
15776/22750 (epoch 34.673), train_loss = 0.95623939, grad/param norm = 2.6632e-01, time/batch = 18.4327s	
15777/22750 (epoch 34.675), train_loss = 1.10073629, grad/param norm = 2.9793e-01, time/batch = 20.0231s	
15778/22750 (epoch 34.677), train_loss = 0.94222656, grad/param norm = 2.6547e-01, time/batch = 19.5199s	
15779/22750 (epoch 34.679), train_loss = 0.93372230, grad/param norm = 2.5067e-01, time/batch = 18.4958s	
15780/22750 (epoch 34.681), train_loss = 0.94500434, grad/param norm = 2.7162e-01, time/batch = 16.4692s	
15781/22750 (epoch 34.684), train_loss = 0.97096367, grad/param norm = 2.6315e-01, time/batch = 17.4206s	
15782/22750 (epoch 34.686), train_loss = 0.98236878, grad/param norm = 2.6549e-01, time/batch = 17.2427s	
15783/22750 (epoch 34.688), train_loss = 0.94056846, grad/param norm = 2.4487e-01, time/batch = 16.7962s	
15784/22750 (epoch 34.690), train_loss = 0.96667568, grad/param norm = 3.3617e-01, time/batch = 18.0890s	
15785/22750 (epoch 34.692), train_loss = 0.94388195, grad/param norm = 2.8260e-01, time/batch = 18.4330s	
15786/22750 (epoch 34.695), train_loss = 0.83158709, grad/param norm = 2.1772e-01, time/batch = 18.0125s	
15787/22750 (epoch 34.697), train_loss = 0.84419543, grad/param norm = 2.5027e-01, time/batch = 17.7553s	
15788/22750 (epoch 34.699), train_loss = 0.75361160, grad/param norm = 1.9450e-01, time/batch = 17.5952s	
15789/22750 (epoch 34.701), train_loss = 0.68025362, grad/param norm = 2.1527e-01, time/batch = 18.9226s	
15790/22750 (epoch 34.703), train_loss = 0.76886071, grad/param norm = 2.2581e-01, time/batch = 16.6107s	
15791/22750 (epoch 34.705), train_loss = 0.74108919, grad/param norm = 2.0433e-01, time/batch = 19.5835s	
15792/22750 (epoch 34.708), train_loss = 0.82357424, grad/param norm = 2.8467e-01, time/batch = 18.2586s	
15793/22750 (epoch 34.710), train_loss = 0.70251700, grad/param norm = 2.3650e-01, time/batch = 16.4462s	
15794/22750 (epoch 34.712), train_loss = 0.66146711, grad/param norm = 2.1081e-01, time/batch = 18.6942s	
15795/22750 (epoch 34.714), train_loss = 0.66966241, grad/param norm = 1.9936e-01, time/batch = 18.5203s	
15796/22750 (epoch 34.716), train_loss = 0.68847738, grad/param norm = 2.2468e-01, time/batch = 16.3242s	
15797/22750 (epoch 34.719), train_loss = 0.76222633, grad/param norm = 2.7328e-01, time/batch = 18.5171s	
15798/22750 (epoch 34.721), train_loss = 0.87384430, grad/param norm = 2.2877e-01, time/batch = 16.3164s	
15799/22750 (epoch 34.723), train_loss = 0.87006735, grad/param norm = 2.3110e-01, time/batch = 15.8528s	
15800/22750 (epoch 34.725), train_loss = 0.75275137, grad/param norm = 2.3160e-01, time/batch = 16.0899s	
15801/22750 (epoch 34.727), train_loss = 0.75357805, grad/param norm = 2.3904e-01, time/batch = 17.0216s	
15802/22750 (epoch 34.730), train_loss = 0.77351511, grad/param norm = 2.3320e-01, time/batch = 18.2598s	
15803/22750 (epoch 34.732), train_loss = 0.72688950, grad/param norm = 2.0513e-01, time/batch = 16.8091s	
15804/22750 (epoch 34.734), train_loss = 0.64310307, grad/param norm = 1.8390e-01, time/batch = 18.1512s	
15805/22750 (epoch 34.736), train_loss = 0.74165842, grad/param norm = 2.1418e-01, time/batch = 16.2688s	
15806/22750 (epoch 34.738), train_loss = 0.81549345, grad/param norm = 2.3362e-01, time/batch = 16.3374s	
15807/22750 (epoch 34.741), train_loss = 0.89341350, grad/param norm = 2.2191e-01, time/batch = 16.3556s	
15808/22750 (epoch 34.743), train_loss = 0.81503187, grad/param norm = 2.1162e-01, time/batch = 16.1896s	
15809/22750 (epoch 34.745), train_loss = 0.65793007, grad/param norm = 1.8790e-01, time/batch = 16.2346s	
15810/22750 (epoch 34.747), train_loss = 0.78211303, grad/param norm = 1.9852e-01, time/batch = 15.9260s	
15811/22750 (epoch 34.749), train_loss = 0.90445453, grad/param norm = 2.8294e-01, time/batch = 16.0073s	
15812/22750 (epoch 34.752), train_loss = 0.81159277, grad/param norm = 2.8977e-01, time/batch = 15.6759s	
15813/22750 (epoch 34.754), train_loss = 0.78921293, grad/param norm = 2.3464e-01, time/batch = 16.3271s	
15814/22750 (epoch 34.756), train_loss = 0.74727877, grad/param norm = 2.7924e-01, time/batch = 16.1819s	
15815/22750 (epoch 34.758), train_loss = 0.71528204, grad/param norm = 2.2311e-01, time/batch = 15.6979s	
15816/22750 (epoch 34.760), train_loss = 0.72617194, grad/param norm = 2.1140e-01, time/batch = 15.4668s	
15817/22750 (epoch 34.763), train_loss = 0.78813819, grad/param norm = 2.3100e-01, time/batch = 16.4007s	
15818/22750 (epoch 34.765), train_loss = 0.76966691, grad/param norm = 2.1041e-01, time/batch = 16.4842s	
15819/22750 (epoch 34.767), train_loss = 0.83120978, grad/param norm = 2.2365e-01, time/batch = 15.8666s	
15820/22750 (epoch 34.769), train_loss = 0.94871597, grad/param norm = 2.6817e-01, time/batch = 16.0113s	
15821/22750 (epoch 34.771), train_loss = 0.95997576, grad/param norm = 2.5726e-01, time/batch = 15.7692s	
15822/22750 (epoch 34.774), train_loss = 0.75252697, grad/param norm = 2.5429e-01, time/batch = 16.2512s	
15823/22750 (epoch 34.776), train_loss = 0.88470261, grad/param norm = 2.4891e-01, time/batch = 16.0176s	
15824/22750 (epoch 34.778), train_loss = 0.93623198, grad/param norm = 2.5490e-01, time/batch = 16.3560s	
15825/22750 (epoch 34.780), train_loss = 0.81198779, grad/param norm = 2.1448e-01, time/batch = 16.4362s	
15826/22750 (epoch 34.782), train_loss = 0.96273754, grad/param norm = 2.4448e-01, time/batch = 16.1267s	
15827/22750 (epoch 34.785), train_loss = 0.77159550, grad/param norm = 2.1620e-01, time/batch = 15.7122s	
15828/22750 (epoch 34.787), train_loss = 0.67287036, grad/param norm = 2.2073e-01, time/batch = 15.9521s	
15829/22750 (epoch 34.789), train_loss = 0.76418653, grad/param norm = 1.9448e-01, time/batch = 16.6364s	
15830/22750 (epoch 34.791), train_loss = 0.75848362, grad/param norm = 2.2644e-01, time/batch = 15.6974s	
15831/22750 (epoch 34.793), train_loss = 0.72901024, grad/param norm = 2.6137e-01, time/batch = 15.8572s	
15832/22750 (epoch 34.796), train_loss = 0.67445636, grad/param norm = 2.1328e-01, time/batch = 15.6055s	
15833/22750 (epoch 34.798), train_loss = 0.72399698, grad/param norm = 1.9950e-01, time/batch = 17.2170s	
15834/22750 (epoch 34.800), train_loss = 0.71953674, grad/param norm = 2.6566e-01, time/batch = 23.7741s	
15835/22750 (epoch 34.802), train_loss = 0.64489055, grad/param norm = 2.3419e-01, time/batch = 15.6965s	
15836/22750 (epoch 34.804), train_loss = 0.84202832, grad/param norm = 2.1640e-01, time/batch = 15.8845s	
15837/22750 (epoch 34.807), train_loss = 0.82664868, grad/param norm = 2.2244e-01, time/batch = 15.6310s	
15838/22750 (epoch 34.809), train_loss = 0.91659659, grad/param norm = 2.3895e-01, time/batch = 15.7893s	
15839/22750 (epoch 34.811), train_loss = 0.78695910, grad/param norm = 2.2846e-01, time/batch = 15.3749s	
15840/22750 (epoch 34.813), train_loss = 0.81426424, grad/param norm = 2.0454e-01, time/batch = 9.2166s	
15841/22750 (epoch 34.815), train_loss = 0.92605600, grad/param norm = 2.2678e-01, time/batch = 0.7160s	
15842/22750 (epoch 34.818), train_loss = 0.87436431, grad/param norm = 2.0358e-01, time/batch = 0.7080s	
15843/22750 (epoch 34.820), train_loss = 0.99542867, grad/param norm = 2.3209e-01, time/batch = 0.7092s	
15844/22750 (epoch 34.822), train_loss = 0.83434741, grad/param norm = 2.2449e-01, time/batch = 0.7120s	
15845/22750 (epoch 34.824), train_loss = 0.69243225, grad/param norm = 2.0024e-01, time/batch = 0.7078s	
15846/22750 (epoch 34.826), train_loss = 0.79595922, grad/param norm = 2.1703e-01, time/batch = 0.7041s	
15847/22750 (epoch 34.829), train_loss = 0.92002731, grad/param norm = 2.5269e-01, time/batch = 0.8546s	
15848/22750 (epoch 34.831), train_loss = 0.91161017, grad/param norm = 2.8480e-01, time/batch = 1.0261s	
15849/22750 (epoch 34.833), train_loss = 0.82655400, grad/param norm = 2.4330e-01, time/batch = 1.0272s	
15850/22750 (epoch 34.835), train_loss = 0.70207307, grad/param norm = 2.1225e-01, time/batch = 1.0419s	
15851/22750 (epoch 34.837), train_loss = 0.76738908, grad/param norm = 2.0989e-01, time/batch = 1.0335s	
15852/22750 (epoch 34.840), train_loss = 0.71267277, grad/param norm = 2.0992e-01, time/batch = 1.6215s	
15853/22750 (epoch 34.842), train_loss = 0.74425199, grad/param norm = 2.4431e-01, time/batch = 1.9222s	
15854/22750 (epoch 34.844), train_loss = 0.82425568, grad/param norm = 2.4709e-01, time/batch = 2.6533s	
15855/22750 (epoch 34.846), train_loss = 0.84504528, grad/param norm = 2.1263e-01, time/batch = 15.6890s	
15856/22750 (epoch 34.848), train_loss = 0.73874530, grad/param norm = 2.0325e-01, time/batch = 15.7001s	
15857/22750 (epoch 34.851), train_loss = 0.72406612, grad/param norm = 2.2677e-01, time/batch = 16.1040s	
15858/22750 (epoch 34.853), train_loss = 0.88984560, grad/param norm = 2.1192e-01, time/batch = 15.7798s	
15859/22750 (epoch 34.855), train_loss = 0.74321246, grad/param norm = 1.9518e-01, time/batch = 16.6390s	
15860/22750 (epoch 34.857), train_loss = 0.84774646, grad/param norm = 2.3018e-01, time/batch = 16.2167s	
15861/22750 (epoch 34.859), train_loss = 0.81934047, grad/param norm = 2.4666e-01, time/batch = 16.4566s	
15862/22750 (epoch 34.862), train_loss = 0.97236204, grad/param norm = 2.6147e-01, time/batch = 16.6857s	
15863/22750 (epoch 34.864), train_loss = 0.81328368, grad/param norm = 2.1820e-01, time/batch = 16.3584s	
15864/22750 (epoch 34.866), train_loss = 0.84279054, grad/param norm = 2.0187e-01, time/batch = 16.6641s	
15865/22750 (epoch 34.868), train_loss = 0.70941350, grad/param norm = 1.8114e-01, time/batch = 16.6723s	
15866/22750 (epoch 34.870), train_loss = 0.68237970, grad/param norm = 1.9170e-01, time/batch = 16.0207s	
15867/22750 (epoch 34.873), train_loss = 0.77313447, grad/param norm = 2.0781e-01, time/batch = 16.5058s	
15868/22750 (epoch 34.875), train_loss = 0.84212857, grad/param norm = 2.0555e-01, time/batch = 16.6413s	
15869/22750 (epoch 34.877), train_loss = 0.73176654, grad/param norm = 2.1188e-01, time/batch = 16.0996s	
15870/22750 (epoch 34.879), train_loss = 0.88641654, grad/param norm = 2.4022e-01, time/batch = 15.9449s	
15871/22750 (epoch 34.881), train_loss = 0.84270140, grad/param norm = 2.4267e-01, time/batch = 15.8001s	
15872/22750 (epoch 34.884), train_loss = 0.72256533, grad/param norm = 1.9371e-01, time/batch = 16.5185s	
15873/22750 (epoch 34.886), train_loss = 0.82439483, grad/param norm = 2.1339e-01, time/batch = 16.1338s	
15874/22750 (epoch 34.888), train_loss = 0.85734895, grad/param norm = 2.0650e-01, time/batch = 16.1261s	
15875/22750 (epoch 34.890), train_loss = 0.84868921, grad/param norm = 2.4122e-01, time/batch = 16.1058s	
15876/22750 (epoch 34.892), train_loss = 1.07716269, grad/param norm = 2.7365e-01, time/batch = 16.8156s	
15877/22750 (epoch 34.895), train_loss = 0.77572450, grad/param norm = 2.4202e-01, time/batch = 16.4975s	
15878/22750 (epoch 34.897), train_loss = 0.88910691, grad/param norm = 2.3219e-01, time/batch = 16.1770s	
15879/22750 (epoch 34.899), train_loss = 0.84010292, grad/param norm = 2.4806e-01, time/batch = 16.2566s	
15880/22750 (epoch 34.901), train_loss = 0.87049182, grad/param norm = 2.4593e-01, time/batch = 16.5670s	
15881/22750 (epoch 34.903), train_loss = 0.79300948, grad/param norm = 2.3057e-01, time/batch = 16.7257s	
15882/22750 (epoch 34.905), train_loss = 0.86361510, grad/param norm = 2.2845e-01, time/batch = 16.7488s	
15883/22750 (epoch 34.908), train_loss = 0.68832303, grad/param norm = 2.1940e-01, time/batch = 16.4557s	
15884/22750 (epoch 34.910), train_loss = 0.63079054, grad/param norm = 2.0436e-01, time/batch = 16.1179s	
15885/22750 (epoch 34.912), train_loss = 0.76902476, grad/param norm = 2.0243e-01, time/batch = 16.6541s	
15886/22750 (epoch 34.914), train_loss = 0.80349360, grad/param norm = 2.2246e-01, time/batch = 16.3469s	
15887/22750 (epoch 34.916), train_loss = 0.63966328, grad/param norm = 1.9749e-01, time/batch = 15.6088s	
15888/22750 (epoch 34.919), train_loss = 0.77908091, grad/param norm = 2.3191e-01, time/batch = 15.6812s	
15889/22750 (epoch 34.921), train_loss = 0.62007348, grad/param norm = 1.9522e-01, time/batch = 15.8500s	
15890/22750 (epoch 34.923), train_loss = 0.71843564, grad/param norm = 2.1019e-01, time/batch = 11.7446s	
15891/22750 (epoch 34.925), train_loss = 0.78372865, grad/param norm = 1.9941e-01, time/batch = 0.7176s	
15892/22750 (epoch 34.927), train_loss = 0.64080158, grad/param norm = 2.0849e-01, time/batch = 0.7164s	
15893/22750 (epoch 34.930), train_loss = 0.60198783, grad/param norm = 2.0115e-01, time/batch = 0.7134s	
15894/22750 (epoch 34.932), train_loss = 0.78076964, grad/param norm = 2.1915e-01, time/batch = 0.7159s	
15895/22750 (epoch 34.934), train_loss = 0.64809208, grad/param norm = 1.8409e-01, time/batch = 0.7195s	
15896/22750 (epoch 34.936), train_loss = 0.87911301, grad/param norm = 2.2025e-01, time/batch = 0.7164s	
15897/22750 (epoch 34.938), train_loss = 0.87619695, grad/param norm = 2.0346e-01, time/batch = 0.8270s	
15898/22750 (epoch 34.941), train_loss = 0.94461271, grad/param norm = 2.5265e-01, time/batch = 1.0351s	
15899/22750 (epoch 34.943), train_loss = 0.81121057, grad/param norm = 2.1542e-01, time/batch = 1.0373s	
15900/22750 (epoch 34.945), train_loss = 0.81021565, grad/param norm = 2.4690e-01, time/batch = 1.0292s	
15901/22750 (epoch 34.947), train_loss = 0.74297277, grad/param norm = 2.2646e-01, time/batch = 1.0392s	
15902/22750 (epoch 34.949), train_loss = 0.74332924, grad/param norm = 2.2817e-01, time/batch = 1.5214s	
15903/22750 (epoch 34.952), train_loss = 0.74678009, grad/param norm = 2.0528e-01, time/batch = 1.9284s	
15904/22750 (epoch 34.954), train_loss = 0.69364319, grad/param norm = 2.1678e-01, time/batch = 1.9173s	
15905/22750 (epoch 34.956), train_loss = 0.83979565, grad/param norm = 2.2175e-01, time/batch = 15.6852s	
15906/22750 (epoch 34.958), train_loss = 0.69566859, grad/param norm = 1.8968e-01, time/batch = 15.4639s	
15907/22750 (epoch 34.960), train_loss = 0.69028606, grad/param norm = 2.1304e-01, time/batch = 16.1247s	
15908/22750 (epoch 34.963), train_loss = 0.80096544, grad/param norm = 2.1664e-01, time/batch = 16.3652s	
15909/22750 (epoch 34.965), train_loss = 0.85944514, grad/param norm = 2.1734e-01, time/batch = 16.3422s	
15910/22750 (epoch 34.967), train_loss = 0.84244737, grad/param norm = 2.4531e-01, time/batch = 15.8664s	
15911/22750 (epoch 34.969), train_loss = 0.77586243, grad/param norm = 2.3866e-01, time/batch = 16.6487s	
15912/22750 (epoch 34.971), train_loss = 0.72452462, grad/param norm = 2.0378e-01, time/batch = 16.1816s	
15913/22750 (epoch 34.974), train_loss = 0.72243109, grad/param norm = 1.9797e-01, time/batch = 16.5646s	
15914/22750 (epoch 34.976), train_loss = 0.76989803, grad/param norm = 2.4512e-01, time/batch = 16.4116s	
15915/22750 (epoch 34.978), train_loss = 0.74432174, grad/param norm = 2.1269e-01, time/batch = 16.1528s	
15916/22750 (epoch 34.980), train_loss = 0.89928775, grad/param norm = 2.7418e-01, time/batch = 15.6166s	
15917/22750 (epoch 34.982), train_loss = 0.73292235, grad/param norm = 2.0004e-01, time/batch = 15.9476s	
15918/22750 (epoch 34.985), train_loss = 0.91845883, grad/param norm = 2.3320e-01, time/batch = 16.1787s	
15919/22750 (epoch 34.987), train_loss = 0.65127014, grad/param norm = 1.8768e-01, time/batch = 16.4213s	
15920/22750 (epoch 34.989), train_loss = 0.73321357, grad/param norm = 2.4299e-01, time/batch = 16.1027s	
15921/22750 (epoch 34.991), train_loss = 0.82227546, grad/param norm = 2.4410e-01, time/batch = 17.1581s	
15922/22750 (epoch 34.993), train_loss = 0.78651771, grad/param norm = 2.4698e-01, time/batch = 16.8267s	
15923/22750 (epoch 34.996), train_loss = 0.69866684, grad/param norm = 2.3267e-01, time/batch = 17.4214s	
15924/22750 (epoch 34.998), train_loss = 0.90594096, grad/param norm = 2.8930e-01, time/batch = 16.9736s	
decayed learning rate by a factor 0.97 to 0.00090593092819348	
15925/22750 (epoch 35.000), train_loss = 0.77135279, grad/param norm = 2.1852e-01, time/batch = 18.3380s	
15926/22750 (epoch 35.002), train_loss = 0.94051940, grad/param norm = 2.3329e-01, time/batch = 18.7539s	
15927/22750 (epoch 35.004), train_loss = 0.75346857, grad/param norm = 2.2198e-01, time/batch = 20.1030s	
15928/22750 (epoch 35.007), train_loss = 0.75555007, grad/param norm = 2.3933e-01, time/batch = 18.2823s	
15929/22750 (epoch 35.009), train_loss = 0.91434806, grad/param norm = 2.4060e-01, time/batch = 16.8323s	
15930/22750 (epoch 35.011), train_loss = 0.97959616, grad/param norm = 2.7172e-01, time/batch = 19.0048s	
15931/22750 (epoch 35.013), train_loss = 0.91503339, grad/param norm = 2.4788e-01, time/batch = 17.1440s	
15932/22750 (epoch 35.015), train_loss = 0.83209641, grad/param norm = 2.3690e-01, time/batch = 16.7148s	
15933/22750 (epoch 35.018), train_loss = 0.89745084, grad/param norm = 2.4422e-01, time/batch = 15.9523s	
15934/22750 (epoch 35.020), train_loss = 0.93755668, grad/param norm = 2.2228e-01, time/batch = 16.2470s	
15935/22750 (epoch 35.022), train_loss = 0.78746817, grad/param norm = 2.3145e-01, time/batch = 16.0029s	
15936/22750 (epoch 35.024), train_loss = 0.81296674, grad/param norm = 2.4614e-01, time/batch = 17.9082s	
15937/22750 (epoch 35.026), train_loss = 0.84087360, grad/param norm = 2.1473e-01, time/batch = 15.9640s	
15938/22750 (epoch 35.029), train_loss = 0.66168085, grad/param norm = 2.1596e-01, time/batch = 16.8585s	
15939/22750 (epoch 35.031), train_loss = 1.00659580, grad/param norm = 2.4081e-01, time/batch = 27.5462s	
15940/22750 (epoch 35.033), train_loss = 0.80808155, grad/param norm = 2.3159e-01, time/batch = 22.5390s	
15941/22750 (epoch 35.035), train_loss = 0.87139512, grad/param norm = 2.4192e-01, time/batch = 17.0911s	
15942/22750 (epoch 35.037), train_loss = 0.88794520, grad/param norm = 2.2650e-01, time/batch = 15.5293s	
15943/22750 (epoch 35.040), train_loss = 0.79078458, grad/param norm = 2.0301e-01, time/batch = 18.0165s	
15944/22750 (epoch 35.042), train_loss = 0.82548372, grad/param norm = 2.2429e-01, time/batch = 16.7043s	
15945/22750 (epoch 35.044), train_loss = 0.78991589, grad/param norm = 2.0477e-01, time/batch = 16.7904s	
15946/22750 (epoch 35.046), train_loss = 0.86902143, grad/param norm = 2.3964e-01, time/batch = 18.1092s	
15947/22750 (epoch 35.048), train_loss = 0.79985812, grad/param norm = 2.1127e-01, time/batch = 18.0588s	
15948/22750 (epoch 35.051), train_loss = 0.80825471, grad/param norm = 2.3651e-01, time/batch = 15.9445s	
15949/22750 (epoch 35.053), train_loss = 0.77832951, grad/param norm = 1.8882e-01, time/batch = 16.6435s	
15950/22750 (epoch 35.055), train_loss = 0.68158508, grad/param norm = 2.0030e-01, time/batch = 15.6295s	
15951/22750 (epoch 35.057), train_loss = 0.95158416, grad/param norm = 2.6721e-01, time/batch = 15.9171s	
15952/22750 (epoch 35.059), train_loss = 0.61544118, grad/param norm = 2.2280e-01, time/batch = 16.4260s	
15953/22750 (epoch 35.062), train_loss = 0.68313330, grad/param norm = 2.1363e-01, time/batch = 16.6793s	
15954/22750 (epoch 35.064), train_loss = 0.89037273, grad/param norm = 2.1879e-01, time/batch = 18.5362s	
15955/22750 (epoch 35.066), train_loss = 0.72247764, grad/param norm = 2.0130e-01, time/batch = 17.6968s	
15956/22750 (epoch 35.068), train_loss = 0.71290500, grad/param norm = 1.9359e-01, time/batch = 17.4371s	
15957/22750 (epoch 35.070), train_loss = 0.61209086, grad/param norm = 1.8606e-01, time/batch = 16.5730s	
15958/22750 (epoch 35.073), train_loss = 0.73237886, grad/param norm = 2.2318e-01, time/batch = 16.2613s	
15959/22750 (epoch 35.075), train_loss = 0.79992518, grad/param norm = 2.2360e-01, time/batch = 17.0710s	
15960/22750 (epoch 35.077), train_loss = 0.58891225, grad/param norm = 2.3173e-01, time/batch = 17.9182s	
15961/22750 (epoch 35.079), train_loss = 0.78451962, grad/param norm = 2.3216e-01, time/batch = 18.7564s	
15962/22750 (epoch 35.081), train_loss = 0.75047567, grad/param norm = 2.3624e-01, time/batch = 17.5780s	
15963/22750 (epoch 35.084), train_loss = 0.76154979, grad/param norm = 2.2131e-01, time/batch = 17.9832s	
15964/22750 (epoch 35.086), train_loss = 0.77989863, grad/param norm = 2.0316e-01, time/batch = 19.4385s	
15965/22750 (epoch 35.088), train_loss = 0.72600828, grad/param norm = 2.2488e-01, time/batch = 18.7945s	
15966/22750 (epoch 35.090), train_loss = 0.76383522, grad/param norm = 2.1391e-01, time/batch = 18.5879s	
15967/22750 (epoch 35.092), train_loss = 0.84204527, grad/param norm = 2.1176e-01, time/batch = 19.9906s	
15968/22750 (epoch 35.095), train_loss = 0.71142423, grad/param norm = 2.0592e-01, time/batch = 19.5591s	
15969/22750 (epoch 35.097), train_loss = 0.77974060, grad/param norm = 1.9295e-01, time/batch = 16.9050s	
15970/22750 (epoch 35.099), train_loss = 0.73051447, grad/param norm = 2.1039e-01, time/batch = 18.0020s	
15971/22750 (epoch 35.101), train_loss = 0.65156112, grad/param norm = 2.0020e-01, time/batch = 20.4008s	
15972/22750 (epoch 35.103), train_loss = 0.83933685, grad/param norm = 2.4702e-01, time/batch = 17.3451s	
15973/22750 (epoch 35.105), train_loss = 0.90909847, grad/param norm = 2.4970e-01, time/batch = 19.6967s	
15974/22750 (epoch 35.108), train_loss = 0.80169957, grad/param norm = 2.1781e-01, time/batch = 19.5264s	
15975/22750 (epoch 35.110), train_loss = 0.88305791, grad/param norm = 2.1654e-01, time/batch = 18.1911s	
15976/22750 (epoch 35.112), train_loss = 0.65494523, grad/param norm = 1.7011e-01, time/batch = 18.5035s	
15977/22750 (epoch 35.114), train_loss = 0.58642737, grad/param norm = 2.0547e-01, time/batch = 18.4220s	
15978/22750 (epoch 35.116), train_loss = 0.78692540, grad/param norm = 2.1835e-01, time/batch = 18.1780s	
15979/22750 (epoch 35.119), train_loss = 0.72667204, grad/param norm = 1.9250e-01, time/batch = 17.5009s	
15980/22750 (epoch 35.121), train_loss = 0.75662573, grad/param norm = 2.4875e-01, time/batch = 19.5848s	
15981/22750 (epoch 35.123), train_loss = 0.66298424, grad/param norm = 2.1255e-01, time/batch = 17.5804s	
15982/22750 (epoch 35.125), train_loss = 0.89867554, grad/param norm = 2.1094e-01, time/batch = 16.0702s	
15983/22750 (epoch 35.127), train_loss = 0.73960182, grad/param norm = 2.1716e-01, time/batch = 16.6174s	
15984/22750 (epoch 35.130), train_loss = 0.75002906, grad/param norm = 2.0430e-01, time/batch = 16.2141s	
15985/22750 (epoch 35.132), train_loss = 0.72131178, grad/param norm = 2.1452e-01, time/batch = 16.6420s	
15986/22750 (epoch 35.134), train_loss = 0.74129808, grad/param norm = 1.9630e-01, time/batch = 16.5662s	
15987/22750 (epoch 35.136), train_loss = 0.62440535, grad/param norm = 2.0837e-01, time/batch = 16.8306s	
15988/22750 (epoch 35.138), train_loss = 0.83693692, grad/param norm = 2.3078e-01, time/batch = 18.5980s	
15989/22750 (epoch 35.141), train_loss = 0.79109243, grad/param norm = 2.2185e-01, time/batch = 16.0920s	
15990/22750 (epoch 35.143), train_loss = 0.70839608, grad/param norm = 1.9698e-01, time/batch = 16.2487s	
15991/22750 (epoch 35.145), train_loss = 0.90735515, grad/param norm = 2.3898e-01, time/batch = 18.7015s	
15992/22750 (epoch 35.147), train_loss = 0.94235203, grad/param norm = 2.4706e-01, time/batch = 18.6058s	
15993/22750 (epoch 35.149), train_loss = 0.78555482, grad/param norm = 2.1654e-01, time/batch = 20.1859s	
15994/22750 (epoch 35.152), train_loss = 0.76935468, grad/param norm = 2.1437e-01, time/batch = 16.2218s	
15995/22750 (epoch 35.154), train_loss = 0.71502583, grad/param norm = 2.2222e-01, time/batch = 19.2536s	
15996/22750 (epoch 35.156), train_loss = 0.69663178, grad/param norm = 2.1731e-01, time/batch = 17.5848s	
15997/22750 (epoch 35.158), train_loss = 0.68605190, grad/param norm = 2.1399e-01, time/batch = 18.2462s	
15998/22750 (epoch 35.160), train_loss = 0.78661603, grad/param norm = 2.3727e-01, time/batch = 19.0917s	
15999/22750 (epoch 35.163), train_loss = 0.90827349, grad/param norm = 2.2017e-01, time/batch = 18.1538s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_wakata_epoch35.16_1.7064.t7	
16000/22750 (epoch 35.165), train_loss = 0.83280975, grad/param norm = 2.2316e-01, time/batch = 19.4346s	
16001/22750 (epoch 35.167), train_loss = 1.44546935, grad/param norm = 3.2071e-01, time/batch = 17.3090s	
16002/22750 (epoch 35.169), train_loss = 0.80430871, grad/param norm = 2.5169e-01, time/batch = 16.6821s	
16003/22750 (epoch 35.171), train_loss = 0.66070164, grad/param norm = 1.8713e-01, time/batch = 16.9174s	
16004/22750 (epoch 35.174), train_loss = 0.66501898, grad/param norm = 2.2044e-01, time/batch = 16.7426s	
16005/22750 (epoch 35.176), train_loss = 0.68937026, grad/param norm = 2.2784e-01, time/batch = 17.0919s	
16006/22750 (epoch 35.178), train_loss = 0.70614179, grad/param norm = 1.9852e-01, time/batch = 17.0698s	
16007/22750 (epoch 35.180), train_loss = 0.88303769, grad/param norm = 3.3205e-01, time/batch = 17.0269s	
16008/22750 (epoch 35.182), train_loss = 0.82811276, grad/param norm = 2.1068e-01, time/batch = 17.9150s	
16009/22750 (epoch 35.185), train_loss = 0.86351333, grad/param norm = 2.5356e-01, time/batch = 18.3389s	
16010/22750 (epoch 35.187), train_loss = 0.68106826, grad/param norm = 2.1972e-01, time/batch = 16.6719s	
16011/22750 (epoch 35.189), train_loss = 0.69902879, grad/param norm = 2.8224e-01, time/batch = 20.3949s	
16012/22750 (epoch 35.191), train_loss = 0.72945708, grad/param norm = 2.3261e-01, time/batch = 17.9310s	
16013/22750 (epoch 35.193), train_loss = 0.83831248, grad/param norm = 2.2613e-01, time/batch = 17.6791s	
16014/22750 (epoch 35.196), train_loss = 0.75583677, grad/param norm = 2.3506e-01, time/batch = 20.3354s	
16015/22750 (epoch 35.198), train_loss = 0.58241687, grad/param norm = 2.1382e-01, time/batch = 20.5149s	
16016/22750 (epoch 35.200), train_loss = 0.77635499, grad/param norm = 2.4463e-01, time/batch = 18.9132s	
16017/22750 (epoch 35.202), train_loss = 0.83525188, grad/param norm = 2.4918e-01, time/batch = 17.2237s	
16018/22750 (epoch 35.204), train_loss = 0.79481612, grad/param norm = 2.1309e-01, time/batch = 17.1656s	
16019/22750 (epoch 35.207), train_loss = 0.77940075, grad/param norm = 2.0419e-01, time/batch = 18.2537s	
16020/22750 (epoch 35.209), train_loss = 0.73395785, grad/param norm = 2.1587e-01, time/batch = 16.7512s	
16021/22750 (epoch 35.211), train_loss = 0.67373966, grad/param norm = 2.3462e-01, time/batch = 18.4227s	
16022/22750 (epoch 35.213), train_loss = 0.61087288, grad/param norm = 2.2457e-01, time/batch = 17.0912s	
16023/22750 (epoch 35.215), train_loss = 0.57807478, grad/param norm = 1.8563e-01, time/batch = 18.1127s	
16024/22750 (epoch 35.218), train_loss = 0.70407871, grad/param norm = 2.5685e-01, time/batch = 18.6215s	
16025/22750 (epoch 35.220), train_loss = 0.63330171, grad/param norm = 2.1565e-01, time/batch = 19.8704s	
16026/22750 (epoch 35.222), train_loss = 0.65306701, grad/param norm = 2.0181e-01, time/batch = 16.6639s	
16027/22750 (epoch 35.224), train_loss = 0.68664984, grad/param norm = 1.9459e-01, time/batch = 18.9051s	
16028/22750 (epoch 35.226), train_loss = 0.75119974, grad/param norm = 1.9858e-01, time/batch = 18.6659s	
16029/22750 (epoch 35.229), train_loss = 0.78440080, grad/param norm = 2.2217e-01, time/batch = 19.3996s	
16030/22750 (epoch 35.231), train_loss = 0.68575479, grad/param norm = 2.4523e-01, time/batch = 19.1684s	
16031/22750 (epoch 35.233), train_loss = 0.63330060, grad/param norm = 2.2946e-01, time/batch = 17.2388s	
16032/22750 (epoch 35.235), train_loss = 0.60013640, grad/param norm = 2.2199e-01, time/batch = 16.2518s	
16033/22750 (epoch 35.237), train_loss = 0.69672071, grad/param norm = 2.5394e-01, time/batch = 16.8306s	
16034/22750 (epoch 35.240), train_loss = 0.76181238, grad/param norm = 2.0660e-01, time/batch = 16.1079s	
16035/22750 (epoch 35.242), train_loss = 0.92540645, grad/param norm = 2.9017e-01, time/batch = 16.4065s	
16036/22750 (epoch 35.244), train_loss = 0.90335816, grad/param norm = 2.2731e-01, time/batch = 16.0692s	
16037/22750 (epoch 35.246), train_loss = 0.92549957, grad/param norm = 2.5085e-01, time/batch = 16.4044s	
16038/22750 (epoch 35.248), train_loss = 0.77401425, grad/param norm = 2.1977e-01, time/batch = 16.0830s	
16039/22750 (epoch 35.251), train_loss = 0.86951466, grad/param norm = 2.4612e-01, time/batch = 16.1729s	
16040/22750 (epoch 35.253), train_loss = 0.81986992, grad/param norm = 2.5876e-01, time/batch = 16.6659s	
16041/22750 (epoch 35.255), train_loss = 0.78439719, grad/param norm = 2.1149e-01, time/batch = 16.4091s	
16042/22750 (epoch 35.257), train_loss = 0.71219948, grad/param norm = 2.3023e-01, time/batch = 16.5068s	
16043/22750 (epoch 35.259), train_loss = 0.88452608, grad/param norm = 2.7596e-01, time/batch = 16.1267s	
16044/22750 (epoch 35.262), train_loss = 0.79655994, grad/param norm = 2.5687e-01, time/batch = 16.7435s	
16045/22750 (epoch 35.264), train_loss = 0.61890162, grad/param norm = 2.4584e-01, time/batch = 16.0849s	
16046/22750 (epoch 35.266), train_loss = 0.75404801, grad/param norm = 2.4779e-01, time/batch = 15.8436s	
16047/22750 (epoch 35.268), train_loss = 0.88981127, grad/param norm = 2.3701e-01, time/batch = 16.0032s	
16048/22750 (epoch 35.270), train_loss = 0.68381665, grad/param norm = 2.3014e-01, time/batch = 15.7754s	
16049/22750 (epoch 35.273), train_loss = 1.01737085, grad/param norm = 2.3418e-01, time/batch = 15.5253s	
16050/22750 (epoch 35.275), train_loss = 0.91541260, grad/param norm = 2.1582e-01, time/batch = 16.1799s	
16051/22750 (epoch 35.277), train_loss = 0.75813867, grad/param norm = 2.5036e-01, time/batch = 16.5737s	
16052/22750 (epoch 35.279), train_loss = 0.67267154, grad/param norm = 2.2302e-01, time/batch = 16.5786s	
16053/22750 (epoch 35.281), train_loss = 0.91237432, grad/param norm = 2.4527e-01, time/batch = 15.5489s	
16054/22750 (epoch 35.284), train_loss = 0.79314926, grad/param norm = 1.8850e-01, time/batch = 15.3841s	
16055/22750 (epoch 35.286), train_loss = 0.84120893, grad/param norm = 2.4298e-01, time/batch = 15.8716s	
16056/22750 (epoch 35.288), train_loss = 0.92402171, grad/param norm = 2.2834e-01, time/batch = 16.2356s	
16057/22750 (epoch 35.290), train_loss = 0.81964963, grad/param norm = 2.4348e-01, time/batch = 16.2400s	
16058/22750 (epoch 35.292), train_loss = 0.86611922, grad/param norm = 2.7738e-01, time/batch = 15.8486s	
16059/22750 (epoch 35.295), train_loss = 0.81183018, grad/param norm = 2.4448e-01, time/batch = 16.1725s	
16060/22750 (epoch 35.297), train_loss = 0.79758211, grad/param norm = 2.2860e-01, time/batch = 16.3872s	
16061/22750 (epoch 35.299), train_loss = 0.88111435, grad/param norm = 2.6281e-01, time/batch = 16.0021s	
16062/22750 (epoch 35.301), train_loss = 0.78947204, grad/param norm = 2.1163e-01, time/batch = 16.0203s	
16063/22750 (epoch 35.303), train_loss = 0.84447402, grad/param norm = 2.2790e-01, time/batch = 16.1127s	
16064/22750 (epoch 35.305), train_loss = 0.95256599, grad/param norm = 2.3300e-01, time/batch = 15.7118s	
16065/22750 (epoch 35.308), train_loss = 0.84637126, grad/param norm = 2.1518e-01, time/batch = 16.1175s	
16066/22750 (epoch 35.310), train_loss = 0.73729040, grad/param norm = 2.5421e-01, time/batch = 16.1764s	
16067/22750 (epoch 35.312), train_loss = 0.81411893, grad/param norm = 2.1606e-01, time/batch = 16.4915s	
16068/22750 (epoch 35.314), train_loss = 0.79632856, grad/param norm = 2.0303e-01, time/batch = 15.7775s	
16069/22750 (epoch 35.316), train_loss = 0.77084352, grad/param norm = 2.2110e-01, time/batch = 15.6901s	
16070/22750 (epoch 35.319), train_loss = 0.82702386, grad/param norm = 2.5947e-01, time/batch = 16.0126s	
16071/22750 (epoch 35.321), train_loss = 0.75064565, grad/param norm = 2.4713e-01, time/batch = 15.8455s	
16072/22750 (epoch 35.323), train_loss = 0.82555825, grad/param norm = 2.3735e-01, time/batch = 15.7652s	
16073/22750 (epoch 35.325), train_loss = 0.70320993, grad/param norm = 1.9897e-01, time/batch = 15.7022s	
16074/22750 (epoch 35.327), train_loss = 0.74189914, grad/param norm = 2.5279e-01, time/batch = 15.9410s	
16075/22750 (epoch 35.330), train_loss = 0.91922704, grad/param norm = 2.4241e-01, time/batch = 15.5561s	
16076/22750 (epoch 35.332), train_loss = 0.97571144, grad/param norm = 2.2114e-01, time/batch = 15.6272s	
16077/22750 (epoch 35.334), train_loss = 0.65261171, grad/param norm = 2.1575e-01, time/batch = 15.7671s	
16078/22750 (epoch 35.336), train_loss = 0.87429018, grad/param norm = 2.2062e-01, time/batch = 16.0072s	
16079/22750 (epoch 35.338), train_loss = 0.77518392, grad/param norm = 2.2155e-01, time/batch = 15.7657s	
16080/22750 (epoch 35.341), train_loss = 0.80703779, grad/param norm = 2.3473e-01, time/batch = 15.7733s	
16081/22750 (epoch 35.343), train_loss = 0.69640157, grad/param norm = 2.5180e-01, time/batch = 16.8756s	
16082/22750 (epoch 35.345), train_loss = 0.85335676, grad/param norm = 2.8287e-01, time/batch = 16.7329s	
16083/22750 (epoch 35.347), train_loss = 0.89297358, grad/param norm = 2.3866e-01, time/batch = 16.0995s	
16084/22750 (epoch 35.349), train_loss = 0.65743521, grad/param norm = 2.4474e-01, time/batch = 15.6403s	
16085/22750 (epoch 35.352), train_loss = 0.91514729, grad/param norm = 2.4978e-01, time/batch = 16.1179s	
16086/22750 (epoch 35.354), train_loss = 0.90017095, grad/param norm = 2.5106e-01, time/batch = 15.6300s	
16087/22750 (epoch 35.356), train_loss = 0.85035807, grad/param norm = 2.1135e-01, time/batch = 15.9344s	
16088/22750 (epoch 35.358), train_loss = 0.76821854, grad/param norm = 2.2505e-01, time/batch = 16.0081s	
16089/22750 (epoch 35.360), train_loss = 0.93254995, grad/param norm = 2.2560e-01, time/batch = 16.8813s	
16090/22750 (epoch 35.363), train_loss = 0.76545861, grad/param norm = 2.6744e-01, time/batch = 15.5156s	
16091/22750 (epoch 35.365), train_loss = 0.63985678, grad/param norm = 2.2526e-01, time/batch = 15.5265s	
16092/22750 (epoch 35.367), train_loss = 0.73529477, grad/param norm = 2.3559e-01, time/batch = 15.6044s	
16093/22750 (epoch 35.369), train_loss = 0.80505702, grad/param norm = 2.2125e-01, time/batch = 16.2450s	
16094/22750 (epoch 35.371), train_loss = 0.81892110, grad/param norm = 2.2502e-01, time/batch = 15.4649s	
16095/22750 (epoch 35.374), train_loss = 0.71182248, grad/param norm = 2.3733e-01, time/batch = 15.4733s	
16096/22750 (epoch 35.376), train_loss = 0.78734285, grad/param norm = 2.5337e-01, time/batch = 15.7223s	
16097/22750 (epoch 35.378), train_loss = 0.79304814, grad/param norm = 2.0985e-01, time/batch = 15.3813s	
16098/22750 (epoch 35.380), train_loss = 0.87622156, grad/param norm = 2.4212e-01, time/batch = 15.6140s	
16099/22750 (epoch 35.382), train_loss = 0.77877005, grad/param norm = 2.1956e-01, time/batch = 16.0986s	
16100/22750 (epoch 35.385), train_loss = 0.85456708, grad/param norm = 2.1011e-01, time/batch = 16.6484s	
16101/22750 (epoch 35.387), train_loss = 0.82723741, grad/param norm = 2.0945e-01, time/batch = 16.4754s	
16102/22750 (epoch 35.389), train_loss = 0.64404839, grad/param norm = 1.9228e-01, time/batch = 15.3613s	
16103/22750 (epoch 35.391), train_loss = 0.50128042, grad/param norm = 1.8105e-01, time/batch = 15.5266s	
16104/22750 (epoch 35.393), train_loss = 0.65846913, grad/param norm = 2.2082e-01, time/batch = 16.3382s	
16105/22750 (epoch 35.396), train_loss = 0.82300588, grad/param norm = 2.2832e-01, time/batch = 15.7023s	
16106/22750 (epoch 35.398), train_loss = 0.74491224, grad/param norm = 2.0789e-01, time/batch = 15.5570s	
16107/22750 (epoch 35.400), train_loss = 0.78965313, grad/param norm = 2.3486e-01, time/batch = 15.9599s	
16108/22750 (epoch 35.402), train_loss = 0.81573776, grad/param norm = 2.2133e-01, time/batch = 16.3035s	
16109/22750 (epoch 35.404), train_loss = 0.89413634, grad/param norm = 2.2317e-01, time/batch = 15.6845s	
16110/22750 (epoch 35.407), train_loss = 0.88596196, grad/param norm = 2.5040e-01, time/batch = 16.1776s	
16111/22750 (epoch 35.409), train_loss = 0.72787088, grad/param norm = 2.3285e-01, time/batch = 16.1727s	
16112/22750 (epoch 35.411), train_loss = 0.72398307, grad/param norm = 2.1444e-01, time/batch = 15.7646s	
16113/22750 (epoch 35.413), train_loss = 0.57465184, grad/param norm = 1.9670e-01, time/batch = 16.1756s	
16114/22750 (epoch 35.415), train_loss = 0.65388803, grad/param norm = 2.0904e-01, time/batch = 15.8508s	
16115/22750 (epoch 35.418), train_loss = 0.75246696, grad/param norm = 2.4448e-01, time/batch = 16.2638s	
16116/22750 (epoch 35.420), train_loss = 0.86971861, grad/param norm = 3.6668e-01, time/batch = 15.8814s	
16117/22750 (epoch 35.422), train_loss = 1.00478221, grad/param norm = 3.0357e-01, time/batch = 15.7143s	
16118/22750 (epoch 35.424), train_loss = 0.96974160, grad/param norm = 2.4802e-01, time/batch = 15.4713s	
16119/22750 (epoch 35.426), train_loss = 0.95124399, grad/param norm = 2.2450e-01, time/batch = 16.5666s	
16120/22750 (epoch 35.429), train_loss = 0.71961594, grad/param norm = 2.0827e-01, time/batch = 16.6793s	
16121/22750 (epoch 35.431), train_loss = 0.65744178, grad/param norm = 2.0319e-01, time/batch = 16.1994s	
16122/22750 (epoch 35.433), train_loss = 0.74388058, grad/param norm = 1.9994e-01, time/batch = 16.0883s	
16123/22750 (epoch 35.435), train_loss = 0.57794818, grad/param norm = 1.7226e-01, time/batch = 18.5837s	
16124/22750 (epoch 35.437), train_loss = 0.50395245, grad/param norm = 1.9630e-01, time/batch = 17.9324s	
16125/22750 (epoch 35.440), train_loss = 0.73902227, grad/param norm = 2.4197e-01, time/batch = 17.0398s	
16126/22750 (epoch 35.442), train_loss = 0.79735873, grad/param norm = 2.5762e-01, time/batch = 17.2636s	
16127/22750 (epoch 35.444), train_loss = 0.74091593, grad/param norm = 2.2812e-01, time/batch = 19.0835s	
16128/22750 (epoch 35.446), train_loss = 0.76954678, grad/param norm = 2.5700e-01, time/batch = 17.0884s	
16129/22750 (epoch 35.448), train_loss = 0.99184614, grad/param norm = 2.5397e-01, time/batch = 16.6271s	
16130/22750 (epoch 35.451), train_loss = 0.96163810, grad/param norm = 2.3740e-01, time/batch = 17.0027s	
16131/22750 (epoch 35.453), train_loss = 0.84300727, grad/param norm = 2.5051e-01, time/batch = 16.6660s	
16132/22750 (epoch 35.455), train_loss = 0.94996945, grad/param norm = 2.3088e-01, time/batch = 17.3069s	
16133/22750 (epoch 35.457), train_loss = 0.84755983, grad/param norm = 3.4769e-01, time/batch = 17.4824s	
16134/22750 (epoch 35.459), train_loss = 0.85229551, grad/param norm = 2.2917e-01, time/batch = 20.1626s	
16135/22750 (epoch 35.462), train_loss = 0.81720177, grad/param norm = 2.2758e-01, time/batch = 20.0140s	
16136/22750 (epoch 35.464), train_loss = 0.69170581, grad/param norm = 2.1674e-01, time/batch = 16.4338s	
16137/22750 (epoch 35.466), train_loss = 0.87329719, grad/param norm = 2.8215e-01, time/batch = 18.0327s	
16138/22750 (epoch 35.468), train_loss = 0.82527794, grad/param norm = 2.3749e-01, time/batch = 18.3337s	
16139/22750 (epoch 35.470), train_loss = 0.90991829, grad/param norm = 2.5818e-01, time/batch = 17.5005s	
16140/22750 (epoch 35.473), train_loss = 0.77519337, grad/param norm = 2.1636e-01, time/batch = 17.7499s	
16141/22750 (epoch 35.475), train_loss = 0.80709186, grad/param norm = 2.2725e-01, time/batch = 17.9109s	
16142/22750 (epoch 35.477), train_loss = 0.69603793, grad/param norm = 2.2036e-01, time/batch = 18.7906s	
16143/22750 (epoch 35.479), train_loss = 0.69200777, grad/param norm = 2.0657e-01, time/batch = 28.4316s	
16144/22750 (epoch 35.481), train_loss = 0.65054033, grad/param norm = 2.0112e-01, time/batch = 20.0996s	
16145/22750 (epoch 35.484), train_loss = 0.55267601, grad/param norm = 2.1111e-01, time/batch = 18.5941s	
16146/22750 (epoch 35.486), train_loss = 0.66577033, grad/param norm = 2.2560e-01, time/batch = 19.8165s	
16147/22750 (epoch 35.488), train_loss = 0.60946275, grad/param norm = 1.9728e-01, time/batch = 19.2426s	
16148/22750 (epoch 35.490), train_loss = 0.78123583, grad/param norm = 2.2091e-01, time/batch = 16.9764s	
16149/22750 (epoch 35.492), train_loss = 0.84426864, grad/param norm = 2.3001e-01, time/batch = 16.6657s	
16150/22750 (epoch 35.495), train_loss = 0.70613872, grad/param norm = 2.1148e-01, time/batch = 16.8442s	
16151/22750 (epoch 35.497), train_loss = 0.75648056, grad/param norm = 2.3661e-01, time/batch = 17.6751s	
16152/22750 (epoch 35.499), train_loss = 0.68214044, grad/param norm = 2.3045e-01, time/batch = 17.5080s	
16153/22750 (epoch 35.501), train_loss = 0.74094901, grad/param norm = 2.3242e-01, time/batch = 19.6037s	
16154/22750 (epoch 35.503), train_loss = 0.73588043, grad/param norm = 2.2372e-01, time/batch = 18.7408s	
16155/22750 (epoch 35.505), train_loss = 0.65436140, grad/param norm = 2.0740e-01, time/batch = 18.2523s	
16156/22750 (epoch 35.508), train_loss = 0.61896023, grad/param norm = 2.0971e-01, time/batch = 16.7609s	
16157/22750 (epoch 35.510), train_loss = 0.66683932, grad/param norm = 2.1441e-01, time/batch = 18.3320s	
16158/22750 (epoch 35.512), train_loss = 0.69055141, grad/param norm = 2.0780e-01, time/batch = 16.4903s	
16159/22750 (epoch 35.514), train_loss = 0.72232142, grad/param norm = 2.1180e-01, time/batch = 17.1471s	
16160/22750 (epoch 35.516), train_loss = 0.71003900, grad/param norm = 2.2338e-01, time/batch = 16.6290s	
16161/22750 (epoch 35.519), train_loss = 0.85049867, grad/param norm = 2.4641e-01, time/batch = 19.4089s	
16162/22750 (epoch 35.521), train_loss = 0.76782965, grad/param norm = 2.3018e-01, time/batch = 19.6709s	
16163/22750 (epoch 35.523), train_loss = 0.70433762, grad/param norm = 2.2097e-01, time/batch = 20.6788s	
16164/22750 (epoch 35.525), train_loss = 0.92881796, grad/param norm = 2.9754e-01, time/batch = 20.0063s	
16165/22750 (epoch 35.527), train_loss = 0.79331097, grad/param norm = 2.1577e-01, time/batch = 17.8387s	
16166/22750 (epoch 35.530), train_loss = 0.68981939, grad/param norm = 2.1879e-01, time/batch = 19.0768s	
16167/22750 (epoch 35.532), train_loss = 0.65018148, grad/param norm = 2.0466e-01, time/batch = 18.8340s	
16168/22750 (epoch 35.534), train_loss = 0.86100816, grad/param norm = 2.7588e-01, time/batch = 17.7115s	
16169/22750 (epoch 35.536), train_loss = 0.80477856, grad/param norm = 2.0075e-01, time/batch = 16.3279s	
16170/22750 (epoch 35.538), train_loss = 0.78731694, grad/param norm = 2.1206e-01, time/batch = 16.4405s	
16171/22750 (epoch 35.541), train_loss = 0.68361813, grad/param norm = 2.6763e-01, time/batch = 17.8530s	
16172/22750 (epoch 35.543), train_loss = 0.66600227, grad/param norm = 2.0682e-01, time/batch = 18.0371s	
16173/22750 (epoch 35.545), train_loss = 0.83981016, grad/param norm = 2.2997e-01, time/batch = 18.3503s	
16174/22750 (epoch 35.547), train_loss = 0.72083108, grad/param norm = 1.9539e-01, time/batch = 18.2580s	
16175/22750 (epoch 35.549), train_loss = 0.73326765, grad/param norm = 2.1825e-01, time/batch = 16.5080s	
16176/22750 (epoch 35.552), train_loss = 0.81417137, grad/param norm = 2.3616e-01, time/batch = 16.7623s	
16177/22750 (epoch 35.554), train_loss = 0.85022657, grad/param norm = 2.4599e-01, time/batch = 18.3362s	
16178/22750 (epoch 35.556), train_loss = 0.80576092, grad/param norm = 2.1434e-01, time/batch = 17.3368s	
16179/22750 (epoch 35.558), train_loss = 0.78938467, grad/param norm = 2.3605e-01, time/batch = 18.1740s	
16180/22750 (epoch 35.560), train_loss = 0.73527588, grad/param norm = 2.0058e-01, time/batch = 19.1918s	
16181/22750 (epoch 35.563), train_loss = 0.86067412, grad/param norm = 2.4343e-01, time/batch = 19.6780s	
16182/22750 (epoch 35.565), train_loss = 0.83880149, grad/param norm = 2.8778e-01, time/batch = 18.7070s	
16183/22750 (epoch 35.567), train_loss = 0.83832335, grad/param norm = 2.4907e-01, time/batch = 18.5035s	
16184/22750 (epoch 35.569), train_loss = 0.75677015, grad/param norm = 2.3132e-01, time/batch = 19.9899s	
16185/22750 (epoch 35.571), train_loss = 0.77132589, grad/param norm = 2.3818e-01, time/batch = 17.0783s	
16186/22750 (epoch 35.574), train_loss = 0.79198866, grad/param norm = 2.2616e-01, time/batch = 18.0736s	
16187/22750 (epoch 35.576), train_loss = 0.73963903, grad/param norm = 2.0664e-01, time/batch = 16.6349s	
16188/22750 (epoch 35.578), train_loss = 0.66093635, grad/param norm = 2.2816e-01, time/batch = 16.5096s	
16189/22750 (epoch 35.580), train_loss = 0.82466011, grad/param norm = 2.4919e-01, time/batch = 19.1797s	
16190/22750 (epoch 35.582), train_loss = 0.68324362, grad/param norm = 1.8435e-01, time/batch = 17.3462s	
16191/22750 (epoch 35.585), train_loss = 0.68522807, grad/param norm = 2.2522e-01, time/batch = 18.6609s	
16192/22750 (epoch 35.587), train_loss = 0.67762126, grad/param norm = 1.8925e-01, time/batch = 17.0832s	
16193/22750 (epoch 35.589), train_loss = 0.59019699, grad/param norm = 1.9548e-01, time/batch = 16.7483s	
16194/22750 (epoch 35.591), train_loss = 0.74614263, grad/param norm = 1.9451e-01, time/batch = 17.7327s	
16195/22750 (epoch 35.593), train_loss = 0.87760628, grad/param norm = 2.2088e-01, time/batch = 16.9270s	
16196/22750 (epoch 35.596), train_loss = 0.86921406, grad/param norm = 2.6271e-01, time/batch = 17.8463s	
16197/22750 (epoch 35.598), train_loss = 0.90547685, grad/param norm = 2.5572e-01, time/batch = 16.7566s	
16198/22750 (epoch 35.600), train_loss = 0.92034423, grad/param norm = 2.6866e-01, time/batch = 17.2414s	
16199/22750 (epoch 35.602), train_loss = 0.70635305, grad/param norm = 2.0215e-01, time/batch = 19.1919s	
16200/22750 (epoch 35.604), train_loss = 0.72895035, grad/param norm = 2.2370e-01, time/batch = 20.3603s	
16201/22750 (epoch 35.607), train_loss = 0.67308079, grad/param norm = 1.9221e-01, time/batch = 17.5029s	
16202/22750 (epoch 35.609), train_loss = 0.63967555, grad/param norm = 2.0740e-01, time/batch = 19.1528s	
16203/22750 (epoch 35.611), train_loss = 0.72121793, grad/param norm = 2.0262e-01, time/batch = 17.5805s	
16204/22750 (epoch 35.613), train_loss = 0.70781841, grad/param norm = 2.4177e-01, time/batch = 19.0720s	
16205/22750 (epoch 35.615), train_loss = 0.70779376, grad/param norm = 1.7821e-01, time/batch = 17.8400s	
16206/22750 (epoch 35.618), train_loss = 0.74545262, grad/param norm = 2.1182e-01, time/batch = 19.5778s	
16207/22750 (epoch 35.620), train_loss = 0.74006576, grad/param norm = 2.3375e-01, time/batch = 18.4204s	
16208/22750 (epoch 35.622), train_loss = 0.63145376, grad/param norm = 1.8704e-01, time/batch = 16.7190s	
16209/22750 (epoch 35.624), train_loss = 0.72698963, grad/param norm = 2.8298e-01, time/batch = 17.3842s	
16210/22750 (epoch 35.626), train_loss = 0.62329099, grad/param norm = 2.0895e-01, time/batch = 19.4452s	
16211/22750 (epoch 35.629), train_loss = 0.72022833, grad/param norm = 2.1969e-01, time/batch = 18.2568s	
16212/22750 (epoch 35.631), train_loss = 0.76027386, grad/param norm = 2.0377e-01, time/batch = 19.7459s	
16213/22750 (epoch 35.633), train_loss = 0.64008352, grad/param norm = 1.9989e-01, time/batch = 18.4250s	
16214/22750 (epoch 35.635), train_loss = 0.74853010, grad/param norm = 2.0703e-01, time/batch = 18.6627s	
16215/22750 (epoch 35.637), train_loss = 0.81754901, grad/param norm = 3.0141e-01, time/batch = 16.6715s	
16216/22750 (epoch 35.640), train_loss = 0.82042508, grad/param norm = 2.2074e-01, time/batch = 16.9105s	
16217/22750 (epoch 35.642), train_loss = 0.86492481, grad/param norm = 2.1996e-01, time/batch = 17.7452s	
16218/22750 (epoch 35.644), train_loss = 0.76424741, grad/param norm = 2.8020e-01, time/batch = 17.1861s	
16219/22750 (epoch 35.646), train_loss = 0.83341991, grad/param norm = 2.7591e-01, time/batch = 18.7607s	
16220/22750 (epoch 35.648), train_loss = 0.81365449, grad/param norm = 2.2479e-01, time/batch = 19.3513s	
16221/22750 (epoch 35.651), train_loss = 0.80984142, grad/param norm = 2.1670e-01, time/batch = 18.0123s	
16222/22750 (epoch 35.653), train_loss = 0.84069621, grad/param norm = 2.0829e-01, time/batch = 17.2666s	
16223/22750 (epoch 35.655), train_loss = 0.78070714, grad/param norm = 2.0999e-01, time/batch = 18.4200s	
16224/22750 (epoch 35.657), train_loss = 0.90811617, grad/param norm = 2.5030e-01, time/batch = 17.3274s	
16225/22750 (epoch 35.659), train_loss = 0.94103507, grad/param norm = 2.1689e-01, time/batch = 15.7869s	
16226/22750 (epoch 35.662), train_loss = 0.91277401, grad/param norm = 2.6453e-01, time/batch = 18.7611s	
16227/22750 (epoch 35.664), train_loss = 0.83271157, grad/param norm = 2.3411e-01, time/batch = 19.1076s	
16228/22750 (epoch 35.666), train_loss = 0.65375801, grad/param norm = 1.9515e-01, time/batch = 17.6269s	
16229/22750 (epoch 35.668), train_loss = 0.77019667, grad/param norm = 2.1866e-01, time/batch = 19.5391s	
16230/22750 (epoch 35.670), train_loss = 0.72913740, grad/param norm = 2.1059e-01, time/batch = 20.0698s	
16231/22750 (epoch 35.673), train_loss = 0.93338218, grad/param norm = 2.2476e-01, time/batch = 17.6561s	
16232/22750 (epoch 35.675), train_loss = 1.06078553, grad/param norm = 2.9734e-01, time/batch = 18.2424s	
16233/22750 (epoch 35.677), train_loss = 0.92188266, grad/param norm = 2.3758e-01, time/batch = 18.9980s	
16234/22750 (epoch 35.679), train_loss = 0.94409214, grad/param norm = 2.8929e-01, time/batch = 16.8051s	
16235/22750 (epoch 35.681), train_loss = 0.92624780, grad/param norm = 2.6447e-01, time/batch = 16.9182s	
16236/22750 (epoch 35.684), train_loss = 0.96016924, grad/param norm = 2.5911e-01, time/batch = 19.1052s	
16237/22750 (epoch 35.686), train_loss = 0.98125237, grad/param norm = 2.7782e-01, time/batch = 17.4051s	
16238/22750 (epoch 35.688), train_loss = 0.92041780, grad/param norm = 2.3729e-01, time/batch = 19.0247s	
16239/22750 (epoch 35.690), train_loss = 0.91779398, grad/param norm = 2.4733e-01, time/batch = 18.8313s	
16240/22750 (epoch 35.692), train_loss = 0.92355986, grad/param norm = 2.6646e-01, time/batch = 17.8490s	
16241/22750 (epoch 35.695), train_loss = 0.81899148, grad/param norm = 2.2092e-01, time/batch = 17.2444s	
16242/22750 (epoch 35.697), train_loss = 0.82705590, grad/param norm = 2.1319e-01, time/batch = 17.0928s	
16243/22750 (epoch 35.699), train_loss = 0.74156882, grad/param norm = 2.0716e-01, time/batch = 16.8482s	
16244/22750 (epoch 35.701), train_loss = 0.67973765, grad/param norm = 2.2126e-01, time/batch = 16.7440s	
16245/22750 (epoch 35.703), train_loss = 0.74823611, grad/param norm = 2.1919e-01, time/batch = 18.5798s	
16246/22750 (epoch 35.705), train_loss = 0.73296088, grad/param norm = 1.9463e-01, time/batch = 18.6874s	
16247/22750 (epoch 35.708), train_loss = 0.80325743, grad/param norm = 2.5410e-01, time/batch = 17.7901s	
16248/22750 (epoch 35.710), train_loss = 0.70171641, grad/param norm = 2.4186e-01, time/batch = 16.3803s	
16249/22750 (epoch 35.712), train_loss = 0.63414349, grad/param norm = 1.9186e-01, time/batch = 16.6753s	
16250/22750 (epoch 35.714), train_loss = 0.65578064, grad/param norm = 2.1581e-01, time/batch = 16.6737s	
16251/22750 (epoch 35.716), train_loss = 0.68224621, grad/param norm = 2.0625e-01, time/batch = 16.9899s	
16252/22750 (epoch 35.719), train_loss = 0.74816466, grad/param norm = 2.5476e-01, time/batch = 17.5080s	
16253/22750 (epoch 35.721), train_loss = 0.85963907, grad/param norm = 2.3324e-01, time/batch = 16.0340s	
16254/22750 (epoch 35.723), train_loss = 0.87244540, grad/param norm = 2.7229e-01, time/batch = 17.8414s	
16255/22750 (epoch 35.725), train_loss = 0.74377840, grad/param norm = 2.3398e-01, time/batch = 17.6061s	
16256/22750 (epoch 35.727), train_loss = 0.75785435, grad/param norm = 2.2489e-01, time/batch = 20.1040s	
16257/22750 (epoch 35.730), train_loss = 0.74433810, grad/param norm = 2.1237e-01, time/batch = 19.3776s	
16258/22750 (epoch 35.732), train_loss = 0.71889165, grad/param norm = 2.0782e-01, time/batch = 16.9049s	
16259/22750 (epoch 35.734), train_loss = 0.63230410, grad/param norm = 1.7868e-01, time/batch = 18.5647s	
16260/22750 (epoch 35.736), train_loss = 0.72799207, grad/param norm = 2.2755e-01, time/batch = 17.5377s	
16261/22750 (epoch 35.738), train_loss = 0.82205890, grad/param norm = 2.4485e-01, time/batch = 16.6402s	
16262/22750 (epoch 35.741), train_loss = 0.89012442, grad/param norm = 2.4235e-01, time/batch = 17.2441s	
16263/22750 (epoch 35.743), train_loss = 0.80950729, grad/param norm = 2.2814e-01, time/batch = 17.8228s	
16264/22750 (epoch 35.745), train_loss = 0.65942222, grad/param norm = 2.1190e-01, time/batch = 19.2520s	
16265/22750 (epoch 35.747), train_loss = 0.76370138, grad/param norm = 1.8322e-01, time/batch = 17.6493s	
16266/22750 (epoch 35.749), train_loss = 0.88627715, grad/param norm = 2.4335e-01, time/batch = 15.5983s	
16267/22750 (epoch 35.752), train_loss = 0.79260287, grad/param norm = 2.4466e-01, time/batch = 17.3396s	
16268/22750 (epoch 35.754), train_loss = 0.79784232, grad/param norm = 2.4043e-01, time/batch = 16.6254s	
16269/22750 (epoch 35.756), train_loss = 0.73454878, grad/param norm = 2.4622e-01, time/batch = 18.9074s	
16270/22750 (epoch 35.758), train_loss = 0.70673632, grad/param norm = 2.0085e-01, time/batch = 16.7222s	
16271/22750 (epoch 35.760), train_loss = 0.70746428, grad/param norm = 2.2169e-01, time/batch = 16.5941s	
16272/22750 (epoch 35.763), train_loss = 0.77812677, grad/param norm = 2.1710e-01, time/batch = 18.0876s	
16273/22750 (epoch 35.765), train_loss = 0.75833197, grad/param norm = 2.2746e-01, time/batch = 18.0011s	
16274/22750 (epoch 35.767), train_loss = 0.81247309, grad/param norm = 2.3287e-01, time/batch = 20.1005s	
16275/22750 (epoch 35.769), train_loss = 0.90146188, grad/param norm = 2.3087e-01, time/batch = 18.5903s	
16276/22750 (epoch 35.771), train_loss = 0.94936030, grad/param norm = 2.5816e-01, time/batch = 19.2804s	
16277/22750 (epoch 35.774), train_loss = 0.74422212, grad/param norm = 2.7911e-01, time/batch = 16.9071s	
16278/22750 (epoch 35.776), train_loss = 0.89043148, grad/param norm = 2.5890e-01, time/batch = 17.0806s	
16279/22750 (epoch 35.778), train_loss = 0.92315510, grad/param norm = 2.9886e-01, time/batch = 20.2435s	
16280/22750 (epoch 35.780), train_loss = 0.81285020, grad/param norm = 2.2984e-01, time/batch = 18.9127s	
16281/22750 (epoch 35.782), train_loss = 0.94647523, grad/param norm = 2.6024e-01, time/batch = 18.1597s	
16282/22750 (epoch 35.785), train_loss = 0.77609398, grad/param norm = 2.3656e-01, time/batch = 19.2447s	
16283/22750 (epoch 35.787), train_loss = 0.68220064, grad/param norm = 2.5918e-01, time/batch = 20.5956s	
16284/22750 (epoch 35.789), train_loss = 0.76795167, grad/param norm = 2.1786e-01, time/batch = 18.7530s	
16285/22750 (epoch 35.791), train_loss = 0.74584338, grad/param norm = 2.2241e-01, time/batch = 19.6827s	
16286/22750 (epoch 35.793), train_loss = 0.70731189, grad/param norm = 2.5137e-01, time/batch = 19.0878s	
16287/22750 (epoch 35.796), train_loss = 0.66256585, grad/param norm = 1.9599e-01, time/batch = 19.4994s	
16288/22750 (epoch 35.798), train_loss = 0.71838654, grad/param norm = 2.0527e-01, time/batch = 17.8386s	
16289/22750 (epoch 35.800), train_loss = 0.70134747, grad/param norm = 2.1853e-01, time/batch = 18.5796s	
16290/22750 (epoch 35.802), train_loss = 0.65380487, grad/param norm = 2.4181e-01, time/batch = 16.9721s	
16291/22750 (epoch 35.804), train_loss = 0.84335522, grad/param norm = 2.2218e-01, time/batch = 18.2439s	
16292/22750 (epoch 35.807), train_loss = 0.81937920, grad/param norm = 2.4033e-01, time/batch = 17.5858s	
16293/22750 (epoch 35.809), train_loss = 0.90675869, grad/param norm = 2.3237e-01, time/batch = 18.1544s	
16294/22750 (epoch 35.811), train_loss = 0.78464368, grad/param norm = 2.3181e-01, time/batch = 16.7822s	
16295/22750 (epoch 35.813), train_loss = 0.79578502, grad/param norm = 2.1312e-01, time/batch = 18.4312s	
16296/22750 (epoch 35.815), train_loss = 0.91766315, grad/param norm = 2.2438e-01, time/batch = 17.6529s	
16297/22750 (epoch 35.818), train_loss = 0.85819020, grad/param norm = 2.0373e-01, time/batch = 19.0792s	
16298/22750 (epoch 35.820), train_loss = 0.98187841, grad/param norm = 2.2097e-01, time/batch = 17.3504s	
16299/22750 (epoch 35.822), train_loss = 0.83053765, grad/param norm = 2.4371e-01, time/batch = 17.9207s	
16300/22750 (epoch 35.824), train_loss = 0.67578408, grad/param norm = 1.8306e-01, time/batch = 18.9936s	
16301/22750 (epoch 35.826), train_loss = 0.78881264, grad/param norm = 2.4892e-01, time/batch = 18.1841s	
16302/22750 (epoch 35.829), train_loss = 0.88291127, grad/param norm = 2.4731e-01, time/batch = 19.4542s	
16303/22750 (epoch 35.831), train_loss = 0.87063817, grad/param norm = 2.4731e-01, time/batch = 16.2087s	
16304/22750 (epoch 35.833), train_loss = 0.80522550, grad/param norm = 2.3194e-01, time/batch = 16.7611s	
16305/22750 (epoch 35.835), train_loss = 0.69229302, grad/param norm = 2.6497e-01, time/batch = 17.0693s	
16306/22750 (epoch 35.837), train_loss = 0.75175264, grad/param norm = 2.3612e-01, time/batch = 17.6009s	
16307/22750 (epoch 35.840), train_loss = 0.70088858, grad/param norm = 2.3555e-01, time/batch = 17.2557s	
16308/22750 (epoch 35.842), train_loss = 0.71997814, grad/param norm = 2.2670e-01, time/batch = 17.0980s	
16309/22750 (epoch 35.844), train_loss = 0.80356753, grad/param norm = 2.4996e-01, time/batch = 16.7213s	
16310/22750 (epoch 35.846), train_loss = 0.83238051, grad/param norm = 2.2654e-01, time/batch = 16.4275s	
16311/22750 (epoch 35.848), train_loss = 0.72509245, grad/param norm = 1.9536e-01, time/batch = 17.0275s	
16312/22750 (epoch 35.851), train_loss = 0.70478680, grad/param norm = 2.1900e-01, time/batch = 17.5162s	
16313/22750 (epoch 35.853), train_loss = 0.87961598, grad/param norm = 2.2019e-01, time/batch = 19.0241s	
16314/22750 (epoch 35.855), train_loss = 0.74922181, grad/param norm = 1.9703e-01, time/batch = 17.1623s	
16315/22750 (epoch 35.857), train_loss = 0.83073956, grad/param norm = 2.2202e-01, time/batch = 18.4167s	
16316/22750 (epoch 35.859), train_loss = 0.80847711, grad/param norm = 2.1481e-01, time/batch = 18.3351s	
16317/22750 (epoch 35.862), train_loss = 0.96093009, grad/param norm = 2.5016e-01, time/batch = 19.1479s	
16318/22750 (epoch 35.864), train_loss = 0.80367607, grad/param norm = 2.2222e-01, time/batch = 18.1493s	
16319/22750 (epoch 35.866), train_loss = 0.83872164, grad/param norm = 2.1092e-01, time/batch = 18.9121s	
16320/22750 (epoch 35.868), train_loss = 0.71072099, grad/param norm = 2.3426e-01, time/batch = 18.1915s	
16321/22750 (epoch 35.870), train_loss = 0.67123942, grad/param norm = 2.2262e-01, time/batch = 17.7903s	
16322/22750 (epoch 35.873), train_loss = 0.77727379, grad/param norm = 2.1839e-01, time/batch = 20.4485s	
16323/22750 (epoch 35.875), train_loss = 0.82085473, grad/param norm = 2.0553e-01, time/batch = 19.5130s	
16324/22750 (epoch 35.877), train_loss = 0.72216778, grad/param norm = 2.3663e-01, time/batch = 17.1345s	
16325/22750 (epoch 35.879), train_loss = 0.88833719, grad/param norm = 2.5076e-01, time/batch = 18.7514s	
16326/22750 (epoch 35.881), train_loss = 0.81569215, grad/param norm = 2.2455e-01, time/batch = 18.7495s	
16327/22750 (epoch 35.884), train_loss = 0.71592383, grad/param norm = 1.9472e-01, time/batch = 17.6600s	
16328/22750 (epoch 35.886), train_loss = 0.82136511, grad/param norm = 2.2868e-01, time/batch = 19.3231s	
16329/22750 (epoch 35.888), train_loss = 0.83586268, grad/param norm = 1.9584e-01, time/batch = 17.3254s	
16330/22750 (epoch 35.890), train_loss = 0.83809031, grad/param norm = 2.7446e-01, time/batch = 16.9295s	
16331/22750 (epoch 35.892), train_loss = 1.05859248, grad/param norm = 2.6095e-01, time/batch = 16.6217s	
16332/22750 (epoch 35.895), train_loss = 0.76918576, grad/param norm = 2.7629e-01, time/batch = 19.3451s	
16333/22750 (epoch 35.897), train_loss = 0.88757269, grad/param norm = 2.4954e-01, time/batch = 18.0914s	
16334/22750 (epoch 35.899), train_loss = 0.81011069, grad/param norm = 2.3406e-01, time/batch = 16.9142s	
16335/22750 (epoch 35.901), train_loss = 0.85902326, grad/param norm = 2.5001e-01, time/batch = 16.1583s	
16336/22750 (epoch 35.903), train_loss = 0.77567694, grad/param norm = 2.1527e-01, time/batch = 18.4161s	
16337/22750 (epoch 35.905), train_loss = 0.86539059, grad/param norm = 2.3182e-01, time/batch = 17.9254s	
16338/22750 (epoch 35.908), train_loss = 0.67262388, grad/param norm = 2.2400e-01, time/batch = 16.7318s	
16339/22750 (epoch 35.910), train_loss = 0.61263187, grad/param norm = 2.1936e-01, time/batch = 17.7954s	
16340/22750 (epoch 35.912), train_loss = 0.78351018, grad/param norm = 2.1966e-01, time/batch = 19.2486s	
16341/22750 (epoch 35.914), train_loss = 0.79219089, grad/param norm = 2.1254e-01, time/batch = 26.9158s	
16342/22750 (epoch 35.916), train_loss = 0.62037740, grad/param norm = 1.9346e-01, time/batch = 16.1053s	
16343/22750 (epoch 35.919), train_loss = 0.77289328, grad/param norm = 2.2399e-01, time/batch = 15.6978s	
16344/22750 (epoch 35.921), train_loss = 0.60638768, grad/param norm = 1.8652e-01, time/batch = 15.6147s	
16345/22750 (epoch 35.923), train_loss = 0.71202536, grad/param norm = 2.1549e-01, time/batch = 15.3664s	
16346/22750 (epoch 35.925), train_loss = 0.77361288, grad/param norm = 2.0646e-01, time/batch = 16.1506s	
16347/22750 (epoch 35.927), train_loss = 0.62049059, grad/param norm = 2.1427e-01, time/batch = 17.1090s	
16348/22750 (epoch 35.930), train_loss = 0.58963957, grad/param norm = 1.9820e-01, time/batch = 17.3425s	
16349/22750 (epoch 35.932), train_loss = 0.76752556, grad/param norm = 2.1077e-01, time/batch = 16.1560s	
16350/22750 (epoch 35.934), train_loss = 0.64098654, grad/param norm = 1.8666e-01, time/batch = 17.4458s	
16351/22750 (epoch 35.936), train_loss = 0.87782015, grad/param norm = 2.3898e-01, time/batch = 16.2516s	
16352/22750 (epoch 35.938), train_loss = 0.86827467, grad/param norm = 2.1009e-01, time/batch = 17.2650s	
16353/22750 (epoch 35.941), train_loss = 0.90910881, grad/param norm = 2.3892e-01, time/batch = 17.2762s	
16354/22750 (epoch 35.943), train_loss = 0.80347379, grad/param norm = 2.3522e-01, time/batch = 17.5080s	
16355/22750 (epoch 35.945), train_loss = 0.80406799, grad/param norm = 2.1994e-01, time/batch = 19.0879s	
16356/22750 (epoch 35.947), train_loss = 0.73529616, grad/param norm = 2.4205e-01, time/batch = 16.9252s	
16357/22750 (epoch 35.949), train_loss = 0.73328298, grad/param norm = 2.1779e-01, time/batch = 17.3470s	
16358/22750 (epoch 35.952), train_loss = 0.73698098, grad/param norm = 2.1771e-01, time/batch = 18.7649s	
16359/22750 (epoch 35.954), train_loss = 0.67597860, grad/param norm = 2.0951e-01, time/batch = 17.8595s	
16360/22750 (epoch 35.956), train_loss = 0.83503335, grad/param norm = 2.1674e-01, time/batch = 18.6248s	
16361/22750 (epoch 35.958), train_loss = 0.69487675, grad/param norm = 1.8611e-01, time/batch = 17.3444s	
16362/22750 (epoch 35.960), train_loss = 0.67672637, grad/param norm = 2.1176e-01, time/batch = 19.2634s	
16363/22750 (epoch 35.963), train_loss = 0.78377591, grad/param norm = 2.0333e-01, time/batch = 19.3378s	
16364/22750 (epoch 35.965), train_loss = 0.84471240, grad/param norm = 2.0865e-01, time/batch = 16.7534s	
16365/22750 (epoch 35.967), train_loss = 0.83561885, grad/param norm = 2.4269e-01, time/batch = 16.4777s	
16366/22750 (epoch 35.969), train_loss = 0.75146813, grad/param norm = 2.1076e-01, time/batch = 17.3325s	
16367/22750 (epoch 35.971), train_loss = 0.72486260, grad/param norm = 1.9871e-01, time/batch = 17.1659s	
16368/22750 (epoch 35.974), train_loss = 0.70077233, grad/param norm = 1.9088e-01, time/batch = 16.9813s	
16369/22750 (epoch 35.976), train_loss = 0.73914798, grad/param norm = 2.5016e-01, time/batch = 17.1002s	
16370/22750 (epoch 35.978), train_loss = 0.71739092, grad/param norm = 2.1207e-01, time/batch = 16.9888s	
16371/22750 (epoch 35.980), train_loss = 0.87425256, grad/param norm = 2.4413e-01, time/batch = 17.0748s	
16372/22750 (epoch 35.982), train_loss = 0.72070995, grad/param norm = 2.2131e-01, time/batch = 16.7577s	
16373/22750 (epoch 35.985), train_loss = 0.91712520, grad/param norm = 2.5806e-01, time/batch = 16.7573s	
16374/22750 (epoch 35.987), train_loss = 0.66014571, grad/param norm = 2.2335e-01, time/batch = 17.1332s	
16375/22750 (epoch 35.989), train_loss = 0.73037571, grad/param norm = 2.5540e-01, time/batch = 17.1939s	
16376/22750 (epoch 35.991), train_loss = 0.81187168, grad/param norm = 2.6418e-01, time/batch = 16.8217s	
16377/22750 (epoch 35.993), train_loss = 0.78471689, grad/param norm = 2.6617e-01, time/batch = 16.2768s	
16378/22750 (epoch 35.996), train_loss = 0.68726315, grad/param norm = 2.4978e-01, time/batch = 16.5950s	
16379/22750 (epoch 35.998), train_loss = 0.87657339, grad/param norm = 2.4226e-01, time/batch = 16.4181s	
decayed learning rate by a factor 0.97 to 0.00087875300034768	
16380/22750 (epoch 36.000), train_loss = 0.76167191, grad/param norm = 2.0106e-01, time/batch = 16.5088s	
16381/22750 (epoch 36.002), train_loss = 0.94769029, grad/param norm = 2.3476e-01, time/batch = 16.3502s	
16382/22750 (epoch 36.004), train_loss = 0.75430116, grad/param norm = 2.5927e-01, time/batch = 16.8977s	
16383/22750 (epoch 36.007), train_loss = 0.74570666, grad/param norm = 2.4021e-01, time/batch = 16.5677s	
16384/22750 (epoch 36.009), train_loss = 0.90998452, grad/param norm = 2.6077e-01, time/batch = 16.4951s	
16385/22750 (epoch 36.011), train_loss = 0.95861772, grad/param norm = 2.6627e-01, time/batch = 16.1839s	
16386/22750 (epoch 36.013), train_loss = 0.89585085, grad/param norm = 2.4715e-01, time/batch = 16.3446s	
16387/22750 (epoch 36.015), train_loss = 0.80883046, grad/param norm = 2.5590e-01, time/batch = 16.0952s	
16388/22750 (epoch 36.018), train_loss = 0.88838159, grad/param norm = 2.8027e-01, time/batch = 15.9477s	
16389/22750 (epoch 36.020), train_loss = 0.92333410, grad/param norm = 2.3474e-01, time/batch = 16.2119s	
16390/22750 (epoch 36.022), train_loss = 0.78681690, grad/param norm = 2.3941e-01, time/batch = 16.5973s	
16391/22750 (epoch 36.024), train_loss = 0.80103856, grad/param norm = 2.4569e-01, time/batch = 16.3065s	
16392/22750 (epoch 36.026), train_loss = 0.83831397, grad/param norm = 2.6966e-01, time/batch = 16.1832s	
16393/22750 (epoch 36.029), train_loss = 0.64967570, grad/param norm = 2.2486e-01, time/batch = 16.8946s	
16394/22750 (epoch 36.031), train_loss = 0.99294103, grad/param norm = 2.5419e-01, time/batch = 16.3505s	
16395/22750 (epoch 36.033), train_loss = 0.79472762, grad/param norm = 2.4637e-01, time/batch = 16.3378s	
16396/22750 (epoch 36.035), train_loss = 0.85276384, grad/param norm = 2.4339e-01, time/batch = 16.2616s	
16397/22750 (epoch 36.037), train_loss = 0.89031536, grad/param norm = 2.2592e-01, time/batch = 16.5816s	
16398/22750 (epoch 36.040), train_loss = 0.78413087, grad/param norm = 2.3749e-01, time/batch = 16.2001s	
16399/22750 (epoch 36.042), train_loss = 0.82911508, grad/param norm = 2.4749e-01, time/batch = 16.0474s	
16400/22750 (epoch 36.044), train_loss = 0.78222855, grad/param norm = 2.2549e-01, time/batch = 16.4429s	
16401/22750 (epoch 36.046), train_loss = 0.85636535, grad/param norm = 2.2999e-01, time/batch = 16.2118s	
16402/22750 (epoch 36.048), train_loss = 0.78578578, grad/param norm = 2.1981e-01, time/batch = 16.1910s	
16403/22750 (epoch 36.051), train_loss = 0.80333456, grad/param norm = 2.3607e-01, time/batch = 16.1008s	
16404/22750 (epoch 36.053), train_loss = 0.78073403, grad/param norm = 2.1552e-01, time/batch = 16.6528s	
16405/22750 (epoch 36.055), train_loss = 0.67866541, grad/param norm = 2.1813e-01, time/batch = 16.1856s	
16406/22750 (epoch 36.057), train_loss = 0.92579189, grad/param norm = 2.2006e-01, time/batch = 16.6374s	
16407/22750 (epoch 36.059), train_loss = 0.59349293, grad/param norm = 2.1863e-01, time/batch = 16.2617s	
16408/22750 (epoch 36.062), train_loss = 0.67273887, grad/param norm = 2.2785e-01, time/batch = 16.8246s	
16409/22750 (epoch 36.064), train_loss = 0.88618580, grad/param norm = 2.3020e-01, time/batch = 16.3700s	
16410/22750 (epoch 36.066), train_loss = 0.70214282, grad/param norm = 1.9566e-01, time/batch = 16.2848s	
16411/22750 (epoch 36.068), train_loss = 0.71334373, grad/param norm = 2.0208e-01, time/batch = 17.1266s	
16412/22750 (epoch 36.070), train_loss = 0.60192912, grad/param norm = 1.8305e-01, time/batch = 16.2651s	
16413/22750 (epoch 36.073), train_loss = 0.73176536, grad/param norm = 2.2332e-01, time/batch = 16.4272s	
16414/22750 (epoch 36.075), train_loss = 0.76864347, grad/param norm = 1.8700e-01, time/batch = 17.1891s	
16415/22750 (epoch 36.077), train_loss = 0.57913353, grad/param norm = 2.0620e-01, time/batch = 16.9041s	
16416/22750 (epoch 36.079), train_loss = 0.76719652, grad/param norm = 2.4315e-01, time/batch = 16.7362s	
16417/22750 (epoch 36.081), train_loss = 0.72302091, grad/param norm = 2.0325e-01, time/batch = 16.7542s	
16418/22750 (epoch 36.084), train_loss = 0.73743177, grad/param norm = 2.0544e-01, time/batch = 16.8447s	
16419/22750 (epoch 36.086), train_loss = 0.78243786, grad/param norm = 2.1088e-01, time/batch = 16.8470s	
16420/22750 (epoch 36.088), train_loss = 0.71542575, grad/param norm = 2.1310e-01, time/batch = 16.4442s	
16421/22750 (epoch 36.090), train_loss = 0.75548458, grad/param norm = 2.2519e-01, time/batch = 16.5373s	
16422/22750 (epoch 36.092), train_loss = 0.84568830, grad/param norm = 2.3142e-01, time/batch = 16.9864s	
16423/22750 (epoch 36.095), train_loss = 0.70211236, grad/param norm = 2.1125e-01, time/batch = 16.7460s	
16424/22750 (epoch 36.097), train_loss = 0.76896558, grad/param norm = 2.2789e-01, time/batch = 16.9143s	
16425/22750 (epoch 36.099), train_loss = 0.70935083, grad/param norm = 2.0874e-01, time/batch = 16.7568s	
16426/22750 (epoch 36.101), train_loss = 0.64539370, grad/param norm = 2.2158e-01, time/batch = 16.5684s	
16427/22750 (epoch 36.103), train_loss = 0.84154692, grad/param norm = 2.5867e-01, time/batch = 16.3538s	
16428/22750 (epoch 36.105), train_loss = 0.90547121, grad/param norm = 2.9884e-01, time/batch = 16.2029s	
16429/22750 (epoch 36.108), train_loss = 0.79843189, grad/param norm = 2.4840e-01, time/batch = 17.2970s	
16430/22750 (epoch 36.110), train_loss = 0.87633667, grad/param norm = 2.2187e-01, time/batch = 16.0004s	
16431/22750 (epoch 36.112), train_loss = 0.64633510, grad/param norm = 1.7714e-01, time/batch = 16.6067s	
16432/22750 (epoch 36.114), train_loss = 0.56645999, grad/param norm = 1.8745e-01, time/batch = 16.4969s	
16433/22750 (epoch 36.116), train_loss = 0.77679436, grad/param norm = 2.0873e-01, time/batch = 16.7961s	
16434/22750 (epoch 36.119), train_loss = 0.71620145, grad/param norm = 1.8271e-01, time/batch = 16.6508s	
16435/22750 (epoch 36.121), train_loss = 0.74478750, grad/param norm = 2.4790e-01, time/batch = 16.6595s	
16436/22750 (epoch 36.123), train_loss = 0.66155688, grad/param norm = 2.3217e-01, time/batch = 16.5028s	
16437/22750 (epoch 36.125), train_loss = 0.87577307, grad/param norm = 2.1191e-01, time/batch = 16.4973s	
16438/22750 (epoch 36.127), train_loss = 0.74791138, grad/param norm = 2.4992e-01, time/batch = 16.3749s	
16439/22750 (epoch 36.130), train_loss = 0.74146661, grad/param norm = 1.9058e-01, time/batch = 16.2130s	
16440/22750 (epoch 36.132), train_loss = 0.70568684, grad/param norm = 2.1274e-01, time/batch = 16.7668s	
16441/22750 (epoch 36.134), train_loss = 0.72417010, grad/param norm = 1.9254e-01, time/batch = 16.4502s	
16442/22750 (epoch 36.136), train_loss = 0.60985086, grad/param norm = 2.1791e-01, time/batch = 16.5969s	
16443/22750 (epoch 36.138), train_loss = 0.81614580, grad/param norm = 2.2639e-01, time/batch = 16.5846s	
16444/22750 (epoch 36.141), train_loss = 0.76932072, grad/param norm = 2.1354e-01, time/batch = 16.5708s	
16445/22750 (epoch 36.143), train_loss = 0.68861610, grad/param norm = 1.8435e-01, time/batch = 16.3523s	
16446/22750 (epoch 36.145), train_loss = 0.88507744, grad/param norm = 2.2931e-01, time/batch = 16.2608s	
16447/22750 (epoch 36.147), train_loss = 0.91851192, grad/param norm = 2.4055e-01, time/batch = 16.7371s	
16448/22750 (epoch 36.149), train_loss = 0.77451409, grad/param norm = 2.4218e-01, time/batch = 20.5039s	
16449/22750 (epoch 36.152), train_loss = 0.77157858, grad/param norm = 2.2389e-01, time/batch = 19.9505s	
16450/22750 (epoch 36.154), train_loss = 0.70583011, grad/param norm = 2.1963e-01, time/batch = 18.1151s	
16451/22750 (epoch 36.156), train_loss = 0.69468100, grad/param norm = 2.2463e-01, time/batch = 19.9060s	
16452/22750 (epoch 36.158), train_loss = 0.67532599, grad/param norm = 2.2548e-01, time/batch = 17.9862s	
16453/22750 (epoch 36.160), train_loss = 0.76707040, grad/param norm = 2.3215e-01, time/batch = 17.4021s	
16454/22750 (epoch 36.163), train_loss = 0.90372401, grad/param norm = 2.6897e-01, time/batch = 16.5357s	
16455/22750 (epoch 36.165), train_loss = 0.82563409, grad/param norm = 2.1476e-01, time/batch = 16.9741s	
16456/22750 (epoch 36.167), train_loss = 0.71869217, grad/param norm = 2.3947e-01, time/batch = 16.7708s	
16457/22750 (epoch 36.169), train_loss = 0.78432529, grad/param norm = 2.6566e-01, time/batch = 17.3198s	
16458/22750 (epoch 36.171), train_loss = 0.65476355, grad/param norm = 1.9787e-01, time/batch = 16.7850s	
16459/22750 (epoch 36.174), train_loss = 0.64696237, grad/param norm = 2.2829e-01, time/batch = 16.6981s	
16460/22750 (epoch 36.176), train_loss = 0.67028860, grad/param norm = 2.1225e-01, time/batch = 16.8473s	
16461/22750 (epoch 36.178), train_loss = 0.70584816, grad/param norm = 2.1584e-01, time/batch = 16.8441s	
16462/22750 (epoch 36.180), train_loss = 0.87597694, grad/param norm = 3.3377e-01, time/batch = 16.9930s	
16463/22750 (epoch 36.182), train_loss = 0.83527125, grad/param norm = 2.4303e-01, time/batch = 16.9824s	
16464/22750 (epoch 36.185), train_loss = 0.85641238, grad/param norm = 2.3466e-01, time/batch = 17.0601s	
16465/22750 (epoch 36.187), train_loss = 0.65789272, grad/param norm = 1.8975e-01, time/batch = 16.8682s	
16466/22750 (epoch 36.189), train_loss = 0.67779760, grad/param norm = 2.5193e-01, time/batch = 16.6093s	
16467/22750 (epoch 36.191), train_loss = 0.70989507, grad/param norm = 1.9893e-01, time/batch = 16.6873s	
16468/22750 (epoch 36.193), train_loss = 0.82307441, grad/param norm = 2.2277e-01, time/batch = 16.6971s	
16469/22750 (epoch 36.196), train_loss = 0.75721673, grad/param norm = 2.3882e-01, time/batch = 16.7745s	
16470/22750 (epoch 36.198), train_loss = 0.57424211, grad/param norm = 2.0254e-01, time/batch = 16.5213s	
16471/22750 (epoch 36.200), train_loss = 0.75591336, grad/param norm = 2.0267e-01, time/batch = 16.8372s	
16472/22750 (epoch 36.202), train_loss = 0.84291724, grad/param norm = 3.0371e-01, time/batch = 16.7509s	
16473/22750 (epoch 36.204), train_loss = 0.79114357, grad/param norm = 2.1615e-01, time/batch = 16.9114s	
16474/22750 (epoch 36.207), train_loss = 0.78340041, grad/param norm = 2.3374e-01, time/batch = 16.7697s	
16475/22750 (epoch 36.209), train_loss = 0.71433872, grad/param norm = 2.1398e-01, time/batch = 17.0679s	
16476/22750 (epoch 36.211), train_loss = 0.68766610, grad/param norm = 2.4535e-01, time/batch = 16.9894s	
16477/22750 (epoch 36.213), train_loss = 0.59508170, grad/param norm = 2.0876e-01, time/batch = 17.0814s	
16478/22750 (epoch 36.215), train_loss = 0.58362572, grad/param norm = 1.8383e-01, time/batch = 17.0753s	
16479/22750 (epoch 36.218), train_loss = 0.68121195, grad/param norm = 2.3284e-01, time/batch = 17.1104s	
16480/22750 (epoch 36.220), train_loss = 0.60911356, grad/param norm = 2.2187e-01, time/batch = 17.2388s	
16481/22750 (epoch 36.222), train_loss = 0.62128306, grad/param norm = 1.9204e-01, time/batch = 16.9142s	
16482/22750 (epoch 36.224), train_loss = 0.68097493, grad/param norm = 2.0434e-01, time/batch = 17.0783s	
16483/22750 (epoch 36.226), train_loss = 0.75097188, grad/param norm = 2.2856e-01, time/batch = 17.0915s	
16484/22750 (epoch 36.229), train_loss = 0.77735526, grad/param norm = 2.2915e-01, time/batch = 17.0090s	
16485/22750 (epoch 36.231), train_loss = 0.66510102, grad/param norm = 2.1516e-01, time/batch = 17.0678s	
16486/22750 (epoch 36.233), train_loss = 0.61677560, grad/param norm = 2.2649e-01, time/batch = 16.7852s	
16487/22750 (epoch 36.235), train_loss = 0.58711298, grad/param norm = 2.1345e-01, time/batch = 16.9201s	
16488/22750 (epoch 36.237), train_loss = 0.66075292, grad/param norm = 2.1964e-01, time/batch = 17.0163s	
16489/22750 (epoch 36.240), train_loss = 0.74710909, grad/param norm = 1.9130e-01, time/batch = 17.0344s	
16490/22750 (epoch 36.242), train_loss = 0.90260376, grad/param norm = 2.7495e-01, time/batch = 16.7583s	
16491/22750 (epoch 36.244), train_loss = 0.90392267, grad/param norm = 2.4500e-01, time/batch = 16.6740s	
16492/22750 (epoch 36.246), train_loss = 0.90823360, grad/param norm = 2.5692e-01, time/batch = 16.9077s	
16493/22750 (epoch 36.248), train_loss = 0.75156027, grad/param norm = 1.9298e-01, time/batch = 16.7425s	
16494/22750 (epoch 36.251), train_loss = 0.85933556, grad/param norm = 2.2226e-01, time/batch = 17.0443s	
16495/22750 (epoch 36.253), train_loss = 0.82985154, grad/param norm = 2.8884e-01, time/batch = 17.2237s	
16496/22750 (epoch 36.255), train_loss = 0.79932196, grad/param norm = 2.5642e-01, time/batch = 17.2569s	
16497/22750 (epoch 36.257), train_loss = 0.69850352, grad/param norm = 2.2210e-01, time/batch = 17.0160s	
16498/22750 (epoch 36.259), train_loss = 0.86422279, grad/param norm = 3.1288e-01, time/batch = 17.1370s	
16499/22750 (epoch 36.262), train_loss = 0.77549805, grad/param norm = 2.3032e-01, time/batch = 17.3251s	
16500/22750 (epoch 36.264), train_loss = 0.61543955, grad/param norm = 2.4024e-01, time/batch = 17.0711s	
16501/22750 (epoch 36.266), train_loss = 0.76799384, grad/param norm = 2.7194e-01, time/batch = 16.9991s	
16502/22750 (epoch 36.268), train_loss = 0.87969877, grad/param norm = 2.6467e-01, time/batch = 16.9886s	
16503/22750 (epoch 36.270), train_loss = 0.68017114, grad/param norm = 2.3181e-01, time/batch = 17.0773s	
16504/22750 (epoch 36.273), train_loss = 1.00540437, grad/param norm = 3.0385e-01, time/batch = 17.0818s	
16505/22750 (epoch 36.275), train_loss = 0.89754770, grad/param norm = 2.1188e-01, time/batch = 17.1654s	
16506/22750 (epoch 36.277), train_loss = 0.74643964, grad/param norm = 2.4331e-01, time/batch = 17.3359s	
16507/22750 (epoch 36.279), train_loss = 0.65315561, grad/param norm = 2.0565e-01, time/batch = 17.1100s	
16508/22750 (epoch 36.281), train_loss = 0.88347158, grad/param norm = 2.3559e-01, time/batch = 16.8434s	
16509/22750 (epoch 36.284), train_loss = 0.80342353, grad/param norm = 2.2472e-01, time/batch = 16.8186s	
16510/22750 (epoch 36.286), train_loss = 0.83924585, grad/param norm = 2.1840e-01, time/batch = 16.7323s	
16511/22750 (epoch 36.288), train_loss = 0.91011878, grad/param norm = 2.3831e-01, time/batch = 16.7463s	
16512/22750 (epoch 36.290), train_loss = 0.80896719, grad/param norm = 2.2873e-01, time/batch = 16.7280s	
16513/22750 (epoch 36.292), train_loss = 0.85131383, grad/param norm = 2.5544e-01, time/batch = 16.8844s	
16514/22750 (epoch 36.295), train_loss = 0.80509671, grad/param norm = 2.3455e-01, time/batch = 16.5049s	
16515/22750 (epoch 36.297), train_loss = 0.81669514, grad/param norm = 2.7031e-01, time/batch = 16.9827s	
16516/22750 (epoch 36.299), train_loss = 0.86535207, grad/param norm = 2.5885e-01, time/batch = 16.9369s	
16517/22750 (epoch 36.301), train_loss = 0.77737385, grad/param norm = 1.9790e-01, time/batch = 17.2031s	
16518/22750 (epoch 36.303), train_loss = 0.82612226, grad/param norm = 2.1835e-01, time/batch = 17.2346s	
16519/22750 (epoch 36.305), train_loss = 0.93338179, grad/param norm = 2.2690e-01, time/batch = 17.0114s	
16520/22750 (epoch 36.308), train_loss = 0.84496119, grad/param norm = 2.3451e-01, time/batch = 17.1492s	
16521/22750 (epoch 36.310), train_loss = 0.72510476, grad/param norm = 2.5610e-01, time/batch = 17.2140s	
16522/22750 (epoch 36.312), train_loss = 0.81347769, grad/param norm = 2.4551e-01, time/batch = 16.9992s	
16523/22750 (epoch 36.314), train_loss = 0.80363014, grad/param norm = 2.3002e-01, time/batch = 17.1619s	
16524/22750 (epoch 36.316), train_loss = 0.75337524, grad/param norm = 2.1515e-01, time/batch = 17.3261s	
16525/22750 (epoch 36.319), train_loss = 0.81013099, grad/param norm = 2.4759e-01, time/batch = 17.1855s	
16526/22750 (epoch 36.321), train_loss = 0.73410780, grad/param norm = 2.6625e-01, time/batch = 17.2089s	
16527/22750 (epoch 36.323), train_loss = 0.80213187, grad/param norm = 2.3298e-01, time/batch = 17.0236s	
16528/22750 (epoch 36.325), train_loss = 0.68645102, grad/param norm = 1.9324e-01, time/batch = 16.9195s	
16529/22750 (epoch 36.327), train_loss = 0.72922457, grad/param norm = 2.3080e-01, time/batch = 16.9200s	
16530/22750 (epoch 36.330), train_loss = 0.91547539, grad/param norm = 2.3224e-01, time/batch = 16.8320s	
16531/22750 (epoch 36.332), train_loss = 0.96624992, grad/param norm = 2.4288e-01, time/batch = 19.0600s	
16532/22750 (epoch 36.334), train_loss = 0.64453122, grad/param norm = 2.2173e-01, time/batch = 17.9127s	
16533/22750 (epoch 36.336), train_loss = 0.86696262, grad/param norm = 1.9745e-01, time/batch = 20.4938s	
16534/22750 (epoch 36.338), train_loss = 0.76864802, grad/param norm = 2.2348e-01, time/batch = 17.2672s	
16535/22750 (epoch 36.341), train_loss = 0.79500340, grad/param norm = 2.3926e-01, time/batch = 19.0830s	
16536/22750 (epoch 36.343), train_loss = 0.67080234, grad/param norm = 2.0690e-01, time/batch = 17.3877s	
16537/22750 (epoch 36.345), train_loss = 0.84100682, grad/param norm = 3.0308e-01, time/batch = 17.4193s	
16538/22750 (epoch 36.347), train_loss = 0.89677000, grad/param norm = 2.5873e-01, time/batch = 17.4827s	
16539/22750 (epoch 36.349), train_loss = 0.63192703, grad/param norm = 2.6143e-01, time/batch = 17.5016s	
16540/22750 (epoch 36.352), train_loss = 0.91677297, grad/param norm = 2.4938e-01, time/batch = 17.3880s	
16541/22750 (epoch 36.354), train_loss = 0.87956307, grad/param norm = 2.4684e-01, time/batch = 17.5555s	
16542/22750 (epoch 36.356), train_loss = 0.84953335, grad/param norm = 2.4304e-01, time/batch = 17.5663s	
16543/22750 (epoch 36.358), train_loss = 0.75286985, grad/param norm = 2.3657e-01, time/batch = 17.4224s	
16544/22750 (epoch 36.360), train_loss = 0.91690201, grad/param norm = 2.3117e-01, time/batch = 17.5207s	
16545/22750 (epoch 36.363), train_loss = 0.74102381, grad/param norm = 2.4239e-01, time/batch = 17.1606s	
16546/22750 (epoch 36.365), train_loss = 0.63577952, grad/param norm = 2.4034e-01, time/batch = 16.7924s	
16547/22750 (epoch 36.367), train_loss = 0.73354592, grad/param norm = 2.3391e-01, time/batch = 16.9099s	
16548/22750 (epoch 36.369), train_loss = 0.79460012, grad/param norm = 2.3438e-01, time/batch = 16.7623s	
16549/22750 (epoch 36.371), train_loss = 0.80010226, grad/param norm = 2.4614e-01, time/batch = 16.9680s	
16550/22750 (epoch 36.374), train_loss = 0.69652404, grad/param norm = 2.2376e-01, time/batch = 16.4344s	
16551/22750 (epoch 36.376), train_loss = 0.76120084, grad/param norm = 1.9349e-01, time/batch = 30.3742s	
16552/22750 (epoch 36.378), train_loss = 0.79374830, grad/param norm = 2.3040e-01, time/batch = 16.5340s	
16553/22750 (epoch 36.380), train_loss = 0.83985892, grad/param norm = 2.1131e-01, time/batch = 16.9121s	
16554/22750 (epoch 36.382), train_loss = 0.75887471, grad/param norm = 2.1044e-01, time/batch = 16.7970s	
16555/22750 (epoch 36.385), train_loss = 0.84475118, grad/param norm = 2.0757e-01, time/batch = 17.2658s	
16556/22750 (epoch 36.387), train_loss = 0.82776494, grad/param norm = 2.2405e-01, time/batch = 17.3445s	
16557/22750 (epoch 36.389), train_loss = 0.63195244, grad/param norm = 2.0843e-01, time/batch = 17.2326s	
16558/22750 (epoch 36.391), train_loss = 0.49908633, grad/param norm = 1.7970e-01, time/batch = 17.0115s	
16559/22750 (epoch 36.393), train_loss = 0.64833950, grad/param norm = 2.0509e-01, time/batch = 17.2231s	
16560/22750 (epoch 36.396), train_loss = 0.80532862, grad/param norm = 2.2310e-01, time/batch = 17.3107s	
16561/22750 (epoch 36.398), train_loss = 0.72870578, grad/param norm = 2.2309e-01, time/batch = 17.4078s	
16562/22750 (epoch 36.400), train_loss = 0.78536596, grad/param norm = 2.4492e-01, time/batch = 17.1966s	
16563/22750 (epoch 36.402), train_loss = 0.79425440, grad/param norm = 2.2005e-01, time/batch = 17.2244s	
16564/22750 (epoch 36.404), train_loss = 0.88454255, grad/param norm = 2.5958e-01, time/batch = 17.1877s	
16565/22750 (epoch 36.407), train_loss = 0.86106737, grad/param norm = 2.3659e-01, time/batch = 17.1959s	
16566/22750 (epoch 36.409), train_loss = 0.71415192, grad/param norm = 2.3098e-01, time/batch = 17.1712s	
16567/22750 (epoch 36.411), train_loss = 0.72027743, grad/param norm = 2.0462e-01, time/batch = 17.3151s	
16568/22750 (epoch 36.413), train_loss = 0.56324664, grad/param norm = 2.1094e-01, time/batch = 17.4829s	
16569/22750 (epoch 36.415), train_loss = 0.64737413, grad/param norm = 2.2076e-01, time/batch = 17.3311s	
16570/22750 (epoch 36.418), train_loss = 0.73991250, grad/param norm = 2.5088e-01, time/batch = 17.2679s	
16571/22750 (epoch 36.420), train_loss = 0.85004252, grad/param norm = 2.7460e-01, time/batch = 17.6652s	
16572/22750 (epoch 36.422), train_loss = 0.98569078, grad/param norm = 3.1920e-01, time/batch = 17.0521s	
16573/22750 (epoch 36.424), train_loss = 0.97556795, grad/param norm = 2.5590e-01, time/batch = 17.0459s	
16574/22750 (epoch 36.426), train_loss = 0.93855531, grad/param norm = 2.2254e-01, time/batch = 17.3567s	
16575/22750 (epoch 36.429), train_loss = 0.71009292, grad/param norm = 2.1833e-01, time/batch = 17.3094s	
16576/22750 (epoch 36.431), train_loss = 0.63695275, grad/param norm = 1.9000e-01, time/batch = 17.2609s	
16577/22750 (epoch 36.433), train_loss = 0.74343513, grad/param norm = 2.1373e-01, time/batch = 17.0911s	
16578/22750 (epoch 36.435), train_loss = 0.57006878, grad/param norm = 1.6054e-01, time/batch = 17.2469s	
16579/22750 (epoch 36.437), train_loss = 0.50855135, grad/param norm = 1.8647e-01, time/batch = 17.0187s	
16580/22750 (epoch 36.440), train_loss = 0.73261704, grad/param norm = 2.5243e-01, time/batch = 17.0199s	
16581/22750 (epoch 36.442), train_loss = 0.77105635, grad/param norm = 2.5196e-01, time/batch = 17.2535s	
16582/22750 (epoch 36.444), train_loss = 0.74228651, grad/param norm = 2.3486e-01, time/batch = 17.4478s	
16583/22750 (epoch 36.446), train_loss = 0.75710759, grad/param norm = 2.4496e-01, time/batch = 17.3635s	
16584/22750 (epoch 36.448), train_loss = 0.99019443, grad/param norm = 2.6750e-01, time/batch = 17.1175s	
16585/22750 (epoch 36.451), train_loss = 0.94495550, grad/param norm = 2.2508e-01, time/batch = 17.5339s	
16586/22750 (epoch 36.453), train_loss = 0.82171819, grad/param norm = 2.5457e-01, time/batch = 17.3253s	
16587/22750 (epoch 36.455), train_loss = 0.94660711, grad/param norm = 2.3637e-01, time/batch = 17.4213s	
16588/22750 (epoch 36.457), train_loss = 0.82810037, grad/param norm = 3.9118e-01, time/batch = 17.5197s	
16589/22750 (epoch 36.459), train_loss = 0.83526139, grad/param norm = 2.2595e-01, time/batch = 17.4129s	
16590/22750 (epoch 36.462), train_loss = 0.81288079, grad/param norm = 2.0732e-01, time/batch = 17.2069s	
16591/22750 (epoch 36.464), train_loss = 0.70591859, grad/param norm = 2.4960e-01, time/batch = 17.1683s	
16592/22750 (epoch 36.466), train_loss = 0.84940858, grad/param norm = 2.6739e-01, time/batch = 17.4511s	
16593/22750 (epoch 36.468), train_loss = 0.81992841, grad/param norm = 2.5151e-01, time/batch = 17.3658s	
16594/22750 (epoch 36.470), train_loss = 0.91518461, grad/param norm = 2.8018e-01, time/batch = 17.2877s	
16595/22750 (epoch 36.473), train_loss = 0.77517728, grad/param norm = 2.0999e-01, time/batch = 17.1691s	
16596/22750 (epoch 36.475), train_loss = 0.79871670, grad/param norm = 2.4875e-01, time/batch = 17.3270s	
16597/22750 (epoch 36.477), train_loss = 0.69923612, grad/param norm = 2.3500e-01, time/batch = 17.3367s	
16598/22750 (epoch 36.479), train_loss = 0.67182999, grad/param norm = 2.0219e-01, time/batch = 17.3313s	
16599/22750 (epoch 36.481), train_loss = 0.62813088, grad/param norm = 1.7882e-01, time/batch = 17.4995s	
16600/22750 (epoch 36.484), train_loss = 0.55212428, grad/param norm = 2.1869e-01, time/batch = 17.3430s	
16601/22750 (epoch 36.486), train_loss = 0.65381933, grad/param norm = 2.2392e-01, time/batch = 17.0241s	
16602/22750 (epoch 36.488), train_loss = 0.60235264, grad/param norm = 2.0581e-01, time/batch = 17.5881s	
16603/22750 (epoch 36.490), train_loss = 0.76234175, grad/param norm = 2.2285e-01, time/batch = 17.3489s	
16604/22750 (epoch 36.492), train_loss = 0.84861588, grad/param norm = 2.2960e-01, time/batch = 17.1754s	
16605/22750 (epoch 36.495), train_loss = 0.70123296, grad/param norm = 2.3864e-01, time/batch = 17.0769s	
16606/22750 (epoch 36.497), train_loss = 0.75055547, grad/param norm = 2.5658e-01, time/batch = 17.1807s	
16607/22750 (epoch 36.499), train_loss = 0.67257390, grad/param norm = 2.0210e-01, time/batch = 17.0836s	
16608/22750 (epoch 36.501), train_loss = 0.73598059, grad/param norm = 2.3995e-01, time/batch = 17.0814s	
16609/22750 (epoch 36.503), train_loss = 0.72852639, grad/param norm = 2.2376e-01, time/batch = 17.3274s	
16610/22750 (epoch 36.505), train_loss = 0.66174126, grad/param norm = 2.2844e-01, time/batch = 17.2273s	
16611/22750 (epoch 36.508), train_loss = 0.61717615, grad/param norm = 2.2244e-01, time/batch = 17.4479s	
16612/22750 (epoch 36.510), train_loss = 0.66867537, grad/param norm = 2.2742e-01, time/batch = 17.0571s	
16613/22750 (epoch 36.512), train_loss = 0.69780271, grad/param norm = 2.2915e-01, time/batch = 16.9753s	
16614/22750 (epoch 36.514), train_loss = 0.71705753, grad/param norm = 2.1756e-01, time/batch = 16.1925s	
16615/22750 (epoch 36.516), train_loss = 0.69511461, grad/param norm = 2.2170e-01, time/batch = 15.7838s	
16616/22750 (epoch 36.519), train_loss = 0.84792869, grad/param norm = 3.1281e-01, time/batch = 16.4093s	
16617/22750 (epoch 36.521), train_loss = 0.75731604, grad/param norm = 2.3734e-01, time/batch = 15.2902s	
16618/22750 (epoch 36.523), train_loss = 0.69060446, grad/param norm = 2.8447e-01, time/batch = 15.2812s	
16619/22750 (epoch 36.525), train_loss = 0.89473907, grad/param norm = 2.5443e-01, time/batch = 15.4506s	
16620/22750 (epoch 36.527), train_loss = 0.77712246, grad/param norm = 2.1801e-01, time/batch = 16.2281s	
16621/22750 (epoch 36.530), train_loss = 0.68990601, grad/param norm = 2.0857e-01, time/batch = 15.5177s	
16622/22750 (epoch 36.532), train_loss = 0.65059823, grad/param norm = 2.0701e-01, time/batch = 15.2883s	
16623/22750 (epoch 36.534), train_loss = 0.82454926, grad/param norm = 2.4644e-01, time/batch = 16.0310s	
16624/22750 (epoch 36.536), train_loss = 0.78905053, grad/param norm = 1.9589e-01, time/batch = 15.9504s	
16625/22750 (epoch 36.538), train_loss = 0.77245910, grad/param norm = 2.0562e-01, time/batch = 18.3628s	
16626/22750 (epoch 36.541), train_loss = 0.68371106, grad/param norm = 2.1587e-01, time/batch = 18.9248s	
16627/22750 (epoch 36.543), train_loss = 0.66099103, grad/param norm = 2.1883e-01, time/batch = 18.0009s	
16628/22750 (epoch 36.545), train_loss = 0.82650889, grad/param norm = 2.3431e-01, time/batch = 19.1610s	
16629/22750 (epoch 36.547), train_loss = 0.71380511, grad/param norm = 2.1600e-01, time/batch = 17.7278s	
16630/22750 (epoch 36.549), train_loss = 0.72016702, grad/param norm = 2.0540e-01, time/batch = 16.5847s	
16631/22750 (epoch 36.552), train_loss = 0.81275394, grad/param norm = 2.2538e-01, time/batch = 17.9921s	
16632/22750 (epoch 36.554), train_loss = 0.81820644, grad/param norm = 2.3078e-01, time/batch = 18.6632s	
16633/22750 (epoch 36.556), train_loss = 0.81459149, grad/param norm = 2.2799e-01, time/batch = 17.3372s	
16634/22750 (epoch 36.558), train_loss = 0.76717937, grad/param norm = 2.2061e-01, time/batch = 19.1992s	
16635/22750 (epoch 36.560), train_loss = 0.71885705, grad/param norm = 2.1481e-01, time/batch = 18.4253s	
16636/22750 (epoch 36.563), train_loss = 0.83854709, grad/param norm = 2.2779e-01, time/batch = 17.5507s	
16637/22750 (epoch 36.565), train_loss = 0.82928257, grad/param norm = 2.5109e-01, time/batch = 17.3785s	
16638/22750 (epoch 36.567), train_loss = 0.80179789, grad/param norm = 2.3080e-01, time/batch = 18.9166s	
16639/22750 (epoch 36.569), train_loss = 0.74549880, grad/param norm = 2.7170e-01, time/batch = 19.4954s	
16640/22750 (epoch 36.571), train_loss = 0.76702174, grad/param norm = 2.4014e-01, time/batch = 17.7390s	
16641/22750 (epoch 36.574), train_loss = 0.78002529, grad/param norm = 2.2610e-01, time/batch = 18.0148s	
16642/22750 (epoch 36.576), train_loss = 0.74050463, grad/param norm = 2.1481e-01, time/batch = 18.2699s	
16643/22750 (epoch 36.578), train_loss = 0.64883614, grad/param norm = 2.2390e-01, time/batch = 18.1642s	
16644/22750 (epoch 36.580), train_loss = 0.82628277, grad/param norm = 2.5394e-01, time/batch = 17.6083s	
16645/22750 (epoch 36.582), train_loss = 0.67344846, grad/param norm = 1.8957e-01, time/batch = 18.9824s	
16646/22750 (epoch 36.585), train_loss = 0.66520320, grad/param norm = 2.2354e-01, time/batch = 18.4835s	
16647/22750 (epoch 36.587), train_loss = 0.66977036, grad/param norm = 1.9945e-01, time/batch = 17.3724s	
16648/22750 (epoch 36.589), train_loss = 0.55983766, grad/param norm = 1.8218e-01, time/batch = 17.7646s	
16649/22750 (epoch 36.591), train_loss = 0.75539358, grad/param norm = 2.0915e-01, time/batch = 16.8427s	
16650/22750 (epoch 36.593), train_loss = 0.87034503, grad/param norm = 2.3736e-01, time/batch = 17.7519s	
16651/22750 (epoch 36.596), train_loss = 0.84160544, grad/param norm = 2.4012e-01, time/batch = 20.8096s	
16652/22750 (epoch 36.598), train_loss = 0.87632966, grad/param norm = 2.6992e-01, time/batch = 17.1656s	
16653/22750 (epoch 36.600), train_loss = 0.89574625, grad/param norm = 2.5932e-01, time/batch = 16.6790s	
16654/22750 (epoch 36.602), train_loss = 0.70709660, grad/param norm = 2.2242e-01, time/batch = 16.5757s	
16655/22750 (epoch 36.604), train_loss = 0.71326843, grad/param norm = 2.1887e-01, time/batch = 15.7720s	
16656/22750 (epoch 36.607), train_loss = 0.65903178, grad/param norm = 1.9191e-01, time/batch = 15.6212s	
16657/22750 (epoch 36.609), train_loss = 0.64073998, grad/param norm = 2.4639e-01, time/batch = 15.8591s	
16658/22750 (epoch 36.611), train_loss = 0.71020090, grad/param norm = 2.0773e-01, time/batch = 15.5368s	
16659/22750 (epoch 36.613), train_loss = 0.69372254, grad/param norm = 2.3331e-01, time/batch = 15.6133s	
16660/22750 (epoch 36.615), train_loss = 0.69634675, grad/param norm = 1.7035e-01, time/batch = 15.6177s	
16661/22750 (epoch 36.618), train_loss = 0.73149144, grad/param norm = 2.0642e-01, time/batch = 16.5648s	
16662/22750 (epoch 36.620), train_loss = 0.72311914, grad/param norm = 2.1844e-01, time/batch = 15.1358s	
16663/22750 (epoch 36.622), train_loss = 0.60305736, grad/param norm = 1.6771e-01, time/batch = 15.2183s	
16664/22750 (epoch 36.624), train_loss = 0.73015909, grad/param norm = 2.6863e-01, time/batch = 15.1439s	
16665/22750 (epoch 36.626), train_loss = 0.60592701, grad/param norm = 1.9468e-01, time/batch = 15.9382s	
16666/22750 (epoch 36.629), train_loss = 0.70186155, grad/param norm = 2.3737e-01, time/batch = 14.9014s	
16667/22750 (epoch 36.631), train_loss = 0.74420983, grad/param norm = 2.0323e-01, time/batch = 15.2062s	
16668/22750 (epoch 36.633), train_loss = 0.63396935, grad/param norm = 2.0152e-01, time/batch = 15.4396s	
16669/22750 (epoch 36.635), train_loss = 0.75631715, grad/param norm = 2.2444e-01, time/batch = 15.5325s	
16670/22750 (epoch 36.637), train_loss = 0.79930853, grad/param norm = 3.1087e-01, time/batch = 15.1329s	
16671/22750 (epoch 36.640), train_loss = 0.81044874, grad/param norm = 2.4642e-01, time/batch = 15.2172s	
16672/22750 (epoch 36.642), train_loss = 0.85942053, grad/param norm = 2.3897e-01, time/batch = 15.6050s	
16673/22750 (epoch 36.644), train_loss = 0.73586252, grad/param norm = 2.6321e-01, time/batch = 15.8483s	
16674/22750 (epoch 36.646), train_loss = 0.80556576, grad/param norm = 2.7690e-01, time/batch = 15.3025s	
16675/22750 (epoch 36.648), train_loss = 0.77518052, grad/param norm = 2.1145e-01, time/batch = 14.9925s	
16676/22750 (epoch 36.651), train_loss = 0.81340176, grad/param norm = 2.3609e-01, time/batch = 15.3890s	
16677/22750 (epoch 36.653), train_loss = 0.84279037, grad/param norm = 2.0980e-01, time/batch = 15.6806s	
16678/22750 (epoch 36.655), train_loss = 0.77695753, grad/param norm = 2.1339e-01, time/batch = 16.2984s	
16679/22750 (epoch 36.657), train_loss = 0.89483896, grad/param norm = 2.4582e-01, time/batch = 15.3653s	
16680/22750 (epoch 36.659), train_loss = 0.93512317, grad/param norm = 2.2930e-01, time/batch = 15.6929s	
16681/22750 (epoch 36.662), train_loss = 0.90353359, grad/param norm = 2.8342e-01, time/batch = 15.7636s	
16682/22750 (epoch 36.664), train_loss = 0.80392304, grad/param norm = 2.1287e-01, time/batch = 15.7993s	
16683/22750 (epoch 36.666), train_loss = 0.64919514, grad/param norm = 2.0399e-01, time/batch = 16.3324s	
16684/22750 (epoch 36.668), train_loss = 0.74975976, grad/param norm = 2.2216e-01, time/batch = 16.2666s	
16685/22750 (epoch 36.670), train_loss = 0.72074135, grad/param norm = 2.2179e-01, time/batch = 15.7193s	
16686/22750 (epoch 36.673), train_loss = 0.94883557, grad/param norm = 3.4649e-01, time/batch = 15.4659s	
16687/22750 (epoch 36.675), train_loss = 1.04059630, grad/param norm = 2.9416e-01, time/batch = 15.5696s	
16688/22750 (epoch 36.677), train_loss = 0.91196105, grad/param norm = 2.3514e-01, time/batch = 16.1833s	
16689/22750 (epoch 36.679), train_loss = 0.92631796, grad/param norm = 2.8260e-01, time/batch = 15.3796s	
16690/22750 (epoch 36.681), train_loss = 0.91784307, grad/param norm = 2.5315e-01, time/batch = 15.5393s	
16691/22750 (epoch 36.684), train_loss = 0.93932938, grad/param norm = 2.7088e-01, time/batch = 15.7717s	
16692/22750 (epoch 36.686), train_loss = 0.97489831, grad/param norm = 2.7213e-01, time/batch = 16.0140s	
16693/22750 (epoch 36.688), train_loss = 0.91141358, grad/param norm = 2.7268e-01, time/batch = 15.6965s	
16694/22750 (epoch 36.690), train_loss = 0.92883649, grad/param norm = 2.8128e-01, time/batch = 15.7873s	
16695/22750 (epoch 36.692), train_loss = 0.90658992, grad/param norm = 2.6047e-01, time/batch = 15.7752s	
16696/22750 (epoch 36.695), train_loss = 0.82196961, grad/param norm = 2.2823e-01, time/batch = 15.2245s	
16697/22750 (epoch 36.697), train_loss = 0.80858546, grad/param norm = 2.0817e-01, time/batch = 14.9904s	
16698/22750 (epoch 36.699), train_loss = 0.72566558, grad/param norm = 1.9685e-01, time/batch = 15.0766s	
16699/22750 (epoch 36.701), train_loss = 0.66586411, grad/param norm = 2.4407e-01, time/batch = 16.4011s	
16700/22750 (epoch 36.703), train_loss = 0.74450249, grad/param norm = 2.2924e-01, time/batch = 15.9184s	
16701/22750 (epoch 36.705), train_loss = 0.73720529, grad/param norm = 2.1504e-01, time/batch = 16.1682s	
16702/22750 (epoch 36.708), train_loss = 0.78461008, grad/param norm = 2.5709e-01, time/batch = 16.0923s	
16703/22750 (epoch 36.710), train_loss = 0.68274181, grad/param norm = 2.2335e-01, time/batch = 16.1720s	
16704/22750 (epoch 36.712), train_loss = 0.62961657, grad/param norm = 2.2146e-01, time/batch = 15.7080s	
16705/22750 (epoch 36.714), train_loss = 0.65289942, grad/param norm = 2.1668e-01, time/batch = 15.8649s	
16706/22750 (epoch 36.716), train_loss = 0.66235652, grad/param norm = 2.0588e-01, time/batch = 16.2320s	
16707/22750 (epoch 36.719), train_loss = 0.74136867, grad/param norm = 2.7818e-01, time/batch = 15.9296s	
16708/22750 (epoch 36.721), train_loss = 0.84095474, grad/param norm = 2.2877e-01, time/batch = 15.8091s	
16709/22750 (epoch 36.723), train_loss = 0.84770777, grad/param norm = 2.3595e-01, time/batch = 16.2123s	
16710/22750 (epoch 36.725), train_loss = 0.73782640, grad/param norm = 3.1296e-01, time/batch = 16.9153s	
16711/22750 (epoch 36.727), train_loss = 0.75745121, grad/param norm = 2.3731e-01, time/batch = 16.5972s	
16712/22750 (epoch 36.730), train_loss = 0.74178582, grad/param norm = 2.3025e-01, time/batch = 16.8532s	
16713/22750 (epoch 36.732), train_loss = 0.71141517, grad/param norm = 2.1560e-01, time/batch = 16.8317s	
16714/22750 (epoch 36.734), train_loss = 0.62573483, grad/param norm = 2.0709e-01, time/batch = 17.0647s	
16715/22750 (epoch 36.736), train_loss = 0.72974553, grad/param norm = 2.2603e-01, time/batch = 16.6706s	
16716/22750 (epoch 36.738), train_loss = 0.81653809, grad/param norm = 2.6583e-01, time/batch = 16.6700s	
16717/22750 (epoch 36.741), train_loss = 0.88701781, grad/param norm = 2.2817e-01, time/batch = 16.9992s	
16718/22750 (epoch 36.743), train_loss = 0.80129782, grad/param norm = 2.3046e-01, time/batch = 17.1390s	
16719/22750 (epoch 36.745), train_loss = 0.64463140, grad/param norm = 2.0105e-01, time/batch = 16.7112s	
16720/22750 (epoch 36.747), train_loss = 0.77172575, grad/param norm = 2.0676e-01, time/batch = 16.8310s	
16721/22750 (epoch 36.749), train_loss = 0.87814856, grad/param norm = 2.6109e-01, time/batch = 16.8849s	
16722/22750 (epoch 36.752), train_loss = 0.77319399, grad/param norm = 2.3639e-01, time/batch = 16.3470s	
16723/22750 (epoch 36.754), train_loss = 0.78218048, grad/param norm = 2.3887e-01, time/batch = 16.1979s	
16724/22750 (epoch 36.756), train_loss = 0.70944919, grad/param norm = 2.3314e-01, time/batch = 16.5047s	
16725/22750 (epoch 36.758), train_loss = 0.69555533, grad/param norm = 2.0396e-01, time/batch = 16.7643s	
16726/22750 (epoch 36.760), train_loss = 0.70537821, grad/param norm = 2.3234e-01, time/batch = 16.5202s	
16727/22750 (epoch 36.763), train_loss = 0.76620342, grad/param norm = 2.2889e-01, time/batch = 16.6195s	
16728/22750 (epoch 36.765), train_loss = 0.72952282, grad/param norm = 2.1857e-01, time/batch = 17.1130s	
16729/22750 (epoch 36.767), train_loss = 0.80218259, grad/param norm = 2.1797e-01, time/batch = 17.3746s	
16730/22750 (epoch 36.769), train_loss = 0.90941195, grad/param norm = 2.6443e-01, time/batch = 16.6871s	
16731/22750 (epoch 36.771), train_loss = 0.93257898, grad/param norm = 2.8144e-01, time/batch = 17.0402s	
16732/22750 (epoch 36.774), train_loss = 0.72420638, grad/param norm = 2.5746e-01, time/batch = 17.1325s	
16733/22750 (epoch 36.776), train_loss = 0.85696776, grad/param norm = 2.3060e-01, time/batch = 16.6861s	
16734/22750 (epoch 36.778), train_loss = 0.90861959, grad/param norm = 2.4490e-01, time/batch = 16.5888s	
16735/22750 (epoch 36.780), train_loss = 0.80367349, grad/param norm = 2.3852e-01, time/batch = 16.9726s	
16736/22750 (epoch 36.782), train_loss = 0.94078802, grad/param norm = 2.5018e-01, time/batch = 16.9617s	
16737/22750 (epoch 36.785), train_loss = 0.77836394, grad/param norm = 2.4973e-01, time/batch = 16.4283s	
16738/22750 (epoch 36.787), train_loss = 0.65817700, grad/param norm = 2.5937e-01, time/batch = 16.4272s	
16739/22750 (epoch 36.789), train_loss = 0.74267430, grad/param norm = 2.1517e-01, time/batch = 17.0068s	
16740/22750 (epoch 36.791), train_loss = 0.72654109, grad/param norm = 2.0776e-01, time/batch = 16.4490s	
16741/22750 (epoch 36.793), train_loss = 0.68968947, grad/param norm = 2.4829e-01, time/batch = 16.5364s	
16742/22750 (epoch 36.796), train_loss = 0.66557254, grad/param norm = 2.1582e-01, time/batch = 16.6914s	
16743/22750 (epoch 36.798), train_loss = 0.72872958, grad/param norm = 2.2866e-01, time/batch = 16.6698s	
16744/22750 (epoch 36.800), train_loss = 0.70227779, grad/param norm = 2.4521e-01, time/batch = 16.4335s	
16745/22750 (epoch 36.802), train_loss = 0.63761240, grad/param norm = 2.2267e-01, time/batch = 16.5993s	
16746/22750 (epoch 36.804), train_loss = 0.83575815, grad/param norm = 2.1513e-01, time/batch = 17.0680s	
16747/22750 (epoch 36.807), train_loss = 0.79446361, grad/param norm = 2.2430e-01, time/batch = 16.8277s	
16748/22750 (epoch 36.809), train_loss = 0.89446500, grad/param norm = 2.4116e-01, time/batch = 16.6777s	
16749/22750 (epoch 36.811), train_loss = 0.76561144, grad/param norm = 2.2062e-01, time/batch = 16.8354s	
16750/22750 (epoch 36.813), train_loss = 0.79641652, grad/param norm = 2.1233e-01, time/batch = 16.7769s	
16751/22750 (epoch 36.815), train_loss = 0.90338296, grad/param norm = 2.3208e-01, time/batch = 16.6237s	
16752/22750 (epoch 36.818), train_loss = 0.84958406, grad/param norm = 2.1064e-01, time/batch = 16.5442s	
16753/22750 (epoch 36.820), train_loss = 0.97669371, grad/param norm = 2.5129e-01, time/batch = 16.9199s	
16754/22750 (epoch 36.822), train_loss = 0.80668568, grad/param norm = 2.2491e-01, time/batch = 16.5927s	
16755/22750 (epoch 36.824), train_loss = 0.67646025, grad/param norm = 2.0692e-01, time/batch = 16.8445s	
16756/22750 (epoch 36.826), train_loss = 0.78028148, grad/param norm = 2.2972e-01, time/batch = 16.6674s	
16757/22750 (epoch 36.829), train_loss = 0.86939548, grad/param norm = 2.5342e-01, time/batch = 16.9793s	
16758/22750 (epoch 36.831), train_loss = 0.86242174, grad/param norm = 2.5449e-01, time/batch = 16.7586s	
16759/22750 (epoch 36.833), train_loss = 0.79782243, grad/param norm = 2.3863e-01, time/batch = 16.5302s	
16760/22750 (epoch 36.835), train_loss = 0.68436670, grad/param norm = 2.4662e-01, time/batch = 17.0767s	
16761/22750 (epoch 36.837), train_loss = 0.74823626, grad/param norm = 2.5205e-01, time/batch = 16.8005s	
16762/22750 (epoch 36.840), train_loss = 0.67829689, grad/param norm = 1.9796e-01, time/batch = 16.7803s	
16763/22750 (epoch 36.842), train_loss = 0.70947087, grad/param norm = 2.4715e-01, time/batch = 17.2107s	
16764/22750 (epoch 36.844), train_loss = 0.79732991, grad/param norm = 2.5558e-01, time/batch = 31.0634s	
16765/22750 (epoch 36.846), train_loss = 0.82804535, grad/param norm = 2.2456e-01, time/batch = 16.9890s	
16766/22750 (epoch 36.848), train_loss = 0.71510260, grad/param norm = 1.9603e-01, time/batch = 16.9020s	
16767/22750 (epoch 36.851), train_loss = 0.69654044, grad/param norm = 2.2100e-01, time/batch = 16.9213s	
16768/22750 (epoch 36.853), train_loss = 0.87342094, grad/param norm = 2.2774e-01, time/batch = 16.9157s	
16769/22750 (epoch 36.855), train_loss = 0.72369696, grad/param norm = 2.0304e-01, time/batch = 16.7062s	
16770/22750 (epoch 36.857), train_loss = 0.82672532, grad/param norm = 2.2637e-01, time/batch = 16.7574s	
16771/22750 (epoch 36.859), train_loss = 0.79580943, grad/param norm = 2.4127e-01, time/batch = 16.8197s	
16772/22750 (epoch 36.862), train_loss = 0.94953251, grad/param norm = 2.4509e-01, time/batch = 16.9366s	
16773/22750 (epoch 36.864), train_loss = 0.78359696, grad/param norm = 2.1181e-01, time/batch = 16.6867s	
16774/22750 (epoch 36.866), train_loss = 0.83522480, grad/param norm = 2.2932e-01, time/batch = 16.9871s	
16775/22750 (epoch 36.868), train_loss = 0.68228725, grad/param norm = 1.9257e-01, time/batch = 16.6887s	
16776/22750 (epoch 36.870), train_loss = 0.66647754, grad/param norm = 2.1018e-01, time/batch = 16.6842s	
16777/22750 (epoch 36.873), train_loss = 0.75921000, grad/param norm = 2.2259e-01, time/batch = 16.9924s	
16778/22750 (epoch 36.875), train_loss = 0.82531972, grad/param norm = 2.1894e-01, time/batch = 16.5189s	
16779/22750 (epoch 36.877), train_loss = 0.71397354, grad/param norm = 1.9827e-01, time/batch = 16.5025s	
16780/22750 (epoch 36.879), train_loss = 0.87338877, grad/param norm = 2.4345e-01, time/batch = 16.7616s	
16781/22750 (epoch 36.881), train_loss = 0.81467681, grad/param norm = 2.2158e-01, time/batch = 16.8467s	
16782/22750 (epoch 36.884), train_loss = 0.71007529, grad/param norm = 2.0677e-01, time/batch = 16.6612s	
16783/22750 (epoch 36.886), train_loss = 0.79839363, grad/param norm = 2.3533e-01, time/batch = 16.6755s	
16784/22750 (epoch 36.888), train_loss = 0.82080190, grad/param norm = 2.0016e-01, time/batch = 16.8595s	
16785/22750 (epoch 36.890), train_loss = 0.82967567, grad/param norm = 2.3137e-01, time/batch = 16.5989s	
16786/22750 (epoch 36.892), train_loss = 1.04858881, grad/param norm = 2.7862e-01, time/batch = 16.8363s	
16787/22750 (epoch 36.895), train_loss = 0.74058403, grad/param norm = 2.3402e-01, time/batch = 16.4282s	
16788/22750 (epoch 36.897), train_loss = 0.88489541, grad/param norm = 2.4736e-01, time/batch = 16.9811s	
16789/22750 (epoch 36.899), train_loss = 0.80573486, grad/param norm = 2.3438e-01, time/batch = 16.1753s	
16790/22750 (epoch 36.901), train_loss = 0.85971485, grad/param norm = 2.5948e-01, time/batch = 16.3367s	
16791/22750 (epoch 36.903), train_loss = 0.77043791, grad/param norm = 2.2340e-01, time/batch = 16.5969s	
16792/22750 (epoch 36.905), train_loss = 0.83508646, grad/param norm = 2.1523e-01, time/batch = 16.7455s	
16793/22750 (epoch 36.908), train_loss = 0.65703334, grad/param norm = 2.1631e-01, time/batch = 17.0414s	
16794/22750 (epoch 36.910), train_loss = 0.59993057, grad/param norm = 2.0650e-01, time/batch = 17.2790s	
16795/22750 (epoch 36.912), train_loss = 0.76215600, grad/param norm = 2.2198e-01, time/batch = 17.5479s	
16796/22750 (epoch 36.914), train_loss = 0.78846666, grad/param norm = 2.3847e-01, time/batch = 17.2897s	
16797/22750 (epoch 36.916), train_loss = 0.61529748, grad/param norm = 2.1855e-01, time/batch = 17.2165s	
16798/22750 (epoch 36.919), train_loss = 0.76743080, grad/param norm = 2.2846e-01, time/batch = 17.2956s	
16799/22750 (epoch 36.921), train_loss = 0.59883773, grad/param norm = 2.2548e-01, time/batch = 17.2455s	
16800/22750 (epoch 36.923), train_loss = 0.69802397, grad/param norm = 2.0384e-01, time/batch = 17.3354s	
16801/22750 (epoch 36.925), train_loss = 0.76807302, grad/param norm = 2.0000e-01, time/batch = 17.1633s	
16802/22750 (epoch 36.927), train_loss = 0.60354520, grad/param norm = 1.9808e-01, time/batch = 17.3796s	
16803/22750 (epoch 36.930), train_loss = 0.58547279, grad/param norm = 2.1406e-01, time/batch = 17.0876s	
16804/22750 (epoch 36.932), train_loss = 0.75733120, grad/param norm = 2.3244e-01, time/batch = 17.2275s	
16805/22750 (epoch 36.934), train_loss = 0.63798800, grad/param norm = 1.8770e-01, time/batch = 17.2130s	
16806/22750 (epoch 36.936), train_loss = 0.86597350, grad/param norm = 2.5446e-01, time/batch = 17.0693s	
16807/22750 (epoch 36.938), train_loss = 0.85808983, grad/param norm = 2.0964e-01, time/batch = 16.9541s	
16808/22750 (epoch 36.941), train_loss = 0.91072652, grad/param norm = 2.6099e-01, time/batch = 16.7397s	
16809/22750 (epoch 36.943), train_loss = 0.78735567, grad/param norm = 2.1538e-01, time/batch = 16.9689s	
16810/22750 (epoch 36.945), train_loss = 0.79697307, grad/param norm = 2.5362e-01, time/batch = 16.6496s	
16811/22750 (epoch 36.947), train_loss = 0.71256788, grad/param norm = 2.1261e-01, time/batch = 17.1586s	
16812/22750 (epoch 36.949), train_loss = 0.71794850, grad/param norm = 2.2577e-01, time/batch = 17.1769s	
16813/22750 (epoch 36.952), train_loss = 0.72123125, grad/param norm = 2.0744e-01, time/batch = 17.2507s	
16814/22750 (epoch 36.954), train_loss = 0.66893785, grad/param norm = 2.1757e-01, time/batch = 17.0940s	
16815/22750 (epoch 36.956), train_loss = 0.81807461, grad/param norm = 2.3984e-01, time/batch = 17.1679s	
16816/22750 (epoch 36.958), train_loss = 0.69320407, grad/param norm = 1.9520e-01, time/batch = 17.6095s	
16817/22750 (epoch 36.960), train_loss = 0.67472205, grad/param norm = 2.0751e-01, time/batch = 17.3534s	
16818/22750 (epoch 36.963), train_loss = 0.78444119, grad/param norm = 2.1255e-01, time/batch = 17.5349s	
16819/22750 (epoch 36.965), train_loss = 0.83147182, grad/param norm = 2.1054e-01, time/batch = 16.9966s	
16820/22750 (epoch 36.967), train_loss = 0.82143900, grad/param norm = 2.3309e-01, time/batch = 16.7645s	
16821/22750 (epoch 36.969), train_loss = 0.74115249, grad/param norm = 2.4040e-01, time/batch = 16.9302s	
16822/22750 (epoch 36.971), train_loss = 0.70373028, grad/param norm = 2.0106e-01, time/batch = 17.0842s	
16823/22750 (epoch 36.974), train_loss = 0.68469837, grad/param norm = 1.9662e-01, time/batch = 16.9926s	
16824/22750 (epoch 36.976), train_loss = 0.72668281, grad/param norm = 2.3606e-01, time/batch = 16.8435s	
16825/22750 (epoch 36.978), train_loss = 0.71210253, grad/param norm = 2.1170e-01, time/batch = 16.8362s	
16826/22750 (epoch 36.980), train_loss = 0.87669592, grad/param norm = 2.8103e-01, time/batch = 16.9734s	
16827/22750 (epoch 36.982), train_loss = 0.70941008, grad/param norm = 2.0297e-01, time/batch = 17.0493s	
16828/22750 (epoch 36.985), train_loss = 0.89295811, grad/param norm = 2.2392e-01, time/batch = 16.8375s	
16829/22750 (epoch 36.987), train_loss = 0.63480637, grad/param norm = 2.0755e-01, time/batch = 16.8235s	
16830/22750 (epoch 36.989), train_loss = 0.70935872, grad/param norm = 2.3166e-01, time/batch = 16.9731s	
16831/22750 (epoch 36.991), train_loss = 0.80937581, grad/param norm = 2.8080e-01, time/batch = 16.6161s	
16832/22750 (epoch 36.993), train_loss = 0.76232629, grad/param norm = 2.5856e-01, time/batch = 16.8397s	
16833/22750 (epoch 36.996), train_loss = 0.68629495, grad/param norm = 2.7367e-01, time/batch = 16.9183s	
16834/22750 (epoch 36.998), train_loss = 0.84816037, grad/param norm = 2.4347e-01, time/batch = 17.0742s	
decayed learning rate by a factor 0.97 to 0.00085239041033725	
16835/22750 (epoch 37.000), train_loss = 0.74202151, grad/param norm = 2.1179e-01, time/batch = 16.9083s	
16836/22750 (epoch 37.002), train_loss = 0.93368012, grad/param norm = 2.3782e-01, time/batch = 16.9161s	
16837/22750 (epoch 37.004), train_loss = 0.72867073, grad/param norm = 2.0962e-01, time/batch = 17.0861s	
16838/22750 (epoch 37.007), train_loss = 0.73916608, grad/param norm = 2.3921e-01, time/batch = 17.0478s	
16839/22750 (epoch 37.009), train_loss = 0.89917003, grad/param norm = 2.7015e-01, time/batch = 16.8397s	
16840/22750 (epoch 37.011), train_loss = 0.97070551, grad/param norm = 3.8384e-01, time/batch = 16.9067s	
16841/22750 (epoch 37.013), train_loss = 0.89146582, grad/param norm = 2.7743e-01, time/batch = 17.1252s	
16842/22750 (epoch 37.015), train_loss = 0.79755433, grad/param norm = 2.2786e-01, time/batch = 17.2124s	
16843/22750 (epoch 37.018), train_loss = 0.87579975, grad/param norm = 2.6324e-01, time/batch = 16.9938s	
16844/22750 (epoch 37.020), train_loss = 0.91257805, grad/param norm = 2.5416e-01, time/batch = 17.2504s	
16845/22750 (epoch 37.022), train_loss = 0.76210834, grad/param norm = 2.3243e-01, time/batch = 16.9374s	
16846/22750 (epoch 37.024), train_loss = 0.79235976, grad/param norm = 2.3948e-01, time/batch = 17.1569s	
16847/22750 (epoch 37.026), train_loss = 0.81195771, grad/param norm = 2.3738e-01, time/batch = 16.9990s	
16848/22750 (epoch 37.029), train_loss = 0.64484601, grad/param norm = 2.3150e-01, time/batch = 16.9945s	
16849/22750 (epoch 37.031), train_loss = 0.98399194, grad/param norm = 2.7147e-01, time/batch = 16.8364s	
16850/22750 (epoch 37.033), train_loss = 0.79780930, grad/param norm = 2.2168e-01, time/batch = 16.8417s	
16851/22750 (epoch 37.035), train_loss = 0.84024187, grad/param norm = 2.4514e-01, time/batch = 17.3809s	
16852/22750 (epoch 37.037), train_loss = 0.87736944, grad/param norm = 2.4287e-01, time/batch = 16.7662s	
16853/22750 (epoch 37.040), train_loss = 0.77867305, grad/param norm = 2.3879e-01, time/batch = 16.8444s	
16854/22750 (epoch 37.042), train_loss = 0.80579580, grad/param norm = 2.3747e-01, time/batch = 17.0749s	
16855/22750 (epoch 37.044), train_loss = 0.78270736, grad/param norm = 2.3054e-01, time/batch = 16.7895s	
16856/22750 (epoch 37.046), train_loss = 0.86487334, grad/param norm = 3.1926e-01, time/batch = 17.1946s	
16857/22750 (epoch 37.048), train_loss = 0.77600836, grad/param norm = 2.1726e-01, time/batch = 16.9351s	
16858/22750 (epoch 37.051), train_loss = 0.78999669, grad/param norm = 2.5029e-01, time/batch = 17.2275s	
16859/22750 (epoch 37.053), train_loss = 0.76405319, grad/param norm = 2.0547e-01, time/batch = 17.2219s	
16860/22750 (epoch 37.055), train_loss = 0.66407935, grad/param norm = 1.8440e-01, time/batch = 16.6661s	
16861/22750 (epoch 37.057), train_loss = 0.91478816, grad/param norm = 2.3753e-01, time/batch = 16.8984s	
16862/22750 (epoch 37.059), train_loss = 0.58925421, grad/param norm = 2.5020e-01, time/batch = 16.9146s	
16863/22750 (epoch 37.062), train_loss = 0.65837552, grad/param norm = 2.1308e-01, time/batch = 16.9239s	
16864/22750 (epoch 37.064), train_loss = 0.88999690, grad/param norm = 2.4631e-01, time/batch = 16.7730s	
16865/22750 (epoch 37.066), train_loss = 0.68594917, grad/param norm = 1.9231e-01, time/batch = 16.7765s	
16866/22750 (epoch 37.068), train_loss = 0.70176990, grad/param norm = 1.9849e-01, time/batch = 16.6127s	
16867/22750 (epoch 37.070), train_loss = 0.60465159, grad/param norm = 1.9212e-01, time/batch = 16.9110s	
16868/22750 (epoch 37.073), train_loss = 0.72205861, grad/param norm = 2.3284e-01, time/batch = 17.0636s	
16869/22750 (epoch 37.075), train_loss = 0.77852730, grad/param norm = 2.6727e-01, time/batch = 16.9953s	
16870/22750 (epoch 37.077), train_loss = 0.56939902, grad/param norm = 2.2440e-01, time/batch = 17.1589s	
16871/22750 (epoch 37.079), train_loss = 0.78252947, grad/param norm = 2.8103e-01, time/batch = 17.3343s	
16872/22750 (epoch 37.081), train_loss = 0.73170162, grad/param norm = 2.6722e-01, time/batch = 17.5337s	
16873/22750 (epoch 37.084), train_loss = 0.73061060, grad/param norm = 2.1486e-01, time/batch = 17.3407s	
16874/22750 (epoch 37.086), train_loss = 0.76740874, grad/param norm = 2.1330e-01, time/batch = 17.3371s	
16875/22750 (epoch 37.088), train_loss = 0.71149697, grad/param norm = 2.2498e-01, time/batch = 17.0237s	
16876/22750 (epoch 37.090), train_loss = 0.73972285, grad/param norm = 2.3772e-01, time/batch = 16.9559s	
16877/22750 (epoch 37.092), train_loss = 0.82263600, grad/param norm = 2.1518e-01, time/batch = 17.0593s	
16878/22750 (epoch 37.095), train_loss = 0.70458245, grad/param norm = 2.1826e-01, time/batch = 17.0725s	
16879/22750 (epoch 37.097), train_loss = 0.75570900, grad/param norm = 2.1077e-01, time/batch = 17.2282s	
16880/22750 (epoch 37.099), train_loss = 0.70421106, grad/param norm = 2.3635e-01, time/batch = 17.0662s	
16881/22750 (epoch 37.101), train_loss = 0.64284392, grad/param norm = 2.1991e-01, time/batch = 17.2235s	
16882/22750 (epoch 37.103), train_loss = 0.81900451, grad/param norm = 2.4047e-01, time/batch = 17.0697s	
16883/22750 (epoch 37.105), train_loss = 0.90051767, grad/param norm = 2.7667e-01, time/batch = 16.3414s	
16884/22750 (epoch 37.108), train_loss = 0.79625654, grad/param norm = 2.5796e-01, time/batch = 16.0276s	
16885/22750 (epoch 37.110), train_loss = 0.86924139, grad/param norm = 2.5392e-01, time/batch = 15.6937s	
16886/22750 (epoch 37.112), train_loss = 0.65364030, grad/param norm = 1.8226e-01, time/batch = 16.3423s	
16887/22750 (epoch 37.114), train_loss = 0.56891815, grad/param norm = 1.9399e-01, time/batch = 15.9365s	
16888/22750 (epoch 37.116), train_loss = 0.77117927, grad/param norm = 2.0626e-01, time/batch = 15.6930s	
16889/22750 (epoch 37.119), train_loss = 0.71800442, grad/param norm = 2.0556e-01, time/batch = 15.6050s	
16890/22750 (epoch 37.121), train_loss = 0.74087090, grad/param norm = 2.4707e-01, time/batch = 16.0918s	
16891/22750 (epoch 37.123), train_loss = 0.65250932, grad/param norm = 2.1230e-01, time/batch = 15.6799s	
16892/22750 (epoch 37.125), train_loss = 0.87233150, grad/param norm = 2.2469e-01, time/batch = 15.9275s	
16893/22750 (epoch 37.127), train_loss = 0.72578134, grad/param norm = 2.4314e-01, time/batch = 16.5530s	
16894/22750 (epoch 37.130), train_loss = 0.73704285, grad/param norm = 2.0272e-01, time/batch = 16.2354s	
16895/22750 (epoch 37.132), train_loss = 0.70219593, grad/param norm = 2.0918e-01, time/batch = 15.2169s	
16896/22750 (epoch 37.134), train_loss = 0.71946619, grad/param norm = 2.2576e-01, time/batch = 15.4616s	
16897/22750 (epoch 37.136), train_loss = 0.61390118, grad/param norm = 2.2334e-01, time/batch = 15.9249s	
16898/22750 (epoch 37.138), train_loss = 0.83345276, grad/param norm = 2.5041e-01, time/batch = 16.4060s	
16899/22750 (epoch 37.141), train_loss = 0.74840793, grad/param norm = 2.0428e-01, time/batch = 15.5103s	
16900/22750 (epoch 37.143), train_loss = 0.68749702, grad/param norm = 1.9826e-01, time/batch = 15.5992s	
16901/22750 (epoch 37.145), train_loss = 0.85718910, grad/param norm = 2.2380e-01, time/batch = 16.3296s	
16902/22750 (epoch 37.147), train_loss = 0.91991393, grad/param norm = 2.3057e-01, time/batch = 15.6010s	
16903/22750 (epoch 37.149), train_loss = 0.76743273, grad/param norm = 2.2235e-01, time/batch = 15.7009s	
16904/22750 (epoch 37.152), train_loss = 0.75603181, grad/param norm = 2.1133e-01, time/batch = 15.5532s	
16905/22750 (epoch 37.154), train_loss = 0.69523890, grad/param norm = 2.3290e-01, time/batch = 16.0053s	
16906/22750 (epoch 37.156), train_loss = 0.67851806, grad/param norm = 2.1158e-01, time/batch = 15.6184s	
16907/22750 (epoch 37.158), train_loss = 0.66033427, grad/param norm = 2.4647e-01, time/batch = 15.3654s	
16908/22750 (epoch 37.160), train_loss = 0.75395895, grad/param norm = 2.2317e-01, time/batch = 15.6767s	
16909/22750 (epoch 37.163), train_loss = 0.88244757, grad/param norm = 2.3654e-01, time/batch = 16.0669s	
16910/22750 (epoch 37.165), train_loss = 0.81659954, grad/param norm = 2.3330e-01, time/batch = 15.5155s	
16911/22750 (epoch 37.167), train_loss = 0.69065304, grad/param norm = 2.1368e-01, time/batch = 15.7655s	
16912/22750 (epoch 37.169), train_loss = 0.76640382, grad/param norm = 2.2257e-01, time/batch = 16.1683s	
16913/22750 (epoch 37.171), train_loss = 0.65346744, grad/param norm = 1.9455e-01, time/batch = 15.9359s	
16914/22750 (epoch 37.174), train_loss = 0.64846430, grad/param norm = 2.4431e-01, time/batch = 15.7099s	
16915/22750 (epoch 37.176), train_loss = 0.66080570, grad/param norm = 2.0639e-01, time/batch = 15.3764s	
16916/22750 (epoch 37.178), train_loss = 0.69902585, grad/param norm = 2.0256e-01, time/batch = 15.8709s	
16917/22750 (epoch 37.180), train_loss = 0.84472598, grad/param norm = 2.8816e-01, time/batch = 16.0013s	
16918/22750 (epoch 37.182), train_loss = 0.81612957, grad/param norm = 2.3874e-01, time/batch = 15.6844s	
16919/22750 (epoch 37.185), train_loss = 0.84524157, grad/param norm = 2.6377e-01, time/batch = 15.3617s	
16920/22750 (epoch 37.187), train_loss = 0.65988433, grad/param norm = 2.1607e-01, time/batch = 15.9157s	
16921/22750 (epoch 37.189), train_loss = 0.66384300, grad/param norm = 2.2854e-01, time/batch = 15.3512s	
16922/22750 (epoch 37.191), train_loss = 0.70757944, grad/param norm = 2.5909e-01, time/batch = 15.4357s	
16923/22750 (epoch 37.193), train_loss = 0.80998420, grad/param norm = 2.5346e-01, time/batch = 15.3498s	
16924/22750 (epoch 37.196), train_loss = 0.74439149, grad/param norm = 2.4217e-01, time/batch = 16.4156s	
16925/22750 (epoch 37.198), train_loss = 0.56453767, grad/param norm = 2.5163e-01, time/batch = 15.1205s	
16926/22750 (epoch 37.200), train_loss = 0.77254524, grad/param norm = 2.9908e-01, time/batch = 15.6196s	
16927/22750 (epoch 37.202), train_loss = 0.81094177, grad/param norm = 2.4917e-01, time/batch = 15.7641s	
16928/22750 (epoch 37.204), train_loss = 0.77558485, grad/param norm = 2.2141e-01, time/batch = 16.1586s	
16929/22750 (epoch 37.207), train_loss = 0.77650888, grad/param norm = 2.5035e-01, time/batch = 16.0838s	
16930/22750 (epoch 37.209), train_loss = 0.72739666, grad/param norm = 2.2490e-01, time/batch = 15.8326s	
16931/22750 (epoch 37.211), train_loss = 0.67430728, grad/param norm = 2.4774e-01, time/batch = 16.5658s	
16932/22750 (epoch 37.213), train_loss = 0.57961201, grad/param norm = 2.0570e-01, time/batch = 15.8485s	
16933/22750 (epoch 37.215), train_loss = 0.56422302, grad/param norm = 1.7204e-01, time/batch = 15.6886s	
16934/22750 (epoch 37.218), train_loss = 0.66916627, grad/param norm = 2.5409e-01, time/batch = 15.6853s	
16935/22750 (epoch 37.220), train_loss = 0.61935775, grad/param norm = 2.2836e-01, time/batch = 15.9555s	
16936/22750 (epoch 37.222), train_loss = 0.61705356, grad/param norm = 2.1306e-01, time/batch = 15.8722s	
16937/22750 (epoch 37.224), train_loss = 0.66999253, grad/param norm = 2.1131e-01, time/batch = 15.6360s	
16938/22750 (epoch 37.226), train_loss = 0.73577930, grad/param norm = 2.1405e-01, time/batch = 15.6329s	
16939/22750 (epoch 37.229), train_loss = 0.78929598, grad/param norm = 2.6995e-01, time/batch = 16.1593s	
16940/22750 (epoch 37.231), train_loss = 0.65487431, grad/param norm = 2.0998e-01, time/batch = 15.6164s	
16941/22750 (epoch 37.233), train_loss = 0.59474289, grad/param norm = 2.1539e-01, time/batch = 16.1724s	
16942/22750 (epoch 37.235), train_loss = 0.56977337, grad/param norm = 2.2611e-01, time/batch = 15.7665s	
16943/22750 (epoch 37.237), train_loss = 0.68387138, grad/param norm = 2.4220e-01, time/batch = 15.6849s	
16944/22750 (epoch 37.240), train_loss = 0.73842184, grad/param norm = 2.0758e-01, time/batch = 15.5243s	
16945/22750 (epoch 37.242), train_loss = 0.87226410, grad/param norm = 2.4389e-01, time/batch = 15.6180s	
16946/22750 (epoch 37.244), train_loss = 0.87525200, grad/param norm = 2.3456e-01, time/batch = 15.9500s	
16947/22750 (epoch 37.246), train_loss = 0.90549027, grad/param norm = 2.6700e-01, time/batch = 15.9420s	
16948/22750 (epoch 37.248), train_loss = 0.73248469, grad/param norm = 2.1586e-01, time/batch = 16.3548s	
16949/22750 (epoch 37.251), train_loss = 0.85562261, grad/param norm = 2.4321e-01, time/batch = 15.5468s	
16950/22750 (epoch 37.253), train_loss = 0.78672154, grad/param norm = 2.4684e-01, time/batch = 16.0131s	
16951/22750 (epoch 37.255), train_loss = 0.76673119, grad/param norm = 2.1011e-01, time/batch = 15.6052s	
16952/22750 (epoch 37.257), train_loss = 0.68872093, grad/param norm = 2.6135e-01, time/batch = 15.7640s	
16953/22750 (epoch 37.259), train_loss = 0.84529810, grad/param norm = 2.8371e-01, time/batch = 15.6095s	
16954/22750 (epoch 37.262), train_loss = 0.77265263, grad/param norm = 2.4854e-01, time/batch = 16.2239s	
16955/22750 (epoch 37.264), train_loss = 0.59084489, grad/param norm = 2.1428e-01, time/batch = 15.9203s	
16956/22750 (epoch 37.266), train_loss = 0.75481090, grad/param norm = 2.7040e-01, time/batch = 15.6464s	
16957/22750 (epoch 37.268), train_loss = 0.87026512, grad/param norm = 2.5793e-01, time/batch = 15.7151s	
16958/22750 (epoch 37.270), train_loss = 0.66296572, grad/param norm = 2.2152e-01, time/batch = 17.7213s	
16959/22750 (epoch 37.273), train_loss = 0.99241049, grad/param norm = 2.5847e-01, time/batch = 19.6015s	
16960/22750 (epoch 37.275), train_loss = 0.88996764, grad/param norm = 2.3465e-01, time/batch = 15.6098s	
16961/22750 (epoch 37.277), train_loss = 0.75215779, grad/param norm = 2.8648e-01, time/batch = 18.0667s	
16962/22750 (epoch 37.279), train_loss = 0.65751562, grad/param norm = 2.4701e-01, time/batch = 19.7339s	
16963/22750 (epoch 37.281), train_loss = 0.88034874, grad/param norm = 2.3418e-01, time/batch = 19.0916s	
16964/22750 (epoch 37.284), train_loss = 0.78728686, grad/param norm = 2.0332e-01, time/batch = 17.7502s	
16965/22750 (epoch 37.286), train_loss = 0.84275913, grad/param norm = 2.2962e-01, time/batch = 19.4309s	
16966/22750 (epoch 37.288), train_loss = 0.92525935, grad/param norm = 2.5395e-01, time/batch = 19.3567s	
16967/22750 (epoch 37.290), train_loss = 0.78830436, grad/param norm = 2.0400e-01, time/batch = 19.6143s	
16968/22750 (epoch 37.292), train_loss = 0.83565671, grad/param norm = 2.9755e-01, time/batch = 18.4735s	
16969/22750 (epoch 37.295), train_loss = 0.80019260, grad/param norm = 2.3382e-01, time/batch = 17.9279s	
16970/22750 (epoch 37.297), train_loss = 0.79571150, grad/param norm = 2.4186e-01, time/batch = 18.2538s	
16971/22750 (epoch 37.299), train_loss = 0.86704498, grad/param norm = 2.7168e-01, time/batch = 17.4913s	
16972/22750 (epoch 37.301), train_loss = 0.76607814, grad/param norm = 2.1373e-01, time/batch = 20.1578s	
16973/22750 (epoch 37.303), train_loss = 0.81541190, grad/param norm = 2.2853e-01, time/batch = 19.1678s	
16974/22750 (epoch 37.305), train_loss = 0.93444095, grad/param norm = 2.4928e-01, time/batch = 18.9207s	
16975/22750 (epoch 37.308), train_loss = 0.82422313, grad/param norm = 2.1139e-01, time/batch = 21.0170s	
16976/22750 (epoch 37.310), train_loss = 0.71486133, grad/param norm = 2.5431e-01, time/batch = 17.5293s	
16977/22750 (epoch 37.312), train_loss = 0.79536566, grad/param norm = 2.4580e-01, time/batch = 32.3417s	
16978/22750 (epoch 37.314), train_loss = 0.78906851, grad/param norm = 2.2217e-01, time/batch = 18.3439s	
16979/22750 (epoch 37.316), train_loss = 0.75584755, grad/param norm = 2.1899e-01, time/batch = 18.1676s	
16980/22750 (epoch 37.319), train_loss = 0.79828861, grad/param norm = 2.5660e-01, time/batch = 18.0867s	
16981/22750 (epoch 37.321), train_loss = 0.72028870, grad/param norm = 2.5145e-01, time/batch = 17.9941s	
16982/22750 (epoch 37.323), train_loss = 0.79810622, grad/param norm = 2.4151e-01, time/batch = 19.0070s	
16983/22750 (epoch 37.325), train_loss = 0.68763924, grad/param norm = 2.1957e-01, time/batch = 17.7868s	
16984/22750 (epoch 37.327), train_loss = 0.72076929, grad/param norm = 2.4788e-01, time/batch = 20.5183s	
16985/22750 (epoch 37.330), train_loss = 0.90985331, grad/param norm = 2.6677e-01, time/batch = 20.2694s	
16986/22750 (epoch 37.332), train_loss = 0.95886655, grad/param norm = 2.2823e-01, time/batch = 17.0971s	
16987/22750 (epoch 37.334), train_loss = 0.62131292, grad/param norm = 1.9541e-01, time/batch = 17.7629s	
16988/22750 (epoch 37.336), train_loss = 0.85146335, grad/param norm = 2.2782e-01, time/batch = 18.3431s	
16989/22750 (epoch 37.338), train_loss = 0.76440090, grad/param norm = 2.3468e-01, time/batch = 17.9129s	
16990/22750 (epoch 37.341), train_loss = 0.77550109, grad/param norm = 2.1995e-01, time/batch = 18.2456s	
16991/22750 (epoch 37.343), train_loss = 0.67956350, grad/param norm = 2.8144e-01, time/batch = 18.7492s	
16992/22750 (epoch 37.345), train_loss = 0.86193510, grad/param norm = 3.2440e-01, time/batch = 18.1947s	
16993/22750 (epoch 37.347), train_loss = 0.87435874, grad/param norm = 2.3012e-01, time/batch = 17.7649s	
16994/22750 (epoch 37.349), train_loss = 0.65343284, grad/param norm = 2.6289e-01, time/batch = 18.7594s	
16995/22750 (epoch 37.352), train_loss = 0.92015861, grad/param norm = 2.6378e-01, time/batch = 18.6821s	
16996/22750 (epoch 37.354), train_loss = 0.87563838, grad/param norm = 2.3741e-01, time/batch = 18.4841s	
16997/22750 (epoch 37.356), train_loss = 0.83978888, grad/param norm = 2.3311e-01, time/batch = 16.3176s	
16998/22750 (epoch 37.358), train_loss = 0.76181725, grad/param norm = 2.4945e-01, time/batch = 16.3134s	
16999/22750 (epoch 37.360), train_loss = 0.91838540, grad/param norm = 2.5837e-01, time/batch = 16.6595s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_wakata_epoch37.36_1.7268.t7	
17000/22750 (epoch 37.363), train_loss = 0.73285177, grad/param norm = 2.5768e-01, time/batch = 16.6236s	
17001/22750 (epoch 37.365), train_loss = 1.32865486, grad/param norm = 3.0168e-01, time/batch = 19.4130s	
17002/22750 (epoch 37.367), train_loss = 0.72285572, grad/param norm = 2.5836e-01, time/batch = 18.5118s	
17003/22750 (epoch 37.369), train_loss = 0.81103177, grad/param norm = 3.0625e-01, time/batch = 17.6636s	
17004/22750 (epoch 37.371), train_loss = 0.79547276, grad/param norm = 2.5558e-01, time/batch = 19.4160s	
17005/22750 (epoch 37.374), train_loss = 0.71404991, grad/param norm = 2.4820e-01, time/batch = 18.5271s	
17006/22750 (epoch 37.376), train_loss = 0.75166299, grad/param norm = 2.0849e-01, time/batch = 19.1994s	
17007/22750 (epoch 37.378), train_loss = 0.78396265, grad/param norm = 2.2973e-01, time/batch = 18.4507s	
17008/22750 (epoch 37.380), train_loss = 0.84214004, grad/param norm = 2.3769e-01, time/batch = 19.4987s	
17009/22750 (epoch 37.382), train_loss = 0.73788044, grad/param norm = 2.0954e-01, time/batch = 17.3334s	
17010/22750 (epoch 37.385), train_loss = 0.83250179, grad/param norm = 2.0557e-01, time/batch = 17.5569s	
17011/22750 (epoch 37.387), train_loss = 0.81238003, grad/param norm = 2.1501e-01, time/batch = 16.8453s	
17012/22750 (epoch 37.389), train_loss = 0.63410564, grad/param norm = 2.1830e-01, time/batch = 19.2591s	
17013/22750 (epoch 37.391), train_loss = 0.49790097, grad/param norm = 2.0546e-01, time/batch = 18.2480s	
17014/22750 (epoch 37.393), train_loss = 0.65033981, grad/param norm = 2.2764e-01, time/batch = 18.9399s	
17015/22750 (epoch 37.396), train_loss = 0.79305976, grad/param norm = 2.2033e-01, time/batch = 19.4533s	
17016/22750 (epoch 37.398), train_loss = 0.71278635, grad/param norm = 1.9889e-01, time/batch = 19.1969s	
17017/22750 (epoch 37.400), train_loss = 0.77131791, grad/param norm = 2.3985e-01, time/batch = 18.4319s	
17018/22750 (epoch 37.402), train_loss = 0.79580642, grad/param norm = 2.1332e-01, time/batch = 20.6480s	
17019/22750 (epoch 37.404), train_loss = 0.89663684, grad/param norm = 2.7191e-01, time/batch = 19.4896s	
17020/22750 (epoch 37.407), train_loss = 0.86640907, grad/param norm = 2.5946e-01, time/batch = 18.4062s	
17021/22750 (epoch 37.409), train_loss = 0.71677775, grad/param norm = 2.5637e-01, time/batch = 18.9918s	
17022/22750 (epoch 37.411), train_loss = 0.71540645, grad/param norm = 2.2013e-01, time/batch = 18.8319s	
17023/22750 (epoch 37.413), train_loss = 0.56591184, grad/param norm = 2.1691e-01, time/batch = 19.7049s	
17024/22750 (epoch 37.415), train_loss = 0.63975359, grad/param norm = 2.1525e-01, time/batch = 19.0164s	
17025/22750 (epoch 37.418), train_loss = 0.73593101, grad/param norm = 2.6244e-01, time/batch = 20.0997s	
17026/22750 (epoch 37.420), train_loss = 0.84226416, grad/param norm = 2.6690e-01, time/batch = 17.9234s	
17027/22750 (epoch 37.422), train_loss = 0.98246407, grad/param norm = 2.9633e-01, time/batch = 19.8209s	
17028/22750 (epoch 37.424), train_loss = 0.95095433, grad/param norm = 2.5702e-01, time/batch = 19.8268s	
17029/22750 (epoch 37.426), train_loss = 0.94252330, grad/param norm = 2.3483e-01, time/batch = 16.9044s	
17030/22750 (epoch 37.429), train_loss = 0.70822772, grad/param norm = 2.2543e-01, time/batch = 17.5122s	
17031/22750 (epoch 37.431), train_loss = 0.63416300, grad/param norm = 1.9758e-01, time/batch = 19.0008s	
17032/22750 (epoch 37.433), train_loss = 0.71975809, grad/param norm = 2.1087e-01, time/batch = 18.3604s	
17033/22750 (epoch 37.435), train_loss = 0.56311614, grad/param norm = 1.7399e-01, time/batch = 20.7713s	
17034/22750 (epoch 37.437), train_loss = 0.49233590, grad/param norm = 1.8159e-01, time/batch = 17.6294s	
17035/22750 (epoch 37.440), train_loss = 0.70867649, grad/param norm = 2.3427e-01, time/batch = 17.2557s	
17036/22750 (epoch 37.442), train_loss = 0.75220617, grad/param norm = 2.3537e-01, time/batch = 19.1491s	
17037/22750 (epoch 37.444), train_loss = 0.72609012, grad/param norm = 2.5006e-01, time/batch = 18.6616s	
17038/22750 (epoch 37.446), train_loss = 0.75332180, grad/param norm = 2.5108e-01, time/batch = 18.0011s	
17039/22750 (epoch 37.448), train_loss = 0.96621672, grad/param norm = 2.6774e-01, time/batch = 19.8184s	
17040/22750 (epoch 37.451), train_loss = 0.93236499, grad/param norm = 2.2497e-01, time/batch = 20.1811s	
17041/22750 (epoch 37.453), train_loss = 0.81237147, grad/param norm = 2.4658e-01, time/batch = 18.4374s	
17042/22750 (epoch 37.455), train_loss = 0.93902819, grad/param norm = 2.5770e-01, time/batch = 20.1054s	
17043/22750 (epoch 37.457), train_loss = 0.84448498, grad/param norm = 5.5497e-01, time/batch = 20.4107s	
17044/22750 (epoch 37.459), train_loss = 0.83366293, grad/param norm = 2.2252e-01, time/batch = 18.9991s	
17045/22750 (epoch 37.462), train_loss = 0.80744267, grad/param norm = 2.4577e-01, time/batch = 16.6071s	
17046/22750 (epoch 37.464), train_loss = 0.68335902, grad/param norm = 2.0751e-01, time/batch = 18.3200s	
17047/22750 (epoch 37.466), train_loss = 0.86089213, grad/param norm = 3.5362e-01, time/batch = 20.0019s	
17048/22750 (epoch 37.468), train_loss = 0.80621381, grad/param norm = 2.3633e-01, time/batch = 18.0055s	
17049/22750 (epoch 37.470), train_loss = 0.89535691, grad/param norm = 2.4512e-01, time/batch = 20.6592s	
17050/22750 (epoch 37.473), train_loss = 0.75485622, grad/param norm = 2.1214e-01, time/batch = 18.2152s	
17051/22750 (epoch 37.475), train_loss = 0.80061449, grad/param norm = 2.6996e-01, time/batch = 18.6785s	
17052/22750 (epoch 37.477), train_loss = 0.68766895, grad/param norm = 2.3757e-01, time/batch = 18.0007s	
17053/22750 (epoch 37.479), train_loss = 0.67287258, grad/param norm = 2.1091e-01, time/batch = 18.2503s	
17054/22750 (epoch 37.481), train_loss = 0.61835227, grad/param norm = 1.8319e-01, time/batch = 17.7408s	
17055/22750 (epoch 37.484), train_loss = 0.52915328, grad/param norm = 2.1803e-01, time/batch = 17.1591s	
17056/22750 (epoch 37.486), train_loss = 0.64579837, grad/param norm = 2.3952e-01, time/batch = 18.8949s	
17057/22750 (epoch 37.488), train_loss = 0.59348798, grad/param norm = 1.9999e-01, time/batch = 19.8139s	
17058/22750 (epoch 37.490), train_loss = 0.74735825, grad/param norm = 2.3129e-01, time/batch = 17.8263s	
17059/22750 (epoch 37.492), train_loss = 0.83292043, grad/param norm = 2.4900e-01, time/batch = 17.8533s	
17060/22750 (epoch 37.495), train_loss = 0.70099578, grad/param norm = 2.3222e-01, time/batch = 20.0254s	
17061/22750 (epoch 37.497), train_loss = 0.73954645, grad/param norm = 2.4273e-01, time/batch = 18.0956s	
17062/22750 (epoch 37.499), train_loss = 0.67940528, grad/param norm = 2.3635e-01, time/batch = 19.3327s	
17063/22750 (epoch 37.501), train_loss = 0.71623883, grad/param norm = 2.3760e-01, time/batch = 20.2401s	
17064/22750 (epoch 37.503), train_loss = 0.72679125, grad/param norm = 2.1974e-01, time/batch = 18.4977s	
17065/22750 (epoch 37.505), train_loss = 0.64787236, grad/param norm = 2.3339e-01, time/batch = 19.7490s	
17066/22750 (epoch 37.508), train_loss = 0.62108038, grad/param norm = 2.2131e-01, time/batch = 18.3435s	
17067/22750 (epoch 37.510), train_loss = 0.63185010, grad/param norm = 1.8652e-01, time/batch = 18.7624s	
17068/22750 (epoch 37.512), train_loss = 0.67350863, grad/param norm = 2.1533e-01, time/batch = 20.5190s	
17069/22750 (epoch 37.514), train_loss = 0.70577391, grad/param norm = 2.2845e-01, time/batch = 19.0406s	
17070/22750 (epoch 37.516), train_loss = 0.68731760, grad/param norm = 2.2522e-01, time/batch = 17.0278s	
17071/22750 (epoch 37.519), train_loss = 0.83252243, grad/param norm = 2.8019e-01, time/batch = 17.3998s	
17072/22750 (epoch 37.521), train_loss = 0.75588886, grad/param norm = 2.6979e-01, time/batch = 16.5128s	
17073/22750 (epoch 37.523), train_loss = 0.68527403, grad/param norm = 2.4609e-01, time/batch = 17.8962s	
17074/22750 (epoch 37.525), train_loss = 0.88015174, grad/param norm = 2.8383e-01, time/batch = 17.8367s	
17075/22750 (epoch 37.527), train_loss = 0.77060162, grad/param norm = 1.9817e-01, time/batch = 20.0776s	
17076/22750 (epoch 37.530), train_loss = 0.66820338, grad/param norm = 2.1123e-01, time/batch = 18.9489s	
17077/22750 (epoch 37.532), train_loss = 0.64338829, grad/param norm = 2.6500e-01, time/batch = 17.3426s	
17078/22750 (epoch 37.534), train_loss = 0.82254528, grad/param norm = 2.4646e-01, time/batch = 20.5310s	
17079/22750 (epoch 37.536), train_loss = 0.78177239, grad/param norm = 2.0189e-01, time/batch = 19.2520s	
17080/22750 (epoch 37.538), train_loss = 0.77255399, grad/param norm = 2.0895e-01, time/batch = 19.4926s	
17081/22750 (epoch 37.541), train_loss = 0.65838219, grad/param norm = 2.2686e-01, time/batch = 19.4907s	
17082/22750 (epoch 37.543), train_loss = 0.65361463, grad/param norm = 2.1371e-01, time/batch = 19.9927s	
17083/22750 (epoch 37.545), train_loss = 0.81609848, grad/param norm = 2.4669e-01, time/batch = 17.6504s	
17084/22750 (epoch 37.547), train_loss = 0.70262852, grad/param norm = 1.8746e-01, time/batch = 19.7593s	
17085/22750 (epoch 37.549), train_loss = 0.71927709, grad/param norm = 2.3491e-01, time/batch = 20.3591s	
17086/22750 (epoch 37.552), train_loss = 0.80996882, grad/param norm = 2.3274e-01, time/batch = 18.3409s	
17087/22750 (epoch 37.554), train_loss = 0.82227838, grad/param norm = 2.4975e-01, time/batch = 20.0987s	
17088/22750 (epoch 37.556), train_loss = 0.79072408, grad/param norm = 2.1617e-01, time/batch = 20.0761s	
17089/22750 (epoch 37.558), train_loss = 0.75495401, grad/param norm = 2.4121e-01, time/batch = 18.2393s	
17090/22750 (epoch 37.560), train_loss = 0.71448771, grad/param norm = 2.3247e-01, time/batch = 18.0718s	
17091/22750 (epoch 37.563), train_loss = 0.82883577, grad/param norm = 2.4756e-01, time/batch = 20.6486s	
17092/22750 (epoch 37.565), train_loss = 0.79077819, grad/param norm = 2.1944e-01, time/batch = 18.2441s	
17093/22750 (epoch 37.567), train_loss = 0.80076199, grad/param norm = 2.4434e-01, time/batch = 17.6989s	
17094/22750 (epoch 37.569), train_loss = 0.74043552, grad/param norm = 2.3070e-01, time/batch = 20.1935s	
17095/22750 (epoch 37.571), train_loss = 0.73255420, grad/param norm = 2.2183e-01, time/batch = 17.6856s	
17096/22750 (epoch 37.574), train_loss = 0.77221918, grad/param norm = 2.2246e-01, time/batch = 19.2510s	
17097/22750 (epoch 37.576), train_loss = 0.71940361, grad/param norm = 1.9378e-01, time/batch = 17.7480s	
17098/22750 (epoch 37.578), train_loss = 0.65098743, grad/param norm = 2.5139e-01, time/batch = 18.5498s	
17099/22750 (epoch 37.580), train_loss = 0.81449429, grad/param norm = 2.4444e-01, time/batch = 19.0719s	
17100/22750 (epoch 37.582), train_loss = 0.65735520, grad/param norm = 1.8935e-01, time/batch = 18.3286s	
17101/22750 (epoch 37.585), train_loss = 0.65370194, grad/param norm = 2.0449e-01, time/batch = 18.4239s	
17102/22750 (epoch 37.587), train_loss = 0.66375543, grad/param norm = 1.9749e-01, time/batch = 18.7645s	
17103/22750 (epoch 37.589), train_loss = 0.56075824, grad/param norm = 1.8714e-01, time/batch = 19.7834s	
17104/22750 (epoch 37.591), train_loss = 0.73785839, grad/param norm = 2.0972e-01, time/batch = 19.3307s	
17105/22750 (epoch 37.593), train_loss = 0.85930905, grad/param norm = 2.4445e-01, time/batch = 18.0916s	
17106/22750 (epoch 37.596), train_loss = 0.83140068, grad/param norm = 2.5711e-01, time/batch = 17.4971s	
17107/22750 (epoch 37.598), train_loss = 0.86448753, grad/param norm = 2.6370e-01, time/batch = 18.8411s	
17108/22750 (epoch 37.600), train_loss = 0.89738627, grad/param norm = 2.5701e-01, time/batch = 18.0726s	
17109/22750 (epoch 37.602), train_loss = 0.69560206, grad/param norm = 2.0910e-01, time/batch = 18.6501s	
17110/22750 (epoch 37.604), train_loss = 0.70692789, grad/param norm = 2.2369e-01, time/batch = 20.0917s	
17111/22750 (epoch 37.607), train_loss = 0.64942937, grad/param norm = 1.8401e-01, time/batch = 18.3656s	
17112/22750 (epoch 37.609), train_loss = 0.62821618, grad/param norm = 2.1404e-01, time/batch = 19.5193s	
17113/22750 (epoch 37.611), train_loss = 0.70422592, grad/param norm = 2.2325e-01, time/batch = 18.2756s	
17114/22750 (epoch 37.613), train_loss = 0.68508274, grad/param norm = 2.1316e-01, time/batch = 18.9130s	
17115/22750 (epoch 37.615), train_loss = 0.69105275, grad/param norm = 1.9088e-01, time/batch = 16.7420s	
17116/22750 (epoch 37.618), train_loss = 0.73259209, grad/param norm = 2.2722e-01, time/batch = 17.3139s	
17117/22750 (epoch 37.620), train_loss = 0.73222407, grad/param norm = 2.3863e-01, time/batch = 16.9940s	
17118/22750 (epoch 37.622), train_loss = 0.61606226, grad/param norm = 1.8376e-01, time/batch = 16.5891s	
17119/22750 (epoch 37.624), train_loss = 0.70511700, grad/param norm = 2.2600e-01, time/batch = 19.0025s	
17120/22750 (epoch 37.626), train_loss = 0.60826909, grad/param norm = 2.1829e-01, time/batch = 18.4343s	
17121/22750 (epoch 37.629), train_loss = 0.69066216, grad/param norm = 2.1890e-01, time/batch = 19.0991s	
17122/22750 (epoch 37.631), train_loss = 0.72910750, grad/param norm = 2.0173e-01, time/batch = 19.3452s	
17123/22750 (epoch 37.633), train_loss = 0.61900582, grad/param norm = 2.0815e-01, time/batch = 18.4111s	
17124/22750 (epoch 37.635), train_loss = 0.72680234, grad/param norm = 2.1019e-01, time/batch = 19.1584s	
17125/22750 (epoch 37.637), train_loss = 0.77867742, grad/param norm = 2.6029e-01, time/batch = 17.1623s	
17126/22750 (epoch 37.640), train_loss = 0.80716667, grad/param norm = 2.4888e-01, time/batch = 19.0936s	
17127/22750 (epoch 37.642), train_loss = 0.82986406, grad/param norm = 2.2712e-01, time/batch = 18.9090s	
17128/22750 (epoch 37.644), train_loss = 0.74561889, grad/param norm = 3.0537e-01, time/batch = 18.5186s	
17129/22750 (epoch 37.646), train_loss = 0.80468743, grad/param norm = 2.5178e-01, time/batch = 20.2748s	
17130/22750 (epoch 37.648), train_loss = 0.78340509, grad/param norm = 2.3569e-01, time/batch = 20.1948s	
17131/22750 (epoch 37.651), train_loss = 0.80765962, grad/param norm = 2.4940e-01, time/batch = 16.7619s	
17132/22750 (epoch 37.653), train_loss = 0.82211739, grad/param norm = 2.2502e-01, time/batch = 18.4888s	
17133/22750 (epoch 37.655), train_loss = 0.76436632, grad/param norm = 2.1317e-01, time/batch = 19.3419s	
17134/22750 (epoch 37.657), train_loss = 0.87796552, grad/param norm = 2.4423e-01, time/batch = 17.4993s	
17135/22750 (epoch 37.659), train_loss = 0.91973775, grad/param norm = 2.2969e-01, time/batch = 18.3492s	
17136/22750 (epoch 37.662), train_loss = 0.90264186, grad/param norm = 2.7890e-01, time/batch = 18.7294s	
17137/22750 (epoch 37.664), train_loss = 0.81341233, grad/param norm = 2.6271e-01, time/batch = 19.0804s	
17138/22750 (epoch 37.666), train_loss = 0.64662433, grad/param norm = 2.1375e-01, time/batch = 19.4372s	
17139/22750 (epoch 37.668), train_loss = 0.73900741, grad/param norm = 2.1885e-01, time/batch = 19.9321s	
17140/22750 (epoch 37.670), train_loss = 0.71832103, grad/param norm = 2.1642e-01, time/batch = 16.7709s	
17141/22750 (epoch 37.673), train_loss = 0.91513253, grad/param norm = 2.6132e-01, time/batch = 17.0988s	
17142/22750 (epoch 37.675), train_loss = 1.04514806, grad/param norm = 3.1147e-01, time/batch = 19.0118s	
17143/22750 (epoch 37.677), train_loss = 0.89498300, grad/param norm = 2.5040e-01, time/batch = 18.4204s	
17144/22750 (epoch 37.679), train_loss = 0.89885189, grad/param norm = 2.8438e-01, time/batch = 17.3467s	
17145/22750 (epoch 37.681), train_loss = 0.90884363, grad/param norm = 2.5896e-01, time/batch = 18.4207s	
17146/22750 (epoch 37.684), train_loss = 0.92306942, grad/param norm = 2.5342e-01, time/batch = 19.0619s	
17147/22750 (epoch 37.686), train_loss = 0.94433172, grad/param norm = 2.5368e-01, time/batch = 18.8403s	
17148/22750 (epoch 37.688), train_loss = 0.89084602, grad/param norm = 2.4426e-01, time/batch = 19.9408s	
17149/22750 (epoch 37.690), train_loss = 0.89608886, grad/param norm = 2.4185e-01, time/batch = 18.6935s	
17150/22750 (epoch 37.692), train_loss = 0.88715394, grad/param norm = 2.4924e-01, time/batch = 17.9302s	
17151/22750 (epoch 37.695), train_loss = 0.78053828, grad/param norm = 2.1807e-01, time/batch = 20.1627s	
17152/22750 (epoch 37.697), train_loss = 0.79574035, grad/param norm = 2.2716e-01, time/batch = 19.2596s	
17153/22750 (epoch 37.699), train_loss = 0.72233866, grad/param norm = 2.0407e-01, time/batch = 17.2526s	
17154/22750 (epoch 37.701), train_loss = 0.65971132, grad/param norm = 2.4210e-01, time/batch = 16.0936s	
17155/22750 (epoch 37.703), train_loss = 0.73666048, grad/param norm = 2.2546e-01, time/batch = 15.7707s	
17156/22750 (epoch 37.705), train_loss = 0.72491317, grad/param norm = 2.3656e-01, time/batch = 17.4654s	
17157/22750 (epoch 37.708), train_loss = 0.79535631, grad/param norm = 2.6478e-01, time/batch = 18.1840s	
17158/22750 (epoch 37.710), train_loss = 0.68649429, grad/param norm = 2.3835e-01, time/batch = 20.6070s	
17159/22750 (epoch 37.712), train_loss = 0.62237522, grad/param norm = 2.3479e-01, time/batch = 18.5711s	
17160/22750 (epoch 37.714), train_loss = 0.63543515, grad/param norm = 2.0801e-01, time/batch = 17.5089s	
17161/22750 (epoch 37.716), train_loss = 0.66372812, grad/param norm = 2.1917e-01, time/batch = 19.7298s	
17162/22750 (epoch 37.719), train_loss = 0.73009286, grad/param norm = 2.9411e-01, time/batch = 19.9938s	
17163/22750 (epoch 37.721), train_loss = 0.84852049, grad/param norm = 2.3273e-01, time/batch = 29.6573s	
17164/22750 (epoch 37.723), train_loss = 0.82741427, grad/param norm = 2.5740e-01, time/batch = 22.2361s	
17165/22750 (epoch 37.725), train_loss = 0.73004196, grad/param norm = 2.5194e-01, time/batch = 20.0901s	
17166/22750 (epoch 37.727), train_loss = 0.75231661, grad/param norm = 2.4556e-01, time/batch = 19.9207s	
17167/22750 (epoch 37.730), train_loss = 0.72212892, grad/param norm = 2.1923e-01, time/batch = 19.1468s	
17168/22750 (epoch 37.732), train_loss = 0.69160739, grad/param norm = 2.0551e-01, time/batch = 18.1769s	
17169/22750 (epoch 37.734), train_loss = 0.62783212, grad/param norm = 1.9367e-01, time/batch = 17.8373s	
17170/22750 (epoch 37.736), train_loss = 0.72021612, grad/param norm = 2.2972e-01, time/batch = 17.5170s	
17171/22750 (epoch 37.738), train_loss = 0.80836554, grad/param norm = 2.4159e-01, time/batch = 16.6710s	
17172/22750 (epoch 37.741), train_loss = 0.88812553, grad/param norm = 2.3230e-01, time/batch = 16.7704s	
17173/22750 (epoch 37.743), train_loss = 0.77416140, grad/param norm = 2.2575e-01, time/batch = 16.8787s	
17174/22750 (epoch 37.745), train_loss = 0.63364068, grad/param norm = 1.9171e-01, time/batch = 16.0716s	
17175/22750 (epoch 37.747), train_loss = 0.75314164, grad/param norm = 1.9771e-01, time/batch = 16.0349s	
17176/22750 (epoch 37.749), train_loss = 0.86200083, grad/param norm = 2.6136e-01, time/batch = 16.5301s	
17177/22750 (epoch 37.752), train_loss = 0.77541979, grad/param norm = 2.7279e-01, time/batch = 15.9522s	
17178/22750 (epoch 37.754), train_loss = 0.76294421, grad/param norm = 2.2293e-01, time/batch = 15.6213s	
17179/22750 (epoch 37.756), train_loss = 0.71716645, grad/param norm = 2.6037e-01, time/batch = 16.7160s	
17180/22750 (epoch 37.758), train_loss = 0.67922420, grad/param norm = 2.2726e-01, time/batch = 16.6380s	
17181/22750 (epoch 37.760), train_loss = 0.67917327, grad/param norm = 2.0760e-01, time/batch = 16.6588s	
17182/22750 (epoch 37.763), train_loss = 0.76196763, grad/param norm = 2.3300e-01, time/batch = 16.7524s	
17183/22750 (epoch 37.765), train_loss = 0.73724452, grad/param norm = 2.2999e-01, time/batch = 16.7388s	
17184/22750 (epoch 37.767), train_loss = 0.78701234, grad/param norm = 2.0744e-01, time/batch = 17.0197s	
17185/22750 (epoch 37.769), train_loss = 0.87352582, grad/param norm = 2.4477e-01, time/batch = 16.9511s	
17186/22750 (epoch 37.771), train_loss = 0.91037541, grad/param norm = 2.6084e-01, time/batch = 17.6165s	
17187/22750 (epoch 37.774), train_loss = 0.71731999, grad/param norm = 2.6654e-01, time/batch = 16.7549s	
17188/22750 (epoch 37.776), train_loss = 0.85021500, grad/param norm = 2.5393e-01, time/batch = 16.0247s	
17189/22750 (epoch 37.778), train_loss = 0.89684689, grad/param norm = 2.5526e-01, time/batch = 15.9333s	
17190/22750 (epoch 37.780), train_loss = 0.79119065, grad/param norm = 2.3641e-01, time/batch = 16.1759s	
17191/22750 (epoch 37.782), train_loss = 0.89544320, grad/param norm = 2.3452e-01, time/batch = 16.0021s	
17192/22750 (epoch 37.785), train_loss = 0.75272295, grad/param norm = 2.5225e-01, time/batch = 15.9210s	
17193/22750 (epoch 37.787), train_loss = 0.65877105, grad/param norm = 2.4434e-01, time/batch = 15.6919s	
17194/22750 (epoch 37.789), train_loss = 0.75047436, grad/param norm = 2.2929e-01, time/batch = 15.9214s	
17195/22750 (epoch 37.791), train_loss = 0.72495103, grad/param norm = 2.2719e-01, time/batch = 15.2970s	
17196/22750 (epoch 37.793), train_loss = 0.70492448, grad/param norm = 2.8030e-01, time/batch = 15.6305s	
17197/22750 (epoch 37.796), train_loss = 0.64978808, grad/param norm = 2.1713e-01, time/batch = 16.2599s	
17198/22750 (epoch 37.798), train_loss = 0.70588196, grad/param norm = 2.2604e-01, time/batch = 15.7613s	
17199/22750 (epoch 37.800), train_loss = 0.68366885, grad/param norm = 2.5386e-01, time/batch = 15.6792s	
17200/22750 (epoch 37.802), train_loss = 0.63312298, grad/param norm = 2.2702e-01, time/batch = 18.2389s	
17201/22750 (epoch 37.804), train_loss = 0.81538444, grad/param norm = 2.0536e-01, time/batch = 17.8379s	
17202/22750 (epoch 37.807), train_loss = 0.79487095, grad/param norm = 2.6292e-01, time/batch = 19.8229s	
17203/22750 (epoch 37.809), train_loss = 0.88641499, grad/param norm = 2.5068e-01, time/batch = 18.8384s	
17204/22750 (epoch 37.811), train_loss = 0.76691546, grad/param norm = 2.5814e-01, time/batch = 17.6894s	
17205/22750 (epoch 37.813), train_loss = 0.78478560, grad/param norm = 2.1188e-01, time/batch = 17.9317s	
17206/22750 (epoch 37.815), train_loss = 0.88836135, grad/param norm = 2.2954e-01, time/batch = 20.4514s	
17207/22750 (epoch 37.818), train_loss = 0.83818400, grad/param norm = 2.1394e-01, time/batch = 18.6617s	
17208/22750 (epoch 37.820), train_loss = 0.96207442, grad/param norm = 2.4791e-01, time/batch = 17.3303s	
17209/22750 (epoch 37.822), train_loss = 0.79820901, grad/param norm = 2.1629e-01, time/batch = 18.7437s	
17210/22750 (epoch 37.824), train_loss = 0.66334244, grad/param norm = 1.9585e-01, time/batch = 19.4931s	
17211/22750 (epoch 37.826), train_loss = 0.77635886, grad/param norm = 2.5877e-01, time/batch = 17.4236s	
17212/22750 (epoch 37.829), train_loss = 0.87136294, grad/param norm = 2.5392e-01, time/batch = 19.7449s	
17213/22750 (epoch 37.831), train_loss = 0.84761483, grad/param norm = 2.6613e-01, time/batch = 20.6953s	
17214/22750 (epoch 37.833), train_loss = 0.79651441, grad/param norm = 2.4787e-01, time/batch = 18.5910s	
17215/22750 (epoch 37.835), train_loss = 0.67656078, grad/param norm = 2.4933e-01, time/batch = 19.8573s	
17216/22750 (epoch 37.837), train_loss = 0.74181951, grad/param norm = 2.3681e-01, time/batch = 19.5982s	
17217/22750 (epoch 37.840), train_loss = 0.68710945, grad/param norm = 2.0503e-01, time/batch = 18.4196s	
17218/22750 (epoch 37.842), train_loss = 0.70863210, grad/param norm = 2.3922e-01, time/batch = 18.6678s	
17219/22750 (epoch 37.844), train_loss = 0.79015321, grad/param norm = 2.6401e-01, time/batch = 17.8363s	
17220/22750 (epoch 37.846), train_loss = 0.80513578, grad/param norm = 2.0885e-01, time/batch = 17.0091s	
17221/22750 (epoch 37.848), train_loss = 0.70323737, grad/param norm = 2.1777e-01, time/batch = 19.4113s	
17222/22750 (epoch 37.851), train_loss = 0.69600111, grad/param norm = 2.3981e-01, time/batch = 18.7119s	
17223/22750 (epoch 37.853), train_loss = 0.87734174, grad/param norm = 2.3626e-01, time/batch = 18.9492s	
17224/22750 (epoch 37.855), train_loss = 0.71919027, grad/param norm = 1.8995e-01, time/batch = 17.9455s	
17225/22750 (epoch 37.857), train_loss = 0.81366077, grad/param norm = 2.1135e-01, time/batch = 19.1781s	
17226/22750 (epoch 37.859), train_loss = 0.79736846, grad/param norm = 2.8252e-01, time/batch = 17.6814s	
17227/22750 (epoch 37.862), train_loss = 0.93544953, grad/param norm = 2.5815e-01, time/batch = 17.7566s	
17228/22750 (epoch 37.864), train_loss = 0.77573473, grad/param norm = 2.3280e-01, time/batch = 17.2676s	
17229/22750 (epoch 37.866), train_loss = 0.81512557, grad/param norm = 2.1646e-01, time/batch = 17.2612s	
17230/22750 (epoch 37.868), train_loss = 0.69554391, grad/param norm = 2.1949e-01, time/batch = 17.8200s	
17231/22750 (epoch 37.870), train_loss = 0.66371065, grad/param norm = 2.3535e-01, time/batch = 21.3308s	
17232/22750 (epoch 37.873), train_loss = 0.75168157, grad/param norm = 2.0355e-01, time/batch = 19.2859s	
17233/22750 (epoch 37.875), train_loss = 0.80895507, grad/param norm = 2.2910e-01, time/batch = 19.5220s	
17234/22750 (epoch 37.877), train_loss = 0.70956295, grad/param norm = 2.3207e-01, time/batch = 19.0240s	
17235/22750 (epoch 37.879), train_loss = 0.84436390, grad/param norm = 2.2875e-01, time/batch = 18.3499s	
17236/22750 (epoch 37.881), train_loss = 0.79849776, grad/param norm = 2.4080e-01, time/batch = 18.1854s	
17237/22750 (epoch 37.884), train_loss = 0.68512675, grad/param norm = 1.8707e-01, time/batch = 18.9200s	
17238/22750 (epoch 37.886), train_loss = 0.79727351, grad/param norm = 2.2696e-01, time/batch = 19.0912s	
17239/22750 (epoch 37.888), train_loss = 0.81390964, grad/param norm = 2.0596e-01, time/batch = 18.9990s	
17240/22750 (epoch 37.890), train_loss = 0.81724449, grad/param norm = 2.3596e-01, time/batch = 18.4406s	
17241/22750 (epoch 37.892), train_loss = 1.02955530, grad/param norm = 2.8285e-01, time/batch = 19.9416s	
17242/22750 (epoch 37.895), train_loss = 0.73728293, grad/param norm = 2.4277e-01, time/batch = 17.3429s	
17243/22750 (epoch 37.897), train_loss = 0.86483537, grad/param norm = 2.4737e-01, time/batch = 17.6846s	
17244/22750 (epoch 37.899), train_loss = 0.80011324, grad/param norm = 2.4077e-01, time/batch = 20.3973s	
17245/22750 (epoch 37.901), train_loss = 0.84921259, grad/param norm = 2.7194e-01, time/batch = 16.7825s	
17246/22750 (epoch 37.903), train_loss = 0.76208400, grad/param norm = 2.4290e-01, time/batch = 18.3146s	
17247/22750 (epoch 37.905), train_loss = 0.83409009, grad/param norm = 2.2458e-01, time/batch = 17.7361s	
17248/22750 (epoch 37.908), train_loss = 0.65569361, grad/param norm = 2.2169e-01, time/batch = 18.1896s	
17249/22750 (epoch 37.910), train_loss = 0.58637157, grad/param norm = 2.0065e-01, time/batch = 19.2932s	
17250/22750 (epoch 37.912), train_loss = 0.74584795, grad/param norm = 2.1299e-01, time/batch = 19.5313s	
17251/22750 (epoch 37.914), train_loss = 0.76429787, grad/param norm = 2.3033e-01, time/batch = 20.6935s	
17252/22750 (epoch 37.916), train_loss = 0.61705030, grad/param norm = 2.1341e-01, time/batch = 18.0803s	
17253/22750 (epoch 37.919), train_loss = 0.75509214, grad/param norm = 2.3637e-01, time/batch = 17.4924s	
17254/22750 (epoch 37.921), train_loss = 0.59687812, grad/param norm = 1.9973e-01, time/batch = 19.6680s	
17255/22750 (epoch 37.923), train_loss = 0.68952515, grad/param norm = 2.2183e-01, time/batch = 19.7419s	
17256/22750 (epoch 37.925), train_loss = 0.75697007, grad/param norm = 2.2026e-01, time/batch = 18.0098s	
17257/22750 (epoch 37.927), train_loss = 0.60902304, grad/param norm = 2.2464e-01, time/batch = 17.7749s	
17258/22750 (epoch 37.930), train_loss = 0.57299831, grad/param norm = 2.0261e-01, time/batch = 19.9362s	
17259/22750 (epoch 37.932), train_loss = 0.73437142, grad/param norm = 2.1757e-01, time/batch = 17.3770s	
17260/22750 (epoch 37.934), train_loss = 0.62114003, grad/param norm = 1.7853e-01, time/batch = 18.9436s	
17261/22750 (epoch 37.936), train_loss = 0.85651984, grad/param norm = 2.3148e-01, time/batch = 18.4287s	
17262/22750 (epoch 37.938), train_loss = 0.84408558, grad/param norm = 2.2214e-01, time/batch = 17.0718s	
17263/22750 (epoch 37.941), train_loss = 0.89194116, grad/param norm = 2.8017e-01, time/batch = 18.2574s	
17264/22750 (epoch 37.943), train_loss = 0.77887075, grad/param norm = 2.2660e-01, time/batch = 16.1892s	
17265/22750 (epoch 37.945), train_loss = 0.78901218, grad/param norm = 2.4498e-01, time/batch = 17.0881s	
17266/22750 (epoch 37.947), train_loss = 0.71869860, grad/param norm = 2.5034e-01, time/batch = 17.1894s	
17267/22750 (epoch 37.949), train_loss = 0.71126132, grad/param norm = 2.1676e-01, time/batch = 20.2727s	
17268/22750 (epoch 37.952), train_loss = 0.72267092, grad/param norm = 2.1776e-01, time/batch = 18.3523s	
17269/22750 (epoch 37.954), train_loss = 0.65265117, grad/param norm = 1.9734e-01, time/batch = 19.0945s	
17270/22750 (epoch 37.956), train_loss = 0.81617403, grad/param norm = 2.1512e-01, time/batch = 20.4207s	
17271/22750 (epoch 37.958), train_loss = 0.66588188, grad/param norm = 1.7710e-01, time/batch = 19.0108s	
17272/22750 (epoch 37.960), train_loss = 0.66677720, grad/param norm = 2.5414e-01, time/batch = 17.4877s	
17273/22750 (epoch 37.963), train_loss = 0.77374062, grad/param norm = 2.1746e-01, time/batch = 16.6623s	
17274/22750 (epoch 37.965), train_loss = 0.83146060, grad/param norm = 2.1329e-01, time/batch = 18.1735s	
17275/22750 (epoch 37.967), train_loss = 0.80224893, grad/param norm = 2.2108e-01, time/batch = 16.2372s	
17276/22750 (epoch 37.969), train_loss = 0.73656132, grad/param norm = 2.9950e-01, time/batch = 16.0606s	
17277/22750 (epoch 37.971), train_loss = 0.70216315, grad/param norm = 1.9969e-01, time/batch = 20.6830s	
17278/22750 (epoch 37.974), train_loss = 0.68677891, grad/param norm = 2.0943e-01, time/batch = 19.5049s	
17279/22750 (epoch 37.976), train_loss = 0.73860571, grad/param norm = 2.8812e-01, time/batch = 18.4298s	
17280/22750 (epoch 37.978), train_loss = 0.71370239, grad/param norm = 2.4136e-01, time/batch = 19.2458s	
17281/22750 (epoch 37.980), train_loss = 0.86593329, grad/param norm = 2.5694e-01, time/batch = 19.0842s	
17282/22750 (epoch 37.982), train_loss = 0.70048097, grad/param norm = 2.0349e-01, time/batch = 17.6593s	
17283/22750 (epoch 37.985), train_loss = 0.89088751, grad/param norm = 2.3043e-01, time/batch = 19.3239s	
17284/22750 (epoch 37.987), train_loss = 0.63450589, grad/param norm = 2.0921e-01, time/batch = 19.3258s	
17285/22750 (epoch 37.989), train_loss = 0.70144928, grad/param norm = 2.6163e-01, time/batch = 17.7695s	
17286/22750 (epoch 37.991), train_loss = 0.78436326, grad/param norm = 2.2444e-01, time/batch = 20.3671s	
17287/22750 (epoch 37.993), train_loss = 0.75763157, grad/param norm = 2.6172e-01, time/batch = 20.1240s	
17288/22750 (epoch 37.996), train_loss = 0.66823135, grad/param norm = 2.5552e-01, time/batch = 17.3192s	
17289/22750 (epoch 37.998), train_loss = 0.84833418, grad/param norm = 2.5163e-01, time/batch = 18.5773s	
decayed learning rate by a factor 0.97 to 0.00082681869802713	
17290/22750 (epoch 38.000), train_loss = 0.74376318, grad/param norm = 2.2805e-01, time/batch = 16.9274s	
17291/22750 (epoch 38.002), train_loss = 0.90117641, grad/param norm = 2.3829e-01, time/batch = 16.9037s	
17292/22750 (epoch 38.004), train_loss = 0.71551614, grad/param norm = 2.1892e-01, time/batch = 19.1647s	
17293/22750 (epoch 38.007), train_loss = 0.71630951, grad/param norm = 2.4598e-01, time/batch = 18.1634s	
17294/22750 (epoch 38.009), train_loss = 0.89670609, grad/param norm = 2.7456e-01, time/batch = 17.1588s	
17295/22750 (epoch 38.011), train_loss = 0.93175942, grad/param norm = 2.6123e-01, time/batch = 20.4160s	
17296/22750 (epoch 38.013), train_loss = 0.87575362, grad/param norm = 2.5026e-01, time/batch = 17.3677s	
17297/22750 (epoch 38.015), train_loss = 0.78517591, grad/param norm = 2.4305e-01, time/batch = 17.1001s	
17298/22750 (epoch 38.018), train_loss = 0.86148400, grad/param norm = 2.5933e-01, time/batch = 16.9101s	
17299/22750 (epoch 38.020), train_loss = 0.91059695, grad/param norm = 2.5940e-01, time/batch = 20.0597s	
17300/22750 (epoch 38.022), train_loss = 0.77313528, grad/param norm = 2.6348e-01, time/batch = 17.8276s	
17301/22750 (epoch 38.024), train_loss = 0.78427599, grad/param norm = 2.8336e-01, time/batch = 18.4160s	
17302/22750 (epoch 38.026), train_loss = 0.83357835, grad/param norm = 3.1387e-01, time/batch = 18.3432s	
17303/22750 (epoch 38.029), train_loss = 0.63556700, grad/param norm = 2.3063e-01, time/batch = 18.2658s	
17304/22750 (epoch 38.031), train_loss = 0.98178284, grad/param norm = 2.4006e-01, time/batch = 18.5253s	
17305/22750 (epoch 38.033), train_loss = 0.77438784, grad/param norm = 2.3272e-01, time/batch = 18.6874s	
17306/22750 (epoch 38.035), train_loss = 0.82371564, grad/param norm = 2.3129e-01, time/batch = 19.0423s	
17307/22750 (epoch 38.037), train_loss = 0.86462086, grad/param norm = 2.4892e-01, time/batch = 18.7691s	
17308/22750 (epoch 38.040), train_loss = 0.76175352, grad/param norm = 2.1809e-01, time/batch = 18.5938s	
17309/22750 (epoch 38.042), train_loss = 0.79797682, grad/param norm = 2.1085e-01, time/batch = 20.8280s	
17310/22750 (epoch 38.044), train_loss = 0.76597271, grad/param norm = 2.3433e-01, time/batch = 18.4178s	
17311/22750 (epoch 38.046), train_loss = 0.84942516, grad/param norm = 2.4047e-01, time/batch = 4.3969s	
17312/22750 (epoch 38.048), train_loss = 0.76827310, grad/param norm = 2.2124e-01, time/batch = 0.7167s	
17313/22750 (epoch 38.051), train_loss = 0.76312271, grad/param norm = 2.0994e-01, time/batch = 0.7004s	
17314/22750 (epoch 38.053), train_loss = 0.75727222, grad/param norm = 2.1519e-01, time/batch = 0.6975s	
17315/22750 (epoch 38.055), train_loss = 0.66361606, grad/param norm = 2.1205e-01, time/batch = 0.6943s	
17316/22750 (epoch 38.057), train_loss = 0.91386562, grad/param norm = 2.6091e-01, time/batch = 0.6983s	
17317/22750 (epoch 38.059), train_loss = 0.57392460, grad/param norm = 2.0749e-01, time/batch = 0.7010s	
17318/22750 (epoch 38.062), train_loss = 0.65618715, grad/param norm = 1.9929e-01, time/batch = 0.9282s	
17319/22750 (epoch 38.064), train_loss = 0.87477062, grad/param norm = 2.4229e-01, time/batch = 1.0231s	
17320/22750 (epoch 38.066), train_loss = 0.68939889, grad/param norm = 2.1030e-01, time/batch = 1.0446s	
17321/22750 (epoch 38.068), train_loss = 0.69068346, grad/param norm = 2.0951e-01, time/batch = 1.0252s	
17322/22750 (epoch 38.070), train_loss = 0.58276487, grad/param norm = 1.8572e-01, time/batch = 1.0154s	
17323/22750 (epoch 38.073), train_loss = 0.72114127, grad/param norm = 2.4994e-01, time/batch = 1.7981s	
17324/22750 (epoch 38.075), train_loss = 0.75268346, grad/param norm = 2.0465e-01, time/batch = 1.9208s	
17325/22750 (epoch 38.077), train_loss = 0.55936624, grad/param norm = 1.9999e-01, time/batch = 6.2704s	
17326/22750 (epoch 38.079), train_loss = 0.74265934, grad/param norm = 2.3233e-01, time/batch = 18.7548s	
17327/22750 (epoch 38.081), train_loss = 0.70024894, grad/param norm = 2.0366e-01, time/batch = 19.0279s	
17328/22750 (epoch 38.084), train_loss = 0.71984419, grad/param norm = 2.1822e-01, time/batch = 18.6243s	
17329/22750 (epoch 38.086), train_loss = 0.74403159, grad/param norm = 2.0957e-01, time/batch = 19.2522s	
17330/22750 (epoch 38.088), train_loss = 0.70933968, grad/param norm = 2.1648e-01, time/batch = 18.8977s	
17331/22750 (epoch 38.090), train_loss = 0.71574888, grad/param norm = 2.2415e-01, time/batch = 17.1657s	
17332/22750 (epoch 38.092), train_loss = 0.82603023, grad/param norm = 2.3272e-01, time/batch = 19.0964s	
17333/22750 (epoch 38.095), train_loss = 0.69630478, grad/param norm = 2.4484e-01, time/batch = 18.3525s	
17334/22750 (epoch 38.097), train_loss = 0.75276990, grad/param norm = 2.2843e-01, time/batch = 17.5046s	
17335/22750 (epoch 38.099), train_loss = 0.68331447, grad/param norm = 2.0742e-01, time/batch = 19.9816s	
17336/22750 (epoch 38.101), train_loss = 0.62764257, grad/param norm = 2.1691e-01, time/batch = 19.9367s	
17337/22750 (epoch 38.103), train_loss = 0.81292844, grad/param norm = 2.8696e-01, time/batch = 18.1963s	
17338/22750 (epoch 38.105), train_loss = 0.87900916, grad/param norm = 2.8931e-01, time/batch = 20.1108s	
17339/22750 (epoch 38.108), train_loss = 0.78915900, grad/param norm = 2.3569e-01, time/batch = 18.9215s	
17340/22750 (epoch 38.110), train_loss = 0.84087562, grad/param norm = 2.3094e-01, time/batch = 19.4071s	
17341/22750 (epoch 38.112), train_loss = 0.63689906, grad/param norm = 1.8172e-01, time/batch = 18.5041s	
17342/22750 (epoch 38.114), train_loss = 0.55976470, grad/param norm = 2.0400e-01, time/batch = 18.3345s	
17343/22750 (epoch 38.116), train_loss = 0.76707467, grad/param norm = 2.4756e-01, time/batch = 18.0001s	
17344/22750 (epoch 38.119), train_loss = 0.70834015, grad/param norm = 1.9291e-01, time/batch = 19.5862s	
17345/22750 (epoch 38.121), train_loss = 0.71992102, grad/param norm = 2.4802e-01, time/batch = 18.6856s	
17346/22750 (epoch 38.123), train_loss = 0.65324224, grad/param norm = 2.4317e-01, time/batch = 19.4507s	
17347/22750 (epoch 38.125), train_loss = 0.86675469, grad/param norm = 2.1921e-01, time/batch = 18.7011s	
17348/22750 (epoch 38.127), train_loss = 0.71742625, grad/param norm = 2.3169e-01, time/batch = 20.0012s	
17349/22750 (epoch 38.130), train_loss = 0.71628280, grad/param norm = 1.9511e-01, time/batch = 18.9965s	
17350/22750 (epoch 38.132), train_loss = 0.69657331, grad/param norm = 2.2075e-01, time/batch = 18.1743s	
17351/22750 (epoch 38.134), train_loss = 0.70380581, grad/param norm = 1.9660e-01, time/batch = 15.8665s	
17352/22750 (epoch 38.136), train_loss = 0.59866690, grad/param norm = 2.4374e-01, time/batch = 18.7539s	
17353/22750 (epoch 38.138), train_loss = 0.80920477, grad/param norm = 2.3744e-01, time/batch = 19.3235s	
17354/22750 (epoch 38.141), train_loss = 0.74524169, grad/param norm = 2.2636e-01, time/batch = 19.5331s	
17355/22750 (epoch 38.143), train_loss = 0.69031544, grad/param norm = 2.0790e-01, time/batch = 20.4381s	
17356/22750 (epoch 38.145), train_loss = 0.85568443, grad/param norm = 2.3344e-01, time/batch = 18.2579s	
17357/22750 (epoch 38.147), train_loss = 0.90135109, grad/param norm = 2.4888e-01, time/batch = 18.8311s	
17358/22750 (epoch 38.149), train_loss = 0.73989021, grad/param norm = 2.0428e-01, time/batch = 18.0163s	
17359/22750 (epoch 38.152), train_loss = 0.73120891, grad/param norm = 1.9344e-01, time/batch = 18.5011s	
17360/22750 (epoch 38.154), train_loss = 0.68868934, grad/param norm = 2.2559e-01, time/batch = 16.9393s	
17361/22750 (epoch 38.156), train_loss = 0.66928648, grad/param norm = 1.9942e-01, time/batch = 18.3897s	
17362/22750 (epoch 38.158), train_loss = 0.65744950, grad/param norm = 2.1964e-01, time/batch = 19.0908s	
17363/22750 (epoch 38.160), train_loss = 0.74426594, grad/param norm = 2.4203e-01, time/batch = 19.0173s	
17364/22750 (epoch 38.163), train_loss = 0.88600919, grad/param norm = 2.3794e-01, time/batch = 20.2708s	
17365/22750 (epoch 38.165), train_loss = 0.80577507, grad/param norm = 2.2385e-01, time/batch = 19.9377s	
17366/22750 (epoch 38.167), train_loss = 0.68204794, grad/param norm = 2.0911e-01, time/batch = 17.7613s	
17367/22750 (epoch 38.169), train_loss = 0.73836468, grad/param norm = 2.2178e-01, time/batch = 20.2359s	
17368/22750 (epoch 38.171), train_loss = 0.63936113, grad/param norm = 1.9030e-01, time/batch = 19.2461s	
17369/22750 (epoch 38.174), train_loss = 0.62413189, grad/param norm = 2.3749e-01, time/batch = 17.6744s	
17370/22750 (epoch 38.176), train_loss = 0.65184671, grad/param norm = 2.1001e-01, time/batch = 19.8221s	
17371/22750 (epoch 38.178), train_loss = 0.68487476, grad/param norm = 2.0194e-01, time/batch = 20.1054s	
17372/22750 (epoch 38.180), train_loss = 0.83946119, grad/param norm = 2.9029e-01, time/batch = 33.5620s	
17373/22750 (epoch 38.182), train_loss = 0.79113484, grad/param norm = 2.3396e-01, time/batch = 19.5930s	
17374/22750 (epoch 38.185), train_loss = 0.81830285, grad/param norm = 2.3139e-01, time/batch = 16.9867s	
17375/22750 (epoch 38.187), train_loss = 0.64301783, grad/param norm = 1.9936e-01, time/batch = 16.4952s	
17376/22750 (epoch 38.189), train_loss = 0.64560254, grad/param norm = 2.2758e-01, time/batch = 16.4903s	
17377/22750 (epoch 38.191), train_loss = 0.69524413, grad/param norm = 1.9984e-01, time/batch = 17.5974s	
17378/22750 (epoch 38.193), train_loss = 0.79572513, grad/param norm = 2.1938e-01, time/batch = 16.4165s	
17379/22750 (epoch 38.196), train_loss = 0.73061766, grad/param norm = 2.3188e-01, time/batch = 19.6786s	
17380/22750 (epoch 38.198), train_loss = 0.54763773, grad/param norm = 1.9564e-01, time/batch = 21.1767s	
17381/22750 (epoch 38.200), train_loss = 0.73707904, grad/param norm = 2.1494e-01, time/batch = 18.5125s	
17382/22750 (epoch 38.202), train_loss = 0.82370017, grad/param norm = 3.1942e-01, time/batch = 19.2553s	
17383/22750 (epoch 38.204), train_loss = 0.76384904, grad/param norm = 2.0939e-01, time/batch = 16.3658s	
17384/22750 (epoch 38.207), train_loss = 0.75586534, grad/param norm = 2.2446e-01, time/batch = 17.5059s	
17385/22750 (epoch 38.209), train_loss = 0.71180551, grad/param norm = 2.3296e-01, time/batch = 18.0813s	
17386/22750 (epoch 38.211), train_loss = 0.64440574, grad/param norm = 2.1303e-01, time/batch = 18.9196s	
17387/22750 (epoch 38.213), train_loss = 0.58239168, grad/param norm = 2.3217e-01, time/batch = 17.3280s	
17388/22750 (epoch 38.215), train_loss = 0.57229455, grad/param norm = 1.9196e-01, time/batch = 18.4341s	
17389/22750 (epoch 38.218), train_loss = 0.65777505, grad/param norm = 2.2443e-01, time/batch = 20.5148s	
17390/22750 (epoch 38.220), train_loss = 0.61660349, grad/param norm = 2.2612e-01, time/batch = 18.7692s	
17391/22750 (epoch 38.222), train_loss = 0.62352177, grad/param norm = 3.0903e-01, time/batch = 18.7591s	
17392/22750 (epoch 38.224), train_loss = 0.64891356, grad/param norm = 1.9130e-01, time/batch = 19.9084s	
17393/22750 (epoch 38.226), train_loss = 0.72795125, grad/param norm = 2.2209e-01, time/batch = 19.2410s	
17394/22750 (epoch 38.229), train_loss = 0.75385297, grad/param norm = 2.2474e-01, time/batch = 18.6527s	
17395/22750 (epoch 38.231), train_loss = 0.65268176, grad/param norm = 2.1555e-01, time/batch = 20.0657s	
17396/22750 (epoch 38.233), train_loss = 0.59687765, grad/param norm = 2.2604e-01, time/batch = 19.9831s	
17397/22750 (epoch 38.235), train_loss = 0.57982632, grad/param norm = 2.1017e-01, time/batch = 19.2598s	
17398/22750 (epoch 38.237), train_loss = 0.64787904, grad/param norm = 2.1421e-01, time/batch = 18.3344s	
17399/22750 (epoch 38.240), train_loss = 0.71254885, grad/param norm = 1.9701e-01, time/batch = 21.8368s	
17400/22750 (epoch 38.242), train_loss = 0.86383607, grad/param norm = 2.4771e-01, time/batch = 17.9310s	
17401/22750 (epoch 38.244), train_loss = 0.86281084, grad/param norm = 2.3460e-01, time/batch = 17.8170s	
17402/22750 (epoch 38.246), train_loss = 0.87839165, grad/param norm = 2.5339e-01, time/batch = 18.3180s	
17403/22750 (epoch 38.248), train_loss = 0.73625292, grad/param norm = 2.4289e-01, time/batch = 17.8990s	
17404/22750 (epoch 38.251), train_loss = 0.82462416, grad/param norm = 2.4887e-01, time/batch = 18.9978s	
17405/22750 (epoch 38.253), train_loss = 0.81273887, grad/param norm = 3.1876e-01, time/batch = 18.0893s	
17406/22750 (epoch 38.255), train_loss = 0.76851786, grad/param norm = 2.2057e-01, time/batch = 18.3429s	
17407/22750 (epoch 38.257), train_loss = 0.68170386, grad/param norm = 2.1593e-01, time/batch = 19.5263s	
17408/22750 (epoch 38.259), train_loss = 0.83877874, grad/param norm = 3.0258e-01, time/batch = 20.3621s	
17409/22750 (epoch 38.262), train_loss = 0.76018195, grad/param norm = 2.3295e-01, time/batch = 18.4245s	
17410/22750 (epoch 38.264), train_loss = 0.59213036, grad/param norm = 2.4120e-01, time/batch = 18.1703s	
17411/22750 (epoch 38.266), train_loss = 0.74019924, grad/param norm = 2.6729e-01, time/batch = 19.0069s	
17412/22750 (epoch 38.268), train_loss = 0.84563647, grad/param norm = 2.3837e-01, time/batch = 18.9239s	
17413/22750 (epoch 38.270), train_loss = 0.65931769, grad/param norm = 2.4734e-01, time/batch = 16.9686s	
17414/22750 (epoch 38.273), train_loss = 0.96983079, grad/param norm = 2.5449e-01, time/batch = 19.4256s	
17415/22750 (epoch 38.275), train_loss = 0.86938094, grad/param norm = 2.2579e-01, time/batch = 19.7543s	
17416/22750 (epoch 38.277), train_loss = 0.73930717, grad/param norm = 2.7576e-01, time/batch = 19.3519s	
17417/22750 (epoch 38.279), train_loss = 0.62951198, grad/param norm = 2.0623e-01, time/batch = 19.6918s	
17418/22750 (epoch 38.281), train_loss = 0.86330800, grad/param norm = 2.6318e-01, time/batch = 19.5173s	
17419/22750 (epoch 38.284), train_loss = 0.77226566, grad/param norm = 2.1082e-01, time/batch = 18.3066s	
17420/22750 (epoch 38.286), train_loss = 0.84227557, grad/param norm = 2.3633e-01, time/batch = 18.7687s	
17421/22750 (epoch 38.288), train_loss = 0.89633189, grad/param norm = 2.5794e-01, time/batch = 16.9306s	
17422/22750 (epoch 38.290), train_loss = 0.79407176, grad/param norm = 2.6182e-01, time/batch = 18.0045s	
17423/22750 (epoch 38.292), train_loss = 0.82455517, grad/param norm = 3.0923e-01, time/batch = 18.1542s	
17424/22750 (epoch 38.295), train_loss = 0.77295335, grad/param norm = 2.4548e-01, time/batch = 19.1689s	
17425/22750 (epoch 38.297), train_loss = 0.77121653, grad/param norm = 2.3761e-01, time/batch = 19.3603s	
17426/22750 (epoch 38.299), train_loss = 0.83582359, grad/param norm = 2.6796e-01, time/batch = 18.7733s	
17427/22750 (epoch 38.301), train_loss = 0.75154795, grad/param norm = 2.1268e-01, time/batch = 19.1093s	
17428/22750 (epoch 38.303), train_loss = 0.81080712, grad/param norm = 2.3943e-01, time/batch = 17.9287s	
17429/22750 (epoch 38.305), train_loss = 0.91806584, grad/param norm = 2.4051e-01, time/batch = 17.2440s	
17430/22750 (epoch 38.308), train_loss = 0.82539678, grad/param norm = 2.3158e-01, time/batch = 19.8132s	
17431/22750 (epoch 38.310), train_loss = 0.71417259, grad/param norm = 2.6345e-01, time/batch = 19.3270s	
17432/22750 (epoch 38.312), train_loss = 0.77324754, grad/param norm = 2.2963e-01, time/batch = 19.5562s	
17433/22750 (epoch 38.314), train_loss = 0.77011836, grad/param norm = 2.0260e-01, time/batch = 19.4971s	
17434/22750 (epoch 38.316), train_loss = 0.73038923, grad/param norm = 2.2690e-01, time/batch = 19.6110s	
17435/22750 (epoch 38.319), train_loss = 0.79171411, grad/param norm = 2.3867e-01, time/batch = 18.1630s	
17436/22750 (epoch 38.321), train_loss = 0.71444034, grad/param norm = 2.6594e-01, time/batch = 17.9382s	
17437/22750 (epoch 38.323), train_loss = 0.78167803, grad/param norm = 2.3630e-01, time/batch = 18.9355s	
17438/22750 (epoch 38.325), train_loss = 0.67896378, grad/param norm = 2.2462e-01, time/batch = 16.4426s	
17439/22750 (epoch 38.327), train_loss = 0.72320738, grad/param norm = 2.7390e-01, time/batch = 20.0793s	
17440/22750 (epoch 38.330), train_loss = 0.88037513, grad/param norm = 2.5286e-01, time/batch = 19.6757s	
17441/22750 (epoch 38.332), train_loss = 0.94874892, grad/param norm = 2.3314e-01, time/batch = 17.3604s	
17442/22750 (epoch 38.334), train_loss = 0.62711841, grad/param norm = 2.0902e-01, time/batch = 18.9254s	
17443/22750 (epoch 38.336), train_loss = 0.84559313, grad/param norm = 2.0154e-01, time/batch = 18.4895s	
17444/22750 (epoch 38.338), train_loss = 0.74861994, grad/param norm = 2.2654e-01, time/batch = 19.5949s	
17445/22750 (epoch 38.341), train_loss = 0.77450270, grad/param norm = 2.3603e-01, time/batch = 17.6018s	
17446/22750 (epoch 38.343), train_loss = 0.65363206, grad/param norm = 2.4343e-01, time/batch = 20.2757s	
17447/22750 (epoch 38.345), train_loss = 0.82510281, grad/param norm = 4.1087e-01, time/batch = 19.9469s	
17448/22750 (epoch 38.347), train_loss = 0.87043086, grad/param norm = 2.5258e-01, time/batch = 17.6246s	
17449/22750 (epoch 38.349), train_loss = 0.64173721, grad/param norm = 2.6259e-01, time/batch = 18.6097s	
17450/22750 (epoch 38.352), train_loss = 0.89341466, grad/param norm = 2.2585e-01, time/batch = 19.4123s	
17451/22750 (epoch 38.354), train_loss = 0.86878813, grad/param norm = 2.6662e-01, time/batch = 18.4857s	
17452/22750 (epoch 38.356), train_loss = 0.82804666, grad/param norm = 2.2263e-01, time/batch = 17.7464s	
17453/22750 (epoch 38.358), train_loss = 0.73511283, grad/param norm = 2.3113e-01, time/batch = 17.8368s	
17454/22750 (epoch 38.360), train_loss = 0.90132265, grad/param norm = 2.2900e-01, time/batch = 16.4287s	
17455/22750 (epoch 38.363), train_loss = 0.71331976, grad/param norm = 2.3332e-01, time/batch = 20.6507s	
17456/22750 (epoch 38.365), train_loss = 0.62022915, grad/param norm = 2.1632e-01, time/batch = 19.1956s	
17457/22750 (epoch 38.367), train_loss = 0.72605592, grad/param norm = 2.5832e-01, time/batch = 18.9387s	
17458/22750 (epoch 38.369), train_loss = 0.79031192, grad/param norm = 2.5598e-01, time/batch = 19.6127s	
17459/22750 (epoch 38.371), train_loss = 0.79823801, grad/param norm = 2.7020e-01, time/batch = 17.8595s	
17460/22750 (epoch 38.374), train_loss = 0.68212405, grad/param norm = 2.3549e-01, time/batch = 18.8329s	
17461/22750 (epoch 38.376), train_loss = 0.75166170, grad/param norm = 2.0814e-01, time/batch = 18.4095s	
17462/22750 (epoch 38.378), train_loss = 0.77721161, grad/param norm = 2.1544e-01, time/batch = 19.1704s	
17463/22750 (epoch 38.380), train_loss = 0.81967686, grad/param norm = 2.1769e-01, time/batch = 17.5914s	
17464/22750 (epoch 38.382), train_loss = 0.74603695, grad/param norm = 2.4293e-01, time/batch = 17.7640s	
17465/22750 (epoch 38.385), train_loss = 0.82918015, grad/param norm = 2.1465e-01, time/batch = 20.2650s	
17466/22750 (epoch 38.387), train_loss = 0.80401784, grad/param norm = 2.2581e-01, time/batch = 20.0256s	
17467/22750 (epoch 38.389), train_loss = 0.63083976, grad/param norm = 2.1193e-01, time/batch = 20.0849s	
17468/22750 (epoch 38.391), train_loss = 0.48119033, grad/param norm = 1.6608e-01, time/batch = 16.9381s	
17469/22750 (epoch 38.393), train_loss = 0.64495541, grad/param norm = 2.2977e-01, time/batch = 18.4265s	
17470/22750 (epoch 38.396), train_loss = 0.78940543, grad/param norm = 2.2490e-01, time/batch = 16.9165s	
17471/22750 (epoch 38.398), train_loss = 0.71245110, grad/param norm = 1.9317e-01, time/batch = 19.4971s	
17472/22750 (epoch 38.400), train_loss = 0.77613497, grad/param norm = 2.4103e-01, time/batch = 19.6614s	
17473/22750 (epoch 38.402), train_loss = 0.78098083, grad/param norm = 2.3515e-01, time/batch = 17.3396s	
17474/22750 (epoch 38.404), train_loss = 0.87638341, grad/param norm = 2.6285e-01, time/batch = 16.7557s	
17475/22750 (epoch 38.407), train_loss = 0.85321291, grad/param norm = 2.3448e-01, time/batch = 19.6636s	
17476/22750 (epoch 38.409), train_loss = 0.69967873, grad/param norm = 2.3623e-01, time/batch = 19.1007s	
17477/22750 (epoch 38.411), train_loss = 0.68944344, grad/param norm = 2.1800e-01, time/batch = 18.1771s	
17478/22750 (epoch 38.413), train_loss = 0.55286148, grad/param norm = 2.9858e-01, time/batch = 19.9071s	
17479/22750 (epoch 38.415), train_loss = 0.63963807, grad/param norm = 2.4124e-01, time/batch = 18.2263s	
17480/22750 (epoch 38.418), train_loss = 0.71433728, grad/param norm = 2.1954e-01, time/batch = 16.0921s	
17481/22750 (epoch 38.420), train_loss = 0.82172797, grad/param norm = 2.6206e-01, time/batch = 17.5794s	
17482/22750 (epoch 38.422), train_loss = 0.95310955, grad/param norm = 2.7623e-01, time/batch = 18.2639s	
17483/22750 (epoch 38.424), train_loss = 0.93727629, grad/param norm = 2.4248e-01, time/batch = 17.8247s	
17484/22750 (epoch 38.426), train_loss = 0.92752789, grad/param norm = 2.3759e-01, time/batch = 20.6849s	
17485/22750 (epoch 38.429), train_loss = 0.70173144, grad/param norm = 2.2730e-01, time/batch = 20.5182s	
17486/22750 (epoch 38.431), train_loss = 0.62829031, grad/param norm = 2.0994e-01, time/batch = 17.5106s	
17487/22750 (epoch 38.433), train_loss = 0.71554262, grad/param norm = 2.0659e-01, time/batch = 18.0705s	
17488/22750 (epoch 38.435), train_loss = 0.55403192, grad/param norm = 1.5816e-01, time/batch = 19.5640s	
17489/22750 (epoch 38.437), train_loss = 0.49583880, grad/param norm = 2.0122e-01, time/batch = 18.2427s	
17490/22750 (epoch 38.440), train_loss = 0.70552237, grad/param norm = 2.6835e-01, time/batch = 17.4305s	
17491/22750 (epoch 38.442), train_loss = 0.73080119, grad/param norm = 2.4497e-01, time/batch = 19.7434s	
17492/22750 (epoch 38.444), train_loss = 0.71407021, grad/param norm = 2.2746e-01, time/batch = 19.6587s	
17493/22750 (epoch 38.446), train_loss = 0.72681535, grad/param norm = 2.6069e-01, time/batch = 18.9298s	
17494/22750 (epoch 38.448), train_loss = 0.96701997, grad/param norm = 2.6744e-01, time/batch = 19.8461s	
17495/22750 (epoch 38.451), train_loss = 0.92062422, grad/param norm = 2.3214e-01, time/batch = 19.8531s	
17496/22750 (epoch 38.453), train_loss = 0.80860632, grad/param norm = 2.6742e-01, time/batch = 20.2556s	
17497/22750 (epoch 38.455), train_loss = 0.91452405, grad/param norm = 2.2864e-01, time/batch = 19.0989s	
17498/22750 (epoch 38.457), train_loss = 0.81526291, grad/param norm = 3.1820e-01, time/batch = 18.3287s	
17499/22750 (epoch 38.459), train_loss = 0.83418297, grad/param norm = 2.3455e-01, time/batch = 18.7255s	
17500/22750 (epoch 38.462), train_loss = 0.76989783, grad/param norm = 2.0527e-01, time/batch = 18.5059s	
17501/22750 (epoch 38.464), train_loss = 0.66668749, grad/param norm = 2.1093e-01, time/batch = 17.2448s	
17502/22750 (epoch 38.466), train_loss = 0.82679657, grad/param norm = 3.0386e-01, time/batch = 19.3528s	
17503/22750 (epoch 38.468), train_loss = 0.80304564, grad/param norm = 2.3017e-01, time/batch = 18.9927s	
17504/22750 (epoch 38.470), train_loss = 0.88822509, grad/param norm = 2.7940e-01, time/batch = 19.7061s	
17505/22750 (epoch 38.473), train_loss = 0.74426718, grad/param norm = 2.4078e-01, time/batch = 16.7436s	
17506/22750 (epoch 38.475), train_loss = 0.77298087, grad/param norm = 2.3479e-01, time/batch = 15.8249s	
17507/22750 (epoch 38.477), train_loss = 0.66891160, grad/param norm = 2.2078e-01, time/batch = 16.5779s	
17508/22750 (epoch 38.479), train_loss = 0.65458505, grad/param norm = 2.0240e-01, time/batch = 16.5217s	
17509/22750 (epoch 38.481), train_loss = 0.61810622, grad/param norm = 1.8326e-01, time/batch = 16.4283s	
17510/22750 (epoch 38.484), train_loss = 0.52209473, grad/param norm = 2.1613e-01, time/batch = 15.8387s	
17511/22750 (epoch 38.486), train_loss = 0.63505215, grad/param norm = 2.3630e-01, time/batch = 19.0978s	
17512/22750 (epoch 38.488), train_loss = 0.58812151, grad/param norm = 2.1718e-01, time/batch = 17.7137s	
17513/22750 (epoch 38.490), train_loss = 0.74632395, grad/param norm = 2.2922e-01, time/batch = 19.9348s	
17514/22750 (epoch 38.492), train_loss = 0.81517328, grad/param norm = 2.2808e-01, time/batch = 19.6071s	
17515/22750 (epoch 38.495), train_loss = 0.68888383, grad/param norm = 2.7090e-01, time/batch = 18.3353s	
17516/22750 (epoch 38.497), train_loss = 0.73561364, grad/param norm = 2.5829e-01, time/batch = 17.9113s	
17517/22750 (epoch 38.499), train_loss = 0.66690099, grad/param norm = 2.2331e-01, time/batch = 18.5022s	
17518/22750 (epoch 38.501), train_loss = 0.71617279, grad/param norm = 2.4877e-01, time/batch = 19.2402s	
17519/22750 (epoch 38.503), train_loss = 0.69576884, grad/param norm = 2.1405e-01, time/batch = 18.0235s	
17520/22750 (epoch 38.505), train_loss = 0.64880631, grad/param norm = 2.2257e-01, time/batch = 17.9249s	
17521/22750 (epoch 38.508), train_loss = 0.61185952, grad/param norm = 2.1053e-01, time/batch = 15.8841s	
17522/22750 (epoch 38.510), train_loss = 0.63496727, grad/param norm = 2.2114e-01, time/batch = 18.1835s	
17523/22750 (epoch 38.512), train_loss = 0.66970545, grad/param norm = 2.2071e-01, time/batch = 17.4205s	
17524/22750 (epoch 38.514), train_loss = 0.69634650, grad/param norm = 2.3080e-01, time/batch = 19.5099s	
17525/22750 (epoch 38.516), train_loss = 0.68419212, grad/param norm = 2.5744e-01, time/batch = 16.5126s	
17526/22750 (epoch 38.519), train_loss = 0.81858387, grad/param norm = 2.2452e-01, time/batch = 18.5640s	
17527/22750 (epoch 38.521), train_loss = 0.73163645, grad/param norm = 2.3588e-01, time/batch = 16.6815s	
17528/22750 (epoch 38.523), train_loss = 0.66883525, grad/param norm = 2.4355e-01, time/batch = 16.6050s	
17529/22750 (epoch 38.525), train_loss = 0.85667384, grad/param norm = 2.7801e-01, time/batch = 17.0131s	
17530/22750 (epoch 38.527), train_loss = 0.76520309, grad/param norm = 2.5145e-01, time/batch = 18.9148s	
17531/22750 (epoch 38.530), train_loss = 0.67390556, grad/param norm = 2.2022e-01, time/batch = 20.5262s	
17532/22750 (epoch 38.532), train_loss = 0.62212472, grad/param norm = 2.0368e-01, time/batch = 18.3525s	
17533/22750 (epoch 38.534), train_loss = 0.81423905, grad/param norm = 2.6276e-01, time/batch = 19.9453s	
17534/22750 (epoch 38.536), train_loss = 0.77203272, grad/param norm = 1.9869e-01, time/batch = 16.7243s	
17535/22750 (epoch 38.538), train_loss = 0.76036362, grad/param norm = 2.1712e-01, time/batch = 16.6731s	
17536/22750 (epoch 38.541), train_loss = 0.67113338, grad/param norm = 2.7277e-01, time/batch = 19.0911s	
17537/22750 (epoch 38.543), train_loss = 0.64503465, grad/param norm = 2.3335e-01, time/batch = 19.2325s	
17538/22750 (epoch 38.545), train_loss = 0.80587831, grad/param norm = 2.3478e-01, time/batch = 18.5674s	
17539/22750 (epoch 38.547), train_loss = 0.69313146, grad/param norm = 2.1345e-01, time/batch = 19.1686s	
17540/22750 (epoch 38.549), train_loss = 0.70515501, grad/param norm = 2.2593e-01, time/batch = 20.6793s	
17541/22750 (epoch 38.552), train_loss = 0.79480251, grad/param norm = 2.5008e-01, time/batch = 20.0301s	
17542/22750 (epoch 38.554), train_loss = 0.80934794, grad/param norm = 2.5204e-01, time/batch = 18.6824s	
17543/22750 (epoch 38.556), train_loss = 0.78138347, grad/param norm = 2.2509e-01, time/batch = 20.2636s	
17544/22750 (epoch 38.558), train_loss = 0.74644175, grad/param norm = 2.3269e-01, time/batch = 18.1497s	
17545/22750 (epoch 38.560), train_loss = 0.69979733, grad/param norm = 2.0304e-01, time/batch = 17.5853s	
17546/22750 (epoch 38.563), train_loss = 0.80703781, grad/param norm = 2.5363e-01, time/batch = 20.4204s	
17547/22750 (epoch 38.565), train_loss = 0.79384678, grad/param norm = 2.5415e-01, time/batch = 19.7448s	
17548/22750 (epoch 38.567), train_loss = 0.78174139, grad/param norm = 2.3683e-01, time/batch = 17.8308s	
17549/22750 (epoch 38.569), train_loss = 0.71829552, grad/param norm = 2.1454e-01, time/batch = 19.4145s	
17550/22750 (epoch 38.571), train_loss = 0.74571506, grad/param norm = 2.5400e-01, time/batch = 19.5975s	
17551/22750 (epoch 38.574), train_loss = 0.75816875, grad/param norm = 2.5499e-01, time/batch = 15.7965s	
17552/22750 (epoch 38.576), train_loss = 0.72511054, grad/param norm = 2.3364e-01, time/batch = 18.6958s	
17553/22750 (epoch 38.578), train_loss = 0.63532567, grad/param norm = 2.2856e-01, time/batch = 20.4307s	
17554/22750 (epoch 38.580), train_loss = 0.81597913, grad/param norm = 2.7779e-01, time/batch = 17.1687s	
17555/22750 (epoch 38.582), train_loss = 0.66208677, grad/param norm = 1.9729e-01, time/batch = 18.8366s	
17556/22750 (epoch 38.585), train_loss = 0.65157751, grad/param norm = 2.2404e-01, time/batch = 17.9144s	
17557/22750 (epoch 38.587), train_loss = 0.66127498, grad/param norm = 2.0117e-01, time/batch = 16.0517s	
17558/22750 (epoch 38.589), train_loss = 0.56009756, grad/param norm = 2.0482e-01, time/batch = 16.9139s	
17559/22750 (epoch 38.591), train_loss = 0.73294043, grad/param norm = 2.1931e-01, time/batch = 17.9936s	
17560/22750 (epoch 38.593), train_loss = 0.84735622, grad/param norm = 2.3463e-01, time/batch = 19.9030s	
17561/22750 (epoch 38.596), train_loss = 0.82261672, grad/param norm = 2.3212e-01, time/batch = 16.2924s	
17562/22750 (epoch 38.598), train_loss = 0.83989871, grad/param norm = 2.6614e-01, time/batch = 15.8845s	
17563/22750 (epoch 38.600), train_loss = 0.87744466, grad/param norm = 2.7694e-01, time/batch = 16.0171s	
17564/22750 (epoch 38.602), train_loss = 0.67430347, grad/param norm = 2.0629e-01, time/batch = 23.8243s	
17565/22750 (epoch 38.604), train_loss = 0.71083109, grad/param norm = 2.3521e-01, time/batch = 25.7181s	
17566/22750 (epoch 38.607), train_loss = 0.65765103, grad/param norm = 2.0207e-01, time/batch = 17.9003s	
17567/22750 (epoch 38.609), train_loss = 0.62911808, grad/param norm = 2.1415e-01, time/batch = 17.8309s	
17568/22750 (epoch 38.611), train_loss = 0.70836394, grad/param norm = 2.2881e-01, time/batch = 18.3318s	
17569/22750 (epoch 38.613), train_loss = 0.67210414, grad/param norm = 2.3104e-01, time/batch = 18.2485s	
17570/22750 (epoch 38.615), train_loss = 0.68201435, grad/param norm = 1.8511e-01, time/batch = 18.1800s	
17571/22750 (epoch 38.618), train_loss = 0.71070674, grad/param norm = 1.9652e-01, time/batch = 16.2119s	
17572/22750 (epoch 38.620), train_loss = 0.71321308, grad/param norm = 2.1974e-01, time/batch = 18.1114s	
17573/22750 (epoch 38.622), train_loss = 0.60566962, grad/param norm = 1.7475e-01, time/batch = 18.1781s	
17574/22750 (epoch 38.624), train_loss = 0.68768649, grad/param norm = 2.1506e-01, time/batch = 18.0154s	
17575/22750 (epoch 38.626), train_loss = 0.57958223, grad/param norm = 1.9821e-01, time/batch = 19.1723s	
17576/22750 (epoch 38.629), train_loss = 0.68280971, grad/param norm = 2.0386e-01, time/batch = 17.1639s	
17577/22750 (epoch 38.631), train_loss = 0.71753151, grad/param norm = 2.1427e-01, time/batch = 17.5128s	
17578/22750 (epoch 38.633), train_loss = 0.61845157, grad/param norm = 2.0169e-01, time/batch = 18.5093s	
17579/22750 (epoch 38.635), train_loss = 0.72505952, grad/param norm = 2.2290e-01, time/batch = 19.5901s	
17580/22750 (epoch 38.637), train_loss = 0.76672166, grad/param norm = 2.9024e-01, time/batch = 18.0831s	
17581/22750 (epoch 38.640), train_loss = 0.78863237, grad/param norm = 2.3237e-01, time/batch = 18.3301s	
17582/22750 (epoch 38.642), train_loss = 0.83452239, grad/param norm = 2.3557e-01, time/batch = 17.7880s	
17583/22750 (epoch 38.644), train_loss = 0.72054296, grad/param norm = 2.2717e-01, time/batch = 18.2733s	
17584/22750 (epoch 38.646), train_loss = 0.79934713, grad/param norm = 3.2451e-01, time/batch = 19.0151s	
17585/22750 (epoch 38.648), train_loss = 0.77134131, grad/param norm = 2.3618e-01, time/batch = 17.7602s	
17586/22750 (epoch 38.651), train_loss = 0.78356110, grad/param norm = 2.3143e-01, time/batch = 19.5921s	
17587/22750 (epoch 38.653), train_loss = 0.80885601, grad/param norm = 1.9196e-01, time/batch = 17.5161s	
17588/22750 (epoch 38.655), train_loss = 0.74828861, grad/param norm = 2.0393e-01, time/batch = 18.7950s	
17589/22750 (epoch 38.657), train_loss = 0.86268604, grad/param norm = 2.4876e-01, time/batch = 19.8304s	
17590/22750 (epoch 38.659), train_loss = 0.89735261, grad/param norm = 2.1125e-01, time/batch = 17.9109s	
17591/22750 (epoch 38.662), train_loss = 0.87389801, grad/param norm = 3.0185e-01, time/batch = 20.4047s	
17592/22750 (epoch 38.664), train_loss = 0.78369619, grad/param norm = 2.2232e-01, time/batch = 20.0934s	
17593/22750 (epoch 38.666), train_loss = 0.63961890, grad/param norm = 2.1408e-01, time/batch = 18.4459s	
17594/22750 (epoch 38.668), train_loss = 0.72605584, grad/param norm = 2.2113e-01, time/batch = 19.1196s	
17595/22750 (epoch 38.670), train_loss = 0.70309767, grad/param norm = 2.1464e-01, time/batch = 19.4527s	
17596/22750 (epoch 38.673), train_loss = 0.89681740, grad/param norm = 2.1634e-01, time/batch = 17.0782s	
17597/22750 (epoch 38.675), train_loss = 1.01711468, grad/param norm = 2.7051e-01, time/batch = 17.5017s	
17598/22750 (epoch 38.677), train_loss = 0.87940750, grad/param norm = 2.5544e-01, time/batch = 17.6022s	
17599/22750 (epoch 38.679), train_loss = 0.87098890, grad/param norm = 2.4363e-01, time/batch = 18.0092s	
17600/22750 (epoch 38.681), train_loss = 0.89746511, grad/param norm = 2.7103e-01, time/batch = 17.0826s	
17601/22750 (epoch 38.684), train_loss = 0.90379301, grad/param norm = 2.5087e-01, time/batch = 19.7739s	
17602/22750 (epoch 38.686), train_loss = 0.94529093, grad/param norm = 2.5303e-01, time/batch = 19.4318s	
17603/22750 (epoch 38.688), train_loss = 0.88946957, grad/param norm = 2.6216e-01, time/batch = 18.9413s	
17604/22750 (epoch 38.690), train_loss = 0.89905938, grad/param norm = 2.5766e-01, time/batch = 18.6013s	
17605/22750 (epoch 38.692), train_loss = 0.87724795, grad/param norm = 2.5003e-01, time/batch = 19.2524s	
17606/22750 (epoch 38.695), train_loss = 0.79449845, grad/param norm = 2.2730e-01, time/batch = 18.1594s	
17607/22750 (epoch 38.697), train_loss = 0.78759067, grad/param norm = 2.1761e-01, time/batch = 19.2220s	
17608/22750 (epoch 38.699), train_loss = 0.70871079, grad/param norm = 2.1361e-01, time/batch = 19.4883s	
17609/22750 (epoch 38.701), train_loss = 0.65370375, grad/param norm = 2.3382e-01, time/batch = 16.9821s	
17610/22750 (epoch 38.703), train_loss = 0.72349676, grad/param norm = 2.3307e-01, time/batch = 20.4277s	
17611/22750 (epoch 38.705), train_loss = 0.71701995, grad/param norm = 2.1740e-01, time/batch = 19.6876s	
17612/22750 (epoch 38.708), train_loss = 0.77451162, grad/param norm = 2.5203e-01, time/batch = 18.7669s	
17613/22750 (epoch 38.710), train_loss = 0.67839085, grad/param norm = 2.2977e-01, time/batch = 19.0909s	
17614/22750 (epoch 38.712), train_loss = 0.59797816, grad/param norm = 2.0215e-01, time/batch = 18.0948s	
17615/22750 (epoch 38.714), train_loss = 0.63237407, grad/param norm = 2.0225e-01, time/batch = 18.4074s	
17616/22750 (epoch 38.716), train_loss = 0.65262102, grad/param norm = 2.1168e-01, time/batch = 18.5820s	
17617/22750 (epoch 38.719), train_loss = 0.71247508, grad/param norm = 2.7576e-01, time/batch = 19.5710s	
17618/22750 (epoch 38.721), train_loss = 0.82429891, grad/param norm = 2.1841e-01, time/batch = 17.3389s	
17619/22750 (epoch 38.723), train_loss = 0.83483970, grad/param norm = 3.0944e-01, time/batch = 18.7804s	
17620/22750 (epoch 38.725), train_loss = 0.72800760, grad/param norm = 2.6611e-01, time/batch = 19.0214s	
17621/22750 (epoch 38.727), train_loss = 0.73541215, grad/param norm = 2.2641e-01, time/batch = 19.0055s	
17622/22750 (epoch 38.730), train_loss = 0.71903399, grad/param norm = 2.2623e-01, time/batch = 17.3589s	
17623/22750 (epoch 38.732), train_loss = 0.67786747, grad/param norm = 2.0153e-01, time/batch = 19.0706s	
17624/22750 (epoch 38.734), train_loss = 0.61396084, grad/param norm = 1.8757e-01, time/batch = 19.5784s	
17625/22750 (epoch 38.736), train_loss = 0.71953768, grad/param norm = 2.3951e-01, time/batch = 18.1708s	
17626/22750 (epoch 38.738), train_loss = 0.78784959, grad/param norm = 2.5364e-01, time/batch = 18.4961s	
17627/22750 (epoch 38.741), train_loss = 0.85818619, grad/param norm = 2.2266e-01, time/batch = 20.7479s	
17628/22750 (epoch 38.743), train_loss = 0.76771690, grad/param norm = 2.1779e-01, time/batch = 17.4999s	
17629/22750 (epoch 38.745), train_loss = 0.63960017, grad/param norm = 2.1817e-01, time/batch = 19.3403s	
17630/22750 (epoch 38.747), train_loss = 0.76039459, grad/param norm = 2.2043e-01, time/batch = 19.5311s	
17631/22750 (epoch 38.749), train_loss = 0.85934583, grad/param norm = 2.7478e-01, time/batch = 18.4338s	
17632/22750 (epoch 38.752), train_loss = 0.75535547, grad/param norm = 2.4008e-01, time/batch = 18.8512s	
17633/22750 (epoch 38.754), train_loss = 0.75997708, grad/param norm = 2.4776e-01, time/batch = 19.1511s	
17634/22750 (epoch 38.756), train_loss = 0.69776710, grad/param norm = 2.8463e-01, time/batch = 18.4321s	
17635/22750 (epoch 38.758), train_loss = 0.68340459, grad/param norm = 2.0679e-01, time/batch = 18.8341s	
17636/22750 (epoch 38.760), train_loss = 0.67608872, grad/param norm = 2.3024e-01, time/batch = 19.4253s	
17637/22750 (epoch 38.763), train_loss = 0.74490125, grad/param norm = 2.4274e-01, time/batch = 18.7532s	
17638/22750 (epoch 38.765), train_loss = 0.72766455, grad/param norm = 2.3246e-01, time/batch = 18.0033s	
17639/22750 (epoch 38.767), train_loss = 0.78198227, grad/param norm = 2.2588e-01, time/batch = 18.7747s	
17640/22750 (epoch 38.769), train_loss = 0.87138256, grad/param norm = 2.4960e-01, time/batch = 20.2789s	
17641/22750 (epoch 38.771), train_loss = 0.88780886, grad/param norm = 2.9639e-01, time/batch = 19.9282s	
17642/22750 (epoch 38.774), train_loss = 0.70865414, grad/param norm = 2.4551e-01, time/batch = 19.8484s	
17643/22750 (epoch 38.776), train_loss = 0.82805529, grad/param norm = 2.3393e-01, time/batch = 18.5082s	
17644/22750 (epoch 38.778), train_loss = 0.89245904, grad/param norm = 2.6692e-01, time/batch = 16.8070s	
17645/22750 (epoch 38.780), train_loss = 0.78861960, grad/param norm = 2.4327e-01, time/batch = 17.3412s	
17646/22750 (epoch 38.782), train_loss = 0.91370920, grad/param norm = 2.9320e-01, time/batch = 17.9290s	
17647/22750 (epoch 38.785), train_loss = 0.75024207, grad/param norm = 2.3975e-01, time/batch = 18.3356s	
17648/22750 (epoch 38.787), train_loss = 0.65224683, grad/param norm = 2.3155e-01, time/batch = 19.4356s	
17649/22750 (epoch 38.789), train_loss = 0.73394008, grad/param norm = 2.2616e-01, time/batch = 20.6836s	
17650/22750 (epoch 38.791), train_loss = 0.71140084, grad/param norm = 2.2046e-01, time/batch = 19.4448s	
17651/22750 (epoch 38.793), train_loss = 0.67981031, grad/param norm = 2.4336e-01, time/batch = 20.2570s	
17652/22750 (epoch 38.796), train_loss = 0.64546925, grad/param norm = 2.0805e-01, time/batch = 18.9232s	
17653/22750 (epoch 38.798), train_loss = 0.70332319, grad/param norm = 2.2302e-01, time/batch = 18.6823s	
17654/22750 (epoch 38.800), train_loss = 0.69454600, grad/param norm = 2.4900e-01, time/batch = 18.4911s	
17655/22750 (epoch 38.802), train_loss = 0.63285539, grad/param norm = 2.7844e-01, time/batch = 17.4959s	
17656/22750 (epoch 38.804), train_loss = 0.81279423, grad/param norm = 2.1881e-01, time/batch = 19.1686s	
17657/22750 (epoch 38.807), train_loss = 0.78715757, grad/param norm = 2.4276e-01, time/batch = 28.8897s	
17658/22750 (epoch 38.809), train_loss = 0.88535998, grad/param norm = 2.5915e-01, time/batch = 20.9424s	
17659/22750 (epoch 38.811), train_loss = 0.75093718, grad/param norm = 2.7345e-01, time/batch = 18.0120s	
17660/22750 (epoch 38.813), train_loss = 0.77730073, grad/param norm = 2.2798e-01, time/batch = 17.9926s	
17661/22750 (epoch 38.815), train_loss = 0.86189675, grad/param norm = 2.3102e-01, time/batch = 16.3986s	
17662/22750 (epoch 38.818), train_loss = 0.82280547, grad/param norm = 2.0667e-01, time/batch = 17.1805s	
17663/22750 (epoch 38.820), train_loss = 0.94439063, grad/param norm = 2.3760e-01, time/batch = 16.7688s	
17664/22750 (epoch 38.822), train_loss = 0.78483530, grad/param norm = 2.2728e-01, time/batch = 19.4874s	
17665/22750 (epoch 38.824), train_loss = 0.65922596, grad/param norm = 2.0152e-01, time/batch = 16.2823s	
17666/22750 (epoch 38.826), train_loss = 0.74740237, grad/param norm = 2.3115e-01, time/batch = 18.7861s	
17667/22750 (epoch 38.829), train_loss = 0.86300212, grad/param norm = 2.7412e-01, time/batch = 16.4658s	
17668/22750 (epoch 38.831), train_loss = 0.82725712, grad/param norm = 2.5696e-01, time/batch = 18.6172s	
17669/22750 (epoch 38.833), train_loss = 0.76648070, grad/param norm = 2.4697e-01, time/batch = 18.8381s	
17670/22750 (epoch 38.835), train_loss = 0.68411691, grad/param norm = 2.4402e-01, time/batch = 18.1672s	
17671/22750 (epoch 38.837), train_loss = 0.71957282, grad/param norm = 2.3048e-01, time/batch = 17.0964s	
17672/22750 (epoch 38.840), train_loss = 0.66669483, grad/param norm = 2.0437e-01, time/batch = 18.3259s	
17673/22750 (epoch 38.842), train_loss = 0.69081970, grad/param norm = 2.5892e-01, time/batch = 17.0070s	
17674/22750 (epoch 38.844), train_loss = 0.76753680, grad/param norm = 2.3577e-01, time/batch = 17.7582s	
17675/22750 (epoch 38.846), train_loss = 0.80561707, grad/param norm = 2.0689e-01, time/batch = 20.6906s	
17676/22750 (epoch 38.848), train_loss = 0.70298579, grad/param norm = 2.1727e-01, time/batch = 18.3166s	
17677/22750 (epoch 38.851), train_loss = 0.68349111, grad/param norm = 2.3197e-01, time/batch = 18.6732s	
17678/22750 (epoch 38.853), train_loss = 0.84680334, grad/param norm = 2.3380e-01, time/batch = 18.5797s	
17679/22750 (epoch 38.855), train_loss = 0.72348492, grad/param norm = 2.3901e-01, time/batch = 17.3413s	
17680/22750 (epoch 38.857), train_loss = 0.79769299, grad/param norm = 2.1803e-01, time/batch = 18.9043s	
17681/22750 (epoch 38.859), train_loss = 0.76726012, grad/param norm = 2.2123e-01, time/batch = 20.1599s	
17682/22750 (epoch 38.862), train_loss = 0.92155786, grad/param norm = 2.5852e-01, time/batch = 18.5065s	
17683/22750 (epoch 38.864), train_loss = 0.76756748, grad/param norm = 2.2445e-01, time/batch = 18.6732s	
17684/22750 (epoch 38.866), train_loss = 0.80260954, grad/param norm = 2.1704e-01, time/batch = 19.5191s	
17685/22750 (epoch 38.868), train_loss = 0.69323066, grad/param norm = 2.3009e-01, time/batch = 18.2888s	
17686/22750 (epoch 38.870), train_loss = 0.64655394, grad/param norm = 2.2667e-01, time/batch = 19.2702s	
17687/22750 (epoch 38.873), train_loss = 0.73808061, grad/param norm = 2.2160e-01, time/batch = 19.4185s	
17688/22750 (epoch 38.875), train_loss = 0.79323962, grad/param norm = 2.1041e-01, time/batch = 18.6534s	
17689/22750 (epoch 38.877), train_loss = 0.68785464, grad/param norm = 2.0052e-01, time/batch = 19.4009s	
17690/22750 (epoch 38.879), train_loss = 0.84319679, grad/param norm = 2.5601e-01, time/batch = 19.6353s	
17691/22750 (epoch 38.881), train_loss = 0.78365283, grad/param norm = 2.3490e-01, time/batch = 18.8848s	
17692/22750 (epoch 38.884), train_loss = 0.68921842, grad/param norm = 2.0799e-01, time/batch = 18.9982s	
17693/22750 (epoch 38.886), train_loss = 0.77896571, grad/param norm = 2.1581e-01, time/batch = 17.7694s	
17694/22750 (epoch 38.888), train_loss = 0.80645685, grad/param norm = 2.1246e-01, time/batch = 20.2597s	
17695/22750 (epoch 38.890), train_loss = 0.81085728, grad/param norm = 2.2602e-01, time/batch = 18.5265s	
17696/22750 (epoch 38.892), train_loss = 1.00261348, grad/param norm = 2.6908e-01, time/batch = 20.5675s	
17697/22750 (epoch 38.895), train_loss = 0.71978985, grad/param norm = 2.4763e-01, time/batch = 20.6548s	
17698/22750 (epoch 38.897), train_loss = 0.86073404, grad/param norm = 2.4162e-01, time/batch = 18.6657s	
17699/22750 (epoch 38.899), train_loss = 0.77948693, grad/param norm = 2.4705e-01, time/batch = 18.5721s	
17700/22750 (epoch 38.901), train_loss = 0.83241332, grad/param norm = 2.6508e-01, time/batch = 21.6305s	
17701/22750 (epoch 38.903), train_loss = 0.76348851, grad/param norm = 2.4038e-01, time/batch = 18.4890s	
17702/22750 (epoch 38.905), train_loss = 0.83161565, grad/param norm = 2.6720e-01, time/batch = 20.9090s	
17703/22750 (epoch 38.908), train_loss = 0.63514506, grad/param norm = 2.3527e-01, time/batch = 21.6609s	
17704/22750 (epoch 38.910), train_loss = 0.59147115, grad/param norm = 2.1104e-01, time/batch = 17.9076s	
17705/22750 (epoch 38.912), train_loss = 0.74889840, grad/param norm = 2.1943e-01, time/batch = 20.8062s	
17706/22750 (epoch 38.914), train_loss = 0.76281869, grad/param norm = 2.3641e-01, time/batch = 20.2335s	
17707/22750 (epoch 38.916), train_loss = 0.61020113, grad/param norm = 2.1431e-01, time/batch = 18.4918s	
17708/22750 (epoch 38.919), train_loss = 0.75241558, grad/param norm = 2.6816e-01, time/batch = 18.5731s	
17709/22750 (epoch 38.921), train_loss = 0.59237997, grad/param norm = 1.9780e-01, time/batch = 17.6480s	
17710/22750 (epoch 38.923), train_loss = 0.67802623, grad/param norm = 2.2347e-01, time/batch = 16.7524s	
17711/22750 (epoch 38.925), train_loss = 0.74846085, grad/param norm = 2.2052e-01, time/batch = 16.1417s	
17712/22750 (epoch 38.927), train_loss = 0.59025376, grad/param norm = 2.0276e-01, time/batch = 16.8516s	
17713/22750 (epoch 38.930), train_loss = 0.56807096, grad/param norm = 2.0827e-01, time/batch = 18.1715s	
17714/22750 (epoch 38.932), train_loss = 0.73936588, grad/param norm = 2.4143e-01, time/batch = 17.1759s	
17715/22750 (epoch 38.934), train_loss = 0.62057616, grad/param norm = 1.9932e-01, time/batch = 17.6607s	
17716/22750 (epoch 38.936), train_loss = 0.83997016, grad/param norm = 2.4288e-01, time/batch = 16.2594s	
17717/22750 (epoch 38.938), train_loss = 0.84077450, grad/param norm = 2.0768e-01, time/batch = 17.3907s	
17718/22750 (epoch 38.941), train_loss = 0.87263311, grad/param norm = 2.5958e-01, time/batch = 17.0962s	
17719/22750 (epoch 38.943), train_loss = 0.76573262, grad/param norm = 2.1328e-01, time/batch = 17.4304s	
17720/22750 (epoch 38.945), train_loss = 0.78683302, grad/param norm = 2.3669e-01, time/batch = 16.0356s	
17721/22750 (epoch 38.947), train_loss = 0.69678341, grad/param norm = 2.3833e-01, time/batch = 20.3538s	
17722/22750 (epoch 38.949), train_loss = 0.72086153, grad/param norm = 2.4868e-01, time/batch = 19.5250s	
17723/22750 (epoch 38.952), train_loss = 0.71488512, grad/param norm = 2.4422e-01, time/batch = 19.0830s	
17724/22750 (epoch 38.954), train_loss = 0.65951370, grad/param norm = 2.1314e-01, time/batch = 18.2483s	
17725/22750 (epoch 38.956), train_loss = 0.81240419, grad/param norm = 3.0306e-01, time/batch = 18.3408s	
17726/22750 (epoch 38.958), train_loss = 0.67759091, grad/param norm = 1.9663e-01, time/batch = 19.1614s	
17727/22750 (epoch 38.960), train_loss = 0.66816514, grad/param norm = 2.4556e-01, time/batch = 17.7475s	
17728/22750 (epoch 38.963), train_loss = 0.78321476, grad/param norm = 2.3288e-01, time/batch = 20.5102s	
17729/22750 (epoch 38.965), train_loss = 0.82511720, grad/param norm = 2.2325e-01, time/batch = 19.6889s	
17730/22750 (epoch 38.967), train_loss = 0.78210554, grad/param norm = 2.4086e-01, time/batch = 18.6940s	
17731/22750 (epoch 38.969), train_loss = 0.72330818, grad/param norm = 2.4333e-01, time/batch = 19.7658s	
17732/22750 (epoch 38.971), train_loss = 0.69351979, grad/param norm = 2.1037e-01, time/batch = 20.0817s	
17733/22750 (epoch 38.974), train_loss = 0.65936751, grad/param norm = 1.9732e-01, time/batch = 17.7462s	
17734/22750 (epoch 38.976), train_loss = 0.71012795, grad/param norm = 2.5059e-01, time/batch = 19.4935s	
17735/22750 (epoch 38.978), train_loss = 0.69781091, grad/param norm = 2.1891e-01, time/batch = 17.4763s	
17736/22750 (epoch 38.980), train_loss = 0.85801054, grad/param norm = 2.7477e-01, time/batch = 18.2436s	
17737/22750 (epoch 38.982), train_loss = 0.69956788, grad/param norm = 2.1475e-01, time/batch = 20.3367s	
17738/22750 (epoch 38.985), train_loss = 0.87468296, grad/param norm = 2.5754e-01, time/batch = 17.2003s	
17739/22750 (epoch 38.987), train_loss = 0.62232254, grad/param norm = 2.0840e-01, time/batch = 18.6591s	
17740/22750 (epoch 38.989), train_loss = 0.69046804, grad/param norm = 2.2347e-01, time/batch = 19.0679s	
17741/22750 (epoch 38.991), train_loss = 0.77680276, grad/param norm = 2.2676e-01, time/batch = 18.4964s	
17742/22750 (epoch 38.993), train_loss = 0.74987056, grad/param norm = 2.8623e-01, time/batch = 17.4198s	
17743/22750 (epoch 38.996), train_loss = 0.65703610, grad/param norm = 2.6935e-01, time/batch = 18.4901s	
17744/22750 (epoch 38.998), train_loss = 0.82754289, grad/param norm = 2.4363e-01, time/batch = 18.8308s	
decayed learning rate by a factor 0.97 to 0.00080201413708631	
17745/22750 (epoch 39.000), train_loss = 0.72054208, grad/param norm = 2.1417e-01, time/batch = 18.5692s	
17746/22750 (epoch 39.002), train_loss = 0.89891938, grad/param norm = 2.3458e-01, time/batch = 18.5855s	
17747/22750 (epoch 39.004), train_loss = 0.71047341, grad/param norm = 2.3147e-01, time/batch = 20.3574s	
17748/22750 (epoch 39.007), train_loss = 0.72004480, grad/param norm = 3.1757e-01, time/batch = 20.6792s	
17749/22750 (epoch 39.009), train_loss = 0.89371271, grad/param norm = 2.8006e-01, time/batch = 18.8317s	
17750/22750 (epoch 39.011), train_loss = 0.92865829, grad/param norm = 2.7728e-01, time/batch = 19.3945s	
17751/22750 (epoch 39.013), train_loss = 0.85722737, grad/param norm = 2.4157e-01, time/batch = 19.6627s	
17752/22750 (epoch 39.015), train_loss = 0.77701148, grad/param norm = 2.6600e-01, time/batch = 17.1882s	
17753/22750 (epoch 39.018), train_loss = 0.87182595, grad/param norm = 2.8230e-01, time/batch = 20.1430s	
17754/22750 (epoch 39.020), train_loss = 0.88338538, grad/param norm = 2.4950e-01, time/batch = 19.1655s	
17755/22750 (epoch 39.022), train_loss = 0.75724040, grad/param norm = 2.4716e-01, time/batch = 31.1114s	
17756/22750 (epoch 39.024), train_loss = 0.75365748, grad/param norm = 2.5021e-01, time/batch = 20.2354s	
17757/22750 (epoch 39.026), train_loss = 0.79928383, grad/param norm = 2.3604e-01, time/batch = 17.7328s	
17758/22750 (epoch 39.029), train_loss = 0.62544131, grad/param norm = 2.4077e-01, time/batch = 17.1586s	
17759/22750 (epoch 39.031), train_loss = 0.95456132, grad/param norm = 2.5237e-01, time/batch = 16.6063s	
17760/22750 (epoch 39.033), train_loss = 0.76773367, grad/param norm = 2.4024e-01, time/batch = 15.4438s	
17761/22750 (epoch 39.035), train_loss = 0.80810100, grad/param norm = 2.1535e-01, time/batch = 15.8499s	
17762/22750 (epoch 39.037), train_loss = 0.84770875, grad/param norm = 2.3043e-01, time/batch = 15.9411s	
17763/22750 (epoch 39.040), train_loss = 0.76580758, grad/param norm = 2.2466e-01, time/batch = 15.8555s	
17764/22750 (epoch 39.042), train_loss = 0.79308636, grad/param norm = 2.3552e-01, time/batch = 15.7817s	
17765/22750 (epoch 39.044), train_loss = 0.76006711, grad/param norm = 2.3193e-01, time/batch = 16.1197s	
17766/22750 (epoch 39.046), train_loss = 0.83394262, grad/param norm = 2.5241e-01, time/batch = 16.2625s	
17767/22750 (epoch 39.048), train_loss = 0.76200616, grad/param norm = 2.3592e-01, time/batch = 15.4553s	
17768/22750 (epoch 39.051), train_loss = 0.76621312, grad/param norm = 2.2892e-01, time/batch = 15.5248s	
17769/22750 (epoch 39.053), train_loss = 0.75605821, grad/param norm = 2.1711e-01, time/batch = 16.0127s	
17770/22750 (epoch 39.055), train_loss = 0.65651235, grad/param norm = 2.1430e-01, time/batch = 15.5252s	
17771/22750 (epoch 39.057), train_loss = 0.88351052, grad/param norm = 2.2197e-01, time/batch = 16.0037s	
17772/22750 (epoch 39.059), train_loss = 0.57282794, grad/param norm = 2.1860e-01, time/batch = 15.8437s	
17773/22750 (epoch 39.062), train_loss = 0.64618009, grad/param norm = 2.0553e-01, time/batch = 16.0838s	
17774/22750 (epoch 39.064), train_loss = 0.87018173, grad/param norm = 2.4773e-01, time/batch = 15.7740s	
17775/22750 (epoch 39.066), train_loss = 0.67075912, grad/param norm = 1.9364e-01, time/batch = 15.3899s	
17776/22750 (epoch 39.068), train_loss = 0.67474766, grad/param norm = 2.0456e-01, time/batch = 15.8770s	
17777/22750 (epoch 39.070), train_loss = 0.59395033, grad/param norm = 1.9226e-01, time/batch = 16.0102s	
17778/22750 (epoch 39.073), train_loss = 0.69545283, grad/param norm = 2.2583e-01, time/batch = 15.7068s	
17779/22750 (epoch 39.075), train_loss = 0.73814705, grad/param norm = 1.9901e-01, time/batch = 15.6175s	
17780/22750 (epoch 39.077), train_loss = 0.55681194, grad/param norm = 2.3128e-01, time/batch = 15.8516s	
17781/22750 (epoch 39.079), train_loss = 0.74128041, grad/param norm = 2.2894e-01, time/batch = 15.7701s	
17782/22750 (epoch 39.081), train_loss = 0.69749314, grad/param norm = 2.1094e-01, time/batch = 15.3625s	
17783/22750 (epoch 39.084), train_loss = 0.70075877, grad/param norm = 2.0980e-01, time/batch = 15.4312s	
17784/22750 (epoch 39.086), train_loss = 0.74344926, grad/param norm = 2.2020e-01, time/batch = 16.0908s	
17785/22750 (epoch 39.088), train_loss = 0.70175017, grad/param norm = 2.2584e-01, time/batch = 16.0002s	
17786/22750 (epoch 39.090), train_loss = 0.71562033, grad/param norm = 2.2206e-01, time/batch = 15.7214s	
17787/22750 (epoch 39.092), train_loss = 0.81257898, grad/param norm = 2.3583e-01, time/batch = 15.8028s	
17788/22750 (epoch 39.095), train_loss = 0.66886805, grad/param norm = 2.0881e-01, time/batch = 16.3540s	
17789/22750 (epoch 39.097), train_loss = 0.73726316, grad/param norm = 2.1632e-01, time/batch = 15.3862s	
17790/22750 (epoch 39.099), train_loss = 0.67394710, grad/param norm = 2.2905e-01, time/batch = 16.0857s	
17791/22750 (epoch 39.101), train_loss = 0.63042794, grad/param norm = 2.6624e-01, time/batch = 15.9239s	
17792/22750 (epoch 39.103), train_loss = 0.79379922, grad/param norm = 2.4116e-01, time/batch = 15.8510s	
17793/22750 (epoch 39.105), train_loss = 0.86937153, grad/param norm = 2.7523e-01, time/batch = 15.8626s	
17794/22750 (epoch 39.108), train_loss = 0.77819620, grad/param norm = 2.4249e-01, time/batch = 15.7601s	
17795/22750 (epoch 39.110), train_loss = 0.83745921, grad/param norm = 2.4705e-01, time/batch = 16.3309s	
17796/22750 (epoch 39.112), train_loss = 0.62224963, grad/param norm = 1.7170e-01, time/batch = 15.3756s	
17797/22750 (epoch 39.114), train_loss = 0.55310566, grad/param norm = 1.9866e-01, time/batch = 15.4723s	
17798/22750 (epoch 39.116), train_loss = 0.75639888, grad/param norm = 2.1414e-01, time/batch = 15.5477s	
17799/22750 (epoch 39.119), train_loss = 0.69430591, grad/param norm = 1.9547e-01, time/batch = 16.0295s	
17800/22750 (epoch 39.121), train_loss = 0.72524514, grad/param norm = 2.4521e-01, time/batch = 15.7182s	
17801/22750 (epoch 39.123), train_loss = 0.62651060, grad/param norm = 2.1127e-01, time/batch = 15.5411s	
17802/22750 (epoch 39.125), train_loss = 0.85263229, grad/param norm = 2.3033e-01, time/batch = 15.5286s	
17803/22750 (epoch 39.127), train_loss = 0.71797363, grad/param norm = 2.5859e-01, time/batch = 15.7660s	
17804/22750 (epoch 39.130), train_loss = 0.72255010, grad/param norm = 2.0486e-01, time/batch = 15.6823s	
17805/22750 (epoch 39.132), train_loss = 0.68781539, grad/param norm = 2.0360e-01, time/batch = 15.6831s	
17806/22750 (epoch 39.134), train_loss = 0.69678846, grad/param norm = 1.9823e-01, time/batch = 15.6032s	
17807/22750 (epoch 39.136), train_loss = 0.59107800, grad/param norm = 2.2663e-01, time/batch = 15.9288s	
17808/22750 (epoch 39.138), train_loss = 0.81095877, grad/param norm = 2.5304e-01, time/batch = 15.5534s	
17809/22750 (epoch 39.141), train_loss = 0.72913911, grad/param norm = 2.3802e-01, time/batch = 16.0592s	
17810/22750 (epoch 39.143), train_loss = 0.68397568, grad/param norm = 2.0044e-01, time/batch = 15.6238s	
17811/22750 (epoch 39.145), train_loss = 0.85143669, grad/param norm = 2.4434e-01, time/batch = 15.4526s	
17812/22750 (epoch 39.147), train_loss = 0.89111525, grad/param norm = 2.5000e-01, time/batch = 15.6026s	
17813/22750 (epoch 39.149), train_loss = 0.74814573, grad/param norm = 2.1998e-01, time/batch = 15.8359s	
17814/22750 (epoch 39.152), train_loss = 0.73518564, grad/param norm = 2.0870e-01, time/batch = 16.0084s	
17815/22750 (epoch 39.154), train_loss = 0.67176628, grad/param norm = 2.2459e-01, time/batch = 15.6877s	
17816/22750 (epoch 39.156), train_loss = 0.65496849, grad/param norm = 2.1004e-01, time/batch = 15.6221s	
17817/22750 (epoch 39.158), train_loss = 0.64536554, grad/param norm = 2.0882e-01, time/batch = 15.5316s	
17818/22750 (epoch 39.160), train_loss = 0.72962028, grad/param norm = 2.1621e-01, time/batch = 16.0166s	
17819/22750 (epoch 39.163), train_loss = 0.86528712, grad/param norm = 2.4112e-01, time/batch = 15.5544s	
17820/22750 (epoch 39.165), train_loss = 0.78570732, grad/param norm = 2.1565e-01, time/batch = 15.5521s	
17821/22750 (epoch 39.167), train_loss = 0.68129888, grad/param norm = 2.2911e-01, time/batch = 15.6338s	
17822/22750 (epoch 39.169), train_loss = 0.73937667, grad/param norm = 2.4184e-01, time/batch = 16.0714s	
17823/22750 (epoch 39.171), train_loss = 0.62964921, grad/param norm = 1.9593e-01, time/batch = 15.5116s	
17824/22750 (epoch 39.174), train_loss = 0.60777200, grad/param norm = 2.1429e-01, time/batch = 15.6754s	
17825/22750 (epoch 39.176), train_loss = 0.65080277, grad/param norm = 2.4037e-01, time/batch = 15.7768s	
17826/22750 (epoch 39.178), train_loss = 0.67773626, grad/param norm = 2.1471e-01, time/batch = 16.0167s	
17827/22750 (epoch 39.180), train_loss = 0.82324223, grad/param norm = 2.9500e-01, time/batch = 15.5957s	
17828/22750 (epoch 39.182), train_loss = 0.78409131, grad/param norm = 2.4061e-01, time/batch = 15.4410s	
17829/22750 (epoch 39.185), train_loss = 0.81007492, grad/param norm = 2.6684e-01, time/batch = 15.7847s	
17830/22750 (epoch 39.187), train_loss = 0.64974276, grad/param norm = 2.1549e-01, time/batch = 16.0242s	
17831/22750 (epoch 39.189), train_loss = 0.62985940, grad/param norm = 2.0862e-01, time/batch = 15.7794s	
17832/22750 (epoch 39.191), train_loss = 0.67641887, grad/param norm = 1.9618e-01, time/batch = 15.5502s	
17833/22750 (epoch 39.193), train_loss = 0.77165444, grad/param norm = 2.0611e-01, time/batch = 15.7732s	
17834/22750 (epoch 39.196), train_loss = 0.71201318, grad/param norm = 2.2915e-01, time/batch = 15.2976s	
17835/22750 (epoch 39.198), train_loss = 0.54981897, grad/param norm = 2.3001e-01, time/batch = 15.6006s	
17836/22750 (epoch 39.200), train_loss = 0.73128227, grad/param norm = 2.1006e-01, time/batch = 18.6656s	
17837/22750 (epoch 39.202), train_loss = 0.79005634, grad/param norm = 2.4746e-01, time/batch = 17.8143s	
17838/22750 (epoch 39.204), train_loss = 0.75300185, grad/param norm = 2.0473e-01, time/batch = 19.2582s	
17839/22750 (epoch 39.207), train_loss = 0.75042808, grad/param norm = 2.2313e-01, time/batch = 18.8581s	
17840/22750 (epoch 39.209), train_loss = 0.70168065, grad/param norm = 2.1190e-01, time/batch = 19.5245s	
17841/22750 (epoch 39.211), train_loss = 0.64304400, grad/param norm = 2.2714e-01, time/batch = 18.7733s	
17842/22750 (epoch 39.213), train_loss = 0.56863821, grad/param norm = 2.3468e-01, time/batch = 18.7741s	
17843/22750 (epoch 39.215), train_loss = 0.56688480, grad/param norm = 1.9151e-01, time/batch = 17.5759s	
17844/22750 (epoch 39.218), train_loss = 0.65594576, grad/param norm = 2.4938e-01, time/batch = 19.8353s	
17845/22750 (epoch 39.220), train_loss = 0.61021057, grad/param norm = 2.2066e-01, time/batch = 19.0792s	
17846/22750 (epoch 39.222), train_loss = 0.60449539, grad/param norm = 2.1975e-01, time/batch = 17.6726s	
17847/22750 (epoch 39.224), train_loss = 0.64808154, grad/param norm = 1.9702e-01, time/batch = 18.2441s	
17848/22750 (epoch 39.226), train_loss = 0.71163590, grad/param norm = 2.3104e-01, time/batch = 18.5879s	
17849/22750 (epoch 39.229), train_loss = 0.74608609, grad/param norm = 2.4847e-01, time/batch = 19.7031s	
17850/22750 (epoch 39.231), train_loss = 0.65786316, grad/param norm = 2.2389e-01, time/batch = 19.9200s	
17851/22750 (epoch 39.233), train_loss = 0.58129150, grad/param norm = 2.4216e-01, time/batch = 21.0526s	
17852/22750 (epoch 39.235), train_loss = 0.55834831, grad/param norm = 2.1863e-01, time/batch = 17.8214s	
17853/22750 (epoch 39.237), train_loss = 0.65384060, grad/param norm = 2.4387e-01, time/batch = 18.5838s	
17854/22750 (epoch 39.240), train_loss = 0.71867534, grad/param norm = 1.9808e-01, time/batch = 19.3264s	
17855/22750 (epoch 39.242), train_loss = 0.84394675, grad/param norm = 2.4863e-01, time/batch = 19.4995s	
17856/22750 (epoch 39.244), train_loss = 0.85749804, grad/param norm = 2.4636e-01, time/batch = 17.9243s	
17857/22750 (epoch 39.246), train_loss = 0.87554890, grad/param norm = 2.5196e-01, time/batch = 20.0262s	
17858/22750 (epoch 39.248), train_loss = 0.72520494, grad/param norm = 2.0315e-01, time/batch = 19.7703s	
17859/22750 (epoch 39.251), train_loss = 0.82508480, grad/param norm = 2.4484e-01, time/batch = 18.7672s	
17860/22750 (epoch 39.253), train_loss = 0.79660379, grad/param norm = 2.8722e-01, time/batch = 18.5940s	
17861/22750 (epoch 39.255), train_loss = 0.76990260, grad/param norm = 2.4109e-01, time/batch = 19.9178s	
17862/22750 (epoch 39.257), train_loss = 0.65780485, grad/param norm = 2.0595e-01, time/batch = 16.4909s	
17863/22750 (epoch 39.259), train_loss = 0.82482333, grad/param norm = 2.8184e-01, time/batch = 15.9960s	
17864/22750 (epoch 39.262), train_loss = 0.74915451, grad/param norm = 2.3640e-01, time/batch = 16.2578s	
17865/22750 (epoch 39.264), train_loss = 0.57888921, grad/param norm = 2.4381e-01, time/batch = 15.5509s	
17866/22750 (epoch 39.266), train_loss = 0.72383930, grad/param norm = 2.7580e-01, time/batch = 16.2440s	
17867/22750 (epoch 39.268), train_loss = 0.87150992, grad/param norm = 2.6934e-01, time/batch = 15.9940s	
17868/22750 (epoch 39.270), train_loss = 0.64838860, grad/param norm = 2.5844e-01, time/batch = 14.8351s	
17869/22750 (epoch 39.273), train_loss = 0.97680159, grad/param norm = 2.9924e-01, time/batch = 15.0680s	
17870/22750 (epoch 39.275), train_loss = 0.86015714, grad/param norm = 2.2617e-01, time/batch = 15.4566s	
17871/22750 (epoch 39.277), train_loss = 0.73895067, grad/param norm = 2.6293e-01, time/batch = 15.9976s	
17872/22750 (epoch 39.279), train_loss = 0.63100953, grad/param norm = 2.1754e-01, time/batch = 15.2046s	
17873/22750 (epoch 39.281), train_loss = 0.86840535, grad/param norm = 2.5863e-01, time/batch = 15.6095s	
17874/22750 (epoch 39.284), train_loss = 0.76802718, grad/param norm = 2.0418e-01, time/batch = 15.6955s	
17875/22750 (epoch 39.286), train_loss = 0.80826006, grad/param norm = 2.3855e-01, time/batch = 15.0471s	
17876/22750 (epoch 39.288), train_loss = 0.89693106, grad/param norm = 2.5888e-01, time/batch = 15.1319s	
17877/22750 (epoch 39.290), train_loss = 0.77991561, grad/param norm = 2.3141e-01, time/batch = 15.6171s	
17878/22750 (epoch 39.292), train_loss = 0.81618246, grad/param norm = 2.8713e-01, time/batch = 14.9683s	
17879/22750 (epoch 39.295), train_loss = 0.78638131, grad/param norm = 2.4074e-01, time/batch = 15.0811s	
17880/22750 (epoch 39.297), train_loss = 0.78414998, grad/param norm = 2.6123e-01, time/batch = 15.0724s	
17881/22750 (epoch 39.299), train_loss = 0.83174603, grad/param norm = 2.6006e-01, time/batch = 15.3772s	
17882/22750 (epoch 39.301), train_loss = 0.75082128, grad/param norm = 2.3546e-01, time/batch = 14.9661s	
17883/22750 (epoch 39.303), train_loss = 0.78728476, grad/param norm = 2.1894e-01, time/batch = 15.1357s	
17884/22750 (epoch 39.305), train_loss = 0.89559524, grad/param norm = 2.3488e-01, time/batch = 15.4539s	
17885/22750 (epoch 39.308), train_loss = 0.80304996, grad/param norm = 2.2178e-01, time/batch = 15.2755s	
17886/22750 (epoch 39.310), train_loss = 0.69146885, grad/param norm = 2.5831e-01, time/batch = 15.2100s	
17887/22750 (epoch 39.312), train_loss = 0.76561126, grad/param norm = 2.4225e-01, time/batch = 15.3714s	
17888/22750 (epoch 39.314), train_loss = 0.78339594, grad/param norm = 2.4004e-01, time/batch = 15.1521s	
17889/22750 (epoch 39.316), train_loss = 0.73541329, grad/param norm = 2.0588e-01, time/batch = 15.2208s	
17890/22750 (epoch 39.319), train_loss = 0.76823921, grad/param norm = 2.4635e-01, time/batch = 14.9153s	
17891/22750 (epoch 39.321), train_loss = 0.70356901, grad/param norm = 2.3071e-01, time/batch = 15.6165s	
17892/22750 (epoch 39.323), train_loss = 0.78441869, grad/param norm = 2.4782e-01, time/batch = 14.9747s	
17893/22750 (epoch 39.325), train_loss = 0.65604751, grad/param norm = 1.9850e-01, time/batch = 15.8565s	
17894/22750 (epoch 39.327), train_loss = 0.70362663, grad/param norm = 2.6656e-01, time/batch = 15.9263s	
17895/22750 (epoch 39.330), train_loss = 0.86545124, grad/param norm = 2.4431e-01, time/batch = 15.2928s	
17896/22750 (epoch 39.332), train_loss = 0.93803236, grad/param norm = 2.4243e-01, time/batch = 15.2918s	
17897/22750 (epoch 39.334), train_loss = 0.61323111, grad/param norm = 2.0315e-01, time/batch = 15.7641s	
17898/22750 (epoch 39.336), train_loss = 0.83039702, grad/param norm = 2.2198e-01, time/batch = 14.8807s	
17899/22750 (epoch 39.338), train_loss = 0.73973079, grad/param norm = 2.6859e-01, time/batch = 14.9748s	
17900/22750 (epoch 39.341), train_loss = 0.75945940, grad/param norm = 2.6480e-01, time/batch = 14.9935s	
17901/22750 (epoch 39.343), train_loss = 0.64998589, grad/param norm = 2.2261e-01, time/batch = 15.6952s	
17902/22750 (epoch 39.345), train_loss = 0.80642472, grad/param norm = 2.8319e-01, time/batch = 15.5399s	
17903/22750 (epoch 39.347), train_loss = 0.86010201, grad/param norm = 2.5781e-01, time/batch = 15.1420s	
17904/22750 (epoch 39.349), train_loss = 0.61728860, grad/param norm = 2.7353e-01, time/batch = 15.3604s	
17905/22750 (epoch 39.352), train_loss = 0.87570472, grad/param norm = 2.4613e-01, time/batch = 15.2939s	
17906/22750 (epoch 39.354), train_loss = 0.85753688, grad/param norm = 2.5655e-01, time/batch = 15.0324s	
17907/22750 (epoch 39.356), train_loss = 0.82740219, grad/param norm = 2.2227e-01, time/batch = 15.0449s	
17908/22750 (epoch 39.358), train_loss = 0.73411531, grad/param norm = 2.4707e-01, time/batch = 15.2047s	
17909/22750 (epoch 39.360), train_loss = 0.89779709, grad/param norm = 2.4256e-01, time/batch = 15.2898s	
17910/22750 (epoch 39.363), train_loss = 0.70379530, grad/param norm = 2.4285e-01, time/batch = 15.1402s	
17911/22750 (epoch 39.365), train_loss = 0.60838450, grad/param norm = 2.2090e-01, time/batch = 14.8264s	
17912/22750 (epoch 39.367), train_loss = 0.69905238, grad/param norm = 2.2687e-01, time/batch = 15.5415s	
17913/22750 (epoch 39.369), train_loss = 0.77910865, grad/param norm = 2.6253e-01, time/batch = 15.9411s	
17914/22750 (epoch 39.371), train_loss = 0.78574727, grad/param norm = 2.5956e-01, time/batch = 15.1337s	
17915/22750 (epoch 39.374), train_loss = 0.67647661, grad/param norm = 2.1804e-01, time/batch = 15.2823s	
17916/22750 (epoch 39.376), train_loss = 0.74497869, grad/param norm = 2.1394e-01, time/batch = 15.3720s	
17917/22750 (epoch 39.378), train_loss = 0.75951884, grad/param norm = 2.0822e-01, time/batch = 15.5359s	
17918/22750 (epoch 39.380), train_loss = 0.82322628, grad/param norm = 2.3871e-01, time/batch = 15.2057s	
17919/22750 (epoch 39.382), train_loss = 0.72639886, grad/param norm = 2.1675e-01, time/batch = 15.2884s	
17920/22750 (epoch 39.385), train_loss = 0.81935984, grad/param norm = 2.2186e-01, time/batch = 15.7024s	
17921/22750 (epoch 39.387), train_loss = 0.78619238, grad/param norm = 2.1802e-01, time/batch = 15.0576s	
17922/22750 (epoch 39.389), train_loss = 0.61306442, grad/param norm = 2.0325e-01, time/batch = 15.3131s	
17923/22750 (epoch 39.391), train_loss = 0.47582470, grad/param norm = 1.8374e-01, time/batch = 15.0825s	
17924/22750 (epoch 39.393), train_loss = 0.63391952, grad/param norm = 2.3534e-01, time/batch = 15.5468s	
17925/22750 (epoch 39.396), train_loss = 0.78220346, grad/param norm = 2.3515e-01, time/batch = 15.1312s	
17926/22750 (epoch 39.398), train_loss = 0.70933386, grad/param norm = 2.1517e-01, time/batch = 15.1320s	
17927/22750 (epoch 39.400), train_loss = 0.75540482, grad/param norm = 2.6862e-01, time/batch = 15.2080s	
17928/22750 (epoch 39.402), train_loss = 0.76368570, grad/param norm = 2.3246e-01, time/batch = 15.2060s	
17929/22750 (epoch 39.404), train_loss = 0.85644030, grad/param norm = 2.4973e-01, time/batch = 15.8295s	
17930/22750 (epoch 39.407), train_loss = 0.82909320, grad/param norm = 2.4277e-01, time/batch = 15.1364s	
17931/22750 (epoch 39.409), train_loss = 0.69565901, grad/param norm = 2.3458e-01, time/batch = 15.1568s	
17932/22750 (epoch 39.411), train_loss = 0.70370562, grad/param norm = 2.3088e-01, time/batch = 15.9534s	
17933/22750 (epoch 39.413), train_loss = 0.54482609, grad/param norm = 2.1793e-01, time/batch = 15.3958s	
17934/22750 (epoch 39.415), train_loss = 0.62307370, grad/param norm = 2.0690e-01, time/batch = 15.4026s	
17935/22750 (epoch 39.418), train_loss = 0.70832678, grad/param norm = 2.3552e-01, time/batch = 15.2229s	
17936/22750 (epoch 39.420), train_loss = 0.81276268, grad/param norm = 2.5116e-01, time/batch = 16.0115s	
17937/22750 (epoch 39.422), train_loss = 0.94534444, grad/param norm = 2.8691e-01, time/batch = 15.6045s	
17938/22750 (epoch 39.424), train_loss = 0.97716822, grad/param norm = 3.5094e-01, time/batch = 15.2134s	
17939/22750 (epoch 39.426), train_loss = 0.92095598, grad/param norm = 2.3649e-01, time/batch = 15.2959s	
17940/22750 (epoch 39.429), train_loss = 0.70077797, grad/param norm = 2.1269e-01, time/batch = 15.7603s	
17941/22750 (epoch 39.431), train_loss = 0.61192946, grad/param norm = 1.9348e-01, time/batch = 18.7597s	
17942/22750 (epoch 39.433), train_loss = 0.69832380, grad/param norm = 2.0667e-01, time/batch = 19.2940s	
17943/22750 (epoch 39.435), train_loss = 0.54063443, grad/param norm = 1.6220e-01, time/batch = 18.8555s	
17944/22750 (epoch 39.437), train_loss = 0.48826353, grad/param norm = 1.8192e-01, time/batch = 18.7970s	
17945/22750 (epoch 39.440), train_loss = 0.68971341, grad/param norm = 2.2990e-01, time/batch = 18.1052s	
17946/22750 (epoch 39.442), train_loss = 0.73250988, grad/param norm = 2.4813e-01, time/batch = 17.2799s	
17947/22750 (epoch 39.444), train_loss = 0.70597773, grad/param norm = 2.2841e-01, time/batch = 17.7749s	
17948/22750 (epoch 39.446), train_loss = 0.71732423, grad/param norm = 2.5882e-01, time/batch = 19.0910s	
17949/22750 (epoch 39.448), train_loss = 0.94073901, grad/param norm = 2.5269e-01, time/batch = 18.0139s	
17950/22750 (epoch 39.451), train_loss = 0.90656418, grad/param norm = 2.2646e-01, time/batch = 16.0053s	
17951/22750 (epoch 39.453), train_loss = 0.78361723, grad/param norm = 2.4569e-01, time/batch = 19.1984s	
17952/22750 (epoch 39.455), train_loss = 0.90580093, grad/param norm = 2.4779e-01, time/batch = 19.4144s	
17953/22750 (epoch 39.457), train_loss = 0.79630945, grad/param norm = 3.5403e-01, time/batch = 19.1054s	
17954/22750 (epoch 39.459), train_loss = 0.81543050, grad/param norm = 2.3054e-01, time/batch = 18.7848s	
17955/22750 (epoch 39.462), train_loss = 0.76693074, grad/param norm = 2.1291e-01, time/batch = 19.4959s	
17956/22750 (epoch 39.464), train_loss = 0.64841583, grad/param norm = 2.1790e-01, time/batch = 12.6443s	
17957/22750 (epoch 39.466), train_loss = 0.81714448, grad/param norm = 2.9383e-01, time/batch = 0.7179s	
17958/22750 (epoch 39.468), train_loss = 0.79066363, grad/param norm = 2.4586e-01, time/batch = 0.7077s	
17959/22750 (epoch 39.470), train_loss = 0.86299508, grad/param norm = 2.5813e-01, time/batch = 0.6995s	
17960/22750 (epoch 39.473), train_loss = 0.72757907, grad/param norm = 2.1773e-01, time/batch = 0.7276s	
17961/22750 (epoch 39.475), train_loss = 0.78558892, grad/param norm = 2.4623e-01, time/batch = 0.7165s	
17962/22750 (epoch 39.477), train_loss = 0.65624672, grad/param norm = 2.2540e-01, time/batch = 0.7053s	
17963/22750 (epoch 39.479), train_loss = 0.64451004, grad/param norm = 2.0139e-01, time/batch = 0.8359s	
17964/22750 (epoch 39.481), train_loss = 0.61173198, grad/param norm = 1.9385e-01, time/batch = 1.0318s	
17965/22750 (epoch 39.484), train_loss = 0.51234824, grad/param norm = 2.2500e-01, time/batch = 1.0319s	
17966/22750 (epoch 39.486), train_loss = 0.63468873, grad/param norm = 2.3502e-01, time/batch = 1.0654s	
17967/22750 (epoch 39.488), train_loss = 0.57080009, grad/param norm = 2.1284e-01, time/batch = 1.0487s	
17968/22750 (epoch 39.490), train_loss = 0.73752480, grad/param norm = 2.2531e-01, time/batch = 1.5058s	
17969/22750 (epoch 39.492), train_loss = 0.81987654, grad/param norm = 2.3924e-01, time/batch = 1.8985s	
17970/22750 (epoch 39.495), train_loss = 0.67414330, grad/param norm = 2.6375e-01, time/batch = 1.9156s	
17971/22750 (epoch 39.497), train_loss = 0.71618160, grad/param norm = 2.3858e-01, time/batch = 18.0366s	
17972/22750 (epoch 39.499), train_loss = 0.65430867, grad/param norm = 2.2752e-01, time/batch = 18.6807s	
17973/22750 (epoch 39.501), train_loss = 0.71058920, grad/param norm = 2.5277e-01, time/batch = 18.5006s	
17974/22750 (epoch 39.503), train_loss = 0.70839680, grad/param norm = 2.4028e-01, time/batch = 19.4513s	
17975/22750 (epoch 39.505), train_loss = 0.63194063, grad/param norm = 2.2374e-01, time/batch = 19.4578s	
17976/22750 (epoch 39.508), train_loss = 0.59951922, grad/param norm = 2.2493e-01, time/batch = 18.7685s	
17977/22750 (epoch 39.510), train_loss = 0.63650914, grad/param norm = 2.2879e-01, time/batch = 17.5021s	
17978/22750 (epoch 39.512), train_loss = 0.67097101, grad/param norm = 2.2627e-01, time/batch = 18.0181s	
17979/22750 (epoch 39.514), train_loss = 0.68887271, grad/param norm = 2.4037e-01, time/batch = 18.2505s	
17980/22750 (epoch 39.516), train_loss = 0.66401826, grad/param norm = 2.2035e-01, time/batch = 17.2616s	
17981/22750 (epoch 39.519), train_loss = 0.82327853, grad/param norm = 2.8012e-01, time/batch = 18.9236s	
17982/22750 (epoch 39.521), train_loss = 0.72904730, grad/param norm = 2.2579e-01, time/batch = 16.8235s	
17983/22750 (epoch 39.523), train_loss = 0.65100468, grad/param norm = 2.4264e-01, time/batch = 19.4411s	
17984/22750 (epoch 39.525), train_loss = 0.84524282, grad/param norm = 2.6467e-01, time/batch = 18.9652s	
17985/22750 (epoch 39.527), train_loss = 0.76778138, grad/param norm = 2.2864e-01, time/batch = 16.7069s	
17986/22750 (epoch 39.530), train_loss = 0.66257628, grad/param norm = 2.1737e-01, time/batch = 30.6820s	
17987/22750 (epoch 39.532), train_loss = 0.63338421, grad/param norm = 2.5400e-01, time/batch = 17.6876s	
17988/22750 (epoch 39.534), train_loss = 0.81668489, grad/param norm = 2.7960e-01, time/batch = 18.0114s	
17989/22750 (epoch 39.536), train_loss = 0.76386901, grad/param norm = 2.0247e-01, time/batch = 18.4374s	
17990/22750 (epoch 39.538), train_loss = 0.74241661, grad/param norm = 2.0117e-01, time/batch = 19.3279s	
17991/22750 (epoch 39.541), train_loss = 0.64797205, grad/param norm = 2.1938e-01, time/batch = 19.5010s	
17992/22750 (epoch 39.543), train_loss = 0.63311363, grad/param norm = 2.2704e-01, time/batch = 18.1958s	
17993/22750 (epoch 39.545), train_loss = 0.79476864, grad/param norm = 2.3668e-01, time/batch = 20.1814s	
17994/22750 (epoch 39.547), train_loss = 0.68440690, grad/param norm = 1.8998e-01, time/batch = 20.1874s	
17995/22750 (epoch 39.549), train_loss = 0.70276787, grad/param norm = 2.4881e-01, time/batch = 16.5198s	
17996/22750 (epoch 39.552), train_loss = 0.77074765, grad/param norm = 2.2083e-01, time/batch = 19.7288s	
17997/22750 (epoch 39.554), train_loss = 0.80624703, grad/param norm = 2.6415e-01, time/batch = 19.1821s	
17998/22750 (epoch 39.556), train_loss = 0.78519959, grad/param norm = 2.3151e-01, time/batch = 18.1612s	
17999/22750 (epoch 39.558), train_loss = 0.73175262, grad/param norm = 2.3225e-01, time/batch = 18.3216s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_wakata_epoch39.56_1.7641.t7	
18000/22750 (epoch 39.560), train_loss = 0.69143770, grad/param norm = 2.1483e-01, time/batch = 18.0867s	
18001/22750 (epoch 39.563), train_loss = 1.60339862, grad/param norm = 4.2442e-01, time/batch = 19.9897s	
18002/22750 (epoch 39.565), train_loss = 0.82255061, grad/param norm = 3.0061e-01, time/batch = 18.6700s	
18003/22750 (epoch 39.567), train_loss = 0.78131331, grad/param norm = 2.6844e-01, time/batch = 19.4846s	
18004/22750 (epoch 39.569), train_loss = 0.72644561, grad/param norm = 2.3764e-01, time/batch = 19.6840s	
18005/22750 (epoch 39.571), train_loss = 0.73817129, grad/param norm = 2.5974e-01, time/batch = 18.6827s	
18006/22750 (epoch 39.574), train_loss = 0.75352186, grad/param norm = 2.2733e-01, time/batch = 19.5240s	
18007/22750 (epoch 39.576), train_loss = 0.71527794, grad/param norm = 2.3717e-01, time/batch = 19.1810s	
18008/22750 (epoch 39.578), train_loss = 0.64728672, grad/param norm = 2.4118e-01, time/batch = 18.7410s	
18009/22750 (epoch 39.580), train_loss = 0.78359804, grad/param norm = 2.4188e-01, time/batch = 19.3254s	
18010/22750 (epoch 39.582), train_loss = 0.64276137, grad/param norm = 1.9967e-01, time/batch = 19.9894s	
18011/22750 (epoch 39.585), train_loss = 0.62540879, grad/param norm = 2.0670e-01, time/batch = 18.9115s	
18012/22750 (epoch 39.587), train_loss = 0.65182932, grad/param norm = 1.9302e-01, time/batch = 19.2552s	
18013/22750 (epoch 39.589), train_loss = 0.55154785, grad/param norm = 1.8504e-01, time/batch = 19.1156s	
18014/22750 (epoch 39.591), train_loss = 0.72100164, grad/param norm = 2.0654e-01, time/batch = 19.0230s	
18015/22750 (epoch 39.593), train_loss = 0.84253380, grad/param norm = 2.4723e-01, time/batch = 19.3722s	
18016/22750 (epoch 39.596), train_loss = 0.79932146, grad/param norm = 2.1665e-01, time/batch = 18.0253s	
18017/22750 (epoch 39.598), train_loss = 0.83777366, grad/param norm = 3.0411e-01, time/batch = 19.3239s	
18018/22750 (epoch 39.600), train_loss = 0.86695420, grad/param norm = 2.6273e-01, time/batch = 18.5701s	
18019/22750 (epoch 39.602), train_loss = 0.67142980, grad/param norm = 2.3432e-01, time/batch = 18.4925s	
18020/22750 (epoch 39.604), train_loss = 0.70176543, grad/param norm = 2.3337e-01, time/batch = 16.6876s	
18021/22750 (epoch 39.607), train_loss = 0.64304067, grad/param norm = 1.9831e-01, time/batch = 15.2000s	
18022/22750 (epoch 39.609), train_loss = 0.60974597, grad/param norm = 2.2432e-01, time/batch = 16.4031s	
18023/22750 (epoch 39.611), train_loss = 0.69319865, grad/param norm = 2.3429e-01, time/batch = 19.6045s	
18024/22750 (epoch 39.613), train_loss = 0.66000544, grad/param norm = 2.0886e-01, time/batch = 16.6755s	
18025/22750 (epoch 39.615), train_loss = 0.67260462, grad/param norm = 1.7577e-01, time/batch = 16.7770s	
18026/22750 (epoch 39.618), train_loss = 0.72036072, grad/param norm = 2.1859e-01, time/batch = 17.6711s	
18027/22750 (epoch 39.620), train_loss = 0.71580584, grad/param norm = 2.4618e-01, time/batch = 18.1625s	
18028/22750 (epoch 39.622), train_loss = 0.60349624, grad/param norm = 1.8298e-01, time/batch = 18.0549s	
18029/22750 (epoch 39.624), train_loss = 0.68391593, grad/param norm = 2.5276e-01, time/batch = 18.5853s	
18030/22750 (epoch 39.626), train_loss = 0.57218682, grad/param norm = 2.0063e-01, time/batch = 17.6570s	
18031/22750 (epoch 39.629), train_loss = 0.66834646, grad/param norm = 2.2128e-01, time/batch = 17.3599s	
18032/22750 (epoch 39.631), train_loss = 0.71109111, grad/param norm = 2.0294e-01, time/batch = 17.8613s	
18033/22750 (epoch 39.633), train_loss = 0.61585576, grad/param norm = 2.1001e-01, time/batch = 16.7117s	
18034/22750 (epoch 39.635), train_loss = 0.70940788, grad/param norm = 2.1315e-01, time/batch = 19.6650s	
18035/22750 (epoch 39.637), train_loss = 0.77265673, grad/param norm = 3.0232e-01, time/batch = 17.3459s	
18036/22750 (epoch 39.640), train_loss = 0.78314632, grad/param norm = 2.2630e-01, time/batch = 17.4379s	
18037/22750 (epoch 39.642), train_loss = 0.81402592, grad/param norm = 2.4339e-01, time/batch = 17.8245s	
18038/22750 (epoch 39.644), train_loss = 0.73386191, grad/param norm = 2.5919e-01, time/batch = 16.9258s	
18039/22750 (epoch 39.646), train_loss = 0.79735611, grad/param norm = 3.0235e-01, time/batch = 16.9954s	
18040/22750 (epoch 39.648), train_loss = 0.76688040, grad/param norm = 2.3778e-01, time/batch = 18.5181s	
18041/22750 (epoch 39.651), train_loss = 0.77580934, grad/param norm = 2.4853e-01, time/batch = 18.0228s	
18042/22750 (epoch 39.653), train_loss = 0.80058355, grad/param norm = 2.0708e-01, time/batch = 19.7627s	
18043/22750 (epoch 39.655), train_loss = 0.73145583, grad/param norm = 2.0414e-01, time/batch = 18.5243s	
18044/22750 (epoch 39.657), train_loss = 0.84897544, grad/param norm = 2.4788e-01, time/batch = 18.0098s	
18045/22750 (epoch 39.659), train_loss = 0.89776904, grad/param norm = 2.4884e-01, time/batch = 16.8484s	
18046/22750 (epoch 39.662), train_loss = 0.87002082, grad/param norm = 2.4099e-01, time/batch = 18.5083s	
18047/22750 (epoch 39.664), train_loss = 0.78501368, grad/param norm = 2.4621e-01, time/batch = 18.5056s	
18048/22750 (epoch 39.666), train_loss = 0.63581857, grad/param norm = 1.9987e-01, time/batch = 18.0912s	
18049/22750 (epoch 39.668), train_loss = 0.71186955, grad/param norm = 2.0935e-01, time/batch = 18.0044s	
18050/22750 (epoch 39.670), train_loss = 0.69060745, grad/param norm = 2.3459e-01, time/batch = 17.8533s	
18051/22750 (epoch 39.673), train_loss = 0.90123767, grad/param norm = 2.8551e-01, time/batch = 17.4448s	
18052/22750 (epoch 39.675), train_loss = 1.00872271, grad/param norm = 3.1123e-01, time/batch = 17.4996s	
18053/22750 (epoch 39.677), train_loss = 0.87680327, grad/param norm = 2.5992e-01, time/batch = 18.5743s	
18054/22750 (epoch 39.679), train_loss = 0.87629316, grad/param norm = 2.9955e-01, time/batch = 17.2498s	
18055/22750 (epoch 39.681), train_loss = 0.88525575, grad/param norm = 2.9160e-01, time/batch = 16.5080s	
18056/22750 (epoch 39.684), train_loss = 0.89275603, grad/param norm = 2.7726e-01, time/batch = 18.6630s	
18057/22750 (epoch 39.686), train_loss = 0.93122650, grad/param norm = 2.4090e-01, time/batch = 17.6021s	
18058/22750 (epoch 39.688), train_loss = 0.86992847, grad/param norm = 2.5119e-01, time/batch = 18.1099s	
18059/22750 (epoch 39.690), train_loss = 0.88279752, grad/param norm = 3.0071e-01, time/batch = 18.6772s	
18060/22750 (epoch 39.692), train_loss = 0.86787699, grad/param norm = 2.5813e-01, time/batch = 20.1185s	
18061/22750 (epoch 39.695), train_loss = 0.76461023, grad/param norm = 2.1441e-01, time/batch = 19.0905s	
18062/22750 (epoch 39.697), train_loss = 0.77866936, grad/param norm = 2.1329e-01, time/batch = 18.3592s	
18063/22750 (epoch 39.699), train_loss = 0.69588580, grad/param norm = 2.0539e-01, time/batch = 18.4333s	
18064/22750 (epoch 39.701), train_loss = 0.63446317, grad/param norm = 2.4584e-01, time/batch = 17.0827s	
18065/22750 (epoch 39.703), train_loss = 0.71617606, grad/param norm = 2.3146e-01, time/batch = 19.2501s	
18066/22750 (epoch 39.705), train_loss = 0.69591883, grad/param norm = 2.0939e-01, time/batch = 18.7450s	
18067/22750 (epoch 39.708), train_loss = 0.76564698, grad/param norm = 2.6964e-01, time/batch = 18.6628s	
18068/22750 (epoch 39.710), train_loss = 0.65767092, grad/param norm = 2.1832e-01, time/batch = 18.2772s	
18069/22750 (epoch 39.712), train_loss = 0.59751373, grad/param norm = 2.5832e-01, time/batch = 19.5179s	
18070/22750 (epoch 39.714), train_loss = 0.62598115, grad/param norm = 1.9794e-01, time/batch = 18.1844s	
18071/22750 (epoch 39.716), train_loss = 0.64101725, grad/param norm = 1.9681e-01, time/batch = 17.1786s	
18072/22750 (epoch 39.719), train_loss = 0.71061578, grad/param norm = 3.0388e-01, time/batch = 19.8258s	
18073/22750 (epoch 39.721), train_loss = 0.83444575, grad/param norm = 2.5685e-01, time/batch = 18.5154s	
18074/22750 (epoch 39.723), train_loss = 0.81560227, grad/param norm = 2.6273e-01, time/batch = 18.2408s	
18075/22750 (epoch 39.725), train_loss = 0.70438361, grad/param norm = 2.3907e-01, time/batch = 17.9209s	
18076/22750 (epoch 39.727), train_loss = 0.73665570, grad/param norm = 2.4450e-01, time/batch = 20.3234s	
18077/22750 (epoch 39.730), train_loss = 0.70523868, grad/param norm = 2.3019e-01, time/batch = 17.4396s	
18078/22750 (epoch 39.732), train_loss = 0.67609374, grad/param norm = 2.0525e-01, time/batch = 19.2670s	
18079/22750 (epoch 39.734), train_loss = 0.61716217, grad/param norm = 1.9277e-01, time/batch = 19.2692s	
18080/22750 (epoch 39.736), train_loss = 0.69780074, grad/param norm = 2.2050e-01, time/batch = 18.1860s	
18081/22750 (epoch 39.738), train_loss = 0.78041630, grad/param norm = 2.5907e-01, time/batch = 17.0030s	
18082/22750 (epoch 39.741), train_loss = 0.85827312, grad/param norm = 2.2896e-01, time/batch = 16.6028s	
18083/22750 (epoch 39.743), train_loss = 0.75607218, grad/param norm = 2.1918e-01, time/batch = 16.7578s	
18084/22750 (epoch 39.745), train_loss = 0.61023688, grad/param norm = 1.8490e-01, time/batch = 16.3462s	
18085/22750 (epoch 39.747), train_loss = 0.72944906, grad/param norm = 1.9711e-01, time/batch = 16.7679s	
18086/22750 (epoch 39.749), train_loss = 0.82699098, grad/param norm = 2.3869e-01, time/batch = 16.8335s	
18087/22750 (epoch 39.752), train_loss = 0.74861549, grad/param norm = 2.5636e-01, time/batch = 16.6427s	
18088/22750 (epoch 39.754), train_loss = 0.74377897, grad/param norm = 2.2882e-01, time/batch = 16.8262s	
18089/22750 (epoch 39.756), train_loss = 0.68024892, grad/param norm = 2.3054e-01, time/batch = 20.0081s	
18090/22750 (epoch 39.758), train_loss = 0.66207943, grad/param norm = 1.9520e-01, time/batch = 17.7747s	
18091/22750 (epoch 39.760), train_loss = 0.65459099, grad/param norm = 2.1497e-01, time/batch = 18.0841s	
18092/22750 (epoch 39.763), train_loss = 0.72510568, grad/param norm = 2.2689e-01, time/batch = 17.8978s	
18093/22750 (epoch 39.765), train_loss = 0.71176406, grad/param norm = 2.2320e-01, time/batch = 17.0065s	
18094/22750 (epoch 39.767), train_loss = 0.76464442, grad/param norm = 1.9543e-01, time/batch = 16.9945s	
18095/22750 (epoch 39.769), train_loss = 0.86369405, grad/param norm = 2.9491e-01, time/batch = 17.9174s	
18096/22750 (epoch 39.771), train_loss = 0.88363813, grad/param norm = 2.7623e-01, time/batch = 17.9967s	
18097/22750 (epoch 39.774), train_loss = 0.68553353, grad/param norm = 2.4698e-01, time/batch = 18.7744s	
18098/22750 (epoch 39.776), train_loss = 0.82743108, grad/param norm = 2.5183e-01, time/batch = 18.0158s	
18099/22750 (epoch 39.778), train_loss = 0.85891382, grad/param norm = 2.4184e-01, time/batch = 18.5012s	
18100/22750 (epoch 39.780), train_loss = 0.77215218, grad/param norm = 2.2954e-01, time/batch = 18.7346s	
18101/22750 (epoch 39.782), train_loss = 0.87473873, grad/param norm = 2.4878e-01, time/batch = 17.4256s	
18102/22750 (epoch 39.785), train_loss = 0.72842048, grad/param norm = 2.4746e-01, time/batch = 18.7392s	
18103/22750 (epoch 39.787), train_loss = 0.62358679, grad/param norm = 2.3486e-01, time/batch = 18.9146s	
18104/22750 (epoch 39.789), train_loss = 0.71823494, grad/param norm = 2.0847e-01, time/batch = 18.0925s	
18105/22750 (epoch 39.791), train_loss = 0.69867141, grad/param norm = 2.2227e-01, time/batch = 19.7328s	
18106/22750 (epoch 39.793), train_loss = 0.68720211, grad/param norm = 3.0850e-01, time/batch = 19.6922s	
18107/22750 (epoch 39.796), train_loss = 0.61941034, grad/param norm = 2.0319e-01, time/batch = 16.1015s	
18108/22750 (epoch 39.798), train_loss = 0.67381278, grad/param norm = 2.0738e-01, time/batch = 19.0070s	
18109/22750 (epoch 39.800), train_loss = 0.67891281, grad/param norm = 2.3561e-01, time/batch = 19.7332s	
18110/22750 (epoch 39.802), train_loss = 0.63305897, grad/param norm = 2.4284e-01, time/batch = 18.1592s	
18111/22750 (epoch 39.804), train_loss = 0.80690896, grad/param norm = 2.3985e-01, time/batch = 17.8437s	
18112/22750 (epoch 39.807), train_loss = 0.78714939, grad/param norm = 2.5686e-01, time/batch = 18.6616s	
18113/22750 (epoch 39.809), train_loss = 0.87207246, grad/param norm = 2.5590e-01, time/batch = 18.4947s	
18114/22750 (epoch 39.811), train_loss = 0.72998457, grad/param norm = 2.1703e-01, time/batch = 19.1549s	
18115/22750 (epoch 39.813), train_loss = 0.77443705, grad/param norm = 2.6490e-01, time/batch = 19.7652s	
18116/22750 (epoch 39.815), train_loss = 0.86758435, grad/param norm = 2.3859e-01, time/batch = 19.6814s	
18117/22750 (epoch 39.818), train_loss = 0.82314221, grad/param norm = 2.3466e-01, time/batch = 18.1738s	
18118/22750 (epoch 39.820), train_loss = 0.94204839, grad/param norm = 2.3912e-01, time/batch = 18.3527s	
18119/22750 (epoch 39.822), train_loss = 0.78603562, grad/param norm = 2.4203e-01, time/batch = 16.9087s	
18120/22750 (epoch 39.824), train_loss = 0.64842899, grad/param norm = 1.9237e-01, time/batch = 18.3977s	
18121/22750 (epoch 39.826), train_loss = 0.75602980, grad/param norm = 2.3742e-01, time/batch = 18.6519s	
18122/22750 (epoch 39.829), train_loss = 0.84196204, grad/param norm = 2.5259e-01, time/batch = 18.9962s	
18123/22750 (epoch 39.831), train_loss = 0.83129157, grad/param norm = 3.2079e-01, time/batch = 18.1963s	
18124/22750 (epoch 39.833), train_loss = 0.76872695, grad/param norm = 2.4918e-01, time/batch = 20.1124s	
18125/22750 (epoch 39.835), train_loss = 0.66813029, grad/param norm = 2.5081e-01, time/batch = 20.0254s	
18126/22750 (epoch 39.837), train_loss = 0.71663059, grad/param norm = 2.4957e-01, time/batch = 19.1593s	
18127/22750 (epoch 39.840), train_loss = 0.67753421, grad/param norm = 2.3280e-01, time/batch = 18.8943s	
18128/22750 (epoch 39.842), train_loss = 0.68487137, grad/param norm = 2.6620e-01, time/batch = 15.9518s	
18129/22750 (epoch 39.844), train_loss = 0.75169413, grad/param norm = 2.4738e-01, time/batch = 16.7463s	
18130/22750 (epoch 39.846), train_loss = 0.79855585, grad/param norm = 2.0921e-01, time/batch = 19.2531s	
18131/22750 (epoch 39.848), train_loss = 0.68580149, grad/param norm = 2.0609e-01, time/batch = 19.9899s	
18132/22750 (epoch 39.851), train_loss = 0.67512439, grad/param norm = 2.3533e-01, time/batch = 19.6989s	
18133/22750 (epoch 39.853), train_loss = 0.85420904, grad/param norm = 2.2989e-01, time/batch = 20.0111s	
18134/22750 (epoch 39.855), train_loss = 0.69884515, grad/param norm = 1.9435e-01, time/batch = 21.1044s	
18135/22750 (epoch 39.857), train_loss = 0.78837555, grad/param norm = 2.0461e-01, time/batch = 19.2464s	
18136/22750 (epoch 39.859), train_loss = 0.75998146, grad/param norm = 2.3207e-01, time/batch = 18.0881s	
18137/22750 (epoch 39.862), train_loss = 0.91027601, grad/param norm = 2.9118e-01, time/batch = 17.2227s	
18138/22750 (epoch 39.864), train_loss = 0.75477605, grad/param norm = 2.1262e-01, time/batch = 18.3223s	
18139/22750 (epoch 39.866), train_loss = 0.80424194, grad/param norm = 2.3198e-01, time/batch = 17.3148s	
18140/22750 (epoch 39.868), train_loss = 0.67023925, grad/param norm = 2.2111e-01, time/batch = 20.8195s	
18141/22750 (epoch 39.870), train_loss = 0.65763857, grad/param norm = 2.3483e-01, time/batch = 20.4997s	
18142/22750 (epoch 39.873), train_loss = 0.73455587, grad/param norm = 2.2044e-01, time/batch = 16.0004s	
18143/22750 (epoch 39.875), train_loss = 0.78061022, grad/param norm = 2.1864e-01, time/batch = 20.7699s	
18144/22750 (epoch 39.877), train_loss = 0.69220870, grad/param norm = 2.1707e-01, time/batch = 17.9276s	
18145/22750 (epoch 39.879), train_loss = 0.82930277, grad/param norm = 2.3365e-01, time/batch = 16.6853s	
18146/22750 (epoch 39.881), train_loss = 0.77556995, grad/param norm = 2.4000e-01, time/batch = 18.8207s	
18147/22750 (epoch 39.884), train_loss = 0.67100889, grad/param norm = 2.0227e-01, time/batch = 20.1655s	
18148/22750 (epoch 39.886), train_loss = 0.77015014, grad/param norm = 2.1566e-01, time/batch = 19.2401s	
18149/22750 (epoch 39.888), train_loss = 0.80053227, grad/param norm = 2.1991e-01, time/batch = 17.8128s	
18150/22750 (epoch 39.890), train_loss = 0.80415337, grad/param norm = 2.4808e-01, time/batch = 20.8365s	
18151/22750 (epoch 39.892), train_loss = 0.99170440, grad/param norm = 2.6749e-01, time/batch = 19.1202s	
18152/22750 (epoch 39.895), train_loss = 0.71718662, grad/param norm = 2.4389e-01, time/batch = 18.5325s	
18153/22750 (epoch 39.897), train_loss = 0.84732706, grad/param norm = 2.4243e-01, time/batch = 19.7472s	
18154/22750 (epoch 39.899), train_loss = 0.77960955, grad/param norm = 2.4152e-01, time/batch = 19.0849s	
18155/22750 (epoch 39.901), train_loss = 0.82286058, grad/param norm = 2.5120e-01, time/batch = 18.5117s	
18156/22750 (epoch 39.903), train_loss = 0.73683264, grad/param norm = 2.6310e-01, time/batch = 18.6563s	
18157/22750 (epoch 39.905), train_loss = 0.81224026, grad/param norm = 2.3101e-01, time/batch = 19.9076s	
18158/22750 (epoch 39.908), train_loss = 0.63205756, grad/param norm = 2.1316e-01, time/batch = 18.3127s	
18159/22750 (epoch 39.910), train_loss = 0.58976959, grad/param norm = 2.4643e-01, time/batch = 18.6079s	
18160/22750 (epoch 39.912), train_loss = 0.72982550, grad/param norm = 2.5259e-01, time/batch = 19.4528s	
18161/22750 (epoch 39.914), train_loss = 0.74843824, grad/param norm = 2.2205e-01, time/batch = 18.6872s	
18162/22750 (epoch 39.916), train_loss = 0.59771151, grad/param norm = 1.9989e-01, time/batch = 18.6508s	
18163/22750 (epoch 39.919), train_loss = 0.72892899, grad/param norm = 2.5096e-01, time/batch = 19.1659s	
18164/22750 (epoch 39.921), train_loss = 0.57754595, grad/param norm = 1.8592e-01, time/batch = 17.8383s	
18165/22750 (epoch 39.923), train_loss = 0.68836541, grad/param norm = 2.1885e-01, time/batch = 17.4093s	
18166/22750 (epoch 39.925), train_loss = 0.73593363, grad/param norm = 2.0415e-01, time/batch = 19.9902s	
18167/22750 (epoch 39.927), train_loss = 0.60002248, grad/param norm = 2.0887e-01, time/batch = 17.5167s	
18168/22750 (epoch 39.930), train_loss = 0.55831163, grad/param norm = 1.8980e-01, time/batch = 19.1600s	
18169/22750 (epoch 39.932), train_loss = 0.71066022, grad/param norm = 2.1932e-01, time/batch = 19.3721s	
18170/22750 (epoch 39.934), train_loss = 0.61517248, grad/param norm = 1.9844e-01, time/batch = 19.2785s	
18171/22750 (epoch 39.936), train_loss = 0.82764672, grad/param norm = 2.3496e-01, time/batch = 18.9566s	
18172/22750 (epoch 39.938), train_loss = 0.82698613, grad/param norm = 2.0615e-01, time/batch = 18.3365s	
18173/22750 (epoch 39.941), train_loss = 0.86546720, grad/param norm = 2.5883e-01, time/batch = 20.3950s	
18174/22750 (epoch 39.943), train_loss = 0.74782254, grad/param norm = 2.0960e-01, time/batch = 29.2284s	
18175/22750 (epoch 39.945), train_loss = 0.77178335, grad/param norm = 2.1833e-01, time/batch = 15.6774s	
18176/22750 (epoch 39.947), train_loss = 0.68236739, grad/param norm = 2.2434e-01, time/batch = 16.0675s	
18177/22750 (epoch 39.949), train_loss = 0.70165985, grad/param norm = 2.4539e-01, time/batch = 16.0022s	
18178/22750 (epoch 39.952), train_loss = 0.69878578, grad/param norm = 2.2563e-01, time/batch = 15.6053s	
18179/22750 (epoch 39.954), train_loss = 0.63937153, grad/param norm = 2.3260e-01, time/batch = 15.5245s	
18180/22750 (epoch 39.956), train_loss = 0.80132925, grad/param norm = 2.4723e-01, time/batch = 16.5496s	
18181/22750 (epoch 39.958), train_loss = 0.65277875, grad/param norm = 1.9430e-01, time/batch = 16.1505s	
18182/22750 (epoch 39.960), train_loss = 0.64536417, grad/param norm = 2.0295e-01, time/batch = 15.9018s	
18183/22750 (epoch 39.963), train_loss = 0.74995682, grad/param norm = 2.2047e-01, time/batch = 15.7495s	
18184/22750 (epoch 39.965), train_loss = 0.80797568, grad/param norm = 2.1609e-01, time/batch = 16.0633s	
18185/22750 (epoch 39.967), train_loss = 0.77337110, grad/param norm = 2.2095e-01, time/batch = 15.9898s	
18186/22750 (epoch 39.969), train_loss = 0.70564544, grad/param norm = 2.3972e-01, time/batch = 16.0813s	
18187/22750 (epoch 39.971), train_loss = 0.67799942, grad/param norm = 2.1063e-01, time/batch = 16.1511s	
18188/22750 (epoch 39.974), train_loss = 0.66712564, grad/param norm = 2.0612e-01, time/batch = 16.6367s	
18189/22750 (epoch 39.976), train_loss = 0.69173074, grad/param norm = 2.4056e-01, time/batch = 16.0797s	
18190/22750 (epoch 39.978), train_loss = 0.67116625, grad/param norm = 2.1979e-01, time/batch = 16.3383s	
18191/22750 (epoch 39.980), train_loss = 0.85006782, grad/param norm = 2.5484e-01, time/batch = 16.4199s	
18192/22750 (epoch 39.982), train_loss = 0.67749715, grad/param norm = 2.1545e-01, time/batch = 16.0734s	
18193/22750 (epoch 39.985), train_loss = 0.85386153, grad/param norm = 2.3986e-01, time/batch = 15.5353s	
18194/22750 (epoch 39.987), train_loss = 0.61370524, grad/param norm = 2.0831e-01, time/batch = 15.1990s	
18195/22750 (epoch 39.989), train_loss = 0.66060805, grad/param norm = 2.1543e-01, time/batch = 15.8506s	
18196/22750 (epoch 39.991), train_loss = 0.76671630, grad/param norm = 2.2383e-01, time/batch = 15.8518s	
18197/22750 (epoch 39.993), train_loss = 0.74075920, grad/param norm = 2.7017e-01, time/batch = 15.4391s	
18198/22750 (epoch 39.996), train_loss = 0.64837152, grad/param norm = 2.7787e-01, time/batch = 15.4334s	
18199/22750 (epoch 39.998), train_loss = 0.83768245, grad/param norm = 2.7879e-01, time/batch = 15.3608s	
decayed learning rate by a factor 0.97 to 0.00077795371297373	
18200/22750 (epoch 40.000), train_loss = 0.71230963, grad/param norm = 2.2714e-01, time/batch = 15.0295s	
18201/22750 (epoch 40.002), train_loss = 0.88523881, grad/param norm = 2.4719e-01, time/batch = 16.0172s	
18202/22750 (epoch 40.004), train_loss = 0.69349296, grad/param norm = 2.0650e-01, time/batch = 15.4394s	
18203/22750 (epoch 40.007), train_loss = 0.71572285, grad/param norm = 2.7751e-01, time/batch = 15.9294s	
18204/22750 (epoch 40.009), train_loss = 0.85857339, grad/param norm = 2.7262e-01, time/batch = 16.7205s	
18205/22750 (epoch 40.011), train_loss = 0.89502201, grad/param norm = 2.5691e-01, time/batch = 16.4072s	
18206/22750 (epoch 40.013), train_loss = 0.83267637, grad/param norm = 2.3201e-01, time/batch = 16.5628s	
18207/22750 (epoch 40.015), train_loss = 0.75429296, grad/param norm = 2.3987e-01, time/batch = 16.8965s	
18208/22750 (epoch 40.018), train_loss = 0.84869663, grad/param norm = 2.5231e-01, time/batch = 16.7384s	
18209/22750 (epoch 40.020), train_loss = 0.88468253, grad/param norm = 2.6774e-01, time/batch = 16.8304s	
18210/22750 (epoch 40.022), train_loss = 0.74218208, grad/param norm = 2.4718e-01, time/batch = 17.1378s	
18211/22750 (epoch 40.024), train_loss = 0.74491125, grad/param norm = 2.3796e-01, time/batch = 19.3737s	
18212/22750 (epoch 40.026), train_loss = 0.79251919, grad/param norm = 2.5027e-01, time/batch = 19.2132s	
18213/22750 (epoch 40.029), train_loss = 0.62291098, grad/param norm = 2.3534e-01, time/batch = 17.2464s	
18214/22750 (epoch 40.031), train_loss = 0.96658147, grad/param norm = 2.6714e-01, time/batch = 16.5527s	
18215/22750 (epoch 40.033), train_loss = 0.75836046, grad/param norm = 2.5203e-01, time/batch = 19.5789s	
18216/22750 (epoch 40.035), train_loss = 0.78882346, grad/param norm = 2.1868e-01, time/batch = 18.0726s	
18217/22750 (epoch 40.037), train_loss = 0.83592197, grad/param norm = 2.2950e-01, time/batch = 17.0963s	
18218/22750 (epoch 40.040), train_loss = 0.74460986, grad/param norm = 2.3259e-01, time/batch = 18.2432s	
18219/22750 (epoch 40.042), train_loss = 0.78496927, grad/param norm = 2.3201e-01, time/batch = 17.3651s	
18220/22750 (epoch 40.044), train_loss = 0.74788060, grad/param norm = 2.3717e-01, time/batch = 18.4419s	
18221/22750 (epoch 40.046), train_loss = 0.82850222, grad/param norm = 2.5950e-01, time/batch = 19.0735s	
18222/22750 (epoch 40.048), train_loss = 0.74866155, grad/param norm = 2.0867e-01, time/batch = 19.8507s	
18223/22750 (epoch 40.051), train_loss = 0.74726262, grad/param norm = 2.2560e-01, time/batch = 16.3231s	
18224/22750 (epoch 40.053), train_loss = 0.73861346, grad/param norm = 2.1571e-01, time/batch = 16.7729s	
18225/22750 (epoch 40.055), train_loss = 0.64027206, grad/param norm = 2.0679e-01, time/batch = 17.0913s	
18226/22750 (epoch 40.057), train_loss = 0.86873140, grad/param norm = 2.3305e-01, time/batch = 18.3244s	
18227/22750 (epoch 40.059), train_loss = 0.56231342, grad/param norm = 2.0512e-01, time/batch = 18.9784s	
18228/22750 (epoch 40.062), train_loss = 0.63071476, grad/param norm = 2.0666e-01, time/batch = 17.9898s	
18229/22750 (epoch 40.064), train_loss = 0.85081100, grad/param norm = 2.3563e-01, time/batch = 20.5233s	
18230/22750 (epoch 40.066), train_loss = 0.65932000, grad/param norm = 2.0321e-01, time/batch = 19.0099s	
18231/22750 (epoch 40.068), train_loss = 0.67693003, grad/param norm = 2.1826e-01, time/batch = 19.4386s	
18232/22750 (epoch 40.070), train_loss = 0.58472801, grad/param norm = 1.9825e-01, time/batch = 21.1463s	
18233/22750 (epoch 40.073), train_loss = 0.70519962, grad/param norm = 2.4964e-01, time/batch = 18.1611s	
18234/22750 (epoch 40.075), train_loss = 0.73791031, grad/param norm = 2.6009e-01, time/batch = 18.5078s	
18235/22750 (epoch 40.077), train_loss = 0.54403172, grad/param norm = 2.1519e-01, time/batch = 19.9221s	
18236/22750 (epoch 40.079), train_loss = 0.73006047, grad/param norm = 2.8457e-01, time/batch = 17.1350s	
18237/22750 (epoch 40.081), train_loss = 0.67967687, grad/param norm = 2.0103e-01, time/batch = 17.3253s	
18238/22750 (epoch 40.084), train_loss = 0.70766126, grad/param norm = 2.1166e-01, time/batch = 17.7662s	
18239/22750 (epoch 40.086), train_loss = 0.73009403, grad/param norm = 2.0340e-01, time/batch = 18.3641s	
18240/22750 (epoch 40.088), train_loss = 0.70112779, grad/param norm = 2.2209e-01, time/batch = 19.0207s	
18241/22750 (epoch 40.090), train_loss = 0.72122778, grad/param norm = 2.6206e-01, time/batch = 19.6703s	
18242/22750 (epoch 40.092), train_loss = 0.79510831, grad/param norm = 2.2292e-01, time/batch = 19.0670s	
18243/22750 (epoch 40.095), train_loss = 0.68778229, grad/param norm = 2.4705e-01, time/batch = 17.9220s	
18244/22750 (epoch 40.097), train_loss = 0.74034212, grad/param norm = 2.2682e-01, time/batch = 18.4195s	
18245/22750 (epoch 40.099), train_loss = 0.67412862, grad/param norm = 2.0950e-01, time/batch = 18.5852s	
18246/22750 (epoch 40.101), train_loss = 0.61188119, grad/param norm = 2.0621e-01, time/batch = 16.6824s	
18247/22750 (epoch 40.103), train_loss = 0.78594551, grad/param norm = 2.4975e-01, time/batch = 19.6044s	
18248/22750 (epoch 40.105), train_loss = 0.84950767, grad/param norm = 2.7265e-01, time/batch = 20.8536s	
18249/22750 (epoch 40.108), train_loss = 0.75989340, grad/param norm = 2.2409e-01, time/batch = 17.5975s	
18250/22750 (epoch 40.110), train_loss = 0.80837898, grad/param norm = 2.2747e-01, time/batch = 17.8352s	
18251/22750 (epoch 40.112), train_loss = 0.60620014, grad/param norm = 1.6904e-01, time/batch = 19.4789s	
18252/22750 (epoch 40.114), train_loss = 0.54372473, grad/param norm = 1.8568e-01, time/batch = 18.3993s	
18253/22750 (epoch 40.116), train_loss = 0.74642144, grad/param norm = 2.1904e-01, time/batch = 18.7440s	
18254/22750 (epoch 40.119), train_loss = 0.68399897, grad/param norm = 1.9642e-01, time/batch = 17.9983s	
18255/22750 (epoch 40.121), train_loss = 0.70027324, grad/param norm = 2.2219e-01, time/batch = 17.2645s	
18256/22750 (epoch 40.123), train_loss = 0.63886392, grad/param norm = 2.7317e-01, time/batch = 18.9375s	
18257/22750 (epoch 40.125), train_loss = 0.84036288, grad/param norm = 2.3613e-01, time/batch = 20.1177s	
18258/22750 (epoch 40.127), train_loss = 0.69601615, grad/param norm = 2.4187e-01, time/batch = 18.5315s	
18259/22750 (epoch 40.130), train_loss = 0.70832773, grad/param norm = 1.9635e-01, time/batch = 17.3615s	
18260/22750 (epoch 40.132), train_loss = 0.67722087, grad/param norm = 2.2051e-01, time/batch = 17.2387s	
18261/22750 (epoch 40.134), train_loss = 0.68586334, grad/param norm = 1.9687e-01, time/batch = 17.6840s	
18262/22750 (epoch 40.136), train_loss = 0.58947118, grad/param norm = 2.3924e-01, time/batch = 18.1614s	
18263/22750 (epoch 40.138), train_loss = 0.79629854, grad/param norm = 2.2268e-01, time/batch = 20.0009s	
18264/22750 (epoch 40.141), train_loss = 0.72088110, grad/param norm = 1.9938e-01, time/batch = 19.4215s	
18265/22750 (epoch 40.143), train_loss = 0.66587928, grad/param norm = 1.8750e-01, time/batch = 18.1598s	
18266/22750 (epoch 40.145), train_loss = 0.82954816, grad/param norm = 2.2637e-01, time/batch = 20.2751s	
18267/22750 (epoch 40.147), train_loss = 0.89154982, grad/param norm = 2.6083e-01, time/batch = 20.3658s	
18268/22750 (epoch 40.149), train_loss = 0.73760287, grad/param norm = 2.3306e-01, time/batch = 19.6249s	
18269/22750 (epoch 40.152), train_loss = 0.71567659, grad/param norm = 2.1626e-01, time/batch = 18.8192s	
18270/22750 (epoch 40.154), train_loss = 0.66033092, grad/param norm = 2.2295e-01, time/batch = 20.5668s	
18271/22750 (epoch 40.156), train_loss = 0.65038261, grad/param norm = 2.1587e-01, time/batch = 17.3439s	
18272/22750 (epoch 40.158), train_loss = 0.63767217, grad/param norm = 2.3930e-01, time/batch = 19.3375s	
18273/22750 (epoch 40.160), train_loss = 0.71990337, grad/param norm = 2.6607e-01, time/batch = 17.7476s	
18274/22750 (epoch 40.163), train_loss = 0.84263807, grad/param norm = 2.2946e-01, time/batch = 18.5482s	
18275/22750 (epoch 40.165), train_loss = 0.76683581, grad/param norm = 2.0821e-01, time/batch = 18.8167s	
18276/22750 (epoch 40.167), train_loss = 0.66853699, grad/param norm = 2.3112e-01, time/batch = 18.7589s	
18277/22750 (epoch 40.169), train_loss = 0.73006366, grad/param norm = 2.5010e-01, time/batch = 18.2772s	
18278/22750 (epoch 40.171), train_loss = 0.61599772, grad/param norm = 2.0814e-01, time/batch = 17.8419s	
18279/22750 (epoch 40.174), train_loss = 0.60649912, grad/param norm = 2.1125e-01, time/batch = 19.6671s	
18280/22750 (epoch 40.176), train_loss = 0.63640513, grad/param norm = 2.4620e-01, time/batch = 19.9857s	
18281/22750 (epoch 40.178), train_loss = 0.67456501, grad/param norm = 2.1037e-01, time/batch = 18.5013s	
18282/22750 (epoch 40.180), train_loss = 0.81965374, grad/param norm = 2.8585e-01, time/batch = 20.3112s	
18283/22750 (epoch 40.182), train_loss = 0.76561932, grad/param norm = 2.4234e-01, time/batch = 18.8362s	
18284/22750 (epoch 40.185), train_loss = 0.79895023, grad/param norm = 2.3809e-01, time/batch = 18.8393s	
18285/22750 (epoch 40.187), train_loss = 0.63419888, grad/param norm = 2.0583e-01, time/batch = 19.8455s	
18286/22750 (epoch 40.189), train_loss = 0.62500328, grad/param norm = 2.1714e-01, time/batch = 18.7803s	
18287/22750 (epoch 40.191), train_loss = 0.66874677, grad/param norm = 1.9320e-01, time/batch = 19.5874s	
18288/22750 (epoch 40.193), train_loss = 0.77204706, grad/param norm = 2.1961e-01, time/batch = 20.0771s	
18289/22750 (epoch 40.196), train_loss = 0.70530777, grad/param norm = 2.3373e-01, time/batch = 17.1896s	
18290/22750 (epoch 40.198), train_loss = 0.53173444, grad/param norm = 2.5491e-01, time/batch = 17.9034s	
18291/22750 (epoch 40.200), train_loss = 0.71569464, grad/param norm = 2.2388e-01, time/batch = 18.8248s	
18292/22750 (epoch 40.202), train_loss = 0.77164580, grad/param norm = 2.6936e-01, time/batch = 17.9256s	
18293/22750 (epoch 40.204), train_loss = 0.74458155, grad/param norm = 2.0634e-01, time/batch = 18.4283s	
18294/22750 (epoch 40.207), train_loss = 0.74829190, grad/param norm = 2.2850e-01, time/batch = 17.4599s	
18295/22750 (epoch 40.209), train_loss = 0.69335503, grad/param norm = 2.0935e-01, time/batch = 18.7701s	
18296/22750 (epoch 40.211), train_loss = 0.62059775, grad/param norm = 2.1048e-01, time/batch = 19.1037s	
18297/22750 (epoch 40.213), train_loss = 0.54974005, grad/param norm = 2.0296e-01, time/batch = 18.0100s	
18298/22750 (epoch 40.215), train_loss = 0.54967653, grad/param norm = 1.9303e-01, time/batch = 17.5755s	
18299/22750 (epoch 40.218), train_loss = 0.65653773, grad/param norm = 2.5974e-01, time/batch = 19.1630s	
18300/22750 (epoch 40.220), train_loss = 0.60459863, grad/param norm = 2.2080e-01, time/batch = 16.1370s	
18301/22750 (epoch 40.222), train_loss = 0.59890119, grad/param norm = 2.1383e-01, time/batch = 16.4356s	
18302/22750 (epoch 40.224), train_loss = 0.62798659, grad/param norm = 1.9684e-01, time/batch = 17.8331s	
18303/22750 (epoch 40.226), train_loss = 0.70392315, grad/param norm = 2.1848e-01, time/batch = 16.7776s	
18304/22750 (epoch 40.229), train_loss = 0.72871312, grad/param norm = 2.3168e-01, time/batch = 18.8939s	
18305/22750 (epoch 40.231), train_loss = 0.62490593, grad/param norm = 2.0218e-01, time/batch = 19.4360s	
18306/22750 (epoch 40.233), train_loss = 0.59434973, grad/param norm = 3.0275e-01, time/batch = 20.0118s	
18307/22750 (epoch 40.235), train_loss = 0.56729735, grad/param norm = 2.3431e-01, time/batch = 16.4898s	
18308/22750 (epoch 40.237), train_loss = 0.63091998, grad/param norm = 2.2374e-01, time/batch = 17.5218s	
18309/22750 (epoch 40.240), train_loss = 0.71343909, grad/param norm = 1.9244e-01, time/batch = 18.2481s	
18310/22750 (epoch 40.242), train_loss = 0.84376478, grad/param norm = 2.5487e-01, time/batch = 18.6587s	
18311/22750 (epoch 40.244), train_loss = 0.84842360, grad/param norm = 2.4882e-01, time/batch = 19.9834s	
18312/22750 (epoch 40.246), train_loss = 0.85880632, grad/param norm = 2.3761e-01, time/batch = 19.7452s	
18313/22750 (epoch 40.248), train_loss = 0.72052792, grad/param norm = 2.0582e-01, time/batch = 18.7527s	
18314/22750 (epoch 40.251), train_loss = 0.79432374, grad/param norm = 2.5637e-01, time/batch = 19.1975s	
18315/22750 (epoch 40.253), train_loss = 0.77822464, grad/param norm = 2.6704e-01, time/batch = 20.8513s	
18316/22750 (epoch 40.255), train_loss = 0.75646105, grad/param norm = 2.2816e-01, time/batch = 17.4819s	
18317/22750 (epoch 40.257), train_loss = 0.65826565, grad/param norm = 2.2269e-01, time/batch = 16.0738s	
18318/22750 (epoch 40.259), train_loss = 0.81045941, grad/param norm = 2.9490e-01, time/batch = 20.2362s	
18319/22750 (epoch 40.262), train_loss = 0.75639036, grad/param norm = 2.4750e-01, time/batch = 18.5838s	
18320/22750 (epoch 40.264), train_loss = 0.58241381, grad/param norm = 2.4131e-01, time/batch = 18.8865s	
18321/22750 (epoch 40.266), train_loss = 0.71383836, grad/param norm = 2.7591e-01, time/batch = 20.0707s	
18322/22750 (epoch 40.268), train_loss = 0.85540260, grad/param norm = 2.5891e-01, time/batch = 19.2650s	
18323/22750 (epoch 40.270), train_loss = 0.65018180, grad/param norm = 2.4108e-01, time/batch = 19.9179s	
18324/22750 (epoch 40.273), train_loss = 0.96950605, grad/param norm = 2.8971e-01, time/batch = 18.3634s	
18325/22750 (epoch 40.275), train_loss = 0.84824405, grad/param norm = 2.3529e-01, time/batch = 18.1755s	
18326/22750 (epoch 40.277), train_loss = 0.71887828, grad/param norm = 2.5465e-01, time/batch = 16.7602s	
18327/22750 (epoch 40.279), train_loss = 0.62314479, grad/param norm = 2.3839e-01, time/batch = 17.4337s	
18328/22750 (epoch 40.281), train_loss = 0.85188373, grad/param norm = 2.3963e-01, time/batch = 17.2982s	
18329/22750 (epoch 40.284), train_loss = 0.75976478, grad/param norm = 2.0628e-01, time/batch = 16.7229s	
18330/22750 (epoch 40.286), train_loss = 0.79716476, grad/param norm = 2.3047e-01, time/batch = 16.7502s	
18331/22750 (epoch 40.288), train_loss = 0.88597558, grad/param norm = 2.7959e-01, time/batch = 17.9347s	
18332/22750 (epoch 40.290), train_loss = 0.77434566, grad/param norm = 2.2828e-01, time/batch = 18.6083s	
18333/22750 (epoch 40.292), train_loss = 0.79203784, grad/param norm = 2.6210e-01, time/batch = 18.2627s	
18334/22750 (epoch 40.295), train_loss = 0.77674605, grad/param norm = 2.4424e-01, time/batch = 17.4307s	
18335/22750 (epoch 40.297), train_loss = 0.75706810, grad/param norm = 2.3082e-01, time/batch = 17.4160s	
18336/22750 (epoch 40.299), train_loss = 0.83037445, grad/param norm = 2.8319e-01, time/batch = 16.6484s	
18337/22750 (epoch 40.301), train_loss = 0.72420988, grad/param norm = 2.0806e-01, time/batch = 17.0733s	
18338/22750 (epoch 40.303), train_loss = 0.77927447, grad/param norm = 2.3029e-01, time/batch = 16.4070s	
18339/22750 (epoch 40.305), train_loss = 0.86770085, grad/param norm = 2.1573e-01, time/batch = 16.4835s	
18340/22750 (epoch 40.308), train_loss = 0.79574536, grad/param norm = 2.2751e-01, time/batch = 16.3212s	
18341/22750 (epoch 40.310), train_loss = 0.68109873, grad/param norm = 2.6285e-01, time/batch = 18.5062s	
18342/22750 (epoch 40.312), train_loss = 0.76068331, grad/param norm = 2.6879e-01, time/batch = 20.1182s	
18343/22750 (epoch 40.314), train_loss = 0.76767930, grad/param norm = 2.2842e-01, time/batch = 19.0163s	
18344/22750 (epoch 40.316), train_loss = 0.72073333, grad/param norm = 2.1223e-01, time/batch = 18.4367s	
18345/22750 (epoch 40.319), train_loss = 0.77219560, grad/param norm = 2.3659e-01, time/batch = 20.4783s	
18346/22750 (epoch 40.321), train_loss = 0.69633402, grad/param norm = 2.7102e-01, time/batch = 18.8417s	
18347/22750 (epoch 40.323), train_loss = 0.78911891, grad/param norm = 2.4194e-01, time/batch = 20.0131s	
18348/22750 (epoch 40.325), train_loss = 0.65287780, grad/param norm = 2.1469e-01, time/batch = 19.5824s	
18349/22750 (epoch 40.327), train_loss = 0.68918347, grad/param norm = 2.3588e-01, time/batch = 18.7625s	
18350/22750 (epoch 40.330), train_loss = 0.86084364, grad/param norm = 2.3785e-01, time/batch = 19.7376s	
18351/22750 (epoch 40.332), train_loss = 0.93351616, grad/param norm = 2.4807e-01, time/batch = 19.5263s	
18352/22750 (epoch 40.334), train_loss = 0.60709606, grad/param norm = 2.0799e-01, time/batch = 17.3483s	
18353/22750 (epoch 40.336), train_loss = 0.83007709, grad/param norm = 2.0540e-01, time/batch = 19.4550s	
18354/22750 (epoch 40.338), train_loss = 0.73794783, grad/param norm = 2.5186e-01, time/batch = 20.4484s	
18355/22750 (epoch 40.341), train_loss = 0.74408228, grad/param norm = 2.2597e-01, time/batch = 18.5899s	
18356/22750 (epoch 40.343), train_loss = 0.64260935, grad/param norm = 2.2894e-01, time/batch = 17.8353s	
18357/22750 (epoch 40.345), train_loss = 0.78559146, grad/param norm = 2.7740e-01, time/batch = 18.0078s	
18358/22750 (epoch 40.347), train_loss = 0.84881107, grad/param norm = 2.5685e-01, time/batch = 19.1680s	
18359/22750 (epoch 40.349), train_loss = 0.62182203, grad/param norm = 2.7868e-01, time/batch = 18.4124s	
18360/22750 (epoch 40.352), train_loss = 0.87599790, grad/param norm = 2.6161e-01, time/batch = 20.0732s	
18361/22750 (epoch 40.354), train_loss = 0.85186607, grad/param norm = 2.6025e-01, time/batch = 18.7576s	
18362/22750 (epoch 40.356), train_loss = 0.80455330, grad/param norm = 2.3596e-01, time/batch = 18.5088s	
18363/22750 (epoch 40.358), train_loss = 0.72471126, grad/param norm = 2.4792e-01, time/batch = 19.9158s	
18364/22750 (epoch 40.360), train_loss = 0.88344164, grad/param norm = 2.2945e-01, time/batch = 19.8540s	
18365/22750 (epoch 40.363), train_loss = 0.69346694, grad/param norm = 2.5702e-01, time/batch = 18.3649s	
18366/22750 (epoch 40.365), train_loss = 0.59822321, grad/param norm = 2.2838e-01, time/batch = 18.5806s	
18367/22750 (epoch 40.367), train_loss = 0.69378408, grad/param norm = 2.6302e-01, time/batch = 20.5824s	
18368/22750 (epoch 40.369), train_loss = 0.76074417, grad/param norm = 2.5634e-01, time/batch = 18.4191s	
18369/22750 (epoch 40.371), train_loss = 0.77302918, grad/param norm = 2.9197e-01, time/batch = 19.6584s	
18370/22750 (epoch 40.374), train_loss = 0.66795400, grad/param norm = 2.3008e-01, time/batch = 18.5748s	
18371/22750 (epoch 40.376), train_loss = 0.74560195, grad/param norm = 2.5841e-01, time/batch = 33.5371s	
18372/22750 (epoch 40.378), train_loss = 0.76327878, grad/param norm = 2.6277e-01, time/batch = 18.7691s	
18373/22750 (epoch 40.380), train_loss = 0.81215538, grad/param norm = 2.4956e-01, time/batch = 17.9131s	
18374/22750 (epoch 40.382), train_loss = 0.72046617, grad/param norm = 2.3024e-01, time/batch = 16.0231s	
18375/22750 (epoch 40.385), train_loss = 0.80167752, grad/param norm = 2.1654e-01, time/batch = 20.8479s	
18376/22750 (epoch 40.387), train_loss = 0.78056726, grad/param norm = 2.3511e-01, time/batch = 18.1599s	
18377/22750 (epoch 40.389), train_loss = 0.61012440, grad/param norm = 2.1948e-01, time/batch = 17.9020s	
18378/22750 (epoch 40.391), train_loss = 0.47544011, grad/param norm = 1.8987e-01, time/batch = 20.1645s	
18379/22750 (epoch 40.393), train_loss = 0.62737968, grad/param norm = 2.2717e-01, time/batch = 19.4924s	
18380/22750 (epoch 40.396), train_loss = 0.75919550, grad/param norm = 2.1999e-01, time/batch = 18.6710s	
18381/22750 (epoch 40.398), train_loss = 0.69032149, grad/param norm = 2.0193e-01, time/batch = 17.4229s	
18382/22750 (epoch 40.400), train_loss = 0.76893500, grad/param norm = 2.6666e-01, time/batch = 19.1740s	
18383/22750 (epoch 40.402), train_loss = 0.75424051, grad/param norm = 2.2340e-01, time/batch = 18.9154s	
18384/22750 (epoch 40.404), train_loss = 0.85768169, grad/param norm = 2.3318e-01, time/batch = 20.5992s	
18385/22750 (epoch 40.407), train_loss = 0.82930515, grad/param norm = 2.2959e-01, time/batch = 20.5324s	
18386/22750 (epoch 40.409), train_loss = 0.68315286, grad/param norm = 2.4051e-01, time/batch = 18.1758s	
18387/22750 (epoch 40.411), train_loss = 0.66774496, grad/param norm = 1.9602e-01, time/batch = 17.8341s	
18388/22750 (epoch 40.413), train_loss = 0.53556549, grad/param norm = 2.3129e-01, time/batch = 17.2692s	
18389/22750 (epoch 40.415), train_loss = 0.62476439, grad/param norm = 2.0233e-01, time/batch = 18.2234s	
18390/22750 (epoch 40.418), train_loss = 0.70029583, grad/param norm = 2.3925e-01, time/batch = 18.1861s	
18391/22750 (epoch 40.420), train_loss = 0.79950680, grad/param norm = 2.8507e-01, time/batch = 18.3354s	
18392/22750 (epoch 40.422), train_loss = 0.93063547, grad/param norm = 2.8694e-01, time/batch = 18.5099s	
18393/22750 (epoch 40.424), train_loss = 0.93635836, grad/param norm = 2.8690e-01, time/batch = 19.8570s	
18394/22750 (epoch 40.426), train_loss = 0.89782706, grad/param norm = 2.2828e-01, time/batch = 19.6740s	
18395/22750 (epoch 40.429), train_loss = 0.67949009, grad/param norm = 2.2462e-01, time/batch = 19.3564s	
18396/22750 (epoch 40.431), train_loss = 0.61022069, grad/param norm = 2.0438e-01, time/batch = 17.4265s	
18397/22750 (epoch 40.433), train_loss = 0.70785642, grad/param norm = 2.3053e-01, time/batch = 19.6460s	
18398/22750 (epoch 40.435), train_loss = 0.54392492, grad/param norm = 1.7451e-01, time/batch = 19.4134s	
18399/22750 (epoch 40.437), train_loss = 0.48071440, grad/param norm = 1.8394e-01, time/batch = 18.3235s	
18400/22750 (epoch 40.440), train_loss = 0.67666516, grad/param norm = 2.2465e-01, time/batch = 19.2399s	
18401/22750 (epoch 40.442), train_loss = 0.70948642, grad/param norm = 2.3485e-01, time/batch = 20.4298s	
18402/22750 (epoch 40.444), train_loss = 0.69408929, grad/param norm = 2.2621e-01, time/batch = 18.5086s	
18403/22750 (epoch 40.446), train_loss = 0.70373934, grad/param norm = 2.4495e-01, time/batch = 19.5954s	
18404/22750 (epoch 40.448), train_loss = 0.92591949, grad/param norm = 2.7489e-01, time/batch = 17.3604s	
18405/22750 (epoch 40.451), train_loss = 0.88876153, grad/param norm = 2.2716e-01, time/batch = 17.4842s	
18406/22750 (epoch 40.453), train_loss = 0.77685263, grad/param norm = 3.0865e-01, time/batch = 20.1334s	
18407/22750 (epoch 40.455), train_loss = 0.89500234, grad/param norm = 2.4742e-01, time/batch = 19.4881s	
18408/22750 (epoch 40.457), train_loss = 0.79137249, grad/param norm = 3.8822e-01, time/batch = 18.0876s	
18409/22750 (epoch 40.459), train_loss = 0.81311340, grad/param norm = 2.3259e-01, time/batch = 16.6596s	
18410/22750 (epoch 40.462), train_loss = 0.74841275, grad/param norm = 2.1402e-01, time/batch = 20.6927s	
18411/22750 (epoch 40.464), train_loss = 0.64486659, grad/param norm = 2.3432e-01, time/batch = 19.3536s	
18412/22750 (epoch 40.466), train_loss = 0.80963614, grad/param norm = 3.0811e-01, time/batch = 16.9344s	
18413/22750 (epoch 40.468), train_loss = 0.77396522, grad/param norm = 2.3909e-01, time/batch = 20.5875s	
18414/22750 (epoch 40.470), train_loss = 0.85183087, grad/param norm = 2.4870e-01, time/batch = 18.6612s	
18415/22750 (epoch 40.473), train_loss = 0.72310809, grad/param norm = 2.2027e-01, time/batch = 18.9876s	
18416/22750 (epoch 40.475), train_loss = 0.76730242, grad/param norm = 2.5535e-01, time/batch = 19.4970s	
18417/22750 (epoch 40.477), train_loss = 0.66272044, grad/param norm = 2.5175e-01, time/batch = 19.4158s	
18418/22750 (epoch 40.479), train_loss = 0.64084339, grad/param norm = 2.2064e-01, time/batch = 17.4104s	
18419/22750 (epoch 40.481), train_loss = 0.60574768, grad/param norm = 1.8389e-01, time/batch = 20.0949s	
18420/22750 (epoch 40.484), train_loss = 0.51475031, grad/param norm = 2.3246e-01, time/batch = 20.1776s	
18421/22750 (epoch 40.486), train_loss = 0.61474562, grad/param norm = 2.3596e-01, time/batch = 19.5293s	
18422/22750 (epoch 40.488), train_loss = 0.57720950, grad/param norm = 2.1454e-01, time/batch = 19.2674s	
18423/22750 (epoch 40.490), train_loss = 0.72431638, grad/param norm = 2.2555e-01, time/batch = 18.2356s	
18424/22750 (epoch 40.492), train_loss = 0.80660757, grad/param norm = 2.4012e-01, time/batch = 17.4052s	
18425/22750 (epoch 40.495), train_loss = 0.67874082, grad/param norm = 2.2342e-01, time/batch = 18.8308s	
18426/22750 (epoch 40.497), train_loss = 0.71456451, grad/param norm = 2.8811e-01, time/batch = 16.7578s	
18427/22750 (epoch 40.499), train_loss = 0.63788459, grad/param norm = 2.1774e-01, time/batch = 18.4125s	
18428/22750 (epoch 40.501), train_loss = 0.69494851, grad/param norm = 2.3857e-01, time/batch = 18.0999s	
18429/22750 (epoch 40.503), train_loss = 0.68674677, grad/param norm = 2.2499e-01, time/batch = 19.2562s	
18430/22750 (epoch 40.505), train_loss = 0.63128692, grad/param norm = 3.2872e-01, time/batch = 18.8543s	
18431/22750 (epoch 40.508), train_loss = 0.60075973, grad/param norm = 2.1862e-01, time/batch = 19.0094s	
18432/22750 (epoch 40.510), train_loss = 0.61662091, grad/param norm = 2.3632e-01, time/batch = 18.1581s	
18433/22750 (epoch 40.512), train_loss = 0.66536108, grad/param norm = 2.3936e-01, time/batch = 19.3907s	
18434/22750 (epoch 40.514), train_loss = 0.68145132, grad/param norm = 2.3576e-01, time/batch = 17.1401s	
18435/22750 (epoch 40.516), train_loss = 0.66214669, grad/param norm = 2.5779e-01, time/batch = 17.2530s	
18436/22750 (epoch 40.519), train_loss = 0.81187750, grad/param norm = 2.7036e-01, time/batch = 19.1558s	
18437/22750 (epoch 40.521), train_loss = 0.72487925, grad/param norm = 2.2643e-01, time/batch = 18.9208s	
18438/22750 (epoch 40.523), train_loss = 0.65270385, grad/param norm = 2.7625e-01, time/batch = 17.6016s	
18439/22750 (epoch 40.525), train_loss = 0.83987152, grad/param norm = 2.6807e-01, time/batch = 20.4381s	
18440/22750 (epoch 40.527), train_loss = 0.75419238, grad/param norm = 2.3074e-01, time/batch = 17.8394s	
18441/22750 (epoch 40.530), train_loss = 0.66568797, grad/param norm = 2.3084e-01, time/batch = 17.6782s	
18442/22750 (epoch 40.532), train_loss = 0.60183796, grad/param norm = 1.9090e-01, time/batch = 17.5865s	
18443/22750 (epoch 40.534), train_loss = 0.78970949, grad/param norm = 2.4092e-01, time/batch = 18.5824s	
18444/22750 (epoch 40.536), train_loss = 0.75413658, grad/param norm = 2.0049e-01, time/batch = 17.4128s	
18445/22750 (epoch 40.538), train_loss = 0.74685716, grad/param norm = 2.2605e-01, time/batch = 18.4242s	
18446/22750 (epoch 40.541), train_loss = 0.63770030, grad/param norm = 2.5071e-01, time/batch = 16.0268s	
18447/22750 (epoch 40.543), train_loss = 0.63651900, grad/param norm = 2.1503e-01, time/batch = 17.5195s	
18448/22750 (epoch 40.545), train_loss = 0.79430469, grad/param norm = 2.6523e-01, time/batch = 17.5348s	
18449/22750 (epoch 40.547), train_loss = 0.69455994, grad/param norm = 2.0920e-01, time/batch = 19.7009s	
18450/22750 (epoch 40.549), train_loss = 0.69710094, grad/param norm = 2.3803e-01, time/batch = 17.6701s	
18451/22750 (epoch 40.552), train_loss = 0.77501024, grad/param norm = 2.5479e-01, time/batch = 18.6702s	
18452/22750 (epoch 40.554), train_loss = 0.77955506, grad/param norm = 2.5481e-01, time/batch = 17.0118s	
18453/22750 (epoch 40.556), train_loss = 0.77229207, grad/param norm = 2.3799e-01, time/batch = 18.7627s	
18454/22750 (epoch 40.558), train_loss = 0.72311780, grad/param norm = 2.4286e-01, time/batch = 17.5083s	
18455/22750 (epoch 40.560), train_loss = 0.68052650, grad/param norm = 2.1588e-01, time/batch = 17.0247s	
18456/22750 (epoch 40.563), train_loss = 0.82299928, grad/param norm = 2.8162e-01, time/batch = 16.2080s	
18457/22750 (epoch 40.565), train_loss = 0.78526542, grad/param norm = 3.3237e-01, time/batch = 19.1278s	
18458/22750 (epoch 40.567), train_loss = 0.76382964, grad/param norm = 2.3377e-01, time/batch = 18.4698s	
18459/22750 (epoch 40.569), train_loss = 0.70976926, grad/param norm = 2.1783e-01, time/batch = 19.6791s	
18460/22750 (epoch 40.571), train_loss = 0.72267561, grad/param norm = 2.1821e-01, time/batch = 17.4271s	
18461/22750 (epoch 40.574), train_loss = 0.74961170, grad/param norm = 2.4445e-01, time/batch = 18.0815s	
18462/22750 (epoch 40.576), train_loss = 0.70414721, grad/param norm = 2.2156e-01, time/batch = 17.5088s	
18463/22750 (epoch 40.578), train_loss = 0.62799002, grad/param norm = 2.4487e-01, time/batch = 17.0607s	
18464/22750 (epoch 40.580), train_loss = 0.78348072, grad/param norm = 2.5435e-01, time/batch = 17.5060s	
18465/22750 (epoch 40.582), train_loss = 0.63820867, grad/param norm = 2.0271e-01, time/batch = 19.7661s	
18466/22750 (epoch 40.585), train_loss = 0.63417929, grad/param norm = 2.1896e-01, time/batch = 19.1869s	
18467/22750 (epoch 40.587), train_loss = 0.64003441, grad/param norm = 2.0226e-01, time/batch = 19.7471s	
18468/22750 (epoch 40.589), train_loss = 0.54604072, grad/param norm = 2.0333e-01, time/batch = 16.1498s	
18469/22750 (epoch 40.591), train_loss = 0.71831470, grad/param norm = 2.0068e-01, time/batch = 15.6057s	
18470/22750 (epoch 40.593), train_loss = 0.82286384, grad/param norm = 2.3159e-01, time/batch = 16.5130s	
18471/22750 (epoch 40.596), train_loss = 0.79548989, grad/param norm = 2.4302e-01, time/batch = 16.3392s	
18472/22750 (epoch 40.598), train_loss = 0.81509682, grad/param norm = 2.6895e-01, time/batch = 17.5189s	
18473/22750 (epoch 40.600), train_loss = 0.86463175, grad/param norm = 2.5387e-01, time/batch = 16.7718s	
18474/22750 (epoch 40.602), train_loss = 0.66011177, grad/param norm = 2.0499e-01, time/batch = 17.5861s	
18475/22750 (epoch 40.604), train_loss = 0.67966963, grad/param norm = 2.1593e-01, time/batch = 17.8553s	
18476/22750 (epoch 40.607), train_loss = 0.62664220, grad/param norm = 1.9024e-01, time/batch = 19.4752s	
18477/22750 (epoch 40.609), train_loss = 0.61692425, grad/param norm = 2.2811e-01, time/batch = 16.4759s	
18478/22750 (epoch 40.611), train_loss = 0.67541162, grad/param norm = 2.1908e-01, time/batch = 17.1981s	
18479/22750 (epoch 40.613), train_loss = 0.65774551, grad/param norm = 2.3614e-01, time/batch = 18.3596s	
18480/22750 (epoch 40.615), train_loss = 0.67675981, grad/param norm = 2.0533e-01, time/batch = 17.9172s	
18481/22750 (epoch 40.618), train_loss = 0.70476468, grad/param norm = 2.0620e-01, time/batch = 17.0865s	
18482/22750 (epoch 40.620), train_loss = 0.69846472, grad/param norm = 2.4348e-01, time/batch = 19.0975s	
18483/22750 (epoch 40.622), train_loss = 0.60325896, grad/param norm = 1.9179e-01, time/batch = 19.3288s	
18484/22750 (epoch 40.624), train_loss = 0.68950022, grad/param norm = 2.6513e-01, time/batch = 18.4955s	
18485/22750 (epoch 40.626), train_loss = 0.57513480, grad/param norm = 2.0553e-01, time/batch = 18.4962s	
18486/22750 (epoch 40.629), train_loss = 0.66003479, grad/param norm = 2.3060e-01, time/batch = 19.9451s	
18487/22750 (epoch 40.631), train_loss = 0.69305855, grad/param norm = 2.0164e-01, time/batch = 19.4306s	
18488/22750 (epoch 40.633), train_loss = 0.60209587, grad/param norm = 2.0997e-01, time/batch = 19.1553s	
18489/22750 (epoch 40.635), train_loss = 0.71051151, grad/param norm = 2.1319e-01, time/batch = 19.4945s	
18490/22750 (epoch 40.637), train_loss = 0.76555676, grad/param norm = 3.0526e-01, time/batch = 17.9199s	
18491/22750 (epoch 40.640), train_loss = 0.74672085, grad/param norm = 2.1743e-01, time/batch = 19.1635s	
18492/22750 (epoch 40.642), train_loss = 0.79698969, grad/param norm = 2.0921e-01, time/batch = 20.0653s	
18493/22750 (epoch 40.644), train_loss = 0.70750124, grad/param norm = 2.3124e-01, time/batch = 19.1040s	
18494/22750 (epoch 40.646), train_loss = 0.77063845, grad/param norm = 3.1913e-01, time/batch = 16.5184s	
18495/22750 (epoch 40.648), train_loss = 0.75841781, grad/param norm = 2.3889e-01, time/batch = 16.2489s	
18496/22750 (epoch 40.651), train_loss = 0.76400083, grad/param norm = 2.2623e-01, time/batch = 17.5905s	
18497/22750 (epoch 40.653), train_loss = 0.80756927, grad/param norm = 2.1976e-01, time/batch = 18.8961s	
18498/22750 (epoch 40.655), train_loss = 0.73879664, grad/param norm = 2.1618e-01, time/batch = 18.2493s	
18499/22750 (epoch 40.657), train_loss = 0.84166778, grad/param norm = 2.3976e-01, time/batch = 18.1691s	
18500/22750 (epoch 40.659), train_loss = 0.89424814, grad/param norm = 2.4850e-01, time/batch = 17.9804s	
18501/22750 (epoch 40.662), train_loss = 0.86316050, grad/param norm = 3.1957e-01, time/batch = 17.4330s	
18502/22750 (epoch 40.664), train_loss = 0.77166930, grad/param norm = 2.3022e-01, time/batch = 18.6091s	
18503/22750 (epoch 40.666), train_loss = 0.62806135, grad/param norm = 2.2664e-01, time/batch = 18.5347s	
18504/22750 (epoch 40.668), train_loss = 0.70449465, grad/param norm = 2.2315e-01, time/batch = 19.8533s	
18505/22750 (epoch 40.670), train_loss = 0.66360474, grad/param norm = 2.0878e-01, time/batch = 19.9154s	
18506/22750 (epoch 40.673), train_loss = 0.87273478, grad/param norm = 2.5529e-01, time/batch = 18.6658s	
18507/22750 (epoch 40.675), train_loss = 0.99028017, grad/param norm = 3.0427e-01, time/batch = 18.1772s	
18508/22750 (epoch 40.677), train_loss = 0.85333713, grad/param norm = 2.5137e-01, time/batch = 17.1569s	
18509/22750 (epoch 40.679), train_loss = 0.86329173, grad/param norm = 3.0172e-01, time/batch = 17.8066s	
18510/22750 (epoch 40.681), train_loss = 0.86469726, grad/param norm = 2.6180e-01, time/batch = 17.4199s	
18511/22750 (epoch 40.684), train_loss = 0.88805123, grad/param norm = 2.6988e-01, time/batch = 19.6833s	
18512/22750 (epoch 40.686), train_loss = 0.92102908, grad/param norm = 2.8087e-01, time/batch = 19.3525s	
18513/22750 (epoch 40.688), train_loss = 0.85922872, grad/param norm = 2.6763e-01, time/batch = 20.0204s	
18514/22750 (epoch 40.690), train_loss = 0.86139219, grad/param norm = 2.3622e-01, time/batch = 18.5799s	
18515/22750 (epoch 40.692), train_loss = 0.86317974, grad/param norm = 2.7719e-01, time/batch = 19.7382s	
18516/22750 (epoch 40.695), train_loss = 0.76178326, grad/param norm = 2.2985e-01, time/batch = 18.4022s	
18517/22750 (epoch 40.697), train_loss = 0.78977723, grad/param norm = 2.4662e-01, time/batch = 18.9180s	
18518/22750 (epoch 40.699), train_loss = 0.69350889, grad/param norm = 2.3560e-01, time/batch = 17.7467s	
18519/22750 (epoch 40.701), train_loss = 0.63186108, grad/param norm = 2.3471e-01, time/batch = 16.8203s	
18520/22750 (epoch 40.703), train_loss = 0.72323134, grad/param norm = 3.1183e-01, time/batch = 19.3349s	
18521/22750 (epoch 40.705), train_loss = 0.69566094, grad/param norm = 2.4587e-01, time/batch = 20.2718s	
18522/22750 (epoch 40.708), train_loss = 0.74342904, grad/param norm = 2.5768e-01, time/batch = 17.7823s	
18523/22750 (epoch 40.710), train_loss = 0.64781647, grad/param norm = 2.3783e-01, time/batch = 17.8543s	
18524/22750 (epoch 40.712), train_loss = 0.57232495, grad/param norm = 2.1982e-01, time/batch = 17.3522s	
18525/22750 (epoch 40.714), train_loss = 0.62644859, grad/param norm = 2.2001e-01, time/batch = 18.0108s	
18526/22750 (epoch 40.716), train_loss = 0.61680644, grad/param norm = 2.0372e-01, time/batch = 18.0023s	
18527/22750 (epoch 40.719), train_loss = 0.68198724, grad/param norm = 2.6463e-01, time/batch = 18.9136s	
18528/22750 (epoch 40.721), train_loss = 0.82073296, grad/param norm = 2.2585e-01, time/batch = 19.3238s	
18529/22750 (epoch 40.723), train_loss = 0.80927385, grad/param norm = 2.7662e-01, time/batch = 17.0951s	
18530/22750 (epoch 40.725), train_loss = 0.70377424, grad/param norm = 2.4596e-01, time/batch = 20.1078s	
18531/22750 (epoch 40.727), train_loss = 0.72711220, grad/param norm = 2.2968e-01, time/batch = 19.3524s	
18532/22750 (epoch 40.730), train_loss = 0.68557840, grad/param norm = 2.1285e-01, time/batch = 17.5637s	
18533/22750 (epoch 40.732), train_loss = 0.67022728, grad/param norm = 2.2345e-01, time/batch = 19.0730s	
18534/22750 (epoch 40.734), train_loss = 0.59730703, grad/param norm = 1.8604e-01, time/batch = 17.4348s	
18535/22750 (epoch 40.736), train_loss = 0.69027870, grad/param norm = 2.3625e-01, time/batch = 17.0864s	
18536/22750 (epoch 40.738), train_loss = 0.76157099, grad/param norm = 2.3745e-01, time/batch = 19.8197s	
18537/22750 (epoch 40.741), train_loss = 0.86382936, grad/param norm = 2.5145e-01, time/batch = 16.9000s	
18538/22750 (epoch 40.743), train_loss = 0.74396234, grad/param norm = 2.2827e-01, time/batch = 17.2217s	
18539/22750 (epoch 40.745), train_loss = 0.61725803, grad/param norm = 1.9681e-01, time/batch = 16.1918s	
18540/22750 (epoch 40.747), train_loss = 0.73301352, grad/param norm = 2.0596e-01, time/batch = 19.3573s	
18541/22750 (epoch 40.749), train_loss = 0.83669208, grad/param norm = 2.7071e-01, time/batch = 18.6836s	
18542/22750 (epoch 40.752), train_loss = 0.73777492, grad/param norm = 2.2782e-01, time/batch = 17.4167s	
18543/22750 (epoch 40.754), train_loss = 0.74335464, grad/param norm = 2.5059e-01, time/batch = 18.3366s	
18544/22750 (epoch 40.756), train_loss = 0.68302979, grad/param norm = 2.5502e-01, time/batch = 16.6106s	
18545/22750 (epoch 40.758), train_loss = 0.64902312, grad/param norm = 2.0842e-01, time/batch = 17.1013s	
18546/22750 (epoch 40.760), train_loss = 0.65000768, grad/param norm = 2.2719e-01, time/batch = 17.8420s	
18547/22750 (epoch 40.763), train_loss = 0.70845408, grad/param norm = 2.2863e-01, time/batch = 17.4353s	
18548/22750 (epoch 40.765), train_loss = 0.71488863, grad/param norm = 2.4135e-01, time/batch = 19.1782s	
18549/22750 (epoch 40.767), train_loss = 0.76634584, grad/param norm = 2.4384e-01, time/batch = 19.3354s	
18550/22750 (epoch 40.769), train_loss = 0.83922038, grad/param norm = 2.7028e-01, time/batch = 18.3516s	
18551/22750 (epoch 40.771), train_loss = 0.86262836, grad/param norm = 2.8695e-01, time/batch = 17.5137s	
18552/22750 (epoch 40.774), train_loss = 0.67616394, grad/param norm = 2.4832e-01, time/batch = 17.4059s	
18553/22750 (epoch 40.776), train_loss = 0.82672626, grad/param norm = 2.8360e-01, time/batch = 17.3406s	
18554/22750 (epoch 40.778), train_loss = 0.85072228, grad/param norm = 2.5485e-01, time/batch = 17.2413s	
18555/22750 (epoch 40.780), train_loss = 0.77063215, grad/param norm = 2.5502e-01, time/batch = 17.1596s	
18556/22750 (epoch 40.782), train_loss = 0.87699217, grad/param norm = 2.6273e-01, time/batch = 17.1804s	
18557/22750 (epoch 40.785), train_loss = 0.71022267, grad/param norm = 2.5596e-01, time/batch = 17.2619s	
18558/22750 (epoch 40.787), train_loss = 0.64143120, grad/param norm = 2.6667e-01, time/batch = 19.3509s	
18559/22750 (epoch 40.789), train_loss = 0.71060020, grad/param norm = 2.1211e-01, time/batch = 17.6812s	
18560/22750 (epoch 40.791), train_loss = 0.69389076, grad/param norm = 2.3242e-01, time/batch = 20.2600s	
18561/22750 (epoch 40.793), train_loss = 0.67472007, grad/param norm = 2.6006e-01, time/batch = 19.8975s	
18562/22750 (epoch 40.796), train_loss = 0.62776254, grad/param norm = 2.2736e-01, time/batch = 18.8972s	
18563/22750 (epoch 40.798), train_loss = 0.67383717, grad/param norm = 2.2029e-01, time/batch = 15.7079s	
18564/22750 (epoch 40.800), train_loss = 0.66231564, grad/param norm = 2.4179e-01, time/batch = 18.6754s	
18565/22750 (epoch 40.802), train_loss = 0.60098779, grad/param norm = 2.2290e-01, time/batch = 28.1670s	
18566/22750 (epoch 40.804), train_loss = 0.77922802, grad/param norm = 2.1601e-01, time/batch = 19.8949s	
18567/22750 (epoch 40.807), train_loss = 0.76894818, grad/param norm = 2.5485e-01, time/batch = 19.8547s	
18568/22750 (epoch 40.809), train_loss = 0.85849811, grad/param norm = 2.4599e-01, time/batch = 16.4942s	
18569/22750 (epoch 40.811), train_loss = 0.72088855, grad/param norm = 2.3851e-01, time/batch = 16.0885s	
18570/22750 (epoch 40.813), train_loss = 0.76916260, grad/param norm = 2.4537e-01, time/batch = 16.2724s	
18571/22750 (epoch 40.815), train_loss = 0.85382492, grad/param norm = 2.4559e-01, time/batch = 16.4184s	
18572/22750 (epoch 40.818), train_loss = 0.80053277, grad/param norm = 2.1297e-01, time/batch = 17.0959s	
18573/22750 (epoch 40.820), train_loss = 0.92463613, grad/param norm = 2.4677e-01, time/batch = 17.4214s	
18574/22750 (epoch 40.822), train_loss = 0.77099174, grad/param norm = 2.4697e-01, time/batch = 17.9234s	
18575/22750 (epoch 40.824), train_loss = 0.64221820, grad/param norm = 2.0396e-01, time/batch = 17.5333s	
18576/22750 (epoch 40.826), train_loss = 0.72799848, grad/param norm = 2.4844e-01, time/batch = 16.7539s	
18577/22750 (epoch 40.829), train_loss = 0.82118934, grad/param norm = 2.5837e-01, time/batch = 16.9644s	
18578/22750 (epoch 40.831), train_loss = 0.81479904, grad/param norm = 2.8338e-01, time/batch = 18.0269s	
18579/22750 (epoch 40.833), train_loss = 0.76675005, grad/param norm = 2.6973e-01, time/batch = 16.7642s	
18580/22750 (epoch 40.835), train_loss = 0.66145273, grad/param norm = 2.4973e-01, time/batch = 18.6643s	
18581/22750 (epoch 40.837), train_loss = 0.71454332, grad/param norm = 2.3831e-01, time/batch = 18.5003s	
18582/22750 (epoch 40.840), train_loss = 0.66044357, grad/param norm = 2.1071e-01, time/batch = 3.5369s	
18583/22750 (epoch 40.842), train_loss = 0.67922689, grad/param norm = 2.6134e-01, time/batch = 0.7035s	
18584/22750 (epoch 40.844), train_loss = 0.76392338, grad/param norm = 2.7072e-01, time/batch = 0.7061s	
18585/22750 (epoch 40.846), train_loss = 0.79394516, grad/param norm = 2.3228e-01, time/batch = 0.7074s	
18586/22750 (epoch 40.848), train_loss = 0.68789460, grad/param norm = 2.2306e-01, time/batch = 0.7032s	
18587/22750 (epoch 40.851), train_loss = 0.66969206, grad/param norm = 2.3888e-01, time/batch = 0.7069s	
18588/22750 (epoch 40.853), train_loss = 0.83200989, grad/param norm = 2.4184e-01, time/batch = 0.7012s	
18589/22750 (epoch 40.855), train_loss = 0.70003126, grad/param norm = 2.0476e-01, time/batch = 0.9482s	
18590/22750 (epoch 40.857), train_loss = 0.79304238, grad/param norm = 2.2618e-01, time/batch = 1.0233s	
18591/22750 (epoch 40.859), train_loss = 0.75363659, grad/param norm = 2.1923e-01, time/batch = 1.0193s	
18592/22750 (epoch 40.862), train_loss = 0.91137536, grad/param norm = 3.0372e-01, time/batch = 1.0060s	
18593/22750 (epoch 40.864), train_loss = 0.75508353, grad/param norm = 2.3896e-01, time/batch = 1.0112s	
18594/22750 (epoch 40.866), train_loss = 0.79788054, grad/param norm = 2.3020e-01, time/batch = 1.7458s	
18595/22750 (epoch 40.868), train_loss = 0.67433416, grad/param norm = 2.4302e-01, time/batch = 1.9197s	
18596/22750 (epoch 40.870), train_loss = 0.64322363, grad/param norm = 2.3490e-01, time/batch = 4.8300s	
18597/22750 (epoch 40.873), train_loss = 0.73038784, grad/param norm = 2.2233e-01, time/batch = 17.6861s	
18598/22750 (epoch 40.875), train_loss = 0.77440017, grad/param norm = 2.1312e-01, time/batch = 18.2540s	
18599/22750 (epoch 40.877), train_loss = 0.68736131, grad/param norm = 2.3753e-01, time/batch = 20.3323s	
18600/22750 (epoch 40.879), train_loss = 0.82180737, grad/param norm = 2.5882e-01, time/batch = 20.2687s	
18601/22750 (epoch 40.881), train_loss = 0.76700137, grad/param norm = 2.2953e-01, time/batch = 18.1740s	
18602/22750 (epoch 40.884), train_loss = 0.66124345, grad/param norm = 2.1324e-01, time/batch = 18.5975s	
18603/22750 (epoch 40.886), train_loss = 0.75992015, grad/param norm = 2.2133e-01, time/batch = 17.4988s	
18604/22750 (epoch 40.888), train_loss = 0.78973254, grad/param norm = 2.1088e-01, time/batch = 19.6636s	
18605/22750 (epoch 40.890), train_loss = 0.78630249, grad/param norm = 2.3098e-01, time/batch = 17.6694s	
18606/22750 (epoch 40.892), train_loss = 0.97266148, grad/param norm = 2.6859e-01, time/batch = 17.3382s	
18607/22750 (epoch 40.895), train_loss = 0.69233652, grad/param norm = 2.3423e-01, time/batch = 19.1676s	
18608/22750 (epoch 40.897), train_loss = 0.84393399, grad/param norm = 2.3637e-01, time/batch = 17.0236s	
18609/22750 (epoch 40.899), train_loss = 0.74941146, grad/param norm = 2.3469e-01, time/batch = 19.0322s	
18610/22750 (epoch 40.901), train_loss = 0.80978584, grad/param norm = 2.4075e-01, time/batch = 16.7968s	
18611/22750 (epoch 40.903), train_loss = 0.73048184, grad/param norm = 2.2075e-01, time/batch = 17.7575s	
18612/22750 (epoch 40.905), train_loss = 0.80086198, grad/param norm = 2.4345e-01, time/batch = 18.8225s	
18613/22750 (epoch 40.908), train_loss = 0.62151612, grad/param norm = 2.3259e-01, time/batch = 17.9121s	
18614/22750 (epoch 40.910), train_loss = 0.57346437, grad/param norm = 2.1426e-01, time/batch = 19.9050s	
18615/22750 (epoch 40.912), train_loss = 0.73206361, grad/param norm = 2.2846e-01, time/batch = 19.2331s	
18616/22750 (epoch 40.914), train_loss = 0.75326483, grad/param norm = 2.3346e-01, time/batch = 19.1688s	
18617/22750 (epoch 40.916), train_loss = 0.58828298, grad/param norm = 2.0023e-01, time/batch = 21.0831s	
18618/22750 (epoch 40.919), train_loss = 0.73533409, grad/param norm = 2.4469e-01, time/batch = 19.9251s	
18619/22750 (epoch 40.921), train_loss = 0.56623003, grad/param norm = 1.9228e-01, time/batch = 20.4499s	
18620/22750 (epoch 40.923), train_loss = 0.66038090, grad/param norm = 2.0255e-01, time/batch = 19.4947s	
18621/22750 (epoch 40.925), train_loss = 0.72864776, grad/param norm = 2.3191e-01, time/batch = 19.1511s	
18622/22750 (epoch 40.927), train_loss = 0.58092065, grad/param norm = 2.0963e-01, time/batch = 19.7375s	
18623/22750 (epoch 40.930), train_loss = 0.55129811, grad/param norm = 2.1358e-01, time/batch = 18.3370s	
18624/22750 (epoch 40.932), train_loss = 0.71186778, grad/param norm = 2.2408e-01, time/batch = 17.7203s	
18625/22750 (epoch 40.934), train_loss = 0.60813786, grad/param norm = 1.9006e-01, time/batch = 19.8132s	
18626/22750 (epoch 40.936), train_loss = 0.82188393, grad/param norm = 2.7054e-01, time/batch = 19.6865s	
18627/22750 (epoch 40.938), train_loss = 0.81355007, grad/param norm = 2.3016e-01, time/batch = 18.2712s	
18628/22750 (epoch 40.941), train_loss = 0.82958183, grad/param norm = 2.5340e-01, time/batch = 19.0962s	
18629/22750 (epoch 40.943), train_loss = 0.74922272, grad/param norm = 2.1964e-01, time/batch = 17.8530s	
18630/22750 (epoch 40.945), train_loss = 0.76215881, grad/param norm = 2.7545e-01, time/batch = 18.9052s	
18631/22750 (epoch 40.947), train_loss = 0.67672278, grad/param norm = 2.1767e-01, time/batch = 19.9995s	
18632/22750 (epoch 40.949), train_loss = 0.68648010, grad/param norm = 2.2374e-01, time/batch = 18.0979s	
18633/22750 (epoch 40.952), train_loss = 0.70121196, grad/param norm = 2.3924e-01, time/batch = 18.5716s	
18634/22750 (epoch 40.954), train_loss = 0.62609236, grad/param norm = 2.0196e-01, time/batch = 18.9987s	
18635/22750 (epoch 40.956), train_loss = 0.78001834, grad/param norm = 2.2584e-01, time/batch = 19.2553s	
18636/22750 (epoch 40.958), train_loss = 0.64960257, grad/param norm = 1.9543e-01, time/batch = 20.0071s	
18637/22750 (epoch 40.960), train_loss = 0.64573971, grad/param norm = 2.1948e-01, time/batch = 18.3626s	
18638/22750 (epoch 40.963), train_loss = 0.73790014, grad/param norm = 2.0707e-01, time/batch = 19.7631s	
18639/22750 (epoch 40.965), train_loss = 0.78934086, grad/param norm = 2.1589e-01, time/batch = 19.7449s	
18640/22750 (epoch 40.967), train_loss = 0.75803451, grad/param norm = 2.3517e-01, time/batch = 16.7644s	
18641/22750 (epoch 40.969), train_loss = 0.69781344, grad/param norm = 2.7136e-01, time/batch = 19.7311s	
18642/22750 (epoch 40.971), train_loss = 0.65741726, grad/param norm = 2.1045e-01, time/batch = 19.5853s	
18643/22750 (epoch 40.974), train_loss = 0.64994963, grad/param norm = 2.0286e-01, time/batch = 17.6592s	
18644/22750 (epoch 40.976), train_loss = 0.71211912, grad/param norm = 2.7747e-01, time/batch = 20.4901s	
18645/22750 (epoch 40.978), train_loss = 0.66562480, grad/param norm = 2.1477e-01, time/batch = 19.6963s	
18646/22750 (epoch 40.980), train_loss = 0.82913989, grad/param norm = 2.4781e-01, time/batch = 19.4482s	
18647/22750 (epoch 40.982), train_loss = 0.67539148, grad/param norm = 2.0685e-01, time/batch = 19.8625s	
18648/22750 (epoch 40.985), train_loss = 0.87413930, grad/param norm = 2.6928e-01, time/batch = 19.7427s	
18649/22750 (epoch 40.987), train_loss = 0.61982487, grad/param norm = 2.3609e-01, time/batch = 18.4913s	
18650/22750 (epoch 40.989), train_loss = 0.66977304, grad/param norm = 2.3843e-01, time/batch = 19.2469s	
18651/22750 (epoch 40.991), train_loss = 0.76586614, grad/param norm = 2.4062e-01, time/batch = 17.1525s	
18652/22750 (epoch 40.993), train_loss = 0.72612297, grad/param norm = 3.1363e-01, time/batch = 18.0813s	
18653/22750 (epoch 40.996), train_loss = 0.63983815, grad/param norm = 2.3617e-01, time/batch = 17.8453s	
18654/22750 (epoch 40.998), train_loss = 0.80677380, grad/param norm = 2.4403e-01, time/batch = 20.2812s	
decayed learning rate by a factor 0.97 to 0.00075461510158451	
18655/22750 (epoch 41.000), train_loss = 0.71032190, grad/param norm = 2.2296e-01, time/batch = 18.8429s	
18656/22750 (epoch 41.002), train_loss = 0.90792967, grad/param norm = 2.8940e-01, time/batch = 20.6730s	
18657/22750 (epoch 41.004), train_loss = 0.68046864, grad/param norm = 2.1382e-01, time/batch = 19.1688s	
18658/22750 (epoch 41.007), train_loss = 0.68684802, grad/param norm = 2.5447e-01, time/batch = 19.0736s	
18659/22750 (epoch 41.009), train_loss = 0.85043174, grad/param norm = 2.8296e-01, time/batch = 17.3208s	
18660/22750 (epoch 41.011), train_loss = 0.91687465, grad/param norm = 3.2631e-01, time/batch = 18.0894s	
18661/22750 (epoch 41.013), train_loss = 0.84361955, grad/param norm = 2.5607e-01, time/batch = 18.5815s	
18662/22750 (epoch 41.015), train_loss = 0.74492170, grad/param norm = 2.3162e-01, time/batch = 16.2536s	
18663/22750 (epoch 41.018), train_loss = 0.86127215, grad/param norm = 2.7894e-01, time/batch = 18.5286s	
18664/22750 (epoch 41.020), train_loss = 0.86461142, grad/param norm = 2.6187e-01, time/batch = 19.5244s	
18665/22750 (epoch 41.022), train_loss = 0.73064146, grad/param norm = 2.4989e-01, time/batch = 18.6824s	
18666/22750 (epoch 41.024), train_loss = 0.73564346, grad/param norm = 2.3535e-01, time/batch = 19.8340s	
18667/22750 (epoch 41.026), train_loss = 0.77806100, grad/param norm = 2.5530e-01, time/batch = 18.0201s	
18668/22750 (epoch 41.029), train_loss = 0.59631427, grad/param norm = 2.3221e-01, time/batch = 18.2469s	
18669/22750 (epoch 41.031), train_loss = 0.94245422, grad/param norm = 2.4428e-01, time/batch = 17.6717s	
18670/22750 (epoch 41.033), train_loss = 0.74914394, grad/param norm = 2.4165e-01, time/batch = 18.8318s	
18671/22750 (epoch 41.035), train_loss = 0.79276587, grad/param norm = 2.3206e-01, time/batch = 18.5090s	
18672/22750 (epoch 41.037), train_loss = 0.83053852, grad/param norm = 2.7164e-01, time/batch = 16.9609s	
18673/22750 (epoch 41.040), train_loss = 0.74052103, grad/param norm = 2.3284e-01, time/batch = 19.1118s	
18674/22750 (epoch 41.042), train_loss = 0.77617258, grad/param norm = 2.3682e-01, time/batch = 19.6875s	
18675/22750 (epoch 41.044), train_loss = 0.73656589, grad/param norm = 2.1533e-01, time/batch = 18.6567s	
18676/22750 (epoch 41.046), train_loss = 0.82961986, grad/param norm = 3.2508e-01, time/batch = 19.4159s	
18677/22750 (epoch 41.048), train_loss = 0.75461643, grad/param norm = 2.2435e-01, time/batch = 19.2536s	
18678/22750 (epoch 41.051), train_loss = 0.73866009, grad/param norm = 2.3222e-01, time/batch = 17.0500s	
18679/22750 (epoch 41.053), train_loss = 0.73248780, grad/param norm = 2.1007e-01, time/batch = 19.4900s	
18680/22750 (epoch 41.055), train_loss = 0.64758068, grad/param norm = 2.3477e-01, time/batch = 20.4333s	
18681/22750 (epoch 41.057), train_loss = 0.85760596, grad/param norm = 2.3607e-01, time/batch = 18.2740s	
18682/22750 (epoch 41.059), train_loss = 0.55803095, grad/param norm = 2.2419e-01, time/batch = 20.5321s	
18683/22750 (epoch 41.062), train_loss = 0.63718164, grad/param norm = 2.2006e-01, time/batch = 19.6795s	
18684/22750 (epoch 41.064), train_loss = 0.85096471, grad/param norm = 2.4410e-01, time/batch = 17.3227s	
18685/22750 (epoch 41.066), train_loss = 0.65715917, grad/param norm = 2.0979e-01, time/batch = 18.2412s	
18686/22750 (epoch 41.068), train_loss = 0.66301123, grad/param norm = 2.0725e-01, time/batch = 17.3622s	
18687/22750 (epoch 41.070), train_loss = 0.58357359, grad/param norm = 1.8973e-01, time/batch = 17.3452s	
18688/22750 (epoch 41.073), train_loss = 0.68546324, grad/param norm = 2.4045e-01, time/batch = 18.4960s	
18689/22750 (epoch 41.075), train_loss = 0.72396078, grad/param norm = 2.0992e-01, time/batch = 19.7733s	
18690/22750 (epoch 41.077), train_loss = 0.54653372, grad/param norm = 2.1991e-01, time/batch = 18.8269s	
18691/22750 (epoch 41.079), train_loss = 0.74049213, grad/param norm = 2.8194e-01, time/batch = 17.4125s	
18692/22750 (epoch 41.081), train_loss = 0.68512955, grad/param norm = 2.1022e-01, time/batch = 16.7725s	
18693/22750 (epoch 41.084), train_loss = 0.70145569, grad/param norm = 2.4045e-01, time/batch = 16.4275s	
18694/22750 (epoch 41.086), train_loss = 0.72371902, grad/param norm = 2.0392e-01, time/batch = 17.0904s	
18695/22750 (epoch 41.088), train_loss = 0.68931443, grad/param norm = 2.1738e-01, time/batch = 17.7487s	
18696/22750 (epoch 41.090), train_loss = 0.68805409, grad/param norm = 2.0232e-01, time/batch = 18.5741s	
18697/22750 (epoch 41.092), train_loss = 0.77880113, grad/param norm = 2.1798e-01, time/batch = 18.4192s	
18698/22750 (epoch 41.095), train_loss = 0.66928564, grad/param norm = 2.4360e-01, time/batch = 18.2603s	
18699/22750 (epoch 41.097), train_loss = 0.72711037, grad/param norm = 2.1006e-01, time/batch = 19.1254s	
18700/22750 (epoch 41.099), train_loss = 0.65089807, grad/param norm = 2.3749e-01, time/batch = 19.4588s	
18701/22750 (epoch 41.101), train_loss = 0.60937842, grad/param norm = 2.1524e-01, time/batch = 18.5223s	
18702/22750 (epoch 41.103), train_loss = 0.78146579, grad/param norm = 2.7620e-01, time/batch = 19.3312s	
18703/22750 (epoch 41.105), train_loss = 0.86741149, grad/param norm = 2.9813e-01, time/batch = 17.7403s	
18704/22750 (epoch 41.108), train_loss = 0.77411654, grad/param norm = 2.6415e-01, time/batch = 18.1627s	
18705/22750 (epoch 41.110), train_loss = 0.79885780, grad/param norm = 2.1644e-01, time/batch = 20.9713s	
18706/22750 (epoch 41.112), train_loss = 0.62932076, grad/param norm = 1.9690e-01, time/batch = 18.4910s	
18707/22750 (epoch 41.114), train_loss = 0.54896884, grad/param norm = 2.1460e-01, time/batch = 18.0820s	
18708/22750 (epoch 41.116), train_loss = 0.73274244, grad/param norm = 2.2443e-01, time/batch = 21.1070s	
18709/22750 (epoch 41.119), train_loss = 0.68383789, grad/param norm = 2.0345e-01, time/batch = 19.4437s	
18710/22750 (epoch 41.121), train_loss = 0.69988138, grad/param norm = 2.6019e-01, time/batch = 17.8563s	
18711/22750 (epoch 41.123), train_loss = 0.61449164, grad/param norm = 2.1216e-01, time/batch = 16.4037s	
18712/22750 (epoch 41.125), train_loss = 0.83459376, grad/param norm = 2.1550e-01, time/batch = 19.0888s	
18713/22750 (epoch 41.127), train_loss = 0.68939117, grad/param norm = 2.3626e-01, time/batch = 17.0859s	
18714/22750 (epoch 41.130), train_loss = 0.69844663, grad/param norm = 2.3084e-01, time/batch = 18.0149s	
18715/22750 (epoch 41.132), train_loss = 0.66238229, grad/param norm = 2.0252e-01, time/batch = 18.7509s	
18716/22750 (epoch 41.134), train_loss = 0.67550777, grad/param norm = 1.9568e-01, time/batch = 19.2567s	
18717/22750 (epoch 41.136), train_loss = 0.58092076, grad/param norm = 2.3717e-01, time/batch = 16.7943s	
18718/22750 (epoch 41.138), train_loss = 0.79680200, grad/param norm = 2.5851e-01, time/batch = 18.3927s	
18719/22750 (epoch 41.141), train_loss = 0.70614829, grad/param norm = 2.1540e-01, time/batch = 18.9426s	
18720/22750 (epoch 41.143), train_loss = 0.66989359, grad/param norm = 1.9597e-01, time/batch = 18.0597s	
18721/22750 (epoch 41.145), train_loss = 0.82678555, grad/param norm = 2.4839e-01, time/batch = 19.7246s	
18722/22750 (epoch 41.147), train_loss = 0.87330934, grad/param norm = 2.4971e-01, time/batch = 18.8243s	
18723/22750 (epoch 41.149), train_loss = 0.72330026, grad/param norm = 2.2291e-01, time/batch = 16.8275s	
18724/22750 (epoch 41.152), train_loss = 0.71395148, grad/param norm = 2.1060e-01, time/batch = 19.2504s	
18725/22750 (epoch 41.154), train_loss = 0.65227029, grad/param norm = 2.3084e-01, time/batch = 17.2029s	
18726/22750 (epoch 41.156), train_loss = 0.64392421, grad/param norm = 2.1297e-01, time/batch = 18.2846s	
18727/22750 (epoch 41.158), train_loss = 0.61201792, grad/param norm = 2.4662e-01, time/batch = 18.7060s	
18728/22750 (epoch 41.160), train_loss = 0.70058481, grad/param norm = 2.2496e-01, time/batch = 19.4418s	
18729/22750 (epoch 41.163), train_loss = 0.84962195, grad/param norm = 2.9328e-01, time/batch = 18.5858s	
18730/22750 (epoch 41.165), train_loss = 0.77193554, grad/param norm = 2.3736e-01, time/batch = 18.6763s	
18731/22750 (epoch 41.167), train_loss = 0.66820863, grad/param norm = 2.2955e-01, time/batch = 18.7586s	
18732/22750 (epoch 41.169), train_loss = 0.72504021, grad/param norm = 3.0373e-01, time/batch = 18.2555s	
18733/22750 (epoch 41.171), train_loss = 0.61144537, grad/param norm = 2.1888e-01, time/batch = 18.0911s	
18734/22750 (epoch 41.174), train_loss = 0.61670669, grad/param norm = 2.4319e-01, time/batch = 19.1721s	
18735/22750 (epoch 41.176), train_loss = 0.62262712, grad/param norm = 2.1843e-01, time/batch = 16.8444s	
18736/22750 (epoch 41.178), train_loss = 0.66982569, grad/param norm = 2.2923e-01, time/batch = 16.9076s	
18737/22750 (epoch 41.180), train_loss = 0.80332285, grad/param norm = 2.8518e-01, time/batch = 16.8696s	
18738/22750 (epoch 41.182), train_loss = 0.75936720, grad/param norm = 2.3234e-01, time/batch = 16.6904s	
18739/22750 (epoch 41.185), train_loss = 0.80190938, grad/param norm = 2.2994e-01, time/batch = 17.5928s	
18740/22750 (epoch 41.187), train_loss = 0.63169761, grad/param norm = 1.9436e-01, time/batch = 19.4785s	
18741/22750 (epoch 41.189), train_loss = 0.62385792, grad/param norm = 2.2097e-01, time/batch = 17.9041s	
18742/22750 (epoch 41.191), train_loss = 0.66867855, grad/param norm = 2.3218e-01, time/batch = 16.7577s	
18743/22750 (epoch 41.193), train_loss = 0.75633132, grad/param norm = 2.1093e-01, time/batch = 18.0113s	
18744/22750 (epoch 41.196), train_loss = 0.69904524, grad/param norm = 2.3064e-01, time/batch = 20.9485s	
18745/22750 (epoch 41.198), train_loss = 0.52429005, grad/param norm = 2.0902e-01, time/batch = 19.5354s	
18746/22750 (epoch 41.200), train_loss = 0.71898203, grad/param norm = 2.4058e-01, time/batch = 18.4172s	
18747/22750 (epoch 41.202), train_loss = 0.78024115, grad/param norm = 2.7506e-01, time/batch = 18.8442s	
18748/22750 (epoch 41.204), train_loss = 0.73278691, grad/param norm = 2.4997e-01, time/batch = 19.8185s	
18749/22750 (epoch 41.207), train_loss = 0.74077539, grad/param norm = 2.2172e-01, time/batch = 18.4047s	
18750/22750 (epoch 41.209), train_loss = 0.68841091, grad/param norm = 2.0247e-01, time/batch = 18.4111s	
18751/22750 (epoch 41.211), train_loss = 0.63410281, grad/param norm = 2.3439e-01, time/batch = 20.8254s	
18752/22750 (epoch 41.213), train_loss = 0.54654433, grad/param norm = 2.2125e-01, time/batch = 18.5719s	
18753/22750 (epoch 41.215), train_loss = 0.54290816, grad/param norm = 2.1690e-01, time/batch = 20.3551s	
18754/22750 (epoch 41.218), train_loss = 0.63331711, grad/param norm = 2.6423e-01, time/batch = 20.5179s	
18755/22750 (epoch 41.220), train_loss = 0.59591471, grad/param norm = 2.1197e-01, time/batch = 18.3570s	
18756/22750 (epoch 41.222), train_loss = 0.59389061, grad/param norm = 2.4050e-01, time/batch = 17.3974s	
18757/22750 (epoch 41.224), train_loss = 0.62791150, grad/param norm = 2.1067e-01, time/batch = 17.9198s	
18758/22750 (epoch 41.226), train_loss = 0.69355630, grad/param norm = 2.2097e-01, time/batch = 18.8249s	
18759/22750 (epoch 41.229), train_loss = 0.71852086, grad/param norm = 2.1345e-01, time/batch = 19.0690s	
18760/22750 (epoch 41.231), train_loss = 0.62422924, grad/param norm = 2.1978e-01, time/batch = 19.3239s	
18761/22750 (epoch 41.233), train_loss = 0.58428335, grad/param norm = 2.5458e-01, time/batch = 19.9940s	
18762/22750 (epoch 41.235), train_loss = 0.56434534, grad/param norm = 2.4728e-01, time/batch = 19.0136s	
18763/22750 (epoch 41.237), train_loss = 0.63276413, grad/param norm = 2.7239e-01, time/batch = 17.0187s	
18764/22750 (epoch 41.240), train_loss = 0.68982625, grad/param norm = 1.9329e-01, time/batch = 20.4417s	
18765/22750 (epoch 41.242), train_loss = 0.83200974, grad/param norm = 2.8488e-01, time/batch = 19.4911s	
18766/22750 (epoch 41.244), train_loss = 0.84208174, grad/param norm = 2.3886e-01, time/batch = 18.1583s	
18767/22750 (epoch 41.246), train_loss = 0.83941132, grad/param norm = 2.5319e-01, time/batch = 20.3180s	
18768/22750 (epoch 41.248), train_loss = 0.69811009, grad/param norm = 2.1294e-01, time/batch = 18.0856s	
18769/22750 (epoch 41.251), train_loss = 0.79528432, grad/param norm = 2.4949e-01, time/batch = 18.5141s	
18770/22750 (epoch 41.253), train_loss = 0.77217811, grad/param norm = 2.7397e-01, time/batch = 20.6638s	
18771/22750 (epoch 41.255), train_loss = 0.74979099, grad/param norm = 2.3342e-01, time/batch = 32.1686s	
18772/22750 (epoch 41.257), train_loss = 0.65252784, grad/param norm = 2.1956e-01, time/batch = 19.6920s	
18773/22750 (epoch 41.259), train_loss = 0.80205642, grad/param norm = 2.7213e-01, time/batch = 17.4940s	
18774/22750 (epoch 41.262), train_loss = 0.74824152, grad/param norm = 2.6206e-01, time/batch = 16.4411s	
18775/22750 (epoch 41.264), train_loss = 0.56908599, grad/param norm = 2.3062e-01, time/batch = 16.0371s	
18776/22750 (epoch 41.266), train_loss = 0.70895826, grad/param norm = 2.6714e-01, time/batch = 16.9095s	
18777/22750 (epoch 41.268), train_loss = 0.84046231, grad/param norm = 2.7077e-01, time/batch = 16.4235s	
18778/22750 (epoch 41.270), train_loss = 0.64594888, grad/param norm = 2.5047e-01, time/batch = 16.4816s	
18779/22750 (epoch 41.273), train_loss = 0.94904161, grad/param norm = 2.6599e-01, time/batch = 17.2672s	
18780/22750 (epoch 41.275), train_loss = 0.83266480, grad/param norm = 2.0652e-01, time/batch = 18.1000s	
18781/22750 (epoch 41.277), train_loss = 0.70569948, grad/param norm = 2.5611e-01, time/batch = 18.0138s	
18782/22750 (epoch 41.279), train_loss = 0.61060099, grad/param norm = 2.0804e-01, time/batch = 18.4910s	
18783/22750 (epoch 41.281), train_loss = 0.83981857, grad/param norm = 2.4920e-01, time/batch = 19.7305s	
18784/22750 (epoch 41.284), train_loss = 0.75232846, grad/param norm = 2.1008e-01, time/batch = 19.1498s	
18785/22750 (epoch 41.286), train_loss = 0.78152181, grad/param norm = 2.3680e-01, time/batch = 19.6457s	
18786/22750 (epoch 41.288), train_loss = 0.85927286, grad/param norm = 2.5745e-01, time/batch = 19.1768s	
18787/22750 (epoch 41.290), train_loss = 0.77546534, grad/param norm = 2.4200e-01, time/batch = 17.2170s	
18788/22750 (epoch 41.292), train_loss = 0.80199785, grad/param norm = 2.8872e-01, time/batch = 19.5926s	
18789/22750 (epoch 41.295), train_loss = 0.75407483, grad/param norm = 2.3645e-01, time/batch = 20.1038s	
18790/22750 (epoch 41.297), train_loss = 0.75157973, grad/param norm = 2.4124e-01, time/batch = 18.6091s	
18791/22750 (epoch 41.299), train_loss = 0.81178152, grad/param norm = 2.6323e-01, time/batch = 20.4125s	
18792/22750 (epoch 41.301), train_loss = 0.71590382, grad/param norm = 2.2660e-01, time/batch = 20.4814s	
18793/22750 (epoch 41.303), train_loss = 0.78157397, grad/param norm = 2.5550e-01, time/batch = 18.2485s	
18794/22750 (epoch 41.305), train_loss = 0.86221620, grad/param norm = 2.2460e-01, time/batch = 18.5600s	
18795/22750 (epoch 41.308), train_loss = 0.79726071, grad/param norm = 2.5146e-01, time/batch = 18.9986s	
18796/22750 (epoch 41.310), train_loss = 0.66525473, grad/param norm = 2.4326e-01, time/batch = 17.8453s	
18797/22750 (epoch 41.312), train_loss = 0.75247449, grad/param norm = 2.5850e-01, time/batch = 18.6884s	
18798/22750 (epoch 41.314), train_loss = 0.76606200, grad/param norm = 2.5107e-01, time/batch = 20.5911s	
18799/22750 (epoch 41.316), train_loss = 0.71248212, grad/param norm = 2.2261e-01, time/batch = 19.1770s	
18800/22750 (epoch 41.319), train_loss = 0.75926731, grad/param norm = 2.6081e-01, time/batch = 19.5768s	
18801/22750 (epoch 41.321), train_loss = 0.68543942, grad/param norm = 2.3852e-01, time/batch = 18.9162s	
18802/22750 (epoch 41.323), train_loss = 0.76769436, grad/param norm = 2.4348e-01, time/batch = 18.4674s	
18803/22750 (epoch 41.325), train_loss = 0.64788666, grad/param norm = 2.1196e-01, time/batch = 18.5818s	
18804/22750 (epoch 41.327), train_loss = 0.68235893, grad/param norm = 2.8186e-01, time/batch = 18.0731s	
18805/22750 (epoch 41.330), train_loss = 0.84270578, grad/param norm = 2.3687e-01, time/batch = 19.3529s	
18806/22750 (epoch 41.332), train_loss = 0.92702113, grad/param norm = 2.4017e-01, time/batch = 17.9344s	
18807/22750 (epoch 41.334), train_loss = 0.58077649, grad/param norm = 2.2976e-01, time/batch = 17.0913s	
18808/22750 (epoch 41.336), train_loss = 0.81669139, grad/param norm = 2.4315e-01, time/batch = 17.7727s	
18809/22750 (epoch 41.338), train_loss = 0.72406383, grad/param norm = 2.2797e-01, time/batch = 16.9282s	
18810/22750 (epoch 41.341), train_loss = 0.73273145, grad/param norm = 2.3359e-01, time/batch = 18.9276s	
18811/22750 (epoch 41.343), train_loss = 0.63836635, grad/param norm = 2.5984e-01, time/batch = 18.3400s	
18812/22750 (epoch 41.345), train_loss = 0.76893022, grad/param norm = 3.0868e-01, time/batch = 17.8561s	
18813/22750 (epoch 41.347), train_loss = 0.81957127, grad/param norm = 2.3420e-01, time/batch = 17.6727s	
18814/22750 (epoch 41.349), train_loss = 0.60063661, grad/param norm = 2.5339e-01, time/batch = 19.8382s	
18815/22750 (epoch 41.352), train_loss = 0.85970444, grad/param norm = 2.2928e-01, time/batch = 19.8414s	
18816/22750 (epoch 41.354), train_loss = 0.83633552, grad/param norm = 2.6141e-01, time/batch = 17.6157s	
18817/22750 (epoch 41.356), train_loss = 0.79970727, grad/param norm = 2.2748e-01, time/batch = 18.6241s	
18818/22750 (epoch 41.358), train_loss = 0.70919250, grad/param norm = 2.4550e-01, time/batch = 19.0032s	
18819/22750 (epoch 41.360), train_loss = 0.87596685, grad/param norm = 2.2321e-01, time/batch = 17.2233s	
18820/22750 (epoch 41.363), train_loss = 0.69152867, grad/param norm = 2.6632e-01, time/batch = 18.6656s	
18821/22750 (epoch 41.365), train_loss = 0.59094129, grad/param norm = 2.4072e-01, time/batch = 18.4976s	
18822/22750 (epoch 41.367), train_loss = 0.68273581, grad/param norm = 2.4709e-01, time/batch = 17.5123s	
18823/22750 (epoch 41.369), train_loss = 0.77382607, grad/param norm = 2.5951e-01, time/batch = 18.6784s	
18824/22750 (epoch 41.371), train_loss = 0.76979476, grad/param norm = 2.6116e-01, time/batch = 20.1922s	
18825/22750 (epoch 41.374), train_loss = 0.66446911, grad/param norm = 2.4540e-01, time/batch = 18.0390s	
18826/22750 (epoch 41.376), train_loss = 0.73557546, grad/param norm = 2.3065e-01, time/batch = 17.3588s	
18827/22750 (epoch 41.378), train_loss = 0.75660982, grad/param norm = 2.2254e-01, time/batch = 18.9311s	
18828/22750 (epoch 41.380), train_loss = 0.81695546, grad/param norm = 2.6513e-01, time/batch = 18.8324s	
18829/22750 (epoch 41.382), train_loss = 0.69831801, grad/param norm = 2.1977e-01, time/batch = 17.0084s	
18830/22750 (epoch 41.385), train_loss = 0.79480103, grad/param norm = 2.4403e-01, time/batch = 18.7591s	
18831/22750 (epoch 41.387), train_loss = 0.77125155, grad/param norm = 2.3169e-01, time/batch = 19.5026s	
18832/22750 (epoch 41.389), train_loss = 0.61018153, grad/param norm = 2.1260e-01, time/batch = 18.6030s	
18833/22750 (epoch 41.391), train_loss = 0.46815577, grad/param norm = 1.8957e-01, time/batch = 17.7182s	
18834/22750 (epoch 41.393), train_loss = 0.60594518, grad/param norm = 2.0709e-01, time/batch = 18.0280s	
18835/22750 (epoch 41.396), train_loss = 0.75368216, grad/param norm = 2.2308e-01, time/batch = 17.9942s	
18836/22750 (epoch 41.398), train_loss = 0.68306839, grad/param norm = 2.0779e-01, time/batch = 20.3106s	
18837/22750 (epoch 41.400), train_loss = 0.74110202, grad/param norm = 2.7059e-01, time/batch = 20.4840s	
18838/22750 (epoch 41.402), train_loss = 0.74615677, grad/param norm = 2.1588e-01, time/batch = 16.8076s	
18839/22750 (epoch 41.404), train_loss = 0.82022984, grad/param norm = 2.2487e-01, time/batch = 16.8390s	
18840/22750 (epoch 41.407), train_loss = 0.81842082, grad/param norm = 2.5615e-01, time/batch = 17.5022s	
18841/22750 (epoch 41.409), train_loss = 0.68662438, grad/param norm = 2.3416e-01, time/batch = 18.5773s	
18842/22750 (epoch 41.411), train_loss = 0.67864253, grad/param norm = 2.2355e-01, time/batch = 18.9987s	
18843/22750 (epoch 41.413), train_loss = 0.52791109, grad/param norm = 2.3986e-01, time/batch = 20.1112s	
18844/22750 (epoch 41.415), train_loss = 0.61857627, grad/param norm = 2.3023e-01, time/batch = 19.9971s	
18845/22750 (epoch 41.418), train_loss = 0.68166071, grad/param norm = 2.2777e-01, time/batch = 17.4154s	
18846/22750 (epoch 41.420), train_loss = 0.79260393, grad/param norm = 2.5397e-01, time/batch = 18.8078s	
18847/22750 (epoch 41.422), train_loss = 0.92335817, grad/param norm = 2.8121e-01, time/batch = 20.1545s	
18848/22750 (epoch 41.424), train_loss = 0.92577187, grad/param norm = 2.5417e-01, time/batch = 17.0464s	
18849/22750 (epoch 41.426), train_loss = 0.90387285, grad/param norm = 2.5253e-01, time/batch = 20.6486s	
18850/22750 (epoch 41.429), train_loss = 0.67425980, grad/param norm = 2.2927e-01, time/batch = 20.0957s	
18851/22750 (epoch 41.431), train_loss = 0.61666224, grad/param norm = 2.1821e-01, time/batch = 20.3120s	
18852/22750 (epoch 41.433), train_loss = 0.69483963, grad/param norm = 2.4272e-01, time/batch = 19.3134s	
18853/22750 (epoch 41.435), train_loss = 0.53123887, grad/param norm = 1.7622e-01, time/batch = 17.5689s	
18854/22750 (epoch 41.437), train_loss = 0.48051962, grad/param norm = 1.8052e-01, time/batch = 16.5413s	
18855/22750 (epoch 41.440), train_loss = 0.68700206, grad/param norm = 2.5254e-01, time/batch = 16.6116s	
18856/22750 (epoch 41.442), train_loss = 0.71627374, grad/param norm = 2.6191e-01, time/batch = 17.0245s	
18857/22750 (epoch 41.444), train_loss = 0.69181840, grad/param norm = 2.3832e-01, time/batch = 17.1210s	
18858/22750 (epoch 41.446), train_loss = 0.68736541, grad/param norm = 2.4011e-01, time/batch = 17.1133s	
18859/22750 (epoch 41.448), train_loss = 0.92510061, grad/param norm = 2.6858e-01, time/batch = 17.1315s	
18860/22750 (epoch 41.451), train_loss = 0.87191836, grad/param norm = 2.2825e-01, time/batch = 17.2143s	
18861/22750 (epoch 41.453), train_loss = 0.75717288, grad/param norm = 2.4451e-01, time/batch = 17.2992s	
18862/22750 (epoch 41.455), train_loss = 0.87945323, grad/param norm = 2.3879e-01, time/batch = 18.2093s	
18863/22750 (epoch 41.457), train_loss = 0.78702719, grad/param norm = 3.8092e-01, time/batch = 19.1769s	
18864/22750 (epoch 41.459), train_loss = 0.79107077, grad/param norm = 2.3007e-01, time/batch = 17.3313s	
18865/22750 (epoch 41.462), train_loss = 0.74479271, grad/param norm = 2.2282e-01, time/batch = 18.7518s	
18866/22750 (epoch 41.464), train_loss = 0.63437965, grad/param norm = 2.4549e-01, time/batch = 16.7016s	
18867/22750 (epoch 41.466), train_loss = 0.80169552, grad/param norm = 3.3310e-01, time/batch = 17.8427s	
18868/22750 (epoch 41.468), train_loss = 0.78294221, grad/param norm = 2.4473e-01, time/batch = 17.3406s	
18869/22750 (epoch 41.470), train_loss = 0.84327054, grad/param norm = 2.5699e-01, time/batch = 18.0996s	
18870/22750 (epoch 41.473), train_loss = 0.70336414, grad/param norm = 2.3015e-01, time/batch = 18.8558s	
18871/22750 (epoch 41.475), train_loss = 0.75574730, grad/param norm = 2.4582e-01, time/batch = 17.8169s	
18872/22750 (epoch 41.477), train_loss = 0.64909188, grad/param norm = 2.4003e-01, time/batch = 20.4053s	
18873/22750 (epoch 41.479), train_loss = 0.61593920, grad/param norm = 2.0796e-01, time/batch = 19.0059s	
18874/22750 (epoch 41.481), train_loss = 0.58863327, grad/param norm = 2.0261e-01, time/batch = 17.8437s	
18875/22750 (epoch 41.484), train_loss = 0.50025639, grad/param norm = 2.0675e-01, time/batch = 19.4921s	
18876/22750 (epoch 41.486), train_loss = 0.60706483, grad/param norm = 2.4145e-01, time/batch = 15.1936s	
18877/22750 (epoch 41.488), train_loss = 0.56250166, grad/param norm = 2.0454e-01, time/batch = 18.3548s	
18878/22750 (epoch 41.490), train_loss = 0.70426817, grad/param norm = 2.1696e-01, time/batch = 18.6195s	
18879/22750 (epoch 41.492), train_loss = 0.79761093, grad/param norm = 2.4683e-01, time/batch = 18.1780s	
18880/22750 (epoch 41.495), train_loss = 0.65990084, grad/param norm = 2.3377e-01, time/batch = 19.7575s	
18881/22750 (epoch 41.497), train_loss = 0.71457934, grad/param norm = 2.4085e-01, time/batch = 17.9341s	
18882/22750 (epoch 41.499), train_loss = 0.63663469, grad/param norm = 2.2868e-01, time/batch = 16.4955s	
18883/22750 (epoch 41.501), train_loss = 0.68908178, grad/param norm = 2.4154e-01, time/batch = 18.1637s	
18884/22750 (epoch 41.503), train_loss = 0.68066526, grad/param norm = 2.2084e-01, time/batch = 16.8387s	
18885/22750 (epoch 41.505), train_loss = 0.61802607, grad/param norm = 2.3148e-01, time/batch = 19.3198s	
18886/22750 (epoch 41.508), train_loss = 0.60087389, grad/param norm = 2.4719e-01, time/batch = 17.2645s	
18887/22750 (epoch 41.510), train_loss = 0.60703205, grad/param norm = 2.3088e-01, time/batch = 18.2592s	
18888/22750 (epoch 41.512), train_loss = 0.66591244, grad/param norm = 2.3984e-01, time/batch = 17.0965s	
18889/22750 (epoch 41.514), train_loss = 0.67322208, grad/param norm = 2.4083e-01, time/batch = 18.0385s	
18890/22750 (epoch 41.516), train_loss = 0.65015750, grad/param norm = 2.2053e-01, time/batch = 18.7440s	
18891/22750 (epoch 41.519), train_loss = 0.79135503, grad/param norm = 2.3675e-01, time/batch = 19.1758s	
18892/22750 (epoch 41.521), train_loss = 0.70581438, grad/param norm = 2.2802e-01, time/batch = 19.9001s	
18893/22750 (epoch 41.523), train_loss = 0.64324256, grad/param norm = 2.4459e-01, time/batch = 18.5100s	
18894/22750 (epoch 41.525), train_loss = 0.84034705, grad/param norm = 2.9107e-01, time/batch = 16.6605s	
18895/22750 (epoch 41.527), train_loss = 0.75347095, grad/param norm = 2.3389e-01, time/batch = 16.6686s	
18896/22750 (epoch 41.530), train_loss = 0.64440461, grad/param norm = 2.2016e-01, time/batch = 20.5872s	
18897/22750 (epoch 41.532), train_loss = 0.59915755, grad/param norm = 2.3295e-01, time/batch = 18.2003s	
18898/22750 (epoch 41.534), train_loss = 0.77156067, grad/param norm = 2.4832e-01, time/batch = 19.9525s	
18899/22750 (epoch 41.536), train_loss = 0.74687187, grad/param norm = 2.2186e-01, time/batch = 19.4195s	
18900/22750 (epoch 41.538), train_loss = 0.72924198, grad/param norm = 2.2583e-01, time/batch = 17.0749s	
18901/22750 (epoch 41.541), train_loss = 0.62853956, grad/param norm = 2.3809e-01, time/batch = 19.4819s	
18902/22750 (epoch 41.543), train_loss = 0.61273138, grad/param norm = 2.1165e-01, time/batch = 18.5014s	
18903/22750 (epoch 41.545), train_loss = 0.78319277, grad/param norm = 2.4691e-01, time/batch = 19.4104s	
18904/22750 (epoch 41.547), train_loss = 0.66662946, grad/param norm = 2.0979e-01, time/batch = 19.3393s	
18905/22750 (epoch 41.549), train_loss = 0.67689222, grad/param norm = 2.1345e-01, time/batch = 18.7995s	
18906/22750 (epoch 41.552), train_loss = 0.75351387, grad/param norm = 2.3160e-01, time/batch = 19.0330s	
18907/22750 (epoch 41.554), train_loss = 0.77217153, grad/param norm = 2.6283e-01, time/batch = 19.1661s	
18908/22750 (epoch 41.556), train_loss = 0.75938004, grad/param norm = 2.3865e-01, time/batch = 17.3957s	
18909/22750 (epoch 41.558), train_loss = 0.71441916, grad/param norm = 2.3448e-01, time/batch = 18.6618s	
18910/22750 (epoch 41.560), train_loss = 0.67412525, grad/param norm = 2.1147e-01, time/batch = 16.4853s	
18911/22750 (epoch 41.563), train_loss = 0.79318410, grad/param norm = 2.4341e-01, time/batch = 17.4800s	
18912/22750 (epoch 41.565), train_loss = 0.77667883, grad/param norm = 2.6174e-01, time/batch = 17.6496s	
18913/22750 (epoch 41.567), train_loss = 0.74455700, grad/param norm = 2.2940e-01, time/batch = 17.0129s	
18914/22750 (epoch 41.569), train_loss = 0.71380076, grad/param norm = 2.2459e-01, time/batch = 19.3494s	
18915/22750 (epoch 41.571), train_loss = 0.70160214, grad/param norm = 2.4907e-01, time/batch = 18.9379s	
18916/22750 (epoch 41.574), train_loss = 0.72129878, grad/param norm = 2.4345e-01, time/batch = 18.7860s	
18917/22750 (epoch 41.576), train_loss = 0.69196373, grad/param norm = 2.2506e-01, time/batch = 18.9110s	
18918/22750 (epoch 41.578), train_loss = 0.61927863, grad/param norm = 2.1595e-01, time/batch = 17.6562s	
18919/22750 (epoch 41.580), train_loss = 0.75881927, grad/param norm = 2.7459e-01, time/batch = 19.2390s	
18920/22750 (epoch 41.582), train_loss = 0.63631888, grad/param norm = 1.9436e-01, time/batch = 18.6585s	
18921/22750 (epoch 41.585), train_loss = 0.61329406, grad/param norm = 2.1742e-01, time/batch = 18.8088s	
18922/22750 (epoch 41.587), train_loss = 0.62802387, grad/param norm = 2.0012e-01, time/batch = 17.0719s	
18923/22750 (epoch 41.589), train_loss = 0.54629363, grad/param norm = 2.0012e-01, time/batch = 19.0033s	
18924/22750 (epoch 41.591), train_loss = 0.71658368, grad/param norm = 2.0828e-01, time/batch = 20.5238s	
18925/22750 (epoch 41.593), train_loss = 0.81087778, grad/param norm = 2.3854e-01, time/batch = 20.8710s	
18926/22750 (epoch 41.596), train_loss = 0.78529251, grad/param norm = 2.3542e-01, time/batch = 17.5030s	
18927/22750 (epoch 41.598), train_loss = 0.79187483, grad/param norm = 2.7492e-01, time/batch = 18.3260s	
18928/22750 (epoch 41.600), train_loss = 0.84708448, grad/param norm = 2.5059e-01, time/batch = 15.7634s	
18929/22750 (epoch 41.602), train_loss = 0.64184121, grad/param norm = 2.2435e-01, time/batch = 17.2323s	
18930/22750 (epoch 41.604), train_loss = 0.68340763, grad/param norm = 2.4353e-01, time/batch = 19.9068s	
18931/22750 (epoch 41.607), train_loss = 0.63648259, grad/param norm = 2.0695e-01, time/batch = 18.9975s	
18932/22750 (epoch 41.609), train_loss = 0.60044237, grad/param norm = 2.4002e-01, time/batch = 17.6164s	
18933/22750 (epoch 41.611), train_loss = 0.67434648, grad/param norm = 2.3156e-01, time/batch = 19.3350s	
18934/22750 (epoch 41.613), train_loss = 0.64674734, grad/param norm = 2.4747e-01, time/batch = 20.3602s	
18935/22750 (epoch 41.615), train_loss = 0.67432516, grad/param norm = 2.2064e-01, time/batch = 19.0035s	
18936/22750 (epoch 41.618), train_loss = 0.69670001, grad/param norm = 2.0353e-01, time/batch = 17.2483s	
18937/22750 (epoch 41.620), train_loss = 0.67626441, grad/param norm = 2.3578e-01, time/batch = 20.4000s	
18938/22750 (epoch 41.622), train_loss = 0.59588815, grad/param norm = 1.7786e-01, time/batch = 20.0772s	
18939/22750 (epoch 41.624), train_loss = 0.67415330, grad/param norm = 3.0239e-01, time/batch = 17.9974s	
18940/22750 (epoch 41.626), train_loss = 0.57395462, grad/param norm = 2.4195e-01, time/batch = 18.4398s	
18941/22750 (epoch 41.629), train_loss = 0.65799320, grad/param norm = 2.2246e-01, time/batch = 19.9590s	
18942/22750 (epoch 41.631), train_loss = 0.68265676, grad/param norm = 1.9687e-01, time/batch = 18.5247s	
18943/22750 (epoch 41.633), train_loss = 0.59381473, grad/param norm = 2.0118e-01, time/batch = 18.2518s	
18944/22750 (epoch 41.635), train_loss = 0.70068421, grad/param norm = 2.1281e-01, time/batch = 19.9881s	
18945/22750 (epoch 41.637), train_loss = 0.74628503, grad/param norm = 2.8416e-01, time/batch = 18.3294s	
18946/22750 (epoch 41.640), train_loss = 0.75281910, grad/param norm = 2.6743e-01, time/batch = 19.1601s	
18947/22750 (epoch 41.642), train_loss = 0.80343009, grad/param norm = 2.2750e-01, time/batch = 18.5868s	
18948/22750 (epoch 41.644), train_loss = 0.70619428, grad/param norm = 2.5038e-01, time/batch = 18.1658s	
18949/22750 (epoch 41.646), train_loss = 0.77759007, grad/param norm = 3.0656e-01, time/batch = 18.1788s	
18950/22750 (epoch 41.648), train_loss = 0.74148068, grad/param norm = 2.2121e-01, time/batch = 19.3550s	
18951/22750 (epoch 41.651), train_loss = 0.76350738, grad/param norm = 2.4660e-01, time/batch = 19.1920s	
18952/22750 (epoch 41.653), train_loss = 0.77340963, grad/param norm = 2.0664e-01, time/batch = 19.3507s	
18953/22750 (epoch 41.655), train_loss = 0.72569732, grad/param norm = 2.1956e-01, time/batch = 18.6576s	
18954/22750 (epoch 41.657), train_loss = 0.82716557, grad/param norm = 2.4291e-01, time/batch = 18.1520s	
18955/22750 (epoch 41.659), train_loss = 0.87061633, grad/param norm = 2.2546e-01, time/batch = 17.7607s	
18956/22750 (epoch 41.662), train_loss = 0.85812263, grad/param norm = 3.2591e-01, time/batch = 19.0715s	
18957/22750 (epoch 41.664), train_loss = 0.75957668, grad/param norm = 2.3557e-01, time/batch = 18.2560s	
18958/22750 (epoch 41.666), train_loss = 0.62343775, grad/param norm = 2.1704e-01, time/batch = 18.5032s	
18959/22750 (epoch 41.668), train_loss = 0.69639350, grad/param norm = 2.2653e-01, time/batch = 18.9329s	
18960/22750 (epoch 41.670), train_loss = 0.66943845, grad/param norm = 2.2632e-01, time/batch = 19.7908s	
18961/22750 (epoch 41.673), train_loss = 0.87274996, grad/param norm = 2.7513e-01, time/batch = 17.8653s	
18962/22750 (epoch 41.675), train_loss = 0.98477431, grad/param norm = 3.5299e-01, time/batch = 18.3492s	
18963/22750 (epoch 41.677), train_loss = 0.85116771, grad/param norm = 2.5915e-01, time/batch = 19.4162s	
18964/22750 (epoch 41.679), train_loss = 0.84918347, grad/param norm = 2.9250e-01, time/batch = 27.2710s	
18965/22750 (epoch 41.681), train_loss = 0.84715215, grad/param norm = 2.5882e-01, time/batch = 23.7491s	
18966/22750 (epoch 41.684), train_loss = 0.86763027, grad/param norm = 2.3866e-01, time/batch = 18.5158s	
18967/22750 (epoch 41.686), train_loss = 0.91212453, grad/param norm = 2.8638e-01, time/batch = 16.8259s	
18968/22750 (epoch 41.688), train_loss = 0.86437134, grad/param norm = 2.6920e-01, time/batch = 17.8474s	
18969/22750 (epoch 41.690), train_loss = 0.84553181, grad/param norm = 2.5694e-01, time/batch = 16.1973s	
18970/22750 (epoch 41.692), train_loss = 0.85029331, grad/param norm = 2.4119e-01, time/batch = 16.1709s	
18971/22750 (epoch 41.695), train_loss = 0.76308141, grad/param norm = 2.4693e-01, time/batch = 15.8501s	
18972/22750 (epoch 41.697), train_loss = 0.76803888, grad/param norm = 2.1720e-01, time/batch = 16.0996s	
18973/22750 (epoch 41.699), train_loss = 0.68566690, grad/param norm = 2.3640e-01, time/batch = 15.6919s	
18974/22750 (epoch 41.701), train_loss = 0.61841847, grad/param norm = 2.3634e-01, time/batch = 16.2635s	
18975/22750 (epoch 41.703), train_loss = 0.71411296, grad/param norm = 2.6099e-01, time/batch = 16.0125s	
18976/22750 (epoch 41.705), train_loss = 0.68129753, grad/param norm = 2.0925e-01, time/batch = 15.6923s	
18977/22750 (epoch 41.708), train_loss = 0.72732274, grad/param norm = 2.7844e-01, time/batch = 15.7817s	
18978/22750 (epoch 41.710), train_loss = 0.64918094, grad/param norm = 2.5094e-01, time/batch = 16.1976s	
18979/22750 (epoch 41.712), train_loss = 0.57450383, grad/param norm = 2.1823e-01, time/batch = 15.6306s	
18980/22750 (epoch 41.714), train_loss = 0.61252158, grad/param norm = 2.1261e-01, time/batch = 15.6305s	
18981/22750 (epoch 41.716), train_loss = 0.63784692, grad/param norm = 2.4498e-01, time/batch = 16.3416s	
18982/22750 (epoch 41.719), train_loss = 0.68670274, grad/param norm = 2.6078e-01, time/batch = 16.1704s	
18983/22750 (epoch 41.721), train_loss = 0.80561902, grad/param norm = 2.2145e-01, time/batch = 15.8390s	
18984/22750 (epoch 41.723), train_loss = 0.79188080, grad/param norm = 2.5481e-01, time/batch = 16.4101s	
18985/22750 (epoch 41.725), train_loss = 0.69707374, grad/param norm = 2.5371e-01, time/batch = 16.1541s	
18986/22750 (epoch 41.727), train_loss = 0.72094245, grad/param norm = 2.3376e-01, time/batch = 16.0056s	
18987/22750 (epoch 41.730), train_loss = 0.68310655, grad/param norm = 2.1885e-01, time/batch = 15.6151s	
18988/22750 (epoch 41.732), train_loss = 0.66737161, grad/param norm = 2.2887e-01, time/batch = 15.5525s	
18989/22750 (epoch 41.734), train_loss = 0.60417100, grad/param norm = 1.8843e-01, time/batch = 16.0419s	
18990/22750 (epoch 41.736), train_loss = 0.70064739, grad/param norm = 2.7637e-01, time/batch = 15.7870s	
18991/22750 (epoch 41.738), train_loss = 0.76171994, grad/param norm = 2.5802e-01, time/batch = 15.7815s	
18992/22750 (epoch 41.741), train_loss = 0.83979817, grad/param norm = 2.3239e-01, time/batch = 15.6910s	
18993/22750 (epoch 41.743), train_loss = 0.73541844, grad/param norm = 2.2334e-01, time/batch = 16.1064s	
18994/22750 (epoch 41.745), train_loss = 0.61263887, grad/param norm = 1.9981e-01, time/batch = 16.1724s	
18995/22750 (epoch 41.747), train_loss = 0.71202003, grad/param norm = 2.2017e-01, time/batch = 15.6096s	
18996/22750 (epoch 41.749), train_loss = 0.81487815, grad/param norm = 2.5574e-01, time/batch = 16.0192s	
18997/22750 (epoch 41.752), train_loss = 0.73751661, grad/param norm = 2.5050e-01, time/batch = 15.9516s	
18998/22750 (epoch 41.754), train_loss = 0.72774165, grad/param norm = 2.5451e-01, time/batch = 15.7692s	
18999/22750 (epoch 41.756), train_loss = 0.66284601, grad/param norm = 2.5091e-01, time/batch = 15.6363s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_wakata_epoch41.76_1.7623.t7	
19000/22750 (epoch 41.758), train_loss = 0.65673622, grad/param norm = 2.1350e-01, time/batch = 16.1066s	
19001/22750 (epoch 41.760), train_loss = 1.53161609, grad/param norm = 4.0298e-01, time/batch = 16.1697s	
19002/22750 (epoch 41.763), train_loss = 0.72170946, grad/param norm = 2.5030e-01, time/batch = 16.1810s	
19003/22750 (epoch 41.765), train_loss = 0.71815159, grad/param norm = 2.5460e-01, time/batch = 15.7943s	
19004/22750 (epoch 41.767), train_loss = 0.75903903, grad/param norm = 2.2461e-01, time/batch = 15.7927s	
19005/22750 (epoch 41.769), train_loss = 0.82331975, grad/param norm = 2.6342e-01, time/batch = 16.2732s	
19006/22750 (epoch 41.771), train_loss = 0.87252805, grad/param norm = 2.9057e-01, time/batch = 16.7532s	
19007/22750 (epoch 41.774), train_loss = 0.66554600, grad/param norm = 2.3704e-01, time/batch = 16.3323s	
19008/22750 (epoch 41.776), train_loss = 0.79618159, grad/param norm = 2.7293e-01, time/batch = 15.6710s	
19009/22750 (epoch 41.778), train_loss = 0.85029580, grad/param norm = 2.5949e-01, time/batch = 16.7972s	
19010/22750 (epoch 41.780), train_loss = 0.74284484, grad/param norm = 2.3471e-01, time/batch = 16.1665s	
19011/22750 (epoch 41.782), train_loss = 0.85316256, grad/param norm = 2.4006e-01, time/batch = 16.0207s	
19012/22750 (epoch 41.785), train_loss = 0.72162015, grad/param norm = 2.5211e-01, time/batch = 16.2525s	
19013/22750 (epoch 41.787), train_loss = 0.61121272, grad/param norm = 2.3695e-01, time/batch = 16.0135s	
19014/22750 (epoch 41.789), train_loss = 0.70368459, grad/param norm = 2.2836e-01, time/batch = 15.6328s	
19015/22750 (epoch 41.791), train_loss = 0.67652724, grad/param norm = 2.2953e-01, time/batch = 15.6378s	
19016/22750 (epoch 41.793), train_loss = 0.66135543, grad/param norm = 2.6957e-01, time/batch = 15.7876s	
19017/22750 (epoch 41.796), train_loss = 0.61613954, grad/param norm = 2.0451e-01, time/batch = 15.9512s	
19018/22750 (epoch 41.798), train_loss = 0.67013447, grad/param norm = 2.0984e-01, time/batch = 16.0911s	
19019/22750 (epoch 41.800), train_loss = 0.66697135, grad/param norm = 2.5160e-01, time/batch = 15.6934s	
19020/22750 (epoch 41.802), train_loss = 0.60486968, grad/param norm = 2.1688e-01, time/batch = 16.4345s	
19021/22750 (epoch 41.804), train_loss = 0.78833372, grad/param norm = 2.1090e-01, time/batch = 16.1589s	
19022/22750 (epoch 41.807), train_loss = 0.75956193, grad/param norm = 2.3854e-01, time/batch = 16.0888s	
19023/22750 (epoch 41.809), train_loss = 0.83643233, grad/param norm = 2.7235e-01, time/batch = 15.6932s	
19024/22750 (epoch 41.811), train_loss = 0.73394305, grad/param norm = 2.9169e-01, time/batch = 16.0140s	
19025/22750 (epoch 41.813), train_loss = 0.75797363, grad/param norm = 2.3780e-01, time/batch = 16.2656s	
19026/22750 (epoch 41.815), train_loss = 0.83352726, grad/param norm = 2.2514e-01, time/batch = 15.7922s	
19027/22750 (epoch 41.818), train_loss = 0.79190105, grad/param norm = 2.2653e-01, time/batch = 15.7848s	
19028/22750 (epoch 41.820), train_loss = 0.91044169, grad/param norm = 2.3053e-01, time/batch = 15.7183s	
19029/22750 (epoch 41.822), train_loss = 0.77108897, grad/param norm = 2.5820e-01, time/batch = 15.6104s	
19030/22750 (epoch 41.824), train_loss = 0.63086360, grad/param norm = 1.8708e-01, time/batch = 15.9960s	
19031/22750 (epoch 41.826), train_loss = 0.72041642, grad/param norm = 2.3520e-01, time/batch = 16.4782s	
19032/22750 (epoch 41.829), train_loss = 0.80904647, grad/param norm = 2.6342e-01, time/batch = 15.8374s	
19033/22750 (epoch 41.831), train_loss = 0.80597515, grad/param norm = 2.5507e-01, time/batch = 15.8524s	
19034/22750 (epoch 41.833), train_loss = 0.74901201, grad/param norm = 2.5505e-01, time/batch = 15.7745s	
19035/22750 (epoch 41.835), train_loss = 0.65990139, grad/param norm = 2.6643e-01, time/batch = 16.4170s	
19036/22750 (epoch 41.837), train_loss = 0.70590560, grad/param norm = 2.2882e-01, time/batch = 15.8760s	
19037/22750 (epoch 41.840), train_loss = 0.64945700, grad/param norm = 2.1206e-01, time/batch = 15.5488s	
19038/22750 (epoch 41.842), train_loss = 0.66908502, grad/param norm = 2.4670e-01, time/batch = 15.4715s	
19039/22750 (epoch 41.844), train_loss = 0.75275498, grad/param norm = 2.4704e-01, time/batch = 18.5195s	
19040/22750 (epoch 41.846), train_loss = 0.78664656, grad/param norm = 2.2609e-01, time/batch = 16.2009s	
19041/22750 (epoch 41.848), train_loss = 0.67773008, grad/param norm = 2.3857e-01, time/batch = 17.8344s	
19042/22750 (epoch 41.851), train_loss = 0.66852880, grad/param norm = 2.3502e-01, time/batch = 18.7352s	
19043/22750 (epoch 41.853), train_loss = 0.82731293, grad/param norm = 2.5271e-01, time/batch = 18.4831s	
19044/22750 (epoch 41.855), train_loss = 0.69006580, grad/param norm = 1.9570e-01, time/batch = 20.1489s	
19045/22750 (epoch 41.857), train_loss = 0.77582765, grad/param norm = 2.1869e-01, time/batch = 17.7532s	
19046/22750 (epoch 41.859), train_loss = 0.73313108, grad/param norm = 2.2415e-01, time/batch = 17.8495s	
19047/22750 (epoch 41.862), train_loss = 0.88975308, grad/param norm = 2.8483e-01, time/batch = 21.1802s	
19048/22750 (epoch 41.864), train_loss = 0.73959175, grad/param norm = 2.2835e-01, time/batch = 19.1685s	
19049/22750 (epoch 41.866), train_loss = 0.78640857, grad/param norm = 2.4539e-01, time/batch = 17.3958s	
19050/22750 (epoch 41.868), train_loss = 0.65247907, grad/param norm = 2.2950e-01, time/batch = 17.3365s	
19051/22750 (epoch 41.870), train_loss = 0.63461359, grad/param norm = 2.4354e-01, time/batch = 19.3144s	
19052/22750 (epoch 41.873), train_loss = 0.72902234, grad/param norm = 2.5142e-01, time/batch = 18.3954s	
19053/22750 (epoch 41.875), train_loss = 0.77237823, grad/param norm = 2.3449e-01, time/batch = 20.1519s	
19054/22750 (epoch 41.877), train_loss = 0.68370256, grad/param norm = 2.2584e-01, time/batch = 20.4086s	
19055/22750 (epoch 41.879), train_loss = 0.81014519, grad/param norm = 2.4379e-01, time/batch = 19.1867s	
19056/22750 (epoch 41.881), train_loss = 0.74003874, grad/param norm = 2.5231e-01, time/batch = 21.3439s	
19057/22750 (epoch 41.884), train_loss = 0.64890120, grad/param norm = 1.9854e-01, time/batch = 20.1708s	
19058/22750 (epoch 41.886), train_loss = 0.74453448, grad/param norm = 2.1770e-01, time/batch = 18.7493s	
19059/22750 (epoch 41.888), train_loss = 0.78043960, grad/param norm = 2.1428e-01, time/batch = 19.2191s	
19060/22750 (epoch 41.890), train_loss = 0.78348548, grad/param norm = 2.4376e-01, time/batch = 18.2511s	
19061/22750 (epoch 41.892), train_loss = 0.96333352, grad/param norm = 2.6600e-01, time/batch = 18.4123s	
19062/22750 (epoch 41.895), train_loss = 0.69524376, grad/param norm = 2.4259e-01, time/batch = 18.4967s	
19063/22750 (epoch 41.897), train_loss = 0.84902044, grad/param norm = 2.8037e-01, time/batch = 21.6630s	
19064/22750 (epoch 41.899), train_loss = 0.74125870, grad/param norm = 2.2171e-01, time/batch = 16.6506s	
19065/22750 (epoch 41.901), train_loss = 0.80717318, grad/param norm = 2.5390e-01, time/batch = 16.0749s	
19066/22750 (epoch 41.903), train_loss = 0.71319372, grad/param norm = 2.1738e-01, time/batch = 16.5116s	
19067/22750 (epoch 41.905), train_loss = 0.79105071, grad/param norm = 2.4206e-01, time/batch = 16.1790s	
19068/22750 (epoch 41.908), train_loss = 0.61218974, grad/param norm = 2.1744e-01, time/batch = 16.1440s	
19069/22750 (epoch 41.910), train_loss = 0.56401309, grad/param norm = 2.1726e-01, time/batch = 17.1837s	
19070/22750 (epoch 41.912), train_loss = 0.72516033, grad/param norm = 2.2026e-01, time/batch = 19.4033s	
19071/22750 (epoch 41.914), train_loss = 0.73737325, grad/param norm = 2.3653e-01, time/batch = 17.2189s	
19072/22750 (epoch 41.916), train_loss = 0.59082376, grad/param norm = 2.2627e-01, time/batch = 18.0027s	
19073/22750 (epoch 41.919), train_loss = 0.72244915, grad/param norm = 2.4016e-01, time/batch = 18.6825s	
19074/22750 (epoch 41.921), train_loss = 0.56696781, grad/param norm = 2.0450e-01, time/batch = 16.8416s	
19075/22750 (epoch 41.923), train_loss = 0.66451280, grad/param norm = 2.1522e-01, time/batch = 19.0936s	
19076/22750 (epoch 41.925), train_loss = 0.71833229, grad/param norm = 2.1832e-01, time/batch = 19.8426s	
19077/22750 (epoch 41.927), train_loss = 0.58191214, grad/param norm = 2.1272e-01, time/batch = 18.6592s	
19078/22750 (epoch 41.930), train_loss = 0.54334676, grad/param norm = 2.0043e-01, time/batch = 19.8960s	
19079/22750 (epoch 41.932), train_loss = 0.69046081, grad/param norm = 2.1559e-01, time/batch = 18.6448s	
19080/22750 (epoch 41.934), train_loss = 0.60027429, grad/param norm = 1.9160e-01, time/batch = 18.5766s	
19081/22750 (epoch 41.936), train_loss = 0.80662866, grad/param norm = 2.6214e-01, time/batch = 17.8252s	
19082/22750 (epoch 41.938), train_loss = 0.79269553, grad/param norm = 2.1279e-01, time/batch = 19.5085s	
19083/22750 (epoch 41.941), train_loss = 0.82290505, grad/param norm = 2.5814e-01, time/batch = 18.6908s	
19084/22750 (epoch 41.943), train_loss = 0.74133514, grad/param norm = 2.1740e-01, time/batch = 19.6652s	
19085/22750 (epoch 41.945), train_loss = 0.76792644, grad/param norm = 2.4801e-01, time/batch = 19.5993s	
19086/22750 (epoch 41.947), train_loss = 0.68195696, grad/param norm = 2.5405e-01, time/batch = 19.1412s	
19087/22750 (epoch 41.949), train_loss = 0.68407866, grad/param norm = 2.2792e-01, time/batch = 17.9076s	
19088/22750 (epoch 41.952), train_loss = 0.68500220, grad/param norm = 2.3553e-01, time/batch = 19.0778s	
19089/22750 (epoch 41.954), train_loss = 0.62941040, grad/param norm = 2.3802e-01, time/batch = 17.6770s	
19090/22750 (epoch 41.956), train_loss = 0.78215994, grad/param norm = 2.1803e-01, time/batch = 15.9084s	
19091/22750 (epoch 41.958), train_loss = 0.64696635, grad/param norm = 2.0587e-01, time/batch = 17.9954s	
19092/22750 (epoch 41.960), train_loss = 0.62180652, grad/param norm = 2.0462e-01, time/batch = 20.1031s	
19093/22750 (epoch 41.963), train_loss = 0.72372398, grad/param norm = 1.9665e-01, time/batch = 16.7874s	
19094/22750 (epoch 41.965), train_loss = 0.79036226, grad/param norm = 2.2819e-01, time/batch = 18.4379s	
19095/22750 (epoch 41.967), train_loss = 0.75094261, grad/param norm = 2.4555e-01, time/batch = 16.8275s	
19096/22750 (epoch 41.969), train_loss = 0.68365431, grad/param norm = 2.5223e-01, time/batch = 20.5025s	
19097/22750 (epoch 41.971), train_loss = 0.66034421, grad/param norm = 2.2944e-01, time/batch = 16.9137s	
19098/22750 (epoch 41.974), train_loss = 0.65474352, grad/param norm = 2.3118e-01, time/batch = 18.4927s	
19099/22750 (epoch 41.976), train_loss = 0.68234128, grad/param norm = 2.2545e-01, time/batch = 16.8108s	
19100/22750 (epoch 41.978), train_loss = 0.65605446, grad/param norm = 2.1383e-01, time/batch = 16.5676s	
19101/22750 (epoch 41.980), train_loss = 0.85069989, grad/param norm = 3.0372e-01, time/batch = 17.9194s	
19102/22750 (epoch 41.982), train_loss = 0.67391488, grad/param norm = 2.4667e-01, time/batch = 20.9192s	
19103/22750 (epoch 41.985), train_loss = 0.84172679, grad/param norm = 2.4703e-01, time/batch = 18.7036s	
19104/22750 (epoch 41.987), train_loss = 0.58801235, grad/param norm = 2.0218e-01, time/batch = 18.2666s	
19105/22750 (epoch 41.989), train_loss = 0.65344259, grad/param norm = 2.4116e-01, time/batch = 18.6788s	
19106/22750 (epoch 41.991), train_loss = 0.74906067, grad/param norm = 2.7357e-01, time/batch = 19.8290s	
19107/22750 (epoch 41.993), train_loss = 0.71413607, grad/param norm = 2.6403e-01, time/batch = 18.2418s	
19108/22750 (epoch 41.996), train_loss = 0.62962182, grad/param norm = 2.3732e-01, time/batch = 18.2416s	
19109/22750 (epoch 41.998), train_loss = 0.81805311, grad/param norm = 2.8175e-01, time/batch = 18.6565s	
decayed learning rate by a factor 0.97 to 0.00073197664853698	
19110/22750 (epoch 42.000), train_loss = 0.70012667, grad/param norm = 2.2099e-01, time/batch = 18.4883s	
19111/22750 (epoch 42.002), train_loss = 0.87370313, grad/param norm = 2.4054e-01, time/batch = 19.6835s	
19112/22750 (epoch 42.004), train_loss = 0.67768809, grad/param norm = 2.2782e-01, time/batch = 21.4328s	
19113/22750 (epoch 42.007), train_loss = 0.67655413, grad/param norm = 2.5867e-01, time/batch = 19.8404s	
19114/22750 (epoch 42.009), train_loss = 0.84007743, grad/param norm = 2.7639e-01, time/batch = 18.0789s	
19115/22750 (epoch 42.011), train_loss = 0.89785539, grad/param norm = 2.6853e-01, time/batch = 19.2608s	
19116/22750 (epoch 42.013), train_loss = 0.80434484, grad/param norm = 2.3631e-01, time/batch = 18.2454s	
19117/22750 (epoch 42.015), train_loss = 0.73670937, grad/param norm = 2.3642e-01, time/batch = 18.3241s	
19118/22750 (epoch 42.018), train_loss = 0.83901180, grad/param norm = 2.4535e-01, time/batch = 19.8314s	
19119/22750 (epoch 42.020), train_loss = 0.86804518, grad/param norm = 2.8516e-01, time/batch = 18.4238s	
19120/22750 (epoch 42.022), train_loss = 0.73867340, grad/param norm = 2.6901e-01, time/batch = 17.8551s	
19121/22750 (epoch 42.024), train_loss = 0.72648310, grad/param norm = 2.4722e-01, time/batch = 21.0845s	
19122/22750 (epoch 42.026), train_loss = 0.77406411, grad/param norm = 2.5710e-01, time/batch = 19.0261s	
19123/22750 (epoch 42.029), train_loss = 0.59222632, grad/param norm = 2.3118e-01, time/batch = 19.4947s	
19124/22750 (epoch 42.031), train_loss = 0.94634311, grad/param norm = 2.6433e-01, time/batch = 19.9809s	
19125/22750 (epoch 42.033), train_loss = 0.75512473, grad/param norm = 2.5844e-01, time/batch = 18.7324s	
19126/22750 (epoch 42.035), train_loss = 0.78053091, grad/param norm = 2.5226e-01, time/batch = 18.6455s	
19127/22750 (epoch 42.037), train_loss = 0.82000641, grad/param norm = 2.5152e-01, time/batch = 18.6641s	
19128/22750 (epoch 42.040), train_loss = 0.73875719, grad/param norm = 2.1236e-01, time/batch = 19.5588s	
19129/22750 (epoch 42.042), train_loss = 0.76559768, grad/param norm = 2.1866e-01, time/batch = 18.6830s	
19130/22750 (epoch 42.044), train_loss = 0.73291861, grad/param norm = 2.3698e-01, time/batch = 19.6081s	
19131/22750 (epoch 42.046), train_loss = 0.81190181, grad/param norm = 2.7514e-01, time/batch = 17.6930s	
19132/22750 (epoch 42.048), train_loss = 0.74441475, grad/param norm = 2.3473e-01, time/batch = 16.4445s	
19133/22750 (epoch 42.051), train_loss = 0.73608802, grad/param norm = 2.2965e-01, time/batch = 17.3962s	
19134/22750 (epoch 42.053), train_loss = 0.71727913, grad/param norm = 2.0771e-01, time/batch = 18.4879s	
19135/22750 (epoch 42.055), train_loss = 0.64296125, grad/param norm = 2.0441e-01, time/batch = 17.5143s	
19136/22750 (epoch 42.057), train_loss = 0.85239616, grad/param norm = 2.4952e-01, time/batch = 19.4185s	
19137/22750 (epoch 42.059), train_loss = 0.54425024, grad/param norm = 2.1117e-01, time/batch = 17.3441s	
19138/22750 (epoch 42.062), train_loss = 0.61348379, grad/param norm = 1.9544e-01, time/batch = 19.6821s	
19139/22750 (epoch 42.064), train_loss = 0.83383013, grad/param norm = 2.4593e-01, time/batch = 18.7661s	
19140/22750 (epoch 42.066), train_loss = 0.64977953, grad/param norm = 2.0798e-01, time/batch = 20.9320s	
19141/22750 (epoch 42.068), train_loss = 0.65515297, grad/param norm = 1.9936e-01, time/batch = 19.1853s	
19142/22750 (epoch 42.070), train_loss = 0.56526616, grad/param norm = 1.9037e-01, time/batch = 18.0820s	
19143/22750 (epoch 42.073), train_loss = 0.67507019, grad/param norm = 2.2462e-01, time/batch = 19.7423s	
19144/22750 (epoch 42.075), train_loss = 0.70739928, grad/param norm = 2.0475e-01, time/batch = 19.5738s	
19145/22750 (epoch 42.077), train_loss = 0.53615989, grad/param norm = 2.0415e-01, time/batch = 19.2441s	
19146/22750 (epoch 42.079), train_loss = 0.72192027, grad/param norm = 2.8795e-01, time/batch = 17.8269s	
19147/22750 (epoch 42.081), train_loss = 0.66491255, grad/param norm = 2.1009e-01, time/batch = 19.0824s	
19148/22750 (epoch 42.084), train_loss = 0.68817487, grad/param norm = 2.0615e-01, time/batch = 20.1904s	
19149/22750 (epoch 42.086), train_loss = 0.70977714, grad/param norm = 2.1480e-01, time/batch = 20.4367s	
19150/22750 (epoch 42.088), train_loss = 0.68041823, grad/param norm = 2.2883e-01, time/batch = 18.5724s	
19151/22750 (epoch 42.090), train_loss = 0.69725397, grad/param norm = 2.3680e-01, time/batch = 18.6658s	
19152/22750 (epoch 42.092), train_loss = 0.77654862, grad/param norm = 2.3050e-01, time/batch = 18.5073s	
19153/22750 (epoch 42.095), train_loss = 0.66701638, grad/param norm = 2.3156e-01, time/batch = 19.3264s	
19154/22750 (epoch 42.097), train_loss = 0.71864936, grad/param norm = 2.2743e-01, time/batch = 18.3338s	
19155/22750 (epoch 42.099), train_loss = 0.65747380, grad/param norm = 2.3041e-01, time/batch = 17.0905s	
19156/22750 (epoch 42.101), train_loss = 0.60492171, grad/param norm = 2.2782e-01, time/batch = 20.3447s	
19157/22750 (epoch 42.103), train_loss = 0.75646418, grad/param norm = 2.5706e-01, time/batch = 18.8632s	
19158/22750 (epoch 42.105), train_loss = 0.82918499, grad/param norm = 3.0115e-01, time/batch = 20.1989s	
19159/22750 (epoch 42.108), train_loss = 0.76742884, grad/param norm = 2.6085e-01, time/batch = 20.3190s	
19160/22750 (epoch 42.110), train_loss = 0.79580585, grad/param norm = 2.3625e-01, time/batch = 30.5387s	
19161/22750 (epoch 42.112), train_loss = 0.58889068, grad/param norm = 1.7754e-01, time/batch = 19.4115s	
19162/22750 (epoch 42.114), train_loss = 0.52594647, grad/param norm = 1.9395e-01, time/batch = 17.4792s	
19163/22750 (epoch 42.116), train_loss = 0.73558609, grad/param norm = 2.2509e-01, time/batch = 17.8293s	
19164/22750 (epoch 42.119), train_loss = 0.67677504, grad/param norm = 2.1421e-01, time/batch = 16.3571s	
19165/22750 (epoch 42.121), train_loss = 0.68426971, grad/param norm = 2.5383e-01, time/batch = 15.7182s	
19166/22750 (epoch 42.123), train_loss = 0.60963410, grad/param norm = 2.2171e-01, time/batch = 16.0318s	
19167/22750 (epoch 42.125), train_loss = 0.81256017, grad/param norm = 2.1411e-01, time/batch = 15.7939s	
19168/22750 (epoch 42.127), train_loss = 0.69429670, grad/param norm = 2.8503e-01, time/batch = 15.7118s	
19169/22750 (epoch 42.130), train_loss = 0.70092796, grad/param norm = 2.1677e-01, time/batch = 15.6824s	
19170/22750 (epoch 42.132), train_loss = 0.67207523, grad/param norm = 2.1457e-01, time/batch = 16.0999s	
19171/22750 (epoch 42.134), train_loss = 0.67099972, grad/param norm = 1.9843e-01, time/batch = 16.0127s	
19172/22750 (epoch 42.136), train_loss = 0.56703716, grad/param norm = 2.2797e-01, time/batch = 16.0185s	
19173/22750 (epoch 42.138), train_loss = 0.78943169, grad/param norm = 2.4581e-01, time/batch = 15.6057s	
19174/22750 (epoch 42.141), train_loss = 0.71041914, grad/param norm = 2.2857e-01, time/batch = 16.2643s	
19175/22750 (epoch 42.143), train_loss = 0.65997011, grad/param norm = 2.1165e-01, time/batch = 15.7875s	
19176/22750 (epoch 42.145), train_loss = 0.80495372, grad/param norm = 2.5631e-01, time/batch = 15.6251s	
19177/22750 (epoch 42.147), train_loss = 0.86596777, grad/param norm = 2.5799e-01, time/batch = 15.7940s	
19178/22750 (epoch 42.149), train_loss = 0.72383814, grad/param norm = 2.3001e-01, time/batch = 16.1018s	
19179/22750 (epoch 42.152), train_loss = 0.70279547, grad/param norm = 2.0109e-01, time/batch = 16.2449s	
19180/22750 (epoch 42.154), train_loss = 0.64030210, grad/param norm = 2.1466e-01, time/batch = 16.1591s	
19181/22750 (epoch 42.156), train_loss = 0.63788578, grad/param norm = 2.0764e-01, time/batch = 16.1767s	
19182/22750 (epoch 42.158), train_loss = 0.61862285, grad/param norm = 2.2046e-01, time/batch = 15.6831s	
19183/22750 (epoch 42.160), train_loss = 0.71228212, grad/param norm = 2.6008e-01, time/batch = 15.9297s	
19184/22750 (epoch 42.163), train_loss = 0.82481324, grad/param norm = 2.5853e-01, time/batch = 15.6092s	
19185/22750 (epoch 42.165), train_loss = 0.75754456, grad/param norm = 2.1945e-01, time/batch = 16.2830s	
19186/22750 (epoch 42.167), train_loss = 0.66260978, grad/param norm = 2.4349e-01, time/batch = 15.6365s	
19187/22750 (epoch 42.169), train_loss = 0.69887428, grad/param norm = 2.4018e-01, time/batch = 15.7097s	
19188/22750 (epoch 42.171), train_loss = 0.60198719, grad/param norm = 1.9955e-01, time/batch = 15.6290s	
19189/22750 (epoch 42.174), train_loss = 0.59133916, grad/param norm = 2.2194e-01, time/batch = 16.1878s	
19190/22750 (epoch 42.176), train_loss = 0.60942571, grad/param norm = 2.1798e-01, time/batch = 15.9329s	
19191/22750 (epoch 42.178), train_loss = 0.65869997, grad/param norm = 2.0917e-01, time/batch = 15.7614s	
19192/22750 (epoch 42.180), train_loss = 0.80332464, grad/param norm = 2.9568e-01, time/batch = 15.9224s	
19193/22750 (epoch 42.182), train_loss = 0.74512549, grad/param norm = 2.5031e-01, time/batch = 15.6877s	
19194/22750 (epoch 42.185), train_loss = 0.79081229, grad/param norm = 2.5704e-01, time/batch = 16.0073s	
19195/22750 (epoch 42.187), train_loss = 0.62326891, grad/param norm = 2.0828e-01, time/batch = 15.4507s	
19196/22750 (epoch 42.189), train_loss = 0.60257064, grad/param norm = 2.0749e-01, time/batch = 16.0400s	
19197/22750 (epoch 42.191), train_loss = 0.65789132, grad/param norm = 1.9509e-01, time/batch = 15.8760s	
19198/22750 (epoch 42.193), train_loss = 0.74539698, grad/param norm = 2.1427e-01, time/batch = 15.7220s	
19199/22750 (epoch 42.196), train_loss = 0.68297745, grad/param norm = 2.2049e-01, time/batch = 16.0056s	
19200/22750 (epoch 42.198), train_loss = 0.50920834, grad/param norm = 2.0924e-01, time/batch = 16.0920s	
19201/22750 (epoch 42.200), train_loss = 0.70644058, grad/param norm = 2.1779e-01, time/batch = 15.6042s	
19202/22750 (epoch 42.202), train_loss = 0.75715624, grad/param norm = 2.9447e-01, time/batch = 15.4404s	
19203/22750 (epoch 42.204), train_loss = 0.72483311, grad/param norm = 2.1516e-01, time/batch = 15.4480s	
19204/22750 (epoch 42.207), train_loss = 0.72938723, grad/param norm = 2.2163e-01, time/batch = 16.0109s	
19205/22750 (epoch 42.209), train_loss = 0.66527573, grad/param norm = 2.1304e-01, time/batch = 15.2840s	
19206/22750 (epoch 42.211), train_loss = 0.61705321, grad/param norm = 2.2310e-01, time/batch = 15.3008s	
19207/22750 (epoch 42.213), train_loss = 0.53135640, grad/param norm = 2.1049e-01, time/batch = 15.4465s	
19208/22750 (epoch 42.215), train_loss = 0.54421616, grad/param norm = 1.9386e-01, time/batch = 15.9608s	
19209/22750 (epoch 42.218), train_loss = 0.63606092, grad/param norm = 2.5926e-01, time/batch = 16.1141s	
19210/22750 (epoch 42.220), train_loss = 0.59774108, grad/param norm = 2.6582e-01, time/batch = 15.7635s	
19211/22750 (epoch 42.222), train_loss = 0.57707497, grad/param norm = 2.2448e-01, time/batch = 16.3327s	
19212/22750 (epoch 42.224), train_loss = 0.61367007, grad/param norm = 2.2353e-01, time/batch = 15.9312s	
19213/22750 (epoch 42.226), train_loss = 0.68303195, grad/param norm = 2.3737e-01, time/batch = 15.9511s	
19214/22750 (epoch 42.229), train_loss = 0.72483431, grad/param norm = 2.3502e-01, time/batch = 16.3170s	
19215/22750 (epoch 42.231), train_loss = 0.61621809, grad/param norm = 2.1935e-01, time/batch = 16.5632s	
19216/22750 (epoch 42.233), train_loss = 0.57869860, grad/param norm = 2.4355e-01, time/batch = 16.1093s	
19217/22750 (epoch 42.235), train_loss = 0.54728370, grad/param norm = 2.1512e-01, time/batch = 15.9364s	
19218/22750 (epoch 42.237), train_loss = 0.60745477, grad/param norm = 2.0635e-01, time/batch = 16.1037s	
19219/22750 (epoch 42.240), train_loss = 0.69061086, grad/param norm = 1.9451e-01, time/batch = 16.1124s	
19220/22750 (epoch 42.242), train_loss = 0.83347471, grad/param norm = 3.8299e-01, time/batch = 15.9064s	
19221/22750 (epoch 42.244), train_loss = 0.84985587, grad/param norm = 2.8814e-01, time/batch = 15.7693s	
19222/22750 (epoch 42.246), train_loss = 0.83692802, grad/param norm = 2.4507e-01, time/batch = 16.0115s	
19223/22750 (epoch 42.248), train_loss = 0.71112684, grad/param norm = 2.3814e-01, time/batch = 15.8507s	
19224/22750 (epoch 42.251), train_loss = 0.77279380, grad/param norm = 2.4558e-01, time/batch = 15.8477s	
19225/22750 (epoch 42.253), train_loss = 0.76358591, grad/param norm = 3.0398e-01, time/batch = 15.9278s	
19226/22750 (epoch 42.255), train_loss = 0.73731342, grad/param norm = 2.2171e-01, time/batch = 16.1787s	
19227/22750 (epoch 42.257), train_loss = 0.63969738, grad/param norm = 2.3279e-01, time/batch = 15.6993s	
19228/22750 (epoch 42.259), train_loss = 0.78010051, grad/param norm = 2.9932e-01, time/batch = 15.9313s	
19229/22750 (epoch 42.262), train_loss = 0.72886863, grad/param norm = 2.3648e-01, time/batch = 15.8657s	
19230/22750 (epoch 42.264), train_loss = 0.56516947, grad/param norm = 2.2940e-01, time/batch = 16.0070s	
19231/22750 (epoch 42.266), train_loss = 0.70175328, grad/param norm = 2.8204e-01, time/batch = 15.2790s	
19232/22750 (epoch 42.268), train_loss = 0.83916291, grad/param norm = 2.6714e-01, time/batch = 15.8550s	
19233/22750 (epoch 42.270), train_loss = 0.65743145, grad/param norm = 2.8408e-01, time/batch = 15.5992s	
19234/22750 (epoch 42.273), train_loss = 0.96557994, grad/param norm = 3.0956e-01, time/batch = 16.1655s	
19235/22750 (epoch 42.275), train_loss = 0.83579633, grad/param norm = 2.4453e-01, time/batch = 15.7574s	
19236/22750 (epoch 42.277), train_loss = 0.70969691, grad/param norm = 2.6997e-01, time/batch = 15.9379s	
19237/22750 (epoch 42.279), train_loss = 0.59690087, grad/param norm = 2.1517e-01, time/batch = 16.0222s	
19238/22750 (epoch 42.281), train_loss = 0.83740267, grad/param norm = 2.6484e-01, time/batch = 15.9523s	
19239/22750 (epoch 42.284), train_loss = 0.74831283, grad/param norm = 2.3291e-01, time/batch = 16.2522s	
19240/22750 (epoch 42.286), train_loss = 0.78695863, grad/param norm = 2.4695e-01, time/batch = 19.1869s	
19241/22750 (epoch 42.288), train_loss = 0.85211897, grad/param norm = 2.6713e-01, time/batch = 18.2407s	
19242/22750 (epoch 42.290), train_loss = 0.77364639, grad/param norm = 2.4583e-01, time/batch = 20.0798s	
19243/22750 (epoch 42.292), train_loss = 0.77561678, grad/param norm = 2.5832e-01, time/batch = 18.5013s	
19244/22750 (epoch 42.295), train_loss = 0.74857753, grad/param norm = 2.2187e-01, time/batch = 17.8323s	
19245/22750 (epoch 42.297), train_loss = 0.74731352, grad/param norm = 2.3527e-01, time/batch = 18.4941s	
19246/22750 (epoch 42.299), train_loss = 0.78669701, grad/param norm = 2.5424e-01, time/batch = 19.5107s	
19247/22750 (epoch 42.301), train_loss = 0.70410114, grad/param norm = 2.2172e-01, time/batch = 19.1855s	
19248/22750 (epoch 42.303), train_loss = 0.76540202, grad/param norm = 2.4556e-01, time/batch = 20.7720s	
19249/22750 (epoch 42.305), train_loss = 0.86050060, grad/param norm = 2.3355e-01, time/batch = 19.7494s	
19250/22750 (epoch 42.308), train_loss = 0.78197461, grad/param norm = 2.3623e-01, time/batch = 18.3216s	
19251/22750 (epoch 42.310), train_loss = 0.67085140, grad/param norm = 2.6064e-01, time/batch = 20.1508s	
19252/22750 (epoch 42.312), train_loss = 0.73019347, grad/param norm = 2.5181e-01, time/batch = 17.4967s	
19253/22750 (epoch 42.314), train_loss = 0.74458490, grad/param norm = 2.3682e-01, time/batch = 18.9193s	
19254/22750 (epoch 42.316), train_loss = 0.69741097, grad/param norm = 2.0607e-01, time/batch = 18.4217s	
19255/22750 (epoch 42.319), train_loss = 0.75701310, grad/param norm = 2.7148e-01, time/batch = 20.0960s	
19256/22750 (epoch 42.321), train_loss = 0.68161564, grad/param norm = 2.4937e-01, time/batch = 20.3423s	
19257/22750 (epoch 42.323), train_loss = 0.75252436, grad/param norm = 2.2486e-01, time/batch = 19.3780s	
19258/22750 (epoch 42.325), train_loss = 0.63138052, grad/param norm = 2.0413e-01, time/batch = 20.4175s	
19259/22750 (epoch 42.327), train_loss = 0.66916495, grad/param norm = 2.4013e-01, time/batch = 19.6562s	
19260/22750 (epoch 42.330), train_loss = 0.83389296, grad/param norm = 2.5797e-01, time/batch = 19.4897s	
19261/22750 (epoch 42.332), train_loss = 0.92981263, grad/param norm = 2.7008e-01, time/batch = 18.7369s	
19262/22750 (epoch 42.334), train_loss = 0.58912820, grad/param norm = 2.0091e-01, time/batch = 19.1464s	
19263/22750 (epoch 42.336), train_loss = 0.79754813, grad/param norm = 2.0205e-01, time/batch = 18.3105s	
19264/22750 (epoch 42.338), train_loss = 0.71801981, grad/param norm = 2.4269e-01, time/batch = 20.6884s	
19265/22750 (epoch 42.341), train_loss = 0.72142684, grad/param norm = 2.1901e-01, time/batch = 20.3626s	
19266/22750 (epoch 42.343), train_loss = 0.64009810, grad/param norm = 2.5427e-01, time/batch = 19.2584s	
19267/22750 (epoch 42.345), train_loss = 0.77030656, grad/param norm = 2.6960e-01, time/batch = 20.3070s	
19268/22750 (epoch 42.347), train_loss = 0.81890057, grad/param norm = 2.5866e-01, time/batch = 17.8236s	
19269/22750 (epoch 42.349), train_loss = 0.59128008, grad/param norm = 2.5115e-01, time/batch = 16.7306s	
19270/22750 (epoch 42.352), train_loss = 0.85533169, grad/param norm = 2.5542e-01, time/batch = 18.7471s	
19271/22750 (epoch 42.354), train_loss = 0.83047904, grad/param norm = 2.7896e-01, time/batch = 17.3099s	
19272/22750 (epoch 42.356), train_loss = 0.78165234, grad/param norm = 2.2366e-01, time/batch = 19.4260s	
19273/22750 (epoch 42.358), train_loss = 0.68874757, grad/param norm = 2.3849e-01, time/batch = 19.6867s	
19274/22750 (epoch 42.360), train_loss = 0.86851221, grad/param norm = 2.2866e-01, time/batch = 19.9443s	
19275/22750 (epoch 42.363), train_loss = 0.68463078, grad/param norm = 2.4130e-01, time/batch = 19.0286s	
19276/22750 (epoch 42.365), train_loss = 0.57927830, grad/param norm = 2.2094e-01, time/batch = 18.9091s	
19277/22750 (epoch 42.367), train_loss = 0.67600687, grad/param norm = 2.5563e-01, time/batch = 20.0003s	
19278/22750 (epoch 42.369), train_loss = 0.74404130, grad/param norm = 2.6027e-01, time/batch = 18.9067s	
19279/22750 (epoch 42.371), train_loss = 0.73813700, grad/param norm = 2.3761e-01, time/batch = 18.7436s	
19280/22750 (epoch 42.374), train_loss = 0.65647386, grad/param norm = 2.5419e-01, time/batch = 19.8140s	
19281/22750 (epoch 42.376), train_loss = 0.72311259, grad/param norm = 2.1409e-01, time/batch = 18.5864s	
19282/22750 (epoch 42.378), train_loss = 0.74751411, grad/param norm = 2.2768e-01, time/batch = 20.9167s	
19283/22750 (epoch 42.380), train_loss = 0.77930122, grad/param norm = 2.1298e-01, time/batch = 18.1873s	
19284/22750 (epoch 42.382), train_loss = 0.71266123, grad/param norm = 2.2893e-01, time/batch = 18.1816s	
19285/22750 (epoch 42.385), train_loss = 0.78104528, grad/param norm = 2.3451e-01, time/batch = 19.2460s	
19286/22750 (epoch 42.387), train_loss = 0.76228799, grad/param norm = 2.4396e-01, time/batch = 19.9936s	
19287/22750 (epoch 42.389), train_loss = 0.59627095, grad/param norm = 2.2897e-01, time/batch = 19.7369s	
19288/22750 (epoch 42.391), train_loss = 0.45114689, grad/param norm = 1.6319e-01, time/batch = 17.9979s	
19289/22750 (epoch 42.393), train_loss = 0.61340011, grad/param norm = 2.4922e-01, time/batch = 17.9325s	
19290/22750 (epoch 42.396), train_loss = 0.73411698, grad/param norm = 2.1405e-01, time/batch = 20.3720s	
19291/22750 (epoch 42.398), train_loss = 0.68087444, grad/param norm = 2.1639e-01, time/batch = 18.2503s	
19292/22750 (epoch 42.400), train_loss = 0.74156198, grad/param norm = 2.6326e-01, time/batch = 19.1614s	
19293/22750 (epoch 42.402), train_loss = 0.73564380, grad/param norm = 2.2670e-01, time/batch = 19.8301s	
19294/22750 (epoch 42.404), train_loss = 0.81861576, grad/param norm = 2.4431e-01, time/batch = 17.6736s	
19295/22750 (epoch 42.407), train_loss = 0.81627556, grad/param norm = 2.8197e-01, time/batch = 18.6649s	
19296/22750 (epoch 42.409), train_loss = 0.67580887, grad/param norm = 2.5084e-01, time/batch = 20.3954s	
19297/22750 (epoch 42.411), train_loss = 0.66338418, grad/param norm = 2.2325e-01, time/batch = 17.3249s	
19298/22750 (epoch 42.413), train_loss = 0.52458476, grad/param norm = 2.1392e-01, time/batch = 19.0090s	
19299/22750 (epoch 42.415), train_loss = 0.60897868, grad/param norm = 2.2416e-01, time/batch = 20.5244s	
19300/22750 (epoch 42.418), train_loss = 0.68272993, grad/param norm = 2.4506e-01, time/batch = 19.5875s	
19301/22750 (epoch 42.420), train_loss = 0.78431021, grad/param norm = 2.9902e-01, time/batch = 20.9929s	
19302/22750 (epoch 42.422), train_loss = 0.92448465, grad/param norm = 3.3515e-01, time/batch = 19.7333s	
19303/22750 (epoch 42.424), train_loss = 0.92597511, grad/param norm = 2.7794e-01, time/batch = 18.9191s	
19304/22750 (epoch 42.426), train_loss = 0.88522579, grad/param norm = 2.2622e-01, time/batch = 19.2418s	
19305/22750 (epoch 42.429), train_loss = 0.66762819, grad/param norm = 2.1778e-01, time/batch = 19.2424s	
19306/22750 (epoch 42.431), train_loss = 0.60116036, grad/param norm = 2.0123e-01, time/batch = 18.5041s	
19307/22750 (epoch 42.433), train_loss = 0.68456134, grad/param norm = 2.2973e-01, time/batch = 19.3330s	
19308/22750 (epoch 42.435), train_loss = 0.54109135, grad/param norm = 1.9582e-01, time/batch = 20.0216s	
19309/22750 (epoch 42.437), train_loss = 0.46682564, grad/param norm = 1.7633e-01, time/batch = 19.8510s	
19310/22750 (epoch 42.440), train_loss = 0.67060338, grad/param norm = 2.5264e-01, time/batch = 19.4241s	
19311/22750 (epoch 42.442), train_loss = 0.69501723, grad/param norm = 2.3153e-01, time/batch = 16.4732s	
19312/22750 (epoch 42.444), train_loss = 0.67089861, grad/param norm = 2.2828e-01, time/batch = 17.4190s	
19313/22750 (epoch 42.446), train_loss = 0.69910856, grad/param norm = 2.8443e-01, time/batch = 18.0602s	
19314/22750 (epoch 42.448), train_loss = 0.90882226, grad/param norm = 2.6837e-01, time/batch = 18.1663s	
19315/22750 (epoch 42.451), train_loss = 0.87017782, grad/param norm = 2.4977e-01, time/batch = 18.5064s	
19316/22750 (epoch 42.453), train_loss = 0.75847480, grad/param norm = 2.8190e-01, time/batch = 17.9320s	
19317/22750 (epoch 42.455), train_loss = 0.85342444, grad/param norm = 2.3958e-01, time/batch = 20.1957s	
19318/22750 (epoch 42.457), train_loss = 0.75480012, grad/param norm = 3.1236e-01, time/batch = 19.2468s	
19319/22750 (epoch 42.459), train_loss = 0.78041854, grad/param norm = 2.2012e-01, time/batch = 18.9855s	
19320/22750 (epoch 42.462), train_loss = 0.73561395, grad/param norm = 2.2835e-01, time/batch = 21.0671s	
19321/22750 (epoch 42.464), train_loss = 0.61583481, grad/param norm = 2.1948e-01, time/batch = 20.1339s	
19322/22750 (epoch 42.466), train_loss = 0.78158585, grad/param norm = 2.7482e-01, time/batch = 18.5916s	
19323/22750 (epoch 42.468), train_loss = 0.75959563, grad/param norm = 2.4117e-01, time/batch = 18.4819s	
19324/22750 (epoch 42.470), train_loss = 0.85640082, grad/param norm = 2.8727e-01, time/batch = 19.7255s	
19325/22750 (epoch 42.473), train_loss = 0.70353013, grad/param norm = 2.2812e-01, time/batch = 18.5923s	
19326/22750 (epoch 42.475), train_loss = 0.75067093, grad/param norm = 2.7222e-01, time/batch = 18.2708s	
19327/22750 (epoch 42.477), train_loss = 0.64576482, grad/param norm = 2.4269e-01, time/batch = 20.6910s	
19328/22750 (epoch 42.479), train_loss = 0.62737754, grad/param norm = 2.2482e-01, time/batch = 18.2625s	
19329/22750 (epoch 42.481), train_loss = 0.59210292, grad/param norm = 2.1157e-01, time/batch = 18.8202s	
19330/22750 (epoch 42.484), train_loss = 0.50651976, grad/param norm = 2.4053e-01, time/batch = 17.7436s	
19331/22750 (epoch 42.486), train_loss = 0.59391759, grad/param norm = 1.9643e-01, time/batch = 18.3507s	
19332/22750 (epoch 42.488), train_loss = 0.55732033, grad/param norm = 2.0371e-01, time/batch = 18.9162s	
19333/22750 (epoch 42.490), train_loss = 0.69211296, grad/param norm = 2.2667e-01, time/batch = 19.6686s	
19334/22750 (epoch 42.492), train_loss = 0.79567240, grad/param norm = 2.3814e-01, time/batch = 20.5136s	
19335/22750 (epoch 42.495), train_loss = 0.66698325, grad/param norm = 2.4950e-01, time/batch = 19.8361s	
19336/22750 (epoch 42.497), train_loss = 0.71340961, grad/param norm = 2.8965e-01, time/batch = 19.4939s	
19337/22750 (epoch 42.499), train_loss = 0.63391179, grad/param norm = 2.5075e-01, time/batch = 17.7595s	
19338/22750 (epoch 42.501), train_loss = 0.67359810, grad/param norm = 2.4760e-01, time/batch = 17.6680s	
19339/22750 (epoch 42.503), train_loss = 0.67175609, grad/param norm = 2.2765e-01, time/batch = 16.8952s	
19340/22750 (epoch 42.505), train_loss = 0.59950672, grad/param norm = 2.3402e-01, time/batch = 20.0703s	
19341/22750 (epoch 42.508), train_loss = 0.58092717, grad/param norm = 2.1072e-01, time/batch = 17.7448s	
19342/22750 (epoch 42.510), train_loss = 0.59936307, grad/param norm = 2.1583e-01, time/batch = 19.0006s	
19343/22750 (epoch 42.512), train_loss = 0.64507614, grad/param norm = 2.3991e-01, time/batch = 18.2866s	
19344/22750 (epoch 42.514), train_loss = 0.65306957, grad/param norm = 2.4354e-01, time/batch = 18.4412s	
19345/22750 (epoch 42.516), train_loss = 0.64907469, grad/param norm = 2.7230e-01, time/batch = 19.7710s	
19346/22750 (epoch 42.519), train_loss = 0.76616924, grad/param norm = 2.2466e-01, time/batch = 18.7507s	
19347/22750 (epoch 42.521), train_loss = 0.70442972, grad/param norm = 2.4456e-01, time/batch = 18.3176s	
19348/22750 (epoch 42.523), train_loss = 0.60909647, grad/param norm = 2.3943e-01, time/batch = 19.7126s	
19349/22750 (epoch 42.525), train_loss = 0.79903037, grad/param norm = 2.3721e-01, time/batch = 19.5719s	
19350/22750 (epoch 42.527), train_loss = 0.71305207, grad/param norm = 2.0742e-01, time/batch = 19.0086s	
19351/22750 (epoch 42.530), train_loss = 0.65419155, grad/param norm = 2.4402e-01, time/batch = 20.4963s	
19352/22750 (epoch 42.532), train_loss = 0.58767348, grad/param norm = 2.1948e-01, time/batch = 20.7784s	
19353/22750 (epoch 42.534), train_loss = 0.75877791, grad/param norm = 2.4970e-01, time/batch = 18.7842s	
19354/22750 (epoch 42.536), train_loss = 0.73251868, grad/param norm = 2.1257e-01, time/batch = 19.5014s	
19355/22750 (epoch 42.538), train_loss = 0.71252338, grad/param norm = 2.1644e-01, time/batch = 18.9009s	
19356/22750 (epoch 42.541), train_loss = 0.62862415, grad/param norm = 2.6096e-01, time/batch = 19.1628s	
19357/22750 (epoch 42.543), train_loss = 0.61572519, grad/param norm = 2.1926e-01, time/batch = 17.6696s	
19358/22750 (epoch 42.545), train_loss = 0.77511589, grad/param norm = 2.4548e-01, time/batch = 19.2538s	
19359/22750 (epoch 42.547), train_loss = 0.66998163, grad/param norm = 1.9253e-01, time/batch = 19.9972s	
19360/22750 (epoch 42.549), train_loss = 0.67727824, grad/param norm = 2.3712e-01, time/batch = 34.7297s	
19361/22750 (epoch 42.552), train_loss = 0.74048277, grad/param norm = 2.3374e-01, time/batch = 20.6050s	
19362/22750 (epoch 42.554), train_loss = 0.75283173, grad/param norm = 2.4306e-01, time/batch = 16.8260s	
19363/22750 (epoch 42.556), train_loss = 0.74506460, grad/param norm = 2.1632e-01, time/batch = 17.0656s	
19364/22750 (epoch 42.558), train_loss = 0.70626862, grad/param norm = 2.7252e-01, time/batch = 18.9162s	
19365/22750 (epoch 42.560), train_loss = 0.66972073, grad/param norm = 2.2189e-01, time/batch = 18.9056s	
19366/22750 (epoch 42.563), train_loss = 0.78956319, grad/param norm = 2.9192e-01, time/batch = 17.5881s	
19367/22750 (epoch 42.565), train_loss = 0.75541339, grad/param norm = 2.4179e-01, time/batch = 17.9910s	
19368/22750 (epoch 42.567), train_loss = 0.73367647, grad/param norm = 2.3534e-01, time/batch = 16.7693s	
19369/22750 (epoch 42.569), train_loss = 0.68500868, grad/param norm = 2.1385e-01, time/batch = 16.7716s	
19370/22750 (epoch 42.571), train_loss = 0.70044584, grad/param norm = 2.4681e-01, time/batch = 18.6757s	
19371/22750 (epoch 42.574), train_loss = 0.72205377, grad/param norm = 2.6012e-01, time/batch = 21.4819s	
19372/22750 (epoch 42.576), train_loss = 0.70814555, grad/param norm = 2.8187e-01, time/batch = 17.9731s	
19373/22750 (epoch 42.578), train_loss = 0.61350172, grad/param norm = 2.4588e-01, time/batch = 19.3186s	
19374/22750 (epoch 42.580), train_loss = 0.74951456, grad/param norm = 2.5771e-01, time/batch = 18.0047s	
19375/22750 (epoch 42.582), train_loss = 0.63804181, grad/param norm = 2.2002e-01, time/batch = 18.5772s	
19376/22750 (epoch 42.585), train_loss = 0.61190140, grad/param norm = 2.2799e-01, time/batch = 19.9969s	
19377/22750 (epoch 42.587), train_loss = 0.61822068, grad/param norm = 1.9468e-01, time/batch = 17.2749s	
19378/22750 (epoch 42.589), train_loss = 0.52774691, grad/param norm = 1.9007e-01, time/batch = 19.7672s	
19379/22750 (epoch 42.591), train_loss = 0.69874411, grad/param norm = 2.0342e-01, time/batch = 19.5929s	
19380/22750 (epoch 42.593), train_loss = 0.80451692, grad/param norm = 2.4717e-01, time/batch = 17.9137s	
19381/22750 (epoch 42.596), train_loss = 0.76541837, grad/param norm = 2.3155e-01, time/batch = 19.5708s	
19382/22750 (epoch 42.598), train_loss = 0.77781670, grad/param norm = 2.6520e-01, time/batch = 17.1901s	
19383/22750 (epoch 42.600), train_loss = 0.84585194, grad/param norm = 2.5019e-01, time/batch = 19.5741s	
19384/22750 (epoch 42.602), train_loss = 0.62996213, grad/param norm = 2.1084e-01, time/batch = 15.5855s	
19385/22750 (epoch 42.604), train_loss = 0.67465294, grad/param norm = 2.3362e-01, time/batch = 17.7485s	
19386/22750 (epoch 42.607), train_loss = 0.61639600, grad/param norm = 1.9899e-01, time/batch = 18.7761s	
19387/22750 (epoch 42.609), train_loss = 0.60371218, grad/param norm = 2.4146e-01, time/batch = 20.1890s	
19388/22750 (epoch 42.611), train_loss = 0.65857590, grad/param norm = 2.2075e-01, time/batch = 18.0254s	
19389/22750 (epoch 42.613), train_loss = 0.63278556, grad/param norm = 2.5603e-01, time/batch = 20.6611s	
19390/22750 (epoch 42.615), train_loss = 0.65642869, grad/param norm = 2.0130e-01, time/batch = 19.1675s	
19391/22750 (epoch 42.618), train_loss = 0.69512850, grad/param norm = 2.2202e-01, time/batch = 17.7411s	
19392/22750 (epoch 42.620), train_loss = 0.66754001, grad/param norm = 2.3279e-01, time/batch = 18.9225s	
19393/22750 (epoch 42.622), train_loss = 0.59035578, grad/param norm = 1.9770e-01, time/batch = 16.6811s	
19394/22750 (epoch 42.624), train_loss = 0.67427201, grad/param norm = 2.7853e-01, time/batch = 18.4133s	
19395/22750 (epoch 42.626), train_loss = 0.55485296, grad/param norm = 1.8932e-01, time/batch = 18.7304s	
19396/22750 (epoch 42.629), train_loss = 0.64939758, grad/param norm = 2.1988e-01, time/batch = 19.2535s	
19397/22750 (epoch 42.631), train_loss = 0.68311649, grad/param norm = 2.1935e-01, time/batch = 19.5200s	
19398/22750 (epoch 42.633), train_loss = 0.59410633, grad/param norm = 2.1517e-01, time/batch = 18.6081s	
19399/22750 (epoch 42.635), train_loss = 0.68450956, grad/param norm = 2.0858e-01, time/batch = 19.3371s	
19400/22750 (epoch 42.637), train_loss = 0.74725874, grad/param norm = 3.0214e-01, time/batch = 19.8262s	
19401/22750 (epoch 42.640), train_loss = 0.74952056, grad/param norm = 2.2392e-01, time/batch = 17.8984s	
19402/22750 (epoch 42.642), train_loss = 0.77961093, grad/param norm = 2.3390e-01, time/batch = 17.7562s	
19403/22750 (epoch 42.644), train_loss = 0.68491102, grad/param norm = 2.3810e-01, time/batch = 19.5739s	
19404/22750 (epoch 42.646), train_loss = 0.75803161, grad/param norm = 2.8256e-01, time/batch = 18.9294s	
19405/22750 (epoch 42.648), train_loss = 0.73866905, grad/param norm = 2.2880e-01, time/batch = 20.1902s	
19406/22750 (epoch 42.651), train_loss = 0.74881736, grad/param norm = 2.5097e-01, time/batch = 19.9483s	
19407/22750 (epoch 42.653), train_loss = 0.78576454, grad/param norm = 2.1842e-01, time/batch = 18.2454s	
19408/22750 (epoch 42.655), train_loss = 0.73640177, grad/param norm = 2.4677e-01, time/batch = 18.0941s	
19409/22750 (epoch 42.657), train_loss = 0.81850007, grad/param norm = 2.6153e-01, time/batch = 19.2524s	
19410/22750 (epoch 42.659), train_loss = 0.86709294, grad/param norm = 2.2332e-01, time/batch = 16.8334s	
19411/22750 (epoch 42.662), train_loss = 0.85150704, grad/param norm = 2.9544e-01, time/batch = 20.1413s	
19412/22750 (epoch 42.664), train_loss = 0.74850013, grad/param norm = 2.4830e-01, time/batch = 18.4969s	
19413/22750 (epoch 42.666), train_loss = 0.62888423, grad/param norm = 2.4193e-01, time/batch = 15.9732s	
19414/22750 (epoch 42.668), train_loss = 0.67205581, grad/param norm = 2.0149e-01, time/batch = 19.8498s	
19415/22750 (epoch 42.670), train_loss = 0.65678038, grad/param norm = 2.3649e-01, time/batch = 20.2778s	
19416/22750 (epoch 42.673), train_loss = 0.85584313, grad/param norm = 2.4634e-01, time/batch = 19.8400s	
19417/22750 (epoch 42.675), train_loss = 0.95166007, grad/param norm = 3.0386e-01, time/batch = 19.9879s	
19418/22750 (epoch 42.677), train_loss = 0.82960674, grad/param norm = 2.2598e-01, time/batch = 18.7501s	
19419/22750 (epoch 42.679), train_loss = 0.82443566, grad/param norm = 2.9072e-01, time/batch = 19.2486s	
19420/22750 (epoch 42.681), train_loss = 0.83228988, grad/param norm = 2.7421e-01, time/batch = 19.9893s	
19421/22750 (epoch 42.684), train_loss = 0.86885137, grad/param norm = 2.8689e-01, time/batch = 19.5031s	
19422/22750 (epoch 42.686), train_loss = 0.90124491, grad/param norm = 2.5387e-01, time/batch = 19.6951s	
19423/22750 (epoch 42.688), train_loss = 0.83784142, grad/param norm = 2.5699e-01, time/batch = 16.1231s	
19424/22750 (epoch 42.690), train_loss = 0.84110688, grad/param norm = 2.7082e-01, time/batch = 20.4377s	
19425/22750 (epoch 42.692), train_loss = 0.83742254, grad/param norm = 2.6272e-01, time/batch = 17.9324s	
19426/22750 (epoch 42.695), train_loss = 0.74059704, grad/param norm = 2.1731e-01, time/batch = 17.9857s	
19427/22750 (epoch 42.697), train_loss = 0.76230253, grad/param norm = 2.2622e-01, time/batch = 19.4956s	
19428/22750 (epoch 42.699), train_loss = 0.66280836, grad/param norm = 2.0273e-01, time/batch = 18.5009s	
19429/22750 (epoch 42.701), train_loss = 0.62179187, grad/param norm = 2.3886e-01, time/batch = 17.4156s	
19430/22750 (epoch 42.703), train_loss = 0.68904161, grad/param norm = 2.4336e-01, time/batch = 20.0215s	
19431/22750 (epoch 42.705), train_loss = 0.66515797, grad/param norm = 2.2292e-01, time/batch = 19.1862s	
19432/22750 (epoch 42.708), train_loss = 0.70336932, grad/param norm = 2.7769e-01, time/batch = 17.7536s	
19433/22750 (epoch 42.710), train_loss = 0.63607881, grad/param norm = 2.3084e-01, time/batch = 19.4371s	
19434/22750 (epoch 42.712), train_loss = 0.55405081, grad/param norm = 2.1958e-01, time/batch = 19.9807s	
19435/22750 (epoch 42.714), train_loss = 0.60636785, grad/param norm = 2.0666e-01, time/batch = 19.0750s	
19436/22750 (epoch 42.716), train_loss = 0.61497429, grad/param norm = 2.0043e-01, time/batch = 18.4235s	
19437/22750 (epoch 42.719), train_loss = 0.68189411, grad/param norm = 2.6822e-01, time/batch = 20.4800s	
19438/22750 (epoch 42.721), train_loss = 0.81318849, grad/param norm = 2.6142e-01, time/batch = 21.4391s	
19439/22750 (epoch 42.723), train_loss = 0.77707986, grad/param norm = 2.8621e-01, time/batch = 19.6416s	
19440/22750 (epoch 42.725), train_loss = 0.67682501, grad/param norm = 2.4840e-01, time/batch = 22.9640s	
19441/22750 (epoch 42.727), train_loss = 0.71872278, grad/param norm = 2.4403e-01, time/batch = 23.3797s	
19442/22750 (epoch 42.730), train_loss = 0.68239064, grad/param norm = 2.3927e-01, time/batch = 23.4397s	
19443/22750 (epoch 42.732), train_loss = 0.64834432, grad/param norm = 2.1709e-01, time/batch = 23.1197s	
19444/22750 (epoch 42.734), train_loss = 0.58650170, grad/param norm = 1.9669e-01, time/batch = 22.7967s	
19445/22750 (epoch 42.736), train_loss = 0.67982674, grad/param norm = 2.3937e-01, time/batch = 24.4369s	
19446/22750 (epoch 42.738), train_loss = 0.73657777, grad/param norm = 2.4812e-01, time/batch = 23.2026s	
19447/22750 (epoch 42.741), train_loss = 0.83340311, grad/param norm = 2.6116e-01, time/batch = 22.9814s	
19448/22750 (epoch 42.743), train_loss = 0.72780174, grad/param norm = 2.3488e-01, time/batch = 25.8549s	
19449/22750 (epoch 42.745), train_loss = 0.59651145, grad/param norm = 2.1187e-01, time/batch = 24.2419s	
19450/22750 (epoch 42.747), train_loss = 0.71467091, grad/param norm = 2.0636e-01, time/batch = 23.2773s	
19451/22750 (epoch 42.749), train_loss = 0.81655623, grad/param norm = 2.7310e-01, time/batch = 21.9487s	
19452/22750 (epoch 42.752), train_loss = 0.72700719, grad/param norm = 2.5787e-01, time/batch = 25.3200s	
19453/22750 (epoch 42.754), train_loss = 0.72703021, grad/param norm = 2.4894e-01, time/batch = 24.1202s	
19454/22750 (epoch 42.756), train_loss = 0.65346293, grad/param norm = 2.3077e-01, time/batch = 23.4901s	
19455/22750 (epoch 42.758), train_loss = 0.63450114, grad/param norm = 2.0520e-01, time/batch = 20.1124s	
19456/22750 (epoch 42.760), train_loss = 0.64535657, grad/param norm = 2.4459e-01, time/batch = 17.7310s	
19457/22750 (epoch 42.763), train_loss = 0.69831874, grad/param norm = 2.4280e-01, time/batch = 24.0191s	
19458/22750 (epoch 42.765), train_loss = 0.68941180, grad/param norm = 2.3228e-01, time/batch = 16.9059s	
19459/22750 (epoch 42.767), train_loss = 0.74655204, grad/param norm = 2.4805e-01, time/batch = 15.5133s	
19460/22750 (epoch 42.769), train_loss = 0.83233107, grad/param norm = 2.7492e-01, time/batch = 16.1690s	
19461/22750 (epoch 42.771), train_loss = 0.83669297, grad/param norm = 3.1668e-01, time/batch = 16.2668s	
19462/22750 (epoch 42.774), train_loss = 0.65733493, grad/param norm = 2.7603e-01, time/batch = 15.8527s	
19463/22750 (epoch 42.776), train_loss = 0.79296601, grad/param norm = 2.6274e-01, time/batch = 16.1068s	
19464/22750 (epoch 42.778), train_loss = 0.83150529, grad/param norm = 2.6029e-01, time/batch = 16.5001s	
19465/22750 (epoch 42.780), train_loss = 0.73600510, grad/param norm = 2.3980e-01, time/batch = 15.7713s	
19466/22750 (epoch 42.782), train_loss = 0.85320999, grad/param norm = 2.4967e-01, time/batch = 15.4370s	
19467/22750 (epoch 42.785), train_loss = 0.69689372, grad/param norm = 2.7098e-01, time/batch = 16.1001s	
19468/22750 (epoch 42.787), train_loss = 0.61703377, grad/param norm = 2.9532e-01, time/batch = 15.8559s	
19469/22750 (epoch 42.789), train_loss = 0.70359950, grad/param norm = 2.2653e-01, time/batch = 15.6941s	
19470/22750 (epoch 42.791), train_loss = 0.67199138, grad/param norm = 2.2468e-01, time/batch = 16.2637s	
19471/22750 (epoch 42.793), train_loss = 0.65673262, grad/param norm = 2.9598e-01, time/batch = 16.4237s	
19472/22750 (epoch 42.796), train_loss = 0.61757739, grad/param norm = 2.4087e-01, time/batch = 16.0138s	
19473/22750 (epoch 42.798), train_loss = 0.65995153, grad/param norm = 2.0905e-01, time/batch = 15.3890s	
19474/22750 (epoch 42.800), train_loss = 0.65558684, grad/param norm = 2.6865e-01, time/batch = 15.1170s	
19475/22750 (epoch 42.802), train_loss = 0.60969242, grad/param norm = 2.4519e-01, time/batch = 16.0953s	
19476/22750 (epoch 42.804), train_loss = 0.78443605, grad/param norm = 2.3047e-01, time/batch = 15.2784s	
19477/22750 (epoch 42.807), train_loss = 0.75123840, grad/param norm = 2.4960e-01, time/batch = 19.1487s	
19478/22750 (epoch 42.809), train_loss = 0.84330186, grad/param norm = 2.6292e-01, time/batch = 18.6636s	
19479/22750 (epoch 42.811), train_loss = 0.70404938, grad/param norm = 2.2043e-01, time/batch = 20.0739s	
19480/22750 (epoch 42.813), train_loss = 0.75140967, grad/param norm = 2.7201e-01, time/batch = 18.8998s	
19481/22750 (epoch 42.815), train_loss = 0.83579659, grad/param norm = 2.4467e-01, time/batch = 18.2340s	
19482/22750 (epoch 42.818), train_loss = 0.78375198, grad/param norm = 2.3213e-01, time/batch = 18.9316s	
19483/22750 (epoch 42.820), train_loss = 0.88760750, grad/param norm = 2.2978e-01, time/batch = 20.2538s	
19484/22750 (epoch 42.822), train_loss = 0.74427855, grad/param norm = 2.3612e-01, time/batch = 19.3572s	
19485/22750 (epoch 42.824), train_loss = 0.62691006, grad/param norm = 2.0306e-01, time/batch = 19.2435s	
19486/22750 (epoch 42.826), train_loss = 0.69966562, grad/param norm = 2.5365e-01, time/batch = 18.5858s	
19487/22750 (epoch 42.829), train_loss = 0.79840503, grad/param norm = 2.6329e-01, time/batch = 19.5574s	
19488/22750 (epoch 42.831), train_loss = 0.79019537, grad/param norm = 2.3793e-01, time/batch = 18.4825s	
19489/22750 (epoch 42.833), train_loss = 0.74041085, grad/param norm = 2.4547e-01, time/batch = 18.8299s	
19490/22750 (epoch 42.835), train_loss = 0.65062977, grad/param norm = 2.6979e-01, time/batch = 18.0046s	
19491/22750 (epoch 42.837), train_loss = 0.69057384, grad/param norm = 2.1895e-01, time/batch = 18.1698s	
19492/22750 (epoch 42.840), train_loss = 0.63236409, grad/param norm = 2.1009e-01, time/batch = 19.6035s	
19493/22750 (epoch 42.842), train_loss = 0.65814129, grad/param norm = 2.4580e-01, time/batch = 17.5209s	
19494/22750 (epoch 42.844), train_loss = 0.72338159, grad/param norm = 2.2811e-01, time/batch = 16.6594s	
19495/22750 (epoch 42.846), train_loss = 0.77731346, grad/param norm = 2.3644e-01, time/batch = 17.2457s	
19496/22750 (epoch 42.848), train_loss = 0.67166650, grad/param norm = 2.1635e-01, time/batch = 16.8140s	
19497/22750 (epoch 42.851), train_loss = 0.64533534, grad/param norm = 2.3460e-01, time/batch = 18.5610s	
19498/22750 (epoch 42.853), train_loss = 0.81544275, grad/param norm = 2.3312e-01, time/batch = 17.3309s	
19499/22750 (epoch 42.855), train_loss = 0.69536960, grad/param norm = 1.9763e-01, time/batch = 19.5870s	
19500/22750 (epoch 42.857), train_loss = 0.76476248, grad/param norm = 2.1275e-01, time/batch = 19.5392s	
19501/22750 (epoch 42.859), train_loss = 0.72627733, grad/param norm = 2.6506e-01, time/batch = 18.9180s	
19502/22750 (epoch 42.862), train_loss = 0.87292858, grad/param norm = 2.5767e-01, time/batch = 18.0735s	
19503/22750 (epoch 42.864), train_loss = 0.73194650, grad/param norm = 2.3737e-01, time/batch = 16.8311s	
19504/22750 (epoch 42.866), train_loss = 0.78410166, grad/param norm = 2.5128e-01, time/batch = 16.3467s	
19505/22750 (epoch 42.868), train_loss = 0.64836050, grad/param norm = 2.4231e-01, time/batch = 16.5945s	
19506/22750 (epoch 42.870), train_loss = 0.62742273, grad/param norm = 2.2899e-01, time/batch = 18.8362s	
19507/22750 (epoch 42.873), train_loss = 0.72284062, grad/param norm = 2.4047e-01, time/batch = 18.6552s	
19508/22750 (epoch 42.875), train_loss = 0.76712573, grad/param norm = 2.4434e-01, time/batch = 16.8222s	
19509/22750 (epoch 42.877), train_loss = 0.67813358, grad/param norm = 2.6202e-01, time/batch = 15.3801s	
19510/22750 (epoch 42.879), train_loss = 0.80879824, grad/param norm = 2.4635e-01, time/batch = 19.2820s	
19511/22750 (epoch 42.881), train_loss = 0.73381929, grad/param norm = 2.3676e-01, time/batch = 17.4546s	
19512/22750 (epoch 42.884), train_loss = 0.63541071, grad/param norm = 2.0589e-01, time/batch = 18.9252s	
19513/22750 (epoch 42.886), train_loss = 0.73653724, grad/param norm = 2.2479e-01, time/batch = 19.2494s	
19514/22750 (epoch 42.888), train_loss = 0.76505573, grad/param norm = 2.1973e-01, time/batch = 16.8931s	
19515/22750 (epoch 42.890), train_loss = 0.77334163, grad/param norm = 2.5777e-01, time/batch = 16.6682s	
19516/22750 (epoch 42.892), train_loss = 0.94084264, grad/param norm = 2.7335e-01, time/batch = 17.3127s	
19517/22750 (epoch 42.895), train_loss = 0.68768644, grad/param norm = 3.7288e-01, time/batch = 17.9167s	
19518/22750 (epoch 42.897), train_loss = 0.82560796, grad/param norm = 2.4908e-01, time/batch = 4.6142s	
19519/22750 (epoch 42.899), train_loss = 0.75132664, grad/param norm = 2.5837e-01, time/batch = 0.7063s	
19520/22750 (epoch 42.901), train_loss = 0.80860147, grad/param norm = 2.8022e-01, time/batch = 0.7032s	
19521/22750 (epoch 42.903), train_loss = 0.72738570, grad/param norm = 2.5118e-01, time/batch = 0.6990s	
19522/22750 (epoch 42.905), train_loss = 0.77468286, grad/param norm = 2.3596e-01, time/batch = 0.7176s	
19523/22750 (epoch 42.908), train_loss = 0.61027327, grad/param norm = 2.5494e-01, time/batch = 0.7158s	
19524/22750 (epoch 42.910), train_loss = 0.56131143, grad/param norm = 2.1387e-01, time/batch = 0.7032s	
19525/22750 (epoch 42.912), train_loss = 0.71401859, grad/param norm = 2.2531e-01, time/batch = 0.9481s	
19526/22750 (epoch 42.914), train_loss = 0.73838229, grad/param norm = 2.4929e-01, time/batch = 1.0351s	
19527/22750 (epoch 42.916), train_loss = 0.57351967, grad/param norm = 2.0048e-01, time/batch = 1.0250s	
19528/22750 (epoch 42.919), train_loss = 0.72346939, grad/param norm = 2.6762e-01, time/batch = 1.0231s	
19529/22750 (epoch 42.921), train_loss = 0.56746507, grad/param norm = 1.9735e-01, time/batch = 1.0265s	
19530/22750 (epoch 42.923), train_loss = 0.65719291, grad/param norm = 2.1457e-01, time/batch = 1.8387s	
19531/22750 (epoch 42.925), train_loss = 0.71513097, grad/param norm = 2.3266e-01, time/batch = 1.9130s	
19532/22750 (epoch 42.927), train_loss = 0.56509800, grad/param norm = 2.1226e-01, time/batch = 8.6627s	
19533/22750 (epoch 42.930), train_loss = 0.53499102, grad/param norm = 2.0849e-01, time/batch = 18.7009s	
19534/22750 (epoch 42.932), train_loss = 0.67664068, grad/param norm = 2.4965e-01, time/batch = 18.3470s	
19535/22750 (epoch 42.934), train_loss = 0.60385226, grad/param norm = 2.1097e-01, time/batch = 18.5955s	
19536/22750 (epoch 42.936), train_loss = 0.79472322, grad/param norm = 2.3463e-01, time/batch = 17.9231s	
19537/22750 (epoch 42.938), train_loss = 0.79543160, grad/param norm = 2.2938e-01, time/batch = 15.7837s	
19538/22750 (epoch 42.941), train_loss = 0.82014471, grad/param norm = 2.5380e-01, time/batch = 18.5018s	
19539/22750 (epoch 42.943), train_loss = 0.72268142, grad/param norm = 2.2038e-01, time/batch = 19.4902s	
19540/22750 (epoch 42.945), train_loss = 0.73941516, grad/param norm = 2.4618e-01, time/batch = 19.4091s	
19541/22750 (epoch 42.947), train_loss = 0.66587523, grad/param norm = 2.6770e-01, time/batch = 18.9939s	
19542/22750 (epoch 42.949), train_loss = 0.69211242, grad/param norm = 2.5788e-01, time/batch = 19.1943s	
19543/22750 (epoch 42.952), train_loss = 0.67944338, grad/param norm = 2.2892e-01, time/batch = 19.8611s	
19544/22750 (epoch 42.954), train_loss = 0.60031088, grad/param norm = 1.9333e-01, time/batch = 17.4148s	
19545/22750 (epoch 42.956), train_loss = 0.76151798, grad/param norm = 2.1809e-01, time/batch = 19.4225s	
19546/22750 (epoch 42.958), train_loss = 0.62548510, grad/param norm = 1.9239e-01, time/batch = 19.7412s	
19547/22750 (epoch 42.960), train_loss = 0.62497386, grad/param norm = 2.3658e-01, time/batch = 17.2436s	
19548/22750 (epoch 42.963), train_loss = 0.72434569, grad/param norm = 2.2005e-01, time/batch = 18.1775s	
19549/22750 (epoch 42.965), train_loss = 0.77684527, grad/param norm = 2.1014e-01, time/batch = 17.9932s	
19550/22750 (epoch 42.967), train_loss = 0.74290181, grad/param norm = 2.2727e-01, time/batch = 17.3384s	
19551/22750 (epoch 42.969), train_loss = 0.67199997, grad/param norm = 2.5168e-01, time/batch = 19.7698s	
19552/22750 (epoch 42.971), train_loss = 0.64898123, grad/param norm = 2.0991e-01, time/batch = 20.3607s	
19553/22750 (epoch 42.974), train_loss = 0.64182196, grad/param norm = 2.1096e-01, time/batch = 19.4156s	
19554/22750 (epoch 42.976), train_loss = 0.67851481, grad/param norm = 2.3423e-01, time/batch = 17.1006s	
19555/22750 (epoch 42.978), train_loss = 0.63895250, grad/param norm = 2.2239e-01, time/batch = 18.8929s	
19556/22750 (epoch 42.980), train_loss = 0.82490219, grad/param norm = 2.4520e-01, time/batch = 17.5747s	
19557/22750 (epoch 42.982), train_loss = 0.66437373, grad/param norm = 2.1809e-01, time/batch = 18.0997s	
19558/22750 (epoch 42.985), train_loss = 0.83437779, grad/param norm = 2.7060e-01, time/batch = 18.4912s	
19559/22750 (epoch 42.987), train_loss = 0.58633914, grad/param norm = 2.1140e-01, time/batch = 20.2581s	
19560/22750 (epoch 42.989), train_loss = 0.64186610, grad/param norm = 2.5665e-01, time/batch = 18.1084s	
19561/22750 (epoch 42.991), train_loss = 0.75898890, grad/param norm = 2.3422e-01, time/batch = 21.0911s	
19562/22750 (epoch 42.993), train_loss = 0.72299708, grad/param norm = 2.8937e-01, time/batch = 19.9281s	
19563/22750 (epoch 42.996), train_loss = 0.62244358, grad/param norm = 2.4231e-01, time/batch = 23.4262s	
19564/22750 (epoch 42.998), train_loss = 0.80280235, grad/param norm = 2.4756e-01, time/batch = 32.5756s	
decayed learning rate by a factor 0.97 to 0.00071001734908087	
19565/22750 (epoch 43.000), train_loss = 0.68954506, grad/param norm = 2.1946e-01, time/batch = 18.5978s	
19566/22750 (epoch 43.002), train_loss = 0.86267791, grad/param norm = 2.3428e-01, time/batch = 16.9927s	
19567/22750 (epoch 43.004), train_loss = 0.67909820, grad/param norm = 2.7727e-01, time/batch = 18.5163s	
19568/22750 (epoch 43.007), train_loss = 0.68626433, grad/param norm = 2.9605e-01, time/batch = 19.3632s	
19569/22750 (epoch 43.009), train_loss = 0.84275330, grad/param norm = 3.0055e-01, time/batch = 19.2683s	
19570/22750 (epoch 43.011), train_loss = 0.87806838, grad/param norm = 2.6972e-01, time/batch = 18.1418s	
19571/22750 (epoch 43.013), train_loss = 0.78830976, grad/param norm = 2.2334e-01, time/batch = 18.0025s	
19572/22750 (epoch 43.015), train_loss = 0.73148613, grad/param norm = 2.9604e-01, time/batch = 16.7497s	
19573/22750 (epoch 43.018), train_loss = 0.84998462, grad/param norm = 2.8204e-01, time/batch = 17.7415s	
19574/22750 (epoch 43.020), train_loss = 0.85505179, grad/param norm = 2.9262e-01, time/batch = 18.8183s	
19575/22750 (epoch 43.022), train_loss = 0.73839154, grad/param norm = 2.6318e-01, time/batch = 18.0738s	
19576/22750 (epoch 43.024), train_loss = 0.72437938, grad/param norm = 2.5539e-01, time/batch = 16.4324s	
19577/22750 (epoch 43.026), train_loss = 0.75660128, grad/param norm = 2.4284e-01, time/batch = 18.7791s	
19578/22750 (epoch 43.029), train_loss = 0.59270969, grad/param norm = 2.7390e-01, time/batch = 19.7668s	
19579/22750 (epoch 43.031), train_loss = 0.94383250, grad/param norm = 3.0191e-01, time/batch = 19.5718s	
19580/22750 (epoch 43.033), train_loss = 0.74462871, grad/param norm = 2.8484e-01, time/batch = 19.1551s	
19581/22750 (epoch 43.035), train_loss = 0.77600413, grad/param norm = 2.9495e-01, time/batch = 18.2426s	
19582/22750 (epoch 43.037), train_loss = 0.80272973, grad/param norm = 2.3881e-01, time/batch = 19.5514s	
19583/22750 (epoch 43.040), train_loss = 0.72759931, grad/param norm = 2.1196e-01, time/batch = 20.1407s	
19584/22750 (epoch 43.042), train_loss = 0.76082546, grad/param norm = 2.3734e-01, time/batch = 19.0674s	
19585/22750 (epoch 43.044), train_loss = 0.72803725, grad/param norm = 2.2842e-01, time/batch = 19.6081s	
19586/22750 (epoch 43.046), train_loss = 0.81964646, grad/param norm = 2.8917e-01, time/batch = 19.2656s	
19587/22750 (epoch 43.048), train_loss = 0.75034257, grad/param norm = 2.4113e-01, time/batch = 19.9438s	
19588/22750 (epoch 43.051), train_loss = 0.73186948, grad/param norm = 2.4114e-01, time/batch = 17.6650s	
19589/22750 (epoch 43.053), train_loss = 0.71562385, grad/param norm = 2.0244e-01, time/batch = 18.0887s	
19590/22750 (epoch 43.055), train_loss = 0.63902403, grad/param norm = 2.0566e-01, time/batch = 20.2333s	
19591/22750 (epoch 43.057), train_loss = 0.84276003, grad/param norm = 2.7060e-01, time/batch = 17.9956s	
19592/22750 (epoch 43.059), train_loss = 0.53669116, grad/param norm = 2.1476e-01, time/batch = 18.0081s	
19593/22750 (epoch 43.062), train_loss = 0.61839833, grad/param norm = 2.1630e-01, time/batch = 20.8952s	
19594/22750 (epoch 43.064), train_loss = 0.82530784, grad/param norm = 2.3754e-01, time/batch = 18.2494s	
19595/22750 (epoch 43.066), train_loss = 0.64754178, grad/param norm = 2.1777e-01, time/batch = 20.4341s	
19596/22750 (epoch 43.068), train_loss = 0.64782128, grad/param norm = 1.9568e-01, time/batch = 20.5217s	
19597/22750 (epoch 43.070), train_loss = 0.56006296, grad/param norm = 1.9058e-01, time/batch = 17.0749s	
19598/22750 (epoch 43.073), train_loss = 0.67649541, grad/param norm = 2.3857e-01, time/batch = 19.6562s	
19599/22750 (epoch 43.075), train_loss = 0.71472687, grad/param norm = 2.3064e-01, time/batch = 20.8980s	
19600/22750 (epoch 43.077), train_loss = 0.53176034, grad/param norm = 2.5671e-01, time/batch = 17.9926s	
19601/22750 (epoch 43.079), train_loss = 0.70155166, grad/param norm = 2.5135e-01, time/batch = 19.7938s	
19602/22750 (epoch 43.081), train_loss = 0.65659557, grad/param norm = 2.1028e-01, time/batch = 21.3345s	
19603/22750 (epoch 43.084), train_loss = 0.66634554, grad/param norm = 2.0172e-01, time/batch = 17.7704s	
19604/22750 (epoch 43.086), train_loss = 0.69861707, grad/param norm = 2.1293e-01, time/batch = 20.9767s	
19605/22750 (epoch 43.088), train_loss = 0.69041500, grad/param norm = 2.3738e-01, time/batch = 19.3935s	
19606/22750 (epoch 43.090), train_loss = 0.68796192, grad/param norm = 2.3836e-01, time/batch = 17.3256s	
19607/22750 (epoch 43.092), train_loss = 0.77025754, grad/param norm = 2.3314e-01, time/batch = 16.5207s	
19608/22750 (epoch 43.095), train_loss = 0.65493735, grad/param norm = 2.2492e-01, time/batch = 18.3202s	
19609/22750 (epoch 43.097), train_loss = 0.71994328, grad/param norm = 2.3500e-01, time/batch = 18.8386s	
19610/22750 (epoch 43.099), train_loss = 0.65398364, grad/param norm = 2.7831e-01, time/batch = 18.3977s	
19611/22750 (epoch 43.101), train_loss = 0.60458219, grad/param norm = 2.5567e-01, time/batch = 20.5993s	
19612/22750 (epoch 43.103), train_loss = 0.75947788, grad/param norm = 2.5588e-01, time/batch = 19.5142s	
19613/22750 (epoch 43.105), train_loss = 0.83365413, grad/param norm = 2.9344e-01, time/batch = 19.8201s	
19614/22750 (epoch 43.108), train_loss = 0.75345163, grad/param norm = 2.3557e-01, time/batch = 20.4011s	
19615/22750 (epoch 43.110), train_loss = 0.79135630, grad/param norm = 2.3669e-01, time/batch = 19.9909s	
19616/22750 (epoch 43.112), train_loss = 0.58975085, grad/param norm = 1.7893e-01, time/batch = 19.0486s	
19617/22750 (epoch 43.114), train_loss = 0.52938559, grad/param norm = 1.9525e-01, time/batch = 19.7502s	
19618/22750 (epoch 43.116), train_loss = 0.71820398, grad/param norm = 2.0596e-01, time/batch = 18.2129s	
19619/22750 (epoch 43.119), train_loss = 0.65872465, grad/param norm = 2.0877e-01, time/batch = 20.1644s	
19620/22750 (epoch 43.121), train_loss = 0.68201625, grad/param norm = 2.6478e-01, time/batch = 17.2674s	
19621/22750 (epoch 43.123), train_loss = 0.60781876, grad/param norm = 2.4157e-01, time/batch = 20.5755s	
19622/22750 (epoch 43.125), train_loss = 0.80820520, grad/param norm = 2.2075e-01, time/batch = 18.7391s	
19623/22750 (epoch 43.127), train_loss = 0.66624276, grad/param norm = 2.3054e-01, time/batch = 21.0621s	
19624/22750 (epoch 43.130), train_loss = 0.69730497, grad/param norm = 2.1218e-01, time/batch = 21.7052s	
19625/22750 (epoch 43.132), train_loss = 0.64865913, grad/param norm = 2.2751e-01, time/batch = 17.9692s	
19626/22750 (epoch 43.134), train_loss = 0.66391240, grad/param norm = 2.0562e-01, time/batch = 20.0669s	
19627/22750 (epoch 43.136), train_loss = 0.57460825, grad/param norm = 2.4000e-01, time/batch = 21.0624s	
19628/22750 (epoch 43.138), train_loss = 0.79284995, grad/param norm = 2.6410e-01, time/batch = 17.5111s	
19629/22750 (epoch 43.141), train_loss = 0.69935823, grad/param norm = 2.1530e-01, time/batch = 20.5891s	
19630/22750 (epoch 43.143), train_loss = 0.65076114, grad/param norm = 1.9976e-01, time/batch = 21.0829s	
19631/22750 (epoch 43.145), train_loss = 0.79022669, grad/param norm = 2.2504e-01, time/batch = 17.2523s	
19632/22750 (epoch 43.147), train_loss = 0.86507484, grad/param norm = 2.6357e-01, time/batch = 20.4415s	
19633/22750 (epoch 43.149), train_loss = 0.72006100, grad/param norm = 2.5931e-01, time/batch = 20.6533s	
19634/22750 (epoch 43.152), train_loss = 0.70321665, grad/param norm = 2.1168e-01, time/batch = 17.9105s	
19635/22750 (epoch 43.154), train_loss = 0.62601184, grad/param norm = 2.1469e-01, time/batch = 18.1272s	
19636/22750 (epoch 43.156), train_loss = 0.62940267, grad/param norm = 2.3607e-01, time/batch = 20.4060s	
19637/22750 (epoch 43.158), train_loss = 0.61791222, grad/param norm = 2.2862e-01, time/batch = 20.1675s	
19638/22750 (epoch 43.160), train_loss = 0.68651939, grad/param norm = 2.2318e-01, time/batch = 19.8449s	
19639/22750 (epoch 43.163), train_loss = 0.82134672, grad/param norm = 2.4758e-01, time/batch = 19.6095s	
19640/22750 (epoch 43.165), train_loss = 0.75836319, grad/param norm = 2.5493e-01, time/batch = 19.4696s	
19641/22750 (epoch 43.167), train_loss = 0.65998986, grad/param norm = 2.4298e-01, time/batch = 17.8425s	
19642/22750 (epoch 43.169), train_loss = 0.71128923, grad/param norm = 3.4159e-01, time/batch = 19.2462s	
19643/22750 (epoch 43.171), train_loss = 0.59860830, grad/param norm = 2.3551e-01, time/batch = 17.7469s	
19644/22750 (epoch 43.174), train_loss = 0.59204135, grad/param norm = 2.2510e-01, time/batch = 16.4127s	
19645/22750 (epoch 43.176), train_loss = 0.60634585, grad/param norm = 2.4897e-01, time/batch = 16.8340s	
19646/22750 (epoch 43.178), train_loss = 0.65371730, grad/param norm = 2.1529e-01, time/batch = 16.4200s	
19647/22750 (epoch 43.180), train_loss = 0.78747814, grad/param norm = 2.8334e-01, time/batch = 16.2519s	
19648/22750 (epoch 43.182), train_loss = 0.73263210, grad/param norm = 2.5416e-01, time/batch = 17.0197s	
19649/22750 (epoch 43.185), train_loss = 0.77807323, grad/param norm = 2.2665e-01, time/batch = 19.5643s	
19650/22750 (epoch 43.187), train_loss = 0.61402856, grad/param norm = 2.0251e-01, time/batch = 17.0628s	
19651/22750 (epoch 43.189), train_loss = 0.60615542, grad/param norm = 2.5601e-01, time/batch = 20.1510s	
19652/22750 (epoch 43.191), train_loss = 0.66147991, grad/param norm = 2.3656e-01, time/batch = 19.1617s	
19653/22750 (epoch 43.193), train_loss = 0.75206342, grad/param norm = 2.2890e-01, time/batch = 18.7540s	
19654/22750 (epoch 43.196), train_loss = 0.67340695, grad/param norm = 2.2563e-01, time/batch = 19.0150s	
19655/22750 (epoch 43.198), train_loss = 0.50535812, grad/param norm = 2.0717e-01, time/batch = 19.7752s	
19656/22750 (epoch 43.200), train_loss = 0.68531718, grad/param norm = 2.1408e-01, time/batch = 19.4357s	
19657/22750 (epoch 43.202), train_loss = 0.74711173, grad/param norm = 2.6814e-01, time/batch = 20.0134s	
19658/22750 (epoch 43.204), train_loss = 0.71818665, grad/param norm = 2.1969e-01, time/batch = 19.4965s	
19659/22750 (epoch 43.207), train_loss = 0.72590042, grad/param norm = 2.1139e-01, time/batch = 18.4967s	
19660/22750 (epoch 43.209), train_loss = 0.66788860, grad/param norm = 2.1197e-01, time/batch = 18.0811s	
19661/22750 (epoch 43.211), train_loss = 0.61175763, grad/param norm = 2.4522e-01, time/batch = 19.1617s	
19662/22750 (epoch 43.213), train_loss = 0.53712183, grad/param norm = 2.3414e-01, time/batch = 19.3368s	
19663/22750 (epoch 43.215), train_loss = 0.52367712, grad/param norm = 1.9305e-01, time/batch = 17.6659s	
19664/22750 (epoch 43.218), train_loss = 0.61925929, grad/param norm = 2.6173e-01, time/batch = 20.2869s	
19665/22750 (epoch 43.220), train_loss = 0.58835462, grad/param norm = 2.5342e-01, time/batch = 17.7010s	
19666/22750 (epoch 43.222), train_loss = 0.56899550, grad/param norm = 2.0261e-01, time/batch = 18.3302s	
19667/22750 (epoch 43.224), train_loss = 0.58878275, grad/param norm = 1.9152e-01, time/batch = 19.4047s	
19668/22750 (epoch 43.226), train_loss = 0.67469329, grad/param norm = 2.2526e-01, time/batch = 19.2404s	
19669/22750 (epoch 43.229), train_loss = 0.71010051, grad/param norm = 2.4391e-01, time/batch = 17.9251s	
19670/22750 (epoch 43.231), train_loss = 0.62147907, grad/param norm = 2.4129e-01, time/batch = 18.1695s	
19671/22750 (epoch 43.233), train_loss = 0.56478432, grad/param norm = 2.6776e-01, time/batch = 19.0737s	
19672/22750 (epoch 43.235), train_loss = 0.55669493, grad/param norm = 2.8723e-01, time/batch = 19.2684s	
19673/22750 (epoch 43.237), train_loss = 0.61031050, grad/param norm = 2.3595e-01, time/batch = 19.2887s	
19674/22750 (epoch 43.240), train_loss = 0.69600335, grad/param norm = 2.0991e-01, time/batch = 19.7834s	
19675/22750 (epoch 43.242), train_loss = 0.82432171, grad/param norm = 2.8160e-01, time/batch = 18.4264s	
19676/22750 (epoch 43.244), train_loss = 0.80496751, grad/param norm = 2.4040e-01, time/batch = 18.7364s	
19677/22750 (epoch 43.246), train_loss = 0.84224487, grad/param norm = 3.5971e-01, time/batch = 19.4967s	
19678/22750 (epoch 43.248), train_loss = 0.69891289, grad/param norm = 2.0778e-01, time/batch = 20.2448s	
19679/22750 (epoch 43.251), train_loss = 0.77754330, grad/param norm = 2.5730e-01, time/batch = 18.3354s	
19680/22750 (epoch 43.253), train_loss = 0.75227440, grad/param norm = 3.0053e-01, time/batch = 17.9022s	
19681/22750 (epoch 43.255), train_loss = 0.73698003, grad/param norm = 2.5519e-01, time/batch = 20.3639s	
19682/22750 (epoch 43.257), train_loss = 0.65019530, grad/param norm = 2.4608e-01, time/batch = 19.3537s	
19683/22750 (epoch 43.259), train_loss = 0.78258990, grad/param norm = 3.0008e-01, time/batch = 18.5326s	
19684/22750 (epoch 43.262), train_loss = 0.73568336, grad/param norm = 2.7145e-01, time/batch = 19.3168s	
19685/22750 (epoch 43.264), train_loss = 0.54223014, grad/param norm = 2.0017e-01, time/batch = 17.8233s	
19686/22750 (epoch 43.266), train_loss = 0.69147701, grad/param norm = 2.6840e-01, time/batch = 20.1481s	
19687/22750 (epoch 43.268), train_loss = 0.83086181, grad/param norm = 2.6307e-01, time/batch = 19.0128s	
19688/22750 (epoch 43.270), train_loss = 0.64525432, grad/param norm = 2.4841e-01, time/batch = 18.3946s	
19689/22750 (epoch 43.273), train_loss = 0.95783878, grad/param norm = 2.9571e-01, time/batch = 19.7473s	
19690/22750 (epoch 43.275), train_loss = 0.82645217, grad/param norm = 2.3432e-01, time/batch = 19.4526s	
19691/22750 (epoch 43.277), train_loss = 0.71658368, grad/param norm = 3.0629e-01, time/batch = 18.2711s	
19692/22750 (epoch 43.279), train_loss = 0.60512678, grad/param norm = 2.1926e-01, time/batch = 21.1745s	
19693/22750 (epoch 43.281), train_loss = 0.81600471, grad/param norm = 2.2331e-01, time/batch = 20.6469s	
19694/22750 (epoch 43.284), train_loss = 0.74004504, grad/param norm = 2.1558e-01, time/batch = 18.2552s	
19695/22750 (epoch 43.286), train_loss = 0.77907443, grad/param norm = 2.6352e-01, time/batch = 19.3188s	
19696/22750 (epoch 43.288), train_loss = 0.83611601, grad/param norm = 2.7366e-01, time/batch = 19.0831s	
19697/22750 (epoch 43.290), train_loss = 0.75148850, grad/param norm = 2.3631e-01, time/batch = 18.9130s	
19698/22750 (epoch 43.292), train_loss = 0.76994629, grad/param norm = 2.6262e-01, time/batch = 19.7511s	
19699/22750 (epoch 43.295), train_loss = 0.75369945, grad/param norm = 2.6221e-01, time/batch = 16.3154s	
19700/22750 (epoch 43.297), train_loss = 0.73268754, grad/param norm = 2.3221e-01, time/batch = 19.6848s	
19701/22750 (epoch 43.299), train_loss = 0.79154763, grad/param norm = 2.6210e-01, time/batch = 19.9384s	
19702/22750 (epoch 43.301), train_loss = 0.69573870, grad/param norm = 2.2275e-01, time/batch = 19.9108s	
19703/22750 (epoch 43.303), train_loss = 0.75563074, grad/param norm = 2.5462e-01, time/batch = 18.9893s	
19704/22750 (epoch 43.305), train_loss = 0.82790702, grad/param norm = 2.3309e-01, time/batch = 17.3296s	
19705/22750 (epoch 43.308), train_loss = 0.79111764, grad/param norm = 2.4054e-01, time/batch = 19.6494s	
19706/22750 (epoch 43.310), train_loss = 0.64956979, grad/param norm = 2.4624e-01, time/batch = 18.6019s	
19707/22750 (epoch 43.312), train_loss = 0.72550649, grad/param norm = 2.5546e-01, time/batch = 16.2208s	
19708/22750 (epoch 43.314), train_loss = 0.74832640, grad/param norm = 2.3991e-01, time/batch = 17.1121s	
19709/22750 (epoch 43.316), train_loss = 0.70137259, grad/param norm = 2.2955e-01, time/batch = 15.6819s	
19710/22750 (epoch 43.319), train_loss = 0.74752611, grad/param norm = 2.4588e-01, time/batch = 16.7101s	
19711/22750 (epoch 43.321), train_loss = 0.68360711, grad/param norm = 2.7588e-01, time/batch = 17.9361s	
19712/22750 (epoch 43.323), train_loss = 0.74455338, grad/param norm = 2.2956e-01, time/batch = 18.5733s	
19713/22750 (epoch 43.325), train_loss = 0.63624802, grad/param norm = 2.1690e-01, time/batch = 18.5183s	
19714/22750 (epoch 43.327), train_loss = 0.67863200, grad/param norm = 2.9575e-01, time/batch = 17.6873s	
19715/22750 (epoch 43.330), train_loss = 0.83535979, grad/param norm = 2.5249e-01, time/batch = 17.3404s	
19716/22750 (epoch 43.332), train_loss = 0.92006294, grad/param norm = 2.8501e-01, time/batch = 15.7106s	
19717/22750 (epoch 43.334), train_loss = 0.57538699, grad/param norm = 1.8471e-01, time/batch = 17.0833s	
19718/22750 (epoch 43.336), train_loss = 0.78552522, grad/param norm = 2.0401e-01, time/batch = 18.4470s	
19719/22750 (epoch 43.338), train_loss = 0.71540684, grad/param norm = 2.5377e-01, time/batch = 19.6052s	
19720/22750 (epoch 43.341), train_loss = 0.71354240, grad/param norm = 2.2501e-01, time/batch = 18.6054s	
19721/22750 (epoch 43.343), train_loss = 0.62923510, grad/param norm = 2.3749e-01, time/batch = 18.5881s	
19722/22750 (epoch 43.345), train_loss = 0.75012038, grad/param norm = 3.0956e-01, time/batch = 18.1460s	
19723/22750 (epoch 43.347), train_loss = 0.80616678, grad/param norm = 2.5431e-01, time/batch = 19.0801s	
19724/22750 (epoch 43.349), train_loss = 0.60004357, grad/param norm = 2.5083e-01, time/batch = 18.3317s	
19725/22750 (epoch 43.352), train_loss = 0.84764190, grad/param norm = 2.7718e-01, time/batch = 19.4089s	
19726/22750 (epoch 43.354), train_loss = 0.82614983, grad/param norm = 2.7516e-01, time/batch = 18.8505s	
19727/22750 (epoch 43.356), train_loss = 0.77148941, grad/param norm = 2.4443e-01, time/batch = 18.8363s	
19728/22750 (epoch 43.358), train_loss = 0.69325003, grad/param norm = 2.5379e-01, time/batch = 20.2654s	
19729/22750 (epoch 43.360), train_loss = 0.85785984, grad/param norm = 2.4048e-01, time/batch = 19.2702s	
19730/22750 (epoch 43.363), train_loss = 0.68354278, grad/param norm = 2.5254e-01, time/batch = 19.0043s	
19731/22750 (epoch 43.365), train_loss = 0.57757840, grad/param norm = 2.2014e-01, time/batch = 18.2548s	
19732/22750 (epoch 43.367), train_loss = 0.67842996, grad/param norm = 2.4421e-01, time/batch = 19.4977s	
19733/22750 (epoch 43.369), train_loss = 0.73940698, grad/param norm = 2.7993e-01, time/batch = 17.5920s	
19734/22750 (epoch 43.371), train_loss = 0.76044555, grad/param norm = 2.7505e-01, time/batch = 20.3142s	
19735/22750 (epoch 43.374), train_loss = 0.64355521, grad/param norm = 2.2240e-01, time/batch = 17.5408s	
19736/22750 (epoch 43.376), train_loss = 0.72232270, grad/param norm = 2.2642e-01, time/batch = 17.8334s	
19737/22750 (epoch 43.378), train_loss = 0.73351787, grad/param norm = 2.2466e-01, time/batch = 17.0920s	
19738/22750 (epoch 43.380), train_loss = 0.78518870, grad/param norm = 2.2167e-01, time/batch = 18.4460s	
19739/22750 (epoch 43.382), train_loss = 0.68735465, grad/param norm = 2.2649e-01, time/batch = 18.5015s	
19740/22750 (epoch 43.385), train_loss = 0.77625832, grad/param norm = 2.5140e-01, time/batch = 17.3556s	
19741/22750 (epoch 43.387), train_loss = 0.73967379, grad/param norm = 2.2533e-01, time/batch = 18.9912s	
19742/22750 (epoch 43.389), train_loss = 0.60458685, grad/param norm = 2.3170e-01, time/batch = 19.3240s	
19743/22750 (epoch 43.391), train_loss = 0.46229063, grad/param norm = 1.8075e-01, time/batch = 17.1932s	
19744/22750 (epoch 43.393), train_loss = 0.61483869, grad/param norm = 2.3201e-01, time/batch = 20.3641s	
19745/22750 (epoch 43.396), train_loss = 0.73288742, grad/param norm = 2.2346e-01, time/batch = 19.7800s	
19746/22750 (epoch 43.398), train_loss = 0.66629157, grad/param norm = 2.0241e-01, time/batch = 18.6086s	
19747/22750 (epoch 43.400), train_loss = 0.72586996, grad/param norm = 2.6405e-01, time/batch = 16.5277s	
19748/22750 (epoch 43.402), train_loss = 0.72084708, grad/param norm = 2.2286e-01, time/batch = 17.3126s	
19749/22750 (epoch 43.404), train_loss = 0.82055782, grad/param norm = 2.3471e-01, time/batch = 18.5933s	
19750/22750 (epoch 43.407), train_loss = 0.79359386, grad/param norm = 2.4332e-01, time/batch = 18.5938s	
19751/22750 (epoch 43.409), train_loss = 0.66166669, grad/param norm = 2.1652e-01, time/batch = 18.6604s	
19752/22750 (epoch 43.411), train_loss = 0.66073260, grad/param norm = 2.2665e-01, time/batch = 21.6908s	
19753/22750 (epoch 43.413), train_loss = 0.51595515, grad/param norm = 2.9221e-01, time/batch = 31.2116s	
19754/22750 (epoch 43.415), train_loss = 0.59920705, grad/param norm = 2.1831e-01, time/batch = 20.2619s	
19755/22750 (epoch 43.418), train_loss = 0.67858320, grad/param norm = 2.3872e-01, time/batch = 18.7547s	
19756/22750 (epoch 43.420), train_loss = 0.77564141, grad/param norm = 2.8093e-01, time/batch = 18.5727s	
19757/22750 (epoch 43.422), train_loss = 0.89230454, grad/param norm = 2.5501e-01, time/batch = 16.9211s	
19758/22750 (epoch 43.424), train_loss = 0.90574990, grad/param norm = 3.0112e-01, time/batch = 16.6687s	
19759/22750 (epoch 43.426), train_loss = 0.88658738, grad/param norm = 2.6105e-01, time/batch = 16.4793s	
19760/22750 (epoch 43.429), train_loss = 0.66669222, grad/param norm = 2.2226e-01, time/batch = 16.5930s	
19761/22750 (epoch 43.431), train_loss = 0.59094808, grad/param norm = 1.9641e-01, time/batch = 16.9513s	
19762/22750 (epoch 43.433), train_loss = 0.65809111, grad/param norm = 2.2096e-01, time/batch = 16.5340s	
19763/22750 (epoch 43.435), train_loss = 0.51801241, grad/param norm = 1.7398e-01, time/batch = 18.9429s	
19764/22750 (epoch 43.437), train_loss = 0.46525038, grad/param norm = 1.9319e-01, time/batch = 19.1223s	
19765/22750 (epoch 43.440), train_loss = 0.67267059, grad/param norm = 2.6850e-01, time/batch = 18.5781s	
19766/22750 (epoch 43.442), train_loss = 0.69208714, grad/param norm = 2.2581e-01, time/batch = 18.5052s	
19767/22750 (epoch 43.444), train_loss = 0.67579819, grad/param norm = 2.3839e-01, time/batch = 17.3489s	
19768/22750 (epoch 43.446), train_loss = 0.68182764, grad/param norm = 2.8083e-01, time/batch = 18.4117s	
19769/22750 (epoch 43.448), train_loss = 0.88896377, grad/param norm = 2.7807e-01, time/batch = 18.1746s	
19770/22750 (epoch 43.451), train_loss = 0.86191898, grad/param norm = 2.2797e-01, time/batch = 17.3512s	
19771/22750 (epoch 43.453), train_loss = 0.73646262, grad/param norm = 2.4673e-01, time/batch = 18.5078s	
19772/22750 (epoch 43.455), train_loss = 0.86334772, grad/param norm = 2.3731e-01, time/batch = 18.9370s	
19773/22750 (epoch 43.457), train_loss = 0.74841130, grad/param norm = 3.1579e-01, time/batch = 19.3391s	
19774/22750 (epoch 43.459), train_loss = 0.78174584, grad/param norm = 2.2751e-01, time/batch = 19.7353s	
19775/22750 (epoch 43.462), train_loss = 0.71473314, grad/param norm = 2.2410e-01, time/batch = 19.4920s	
19776/22750 (epoch 43.464), train_loss = 0.61037307, grad/param norm = 2.3940e-01, time/batch = 19.4101s	
19777/22750 (epoch 43.466), train_loss = 0.78247251, grad/param norm = 3.0790e-01, time/batch = 18.9902s	
19778/22750 (epoch 43.468), train_loss = 0.75118547, grad/param norm = 2.8088e-01, time/batch = 18.4001s	
19779/22750 (epoch 43.470), train_loss = 0.81502840, grad/param norm = 2.6383e-01, time/batch = 19.3529s	
19780/22750 (epoch 43.473), train_loss = 0.69443855, grad/param norm = 3.0620e-01, time/batch = 19.8627s	
19781/22750 (epoch 43.475), train_loss = 0.73566415, grad/param norm = 2.3715e-01, time/batch = 19.1023s	
19782/22750 (epoch 43.477), train_loss = 0.62203071, grad/param norm = 2.4314e-01, time/batch = 19.1756s	
19783/22750 (epoch 43.479), train_loss = 0.59753923, grad/param norm = 2.1691e-01, time/batch = 20.4863s	
19784/22750 (epoch 43.481), train_loss = 0.57693813, grad/param norm = 2.0880e-01, time/batch = 17.4998s	
19785/22750 (epoch 43.484), train_loss = 0.50929374, grad/param norm = 2.6214e-01, time/batch = 19.5785s	
19786/22750 (epoch 43.486), train_loss = 0.59293776, grad/param norm = 2.2553e-01, time/batch = 18.9162s	
19787/22750 (epoch 43.488), train_loss = 0.53470241, grad/param norm = 2.1480e-01, time/batch = 17.7483s	
19788/22750 (epoch 43.490), train_loss = 0.68585030, grad/param norm = 2.1312e-01, time/batch = 17.6503s	
19789/22750 (epoch 43.492), train_loss = 0.78478797, grad/param norm = 2.6550e-01, time/batch = 18.4303s	
19790/22750 (epoch 43.495), train_loss = 0.65093180, grad/param norm = 2.4259e-01, time/batch = 19.1691s	
19791/22750 (epoch 43.497), train_loss = 0.68652899, grad/param norm = 2.5437e-01, time/batch = 18.8597s	
19792/22750 (epoch 43.499), train_loss = 0.61936601, grad/param norm = 2.3767e-01, time/batch = 19.8317s	
19793/22750 (epoch 43.501), train_loss = 0.67183745, grad/param norm = 2.9777e-01, time/batch = 19.4934s	
19794/22750 (epoch 43.503), train_loss = 0.67610784, grad/param norm = 2.2055e-01, time/batch = 18.7480s	
19795/22750 (epoch 43.505), train_loss = 0.60206615, grad/param norm = 2.4494e-01, time/batch = 18.4155s	
19796/22750 (epoch 43.508), train_loss = 0.58307003, grad/param norm = 2.0471e-01, time/batch = 19.5011s	
19797/22750 (epoch 43.510), train_loss = 0.59716165, grad/param norm = 2.2477e-01, time/batch = 18.9235s	
19798/22750 (epoch 43.512), train_loss = 0.64053104, grad/param norm = 2.2927e-01, time/batch = 20.2649s	
19799/22750 (epoch 43.514), train_loss = 0.65965920, grad/param norm = 2.4379e-01, time/batch = 19.1176s	
19800/22750 (epoch 43.516), train_loss = 0.63567464, grad/param norm = 2.4834e-01, time/batch = 19.5886s	
19801/22750 (epoch 43.519), train_loss = 0.78338992, grad/param norm = 2.4037e-01, time/batch = 16.6699s	
19802/22750 (epoch 43.521), train_loss = 0.69710669, grad/param norm = 2.3582e-01, time/batch = 18.0098s	
19803/22750 (epoch 43.523), train_loss = 0.59972081, grad/param norm = 2.2639e-01, time/batch = 16.1823s	
19804/22750 (epoch 43.525), train_loss = 0.79133062, grad/param norm = 2.5828e-01, time/batch = 18.1725s	
19805/22750 (epoch 43.527), train_loss = 0.71857556, grad/param norm = 2.2597e-01, time/batch = 18.6727s	
19806/22750 (epoch 43.530), train_loss = 0.62800410, grad/param norm = 2.2650e-01, time/batch = 17.7460s	
19807/22750 (epoch 43.532), train_loss = 0.57113878, grad/param norm = 2.0496e-01, time/batch = 17.0015s	
19808/22750 (epoch 43.534), train_loss = 0.75675454, grad/param norm = 2.6984e-01, time/batch = 19.3319s	
19809/22750 (epoch 43.536), train_loss = 0.73320893, grad/param norm = 2.1662e-01, time/batch = 19.0433s	
19810/22750 (epoch 43.538), train_loss = 0.69678849, grad/param norm = 2.0843e-01, time/batch = 18.6690s	
19811/22750 (epoch 43.541), train_loss = 0.61701863, grad/param norm = 2.3616e-01, time/batch = 16.7409s	
19812/22750 (epoch 43.543), train_loss = 0.60179505, grad/param norm = 2.1929e-01, time/batch = 19.5764s	
19813/22750 (epoch 43.545), train_loss = 0.74870475, grad/param norm = 2.4786e-01, time/batch = 17.7411s	
19814/22750 (epoch 43.547), train_loss = 0.65813145, grad/param norm = 1.9454e-01, time/batch = 16.0814s	
19815/22750 (epoch 43.549), train_loss = 0.67651509, grad/param norm = 2.2859e-01, time/batch = 15.9070s	
19816/22750 (epoch 43.552), train_loss = 0.73427090, grad/param norm = 2.5783e-01, time/batch = 16.4529s	
19817/22750 (epoch 43.554), train_loss = 0.73811479, grad/param norm = 2.4711e-01, time/batch = 15.8885s	
19818/22750 (epoch 43.556), train_loss = 0.74343010, grad/param norm = 2.5884e-01, time/batch = 19.5538s	
19819/22750 (epoch 43.558), train_loss = 0.69089803, grad/param norm = 2.5233e-01, time/batch = 19.1764s	
19820/22750 (epoch 43.560), train_loss = 0.66103912, grad/param norm = 2.2744e-01, time/batch = 18.1053s	
19821/22750 (epoch 43.563), train_loss = 0.76982035, grad/param norm = 2.4119e-01, time/batch = 17.6821s	
19822/22750 (epoch 43.565), train_loss = 0.75543097, grad/param norm = 2.6451e-01, time/batch = 16.9453s	
19823/22750 (epoch 43.567), train_loss = 0.73000175, grad/param norm = 2.4646e-01, time/batch = 18.0049s	
19824/22750 (epoch 43.569), train_loss = 0.69750953, grad/param norm = 2.4100e-01, time/batch = 18.4193s	
19825/22750 (epoch 43.571), train_loss = 0.68652631, grad/param norm = 2.4118e-01, time/batch = 19.6576s	
19826/22750 (epoch 43.574), train_loss = 0.71643711, grad/param norm = 2.6438e-01, time/batch = 19.1636s	
19827/22750 (epoch 43.576), train_loss = 0.68441727, grad/param norm = 2.1165e-01, time/batch = 18.8288s	
19828/22750 (epoch 43.578), train_loss = 0.62393268, grad/param norm = 2.5200e-01, time/batch = 18.5174s	
19829/22750 (epoch 43.580), train_loss = 0.75467689, grad/param norm = 2.5727e-01, time/batch = 19.1156s	
19830/22750 (epoch 43.582), train_loss = 0.62892761, grad/param norm = 2.1193e-01, time/batch = 19.0952s	
19831/22750 (epoch 43.585), train_loss = 0.59272731, grad/param norm = 2.1187e-01, time/batch = 17.4263s	
19832/22750 (epoch 43.587), train_loss = 0.62173335, grad/param norm = 2.0057e-01, time/batch = 18.9921s	
19833/22750 (epoch 43.589), train_loss = 0.52232413, grad/param norm = 1.8397e-01, time/batch = 17.5842s	
19834/22750 (epoch 43.591), train_loss = 0.69187591, grad/param norm = 2.0068e-01, time/batch = 18.4149s	
19835/22750 (epoch 43.593), train_loss = 0.79456599, grad/param norm = 2.4013e-01, time/batch = 17.7650s	
19836/22750 (epoch 43.596), train_loss = 0.75104895, grad/param norm = 2.4877e-01, time/batch = 18.3253s	
19837/22750 (epoch 43.598), train_loss = 0.77851603, grad/param norm = 3.0045e-01, time/batch = 20.3473s	
19838/22750 (epoch 43.600), train_loss = 0.83794024, grad/param norm = 2.6898e-01, time/batch = 19.8662s	
19839/22750 (epoch 43.602), train_loss = 0.61585999, grad/param norm = 1.9731e-01, time/batch = 18.9561s	
19840/22750 (epoch 43.604), train_loss = 0.66819335, grad/param norm = 2.4276e-01, time/batch = 16.7754s	
19841/22750 (epoch 43.607), train_loss = 0.61817167, grad/param norm = 2.3327e-01, time/batch = 17.0849s	
19842/22750 (epoch 43.609), train_loss = 0.59511451, grad/param norm = 2.6877e-01, time/batch = 17.5852s	
19843/22750 (epoch 43.611), train_loss = 0.66393765, grad/param norm = 2.3135e-01, time/batch = 18.5811s	
19844/22750 (epoch 43.613), train_loss = 0.64385067, grad/param norm = 3.0366e-01, time/batch = 18.0806s	
19845/22750 (epoch 43.615), train_loss = 0.65602305, grad/param norm = 2.0567e-01, time/batch = 19.0057s	
19846/22750 (epoch 43.618), train_loss = 0.68779147, grad/param norm = 2.2487e-01, time/batch = 17.7723s	
19847/22750 (epoch 43.620), train_loss = 0.66170224, grad/param norm = 2.5352e-01, time/batch = 19.7030s	
19848/22750 (epoch 43.622), train_loss = 0.58042427, grad/param norm = 1.8660e-01, time/batch = 20.2701s	
19849/22750 (epoch 43.624), train_loss = 0.64996920, grad/param norm = 2.6284e-01, time/batch = 18.5667s	
19850/22750 (epoch 43.626), train_loss = 0.55587790, grad/param norm = 2.0391e-01, time/batch = 19.1596s	
19851/22750 (epoch 43.629), train_loss = 0.63532708, grad/param norm = 2.0734e-01, time/batch = 18.5838s	
19852/22750 (epoch 43.631), train_loss = 0.66580236, grad/param norm = 1.9351e-01, time/batch = 18.4246s	
19853/22750 (epoch 43.633), train_loss = 0.58202942, grad/param norm = 2.1241e-01, time/batch = 19.1766s	
19854/22750 (epoch 43.635), train_loss = 0.69614010, grad/param norm = 2.3379e-01, time/batch = 19.7484s	
19855/22750 (epoch 43.637), train_loss = 0.74072078, grad/param norm = 3.0368e-01, time/batch = 18.5181s	
19856/22750 (epoch 43.640), train_loss = 0.73102196, grad/param norm = 2.3962e-01, time/batch = 18.1717s	
19857/22750 (epoch 43.642), train_loss = 0.77845959, grad/param norm = 2.3056e-01, time/batch = 20.0991s	
19858/22750 (epoch 43.644), train_loss = 0.68301968, grad/param norm = 2.3579e-01, time/batch = 18.4831s	
19859/22750 (epoch 43.646), train_loss = 0.73042281, grad/param norm = 2.4277e-01, time/batch = 17.4308s	
19860/22750 (epoch 43.648), train_loss = 0.73035887, grad/param norm = 2.4013e-01, time/batch = 18.8260s	
19861/22750 (epoch 43.651), train_loss = 0.72859040, grad/param norm = 2.4126e-01, time/batch = 18.3797s	
19862/22750 (epoch 43.653), train_loss = 0.76484547, grad/param norm = 2.1347e-01, time/batch = 15.9222s	
19863/22750 (epoch 43.655), train_loss = 0.70846558, grad/param norm = 2.3268e-01, time/batch = 16.4236s	
19864/22750 (epoch 43.657), train_loss = 0.82768982, grad/param norm = 2.8395e-01, time/batch = 17.5218s	
19865/22750 (epoch 43.659), train_loss = 0.86425603, grad/param norm = 2.3455e-01, time/batch = 18.0148s	
19866/22750 (epoch 43.662), train_loss = 0.83170596, grad/param norm = 3.2907e-01, time/batch = 19.6917s	
19867/22750 (epoch 43.664), train_loss = 0.72417455, grad/param norm = 2.3309e-01, time/batch = 19.3596s	
19868/22750 (epoch 43.666), train_loss = 0.60165720, grad/param norm = 2.0013e-01, time/batch = 16.5946s	
19869/22750 (epoch 43.668), train_loss = 0.67467975, grad/param norm = 2.4127e-01, time/batch = 18.9165s	
19870/22750 (epoch 43.670), train_loss = 0.64774696, grad/param norm = 2.2912e-01, time/batch = 17.5529s	
19871/22750 (epoch 43.673), train_loss = 0.85238526, grad/param norm = 2.6749e-01, time/batch = 17.0889s	
19872/22750 (epoch 43.675), train_loss = 0.96340410, grad/param norm = 3.5761e-01, time/batch = 17.9331s	
19873/22750 (epoch 43.677), train_loss = 0.82999290, grad/param norm = 2.6529e-01, time/batch = 19.5045s	
19874/22750 (epoch 43.679), train_loss = 0.81856763, grad/param norm = 2.7425e-01, time/batch = 19.5315s	
19875/22750 (epoch 43.681), train_loss = 0.83147439, grad/param norm = 2.6559e-01, time/batch = 18.5290s	
19876/22750 (epoch 43.684), train_loss = 0.86057493, grad/param norm = 2.6172e-01, time/batch = 17.9435s	
19877/22750 (epoch 43.686), train_loss = 0.88704017, grad/param norm = 2.7300e-01, time/batch = 20.4964s	
19878/22750 (epoch 43.688), train_loss = 0.83109434, grad/param norm = 2.5351e-01, time/batch = 17.5080s	
19879/22750 (epoch 43.690), train_loss = 0.82530801, grad/param norm = 2.5776e-01, time/batch = 18.8191s	
19880/22750 (epoch 43.692), train_loss = 0.82428177, grad/param norm = 2.4427e-01, time/batch = 18.8091s	
19881/22750 (epoch 43.695), train_loss = 0.73536701, grad/param norm = 2.3939e-01, time/batch = 17.8250s	
19882/22750 (epoch 43.697), train_loss = 0.75269874, grad/param norm = 2.1667e-01, time/batch = 19.4784s	
19883/22750 (epoch 43.699), train_loss = 0.64909644, grad/param norm = 2.1044e-01, time/batch = 19.9282s	
19884/22750 (epoch 43.701), train_loss = 0.60909586, grad/param norm = 2.4697e-01, time/batch = 18.1154s	
19885/22750 (epoch 43.703), train_loss = 0.67187734, grad/param norm = 2.5225e-01, time/batch = 19.8540s	
19886/22750 (epoch 43.705), train_loss = 0.66154243, grad/param norm = 2.3103e-01, time/batch = 19.5941s	
19887/22750 (epoch 43.708), train_loss = 0.70920631, grad/param norm = 4.4195e-01, time/batch = 19.1719s	
19888/22750 (epoch 43.710), train_loss = 0.63029154, grad/param norm = 2.2693e-01, time/batch = 20.1609s	
19889/22750 (epoch 43.712), train_loss = 0.55124503, grad/param norm = 2.4204e-01, time/batch = 18.5114s	
19890/22750 (epoch 43.714), train_loss = 0.61320469, grad/param norm = 2.1811e-01, time/batch = 18.4982s	
19891/22750 (epoch 43.716), train_loss = 0.60168400, grad/param norm = 2.3063e-01, time/batch = 19.0893s	
19892/22750 (epoch 43.719), train_loss = 0.66832610, grad/param norm = 3.2350e-01, time/batch = 18.2532s	
19893/22750 (epoch 43.721), train_loss = 0.81159854, grad/param norm = 2.3952e-01, time/batch = 18.7836s	
19894/22750 (epoch 43.723), train_loss = 0.76125336, grad/param norm = 2.6293e-01, time/batch = 18.1973s	
19895/22750 (epoch 43.725), train_loss = 0.66169914, grad/param norm = 2.2688e-01, time/batch = 19.1109s	
19896/22750 (epoch 43.727), train_loss = 0.71067554, grad/param norm = 2.4416e-01, time/batch = 20.4233s	
19897/22750 (epoch 43.730), train_loss = 0.66550136, grad/param norm = 2.2084e-01, time/batch = 17.8212s	
19898/22750 (epoch 43.732), train_loss = 0.65609207, grad/param norm = 2.2639e-01, time/batch = 18.9223s	
19899/22750 (epoch 43.734), train_loss = 0.59075830, grad/param norm = 1.9461e-01, time/batch = 19.9022s	
19900/22750 (epoch 43.736), train_loss = 0.67004507, grad/param norm = 2.2615e-01, time/batch = 17.9225s	
19901/22750 (epoch 43.738), train_loss = 0.72408411, grad/param norm = 2.3489e-01, time/batch = 19.7436s	
19902/22750 (epoch 43.741), train_loss = 0.82630431, grad/param norm = 2.4864e-01, time/batch = 20.2614s	
19903/22750 (epoch 43.743), train_loss = 0.71706208, grad/param norm = 2.5315e-01, time/batch = 18.2021s	
19904/22750 (epoch 43.745), train_loss = 0.60122588, grad/param norm = 2.1652e-01, time/batch = 20.8636s	
19905/22750 (epoch 43.747), train_loss = 0.70282293, grad/param norm = 1.9940e-01, time/batch = 20.5955s	
19906/22750 (epoch 43.749), train_loss = 0.81175260, grad/param norm = 2.8236e-01, time/batch = 16.3995s	
19907/22750 (epoch 43.752), train_loss = 0.71995942, grad/param norm = 2.3107e-01, time/batch = 17.3212s	
19908/22750 (epoch 43.754), train_loss = 0.71751019, grad/param norm = 2.5819e-01, time/batch = 16.3352s	
19909/22750 (epoch 43.756), train_loss = 0.65217537, grad/param norm = 2.3656e-01, time/batch = 17.1450s	
19910/22750 (epoch 43.758), train_loss = 0.64276722, grad/param norm = 2.4022e-01, time/batch = 17.5054s	
19911/22750 (epoch 43.760), train_loss = 0.65019632, grad/param norm = 2.5583e-01, time/batch = 17.9175s	
19912/22750 (epoch 43.763), train_loss = 0.68694341, grad/param norm = 2.3570e-01, time/batch = 20.2780s	
19913/22750 (epoch 43.765), train_loss = 0.68773434, grad/param norm = 2.5203e-01, time/batch = 17.3648s	
19914/22750 (epoch 43.767), train_loss = 0.73230610, grad/param norm = 2.3188e-01, time/batch = 17.9590s	
19915/22750 (epoch 43.769), train_loss = 0.81862459, grad/param norm = 2.7851e-01, time/batch = 18.6123s	
19916/22750 (epoch 43.771), train_loss = 0.83548285, grad/param norm = 2.8219e-01, time/batch = 17.2650s	
19917/22750 (epoch 43.774), train_loss = 0.64820496, grad/param norm = 2.3534e-01, time/batch = 20.1652s	
19918/22750 (epoch 43.776), train_loss = 0.77274227, grad/param norm = 2.6024e-01, time/batch = 17.8424s	
19919/22750 (epoch 43.778), train_loss = 0.81588971, grad/param norm = 2.4228e-01, time/batch = 19.0085s	
19920/22750 (epoch 43.780), train_loss = 0.74636890, grad/param norm = 2.6090e-01, time/batch = 19.7228s	
19921/22750 (epoch 43.782), train_loss = 0.85180347, grad/param norm = 2.6482e-01, time/batch = 20.5993s	
19922/22750 (epoch 43.785), train_loss = 0.68529056, grad/param norm = 2.4368e-01, time/batch = 18.8509s	
19923/22750 (epoch 43.787), train_loss = 0.60819787, grad/param norm = 2.8443e-01, time/batch = 17.5287s	
19924/22750 (epoch 43.789), train_loss = 0.68962243, grad/param norm = 2.3060e-01, time/batch = 18.5009s	
19925/22750 (epoch 43.791), train_loss = 0.66810381, grad/param norm = 2.3237e-01, time/batch = 19.9062s	
19926/22750 (epoch 43.793), train_loss = 0.64163234, grad/param norm = 2.3847e-01, time/batch = 18.2571s	
19927/22750 (epoch 43.796), train_loss = 0.60730044, grad/param norm = 2.2002e-01, time/batch = 19.4006s	
19928/22750 (epoch 43.798), train_loss = 0.64922261, grad/param norm = 2.0320e-01, time/batch = 20.2370s	
19929/22750 (epoch 43.800), train_loss = 0.64632626, grad/param norm = 2.6377e-01, time/batch = 18.4753s	
19930/22750 (epoch 43.802), train_loss = 0.59066582, grad/param norm = 2.6996e-01, time/batch = 19.5033s	
19931/22750 (epoch 43.804), train_loss = 0.76805532, grad/param norm = 2.2607e-01, time/batch = 20.1046s	
19932/22750 (epoch 43.807), train_loss = 0.75558735, grad/param norm = 3.0762e-01, time/batch = 19.3545s	
19933/22750 (epoch 43.809), train_loss = 0.84003513, grad/param norm = 3.2316e-01, time/batch = 17.9148s	
19934/22750 (epoch 43.811), train_loss = 0.72833368, grad/param norm = 2.6484e-01, time/batch = 17.3992s	
19935/22750 (epoch 43.813), train_loss = 0.74950421, grad/param norm = 2.5175e-01, time/batch = 17.8145s	
19936/22750 (epoch 43.815), train_loss = 0.80587059, grad/param norm = 2.2725e-01, time/batch = 17.7494s	
19937/22750 (epoch 43.818), train_loss = 0.77197476, grad/param norm = 2.2566e-01, time/batch = 19.9091s	
19938/22750 (epoch 43.820), train_loss = 0.88299196, grad/param norm = 2.3972e-01, time/batch = 18.3440s	
19939/22750 (epoch 43.822), train_loss = 0.74126936, grad/param norm = 2.3958e-01, time/batch = 19.2826s	
19940/22750 (epoch 43.824), train_loss = 0.61162557, grad/param norm = 1.9587e-01, time/batch = 18.2695s	
19941/22750 (epoch 43.826), train_loss = 0.69405302, grad/param norm = 2.5595e-01, time/batch = 18.7081s	
19942/22750 (epoch 43.829), train_loss = 0.77718410, grad/param norm = 2.5314e-01, time/batch = 19.7446s	
19943/22750 (epoch 43.831), train_loss = 0.79394577, grad/param norm = 2.8358e-01, time/batch = 17.6727s	
19944/22750 (epoch 43.833), train_loss = 0.73326211, grad/param norm = 2.6364e-01, time/batch = 20.0720s	
19945/22750 (epoch 43.835), train_loss = 0.63779431, grad/param norm = 2.4374e-01, time/batch = 31.5264s	
19946/22750 (epoch 43.837), train_loss = 0.68806834, grad/param norm = 2.3064e-01, time/batch = 17.1011s	
19947/22750 (epoch 43.840), train_loss = 0.63750639, grad/param norm = 2.1959e-01, time/batch = 17.9157s	
19948/22750 (epoch 43.842), train_loss = 0.65378401, grad/param norm = 2.8080e-01, time/batch = 17.7312s	
19949/22750 (epoch 43.844), train_loss = 0.73659285, grad/param norm = 2.7108e-01, time/batch = 17.6688s	
19950/22750 (epoch 43.846), train_loss = 0.75833601, grad/param norm = 2.1737e-01, time/batch = 16.1169s	
19951/22750 (epoch 43.848), train_loss = 0.65541300, grad/param norm = 2.0248e-01, time/batch = 16.3243s	
19952/22750 (epoch 43.851), train_loss = 0.64787983, grad/param norm = 2.4725e-01, time/batch = 18.0085s	
19953/22750 (epoch 43.853), train_loss = 0.81434882, grad/param norm = 2.5169e-01, time/batch = 18.4136s	
19954/22750 (epoch 43.855), train_loss = 0.68394222, grad/param norm = 1.9653e-01, time/batch = 17.9991s	
19955/22750 (epoch 43.857), train_loss = 0.75832031, grad/param norm = 2.3216e-01, time/batch = 18.2455s	
19956/22750 (epoch 43.859), train_loss = 0.73705523, grad/param norm = 2.6059e-01, time/batch = 16.8861s	
19957/22750 (epoch 43.862), train_loss = 0.87207164, grad/param norm = 2.8508e-01, time/batch = 16.4806s	
19958/22750 (epoch 43.864), train_loss = 0.71425371, grad/param norm = 2.3576e-01, time/batch = 18.7483s	
19959/22750 (epoch 43.866), train_loss = 0.76722236, grad/param norm = 2.4145e-01, time/batch = 18.1437s	
19960/22750 (epoch 43.868), train_loss = 0.63494862, grad/param norm = 2.3089e-01, time/batch = 16.6627s	
19961/22750 (epoch 43.870), train_loss = 0.62487031, grad/param norm = 2.6966e-01, time/batch = 16.4039s	
19962/22750 (epoch 43.873), train_loss = 0.70910444, grad/param norm = 2.3715e-01, time/batch = 16.7672s	
19963/22750 (epoch 43.875), train_loss = 0.75370808, grad/param norm = 2.2964e-01, time/batch = 17.5053s	
19964/22750 (epoch 43.877), train_loss = 0.67521501, grad/param norm = 2.3191e-01, time/batch = 16.8341s	
19965/22750 (epoch 43.879), train_loss = 0.80561715, grad/param norm = 2.5781e-01, time/batch = 19.3458s	
19966/22750 (epoch 43.881), train_loss = 0.73582283, grad/param norm = 2.6226e-01, time/batch = 18.2890s	
19967/22750 (epoch 43.884), train_loss = 0.64161885, grad/param norm = 2.3826e-01, time/batch = 15.8488s	
19968/22750 (epoch 43.886), train_loss = 0.71509617, grad/param norm = 2.2200e-01, time/batch = 16.8675s	
19969/22750 (epoch 43.888), train_loss = 0.75682217, grad/param norm = 2.1737e-01, time/batch = 20.2472s	
19970/22750 (epoch 43.890), train_loss = 0.76585539, grad/param norm = 2.2860e-01, time/batch = 18.6647s	
19971/22750 (epoch 43.892), train_loss = 0.93555382, grad/param norm = 2.8440e-01, time/batch = 17.5826s	
19972/22750 (epoch 43.895), train_loss = 0.70060230, grad/param norm = 3.0735e-01, time/batch = 18.7422s	
19973/22750 (epoch 43.897), train_loss = 0.82847520, grad/param norm = 2.5683e-01, time/batch = 19.9877s	
19974/22750 (epoch 43.899), train_loss = 0.73563661, grad/param norm = 2.5402e-01, time/batch = 18.0796s	
19975/22750 (epoch 43.901), train_loss = 0.80286830, grad/param norm = 2.8069e-01, time/batch = 19.2819s	
19976/22750 (epoch 43.903), train_loss = 0.70198435, grad/param norm = 2.4564e-01, time/batch = 19.0285s	
19977/22750 (epoch 43.905), train_loss = 0.76886272, grad/param norm = 2.4925e-01, time/batch = 17.6909s	
19978/22750 (epoch 43.908), train_loss = 0.61446809, grad/param norm = 2.7476e-01, time/batch = 17.1701s	
19979/22750 (epoch 43.910), train_loss = 0.54933001, grad/param norm = 2.2817e-01, time/batch = 17.1100s	
19980/22750 (epoch 43.912), train_loss = 0.72768944, grad/param norm = 2.6429e-01, time/batch = 16.9314s	
19981/22750 (epoch 43.914), train_loss = 0.73915950, grad/param norm = 2.4455e-01, time/batch = 17.2607s	
19982/22750 (epoch 43.916), train_loss = 0.57794563, grad/param norm = 1.9586e-01, time/batch = 19.3267s	
19983/22750 (epoch 43.919), train_loss = 0.71628348, grad/param norm = 2.3544e-01, time/batch = 17.3371s	
19984/22750 (epoch 43.921), train_loss = 0.55482523, grad/param norm = 1.9357e-01, time/batch = 17.9444s	
19985/22750 (epoch 43.923), train_loss = 0.65764901, grad/param norm = 2.3644e-01, time/batch = 20.7599s	
19986/22750 (epoch 43.925), train_loss = 0.70913310, grad/param norm = 2.1408e-01, time/batch = 18.6116s	
19987/22750 (epoch 43.927), train_loss = 0.56440628, grad/param norm = 2.1690e-01, time/batch = 18.0818s	
19988/22750 (epoch 43.930), train_loss = 0.53910318, grad/param norm = 2.0431e-01, time/batch = 16.9396s	
19989/22750 (epoch 43.932), train_loss = 0.68896300, grad/param norm = 2.3479e-01, time/batch = 16.4186s	
19990/22750 (epoch 43.934), train_loss = 0.58960843, grad/param norm = 1.8618e-01, time/batch = 18.3017s	
19991/22750 (epoch 43.936), train_loss = 0.78524795, grad/param norm = 2.5725e-01, time/batch = 19.2279s	
19992/22750 (epoch 43.938), train_loss = 0.77927286, grad/param norm = 2.1475e-01, time/batch = 19.6658s	
19993/22750 (epoch 43.941), train_loss = 0.81758099, grad/param norm = 2.8211e-01, time/batch = 20.3508s	
19994/22750 (epoch 43.943), train_loss = 0.70150156, grad/param norm = 2.1529e-01, time/batch = 18.4926s	
19995/22750 (epoch 43.945), train_loss = 0.74387671, grad/param norm = 2.6484e-01, time/batch = 20.6900s	
19996/22750 (epoch 43.947), train_loss = 0.65721028, grad/param norm = 2.4301e-01, time/batch = 19.4151s	
19997/22750 (epoch 43.949), train_loss = 0.67298061, grad/param norm = 2.6767e-01, time/batch = 18.1674s	
19998/22750 (epoch 43.952), train_loss = 0.69512004, grad/param norm = 2.7549e-01, time/batch = 18.8236s	
19999/22750 (epoch 43.954), train_loss = 0.60156027, grad/param norm = 2.1952e-01, time/batch = 19.2467s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_wakata_epoch43.96_1.7942.t7	
20000/22750 (epoch 43.956), train_loss = 0.76468345, grad/param norm = 2.1599e-01, time/batch = 18.5867s	
20001/22750 (epoch 43.958), train_loss = 1.44843314, grad/param norm = 3.1152e-01, time/batch = 17.0736s	
20002/22750 (epoch 43.960), train_loss = 0.63050975, grad/param norm = 2.2345e-01, time/batch = 18.8318s	
20003/22750 (epoch 43.963), train_loss = 0.72458257, grad/param norm = 2.0502e-01, time/batch = 19.2484s	
20004/22750 (epoch 43.965), train_loss = 0.77398244, grad/param norm = 2.1250e-01, time/batch = 17.6544s	
20005/22750 (epoch 43.967), train_loss = 0.73940001, grad/param norm = 2.2656e-01, time/batch = 20.6043s	
20006/22750 (epoch 43.969), train_loss = 0.65878436, grad/param norm = 2.6894e-01, time/batch = 19.6804s	
20007/22750 (epoch 43.971), train_loss = 0.64909902, grad/param norm = 2.2116e-01, time/batch = 18.6040s	
20008/22750 (epoch 43.974), train_loss = 0.63127297, grad/param norm = 2.1744e-01, time/batch = 18.2656s	
20009/22750 (epoch 43.976), train_loss = 0.66841523, grad/param norm = 2.3122e-01, time/batch = 18.9050s	
20010/22750 (epoch 43.978), train_loss = 0.63796764, grad/param norm = 2.3188e-01, time/batch = 16.8296s	
20011/22750 (epoch 43.980), train_loss = 0.81971906, grad/param norm = 2.7251e-01, time/batch = 17.8451s	
20012/22750 (epoch 43.982), train_loss = 0.64785603, grad/param norm = 2.3640e-01, time/batch = 20.0615s	
20013/22750 (epoch 43.985), train_loss = 0.82521998, grad/param norm = 2.6474e-01, time/batch = 20.2550s	
20014/22750 (epoch 43.987), train_loss = 0.58227038, grad/param norm = 2.4608e-01, time/batch = 17.9137s	
20015/22750 (epoch 43.989), train_loss = 0.63224250, grad/param norm = 2.4333e-01, time/batch = 16.9051s	
20016/22750 (epoch 43.991), train_loss = 0.74190282, grad/param norm = 2.4302e-01, time/batch = 16.6214s	
20017/22750 (epoch 43.993), train_loss = 0.69574803, grad/param norm = 3.1196e-01, time/batch = 16.9997s	
20018/22750 (epoch 43.996), train_loss = 0.60848009, grad/param norm = 2.2920e-01, time/batch = 18.0996s	
20019/22750 (epoch 43.998), train_loss = 0.80214183, grad/param norm = 2.7974e-01, time/batch = 19.0880s	
decayed learning rate by a factor 0.97 to 0.00068871682860844	
20020/22750 (epoch 44.000), train_loss = 0.68426378, grad/param norm = 2.3930e-01, time/batch = 16.2602s	
20021/22750 (epoch 44.002), train_loss = 0.86022973, grad/param norm = 2.6825e-01, time/batch = 17.7569s	
20022/22750 (epoch 44.004), train_loss = 0.66892680, grad/param norm = 2.2122e-01, time/batch = 17.9363s	
20023/22750 (epoch 44.007), train_loss = 0.67767518, grad/param norm = 2.7982e-01, time/batch = 18.5421s	
20024/22750 (epoch 44.009), train_loss = 0.84037009, grad/param norm = 2.8160e-01, time/batch = 18.0883s	
20025/22750 (epoch 44.011), train_loss = 0.89607734, grad/param norm = 3.0527e-01, time/batch = 16.1341s	
20026/22750 (epoch 44.013), train_loss = 0.78973661, grad/param norm = 2.5260e-01, time/batch = 17.7604s	
20027/22750 (epoch 44.015), train_loss = 0.71987584, grad/param norm = 2.4276e-01, time/batch = 18.5826s	
20028/22750 (epoch 44.018), train_loss = 0.82205190, grad/param norm = 2.4432e-01, time/batch = 19.0046s	
20029/22750 (epoch 44.020), train_loss = 0.83483481, grad/param norm = 2.9664e-01, time/batch = 18.3372s	
20030/22750 (epoch 44.022), train_loss = 0.72176644, grad/param norm = 2.7485e-01, time/batch = 18.0008s	
20031/22750 (epoch 44.024), train_loss = 0.71866174, grad/param norm = 2.3695e-01, time/batch = 20.4152s	
20032/22750 (epoch 44.026), train_loss = 0.77158949, grad/param norm = 3.2776e-01, time/batch = 18.6772s	
20033/22750 (epoch 44.029), train_loss = 0.57928115, grad/param norm = 2.2961e-01, time/batch = 19.4225s	
20034/22750 (epoch 44.031), train_loss = 0.92286487, grad/param norm = 2.5874e-01, time/batch = 19.0148s	
20035/22750 (epoch 44.033), train_loss = 0.73328673, grad/param norm = 2.7229e-01, time/batch = 20.5003s	
20036/22750 (epoch 44.035), train_loss = 0.75880656, grad/param norm = 2.3348e-01, time/batch = 19.4099s	
20037/22750 (epoch 44.037), train_loss = 0.78941937, grad/param norm = 2.9397e-01, time/batch = 17.9092s	
20038/22750 (epoch 44.040), train_loss = 0.72118024, grad/param norm = 2.2637e-01, time/batch = 18.1794s	
20039/22750 (epoch 44.042), train_loss = 0.75889436, grad/param norm = 2.6280e-01, time/batch = 19.2432s	
20040/22750 (epoch 44.044), train_loss = 0.72872753, grad/param norm = 2.9425e-01, time/batch = 17.9225s	
20041/22750 (epoch 44.046), train_loss = 0.80085716, grad/param norm = 2.5794e-01, time/batch = 19.6884s	
20042/22750 (epoch 44.048), train_loss = 0.74852803, grad/param norm = 2.5645e-01, time/batch = 20.2897s	
20043/22750 (epoch 44.051), train_loss = 0.72926312, grad/param norm = 2.4570e-01, time/batch = 19.1134s	
20044/22750 (epoch 44.053), train_loss = 0.70887157, grad/param norm = 2.2571e-01, time/batch = 17.5925s	
20045/22750 (epoch 44.055), train_loss = 0.63273076, grad/param norm = 2.4335e-01, time/batch = 17.9091s	
20046/22750 (epoch 44.057), train_loss = 0.82831308, grad/param norm = 2.7610e-01, time/batch = 16.6586s	
20047/22750 (epoch 44.059), train_loss = 0.53568619, grad/param norm = 1.9798e-01, time/batch = 17.1390s	
20048/22750 (epoch 44.062), train_loss = 0.60060514, grad/param norm = 2.0562e-01, time/batch = 16.4963s	
20049/22750 (epoch 44.064), train_loss = 0.82248600, grad/param norm = 2.4286e-01, time/batch = 17.6694s	
20050/22750 (epoch 44.066), train_loss = 0.62733761, grad/param norm = 2.0586e-01, time/batch = 18.9340s	
20051/22750 (epoch 44.068), train_loss = 0.63680418, grad/param norm = 2.0233e-01, time/batch = 18.6169s	
20052/22750 (epoch 44.070), train_loss = 0.54434285, grad/param norm = 1.9415e-01, time/batch = 19.3694s	
20053/22750 (epoch 44.073), train_loss = 0.65843257, grad/param norm = 2.2671e-01, time/batch = 18.1680s	
20054/22750 (epoch 44.075), train_loss = 0.71284814, grad/param norm = 2.3958e-01, time/batch = 18.6708s	
20055/22750 (epoch 44.077), train_loss = 0.52150547, grad/param norm = 2.2608e-01, time/batch = 18.5758s	
20056/22750 (epoch 44.079), train_loss = 0.69282652, grad/param norm = 2.3685e-01, time/batch = 18.2395s	
20057/22750 (epoch 44.081), train_loss = 0.66530147, grad/param norm = 2.1870e-01, time/batch = 19.2460s	
20058/22750 (epoch 44.084), train_loss = 0.66703465, grad/param norm = 2.1074e-01, time/batch = 17.2548s	
20059/22750 (epoch 44.086), train_loss = 0.69008047, grad/param norm = 2.3585e-01, time/batch = 16.8590s	
20060/22750 (epoch 44.088), train_loss = 0.66344799, grad/param norm = 2.0966e-01, time/batch = 20.1082s	
20061/22750 (epoch 44.090), train_loss = 0.67256443, grad/param norm = 2.4167e-01, time/batch = 17.4259s	
20062/22750 (epoch 44.092), train_loss = 0.75698803, grad/param norm = 2.2637e-01, time/batch = 16.4365s	
20063/22750 (epoch 44.095), train_loss = 0.65802233, grad/param norm = 2.5010e-01, time/batch = 18.9101s	
20064/22750 (epoch 44.097), train_loss = 0.70783996, grad/param norm = 2.3633e-01, time/batch = 18.5722s	
20065/22750 (epoch 44.099), train_loss = 0.63259878, grad/param norm = 2.5164e-01, time/batch = 19.7365s	
20066/22750 (epoch 44.101), train_loss = 0.59729049, grad/param norm = 2.2293e-01, time/batch = 18.8039s	
20067/22750 (epoch 44.103), train_loss = 0.73719879, grad/param norm = 2.7052e-01, time/batch = 19.5713s	
20068/22750 (epoch 44.105), train_loss = 0.79541371, grad/param norm = 2.7930e-01, time/batch = 20.8609s	
20069/22750 (epoch 44.108), train_loss = 0.74526253, grad/param norm = 2.5096e-01, time/batch = 18.4318s	
20070/22750 (epoch 44.110), train_loss = 0.76842776, grad/param norm = 2.1437e-01, time/batch = 20.2816s	
20071/22750 (epoch 44.112), train_loss = 0.59051255, grad/param norm = 1.9169e-01, time/batch = 18.8120s	
20072/22750 (epoch 44.114), train_loss = 0.52117570, grad/param norm = 2.0599e-01, time/batch = 18.9055s	
20073/22750 (epoch 44.116), train_loss = 0.72011434, grad/param norm = 2.1841e-01, time/batch = 19.0699s	
20074/22750 (epoch 44.119), train_loss = 0.65544371, grad/param norm = 2.1160e-01, time/batch = 20.7347s	
20075/22750 (epoch 44.121), train_loss = 0.67506949, grad/param norm = 2.3933e-01, time/batch = 18.1614s	
20076/22750 (epoch 44.123), train_loss = 0.60267872, grad/param norm = 2.5073e-01, time/batch = 17.6030s	
20077/22750 (epoch 44.125), train_loss = 0.79831042, grad/param norm = 2.3011e-01, time/batch = 17.1658s	
20078/22750 (epoch 44.127), train_loss = 0.67038048, grad/param norm = 2.6436e-01, time/batch = 17.7650s	
20079/22750 (epoch 44.130), train_loss = 0.68336317, grad/param norm = 2.1592e-01, time/batch = 16.5663s	
20080/22750 (epoch 44.132), train_loss = 0.64240178, grad/param norm = 2.1144e-01, time/batch = 16.0838s	
20081/22750 (epoch 44.134), train_loss = 0.65955622, grad/param norm = 2.0964e-01, time/batch = 15.8512s	
20082/22750 (epoch 44.136), train_loss = 0.56100736, grad/param norm = 2.2957e-01, time/batch = 16.3651s	
20083/22750 (epoch 44.138), train_loss = 0.77026484, grad/param norm = 2.3735e-01, time/batch = 17.1054s	
20084/22750 (epoch 44.141), train_loss = 0.68748842, grad/param norm = 2.3224e-01, time/batch = 17.7535s	
20085/22750 (epoch 44.143), train_loss = 0.64522505, grad/param norm = 1.9331e-01, time/batch = 19.2407s	
20086/22750 (epoch 44.145), train_loss = 0.79032871, grad/param norm = 2.3179e-01, time/batch = 17.7505s	
20087/22750 (epoch 44.147), train_loss = 0.86417930, grad/param norm = 2.8970e-01, time/batch = 18.8582s	
20088/22750 (epoch 44.149), train_loss = 0.70282190, grad/param norm = 2.0797e-01, time/batch = 18.2866s	
20089/22750 (epoch 44.152), train_loss = 0.69696744, grad/param norm = 2.2948e-01, time/batch = 16.7339s	
20090/22750 (epoch 44.154), train_loss = 0.62326975, grad/param norm = 2.3546e-01, time/batch = 18.5893s	
20091/22750 (epoch 44.156), train_loss = 0.62911916, grad/param norm = 2.2934e-01, time/batch = 19.4140s	
20092/22750 (epoch 44.158), train_loss = 0.59786499, grad/param norm = 2.3469e-01, time/batch = 18.5665s	
20093/22750 (epoch 44.160), train_loss = 0.70021700, grad/param norm = 4.0099e-01, time/batch = 20.0716s	
20094/22750 (epoch 44.163), train_loss = 0.81300306, grad/param norm = 2.7502e-01, time/batch = 18.9259s	
20095/22750 (epoch 44.165), train_loss = 0.74272968, grad/param norm = 2.4124e-01, time/batch = 19.0343s	
20096/22750 (epoch 44.167), train_loss = 0.65214173, grad/param norm = 2.4455e-01, time/batch = 19.6022s	
20097/22750 (epoch 44.169), train_loss = 0.68915480, grad/param norm = 2.6753e-01, time/batch = 18.5921s	
20098/22750 (epoch 44.171), train_loss = 0.60536574, grad/param norm = 2.4350e-01, time/batch = 18.0728s	
20099/22750 (epoch 44.174), train_loss = 0.59222205, grad/param norm = 2.2453e-01, time/batch = 19.4064s	
20100/22750 (epoch 44.176), train_loss = 0.60241212, grad/param norm = 2.4430e-01, time/batch = 17.3297s	
20101/22750 (epoch 44.178), train_loss = 0.66116775, grad/param norm = 2.5052e-01, time/batch = 18.4186s	
20102/22750 (epoch 44.180), train_loss = 0.78587716, grad/param norm = 3.5610e-01, time/batch = 17.7397s	
20103/22750 (epoch 44.182), train_loss = 0.73805666, grad/param norm = 2.4556e-01, time/batch = 19.7436s	
20104/22750 (epoch 44.185), train_loss = 0.78456108, grad/param norm = 2.5308e-01, time/batch = 17.8408s	
20105/22750 (epoch 44.187), train_loss = 0.60529736, grad/param norm = 2.0935e-01, time/batch = 17.4391s	
20106/22750 (epoch 44.189), train_loss = 0.61091449, grad/param norm = 2.3573e-01, time/batch = 17.5977s	
20107/22750 (epoch 44.191), train_loss = 0.65917433, grad/param norm = 2.2279e-01, time/batch = 17.3365s	
20108/22750 (epoch 44.193), train_loss = 0.73039125, grad/param norm = 2.3397e-01, time/batch = 17.7393s	
20109/22750 (epoch 44.196), train_loss = 0.67648006, grad/param norm = 2.2935e-01, time/batch = 19.0820s	
20110/22750 (epoch 44.198), train_loss = 0.49807243, grad/param norm = 1.9558e-01, time/batch = 18.4085s	
20111/22750 (epoch 44.200), train_loss = 0.68840593, grad/param norm = 2.2024e-01, time/batch = 18.5064s	
20112/22750 (epoch 44.202), train_loss = 0.73922664, grad/param norm = 2.6744e-01, time/batch = 16.9205s	
20113/22750 (epoch 44.204), train_loss = 0.71518304, grad/param norm = 2.2235e-01, time/batch = 18.1910s	
20114/22750 (epoch 44.207), train_loss = 0.72622630, grad/param norm = 2.3672e-01, time/batch = 19.2097s	
20115/22750 (epoch 44.209), train_loss = 0.65297932, grad/param norm = 2.2596e-01, time/batch = 18.6955s	
20116/22750 (epoch 44.211), train_loss = 0.60036645, grad/param norm = 2.2787e-01, time/batch = 19.9007s	
20117/22750 (epoch 44.213), train_loss = 0.53027575, grad/param norm = 2.4841e-01, time/batch = 19.6625s	
20118/22750 (epoch 44.215), train_loss = 0.51893559, grad/param norm = 1.7922e-01, time/batch = 17.1610s	
20119/22750 (epoch 44.218), train_loss = 0.61303571, grad/param norm = 2.6733e-01, time/batch = 19.5777s	
20120/22750 (epoch 44.220), train_loss = 0.57911069, grad/param norm = 2.2518e-01, time/batch = 18.9139s	
20121/22750 (epoch 44.222), train_loss = 0.57019833, grad/param norm = 2.2200e-01, time/batch = 18.1576s	
20122/22750 (epoch 44.224), train_loss = 0.59414270, grad/param norm = 2.1394e-01, time/batch = 18.2522s	
20123/22750 (epoch 44.226), train_loss = 0.68613865, grad/param norm = 2.5643e-01, time/batch = 20.4258s	
20124/22750 (epoch 44.229), train_loss = 0.69249173, grad/param norm = 2.0815e-01, time/batch = 19.0201s	
20125/22750 (epoch 44.231), train_loss = 0.60854611, grad/param norm = 2.1291e-01, time/batch = 18.8383s	
20126/22750 (epoch 44.233), train_loss = 0.55343422, grad/param norm = 2.7660e-01, time/batch = 18.3456s	
20127/22750 (epoch 44.235), train_loss = 0.55859694, grad/param norm = 2.4105e-01, time/batch = 18.0073s	
20128/22750 (epoch 44.237), train_loss = 0.60778641, grad/param norm = 2.6756e-01, time/batch = 17.0990s	
20129/22750 (epoch 44.240), train_loss = 0.69993252, grad/param norm = 2.0431e-01, time/batch = 16.4276s	
20130/22750 (epoch 44.242), train_loss = 0.79484937, grad/param norm = 2.3447e-01, time/batch = 19.0902s	
20131/22750 (epoch 44.244), train_loss = 0.82040515, grad/param norm = 2.8231e-01, time/batch = 19.5861s	
20132/22750 (epoch 44.246), train_loss = 0.82015537, grad/param norm = 2.4901e-01, time/batch = 20.9388s	
20133/22750 (epoch 44.248), train_loss = 0.68149932, grad/param norm = 1.9357e-01, time/batch = 19.2866s	
20134/22750 (epoch 44.251), train_loss = 0.75464328, grad/param norm = 2.7570e-01, time/batch = 7.7699s	
20135/22750 (epoch 44.253), train_loss = 0.74976726, grad/param norm = 3.1041e-01, time/batch = 0.7187s	
20136/22750 (epoch 44.255), train_loss = 0.73086384, grad/param norm = 2.4334e-01, time/batch = 0.7016s	
20137/22750 (epoch 44.257), train_loss = 0.62169454, grad/param norm = 2.2615e-01, time/batch = 0.6990s	
20138/22750 (epoch 44.259), train_loss = 0.77538261, grad/param norm = 3.4926e-01, time/batch = 0.7175s	
20139/22750 (epoch 44.262), train_loss = 0.73056480, grad/param norm = 2.7505e-01, time/batch = 0.7175s	
20140/22750 (epoch 44.264), train_loss = 0.54323410, grad/param norm = 2.5726e-01, time/batch = 0.8097s	
20141/22750 (epoch 44.266), train_loss = 0.67331491, grad/param norm = 2.6006e-01, time/batch = 1.0242s	
20142/22750 (epoch 44.268), train_loss = 0.83471614, grad/param norm = 2.6260e-01, time/batch = 1.0372s	
20143/22750 (epoch 44.270), train_loss = 0.63048703, grad/param norm = 2.4489e-01, time/batch = 1.0410s	
20144/22750 (epoch 44.273), train_loss = 0.93809824, grad/param norm = 2.7092e-01, time/batch = 1.0315s	
20145/22750 (epoch 44.275), train_loss = 0.82172611, grad/param norm = 2.2679e-01, time/batch = 1.5019s	
20146/22750 (epoch 44.277), train_loss = 0.68774806, grad/param norm = 2.6562e-01, time/batch = 1.9129s	
20147/22750 (epoch 44.279), train_loss = 0.58701708, grad/param norm = 2.2499e-01, time/batch = 1.9032s	
20148/22750 (epoch 44.281), train_loss = 0.80896059, grad/param norm = 2.5045e-01, time/batch = 17.8972s	
20149/22750 (epoch 44.284), train_loss = 0.72956774, grad/param norm = 2.1549e-01, time/batch = 18.0046s	
20150/22750 (epoch 44.286), train_loss = 0.75302840, grad/param norm = 2.4993e-01, time/batch = 16.5395s	
20151/22750 (epoch 44.288), train_loss = 0.83218335, grad/param norm = 2.6319e-01, time/batch = 17.3117s	
20152/22750 (epoch 44.290), train_loss = 0.75831960, grad/param norm = 2.4271e-01, time/batch = 15.2878s	
20153/22750 (epoch 44.292), train_loss = 0.76868421, grad/param norm = 2.7474e-01, time/batch = 15.2339s	
20154/22750 (epoch 44.295), train_loss = 0.73520149, grad/param norm = 2.2136e-01, time/batch = 15.1341s	
20155/22750 (epoch 44.297), train_loss = 0.74733953, grad/param norm = 2.9266e-01, time/batch = 15.8689s	
20156/22750 (epoch 44.299), train_loss = 0.77850357, grad/param norm = 2.5071e-01, time/batch = 15.0708s	
20157/22750 (epoch 44.301), train_loss = 0.67297519, grad/param norm = 2.1169e-01, time/batch = 15.1457s	
20158/22750 (epoch 44.303), train_loss = 0.74313453, grad/param norm = 2.3786e-01, time/batch = 15.4191s	
20159/22750 (epoch 44.305), train_loss = 0.83044979, grad/param norm = 2.2699e-01, time/batch = 15.2033s	
20160/22750 (epoch 44.308), train_loss = 0.76637172, grad/param norm = 2.5417e-01, time/batch = 15.4492s	
20161/22750 (epoch 44.310), train_loss = 0.65102434, grad/param norm = 2.5698e-01, time/batch = 15.8355s	
20162/22750 (epoch 44.312), train_loss = 0.71984943, grad/param norm = 2.4848e-01, time/batch = 15.2054s	
20163/22750 (epoch 44.314), train_loss = 0.73353978, grad/param norm = 2.3845e-01, time/batch = 15.0539s	
20164/22750 (epoch 44.316), train_loss = 0.70381478, grad/param norm = 2.3413e-01, time/batch = 15.0636s	
20165/22750 (epoch 44.319), train_loss = 0.73854270, grad/param norm = 2.4227e-01, time/batch = 15.5465s	
20166/22750 (epoch 44.321), train_loss = 0.67777362, grad/param norm = 2.4531e-01, time/batch = 15.1438s	
20167/22750 (epoch 44.323), train_loss = 0.74295175, grad/param norm = 2.4771e-01, time/batch = 15.3069s	
20168/22750 (epoch 44.325), train_loss = 0.62084219, grad/param norm = 2.0681e-01, time/batch = 15.4136s	
20169/22750 (epoch 44.327), train_loss = 0.65274305, grad/param norm = 2.4345e-01, time/batch = 15.4540s	
20170/22750 (epoch 44.330), train_loss = 0.82708517, grad/param norm = 2.7178e-01, time/batch = 15.2068s	
20171/22750 (epoch 44.332), train_loss = 0.89748854, grad/param norm = 2.5780e-01, time/batch = 15.7687s	
20172/22750 (epoch 44.334), train_loss = 0.58332460, grad/param norm = 1.9655e-01, time/batch = 15.0468s	
20173/22750 (epoch 44.336), train_loss = 0.77906737, grad/param norm = 2.1418e-01, time/batch = 15.9313s	
20174/22750 (epoch 44.338), train_loss = 0.70261399, grad/param norm = 2.6302e-01, time/batch = 15.4540s	
20175/22750 (epoch 44.341), train_loss = 0.71998968, grad/param norm = 2.5802e-01, time/batch = 14.9117s	
20176/22750 (epoch 44.343), train_loss = 0.62209409, grad/param norm = 2.5194e-01, time/batch = 14.9179s	
20177/22750 (epoch 44.345), train_loss = 0.73866790, grad/param norm = 2.7886e-01, time/batch = 15.4789s	
20178/22750 (epoch 44.347), train_loss = 0.79760488, grad/param norm = 2.5585e-01, time/batch = 15.0568s	
20179/22750 (epoch 44.349), train_loss = 0.59860183, grad/param norm = 2.9374e-01, time/batch = 15.8627s	
20180/22750 (epoch 44.352), train_loss = 0.83546930, grad/param norm = 2.5397e-01, time/batch = 15.2159s	
20181/22750 (epoch 44.354), train_loss = 0.80767074, grad/param norm = 2.5787e-01, time/batch = 16.0075s	
20182/22750 (epoch 44.356), train_loss = 0.76481462, grad/param norm = 2.2988e-01, time/batch = 15.2913s	
20183/22750 (epoch 44.358), train_loss = 0.68477426, grad/param norm = 2.5064e-01, time/batch = 15.2136s	
20184/22750 (epoch 44.360), train_loss = 0.85485444, grad/param norm = 2.3171e-01, time/batch = 15.8458s	
20185/22750 (epoch 44.363), train_loss = 0.66450540, grad/param norm = 2.2956e-01, time/batch = 15.2179s	
20186/22750 (epoch 44.365), train_loss = 0.58264411, grad/param norm = 2.4659e-01, time/batch = 14.9992s	
20187/22750 (epoch 44.367), train_loss = 0.65198785, grad/param norm = 2.5930e-01, time/batch = 15.2229s	
20188/22750 (epoch 44.369), train_loss = 0.74108357, grad/param norm = 2.9269e-01, time/batch = 15.2163s	
20189/22750 (epoch 44.371), train_loss = 0.72851790, grad/param norm = 2.8364e-01, time/batch = 15.6123s	
20190/22750 (epoch 44.374), train_loss = 0.62718432, grad/param norm = 2.4154e-01, time/batch = 15.1252s	
20191/22750 (epoch 44.376), train_loss = 0.71385737, grad/param norm = 2.4112e-01, time/batch = 15.2185s	
20192/22750 (epoch 44.378), train_loss = 0.73462466, grad/param norm = 2.3720e-01, time/batch = 15.3703s	
20193/22750 (epoch 44.380), train_loss = 0.76807121, grad/param norm = 2.1297e-01, time/batch = 15.7576s	
20194/22750 (epoch 44.382), train_loss = 0.68355040, grad/param norm = 2.4799e-01, time/batch = 14.9652s	
20195/22750 (epoch 44.385), train_loss = 0.76711925, grad/param norm = 2.5196e-01, time/batch = 15.3749s	
20196/22750 (epoch 44.387), train_loss = 0.74277637, grad/param norm = 2.6065e-01, time/batch = 15.3087s	
20197/22750 (epoch 44.389), train_loss = 0.57193831, grad/param norm = 1.9963e-01, time/batch = 15.4658s	
20198/22750 (epoch 44.391), train_loss = 0.45017806, grad/param norm = 1.8526e-01, time/batch = 15.3694s	
20199/22750 (epoch 44.393), train_loss = 0.60340341, grad/param norm = 2.4286e-01, time/batch = 15.2408s	
20200/22750 (epoch 44.396), train_loss = 0.72082650, grad/param norm = 2.1088e-01, time/batch = 15.4428s	
20201/22750 (epoch 44.398), train_loss = 0.65968858, grad/param norm = 2.0277e-01, time/batch = 15.2889s	
20202/22750 (epoch 44.400), train_loss = 0.73280185, grad/param norm = 2.7554e-01, time/batch = 15.0433s	
20203/22750 (epoch 44.402), train_loss = 0.70175612, grad/param norm = 2.1467e-01, time/batch = 15.2076s	
20204/22750 (epoch 44.404), train_loss = 0.80753135, grad/param norm = 2.6243e-01, time/batch = 15.8375s	
20205/22750 (epoch 44.407), train_loss = 0.79154504, grad/param norm = 2.3594e-01, time/batch = 16.2252s	
20206/22750 (epoch 44.409), train_loss = 0.65132084, grad/param norm = 2.2933e-01, time/batch = 15.3647s	
20207/22750 (epoch 44.411), train_loss = 0.64917786, grad/param norm = 2.1977e-01, time/batch = 14.9742s	
20208/22750 (epoch 44.413), train_loss = 0.51024287, grad/param norm = 2.3621e-01, time/batch = 15.6371s	
20209/22750 (epoch 44.415), train_loss = 0.58031620, grad/param norm = 2.1370e-01, time/batch = 14.9169s	
20210/22750 (epoch 44.418), train_loss = 0.67049181, grad/param norm = 2.4895e-01, time/batch = 15.4832s	
20211/22750 (epoch 44.420), train_loss = 0.76139992, grad/param norm = 2.9025e-01, time/batch = 15.0531s	
20212/22750 (epoch 44.422), train_loss = 0.86649026, grad/param norm = 2.6080e-01, time/batch = 15.8590s	
20213/22750 (epoch 44.424), train_loss = 0.88500892, grad/param norm = 2.7982e-01, time/batch = 15.0526s	
20214/22750 (epoch 44.426), train_loss = 0.87481679, grad/param norm = 2.5101e-01, time/batch = 15.2987s	
20215/22750 (epoch 44.429), train_loss = 0.64633251, grad/param norm = 2.2547e-01, time/batch = 15.1313s	
20216/22750 (epoch 44.431), train_loss = 0.58426813, grad/param norm = 2.0556e-01, time/batch = 15.4563s	
20217/22750 (epoch 44.433), train_loss = 0.66098551, grad/param norm = 2.3922e-01, time/batch = 14.9641s	
20218/22750 (epoch 44.435), train_loss = 0.51197121, grad/param norm = 1.8761e-01, time/batch = 15.5267s	
20219/22750 (epoch 44.437), train_loss = 0.44554222, grad/param norm = 1.7252e-01, time/batch = 14.8338s	
20220/22750 (epoch 44.440), train_loss = 0.65839213, grad/param norm = 2.3573e-01, time/batch = 15.5320s	
20221/22750 (epoch 44.442), train_loss = 0.69045645, grad/param norm = 2.5138e-01, time/batch = 15.9285s	
20222/22750 (epoch 44.444), train_loss = 0.66737143, grad/param norm = 2.4411e-01, time/batch = 15.3655s	
20223/22750 (epoch 44.446), train_loss = 0.66767295, grad/param norm = 2.5569e-01, time/batch = 15.3631s	
20224/22750 (epoch 44.448), train_loss = 0.89723037, grad/param norm = 2.9632e-01, time/batch = 15.2896s	
20225/22750 (epoch 44.451), train_loss = 0.85440683, grad/param norm = 2.6219e-01, time/batch = 14.9767s	
20226/22750 (epoch 44.453), train_loss = 0.72166768, grad/param norm = 2.5810e-01, time/batch = 15.4471s	
20227/22750 (epoch 44.455), train_loss = 0.83839715, grad/param norm = 2.4279e-01, time/batch = 15.3705s	
20228/22750 (epoch 44.457), train_loss = 0.73296860, grad/param norm = 3.0667e-01, time/batch = 14.9711s	
20229/22750 (epoch 44.459), train_loss = 0.76569796, grad/param norm = 2.2861e-01, time/batch = 14.9042s	
20230/22750 (epoch 44.462), train_loss = 0.71666148, grad/param norm = 2.2149e-01, time/batch = 15.9853s	
20231/22750 (epoch 44.464), train_loss = 0.59731605, grad/param norm = 2.0410e-01, time/batch = 17.5438s	
20232/22750 (epoch 44.466), train_loss = 0.76254372, grad/param norm = 2.9648e-01, time/batch = 18.6861s	
20233/22750 (epoch 44.468), train_loss = 0.73704438, grad/param norm = 2.5866e-01, time/batch = 16.9320s	
20234/22750 (epoch 44.470), train_loss = 0.80768067, grad/param norm = 2.4052e-01, time/batch = 18.6728s	
20235/22750 (epoch 44.473), train_loss = 0.68561290, grad/param norm = 2.3024e-01, time/batch = 18.8927s	
20236/22750 (epoch 44.475), train_loss = 0.72555106, grad/param norm = 2.6907e-01, time/batch = 18.2483s	
20237/22750 (epoch 44.477), train_loss = 0.62963982, grad/param norm = 2.8550e-01, time/batch = 15.2097s	
20238/22750 (epoch 44.479), train_loss = 0.60275974, grad/param norm = 2.0795e-01, time/batch = 16.1972s	
20239/22750 (epoch 44.481), train_loss = 0.56886141, grad/param norm = 2.0075e-01, time/batch = 19.8526s	
20240/22750 (epoch 44.484), train_loss = 0.49859793, grad/param norm = 2.4957e-01, time/batch = 19.8531s	
20241/22750 (epoch 44.486), train_loss = 0.57832016, grad/param norm = 2.1280e-01, time/batch = 16.9405s	
20242/22750 (epoch 44.488), train_loss = 0.54129044, grad/param norm = 2.1826e-01, time/batch = 19.4136s	
20243/22750 (epoch 44.490), train_loss = 0.68202718, grad/param norm = 2.3510e-01, time/batch = 17.0158s	
20244/22750 (epoch 44.492), train_loss = 0.77918018, grad/param norm = 2.4346e-01, time/batch = 17.5621s	
20245/22750 (epoch 44.495), train_loss = 0.64921021, grad/param norm = 2.4238e-01, time/batch = 17.1027s	
20246/22750 (epoch 44.497), train_loss = 0.69812006, grad/param norm = 3.2694e-01, time/batch = 19.2371s	
20247/22750 (epoch 44.499), train_loss = 0.62388421, grad/param norm = 2.3909e-01, time/batch = 20.0758s	
20248/22750 (epoch 44.501), train_loss = 0.66931692, grad/param norm = 2.5871e-01, time/batch = 18.6877s	
20249/22750 (epoch 44.503), train_loss = 0.66342839, grad/param norm = 2.2664e-01, time/batch = 20.1117s	
20250/22750 (epoch 44.505), train_loss = 0.59956530, grad/param norm = 2.4692e-01, time/batch = 19.2809s	
20251/22750 (epoch 44.508), train_loss = 0.57223062, grad/param norm = 2.0299e-01, time/batch = 16.7125s	
20252/22750 (epoch 44.510), train_loss = 0.57906467, grad/param norm = 2.2385e-01, time/batch = 17.3543s	
20253/22750 (epoch 44.512), train_loss = 0.64022314, grad/param norm = 2.4972e-01, time/batch = 17.1597s	
20254/22750 (epoch 44.514), train_loss = 0.64583525, grad/param norm = 2.4276e-01, time/batch = 17.7405s	
20255/22750 (epoch 44.516), train_loss = 0.64243439, grad/param norm = 2.6456e-01, time/batch = 19.1675s	
20256/22750 (epoch 44.519), train_loss = 0.77037864, grad/param norm = 2.3983e-01, time/batch = 19.0838s	
20257/22750 (epoch 44.521), train_loss = 0.67679753, grad/param norm = 2.3234e-01, time/batch = 17.0412s	
20258/22750 (epoch 44.523), train_loss = 0.59503963, grad/param norm = 2.3003e-01, time/batch = 17.9331s	
20259/22750 (epoch 44.525), train_loss = 0.77570098, grad/param norm = 2.4875e-01, time/batch = 17.9297s	
20260/22750 (epoch 44.527), train_loss = 0.72015645, grad/param norm = 2.6076e-01, time/batch = 16.2893s	
20261/22750 (epoch 44.530), train_loss = 0.62503410, grad/param norm = 2.3160e-01, time/batch = 17.0477s	
20262/22750 (epoch 44.532), train_loss = 0.57375706, grad/param norm = 2.2193e-01, time/batch = 19.7354s	
20263/22750 (epoch 44.534), train_loss = 0.74055817, grad/param norm = 2.4790e-01, time/batch = 19.4889s	
20264/22750 (epoch 44.536), train_loss = 0.72106939, grad/param norm = 2.0720e-01, time/batch = 17.7632s	
20265/22750 (epoch 44.538), train_loss = 0.69473190, grad/param norm = 2.1965e-01, time/batch = 18.3334s	
20266/22750 (epoch 44.541), train_loss = 0.62097902, grad/param norm = 2.7888e-01, time/batch = 19.7613s	
20267/22750 (epoch 44.543), train_loss = 0.59584784, grad/param norm = 2.1137e-01, time/batch = 19.2746s	
20268/22750 (epoch 44.545), train_loss = 0.75766490, grad/param norm = 2.3874e-01, time/batch = 18.7001s	
20269/22750 (epoch 44.547), train_loss = 0.64517925, grad/param norm = 2.0129e-01, time/batch = 18.9229s	
20270/22750 (epoch 44.549), train_loss = 0.66880259, grad/param norm = 2.3808e-01, time/batch = 18.5665s	
20271/22750 (epoch 44.552), train_loss = 0.72309651, grad/param norm = 2.4869e-01, time/batch = 19.3270s	
20272/22750 (epoch 44.554), train_loss = 0.72184161, grad/param norm = 2.3801e-01, time/batch = 18.9900s	
20273/22750 (epoch 44.556), train_loss = 0.72150821, grad/param norm = 2.1426e-01, time/batch = 16.4951s	
20274/22750 (epoch 44.558), train_loss = 0.66918576, grad/param norm = 2.2358e-01, time/batch = 16.4727s	
20275/22750 (epoch 44.560), train_loss = 0.65831882, grad/param norm = 2.2825e-01, time/batch = 16.8510s	
20276/22750 (epoch 44.563), train_loss = 0.77054829, grad/param norm = 3.0771e-01, time/batch = 18.2069s	
20277/22750 (epoch 44.565), train_loss = 0.73267364, grad/param norm = 2.3536e-01, time/batch = 17.0205s	
20278/22750 (epoch 44.567), train_loss = 0.73306172, grad/param norm = 2.4694e-01, time/batch = 17.4324s	
20279/22750 (epoch 44.569), train_loss = 0.68610234, grad/param norm = 2.2993e-01, time/batch = 16.1614s	
20280/22750 (epoch 44.571), train_loss = 0.67551200, grad/param norm = 2.4038e-01, time/batch = 16.3852s	
20281/22750 (epoch 44.574), train_loss = 0.70279359, grad/param norm = 2.3122e-01, time/batch = 16.7200s	
20282/22750 (epoch 44.576), train_loss = 0.67684186, grad/param norm = 2.2902e-01, time/batch = 16.3071s	
20283/22750 (epoch 44.578), train_loss = 0.58726649, grad/param norm = 2.2236e-01, time/batch = 15.9264s	
20284/22750 (epoch 44.580), train_loss = 0.73413532, grad/param norm = 2.5334e-01, time/batch = 15.8529s	
20285/22750 (epoch 44.582), train_loss = 0.63350157, grad/param norm = 2.2329e-01, time/batch = 18.2361s	
20286/22750 (epoch 44.585), train_loss = 0.59503321, grad/param norm = 2.3833e-01, time/batch = 19.2740s	
20287/22750 (epoch 44.587), train_loss = 0.61322850, grad/param norm = 2.0994e-01, time/batch = 20.3471s	
20288/22750 (epoch 44.589), train_loss = 0.51381847, grad/param norm = 1.8777e-01, time/batch = 18.6066s	
20289/22750 (epoch 44.591), train_loss = 0.68144604, grad/param norm = 2.1406e-01, time/batch = 20.1498s	
20290/22750 (epoch 44.593), train_loss = 0.77175271, grad/param norm = 2.3999e-01, time/batch = 18.0005s	
20291/22750 (epoch 44.596), train_loss = 0.74530484, grad/param norm = 2.2416e-01, time/batch = 18.4820s	
20292/22750 (epoch 44.598), train_loss = 0.75696754, grad/param norm = 2.6643e-01, time/batch = 20.2392s	
20293/22750 (epoch 44.600), train_loss = 0.85056710, grad/param norm = 2.7585e-01, time/batch = 18.0932s	
20294/22750 (epoch 44.602), train_loss = 0.62683508, grad/param norm = 2.3024e-01, time/batch = 18.5101s	
20295/22750 (epoch 44.604), train_loss = 0.66017778, grad/param norm = 2.3443e-01, time/batch = 19.1648s	
20296/22750 (epoch 44.607), train_loss = 0.61316883, grad/param norm = 2.1204e-01, time/batch = 19.6987s	
20297/22750 (epoch 44.609), train_loss = 0.59524392, grad/param norm = 2.5617e-01, time/batch = 15.9059s	
20298/22750 (epoch 44.611), train_loss = 0.64127716, grad/param norm = 2.4309e-01, time/batch = 15.6420s	
20299/22750 (epoch 44.613), train_loss = 0.62357038, grad/param norm = 2.6084e-01, time/batch = 15.4806s	
20300/22750 (epoch 44.615), train_loss = 0.64653649, grad/param norm = 2.7719e-01, time/batch = 15.2405s	
20301/22750 (epoch 44.618), train_loss = 0.68248200, grad/param norm = 2.2822e-01, time/batch = 15.9809s	
20302/22750 (epoch 44.620), train_loss = 0.64563429, grad/param norm = 2.5011e-01, time/batch = 16.2171s	
20303/22750 (epoch 44.622), train_loss = 0.57920136, grad/param norm = 1.9207e-01, time/batch = 15.6355s	
20304/22750 (epoch 44.624), train_loss = 0.63036470, grad/param norm = 2.3333e-01, time/batch = 15.6613s	
20305/22750 (epoch 44.626), train_loss = 0.55642677, grad/param norm = 2.2004e-01, time/batch = 15.6528s	
20306/22750 (epoch 44.629), train_loss = 0.63396789, grad/param norm = 2.7378e-01, time/batch = 15.3182s	
20307/22750 (epoch 44.631), train_loss = 0.65866984, grad/param norm = 2.0902e-01, time/batch = 15.4045s	
20308/22750 (epoch 44.633), train_loss = 0.58003881, grad/param norm = 2.0522e-01, time/batch = 15.7148s	
20309/22750 (epoch 44.635), train_loss = 0.67384632, grad/param norm = 2.2776e-01, time/batch = 19.1550s	
20310/22750 (epoch 44.637), train_loss = 0.72266545, grad/param norm = 3.1917e-01, time/batch = 19.9883s	
20311/22750 (epoch 44.640), train_loss = 0.72878216, grad/param norm = 2.3914e-01, time/batch = 18.8991s	
20312/22750 (epoch 44.642), train_loss = 0.76432093, grad/param norm = 2.4502e-01, time/batch = 16.9755s	
20313/22750 (epoch 44.644), train_loss = 0.67764254, grad/param norm = 2.3407e-01, time/batch = 19.3149s	
20314/22750 (epoch 44.646), train_loss = 0.73880345, grad/param norm = 2.6696e-01, time/batch = 19.8619s	
20315/22750 (epoch 44.648), train_loss = 0.72097898, grad/param norm = 2.2415e-01, time/batch = 19.0192s	
20316/22750 (epoch 44.651), train_loss = 0.72736018, grad/param norm = 2.3578e-01, time/batch = 20.3456s	
20317/22750 (epoch 44.653), train_loss = 0.77450854, grad/param norm = 2.3125e-01, time/batch = 18.9208s	
20318/22750 (epoch 44.655), train_loss = 0.70252637, grad/param norm = 2.0942e-01, time/batch = 17.9109s	
20319/22750 (epoch 44.657), train_loss = 0.80592099, grad/param norm = 2.6615e-01, time/batch = 19.5782s	
20320/22750 (epoch 44.659), train_loss = 0.84889666, grad/param norm = 2.3718e-01, time/batch = 19.2472s	
20321/22750 (epoch 44.662), train_loss = 0.83752756, grad/param norm = 3.6758e-01, time/batch = 16.6771s	
20322/22750 (epoch 44.664), train_loss = 0.73991691, grad/param norm = 2.9088e-01, time/batch = 20.3341s	
20323/22750 (epoch 44.666), train_loss = 0.60817733, grad/param norm = 2.4607e-01, time/batch = 18.5872s	
20324/22750 (epoch 44.668), train_loss = 0.66725408, grad/param norm = 2.3427e-01, time/batch = 18.1693s	
20325/22750 (epoch 44.670), train_loss = 0.64015593, grad/param norm = 2.3932e-01, time/batch = 19.5955s	
20326/22750 (epoch 44.673), train_loss = 0.84800664, grad/param norm = 2.5153e-01, time/batch = 18.3329s	
20327/22750 (epoch 44.675), train_loss = 0.94196335, grad/param norm = 3.0853e-01, time/batch = 18.9193s	
20328/22750 (epoch 44.677), train_loss = 0.82809953, grad/param norm = 2.8057e-01, time/batch = 19.4918s	
20329/22750 (epoch 44.679), train_loss = 0.80965457, grad/param norm = 2.8460e-01, time/batch = 18.0040s	
20330/22750 (epoch 44.681), train_loss = 0.80309186, grad/param norm = 2.5306e-01, time/batch = 19.6580s	
20331/22750 (epoch 44.684), train_loss = 0.84663220, grad/param norm = 2.7572e-01, time/batch = 19.0129s	
20332/22750 (epoch 44.686), train_loss = 0.88845450, grad/param norm = 2.7512e-01, time/batch = 18.1062s	
20333/22750 (epoch 44.688), train_loss = 0.81635256, grad/param norm = 2.6467e-01, time/batch = 20.1706s	
20334/22750 (epoch 44.690), train_loss = 0.80825874, grad/param norm = 2.4336e-01, time/batch = 16.6671s	
20335/22750 (epoch 44.692), train_loss = 0.82766801, grad/param norm = 3.1039e-01, time/batch = 18.9799s	
20336/22750 (epoch 44.695), train_loss = 0.73929660, grad/param norm = 2.4863e-01, time/batch = 19.1579s	
20337/22750 (epoch 44.697), train_loss = 0.74951247, grad/param norm = 2.3594e-01, time/batch = 17.2586s	
20338/22750 (epoch 44.699), train_loss = 0.67222568, grad/param norm = 2.4675e-01, time/batch = 19.4825s	
20339/22750 (epoch 44.701), train_loss = 0.60114110, grad/param norm = 2.3167e-01, time/batch = 18.3324s	
20340/22750 (epoch 44.703), train_loss = 0.67012292, grad/param norm = 2.6027e-01, time/batch = 18.2655s	
20341/22750 (epoch 44.705), train_loss = 0.64775934, grad/param norm = 2.3108e-01, time/batch = 19.5362s	
20342/22750 (epoch 44.708), train_loss = 0.70442783, grad/param norm = 3.2071e-01, time/batch = 18.6953s	
20343/22750 (epoch 44.710), train_loss = 0.61329134, grad/param norm = 2.1983e-01, time/batch = 17.5402s	
20344/22750 (epoch 44.712), train_loss = 0.54355587, grad/param norm = 2.3722e-01, time/batch = 18.9136s	
20345/22750 (epoch 44.714), train_loss = 0.59750395, grad/param norm = 2.0755e-01, time/batch = 19.6692s	
20346/22750 (epoch 44.716), train_loss = 0.60825456, grad/param norm = 2.6023e-01, time/batch = 19.3230s	
20347/22750 (epoch 44.719), train_loss = 0.67025750, grad/param norm = 2.6990e-01, time/batch = 19.1544s	
20348/22750 (epoch 44.721), train_loss = 0.79158372, grad/param norm = 2.3774e-01, time/batch = 17.8977s	
20349/22750 (epoch 44.723), train_loss = 0.76768830, grad/param norm = 2.7888e-01, time/batch = 19.6090s	
20350/22750 (epoch 44.725), train_loss = 0.65386018, grad/param norm = 2.2611e-01, time/batch = 19.1930s	
20351/22750 (epoch 44.727), train_loss = 0.70268493, grad/param norm = 2.4989e-01, time/batch = 19.3428s	
20352/22750 (epoch 44.730), train_loss = 0.66481828, grad/param norm = 2.3156e-01, time/batch = 19.5946s	
20353/22750 (epoch 44.732), train_loss = 0.64725158, grad/param norm = 2.2773e-01, time/batch = 18.1785s	
20354/22750 (epoch 44.734), train_loss = 0.59151085, grad/param norm = 1.9747e-01, time/batch = 19.0824s	
20355/22750 (epoch 44.736), train_loss = 0.66571577, grad/param norm = 2.3196e-01, time/batch = 19.8326s	
20356/22750 (epoch 44.738), train_loss = 0.72816325, grad/param norm = 2.5158e-01, time/batch = 28.9882s	
20357/22750 (epoch 44.741), train_loss = 0.82833284, grad/param norm = 2.9542e-01, time/batch = 18.4587s	
20358/22750 (epoch 44.743), train_loss = 0.71348809, grad/param norm = 2.4151e-01, time/batch = 17.6832s	
20359/22750 (epoch 44.745), train_loss = 0.58919546, grad/param norm = 2.2203e-01, time/batch = 16.2778s	
20360/22750 (epoch 44.747), train_loss = 0.69324760, grad/param norm = 2.1856e-01, time/batch = 19.7496s	
20361/22750 (epoch 44.749), train_loss = 0.80448803, grad/param norm = 3.1028e-01, time/batch = 19.1565s	
20362/22750 (epoch 44.752), train_loss = 0.72493615, grad/param norm = 2.5701e-01, time/batch = 17.7340s	
20363/22750 (epoch 44.754), train_loss = 0.69805197, grad/param norm = 2.4141e-01, time/batch = 19.7510s	
20364/22750 (epoch 44.756), train_loss = 0.64816670, grad/param norm = 2.6418e-01, time/batch = 18.3117s	
20365/22750 (epoch 44.758), train_loss = 0.62549461, grad/param norm = 2.1763e-01, time/batch = 19.2423s	
20366/22750 (epoch 44.760), train_loss = 0.61843268, grad/param norm = 2.2985e-01, time/batch = 19.1569s	
20367/22750 (epoch 44.763), train_loss = 0.69285402, grad/param norm = 2.5347e-01, time/batch = 19.1632s	
20368/22750 (epoch 44.765), train_loss = 0.67683007, grad/param norm = 2.3934e-01, time/batch = 17.3578s	
20369/22750 (epoch 44.767), train_loss = 0.72730727, grad/param norm = 2.3959e-01, time/batch = 16.8531s	
20370/22750 (epoch 44.769), train_loss = 0.80388503, grad/param norm = 2.8182e-01, time/batch = 16.9021s	
20371/22750 (epoch 44.771), train_loss = 0.82656345, grad/param norm = 2.8166e-01, time/batch = 17.4922s	
20372/22750 (epoch 44.774), train_loss = 0.63442541, grad/param norm = 2.4483e-01, time/batch = 17.8966s	
20373/22750 (epoch 44.776), train_loss = 0.77383840, grad/param norm = 2.5858e-01, time/batch = 19.3207s	
20374/22750 (epoch 44.778), train_loss = 0.81112207, grad/param norm = 2.6962e-01, time/batch = 20.4847s	
20375/22750 (epoch 44.780), train_loss = 0.73022189, grad/param norm = 2.4491e-01, time/batch = 17.9001s	
20376/22750 (epoch 44.782), train_loss = 0.83291617, grad/param norm = 2.7024e-01, time/batch = 20.1108s	
20377/22750 (epoch 44.785), train_loss = 0.68297913, grad/param norm = 2.7716e-01, time/batch = 21.4319s	
20378/22750 (epoch 44.787), train_loss = 0.59912465, grad/param norm = 2.2912e-01, time/batch = 17.3626s	
20379/22750 (epoch 44.789), train_loss = 0.69235007, grad/param norm = 2.6140e-01, time/batch = 18.7383s	
20380/22750 (epoch 44.791), train_loss = 0.66514975, grad/param norm = 2.4103e-01, time/batch = 18.7382s	
20381/22750 (epoch 44.793), train_loss = 0.64499423, grad/param norm = 2.5624e-01, time/batch = 17.9083s	
20382/22750 (epoch 44.796), train_loss = 0.59383163, grad/param norm = 2.3047e-01, time/batch = 20.4829s	
20383/22750 (epoch 44.798), train_loss = 0.65451222, grad/param norm = 2.2955e-01, time/batch = 16.9110s	
20384/22750 (epoch 44.800), train_loss = 0.63283550, grad/param norm = 2.3892e-01, time/batch = 17.1999s	
20385/22750 (epoch 44.802), train_loss = 0.60397578, grad/param norm = 2.3695e-01, time/batch = 16.7551s	
20386/22750 (epoch 44.804), train_loss = 0.77513937, grad/param norm = 2.2181e-01, time/batch = 19.7753s	
20387/22750 (epoch 44.807), train_loss = 0.74168107, grad/param norm = 2.5352e-01, time/batch = 19.4326s	
20388/22750 (epoch 44.809), train_loss = 0.84889097, grad/param norm = 3.1282e-01, time/batch = 18.7376s	
20389/22750 (epoch 44.811), train_loss = 0.70211833, grad/param norm = 2.2587e-01, time/batch = 18.0725s	
20390/22750 (epoch 44.813), train_loss = 0.73261165, grad/param norm = 2.4712e-01, time/batch = 18.0755s	
20391/22750 (epoch 44.815), train_loss = 0.81533186, grad/param norm = 2.6371e-01, time/batch = 18.9170s	
20392/22750 (epoch 44.818), train_loss = 0.77255575, grad/param norm = 2.1898e-01, time/batch = 20.2349s	
20393/22750 (epoch 44.820), train_loss = 0.87304560, grad/param norm = 2.4125e-01, time/batch = 18.7593s	
20394/22750 (epoch 44.822), train_loss = 0.73301386, grad/param norm = 2.4476e-01, time/batch = 18.0207s	
20395/22750 (epoch 44.824), train_loss = 0.61889568, grad/param norm = 2.2714e-01, time/batch = 20.5138s	
20396/22750 (epoch 44.826), train_loss = 0.68789496, grad/param norm = 2.4472e-01, time/batch = 19.0335s	
20397/22750 (epoch 44.829), train_loss = 0.78415418, grad/param norm = 2.5297e-01, time/batch = 17.5148s	
20398/22750 (epoch 44.831), train_loss = 0.78139914, grad/param norm = 2.6179e-01, time/batch = 19.4174s	
20399/22750 (epoch 44.833), train_loss = 0.72254294, grad/param norm = 2.8693e-01, time/batch = 18.5820s	
20400/22750 (epoch 44.835), train_loss = 0.62389899, grad/param norm = 2.6318e-01, time/batch = 18.9167s	
20401/22750 (epoch 44.837), train_loss = 0.67098095, grad/param norm = 2.1436e-01, time/batch = 18.0906s	
20402/22750 (epoch 44.840), train_loss = 0.62132672, grad/param norm = 2.1514e-01, time/batch = 19.4334s	
20403/22750 (epoch 44.842), train_loss = 0.63447552, grad/param norm = 2.5517e-01, time/batch = 19.6808s	
20404/22750 (epoch 44.844), train_loss = 0.71595734, grad/param norm = 2.7114e-01, time/batch = 18.5980s	
20405/22750 (epoch 44.846), train_loss = 0.76592079, grad/param norm = 2.5407e-01, time/batch = 17.3479s	
20406/22750 (epoch 44.848), train_loss = 0.64815856, grad/param norm = 2.1624e-01, time/batch = 17.0996s	
20407/22750 (epoch 44.851), train_loss = 0.65041463, grad/param norm = 2.2894e-01, time/batch = 17.2450s	
20408/22750 (epoch 44.853), train_loss = 0.80168065, grad/param norm = 2.3040e-01, time/batch = 17.5627s	
20409/22750 (epoch 44.855), train_loss = 0.67214827, grad/param norm = 1.9595e-01, time/batch = 19.4914s	
20410/22750 (epoch 44.857), train_loss = 0.73969794, grad/param norm = 2.0628e-01, time/batch = 17.8287s	
20411/22750 (epoch 44.859), train_loss = 0.71949811, grad/param norm = 2.1440e-01, time/batch = 19.2634s	
20412/22750 (epoch 44.862), train_loss = 0.84330577, grad/param norm = 2.6418e-01, time/batch = 20.1021s	
20413/22750 (epoch 44.864), train_loss = 0.72236079, grad/param norm = 2.4827e-01, time/batch = 18.7826s	
20414/22750 (epoch 44.866), train_loss = 0.76418513, grad/param norm = 2.4930e-01, time/batch = 18.5972s	
20415/22750 (epoch 44.868), train_loss = 0.62756428, grad/param norm = 2.4867e-01, time/batch = 18.4148s	
20416/22750 (epoch 44.870), train_loss = 0.61603313, grad/param norm = 2.4064e-01, time/batch = 18.8291s	
20417/22750 (epoch 44.873), train_loss = 0.70517212, grad/param norm = 2.3943e-01, time/batch = 16.5257s	
20418/22750 (epoch 44.875), train_loss = 0.73942771, grad/param norm = 2.2509e-01, time/batch = 17.1051s	
20419/22750 (epoch 44.877), train_loss = 0.66941898, grad/param norm = 2.3565e-01, time/batch = 17.9210s	
20420/22750 (epoch 44.879), train_loss = 0.79045614, grad/param norm = 2.4862e-01, time/batch = 18.4209s	
20421/22750 (epoch 44.881), train_loss = 0.71191480, grad/param norm = 2.3603e-01, time/batch = 20.7692s	
20422/22750 (epoch 44.884), train_loss = 0.63011696, grad/param norm = 2.2208e-01, time/batch = 18.9436s	
20423/22750 (epoch 44.886), train_loss = 0.71721763, grad/param norm = 2.3305e-01, time/batch = 18.0784s	
20424/22750 (epoch 44.888), train_loss = 0.74944516, grad/param norm = 2.1929e-01, time/batch = 19.0735s	
20425/22750 (epoch 44.890), train_loss = 0.75213530, grad/param norm = 2.3132e-01, time/batch = 18.5113s	
20426/22750 (epoch 44.892), train_loss = 0.91698566, grad/param norm = 2.9299e-01, time/batch = 18.6643s	
20427/22750 (epoch 44.895), train_loss = 0.66793275, grad/param norm = 2.3519e-01, time/batch = 18.0689s	
20428/22750 (epoch 44.897), train_loss = 0.81754944, grad/param norm = 2.7441e-01, time/batch = 17.5905s	
20429/22750 (epoch 44.899), train_loss = 0.73341819, grad/param norm = 2.6668e-01, time/batch = 19.1716s	
20430/22750 (epoch 44.901), train_loss = 0.79433340, grad/param norm = 2.5583e-01, time/batch = 20.0298s	
20431/22750 (epoch 44.903), train_loss = 0.69632762, grad/param norm = 2.3810e-01, time/batch = 19.1836s	
20432/22750 (epoch 44.905), train_loss = 0.74893415, grad/param norm = 2.4142e-01, time/batch = 16.7656s	
20433/22750 (epoch 44.908), train_loss = 0.59668564, grad/param norm = 2.5668e-01, time/batch = 17.9108s	
20434/22750 (epoch 44.910), train_loss = 0.54155435, grad/param norm = 2.0923e-01, time/batch = 19.4180s	
20435/22750 (epoch 44.912), train_loss = 0.69888028, grad/param norm = 2.5251e-01, time/batch = 19.2515s	
20436/22750 (epoch 44.914), train_loss = 0.72889754, grad/param norm = 3.0511e-01, time/batch = 16.9054s	
20437/22750 (epoch 44.916), train_loss = 0.57669818, grad/param norm = 2.2569e-01, time/batch = 18.3358s	
20438/22750 (epoch 44.919), train_loss = 0.71266395, grad/param norm = 2.7067e-01, time/batch = 18.7002s	
20439/22750 (epoch 44.921), train_loss = 0.54516113, grad/param norm = 2.0045e-01, time/batch = 18.9337s	
20440/22750 (epoch 44.923), train_loss = 0.65263614, grad/param norm = 2.0833e-01, time/batch = 19.5383s	
20441/22750 (epoch 44.925), train_loss = 0.69066590, grad/param norm = 2.1301e-01, time/batch = 17.5210s	
20442/22750 (epoch 44.927), train_loss = 0.56016572, grad/param norm = 2.1770e-01, time/batch = 18.8271s	
20443/22750 (epoch 44.930), train_loss = 0.53305806, grad/param norm = 2.1639e-01, time/batch = 18.0784s	
20444/22750 (epoch 44.932), train_loss = 0.66328567, grad/param norm = 2.3259e-01, time/batch = 18.8175s	
20445/22750 (epoch 44.934), train_loss = 0.58588895, grad/param norm = 2.0855e-01, time/batch = 18.4174s	
20446/22750 (epoch 44.936), train_loss = 0.77596723, grad/param norm = 2.4167e-01, time/batch = 18.8350s	
20447/22750 (epoch 44.938), train_loss = 0.76813393, grad/param norm = 2.2621e-01, time/batch = 18.3494s	
20448/22750 (epoch 44.941), train_loss = 0.79498806, grad/param norm = 2.6153e-01, time/batch = 20.5148s	
20449/22750 (epoch 44.943), train_loss = 0.71930048, grad/param norm = 2.4621e-01, time/batch = 18.2759s	
20450/22750 (epoch 44.945), train_loss = 0.72253392, grad/param norm = 2.4865e-01, time/batch = 17.8399s	
20451/22750 (epoch 44.947), train_loss = 0.64531467, grad/param norm = 2.3102e-01, time/batch = 19.9175s	
20452/22750 (epoch 44.949), train_loss = 0.66126198, grad/param norm = 2.3909e-01, time/batch = 17.5768s	
20453/22750 (epoch 44.952), train_loss = 0.66625758, grad/param norm = 2.3607e-01, time/batch = 20.9755s	
20454/22750 (epoch 44.954), train_loss = 0.58568788, grad/param norm = 2.2042e-01, time/batch = 19.2394s	
20455/22750 (epoch 44.956), train_loss = 0.74670914, grad/param norm = 2.3421e-01, time/batch = 18.2531s	
20456/22750 (epoch 44.958), train_loss = 0.62700962, grad/param norm = 2.0696e-01, time/batch = 20.5172s	
20457/22750 (epoch 44.960), train_loss = 0.60869387, grad/param norm = 2.3634e-01, time/batch = 19.6008s	
20458/22750 (epoch 44.963), train_loss = 0.71940921, grad/param norm = 2.2476e-01, time/batch = 18.1104s	
20459/22750 (epoch 44.965), train_loss = 0.76483920, grad/param norm = 2.1700e-01, time/batch = 19.8474s	
20460/22750 (epoch 44.967), train_loss = 0.73261690, grad/param norm = 2.2070e-01, time/batch = 19.4188s	
20461/22750 (epoch 44.969), train_loss = 0.65629462, grad/param norm = 2.4545e-01, time/batch = 17.5585s	
20462/22750 (epoch 44.971), train_loss = 0.64148825, grad/param norm = 2.2572e-01, time/batch = 19.3221s	
20463/22750 (epoch 44.974), train_loss = 0.64131839, grad/param norm = 2.2331e-01, time/batch = 17.0074s	
20464/22750 (epoch 44.976), train_loss = 0.65406816, grad/param norm = 2.3394e-01, time/batch = 16.1519s	
20465/22750 (epoch 44.978), train_loss = 0.62350941, grad/param norm = 2.3337e-01, time/batch = 18.3258s	
20466/22750 (epoch 44.980), train_loss = 0.82776690, grad/param norm = 2.6695e-01, time/batch = 18.5962s	
20467/22750 (epoch 44.982), train_loss = 0.65081527, grad/param norm = 2.0733e-01, time/batch = 18.6120s	
20468/22750 (epoch 44.985), train_loss = 0.82544321, grad/param norm = 2.4999e-01, time/batch = 17.9897s	
20469/22750 (epoch 44.987), train_loss = 0.58055428, grad/param norm = 2.3475e-01, time/batch = 20.2192s	
20470/22750 (epoch 44.989), train_loss = 0.61789058, grad/param norm = 2.5383e-01, time/batch = 18.3441s	
20471/22750 (epoch 44.991), train_loss = 0.74045062, grad/param norm = 2.5588e-01, time/batch = 17.8166s	
20472/22750 (epoch 44.993), train_loss = 0.69456554, grad/param norm = 2.7587e-01, time/batch = 19.3286s	
20473/22750 (epoch 44.996), train_loss = 0.60444740, grad/param norm = 2.3866e-01, time/batch = 18.8175s	
20474/22750 (epoch 44.998), train_loss = 0.78927286, grad/param norm = 2.6951e-01, time/batch = 19.0280s	
decayed learning rate by a factor 0.97 to 0.00066805532375019	
20475/22750 (epoch 45.000), train_loss = 0.67642862, grad/param norm = 2.4526e-01, time/batch = 20.6817s	
20476/22750 (epoch 45.002), train_loss = 0.85374924, grad/param norm = 2.5854e-01, time/batch = 18.0342s	
20477/22750 (epoch 45.004), train_loss = 0.66211681, grad/param norm = 2.2478e-01, time/batch = 18.4230s	
20478/22750 (epoch 45.007), train_loss = 0.67310846, grad/param norm = 2.8918e-01, time/batch = 18.3513s	
20479/22750 (epoch 45.009), train_loss = 0.81730945, grad/param norm = 2.6027e-01, time/batch = 18.4992s	
20480/22750 (epoch 45.011), train_loss = 0.87352715, grad/param norm = 2.9669e-01, time/batch = 18.1454s	
20481/22750 (epoch 45.013), train_loss = 0.77260264, grad/param norm = 2.4619e-01, time/batch = 18.2520s	
20482/22750 (epoch 45.015), train_loss = 0.70473727, grad/param norm = 2.2415e-01, time/batch = 20.0698s	
20483/22750 (epoch 45.018), train_loss = 0.81808829, grad/param norm = 2.4982e-01, time/batch = 19.5902s	
20484/22750 (epoch 45.020), train_loss = 0.83032073, grad/param norm = 2.5620e-01, time/batch = 19.0830s	
20485/22750 (epoch 45.022), train_loss = 0.72113105, grad/param norm = 2.5682e-01, time/batch = 20.0897s	
20486/22750 (epoch 45.024), train_loss = 0.69494430, grad/param norm = 2.2706e-01, time/batch = 18.6597s	
20487/22750 (epoch 45.026), train_loss = 0.74255999, grad/param norm = 2.6604e-01, time/batch = 18.2388s	
20488/22750 (epoch 45.029), train_loss = 0.59209578, grad/param norm = 2.7567e-01, time/batch = 19.5834s	
20489/22750 (epoch 45.031), train_loss = 0.91128950, grad/param norm = 2.5538e-01, time/batch = 20.7353s	
20490/22750 (epoch 45.033), train_loss = 0.73595873, grad/param norm = 3.1774e-01, time/batch = 17.0766s	
20491/22750 (epoch 45.035), train_loss = 0.75991588, grad/param norm = 2.6461e-01, time/batch = 17.9827s	
20492/22750 (epoch 45.037), train_loss = 0.77488248, grad/param norm = 2.5448e-01, time/batch = 19.3357s	
20493/22750 (epoch 45.040), train_loss = 0.71969709, grad/param norm = 2.1718e-01, time/batch = 19.3509s	
20494/22750 (epoch 45.042), train_loss = 0.73930465, grad/param norm = 2.7118e-01, time/batch = 19.5224s	
20495/22750 (epoch 45.044), train_loss = 0.70934332, grad/param norm = 2.5220e-01, time/batch = 16.5082s	
20496/22750 (epoch 45.046), train_loss = 0.80430085, grad/param norm = 3.1539e-01, time/batch = 18.0830s	
20497/22750 (epoch 45.048), train_loss = 0.73590096, grad/param norm = 2.3462e-01, time/batch = 18.4225s	
20498/22750 (epoch 45.051), train_loss = 0.72138525, grad/param norm = 2.3850e-01, time/batch = 20.4938s	
20499/22750 (epoch 45.053), train_loss = 0.71281923, grad/param norm = 2.1734e-01, time/batch = 18.2502s	
20500/22750 (epoch 45.055), train_loss = 0.62895502, grad/param norm = 2.1702e-01, time/batch = 18.4117s	
20501/22750 (epoch 45.057), train_loss = 0.82259317, grad/param norm = 2.3541e-01, time/batch = 20.7697s	
20502/22750 (epoch 45.059), train_loss = 0.52732968, grad/param norm = 2.1137e-01, time/batch = 18.7133s	
20503/22750 (epoch 45.062), train_loss = 0.60472887, grad/param norm = 2.1631e-01, time/batch = 18.4444s	
20504/22750 (epoch 45.064), train_loss = 0.81944382, grad/param norm = 2.6284e-01, time/batch = 16.8402s	
20505/22750 (epoch 45.066), train_loss = 0.62252708, grad/param norm = 2.2306e-01, time/batch = 19.3954s	
20506/22750 (epoch 45.068), train_loss = 0.64340930, grad/param norm = 2.0186e-01, time/batch = 17.9068s	
20507/22750 (epoch 45.070), train_loss = 0.54069357, grad/param norm = 2.0168e-01, time/batch = 19.8252s	
20508/22750 (epoch 45.073), train_loss = 0.64201214, grad/param norm = 2.2068e-01, time/batch = 18.9943s	
20509/22750 (epoch 45.075), train_loss = 0.70476865, grad/param norm = 2.2978e-01, time/batch = 17.7821s	
20510/22750 (epoch 45.077), train_loss = 0.51958336, grad/param norm = 2.2771e-01, time/batch = 19.8660s	
20511/22750 (epoch 45.079), train_loss = 0.69758298, grad/param norm = 2.4697e-01, time/batch = 19.9335s	
20512/22750 (epoch 45.081), train_loss = 0.64950644, grad/param norm = 2.2065e-01, time/batch = 18.5861s	
20513/22750 (epoch 45.084), train_loss = 0.64765516, grad/param norm = 2.2547e-01, time/batch = 19.0689s	
20514/22750 (epoch 45.086), train_loss = 0.69074832, grad/param norm = 2.0179e-01, time/batch = 19.9900s	
20515/22750 (epoch 45.088), train_loss = 0.66098552, grad/param norm = 2.3276e-01, time/batch = 17.7425s	
20516/22750 (epoch 45.090), train_loss = 0.66965819, grad/param norm = 2.3873e-01, time/batch = 17.7369s	
20517/22750 (epoch 45.092), train_loss = 0.74960954, grad/param norm = 2.3654e-01, time/batch = 19.4960s	
20518/22750 (epoch 45.095), train_loss = 0.63084266, grad/param norm = 2.4045e-01, time/batch = 18.5335s	
20519/22750 (epoch 45.097), train_loss = 0.71141680, grad/param norm = 2.3670e-01, time/batch = 18.8641s	
20520/22750 (epoch 45.099), train_loss = 0.63041871, grad/param norm = 2.4188e-01, time/batch = 20.2787s	
20521/22750 (epoch 45.101), train_loss = 0.58783482, grad/param norm = 2.3489e-01, time/batch = 18.4068s	
20522/22750 (epoch 45.103), train_loss = 0.73198797, grad/param norm = 2.5421e-01, time/batch = 17.2551s	
20523/22750 (epoch 45.105), train_loss = 0.81115044, grad/param norm = 2.8738e-01, time/batch = 18.9100s	
20524/22750 (epoch 45.108), train_loss = 0.73212342, grad/param norm = 2.3954e-01, time/batch = 17.5016s	
20525/22750 (epoch 45.110), train_loss = 0.76641067, grad/param norm = 2.3938e-01, time/batch = 17.9908s	
20526/22750 (epoch 45.112), train_loss = 0.57715302, grad/param norm = 1.8657e-01, time/batch = 20.5925s	
20527/22750 (epoch 45.114), train_loss = 0.51261003, grad/param norm = 1.9525e-01, time/batch = 17.8491s	
20528/22750 (epoch 45.116), train_loss = 0.71089341, grad/param norm = 2.2506e-01, time/batch = 18.5471s	
20529/22750 (epoch 45.119), train_loss = 0.65774115, grad/param norm = 2.2934e-01, time/batch = 19.6800s	
20530/22750 (epoch 45.121), train_loss = 0.66067005, grad/param norm = 2.5678e-01, time/batch = 18.2623s	
20531/22750 (epoch 45.123), train_loss = 0.59237359, grad/param norm = 2.2368e-01, time/batch = 17.9910s	
20532/22750 (epoch 45.125), train_loss = 0.77730665, grad/param norm = 2.2550e-01, time/batch = 18.7367s	
20533/22750 (epoch 45.127), train_loss = 0.66245640, grad/param norm = 2.6269e-01, time/batch = 18.5819s	
20534/22750 (epoch 45.130), train_loss = 0.68970996, grad/param norm = 2.4316e-01, time/batch = 18.7570s	
20535/22750 (epoch 45.132), train_loss = 0.63705000, grad/param norm = 2.1415e-01, time/batch = 19.0190s	
20536/22750 (epoch 45.134), train_loss = 0.65350261, grad/param norm = 2.1532e-01, time/batch = 20.4412s	
20537/22750 (epoch 45.136), train_loss = 0.55579603, grad/param norm = 2.2880e-01, time/batch = 18.7065s	
20538/22750 (epoch 45.138), train_loss = 0.76591633, grad/param norm = 2.4362e-01, time/batch = 18.4198s	
20539/22750 (epoch 45.141), train_loss = 0.67187288, grad/param norm = 2.2262e-01, time/batch = 18.5052s	
20540/22750 (epoch 45.143), train_loss = 0.65388989, grad/param norm = 2.2469e-01, time/batch = 18.6535s	
20541/22750 (epoch 45.145), train_loss = 0.78896761, grad/param norm = 2.3703e-01, time/batch = 18.4019s	
20542/22750 (epoch 45.147), train_loss = 0.83637234, grad/param norm = 2.3382e-01, time/batch = 19.0866s	
20543/22750 (epoch 45.149), train_loss = 0.70434159, grad/param norm = 2.3893e-01, time/batch = 19.5150s	
20544/22750 (epoch 45.152), train_loss = 0.69050418, grad/param norm = 2.1481e-01, time/batch = 18.9550s	
20545/22750 (epoch 45.154), train_loss = 0.61081484, grad/param norm = 2.2841e-01, time/batch = 19.9565s	
20546/22750 (epoch 45.156), train_loss = 0.60641258, grad/param norm = 2.2704e-01, time/batch = 20.6024s	
20547/22750 (epoch 45.158), train_loss = 0.59096895, grad/param norm = 2.0801e-01, time/batch = 29.4182s	
20548/22750 (epoch 45.160), train_loss = 0.68031390, grad/param norm = 2.6367e-01, time/batch = 20.9691s	
20549/22750 (epoch 45.163), train_loss = 0.80324237, grad/param norm = 2.5714e-01, time/batch = 16.3849s	
20550/22750 (epoch 45.165), train_loss = 0.73843972, grad/param norm = 2.4821e-01, time/batch = 16.9989s	
20551/22750 (epoch 45.167), train_loss = 0.64880484, grad/param norm = 2.5063e-01, time/batch = 17.2301s	
20552/22750 (epoch 45.169), train_loss = 0.67742414, grad/param norm = 2.5678e-01, time/batch = 18.0048s	
20553/22750 (epoch 45.171), train_loss = 0.58169928, grad/param norm = 2.0456e-01, time/batch = 18.5118s	
20554/22750 (epoch 45.174), train_loss = 0.57412831, grad/param norm = 2.4381e-01, time/batch = 20.0218s	
20555/22750 (epoch 45.176), train_loss = 0.58018867, grad/param norm = 2.2803e-01, time/batch = 19.5975s	
20556/22750 (epoch 45.178), train_loss = 0.65830010, grad/param norm = 2.2790e-01, time/batch = 17.7502s	
20557/22750 (epoch 45.180), train_loss = 0.80496999, grad/param norm = 5.2522e-01, time/batch = 18.7628s	
20558/22750 (epoch 45.182), train_loss = 0.73701981, grad/param norm = 3.0706e-01, time/batch = 18.1581s	
20559/22750 (epoch 45.185), train_loss = 0.77279413, grad/param norm = 2.6259e-01, time/batch = 18.9733s	
20560/22750 (epoch 45.187), train_loss = 0.60632922, grad/param norm = 2.1977e-01, time/batch = 17.1572s	
20561/22750 (epoch 45.189), train_loss = 0.59185068, grad/param norm = 2.6413e-01, time/batch = 18.2351s	
20562/22750 (epoch 45.191), train_loss = 0.64746136, grad/param norm = 2.0937e-01, time/batch = 19.5014s	
20563/22750 (epoch 45.193), train_loss = 0.72823134, grad/param norm = 2.0840e-01, time/batch = 17.8945s	
20564/22750 (epoch 45.196), train_loss = 0.66547858, grad/param norm = 2.3998e-01, time/batch = 19.4144s	
20565/22750 (epoch 45.198), train_loss = 0.49772948, grad/param norm = 2.0482e-01, time/batch = 17.8272s	
20566/22750 (epoch 45.200), train_loss = 0.68359515, grad/param norm = 2.7968e-01, time/batch = 17.7517s	
20567/22750 (epoch 45.202), train_loss = 0.73051786, grad/param norm = 2.8836e-01, time/batch = 19.0879s	
20568/22750 (epoch 45.204), train_loss = 0.71883103, grad/param norm = 2.4256e-01, time/batch = 19.2390s	
20569/22750 (epoch 45.207), train_loss = 0.72607276, grad/param norm = 2.3366e-01, time/batch = 16.6787s	
20570/22750 (epoch 45.209), train_loss = 0.66320882, grad/param norm = 2.2141e-01, time/batch = 19.2605s	
20571/22750 (epoch 45.211), train_loss = 0.58617361, grad/param norm = 2.3683e-01, time/batch = 18.5116s	
20572/22750 (epoch 45.213), train_loss = 0.52116374, grad/param norm = 2.2104e-01, time/batch = 18.1466s	
20573/22750 (epoch 45.215), train_loss = 0.51441123, grad/param norm = 1.9538e-01, time/batch = 20.3996s	
20574/22750 (epoch 45.218), train_loss = 0.61786805, grad/param norm = 2.5795e-01, time/batch = 19.3921s	
20575/22750 (epoch 45.220), train_loss = 0.59111821, grad/param norm = 3.1030e-01, time/batch = 18.2448s	
20576/22750 (epoch 45.222), train_loss = 0.56643302, grad/param norm = 2.2985e-01, time/batch = 17.8303s	
20577/22750 (epoch 45.224), train_loss = 0.58026062, grad/param norm = 1.8499e-01, time/batch = 17.9672s	
20578/22750 (epoch 45.226), train_loss = 0.66549165, grad/param norm = 2.4483e-01, time/batch = 19.4879s	
20579/22750 (epoch 45.229), train_loss = 0.68477806, grad/param norm = 2.3783e-01, time/batch = 18.7355s	
20580/22750 (epoch 45.231), train_loss = 0.61016209, grad/param norm = 2.9283e-01, time/batch = 20.1847s	
20581/22750 (epoch 45.233), train_loss = 0.56796050, grad/param norm = 2.5503e-01, time/batch = 19.9495s	
20582/22750 (epoch 45.235), train_loss = 0.52617479, grad/param norm = 2.1935e-01, time/batch = 19.2333s	
20583/22750 (epoch 45.237), train_loss = 0.59954242, grad/param norm = 2.1955e-01, time/batch = 19.5924s	
20584/22750 (epoch 45.240), train_loss = 0.67576468, grad/param norm = 2.0568e-01, time/batch = 18.4053s	
20585/22750 (epoch 45.242), train_loss = 0.79265344, grad/param norm = 3.0050e-01, time/batch = 18.8133s	
20586/22750 (epoch 45.244), train_loss = 0.78804793, grad/param norm = 2.5060e-01, time/batch = 19.4143s	
20587/22750 (epoch 45.246), train_loss = 0.81024530, grad/param norm = 2.5094e-01, time/batch = 18.2527s	
20588/22750 (epoch 45.248), train_loss = 0.68004542, grad/param norm = 2.0649e-01, time/batch = 19.3359s	
20589/22750 (epoch 45.251), train_loss = 0.72888035, grad/param norm = 2.1416e-01, time/batch = 19.7750s	
20590/22750 (epoch 45.253), train_loss = 0.73689031, grad/param norm = 2.8985e-01, time/batch = 20.5818s	
20591/22750 (epoch 45.255), train_loss = 0.72787860, grad/param norm = 2.8202e-01, time/batch = 17.4184s	
20592/22750 (epoch 45.257), train_loss = 0.63680205, grad/param norm = 2.4542e-01, time/batch = 18.7498s	
20593/22750 (epoch 45.259), train_loss = 0.74714683, grad/param norm = 2.5541e-01, time/batch = 18.7490s	
20594/22750 (epoch 45.262), train_loss = 0.72525566, grad/param norm = 2.6949e-01, time/batch = 17.9973s	
20595/22750 (epoch 45.264), train_loss = 0.53384316, grad/param norm = 2.3239e-01, time/batch = 20.1542s	
20596/22750 (epoch 45.266), train_loss = 0.65898489, grad/param norm = 2.5749e-01, time/batch = 18.9201s	
20597/22750 (epoch 45.268), train_loss = 0.82741497, grad/param norm = 2.5791e-01, time/batch = 17.5084s	
20598/22750 (epoch 45.270), train_loss = 0.61828554, grad/param norm = 2.2715e-01, time/batch = 20.3418s	
20599/22750 (epoch 45.273), train_loss = 0.96074059, grad/param norm = 3.4527e-01, time/batch = 20.1888s	
20600/22750 (epoch 45.275), train_loss = 0.81774133, grad/param norm = 2.3370e-01, time/batch = 19.2747s	
20601/22750 (epoch 45.277), train_loss = 0.70054400, grad/param norm = 3.0675e-01, time/batch = 19.5720s	
20602/22750 (epoch 45.279), train_loss = 0.58697945, grad/param norm = 2.2176e-01, time/batch = 18.7579s	
20603/22750 (epoch 45.281), train_loss = 0.79458305, grad/param norm = 2.3033e-01, time/batch = 17.8513s	
20604/22750 (epoch 45.284), train_loss = 0.71204916, grad/param norm = 2.2516e-01, time/batch = 17.7470s	
20605/22750 (epoch 45.286), train_loss = 0.75128039, grad/param norm = 2.4634e-01, time/batch = 18.2478s	
20606/22750 (epoch 45.288), train_loss = 0.83752979, grad/param norm = 3.1263e-01, time/batch = 18.5909s	
20607/22750 (epoch 45.290), train_loss = 0.74936190, grad/param norm = 2.5339e-01, time/batch = 19.1008s	
20608/22750 (epoch 45.292), train_loss = 0.75694395, grad/param norm = 3.0100e-01, time/batch = 20.1716s	
20609/22750 (epoch 45.295), train_loss = 0.72920704, grad/param norm = 2.3485e-01, time/batch = 19.4469s	
20610/22750 (epoch 45.297), train_loss = 0.72231780, grad/param norm = 2.3168e-01, time/batch = 16.5219s	
20611/22750 (epoch 45.299), train_loss = 0.75834448, grad/param norm = 2.5747e-01, time/batch = 19.4229s	
20612/22750 (epoch 45.301), train_loss = 0.66320799, grad/param norm = 2.3647e-01, time/batch = 16.7617s	
20613/22750 (epoch 45.303), train_loss = 0.72783221, grad/param norm = 2.3271e-01, time/batch = 17.0164s	
20614/22750 (epoch 45.305), train_loss = 0.82089733, grad/param norm = 2.2981e-01, time/batch = 18.3048s	
20615/22750 (epoch 45.308), train_loss = 0.77142561, grad/param norm = 2.5240e-01, time/batch = 16.0090s	
20616/22750 (epoch 45.310), train_loss = 0.63346718, grad/param norm = 2.4389e-01, time/batch = 17.0789s	
20617/22750 (epoch 45.312), train_loss = 0.70855176, grad/param norm = 2.5352e-01, time/batch = 17.5171s	
20618/22750 (epoch 45.314), train_loss = 0.73038894, grad/param norm = 2.6140e-01, time/batch = 19.9947s	
20619/22750 (epoch 45.316), train_loss = 0.68277313, grad/param norm = 2.4714e-01, time/batch = 18.2684s	
20620/22750 (epoch 45.319), train_loss = 0.73490057, grad/param norm = 2.6786e-01, time/batch = 17.3422s	
20621/22750 (epoch 45.321), train_loss = 0.66293843, grad/param norm = 2.7168e-01, time/batch = 20.4078s	
20622/22750 (epoch 45.323), train_loss = 0.73673838, grad/param norm = 2.5074e-01, time/batch = 18.6678s	
20623/22750 (epoch 45.325), train_loss = 0.61386112, grad/param norm = 2.1038e-01, time/batch = 18.4216s	
20624/22750 (epoch 45.327), train_loss = 0.65875321, grad/param norm = 3.0008e-01, time/batch = 18.7367s	
20625/22750 (epoch 45.330), train_loss = 0.80952121, grad/param norm = 2.4830e-01, time/batch = 19.5669s	
20626/22750 (epoch 45.332), train_loss = 0.89101806, grad/param norm = 2.4177e-01, time/batch = 19.0697s	
20627/22750 (epoch 45.334), train_loss = 0.57339664, grad/param norm = 1.9786e-01, time/batch = 19.1060s	
20628/22750 (epoch 45.336), train_loss = 0.76805777, grad/param norm = 2.0438e-01, time/batch = 19.5419s	
20629/22750 (epoch 45.338), train_loss = 0.69601104, grad/param norm = 2.5804e-01, time/batch = 17.6875s	
20630/22750 (epoch 45.341), train_loss = 0.70098040, grad/param norm = 2.3816e-01, time/batch = 17.8503s	
20631/22750 (epoch 45.343), train_loss = 0.60465594, grad/param norm = 2.2314e-01, time/batch = 18.5110s	
20632/22750 (epoch 45.345), train_loss = 0.74720306, grad/param norm = 3.0038e-01, time/batch = 18.7621s	
20633/22750 (epoch 45.347), train_loss = 0.77394436, grad/param norm = 2.3162e-01, time/batch = 17.6736s	
20634/22750 (epoch 45.349), train_loss = 0.57959309, grad/param norm = 2.7106e-01, time/batch = 20.0684s	
20635/22750 (epoch 45.352), train_loss = 0.82609722, grad/param norm = 2.8595e-01, time/batch = 20.0831s	
20636/22750 (epoch 45.354), train_loss = 0.79565005, grad/param norm = 2.5015e-01, time/batch = 18.4274s	
20637/22750 (epoch 45.356), train_loss = 0.76476671, grad/param norm = 2.4013e-01, time/batch = 20.8267s	
20638/22750 (epoch 45.358), train_loss = 0.67302395, grad/param norm = 2.3668e-01, time/batch = 20.3432s	
20639/22750 (epoch 45.360), train_loss = 0.84255216, grad/param norm = 2.5101e-01, time/batch = 18.0135s	
20640/22750 (epoch 45.363), train_loss = 0.65568950, grad/param norm = 2.3531e-01, time/batch = 19.8058s	
20641/22750 (epoch 45.365), train_loss = 0.57796394, grad/param norm = 2.4783e-01, time/batch = 18.1622s	
20642/22750 (epoch 45.367), train_loss = 0.65268613, grad/param norm = 2.6548e-01, time/batch = 16.6426s	
20643/22750 (epoch 45.369), train_loss = 0.71862672, grad/param norm = 2.5239e-01, time/batch = 20.3153s	
20644/22750 (epoch 45.371), train_loss = 0.72735435, grad/param norm = 2.7457e-01, time/batch = 16.7416s	
20645/22750 (epoch 45.374), train_loss = 0.61993957, grad/param norm = 2.0712e-01, time/batch = 18.6792s	
20646/22750 (epoch 45.376), train_loss = 0.71307851, grad/param norm = 2.7732e-01, time/batch = 20.2821s	
20647/22750 (epoch 45.378), train_loss = 0.70726815, grad/param norm = 2.0590e-01, time/batch = 20.4295s	
20648/22750 (epoch 45.380), train_loss = 0.77915420, grad/param norm = 2.7230e-01, time/batch = 18.2757s	
20649/22750 (epoch 45.382), train_loss = 0.66887480, grad/param norm = 2.2854e-01, time/batch = 19.0940s	
20650/22750 (epoch 45.385), train_loss = 0.76478389, grad/param norm = 2.7438e-01, time/batch = 18.7630s	
20651/22750 (epoch 45.387), train_loss = 0.72060775, grad/param norm = 2.2977e-01, time/batch = 18.0074s	
20652/22750 (epoch 45.389), train_loss = 0.59321826, grad/param norm = 2.2921e-01, time/batch = 18.5023s	
20653/22750 (epoch 45.391), train_loss = 0.44927989, grad/param norm = 1.8926e-01, time/batch = 18.6566s	
20654/22750 (epoch 45.393), train_loss = 0.58290528, grad/param norm = 2.1659e-01, time/batch = 19.6734s	
20655/22750 (epoch 45.396), train_loss = 0.72343786, grad/param norm = 2.2612e-01, time/batch = 18.7619s	
20656/22750 (epoch 45.398), train_loss = 0.66669093, grad/param norm = 2.3119e-01, time/batch = 19.8587s	
20657/22750 (epoch 45.400), train_loss = 0.72711158, grad/param norm = 2.5961e-01, time/batch = 20.5050s	
20658/22750 (epoch 45.402), train_loss = 0.70007933, grad/param norm = 2.2406e-01, time/batch = 18.0022s	
20659/22750 (epoch 45.404), train_loss = 0.78732419, grad/param norm = 2.5365e-01, time/batch = 19.1691s	
20660/22750 (epoch 45.407), train_loss = 0.78662889, grad/param norm = 2.6001e-01, time/batch = 18.8450s	
20661/22750 (epoch 45.409), train_loss = 0.65220749, grad/param norm = 2.2795e-01, time/batch = 16.9034s	
20662/22750 (epoch 45.411), train_loss = 0.64843638, grad/param norm = 2.2594e-01, time/batch = 16.8924s	
20663/22750 (epoch 45.413), train_loss = 0.50286547, grad/param norm = 2.3227e-01, time/batch = 17.3173s	
20664/22750 (epoch 45.415), train_loss = 0.58322994, grad/param norm = 2.3301e-01, time/batch = 18.1970s	
20665/22750 (epoch 45.418), train_loss = 0.67072565, grad/param norm = 2.8678e-01, time/batch = 15.7049s	
20666/22750 (epoch 45.420), train_loss = 0.74099206, grad/param norm = 2.5264e-01, time/batch = 16.8564s	
20667/22750 (epoch 45.422), train_loss = 0.87168715, grad/param norm = 3.0069e-01, time/batch = 19.5900s	
20668/22750 (epoch 45.424), train_loss = 0.89278747, grad/param norm = 2.9832e-01, time/batch = 17.8286s	
20669/22750 (epoch 45.426), train_loss = 0.86591527, grad/param norm = 2.4118e-01, time/batch = 19.4237s	
20670/22750 (epoch 45.429), train_loss = 0.64456978, grad/param norm = 2.7464e-01, time/batch = 18.5038s	
20671/22750 (epoch 45.431), train_loss = 0.58928899, grad/param norm = 2.3041e-01, time/batch = 18.0954s	
20672/22750 (epoch 45.433), train_loss = 0.66038108, grad/param norm = 2.4361e-01, time/batch = 18.6566s	
20673/22750 (epoch 45.435), train_loss = 0.51589342, grad/param norm = 1.9759e-01, time/batch = 18.7728s	
20674/22750 (epoch 45.437), train_loss = 0.45885730, grad/param norm = 1.9577e-01, time/batch = 18.7784s	
20675/22750 (epoch 45.440), train_loss = 0.66303959, grad/param norm = 2.4571e-01, time/batch = 16.2134s	
20676/22750 (epoch 45.442), train_loss = 0.69243982, grad/param norm = 2.4781e-01, time/batch = 18.9543s	
20677/22750 (epoch 45.444), train_loss = 0.64692743, grad/param norm = 2.4036e-01, time/batch = 17.8570s	
20678/22750 (epoch 45.446), train_loss = 0.65501171, grad/param norm = 2.3446e-01, time/batch = 15.5891s	
20679/22750 (epoch 45.448), train_loss = 0.87362940, grad/param norm = 2.8473e-01, time/batch = 18.9150s	
20680/22750 (epoch 45.451), train_loss = 0.83175754, grad/param norm = 2.3310e-01, time/batch = 17.4241s	
20681/22750 (epoch 45.453), train_loss = 0.71157227, grad/param norm = 2.5775e-01, time/batch = 18.8319s	
20682/22750 (epoch 45.455), train_loss = 0.82800549, grad/param norm = 2.4445e-01, time/batch = 18.4182s	
20683/22750 (epoch 45.457), train_loss = 0.73258515, grad/param norm = 3.7471e-01, time/batch = 19.4414s	
20684/22750 (epoch 45.459), train_loss = 0.76864396, grad/param norm = 2.3439e-01, time/batch = 18.3702s	
20685/22750 (epoch 45.462), train_loss = 0.68964189, grad/param norm = 2.1601e-01, time/batch = 19.5303s	
20686/22750 (epoch 45.464), train_loss = 0.59773487, grad/param norm = 2.5308e-01, time/batch = 16.5581s	
20687/22750 (epoch 45.466), train_loss = 0.76420669, grad/param norm = 2.9590e-01, time/batch = 18.0895s	
20688/22750 (epoch 45.468), train_loss = 0.72848626, grad/param norm = 2.6261e-01, time/batch = 19.5730s	
20689/22750 (epoch 45.470), train_loss = 0.79496862, grad/param norm = 2.4117e-01, time/batch = 18.5826s	
20690/22750 (epoch 45.473), train_loss = 0.67319955, grad/param norm = 2.6116e-01, time/batch = 19.8213s	
20691/22750 (epoch 45.475), train_loss = 0.71646304, grad/param norm = 2.3343e-01, time/batch = 7.2134s	
20692/22750 (epoch 45.477), train_loss = 0.62370439, grad/param norm = 2.6761e-01, time/batch = 0.7267s	
20693/22750 (epoch 45.479), train_loss = 0.58202664, grad/param norm = 2.0641e-01, time/batch = 0.7007s	
20694/22750 (epoch 45.481), train_loss = 0.56995688, grad/param norm = 2.1474e-01, time/batch = 0.7086s	
20695/22750 (epoch 45.484), train_loss = 0.48018457, grad/param norm = 2.2962e-01, time/batch = 0.6953s	
20696/22750 (epoch 45.486), train_loss = 0.56233856, grad/param norm = 2.0198e-01, time/batch = 0.6993s	
20697/22750 (epoch 45.488), train_loss = 0.52766599, grad/param norm = 2.2687e-01, time/batch = 0.7010s	
20698/22750 (epoch 45.490), train_loss = 0.66159096, grad/param norm = 2.4991e-01, time/batch = 0.6976s	
20699/22750 (epoch 45.492), train_loss = 0.75772317, grad/param norm = 2.4661e-01, time/batch = 0.7020s	
20700/22750 (epoch 45.495), train_loss = 0.64525024, grad/param norm = 2.6742e-01, time/batch = 0.7037s	
20701/22750 (epoch 45.497), train_loss = 0.68221588, grad/param norm = 2.8540e-01, time/batch = 0.7033s	
20702/22750 (epoch 45.499), train_loss = 0.61400208, grad/param norm = 2.3203e-01, time/batch = 0.7031s	
20703/22750 (epoch 45.501), train_loss = 0.64496374, grad/param norm = 2.6621e-01, time/batch = 0.7003s	
20704/22750 (epoch 45.503), train_loss = 0.65518762, grad/param norm = 2.2546e-01, time/batch = 0.6957s	
20705/22750 (epoch 45.505), train_loss = 0.58837339, grad/param norm = 2.5458e-01, time/batch = 0.8369s	
20706/22750 (epoch 45.508), train_loss = 0.58375845, grad/param norm = 2.4529e-01, time/batch = 1.0123s	
20707/22750 (epoch 45.510), train_loss = 0.57073603, grad/param norm = 2.1699e-01, time/batch = 1.0203s	
20708/22750 (epoch 45.512), train_loss = 0.62229190, grad/param norm = 2.3023e-01, time/batch = 1.0189s	
20709/22750 (epoch 45.514), train_loss = 0.63873573, grad/param norm = 2.6212e-01, time/batch = 1.0223s	
20710/22750 (epoch 45.516), train_loss = 0.61750495, grad/param norm = 2.3113e-01, time/batch = 1.4931s	
20711/22750 (epoch 45.519), train_loss = 0.75631204, grad/param norm = 2.3860e-01, time/batch = 1.9110s	
20712/22750 (epoch 45.521), train_loss = 0.67393777, grad/param norm = 2.3854e-01, time/batch = 1.9154s	
20713/22750 (epoch 45.523), train_loss = 0.58413497, grad/param norm = 2.4280e-01, time/batch = 16.6844s	
20714/22750 (epoch 45.525), train_loss = 0.76098573, grad/param norm = 2.8115e-01, time/batch = 16.1790s	
20715/22750 (epoch 45.527), train_loss = 0.69497769, grad/param norm = 2.2703e-01, time/batch = 16.7059s	
20716/22750 (epoch 45.530), train_loss = 0.60965166, grad/param norm = 2.1826e-01, time/batch = 17.5930s	
20717/22750 (epoch 45.532), train_loss = 0.55571629, grad/param norm = 2.2990e-01, time/batch = 17.4035s	
20718/22750 (epoch 45.534), train_loss = 0.72461587, grad/param norm = 2.4070e-01, time/batch = 17.9915s	
20719/22750 (epoch 45.536), train_loss = 0.71417128, grad/param norm = 2.2288e-01, time/batch = 18.5094s	
20720/22750 (epoch 45.538), train_loss = 0.69794577, grad/param norm = 2.3030e-01, time/batch = 18.5817s	
20721/22750 (epoch 45.541), train_loss = 0.60085871, grad/param norm = 2.5141e-01, time/batch = 16.1146s	
20722/22750 (epoch 45.543), train_loss = 0.58924172, grad/param norm = 2.1300e-01, time/batch = 17.4966s	
20723/22750 (epoch 45.545), train_loss = 0.73664065, grad/param norm = 2.5067e-01, time/batch = 19.0855s	
20724/22750 (epoch 45.547), train_loss = 0.64468132, grad/param norm = 2.0718e-01, time/batch = 19.2006s	
20725/22750 (epoch 45.549), train_loss = 0.66314673, grad/param norm = 2.1953e-01, time/batch = 18.1821s	
20726/22750 (epoch 45.552), train_loss = 0.70459537, grad/param norm = 2.2307e-01, time/batch = 17.2486s	
20727/22750 (epoch 45.554), train_loss = 0.70204958, grad/param norm = 2.5566e-01, time/batch = 17.9867s	
20728/22750 (epoch 45.556), train_loss = 0.71466203, grad/param norm = 2.2629e-01, time/batch = 17.7412s	
20729/22750 (epoch 45.558), train_loss = 0.65418935, grad/param norm = 2.4467e-01, time/batch = 20.0624s	
20730/22750 (epoch 45.560), train_loss = 0.64536979, grad/param norm = 2.3012e-01, time/batch = 17.8466s	
20731/22750 (epoch 45.563), train_loss = 0.74537614, grad/param norm = 2.9179e-01, time/batch = 18.4950s	
20732/22750 (epoch 45.565), train_loss = 0.73724521, grad/param norm = 2.6636e-01, time/batch = 20.3544s	
20733/22750 (epoch 45.567), train_loss = 0.70102958, grad/param norm = 2.2018e-01, time/batch = 18.9484s	
20734/22750 (epoch 45.569), train_loss = 0.69359630, grad/param norm = 2.5279e-01, time/batch = 18.7003s	
20735/22750 (epoch 45.571), train_loss = 0.66275892, grad/param norm = 2.4492e-01, time/batch = 19.3291s	
20736/22750 (epoch 45.574), train_loss = 0.68216466, grad/param norm = 2.5115e-01, time/batch = 17.2619s	
20737/22750 (epoch 45.576), train_loss = 0.66057484, grad/param norm = 1.9083e-01, time/batch = 18.1675s	
20738/22750 (epoch 45.578), train_loss = 0.57277603, grad/param norm = 2.2015e-01, time/batch = 16.4251s	
20739/22750 (epoch 45.580), train_loss = 0.71463518, grad/param norm = 2.5208e-01, time/batch = 17.6565s	
20740/22750 (epoch 45.582), train_loss = 0.62085591, grad/param norm = 2.0467e-01, time/batch = 17.6657s	
20741/22750 (epoch 45.585), train_loss = 0.58261634, grad/param norm = 2.4998e-01, time/batch = 17.2446s	
20742/22750 (epoch 45.587), train_loss = 0.60472598, grad/param norm = 2.1160e-01, time/batch = 20.7542s	
20743/22750 (epoch 45.589), train_loss = 0.49699515, grad/param norm = 1.6586e-01, time/batch = 20.2802s	
20744/22750 (epoch 45.591), train_loss = 0.67212023, grad/param norm = 2.0810e-01, time/batch = 16.9986s	
20745/22750 (epoch 45.593), train_loss = 0.78314342, grad/param norm = 2.8561e-01, time/batch = 19.6436s	
20746/22750 (epoch 45.596), train_loss = 0.73406160, grad/param norm = 2.3025e-01, time/batch = 18.0993s	
20747/22750 (epoch 45.598), train_loss = 0.73940900, grad/param norm = 2.7226e-01, time/batch = 18.0121s	
20748/22750 (epoch 45.600), train_loss = 0.83936015, grad/param norm = 2.9189e-01, time/batch = 17.5019s	
20749/22750 (epoch 45.602), train_loss = 0.61043610, grad/param norm = 2.0106e-01, time/batch = 19.9924s	
20750/22750 (epoch 45.604), train_loss = 0.65329686, grad/param norm = 2.4174e-01, time/batch = 19.7751s	
20751/22750 (epoch 45.607), train_loss = 0.60016814, grad/param norm = 2.1156e-01, time/batch = 18.6092s	
20752/22750 (epoch 45.609), train_loss = 0.57152398, grad/param norm = 2.3422e-01, time/batch = 20.8552s	
20753/22750 (epoch 45.611), train_loss = 0.64220318, grad/param norm = 2.1893e-01, time/batch = 19.0013s	
20754/22750 (epoch 45.613), train_loss = 0.63001988, grad/param norm = 2.7446e-01, time/batch = 18.0142s	
20755/22750 (epoch 45.615), train_loss = 0.63560336, grad/param norm = 2.7857e-01, time/batch = 18.4058s	
20756/22750 (epoch 45.618), train_loss = 0.66531290, grad/param norm = 2.1124e-01, time/batch = 19.8273s	
20757/22750 (epoch 45.620), train_loss = 0.64788698, grad/param norm = 2.5571e-01, time/batch = 16.6607s	
20758/22750 (epoch 45.622), train_loss = 0.57348580, grad/param norm = 1.9822e-01, time/batch = 20.8175s	
20759/22750 (epoch 45.624), train_loss = 0.63410143, grad/param norm = 2.6748e-01, time/batch = 20.9212s	
20760/22750 (epoch 45.626), train_loss = 0.54474704, grad/param norm = 1.9110e-01, time/batch = 33.8264s	
20761/22750 (epoch 45.629), train_loss = 0.62055489, grad/param norm = 2.3295e-01, time/batch = 18.1777s	
20762/22750 (epoch 45.631), train_loss = 0.64690779, grad/param norm = 2.1423e-01, time/batch = 18.1630s	
20763/22750 (epoch 45.633), train_loss = 0.57591265, grad/param norm = 2.7233e-01, time/batch = 18.6891s	
20764/22750 (epoch 45.635), train_loss = 0.67665797, grad/param norm = 2.4058e-01, time/batch = 17.9502s	
20765/22750 (epoch 45.637), train_loss = 0.70928342, grad/param norm = 3.0305e-01, time/batch = 15.7410s	
20766/22750 (epoch 45.640), train_loss = 0.71581261, grad/param norm = 2.4329e-01, time/batch = 15.9340s	
20767/22750 (epoch 45.642), train_loss = 0.74678065, grad/param norm = 2.3209e-01, time/batch = 17.1039s	
20768/22750 (epoch 45.644), train_loss = 0.66823955, grad/param norm = 2.5264e-01, time/batch = 17.1152s	
20769/22750 (epoch 45.646), train_loss = 0.72926183, grad/param norm = 2.8482e-01, time/batch = 18.0884s	
20770/22750 (epoch 45.648), train_loss = 0.71512786, grad/param norm = 2.2077e-01, time/batch = 18.5878s	
20771/22750 (epoch 45.651), train_loss = 0.71112554, grad/param norm = 2.3715e-01, time/batch = 17.5083s	
20772/22750 (epoch 45.653), train_loss = 0.74129723, grad/param norm = 2.0194e-01, time/batch = 17.1780s	
20773/22750 (epoch 45.655), train_loss = 0.69757938, grad/param norm = 2.0298e-01, time/batch = 17.4230s	
20774/22750 (epoch 45.657), train_loss = 0.81200260, grad/param norm = 2.6299e-01, time/batch = 20.1540s	
20775/22750 (epoch 45.659), train_loss = 0.85948937, grad/param norm = 2.6817e-01, time/batch = 19.1647s	
20776/22750 (epoch 45.662), train_loss = 0.83464032, grad/param norm = 3.5069e-01, time/batch = 18.3440s	
20777/22750 (epoch 45.664), train_loss = 0.72125581, grad/param norm = 2.7233e-01, time/batch = 19.4547s	
20778/22750 (epoch 45.666), train_loss = 0.61101168, grad/param norm = 2.7897e-01, time/batch = 19.6970s	
20779/22750 (epoch 45.668), train_loss = 0.66398584, grad/param norm = 2.4208e-01, time/batch = 17.0194s	
20780/22750 (epoch 45.670), train_loss = 0.64171583, grad/param norm = 2.6337e-01, time/batch = 17.5780s	
20781/22750 (epoch 45.673), train_loss = 0.84958187, grad/param norm = 2.7346e-01, time/batch = 19.4103s	
20782/22750 (epoch 45.675), train_loss = 0.92633000, grad/param norm = 2.8169e-01, time/batch = 18.4119s	
20783/22750 (epoch 45.677), train_loss = 0.80384827, grad/param norm = 2.6996e-01, time/batch = 18.5859s	
20784/22750 (epoch 45.679), train_loss = 0.79574990, grad/param norm = 2.8871e-01, time/batch = 19.5809s	
20785/22750 (epoch 45.681), train_loss = 0.78935879, grad/param norm = 2.4251e-01, time/batch = 18.5274s	
20786/22750 (epoch 45.684), train_loss = 0.83521173, grad/param norm = 2.5272e-01, time/batch = 19.2428s	
20787/22750 (epoch 45.686), train_loss = 0.85913429, grad/param norm = 2.8990e-01, time/batch = 19.2575s	
20788/22750 (epoch 45.688), train_loss = 0.80224558, grad/param norm = 3.0139e-01, time/batch = 17.9976s	
20789/22750 (epoch 45.690), train_loss = 0.80739130, grad/param norm = 3.2343e-01, time/batch = 16.8378s	
20790/22750 (epoch 45.692), train_loss = 0.81718246, grad/param norm = 2.8376e-01, time/batch = 17.0060s	
20791/22750 (epoch 45.695), train_loss = 0.72726863, grad/param norm = 2.3532e-01, time/batch = 17.8942s	
20792/22750 (epoch 45.697), train_loss = 0.73509136, grad/param norm = 2.1360e-01, time/batch = 17.0259s	
20793/22750 (epoch 45.699), train_loss = 0.65380511, grad/param norm = 2.3973e-01, time/batch = 18.2407s	
20794/22750 (epoch 45.701), train_loss = 0.59859760, grad/param norm = 2.4276e-01, time/batch = 17.3427s	
20795/22750 (epoch 45.703), train_loss = 0.67020369, grad/param norm = 2.6114e-01, time/batch = 19.0135s	
20796/22750 (epoch 45.705), train_loss = 0.63323139, grad/param norm = 2.2316e-01, time/batch = 18.9423s	
20797/22750 (epoch 45.708), train_loss = 0.68504028, grad/param norm = 2.5706e-01, time/batch = 19.9091s	
20798/22750 (epoch 45.710), train_loss = 0.62570169, grad/param norm = 3.0145e-01, time/batch = 18.1728s	
20799/22750 (epoch 45.712), train_loss = 0.52849860, grad/param norm = 2.1534e-01, time/batch = 18.3458s	
20800/22750 (epoch 45.714), train_loss = 0.59534973, grad/param norm = 2.1582e-01, time/batch = 18.9929s	
20801/22750 (epoch 45.716), train_loss = 0.59743292, grad/param norm = 2.4223e-01, time/batch = 18.0055s	
20802/22750 (epoch 45.719), train_loss = 0.66181980, grad/param norm = 2.5344e-01, time/batch = 18.1841s	
20803/22750 (epoch 45.721), train_loss = 0.79394424, grad/param norm = 2.5400e-01, time/batch = 18.5748s	
20804/22750 (epoch 45.723), train_loss = 0.76800765, grad/param norm = 3.0344e-01, time/batch = 19.2717s	
20805/22750 (epoch 45.725), train_loss = 0.65231882, grad/param norm = 2.5088e-01, time/batch = 18.7606s	
20806/22750 (epoch 45.727), train_loss = 0.68725715, grad/param norm = 2.3723e-01, time/batch = 18.6713s	
20807/22750 (epoch 45.730), train_loss = 0.66511852, grad/param norm = 2.2676e-01, time/batch = 16.2687s	
20808/22750 (epoch 45.732), train_loss = 0.63336664, grad/param norm = 2.1974e-01, time/batch = 17.0809s	
20809/22750 (epoch 45.734), train_loss = 0.57642844, grad/param norm = 2.0242e-01, time/batch = 18.0151s	
20810/22750 (epoch 45.736), train_loss = 0.66491781, grad/param norm = 2.7467e-01, time/batch = 18.9965s	
20811/22750 (epoch 45.738), train_loss = 0.71710607, grad/param norm = 2.5870e-01, time/batch = 18.3328s	
20812/22750 (epoch 45.741), train_loss = 0.80656354, grad/param norm = 2.3290e-01, time/batch = 18.4569s	
20813/22750 (epoch 45.743), train_loss = 0.70386916, grad/param norm = 2.5452e-01, time/batch = 18.7645s	
20814/22750 (epoch 45.745), train_loss = 0.59514056, grad/param norm = 2.1511e-01, time/batch = 19.6146s	
20815/22750 (epoch 45.747), train_loss = 0.70583088, grad/param norm = 2.3081e-01, time/batch = 18.8350s	
20816/22750 (epoch 45.749), train_loss = 0.78917295, grad/param norm = 2.5599e-01, time/batch = 20.2448s	
20817/22750 (epoch 45.752), train_loss = 0.70912878, grad/param norm = 2.4731e-01, time/batch = 18.2624s	
20818/22750 (epoch 45.754), train_loss = 0.68867608, grad/param norm = 2.3491e-01, time/batch = 19.3197s	
20819/22750 (epoch 45.756), train_loss = 0.64152501, grad/param norm = 2.4787e-01, time/batch = 18.5827s	
20820/22750 (epoch 45.758), train_loss = 0.62248587, grad/param norm = 2.1663e-01, time/batch = 19.1662s	
20821/22750 (epoch 45.760), train_loss = 0.61315217, grad/param norm = 2.4038e-01, time/batch = 17.8683s	
20822/22750 (epoch 45.763), train_loss = 0.65625268, grad/param norm = 2.3630e-01, time/batch = 20.6940s	
20823/22750 (epoch 45.765), train_loss = 0.66378498, grad/param norm = 2.2360e-01, time/batch = 20.6178s	
20824/22750 (epoch 45.767), train_loss = 0.71840752, grad/param norm = 2.0874e-01, time/batch = 16.5796s	
20825/22750 (epoch 45.769), train_loss = 0.80370819, grad/param norm = 3.1546e-01, time/batch = 20.2492s	
20826/22750 (epoch 45.771), train_loss = 0.81702383, grad/param norm = 3.0620e-01, time/batch = 19.3290s	
20827/22750 (epoch 45.774), train_loss = 0.64414151, grad/param norm = 2.5928e-01, time/batch = 16.7497s	
20828/22750 (epoch 45.776), train_loss = 0.76043349, grad/param norm = 2.8367e-01, time/batch = 19.8973s	
20829/22750 (epoch 45.778), train_loss = 0.79056239, grad/param norm = 2.5218e-01, time/batch = 18.9233s	
20830/22750 (epoch 45.780), train_loss = 0.71145992, grad/param norm = 2.3050e-01, time/batch = 18.9501s	
20831/22750 (epoch 45.782), train_loss = 0.81529122, grad/param norm = 2.5524e-01, time/batch = 19.1235s	
20832/22750 (epoch 45.785), train_loss = 0.67064196, grad/param norm = 2.5816e-01, time/batch = 20.2669s	
20833/22750 (epoch 45.787), train_loss = 0.57681611, grad/param norm = 2.3859e-01, time/batch = 19.2481s	
20834/22750 (epoch 45.789), train_loss = 0.65875727, grad/param norm = 2.0954e-01, time/batch = 17.3356s	
20835/22750 (epoch 45.791), train_loss = 0.63906518, grad/param norm = 2.4438e-01, time/batch = 18.2452s	
20836/22750 (epoch 45.793), train_loss = 0.65231775, grad/param norm = 4.7116e-01, time/batch = 18.2545s	
20837/22750 (epoch 45.796), train_loss = 0.59473592, grad/param norm = 2.3008e-01, time/batch = 17.7479s	
20838/22750 (epoch 45.798), train_loss = 0.64200691, grad/param norm = 2.0125e-01, time/batch = 18.5994s	
20839/22750 (epoch 45.800), train_loss = 0.65225488, grad/param norm = 2.7048e-01, time/batch = 19.7097s	
20840/22750 (epoch 45.802), train_loss = 0.58346650, grad/param norm = 2.6010e-01, time/batch = 17.7573s	
20841/22750 (epoch 45.804), train_loss = 0.75736866, grad/param norm = 2.3681e-01, time/batch = 17.4633s	
20842/22750 (epoch 45.807), train_loss = 0.74213690, grad/param norm = 2.6469e-01, time/batch = 19.1662s	
20843/22750 (epoch 45.809), train_loss = 0.81931972, grad/param norm = 2.7225e-01, time/batch = 17.8465s	
20844/22750 (epoch 45.811), train_loss = 0.70321358, grad/param norm = 2.5020e-01, time/batch = 20.1523s	
20845/22750 (epoch 45.813), train_loss = 0.72214641, grad/param norm = 2.3704e-01, time/batch = 18.4128s	
20846/22750 (epoch 45.815), train_loss = 0.79092878, grad/param norm = 2.3890e-01, time/batch = 18.2557s	
20847/22750 (epoch 45.818), train_loss = 0.76301763, grad/param norm = 2.4994e-01, time/batch = 18.9975s	
20848/22750 (epoch 45.820), train_loss = 0.87170126, grad/param norm = 2.3761e-01, time/batch = 20.4512s	
20849/22750 (epoch 45.822), train_loss = 0.73579781, grad/param norm = 2.4819e-01, time/batch = 19.1090s	
20850/22750 (epoch 45.824), train_loss = 0.62082994, grad/param norm = 2.2270e-01, time/batch = 18.0293s	
20851/22750 (epoch 45.826), train_loss = 0.68268934, grad/param norm = 2.8554e-01, time/batch = 17.9098s	
20852/22750 (epoch 45.829), train_loss = 0.76672917, grad/param norm = 2.6979e-01, time/batch = 17.5741s	
20853/22750 (epoch 45.831), train_loss = 0.77908330, grad/param norm = 2.7686e-01, time/batch = 17.8326s	
20854/22750 (epoch 45.833), train_loss = 0.71205711, grad/param norm = 2.5742e-01, time/batch = 20.8993s	
20855/22750 (epoch 45.835), train_loss = 0.62171737, grad/param norm = 2.7960e-01, time/batch = 16.3164s	
20856/22750 (epoch 45.837), train_loss = 0.66935309, grad/param norm = 2.2146e-01, time/batch = 15.9240s	
20857/22750 (epoch 45.840), train_loss = 0.61244067, grad/param norm = 2.2721e-01, time/batch = 16.2951s	
20858/22750 (epoch 45.842), train_loss = 0.63289012, grad/param norm = 2.7158e-01, time/batch = 18.7835s	
20859/22750 (epoch 45.844), train_loss = 0.72336698, grad/param norm = 2.7878e-01, time/batch = 18.6077s	
20860/22750 (epoch 45.846), train_loss = 0.74447384, grad/param norm = 2.2111e-01, time/batch = 17.5965s	
20861/22750 (epoch 45.848), train_loss = 0.65406926, grad/param norm = 2.0899e-01, time/batch = 18.4176s	
20862/22750 (epoch 45.851), train_loss = 0.63533621, grad/param norm = 2.3612e-01, time/batch = 17.5894s	
20863/22750 (epoch 45.853), train_loss = 0.80947048, grad/param norm = 2.6414e-01, time/batch = 16.3243s	
20864/22750 (epoch 45.855), train_loss = 0.66794869, grad/param norm = 1.9016e-01, time/batch = 19.8051s	
20865/22750 (epoch 45.857), train_loss = 0.73368295, grad/param norm = 2.3269e-01, time/batch = 17.5206s	
20866/22750 (epoch 45.859), train_loss = 0.70322939, grad/param norm = 2.2088e-01, time/batch = 18.3725s	
20867/22750 (epoch 45.862), train_loss = 0.83247605, grad/param norm = 2.8930e-01, time/batch = 20.0150s	
20868/22750 (epoch 45.864), train_loss = 0.70969930, grad/param norm = 2.5468e-01, time/batch = 18.1769s	
20869/22750 (epoch 45.866), train_loss = 0.74601592, grad/param norm = 2.5025e-01, time/batch = 18.6011s	
20870/22750 (epoch 45.868), train_loss = 0.61510138, grad/param norm = 2.1410e-01, time/batch = 17.5846s	
20871/22750 (epoch 45.870), train_loss = 0.61803925, grad/param norm = 2.4676e-01, time/batch = 19.4871s	
20872/22750 (epoch 45.873), train_loss = 0.70386768, grad/param norm = 2.4260e-01, time/batch = 17.9217s	
20873/22750 (epoch 45.875), train_loss = 0.72617167, grad/param norm = 2.2405e-01, time/batch = 17.8359s	
20874/22750 (epoch 45.877), train_loss = 0.65808851, grad/param norm = 2.5846e-01, time/batch = 17.6731s	
20875/22750 (epoch 45.879), train_loss = 0.78592527, grad/param norm = 2.7865e-01, time/batch = 20.1133s	
20876/22750 (epoch 45.881), train_loss = 0.71077320, grad/param norm = 2.4027e-01, time/batch = 17.9301s	
20877/22750 (epoch 45.884), train_loss = 0.62555915, grad/param norm = 2.1719e-01, time/batch = 20.1182s	
20878/22750 (epoch 45.886), train_loss = 0.71156725, grad/param norm = 2.3862e-01, time/batch = 18.9173s	
20879/22750 (epoch 45.888), train_loss = 0.74189504, grad/param norm = 2.2320e-01, time/batch = 17.3417s	
20880/22750 (epoch 45.890), train_loss = 0.75700834, grad/param norm = 2.4838e-01, time/batch = 19.6609s	
20881/22750 (epoch 45.892), train_loss = 0.91288195, grad/param norm = 2.8473e-01, time/batch = 18.5837s	
20882/22750 (epoch 45.895), train_loss = 0.66369089, grad/param norm = 2.5239e-01, time/batch = 17.4772s	
20883/22750 (epoch 45.897), train_loss = 0.80533316, grad/param norm = 2.3271e-01, time/batch = 17.1838s	
20884/22750 (epoch 45.899), train_loss = 0.71139592, grad/param norm = 2.4858e-01, time/batch = 17.0670s	
20885/22750 (epoch 45.901), train_loss = 0.79062051, grad/param norm = 2.7912e-01, time/batch = 19.1746s	
20886/22750 (epoch 45.903), train_loss = 0.68259338, grad/param norm = 2.2987e-01, time/batch = 20.8495s	
20887/22750 (epoch 45.905), train_loss = 0.74567898, grad/param norm = 2.7832e-01, time/batch = 18.9086s	
20888/22750 (epoch 45.908), train_loss = 0.59587104, grad/param norm = 2.5211e-01, time/batch = 18.9038s	
20889/22750 (epoch 45.910), train_loss = 0.53294466, grad/param norm = 2.1929e-01, time/batch = 18.9041s	
20890/22750 (epoch 45.912), train_loss = 0.70133306, grad/param norm = 2.4462e-01, time/batch = 19.2599s	
20891/22750 (epoch 45.914), train_loss = 0.72469860, grad/param norm = 2.6827e-01, time/batch = 19.4187s	
20892/22750 (epoch 45.916), train_loss = 0.56764087, grad/param norm = 2.2427e-01, time/batch = 19.4845s	
20893/22750 (epoch 45.919), train_loss = 0.71068238, grad/param norm = 2.6937e-01, time/batch = 18.5200s	
20894/22750 (epoch 45.921), train_loss = 0.54665393, grad/param norm = 2.0060e-01, time/batch = 19.2003s	
20895/22750 (epoch 45.923), train_loss = 0.64684442, grad/param norm = 2.0771e-01, time/batch = 18.8649s	
20896/22750 (epoch 45.925), train_loss = 0.70535885, grad/param norm = 2.3623e-01, time/batch = 20.0569s	
20897/22750 (epoch 45.927), train_loss = 0.55492875, grad/param norm = 2.1243e-01, time/batch = 20.1616s	
20898/22750 (epoch 45.930), train_loss = 0.52189127, grad/param norm = 2.0288e-01, time/batch = 18.7464s	
20899/22750 (epoch 45.932), train_loss = 0.66992972, grad/param norm = 2.4634e-01, time/batch = 19.7316s	
20900/22750 (epoch 45.934), train_loss = 0.58404237, grad/param norm = 1.9774e-01, time/batch = 19.0577s	
20901/22750 (epoch 45.936), train_loss = 0.75844558, grad/param norm = 2.7842e-01, time/batch = 18.8361s	
20902/22750 (epoch 45.938), train_loss = 0.75899664, grad/param norm = 2.3622e-01, time/batch = 19.6908s	
20903/22750 (epoch 45.941), train_loss = 0.79747734, grad/param norm = 2.6939e-01, time/batch = 20.1898s	
20904/22750 (epoch 45.943), train_loss = 0.69238442, grad/param norm = 2.2089e-01, time/batch = 17.9182s	
20905/22750 (epoch 45.945), train_loss = 0.72348845, grad/param norm = 3.8540e-01, time/batch = 18.7416s	
20906/22750 (epoch 45.947), train_loss = 0.64277915, grad/param norm = 2.6446e-01, time/batch = 17.1421s	
20907/22750 (epoch 45.949), train_loss = 0.65874884, grad/param norm = 2.5457e-01, time/batch = 15.9978s	
20908/22750 (epoch 45.952), train_loss = 0.67270458, grad/param norm = 2.7254e-01, time/batch = 16.2569s	
20909/22750 (epoch 45.954), train_loss = 0.58141579, grad/param norm = 2.3165e-01, time/batch = 16.9980s	
20910/22750 (epoch 45.956), train_loss = 0.74956021, grad/param norm = 2.4838e-01, time/batch = 18.9150s	
20911/22750 (epoch 45.958), train_loss = 0.61407974, grad/param norm = 2.0086e-01, time/batch = 17.9480s	
20912/22750 (epoch 45.960), train_loss = 0.60325105, grad/param norm = 2.2225e-01, time/batch = 16.4680s	
20913/22750 (epoch 45.963), train_loss = 0.69509736, grad/param norm = 2.0095e-01, time/batch = 19.1811s	
20914/22750 (epoch 45.965), train_loss = 0.77008081, grad/param norm = 2.3831e-01, time/batch = 17.8525s	
20915/22750 (epoch 45.967), train_loss = 0.73004328, grad/param norm = 2.3292e-01, time/batch = 18.0029s	
20916/22750 (epoch 45.969), train_loss = 0.65385402, grad/param norm = 2.5349e-01, time/batch = 18.0784s	
20917/22750 (epoch 45.971), train_loss = 0.63479264, grad/param norm = 2.1485e-01, time/batch = 18.0833s	
20918/22750 (epoch 45.974), train_loss = 0.62293582, grad/param norm = 2.0922e-01, time/batch = 16.7257s	
20919/22750 (epoch 45.976), train_loss = 0.66877362, grad/param norm = 2.5723e-01, time/batch = 17.4285s	
20920/22750 (epoch 45.978), train_loss = 0.61806337, grad/param norm = 2.2369e-01, time/batch = 16.6903s	
20921/22750 (epoch 45.980), train_loss = 0.81205147, grad/param norm = 2.5280e-01, time/batch = 16.9410s	
20922/22750 (epoch 45.982), train_loss = 0.63663359, grad/param norm = 1.9337e-01, time/batch = 19.6785s	
20923/22750 (epoch 45.985), train_loss = 0.80546843, grad/param norm = 2.5214e-01, time/batch = 18.0937s	
20924/22750 (epoch 45.987), train_loss = 0.55676281, grad/param norm = 2.1474e-01, time/batch = 16.6770s	
20925/22750 (epoch 45.989), train_loss = 0.61559005, grad/param norm = 2.6647e-01, time/batch = 15.9491s	
20926/22750 (epoch 45.991), train_loss = 0.73212645, grad/param norm = 2.6295e-01, time/batch = 15.6972s	
20927/22750 (epoch 45.993), train_loss = 0.67733028, grad/param norm = 2.5451e-01, time/batch = 17.0091s	
20928/22750 (epoch 45.996), train_loss = 0.59569283, grad/param norm = 2.3820e-01, time/batch = 17.5094s	
20929/22750 (epoch 45.998), train_loss = 0.76268503, grad/param norm = 2.4659e-01, time/batch = 17.5150s	
decayed learning rate by a factor 0.97 to 0.00064801366403768	
20930/22750 (epoch 46.000), train_loss = 0.65530702, grad/param norm = 2.2497e-01, time/batch = 19.5361s	
20931/22750 (epoch 46.002), train_loss = 0.83742432, grad/param norm = 2.3318e-01, time/batch = 18.1177s	
20932/22750 (epoch 46.004), train_loss = 0.65973680, grad/param norm = 2.2654e-01, time/batch = 19.0951s	
20933/22750 (epoch 46.007), train_loss = 0.67328760, grad/param norm = 2.5334e-01, time/batch = 18.7442s	
20934/22750 (epoch 46.009), train_loss = 0.80288785, grad/param norm = 2.7866e-01, time/batch = 16.5073s	
20935/22750 (epoch 46.011), train_loss = 0.86989704, grad/param norm = 3.2474e-01, time/batch = 16.4148s	
20936/22750 (epoch 46.013), train_loss = 0.77395049, grad/param norm = 2.6722e-01, time/batch = 17.6551s	
20937/22750 (epoch 46.015), train_loss = 0.69242866, grad/param norm = 2.6133e-01, time/batch = 17.0885s	
20938/22750 (epoch 46.018), train_loss = 0.82919837, grad/param norm = 2.8012e-01, time/batch = 16.6924s	
20939/22750 (epoch 46.020), train_loss = 0.80441881, grad/param norm = 2.5976e-01, time/batch = 17.4291s	
20940/22750 (epoch 46.022), train_loss = 0.69662355, grad/param norm = 2.3032e-01, time/batch = 16.8857s	
20941/22750 (epoch 46.024), train_loss = 0.71291822, grad/param norm = 2.8808e-01, time/batch = 18.2738s	
20942/22750 (epoch 46.026), train_loss = 0.72624166, grad/param norm = 2.6589e-01, time/batch = 17.6523s	
20943/22750 (epoch 46.029), train_loss = 0.57350483, grad/param norm = 2.5573e-01, time/batch = 18.8266s	
20944/22750 (epoch 46.031), train_loss = 0.92684788, grad/param norm = 2.9375e-01, time/batch = 17.9289s	
20945/22750 (epoch 46.033), train_loss = 0.72797451, grad/param norm = 2.5829e-01, time/batch = 15.8548s	
20946/22750 (epoch 46.035), train_loss = 0.73983153, grad/param norm = 2.4037e-01, time/batch = 16.8655s	
20947/22750 (epoch 46.037), train_loss = 0.76335399, grad/param norm = 2.5693e-01, time/batch = 19.4389s	
20948/22750 (epoch 46.040), train_loss = 0.70426563, grad/param norm = 2.0419e-01, time/batch = 16.9321s	
20949/22750 (epoch 46.042), train_loss = 0.71550245, grad/param norm = 2.1651e-01, time/batch = 18.9377s	
20950/22750 (epoch 46.044), train_loss = 0.69545892, grad/param norm = 2.3711e-01, time/batch = 18.9374s	
20951/22750 (epoch 46.046), train_loss = 0.78411896, grad/param norm = 3.0354e-01, time/batch = 19.5947s	
20952/22750 (epoch 46.048), train_loss = 0.73655343, grad/param norm = 2.2992e-01, time/batch = 18.5805s	
20953/22750 (epoch 46.051), train_loss = 0.72191081, grad/param norm = 2.3485e-01, time/batch = 16.5568s	
20954/22750 (epoch 46.053), train_loss = 0.69614583, grad/param norm = 2.1765e-01, time/batch = 19.7443s	
20955/22750 (epoch 46.055), train_loss = 0.62080636, grad/param norm = 2.2260e-01, time/batch = 32.3805s	
20956/22750 (epoch 46.057), train_loss = 0.81501138, grad/param norm = 2.9293e-01, time/batch = 17.1499s	
20957/22750 (epoch 46.059), train_loss = 0.52151977, grad/param norm = 2.0489e-01, time/batch = 15.6842s	
20958/22750 (epoch 46.062), train_loss = 0.59350797, grad/param norm = 2.2347e-01, time/batch = 16.8695s	
20959/22750 (epoch 46.064), train_loss = 0.81026168, grad/param norm = 2.5263e-01, time/batch = 17.4473s	
20960/22750 (epoch 46.066), train_loss = 0.61382068, grad/param norm = 2.8262e-01, time/batch = 20.3370s	
20961/22750 (epoch 46.068), train_loss = 0.62575208, grad/param norm = 2.0440e-01, time/batch = 17.1670s	
20962/22750 (epoch 46.070), train_loss = 0.53133331, grad/param norm = 1.8237e-01, time/batch = 18.7563s	
20963/22750 (epoch 46.073), train_loss = 0.63594525, grad/param norm = 2.2972e-01, time/batch = 16.6384s	
20964/22750 (epoch 46.075), train_loss = 0.69037790, grad/param norm = 2.2021e-01, time/batch = 16.5857s	
20965/22750 (epoch 46.077), train_loss = 0.51776295, grad/param norm = 2.2634e-01, time/batch = 16.8820s	
20966/22750 (epoch 46.079), train_loss = 0.69249553, grad/param norm = 2.6553e-01, time/batch = 16.9052s	
20967/22750 (epoch 46.081), train_loss = 0.65012835, grad/param norm = 2.1308e-01, time/batch = 16.7909s	
20968/22750 (epoch 46.084), train_loss = 0.64007325, grad/param norm = 2.1102e-01, time/batch = 16.7141s	
20969/22750 (epoch 46.086), train_loss = 0.67833251, grad/param norm = 2.4603e-01, time/batch = 17.1886s	
20970/22750 (epoch 46.088), train_loss = 0.66946823, grad/param norm = 2.2558e-01, time/batch = 16.8657s	
20971/22750 (epoch 46.090), train_loss = 0.66649396, grad/param norm = 2.2852e-01, time/batch = 17.0820s	
20972/22750 (epoch 46.092), train_loss = 0.74221825, grad/param norm = 2.4555e-01, time/batch = 15.8685s	
20973/22750 (epoch 46.095), train_loss = 0.63171323, grad/param norm = 2.2255e-01, time/batch = 17.8372s	
20974/22750 (epoch 46.097), train_loss = 0.69352663, grad/param norm = 2.3591e-01, time/batch = 17.1018s	
20975/22750 (epoch 46.099), train_loss = 0.61757825, grad/param norm = 2.1747e-01, time/batch = 16.0216s	
20976/22750 (epoch 46.101), train_loss = 0.57383204, grad/param norm = 2.0954e-01, time/batch = 18.5746s	
20977/22750 (epoch 46.103), train_loss = 0.71728395, grad/param norm = 2.5292e-01, time/batch = 21.0991s	
20978/22750 (epoch 46.105), train_loss = 0.77128161, grad/param norm = 2.5748e-01, time/batch = 16.8326s	
20979/22750 (epoch 46.108), train_loss = 0.72803380, grad/param norm = 2.6523e-01, time/batch = 18.4398s	
20980/22750 (epoch 46.110), train_loss = 0.76108673, grad/param norm = 2.3833e-01, time/batch = 18.5757s	
20981/22750 (epoch 46.112), train_loss = 0.58139169, grad/param norm = 1.9486e-01, time/batch = 17.9005s	
20982/22750 (epoch 46.114), train_loss = 0.50927559, grad/param norm = 2.0412e-01, time/batch = 18.7543s	
20983/22750 (epoch 46.116), train_loss = 0.70516017, grad/param norm = 2.1726e-01, time/batch = 16.7923s	
20984/22750 (epoch 46.119), train_loss = 0.64930613, grad/param norm = 2.1196e-01, time/batch = 16.7393s	
20985/22750 (epoch 46.121), train_loss = 0.66087557, grad/param norm = 2.3949e-01, time/batch = 17.4729s	
20986/22750 (epoch 46.123), train_loss = 0.59213753, grad/param norm = 2.7054e-01, time/batch = 18.0953s	
20987/22750 (epoch 46.125), train_loss = 0.77671172, grad/param norm = 2.3159e-01, time/batch = 17.2839s	
20988/22750 (epoch 46.127), train_loss = 0.63860184, grad/param norm = 2.2686e-01, time/batch = 17.3232s	
20989/22750 (epoch 46.130), train_loss = 0.66727713, grad/param norm = 2.1211e-01, time/batch = 19.6923s	
20990/22750 (epoch 46.132), train_loss = 0.63018381, grad/param norm = 2.1535e-01, time/batch = 18.1081s	
20991/22750 (epoch 46.134), train_loss = 0.65482682, grad/param norm = 2.2114e-01, time/batch = 17.2552s	
20992/22750 (epoch 46.136), train_loss = 0.55752803, grad/param norm = 2.3598e-01, time/batch = 18.5937s	
20993/22750 (epoch 46.138), train_loss = 0.74860528, grad/param norm = 2.3338e-01, time/batch = 18.0061s	
20994/22750 (epoch 46.141), train_loss = 0.66900804, grad/param norm = 2.4038e-01, time/batch = 15.9825s	
20995/22750 (epoch 46.143), train_loss = 0.62467663, grad/param norm = 1.9547e-01, time/batch = 16.2704s	
20996/22750 (epoch 46.145), train_loss = 0.76856365, grad/param norm = 2.2583e-01, time/batch = 16.5384s	
20997/22750 (epoch 46.147), train_loss = 0.83339390, grad/param norm = 2.7041e-01, time/batch = 16.6826s	
20998/22750 (epoch 46.149), train_loss = 0.69327147, grad/param norm = 2.6276e-01, time/batch = 17.7872s	
20999/22750 (epoch 46.152), train_loss = 0.69121702, grad/param norm = 2.3951e-01, time/batch = 15.7926s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_wakata_epoch46.15_1.8189.t7	
21000/22750 (epoch 46.154), train_loss = 0.60623677, grad/param norm = 2.3345e-01, time/batch = 17.1631s	
21001/22750 (epoch 46.156), train_loss = 1.46480427, grad/param norm = 3.7587e-01, time/batch = 17.3649s	
21002/22750 (epoch 46.158), train_loss = 0.62116895, grad/param norm = 2.8687e-01, time/batch = 17.3576s	
21003/22750 (epoch 46.160), train_loss = 0.67268748, grad/param norm = 2.1673e-01, time/batch = 18.6028s	
21004/22750 (epoch 46.163), train_loss = 0.79293616, grad/param norm = 2.5399e-01, time/batch = 18.5853s	
21005/22750 (epoch 46.165), train_loss = 0.73027886, grad/param norm = 2.4178e-01, time/batch = 18.4972s	
21006/22750 (epoch 46.167), train_loss = 0.63979020, grad/param norm = 2.2922e-01, time/batch = 18.0031s	
21007/22750 (epoch 46.169), train_loss = 0.65679768, grad/param norm = 2.7270e-01, time/batch = 15.9897s	
21008/22750 (epoch 46.171), train_loss = 0.58008433, grad/param norm = 2.0828e-01, time/batch = 16.7738s	
21009/22750 (epoch 46.174), train_loss = 0.56391087, grad/param norm = 2.2095e-01, time/batch = 17.3169s	
21010/22750 (epoch 46.176), train_loss = 0.58514337, grad/param norm = 2.3779e-01, time/batch = 17.0831s	
21011/22750 (epoch 46.178), train_loss = 0.64072364, grad/param norm = 2.3193e-01, time/batch = 19.3494s	
21012/22750 (epoch 46.180), train_loss = 0.76758252, grad/param norm = 2.7248e-01, time/batch = 19.5214s	
21013/22750 (epoch 46.182), train_loss = 0.70837442, grad/param norm = 2.5006e-01, time/batch = 17.5959s	
21014/22750 (epoch 46.185), train_loss = 0.76437358, grad/param norm = 2.4604e-01, time/batch = 16.7293s	
21015/22750 (epoch 46.187), train_loss = 0.60753209, grad/param norm = 2.2910e-01, time/batch = 17.2588s	
21016/22750 (epoch 46.189), train_loss = 0.58578086, grad/param norm = 2.1753e-01, time/batch = 17.1533s	
21017/22750 (epoch 46.191), train_loss = 0.63883779, grad/param norm = 2.1123e-01, time/batch = 17.4640s	
21018/22750 (epoch 46.193), train_loss = 0.71338635, grad/param norm = 2.0462e-01, time/batch = 17.1634s	
21019/22750 (epoch 46.196), train_loss = 0.64768710, grad/param norm = 2.1737e-01, time/batch = 16.9258s	
21020/22750 (epoch 46.198), train_loss = 0.48248104, grad/param norm = 2.2261e-01, time/batch = 16.7749s	
21021/22750 (epoch 46.200), train_loss = 0.67067922, grad/param norm = 2.1678e-01, time/batch = 16.8672s	
21022/22750 (epoch 46.202), train_loss = 0.73880506, grad/param norm = 2.8821e-01, time/batch = 17.1025s	
21023/22750 (epoch 46.204), train_loss = 0.69604881, grad/param norm = 2.2824e-01, time/batch = 16.9316s	
21024/22750 (epoch 46.207), train_loss = 0.70748964, grad/param norm = 2.1983e-01, time/batch = 17.0854s	
21025/22750 (epoch 46.209), train_loss = 0.63038086, grad/param norm = 2.1202e-01, time/batch = 16.9203s	
21026/22750 (epoch 46.211), train_loss = 0.59013986, grad/param norm = 2.5752e-01, time/batch = 16.9200s	
21027/22750 (epoch 46.213), train_loss = 0.50404200, grad/param norm = 2.0265e-01, time/batch = 17.2230s	
21028/22750 (epoch 46.215), train_loss = 0.52031713, grad/param norm = 2.3397e-01, time/batch = 17.1289s	
21029/22750 (epoch 46.218), train_loss = 0.59091776, grad/param norm = 2.6064e-01, time/batch = 17.3034s	
21030/22750 (epoch 46.220), train_loss = 0.57580861, grad/param norm = 2.3391e-01, time/batch = 16.9217s	
21031/22750 (epoch 46.222), train_loss = 0.55038765, grad/param norm = 2.0262e-01, time/batch = 17.0190s	
21032/22750 (epoch 46.224), train_loss = 0.55855004, grad/param norm = 2.0324e-01, time/batch = 17.0075s	
21033/22750 (epoch 46.226), train_loss = 0.64459350, grad/param norm = 2.1027e-01, time/batch = 16.9191s	
21034/22750 (epoch 46.229), train_loss = 0.67598435, grad/param norm = 2.3602e-01, time/batch = 17.3092s	
21035/22750 (epoch 46.231), train_loss = 0.59110258, grad/param norm = 2.4056e-01, time/batch = 17.0122s	
21036/22750 (epoch 46.233), train_loss = 0.54217921, grad/param norm = 2.4877e-01, time/batch = 17.2033s	
21037/22750 (epoch 46.235), train_loss = 0.53778758, grad/param norm = 2.2321e-01, time/batch = 16.9126s	
21038/22750 (epoch 46.237), train_loss = 0.59761529, grad/param norm = 2.9160e-01, time/batch = 16.8292s	
21039/22750 (epoch 46.240), train_loss = 0.68093526, grad/param norm = 2.0954e-01, time/batch = 16.8121s	
21040/22750 (epoch 46.242), train_loss = 0.77141698, grad/param norm = 2.2376e-01, time/batch = 16.8318s	
21041/22750 (epoch 46.244), train_loss = 0.78370300, grad/param norm = 2.7343e-01, time/batch = 16.8547s	
21042/22750 (epoch 46.246), train_loss = 0.79939188, grad/param norm = 2.7572e-01, time/batch = 16.6940s	
21043/22750 (epoch 46.248), train_loss = 0.69534156, grad/param norm = 2.2477e-01, time/batch = 16.5908s	
21044/22750 (epoch 46.251), train_loss = 0.72195197, grad/param norm = 2.3278e-01, time/batch = 16.6776s	
21045/22750 (epoch 46.253), train_loss = 0.72592513, grad/param norm = 2.9099e-01, time/batch = 16.8301s	
21046/22750 (epoch 46.255), train_loss = 0.71464660, grad/param norm = 2.4050e-01, time/batch = 17.2167s	
21047/22750 (epoch 46.257), train_loss = 0.61339905, grad/param norm = 2.4281e-01, time/batch = 17.0051s	
21048/22750 (epoch 46.259), train_loss = 0.73490947, grad/param norm = 2.9205e-01, time/batch = 17.4042s	
21049/22750 (epoch 46.262), train_loss = 0.69438105, grad/param norm = 2.3170e-01, time/batch = 17.1997s	
21050/22750 (epoch 46.264), train_loss = 0.53942501, grad/param norm = 2.5325e-01, time/batch = 17.0328s	
21051/22750 (epoch 46.266), train_loss = 0.66514397, grad/param norm = 2.8415e-01, time/batch = 17.4704s	
21052/22750 (epoch 46.268), train_loss = 0.80851040, grad/param norm = 2.5437e-01, time/batch = 17.3780s	
21053/22750 (epoch 46.270), train_loss = 0.63376618, grad/param norm = 2.7249e-01, time/batch = 17.2636s	
21054/22750 (epoch 46.273), train_loss = 0.93351930, grad/param norm = 2.9808e-01, time/batch = 17.4838s	
21055/22750 (epoch 46.275), train_loss = 0.81544799, grad/param norm = 2.4761e-01, time/batch = 17.6407s	
21056/22750 (epoch 46.277), train_loss = 0.68441845, grad/param norm = 2.8861e-01, time/batch = 17.5029s	
21057/22750 (epoch 46.279), train_loss = 0.57364359, grad/param norm = 2.1357e-01, time/batch = 17.4979s	
21058/22750 (epoch 46.281), train_loss = 0.80106869, grad/param norm = 2.4850e-01, time/batch = 17.5154s	
21059/22750 (epoch 46.284), train_loss = 0.71952025, grad/param norm = 2.2005e-01, time/batch = 17.4342s	
21060/22750 (epoch 46.286), train_loss = 0.74369669, grad/param norm = 2.7175e-01, time/batch = 17.2719s	
21061/22750 (epoch 46.288), train_loss = 0.81393360, grad/param norm = 2.7628e-01, time/batch = 17.3589s	
21062/22750 (epoch 46.290), train_loss = 0.73138977, grad/param norm = 2.3517e-01, time/batch = 17.4892s	
21063/22750 (epoch 46.292), train_loss = 0.74321400, grad/param norm = 3.0120e-01, time/batch = 17.4029s	
21064/22750 (epoch 46.295), train_loss = 0.72991346, grad/param norm = 2.3507e-01, time/batch = 17.3147s	
21065/22750 (epoch 46.297), train_loss = 0.72323586, grad/param norm = 2.7696e-01, time/batch = 17.4037s	
21066/22750 (epoch 46.299), train_loss = 0.76533107, grad/param norm = 2.6369e-01, time/batch = 17.1994s	
21067/22750 (epoch 46.301), train_loss = 0.65925650, grad/param norm = 2.2408e-01, time/batch = 17.1931s	
21068/22750 (epoch 46.303), train_loss = 0.73180971, grad/param norm = 2.5488e-01, time/batch = 17.2778s	
21069/22750 (epoch 46.305), train_loss = 0.80012059, grad/param norm = 2.4604e-01, time/batch = 17.3944s	
21070/22750 (epoch 46.308), train_loss = 0.77001803, grad/param norm = 2.6138e-01, time/batch = 17.0345s	
21071/22750 (epoch 46.310), train_loss = 0.63391350, grad/param norm = 2.6375e-01, time/batch = 17.3397s	
21072/22750 (epoch 46.312), train_loss = 0.69901616, grad/param norm = 2.4383e-01, time/batch = 17.4119s	
21073/22750 (epoch 46.314), train_loss = 0.73021067, grad/param norm = 2.3938e-01, time/batch = 17.5062s	
21074/22750 (epoch 46.316), train_loss = 0.67848647, grad/param norm = 2.2580e-01, time/batch = 17.4169s	
21075/22750 (epoch 46.319), train_loss = 0.72348899, grad/param norm = 3.2528e-01, time/batch = 17.2373s	
21076/22750 (epoch 46.321), train_loss = 0.66289723, grad/param norm = 2.6318e-01, time/batch = 17.2679s	
21077/22750 (epoch 46.323), train_loss = 0.74585461, grad/param norm = 2.7025e-01, time/batch = 17.0454s	
21078/22750 (epoch 46.325), train_loss = 0.62148810, grad/param norm = 2.1564e-01, time/batch = 17.1949s	
21079/22750 (epoch 46.327), train_loss = 0.65712211, grad/param norm = 2.7962e-01, time/batch = 17.3430s	
21080/22750 (epoch 46.330), train_loss = 0.80482117, grad/param norm = 2.7660e-01, time/batch = 17.1117s	
21081/22750 (epoch 46.332), train_loss = 0.88957405, grad/param norm = 2.5669e-01, time/batch = 17.4132s	
21082/22750 (epoch 46.334), train_loss = 0.56184610, grad/param norm = 1.9440e-01, time/batch = 17.4553s	
21083/22750 (epoch 46.336), train_loss = 0.76263472, grad/param norm = 2.2187e-01, time/batch = 17.2582s	
21084/22750 (epoch 46.338), train_loss = 0.69271212, grad/param norm = 2.7074e-01, time/batch = 17.1703s	
21085/22750 (epoch 46.341), train_loss = 0.69654985, grad/param norm = 2.3391e-01, time/batch = 17.2100s	
21086/22750 (epoch 46.343), train_loss = 0.60202349, grad/param norm = 2.2891e-01, time/batch = 17.4165s	
21087/22750 (epoch 46.345), train_loss = 0.72056153, grad/param norm = 2.7698e-01, time/batch = 17.4578s	
21088/22750 (epoch 46.347), train_loss = 0.75582604, grad/param norm = 2.7105e-01, time/batch = 17.1404s	
21089/22750 (epoch 46.349), train_loss = 0.57512151, grad/param norm = 2.6888e-01, time/batch = 17.3690s	
21090/22750 (epoch 46.352), train_loss = 0.83697050, grad/param norm = 2.8485e-01, time/batch = 17.2643s	
21091/22750 (epoch 46.354), train_loss = 0.79409256, grad/param norm = 2.5604e-01, time/batch = 17.1838s	
21092/22750 (epoch 46.356), train_loss = 0.72994371, grad/param norm = 2.2434e-01, time/batch = 17.2468s	
21093/22750 (epoch 46.358), train_loss = 0.65422859, grad/param norm = 2.3095e-01, time/batch = 17.4151s	
21094/22750 (epoch 46.360), train_loss = 0.83236344, grad/param norm = 2.3634e-01, time/batch = 17.1731s	
21095/22750 (epoch 46.363), train_loss = 0.64283264, grad/param norm = 2.4253e-01, time/batch = 17.0958s	
21096/22750 (epoch 46.365), train_loss = 0.56283235, grad/param norm = 2.4095e-01, time/batch = 17.2365s	
21097/22750 (epoch 46.367), train_loss = 0.64175860, grad/param norm = 2.5170e-01, time/batch = 17.4181s	
21098/22750 (epoch 46.369), train_loss = 0.69069501, grad/param norm = 2.5698e-01, time/batch = 17.5974s	
21099/22750 (epoch 46.371), train_loss = 0.73257188, grad/param norm = 2.6243e-01, time/batch = 17.1043s	
21100/22750 (epoch 46.374), train_loss = 0.60919193, grad/param norm = 2.1339e-01, time/batch = 17.0852s	
21101/22750 (epoch 46.376), train_loss = 0.69538852, grad/param norm = 2.2362e-01, time/batch = 17.0004s	
21102/22750 (epoch 46.378), train_loss = 0.72112514, grad/param norm = 2.4291e-01, time/batch = 16.9274s	
21103/22750 (epoch 46.380), train_loss = 0.76901329, grad/param norm = 2.3626e-01, time/batch = 17.3252s	
21104/22750 (epoch 46.382), train_loss = 0.67042744, grad/param norm = 2.3216e-01, time/batch = 17.2266s	
21105/22750 (epoch 46.385), train_loss = 0.75592708, grad/param norm = 2.4668e-01, time/batch = 16.9278s	
21106/22750 (epoch 46.387), train_loss = 0.72605670, grad/param norm = 2.4916e-01, time/batch = 16.6915s	
21107/22750 (epoch 46.389), train_loss = 0.57863384, grad/param norm = 2.3559e-01, time/batch = 16.8784s	
21108/22750 (epoch 46.391), train_loss = 0.44332289, grad/param norm = 1.9077e-01, time/batch = 16.5133s	
21109/22750 (epoch 46.393), train_loss = 0.58215720, grad/param norm = 2.3398e-01, time/batch = 16.7073s	
21110/22750 (epoch 46.396), train_loss = 0.70879563, grad/param norm = 2.0918e-01, time/batch = 16.5705s	
21111/22750 (epoch 46.398), train_loss = 0.64494122, grad/param norm = 2.0474e-01, time/batch = 16.3442s	
21112/22750 (epoch 46.400), train_loss = 0.70824384, grad/param norm = 2.6296e-01, time/batch = 16.0103s	
21113/22750 (epoch 46.402), train_loss = 0.68960274, grad/param norm = 2.2326e-01, time/batch = 16.9585s	
21114/22750 (epoch 46.404), train_loss = 0.79154717, grad/param norm = 2.6932e-01, time/batch = 16.5049s	
21115/22750 (epoch 46.407), train_loss = 0.76996312, grad/param norm = 2.3399e-01, time/batch = 16.0157s	
21116/22750 (epoch 46.409), train_loss = 0.63793486, grad/param norm = 2.2896e-01, time/batch = 16.3569s	
21117/22750 (epoch 46.411), train_loss = 0.64568307, grad/param norm = 2.2486e-01, time/batch = 16.3279s	
21118/22750 (epoch 46.413), train_loss = 0.50093990, grad/param norm = 2.5656e-01, time/batch = 16.5373s	
21119/22750 (epoch 46.415), train_loss = 0.57301042, grad/param norm = 2.1168e-01, time/batch = 15.7211s	
21120/22750 (epoch 46.418), train_loss = 0.66383027, grad/param norm = 2.7197e-01, time/batch = 16.1022s	
21121/22750 (epoch 46.420), train_loss = 0.72935456, grad/param norm = 3.4254e-01, time/batch = 16.6856s	
21122/22750 (epoch 46.422), train_loss = 0.85537754, grad/param norm = 2.8483e-01, time/batch = 16.8875s	
21123/22750 (epoch 46.424), train_loss = 0.87067039, grad/param norm = 2.4974e-01, time/batch = 16.3419s	
21124/22750 (epoch 46.426), train_loss = 0.86204222, grad/param norm = 2.5442e-01, time/batch = 16.0955s	
21125/22750 (epoch 46.429), train_loss = 0.65058071, grad/param norm = 2.2527e-01, time/batch = 16.4759s	
21126/22750 (epoch 46.431), train_loss = 0.57275515, grad/param norm = 2.2747e-01, time/batch = 15.6144s	
21127/22750 (epoch 46.433), train_loss = 0.64361756, grad/param norm = 2.3084e-01, time/batch = 15.2085s	
21128/22750 (epoch 46.435), train_loss = 0.50010586, grad/param norm = 1.8630e-01, time/batch = 15.4526s	
21129/22750 (epoch 46.437), train_loss = 0.44808098, grad/param norm = 1.9268e-01, time/batch = 15.9302s	
21130/22750 (epoch 46.440), train_loss = 0.65377536, grad/param norm = 2.6914e-01, time/batch = 15.6045s	
21131/22750 (epoch 46.442), train_loss = 0.68372665, grad/param norm = 2.5218e-01, time/batch = 15.7767s	
21132/22750 (epoch 46.444), train_loss = 0.64841631, grad/param norm = 2.2696e-01, time/batch = 16.0261s	
21133/22750 (epoch 46.446), train_loss = 0.65820093, grad/param norm = 2.6754e-01, time/batch = 15.9409s	
21134/22750 (epoch 46.448), train_loss = 0.87102821, grad/param norm = 2.9609e-01, time/batch = 15.9298s	
21135/22750 (epoch 46.451), train_loss = 0.83125928, grad/param norm = 2.3910e-01, time/batch = 15.6897s	
21136/22750 (epoch 46.453), train_loss = 0.70088475, grad/param norm = 2.4234e-01, time/batch = 16.2545s	
21137/22750 (epoch 46.455), train_loss = 0.81876009, grad/param norm = 2.5351e-01, time/batch = 16.8103s	
21138/22750 (epoch 46.457), train_loss = 0.74089437, grad/param norm = 3.7096e-01, time/batch = 16.2564s	
21139/22750 (epoch 46.459), train_loss = 0.74888573, grad/param norm = 2.3516e-01, time/batch = 15.6983s	
21140/22750 (epoch 46.462), train_loss = 0.69329806, grad/param norm = 2.3265e-01, time/batch = 17.3159s	
21141/22750 (epoch 46.464), train_loss = 0.58981831, grad/param norm = 2.2464e-01, time/batch = 18.9972s	
21142/22750 (epoch 46.466), train_loss = 0.73575186, grad/param norm = 2.9034e-01, time/batch = 18.7592s	
21143/22750 (epoch 46.468), train_loss = 0.72964674, grad/param norm = 2.6538e-01, time/batch = 17.1882s	
21144/22750 (epoch 46.470), train_loss = 0.79322439, grad/param norm = 2.6295e-01, time/batch = 17.3998s	
21145/22750 (epoch 46.473), train_loss = 0.66081137, grad/param norm = 3.0989e-01, time/batch = 17.2209s	
21146/22750 (epoch 46.475), train_loss = 0.70433436, grad/param norm = 2.4731e-01, time/batch = 19.3238s	
21147/22750 (epoch 46.477), train_loss = 0.61548314, grad/param norm = 2.6250e-01, time/batch = 19.3473s	
21148/22750 (epoch 46.479), train_loss = 0.57963480, grad/param norm = 2.2180e-01, time/batch = 18.8516s	
21149/22750 (epoch 46.481), train_loss = 0.55580596, grad/param norm = 2.0920e-01, time/batch = 19.3693s	
21150/22750 (epoch 46.484), train_loss = 0.48567297, grad/param norm = 2.7948e-01, time/batch = 19.1439s	
21151/22750 (epoch 46.486), train_loss = 0.56579999, grad/param norm = 2.1057e-01, time/batch = 18.1502s	
21152/22750 (epoch 46.488), train_loss = 0.52622818, grad/param norm = 2.1715e-01, time/batch = 19.9850s	
21153/22750 (epoch 46.490), train_loss = 0.66458465, grad/param norm = 2.5476e-01, time/batch = 19.4946s	
21154/22750 (epoch 46.492), train_loss = 0.76116875, grad/param norm = 2.5494e-01, time/batch = 18.6671s	
21155/22750 (epoch 46.495), train_loss = 0.63703422, grad/param norm = 2.2254e-01, time/batch = 19.2678s	
21156/22750 (epoch 46.497), train_loss = 0.67309038, grad/param norm = 2.9118e-01, time/batch = 30.0439s	
21157/22750 (epoch 46.499), train_loss = 0.60518429, grad/param norm = 2.3416e-01, time/batch = 15.7787s	
21158/22750 (epoch 46.501), train_loss = 0.65249187, grad/param norm = 2.5028e-01, time/batch = 16.5992s	
21159/22750 (epoch 46.503), train_loss = 0.64949717, grad/param norm = 2.2905e-01, time/batch = 16.0319s	
21160/22750 (epoch 46.505), train_loss = 0.59306667, grad/param norm = 2.5549e-01, time/batch = 16.2580s	
21161/22750 (epoch 46.508), train_loss = 0.56854378, grad/param norm = 2.1825e-01, time/batch = 15.6768s	
21162/22750 (epoch 46.510), train_loss = 0.56416165, grad/param norm = 2.2414e-01, time/batch = 16.0686s	
21163/22750 (epoch 46.512), train_loss = 0.61600757, grad/param norm = 2.2160e-01, time/batch = 15.9300s	
21164/22750 (epoch 46.514), train_loss = 0.62945305, grad/param norm = 2.3483e-01, time/batch = 15.9218s	
21165/22750 (epoch 46.516), train_loss = 0.61964475, grad/param norm = 2.5557e-01, time/batch = 16.5048s	
21166/22750 (epoch 46.519), train_loss = 0.77669655, grad/param norm = 2.4972e-01, time/batch = 16.0266s	
21167/22750 (epoch 46.521), train_loss = 0.66269247, grad/param norm = 2.3835e-01, time/batch = 15.6179s	
21168/22750 (epoch 46.523), train_loss = 0.59416164, grad/param norm = 3.1698e-01, time/batch = 16.4988s	
21169/22750 (epoch 46.525), train_loss = 0.77042184, grad/param norm = 2.9755e-01, time/batch = 15.9269s	
21170/22750 (epoch 46.527), train_loss = 0.69660646, grad/param norm = 2.2797e-01, time/batch = 16.0104s	
21171/22750 (epoch 46.530), train_loss = 0.62031272, grad/param norm = 2.4554e-01, time/batch = 15.6865s	
21172/22750 (epoch 46.532), train_loss = 0.55717305, grad/param norm = 2.0358e-01, time/batch = 15.4442s	
21173/22750 (epoch 46.534), train_loss = 0.72172345, grad/param norm = 2.7250e-01, time/batch = 16.0907s	
21174/22750 (epoch 46.536), train_loss = 0.70312730, grad/param norm = 2.0320e-01, time/batch = 15.7552s	
21175/22750 (epoch 46.538), train_loss = 0.68527840, grad/param norm = 2.2786e-01, time/batch = 15.6610s	
21176/22750 (epoch 46.541), train_loss = 0.59942394, grad/param norm = 2.5219e-01, time/batch = 15.4656s	
21177/22750 (epoch 46.543), train_loss = 0.58353434, grad/param norm = 2.3222e-01, time/batch = 15.8693s	
21178/22750 (epoch 46.545), train_loss = 0.73649887, grad/param norm = 2.4652e-01, time/batch = 16.4995s	
21179/22750 (epoch 46.547), train_loss = 0.64154841, grad/param norm = 2.0305e-01, time/batch = 15.7451s	
21180/22750 (epoch 46.549), train_loss = 0.64560660, grad/param norm = 2.3016e-01, time/batch = 15.5367s	
21181/22750 (epoch 46.552), train_loss = 0.70627029, grad/param norm = 2.5429e-01, time/batch = 16.1005s	
21182/22750 (epoch 46.554), train_loss = 0.69747989, grad/param norm = 2.3821e-01, time/batch = 16.7922s	
21183/22750 (epoch 46.556), train_loss = 0.70543248, grad/param norm = 2.2322e-01, time/batch = 15.9990s	
21184/22750 (epoch 46.558), train_loss = 0.65751903, grad/param norm = 2.5913e-01, time/batch = 15.9248s	
21185/22750 (epoch 46.560), train_loss = 0.64281577, grad/param norm = 2.4396e-01, time/batch = 16.2488s	
21186/22750 (epoch 46.563), train_loss = 0.74093004, grad/param norm = 2.5365e-01, time/batch = 15.7087s	
21187/22750 (epoch 46.565), train_loss = 0.73421677, grad/param norm = 2.6255e-01, time/batch = 16.0293s	
21188/22750 (epoch 46.567), train_loss = 0.71590748, grad/param norm = 2.4567e-01, time/batch = 15.7845s	
21189/22750 (epoch 46.569), train_loss = 0.67389902, grad/param norm = 2.3943e-01, time/batch = 20.2856s	
21190/22750 (epoch 46.571), train_loss = 0.65585792, grad/param norm = 2.4736e-01, time/batch = 32.5921s	
21191/22750 (epoch 46.574), train_loss = 0.67485335, grad/param norm = 2.2032e-01, time/batch = 29.7094s	
21192/22750 (epoch 46.576), train_loss = 0.66369974, grad/param norm = 2.2518e-01, time/batch = 33.3842s	
21193/22750 (epoch 46.578), train_loss = 0.58353073, grad/param norm = 2.4754e-01, time/batch = 33.0615s	
21194/22750 (epoch 46.580), train_loss = 0.69347015, grad/param norm = 2.3756e-01, time/batch = 29.5299s	
21195/22750 (epoch 46.582), train_loss = 0.62032323, grad/param norm = 2.3645e-01, time/batch = 33.6743s	
21196/22750 (epoch 46.585), train_loss = 0.57937321, grad/param norm = 2.2714e-01, time/batch = 32.5880s	
21197/22750 (epoch 46.587), train_loss = 0.59832112, grad/param norm = 2.0212e-01, time/batch = 33.7338s	
21198/22750 (epoch 46.589), train_loss = 0.50017992, grad/param norm = 1.8220e-01, time/batch = 33.4854s	
21199/22750 (epoch 46.591), train_loss = 0.66979092, grad/param norm = 2.3292e-01, time/batch = 32.3294s	
21200/22750 (epoch 46.593), train_loss = 0.78487118, grad/param norm = 3.0645e-01, time/batch = 27.0727s	
21201/22750 (epoch 46.596), train_loss = 0.72037957, grad/param norm = 2.3208e-01, time/batch = 15.6013s	
21202/22750 (epoch 46.598), train_loss = 0.73198022, grad/param norm = 2.8524e-01, time/batch = 15.8494s	
21203/22750 (epoch 46.600), train_loss = 0.81444010, grad/param norm = 2.3511e-01, time/batch = 15.8529s	
21204/22750 (epoch 46.602), train_loss = 0.59305825, grad/param norm = 2.0709e-01, time/batch = 16.0762s	
21205/22750 (epoch 46.604), train_loss = 0.63146056, grad/param norm = 2.2294e-01, time/batch = 15.2904s	
21206/22750 (epoch 46.607), train_loss = 0.59799639, grad/param norm = 2.1399e-01, time/batch = 15.4577s	
21207/22750 (epoch 46.609), train_loss = 0.57374921, grad/param norm = 2.2780e-01, time/batch = 16.1219s	
21208/22750 (epoch 46.611), train_loss = 0.60418446, grad/param norm = 2.2136e-01, time/batch = 15.7941s	
21209/22750 (epoch 46.613), train_loss = 0.61080370, grad/param norm = 2.2457e-01, time/batch = 15.5351s	
21210/22750 (epoch 46.615), train_loss = 0.65659475, grad/param norm = 2.5340e-01, time/batch = 15.5299s	
21211/22750 (epoch 46.618), train_loss = 0.66837759, grad/param norm = 2.1133e-01, time/batch = 15.8535s	
21212/22750 (epoch 46.620), train_loss = 0.63267648, grad/param norm = 2.5940e-01, time/batch = 15.5979s	
21213/22750 (epoch 46.622), train_loss = 0.57437496, grad/param norm = 2.0427e-01, time/batch = 15.9934s	
21214/22750 (epoch 46.624), train_loss = 0.62598855, grad/param norm = 2.5477e-01, time/batch = 15.5306s	
21215/22750 (epoch 46.626), train_loss = 0.54210601, grad/param norm = 2.0575e-01, time/batch = 16.0820s	
21216/22750 (epoch 46.629), train_loss = 0.60353854, grad/param norm = 2.1356e-01, time/batch = 15.5487s	
21217/22750 (epoch 46.631), train_loss = 0.65151800, grad/param norm = 2.2701e-01, time/batch = 15.7035s	
21218/22750 (epoch 46.633), train_loss = 0.56317554, grad/param norm = 2.0791e-01, time/batch = 16.0244s	
21219/22750 (epoch 46.635), train_loss = 0.65346107, grad/param norm = 2.0557e-01, time/batch = 15.8535s	
21220/22750 (epoch 46.637), train_loss = 0.70423862, grad/param norm = 2.8734e-01, time/batch = 15.5377s	
21221/22750 (epoch 46.640), train_loss = 0.70719870, grad/param norm = 2.3591e-01, time/batch = 15.8415s	
21222/22750 (epoch 46.642), train_loss = 0.73327985, grad/param norm = 2.3917e-01, time/batch = 16.0151s	
21223/22750 (epoch 46.644), train_loss = 0.66854139, grad/param norm = 2.7258e-01, time/batch = 15.6903s	
21224/22750 (epoch 46.646), train_loss = 0.72272655, grad/param norm = 2.8976e-01, time/batch = 15.6127s	
21225/22750 (epoch 46.648), train_loss = 0.71353430, grad/param norm = 2.4958e-01, time/batch = 19.6400s	
21226/22750 (epoch 46.651), train_loss = 0.70454528, grad/param norm = 2.3009e-01, time/batch = 19.0913s	
21227/22750 (epoch 46.653), train_loss = 0.74375962, grad/param norm = 2.1593e-01, time/batch = 19.3676s	
21228/22750 (epoch 46.655), train_loss = 0.68728989, grad/param norm = 2.1115e-01, time/batch = 20.3711s	
21229/22750 (epoch 46.657), train_loss = 0.79430853, grad/param norm = 2.5779e-01, time/batch = 18.8401s	
21230/22750 (epoch 46.659), train_loss = 0.83937025, grad/param norm = 2.4178e-01, time/batch = 19.9144s	
21231/22750 (epoch 46.662), train_loss = 0.82418347, grad/param norm = 4.2342e-01, time/batch = 18.9647s	
21232/22750 (epoch 46.664), train_loss = 0.70332876, grad/param norm = 2.6278e-01, time/batch = 18.5839s	
21233/22750 (epoch 46.666), train_loss = 0.59703518, grad/param norm = 2.2428e-01, time/batch = 18.1645s	
21234/22750 (epoch 46.668), train_loss = 0.64958763, grad/param norm = 2.6315e-01, time/batch = 18.0765s	
21235/22750 (epoch 46.670), train_loss = 0.62413440, grad/param norm = 2.3578e-01, time/batch = 18.2477s	
21236/22750 (epoch 46.673), train_loss = 0.82508262, grad/param norm = 2.6916e-01, time/batch = 15.9163s	
21237/22750 (epoch 46.675), train_loss = 0.92150670, grad/param norm = 3.3289e-01, time/batch = 20.0277s	
21238/22750 (epoch 46.677), train_loss = 0.79854063, grad/param norm = 2.5862e-01, time/batch = 18.5917s	
21239/22750 (epoch 46.679), train_loss = 0.78901792, grad/param norm = 2.9089e-01, time/batch = 18.7503s	
21240/22750 (epoch 46.681), train_loss = 0.80285183, grad/param norm = 3.2329e-01, time/batch = 19.3268s	
21241/22750 (epoch 46.684), train_loss = 0.82825620, grad/param norm = 2.4853e-01, time/batch = 20.1653s	
21242/22750 (epoch 46.686), train_loss = 0.86185332, grad/param norm = 2.6949e-01, time/batch = 20.0636s	
21243/22750 (epoch 46.688), train_loss = 0.80184984, grad/param norm = 2.5681e-01, time/batch = 20.7251s	
21244/22750 (epoch 46.690), train_loss = 0.79161596, grad/param norm = 2.7214e-01, time/batch = 20.0264s	
21245/22750 (epoch 46.692), train_loss = 0.79506290, grad/param norm = 2.8591e-01, time/batch = 19.1129s	
21246/22750 (epoch 46.695), train_loss = 0.72026344, grad/param norm = 2.3820e-01, time/batch = 19.0726s	
21247/22750 (epoch 46.697), train_loss = 0.73403941, grad/param norm = 2.5626e-01, time/batch = 19.9032s	
21248/22750 (epoch 46.699), train_loss = 0.64214452, grad/param norm = 2.6119e-01, time/batch = 18.3337s	
21249/22750 (epoch 46.701), train_loss = 0.59328356, grad/param norm = 2.5623e-01, time/batch = 16.6937s	
21250/22750 (epoch 46.703), train_loss = 0.65300941, grad/param norm = 2.5804e-01, time/batch = 20.6601s	
21251/22750 (epoch 46.705), train_loss = 0.62207262, grad/param norm = 2.2114e-01, time/batch = 18.7138s	
21252/22750 (epoch 46.708), train_loss = 0.67433136, grad/param norm = 2.9085e-01, time/batch = 19.5755s	
21253/22750 (epoch 46.710), train_loss = 0.62383162, grad/param norm = 2.4941e-01, time/batch = 17.1094s	
21254/22750 (epoch 46.712), train_loss = 0.52861517, grad/param norm = 2.4173e-01, time/batch = 16.4063s	
21255/22750 (epoch 46.714), train_loss = 0.59162430, grad/param norm = 2.2511e-01, time/batch = 19.8567s	
21256/22750 (epoch 46.716), train_loss = 0.58854216, grad/param norm = 2.1741e-01, time/batch = 17.9205s	
21257/22750 (epoch 46.719), train_loss = 0.65420572, grad/param norm = 2.8332e-01, time/batch = 18.1704s	
21258/22750 (epoch 46.721), train_loss = 0.79027452, grad/param norm = 2.2522e-01, time/batch = 17.9132s	
21259/22750 (epoch 46.723), train_loss = 0.73780040, grad/param norm = 2.6801e-01, time/batch = 19.0831s	
21260/22750 (epoch 46.725), train_loss = 0.63876169, grad/param norm = 2.4371e-01, time/batch = 18.9884s	
21261/22750 (epoch 46.727), train_loss = 0.70009554, grad/param norm = 2.6397e-01, time/batch = 19.5814s	
21262/22750 (epoch 46.730), train_loss = 0.66556586, grad/param norm = 2.7486e-01, time/batch = 18.7853s	
21263/22750 (epoch 46.732), train_loss = 0.62811908, grad/param norm = 2.1150e-01, time/batch = 20.0213s	
21264/22750 (epoch 46.734), train_loss = 0.57308390, grad/param norm = 2.0753e-01, time/batch = 18.1915s	
21265/22750 (epoch 46.736), train_loss = 0.64792468, grad/param norm = 2.2995e-01, time/batch = 19.1707s	
21266/22750 (epoch 46.738), train_loss = 0.71443850, grad/param norm = 2.9175e-01, time/batch = 17.6728s	
21267/22750 (epoch 46.741), train_loss = 0.80574831, grad/param norm = 2.6404e-01, time/batch = 17.3225s	
21268/22750 (epoch 46.743), train_loss = 0.67950166, grad/param norm = 2.2835e-01, time/batch = 19.2496s	
21269/22750 (epoch 46.745), train_loss = 0.57477200, grad/param norm = 2.0961e-01, time/batch = 16.9321s	
21270/22750 (epoch 46.747), train_loss = 0.68285498, grad/param norm = 2.2899e-01, time/batch = 18.5727s	
21271/22750 (epoch 46.749), train_loss = 0.78479853, grad/param norm = 2.6605e-01, time/batch = 19.1947s	
21272/22750 (epoch 46.752), train_loss = 0.70714754, grad/param norm = 2.4811e-01, time/batch = 19.1165s	
21273/22750 (epoch 46.754), train_loss = 0.68035535, grad/param norm = 2.5927e-01, time/batch = 17.9462s	
21274/22750 (epoch 46.756), train_loss = 0.61545984, grad/param norm = 2.3203e-01, time/batch = 19.4955s	
21275/22750 (epoch 46.758), train_loss = 0.61424500, grad/param norm = 2.0717e-01, time/batch = 19.2510s	
21276/22750 (epoch 46.760), train_loss = 0.59295431, grad/param norm = 2.1871e-01, time/batch = 19.0827s	
21277/22750 (epoch 46.763), train_loss = 0.65857128, grad/param norm = 2.3687e-01, time/batch = 17.6776s	
21278/22750 (epoch 46.765), train_loss = 0.66329971, grad/param norm = 2.6725e-01, time/batch = 18.1667s	
21279/22750 (epoch 46.767), train_loss = 0.70536435, grad/param norm = 2.3947e-01, time/batch = 20.2401s	
21280/22750 (epoch 46.769), train_loss = 0.77547815, grad/param norm = 2.8405e-01, time/batch = 18.8488s	
21281/22750 (epoch 46.771), train_loss = 0.80612658, grad/param norm = 2.9288e-01, time/batch = 18.6270s	
21282/22750 (epoch 46.774), train_loss = 0.62467314, grad/param norm = 2.2865e-01, time/batch = 20.2909s	
21283/22750 (epoch 46.776), train_loss = 0.75933411, grad/param norm = 2.4996e-01, time/batch = 16.9199s	
21284/22750 (epoch 46.778), train_loss = 0.78845814, grad/param norm = 2.5302e-01, time/batch = 19.7237s	
21285/22750 (epoch 46.780), train_loss = 0.70654119, grad/param norm = 2.2468e-01, time/batch = 17.7436s	
21286/22750 (epoch 46.782), train_loss = 0.80136912, grad/param norm = 2.5498e-01, time/batch = 16.1045s	
21287/22750 (epoch 46.785), train_loss = 0.66321544, grad/param norm = 2.6708e-01, time/batch = 18.7539s	
21288/22750 (epoch 46.787), train_loss = 0.58172858, grad/param norm = 2.7081e-01, time/batch = 19.7500s	
21289/22750 (epoch 46.789), train_loss = 0.67041114, grad/param norm = 2.3684e-01, time/batch = 19.0889s	
21290/22750 (epoch 46.791), train_loss = 0.65162504, grad/param norm = 2.4435e-01, time/batch = 20.1133s	
21291/22750 (epoch 46.793), train_loss = 0.64284299, grad/param norm = 2.9019e-01, time/batch = 20.5209s	
21292/22750 (epoch 46.796), train_loss = 0.59968450, grad/param norm = 2.7691e-01, time/batch = 18.2572s	
21293/22750 (epoch 46.798), train_loss = 0.63339865, grad/param norm = 2.1802e-01, time/batch = 18.9148s	
21294/22750 (epoch 46.800), train_loss = 0.63118851, grad/param norm = 2.6941e-01, time/batch = 18.4157s	
21295/22750 (epoch 46.802), train_loss = 0.58621611, grad/param norm = 2.3017e-01, time/batch = 18.7455s	
21296/22750 (epoch 46.804), train_loss = 0.75003519, grad/param norm = 2.1569e-01, time/batch = 20.4938s	
21297/22750 (epoch 46.807), train_loss = 0.72865590, grad/param norm = 2.7817e-01, time/batch = 19.3499s	
21298/22750 (epoch 46.809), train_loss = 0.81221998, grad/param norm = 2.6684e-01, time/batch = 19.3522s	
21299/22750 (epoch 46.811), train_loss = 0.68998595, grad/param norm = 2.4571e-01, time/batch = 17.0823s	
21300/22750 (epoch 46.813), train_loss = 0.71157179, grad/param norm = 2.2948e-01, time/batch = 17.5244s	
21301/22750 (epoch 46.815), train_loss = 0.78628589, grad/param norm = 2.3659e-01, time/batch = 17.2359s	
21302/22750 (epoch 46.818), train_loss = 0.74915815, grad/param norm = 2.5739e-01, time/batch = 16.7538s	
21303/22750 (epoch 46.820), train_loss = 0.84710747, grad/param norm = 2.3132e-01, time/batch = 17.3469s	
21304/22750 (epoch 46.822), train_loss = 0.71858416, grad/param norm = 2.4625e-01, time/batch = 18.2392s	
21305/22750 (epoch 46.824), train_loss = 0.60689929, grad/param norm = 2.1074e-01, time/batch = 17.4000s	
21306/22750 (epoch 46.826), train_loss = 0.66418163, grad/param norm = 2.2037e-01, time/batch = 18.4304s	
21307/22750 (epoch 46.829), train_loss = 0.75218861, grad/param norm = 2.6305e-01, time/batch = 19.1879s	
21308/22750 (epoch 46.831), train_loss = 0.77668582, grad/param norm = 2.8624e-01, time/batch = 18.6786s	
21309/22750 (epoch 46.833), train_loss = 0.70828995, grad/param norm = 2.7725e-01, time/batch = 17.5937s	
21310/22750 (epoch 46.835), train_loss = 0.62230766, grad/param norm = 2.8656e-01, time/batch = 15.9864s	
21311/22750 (epoch 46.837), train_loss = 0.68781653, grad/param norm = 2.6332e-01, time/batch = 17.0933s	
21312/22750 (epoch 46.840), train_loss = 0.62414066, grad/param norm = 2.5302e-01, time/batch = 16.5785s	
21313/22750 (epoch 46.842), train_loss = 0.62062067, grad/param norm = 2.6321e-01, time/batch = 19.0844s	
21314/22750 (epoch 46.844), train_loss = 0.70989395, grad/param norm = 2.8219e-01, time/batch = 17.9133s	
21315/22750 (epoch 46.846), train_loss = 0.75155532, grad/param norm = 2.4781e-01, time/batch = 17.9713s	
21316/22750 (epoch 46.848), train_loss = 0.65257190, grad/param norm = 2.2096e-01, time/batch = 18.1040s	
21317/22750 (epoch 46.851), train_loss = 0.63681569, grad/param norm = 2.3727e-01, time/batch = 18.5758s	
21318/22750 (epoch 46.853), train_loss = 0.79030378, grad/param norm = 2.4494e-01, time/batch = 18.9956s	
21319/22750 (epoch 46.855), train_loss = 0.67184793, grad/param norm = 2.2101e-01, time/batch = 18.5805s	
21320/22750 (epoch 46.857), train_loss = 0.74025629, grad/param norm = 2.4688e-01, time/batch = 18.6749s	
21321/22750 (epoch 46.859), train_loss = 0.70886841, grad/param norm = 2.3684e-01, time/batch = 19.1585s	
21322/22750 (epoch 46.862), train_loss = 0.82278166, grad/param norm = 3.2138e-01, time/batch = 17.0880s	
21323/22750 (epoch 46.864), train_loss = 0.69687820, grad/param norm = 2.6057e-01, time/batch = 19.8203s	
21324/22750 (epoch 46.866), train_loss = 0.74728592, grad/param norm = 2.4815e-01, time/batch = 20.8140s	
21325/22750 (epoch 46.868), train_loss = 0.61370452, grad/param norm = 2.2898e-01, time/batch = 19.2699s	
21326/22750 (epoch 46.870), train_loss = 0.60678335, grad/param norm = 2.2592e-01, time/batch = 20.3425s	
21327/22750 (epoch 46.873), train_loss = 0.69276648, grad/param norm = 2.4236e-01, time/batch = 20.0168s	
21328/22750 (epoch 46.875), train_loss = 0.72264525, grad/param norm = 2.2857e-01, time/batch = 17.3307s	
21329/22750 (epoch 46.877), train_loss = 0.66313359, grad/param norm = 2.6004e-01, time/batch = 18.1731s	
21330/22750 (epoch 46.879), train_loss = 0.76743466, grad/param norm = 2.5559e-01, time/batch = 17.8454s	
21331/22750 (epoch 46.881), train_loss = 0.70122176, grad/param norm = 2.3707e-01, time/batch = 17.6374s	
21332/22750 (epoch 46.884), train_loss = 0.60219092, grad/param norm = 2.2188e-01, time/batch = 18.5649s	
21333/22750 (epoch 46.886), train_loss = 0.70172574, grad/param norm = 2.2275e-01, time/batch = 18.6565s	
21334/22750 (epoch 46.888), train_loss = 0.73930121, grad/param norm = 2.2556e-01, time/batch = 19.5160s	
21335/22750 (epoch 46.890), train_loss = 0.73825151, grad/param norm = 2.3989e-01, time/batch = 19.4310s	
21336/22750 (epoch 46.892), train_loss = 0.89723261, grad/param norm = 2.7218e-01, time/batch = 20.3434s	
21337/22750 (epoch 46.895), train_loss = 0.66524173, grad/param norm = 2.8180e-01, time/batch = 17.9193s	
21338/22750 (epoch 46.897), train_loss = 0.79032467, grad/param norm = 2.6502e-01, time/batch = 17.1759s	
21339/22750 (epoch 46.899), train_loss = 0.70006011, grad/param norm = 2.2532e-01, time/batch = 16.3162s	
21340/22750 (epoch 46.901), train_loss = 0.78363441, grad/param norm = 2.8287e-01, time/batch = 18.1734s	
21341/22750 (epoch 46.903), train_loss = 0.67823725, grad/param norm = 2.5706e-01, time/batch = 16.7707s	
21342/22750 (epoch 46.905), train_loss = 0.73396780, grad/param norm = 2.7631e-01, time/batch = 19.4278s	
21343/22750 (epoch 46.908), train_loss = 0.57761909, grad/param norm = 2.5681e-01, time/batch = 18.8519s	
21344/22750 (epoch 46.910), train_loss = 0.52772953, grad/param norm = 3.0967e-01, time/batch = 18.1158s	
21345/22750 (epoch 46.912), train_loss = 0.69775728, grad/param norm = 2.5707e-01, time/batch = 20.5249s	
21346/22750 (epoch 46.914), train_loss = 0.70699032, grad/param norm = 2.3530e-01, time/batch = 17.9035s	
21347/22750 (epoch 46.916), train_loss = 0.56295732, grad/param norm = 2.1162e-01, time/batch = 19.2183s	
21348/22750 (epoch 46.919), train_loss = 0.69377609, grad/param norm = 2.4329e-01, time/batch = 30.5214s	
21349/22750 (epoch 46.921), train_loss = 0.53107561, grad/param norm = 2.1407e-01, time/batch = 24.6905s	
21350/22750 (epoch 46.923), train_loss = 0.64300469, grad/param norm = 2.5406e-01, time/batch = 18.4049s	
21351/22750 (epoch 46.925), train_loss = 0.69956299, grad/param norm = 2.5794e-01, time/batch = 16.4884s	
21352/22750 (epoch 46.927), train_loss = 0.53586135, grad/param norm = 2.1392e-01, time/batch = 20.8647s	
21353/22750 (epoch 46.930), train_loss = 0.52597621, grad/param norm = 2.2452e-01, time/batch = 17.8558s	
21354/22750 (epoch 46.932), train_loss = 0.65758839, grad/param norm = 2.3908e-01, time/batch = 20.3061s	
21355/22750 (epoch 46.934), train_loss = 0.57902962, grad/param norm = 2.0721e-01, time/batch = 18.2375s	
21356/22750 (epoch 46.936), train_loss = 0.76824369, grad/param norm = 2.7123e-01, time/batch = 17.5016s	
21357/22750 (epoch 46.938), train_loss = 0.74745632, grad/param norm = 2.2770e-01, time/batch = 19.4926s	
21358/22750 (epoch 46.941), train_loss = 0.78804015, grad/param norm = 3.0055e-01, time/batch = 16.6213s	
21359/22750 (epoch 46.943), train_loss = 0.69126686, grad/param norm = 2.2010e-01, time/batch = 17.5932s	
21360/22750 (epoch 46.945), train_loss = 0.71159352, grad/param norm = 2.6922e-01, time/batch = 18.0283s	
21361/22750 (epoch 46.947), train_loss = 0.63076461, grad/param norm = 2.2423e-01, time/batch = 17.9381s	
21362/22750 (epoch 46.949), train_loss = 0.65240960, grad/param norm = 2.1865e-01, time/batch = 19.2616s	
21363/22750 (epoch 46.952), train_loss = 0.65478575, grad/param norm = 2.3365e-01, time/batch = 17.8165s	
21364/22750 (epoch 46.954), train_loss = 0.56381256, grad/param norm = 2.0512e-01, time/batch = 19.6608s	
21365/22750 (epoch 46.956), train_loss = 0.74798976, grad/param norm = 2.3177e-01, time/batch = 19.2531s	
21366/22750 (epoch 46.958), train_loss = 0.61290445, grad/param norm = 2.2434e-01, time/batch = 18.3335s	
21367/22750 (epoch 46.960), train_loss = 0.59369389, grad/param norm = 2.3127e-01, time/batch = 16.6452s	
21368/22750 (epoch 46.963), train_loss = 0.69835058, grad/param norm = 2.1296e-01, time/batch = 20.1872s	
21369/22750 (epoch 46.965), train_loss = 0.73710470, grad/param norm = 2.2883e-01, time/batch = 19.2753s	
21370/22750 (epoch 46.967), train_loss = 0.71816980, grad/param norm = 2.2555e-01, time/batch = 20.7673s	
21371/22750 (epoch 46.969), train_loss = 0.63293842, grad/param norm = 2.4044e-01, time/batch = 20.0028s	
21372/22750 (epoch 46.971), train_loss = 0.63154444, grad/param norm = 2.3425e-01, time/batch = 17.3400s	
21373/22750 (epoch 46.974), train_loss = 0.61722309, grad/param norm = 2.2423e-01, time/batch = 15.7917s	
21374/22750 (epoch 46.976), train_loss = 0.63620341, grad/param norm = 2.3500e-01, time/batch = 18.9938s	
21375/22750 (epoch 46.978), train_loss = 0.61488592, grad/param norm = 2.2599e-01, time/batch = 18.5787s	
21376/22750 (epoch 46.980), train_loss = 0.79097070, grad/param norm = 2.5340e-01, time/batch = 19.7441s	
21377/22750 (epoch 46.982), train_loss = 0.62588679, grad/param norm = 1.9315e-01, time/batch = 18.9954s	
21378/22750 (epoch 46.985), train_loss = 0.80588723, grad/param norm = 2.6106e-01, time/batch = 18.1750s	
21379/22750 (epoch 46.987), train_loss = 0.56432629, grad/param norm = 2.2372e-01, time/batch = 19.9859s	
21380/22750 (epoch 46.989), train_loss = 0.59703731, grad/param norm = 2.4141e-01, time/batch = 18.8574s	
21381/22750 (epoch 46.991), train_loss = 0.71737808, grad/param norm = 2.3190e-01, time/batch = 19.6588s	
21382/22750 (epoch 46.993), train_loss = 0.66536046, grad/param norm = 2.6577e-01, time/batch = 19.4016s	
21383/22750 (epoch 46.996), train_loss = 0.59294362, grad/param norm = 2.2711e-01, time/batch = 20.7449s	
21384/22750 (epoch 46.998), train_loss = 0.76493015, grad/param norm = 2.5661e-01, time/batch = 20.2320s	
decayed learning rate by a factor 0.97 to 0.00062857325411655	
21385/22750 (epoch 47.000), train_loss = 0.66233530, grad/param norm = 2.4850e-01, time/batch = 19.4863s	
21386/22750 (epoch 47.002), train_loss = 0.82642983, grad/param norm = 2.6322e-01, time/batch = 17.3519s	
21387/22750 (epoch 47.004), train_loss = 0.65222377, grad/param norm = 2.5878e-01, time/batch = 19.0992s	
21388/22750 (epoch 47.007), train_loss = 0.64836378, grad/param norm = 2.6048e-01, time/batch = 19.2419s	
21389/22750 (epoch 47.009), train_loss = 0.78132336, grad/param norm = 2.5259e-01, time/batch = 16.4907s	
21390/22750 (epoch 47.011), train_loss = 0.84593122, grad/param norm = 2.6632e-01, time/batch = 18.7537s	
21391/22750 (epoch 47.013), train_loss = 0.76207127, grad/param norm = 2.2984e-01, time/batch = 17.2574s	
21392/22750 (epoch 47.015), train_loss = 0.68811172, grad/param norm = 2.2119e-01, time/batch = 19.8265s	
21393/22750 (epoch 47.018), train_loss = 0.80071682, grad/param norm = 2.6941e-01, time/batch = 18.8489s	
21394/22750 (epoch 47.020), train_loss = 0.80440682, grad/param norm = 2.4113e-01, time/batch = 18.2500s	
21395/22750 (epoch 47.022), train_loss = 0.69869410, grad/param norm = 2.4404e-01, time/batch = 16.3788s	
21396/22750 (epoch 47.024), train_loss = 0.68974274, grad/param norm = 2.4991e-01, time/batch = 17.0204s	
21397/22750 (epoch 47.026), train_loss = 0.74177335, grad/param norm = 3.5453e-01, time/batch = 19.0381s	
21398/22750 (epoch 47.029), train_loss = 0.58223975, grad/param norm = 2.5088e-01, time/batch = 17.6050s	
21399/22750 (epoch 47.031), train_loss = 0.92259986, grad/param norm = 3.1480e-01, time/batch = 20.3248s	
21400/22750 (epoch 47.033), train_loss = 0.73151640, grad/param norm = 2.7073e-01, time/batch = 18.2458s	
21401/22750 (epoch 47.035), train_loss = 0.73895355, grad/param norm = 2.7016e-01, time/batch = 17.4190s	
21402/22750 (epoch 47.037), train_loss = 0.77621768, grad/param norm = 2.6399e-01, time/batch = 18.4243s	
21403/22750 (epoch 47.040), train_loss = 0.71057310, grad/param norm = 2.2655e-01, time/batch = 19.4191s	
21404/22750 (epoch 47.042), train_loss = 0.71276100, grad/param norm = 2.9252e-01, time/batch = 18.8335s	
21405/22750 (epoch 47.044), train_loss = 0.69917069, grad/param norm = 2.5481e-01, time/batch = 18.8368s	
21406/22750 (epoch 47.046), train_loss = 0.78530623, grad/param norm = 2.8526e-01, time/batch = 19.8470s	
21407/22750 (epoch 47.048), train_loss = 0.72828591, grad/param norm = 2.5216e-01, time/batch = 19.8420s	
21408/22750 (epoch 47.051), train_loss = 0.71897986, grad/param norm = 2.6555e-01, time/batch = 19.4361s	
21409/22750 (epoch 47.053), train_loss = 0.69973108, grad/param norm = 2.0633e-01, time/batch = 18.3269s	
21410/22750 (epoch 47.055), train_loss = 0.62384886, grad/param norm = 2.3054e-01, time/batch = 18.3881s	
21411/22750 (epoch 47.057), train_loss = 0.80876848, grad/param norm = 2.6671e-01, time/batch = 20.2277s	
21412/22750 (epoch 47.059), train_loss = 0.53070517, grad/param norm = 2.5065e-01, time/batch = 18.2618s	
21413/22750 (epoch 47.062), train_loss = 0.59086088, grad/param norm = 2.2776e-01, time/batch = 18.9106s	
21414/22750 (epoch 47.064), train_loss = 0.81050765, grad/param norm = 2.4701e-01, time/batch = 20.8342s	
21415/22750 (epoch 47.066), train_loss = 0.61531050, grad/param norm = 2.3921e-01, time/batch = 18.9408s	
21416/22750 (epoch 47.068), train_loss = 0.61389132, grad/param norm = 1.9092e-01, time/batch = 20.0982s	
21417/22750 (epoch 47.070), train_loss = 0.52631513, grad/param norm = 1.9468e-01, time/batch = 16.7485s	
21418/22750 (epoch 47.073), train_loss = 0.63661973, grad/param norm = 2.2821e-01, time/batch = 17.6008s	
21419/22750 (epoch 47.075), train_loss = 0.69921154, grad/param norm = 2.3894e-01, time/batch = 16.8382s	
21420/22750 (epoch 47.077), train_loss = 0.51327081, grad/param norm = 2.3846e-01, time/batch = 17.3534s	
21421/22750 (epoch 47.079), train_loss = 0.67237690, grad/param norm = 2.3509e-01, time/batch = 17.5981s	
21422/22750 (epoch 47.081), train_loss = 0.64236401, grad/param norm = 2.3020e-01, time/batch = 17.0162s	
21423/22750 (epoch 47.084), train_loss = 0.63626895, grad/param norm = 2.3064e-01, time/batch = 16.2295s	
21424/22750 (epoch 47.086), train_loss = 0.67297721, grad/param norm = 2.0574e-01, time/batch = 16.3684s	
21425/22750 (epoch 47.088), train_loss = 0.65264521, grad/param norm = 2.4593e-01, time/batch = 19.0278s	
21426/22750 (epoch 47.090), train_loss = 0.65069257, grad/param norm = 2.3631e-01, time/batch = 16.7109s	
21427/22750 (epoch 47.092), train_loss = 0.73553709, grad/param norm = 2.4222e-01, time/batch = 16.7925s	
21428/22750 (epoch 47.095), train_loss = 0.61948037, grad/param norm = 2.2646e-01, time/batch = 19.2495s	
21429/22750 (epoch 47.097), train_loss = 0.70562121, grad/param norm = 2.6508e-01, time/batch = 19.1687s	
21430/22750 (epoch 47.099), train_loss = 0.63340783, grad/param norm = 2.9602e-01, time/batch = 17.6731s	
21431/22750 (epoch 47.101), train_loss = 0.58458500, grad/param norm = 2.7567e-01, time/batch = 18.5010s	
21432/22750 (epoch 47.103), train_loss = 0.71658357, grad/param norm = 2.6679e-01, time/batch = 19.1713s	
21433/22750 (epoch 47.105), train_loss = 0.76549833, grad/param norm = 2.9104e-01, time/batch = 18.0061s	
21434/22750 (epoch 47.108), train_loss = 0.72202150, grad/param norm = 2.4520e-01, time/batch = 17.9962s	
21435/22750 (epoch 47.110), train_loss = 0.76031431, grad/param norm = 2.3579e-01, time/batch = 17.1457s	
21436/22750 (epoch 47.112), train_loss = 0.56409064, grad/param norm = 2.0158e-01, time/batch = 20.2554s	
21437/22750 (epoch 47.114), train_loss = 0.51202821, grad/param norm = 2.2401e-01, time/batch = 17.2728s	
21438/22750 (epoch 47.116), train_loss = 0.69715662, grad/param norm = 2.3448e-01, time/batch = 19.3288s	
21439/22750 (epoch 47.119), train_loss = 0.64503440, grad/param norm = 2.1377e-01, time/batch = 20.6469s	
21440/22750 (epoch 47.121), train_loss = 0.66285026, grad/param norm = 3.0453e-01, time/batch = 18.4116s	
21441/22750 (epoch 47.123), train_loss = 0.58017407, grad/param norm = 2.5228e-01, time/batch = 18.7492s	
21442/22750 (epoch 47.125), train_loss = 0.74960920, grad/param norm = 2.2735e-01, time/batch = 19.1788s	
21443/22750 (epoch 47.127), train_loss = 0.64293712, grad/param norm = 2.3411e-01, time/batch = 16.5751s	
21444/22750 (epoch 47.130), train_loss = 0.66976587, grad/param norm = 2.2034e-01, time/batch = 16.1922s	
21445/22750 (epoch 47.132), train_loss = 0.62350393, grad/param norm = 2.1778e-01, time/batch = 18.1175s	
21446/22750 (epoch 47.134), train_loss = 0.65394921, grad/param norm = 2.1525e-01, time/batch = 16.5278s	
21447/22750 (epoch 47.136), train_loss = 0.54400383, grad/param norm = 2.4399e-01, time/batch = 18.0715s	
21448/22750 (epoch 47.138), train_loss = 0.74869508, grad/param norm = 2.4797e-01, time/batch = 18.3435s	
21449/22750 (epoch 47.141), train_loss = 0.65889085, grad/param norm = 2.3117e-01, time/batch = 18.9322s	
21450/22750 (epoch 47.143), train_loss = 0.63629311, grad/param norm = 2.1950e-01, time/batch = 16.5965s	
21451/22750 (epoch 47.145), train_loss = 0.78620096, grad/param norm = 2.8511e-01, time/batch = 19.1663s	
21452/22750 (epoch 47.147), train_loss = 0.82374249, grad/param norm = 2.3920e-01, time/batch = 17.5094s	
21453/22750 (epoch 47.149), train_loss = 0.69284410, grad/param norm = 2.4686e-01, time/batch = 16.5427s	
21454/22750 (epoch 47.152), train_loss = 0.69415062, grad/param norm = 2.4787e-01, time/batch = 16.8640s	
21455/22750 (epoch 47.154), train_loss = 0.60052958, grad/param norm = 2.5178e-01, time/batch = 17.9508s	
21456/22750 (epoch 47.156), train_loss = 0.62003424, grad/param norm = 2.3996e-01, time/batch = 17.1619s	
21457/22750 (epoch 47.158), train_loss = 0.57995439, grad/param norm = 2.1975e-01, time/batch = 18.6737s	
21458/22750 (epoch 47.160), train_loss = 0.66479121, grad/param norm = 2.6844e-01, time/batch = 18.8384s	
21459/22750 (epoch 47.163), train_loss = 0.79059114, grad/param norm = 2.3735e-01, time/batch = 19.3276s	
21460/22750 (epoch 47.165), train_loss = 0.73060905, grad/param norm = 2.3103e-01, time/batch = 18.2303s	
21461/22750 (epoch 47.167), train_loss = 0.63093858, grad/param norm = 2.5773e-01, time/batch = 18.7642s	
21462/22750 (epoch 47.169), train_loss = 0.66416962, grad/param norm = 2.6421e-01, time/batch = 19.0767s	
21463/22750 (epoch 47.171), train_loss = 0.57772967, grad/param norm = 2.2789e-01, time/batch = 17.5972s	
21464/22750 (epoch 47.174), train_loss = 0.55728829, grad/param norm = 2.3604e-01, time/batch = 19.1912s	
21465/22750 (epoch 47.176), train_loss = 0.58039805, grad/param norm = 2.2812e-01, time/batch = 16.2310s	
21466/22750 (epoch 47.178), train_loss = 0.63144279, grad/param norm = 2.6405e-01, time/batch = 19.0140s	
21467/22750 (epoch 47.180), train_loss = 0.76304726, grad/param norm = 3.7361e-01, time/batch = 18.9164s	
21468/22750 (epoch 47.182), train_loss = 0.70822717, grad/param norm = 2.4970e-01, time/batch = 18.7507s	
21469/22750 (epoch 47.185), train_loss = 0.76532339, grad/param norm = 2.7544e-01, time/batch = 19.1589s	
21470/22750 (epoch 47.187), train_loss = 0.58946262, grad/param norm = 2.3169e-01, time/batch = 17.7706s	
21471/22750 (epoch 47.189), train_loss = 0.59001416, grad/param norm = 2.1750e-01, time/batch = 17.0497s	
21472/22750 (epoch 47.191), train_loss = 0.62638416, grad/param norm = 1.9580e-01, time/batch = 20.0036s	
21473/22750 (epoch 47.193), train_loss = 0.70942538, grad/param norm = 2.0089e-01, time/batch = 18.5979s	
21474/22750 (epoch 47.196), train_loss = 0.64037645, grad/param norm = 2.3221e-01, time/batch = 19.7825s	
21475/22750 (epoch 47.198), train_loss = 0.48782255, grad/param norm = 2.2366e-01, time/batch = 18.2858s	
21476/22750 (epoch 47.200), train_loss = 0.67152899, grad/param norm = 2.1811e-01, time/batch = 17.3147s	
21477/22750 (epoch 47.202), train_loss = 0.71170520, grad/param norm = 2.6578e-01, time/batch = 18.2614s	
21478/22750 (epoch 47.204), train_loss = 0.69350843, grad/param norm = 2.4254e-01, time/batch = 18.6630s	
21479/22750 (epoch 47.207), train_loss = 0.71626814, grad/param norm = 2.4505e-01, time/batch = 17.6723s	
21480/22750 (epoch 47.209), train_loss = 0.63619802, grad/param norm = 2.3033e-01, time/batch = 18.0971s	
21481/22750 (epoch 47.211), train_loss = 0.58456090, grad/param norm = 2.4412e-01, time/batch = 16.3131s	
21482/22750 (epoch 47.213), train_loss = 0.50043306, grad/param norm = 2.2740e-01, time/batch = 16.3311s	
21483/22750 (epoch 47.215), train_loss = 0.49739519, grad/param norm = 1.8721e-01, time/batch = 16.4497s	
21484/22750 (epoch 47.218), train_loss = 0.59579038, grad/param norm = 2.5911e-01, time/batch = 17.1908s	
21485/22750 (epoch 47.220), train_loss = 0.56849556, grad/param norm = 2.2165e-01, time/batch = 16.6441s	
21486/22750 (epoch 47.222), train_loss = 0.55807012, grad/param norm = 2.4018e-01, time/batch = 17.4210s	
21487/22750 (epoch 47.224), train_loss = 0.56698112, grad/param norm = 1.9726e-01, time/batch = 18.5009s	
21488/22750 (epoch 47.226), train_loss = 0.65457150, grad/param norm = 2.5623e-01, time/batch = 17.4137s	
21489/22750 (epoch 47.229), train_loss = 0.66999869, grad/param norm = 2.3782e-01, time/batch = 19.0134s	
21490/22750 (epoch 47.231), train_loss = 0.58987979, grad/param norm = 2.4466e-01, time/batch = 17.7613s	
21491/22750 (epoch 47.233), train_loss = 0.53583407, grad/param norm = 2.5529e-01, time/batch = 19.7336s	
21492/22750 (epoch 47.235), train_loss = 0.53638859, grad/param norm = 2.3037e-01, time/batch = 19.4230s	
21493/22750 (epoch 47.237), train_loss = 0.58313156, grad/param norm = 2.3288e-01, time/batch = 18.4225s	
21494/22750 (epoch 47.240), train_loss = 0.67903363, grad/param norm = 2.1886e-01, time/batch = 18.4479s	
21495/22750 (epoch 47.242), train_loss = 0.77200327, grad/param norm = 2.9179e-01, time/batch = 18.6989s	
21496/22750 (epoch 47.244), train_loss = 0.78263633, grad/param norm = 2.6282e-01, time/batch = 16.6903s	
21497/22750 (epoch 47.246), train_loss = 0.79978455, grad/param norm = 2.9861e-01, time/batch = 18.6629s	
21498/22750 (epoch 47.248), train_loss = 0.67162236, grad/param norm = 2.1483e-01, time/batch = 18.5892s	
21499/22750 (epoch 47.251), train_loss = 0.72226265, grad/param norm = 2.3955e-01, time/batch = 17.0681s	
21500/22750 (epoch 47.253), train_loss = 0.72211247, grad/param norm = 3.2592e-01, time/batch = 17.0138s	
21501/22750 (epoch 47.255), train_loss = 0.70620482, grad/param norm = 2.3256e-01, time/batch = 19.9930s	
21502/22750 (epoch 47.257), train_loss = 0.60689939, grad/param norm = 2.3424e-01, time/batch = 18.7765s	
21503/22750 (epoch 47.259), train_loss = 0.74670002, grad/param norm = 3.3887e-01, time/batch = 18.7914s	
21504/22750 (epoch 47.262), train_loss = 0.70532926, grad/param norm = 2.6568e-01, time/batch = 19.1971s	
21505/22750 (epoch 47.264), train_loss = 0.52549658, grad/param norm = 2.2219e-01, time/batch = 18.6560s	
21506/22750 (epoch 47.266), train_loss = 0.65264363, grad/param norm = 2.7268e-01, time/batch = 15.9868s	
21507/22750 (epoch 47.268), train_loss = 0.79293269, grad/param norm = 2.5132e-01, time/batch = 17.5998s	
21508/22750 (epoch 47.270), train_loss = 0.62338524, grad/param norm = 2.7579e-01, time/batch = 17.0074s	
21509/22750 (epoch 47.273), train_loss = 0.91377529, grad/param norm = 3.0469e-01, time/batch = 17.1621s	
21510/22750 (epoch 47.275), train_loss = 0.79555601, grad/param norm = 2.3708e-01, time/batch = 17.7342s	
21511/22750 (epoch 47.277), train_loss = 0.67332640, grad/param norm = 2.7726e-01, time/batch = 17.4744s	
21512/22750 (epoch 47.279), train_loss = 0.57797649, grad/param norm = 2.2844e-01, time/batch = 16.9244s	
21513/22750 (epoch 47.281), train_loss = 0.77311052, grad/param norm = 2.4541e-01, time/batch = 17.2973s	
21514/22750 (epoch 47.284), train_loss = 0.71750936, grad/param norm = 2.2681e-01, time/batch = 18.2609s	
21515/22750 (epoch 47.286), train_loss = 0.73545290, grad/param norm = 2.4938e-01, time/batch = 20.6868s	
21516/22750 (epoch 47.288), train_loss = 0.81924409, grad/param norm = 2.8318e-01, time/batch = 19.0706s	
21517/22750 (epoch 47.290), train_loss = 0.73530955, grad/param norm = 2.4599e-01, time/batch = 19.5749s	
21518/22750 (epoch 47.292), train_loss = 0.73445658, grad/param norm = 3.1184e-01, time/batch = 16.3953s	
21519/22750 (epoch 47.295), train_loss = 0.71436762, grad/param norm = 2.1961e-01, time/batch = 17.1580s	
21520/22750 (epoch 47.297), train_loss = 0.71048140, grad/param norm = 2.5505e-01, time/batch = 17.2606s	
21521/22750 (epoch 47.299), train_loss = 0.74397430, grad/param norm = 2.7886e-01, time/batch = 16.7538s	
21522/22750 (epoch 47.301), train_loss = 0.65504444, grad/param norm = 2.7788e-01, time/batch = 18.3350s	
21523/22750 (epoch 47.303), train_loss = 0.71906142, grad/param norm = 2.5729e-01, time/batch = 17.1837s	
21524/22750 (epoch 47.305), train_loss = 0.78525652, grad/param norm = 2.3788e-01, time/batch = 19.8521s	
21525/22750 (epoch 47.308), train_loss = 0.75975881, grad/param norm = 2.6333e-01, time/batch = 19.3560s	
21526/22750 (epoch 47.310), train_loss = 0.62346963, grad/param norm = 2.5263e-01, time/batch = 18.5808s	
21527/22750 (epoch 47.312), train_loss = 0.68750875, grad/param norm = 2.4297e-01, time/batch = 17.0721s	
21528/22750 (epoch 47.314), train_loss = 0.72230953, grad/param norm = 2.8320e-01, time/batch = 17.6574s	
21529/22750 (epoch 47.316), train_loss = 0.67925799, grad/param norm = 2.6136e-01, time/batch = 18.6780s	
21530/22750 (epoch 47.319), train_loss = 0.72710700, grad/param norm = 2.7946e-01, time/batch = 20.3098s	
21531/22750 (epoch 47.321), train_loss = 0.64931763, grad/param norm = 2.5605e-01, time/batch = 17.1953s	
21532/22750 (epoch 47.323), train_loss = 0.72838003, grad/param norm = 2.4739e-01, time/batch = 16.5605s	
21533/22750 (epoch 47.325), train_loss = 0.61050012, grad/param norm = 2.4412e-01, time/batch = 16.9066s	
21534/22750 (epoch 47.327), train_loss = 0.63160051, grad/param norm = 2.5210e-01, time/batch = 19.3408s	
21535/22750 (epoch 47.330), train_loss = 0.79112819, grad/param norm = 2.4749e-01, time/batch = 18.4487s	
21536/22750 (epoch 47.332), train_loss = 0.87775040, grad/param norm = 2.7605e-01, time/batch = 18.4306s	
21537/22750 (epoch 47.334), train_loss = 0.58241570, grad/param norm = 2.2431e-01, time/batch = 16.2325s	
21538/22750 (epoch 47.336), train_loss = 0.75844490, grad/param norm = 2.2393e-01, time/batch = 17.0153s	
21539/22750 (epoch 47.338), train_loss = 0.69379221, grad/param norm = 2.6874e-01, time/batch = 17.1059s	
21540/22750 (epoch 47.341), train_loss = 0.68367545, grad/param norm = 2.3479e-01, time/batch = 17.3370s	
21541/22750 (epoch 47.343), train_loss = 0.59616265, grad/param norm = 2.4544e-01, time/batch = 19.8350s	
21542/22750 (epoch 47.345), train_loss = 0.73562640, grad/param norm = 3.3924e-01, time/batch = 23.4109s	
21543/22750 (epoch 47.347), train_loss = 0.75464265, grad/param norm = 2.5303e-01, time/batch = 28.9413s	
21544/22750 (epoch 47.349), train_loss = 0.56892453, grad/param norm = 2.3777e-01, time/batch = 16.4978s	
21545/22750 (epoch 47.352), train_loss = 0.81568367, grad/param norm = 2.7696e-01, time/batch = 17.3150s	
21546/22750 (epoch 47.354), train_loss = 0.77588468, grad/param norm = 2.6932e-01, time/batch = 16.0283s	
21547/22750 (epoch 47.356), train_loss = 0.73007458, grad/param norm = 2.2215e-01, time/batch = 16.5881s	
21548/22750 (epoch 47.358), train_loss = 0.65602841, grad/param norm = 2.4732e-01, time/batch = 16.1671s	
21549/22750 (epoch 47.360), train_loss = 0.82248889, grad/param norm = 2.3674e-01, time/batch = 15.7962s	
21550/22750 (epoch 47.363), train_loss = 0.65586200, grad/param norm = 2.6241e-01, time/batch = 16.0957s	
21551/22750 (epoch 47.365), train_loss = 0.56732877, grad/param norm = 2.4958e-01, time/batch = 15.6113s	
21552/22750 (epoch 47.367), train_loss = 0.63741395, grad/param norm = 2.6887e-01, time/batch = 16.0170s	
21553/22750 (epoch 47.369), train_loss = 0.70309967, grad/param norm = 2.7664e-01, time/batch = 15.9358s	
21554/22750 (epoch 47.371), train_loss = 0.71787082, grad/param norm = 2.7805e-01, time/batch = 16.2420s	
21555/22750 (epoch 47.374), train_loss = 0.63492744, grad/param norm = 2.9099e-01, time/batch = 15.6944s	
21556/22750 (epoch 47.376), train_loss = 0.69825673, grad/param norm = 2.4423e-01, time/batch = 16.4983s	
21557/22750 (epoch 47.378), train_loss = 0.70361282, grad/param norm = 2.3300e-01, time/batch = 15.6830s	
21558/22750 (epoch 47.380), train_loss = 0.75458442, grad/param norm = 2.3331e-01, time/batch = 15.6236s	
21559/22750 (epoch 47.382), train_loss = 0.66080141, grad/param norm = 2.3135e-01, time/batch = 16.4770s	
21560/22750 (epoch 47.385), train_loss = 0.74848705, grad/param norm = 2.5534e-01, time/batch = 16.1733s	
21561/22750 (epoch 47.387), train_loss = 0.71933652, grad/param norm = 2.5845e-01, time/batch = 15.3838s	
21562/22750 (epoch 47.389), train_loss = 0.56683212, grad/param norm = 2.1083e-01, time/batch = 15.4715s	
21563/22750 (epoch 47.391), train_loss = 0.43751366, grad/param norm = 1.8776e-01, time/batch = 15.6950s	
21564/22750 (epoch 47.393), train_loss = 0.57293045, grad/param norm = 2.1439e-01, time/batch = 16.0076s	
21565/22750 (epoch 47.396), train_loss = 0.70893180, grad/param norm = 2.2559e-01, time/batch = 16.3164s	
21566/22750 (epoch 47.398), train_loss = 0.65487967, grad/param norm = 2.0935e-01, time/batch = 15.5333s	
21567/22750 (epoch 47.400), train_loss = 0.71303951, grad/param norm = 3.1056e-01, time/batch = 15.8385s	
21568/22750 (epoch 47.402), train_loss = 0.68956644, grad/param norm = 2.5206e-01, time/batch = 15.7766s	
21569/22750 (epoch 47.404), train_loss = 0.78092301, grad/param norm = 2.6482e-01, time/batch = 15.1935s	
21570/22750 (epoch 47.407), train_loss = 0.77204677, grad/param norm = 2.5633e-01, time/batch = 15.6075s	
21571/22750 (epoch 47.409), train_loss = 0.63490451, grad/param norm = 2.7528e-01, time/batch = 15.9353s	
21572/22750 (epoch 47.411), train_loss = 0.62902500, grad/param norm = 2.0994e-01, time/batch = 15.4696s	
21573/22750 (epoch 47.413), train_loss = 0.48748108, grad/param norm = 2.2753e-01, time/batch = 15.7727s	
21574/22750 (epoch 47.415), train_loss = 0.57352615, grad/param norm = 2.5519e-01, time/batch = 16.3095s	
21575/22750 (epoch 47.418), train_loss = 0.65672072, grad/param norm = 2.5552e-01, time/batch = 16.4184s	
21576/22750 (epoch 47.420), train_loss = 0.74540108, grad/param norm = 3.0144e-01, time/batch = 15.6908s	
21577/22750 (epoch 47.422), train_loss = 0.83917972, grad/param norm = 2.7993e-01, time/batch = 16.1692s	
21578/22750 (epoch 47.424), train_loss = 0.86308003, grad/param norm = 2.6740e-01, time/batch = 15.6066s	
21579/22750 (epoch 47.426), train_loss = 0.86366468, grad/param norm = 2.5643e-01, time/batch = 16.3156s	
21580/22750 (epoch 47.429), train_loss = 0.62352800, grad/param norm = 2.1704e-01, time/batch = 15.5990s	
21581/22750 (epoch 47.431), train_loss = 0.56963526, grad/param norm = 2.0429e-01, time/batch = 16.0143s	
21582/22750 (epoch 47.433), train_loss = 0.64303936, grad/param norm = 2.3332e-01, time/batch = 16.7961s	
21583/22750 (epoch 47.435), train_loss = 0.50197049, grad/param norm = 1.8732e-01, time/batch = 16.1787s	
21584/22750 (epoch 47.437), train_loss = 0.44468353, grad/param norm = 2.3833e-01, time/batch = 16.6682s	
21585/22750 (epoch 47.440), train_loss = 0.64426266, grad/param norm = 2.3904e-01, time/batch = 15.7049s	
21586/22750 (epoch 47.442), train_loss = 0.69304726, grad/param norm = 2.6787e-01, time/batch = 16.2656s	
21587/22750 (epoch 47.444), train_loss = 0.64790046, grad/param norm = 2.5041e-01, time/batch = 16.3251s	
21588/22750 (epoch 47.446), train_loss = 0.63400337, grad/param norm = 2.5718e-01, time/batch = 15.4575s	
21589/22750 (epoch 47.448), train_loss = 0.84685080, grad/param norm = 2.5801e-01, time/batch = 16.0273s	
21590/22750 (epoch 47.451), train_loss = 0.82542414, grad/param norm = 2.9826e-01, time/batch = 16.0965s	
21591/22750 (epoch 47.453), train_loss = 0.70585181, grad/param norm = 3.2606e-01, time/batch = 16.1778s	
21592/22750 (epoch 47.455), train_loss = 0.81178261, grad/param norm = 2.6057e-01, time/batch = 16.4297s	
21593/22750 (epoch 47.457), train_loss = 0.72652903, grad/param norm = 3.2536e-01, time/batch = 16.5041s	
21594/22750 (epoch 47.459), train_loss = 0.75081385, grad/param norm = 2.3198e-01, time/batch = 15.6895s	
21595/22750 (epoch 47.462), train_loss = 0.69188723, grad/param norm = 2.3870e-01, time/batch = 15.7776s	
21596/22750 (epoch 47.464), train_loss = 0.58864338, grad/param norm = 2.3870e-01, time/batch = 16.0181s	
21597/22750 (epoch 47.466), train_loss = 0.75077215, grad/param norm = 3.1799e-01, time/batch = 16.1841s	
21598/22750 (epoch 47.468), train_loss = 0.70530822, grad/param norm = 2.2648e-01, time/batch = 15.6271s	
21599/22750 (epoch 47.470), train_loss = 0.78624095, grad/param norm = 2.6175e-01, time/batch = 15.9275s	
21600/22750 (epoch 47.473), train_loss = 0.66775754, grad/param norm = 2.3959e-01, time/batch = 15.7042s	
21601/22750 (epoch 47.475), train_loss = 0.69499590, grad/param norm = 2.4807e-01, time/batch = 16.5591s	
21602/22750 (epoch 47.477), train_loss = 0.60853814, grad/param norm = 2.5120e-01, time/batch = 16.6517s	
21603/22750 (epoch 47.479), train_loss = 0.57869268, grad/param norm = 2.2668e-01, time/batch = 16.5084s	
21604/22750 (epoch 47.481), train_loss = 0.55543611, grad/param norm = 1.8754e-01, time/batch = 16.6577s	
21605/22750 (epoch 47.484), train_loss = 0.48343176, grad/param norm = 2.4840e-01, time/batch = 16.1897s	
21606/22750 (epoch 47.486), train_loss = 0.54425010, grad/param norm = 1.8680e-01, time/batch = 15.6901s	
21607/22750 (epoch 47.488), train_loss = 0.53911575, grad/param norm = 2.9577e-01, time/batch = 16.1786s	
21608/22750 (epoch 47.490), train_loss = 0.64869214, grad/param norm = 2.3236e-01, time/batch = 16.5023s	
21609/22750 (epoch 47.492), train_loss = 0.74562531, grad/param norm = 2.5529e-01, time/batch = 16.1779s	
21610/22750 (epoch 47.495), train_loss = 0.64132828, grad/param norm = 2.8523e-01, time/batch = 16.5993s	
21611/22750 (epoch 47.497), train_loss = 0.65273076, grad/param norm = 2.7904e-01, time/batch = 16.5772s	
21612/22750 (epoch 47.499), train_loss = 0.60038807, grad/param norm = 2.7708e-01, time/batch = 17.0439s	
21613/22750 (epoch 47.501), train_loss = 0.62706607, grad/param norm = 2.4754e-01, time/batch = 16.4083s	
21614/22750 (epoch 47.503), train_loss = 0.64038359, grad/param norm = 2.1973e-01, time/batch = 16.5520s	
21615/22750 (epoch 47.505), train_loss = 0.58240489, grad/param norm = 3.0678e-01, time/batch = 16.0636s	
21616/22750 (epoch 47.508), train_loss = 0.57294545, grad/param norm = 2.2644e-01, time/batch = 16.2289s	
21617/22750 (epoch 47.510), train_loss = 0.56649045, grad/param norm = 2.5154e-01, time/batch = 15.4206s	
21618/22750 (epoch 47.512), train_loss = 0.62029495, grad/param norm = 2.5430e-01, time/batch = 15.7622s	
21619/22750 (epoch 47.514), train_loss = 0.62596952, grad/param norm = 2.3137e-01, time/batch = 16.6691s	
21620/22750 (epoch 47.516), train_loss = 0.60101141, grad/param norm = 2.3470e-01, time/batch = 16.3067s	
21621/22750 (epoch 47.519), train_loss = 0.75674250, grad/param norm = 2.4971e-01, time/batch = 16.9069s	
21622/22750 (epoch 47.521), train_loss = 0.67176774, grad/param norm = 2.4842e-01, time/batch = 19.8605s	
21623/22750 (epoch 47.523), train_loss = 0.57279319, grad/param norm = 2.6227e-01, time/batch = 16.9848s	
21624/22750 (epoch 47.525), train_loss = 0.73451526, grad/param norm = 2.4020e-01, time/batch = 17.2717s	
21625/22750 (epoch 47.527), train_loss = 0.68741402, grad/param norm = 2.3046e-01, time/batch = 18.7263s	
21626/22750 (epoch 47.530), train_loss = 0.60725620, grad/param norm = 2.3487e-01, time/batch = 17.5781s	
21627/22750 (epoch 47.532), train_loss = 0.55048843, grad/param norm = 2.1643e-01, time/batch = 20.0581s	
21628/22750 (epoch 47.534), train_loss = 0.72050894, grad/param norm = 3.2913e-01, time/batch = 18.0617s	
21629/22750 (epoch 47.536), train_loss = 0.70687438, grad/param norm = 2.0147e-01, time/batch = 17.2471s	
21630/22750 (epoch 47.538), train_loss = 0.68952748, grad/param norm = 2.3805e-01, time/batch = 16.8344s	
21631/22750 (epoch 47.541), train_loss = 0.58708225, grad/param norm = 2.3419e-01, time/batch = 17.0119s	
21632/22750 (epoch 47.543), train_loss = 0.56579887, grad/param norm = 2.2384e-01, time/batch = 19.5720s	
21633/22750 (epoch 47.545), train_loss = 0.73228703, grad/param norm = 2.9577e-01, time/batch = 18.3555s	
21634/22750 (epoch 47.547), train_loss = 0.63179703, grad/param norm = 2.0419e-01, time/batch = 17.0125s	
21635/22750 (epoch 47.549), train_loss = 0.65433592, grad/param norm = 2.4870e-01, time/batch = 18.8075s	
21636/22750 (epoch 47.552), train_loss = 0.69373153, grad/param norm = 2.5615e-01, time/batch = 17.4810s	
21637/22750 (epoch 47.554), train_loss = 0.68936550, grad/param norm = 2.4798e-01, time/batch = 17.5885s	
21638/22750 (epoch 47.556), train_loss = 0.70532476, grad/param norm = 2.6850e-01, time/batch = 18.9261s	
21639/22750 (epoch 47.558), train_loss = 0.64990176, grad/param norm = 2.4594e-01, time/batch = 18.7452s	
21640/22750 (epoch 47.560), train_loss = 0.62359675, grad/param norm = 2.2153e-01, time/batch = 16.5424s	
21641/22750 (epoch 47.563), train_loss = 0.73837390, grad/param norm = 2.8310e-01, time/batch = 16.5936s	
21642/22750 (epoch 47.565), train_loss = 0.72336322, grad/param norm = 2.5065e-01, time/batch = 17.6696s	
21643/22750 (epoch 47.567), train_loss = 0.68504360, grad/param norm = 2.2035e-01, time/batch = 19.2620s	
21644/22750 (epoch 47.569), train_loss = 0.66254728, grad/param norm = 2.0703e-01, time/batch = 18.1197s	
21645/22750 (epoch 47.571), train_loss = 0.64739692, grad/param norm = 2.4631e-01, time/batch = 20.5266s	
21646/22750 (epoch 47.574), train_loss = 0.66928474, grad/param norm = 2.8294e-01, time/batch = 18.3180s	
21647/22750 (epoch 47.576), train_loss = 0.66164188, grad/param norm = 2.0295e-01, time/batch = 17.3428s	
21648/22750 (epoch 47.578), train_loss = 0.55758888, grad/param norm = 2.1792e-01, time/batch = 17.6553s	
21649/22750 (epoch 47.580), train_loss = 0.69690010, grad/param norm = 2.5258e-01, time/batch = 17.1254s	
21650/22750 (epoch 47.582), train_loss = 0.61909728, grad/param norm = 2.1128e-01, time/batch = 15.9450s	
21651/22750 (epoch 47.585), train_loss = 0.57789910, grad/param norm = 2.2787e-01, time/batch = 16.3338s	
21652/22750 (epoch 47.587), train_loss = 0.59108136, grad/param norm = 2.2786e-01, time/batch = 16.0858s	
21653/22750 (epoch 47.589), train_loss = 0.49752611, grad/param norm = 1.8630e-01, time/batch = 15.5325s	
21654/22750 (epoch 47.591), train_loss = 0.65025510, grad/param norm = 2.0987e-01, time/batch = 14.9175s	
21655/22750 (epoch 47.593), train_loss = 0.76894941, grad/param norm = 2.5949e-01, time/batch = 16.4470s	
21656/22750 (epoch 47.596), train_loss = 0.72747843, grad/param norm = 2.6681e-01, time/batch = 16.6516s	
21657/22750 (epoch 47.598), train_loss = 0.73315603, grad/param norm = 3.2227e-01, time/batch = 15.1480s	
21658/22750 (epoch 47.600), train_loss = 0.82423592, grad/param norm = 2.6963e-01, time/batch = 15.2856s	
21659/22750 (epoch 47.602), train_loss = 0.59099031, grad/param norm = 1.9897e-01, time/batch = 15.3841s	
21660/22750 (epoch 47.604), train_loss = 0.63316221, grad/param norm = 2.3829e-01, time/batch = 15.6807s	
21661/22750 (epoch 47.607), train_loss = 0.59405079, grad/param norm = 2.1532e-01, time/batch = 15.1381s	
21662/22750 (epoch 47.609), train_loss = 0.57779701, grad/param norm = 2.5061e-01, time/batch = 15.3744s	
21663/22750 (epoch 47.611), train_loss = 0.62275858, grad/param norm = 2.3499e-01, time/batch = 16.0754s	
21664/22750 (epoch 47.613), train_loss = 0.59759162, grad/param norm = 2.3043e-01, time/batch = 15.5291s	
21665/22750 (epoch 47.615), train_loss = 0.62818357, grad/param norm = 2.2259e-01, time/batch = 16.1575s	
21666/22750 (epoch 47.618), train_loss = 0.65758225, grad/param norm = 2.1342e-01, time/batch = 15.5423s	
21667/22750 (epoch 47.620), train_loss = 0.64093076, grad/param norm = 2.7674e-01, time/batch = 15.4035s	
21668/22750 (epoch 47.622), train_loss = 0.57056833, grad/param norm = 2.1789e-01, time/batch = 16.7268s	
21669/22750 (epoch 47.624), train_loss = 0.60869836, grad/param norm = 2.1977e-01, time/batch = 16.6258s	
21670/22750 (epoch 47.626), train_loss = 0.53730313, grad/param norm = 2.0905e-01, time/batch = 15.7635s	
21671/22750 (epoch 47.629), train_loss = 0.59650665, grad/param norm = 2.1321e-01, time/batch = 15.8388s	
21672/22750 (epoch 47.631), train_loss = 0.63806726, grad/param norm = 2.1841e-01, time/batch = 16.2531s	
21673/22750 (epoch 47.633), train_loss = 0.56089474, grad/param norm = 2.0802e-01, time/batch = 15.7830s	
21674/22750 (epoch 47.635), train_loss = 0.64537287, grad/param norm = 2.2686e-01, time/batch = 15.2959s	
21675/22750 (epoch 47.637), train_loss = 0.68606818, grad/param norm = 2.6964e-01, time/batch = 15.2091s	
21676/22750 (epoch 47.640), train_loss = 0.69582324, grad/param norm = 2.5467e-01, time/batch = 15.2047s	
21677/22750 (epoch 47.642), train_loss = 0.72376488, grad/param norm = 2.3128e-01, time/batch = 15.1375s	
21678/22750 (epoch 47.644), train_loss = 0.66188612, grad/param norm = 2.4403e-01, time/batch = 15.2920s	
21679/22750 (epoch 47.646), train_loss = 0.72975685, grad/param norm = 2.9440e-01, time/batch = 15.3117s	
21680/22750 (epoch 47.648), train_loss = 0.71318728, grad/param norm = 2.3277e-01, time/batch = 15.0774s	
21681/22750 (epoch 47.651), train_loss = 0.70078045, grad/param norm = 2.3909e-01, time/batch = 16.0982s	
21682/22750 (epoch 47.653), train_loss = 0.73272754, grad/param norm = 2.1001e-01, time/batch = 15.7512s	
21683/22750 (epoch 47.655), train_loss = 0.67521653, grad/param norm = 2.0242e-01, time/batch = 15.9410s	
21684/22750 (epoch 47.657), train_loss = 0.78440733, grad/param norm = 2.5524e-01, time/batch = 15.7006s	
21685/22750 (epoch 47.659), train_loss = 0.83711698, grad/param norm = 2.7468e-01, time/batch = 15.1317s	
21686/22750 (epoch 47.662), train_loss = 0.81346144, grad/param norm = 3.0764e-01, time/batch = 15.7571s	
21687/22750 (epoch 47.664), train_loss = 0.69164376, grad/param norm = 2.5589e-01, time/batch = 16.4681s	
21688/22750 (epoch 47.666), train_loss = 0.58767967, grad/param norm = 2.1628e-01, time/batch = 15.4572s	
21689/22750 (epoch 47.668), train_loss = 0.63682656, grad/param norm = 2.2375e-01, time/batch = 15.2891s	
21690/22750 (epoch 47.670), train_loss = 0.60793467, grad/param norm = 2.4783e-01, time/batch = 15.2967s	
21691/22750 (epoch 47.673), train_loss = 0.80291422, grad/param norm = 2.4336e-01, time/batch = 15.6441s	
21692/22750 (epoch 47.675), train_loss = 0.90908186, grad/param norm = 3.1204e-01, time/batch = 15.1461s	
21693/22750 (epoch 47.677), train_loss = 0.78043687, grad/param norm = 2.8608e-01, time/batch = 16.3268s	
21694/22750 (epoch 47.679), train_loss = 0.76939959, grad/param norm = 2.7714e-01, time/batch = 15.9913s	
21695/22750 (epoch 47.681), train_loss = 0.77618456, grad/param norm = 2.6564e-01, time/batch = 15.5219s	
21696/22750 (epoch 47.684), train_loss = 0.82792572, grad/param norm = 2.5990e-01, time/batch = 15.6075s	
21697/22750 (epoch 47.686), train_loss = 0.85065204, grad/param norm = 3.2333e-01, time/batch = 15.2176s	
21698/22750 (epoch 47.688), train_loss = 0.79823887, grad/param norm = 2.7291e-01, time/batch = 15.3703s	
21699/22750 (epoch 47.690), train_loss = 0.79032644, grad/param norm = 2.6640e-01, time/batch = 15.2120s	
21700/22750 (epoch 47.692), train_loss = 0.80095000, grad/param norm = 2.8386e-01, time/batch = 15.1189s	
21701/22750 (epoch 47.695), train_loss = 0.72462203, grad/param norm = 2.3462e-01, time/batch = 15.3663s	
21702/22750 (epoch 47.697), train_loss = 0.72829713, grad/param norm = 2.4293e-01, time/batch = 15.2966s	
21703/22750 (epoch 47.699), train_loss = 0.63016302, grad/param norm = 2.1634e-01, time/batch = 15.7126s	
21704/22750 (epoch 47.701), train_loss = 0.57364474, grad/param norm = 2.3324e-01, time/batch = 15.2284s	
21705/22750 (epoch 47.703), train_loss = 0.65005846, grad/param norm = 2.6605e-01, time/batch = 15.1617s	
21706/22750 (epoch 47.705), train_loss = 0.62116313, grad/param norm = 2.7536e-01, time/batch = 15.7055s	
21707/22750 (epoch 47.708), train_loss = 0.67924260, grad/param norm = 2.9656e-01, time/batch = 15.0543s	
21708/22750 (epoch 47.710), train_loss = 0.59163270, grad/param norm = 2.0249e-01, time/batch = 15.2144s	
21709/22750 (epoch 47.712), train_loss = 0.51228946, grad/param norm = 1.9547e-01, time/batch = 15.6149s	
21710/22750 (epoch 47.714), train_loss = 0.58571397, grad/param norm = 2.2645e-01, time/batch = 15.8342s	
21711/22750 (epoch 47.716), train_loss = 0.58423417, grad/param norm = 2.2045e-01, time/batch = 15.5287s	
21712/22750 (epoch 47.719), train_loss = 0.66015088, grad/param norm = 3.5981e-01, time/batch = 15.2186s	
21713/22750 (epoch 47.721), train_loss = 0.79060315, grad/param norm = 2.7642e-01, time/batch = 16.0002s	
21714/22750 (epoch 47.723), train_loss = 0.73436296, grad/param norm = 2.9904e-01, time/batch = 16.5067s	
21715/22750 (epoch 47.725), train_loss = 0.63964154, grad/param norm = 2.7527e-01, time/batch = 15.8141s	
21716/22750 (epoch 47.727), train_loss = 0.67568324, grad/param norm = 2.3881e-01, time/batch = 15.8046s	
21717/22750 (epoch 47.730), train_loss = 0.64780875, grad/param norm = 2.4206e-01, time/batch = 15.5563s	
21718/22750 (epoch 47.732), train_loss = 0.63139426, grad/param norm = 2.5658e-01, time/batch = 16.1943s	
21719/22750 (epoch 47.734), train_loss = 0.56895475, grad/param norm = 2.0674e-01, time/batch = 15.2987s	
21720/22750 (epoch 47.736), train_loss = 0.64125646, grad/param norm = 2.5629e-01, time/batch = 15.6218s	
21721/22750 (epoch 47.738), train_loss = 0.70349000, grad/param norm = 2.8877e-01, time/batch = 15.5342s	
21722/22750 (epoch 47.741), train_loss = 0.78581063, grad/param norm = 2.5585e-01, time/batch = 16.3982s	
21723/22750 (epoch 47.743), train_loss = 0.68177892, grad/param norm = 2.6560e-01, time/batch = 15.9444s	
21724/22750 (epoch 47.745), train_loss = 0.56917263, grad/param norm = 2.0024e-01, time/batch = 16.6474s	
21725/22750 (epoch 47.747), train_loss = 0.67743399, grad/param norm = 2.2331e-01, time/batch = 16.3079s	
21726/22750 (epoch 47.749), train_loss = 0.78631695, grad/param norm = 2.9478e-01, time/batch = 15.5417s	
21727/22750 (epoch 47.752), train_loss = 0.70204500, grad/param norm = 2.6033e-01, time/batch = 15.4031s	
21728/22750 (epoch 47.754), train_loss = 0.67404300, grad/param norm = 2.3593e-01, time/batch = 15.2995s	
21729/22750 (epoch 47.756), train_loss = 0.62329752, grad/param norm = 2.4611e-01, time/batch = 15.7264s	
21730/22750 (epoch 47.758), train_loss = 0.61409247, grad/param norm = 2.3837e-01, time/batch = 15.4705s	
21731/22750 (epoch 47.760), train_loss = 0.60853512, grad/param norm = 2.5658e-01, time/batch = 15.3005s	
21732/22750 (epoch 47.763), train_loss = 0.64840960, grad/param norm = 2.3751e-01, time/batch = 15.0554s	
21733/22750 (epoch 47.765), train_loss = 0.64470442, grad/param norm = 2.3786e-01, time/batch = 16.1775s	
21734/22750 (epoch 47.767), train_loss = 0.70012683, grad/param norm = 2.2670e-01, time/batch = 15.4581s	
21735/22750 (epoch 47.769), train_loss = 0.78494602, grad/param norm = 2.9911e-01, time/batch = 15.6217s	
21736/22750 (epoch 47.771), train_loss = 0.79130657, grad/param norm = 2.5440e-01, time/batch = 15.2925s	
21737/22750 (epoch 47.774), train_loss = 0.61723198, grad/param norm = 2.5237e-01, time/batch = 15.5972s	
21738/22750 (epoch 47.776), train_loss = 0.74632007, grad/param norm = 2.5819e-01, time/batch = 14.9621s	
21739/22750 (epoch 47.778), train_loss = 0.77223579, grad/param norm = 2.4837e-01, time/batch = 15.6199s	
21740/22750 (epoch 47.780), train_loss = 0.70537618, grad/param norm = 2.4548e-01, time/batch = 15.3030s	
21741/22750 (epoch 47.782), train_loss = 0.79321170, grad/param norm = 2.6852e-01, time/batch = 16.0305s	
21742/22750 (epoch 47.785), train_loss = 0.66659921, grad/param norm = 2.6314e-01, time/batch = 20.1885s	
21743/22750 (epoch 47.787), train_loss = 0.57810139, grad/param norm = 2.5275e-01, time/batch = 15.8683s	
21744/22750 (epoch 47.789), train_loss = 0.65287312, grad/param norm = 2.1236e-01, time/batch = 17.1847s	
21745/22750 (epoch 47.791), train_loss = 0.63830966, grad/param norm = 2.5296e-01, time/batch = 16.3258s	
21746/22750 (epoch 47.793), train_loss = 0.61317620, grad/param norm = 2.9083e-01, time/batch = 16.5981s	
21747/22750 (epoch 47.796), train_loss = 0.57001741, grad/param norm = 2.1775e-01, time/batch = 15.7576s	
21748/22750 (epoch 47.798), train_loss = 0.63098955, grad/param norm = 2.1734e-01, time/batch = 17.2437s	
21749/22750 (epoch 47.800), train_loss = 0.62273486, grad/param norm = 2.5663e-01, time/batch = 16.6745s	
21750/22750 (epoch 47.802), train_loss = 0.58393180, grad/param norm = 2.9998e-01, time/batch = 16.9532s	
21751/22750 (epoch 47.804), train_loss = 0.73530114, grad/param norm = 2.1113e-01, time/batch = 18.8508s	
21752/22750 (epoch 47.807), train_loss = 0.70865389, grad/param norm = 2.4576e-01, time/batch = 18.3779s	
21753/22750 (epoch 47.809), train_loss = 0.80032763, grad/param norm = 2.9459e-01, time/batch = 19.4442s	
21754/22750 (epoch 47.811), train_loss = 0.68818191, grad/param norm = 2.6105e-01, time/batch = 18.5125s	
21755/22750 (epoch 47.813), train_loss = 0.70091560, grad/param norm = 2.3041e-01, time/batch = 18.1764s	
21756/22750 (epoch 47.815), train_loss = 0.77537127, grad/param norm = 2.5539e-01, time/batch = 16.8169s	
21757/22750 (epoch 47.818), train_loss = 0.76030215, grad/param norm = 2.5092e-01, time/batch = 19.8213s	
21758/22750 (epoch 47.820), train_loss = 0.83789751, grad/param norm = 2.3188e-01, time/batch = 17.3227s	
21759/22750 (epoch 47.822), train_loss = 0.71054101, grad/param norm = 2.3425e-01, time/batch = 20.4056s	
21760/22750 (epoch 47.824), train_loss = 0.60347904, grad/param norm = 2.1462e-01, time/batch = 19.1835s	
21761/22750 (epoch 47.826), train_loss = 0.65660174, grad/param norm = 2.4852e-01, time/batch = 31.0231s	
21762/22750 (epoch 47.829), train_loss = 0.74417531, grad/param norm = 2.4697e-01, time/batch = 18.7742s	
21763/22750 (epoch 47.831), train_loss = 0.75697898, grad/param norm = 2.5657e-01, time/batch = 16.9034s	
21764/22750 (epoch 47.833), train_loss = 0.69954288, grad/param norm = 2.7545e-01, time/batch = 16.3375s	
21765/22750 (epoch 47.835), train_loss = 0.61142582, grad/param norm = 2.7710e-01, time/batch = 15.6014s	
21766/22750 (epoch 47.837), train_loss = 0.67263405, grad/param norm = 2.5375e-01, time/batch = 15.2903s	
21767/22750 (epoch 47.840), train_loss = 0.59397016, grad/param norm = 2.2294e-01, time/batch = 15.6178s	
21768/22750 (epoch 47.842), train_loss = 0.60933840, grad/param norm = 2.6216e-01, time/batch = 15.4487s	
21769/22750 (epoch 47.844), train_loss = 0.70490991, grad/param norm = 2.7596e-01, time/batch = 15.1197s	
21770/22750 (epoch 47.846), train_loss = 0.73398364, grad/param norm = 2.6081e-01, time/batch = 15.5177s	
21771/22750 (epoch 47.848), train_loss = 0.64354845, grad/param norm = 2.2819e-01, time/batch = 16.3353s	
21772/22750 (epoch 47.851), train_loss = 0.61937547, grad/param norm = 2.2819e-01, time/batch = 15.0676s	
21773/22750 (epoch 47.853), train_loss = 0.79328234, grad/param norm = 2.6083e-01, time/batch = 15.5488s	
21774/22750 (epoch 47.855), train_loss = 0.65399434, grad/param norm = 1.7968e-01, time/batch = 14.9092s	
21775/22750 (epoch 47.857), train_loss = 0.72461139, grad/param norm = 2.5134e-01, time/batch = 15.8577s	
21776/22750 (epoch 47.859), train_loss = 0.69934768, grad/param norm = 2.3243e-01, time/batch = 15.9468s	
21777/22750 (epoch 47.862), train_loss = 0.82770980, grad/param norm = 2.6531e-01, time/batch = 15.7762s	
21778/22750 (epoch 47.864), train_loss = 0.68190021, grad/param norm = 2.3929e-01, time/batch = 16.7261s	
21779/22750 (epoch 47.866), train_loss = 0.73426098, grad/param norm = 2.7523e-01, time/batch = 16.0038s	
21780/22750 (epoch 47.868), train_loss = 0.59973132, grad/param norm = 2.2025e-01, time/batch = 15.9208s	
21781/22750 (epoch 47.870), train_loss = 0.61994320, grad/param norm = 2.7192e-01, time/batch = 16.3747s	
21782/22750 (epoch 47.873), train_loss = 0.69072697, grad/param norm = 3.0039e-01, time/batch = 15.9136s	
21783/22750 (epoch 47.875), train_loss = 0.71420192, grad/param norm = 2.3024e-01, time/batch = 15.2193s	
21784/22750 (epoch 47.877), train_loss = 0.65209447, grad/param norm = 2.6182e-01, time/batch = 15.5436s	
21785/22750 (epoch 47.879), train_loss = 0.78258664, grad/param norm = 3.0250e-01, time/batch = 15.8629s	
21786/22750 (epoch 47.881), train_loss = 0.68855677, grad/param norm = 2.3124e-01, time/batch = 16.4945s	
21787/22750 (epoch 47.884), train_loss = 0.62027490, grad/param norm = 2.7563e-01, time/batch = 15.7781s	
21788/22750 (epoch 47.886), train_loss = 0.70473197, grad/param norm = 2.3647e-01, time/batch = 16.3270s	
21789/22750 (epoch 47.888), train_loss = 0.73565365, grad/param norm = 2.2797e-01, time/batch = 15.2877s	
21790/22750 (epoch 47.890), train_loss = 0.74378556, grad/param norm = 2.6180e-01, time/batch = 15.8321s	
21791/22750 (epoch 47.892), train_loss = 0.89686797, grad/param norm = 3.0451e-01, time/batch = 15.4470s	
21792/22750 (epoch 47.895), train_loss = 0.64025642, grad/param norm = 2.6109e-01, time/batch = 15.8600s	
21793/22750 (epoch 47.897), train_loss = 0.77793834, grad/param norm = 2.4385e-01, time/batch = 15.0535s	
21794/22750 (epoch 47.899), train_loss = 0.70609009, grad/param norm = 2.4478e-01, time/batch = 15.6192s	
21795/22750 (epoch 47.901), train_loss = 0.76726008, grad/param norm = 2.5780e-01, time/batch = 14.8893s	
21796/22750 (epoch 47.903), train_loss = 0.68298455, grad/param norm = 2.3933e-01, time/batch = 14.7397s	
21797/22750 (epoch 47.905), train_loss = 0.71132980, grad/param norm = 2.5621e-01, time/batch = 14.8218s	
21798/22750 (epoch 47.908), train_loss = 0.57890005, grad/param norm = 2.5111e-01, time/batch = 15.1315s	
21799/22750 (epoch 47.910), train_loss = 0.52190186, grad/param norm = 2.5850e-01, time/batch = 14.8209s	
21800/22750 (epoch 47.912), train_loss = 0.69027395, grad/param norm = 2.6688e-01, time/batch = 14.8141s	
21801/22750 (epoch 47.914), train_loss = 0.71913328, grad/param norm = 2.6682e-01, time/batch = 15.0562s	
21802/22750 (epoch 47.916), train_loss = 0.56033985, grad/param norm = 2.2262e-01, time/batch = 15.1167s	
21803/22750 (epoch 47.919), train_loss = 0.69279452, grad/param norm = 2.5552e-01, time/batch = 15.0612s	
21804/22750 (epoch 47.921), train_loss = 0.53487539, grad/param norm = 2.3665e-01, time/batch = 15.9298s	
21805/22750 (epoch 47.923), train_loss = 0.64920097, grad/param norm = 2.2908e-01, time/batch = 15.6027s	
21806/22750 (epoch 47.925), train_loss = 0.69082235, grad/param norm = 2.3169e-01, time/batch = 16.2634s	
21807/22750 (epoch 47.927), train_loss = 0.53457921, grad/param norm = 2.4876e-01, time/batch = 15.7767s	
21808/22750 (epoch 47.930), train_loss = 0.51558258, grad/param norm = 2.1518e-01, time/batch = 15.7030s	
21809/22750 (epoch 47.932), train_loss = 0.64577264, grad/param norm = 2.3205e-01, time/batch = 15.7213s	
21810/22750 (epoch 47.934), train_loss = 0.57648735, grad/param norm = 2.0647e-01, time/batch = 16.0985s	
21811/22750 (epoch 47.936), train_loss = 0.75198891, grad/param norm = 2.4979e-01, time/batch = 15.8640s	
21812/22750 (epoch 47.938), train_loss = 0.73122894, grad/param norm = 2.1004e-01, time/batch = 15.5529s	
21813/22750 (epoch 47.941), train_loss = 0.78246490, grad/param norm = 2.9837e-01, time/batch = 16.0892s	
21814/22750 (epoch 47.943), train_loss = 0.67807007, grad/param norm = 2.2822e-01, time/batch = 15.5288s	
21815/22750 (epoch 47.945), train_loss = 0.70517474, grad/param norm = 2.6260e-01, time/batch = 15.6909s	
21816/22750 (epoch 47.947), train_loss = 0.64307840, grad/param norm = 2.5588e-01, time/batch = 15.2116s	
21817/22750 (epoch 47.949), train_loss = 0.63791863, grad/param norm = 2.2693e-01, time/batch = 15.9076s	
21818/22750 (epoch 47.952), train_loss = 0.64024525, grad/param norm = 2.2292e-01, time/batch = 15.4506s	
21819/22750 (epoch 47.954), train_loss = 0.57472411, grad/param norm = 2.3184e-01, time/batch = 15.2989s	
21820/22750 (epoch 47.956), train_loss = 0.72978428, grad/param norm = 2.2532e-01, time/batch = 15.1405s	
21821/22750 (epoch 47.958), train_loss = 0.59630319, grad/param norm = 2.0088e-01, time/batch = 15.7121s	
21822/22750 (epoch 47.960), train_loss = 0.58036807, grad/param norm = 2.0930e-01, time/batch = 15.6209s	
21823/22750 (epoch 47.963), train_loss = 0.69424509, grad/param norm = 2.2012e-01, time/batch = 15.2285s	
21824/22750 (epoch 47.965), train_loss = 0.74549254, grad/param norm = 2.3340e-01, time/batch = 15.7778s	
21825/22750 (epoch 47.967), train_loss = 0.71623260, grad/param norm = 2.4501e-01, time/batch = 15.3794s	
21826/22750 (epoch 47.969), train_loss = 0.63831253, grad/param norm = 2.4972e-01, time/batch = 15.0533s	
21827/22750 (epoch 47.971), train_loss = 0.62763269, grad/param norm = 2.5504e-01, time/batch = 15.4518s	
21828/22750 (epoch 47.974), train_loss = 0.60876799, grad/param norm = 2.1733e-01, time/batch = 15.5344s	
21829/22750 (epoch 47.976), train_loss = 0.63784931, grad/param norm = 2.2117e-01, time/batch = 15.3735s	
21830/22750 (epoch 47.978), train_loss = 0.60196364, grad/param norm = 2.3809e-01, time/batch = 16.1490s	
21831/22750 (epoch 47.980), train_loss = 0.78367247, grad/param norm = 2.4217e-01, time/batch = 16.0001s	
21832/22750 (epoch 47.982), train_loss = 0.62852338, grad/param norm = 2.1015e-01, time/batch = 16.0302s	
21833/22750 (epoch 47.985), train_loss = 0.80524338, grad/param norm = 2.8858e-01, time/batch = 15.8848s	
21834/22750 (epoch 47.987), train_loss = 0.54903132, grad/param norm = 2.2115e-01, time/batch = 15.9621s	
21835/22750 (epoch 47.989), train_loss = 0.59746086, grad/param norm = 2.4018e-01, time/batch = 15.7955s	
21836/22750 (epoch 47.991), train_loss = 0.72449663, grad/param norm = 3.3470e-01, time/batch = 16.4141s	
21837/22750 (epoch 47.993), train_loss = 0.65753674, grad/param norm = 2.8402e-01, time/batch = 15.7604s	
21838/22750 (epoch 47.996), train_loss = 0.57593007, grad/param norm = 2.2525e-01, time/batch = 15.2899s	
21839/22750 (epoch 47.998), train_loss = 0.76683669, grad/param norm = 2.5365e-01, time/batch = 15.3788s	
decayed learning rate by a factor 0.97 to 0.00060971605649306	
21840/22750 (epoch 48.000), train_loss = 0.65433115, grad/param norm = 2.4377e-01, time/batch = 15.7857s	
21841/22750 (epoch 48.002), train_loss = 0.82159520, grad/param norm = 2.5614e-01, time/batch = 15.3901s	
21842/22750 (epoch 48.004), train_loss = 0.65052935, grad/param norm = 2.2137e-01, time/batch = 16.1808s	
21843/22750 (epoch 48.007), train_loss = 0.64326618, grad/param norm = 2.5238e-01, time/batch = 18.4163s	
21844/22750 (epoch 48.009), train_loss = 0.78524820, grad/param norm = 2.7605e-01, time/batch = 19.4246s	
21845/22750 (epoch 48.011), train_loss = 0.84300108, grad/param norm = 2.9888e-01, time/batch = 19.8531s	
21846/22750 (epoch 48.013), train_loss = 0.75298000, grad/param norm = 2.5468e-01, time/batch = 16.9843s	
21847/22750 (epoch 48.015), train_loss = 0.67101694, grad/param norm = 2.4818e-01, time/batch = 17.2430s	
21848/22750 (epoch 48.018), train_loss = 0.79943036, grad/param norm = 2.5333e-01, time/batch = 16.2019s	
21849/22750 (epoch 48.020), train_loss = 0.78366927, grad/param norm = 2.6822e-01, time/batch = 17.5006s	
21850/22750 (epoch 48.022), train_loss = 0.68965586, grad/param norm = 2.6296e-01, time/batch = 16.9177s	
21851/22750 (epoch 48.024), train_loss = 0.69303000, grad/param norm = 2.7207e-01, time/batch = 16.3548s	
21852/22750 (epoch 48.026), train_loss = 0.70661924, grad/param norm = 3.2139e-01, time/batch = 19.5081s	
21853/22750 (epoch 48.029), train_loss = 0.56640142, grad/param norm = 2.6970e-01, time/batch = 18.4070s	
21854/22750 (epoch 48.031), train_loss = 0.91848349, grad/param norm = 2.9869e-01, time/batch = 16.5692s	
21855/22750 (epoch 48.033), train_loss = 0.70642464, grad/param norm = 2.4926e-01, time/batch = 19.1236s	
21856/22750 (epoch 48.035), train_loss = 0.73580184, grad/param norm = 2.6565e-01, time/batch = 19.7049s	
21857/22750 (epoch 48.037), train_loss = 0.74246752, grad/param norm = 2.5477e-01, time/batch = 17.2729s	
21858/22750 (epoch 48.040), train_loss = 0.69785068, grad/param norm = 2.1349e-01, time/batch = 17.0025s	
21859/22750 (epoch 48.042), train_loss = 0.69881473, grad/param norm = 2.8037e-01, time/batch = 18.4833s	
21860/22750 (epoch 48.044), train_loss = 0.68754486, grad/param norm = 2.7084e-01, time/batch = 17.1543s	
21861/22750 (epoch 48.046), train_loss = 0.77390198, grad/param norm = 2.6769e-01, time/batch = 16.4263s	
21862/22750 (epoch 48.048), train_loss = 0.72497941, grad/param norm = 2.4193e-01, time/batch = 17.5585s	
21863/22750 (epoch 48.051), train_loss = 0.70933086, grad/param norm = 2.4111e-01, time/batch = 17.6414s	
21864/22750 (epoch 48.053), train_loss = 0.68819565, grad/param norm = 2.2732e-01, time/batch = 18.5060s	
21865/22750 (epoch 48.055), train_loss = 0.61951685, grad/param norm = 2.2674e-01, time/batch = 18.9399s	
21866/22750 (epoch 48.057), train_loss = 0.79856725, grad/param norm = 2.5579e-01, time/batch = 16.9720s	
21867/22750 (epoch 48.059), train_loss = 0.50030111, grad/param norm = 2.0970e-01, time/batch = 16.5690s	
21868/22750 (epoch 48.062), train_loss = 0.58071544, grad/param norm = 2.2641e-01, time/batch = 18.7550s	
21869/22750 (epoch 48.064), train_loss = 0.79523413, grad/param norm = 2.6007e-01, time/batch = 17.0631s	
21870/22750 (epoch 48.066), train_loss = 0.59343003, grad/param norm = 2.0940e-01, time/batch = 16.6500s	
21871/22750 (epoch 48.068), train_loss = 0.61443078, grad/param norm = 2.1552e-01, time/batch = 16.8065s	
21872/22750 (epoch 48.070), train_loss = 0.51867919, grad/param norm = 1.9271e-01, time/batch = 16.0151s	
21873/22750 (epoch 48.073), train_loss = 0.63163067, grad/param norm = 2.5145e-01, time/batch = 16.4932s	
21874/22750 (epoch 48.075), train_loss = 0.67350879, grad/param norm = 2.0670e-01, time/batch = 16.3275s	
21875/22750 (epoch 48.077), train_loss = 0.51596318, grad/param norm = 2.4292e-01, time/batch = 16.1720s	
21876/22750 (epoch 48.079), train_loss = 0.68598966, grad/param norm = 2.3539e-01, time/batch = 15.8553s	
21877/22750 (epoch 48.081), train_loss = 0.62962891, grad/param norm = 2.1361e-01, time/batch = 15.5406s	
21878/22750 (epoch 48.084), train_loss = 0.62415200, grad/param norm = 2.1602e-01, time/batch = 16.1111s	
21879/22750 (epoch 48.086), train_loss = 0.66461278, grad/param norm = 2.1325e-01, time/batch = 15.5418s	
21880/22750 (epoch 48.088), train_loss = 0.62953537, grad/param norm = 2.1390e-01, time/batch = 16.0163s	
21881/22750 (epoch 48.090), train_loss = 0.65033996, grad/param norm = 2.4206e-01, time/batch = 15.8489s	
21882/22750 (epoch 48.092), train_loss = 0.71426366, grad/param norm = 2.2709e-01, time/batch = 15.7698s	
21883/22750 (epoch 48.095), train_loss = 0.61544370, grad/param norm = 2.2554e-01, time/batch = 15.6053s	
21884/22750 (epoch 48.097), train_loss = 0.68839713, grad/param norm = 2.3352e-01, time/batch = 15.9257s	
21885/22750 (epoch 48.099), train_loss = 0.62424672, grad/param norm = 2.7159e-01, time/batch = 15.9315s	
21886/22750 (epoch 48.101), train_loss = 0.55904483, grad/param norm = 2.1390e-01, time/batch = 15.7748s	
21887/22750 (epoch 48.103), train_loss = 0.70834159, grad/param norm = 2.6555e-01, time/batch = 15.5993s	
21888/22750 (epoch 48.105), train_loss = 0.76913896, grad/param norm = 3.1657e-01, time/batch = 15.7814s	
21889/22750 (epoch 48.108), train_loss = 0.71898469, grad/param norm = 2.4639e-01, time/batch = 16.7331s	
21890/22750 (epoch 48.110), train_loss = 0.74634737, grad/param norm = 2.5082e-01, time/batch = 15.3806s	
21891/22750 (epoch 48.112), train_loss = 0.56443152, grad/param norm = 1.9193e-01, time/batch = 16.0229s	
21892/22750 (epoch 48.114), train_loss = 0.49178425, grad/param norm = 1.9856e-01, time/batch = 15.9476s	
21893/22750 (epoch 48.116), train_loss = 0.69287106, grad/param norm = 2.2093e-01, time/batch = 16.7969s	
21894/22750 (epoch 48.119), train_loss = 0.63232459, grad/param norm = 2.0434e-01, time/batch = 16.3158s	
21895/22750 (epoch 48.121), train_loss = 0.64531832, grad/param norm = 2.5255e-01, time/batch = 16.1907s	
21896/22750 (epoch 48.123), train_loss = 0.57467297, grad/param norm = 2.4255e-01, time/batch = 16.4860s	
21897/22750 (epoch 48.125), train_loss = 0.73403313, grad/param norm = 2.1145e-01, time/batch = 16.4086s	
21898/22750 (epoch 48.127), train_loss = 0.64058193, grad/param norm = 2.4569e-01, time/batch = 15.9988s	
21899/22750 (epoch 48.130), train_loss = 0.65583983, grad/param norm = 2.2190e-01, time/batch = 15.7077s	
21900/22750 (epoch 48.132), train_loss = 0.61645686, grad/param norm = 2.1265e-01, time/batch = 16.0908s	
21901/22750 (epoch 48.134), train_loss = 0.64400826, grad/param norm = 2.1030e-01, time/batch = 16.0358s	
21902/22750 (epoch 48.136), train_loss = 0.54184017, grad/param norm = 2.2570e-01, time/batch = 15.8595s	
21903/22750 (epoch 48.138), train_loss = 0.74455162, grad/param norm = 2.4484e-01, time/batch = 16.0273s	
21904/22750 (epoch 48.141), train_loss = 0.65233652, grad/param norm = 2.1556e-01, time/batch = 15.9487s	
21905/22750 (epoch 48.143), train_loss = 0.62699781, grad/param norm = 2.2080e-01, time/batch = 15.6921s	
21906/22750 (epoch 48.145), train_loss = 0.76670038, grad/param norm = 2.3539e-01, time/batch = 15.5333s	
21907/22750 (epoch 48.147), train_loss = 0.81136894, grad/param norm = 2.6386e-01, time/batch = 15.6881s	
21908/22750 (epoch 48.149), train_loss = 0.68152447, grad/param norm = 2.4805e-01, time/batch = 15.9310s	
21909/22750 (epoch 48.152), train_loss = 0.67398644, grad/param norm = 2.3915e-01, time/batch = 15.6897s	
21910/22750 (epoch 48.154), train_loss = 0.58853239, grad/param norm = 2.2849e-01, time/batch = 15.6111s	
21911/22750 (epoch 48.156), train_loss = 0.61468048, grad/param norm = 2.3652e-01, time/batch = 15.5343s	
21912/22750 (epoch 48.158), train_loss = 0.58023213, grad/param norm = 2.4342e-01, time/batch = 15.9195s	
21913/22750 (epoch 48.160), train_loss = 0.68130257, grad/param norm = 2.7726e-01, time/batch = 15.4577s	
21914/22750 (epoch 48.163), train_loss = 0.78930659, grad/param norm = 2.7808e-01, time/batch = 15.2077s	
21915/22750 (epoch 48.165), train_loss = 0.72627456, grad/param norm = 2.4817e-01, time/batch = 16.2443s	
21916/22750 (epoch 48.167), train_loss = 0.62801392, grad/param norm = 2.3653e-01, time/batch = 16.0308s	
21917/22750 (epoch 48.169), train_loss = 0.64764475, grad/param norm = 2.5097e-01, time/batch = 16.0934s	
21918/22750 (epoch 48.171), train_loss = 0.56750957, grad/param norm = 2.0013e-01, time/batch = 15.8730s	
21919/22750 (epoch 48.174), train_loss = 0.55109012, grad/param norm = 2.2686e-01, time/batch = 16.0265s	
21920/22750 (epoch 48.176), train_loss = 0.57526793, grad/param norm = 2.3468e-01, time/batch = 16.1692s	
21921/22750 (epoch 48.178), train_loss = 0.63543376, grad/param norm = 2.4248e-01, time/batch = 16.2661s	
21922/22750 (epoch 48.180), train_loss = 0.78289194, grad/param norm = 4.7367e-01, time/batch = 16.5861s	
21923/22750 (epoch 48.182), train_loss = 0.70755311, grad/param norm = 2.7980e-01, time/batch = 16.4222s	
21924/22750 (epoch 48.185), train_loss = 0.75650208, grad/param norm = 2.5329e-01, time/batch = 16.3428s	
21925/22750 (epoch 48.187), train_loss = 0.59180567, grad/param norm = 2.4491e-01, time/batch = 16.5914s	
21926/22750 (epoch 48.189), train_loss = 0.58383551, grad/param norm = 2.2794e-01, time/batch = 16.9047s	
21927/22750 (epoch 48.191), train_loss = 0.63695759, grad/param norm = 2.3337e-01, time/batch = 16.3616s	
21928/22750 (epoch 48.193), train_loss = 0.69304994, grad/param norm = 2.2094e-01, time/batch = 15.9598s	
21929/22750 (epoch 48.196), train_loss = 0.62968223, grad/param norm = 2.3435e-01, time/batch = 15.9302s	
21930/22750 (epoch 48.198), train_loss = 0.46817741, grad/param norm = 2.0376e-01, time/batch = 16.6365s	
21931/22750 (epoch 48.200), train_loss = 0.65577896, grad/param norm = 2.0553e-01, time/batch = 16.4078s	
21932/22750 (epoch 48.202), train_loss = 0.70745548, grad/param norm = 2.6268e-01, time/batch = 16.0859s	
21933/22750 (epoch 48.204), train_loss = 0.68592954, grad/param norm = 2.4651e-01, time/batch = 16.1571s	
21934/22750 (epoch 48.207), train_loss = 0.70208878, grad/param norm = 2.1967e-01, time/batch = 16.1809s	
21935/22750 (epoch 48.209), train_loss = 0.62731462, grad/param norm = 2.2003e-01, time/batch = 15.5319s	
21936/22750 (epoch 48.211), train_loss = 0.57426420, grad/param norm = 2.5062e-01, time/batch = 15.9364s	
21937/22750 (epoch 48.213), train_loss = 0.48902813, grad/param norm = 2.0766e-01, time/batch = 15.9390s	
21938/22750 (epoch 48.215), train_loss = 0.50866997, grad/param norm = 2.1541e-01, time/batch = 16.2669s	
21939/22750 (epoch 48.218), train_loss = 0.57843409, grad/param norm = 2.4146e-01, time/batch = 15.8637s	
21940/22750 (epoch 48.220), train_loss = 0.55595456, grad/param norm = 2.6477e-01, time/batch = 15.9302s	
21941/22750 (epoch 48.222), train_loss = 0.54099953, grad/param norm = 2.2237e-01, time/batch = 16.5071s	
21942/22750 (epoch 48.224), train_loss = 0.56153828, grad/param norm = 2.1558e-01, time/batch = 16.7948s	
21943/22750 (epoch 48.226), train_loss = 0.63403586, grad/param norm = 2.1703e-01, time/batch = 16.4978s	
21944/22750 (epoch 48.229), train_loss = 0.67406455, grad/param norm = 3.3565e-01, time/batch = 16.8795s	
21945/22750 (epoch 48.231), train_loss = 0.58141863, grad/param norm = 2.3151e-01, time/batch = 16.7469s	
21946/22750 (epoch 48.233), train_loss = 0.54068301, grad/param norm = 3.4879e-01, time/batch = 16.1757s	
21947/22750 (epoch 48.235), train_loss = 0.53063748, grad/param norm = 2.2163e-01, time/batch = 16.8072s	
21948/22750 (epoch 48.237), train_loss = 0.57111664, grad/param norm = 2.2461e-01, time/batch = 16.1756s	
21949/22750 (epoch 48.240), train_loss = 0.66489734, grad/param norm = 1.9141e-01, time/batch = 16.5756s	
21950/22750 (epoch 48.242), train_loss = 0.76076232, grad/param norm = 2.5507e-01, time/batch = 16.1952s	
21951/22750 (epoch 48.244), train_loss = 0.75953908, grad/param norm = 2.6482e-01, time/batch = 15.8716s	
21952/22750 (epoch 48.246), train_loss = 0.79309762, grad/param norm = 2.6772e-01, time/batch = 16.7389s	
21953/22750 (epoch 48.248), train_loss = 0.67302794, grad/param norm = 2.1497e-01, time/batch = 15.7898s	
21954/22750 (epoch 48.251), train_loss = 0.72541707, grad/param norm = 2.9918e-01, time/batch = 15.8553s	
21955/22750 (epoch 48.253), train_loss = 0.70218032, grad/param norm = 2.7289e-01, time/batch = 15.8410s	
21956/22750 (epoch 48.255), train_loss = 0.70648697, grad/param norm = 2.6794e-01, time/batch = 15.9353s	
21957/22750 (epoch 48.257), train_loss = 0.59863443, grad/param norm = 2.3803e-01, time/batch = 15.6145s	
21958/22750 (epoch 48.259), train_loss = 0.71094394, grad/param norm = 2.8983e-01, time/batch = 15.8441s	
21959/22750 (epoch 48.262), train_loss = 0.70890132, grad/param norm = 2.6053e-01, time/batch = 15.7682s	
21960/22750 (epoch 48.264), train_loss = 0.51089668, grad/param norm = 2.4871e-01, time/batch = 16.0756s	
21961/22750 (epoch 48.266), train_loss = 0.64930785, grad/param norm = 3.2745e-01, time/batch = 16.0332s	
21962/22750 (epoch 48.268), train_loss = 0.80507580, grad/param norm = 2.6441e-01, time/batch = 16.9528s	
21963/22750 (epoch 48.270), train_loss = 0.63429442, grad/param norm = 2.7729e-01, time/batch = 14.4936s	
21964/22750 (epoch 48.273), train_loss = 0.90115298, grad/param norm = 2.8791e-01, time/batch = 0.7230s	
21965/22750 (epoch 48.275), train_loss = 0.79403472, grad/param norm = 2.2593e-01, time/batch = 0.6995s	
21966/22750 (epoch 48.277), train_loss = 0.66206671, grad/param norm = 2.7525e-01, time/batch = 0.6938s	
21967/22750 (epoch 48.279), train_loss = 0.56002109, grad/param norm = 2.0783e-01, time/batch = 0.7111s	
21968/22750 (epoch 48.281), train_loss = 0.77892419, grad/param norm = 2.4697e-01, time/batch = 0.7244s	
21969/22750 (epoch 48.284), train_loss = 0.70585969, grad/param norm = 2.2612e-01, time/batch = 0.7011s	
21970/22750 (epoch 48.286), train_loss = 0.72945756, grad/param norm = 2.8083e-01, time/batch = 0.7296s	
21971/22750 (epoch 48.288), train_loss = 0.79639026, grad/param norm = 2.9277e-01, time/batch = 1.0213s	
21972/22750 (epoch 48.290), train_loss = 0.72103075, grad/param norm = 2.5624e-01, time/batch = 1.0194s	
21973/22750 (epoch 48.292), train_loss = 0.73052815, grad/param norm = 3.4630e-01, time/batch = 1.0573s	
21974/22750 (epoch 48.295), train_loss = 0.70318255, grad/param norm = 2.5222e-01, time/batch = 1.0172s	
21975/22750 (epoch 48.297), train_loss = 0.71286742, grad/param norm = 2.6425e-01, time/batch = 1.2917s	
21976/22750 (epoch 48.299), train_loss = 0.74895288, grad/param norm = 2.5680e-01, time/batch = 1.8839s	
21977/22750 (epoch 48.301), train_loss = 0.63992006, grad/param norm = 2.2091e-01, time/batch = 1.8852s	
21978/22750 (epoch 48.303), train_loss = 0.70673081, grad/param norm = 2.4701e-01, time/batch = 13.1486s	
21979/22750 (epoch 48.305), train_loss = 0.77608787, grad/param norm = 2.4370e-01, time/batch = 19.9070s	
21980/22750 (epoch 48.308), train_loss = 0.74680617, grad/param norm = 2.5661e-01, time/batch = 17.6552s	
21981/22750 (epoch 48.310), train_loss = 0.62135934, grad/param norm = 2.4929e-01, time/batch = 16.5872s	
21982/22750 (epoch 48.312), train_loss = 0.67734857, grad/param norm = 2.7464e-01, time/batch = 17.7653s	
21983/22750 (epoch 48.314), train_loss = 0.71186676, grad/param norm = 2.4095e-01, time/batch = 16.7239s	
21984/22750 (epoch 48.316), train_loss = 0.65512140, grad/param norm = 2.2978e-01, time/batch = 16.9359s	
21985/22750 (epoch 48.319), train_loss = 0.72381187, grad/param norm = 2.9026e-01, time/batch = 16.6774s	
21986/22750 (epoch 48.321), train_loss = 0.62529742, grad/param norm = 2.3385e-01, time/batch = 19.3452s	
21987/22750 (epoch 48.323), train_loss = 0.71889294, grad/param norm = 2.4988e-01, time/batch = 18.3563s	
21988/22750 (epoch 48.325), train_loss = 0.59823764, grad/param norm = 2.1835e-01, time/batch = 20.9323s	
21989/22750 (epoch 48.327), train_loss = 0.64377708, grad/param norm = 2.8046e-01, time/batch = 20.4953s	
21990/22750 (epoch 48.330), train_loss = 0.78390243, grad/param norm = 2.4630e-01, time/batch = 17.3391s	
21991/22750 (epoch 48.332), train_loss = 0.88347326, grad/param norm = 2.6555e-01, time/batch = 18.0736s	
21992/22750 (epoch 48.334), train_loss = 0.55929424, grad/param norm = 1.9666e-01, time/batch = 17.2532s	
21993/22750 (epoch 48.336), train_loss = 0.74982018, grad/param norm = 2.0375e-01, time/batch = 26.2771s	
21994/22750 (epoch 48.338), train_loss = 0.66093588, grad/param norm = 2.2459e-01, time/batch = 25.5648s	
21995/22750 (epoch 48.341), train_loss = 0.67893397, grad/param norm = 2.4910e-01, time/batch = 18.9073s	
21996/22750 (epoch 48.343), train_loss = 0.59421129, grad/param norm = 2.2345e-01, time/batch = 18.2632s	
21997/22750 (epoch 48.345), train_loss = 0.72731026, grad/param norm = 4.3548e-01, time/batch = 20.6894s	
21998/22750 (epoch 48.347), train_loss = 0.73654310, grad/param norm = 2.5786e-01, time/batch = 20.6018s	
21999/22750 (epoch 48.349), train_loss = 0.59713603, grad/param norm = 3.1863e-01, time/batch = 18.0866s	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_wakata_epoch48.35_1.8495.t7	
22000/22750 (epoch 48.352), train_loss = 0.81175920, grad/param norm = 2.5806e-01, time/batch = 19.3239s	
22001/22750 (epoch 48.354), train_loss = 1.88738318, grad/param norm = 4.8570e-01, time/batch = 21.5082s	
22002/22750 (epoch 48.356), train_loss = 0.73707904, grad/param norm = 2.4654e-01, time/batch = 20.5748s	
22003/22750 (epoch 48.358), train_loss = 0.64950096, grad/param norm = 2.3670e-01, time/batch = 17.2633s	
22004/22750 (epoch 48.360), train_loss = 0.82649433, grad/param norm = 2.9935e-01, time/batch = 17.2336s	
22005/22750 (epoch 48.363), train_loss = 0.63873382, grad/param norm = 2.8842e-01, time/batch = 18.9917s	
22006/22750 (epoch 48.365), train_loss = 0.56203075, grad/param norm = 2.6063e-01, time/batch = 17.3843s	
22007/22750 (epoch 48.367), train_loss = 0.62976264, grad/param norm = 2.7234e-01, time/batch = 18.4218s	
22008/22750 (epoch 48.369), train_loss = 0.70288168, grad/param norm = 3.0730e-01, time/batch = 20.5612s	
22009/22750 (epoch 48.371), train_loss = 0.72292921, grad/param norm = 2.8220e-01, time/batch = 18.2563s	
22010/22750 (epoch 48.374), train_loss = 0.62493454, grad/param norm = 2.9139e-01, time/batch = 19.7480s	
22011/22750 (epoch 48.376), train_loss = 0.68086282, grad/param norm = 2.3211e-01, time/batch = 21.7604s	
22012/22750 (epoch 48.378), train_loss = 0.70190141, grad/param norm = 2.1237e-01, time/batch = 19.4353s	
22013/22750 (epoch 48.380), train_loss = 0.75135207, grad/param norm = 2.2183e-01, time/batch = 19.8688s	
22014/22750 (epoch 48.382), train_loss = 0.67455030, grad/param norm = 2.7581e-01, time/batch = 20.8135s	
22015/22750 (epoch 48.385), train_loss = 0.72065627, grad/param norm = 2.2681e-01, time/batch = 19.0693s	
22016/22750 (epoch 48.387), train_loss = 0.71275223, grad/param norm = 2.5809e-01, time/batch = 16.8818s	
22017/22750 (epoch 48.389), train_loss = 0.57449331, grad/param norm = 2.4830e-01, time/batch = 17.5640s	
22018/22750 (epoch 48.391), train_loss = 0.43389128, grad/param norm = 1.8169e-01, time/batch = 17.3269s	
22019/22750 (epoch 48.393), train_loss = 0.57556163, grad/param norm = 2.3487e-01, time/batch = 16.7386s	
22020/22750 (epoch 48.396), train_loss = 0.70946178, grad/param norm = 2.2916e-01, time/batch = 17.4946s	
22021/22750 (epoch 48.398), train_loss = 0.63746293, grad/param norm = 2.2281e-01, time/batch = 17.5946s	
22022/22750 (epoch 48.400), train_loss = 0.71670298, grad/param norm = 3.0040e-01, time/batch = 19.3509s	
22023/22750 (epoch 48.402), train_loss = 0.68018088, grad/param norm = 2.3048e-01, time/batch = 17.2348s	
22024/22750 (epoch 48.404), train_loss = 0.77053455, grad/param norm = 2.5419e-01, time/batch = 18.6024s	
22025/22750 (epoch 48.407), train_loss = 0.76326731, grad/param norm = 2.7844e-01, time/batch = 17.8590s	
22026/22750 (epoch 48.409), train_loss = 0.62921618, grad/param norm = 2.3718e-01, time/batch = 19.6603s	
22027/22750 (epoch 48.411), train_loss = 0.61827899, grad/param norm = 2.2067e-01, time/batch = 19.2583s	
22028/22750 (epoch 48.413), train_loss = 0.47725289, grad/param norm = 2.1694e-01, time/batch = 18.7538s	
22029/22750 (epoch 48.415), train_loss = 0.56326718, grad/param norm = 2.2614e-01, time/batch = 19.0874s	
22030/22750 (epoch 48.418), train_loss = 0.65047547, grad/param norm = 2.6191e-01, time/batch = 16.8503s	
22031/22750 (epoch 48.420), train_loss = 0.73663895, grad/param norm = 2.8912e-01, time/batch = 17.9238s	
22032/22750 (epoch 48.422), train_loss = 0.84744664, grad/param norm = 3.4070e-01, time/batch = 17.1795s	
22033/22750 (epoch 48.424), train_loss = 0.85984701, grad/param norm = 2.8653e-01, time/batch = 18.9323s	
22034/22750 (epoch 48.426), train_loss = 0.85125974, grad/param norm = 2.5538e-01, time/batch = 18.9399s	
22035/22750 (epoch 48.429), train_loss = 0.63757916, grad/param norm = 2.2643e-01, time/batch = 16.8181s	
22036/22750 (epoch 48.431), train_loss = 0.56569498, grad/param norm = 2.1793e-01, time/batch = 17.2581s	
22037/22750 (epoch 48.433), train_loss = 0.63842096, grad/param norm = 2.4189e-01, time/batch = 17.3450s	
22038/22750 (epoch 48.435), train_loss = 0.49086535, grad/param norm = 2.0214e-01, time/batch = 17.3281s	
22039/22750 (epoch 48.437), train_loss = 0.43391288, grad/param norm = 1.9167e-01, time/batch = 17.6591s	
22040/22750 (epoch 48.440), train_loss = 0.66648110, grad/param norm = 3.0186e-01, time/batch = 18.9244s	
22041/22750 (epoch 48.442), train_loss = 0.68377017, grad/param norm = 2.6243e-01, time/batch = 19.0023s	
22042/22750 (epoch 48.444), train_loss = 0.63437243, grad/param norm = 2.6738e-01, time/batch = 18.5641s	
22043/22750 (epoch 48.446), train_loss = 0.64610910, grad/param norm = 2.7283e-01, time/batch = 21.6702s	
22044/22750 (epoch 48.448), train_loss = 0.86141477, grad/param norm = 2.9186e-01, time/batch = 18.3568s	
22045/22750 (epoch 48.451), train_loss = 0.81999278, grad/param norm = 2.4189e-01, time/batch = 18.5363s	
22046/22750 (epoch 48.453), train_loss = 0.70090195, grad/param norm = 2.7852e-01, time/batch = 17.4906s	
22047/22750 (epoch 48.455), train_loss = 0.79778621, grad/param norm = 2.5925e-01, time/batch = 18.9841s	
22048/22750 (epoch 48.457), train_loss = 0.70323189, grad/param norm = 2.9565e-01, time/batch = 18.0065s	
22049/22750 (epoch 48.459), train_loss = 0.74230411, grad/param norm = 2.4462e-01, time/batch = 17.6071s	
22050/22750 (epoch 48.462), train_loss = 0.67992880, grad/param norm = 2.1561e-01, time/batch = 15.9081s	
22051/22750 (epoch 48.464), train_loss = 0.57990106, grad/param norm = 2.5085e-01, time/batch = 16.7333s	
22052/22750 (epoch 48.466), train_loss = 0.72799142, grad/param norm = 3.4346e-01, time/batch = 16.5130s	
22053/22750 (epoch 48.468), train_loss = 0.72456540, grad/param norm = 2.7849e-01, time/batch = 18.7704s	
22054/22750 (epoch 48.470), train_loss = 0.78654155, grad/param norm = 4.5410e-01, time/batch = 18.0269s	
22055/22750 (epoch 48.473), train_loss = 0.65479854, grad/param norm = 2.2998e-01, time/batch = 19.6099s	
22056/22750 (epoch 48.475), train_loss = 0.70613753, grad/param norm = 2.6652e-01, time/batch = 18.5265s	
22057/22750 (epoch 48.477), train_loss = 0.60535768, grad/param norm = 2.6826e-01, time/batch = 17.2598s	
22058/22750 (epoch 48.479), train_loss = 0.56396823, grad/param norm = 2.0956e-01, time/batch = 17.8297s	
22059/22750 (epoch 48.481), train_loss = 0.55144325, grad/param norm = 2.0995e-01, time/batch = 18.3288s	
22060/22750 (epoch 48.484), train_loss = 0.46846976, grad/param norm = 2.5189e-01, time/batch = 20.8241s	
22061/22750 (epoch 48.486), train_loss = 0.55123749, grad/param norm = 2.4504e-01, time/batch = 16.5144s	
22062/22750 (epoch 48.488), train_loss = 0.52232229, grad/param norm = 2.2973e-01, time/batch = 19.1913s	
22063/22750 (epoch 48.490), train_loss = 0.65035679, grad/param norm = 2.3714e-01, time/batch = 18.0844s	
22064/22750 (epoch 48.492), train_loss = 0.73563844, grad/param norm = 2.4959e-01, time/batch = 19.0852s	
22065/22750 (epoch 48.495), train_loss = 0.62146383, grad/param norm = 2.4457e-01, time/batch = 19.6121s	
22066/22750 (epoch 48.497), train_loss = 0.66148013, grad/param norm = 2.8772e-01, time/batch = 18.8709s	
22067/22750 (epoch 48.499), train_loss = 0.57950948, grad/param norm = 2.2279e-01, time/batch = 18.5909s	
22068/22750 (epoch 48.501), train_loss = 0.63307927, grad/param norm = 2.5451e-01, time/batch = 17.8162s	
22069/22750 (epoch 48.503), train_loss = 0.65392898, grad/param norm = 2.3593e-01, time/batch = 16.6273s	
22070/22750 (epoch 48.505), train_loss = 0.57829437, grad/param norm = 2.6711e-01, time/batch = 16.9869s	
22071/22750 (epoch 48.508), train_loss = 0.57446257, grad/param norm = 2.2254e-01, time/batch = 16.5704s	
22072/22750 (epoch 48.510), train_loss = 0.54630635, grad/param norm = 2.2149e-01, time/batch = 17.2622s	
22073/22750 (epoch 48.512), train_loss = 0.60707978, grad/param norm = 2.2930e-01, time/batch = 18.2508s	
22074/22750 (epoch 48.514), train_loss = 0.63581173, grad/param norm = 2.8020e-01, time/batch = 18.7670s	
22075/22750 (epoch 48.516), train_loss = 0.60593698, grad/param norm = 2.5855e-01, time/batch = 19.6093s	
22076/22750 (epoch 48.519), train_loss = 0.75148729, grad/param norm = 2.4324e-01, time/batch = 16.7020s	
22077/22750 (epoch 48.521), train_loss = 0.66794240, grad/param norm = 2.4082e-01, time/batch = 19.7500s	
22078/22750 (epoch 48.523), train_loss = 0.57174152, grad/param norm = 2.4886e-01, time/batch = 17.4400s	
22079/22750 (epoch 48.525), train_loss = 0.73273377, grad/param norm = 2.4052e-01, time/batch = 18.3466s	
22080/22750 (epoch 48.527), train_loss = 0.68459838, grad/param norm = 2.2520e-01, time/batch = 18.8304s	
22081/22750 (epoch 48.530), train_loss = 0.60988479, grad/param norm = 2.6399e-01, time/batch = 18.5871s	
22082/22750 (epoch 48.532), train_loss = 0.54043866, grad/param norm = 2.0463e-01, time/batch = 19.6687s	
22083/22750 (epoch 48.534), train_loss = 0.68826604, grad/param norm = 2.4241e-01, time/batch = 17.0898s	
22084/22750 (epoch 48.536), train_loss = 0.69178694, grad/param norm = 2.0728e-01, time/batch = 16.4038s	
22085/22750 (epoch 48.538), train_loss = 0.68982234, grad/param norm = 2.3852e-01, time/batch = 18.4104s	
22086/22750 (epoch 48.541), train_loss = 0.58861164, grad/param norm = 2.4526e-01, time/batch = 15.6246s	
22087/22750 (epoch 48.543), train_loss = 0.56866583, grad/param norm = 2.3177e-01, time/batch = 16.0024s	
22088/22750 (epoch 48.545), train_loss = 0.73298501, grad/param norm = 2.5960e-01, time/batch = 15.6300s	
22089/22750 (epoch 48.547), train_loss = 0.63937876, grad/param norm = 2.1557e-01, time/batch = 15.4473s	
22090/22750 (epoch 48.549), train_loss = 0.63671868, grad/param norm = 2.5012e-01, time/batch = 15.6011s	
22091/22750 (epoch 48.552), train_loss = 0.68947452, grad/param norm = 2.6045e-01, time/batch = 15.7764s	
22092/22750 (epoch 48.554), train_loss = 0.68185834, grad/param norm = 2.6030e-01, time/batch = 15.7747s	
22093/22750 (epoch 48.556), train_loss = 0.69465302, grad/param norm = 2.4419e-01, time/batch = 15.6065s	
22094/22750 (epoch 48.558), train_loss = 0.64154231, grad/param norm = 2.3026e-01, time/batch = 15.6047s	
22095/22750 (epoch 48.560), train_loss = 0.60518830, grad/param norm = 2.1905e-01, time/batch = 16.5628s	
22096/22750 (epoch 48.563), train_loss = 0.71323792, grad/param norm = 2.6427e-01, time/batch = 16.1055s	
22097/22750 (epoch 48.565), train_loss = 0.72654837, grad/param norm = 2.7039e-01, time/batch = 16.2827s	
22098/22750 (epoch 48.567), train_loss = 0.69055106, grad/param norm = 2.5458e-01, time/batch = 16.2654s	
22099/22750 (epoch 48.569), train_loss = 0.65998799, grad/param norm = 2.3051e-01, time/batch = 16.2705s	
22100/22750 (epoch 48.571), train_loss = 0.65589455, grad/param norm = 2.6160e-01, time/batch = 16.2837s	
22101/22750 (epoch 48.574), train_loss = 0.66224234, grad/param norm = 2.6399e-01, time/batch = 16.1903s	
22102/22750 (epoch 48.576), train_loss = 0.65174588, grad/param norm = 2.3193e-01, time/batch = 16.4112s	
22103/22750 (epoch 48.578), train_loss = 0.57139115, grad/param norm = 2.4813e-01, time/batch = 16.3426s	
22104/22750 (epoch 48.580), train_loss = 0.68712933, grad/param norm = 2.5701e-01, time/batch = 16.1802s	
22105/22750 (epoch 48.582), train_loss = 0.60564724, grad/param norm = 2.1549e-01, time/batch = 16.6606s	
22106/22750 (epoch 48.585), train_loss = 0.56667117, grad/param norm = 2.3259e-01, time/batch = 16.7376s	
22107/22750 (epoch 48.587), train_loss = 0.59505752, grad/param norm = 2.1372e-01, time/batch = 16.0866s	
22108/22750 (epoch 48.589), train_loss = 0.48961729, grad/param norm = 1.8085e-01, time/batch = 16.0306s	
22109/22750 (epoch 48.591), train_loss = 0.64230348, grad/param norm = 2.2307e-01, time/batch = 15.7122s	
22110/22750 (epoch 48.593), train_loss = 0.75956167, grad/param norm = 2.8863e-01, time/batch = 16.6605s	
22111/22750 (epoch 48.596), train_loss = 0.71919051, grad/param norm = 2.6840e-01, time/batch = 15.7165s	
22112/22750 (epoch 48.598), train_loss = 0.72908857, grad/param norm = 3.0108e-01, time/batch = 15.5207s	
22113/22750 (epoch 48.600), train_loss = 0.79306365, grad/param norm = 2.5637e-01, time/batch = 15.6085s	
22114/22750 (epoch 48.602), train_loss = 0.57684745, grad/param norm = 2.4340e-01, time/batch = 15.7679s	
22115/22750 (epoch 48.604), train_loss = 0.62319380, grad/param norm = 2.3671e-01, time/batch = 15.5432s	
22116/22750 (epoch 48.607), train_loss = 0.59753757, grad/param norm = 2.3455e-01, time/batch = 16.1763s	
22117/22750 (epoch 48.609), train_loss = 0.55671762, grad/param norm = 2.3343e-01, time/batch = 15.7616s	
22118/22750 (epoch 48.611), train_loss = 0.60072883, grad/param norm = 2.2670e-01, time/batch = 15.4506s	
22119/22750 (epoch 48.613), train_loss = 0.60539207, grad/param norm = 2.5641e-01, time/batch = 16.7991s	
22120/22750 (epoch 48.615), train_loss = 0.61837465, grad/param norm = 2.1537e-01, time/batch = 16.0991s	
22121/22750 (epoch 48.618), train_loss = 0.65190736, grad/param norm = 2.1080e-01, time/batch = 16.7375s	
22122/22750 (epoch 48.620), train_loss = 0.61877715, grad/param norm = 2.5258e-01, time/batch = 15.7320s	
22123/22750 (epoch 48.622), train_loss = 0.56145500, grad/param norm = 1.9429e-01, time/batch = 15.8766s	
22124/22750 (epoch 48.624), train_loss = 0.60779735, grad/param norm = 2.5630e-01, time/batch = 16.2665s	
22125/22750 (epoch 48.626), train_loss = 0.53664439, grad/param norm = 2.1491e-01, time/batch = 17.0494s	
22126/22750 (epoch 48.629), train_loss = 0.60633662, grad/param norm = 2.2803e-01, time/batch = 16.4840s	
22127/22750 (epoch 48.631), train_loss = 0.62942508, grad/param norm = 2.1621e-01, time/batch = 15.9441s	
22128/22750 (epoch 48.633), train_loss = 0.55763047, grad/param norm = 2.1570e-01, time/batch = 15.7755s	
22129/22750 (epoch 48.635), train_loss = 0.63866378, grad/param norm = 2.3020e-01, time/batch = 15.9348s	
22130/22750 (epoch 48.637), train_loss = 0.69317259, grad/param norm = 3.3580e-01, time/batch = 15.6869s	
22131/22750 (epoch 48.640), train_loss = 0.68744326, grad/param norm = 2.4344e-01, time/batch = 15.6855s	
22132/22750 (epoch 48.642), train_loss = 0.72794575, grad/param norm = 2.4319e-01, time/batch = 15.9428s	
22133/22750 (epoch 48.644), train_loss = 0.63510048, grad/param norm = 2.1370e-01, time/batch = 15.3744s	
22134/22750 (epoch 48.646), train_loss = 0.72158069, grad/param norm = 3.2902e-01, time/batch = 15.9511s	
22135/22750 (epoch 48.648), train_loss = 0.70531997, grad/param norm = 2.4135e-01, time/batch = 15.4728s	
22136/22750 (epoch 48.651), train_loss = 0.69455010, grad/param norm = 2.3208e-01, time/batch = 16.1872s	
22137/22750 (epoch 48.653), train_loss = 0.72117813, grad/param norm = 2.0921e-01, time/batch = 15.4451s	
22138/22750 (epoch 48.655), train_loss = 0.68802849, grad/param norm = 2.3524e-01, time/batch = 15.9282s	
22139/22750 (epoch 48.657), train_loss = 0.78502408, grad/param norm = 2.7364e-01, time/batch = 15.3717s	
22140/22750 (epoch 48.659), train_loss = 0.83450522, grad/param norm = 2.6727e-01, time/batch = 16.1602s	
22141/22750 (epoch 48.662), train_loss = 0.80749533, grad/param norm = 2.7509e-01, time/batch = 15.9370s	
22142/22750 (epoch 48.664), train_loss = 0.69954853, grad/param norm = 2.6258e-01, time/batch = 16.5675s	
22143/22750 (epoch 48.666), train_loss = 0.58298395, grad/param norm = 2.2711e-01, time/batch = 16.5042s	
22144/22750 (epoch 48.668), train_loss = 0.62271182, grad/param norm = 2.2520e-01, time/batch = 16.1828s	
22145/22750 (epoch 48.670), train_loss = 0.60057709, grad/param norm = 2.5285e-01, time/batch = 16.1828s	
22146/22750 (epoch 48.673), train_loss = 0.82425499, grad/param norm = 3.0855e-01, time/batch = 15.6330s	
22147/22750 (epoch 48.675), train_loss = 0.89097301, grad/param norm = 2.6744e-01, time/batch = 15.8755s	
22148/22750 (epoch 48.677), train_loss = 0.77785390, grad/param norm = 2.6368e-01, time/batch = 16.2710s	
22149/22750 (epoch 48.679), train_loss = 0.76121265, grad/param norm = 2.7151e-01, time/batch = 16.1692s	
22150/22750 (epoch 48.681), train_loss = 0.77974942, grad/param norm = 2.8068e-01, time/batch = 16.1721s	
22151/22750 (epoch 48.684), train_loss = 0.78897397, grad/param norm = 2.5119e-01, time/batch = 16.7460s	
22152/22750 (epoch 48.686), train_loss = 0.83903664, grad/param norm = 2.7449e-01, time/batch = 16.8105s	
22153/22750 (epoch 48.688), train_loss = 0.77432716, grad/param norm = 2.4463e-01, time/batch = 16.4265s	
22154/22750 (epoch 48.690), train_loss = 0.78005251, grad/param norm = 3.1247e-01, time/batch = 16.3403s	
22155/22750 (epoch 48.692), train_loss = 0.78652954, grad/param norm = 3.0622e-01, time/batch = 15.8595s	
22156/22750 (epoch 48.695), train_loss = 0.69516906, grad/param norm = 2.2973e-01, time/batch = 15.7810s	
22157/22750 (epoch 48.697), train_loss = 0.72366315, grad/param norm = 2.6833e-01, time/batch = 15.6886s	
22158/22750 (epoch 48.699), train_loss = 0.61632824, grad/param norm = 2.2170e-01, time/batch = 16.0404s	
22159/22750 (epoch 48.701), train_loss = 0.58247004, grad/param norm = 2.8089e-01, time/batch = 15.6978s	
22160/22750 (epoch 48.703), train_loss = 0.65970752, grad/param norm = 2.8593e-01, time/batch = 15.8619s	
22161/22750 (epoch 48.705), train_loss = 0.61892025, grad/param norm = 2.2696e-01, time/batch = 15.6122s	
22162/22750 (epoch 48.708), train_loss = 0.65136104, grad/param norm = 2.6736e-01, time/batch = 16.4966s	
22163/22750 (epoch 48.710), train_loss = 0.60237913, grad/param norm = 2.4206e-01, time/batch = 15.5208s	
22164/22750 (epoch 48.712), train_loss = 0.50955942, grad/param norm = 2.0692e-01, time/batch = 15.6154s	
22165/22750 (epoch 48.714), train_loss = 0.57367113, grad/param norm = 2.1636e-01, time/batch = 15.6140s	
22166/22750 (epoch 48.716), train_loss = 0.57470103, grad/param norm = 1.9695e-01, time/batch = 16.0985s	
22167/22750 (epoch 48.719), train_loss = 0.63843303, grad/param norm = 2.7544e-01, time/batch = 15.7054s	
22168/22750 (epoch 48.721), train_loss = 0.77507721, grad/param norm = 2.5536e-01, time/batch = 16.1689s	
22169/22750 (epoch 48.723), train_loss = 0.71585556, grad/param norm = 2.9504e-01, time/batch = 16.6193s	
22170/22750 (epoch 48.725), train_loss = 0.61926586, grad/param norm = 2.3368e-01, time/batch = 16.5023s	
22171/22750 (epoch 48.727), train_loss = 0.66452368, grad/param norm = 2.4552e-01, time/batch = 16.8877s	
22172/22750 (epoch 48.730), train_loss = 0.62817140, grad/param norm = 2.2299e-01, time/batch = 16.4107s	
22173/22750 (epoch 48.732), train_loss = 0.61728480, grad/param norm = 2.4281e-01, time/batch = 16.6445s	
22174/22750 (epoch 48.734), train_loss = 0.56705421, grad/param norm = 2.1089e-01, time/batch = 16.5470s	
22175/22750 (epoch 48.736), train_loss = 0.62628375, grad/param norm = 2.5850e-01, time/batch = 16.0785s	
22176/22750 (epoch 48.738), train_loss = 0.68146031, grad/param norm = 2.4857e-01, time/batch = 15.6599s	
22177/22750 (epoch 48.741), train_loss = 0.79656353, grad/param norm = 2.6112e-01, time/batch = 16.3031s	
22178/22750 (epoch 48.743), train_loss = 0.67361067, grad/param norm = 2.5551e-01, time/batch = 16.3904s	
22179/22750 (epoch 48.745), train_loss = 0.57562708, grad/param norm = 2.1445e-01, time/batch = 15.6806s	
22180/22750 (epoch 48.747), train_loss = 0.67266126, grad/param norm = 2.1624e-01, time/batch = 15.9920s	
22181/22750 (epoch 48.749), train_loss = 0.78324095, grad/param norm = 2.7613e-01, time/batch = 16.0056s	
22182/22750 (epoch 48.752), train_loss = 0.68533558, grad/param norm = 2.5533e-01, time/batch = 16.0831s	
22183/22750 (epoch 48.754), train_loss = 0.66365325, grad/param norm = 2.5243e-01, time/batch = 16.2359s	
22184/22750 (epoch 48.756), train_loss = 0.61903322, grad/param norm = 2.5637e-01, time/batch = 16.2153s	
22185/22750 (epoch 48.758), train_loss = 0.60264679, grad/param norm = 2.1763e-01, time/batch = 16.0304s	
22186/22750 (epoch 48.760), train_loss = 0.59658480, grad/param norm = 2.5752e-01, time/batch = 16.4337s	
22187/22750 (epoch 48.763), train_loss = 0.64739857, grad/param norm = 2.5838e-01, time/batch = 16.7556s	
22188/22750 (epoch 48.765), train_loss = 0.65592413, grad/param norm = 2.4757e-01, time/batch = 16.5209s	
22189/22750 (epoch 48.767), train_loss = 0.70059404, grad/param norm = 2.4925e-01, time/batch = 16.0459s	
22190/22750 (epoch 48.769), train_loss = 0.76675106, grad/param norm = 2.7272e-01, time/batch = 15.9878s	
22191/22750 (epoch 48.771), train_loss = 0.79757897, grad/param norm = 2.9122e-01, time/batch = 17.5982s	
22192/22750 (epoch 48.774), train_loss = 0.61759757, grad/param norm = 2.5143e-01, time/batch = 17.5884s	
22193/22750 (epoch 48.776), train_loss = 0.73863707, grad/param norm = 2.5636e-01, time/batch = 17.2815s	
22194/22750 (epoch 48.778), train_loss = 0.77353254, grad/param norm = 2.6949e-01, time/batch = 16.8500s	
22195/22750 (epoch 48.780), train_loss = 0.68585883, grad/param norm = 2.2646e-01, time/batch = 31.6615s	
22196/22750 (epoch 48.782), train_loss = 0.77952893, grad/param norm = 2.3665e-01, time/batch = 18.1637s	
22197/22750 (epoch 48.785), train_loss = 0.64974422, grad/param norm = 2.8922e-01, time/batch = 17.4867s	
22198/22750 (epoch 48.787), train_loss = 0.57190172, grad/param norm = 2.6770e-01, time/batch = 16.4041s	
22199/22750 (epoch 48.789), train_loss = 0.65535823, grad/param norm = 2.2825e-01, time/batch = 17.0034s	
22200/22750 (epoch 48.791), train_loss = 0.62499464, grad/param norm = 2.2505e-01, time/batch = 15.8546s	
22201/22750 (epoch 48.793), train_loss = 0.62012860, grad/param norm = 2.6661e-01, time/batch = 16.5739s	
22202/22750 (epoch 48.796), train_loss = 0.56298288, grad/param norm = 2.3457e-01, time/batch = 16.0086s	
22203/22750 (epoch 48.798), train_loss = 0.62995950, grad/param norm = 2.4154e-01, time/batch = 15.8559s	
22204/22750 (epoch 48.800), train_loss = 0.61392140, grad/param norm = 2.6990e-01, time/batch = 15.7816s	
22205/22750 (epoch 48.802), train_loss = 0.58109110, grad/param norm = 3.0783e-01, time/batch = 16.3531s	
22206/22750 (epoch 48.804), train_loss = 0.73562709, grad/param norm = 2.2904e-01, time/batch = 16.2487s	
22207/22750 (epoch 48.807), train_loss = 0.71555371, grad/param norm = 2.5694e-01, time/batch = 16.6357s	
22208/22750 (epoch 48.809), train_loss = 0.80779670, grad/param norm = 3.5025e-01, time/batch = 16.2537s	
22209/22750 (epoch 48.811), train_loss = 0.67855856, grad/param norm = 2.6455e-01, time/batch = 16.4105s	
22210/22750 (epoch 48.813), train_loss = 0.69665304, grad/param norm = 2.3378e-01, time/batch = 16.1632s	
22211/22750 (epoch 48.815), train_loss = 0.76437737, grad/param norm = 2.2063e-01, time/batch = 15.8597s	
22212/22750 (epoch 48.818), train_loss = 0.73667774, grad/param norm = 2.4393e-01, time/batch = 16.3292s	
22213/22750 (epoch 48.820), train_loss = 0.82910433, grad/param norm = 2.4977e-01, time/batch = 15.7623s	
22214/22750 (epoch 48.822), train_loss = 0.70645175, grad/param norm = 2.4270e-01, time/batch = 15.9362s	
22215/22750 (epoch 48.824), train_loss = 0.60264761, grad/param norm = 2.1830e-01, time/batch = 15.9314s	
22216/22750 (epoch 48.826), train_loss = 0.65749831, grad/param norm = 2.7846e-01, time/batch = 16.2644s	
22217/22750 (epoch 48.829), train_loss = 0.73355720, grad/param norm = 2.4050e-01, time/batch = 16.5611s	
22218/22750 (epoch 48.831), train_loss = 0.74976570, grad/param norm = 2.5311e-01, time/batch = 16.3394s	
22219/22750 (epoch 48.833), train_loss = 0.69881176, grad/param norm = 2.7793e-01, time/batch = 16.7339s	
22220/22750 (epoch 48.835), train_loss = 0.59670641, grad/param norm = 2.6847e-01, time/batch = 16.3542s	
22221/22750 (epoch 48.837), train_loss = 0.68193720, grad/param norm = 2.5751e-01, time/batch = 15.8525s	
22222/22750 (epoch 48.840), train_loss = 0.59966022, grad/param norm = 2.3403e-01, time/batch = 16.4305s	
22223/22750 (epoch 48.842), train_loss = 0.59434624, grad/param norm = 2.5833e-01, time/batch = 16.4966s	
22224/22750 (epoch 48.844), train_loss = 0.70920308, grad/param norm = 3.1312e-01, time/batch = 15.8580s	
22225/22750 (epoch 48.846), train_loss = 0.72702548, grad/param norm = 2.4414e-01, time/batch = 16.1006s	
22226/22750 (epoch 48.848), train_loss = 0.63926033, grad/param norm = 2.3589e-01, time/batch = 15.9433s	
22227/22750 (epoch 48.851), train_loss = 0.61889177, grad/param norm = 2.3444e-01, time/batch = 16.5147s	
22228/22750 (epoch 48.853), train_loss = 0.79048179, grad/param norm = 2.6502e-01, time/batch = 16.6109s	
22229/22750 (epoch 48.855), train_loss = 0.65897351, grad/param norm = 2.0680e-01, time/batch = 16.1143s	
22230/22750 (epoch 48.857), train_loss = 0.72404330, grad/param norm = 2.8780e-01, time/batch = 16.1769s	
22231/22750 (epoch 48.859), train_loss = 0.70110563, grad/param norm = 3.1401e-01, time/batch = 16.1007s	
22232/22750 (epoch 48.862), train_loss = 0.80723724, grad/param norm = 2.8459e-01, time/batch = 15.9368s	
22233/22750 (epoch 48.864), train_loss = 0.68205462, grad/param norm = 2.4274e-01, time/batch = 15.6950s	
22234/22750 (epoch 48.866), train_loss = 0.72279980, grad/param norm = 2.4014e-01, time/batch = 15.9450s	
22235/22750 (epoch 48.868), train_loss = 0.61663991, grad/param norm = 2.3665e-01, time/batch = 15.6241s	
22236/22750 (epoch 48.870), train_loss = 0.59176153, grad/param norm = 2.1585e-01, time/batch = 15.6903s	
22237/22750 (epoch 48.873), train_loss = 0.68014585, grad/param norm = 2.5944e-01, time/batch = 16.0967s	
22238/22750 (epoch 48.875), train_loss = 0.70981565, grad/param norm = 2.2807e-01, time/batch = 16.1747s	
22239/22750 (epoch 48.877), train_loss = 0.66679499, grad/param norm = 2.4007e-01, time/batch = 15.9352s	
22240/22750 (epoch 48.879), train_loss = 0.77525887, grad/param norm = 2.7474e-01, time/batch = 15.6213s	
22241/22750 (epoch 48.881), train_loss = 0.67580148, grad/param norm = 2.2749e-01, time/batch = 15.5558s	
22242/22750 (epoch 48.884), train_loss = 0.61051821, grad/param norm = 2.1598e-01, time/batch = 16.6441s	
22243/22750 (epoch 48.886), train_loss = 0.68940060, grad/param norm = 2.1979e-01, time/batch = 15.9351s	
22244/22750 (epoch 48.888), train_loss = 0.73192344, grad/param norm = 2.3829e-01, time/batch = 16.7397s	
22245/22750 (epoch 48.890), train_loss = 0.73652115, grad/param norm = 2.5015e-01, time/batch = 16.5613s	
22246/22750 (epoch 48.892), train_loss = 0.89273226, grad/param norm = 2.9050e-01, time/batch = 16.4309s	
22247/22750 (epoch 48.895), train_loss = 0.64899378, grad/param norm = 2.5859e-01, time/batch = 16.7374s	
22248/22750 (epoch 48.897), train_loss = 0.78194742, grad/param norm = 2.8551e-01, time/batch = 16.1826s	
22249/22750 (epoch 48.899), train_loss = 0.69812573, grad/param norm = 2.6684e-01, time/batch = 16.6478s	
22250/22750 (epoch 48.901), train_loss = 0.78160493, grad/param norm = 2.7952e-01, time/batch = 16.1607s	
22251/22750 (epoch 48.903), train_loss = 0.66477179, grad/param norm = 2.4066e-01, time/batch = 15.5443s	
22252/22750 (epoch 48.905), train_loss = 0.70713506, grad/param norm = 2.6780e-01, time/batch = 15.5479s	
22253/22750 (epoch 48.908), train_loss = 0.57096882, grad/param norm = 2.4019e-01, time/batch = 15.8633s	
22254/22750 (epoch 48.910), train_loss = 0.52337190, grad/param norm = 2.5981e-01, time/batch = 15.4631s	
22255/22750 (epoch 48.912), train_loss = 0.69569310, grad/param norm = 3.2647e-01, time/batch = 15.5208s	
22256/22750 (epoch 48.914), train_loss = 0.69786260, grad/param norm = 2.5210e-01, time/batch = 15.5238s	
22257/22750 (epoch 48.916), train_loss = 0.55542771, grad/param norm = 2.1715e-01, time/batch = 16.0030s	
22258/22750 (epoch 48.919), train_loss = 0.69032704, grad/param norm = 2.8362e-01, time/batch = 15.7642s	
22259/22750 (epoch 48.921), train_loss = 0.52992269, grad/param norm = 2.4059e-01, time/batch = 15.8893s	
22260/22750 (epoch 48.923), train_loss = 0.64030748, grad/param norm = 2.8171e-01, time/batch = 15.5320s	
22261/22750 (epoch 48.925), train_loss = 0.67343086, grad/param norm = 2.2882e-01, time/batch = 15.7672s	
22262/22750 (epoch 48.927), train_loss = 0.52667619, grad/param norm = 2.2782e-01, time/batch = 15.5418s	
22263/22750 (epoch 48.930), train_loss = 0.51101545, grad/param norm = 2.1688e-01, time/batch = 15.5301s	
22264/22750 (epoch 48.932), train_loss = 0.65879071, grad/param norm = 2.9849e-01, time/batch = 16.5649s	
22265/22750 (epoch 48.934), train_loss = 0.58300068, grad/param norm = 2.7191e-01, time/batch = 16.2528s	
22266/22750 (epoch 48.936), train_loss = 0.74814328, grad/param norm = 3.1382e-01, time/batch = 16.8394s	
22267/22750 (epoch 48.938), train_loss = 0.72551567, grad/param norm = 2.3596e-01, time/batch = 17.2687s	
22268/22750 (epoch 48.941), train_loss = 0.77694953, grad/param norm = 2.6609e-01, time/batch = 17.3262s	
22269/22750 (epoch 48.943), train_loss = 0.68390007, grad/param norm = 2.7119e-01, time/batch = 17.0212s	
22270/22750 (epoch 48.945), train_loss = 0.69083086, grad/param norm = 2.6008e-01, time/batch = 16.9164s	
22271/22750 (epoch 48.947), train_loss = 0.62203119, grad/param norm = 2.4808e-01, time/batch = 17.0918s	
22272/22750 (epoch 48.949), train_loss = 0.64751352, grad/param norm = 2.4637e-01, time/batch = 16.9465s	
22273/22750 (epoch 48.952), train_loss = 0.65167047, grad/param norm = 2.6054e-01, time/batch = 17.2215s	
22274/22750 (epoch 48.954), train_loss = 0.53921838, grad/param norm = 1.9677e-01, time/batch = 17.1037s	
22275/22750 (epoch 48.956), train_loss = 0.71802587, grad/param norm = 2.3012e-01, time/batch = 17.4341s	
22276/22750 (epoch 48.958), train_loss = 0.59192072, grad/param norm = 2.0842e-01, time/batch = 17.3313s	
22277/22750 (epoch 48.960), train_loss = 0.58511408, grad/param norm = 2.5674e-01, time/batch = 17.2421s	
22278/22750 (epoch 48.963), train_loss = 0.68116478, grad/param norm = 2.1731e-01, time/batch = 17.4052s	
22279/22750 (epoch 48.965), train_loss = 0.72839401, grad/param norm = 2.0840e-01, time/batch = 17.2937s	
22280/22750 (epoch 48.967), train_loss = 0.71956933, grad/param norm = 2.6622e-01, time/batch = 17.2323s	
22281/22750 (epoch 48.969), train_loss = 0.62245790, grad/param norm = 2.4770e-01, time/batch = 17.1785s	
22282/22750 (epoch 48.971), train_loss = 0.61492407, grad/param norm = 2.3055e-01, time/batch = 17.4001s	
22283/22750 (epoch 48.974), train_loss = 0.60582493, grad/param norm = 2.3266e-01, time/batch = 17.1768s	
22284/22750 (epoch 48.976), train_loss = 0.63770900, grad/param norm = 2.4497e-01, time/batch = 17.1915s	
22285/22750 (epoch 48.978), train_loss = 0.59542963, grad/param norm = 2.3670e-01, time/batch = 17.2469s	
22286/22750 (epoch 48.980), train_loss = 0.78253072, grad/param norm = 2.4953e-01, time/batch = 17.1163s	
22287/22750 (epoch 48.982), train_loss = 0.61495227, grad/param norm = 1.9434e-01, time/batch = 17.1827s	
22288/22750 (epoch 48.985), train_loss = 0.78569032, grad/param norm = 2.5238e-01, time/batch = 17.1710s	
22289/22750 (epoch 48.987), train_loss = 0.53770101, grad/param norm = 2.0457e-01, time/batch = 17.1810s	
22290/22750 (epoch 48.989), train_loss = 0.58085433, grad/param norm = 2.3248e-01, time/batch = 17.2546s	
22291/22750 (epoch 48.991), train_loss = 0.70866936, grad/param norm = 2.4100e-01, time/batch = 17.2656s	
22292/22750 (epoch 48.993), train_loss = 0.65695124, grad/param norm = 2.8810e-01, time/batch = 17.1666s	
22293/22750 (epoch 48.996), train_loss = 0.57838213, grad/param norm = 2.8772e-01, time/batch = 17.2524s	
22294/22750 (epoch 48.998), train_loss = 0.73929068, grad/param norm = 2.6394e-01, time/batch = 17.3561s	
decayed learning rate by a factor 0.97 to 0.00059142457479826	
22295/22750 (epoch 49.000), train_loss = 0.64435583, grad/param norm = 2.3059e-01, time/batch = 17.3605s	
22296/22750 (epoch 49.002), train_loss = 0.80168464, grad/param norm = 2.2787e-01, time/batch = 17.1807s	
22297/22750 (epoch 49.004), train_loss = 0.64469990, grad/param norm = 2.1451e-01, time/batch = 17.0426s	
22298/22750 (epoch 49.007), train_loss = 0.63487777, grad/param norm = 2.3527e-01, time/batch = 17.2615s	
22299/22750 (epoch 49.009), train_loss = 0.77859185, grad/param norm = 2.7984e-01, time/batch = 17.1061s	
22300/22750 (epoch 49.011), train_loss = 0.83508076, grad/param norm = 2.7493e-01, time/batch = 17.0010s	
22301/22750 (epoch 49.013), train_loss = 0.74862206, grad/param norm = 2.3719e-01, time/batch = 17.1764s	
22302/22750 (epoch 49.015), train_loss = 0.66880914, grad/param norm = 2.6040e-01, time/batch = 17.1514s	
22303/22750 (epoch 49.018), train_loss = 0.79153617, grad/param norm = 2.4160e-01, time/batch = 17.2935s	
22304/22750 (epoch 49.020), train_loss = 0.78039714, grad/param norm = 2.6125e-01, time/batch = 17.1619s	
22305/22750 (epoch 49.022), train_loss = 0.67819474, grad/param norm = 2.5858e-01, time/batch = 17.0068s	
22306/22750 (epoch 49.024), train_loss = 0.68084035, grad/param norm = 2.5234e-01, time/batch = 17.0514s	
22307/22750 (epoch 49.026), train_loss = 0.71215853, grad/param norm = 2.6329e-01, time/batch = 16.6767s	
22308/22750 (epoch 49.029), train_loss = 0.55922501, grad/param norm = 2.4492e-01, time/batch = 16.6117s	
22309/22750 (epoch 49.031), train_loss = 0.89627453, grad/param norm = 3.1362e-01, time/batch = 17.0806s	
22310/22750 (epoch 49.033), train_loss = 0.71067855, grad/param norm = 2.8475e-01, time/batch = 16.9176s	
22311/22750 (epoch 49.035), train_loss = 0.72609017, grad/param norm = 2.5488e-01, time/batch = 16.6817s	
22312/22750 (epoch 49.037), train_loss = 0.73849184, grad/param norm = 2.6087e-01, time/batch = 16.6790s	
22313/22750 (epoch 49.040), train_loss = 0.69320629, grad/param norm = 2.2731e-01, time/batch = 16.6865s	
22314/22750 (epoch 49.042), train_loss = 0.68966696, grad/param norm = 2.6509e-01, time/batch = 16.6014s	
22315/22750 (epoch 49.044), train_loss = 0.67495450, grad/param norm = 2.4961e-01, time/batch = 16.6784s	
22316/22750 (epoch 49.046), train_loss = 0.77059359, grad/param norm = 2.8782e-01, time/batch = 16.6551s	
22317/22750 (epoch 49.048), train_loss = 0.70948943, grad/param norm = 2.2200e-01, time/batch = 16.8096s	
22318/22750 (epoch 49.051), train_loss = 0.70061578, grad/param norm = 2.4590e-01, time/batch = 16.5868s	
22319/22750 (epoch 49.053), train_loss = 0.67354515, grad/param norm = 2.1104e-01, time/batch = 16.7427s	
22320/22750 (epoch 49.055), train_loss = 0.60980433, grad/param norm = 2.1884e-01, time/batch = 17.3029s	
22321/22750 (epoch 49.057), train_loss = 0.80481342, grad/param norm = 3.0726e-01, time/batch = 16.7825s	
22322/22750 (epoch 49.059), train_loss = 0.50094389, grad/param norm = 2.0924e-01, time/batch = 16.8546s	
22323/22750 (epoch 49.062), train_loss = 0.57278563, grad/param norm = 2.0683e-01, time/batch = 16.7770s	
22324/22750 (epoch 49.064), train_loss = 0.79029448, grad/param norm = 2.5077e-01, time/batch = 16.9306s	
22325/22750 (epoch 49.066), train_loss = 0.58415873, grad/param norm = 2.1752e-01, time/batch = 16.7566s	
22326/22750 (epoch 49.068), train_loss = 0.61032124, grad/param norm = 1.9416e-01, time/batch = 16.8368s	
22327/22750 (epoch 49.070), train_loss = 0.51798016, grad/param norm = 2.1871e-01, time/batch = 16.9048s	
22328/22750 (epoch 49.073), train_loss = 0.60466776, grad/param norm = 2.2068e-01, time/batch = 16.7626s	
22329/22750 (epoch 49.075), train_loss = 0.67777616, grad/param norm = 2.1607e-01, time/batch = 16.6824s	
22330/22750 (epoch 49.077), train_loss = 0.51481981, grad/param norm = 2.2483e-01, time/batch = 16.8160s	
22331/22750 (epoch 49.079), train_loss = 0.66444029, grad/param norm = 2.8990e-01, time/batch = 17.3849s	
22332/22750 (epoch 49.081), train_loss = 0.63111041, grad/param norm = 2.1866e-01, time/batch = 16.8545s	
22333/22750 (epoch 49.084), train_loss = 0.60676854, grad/param norm = 2.1354e-01, time/batch = 17.1323s	
22334/22750 (epoch 49.086), train_loss = 0.66067435, grad/param norm = 2.2768e-01, time/batch = 16.9274s	
22335/22750 (epoch 49.088), train_loss = 0.64139849, grad/param norm = 2.3011e-01, time/batch = 17.0023s	
22336/22750 (epoch 49.090), train_loss = 0.64163263, grad/param norm = 2.4007e-01, time/batch = 16.8400s	
22337/22750 (epoch 49.092), train_loss = 0.70500765, grad/param norm = 2.2715e-01, time/batch = 16.7494s	
22338/22750 (epoch 49.095), train_loss = 0.61002826, grad/param norm = 2.2496e-01, time/batch = 17.0608s	
22339/22750 (epoch 49.097), train_loss = 0.67626692, grad/param norm = 2.4458e-01, time/batch = 16.5957s	
22340/22750 (epoch 49.099), train_loss = 0.60935672, grad/param norm = 2.5389e-01, time/batch = 16.8950s	
22341/22750 (epoch 49.101), train_loss = 0.55069630, grad/param norm = 2.2450e-01, time/batch = 17.0800s	
22342/22750 (epoch 49.103), train_loss = 0.68481190, grad/param norm = 2.3372e-01, time/batch = 17.0866s	
22343/22750 (epoch 49.105), train_loss = 0.76895434, grad/param norm = 3.2908e-01, time/batch = 16.8675s	
22344/22750 (epoch 49.108), train_loss = 0.70914441, grad/param norm = 2.4487e-01, time/batch = 16.7842s	
22345/22750 (epoch 49.110), train_loss = 0.73368742, grad/param norm = 2.4306e-01, time/batch = 17.2922s	
22346/22750 (epoch 49.112), train_loss = 0.55529518, grad/param norm = 1.8472e-01, time/batch = 17.1583s	
22347/22750 (epoch 49.114), train_loss = 0.49561135, grad/param norm = 2.2407e-01, time/batch = 17.0133s	
22348/22750 (epoch 49.116), train_loss = 0.68656894, grad/param norm = 2.3485e-01, time/batch = 17.2123s	
22349/22750 (epoch 49.119), train_loss = 0.64514400, grad/param norm = 2.2257e-01, time/batch = 17.2539s	
22350/22750 (epoch 49.121), train_loss = 0.63468153, grad/param norm = 2.4683e-01, time/batch = 19.8938s	
22351/22750 (epoch 49.123), train_loss = 0.55601462, grad/param norm = 2.2168e-01, time/batch = 20.4902s	
22352/22750 (epoch 49.125), train_loss = 0.73143097, grad/param norm = 2.5792e-01, time/batch = 20.5743s	
22353/22750 (epoch 49.127), train_loss = 0.62571957, grad/param norm = 2.4318e-01, time/batch = 21.9269s	
22354/22750 (epoch 49.130), train_loss = 0.65745987, grad/param norm = 2.1634e-01, time/batch = 18.0917s	
22355/22750 (epoch 49.132), train_loss = 0.61986303, grad/param norm = 2.1750e-01, time/batch = 17.0791s	
22356/22750 (epoch 49.134), train_loss = 0.64071646, grad/param norm = 2.2238e-01, time/batch = 17.0705s	
22357/22750 (epoch 49.136), train_loss = 0.52307111, grad/param norm = 2.1873e-01, time/batch = 17.6736s	
22358/22750 (epoch 49.138), train_loss = 0.72801181, grad/param norm = 2.4164e-01, time/batch = 18.6376s	
22359/22750 (epoch 49.141), train_loss = 0.64849616, grad/param norm = 2.6244e-01, time/batch = 19.1585s	
22360/22750 (epoch 49.143), train_loss = 0.63255945, grad/param norm = 2.5547e-01, time/batch = 16.8441s	
22361/22750 (epoch 49.145), train_loss = 0.76664799, grad/param norm = 2.7039e-01, time/batch = 16.2748s	
22362/22750 (epoch 49.147), train_loss = 0.80425380, grad/param norm = 2.5214e-01, time/batch = 17.0112s	
22363/22750 (epoch 49.149), train_loss = 0.68108509, grad/param norm = 2.7555e-01, time/batch = 18.2809s	
22364/22750 (epoch 49.152), train_loss = 0.68214091, grad/param norm = 2.6701e-01, time/batch = 18.1694s	
22365/22750 (epoch 49.154), train_loss = 0.58851184, grad/param norm = 2.4188e-01, time/batch = 18.8249s	
22366/22750 (epoch 49.156), train_loss = 0.59680762, grad/param norm = 2.3510e-01, time/batch = 19.6661s	
22367/22750 (epoch 49.158), train_loss = 0.56816206, grad/param norm = 2.1273e-01, time/batch = 20.0686s	
22368/22750 (epoch 49.160), train_loss = 0.65818533, grad/param norm = 2.4715e-01, time/batch = 16.8752s	
22369/22750 (epoch 49.163), train_loss = 0.77500416, grad/param norm = 2.5152e-01, time/batch = 17.3946s	
22370/22750 (epoch 49.165), train_loss = 0.72140334, grad/param norm = 2.6735e-01, time/batch = 20.2736s	
22371/22750 (epoch 49.167), train_loss = 0.61242545, grad/param norm = 2.3577e-01, time/batch = 17.1829s	
22372/22750 (epoch 49.169), train_loss = 0.64159689, grad/param norm = 2.7638e-01, time/batch = 19.6138s	
22373/22750 (epoch 49.171), train_loss = 0.56648480, grad/param norm = 2.1079e-01, time/batch = 19.0069s	
22374/22750 (epoch 49.174), train_loss = 0.52991942, grad/param norm = 2.0333e-01, time/batch = 17.9208s	
22375/22750 (epoch 49.176), train_loss = 0.57092585, grad/param norm = 2.3982e-01, time/batch = 17.7458s	
22376/22750 (epoch 49.178), train_loss = 0.60875674, grad/param norm = 2.1436e-01, time/batch = 16.9449s	
22377/22750 (epoch 49.180), train_loss = 0.77739890, grad/param norm = 4.2328e-01, time/batch = 16.6805s	
22378/22750 (epoch 49.182), train_loss = 0.71208541, grad/param norm = 2.8360e-01, time/batch = 16.6136s	
22379/22750 (epoch 49.185), train_loss = 0.74591040, grad/param norm = 2.7112e-01, time/batch = 16.3195s	
22380/22750 (epoch 49.187), train_loss = 0.57418606, grad/param norm = 2.1858e-01, time/batch = 17.4409s	
22381/22750 (epoch 49.189), train_loss = 0.58664902, grad/param norm = 2.6183e-01, time/batch = 17.8981s	
22382/22750 (epoch 49.191), train_loss = 0.62083749, grad/param norm = 2.2257e-01, time/batch = 21.0742s	
22383/22750 (epoch 49.193), train_loss = 0.70829895, grad/param norm = 2.5940e-01, time/batch = 18.5801s	
22384/22750 (epoch 49.196), train_loss = 0.63503584, grad/param norm = 3.4788e-01, time/batch = 17.5000s	
22385/22750 (epoch 49.198), train_loss = 0.47609986, grad/param norm = 2.3351e-01, time/batch = 17.5007s	
22386/22750 (epoch 49.200), train_loss = 0.66155286, grad/param norm = 2.1255e-01, time/batch = 18.5871s	
22387/22750 (epoch 49.202), train_loss = 0.71376241, grad/param norm = 3.0908e-01, time/batch = 18.9927s	
22388/22750 (epoch 49.204), train_loss = 0.68559097, grad/param norm = 2.3342e-01, time/batch = 18.3315s	
22389/22750 (epoch 49.207), train_loss = 0.71587186, grad/param norm = 2.8349e-01, time/batch = 19.6772s	
22390/22750 (epoch 49.209), train_loss = 0.63343558, grad/param norm = 2.1721e-01, time/batch = 20.0170s	
22391/22750 (epoch 49.211), train_loss = 0.56921160, grad/param norm = 2.2868e-01, time/batch = 19.0205s	
22392/22750 (epoch 49.213), train_loss = 0.48105313, grad/param norm = 2.0858e-01, time/batch = 18.2691s	
22393/22750 (epoch 49.215), train_loss = 0.49849649, grad/param norm = 1.8837e-01, time/batch = 20.0910s	
22394/22750 (epoch 49.218), train_loss = 0.59274959, grad/param norm = 3.0691e-01, time/batch = 17.1514s	
22395/22750 (epoch 49.220), train_loss = 0.55731832, grad/param norm = 2.2959e-01, time/batch = 18.7622s	
22396/22750 (epoch 49.222), train_loss = 0.54100089, grad/param norm = 2.3084e-01, time/batch = 17.8268s	
22397/22750 (epoch 49.224), train_loss = 0.55141402, grad/param norm = 2.0600e-01, time/batch = 18.1616s	
22398/22750 (epoch 49.226), train_loss = 0.63030191, grad/param norm = 2.3114e-01, time/batch = 17.2483s	
22399/22750 (epoch 49.229), train_loss = 0.64441831, grad/param norm = 2.0843e-01, time/batch = 17.0581s	
22400/22750 (epoch 49.231), train_loss = 0.57543198, grad/param norm = 2.5168e-01, time/batch = 16.7975s	
22401/22750 (epoch 49.233), train_loss = 0.52832211, grad/param norm = 2.3251e-01, time/batch = 17.1105s	
22402/22750 (epoch 49.235), train_loss = 0.53145625, grad/param norm = 2.4262e-01, time/batch = 17.0181s	
22403/22750 (epoch 49.237), train_loss = 0.56697824, grad/param norm = 2.8763e-01, time/batch = 17.0240s	
22404/22750 (epoch 49.240), train_loss = 0.65970800, grad/param norm = 2.1307e-01, time/batch = 27.3238s	
22405/22750 (epoch 49.242), train_loss = 0.73920634, grad/param norm = 2.4048e-01, time/batch = 20.8572s	
22406/22750 (epoch 49.244), train_loss = 0.75330068, grad/param norm = 2.5335e-01, time/batch = 17.0717s	
22407/22750 (epoch 49.246), train_loss = 0.78242113, grad/param norm = 2.6876e-01, time/batch = 17.2265s	
22408/22750 (epoch 49.248), train_loss = 0.65267601, grad/param norm = 2.0348e-01, time/batch = 16.5967s	
22409/22750 (epoch 49.251), train_loss = 0.70379429, grad/param norm = 2.6320e-01, time/batch = 16.7563s	
22410/22750 (epoch 49.253), train_loss = 0.70553321, grad/param norm = 3.2853e-01, time/batch = 16.8258s	
22411/22750 (epoch 49.255), train_loss = 0.70273758, grad/param norm = 2.6464e-01, time/batch = 16.9418s	
22412/22750 (epoch 49.257), train_loss = 0.60746264, grad/param norm = 2.4972e-01, time/batch = 16.9354s	
22413/22750 (epoch 49.259), train_loss = 0.69643442, grad/param norm = 2.6264e-01, time/batch = 16.9138s	
22414/22750 (epoch 49.262), train_loss = 0.67484738, grad/param norm = 2.4143e-01, time/batch = 17.4472s	
22415/22750 (epoch 49.264), train_loss = 0.50629424, grad/param norm = 2.1886e-01, time/batch = 17.0601s	
22416/22750 (epoch 49.266), train_loss = 0.64334589, grad/param norm = 3.2977e-01, time/batch = 17.3216s	
22417/22750 (epoch 49.268), train_loss = 0.79079404, grad/param norm = 2.6306e-01, time/batch = 17.0750s	
22418/22750 (epoch 49.270), train_loss = 0.62718079, grad/param norm = 2.9474e-01, time/batch = 17.1707s	
22419/22750 (epoch 49.273), train_loss = 0.92868263, grad/param norm = 3.9207e-01, time/batch = 17.1663s	
22420/22750 (epoch 49.275), train_loss = 0.80144527, grad/param norm = 2.3955e-01, time/batch = 16.8329s	
22421/22750 (epoch 49.277), train_loss = 0.67085610, grad/param norm = 2.9764e-01, time/batch = 17.4572s	
22422/22750 (epoch 49.279), train_loss = 0.57171254, grad/param norm = 2.4513e-01, time/batch = 17.3459s	
22423/22750 (epoch 49.281), train_loss = 0.75857643, grad/param norm = 2.3853e-01, time/batch = 17.2772s	
22424/22750 (epoch 49.284), train_loss = 0.70620594, grad/param norm = 2.3469e-01, time/batch = 17.3484s	
22425/22750 (epoch 49.286), train_loss = 0.71498788, grad/param norm = 2.6649e-01, time/batch = 17.3359s	
22426/22750 (epoch 49.288), train_loss = 0.78532218, grad/param norm = 2.5063e-01, time/batch = 17.3301s	
22427/22750 (epoch 49.290), train_loss = 0.71735975, grad/param norm = 2.4569e-01, time/batch = 16.8397s	
22428/22750 (epoch 49.292), train_loss = 0.71103778, grad/param norm = 2.6896e-01, time/batch = 17.0012s	
22429/22750 (epoch 49.295), train_loss = 0.70505254, grad/param norm = 2.4848e-01, time/batch = 16.7534s	
22430/22750 (epoch 49.297), train_loss = 0.68483742, grad/param norm = 2.6090e-01, time/batch = 16.6764s	
22431/22750 (epoch 49.299), train_loss = 0.72155434, grad/param norm = 2.5620e-01, time/batch = 16.9177s	
22432/22750 (epoch 49.301), train_loss = 0.63993920, grad/param norm = 2.3124e-01, time/batch = 16.8492s	
22433/22750 (epoch 49.303), train_loss = 0.69549156, grad/param norm = 2.5352e-01, time/batch = 17.0856s	
22434/22750 (epoch 49.305), train_loss = 0.75760457, grad/param norm = 2.3161e-01, time/batch = 16.7774s	
22435/22750 (epoch 49.308), train_loss = 0.74330454, grad/param norm = 2.4806e-01, time/batch = 17.2412s	
22436/22750 (epoch 49.310), train_loss = 0.61804928, grad/param norm = 2.7234e-01, time/batch = 16.9942s	
22437/22750 (epoch 49.312), train_loss = 0.67974437, grad/param norm = 2.6379e-01, time/batch = 17.1624s	
22438/22750 (epoch 49.314), train_loss = 0.71247434, grad/param norm = 2.8077e-01, time/batch = 17.2423s	
22439/22750 (epoch 49.316), train_loss = 0.65821704, grad/param norm = 2.4782e-01, time/batch = 17.3011s	
22440/22750 (epoch 49.319), train_loss = 0.71176051, grad/param norm = 2.8684e-01, time/batch = 17.2457s	
22441/22750 (epoch 49.321), train_loss = 0.62450073, grad/param norm = 2.9043e-01, time/batch = 17.1596s	
22442/22750 (epoch 49.323), train_loss = 0.72392895, grad/param norm = 2.6253e-01, time/batch = 17.5650s	
22443/22750 (epoch 49.325), train_loss = 0.60200897, grad/param norm = 2.1584e-01, time/batch = 17.4446s	
22444/22750 (epoch 49.327), train_loss = 0.63058421, grad/param norm = 2.5517e-01, time/batch = 17.5181s	
22445/22750 (epoch 49.330), train_loss = 0.78509254, grad/param norm = 2.6301e-01, time/batch = 17.6733s	
22446/22750 (epoch 49.332), train_loss = 0.88965269, grad/param norm = 2.9271e-01, time/batch = 17.2982s	
22447/22750 (epoch 49.334), train_loss = 0.55975505, grad/param norm = 1.9093e-01, time/batch = 16.9212s	
22448/22750 (epoch 49.336), train_loss = 0.73351947, grad/param norm = 2.3066e-01, time/batch = 16.9277s	
22449/22750 (epoch 49.338), train_loss = 0.66905763, grad/param norm = 2.4301e-01, time/batch = 17.0286s	
22450/22750 (epoch 49.341), train_loss = 0.68050231, grad/param norm = 2.5951e-01, time/batch = 16.9250s	
22451/22750 (epoch 49.343), train_loss = 0.58612002, grad/param norm = 2.4537e-01, time/batch = 17.0647s	
22452/22750 (epoch 49.345), train_loss = 0.73781208, grad/param norm = 3.7815e-01, time/batch = 17.3095s	
22453/22750 (epoch 49.347), train_loss = 0.72926459, grad/param norm = 2.4218e-01, time/batch = 17.1476s	
22454/22750 (epoch 49.349), train_loss = 0.55726945, grad/param norm = 2.3528e-01, time/batch = 17.3685s	
22455/22750 (epoch 49.352), train_loss = 0.80709355, grad/param norm = 2.9090e-01, time/batch = 17.0854s	
22456/22750 (epoch 49.354), train_loss = 0.81194259, grad/param norm = 3.0738e-01, time/batch = 17.1778s	
22457/22750 (epoch 49.356), train_loss = 0.71785863, grad/param norm = 2.5063e-01, time/batch = 17.1038s	
22458/22750 (epoch 49.358), train_loss = 0.62942126, grad/param norm = 2.3981e-01, time/batch = 17.4762s	
22459/22750 (epoch 49.360), train_loss = 0.81279186, grad/param norm = 2.5304e-01, time/batch = 17.4671s	
22460/22750 (epoch 49.363), train_loss = 0.62864937, grad/param norm = 2.3854e-01, time/batch = 17.2604s	
22461/22750 (epoch 49.365), train_loss = 0.55188893, grad/param norm = 2.5200e-01, time/batch = 17.3343s	
22462/22750 (epoch 49.367), train_loss = 0.63026101, grad/param norm = 2.6784e-01, time/batch = 17.2516s	
22463/22750 (epoch 49.369), train_loss = 0.68608502, grad/param norm = 3.0144e-01, time/batch = 17.1526s	
22464/22750 (epoch 49.371), train_loss = 0.71511520, grad/param norm = 2.9722e-01, time/batch = 16.7633s	
22465/22750 (epoch 49.374), train_loss = 0.60315724, grad/param norm = 2.4647e-01, time/batch = 16.8566s	
22466/22750 (epoch 49.376), train_loss = 0.68298889, grad/param norm = 2.2524e-01, time/batch = 17.0218s	
22467/22750 (epoch 49.378), train_loss = 0.70143032, grad/param norm = 2.3489e-01, time/batch = 16.7835s	
22468/22750 (epoch 49.380), train_loss = 0.73442603, grad/param norm = 2.4243e-01, time/batch = 16.9962s	
22469/22750 (epoch 49.382), train_loss = 0.65066093, grad/param norm = 2.3348e-01, time/batch = 16.9881s	
22470/22750 (epoch 49.385), train_loss = 0.72336099, grad/param norm = 2.4416e-01, time/batch = 16.9230s	
22471/22750 (epoch 49.387), train_loss = 0.70117857, grad/param norm = 2.5141e-01, time/batch = 16.9159s	
22472/22750 (epoch 49.389), train_loss = 0.55189649, grad/param norm = 2.2625e-01, time/batch = 16.8458s	
22473/22750 (epoch 49.391), train_loss = 0.43025226, grad/param norm = 1.8355e-01, time/batch = 13.1901s	
22474/22750 (epoch 49.393), train_loss = 0.56287853, grad/param norm = 2.4745e-01, time/batch = 0.7610s	
22475/22750 (epoch 49.396), train_loss = 0.69103302, grad/param norm = 2.4281e-01, time/batch = 0.7518s	
22476/22750 (epoch 49.398), train_loss = 0.64277959, grad/param norm = 2.1947e-01, time/batch = 0.7589s	
22477/22750 (epoch 49.400), train_loss = 0.69898038, grad/param norm = 2.9120e-01, time/batch = 0.7557s	
22478/22750 (epoch 49.402), train_loss = 0.67537090, grad/param norm = 2.5992e-01, time/batch = 0.7624s	
22479/22750 (epoch 49.404), train_loss = 0.75936199, grad/param norm = 2.4068e-01, time/batch = 0.7641s	
22480/22750 (epoch 49.407), train_loss = 0.75918359, grad/param norm = 2.7874e-01, time/batch = 1.0013s	
22481/22750 (epoch 49.409), train_loss = 0.61785598, grad/param norm = 2.3931e-01, time/batch = 1.1094s	
22482/22750 (epoch 49.411), train_loss = 0.61877336, grad/param norm = 2.2444e-01, time/batch = 1.1044s	
22483/22750 (epoch 49.413), train_loss = 0.48381352, grad/param norm = 2.4645e-01, time/batch = 1.0883s	
22484/22750 (epoch 49.415), train_loss = 0.55651608, grad/param norm = 2.1664e-01, time/batch = 1.2428s	
22485/22750 (epoch 49.418), train_loss = 0.63578194, grad/param norm = 2.6034e-01, time/batch = 2.0054s	
22486/22750 (epoch 49.420), train_loss = 0.72561492, grad/param norm = 3.2284e-01, time/batch = 2.0370s	
22487/22750 (epoch 49.422), train_loss = 0.82963463, grad/param norm = 3.9546e-01, time/batch = 12.7378s	
22488/22750 (epoch 49.424), train_loss = 0.84935381, grad/param norm = 2.7356e-01, time/batch = 16.9171s	
22489/22750 (epoch 49.426), train_loss = 0.85768439, grad/param norm = 2.7648e-01, time/batch = 17.0823s	
22490/22750 (epoch 49.429), train_loss = 0.62287065, grad/param norm = 2.3886e-01, time/batch = 17.1333s	
22491/22750 (epoch 49.431), train_loss = 0.55748720, grad/param norm = 2.2797e-01, time/batch = 18.0973s	
22492/22750 (epoch 49.433), train_loss = 0.63794423, grad/param norm = 2.5901e-01, time/batch = 17.4896s	
22493/22750 (epoch 49.435), train_loss = 0.48890013, grad/param norm = 1.9165e-01, time/batch = 18.3297s	
22494/22750 (epoch 49.437), train_loss = 0.43293937, grad/param norm = 1.9457e-01, time/batch = 18.7592s	
22495/22750 (epoch 49.440), train_loss = 0.65128312, grad/param norm = 2.6774e-01, time/batch = 18.9902s	
22496/22750 (epoch 49.442), train_loss = 0.67140379, grad/param norm = 2.4136e-01, time/batch = 17.8008s	
22497/22750 (epoch 49.444), train_loss = 0.62941777, grad/param norm = 2.3411e-01, time/batch = 19.2498s	
22498/22750 (epoch 49.446), train_loss = 0.63956582, grad/param norm = 2.5999e-01, time/batch = 17.0569s	
22499/22750 (epoch 49.448), train_loss = 0.84531580, grad/param norm = 2.7954e-01, time/batch = 17.0664s	
22500/22750 (epoch 49.451), train_loss = 0.80576775, grad/param norm = 2.4319e-01, time/batch = 18.4070s	
22501/22750 (epoch 49.453), train_loss = 0.67995591, grad/param norm = 2.5297e-01, time/batch = 20.0106s	
22502/22750 (epoch 49.455), train_loss = 0.79473629, grad/param norm = 2.5501e-01, time/batch = 17.2750s	
22503/22750 (epoch 49.457), train_loss = 0.71209177, grad/param norm = 3.8860e-01, time/batch = 18.0059s	
22504/22750 (epoch 49.459), train_loss = 0.72922967, grad/param norm = 2.2479e-01, time/batch = 17.5003s	
22505/22750 (epoch 49.462), train_loss = 0.67416315, grad/param norm = 2.4181e-01, time/batch = 18.5002s	
22506/22750 (epoch 49.464), train_loss = 0.57744060, grad/param norm = 2.2692e-01, time/batch = 18.0784s	
22507/22750 (epoch 49.466), train_loss = 0.74378758, grad/param norm = 3.1176e-01, time/batch = 18.0164s	
22508/22750 (epoch 49.468), train_loss = 0.69924132, grad/param norm = 2.6772e-01, time/batch = 20.1592s	
22509/22750 (epoch 49.470), train_loss = 0.76022471, grad/param norm = 2.4240e-01, time/batch = 18.0943s	
22510/22750 (epoch 49.473), train_loss = 0.64600118, grad/param norm = 2.5541e-01, time/batch = 17.0497s	
22511/22750 (epoch 49.475), train_loss = 0.69106275, grad/param norm = 2.6696e-01, time/batch = 18.7253s	
22512/22750 (epoch 49.477), train_loss = 0.59591134, grad/param norm = 2.5870e-01, time/batch = 18.0122s	
22513/22750 (epoch 49.479), train_loss = 0.57255960, grad/param norm = 2.4051e-01, time/batch = 18.8478s	
22514/22750 (epoch 49.481), train_loss = 0.54552802, grad/param norm = 2.3090e-01, time/batch = 17.5894s	
22515/22750 (epoch 49.484), train_loss = 0.45850755, grad/param norm = 2.2976e-01, time/batch = 18.4962s	
22516/22750 (epoch 49.486), train_loss = 0.54940138, grad/param norm = 2.3284e-01, time/batch = 16.3565s	
22517/22750 (epoch 49.488), train_loss = 0.50796733, grad/param norm = 2.2408e-01, time/batch = 16.6439s	
22518/22750 (epoch 49.490), train_loss = 0.62892473, grad/param norm = 2.3745e-01, time/batch = 18.7344s	
22519/22750 (epoch 49.492), train_loss = 0.72806066, grad/param norm = 2.4686e-01, time/batch = 16.9869s	
22520/22750 (epoch 49.495), train_loss = 0.62146776, grad/param norm = 2.7526e-01, time/batch = 17.1365s	
22521/22750 (epoch 49.497), train_loss = 0.64487908, grad/param norm = 2.7684e-01, time/batch = 16.5130s	
22522/22750 (epoch 49.499), train_loss = 0.58318974, grad/param norm = 2.4969e-01, time/batch = 16.0276s	
22523/22750 (epoch 49.501), train_loss = 0.62961662, grad/param norm = 2.8104e-01, time/batch = 15.8571s	
22524/22750 (epoch 49.503), train_loss = 0.63131953, grad/param norm = 2.3704e-01, time/batch = 15.8512s	
22525/22750 (epoch 49.505), train_loss = 0.56573896, grad/param norm = 2.7281e-01, time/batch = 15.8498s	
22526/22750 (epoch 49.508), train_loss = 0.56236279, grad/param norm = 2.1983e-01, time/batch = 16.1476s	
22527/22750 (epoch 49.510), train_loss = 0.55911374, grad/param norm = 2.4569e-01, time/batch = 15.5269s	
22528/22750 (epoch 49.512), train_loss = 0.59746771, grad/param norm = 2.4132e-01, time/batch = 15.7754s	
22529/22750 (epoch 49.514), train_loss = 0.62182838, grad/param norm = 2.6398e-01, time/batch = 15.7731s	
22530/22750 (epoch 49.516), train_loss = 0.60098078, grad/param norm = 2.5136e-01, time/batch = 16.3421s	
22531/22750 (epoch 49.519), train_loss = 0.74443143, grad/param norm = 2.5272e-01, time/batch = 15.3915s	
22532/22750 (epoch 49.521), train_loss = 0.65485139, grad/param norm = 2.4570e-01, time/batch = 16.1914s	
22533/22750 (epoch 49.523), train_loss = 0.56989268, grad/param norm = 2.6323e-01, time/batch = 15.6322s	
22534/22750 (epoch 49.525), train_loss = 0.72543584, grad/param norm = 2.6839e-01, time/batch = 15.6942s	
22535/22750 (epoch 49.527), train_loss = 0.67667698, grad/param norm = 2.4926e-01, time/batch = 15.6933s	
22536/22750 (epoch 49.530), train_loss = 0.59690335, grad/param norm = 2.3488e-01, time/batch = 15.5331s	
22537/22750 (epoch 49.532), train_loss = 0.55425189, grad/param norm = 2.3759e-01, time/batch = 15.9435s	
22538/22750 (epoch 49.534), train_loss = 0.67715791, grad/param norm = 2.3587e-01, time/batch = 15.9354s	
22539/22750 (epoch 49.536), train_loss = 0.68495516, grad/param norm = 2.1678e-01, time/batch = 16.8733s	
22540/22750 (epoch 49.538), train_loss = 0.67923882, grad/param norm = 2.2747e-01, time/batch = 15.5901s	
22541/22750 (epoch 49.541), train_loss = 0.57306386, grad/param norm = 2.4537e-01, time/batch = 15.9324s	
22542/22750 (epoch 49.543), train_loss = 0.54491236, grad/param norm = 1.9624e-01, time/batch = 16.3255s	
22543/22750 (epoch 49.545), train_loss = 0.70417786, grad/param norm = 2.3834e-01, time/batch = 16.1041s	
22544/22750 (epoch 49.547), train_loss = 0.61468223, grad/param norm = 1.9489e-01, time/batch = 15.3852s	
22545/22750 (epoch 49.549), train_loss = 0.63004927, grad/param norm = 2.3147e-01, time/batch = 15.9533s	
22546/22750 (epoch 49.552), train_loss = 0.67828397, grad/param norm = 2.2777e-01, time/batch = 15.4607s	
22547/22750 (epoch 49.554), train_loss = 0.66849593, grad/param norm = 2.2671e-01, time/batch = 15.4513s	
22548/22750 (epoch 49.556), train_loss = 0.69432546, grad/param norm = 2.4421e-01, time/batch = 15.5333s	
22549/22750 (epoch 49.558), train_loss = 0.63868204, grad/param norm = 2.2288e-01, time/batch = 16.1650s	
22550/22750 (epoch 49.560), train_loss = 0.60050764, grad/param norm = 2.2685e-01, time/batch = 15.4384s	
22551/22750 (epoch 49.563), train_loss = 0.72171044, grad/param norm = 2.5592e-01, time/batch = 16.0890s	
22552/22750 (epoch 49.565), train_loss = 0.73149806, grad/param norm = 3.1309e-01, time/batch = 15.8501s	
22553/22750 (epoch 49.567), train_loss = 0.68266906, grad/param norm = 2.4083e-01, time/batch = 15.8558s	
22554/22750 (epoch 49.569), train_loss = 0.65891605, grad/param norm = 2.3676e-01, time/batch = 15.8492s	
22555/22750 (epoch 49.571), train_loss = 0.64448862, grad/param norm = 2.7370e-01, time/batch = 15.3712s	
22556/22750 (epoch 49.574), train_loss = 0.66827542, grad/param norm = 2.7697e-01, time/batch = 15.8638s	
22557/22750 (epoch 49.576), train_loss = 0.64917801, grad/param norm = 2.2194e-01, time/batch = 15.8636s	
22558/22750 (epoch 49.578), train_loss = 0.55291150, grad/param norm = 2.3054e-01, time/batch = 15.7179s	
22559/22750 (epoch 49.580), train_loss = 0.67114382, grad/param norm = 2.4265e-01, time/batch = 15.6185s	
22560/22750 (epoch 49.582), train_loss = 0.60184859, grad/param norm = 2.3578e-01, time/batch = 16.4163s	
22561/22750 (epoch 49.585), train_loss = 0.55546161, grad/param norm = 2.1214e-01, time/batch = 15.6112s	
22562/22750 (epoch 49.587), train_loss = 0.57865274, grad/param norm = 2.2355e-01, time/batch = 15.4607s	
22563/22750 (epoch 49.589), train_loss = 0.47975830, grad/param norm = 1.7691e-01, time/batch = 15.6096s	
22564/22750 (epoch 49.591), train_loss = 0.63097351, grad/param norm = 2.1042e-01, time/batch = 16.0191s	
22565/22750 (epoch 49.593), train_loss = 0.74887629, grad/param norm = 2.6797e-01, time/batch = 15.4507s	
22566/22750 (epoch 49.596), train_loss = 0.71445447, grad/param norm = 2.8746e-01, time/batch = 16.4693s	
22567/22750 (epoch 49.598), train_loss = 0.72527929, grad/param norm = 3.0243e-01, time/batch = 15.6921s	
22568/22750 (epoch 49.600), train_loss = 0.79886564, grad/param norm = 2.5571e-01, time/batch = 15.8777s	
22569/22750 (epoch 49.602), train_loss = 0.57568016, grad/param norm = 2.2495e-01, time/batch = 15.2245s	
22570/22750 (epoch 49.604), train_loss = 0.60984531, grad/param norm = 2.5388e-01, time/batch = 16.4796s	
22571/22750 (epoch 49.607), train_loss = 0.57291016, grad/param norm = 2.1155e-01, time/batch = 15.6201s	
22572/22750 (epoch 49.609), train_loss = 0.54411466, grad/param norm = 2.5068e-01, time/batch = 15.6834s	
22573/22750 (epoch 49.611), train_loss = 0.59664258, grad/param norm = 2.4438e-01, time/batch = 15.6872s	
22574/22750 (epoch 49.613), train_loss = 0.58212911, grad/param norm = 2.2593e-01, time/batch = 15.6207s	
22575/22750 (epoch 49.615), train_loss = 0.61105784, grad/param norm = 2.2280e-01, time/batch = 16.1743s	
22576/22750 (epoch 49.618), train_loss = 0.64429528, grad/param norm = 2.0557e-01, time/batch = 16.3336s	
22577/22750 (epoch 49.620), train_loss = 0.59995390, grad/param norm = 2.3459e-01, time/batch = 15.6221s	
22578/22750 (epoch 49.622), train_loss = 0.56018956, grad/param norm = 2.3078e-01, time/batch = 15.4638s	
22579/22750 (epoch 49.624), train_loss = 0.58954807, grad/param norm = 2.3201e-01, time/batch = 16.1659s	
22580/22750 (epoch 49.626), train_loss = 0.53473279, grad/param norm = 2.0654e-01, time/batch = 15.5238s	
22581/22750 (epoch 49.629), train_loss = 0.59573912, grad/param norm = 2.4299e-01, time/batch = 15.6227s	
22582/22750 (epoch 49.631), train_loss = 0.61389146, grad/param norm = 2.2028e-01, time/batch = 15.4676s	
22583/22750 (epoch 49.633), train_loss = 0.54545984, grad/param norm = 2.0212e-01, time/batch = 16.1009s	
22584/22750 (epoch 49.635), train_loss = 0.62610027, grad/param norm = 2.0843e-01, time/batch = 15.9968s	
22585/22750 (epoch 49.637), train_loss = 0.67063680, grad/param norm = 3.1466e-01, time/batch = 15.6038s	
22586/22750 (epoch 49.640), train_loss = 0.67118660, grad/param norm = 2.3070e-01, time/batch = 15.9374s	
22587/22750 (epoch 49.642), train_loss = 0.70607940, grad/param norm = 2.2719e-01, time/batch = 15.9285s	
22588/22750 (epoch 49.644), train_loss = 0.64892495, grad/param norm = 3.0564e-01, time/batch = 15.7739s	
22589/22750 (epoch 49.646), train_loss = 0.70588389, grad/param norm = 2.8805e-01, time/batch = 16.2325s	
22590/22750 (epoch 49.648), train_loss = 0.70674373, grad/param norm = 2.7569e-01, time/batch = 16.0860s	
22591/22750 (epoch 49.651), train_loss = 0.69309207, grad/param norm = 2.3785e-01, time/batch = 16.1045s	
22592/22750 (epoch 49.653), train_loss = 0.72097145, grad/param norm = 2.3531e-01, time/batch = 17.1374s	
22593/22750 (epoch 49.655), train_loss = 0.67046359, grad/param norm = 2.2885e-01, time/batch = 16.9678s	
22594/22750 (epoch 49.657), train_loss = 0.77440612, grad/param norm = 2.6244e-01, time/batch = 17.1508s	
22595/22750 (epoch 49.659), train_loss = 0.82066421, grad/param norm = 2.4633e-01, time/batch = 17.0092s	
22596/22750 (epoch 49.662), train_loss = 0.79837474, grad/param norm = 3.2758e-01, time/batch = 17.1519s	
22597/22750 (epoch 49.664), train_loss = 0.68699972, grad/param norm = 2.6939e-01, time/batch = 17.3165s	
22598/22750 (epoch 49.666), train_loss = 0.57730891, grad/param norm = 2.0932e-01, time/batch = 17.2585s	
22599/22750 (epoch 49.668), train_loss = 0.61974212, grad/param norm = 2.2851e-01, time/batch = 17.4660s	
22600/22750 (epoch 49.670), train_loss = 0.58248675, grad/param norm = 2.4264e-01, time/batch = 17.0259s	
22601/22750 (epoch 49.673), train_loss = 0.78420242, grad/param norm = 2.6108e-01, time/batch = 17.1135s	
22602/22750 (epoch 49.675), train_loss = 0.89700468, grad/param norm = 3.7599e-01, time/batch = 17.1203s	
22603/22750 (epoch 49.677), train_loss = 0.76341452, grad/param norm = 2.7282e-01, time/batch = 16.9747s	
22604/22750 (epoch 49.679), train_loss = 0.75728907, grad/param norm = 3.1729e-01, time/batch = 17.0968s	
22605/22750 (epoch 49.681), train_loss = 0.76685533, grad/param norm = 2.6868e-01, time/batch = 17.0931s	
22606/22750 (epoch 49.684), train_loss = 0.80466081, grad/param norm = 2.6203e-01, time/batch = 17.0818s	
22607/22750 (epoch 49.686), train_loss = 0.84510024, grad/param norm = 3.2427e-01, time/batch = 17.2577s	
22608/22750 (epoch 49.688), train_loss = 0.76999185, grad/param norm = 2.6310e-01, time/batch = 17.0805s	
22609/22750 (epoch 49.690), train_loss = 0.77641216, grad/param norm = 2.7406e-01, time/batch = 17.1334s	
22610/22750 (epoch 49.692), train_loss = 0.76167123, grad/param norm = 2.5851e-01, time/batch = 17.2739s	
22611/22750 (epoch 49.695), train_loss = 0.68860225, grad/param norm = 2.2727e-01, time/batch = 17.2613s	
22612/22750 (epoch 49.697), train_loss = 0.71645468, grad/param norm = 2.2931e-01, time/batch = 17.1120s	
22613/22750 (epoch 49.699), train_loss = 0.61028326, grad/param norm = 2.2490e-01, time/batch = 17.2723s	
22614/22750 (epoch 49.701), train_loss = 0.55879604, grad/param norm = 2.3514e-01, time/batch = 17.1987s	
22615/22750 (epoch 49.703), train_loss = 0.62787422, grad/param norm = 2.3825e-01, time/batch = 17.2454s	
22616/22750 (epoch 49.705), train_loss = 0.60965124, grad/param norm = 3.0629e-01, time/batch = 17.3267s	
22617/22750 (epoch 49.708), train_loss = 0.65069646, grad/param norm = 2.7245e-01, time/batch = 17.2452s	
22618/22750 (epoch 49.710), train_loss = 0.58367137, grad/param norm = 2.1691e-01, time/batch = 17.3300s	
22619/22750 (epoch 49.712), train_loss = 0.49307897, grad/param norm = 2.1058e-01, time/batch = 17.1692s	
22620/22750 (epoch 49.714), train_loss = 0.56460117, grad/param norm = 2.1154e-01, time/batch = 17.2527s	
22621/22750 (epoch 49.716), train_loss = 0.56510087, grad/param norm = 2.1219e-01, time/batch = 17.2562s	
22622/22750 (epoch 49.719), train_loss = 0.62995590, grad/param norm = 2.8965e-01, time/batch = 17.5559s	
22623/22750 (epoch 49.721), train_loss = 0.76973406, grad/param norm = 2.2691e-01, time/batch = 17.1916s	
22624/22750 (epoch 49.723), train_loss = 0.72503886, grad/param norm = 3.0920e-01, time/batch = 17.2324s	
22625/22750 (epoch 49.725), train_loss = 0.61140022, grad/param norm = 2.7004e-01, time/batch = 17.1739s	
22626/22750 (epoch 49.727), train_loss = 0.66872206, grad/param norm = 2.4297e-01, time/batch = 17.1513s	
22627/22750 (epoch 49.730), train_loss = 0.62815387, grad/param norm = 2.5198e-01, time/batch = 17.0901s	
22628/22750 (epoch 49.732), train_loss = 0.61034328, grad/param norm = 2.2737e-01, time/batch = 18.7881s	
22629/22750 (epoch 49.734), train_loss = 0.55709079, grad/param norm = 2.1072e-01, time/batch = 29.3093s	
22630/22750 (epoch 49.736), train_loss = 0.62584922, grad/param norm = 2.7161e-01, time/batch = 17.3058s	
22631/22750 (epoch 49.738), train_loss = 0.67922002, grad/param norm = 2.6994e-01, time/batch = 17.1608s	
22632/22750 (epoch 49.741), train_loss = 0.78818400, grad/param norm = 2.4435e-01, time/batch = 17.4988s	
22633/22750 (epoch 49.743), train_loss = 0.65619999, grad/param norm = 2.3238e-01, time/batch = 17.0132s	
22634/22750 (epoch 49.745), train_loss = 0.56062750, grad/param norm = 1.9122e-01, time/batch = 17.0112s	
22635/22750 (epoch 49.747), train_loss = 0.66374118, grad/param norm = 2.3578e-01, time/batch = 17.4070s	
22636/22750 (epoch 49.749), train_loss = 0.76749978, grad/param norm = 2.5161e-01, time/batch = 17.3291s	
22637/22750 (epoch 49.752), train_loss = 0.68476160, grad/param norm = 2.5274e-01, time/batch = 17.4120s	
22638/22750 (epoch 49.754), train_loss = 0.65408348, grad/param norm = 2.4405e-01, time/batch = 17.4640s	
22639/22750 (epoch 49.756), train_loss = 0.61287710, grad/param norm = 2.3835e-01, time/batch = 17.4336s	
22640/22750 (epoch 49.758), train_loss = 0.59537247, grad/param norm = 2.3777e-01, time/batch = 17.3554s	
22641/22750 (epoch 49.760), train_loss = 0.58650489, grad/param norm = 2.6316e-01, time/batch = 17.4430s	
22642/22750 (epoch 49.763), train_loss = 0.63055836, grad/param norm = 2.4187e-01, time/batch = 17.2396s	
22643/22750 (epoch 49.765), train_loss = 0.63986639, grad/param norm = 2.5145e-01, time/batch = 17.2569s	
22644/22750 (epoch 49.767), train_loss = 0.68721582, grad/param norm = 2.2567e-01, time/batch = 17.3336s	
22645/22750 (epoch 49.769), train_loss = 0.75985701, grad/param norm = 3.0591e-01, time/batch = 17.5352s	
22646/22750 (epoch 49.771), train_loss = 0.76830620, grad/param norm = 3.0199e-01, time/batch = 17.3993s	
22647/22750 (epoch 49.774), train_loss = 0.60200308, grad/param norm = 2.3165e-01, time/batch = 17.0854s	
22648/22750 (epoch 49.776), train_loss = 0.73155897, grad/param norm = 2.5264e-01, time/batch = 17.4023s	
22649/22750 (epoch 49.778), train_loss = 0.73795880, grad/param norm = 2.4469e-01, time/batch = 17.4343s	
22650/22750 (epoch 49.780), train_loss = 0.68326448, grad/param norm = 2.3875e-01, time/batch = 17.3462s	
22651/22750 (epoch 49.782), train_loss = 0.77124390, grad/param norm = 2.7227e-01, time/batch = 17.4475s	
22652/22750 (epoch 49.785), train_loss = 0.64426046, grad/param norm = 2.5212e-01, time/batch = 17.4436s	
22653/22750 (epoch 49.787), train_loss = 0.56200504, grad/param norm = 3.0450e-01, time/batch = 17.2526s	
22654/22750 (epoch 49.789), train_loss = 0.63673935, grad/param norm = 2.1035e-01, time/batch = 17.3423s	
22655/22750 (epoch 49.791), train_loss = 0.62437356, grad/param norm = 2.5497e-01, time/batch = 17.3272s	
22656/22750 (epoch 49.793), train_loss = 0.61358504, grad/param norm = 2.5945e-01, time/batch = 17.2484s	
22657/22750 (epoch 49.796), train_loss = 0.55199226, grad/param norm = 2.0261e-01, time/batch = 17.3129s	
22658/22750 (epoch 49.798), train_loss = 0.61659982, grad/param norm = 2.1354e-01, time/batch = 17.3367s	
22659/22750 (epoch 49.800), train_loss = 0.60919191, grad/param norm = 3.0665e-01, time/batch = 17.4427s	
22660/22750 (epoch 49.802), train_loss = 0.57100797, grad/param norm = 3.7109e-01, time/batch = 17.3671s	
22661/22750 (epoch 49.804), train_loss = 0.72996280, grad/param norm = 2.2444e-01, time/batch = 17.6858s	
22662/22750 (epoch 49.807), train_loss = 0.69039142, grad/param norm = 2.4139e-01, time/batch = 17.4083s	
22663/22750 (epoch 49.809), train_loss = 0.77854458, grad/param norm = 2.7363e-01, time/batch = 17.4275s	
22664/22750 (epoch 49.811), train_loss = 0.66862169, grad/param norm = 2.4007e-01, time/batch = 17.3368s	
22665/22750 (epoch 49.813), train_loss = 0.68252745, grad/param norm = 2.4913e-01, time/batch = 17.5665s	
22666/22750 (epoch 49.815), train_loss = 0.77073236, grad/param norm = 2.4330e-01, time/batch = 17.3381s	
22667/22750 (epoch 49.818), train_loss = 0.73306733, grad/param norm = 2.3496e-01, time/batch = 17.2589s	
22668/22750 (epoch 49.820), train_loss = 0.81858909, grad/param norm = 2.2313e-01, time/batch = 17.3164s	
22669/22750 (epoch 49.822), train_loss = 0.69507777, grad/param norm = 2.7841e-01, time/batch = 17.4066s	
22670/22750 (epoch 49.824), train_loss = 0.57794175, grad/param norm = 2.0156e-01, time/batch = 17.3482s	
22671/22750 (epoch 49.826), train_loss = 0.65451366, grad/param norm = 3.4643e-01, time/batch = 17.1826s	
22672/22750 (epoch 49.829), train_loss = 0.73428146, grad/param norm = 2.6145e-01, time/batch = 17.5677s	
22673/22750 (epoch 49.831), train_loss = 0.76065284, grad/param norm = 2.9485e-01, time/batch = 17.4842s	
22674/22750 (epoch 49.833), train_loss = 0.68356557, grad/param norm = 2.8766e-01, time/batch = 17.3216s	
22675/22750 (epoch 49.835), train_loss = 0.58906829, grad/param norm = 2.9605e-01, time/batch = 17.2469s	
22676/22750 (epoch 49.837), train_loss = 0.66174683, grad/param norm = 2.5092e-01, time/batch = 17.0846s	
22677/22750 (epoch 49.840), train_loss = 0.58115284, grad/param norm = 2.5232e-01, time/batch = 17.0113s	
22678/22750 (epoch 49.842), train_loss = 0.58806258, grad/param norm = 2.3919e-01, time/batch = 17.1050s	
22679/22750 (epoch 49.844), train_loss = 0.69364481, grad/param norm = 2.6896e-01, time/batch = 17.2675s	
22680/22750 (epoch 49.846), train_loss = 0.73118523, grad/param norm = 2.5067e-01, time/batch = 17.1081s	
22681/22750 (epoch 49.848), train_loss = 0.64949252, grad/param norm = 3.1291e-01, time/batch = 16.9358s	
22682/22750 (epoch 49.851), train_loss = 0.62597384, grad/param norm = 2.3963e-01, time/batch = 16.8373s	
22683/22750 (epoch 49.853), train_loss = 0.77433546, grad/param norm = 2.4595e-01, time/batch = 16.9668s	
22684/22750 (epoch 49.855), train_loss = 0.65042837, grad/param norm = 2.2140e-01, time/batch = 16.3121s	
22685/22750 (epoch 49.857), train_loss = 0.69663133, grad/param norm = 2.3000e-01, time/batch = 15.8228s	
22686/22750 (epoch 49.859), train_loss = 0.69270365, grad/param norm = 2.4325e-01, time/batch = 16.1133s	
22687/22750 (epoch 49.862), train_loss = 0.80063516, grad/param norm = 2.6207e-01, time/batch = 15.9182s	
22688/22750 (epoch 49.864), train_loss = 0.68013675, grad/param norm = 2.7419e-01, time/batch = 16.4892s	
22689/22750 (epoch 49.866), train_loss = 0.70623157, grad/param norm = 2.2936e-01, time/batch = 15.3898s	
22690/22750 (epoch 49.868), train_loss = 0.59204016, grad/param norm = 2.1965e-01, time/batch = 15.7922s	
22691/22750 (epoch 49.870), train_loss = 0.60989258, grad/param norm = 2.6487e-01, time/batch = 15.6399s	
22692/22750 (epoch 49.873), train_loss = 0.67129680, grad/param norm = 2.5560e-01, time/batch = 15.9428s	
22693/22750 (epoch 49.875), train_loss = 0.70521777, grad/param norm = 2.6121e-01, time/batch = 15.5171s	
22694/22750 (epoch 49.877), train_loss = 0.63738103, grad/param norm = 2.2530e-01, time/batch = 15.9212s	
22695/22750 (epoch 49.879), train_loss = 0.75365575, grad/param norm = 2.8620e-01, time/batch = 15.2093s	
22696/22750 (epoch 49.881), train_loss = 0.66582619, grad/param norm = 2.2906e-01, time/batch = 15.6074s	
22697/22750 (epoch 49.884), train_loss = 0.58461233, grad/param norm = 2.3660e-01, time/batch = 15.3515s	
22698/22750 (epoch 49.886), train_loss = 0.68706205, grad/param norm = 2.2264e-01, time/batch = 15.8384s	
22699/22750 (epoch 49.888), train_loss = 0.71519119, grad/param norm = 2.2409e-01, time/batch = 15.6082s	
22700/22750 (epoch 49.890), train_loss = 0.73901432, grad/param norm = 2.9038e-01, time/batch = 15.6902s	
22701/22750 (epoch 49.892), train_loss = 0.87623102, grad/param norm = 2.8446e-01, time/batch = 15.4590s	
22702/22750 (epoch 49.895), train_loss = 0.64076350, grad/param norm = 3.1234e-01, time/batch = 19.2460s	
22703/22750 (epoch 49.897), train_loss = 0.76200258, grad/param norm = 2.4868e-01, time/batch = 16.9247s	
22704/22750 (epoch 49.899), train_loss = 0.68422422, grad/param norm = 2.4850e-01, time/batch = 17.5658s	
22705/22750 (epoch 49.901), train_loss = 0.76529229, grad/param norm = 2.9941e-01, time/batch = 17.0544s	
22706/22750 (epoch 49.903), train_loss = 0.65034923, grad/param norm = 2.4588e-01, time/batch = 16.4969s	
22707/22750 (epoch 49.905), train_loss = 0.69491922, grad/param norm = 2.5662e-01, time/batch = 15.8485s	
22708/22750 (epoch 49.908), train_loss = 0.55516470, grad/param norm = 2.5344e-01, time/batch = 16.0989s	
22709/22750 (epoch 49.910), train_loss = 0.51746299, grad/param norm = 2.1487e-01, time/batch = 16.8656s	
22710/22750 (epoch 49.912), train_loss = 0.68360081, grad/param norm = 2.6535e-01, time/batch = 15.3194s	
22711/22750 (epoch 49.914), train_loss = 0.71779627, grad/param norm = 2.9730e-01, time/batch = 15.7934s	
22712/22750 (epoch 49.916), train_loss = 0.55800158, grad/param norm = 2.4751e-01, time/batch = 15.6302s	
22713/22750 (epoch 49.919), train_loss = 0.67535873, grad/param norm = 2.6340e-01, time/batch = 15.8608s	
22714/22750 (epoch 49.921), train_loss = 0.51750682, grad/param norm = 2.1904e-01, time/batch = 15.7033s	
22715/22750 (epoch 49.923), train_loss = 0.64156987, grad/param norm = 2.3526e-01, time/batch = 15.6147s	
22716/22750 (epoch 49.925), train_loss = 0.68014603, grad/param norm = 2.3863e-01, time/batch = 16.2542s	
22717/22750 (epoch 49.927), train_loss = 0.52122890, grad/param norm = 2.2323e-01, time/batch = 15.5210s	
22718/22750 (epoch 49.930), train_loss = 0.50054508, grad/param norm = 2.1470e-01, time/batch = 15.8297s	
22719/22750 (epoch 49.932), train_loss = 0.64317761, grad/param norm = 2.5325e-01, time/batch = 14.8877s	
22720/22750 (epoch 49.934), train_loss = 0.57540672, grad/param norm = 2.0785e-01, time/batch = 15.4760s	
22721/22750 (epoch 49.936), train_loss = 0.74457652, grad/param norm = 2.6449e-01, time/batch = 15.4647s	
22722/22750 (epoch 49.938), train_loss = 0.73243574, grad/param norm = 2.3867e-01, time/batch = 15.5641s	
22723/22750 (epoch 49.941), train_loss = 0.76303758, grad/param norm = 2.7043e-01, time/batch = 15.3893s	
22724/22750 (epoch 49.943), train_loss = 0.65604650, grad/param norm = 2.0446e-01, time/batch = 16.6349s	
22725/22750 (epoch 49.945), train_loss = 0.70340689, grad/param norm = 2.8745e-01, time/batch = 16.4702s	
22726/22750 (epoch 49.947), train_loss = 0.62481344, grad/param norm = 2.9122e-01, time/batch = 15.6985s	
22727/22750 (epoch 49.949), train_loss = 0.62871022, grad/param norm = 2.1483e-01, time/batch = 15.5319s	
22728/22750 (epoch 49.952), train_loss = 0.64704747, grad/param norm = 2.5031e-01, time/batch = 15.8644s	
22729/22750 (epoch 49.954), train_loss = 0.55824429, grad/param norm = 2.2626e-01, time/batch = 15.7019s	
22730/22750 (epoch 49.956), train_loss = 0.71414290, grad/param norm = 2.3800e-01, time/batch = 15.7901s	
22731/22750 (epoch 49.958), train_loss = 0.57758848, grad/param norm = 1.8735e-01, time/batch = 15.7231s	
22732/22750 (epoch 49.960), train_loss = 0.57250605, grad/param norm = 2.8407e-01, time/batch = 15.8017s	
22733/22750 (epoch 49.963), train_loss = 0.67355514, grad/param norm = 2.1401e-01, time/batch = 15.7078s	
22734/22750 (epoch 49.965), train_loss = 0.73073099, grad/param norm = 2.2433e-01, time/batch = 15.2294s	
22735/22750 (epoch 49.967), train_loss = 0.70408941, grad/param norm = 2.3597e-01, time/batch = 16.2602s	
22736/22750 (epoch 49.969), train_loss = 0.62713271, grad/param norm = 2.6355e-01, time/batch = 15.8508s	
22737/22750 (epoch 49.971), train_loss = 0.59420046, grad/param norm = 2.2672e-01, time/batch = 15.9992s	
22738/22750 (epoch 49.974), train_loss = 0.61073978, grad/param norm = 2.6199e-01, time/batch = 15.4500s	
22739/22750 (epoch 49.976), train_loss = 0.61841277, grad/param norm = 2.2754e-01, time/batch = 16.1727s	
22740/22750 (epoch 49.978), train_loss = 0.59944241, grad/param norm = 2.5319e-01, time/batch = 15.8333s	
22741/22750 (epoch 49.980), train_loss = 0.77377156, grad/param norm = 2.6079e-01, time/batch = 15.1367s	
22742/22750 (epoch 49.982), train_loss = 0.60686395, grad/param norm = 1.9792e-01, time/batch = 15.0000s	
22743/22750 (epoch 49.985), train_loss = 0.78056444, grad/param norm = 2.6058e-01, time/batch = 15.7165s	
22744/22750 (epoch 49.987), train_loss = 0.54417527, grad/param norm = 2.6050e-01, time/batch = 15.0051s	
22745/22750 (epoch 49.989), train_loss = 0.58465156, grad/param norm = 2.5938e-01, time/batch = 15.5358s	
22746/22750 (epoch 49.991), train_loss = 0.70685208, grad/param norm = 2.5128e-01, time/batch = 16.4774s	
22747/22750 (epoch 49.993), train_loss = 0.64555035, grad/param norm = 2.8558e-01, time/batch = 16.6587s	
22748/22750 (epoch 49.996), train_loss = 0.57619594, grad/param norm = 2.3010e-01, time/batch = 16.3461s	
22749/22750 (epoch 49.998), train_loss = 0.74398821, grad/param norm = 2.6052e-01, time/batch = 15.3670s	
decayed learning rate by a factor 0.97 to 0.00057368183755432	
evaluating loss over split index 2	
1/24...	
2/24...	
3/24...	
4/24...	
5/24...	
6/24...	
7/24...	
8/24...	
9/24...	
10/24...	
11/24...	
12/24...	
13/24...	
14/24...	
15/24...	
16/24...	
17/24...	
18/24...	
19/24...	
20/24...	
21/24...	
22/24...	
23/24...	
24/24...	
saving checkpoint to /home/ubuntu/scimirrorbot/dat/models/lm_astro_wakata_epoch50.00_1.8754.t7	
22750/22750 (epoch 50.000), train_loss = 0.65357673, grad/param norm = 2.5422e-01, time/batch = 15.4347s	

real	4985m44.099s
user	4948m14.956s
sys	4m11.976s
